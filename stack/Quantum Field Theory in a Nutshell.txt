
Praise for the first edition
“Quantum field theory is an extraordinarily beautiful subject, but it can be an intimidating
one. The profound and deeply physical concepts it embodies can get lost, to the beginner,
amidst its technicalities. In this book, Zee imparts the wisdom of an experienced and
remarkably creative practitioner in a user-friendly style. I wish something like it had been
available when I was a student.”
—Frank Wilczek, Massachusetts Institute of Technology
“Finally! Zee has written a ground-breaking quantum field theory text based on the course
I made him teach when I chaired the Princeton physics department. With utmost clarity
he gives the eager student a light-hearted and easy-going introduction to the multifaceted
wonders of quantum field theory. I wish I had this book when I taught the subject.”
—Marvin L. Goldberger, President, Emeritus, California Institute of Technology
“This book is filled with charming explanations that students will find beneficial.”
—Ed Witten, Institute for Advanced Study
“This book is perhaps the most user-friendly introductory text to the essentials of quantum
field theory and its many modern applications. With his physically intuitive approach,
Professor Zee makes a serious topic more reachable for beginners, reducing the conceptual
barrier while preserving enough mathematical details necessary for a firm grasp of the
subject.”
—Bei Lok Hu, University of Maryland
“Like the famous Feynman Lectures on Physics, this book has the flavor of a good
blackboard lecture. Zee presents technical details, but only insofar as they serve the larger
purpose of giving insight into quantum field theory and bringing out its beauty.”
—Stephen M. Barr, University of Delaware
“This is a fantastic book—exciting, amusing, unique, and very valuable.”
—Clifford V. Johnson, University of Durham
“Tony Zee explains quantum field theory with a clear and engaging style. For budding or
seasoned condensed matter physicists alike, he shows us that field theory is a nourishing
nut to be cracked and savored.”
—Matthew P. A. Fisher, Kavli Institute for Theoretical Physics
“I was so engrossed that I spent all of Saturday and Sunday one weekend absorbing half
the book, to my wife’s dismay. Zee has a talent for explaining the most abstruse and
arcane concepts in an elegant way, using the minimum number of equations (the jokes
and anecdotes help). . . . I wish this were available when I was a graduate student. Buy
the book, keep it by your bed, and relish the insights delivered with such flair and grace.”
—N. P. Ong, Princeton University

What readers are saying
“Funny, chatty, physical: QFT education transformed!! This text stands apart from others
in so many ways that it’s difficult to list them all. . . . The exposition is breezy and chatty.
The text is never boring to read, and is at times very, very funny. Puns and jokes abound,
as do anecdotes. . . . A book which is much easier, and more fun, to read than any of the
others. Zee’s skills as a popular physics writer have been used to excellent effect in writing
this textbook. . . . Wholeheartedly recommended.”
—M. Haque
“A readable, and rereadable instant classic on QFT. . . . At an introductory level, this type
of book—with its pedagogical (and often very funny) narrative—is priceless. [It] is full
of fantastic insights akin to reading the Feynman lectures. I have since used QFT in a
Nutshell as a review for [my] year-long course covering all of Peskin and Schroder, and
have been pleasantly surprised at how Zee is able to preemptively answer many of the
open questions that eluded me during my course. . . . I value QFT in a Nutshell the same
way I do the Feynman lectures. . . . It’s a text to teach an understanding of physics.”
—Flip Tanedo
“One of those books a person interested in theoretical physics simply must own! A real
scientific masterpiece. I bought it at the time I was a physics sophomore and that was the
best choice I could have made. It was this book that triggered my interest in quantum field
theory and crystallized my dreams of becoming a theoretical physicist. . . . The main goal
of the book is to make the reader gain real intuition in the field. Amazing . . . amusing . . .
real fun. What also distinguishes this book from others dealing with a similar subject
is that it is written like a tale. . . . I feel enormously fortunate to have come across this
book at the beginning of my adventure with theoretical physics. . . . Definitely the best
quantum field theory book I have ever read.”
—Anonymous
“I have used Quantum Field Theory in a Nutshell as the primary text. . . . I am immensely
pleased with the book, and recommend it highly. . . . Don’t let the ‘damn the torpedoes,
full steam ahead’ approach scare you off. Once you get used to seeing the physics quickly,
I think you will find the experience very satisfying intellectually.”
—Jim Napolitano
“This is undoubtedly the best book I have ever read about the subject. Zee does a fantastic
job of explaining quantum field theory, in a way I have never seen before, and I have
read most of the other books on this topic. If you are looking for quantum field theory
explanations that are clear, precise, concise, intuitive, and fun to read—this is the book
for you.”
—Anonymous

“One of the most artistic and deepest books ever written on quantum field theory.
Amazing . . . extremely pleasant . . . a lot of very deep and illuminating remarks. . . . I
recommend the book by Zee to everybody who wants to get a clear idea what good physics
is about.”
—Slava Mukhanov
“Perfect for learning field theory on your own—by far the clearest and easiest to follow
book I’ve found on the subject.”
—Ian Z. Lovejoy
“A beautifully written introduction to the modern view of fields . . . breezy and
enchanting, leading to exceptional clarity without sacrificing depth, breadth, or rigor
of content. . . . [It] passes my test of true greatness: I wish it had been the first book on
this topic that I had found.”
—Jeffrey D. Scargle
“A breeze of fresh air . . . a real literary gem which will be useful for students who make
their first steps in this difficult subject and an enjoyable treat for experts, who will find
new and deep insights. Indeed, the Nutshell is like a bright light source shining among
tall and heavy trees—the many more formal books that exist—and helps seeing the forest
as a whole! . . . I have been practicing QFT during the past two decades and with all my
experience I was thrilled with enjoyment when I read some of the sections.”
—Joshua Feinberg
“This text not only teaches up-to-date quantum field theory, but also tells readers how
research is actually done and shows them how to think about physics. [It teaches things
that] people usually say ‘cannot be learned from books.’ [It is] in the same style as Fearful
Symmetry and Einstein’s Universe. All three books . . . are classics.”
—Yu Shi
“I belong to the [group of] enthusiastic laymen having enough curiosity and insistence . . .
but lacking the mastery of advanced math and physics. . . . I really could not see the forest
for the trees. But at long last I got this book!”
—Makay Attila
“More fun than any other QFT book I have read. The comparisons to Feynman’s
writings made by several of the reviewers seem quite apt. . . . His enthusiasm is quite
infectious. . . . I doubt that any other book will spark your interest like this one does.”
—Stephen Wandzura
“I’m having a blast reading this book. It’s both deep and entertaining; this is a rare breed,
indeed. I usually prefer the more formal style (big Landau fan), but I have to say that when
Zee has the talent to present things his way, it’s a definite plus.”
—Pierre Jouvelot

“Required reading for QFT: [it] heralds the introduction of a book on quantum field theory
that you can sit down and read. My professor’s lectures made much more sense as I
followed along in this book, because concepts were actually EXPLAINED, not just worked
out.”
—Alexander Scott
“Not your father’s quantum field theory text: I particularly appreciate that things are
motivated physically before their mathematical articulation. . . . Most especially though,
the author’s ‘heuristic’ descriptions are the best I have read anywhere. From them alone
the essential ideas become crystal clear.”
—Dan Dill

Q uantum Field Theory in a Nutshell

This page intentionally left blank

Q uantum Field Theory in a Nutshell
SECOND EDITION
A. Zee
P R I N C E T O N
U N I V E R S I T Y
P R E S S
.
P R I N C E T O N
A N D
O X F O R D

Copyright © 2010 by Princeton University Press
Published by Princeton University Press, 41 William Street,
Princeton, New Jersey 08540
In the United Kingdom: Princeton University Press,
6 Oxford Street, Woodstock, Oxfordshire OX20 1TW
All Rights Reserved
Library of Congress Cataloging-in-Publication Data
Zee, A.
Quantum field theory in a nutshell / A. Zee.—2nd ed.
p.
cm.
Includes bibliographical references and index.
ISBN 978-0-691-14034-6 (hardcover : alk. paper)
1. Quantum field theory.
I. Title.
QC174.45.Z44 2010
530.14′3—dc22
2009015469
British Library Cataloging-in-Publication Data is available
This book has been composed in Scala LF with ZzTEX
by Princeton Editorial Associates, Inc., Scottsdale, Arizona
Printed on acid-free paper.
press.princeton.edu
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1

To my parents,
who valued education above all else

This page intentionally left blank

Contents
Preface to the First Edition
xv
Preface to the Second Edition
xix
Convention, Notation, and Units
xxv
I Part I: Motivation and Foundation
I.1
Who Needs It?
3
I.2
Path Integral Formulation of Quantum Physics
7
I.3
From Mattress to Field
17
I.4
From Field to Particle to Force
26
I.5
Coulomb and Newton: Repulsion and Attraction
32
I.6
Inverse Square Law and the Floating 3-Brane
40
I.7
Feynman Diagrams
43
I.8
Quantizing Canonically
61
I.9
Disturbing the Vacuum
70
I.10
Symmetry
76
I.11
Field Theory in Curved Spacetime
81
I.12
Field Theory Redux
88
II Part II: Dirac and the Spinor
II.1
The Dirac Equation
93
II.2
Quantizing the Dirac Field
107
II.3
Lorentz Group and Weyl Spinors
114
II.4
Spin-Statistics Connection
120

xii | Contents
II.5
Vacuum Energy, Grassmann Integrals, and Feynman Diagrams
for Fermions
123
II.6
Electron Scattering and Gauge Invariance
132
II.7
Diagrammatic Proof of Gauge Invariance
144
II.8
Photon-Electron Scattering and Crossing
152
III Part III: Renormalization and Gauge Invariance
III.1
Cutting Off Our Ignorance
161
III.2
Renormalizable versus Nonrenormalizable
169
III.3
Counterterms and Physical Perturbation Theory
173
III.4
Gauge Invariance: A Photon Can Find No Rest
182
III.5
Field Theory without Relativity
190
III.6
The Magnetic Moment of the Electron
194
III.7
Polarizing the Vacuum and Renormalizing the Charge
200
III.8
Becoming Imaginary and Conserving Probability
207
IV Part IV: Symmetry and Symmetry Breaking
IV.1
Symmetry Breaking
223
IV.2
The Pion as a Nambu-Goldstone Boson
231
IV.3
Effective Potential
237
IV.4
Magnetic Monopole
245
IV.5
Nonabelian Gauge Theory
253
IV.6
The Anderson-Higgs Mechanism
263
IV.7
Chiral Anomaly
270
V Part V: Field Theory and Collective Phenomena
V.1
Superfluids
283
V.2
Euclid, Boltzmann, Hawking, and Field Theory at Finite Temperature
287
V.3
Landau-Ginzburg Theory of Critical Phenomena
292
V.4
Superconductivity
295
V.5
Peierls Instability
298
V.6
Solitons
302
V.7
Vortices, Monopoles, and Instantons
306
VI Part VI: Field Theory and Condensed Matter
VI.1
Fractional Statistics, Chern-Simons Term, and Topological
Field Theory
315
VI.2
Quantum Hall Fluids
322

Contents | xiii
VI.3
Duality
331
VI.4
The σ Models as Effective Field Theories
340
VI.5
Ferromagnets and Antiferromagnets
344
VI.6
Surface Growth and Field Theory
347
VI.7
Disorder: Replicas and Grassmannian Symmetry
350
VI.8
Renormalization Group Flow as a Natural Concept in High Energy
and Condensed Matter Physics
356
VII Part VII: Grand Unification
VII.1
Quantizing Yang-Mills Theory and Lattice Gauge Theory
371
VII.2
Electroweak Unification
379
VII.3
Quantum Chromodynamics
385
VII.4
Large N Expansion
394
VII.5
Grand Unification
407
VII.6
Protons Are Not Forever
413
VII.7
SO(10) Unification
421
VIII Part VIII: Gravity and Beyond
VIII.1 Gravity as a Field Theory and the Kaluza-Klein Picture
433
VIII.2 The Cosmological Constant Problem and the Cosmic Coincidence
Problems
448
VIII.3 Effective Field Theory Approach to Understanding Nature
452
VIII.4 Supersymmetry: A Very Brief Introduction
461
VIII.5 A Glimpse of String Theory as a 2-Dimensional Field Theory
469
Closing Words
473
N Part N
N.1
Gravitational Waves and Effective Field Theory
479
N.2
Gluon Scattering in Pure Yang-Mills Theory
483
N.3
Subterranean Connections in Gauge Theories
497
N.4
Is Einstein Gravity Secretly the Square of Yang-Mills Theory?
513
More Closing Words
521
Appendix A: Gaussian Integration and the Central Identity of Quantum
Field Theory
523
Appendix B: A Brief Review of Group Theory
525

xiv | Contents
Appendix C: Feynman Rules
534
Appendix D: Various Identities and Feynman Integrals
538
Appendix E: Dotted and Undotted Indices and the Majorana Spinor
541
Solutions to Selected Exercises
545
Further Reading
559
Index
563

Preface to the First Edition
As a student, I was rearing at the bit, after a course on quantum mechanics, to learn
quantum field theory, but the books on the subject all seemed so formidable. Fortunately,
I came across a little book by Mandl on field theory, which gave me a taste of the subject
enabling me to go on and tackle the more substantive texts. I have since learned that other
physicists of my generation had similar good experiences with Mandl.
In the last three decades or so, quantum field theory has veritably exploded and Mandl
would be hopelessly out of date to recommend to a student now. Thus I thought of writing
a book on the essentials of modern quantum field theory addressed to the bright and eager
student who has just completed a course on quantum mechanics and who is impatient to
start tackling quantum field theory.
I envisaged a relatively thin book, thin at least in comparison with the many weighty
tomes on the subject. I envisaged the style to be breezy and colloquial, and the choice
of topics to be idiosyncratic, certainly not encyclopedic. I envisaged having many short
chapters, keeping each chapter “bite-sized.”
The challenge in writing this book is to keep it thin and accessible while at the same
time introducing as many modern topics as possible. A tough balancing act! In the end,
I had to be unrepentantly idiosyncratic in what I chose to cover. Note to the prospective
book reviewer: You can always criticize the book for leaving out your favorite topics. I do
not apologize in any way, shape, or form. My motto in this regard (and in life as well),
taken from the Ricky Nelson song “Garden Party,” is “You can’t please everyone so you
gotta please yourself.”
This book differs from other quantum field theory books that have come out in recent
years in several respects.
I want to get across the important point that the usefulness of quantum field theory is far
from limited to high energy physics, a misleading impression my generation of theoretical
physicists were inculcated with and which amazingly enough some recent textbooks on

xvi | Preface to the First Edition
quantum field theory (all written by high energy physicists) continue to foster. For instance,
the study of driven surface growth provides a particularly clear, transparent, and physical
example of the importance of the renormalization group in quantum field theory. Instead
of being entangled in all sorts of conceptual irrelevancies such as divergences, we have
the obviously physical notion of changing the ruler used to measure the fluctuating
surface. Other examples include random matrix theory and Chern-Simons gauge theory
in quantum Hall fluids. I hope that condensed matter theory students will find this book
helpful in getting a first taste of quantum field theory. The book is divided into eight parts,1
with two devoted more or less exclusively to condensed matter physics.
I try to give the reader at least a brief glimpse into contemporary developments, for
example, just enough of a taste of string theory to whet the appetite. This book is perhaps
also exceptional in incorporating gravity from the beginning. Some topics are treated quite
differently than in traditional texts. I introduce the Faddeev-Popov method to quantize
electromagnetism and the language of differential forms to develop Yang-Mills theory, for
example.
The emphasis is resoundingly on the conceptual rather than the computational. The
only calculation I carry out in all its gory details is that of the magnetic moment of the
electron. Throughout, specific examples rather than heavy abstract formalism will be
favored. Instead of dealing with the most general case, I always opt for the simplest.
I had to struggle constantly between clarity and wordiness. In trying to anticipate and to
minimize what would confuse the reader, I often find that I have to belabor certain points
more than what I would like.
I tried to avoid the dreaded phrase “It can be shown that . . . ” as much as possible.
Otherwise, I could have written a much thinner book than this! There are indeed thinner
books on quantum field theory: I looked at a couple and discovered that they hardly explain
anything. I must confess that I have an almost insatiable desire to explain.
As the manuscript grew, the list of topics that I reluctantly had to drop also kept growing.
So many beautiful results, but so little space! It almost makes me ill to think about all the
stuff (bosonization, instanton, conformal field theory, etc., etc.) I had to leave out. As one
colleague remarked, the nutshell is turning into a coconut shell!
Shelley Glashow once described the genesis of physical theories: “Tapestries are made
by many artisans working together. The contributions of separate workers cannot be
discerned in the completed work, and the loose and false threads have been covered over.” I
regret that other than giving a few tidbits here and there I could not go into the fascinating
history of quantum field theory, with all its defeats and triumphs. On those occasions
when I refer to original papers I suffer from that disconcerting quirk of human psychology
of tending to favor my own more than decorum might have allowed. I certainly did not
attempt a true bibliography.
1 Murray Gell-Mann used to talk about the eightfold way to wisdom and salvation in Buddhism (M. Gell-Mann
and Y. Ne’eman, The Eightfold Way). Readers familiar with contemporary Chinese literature would know that the
celestial dragon has eight parts.

Preface to the First Edition | xvii
The genesis of this book goes back to the quantum field theory course I taught as a
beginning assistant professor at Princeton University. I had the enormous good fortune
of having Ed Witten as my teaching assistant and grader. Ed produced lucidly written
solutions to the homework problems I assigned, to the extent that the next year I went
to the chairman to ask “What is wrong with the TA I have this year? He is not half as
good as the guy last year!” Some colleagues asked me to write up my notes for a much
needed text (those were the exciting times when gauge theories, asymptotic freedom,
and scores of topics not to be found in any texts all had to be learned somehow) but a
wiser senior colleague convinced me that it might spell disaster for my research career.
Decades later, the time has come. I particularly thank Murph Goldberger for urging me
to turn what expository talents I have from writing popular books to writing textbooks. It
is also a pleasure to say a word in memory of the late Sam Treiman, teacher, colleague,
and collaborator, who as a member of the editorial board of Princeton University Press
persuaded me to commit to this project. I regret that my slow pace in finishing the book
deprived him of seeing the finished product.
Over the years I have refined my knowledge of quantum field theory in discussions
with numerous colleagues and collaborators. As a student, I attended courses on quan-
tum field theory offered by Arthur Wightman, Julian Schwinger, and Sidney Coleman. I
was fortunate that these three eminent physicists each has his own distinctive style and
approach.
The book has been tested “in the field” in courses I taught. I used it in my field theory
course at the University of California at Santa Barbara, and I am grateful to some of
the students, in particular Ted Erler, Andrew Frey, Sean Roy, and Dean Townsley, for
comments. I benefitted from the comments of various distinguished physicists who read
all or parts of the manuscript, including Steve Barr, Doug Eardley, Matt Fisher, Murph
Goldberger, Victor Gurarie, Steve Hsu, Bei-lok Hu, Clifford Johnson, Mehran Kardar, Ian
Low, Joe Polchinski, Arkady Vainshtein, Frank Wilczek, Ed Witten, and especially Joshua
Feinberg. Joshua also did many of the exercises.
Talking about exercises: You didn’t get this far in physics without realizing the absolute
importance of doing exercises in learning a subject. It is especially important that you do
most of the exercises in this book, because to compensate for its relative slimness I have
to develop in the exercises a number of important points some of which I need for later
chapters. Solutions to some selected problems are given.
I will maintain a web page http://theory.kitp.ucsb.edu/~zee/nuts.html listing all the
errors, typographical and otherwise, and points of confusion that will undoubtedly come
to my attention.
I thank my editors, Trevor Lipscombe, Sarah Green, and the staff of Princeton Editorial
Associates (particularly Cyd Westmoreland and Evelyn Grossberg) for their advice and for
seeing this project through. Finally, I thank Peter Zee for suggesting the cover painting.

This page intentionally left blank

Preface to the Second Edition
What one fool could understand, another can.
—R. P. Feynman1
Appreciating the appreciators
It has been nearly six years since this book was published on March 10, 2003. Since authors
often think of books as their children, I may liken the flood of appreciation from readers,
students, and physicists to the glorious report cards a bright child brings home from
school. Knowing that there are people who appreciate the care and clarity crafted into the
pedagogy is a most gratifying feeling. In working on this new edition, merely looking at
the titles of the customer reviews on Amazon.com would lighten my task and quicken my
pace: “Funny, chatty, physical. QFT education transformed!,” “A readable, and re-readable
instant classic on QFT,” “A must read book if you want to understand essentials in QFT,”
“One of the most artistic and deepest books ever written on quantum field theory,” “Perfect
for learning field theory on your own,” “Both deep and entertaining,” “One of those books
a person interested in theoretical physics simply must own,” and so on.
In a Physics Today review, Zvi Bern, a preeminent younger field theorist, wrote:
Perhaps foremost in his mind was how to make Quantum Field Theory in a Nutshell as much fun
as possible. . . . I have not had this much fun with a physics book since reading The Feynman
Lectures on Physics. . . . [This is a book] that no student of quantum field theory should be
without. Quantum Field Theory in a Nutshell is the ideal book for a graduate student to curl up
with after having completed a course on quantum mechanics. But, mainly, it is for anyone who
wishes to experience the sheer beauty and elegance of quantum field theory.
A classical Chinese scholar famously lamented “He who knows me are so few!” but here
Zvi read my mind.
Einstein proclaimed, “Physics should be made as simple as possible, but not any
simpler.” My response would be “Physics should be made as fun as possible, but not
1 R. P. Feynman, QED: The Strange Theory of Light and Matter, p. xx.

xx | Preface to the Second Edition
any funnier.” I overcame the editor’s reluctance and included jokes and stories. And yes, I
have also written a popular book Fearful Symmetry about the “sheer beauty and elegance”
of modern physics, which at least in that book largely meant quantum field theory. I want
to share that sense of fun and beauty as much as possible. I’ve heard some people say that
“Beauty is truth” but “Beauty is fun” is more like it.
I had written books before, but this was my first textbook. The challenges and rewards
in writing different types of book are certainly different, but to me, a university professor
devoted to the ideals of teaching, the feeling of passing on what I have learned and
understood is simply incomparable. (And the nice part is that I don’t have to hand out
final grades.) It may sound corny, but I owe it, to those who taught me and to those
authors whose field theory texts I studied, to give something back to the theoretical physics
community. It is a wonderful feeling for me to meet young hotshot researchers who had
studied this text and now know more about field theory than I do.
How I made the book better: The first text that covers the twenty-first century
When my editor Ingrid Gnerlich asked me for a second edition I thought long and hard
about how to make this edition better than the first. I have clarified and elaborated here
and there, added explanations and exercises, and done more “practical” Feynman diagram
calculations to appease those readers of the first edition who felt that I didn’t calculate
enough. There are now three more chapters in the main text. I have also made the “most
accessible” text on quantum field theory even more accessible by explaining stuff that
I thought readers who already studied quantum mechanics should know. For example,
I added a concise review of the Dirac delta function to chapter I.2. But to the guy on
Amazon.com who wanted complex analysis explained, sorry, I won’t do it. There is a limit.
Already, I gave a basically self-contained coverage of group theory.
More excitingly, and to make my life more difficult, I added, to the existing eight parts
(of the celestial dragon), a new part consisting of four chapters, covering field theoretic
happenings of the last decade or so. Thus I can say that this is the first text since the birth
of quantum field theory in the late 1920s that covers the twenty-first century.
Quantum field theory is a mature but certainly not a finished subject, as some stu-
dents mistakenly believe. As one of the deepest constructs in theoretical physics and all
encompassing in its reach, it is bound to have yet unplumbed depths, secret subterranean
connections, and delightful surprises. While many theoretical physicists have moved past
quantum field theory to string theory and even string field theory, they often take the limit
in which the string description reduces to a field description, thus on occasion revealing
previously unsuspected properties of quantum field theories. We will see an example in
chapter N.4.
My friends admonished me to maintain, above all else, the “delightful tone” of the first
edition. I hope that I have succeeded, even though the material contained in part N is “hot
off the stove” stuff, unlike the long-understood material covered in the main text. I also
added a few jokes and stories, such as the one about Fermi declining to trace.

Preface to the Second Edition | xxi
As with the first edition, I will maintain a web site http://theory.kitp.ucsb.edu/~zee/
nuts2.html listing the errors, typographical or otherwise, that will undoubtedly come to
my attention.
Encouraging words
In the quote that started this preface, Feynman was referring to himself, and to you! Of
course, Feynman didn’t simply understand the quantum field theory of electromagnetism,
he also invented a large chunk of it. To paraphrase Feynman, I wrote this book for fools
like you and me. If a fool like me could write a book on quantum field theory, then surely
you can understand it.
As I said in the preface to the first edition, I wrote this book for those who, having
learned quantum mechanics, are eager to tackle quantum field theory. During a sabbatical
year (2006–07) I spent at Harvard, I was able to experimentally verify my hypothesis that
a person who has mastered quantum mechanics could understand my book on his or her
own without much difficulty. I was sent a freshman who had taught himself quantum
mechanics in high school. I gave him my book to read and every couple of weeks or so
he came by to ask a question or two. Even without these brief sessions, he would have
understood much of the book. In fact, at least half of his questions stem from the holes
in his knowledge of quantum mechanics. I have incorporated my answers to his field
theoretic questions into this edition.
As I also said in the original preface, I had tested some of the material in the book “in the
field” in courses I taught at Princeton University and later at the University of California at
Santa Barbara. Since 2003, I have been gratified to know that it has been used successfully
in courses at many institutions.
I understand that, of the different groups of readers, those who are trying to learn
quantum field theory on their own could easily get discouraged. Let me offer you some
cheering words. First of all, that is very admirable of you! Of all the established subjects
in theoretical physics, quantum field theory is by far the most subtle and profound. By
consensus it is much much harder to learn than Einstein’s theory of gravity, which in fact
should properly be regarded as part of field theory, as will be made clear in this book. So
don’t expect easy cruising, particularly if you don’t have someone to clarify things for you
once in a while. Try an online physics forum. Do at least some of the exercises. Remember:
“No one expects a guitarist to learn to play by going to concerts in Central Park or by
spending hours reading transcriptions of Jimi Hendrix solos. Guitarists practice. Guitarists
play the guitar until their fingertips are calloused. Similarly, physicists solve problems.”2
Of course, if you don’t have the prerequisites, you won’t be able to understand this or any
other field theory text. But if you have mastered quantum mechanics, keep on trucking
and you will get there.
2 N. Newbury et al., Princeton Problems in Physics with Solutions, Princeton University Press, Princeton, 1991.

xxii | Preface to the Second Edition
The view will be worth it, I promise. My thesis advisor Sidney Coleman used to start his
field theory course saying, “Not only God knows, I know, and by the end of the semester,
you will know.” By the end of this book, you too will know how God weaves the universe
out of a web of interlocking fields. I would like to change Dirac’s statement “God is a
mathematician” to “God is a quantum field theorist.”
Some of you steady truckers might want to ask what to do when you get to the end. Dur-
ing my junior year in college, after my encounter with Mandl, I asked Arthur Wightman
what to read next. He told me to read the textbook by S. S. Schweber, which at close to a
thousand pages was referred to by students as “the monster” and which could be extremely
opaque at places. After I slugged my way to the end, Wightman told me, “Read it again.”
Fortunately for me, volume I of Bjorken and Drell had already come out. But there is wis-
dom in reading a book again; things that you miss the first time may later leap out at you.
So my advice is “Read it again.” Of course, every physics student also knows that different
explanations offered by different books may click with different folks. So read other field
theory books. Quantum field theory is so profound that most people won’t get it in one
pass.
On the subject of other field theory texts: James Bjorken kindly wrote in my much-used
copy of Bjorken and Drell that the book was obsolete. Hey BJ, it isn’t. Certainly, volume I
will never be pass´e. On another occasion, Steve Weinberg told me, referring to his field
theory book, that “I wrote the book that I would have liked to learn from.” I could equally
well say that “I wrote the book that I would have liked to learn from.” Without the least
bit of hubris, I can say that I prefer my book to Schweber’s. The moral here is that if you
don’t like this book you should write your own.
I try not to do clunky
I explained my philosophy in the preface to the first edition, but allow me a few more
words here. I will teach you how to calculate, but I also have what I regard as a higher aim,
to convey to you an enjoyment of quantum field theory in all its splendors (and by “all” I
mean not merely quantum field theory as defined by some myopic physicists as applicable
only to particle physics). I try to erect an elegant and logically tight framework and put a
light touch on a heavy subject.
In spite of the image conjured up by Zvi Bern of some future field theorist curled up
in bed reading this book, I expect you to grab pen and paper and work. You could do
it in bed if you want, but work you must. I intentionally did not fill in all the steps; it
would hardly be a light touch if I do every bit of algebra for you. Nevertheless, I have done
algebra when I think that it would help you. Actually, I love doing algebra, particularly
when things work out so elegantly as in quantum field theory. But I don’t do clunky. I
do not like clunky-looking equations. I avoid spelling everything out and so expect you
to have a certain amount of “sense.” As a small example, near the end of chapter I.10 I
suppressed the spacetime dependence of the fields ϕa and δϕa. If you didn’t realize, after

Preface to the Second Edition | xxiii
some 70 pages, that fields are functions of where you are in spacetime, you are quite lost,
my friend. My plan is to “keep you on your toes” and I purposely want you to feel puzzled
occasionally. I have faith that the sort of person who would be reading this book can always
figure it out after a bit of thought. I realize that there are at least three distinct groups of
readers, but let me say to the students, “How do you expect to do research if you have to
be spoon-fed from line to line in a textbook?”
Nuts who do not appreciate the Nutshell
In the original preface, I quoted Ricky Nelson on the impossibility of pleasing everyone and
so I was not at all surprised to find on Amazon.com a few people whom one of my friends
calls “nuts who do not appreciate the Nutshell.” My friends advise me to leave these people
alone but I am sufficiently peeved to want to say a few words in my defense, no matter how
nutty the charge. First, I suppose that those who say the book is too mathematical cancel
out those who say the book is not mathematical enough. The people in the first group are
not informed, while those in the second group are misinformed.
Quantum field theory does not have to be mathematical. I know of at least three Field
Medalists who enjoyed the book. A review for the American Mathematical Society offered
this deep statement in praise of the book: “It is often deeper to know why something is
true rather than to have a proof that it is true.” (Indeed, a Fields Medalist once told me that
top mathematicians secretly think like physicists and after they work out the broad outline
of a proof they then dress it up with epsilons and deltas. I have no idea if this is true only
for one, for many, or for all Fields Medalists. I suspect that it is true for many.)
Then there is the person who denounces the book for its lack of rigor. Well, I happen to
know, or at least used to know, a thing or two about mathematical rigor, since I wrote my
senior thesis with Wightman on what I would call “fairly rigorous” quantum field theory.
As we like to say in the theoretical physics community, too much rigor soon leads to rigor
mortis. Be warned. Indeed, as Feynman would tell students, if this ain’t rigorous enough
for you the math department is just one building over. So read a more rigorous book. It is
a free country.
More serious is the impression that several posters on Amazon.com have that the book is
too elementary. I humbly beg to differ. The book gives the impression of being elementary
but in fact covers more material than many other texts. If you master everything in the
Nutshell, you would know more than most professors of field theory and could start doing
research. I am not merely making an idle claim but could give an actual proof. All the
ingredients that went into the spinor helicity formalism that led to a deep field theoretic
discovery described in part N could be found in the first edition of this book. Of course,
reading a textbook is not enough; you have to come up with the good ideas.
As for he who says that the book does not look complicated enough and hence can’t be
a serious treatment, I would ask him to compare a modern text on electromagnetism with
Maxwell’s treatises.

xxiv | Preface to the Second Edition
Thanks
In the original preface and closing words, I mentioned that I learned a great deal of quan-
tum field theory from Sidney Coleman. His clarity of thought and lucid exposition have
always inspired me. Unhappily, he passed away in 2007. After this book was published, I
visited Sidney on different occasions, but sadly, he was already in a mental fog.
In preparing this second edition, I am grateful to Nima Arkani-Hamed, Yoni Ben-Tov,
Nathan Berkovits, Marty Einhorn, Joshua Feinberg, Howard Georgi, Tim Hsieh, Brendan
Keller, Joe Polchinski, Yong-shi Wu, and Jean-Bernard Zuber for their helpful comments.
Some of them read parts or all of the added chapters. I thank especially Zvi Bern and
Rafael Porto for going over the chapters in part N with great care and for many useful
suggestions. I also thank Craig Kunimoto, Richard Neher, Matt Pillsbury, and Rafael
Porto for teaching me the black art of composing equations on the computer. My editor
at Princeton University Press, Ingrid Gnerlich, has always been a pleasure to talk to
and work with. I also thank Kathleen Cioffi and Cyd Westmoreland for their meticulous
work in producing this book. Last but not least, I am grateful to my wife Janice for her
encouragement and loving support.

Convention, Notation, and Units
For the same reason that we no longer use a certain king’s feet to measure distance, we use
natural units in which the speed of light c and the Dirac symbol ℏare both set equal to 1.
Planck made the profound observation that in natural units all physical quantities can be
expressed in terms of the Planck mass MPlanck ≡1/

GNewton ≃1019Gev. The quantities
c and ℏare not so much fundamental constants as conversion factors. In this light, I am
genuinely puzzled by condensed matter physicists carrying around Boltzmann’s constant
k, which is no different from the conversion factor between feet and meters.
Spacetime coordinates xμ are labeled by Greek indices (μ = 0, 1, 2, 3 ) with the time
coordinate x0 sometimes denoted by t. Space coordinates xi are labeled by Latin indices
(i = 1, 2, 3) and ∂μ ≡∂/∂xμ . We use a Minkowski metric ημν with signature ( +, −, −, −)
so that η00 = +1. We write ημν∂μϕ∂νϕ = ∂μϕ∂μϕ = (∂ϕ)2 = (∂ϕ/∂t)2 −
i(∂ϕ/∂xi)2. The
metric in curved spacetime is always denoted by gμν, but often I will also use gμν for the
Minkowski metric when the context indicates clearly that we are in flat spacetime.
Since I will be talking mostly about relativistic quantum field theory in this book I will
without further clarification use a relativistic language. Thus, when I speak of momentum,
unless otherwise specified, I mean energy and momentum. Also since ℏ= 1, I will not
distinguish between wave vector k and momentum, and between frequency ω and energy.
In local field theory I deal primarily with the Lagrangian density L and not the La-
grangian L =

d3x L . As is common practice in the literature and in oral discussion, I
will often abuse terminology and simply refer to L as the Lagrangian. I will commit other
minor abuses such as writing 1 instead of I for the unit matrix. I use the same symbol
ϕ for the Fourier transform ϕ(k) of a function ϕ(x) whenever there is no risk of confu-
sion, as is almost always the case. I prefer an abused terminology to cluttered notation and
unbearable pedantry.
The symbol ∗denotes complex conjugation, and † hermitean conjugation: The former
applies to a number and the latter to an operator. I also use the notation c.c. and h.c. Often

xxvi | Convention, Notation, and Units
when there is no risk of confusion I abuse the notation, using † when I should use ∗. For
instance, in a path integral, bosonic fields are just number-valued fields, but nevertheless
I write ϕ† rather than ϕ∗. For a matrix M, then of course M† and M∗should be carefully
distinguished from each other.
I made an effort to get factors of 2 and π right, but some errors will be inevitable.

Q uantum Field Theory in a Nutshell

This page intentionally left blank

Part I
Motivation and Foundation

This page intentionally left blank

I.1
Who Needs It?
Who needs quantum field theory?
Quantum field theory arose out of our need to describe the ephemeral nature of life.
No, seriously, quantum field theory is needed when we confront simultaneously the two
great physics innovations of the last century of the previous millennium: special relativity
and quantum mechanics. Consider a fast moving rocket ship close to light speed. You need
special relativity but not quantum mechanics to study its motion. On the other hand, to
study a slow moving electron scattering on a proton, you must invoke quantum mechanics,
but you don’t have to know a thing about special relativity.
It is in the peculiar confluence of special relativity and quantum mechanics that a new
set of phenomena arises: Particles can be born and particles can die. It is this matter of
birth, life, and death that requires the development of a new subject in physics, that of
quantum field theory.
Let me give a heuristic discussion. In quantum mechanics the uncertainty principle tells
us that the energy can fluctuate wildly over a small interval of time. According to special
relativity, energy can be converted into mass and vice versa. With quantum mechanics and
special relativity, the wildly fluctuating energy can metamorphose into mass, that is, into
new particles not previously present.
Write down the Schr¨odinger equation for an electron scattering off a proton. The
equation describes the wave function of one electron, and no matter how you shake
and bake the mathematics of the partial differential equation, the electron you follow
will remain one electron. But special relativity tells us that energy can be converted to
matter: If the electron is energetic enough, an electron and a positron (“the antielectron”)
can be produced. The Schr¨odinger equation is simply incapable of describing such a
phenomenon. Nonrelativistic quantum mechanics must break down.
You saw the need for quantum field theory at another point in your education. Toward
the end of a good course on nonrelativistic quantum mechanics the interaction between
radiation and atoms is often discussed. You would recall that the electromagnetic field is

4 | I. Motivation and Foundation
Figure I.1.1
treated as a field; well, it is a field. Its Fourier components are quantized as a collection
of harmonic oscillators, leading to creation and annihilation operators for photons. So
there, the electromagnetic field is a quantum field. Meanwhile, the electron is treated as a
poor cousin, with a wave function (x) governed by the good old Schr¨odinger equation.
Photons can be created or annihilated, but not electrons. Quite aside from the experimental
fact that electrons and positrons could be created in pairs, it would be intellectually more
satisfying to treat electrons and photons, as they are both elementary particles, on the same
footing.
So, I was more or less right: Quantum field theory is a response to the ephemeral nature
of life.
All of this is rather vague, and one of the purposes of this book is to make these remarks
more precise. For the moment, to make these thoughts somewhat more concrete, let us
ask where in classical physics we might have encountered something vaguely resembling
the birth and death of particles. Think of a mattress, which we idealize as a 2-dimensional
lattice of point masses connected to each other by springs (fig. I.1.1). For simplicity, let
us focus on the vertical displacement [which we denote by qa(t)] of the point masses and
neglect the small horizontal movement. The index a simply tells us which mass we are
talking about. The Lagrangian is then
L = 1
2(

a
m˙q2
a −

a,b
kabqaqb −

a,b,c
gabcqaqbqc −. . .)
(1)
Keeping only the terms quadratic in q (the “harmonic approximation”) we have the equa-
tions of motion m¨qa = −
b kabqb. Taking the q’s as oscillating with frequency ω, we
have 
b kabqb = mω2qa. The eigenfrequencies and eigenmodes are determined, respec-
tively, by the eigenvalues and eigenvectors of the matrix k. As usual, we can form wave
packets by superposing eigenmodes. When we quantize the theory, these wave packets be-
have like particles, in the same way that electromagnetic wave packets when quantized
behave like particles called photons.

I.1. Who Needs It? | 5
Since the theory is linear, two wave packets pass right through each other. But once we
include the nonlinear terms, namely the terms cubic, quartic, and so forth in the q’s in
(1), the theory becomes anharmonic. Eigenmodes now couple to each other. A wave packet
might decay into two wave packets. When two wave packets come near each other, they
scatter and perhaps produce more wave packets. This naturally suggests that the physics
of particles can be described in these terms.
Quantum field theory grew out of essentially these sorts of physical ideas.
It struck me as limiting that even after some 75 years, the whole subject of quantum
field theory remains rooted in this harmonic paradigm, to use a dreadfully pretentious
word. We have not been able to get away from the basic notions of oscillations and wave
packets. Indeed, string theory, the heir to quantum field theory, is still firmly founded on
this harmonic paradigm. Surely, a brilliant young physicist, perhaps a reader of this book,
will take us beyond.
Condensed matter physics
In this book I will focus mainly on relativistic field theory, but let me mention here that
one of the great advances in theoretical physics in the last 30 years or so is the increasingly
sophisticated use of quantum field theory in condensed matter physics. At first sight this
seems rather surprising. After all, a piece of “condensed matter” consists of an enormous
swarm of electrons moving nonrelativistically, knocking about among various atomic ions
and interacting via the electromagnetic force. Why can’t we simply write down a gigantic
wave function (x1, x2, . . . , xN), where xj denotes the position of the jth electron and N
is a large but finite number? Okay,  is a function of many variables but it is still governed
by a nonrelativistic Schr¨odinger equation.
The answer is yes, we can, and indeed that was how solid state physics was first studied
in its heroic early days (and still is in many of its subbranches).
Why then does a condensed matter theorist need quantum field theory? Again, let us
first go for a heuristic discussion, giving an overall impression rather than all the details. In
a typical solid, the ions vibrate around their equilibrium lattice positions. This vibrational
dynamics is best described by so-called phonons, which correspond more or less to the
wave packets in the mattress model described above.
This much you can read about in any standard text on solid state physics. Furthermore,
if you have had a course on solid state physics, you would recall that the energy levels
available to electrons form bands. When an electron is kicked (by a phonon field say) from
a filled band to an empty band, a hole is left behind in the previously filled band. This
hole can move about with its own identity as a particle, enjoying a perfectly comfortable
existence until another electron comes into the band and annihilates it. Indeed, it was
with a picture of this kind that Dirac first conceived of a hole in the “electron sea” as the
antiparticle of the electron, the positron.
We will flesh out this heuristic discussion in subsequent chapters in parts V and VI.

6 | I. Motivation and Foundation
Marriages
To summarize, quantum field theory was born of the necessity of dealing with the marriage
of special relativity and quantum mechanics, just as the new science of string theory is
being born of the necessity of dealing with the marriage of general relativity and quantum
mechanics.

I.2
Path Integral Formulation of Quantum Physics
The professor’s nightmare: a wise guy in the class
As I noted in the preface, I know perfectly well that you are eager to dive into quantum field
theory, but first we have to review the path integral formalism of quantum mechanics. This
formalism is not universally taught in introductory courses on quantum mechanics, but
even if you have been exposed to it, this chapter will serve as a useful review. The reason I
start with the path integral formalism is that it offers a particularly convenient way of going
from quantum mechanics to quantum field theory. I will first give a heuristic discussion,
to be followed by a more formal mathematical treatment.
Perhaps the best way to introduce the path integral formalism is by telling a story,
certainly apocryphal as many physics stories are. Long ago, in a quantum mechanics class,
the professor droned on and on about the double-slit experiment, giving the standard
treatment. A particle emitted from a source S (fig. I.2.1) at time t = 0 passes through one
or the other of two holes, A1 and A2, drilled in a screen and is detected at time t = T by
a detector located at O. The amplitude for detection is given by a fundamental postulate
of quantum mechanics, the superposition principle, as the sum of the amplitude for the
particle to propagate from the source S through the hole A1 and then onward to the point
O and the amplitude for the particle to propagate from the source S through the hole A2
and then onward to the point O.
Suddenly, a very bright student, let us call him Feynman, asked, “Professor, what if
we drill a third hole in the screen?” The professor replied, “Clearly, the amplitude for
the particle to be detected at the point O is now given by the sum of three amplitudes,
the amplitude for the particle to propagate from the source S through the hole A1 and
then onward to the point O, the amplitude for the particle to propagate from the source S
through the hole A2 and then onward to the point O, and the amplitude for the particle to
propagate from the source S through the hole A3 and then onward to the point O.”
The professor was just about ready to continue when Feynman interjected again, “What
if I drill a fourth and a fifth hole in the screen?” Now the professor is visibly losing his

8 | I. Motivation and Foundation
S
O
A1
A2
Figure I.2.1
patience: “All right, wise guy, I think it is obvious to the whole class that we just sum over
all the holes.”
To make what the professor said precise, denote the amplitude for the particle to
propagate from the source S through the hole Ai and then onward to the point O as
A(S →Ai →O). Then the amplitude for the particle to be detected at the point O is
A(detected at O)=

i
A(S →Ai →O)
(1)
But Feynman persisted, “What if we now add another screen (fig. I.2.2) with some holes
drilled in it?” The professor was really losing his patience: “Look, can’t you see that you
just take the amplitude to go from the source S to the hole Ai in the first screen, then to
the hole Bj in the second screen, then to the detector at O, and then sum over all i and j?”
Feynman continued to pester, “What if I put in a third screen, a fourth screen, eh? What
if I put in a screen and drill an infinite number of holes in it so that the screen is no longer
there?” The professor sighed, “Let’s move on; there is a lot of material to cover in this
course.”
S
O
A1
A2
A3
B1
B2
B3
B4
Figure I.2.2

I.2. Path Integral Formulation | 9
S
O
Figure I.2.3
But dear reader, surely you see what that wise guy Feynman was driving at. I especially
enjoy his observation that if you put in a screen and drill an infinite number of holes in it,
then that screen is not really there. Very Zen! What Feynman showed is that even if there
were just empty space between the source and the detector, the amplitude for the particle
to propagate from the source to the detector is the sum of the amplitudes for the particle to
go through each one of the holes in each one of the (nonexistent) screens. In other words,
we have to sum over the amplitude for the particle to propagate from the source to the
detector following all possible paths between the source and the detector (fig. I.2.3).
A(particle to go from S to O in time T ) =

(paths)
A

particle to go from S to O in time T following a particular path

(2)
Now the mathematically rigorous will surely get anxious over how 
(paths) is to be
defined. Feynman followed Newton and Leibniz: Take a path (fig. I.2.4), approximate it
by straight line segments, and let the segments go to zero. You can see that this is just like
filling up a space with screens spaced infinitesimally close to each other, with an infinite
number of holes drilled in each screen.
Fine, but how to construct the amplitude A(particle to go from S to O in time T following
a particular path)? Well, we can use the unitarity of quantum mechanics: If we know the
amplitude for each infinitesimal segment, then we just multiply them together to get the
amplitude of the whole path.
S
O
Figure I.2.4

10 | I. Motivation and Foundation
In quantum mechanics, the amplitude to propagate from a point qI to a point qF in
time T is governed by the unitary operator e−iHT, where H is the Hamiltonian. More
precisely, denoting by |q⟩the state in which the particle is at q, the amplitude in question
is just ⟨qF|e−iHT |qI⟩. Here we are using the Dirac bra and ket notation. Of course,
philosophically, you can argue that to say the amplitude is ⟨qF|e−iHT |qI⟩amounts to a
postulate and a definition of H. It is then up to experimentalists to discover that H is
hermitean, has the form of the classical Hamiltonian, et cetera.
Indeed, the whole path integral formalism could be written down mathematically start-
ing with the quantity ⟨qF|e−iHT |qI⟩, without any of Feynman’s jive about screens with an
infinite number of holes. Many physicists would prefer a mathematical treatment without
the talk. As a matter of fact, the path integral formalism was invented by Dirac precisely
in this way, long before Feynman.1
A necessary word about notation even though it interrupts the narrative flow: We denote
the coordinates transverse to the axis connecting the source to the detector by q, rather
than x, for a reason which will emerge in a later chapter. For notational simplicity, we will
think of q as 1-dimensional and suppress the coordinate along the axis connecting the
source to the detector.
Dirac’s formulation
Let us divide the time T into N segments each lasting δt = T /N. Then we write
⟨qF|e−iHT |qI⟩= ⟨qF|e−iHδte−iHδt . . . e−iHδt |qI⟩
Our states are normalized by ⟨q′|q⟩= δ(q′ −q) with δ the Dirac delta function. (Recall
that δ is defined by δ(q) =
 ∞
−∞(dp/2π)eipq and

dqδ(q) = 1. See appendix 1.) Now use
the fact that |q⟩forms a complete set of states so that

dq |q⟩⟨q| = 1. To see that the
normalization is correct, multiply on the left by ⟨q′′| and on the right by |q′⟩, thus obtaining

dqδ(q′′ −q)δ(q −q′) = δ(q′′ −q′). Insert 1 between all these factors of e−iHδt and write
⟨qF|e−iHT |qI⟩
= (
N−1

j=1

dqj)⟨qF|e−iHδt |qN−1⟩⟨qN−1|e−iHδt |qN−2⟩. . . ⟨q2|e−iHδt |q1⟩⟨q1|e−iHδt |qI⟩
(3)
Focus on an individual factor ⟨qj+1|e−iHδt |qj⟩. Let us take the baby step of first eval-
uating it just for the free-particle case in which H = ˆp2/2m. The hat on ˆp reminds us
that it is an operator. Denote by |p⟩the eigenstate of ˆp, namely ˆp |p⟩= p |p⟩. Do you re-
member from your course in quantum mechanics that ⟨q|p⟩= eipq? Sure you do. This
1 For the true history of the path integral, see p. xv of my introduction to R. P. Feynman, QED: The Strange
Theory of Light and Matter.

I.2. Path Integral Formulation | 11
just says that the momentum eigenstate is a plane wave in the coordinate representa-
tion. (The normalization is such that

(dp/2π)|p⟩⟨p| = 1. Again, to see that the nor-
malization is correct, multiply on the left by ⟨q′| and on the right by |q⟩, thus obtaining

(dp/2π)eip(q′−q) = δ(q′ −q).) So again inserting a complete set of states, we write
⟨qj+1|e−iδt( ˆp2/2m) |qj⟩=

dp
2π ⟨qj+1|e−iδt( ˆp2/2m) |p⟩⟨p|qj⟩
=

dp
2π e−iδt(p2/2m)⟨qj+1|p⟩⟨p|qj⟩
=

dp
2π e−iδt(p2/2m)eip(qj+1−qj)
Note that we removed the hat from the momentum operator in the exponential: Since the
momentum operator is acting on an eigenstate, it can be replaced by its eigenvalue. Also,
we are evidently working in the Heisenberg picture.
The integral over p is known as a Gaussian integral, with which you may already be
familiar. If not, turn to appendix 2 to this chapter.
Doing the integral over p, we get (using (21))
⟨qj+1|e−iδt( ˆp2/2m) |qj⟩=
	 −im
2πδt

 1
2
e[im(qj+1−qj)2]/2δt
=
	 −im
2πδt

 1
2
eiδt(m/2)[(qj+1−qj)/δt]2
Putting this into (3) yields
⟨qF|e−iHT |qI⟩=
	 −im
2πδt

 N
2
N−1

k=1

dqk

eiδt(m/2)N−1
j=0 [(qj+1−qj)/δt]2
with q0 ≡qI and qN ≡qF .
We can now go to the continuum limit δt →0. Newton and Leibniz taught us to replace
[(qj+1 −qj)/δt]2 by ˙q2, and δt N−1
j=0 by
 T
0 dt. Finally, we define the integral over paths
as

Dq(t) = lim
N→∞
	 −im
2πδt

 N
2
N−1

k=1

dqk

We thus obtain the path integral representation
⟨qF|e−iHT |qI⟩=

Dq(t) ei  T
0 dt 1
2 m˙q2
(4)
This fundamental result tells us that to obtain ⟨qF|e−iHT |qI⟩we simply integrate over
all possible paths q(t) such that q(0) = qI and q(T ) = qF.
As an exercise you should convince yourself that had we started with the Hamiltonian
for a particle in a potential H = ˆp2/2m + V (ˆq) (again the hat on ˆq indicates an operator)
the final result would have been
⟨qF|e−iHT |qI⟩=

Dq(t) ei  T
0 dt[ 1
2 m˙q2−V (q)]
(5)

12 | I. Motivation and Foundation
We recognize the quantity 1
2m˙q2 −V (q) as just the Lagrangian L(˙q, q). The Lagrangian
has emerged naturally from the Hamiltonian! In general, we have
⟨qF|e−iHT |qI⟩=

Dq(t) ei  T
0 dtL(˙q,q)
(6)
To avoid potential confusion, let me be clear that t appears as an integration variable in
the exponential on the right-hand side. The appearance of t in the path integral measure
Dq(t) is simply to remind us that q is a function of t (as if we need reminding). Indeed,
this measure will often be abbreviated to Dq. You might recall that
 T
0 dtL(˙q, q) is called
the action S(q) in classical mechanics. The action S is a functional of the function q(t).
Often, instead of specifying that the particle starts at an initial position qI and ends at
a final position qF , we prefer to specify that the particle starts in some initial state I and
ends in some final state F . Then we are interested in calculating ⟨F|e−iHT |I⟩, which upon
inserting complete sets of states can be written as

dqF

dqI⟨F|qF⟩⟨qF|e−iHT |qI⟩⟨qI|I⟩,
which mixing Schr¨odinger and Dirac notation we can write as

dqF

dqIF(qF)∗⟨qF|e−iHT |qI⟩I(qI).
In most cases we are interested in taking |I⟩and |F⟩as the ground state, which we will
denote by |0⟩. It is conventional to give the amplitude ⟨0|e−iHT |0⟩the name Z.
At the level of mathematical rigor we are working with, we count on the path integral

Dq(t) ei  T
0 dt[ 1
2m˙q2−V (q)] to converge because the oscillatory phase factors from different
paths tend to cancel out. It is somewhat more rigorous to perform a so-called Wick rotation
to Euclidean time. This amounts to substituting t →−it and rotating the integration
contour in the complex t plane so that the integral becomes
Z =

Dq(t) e− T
0 dt[ 1
2 m˙q2+V (q)],
(7)
known as the Euclidean path integral. As is done in appendix 2 to this chapter with ordinary
integrals we will always assume that we can make this type of substitution with impunity.
The classical world emerges
One particularly nice feature of the path integral formalism is that the classical limit of
quantum mechanics can be recovered easily. We simply restore Planck’s constant ℏin (6):
⟨qF|e−(i/ℏ)HT |qI⟩=

Dq(t) e(i/ℏ)  T
0 dtL(˙q,q)
and take the ℏ→0 limit. Applying the stationary phase or steepest descent method (if you
don’t know it see appendix 3 to this chapter) we obtain e(i/ℏ)  T
0 dtL(˙qc,qc), where qc(t) is
the “classical path” determined by solving the Euler-Lagrange equation (d/dt)(δL/δ ˙q) −
(δL/δq) = 0 with appropriate boundary conditions.

I.2. Path Integral Formulation | 13
Appendix 1
For your convenience, I include a concise review of the Dirac delta function here. Let us define a function dK(x) by
dK(x) ≡

K
2
−K
2
dk
2π eikx = 1
πx sin Kx
2
(8)
for arbitrary real values of x. We see that for large K the even function dK(x) is sharply peaked at the origin x = 0,
reaching a value of K/2π at the origin, crossing zero at x = 2π/K, and then oscillating with ever decreasing
amplitude. Furthermore,
 ∞
−∞
dx dK(x) = 2
π
 ∞
0
dx
x sin Kx
2
= 2
π
 ∞
0
dy
y sin y = 1
(9)
The Dirac delta function is defined by δ(x) = limK→∞dK(x). Heuristically, it could be thought of as an
infinitely sharp spike located at x = 0 such that the area under the spike is equal to 1. Thus for a function s(x)
well-behaved around x = a we have
 ∞
−∞
dx δ(x −a)s(x) = s(a)
(10)
(By the way, for what it is worth, mathematicians call the delta function a “distribution,” not a function.)
Our derivation also yields an integral representation for the delta function that we will use repeatedly in this
text:
δ(x) =
 ∞
−∞
dk
2π eikx
(11)
We will often use the identity
 ∞
−∞
dx δ(f (x))s(x) =

i
s(xi)
|f ′(xi)|
(12)
where xi denotes the zeroes of f (x) (in other words, f (xi) = 0 and f ′(xi) = df (xi)/dx.) To prove this, first show
that
 ∞
−∞dx δ(bx)s(x) =
 ∞
−∞dx δ(x)
|b| s(x) = s(0)/|b|. The factor of 1/b follows from dimensional analysis. (To
see the need for the absolute value, simply note that δ(bx) is a positive function. Alternatively, change integration
variable to y = bx: for b negative we have to flip the integration limits.) To obtain (12), expand around each of
the zeroes of f (x).
Another useful identity (understood in the limit in which the positive infinitesimal ε tends to zero) is
1
x + iε = P 1
x −iπδ(x)
(13)
To see this, simply write 1/(x + iε) = x/(x2 + ε2) −iε/(x2 + ε2), and then note that ε/(x2 + ε2) as a function
of x is sharply spiked around x = 0 and that its integral from −∞to ∞is equal to π. Thus we have another
representation of the Dirac delta function:
δ(x) = 1
π
ε
x2 + ε2
(14)
Meanwhile, the principal value integral is defined by

dxP 1
x f (x) = lim
ε→0

dx
x
x2 + ε2f (x)
(15)

14 | I. Motivation and Foundation
Appendix 2
I will now show you how to do the integral G ≡
 +∞
−∞dxe−1
2 x2. The trick is to square the integral, call the dummy
integration variable in one of the integrals y, and then pass to polar coordinates:
G2 =
 +∞
−∞
dx e−1
2 x2  +∞
−∞
dy e−1
2 y2
= 2π
 +∞
0
dr re−1
2 r2
= 2π
 +∞
0
dw e−w = 2π
Thus, we obtain
 +∞
−∞
dx e−1
2 x2 =
√
2π
(16)
Believe it or not, a significant fraction of the theoretical physics literature consists of varying and elaborating
this basic Gaussian integral. The simplest extension is almost immediate:
 +∞
−∞
dx e−1
2 ax2 =
	2π
a

 1
2
(17)
as can be seen by scaling x →x/√a.
Acting on this repeatedly with −2(d/da) we obtain
⟨x2n⟩≡
 +∞
−∞dx e−1
2 ax2x2n
 +∞
−∞dx e−1
2 ax2
= 1
an (2n −1)(2n −3) . . . 5 . 3 . 1
(18)
The factor 1/an follows from dimensional analysis. To remember the factor (2n −1)!! ≡(2n −1)(2n −3) . . . 5 .
3 . 1 imagine 2n points and connect them in pairs. The first point can be connected to one of (2n −1) points, the
second point can now be connected to one of the remaining (2n −3) points, and so on. This clever observation,
due to Gian Carlo Wick, is known as Wick’s theorem in the field theory literature. Incidentally, field theorists use
the following graphical mnemonic in calculating, for example, ⟨x6⟩: Write ⟨x6⟩as ⟨xxxxxx⟩and connect the x’s,
for example
〈
〉
xxxxxx
The pattern of connection is known as a Wick contraction. In this simple example, since the six x’s are identical,
any one of the distinct Wick contractions gives the same value a−3 and the final result for ⟨x6⟩is just a−3 times
the number of distinct Wick contractions, namely 5 . 3 . 1 = 15. We will soon come to a less trivial example, with
distinct x’s, in which case distinct Wick contraction gives distinct values.
An important variant is the integral
 +∞
−∞
dx e−1
2 ax2+Jx =
	2π
a

 1
2
eJ 2/2a
(19)
To see this, take the expression in the exponent and “complete the square”: −ax2/2 + Jx = −(a/2)(x2 −
2Jx/a) = −(a/2)(x −J/a)2 + J 2/2a. The x integral can now be done by shifting x →x + J/a, giving the
factor of (2π/a)
1
2 . Check that we can also obtain (18) by differentiating with respect to J repeatedly and then
setting J = 0.
Another important variant is obtained by replacing J by iJ:
 +∞
−∞
dx e−1
2 ax2+iJx =
	2π
a

 1
2
e−J 2/2a
(20)

I.2. Path Integral Formulation | 15
To get yet another variant, replace a by −ia:
 +∞
−∞
dx e
1
2 iax2+iJx =
	2πi
a

 1
2
e−iJ 2/2a
(21)
Let us promote a to a real symmetric N by N matrix Aij and x to a vector xi (i, j = 1, . . . , N). Then (19)
generalizes to
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dx1dx2 . . . dxN e−1
2 x.A.x+J.x =
	(2π)N
det[A]

 1
2
e
1
2 J.A−1.J
(22)
where x . A . x = xiAijxj and J . x = Jixi (with repeated indices summed.)
To derive this important relation, diagonalize A by an orthogonal transformation O so that A = O−1 . D . O,
where D is a diagonal matrix. Call yi = Oijxj. In other words, we rotate the coordinates in the N-dimensional
Euclidean space we are integrating over. The expression in the exponential in the integrand then becomes
−1
2y . D . y + (OJ) . y. Using
 +∞
−∞. . .  +∞
−∞dx1 . . . dxN =
 +∞
−∞. . .  +∞
−∞dy1 . . . dyN, we factorize the left-hand
side of (22) into a product of N integrals, each of the form
 +∞
−∞dyie−1
2 Diiy2
i +(OJ)iyi. Plugging into (19) we
obtain the right hand side of (22), since (OJ) . D−1 . (OJ) = J . O−1D−1O . J = J . A−1 . J (where we use the
orthogonality of O). (To make sure you got it, try this explicitly for N = 2.)
Putting in some i’s (A →−iA, J →iJ), we find the generalization of (22)
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dx1dx2 . . . dxN e(i/2)x.A.x+iJ.x
=
	(2πi)N
det[A]

 1
2
e−(i/2)J.A−1.J
(23)
The generalization of (18) is also easy to obtain. Differentiate (22) p times with respect to Ji, Jj , . . . Jk, and
Jl, and then set J = 0. For example, for p = 1 the integrand in (22) becomes e−1
2 x.A.xxi and since the integrand
is now odd in xi the integral vanishes. For p = 2 the integrand becomes e−1
2 x.A.x(xixj), while on the right hand
side we bring down A−1
ij . Rearranging and eliminating det[A] (by setting J = 0 in (22)), we obtain
⟨xixj⟩=
 +∞
−∞
 +∞
−∞. . .  +∞
−∞dx1dx2 . . . dxN e−1
2 x.A.xxixj
 +∞
−∞
 +∞
−∞. . .  +∞
−∞dx1dx2 . . . dxN e−1
2 x.A.x
= A−1
ij
Just do it. Doing it is easier than explaining how to do it. Then do it for p = 3 and 4. You will see immediately how
your result generalizes. When the set of indices i, j , . . . , k, l contains an odd number of elements, ⟨xixj . . . xkxl⟩
vanishes trivially. When the set of indices i, j , . . . , k, l contains an even number of elements, we have
⟨xixj . . . xkxl⟩=

Wick
(A−1)ab . . . (A−1)cd
(24)
where we have defined
⟨xixj . . . xkxl⟩
=
 +∞
−∞
 +∞
−∞. . .  +∞
−∞dx1dx2 . . . dxN e−1
2 x.A.xxixj . . . xkxl
 +∞
−∞
 +∞
−∞. . .  +∞
−∞dx1dx2 . . . dxN e−1
2 x.A.x
(25)
and where the set of indices {a, b, . . . , c, d} represent a permutation of {i, j , . . . , k, l}. The sum in (24) is over
all such permutations or Wick contractions.
For example,
⟨xixjxkxl⟩= (A−1)ij(A−1)kl + (A−1)il(A−1)jk + (A−1)ik(A−1)jl
(26)
(Recall that A, and thus A−1, is symmetric.) As in the simple case when x does not carry any index, we could
connect the x’s in ⟨xixjxkxl⟩in pairs (Wick contraction) and write a factor (A−1)ab if we connect xa to xb.
Notice that since ⟨xixj⟩= (A−1)ij the right hand side of (24) can also be written in terms of objects like ⟨xixj⟩.
Thus, ⟨xixjxkxl⟩= ⟨xixj⟩⟨xkxl⟩+ ⟨xixl⟩⟨xjxk⟩+ ⟨xixk⟩⟨xjxl⟩.

16 | I. Motivation and Foundation
Please work out ⟨xixjxkxlxmxn⟩; you will become an expert on Wick contractions. Of course, (24) reduces to
(18) for N = 1.
Perhaps you are like me and do not like to memorize anything, but some of these formulas might be worth
memorizing as they appear again and again in theoretical physics (and in this book).
Appendix 3
To do an exponential integral of the form I =
 +∞
−∞dqe−(1/ℏ)f (q) we often have to resort to the steepest-descent
approximation, which I will now review for your convenience. In the limit of ℏsmall, the integral is dominated
by the minimum of f (q). Expanding f (q) = f (a) + 1
2f ′′(a)(q −a)2 + O[(q −a)3] and applying (17) we obtain
I = e−(1/ℏ)f (a)
	 2πℏ
f ′′(a)

 1
2
e−O(ℏ
1
2 )
(27)
For f (q) a function of many variables q1, . . . , qN and with a minimum at qj = aj , we generalize immediately
to
I = e−(1/ℏ)f (a)
	 (2πℏ)N
det f ′′(a)

 1
2
e−O(ℏ
1
2 )
(28)
Here f ′′(a) denotes the N by N matrix with entries [f ′′(a)]ij ≡(∂2f/∂qi∂qj)|q=a. In many situations, we do
not even need the factor involving the determinant in (28). If you can derive (28) you are well on your way to
becoming a quantum field theorist!
Exercises
I.2.1
Verify (5).
I.2.2
Derive (24).

I.3
From Mattress to Field
The mattress in the continuum limit
The path integral representation
Z ≡⟨0|e−iHT |0⟩=

Dq(t) ei  T
0 dt[ 1
2 m˙q2−V (q)]
(1)
(we suppress the factor ⟨0|qf ⟩⟨qI |0⟩; we will come back to this issue later in this chapter)
which we derived for the quantum mechanics of a single particle, can be generalized almost
immediately to the case of N particles with the Hamiltonian
H =

a
1
2ma
ˆp2
a + V (ˆq1, ˆq2, . . . , ˆqN).
(2)
We simply keep track mentally of the position of the particles qa with a = 1, 2, . . . , N.
Going through the same steps as before, we obtain
Z ≡⟨0|e−iHT |0⟩=

Dq(t) eiS(q)
(3)
with the action
S(q) =
 T
0
dt
 
a
1
2ma ˙q2
a −V [q1, q2, . . . , qN]

.
The potential energy V (q1, q2, . . . , qN) now includes interaction energy between particles,
namely terms of the form v(qa −qb), as well as the energy due to an external potential,
namely terms of the form w(qa). In particular, let us now write the path integral description
of the quantum dynamics of the mattress described in chapter I.1, with the potential
V (q1, q2, . . . , qN) =

ab
1
2kab(qa −qb)2 + . . .
We are now just a short hop and skip away from a quantum field theory! Suppose we
are only interested in phenomena on length scales much greater than the lattice spacing
l (see fig. I.1.1). Mathematically, we take the continuum limit l →0. In this limit, we can

18 | I. Motivation and Foundation
replace the label a on the particles by a two-dimensional position vector ⃗x, and so we write
q(t, ⃗x) instead of qa(t). It is traditional to replace the Latin letter q by the Greek letter ϕ.
The function ϕ(t, ⃗x) is called a field.
The kinetic energy 
a
1
2ma ˙q2
a now becomes

d2x 1
2σ(∂ϕ/∂t)2. We replace 
a by

d2x/l2 and denote the mass per unit area ma/l2 by σ. We take all the ma’s to be equal;
otherwise σ would be a function of ⃗x, the system would be inhomogeneous, and we would
have a hard time writing down a Lorentz-invariant action (see later).
We next focus on the first term in V . Assume for simplicity that kab connect only nearest
neighbors on the lattice. For nearest-neighbor pairs (qa −qb)2 ≃l2(∂ϕ/∂x)2 + . . . in the
continuum limit; the derivative is obviously taken in the direction that joins the lattice sites
a and b.
Putting it together then, we have
S(q) →S(ϕ) ≡
 T
0
dt

d2xL(ϕ)
=
 T
0
dt

d2x 1
2

σ
	∂ϕ
∂t

2
−ρ
	∂ϕ
∂x

2
+
	∂ϕ
∂y

2
−τϕ2 −ςϕ4 + . . .

(4)
where the parameter ρ is determined by kab and l. The precise relations do not concern us.
Henceforth in this book, we will take the T →∞limit so that we can integrate over all
of spacetime in (4).
We can clean up a bit by writing ρ = σc2 and scaling ϕ →ϕ/√σ , so that the combination
(∂ϕ/∂t)2 −c2[(∂ϕ/∂x)2 + (∂ϕ/∂y)2] appears in the Lagrangian. The parameter c evidently
has the dimension of a velocity and defines the phase velocity of the waves on our mattress.
We started with a mattress for pedagogical reasons. Of course nobody believes that
the fields observed in Nature, such as the meson field or the photon field, are actually
constructed of point masses tied together with springs. The modern view, which I will call
Landau-Ginzburg, is that we start with the desired symmetry, say Lorentz invariance if we
want to do particle physics, decide on the fields we want by specifying how they transform
under the symmetry (in this case we decided on a scalar field ϕ), and then write down
the action involving no more than two time derivatives (because we don’t know how to
quantize actions with more than two time derivatives).
We end up with a Lorentz-invariant action (setting c = 1)
S =

ddx
1
2 (∂ϕ)2 −1
2m2ϕ2 −g
3!ϕ3 −λ
4!ϕ4 + . . .

(5)
where various numerical factors are put in for later convenience. The relativistic nota-
tion (∂ϕ)2 ≡∂μϕ∂μϕ = (∂ϕ/∂t)2 −(∂ϕ/∂x)2 −(∂ϕ/∂y)2 was explained in the note on
convention. The dimension of spacetime, d, clearly can be any integer, even though in
our mattress model it was actually 3. We often write d = D + 1 and speak of a (D + 1)-
dimensional spacetime.
We see here the power of imposing a symmetry. Lorentz invariance together with the
insistence that the Lagrangian involve only at most two powers of ∂/∂t immediately tells us

I.3. From Mattress to Field | 19
that the Lagrangian can only have the form1 L = 1
2(∂ϕ)2 −V (ϕ) with V some function of
ϕ. For simplicity, we now restrict V to be a polynomial in ϕ, although much of the present
discussion will not depend on this restriction. We will have a great deal more to say about
symmetry later. Here we note that, for example, we could insist that physics is symmetric
under ϕ →−ϕ, in which case V (ϕ) would have to be an even polynomial.
Now that you know what a quantum field theory is, you realize why I used the letter q
to label the position of the particle in the previous chapter and not the more common ⃗x.
In quantum field theory, ⃗x is a label, not a dynamical variable. The ⃗x appearing in ϕ(t, ⃗x)
corresponds to the label a in qa(t) in quantum mechanics. The dynamical variable in field
theory is not position, but the field ϕ. The variable ⃗x simply specifies which field variable we
are talking about. I belabor this point because upon first exposure to quantum field theory
some students, used to thinking of ⃗x as a dynamical operator in quantum mechanics, are
confused by its role here.
In summary, we have the table
q →ϕ
a →⃗x
(6)
qa(t) →ϕ(t, ⃗x) = ϕ(x)

a
→

dDx
Thus we finally have the path integral defining a scalar field theory in d = (D + 1) dimen-
sional spacetime:
Z =

Dϕei 
ddx( 1
2 (∂ϕ)2−V (ϕ))
(7)
Note that a (0 + 1)-dimensional quantum field theory is just quantum mechanics.
The classical limit
As I have already remarked, the path integral formalism is particularly convenient for
taking the classical limit. Remembering that Planck’s constant ℏhas the dimension of
energy multiplied by time, we see that it appears in the unitary evolution operator e(−i/ℏ)HT.
Tracing through the derivation of the path integral, we see that we simply divide the overall
factor i by ℏto get
Z =

Dϕe(i/ℏ) 
d4xL(ϕ)
(8)
1 Strictly speaking, a term of the form U(ϕ)(∂ϕ)2 is also possible. In quantum mechanics, a term such as
U(q)(dq/dt)2 in the Lagrangian would describe a particle whose mass depends on position. We will not consider
such “nasty” terms until much later.

20 | I. Motivation and Foundation
In the limit ℏmuch smaller than the relevant action we are considering, we can evaluate the
path integral using the stationary phase (or steepest descent) approximation, as I explained
in the previous chapter in the context of quantum mechanics. We simply determine the
extremum of

d4xL(ϕ). According to the usual Euler-Lagrange variational procedure, this
leads to the equation
∂μ
δL
δ(∂μϕ) −δL
δϕ = 0
(9)
We thus recover the classical field equation, exactly as we should, which in our scalar field
theory reads
(∂2 + m2)ϕ(x) + g
2 ϕ(x)2 + λ
6 ϕ(x)3 + . . . = 0
(10)
The vacuum
In the point particle quantum mechanics discussed in chapter I.2 we wrote the path
integral for ⟨F|e−iHT |I⟩, with some initial and final state, which we can choose at our
pleasure. A convenient and particularly natural choice would be to take |I⟩= |F⟩to be
the ground state. In quantum field theory what should we choose for the initial and final
states? A standard choice for the initial and final states is the ground state or the vacuum
state of the system, denoted by |0⟩, in which, speaking colloquially, nothing is happening.
In other words, we would calculate the quantum transition amplitude from the vacuum to
the vacuum, which would enable us to determine the energy of the ground state. But this
is not a particularly interesting quantity, because in quantum field theory we would like to
measure all energies relative to the vacuum and so, by convention, would set the energy
of the vacuum to zero (possibly by having to subtract a constant from the Lagrangian).
Incidentally, the vacuum in quantum field theory is a stormy sea of quantum fluctuations,
but for this initial pass at quantum field theory, we will not examine it in any detail. We
will certainly come back to the vacuum in later chapters.
Disturbing the vacuum
We might enjoy doing something more exciting than watching a boiling sea of quantum
fluctuations. We might want to disturb the vacuum. Somewhere in space, at some instant
in time, we would like to create a particle, watch it propagate for a while, and then annihilate
it somewhere else in space, at some later instant in time. In other words, we want to set
up a source and a sink (sometimes referred to collectively as sources) at which particles
can be created and annihilated.
To see how to do this, let us go back to the mattress. Bounce up and down on it to create
some excitations. Obviously, pushing on the mass labeled by a in the mattress corresponds
to adding a term such as Ja(t)qa to the potential V (q1, q2, . . . , qN). More generally,

I.3. From Mattress to Field | 21
J
J
J
?
t
x
Figure I.3.1
we can add 
a Ja(t)qa. When we go to field theory this added term gets promoted to

dDxJ(x)ϕ(x) in the field theory Lagrangian, according to the promotion table (6).
This so-called source function J(t, ⃗x) describes how the mattress is being disturbed.
We can choose whatever function we like, corresponding to our freedom to push on the
mattress wherever and whenever we like. In particular, J(x) can vanish everywhere in
spacetime except in some localized regions.
By bouncing up and down on the mattress we can get wave packets going off here and
there (fig. I.3.1). This corresponds precisely to sources (and sinks) for particles. Thus, we
really want the path integral
Z =

Dϕei 
d4x[ 1
2 (∂ϕ)2−V (ϕ)+J(x)ϕ(x)]
(11)
Free field theory
The functional integral in (11) is impossible to do except when
L(ϕ) = 1
2[(∂ϕ)2 −m2ϕ2]
(12)
The corresponding theory is called the free or Gaussian theory. The equation of motion
(9) works out to be (∂2 + m2)ϕ = 0, known as the Klein-Gordon equation.2 Being linear, it
can be solved immediately to give ϕ(⃗x, t) = ei(ωt−⃗k.⃗x) with
ω2 = ⃗k2 + m2
(13)
2 The Klein-Gordon equation was actually discovered by Schr¨odinger before he found the equation that now
bears his name. Later, in 1926, it was written down independently by Klein, Gordon, Fock, Kudar, de Donder,
and Van Dungen.

22 | I. Motivation and Foundation
In the natural units we are using, ℏ= 1 and so frequency ω is the same as energy ℏω
and wave vector ⃗k is the same as momentum ℏ⃗k. Thus, we recognize (13) as the energy-
momentum relation for a particle of mass m, namely the sophisticate’s version of the
layperson’s E = mc2. We expect this field theory to describe a relativistic particle of mass m.
Let us now evaluate (11) in this special case:
Z =

Dϕei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]+Jϕ}
(14)
Integrating by parts under the

d4x and not worrying about the possible contribution of
boundary terms at infinity (we implicitly assume that the fields we are integrating over fall
off sufficiently rapidly), we write
Z =

Dϕei 
d4x[−1
2 ϕ(∂2+m2)ϕ+Jϕ]
(15)
You will encounter functional integrals like this again and again in your study of field
theory. The trick is to imagine discretizing spacetime. You don’t actually have to do it:
Just imagine doing it. Let me sketch how this goes. Replace the function ϕ(x) by the
vector ϕi = ϕ(ia) with i an integer and a the lattice spacing. (For simplicity, I am writing
things as if we were in 1-dimensional spacetime. More generally, just let the index i
enumerate the lattice points in some way.) Then differential operators become matrices.
For example, ∂ϕ(ia) →(1/a) (ϕi+1 −ϕi) ≡
j Mijϕj, with some appropriate matrix M.
Integrals become sums. For example,

d4xJ(x)ϕ(x) →a4 
i Jiϕi.
Now, lo and behold, the integral (15) is just the integral we did in (I.2.23)
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dq1dq2 . . . dqN e(i/2)q.A.q+iJ.q
=
	(2πi)N
det[A]

 1
2
e−(i/2)J.A−1.J
(16)
The role of A in (16) is played in (15) by the differential operator −(∂2 + m2). The defining
equation for the inverse, A . A−1 = I or AijA−1
jk = δik, becomes in the continuum limit
−(∂2 + m2)D(x −y) = δ(4)(x −y)
(17)
We denote the continuum limit of A−1
jk by D(x −y) (which we know must be a function
of x −y, and not of x and y separately, since no point in spacetime is special). Note that
in going from the lattice to the continuum Kronecker is replaced by Dirac. It is very useful
to be able to go back and forth mentally between the lattice and the continuum.
Our final result is
Z(J) = Ce−(i/2) 
d4xd4yJ(x)D(x−y)J(y) ≡CeiW(J)
(18)
with D(x) determined by solving (17). The overall factor C, which corresponds to the overall
factor with the determinant in (16), does not depend on J and, as will become clear in the
discussion to follow, is often of no interest to us. I will often omit writing C altogether.
Clearly, C = Z(J = 0) so that W(J) is defined by
Z(J) ≡Z(J = 0)eiW(J)
(19)

I.3. From Mattress to Field | 23
Observe that
W(J) = −1
2
 
d4xd4yJ(x)D(x −y)J(y)
(20)
is a simple quadratic functional of J . In contrast, Z(J) depends on arbitrarily high powers
of J . This fact will be of importance in chapter I.7.
Free propagator
The function D(x), known as the propagator, plays an essential role in quantum field
theory. As the inverse of a differential operator it is clearly closely related to the Green’s
function you encountered in a course on electromagnetism.
Physicists are sloppy about mathematical rigor, but even so, they have to be careful once
in a while to make sure that what they are doing actually makes sense. For the integral
in (15) to converge for large ϕ we replace m2 →m2 −iε so that the integrand contains a
factor e−ε 
d4xϕ2, where ε is a positive infinitesimal we will let tend to zero.3
We can solve (17) easily by going to momentum space and multiplying together four
copies of the representation (I.2.11) of the Dirac delta function
δ(4)(x −y) =

d4k
(2π)4 eik(x−y)
(21)
The solution is
D(x −y) =

d4k
(2π)4
eik(x−y)
k2 −m2 + iε
(22)
which you can check by plugging into (17):
−(∂2 + m2)D(x −y) =

d4k
(2π)4
k2 −m2
k2 −m2 + iε eik(x−y) =

d4k
(2π)4 eik(x−y) = δ(4)(x −y) as ε →0.
Note that the so-called iε prescription we just mentioned is essential; otherwise the
integral giving D(x) would hit a pole. The magnitude of ε is not important as long as it is
infinitesimal, but the positive sign of ε is crucial as we will see presently. (More on this in
chapter III.8.) Also, note that the sign of k in the exponential does not matter here by the
symmetry k →−k.
To evaluate D(x) we first integrate over k0 by the method of contours. Define ωk ≡
+

⃗k2 + m2 with a plus sign. The integrand has two poles in the complex k0 plane, at
±

ω2
k −iε, which in the ε →0 limit are equal to +ωk −iε and −ωk + iε. Thus for ε
positive, one pole is in the lower half-plane and the other in the upper half plane, and so
as we go along the real k0 axis from −∞to +∞we do not run into the poles. The issue is
how to close the integration contour.
For x0 positive, the factor eik0x0 is exponentially damped for k0 in the upper half-plane.
Hence we should extend the integration contour extending from −∞to +∞on the real
3 As is customary, ε is treated as generic, so that ε multiplied by any positive number is still ε.

24 | I. Motivation and Foundation
axis to include the infinite semicircle in the upper half-plane, thus enclosing the pole at
−ωk + iε and giving −i

d3k
(2π)32ωk e−i(ωkt−⃗k.⃗x). Again, note that we are free to flip the sign
of ⃗k. Also, as is conventional, we use x0 and t interchangeably. (In view of some reader
confusion here in the first edition, I might add that I generally use x0 with k0 and t with
ωk; k0 is a variable that can take on either sign but ωk is a positive function of ⃗k.)
For x0 negative, we do the opposite and close the contour in the lower half-plane, thus
picking up the pole at +ωk −iε. We now obtain −i

(d3k/(2π)32ωk)e+i(ωkt−⃗k.⃗x).
Recall that the Heaviside (we will meet this great and aptly named physicist in chapter
IV.4) step function θ(t) is defined to be equal to 0 for t < 0 and equal to 1 for t > 0. As for
what θ(0) should be, the answer is that since we are proud physicists and not nitpicking
mathematicians we will just wing it when the need arises. The step function allows us to
package our two integration results together as
D(x) = −i

d3k
(2π)32ωk
[e−i(ωkt−⃗k.⃗x)θ(x0) + ei(ωkt−⃗k.⃗x)θ(−x0)]
(23)
Physically, D(x) describes the amplitude for a disturbance in the field to propagate from
the origin to x. Lorentz invariance tells us that it is a function of x2 and the sign of x0 (since
these are the quantities that do not change under a Lorentz transformation). We thus expect
drastically different behavior depending on whether x is inside or outside the lightcone
defined by x2 = (x0)2 −⃗x2 = 0. Without evaluating the d3k integral we can see roughly
how things go. Let us look at some cases.
In the future cone, x = (t, 0) with t > 0, D(x) = −i

(d3k/(2π)32ωk)e−iωkt a superpo-
sition of plane waves and thus D(x) oscillates. In the past cone, x = (t, 0) with t < 0,
D(x) = −i

(d3k/(2π)32ωk)e+iωkt oscillates with the opposite phase.
In contrast, for x spacelike rather than timelike, x0 = 0, we have, upon interpret-
ing θ(0) = 1
2 (the obvious choice; imagine smoothing out the step function), D(x) =
−i

(d3k/(2π)32

⃗k2 + m2)e−i⃗k.⃗x. The square root cut starting at ±im tells us that the
characteristic value of |⃗k| in the integral is of order m, leading to an exponential decay
∼e−m|⃗x|, as we would expect. Classically, a particle cannot get outside the lightcone, but a
quantum field can “leak” out over a distance of order m−1 by the Heisenberg uncertainty
principle.
Exercises
I.3.1
Verify that D(x) decays exponentially for spacelike separation.
I.3.2
Work out the propagator D(x) for a free field theory in (1 + 1)-dimensional spacetime and study the large
x1 behavior for x0 = 0.
I.3.3
Show that the advanced propagator defined by
Dadv(x −y) =

d4k
(2π)4
eik(x−y)
k2 −m2 −i sgn(k0)ε

I.3. From Mattress to Field | 25
(where the sign function is defined by sgn(k0) = +1 if k0 > 0 and sgn(k0) = −1 if k0 < 0) is nonzero only
if x0 > y0. In other words, it only propagates into the future. [Hint: both poles of the integrand are now
in the upper half of the k0-plane.] Incidentally, some authors prefer to write (k0 −ie)2 −⃗k2 −m2 instead
of k2 −m2 −i sgn(k0)ε in the integrand. Similarly, show that the retarded propagator
Dret(x −y) =

d4k
(2π)4
eik(x−y)
k2 −m2 + i sgn(k0)ε
propagates into the past.

I.4
From Field to Particle to Force
From field to particle
In the previous chapter we obtained for the free theory
W(J) = −1
2
 
d4xd4yJ(x)D(x −y)J(y)
(1)
which we now write in terms of the Fourier transform J(k) ≡

d4xe−ikxJ(x):
W(J) = −1
2

d4k
(2π)4 J(k)∗
1
k2 −m2 + iε J(k)
(2)
[Note that J(k)∗= J(−k) for J(x) real.]
We can jump up and down on the mattress any way we like. In other words, we can
choose any J(x) we want, and by exploiting this freedom of choice, we can extract a
remarkable amount of physics.
Consider J(x) = J1(x) + J2(x), where J1(x) and J2(x) are concentrated in two local
regions 1 and 2 in spacetime (fig. I.4.1). Then W(J) contains four terms, of the form J ∗
1 J1,
J ∗
2 J2, J ∗
1 J2, and J ∗
2 J1. Let us focus on the last two of these terms, one of which reads
W(J) = −1
2

d4k
(2π)4 J2(k)∗
1
k2 −m2 + iε J1(k)
(3)
We see that W(J) is large only if J1(x) and J2(x) overlap significantly in their Fourier
transform and if in the region of overlap in momentum space k2 −m2 almost vanishes.
There is a “resonance type” spike at k2 = m2, that is, if the energy-momentum relation
of a particle of mass m is satisfied. (We will use the language of the relativistic physicist,
writing “momentum space” for energy-momentum space, and lapse into nonrelativistic
language only when the context demands it, such as in “energy-momentum relation.”)
We thus interpret the physics contained in our simple field theory as follows: In region
1 in spacetime there exists a source that sends out a “disturbance in the field,” which
is later absorbed by a sink in region 2 in spacetime. Experimentalists choose to call this

I.4. From Field to Particle to Force | 27
J1
t
J2
x
Figure I.4.1
disturbance in the field a particle of mass m. Our expectation based on the equation of
motion that the theory contains a particle of mass m is fulfilled.
A bit of jargon: When k2 = m2, k is said to be on mass shell. Note, however, that in (3)
we integrate over all k, including values of k far from the mass shell. For arbitrary k, it is
a linguistic convenience to say that a “virtual particle” of momentum k propagates from
the source to the sink.
From particle to force
We can now go on to consider other possibilities for J(x) (which we will refer to generically
as sources), for example, J(x) = J1(x) + J2(x), where Ja(x) = δ(3)(⃗x −⃗xa). In other words,
J(x) is a sum of sources that are time-independent infinitely sharp spikes located at ⃗x1 and
⃗x2 in space. (If you like more mathematical rigor than is offered here, you are welcome to
replace the delta function by lumpy functions peaking at ⃗xa. You would simply clutter up
the formulas without gaining much.) More picturesquely, we are describing two massive
lumps sitting at ⃗x1 and ⃗x2 on the mattress and not moving at all [no time dependence in
J(x)].
What do the quantum fluctuations in the field ϕ, that is, the vibrations in the mattress,
do to the two lumps sitting on the mattress? If you expect an attraction between the two
lumps, you are quite right.
As before, W(J) contains four terms. We neglect the “self-interaction” term J1J1 since
this contribution would be present in W regardless of whether J2 is present or not. We
want to study the interaction between the two “massive lumps” represented by J1 and J2.
Similarly we neglect J2J2.

28 | I. Motivation and Foundation
Plugging into (1) and doing the integral over d3x and d3y we immediately obtain
W(J) = −
 
dx0dy0

dk0
2π eik0(x−y)0 
d3k
(2π)3
ei⃗k.( ⃗x1−⃗x2)
k2 −m2 + iε
(4)
(The factor 2 comes from the two terms J2J1 and J1J2. ) Integrating over y0 we get a delta
function setting k0 to zero (so that k is certainly not on mass shell, to throw the jargon
around a bit). Thus we are left with
W(J) =
	
dx0

 
d3k
(2π)3
ei⃗k.( ⃗x1−⃗x2)
⃗k2 + m2
(5)
Note that the infinitesimal iε can be dropped since the denominator ⃗k2 + m2 is always
positive.
The factor (

dx0) should have filled us with fear and trepidation: an integral over time,
it seems to be infinite. Fear not! Recall that in the path integral formalism Z = C eiW(J)
represents ⟨0|e−iHT |0⟩= e−iET, where E is the energy due to the presence of the two
sources acting on each other. The factor (

dx0) produces precisely the time interval T. All
is well. Setting iW = −iET we obtain from (5)
E = −

d3k
(2π)3
ei⃗k.( ⃗x1−⃗x2)
⃗k2 + m2
(6)
The integral is evaluated in an appendix. This energy is negative! The presence of two delta
function sources, at ⃗x1 and ⃗x2, has lowered the energy. (Notice that for the two sources
infinitely far apart, we have, as we might expect, E = 0: the infinitely rapidly oscillating
exponential kills the integral.) In other words, two like objects attract each other by virtue
of their coupling to the field ϕ . We have derived our first physical result in quantum field
theory!
We identify E as the potential energy between two static sources. Even without doing
the integral, we see by dimensional analysis that the characteristic distance beyond which
the integral goes to zero is given by the inverse of the characteristic value of k, which is
m. Thus, we expect the attraction between the two sources to decrease rapidly to zero over
the distance 1/m.
The range of the attractive force generated by the field ϕ is determined inversely by the
mass m of the particle described by the field. Got that?
The integral is done in the appendix to this chapter and gives
E = −1
4πr e−mr
(7)
The result is as we expected: The potential drops off exponentially over the distance scale
1/m. Obviously, dE/dr > 0: The two massive lumps sitting on the mattress can lower the
energy by getting closer to each other.
What we have derived was one of the most celebrated results in twentieth-century
physics. Yukawa proposed that the attraction between nucleons in the atomic nucleus is
due to their coupling to a field like the ϕ field described here. The known range of the
nuclear force enabled him to predict not only the existence of the particle associated with

I.4. From Field to Particle to Force | 29
this field, now called the π meson1 or the pion, but its mass as well. As you probably know,
the pion was eventually discovered with essentially the properties predicted by Yukawa.
Origin of force
That the exchange of a particle can produce a force was one of the most profound concep-
tual advances in physics. We now associate a particle with each of the known forces: for
example, the photon with the electromagnetic force and the graviton with the gravitational
force; the former is experimentally well established and while the latter has not yet been
detected experimentally hardly anyone doubts its existence. We will discuss the photon and
the graviton in the next chapter, but we can already answer a question smart high school
students often ask: Why do Newton’s gravitational force and Coulomb’s electric force both
obey the 1/r2 law?
We see from (7) that if the mass m of the mediating particle vanishes, the force produced
will obey the 1/r2 law. If you trace back over our derivation, you will see that this comes
from the fact that the Lagrangian density for the simplest field theory involves two powers
of the spacetime derivative ∂(since any term involving one derivative such as ϕ ∂ϕ is not
Lorentz invariant). Indeed, the power dependence of the potential follows simply from
dimensional analysis:

d3k(ei⃗k.⃗x/k2) ∼1/r.
Connected versus disconnected
We end with a couple of formal remarks of importance to us only in chapter I.7. First,
note that we might want to draw a small picture fig. (I.4.2) to represent the integrand
J(x)D(x −y)J(y) in W(J): A disturbance propagates from y to x (or vice versa). In fact,
this is the beginning of Feynman diagrams! Second, recall that
Z(J) = Z(J = 0)
∞

n=0
[iW(J)]n
n!
For instance, the n = 2 term in Z(J)/Z(J = 0) is given by
1
2!
	
−i
2

2    
d4x1d4x2d4x3d4x4D(x1 −x2)
D(x3 −x4)J(x1)J(x2)J(x3)J(x4)
The integrand is graphically described in figure I.4.3. The process is said to be discon-
nected: The propagation from x1 to x2 and the propagation from x3 to x4 proceed inde-
pendently. We will come back to the difference between connected and disconnected in
chapter I.7.
1 The etymology behind this word is quite interesting (A. Zee, Fearful Symmetry: see pp. 169 and 335 to learn,
among other things, the French objection and the connection between meson and illusion).

30 | I. Motivation and Foundation
y
x
Figure I.4.2
x1
x2
x4
x3
Figure I.4.3

I.4. From Field to Particle to Force | 31
Appendix
Writing ⃗x ≡( ⃗x1 −⃗x2) and u ≡cos θ with θ the angle between ⃗k and ⃗x, we evaluate the integral in (6) in spherical
coordinates (with k = |⃗k| and r = |⃗x|):
I ≡
1
(2π)2
 ∞
0
dk k2
 +1
−1
du
eikru
k2 + m2 =
2i
(2π)2ir
 ∞
0
dk k sin kr
k2 + m2
(8)
Since the integrand is even, we can extend the integral and write it as
1
2
 ∞
−∞
dk k sin kr
k2 + m2 = 1
2i
 ∞
−∞
dk k
1
k2 + m2eikr.
Since r is positive, we can close the contour in the upper half-plane and pick up the pole at +im, obtaining
(1/2i)(2πi)(im/2im)e−mr = (π/2)e−mr. Thus, I = (1/4πr)e−mr.
Exercise
I.4.1
Calculate the analog of the inverse square law in a (2 + 1)-dimensional universe, and more generally in
a (D + 1)-dimensional universe.

I.5
Coulomb and Newton: Repulsion and Attraction
Why like charges repel
We suggested that quantum field theory can explain both Newton’s gravitational force and
Coulomb’s electric force naturally. Between like objects Newton’s force is attractive while
Coulomb’s force is repulsive. Is quantum field theory “smart enough” to produce this
observational fact, one of the most basic in our understanding of the physical universe?
You bet!
We will first treat the quantum field theory of the electromagnetic field, known as
quantum electrodynamics or QED for short. In order to avoid complications at this stage
associated with gauge invariance (about which much more later) I will consider instead
the field theory of a massive spin 1meson, or vector meson. After all, experimentally all we
know is an upper bound on the photon mass, which although tiny is not mathematically
zero. We can adopt a pragmatic attitude: Calculate with a photon mass m and set m = 0 at
the end, and if the result does not blow up in our faces, we will presume that it is OK.1
Recall Maxwell’s Lagrangian for electromagnetism L = −1
4FμνF μν, where Fμν ≡∂μAν
−∂νAμ with Aμ(x) the vector potential. You can see the reason for the important overall
minus sign in the Lagrangian by looking at the coefficient of (∂0Ai)2, which has to be
positive, just like the coefficient of (∂0ϕ)2 in the Lagrangian for the scalar field. This says
simply that time variation should cost a positive amount of action.
I will now give the photon a small mass by changing the Lagrangian to L = −1
4FμνF μν
+ 1
2m2AμAμ + AμJ μ. (The mass term is written in analogy to the mass term m2ϕ2 in
the scalar field Lagrangian; we will see shortly that the sign is correct and that this term
indeed leads to a photon mass.) I have also added a source J μ(x) ,which in this context is
more familiarly known as a current. We will assume that the current is conserved so that
∂μJ μ = 0.
1 When I took a field theory course as a student with Sidney Coleman this was how he treated QED in order
to avoid discussing gauge invariance.

I.5. Coulomb and Newton | 33
Well, you know that the field theory of our vector meson is defined by the path integral
Z =

DA eiS(A) ≡eiW(J) with the action
S(A) =

d4xL =

d4x{ 1
2Aμ[(∂2 + m2)gμν −∂μ∂ν]Aν + AμJ μ}
(1)
The second equality follows upon integrating by parts [compare (I.3.15)].
By now you have learned that we simply apply (I.3.16). We merely have to find the inverse
of the differential operator in the square bracket; in other words, we have to solve
[(∂2 + m2)gμν −∂μ∂ν]Dνλ(x) = δμ
λ δ(4)(x)
(2)
As before [compare (I.3.17)] we go to momentum space by defining
Dνλ(x) =

d4k
(2π)4 Dνλ(k)eikx
Plugging in, we find that [−(k2 −m2)gμν + kμkν]Dνλ(k) = δμ
λ , giving
Dνλ(k) = −gνλ + kνkλ/m2
k2 −m2
(3)
This is the photon, or more accurately the massive vector meson, propagator. Thus
W(J) = −1
2

d4k
(2π)4 J μ(k)∗−gμν + kμkν/m2
k2 −m2 + iε
J ν(k)
(4)
Since current conservation ∂μJ μ(x) = 0 gets translated into momentum space as
kμJ μ(k) = 0, we can throw away the kμkν term in the photon propagator. The effective
action simplifies to
W(J) = 1
2

d4k
(2π)4 J μ(k)∗
1
k2 −m2 + iε Jμ(k)
(5)
No further computation is needed to obtain a profound result. Just compare this result
to (I.4.2). The field theory has produced an extra sign. The potential energy between two
lumps of charge density J 0(x) is positive. The electromagnetic force between like charges
is repulsive!
We can now safely let the photon mass m go to zero thanks to current conservation.
[Note that we could not have done that in (3).] Indeed, referring to (I.4.7) we see that the
potential energy between like charges is
E =
1
4πr e−mr →
1
4πr
(6)
To accommodate positive and negative charges we can simply write J μ = J μ
p −J μ
n . We
see that a lump with charge density J 0
p is attracted to a lump with charge density J 0
n .
Bypassing Maxwell
Having done electromagnetism in two minutes flat let me now do gravity. Let us move on
to the massive spin 2 meson field. In my treatment of the massive spin 1 meson field I

34 | I. Motivation and Foundation
took a short cut. Assuming that you are familiar with the Maxwell Lagrangian, I simply
added a mass term to it and took off. But I do not feel comfortable assuming that you are
equally familiar with the corresponding Lagrangian for the massless spin 2 field (the so-
called linearized Einstein Lagrangian, which I will discuss in a later chapter). So here I will
follow another strategy.
I invite you to think physically, and together we will arrive at the propagator for a massive
spin 2 field. First, we will warm up with the massive spin 1 case.
In fact, start with something even easier: the propagator D(k) = 1/(k2 −m2) for a
massive spin 0 field. It tells us that the amplitude for the propagation of a spin 0 disturbance
blows up when the disturbance is almost a real particle. The residue of the pole is a property
of the particle. The propagator for a spin 1 field Dνλ carries a pair of Lorentz indices and
in fact we know what it is from (3):
Dνλ(k) = −Gνλ
k2 −m2
(7)
where for later convenience we have defined
Gνλ(k) ≡gνλ −kνkλ
m2
(8)
Let us now understand the physics behind Gνλ. I expect you to remember the concept
of polarization from your course on electromagnetism. A massive spin 1 particle has three
degrees of polarization for the obvious reason that in its rest frame its spin vector can point
in three different directions. The three polarization vectors ε(a)
μ are simply the three unit
vectors pointing along the x, y, and z axes, respectively (a = 1, 2, 3): ε(1)
μ = (0, 1, 0, 0),
ε(2)
μ = (0, 0, 1, 0), ε(3)
μ = (0, 0, 0, 1). In the rest frame kμ = (m, 0, 0, 0) and so
kμε(a)
μ = 0
(9)
Since this is a Lorentz invariant equation, it holds for a moving spin 1 particle as well.
Indeed, with a suitable normalization condition this fixes the three polarization vectors
ε(a)
μ (k) for a particle with momentum k.
The amplitude for a particle with momentum k and polarization a to be created at
the source is proportional to ε(a)
λ (k), and the amplitude for it to be absorbed at the sink
is proportional to ε(a)
ν (k). We multiply the amplitudes together to get the amplitude for
propagation from source to sink, and then sum over the three possible polarizations.
Now we understand the residue of the pole in the spin 1 propagator Dνλ(k): It represents

a ε(a)
ν (k) ε(a)
λ (k) . To calculate this quantity, note that by Lorentz invariance it can only be
a linear combination of gνλ and kνkλ. The condition kμε(a)
μ = 0 fixes it to be proportional
to gνλ −kνkλ/m2. We evaluate the left-hand side for k at rest with ν = λ = 1, for instance,
and fix the overall and all-crucial sign to be −1. Thus

a
ε(a)
ν (k)ε(a)
λ (k) = −Gνλ(k) ≡−
	
gνλ −kνkλ
m2

(10)
We have thus constructed the propagator Dνλ(k) for a massive spin 1 particle, bypassing
Maxwell (see appendix 1).
Onward to spin 2! We want to similarly bypass Einstein.

I.5. Coulomb and Newton | 35
Bypassing Einstein
A massive spin 2 particle has 5 (2 . 2 + 1 = 5, remember?) degrees of polarization, char-
acterized by the five polarization tensors ε(a)
μν (a = 1, 2, . . . , 5) symmetric in the indices μ
and ν satisfying
kμε(a)
μν = 0
(11)
and the tracelessness condition
gμνε(a)
μν = 0
(12)
Let’s count as a check. A symmetric Lorentz tensor has 4 . 5/2 = 10 components. The four
conditions in (11) and the single condition in (12) cut the number of components down to
10 −4 −1 = 5, precisely the right number. (Just to throw some jargon around, remember
how to construct irreducible group representations? If not, read appendix B.) We fix the
normalization of εμν by setting the positive quantity 
a ε(a)
12 (k)ε(a)
12 (k) = 1.
So, in analogy with the spin 1 case we now determine 
a ε(a)
μν (k)ε(a)
λσ (k). We have to
construct this object out of gμν and kμ, or equivalently Gμν and kμ. This quantity must
be a linear combination of terms such as GμνGλσ , Gμνkλkσ , and so forth. Using (11) and
(12) repeatedly (exercise I.5.1) you will easily find that

a
ε(a)
μν (k)ε(a)
λσ (k) = (GμλGνσ + GμσGνλ) −2
3GμνGλσ
(13)
The overall sign and proportionality constant are determined by evaluating both sides for
k at rest (for μ = λ = 1 and ν = σ = 2, for instance).
Thus, we have determined the propagator for a massive spin 2 particle
Dμν, λσ(k) = (GμλGνσ + GμσGνλ) −2
3GμνGλσ
k2 −m2
(14)
Why we fall
We are now ready to understand one of the fundamental mysteries of the universe: Why
masses attract.
Recall from your courses on electromagnetism and special relativity that the energy or
mass density out of which mass is composed is part of a stress-energy tensor T μν. For our
purposes, in fact, all you need to remember is that T μν is a symmetric tensor and that
the component T 00 is the energy density. If you don’t remember, I will give you a physical
explanation in appendix 2.
To couple to the stress-energy tensor, we need a tensor field ϕμν symmetric in its two
indices. In other words, the Lagrangian of the world should contain a term like ϕμνT μν.
This is in fact how we know that the graviton, the particle responsible for gravity, has spin 2,
just as we know that the photon, the particle responsible for electromagnetism and hence

36 | I. Motivation and Foundation
coupled to the current J μ, has spin 1. In Einstein’s theory, which we will discuss in a later
chapter, ϕμν is of course part of the metric tensor.
Just as we pretended that the photon has a small mass to avoid having to discuss gauge
invariance, we will pretend that the graviton has a small mass to avoid having to discuss
general coordinate invariance.2 Aha, we just found the propagator for a massive spin 2
particle. So let’s put it to work.
In precise analogy to (4)
W(J) = −1
2

d4k
(2π)4 J μ(k)∗−gμν + kμkν/m2
k2 −m2 + iε
J ν(k)
(15)
describing the interaction between two electromagnetic currents, the interaction between
two lumps of stress energy is described by
W(T ) =
−1
2

d4k
(2π)4 T μν(k)∗(GμλGνσ + GμσGνλ) −2
3GμνGλσ
k2 −m2 + iε
T λσ(k)
(16)
From
the
conservation
of
energy
and
momentum
∂μT μν(x) = 0
and
hence
kμT μν(k) = 0, we can replace Gμν in (16) by gμν. (Here as is clear from the context gμν still
denotes the flat spacetime metric of Minkowski, rather than the curved metric of Einstein.)
Now comes the punchline. Look at the interaction between two lumps of energy density
T 00. We have from (16) that
W(T ) = −1
2

d4k
(2π)4 T 00(k)∗
1 + 1 −2
3
k2 −m2 + iε T 00(k)
(17)
Comparing with (5) and using the well-known fact that (1 + 1 −2
3) > 0, we see that while
like charges repel, masses attract. Trumpets, please!
The universe
It is difficult to overstate the importance (not to speak of the beauty) of what we have
learned: The exchange of a spin 0 particle produces an attractive force, of a spin 1 particle
a repulsive force, and of a spin 2 particle an attractive force, realized in the hadronic strong
interaction, the electromagnetic interaction, and the gravitational interaction, respectively.
The universal attraction of gravity produces an instability that drives the formation of
structure in the early universe.3 Denser regions become denser yet. The attractive nuclear
force mediated by the spin 0 particle eventually ignites the stars. Furthermore, the attractive
force between protons and neutrons mediated by the spin 0 particle is able to overcome
the repulsive electric force between protons mediated by the spin 1 particle to form a
2 For the moment, I ask you to ignore all subtleties and simply assume that in order to understand gravity it
is kosher to let m →0. I will give a precise discussion of Einstein’s theory of gravity in chapter VIII.1.
3 A good place to read about gravitational instability and the formation of structure in the universe along the
line sketched here is in A. Zee, Einstein’s Universe (formerly known as An Old Man’s Toy).

I.5. Coulomb and Newton | 37
variety of nuclei without which the world would certainly be rather boring. The repulsion
between likes and hence attraction between opposites generated by the spin 1 particle allow
electrically neutral atoms to form.
The world results from a subtle interplay among spin 0, 1, and 2.
In this lightning tour of the universe, we did not mention the weak interaction. In fact,
the weak interaction plays a crucial role in keeping stars such as our sun burning at a
steady rate.
Time differs from space by a sign
This weaving together of fields, particles, and forces to produce a universe rich with
possibilities is so beautiful that it is well worth pausing to examine the underlying physics
some more. The expression in (I.4.1) describes the effect of our disturbing the vacuum
(or the mattress!) with the source J, calculated to second order. Thus some readers may
have recognized that the negative sign in (I.4.6) comes from the elementary quantum
mechanical result that in second order perturbation theory the lowest energy state always
has its energy pushed downward: for the ground state
all the energy denominators have the same sign.
In essence, this “theorem” follows from the property of 2 by 2 matrices. Let us set the
ground state energy to 0 and crudely represent the entirety of the other states by a single
state with energy w > 0. Then the Hamiltonian including the perturbation v effective to
second order is given by
H =
 w
v
v
0

Since the determinant of H (and hence the product of the two eigenvalues) is manifestly
negative, the ground state energy is pushed below 0. [More explicitly, we calculate the
eigenvalue ε with the characteristic equation 0 = ε(ε −w) −v2 ≈−(wε + v2), and hence
ε ≈−v2
w .] In different fields of physics, this phenomenon is variously known as level
repulsion or the seesaw mechanism (see chapter VII.7).
Disturbing the vacuum with a source lowers its energy. Thus it is easy to understand
that generically the exchange of a particles leads to an attractive force.
But then why does the exchange of a spin 1 particle produces a repulsion between like
objects? The secret lies in the profundity that space differs from time by a sign, namely,
that g00 = +1while gii = −1for i = 1, 2, 3. In (10), the left-hand side is manifestly positive
for ν = λ = i. Taking k to be at rest we understand the minus sign in (10) and hence in (4).
Roughly speaking, for spin 2 exchange the sign occurs twice in (16).
Degrees of freedom
Now for a bit of cold water: Logically and mathematically the physics of a particle with mass
m ̸= 0 could well be different from the physics with m = 0. Indeed, we know from classical

38 | I. Motivation and Foundation
electromagnetism that an electromagnetic wave has 2 polarizations, that is, 2 degrees of
freedom. For a massive spin 1particle we can go to its rest frame, where the rotation group
tells us that there are 2.1 + 1 = 3 degrees of freedom. The crucial piece of physics is that we
can never bring the massless photon to its rest frame. Mathematically, the rotation group
SO(3) degenerates into SO(2), the group of 2-dimensional rotations around the direction
of the photon’s momentum.
We will see in chapter II.7 that the longitudinal degree of freedom of a massive spin 1
meson decouples as we take the mass to zero. The treatment given here for the interaction
between charges (6) is correct. However, in the case of gravity, the 2
3 in (17) is replaced by
1 in Einstein’s theory, as we will see chapter VIII.1. Fortunately, the sign of the interaction
given in (17) does not change. Mute the trumpets a bit.
Appendix 1
Pretend that we never heard of the Maxwell Lagrangian. We want to construct a relativistic Lagrangian for a
massive spin 1 meson field. Together we will discover Maxwell. Spin 1 means that the field transforms as a vector
under the 3-dimensional rotation group. The simplest Lorentz object that contains the 3-dimensional vector is
obviously the 4-dimensional vector. Thus, we start with a vector field Aμ(x).
That the vector field carries mass m means that it satisfies the field equation
(∂2 + m2)Aμ = 0
(18)
A spin 1 particle has 3 degrees of freedom [remember, in fancy language, the representation j of the rotation
group has dimension (2j + 1); here j = 1.] On the other hand, the field Aμ(x) contains 4 components. Thus, we
must impose a constraint to cut down the number of degrees of freedom from 4 to 3. The only Lorentz covariant
possibility (linear in Aμ) is
∂μAμ = 0
(19)
It may also be helpful to look at (18) and (19) in momentum space, where they read (k2 −m2)Aμ(k) = 0 and
kμAμ(k) = 0. The first equation tells us that k2 = m2 and the second that if we go to the rest frame kμ = (m, ⃗0)
then A0 vanishes, leaving us with 3 nonzero components Ai with i = 1, 2, 3.
The remarkable observation is that we can combine (18) and (19) into a single equation, namely
(gμν∂2 −∂μ∂ν)Aν + m2Aμ = 0
(20)
Verify that (20) contains both (18) and (19). Act with ∂μ on (20). We obtain m2∂μAμ = 0, which implies that
∂μAμ = 0 . (At this step it is crucial that m ̸= 0 and that we are not talking about the strictly massless photon.)
We have thus obtained (19 ); using (19) in (20) we recover (18).
We can now construct a Lagrangian by multiplying the left-hand side of (20) by + 1
2Aμ (the 1
2 is conventional
but the plus sign is fixed by physics, namely the requirement of positive kinetic energy); thus
L = 1
2Aμ[(∂2 + m2)gμν −∂μ∂ν]Aν
(21)
Integrating by parts, we recognize this as the massive version of the Maxwell Lagrangian. In the limit m →0 we
recover Maxwell.
A word about terminology: Some people insist on calling only Fμν a field and Aμ a potential. Conforming to
common usage, we will not make this fine distinction. For us, any dynamical function of spacetime is a field.

I.5. Coulomb and Newton | 39
Appendix 2: Why does the graviton have spin 2?
First we have to understand why the photon has spin 1. Think physically. Consider a bunch of electrons at
rest inside a small box. An observer moving by sees the box Lorentz-Fitzgerald contracted and thus a higher
charge density than the observer at rest relative to the box. Thus charge density J 0(x) transforms like the time
component of a 4-vector density J μ(x). In other words, J ′0 = J 0/
√
1 −v2. The photon couples to J μ(x) and has
to be described by a 4-vector field Aμ(x) for the Lorentz indices to match.
What about energy density? The observer at rest relative to the box sees each electron contributing m to the
energy enclosed in the box. The moving observer, on the other hand, sees the electrons moving and thus each
having an energy m/
√
1 −v2. With the contracted volume and the enhanced energy, the energy density gets
enhanced by two factors of 1/
√
1 −v2, that is, it transforms like the T 00 component of a 2-indexed tensor T μν.
The graviton couples to T μν(x) and has to be described by a 2-indexed tensor field ϕμν(x) for the Lorentz indices
to match.
Exercise
I.5.1
Write down the most general form for 
a ε(a)
μν (k)ε(a)
λσ (k) using symmetry repeatedly. For example, it must
be invariant under the exchange {μν ↔λσ}. You might end up with something like
AGμνGλσ + B(GμλGνσ + GμσGνλ) + C(Gμνkλkσ + kμkνGλσ)
+ D(kμkλGνσ + kμkσGνλ + kνkσGμλ + kνkλGμσ) + Ekμkνkλkσ
(22)
with various unknown A, . . . , E. Apply kμ 
a ε(a)
μν (k)ε(a)
λσ (k) = 0 and find out what that implies for the
constants. Proceeding in this way, derive (13).

I.6
Inverse Square Law and the Floating 3-Brane
Why inverse square?
In your first encounter with physics, didn’t you wonder why an inverse square force law
and not, say, an inverse cube law? In chapter I.4 you learned the deep answer. When a
massless particle is exchanged between two particles, the potential energy between the
two particles goes as
V (r) ∝

d3k ei⃗k.⃗x 1
⃗k2 ∝1
r
(1)
The spin of the exchanged particle controls the overall sign, but the 1/r follows just from
dimensional analysis, as I remarked earlier. Basically, V (r) is the Fourier transform of the
propagator. The ⃗k2 in the propagator comes from the (∂iϕ . ∂iϕ) term in the action, where
ϕ denotes generically the field associated with the massless particle being exchanged, and
the (∂iϕ . ∂iϕ) form is required by rotational invariance. It couldn’t be ⃗k or ⃗k3 in (1); ⃗k2 is
the simplest possibility. So you can say that in some sense ultimately the inverse square
law comes from rotational invariance!
Physically, the inverse square law goes back to Faraday’s flux picture. Consider a sphere
of radius r surrounding a charge. The electric flux per unit area going through the sphere
varies as 1/4πr2. This geometric fact is reflected in the factor d3k in (1).
Brane world
Remarkably, with the tiny bit of quantum field theory I have exposed you to, I can already
take you to the frontier of current research, current as of the writing of this book. In string
theory, our (3 + 1)-dimensional world could well be embedded in a larger universe, the
way a (2 + 1)-dimensional sheet of paper is embedded in our everyday (3 + 1)-dimensional
world. We are said to be living on a 3 brane.
So suppose there are n extra dimensions, with coordinates x4, x5, . . . , xn+3. Let the
characteristic scales associated with these extra coordinates be R. I can’t go into the

I.6. Inverse Square Law | 41
different detailed scenarios describing what R is precisely. For some reason I can’t go into
either, we are stuck on the 3 brane. In contrast, the graviton is associated intrinsically with
the structure of spacetime and so roams throughout the (n + 3 + 1)-dimensional universe.
All right, what is the gravitational force law between two particles? It is surely not your
grandfather’s gravitational force law: We Fourier transform
V (r) ∝

d3+nk ei⃗k.⃗x 1
⃗k2 ∝
1
r1+n
(2)
to obtain a 1/r1+n law.
Doesn’t this immediately contradict observation?
Well, no, because Newton’s law continues to hold for r ≫R. In this regime, the extra
coordinates are effectively zero compared to the characteristic length scale r we are inter-
ested in. The flux cannot spread far in the direction of the n extra coordinates. Think of
the flux being forced to spread in only the three spatial directions we know, just as the
electromagnetic field in a wave guide is forced to propagate down the tube. Effectively we
are back in (3 + 1)-dimensional spacetime and V (r) reverts to a 1/r dependence.
The new law of gravity (2) holds only in the opposite regime r ≪R. Heuristically, when
R is much larger than the separation between the two particles, the flux does not know
that the extra coordinates are finite in extent and thinks that it lives in an (n + 3 + 1)-
dimensional universe.
Because of the weakness of gravity, Newton’s force law has not been tested to much
accuracy at laboratory distance scales, and so there is plenty of room for theorists to
speculate in: R could easily be much larger than the scale of elementary particles and yet
much smaller than the scale of everyday phenomena. Incredibly, the universe could have
“large extra dimensions”! (The word “large” means large on the scale of particle physics.)
Planck mass
To be quantitative, let us define the Planck mass MPl by writing Newton’s law more
rationally as V (r) = GNm1m2(1/r) = (m1m2/M2
Pl)(1/r). Numerically, MPl ≃1019 Gev.
This enormous value obviously reflects the weakness of gravity.
In fundamental units in which ℏand c are set to unity, gravity defines an intrinsic mass
or energy scale much higher than any scale we have yet explored experimentally. Indeed,
one of the fundamental mysteries of contemporary particle physics is why this mass scale
is so high compared to anything else we know of. I will come back to this so-called hierarchy
problem in due time. For the moment, let us ask if this new picture of gravity, new in the
waning moments of the last century, can alleviate the hierarchy problem by lowering the
intrinsic mass scale of gravity.
Denote the mass scale (the “true scale” of gravity) characteristic of gravity in the (n + 3
+1)-dimensional universe by MTG so that the gravitational potential between two objects
of masses m1 and m2 separated by a distance r ≪R is given by
V (r) =
m1m2
[MTG]2+n
1
r1+n

42 | I. Motivation and Foundation
Note that the dependence on MTG follows from dimensional analysis: two powers to cancel
m1m2 and n powers to match the n extra powers of 1/r. For r ≫R, as we have argued, the
geometric spread of the gravitational flux is cut off by R so that the potential becomes
V (r) =
m1m2
[MTG]2+n
1
Rn
1
r
Comparing with the observed law V (r) = (m1m2/M2
Pl)(1/r) we obtain
M2
TG =
M2
P l
[MTGR]n
(3)
If MTGR could be made large enough, we have the intriguing possibility that the funda-
mental scale of gravity MTG may be much lower than what we have always thought.
Accelerators (such as the large Hadron Collider) could offer an exciting verification of
this intriguing possibility. If the true scale of gravity MTG lies in an energy range accessible
to the accelerator, there may be copious production of gravitons escaping into the higher
dimensional universe. Experimentalists would see a massive amount of missing energy.
Exercise
I.6.1
Putting in the numbers, show that the case n = 1 is already ruled out.

I.7
Feynman Diagrams
Feynman brought quantum field theory to the masses.
—J. Schwinger
Anharmonicity in field theory
The free field theory we studied in the last few chapters was easy to solve because the defin-
ing path integral (I.3.14) is Gaussian, so we could simply apply (I.2.15). (This corresponds
to solving the harmonic oscillator in quantum mechanics.) As I noted in chapter I.3, within
the harmonic approximation the vibrational modes on the mattress can be linearly super-
posed and thus they simply pass through each other. The particles represented by wave
packets constructed out of these modes do not interact:1 hence the term free field theory.
To have the modes scatter off each other we have to include anharmonic terms in the La-
grangian so that the equation of motion is no longer linear. For the sake of simplicity let
us add only one anharmonic term −λ
4!ϕ4 to our free field theory and, recalling (I.3.11), try
to evaluate
Z(J) =

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]−λ
4!ϕ4+Jϕ}
(1)
(We suppress the dependence of Z on λ.)
Doing quantum field theory is no sweat, you say, it just amounts to doing the functional
integral (1). But the integral is not easy! If you could do it, it would be big news.
Feynman diagrams made easy
As an undergraduate, I heard of these mysterious little pictures called Feynman diagrams
and really wanted to learn about them. I am sure that you too have wondered about those
1 A potential source of confusion: Thanks to the propagation of ϕ, the sources coupled to ϕ interact, as was
seen in chapter I.4, but the particles associated with ϕ do not interact with each other. This is like saying that
charged particles coupled to the photon interact, but (to leading approximation) photons do not interact with
each other.

44 | I. Motivation and Foundation
funny diagrams. Well, I want to show you that Feynman diagrams are not such a big deal:
Indeed we have already drawn little spacetime pictures in chapters I.3 and I.4 showing
how particles can appear, propagate, and disappear.
Feynman diagrams have long posed somewhat of an obstacle for first-time learners
of quantum field theory. To derive Feynman diagrams, traditional texts typically adopt the
canonical formalism (which I will introduce in the next chapter) instead of the path integral
formalism used here. As we will see, in the canonical formalism fields appear as quantum
operators. To derive Feynman diagrams, we would have to solve the equation of motion
of the field operators perturbatively in λ. A formidable amount of machinery has to be
developed.
In the opinion of those who prefer the path integral, the path integral formalism
derivation is considerably simpler (naturally!). Nevertheless, the derivation can still get
rather involved and the student could easily lose sight of the forest for the trees. There is
no getting around the fact that you would have to put in some effort.
I will try to make it as easy as possible for you. I have hit upon the great pedagogical
device of letting you discover the Feynman diagrams for yourself. My strategy is to let you
tackle two problems of increasing difficulty, what I call the baby problem and the child
problem. By the time you get through these, the problem of evaluating (1) will seem much
more tractable.
A baby problem
The baby problem is to evaluate the ordinary integral
Z(J) =
 +∞
−∞
dqe−1
2 m2q2−λ
4!q4+Jq
(2)
evidently a much simpler version of (1).
First, a trivial point: we can always scale q →q/m so that Z = m−1F( λ
m4 , J
m), but we
won’t.
For λ = 0 this is just one of the Gaussian integrals done in the appendix of chapter I.2.
Well, you say, it is easy enough to calculate Z(J) as a series in λ : expand
Z(J) =
 +∞
−∞
dqe−1
2 m2q2+Jq

1 −λ
4!q4 + 1
2( λ
4!)2q8 + . . .

and integrate term by term. You probably even know one of several tricks for computing
 +∞
−∞dqe−1
2m2q2+Jqq4n: you write it as ( d
dJ )4n  +∞
−∞dqe−1
2m2q2+Jq and refer to (I.2.19). So
Z(J) = (1 −λ
4!( d
dJ )4 + 1
2( λ
4!)2( d
dJ )8 + . . .)
 +∞
−∞
dqe−1
2 m2q2+Jq
(3)
= e−λ
4!( d
dJ )4  +∞
−∞
dqe−1
2 m2q2+Jq = (2π
m2)
1
2e−λ
4!( d
dJ )4e
1
2m2 J 2
(4)
(There are other tricks, such as differentiating
 +∞
−∞dqe−1
2m2q2+Jq with respect to m2
repeatedly, but I want to discuss a trick that will also work for field theory.) By expanding

I.7. Feynman Diagrams | 45
J
J
J
J
J
J
J
J
J
J
J
J
λ
λ
λ
(a)
(b)
(c)
(    )4λJ4
1
m2
Figure I.7.1
the two exponentials we can obtain any term in a double series expansion of Z(J) in λ and
J . [We will often suppress the overall factor (2π/m2)
1
2 = Z(J = 0, λ = 0) ≡Z(0, 0) since it
will be common to all terms. When we want to be precise, we will define ˜Z = Z(J)/Z(0, 0).]
For example, suppose we want the term of order λ and J 4 in ˜Z. We extract the order
J 8 term in eJ 2/2m2, namely, [1/4!(2m2)4]J 8, replace e−(λ/4!)(d/dJ)4 by −(λ/4!)(d/dJ)4,
and differentiate to get [8!(−λ)/(4!)3(2m2)4]J 4. Another example: the term of order λ2
and J 4 is [12!(−λ)2/(4!)36!2(2m2)6]J 4. A third example: the term of order λ2 and J 6 is
1
2(λ/4!)2(d/dJ)8[1/7!(2m2)7]J 14 = [14!(−λ)2/(4!)26!7!2(2m2)7]J 6. Finally, the term of order
λ and J 0 is [1/2(2m2)2] (−λ).
You can do this as well as I can! Do a few more and you will soon see a pattern. In
fact, you will eventually realize that you can associate diagrams with each term and codify
some rules. Our four examples are associated with the diagrams in figures I.7.1–I.7.4.
You can see, for a reason you will soon understand, that each term can be associated with
several diagrams. I leave you to work out the rules carefully to get the numerical factors
right (but trust me, the “future of democracy” is not going to depend on them). The rules
go something like this: (1) diagrams are made of lines and vertices at which four lines
meet; (2) for each vertex assign a factor of (−λ); (3) for each line assign 1/m2; and (4) for
each external end assign J (e.g., figure I.7.3 has seven lines, two vertices, and six ends,
giving ∼[(−λ)2/(m2)7]J 6.) (Did you notice that twice the number of lines is equal to four
times the number of vertices plus the number of ends? We will meet relations like that in
chapter III.2.)
In addition to the two diagrams shown in figure I.7.3, there are ten diagrams obtained
by adding an unconnected straight line to each of the ten diagrams in figure I.7.2. (Do you
understand why?)
For obvious reasons, some diagrams (e.g., figure I.7.1a, I.7.3a) are known as tree2
diagrams and others (e.g., Figs. I.7.1b and I.7.2a) as loop diagrams.
Do as many examples as you need until you feel thoroughly familiar with what is going
on, because we are going to do exactly the same thing in quantum field theory. It will
look much messier, but only superficially. Be sure you understand how to use diagrams to
2 The Chinese character for tree (A. Zee, Swallowing Clouds) is shown in fig. I.7.5. I leave it to you to figure
out why this diagram does not appear in our Z(J).

J
J
J
J

(a)
(b)
(d)
(e)
(i)
(j)
(    )62J4
(f)
(g)
(h)
(c)

1
m2
Figure I.7.2
J
J
J
J

(a)
(b)
(    )72J6
1
m2
J

J
Figure I.7.3
Figure I.7.4

I.7. Feynman Diagrams | 47
Figure I.7.5
represent the double series expansion of ˜Z(J) before reading on. Please. In my experience
teaching, students who have not thoroughly understood the expansion of ˜Z(J) have no
hope of understanding what we are going to do in the field theory context.
Wick contraction
It is more obvious than obvious that we can expand Z(J) in powers of J , if we please,
instead of in powers of λ. As you will see, particle physicists like to classify in power of J .
In our baby problem, we can write
Z(J) =
∞

s=0
1
s!J s
 +∞
−∞
dqe−1
2 m2q2−(λ/4!)q4qs ≡Z(0, 0)
∞

s=0
1
s!J sG(s)
(5)
The coefficient G(s), whose analogs are known as “Green’s functions” in field theory, can
be evaluated as a series in λ with each term determined by Wick contraction (I.2.10). For
instance, the O(λ) term in G(4) is
−λ
4!Z(0, 0)
 +∞
−∞
dqe−1
2 m2q2q8 = −7!!
4!
1
m8
which of course better be equal3 to what we obtained above for the λJ 4 term in ˜Z. Thus,
there are two ways of computing Z : you expand in λ first or you expand in J first.
Connected versus disconnected
You will have noticed that some Feynman diagrams are connected and others are not.
Thus, figure I.7.3a is connected while 3b is not. I presaged this at the end of chapter I.4
and in figures I.4.2 and I.4.3. Write
Z(J , λ) = Z(J = 0, λ)eW(J ,λ) = Z(J = 0, λ)
∞

N=0
1
N![W(J , λ)]N
(6)
By definition, Z(J = 0, λ) consists of those diagrams with no external source J, such as
the one in figure I.7.4. The statement is that W is a sum of connected diagrams while
3 As a check on the laws of arithmetic we verify that indeed 7!!/(4!)2 = 8!/(4!)324.

48 | I. Motivation and Foundation
Z contains connected as well as disconnected diagrams. Thus, figure I.7.3b consists of
two disconnected pieces and comes from the term (1/2!)[W(J , λ)]2 in (6), the 2! taking
into account that it does not matter which of the two pieces you put “on the left or on the
right.” Similarly, figure I.7.2i comes from (1/3!)[W(J , λ)]3. Thus, it is W that we want to
calculate, not Z. If you’ve had a good course on statistical mechanics, you will recognize
that this business of connected graphs versus disconnected graphs is just what underlies
the relation between free energy and the partition function.
Propagation: from here to there
All these features of the baby problem are structurally the same as the corresponding
features of field theory and we can take over the discussion almost immediately. But before
we graduate to field theory, let us consider what I call a child problem, the evaluation of a
multiple integral instead of a single integral:
Z(J) =
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dq1dq2 . . . dqN e−1
2 q.A.q−(λ/4!)q4+J.q
(7)
with q4 ≡
i q4
i . Generalizing the steps leading to (3) we obtain
Z(J) =
(2π)N
det[A]
 1
2
e−(λ/4!) 
i(∂/∂Ji)4e
1
2 J.A−1.J
(8)
Alternatively, just as in (5) we can expand in powers of J
Z(J) =
∞

s=0
N

i1=1
. . .
N

is=1
1
s!Ji1 . . . Jis
 +∞
−∞

l
dql

e−1
2 q.A.q−(λ/4!)q4qi1 . . . qis
= Z(0, 0)
∞

s=0
N

i1=1
. . .
N

is=1
1
s!Ji1 . . . JisG(s)
i1...is
(9)
which again we can expand in powers of λ and evaluate by Wick contracting.
The one feature the child problem has that the baby problem doesn’t is propagation
“from here to there”. Recall the discussion of the propagator in chapter I.3. Just as in
(I.3.16) we can think of the index i as labeling the sites on a lattice. Indeed, in (I.3.16) we
had in effect evaluated the “2-point Green’s function” G(2)
ij to zeroth order in λ (differentiate
(I.3.16) with respect to J twice):
G(2)
ij (λ = 0) =
 +∞
−∞

l
dql

e−1
2 q.A.qqiqj

/Z(0, 0) = (A−1)ij
(see also the appendix to chapter I.2). The matrix element (A−1)ij describes propagation
from i to j. In the baby problem, each term in the expansion of Z(J) can be associated
with several diagrams but that is no longer true with propagation.

I.7. Feynman Diagrams | 49
Let us now evaluate the “4-point Green’s function” G(4)
ijkl to order λ :
G(4)
ijkl =
 +∞
−∞

m
dqm

e−1
2 q.A.qqiqjqkql

1 −λ
4!

n
q4
n + O(λ2)

/Z(0, 0)
= (A−1)ij(A−1)kl + (A−1)ik(A−1)jl + (A−1)il(A−1)jk
−λ

n
(A−1)in(A−1)jn(A−1)kn(A−1)ln + . . . + O(λ2)
(10)
The first three terms describe one excitation propagating from i to j and another propa-
gating from k to l, plus the two possible permutations on this “history.” The order λ term
tells us that four excitations, propagating from i to n, from j to n, from k to n, and from l
to n, meet at n and interact with an amplitude proportional to λ, where n is anywhere on
the lattice or mattress. By the way, you also see why it is convenient to define the interac-
tion (λ/4!)ϕ4 with a 1/4! : qi has a choice of four qn’s to contract with, qj has three qn’s to
contract with, and so on, producing a factor of 4! to cancel the (1/4!).
I intentionally did not display in (10) the O(λ) terms produced by Wick contracting some
of the qn’s with each other. There are two types: (I) Contracting a pair of qn’s produces
something like λ(A−1)ij(A−1)kn(A−1)ln(A−1)nn and (II) contracting the qn’s with each
other produces the first three terms in (10) multiplied by (A−1)nn(A−1)nn. We see that
(I) and (II) correspond to diagrams b and c in figure I.7.1, respectively. Evidently, the two
excitations do not interact with each other. I will come back to (II) later in this chapter.
Perturbative field theory
You should now be ready for field theory!
Indeed, the functional integral in (1) (which I repeat here)
Z(J) =

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]−(λ/4!)ϕ4+Jϕ}
(11)
has the same form as the ordinary integral in (2) and the multiple integral in (7). There
is one minor difference: there is no i in (2) and (7), but as I noted in chapter I.2 we can
Wick rotate (11) and get rid of the i, but we won’t. The significant difference is that J and
ϕ in (11) are functions of a continuous variable x, while J and q in (2) are not functions of
anything and in (7) are functions of a discrete variable. Aside from that, everything goes
through the same way.
As in (3) and (8) we have
Z(J) = e−(i/4!)λ 
d4w[δ/iδJ(w)]4 
Dϕei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]+Jϕ}
= Z(0, 0)e−(i/4!)λ 
d4w[δ/iδJ(w)]4e−(i/2) 
d4xd4yJ(x)D(x−y)J(y)
(12)
The structural similarity is total.
The role of 1/m2 in (3) and of A−1 (8) is now played by the propagator
D(x −y) =

d4k
(2π)4
eik.(x−y)
k2 −m2 + iε

50 | I. Motivation and Foundation
Incidentally, if you go back to chapter I.3 you will see that if we were in d-dimensional
spacetime, D(x −y) would be given by the same expression with d4k/(2π)4 replaced by
ddk/(2π)d. The ordinary integral (2) is like a field theory in 0-dimensional spacetime: if
we set d = 0, there is no propagating around and D(x −y) collapses to −1/m2. You see
that it all makes sense.
We also know that J(x) corresponds to sources and sinks. Thus, if we expand Z(J)
as a series in J , the powers of J would indicate the number of particles involved in the
process. (Note that in this nomenclature the scattering process ϕ + ϕ →ϕ + ϕ counts as a
4-particle process: we count the total number of incoming and outgoing particles.) Thus,
in particle physics it often makes sense to specify the power of J . Exactly as in the baby
and child problems, we can expand in J first:
Z(J) = Z(0, 0)
∞

s=0
is
s!

dx1 . . . dxsJ(x1) . . . J(xs)G(s)(x1, . . . , xs)
=
∞

s=0
is
s!

dx1 . . . dxsJ(x1) . . . J(xs)

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]−(λ/4!)ϕ4}
ϕ(x1) . . . ϕ(xs)
(13)
In particular, we have the 2-point Green’s function
G(x1, x2) ≡
1
Z(0, 0)

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]−(λ/4!)ϕ4}ϕ(x1)ϕ(x2)
(14)
the 4-point Green’s function,
G(x1, x2, x3, x4) ≡
1
Z(0, 0)

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]−(λ/4!)ϕ4}ϕ(x1)ϕ(x2)ϕ(x3)ϕ(x4)
(15)
and so on. [Sometimes Z(J) is called the generating functional as it generates the Green’s
functions.] Obviously, by translation invariance, G(x1, x2) does not depend on x1 and x2
separately, but only on x1 −x2. Similarly, G(x1, x2, x3, x4) only depends on x1 −x4, x2 −x4,
and x3 −x4. For λ = 0, G(x1, x2) reduces to iD(x1 −x2), the propagator introduced in
chapter I.3. While D(x1 −x2) describes the propagation of a particle between x1 and x2 in
the absence of interaction, G(x1 −x2) describes the propagation of a particle between x1
and x2 in the presence of interaction. If you understood our discussion of G(4)
ijkl, you would
know that G(x1, x2, x3, x4) describes the scattering of particles.
In some sense, there are two ways of doing field theory, what I might call the Schwinger
way (12) or the Wick way (13).
Thus, to summarize, Feynman diagrams are just an extremely convenient way of rep-
resenting the terms in a double series expansion of Z(J) in λ and J .
As I said in the preface, I have no intention of turning you into a whiz at calculating
Feynman diagrams. In any case, that can only come with practice. Instead, I tried to give
you as clear an account as I can muster of the concept behind this marvellous invention of

I.7. Feynman Diagrams | 51
3
4
1
2
x
t
Figure I.7.6
Feynman’s, which as Schwinger noted rather bitterly, enables almost anybody to become
a field theorist. For the moment, don’t worry too much about factors of 4! and 2!
Collision between particles
As I already mentioned, I described in chapter I.4 the strategy of setting up sources and
sinks to watch the propagation of a particle (which I will call a meson) associated with
the field ϕ. Let us now set up two sources and two sinks to watch two mesons scatter off
each other. The setup is shown in figure I.7.6. The sources localized in regions 1 and 2
both produce a meson, and the two mesons eventually disappear into the sinks localized
in regions 3 and 4. It clearly suffices to find in Z a term containing J(x1)J(x2)J(x3)J(x4).
But this is just G(x1, x2, x3, x4).
Let us be content with first order in λ. Going the Wick way we have to evaluate
1
Z(0, 0)

−iλ
4!
 
d4w

Dϕ ei 
d4x{ 1
2 [(∂ϕ)2−m2ϕ2]}
ϕ(x1)ϕ(x2)ϕ(x3)ϕ(x4)ϕ(w)4
(16)
Just as in (10) we Wick contract and obtain
(−iλ)

d4wD(x1 −w)D(x2 −w)D(x3 −w)D(x4 −w)
(17)
As a check, let us also derive this the Schwinger way. Replace e−(i/4!)λ

d4w(δ/δJ(w))4 by
−(i/4!)λ

d4w(δ/δJ(w))4 and e−(i/2) 
d4xd4yJ(x)D(x−y)J(y) by
i4
4!24
 
d4xd4yJ(x)D(x −y)J(y)
4

52 | I. Motivation and Foundation
x3
x4
x1
x2
k3
k4
k1
k2
(a)
(b)
w
Figure I.7.7
To save writing, it would be sagacious to introduce the abbreviations Ja for J(xa),

a for

d4xa, and Dab for D(xa −xb). Dropping overall numerical factors, which I invite you to
fill in, we obtain
∼iλ

w
( δ
δJw
)4
       
DaeDbf DcgDdhJaJbJcJdJeJf JgJh
(18)
The four (δ/δJw)’s hit the eight J’s in all possible combinations producing many terms,
which again I invite you to write out. Two of the three terms are disconnected. The
connected term is
∼iλ

w
   
DawDbwDcwDdwJaJbJcJd
(19)
Evidently, this comes from the four (δ/δJw)’s hitting Je, Jf , Jg, and Jh, thus setting
xe, xf , xg, and xh to w. Compare (19) with [8!(−λ)/(4!)3(2m2)4]J 4 in the baby problem.
Recall that we embarked on this calculation in order to produce two mesons by sources
localized in regions 1 and 2, watch them scatter off each other, and then get rid of them
with sinks localized in regions 3 and 4. In other words, we set the source function J(x)
equal to a set of delta functions peaked at x1, x2, x3, and x4. This can be immediately
read off from (19): the scattering amplitude is just −iλ

w D1wD2wD3wD4w, exactly as
in (17).
The result is very easy to understand (see figure I.7.7a). Two mesons propagate from
their birthplaces at x1 and x2 to the spacetime point w, with amplitude D(x1 −w)D(x2 −
w), scatter with amplitude −iλ, and then propagate from w to their graves at x3 and x4,
with amplitude D(w −x3)D(w −x4) [note that D(x) = D(−x)]. The integration over w
just says that the interaction point w could have been anywhere. Everything is as in the
child problem.
It is really pretty simple once you get it. Still confused? It might help if you think of (12)
as some kind of machine e−(i/4!)λ 
d4w[δ/iδJ(w)]4 operating on
Z(J , λ = 0) = e−(i/2)  
d4xd4yJ(x)D(x−y)J(y)
When expanded out, Z(J , λ = 0) is a bunch of J’s thrown here and there in spacetime,
with pairs of J’s connected by D’s. Think of a bunch of strings with the string ends

I.7. Feynman Diagrams | 53
x3
x4
x1
x2
(a)
y4
y3
y1
y2
x1
x2
x3
x4
w
x3
x4
x1
x2
y4
y3
y1
y2
x1
x2
x3
x4
w1
u2
z2
u1
z1
(b)
w2
Figure I.7.8
corresponding to the J’s. What does the “machine” do? The machine is a sum of terms,
for example, the term
∼λ2

d4w1

d4w2

δ
δJ(w1)
4 
δ
δJ(w2)
4
When this term operates on a term in Z(J , λ = 0) it grabs four string ends and glues them
together at the point w2; then it grabs another 4 string ends and glues them together at
the point w1. The locations w1 and w2 are then integrated over. Two examples are shown
in figure I.7.8. It is a game you can play with a child! This childish game of gluing four
string ends together generates all the Feynman diagrams of our scalar field theory.
Do it once and for all
Now Feynman comes along and says that it is ridiculous to go through this long-winded
yakkety-yak every time. Just figure out the rules once and for all.

54 | I. Motivation and Foundation
For example, for the diagram in figure I.7.7a associate the factor −iλ with the scattering,
the factor D(x1 −w) with the propagation from x1 to w, and so forth—conceptually exactly
the same as in our baby problem. See, you could have invented Feynman diagrams. (Well,
not quite. Maybe not, maybe yes.)
Just as in going from (I.4.1) to (I.4.2), it is easier to pass to momentum space. Indeed,
that is how experiments are actually done. A meson with momentum k1 and a meson with
momentum k2 collide and scatter, emerging with momenta k3 and k4 (see figure I.7.7b).
Each spacetime propagator gives us
D(xa −w) =

d4ka
(2π)4
e±ika(xa−w)
k2
a −m2 + iε
Note that we have the freedom of associating with the dummy integration variable either
a plus or a minus sign in the exponential. Thus in integrating over w in (17) we obtain

d4we−i(k1+k2−k3−k4)w = (2π)4δ(4)(k1 + k2 −k3 −k4).
That the interaction could occur anywhere in spacetime translates into momentum con-
servation k1 + k2 = k3 + k4. (We put in the appropriate minus signs in two of the D’s so
that we can think of k3 and k4 as outgoing momenta.)
So there are Feynman diagrams in real spacetime and in momentum space. Spacetime
Feynman diagrams are literally pictures of what happened. (A trivial remark: the orien-
tation of Feynman diagrams is a matter of idiosyncratic choice. Some people draw them
with time running vertically, others with time running horizontally. We follow Feynman
in this text.)
The rules
We have thus derived the celebrated momentum space Feynman rules for our scalar field
theory:
1. Draw a Feynman diagram of the process (fig. I.7.7b for the example we just discussed).
2. Label each line with a momentum k and associate with it the propagator i/(k2 −m2 + iε).
3. Associate with each interaction vertex the coupling −iλ and (2π)4 δ(4)(
i ki −
j kj),
forcing the sum of momenta 
i ki coming into the vertex to be equal to the sum of momenta

j kj going out of the vertex.
4. Momenta associated with internal lines are to be integrated over with the measure
d4k
(2π)4 .
Incidentally, this corresponds to the summation over intermediate states in ordinary per-
turbation theory.
5. Finally, there is a rule about some really pesky symmetry factors. They are the analogs of
those numerical factors in our baby problem. As a result, some diagrams are to be multiplied
by a symmetry factor such as 1
2. These originate from various combinatorial factors counting
the different ways in which the (δ/δJ)’s can hit the J’s in expressions such as (18). I will let
you discover a symmetry factor in exercise I.7.2.
We will illustrate by examples what these rules (and the concept of internal lines) mean.

I.7. Feynman Diagrams | 55
Our first example is just the diagram (fig. I.7.7b) that we have calculated. Applying the
rules we obtain
−iλ(2π)4δ(4)(k1 + k2 −k3 −k4)
4
	
a=1

i
k2
a −m2 + iε

You would agree that it is silly to drag the factor 4
a=1

i
k2a−m2+iε

around, since it would
be common to all diagrams in which two mesons scatter into two mesons. So we append
to the Feynman rules an additional rule that we do not associate a propagator with external
lines. (This is known in the trade as “amputating the external legs”.)
In an actual scattering experiment, the external particles are of course real and on shell,
that is, their momenta satisfy k2
a −m2 = 0. Thus we better not keep the propagators of the
external lines around. Arithmetically, this amounts to multiplying the Green’s functions
[and what we have calculated thus far are indeed Green’s functions, see (16)] by the factor
a(−i)(k2
a −m2) and then set k2
a = m2 (“putting the particles on shell” in conversation). At
this point, this procedure sounds like formal overkill. We will come back to the rationale
behind it at the end of the next chapter.
Also, since there is always an overall factor for momentum conservation we should not
drag the overall delta function around either. Thus, we have two more rules:
6. Do not associate a propagator with external lines.
7. A delta function for overall momentum conservation is understood.
Applying these rules we obtain an amplitude which we will denote by M. For example,
for the diagram in figure I.7.7b M = −iλ.
The birth of particles
As explained in chapter I.1 one of the motivations for constructing quantum field theory
was to describe the production of particles. We are now ready to describe how two col-
liding mesons can produce four mesons. The Feynman diagram in figure I.7.9 (compare
fig. I.7.3a) can occur in order λ2 in perturbation theory. Amputating the external legs, we
drop the factor 6
a=1[i/k2
a −m2 + iε] associated with the six external lines, keeping only
the propagator associated with the one internal line. For each vertex we put in a factor of
(−iλ) and a momentum conservation delta function (rule 3). Then we integrate over the
internal momentum q (rule 4) to obtain
(−iλ)2

d4q
(2π)4
i
q2 −m2 + iε (2π)4δ(4)(k1 + k2 −k3 −q)(2π)4δ(4)[q −(k4 + k5 + k6)]
(20)
The integral over q is a cinch, giving
(−iλ)2
i
(k4 + k5 + k6)2 −m2 + iε (2π)4δ(4)[k1 + k2 −(k3 + k4 + k5 + k6)]
(21)

56 | I. Motivation and Foundation
k3
k4
k1
k2
k5
k6
q
Figure I.7.9
We have already agreed (rule 7) not to drag the overall delta function around. This exam-
ple teaches us that we didn’t have to write down the delta functions and then annihilate (all
but one of) them by integrating. In figure I.7.9 we could have simply imposed momentum
conservation from the beginning and labeled the internal line as k4 + k5 + k6 instead of q.
With some practice you could just write down the amplitude
M = (−iλ)2
i
(k4 + k5 + k6)2 −m2 + iε
(22)
directly: just remember, a coupling (−iλ) for each vertex and a propagator for each internal
(but not external) line. Pretty easy once you get the hang of it. As Schwinger said, the masses
could do it.
The cost of not being real
The physics involved is also quite clear: The internal line is associated with a virtual particle
whose relativistic 4-momentum k4 + k5 + k6 squared is not necessarily equal to m2, as it
would have to be if the particle were real. The farther the momentum of the virtual particle
is from the mass shell the smaller the amplitude. You are penalized for not being real.
According to the quantum rules for dealing with identical particles, to obtain the full
amplitude we have to symmetrize among the four final momenta. One way of saying it is
to note that the line labeled k3 in figure (I.7.9) could have been labeled k4, k5, or k6, and
we have to add all four contributions.
To make sure that you understand the Feynman rules I insist that you go through the
path integral calculation to obtain (21) starting with (12) and (13).
I am repeating myself but I think it is worth emphasizing again that there is nothing
particularly magical about Feynman diagrams.

I.7. Feynman Diagrams | 57
k1
k2
k3
k4
k
k1 + k2 − k
Figure I.7.10
Loops and a first look at divergence
Just as in our baby problem, we have tree diagrams and loop diagrams. So far we have only
looked at tree diagrams. Our next example is the loop diagram in figure I.7.10 (compare
fig. I.7.2a.) Applying the Feynman rules, we obtain
1
2(−iλ)2

d4k
(2π)4
i
k2 −m2 + iε
i
(k1 + k2 −k)2 −m2 + iε
(23)
As above, the physics embodied in (23) is clear: As k ranges over all possible values, the
integrand is large only if one or the other or both of the virtual particles associated with
the two internal lines are close to being real. Once again, there is a penalty for not being
real (see exercise I.7.4).
For large k the integrand goes as 1/k4. The integral is infinite! It diverges as

d4k(1/k4).
We will come back to this apparent disaster in chapter III.1.
With some practice, you will be able to write down the amplitude by inspection. As
another example, consider the three-loop diagram in figure I.7.11 contributing in O(λ4) to
meson-meson scattering. First, for each loop pick an internal line and label the momentum
it carries, p, q, and r in our example. There is considerable freedom of choice in labeling—
your choice may well not agree with mine, but of course the physics should not depend
on it. The momenta carried by the other internal lines are then fixed by momentum
conservation, as indicated in the figure. Write down a coupling for each vertex, and a
propagator for each internal line, and integrate over the internal momenta p, q, and r.

58 | I. Motivation and Foundation
k1
k2
k3
k4
r
p
q
p − q − r
k1 + k2 − r
k1 + k2 − p
Figure I.7.11
Thus, without worrying about symmetry factors, we have the amplitude
(−iλ)4

d4p
(2π)4
d4q
(2π)4
d4r
(2π)4
i
p2 −m2 + iε
i
(k1 + k2 −p)2 −m2 + iε
i
q2 −m2 + iε
i
(p −q −r)2 −m2 + iε
i
r2 −m2 + iε
i
(k1 + k2 −r)2 −m2 + iε
(24)
Again, this triple integral also diverges: It goes as

d12P(1/P 12).
An assurance
When I teach quantum field theory, at this point in the course some students get un-
accountably very anxious about Feynman diagrams. I would like to assure the reader that
the whole business is really quite simple. Feynman diagrams can be thought of simply as
pictures in spacetime of the antics of particles, coming together, colliding and producing
other particles, and so on. One student was puzzled that the particles do not move in

I.7. Feynman Diagrams | 59
straight lines. Remember that a quantum particle propagates like a wave; D(x −y) gives
us the amplitude for the particle to propagate from x to y. Evidently, it is more convenient to
think of particles in momentum space: Fourier told us so. We will see many more examples
of Feynman diagrams, and you will soon be well acquainted with them. Another student
was concerned about evaluating the integrals in (23) and (24). I haven’t taught you how yet,
but will eventually. The good news is that in contemporary research on the frontline few
theoretical physicists actually have to calculate Feynman diagrams getting all the factors
of 2 right. In most cases, understanding the general behavior of the integral is sufficient.
But of course, you should always take pride in getting everything right. In chapters II.6,
III.6, and III.7 I will calculate Feynman diagrams for you in detail, getting all the factors
right so as to be able to compare with experiments.
Vacuum fluctuations
Let us go back to the terms I neglected in (18) and which you are supposed to have
figured out. For example, the four [δ/δJ(w)]’s could have hit Jc, Jd, Jg, and Jh in (18)
thus producing something like
−iλ
   
DaeDbf JaJbJeJf (

w
DwwDww).
The coefficient of J(x1)J(x2)J(x3)J(x4) is then D13D24(−iλ

w DwwDww) plus terms
obtained by permuting.
The corresponding physical process is easy to describe in words and in pictures (see
figure I.7.12). The source at x1 produces a particle that propagates freely without any
interaction to x3, where it comes to a peaceful death. The particle produced at x2 leads
a similarly uneventful life before being absorbed at x4. The two particles did not interact at
all. Somewhere off at the point w, which could perfectly well be anywhere in the universe,
there was an interaction with amplitude −iλ. This is known as a vacuum fluctuation:
t
x
w
x3
x4
x1
x2
Figure I.7.12

60 | I. Motivation and Foundation
As explained in chapter I.1, quantum mechanics and special relativity inevitably cause
particles to pop out of the vacuum, and they could even interact before vanishing again
into the vacuum. Look at different time slices (one of which is indicated by the dotted line)
in figure I.7.12. In the far past, the universe has no particles. Then it has two particles,
then four, then two again, and finally in the far future, none. We will have a lot more to
say in chapter VIII.2 about these fluctuations. Note that vacuum fluctuations occur also in
our baby and child problems (see, e.g., Figs. I.7.1c, I.7.2g,h,i,j, and so forth).
Two words about history
I believe strongly that any self-respecting physicist should learn about the history of phys-
ics, and the history of quantum field theory is among the most fascinating. Unfortunately,
I do not have the space to go into it here.4 The path integral approach to field theory using
sources J(x) outlined here is mainly associated with Julian Schwinger, who referred to it
as “sorcery” during my graduate student days (so that I could tell people who inquired that
I was studying sorcery in graduate school.) In one of the many myths retold around tribal
fires by physicists, Richard Feynman came upon his rules in a blinding flash of insight.
In 1949 Freeman Dyson showed that the Feynman rules which so mystified people at the
Pocono conference a year earlier could actually be obtained from the more formal work of
Julian Schwinger and of Shin-Itiro Tomonaga.
Exercises
I.7.1
Work out the amplitude corresponding to figure I.7.11 in (24).
I.7.2
Derive (23) from first principles, that is from (11). It is a bit tedious, but straightforward. You should find
a symmetry factor 1
2.
I.7.3
Draw all the diagrams describing two mesons producing four mesons up to and including order λ2.
Write down the corresponding Feynman amplitudes.
I.7.4
By Lorentz invariance we can always take k1 + k2 = (E, ⃗0) in (23). The integral can be studied as a function
of E. Show that for both internal particles to become real E must be greater than 2m. Interpret physically
what is happening.
4 An excellent sketch of the history of quantum field theory is given in chapter 1 of The Quantum Theory of
Fields by S. Weinberg. For a fascinating history of Feynman diagrams, see Drawing Theories Apart by D. Kaiser.

I.8
Quantizing Canonically
Quantum electrodynamics is made to appear more difficult
than it actually is by the very many equivalent methods by
which it may be formulated.
—R. P. Feynman
Always create before we annihilate, not the other way
around.
—Anonymous
Complementary formalisms
I adopted the path integral formalism as the quickest way to quantum field theory. But I
must also discuss the canonical formalism, not only because historically it was the method
used to develop quantum field theory, but also because of its continuing importance.
Interestingly, the canonical and the path integral formalisms often appear complementary,
in the sense that results difficult to see in one are clear in the other.
Heisenberg and Dirac
Let us begin with a lightning review of Heisenberg’s approach to quantum mechanics.
Given a classical Lagrangian for a single particle L = 1
2 ˙q2 −V (q) (we set the mass equal to
1), the canonical momentum is defined as p ≡δL/δ ˙q = ˙q. The Hamiltonian is then given
by H = p ˙q −L = p2/2 + V (q). Heisenberg promoted position q(t) and momentum p(t)
to operators by imposing the canonical commutation relation
[p, q] = −i
(1)
Operators evolve in time according to
dp
dt = i[H , p] = −V ′(q)
(2)

62 | I. Motivation and Foundation
and
dq
dt = i[H , q] = p
(3)
In other words, operators constructed out of p and q evolve according to O(t) =
eiHtO(0)e−iHt. In (1) p and q are understood to be taken at the same time. We obtain
the operator equation of motion ¨q = −V ′(q) by combining (2) and (3).
Following Dirac, we invite ourselves to consider at some instant in time the operator
a ≡(1/
√
2ω)(ωq + ip) with some parameter ω. From (1) we have
[a, a
†] = 1
(4)
The operator a(t) evolves according to
da
dt = i[H ,
1
√
2ω
(ωq + ip)] = −i
ω
2

ip + 1
ω V ′(q)

which can be written in terms of a and a
†. The ground state |0⟩is defined as the state such
that a |0⟩= 0.
In the special case V ′(q) = ω2q we get the particularly simple result da
dt = −iωa. This is
of course the harmonic oscillator L = 1
2 ˙q2 −1
2ω2q2 and H = 1
2(p2 + ω2q2) = ω(a†a + 1
2).
The generalization to many particles is immediate. Starting with
L =

a
1
2 ˙qa
2 −V (q1, q2, . . . , qN)
we have pa = δL/δ ˙qa and
[pa(t), qb(t)] = −iδab
(5)
The generalization to field theory is almost as immediate. In fact, we just use our handy-
dandy substitution table (I.3.6) and see that in D−dimensional space L generalizes to
L =

dDx{ 1
2( ˙ϕ2−( ⃗∇ϕ)2 −m2ϕ2) −u(ϕ)}
(6)
where we denote the anharmonic term (the interaction term in quantum field theory) by
u(ϕ). The canonical momentum density conjugate to the field ϕ(⃗x, t) is then
π(⃗x, t) =
δL
δ ˙ϕ(⃗x, t) = ∂0ϕ(⃗x, t)
(7)
so that the canonical commutation relation at equal times now reads [using (I.3.6)]
[π(⃗x, t), ϕ(⃗x′, t)] = [∂0ϕ(⃗x, t), ϕ(⃗x′, t)] = −iδ(D)(⃗x −⃗x′)
(8)
(and of course also [π(⃗x, t), π(⃗x′, t)] = 0 and [ϕ(⃗x, t), ϕ(⃗x′, t)] = 0.) Note that δab in (5)
gets promoted to δ(D)(⃗x −⃗x′) in (8). You should check that (8) has the correct dimension.
Turning the canonical crank we find the Hamiltonian
H =

dDx[π(⃗x, t)∂0ϕ(⃗x, t) −L]
=

dDx{ 1
2[π2 + ( ⃗∇ϕ)2 + m2ϕ2] + u(ϕ)}
(9)

I.8. Quantizing Canonically | 63
For the case u = 0, corresponding to the harmonic oscillator, we have a free scalar field
theory and can go considerably farther. The field equation reads
(∂2 + m2)ϕ = 0
(10)
Fourier expanding, we have
ϕ(⃗x, t) =

dDk

(2π)D2ωk
[a(⃗k)e−i(ωkt−⃗k.⃗x) + a†(⃗k)ei(ωkt−⃗k.⃗x)]
(11)
with ωk = +

⃗k2 + m2 so that the field equation (10) is satisfied. The peculiar looking factor
(2ωk)−1
2 is chosen so that the canonical relation
[a(⃗k), a
†(⃗k′)] = δ(D)(⃗k −⃗k′)
(12)
appropriate for creation and annihilation operators implies the canonical commutation
[∂0ϕ(⃗x, t), ϕ(⃗x′, t)] = −iδ(D)(⃗x −⃗x′) in (8 ). You should check this but you can see why the
factor (2ωk)−1
2 is needed since in ∂0ϕ a factor ωk is brought down from the exponential.
As in quantum mechanics, the vacuum or ground state ||0⟩is defined by the condition
a(⃗k)|0⟩= 0 for all ⃗k and the single particle state by |⃗k⟩≡a
†(⃗k)|0⟩. Thus, for example,
using (12) we have ⟨0|ϕ(⃗x, t)|⃗k⟩= (1/

(2π)D2ωk)e−i(ωkt−⃗k.⃗x), which we could think of
as the relativistic wave function of a single particle with momentum ⃗k. For later use, we
will write this more compactly as (1/ρ(k))e−ik.x, with ρ(k) ≡

(2π)D2ωk a normalization
factor and k0 = ωk.
To make contact with the path integral formalism let us calculate ⟨0|ϕ(⃗x, t)ϕ(⃗0, 0)|0⟩
for t > 0. Of the four terms a
†a
†, a
†a, aa
†, and aa in the product of the two fields
only aa
† survives, and thus using (12) we obtain

[dDk/(2π)D2ωk]e−i(ωkt−⃗k.⃗x). In other
words, if we define the time-ordered product T [ϕ(x)ϕ(y)] = θ(x0 −y0)ϕ(x)ϕ(y) + θ(y0 −
x0)ϕ(y)ϕ(x), we find
⟨0|T [ϕ(⃗x, t)ϕ(⃗0, 0)]|0⟩=

dDk
(2π)D2ωk
[θ(t)e−i(ωkt−⃗k.⃗x) + θ(−t)e+i(ωkt−⃗k.⃗x)]
(13)
Go back to (I.3.23). We discover that ⟨0|T [ϕ(x)ϕ(0)]|0⟩= iD(x), the propagator for a
particle to go from 0 to x we obtained using the path integral formalism. This further
justifies the iε prescription in (I.3.22). The physical meaning is that we always create
before we annihilate, not the other way around. This is a form of causality as formulated
in quantum field theory.
A remark: The combination dDk/(2ωk), even though it does not look Lorentz invariant,
is in fact a Lorentz invariant measure. To see this, we use (I.2.13) to show that (exercise I.8.1)

d(D+1)kδ(k2 −m2)θ(k0)f (k0, ⃗k) =

dDk
2ωk
f (ωk, ⃗k)
(14)
for any function f (k). Since Lorentz transformations cannot change the sign of k0, the step
function θ(k0) is Lorentz invariant. Thus the left-hand side is manifestly Lorentz invariant,
and hence the right-hand side must also be Lorentz invariant. This shows that relations
such as (13) are Lorentz invariant; they are frame-independent statements.

64 | I. Motivation and Foundation
Scattering amplitude
Now that we have set up the canonical formalism it is instructive to see how the invariant
amplitude Mdefined in the preceding chapter arises using this alternative formalism. Let
us calculate the amplitude ⟨⃗k3⃗k4|e−iHT |⃗k1⃗k2⟩= ⟨⃗k3⃗k4|ei 
d4xL(x) |⃗k1⃗k2⟩for meson scatter-
ing ⃗k1 + ⃗k2 →⃗k3 + ⃗k4 in order λ with u(ϕ) = λ
4!ϕ4. (We have, somewhat sloppily, turned
the large transition time T into

dx0 when going over to the Lagrangian.) Expanding in
λ, we obtain (−i λ
4!)

d4x⟨⃗k3⃗k4|ϕ4(x)|⃗k1⃗k2⟩.
The calculation of the matrix element is not dissimilar to the one we just did for the
propagator. There we have the product of two field operators between the vacuum state.
Here we have the product of four field operators, all evaluated at the same spacetime point
x, sandwiched between two-particle states. There we look for a term of the form a(⃗k)a†(⃗k),
Here, plugging the expansion (11) of the field into the product ϕ4(x), we look for terms of
the form a†(⃗k4)a†(⃗k3)a(⃗k2)a(⃗k1), so that we could remove the two incoming particles and
produce the two outgoing particles. (To avoid unnecessary complications we assume that
all four momenta are different.) We now annihilate and create. The annihilation operator
a(⃗k1) could have come from any one of the four ϕ fields in ϕ4, giving a factor of 4, a(⃗k1)
could have come from any one of the three remaining ϕ fields, giving a factor of 3, a†(⃗k3)
could have come from either of the two remaining ϕ fields, giving a factor of 2, so that we
end up with a factor of 4!, which cancels the factor of 1
4! included in the definition of λ.
(This is of course why, for the sake of convenience, λ is defined the way it is. Recall from
the preceding chapter an analogous step.)
As you just learned and as you can see from (11), we obtain a factor of 1/ρ(k)e−ik.x for
each incoming particle and of 1/ρ(k)e+ik.x for each outgoing particle, giving all together

4
α=1
1
ρ(kα)
 
d4xei(k3+k4−k1−k2).x =

4
α=1
1
ρ(kα)

(2π)4δ4(k3 + k4 −k1 −k2)
It is conventional to refer to Sf i = ⟨f |e−iHT |i⟩, with some initial and final state, as
elements of an “S-matrix” and to define the “transition matrix” T -matrix by S = I + iT ,
that is,
Sf i = δf i + iTf i
(15)
In general, for initial and final states consisting of scalar particles characterized only by
their momenta, we write (using an obvious notation, for example 
i k is the sum of the
particle momenta in the initial state), invoking momentum conservation:
iTf i = (2π)4δ4
⎛
⎝
f
k −

i
k
⎞
⎠

α
1
ρ(kα)

M(f ←i)
(16)
In our simple example, iT (⃗k3⃗k4, ⃗k1⃗k2) = (−i λ
4!)

d4x⟨⃗k3⃗k4|ϕ4(x)|⃗k1⃗k2⟩, and our little cal-
culation showed that M = −iλ, precisely as given in the preceding chapter. But this con-
nection between Tf i and M, being “merely” kinematical, should hold in general, with the
invariant amplitude Mdetermined by the Feynman rules. I will not give a long boring for-

I.8. Quantizing Canonically | 65
mal proof, but you should check this assertion by working out some more involved cases,
such as the scattering amplitude to order λ2, recovering (I.7.23), for example.
Thus, quite pleasingly, we see that the invariant amplitude M determined by the
Feynman rules represents the “heart of the matter” with the momentum conservation
delta function and normalization factors stripped away.
My pedagogical aim here is merely to make one more contact (we will come across
more in later chapters) between the canonical and path integral formalisms, giving
the simplest possible example avoiding all subtleties and complications. Those readers
into rigor are invited to replace the plane wave states |⃗k1⃗k2⟩with wave packet states

d3k1

d3k2f1(⃗k1)f2(⃗k2)|⃗k1⃗k2⟩for some appropriate functions f1 and f2, starting in the
far past when the wave packets were far apart, evolving into the far future, so on and so
forth, all the while smiling with self-satisfaction. The entire procedure is after all no differ-
ent from the treatment of scattering1 in elementary nonrelativistic quantum mechanics.
Complex scalar field
Thus far, we have discussed a hermitean (often called real in a minor abuse of terminology)
scalar field. Consider instead (as we will in chapter I.10) a nonhermitean (usually called
complex in another minor abuse) scalar field governed by L = ∂ϕ
†∂ϕ −m2ϕ
†ϕ.
Again, following Heisenberg, we find the canonical momentum density conjugate to
the field ϕ(⃗x, t), namely π(⃗x, t) = δL/[δ ˙ϕ(⃗x, t)] = ∂0ϕ†(⃗x, t), so that [π(⃗x, t), ϕ(⃗x′, t)] =
[∂0ϕ†(⃗x, t), ϕ(⃗x′, t)] = −iδ(D)(⃗x −⃗x′). Similarly, the canonical momentum density conju-
gate to the field ϕ†(⃗x, t) is ∂0ϕ(⃗x, t).
Varying ϕ† we obtain the Euler-Lagrange equation of motion (∂2 + m2)ϕ = 0. [Similarly,
varying ϕ we obtain (∂2 + m2)ϕ† = 0.] Once again, we could Fourier expand, but now the
nonhermiticity of ϕ means that we have to replace (11) by
ϕ(⃗x, t) =

dDk

(2π)D2ωk

a(⃗k)e−i(ωkt−⃗k.⃗x) + b†(⃗k)ei(ωkt−⃗k.⃗x))
(17)
In (11) hermiticity fixed the second term in the square bracket in terms of the first. Here
in contrast, we are forced to introduce two independent sets of creation and annihilation
operators (a, a
†) and (b, b
†). You should verify that the canonical commutation relations
imply that these indeed behave like creation and annihilation operators.
Consider the current
Jμ = i(ϕ
†∂μϕ −∂μϕ
†ϕ)
(18)
Using the equations of motion you should check that ∂μJ μ = i(ϕ
†∂2ϕ −∂2ϕ
†ϕ). (This
follows immediately from the fact that the equation of motion for ϕ† is the hermitean
1 For example, M. L. Goldberger and K. M. Watson, Collision Theory.

66 | I. Motivation and Foundation
conjugate of the equation of motion for ϕ.) The current is conserved and the corresponding
time-independent charge is given by (verify this!)
Q =

dDxJ0(x) =

dDk[a†(⃗k)a(⃗k) −b†(⃗k)b(⃗k)].
Thus the particle created by a† (call it the “particle”) and the particle created by b† (call it
the “antiparticle”) carry opposite charges. Explicitly, using the commutation relation we
have Qa†|0⟩= +a†|0⟩and Qb†|0⟩= −b†|0⟩.
We conclude that ϕ
†creates a particle and annihilates an antiparticle, that is, it produces
one unit of charge. The field ϕ does the opposite. You should understand this point
thoroughly, as we will need it when we come to the Dirac field for the electron and positron.
The energy of the vacuum
As an instructive exercise let us calculate in the free scalar field theory the expectation
value ⟨0|H |0⟩=

dDx 1
2⟨0|(π2 + ( ⃗∇ϕ)2 + m2ϕ2)|0⟩, which we may loosely refer to as the
“energy of the vacuum.” It is merely a matter of putting together (7), (11), and (12). Let us
focus on the third term in ⟨0|H |0⟩, which in fact we already computed, since
⟨0|ϕ(⃗x, t)ϕ(⃗x, t)|0⟩= ⟨0|ϕ(⃗0, 0)ϕ(⃗0, 0)|0⟩
=
lim
⃗x,t→⃗0,0
⟨0|ϕ(⃗x, t)ϕ(⃗0, 0)|0⟩=
lim
⃗x,t→⃗0,0

dDk
(2π)D2ωk
e−i(ωkt−⃗k.⃗x) =

dDk
(2π)D2ωk
The first equality follows from translation invariance, which also implies that the factor

dDx in ⟨0|H |0⟩can be immediately replaced by V , the volume of space. The calculation
of the other two terms proceeds in much the same way: for example, the two factors of ⃗∇
in ( ⃗∇ϕ)2 just bring down a factor of ⃗k2. Thus
⟨0|H |0⟩= V

dDk
(2π)D2ωk
1
2(ω2
k + ⃗k2 + m2) = V

dDk
(2π)D
1
2ℏωk
(19)
upon restoring ℏ.
You should find this result at once gratifying and alarming, gratifying because we recog-
nize it as the zero point energy of the harmonic oscillator integrated over all momentum
modes and over all space, and alarming because the integral over ⃗k clearly diverges. But we
should not be alarmed: the energy of any physical configuration, for example the mass of a
particle, is to be measured relative to the “energy of the vacuum.” We ask for the difference
in the energy of the world with and without the particle. In other words, we could simply
define the correct Hamiltonian to be H −⟨0|H |0⟩. We will come back to some of these
issues in chapters II.5, III.1, and VIII.2.
Nobody is perfect
In the canonical formalism, time is treated differently from space, and so one might worry
about the Lorentz invariance of the resulting field theory. In the standard treatment given

I.8. Quantizing Canonically | 67
in many texts, we would go on from this point and use the Hamiltonian to generate the
dynamics, developing a perturbation theory in the interaction u(ϕ). After a number of
formal steps, we would manage to derive the Feynman rules, which manifestly define a
Lorentz-invariant theory.
Historically, there was a time when people felt that quantum field theory should be
defined by its collection of Feynman rules, which gives us a concrete procedure to calculate
measurable quantities, such as scattering cross sections. An extreme view along this line
held that fields are merely mathematically crutches used to help us arrive at the Feynman
rules and should be thrown away at the end of the day.
This view became untenable starting in the 1970s, when it was realized that there
is a lot more to quantum field theory than Feynman diagrams. Field theory contains
nonperturbative effects invisible by definition to Feynman diagrams. Many of these effects,
which we will get to in due time, are more easily seen using the path integral formalism.
As I said, the canonical and the path integral formalism often appear to be complemen-
tary, and I will refrain from entering into a discussion about which formalism is superior.
In this book, I adopt a pragmatic attitude and use whatever formalism happens to be easier
for the problem at hand.
Let me mention, however, some particularly troublesome features in each of the two
formalisms. In the canonical formalism fields are quantum operators containing an in-
finite number of degrees of freedom, and sages once debated such delicate questions as
how products of fields are to be defined. On the other hand, in the path integral formal-
ism, plenty of sins can be swept under the rug known as the integration measure (see
chapter IV.7).
Appendix 1
It may seem a bit puzzling that in the canonical formalism the propagator has to be defined with time ordering,
which we did not need in the path integral formalism. To resolve this apparent puzzle, it suffices to look at
quantum mechanics.
Let A[q(t1)] be a function of q, evaluated at time t1. What does the path integral

Dq(t) A[q(t1)]ei  T
0 dtL(˙q,q)
represent in the operator language? Well, working backward to (I.2.4) we see that we would slip A[q(t1)] into the
factor ⟨qj+1|e−iHδt |qj⟩, where the integer j is determined by the condition that the time t1 occurs between the
times jδt and (j + 1)δt. In the resulting factor ⟨qj+1|e−iHδtA[q(t1)]|qj⟩, we could replace the c-number A[q(t1)]
by the operator A[ˆq], since A[ˆq]|qj⟩= A[qj]|qj⟩≃A[q(t1)]|qj⟩to the accuracy we are working with. Note that ˆq is
evidently a Schr¨odinger operator. Thus, putting in this factor ⟨qj+1|e−iHδtA[ˆq]|qj⟩together with all the factors of
⟨qi+1|e−iHδt |qi⟩, we find that the integral in question, namely

Dq(t) A[q(t1)]ei  T
0 dtL(˙q,q), actually represents
⟨qF|e−iH(T −t1)A[ˆq]e−iHt1 |qI⟩= ⟨qF|e−iHT A[ˆq(t1)]|qI⟩
where ˆq(t1) is now evidently a Heisenberg operator. [We have used the standard relation between Heisenberg
and Schr¨odinger operators, namely, OH(t) = eiHtOSe−iHt.] I find this passage back and forth between the Dirac,
Schr¨odinger, and Heisenberg pictures quite instructive, perhaps even amusing.
We
are
now
prepared
to
ask
the
more
complicated
question:
what
does
the
path
integral

Dq(t) A[q(t1)]B[q(t2)]ei  T
0 dtL(˙q,q) represent in the operator language? Here B[q(t2)] is some other function of
q evaluated at time t2. So we also slip B[q(t2)] into the appropriate factor in (I.2.4) and replace B[q(t2)] by B[ ˆq].
But now we see that we have to keep track of whether t1 or t2 is the earlier of the two times. If t2 is earlier, the
operator A[ˆq] would appear to the left of the operator B[ ˆq], and if t1 is earlier, to the right. Explicitly, if t2 is earlier

68 | I. Motivation and Foundation
than t1,we would end up with the sequence
e−iH(T −t1)A[ˆq]e−iH(t1−t2)B[ˆq]e−iHt2 = e−iHT A[ˆq(t1)]B[ˆq(t2)]
(20)
upon passing from the Schr¨odinger to the Heisenberg picture, just as in the simpler situation above. Thus we
define the time-ordered product
T [A[ˆq(t1)]B[ˆq(t2)]] ≡θ(t1 −t2)A[ˆq(t1)]B[ˆq(t2)] + θ(t2 −t1)B[ˆq(t2)]A[ˆq(t1)]
(21)
We just learned that
⟨qF|e−iHT T [A[ˆq(t1)]B[ˆq(t2)]]|qI⟩=

Dq(t) A[q(t1)]B[q(t2)]ei  T
0 dtL(˙q,q)
(22)
The concept of time ordering does not appear on the right-hand side, but is essential on the left-hand side.
Generalizing the discussion here, we see that the Green’s functions G(n)(x1, x2, . . . , xn) introduced in the
preceding chapter [see (I.7.13–15)] is given in the canonical formalism by the vacuum expectation value of a time-
ordered product of field operators ⟨0|T {ϕ(x1)ϕ(x2) . . . ϕ(xn)}|0⟩. That (13) gives the propagator is a special case
of this relationship.
We could also consider ⟨0|T {O1(x1)O2(x2) . . . On(xn)}|0⟩, the vacuum expectation value of a time-ordered
product of various operators Oi(x) [the current Jμ(x), for example] made out of the quantum field. Such objects
will appear in later chapters [for example, (VII.3.7)].
Appendix 2: Field redefinition
This is perhaps a good place to reveal to the innocent reader that there does not exist an international commission
in Brussels mandating what field one is required to use. If we use ϕ, some other guy is perfectly entitled to use
η, assuming that the two fields are related by some invertible function with η = f (ϕ). (To be specific, it is often
helpful to think of η = ϕ + αϕ3 with some parameter α.) This is known as a field redefinition, an often useful
thing to do, as we will see repeatedly.
The S-matrix amplitudes that experimentalists measure are invariant under field redefinition. But this is
tautological trivia: the scattering amplitude ⟨⃗k3⃗k4|e−iHT |⃗k1⃗k2⟩, for example, does not even know about ϕ and η.
The issue is with the formalism we use to calculate the S-matrix.
In the path integral formalism, it is also trivial that we could write Z(J) =

Dη ei[S(η)+
d4xJη] just as well
as Z(J) =

Dϕ ei[S(ϕ)+
d4xJϕ]. This result, a mere change of integration variable, was known to Newton and
Leibniz. But suppose we write ˜Z(J) =

Dϕ ei[S(ϕ)+
d4xJη]. Now of course any dolt could see that ˜Z(J) ̸= Z(J),
and a fortiori, the Green’s functions (I.7.14,15) obtained by differentiating ˜Z(J) and Z(J) are not equal.
The nontrivial physical statement is that the S-matrix amplitudes obtained from ˜Z(J) and Z(J) are in fact
the same. This better be the case, since we are claiming that the path integral formalism provides a way to actual
physics. To see how this apparent “miracle" (Green’s functions completely different, S-matrix amplitudes the
same) occurs, let us think physically. We set up our sources to produce or remove one single field disturbance,
as indicated in figure I.4.1. Our friend, who uses ˜Z(J), in contrast, set up his sources to produce or remove
η = ϕ + αϕ3 (we specialize for pedagogical clarity), so that once in a while (with a probability determined by α)
he is producing three field disturbances instead of one, as shown in figure I.8.1. As a result, while he thinks
that he is scattering four mesons, occasionally he is actually scattering six mesons. (Perhaps he should give his
accelerator a tune up.)
But to obtain S-matrix amplitudes we are told to multiply the Green’s functions by (k2 −m2) for each external
leg carrying momentum k, and then set k2 to m2. When we do this, the diagram in figure I.8.1a survives, since
it has a pole that goes like 1/(k2 −m2) but the extraneous diagram in figure I.8.1b is eliminated. Very simple.
One point worth emphasizing is that m here is the actual physical mass of the particle. Let’s be precise when we
should. Take the single particle state |⃗k⟩. Act on it with the Hamiltonian. Then H |⃗k⟩=

⃗k2 + m2 |⃗k⟩. The m that
appears in the eigenvalue of the Hamiltonian is the actual physical mass. We will come back to the issue of the
physical mass in chapter III.3.
In the canonical formalism, the field is an operator, and as we saw just now, the calculation of S-matrix
amplitudes involves evaluating products of field operators between physical states. In particular, the matrix
elements ⟨⃗k|ϕ |0⟩and ⟨0|ϕ |⃗k⟩(related by hermitean conjugation) come in crucially. If we use some other field η,

I.8. Quantizing Canonically | 69




(a)
(b)
J
J
Figure I.8.1
what matters is merely that ⟨⃗k|η |0⟩is not zero, in which case we could always write ⟨⃗k|η |0⟩= Z
1
2 ⟨⃗k|ϕ |0⟩with
Z some c-number. We simply divide the scattering amplitude by the appropriate powers of Z
1
2 .
Exercises
I.8.1
Derive (14). Then verify explicitly that dDk/(2ωk) is indeed Lorentz invariant. Some authors prefer to
replace

2ωk in (11) by 2ωk when relating the scalar field to the creation and annihilation operators.
Show that the operators defined by these authors are Lorentz covariant. Work out their commutation
relation.
I.8.2
Calculate ⟨⃗k′|H |⃗k⟩, where |⃗k⟩= a†(⃗k)|0⟩.
I.8.3
For the complex scalar field discussed in the text calculate ⟨0|T [ϕ(x)ϕ
†(0)]|0⟩.
I.8.4
Show that [Q, ϕ(x)] = −ϕ(x).

I.9
Disturbing the Vacuum
Casimir effect
In the preceding chapter, we computed the energy of the vacuum ⟨0|H |0⟩and obtained
the gratifying result that it is given by the zero point energy of the harmonic oscillator
integrated over all momentum modes and over space. I explained that the energy of any
physical configuration, for example, the mass of a particle, is to be measured relative to
this vacuum energy. In effect, we simply subtract off this vacuum energy and define the
correct Hamiltonian to be H −⟨0|H |0⟩.
But what if we disturb the vacuum?
Physically, we could compare the energy of the vacuum before and after we introduce
the disturbance, by varying the disturbance for example. Of course, it is not just our
textbook scalar field that contributes to the energy of the vacuum. The electromagnetic
field, for instance, also undergoes quantum fluctuation and would contribute, with its
two polarization degrees of freedom, to the energy density ε of the vacuum the amount
2

d3k/(2π)3 1
2ℏωk. In 1948 Casimir had the brilliant insight that we could disturb the
vacuum and produce a shift ε. While ε is not observable, ε should be observable since
we can control how we disturb the vacuum. In particular, Casimir considered introducing
two parallel “perfectly” conducting plates (formally of zero thickness and infinite extent)
into the vacuum. The variation of ε with the distance d between the plates would lead to
a force between the plates, known as the Casimir force. In reality, it is the electromagnetic
field that is responsible, not our silly scalar field.
Call the direction perpendicular to the plates the x axis. Because of the boundary
conditions the electromagnetic field must satisfy on the conducting plates, the wave vector
⃗k can only take on the values (πn/d, ky, kz), with n an integer. Thus the energy per unit
area between the plates is changed to 
n

dkydkz/(2π)2
(πn/d)2 + k2
y + k2
z.
To calculate the force, we vary d, but then we would have to worry about how the energy
density outside the two plates varies. A clever trick exists for avoiding this worry: we
introduce three plates! See figure (I.9.1). We hold the two outer plates fixed and move

I.9. Disturbing the Vacuum | 71
L
d
L− d
Figure I.9.1
only the inner plate. Now we don’t have to worry about the world outside the plates. The
separation L between the two outer plates can be taken to be as large as we like.
In the spirit of this book (and my philosophy) of avoiding computational tedium as
much as possible, I propose two simplifications: (I) do the calculation for a massless scalar
field instead of the electromagnetic field so we won’t have to worry about polarization
and stuff like that, and (II) retreat to a (1 + 1)-dimensional spacetime so we won’t have
to integrate over ky and kz. Readers of quantum field theory texts do not need to watch
their authors show off their prowess in doing integrals. As you will see, the calculation is
exceedingly instructive and gives us an early taste of the art of extracting finite physical
results from seemingly infinite expressions, known as regularization, that we will study
in chapters III.1–3.
With this set-up, the energy E = f (d) + f (L −d) with
f (d) = 1
2
∞

n=1
ωn = π
2d
∞

n=1
n
(1)
since the modes are given by sin(nπx/d) (n = 1, . . . , ∞) with the corresponding energy
ωn = nπ/d.
Aagh! What do we do with
∞

n=1
n ? None of the ancient Greeks from Zeno on could tell us.
What they should tell us is that we are doing physics, not mathematics! Physical plates
cannot keep arbitrarily high frequency waves from leaking out.1
To incorporate this piece of all-important physics, we should introduce a factor e−aωn/π
with a parameter a having the dimension of time (or in our natural units, length) so
that modes with ωn ≫π/a do not contribute: they don’t see the plates! The characteristic
1 See footnote 1 in chapter III.1.

72 | I. Motivation and Foundation
frequency π/a parametrizes the high frequency response of the conducting plates. Thus
we have
f (d) = π
2d
∞

n=1
ne−an/d = −π
2
∂
∂a
∞

n=1
e−an/d = −π
2
∂
∂a
1
1 −e−a/d = π
2d
ea/d
(ea/d −1)2
Since we want a−1 to be large, we take the limit a small so that
f (d) = πd
2a2 −
π
24d + πa2
480d3 + O(a4/d5).
(2)
Note that f (d) blows up as a →0, as it should, since we are then back to (1). But the force
between two conducting plates shouldn’t blow up. Experimentalists might have noticed it
by now!
Well, the force is given by
F = −∂E
∂d = −{f ′(d) −f ′(L −d)} = −

1
2πa2 +
π
24d2 + . . .

−(d →L −d)

−→
a→0 −π
24
 1
d2 −
1
(L −d)2

−→
L≫d −πℏc
24d2
(3)
Behold, the parameter a we have introduced to make sense of the divergent sum in (1) has
disappeared in our final result for the physically measurable force. In the last step, using
dimensional analysis we restored ℏto underline the quantum nature of the force.
The Casimir force between two plates is attractive. Notice that the 1/d2 of the force
simply follows from dimensional analysis since in natural units force has dimension of
an inverse length squared. In a tour de force, experimentalists have measured this tiny
force. The fluctuating quantum field is quite real!
To obtain a sensible result we need to regularize in the ultraviolet (namely the high
frequency or short time behavior parametrized by a) and in the infrared (namely the long
distance cutoff represented by L). Notice how a and L “work” together in (3).
This calculation foreshadows the renormalization of quantum field theories, a topic
made mysterious and almost incomprehensible in many older texts. In fact, it is perfectly
sensible. We will discuss renormalization in detail in chapters III.1 and III.2, but for now
let us review what we just did.
Instead of panicking when faced with the divergent sum in (1), we remind ourselves
that we are proud physicists and that physics tells us that the sum should not go all the
way to infinity. In a conducting plate, electrons rush about to counteract any applied tan-
gential electric field. But when the incident wave oscillates at sufficiently high frequency,
the electrons can’t keep up. Thus the idealization of a perfectly conducting plate fails. We
regularize (such an ugly term but that’s what field theorists use!) the sum in a mathemati-
cally convenient way by introducing a damping factor. The single parameter a is supposed
to summarize the unknown high frequency physics that causes the electron to fail to keep
up. In reality, a−1 is related to the plasma frequency of the metal making up the plate.

I.9. Disturbing the Vacuum | 73
A priori, the Casimir force between the two plates could end up depending on the
parameter a. In that case, the Casimir force would tell us something about the response of a
conducting plate to high frequency electric fields, and it would have made for an interesting
chapter in a text on solid state physics. Since this is in fact a quantum field theory text, you
might have suspected that the Casimir force represents some fundamental physics about
fluctuating quantum fields and that a would drop out. That the Casimir force is “universal”
makes it unusually interesting. Notice however, as is physically sensible, that the O(1/d4)
correction to the Casimir force does depend on whether the experimentalist used copper
or aluminum plates.
We might then wonder whether the leading term F = −π/(24d2) depends on the
particular regularization we used. What if we suppress the higher terms in the divergent
sum with some other function? We will address this question in the appendix to this
chapter.
Amusingly, the 24 in (3) is the same 24 that appears in string theory! (The dimension
of spacetime the quantum bosonic string must live in is determined to be 24 + 2 = 26.)
The reader who knows string theory would know what these two cryptic statements are
about (summing up the zero modes of the string). Appallingly, in an apparent attempt to
make the subject appear even more mysterious than it is, some treatments simply assert
that the sum
∞

n=1
n is by some mathematical sleight-of-hand equal to −1/12. Even though
it would have allowed us to wormhole from (1) to (3) instantly, this assertion is manifestly
absurd. What we did here, however, makes physical sense.
Appendix
Here we address the fundamental issue of whether a physical quantity we extract by cutting off high frequency
contributions could depend on how we cut. Let me mention that in recent years the study of Casimir force for
actual physical situations has grown into an active area of research, but clearly my aim here is not to give a realistic
account of this field, but to study in an easily understood context an issue (as you will see) central to quantum
field theory. My hope is that by the time you get to actually regularize a field theory in (3 + 1)-dimensional
spacetime, you would have amply mastered the essential physics and not have to struggle with the mechanics of
regularization.
Let us first generalize a bit the regularization scheme we used and write
f (d) = π
2d
∞

n=1
ng
na
d

= π
2
∂
∂a
∞

n=1
h
na
d

≡π
2
∂
∂a H
a
d

(4)
Here g(v) = h′(v) is a rapidly decreasing function so that the sums make sense, chosen judiciously to allow
ready evaluation of H(a/d) ≡
∞

n=1
h(na/d). [In (2), we chose g(v) = e−v and hence h(v) = −e−v.] We would like
to know how the Casimir force,
−F = ∂f (d)
∂d
−(d →L −d) = π
2
∂2
∂d∂a H(a
d ) −(d →L −d)
(5)
depends on g(v).
Let us try to get as far as we can using physical arguments and dimensional analysis. Expand H as follows:
πH(a/d) = . . . + γ−2d2/a2 + γ−1d/a + γ0 + γ1a/d + γ2a2/d2 + . . .. We might be tempted to just write a Taylor
series in a/d, but nothing tells us that H(a/d) might not blow up as a →0. Indeed, the example in (3) contains
a term like d/a, and so we better be cautious.

74 | I. Motivation and Foundation
We will presently argue physically that the series in fact terminate in one direction. The force is given by
F =

. . . + γ−2
2d
a3 + γ−1
1
2a2 + γ1
1
2d2 + γ2
2a
d3 + . . .

−(d →L −d)
(6)
Look at the γ−2 term: it contributes to the force a term like (d −(L −d))/a3. But as remarked earlier, the two
outer plates could be taken as far apart as we like. The force could not depend on L, and thus on physical grounds
γ−2 must vanish. Similarly, all γ−k for k > 2 must vanish.
Next, we note that the γ−1, although definitely not zero, gets subtracted away since it does not depend on d.
(The γ0 term has already gone away.) At this point, notice that, furthermore, the γk terms with k > 2 all vanish
as a →0. You could check that all these assertions hold for the g(v) used in the text.
Remarkably, the Casimir force is determined by γ1 alone: F = γ1/(2d2). As noted earlier, the force has to be
proportional to 1/d2. This fact alone shows us that in (6) we only need to keep the γ1 term. In the text, we found
γ1 = −π/12. In exercise I.9.1 I invite you to go through an amusing calculation obtaining the same value for γ1
with an entirely different choice of g(v).
This already suggests that the Casimir force is regularization independent, that it tells us more about the
vacuum than about metallic conductivity, but still it is highly instructive to study an entire class of damping or
regularizing functions to watch how regularization independence emerges. Let us regularize the sum over zero
point energies to f (d) = 1
2
∞

n=1
ωnK(ωn) with
K(ω) =

α
cα
α
ω + α
(7)
Here cα is a bunch of real numbers and α (known as regulators or regulator frequencies) a bunch of high
frequencies subject to certain conditions but otherwise chosen entirely at our discretion. For the sum
∞

n=1
ωnK(ωn)
to converge, we need K(ωn) to vanish faster than 1/ω2
n. In fact, for ω much larger than α, K(ω) →1
ω

α cαα −
1
ω2

α cαα2 + . . .. The requirement that the 1/ω and 1/ω2 terms vanish gives the conditions

α
cαα = 0
(8)
and

α
cα2
α = 0
(9)
respectively.
Furthermore, low frequency physics is not to be modified, and so we want K(ω) →1 for ω << α, thus
requiring

α
cα = 1
(10)
At this point, we do not even have to specify the set the index α runs over beyond the fact that the three conditions
(8),(9), and (10) require that α must take on at least three values. Note also that some of the cα’s must be negative.
Incidentally, we could do with fewer regulators if we are willing to invoke some knowledge of metals, for instance,
that K(ω) = K(−ω), but that is not the issue here.
We now show that the Casimir force between the two plates does not depend on the choices of cα and α.
First, being physicists rather than mathematicians, we freely interchange the two sums in f (d) and write
f (d) = 1
2

α
cαα

n
ωn
ωn + α
= −1
2

α
cαα

n
α
ωn + α
(11)

I.9. Disturbing the Vacuum | 75
where, without further ceremony, we have used condition (8). Next, keeping in mind that the sum

n α/(ωn + α) is to be put back into (11), we massage it (defining for convenience bα = π/α) as follows:
∞

n=1

ωn +  =
∞

n=1
 ∞
0
dte−t(1+n b
d ) =
 ∞
0
dte−t

1
1 −e−bt
d
−1

=
 ∞
0
dte−t[ d
tb −1
2 + tb
12d + O

b3
]
(12)
(To avoid clutter we have temporarily suppressed the index α.) All these manipulations make perfect sense since
the entire expression is to be inserted into the sum over α in (11) after we restore the index α. It appears that the
result would depend on cα and λα. In fact, mentally restoring and inserting, we see that the 1/b term in (12) can
be thrown away since

α
cαα/bα = π

α
cα2
α = 0
(13)
[There is in fact a bit of an overkill here since this term corresponds to the γ−1 term, which does not appear in
the force anyway. Thus the condition (9) is, strictly speaking, not necessary. We are regularizing not merely the
force, but f (d) so that it defines a sensible function.] Similarly, the b0 term in (12) can be thrown away thanks
to (8). Thus, keeping only the b term in (12), we obtain
f (d) = −1
24d
 ∞
0
dte−tt

α
cααbα + O
 1
d3

= −π
24d + O
 1
d3

(14)
Indeed, f (d), and a fortiori the Casimir force, do not depend on the cα’s and α’s. To the level of rigor enter-
tained by physicists (but certainly not mathematicians), this amounts to a proof of regularization independence
since with enough regulators we could approximate any (reasonable) function K(ω) that actually describes real
conducting plates. Again, as is physically sensible, you could check that the O(1/d3) term in f (d) does depend
on the regularization scheme.
The reason that I did this calculation in detail is that we will encounter this class of regularization, known as
Pauli-Villars, in chapter III.1 and especially in the calculation of the anomalous magnetic moment of the electron
in chapter III.7, and it is instructive to see how regularization works in a more physical context before dealing
with all the complications of relativistic field theory.
Exercises
I.9.1
Choose the damping function g(v) = 1/(1 + v)2 instead of the one in the text. Show that this re-
sults in the same Casimir force. [Hint: To sum the resulting series, pass to an integral representation
H(ξ) = −
∞

n=1
1/(1 + nξ) = −
∞

n=1
 ∞
0
dte−(1+nξ)t =
 ∞
0
dte−t/(1 −eξt). Note that the integral blows up
logarithmically near the lower limit, as expected.]
I.9.2
Show that with the regularization used in the appendix, the 1/d expansion of the force between two
conducting plates contains only even powers.
I.9.3
Show off your skill in doing integrals by calculating the Casimir force in (3 + 1)-dimensional spacetime.
For help, see M. Kardar and R. Golestanian, Rev. Mod. Phys. 71: 1233, 1999; J. Feinberg, A. Mann, and
M. Revzen, Ann. Phys. 288: 103, 2001.

I.10
Symmetry
Symmetry, transformation, and invariance
The importance of symmetry in modern physics cannot be overstated.1
When a law of physics does not change upon some transformation, that law is said to
exhibit a symmetry.
I have already used Lorentz invariance to restrict the form of an action. Lorentz invari-
ance is of course a symmetry of spacetime, but fields can also transform in what is thought
of as an internal space. Indeed, we have already seen a simple example of this. I noted in
passing in chapter I.3 that we could require the action of a scalar field theory to be invariant
under the transformation ϕ →−ϕ and so exclude terms of odd power in ϕ, such as ϕ3,
from the action.
With the ϕ3 term included, two mesons could scatter and go into three mesons, for
example by the diagrams in (fig. I.10.1). But with this term excluded, you can easily
convince yourself that this process is no longer allowed. You will not be able to draw
a Feynman diagram with an odd number of external lines. (Think about modifying the
integral in our baby problem in chapter I.7 to
 +∞
−∞dqe−1
2m2q2−gq3−λq4+Jq.) Thus the
simple reflection symmetry ϕ →−ϕ implies that in any scattering process the number
of mesons is conserved modulo 2.
Now that we understand one scalar field, let us consider a theory with two scalar fields
ϕ1 and ϕ2 satisfying the reflection symmetry ϕa →−ϕa (a = 1 or 2) :
L = 1
2(∂ϕ1)2 −1
2m2
1ϕ2
1 −λ1
4 ϕ4
1 + 1
2(∂ϕ2)2 −1
2m2
2ϕ2
2 −λ2
4 ϕ4
2 −ρ
2 ϕ2
1ϕ2
2
(1)
We have two scalar particles, call them 1 and 2, with mass m1 and m2. To lowest order,
they scatter in the processes 1 + 1 →1 + 1, 2 + 2 →2 + 2, 1 + 2 →1 + 2, 1 + 1 →2 + 2,
and 2 + 2 →1 + 1 (convince yourself). With the five parameters m1, m2, λ1, λ2, and ρ
completely arbitrary, there is no relationship between the two particles.
1 A. Zee, Fearful Symmetry.

I.10. Symmetry | 77
Figure I.10.1
It is almost an article of faith among theoretical physicists, enunciated forcefully by
Einstein among others, that the fundamental laws should be orderly and simple, rather
than arbitrary and complicated. This orderliness is reflected in the symmetry of the action.
Suppose that m1 = m2 and λ1 = λ2; then the two particles would have the same mass and
their interaction, with themselves and with each other, would be the same. The Lagrangian
L becomes invariant under the interchange symmetry ϕ1 ←→ϕ2.
Next, suppose we further impose the condition ρ = λ1 = λ2 so that the Lagrangian
becomes
L = 1
2

(∂ϕ1)2 + (∂ϕ2)2
−1
2m2 
ϕ2
1 + ϕ2
2

−λ
4

ϕ2
1 + ϕ2
2
2
(2)
It is now invariant under the 2-dimensional rotation {ϕ1(x) →cos θ ϕ1(x) + sin θ ϕ2(x),
ϕ2(x) →−sin θ ϕ1(x) + cos θ ϕ2(x)} with θ an arbitrary angle. We say that the theory
enjoys an “internal” SO(2) symmetry, internal in the sense that the transformation has
nothing to do with spacetime. In contrast to the interchange symmetry ϕ1 ←→ϕ2 the
transformation depends on the continuous parameter θ, and the corresponding symmetry
is said to be continuous.
We see from this simple example that symmetries exist in hierarchies.
Continuous symmetries
If we stare at the equations of motion (∂2 + m2)ϕa = −λ⃗ϕ2ϕa long enough we see that if
we define J μ ≡i(ϕ1∂μϕ2 −ϕ2∂μϕ1), then ∂μJ μ = i(ϕ1∂2ϕ2 −ϕ2∂2ϕ1) = 0 so that J μ is a
conserved current. The corresponding charge Q =

dDx J 0, just like electric charge, is
conserved.
Historically, when Heisenberg noticed that the mass of the newly discovered neutron
was almost the same as the mass of a proton, he proposed that if electromagnetism were
somehow turned off there would be an internal symmetry transforming a proton into a
neutron.
An internal symmetry restricts the form of the theory, just as Lorentz invariance restricts
the form of the theory. Generalizing our simple example, we could construct a field theory
containing N scalar fields ϕa, with a = 1, . . . , N such that the theory is invariant under the
transformations ϕa →Rabϕb (repeated indices summed), where the matrix R is an element
of the rotation group SO(N) (see appendix B for a review of group theory). The fields ϕa
transform as a vector ⃗ϕ = (ϕ1, . . . , ϕN). We can form only one basic invariant, namely the

78 | I. Motivation and Foundation
c
d
a
b
2i(abcd  acbd  adbc)
Figure I.10.2
scalar product ⃗ϕ . ⃗ϕ = ϕaϕa = ⃗ϕ2 (as always, repeated indices are summed unless otherwise
specified). The Lagrangian is thus restricted to have the form
L = 1
2

(∂⃗ϕ)2 −m2⃗ϕ2
−λ
4 (⃗ϕ2)2
(3)
The Feynman rules are given in fig. I.10.2. When we draw Feynman diagrams, each line
carries an internal index in addition to momentum.
Symmetry manifests itself in physical amplitudes. For example, imagine calculating
the propagator iDab(x) =

D ⃗ϕeiSϕa(x)ϕb(0). We assume that the measure D ⃗ϕ is in-
variant under SO(N). By thinking about how Dab(x) transforms under the symmetry
group SO(N) you see easily (exercise I.10.2) that it must be proportional to δab. You can
check this by drawing a few Feynman diagrams or by considering an ordinary integral

d ⃗qe−S(q)qaqb. No matter how complicated a diagram you draw (fig. I.10.3, e.g.) you al-
ways get this factor of δab. Similarly, scattering amplitudes must also exhibit the symmetry.
Without the SO(N) symmetry, many other terms would be possible (e.g., ϕaϕbϕcϕd for
some arbitrary choice of a, b, c, and d) in (3).
Wecanwrite R = eθ.T whereθ . T = 
A θAT A isarealantisymmetricmatrix.Thegroup
SO(N) has N(N −1)/2 generators, which we denote by T A. [Think of the familiar case of
SO(3).] Under an infinitesimal transformation (repeated indices summed) ϕa →Rabϕb ≃
(1 + θAT A)abϕb, or in other words, we have the infinitesimal change δϕa = θAT Aabϕb.
Noether’s theorem
We now come to one of the most profound observations in theoretical physics, namely
Noether’s theorem, which states that a conserved current is associated with each generator
a
b
d
h
g
c
e
f
i
j
m
k
l
Figure I.10.3

I.10. Symmetry | 79
of a continuous symmetry. The appearance of a conserved current for (2) is not an acci-
dent.
As is often the case with the most important theorems, the proof of Noether’s theorem is
astonishingly simple. Denote the fields in our theory generically by ϕa. Since the symmetry
is continuous, we can consider an infinitesimal change δϕa. Since L does not change,
we have
0 = δL = δL
δϕa
δϕa +
δL
δ∂μϕa
δ∂μϕa
= δL
δϕa
δϕa +
δL
δ∂μϕa
∂μδϕa
(4)
We would have been stuck at this point, but if we use the equations of motion δL/δϕa =
∂μ(δL/δ∂μϕa) we can combine the two terms and obtain
0 = ∂μ

δL
δ∂μϕa
δϕa

(5)
If we define
J μ ≡
δL
δ∂μϕa
δϕa
(6)
then (5) says that ∂μJ μ = 0. We have found a conserved current! [It is clear from the
derivation that the repeated index a is summed in (6)].
Let us immediately illustrate with the simple scalar field theory in (3). Plugging δϕa =
θA(T A)abϕb into (6) and noting that θA is arbitrary, we obtain N(N −1)/2 conserved
currents J A
μ = ∂μϕa(T A)abϕb, one for each generator of the symmetry group SO(N).
In the special case N = 2, we can define a complex field ϕ ≡(ϕ1 + iϕ2)/
√
2. The La-
grangian in (3) can be written as
L = ∂ϕ
†∂ϕ −m2ϕ
†ϕ −λ(ϕ
†ϕ)2,
and is clearly invariant under ϕ →eiθϕ and ϕ
† →e−iθϕ
†. We find from (6) that Jμ =
i(ϕ
†∂μϕ −∂μϕ
†ϕ), the current we met already in chapter I.8. Mathematically, this is
because the groups SO(2) and U(1) are isomorphic (see appendix B).
For pedagogical clarity I have used the example of scalar fields transforming as a vector
under the group SO(N). Obviously, the preceding discussion holds for an arbitrary group
G with the fields ϕ transforming under an arbitrary representation R of G. The conserved
currents are still given by J A
μ = ∂μϕa(T A)abϕb with T A the generators evaluated in the
representation R. For example, if ϕ transform as the 5-dimensional representation of
SO(3) then T A is a 5 by 5 matrix.
For physics to be invariant under a group of transformations it is only necessary that the
action be invariant. The Lagrangian density L could very well change by a total divergence:
δL = ∂μKμ, provided that the relevant boundary term could be dropped. Then we would
see immediately from (5) that all we have to do to obtain a formula for the conserved
current is to modify (6) to J μ ≡(δL/δ∂μϕa)δϕa −Kμ. As we will see in chapter VIII.4,
many supersymmetric field theories are of this type.

80 | I. Motivation and Foundation
Charge as generators
Using the canonical formalism of chapter I.8, we can derive an elegant result for the charge
associated with the conserved current
Q ≡

d3xJ 0 =

d3x δL
δ∂0ϕa
δϕa
Note that Q does not depend on the time at which the integral is evaluated:
dQ
dt =

d3x∂0J 0 = −

d3x∂iJ i = 0
(7)
Recognizing that δL/δ∂0ϕa is just the canonical momentum conjugate to the field ϕa, we
see that
i[Q, ϕa] = δϕa
(8)
The charge operator generates the corresponding transformation on the fields. An impor-
tant special case is for the complex field ϕ in SO(2) ≃U(1) theory we discussed; then
[Q, ϕ] = ϕ and eiθQϕe−iθQ = eiθϕ.
Exercises
I.10.1
Some authors prefer the following more elaborate formulation of Noether’s theorem. Suppose that the
action does not change under an infinitesimal transformation δϕa(x) = θAV A
a [with θA some parameters
labeled by A and V A
a some function of the fields ϕb(x) and possibly also of their first derivatives with
respect to x]. It is important to emphasize that when we say the action S does not change we are not
allowed to use the equations of motion. After all, the Euler-Lagrange equations of motion follow from
demanding that δS = 0 for any variation δϕa subject to certain boundary conditions. Our scalar field
theory example nicely illustrates this point, which is confused in some books: δS = 0 merely because S
is constructed using the scalar product of O(N) vectors.
Now let us do something apparently a bit strange. Let us consider the infinitesimal change written
above but with the parameters θA dependent on x. In other words, we now consider δϕa(x) = θA(x)V A
a .
Then of course there is no reason for δS to vanish; but, on the other hand, we know that since δS does
vanish when θA is constant, δS must have the form δS =

d4xJ μ(x)∂μθA(x). In practice, this gives us
a quick way of reading off the current J μ(x); it is just the coefficient of ∂μθA(x) in δS.
Show how all this works for the Lagrangian in (3).
I.10.2
Show that Dab(x) must be proportional to δab as stated in the text.
I.10.3
Write the Lagrangian for an SO(3) invariant theory containing a Lorentz scalar field ϕ transforming
in the 5-dimensional representation up to quartic terms. [Hint: It is convenient to write ϕ as a 3 by 3
symmetric traceless matrix.]
I.10.4
Add a Lorentz scalar field η transforming as a vector under SO(3) to the Lagrangian in exercise I.10.3,
maintaining SO(3) invariance. Determine the Noether currents in this theory. Using the equations of
motion, check that the currents are conserved.

I.11
Field Theory in Curved Spacetime
General coordinate transformation
In Einstein’s theory of gravity, the invariant Minkowskian spacetime interval ds2 =
ημνdxμdxν = (dt)2 −(d ⃗x)2 is replaced by ds2 = gμνdxμdxν, where the metric tensor
gμν(x) is a function of the spacetime coordinates x. The guiding principle, known as the
principle of general covariance, states that physics, as embodied in the action S, must be
invariant under arbitrary coordinate transformations x →x′(x). More precisely, the prin-
ciple1 states that with suitable restrictions the effect of a gravitational field is equivalent to
that of a coordinate transformation.
Since
ds2 = g′
λσdx′λdx′σ = g′
λσ
∂x′λ
∂xμ
∂x′σ
∂xν dxμdxν = gμνdxμdxν
the metric transforms as
g′
λσ(x′)∂x′λ
∂xμ
∂x′σ
∂xν = gμν(x)
(1)
The inverse of the metric gμν is defined by gμνgνρ = δμ
ρ .
A scalar field by its very name does not transform: ϕ(x) = ϕ′(x′). The gradient of the
scalar field transforms as
∂μϕ(x) = ∂x′λ
∂xμ
∂ϕ′(x′)
∂x′λ
= ∂x′λ
∂xμ ∂′
λϕ′(x′)
By definition, a (covariant) vector field transforms as
Aμ(x) = ∂x′λ
∂xμ A′
λ(x′)
1 For a precise statement of the principle of general covariance, see S. Weinberg, Gravitation and Cosmology,
p. 92.

82 | I. Motivation and Foundation
so that ∂μϕ(x) is a vector field. Given two vector fields Aμ(x) and Bν(x), we can contract
them with gμν(x) to form gμν(x)Aμ(x)Bν(x), which, as you can immediately check, is
a scalar. In particular, gμν(x)∂μϕ(x)∂νϕ(x) is a scalar. Thus, if we simply replace the
Minkowski metric ημν in the Lagrangian L = 1
2[(∂ϕ)2 −m2ϕ2] = 1
2(ημν∂μϕ∂νϕ −m2ϕ2) by
the Einstein metric gμν, the Lagrangian is invariant under coordinate transformation.
The action is obtained by integrating the Lagrangian over spacetime. Under a coordinate
transformation d4x′ = d4x det(∂x′/∂x). Taking the determinant of (1), we have
g ≡det gμν = det g′
λσ
∂x′λ
∂xμ
∂x′σ
∂xν = g′

det
∂x′
∂x
2
(2)
We see that the combination d4x√−g = d4x′
−g′ is invariant under coordinate transfor-
mation.
Thus, given a quantum field theory we can immediately write down the theory in curved
spacetime. All we have to do is promote the Minkowski metric ημν in our Lagrangian to the
Einstein metric gμν and include a factor √−g in the spacetime integration measure.2 The
action S would then be invariant under arbitrary coordinate transformations. For example,
the action for a scalar field in curved spacetime is simply
S =

d4x√−g 1
2(gμν∂μϕ∂νϕ −m2ϕ2)
(3)
(There is a slight subtlety involving the spin 1
2 field that we will talk about in part II. We
will eventually come to it in chapter VIII.1.)
There is no essential difficulty in quantizing the scalar field in curved spacetime. We
simply treat gμν as given [e.g., the Schwarzschild metric in spherical coordinates: g00 =
(1 −2GM/r), grr = −(1 −2GM/r)−1, gθθ = −r2, and gφφ = −r2 sin2 θ] and study the
path integral

DϕeiS, which is still a Gaussian integral and thus do-able. The propagator
of the scalar field D(x, y) can be worked out and so on and so forth. (see exercise I.11.1).
At this point, aside from the fact that gμν(x) carries Lorentz indices while ϕ(x) does not,
the metric gμν looks just like a field and is in fact a classical field. Write the action of the
world S = Sg + SM as the sum of two terms: Sg describing the dynamics of the gravitational
field gμν (which we will come to in chapter VIII.1) and SM describing the dynamics of all
the other fields in the world [the “matter fields,” namely ϕ in our simple example with SM
as given in (3)]. We could quantize gravity by integrating over gμν as well, thus extending
the path integral to

DgDϕeiS.
Easier said than done! As you have surely heard, all attempts to integrate over gμν(x)
have been beset with difficulties, eventually driving theorists to seek solace in string theory.
I will explain in due time why Einstein’s theory is known as “nonrenormalizable.”
2 We also have to replace ordinary derivatives ∂μ by the covariant derivatives Dμ of general relativity, but acting
on a scalar field ϕ the covariant derivative is just the ordinary derivative Dμϕ = ∂μϕ.

I.11. Field Theory in Spacetime | 83
What the graviton listens to
One of the most profound results to come out of Einstein’s theory of gravity is a funda-
mental definition of energy and momentum. What exactly are energy and momentum any
way? Energy and momentum are what the graviton listens to. (The graviton is of course
the particle associated with the field gμν.)
The stress-energy tensor T μν is defined as the variation of the matter action SM with
respect to the metric gμν (holding the coordinates xμ fixed):
T μν(x) = −
2
√−g
δSM
δgμν(x)
(4)
Energy is defined as E =P 0=

d3x√−gT 00(x) and momentum as P i =

d3x√−gT 0i(x).
Even if we are not interested in curved spacetime per se, (4) still offers us a simple (and
fundamental) way to determine the stress energy of a field theory in flat spacetime. We
simply vary around the Minkowski metric ημν by writing gμν = ημν + hμν and expand SM
to first order in h. According to (4), we have3
SM(h) = SM(h = 0) −

d4x

1
2hμνT μν + O(h2)

.
(5)
The symmetric tensor field hμν(x) is in fact the graviton field (see chapters I.5 and
VIII.1). The stress-energy tensor T μν(x) is what the graviton field couples to, just as the
electromagnetic current J μ(x) is what the photon field couples to.
Consider a general SM =

d4x√−g(A + gμνBμν + gμνgλρCμνλρ + . . .). Since −g =
1 + ημνhμν + O(h2) and gμν = ημν −hμν + O(h2), we find
Tμν = 2(Bμν + 2Cμνλρηλρ + . . .) −ημνL
(6)
in flat spacetime. Note
T ≡ημνTμν = −(4A + 2ημνBμν + 0 . ημνηλρCμνλρ + . . .)
(7)
which we have written in a form emphasizing that Cμνλρ does not contribute to the trace
of the stress-energy tensor.
We now show the power of this definition of Tμν by obtaining long-familiar results
about the electromagnetic field. Promoting the Lagrangian of the massive spin 1 field
to curved spacetime we have4 L = (−1
4gμνgλρFμλFνρ + 1
2m2gμνAμAν) and thus5 Tμν =
−FμλF λ
ν + m2AμAν −ημνL.
3 I use the normal convention in which indices are summed regardless of any symmetry; in other words,
1
2hμνT μν = 1
2(h01T 01 + h10T 10 + . . .) = h01T 01 + . . . .
4 Here we use the fact that the covariant curl is equal to the ordinary curl DμAν −DνAμ = ∂μAν −∂νAμ and
so Fμν does not involve the metric.
5 Holding xμ fixed means that we hold ∂μ and hence Aμ fixed since Aμ is related to ∂μ by gauge invariance.
We are anticipating (see chapter II.7) here, but you have surely heard of gauge invariance in a nonrelativistic
context.

84 | I. Motivation and Foundation
For the electromagnetic field we set m = 0. First, L = −1
4FμνF μν = −1
4 (−2F 2
0i + F 2
ij) =
1
2( ⃗E2 −⃗B2). Thus, T00 = −F0λF λ
0 −1
2( ⃗E2 −⃗B2) = 1
2( ⃗E2 + ⃗B2). That was comforting, to
see a result we knew from “childhood.” Incidentally, this also makes clear that we can
think of ⃗E2 as kinetic energy and ⃗B2 as potential energy. Next, T0i = −F0λF λ
i = F0jFij =
εijkEjBk = ( ⃗E × ⃗B)i. The Poynting vector has just emerged.
Since the Maxwell Lagrangian L = −1
4gμνgλρFμλFνρ involves only the C term with
Cμνλρ = −1
4FμνFλρ, we see from (7) that the stress-energy tensor of the electromagnetic
field is traceless, an important fact we will need in chapter VIII.1. We can of course check
directly that T = 0 (exercise I.11.4).6
Appendix: A concise introduction to curved spacetime
General relativity is often made to seem more difficult and mysterious than need be. Here I give a concise review
of some of its basic elements for later use.
Denote the spacetime coordinates of a point particle by Xμ. To construct its action note that the only
coordinate invariant quantity is the “length”7 of the world line traced out by the particle (fig. I.11.1), namely

ds =
 gμνdXμdXν, where gμν is evaluated at the position of the particle of course. Thus, the action for a
point particle must be proportional to

ds =
 
gμνdXμdXν =
 
gμν[X(ζ)]dXμ
dζ
dXν
dζ dζ
where ζ is any parameter that varies monotonically along the world line. The length, being geometric, is
manifestly reparametrization invariant, that is, independent of our choice of ζ as long as it is reasonable. This
is one of those “more obvious than obvious” facts since
 gμνdXμdXν is manifestly independent of ζ . If we
insist, we can check the reparametrization invariance of

ds. Obviously the powers of dζ match. Explicitly, if
we write ζ = ζ(η), then dXμ/dζ = (dη/dζ)(dXμ/dη) and dζ = (dζ/dη)dη.
Let us define
K ≡gμν[X(ζ)]dXμ
dζ
dXν
dζ
for ease of writing. Setting the variation of

dζ
√
K equal to zero, we obtain

dζ
1
√
K
(2gμν
dXμ
dζ
dδXν
dζ
+ ∂λgμν
dXμ
dζ
dXν
dζ δXλ) = 0
which upon integration by parts (and with δXλ = 0 at the endpoints as usual) gives the equation of motion
√
K d
dζ
 1
√
K
2gμλ
dXμ
dζ

−∂λgμν
dXμ
dζ
dXν
dζ
= 0
(8)
To simplify (8) we exploit our freedom in choosing ζ and set dζ = ds, so that K = 1. We have
2gμλ
d2Xμ
ds2
+ 2∂σgμλ
dXσ
ds
dXμ
ds
−∂λgμν
dXμ
ds
dXν
ds
= 0
6 We see that tracelessness is related to the fact that the electromagnetic field has no mass scale. Pure
electromagnetism is said to be scale or dilatation invariant. For more on dilatation invariance see S. Coleman,
Aspects of Symmetry, p. 67.
7 We put “length” in quotes because if gμν had a Euclidean signature then

ds would indeed be the length
and minimizing

ds would give the shortest path (the geodesic) between the endpoints, but here gμν has a
Minkowskian signature.

I.11. Field Theory in Spacetime | 85
Xμ(ζ)
Figure I.11.1
which upon multiplication by gρλ becomes
d2Xρ
ds2 + 1
2gρλ(2∂νgμλ −∂λgμν)dXμ
ds
dXν
ds
= 0
that is,
d2Xρ
ds2 + ρ
μν[X(s)]dXμ
ds
dXν
ds = 0
(9)
if we define the Riemann-Christoffel symbol by
ρ
μν ≡1
2gρλ(∂μgνλ + ∂νgμλ −∂λgμν)
(10)
Given the initial position Xμ(s0) and velocity (dXμ/ds)(s0) we have four second order differential equations (9)
determining the geodesic followed by the particle in curved spacetime. Note that, contrary to the impression
given by some texts, unlike (8), (9) is not reparametrization invariant.
To recover Newtonian gravity, three conditions must be met: (1) the particle moves slowly dXi/ds ≪dX0/ds;
(2) the gravitational field is weak, so that the metric is almost Minkowskian gμν ≃ημν + hμν; and (3) the
gravitational field does not depend on time. Condition (1) means that d2Xρ/ds2 + ρ
00(dX0/ds)2 ≃0, while (2)
and (3) imply that ρ
00 ≃−1
2ηρλ∂λh00. Thus, (9) reduces to d2X0/ds2 ≃0 (which implies that dX0/ds is a constant)
and d2Xi/ds2 + 1
2∂ih00(dX0/ds)2 ≃0, which since X0 is proportional to s becomes d2Xi/dt2 ≃−1
2∂ih00. Thus,
we obtain Newton’s equation d2 ⃗X
dt2 ≃−⃗∇φ if we define the gravitational potential φ by h00 = 2φ:
g00 ≃1 + 2φ
(11)
Referring to the Schwarzschild metric, we see that far from a massive body, φ = −GM/r, as we expect. (Note
also that this derivation depends neither on hij nor on h0j , as long as they are time independent.)
Thus, the action of a point particle is
S = −m
 
gμνdXμdXν = −m
 
gμν[X(ζ)]dXμ
dζ
dXν
dζ dζ
(12)
The m follows from dimensional analysis.
A slick way of deriving S (which also allows us to see the minus sign) is to start with the nonrelativistic action
of a particle in a gravitational potential φ, namely S =

Ldt =

( 1
2mv2 −m −mφ)dt. Note that the rest mass

86 | I. Motivation and Foundation
m comes in with a minus sign as it is part of the potential energy in nonrelativistic physics. Now force S into a
relativistic form: For small v and φ,
S = −m

(1 −1
2v2 + φ)dt ≃−m
 
1 −v2 + 2φdt
= −m
 
(1 + 2φ)(dt)2 −(d ⃗x)2
We see8 that the 2 in (11) comes from the square root in the Lorentz-Fitzgerald quantity
√
1 −v2.
Now that we have S we can calculate the stress energy of a point particle using (4):
T μν(x) =
m
√−g

dζK−1
2δ(4)[x −X(ζ)]dXμ
dζ
dXν
dζ
Setting ζ to s (which we call the proper time τ in this context) we have
T μν(x) =
m
√−g

dτδ(4)[x −X(τ)]dXμ
dτ
dXν
dτ
In particular, as we expect the 4-momentum of the particle is given by
P ν =

d3x√−gT 0ν = m

dτδ[x0 −X0(τ)]dX0
dτ
dXν
dτ
= mdXν
dτ
The action (12) given here has two defects: (1) it is difficult to deal with a path integral

DXe−im 
dζ√
(dXμ/dζ)(dXμ/dζ) involving a square root, and (2) S does not make sense for a massless particle.
To remedy these defects, note that classically, S is equivalent to
Simp = −1
2

dζ
 1
γ
dXμ
dζ
dXμ
dζ
+ γ m2

(13)
where (dXμ/dζ)(dXμ/dζ) = gμν(X)(dXμ/dζ)(dXν/dζ). Varying with respect to γ (ζ) we obtain m2γ 2 =
(dXμ/dζ)(dXμ/dζ). Eliminating γ in Simp we recover S.
The path integral

DXeiSimp has a standard quadratic form.9 Quantum mechanics of a relativistic point parti-
cle is best formulated in terms of Simp, not S. Furthermore, for m = 0, Simp = −1
2

dζ[γ −1(dXμ/dζ)(dXμ/dζ)]
makes perfect sense. Note that varying with respect to γ now gives the well-known fact that for a massless particle
gμν(X)dXμdXν = 0.
The action Simp will provide the starting point for our discussion on string theory in chapter VIII.5.
Exercises
I.11.1
Integrate by parts to obtain for the scalar field action
S = −

d4x√−g 1
2ϕ(
1
√−g ∂μ
√−ggμν∂ν + m2)ϕ
8 We should not conclude from this that gij = δij . The point is that to leading order in v/c, our particle is
sensitive only to g00, as we have just shown. Indeed, restoring c in the Schwarzschild metric we have
ds2 = (1 −2GM
c2r )c2dt2 −(1 −2GM
c2r )−1dr2 −r2dθ2 −r2 sin2 θdφ2
→c2dt2 −d ⃗x2 −2GM
r
dt2 + O(1/c2)
9 One technical problem, which we will address in chapter III.4, is that in the integral over X(ζ) apparently
different functions X(ζ) may in fact be the same physically, related by a reparametrization.

I.11. Field Theory in Spacetime | 87
and write the equation of motion for ϕ in curved spacetime. Discuss the propagator of the scalar field
D(x, y) (which is of course no longer translation invariant, i.e., it is no longer a function of x −y).
I.11.2
Use (4) to find E for a scalar field theory in flat spacetime. Show that the result agrees with what you
would obtain using the canonical formalism of chapter I.8.
I.11.3
Show that in flat spacetime P μ as derived here from the stress energy tensor T μν when interpreted as
an operator in the canonical formalism satisfies [P μ, ϕ(x)] = −i∂μϕ(x), and thus does exactly what you
expect the energy and momentum operators to do, namely to be conjugate to time and space and hence
represented by −i∂μ.
I.11.4
Show that for the Maxwell field Tij = −(EiEj + Bi Bj) + 1
2δij( ⃗E2 + ⃗B2) and hence T = 0.

I.12
Field Theory Redux
What have you learned so far?
Now that we have reached the end of part I, let us take stock of what you have learned.
Quantum field theory is not that difficult; it just consists of doing one great big integral
Z(J) =

Dϕ ei 
dD+1x[ 1
2 (∂ϕ)2−1
2 m2ϕ2−λϕ4+Jϕ]
(1)
By repeatedly functionally differentiating Z(J) and then setting J = 0 we obtain

Dϕ ϕ(x1)ϕ(x2) . . . ϕ(xn)ei 
dD+1x[ 1
2 (∂ϕ)2−1
2 m2ϕ2−λϕ4]
(2)
which tells us about the amplitude for n particles associated with the field ϕ to come into
and go out of existence at the spacetime points x1, x2, . . . , xn, interacting with each other
in between. Birth and death, with some kind of life in between.
Ah, if we could only do the integral in (1)! But we can’t. So one way of going about it is
to evaluate the integral as a series in λ :
∞

k=0
(−iλ)k
k!

Dϕ ϕ(x1)ϕ(x2) . . . ϕ(xn)[

dD+1yϕ(y)4]kei
dD+1x[ 1
2 (∂ϕ)2−1
2 m2ϕ2]
(3)
To keep track of the terms in the series we draw little diagrams.
Quantum field theorists try to dream up ways to evaluate (1), and failing that, they invent
tricks and methods for extracting the physics they are interested in, by hook and by crook,
without actually evaluating (1).
To see that quantum field theory is a straightforward generalization of quantum me-
chanics, look at how (1) reduces appropriately. We have written the theory in (D + 1)-
dimensional spacetime, that is, D spatial dimensions and 1temporal dimension. Consider
(1) in (0 + 1)-dimensional spacetime, that is, no space; it becomes
Z(J) =

Dϕ ei 
dt[ 1
2 ( dϕ
dt )2−1
2 m2ϕ2−λϕ4+Jϕ]
(4)

I.12. Field Theory Redux | 89
where we now denote the spacetime coordinate x just by time t. We recognize this as the
quantum mechanics of an anharmonic oscillator with the position of the mass point tied
to the spring denoted by ϕ and with an external force J pushing on the oscillator.
In the quantum field theory (1), each term in the action makes physical sense: The first
two terms generalize the harmonic oscillator to include spatial variations, the third term
the anharmonicity, and the last term an external probe. You can think of a quantum field
theory as an infinite collection of anharmonic oscillators, one at each point in space.
We have here a scalar field ϕ. In previous and future chapters, the notion of field was
and will be generalized ever so slightly: The field can transform according to a nontrivial
representation of the Lorentz group. We have already encountered fields transforming as
a vector and a tensor and will presently encounter a field transforming as a spinor. Lorentz
invariance and whatever other symmetries we have constrain the form of the action. The
integral will look more complicated but the approach is exactly as outlined here.
That’s just about all there is to quantum field theory.

This page intentionally left blank

Part II
Dirac and the Spinor

This page intentionally left blank

II.1
The Dirac Equation
Staring into a fire
According to a physics legend, apparently even true, Dirac was staring into a fire one
evening in 1928 when he realized that he wanted, for reasons that are no longer relevant,
a relativistic wave equation linear in spacetime derivatives ∂μ ≡∂/∂xμ. At that time, the
Klein-Gordon equation (∂2 + m2)ϕ = 0, which describes a free particle of mass m and
quadratic in spacetime derivatives, was already well known. This is in fact the equation of
motion of the scalar field theory we studied earlier.
At first sight, what Dirac wanted does not make sense. The equation is supposed to
have the form “some linear combination of ∂μ acting on some field ψ is equal to some
constant times the field.” Denote the linear combination by cμ∂μ. If the cμ’s are four
ordinary numbers, then the four-vector cμ defines some direction and the equation cannot
be Lorentz invariant.
Nevertheless, let us follow Dirac and write, using modern notation,
(iγ μ∂μ −m)ψ = 0
(1)
At this point, the four quantities iγ μ are just the coefficients of ∂μ and m is just a constant.
We have already argued that γ μ cannot simply be four numbers. Well, let us see what these
objects have to be in order for this equation to contain the correct physics.
Acting on (1) with (iγ μ∂μ + m), Dirac obtained −(γ μγ ν∂μ∂ν + m2)ψ = 0. It is tradi-
tional to define, in addition to the commutator [A, B] = AB −BA familiar from quan-
tum mechanics, the anticommutator {A, B} = AB + BA. Since derivatives commute,
γ μγ ν∂μ∂ν = 1
2{γ μ, γ ν}∂μ∂ν, and we have ( 1
2{γ μ, γ ν}∂μ∂ν + m2)ψ = 0. In a moment of
inspiration Dirac realized that if
{γ μ, γ ν} = 2ημν
(2)
with ημν the Minkowski metric he would obtain (∂2 + m2)ψ = 0, which describes a particle
of mass m, and thus (1) would also describe a particle of mass m.

94 | II. Dirac and the Spinor
Since ημν is a diagonal matrix with diagonal elements η00 = 1 and ηjj = −1, (2) says
that (γ 0)2 = 1, (γ j)2 = −1, and γ μγ ν = −γ νγ μ for μ ̸= ν. This last statement, that the
coefficients γ μ anticommute with each other, implies that they indeed cannot be ordinary
numbers. Dirac’s thought would make sense if we could find four such objects.
Clifford algebra
A set of objects γ μ (clearly d of them in d-dimensional spacetime) satisfying the relation
(2) is said to form a Clifford algebra. I will develop the mathematics of Clifford algebra
later. Suffice it for you to check here that the following 4 by 4 matrices satisfy (2):
γ 0 =

 I
0
0
−I

= I ⊗τ3
(3)
γ i =

 0
σ i
−σ i
0

= σ i ⊗iτ2
(4)
Here σ and τ denote the standard Pauli matrices. For historical reasons the four matrices
γ μ are known as gamma matrices—not a very imaginative name! (Our convention is such
that whether an index on a Pauli matrix is upper or lower has no significance. On the other
hand, we define γμ ≡ημνγ ν and it does matter whether the index on a gamma matrix is
upper or lower; it is to be treated just like the index on any Lorentz vector. This convention
is useful because then γ μ∂μ = γμ∂μ.)
The direct product notation is convenient for computation: For example, γ iγ j = (σ i ⊗
iτ2)(σ j ⊗iτ2) = (σ iσ j ⊗i2τ2τ2) = −(σ iσ j ⊗I) and thus {γ i, γ j} = −{σ i, σ j} ⊗I =
−2δij as desired.
You can convince yourself that the γ μ’s cannot be smaller than 4 by 4 matrices. The
mathematics forces the Dirac spinor ψ to have 4 components! The physical content of
the Dirac equation (1) is most transparent if we transform to momentum space: we plug
ψ(x) =

[d4p/(2π)4]e−ipxψ(p) into (1) and obtain
(γ μpμ −m)ψ(p) = 0
(5)
Since (5) is Lorentz invariant, as we will show below, we can examine its physical content
in any frame, in particular the rest frame pμ = (m, ⃗0), in which it becomes
(γ 0 −1)ψ = 0
(6)
As (γ 0 −1)2 = −2(γ 0 −1) we recognize (γ 0 −1) as a projection operator up to a trivial nor-
malization. Indeed, using the explicit form in (3), we see that there is nothing mysterious
to Dirac’s equation: When written out, (6) reads

 0
0
0
I

ψ = 0
thus telling us that 2 of the 4 components in ψ are zero.

II.1. The Dirac Equation | 95
This makes perfect sense since we know that the electron has 2 physical degrees of
freedom, not 4. Viewed in this light, the mysterious Dirac equation is no more and no less
than a projection that gets rid of the unwanted degrees of freedom. Compare our discussion
of the equation of motion of a massive spin 1 particle (chapter I.5). There also, 1 of the 4
components of Aμ is projected out. Indeed, the Klein-Gordon equation (∂2 + m2)ϕ(x) = 0
just projects out those Fourier components ϕ(k) not satisfying the mass shell condition
k2 = m2. Our discussion provides a unified view of the equations of motion in relativistic
physics: They just project out the unphysical components.
A convenient notation introduced by Feynman, ̸a ≡γ μaμ for any 4-vector aμ, is now
standard. The Dirac equation then reads (i̸∂−m)ψ = 0.
Cousins of the gamma matrices
Under a Lorentz transformation x′ν = ν
μxμ, the 4 components of the vector field Aμ
transform like, well, a vector. How do the 4 components of ψ transform? Surely not in the
same way as Aμ since even under rotation ψ and Aμ transform quite differently: one as
spin 1
2 and the other as spin 1. Let us write ψ(x) →ψ′(x′) ≡S()ψ(x) and try to determine
the 4 by 4 matrix S().
It is a good idea to first sort out (and name) the 16 linearly independent 4 by 4 matrices.
We already know five of them: the identity matrix and the γ μ’s. The strategy is simply
to multiply the γ μ ’s together, thus generating more 4 by 4 matrices until we get all 16.
Since the square of a gamma matrix γ μ is equal to ±1 and the γ μ’s anticommute with
each other, we have to consider only γ μγ ν, γ μγ νγ λ, and γ μγ νγ λγ ρ with μ, ν, λ, and ρ all
different from one another. Thus, the only product of four gamma matrices that we have
to consider is
γ 5 ≡iγ 0γ 1γ 2γ 3
(7)
This combination is so important that it has its own name! (The peculiar name comes
about because in some old-fashioned notation the time coordinate was called x4 with a
corresponding γ 4.) We have
γ 5 = i(I ⊗τ3)(σ 1 ⊗iτ2)(σ 2 ⊗iτ2)(σ 3 ⊗iτ2) = i4(I ⊗τ3)(σ 1σ 2σ 3 ⊗τ2)
and so
γ 5 = I ⊗τ1 =

 0
I
I
0

(8)
With the factor of i included, γ 5 is manifestly hermitean. An important property is that γ 5
anticommutes with the γ μ’s:
{γ 5, γ μ} = 0
(9)

96 | II. Dirac and the Spinor
Continuing, we see that the products of three gamma matrices, all different, can be
written as γ μγ 5 (e.g., γ 1γ 2γ 3 = −iγ 0γ 5). Finally, using (2) we can write the product of
two gamma matrices as γ μγ ν = ημν −iσ μν, where
σ μν ≡i
2[γ μ, γ ν]
(10)
There are 4 . 3/2 = 6 of these σ μν matrices.
Count them, we got all 16. The set of 16 matrices {1, γ μ, σ μν, γ μγ 5, γ 5} forms a
complete basis of the space of all 4 by 4 matrices, that is, any 4 by 4 matrix can be written
as a linear combination of these 16 matrices.
It is instructive to write out σ μν explicitly in the representation (3) and (4):
σ 0i = i

 0
σ i
σ i
0

(11)
σ ij = εijk

 σ k
0
0
σ k

(12)
We see that σ ij are just the Pauli matrices doubly stacked, for example,
σ 12 =

 σ 3
0
0
σ 3

Lorentz transformation
Recall from a course on quantum mechanics that a general rotation can be written as
ei ⃗θ ⃗Jwith ⃗J the 3 generators of rotation and ⃗θ 3 rotation parameters. Recall also that the
Lorentz group contains boosts in addition to rotations, with ⃗K denoting the 3 generators of
boosts. Recall from a course on electromagnetism that the 6 generators { ⃗J , ⃗K} transform
under the Lorentz group as the components of an antisymmetric tensor just like the
electromagnetic field Fμν and thus can be denoted by Jμν. I will discuss these matters
in more detail in chapter II.3. For the moment, suffice it to note that with this notation
we can write a Lorentz transformation as  = e−i
2ωμνJ μν, with J ij generating rotations,
J 0i generating boosts, and the antisymmetric tensor ωμν = −ωνμ with its 6 = 4 . 3/2
components corresponding to the 3 rotation and 3 boost parameters.
Given the preceding discussion and the fact that there are six matrices σ μν, we suspect
that up to an overall numerical factor the σ μν’s must represent the 6 generators J μν of the
Lorentz group acting on a spinor. In fact, our suspicion is confirmed by thinking about
what a rotation e−i
2ωijJ ij does. Referring to (12) we see that if J ij is represented by 1
2σ ij
this would correspond exactly to how a spin 1
2 particle transforms in quantum mechanics.
More precisely, separate the 4 components of the Dirac spinor into 2 sets of 2 components:
ψ =

 φ
χ

(13)

II.1. The Dirac Equation | 97
From (12) we see that under a rotation around the 3rd axis, φ →e−iω12 1
2σ 3φ and χ →
e−iω12 1
2σ 3χ. It is gratifying to see that φ and χ transform like 2-component Pauli spinors.
We have thus figured out that a Lorentz transformation  acting on ψ is represented
by S() = e−(i/4)ωμνσ μν, and so, acting on ψ, the generators J μν are indeed represented
by
1
2σ μν. Therefore we would expect that if ψ(x) satisfies the Dirac equation (1) then
ψ′(x′) ≡S()ψ(x) would satisfy the Dirac equation in the primed frame,
(iγ μ∂′
μ −m)ψ′(x′) = 0
(14)
where ∂′
μ ≡∂/∂x′μ. To show this, calculate [σ μν, γ λ] = 2i(γ μηνλ −γ νημλ) and hence
for ω infinitesimal Sγ λS−1 = γ λ −(i/4)ωμν[σ μν, γ λ] = γ λ + γ μω λ
μ . Building up a finite
Lorentz transformation by compounding infinitesimal transformations (just as in the
standard discussion of the rotation group in quantum mechanics), we have Sγ λS−1 =
λ
μγ μ.
Dirac bilinears
The Clifford algebra tells us that (γ 0)2 = +1 and (γ i)2 = −1; hence the necessity for the i
in (4). One consequence of the i is that γ 0 is hermitean while γ i is antihermitean, a fact
conveniently expressed as
(γ μ)† = γ 0γ μγ 0
(15)
Thus, contrary to what you might think, the bilinear ψ†γ μψ is not hermitean; rather,
¯ψγ μψ is hermitean with ¯ψ ≡ψ†γ 0. The necessity for introducing ¯ψ in addition to ψ† in
relativistic physics is traced back to the (+, −, −, −) signature of the Minkowski metric.
It follows that (σ μν)† = γ 0σ μνγ 0. Hence, S()† = γ 0e(i/4)ωμνσ μνγ 0, (which incidentally,
clearly shows that S is not unitary, a fact we knew since σ0i is not hermitean), and so
¯ψ′(x′) = ψ(x)†S()†γ 0 = ¯ψ(x)e+(i/4)ωμνσ μν.
(16)
We have
¯ψ′(x′)ψ′(x′) = ¯ψ(x)e+(i/4)ωμνσ μνe−(i/4)ωμνσ μνψ(x) = ¯ψ(x)ψ(x)
You are probably used to writing ψ†ψ in nonrelativistic physics. In relativistic physics you
have to get used to writing ¯ψψ. It is ¯ψψ, not ψ†ψ, that transforms as a Lorentz scalar.
There are obviously 16 Dirac bilinears ¯ψψ that we can form, corresponding to the 16
linearly independent ’s. You can now work out how various fermion bilinears transform
(exercise II.1.1). The notation is rather nice: Various objects transform the way it looks like
they should transform. We simply look at the Lorentz indices they carry. Thus, ¯ψ(x)γ μψ(x)
transforms as a Lorentz vector.

98 | II. Dirac and the Spinor
Parity
An important discrete symmetry in physics is that of parity or reflection in a mirror1
xμ →x′μ = (x0, −⃗x)
(17)
Multiply the Dirac equation (1) by γ 0 : γ 0(iγ μ∂μ −m)ψ(x) = 0 = (iγ μ∂′
μ −m)γ 0ψ(x),
where ∂′
μ ≡∂/∂x′μ. Thus,
ψ′(x′) ≡ηγ 0ψ(x)
(18)
satisfies the Dirac equation in the space-reflected world (where η is an arbitrary phase that
we can set to 1).
Note, for example, ¯ψ′(x′)ψ′(x′) = ¯ψ(x)ψ(x) but ¯ψ′(x′)γ 5ψ′(x′) = ¯ψ(x)γ 0γ 5 γ 0ψ(x) =
−¯ψ(x)γ 5ψ(x). Under a Lorentz transformation ¯ψ(x)γ 5ψ(x) and ¯ψ(x)ψ(x) transform in
the same way but under space reflection they transform in an opposite way; in other words,
while ¯ψ(x)ψ(x) transforms as a scalar, ¯ψ(x)γ 5ψ(x) transforms as a pseudoscalar.
You are now ready to do the all-important exercises in this chapter.
The Dirac Lagrangian
An interesting question: What Lagrangian would give Dirac’s equation? The answer is
L = ¯ψ(i̸∂−m)ψ
(19)
Since ψ is complex we can vary ψ and ¯ψ independently to obtain the Euler-Lagrange
equation of motion. Thus, ∂μ(δL/δ∂μψ) −δL/δψ = 0 gives ∂μ(i ¯ψγ μ) +m ¯ψ = 0, which
upon hermitean conjugation and multiplication by γ 0 gives the Dirac equation (1). The
other variational equation ∂μ(δL/δ∂μ ¯ψ) −δL/δ ¯ψ = 0 gives the Dirac equation even more
directly. (If you are disturbed by the asymmetric treatment of ψ and ¯ψ, you can always
integrate by parts in the action, have ∂μ act on ¯ψ in the Lagrangian, and then average the
two forms of the Lagrangian. The action S =

d4xL treats ψ and ¯ψ symmetrically.)
Slow and fast electrons
Given a set of gamma matrices it is straightforward to solve the Dirac equation
( ̸p −m)ψ(p) = 0
(20)
for ψ(p): It is a simple matrix equation (see exercise II.1.3).
1 Rotations consist of all linear transformations xi →Rijxj such that det R = +1. Those transformations with
det R = −1are composed of parity followed by a rotation. In (3 + 1)-dimensional spacetime, parity can be defined
as reversing one of the spatial coordinates or all three spatial coordinates. The two operations are related by a
rotation. Note that in odd dimensional spacetime, parity is not the same as space inversion, in which all spatial
coordinates are reversed (see exercise II.1.12).

II.1. The Dirac Equation | 99
Note that if somebody uses the gamma matrices γ μ, you are free to use instead γ ′μ =
W −1γ μW with W any 4 by 4 matrix with an inverse. Obviously, γ ′μ also satisfy the Clifford
algebra. This freedom of choice corresponds to a simple change of basis. Physics cannot
depend on the choice of basis, but which basis is the most convenient depends on the
physics.
For example, suppose we want to study a slowly moving electron. Let us use the basis
defined by (3) and (4), and the 2-component decomposition of ψ (13). Since (6) tells us
that χ(p) = 0 for an electron at rest, we expect χ(p) to be much smaller than φ(p) for a
slowly moving electron.
In contrast, for momentum much larger than the mass, we can approximate (20) by
̸pψ(p) = 0. Multiplying on the left by γ 5, we see that if ψ(p) is a solution then γ 5ψ(p)
is also a solution since γ 5 anticommutes with γ μ. Since (γ 5)2 = 1, we can form two
projection operators PL ≡1
2(1 −γ 5) and PR ≡1
2(1 + γ 5), satisfying P 2
L = PL, P 2
R = PR,
and PLPR = 0. It is extremely useful to introduce the two combinations ψL = 1
2(1 −γ 5)ψ
and ψR = 1
2(1 + γ 5)ψ. Note that γ 5ψL = −ψL and γ 5ψR = +ψR. Physically, a relativistic
electron has two degrees of freedom known as helicities: it can spin either clockwise or
anticlockwise around the direction of motion. I leave it to you as an exercise to show that
ψL and ψR correspond to precisely these two possibilities. The subscripts L and R indicate
left and right handed. Thus, for fast moving electrons, a basis known as the Weyl basis,
designed so that γ 5, rather than γ 0, is diagonal, is more convenient. Instead of (3), we
choose
γ 0 =

 0
I
I
0

= I ⊗τ1
(21)
We keep γ i as in (4). This defines the Weyl basis. We now calculate
γ 5 ≡iγ 0γ 1γ 2γ 3 = i(I ⊗τ1)(σ 1σ 2σ 3 ⊗i3τ2) = −(I ⊗τ3) =

 −I
0
0
I

(22)
which is indeed diagonal as desired. The decomposition into left and right handed fields is
of course defined regardless of what basis we feel like using, but in the Weyl basis we have
the nice feature that ψL has two upper components and ψR has two lower components.
The spinors ψL and ψR are known as Weyl spinors.
Note that in going from the Dirac to the Weyl basis γ 0 and γ 5 trade places (up to a sign):
Dirac : γ 0diagonal;
Weyl : γ 5diagonal.
(23)
Physics dictates which basis to use: We prefer to have γ 0 diagonal when we deal with
slowly moving spin 1
2 particles, while we prefer to have γ 5 diagonal when we deal with fast
moving spin 1
2 particles .
I note in passing that if we define σ μ ≡(I , ⃗σ) and ¯σ μ ≡(I , −⃗σ) we can write
γ μ =

 0
σ μ
¯σ μ
0

more compactly in the Weyl basis. (We develop this further in appendix E.)

100 | II. Dirac and the Spinor
Chirality or handedness
Regardless of whether a Dirac field ψ(x) is massive or massless, it is enormously useful to
decompose ψ into left and right handed fields ψ(x) = ψL(x) + ψR(x) ≡1
2(1 −γ 5)ψ(x) +
1
2(1 + γ 5)ψ(x). As an exercise, show that you can write the Dirac Lagrangian as
L = ¯ψ(i̸∂−m)ψ = ¯ψLi̸∂ψL + ¯ψRi̸∂ψR −m( ¯ψLψR + ¯ψRψL)
(24)
The kinetic energy connects left to left and right to right, while the mass term connects
left to right and right to left.
The transformation ψ →eiθψ leaves the Lagrangian L invariant. Applying Noether’s
theorem, we obtain the conserved current associated with this symmetry J μ = ¯ψγ μψ.
Projecting into left and right handed fields we see that they transform the same way:
ψL →eiθψL and ψR →eiθψR.
If m = 0, L enjoys an additional symmetry, known as a chiral symmetry, under which
ψ →eiφγ 5ψ. Noether’s theorem tells us that the axial current J 5μ ≡¯ψγ μγ 5ψ is conserved.
The left and right handed fields transform in opposite ways: ψL →e−iφψL and ψR →
eiφψR. These points are particularly obvious when L is written in terms of ψL and ψR, as
in (24).
In 1956 Lee and Yang proposed that the weak interaction does not preserve parity. It was
eventually realized (with these four words I brush over a beautiful chapter in the history
of particle physics; I urge you to read about it!) that the weak interaction Lagrangian has
the generic form
L = G ¯ψ1Lγ μψ2L ¯ψ3Lγμψ4L
(25)
where ψ1,2,3,4 denotes four Dirac fields and G the Fermi coupling constant. This La-
grangian clearly violates parity: Under a spatial reflection, left handed fields are trans-
formed into right handed fields and vice versa.
Incidentally, henceforth when I say a Lagrangian has a certain form, I will usually
indicate only one or more of the relevant terms in the Lagrangian, as in (25). The other
terms in the Lagrangian, such as
¯ψ1(i̸∂−m1)ψ1, are understood. If the term is not
hermitean, then it is understood that we also add its hermitean conjugate.
Interactions
As we saw in (25) given the classification of bilinears in the spinor field you worked out
in an exercise it is easy to introduce interactions. As another example, we can couple
a scalar field ϕ to the Dirac field by adding the term gϕ ¯ψψ (with g some coupling
constant) to the Lagrangian L = ¯ψ(i̸∂−m)ψ (and of course also adding the Lagrangian
for ϕ). Similarly, we can couple a vector field Aμ by adding the term eAμ ¯ψγ μψ. We
note that in this case we can introduce the covariant derivative Dμ = ∂μ −ieAμ and write

II.1. The Dirac Equation | 101
L = ¯ψ(i̸∂−m)ψ + eAμ ¯ψγ μψ = ¯ψ(iγ μDμ −m)ψ. Thus, the Lagrangian for a Dirac field
interacting with a vector field of mass μ reads
L = ¯ψ(iγ μDμ −m)ψ −1
4FμνF μν −1
2μ2AμAμ
(26)
If the mass μ vanishes, this is the Lagrangian for quantum electrodynamics. Varying with
respect to ¯ψ, we obtain the Dirac equation in the presence of an electromagnetic field:
[iγ μ(∂μ −ieAμ) −m]ψ = 0
(27)
Charge conjugation and antimatter
With coupling to the electromagnetic field, we have the concept of charge and hence of
charge conjugation. Let us try to flip the charge e. Take the complex conjugate of (27):
[−iγ μ∗(∂μ + ieAμ) −m]ψ∗= 0. Complex conjugating (2) we see that the −γ μ∗also satisfy
the Clifford algebra and thus must be the γ μ matrices expressed in a different basis, that
is, there exists a matrix Cγ 0 (the notation with an explicit factor of γ 0 is standard; see
below) such that −γ μ∗= (Cγ 0)−1γ μ(Cγ 0). Plugging in, we find that
[iγ μ(∂μ + ieAμ) −m]ψc = 0
(28)
where we have defined ψc ≡Cγ 0ψ∗. Thus, if ψ is the field of the electron, then ψc is the
field of a particle with a charge opposite to that of the electron but with the same mass,
namely the positron.
The discovery of antimatter was one of the most momentous in twentieth-century
physics. We will discuss antimatter in more detail in the next chapter.
It may be instructive to look at the specific form of the charge conjugation matrix C. We
can write the defining equation for C as Cγ 0γ μ∗γ 0C−1 = −γ μ. Complex conjugating the
equation (γ μ)† = γ 0γ μγ 0, we obtain (γ μ)T = γ 0γ μ∗γ 0 if γ 0 is real. Thus,
(γ μ)T = −C−1γ μC
(29)
which explains why C is defined with a γ 0 attached.
In both the Dirac and the Weyl bases γ 2 is the only imaginary gamma matrix. Then the
defining equation for C just says that Cγ 0 commutes with γ 2 but anticommutes with the
other three γ matrices. So evidently C = γ 2γ 0 [up to an arbitrary phase not fixed by (29)]
and indeed γ 2γ μ∗γ 2 = γ μ. Note that we have the simple (and satisfying) relation
ψc = γ 2ψ∗
(30)
You can easily convince yourself (exercise II.1.9) that the charge conjugate of a left
handed field is right handed and vice versa. As we will see later, this fact turns out to
be crucial in the construction of grand unified theory. Experimentally, it is known that the
neutrino is left handed. Thus, we can now predict that the antineutrino is right handed.

102 | II. Dirac and the Spinor
Furthermore, ψc transforms as a spinor. Let’s check: Under a Lorentz transformation
ψ →e−(i/4)ωμνσ μνψ, complex conjugating we have ψ∗→e+(i/4)ωμν(σ μν)∗ψ∗; hence ψc →
γ 2e+(i/4)ωμν(σ μν)∗ψ∗= e−(i/4)ωμνσ μνψc. [Recall from (10) that σ μν is defined with an explicit
i.]
Note that CT = γ 0γ 2 = −C in both the Dirac and the Weyl bases.
Majorana neutrino
Since ψc transforms as a spinor, Majorana2 noted that Lorentz invariance allows not only
the Dirac equation i̸∂ψ = mψ but also the Majorana equation
i̸∂ψ = mψc
(31)
Complex conjugating this equation and multiplying by γ 2, we have −γ 2iγ μ∗∂μψ∗=
γ 2m(−γ 2)ψ, that is, i̸∂ψc = mψ. Thus, −∂2ψ = i̸∂(i̸∂ψ) = i̸∂mψc = m2ψ. As we antic-
ipated, m is indeed the mass, known as a Majorana mass, of the particle associated with
ψ.
The Majorana equation (31) can be obtained from the Lagrangian3
L = ¯ψi̸∂ψ −1
2m(ψT Cψ + ¯ψC ¯ψT )
(32)
upon varying ¯ψ.
Since ψ and ψc carry opposite charge, the Majorana equation, unlike the Dirac equation,
can only be applied to electrically neutral fields. However, as ψc is right handed if ψ is left
handed, the Majorana equation, again unlike the Dirac equation, preserves handedness.
Thus, the Majorana equation is almost tailor made for the neutrino.
From its conception the neutrino was assumed to be massless, but couple of years ago
experimentalists established that it has a small but nonvanishing mass. As of this writing, it
is not known whether the neutrino mass is Dirac or Majorana. We will see in chapter VII.7
that a Majorana mass for the neutrino arises naturally in the SO(10) grand unified theory.
Finally, there is the possibility that ψ = ψc, in which case ψ is known as a Majorana
spinor.
Time reversal
Finally, we come to time reversal,4 which as you probably know, is much more confusing
to discuss than parity and charge conjugation. In a famous 1932 paper Wigner showed that
2 Ettore Majorana had a brilliant but tragically short career. In his early thirties, he disappeared off the coast
of Sicily during a boat trip. The precise cause of his death remains a mystery. See F. Guerra and N. Robotti, Ettore
Majorana: Aspects of His Scientific and Academic Activity.
3 Upon recalling that C is antisymmetric, you may have worried that ψT Cψ = Cαβψαψβ vanishes. In future
chapters we will learn that ψ has to be treated as anticommuting “Grassmannian numbers.”
4 Incidentally, I do not feel that we completely understand the implications of time-reversal invariance. See
A. Zee, “Night thoughts on consciousness and time reversal,” in: Art and Symmetry in Experimental Physics: pp.
246–249 .

II.1. The Dirac Equation | 103
time reversal is represented by an antiunitary operator. Since this peculiar feature already
appears in nonrelativistic quantum physics, it is in some sense not the responsibility of a
book on relativistic quantum field theory to explain time reversal as an antiunitary operator.
Nevertheless, let me try to be as clear as possible. I adopt the approach of “letting the
physics, namely the equations, lead us.”
Take the Schr¨odinger equation i(∂/∂t)
(t) = H
(t) (and for definiteness, think of
H = −(1/2m)∇2 + V (⃗x), just simple one particle nonrelativistic quantum mechanics.)
We suppress the dependence of 
 on ⃗x. Consider the transformation t →t′ = −t. We
want to find a 
′(t′) such that i(∂/∂t′)
′(t′) = H
′(t′). Write 
′(t′) = T 
(t), where T
is some operator to be determined (up to some arbitrary phase factor η). Plugging in, we
have i[∂/∂(−t)]T 
(t) = HT 
(t). Multiply by T −1, and we obtain T −1(−i)T (∂/∂t)
(t) =
T −1HT 
(t). Since H does not involve time in any way, we want T −1H = HT −1. Then
T −1(−i)T (∂/∂t)
(t) = H
(t). We are forced to conclude, as Wigner was, that
T −1(−i)T = i
(33)
Speaking colloquially, we can say that in quantum physics time goes with an i and so
flipping time means flipping i as well.
Let T = UK, where K complex conjugates everything to its right. Then T −1 = KU−1
and (33) holds if U−1iU = i, that is, if U−1 is just an ordinary (unitary) operator that does
nothing to i. We will determine U as we go along. The presence of K makes T “antiunitary.”
We check that this works for a spinless particle in a plane wave state 
(t) = ei(⃗k.⃗x−Et).
Plugging in, we have 
′(t′) = T 
(t) = UK
(t) = U
∗(t) = Ue−i(⃗k.⃗x−Et); since 
 has
only one component, U is just a phase factor5 η that we can choose to be 1. Rewriting, we
have 
′(t) = e−i(⃗k.⃗x+Et) = ei(−⃗k.⃗x−Et). Indeed, 
′ describes a plane wave moving in the
opposite direction. Crucially, 
′(t) ∝e−iEt and thus has positive energy as it should. Note
that acting on a spinless particle T 2 = UKUK = UU∗K2 = +1.
Next consider a spin 1
2 nonrelativistic electron. Acting with T on the spin-up state
 1
0

we want to obtain the spin-down state
 0
1

. Thus, we need a nontrivial matrix U = ησ2
to flip the spin:
T
 1
0

= U
 1
0

= iη
 0
1

Similarly, T acting on the spin-down state produces the spin-up state. Note that acting on
a spin 1
2 particle
T 2 = ησ2Kησ2K = ησ2η∗σ ∗
2 KK = −1
This is the origin of Kramer’s degeneracy: In a system with an odd number of electrons
in an electric field, no matter how complicated, each energy level is twofold degenerate.
The proof is very simple: Since the system is time reversal invariant, 
 and T 
 have the
same energy. Suppose they actually represent the same state. Then T 
 = eiα
, but then
5 It is a phase factor rather than an arbitrary complex number because we require that |
′|2 = |
|2.

104 | II. Dirac and the Spinor
T 2
 = T (T 
) = T eiα
 = e−iαT 
 = 
 ̸= −
. So 
 and T 
 must represent two distinct
states.
All of this is beautiful stuff, which as I noted earlier you could and should have learned
in a decent course on quantum mechanics. My responsibility here is to show you how it
works for the Dirac equation. Multiplying (1) by γ 0 from the left, we have i(∂/∂t)ψ(t) =
Hψ(t) with H = −iγ 0γ i∂i + γ 0m. Once again, we want i(∂/∂t′)ψ′(t′) = Hψ′(t′) with
ψ′(t′) = T ψ(t) and T some operator to be determined. The discussion above carries
over if T −1HT = H, that is, KU−1HUK = H . Thus, we require KU−1γ 0UK = γ 0 and
KU−1(iγ 0γ i)UK = iγ 0γ i. Multiplying by K on the left and on the right, we see that
we have to solve for a U such that U−1γ 0U = γ 0∗and U−1γ iU = −γ i∗. We now restrict
ourselves to the Dirac and Weyl bases, in both of which γ 2 is the only imaginary guy. Okay,
what flips γ 1 and γ 3 but not γ 0 and γ 2? Well, U = ηγ 1γ 3 (with η an arbitrary phase factor)
works:
ψ′(t′) = ηγ 1γ 3Kψ(t)
(34)
Since the γ i’s are the same in both the Dirac and the Weyl bases, in either we have from
(4)
U = η(σ 1 ⊗iτ2)(σ 3 ⊗iτ2) = ηiσ 2 ⊗1
As we expect, acting on the 2-component spinors contained in ψ, the time reversal operator
T involves multiplying by iσ 2. Note also that as in the nonrelativistic case T 2ψ = −ψ.
It may not have escaped your notice that γ 0 appears in the parity operator (18), γ 2 in
charge conjugation (30), and γ 1γ 3 in time reversal (34). If we change a Dirac particle to its
antiparticle and flip spacetime, γ 5 appears.
CPT theorem
There exists a profound theorem stating that any local Lorentz invariant field theory must
be invariant under6 CPT , the combined action of charge conjugation, parity, and time
reversal. The pedestrian proof consists simply of checking that any Lorentz invariant local
interaction you can write down [such as (25)], while it may break charge conjugation,
parity, or time reversal separately, respects CPT . The more fundamental proof involves
considerable formal machinery that I will not develop here. You are urged to read about
the phenomenological study of charge conjugation, parity, time reversal, and CPT , surely
one of the most fascinating chapters in the history of physics.7
6 A rather pedantic point, but potentially confusing to some students, is that I distinguish carefully between the
action of charge conjugation C and the matrix C: Charge conjugation C involves taking the complex conjugate of
ψ and then scrambling the components with Cγ 0. Similarly, I distinguish between the operation of time reversal
T and the matrix T .
7 See, e.g., J. J. Sakurai, Invariance Principles and Elementary Particles and E. D. Commins, Weak Interactions.

II.1. The Dirac Equation | 105
Two stories
I end this chapter with two of my favorite physics stories—one short and one long.
Paul Dirac was notoriously a man of few words. Dick Feynman told the story that when
he first met Dirac at a conference, Dirac said after a long silence, “I have an equation; do
you have one too?”
Enrico Fermi did not usually take notes, but during the 1948 Pocono conference (see
chapter I.7) he took voluminous notes during Julian Schwinger’s lecture. When he got
back to Chicago, he assembled a group consisting of two professors, Edward Teller and
Gregory Wentzel, and four graduate students, Geoff Chew, Murph Goldberger, Marshall
Rosenbluth, and Chen-Ning Yang (all to become major figures later). The group met in
Fermi’s office several times a week, a couple of hours each time, to try to figure out what
Schwinger had done. After 6 weeks, everyone was exhausted. Then someone asked, “Didn’t
Feynman also speak?” The three professors, who had attended the conference, said yes.
But when pressed, not Fermi, nor Teller, nor Wentzel could recall what Feynman had said.
All they remembered was his strange notation: p with a funny slash through it.8
Exercises
II.1.1
Show that the following bilinears in the spinor field ¯ψψ, ¯ψγ μψ, ¯ψσ μνψ, ¯ψγ μγ 5ψ, and ¯ψγ 5ψ trans-
form under the Lorentz group and parity as a scalar, a vector, a tensor, a pseudovector or axial vector, and
a pseudoscalar, respectively. [Hint: For example, ¯ψγ μγ 5ψ →¯ψ[1 + (i/4)ωσ]γ μγ 5[1 −(i/4)ωσ]ψ under
an infinitesimal Lorentz transformation and →¯ψγ 0γ μγ 5γ 0ψ under parity. Work out these transforma-
tion laws and show that they define an axial vector.]
II.1.2
Write all the bilinears in the preceding exercise in terms of ψL and ψR.
II.1.3
Solve ( ̸p −m)ψ(p) = 0 explicitly (by rotational invariance it suffices to solve it for ⃗p along the 3rd
direction, say). Verify that indeed χ is much smaller than φ for a slowly moving electron. What happens
for a fast moving electron?
II.1.4
Exploiting the fact that χ is much smaller than φ for a slowly moving electron, find the approximate
equation satisfied by φ.
II.1.5
For a relativistic electron moving along the z-axis, perform a rotation around the z-axis. In other words,
study the effect of e−(i/4)ωσ 12 on ψ(p) and verify the assertion in the text regarding ψL and ψR.
II.1.6
Solve the massless Dirac equation.
II.1.7
Show explicitly that (25) violates parity.
II.1.8
The defining equation for C evidently fixes C only up to an overall constant. Show that this constant is
fixed by requiring (ψc)c = ψ.
8 C. N. Yang, Lecture at the Schwinger Memorial Session of the American Physical Society meeting in
Washington D. C., 1995.

106 | II. Dirac and the Spinor
II.1.9
Show that the charge conjugate of a left handed field is right handed and vice versa.
II.1.10
Show that ψCψ is a Lorentz scalar.
II.1.11
Work out the Dirac equation in (1 + 1)-dimensional spacetime.
II.1.12
Work out the Dirac equation in (2 + 1)-dimensional spacetime. Show that the apparently innocuous
mass term violates parity and time reversal. [Hint: The three γ μ’s are just the three Pauli matrices with
appropriate factors of i.]

II.2
Quantizing the Dirac Field
Anticommutation
We will use the canonical formalism of chapter I.8 to quantize the Dirac field.
Long and careful study of atomic spectroscopy revealed that the wave function of two
electrons had to be antisymmetric upon exchange of their quantum numbers. It follows
that we cannot put two electrons into the same energy level so that they will have the
same quantum numbers. In 1928 Jordan and Wigner showed how this requirement of an
antisymmetric wave function can be formalized by having the creation and annihilation
operators for electrons satisfy anticommutation rather than commutation relations as in
(I.8.12).
Let us start out with a state with no electron |0⟩and denote by b†
α the operator creating
an electron with the quantum numbers α. In other words, the state b†
α |0⟩is the state
with an electron having the quantum numbers α. Now suppose we want to have another
electron with the quantum numbers β, so we construct the state b†
βb†
α |0⟩. For this to be
antisymmetric upon interchanging α and β we must have
{b†
α, b†
β} ≡b†
αb†
β + b†
βb†
α = 0
(1)
Upon hermitean conjugation, we have {bα, bβ} = 0. In particular, b†
αb†
α = 0, so that we
cannot create two electrons with the same quantum numbers.
To this anticommutation relation we add
{bα, b†
β} = δαβ
(2)
One way of arguing for this is to say that we would like the number operator to be
N = 
α b†
αbα, just as in the bosonic case. Show with one line of algebra that [AB, C] =
A[B, C] + [A, C]B or [AB, C] = A{B, C} −{A, C}B. (A heuristic way of remembering
the minus sign in the anticommuting case is that we have to move C past B in order for
C to do its anticommuting with A.) For the desired number operator to work we need
[
α b†
αbα, b†
β] = +b†
β (so that as usual N |0⟩= 0, and Nb†
β |0⟩= b†
β |0⟩) and so we have (2).

108 | II. Dirac and the Spinor
The Dirac field
Let us now turn to the free Dirac Lagrangian
L = ¯ψ(i̸∂−m)ψ
(3)
The momentum conjugate to ψ is πα = δL/δ∂tψα = iψ
†
α. We anticipate that the correct
canonical procedure requires imposing the anticommutation relation:
{ψα(⃗x, t), ψ
†
β(⃗0, t)} = δ(3)(⃗x)δαβ
(4)
We will derive this below.
The Dirac field satisfies
(i̸∂−m)ψ = 0
(5)
Plugging in plane waves u(p, s)e−ipx and v(p, s)eipx for ψ, we have
(̸p −m)u(p, s) = 0
(6)
and
(̸p + m)v(p, s) = 0
(7)
The index s = ±1 reminds us that each of these two equations has two solutions, spin
up and spin down. Evidently, under a Lorentz transformation the two spinors u and v
transform in the same way as ψ. Thus, if we define ¯u ≡u†γ 0 and ¯v ≡v†γ 0, then ¯uu and
¯vv are Lorentz scalars.
This subject is full of “peculiar” signs and so I will proceed very carefully and show you
how every sign makes sense.
First, since (6) and (7) are linear we have to fix the normalization of u and v. Since
¯u(p, s)u(p, s) and ¯v(p, s)v(p, s) are Lorentz scalars, the normalization condition we
impose on them in the rest frame will hold in any frame.
Our strategy is to do things in the rest frame using a particular basis and then invoke
Lorentz invariance and basis independence. In the rest frame, (6) and (7) reduce to
(γ 0 −1)u = 0 and (γ 0 + 1)v = 0. In particular, in the Dirac basis γ 0 =
 I
0
0
−I

, so the
two independent spinors u (labeled by spin s = ±1) have the form
⎛
⎜⎜⎜⎜⎜⎝
1
0
0
0
⎞
⎟⎟⎟⎟⎟⎠
and
⎛
⎜⎜⎜⎜⎜⎝
0
1
0
0
⎞
⎟⎟⎟⎟⎟⎠

II.2. Quantizing the Dirac Field | 109
while the two independent spinors v have the form
⎛
⎜⎜⎜⎜⎜⎝
0
0
1
0
⎞
⎟⎟⎟⎟⎟⎠
and
⎛
⎜⎜⎜⎜⎜⎝
0
0
0
1
⎞
⎟⎟⎟⎟⎟⎠
The normalization conditions we have implicitly chosen are then ¯u(p, s)u(p, s) = 1 and
¯v(p, s)v(p, s) = −1. Note the minus sign thrust upon us. Clearly, we also have the orthog-
onality condition ¯uv = 0 and ¯vu = 0. Lorentz invariance and basis independence then tell
us that these four relations hold in general.
Furthermore, in the rest frame

s
uα(p, s)¯uβ(p, s) =
 I
0
0
0

αβ
= 1
2(γ 0 + 1)αβ
and

s
vα(p, s)¯vβ(p, s) =
 0
0
0
−I

αβ
= 1
2(γ 0 −1)αβ
Thus, in general

s
uα(p, s)¯uβ(p, s) =
 ̸p + m
2m

αβ
(8)
and

s
vα(p, s)¯vβ(p, s) =
 ̸p −m
2m

αβ
(9)
Another way of deriving (8) is to note that the left hand side is a 4 by 4 matrix (it is like a
column vector multiplied by a row vector on the right) and so must be a linear combination
of the sixteen 4 by 4 matrices we listed in chapter II.1. Argue that γ 5 and γ μγ 5 are ruled out
by parity and that σ μν is ruled out by Lorentz invariance and the fact that only one Lorentz
vector, namely pμ, is available. Hence the right hand side must be a linear combination of
̸p and m. Fix the relative coefficient by acting with ̸p −m from the left. The normalization
is fixed by setting α = β and summing over α. Similarly for (9). In particular, setting α = β
and summing over α, we recover ¯v(p, s)v(p, s) = −1.
We are now ready to promote ψ(x) to an operator. In analogy with (I.8.11) we expand
the field in plane waves1
ψα(x) =

d3p
(2π)
3
2(Ep/m)
1
2

s
[b(p, s)uα(p, s)e−ipx + d
†(p, s)vα(p, s)eipx]
(10)
(Here Ep = p0 = +

⃗p2 + m2 and px = pμxμ.) The normalization factor (Ep/m)
1
2 is
slightly different from that in (I.8.11) for reasons we will see. Otherwise, the rationale
1 The notation is standard. See e.g., J. A. Bjorken and S. D. Drell, Relativistic Quantum Mechanics.

110 | II. Dirac and the Spinor
for (10) is essentially the same as in (I.8.11). We integrate over momentum ⃗p, sum over
spin s, expand in plane waves, and give names to the coefficients in the expansion. Because
ψ is complex, we have, similar to the complex scalar field in chapter I.8, a b operator and
a d† operator.
Just as in chapter I.8, the operators b and d† must carry the same charge. Thus, if b
annihilates an electron with charge e = −|e|, d† must remove charge e; that is, it creates
a positron with charge −e = |e|.
A word on notation: in (10) b(p, s), d
†(p, s), u(p, s), and v(p, s) are written as functions
of the 4-momentum p but strictly speaking they are functions of ⃗p only, with p0 always
understood to be +

⃗p2 + m2.
Thus let b
†(p, s) and b(p, s) be the creation and annihilation operators for an electron
of momentum p and spin s. Our introductory discussion indicates that we should impose
{b(p, s), b
†(p′, s′)} = δ(3)( ⃗p −⃗p ′)δss′
(11)
{b(p, s), b(p′, s′)} = 0
(12)
{b
†(p, s), b
†(p′, s′)} = 0
(13)
There is a corresponding set of relations for d†(p, s) and d(p, s) the creation and annihi-
lation operators for a positron, for instance,
{d(p, s), d†(p′, s′)} = δ(3)( ⃗p −⃗p ′)δss′
(14)
We now have to show that we indeed obtain (4). Write
¯ψ(0) =

d3p′
(2π)
3
2(Ep′/m)
1
2

s′
[b†(p′, s′)¯u(p′, s′) + d(p′, s′)¯v(p′, s′)]
Nothing to do but to plow ahead:
{ψ(⃗x, 0), ¯ψ(0)}
=

d3p
(2π)3(Ep/m)

s
[u(p, s)¯u(p, s)ei ⃗p.⃗x + v(p, s)¯v(p, s)e−i ⃗p.⃗x]
if we take b and b† to anticommute with d and d†. Using (8) and (9) we obtain
{ψ(⃗x, 0), ¯ψ(0)} =

d3p
(2π)3(2Ep)[(̸p + m)ei ⃗p.⃗x + (̸p −m)e−i ⃗p.⃗x]
=

d3p
(2π)3(2Ep)2p0γ 0e−i ⃗p.⃗x = γ 0δ(3)(⃗x)
which is just (4) slightly disguised.
Similarly, writing schematically, we have {ψ, ψ} = 0 and {ψ
†, ψ
†} = 0.
We are of course free to normalize the spinors u and v however we like. One alternative
normalization is to define u and v as the u and v given here multiplied by (2m)
1
2, thus
changing (8) and (9) to 
su¯u ≠p + m and 
sv ¯v ≠p −m. Multiplying the numerator and
denominator in (10) by (2m)
1
2, we see that the normalization factor (Ep/m)
1
2 is changed to
(2Ep)
1
2 [thus making it the same as the normalization factor for the scalar field in (I.8.11)].

II.2. Quantizing the Dirac Field | 111
This alternative normalization (let us call it “any mass normalization”) is particularly
convenient when we deal with massless spin- 1
2 particles: we could set m = 0 everywhere
without ever encountering m in the denominator as in (8) and (9).
The advantage of the normalization used here (let us call it “rest normalization”) is that
the spinors assume simple forms in the rest frame, as we have just seen. This would prove
to be advantageous when we calculate the magnetic moment of the electron in chapter
III.6, for example. Of course, multiplying and dividing here and there by (2m)
1
2 is a trivial
operation, and there is not much sense in arguing over the relative advantages of one
normalization over another.
In chapter II.6 we will calculate electron scattering at energies high compared to the
mass m, so that effectively we could set m = 0. Actually, even then, “rest normalization”
has the slight advantage of providing a (rather weak) check on the calculation. We set m = 0
everywhere we can, such as in the numerator of (8) and (9), but not where we can’t, such as
in the denominator. Then m must cancel out in physical quantities such as the differential
scattering cross section.
Energy of the vacuum
An important exercise at this point is to calculate the Hamiltonian starting with the
Hamiltonian density
H = π ∂ψ
∂t −L = ¯ψ(i ⃗γ . ⃗∂+ m)ψ
(15)
Inserting (10) into this expression and integrating, we have
H =

d3xH =

d3x ¯ψ(i ⃗γ . ⃗∂+ m)ψ =

d3x ¯ψiγ 0 ∂ψ
∂t
(16)
which works out to be
H =

d3p

s
Ep[b
†(p, s)b(p, s) −d(p, s)d
†(p, s)]
(17)
We can see the all important minus sign in (17) schematically: In (16) ¯ψ gives a factor
∼(b
† + d), while ∂/∂t acting on ψ brings down a relative minus sign giving ∼(b −d
†),
thus giving us ∼(b
† + d)(b −d
†) ∼b
†b −dd
† (orthogonality between spinors vu = 0 kills
the cross terms).
To bring the second term in (17) into the right order, we anticommute −d(p, s)d
†(p, s)
= d
†(p, s)d(p, s) −δ(3)(⃗0) so that
H =

d3p

s
Ep[b
†(p, s)b(p, s) + d
†(p, s)d(p, s)]
−δ(3)(⃗0)

d3p

s
Ep
(18)
The first two terms tell us that each electron and each positron of momentum p and spin
s has exactly the same energy Ep, as it should. But what about the last term? That δ(3)(⃗0)
should fill us with fear and loathing.

112 | II. Dirac and the Spinor
It is OK: Noting that δ(3)( ⃗p) = [1/(2π)3]

d3xei ⃗p⃗x, we see that δ(3)(⃗0) = [1/(2π)3]

d3x
(we encounter the same maneuver in exercise I.8.2) and so the last term contributes to H
E0 = −1
h3

d3x

d3p

s
2( 1
2Ep)
(19)
(since in natural units we have ℏ= 1 and hence h = 2π). We have an energy −1
2Ep in each
unit-size phase-space cell (1/h3)d3x d3p in the sense of statistical mechanics, for each spin
and for the electron and positron separately (hence the factor of 2) . This infinite additive
term E0 is precisely the analog of the zero point energy 1
2ℏω of the harmonic oscillator you
encountered in your quantum mechanics course. But it comes in with a minus sign!
The sign is bizarre and peculiar! Each mode of the Dirac field contributes −1
2ℏω to
the vacuum energy. In contrast, each mode of a scalar field contributes 1
2ℏω as we saw
in chapter I.8. This fact is of crucial importance in the development of supersymmetry,
which we will discuss in chapter VIII.4.
Fermion propagating through spacetime
In analogy with (I.8.14), the propagator for the electron is given by iSαβ(x) ≡
⟨0|T ψα(x) ¯ψβ(0)|0⟩, where the argument of ¯ψ has been set to 0 by translation invariance.
As we will see, the anticommuting character of ψ requires us to define the time-ordered
product with a minus sign, namely
T ψ(x) ¯ψ(0) ≡θ(x0)ψ(x) ¯ψ(0) −θ(−x0) ¯ψ(0)ψ(x)
(20)
Referring to (10), we obtain for x0 > 0,
iS(x) = ⟨0|ψ(x) ¯ψ(0)|0⟩=

d3p
(2π)3(Ep/m)

s
u(p, s)¯u(p, s)e−ipx
=

d3p
(2π)3(Ep/m)
̸p + m
2m
e−ipx
For x0 < 0, we have to be a bit careful about the spinorial indices:
iSαβ(x) = −⟨0| ¯ψβ(0)ψα(x)|0⟩
= −

d3p
(2π)3(Ep/m)

s
¯vβ(p, s)vα(p, s)e−ipx
= −

d3p
(2π)3(Ep/m)( ̸p −m
2m
)αβe−ipx
using the identity (9).
Putting things together we obtain
iS(x) =

d3p
(2π)3(Ep/m)

θ(x0) ̸p + m
2m
e−ipx −θ(−x0) ̸p −m
2m
e+ipx

(21)
We will now show that this fermion propagator can be written more elegantly as a
4-dimensional integral:

II.2. Quantizing the Dirac Field | 113
iS(x) = i

d4p
(2π)4 e−ip.x
̸p + m
p2 −m2 + iε =

d4p
(2π)4 e−ip.x
i
̸p −m + iε
(22)
To show that (22) is indeed equivalent to (21) we go through essentially the same steps as
after (I.8.14). In the complex p0 plane the integrand has poles at p0 = ±

⃗p2 + m2 −iε ≃
±(Ep −iε). For x0 > 0 the factor e−ip0x0 tells us to close the contour in the lower half-plane.
We go around the pole at +(Ep −iε) clockwise and obtain
iS(x) = (−i)i

d3p
(2π)3e−ip.x ̸p + m
2Ep
producing the first term in (21). For x0 < 0 we are now told to close the contour in the
upper half-plane and thus we go around the pole at −(Ep −iε) anticlockwise. We obtain
iS(x) = i2

d3p
(2π)3e+iEpx0+i ⃗p.⃗x
1
−2Ep
(−Epγ 0 −⃗p ⃗γ + m)
and flipping ⃗p we have
iS(x) = −

d3p
(2π)3eip.x
1
2Ep
(Epγ 0 −⃗p ⃗γ −m) = −

d3p
(2π)3eip.x
1
2Ep
( ̸p −m)
precisely the second term in (21) with the minus sign and all. Thus, we must define the
time-ordered product with the minus sign as in (20).
After all these steps, we see that in momentum space the fermion propagator has the
elegant form
iS(p) =
i
̸p −m + iε
(23)
This makes perfect sense: S(p) comes out to be the inverse of the Dirac operator ̸p −m,
just as the scalar boson propagator D(k) = 1/(k2 −m2 + iε) is the inverse of the Klein-
Gordon operator k2 −m2.
Poetic but confusing metaphors
In closing this chapter let me ask you some rhetorical questions. Did I speak of an
electron going backward in time? Did I mumble something about a sea of negative energy
electrons? This metaphorical language, when used by brilliant minds, the likes of Dirac
and Feynman, was evocative and inspirational, but unfortunately confused generations
of physics students and physicists. The presentation given here is in the modern spirit,
which seeks to avoid these potentially confusing metaphors.
Exercises
II.2.1
Use Noether’s theorem to derive the conserved current J μ = ¯ψγ μψ. Calculate [Q, ψ], thus showing that
b and d† must carry the same charge.
II.2.2
Quantize the Dirac field in a box of volume of V and show that the vacuum energy E0 is indeed
proportional to V . [Hint: The integral over momentum

d3p is replaced by a sum over discrete values
of the momentum.]

II.3
Lorentz Group and Weyl Spinors
The Lorentz algebra
In chapter II.1 we followed Dirac’s brilliantly idiosyncratic way of deriving his equation.
We develop here a more logical and mathematical theory of the Dirac spinor. A deeper
understanding of the Dirac spinor not only gives us a certain satisfaction, but is also
indispensable, as we will see later, in studying supersymmetry, one of the foundational
concepts of superstring theory; and of course, most of the fundamental particles such as
the electron and the quarks carry spin 1
2 and are described by spinor fields.
Let us begin by reminding ourselves how the rotation group works. The three generators
Ji (i = 1, 2, 3 or x, y, z) of the rotation group satisfy the commutation relation
[Ji, Jj] = iϵijkJk
(1)
When acting on the spacetime coordinates, written as a column vector
⎛
⎜⎜⎜⎜⎜⎝
x0
x1
x2
x3
⎞
⎟⎟⎟⎟⎟⎠
the generators of rotations are represented by the hermitean matrices
J1 =
⎛
⎜⎜⎜⎜⎜⎝
0
0
0
0
0
0
0
0
0
0
0
−i
0
0
i
0
⎞
⎟⎟⎟⎟⎟⎠
(2)
with J2 and J3 obtained by cyclic permutations. You should verify by laboriously multi-
plying these three matrices that (1) is satisfied. Note that the signs of Ji are fixed by the
commutation relation (1).

II.3. Lorentz Group and Spinors | 115
Now add the Lorentz boosts. A boost in the x ≡x1 direction transforms the spacetime
coordinates:
t′ = (cosh ϕ) t + (sinh ϕ) x;
x′ = (sinh ϕ) t + (cosh ϕ) x
(3)
or for infinitesimal ϕ
t′ = t + ϕ x;
x′ = x + ϕ t
(4)
In other words, the infinitesimal generator of a Lorentz boost in the x direction is repre-
sented by the hermitean matrix (x0 ≡t as usual)
iK1 =
⎛
⎜⎜⎜⎜⎜⎝
0
1
0
0
1
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟⎟⎟⎟⎟⎠
(5)
Similarly,
iK2 =
⎛
⎜⎜⎜⎜⎜⎝
0
0
1
0
0
0
0
0
1
0
0
0
0
0
0
0
⎞
⎟⎟⎟⎟⎟⎠
(6)
I leave it to you to write down K3. Note that Ki is defined to be antihermitean.
Check that [Ji, Kj] = iϵijkKk. To see that this implies that the boost generators Ki
transform as a 3-vector ⃗K under rotation, as you would expect, apply a rotation through
an infinitesimal angle θ around the 3-axis. Then (you might wish to review the material in
appendix B at this point) K1 →eiθJ3K1e−iθJ3 = K1 + iθ[J3, K1] + O(θ2) = K1 + iθ(iK2) +
O(θ2) = cosθ K1 −sinθ K2 to the order indicated.
You are now about to do one of the most significant calculations in the history of
twentieth century physics. By brute force compute [K1, K2], evidently an antisymmetric
matrix. You will discover that it is equal to −iJ3. Two Lorentz boosts produce a rotation!
(You might recall from your course on electromagnetism that this mathematical fact is
responsible for the physics of the Thomas precession.)
Mathematically, the generators of the Lorentz group satisfy the following algebra [known
to the cognoscenti as SO(3, 1)]:
[Ji, Jj] = iϵijkJk
(7)
[Ji, Kj] = iϵijkKk
(8)
[Ki, Kj] = −iϵijkJk
(9)
Note the all-important minus sign!

116 | II. Dirac and the Spinor
How do we study this algebra? The crucial observation is that the algebra falls apart into
two pieces if we form the combinations J±i ≡1
2(Ji ± iKi). You should check that
[J+i, J+j] = iϵijkJ+k
(10)
[J−i, J−j] = iϵijkJ−k
(11)
and most remarkably
[J+i, J−j] = 0
(12)
This last commutation relation tells us that J+ and J−form two separate SU(2) algebras.
(For more, see appendix B.)
From algebra to representation
This means that you can simply use what you have already learned about angular mo-
mentum in elementary quantum mechanics and the representation of SU(2) to deter-
mine all the representations of SO(3, 1). As you know, the representations of SU(2)
are labeled by j = 0, 1
2 , 1, 3
2 , . . . . We can think of each representation as consisting of
(2j + 1) objects ψm with m = −j , −j + 1, . . . , j −1, j that transform into each other
under SU(2). It follows immediately that the representations of SO(3, 1) are labeled by
(j+, j−) with j+ and j−each taking on the values 0, 1
2, 1, 3
2, . . . . Each representation
consists of (2j+ + 1)(2j−+ 1) objects ψm+m−with m+ = −j+, −j+ + 1, . . . , j+ −1, j+
and m−= −j−, −j−+ 1, . . . , j−−1, j−.
Thus, the representations of SO(3, 1) are (0, 0), ( 1
2, 0), (0, 1
2), (1, 0), (0, 1), ( 1
2, 1
2), and
so on, in order of increasing dimension. We recognize the 1-dimensional representation
(0, 0) as clearly the trivial one, the Lorentz scalar. By counting dimensions, we expect
that the 4-dimensional representation ( 1
2 , 1
2) has to be the Lorentz vector, the defining
representation of the Lorentz group (see exercise II.3.1).
Spinor representations
What about the representation ( 1
2, 0)? Let us write the two objects as ψα with α = 1, 2.
Well, what does the notation ( 1
2, 0) mean? It says that J+i = 1
2(Ji + iKi) acting on ψα is
represented by 1
2σi while J−i = 1
2(Ji −iKi) acting on ψα is represented by 0. By adding
and subtracting we find that
Ji = 1
2σi
(13)
and
iKi = 1
2σi
(14)

II.3. Lorentz Group and Spinors | 117
where the equal sign means “represented by” in this context. (By convention we do not
distinguish between upper and lower indices on the 3-dimensional quantities Ji, Ki, and
σi.) Note again that Ki is anti-hermitean.
Similarly, let us denote the two objects in (0, 1
2) by the peculiar symbol ¯χ ˙α. I should em-
phasize the trivial but potentially confusing point that unlike the bar used in chapter II.1,
the bar on ¯χ ˙αis a typographical element: Think of the symbol ¯χ as a letter in the Hittite
alphabet if you like. Similarly, the symbol ˙α bears no relation to α: we do not obtain ˙α
by operating on α in any way. The rather strange notation is known informally as “dotted
and undotted” and more formally as the van der Waerden notation—a bit excessive for our
rather modest purposes at this point but I introduce it because it is the notation used in
supersymmetric physics and superstring theory. (Incidentally, Dirac allegedly said that he
wished he had invented the dotted and undotted notation.) Repeating the same steps as
above, you will find that on the representation (0, 1
2) we have Ji = 1
2σi and iKi = −1
2σi.
The minus sign is crucial.
The 2-component spinors ψα and ¯χ ˙αare called Weyl spinors and furnish perfectly good
representations of the Lorentz group. Why then does the Dirac spinor have 4 components?
The reason is parity. Under parity, ⃗x →−⃗x and ⃗p →−⃗p, and thus ⃗J →⃗J and ⃗K →−⃗K,
and so ⃗J+ ↔⃗J−. In other words, under parity the representations ( 1
2 , 0) ↔(0, 1
2). There-
fore, to describe the electron we must use both of these 2-dimensional representations, or
in mathematical notation, the 4-dimensional reducible representation ( 1
2 , 0) ⊕(0, 1
2).
We thus stack two Weyl spinors together to form a Dirac spinor

 =
 ψα
¯χ ˙α

(15)
The spinor 
(p) is of course a function of 4-momentum p [and by implication also ψα(p)
and ¯χ ˙α(p)] but we will suppress the p dependence for the time being. Referring to (13)
and (14) we see that acting on 
 the generators of rotation
⃗J =
 1
2 ⃗σ
0
0
1
2 ⃗σ

where once again the equality means “represented by,” and the generators of boost
i ⃗K =
 1
2 ⃗σ
0
0
−1
2 ⃗σ

Note once again the all-important minus sign.
Parity forces us to have a 4-component spinor but we know on the other hand that the
electron has only two physical degrees of freedom. Let us go to the rest frame. We must
project out two of the components contained in 
(pr) with the rest momentum pr ≡
(m, ⃗0). With the benefit of hindsight, we write the projection operator as P = 1
2(1 −γ 0).
You are probably guessing from the notation that γ 0 will turn out to be one of the gamma
matrices, but at this point, logically γ 0 is just some 4 by 4 matrix. The condition P2 = P
implies that (γ 0)2 = 1so that the eigenvalues of γ 0 are ±1. Since ψα ↔¯χ ˙α under parity we
naturally guess that ψα and ¯χ ˙αcorrespond to the left and right handed fields of chapter II.1.

118 | II. Dirac and the Spinor
We cannot simply use the projection to set for example ¯χ ˙αto 0. Parity means that we should
treat ψα and ¯χ ˙αon the same footing. We choose
γ 0 =
 0
1
1
0

,
or more explicitly
⎛
⎜⎜⎜⎜⎜⎝
0
0
1
0
0
0
0
1
1
0
0
0
0
1
0
0
⎞
⎟⎟⎟⎟⎟⎠
(Different choices of γ 0 correspond to the different basis choices discussed in chapter II.1.)
In other words, in the rest frame ψα−¯χ ˙α = 0. The projection to two degrees of freedom
can be written as
(γ 0 −1)
(pr) = 0
(16)
Indeed, we recognize this as just the Weyl basis introduced in chapter II.1.
The Dirac equation
We have derived the Dirac equation, a bit in disguise!
Since our derivation is based on a step-by-step study of the spinor representation of the
Lorentz group, we know how to obtain the equation satisfied by 
(p) for any p: We simply
boost. Writing 
(p) = e−i ⃗ϕ ⃗K
(pr), we have (e−i ⃗ϕ ⃗Kγ 0ei ⃗ϕ ⃗K −1)
(p) = 0. Introducing the
notation γ μpμ/m ≡e−i ⃗ϕ ⃗Kγ 0ei ⃗ϕ ⃗K, we obtain the Dirac equation
(γ μpμ −m)
(p) = 0
(17)
You can work out the details as an exercise.
The derivation here represents the deep group theoretic way of looking at the Dirac
equation: It is a projection boosted into an arbitrary frame.
Note that this is an example of the power of symmetry, which pervades modern physics
and this book: Our knowledge of how the electron field transforms under the rotation
group, namely that it has spin 1
2 , allows us to know how it transforms under the Lorentz
group. Symmetry rules!
In appendix E we will develop the dotted and undotted notation further for later use in
the chapter on supersymmetry.
In light of your deeper group theoretic understanding it is a good idea to reread chap-
ter II.1 and compare it with this chapter.

II.3. Lorentz Group and Spinors | 119
Exercises
II.3.1
Show by explicit computation that ( 1
2 , 1
2) is indeed the Lorentz vector.
II.3.2
Work out how the six objects contained in the (1, 0) and (0, 1) transform under the Lorentz group.
Recall from your course on electromagnetism how the electric and magnetic fields ⃗E and ⃗B transform.
Conclude that the electromagnetic field in fact transforms as (1, 0) ⊕(0, 1). Show that it is parity that
once again forces us to use a reducible representation.
II.3.3
Show that
e−i ⃗ϕ ⃗Kγ 0ei ⃗ϕ ⃗K =
 0
e−⃗ϕ⃗σ
e ⃗ϕ⃗σ
0

and
e ⃗ϕ⃗σ = cosh ϕ + ⃗σ . ˆϕ sinh ϕ
with the unit vector ˆϕ ≡⃗ϕ/ϕ. Identifying ⃗p = m ˆϕ sinh ϕ, derive the Dirac equation. Show that
γ i =
 0
σi
−σi
0

II.3.4
Show that a spin 3
2 particle can be described by a vector-spinor 
αμ, namely a Dirac spinor carrying a
Lorentz index. Find the corresponding equations of motion, known as the Rarita-Schwinger equations.
[Hint: The object 
αμ has 16 components, which we need to cut down to 2 . 3
2 + 1 = 4 components.]

II.4
Spin-Statistics Connection
There is no one fact in the physical world which has
a greater impact on the way things are, than the Pauli
exclusion principle.1
Degrees of intellectual incompleteness
In a course on nonrelativistic quantum mechanics you learned about the Pauli exclusion
principle2 and its later generalization stating that particles with half integer spins, such as
electrons, obey Fermi-Dirac statistics and want to stay apart, while in contrast particles with
integer spins, such as photons or pairs of electrons, obey Bose-Einstein statistics and love
to stick together. From the microscopic structure of atoms to the macroscopic structure
of neutron stars, a dazzling wealth of physical phenomena would be incomprehensible
without this spin-statistics rule. Many elements of condensed matter physics, for instance,
band structure, Fermi liquid theory, superfluidity, superconductivity, quantum Hall effect,
and so on and so forth, are consequences of this rule.
Quantum statistics, one of the most subtle concepts in physics, rests on the fact that in
the quantum world, all elementary particles and hence all atoms, are absolutely identical
to, and thus indistinguishable from, one other.3 It should be recognized as a triumph of
quantum field theory that it is able to explain absolute identity and indistinguishability
easily and naturally. Every electron in the universe is an excitation in one and the same
electron field ψ. Otherwise, one might be able to imagine that the electrons we now
1 I. Duck and E. C. G. Sudarshan, Pauli and the Spin-Statistics Theorem, p. 21.
2 While a student in Cambridge, E. C. Stoner came to within a hair of stating the exclusion principle.
Pauli himself in his famous paper (Zeit. f. Physik 31: 765, 1925) only claimed to “summarize and generalize
Stoner’s idea.” However, later in his Nobel Prize lecture Pauli was characteristically ungenerous toward Stoner’s
contribution. A detailed and fascinating history of the spin and statistics connection may be found in Duck and
Sudarshan, op. cit.
3 Early in life, I read in one of George Gamow’s popular physics books that he could not explain quantum
statistics—all he could manage for Fermi statistics was an analogy, invoking Greta Garbo’s famous remark “I
vont to be alone.”—and that one would have to go to school to learn about it. Perhaps this spurs me, later in life,
to write popular physics books also. See A. Zee, Einstein’s Universe, p. x.

II.4. Spin-Statistics Connection | 121
know came off an assembly line somewhere in the early universe and could all be slightly
different owing to some negligence in the manufacturing process.
While the spin-statistics rule has such a profound impact in quantum mechanics, its
explanation had to wait for the development of relativistic quantum field theory. Imagine
a civilization that for some reason developed quantum mechanics but has yet to discover
special relativity. Physicists in this civilization eventually realize that they have to invent
some rule to account for the phenomena mentioned above, none of which involves motion
fast compared to the speed of light. Physics would have been intellectually unsatisfying
and incomplete.
One interesting criterion in comparing different areas of physics is their degree of
intellectual incompleteness.
Certainly, in physics we often accept a rule that cannot be explained until we move to the
next level. For instance, in much of physics, we take as a given the fact that the charge of the
protonandthechargeofelectron areexactlyequalandopposite.Quantumelectrodynamics
by itself is not capable of explaining this striking fact either. This fact, charge quantization,
can only be deduced by embedding quantum electrodynamics into a larger structure, such
as a grand unified theory, as we will see in chapter VII.6. (In chapter IV.4 we will learn that
the existence of magnetic monopoles implies charge quantization, but monopoles do not
exist in pure quantum electrodynamics.)
Thus, the explanation of the spin-statistics connection, by Fierz and by Pauli in the late
1930s, and by L¨uders and Zumino and by Burgoyne in the late 1950s, ranks as one of the
great triumphs of relativistic quantum field theory. I do not have the space to give a general
and rigorous proof 4 here. I will merely sketch what goes terribly wrong if we violate the
spin-statistics connection.
The price of perversity
A basic quantum principle states that if two observables commute then they are simul-
taneously diagonalizable and hence observable. A basic relativistic principle states that if
two spacetime points are spacelike with respect to each other then no signal can propagate
between them, and hence the measurement of an observable at one of the points cannot
influence the measurement of another observable at the other point.
Consider the charge density J0 = i(ϕ†∂0ϕ −∂0ϕ†ϕ) in a charged scalar field theory.
According to the two fundamental principles just enunciated, J0(⃗x, t = 0) and J0(⃗y, t = 0)
should commute for ⃗x ̸= ⃗y. In calculating the commutator of J0(⃗x, t = 0) with J0(⃗y, t = 0),
we simply use the fact that ϕ(⃗x, t = 0) and ∂0ϕ(⃗x, t = 0) commute with ϕ(⃗y, t = 0) and
∂0ϕ(⃗y, t = 0), so we just move the field at ⃗x steadily past the field at ⃗y. The commutator
vanishes almost trivially.
4 See I. Duck and E. C. G. Sudarshan, Pauli and the Spin-Statistics Theorem, and R. F. Streater and A. S.
Wightman, PCT, Spin Statistics, and All That.

122 | II. Dirac and the Spinor
Now suppose we are perverse and quantize the creation and annihilation operators in
the expansion (I.8.11)
ϕ(⃗x, t = 0) =

dDk

(2π)D2ωk
[a(⃗k)ei⃗k.⃗x + a†(⃗k)e−i⃗k.⃗x]
(1)
according to anticommutation rules
{a(⃗k), a†(⃗q)} = δ(D)(⃗k −⃗q)
and
{a(⃗k), a(⃗q)} = 0 = {a†(⃗k), a†(⃗q)}
instead of the correct commutation rules.
What is the price of perversity?
Now when we try to move J0(⃗y, t = 0) past J0(⃗x, t = 0), we have to move the field at ⃗y
past the field at ⃗x using the anticommutator
{ϕ(⃗x, t = 0), ϕ(⃗y, t = 0)}
=
 
dDk

(2π)D2ωk
dDq

(2π)D2ωq
{[a(⃗k)ei⃗k.⃗x + a†(⃗k)e−i⃗k.⃗x], [a(⃗q)ei ⃗q.⃗y + a†(⃗q)e−i⃗q.⃗y]}
=

dDk
(2π)D2ωk
(ei⃗k.(⃗x−⃗y) + e−i⃗k.(⃗x−⃗y))
(2)
You see the problem? In a normal scalar-field theory that obeys the spin-statistics
connection, we would have computed the commutator, and then in the last expression
in (2) we would have gotten (ei⃗k.(⃗x−⃗y) −e−i⃗k.(⃗x−⃗y)) instead of (ei⃗k.(⃗x−⃗y) + e−i⃗k.(⃗x−⃗y)). The
integral

dDk
(2π)D2ωk
(ei⃗k.(⃗x−⃗y) −e−i⃗k.(⃗x−⃗y))
would obviously vanish and all would be well. With the plus sign, we get in (2) a nonvan-
ishing piece of junk. A disaster if we quantize the scalar field as anticommuting! A spin 0
field has to be commuting. Thus, relativity and quantum physics join hands to force the
spin-statistics connection.
It is sometimes said that because of electromagnetism you do not sink through the floor
and because of gravity you do not float to the ceiling, and you would be sinking or floating
in total darkness were it not for the weak interaction, which regulates stellar burning.
Without the spin-statistics connection, electrons would not obey Pauli exclusion. Matter
would just collapse.5
Exercise
II.4.1
Show that we would also get into trouble if we quantize the Dirac field with commutation instead of
anticommutation rules. Calculate the commutator [J 0(⃗x, 0), J 0(0)].
5 The proof of the stability of matter, given by Dyson and Lenard, depends crucially on Pauli exclusion.

II.5
Vacuum Energy, Grassmann Integrals,
and Feynman Diagrams for Fermions
The vacuum is a boiling sea of nothingness, full of sound
and fury, signifying a great deal.
—Anonymous
Fermions are weird
I developed the quantum field theory of a scalar field ϕ(x) first in the path integral
formalism and then in the canonical formalism. In contrast, I have thus far developed
the quantum field theory of the free spin 1
2 field ψ(x) only in the canonical formalism.
We learned that the spin-statistics connection forces the field operator ψ(x) to satisfy
anticommutation relations. This immediately suggests something of a mystery in writing
down the path integral for the spinor field ψ. In the path integral formalism ψ(x) is not an
operator but merely an integration variable. How do we express the fact that its operator
counterpart in the canonical formalism anticommutes?
We presumably cannot represent ψ as a commuting variable, as we did ϕ.Indeed, we will
discover that in the path integral formalism ψ is to be treated not as an ordinary complex
number but as a novel kind of mathematical entity known as a Grassmann number.
If you thought about it, you would realize that some novel mathematical structure is
needed. In chapter I.3 we promoted the coordinates of point particles qi(t) in quantum
mechanics to the notion of a scalar field ϕ(⃗x, t). But you already know from quantum
mechanics that a spin 1
2 particle has the peculiar property that its wave function turns into
minus itself when rotated through 2π. Unlike particle coordinates, half integral spin is
not an intuitive concept.
Vacuum energy
To motivate the introduction of Grassmann-valued fields I will discuss the notion of
vacuum energy. The reason for this apparently strange strategy will become clear shortly.
Quantum field theory was first developed to describe the scattering of photons and
electrons, and later the scattering of particles. Recall that in chapter I.7 while studying the

124 | II. Dirac and the Spinor
scattering of particles we encountered diagrams describing vacuum fluctuations, which
we simply neglected (see fig. I.7.12). Quite naturally, particle physicists considered these
fluctuations to be of no importance. Experimentally, we scatter particles off each other. Who
cares about fluctuations in the vacuum somewhere else? It was only in the early 1970s that
physicists fully appreciated the importance of vacuum fluctuations. We will come back to
the importance of the vacuum1 in a later chapter.
In chapters I.8 and II.2 we calculated the vacuum energy of a free scalar field and of a free
spinor field using the canonical formalism. To motivate the use of Grassmann numbers
to formulate the path integral for the spinor field I will adopt the following strategy. First,
I use the path integral formalism to obtain the result we already have for the free scalar
field using the canonical formalism. Then we will see that in order to produce the result
we already have for the free spinor field we must modify the path integral.
By definition, vacuum fluctuations occur even when there are no sources to produce
particles. Thus, let us consider the generating functional of a free scalar field theory in the
absence of sources:2
Z =

Dϕei 
d4x 1
2 [(∂ϕ)2−m2ϕ2] = C

1
det[∂2 + m2]
 1
2
= Ce−1
2 Tr log(∂2+m2)
(1)
For the first equality we used (I.2.15) and absorbed inessential factors into the constant C.
In the second equality we used the important identity
det M = eTr log M
(2)
which you encountered in exercise I.11.2.
Recall that Z = ⟨0|e−iHT |0⟩(with T →∞understood so that we integrate over all
of spacetime in (1)), which in this case is just e−iET with E the energy of the vacuum.
Evaluating the trace in (1)
TrO =

d4x⟨x|O |x⟩
=

d4x

d4k
(2π)4

d4q
(2π)4 ⟨x|k⟩⟨k|O |q⟩⟨q|x⟩
we obtain
iET = 1
2V T

d4k
(2π)4 log(k2 −m2 + iε) + A
where A is an infinite constant corresponding to the multiplicative factor C in (1). Recall
that in the derivation of the path integral we had lots of divergent multiplicative factors;
this is where they can come in. The presence of A is a good thing here since it solves a
problem you might have noticed: The argument of the log is not dimensionless. Let us
define m′ by writing
1 Indeed, we have already discussed one way to observe the effects of vacuum fluctuations in chapter I.9.
2 Strictly speaking, to render the expressions here well defined we should replace m2 by m2 −iε as discussed
earlier.

II.5. Feynman Diagrams for Fermions | 125
A = −1
2V T

d4k
(2π)4 log(k2 −m′2 + iε)
In other words, we do not calculate the vacuum energy as such, but only the difference
between it and the vacuum energy we would have had if the particle had mass m′ instead
of m. The arbitrarily long time T cancels out and E is proportional to the volume of space
V , as might be expected. Thus, the (difference in) vacuum energy density is
E
V = −i
2

d4k
(2π)4 log
 k2 −m2 + iε
k2 −m′2 + iε

(3)
= −i
2

d3k
(2π)3

dω
2π log

ω2 −ω2
k + iε
ω2 −ω′2
k + iε

where ω
′
k ≡+

⃗k2 + m
′2. We treat the (convergent) integral over ω by integrating by parts:

dω
2π
dω
dω log

ω2 −ω2
k + iε
ω2 −ω′2
k + iε

= −2

dω
2π ω

ω
ω2 −ω2
k + iε −(ωk →ω′
k)

= −i2ω2
k(
1
−2ωk
) −(ωk →ω′
k)
= +i(ωk −ω′
k)
(4)
Indeed, restoring ℏwe get the result we want:
E
V =

d3k
(2π)3( 1
2ℏωk −1
2ℏω′
k)
(5)
We had to go through a few arithmetical steps to obtain this result, but the important point
is that using the path integral formalism we have managed to obtain a result previously
obtained using the canonical formalism.
A peculiar sign for fermions
Our goal is to figure out the path integral for the spinor field. Recall from chapter II.2 that
the vacuum energy of the spinor field comes out to have the opposite sign to the vacuum
energy of the scalar field, a sign that surely ranks among the “top ten” signs of theoretical
physics. How are we to get it using the path integral?
As explained in chapter I.3, the origin of (1) lies in the simple Gaussian integration
formula
 +∞
−∞
dxe−1
2 ax2 =

2π
a =
√
2πe−1
2 log a
Roughly speaking, we have to find a new type of integral so that the analog of the Gaussian
integral would go something like e+ 1
2 log a.

126 | II. Dirac and the Spinor
Grassmann math
It turns out that the mathematics we need was invented long ago by Grassmann. Let
us postulate a new kind of number, called the Grassmann or anticommuting number,
such that if η and ξ are Grassmann numbers, then ηξ = −ξη. In particular, η2 = 0.
Heuristically, this mirrors the anticommutation relation satisfied by the spinor field.
Grassmann assumed that any function of η can be expanded in a Taylor series. Since η2 = 0,
the most general function of η is f (η) = a + bη, with a and b two ordinary numbers.
How do we define integration over η? Grassmann noted that an essential property of
ordinary integrals is that we can shift the dummy integration variable:
 +∞
−∞dxf (x + c) =
 +∞
−∞dxf (x). Thus, we should also insist that the Grassmann integral obey the rule

dηf (η + ξ) =

dηf (η), where ξ is an arbitrary Grassmann number. Plugging into the
most general function given above, we find that

dηbξ = 0.Since ξ is arbitrary this can only
hold if we define

dηb = 0 for any ordinary number b, and in particular

dη ≡

dη1 = 0
Since given three Grassmann numbers χ, η, and ξ, we have χ(ηξ) = (ηξ)χ, that is, the
product (ηξ) commutes with any Grassmann number χ, we feel that the product of two
anticommuting numbers should be an ordinary number. Thus, the integral

dηη is just
an ordinary number that we can simply take to be 1: This fixes the normalization of dη.
Thus Grassmann integration is extraordinarily simple, being defined by two rules:

dη = 0
(6)
and

dηη = 1
(7)
With these two rules we can integrate any function of η :

dηf (η) =

dη(a + bη) = b
(8)
if b is an ordinary number so that f (η) is Grassmannian, and

dηf (η) =

dη(a + bη) = −b
(9)
if b is Grassmannian so that f (η) is an ordinary number. Note that the concept of a
range of integration does not exist for Grassmann integration. It is much easier to master
Grassmann integration than ordinary integration!
Let η and ¯η be two independent Grassmann numbers and a an ordinary number. Then
the Grassmannian analog of the Gaussian integral gives

dη

d ¯ηe ¯ηaη =

dη

d ¯η(1 + ¯ηaη) =

dηaη = a = e+ log a
(10)
Precisely what we had wanted!
We can generalize immediately: Let η = (η1, η2, . . . , ηN) be N Grassmann numbers,
and similarly for ¯η; we then have

II.5. Feynman Diagrams for Fermions | 127

dη

d ¯ηe ¯ηAη = det A
(11)
for A = {Aij} an antisymmetric N by N matrix. (Note that contrary to the bosonic case, the
inverse of A need not exist.) We can further generalize to a functional integral.
As we will see shortly, we now have all the mathematics we need.
Grassmann path integral
In analogy with the generating functional for the scalar field
Z =

DϕeiS(ϕ) =

Dϕei 
d4x 1
2 [(∂ϕ)2−(m2−iε)ϕ2]
we would naturally write the generating functional for the spinor field as
Z =

DψD ¯ψeiS(ψ , ¯ψ) =

Dψ

D ¯ψei 
d4x ¯ψ(i̸∂−m+iε)ψ
Treating the integration variables ψ and ¯ψ as Grassmann-valued Dirac spinors, we imme-
diately obtain
Z =

Dψ

D ¯ψei 
d4x ¯ψ(i̸∂−m+iε)ψ = C′ det(i̸∂−m + iε)
= C′etr log(i̸∂−m+iε)
(12)
where C′ is some multiplicative constant. Using the cyclic property of the trace, we note
that (here m is understood to be m −iε)
tr log(i̸∂−m) = tr log γ 5(i̸∂−m)γ 5 = tr log(−i̸∂−m)
= 1
2[tr log(i̸∂−m) + tr log(−i̸∂−m)]
= 1
2tr log(∂2 + m2).
(13)
Thus, Z = C′e
1
2tr log(∂2+m2−iε) [compare with (1)!].
We see that we get the same vacuum energy we obtained in chapter II.2 using the
canonical formalism if we remember that the trace operation here contains a factor of
4 compared to the trace operation in (1), since (i̸∂−m) is a 4 by 4 matrix.
Heuristically, we can now see the necessity for Grassmann variables. If we were to treat
ψ and ¯ψ as complex numbers in (12), we would obtain something like (1/det[i̸∂−m]) =
e−tr log(i̸∂−m) and so have the wrong sign for the vacuum energy. We want the determinant
to come out in the numerator rather than in the denominator.
Dirac propagator
Now that we have learned that the Dirac field is to be quantized by a Grassmann path
integral we can introduce Grassmannian spinor sources η and ¯η :
Z(η, ¯η) =

DψD ¯ψei 
d4x[ ¯ψ(i̸∂−m)ψ+¯ηψ+ ¯ψη]
(14)

128 | II. Dirac and the Spinor
p
p + k
p
k
Figure II.5.1
and proceed pretty much as before. Completing the square just as in the case of the scalar
field, we have
¯ψKψ + ¯ηψ + ¯ψη = ( ¯ψ + ¯ηK−1)K(ψ + K−1η) −¯ηK−1η
(15)
and thus
Z(η, ¯η) = C′′e−i ¯η(i̸∂−m)−1η
(16)
The propagator S(x) for the Dirac field is the inverse of the operator (i̸∂−m): in other
words, S(x) is determined by
(i̸∂−m)S(x) = δ(4)(x)
(17)
As you can verify, the solution is
iS(x) =

d4p
(2π)4
ie−ipx
̸p −m + iε
(18)
in agreement with (II.2.22).
Feynman rules for fermions
We can now derive the Feynman rules for fermions in the same way that we derived
the Feynman rules for a scalar field. For example, consider the theory of a scalar field
interacting with a Dirac field
L = ¯ψ(iγ μ∂μ −m)ψ + 1
2[(∂ϕ)2 −μ2ϕ2] −λϕ4 + f ϕ ¯ψψ
(19)
The generating functional
Z(η, ¯η, J) =

DψD ¯ψDϕeiS(ψ , ¯ψ ,ϕ)+i 
d4x(Jϕ+¯ηψ+ ¯ψη)
(20)
can be evaluated as a double series in the couplings λ and f . The Feynman rules (not
repeating the rules involving only the boson) are as follows:
1. Draw a diagram with straight lines for the fermion and dotted lines for the boson, and label
each line with a momentum, for example, as in figure II.5.1.

II.5. Feynman Diagrams for Fermions | 129
2. Associate with each fermion line the propagator
i
̸p −m + iε = i
̸p + m
p2 −m2 + iε
(21)
3. Associate with each interaction vertex the coupling factor if and the factor (2π)4δ(4)(
in p
−
out p) expressing momentum conservation (the two sums are taken over the incoming
and the outgoing momenta, respectively).
4. Momenta associated with internal lines are to be integrated over with the measure

[d4p/(2π)4].
5. External lines are to be amputated. For an incoming fermion line write u(p, s) and for
an outgoing fermion line ¯u(p′, s′). The sources and sinks have to recognize the spin
polarization of the fermion being produced and absorbed. [For antifermions, we would have
¯v(p, s) and v(p′, s′). You can see from (II.2.10) that an outgoing antifermion is associated
with v rather than ¯v.]
6. A factor of (−1) is to be associated with each closed fermion line. The spinor index carried
by the fermion should be summed over, thus leading to a trace for each closed fermion line.
[For an example, see (II.7.7–9).]
Note that rule 6 is unique to fermions, and is needed to account for their negative
contribution to the vacuum energy. The Feynman diagram corresponding to vacuum
fluctuation has no external line. I will discuss these points in detail in chapter IV.3.
For the theory of a massive vector field interacting with a Dirac field mentioned in
chapter II.1
L = ¯ψ[iγ μ(∂μ −ieAμ) −m]ψ −1
4FμνF μν + 1
2μ2AμAμ
(22)
the rules differ from above as follows. The vector boson propagator is given by
i
k2 −μ2
kμkν
μ2 −gμν

(23)
and thus each vector boson line is associated not only with a momentum, but also with
indices μ and ν. The vertex (figure II.5.2) is associated with ieγ μ.
p + k
p
k
ieγμ
Figure II.5.2

130 | II. Dirac and the Spinor
If the vector boson line in figure II.5.2 is external and on shell, we have to specify its
polarization. As discussed in chapter I.5, a massive vector boson has three degrees of
polarizations described by the polarization vector ε(a)
μ
for a = 1, 2, 3. The amplitude for
emitting or absorbing a vector boson with polarization a is ieγ με(a)
μ = ie ̸ ε(a)
μ .
In Schwinger’s sorcery, the source for producing a vector boson Jμ(x), in contrast to
the source for producing a scalar meson J(x), carries a Lorentz index. Work in momen-
tum space. Current conservation kμJμ(k) = 0 implies that we can decompose Jμ(k) =
3
a=1J (a)(k)ε(a)
μ (k). The clever experimentalist sets up her machine, that is, chooses the
functions J (a)(k), so as to produce a vector boson of the desired momentum k and polar-
ization a. Current conservation requires kμε(a)
μ (k) = 0. For kμ = (ω(k), 0, 0, k), we could
choose
ε(1)
μ (k) = (0, 1, 0, 0),
ε(2)
μ (k) = (0, 0, 1, 0),
ε(3)
μ (k) = (−k, 0, 0, ω(k))/m
(24)
In the canonical formalism, we have in analogy with the expansion of the scalar field ϕ
in (I.8.11)
Aμ(⃗x, t) =

dDk

(2π)D2ωk
3
a=1{a(a)(⃗k)ε(a)
μ (k)e−i(ωkt−⃗k.⃗x) + a(a)†(⃗k)ε(a)∗
μ
(k)ei(ωkt−⃗k.⃗x)}
(25)
(I trust you not to confuse the letter a used to denote annihilation and used to label
polarization.) The point is that in contrast to ϕ, Aμ carries a Lorentz index, which the
creation and annihilation operators have to “know about” (through the polarization label.)
It is instructive to compare with the expansion of the fermion field ψ in (II.2.10): the spinor
index α on ψ is carried in the expansion by the spinors u(p, s) and v(p, s). In each case,
an index (μ in the case of the vector and α in the case of the spinor) known to the Lorentz
group is “traded” for a label specifying the spin polarization (a and s respectively.)
A minor technicality: notice that I have complex conjugated the polarization vector
associated with the creation operator a(a)†(⃗k) in (25) even though the polarization vectors in
(24) are real. This is because experimentalists sometimes enjoy using circularly polarized
photons with polarization vectors ε(1)
μ (k) = (0, 1, i, 0)/
√
2, ε(2)
μ (k) = (0, 1, −i, 0)/
√
2.
p
p + k
p
k
Figure II.5.3

II.5. Feynman Diagrams for Fermions | 131
Exercises
II.5.1
Write down the Feynman amplitude for the diagram in figure II.5.1 for the scalar theory (19). The answer
is given in chapter III.3.
II.5.2
Applying the Feynman rules for the vector theory (22) show that the amplitude for the diagram in
figure II.5.3 is given by
(ie)2i2

d4k
(2π)4
1
k2 −μ2
kμkν
μ2 −gμν

¯u(p)γ ν
̸p + ̸k + m
(p + k)2 −m2γ μu(p)
(26)

II.6
Electron Scattering and Gauge Invariance
Electron-proton scattering
We will now finally calculate a physical process that experimentalists can go out and
measure. Consider scattering an electron off a proton. (For the moment let us ignore the
strong interaction that the proton also participates in. We will learn in chapter III.6 how
to take this fact into account. Here we pretend that the proton, just like the electron, is a
structureless spin- 1
2 fermion obeying the Dirac equation.) To order e2 the relevant Feynman
diagram is given in figure II.6.1 in which the electron and the proton exchange a photon.
But wait, from chapter I.5 we only know how to write down the propagator iDμν =
i
 kμkν
μ2 −ημν

/(k2 −μ2) for a hypothetical massive photon. (Trivial notational change: the
mass of the photon is now called μ, since m is reserved for the mass of the electron and
M for the mass of the proton.) In that chapter I outlined our philosophy: we will plunge
ahead and calculate with a nonzero μ and hope that at the end we can set μ to zero. Indeed,
when we calculated the potential energy between two external charges, we find that we can
let μ →0 without any signs of trouble [see (I.5.6)]. In this chapter and the next, we would
like to see whether this will always be the case.
Applying the Feynman rules, we obtain the amplitude for the diagram in figure II.6.1
(with k = P −p the momentum transfer in the scattering)
M(P , PN) = (−ie)(ie)
i
(P −p)2 −μ2
kμkν
μ2 −ημν

¯u(P )γ μu(p)¯u(PN)γ νu(pN)
(1)
We have suppressed the spin labels and used the subscript N (for nucleon) to refer to the
proton.
Now notice that
kμ ¯u(P)γ μu(p) = (P −p)μ ¯u(P)γ μu(p) = ¯u(P )(̸P −̸p)u(p) = ¯u(P )(m −m)u(p) = 0
(2)
by virtue of the equations of motion satisfied by ¯u(P) and u(p). Similarly, kμ ¯u(PN)γμu(pN)
= 0.

II.6. Scattering and Gauge Invariance | 133
k
PN
pN
P
p
Figure II.6.1
This important observation implies that the kμkν/μ2 term in the photon propagator does
not enter. Thus
M(P , PN) = −ie2
1
(P −p)2 −μ2 ¯u(P )γ μu(p)¯u(PN)γμu(pN)
(3)
and we can now set the photon mass μ to zero with impunity and replace (P −p)2 −μ2
in the denominator by (P −p)2.
Note that the identity that allows us to set μ to zero is just the momentum space version
of electromagnetic current conservation ∂μJ μ = ∂μ( ¯ψγ μψ) = 0. You would notice that
this calculation is intimately related to the one we did in going from (I.5.4) to (I.5.5), with
¯u(P)γ μu(p) playing the role of J μ(k).
Potential scattering
That the proton mass M is so much larger than the electron mass m allows us to make
a useful approximation familiar from elementary physics. In the limit M/m tending to
infinity, the proton hardly moves, and we could use, for the proton, the spinors for a particle
at rest given in chapter II.2, so that ¯u(PN)γ0u(pN) ≈1 and ¯u(PN)γiu(pN) ≈0. Thus
M = −ie2
k2
¯u(P)γ 0u(p)
(4)
We recognize that we are scattering the electron in the Coulomb potential generated by
the proton. Work out the (familiar) kinematics: p = (E, 0, 0, | ⃗p|) and P = (E, 0, | ⃗p| sin θ,
| ⃗p| cos θ). We see that k = P −p is purely spacelike and k2 = −⃗k2 = −4| ⃗p|2 sin2(θ/2).
Recall from (I.4.7) that

d3xei⃗k.⃗x

−e
4πr

= −e
⃗k2
(5)
We represent potential scattering by the Feynman diagram in figure II.6.2: the proton has
disappeared and been replaced by a cross, which supplies the virtual photon the electron
interacts with. It is in this sense that you could think of the Coulomb potential picturesquely
as a swarm of virtual photons.

134 | II. Dirac and the Spinor
k
X
P
p
Figure II.6.2
Once again, it is instructive to use the canonical formalism to derive this expression for
M for potential scattering. We want the transition amplitude ⟨P , S|e−iHT |p, s⟩with the
single electron state |p, s⟩≡b†(p, s)|0⟩. The term in the Lagrangian describing the elec-
tron interacting with the external c-number potential Aμ(x) is given in (II.5.22) and thus
to leading order we have the transition amplitude ie

d4x⟨P , S| ¯ψ(x)γ μψ(x)|p, s⟩Aμ(x).
Using (II.2.10–11) we evaluate this as
ie

d4x(1/ρ(P))(1/ρ(p))(¯u(P , S)γ μu(p, s))ei(P−p)xAμ(x)
Here ρ(p) denotes the fermion normalization factor

(2π)3Ep/m in (II.2.10). Given that
the Coulomb potential has only a time component and does not depend on time, we see
that integration over time gives us an energy conservation delta function, and integration
over space the Fourier transform of the potential, as in (5). Thus the above becomes
(1/ρ(P))(1/ρ(p))(2π)δ(EP −Ep)( −ie2
⃗k2 )¯u(P , S)γ 0u(p, s). Satisfyingly, we have recovered
the Feynman amplitude up to normalization factors and an energy conservation delta
function, just as in (I.8.16) except for the substitution of boson for fermion normalization
factors. Notice that we have energy conservation but not 3-momentum conservation, a fact
we understand perfectly well when we dribble a basketball ball, for example.
Electron-electron scattering
Next, we graduate to two electrons scattering off each other: e−(p1) + e−(p2) →e−(P1) +
e−(P2). Here we have a new piece of physics: the two electrons are identical. A profound
tenet of quantum physics states that we cannot distinguish between the two outgoing
electrons. Now there are two Feynman diagrams (see fig. II.6.3) to order e2, obtained
by interchanging the two outgoing electrons. The electron carrying momentum P1 could
have “come from” the incoming electron carrying momentum p1 or the incoming electron
carrying momentum p2.
We have for figure II.6.3a the amplitude
A(P1, P2) = (ie2/(P1 −p1)2)¯u(P1)γ μu(p1)¯u(P2)γμu(p2)

II.6. Scattering and Gauge Invariance | 135
(a)
P1
P2
p1
p2
k
(b)
P1
P2
p1
p2
Figure II.6.3
as before. We have only indicated the dependence of A on the final momenta, suppressing
the other dependence. By Fermi statistics, the amplitude for the diagram in figure II.6.3
is then −A(P2, P1). Thus the invariant amplitude for two electrons of momentum p1 and
p2 to scatter into two electrons with momentum P1 and P2 is
M = A(P1, P2) −A(P2, P1)
(6)
To obtain the cross section we have to square the amplitude
|M|2 = [|A(P1, P2)|2 + (P1 ↔P2)] −2 Re A(P2, P1)∗A(P1, P2)
(7)

136 | II. Dirac and the Spinor
At this point we have to do a fair amount of arithmetic, but keep in mind that there
is nothing conceptually intricate in what follows. First, we have to learn to complex con-
jugate spinor amplitudes. Using (II.1.15), note that in general (¯u(p′)γμ . . . γνu(p))∗=
u(p)†γ †
ν . . . γ †
μγ 0u(p′) = ¯u(p)γν . . . γμu(p′). Here γμ . . . γν represents a product of any
number of γ matrices. Complex conjugation reverses the order of the product and inter-
changes the two spinors. Thus we have
|A(P1, P2)|2 = e4
k4 [¯u(P1)γ μu(p1)¯u(p1)γ νu(P1)][¯u(P2)γμu(p2)¯u(p2)γνu(P2)]
(8)
which factorizes with one factor involving spinors carrying momentum with subscript 1
and another factor involving spinors carrying momentum with subscript 2. In contrast,
the interference term A(P2, P1)∗A(P1, P2) does not factorize.
In the simplest experiments, the initial electrons are unpolarized, and the polarization
of the outgoing electrons is not measured. We average over initial spins and sum over final
spins using (II.2.8):

su(p, s)¯u(p, s) = ̸p + m
2m
(9)
In averaging and summing |A(P1, P2)|2 we encounter the object (displaying the spin labels
explicitly)
τ μν(P1, p1) ≡1
2

¯u(P1, S)γ μu(p1, s)¯u(p1, s)γ νu(P1, S)
(10)
=
1
2(2m)2tr(̸P 1 + m)γ μ(̸p1 + m)γ ν
(11)
which is to be multiplied by τμν(P2, p2).
Well, we, or rather you, have to develop some technology for evaluating the trace of
products of gamma matrices. The key observation is that the square of a gamma matrix
is either +1 or −1, and different gamma matrices anticommute. Clearly, the trace of a
product of an odd number of gamma matrices vanish. Furthermore, since there are only
four different gamma matrices, the trace of a product of six gamma matrices can always be
reduced to the trace of a product of four gamma matrices, since there are always pairs of
gamma matrices that are equal and can be brought together by anticommuting. Similarly
for the trace of a product of an even higher number of gamma matrices.
Hence τ μν(P1, p1) =
1
2(2m)2(tr(̸P 1γ μ ̸p1γ ν) + m2tr(γ μγ ν)). Writing tr(̸P 1γ μ ̸p1γ ν) =
P1ρp1λtr(γ ργ μγ λγ ν) and using the expressions for the trace of a product of an even
number of gamma matrices listed in appendix D, we obtain τ μν(P1, p1) =
1
2(2m)24(P μ
1 pν
1 −
ημνP1 . p1 + P ν
1 pμ
1 + m2ημν).
In averaging and summing A(P2, P1)∗A(P1, P2) we encounter the more involved object
κ ≡1
22
   
¯u(P1)γ μu(p1)¯u(P2)γμu(p2)¯u(p1)γ νu(P2)¯u(p2)γνu(P1)
(12)
where for simplicity of notation we have suppressed the spin labels. Applying (9) we can
write κ as a single trace. The evaluation of κ is quite tedious, since it involves traces of
products of up to eight gamma matrices.

II.6. Scattering and Gauge Invariance | 137
We will be content to study electron-electron scattering in the relativistic limit in which
m may be neglected compared to the momenta. As explained in chapter II.2, while we
are using the “rest normalization” for spinors we can nevertheless set m to 0 wherever
possible. Then
κ =
1
4(2m)4 tr(̸P 1γ μ ̸p1γ ν ̸P 2γμ ̸p2γν)
(13)
Applying the identities in appendix D to (13) we obtain tr(̸P 1γ μ ̸p1γ ν ̸P 2γμ ̸p2γν) =
−2tr(̸P 1γ μ ̸p1 ̸p2γμ ̸P 2) = −32p1 . p2P1 . P2.
In the same limit τ μν(P1, p1) =
2
(2m)2(P μ
1 pν
1 + P ν
1 pμ
1 −ημνP1 . p1) and thus
τ μν(P1, p1)τμν(P2, p2) =
4
(2m)4 (P μ
1 pν
1 + P ν
1 pμ
1 −ημνP1 . p1)(2P2μp2ν −ημνP2 . p2)
(14)
= 4 . 2
(2m)4 (p1 . p2P1 . P2 + p1 . P2p2 . P1)
(15)
An amusing story to break up this tedious calculation: Murph Goldberger, who was
a graduate student at the University of Chicago after working on the Manhattan Project
during the war and whom I mentioned in chapter II.1 regarding the Feynman slash, told
me that Enrico Fermi marvelled at this method of taking a trace that young people were
using to sum over spin- 1
2 polarizations. Fermi and others in the older generation had
simply memorized the specific form of the spinors in the Dirac basis (which you know from
doing exercise II.1.3) and consequently the expressions for ¯u(P , S)γ μu(p, s). They simply
multiplied these expressions together and added up the different possibilities. Fermi was
skeptical of the fancy schmancy method the young Turks were using and challenged Murph
to a race on the blackboard. Of course, with his lightning speed, Fermi won. To me, it is
amazing, living in the age of string theory, that another generation once regarded the
trace as fancy math. I confessed that I was even a bit doubtful of this story until I looked at
Feynman’s book Quantum Electrodynamics, but guess what, Feynman indeed constructed,
on page 100 in the edition I own, a table showing the result for the amplitude squared for
various spin polarizations. Some pages later, he mentioned that polarizations could also
be summed using the spur (the original German word for trace). Another amusing aside:
spur is cognate with the English word spoor, meaning animal droppings, and hence also
meaning track, trail, and trace. All right, back to work!
While it is not the purpose of this book to teach you to calculate cross sections for a
living, it is character building to occasionally push calculations to the bitter end. Here
is a good place to introduce some useful relativistic kinematics. In calculating the cross
section for the scattering process p1 + p2 →P1 + P2 (with the masses of the four particles
all different in general) we typically encounter Lorentz invariants such as p1 . P2. A priori,
you might think there are six such invariants, but in fact, you know that there are only
physical variables, the incident energy E and the scattering angle θ. The cleanest way to
organize these invariants is to introduce what are called Mandelstam variables:
s ≡(p1 + p2)2 = (P1 + P2)2
(16)
t ≡(P1 −p1)2 = (P2 −p2)2
(17)
u ≡(P2 −p1)2 = (P1 −p2)2
(18)

138 | II. Dirac and the Spinor
You know that there must be an identity reducing the three variables s, t, and u to two.
Show that (with an obvious notation)
s + t + u = m2
1 + m2
2 + M2
1 + M2
2
(19)
For our calculation here, we specialize to the center of mass frame in the relativistic limit
p1 = E(1, 0, 0, 1), p2 = E(1, 0, 0, −1), P1 = E(1, sin θ, 0, cos θ), andP2 = E(1, −sin θ, 0,
−cos θ). Hence
p1 . p2 = P1 . P2 = 2E2 = 1
2s
(20)
p1 . P1 = p2 . P2 = 2E2 sin2 θ
2 = −1
2t
(21)
and
p1 . P2 = p2 . P1 = 2E2 cos2 θ
2 = −1
2u
(22)
Also, in this limit (P1 −p1)4 = (−2p1 . P1)2 = 16E4 sin4(θ/2) = t4. Putting it together, we
obtain 1
4
|M|2 = (e4/4m4)f (θ), where
f (θ) = s2 + u2
t2
+ 2s2
tu + s2 + t2
u2
= s4 + t4 + u4
t2u2
=

1 + cos4(θ/2)
sin4(θ/2)
+
2
sin2(θ/2) cos2(θ/2)
+ 1 + sin4(θ/2)
cos4(θ/2)

(23)
= 2

1
sin4(θ/2)
+ 1 +
1
cos4(θ/2)

(24)
The physical origin of each of the terms in (23) [before we simplify with trigonometric
identities] to get to (24) is clear. The first term strongly favors forward scattering due
to the photon propagator ∼1/k2 blowing up at k ∼0. The third term is required by the
indistinguishability of the two outgoing electrons: the scattering must be symmetric under
θ →π −θ, since experimentalists can’t tell whether a particular incoming electron has
scattered forward or backward. The second term is the most interesting of all: it comes from
quantum interference. If we had mistakenly thought that electrons are bosons and taken
the plus sign in (6), the second term in f (θ) would come with a minus sign. This makes
a big difference: for instance, f (π/2) would be 5 −8 + 5 = 2 instead of 5 + 8 + 5 = 18.
Since the conversion of a squared probability amplitude to a cross section is conceptually
the same as in nonrelativistic quantum mechanics (divide by the incoming flux, etc.), I
will relegate the derivation to an appendix and let you go the last few steps and obtain the
differential cross section as an exercise:
dσ
d = α2
8E2f (θ)
(25)
with the fine structure constant α ≡e2/4π ≈1/137.

II.6. Scattering and Gauge Invariance | 139
An amazing subject
When you think about it, theoretical physics is truly an amazing business. After the
appropriate equipments are assembled and high energy electrons are scattered off each
other, experimentalists indeed would find the differential cross section given in (25). There
is almost something magical about it.
Appendix: Decay rate and cross section
To make contact with experiments, we have to convert transition amplitudes into the scattering cross sections
and decay rates that experimentalists actually measure. I assume that you are already familiar with the physical
concepts behind these measurements from a course on nonrelativistic quantum mechanics, and thus here we
focus more on those aspects specific to quantum field theory.
To be able to count states, we adopt an expedient probably already familiar to you from quantum statistical
mechanics, namely that we enclose our system in a box, say a cube with length L on each side with L much larger
than the characteristic size of our system. With periodic boundary conditions, the allowed plane wave states ei ⃗p.⃗x
carry momentum
⃗p = 2π
L (nx, ny, nz)
(26)
where the ni’s are three integers. The allowed values of momentum form a lattice of points in momentum space
with spacing 2π/L between points. Experimentalists measure momentum with finite resolution, small but much
larger than 2π/L. Thus, an infinitesimal volume d3p in momentum space contains d3p/(2π/L)3 = V d3p/(2π)3
states with V = L3 the volume of the box. We obtain the correspondence

d3p
(2π)3f (p) ↔1
V

p
f (p)
(27)
In the sum the values of p ranges over the discrete values in (26). The correspondence (27) between continuum
normalization and the discrete box normalization implies that
δ(3)( ⃗p −⃗p′) ↔
V
(2π)3δ ⃗p ⃗p′
(28)
with the Kronecker delta δ ⃗p ⃗p′ equal to 1 if ⃗p = ⃗p′ and 0 otherwise. One way of remembering these correspondences
is simply by dimensional matching.
Let us now look at the expansion (I.8.17) of a complex scalar field
ϕ(⃗x, t) =

d3k

(2π)32ωk
[a(⃗k)e−i(ωkt−⃗k.⃗x) + b†(⃗k)ei(ωkt−⃗k.⃗x)]
(29)
in terms of creation and annihilation operators. Henceforth, in order not to clutter up the page, I will abuse
notation slightly, for example, dropping the arrows on vectors when there is no risk of confusion. Going over to
the box normalization, we replace the commutation relation [a(k), a†(k′)] = δ(3)(⃗k −⃗k′) by
[a(k), a†(k′)] =
V
(2π)3δ⃗k⃗k′
(30)
We now normalize the creation and annihilation operators by
a(k) =

V
(2π)3
 1
2
˜a(k)
(31)

140 | II. Dirac and the Spinor
so that
[˜a(k), ˜a†(k′)] = δk,k′
(32)
Thus the state |⃗k⟩≡˜a†(⃗k)|0⟩is properly normalized: ⟨⃗k|⃗k⟩= 1. Using (27) and (31), we end up with
ϕ(x) =
1
V
1
2

k
1

2ωk
(˜ae−ikx + ˜b†eikx)
(33)
We specified a complex, rather than a real, scalar field because then, as you showed in exercise I.8.4, a
conserved current can be defined with the corresponding charge Q =

d3xJ 0 =

d3k(a†(k)a(k) −b†(k)b(k)) →

k(˜a†(k)˜a(k) −˜b†(k)˜b(k)). It follows immediately that ⟨⃗k|Q|⃗k⟩= 1, so that for the state |⃗k⟩we have one particle
in the box.
To derive the formula for the decay rate, we focus, for the sake of pedagogical clarity, on a toy Lagrangian
L = g(η†ξ†ϕ + h.c.) describing the decay ϕ →η + ξ of a meson into two other mesons. (As usual, we display
only the part of the Lagrangian that is of immediate interest. In other words, we suppress the stuff you have long
since mastered: L = ∂ϕ†∂ϕ −mϕϕ†ϕ + . . . and all the rest.)
The transition amplitude ⟨⃗p, ⃗q|e−iHT |⃗k⟩is given to lowest order by A = i⟨⃗p, ⃗q|

d4x(gη†(x)ξ†(x)ϕ(x))|⃗k⟩.
Here we use the states we “carefully” normalized above, namely the ones created by the various “analogs” of ˜a†.
(Just as in quantum mechanics, strictly, we should use wave packets instead of plane wave states. I assume that
you have gone through that at least once.) Plugging in the various “analogs” of (33), we have
A = ig( 1
V
1
2
)3 
p′

q′

k′
1
2ωp′2ωq′2ωk′

d4xei(p′+q′−k′)⟨⃗p, ⃗q| ˜a†(p′)˜a†(q′)˜a(k′)|⃗k⟩
= ig 1
V
3
2
1
2ωp2ωq2ωk
(2π)4δ(4)(p + q −k)
(34)
Here we have committed various minor transgressions against notational consistency. For example, since
the three particles ϕ, η, and ξ have different masses, the symbol ω represents, depending on context, different
functions of its subscript (thus ωp =

⃗p2 + m2
η, and so forth). Similarly, ˜a(k′) should really be written as ˜aϕ(k′),
and so forth. Also, we confound 3- and 4-momenta. I would like to think that these all fall under the category of
what the Catholic church used to call venial sins. In any case, you know full well what I am talking about.
Next, we square the transition amplitude A to find the transition probability. You might be worried, because
it appears that we will have to square the Dirac delta function. But fear not, we have enclosed ourselves in a box.
Furthermore, we are in reality calculating ⟨⃗p, ⃗q|e−iHT |⃗k⟩, the amplitude for the state |⃗k⟩to become the state
| ⃗p, ⃗q⟩after a large but finite time T . Thus we could in all comfort write
[(2π)4δ(4)(p + q −k)]2 = (2π)4δ(4)(p + q −k)

d4xei(p+q−k)x
= (2π)4δ(4)(p + q −k)

d4x = (2π)4δ(4)(p + q −k)V T
(35)
Thus the transition probability per unit time, aka the transition rate, is equal to
|A|2
T
= V
V 3

1
2ωp2ωq2ωk

(2π)4δ(4)(p + q −k)g2
(36)
Recall that there are V d3p/(2π)3 states in the volume d3p in momentum space. Hence, multiplying the number
of final states (V d3p/(2π)3)(V d3q/(2π)3) by the transition rate |A|2/T , we obtain the differential decay rate of
a meson into two mesons carrying off momenta in some specified range d3p and d3q:
d =
1
2ωk
V
V 3

V
d3p
(2π)32ωp
 
V
d3q
(2π)32ωq

(2π)4δ(4)(p + q −k)g2
(37)
Yes sir, indeed, the factors of V cancel, as they should.
To obtain the total decay rate  we integrate over d3p and d3q. Notice the factor 1/2ωk: the decay rate for a
moving particle is smaller than that of a resting particle by a factor m/ωk. We have derived time dilation, as we
had better.

II.6. Scattering and Gauge Invariance | 141
We are now ready to generalize to the decay of a particle carrying momentum P into n particles carrying
momenta k1, . . . , kn. For definiteness, we suppose that these are all Bose particles. First, we draw all the relevant
Feynman diagrams and compute the invariant amplitude M. (In our toy example, M= ig.) Second, the transition
probability contains a factor 1/V n+1, one factor of 1/V for each particle, but when we squared the momentum
conservation delta function we also obtained a factor of V T , which converts the transition probability into a
transition rate and knocks off one power of V , leaving the factor 1/V n. Next, when we sum over final states, we
have a factor V d3ki/((2π)32ωki) for each particle in the final state. Thus the factors of V indeed cancel.
The differential decay rate of a boson of mass M in its rest frame is thus given by
d =
1
2M
d3k1
(2π)32ω(k1)
. . .
d3kn
(2π)32ω(kn)(2π)4δ(4)

P −
n

i=1
ki

|M|2
(38)
At this point, we recall that, as explained in chapter II.2, in the expansion of a fermion field into creation and
annihilation operators [see (II.2.10)], we have a choice of two commonly used normalizations, trivially related
by a factor (2m)
1
2 . If you choose to use the “rest normalization" so that spinors come out nice in the rest frame,
then the field expansion contains the normalization factor (Ep/m)
1
2 instead of the factor (2ωk)
1
2 for a Bose
field [see (I.8.11)]. This entails the trivial replacement, for each fermion, of the factor 2ω(k) = 2

⃗k2 + m2 by
E(p)/m =

⃗p2 + m2/m. In particular, for the decay rate of a fermion the factor 1/2M should be removed. If
you choose the “any mass renormalization,” you have to remember to normalize the spinors appearing in M
correctly, but you need not touch the phase space factors derived here.
We next turn to scattering cross sections. As I already said, the basic concepts involved should already be
familiar to you from nonrelativistic quantum mechanics. Nevertheless, it may be helpful to review the basic
notions involved. For the sake of definiteness, consider some happy experimentalist sending a beam of hapless
electrons crashing into a stationary proton. The flux of the beam is defined as the number of electrons crossing
an imagined unit area per unit time and is thus given by F = nv, where n and v denote the density and velocity
of the electrons in the beam. The measured event rate divided by the flux of the beam is defined to be the cross
section σ, which has the dimension of an area and could be thought of as the effective size of the proton as seen
by the electrons.
It may be more helpful to go to the rest frame of the electrons, in which the proton is plowing through the
cloud of electrons like a bulldozer. In time t the proton moves through a distance vt and thus sweeps through
a volume σvt, which contains nσvt electrons. Dividing this by t gives us the event rate nvσ.
To measure the differential cross section, the experimentalist sets up, typically in the lab frame in which the
target particle is at rest, a detector spanning a solid angle d = sin θdθdφ and counts the number of events per
unit time.
All of this is familiar stuff. Now we could essentially take over our calculation of the differential decay rate
almost in its entirety to calculate the differential cross section for the process p1 + p2 →k1 + k2 + . . . + kn. With
two particles in the initial state we now have a factor of (1/V )n+2 in the transition probability. But as before, the
square of the momentum conservation delta function produces one power of V and counting the momentum
final states gives a factor V n, so that we are left with a factor of 1/V . You might be worried about this remaining
factor of 1/V , but recall that we still have to divide by the flux, given by |⃗v1 −⃗v2|n. Since we have normalized to
one particle in the box the density n is 1/V . Once again, all factors of V cancel, as they must.
The procedure is thus to draw all relevant diagrams to the order desired and calculate the Feynman amplitude
M for the process p1 + p2 →k1 + k2 + . . . + kn. Then the differential cross section is given by (again assuming
all particles to be bosons)
dσ =
1
|⃗v1 −⃗v2|2ω(p1)2ω(p2)
d3k1
(2π)32ω(k1)
. . .
d3kn
(2π)32ω(kn)(2π)4δ(4)

p1 + p2 −
n

i=1
ki

|M|2
(39)
We are implicitly working in a collinear frame in which the velocities of the incoming particles, ⃗v1 and ⃗v2,
point in opposite directions. This class of frames includes the familiar center of mass frame and the lab frame (in
which ⃗v2=0). In a collinear frame, p1 = E1(1, 0, 0, v1) and p2 = E2(1, 0, 0, v2), and a simple calculation shows
that ((p1p2)2 −m2
1m2
2) = (E1E2(v1 −v2))2. We could write the factor |⃗v1 −⃗v2|E1E2 in dσ in the more invariant-
looking form ((p1p2)2 −m2
1m2
2)
1
2 , thus showing explicitly that the differential cross section is invariant under
Lorentz boosts in the direction of the beam, as physically must be the case.

142 | II. Dirac and the Spinor
An often encountered case involves two particles scattering into two particles in the center of mass frame. Let
us do the phase space integral

(d3k1/2ω1)(d3k2/2ω2)δ(4)(P −k1 −k2) here for easy reference. We will do it in
two different ways for your edification.
We could immediately integrate over d3k2 thus knocking out the 3-dimensional momentum conservation
delta function δ3( ⃗k1 + ⃗k2). Writing d3k1 = k2
1dk1d, we integrate over the remaining energy conservation delta
function δ(

k2
1 + m2
1 +

k2
1 + m2
2 −Etotal). Using (I.2.13), we find that the integral over k1 gives k1ω1ω2/Etotal,
where ω1 ≡

k2
1 + m2
1 and ω2 ≡

k2
1 + m2
2, with k1 determined by

k2
1 + m2
1 +

k2
1 + m2
2 = Etotal. Thus we obtain

d3k1
2ω1
d3k2
2ω2
δ(4)(P −k1 −k2) =
k1
4Etotal

d
(40)
Once again, if you use the “rest normalization" for fermions, remember to make the replacement as explained
above for the decay rate. The factor of 1
4 should be replaced by mf /2 for one fermion and one boson, and by
m1m2 for two fermions.
Alternatively, we use (I.8.14) and regressing, write d3k2 =

d4k2θ(k0
2)δ(k2
2 −m2
2)2ω2. Integrate over d4k2 and
knock out the 4-dimensional delta function, leaving us with

2ω2dk1k2
1d/(2ω12ω2)δ((P −k1)2 −m2
2). The
argument of the delta function is E2
total −2Etotalk1 + m2
1 −m2
2, and thus integrating over k1 we get a factor of
2Etotal in the denominator, giving a result in agreement with (40).
For the record, you could work out the kinematics and obtain
k1 =

(E2
total −(m1 + m2)2)(E2
total −(m1 −m2)2)/2Etotal
Evidently, this phase space integral also applies to the decay into two particles in the rest frame of the parent
particle, in which case we replace Etotal by M. In particular, for our toy example, we have
 =
g2
16πM3

(M2 −(m + μ)2)(M2 −(m −μ)2)
(41)
The differential cross section for two-into-two scattering in the center of mass frame is given by
dσ
d =
1
(2π)2|⃗v1 −⃗v2|2ω(p1)2ω(p2)
k1
Etotal
F|M|2
(42)
In particular, in the text we calculated electron-electron scattering in the relativistic limit. As shown there, we
can write |M|2 = |
M|2/(2m)4 in terms of some reduced invariant amplitude 
M. The factor 1/(2m)4 transforms
the factors 2ω(p) into 2E. Things simplify enormously, with |⃗v1 −⃗v2| = 2 and k1 = 1
2Etotal, so that finally
dσ
d =
1
24(4π)2E2|
M|2
(43)
Last, we come to the statistical factor S that must be included in calculating the total decay rate and the total
cross section to avoid over-counting if there are identical particles in the final state. The factor S has nothing to do
with quantum field theory per se and should already be familiar to you from nonrelativistic quantum mechanics.
The rule is that if there are ni identical particles of type i in the final state, the total decay rate or the total cross
section must be multiplied by S = i1/ni! to account for indistinguishability.
To see the necessity for this factor, it suffices to think about the simplest case of two identical Bose particles.
To be specific, consider electron-positron annihilation into two photons (which we will study in chapter II.8). For
simplicity, average and sum over all spin polarizations. Let us calculate dσ/d according to (43) above. This is
the probability that a photon will check into a detector set up at angles θ and φ relative to the beam direction. If
the detector clicks, then we know that the other photon emerged at an angle π −θ relative to the beam direction.
Thus the total cross section should be
σ = 1
2

d dσ
d = 1
2
 π
0
dθ dσ
dθ
(44)
(The second equality is for all the elementary cases we will encounter in which dσ does not depend on the
azimuthal angle φ.) In other words, to avoid double counting, we should divide by 2 if we integrate over the full
angular range of θ.
More formally, we argue as follows. In quantum mechanics, a set of states |α⟩is complete if 1 = 
α |α⟨⟩α|
(“decomposition of 1”). Acting with this on |β⟩we see that these states must be normalized according to
⟨α|β⟩= δαβ.

II.6. Scattering and Gauge Invariance | 143
Now consider the state
|k1, k2⟩≡1
√
2
˜a†(k1)˜a†(k2)|0⟩= |k2, k1⟩
(45)
containing two identical bosons. By repeatedly using the commutation relation (32), we compute ⟨q1, q2|k1, k2⟩=
⟨0|˜a(q1)˜a(q2)˜a†(k1)˜a†(k2)|0⟩=
1
2(δq1k1δq2k2 + δq2k1δq1k2).
Thus

q1

q2 |q1, q2⟩⟨q1, q2|k1, k2⟩
= 
q1

q2 |q1, q2⟩1
2(δq1k1δq2k2 + δq2k1δq1k2) = 1
2(|k1, k2⟩+ |k2, k1⟩) = |k1, k2⟩. Thus the states |k1, k2⟩are nor-
malized properly. In the sum over states, we have 1 = . . . + 
q1

q2 |q1, q2⟩⟨q1, q2| + . . ..
In other words, if we are to sum over q1 and q2 independently, then we must normalize our states as in (45)
with the factor of 1/
√
2. But then this factor would appear multiplying M. In calculating the total decay rate
or the total cross section, we are effectively summing over a complete set of final states. In summary, we have
two options: either we treat the integration over d3k1d3k2 as independent in which case we have to multiply the
integral by 1
2, or we integrate over only half of phase space.
We readily generalize from this factor of 1
2 to the statistical factor S.
In closing, let me mention two interesting pieces of physics.
To calculate the cross section σ, we have to divide by the flux, and hence σ is proportional to 1/|⃗v1 −⃗v2|.
For exothermal processes, such as electron-positron annihilation into photons or slow neutron capture, σ could
become huge as the relative velocity vrel →0. Fermi exploited this fact to great advantage in studying nuclear
fission. Note that although the cross section, which has dimension of an area, formally goes to infinity, the
reaction rate (the number of reactions per unit time) remains finite.
Positronium decay into photons is an example of a bound state decaying in finite time. In positronium, the
positron and electron are not approaching each other in plane wave states, as we assumed in our cross section
calculation. Rather, the probability (per unit volume) that the positron finds itself near the electron is given by
|ψ(0)|2 according to elementary quantum mechanics, with ψ(x) the bound state wave function for whatever
state of positronium we are interested in. In other words, |ψ(0)|2 gives the volume density of positrons near the
electron. Since vσ is a volume divided by time, the decay rate is given by  = vσ|ψ(0)|2.
Exercises
II.6.1
Show that the differential cross section for a relativistic electron scattering in a Coulomb potential is
given by
dσ
d =
α2
4 ⃗p2v2sin4(θ/2)
(1 −v2sin2(θ/2)).
Known as the Mott cross section, it reduces to the Rutherford cross section you derived in a course on
quantum mechanics in the limit the electron velocity v →0.
II.6.2
To order e2 the amplitude for positron scattering off a proton is just minus the amplitude (3) for electron
scattering off a proton. Thus, somewhat counterintuitively, the differential cross sections for positron
scattering off a proton and for electron scattering off a proton are the same to this order. Show that to
the next order this is no longer true.
II.6.3
Show that the trace of a product of odd number of gamma matrices vanishes.
II.6.4
Prove the identity s + t + u = 
a m2
a.
II.6.5
Verify the differential cross section for relativistic electron electron scattering given in (25).
II.6.6
For those who relish long calculations, determine the differential cross section for electron-electron
scattering without taking the relativistic limit.
II.6.7
Show that the decay rate for one boson of mass M into two bosons of masses m and μ is given by
 =
|M|2
16πM3

(M2 −(m + μ)2)(M2 −(m −μ)2)

II.7
Diagrammatic Proof of Gauge Invariance
Gauge invariance
Conceptually, rather than calculate cross sections, we have the more important task of
proving that we can indeed set the photon mass μ equal to zero with impunity in calculating
any physical process. With μ = 0, the Lagrangian given in chapter II.1 becomes the
Lagrangian for quantum electrodynamics:
L = ¯ψ[iγ μ(∂μ −ieAμ) −m]ψ −1
4FμνF μν
(1)
We are now ready for one of the most important observations in the history of theoretical
physics. Behold, the Lagrangian is left invariant by the gauge transformation
ψ(x) →ei(x)ψ(x)
(2)
and
Aμ(x) →Aμ(x) + 1
ie e−i(x)∂μei(x) = Aμ(x) + 1
e ∂μ(x)
(3)
which implies
Fμν(x) →Fμν(x)
(4)
You are of course already familiar with (3) and the invariance of Fμν from classical
electromagnetism.
In contemporary theoretical physics, gauge invariance1 is regarded as fundamental and
all important, as we will see later. The modern philosophy is to look at (1) as a consequence
of (2) and (3). If we want to construct a gauge invariant relativistic field theory involving a
spin 1
2 and a spin 1 field, then we are forced to quantum electrodynamics.
1 The discovery of gauge invariance was one of the most arduous in the history of physics. Read J. D. Jackson
and L. B. Okun, “Historical roots of gauge invariance,” Rev. Mod. Phys. 73, 2001 and learn about the sad story of
a great physicist whose misfortune in life was that his name differed from that of another physicist by only one
letter.

II.7. Proof of Gauge Invariance | 145
You will notice that in (3) I have carefully given two equivalent forms. While it is simpler,
and commonly done in most textbooks, to write the second form, we should also keep the
first form in mind. Note that (x) and (x) + 2π give exactly the same transformation.
Mathematically speaking, the quantities ei(x) and ∂μ(x) are well defined, but (x) is
not.
After these apparently formal but actually physically important remarks, we are ready
to work on the proof. I will let you give the general proof, but I will show you the way by
working through some representative examples.
Recall that the propagator for the hypothetical massive photon is iDμν = i(kμkν/μ2 −
gμν)/(k2 −μ2). We can set the μ2 in the denominator equal to zero without further ado
andwritethephotonpropagatoreffectivelyasiDμν = i(kμkν/μ2 −gμν)/k2.Thedangerous
term is kμkν/μ2. We want to show that it goes away.
A specific example
First consider electron-electron scattering to order e4. Of the many diagrams, focus on the
two in figure II.7.1.a. The Feynman amplitude is then
¯u(p′)

γ λ
1
̸p+ ̸ k −mγ μ + γ μ
1
̸p′−̸ k −mγ λ

u(p) i
k2
kμkν
μ2 −δν
μ

λν
(5)
where λν is some factor whose detailed structure does not concern us. For the specific
case shown in figure II.7.1a we can of course write out λν explicitly if we want. Note the
plus sign here from interchanging the two photons since photons obey Bose statistics.
p + k
λ
μ
p’ − k
λ
μ
(a)
p’
k
p
p’
k
p
k’
k’
Figure II.7.1

146 | II. Dirac and the Spinor
(b)
p’
k
p
p’
k
p
p’ − k
λ
μ
p + k
λ
μ
Figure II.7.1 (continued)
Focus on the dangerous term. Contracting the ¯u(p′)(. . .)u(p) factor in (5) with kμ we
have
¯u(p′)

γ λ
1
̸p+ ̸ k −m ̸ k+ ̸ k
1
̸p′−̸ k −mγ λ

u(p)
(6)
The trick is to write the ̸ k in the numerator of the first term as (̸p+ ̸ k −m) −(̸p −m), and
in the numerator of the second term as (̸p′ −m) −(̸p′−̸ k −m). Using (̸p −m)u(p) = 0
and ¯u(p′)(̸p′ −m) = 0, we see that the expression in (6) vanishes. This proves the theorem
in this simple example. But since the explicit form of λν did not enter, the proof would
have gone through even if figure II.7.1a were replaced by the more general figure II.7.1b,
where arbitrarily complicated processes could be going on under the shaded blob.
Indeed we can generalize to figure II.7.1c. Apart from the photon carrying momentum
k that we are focusing on, there are already n photons attached to the electron line. These
n photons are just “spectators” in the proof in the same way that the photon carrying
momentum k′ in figure II.7.1a never came into the proof that (6) vanishes. The photon
we are focusing on can attach to the electron line in n + 1 different places. You can now
extend the proof as an exercise.
Photon landing on an internal line
In the example we just considered, the photon line in question lands on an external electron
line. The fact that the line is “capped at the two ends” by ¯u(p′) and u(p) is crucial in the
proof. What if the photon line in question lands on an internal line?
An example is shown in figure II.7.2, contributing to electron-electron scattering in
order e8. The figure contains three distinct diagrams. The electron “on the left” emits

II.7. Proof of Gauge Invariance | 147
(c)
p’
k
p
Figure II.7.1 (continued)
three photons, which attach to an internal electron loop. The electron “on the right”
emits a photon with momentum k, which can attach to the loop in three distinct ways.
Since what we care about is whether the kμkρ/μ2 piece in the photon propagator
i(kμkρ/μ2 −gμρ)/k2 goes away or not, we can for our purposes replace that photon
propagator by kμ. To save writing slightly, we define p1 = p + q1 and p2 = p1 + q2 (see the
momentum labels in figure II.7.2): Let’s focus on the relevant part of the three diagrams,
referring to them as A, B, and C.
A =

d4p
(2π)4 tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −mγ λ
1
̸p+ ̸ k −m ̸ k
1
̸p −m

(7)
B =

d4p
(2π)4 tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −m ̸ k
1
̸p1 −mγ λ
1
̸p −m

(8)
and
C =

d4p
(2π)4 tr

γ ν
1
̸p2+ ̸ k −m ̸ k
1
̸p2 −mγ σ
1
̸p1 −mγ λ
1
̸p −m

(9)
This looks like an unholy mess, but it really isn’t. We use the same trick we used before.
In C write ̸ k = ( ̸p2+ ̸ k −m) −(̸p2 −m), so that
C =

d4p
(2π)4

tr

γ ν
1
̸p2 −mγ σ
1
̸p1 −mγ λ
1
̸p −m

−tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1 −mγ λ
1
̸p −m

(10)
In B write ̸ k = ( ̸p1+ ̸ k −m) −( ̸p1 −m), so that
B =

d4p
(2π)4

tr(γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1 −mγ λ
1
̸p −m)
−tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −mγ λ
1
̸p −m

(11)

148 | II. Dirac and the Spinor
p + k
k
p
p1 + k
p2 + k
q1
q2
−(q1 + q2 + k)
λ
σ
ν
A
k
p
p1 + k
p2 + k
q1
q2
−(q1 + q2 + k)
λ
σ
ν
B
p1
k
p
p2
p2+k
q1
q2
−(q1 + q2 + k)
λ
σ
ν
C
p1
Figure II.7.2

II.7. Proof of Gauge Invariance | 149
Finally, in A write ̸ k = ( ̸p+ ̸ k −m) −( ̸p −m)
A =

d4p
(2π)4

tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −mγ λ
1
̸p −m

−tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −mγ λ
1
̸p+ ̸ k −m

(12)
Now you see what is happening. When we add the three diagrams together terms cancel
in pairs, leaving us with
A + B + C =

d4p
(2π)4

tr

γ ν
1
̸p2 −mγ σ
1
̸p1 −mγ λ
1
̸p −m

−tr

γ ν
1
̸p2+ ̸ k −mγ σ
1
̸p1+ ̸ k −mγ λ
1
̸p+ ̸ k −m

(13)
If we shift (see exercise II.7.2) the dummy integration variable p →p −k in the second
term, we see that the two terms cancel. Indeed, the kμkρ/μ2 piece in the photon propagator
goes away and we can set μ = 0.
I will leave the general proof to you. We have done it for one particular process. Try it
for some other process. You will see how it goes.
Ward-Takahashi identity
Let’s summarize. Given any physical amplitude T μ...(k, . . .) with external electrons on
shell [this is jargon for saying that all necessary factors u(p) and ¯u(p) are included in
T μ...(k, . . .)] describing a process with a photon carrying momentum k coming out of, or
going into, a vertex labeled by the Lorentz index μ, we have
kμT μ...(k, . . .) = 0
(14)
This is sometimes known as a Ward-Takahashi identity.
The bottom line is that we can write iDμν = −igμν/k2 for the photon propagator. Since
we can discard the kμkν/μ2 term in the photon propagator i(kμkν/μ2 −gμν)/k2 we can
also add in a kμkν/k2 term with an arbitrary coefficient. Thus, for the photon propagator
we can use
iDμν = i
k2

(1 −ξ) kμkν
k2
−gμν

(15)
where we can choose the number ξ to simplify our calculation as much as possible.
Evidently, the choice of ξ amounts to a choice of gauge for the electromagnetic field. In
particular, the choice ξ = 1is known as the Feynman gauge, and the choice ξ = 0 is known
as the Landau gauge. If you find an especially nice choice, you can have a gauge named
after you as well! For fairly simple calculations, it is often advisable to calculate with an
arbitrary ξ. The fact that the end result must not depend on ξ provides a useful check on
the arithmetic.

150 | II. Dirac and the Spinor
This completes the derivation of the Feynman rules for quantum electrodynamics: They
are the same rules as those given in chapter II.5 for the massive vector boson theory except
for the photon propagator given in (15).
We have given here a diagrammatic proof of the gauge invariance of quantum
electrodynamics. We will worry later (in chapter IV.7) about the possibility that the shift of
integration momentum used in the proof may not be allowed in some cases.
The longitudinal mode
We now come back to the worry we had in chapter I.5. Consider a massive spin 1 meson
moving along the z−direction. The 3 polarization vectors are fixed by the condition kλελ =
0 with kλ = (ω, 0, 0, k) (recall chapter I.5) and the normalization ελελ = −1, so that ε(1)
λ =
(0, 1, 0, 0), ε(2)
λ = (0, 0, 1, 0), ε(3)
λ = (−k, 0, 0, ω)/μ. Note that as μ →0, the longitudinal
polarization vector ε(3)
λ
becomes proportional to kλ = (ω, 0, 0, −k). The amplitude for
emitting a meson with a longitudinal polarization in the process described by (14) is
given by ε(3)
λ T λ... = (−kT 0... + ωT 3...)/μ = (−kT 0... +

k2 + μ2T 3...)/μ ≃(−kT 0... +
(k + μ2
2k )T 3...)/μ (for μ ≪k), namely −(kλT λ.../μ) + μ
2k T 3... with kλ = (k, 0, 0, −k).Upon
using (14) we see that the amplitude ε(3)
λ T λ... →μ
2kT 3... →0 as μ →0.
The longitudinal mode of the photon does not exist because it decouples from all physical
processes.
Here is an apparent paradox. Mr. Boltzmann tells us that in thermal equilibrium each
degree of freedom is associated with 1
2T . Thus, by measuring some thermal property (such
as the specific heat) of a box of photon gas to an accuracy of 2/3 an experimentalist could
tell if the photon is truly massless rather than have a mass of a zillionth of an electron volt.
The resolution is of course that as the coupling of the longitudinal mode vanishes as
μ →0 the time it takes for the longitudinal mode to come to thermal equilibrium goes to
infinity. Our crafty experimentalist would have to be very patient.
Emission and absorption of photons
According to chapter II.5, the amplitude for emitting or absorbing an external on-shell
photon with momentum k and polarization a (a = 1, 2) is given by ε(a)
μ (k)T μ...(k, . . .).
Thanks to (14), we are free to vary the polarization vector
ε(a)
μ (k) →ε(a)
μ (k) + λkμ
(16)
for arbitrary λ. You should recognize (16) as the momentum space version of (3). As we
will see in the next chapter, by a judicious choice of ε(a)
μ (k), we can simplify a given
calculation considerably. In one choice, known as the “transverse gauge,” the 4-vectors
ε(a)
μ (k) = (0, ⃗ε(k)) for a = 1, 2 do not have time components. (For a photon moving in the
z-direction, this is just the choice specified in the preceding section.)

II.7. Proof of Gauge Invariance | 151
Exercises
II.7.1
Extend the proof to cover figure II.7.1c. [Hint: To get oriented, note that figure II.7.1b corresponds to
n = 1.]
II.7.2
You might have worried whether the shift of integration variable is allowed. Rationalizing the denomi-
nators in the first integral

d4p
(2π)4 tr(γ ν
1
̸p2 −mγ σ
1
̸p1 −mγ λ
1
̸p −m)
in (13) and imagining doing the trace, you can convince yourself that this integral is only logarithmically
divergent and hence that the shift is allowed. This issue will come up again in chapter IV.7 and we are
anticipating a bit here.

II.8
Photon-Electron Scattering and Crossing
Photon scattering on an electron
We now apply what we just learned to calculating the amplitude for the Compton scattering
of a photon on an electron, namely, the process γ (k) + e(p) →γ (k′) + e(p′). First step:
draw the Feynman diagrams, and notice that there are two, as indicated in figure II.8.1.
The electron can either absorb the photon carrying momentum k first or emit the photon
carrying momentum k′ first. Think back to the spacetime stories we talked about in chapter
I.7. The plot of our biopic here is boringly simple: the electron comes along, absorbs and
then emits a photon, or emits and absorbs a photon, and then continues on its merry way.
Because this is a quantum movie, the two alternate plots are shown superposed.
So, apply the Feynman rules (chapter II.5) to get (just to make the writing a bit easier,
we take the polarization vectors ε and ε′ to be real)
M = A(ε′, k′; ε, k) + (ε′ ↔ε, k′ ↔−k)
(1)
where
A(ε′, k′; ε, k) = (−ie)2¯u(p′) ̸ε′
i
̸p + ̸k −m ̸εu(p)
= i(−ie)2
2pk
¯u(p′) ̸ε′(̸p + ̸k + m) ̸εu(p)
(2)
In either case, absorb first or emit first, the electron is penalized for not being real, by the
factor of 1/((p + k)2 −m2) = 1/(2pk) in one case, and 1/((p −k′)2 −m2) = −1/(2pk′) in
the other.
At this point, to obtain the differential cross section, you just have take a deep breath and
calculate away. I will show you, however, that we could simplify the calculation considerably
by a clever choice of polarization vectors and of the frame of reference. (The calculation is
still a big mess, though!) For a change, we will be macho guys and not average and sum
over the photon polarizations.

II.8. Photon-Electron Scattering | 153
p + k
p − k’
(b)
(a)
p’
, k
’, k’
p
p’
, k
p
’, k’
Figure II.8.1
In any case, we have εk = 0 and ε′k′ = 0. Now choose the transverse gauge introduced
in the preceding chapter, so that ε and ε′ have zero time components. Then calculate in
the lab frame. Since p = (m, 0, 0, 0), we have the additional relations
εp = 0
(3)
and
ε′p = 0
(4)
Why is this a shrewd choice? Recall that ̸a ̸b = 2ab −̸b ̸a. Thus, we could move ̸p past
̸ε or ̸ε′ at the rather small cost of flipping a sign. Notice in (1) that (̸p + ̸k + m) ̸εu(p) =
̸ε(−̸p −̸k + m)u(p) = −̸ε ̸ku(p) (where we have used εk = 0.) Thus
A(ε′, k′; ε, k) = ie2¯u(p′) ̸ε′ ̸ε ̸k
2pk u(p)
(5)
To obtain the differential cross section, we need |M|2. We will wimp out a bit and
suppose, just as in chapter II.6, that the initial electron is unpolarized and the polarization
of the final electron is not measured. Then averaging over initial polarization and summing
over final polarization we have [applying II.2.8]
1
2|A(ε′, k′; ε, k)|2 =
e4
2(2m)2(2pk)2tr(̸p′ + m) ̸ε′ ̸ε ̸k(̸p + m) ̸k ̸ε ̸ε′
(6)
In evaluating the trace, keep in mind that the trace of an odd number of gamma
matrices vanishes. The term proportional to m2 contains ̸k ̸k = k2 = 0 and hence van-
ishes. We are left with tr(̸p′ ̸ε′ ̸ε ̸k ̸p ̸k ̸ε ̸ε′) = 2kp tr(̸p′ ̸ε′ ̸ε ̸k ̸ε ̸ε′) = −2kp tr(̸p′ ̸ε′ ̸ε ̸ε ̸k ̸ε′)
= 2kp tr(̸p′ ̸ε′ ̸k ̸ε′) = 8kp[2(kε′)2 + k′p].

154 | II. Dirac and the Spinor
Work through the steps as indicated and the strategy should be clear. We anticommute
judiciously to exploit the “zero relations” εp = 0, ε′p = 0, εk = 0, and ε′k′ = 0 and the
normalization conditions ̸ε ̸ε = ε2 = −1 and ̸ε′ ̸ε′ = ε′2 = −1 as much as possible.
We obtain
1
2|A(ε′, k′; ε, k)|2 =
e4
2(2m)2(2pk)28kp[2(kε′)2 + k′p]
(7)
The other term
1
2|A(ε, −k; ε′, k′)|2 =
e4
2(2m)2(2pk)28(−k′p)[2(k′ε)2 −kp]
follows immediately by inspecting figure II.8.1 and interchanging (ε′ ↔ε, k′ ↔−k).
Just as in chapter II.6, the interference term
1
2A(ε, −k; ε′, k′)∗A(ε′, k′; ε, k) =
e4
2(2m)2(2pk)(−2pk′)tr(̸p′ + m) ̸ε′ ̸ε ̸k(̸p + m) ̸k′ ̸ε′ ̸ε
(8)
is the most tedious to evaluate. Call the trace T . Clearly, it would be best to eliminate
p′ = p + k −k′, since we could “do more” with ̸p than ̸p′. Divide and conquer: write T =
P + Q1 + Q2. First, massage P ≡tr(̸p + m) ̸ε′ ̸ε ̸k(̸p + m) ̸k′ ̸ε′ ̸ε = m2tr ̸ε′ ̸ε ̸k ̸k′ ̸ε′ ̸ε +
tr ̸p ̸ε′ ̸ε ̸k ̸p ̸k′ ̸ε′ ̸ε. In the second term, we could sail the first ̸p past the ̸ε and ̸ε′ (ah, so
nice to work in the rest frame for this problem!) to find the combination ̸p ̸k ̸p = 2kp ̸p −
m2 ̸k. The m2 term gives a contribution that cancels the first term in P, leaving us with
P = 2kp tr ̸ε′ ̸ε ̸p ̸k′ ̸ε′ ̸ε = 2kp tr ̸p ̸k′ ̸ε′(2ε′ε −̸ε′ ̸ε) ̸ε = 8(kp)(k′p)[2(εε′)2 −1]. Similarly,
Q1 = tr ̸k ̸ε′ ̸ε ̸k ̸p ̸k′ ̸ε′ ̸ε = −2kε′ tr ̸k ̸p ̸k′ ̸ε′ = −8(ε′k)2k′p and Q2 = −tr ̸k′ ̸ε′ ̸ε ̸k ̸p ̸k′ ̸ε′ ̸ε
= 8(εk′)2kp′.
Putting it all together and writing kp′ = k′p = mω′ and k′p′ = kp = mω, we find
1
2|M|2 =
e4
(2m)2
ω′
ω + ω
ω′ + 4(εε′)2 −2

(9)
We calculate the differential cross section as in chapter II.6 with some minor differences
since we are in the lab frame, obtaining
dσ =
m
(2π)22ω

d3k′
2ω′
d3p′
Ep′ δ(4)(k′ + p′ −k −p)

1
2
 
|M|2
(10)
As described in the appendix to chapter II.6, we could use (I.8.14) and write
 d3p′
Ep′ (. . .) =

d4p′θ(p′0)δ(p′2 −m2)(. . .). Doing the integral over d4p′ to knock out the 4-dimensional
delta function, we are left with a delta function enforcing the mass shell condition 0 =
p′2 −m2 = (p + k −k′)2 −m2 = 2p(k −k′) −2kk′ = 2m(ω −ω′) −2ωω′(1 −cos θ), with
θ the scattering angle of the photon. Thus, the frequency of the outgoing photon and of
the incoming photon are related by
ω′ =
ω
1 + 2ω
m sin2 θ
2
(11)
giving the frequency shift that won Arthur Compton the Nobel Prize. You realize of course
that this formula, though profound at the time, is “merely” relativistic kinematics and has
nothing to do with quantum field theory per se.

II.8. Photon-Electron Scattering | 155
2, k2
1, k1
2, k2
1, k1
p1  k2
p1  k1
p2
p1
p2
p1
(b)
(a)
Figure II.8.2
What quantum field theory gives us is the Klein-Nishina formula (1929)
dσ
d =
1
(2m)2( e2
4π )2(ω′
ω )2
ω′
ω + ω
ω′ + 4(εε′)2 −2

.
(12)
You ought to be impressed by the year.
Electron-positron annihilation
Here and in chapter II.6 we calculated the cross sections for some interesting scattering
processes. At the end of that chapter we marvelled at the magic of theoretical physics.
Even more magical is the annihilation of matter and antimatter, a process that occurs
only in relativistic quantum field theory. Specifically, an electron and a positron meet and
annihilate each other, giving rise to two photons: e−(p1) + e+(p2) →γ (ε1, k1) + γ (ε2, k2).
(Annihilating into one physical, that is, on-shell, photon is kinematically impossible.)
This process, often featured in science fiction, is unknown in nonrelativistic quantum
mechanics. Without quantum field theory, you would be clueless on how to calculate, say,
the angular distribution of the outgoing photons.
But having come this far, you simply apply the Feynman rules to the diagrams in fig-
ure II.8.2, which describe the process to order e2. We find the amplitude M =
A(k1, ε1; k2, ε2) + A(k2, ε2; k1, ε1) (Bose statistics for the two photons!), where
A(k1, ε1; k2, ε2) = (ie)(−ie)¯v(p2) ̸ε2
i
̸p1 −̸k1 −m ̸ε1u(p1)
(13)
Students of quantum field theory are sometimes confused that while the incoming electron
goes with the spinor u, the incoming positron goes with ¯v, and not with v. You could check
this by inspecting the hermitean conjugate of (II.2.10). Even simpler, note that ¯v(. . .)u
[with (. . .) a bunch of gamma matrices contracted with various momenta] transforms
correctly under the Lorentz group, while v(. . .)u does not (and does not even make sense,
since they are both column spinors.) Or note that the annihilation operator d for the
positron is associated with ¯v, not v.

156 | II. Dirac and the Spinor
I want to emphasize that the positron carries momentum p2 = (+
	
⃗p2
2 + m2, ⃗p2) on its
way to that fatal rendezvous with the electron. Its energy p0
2 = +
	
⃗p2
2 + m2 is manifestly
positive. Nor is any physical particle traveling backward in time. The honest experimental-
ist who arranged for the positron to be produced wouldn’t have it otherwise. Remember
my rant at the end of chapter II.2?
In figure II.8.2a I have labeled the various lines with arrows indicating momentum
flow. The external particles are physical and there would have been serious legal issues
if their energies were not positive. There is no such restriction on the virtual particle
being exchanged, though. Which way we draw the arrow on the virtual particle is purely
up to us. We could reverse the arrow, and then the momentum label would become
p2 −k2 = k1 −p1: the time component of this “composite” 4-vector can be either positive
or negative.
To make the point totally clear, we could also label the lines by dotted arrows showing the
flow of (electron) charge. Indeed, on the positron line, momentum and (electron) charge
flow in opposite directions.
Crossing
I now invite you to discover something interesting by staring at the expression in (13) for
a while.
Got it? Does it remind you of some other amplitude?
No? How about looking at the amplitude for Compton scattering in (2)?
Notice that the two amplitudes could be turned into each other (up to an irrelevant sign)
by the exchange
p ↔p1, k ↔−k1, p′ ↔−p2, k′ ↔k2, ε ↔ε1, ε′ ↔ε2, u(p) ↔u(p1), u(p′) ↔v(p2)
(14)
This is known as crossing. Diagrammatically, we are effectively turning the diagrams in
figures II.8.1 and II.8.2 into each other by 90
◦rotations. Crossing expresses in precise terms
what people who like to mumble something about negative energy traveling backward in
time have in mind.
Once again, it is advantageous to work in the electron rest frame and in the transverse
gauge, so that we have ε1p1 = 0 and ε2p1 = 0 as well as ε1k1 = 0 and ε2k1 = 0. Averaging
over the electron and positron polarizations we obtain
dσ
d = α2
8m

 ω1
| ⃗p|
 ω′
ω + ω
ω′ −4(εε′)2 + 2

(15)
with ω1 = m(m + E)/(m + E −p cos θ), ω2 = (E −m −p cos θ)ω1/m, and p = | ⃗p| and
E the positron momentum and energy, respectively.

II.8. Photon-Electron Scattering | 157
x
time
y
Figure II.8.3
Special relativity and quantum mechanics require antimatter
The formalism in chapter II.2 makes it totally clear that antimatter is obligatory. For us to
be able to add the operators b and d† in (II.2.10) they must carry the same electric charge,
and thus b and d carry opposite charge. No room for argument there. Still, it would be
comforting to have a physical argument that special relativity and quantum mechanics
mandate antimatter.
Compton scattering offers a context for constructing a nice heuristic argument. Think
of the process in spacetime. We have redrawn figure II.8.1a in figure II.8.3: the electron is
hit by the photon at the point x, propagates to the point y, and emits a photon. We have
assumed implicitly that (y0 −x0) > 0, since we don’t know what propagating backward
in time means. (If the reader knows how to build a time machine, let me know.) But
special relativity tells us that another observer moving by (along the 1-direction say) would
see the time difference (y′0 −x′0) = coshϕ(y0 −x0) −sinhϕ(y1 −x1), which could be
negative for large enough boost parameter ϕ, provided that (y1 −x1) > (y0 −x0), that
is, if the separation between the two spacetime points x and y were spacelike. Then this
observer would see the field disturbance propagating from y to x. Since we see negative
electric charge propagating from x to y, the other observer must see positive electric
charge propagating from y to x. Without special relativity, as in nonrelativistic quantum
mechanics, we simply write down the Sch¨odinger equation for the electron and that is
that. Special relativity allows different observers to see different time ordering and hence
opposite charges flowing toward the future.
Exercises
II.8.1
Show that averaging and summing over photon polarizations amounts to replacing the square bracket
in (9) by 2[ ω′
ω + ω
ω′ −sin2 θ]. [Hint: We are working in the transverse gauge.]
II.8.2
Repeat the calculation of Compton scattering for circularly polarized photons.

This page intentionally left blank

Part III
Renormalization and Gauge Invariance

This page intentionally left blank

III.1
Cutting Off Our Ignorance
Who is afraid of infinities? Not I, I just cut them off.
—Anonymous
An apparent sleight of hand
The pioneers of quantum field theory were enormously puzzled by the divergent integrals
that they often encountered in their calculations, and they spent much of the 1930s
and 1940s struggling with these infinities. Many leading lights of the day, driven to
desperation, advocated abandoning quantum field theory altogether. Eventually, a so-called
renormalization procedure was developed whereby the infinities were argued away and
finite physical results were obtained. But for many years, well into the late 1960s and even
the 1970s many physicists looked upon renormalization theory suspiciously as a sleight of
hand. Jokes circulated that in quantum field theory infinity is equal to zero and that under
the rug in a field theorist’s office had been swept many infinities.
Eventually, starting in the 1970s a better understanding of quantum field theory was
developed through the efforts of Ken Wilson and many others. Field theorists gradually
came to realize that there is no problem of divergences in quantum field theory at all. We
now understand quantum field theory as an effective low energy theory in a sense I will
explain briefly here and in more detail in chapter VIII.3.
Field theory blowing up
We have to see an infinity before we can talk about how to deal with infinities. Well, we
saw one in chapter I.7. Recall that the order λ2 correction (I.7.23) to the meson-meson
scattering amplitude diverges. With K ≡k1 + k2, we have
M = 1
2(−iλ)2i2

d4k
(2π)4
1
k2 −m2 + iε
1
(K −k)2 −m2 + iε
(1)
As I remarked back in chapter I.7, even without doing any calculations we can see the
problem that confounded the pioneers of quantum field theory. The integrand goes as 1/k4

162 | III. Renormalization and Gauge Invariance
for large k and thus the integral diverges logarithmically as

d4k/k4. (The ordinary integral
 ∞dr rn diverges linearly for n = 0, quadratically for n = 1, and so on, and
 ∞dr/r
diverges logarithmically.) Since this divergence is associated with large values of k it is
known as an ultraviolet divergence.
To see how to deal with this apparent infinity, we have to distinguish between two con-
ceptually separate issues, associated with the terrible names “regularization” and “renor-
malization” for historical reasons.
Parametrization of ignorance
Suppose we are studying quantum electrodynamics instead of this artificial ϕ4 theory. It
would be utterly unreasonable to insist that the theory of an electron interacting with a
photon would hold to arbitrarily high energies. At the very least, with increasingly higher
energies other particles come in, and eventually electrodynamics becomes merely part of
a larger electroweak theory. Indeed, these days it is thought that as we go to higher and
higher energies the whole edifice of quantum field theory will ultimately turn out to be an
approximation to a theory whose identity we don’t yet know, but probably a string theory
according to some physicists.
The modern view is that quantum field theory should be regarded as an effective low
energy theory, valid up to some energy (or momentum in a Lorentz invariant theory) scale
. We can imagine living in a universe described by our toy ϕ4 theory. As physicists in
this universe explore physics to higher and higher momentum scales they will eventually
discover that their universe is a mattress constructed out of mass points and springs. The
scale  is roughly the inverse of the lattice spacing.
When I teach quantum field theory, I like to write “Ignorance is no shame” on the
blackboard for emphasis when I get to this point. Every physical theory should have a
domain of validity beyond which we are ignorant of the physics. Indeed were this not true
physics would not have been able to progress. It is a good thing that Feynman, Schwinger,
Tomonaga, and others who developed quantum electrodynamics did not have to know
about the charm quark for example.
I emphasize that  should be thought of as physical, parametrizing our threshold of
ignorance, and not as a mathematical construct.1 Indeed, physically sensible quantum
field theories should all come with an implicit . If anyone tries to sell you a field theory
claiming that it holds up to arbitrarily high energies, you should check to see if he sold
used cars for a living. (As I wrote this, a colleague who is an editor of Physical Review Letters
told me that he worked as a garbage collector during high school vacations, adding jokingly
that this experience prepared him well for his present position.)
1 We saw a particularly vivid example of this in chapter I.8. When we define a conducting plate as a surface
on which a tangential electric field vanishes, we are ignorant of the physics of the electrons rushing about to
counter any such imposed field. At extremely high frequencies, the electrons can’t rush about fast enough and
new physics comes in, namely that high frequency modes do not see the plates. In calculating the Casimir force
we parametrize our ignorance with a ∼−1.

III.1. Cutting Off Our Ignorance | 163
Figure III.1.1
Thus, in evaluating (1) we should integrate only up to , known as a cutoff. We
literally cut off the momentum integration (fig. III.1.1).2 The integral is said to have been
“regularized.”
Since my philosophy in this book is to emphasize the conceptual rather than the
computational, I will not actually do the integral but merely note that it is equal to
2iC log(2/K2) where C is some numerical constant that you can compute if you want
(see appendix 1 to this chapter). For the sake of simplicity I also assumed that m2 << K2
so that we could neglect m2 in the integrand. It is convenient to use the kinematic variables
s ≡K2 = (k1 + k2)2, t ≡(k1 −k3)2, and u ≡(k1 −k4)2 introduced in chapter II.6. (Writing
out the kj’s explicitly in the center-of-mass frame, you see that s, t, and u are related to
rather mundane quantities such as the center-of-mass energy and the scattering angle.)
After all this, the meson-meson scattering amplitude reads
M = −iλ + iCλ2[log

2
s

+ log

2
t

+ log

2
u

] + O(λ3)
(2)
This much is easy enough to understand. After regularization, we speak of cutoff-
dependent quantities instead of divergent quantities, and M depends logarithmically on
the cutoff.
2 A. Zee, Einstein’s Universe, p. 204. Cartooning schools apparently teach that physicists in general, and
quantum field theorists in particular, all wear lab coats.

164 | III. Renormalization and Gauge Invariance
What is actually measured
Now that we have dealt with regularization, let us turn to renormalization, a terrible word
because it somehow implies we are doing normalization again when in fact we haven’t
yet.
The key here is to imagine what we would tell an experimentalist about to measure
meson-meson scattering. We tell her (or him if you insist) that we need a cutoff  and she
is not bothered at all; to an experimentalist it makes perfect sense that any given theory
has a finite domain of validity.
Our calculation is supposed to tell her how the scattering will depend on the center-of-
mass energy and the scattering angle. So we show her the expression in (2). She points to
λ and exclaims, “What in the world is that?”
We answer, “The coupling constant,” but she says, “What do you mean, coupling
constant, it’s just a Greek letter!”
A confused student, Confusio, who has been listening in, pipes up, “Why the fuss? I
have been studying physics for years and years, and the teachers have shown us lots of
equations with Latin and Greek letters, for example, Hooke’s law F = −kx, and nobody
gets upset about k being just a Latin letter.”
Smart Experimentalist: “But that is because if you give me a spring I can go out and
measure k. That’s the whole point! Mr. Egghead Theorist here has to tell me how to
measure this λ.”
Woah, that is a darn smart experimentalist. We now have to think more carefully what
a coupling constant really means. Think about α, the coupling constant of quantum elec-
trodynamics. Well, it is the coefficient of 1/r in Coulomb’s law. Fine, Monsieur Coulomb
measured it using metallic balls or something. But a modern experimentalist could just
as well have measured α by scattering an electron at such and such an energy and at
such and such a scattering angle off a proton. We explain all this to our experimentalist
friend.
SE, nodding, agrees: “Oh yes, recently my colleague so and so measured the coupling for
meson-meson interaction by scattering one meson off another at such and such an energy
and at such and such a scattering angle, which correspond to your variables s, t, and u
having values s0, t0, and u0. But what does the coupling constant my colleague measured,
let us call it λP , with the subscript meaning “physical,” have to do with your theoretical λ,
which, as far as I am concerned, is just a Greek letter in something you call a Lagrangian!”
Confusio, “Hey, if she’s going to worry about small lambda, I am going to worry about
big lambda. How do I know how big the domain of validity is?”
SE: “Confusio, you are not as dumb as you look! Mr. Egghead Theorist, if I use your
formula (2), what is the precise value of  that I am supposed to plug in? Does it depend
on your mood, Mr. Theorist? If you wake up feeling optimistic, do you use 2 instead of
? And if your girl friend left you, you use 1
2?”
We assert, “Ha, we know the answer to that one. Look at (2): M is supposed to be an
actual scattering amplitude and should not depend on . If someone wants to change 

III.1. Cutting Off Our Ignorance | 165
we just shift λ in such a way so that Mdoes not change. In fact, a couple lines of arithmetic
will show you precisely what dλ/d has to be (see exercise III.1.3).”
SE: “Okay, so λ is secretly a function of . Your notation is lousy.”
We admit, “Exactly, this bad notation has confused generations of physicists.”
SE: “I am still waiting to hear how the λP my experimental colleague measured is related
to your λ.”
We say, “Aha, that’s easy. Just look at (2), which is repeated here for clarity and for your
reading convenience:
M = −iλ + iCλ2

log

2
s

+ log

2
t

+ log

2
u

+ O(λ3)
(3)
According to our theory, λP is given by
−iλP = −iλ + iCλ2

log

2
s0

+ log

2
t0

+ log

2
u0

+ O(λ3)
(4)
To show you clearly what is involved, let us denote the sum of logarithms in the square
bracket in (3) and in (4) by L and by L0, respectively, so that we can write (3) and (4) more
compactly as
M = −iλ + iCλ2L + O(λ3)
(5)
and
−iλP = −iλ + iCλ2L0 + O(λ3)
(6)
That is how λP and λ are related.”
SE: “If you give me the scattering amplitude expressed in terms of the physical coupling
λP then it’s of use to me, but it’s not of use in terms of λ. I understand what λP is, but
not λ.”
We answer: “Fine, it just takes two lines of algebra to eliminate λ in favor of λP . Big deal.
Solving (6) for λ gives
−iλ = −iλP −iCλ2L0 + O(λ3) = −iλP −iCλ2
PL0 + O(λ3
P)
(7)
The second equality is allowed to the order of approximation indicated. Now plug this
into (5)
M = −iλ + iCλ2L + O(λ3) = −iλP −iCλ2
PL0 + iCλ2
PL + O(λ3
P)
(8)
Please check that all manipulations are legitimate up to the order of approximation indi-
cated.”
The “miracle”
Lo and behold! The miracle of renormalization!
Now in the scattering amplitude M we have the combination L −L0 = [log(s0/s) +
log(t0/t) + log(u0/u)]. In other words, the scattering amplitude comes out as
M = −iλP + iCλ2
P

log

s0
s

+ log

t0
t

+ log

u0
u

+ O(λ3
P)
(9)

166 | III. Renormalization and Gauge Invariance
We announce triumphantly to our experimentalist friend that when the scattering
amplitude is expressed in terms of the physical coupling constant λP as she had wanted,
the cutoff  disappear completely!
The answer should always be in terms of physically measurable quantities
The lesson here is that we should express physical quantities not in terms of “fictitious”
theoretical quantities such as λ, but in terms of physically measurable quantities such as
λP .
By the way, in the literature, λP is often denoted by λR and for historical reasons called the
“renormalized coupling constant.” I think that the physics of “renormalization” is much
clearer with the alternative term “physical coupling constant,” hence the subscript P . We
never did have a “normalized coupling constant.”
Suddenly Confusio pipes up again; we have almost forgotten him!
Confusio: “You started out with an M in (2) with two unphysical quantities λ and ,
and their “unphysicalness” sort of cancel each other out.”
SE: “Yeah, it is reminiscent of what distinguishes the good theorists from the bad ones.
The good ones always make an even number of sign errors, and the bad ones always make
an odd number.”
Integrating over only the slow modes
In the path integral formulation, the scattering amplitude M discussed here is obtained
by evaluating the integral (chapter I.7)

Dϕ ϕ(x1)ϕ(x2)ϕ(x3)ϕ(x4)ei 
ddx{ 1
2 [(∂ϕ)2−m2ϕ2]−λ
4!ϕ4}
The regularization used here corresponds roughly to restricting ourselves, in the integral

Dϕ, to integrating over only those field configurations ϕ(x) whose Fourier transform
ϕ(k) vanishes for k >∼. In other words, the fields corresponding to the internal lines in
the Feynman diagrams in fig. (I.7.10) are not allowed to fluctuate too energetically. We will
come back to this path integral formulation later when we discuss the renormalization
group.
Alternative lifestyles
I might also mention that there are a number of alternative ways of regularizing Feyn-
man diagrams, each with advantages and disadvantages that make them suitable for some
calculations but not others. The regularization used here, known as Pauli-Villars, has the
advantage of being physically transparent. Another often used regularization is known as

III.1. Cutting Off Our Ignorance | 167
dimensional regularization. We pretend that we are calculating in d-dimensional space-
time. After the Feynman integral has been beaten down to a suitable form, we do an analytic
continuation in d and set d = 4 at the end of the day. The cutoff dependences of various
integrals now show up as poles as we let d →4. Just as the cutoff  disappears when
the scattering amplitude is expressed in terms of the physical coupling constant λP, in di-
mensional regularization the scattering amplitude expressed in terms of λP is free of poles.
While dimensional regularization proves to be useful in certain contexts as I will note in a
later chapter, it is considerably more abstract and formal than Pauli-Villars regularization.
Each to his or her own taste when it comes to regularizing.
Since the emphasis in this book is on the conceptual rather than the computational, I
won’t discuss other regularization schemes but will merely sketch how Pauli-Villars and
dimensional regularizations work in two appendixes to this chapter.
Appendix 1: Pauli-Villars regularization
The important message of this chapter is the conceptual point that when physical amplitudes are expressed in
term of physical coupling constants the cutoff dependence disappears. The actual calculation of the Feynman
integral is unimportant. But I will show you how to do the integral just in case you would like to do Feynman
integrals for a living.
Let us start with the convergent integral

d4k
(2π)4
1
(k2 −c2 + iε)3 =
−i
32π2c2
(10)
The dependence on c2 follows from dimensional analysis. The overall factor is calculated in appendix D.
Applying the identity (D.15)
1
xy =
 1
0
dα
1
[αx + (1 −α)y]2
(11)
to (1) we have
M =1
2(−iλ)2i2

d4k
(2π)4
 1
0
dα 1
D
with
D = [α(K −k)2 + (1 −α)k2 −m2 + iε]2 = [(k −αK)2 + α(1 −α)K2 −m2 + iε]2
Shift the integration variable k →k + αK and we meet the integral

[d4k/(2π)4] [1/(k2 −c2 + iε)2], where
c2 = m2 −α(1 −α)k2. Pauli-Villars proposed replacing it by

d4k
(2π)4

1
(k2 −c2 + iε)2 −
1
(k2 −2 + iε)2

(12)
with 2 ≫c2. For k much smaller than  the added second term in the integrand is of order −4 and is negligible
compared to the first term since  is much larger than c. For k much larger than , the two terms almost cancel
and the integrand vanishes rapidly with increasing k, effectively cutting off the integral.
Upon differentiating (12) with respect to c2 and using (10) we deduce that (12) must be equal to
(i/16π2) log(2/c2). Thus, the integral
 
d4k
(2π)4
1
(k2 −c2 + iε)2 =
i
16π2 log

2
c2

(13)
is indeed logarithmically dependent on the cutoff, as anticipated in the text.

168 | III. Renormalization and Gauge Invariance
For what it is worth, we obtain
M = iλ2
32π2
 1
0
dα log

2
m2 −α(1 −α)K2 −iε

(14)
Appendix 2: Dimensional regularization
The
basic
idea
behind
dimensional
regularization
is
very
simple.
When
we
reach
I =

[d4k/(2π)4][1/(k2 −c2 + iε)2] we rotate to Euclidean space and generalize to d dimensions (see appen-
dix D):
I(d) = i

dd
Ek
(2π)d
1
(k2 + c2)2 = i
 2πd/2
(d/2)

1
(2π)d
 ∞
0
dk kd−1
1
(k2 + c2)2
As I said, I don’t want to get bogged down in computation in this book, but we’ve got to do what we’ve got to do.
Changing the integration variable by setting k2 + c2 = c2/x we find
 ∞
0
dk kd−1
1
(k2 + c2)2 = 1
2cd−4
 1
0
dx(1 −x)d/2−1x1−d/2,
which we are supposed to recognize as the integral representation of the beta function. After the dust settles, we
obtain
i

dd
Ek
(2π)d
1
(k2 + c2)2 = i
1
(4π)d/2

4 −d
2

cd−4
(15)
As d →4, the right-hand side becomes
i
1
(4π)2

2
4 −d −log c2 + log(4π) −γ + O(d −4)

where γ = 0.577 . . . denotes the Euler-Mascheroni constant.
Comparing with (13) we see that log 2 in Pauli-Villars regularization has been effectively replaced by the pole
2/(4 −d). As noted in the text, when physical quantities are expressed in terms of physical coupling constants,
all such poles cancel.
Exercises
III.1.1
Work through the manipulations leading to (9) without referring to the text.
III.1.2
Regard (1) as an analytic function of K2. Show that it has a cut extending from 4m2 to infinity. [Hint: If
you can’t extract this result directly from (1) look at (14). An extensive discussion of this exercise will be
given in chapter III.8.]
III.1.3
Change  to eε. Show that for M not to change, to the order indicated λ must change by δλ =
6εCλ2 + O(λ3), that is,
 dλ
d = 6Cλ2 + O(λ3)

III.2
Renormalizable versus Nonrenormalizable
Old view versus new view
We learned that if we were to write the meson meson scattering amplitude in terms
of a physically measured coupling constant λP, the dependence on the cutoff  would
disappear (at least to order λ2
P). Were we lucky or what?
Well, it turns out that there are quantum field theories in which this would happen and
that there are quantum field theories in which this would not happen, which gives us a
binary classification of quantum field theories. Again, for historical reasons, the former
are known as “renormalizable theories” and are considered “nice.” The latter are known
as “nonrenormalizable theories,” evoking fear and loathing in theoretical physicists.
Actually, with the new view of field theories as effective low energy theories to some
underlying theory, physicists now look upon nonrenormalizable theories in a much more
sympathetic light than a generation ago. I hope to make all these remarks clear in this and
a later chapter.
High school dimensional analysis
Let us begin with some high school dimensional analysis. In natural units in which ℏ= 1
and c = 1, length and time have the same dimension, the inverse of the dimension of mass
(and of energy and momentum). Particle physicists tend to count dimension in terms of
mass as they are used to thinking of energy scales. Condensed matter physicists, on the
other hand, usually speak of length scales. Thus, a given field operator has (equal and)
opposite dimensions in particle physics and in condensed matter physics. We will use the
convention of the particle physicists.
Since the action S ≡

d4xL appears in the path integral as eiS, it is clearly dimension-
less, thus implying that the Lagrangian (Lagrangian density, strictly speaking) L has the
same dimension as the 4th power of a mass. We will use the notation [L] = 4 to indicate

170 | III. Renormalization and Gauge Invariance
that L has dimension 4. In this notation [x] = −1 and [∂] = 1. Consider the scalar field
theory L = 1
2[(∂ϕ)2 −m2ϕ2] −λϕ4. For the term (∂ϕ)2 to have dimension 4, we see that
[ϕ] = 1(since 2(1+ [ϕ]) = 4). This then implies that [λ] = 0, that is, the coupling λ is dimen-
sionless. The rule is simply that for each term in L, the dimensions of the various pieces,
including the coupling constant and mass, have to add up to 4 (thus, e.g., [λ] + 4[ϕ] = 4).
How about the fermion field ψ? Applying this rule to the Lagrangian L = ¯ψiγ μ∂μψ +
. . . we see that [ψ] = 3
2. (Henceforth we will suppress the . . . ; it is understood that we
are looking at a piece of the Lagrangian. Furthermore, since we are doing dimensional
analysis we will often suppress various irrelevant factors, such as numerical factors and
the gamma matrices in the Fermi interaction that we will come to presently.) Looking at
the coupling f ϕ ¯ψψ we see that the Yukawa coupling f is dimensionless. In contrast, in
the theory of the weak interaction with L = G ¯ψψ ¯ψψ we see that the Fermi coupling G
has dimension −2 (since −2 + 4( 3
2) = 4; got that?).
From the Maxwell Lagrangian −1
4FμνF μν we see that [Aμ] = 1 and hence Aμ has the
same dimension as ∂μ: The vector field has the same dimension as the scalar field. The
electromagnetic coupling eAμ ¯ψγ μψ tells us that e is dimensionless, which we can also
deduce from Coulomb’s law written in natural units V (r) = α/r, with the fine structure
constant α = e2/4π.
Scattering amplitude blows up
We are now ready for a heuristic argument regarding the nonrenormalizability of a theory.
Consider Fermi’s theory of the weak interaction. Imagine calculating the amplitude M
for a four-fermion interaction, say neutrino-neutrino scattering at an energy much smaller
than . In lowest order, M ∼G. Let us try to write down the amplitude to the next order:
M ∼G + G2(?), where we will try to guess what (?) is. Since all masses and energies
are by definition small compared to the cutoff , we can simply set them equal to zero.
Since [G] = −2, by high school dimensional analysis the unknown factor (?) must have
dimension +2. The only possibility for (?) is 2. Hence, the amplitude to the next order
must have the form M ∼G + G22. We can also check this conclusion by looking at the
Feynman diagram in figure III.2.1: Indeed it goes as G2   d4p (1/p)(1/p) ∼G22.
Without a cutoff on the theory, or equivalently with  = ∞, theorists realized that the
theory was sick: Infinity was the predicted value for a physical quantity. Fermi’s weak
interaction theory was said to be nonrenormalizable. Furthermore, if we try to calculate to
higher order, each power of G is accompanied by another factor of 2.
In desperation, some theorists advocated abandoning quantum field theory altogether.
Others expended an enormous amount of effort trying to “cure” weak interaction theory.
For instance, one approach was to speculate that the series (with coefficients suppressed)
M ∼G[1 + G2 + (G2)2 + (G2)4 + . . .] summed to Gf (G2), where the unknown
function f might have the property that f (∞) was finite. In hindsight, we now know that
this is not a fruitful approach.

III.2. Renormalization Issues | 171
ν
ν
ν
ν
ν
ν
Figure III.2.1
Instead, what happened was that toward the late 1960s S. Glashow, A. Salam, and S.
Weinberg, building on the efforts of many others, succeeded in constructing an elec-
troweak theory unifying the electromagnetic and weak interactions, as I will discuss in
chapter VII.2. Fermi’s weak interaction theory emerges within electroweak theory as a
low energy effective theory.
Fermi’s theory cried out
In modern terms, we think of the cutoff  as really being there and we hear the cutoff
dependence of the four-fermion interaction amplitude M∼G + G22 as the sound of the
theory crying out that something dramatic has to happen at the energy scale  ∼(1/G)
1
2.
The second term in the perturbation series becomes comparable to the first, so at the very
least perturbation theory fails.
Here is another way of making the same point. Suppose that we don’t know anything
about cutoff and all that. With G having mass dimension −2, just by high school dimen-
sional analysis we see that the neutrino-neutrino scattering amplitude at center-of-mass
energy E has to go as M ∼G + G2E2 + . . . . When E reaches the scale ∼(1/G)
1
2 the am-
plitude reaches order unity and some new physics must take over just because the cross
section is going to violate the unitarity bound from basic quantum mechanics. (Remember
phase shift and all that?)
In fact, what that something is goes back to Yukawa, who at the same time that he
suggested the meson theory for the nuclear forces also suggested that an intermediate
vector boson could account for the Fermi theory of the weak interaction. (In the 1930s the
distinction between the strong and the weak interactions was far from clear.) Schematically,
consider a theory of a vector boson of mass M coupled to a fermion field via a dimensionless
coupling constant g:
L = ¯ψ(iγ μ∂μ −m)ψ −1
4FμνF μν + M2AμAμ + gAμ ¯ψγ μψ
(1)

172 | III. Renormalization and Gauge Invariance
k
Figure III.2.2
Let’s calculate fermion-fermion scattering. The Feynman diagram in figure III.2.2 gen-
erates an amplitude (−ig)2(¯uγ μu)[i/(k2 −M2 + iε)](¯uγμu), which when the momentum
transfer k is much less than M becomes i(g2/M2)(¯uγ μu)(¯uγμu). But this is just as if the
fermions are interacting via a Fermi theory of the form G( ¯ψγ μψ)( ¯ψγμψ) with G = g2/M2.
If we blithely calculate with the low energy effective theory G( ¯ψγ μψ)( ¯ψγμψ), it cries
out that it is going to fail. Yes sir indeed, at the energy scale (1/G)
1
2 = M/g, the vector
boson is produced. New physics appears.
I find it sobering and extremely appealing that theories in physics have the ability to
announce their own eventual failure and hence their domains of validity, in contrast to
theories in some other areas of human thought.
Einstein’s theory is now crying out
The theory of gravity is also notoriously nonrenormalizable. Simply comparing Newton’s
law V (r) = GNM1M2/r with Coulomb’s V (r) = α/r we see that Newton’s gravitational
constant GN has mass dimension −2. No more need be said. We come to the same
morose conclusion that the theory of gravity, just like Fermi’s theory of weak interaction,
is nonrenormalizable. To repeat the argument, if we calculate graviton-graviton scattering
at energy E, we encounter the series ∼[1 + GNE2 + (GNE2)2 + . . .].
Just as in our discussion of the Fermi theory, the nonrenormalizability of quantum grav-
ity tells us that at the Planck energy scale (1/GN)
1
2 ≡MPlanck ∼1019mproton new physics
must appear. Fermi’s theory cried out, and the new physics turned out to be the elec-
troweak theory. Einstein’s theory is now crying out. Will the new physics turn out to be
string theory?1
Exercise
III.2.1
Consider the d-dimensional scalar field theory S =

ddx( 1
2(∂ϕ)2 + 1
2m2ϕ2 + λϕ4 + . . . + λnϕn + . . .).
Show that [ϕ] = (d −2)/2 and [λn] = n(2 −d)/2 + d. Note that ϕ is dimensionless for d = 2.
1 J. Polchinski, String Theory.

III.3
Counterterms and Physical Perturbation Theory
Renormalizability
The heuristic argument of the previous chapter indicates that theories whose coupling has
negative mass dimension are nonrenormalizable. What about theories with dimensionless
couplings, such as quantum electrodynamics and the ϕ4 theory? As a matter of fact, both
of these theories have been proved to be renormalizable. But it is much more difficult to
prove that a theory is renormalizable than to prove that it is nonrenormalizable. Indeed,
the proof that nonabelian gauge theory (about which more later) is renormalizable took
the efforts of many eminent physicists, culminating in the work of ’t Hooft, Veltman, B.
Lee, Zinn-Justin, and many others.
Consider again the simple ϕ4 theory. First, a trivial remark: The physical coupling
constant λP is a function of s0, t0, and u0 [see (III.1.4)]. For theoretical purposes it is much
less cumbersome to set s0, t0, and u0 equal to μ2 and thus use, instead of (III.1.4), the
simpler definition
−iλP = −iλ + 3iCλ2 log

2
μ2

+ O(λ3)
(1)
This is purely for theoretical convenience.1
We saw that to order λ2 the meson-meson scattering amplitude when expressed in terms
of the physical coupling λP is independent of the cutoff . How do we prove that this is true
to all orders in λ?Dimensional analysis only tells us that to any order in λ the dependence of
the meson scattering amplitude on the cutoff must be a sum of terms going as [log(/μ)]p
with some power p.
The meson-meson scattering amplitude is certainly not the only quantity that depends
on the cutoff. Consider the inverse of the ϕ propagator to order λ2 as shown in figure III.3.1.
1 In fact, the kinematic point s0 = t0 = u0 = μ2 cannot be reached experimentally, but that’s of concern to
theorists.

174 | III. Renormalization and Gauge Invariance
k
k
q
k
k
q
p
(a)
(b)
Figure III.3.1
The Feynman diagram in figure III.3.1a gives something like
−iλ
   d4q
(2π)4
 
i
q2 −m2 + iε

The precise value does not concern us; we merely note that it depends quadratically on the
cutoff  but not on k2. The diagram in figure III.3.1b involves a double integral
I(k, m, ; λ) ≡(−iλ)2
   d4p
(2π)4
d4q
(2π)4
i
p2 −m2 + iε
i
q2 −m2 + iε
i
(p + q + k)2 −m2 + iε
(2)
Counting powers of p and q we see that the integral ∼

(d8P/P 6) and so I depends
quadratically on the cutoff .
By Lorentz invariance I is a function of k2, which we can expand in a series D + Ek2 +
Fk4 + . . . . The quantity D is just I with the external momentum k set equal to zero and
so depends quadratically on the cutoff . Next, we can obtain E by differentiating I with
respect to k twice and then setting k equal to zero. This clearly decreases the powers of p and
q in the integrand by 2 and so E depends only logarithmically on the cutoff . Similarly,
we can obtain F by differentiating I with respect to k four times and then setting k equal to
zero. This decreases the powers of p and q in the integrand by 4 and thus F is given by an
integral that goes as ∼

d8P/P 10 for large P. The integral is convergent and hence cutoff
independent. We can clearly repeat the argument ad infinitum. Thus F and the terms in
(. . .) are cutoff independent as the cutoff goes to infinity and we don’t have to worry about
them.
Putting it altogether, we have the inverse propagator k2 −m2 + a + bk2 up to O(k2) with
a and b, respectively, quadratically and logarithmically cutoff dependent. The propagator
is changed to
1
k2 −m2 →
1
(1 + b)k2 −(m2 −a)
(3)
The pole in k2 is shifted to m2
P ≡m2 + δm2 ≡(m2 −a)(1 + b)−1, which we identify as
the physical mass. This shift is known as mass renormalization. Physically, it is quite
reasonable that quantum fluctuations will shift the mass.

III.3. Physical Perturbation Theory | 175
What about the fact that the residue of the pole in the propagator is no longer 1 but
(1 + b)−1?
To understand this shift in the residue, recall that we blithely normalized the field ϕ so
that L = 1
2(∂ϕ)2 + . . . . That the coefficient of k2 in the lowest order inverse propagator
k2 −m2 is equal to 1 reflects the fact that the coefficient of
1
2(∂ϕ)2 in L is equal to 1.
There is certainly no guarantee that with higher order corrections included the coefficient
of 1
2(∂ϕ)2 in an effective L will stay at 1. Indeed, we see that it is shifted to (1 + b). For
historical reasons, this is known as “wave function renormalization” even though there is
no wave function anywhere in sight. A more modern term would be field renormalization.
(The word renormalization makes some sense in this case, as we did normalize the field
without thinking too much about it.)
Incidentally, it is much easier to say “logarithmic divergent” than to say “logarithmically
dependent on the cutoff ,” so we will often slip into this more historical and less accurate
jargon and use the word divergent. In ϕ4 theory, the wave function renormalization and the
coupling renormalization are logarithmically divergent, while the mass renormalization
is quadratically divergent.
Bare versus physical perturbation theory
What we have been doing thus far is known as bare perturbation theory. We should have
put the subscript 0 on what we have been calling ϕ, m, and λ. The field ϕ0 is known as
the bare field, and m0 and λ0 are known as the bare mass and bare coupling, respectively.
I did not put on the subscript 0 way back in part I because I did not want to clutter up the
notation before you, the student, even knew what a field was.
Seen in this light, using bare perturbation theory seems like a really stupid thing to
do, and it is. Shouldn’t we start out with a zeroth order theory already written in terms of
the physical mass mP and physical coupling λP that experimentalists actually measure,
and perturb around that theory? Yes, indeed, and this way of calculating is known as
renormalized or dressed perturbation theory, or as I prefer to call it, physical perturbation
theory.
We write
L = 1
2[(∂ϕ)2 −m2
Pϕ2] −λP
4! ϕ4 + A(∂ϕ)2 + Bϕ2 + Cϕ4
(4)
(A word on notation: The pedantic would probably want to put a subscript P on the field
ϕ, but let us clutter up the notation as little as possible.) Physical perturbation theory
works as follows. The Feynman rules are as before, but with the crucial difference that
for the coupling we use λP and for the propagator we write i/(k2 −m2
P + iε) with the
physical mass already in place. The last three terms in (4) are known as counterterms.
The coefficients A, B, and C are determined iteratively (see later) as we go to higher and
higher order in perturbation theory. They are represented as crosses in Feynman diagrams,
as indicated in figure III.3.2, with the corresponding Feynman rules. All momentum
integrals are cut off.

176 | III. Renormalization and Gauge Invariance
k
+2i(Ak2 + B)
i
k2−mp
2
k
k
−iλp
4!iC
Figure III.3.2
Let me now explain how A, B, and C are determined iteratively. Suppose we have
determined them to order λN
P . Call their values to this order AN , BN , and CN. Draw all the
diagrams that appear in order λN+1
P
. We determine AN+1, BN+1, and CN+1 by requiring
that the propagator calculated to the order λN+1
P
has a pole at mP with a residue equal to
1, and that the meson-meson scattering amplitude evaluated at some specified values of
the kinematic variables has the value −iλP . In other words, the counterterms are fixed
by the condition that mP and λP are what we say they are. Of course, A, B, and C will
be cutoff dependent. Note that there are precisely three conditions to determine the three
unknowns AN+1, BN+1, and CN+1.
Explained in this way, you can see that it is almost obvious that physical perturbation
theory works, that is, it works in the sense that all the physical quantities that we calculate
will be cutoff independent. Imagine, for example, that you labor long and hard to calculate
the meson-meson scattering amplitude to order λ17
P . It would contain some cutoff depen-
dent and some cutoff independent terms. Then you simply add a contribution given by
C17 and adjust C17 to cancel the cutoff dependent terms.
But ah, you start to worry. You say, “What if I calculate the amplitude for two mesons to
go into four mesons, that is, diagrams with six external legs? If I get a cutoff dependent
answer, then I am up the creek, as there is no counterterm of the form Dϕ6 in (4) to soak
up the cutoff dependence.” Very astute of you, but this worry is covered by the following
power counting theorem.
Degree of divergence
Consider a diagram with BE external ϕ lines. First, a definition: A diagram is said to have
a superficial degree of divergence D if it diverges as D. (A logarithmic divergence log 
counts as D = 0.) The theorem says that D is given by
D = 4 −BE
(5)

III.3. Physical Perturbation Theory | 177
Figure III.3.3
I will give a proof later, but I will first illustrate what (5) means. For the inverse propagator,
which has BE = 2, we are told that D = 2. Indeed, we encountered a quadratic divergence.
For the meson-meson scattering amplitude, BE = 4, and so D = 0, and indeed, it is
logarithmically divergent.
According to the theorem, if you calculate a diagram with six external legs (what is
technically sometimes known as the six-point function), BE = 6 and D = −2. The theorem
says that your diagram is convergent or cutoff independent (i.e., the cutoff dependence
disappears as −2). You didn’t have to worry. You should draw a few diagrams to check
this point. Diagrams with more external legs are even more convergent.
The proof of the theorem follows from simple power counting. In addition to BE and
D, let us define BI as the number of internal lines, V as the number of vertices, and L
as the number of loops. (It is helpful to focus on a specific diagram such as the one in
figure III.3.3 with BE = 6, D = −2, BI = 5, V = 4, and L = 2.)
The number of loops is just the number of

[d4k/(2π)4] we have to do. Each internal
line carries with it a momentum to be integrated over, so we seem to have BI integrals to
do. But the actual number of integrals to be done is of course decreased by the momentum
conservation delta functions associated with the vertices, one to each vertex. There are thus
V delta functions, but one of them is associated with overall momentum conservation of
the entire diagram. Thus, the number of loops is
L = BI −(V −1)
(6)
[If you have trouble following this argument, you should work things out for the diagram
in figure III.3.3 for which this equation reads 2 = 5 −(4 −1).]
For each vertex there are four lines coming out (or going in, depending on how you look
at it). Each external line comes out of (or goes into) one vertex. Each internal line connects
two vertices. Thus,
4V = BE + 2BI
(7)
(For figure III.3.3 this reads 4 . 4 = 6 + 2 . 5.)

178 | III. Renormalization and Gauge Invariance
Finally, for each loop there is a

d4k while for each internal line there is a
i/(k2 −m2 + iε), bringing the powers of momentum down by 2. Hence,
D = 4L −2BI
(8)
(For figure III.3.3 this reads −2 = 4 . 2 −2 . 5.)
Putting (6), (7), and (8) together, we obtain the theorem (5).2 As you can plainly see, this
formalizes the power counting we have been doing all along.
Degree of divergence with fermions
To test if you understood the reasoning leading to (5), consider the Yukawa theory we met
in (II.5.19). (We suppress the counterterms for typographical clarity.)
L = ¯ψ(iγ μ∂μ −mP)ψ + 1
2[(∂ϕ)2 −μ2
Pϕ2] −λPϕ4 + fPϕ ¯ψψ
(9)
Now we have to count FI and FE, the number of internal and external fermion lines,
respectively, and keep track of Vf and Vλ, the number of vertices with the coupling f and
λ, respectively. We have five equations altogether. For instance, (7) splits into two equations
because we now have to count fermion lines as well as boson lines. For example, we now
have
Vf + 4Vλ = BE + 2BI
(10)
We (that is, you) finally obtain
D = 4 −BE −3
2FE
(11)
So the divergent amplitudes, that is, those classes of diagrams with D ≥0, have (BE, FE) =
(0, 2), (2, 0), (1, 2), and (4, 0). We see that these correspond to precisely the six terms in
the Lagrangian (9), and thus we need six counterterms.
Note that this counting of superficial powers of divergence shows that all terms with
mass dimension ≤4 are generated. For example, suppose that in writing down the La-
grangian (9) we forgot to include the λPϕ4 term. The theory would demand that we include
this term: We have to introduce it as a counterterm [the term with (BE, FE) = (4, 0) in the
list above].
A common feature of (5) and (11) is that they both depend only on the number of external
lines and not on the number of vertices V . Thus, for a given number of external lines, no
matter to what order of perturbation theory we go, the superficial degree of divergence
remains the same. Further thought reveals that we are merely formalizing the dimension-
counting argument of the preceding chapter. [Recall that the mass dimension of a Bose
field [ϕ] is 1 and of a Fermi field [ψ] is 3
2. Hence the coefficients 1 and 3
2 in (11).]
2 The superficial degree of divergence measures the divergence of the Feynman diagram as all internal
momenta are scaled uniformly by k →ak with a tending to infinity. In a more rigorous treatment we have to
worry about the momenta in some subdiagram (a piece of the full diagram) going to infinity with other momenta
held fixed.

III.3. Physical Perturbation Theory | 179
Our discussion hardly amounts to a rigorous proof that theories such as the Yukawa
theory are renormalizable. If you demand rigor, you should consult the many field theory
tomes on renormalization theory, and I do mean tomes, in which such arcane topics as
overlapping divergences and Zimmerman’s forest formula are discussed in exhaustive and
exhausting detail.
Nonrenormalizable field theories
It is instructive to see how nonrenormalizable theories reveal their unpleasant personali-
ties when viewed in the context of this discussion. Consider the Fermi theory of the weak
interaction written in a simplified form:
L = ¯ψ(iγ μ∂μ −mP)ψ + G( ¯ψψ)2.
The analogs of (6), (7), and (8) now read L = FI −(V −1), 4V = FE + 2FI , and D =
4L −FI. Solving for the superficial degree of divergence in terms of the external number
of fermion lines, we find
D = 4 −3
2FE + 2V
(12)
Compared to the corresponding equations for renormalizable theories (5) and (11), D
now depends on V . Thus if we calculate fermion-fermion scattering (FE = 4), for example,
the divergence gets worse and worse as we go to higher and higher order in the perturbation
series. This confirms the discussion of the previous chapter. But the really bad news is
that for any FE, we would start running into divergent diagrams when V gets sufficiently
large, so we would have to include an unending stream of counterterms ( ¯ψψ)3, ( ¯ψψ)4,
( ¯ψψ)5, . . . , each with an arbitrary coupling constant to be determined by an experimental
measurement. The theory is severely limited in predictive power.
At one time nonrenormalizable theories were considered hopeless, but they are accepted
in the modern view based on the effective field theory approach, which I will discuss in
chapter VIII.3.
Dependence on dimension
The superficial degree of divergence clearly depends on the dimension d of spacetime since
each loop is associated with

ddk. For example, consider the Fermi interaction G( ¯ψψ)2 in
(1 + 1)-dimensional spacetime. Of the three equations that went into (12) one is changed
to D = 2L −FI , giving
D = 2 −1
2FE
(13)
the analog of (12) for 2-dimensional spacetime. In contrast to (12), V no longer enters, and
the only superficial diagrams have FE = 2 and 4, which we can cancel by the appropriate

180 | III. Renormalization and Gauge Invariance
counterterms. The Fermi interaction is renormalizable in (1 + 1)-dimensional spacetime.
I will come back to it in chapter VII.4.
The Weisskopf phenomenon
I conclude by pointing out that the mass correction to a Bose field and to a Fermi field
diverge differently. Since this phenomenon was first discovered by Weisskopf, I refer to
it as the Weisskopf phenomenon. To see this go back to (11) and observe that BE and FE
contribute differently to the superficial degree of divergence D. For BE = 2, FE = 0, we
have D = 2, and thus the mass correction to a Bose field diverges quadratically, as we have
already seen explicitly [the quantity a in (3)]. But for FE = 2, BE = 0, we have D = 1 and
it looks like the fermion mass is linearly divergent. Actually, in 4-dimensional field theory
we cannot possibly get a linear dependence on the cutoff. To see this, it is easiest to look at,
as an example, the Feynman integral you wrote down for exercise II.5.1, for the diagram
in figure II.5.1:
(if )2i2

d4k
(2π)4
1
k2 −μ2
̸p+ ̸ k + m
(p + k)2 −m2 ≡A(p2) ̸p + B(p2)
(14)
where I define the two unknown functions A(p2) and B(p2) for convenience. (For the
purpose of this discussion it doesn’t matter whether we are doing bare or physical pertur-
bation theory. If the latter, then I have suppressed the subscript P for the sake of notational
clarity.)
Look at the integrand for large k. You see that the integral goes as
  d4k(̸ k/k4) and
looks linearly divergent, but by reflection symmetry k →−k the integral to leading order
vanishes. The integral in (14) is merely logarithmically divergent. The superficial degree
of divergence D often gives an exaggerated estimate of how bad the divergence can be
(hence the adjective “superficial”). In fact, staring at (14) we can prove more, for instance,
that B(p2) must be proportional to m. As an exercise you can show, using the Feynman
rules given in chapter II.5, that the same conclusion holds in quantum electrodynamics.
For a boson, quantum fluctuations give δμ ∝2/μ, while for a fermion such as the
electron, quantum correction to its mass δm ∝m log(/m) is much more benign. It is
interesting to note that in the early twentieth century physicists thought of the electron
as a ball of charge of radius a. The electrostatic energy of such a ball, of the order e2/a,
was identified as the electron mass. Interpreting 1/a as , we could say that in classical
physics the electron mass is proportional to  and diverges linearly. Thus, one way of
stating the Weisskopf phenomenon is that “bosons behave worse than a classical charge,
but fermions behave better.”
As Weisskopf explained in 1939, the difference in the degree of the divergence can be
understood heuristically in terms of quantum statistics. The “bad” behavior of bosons has
to do with their gregariousness. A fermion would push away the virtual fermions fluctuat-
ing in the vacuum, thus creating a cavity in the vacuum charge distribution surrounding

III.3. Physical Perturbation Theory | 181
it. Hence its self-energy is less singular than would be the case were quantum statistics
not taken into account. A boson does the opposite.
The “bad” behavior of bosons will come back to haunt us later.
Power of ℏcounts the number of loops
This is a convenient place to make a useful observation, though unrelated to divergences
and cut-off dependence. Suppose we restore Planck’s unit of action ℏ. In the path integral,
the integrand becomes eiS/ℏ(recall chapter I.2) so that effectively L →L/ℏ. Consider
L = −1
2ϕ(∂2 + m2)ϕ −λ
4!ϕ4, just to be definite. The coupling λ →λ/ℏ, so that each vertex
is now associated with a factor of 1/ℏ. Recall that the propagator is essentially the inverse
of the operator (∂2 + m2), and so in momentum space 1/(k2 −m2) →ℏ/(k2 −m2). Thus
the powers of ℏare given by the number of internal lines minus the number of vertices
P = BI −V = L −1, where we used (6). You can check that this holds in general and not
just for ϕ4 theory.
This observation shows that organizing Feynman diagrams by the number of loops
amounts to an expansion in Planck’s constant (sometimes called a semi-classical expan-
sion), with the tree diagrams providing the leading term. We will come across this again
in chapter IV.3.
Exercises
III.3.1
Show that in (1 + 1)-dimensional spacetime the Dirac field ψ has mass dimension
1
2, and hence the
Fermi coupling is dimensionless.
III.3.2
Derive (11) and (13).
III.3.3
Show that B(p2) in (14) vanishes when we set m = 0. Show that the same behavior holds in quantum
electrodynamics.
III.3.4
We showed that the specific contribution (14) to δm is logarithmically divergent. Convince yourself that
this is actually true to any finite order in perturbation theory.
III.3.5
Show that the result P = L −1 holds for all the theories we have studied.

III.4
Gauge Invariance: A Photon Can Find No Rest
When the central identity blows up
I explained in chapter I.7 that the path integral for a generic field theory can be formally
evaluated in what deserves to be called the Central Identity of Quantum Field Theory:

Dϕe−1
2 ϕ.K.ϕ−V (ϕ)+J.ϕ = e−V (δ/δJ)e
1
2 J.K−1.J
(1)
For any field theory we can always gather up all the fields, put them into one giant column
vector, and call the vector ϕ. We then single out the term quadratic in ϕ write it as 1
2ϕ . K . ϕ,
and call the rest V (ϕ). I am using a compact notation in which spacetime coordinates and
any indices on the field, including Lorentz indices, are included in the indices of the formal
matrix K. We will often use (1) with V = 0 :

Dϕe−1
2 ϕ.K.ϕ+J.ϕ = e
1
2 J.K−1.J
(2)
But what if K does not have an inverse?
This is not an esoteric phenomenon that occurs in some pathological field theory, but
in one of the most basic actions of physics, the Maxwell action
S(A) =

d4xL =

d4x

1
2Aμ(∂2gμν −∂μ∂ν)Aν + AμJ μ
.
(3)
The formal matrix K in (2) is proportional to the differential operator (∂2gμν −∂μ∂ν) ≡
Qμν. A matrix does not have an inverse if some of its eigenvalues are zero, that is, if when
acting on some vector, the matrix annihilates that vector. Well, observe that Qμν annihilates
vectors of the form ∂ν(x) : Qμν∂ν(x) = 0. Thus Qμν has no inverse.
There is absolutely nothing mysterious about this phenomenon; we have already en-
countered it in classical physics. Indeed, when we first learned the concepts of electricity,
we were told that only the “voltage drop” between two points has physical meaning. At
a more sophisticated level, we learned that we can always add any constant (or indeed
any function of time) to the electrostatic potential (which is of course just “voltage”) since

III.4. Gauge Invariance | 183
by definition its gradient is the electric field. At an even more sophisticated level, we see
that solving Maxwell’s equation (which of course comes from just extremizing the action)
amounts to finding the inverse Q−1. [In the notation I am using here Maxwell’s equation
∂μF μν = J ν is written as QμνAν = Jμ, and the solution is Aν = (Q−1)νμJμ.]
Well, Q−1 does not exist! What do we do? We learned that we must impose an additional
constraint on the gauge potential Aμ, known as “fixing a gauge.”
A mundane nonmystery
To emphasize the rather mundane nature of this gauge fixing problem (which some
older texts tend to make into something rather mysterious and almost hopelessly dif-
ficult to understand), consider just an ordinary integral
 +∞
−∞dAe−A.K.A, with A =
(a, b) a 2-component vector and K =
 1
0
0
0

, a matrix without an inverse. Of course
you realize what the problem is: We have
 +∞
−∞
 +∞
−∞da db e−a2 and the integral over
b does not exist. To define the integral we insert into it a delta function δ(b −ξ).
The integral becomes defined and actually does not depend on the arbitrary num-
ber ξ. More generally, we can insert δ[f (b)] with f some function of our choice. In
the context of an ordinary integral, this procedure is of course ludicrous overkill, but
we will use the analog of this procedure in what follows. In this baby problem, we
could regard the variable b, and thus the integral over it, as “redundant.” As we will
see, gauge invariance is also a redundancy in our description of massless spin 1 parti-
cles.
A massless spin 1 field is intrinsically different from a massive spin 1 field—that’s the
crux of the problem. The photon has only two polarization degrees of freedom. (You already
learned in classical electrodynamics that an electromagnetic wave has two transverse
degrees of freedom.) This is the true physical origin of gauge invariance.
In this sense, gauge invariance is, strictly speaking, not a “real” symmetry but merely a
reflection of the fact that we used a redundant description: a Lorentz vector field to describe
two physical degrees of freedom.
Restricting the functional integral
I will now discuss the method for dealing with this redundancy invented by Faddeev and
Popov. As you will see presently, it is the analog of the method we used in our baby problem
above. Even in the context of electromagnetism this method is a bit of overkill, but it will
prove to be essential for nonabelian gauge theories (as we will see in chapter VII.1) and
for gravity. I will describe the method using a completely general and somewhat abstract
language. In the next section, I will then apply the discussion here to a specific example.
If you have some trouble with this section, you might find it helpful to go back and forth
between the two sections.

184 | III. Renormalization and Gauge Invariance
Suppose we have to do the integral I ≡

DAeiS(A); this can be an ordinary integral
or a path integral. Suppose that under the transformation A →Ag the integrand and
the measure do not change, that is, S(A) = S(Ag) and DA = DAg. The transformations
obviously form a group, since if we transform again with g′, the integrand and the measure
do not change under the combined effect of g and g′ and Ag →(Ag)g′ = Agg′. We would
like to write the integral I in the form I = (

Dg)J, with J independent of g. In other
words, we want to factor out the redundant integration over g. Note that Dg is the invariant
measure over the group of transformations and

Dg is the volume of the group. Be aware
of the compactness of the notation in the case of a path integral: A and g are both functions
of the spacetime coordinates x.
I want to emphasize that this hardly represents anything profound or mysterious. If
you have to do the integral I =

dx dy eiS(x,y) with S(x, y) some function of x2 + y2, you
know perfectly well to go to polar coordinates I = (

dθ)J = (2π)J, where J =

dr reiS(r)
is an integral over the radial coordinate r only. The factor 2π is precisely the volume of the
group of rotations in 2 dimensions.
Faddeev and Popov showed how to do this “going over to polar coordinates” in a
unified and elegant way. Following them, we first write the numeral “one” as
1 = (A)

Dgδ[f (Ag)], an equality that merely defines (A). Here f is some function
of our choice and (A), known as the Faddeev-Popov determinant, of course depends on
f . Next, note that [(Ag′)]−1 =

Dgδ[f (Ag′g)] =

Dg′′δ[f (Ag′′)] = [(A)]−1, where the
second equality follows upon defining g′′ = g′g and noting that Dg′′ = Dg. In other words,
we showed that (A) = (Ag) : the Faddeev-Popov determinant is gauge invariant. We
now insert 1 into the integral I we have to do:
I =

DAeiS(A)
=

DAeiS(A)(A)

Dgδ[f (Ag)]
=

Dg

DAeiS(A)(A)δ[f (Ag)]
(4)
As physicists and not mathematicians, we have merrily interchanged the order of
integration.
At the physicist’s level of rigor, we are always allowed to change integration variables
until proven guilty. So let us change A to Ag−1; then
I =


Dg
 
DAeiS(A)(A)δ[f (A)]
(5)
where we have used the fact that DA, S(A), and (A) are all invariant under A →Ag−1.
That’s it. We’ve done it. The group integration (

Dg) has been factored out.
The volume of a compact group is finite, but in gauge theories there is a separate group
at every point in spacetime, and hence (

Dg) is an infinite factor. (This also explains
why there is no gauge fixing problem in theories with global symmetries introduced in

III.4. Gauge Invariance | 185
chapter I.10.) Fortunately, in the path integral Z for field theory we do not care about
overall factors in Z, as was explained in chapter I.3, and thus the factor (

Dg) can simply
be thrown away.
Fixing the electromagnetic gauge
Let us now apply the Faddeev-Popov method to electromagnetism. The transformation
leaving the action invariant is of course Aμ →Aμ −∂μ, so g in the present context is
denoted by  and Ag ≡Aμ −∂μ. Note also that since the integral I we started with is
independent of f it is still independent of f in spite of its appearance in (5). Choose
f (A) = ∂A −σ, where σ is a function of x. In particular, I is independent of σ and
so we can integrate I with an arbitrary functional of σ , in particular, the functional
e−(i/2ξ) 
d4xσ(x)2.
We now turn the crank. First, we calculate
[(A)]−1 ≡

Dgδ[f (Ag)] =

Dδ(∂A −∂2 −σ)
(6)
Next we note that in (5) (A) appears multiplied by δ[f (A)] and so in evaluating [(A)]−1
in (6) we can effectively set f (A) = ∂A −σ to zero. Thus from (6) we have (A) “=”
[

Dδ(∂2)]−1. But this object does not even depend on A, so we can throw it away. Thus,
up to irrelevant overall factors that could be thrown away I is just

DAeiS(A)δ(∂A −σ).
Integrating over σ(x) as we said we were going to do, we finally obtain
Z =

Dσe−(i/2ξ) 
d4xσ(x)2 
DAeiS(A)δ(∂A −σ)
=

DAeiS(A)−(i/2ξ) 
d4x(∂A)2
(7)
Nifty trick by Faddeev and Popov, eh?
Thus, S(A) in (3) is effectively replaced by
Seff(A) = S(A) −1
2ξ

d4x(∂A)2
=

d4x
1
2Aμ

∂2gμν −

1 −1
ξ

∂μ∂ν

Aν + AμJ μ

(8)
and Qμν by Qμν
eff = ∂2gμν −(1 −1/ξ)∂μ∂ν or in momentum space Qμν
eff = −k2gμν + (1 −
1/ξ)kμkν, which does have an inverse. Indeed, you can check that
Qμν
eff

−gνλ + (1 −ξ)kνkλ
k2
 1
k2 = δμ
λ
Thus, the photon propagator can be chosen to be
(−i)
k2

gνλ −(1 −ξ)kνkλ
k2

(9)
in agreement with the conclusion in chapter II.7.

186 | III. Renormalization and Gauge Invariance
While the Faddeev-Popov argument is a lot slicker, many physicists still prefer the explicit
Feynman argument given in chapter II.7. I do. When we deal with the Yang-Mills theory
and the Einstein theory, however, the Faddeev-Popov method is indispensable, as I have
already noted.
A photon can find no rest
Let us understand the physics behind the necessity for imposing by hand a (gauge fixing)
constraint in gauge theories. In chapter I.5 we sidestepped this whole issue of fixing the
gauge by treating the massive vector meson instead of the photon. In effect, we changed
Qμν to (∂2 + m2)gμν −∂μ∂ν, which does have an inverse (in fact we even found the inverse
explicitly). We then showed that we could set the mass m to 0 in physical calculations.
There is, however, a huge and intrinsic difference between massive and massless
particles. Consider a massive particle moving along. We can always boost it to its rest
frame, or in more mathematical terms, we can always Lorentz transform the momentum
of a massive particle to the reference momentum qμ = m(1, 0, 0, 0). (As is the case
elsewhere in this book, if there is no risk of confusion, we write column vectors as row
vectors for typographical convenience.) To study the spin degrees of freedom, we should
evidently sit in the rest frame of the particle and study how its states respond to rotation.
The fancy pants way of saying this is we should study how the states of the particle
transform under that particular subgroup of the Lorentz group (known as the little group)
consisting of those Lorentz transformations  that leave qμ invariant, namely μ
ν qν = qμ.
For qμ = m(1, 0, 0, 0), the little group is obviously the rotation group SO(3). We then apply
what we learned in nonrelativistic quantum mechanics and conclude that a spin j particle
has (2j + 1) spin states (or polarizations in classical physics), as already noted back in
chapter I.5.
But if the particle is massless, we can no longer find a Lorentz boost that would bring
us to its rest frame. A photon can find no rest!
For a massless particle, the best we can do is to transform the particle’s momentum to the
reference momentum qμ = ω(1, 0, 0, 1) for some arbitrarily chosen ω. Again, this is just
a fancy way of saying that we can always call the direction of motion the third axis. What is
the little group that leaves qμ invariant? Obviously, rotations around the third axis, forming
the group O(2), leave qμ invariant. The spin states of a massless particle of any spin around
its direction of motion are known as helicity states, as was already mentioned in chapter
II.1. For a particle of spin j, the helicities ±j are transformed into each other by parity
and time reversal, and thus both helicities must be present if the interactions the particle
participates in respect these discrete symmetries, as is the case with the photon and the
graviton.1 In particular, the photon, as we have seen repeatedly, has only two polarization
degrees of freedom, instead of three, since we no longer have the full rotation group SO(3).
1 But not with the neutrino.

III.4. Gauge Invariance | 187
(You already learned in classical electrodynamics that an electromagnetic wave has two
transverse degrees of freedom.) For more on this, see appendix B.
In this sense, gauge invariance is strictly speaking not a “real” symmetry but merely a
reflection of the fact that we used a redundant description: we used a vector field Aμ with
its four degrees of freedom to describe two physical degrees of freedom. This is the true
physical origin of gauge invariance.
The condition μ
ν qν = qμ should leave us with a 3-parameter subgroup. To find the other
transformations, it suffices to look in the neighborhood of the identity, that is, at Lorentz
transformations of the form (α, β) = I + αA + βB + . . . . By inspection, we see that
A =
⎛
⎜⎜⎜⎜⎜⎝
0
1
0
0
1
0
0
−1
0
0
0
0
0
1
0
0
⎞
⎟⎟⎟⎟⎟⎠
= i(K1 + J2),
B =
⎛
⎜⎜⎜⎜⎜⎝
0
0
1
0
0
0
0
0
1
0
0
−1
0
0
1
0
⎞
⎟⎟⎟⎟⎟⎠
= i(K2 −J1)
(10)
where we used the notation for the generators of the Lorentz group from chapter II.3. Note
that A and B are to a large extent determined by the fact that J and K are symmetric and
antisymmetric, respectively.
By direct computation or by invoking the celebrated minus sign in (II.3.9), we find
that [A, B] = 0. Also, [J3, A] = B and [J3, B] = −A so that, as expected, (A, B) form a
2-component vector under O(2) rotations around the third axis. (For those who must
know, the generators A, B, and J3 generate the group ISO(2), the invariance group of
the Euclidean 2-plane, consisting of two translations and one rotation.)
The preceding paragraph establishing the little group for massless particles applies
for any spin, including zero. Now specialize to a spin 1 massless particle with the two
polarization vectors ϵ±(q) = (1/
√
2)(0, 1, ±i, 0). The polarization vectors are defined by
how they transform under rotation eiφJ3. So it is natural to ask how ϵ±(q) transform under
(α, β). Inspecting (10), we see that
ϵ±(q) →ϵ±(q) + 1
√
2
(α ± iβ)q
(11)
We recognize (11) as a gauge transformation (as was explained in chapter II.7). For a mass-
less spin 1 particle, the gauge transformation is contained in the Lorentz transformations!
Suppose we construct the corresponding spin 1 field as in chapter II.5 [and in analogy
to (I.8.11) and (II.2.10)]:
Aμ(x) =

d3k

(2π)32ωk

α=1,2
[a(α)(⃗k)ε(α)
μ (k)e−i(ωkt−⃗k.⃗x) + a†(α)(⃗k)ε∗(α)
μ
(k)ei(ωkt−⃗k.⃗x))]
(12)
with ωk = |⃗k|. The polarization vectors ε(α)
μ (k) are of coursed determined by the condition
kμε(α)
μ (k) = 0, which we could easily satisfy by defining ε(α)(k) = (q →k)ε(α)(q), where
(q →k) denotes a Lorentz transformation that brings the reference momentum q to k.
Note that the ε(α)(k) thus constructed has a vanishing time component. (To see this,
first boost ε(α)
μ (q) along the third axis and then rotate, for example.) Hence, kμε(α)
μ (k) =
−⃗k . ⃗ε(α)(k) = 0. These properties of ε(α)
μ (k) translate into A0(x) = 0 and
−→∇. ⃗A(x) = 0.

188 | III. Renormalization and Gauge Invariance
These two constraints cut the four degrees of freedom contained in Aμ(x) down to two
and fix what is known as the Coulomb or radiation gauge.2
Given the enormous importance of gauge invariance, it might be instructive to review
the logic underlying the “poor man’s approach” to gauge invariance (which, as I mentioned
in chapter I.5, I learned from Coleman) adopted in this book for pedagogical reasons. You
could have fun faking Feynman’s mannerism and accent, saying, “Aw shucks, all that fancy
talk about little groups! Who needs it? Those experimentalists won’t ever be able to prove
that the photon mass is mathematically zero anyway.”
So start, as in chapter I.5, with the two equations needed for describing a spin 1 massive
particle:
(∂2 + m2)Aμ = 0
(13)
and
∂μAμ = 0
(14)
Equation (14) is needed to cut the number of degrees of freedom contained in Aμ down
from four to three.
Lo and behold, (13) and (14) are equivalent to the single equation
∂μ(∂μAν −∂νAμ) + m2Aν = 0
(15)
Obviously, (13) and (14) together imply (15). To verify that (15) implies (13) and (14), we
act with ∂ν on (15) and obtain
m2∂A = 0
(16)
which for m ̸= 0 requires ∂A = 0, namely (14). Plugging this into (15) we obtain (13).
Having packaged two equations into one, we note that we can derive this single equation
(15) by varying the Lagrangian
L = −1
4FμνF μν + 1
2m2A2
(17)
with Fμν ≡∂μAν −∂νAμ.
Next, suppose we include a source Jμ for this particle by changing the Lagrangian to
L = −1
4FμνF μν + 1
2m2A2 + AμJ μ
(18)
with the resulting equation of motion
∂μ(∂μAν −∂νAμ) + m2Aν = −Jν
(19)
But now observe that when we act with ∂ν on (19) we obtain
m2∂A = −∂J
(20)
2 For a much more detailed and leisurely discussion, see S. Weinberg, Quantum Theory of Fields, pp. 69–74
and 246–255.

III.4. Gauge Invariance | 189
We recover (14) only if ∂μJ μ = 0, that is, if the source producing the particle, commonly
know as the current, is conserved.
Put more vividly, suppose the experimentalists who constructed the accelerator (or
whatever) to produce the spin 1 particle messed up and failed to insure that ∂μJ μ = 0;
then ∂A ̸= 0 and a spin 0 excitation would also be produced. To make sure that the beam
of spin 1 particles is not contaminated with spin 0 particles, the accelerator builders must
assure us that the source Jμ in the Lagrangian (18) is indeed conserved.
Now, if we want to study massless spin 1 particles, we simply set m = 0 in (18). The
“poor man” ends up (just like the “rich man”) using the Lagrangian
L = −1
4FμνF μν + AμJ μ
(21)
to describe the photon. Lo and behold (as we exclaimed in chapter II.7), L is left invariant
by the gauge transformation Aμ →Aμ −∂μ for any (x). (As was also explained in that
chapter, the third polarization decouples in the limit m →0.) The “poor man” has thus
discovered gauge invariance!
However, as I warned in chapter I.5, depending on his or her personality, the poor man
could also wake up in the middle of the night worrying that physics might be discontinuous
in the limit m →0. Thus the little group discussion is needed to remove that nightmare.
But then a “real” physicist in the Feynman mode could always counter that for any physical
measurement everything must be okay as long as the duration of the experiment is short
compared to the characteristic time 1/m. More on this issue in chapter VIII.1.
A reflection on gauge symmetry
As we will see later and as you might have heard, much of the world beyond electro-
magnetism is also described by gauge theories. But as we saw here, gauge theories are
also deeply disturbing and unsatisfying in some sense: They are built on a redundancy
of description. The electromagnetic gauge transformation Aμ →Aμ −∂μ is not truly a
symmetry stating that two physical states have the same properties. Rather, it tells us that
the two gauge potentials Aμ and Aμ −∂μ describe the same physical state. In your or-
derly study of physics, the first place where Aμ becomes indispensable is the Schr¨odinger
equation, as I will explain in chapter IV.4. Within classical physics, you got along perfectly
well with just ⃗E and ⃗B. Some physicists are looking for a formulation of quantum elec-
trodynamics without using Aμ, but so far have failed to turn up an attractive alternative
to what we have. It is conceivable that a truly deep advance in theoretical physics would
involve writing down quantum electrodynamics without writing Aμ.

III.5
Field Theory without Relativity
Slower in its maturity
Quantum field theory at its birth was relativistic. Later in its maturity, it found applications
in condensed matter physics. We will have a lot more to say about the role of quantum field
theory in condensed matter, but for now, we have the more modest goal of learning how
to take the nonrelativistic limit of a quantum field theory.
The Lorentz invariant scalar field theory
L =(∂†)(∂) −m2† −λ(†)2
(1)
(with λ > 0 as always) describes a bunch of interacting bosons. It should certainly contain
the physics of slowly moving bosons. For clarity consider first the relativistic Klein-Gordon
equation
(∂2 + m2) = 0
(2)
for a free scalar field. A mode with energy E = m + ε would oscillate in time as  ∝e−iEt.
In the nonrelativistic limit, the kinetic energy ε is much smaller than the rest mass
m. It makes sense to write (⃗x, t) = e−imtϕ(⃗x, t), with the field ϕ oscillating in time
much more slowly than e−imt. Plugging into (2) and using the identity (∂/∂t)e−imt(. . .) =
e−imt(−im + ∂/∂t)(. . .) twice, we obtain (−im + ∂/∂t)2ϕ −⃗∇2ϕ + m2ϕ = 0. Dropping the
term (∂2/∂t2)ϕ as small compared to −2im(∂/∂t)ϕ, we find Schr¨odinger’s equation, as we
had better:
i ∂
∂t ϕ = −
⃗∇2
2mϕ
(3)
By the way, the Klein-Gordon equation was actually discovered before Schr¨odinger’s
equation.

III.5. Nonrelativistic Field Theory | 191
Having absorbed this, you can now easily take the nonrelativistic limit of a quantum
field theory. Simply plug
(⃗x, t) =
1
√
2m
e−imtϕ(⃗x, t)
(4)
into (1) . (The factor 1/
√
2m is for later convenience.) For example,
∂†
∂t
∂
∂t −m2† →1
2m

im + ∂
∂t

ϕ
† 
−im + ∂
∂t

ϕ

−m2ϕ
†ϕ

≃1
2i

ϕ
† ∂ϕ
∂t −∂ϕ
†
∂t ϕ

(5)
After an integration by parts we arrive at
L = iϕ†∂0ϕ −1
2m∂iϕ†∂iϕ −g2(ϕ†ϕ)2
(6)
where g2 = λ/4m2.
As we saw in chapter I.10 the theory (1) enjoys a conserved Noether current Jμ =
i(†∂μ −∂μ†). The density J0 reduces to ϕ†ϕ, precisely as you would expect, while
Ji reduces to (i/2m)(ϕ†∂iϕ −∂iϕ†ϕ). When you first took a course in quantum mechanics,
didn’t you wonder why the density ρ ≡ϕ†ϕ and the current Ji = (i/2m)(ϕ†∂iϕ −∂iϕ†ϕ)
look so different? As to be expected, various expressions inevitably become uglier when
reduced from a more symmetric to a less symmetric theory.
Number is conjugate to phase angle
Let me point out some differences between the relativistic and nonrelativistic case.
The most striking is that the relativistic theory is quadratic in time derivative, while
the nonrelativistic theory is linear in time derivative. Thus, in the nonrelativistic theory
the momentum density conjugate to the field ϕ, namely δL/δ∂0ϕ, is just iϕ†, so that
[ϕ†(⃗x, t), ϕ(⃗x′, t)] = −δ(D)(⃗x −⃗x′). In condensed matter physics it is often illuminating to
write ϕ = √ρeiθ so that
L = i
2∂0ρ −ρ∂0θ −1
2m

ρ(∂iθ)2 + 1
4ρ (∂iρ)2

−g2ρ2
(7)
The first term is a total divergence. The second term tells us something of great impor-
tance1 in condensed matter physics: in the canonical formalism (chapter I.8), the momen-
tum density conjugate to the phase field θ(x) is δL/δ∂0θ = −ρ and thus Heisenberg tells
us that
[ρ(⃗x, t), θ(⃗x′, t)] = iδ(D)(⃗x −⃗x′)
(8)
1 See P. Anderson, Basic Notions of Condensed Matter Physics, p. 235.

192 | III. Renormalization and Gauge Invariance
Integrating and defining N ≡

dDxρ(⃗x, t) = the total number of bosons, we find one of
the most important relations in condensed matter physics
[N, θ] = i
(9)
Number is conjugate to phase angle, just as momentum is conjugate to position. Marvel
at the elegance of this! You would learn in a condensed matter course that this fundamental
relation underlies the physics of the Josephson junction.
You may know that a system of bosons with a “hard core” repulsion between them is a
superfluid at zero temperature. In particular, Bogoliubov showed that the system contains
an elementary excitation obeying a linear dispersion relation.2 I will discuss superfluidity
in chapter V.1.
In the path integral formalism, going from the complex field ϕ = ϕ1 + iϕ2 to ρ and
θ amounts to a change of integration variables, as I remarked back in chapter I.8. In the
canonical formalism, since one deals with operators, one has to tread with somewhat more
finesse.
The sign of repulsion
In the nonrelativistic theory (7) it is clear that the bosons repel each other: Piling particles
into a high density region would cost you an energy density g2ρ2. But it is less clear in
the relativistic theory that λ(†)2 with λ positive corresponds to repulsion. I outline one
method in exercise III.5.3, but here let’s just take a flying heuristic guess. The Hamiltonian
(density) involves the negative of the Lagrangian and hence goes as λ(†)2 for large 
and would thus be unbounded below for λ < 0. We know physically that a free Bose gas
tends to condense and clump, and with an attractive interaction it surely might want to
collapse. We naturally guess that λ > 0 corresponds to repulsion.
I next give you a more foolproof method. Using the central identity of quantum field
theory we can rewrite the path integral for the theory in (1) as
Z =

DDσei 
d4x[(∂†)(∂)−m2†+2σ†+(1/λ)σ 2]
(10)
Condensed matter physicists call the transformation from (1) to the Lagrangian L =
(∂†)(∂) −m2† + 2σ† + (1/λ)σ 2 the Hubbard-Stratonovich transformation. In
field theory, a field that does not have kinetic energy, such asσ , is known as an auxiliary field
and can be integrated out in the path integral. When we come to the superfield formalism
in chapter VIII.4, auxiliary fields will play an important role.
Indeed, you might recall from chapter III.2 how a theory with an intermediate vector
boson could generate Fermi’s theory of the weak interaction. The same physics is involved
here: The theory (10) in which the  field is coupled to an “intermediate σ boson” can
generate the theory (1).
2 For example, L.D. Landau and E. M. Lifschitz, Statisical Physics, p. 238.

III.5. Nonrelativistic Field Theory | 193
If σ were a “normal scalar field” of the type we have studied, that is, if the terms quadratic
in σ in the Lagrangian had the form
1
2(∂σ)2 −1
2M2σ 2, then its propagator would be
i/(k2 −M2 + iε). The scattering amplitude between two  bosons would be proportional
to this propagator. We learned in chapter I.4 that the exchange of a scalar field leads to an
attractive force.
But σ is not a normal field as evidenced by the fact that the Lagrangian contains
only the quadratic term +(1/λ)σ 2. Thus its propagator is simply i/(1/λ) = iλ, which (for
λ > 0) has a sign opposite to the normal propagator evaluated at low-momentum transfer
i/(k2 −M2 + iε) ≃−i/M2. We conclude that σ exchange leads to a repulsive force.
Incidentally, this argument also shows that the repulsion is infinitely short ranged, like
a delta function interaction. Normally, as we learned in chapter I.4 the range is determined
by the interplay between the k2 and the M2 terms. Here the situation is as if the M2 term
is infinitely large. We can also argue that the interaction λ(†)2 involves creating two
bosons and then annihilating them both at the same spacetime point.
Finite density
One final point of physics that people trained as particle physicists do not always remem-
ber: Condensed matter physicists are not interested in empty space, but want to have a
finite density ¯ρ of bosons around. We learned in statistical mechanics to add a chemical
potential term μϕ†ϕ to the Lagrangian (6). Up to an irrelevant (in this context!) additive
constant, we can rewrite the resulting Lagrangian as
L = iϕ†∂0ϕ −1
2m∂iϕ†∂iϕ −g2(ϕ†ϕ −¯ρ)2
(11)
Amusingly, mass appears in different places in relativistic and nonrelativistic field
theories. To proceed further, I have to develop the concept of spontaneous symmetry
breaking. Thus, adios for now. We will come back to superfluidity in due time.
Exercises
III.5.1
Obtain the Klein-Gordon equation for a particle in an electrostatic potential (such as that of the nucleus)
by the gauge principle of replacing (∂/∂t) in (2) by ∂/∂t −ieA0. Show that in the nonrelativistic limit
this reduces to the Schr¨odinger’s equation for a particle in an external potential.
III.5.2
Take the nonrelativistic limit of the Dirac Lagrangian.
III.5.3
Given a field theory we can compute the scattering amplitude of two particles in the nonrelativistic limit.
We then postulate an interaction potential U(⃗x) between the two particles and use nonrelativistic quan-
tum mechanics to calculate the scattering amplitude, for example in Born approximation. Comparing
the two scattering amplitudes we can determine U(⃗x). Derive the Yukawa and the Coulomb potentials
this way. The application of this method to the λ(†)2 interaction is slightly problematic since the
delta function interaction is a bit singular, but it should be all right for determining whether the force is
repulsive or attractive.

III.6
The Magnetic Moment of the Electron
Dirac’s triumph
I said in the preface that the emphasis in this book is not on computation, but how can I
not tell you about the greatest triumph of quantum field theory?
After Dirac wrote down his equation, the next step was to study how the electron interacts
with the electromagnetic field. According to the gauge principle already used to write
the Schr¨odinger’s equation in an electromagnetic field, to obtain the Dirac equation for
an electron in an external electromagnetic field we merely have to replace the ordinary
derivative ∂μ by the covariant derivative Dμ = ∂μ −ieAμ :
(iγ μDμ −m)ψ = 0
(1)
Recall (II.1.27).
Acting on this equation with (iγ μDμ + m), we obtain −(γ μγ νDμDν + m2)ψ = 0. We
have γ μγ νDμDν = 1
2({γ μ, γ ν} + [γ μ, γ ν])DμDν = DμDμ −iσ μνDμDν and iσ μνDμDν =
(i/2)σ μν[Dμ, Dν] = (e/2)σ μνFμν. Thus

DμDμ −e
2σ μνFμν + m2

ψ = 0
(2)
Now consider a weak constant magnetic field pointing in the 3rd direction for definite-
ness, weak so that we can ignore the (Ai)2 term in (Di)2. By gauge invariance, we can
choose A0 = 0, A1 = −1
2Bx2, and A2 = 1
2Bx1 (so that F12 = ∂1A2 −∂2A1 = B). As we will
see, this is one calculation in which we really have to keep track of factors of 2. Then
(Di)2 = (∂i)2 −ie(∂iAi + Ai∂i) + O(A2
i )
= (∂i)2 −2ie
2 B(x1∂2 −x2∂1) + O(A2
i )
= ⃗∇2 −e ⃗B . ⃗x × ⃗p + O(A2
i )
(3)
Note that we used ∂iAi + Ai∂i = (∂iAi) + 2Ai∂i = 2Ai∂i, where in (∂iAi) the partial deriva-
tive acts only on Ai. You may have recognized ⃗L ≡⃗x × ⃗p as the orbital angular momentum

III.6. Magnetic Moment of Electron | 195
operator. Thus, the orbital angular momentum generates an orbital magnetic moment that
interacts with the magnetic field.
This calculation makes good physical sense. If we were studying the interaction of a
charged scalar field  with an external electromagnetic field we would start with
(DμDμ + m2) = 0
(4)
obtained by replacing the ordinary derivative in the Klein-Gordon equation by covariant
derivatives. We would then go through the same calculation as in (3). Comparing (4) with
(2) we see that the spin of the electron contributes the additional term (e/2)σ μνFμν.
As in chapter II.1 we write ψ =
 φ
χ

in the Dirac basis and focus on φ since in the
nonrelativistic limit it dominates χ. Recall that in that basis σ ij = εijk  σ k
0
0
σ k

. Thus
(e/2)σ μνFμν acting on φ is effectively equal to (e/2)σ 3(F12 −F21) = (e/2)2σ 3B = 2e ⃗B . ⃗S
since ⃗S = (⃗σ/2). Make sure you understand all the factors of 2! Meanwhile, according to
what I told you in chapter II.1, we should write φ = e−imt, where  oscillates much more
slowly than e−imt so that (∂2
0 + m2)e−imt ≃e−imt[−2im(∂/∂t)]. Putting it all together,
we have

−2im ∂
∂t −⃗∇2 −e ⃗B . (⃗L + 2⃗S)

 = 0
(5)
There you have it! As if by magic, Dirac’s equation tells us that a unit of spin angular
momentum interacts with a magnetic field twice as much as a unit of orbital angular
momentum, an observational fact that had puzzled physicists deeply at the time. The
calculation leading to (5) is justly celebrated as one of the greatest in the history of physics.
The story is that Dirac did not do this calculation until a day after he discovered his
equation, so sure was he that the equation had to be right. Another version is that he
dreaded the possibility that the magnetic moment would come out wrong and that Nature
would not take advantage of his beautiful equation.
Another way of seeing that the Dirac equation contains a magnetic moment is by the
Gordon decomposition, the proof of which is given in an exercise:
¯u(p′)γ μu(p) = ¯u(p′)
(p′ + p)μ
2m
+ iσ μν(p′ −p)ν
2m

u(p)
(6)
Looking at the interaction with an electromagnetic field ¯u(p′)γ μu(p)Aμ(p′ −p), we see
that the first term in (6) only depends on the momentum (p′ + p)μ and would have
been there even if we were treating the interaction of a charged scalar particle with the
electromagnetic field to first order. The second term involves spin and gives the mag-
netic moment. One way of saying this is that ¯u(p′)γ μu(p) contains a magnetic moment
component.

196 | III. Renormalization and Gauge Invariance
The anomalous magnetic moment
With improvements in experimental techniques, it became clear by the late 1940’s that the
magnetic moment of the electron was larger than the value calculated by Dirac by a factor
of 1.00118 ± 0.00003. The challenge to any theory of quantum electrodynamics was to
calculate this so-called anomalous magnetic moment. As you probably know, Schwinger’s
spectacular success in meeting this challenge established the correctness of relativistic
quantum field theory, at least in dealing with electromagnetic phenomena, beyond any
doubt.
Before we plunge into the calculation, note that Lorentz invariance and current conser-
vation tell us (see exercise III.6.3) that the matrix element of the electromagnetic current
must have the form (here |p, s⟩denotes a state with an electron of momentum p and
polarization s)
⟨p′, s′|J μ(0)|p, s⟩= ¯u(p′, s′)

γ μF1(q2) + iσ μνqν
2m
F2(q2)

u(p, s)
(7)
where q ≡(p′ −p). The functions F1(q2) and F2(q2), about which Lorentz invariance can
tell us nothing, are known as form factors. To leading order in momentum transfer q, (7)
becomes
¯u(p′, s′)
(p′ + p)μ
2m
F1(0) + iσ μνqν
2m
[F1(0) + F2(0)]

u(p, s)
by the Gordon decomposition. The coefficient of the first term is the electric charge
observed by experimentalists and is by definition equal to 1. (To see this, think of potential
scattering, for example. See chapter II.6.) Thus F1(0) = 1. The magnetic moment of the
electron is shifted from the Dirac value by a factor 1 + F2(0).
Schwinger’s triumph
Let us now calculate F2(0) to order α = e2/4π. First draw all the relevant Feynman dia-
grams to this order (fig. III.6.1). Except for figure 1b, all the Feynman diagrams are clearly
proportional to ¯u(p′, s′)γ μu(p, s) and thus contribute to F1(q2), which we don’t care about.
Happy are we! We only have to calculate one Feynman diagram.
p
q
p’
p
q
p’
p’ + k
p + k
k
(a)
(b)
(c)
(d)
(e)
Figure III.6.1

III.6. Magnetic Moment of Electron | 197
It is convenient to normalize the contribution of figure 1b by comparing it to the lowest
order contribution of figure 1a and write the sum of the two contributions as ¯u(γ μ + μ)u.
Applying the Feynman rules, we find
μ =

d4k
(2π)4
−i
k2

ieγ ν
i
̸p′+ ̸ k −mγ μ
i
̸p+ ̸ k −mieγν

(8)
I will now go through the calculation in some detail not only because it is important, but
also because we will be using a variety of neat tricks springing from the brilliant minds of
Schwinger and Feynman. You should verify all the steps of course.
Simplifying somewhat we obtain μ = −ie2 
[d4k/(2π)4](Nμ/D), where
Nμ = γ ν(̸p′+ ̸ k + m)γ μ(̸p+ ̸ k + m)γν
(9)
and
1
D =
1
(p′ + k)2 −m2
1
(p + k)2 −m2
1
k2 = 2

dα dβ 1
D .
(10)
We have used the identity (D.16). The integral is evaluated over the triangle in the (α-β)
plane bounded by α = 0, β = 0, and α + β = 1, and
D =[k2 + 2k(αp′ + βp)]3 = [l2 −(α + β)2m2]3 + O(q2)
(11)
where we completed a square by defining k = l −(αp′ + βp). The momentum integration
is now over d4l.
Our strategy is to massage Nμ into a form consisting of a linear combination of γ μ, pμ,
and p′μ. Invoking the Gordon decomposition (6) we can write (7) as
¯u

γ μ[F1(q2) + F2(q2)] −1
2m(p′ + p)μF2(q2)

u
Thus, to extract F2(0) we can throw away without ceremony any term proportional to γ μ
that we encounter while massaging Nμ. So, let’s proceed.
Eliminating k in favor of l in (9) we obtain
Nμ = γ ν[̸ l + ̸P ′ + m]γ μ[̸ l + ̸P + m]γν
(12)
where P ′μ ≡(1 −α)p′μ −βpμ and P μ ≡(1 −β)pμ −αp′μ. I will use the identities in
appendix D repeatedly, without alerting you every time I use one. It is convenient to
organize the terms in Nμ by powers of m. (Here I give up writing in complete grammatical
sentences.)
1. The m2 term: a γ μ term, throw away.
2. The m terms: organize by powers of l. The term linear in l integrates to 0 by symmetry.
Thus, we are left with the term independent of l:
m(γ ν ̸P ′γ μγν + γ νγ μ ̸P γν) = 4m[(1 −2α)p′μ + (1 −2β)pμ]
→4m(1 −α −β)(p′ + p)μ
(13)
In the last step I used a handy trick; since D is symmetric under α ←→β, we can sym-
metrize the terms we get in Nμ.

198 | III. Renormalization and Gauge Invariance
3. Finally, the most complicated m0 term. The term quadratic in l: note that we can effectively
replace lσlτ inside

d4l/(2π)4 by 1
4ηστl2 by Lorentz invariance (this step is possible because
we have shifted the integration variable so that D is a Lorentz invariant function of l2.) Thus,
the term quadratic in l gives rise to a γ μ term. Throw it away. Again we throw away the term
linear in l, leaving [use (D.6) here!]
γ ν ̸P ′γ μ ̸P γν = −2̸Pγ μ ̸P ′
→−2[(1 −β) ̸p −αm]γ μ[(1 −α) ̸p′ −βm]
(14)
where in the last step we remembered that μ is to be sandwiched between ¯u(p′) and u(p).
Again, it is convenient to organize the terms in (14) by powers of m. With the various tricks
we have already used, we find that the m2 term can be thrown away, the m term gives
2m(p′ + p)μ[α(1 −α) + β(1 −β)], and the m0 term gives 2m(p′ + p)μ[−2(1 −α)(1 −β)].
Putting it altogether, we find that Nμ →2m(p′ + p)μ(α + β)(1 −α −β)
We can now do the integral

[d4l/(2π)4](1/D) using (D.11). Finally, we obtain
μ = −2ie2

dα dβ( −i
32π2)
1
(α + β)2m2Nμ
= −e2
8π2
1
2m(p′ + p)μ
(15)
and thus, trumpets please:
F2(0) = e2
8π2 = α
2π
(16)
Schwinger’s announcement of this result in 1948 had an electrifying impact on the theo-
retical physics community.
I gave you in this chapter not one, but two, of the great triumphs of twentieth century
physics, although admittedly the first is not a result of field theory per se.
Exercises
III.6.1
Evaluate ¯u(p′)( ̸p′γ μ + γ μ ̸p)u(p) in two different ways and thus prove Gordon decomposition.
III.6.2
Check that (7) is consistent with current conservation. [Hint: By translation invariance (we suppress the
spin variable)
⟨p′|J μ(x)|p⟩= ⟨p′|J μ(0)|p⟩ei(p′−p)x
and hence
⟨p′|∂μJ μ(x)|p⟩= i(p′ −p)μ⟨p′|J μ(0)|p⟩ei(p′−p)x
Thus current conservation implies that qμ⟨p′|J μ(0)|p⟩= 0.]
III.6.3
By Lorentz invariance the right hand side of (7) has to be a vector. The only possibilities are ¯uγ μu,
(p + p′)μ ¯uu, and (p −p′)μ ¯uu. The last term is ruled out because it would not be consistent with current
conservation. Show that the form given in (7) is in fact the most general allowed.

III.6. Magnetic Moment of Electron | 199
III.6.4
In chapter II.6, when discussing electron-proton scattering, we ignored the strong interaction that the
proton participates in. Argue that the effects of the strong interaction could be included phenomenolog-
ically by replacing the vertex ¯u(P , S)γ μu(p, s) in (II.6.1) by
⟨P , S|J μ(0)|p, s⟩= ¯u(P , S)

γ μF1(q2) + iσ μνqν
2m
F2(q2)

u(p, s)
(17)
Careful measurements of electron-proton scattering, thus determining the two proton form factors
F1(q2) and F2(q2), earned R. Hofstadter the 1961 Nobel Prize. While we could account for the general
behavior of these two form factors, we are still unable to calculate them from first principles (in contrast
to the corresponding form factors for the electron.) See chapters IV.2 and VII.3.

III.7
Polarizing the Vacuum and
Renormalizing the Charge
A photon can fluctuate into an electron and a positron
One early triumph of quantum electrodynamics is the understanding of how quantum
fluctuations affect the way the photon propagates. A photon can always metamorphose into
an electron and a positron that, after a short time mandated by the uncertainty principle,
annihilate each other becoming a photon again. The process, which keeps on repeating
itself, is depicted in figure III.7.1.
Quantum fluctuations are not limited to what we just described. The electron and
positron can interact by exchanging a photon, which in turn can change into an electron
and a positron, and so on and so forth. The full process is shown in figure III.7.2, where the
shaded object, denoted by iμν(q) and known as the vacuum polarization tensor, is given
by an infinite number of Feynman diagrams, as shown in figure III.7.3. Figure III.7.1 is
obtained from figure III.7.2 by approximating iμν(q) by its lowest order diagram.
It is convenient to rewrite the Lagrangian L = ¯ψ[iγ μ(∂μ −ieAμ) −m]ψ −1
4FμνF μν by
letting A →(1/e)A, which we are always allowed to do, so that
L = ¯ψ[iγ μ(∂μ −iAμ) −m]ψ −
1
4e2FμνF μν
(1)
Note that the gauge transformation leaving L invariant is given by ψ →eiαψ and Aμ →
Aμ + ∂μα. The photon propagator (chapter III.4), obtained roughly speaking by inverting
(1/4e2)FμνF μν, is now proportional to e2 :
iDμν(q) = −ie2
q2

gμν −(1 −ξ)qμqν
q2

(2)
Every time a photon is exchanged, the amplitude gets a factor of e2. This is just a trivial
but convenient change and does not affect the physics in the slightest. For example, in the
Feynman diagram we calculated in chapter II.6 for electron-electron scattering, the factor
e2 can be thought of as being associated with the photon propagator rather than as coming
from the interaction vertices. In this interpretation e2 measures the ease with which the

III.7. Polarizing the Vacuum | 201
+
+
+
Figure III.7.1
+
+
+
Figure III.7.2
=
+
+
+
+
+
p
p + q
Figure III.7.3
photon propagates through spacetime. The smaller e2, the more action it takes to have
the photon propagate, and the harder for the photon to propagate, the weaker the effect of
electromagnetism.
The diagrammatic proof of gauge invariance given in chapter II.7 implies that
qμμν(q) = 0. Together with Lorentz invariance, this requires that
μν(q) = (qμqν −gμνq2)(q2)
(3)
The physical or renormalized photon propagator as shown in figure III.7.2 is then given
by the geometric series
iDP
μν(q) = iDμν(q) + iDμλ(q)iλρ(q)iDρν(q)
+ iDμλ(q)iλρ(q)iDρσ(q)iσκ(q)iDκν(q) + . . .
= −ie2
q2 gμν{1 −e2(q2) + [e2(q2)]2 + . . .} + qμqν term
= −ie2
q2 gμν
1
1 + e2(q2) + qμqν term
(4)
Because of (3) the (1 −ξ)(qμqλ/q2) part of Dμλ(q) is annihilated when it encounters
λρ(q). Thus, in iDP
μν(q) the gauge parameter ξ enters only into the qμqν term and drops
out in physical amplitudes, as explained in chapter II.7.

202 | III. Renormalization and Gauge Invariance
The residue of the pole in iDP
μν(q) is the physical or renormalized charge squared:
e2
R = e2
1
1 + e2(0)
(5)
Respect for gauge invariance
In order to determine eR in terms of e, let us calculate to lowest order
iμν(q) = (−)

d4p
(2π)4 tr

iγ ν
i
̸p + ̸q −miγ μ
i
̸p −m

(6)
For large p the integrand goes as 1/p2 with a subleading term going as m2/p4 causing
the integral to have a quadratically divergent and a logarithmically divergent piece. (You
see, it is easy to slip into bad language.) Not a conceptual problem at all, as I explained
in chapter III.1. We simply regularize. But now there is a delicate point: Since gauge
invariance plays a crucial role, we must make sure that our regularization respects gauge
invariance.
In the Pauli-Villars regularization (III.1.13) we replace (6) by
iμν(q) = (−)

d4p
(2π)4

tr

iγ ν
i
̸p + ̸q −miγ μ
i
̸p −m

−

a
ca tr

iγ ν
i
̸p + ̸q −ma
iγ μ
i
̸p −ma

(7)
Now the integrand goes as (1 −
a ca)(1/p2) with a subleading term going as (m2 −

a cam2
a)(1/p4), and thus the integral would converge if we choose ca and ma such that

a
ca = 1
(8)
and

a
cam2
a = m2
(9)
Clearly, we have to introduce at least two regulator masses. We are confessing to ignorance
of the physics above the mass scale ma. The integral in (7) is effectively cut off when the
momentum p exceeds ma.
Does a bell ring for you? It should, as this discussion conceptually parallels that in the
appendix to chapter I.9.
The gauge invariant form (3) we expect to get actually suggests that we need fewer
regulator terms than we think. Imagine expanding (6) in powers of q. Since
μν(q) = (qμqν −gμνq2)[(0) + . . .]
we are only interested in terms of O(q2) and higher in the Feynman integral. If we expand
the integrand in (6), we see that the term of O(q2) goes as 1/p4 for large p, thus giving a
logarithmically divergent (speaking bad language again!) contribution. (Incidentally, you

III.7. Polarizing the Vacuum | 203
may recall that this sort of argument was also used in chapter III.3.) It seems that we need
only one regulator. This argument is not rigorous because we have not proved that (q2)
has a power series expansion in q2, but instead of worrying about it let us proceed with
the calculation.
Once the integral is convergent, the proof of gauge invariance given in chapter II.7 now
goes through. Let us recall briefly how the proof went. In computing qμμν(q) we use the
identity
1
̸p + ̸q −m ̸q
1
̸p −m =
1
̸p −m −
1
̸p + ̸q −m
to split the integrand into two pieces that cancel upon shifting the integration variable
p →p + q. Recall from exercise (II.7.2) that we were concerned that in some cases the
shift may not be allowed, but it is allowed if the integral is sufficiently convergent, as is
indeed the case now that we have regularized. In any event, the proof is in the eating of
the pudding, and we will see by explicit calculation that μν(q) indeed has the form in (3).
Having learned various computational tricks in the previous chapter you are now ready
to tackle the calculation. I will help by walking you through it. In order not to clutter up
the page I will suppress the regulator terms in (7) in the intermediate steps and restore
them toward the end. After a few steps you should obtain
iμν(q) = −

d4p
(2π)4
Nμν
D
where Nμν = tr[γν( ̸p + ̸q + m)γμ( ̸p + m)] and
1
D =
 1
0
dα 1
D
with D = [l2 + α(1 −α)q2 −m2 + iε]2, where l = p + αq. Eliminating p in favor of l and
beating on Nμν you will find that Nμν is effectively equal to
−4
1
2gμνl2 + α(1 −α)(2qμqν −gμνq2) −m2gμν

Integrate over l using (D.12) and (D.13) and, writing the contribution from the regulators
explicitly, obtain
μν(q) = −1
4π2
 1
0
dα
	
Fμν(m) −

a
caFμν(ma)

(10)
where
Fμν(m)
= 1
2gμν

2 −2[m2 −α(1 −α)q2] log
2
m2 −α(1 −α)q2 + m2 −α(1 −α)q2

−[α(1 −α)(2qμqν −gμνq2) −m2gμν]

log
2
m2 −α(1 −α)q2 −1

(11)
Remember, you are doing the calculation; I am just pointing the way. In appendix D,  was
introduced to give meaning to various divergent integrals. Since our integral is convergent,

204 | III. Renormalization and Gauge Invariance
we should not need , and indeed, it is gratifying to see that in (10)  drops out thanks
to the conditions (8) and (9). Some other terms drop out as well, and we end up with
μν(q) = −1
2π2(qμqν −gμνq2)
 1
0
dα α(1 −α)
{log[m2 −α(1 −α)q2] −

a
ca log[m2
a −α(1 −α)q2]}
(12)
Lo and behold! The vacuum polarization tensor indeed has the form μν(q) = (qμqν −
gμνq2)(q2). Our regularization scheme does respect gauge invariance.
For q2 ≪m2
a (the kinematic regime we are interested in had better be much lower than
our threshold of ignorance) we simply define log M2 ≡
a
ca log m2
a in (12) and obtain
(q2) =
1
2π2
 1
0
dα α(1 −α) log
M2
m2 −α(1 −α)q2
(13)
Note that our heuristic argument is indeed correct. In the end, effectively we need only
one regulator, but in the intermediate steps we needed two. Actually, this bickering over
the number of regulators is beside the point.
In chapter III.1 I mentioned dimensional regularization as an alternative to Pauli-Villars
regularization. Historically, dimensional regularization was invented to preserve gauge
invariance in nonabelian gauge theories (which I will discuss in a later chapter). It is
instructive to calculate  using dimensional regularization (exercise III.7.1).
Electric charge
Physically, we end up with a result for (q2) containing a parameter M2 expressing our
threshold of ignorance. We conclude that
e2
R = e2
1
1 + (e2/12π2) log(M2/m2) ≃e2

1 −
e2
12π2 log M2
m2

(14)
Quantum fluctuations effectively diminish the charge. I will explain the physical origin of
this effect in a later chapter on renormalization group flow.
You might argue that physically charge is measured by how strongly one electron scatters
off another electron. To order e4 , in addition to the diagrams in chapter II.7, we also have,
among others, the diagrams shown in figure III.7.4a,b,c. We have computed 4a, but what
about 4b and 4c? In many texts, it is shown that contributions of III.7.4b and III.7.4c to
charge renormalization cancel. The advantage of using the Lagrangian in (1) is that this
fact becomes self-evident: Charge is a measure of how the photon propagates.
To belabor a more or less self-evident point let us imagine doing physical or renormalized
perturbation theory as explained in chapter III.3. The Lagrangian is written in terms of
physical or renormalized fields (and as before we drop the subscript P on the fields)
L = ¯ψ(iγ μ(∂μ −iAμ) −mP)ψ −
1
4e2
P
FμνF μν
+ A ¯ψiγ μ(∂μ −iAμ)ψ + B ¯ψψ −CFμνF μν
(15)

III.7. Polarizing the Vacuum | 205
+
(a)
(b)
(c)
Figure III.7.4
where the coefficients of the counterterms A, B, and C are determined iteratively. The
point is that gauge invariance guarantees that ¯ψiγ μ∂μψ and ¯ψγ μAμψ always occur in
the combination ¯ψiγ μ(∂μ −iAμ)ψ: The strength of the coupling of Aμ to ¯ψγ μψ cannot
change. What can change is the ease with which the photon propagates through spacetime.
This statement has profound physical implications. Experimentally, it is known to a
high degree of accuracy that the charges of the electron and the proton are opposite and
exactly equal. If the charges were not exactly equal, there would be a residual electrostatic
force between macroscopic objects. Suppose we discovered a principle that tells us that
the bare charges of the electron and the proton are exactly equal (indeed, as we will see,
in grand unification theories, this fact follows from group theory). How do we know
that quantum fluctuations would not make the charges slightly unequal? After all, the
proton participates in the strong interaction and the electron does not and thus many
more diagrams would contribute to the long range electromagnetic scattering between
two protons. The discussion here makes clear that this equality will be maintained for the
obvious reason that charge renormalization has to do with the photon. In the end, it is all
due to gauge invariance.
Modifying the Coulomb potential
We have focused on charge renormalization, which is determined completely by (0), but
in (13) we obtained the complete function (q2), which tells us how the q dependence of
the photon propagator is modified. According to the discussion in chapter I.5, the Coulomb
potential is just the Fourier transform of the photon propagator (see also exercise III.5.3).
Thus, the Coulomb interaction is modified from the venerable 1/r law at a distance scale
of the order of (2m)−1, namely the inverse of the characteristic value of q in (q2). This
modification was experimentally verified as part of the Lamb shift in atomic spectroscopy,
another great triumph of quantum electrodynamics.

206 | III. Renormalization and Gauge Invariance
Exercises
III.7.1
Calculate μν(q) using dimensional regularization. The procedure is to start with (6), evaluate the trace
in Nμν, shift the integration momentum from p to l, and so forth, proceeding exactly as in the text,
until you have to integrate over the loop momentum l. At that point you “pretend” that you are living
in d-dimensional spacetime, so that the term like lμlν in Nμν, for example, is to be effectively replaced
by (1/d)gμνl2. The integration is to be performed using (III.1.15) and various generalizations thereof.
Show that the form (3) automatically emerges when you continue to d = 4.
III.7.2
Study the modified Coulomb’s law as determined by the Fourier integral

d3q{1/⃗q2[1 + e2(⃗q2)]}ei⃗q ⃗x.

III.8
Becoming Imaginary and Conserving Probability
When Feynman amplitudes go imaginary
Let us admire the polarized vacuum, viz (III.7.13):
(q2) =
1
2π2
 1
0
dαα(1 −α) log
2
m2 −α(1 −α)q2 −iε
(1)
Dear reader, you have come a long way in quantum field theory, to be able to calculate such
an amazing effect. Quantum fluctuations alter the way a photon propagates!
For a spacelike photon, with q2 negative,  is real and positive for momentum small
compared to the threshold of our ignorance . For a timelike photon, we see that if q2 > 0
is large enough, the argument of the logarithm may go negative, and thus  becomes
complex. As you know, the logarithmic function log z could be defined in the complex
z plane with a cut that can be taken conventionally to go along the negative real axis,
so that for w real and positive, log(−w ± iε) = log(w) ± iπ [since in polar coordinates
log(ρeiθ) = log(ρ) + iθ].
We now invite ourselves to define a function in the complex plane: (z) ≡
1/(2π2)
 1
0 dαα(1 −α) log 2/(m2 −α(1 −α)z). The integrand has a cut on the positive
real z axis extending from z = m2/(α(1 −α)) to infinity (fig. III.8.1). Since the maximum
value of α(1 −α) in the integration range is 1
4 , (z) is an analytic function in the complex
z plane with a cut along the real axis starting at zc = 4m2. The integral over α smears all
those cuts of the integrand into one single cut.
For timelike photons with large enough q2, a mathematician might be paralyzed won-
dering which side of the cut to go to, but we as physicists know, as per the iε prescription
from chapter I.3, that we should approach the cut from above, namely that we should take
(q2 + iε) (with ε, as always, a positive infinitesimal) as the physical value. Ultimately,
causality tells us which side of the cut we should be on.
That the imaginary part of  starts at

q2 > 2m provides a strong hint of the physics
behind amplitudes going complex. We began the preceding chapter talking about how

208 | III. Renormalization and Gauge Invariance
z
4m2
Figure III.8.1
a photon merrily propagating along could always metamorphose into a virtual electron-
positron pair that, after a short time dictated by the uncertainly principle, annihilate each
other to become a photon again. For

q2 > 2m the pair is no longer condemned to be
virtual and to fluctuate out of existence almost immediately. The pair has enough energy
to get real. (If you did the exercises religiously, you would recognize that these points were
already developed in exercises I.7.4 and III.1.2.)
Physically, we could argue more forcefully as follows. Imagine a gauge boson of mass M
coupling to electrons just like the photon. (Indeed, in this book we started out supposing
that the photon has a mass.) The vacuum polarization diagram then provides a one-loop
correction to the vector boson propagator. For M > 2m, the vector boson becomes unstable
against decay into an electron-positron pair. At the same time,  acquires an imaginary
part. You might suspect that Im might have something to do with the decay rate. We will
verify these suspicions later and show that, hey, your physical intuition is pretty good.
When we ended the preceding chapter talking about the modifications to the Coulomb
potential, we thought of a spacelike virtual photon being exchanged between two charges as
in electron-electron or electron-proton scattering (chapter II.6). Use crossing (chapter II.8)
to map electron-electron scattering into electron-positron scattering. The vacuum polariza-
tion diagram then appears (fig. III.8.2) as a correction to electron-positron scattering. One
function  covers two different physical situations.
Incidentally, the title of this section should, strictly speaking, have the word “complex,”
but it is more dramatic to say “When Feynman amplitudes go imaginary,” if only to echo
certain movie titles.
Dispersion relations and high frequency behavior
One of the most remarkable discoveries in elementary
particle physics has been that of the existence of the
complex plane.
—J. Schwinger
Considering that amplitudes are calculated in quantum field theory as integrals over
products of propagators, it is more or less clear that amplitudes are analytic functions

III.8. Becoming Imaginary | 209
e
e
e
e
Figure III.8.2
of the external kinematic variables. Another example is the scattering amplitude M in
chapter III.1: it is manifestly an analytic function of s, t, and u with various cuts. From the
late 1950s until the early 1960s, considerable effort was devoted to studying analyticity in
quantum field theory, resulting in a vast literature.
Here we merely touch upon some elementary aspects. Let us start with an embarrass-
ingly simple baby example: f (z) =
 1
0 dα1/(z −α) = log((z −1)/z). The integrand has a
pole at z = α, which got smeared by the integral over α into a cut stretching from 0 to 1.
At the level of physicist rigor, we may think of a cut as a lot of poles mashed together and
a pole as an infinitesimally short cut.
We will mostly encounter real analytic functions, namely functions satisfying f ∗(z) =
f (z∗) (such as log z). Furthermore, we focus on functions that have cuts along the real axis,
as exemplified by (z). For the class of analytic functions specified here, the discontinuity
of the function across the cut is given by discf (x) ≡f (x + iε) −f (x −iε) = f (x + iε) −
f (x + iε)∗= 2iImf (x + iε). Define, for σ real, ρ(σ) = Imf (σ + iε). Using Cauchy’s
theorem with a contour C that goes around the cut as indicated in figure III.8.3, we could
write
f (z) =

C
dz′
2πi
f (z′)
z′ −z .
(2)
Assuming that f (z) vanishes faster than 1/z as z →∞, we can drop the contribution from
infinity and write
f (z) = 1
π

dσ ρ(σ)
σ −z
(3)
where the integral ranges over the cut. Note that we can check this equation using the
identity (I.2.14):
Imf (x + iε) = 1
π

dσρ(σ)Im
1
σ −x −iε = 1
π

dσρ(σ)πδ(σ −x)

210 | III. Renormalization and Gauge Invariance
z
C
Figure III.8.3
This relation tells us that knowing the imaginary part of f along the cut allows us to
construct f in its entirety, including a fortiori its real part on and away from the cut.
Relations of this type, known collectively as dispersion relations, go back at least to the
work of Kramers and Kr¨onig on optics and are enormously useful in many areas of physics.
We will use it in, for example, chapter VII.4.
We implicitly assumed that the integral over σ converges. If not, we can always (formally)
subtract f (0) = 1
π

dσρ(σ)/σ from f (z) as given above and write
f (z) = f (0) + z
π

dσ
ρ(σ)
σ(σ −z)
(4)
The integral over σ now enjoys an additional factor of 1/σ and hence is more convergent.
In this case, to reconstruct f (z), we need, in addition to knowledge of the imaginary part
of f on the cut, an unknown constant f (0). Evidently, we could repeat this process until
we obtain a convergent integral.
A bell rings, and you, the astute reader, see the connection with the renormalization
procedure of introducing counterterms. In the dispersion weltanschauung, divergent
Feynman integrals correspond to integrals over σ that do not converge. Once again,
divergent integrals do not bend real physicists out of shape: we simply admit to ignorance
of the high σ regime.
During the height of the dispersion program, it was jokingly said that particle theorists
either group or disperse, depending on whether you like group theory or complex analysis
better.

III.8. Becoming Imaginary | 211
Imaginary part of Feynman integrals
Going back to the calculation of vacuum polarization in the preceding chapter, we see
that the numerator Nμν, which comes from the spin of the photon and of the electron,
is irrelevant in determining the analytic structure of the Feynman diagram. It is the
denominator D that counts. Thus, to get at a conceptual understanding of analyticity
in quantum field theory, we could dispense with spins and study the analog of vacuum
polarization in the scalar field theory with the interaction term L = g(η†ξ†ϕ + h.c.),
introduced in the appendix to chapter II.6. The ϕ propagator is corrected by the analog
of the diagrams in figure III.7.1 to [compare with (4)]
iDP(q) =
i
q2 −M2 + iϵ +
i
q2 −M2 + iϵ i(q2)
i
q2 −M2 + iϵ + . . .
=
i
q2 −M2 + (q2) + iϵ
(5)
To order g2 we have
i(q2) = i4g2

d4k
(2π)4
1
k2 −μ2 + iε
1
(q −k)2 −m2 + iε
(6)
As in the preceding chapter we need to regulate the integral, but we will leave that implicit.
Having practiced with the spinful calculation of the preceding chapter, you can now
whiz through this spinless calculation and obtain
(z) =
g2
16π2
 1
0
dα log
2
αm2 + (1 −α)μ2 −α(1 −α)z
(7)
with  some cutoff. (Please do whiz and not imagine that you could whiz.) We use the
same Greek letter  and allow the two particles in the loop to have different masses, in
contrast to the situation in quantum electrodynamics.
As before, for z real and negative, the argument of the log is real and positive, and  is
real. By the same token, for z real and positive enough, the argument of the log becomes
negative for some value of α, and (z) goes complex. Indeed,
Im(σ + iε) = −g2
16π2
 1
0
dα(−π)θ[α(1 −α)σ −αm2 −(1 −α)μ2]
= g2
16π
 α+
α−
dα
=
g2
16πσ

(σ −(m + μ)2)(σ −(m −μ)2)
(8)
with α± the two roots of the quadratic equation obtained by setting the argument of the
step function to zero.

212 | III. Renormalization and Gauge Invariance
Decay and distintegration
At this point you might already be flipping back to the expression given in chapter II.6 for
the decay rate of a particle. Earlier we entertained the suspicion that the imaginary part of
(z) corresponds to decay. To confirm our suspicion, let us first go back to elementary
quantum mechanics. The higher energy levels in a hydrogen atom, say, are, strictly
speaking, not eigenstates of the Hamiltonian: an electron in a higher energy level will, in a
finite time, emit a photon and jump to a lower energy level. Phenomenologically, however,
the level could be assigned a complex energy E −i 1
2. The probability of staying in this
level then goes with time like |ψ(t)|2 ∝|e−i(E−i 1
2)t|2 = e−t. (Note that in elementary
quantum mechanics, the Coulomb and radiation components of the electromagnetic field
are treated separately: the former is included in the Schr¨odinger equation but not the latter.
One of the aims of quantum field theory is to remedy this artificial split.)
We now go back to (5) and field theory: note that (q2) effectively shifts M2 →M2 −
(q2). Recall from (III.3.3) that we have counter terms available to, well, counter two
cutoff-dependent pieces of (q2). But we have nothing to counter the imaginary part of
(q2) with, and so it better be cutoff independent. Indeed it is! The cutoff only appears in
the real part in (7).
We conclude that the effect of  going imaginary is to shift the mass of the ϕ meson
by a cutoff-independent amount from M to

M2 −iIm(M2) ≈M −iIm(M2)/(2M).
Note that to order g2 it suffices to evaluate  at the unshifted mass squared M2, since
the shift in mass is itself of order g2. Thus  = Im(M2)/M gives the decay rate, as we
suspected. We obtain (g has dimension of mass and so the dimension is correct)
 =
g2
16πM3

[M2 −(m + μ)2][M2 −(m −μ)2]
(9)
precisely what we had in (II.6.7). You and I could both take a bow for getting all the factors
exactly right!
Note that both the treatment given in elementary quantum mechanics and here are in
the spirit of treating the decay as a small perturbation. As the width becomes large, at some
point it no longer makes good sense to talk of the field associated with the particle ϕ.
Taking the imaginary part directly
We ought to be able to take the imaginary part of the Feynman integral in (6) directly, rather
than having to first calculate it as an integral over the Feynman parameter α. I will now
show you how to do this using a trick. For clarity and convenience, change notation from
(6), label the momentum carried by the two internal lines in figure III.8.4a separately, and
restore the momentum conservation delta function, so that
i(q) = (ig)2i2

d4kη
(2π)4
d4kξ
(2π)4 (2π)4δ4(kη + kξ −q)

1
k2
η −m2
η + iϵ
1
k2
ξ −m2
ξ + iϵ

(10)

III.8. Becoming Imaginary | 213
q
k
k

o
x


(b)
(a)
Figure III.8.4
Write the propagator as 1/(k2 −m2 + iϵ) = P(1/(k2 −m2)) −iπδ(k2 −m2) and, noting
an explicit overall factor of i, take the real part of the curly bracket above, thus obtaining
Im(q) = −g2

d(PηPξ −ηξ)
(11)
For the sake of compactness, we have introduced the notation
d = d4kη
(2π)4
d4kξ
(2π)4 (2π)4δ4(kη + kξ −q),
Pη = P
1
k2
η −m2
η
,
η = πδ(k2
η −m2
η)
and so on.
We welcome the product of two delta functions; they are what we want, restricting the
two particles η and ξ on shell. But yuck, what do we do with the product of the two principal
values? They don’t correspond to anything too physical that we know of.
To get rid of the two principal values, we use a trick.1 First, we regress and recall that
we started out with Feynman diagrams as spacetime diagrams (for example, fig. I.7.6) of
the process under study. Here (fig. III.8.4b) a ϕ excitation turns into an η and a ξ with
amplitude ig at some spacetime point, which by translation invariance we could take to be
the origin; the η and the ξ excitations propagate to some point x with amplitude iDη(x)
and iDξ(x), respectively, and then recombine into ϕ with amplitude ig (note: not −ig).
Fourier transforming this product of spacetime amplitudes gives
i(q) = (ig)2i2

dxe−iqxDη(x)Dξ(x)
(12)
To see that this is indeed the same as (10), all you have to do is to plug in the expression
(I.3.22) for Dη(x) and Dξ(x).
Incidentally, while many “professors of Feynman diagrams” think almost exclusively
in momentum space, Feynman titled his 1949 paper “Space-Time Approach to Quantum
Electrodynamics,” and on occasions it is useful to think of the spacetime roots of a given
Feynman diagram. Now is one of those occasions.
1 C. Itzkyson and J.-B. Zuber, Quantum Field Theory, p. 367.

214 | III. Renormalization and Gauge Invariance
Next, go back to exercise I.3.3 and recall that the advanced propagator Dadv(x) and
retarded propagator Dret(x) vanish for x0 < 0 and x0 > 0, respectively, and thus the product
Dadv(k)Dret(k) manifestly vanishes for all x. Also recall that the advanced and retarded
propagators Dadv(k) and Dret(k) differ from the Feynman propagator D(k) by simply, but
crucially, having their poles in different half-planes in the complex k0 plane. Thus
0 = −ig2

dxe−iqxDη,adv(x)Dξ ,ret(x)
=

d4kη
(2π)4
d4kξ
(2π)4 (2π)4δ4(kη + kξ −q)
1
k2
η −m2
η −iσηϵ
1
k2
ξ −m2
ξ + iσξϵ
(13)
where we used the shorthand ση = sgn(k0
η) and σξ = sgn(k0
ξ). (The sign function is defined
by sgn(x) = ±1 according to whether x > 0 or < 0.) Taking the imaginary part of 0, we
obtain [compare (11)]
0 = −g2

d(PηPξ + σησξηξ)
(14)
Subtracting (14) from (11) to get rid of the rather unpleasant term PηPξ, we find finally
Im(q) = +g2

d(1 + σησξ)(ηξ)
= g2π2

d4kη
(2π)4
d4kξ
(2π)4 (2π)4δ4(kη + kξ −q)θ(k0
η)δ(k2
η −m2
η)θ(k0
ξ)δ(k2
ξ −m2
ξ)(1 + σησξ)
(15)
Thus (q) develops an imaginary part only when the three delta functions can be satisfied
simultaneously.
To see what these three conditions imply, we can, since (q) is a function of q2, go
to a frame in which q = (Q, ⃗0) with Q > 0 with no loss of generality. Since k0
η + k0
ξ =
Q > 0 and since (1 + σησξ) vanishes unless k0
η and k0
ξ have the same sign, k0
η and k0
ξ
must be both positive if Im(q) is to be nonzero, but that is already mandated by the
two step functions. Furthermore, we need to solve the conservation of energy condition
Q =

⃗k2 + m2
η +

⃗k2 + m2
ξ for some 3-vector ⃗k. This is possible only if Q > mη + mξ, in
which case, using the identity (I.8.14)
θ(k0)δ(k2 −μ2) = θ(k0)δ(k0 −εk)
2εk
,
(16)
we obtain
Im(q) = 1
2g2

d3kη
(2π)32ωη
d3kξ
(2π)32ωξ
(2π)4δ4(kη + kξ −q)
(17)
We see that (and as we will see more generally) Im(q) works out to be a finite integral
over delta functions. Indeed, no counter term is needed.
Some readers might feel that this trick of invoking the advanced and retarded propa-
gators is perhaps a bit “too tricky.” For them, I will show a more brute force method in
appendix 1.

III.8. Becoming Imaginary | 215
Unitarity and the Cutkosky cutting rule
The simple example we just went through in detail illustrates what is known as the
Cutkosky cutting rule, which states that to calculate the imaginary part of a Feynman
amplitude we first “cut” through a diagram (as indicated by the dotted line in figure II.8.4a).
For each internal line cut, replace the propagator 1/(k2 −m2 + iϵ) by δ(k2 −m2); in other
words, put the virtual excitation propagating through the cut onto the mass shell. Thus,
in our example, we could jump from (10) to (15) directly. This validates our intuition that
Feynman amplitudes go imaginary when virtual particles can “get real.”
For a precise statement of the cutting rule, see below. (The Cutkosky cut is not be
confused with the Cauchy cut in the complex plane, of course.)
The Cutkosky cutting rule in fact follows in all generality from unitarity. A basic postulate
of quantum mechanics is that the time evolution operator e−iHT is unitary and hence
preserves probability. Recall from chapter I.8 that it is convenient to split off from the
S matrix Sf i = ⟨f |e−iHT |i⟩the piece corresponding to “nothing is happening”: S = I +
iT . Unitarity S†S = I then implies 2 Im T = i(T † −T ) = T †T . Sandwiching this between
initial and final states and inserting a complete set of intermediate states (1 = 
n |n⟩⟨n|)
we have
2 Im Tf i =

n
T †
f nTni
(18)
which some readers might recognize as a generalization of the optical theorem from
elementary quantum mechanics.
It is convenient to introduce F = −iM. (We are merely taking out an explicit factor of
i in M: in our simple example, M corresponds to i, F to .) Then the relation (I.8.16)
between T and M becomes Tf i = (2π)4δ(4)(Pf i)(f i1/ρ)F(f ←i), where for the sake
of compactness we have introduced some obvious notations [thus (f i
1
ρ ) denotes the
product of the normalization factors 1/ρ (see chapter I.8), one for each of the particle in
the state i and in the state f , and Pf i the sum of the momenta in f minus the sum of the
momenta in i.]
With this notation, the left-hand side of the generalized optical theorem becomes
2ImTf i = 2(2π)4δ(4)(Pf i)(f i1/ρ)Im F(f ←i) and the right-hand side

n
T †
f nTni =

n
(2π)4δ(4)(Pf n)(2π)4δ(4)(Pni)

f n
1
ρ
 
ni
1
ρ

(F(n ←f ))∗F(n ←i)
The product of two delta functions δ(4)(Pf n)δ(4)(Pni) = δ(4)(Pf i)δ(4)(Pni), and thus we
could cancel off δ(4)(Pf i). Also (f n1/ρ)(ni1/ρ)/(f i1/ρ) = (n1/ρ2), and we happily
recover the more familiar factor ρ2 [namely (2π)32ω for bosons]. Thus finally, the gener-
alized optical theorem tells that
2ImF(f ←i) =

n
(2π)4δ(4)(Pni)

n
1
ρ2

(F(n ←f ))∗F(n ←i),
(19)

216 | III. Renormalization and Gauge Invariance
namely, that the imaginary part of the Feynman amplitude F(f ←i) is given by a sum
of (F(n ←f ))∗F(n ←i) over intermediate states |n⟩. The particles in the intermediate
state are of course physical and on shell. We are to sum over all possible states |n⟩allowed
by quantum numbers and by the kinematics.
According to Cutkosky, given a Feynman diagram, to obtain its imaginary part, we
simply cut through it in the several different ways allowed, corresponding to the different
possible intermediate state |n⟩. Particles in the state |n⟩are manifestly real, not virtual.
Note that unitarity and hence the optical theorem are nonlinear in the transition am-
plitude. This has proved to be enormously useful in actual computation. Suppose we are
perturbing in some coupling g and we know F(n ←i) and F(n ←f ) to order gN. The op-
tical theorem gives us Im F(f ←i) to order gN+1, and we could then construct F(f ←i)
to order gN+1 using a dispersion relation.
The application of the Cutkosky rule to the vacuum polarization function discussed in
this chapter is particularly simple: there is only one possible way of cutting the Feynman
diagram for . Here the initial and final states |i⟩and |f ⟩both consist of a single ϕ meson,
while the intermediate state |n > consists of an η and a ξ meson.
Referring to the appendix to chapter II.6, we recall that 
n corresponds to

d3kη
(2π)3
d3kξ
(2π)3.
Thus the optical theorem as stated in (19) says that
Im(q) = 1
2g2

d3kη
(2π)32ωη
d3kξ
(2π)32ωξ
(2π)4δ4(kη + kξ −q)
(20)
precisely what we obtained in (17). You and I could take another bow, since we even get
the factor of 2 correctly (as we must!).
We should also say, in concluding this chapter, “Vive Cauchy!”
Appendix 1: Taking the imaginary part by brute force
For those readers who like brute force, we will extract the imaginary part of
 = −ig2

d4k
(2π)4
1
k2 −μ2 + iε
1
(q −k)2 −m2 + iε
(21)
by a more staightforward method, as promised in the text. Since  depends only on q2, we have the luxury
of setting q = (M, ⃗0). We already know that in the complex M2 plane,  has a cut on the axis starting at
M2 = (m + μ)2. Let us verify this by brute force.
We could restrict ourselves to M > 0. Factorizing, we find that the denominator of the integrand is a product of
four factors, k0 −(εk −iε), k0 + (εk −iε), k0 −(M + Ek −iε), and k0 −(M −Ek + iε), and thus the integrand
has four poles in the complex k0 plane. (Evidently, εk =

⃗k2 + μ2, Ek =

⃗k2 + m2, and if you are perplexed over
the difference between εk and ε, then you are hopelessly confused.) We now integrate over k0, choosing to close
the contour in the lower half plane and going around picking up poles. Picking up the pole at εk −iε, we obtain
1 = −g2 
(d3k/(2π)3)(1/(2εk(εk −M −Ek)(εk −M + Ek))). Picking up the pole at M + Ek −iε, we obtain
2 = −g2 
(d3k/(2π)3)(1/((M + Ek −εk)(M + Ek + εk)(2Ek))). We now regard  = 1 + 2 as a function of
M:
 = −g2

d3k
(2π)3
1
(M + Ek −εk)

1
2εk(M −εk −Ek + iε) +
1
2Ek(M + Ek + εk −iε)

(22)

III.8. Becoming Imaginary | 217
In spite of appearances, there is no pole at M ≈εk −Ek. (Since this pole would lead to a cut at μ −m, there better
not be!) For M > 0 we only care about the pole at M ≈εk + Ek =

⃗k2 + μ2 +

⃗k2 + m2. When we integrate over
⃗k, this pole gets smeared into a cut starting at m + μ. So far so good.
To calculate the discontinuity across the cut, we use the identity (16) once again Restoring the iε’s and throwing
away the term we don’t care about, we have effectively
 = −g2

d3k
(2π)3
1
2εk(εk −M −Ek + iε)(εk −M + Ek −iε)
= −2πg2

d4k
(2π)4 θ(k0)δ(k2 −μ2)
1
(M −εk + Ek −iε)(M −(εk + Ek) + iε)
The discontinuity of  across the cut just specified is determined by applying (I.2.13) to the factor
1/(M −(εk + Ek) + iε), giving Im = 2π2g2 
(d4k/(2π)4)θ(k0)δ(k2 −μ2)δ(M −(εk + Ek))/2Ek. Use the
identity (16) again in the form
θ(q0 −k0)θ((q −k)2 −m2) = θ(q0 −k0)θ((q0 −k0) −Ek)
2Ek
(23)
and we obtain
Im = 2π2g2

d4k
(2π)4 θ(k0)δ(k2 −μ2)θ(q0 −k0)δ((q −k)2 −m2)
(24)
Remarkably, as Cutkosky taught us, to obtain the imaginary part we simply replace the propagators in (21) by
delta functions.
Appendix 2: A dispersion representation for the two-point amplitude
I would like to give you a bit more flavor of the dispersion program once active and now being revived (see
part N). Consider the two-point amplitude iD(x) ≡⟨0|T (O(x)O(0))|0⟩, with O(x) some operator in the canonical
formalism. For example, for O(x) equal to the field ϕ(x), D(x) would be the propagator. In chapter I.8, we were
able to evaluate D(x) for a free field theory, because then we could solve the field equation of motion and expand
ϕ(x) in terms of creation and annihilation operators. But what can we do in a fully interacting field theory? There
is no hope of solving the operator field equation of motion.
The goal of the dispersion program of the 1950s and 1960s is to say as much as possible about D(x) based on
general considerations such as analyticity.
OK, so first write iD(x) = θ(x0)⟨0|eiP xO(0)e−iP xO(0)|0⟩+ θ(−x0)⟨0|O(0)eiP xO(0)e−iP x |0⟩, where we
used spacetime translation O(x) = eiP.xO(0)e−iP.x. By the way, if you are not totally sure of this relation, dif-
ferentiate it to obtain ∂μO(x) = i[Pμ, O(x)] which you should recognize as the relativistic version of the usual
Heisenberg equations (I.8.2, 3). Now insert 1= 
n |n⟩⟨n|, with |n⟩a complete set of intermediate states, to obtain
⟨0|eiPxO(0)e−iPxO(0)|0⟩= ⟨0|O(0)e−iPxO(0)|0⟩= 
n⟨0|O(0)|n⟩⟨n|e−iPxO(0)|0⟩= 
ne−iPnx|O0n|2, where
we used P μ |0⟩= 0 and P μ |n⟩= P μ
n |n⟩and defined O0n ≡⟨0|O(0)|n⟩. Next, use the integral representations
for the step function θ(t) = −i

(dω/2π)eiωt/(ω −iε) and θ(−t) = i

(dω/2π)eiωt/(ω + iε). Again, if you are
not sure of this, simply differentiate d
dt θ(t) = −i d
dt

(dω/2π)eiωt/(ω −iε) =

(dω/2π)eiωt, which you recog-
nize from (I.2.12) as indeed the integral representation of the delta function δ(t) = d
dt θ(t). In other words, the
representation used here is the integral of the representation in (I.2.12).
Putting it all together, we obtain
iD(q) =

d4xeiq.xiD(x) = −i(2π)3
n|O0n|2

δ(3)(⃗q −⃗Pn)
P 0
n −q0 −iε + δ(3)(⃗q + ⃗Pn)
P 0
n + q0 −iε

.
(25)
The integral over d3x produced the 3-dimensional delta function, while the integral over dx0 = dt picked up the
denominator in the integral representation for the step function.
Now take the imaginary part using Im1/(P 0
n −q0 −iε) = πδ(q0 −P 0
n ). We thus obtain
Im(i

d4xeiqx⟨0|T (O(x)O(0))|0⟩) = π(2π)3
n|O0n|2(δ(4)(q −Pn) + δ(4)(q + Pn))
(26)

218 | III. Renormalization and Gauge Invariance
with the more pleasing 4-dimensional delta function. Note that for q0 > 0 the term involving δ(4)(q + Pn) drops
out, since the energies of physical states must be positive.
What have we accomplished? Even though we are totally incapable of calculating D(q), we have managed to
represent its imaginary part in terms of physical quantities that are measurable in principle, namely the absolute
square |O0n|2 of the matrix element of O(0) between the vacuum state and the state |n⟩. For example, if O(x) is
the meson field ϕ(x) in a ϕ4 theory, the state |n⟩would consist of the single-meson state, the three-meson state,
and so on. The general hope during the dispersion era was that by keeping a few states we could obtain a decent
approximation to D(q). Note that the result does not depend on perturbing in some coupling constant.
The contribution of the single meson state |⃗k⟩has a particularly simple form, as you might expect.
With our normalization of single-particle states (as in chapter I.8), Lorentz invariance implies ⟨⃗k|O(0)|0⟩=
Z
1
2 /

(2π)32ωk, with ωk =

⃗k2 + m2 and Z
1
2 an unknown constant, measuring the “strength” with which O is
capable of producing the single meson from the vacuum. Putting this into (25) and recognizing that the sum
over single-meson states is now given by

d3k |⃗k⟩⟨⃗k| [with the normalization ⟨⃗k′| ⃗k⟩= δ3(⃗k′ −⃗k)], we find that
the single-meson contribution to iD(q) is given by
−i(2π)3

d3k
Z
(2π)32ωk

δ(3)(⃗q −⃗k)
ωk −q0 −iε + (q →−q)

= −i Z
2ωq

1
ωq −q0 −iε + (q →−q)

=
iZ
q2 −m2 + iε
(27)
This is a very satisfying result: even though we cannot calculate iD(q), we know that it has a pole at a position
determined by the meson mass with a residue that depends on how O is normalized.
As a check, we can also easily calculate the contribution of the single-meson state to −ImD(q). Plugging
into (26), we find, for q0 > 0, πZ

(d3k/2ωk)δ4(q −k) = (πZ/2ωq)δ(q0 −ωq) = πZδ(q2 −m2), where we used
(I.8.14, 16) in the last step.
Given our experience with the vacuum polarization function, we would expect D(q) (which by Lorentz
invariance is a function of q2) to have a cut starting at q2 = (3m)2. To verify this, simply look at (26) and choose ⃗q =
0. The contribution of the three-meson state occurs at

q2 = q0 = P 0
“3” =

⃗k2
1 + m2 +

⃗k2
2 + m2 +

⃗k2
3 + m2 ≥
3m. The sum over states is now a triple integration over ⃗k1, ⃗k2, and ⃗k3, subject to the constraint ⃗k1 + ⃗k2 + ⃗k3 = 0.
Knowing the imaginary part of D(q) we can now write a dispersion relation of the kind in (3).
Finally, if you stare at (26) long enough (see exercise III.8.3) you will discover the relation
Im(i

d4x eiqx⟨0|T (O(x)O(0))|0⟩) = 1
2

d4x eiqx⟨0|[O(x), O(0)]|0⟩
(28)
The discussion here is relevant to the discussion of field redefinition in chapter I.8. Suppose our friend uses
η = Z
1
2 ϕ + αϕ3 instead of ϕ; then the present discussion shows that his propagator

d4x eiqx⟨0|T (η(x)η(0))|0⟩
still has a pole at q2 −m2. The important point is that physics fixes the pole to be at the same location.
Here we have taken O to be a Lorentz scalar. In applications (see chapter VII.3) the role of O is often played
by the electromagnetic current J μ(x) (treated as an operator). The same discussion holds except that we have
to keep track of some Lorentz indices. Indeed, we recognize that the vacuum polarization function μν then
corresponds to the function D in this discussion.
Exercises
III.8.1
Evaluate the imaginary part of the vacuum polarization function, and by explicit calculation verify that it
is related to the decay rate of a vector particle into an electron and a positron.
III.8.2
Suppose we add a term gϕ3 to our scalar ϕ4 theory. Show that to order g4 there is a “box diagram”
contributing to meson scattering p1 + p2 →p3 + p4 with the amplitude
I = g4

d4k
(2π)4
1
(k2 −m2 −iε)((k + p2)2 −m2 −iε)((k −p1)2 −m2 −iε)((k + p2 −p3)2 −m2 −iε)

III.8. Becoming Imaginary | 219
Calculate the integral explicitly as a function of s = (p1 + p2)2 and t = (p3 −p2)2. Study the analyticity
property of I as a function of s for fixed t. Evaluate the discontinuity of I across the cut and verify
Cutkosky’s cutting rule. Check that the optical theorem works. What about the analyticity property of I
as a function of t for fixed s? And as a function of u = (p3 −p1)2?
III.8.3
Prove (28). [Hint: Do unto

d4x eiqx⟨0|[O(x), O(0)]|0⟩what we did to

d4x eiqx⟨0||T (O(x)O(0))|0⟩,
namely, insert 1 = 
n |n⟩⟨n| (with |n⟩a complete set of states) between O(x) and O(0) in the commu-
tator. Now we don’t have to bother with representing the step function.]

This page intentionally left blank

Part IV
Symmetry and Symmetry Breaking

This page intentionally left blank

IV.1
Symmetry Breaking
A symmetric world would be dull
While we would like to believe that the fundamental laws of Nature are symmetric,
a completely symmetric world would be rather dull, and as a matter of fact, the real
world is not perfectly symmetric. More precisely, we want the Lagrangian, but not the
world described by the Lagrangian, to be symmetric. Indeed, a central theme of modern
physics is the study of how symmetries of the Lagrangian can be broken. We will see in
subsequent chapters that our present understanding of the fundamental laws is built upon
an understanding of symmetry breaking.
Consider the Lagrangian studied in chapter I.10:
L = 1
2

(∂⃗ϕ)2 −μ2⃗ϕ2
−λ
4 (⃗ϕ2)2
(1)
where ⃗ϕ = (ϕ1, ϕ2, . . . , ϕN). This Lagrangian exhibits an O(N) symmetry under which ⃗ϕ
transforms as an N-component vector.
We can easily add terms that do not respect the symmetry. For instance, add terms
such as ϕ2
1, ϕ4
1 and ϕ2
1 ⃗ϕ2 and break the O(N) symmetry down to O(N −1), under which
ϕ2, . . . , ϕN rotate as an (N −1)-component vector. This way of breaking the symmetry,
“by hand” as it were, is known as explicit breaking.
We can break the symmetry in stages. Obviously, if we want to, we can break it down to
O(N −M) by hand, for any M < N.
Note that in this example, with the terms we added, the reflection symmetry ϕa →−ϕa
(any a) still holds. It is easy enough to break this symmetry as well, by adding a term such
as ϕ3
a, for example.
Breaking the symmetry by hand is not very interesting. Indeed, we might as well start
with a nonsymmetric Lagrangian in the first place.

224 | IV. Symmetry and Symmetry Breaking
V(q)
q
Figure IV.1.1
Spontaneous symmetry breaking
A more subtle and interesting way is to let the system “break the symmetry itself,” a
phenomenon known as spontaneous symmetry breaking. I will explain by way of an
example. Let us flip the sign of the ⃗ϕ2 term in (1) and write
L = 1
2

(∂⃗ϕ)2 + μ2⃗ϕ2
−λ
4 (⃗ϕ2)2
(2)
Naively, we would conclude that for small λ the field ϕ creates a particle of mass

−μ2 =
iμ. Something is obviously wrong.
The essential physics is analogous to what would happen if we give the spring constant
in an anharmonic oscillator the wrong sign and write L = 1
2(˙q2 + kq2) −(λ/4)q4. We all
know what to do in classical mechanics. The potential energy V (q) = −1
2kq2 + (λ/4)q4
[known as the double-well potential (figure IV.1.1)] has two minima at q = ±v, where
v ≡(k/λ)
1
2. At low energies, we choose either one of the two minima and study small
oscillations around that minimum. Committing to one or the other of the two minima
breaks the reflection symmetry q →−q of the system.
In quantum mechanics, however, the particle can tunnel between the two minima, the
tunneling barrier being V (0) −V (±v). The probability of being in one or the other of
the two minima must be equal, thus respecting the reflection symmetry q →−q of the
Hamiltonian. In particular, the ground state wave function ψ(q) = ψ(−q) is even.
Let us try to extend the same reasoning to quantum field theory. For a generic scalar
field Lagrangian L = 1
2(∂0ϕ)2 −1
2(∂iϕ)2 −V (ϕ) we again have to find the minimum of the
potential energy

dDx[ 1
2(∂iϕ)2 + V (ϕ)], where D is the dimension of space. Clearly, any
spatial variation in ϕ only increases the energy, and so we set ϕ(x) to equal a spacetime
independent quantity ϕ and look for the minimum of V (ϕ). In particular, for the example
in (2), we have
V (ϕ) = −1
2μ2⃗ϕ2 + λ
4 (⃗ϕ2)2
(3)
As we will see, the N = 1 case is dramatically different from the N ≥2 cases.

IV.1. Symmetry Breaking | 225
Difference between quantum mechanics and quantum field theory
Study the N = 1 case first. The potential V (ϕ) looks exactly the same as the potential in
figure IV.1.1 with the horizontal axis relabeled as ϕ. There are two minima at ϕ = ±v =
±(μ2/λ)
1
2 .
But some thought reveals a crucial difference between quantum field theory and quan-
tum mechanics. The tunneling barrier is now [V (0) −V (±v)]

dDx (where D denotes
the dimension of space) and hence infinite (or more precisely, extensive with the volume of
the system)! Tunneling is shut down, and the ground state wave function is concentrated
around either +v or −v. We have to commit to one or the other of the two possibilities
for the ground state and build perturbation theory around it. It does not matter which
one we choose: The physics is equivalent. But by making a choice, we break the reflection
symmetry ϕ →−ϕ of the Lagrangian.
The reflection symmetry is broken spontaneously! We did not put symmetry breaking
terms into the Lagrangian by hand but yet the reflection symmetry is broken.1
Let’s choose the ground state at +v and write ϕ = v + ϕ′. Expanding in ϕ′ we find after
a bit of arithmetic that
L = μ4
4λ + 1
2(∂ϕ′)2 −μ2ϕ′2 −O(ϕ′3)
(4)
The physical particle created by the shifted field ϕ′ has mass
√
2μ. The physical mass
squared has to come out positive since, after all, it is just −V ′′(ϕ)|ϕ=v, as you can see after
a moment’s thought.
Similarly, you would recognize that the first term in (4) is just −V (ϕ)|ϕ=v. If we are only
interested in the scattering of the mesons associated with ϕ′ this term does not enter at all.
Indeed, we are always free to add an arbitrary constant to L to begin with. We had quite
arbitrarily set V (ϕ = 0) equal to 0. The same situation appears in quantum mechanics: In
the discussion of the harmonic oscillator the zero point energy 1
2ℏω is not observable; only
transitions between energy levels are physical. We will return to this point in chapter VIII.2.
Yet another way of looking at (2) is that quantum field theory amounts to doing the
Euclidean functional integral
Z =

Dϕe−
ddx{ 1
2 [(∂ϕ)2−μ2ϕ2]+ λ
4 (ϕ2)2}
and perturbation theory just corresponds to studying the small oscillations around a
minimum of the Euclidean action. Normally, with μ2 positive, we expand around the
minimum ϕ = 0. With μ2 negative, ϕ = 0 is a local maximum and not a minimum.
In quantum field theory what is called the ground state is also known as the vacuum,
since it is literally the state in which the field is “at rest,” with no particles present. Here we
1 An insignificant technical aside for the nitpickers: Strictly speaking, in field theory the ground state wave
function should be called a wave functional, since [ϕ(⃗x)] is a functional of the function ϕ(⃗x).

226 | IV. Symmetry and Symmetry Breaking
have two physically equivalent vacua from which we are to choose one. The value assumed
by ϕ in the ground state, either v or −v in our example, is known as the vacuum expectation
value of ϕ. The field ϕ is said to have acquired a vacuum expectation value.
Continuous symmetry
Let us now turn to (2) with N ≥2. The potential (3) is shown in figure IV.1.2 for N = 2. The
shape of the potential has been variously compared to the bottom of a punted wine bottle
or a Mexican hat. The potential is minimized at ⃗ϕ2 = μ2/λ. Something interesting is going
on: We have an infinite number of vacua characterized by the direction of ⃗ϕ in that vacuum.
Because of the O(2) symmetry of the Lagrangian they are all physically equivalent. The
result had better not depend on our choice. So let us choose ⃗ϕ to point in the 1 direction,
that is, ϕ1 = v ≡+

μ2/λ and ϕ2 = 0.
Now consider fluctuations around this field configuration, in other words, write ϕ1 =
v + ϕ′
1 and ϕ2 = ϕ′
2, plug into (2) for N = 2, and expand L out. I invite you to do the
arithmetic. You should find (after dropping the primes on the fields; why clutter the
notation, right?)
L =μ4
4λ + 1
2

(∂ϕ1)2 + (∂ϕ2)2
−μ2ϕ2
1 + O(ϕ3)
(5)
The constant term is exactly as in (4), and just like the field ϕ′ in (4), the field ϕ1 has mass
√
2μ. But now note the remarkable feature of (5): the absence of a ϕ2
2 term. The field ϕ2 is
massless!
Emergence of massless boson
That ϕ2 comes out massless is not an accident. I will now explain that the masslessness is
a general and exact phenomenon.
Referring back to figure IV.1.2 we can easily understand the particle spectrum. Excitation
in the ϕ1 field corresponds to fluctuation in the radial direction, “climbing the wall” so to
speak, while excitation in the ϕ2 field corresponds to fluctuation in the angular direction,
“rolling along the gutter” so to speak. It costs no energy for a marble to roll along the
minima of the potential energy, going from one minimum to another. Another way of
saying this is to picture a long wavelength excitation of the form ϕ2 = a sin(ωt −⃗k⃗x) with
a small. In a region of length scale small compared to |⃗k|−1, the field ϕ2 is essentially
constant and thus the field ⃗ϕ is just rotated slightly away from the 1 direction, which by
the O(2) symmetry is equivalent to the vacuum. It is only when we look at regions of
length scale large compared to |⃗k|−1 that we realize that the excitation costs energy. Thus,
as |⃗k| →0, we expect the energy of the excitation to vanish.
We now understand the crucial difference between the N = 1 and the N = 2 cases: In
the former we have a reflection symmetry, which is discrete, while in the latter we have an
O(2) symmetry, which is continuous.

IV.1. Symmetry Breaking | 227
Figure IV.1.2
We have worked out the N = 2 case in detail. You should now be able to generalize our
discussion to arbitrary N ≥2 (see exercise IV.1.1).
Meanwhile, it is worth looking at N = 2 from another point of view. Many field theories
can be written in more than one form and it is important to know them under different
guises. Construct the complex field ϕ = (1/
√
2)(ϕ1 + iϕ2); we have ϕ†ϕ = 1
2(ϕ2
1 + ϕ2
2) and
so can write (2) as
L = ∂ϕ†∂ϕ + μ2ϕ†ϕ −λ(ϕ
†ϕ)2
(6)
which is manifestly invariant under the U(1) transformation ϕ →eiαϕ (recall chapter I.10).
You may recognize that this amounts to saying that the groups O(2) and U(1) are locally
isomorphic. Just as we can write a vector in Cartesian or polar coordinates we are free
to parametrize the field by ϕ(x) = ρ(x)eiθ(x) (as in chapter III.5) so that ∂μϕ = (∂μρ +
iρ∂μθ)eiθ. We obtain L = ρ2(∂θ)2 + (∂ρ)2 + μ2ρ2 −λρ4. Spontaneous symmetry breaking
means setting ρ = v + χ with v = +

μ2/2λ, whereupon
L = v2(∂θ)2 +
⎡
⎣(∂χ)2 −2μ2χ2 −4

μ2λ
2 χ3 −λχ4
⎤
⎦+
⎛
⎝

2μ2
λ χ + χ2
⎞
⎠(∂θ)2
(7)
We recognize the phase θ(x) as the massless field. We have arranged the terms in the
Lagrangian in three groups: the kinetic energy of the massless field θ, the kinetic and
potential energy of the massive field χ, and the interaction between θ and χ. (The additive
constant in (5) has been dropped to minimize clutter.)

228 | IV. Symmetry and Symmetry Breaking
Goldstone’s theorem
We will now prove Goldstone’s theorem, which states that whenever a continuous sym-
metry is spontaneously broken, massless fields, known as Nambu2-Goldstone bosons,
emerge.
Recall that associated with every continuous symmetry is a conserved charge Q. That Q
generates a symmetry is stated as
[H , Q] = 0
(8)
Let the vacuum (or ground state in quantum mechanics) be denoted by |0⟩. By adding
an appropriate constant to the Hamiltonian H →H + c we can always write H |0⟩= 0.
Normally, the vacuum is invariant under the symmetry transformation, eiθQ |0⟩= |0⟩, or
in other words Q|0⟩= 0.
But suppose the symmetry is spontaneously broken, so that the vacuum is not invariant
under the symmetry transformation; in other words, Q|0⟩̸= 0. Consider the state Q|0⟩.
What is its energy? Well,
HQ|0⟩= [H , Q]|0⟩= 0
(9)
[The first equality follows from H |0⟩= 0 and the second from (8).] Thus, we have found
another state Q|0⟩with the same energy as |0⟩.
Note that the proof makes no reference to either relativity or fields. You can also see that
it merely formalizes the picture of the marble rolling along the gutter.
In quantum field theory, we have local currents, and so
Q =

dDxJ 0(⃗x, t)
where D denotes the dimension of space and conservation of Q says that the integral can
be evaluated at any time. Consider the state
|s⟩=

dDxe−i⃗k⃗xJ 0(⃗x, t)|0⟩
which has3 spatial momentum ⃗k. As ⃗k goes to zero it goes over to Q|0⟩, which as we learned
in (9) has zero energy. Thus, as the momentum of the state |s⟩goes to zero, its energy goes
to zero. In a relativistic theory, this means precisely that |s⟩describes a massless particle.
2 Y. Nambu, quite deservedly, received the 2008 physics Nobel Prize for his profound contribution to our
understanding of spontaneous symmetry breaking.
3 Acting on it with P i (exercise I.11.3) and using P i |0⟩= 0, we have
P i |s⟩=

dDxe−i⃗k⃗x[P i, J 0(⃗x, t)]|0⟩= −i

dDe−i⃗k.⃗x∂iJ 0(⃗x, t)|0⟩= ki |s⟩
upon integrating by parts.

IV.1. Symmetry Breaking | 229
The proof makes clear that the theorem practically exudes generality: It applies to any
spontaneously broken continuous symmetry.
Counting Nambu-Goldstone bosons
From our proof, we see that the number of Nambu-Goldstone bosons is clearly equal to
the number of conserved charges that do not leave the vacuum invariant, that is, do not
annihilate |0⟩. For each such charge Qα, we can construct a zero-energy state Qα |0⟩.
In our example, we have only one current Jμ = i(ϕ1∂μϕ2 −ϕ2∂μϕ1) and hence one
Nambu-Goldstone boson. In general, if the Lagrangian is left invariant by a symmetry
group G with n(G) generators, but the vacuum is left invariant by only a subgroup H of G
with n(H) generators, then there are n(G)−n(H) Nambu-Goldstone bosons. If you want
to show off your mastery of mathematical jargon you can say that the Nambu-Goldstone
bosons live in the coset space G/H .
Ferromagnet and spin wave
The generality of the proof suggests that the usefulness of Goldstone’s theorem is not
restricted to particle physics. In fact, it originated in condensed matter physics, the classic
example there being the ferromagnet. The Hamiltonian, being composed of just the
interaction of nonrelativistic electrons with the ions in the solid, is of course invariant
under the rotation group SO(3), but the magnetization ⃗
M picks out a direction, and
the ferromagnet is left invariant only under the subgroup SO(2) consisting of rotations
about the axis defined by ⃗
M. The Nambu-Goldstone theorem is easy to visualize physically.
Consider a “spin wave” in which the local magnetization ⃗
M(⃗x) varies slowly from point
to point. A physicist living in a region small compared to the wavelength does not even
realize that he or she is no longer in the “vacuum.” Thus, the frequency of the wave must
go to zero as the wavelength goes to infinity. This is of course exactly the same heuristic
argument given earlier. Note that quantum mechanics is needed only to translate the wave
vector ⃗k into momentum and the frequency ω into energy. I will come back to magnets
and spin wave in chapters V.3 and VI.5.
Quantum fluctuations and the dimension of spacetime
Our discussion of spontaneous symmetry breaking is essentially classical. What happens
when quantum fluctuations are included? I will address this question in detail in chap-
ter IV.3, but for now let us go back to (5). In the ground state, ϕ1 = v and ϕ2 = 0. Recall
that in the mattress model of a scalar field theory the mass term comes from the springs
holding the mattress to its equilibrium position. The term −μ2ϕ′2
1 (note the prime) in (5)

230 | IV. Symmetry and Symmetry Breaking
tells us that it costs action for ϕ′
1 to wander away from its ground state value ϕ′
1 = 0. But
now we are worried: ϕ2 is massless. Can it wander away from its ground state value? To
answer this question let us calculate the mean square fluctuation
⟨(ϕ2(0))2⟩= 1
Z

DϕeiS(ϕ)[ϕ2(0)]2
= lim
x→0
1
Z

DϕeiS(ϕ)ϕ2(x)ϕ2(0)
= lim
x→0

ddk
(2π)d
eikx
k2
(10)
(We recognized the functional integral that defines the propagator; recall chapter I.7.)
The upper limit of the integral in (10) is cut off at some  (which would correspond to
the inverse of the lattice spacing when applying these ideas to a ferromagnet) and so as
explained in chapter III.1 (and as you will see in chapter VIII.3) we are not particularly
worriedabouttheultravioletdivergenceforlarge k.Butwedohavetoworryaboutapossible
infrared divergence for small k. (Note that for a massive field 1/k2 in (10) would have been
replaced by 1/(k2 + μ2) and there would be no infrared divergence.)
We see that there is no infrared divergence for d > 2. Our picture of spontaneously
breaking a continuous symmetry is valid in our (3 + 1)-dimensional world.
However, for d ≤2 the mean square fluctuation of ϕ2 comes out infinite, so our naive
picture is totally off. We have arrived at the Coleman-Mermin-Wagner theorem (proved
independently by a particle theorist and two condensed matter theorists), which states
that spontaneous breaking of a continuous symmetry is impossible for d = 2. Note that
while our discussion is given for O(2) symmetry the conclusion applies to any continuous
symmetry since the argument depends only on the presence of Nambu-Goldstone fields.
In our examples, symmetry is spontaneously broken by a scalar field ϕ, but nothing says
that the field ϕ must be elementary. In many condensed matter systems, superconductors,
for example, symmetries are spontaneously broken, but we know that the system consists
of electrons and atomic nuclei. The field ϕ is generated dynamically, for example as a bound
state of two electrons in superconductors. More on this in chapter V.4. The spontaneous
breaking of a symmetry by a dynamically generated field is sometimes referred to as
dynamical symmetry breaking.4
Exercises
IV.1.1
Show explicitly that there are N −1 Nambu-Goldstone bosons in the G = O(N) example (2).
IV.1.2
Construct the analog of (2) with N complex scalar fields and invariant under SU(N). Count the number
of Nambu-Goldstone bosons when one of the scalar fields acquires a vacuum expectation value.
4 This chapter is dedicated to the memory of the late Jorge Swieca.

IV.2
The Pion as a Nambu-Goldstone Boson
Crisis for field theory
After the spectacular triumphs of quantum field theory in the electromagnetic interaction,
physicists in the 1950s and 1960s were naturally eager to apply it to the strong and weak
interactions. As we have already seen, field theory when applied to the weak interaction
appeared not to be renormalizable. As for the strong interaction, field theory appeared to-
tally untenable for other reasons. For one thing, as the number of experimentally observed
hadrons (namely strongly interacting particles) proliferated, it became clear that were we
to associate a field with each hadron the resulting field theory would be quite a mess, with
numerous arbitrary coupling constants. But even if we were to restrict ourselves to nucle-
ons and pions, the known coupling constant of the interaction between pions and nucleons
is a large number. (Hence the term strong interaction in the first place!) The perturbative
approach that worked so spectacularly well in quantum electrodynamics was doomed to
failure.
Many eminent physicists at the time advocated abandoning quantum field theory al-
together, and at certain graduate schools, quantum field theory was even dropped from
the curriculum. It was not until the early 1970s that quantum field theory made a tri-
umphant comeback. A field theory for the strong interaction was formulated, not in terms
of hadrons, but in terms of quarks and gluons. I will get to that in chapter VII.3.
Pion weak decay
To understand the crisis facing field theory, let us go back in time and imagine what a field
theorist might be trying to do in the late 1950s. Since this is not a book on particle physics,
I will merely sketch the relevant facts. You are urged to consult one of the texts on the
subject.1 By that time, many semileptonic decays such as n →p + e−+ ν, π−→e−+ ν,
1 See, e.g., E. Commins and P. H. Bucksbaum, Weak Interactions of Leptons and Quarks.

232 | IV. Symmetry and Symmetry Breaking
and π−→π0 + e−+ ν had been measured. Neutron β decay n →p + e−+ ν was of
course the process for which Fermi invented his theory, which by that time had assumed
the form L = G[eγ μ(1 −γ5)ν][pγμ(1 −γ5)n], where n is a neutron field annihilating a
neutron, p a proton field annihilating a proton, ν a neutrino field annihilating a neutrino
(or creating an antineutrino as in β decay), and e an electron field annihilating an electron.
It became clear that to write down a field for each hadron and a Lagrangian for each
decay process, as theorists were in fact doing for a while, was a losing battle. Instead, we
should write
L = G[eγ μ(1 −γ5)ν](Jμ −J5μ)
(1)
with Jμ and J5μ two currents transforming as a Lorentz vector, and axial vector respectively.
We think of Jμ and J5μ as quantum operators in a canonical formulation of field theory.
Our task would then be to calculate the matrix elements between hadron states, ⟨p|(Jμ −
J5μ)|n⟩, ⟨0|(Jμ −J5μ)|π−⟩, ⟨π0|(Jμ −J5μ)|π−⟩, and so on, corresponding to the three
decay processes I listed above. (I should make clear that although I am talking about weak
decays, the calculation of these matrix elements is a problem in the strong interaction. In
other words, in understanding these decays, we have to treat the strong interaction to all
orders in the strong coupling, but it suffices to treat the weak interaction to lowest order in
the weak coupling G.) Actually, there is a precedent for the attitude we are adopting here.
To account for nuclear β decay (Z, A) →(Z + 1, A) + e−+ ν, Fermi certainly did not
write a separate Lagrangian for each nucleus. Rather, it was the task of the nuclear theorist
to calculate the matrix element ⟨Z + 1, A|[pγμ(1 −γ5)n]|Z, A⟩. Similarly, it is the task of
the strong interaction theorist to calculate matrix elements such as ⟨p|(Jμ −J5μ)|n⟩.
For the story I am telling, let me focus on trying to calculate the matrix element of
the axial vector current J μ
5 between a neutron and a proton. Here we make a trivial
change in notation: We no longer indicate that we have a neutron in the initial state and a
proton in the final state, but instead we specify the momentum p of the neutron and the
momentum p′ of the proton. Incidentally, in (1) the fields and the currents are of course
all functions of the spacetime coordinates x. Thus, we want to calculate ⟨p′|J μ
5 (x)|p⟩,
but by translation invariance this is equal to ⟨p′|J μ
5 (0)|p⟩e−i(p′−p).x. Henceforth, we
simply calculate ⟨p′|J μ
5 (0)|p⟩and suppress the 0. Note that spin labels have already been
suppressed.
Lorentz invariance and parity can take us some distance: They imply that2
⟨p′|J μ
5 |p⟩= ¯u(p′)[γ μγ 5F(q2) + qμγ 5G(q2)]u(p)
(2)
with q ≡p′ −p [compare with (III.6.7)]. But Lorentz invariance and parity can only take
us so far: We know nothing about the “form factors” F(q2) and G(q2).
2 Another possible term of the form (p′ + p)μγ 5 can be shown to vanish by charge conjugation and isospin
symmetries.

IV.2. Pion as Nambu-Goldstone Boson | 233
(a)
(b)
Figure IV.2.1
Similarly, for the matrix element ⟨0|J μ
5 |π−⟩Lorentz invariance tells us that
⟨0|J μ
5 |k⟩= f kμ
(3)
I have again labeled the initial state by the momentum k of the pion. The right-hand side
of (3) has to be a vector but since k is the only vector available it has to be proportional
to k. Just like F(q2) and G(q2), the constant f is a strong interaction quantity that we
don’t know how to calculate. On the other hand, F(q2), G(q2), and f can all be measured
experimentally. For instance, the rate for the decay π−→e−+ ν clearly depends on f 2.
Too many diagrams
Let us look over the shoulder of a field theorist trying to calculate ⟨p′|J μ
5 |p⟩and ⟨0|J μ
5 |k⟩
in (2) in the late 1950s. He would draw Feynman diagrams such as the ones in figures IV.2.1
and IV.2.2 and soon realize that it would be hopeless. Because of the strong coupling, he
would have to calculate an infinite number of diagrams, even if the strong interaction were
described by a field theory, a notion already rejected by many luminaries of the time.
Figure IV.2.2

234 | IV. Symmetry and Symmetry Breaking
In telling the story of the breakthrough I am not going to follow the absolutely fascinating
history of the subject, full of total confusion and blind alleys. Instead, with the benefit of
hindsight, I am going to tell the story using what I regard as the best pedagogical approach.
The pion is very light
The breakthrough originated in the observation that the mass of the π−at 139 Mev was
considerably less than the mass of the proton at 938 Mev. For a long time this was simply
taken as a fact not in any particular need of an explanation. But eventually some theorists
wondered why one hadron should be so much lighter than another.
Finally, some theorists took the bold step of imagining an “ideal world” in which the
π−is massless. The idea was that this ideal world would be a good approximation of our
world, to an accuracy of about 15% (∼139/938).
Do you remember one circumstance in which a massless spinless particle would emerge
naturally? Yes, spontaneous symmetry breaking! In one of the blinding insights that have
characterized the history of particle physics, some theorists proposed that the π mesons
are the Nambu-Goldstone bosons of some spontaneous broken symmetry.
Indeed, let’s multiply (3) by kμ :
kμ⟨0|J μ
5 |k⟩= f k2 = f m2
π
(4)
which is equal to zero in the ideal world. Recall from our earlier discussion on translation
invariance that
⟨0|J μ
5 (x)|k⟩= ⟨0|J μ
5 (0)|k⟩e−ik.x
and hence
⟨0|∂μJ μ
5 (x)|k⟩= −ikμ⟨0|J μ
5 (0)|k⟩e−ik.x
Thus, if the axial current is conserved, ∂μJ μ
5 (x) = 0, in the ideal world, kμ⟨0|J μ
5 |k⟩= 0
and (4) would indeed imply m2
π = 0.
The ideal world we are discussing enjoys a symmetry known as the chiral symmetry
of the strong interaction. The symmetry is spontaneously broken in the ground state we
inhabit, with the π meson as the Nambu-Goldstone boson. The Noether current associated
with this symmetry is the conserved J μ
5 .
In fact, you should recognize that the manipulation here is closely related to the proof
of the Nambu-Goldstone theorem given in chapter IV.1.
Goldberger-Treiman relation
Now comes the punchline. Multiply (2) by (p′ −p)μ. By the same translation invariance
argument we just used,
(p′ −p)μ⟨p′|J μ
5 (0)|p⟩= i⟨p′|∂μJ μ
5 (x)|p⟩ei(p′−p).x

IV.2. Pion as Nambu-Goldstone Boson | 235
and hence vanishes if ∂μJ μ
5 = 0. On the other hand, multiplying the right-hand side of
(2) by (p′ −p)μ we obtain ¯u(p′)[(̸p′ −̸p)γ 5F(q2) + q2γ 5G(q2)]u(p). Using the Dirac
equation (do it!) we conclude that
0 = 2mNF(q2) + q2G(q2)
(5)
with mN the nucleon mass.
The form factors F(q2) and G(q2) are each determined by an infinite number of
Feynman diagrams we have no hope of calculating, but yet we have managed to relate
them! This represents a common strategy in many areas of physics: When faced with
various quantities we don’t know how to calculate, we can nevertheless try to relate them.
We can go farther by letting q →0 in (5). Referring to (2) we see that F(0) is measured
experimentally in n →p + e−+ ν (the momentum transfer is negligible on the scale of
the strong interaction). But oops, we seem to have a problem: We predict the nucleon mass
mN = 0!
In fact, we are saved by examining figure IV.2.1b: There are an infinite number of
diagrams exhibiting a pole due to none other than the massless π meson, which you can
see gives
f qμ 1
q2gπNN ¯u(p′)γ 5u(p)
(6)
When the π propagator joins onto the nucleon line, an infinite number of diagrams
summed together gives the experimentally measured pion-nucleon coupling constant
gπNN. Thus, referring to (2), we see that for q ∼0 the form factor G(q2) ∼f (1/q2)gπNN.
Plugging into (5), we obtain the celebrated Goldberger-Treiman relation
2mNF(0) + fgπNN = 0
(7)
relatingfourexperimentallymeasuredquantities.Asmightbeexpected, itholdswithabout
a 15% error, consistent with our not living in a world with an exactly massless π meson.
Toward a theory of the strong interaction
The art of relating infinite sets of Feynman diagrams without calculating them, and it is an
art form involving a great deal of cleverness, was developed into a subject called dispersion
relations and S-matrix theory, which we mentioned briefly in chapter III.8. Our present
understanding of the strong interaction was built on this foundation. You could see from
this example that an important component of dispersion relations was the study of the
analyticity properties of Feynman diagrams as described in chapter III.8. The essence of
the Goldberger-Treiman argument is separating the infinite number of diagrams into those
with a pole in the complex q2-plane and those without a pole (but with a cut.)
The discovery that the strong interaction contains a spontaneously broken symmetry
provided a crucial clue to the underlying theory of the strong interaction and ultimately
led to the concepts of quarks and gluons.

236 | IV. Symmetry and Symmetry Breaking
A note for the historian of science: Whether theoretical physicists regard a quantity as
small or large depends (obviously) on the cultural and mental framework they grew up
in. Treiman once told me that the notion of setting 138 Mev to zero, when the energy
released per nucleon in nuclear fission is of order 10 Mev, struck the generation that grew
up with the atomic bomb (as Treiman did—he was with the armed forces in the Pacific) as
surely the height of absurdity. Now of course a new generation of young string theorists
is perfectly comfortable in regarding anything less than the Planck energy 1019 Gev as
essentially zero.

IV.3
Effective Potential
Quantum fluctuations and symmetry breaking
The important phenomenon of spontaneous symmetry breaking was based on minimizing
the classical potential energy V (ϕ) of a quantum field theory. It is natural to wonder how
quantum fluctuations would change this picture.
To motivate the discussion, consider once again (III.3.3)
L = 1
2(∂ϕ)2 −1
2μ2ϕ2 −1
4!λϕ4 + A(∂ϕ)2 + Bϕ2 + Cϕ4
(1)
(Speaking of quantum fluctuations, we have to include counterterms as indicated.) What
have you learned about this theory? For μ2 > 0, the action is extremized at ϕ = 0, and
quantizing the small fluctuations around ϕ = 0 we obtain scalar particles that scatter off
each other. For μ2 < 0, the action is extremized at some ϕmin, and the discrete symmetry
ϕ →−ϕ is spontaneously broken, as you learned in chapter IV.1. What happens when
μ = 0? To break or not to break, that is the question.
A quick guess is that quantum fluctuations would break the symmetry. The μ = 0 theory
is posed on the edge of symmetry breaking, and quantum fluctuations ought to push it
over the brink. Think of a classical pencil perfectly balanced on its tip. Then “switch on”
quantum mechanics.
Wisdom of the son-in-law
Let us follow Schwinger and Jona-Lasinio and develop the formalism that enables us to
answer this question. Consider a scalar field theory defined by
Z = eiW(J) =

Dϕei[S(ϕ)+Jϕ]
(2)
[with the convenient shorthand Jϕ =

d4xJ(x)ϕ(x)]. If we can do the functional integral,
we obtain the generating functional W(J). As explained in chapter I.7, by differentiating

238 | IV. Symmetry and Symmetry Breaking
W with respect to the source J(x) repeatedly, we can obtain any Green’s function and
hence any scattering amplitude we want. In particular,
ϕc(x) ≡
δW
δJ(x) = 1
Z

Dϕei[S(ϕ)+Jϕ]ϕ(x)
(3)
The subscript c is used traditionally to remind us (see appendix 2 in chapter I.8) that in a
canonical formalism ϕc(x) is the expectation value ⟨0| ˆϕ |0⟩of the quantum operator ˆϕ. It
is certainly not to be confused with the integration dummy variable ϕ in (3). The relation
(3) determines ϕc(x) as a functional of J.
Given a functional W of J we can perform a Legendre transform to obtain a functional
 of ϕc. Legendre transform is just the fancy term for the simple relation
(ϕc) = W(J) −

d4xJ(x)ϕc(x)
(4)
The relation is simple, but be careful about what it says: It defines a functional of ϕc(x)
through the implicit dependence of J on ϕc. On the right-hand side of (4) J is to be
eliminated in favor of ϕc by solving (3). We expand the functional (ϕc) in the form
(ϕc) =

d4x[−Veff(ϕc) + Z(ϕc)(∂ϕc)2 + . . .]
(5)
where (. . .) indicates terms with higher and higher powers of ∂. We will soon see the
wisdom of the notation Veff(ϕc).
The point of the Legendre transform is that the functional derivative of  is nice and
simple:
δ(ϕc)
δϕc(y) =

d4x δJ(x)
δϕc(y)
δW(J)
δJ(x) −

d4x δJ(x)
δϕc(y)ϕc(x) −J(y)
= −J(y)
(6)
a relation we can think of as the “dual” of δW(J)/δJ(x) = ϕc(x).
If you vaguely feel that you have seen this sort of manipulation before in your physics
eduction, you are quite right! It was in a course on thermodynamics, where you learned
about the Legendre transform relating the free energy to the energy: F = E −T S with
F a function of the temperature T and E a function of the entropy S. Thus J and
ϕ are “conjugate” pairs just like T and S (or even more clearly magnetic field H and
magnetization M). Convince yourself that this is far more than a mere coincidence.
For J and ϕc independent of x we see from (5) that the condition (6) reduces to
V ′
eff(ϕc) = J
(7)
This relation makes clear what the effective potential Veff(ϕc) is good for. Let’s ask what
happens when there is no external source J . The answer is immediate: (7) tells us that
V ′
eff(ϕc) = 0,
(8)

IV.3. Effective Potential | 239
In other words, the vacuum expectation value of ˆϕ in the absence of an external source is
determined by minimizing Veff(ϕc).
First order in quantum fluctuations
All of these formal manipulations are not worth much if we cannot evaluate W(J). In
fact, in most cases we can only evaluate eiW(J) =

Dϕei[S(ϕ)+Jϕ] in the steepest descent
approximation (see chapter I.2). Let us turn the crank and find the steepest descent “point”
ϕs(x), namely the solution of (henceforth I will drop the subscript c as there is little risk
of confusion)
δ[S(ϕ) +

d4yJ(y)ϕ(y)]
δϕ(x)

ϕs
= 0
(9)
or more explicitly,
∂2ϕs(x) + V ′[ϕs(x)] = J(x)
(10)
Write the dummy integration variable in (2) as ϕ = ϕs + ϕ and expand to quadratic order
in ϕ to obtain
Z = e(i/ℏ)W(J) =

Dϕe(i/ℏ)[S(ϕ)+Jϕ]
≃e(i/ℏ)[S(ϕs)+Jϕs]

Dϕe(i/ℏ) 
d4x 1
2 [(∂
ϕ)2−V ′′(ϕs)
ϕ2]
= e(i/ℏ)[S(ϕs)+Jϕs]−1
2 tr log[∂2+V ′′(ϕs)]
(11)
We have used (II.5.2) to represent the determinant we get upon integrating over ϕ. Note
that I have put back Planck’s constant ℏ. Here ϕs, as a solution of (10), is to be regarded as
a function of J .
Now that we have determined
W(J) = [S(ϕs) + Jϕs] + iℏ
2 tr log[∂2 + V ′′(ϕs)] + O(ℏ2)
it is straightforward to Legendre transform. I will go painfully slowly here:
ϕ = δW
δJ = δ[S(ϕs) + Jϕs]
δϕs
δϕs
δJ + ϕs + O(ℏ) = ϕs + O(ℏ)
To leading order in ℏ, ϕ (namely the object formerly known as ϕc) is equal to ϕs. Thus,
from (4) we obtain
(ϕ) = S(ϕ) + iℏ
2 tr log[∂2 + V ′′(ϕ)] + O(ℏ2)
(12)
Nice though this formula looks, in practice it is impossible to evaluate the trace for
arbitrary ϕ(x) : We have to find all the eigenvalues of the operator ∂2 + V ′′(ϕ), take their
log, and sum. Our task simplifies drastically if we are content with studying (ϕ) for

240 | IV. Symmetry and Symmetry Breaking
ϕ independent of x, in which case V ′′(ϕ) is a constant and the operator ∂2 + V ′′(ϕ) is
translation invariant and easily treated in momentum space:
tr log[∂2 + V ′′(ϕ)] =

d4x⟨x| log[∂2 + V ′′(ϕ)]|x⟩
=

d4x

d4k
(2π)4 ⟨x|k⟩⟨k| log[∂2 + V ′′(ϕ)]|k⟩⟨k|x⟩
=

d4x

d4k
(2π)4 log[−k2 + V ′′(ϕ)]
(13)
Referring to (5), we obtain
Veff(ϕ) = V (ϕ) −iℏ
2

d4k
(2π)4 log
k2 −V ′′(ϕ)
k2

+ O(ℏ2)
(14)
known as the Coleman-Weinberg effective potential. What we computed is the order ℏ
correction to the classical potential V (ϕ). Note that we have added a ϕ independent constant
to make the argument of the logarithm dimensionless.
We can give a nice physical interpretation of (14). Let the universe be suffused with
the scalar field ϕ(x) taking on the value ϕ, a background field so to speak. For V (ϕ) =
1
2μ2ϕ2 + (1/4!)λϕ4, we have V ′′(ϕ) = μ2 + 1
2λϕ2 ≡μ(ϕ)2, which, as the notation μ(ϕ)2
suggests, we recognize as the ϕ-dependent effective mass squared of a scalar particle
propagating in the background field ϕ. The mass squared μ2 in the Lagrangian is corrected
by a term 1
2λϕ2 due to the interaction of the particle with the background field ϕ. Now we
see clearly what (14) tells us: The first term V (ϕ) is the classical energy density contained
in the background ϕ, while the second term is the vacuum energy density of a scalar field
with mass squared equal to V ′′(ϕ) [see (II.5.3) and exercise IV.3.4].
Your renormalization theory at work
The integral in (14) is quadratically divergent, or more correctly, quadratically dependent
on the cutoff. But no sweat, we were instructed to introduce three counterterms (of which
only two are relevant here since ϕ is independent of x). Thus, we actually have
Veff(ϕ) = V (ϕ) + ℏ
2

d4kE
(2π)4 log
	
k2
E + V ′′(ϕ)
k2
E

+ Bϕ2 + Cϕ4 + O(ℏ2)
(15)
where we have Wick rotated to a Euclidean integral (see appendix D). Using (D.9) and
integrating up to k2
E = 2, we obtain (suppressing ℏ)
Veff(ϕ) = V (ϕ) + 2
32π2V ′′(ϕ) −[V ′′(ϕ)]2
64π2
log e
1
22
V ′′(ϕ) + Bϕ2 + Cϕ4
(16)
As expected, since the integrand in (15) goes as 1/k2
E for large k2
E the integral depends
quadratically and logarithmically on the cutoff 2.

IV.3. Effective Potential | 241
Watch renormalization theory at work! Since V is a quartic polynomial in ϕ, V ′′(ϕ) is a
quadratic polynomial and [V ′′(ϕ)]2 a quartic polynomial. Thus, we have just enough coun-
terterms Bϕ2 + Cϕ4 to absorb the cutoff dependence. This is a particularly transparent
example of how the method of adding counterterms works.
To see how bad things can happen in a nonrenormalizable theory, suppose in contrast
that V is a polynomial of degree 6 in ϕ. Then we are allowed to have three counterterms
Bϕ2 + Cϕ4 + Dϕ6, but that is not enough since [V ′′(ϕ)]2 is now a polynomial of degree
8. This means that we should have started out with V a polynomial of degree 8, but then
[V ′′(ϕ)]2 would be a polynomial of degree 12. Clearly, the process escalates into an infinite-
degree polynomial. We see the hallmark of a nonrenormalizable theory: its insatiable
appetite for counterterms.
Imposing renormalization conditions
Waking up from the nightmare of an infinite number of counterterms chasing us, let us
go back to the sweetly renormalizable ϕ4 theory. In chapter III.3 we fix the counterterms
by imposing conditions on various scattering amplitudes. Here we would have to fix the
coefficients B and C by imposing two conditions on Veff(ϕ) at appropriate values of ϕ. We
are working in field space, so to speak, rather than momentum space, but the conceptual
framework is the same.
We could proceed with the general quartic polynomial V (ϕ), but instead let us try to
answer the motivating question of this chapter: What happens when μ = 0, that is, when
V (ϕ) = (1/4!)λϕ4? The arithmetic is also simpler.
Evaluating (16) we get
Veff(ϕ) = ( 2
64π2λ + B)ϕ2 + ( 1
4!λ +
λ2
(16π)2 log ϕ2
2 + C)ϕ4 + O(λ3)
(after absorbing some ϕ-independent constants into C). We see explicitly that the 
dependence can be absorbed into B and C.
We started out with a purely quartic V (ϕ). Quantum fluctuations generate a quadrati-
cally divergent ϕ2 term that we can cancel with the B counterterm. What does μ = 0 mean?
It means that (d2V /dϕ2)|ϕ=0 vanishes. To say that we have a μ = 0 theory means that we
have to maintain a vanishing renormalized mass squared, defined here as the coefficient
of ϕ2. Thus, we impose our first condition
d2Veff
dϕ2

ϕ=0
= 0
(17)
This is a somewhat long-winded way of saying that we want B = −(2/64π2)λ to this
order.
Similarly, we might think that the second condition would be to set (d4Veff/dϕ4)|ϕ=0
equal to some coupling, but differentiating the ϕ4 log ϕ term in Veff four times we are
going to get a term like log ϕ, which is not defined at ϕ = 0. We are forced to impose our

242 | IV. Symmetry and Symmetry Breaking
condition on d4Veff/dϕ4 not at ϕ = 0 but at ϕ equal to some arbitrarily chosen mass M.
(Recall that ϕ has the dimension of mass.) Thus, the second condition reads
d4Veff
dϕ4

ϕ=M
= λ(M)
(18)
where λ(M) is a coupling manifestly dependent on M.
Plugging
Veff(ϕ) = ( 1
4!λ +
λ2
(16π)2 log ϕ2
2 + C)ϕ4 + O(λ3)
into (18) we see that λ(M) is equal to λ plus O(λ2) corrections, among which is a term like
λ2 log M. We can get a clean relation by differentiating λ(M) :
M dλ(M)
dM
=
3
16π2λ2 + O(λ3)
=
3
16π2λ(M)2 + O[λ(M)3]
(19)
where the second equality is correct to the order indicated. This interesting relation tells us
how the coupling λ(M) depends on the mass scale M at which it is defined. Recall exercise
III.1.3. We will come back to this relation in chapter VI.7 on the renormalization group.
Meanwhile, let us press on. Using (18) to determine C and plugging it into Veff we
obtain
Veff(ϕ) = 1
4!λ(M)ϕ4 + λ(M)2
(16π)2ϕ4

log ϕ2
M2 −25
6

+ O[λ(M)3]
(20)
You are no longer surprised, I suppose, that C and the cutoff  have both disappeared.
That’s a renormalizable theory for you!
The fact that Veff does not depend on the arbitrarily chosen M, namely, M(dVeff/dM) =
0, reproduces (19) to the order indicated.
Breaking by quantum fluctuations
Now we can answer the motivating question: To break or not to break?
Quantum fluctuations generate a correction to the potential of the form +ϕ4 log ϕ2,
but log ϕ2 is whopping big and negative for small ϕ! The O(ℏ) correction overwhelms
the classical O(ℏ0) potential +ϕ4 near ϕ = 0. Quantum fluctuations break the discrete
symmetry ϕ →−ϕ.
It is easy enough to determine the minima ±ϕmin of Veff(ϕ) (which you should plot as
a function of ϕ to get a feeling for). But closer inspection shows us that we cannot take the
precise value of ϕmin seriously; Veff has the form λϕ4(1 + λ log ϕ + . . .) suggesting that
the expansion parameter is actually λ log ϕ rather than λ. [Try to convince yourself that
(. . .) starts with (λ log ϕ)2.] The minima ϕmin of Veff clearly occurs when the expansion
parameter is of order unity. In an exercise in chapter IV.7 you will see a clever way of getting
around this problem.

IV.3. Effective Potential | 243
Fermions
In (11) ϕs plays the role of an external field while ϕ corresponds to a quantum field we
integrate over. The role of ϕ can also be played by a fermion field ψ. Consider adding
¯ψ(i̸∂−m −f ϕ)ψ to the Lagrangian. In the path integral
Z =

DϕD ¯ψDψei 
d4x[ 1
2 (∂ϕ)2−V (ϕ)+ ¯ψ(i̸∂−m−f ϕ)ψ]
(21)
we can always choose to integrate over ψ first, obtaining
Z =

Dϕei 
d4x[ 1
2 (∂ϕ)2−V (ϕ)]+tr log(i̸∂−m−f ϕ)
(22)
Repeating the steps in (13) we find that the fermion field contributes
VF(ϕ) = +i

d4p
(2π)4 tr log ̸p −m −f ϕ
̸p
(23)
to Veff(ϕ). (The trace in (23) is taken over the gamma matrices.) Again from chapter II.5,
we see that physically VF(ϕ) represents the vacuum energy of a fermion with the effective
mass m(ϕ) ≡m + f ϕ.
We can massage the trace of the logarithm using tr log M = log det M (II.5.12) and
cyclically permuting factors in a determinant):
tr log(̸p −a) = tr log γ 5(̸p −a)γ 5 = tr log(−̸p −a)
= 1
2 tr(log(̸p −a) + log(̸p + a)) + 1
2 tr log(−1)
= 1
2 tr log(−1)(p2 −a2).
(24)
Hence,
tr log (̸p −a)
̸p
= 1
2 tr log p2 −a2
p2
= 2 log p2 −a2
p2
(25)
and so
VF(ϕ) = 2i

d4p
(2π)4 log p2 −m(ϕ)2
p2
(26)
Contrast the overall sign with the sign in (14): the difference in sign between fermionic
and bosonic loops was explained in chapter II.5.
Thus, in the end the effective potential generated by the quantum fluctuations has a
pleasing interpretation: It is just the energy density due to the fluctuating energy, entirely
analogous to the zero point energy of the harmonic oscillator, of quantum fields living in
the background ϕ (see exercise IV.3.5).
Exercises
IV.3.1
Consider the effective potential in (0 + 1)-dimensional spacetime:
Veff(ϕ) = V (ϕ) + ℏ
2

dkE
(2π) log k2
E + V ′′(ϕ)
k2
E
+ O(ℏ2)

244 | IV. Symmetry and Symmetry Breaking
No counterterm is needed since the integral is perfectly convergent. But (0 + 1)-dimensional field theory
is just quantum mechanics. Evaluate the integral and show that Veff is in complete accord with your
knowledge of quantum mechanics.
IV.3.2
Study Veff in (1 + 1)−dimensional spacetime.
IV.3.3
Consider a massless fermion field ψ coupled to a scalar field ϕ by f ϕ ¯ψψ in (1 + 1)-dimensional
spacetime. Show that
VF = 1
2π (f ϕ)2 log ϕ2
M2
(27)
after a suitable counterterm has been added. This result is important in condensed matter physics, as
we will see in chapter V.5 on the Peierls instability.
IV.3.4
Understand (14) using Feynman diagrams. Show that Veff is generated by an infinite number of di-
agrams. [Hint: Expand the logarithm in (14) as a series in V ′′(ϕ)/k2 and try to associate a Feynman
diagram with each term in the series.]
IV.3.5
Consider the electrodynamics of a complex scalar field
L = −1
4FμνF μν +

(∂μ + ieAμ)ϕ†  
(∂μ −ieAμ)ϕ
!
+ μ2ϕ
†ϕ −λ(ϕ
†ϕ)2
(28)
In a universe suffused with the scalar field ϕ(x) taking on the value ϕ independent of x as in the text,
the Lagrangian will contain a term (e2ϕ†ϕ)AμAμ so that the effective mass squared of the photon field
becomes M(ϕ)2 ≡e2ϕ†ϕ. Show that its contribution to Veff(ϕ) has the form

d4k
(2π)4 log k2 −M(ϕ)2
k2
(29)
Compare with (14) and (26). [Hint: Use the Landau gauge to simplify the calculation.] If you need help,
I strongly urge you to read S. Coleman and E. Weinberg, Phys. Rev. D7: 1883, 1973, a paragon of clarity
in exposition.

IV.4
Magnetic Monopole
Quantum mechanics and magnetic monopoles
Curiously enough, while electric charges are commonplace nobody has ever seen a mag-
netic charge or monopole. Within classical physics we can perfectly well modify one of
Maxwell’s equations to ⃗∇. ⃗B = ρM, with ρM denoting the density of magnetic monopoles.
The only price we have to pay is that the magnetic field ⃗B can no longer be represented
as ⃗B = ⃗∇× ⃗A since otherwise ⃗∇. ⃗B = ⃗∇. ⃗∇× ⃗A = εijk∂i∂jAk = 0 identically. Newton and
Leibniz told us that derivatives commute with each other.
So what, you say. Indeed, who cares that ⃗B cannot be written as ⃗∇× ⃗A? The vector po-
tential ⃗A was introduced into physics only as a mathematical crutch, and indeed that is
still how students are often taught in a course on classical electromagnetism. As the dis-
tinguished nineteenth-century physicist Heaviside thundered, “Physics should be purged
of such rubbish as the scalar and vector potentials; only the fields ⃗E and ⃗B are physical.”
With the advent of quantum mechanics, however, Heaviside was proved to be quite
wrong. Recall, for example, the nonrelativistic Schr¨odinger equation for a charged particle
in an electromagnetic field:

−1
2m( ⃗∇−ie ⃗A)2 + eφ

ψ = Eψ
(1)
Charged particles couple directly to the vector and scalar potentials ⃗A and φ, which are
thus seen as being more fundamental, in some sense, than the electromagnetic fields ⃗E
and ⃗B, as I alluded to in chapter III.4. Quantum physics demands the vector potential.
Dirac noted brilliantly that these remarks imply an intrinsic conflict between quantum
mechanics and the concept of magnetic monopoles. Upon closer analysis, he found that
quantum mechanics does not actually forbid the existence of magnetic monopoles. It
allows magnetic monopoles, but only those carrying a specific amount of magnetic charge.

246 | IV. Symmetry and Symmetry Breaking
Differential forms
For the following discussion and for the next chapter on Yang-Mills theory, it is highly
convenient to use the language of differential forms. Fear not, we will need only a few
elementary concepts. Let xμ be D real variables (thus, the index μ takes on D values)
and Aμ (not necessarily the electromagnetic gauge potential in this purely mathematical
section) be D functions of the x’s. In our applications, xμ represent coordinates and, as
we will see, differential forms have natural geometric interpretations.
We call the object A ≡Aμdxμ a 1-form. The differentials dxμ are treated following New-
ton and Leibniz. If we change coordinates x →x′, then as usual dxμ = (∂xμ/∂x′ν)dx′ν so
that A ≡Aμdxμ = Aμ(∂xμ/∂x′ν)dx′ν ≡A′
νdx′ν. This reproduces the standard transforma-
tion law of vectors under coordinate transformation A′
ν = Aμ(∂xμ/∂x′ν). As an example,
consider A = cos θ dϕ. Regarding θ and ϕ as angular coordinates on a 2-sphere (namely
the surface of a 3-ball), we have Aθ = 0 and Aϕ = cos θ. Similarly, we define a p-form as
H = (1/p!)Hμ1μ2...μpdxμ1dxμ2 . . . dxμp. (Repeated indices are summed, as always.) The
“degenerate” example is that of a 0-form, call it , which is just a scalar function of the
coordinates xμ. An example of a 2-form is F = (1/2!)Fμνdxμdxν.
We now face the question of how to think about products of differentials. In an ele-
mentary course on calculus we learned that dx dy represents the area of an infinitesimal
rectangle with length dx and width dy. At that level, we more or less automatically regard
dy dx as the same as dx dy. The order of writing the differentials does not matter. However,
think about making a coordinate transformation so that x = x(x′, y′) and y = y(x′, y′) are
now functions of the new coordinates x′ and y′. Now look at
dx dy =
 ∂x
∂x′ dx′ + ∂x
∂y′ dy′
  ∂y
∂x′ dx′ + ∂y
∂y′ dy′

(2)
Note that the coefficient of dx′dy′ is (∂x/∂x′)(∂y/∂y′) and that the coefficient of dy′dx′
is (∂x/∂y′)(∂y/∂x′). We see that it is much better if we regard the differentials dxμ
as anticommuting objects [what mathematicians would call Grassmann variables (recall
chapter (II.5)] so that dy′dx′ = −dx′dy′ and dx′dx′ = 0 = dy′dy′. Then (2) simplifies
neatly to
dx dy =
 ∂x
∂x′
∂y
∂y′ −∂x
∂y′
∂y
∂x′

dx′dy′ ≡J(x, y; x′, y′)dx′dy′
(3)
We obtain the correct Jacobian J(x, y; x′, y′) for transforming the area element dx dy to
the area element dx′dy′.
In many texts, dx dy is written as dx^dy. We will omit the wedge—no reason to clutter
up the page.
This little exercise tells us that we should define dxμdxν = −dxνdxμ and regard the
area element dxμdxν as directional. The area elements dxμdxν and dxνdxμ have the same
magnitude but point in opposite directions.

IV.4. Magnetic Monopole | 247
We now define a differential operation d to act on any form. Acting on a p-form H , it
gives by definition
dH = 1
p!∂νHμ1μ2...μpdxνdxμ1dxμ2 . . . dxμp
Thus, d = ∂νdxν and
dA = ∂νAμdxνdxμ = 1
2(∂νAμ −∂μAν)dxνdxμ
In the last step, we used dxμdxν = −dxνdxμ.
We see that this mathematical formalism is almost tailor made to describe electromag-
netism. If we call A ≡Aμdxμ the potential 1-form and think of Aμ as the electromag-
netic potential, then F = dA is in fact the field 2-form. If we write F out in terms of its
components F = (1/2!)Fμνdxμdxν, then Fμν is indeed equal to the electromagnetic field
(∂μAν −∂νAμ).
Note that xμ is not a form, and dxμ is not d acting on a form.
If you like, you can think of differential forms as “merely” an elegantly compact notation.
The point is to think of physical objects such as A and F as entities, without having to
commit to any particular coordinate system. This is particularly convenient when one has
to deal with objects more complicated than A and F , for example in string theory. By using
differential forms, we avoid drowning in a sea of indices.
An important identity is
dd = 0
(4)
which says that acting with d on any form twice gives zero. Verify this as an exercise. In
particular dF = ddA = 0. If you write this out in components you will recognize it as a
standard identity (the “Bianchi identity”) in electromagnetism.
Closed is not necessarily globally exact
It is convenient here to introduce some jargon. A p-form α is said to be closed if dα = 0.
It is said to be exact if there exists a (p −1)-form β such that α = dβ.
Talking the talk, we say that (4) tells us that exact forms are closed.
Is the converse of (4) true? Kind of. The Poincar´e lemma states that a closed form is
locally exact. In other words, if dH = 0 with H some p-form, then locally
H = dK
(5)
for some (p −1)-form K. However, it may or may not be the case that H = dK globally,
that is, everywhere. Actually, whether you know it or not, you are already familiar with the
Poincar´e lemma. For example, surely you learned somewhere that if the curl of a vector
field vanishes, the vector field is locally the gradient of some scalar field.
Forms are ready made to be integrated over. For example, given the 2-form F =
(1/2!)Fμνdxμdxν, we can write

M F for any 2-manifold M. Note that the measure is

248 | IV. Symmetry and Symmetry Breaking
already included and there is no need to specify a coordinate choice. Again, whether you
know it or not, you are already familiar with the important theorem

M
dH =

∂M
H
(6)
with H a p-form and ∂M the boundary of a (p + 1)-dimensional manifold M.
Dirac quantization of magnetic charge
After this dose of mathematics, we are ready to do some physics. Consider a sphere
surrounding a magnetic monopole with magnetic charge g. Then the electromagnetic
field 2-form is given by F = (g/4π)dcos θ dϕ. This is almost a definition of what we mean
by a magnetic monopole (see exercise IV.4.3.) In particular, calculate the magnetic flux by
integrating F over the sphere S2

S2 F = g
(7)
As I have already noted, the area element is automatically included. Indeed, you might
have recognized dcos θ dϕ = −sin θ dθ dϕ as precisely the area element on a unit sphere.
Note that in “ordinary notation” (7) implies the magnetic field ⃗B = (g/4πr2)ˆr, with ˆr the
unit vector in the radial direction.
I will now give a rather mathematical, but rigorous, derivation, originally developed by
Wu and Yang, of Dirac’s quantization of the magnetic charge g.
First, let us recall how gauge invariance works, from, for example, (II.7.3). Under a
transformation of the electron field ψ(x) →ei(x)ψ(x), the electromagnetic gauge poten-
tial changes by
Aμ(x) →Aμ(x) + 1
ie e−i(x)∂μei(x)
or in the language of forms,
A →A + 1
ie e−idei
(8)
Differentiating, we can of course write
Aμ(x) →Aμ(x) + 1
e ∂μ(x)
as is commonly done. The form given in (8) reminds us that gauge transformation is
defined as multiplication by a phase factor ei(x), so that (x) and (x) + 2π describe
exactly the same transformation.
In quantum mechanics A is physical, pace Heaviside, and so we should ask what A
would give rise to F = (g/4π) d cos θ dϕ. Easy, you say; clearly A = (g/4π) cos θ dϕ. (In
checking this by calculating dA, remember that dd = 0.)
But not so fast; your mathematician friend says that dϕ is not defined at the north and
south poles. Put his objection into everyday language: If you are standing on the north pole,
what is your longitude? So strictly speaking it is forbidden to write A = (g/4π) cos θ dϕ.

IV.4. Magnetic Monopole | 249
But, you are smart enough to counter, then what about AN = (g/4π)(cos θ −1) dϕ, eh?
When you act with d on AN you obtain the desired F; the added piece (g/4π)(−1) dϕ gets
annihilated by d thanks once again to the identity (4). At the north pole, cos θ = 1, AN
vanishes, and is thus perfectly well defined.
OK, but your mathematician friend points out that your AN is not defined at the south
pole, where it is equal to (g/4π)(−2)dϕ.
Right, you respond, I anticipated that by adding the subscript N. I am now also forced
to define AS = (g/4π)(cos θ + 1) dϕ. Note that d acting on AS again gives the desired F .
But now AS is defined everywhere except at the north pole.
In mathematical jargon, we say that the gauge potential A is defined locally, but not
globally. The gauge potential AN is defined on a “coordinate patch” covering the northern
hemisphere and extending past the equator as far south as we want as long as we do
not include the south pole. Similarly, AS is defined on a “coordinate patch” covering the
southern hemisphere and extending past the equator as far north as we want as long as
we do not include the north pole.
But what happens where the two coordinate patches overlap, for example, along the
equator. The gauge potentials AN and AS are not the same:
AS −AN = 2 g
4π dϕ
(9)
Now what? Aha, but this is a gauge theory: If AS and AN are related by a gauge transforma-
tion, then all is well. Thus, referring to (8) we require that 2(g/4π) dϕ = (1/ie)e−idei
for some phase function ei. By inspection we have ei = ei2(eg/4π)ϕ.
But ϕ = 0 and ϕ = 2π describe exactly the same point. In order for ei to make sense,
we must have ei2(eg/4π)(2π) = ei2(eg/4π)(0) = 1; in other words, eieg = 1, or
g = 2π
e n
(10)
where n denotes an integer. This is Dirac’s famous discovery that the magnetic charge on
a magnetic monopole is quantized in units of 2π/e. A “dual” way of putting this is that if
the monopole exists then electric charge is quantized in units of 2π/g.
Note that the whole point is that F is locally but not globally exact; otherwise by (6) the
magnetic charge g =

S2 F would be zero.
I show you this rigorous mathematical derivation partly to cut through a lot of the
confusion typical of the derivations in elementary texts and partly because this type of
argument is used repeatedly in more advanced areas of physics, such as string theory.
Electromagnetic duality
That a duality may exist between electric and magnetic fields has tantalized theoretical
physicists for a century and a half. By the way, if you read Maxwell, you will discover that he
often talked about magnetic charges. You can check that Maxwell’s equations are invariant
under the elegant transformation ( ⃗E + i ⃗B) →eiθ( ⃗E + i ⃗B) if magnetic charges exist.

250 | IV. Symmetry and Symmetry Breaking
(a)
(b)
xμ(σ,τ)
xμ(τ)
Figure IV.4.1
One intriguing feature of (10) is that if e is small, then g is large, and vice versa. What
would magnetic charges look like if they exist? They wouldn’t look any different from
electric charges: They too interact with a 1/r potential, with likes repelling and opposites
attracting. In principle, we could have perfectly formulated electromagnetism in terms of
magnetic charges, with magnetic and electric fields exchanging their roles, but the theory
would be strongly coupled, with the coupling g rather than e.
Theoretical physicists are interested in duality because it allows them a glimpse into
field theories in the strongly coupled regime. Under duality, a weakly coupled field theory
is mapped into a strongly coupled field theory. This is exactly the reason why the discovery
some years ago that certain string theories are dual to others caused such enormous
excitement in the string theory community: We get to know how string theories behave in
the strongly coupled regime. More on duality in chapter VI.3.
Forms and geometry
The geometric character of differential forms is further clarified by thinking about the
electromagnetic current of a charged particle tracing out the world line Xμ(τ) in D-
dimensional spacetime (see figure IV.4.1a):
J μ(x) =

dτ dXμ
dτ δ(D)[x −X(τ)]
(11)
The interpretation of this elementary formula from electromagnetism is clear: dXμ/dτ is
the 4-velocity at a given value of the parameter τ (“proper time”) and the delta function
ensures that the current at x vanishes unless the particle passes through x. Note that J μ(x)
is invariant under the reparametrization τ →τ ′(τ).
The generalization to an extended object is more or less obvious. Consider a string. It
traces out a world sheet Xμ(τ , σ) in spacetime (see figure 1b), where σ is a parameter

IV.4. Magnetic Monopole | 251
telling us where we are along the length of the string. [For example, for a closed string,
σ is conventionally taken to range between 0 and 2π with Xμ(τ , 0) = Xμ(τ , 2π).] The
current associated with the string is evidently given by
J μν(x) =

dτdσ det
 ∂τXμ
∂τXν
∂σXμ
∂σXν

δ(D)[x −X(τ , σ)]
(12)
where ∂τ ≡∂/∂τ and so forth. The determinant is forced on us by the requirement of
invariance under reparametrization τ →τ ′(τ , σ), σ →σ ′(τ , σ). It follows that J μν is an
antisymmetric tensor. Hence, the analog of the electromagnetic potential Aμ coupling to
the current J μ is an antisymmetric tensor field Bμν coupling to the current J μν. Thus,
string theory contains a 2-form potential B = 1
2Bμνdxμdxν and the corresponding 3-form
field H = dB. In fact, string theory typically contains numerous p-forms.
Aharonov-Bohm effect
The reality of the gauge potential A was brought home forcefully in 1959 by Aharonov and
Bohm. Consider a magnetic field B confined to a region  as illustrated in figure IV.4.2.
The quantum physics of an electron is described by solving the Schr¨odinger equation (1).
In Feynman’s path integral formalism the amplitude associated with a path P is modified
by a multiplicative factor eie 
P ⃗A.d ⃗x, where the line integral is evaluated along the path P .
Thus, in the path integral calculation of the probability for an electron to propagate from
a to b (fig. IV.4.2), there will be interference between the contributions from path 1 and
path 2 of the form

e
ie 
P1
⃗A.d ⃗x
e
ie 
P2
⃗A.d ⃗x∗
=

eie  ⃗A.d ⃗x

a
b
B = 0
B = 0
Ω
P2
P1
Figure IV.4.2

252 | IV. Symmetry and Symmetry Breaking
but
 ⃗A . d ⃗x =
 ⃗B . d ⃗S is precisely the flux enclosed by the closed curve (P1 −P2), namely
the curve going from a to b along P1 and then returning from b to a along (−P2) since
complex conjugation in effect reverses the direction of the path P2. Remarkably, the
electron feels the effect of the magnetic field even though it never wanders into a region
with a magnetic field present.
When the Aharonov-Bohm paper was first published, no less an authority than Niels
Bohr was deeply disturbed. The effect has since been conclusively demonstrated in a series
of beautiful experiments by Tonomura and collaborators.
Coleman once told of a gedanken prank that connects the Aharonov-Bohm effect to
Dirac quantization of magnetic charge. Let us fabricate an extremely thin solenoid so that
it is essentially invisible and thread it into the lab of an unsuspecting experimentalist,
perhaps our friend from chapter III.1. We turn on a current and generate a magnetic field
through the solenoid. When the experimentalist suddenly sees the magnetic flux coming
out of apparently nowhere, she gets so excited that she starts planning to go to Stockholm.
What is the condition that prevents the experimentalist from discovering the prank? A
careful experimentalist might start scattering electrons around to see if she can detect a
solenoid. The condition that she does not see an Aharonov-Bohm effect and thus does
not discover the prank is precisely that the flux going through the solenoid is an integer
times 2π/e. This implies that the apparent magnetic monopole has precisely the magnetic
charge predicted by Dirac!
Exercises
IV.4.1
Prove dd = 0.
IV.4.2
Show by writing out the components explicitly that dF = 0 expresses something that you are familiar
with but disguised in a compact notation.
IV.4.3
Consider F = (g/4π) d cos θ dϕ. By transforming to Cartesian coordinates show that this describes a
magnetic field pointing outward along the radial direction.
IV.4.4
Restore the factors of ℏand c in Dirac’s quantization condition.
IV.4.5
Write down the reparametrization-invariant current J μνλ of a membrane.
IV.4.6
Let g(x) be the element of a group G. The 1-form v = gdg† is known as the Cartan-Maurer form.
Then tr vN is trivially closed on an N-dimensional manifold since it is already an N-form. Consider
Q =

SN tr vN with SN the N-dimensional sphere. Discuss the topological meaning of Q. These con-
siderations will become important later when we discuss topology in field theory in chapter V.7. [Hint:
Study the case N = 3 and G = SU(2).]

IV.5
Nonabelian Gauge Theory
Most such ideas are eventually discarded or shelved. But some
persist and may become obsessions. Occasionally an obsession
does finally turn out to be something good.
—C. N. Yang talking about an idea that he first had as a
student and that he kept coming back to year after year.1
Local transformation
It was quite a nice little idea.
To explain the idea Yang was talking about, recall our discussion of symmetry in
chapter I.10. For the sake of definiteness let ϕ(x) = {ϕ1(x), ϕ2(x), . . . , ϕN(x)} be an N-
component complex scalar field transforming as ϕ(x) →Uϕ(x), with U an element of
SU(N). Since ϕ† →ϕ†U† and U†U = 1, we have ϕ†ϕ →ϕ†ϕ and ∂ϕ†∂ϕ →∂ϕ†∂ϕ. The
invariance of the Lagrangian L =∂ϕ†∂ϕ −V (ϕ†ϕ) under SU(N) is obvious for any poly-
nomial V .
In the theoretical physics community there are many more people who can answer well-
posed questions than there are people who can pose the truly important questions. The
latter type of physicist can invariably also do much of what the former type can do, but the
reverse is certainly not true.
In 1954 C.N. Yang and R. Mills asked what will happen if the transformation varies from
place to place in spacetime, or in other words, if U = U(x) is a function of x.
Clearly, ϕ†ϕ is still invariant. But in contrast ∂ϕ†∂ϕ is no longer invariant. Indeed,
∂μϕ →∂μ(Uϕ) = U∂μϕ + (∂μU)ϕ = U[∂μϕ + (U†∂μU)ϕ]
To cancel the unwanted term (U†∂μU)ϕ, we generalize the ordinary derivative ∂μ to a
covariant derivative Dμ, which when acting on ϕ, gives
Dμϕ(x) = ∂μϕ(x) −iAμ(x)ϕ(x)
(1)
The field Aμ is called a gauge potential in direct analogy with electromagnetism.
1 C. N. Yang, Selected Papers 1945–1980 with Commentary, p. 19.

254 | IV. Symmetry and Symmetry Breaking
How must Aμ transform, so that Dμϕ(x) →U(x)Dμϕ(x)? In other words, we would
like Dμϕ(x) to transform the way ∂μϕ(x) transformed when U did not depend on x. If
so, then [Dμϕ(x)]†Dμϕ(x) →[Dμϕ(x)]†Dμϕ(x) and can be used as an invariant kinetic
energy term for the field ϕ.
Working backward, we see that Dμϕ(x) →U(x)Dμϕ(x) if ( and it goes without saying
that you should be checking this)
Aμ →UAμU† −i(∂μU)U† = UAμU† + iU∂μU†
(2)
(The equality follows from UU† = 1.) We refer to Aμ as the nonabelian gauge potential
and to (2) as a nonabelian gauge transformation.
Let us now make a series of simple observations.
1. Clearly, Aμ have to be N by N matrices. Work out the transformation law for A†
μ using
(2) and show that the condition Aμ −A†
μ = 0 is preserved by the gauge transformation.
Thus, it is consistent to take Aμ to be hermitean. Specifically, you should work out what
this means for the group SU(2) so that U = eiθ.τ/2 where θ . τ = θaτ a, with τ a the familiar
Pauli matrices.
2. Writing U = eiθ.T with T a the generators of SU(N), we have
Aμ →Aμ + iθa[T a, Aμ] + ∂μθaT a
(3)
under an infinitesimal transformation U ≃1 + iθ . T . For most purposes, the infinitesimal
form (3) suffices.
3. Taking the trace of (3) we see that the trace of Aμ does not transform and so we can take Aμ
to be traceless as well as hermitean. This means that we can always write Aμ = Aa
μT a and
thus decompose the matrix field Aμ into component fields Aa
μ. There are as many Aa
μ’s as
there are generators in the group [3 for SU(2), 8 for SU(3), and so forth.]
4. You are reminded in appendix B that the Lie algebra of the group is defined by [T a, T b] =
if abcT c, where the numbers f abc are called structure constants. For example, f abc = εabc
for SU(2). Thus, (3) can be written as
Aa
μ →Aa
μ −f abcθbAc
μ + ∂μθa
(4)
Note that if θ does not depend on x, the Aa
μ’s transform as the adjoint representation of the
group.
5. If U(x) = eiθ(x) is just an element of the abelian group U(1), all these expressions simplify
and Aμ is just the abelian gauge potential familiar from electromagnetism, with (2 ) the usual
abelian gauge transformation. Hence, Aμ is known as the nonabelian gauge potential.
A transformation U that depends on the spacetime coordinates x is known as a gauge
transformation or local transformation. A Lagrangian L invariant under a gauge transfor-
mation is said to be gauge invariant.

IV.5. Nonabelian Gauge Theory | 255
Construction of the field strength
We can now immediately write a gauge invariant Lagrangian, namely
L =(Dμϕ)†(Dμϕ) −V (ϕ†ϕ)
(5)
but the gauge potential Aμ does not yet have dynamics of its own. In the familiar example
of U(1) gauge invariance, we have written the coupling of the electromagnetic potential
Aμ to the matter field ϕ, but we have yet to write the Maxwell term −1
4FμνF μν in the
Lagrangian. Our first task is to construct a field strength Fμν out of Aμ. How do we do
that? Yang and Mills apparently did it by trial and error. As an exercise you might also
want to try that before reading on.
At this point the language of differential forms introduced in chapter IV.4 proves to
be of use. It is convenient to absorb a factor of −i by defining AM
μ ≡−iAP
μ, where AP
μ
denotes the gauge potential we have been using all along. Until further notice, when
we write Aμ we mean AM
μ . Referring to (1) we see that the covariant derivative has the
cleaner form Dμ = ∂μ + Aμ. (Incidentally, the superscripts M and P indicate the potential
appearing in the mathematical and physical literature, respectively.) As before, let us
introduce A = Aμdxμ, now a matrix 1-form, that is, a form that also happens to be a matrix
in the defining representation of the Lie algebra [e.g., an N by N traceless hermitean matrix
for SU(N).] Note that
A2 = AμAνdxμdxν = 1
2[Aμ, Aν]dxμdxν
is not zero for a nonabelian gauge potential. (Obviously, there is no such object in electro-
magnetism.)
Our task is to construct a 2-form F = 1
2Fμνdxμdxν out of the 1-form A. We adopt a direct
approach. Out of A we can construct only two possible 2-forms: dA and A2. So F must be
a linear combination of the two.
In the notation we are using the transformation law (2) reads
A →UAU
† + UdU
†
(6)
with U a 0-form (and so dU
† = ∂μU
†dxμ.) Applying d to (6) we have
dA →UdAU
† + dUAU
† −UAdU
† + dUdU
†
(7)
Note the minus sign in the third term, from moving the 1-form d past the 1-form A. On
the other hand, squaring (6) we have
A2 →UA2U
† + UAdU
† + UdU
†UAU
† + UdU
†UdU
†
(8)
Applying d to UU
† = 1 we have UdU
† = −dUU
†. Thus, we can rewrite (8) as
A2 →UA2U
† + UAdU
† −dUAU
† −dUdU
†
(9)

256 | IV. Symmetry and Symmetry Breaking
Lo and behold! If we add (7) and (9), six terms knock each other off, leaving us with
something nice and clean:
dA + A2 →U(dA + A2)U
†
(10)
The mathematical structure thus led Yang and Mills to define the field strength
F = dA + A2
(11)
Unlike A, the field strength 2-form F transforms homogeneously (10):
F →UFU
†
(12)
In the abelian case A2 vanishes and F reduces to the usual electromagnetic form. In the
nonabelian case, F is not gauge invariant, but gauge covariant.
Of course, you can also construct F a
μν without using differential forms. As an exercise
you should do it starting with (4). The exercise will make you appreciate differential forms!
At the very least, we can regard differential forms as an elegantly compact notation that
suppresses the indices a and μ in (4). At the same time, the fact that (11) emerges so
smoothly clearly indicates a profound underlying mathematical structure. Indeed, there
is a one-to-one translation between the physicist’s language of gauge theory and the
mathematician’s language of fiber bundles.
Let me show you another route to (11). In analogy to d, define D = d + A, understood
as an operator acting on a form to its right. Let us calculate
D2 = (d + A)(d + A) = d2 + dA + Ad + A2
The first term vanishes, the second can be written as dA = (dA) −Ad; the parenthesis
emphasizes that d acts only on A. Thus,
D2 = (dA) + A2 = F
(13)
Pretty slick? I leave it as an exercise for you to show that D2 transforms homogeneously
and hence so does F .
Elegant though differential forms are, in physics it is often desirable to write more
explicit formulas. We can write (11) out as
F = (∂μAν + AμAν)dxμdxν = 1
2(∂μAν −∂νAμ + [Aμ, Aν])dxμdxν
(14)
With the definition F ≡1
2Fμνdxμdxν we have
Fμν = ∂μAν −∂νAμ + [Aμ, Aν]
(15)
At this point, we might also want to switch back to physicist’s notation. Recall that Aμ
in (15) is actually AM
μ ≡−iAP
μ and so by analogy define F M
μν = −iF P
μν. Thus,
Fμν = ∂μAν −∂νAμ −i[Aμ, Aν]
(16)
where, until further notice, Aμ stands for AP
μ. (One way to see the necessity for the i in (16)
is to remember that physicists like to take Aμ to be a hermitean matrix and the commutator
of two hermitean matrices is antihermitean.)

IV.5. Nonabelian Gauge Theory | 257
As long as we are being explicit we might as well go all the way and exhibit the group
indices as well as the Lorentz indices. We already wrote Aμ = Aa
μT a and so we naturally
write Fμν = F a
μνT a. Then (16) becomes
F a
μν = ∂μAa
ν −∂νAa
μ + f abcAb
μAc
ν
(17)
I mention in passing that for SU(2) A and F transform as vectors and the structure
constant f abc is just εabc, so the vector notation ⃗Fμν = ∂μ ⃗Aν −∂ν ⃗Aμ + ⃗Aμ × ⃗Aν is often
used.
The Yang-Mills Lagrangian
Given that F transforms homogeneously (12) we can immediately write down the analog
of the Maxwell Lagrangian, namely the Yang-Mills Lagrangian
L = −1
2g2 tr FμνF μν
(18)
We are normalizing T a by tr T aT b = 1
2δab so that L = −(1/4g2)F a
μνF aμν. The theory
described by this Lagrangian is known as pure Yang-Mills theory or nonabelian gauge
theory.
Apart from the quadratic term (∂μAa
ν −∂νAa
μ)2, the Lagrangian L = −(1/4g2)F a
μνF aμν
also contains a cubic term f abcAbμAcν(∂μAa
ν −∂νAa
μ) and a quartic term (f abcAb
μAc
ν)2.
As in electromagnetism the quadratic term describes the propagation of a massless vector
boson carrying an internal index a, known as the nonabelian gauge boson or the Yang-
Mills boson. The cubic and quartic terms are not present in electromagnetism and describe
the self-interaction of the nonabelian gauge boson. The corresponding Feynman rules are
given in figure IV.5.1a, 1b, and c.
The physics behind this self-interaction of the Yang-Mills bosons is not hard to under-
stand. The photon couples to charged fields but is not charged itself. Just as the charge
(c)
(b)
(a)
Figure IV.5.1

258 | IV. Symmetry and Symmetry Breaking
of a field tells us how the field transforms under the U(1) gauge group, the analog of the
charge of a field in a nonabelian gauge theory is the representation the field belongs to. The
Yang-Mills bosons couple to all fields transforming nontrivially under the gauge group. But
the Yang-Mills bosons themselves transform nontrivially: In fact, as we have noted, they
transform under the adjoint representation. Thus, they must couple to themselves.
Pure Maxwell theory is free and so essentially trivial. It contains a noninteracting photon.
In contrast, pure Yang-Mills theory contains self-interaction and is highly nontrivial. Note
that the structure coefficients f abc are completely fixed by group theory, and thus in
contrast to a scalar field theory, the cubic and quartic self-interactions of the gauge bosons,
including their relative strengths, are totally fixed by symmetry. If any 4-dimensional field
theory can be solved exactly, pure Yang-Mills theory may be it, but in spite of the enormous
amount of theoretical work devoted to it, it remains unsolved (see chapters VII.3 and VII.4).
’t Hooft’s double-line formalism
While it is convenient to use the component fields Aa
μ for many purposes, the matrix
field Aμ = Aa
μT a embodies the mathematical structure of nonabelian gauge theory more
elegantly. The propagator for the components of the matrix field in a U(N) gauge theory
has the form
⟨0|T Aμ(x)i
jAν(0)k
l |0⟩
= ⟨0|T Aa
μ(x)Ab
ν(0)|0⟩(T a)i
j(T b)k
l
(19)
∝δab(T a)i
j(T b)k
l ∝δi
lδk
j
[We have gone from an SU(N) to a U(N) theory for the sake of simplicity. The generators
of SU(N) satisfy a traceless condition TrT a = 0, as a result of which we would have to
subtract 1
N δi
jδk
l from the right-hand side.] The matrix structure Ai
μj naturally suggests that
we, following ’t Hooft, introduce a double-line formalism, in which the gauge potential is
described by two lines, each associated with one of the two indices i and j. We choose the
convention that the upper index flows into the diagram, while the lower index flows out
of the diagram. The propagator in (19) is represented in figure IV.5.2a. The double-line
formalism allows us to reproduce the index structure δi
lδk
j naturally. The cubic and quartic
couplings are represented in figure IV.5.2b and c.
The constant g introduced in (18) is known as the Yang-Mills coupling constant. We can
always write the quadratic term in (18) in the convention commonly used in electromag-
netism by a trivial rescaling A →gA. After this rescaling, the cubic and quartic couplings
of the Yang-Mills boson go as g and g2, respectively. The covariant derivative in (1) be-
comes Dμϕ = ∂μϕ −igAμϕ, showing that g also measures the coupling of the Yang-Mills
boson to matter. The convention we used, however, brings out the mathematical structure
more clearly. As written in (18), g2 measures the ease with which the Yang-Mills boson can
propagate. Recall that in chapter III.7 we also found this way of defining the coupling as

IV.5. Nonabelian Gauge Theory | 259
i
j
l
k
(a)
(b)
(c)
Figure IV.5.2
a measure of propagation useful in electromagnetism. We will see in chapter VIII.1 that
Newton’s coupling appears in the same way in the Einstein-Hilbert action for gravity.
The θ term
Besides tr FμνF μν, we can also form the dimension-4 term εμνλρ tr FμνFλρ. Clearly,
this term violates time reversal invariance T and parity P since it involves one time
index and three space indices. We will see later that the strong interaction is described
by a nonabelian gauge theory, with the Lagrangian containing the so-called θ term
(θ/32π2)εμνλρ tr FμνFλρ. As you will show in exercise IV.5.3 this term is a total diver-
gence and does not contribute to the equation of motion. Nevertheless, it induces an
electric dipole moment for the neutron. The experimental upper bound on the electric
dipole moment for the neutron translates into an upper bound on θ of the order 10−9. I
will not go into how particle physicists resolve the problem of making sure that θ is small
enough or vanishes outright.
Coupling to matter fields
We took the scalar field ϕ to transform in the fundamental representation of the group.
In general, ϕ can transform in an arbitrary representation R of the gauge group G. We
merely have to write the covariant derivative more generally as
Dμϕ = (∂μ −iAa
μT a
(R))ϕ
(20)
where T a
(R) represents the ath generator in the representation R (see exercise IV.5.1).
Clearly, the prescription to turn a globally symmetric theory into a locally symmetric
theory is to replace the ordinary derivative ∂μ acting on any field, boson or fermion,

260 | IV. Symmetry and Symmetry Breaking
belonging to the representation R by the covariant derivative Dμ = (∂μ −iAa
μT a
(R)). Thus,
the coupling of the nonabelian gauge potential to a fermion field is given by
L = ¯ψ(iγ μDμ −m)ψ = ¯ψ(iγ μ∂μ + γ μAa
μT a
(R) −m)ψ.
(21)
Fields listen to the Yang-Mills gauge bosons according to the representation R that
they belong to, and those that belong to the trivial identity representation do not hear
the call of the gauge bosons. In the special case of a U(1) gauge theory, also known as
electromagnetism, R corresponds to the electric charge of the field. Those fields that
transform trivially under U(1) are electrically neutral.
Appendix
Let me show you another context, somewhat surprising at first sight, in which the Yang-Mills structure pops up.2
Consider Schr¨odinger’s equation
i ∂
∂t (t) = H(t)(t)
(22)
with a time dependent Hamiltonian H(t). The setup is completely general: For instance, we could be talking
about spin states in a magnetic field or about a single particle nonrelativistic Hamiltonian with the wave function
(⃗x, t). We suppress the dependence of H and  on variables other than time t.
First, solve the eigenvalue problem of H(t). Suppose that because of symmetry or some other reason the
spectrum of H(t) contains an n-fold degeneracy, in other words, there exist n distinct solutions of the equations
H(t)ψa(t) = E(t)ψa(t), with a = 1, . . . , n. Note that E(t) can vary with time and that we are assuming that the
degeneracy persists with time, that is, the degeneracy does not occur “accidentally” at one instant in time. We can
always replace H(t) by H(t) −E(t) so that henceforth we have H(t)ψa(t) = 0. Also, the states can be chosen to
be orthogonal so that ⟨ψb(t)|ψa(t)⟩= δba. (For notational reasons it is convenient to jump back and forth between
the Schr¨odinger and the Dirac notation. To make it absolutely clear, we have
⟨ψb(t)|ψa(t)⟩=

d ⃗xψ∗
b(⃗x, t)ψa(⃗x, t)
if we are talking about single particle quantum mechanics.)
Let us now study (22) in the adiabatic limit, that is, we assume that the time scale over which H(t) varies is
much longer than 1/E, where E denotes the energy gap separating the states ψa(t) from neighboring states.
In that case, if (t) starts out in the subspace spanned by {ψa(t)} it will stay in that subspace and we can write
(t) = 	
a ca(t)ψa(t). Plugging this into (22) we obtain immediately 	
a[(dca/dt)ψa(t) + ca(t)(∂ψa/∂t)] = 0.
Taking the scalar product with ψb(t), we obtain
dcb
dt = −

a
Abaca
(23)
with the n by n matrix
Aba(t) ≡i⟨ψb(t)|∂ψa
∂t ⟩
(24)
Now suppose somebody else decides to use a different basis, ψ′
a(t) = U∗
ac(t)ψc(t), related to ours by a unitary
transformation. (The complex conjugate on the unitary matrix U is just a notational choice so that our final
equation will come out looking the same as a celebrated equation in the text; see below.) I have also passed
2 F. Wilczek and A. Zee, “Appearance of Gauge Structure in Simple Dynamical Systems,” Phys. Rev. Lett.
52:2111, 1984.

IV.5. Nonabelian Gauge Theory | 261
to the repeated indices summed notation. Differentiate to obtain (∂ψ′
a/∂t) = U∗
ac(t)(∂ψc/∂t) + (dU∗
ac/dt)ψc(t).
Contracting this with ψ′∗
b (t) = Ubd(t)ψ∗
d(t) and multiplying by i, we find
A′ = UAU† + iU ∂U†
∂t
(25)
Suppose the Hamiltonian H(t) depends on d parameters λ1, . . . , λd. We vary the parameters, thus tracing out a
path defined by {λμ(t), μ = 1, . . . , d} in the d-dimensional parameter space. For example, for a spin Hamiltonian,
{λμ} could represent an external magnetic field. Now (23) becomes
dcb
dt = −

a
(Aμ)baca
dλμ
dt
(26)
if we define (Aμ)ba ≡i⟨ψb|∂μψa⟩, where ∂μ ≡∂/∂λμ, and (25) generalizes to
A′
μ = UAμU† + iU∂μU†
(27)
We have recovered (IV.5.2). Lo and behold, a Yang-Mills gauge potential Aμ has popped up in front of our very
eyes!
The “transport” equation (26) can be formally solved by writing c(λ) = Pe−
Aμdλμ, where the line integral
is over a path connecting an initial point in the parameter space to some final point λ and P denotes a path
ordering operation. We break the path into infinitesimal segments and multiply together the noncommuting
contribution e−Aμλμ from each segment, ordered along the path. In particular, if the path is a closed curve, by
the time we return to the initial values of the parameters, the wave function will have acquired a matrix phase
factor, known as the nonabelian Berry’s phase. This discussion is clearly intimately related to the discussion of
the Aharonov-Bohm phase in the preceding chapter.
To see this nonabelian phase, all we have to do is to find some quantum system with degeneracy in its spectrum
and vary some external parameter such as a magnetic field.3 In their paper, Yang and Mills spoke of the degeneracy
of the proton and neutron under isospin in an idealized world and imagined transporting a proton from one point
in the universe to another. That a proton at one point can be interpreted as a neutron at another necessitates the
introduction of a nonabelian gauge potential. I find it amusing that this imagined transport can now be realized
analogously in the laboratory.
You will realize that the discussion here parallels the discussion in the text leading up to (IV.5.2). The spacetime
dependent symmetry transformation corresponds to a parameter dependent change of basis. When I discuss
gravity in chapter VIII.1 it will become clear that moving the basis {ψa} around in the parameter space is the
precise analog of parallel transporting a local coordinate frame in differential geometry and general relativity. We
will also encounter the quantity P e−
Aμdλμ again in chapter VII.1 in the guise of a Wilson loop.
Exercises
IV.5.1
Write down the Lagrangian of an SU(2) gauge theory with a scalar field in the I = 2 representation.
IV.5.2
Prove the Bianchi identity DF ≡dF + [A, F] = 0. Write this out explicitly with indices and show that in
the abelian case it reduces to half of Maxwell’s equations.
IV.5.3
In 4-dimensions εμνλρ tr FμνFλρ can be written as tr F 2 . Show that d tr F 2 = 0 in any dimensions.
IV.5.4
Invoking the Poincar´e lemma (IV.4.5) and the result of exercise IV.5.3 show that tr F 2 = d tr(AdA + 2
3A3).
Write this last equation out explicitly with indices. Identify these quantities in the case of electromag-
netism.
3 A. Zee, “On the Non-Abelian Gauge Structure in Nuclear Quadrupole Resonance,” Phys. Rev. A38:1, 1988.
The proposed experiment was later done by A. Pines.

262 | IV. Symmetry and Symmetry Breaking
IV.5.5
For a challenge show that tr F n, which appears in higher dimensional theories such as string theory, are
all total divergences. In other words, there exists a (2n −1)-form ω2n−1(A) such that tr F n = dω2n−1(A).
[Hint: A compact representation of the form ω2n−1(A) =
 1
0 dt f2n−1(t, A) exists.] Work out ω5(A)
explicitly and try to generalize knowing ω3 and ω5. Determine the (2n −1)-form f2n−1(t, A). For help,
see B. Zumino et al., Nucl. Phys. B239:477, 1984.
IV.5.6
Write down the Lagrangian of an SU(3) gauge theory with a fermion field in the fundamental or defining
triplet representation.

IV.6
The Anderson-Higgs Mechanism
The gauge potential eats the Nambu-Goldstone boson
As I noted earlier the ability to ask good questions is of crucial importance in physics.
Here is an excellent question: How does spontaneous symmetry breaking manifest itself
in gauge theories?
Going back to chapter IV.1, we gauge the U(1) theory in (IV.1.6) by replacing ∂μϕ with
Dμϕ = (∂μ −ieAμ)ϕ so that
L = −1
4FμνF μν + (Dϕ)†Dϕ + μ2ϕ†ϕ −λ(ϕ†ϕ)2
(1)
Now when we go to polar coordinates ϕ = ρeiθ we have Dμϕ = [∂μρ + iρ(∂μθ −eAμ)]eiθ
and thus
L = −1
4FμνF μν + ρ2(∂μθ −eAμ)2 + (∂ρ)2 + μ2ρ2 −λρ4
(2)
(Compare this with L = ρ2(∂μθ)2 + (∂ρ)2 + μ2ρ2 −λρ4 in the absence of the gauge field.)
Under a gauge transformation ϕ →eiαϕ (so that θ →θ + α) and eAμ →eAμ + ∂μα, and
thus the combination Bμ ≡Aμ −(1/e)∂μθ is gauge invariant. The first two terms in L
thus become −1
4FμνF μν + e2ρ2B2
μ. Note that Fμν = ∂μAν −∂νAμ = ∂μBν −∂νBμ has the
same form in terms of the potential Bμ.
Upon spontaneous symmetry breaking, we write ρ = (1/
√
2)(v + χ), with v =

μ2/λ.
Hence
L = −1
4FμνF μν + 1
2M2B2
μ + e2vχB2
μ + 1
2e2χ2B2
μ
+ 1
2(∂χ)2 −μ2χ2 −
√
λμχ3 −λ
4 χ4 + μ4
4λ
(3)

264 | IV. Symmetry and Symmetry Breaking
The theory now consists of a vector field Bμ with mass
M = ev
(4)
interacting with a scalar field χ with mass
√
2μ. The phase field θ, which would have been
the Nambu-Goldstone boson in the ungauged theory, has disappeared. We say that the
gauge field Aμ has eaten the Nambu-Goldstone boson; it has gained weight and changed
its name to Bμ.
Recall that a massless gauge field has only 2 degrees of freedom, while a massive gauge
field has 3 degrees of freedom. A massless gauge field has to eat a Nambu-Goldstone boson
in order to have the requisite number of degrees of freedom. The Nambu-Goldstone
boson becomes the longitudinal degree of freedom of the massive gauge field. We do not
lose any degrees of freedom, as we had better not.
This phenomenon of a massless gauge field becoming massive by eating a Nambu-
Goldstone boson was discovered by numerous particle physicists1 and is known as the
Higgs mechanism. People variously call ϕ, or more restrictively χ, the Higgs field. The
same phenomenon was discovered in the context of condensed matter physics by Landau,
Ginzburg, and Anderson, and is known as the Anderson mechanism.
Let us give a slightly more involved example, an O(3) gauge theory with a Higgs field ϕa
(a = 1, 2, 3) transforming in the vector representation. The Lagrangian contains the kinetic
energy term 1
2(Dμϕa)2, with Dμϕa = ∂μϕa + gεabcAb
μϕc as indicated in (IV.5.20). Upon
spontaneous symmetry breaking, ⃗ϕ acquires a vacuum expectation value which without
loss of generality we can choose to point in the 3-direction, so that ⟨ϕa⟩= vδa3. We set
ϕ3 = v and see that
1
2(Dμϕa)2 →1
2(gv)2(A1
μAμ1 + A2
μAμ2)
(5)
The gauge potential A1
μ and A2
μ acquires mass gv [compare with (4)] while A3
μ remains
massless.
A more elaborate example is that of an SU(5) gauge theory with ϕ transforming as the 24-
dimensional adjoint representation. (See appendix B for the necessary group theory.) The
field ϕ is a 5 by 5 hermitean traceless matrix. Since the adjoint representation transforms
as ϕ →ϕ + iθa[T a, ϕ], we have Dμϕ = ∂μϕ −igAa
μ[T a, ϕ] with a = 1, . . . , 24 running
over the 24 generators of SU(5). By a symmetry transformation the vacuum expectation
value of ϕ can be taken to be diagonal ⟨ϕi
j⟩= vjδi
j (i, j = 1, . . . , 5), with 	
j vj = 0. (This
is the analog of our choosing ⟨⃗ϕ⟩to point in the 3-direction in the preceding example.) We
have in the Lagrangian
tr(Dμϕ)(Dμϕ) →g2 tr[T a, ⟨ϕ⟩][⟨ϕ⟩, T b]Aa
μAμb
(6)
The gauge boson masses squared are given by the eigenvalues of the 24 by 24 matrix
g2 tr[T a, ⟨ϕ⟩][⟨ϕ⟩, T b], which we can compute laboriously for any given ⟨ϕ⟩.
1 Including P. Higgs, F. Englert, R. Brout, G. Guralnik, C. Hagen, and T. Kibble.

IV.6. Anderson-Higgs Mechanism | 265
It is easy to see, however, which gauge bosons remain massless. As a specific example
(which will be of interest to us in chapter VII.6), suppose
⟨ϕ⟩= v
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
2
0
0
0
0
0
2
0
0
0
0
0
2
0
0
0
0
0
−3
0
0
0
0
0
−3
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
(7)
Which generators T a commute with ⟨ϕ⟩? Clearly, generators of the form

A 0
0 0

and of the
form

0 0
0 B

. Here A represents 3 by 3 hermitean traceless matrices (of which there are
32 −1 = 8, the so-called Gell-Mann matrices) and B represents 2 by 2 hermitean traceless
matrices (of which there are 22 −1 = 3, namely the Pauli matrices). Furthermore, the
generator
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
2
0
0
0
0
0
2
0
0
0
0
0
2
0
0
0
0
0
−3
0
0
0
0
0
−3
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
(8)
being proportional to ⟨ϕ⟩, obviously commutes with ⟨ϕ⟩. Clearly, these generators gen-
erate SU(3), SU(2), and U(1), respectively. Thus, in the 24 by 24 mass-squared matrix
g2 tr[T a, ⟨ϕ⟩][⟨ϕ⟩, T b] there are blocks of submatrices that vanish, namely, an 8 by 8 block,
a 3 by 3 block, and a 1 by 1 block. We have 8 + 3 + 1 = 12 massless gauge bosons. The
remaining 24 −12 = 12 gauge bosons acquire mass.
Counting massless gauge bosons
In general, consider a theory with the global symmetry group G spontaneously broken to
a subgroup H . As we learned in chapter IV.1, n(G) −n(H) Nambu-Goldstone bosons
appear. Now suppose the symmetry group G is gauged. We start with n(G) massless
gauge bosons, one for each generator. Upon spontaneous symmetry breaking, the n(G) −
n(H) Nambu-Goldstone bosons are eaten by n(G) −n(H) gauge bosons, leaving n(H)
massless gauge bosons, exactly the right number since the gauge bosons associated with
the surviving gauge group H should remain massless.
In our simple example, G = U(1), H = nothing: n(G) = 1 and n(H) = 0. In our second
example, G = O(3), H = O(2) ≃U(1) : n(G) = 3 and n(H) = 1, and so we end up with
one massless gauge boson. In the third example, G = SU(5), H = SU(3) ⊗SU(2) ⊗U(1)
so that n(G) = 24 and n(H) = 12. Further examples and generalizations are worked out
in the exercises.

266 | IV. Symmetry and Symmetry Breaking
Gauge boson mass spectrum
It is easy enough to work out the mass spectrum explicitly. The covariant derivative of a
Higgs field is Dμϕ = ∂μϕ + gAa
μT aϕ, where g is the gauge coupling, T a are the generators
of the group G when acting on ϕ, and Aa
μ the gauge potential corresponding to the ath
generator. Upon spontaneous symmetry breaking we replace ϕ by its vacuum expectation
value ⟨ϕ⟩= v. Hence Dμϕ is replaced by gAa
μT av. The kinetic term 1
2(Dμϕ . Dμϕ) [here
(.) denotes the scalar product in the group G] in the Lagrangian thus becomes
1
2g2(T av . T bv)AμaAb
μ ≡1
2Aμa(μ2)abAb
μ
where we have introduced the mass-squared matrix
(μ2)ab = g2(T av . T bv)
(9)
for the gauge bosons. [You will recognize (9) as the generalization of (4); also compare (5)
and (6).] We diagonalize (μ2)ab to obtain the masses of the gauge bosons. The eigenvectors
tell us which linear combinations of Aa
μ correspond to mass eigenstates.
Note that μ2 is an n(G) by n(G) matrix with n(H) zero eigenvalues, whose existence can
also be seen explicitly. Let T c be a generator of H . The statement that H remains unbroken
by the vacuum expectation value v means that the symmetry transformation generated by
T c leaves v invariant; in other words, T cv = 0, and hence the gauge boson associated with
T c remains massless, as it should. All these points are particularly evident in the SU(5)
example we worked out.
Feynman rules in spontaneously broken gauge theories
It is easy enough to derive the Feynman rules for spontaneously broken gauge theories.
Take, for example, (3). As usual, we look at the terms quadratic in the fields, Fourier
transform, and invert. We see that the gauge boson propagator is given by
−i
k2 −M2 + iε (gμν −kμkν
M2 )
(10)
and the χ propagator by
i
k2 −2μ2 + iε
(11)
I leave it to you to work out the rules for the interaction vertices.
As I said in another context, field theories often exist in several equivalent forms.
Take the U(1) theory in (1) and instead of polar coordinates go to Cartesian coordinates
ϕ = (1/
√
2)(ϕ1 + iϕ2) so that
Dμϕ = ∂μϕ −ieAμϕ = 1
√
2
[(∂μϕ1 + eAμϕ2) + i(∂μϕ2 −eAμϕ1)]

IV.6. Anderson-Higgs Mechanism | 267
Then (1) becomes
L = −1
4FμνF μν + 1
2[(∂μϕ1 + eAμϕ2)2 + (∂μϕ2 −eAμϕ1)2]
(12)
+ 1
2μ2(ϕ2
1 + ϕ2
2) −1
4λ(ϕ2
1 + ϕ2
2)2
Spontaneous symmetry breaking means setting ϕ1 →v + ϕ′
1 with v =

μ2/λ.
The physical content of (12) and (3) should be the same. Indeed, expand the Lagrangian
(12) to quadratic order in the fields:
L = μ4
4λ −1
4FμνF μν + 1
2M2A2
μ −MAμ∂μϕ2 + 1
2[(∂μϕ′
1)2 −2μ2ϕ′2
1 ]
+ 1
2(∂μϕ2)2 + . . .
(13)
The spectrum, a gauge boson A with mass M = ev and a scalar boson ϕ′
1 with mass
√
2μ,
is identical to the spectrum in (3). (The particles there were named B and χ.)
But oops, you may have noticed something strange: the term −MAμ∂μϕ2 which mixes
the fields Aμ and ϕ2. Besides, why is ϕ2 still hanging around? Isn’t he supposed to have
been eaten? What to do?
We can of course diagonalize but it is more convenient to get rid of this mixing term.
Referring to the Fadeev-Popov quantization of gauge theories discussed in chapter III.4 we
note that the gauge fixing term generates a term to be added to L. We can cancel the unde-
sirable mixing term by choosing the gauge function to be f (A) = ∂A + ξevϕ2 −σ . Going
through the steps, we obtain the effective Lagrangian Leff = L −(1/2ξ)(∂A + ξMϕ2)2
[compare with (III.4.7)]. The undesirable cross term −MAμ∂μϕ2 in L is now canceled upon
integration by parts. In Leff the terms quadratic in A now read −1
4FμνF μν + 1
2M2A2
μ −
(1/2ξ)(∂A)2 while the terms quadratic in ϕ2 read 1
2[(∂μϕ2)2 −ξM2ϕ22], immediately giving
us the gauge boson propagator
−i
k2 −M2 + iε

gμν −(1 −ξ)
kμkν
k2 −ξM2 + iε

(14)
and the ϕ2 propagator
i
k2 −ξM2 + iε
(15)
This one-parameter class of gauge choices is known as the Rξ gauge. Note that the would-
be Goldstone field ϕ2 remains in the Lagrangian, but the very fact that its mass depends on
the gauge parameter ξ brands it as unphysical. In any physical process, the ξ dependence in
the ϕ2 and A propagators must cancel out so as to leave physical amplitudes ξ independent.
In exercise IV.6.9 you will verify that this is indeed the case in a simple example.
Different gauges have different advantages
You might wonder why we would bother with the Rξ gauge. Why not just use the equivalent
formulation of the theory in (3), known as the unitary gauge, in which the gauge boson

268 | IV. Symmetry and Symmetry Breaking
propagator (10) looks much simpler than (14) and in which we don’t have to deal with the
unphysical ϕ2 field? The reason is that the Rξ gauge and the unitary gauge complement
each other. In the Rξ gauge, the gauge boson propagator (14) goes as 1/k2 for large k and
so renormalizability can be proved rather easily. On the other hand, in the unitary gauge
all fields are physical (hence the name “unitary”) but the gauge boson propagator (10)
apparently goes as kμkν/k2 for large k; to prove renormalizability we must show that the
kμkν piece of the propagator does not contribute. Using both gauges, we can easily prove
that the theory is both renormalizable and unitary. By the way, note that in the limit ξ →∞
(14) goes over to (10) and ϕ2 disappear, at least formally.
In practical calculations, there are typically many diagrams to evaluate. In the Rξ gauge,
the parameter ξ darn well better disappears when we add everything up to form the physical
mass shell amplitude. The Rξ gauge is attractive precisely because this requirement
provides a powerful check on practical calculations.
I remarked earlier that strictly speaking, gauge invariance is not so much a symmetry
as the reflection of a redundancy in the degrees of freedom used. (The photon has only 2
degrees of freedom but we use a field Aμ with 4 components.) A purist would insist, in
the same vein, that there is no such thing as spontaneously breaking a gauge symmetry.
To understand this remark, note that spontaneous breaking amounts to setting ρ ≡|ϕ| to
v and θ to 0 in (2). The statement |ϕ| = v is perfectly U(1) invariant: It defines a circle in ϕ
space. By picking out the point θ = 0 on the circle in a globally symmetric theory we break
the symmetry. In contrast, in a gauge theory, we can use the gauge freedom to fix θ = 0
everywhere in spacetime. Hence the purists. I will refrain from such hair-splitting in this
book and continue to use the convenient language of symmetry breaking even in a gauge
theory.
Exercises
IV.6.1
Consider an SU(5) gauge theory with a Higgs field ϕ transforming as the 5-dimensional representation:
ϕi, i = 1, 2, . . . , 5. Show that a vacuum expectation value of ϕ breaks SU(5) to SU(4). Now add another
Higgs field ϕ′, also transforming as the 5-dimensional representation. Show that the symmetry can either
remain at SU(4) or be broken to SU(3).
IV.6.2
In general, there may be several Higgs fields belonging to various representations labeled by α. Show that
the mass squared matrix for the gauge bosons generalize immediately to (μ2)ab = 	
α g2(T a
α vα . T b
α vα),
where vα is the vacuum expectation value of ϕα and T a
α is the ath generator represented on ϕα. Combine
the situations described in exercises IV.6.1 and IV.6.2 and work out the mass spectrum of the gauge
bosons.
IV.6.3
The gauge group G does not have to be simple; it could be of the form G1 ⊗G2⊗. . . ⊗Gk, with
coupling constants g1, g2, . . . , gk. Consider, for example, the case G = SU(2) ⊗U(1) and a Higgs
field ϕ transforming like the doublet under SU(2) and like a field with charge
1
2 under U(1), so that
Dμϕ = ∂μϕ −i[gAa
μ(τ a/2) + g′Bμ
1
2] ϕ. Let ⟨ϕ⟩=

0
v

. Determine which linear combinations of the
gauge bosons Aa
μ and Bμ acquire mass.
IV.6.4
In chapter IV.5 you worked out an SU(2) gauge theory with a scalar field ϕ in the I = 2 representation.
Write down the most general quartic potential V (ϕ) and study the possible symmetry breaking pattern.

IV.6. Anderson-Higgs Mechanism | 269
IV.6.5
Complete the derivation of the Feynman rules for the theory in (3) and compute the amplitude for the
physical process χ + χ →B + B.
IV.6.6
Derive (14). [Hint: The procedure is exactly the same as that used to obtain (III.4.9).] Write L = 1
2AμQμνAν
with Qμν = (∂2 + M2)gμν −[1 −(1/ξ)]∂μ∂ν or in momentum space Qμν = −(k2 −M2)gμν + [1 −
(1/ξ)]kμkν. The propagator is the inverse of Qμν.
IV.6.7
Work out the (. . .) in (13) and the Feynman rules for the various interaction vertices.
IV.6.8
Using the Feynman rules derived in exercise IV.6.7 calculate the amplitude for the physical process ϕ′
1 +
ϕ′
1 →A + A and show that the dependence on ξ cancels out. Compare with the result in exercise IV.6.5.
[Hint: There are two diagrams, one with A exchange and the other with ϕ2 exchange.]
IV.6.9
Consider the theory defined in (12) with μ = 0. Using the result of exercise IV.3.5 show that
Veff(ϕ) = 1
4λϕ4 +
1
64π2(10λ2 + 3e4)ϕ4

log ϕ2
M2 −25
6

+ . . .
(16)
where ϕ2 = ϕ2
1 + ϕ2
2. This potential has a minimum away from ϕ = 0 and thus the gauge symmetry
is spontaneously broken by quantum fluctuations. In chapter IV.3 we did not have the e4 term and
argued that the minimum we got there was not to be trusted. But here we can balance the λϕ4 against
e4ϕ4 log(ϕ2/M2) for λ of the same order of magnitude as e4. The minimum can be trusted. Show that
the spectrum of this theory consists of a massive scalar boson and a massive vector boson, with
m2(scalar)
m2(vector) = 3
2π
e2
4π
(17)
For help, see S. Coleman and E. Weinberg, Phys. Rev. D7: 1888, 1973.

IV.7
Chiral Anomaly
Classical versus quantum symmetry
I have emphasized the importance of asking good questions. Here is another good one: Is
a symmetry of classical physics necessarily a symmetry of quantum physics?
We have a symmetry of classical physics if a transformation ϕ →ϕ + δϕ leaves the action
S(ϕ) invariant. We have a symmetry of quantum physics if the transformation leaves the
path integral

DϕeiS(ϕ) invariant.
When our question is phrased in this path integral language, the answer seems obvious:
Not necessarily. Indeed, the measure Dϕ may or may not be invariant.
Yet historically, field theorists took as almost self-evident the notion that any symmetry
of classical physics is necessarily a symmetry of quantum physics, and indeed, almost
all the symmetries they encountered in the early days of field theory had the property of
being symmetries of both classical and quantum physics. For instance, we certainly expect
quantum mechanics to be rotational invariant. It would be very odd indeed if quantum
fluctuations were to favor a particular direction.
You have to appreciate the frame of mind that field theorists operated in to understand
their shock when they discovered in the late 1960s that quantum fluctuations can indeed
break classical symmetries. Indeed, they were so shocked as to give this phenomenon the
rather misleading name “anomaly,” as if it were some kind of sickness of field theory. With
the benefits of hindsight, we now understand the anomaly as being no less conceptually
innocuous as the elementary fact that when we change integration variables in an integral
we better not forget the Jacobian.
With the passing of time, field theorists have developed many different ways of looking
at the all important subject of anomaly. They are all instructive and shed different lights
on how the anomaly comes about. For this introductory text I choose to show the existence
of anomaly by an explicit Feynman diagram calculation. The diagram method is certainly
more laborious and less slick than other methods, but the advantage is that you will see

IV.7. Chiral Anomaly | 271
a classical symmetry vanishing in front of your very eyes! No smooth formal argument
for us.
The lesser of two evils
Consider the theory of a single massless fermion L = ¯ψiγ μ∂μψ. You can hardly ask
for a simpler theory! Recall from chapter II.1 that L is manifestly invariant under the
separate transformations ψ →eiθψ and ψ →eiθγ 5ψ, corresponding to the conserved
vector current J μ = ¯ψγ μψ and the conserved axial current J μ
5 = ¯ψγ μγ 5ψ respectively.
You should verify that ∂μJ μ = 0 and ∂μJ μ
5 = 0 follow immediately from the classical
equation of motion iγ μ∂μψ = 0.
Let us now calculate the amplitude for a spacetime history in which a fermion-anti-
fermion pair is created at x1 and another such pair is created at x2 by the vector current,
with the fermion from one pair annihilating the antifermion from the other pair and the
remaining fermion-antifermion pair being subsequently annihilated by the axial current.
This is a long-winded way of describing the amplitude ⟨0|T J λ
5 (0)J μ(x1)J ν(x2)|0⟩in
words, but I want to make sure that you know what I am talking about. Feynman tells
us that the Fourier transform of this amplitude is given by the two “triangle” diagrams in
figure IV.7.1a and b.
λμν(k1, k2) = (−1)i3

d4p
(2π)4
tr

γ λγ 5
1
̸p −̸q γ ν
1
̸p −̸k1
γ μ 1
̸p + γ λγ 5
1
̸p −̸q γ μ
1
̸p −̸k2
γ ν 1
̸p

(1)
with q = k1 + k2. Note that the two terms are required by Bose statistics. The overall factor
of (−1) comes from the closed fermion loop.
Classically, we have two symmetries implying ∂μJ μ = 0 and ∂μJ μ
5 = 0. In the quantum
theory, if ∂μJ μ = 0 continues to hold, then we should have k1μλμν = 0 and k2νλμν = 0,
and if ∂μJ μ
5 = 0 continues to hold, then qλλμν = 0. Now that we have things all set up,
we merely have to calculate λμν to see if the two symmetries hold up under quantum
fluctuations. No big deal.
p
p − q
p − k1
γλγ5
γμ
γν
(a)
p
p − q
γλγ5
(b)
γμ
γν
p − k2
Figure IV.7.1

272 | IV. Symmetry and Symmetry Breaking
Before we blindly calculate, however, let us ask ourselves how sad we would be if either of
the two currents J μ and J μ
5 fails to be conserved. Well, we would be very upset if the vector
current is not conserved. The corresponding charge Q =

d3xJ 0 counts the number of
fermions. We wouldn’t want our fermions to disappear into thin air or pop out of nowhere.
Furthermore, it may please us to couple the photon to the fermion field ψ. In that case,
you would recall from chapter II.7 that we need ∂μJ μ = 0 to prove gauge invariance and
hence show that the photon has only two degrees of polarization. More explicitly, imagine
a photon line coming into the vertex labeled by μ in figure IV.7.1a and b with propagator
(i/k2
1)[ξ(k1μk1ρ/k2
1) −gμρ]. The gauge dependent term ξ(k1μk1ρ/k2
1) would not go away if
the vector current is not conserved, that is, if k1μλμν fails to vanish.
On the other hand, quite frankly, just between us friends, we won’t get too upset if
quantum fluctuation violates axial current conservation. Who cares if the axial charge
Q5 =

d3xJ 0
5 is not constant in time?
Shifting integration variable
So, do k1μλμν and k2νλμν vanish? We will look over Professor Confusio’s shoulders as
he calculates k1μλμν. (We are now in the 1960s, long after the development of renor-
malization theory as described in chapter III.1 and Confusio has managed to get a tenure
track assistant professorship.) He hits λμν as written in (1) with k1μ and using what he
learned in chapter II.7 writes ̸k1 in the first term as ̸p −( ̸p −̸k1) and in the second term
as ( ̸p −̸k2) −( ̸p −̸q), thus obtaining
k1μλμν(k1, k2)
= i

d4p
(2π)4 tr(γ λγ 5
1
̸p −̸q γ ν
1
̸p −̸k1
−γ λγ 5
1
̸p −̸k2
γ ν 1
̸p )
(2)
Just as in chapter II.7, Confusio recognizes that in the integrand the first term is just the
second term with the shift of the integration variable p →p −k1. The two terms cancel
and Professor Confusio publishes a paper saying k1μλμν = 0, as we all expect.
Remember back in chapter II.7 I said we were going to worry later about whether it is
legitimate to shift integration variables. Now is the time to worry!
You could have asked your calculus teacher long ago when it is legitimate to shift
integration variables. When is
 +∞
−∞dpf (p + a) equal to
 +∞
−∞dpf (p)? The difference
between these two integrals is
 +∞
−∞
dp(a d
dp f (p) + . . .) = a(f (+∞) −f (−∞)) + . . .
Clearly, if f (+∞) and f (−∞) are two different constants, then it is not okay to shift. But
if the integral
 +∞
−∞dpf (p) is convergent, or even logarithmically divergent, it is certainly
okay. It was okay in chapter II.7 but definitely not here in (2)!

IV.7. Chiral Anomaly | 273
As usual, we rotate the Feynman integrand to Euclidean space. Generalizing our obser-
vation above to d-dimensional Euclidean space, we have

dd
Ep[f (p + a) −f (p)] =

dd
Ep[aμ∂μf (p) + . . .]
which by Gauss’s theorem is given by a surface integral over an infinitely large sphere
enclosing all of Euclidean spacetime and hence equal to
lim
P →∞aμ
Pμ
P

f (P)Sd−1(P)
where Sd−1(P) is the area of a (d −1)-dimensional sphere (see appendix D) and where an
average over the surface of the sphere is understood. (Recall from our experience evaluating
Feynman diagrams that the average of P μP ν/P 2 is equal to 1
4ημν by a symmetry argument,
with the normalization 1
4 fixed by contracting with ημν.) Rotating back, we have for a 4-
dimensional Minkowskian integral

d4p[f (p + a) −f (p)] = lim
P →∞iaμ
Pμ
P

f (P )(2π2P 3)
(3)
Note the i from Wick rotating back.
Applying (3) with
f (p) = tr

γ λγ 5
1
̸p −̸k2
γ ν 1
̸p

= tr[γ 5( ̸p −̸k2)γ ν ̸pγ λ]
(p −k2)2p2
= 4iετνσλk2τpσ
(p −k2)2p2
we obtain
k1μλμν =
i
(2π)4 lim
P →∞i(−k1)μ Pμ
P
4iετνσλk2τPσ
P 4
2π2P 3 =
i
8π2ελντσk1τk2σ
Contrary to what Confusio said, k1μλμν ̸= 0.
As I have already said, this would be a disaster. Fermion number is not conserved and
matter would be disintegrating all around us! What is the way out?
In fact, we are only marginally smarter than Professor Confusio. We did not notice that
the integral defining λμν in (1) is linearly divergent and is thus not well defined.
Oops, even before we worry about calculating k1μλμν and k2νλμν we better worry
about whether or not λμν depends on the physicist doing the calculation. In other
words, suppose another physicist chooses1 to shift the integration variable p in the linearly
divergent integral in (1) by an arbitrary 4-vector a and define
λμν(a, k1, k2)
= (−1)i3

d4p
(2π)4 tr(γ λγ 5
1
̸p + ̸a −̸q γ ν
1
̸p + ̸a −̸k1
γ μ
1
̸p + ̸a )
+ {μ, k1 ↔ν, k2}
(4)
There can be as many results for the Feynman diagrams in figure IV.7.1a and b as there
are physicists! That would be the end of physics, or at least quantum field theory, for sure.
1 This is the freedom of choice in labeling internal momenta mentioned in chapter I.7.

274 | IV. Symmetry and Symmetry Breaking
Well, whose result should we declare to be correct?
The only sensible answer is that we trust the person who chooses an a such that
k1μλμν(a, k1, k2) and k2νλμν(a, k1, k2) vanish, so that the photon will have the right
number of degrees of freedom should we introduce a photon into the theory.
Let
us
compute
λμν(a, k1, k2) −λμν(k1, k2)
by
applying
(3)
to
f (p) =
tr(γ λγ 5
1
̸p−̸q γ ν
1
̸p−̸k1γ μ 1
̸p). Noting that
f (P) = lim
P →∞
tr(γ λγ 5 ̸P γ ν ̸Pγ μ ̸P)
P 6
= 2P μtr(γ λγ 5 ̸P γ ν ̸P) −P 2 tr(γ λγ 5 ̸Pγ νγ μ)
P 6
= +4iP 2Pσεσνμλ
P 6
we see that
λμν(a, k1, k2) −λμν(k1, k2) = 4i
8π2 lim
P →∞aω PωPσ
P 2 εσνμλ + {μ, k1 ↔ν, k2}
=
i
8π2εσνμλaσ + {μ, k1 ↔ν, k2}
(5)
There are two independent momenta k1 and k2 in the problem, so we can take a =
α(k1 + k2) + β(k1 −k2). Plugging into (5), we obtain
λμν(a, k1, k2) = λμν(k1, k2) + iβ
4π2ελμνσ(k1 −k2)σ
(6)
Note that α drops out.
As expected, λμν(a, k1, k2) depends on β, and hence on a. Our unshakable desire to
have a conserved vector current, that is, k1μλμν(a, k1, k2) = 0, now fixes the parameter β
upon recalling
k1μλμν(k1, k2) =
i
8π2ελντσk1τk2σ
Hence, we must choose to deal with λμν(a, k1, k2) with β = −1
2.
One way of viewing all this is to say that the Feynman rules do not suffice in determining
⟨0|T J λ
5 (0)J μ(x1)J ν(x2)|0⟩. They have to be supplemented by vector current conservation.
The amplitude ⟨0|T J λ
5 (0)J μ(x1)J ν(x2)|0⟩is defined by λμν(a, k1, k2) with β = −1
2.
Quantum fluctuation violates axial current conservation
Now we come to the punchline of the story. We insisted that the vector current be conserved.
Is the axial current also conserved?
To answer this question, we merely have to compute
qλλμν(a, k1, k2) = qλλμν(k1, k2) +
i
4π2εμνλσk1λk2σ
(7)

IV.7. Chiral Anomaly | 275
By now, you know how to do this:
qλλμν(k1, k2) = i

d4p
(2π)4 tr

γ 5
1
̸p −̸q γ ν
1
̸p −̸k1
γ μ
−γ 5
1
̸p −̸k2
γ ν 1
̸p γ μ

+ {μ, k1 ↔ν, k2}
=
i
4π2εμνλσk1λk2σ
(8)
Indeed, you recognize that the integration has already been done in (2). We finally obtain
qλλμν(a, k1, k2) =
i
2π2εμνλσk1λk2σ
(9)
The axial current is not conserved!
In summary, in the simple theory L = ¯ψiγ μ∂μψ while the vector and axial currents are
both conserved classically, quantum fluctuation destroys axial current conservation. This
phenomenon is known variously as the anomaly, the axial anomaly, or the chiral anomaly.
Consequences of the anomaly
As I said, the anomaly is an extraordinarily rich subject. I will content myself with a series
of remarks, the details of which you should work out as exercises.
1. Suppose we gauge our simple theory L = ¯ψiγ μ(∂μ −ieAμ)ψ and speak of Aμ as the photon
field. Then in figure IV.7.1 we can think of two photon lines coming out of the vertices labeled
μ and ν. Our central result (9) can then be written elegantly as two operator equations:
Classical physics: ∂μJ μ
5 = 0
(10)
Quantum physics: ∂μJ μ
5 =
e2
(4π)2εμνλσFμνFλσ
(11)
The divergence of the axial current ∂μJ μ
5 is not zero, but is an operator capable of producing
two photons.
2. Applying the same type of argument as in chapter IV.2 we can calculate the rate of the
decay π0 →γ + γ . Indeed, historically people used the erroneous result (10) to deduce that
this experimentally observed decay cannot occur! See exercise IV.7.2. The resolution of this
apparent paradox led to the correct result (11).
3. Writing the Lagrangian in terms of left and right handed fields ψR and ψL and introducing
the left and right handed currents J μ
R ≡¯ψRγ μψR and J μ
L ≡¯ψLγ μψL, we can repackage the
anomaly as
∂μJ μ
R = 1
2
e2
(4π)2εμνλσFμνFλσ
and
∂μJ μ
L = −1
2
e2
(4π)2εμνλσFμνFλσ
(12)

276 | IV. Symmetry and Symmetry Breaking
(Hence the name chiral!) We can think of left handed and right handed fermions running
around the loop in figure IV.7.1, contributing oppositely to the anomaly.
4. Consider the theory L = ¯ψ(iγ μ∂μ −m)ψ. Then invariance under the transformation ψ →
eiθγ 5ψ is spoiled by the mass term. Classically, ∂μJ μ
5 = 2m ¯ψiγ 5ψ: The axial current is
explicitly not conserved. The anomaly now says that quantum fluctuation produces an
additional term. In the theory L = ¯ψ[iγ μ(∂μ −ieAμ) −m]ψ, we have
∂μJ μ
5 = 2m ¯ψiγ 5ψ +
e2
(4π)2εμνλσFμνFλσ
(13)
5. Recall that in chapter III.7 we introduced Pauli-Villars regulators to calculate vacuum
polarization. We subtract from the integrand what the integrand would have been if the
electron mass were replaced by some regulator mass. The analog of electron mass in (1) is
in fact 0 and so we subtract from the integrand what the integrand would have been if 0
were replaced by a regulator mass M. In other words, we now define
λμν(k1, k2) = (−1)i3

d4p
(2π)4 tr

γ λγ 5
1
̸p −̸q γ ν
1
̸p −̸k1
γ μ 1
̸p
−γ λγ 5
1
̸p −̸q −M γ ν
1
̸p −̸k1 −M γ μ
1
̸p −M

+ {μ, k1 ↔ν, k2}.
(14)
Note that as p →∞the integrand now vanishes faster than 1/p3. This is in accordance
with the philosophy of regularization outlined in chapters III.1 and III.7: For p ≪M, the
threshold of ignorance, the integrand is unchanged. But for p ≫M, the integrand is cut
off. Now the integral in (14) is superficially logarithmically divergent and we can shift the
integration variable p at will.
So how does the chiral anomaly arise? By including the regulator mass M we have broken
axial current conservation explicitly. The anomaly is the statement that this breaking persists
even when we let M tend to infinity. It is extremely instructive (see exercise IV.7.4) to work
this out.
6. Consider the nonabelian theory L = ¯ψiγ μ(∂μ −igAa
μT a)ψ. We merely have to include in
the Feynman amplitude a factor of T a at the vertex labeled by μ and a factor of T b at the vertex
labeled by ν. Everything goes through as before except that in summing over all the different
fermions that run around the loop we obtain a factor tr T aT b. Thus, we see instantly that
in a nonabelian gauge theory
∂μJ μ
5 =
g2
(4π)2εμνλσ tr FμνFλσ
(15)
where Fμν = F a
μνT a is the matrix field strength defined in chapter IV.5. Nonabelian sym-
metry tells us something remarkable: The object εμνλσ tr FμνFλσ contains not only a term
quadratic in A, but also terms cubic and quartic in A, and hence there is also a chiral
anomaly with three and four gauge bosons coming in, as indicated in figure IV.7.2a and
b. Some people refer to the anomaly produced in figures IV.7.1 and IV.7.2 as the triangle,
square, and pentagon anomaly. Historically, after the triangle anomaly was discovered, there
was a controversy as to whether the square and pentagon anomaly existed. The nonabelian

IV.7. Chiral Anomaly | 277
γλγ5
(a)
γλγ5
(b)
Tc
Ta
Tb
Tc
Tb
Ta
Td
Figure IV.7.2
w2
w1
Figure IV.7.3
symmetry argument given here makes things totally obvious, but at the time people calcu-
lated Feynman diagrams explicitly and, as we just saw, there are subtleties lying in wait for
the unwary.
7. We will see in chapter V.7 that the anomaly has deep connections to topology.
8. We computed the chiral anomaly in the free theory L = ¯ψ(iγ μ∂μ −m)ψ. Suppose we
couple the fermion to a scalar field by adding f ϕ ¯ψψ or to the electromagnetic field for
that matter. Now we have to calculate higher order diagrams such as the three-loop diagram
in figure IV.7.3. You would expect that the right-hand side of (9) would be multiplied by
1 + h(f , e, . . .), where h is some unknown function of all the couplings in the theory.
Surprise! Adler and Bardeen proved that h = 0. This apparently miraculous fact, known as
the nonrenormalization of the anomaly, can be understood heuristically as follows. Before
we integrate over the momenta of the scalar propagators in figure IV.7.3 (labeled by w1
and w2) the Feynman integrand has seven fermion propagators and thus is more than
sufficiently convergent that we can shift integration variables with impunity. Thus, before
we integrate over w1 and w2 all the appropriate Ward identities are satisfied, for instance,
qλλμν
3 loops(k1, k2; w1, w2) = 0. You can easily complete the proof. You will give a proof 2 based
on topology in exercise V.7.13.
2 For a simple proof not involving topology, see J. Collins, Renormalization, p. 352.

278 | IV. Symmetry and Symmetry Breaking
(a)
π°
γ
γ
(b)
π°
γ
γ
Figure IV.7.4
9. The preceding point was of great importance in the history of particle physics as it led directly
to the notion of color, as we will discuss in chapter VII.3. The nonrenormalization of the
anomaly allowed the decay amplitude for π0 →γ + γ to be calculated with confidence in the
late 1960s. In the quark model of the time, the amplitude is given by an infinite number of
Feynman diagrams, as indicated in figure IV.7.4 (with a quark running around the fermion
loop), butthenonrenormalization of the anomaly tells us that only figure IV.7.4a contributes.
In other words, the amplitude does not depend on the details of the strong interaction. That
it came out a factor of 3 too small suggested that quarks come in 3 copies, as we will see in
chapter VII.3.
10. It is natural to speculate as to whether quarks and leptons are composites of yet more
fundamental fermions known as preons. The nonrenormalization of the chiral anomaly
provides a powerful tool for this sort of theoretical speculation. No matter how complicated
the relevant interactions might be, as long as they are described by field theory as we know
it, the anomaly at the preon level must be the same as the anomaly at the quark-lepton level.
This so-called anomaly matching condition3 severely constrains the possible preon theories.
11. Historically, field theorists were deeply suspicious of the path integral, preferring the
canonical approach. When the chiral anomaly was discovered, some people even argued that
the existence of the anomaly proved that the path integral was wrong. Look, these people
said, the path integral

D ¯ψDψ ei 
d4x ¯ψiγ μ(∂μ−iAμ)ψ
(16)
is too stupid to tell us that it is not invariant under the chiral transformation ψ →eiθγ 5ψ.
Fujikawa resolved the controversy by showing that the path integral did know about the
anomaly: Under the chiral transformation the measure D ¯ψDψ changes by a Jacobian.
Recall that this was how I motivated this chapter: The action may be invariant but not the
path integral.
3 G. ’t Hooft, in: G. ’t Hooft et al., eds., Recent Developments in Gauge Theories; A. Zee, Phys. Lett. 95B:290, 1980.

IV.7. Chiral Anomaly | 279
Exercises
IV.7.1
Derive (11) from (9). The momentum factors k1λ and k2σ in (9) become the two derivatives in FμνFλσ in
(11).
IV.7.2
Following the reasoning in chapter IV.2 and using the erroneous (10) show that the decay amplitude for
the decay π0 →γ + γ would vanish in the ideal world in which the π0 is massless. Since the π0 does
decay and since our world is close to the ideal world, this provided the first indication historically that
(10) cannot possibly be valid.
IV.7.3
Repeat all the calculations in the text for the theory L = ¯ψ(iγ μ∂μ −m)ψ.
IV.7.4
Take the Pauli-Villars regulated λμν(k1, k2) and contract it with qλ. The analog of the trick in chapter II.7
is to write ̸qγ 5 in the second term as [2M + ( ̸p −M) −( ̸p −̸q + M)]γ 5. Now you can freely shift
integration variables. Show that
qλλμν(k1, k2) = −2Mμν(k1, k2)
(17)
where
μν(k1, k2) ≡(−1)i3

d4p
(2π)4
tr

γ 5
1
̸p −̸q −M γ ν
1
̸p −̸k1 −M γ μ
1
̸p −M

+ {μ, k1 ↔ν, k2}
Evaluate μν and show that μν goes as 1/M in the limit M →∞and so the right hand side of (17)
goes to a finite limit. The anomaly is what the regulator leaves behind as it disappears from the low
energy spectrum: It is like the smile of the Cheshire cat. [We can actually argue that μν goes as 1/M
without doing a detailed calculation. By Lorentz invariance and because of the presence of γ 5, μν
must be proportional to εμνλρk1λk2ρ, but by dimensional analysis, μν must be some constant times
εμνλρk1λk2ρ/M. You might ask why we can’t use something like 1/(k2
1)
1
2 instead of 1/M to make the
dimension come out right. The answer is that from your experience in evaluating Feynman diagrams in
(3 + 1)-dimensional spacetime you can never get a factor like 1/(k2
1)
1
2 .]
IV.7.5
There are literally N ways of deriving the anomaly. Here is another. Evaluate
λμν(k1, k2) = (−1)i3

d4p
(2π)4
tr

γ λγ 5
1
̸p −̸q −mγ ν
1
̸p −̸k1 −mγ μ
1
̸p −m

+ {μ, k1 ↔ν, k2}
in the massive fermion case not by brute force but by first using Lorentz invariance to write
λμν(k1, k2) = ελμνσk1σA1 + . . . + εμνστk1σk2τkλ
2A8
where Ai ≡Ai(k2
1, k2
2, q2) are eight functions of the three Lorentz scalars in the problem. You are
supposed to fill in the dots. By counting powers as in chapters III.3 and III.7 show that two of these
functions are given by superficially logarithmically divergent integrals while the other six are given by
perfectly convergent integrals. Next, impose Bose statistics and vector current conservation k1μλμν =
0 = k2νλμν to show that we can avoid calculating the superficially logarithmically divergent integrals.
Compute the convergent integrals and then evaluate qλλμν(k1, k2).
IV.7.6
Discuss the anomaly by studying the amplitude
⟨0|T J λ
5 (0)J μ
5 (x1)J ν
5 (x2)|0⟩

280 | IV. Symmetry and Symmetry Breaking
given in lowest orders by triangle diagrams with axial currents at each vertex. [Hint: Call the momentum
space amplitude λμν
5
(k1, k2).] Show by using (γ 5)2 = 1 and Bose symmetry that
λμν
5
(k1, k2) = 1
3[λμν(a, k1, k2) + μνλ(a, k2, −q) + νλμ(a, −q, k1)]
Now use (9) to evaluate qλλμν
5
(k1, k2).
IV.7.7
Define the fermionic measure Dψ in (16) carefully by going to Euclidean space. Calculate the Jacobian
upon a chiral transformation and derive the anomaly. [Hint: For help, see K. Fujikawa, Phys. Rev. Lett.
42: 1195, 1979.]
IV.7.8
Compute the pentagon anomaly by Feynman diagrams in order to check remark 6 in the text. In other
words, determine the coefficient c in ∂μJ μ
5 = . . . + cεμνλσ tr AμAνAλAσ .

Part V
Field Theory and Collective Phenomena
I mentioned in the introduction that one of the more intellectually satisfying developments
in the last two or three decades has been the increasingly important role played by field
theoretic methods in condensed matter physics. This is a rich and diverse subject; in this
and subsequent chapters I can barely describe the tip of the iceberg and will have to content
myself with a few selected topics.
Historically, field theory was introduced into condensed matter physics in a rather direct
and straightforward fashion. The nonrelativistic electrons in a condensed matter system
can be described by a field ψ, along the lines discussed in chapter III.5. Field theoretic
Lagrangians may then be written down, Feynman diagrams and rules developed, and so
on and so forth. This is done in a number of specialized texts. What we present here is to a
large extent the more modern view of an effective field theoretic description of a condensed
matter system, valid at low energy and momentum. One of the fascinations of condensed
matter physics is that due to highly nontrivial many body effects the low energy degrees
of freedom might be totally different from the electrons we started out with. A particularly
striking example (to be discussed in chapter VI.2) is the quantum Hall system, in which
the low energy effective degree of freedom carries fractional charge and statistics.
Another advantage of devoting a considerable portion of a field theory book to condensed
matter physics is that historically and pedagogically it is much easier to understand the
renormalization group in condensed matter physics than in particle physics.
I will defiantly not stick to a legalistic separation between condensed matter and particle
physics. Some of the topics treated in Parts V and VI actually belong to particle physics.
And of course I cannot be responsible for explaining condensed matter physics, any more
than I could be responsible for explaining particle physics in chapter IV.2.

This page intentionally left blank

V.1
Superfluids
Repulsive bosons
Consider a finite density ¯ρ of nonrelativistic bosons interacting with a short ranged repul-
sion. Return to (III.5.11):
L = iϕ†∂0ϕ −1
2m∂iϕ†∂iϕ −g2(ϕ†ϕ −¯ρ)2
(1)
The last term is exactly the Mexican well potential of chapter IV.1, forcing the magnitude
of ϕ to be close to √¯ρ , thus suggesting that we use polar variables ϕ ≡√ρeiθ as we did
in (III.5.7). Plugging in and dropping the total derivative (i/2)∂0ρ, we obtain
L = −ρ∂0θ −1
2m
 1
4ρ (∂iρ)2 + ρ(∂iθ)2

−g2(ρ −¯ρ)2
(2)
Spontaneous symmetry breaking
As in chapter IV.1 write √ρ = √¯ρ + h (the vacuum expectation value of ϕ is√¯ρ), assume
h ≪√¯ρ, and expand1:
L = −2

¯ρh∂0θ −
¯ρ
2m(∂iθ)2 −1
2m(∂ih)2 −4g2 ¯ρh2 + . . .
(3)
Picking out the terms up to quadratic in h in (3) we use the “central identity of quantum
field theory” (see appendix A) to integrate out h, obtaining
L = ¯ρ∂0θ
1
4g2 ¯ρ −(1/2m)∂2
i
∂0θ −
¯ρ
2m(∂iθ)2 + . . .
=
1
4g2(∂0θ)2 −
¯ρ
2m(∂iθ)2 + . . .
(4)
1 Note that we have dropped the (potentially interesting) term −¯ρ∂0θ because it is a total divergence.

284 | V. Field Theory and Collective Phenomena
In the second equality we assumed that we are looking at processes with wave number k
small compared to

8g2 ¯ρm so that (1/2m)∂2
i is negligible compared to 4g2 ¯ρ. Thus, we see
that there exists in this fluid of bosons a gapless mode (often referred to as the phonon)
with the dispersion
ω2 = 2g2 ¯ρ
m
⃗k2
(5)
The learned among you will have realized that we have obtained Bogoliubov’s classic result
without ever doing a Bogoliubov rotation.2
Let me briefly remind you of Landau’s idealized argument3 that a linearly dispersing
mode (that is, ω is linear in k) implies superfluidity. Consider a mass M of fluid flowing
down a tube with velocity v. It could lose momentum and slow down to velocity v′
by creating an excitation of momentum k: Mv = Mv′ + ℏk. This is only possible with
sufficient energy to spare if
1
2Mv2 ≥1
2Mv′2 + ℏω(k). Eliminating v′ we obtain for M
macroscopic v ≥ω/k. For a linearly dispersing mode this gives a critical velocity vc ≡ω/k
below which the fluid cannot lose momentum and is hence super. [Thus, from (5) the
idealized vc = g√2 ¯ρ/m.]
Suitably scaling the distance variable, we can summarize the low energy physics of
superfluidity in the compact Lagrangian
L =
1
4g2(∂μθ)2
(6)
which we recognize as the massless version of the scalar field theory we studied in part I,
but with the important proviso that θ is a phase angle field, that is, θ(x) and θ(x) + 2π are
really the same. This gapless mode is evidently the Nambu-Goldstone boson associated
with the spontaneous breaking of the global U(1) symmetry ϕ →eiαϕ.
Linearly dispersing gapless mode
The physics here becomes particularly clear if we think about a gas of free bosons. We can
give a momentum ℏ⃗k to any given boson at the cost of only (ℏ⃗k)2/2m in energy. There
exist many low energy excitations in a free boson system. But as soon as a short ranged
repulsion is turned on between the bosons, a boson moving with momentum ⃗k would
affect all the other bosons. A density wave is set up as a result, with energy proportional
to k as we have shown in (5). The gapless mode has gone from quadratically dispersing to
linearly dispersing. There are far fewer low energy excitations. Specifically, recall that the
density of states is given by N(E) ∝kD−1(dk/dE). For example, for D = 2 the density of
states goes from N(E) ∝constant (in the presence of quadratically dispersing modes) to
N(E) ∝E (in the presence of linearly dispersing modes) at low energies.
2 L. D. Landau and E. M. Lifshitz, Statistical Physics, p. 238.
3 Ibid., p. 192.

V.1. Superfluids | 285
As was emphasized by Feynman4 among others, the physics of superfluidity lies not
in the presence of gapless excitations, but in the paucity of gapless excitations. (After all,
the Fermi liquid has a continuum of gapless modes.) There are too few modes that the
superfluid can lose energy and momentum to.
Relativistic versus nonrelativistic
This is a good place to discuss one subtle difference between spontaneous symmetry
breaking in relativistic and nonrelativistic theories. Consider the relativistic theory studied
in chapter IV.1: L =(∂†)(∂) −λ(† −v2)2. It is often convenient to take the λ →∞
limit holding v fixed. In the language used in chapter IV.1 “climbing the wall” costs
infinitely more energy than “rolling along the gutter.” The resulting theory is defined by
L =(∂†)(∂)
(7)
with the constraint † = v2. This is known as a nonlinear σ model, about which much
more in chapter VI.4.
The existence of a Nambu-Goldstone boson is particularly easy to see in the nonlinear σ
model. The constraint is solved by  = veiθ, which when plugged into L gives L = v2(∂θ)2.
There it is: the Nambu-Goldstone boson θ.
Let’s repeat this in the nonrelativistic domain. Take the limit g2 →∞with ¯ρ held fixed
so that (1) becomes
L = iϕ†∂0ϕ −1
2m∂iϕ†∂iϕ
(8)
with the constraint ϕ†ϕ = ¯ρ. But now if we plug the solution of the constraint ϕ = √¯ρeiθ
into L (and drop the total derivative −¯ρ∂0θ), we get L = −( ¯ρ/2m)(∂iθ)2 with the equation
of motion ∂2
i θ = 0. Oops, what is this? It’s not even a propagating degree of freedom?
Where is the Nambu-Goldstone boson?
Knowing what I already told you, you are not going to be puzzled by this apparent
paradox5 for long, but believe me, I have stumped quite a few excellent relativistic minds
with this one. The Nambu-Goldstone boson is still there, but as we can see from (5) its
propagation velocity ω/k scales to infinity as g and thus it disappears from the spectrum
for any nonzero ⃗k.
Why is it that we are allowed to go to this “nonlinear” limit in the relativistic case?
Because we have Lorentz invariance! The velocity of a linearly dispersing mode, if such a
mode exists, is guaranteed to be equal to 1.
4 R. P. Feynman, Statistical Mechanics.
5 This apparent paradox was discussed by A. Zee, “From Semionics to Topological Fluids” in O. J. P. ´Ebolic et
al., eds., Particle Physics, p. 415.

286 | V. Field Theory and Collective Phenomena
Exercises
V.1.1
Verify that the approximation used to reach (3) is consistent.
V.1.2
To confine the superfluid in an external potential W(⃗x) we would add the term −W(⃗x)ϕ†(⃗x, t)ϕ(⃗x, t)
to (1). Derive the corresponding equation of motion for ϕ. The equation, known as the Gross-Pitaevski
equation, has been much studied in recent years in connection with the Bose-Einstein condensate.

V.2
Euclid, Boltzmann, Hawking, and
Field Theory at Finite Temperature
Statistical mechanics and Euclidean field theory
I mentioned in chapter I.2 that to define the path integral more rigorously we should
perform a Wick rotation t = −itE. The scalar field theory, instead of being defined by the
Minkowskian path integral
Z =

Dϕe(i/ℏ) 
ddx[ 1
2 (∂ϕ)2−V (ϕ)]
(1)
is then defined by the Euclidean functional integral
Z =

Dϕe−(1/ℏ) 
dd
Ex[ 1
2 (∂ϕ)2+V (ϕ)] =

Dϕe−(1/ℏ)E(ϕ)
(2)
where ddx = −idd
Ex, with dd
Ex ≡dtEd(d−1)x. In (1) (∂ϕ)2 = (∂ϕ/∂t)2 −( ⃗∇ϕ)2, while in (2)
(∂ϕ)2 = (∂ϕ/∂tE)2 + ( ⃗∇ϕ)2: The notation is a tad confusing but I am trying not to introduce
too many extraneous symbols. You may or may not find it helpful to think of ( ⃗∇ϕ)2 + V (ϕ)
as one unit, untouched by Wick rotation. I have introduced E(ϕ) ≡

dd
Ex[ 1
2(∂ϕ)2 + V (ϕ)],
which may naturally be regarded as a static energy functional of the field ϕ(x). Thus,
given a configuration ϕ(x) in d-dimensional space, the more it varies, the less likely it is
to contribute to the Euclidean functional integral Z.
The Euclidean functional integral (2) may remind you of statistical mechanics. Indeed,
Herr Boltzmann taught us that in thermal equilibrium at temperature T = 1/β, the
probability for a configuration to occur in a classical system or the probability for a state to
occur in a quantum system is just the Boltzmann factor e−βE suitably normalized, where E
is to be interpreted as the energy of the configuration in a classical system or as the energy
eigenvalue of the state in a quantum system. In particular, recall the classical statistical
mechanics of an N-particle system for which
E(p, q) =

i
1
2mp2
i + V (q1, q2, . . . , qN)

288 | V. Field Theory and Collective Phenomena
The partition function is given (up to some overall constant) by
Z =

i

dpidqie−βE(p,q)
After doing the integrals over p we are left with the (reduced) partition function
Z =

i

dqie−βV (q1,q2,...,qN)
Promoting this to a field theory as in chapter I.3, letting i →x and qi →ϕ(x) as before, we
see that the partition function of a classical field theory with the static energy functional
E(ϕ) has precisely the form in (2), upon identifying the symbol ℏas the temperature
T = 1/β. Thus,
Euclidean quantum field theory in d-dimensional spacetime
∼Classical statistical mechanics in d-dimensional space
(3)
Functional integral representation of the quantum partition function
More interestingly, we move on to quantum statistical mechanics. The integration over
phase space {p, q} is replaced by a trace, that is, a sum over states: Thus the partition
function of a quantum mechanical system (say of a single particle to be definite) with the
Hamiltonian H is given by
Z = tr e−βH =

n
⟨n|e−βH |n⟩
In chapter I.2 we worked out the integral representation of ⟨F|e−iHT |I⟩. (You should
not confuse the time T with the temperature T of course.) Suppose we want an integral
representation of the partition function. No need to do any more work! We simply replace
the time T by −iβ, set |I⟩= |F⟩= |n⟩and sum over |n⟩to obtain
Z = tr e−βH =

PBC
Dqe− β
0 dτL(q)
(4)
Tracing the steps from (I.2.3) to (I.2.5) you can verify that here L(q) = 1
2(dq/dτ)2 + V (q)
is precisely the Lagrangian corresponding to H in the Euclidean time τ . The integral over
τ runs from 0 to β. The trace operation sets the initial and final states equal and so the
functional integral should be done over all paths q(τ) with the boundary condition q(0) =
q(β). The subscript PBC reminds us of this all important periodic boundary condition.
The extension to field theory is immediate. If H is the Hamiltonian of a quantum field
theory in D-dimensional space [and hence d = (D + 1)-dimensional spacetime], then the
partition function (4) is
Z = tr e−βH =

PBC
Dϕe− β
0 dτ 
dDxL(ϕ)
(5)

V.2. Finite Temperatures | 289
with the integral evaluated over all paths ϕ(⃗x, τ) such that
ϕ(⃗x, 0) = ϕ(⃗x, β)
(6)
(Here ϕ represents all the Bose fields in the theory.)
A remarkable result indeed! To study a field theory at finite temperature all we have to
do is rotate it to Euclidean space and impose the boundary condition (6). Thus,
Euclidean quantum field theory in (D + 1)-dimensional
spacetime, 0 ≤τ < β
∼Quantum statistical mechanics in D-dimensional space
(7)
In the zero temperature limit β →∞we recover from (5) the standard Wick-rotated
quantum field theory over an infinite spacetime, as we should.
Surely you would hit it big with mystical types if you were to tell them that temperature
is equivalent to cyclic imaginary time. At the arithmetic level this connection comes merely
from the fact that the central objects in quantum physics e−iHT and in thermal physics
e−βH are formally related by analytic continuation. Some physicists, myself included, feel
that there may be something profound here that we have not quite understood.
Finite temperature Feynman diagrams
If we so desire, we can develop the finite temperature perturbation theory of (5), working
out the Feynman rules and so forth. Everything goes through as before with one major
difference stemming from the condition (6) ϕ(⃗x, τ = 0) = ϕ(⃗x, τ = β). Clearly, when
we Fourier transform with the factor eiωτ , the Euclidean frequency ω can take on only
discrete values ωn ≡(2π/β)n, with n an integer. The propagator of the scalar field becomes
1/(k2
4 + ⃗k2) →1/(ω2
n + ⃗k2). Thus, to evaluate the partition function, we simply write the
relevant Euclidean Feynman diagrams and instead of integrating over frequency we sum
over a discrete set of frequencies ωn = (2πT )n, n = −∞, . . . , +∞. In other words, after
you beat a Feynman integral down to the form

dd
EkF(k2
E), all you have to do is replace it
by 2πT 	
n

dDkF[(2πT )2n2 + ⃗k2].
It is instructive to see what happens in the high-temperature T →∞limit. In summing
over ωn, the n = 0 term dominates since the combination (2πT )2n2 + ⃗k2 occurs in the
denominator. Hence, the diagrams are evaluated effectively in D-dimensional space. We
lose a dimension! Thus,
Euclidean quantum field theory in D-dimensional spacetime
∼High-temperature quantum statistical mechanics in
D-dimensional space
(8)
This is just the statement that at high-temperature quantum statistical mechanics goes
classical [compare (3)].

290 | V. Field Theory and Collective Phenomena
An important application of quantum field theory at finite temperature is to cosmology:
The early universe may be described as a soup of elementary particles at some high
temperature.
Hawking radiation
Hawking radiation from black holes is surely the most striking prediction of gravitational
physics of the last few decades. The notion of black holes goes all the way back to Michell
and Laplace, who noted that the escape velocity from a sufficiently massive object may
exceed the speed of light. Classically, things fall into black holes and that’s that. But with
quantum physics a black hole can in fact radiate like a black body at a characteristic
temperature T .
Remarkably, with what little we learned in chapter I.11 and here, we can actually
determine the black hole temperature. I hasten to add that a systematic development would
be quite involved and fraught with subtleties; indeed, entire books are devoted to this
subject. However, what we need to do is more or less clear. Starting with chapter I.11, we
would have to develop quantum field theory (for instance, that of a scalar field ϕ) in curved
spacetime, in particular in the presence of a black hole, and ask what a vacuum state (i.e.,
a state devoid of ϕ quanta) in the far past evolves into in the far future. We would find a
state filled with a thermal distribution of ϕ quanta. We will not do this here.
In hindsight, people have given numerous heuristic arguments for Hawking radiation.
Here is one. Let us look at the Schwarzschild solution (see chapter I.11)
ds2 =

1 −2GM
r

dt2 −

1 −2GM
r
−1
dr2 −r2dθ2 −r2 sin2 θ dφ2
(9)
At the horizon r = 2GM, the coefficients of dt2 and dr2 change sign, indicating that
time and space, and hence energy and momentum, are interchanged. Clearly, something
strange must occur. With quantum fluctuations, particle and antiparticle pairs are always
popping in and out of the vacuum, but normally, as we had discussed earlier, the uncer-
tainty principle limits the amount of time t the pairs can exist to ∼1/E. Near the black
hole horizon, the situation is different. A pair can fluctuate out of the vacuum right at the
horizon, with the particle just outside the horizon and the antiparticle just inside; heuris-
tically the Heisenberg restriction on t may be evaded since what is meant by energy
changes as we cross the horizon. The antiparticle falls in while the particle escapes to spa-
tial infinity. Of course, a hand-waving argument like this has to be backed up by detailed
calculations.
If black holes do indeed radiate at a definite temperature T , and that is far from obvious
a priori, we can estimate T easily by dimensional analysis. From (9) we see that only the
combination GM, which evidently has the dimension of a length, can come in. Since T
has the dimension of mass, that is, length inverse, we can only have T ∝1/GM.
To determine T precisely, we resort to a rather slick argument. I warn you from the
outset that the argument will be slick and should be taken with a grain of salt. It is only
meant to whet your appetite for a more correct treatment.

V.2. Finite Temperatures | 291
Imagine quantizing a scalar field theory in the Schwarzschild metric, along the line
described in chapter I.11. If upon Wick rotation the field “feels” that time is periodic with
period β, then according to what we have learned in this chapter the quanta of the scalar
field would think that they are living in a heat bath with temperature T = 1/β.
Setting t →−iτ, we rotate the metric to
ds2 = −

1 −2GM
r

dτ 2 +

1 −2GM
r
−1
dr2 + r2dθ2 + r2 sin2 θdφ2

(10)
In the region just outside the horizon r >∼2GM, we perform the general coordinate trans-
formation (τ , r) →(α, R) so that the first two terms in ds2 become R2dα2 + dR2, namely
the length element squared of flat 2-dimensional Euclidean space in polar coordinates.
To
leading
order,
we
can
write
the
Schwarzchild
factor
(1 −2GM/r)
as
(r −2GM)/(2GM) ≡γ 2R2 with the constant γ to be determined. Then the second term
becomes dr2/(γ 2R2) = (4GM)2γ 2dR2, and thus we set γ = 1/(4GM) to get the desired
dR2. The first two terms in −ds2 are then given by R2(dτ/(4GM))2 + dR2. Thus the Eu-
clidean time is related to the polar angle by τ = 4GMα and so has a period of 8πGM = β.
We obtain thus the Hawking temperature
T =
1
8πGM =
ℏc3
8πGM
(11)
Restoring ℏby dimensional analysis, we see that Hawking radiation is indeed a quantum
effect.
It is interesting to note that the Wick rotated geometry just outside the horizon is given
by the direct product of a plane with a 2-sphere of radius 2GM, although, this observation
is not needed for the calculation we just did.
Exercises
V.2.1
Study the free field theory L = 1
2(∂ϕ)2 −1
2m2ϕ2 at finite temperature and derive the Bose-Einstein
distribution.
V.2.2
It probably does not surprise you that for fermionic fields the periodic boundary condition (6) is replaced
by an antiperiodic boundary condition ψ(⃗x, 0) = −ψ(⃗x, β) in order to reproduce the results of chap-
ter II.5. Prove this by looking at the simplest fermionic functional integral. [Hint: The clearest exposition
of this satisfying fact may be found in appendix A of R. Dashen, B. Hasslacher, and A. Neveu, Phys. Rev.
D12: 2443, 1975.]
V.2.3
It is interesting to consider quantum field theory at finite density, as may occur in dense astrophysical
objects or in heavy ion collisions. (In the previous chapter we studied a system of bosons at finite density
and zero temperature.) In statistical mechanics we learned to go from the partition function to the grand
partition function Z = tr e−β(H−μN), where a chemical potential μ is introduced for every conserved
particle number N. For example, for noninteracting relativistic fermions, the Lagrangian is modified
to L = ¯ψ(i ̸ ∂−m)ψ + μ ¯ψγ 0ψ. Note that finite density, as well as finite temperature, breaks Lorentz
invariance. Develop the subject of quantum field theory at finite density as far as you can.

V.3
Landau-Ginzburg Theory of Critical Phenomena
The emergence of nonanalyticity
Historically, the notion of spontaneous symmetry breaking, originating in the work of
Landau and Ginzburg on second-order phase transitions, came into particle physics from
condensed matter physics.
Consider a ferromagnetic material in thermal equilibrium at temperature T . The mag-
netization ⃗
M(x) is defined as the average of the atomic magnetic moments taken over
a region of a size much larger than the length scale characteristic of the relevant micro-
scopic physics. (In this chapter, we are discussing a nonrelativistic theory and x denotes the
spatial coordinates only.) We know that at low temperatures, rotational invariance is spon-
taneously broken and that the material exhibits a bulk magnetization pointing in some
direction. As the temperature is raised past some critical temperature Tc the bulk mag-
netization suddenly disappears. We understand that with increased thermal agitation the
atomic magnetic moments point in increasingly random directions, canceling each other
out. More precisely, it was found experimentally that just below Tc the magnetization | ⃗
M|
vanishes as ∼(Tc −T )β, where the so-called critical exponent β ≃0.37.
This sudden change is known as a second order phase transition, an example of a
critical phenomenon. Historically, critical phenomena presented a challenge to theoretical
physicists. In principle, we are to compute the partition function Z = tr e−H/T with
the microscopic Hamiltonian H, but Z is apparently smooth in T except possibly at
T = 0. Some physicists went as far as saying that nonanalytic behavior such as (Tc −
T )β is impossible and that within experimental error | ⃗
M| actually vanishes as a smooth
function of T . Part of the importance of Onsager’s famous exact solution in 1944 of the 2-
dimensional Ising model is that it settled this question definitively. The secret is that an
infinite sum of terms each of which may be analytic in some variable need not be analytic
in that variable. The trace in tr e−H/T sums over an infinite number of terms.

V.3. Theory of Critical Phenomena | 293
Arguing from symmetry
In most situations, it is essentially impossible to calculate Z starting with the microscopic
Hamiltonian. Landau and Ginzburg had the brilliant insight that the form of the free
energy G as a function of ⃗
M for a system with volume V could be argued from general
principles. First, for ⃗
M constant in x, we have by rotational invariance
G = V [a ⃗
M2 + b( ⃗
M2)2 + . . .]
(1)
where a, b, . . . are unknown (but expected to be smooth) functions of T. Landau and
Ginzburg supposed that a vanishes at some temperature Tc. Unless there is some special
reason, we would expect that for T near Tc we have a = a1(T −Tc) + . . . [rather than, say,
a = a2(T −Tc)2 + . . .]. But you already learned in chapter IV.1 what would happen. For
T > Tc, G is minimized at ⃗
M = 0, but as T drops below Tc, new minima suddenly develop
at | ⃗
M| =

(−a/2b) ∼(Tc −T )
1
2 . Rotational symmetry is spontaneously broken, and the
mysterious nonanalytic behavior pops out easily.
To include the possibility of ⃗
M varying in space, Landau and Ginzburg argued that G
must have the form
G =

d3x{∂i ⃗
M∂i ⃗
M + a ⃗
M2 + b( ⃗
M2)2 + . . .}
(2)
where the coefficient of the (∂i ⃗
M)2 term has been set to 1 by rescaling ⃗
M. You would
recognize (2) as the Euclidean version of the scalar field theory we have been studying. By
dimensional analysis we see that 1/√a sets the length scale. More precisely, for T > Tc,
let us turn on a perturbing external magnetic field ⃗H(x) by adding the term −⃗H . ⃗
M.
Assuming ⃗
M small and minimizing G we obtain (−∂2 + a) ⃗
M ≃⃗H, with the solution
⃗
M(x) =

d3y

d3k
(2π)3
ei⃗k.(⃗x−⃗y)
⃗k2 + a
⃗H(y)
=

d3y
1
4π|⃗x −⃗y|e−√a|⃗x−⃗y| ⃗H(y)
(3)
[Recall that we did the integral in (I.4.7)—admire the unity of physics!]
It is standard to define a correlation function < ⃗
M(x) ⃗
M(0) > by asking what the mag-
netization ⃗
M(x) will be if we use a magnetic field sharply localized at the origin to create
a magnetization ⃗
M(0) there. We expect the correlation function to die off as e−|⃗x|/ξ over
some correlation length ξ that goes to infinity as T approaches Tc from above. The critical
exponent ν is traditionally defined by ξ ∼1/(T −Tc)ν.
In Landau-Ginzburg theory, also known as mean field theory, we obtain ξ = 1/√a and
hence ν = 1
2.
The important point is not how well the predicted critical exponents such as β and ν
agree with experiment but how easily they emerge from Landau-Ginzburg theory. The
theory provides a starting point for a complete theory of critical phenomena, which was
eventually developed by Kadanoff, Fisher, Wilson, and others using the renormalization
group (to be discussed in chapter VI.8).

294 | V. Field Theory and Collective Phenomena
The story goes that Landau had a logarithmic scale with which he ranked theoretical
physicists, with Einstein on top, and that after working out Landau-Ginzburg theory he
moved himself up by half a notch.
Exercise
V.3.1
Another important critical exponent γ is defined by saying that the susceptibility χ ≡(∂M/∂H)|H=0
diverges ∼1/|T −Tc|γ as T approaches Tc. Determine γ in Landau-Ginzburg theory. [Hint: Instructively,
there are two ways of doing it: (a) Add −⃗H . ⃗
M to (1) for ⃗
M and ⃗H constant in space and solve for ⃗
M( ⃗H).
(b) Calculate the susceptibility function χij(x −y) ≡[∂Mi(x)/∂Hj(y)]|H=0 and integrate over space.]

V.4
Superconductivity
Pairing and condensation
When certain materials are cooled below a certain critical temperature Tc, they suddenly be-
come superconducting. Historically, physicists had long suspected that the superconduct-
ing transition, just like the superfluid transition, has something to do with Bose-Einstein
condensation. But electrons are fermions, not bosons, and thus they first have to pair
into bosons, which then condense. We now know that this general picture is substantially
correct: Electrons form Cooper pairs, whose condensation is responsible for superconduc-
tivity.
With brilliant insight, Landau and Ginzburg realized that without having to know the
detailed mechanism driving the pairing of electrons into bosons, they could understand
a great deal about superconductivity by studying the field ϕ(x) associated with these con-
densing bosons. In analogy with the ferromagnetic transition in which the magnetization
⃗
M(x) in a ferromagnet suddenly changes from zero to a nonzero value when the temper-
ature drops below some critical temperature, they proposed that ϕ(x) becomes nonzero
for temperatures below Tc. (In this chapter x denotes spatial coordinates only.) In statisti-
cal physics, quantities such as ⃗
M(x) and ϕ(x) that change through a phase transition are
known as order parameters.
The field ϕ(x) carries two units of electric charge and is therefore complex. The dis-
cussion now unfolds much as in chapter V.3 except that ∂iϕ should be replaced by Diϕ ≡
(∂i −i2eAi)ϕ since ϕ is charged. Following Landau and Ginzburg and including the energy
of the external magnetic field, we write the free energy as
F = 1
4F 2
ij + |Diϕ|2 + a|ϕ|2 + b
2|ϕ|4 + . . .
(1)
which is clearly invariant under the U(1) gauge transformation ϕ →ei2eϕ and Ai →Ai +
∂i. As before, setting the coefficient of |Diϕ|2 equal to 1 just amounts to a normalization
choice for ϕ.
The similarity between (1) and (IV.6.1) should be evident.

296 | V. Field Theory and Collective Phenomena
Meissner effect
A hallmark of superconductivity is the Meissner effect, in which an external magnetic
field ⃗B permeating the material is expelled from it as the temperature drops below Tc. This
indicates that a constant magnetic field inside the material is not favored energetically. The
effective laws of electromagnetism in the material must somehow change at Tc. Normally,
a constant magnetic field would cost an energy of the order ∼⃗B2V , where V is the volume
of the material. Suppose that the energy density is changed from the standard ⃗B2 to ⃗A2
(where as usual ⃗∇× ⃗A = ⃗B). For a constant magnetic field ⃗B, ⃗A grows as the distance and
hence the total energy would grow faster than V . After the material goes superconducting,
we have to pay an unacceptably large amount of extra energy to maintain the constant
magnetic field and so it is more favorable to expel the magnetic field.
Note that a term like ⃗A2 in the effective energy density preserves rotational and transla-
tional invariance but violates electromagnetic gauge invariance. But we already know how
to break gauge invariance from chapter IV.6. Indeed, the U(1) gauge theory described there
and the theory of superconductivity described here are essentially the same, related by a
Wick rotation.
As in chapter V.3 we suppose that for temperature T ≃Tc, a ≃a1(T −Tc) while b
remains positive. The free energy F is minimized by ϕ = 0 above Tc, and by |ϕ| =
√−a/b ≡v below Tc. All this is old hat to you, who have learned that upon symmetry
breaking in a gauge theory the gauge field gains a mass. We simply read off from (1) that
F = 1
4F 2
ij + (2ev)2A2
i + . . .
(2)
which is precisely what we need to explain the Meissner effect.
London penetration length and coherence length
Physically, the magnetic field does not drop precipitously from some nonzero value outside
the superconductor to zero inside, but drops over some characteristic length scale, called
the London penetration length. The magnetic field leaks into the superconductor a bit over
a length scale l, determined by the competition between the energy in the magnetic field
F 2
ij ∼(∂A)2 ∼A2/l2 and the Meissner term (2ev)2A2 in (2). Thus, Landau and Ginzburg
obtained the London penetration length lL ∼(1/ev) = (1/e)√b/−a.
Similarly, the characteristic length scale over which the order parameter ϕ varies is
known as the coherence length lϕ, which can be estimated by balancing the second and
third terms in (1), roughly (∂ϕ)2 ∼ϕ2/l2
ϕ and aϕ2 against each other, giving a coherence
length of order lϕ ∼1/√−a.
Putting things together, we have
lL
lϕ
∼
√
b
e
(3)

V.4. Superconductivity | 297
You might recognize from chapter IV.6 that this is just the ratio of the mass of the scalar
field to the mass of the vector field.
As I remarked earlier, the concept of spontaneous symmetry breaking went from con-
densed matter physics to particle physics. After hearing a talk at the University of Chicago
on the Bardeen-Cooper-Schrieffer theory of superconductivity by the young Schrieffer,
Nambu played an influential role in bringing spontaneous symmetry breaking to the par-
ticle physics community.
Exercises
V.4.1
Vary (1) to obtain the equation for A and determine the London penetration length more carefully.
V.4.2
Determine the coherence length more carefully.

V.5
Peierls Instability
Noninteracting hopping electrons
The appearance of the Dirac equation and a relativistic field theory in a solid would be
surprising indeed, but yes, it is possible.
Consider the Hamiltonian
H = −t

j
(c†
j+1cj + c†
jcj+1)
(1)
describing noninteracting electrons hopping on a 1-dimensional lattice (figure V.5.1). Here
cj annihilates an electron on site j. Thus, the first term describes an electron hopping from
site j to site j + 1 with amplitude t. We have suppressed the spin labels. This is just about
the simplest solid state model; a good place to read about it is in Feynman’s “Freshman
lectures.”
Fourier transforming cj = 	
k eikajc(k) (where a is the spacing between sites), we
immediately find the energy spectrum ε(k) = −2t cos ka (fig. V.5.2). Imposing a periodic
boundary condition on a lattice with N sites, we have k = (2π/Na)n with n an integer
from −1
2N to 1
2N. As N →∞, k becomes a continuous rather than a discrete variable. As
usual, the Brillouin zone is defined by −π/a < k ≤π/a.
There is absolutely nothing relativistic about any of this. Indeed, at the bottom of the
spectrum the energy (up to an irrelevant additive constant) goes as ε(k) ≃2t 1
2(ka)2 ≡
k2/2meff. The electron disperses nonrelativistically with an effective mass meff .
j
j + 1
j − 1
Figure V.5.1

V.5. Peierls Instability | 299
ε(k)
εF
k
π
a
_
+ π
a
Figure V.5.2
But now let us fill the system with electrons up to some Fermi energy εF (see fig.
V.5.2). Focus on an electron near the Fermi surface and measure its energy from εF
and momentum from +kF . Suppose we are interested in electrons with energy small
compared to εF , that is, E ≡ε −εF ≪εF , and momentum small compared to kF , that is,
p ≡k −kF ≪kF . These electrons obey a linear energy-momentum dispersion E = vFp
with the Fermi velocity vF = (∂ε/∂k)|k=kF . We will call the field associated with these
electrons ψR, where the subscript indicates that they are “right moving.” It satisfies the
equation of motion (∂/∂t + vF∂/∂x)ψR = 0.
Similarly, the electrons with momentum around −kF obey the dispersion E = −vFp.
We will call the field associated with these electrons ψL with L for “left moving,” satisfying
(∂/∂t −vF∂/∂x)ψL = 0.
Emergence of the Dirac equation
The Lagrangian summarizing all this is simply
L = iψ†
R
 ∂
∂t + vF
∂
∂x

ψR + iψ†
L
 ∂
∂t −vF
∂
∂x

ψL
(2)
Introducing a 2-component field ψ =

ψL
ψR

, ¯ψ ≡ψ†γ 0 ≡ψ†σ2, and choosing units so
that vF = 1, we may write L more compactly as
L = iψ†
 ∂
∂t −σ3
∂
∂x

ψ = ¯ψiγ μ∂μψ
(3)
with γ 0 = σ2 and γ 1 = iσ1 satisfying the Clifford algebra {γ μ, γ ν} = 2gμν.

300 | V. Field Theory and Collective Phenomena
Amazingly enough, the (1 + 1)-dimensional Dirac Lagrangian emerges in a totally
nonrelativistic situation!
An instability
I will now go on to discuss an important phenomenon known as Peierls’s instability. I will
necessarily have to be a bit sketchy. I don’t have to tell you again that this is not a text on
solid state physics, but in any case you will not find it difficult to fill in the gaps.
Peierls considered a distortion in the lattice, with the ion at site j displaced from its
equilibrium position by cos[q(ja)]. (Shades of our mattress from chapter I.1!) A lattice
distortion with wave vector q = 2kF will connect electrons with momentum kF with
electrons with momentum −kF . In other words, it connects right moving ones with
left moving electrons, or in our field theoretic language ψR with ψL. Since the right
moving electrons and the left moving electrons on the surface of the Fermi sea have the
same energy (namely εF , duh!) we have the always interesting situation of degenerate
perturbation theory:

εF
0
0
εF

+

0 δ
δ 0

with eigenvalues εF ± δ. A gap opens at the surface
of the Fermi sea. Here δ represents the perturbation. Thus, Peierls concluded that the
spectrum changes drastically and the system is unstable under a perturbation with wave
vector 2kF .
A particularly interesting situation occurs when the system is half filled with electrons
(so that the density is one electron per site—recall that electrons have up and down spin).
In other words, kF = π/2a and thus 2kF = π/a. A lattice distortion of the form shown in
figure V.5.3 has precisely this wave vector. Peierls showed that a half-filled system would
want to distort the lattice in this way, doubling the unit cell. It is instructive to see how this
physical phenomenon emerges in a field theoretic formulation.
Denote the displacement of the ion at site j by dj. In the continuum limit, we should be
able to replace dj by a scalar field. Show that a perturbation connecting ψR and ψL couples
to ¯ψψ and ¯ψγ 5ψ, and that a linear combination ¯ψψ and ¯ψγ 5ψ can always be rotated to
¯ψψ by a chiral transformation (see exercise V.5.1.) Thus, we extend (3) to
L = ¯ψiγ μ∂μψ + 1
2[(∂tϕ)2 −v2(∂xϕ)2] −1
2μ2ϕ2 + gϕ ¯ψψ + . . .
(4)
Remember that you worked out the effective potential Veff(ϕ) of this (1 + 1)-dimensional
field theory in exercise IV.3.2: Veff(ϕ) goes as ϕ2 log ϕ2 for small ϕ, which overwhelms the
1
2μ2ϕ2 term. Thus, the symmetry ϕ →−ϕ is dynamically broken. The field ϕ acquires a
vacuum expectation value and ψ becomes massive. In other words, the electron spectrum
develops a gap.
Figure V.5.3

V.5. Peierls Instability | 301
Exercise
V.5.1
Parallel to the discussion in chapter II.1 you can see easily that the space of 2 by 2 matrices is spanned by
the four matrices I , γ μ, and γ 5 ≡γ 0γ 1 = σ3. (Note the peculiar but standard notation of γ 5.) Convince
yourself that 1
2(I ± γ 5) projects out right- and left handed fields just as in (3 + 1)-dimensional spacetime.
Show that in the bilinear ¯ψγ μψ left handed fields are connected to left handed fields and right handed
to right handed and that in the scalar ¯ψψ and the pseudoscalar ¯ψγ 5ψ right handed is connected to
left handed and vice versa. Finally, note that under the transformation ψ →eiθγ 5ψ the scalar and the
pseudoscalar rotate into each other. Check that this transformation leaves the massless Dirac Lagrangian
(3) invariant.

V.6
Solitons
Breaking the shackles of Feynman diagrams
When I teach quantum field theory I like to tell the students that by the mid-1970s field
theorists were breaking the shackles of Feynman diagrams. A bit melodramatic, yes,
but by that time Feynman diagrams, because of their spectacular successes in quantum
electrodynamics, were dominating the thinking of many field theorists, perhaps to excess.
As a student I was even told that Feynman diagrams define quantum field theory, that
quantum fields were merely the “slices of venison”1 used to derive the Feynman rules, and
should be discarded once the rules were obtained. The prevailing view was that it barely
made sense to write down ϕ(x). This view was forever shattered with the discovery of
topological solitons, as we will now discuss.
Small oscillations versus lumps
Consider once again our favorite toy model L = 1
2(∂ϕ)2 −V (ϕ) with the infamous double-
well potential V (ϕ) = (λ/4)(ϕ2 −v2)2 in (1 + 1)-dimensional spacetime. In chapter IV.1
we learned that of the two vacua ϕ = ±v we are to pick one and study small oscillations
around it. So, pick one and write ϕ = v + χ, expand L in χ, and study the dynamics of
the χ meson with mass μ = (λv2)
1
2. Physics then consists of suitably quantized waves
oscillating about the vacuum v.
But that is not the whole story. We can also have a time independent field configuration
with ϕ(x) (in this and the next chapter x will denote only space unless it is clearly meant
to be otherwise from the context) taking on the value −v as x →−∞and +v as x →+∞,
and changing from −v to +v around some point x0 over some length scale l as shown in
1 Gell-Mann used to speak about how pheasant meat is cooked in France between two slices of venison which
are then discarded. He forcefully advocated a program to extract and study the algebraic structure of quantum
field theories which are then discarded.

V.6. Solitons | 303
(a)
(b)
+v
−v
ϕ
x
x0
ε
x
x0
Figure V.6.1
figure V.6.1a. [Note that if we consider the Euclidean version of the field theory, identify
the time coordinate as the y coordinate, and think of ϕ(x, y) as the magnetization (as in
chapter V.3), then the configuration here describes a “domain wall” in a 2-dimensional
magnetic system.]
Think about the energy per unit length
ε(x) = 1
2
dϕ
dx
2
+ λ
4 (ϕ2 −v2)2
(1)
for this configuration, which I plot in figure V.6.1b. Far away from x0 we are in one of the
two vacua and there is no energy density. Near x0, the two terms in ε(x) both contribute to
the energy or mass M =

dx ε(x): the “spatial variation” (in a slight abuse of terminology
often called the “kinetic energy”) term

dx 1
2(dϕ/dx)2 ∼l(v/l)2 ∼v2/l, and the “potential
energy” term

dxλ(ϕ2 −v2)2 ∼lλv4. To minimize the total energy the spatial variation
term wants l to be large, while the potential term wants l to be small. The competition
dM/dl = 0 gives v2/l ∼lλv4, thus fixing l ∼(λv2)−1
2 ∼1/μ. The mass comes out to be
∼μv2 ∼μ(μ2/λ).
We have a lump of energy spread over a region of length l of the order of the Compton
wavelength of the χ meson. By translation invariance, the center of the lump x0 can be
anywhere. Furthermore, since the theory is Lorentz invariant, we can always boost to

304 | V. Field Theory and Collective Phenomena
send the lump moving at any velocity we like. Recalling a famous retort in the annals
of American politics (“It walks like a duck, quacks like a duck, so Mr. Senator, why don’t
you want to call it a duck?”) we have here a particle, known as a kink or a soliton, with
mass ∼μ(μ2/λ) and size ∼l. Perhaps because of the way the soliton was discovered,
many physicists think of it as a big lumbering object, but as we have seen, the size of a
soliton l ∼1/μ can be made as small as we like by increasing μ. So a soliton could look like
a point particle. We will come back to this point in chapter VI.3 when we discuss duality.
Topological stability
While the kink and the meson are the same size, for small λ the kink is much more
massive than the meson. Nevertheless, the kink cannot decay into mesons because it costs
an infinite amount of energy to undo the kink [by “lifting” ϕ(x) over the potential energy
barrier to change it from +v to −v for x from some point >∼x0 to +∞, for example]. The
kink is said to be topologically stable.
The stability is formally guaranteed by the conserved current
J μ = 1
2v εμν∂νϕ
(2)
with the charge
Q =
 +∞
−∞
dxJ 0(x) = 1
2v [ϕ(+∞) −ϕ(−∞)]
Mesons, which are small localized packets of oscillations in the field clearly have Q = 0,
while the kink has Q = 1. Thus, the kink cannot decay into a bunch of mesons. Incidentally,
the charge density J 0 = (1/2v)(dϕ/dx) is concentrated at x0 where ϕ changes most rapidly,
as you would expect.
Note that ∂μJ μ = 0 follows immediately from the antisymmetric symbol εμν and does
not depend on the equation of motion. The current J μ is known as a “topological current.”
Its existence does not follow from Noether’s theorem (chapter I.10) but from topology.
Our discussion also makes clear the existence of an antikink with Q = −1and described
by a configuration with ϕ(−∞) = +v and ϕ(+∞) = −v. The name is justified by consider-
ing the configuration pictured in figure V.6.2 containing a kink and an antikink far apart.
As the kink and the antikink move closer to each other, they clearly can annihilate into
mesons, since the configuration shown in figure V.6.2 and the vacuum configuration with
ϕ(x) = +v everywhere are separated by a finite amount of energy.
A nonperturbative phenomenon
That the mass of the kink comes out inversely proportional to the coupling λ is a clear sign
that field theorists could have done perturbation theory in λ till they were blue in the face
without ever discovering the kink. Feynman diagrams could not have told us about it.

V.6. Solitons | 305
Antikink
Kink
Figure V.6.2
You can calculate the mass of a kink by minimizing
M =

dx

1
2
dϕ
dx
2
+ λ
4

ϕ2 −v22
	
=
μ2
λ

μ

dy

1
2
df
dy
2
+ 1
4

f 2 −1
2
	
where in the last step we performed the obvious scaling ϕ(x) →vf (y) and y = μx. This
scaling argument immediately showed that the mass of the kink M = a(μ2/λ)μ with
a a pure number: The heuristic estimate of the mass proved to be highly trustworthy.
The actual function ϕ(x) and hence a can be computed straightforwardly with standard
variational methods.
Bogomol’nyi inequality
More cleverly, observe that the energy density (1) is the sum of two squares. Using
a2 + b2 ≥2|ab| we obtain
M ≥

dx
λ
2
 1
2 



dϕ
dx
 
ϕ2 −v2



 ≥
λ
2
 1
2





1
3ϕ3 −v2ϕ2
+∞
−∞





 =




4
3
√
2
μ
μ2
λ

Q




We have the elegant result
M ≥|Q|
(3)
with mass M measured in units of (4/3
√
2)μ(μ2/λ). This is an example of a Bogomol’nyi
inequality, which plays an important role in string theory.
Exercises
V.6.1
Show that if ϕ(x) is a solution of the equation of motion, then so is ϕ[(x −vt)/
√
1 −v2].
V.6.2
Discuss the solitons in the so-called sine-Gordon theory L = 1
2(∂ϕ)2 −g cos(βϕ). Find the topological
current. Is the Q = 2 soliton stable or not?
V.6.3
Compute the mass of the kink by the brute force method and check the result from the Bogomol’nyi
inequality.

V.7
Vortices, Monopoles, and Instantons
Vortices
The kink is merely the simplest example of a large class of topological objects in quantum
field theory.
Consider the theory of a complex scalar field in (2 + 1)-dimensional spacetime L =
∂ϕ
†∂ϕ −λ(ϕ
†ϕ −v2)2 with the now familiar Mexican hat potential. With some minor
changes in notation, this is the theory we used to describe interacting bosons and su-
perfluids. (We choose to study the relativistic rather than the nonrelativistic version but as
you will see the issue does not enter for the questions I want to discuss here.)
Are there solitons, that is, objects like the kink, in this theory?
Given some time-independent configuration ϕ(x) let us look at its mass or energy
M =

d2x[∂iϕ
†∂iϕ + λ(ϕ
†ϕ −v2)2].
(1)
The integrand is a sum of two squares, each of which must give a finite contribution. In
particular, for the contribution of the second term to be finite the magnitude of ϕ must
approach v at spatial infinity.
This finite energy requirement does not fix the phase of ϕ however. Using polar coordi-
nates (r, θ) we will consider the Ansatz ϕ −→
r→∞veiθ. Writing ϕ = ϕ1 + iϕ2, we see that the
vector (ϕ1, ϕ2) = v(cos θ, sin θ) points radially outward at infinity. Recall the definition of
the current Ji = i(∂iϕ†ϕ −ϕ†∂iϕ) in a bosonic fluid given in chapter III.5. The flow whirls
about at spatial infinity, and thus this configuration is known as the vortex.
By explicit differentiation or dimensional analysis, we have ∂iϕ ∼v(1/r) as r →∞. Now
look at the first term in M. Oops, the energy diverges logarithmically as v2 
d2x(1/r2).
Is there a way out? Not unless we change the theory.

V.7. Monopoles and Instantons | 307
Vortex into flux tubes
Suppose we gauge the theory by replacing ∂iϕ by Diϕ = ∂iϕ −ieAiϕ. Now we can achieve
finite energy by requiring that the two terms in Diϕ knock each other out so that Diϕ −→
r→∞0
faster than 1/r. In other words, Ai −→
r→∞−(i/e)(1/|ϕ|2)ϕ†∂iϕ = (1/e)∂iθ. Immediately, we
have
Flux ≡

d2xF12 =

C
dxiAi = 2π
e
(2)
where C is an infinitely large circle at spatial infinity and we have used Stokes’ theorem.
Thus, in a gauged U(1) theory the vortex carries a magnetic flux inversely proportional to
the charge. When I say magnetic, I am presuming that A represents the electromagnetic
gauge potential. The vortex discussed here appears as a flux tube in so-called type II
superconductors. It is worth remarking that this fundamental unit of flux (2) is normally
written in the condensed matter physics literature in unnatural units as
0 = hc
e
(3)
very pleasingly uniting three fundamental constants of Nature.
Homotopy groups
Since spatial infinity in 2 dimensional space is topologically a unit circle S1 and since
the field configuration with |ϕ| = v also forms a circle S1, this boundary condition can
be characterized as a map S1 →S1. Since this map cannot be smoothly deformed into the
trivial map in which S1 is mapped onto a point in S1, the corresponding field configuration
is indeed topologically stable. (Think of wrapping a loop of string around a ring.)
Mathematically, maps of Sn into a manifold M are classified by the homotopy group
n(M), which counts the number of topologically inequivalent maps. You can look up the
homotopy groups for various manifolds in tables.1 In particular, for n ≥1, n(Sn) = Z,
where Z is the mathematical notation for the set of all integers. The simplest example
1(S1) = Z is proved almost immediately by exhibiting the maps ϕ −→
r→∞veimθ, with m
any integer (positive or negative), using the context and notation of our discussion for
convenience. Clearly, this map wraps one circle around the other m times.
The language of homotopy groups is not just to impress people, but gives us a unifying
language to discuss topological solitons. Indeed, looking back you can now see that the
kink is a physical manifestation of 0(S0) = Z2, where Z2 denotes the multiplicative group
consisting of {+1, −1} (since the 0-dimensional sphere S0 = {+1, −1} consists of just two
points and is topologically equivalent to the spatial infinity in 1-dimensional space).
1 See tables 6.V and 6.VI, S. Iyanaga and Y. Kawada, eds., Encyclopedic Dictionary of Mathematics, p. 1415.

308 | V. Field Theory and Collective Phenomena
Hedgehogs and monopoles
If you absorbed all this, you are ready to move up to (3 + 1)-dimensional spacetime. Spatial
infinity is now topologically S2. By now you realize that if the scalar field lives on the
manifold M, then we have at infinity the map of S2 →M. The simplest choice is thus to
take S2 for M. Hence, we are led to scalar fields ϕa (a = 1, 2, 3) transforming as a vector ⃗ϕ
under an internal symmetry group O(3) and governed by L = 1
2∂⃗ϕ . ∂⃗ϕ −V (⃗ϕ . ⃗ϕ). (There
should be no confusion in using the arrow to indicate a vector in the internal symmetry
group.)
Let us choose V = λ(⃗ϕ2 −v2)2. The story unfolds much as the story of the vortex. The
requirement that the mass of a time independent configuration
M =

d3x[ 1
2(∂⃗ϕ)2 + λ(⃗ϕ2 −v2)2]
(4)
be finite forces |⃗ϕ| = v at spatial infinity so that ⃗ϕ(r = ∞) indeed lives on S2.
The identity map S2 →S2 indicates that we should consider a configuration such that
ϕa −→
r→∞v xa
r
(5)
This equation looks a bit strange at first sight since it mixes the index of the internal
symmetry group with the index of the spatial coordinates (but in fact we have already
encountered this phenomenon in the vortex). At spatial infinity, the field ⃗ϕ is pointing
radially outward, so this configuration is known picturesquely as a hedgehog. Draw a
picture if you don’t get it!
As in the vortex story, the requirement that the first term in (4) be finite forces us to
introduce an O(3) gauge potential Ab
μ so that we can replace the ordinary derivative ∂iϕa
by the covariant derivative Diϕa = ∂iϕa + eεabcAb
i ϕc. We can then arrange Diϕa to vanish
at infinity. Simple arithmetic shows that with (5) the gauge potential has to go as
Ab
i −→
r→∞
1
e εbij xj
r2
(6)
Imagine yourself in a lab at spatial infinity. Inside a small enough lab, the ⃗ϕ field at
different points are all pointing in approximately the same direction. The gauge group
O(3) is broken down to O(2) ≃U(1). The experimentalists in this lab observe a massless
gauge field associated with the U(1), which they might as well call the electromagnetic
field (“quacks like a duck”). Indeed, the gauge invariant tensor field
Fμν ≡
F a
μνϕa
|ϕ|
−εabcϕa(Dμϕ)b(Dνϕ)c
e|ϕ|3
(7)
can be identified as the electromagnetic field (see exercise V.7.5).
There is no electric field since the configuration is time independent and Ab
0 = 0. We
can only have a magnetic field ⃗B which you can immediately calculate since you know Ab
i ,
but by symmetry we already see that ⃗B can point only in the radial direction.
This is the fabled magnetic monopole first postulated by Dirac!

V.7. Monopoles and Instantons | 309
The presence of magnetic monopoles in spontaneously broken gauge theory was dis-
covered by ’t Hooft and Polyakov. If you calculate the total magnetic flux coming out of the
monopole

d ⃗S . ⃗B, where as usual d ⃗S denotes a small surface element at infinity pointing
radially outward, you will find that it is quantized in suitable units, exactly as Dirac had
stated, as it must (recall chapter IV.4).
We can once again write a Bogomol’nyi inequality for the mass of the monopole
M =

d3x

1
4( ⃗Fij)2 + 1
2(Di ⃗ϕ)2 + V (⃗ϕ)

(8)
[ ⃗Fij transforms as a vector under O(3); recall (IV.5.17).] Observe that
1
4( ⃗Fij)2 + 1
2(Di ⃗ϕ)2 = 1
4( ⃗Fij ± εijkDk ⃗ϕ)2 ∓1
2εijk ⃗Fij . Dk ⃗ϕ
Thus
M ≥

d3x

∓1
2εijk ⃗Fij . Dk ⃗ϕ + V (⃗ϕ)

(9)
We next note that

d3x 1
2εijk ⃗Fij . Dk ⃗ϕ =

d3x 1
2εijk∂k( ⃗Fij . ⃗ϕ) = v

d ⃗S . ⃗B = 4πvg
has an elegant interpretation in terms of the magnetic charge g of the monopole. Further-
more, if we can throw away V (⃗ϕ) while keeping |⃗ϕ| −→
r→∞v, then the inequality M ≥4πv|g|
is saturated by ⃗Fij = ±εijkDk ⃗ϕ. The solutions of this equation are known as Bogomol’nyi-
Prasad-Sommerfeld or BPS states.
It is not difficult to construct an electrically charged magnetic monopole, known as a
dyon. We simply take Ab
0 = (xb/r)f (r) with some suitable function f (r).
One nice feature of the topological monopole is that its mass comes out to be ∼MW/α ∼
137MW (exercise V.7.11), where MW denotes the mass of the intermediate vector boson of
the weak interaction. We are anticipating chapter VII.2 a bit in that the gauge boson that
becomes massive by the Anderson-Higgs mechanism of chapter IV.6 may be identified
with the intermediate vector boson. This explains naturally why the monopole has not yet
been discovered.
Instanton
Consider a nonabelian gauge theory, and rotate the path integral to 4-dimensional Eu-
clidean space. We might wish to evaluate Z =

DAe−S(A) in the steepest descent approx-
imation, in which case we would have to find the extrema of
S(A) =

d4x 1
2g2 tr FμνFμν
with finite action. This implies that at infinity |x| = ∞, Fμν must vanish faster than 1/|x|2,
and so the gauge potential Aμ must be a pure gauge: A = gdg† for g an element of the
gauge group [see (IV.5.6)]. Configurations for which this is true are known as instantons.

310 | V. Field Theory and Collective Phenomena
We see that the instanton is yet one more link in the “great chain of being”: kink-vortex-
monopole-instanton.
Choose the gauge group SU(2) to be definite. In the parametrization g = x4 + i⃗x . ⃗σ
we have by definition g†g = 1 and det g = 1, thus implying x2
4 + ⃗x2 = 1. We learn that
the group manifold of SU(2) is S3. Thus, in an instanton, the gauge potential at infinity
A −→
|x|→∞gdg† + O(1/|x|2) defines a map S3 →S3. Sound familiar? Indeed, you’ve already
seen S0 →S0, S1 →S1, S2 →S2 playing a role in field theory.
Recall from chapter IV.5 that tr F 2 = d tr(AdA + 2
3A3). Thus

tr F 2 =

S3 tr(AdA + 2
3A3) =

S3 tr(AF −1
3A3) = −1
3

S3 tr(gdg†)3
(10)
where we used the fact that F vanishes at infinity. This shows explicitly that

trF 2
depends only on the homotopy of the map S3 →S3 defined by g and is thus a topological
quantity. Incidentally,

S3 tr(gdg†)3 is known to mathematicians as the Pontryagin index
(see exercise V.7.12).
I mentioned in chapter IV.7 that the chiral anomaly is not affected by higher-order
quantum fluctuations. You are now in position to give an elegant topological proof of this
fact (exercise V.7.13).
Kosterlitz-Thouless transition
We were a bit hasty in dismissing the vortex in the nongauged theory L = ∂ϕ
†∂ϕ −λ(ϕ
†ϕ −
v2)2 in (2 + 1)-dimensional spacetime. Around a vortex ϕ ∼veiθ and so it is true, as we
have noted, that the energy of a single vortex diverges logarithmically. But what about a
vortex paired with an antivortex?
Picture a vortex and an antivortex separated by a distance R large compared to the
distance scales in the theory. Around an antivortex ϕ ∼ve−iθ. The field ϕ winds around
the vortex one way and around the antivortex the other way. Convince yourself by drawing
a picture that at spatial infinity ϕ does not wind at all: It just goes to a fixed value. The
winding one way cancels the winding the other way.
Thus, a configuration consisting of a vortex-antivortex pair does not cost infinite energy.
But it does cost a finite amount of energy: In the region between the vortex and the
antivortex ϕ is winding around, in fact roughly twice as fast (as you can see by drawing a
picture). A rough estimate of the energy is thus v2 
d2x(1/r2) ∼v2 log(R/a), where we
integrated over a region of size R, the relevant physical scale in the problem. (To make
sense of the problem we divide R by the size a of the vortex.) The vortex and the antivortex
attract each other with a logarithmic potential. In other words, the configuration cannot
be static: The vortex and the antivortex want to get together and annihilate each other in
a fiery embrace and release that finite amount of energy v2 log(R/a). (Hence the term
antivortex.)
All of this is at zero temperature, but in condensed matter physics we are interested in
the free energy F = E −T S (with S the entropy) at some temperature T rather than the

V.7. Monopoles and Instantons | 311
energy E. Appreciating this elementary point, Kosterlitz and Thouless discovered a phase
transition as the temperature is raised. Consider a gas of vortices and antivortices at some
nonzero temperature. Because of thermal agitation, the vortices and antivortices moving
around may or may not find each other to annihilate. How high do we have to crank up
the temperature for this to happen?
Let us do a heuristic estimate. Consider a single vortex. Herr Boltzmann tells us that the
entropy is the logarithm of the “number” of ways in which we can put the vortex inside
a box of size L (which we will let tend to infinity). Thus, S ∼log(L/a). The entropy S is
to battle the energy E ∼v2 log(L/a). We see that the free energy F ∼(v2 −T ) log(L/a)
goes to infinity if T <∼v2, which we identify as essentially the critical temperature Tc.
A single vortex cannot exist below Tc. Vortices and antivortices are tightly bound below
Tc but are liberated above Tc.
Black hole
The discovery in the 1970s of these topological objects that cannot be seen in perturbation
theory came as a shock to the generation of physicists raised on Feynman diagrams and
canonical quantization. People (including yours truly) were taught that the field operator
ϕ(x) is a highly singular quantum operator and has no physical meaning as such, and
that quantum field theory is defined perturbatively by Feynman diagrams. Even quite
eminent physicists asked in puzzlement what a statement such as ϕ −→
r→∞veiθ would mean.
Learned discussions that in hindsight are totally irrelevant ensued. As I said in introducing
chapter V.6, I like to refer to this historical process as “field theorists breaking the shackles
of Feynman diagrams.”
It is worth mentioning one argument physicists at that time used to convince themselves
that solitons do exist. After all, the Schwarzschild black hole, defined by the metric gμν(x)
(see chapter I.11), had been known since 1916. Just what are the components of the metric
gμν(x)? They are fields in exactly the same way that our scalar field ϕ(x) and our gauge
potential Aμ(x) are fields, and in a quantum theory of gravity gμν would have to be replaced
by a quantum operator just like ϕ and Aμ. So the objects discovered in the 1970s are
conceptually no different from the black hole known in the 1910s. But in the early 1970s
most particle theorists were not particularly aware of quantum gravity.
Exercises
V.7.1
Explain the relation between the mathematical statement 0(S0) = Z2 and the physical result that there
are no kinks with |Q| ≥2.
V.7.2
In the vortex, study the length scales characterizing the variation of the fields ϕ and A. Estimate the mass
of the vortex.

312 | V. Field Theory and Collective Phenomena
V.7.3
Consider the vortex configuration in which ϕ −→
r→∞veiνθ, with ν an integer. Calculate the magnetic flux.
Show that the magnetic flux coming out of an antivortex (for which ν = −1) is opposite to the magnetic
flux coming out of a vortex.
V.7.4
Mathematically, since g(θ) ≡eiνθ may be regarded as an element of the group U(1), we can speak of
a map of S1, the circle at spatial infinity, onto the group U(1). Calculate (i/2π)

S1 gdg†, thus showing
that the winding number is given by this integral of a 1-form.
V.7.5
Show that within a region in which ϕa is constant, Fμν as defined in the text is the electromagnetic field
strength. Compute ⃗B far from the center of a magnetic monopole and show that Dirac quantization
holds.
V.7.6
Display explicitly the map S2 →S2, which wraps one sphere around the other twice. Verify that this map
corresponds to a magnetic monopole with magnetic charge 2.
V.7.7
Write down the variational equations that minimize (8).
V.7.8
Find the BPS solution explicitly.
V.7.9
Discuss the dyon solution. Work it out in the BPS limit.
V.7.10
Verify explicitly that the magnetic monopole is rotation invariant in spite of appearances. By this is
meant that all physical gauge invariant quantities such as ⃗B are covariant under rotation. Gauge variant
quantities such as Ab
i can and do vary under rotation. Write down the generators of rotation.
V.7.11
Show that the mass of the magnetic monopole is about 137MW .
V.7.12
Evaluate n ≡−(1/24π2)

S3 tr(gdg†)3 for the map g = ei ⃗θ.⃗σ . [Hint: By symmetry, you need calculate the
integrand only in a small neighborhood of the identity element of the group or equivalently the north
pole of S3. Next, consider g = ei(θ1σ1+θ2σ2+mθ3σ3) for m an integer and convince yourself that m measures
the number of times S3 wraps around S3.] Compare with exercise V.7.4 and admire the elegance of
mathematics.
V.7.13
Prove that higher order corrections do not change the chiral anomaly ∂μJ μ
5 = [1/(4π)2]εμνλσ tr FμνFλσ
(I have rescaled A →(1/g)A). [Hint: Integrate over spacetime and show that the left hand side is given
by the number of right-handed fermion quanta minus the number of left-handed fermion quanta, so
that both sides are given by integers.]

Part VI
Field Theory and Condensed Matter

This page intentionally left blank

VI.1
Fractional Statistics, Chern-Simons Term, and
Topological Field Theory
Fractional statistics
The existence of bosons and fermions represents one of the most profound features
of quantum physics. When we interchange two identical quantum particles, the wave
function acquires a factor of either +1 or −1. Leinaas and Myrheim, and later Wilczek
independently, had the insight to recognize that in (2 + 1)-dimensional spacetime particles
can also obey statistics other than Bose or Fermi statistics, a statistics now known as
fractional or anyon statistics. These particles are now known as anyons.
To interchange two particles, we can move one of them half-way around the other and
then translate both of them appropriately. When you take one anyon half-way around
another anyon going anticlockwise, the wave function acquires a factor of eiθ where θ
is a real number characteristic of the particle. For θ = 0, we have bosons and for θ = π,
fermions. Particles half-way between bosons and fermions, with θ = π/2, are known as
semions.
After Wilczek’s paper came out, a number of distinguished senior physicists were thor-
oughly confused. Thinking in terms of Schr¨odinger’s wave function, they got into endless
arguments about whether the wave function must be single valued. Indeed, anyon statis-
tics provides a striking example of the fact that the path integral formalism is sometimes
significantly more transparent. The concept of anyon statistics can be formulated in terms
of wave functions but it requires thinking clearly about the configuration space over which
the wave function is defined.
Consider two indistinguishable particles at positions xi
1 and xi
2 at some initial time
that end up at positions xf
1 and xf
2 a time T later. In the path integral representation
for ⟨xf
1 , xf
2 |e−iHT |xi
1, xi
2⟩we have to sum over all paths. In spacetime, the worldlines of
the two particles braid around each other (see fig. VI.1.1). (We are implicitly assuming
that the particles cannot go through each other, which is the case if there is a hard core
repulsion between them.) Clearly, the paths can be divided into topologically distinct
classes, characterized by an integer n equal to the number of times the worldlines of the

316 | VI. Field Theory and Condensed Matter
t
i
1
x
x
i
2
x
f
2
x
f
1
x
Figure VI.1.1
two particles braid around each other. Since the classes cannot be deformed into each
other, the corresponding amplitudes cannot interfere quantum mechanically, and with
the amplitudes in each class we are allowed to associate an additional phase factor eiαn
beyond the usual factor coming from the action.
The dependence of αn on n is determined by how quantum amplitudes are to be
combined. Suppose one particle goes around the other through an angle ϕ1, a history to
which we assign an additional phase factor eif (ϕ1) with f some as yet unknown function.
Suppose this history is followed by another history in which our particle goes around the
other by an additional angle ϕ2. The phase factor eif (ϕ1+ϕ2) we assign to the combined
history clearly has to satisfy the composition law eif (ϕ1+ϕ2) = eif (ϕ1)eif (ϕ2). In other
words, f (ϕ) has to be a linear function of its argument.
We conclude that in (2 + 1)-dimensional spacetime we can associate with the quantum
amplitude corresponding to paths in which one particle goes around the other anti-
clockwise through an angle ϕ a phase factor ei(θ/π)ϕ, with θ an arbitrary real parameter.
Note that when one particle goes around the other clockwise through an angle ϕ the
quantum amplitude acquires a phase factor e−i θ
π ϕ.
When we interchange two anyons, we have to be careful to specify whether we do it
“anticlockwise” or “clockwise,” producing factors eiθ and e−iθ, respectively. This indicates
immediately that parity P and time reversal invariance T are violated.
Chern-Simons theory
The next important question is whether all this can be incorporated in a local quantum field
theory. The answer was given by Wilczek and Zee, who showed that the notion of fractional
statistics can result from the effect of coupling to a gauge potential. The significance of

VI.1. Topological Field Theory | 317
a field theoretic formulation is that it demonstrates conclusively that the idea of anyon
statistics is fully compatible with the cherished principles that we hold dear and that go
into the construction of quantum field theory.
Given a Lagrangian L0 with a conserved current jμ, construct the Lagrangian
L = L0 + γ εμνλaμ∂νaλ + aμjμ
(1)
Here εμνλ denotes the totally antisymmetric symbol in (2 + 1)-dimensional spacetime and
γ is an arbitrary real parameter. Under a gauge transformation aμ →aμ + ∂μ, the term
εμνλaμ∂νaλ, known as the Chern-Simons term, changes by εμνλaμ∂νaλ →εμνλaμ∂νaλ +
εμνλ∂μ∂νaλ. The action changes by δS = γ

d3xεμνλ∂μ(∂νaλ) and thus, if we are
allowed to drop boundary terms, as we assume to be the case here, the Chern-Simons
action is gauge invariant. Note incidentally that in the language of differential form you
learned in chapters IV.5 and IV.6 the Chern-Simons term can be written compactly as ada.
Let us solve the equation of motion derived from (1):
2γ εμνλ∂νaλ = −jμ
(2)
for a particle sitting at rest (so that ji = 0). Integrating the μ = 0 component of (2), we
obtain

d2x(∂1a2 −∂2a1) = −1
2γ

d2xj0
(3)
Thus, the Chern-Simons term has the effect of endowing the charged particles in the
theory with flux. (Here the term charged particles simply means particles that couple to
the gauge potential aμ. In this context, when we refer to charge and flux, we are obviously
not referring to the charge and flux associated with the ordinary electromagnetic field. We
are simply borrowing a useful terminology.)
By the Aharonov-Bohm effect (chapter IV.4), when one of our particles moves around
another, the wave function acquires a phase, thus endowing the particles with anyon
statistics with angle θ = 1/4γ (see exercise VI.1.5).
Strictly speaking, the term “fractional statistics” is somewhat misleading. First, a trivial
remark: The statistics parameter θ does not have to be a fraction. Second, statistics is
not directly related to counting how many particles we can put into a state. The statistics
between anyons is perhaps better thought of as a long ranged phase interaction between
them, mediated by the gauge potential a.
The appearance of εμνλ in (1) signals the violation of parity P and time reversal invari-
ance T , something we already know.
Hopf term
An alternative treatment is to integrate out a in (1). As explained in chapter III.4, and as
in any gauge theory, the inverse of the differential operator ε∂is not defined: It has a zero
mode since (εμνλ∂ν)(∂λF(x)) = 0 for any smooth function F(x). Let us choose the Lorenz

318 | VI. Field Theory and Condensed Matter
gauge ∂μaμ = 0. Then, using the fundamental identity of field theory (see appendix A) we
obtain the nonlocal Lagrangian
LHopf = 1
4γ

jμ
εμνλ∂ν
∂2
jλ

(4)
known as the Hopf term.
To determine the statistics parameter θ consider a history in which one particle moves
half-way around another sitting at rest. The current j is then equal to the sum of two
terms describing the two particles. Plugging into (4) we evaluate the quantum phase
eiS = ei 
d3xLHopf and obtain θ = 1/(4γ ).
Topological field theory
There is something conceptually new about the pure Chern-Simons theory
S = γ

M
d3xεμνλaμ∂νaλ
(5)
It is topological.
Recall from chapter I.11 that a field theory written in flat spacetime can be immediately
promoted to a field theory in curved spacetime by replacing the Minkowski metric ημν by
the Einstein metric gμν and including a factor √−g in the spacetime integration measure.
But in the Chern-Simons theory ημν does not appear! Lorentz indices are contracted
with the totally antisymmetric symbol εμνλ. Furthermore, we don’t need the factor √−g,
as I will now show. Recall also from chapter I.11 that a vector field transforms as aμ(x) =
(∂x′λ/∂xμ)a′
λ(x′) and so for three vector fields
εμνλaμ(x)bν(x)cλ(x) = εμνλ ∂x′σ
∂xμ
∂x′τ
∂xν
∂x′ρ
∂xλ a′
σ(x′)b′
τ(x′)c′
ρ(x′)
= det
∂x′
∂x

εστρa′
σ(x′)b′
τ(x′)c′
ρ(x′)
On the other hand, d3x′ = d3x det(∂x′/∂x). Observe, then,
d3xεμνλaμ(x)bν(x)cλ(x) = d3x′εστρa′
σ(x′)b′
τ(x′)c′
ρ(x′)
which is invariant without the benefit of √−g.
So, the Chern-Simons action in (5) is invariant under general coordinate transforma-
tion—it is already written for curved spacetime. The metric gμν does not enter anywhere.
The Chern-Simons theory does not know about clocks and rulers! It only knows about the
topology of spacetime and is rightly known as a topological field theory. In other words,
when the integral in (5) is evaluated over a closed manifold M the property of the field
theory

DaeiS(a) depends only on the topology of the manifold, and not on whatever
metric we might put on the manifold.

VI.1. Topological Field Theory | 319
Ground state degeneracy
Recall from chapter I.11 the fundamental definition of energy and momentum. The
energy-momentum tensor is defined by the variation of the action with respect to gμν , but
hey, the action here does not depend on gμν. The energy-momentum tensor and hence the
Hamiltonian is identically zero! One way of saying this is that to define the Hamiltonian
we need clocks and rulers.
What does it mean for a quantum system to have a Hamiltonian H = 0? Well, when we
took a course on quantum mechanics, if the professor assigned an exam problem to find
the spectrum of the Hamiltonian 0, we could do it easily! All states have energy E = 0. We
are ready to hand it in.
But the nontrivial problem is to find how many states there are. This number is known
as the ground state degeneracy and depends only on the topology of the manifold M.
Massive Dirac fermions and the Chern-Simons term
Consider a gauge potential aμ coupled to a massive Dirac fermion in (2 + 1)-dimensional
spacetime: L = ¯ψ(i̸∂+ ̸a −m)ψ. You did an exercise way back in chapter II.1 discovering
the rather surprising phenomenon that in (2 + 1)-dimensional spacetime the Dirac mass
term violates P and T . (What? You didn’t do it? You have to go back.) Thus, we would expect
to generate the P and T violating the Chern-Simons term εμνλaμ∂λaν if we integrate out the
fermion to get the term tr log(i̸∂+ ̸a −m) in the effective action, along the lines discussed
in chapter IV.3.
In one-loop order we have the vacuum polarization diagram (diagrammatically exactly
the same as in chapter III.7 but in a spacetime with one less dimension) with a Feynman
integral proportional to

d3p
(2π)3 tr

γ ν
1
̸p + ̸q −mγ μ
1
̸p −m

(6)
As we will see, the change 4 →3 makes all the difference in the world. I leave it to you
to evaluate (6) in detail (exercise VI.1.7) but let me point out the salient features here.
Since the ∂λ in the Chern-Simons term corresponds to qλ in momentum space, in order
to identify the coefficient of the Chern-Simons term we need only differentiate (6) with
respect to qλ and set q →0 :

d3p
(2π)3 tr(γ ν
1
̸p −mγ λ
1
̸p −mγ μ
1
̸p −m)
=

d3p
(2π)3
tr [γ ν( ̸p + m)γ λ( ̸p + m)γ μ( ̸p + m)]
(p2 −m2)3
(7)

320 | VI. Field Theory and Condensed Matter
I will simply focus on one piece of the integral, the piece coming from the term in the
trace proportional to m3:
εμνλm3

d3p
(p2 −m2)3
(8)
As I remarked in exercise II.1.12, in (2 + 1)-dimensional spacetime the γ μ’s are just the
three Pauli matrices and thus tr(γ νγ λγ μ) is proportional to εμνλ: The antisymmetric
symbol appears as we expect from P and T violation.
By dimensional analysis, we see that the integral in (8) is up to a numerical constant
equal to 1/m3 and so m cancels.
But be careful! The integral depends only on m2 and doesn’t know about the sign of m.
The correct answer is proportional to 1/|m|3, not 1/m3. Thus, the coefficient of the Chern-
Simons term is equal to m3/|m|3 = m/|m| = sign of m, up to a numerical constant. An
instructive example of an important sign! This makes sense since under P (or T ) a Dirac
field with mass m is transformed into a Dirac field with mass −m. In a parity-invariant
theory, with a doublet of Dirac fields with masses m and −m a Chern-Simons term should
not be generated.
Exercises
VI.1.1
In a nonrelativistic theory you might think that there are two separate Chern-Simons terms, εijai∂0aj and
εija0∂iaj. Show that gauge invariance forces the two terms to combine into a single Chern-Simons term
εμνλaμ∂νaλ. For the Chern-Simons term, gauge invariance implies Lorentz invariance. In contrast, the
Maxwell term would in general be nonrelativistic, consisting of two terms, f 2
0i and f 2
ij, with an arbitrary
relative coefficient between them (with fμν = ∂μaν −∂νaμ as usual).
VI.1.2
By thinking about mass dimensions, convince yourself that the Chern-Simons term dominates the
Maxwell term at long distances. This is one reason that relativistic field theorists find anyon fluids so
appealing. As long as they are interested only in long distance physics they can ignore the Maxwell
term and play with a relativistic theory (see exercise VI.1.1). Note that this picks out (2 + 1)-dimensional
spacetime as special. In (3 + 1)-dimensional spacetime the generalization of the Chern-Simons term
εμνλσfμνfλσ has the same mass dimension as the Maxwell term f 2. In (4 + 1)-dimensional space the
term ερμνλσaρfμνfλσ is less important at long distances than the Maxwell term f 2.
VI.1.3
There is a generalization of the Chern-Simons term to higher dimensional spacetime different from
that given in exercise IV.1.2. We can introduce a p-form gauge potential (see chapter IV.4). Write the
generalized Chern-Simons term in (2p + 1)-dimensional spacetime and discuss the resulting theory.
VI.1.4
Consider L = γ aε ∂a −(1/4g2)f 2. Calculate the propagator and show that the gauge boson is massive.
Some physicists puzzled by fractional statistics have reasoned that since in the presence of the Maxwell
term the gauge boson is massive and hence short ranged, it can’t possibly generate fractional statistics,
which is manifestly an infinite ranged interaction. (No matter how far apart the two particles we are
interchanging are, the wave function still acquires a phase.) The resolution is that the information is
in fact propagated over an infinite range by a q = 0 pole associated with a gauge degree of freedom.
This apparent paradox is intimately connected with the puzzlement many physicists felt when they first
heard of the Aharonov-Bohm effect. How can a particle in a region with no magnetic field whatsoever
and arbitrarily far from the magnetic flux know about the existence of the magnetic flux?

VI.1. Topological Field Theory | 321
VI.1.5
Show that θ = 1/4γ . There is a somewhat tricky factor1 of 2. So if you are off by a factor of 2, don’t despair.
Try again.
VI.1.6
Find the nonabelian version of the Chern-Simons term ada. [Hint: As in chapter IV.6 it might be easier
to use differential forms.]
VI.1.7
Using the canonical formalism of chapter I.8 show that the Chern-Simons Lagrangian leads to the
Hamiltonian H = 0.
VI.1.8
Evaluate (6).
1 X.G. Wen and A. Zee, J. de Physique, 50: 1623, 1989.

VI.2
Quantum Hall Fluids
Interplay between two pieces of physics
Over the last decade or so, the study of topological quantum fluids (of which the Hall fluid
is an example) has emerged as an interesting subject. The quantum Hall system consists
of a bunch of electrons moving in a plane in the presence of an external magnetic field
B perpendicular to the plane. The magnetic field is assumed to be sufficiently strong so
that the electrons all have spin up, say, so they may be treated as spinless fermions. As is
well known, this seemingly innocuous and simple physical situation contains a wealth of
physics, the elucidation of which has led to two Nobel prizes. This remarkable richness
follows from the interplay between two basic pieces of physics.
1. Even though the electron is pointlike, it takes up a finite amount of room.
Classically, a charged particle in a magnetic field moves in a Larmor circle of radius
r determined by evB = mv2/r. Classically, the radius is not fixed, with more energetic
particles moving in larger circles, but if we quantize the angular momentum mvr to be
h = 2π (in units in which ℏis equal to unity) we obtain eBr2 ∼2π. A quantum electron
takes up an area of order πr2 ∼2π2/eB.
2. Electrons are fermions and want to stay out of each other’s way.
Not only does each electron insist on taking up a finite amount of room, each has to
have its own room. Thus, the quantum Hall problem may be described as a sort of housing
crisis, or as the problem of assigning office space at an Institute for Theoretical Physics to
visitors who do not want to share offices.
Already at this stage, we would expect that when the number of electrons Ne is just
right to fill out space completely, namely when Neπr2 ∼Ne(2π2/eB) ∼A, the area of the
system, something special happens.

VI.2. Quantum Hall Fluids | 323
Landau levels and the integer Hall effect
These heuristic considerations could be made precise, of course. The textbook problem of
a single spinless electron in a magnetic field
−[(∂x −ieAx)2 + (∂y −ieAy)2]ψ = 2mEψ
was solved by Landau decades ago. The states occur in degenerate sets with energy
En =

n + 1
2
 eB
m , n = 0, 1, 2, . . . , known as the nth Landau level. Each Landau level has
degeneracy BA/2π, where A is the area of the system, reflecting the fact that the Larmor
circles may be placed anywhere. Note that one Landau level is separated from the next by
a finite amount of energy (eB/m).
Imagine putting in noninteracting electrons one by one. By the Pauli exclusion principle,
each succeeding electron we put in has to go into a different state in the Landau level. Since
each Landau level can hold BA/2π electrons it is natural (see exercise VI.2.1) to define a
filling factor ν ≡Ne/(BA/2π). When ν is equal to an integer, the first ν Landau levels are
filled. If we want to put in one more electron, it would have to go into the (ν + 1)st Landau
level, costing us more energy than what we spent for the preceding electron.
Thus, for ν equal to an integer the Hall fluid is incompressible. Any attempt to compress
it lessens the degeneracy of the Landau levels (the effective area A decreases and so the
degeneracy BA/2π decreases) and forces some of the electrons to the next level, costing
us lots of energy.
An electric field Ey imposed on the Hall fluid in the y direction produces a current
Jx = σxyEy in the x direction with σxy = ν (in units of e2/h). This is easily understood in
terms of the Lorentz force law obeyed by electrons in the presence of a magnetic field. The
surprising experimental discovery was that the Hall conductance σxy when plotted against
B goes through a series of plateaus, which you might have heard about. To understand
these plateaus we would have to discuss the effect of impurities. I will touch upon the
fascinating subject of impurities and disorder in chapter VI.8.
So, the integer quantum Hall effect is relatively easy to understand.
Fractional Hall effect
After the integer Hall effect, the experimental discovery of the fractional Hall effect,
namely that the Hall fluid is also incompressible for filling factor ν equal to simple odd-
denominator fractions such as 1
3 and 1
5, took theorists completely by surprise. For ν = 1
3,
only one-third of the states in the first Landau level are filled. It would seem that throwing
in a few more electrons would not have that much effect on the system. Why should the
ν = 1
3 Hall fluid be incompressible?
Interaction between electrons turns out to be crucial. The point is that saying the first
Landau level is one-third filled with noninteracting spinless electrons does not define a
unique many-body state: there is an enormous degeneracy since each of the electrons can

324 | VI. Field Theory and Condensed Matter
go into any of the BA/2π states available subject only to Pauli exclusion. But as soon as we
turn on a repulsive interaction between the electrons, a presumably unique ground state
is picked out within the vast space of degenerate states. Wen has described the fractional
Hall state as an intricate dance of electrons: Not only does each electron occupy a finite
amount of room on the dance floor, but due to the mutual repulsion, it has to be careful
not to bump into another electron. The dance has to be carefully choreographed, possible
only for certain special values of ν.
Impurities also play an essential role, but we will postpone the discussion of impurities
to chapter VI.6.
In trying to understand the fractional Hall effect, we have an important clue. You will
remember from chapter V.7 that the fundamental unit of flux is given by 2π, and thus the
number of flux quanta penetrating the plane is equal to Nφ = BA/2π. Thus, the puzzle is
that something special happens when the number of flux quanta per electron Nφ/Ne = ν−1
is an odd integer.
I arranged the chapters so that what you learned in the previous chapter is relevant to
solving the puzzle. Suppose that ν−1 flux quanta are somehow bound to each electron.
When we interchange two such bound systems there is an additional Aharonov-Bohm
phase in addition to the (−1) from the Fermi statistics of the electrons. For ν−1 odd these
bound systems effectively obey Bose statistics and can be described by a complex scalar
field ϕ. The condensation of ϕ turns out to be responsible for the physics of the quantum
Hall fluid.
Effective field theory of the Hall fluid
We would like to derive an effective field theory of the quantum Hall fluid, first obtained
by Kivelson, Hansson, and Zhang. There are two alternative derivations, a long way and a
short way.
In the long way, we start with the Lagrangian describing spinless electrons in a magnetic
field in the second quantized formalism (we will absorb the electric charge e into Aμ),
L = ψ+ i(∂0 −i A0) ψ + 1
2m ψ†(∂i −i Ai)2ψ + V (ψ†ψ)
(1)
and massage it into the form we want. In the previous chapter, we learned that by intro-
ducing a Chern-Simons gauge field we can transform ψ into a scalar field. We then invoke
duality, which we will learn about in the next chapter, to represent the phase degree of
freedom of the scalar field as a gauge field. After a number of steps, we will discover that
the effective theory of the Hall fluid turns out to be a Chern-Simons theory.
Instead, I will follow the short way. We will argue by the “what else can it be” method
or, to put it more elegantly, by invoking general principles.
Let us start by listing what we know about the Hall system.
1. We live in (2 + 1)-dimensional spacetime (because the electrons are restricted to a plane.)
2. The electromagnetic current Jμ is conserved: ∂μJ μ = 0.

VI.2. Quantum Hall Fluids | 325
These two statements are certainly indisputable; when combined they tell us that the
current can be written as the curl of a vector potential
J μ = 1
2π ϵμνλ∂νaλ
(2)
The factor of 1/(2π) defines the normalization of aμ. We learned in school that in 3-
dimensional spacetime, if the divergence of something is zero, then that something is
the curl of something else. That is precisely what (2) says. The only sophistication here is
that what we learned in school works in Minkowskian space as well as Euclidean space—it
is just a matter of a few signs here and there.
The gauge potential comes looking for us
Observe that when we transform aμ by aμ →aμ −∂μ, the current is unchanged. In other
words, aμ is a gauge potential.
We did not go looking for a gauge potential; the gauge potential came looking for us!
There is no place to hide. The existence of a gauge potential follows from completely
general considerations.
3. We want to describe the system field theoretically by an effective local Lagrangian.
4. We are only interested in the physics at long distance and large time, that is, at small
wave number and low frequency.
Indeed, a field theoretic description of a physical system may be regarded as a means of
organizing various aspects of the relevant physics in a systematic way according to their
relative importance at long distances and according to symmetries. We classify terms in a
field theoretic Lagrangian according to powers of derivatives, powers of the fields, and so
forth. A general scheme for classifying terms is according to their mass dimensions, as
explained in chapter III.2. The gauge potential aμ has dimension 1, as is always the case for
any gauge potential coupled to matter fields according to the gauge principle, and thus (2)
is consistent with the fact that the current has mass dimension 2 in (2 + 1)-dimensional
spacetime.
5. Parity and time reversal are broken by the external magnetic field.
This last statement is just as indisputable as statements 1 and 2. The experimentalist
produces the magnetic field by driving a current through a coil with the current flowing
either clockwise or anticlockwise.
Given these five general statements we can deduce the form of the effective Lagrangian.
Since gauge invariance forbids the dimension-2 term aμaμ in the Lagrangian, the
simplest possible term is in fact the dimension-3 Chern-Simons term ϵμνλaμ∂νaλ. Thus,
the Lagrangian is simply
L = k
4π aϵ∂a + . . .
(3)
where k is a dimensionless parameter to be determined.

326 | VI. Field Theory and Condensed Matter
We have introduced and will use henceforth the compact notation ϵa∂b ≡ϵμνλ aμ∂νbλ =
ϵb∂a for two vector fields aμ and bμ.
The terms indicated by (. . .) in (3) include the dimension-4 Maxwell term (1/g2)(f 2
0i −
βf 2
ij) and other terms with higher dimensions. (Here β is some constant; see exer-
cise VI.1.1.) The important observation is that these higher dimensional terms are less
important at long distances. The long distance physics is determined purely by the Chern-
Simons term. In general the coefficient k may well be zero, in which case the physics is
determined by the short distance terms represented by the (. . .) in (3). Put differently, a
Hall fluid may be defined as a 2-dimensional electron system for which the coefficient of
the Chern-Simons term does not vanish, and consequently is such that its long distance
physics is largely independent of the microscopic details that define the system. Indeed,
we can classify 2-dimensional electron systems according to whether k is zero or not.
Coupling the system to an “external” or “additional” electromagnetic gauge potential Aμ
and using (2) we obtain (after integrating by parts and dropping a surface term)
L = k
4π ϵμνλaμ∂νaλ −1
2π ϵμνλAμ∂νaλ = k
4π ϵμνλaμ∂νaλ −1
2π ϵμνλaμ∂νAλ
(4)
Note that the gauge potential of the magnetic field responsible for the Hall effect should
not be included in Aμ; it is implicitly contained already in the coefficient k.
The notion of quasiparticles or “elementary” excitations is basic to condensed matter
physics. The effects of a many-body interaction may be such that the quasiparticles in the
system are no longer electrons. Here we define the quasiparticles as the entities that couple
to the gauge potential and thus write
L = k
4π aϵ∂a + aμjμ −1
2π ϵμνλaμ∂νAλ . . .
(5)
Defining ˜jμ ≡jμ −(1/2π)ϵμνλ ∂νAλ and integrating out the gauge field we obtain (see
VI.1.4)
L = π
k
˜jμ
ϵμνλ∂ν
∂2

˜jλ
(6)
Fractional charge and statistics
We can now simply read off the physics from (6). The Lagrangian contains three types
of terms: AA, Aj, and jj. The AA term has the schematic form A(ϵ∂ϵ∂ϵ∂/∂2)A. Using
ϵ∂ϵ∂∼∂2 and canceling between numerator and denominator, we obtain
L =
1
4πk Aϵ∂A
(7)
Varying with respect to A we determine the electromagnetic current
J μ
em =
1
4πk ϵμνλ∂νAλ
(8)

VI.2. Quantum Hall Fluids | 327
We learn from the μ = 0 component of this equation that an excess density δn of electrons
is related to a local fluctuation of the magnetic field byδn = (1/2πk)δB; thus we can identify
the filling factor ν as 1/k, and from the μ = i components that an electric field produces
a current in the orthogonal direction with σxy = (1/k) = ν.
The Aj term has the schematic form A(ϵ∂ϵ∂/∂2)j. Canceling the differential operators,
we find
L = 1
k Aμjμ
(9)
Thus, the quasiparticle carries electric charge 1/k.
Finally, the quasiparticles interact with each other via
L = π
k jμ ϵμνλ∂
∂2
jλ
(10)
We simply remove the twiddle sign in (6). Recalling chapter VI.1 we see that quasiparticles
obey fractional statistics with
θ
π = 1
k
(11)
By now, you may well be wondering that while all this is fine and good, what would
actually tell us that ν−1 has to be an odd integer?
We now argue that the electron or hole should appear somewhere in the excitation
spectrum. After all, the theory is supposed to describe a system of electrons and thus
far our rather general Lagrangian does not contain any reference to the electron!
Let us look for the hole (or electron). We note from (9) that a bound object made up of
k quasiparticles would have charge equal to 1. This is perhaps the hole! For this to work,
we see that k has to be an integer. So far so good, but k doesn’t have to be odd yet.
What is the statistics of this bound object? Let us move one of these bound objects half-
way around another such bound object, thus effectively interchanging them. When one
quasiparticle moves around another we pick up a phase given by θ/π = 1/k according to
(11). But here we have k quasiparticles going around k quasiparticles and so we pick up a
phase
θ
π = 1
k k2 = k
(12)
For the hole to be a fermion we must require θ/π to be an odd integer. This fixes k to be
an odd integer.
Since ν = 1/k, we have here the classic Laughlin odd-denominator Hall fluids with filling
factor ν = 1
3, 1
5, 1
7 , . . . . The famous result that the quasiparticles carry fractional charge and
statistics just pops out [see (9) and (11)].
This is truly dramatic: a bunch of electrons moving around in a plane with a magnetic
field corresponding to ν = 1
3, and lo and behold, each electron has fragmented into three
pieces, each piece with charge 1
3 and fractional statistics 1
3!

328 | VI. Field Theory and Condensed Matter
A new kind of order
The goal of condensed matter physics is to understand the various states of matter. States
of matter are characterized by the presence (or absence) of order: a ferromagnet becomes
ordered below the transition temperature. In the Landau-Ginzburg theory, as we saw in
chapter V.3, order is associated with spontaneous symmetry breaking, described naturally
with group theory. Girvin and MacDonald first noted that the order in Hall fluids does not
really fit into the Landau-Ginzburg scheme: We have not broken any obvious symmetry.
The topological property of the Hall fluids provides a clue to what is going on. As explained
in the preceding chapter, the ground state degeneracy of a Hall fluid depends on the
topology of the manifold it lives on, a dependence group theory is incapable of accounting
for. Wen has forcefully emphasized that the study of topological order, or more generally
quantum order, may open up a vast new vista on the possible states of matter.1
Comments and generalization
Let me conclude with several comments that might spur you to explore the wealth of
literature on the Hall fluid.
1. The appearance of integers implies that our result is robust. A slick argument can
be made based on the remark in the previous chapter that the Chern-Simons term does
not know about clocks and rulers and hence can’t possibly depend on microphysics such
as the scattering of electrons off impurities which cannot be defined without clocks and
rulers. In contrast, the physics that is not part of the topological field theory and described
by (. . .) in (3) would certainly depend on detailed microphysics.
2. If we had followed the long way to derive the effective field theory of the Hall fluid, we
would have seen that the quasiparticle is actually a vortex constructed (as in chapter V.7)
out of the scalar field representing the electron. Given that the Hall fluid is incompressible,
just about the only excitation you can think of is a vortex with electrons coherently whirling
around.
3. In the previous chapter we remarked that the Chern-Simons term is gauge invariant
only upon dropping a boundary term. But real Hall fluids in the laboratory live in samples
with boundaries. So how can (3) be correct? Remarkably, this apparent “defect” of the theory
actually represents one of its virtues! Suppose the theory (3) is defined on a bounded 2-
dimensional manifold, a disk for example. Then as first argued by Wen there must be
physical degrees of freedom living on the boundary and represented by an action whose
change under a gauge transformation cancels the change of

d3x(k/4π)aϵ ∂a. Physically,
it is clear that an incompressible fluid would have edge excitations2 corresponding to waves
on its boundary.
1 X. G. Wen, Quantum Field Theory of Many-Body Systems.
2 The existence of edge currents in the integer Hall fluid was first pointed out by Halperin.

VI.2. Quantum Hall Fluids | 329
4. What if we refuse to introduce gauge potentials? Since the current Jμ has dimension
2, the simplest term constructed out of the currents, JμJ μ, is already of dimension 4;
indeed, this is just the Maxwell term. There is no way of constructing a dimension 3 local
interaction out of the currents directly. To lower the dimension we are forced to introduce
the inverse of the derivative and write schematically J(1/ϵ∂)J, which is of course just the
non-local Hopf term. Thus, the question “why gauge field?” that people often ask can be
answered in part by saying that the introduction of gauge fields allows us to avoid dealing
with nonlocal interactions.
5. Experimentalists have constructed double-layered quantum Hall systems with an
infinitesimally small tunneling amplitude for electrons to go from one layer to the other.
Assuming that the current J μ
I (I = 1, 2) in each layer is separately conserved, we introduce
two gauge potentials by writing J μ
I =
1
2π ϵμνλ∂νaIλ as in (2). We can repeat our general
argument and arrive at the effective Lagrangian
L =

I ,J
KIJ
4π aIϵ∂aJ + . . .
(13)
The integer k has been promoted to a matrix K. As an exercise, you can derive the Hall
conductance, the fractional charge, and the statistics of the quasiparticles. You would not
be surprised that everywhere 1/k appears we now have the matrix inverse K−1 instead.
An interesting question is what happens when K has a zero eigenvalue. For example, we
could have K =

1 1
1 1

. Then the low energy dynamics of the gauge potential a−≡a1 −a2
is not governed by the Chern-Simons term, but by the Maxwell term in the (. . .) in (13).
We have a linearly dispersing mode and thus a superfluid! This striking prediction3 was
verified experimentally.
6. Finally, an amusing remark: In this formalism electron tunneling corresponds to the
nonconservation of the current J μ
−≡J μ
1 −J μ
2 = (1/2π)ϵμνλ∂νa−λ. The difference N1 −N2
of the number of electrons in the two layers is not conserved. But how can ∂μJ μ
−̸= 0 even
though J μ
−is the curl of a−λ (as I have indicated explicitly)? Recalling chapter IV.4, you the
astute reader say, aha, magnetic monopoles! Tunneling in a double-layered Hall system in
Euclidean spacetime can be described as a gas of monopoles and antimonopoles.4 (Think,
why monopoles and antimonopoles?) Note of course that these are not monopoles in the
usual electromagnetic gauge potential but in the gauge potential a−λ.
What we have given in this section is certainly a very slick derivation of the effective
long distance theory of the Hall fluid. Some would say too slick. Let us go back to our
five general statements or principles. Of these five, four are absolutely indisputable. In
fact, the most questionable is the statement that looks the most innocuous to the casual
reader, namely statement 3. In general, the effective Lagrangian for a condensed matter
system would be nonlocal. We are implicitly assuming that the system does not contain a
massless field, the exchange of which would lead to a nonlocal interaction.5 Also implicit
3 X. G. Wen and A. Zee, Phys. Rev. Lett. 69: 1811, 1992.
4 X. G. Wen and A. Zee, Phys. Rev. B47: 2265, 1993.
5 A technical remark: Vortices (i.e., quasiparticles) pinned to impurities in the Hall fluid can generate an
interaction nonlocal in time.

330 | VI. Field Theory and Condensed Matter
in (3) is the assumption that the Lagrangian can be expressed completely in terms of the
gauge potential a. A priori, we certainly do not know that there might not be other relevant
degrees of freedom. The point is that as long as these degrees of freedom are not gapless
they can be safely integrated out.
Exercises
VI.2.1
To define filling factor precisely, we have to discuss the quantum Hall system on a sphere rather than on
a plane. Put a magnetic monopole of strength G (which according to Dirac can be only a half-integer or
an integer) at the center of a unit sphere. The flux through the sphere is equal to Nφ = 2G. Show that the
single electron energy is given by El = ( 1
2ℏωc)

l(l + 1) −G2
/G with the Landau levels corresponding
to l = G, G + 1, G + 2, . . . , and that the degeneracy of the lth level is 2l + 1. With L Landau levels filled
with noninteracting electrons (ν = L) show that Nφ = ν−1Ne −S, where the topological quantity S is
known as the shift.
VI.2.2
For a challenge, derive the effective field theory for Hall fluids with filling factor ν = m/k with k an
odd integer, such as ν = 2
5 . [Hint: You have to introduce m gauge potentials aIλ and generalize (2) to
J μ = (1/2π)ϵμνλ∂ν
m
I=1 aIλ. The effective theory turns out to be
L = 1
4π
m

I ,J=1
aIKIJϵ∂aJ +
m

I=1
aIμ ˜jIμ + . . .
with the integer k replaced by a matrix K. Compare with (13).]
VI.2.3
For the Lagrangian in (13), derive the analogs of (8), (9), and (11).

VI.3
Duality
A far reaching concept
Duality is a profound and far reaching concept1 in theoretical physics, with origins in
electromagnetism and statistical mechanics. The emergence of duality in recent years in
several areas of modern physics, ranging from the quantum Hall fluids to string theory,
represents a major development in our understanding of quantum field theory. Here I
touch upon one particular example just to give you a flavor of this vast subject.
My plan is to treat a relativistic theory first, and after you get the hang of the subject, I
will go on to discuss the nonrelativistic theory. It makes sense that some of the interesting
physics of the nonrelativistic theory is absent in the relativistic formulation: A larger
symmetry is more constraining. By the same token, the relativistic theory is actually much
easier to understand if only because of notational simplicity.
Vortices
Couple a scalar field in (2 + 1)-dimensions to an external electromagnetic gauge potential,
with the electric charge q indicated explicitly for later convenience:
L = 1
2|(∂μ −iqAμ)ϕ|2 −V (ϕ†ϕ)
(1)
We have already studied this theory many times, most recently in chapter V.7 in connection
with vortices. As usual, write ϕ = |ϕ|eiθ. Minimizing the potential V at |ϕ| = v gives the
ground state field configuration. Setting ϕ = veiθ in (1) we obtain
L = 1
2v2(∂μθ −qAμ)2
(2)
1 For a first introduction to duality, I highly recommend J. M. Figueroa-O’Farrill, Electromagnetic Duality for
Children, http://www.maths.ed.ac.uk/~jmf/Teaching/Lectures/EDC.html.

332 | VI. Field Theory and Condensed Matter
which upon absorbing θ into A by a gauge transformation we recognize as the Meissner
Lagrangian. For later convenience we also introduce the alternative form
L = −1
2v2ξ2
μ + ξμ(∂μθ −qAμ)
(3)
We recover (2) upon eliminating the auxiliary field ξμ (see appendix A and chapter III.5).
In chapter V.7 we learned that the excitation spectrum includes vortices and anti-
vortices, located where |ϕ| vanishes. If, around the zero of |ϕ|, θ changes by 2π, we have
a vortex. Around an antivortex, θ = −2π. Recall that around a vortex sitting at rest, the
electromagnetic gauge potential has to go as
qAi →∂iθ
(4)
at spatial infinity in order for the energy of the vortex to be finite, as we can see from (2).
The magnetic flux

d2xεij∂iAj =

d ⃗x . ⃗A = θvortex
q
= 2π
q
(5)
is quantized in units of 2π/q.
Let us pause to think physically for a minute. On a distance scale large compared to the
size of the vortex, vortices and antivortices appear as points. As discussed in chapter V.7,
the interaction energy of a vortex and an antivortex separated by a distance R is given
by simply plugging into (2). Ignoring the probe field Aμ, which we can take to be as
weak as possible, we obtain ∼
 R
a dr r(∇θ)2 ∼log(R/a) where a is some short distance
cutoff. But recall that the Coulomb interaction in 2-dimensional space is logarithmic since
by dimensional analysis

d2k(ei⃗k.⃗x/k2) ∼log(|⃗x|/a) (with a−1 some ultraviolet cutoff).
Thus, a gas of vortices and antivortices appears as a gas of point “charges” with a Coulomb
interaction between them.
Vortex as charge in a dual theory
Duality is often made out by some theorists to be a branch of higher mathematics but
in fact it derives from an entirely physical idea. In view of the last paragraph, can we not
rewrite the theory so that vortices appear as point “charges” of some as yet unknown gauge
field? In other words, we want a dual theory in which the fundamental field creates and
annihilates vortices rather than ϕ quanta. We will explain the word “dual” in due time.
Remarkably, the rewriting can be accomplished in just a few simple steps. Proceeding
physically and heuristically, we picture the phase field θ as smoothly fluctuating, except
that here and there it winds around 2π. Write ∂μθ = ∂μθsmooth + ∂μθvortex. Plugging into
(3) we write
L = −1
2v2ξ2
μ + ξμ(∂μθsmooth + ∂μθvortex −qAμ)
(6)
Integrate over θsmooth and obtain the constraint ∂μξμ = 0, which can be solved by writing
ξμ = εμνλ∂νaλ
(7)

VI.3. Duality | 333
a trick we used earlier in chapter VI.2. As in that chapter, a gauge potential comes looking
for us, since the change aλ →aλ + ∂λ does not change ξμ. Plugging into (6), we find
L = −1
4v2f 2
μν + εμνλ∂νaλ(∂μθvortex −qAμ)
(8)
where fμν = ∂μaν −∂νaμ.
Our treatment is heuristic because we ignore the fact that |ϕ| vanishes at the vortices.
Physically, we think of the vortices as almost pointlike so that |ϕ| = v “essentially” every-
where. As mentioned in chapter V.6, by appropriate choice of parameters we can make
solitons, vortices, and so on as small as we like. In other words, we neglect the coupling
between θvortex and |ϕ|. A rigorous treatment would require a proper short distance cutoff
by putting the system on a lattice.2 But as long as we capture the essential physics, as we
assuredly will, we will ignore such niceties.
Note for later use that the electromagnetic current J μ, defined as the coefficient of −Aμ
in (8), is determined in terms of the gauge potential aλ to be
J μ = qεμνλ∂νaλ
(9)
Let us integrate the term εμνλ∂νaλ∂μθvortex in (8) by parts to obtain aλελμν∂μ∂νθvortex.
According to Newton and Leibniz, ∂μ commutes with ∂ν, and so apparently we get zero.
But ∂μ and ∂ν commute only when acting on a globally defined function, and, heavens to
Betsy, θvortex is not globally defined since it changes by 2π when we go around a vortex.
In particular, consider a vortex at rest and look at the quantity a0 couples to in (8) namely
εij∂i∂jθvortex = ⃗∇× ( ⃗∇θvortex) in the notation of elementary physics. Integrating this over
a region containing the vortex gives

d2x ⃗∇× ( ⃗∇θvortex) =

d ⃗x . ⃗∇θvortex = 2π. Thus, we
recognize (1/2π)εij∂i∂jθvortex as the density of vortices, the time component of some vortex
current jλ
vortex. By Lorentz invariance, jλ
vortex = (1/2π)ελμν∂μ∂νθvortex.
Thus, we can now write (8) as
L = −1
4v2f 2
μν + (2π)aμjμ
vortex −Aμ(qεμνλ∂νaλ)
(10)
Lo and behold, we have accomplished what we set out to do. We have rewritten the theory
so that the vortex appears as an “electric charge” for the gauge potential aμ. Sometimes
this is called a dual theory, but strictly speaking, it is more accurate to refer to it as the dual
representation of the original theory (1).
Let us introduce a complex scalar field , which we will refer to as the vortex field,
to create and annihilate the vortices and antivortices. In other words, we “elaborate” the
description in (10) to
L = −1
4v2f 2
μν + 1
2|(∂μ −i(2π)aμ)|2 −W() −Aμ(qεμνλ∂νaλ)
(11)
2 For example, M. P. A. Fisher, “Mott Insulators, Spin Liquids, and Quantum Disordered Superconductivity,”
cond-mat/9806164, appendix A.

334 | VI. Field Theory and Condensed Matter
The potential W() contains terms such as λ(†)2 describing the short distance inter-
action of two vortices (or a vortex and an antivortex.) In principle, if we master all the short
distance physics contained in the original theory (1) then these terms are all determined
by the original theory.
Vortex of a vortex
Now we come to the most fascinating aspect of the duality representation and the reason
why the word “dual” is used in the first place. The vortex field  is a complex scalar field,
just like the field ϕ we started with. Thus we can perfectly well form a vortex out of ,
namely a place where  vanishes and around which the phase of  goes through 2π.
Amusingly, we are forming a vortex of a vortex, so to speak.
So, what is a vortex of a vortex?
The duality theorem states that the vortex of a vortex is nothing but the original charge,
described by the field ϕ we started out with! Hence the word duality.
The proof is remarkably simple. The vortex in the theory (11) carries “magnetic flux.”
Referringto(11)weseethat2πai →∂iθ atspatialinfinity.Byexactlythesamemanipulation
as in (5), we have
2π

d2xεij∂iaj = 2π

d ⃗x . ⃗a = 2π
(12)
Note that I put quotation marks around the term “magnetic flux” since as is evident I am
talking about the flux associated with the gauge potential aμ and not the flux associated
with the electromagnetic potential Aμ. But remember that from (9) the electromagnetic
current J μ = qεμνλ∂νaλ and in particular J 0 = qεij∂iaj. Hence, the electric charge (note
no quotation marks) of this vortex of a vortex is equal to

d2xJ 0 = q, precisely the charge
of the original complex scalar field ϕ. This proves the assertion.
Here we have studied vortices, but the same sort of duality also applies to monopoles.
As I remarked in chapter IV.4, duality allows us a glimpse into field theories in the strongly
coupled regime. We learned in chapter V.7 that certain spontaneously broken nonabelian
gauge theories in (3 + 1)-dimensional spacetime contains magnetic monopoles. We can
write a dual theory in terms of the monopole field out of which we can construct mono-
poles. The monopole of a monopole turns out be none other than the charged fields of the
original gauge theory. This duality was first conjectured many years ago by Olive and Mon-
tonen and later shown to be realized in certain supersymmetric gauge theories by Seiberg
and Witten. The understanding of this duality was a “hot” topic a few years ago as it led
to deep new insight about how certain string theories are dual to each other.3 In contrast,
according to one of my distinguished condensed matter colleagues, the important notion
of duality is still underappreciated in the condensed matter physics community.
3 For example, D. I. Olive and P. C. West, eds., Duality and Supersymmetric Theories.

VI.3. Duality | 335
Meissner begets Maxwell and so on
We will close by elaborating slightly on duality in (2 + 1)-dimensional spacetime and how
it might be relevant to the physics of 2-dimensional materials. Consider a Lagrangian L(a)
quadratic in a vector field aμ. Couple an external electromagnetic gauge potential Aμ to
the conserved current εμνλ∂νaλ :
L = L(a) + Aμ(εμνλ∂νaλ)
(13)
Let us ask: For various choices of L(a), if we integrate out a what is the effective
Lagrangian L(A) describing the dynamics of A?
If you have gotten this far in the book, you can easily do the integration. The central
identity of quantum field theory again! Given
L(a) ∼aKa
(14)
we have
L(A) ∼(ε∂A) 1
K (ε∂A) ∼A(ε∂1
K ε∂)A
(15)
We have three choices for L(a) to which I attach various illustrious names:
L(a) ∼a2
Meissner
L(a) ∼aε∂a
Chern-Simons
(16)
L(a) ∼f 2 ∼a∂2a Maxwell
Since we are after conceptual understanding, I won’t bother to keep track of indices and
irrelevant overall constants. (You can fill them in as an exercise.) For example, given
L(a) = fμνf μν with fμν = ∂μaν −∂νaμ we can write L(a) ∼a∂2a and so K = ∂2. Thus,
the effective dynamics of the external electromagnetic gauge potential is given by (15) as
L(A) ∼A[ε∂(1/∂2)ε∂]A ∼A2, the Meissner Lagrangian! In this “quick and dirty” way of
making a living, we simply set εε ∼1 and cancel factors of ∂in the numerator against
those in the denominator. Proceeding in this way, we construct the following table:
Dynamics of a
K
Effective Lagrangian
L(A) ∼A[ε∂(1/K)ε∂]A
Dynamics of the
external probe A
Meissner a2
1
A(ε∂ε∂)A ∼A∂2A
Maxwell F 2
Chern-Simons aε∂a ε∂A(ε∂1
ε∂ε∂)A ∼Aε∂A
Chern-Simons
Aε∂A
Maxwell f 2 ∼a∂2a
∂2 A(ε∂1
∂2ε∂)A ∼AA
Meissner A2
(17)

336 | VI. Field Theory and Condensed Matter
Meissner begets Maxwell, Chern-Simons begets Chern-Simons, and Maxwell begets
Meissner. I find this beautiful and fundamental result, which represents a form of duality,
very striking. Chern-Simons is self-dual: It begets itself.
Going nonrelativistic
It is instructive to compare the nonrelativistic treatment of duality.4 Go back to the super-
fluid Lagrangian of chapter V.1:
L = iϕ†∂0ϕ −1
2m∂iϕ†∂iϕ −g2(ϕ†ϕ −¯ρ)2
(18)
As before, substitute ϕ ≡√ρeiθ to obtain
L = −ρ∂0θ −ρ
2m(∂iθ)2 −g2(ρ −¯ρ)2 + . . .
(19)
which we rewrite as
L = −ξμ∂μθ + m
2ρ ξ2
i −g2(ρ −¯ρ)2 + . . .
(20)
In (19) we have dropped a term ∼(∂iρ1/2)2. In (20) we have defined ξ0 ≡ρ. Integrating
out ξi in (20) we recover (19).
All proceeds as before. Writing θ = θsmooth + θvortex and integrating out θsmooth, we
obtain the constraint ∂μξμ = 0, solved by writing ξμ = ϵμνλ∂ν ˆaλ. The hat on ˆaλ is for later
convenience. Note that the density
ξ0 ≡ρ = ϵij∂i ˆaj ≡ˆf
(21)
is the “magnetic” field strength while
ξi = ϵij(∂0ˆaj −∂j ˆa0) ≡ϵij ˆf0j
(22)
is the “electric” field strength.
Putting all of this into (20) we have
L = m
2ρ
ˆf 2
0i −g2( ˆf −¯ρ)2 −2π ˆaμjμ
vortex + . . .
(23)
To “subtract out” the background “magnetic” field ¯ρ, an obviously sensible move is to write
ˆaμ = ¯aμ + aμ
(24)
where we define the background gauge potential by ¯a0 = 0, ∂0¯aj = 0 (no background
“electric” field) and
ϵij∂i ¯aj = ¯ρ
(25)
4 The treatment given here follows essentially that given by M. P. A. Fisher and D. H. Lee.

VI.3. Duality | 337
The Lagrangian (23) then takes on the cleaner form
L =
 m
2 ¯ρ f 2
0i −g2f 2

−2πaμjμ
vortex −2π ¯aiji
vortex + . . .
(26)
We have expanded ρ ∼¯ρ in the first term. As in (10) the first two terms form the Maxwell
Lagrangian, and the ratio of their coefficients determines the speed of propagation
c =
2g2 ¯ρ
m
1/2
(27)
In suitable units in which c = 1, we have
L = −m
4 ¯ρ fμνf μν −2πaμjμ
vortex −2π ¯aiji
vortex + . . .
(28)
Compare this with (10).
The one thing we missed with our relativistic treatment is the last term in (28), for
the simple reason that we didn’t put in a background. Recall that the term like AiJi in
ordinary electromagnetism means that a moving particle associated with the current Ji
sees a magnetic field ⃗∇× ⃗A. Thus, a moving vortex will see a “magnetic field”
ϵij∂i(¯a + a)j = ¯ρ + ϵij∂iaj
(29)
equal to the sum of ¯ρ, the density of the original bosons, and a fluctuating field.
In the Coulomb gauge ∂iai = 0 we have (f0i)2 = (∂0ai)2 + (∂ia0)2, where the cross term
(∂0ai)(∂ia0) effectively vanishes upon integration by parts. Integrating out the Coulomb
field a0, we obtain
L = −
¯ρ
2m(2π)2
 
d2xd2y

j0(⃗x) log |⃗x −⃗y|
a
j0(⃗y)

+ m
2 ¯ρ (∂0ai)2 −g2f 2 + 2π(ai + ¯ai)jvortex
i
(30)
The vortices repel each other by a logarithmic interaction

d2k(ei⃗k.⃗x/k2) ∼log(|⃗x|/a) as
we have known all along.
A self-dual theory
Interestingly, the spatial part f 2 of the Maxwell Lagrangian comes from the short ranged
repulsion between the original bosons.
If we had taken the bosons to interact by an arbitrary potential V (x) we would have,
instead of the last term in (20),
 
d2xd2y [ρ(x) −¯ρ] V (x −y) [ρ(y) −¯ρ]
(31)
It is easy to see that all the steps go through essentially as before, but now the second term
in (26) becomes
 
d2xd2yf (x)V (x −y)f (y)
(32)

338 | VI. Field Theory and Condensed Matter
Thus, the gauge field propagates according to the dispersion relation
ω2 = (2 ¯ρ/m)V (k)⃗k2
(33)
where V (k) is the Fourier transformation of V (x). In the special case V (x) = g2δ(2)(x) we
recover the linear dispersion given in (27). Indeed, we have a linear dispersion ω ∝|⃗k| as
long as V (x) is sufficiently short ranged for V (⃗k = 0) to be finite.
An interesting case is when V (x) is logarithmic. Then V (k) goes as 1/k2 and so ω ∼
constant: The gauge field ai becomes massive and drops out. The low energy effective
theory consists of a bunch of vortices with a logarithmic interaction between them. Thus,
a theory of bosons with a logarithmic repulsion between them is self dual in the low energy
limit.
The dance of vortices and antivortices
Having gone through this nonrelativistic discussion of duality, let us reward ourselves by
deriving the motion of vortices in a fluid. Let the bulk of the fluid be at rest. According to (28)
the vortex behaves like a charged particle in a background magnetic field ¯b proportional to
the mean density of the fluid ¯ρ. Thus, the force acting on a vortex is the usual Lorentz force
⃗v × ⃗B, and the equation of motion of the vortex in the presence of a force F is then just
¯ρϵij ˙xj = Fi
(34)
This is the well-known result that a vortex, when pushed, moves in a direction perpendic-
ular to the force.
Consider two vortices. According to (30) they repel each other by a logarithmic inter-
action. They move perpendicular to the force. Thus, they end up circling each other. In
contrast, consider a vortex and an antivortex, which attract each other. As a result of this
attraction, they both move in the same direction, perpendicular to the straight line joining
them (see fig. VI.3.1). The vortex and antivortex move along in step, maintaining the dis-
tance between them. This in fact accounts for the famous motion of a smoke ring. If we
cut a smoke ring through its center and perpendicular to the plane it lies in, we have just
+
+
_
(a)
(b)
+
Figure VI.3.1

VI.3. Duality | 339
a vortex with an antivortex for each section. Thus, the entire smoke ring moves along in a
direction perpendicular to the plane it lies in.
All of this can be understood by elementary physics, as it should be. The key observation
is simply that vortices and antivortices produce circular flows in the fluid around them, say
clockwise for vortices and anticlockwise for antivortices. Another basic observation is that
if there is a local flow in the fluid, then any object, be it a vortex or an antivortex, caught in
it would just flow along in the same direction as the local flow. This is a consequence of
Galilean invariance. By drawing a simple picture you can see that this produces the same
pattern of motion as discussed above.

VI.4
The σ Models as Effective Field Theories
The Lagrangian as a mnemonic
Our beloved quantum field theory has had two near death experiences. The first started
around the mid-1930s when physical quantities came out infinite. But it roared back to
life in the late 1940s and early 1950s, thanks to the work of the generation that included
Feynman, Schwinger, Dyson, and others. The second occurred toward the late 1950s. As
we have already discussed, quantum field theory seemed totally incapable of addressing
the strong interaction: The coupling was far too strong for perturbation theory to be of any
use. Many physicists—known collectively as the S-matrix school—felt that field theory
was irrelevant for studying the strong interaction and advocated a program of trying to
derive results from general principles without using field theory. For example, in deriving
the Goldberger-Treiman relation, we could have foregone any mention of field theory and
Feynman diagrams.
Eventually, in a reaction against this trend, people realized that if some results could be
obtained from general considerations such as notions of spontaneous symmetry breaking
and so forth, any Lagrangian incorporating these general properties had to produce the
same results. At the very least, the Lagrangian provides a mnemonic for any physical result
derived without using quantum field theory. Thus was born the notion of long distance
or low energy effective field theory, which would prove enormously useful in both particle
and condensed matter physics (as we have already seen and as we will discuss further in
chapter VIII.3).
The strong interaction at low energies
One of the earliest examples is the σ model of Gell-Mann and L´evy, which describes the
interaction of nucleons and pions. We now know that the strong interaction has to be
described in terms of quarks and gluons. Nevertheless, at long distances, the degrees of

VI.4. σ Models | 341
freedom are the two nucleons and the three pions. The proton and the neutron transform as
a spinor ψ ≡
 p
n

under the SU(2) of isospin. Consider the kinetic energy term ¯ψiγ ∂ψ =
¯ψLiγ ∂ψL + ¯ψRiγ ∂ψR. We note that this term has the larger symmetry SU(2)L × SU(2)R,
with the left handed field ψL and the right handed field ψR transforming as a doublet
under SU(2)L and SU(2)R, respectively. [The SU(2) of isospin is the diagonal subgroup
of SU(2)L × SU(2)R.] We can write ψL ∼( 1
2, 0) and ψR ∼(0, 1
2).
Now we see a problem immediately: The mass term m ¯ψψ = m( ¯ψLψR + h.c.) is not
allowed since ¯ψLψR ∼( 1
2 , 1
2), a 4-dimensional representation of SU(2)L × SU(2)R, a
group locally isomorphic to SO(4).
At this point, lesser physicists would have said, what is the problem, we knew all along
that the strong interaction is invariant only under the SU(2) of isospin, which we will
write as SU(2)I. Under SU(2)I the bilinears constructed out of ¯ψL and ψR transform as
1
2 × 1
2 = 0 + 1, the singlet being ¯ψψ and the triplet ¯ψiγ 5τ aψ. With only SU(2)I symmetry,
we can certainly include the mass term ¯ψψ.
To say it somewhat differently, to fully couple to the four bilinears we can construct out
of ¯ψL and ψR, namely ¯ψψ and ¯ψiγ 5τ aψ, we need four meson fields transforming as the
vector representation under SO(4). But only the three pion fields are known. It seems
clear that we only have SU(2)I symmetry.
Nevertheless, Gell-Mann and L´evy boldly insisted on the larger symmetry SU(2)L ×
SU(2)R ≃SO(4) and simply postulated an additional meson field, which they called σ ,
so that (σ , ⃗π) form the 4-dimensional representation. I leave it to you to verify that
¯ψL(σ + i⃗τ . ⃗π)ψR + h.c. = ¯ψ(σ + i⃗τ . ⃗πγ5)ψ is invariant. Hence, we can write down the
invariant Lagrangian
L = ¯ψ[iγ ∂+ g(σ + i⃗τ . ⃗πγ5)]ψ + L(σ , ⃗π)
(1)
where the part not involving the nucleons reads
L(σ , ⃗π) = 1
2

(∂σ)2 + (∂⃗π)2
+ μ2
2 (σ 2 + ⃗π2) −λ
4 (σ 2 + ⃗π2)2
(2)
This is known as the linear σ model.
The σ model would have struck most physicists as rather strange at the time it was
introduced: The nucleon does not have a mass and there is an extra meson field. Aha, but
you would recognize (2) as precisely the Lagrangian (IV.1.2) (for N = 4) that we studied,
which exhibits spontaneous symmetry breaking. The four scalar fields (ϕ4, ϕ1, ϕ2, ϕ3)
in (IV.1.2) correspond to (σ , ⃗π). With no loss of generality, we can choose the vacuum
expectation value of ϕ to point in the 4th direction, namely the vacuum in which ⟨0|σ |0⟩=

μ2/λ ≡v and ⟨0| ⃗π |0⟩= 0. Expanding σ = v + σ ′ we see immediately that the nucleon
has a mass M = gv. You should not be surprised that the pion comes out massless. The
meson associated with the field σ ′, which we will call the σ meson, has no reason to be
massless and indeed is not.
Can the all-important parameter v be related to a measurable quantity? Indeed. From
chapter I.10 you will recall that the axial current is given by Noether’s theorem as
J a
μ5 = ¯ψγμγ5(τ a/2)ψ + πa∂μσ −σ∂μπa. After σ acquires a vacuum expectation value,

342 | VI. Field Theory and Condensed Matter
J a
μ5 contains a term −v∂μπa. This term implies that the matrix element ⟨0|J a
μ5|πb⟩= ivkμ,
where k denotes the momentum of the pion, and thus v is proportional to the f defined in
chapter IV.2. Indeed, we recognize the mass relation M = gv as precisely the Goldberger-
Treiman relation (IV.2.7) with F(0) = 1 (see exercise VI.4.4).
The nonlinear σ model
It was eventually realized that the main purpose in life of the potential in L(σ , ⃗π) is to
force the vacuum expectation values of the fields to be what they are, so the potential can
be replaced by a constraint σ 2 + ⃗π2 = v2. A more physical way of thinking about this point
is by realizing that the σ meson, if it exists at all, must be very broad since it can decay
via the strong interaction into two pions. We might as well force it out of the low energy
spectrum by making its mass large. By now, you have learned from chapters IV.1 and V.1
that the mass of the σ meson, namely
√
2μ, can be taken to infinity while keeping v fixed
by letting μ2 and λ tend to infinity, keeping their ratio fixed.
We will now focus on L(σ , ⃗π). Instead of thinking abut L(σ , ⃗π) = 1
2[(∂σ)2 + (∂⃗π)2]
with the constraint σ 2 + ⃗π2 = v2, we can simply solve the constraint and plug the solution
σ =
√
v2 −⃗π2 intotheLagrangian, thusobtainingwhatisknownasthenonlinear σ model:
L = 1
2

(∂⃗π)2 + (⃗π . ∂⃗π)2
f 2 −⃗π2

= 1
2(∂⃗π)2 +
1
2f 2(⃗π . ∂⃗π)2 + . . .
(3)
Note that L can be written in the form L = (∂πa)Gab(⃗π)(∂πb);some people like to think of
Gab as a “metric” in field space. [Incidentally, recall that way back in chapter I.3 we restricted
ourselves to the simplest possible kinetic energy term 1
2(∂ϕ)2, rejecting possibilities such
as U(ϕ)(∂ϕ)2. But recall also that in chapter IV.3 we noted that such a term would arise by
quantum fluctuations.]
In accordance with the philosophy that introduced this chapter, any Lagrangian that
captures the correct symmetry properties should describe the same low energy physics.1
This means that anybody, including you, can introduce his or her own parametrization of
the fields.
The nonlinear σ model is actually an example of a broad class of field theories whose
Lagrangian has a simple form but with the fields appearing in it subject to some nontrivial
constraint. An example is the theory defined by
L(U) = f 2
4 tr(∂μU† . ∂μU)
(4)
with U(x) a matrix-valued field and an element of SU(2). Indeed, if we write U = e(i/f )⃗π.⃗τ
we see that L(U) = 1
2(∂⃗π)2 + (1/2f 2)(⃗π . ∂⃗π)2 + . . . , identical to (3) up to the terms
indicated. The ⃗π field here is related to the one in (3) by a field redefinition.
There is considerably more we can say about the nonlinear σ models and their applica-
tions in particle and condensed matter physics, but a thorough discussion would take us
1 S. Weinberg, Physica 96A: 327, 1979.

VI.4. σ Models | 343
far beyond the scope of this book. Instead, I will develop some of their properties in the
exercises and in the next chapter will sketch how they can arise in one class of condensed
matter systems.
Exercises
VI.4.1
Show that the vacuum expectation value of (σ , ⃗π) can indeed point in any direction without changing the
physics. At first sight, this statement seems strange since, by virtue of its γ5 coupling to the nucleon, the
pion is a pseudoscalar field and cannot have a vacuum expectation without breaking parity. But (σ , ⃗π)
are just Greek letters. Show that by a suitable transformation of the nucleon field parity is conserved, as
it should be in the strong interaction.
VI.4.2
Calculate the pion-pion scattering amplitude up to quadratic order in the external momenta, using the
nonlinear σ model (3). [Hint: For help, see S. Weinberg, Phys. Rev. Lett. 17: 616, 1966.]
VI.4.3
Calculate the pion-pion scattering amplitude up to quadratic order in the external momenta, using the
linear σ model (2). Don’t forget the Feynman diagram involving σ meson exchange. You should get the
same result as in exercise VI.4.2.
VI.4.4
Show that the mass relation M = gv amounts to the Goldberger-Treiman relation.

VI.5
Ferromagnets and Antiferromagnets
Magnetic moments
In chapters IV.1 and V.3 I discussed how the concept of the Nambu-Goldstone boson
originated as the spin wave in a ferromagnetic or an antiferromagnetic material. A cartoon
description of such materials consists of a regular lattice on each site of which sits a
local magnetic moment, which we denote by a unit vector ⃗nj with j labeling the site.
In a ferromagnetic material the magnetic moments on neighboring sites want to point
in the same direction, while in an antiferromagnetic material the magnetic moments
on neighboring sites want to point in opposite directions. In other words, the energy is
H =J 
<ij> ⃗ni . ⃗nj, where i and j label neighboring sites. For antiferromagnets J >
0, and for ferromagnets J < 0. I will merely allude to the fully quantum description
formulated in terms of a spin ⃗Sj operator on each site j; the subject lies far beyond the
scope of this text.
In a more microscopic treatment, we would start with a Hamiltonian (such as the
Hubbard Hamiltonian) describing the hopping of electrons and the interaction between
them. Within some approximate mean field treatment the classical variable ⃗nj would then
emerge as the unit vector pointing in the direction of ⟨c
†
j ⃗σcj⟩with c
†
j and cj the electron
creation and annihilation operators, respectively. But this is not a text on solid state physics.
First versus second order in time
Here we would like to derive an effective low energy description of the ferromagnet and
antiferromagnet in the spirit of the σ model description of the preceding chapter. Our
treatment will be significantly longer than the standard discussion given in some field
theory texts, but has the slight advantage of being correct.
The somewhat subtle issue is what kinetic energy term we have to add to −H to form the
Lagrangian L. Since for a unit vector ⃗n we have ⃗n . (d⃗n/dt) = (d(⃗n . ⃗n)/dt) = 0, we cannot

VI.5. Magnetic Systems | 345
make do with one time derivative. With two derivatives we can form (d⃗n/dt) . (d⃗n/dt)
and so
Lwrong =
1
2g2

j
∂⃗nj
∂t
. ∂⃗nj
∂t −J

<ij>
⃗ni . ⃗nj
(1)
A typical field theory text would then pass to the continuum limit and arrive at the
Lagrangian density
L =
1
2g2(∂⃗n
∂t
. ∂⃗n
∂t −c2
s

l
∂⃗n
∂xl . ∂⃗n
∂xl )
(2)
with the constraint [⃗n(x, t)]2 = 1. This is another example of a nonlinear σ model. Just as
in the nonlinear σ model discussed in chapter VI.4, the Lagrangian looks free, but the
nontrivial dynamics comes from the constraint. The constant cs (which is determined in
terms of the microscopic variable J) is the spin wave velocity, as you can see by writing
down the equation of motion (∂2/∂t2)⃗n −c2
s∇2⃗n = 0.
But you can feel that something is wrong. You learned in a quantum mechanics course
that the dynamics of a spin variable ⃗S is first order in time. Consider the most basic
example of a spin in a constant magnetic field described by H = μ⃗S . ⃗B. Then d ⃗S/dt =
i[H , ⃗S] = μ ⃗B × ⃗S. Besides, you might remember from a solid state physics course that in
a ferromagnet the dispersion relation of the spin wave has the nonrelativistic form ω ∝k2
and not the relativistic form ω2 ∝k2 implied by (2).
The resolution of this apparent paradox is based on the Pauli-Hopf identity: Given a unit
vector ⃗n we can always write ⃗n = z†⃗σz, where z =
 z1
z2

consists of two complex numbers
such that z†z ≡z
†
1z1 + z
†
2z2 = 1. Verify this! (A mathematical aside: Writing z1 and z2 out
in terms of real numbers we see that this defines the so-called Hopf map S3 →S2.) While
we cannot form a term quadratic in ⃗n and linear in time derivative, we can write a term
quadratic in the complex doublet z and linear in time derivative. Can you figure it out
before looking at the next line?
The correct version of (1) is
Lcorrect = i

j
z†
j
∂zj
∂t +
1
2g2

j
∂⃗nj
∂t
. ∂⃗nj
∂t −J

<ij>
⃗ni . ⃗nj
(3)
The added term is known as the Berry’s phase term and has deep topological meaning.
You should derive the equation of motion using the identity

dt δ

z†
j
∂zj
∂t

= 1
2i

dt δ⃗nj .

⃗nj ×
∂⃗nj
∂t

(4)
Remarkably, although z†
j(∂zj/∂t) cannot be written simply in terms of ⃗nj , its variation
can be.
Low energy modes in the ferromagnet and the antiferromagnet
In the ground state of a ferromagnet, the magnetic moments all point in the same
direction, which we can choose to be the z-direction. Expanding the equation of motion in

346 | VI. Field Theory and Condensed Matter
small fluctuations around this ground state ⃗nj = ˆez + δ⃗nj (where evidently ˆez denotes the
appropriate unit vector) and Fourier transforming, we obtain
 −ω2
g2 + h(k)
−1
2iω
1
2iω
−ω2
g2 + h(k)
  δnx(k)
δny(k)

= 0
(5)
linking the two components δnx(k) and δny(k) of δ⃗n(k). The condition ⃗nj. ⃗nj = 1 says that
δnz(k) = 0. Here a is the lattice spacing and h(k) ≡4J[2 −cos(kxa) −cos(kya)] ≃2Ja2k2
for small k. (I am implicitly working in two spatial dimensions as evidenced by kx and ky.)
At low frequency the Berry term iω dominates the naive term ω2/g2, which we can
therefore throw away. Setting the determinant of the matrix equal to zero, we see that we
get the correct quadratic dispersion relation ω ∝k2.
The treatment of the antiferromagnet is interestingly different. The so-called N´eel state1
for an antiferromagnet is defined by ⃗nj = (−1)j ˆez. Writing ⃗nj = (−1)j ˆez + δ ⃗nj , we obtain
 −ω2
g2 + f (k)
−1
2iω
1
2iω
−ω2
g2 + f (k)
 
δnx(k)
δny(k + Q)

= 0
(6)
linking
δnx
and
δny
evaluated
at
different
momenta.
Here
f (k) = 4J
[2 + cos(kxa) + cos(kya)]and Q = [π/a, π/a].The appearance of Q is due to (−1)j = eiQaj.
(I will let you figure out the somewhat overly compact notation.) The antiferromagnetic
factor (−1)j explicitly breaks translation invariance and kicks in the momentum Q when-
ever it occurs. A similar equation links δny(k) and δnx(k + Q). Solving these equations,
you will find that there is a high frequency branch that we are not interested in and a low
frequency branch with the linear dispersion ω ∝k.
Thus, the low frequency dynamics of the antiferromagnet can be described by the
nonlinear σ model (2), which when the spin wave velocity is normalized to 1 can be written
in the relativistic form:
L =
1
2g2∂μ⃗n . ∂μ⃗n
(7)
Exercises
VI.5.1
Work out the two branches of the spin wave spectrum in the ferromagnetic case, paying particular
attention to the polarization.
VI.5.2
Verify that in the antiferromagnetic case the Berry’s phase term merely changes the spin wave velocity
and does not affect the spectrum qualitatively as in the ferromagnetic case.
1 Note that while the N´eel state describes the lowest energy configuration for a classical antiferromagnet, it
does not describe the ground state of a quantum antiferromagnet. The terms S+
i S−
j + S−
i S+
j in the Hamiltonian
J 
<ij> ⃗Si . ⃗Sj flip the spins up and down.

VI.6
Surface Growth and Field Theory
In this chapter I will discuss a topic, rather unusual for a field theory text, taken from non-
equilibrium statistical mechanics, one of the hottest growth fields in theoretical physics
over the last few years. I want to introduce you to yet another area in which field theoretic
concepts are of use.
Imagine atoms being deposited randomly on some surface. This is literally how some
novel materials are grown. The height h(x, t) of the surface as it grows is governed by the
Kardar-Parisi-Zhang equation
∂h
∂t = ν∇2h + λ
2(∇h)2 + η(⃗x, t)
(1)
This equation describes a deceptively simple prototype of nonequilibrium dynamics and
has a remarkably wide range of applicability.
To understand (1), consider the various terms on the right-hand side. The term ν∇2h
(with ν > 0) is easy to understand: Positive in the valleys of h and negative on the peaks,
it tends to smooth out the surface. With only this term the problem would be linear and
hence trivial. The nonlinear term (λ/2)(∇h)2 renders the problem highly nontrivial and
interesting; I leave it to you as an exercise to convince yourself of the geometric origin of
this term. The third term describes the random arrival of atoms, with the random variable
η(⃗x, t) usually assumed to be Gaussian distributed, with zero mean,1 and correlations

η(⃗x, t)η(⃗x′, t′)

= 2σ 2δD(⃗x −⃗x′)δ(t −t′)
(2)
In other words, the probability distribution for a particular η(⃗x, t) is given by
P(η) ∝e−
1
2σ2

dDxdt η(⃗x,t)2
Here ⃗x represents coordinates in D-dimensional space. Experimentally, D = 2 for the
situation I described, but theoretically we are free to investigate the problem for any D.
1 There is no loss of generality here since an additive constant in η can be absorbed by the shift h →h + ct.

348 | VI. Field Theory and Condensed Matter
Typically, condensed matter physicists are interested in calculating the correlation be-
tween the height of the surface at two different positions in space and time:
⟨[h(⃗x, t) −h(⃗x′, t′)]2⟩= |⃗x −⃗x′|2χf
|⃗x −⃗x′|z
|t −t′|

,
(3)
The bracket ⟨. . .⟩here and in (2) denotes averaging over different realizations of the
random variable η(⃗x, t). On the right-hand side of (3) I have written the dynamic scaling
form typically postulated in condensed matter physics, where χ and z are the so-called
roughness and dynamic exponents. The challenge is then to show that the scaling form is
correct and to calculate χ and z. Note that the dynamic exponent z (which in general is not
an integer) tells us, roughly speaking, how many powers of space is worth one power of
time. (For λ = 0 we have simple diffusion for which z = 2.) Here f denotes an unknown
function.
I will not go into more technical details. Our interest here is to see how this problem,
which does not even involve quantum mechanics, can be converted into a quantum field
theory. Start with
Z ≡

Dh

Dη e−
1
2σ2

dDxdt η(⃗x,t)2
δ
∂h
∂t −ν∇2h −λ
2(∇h)2 −η(⃗x, t)

(4)
Integrating over η, we obtain Z =

Dh e−S(h) with the action
S(h) =
1
2σ 2

dD⃗x dt
∂h
∂t −ν∇2h −λ
2(∇h)2
2
(5)
You will recognize that this describes a nonrelativistic field theory of a scalar field h(⃗x, t).
The physical quantity we are interested in is then given by
⟨

h(⃗x, t) −h(⃗x′, t′)
2⟩= 1
Z

Dh e−S(h)[h(⃗x, t) −h(⃗x′, t′)]2
(6)
Thus, the challenge of determing the roughness and dynamic exponents in statistical
physics is equivalent to the problem of determining the propagator
D(⃗x, t) ≡1
Z

Dh e−S(h)h(⃗x, t)h(⃗0, 0)
of the scalar field h.
Incidentally, by scaling t →t/ν and h →

σ 2/ν h, we can write the action as
S(h) = 1
2

dD⃗x dt
 ∂
∂t −∇2

h −g
2 (∇h)2
2
(7)
with g2 ≡λ2σ 2/ν3. Expanding the action in powers of h as usual
S(h) = 1
2

dD⃗x dt
 ∂
∂t −∇2

h
2
−g(∇h)2
 ∂
∂t −∇2

h + g2
4 (∇h)4

,
(8)
we recognize the quadratic term as giving us the rather unusual propagator 1/(ω2 + k4) for
the scalar field h, and the cubic and quartic term as describing the interaction. As always,

VI.6. Surface Growth | 349
h
h(x)
θ
d
cos θ
x
Figure VI.6.1
to calculate the desired physical quantity we evaluate the functional or “path” integral
Z =

Dh e−S(h)+
dDxdtJ(x,t)h(x,t)
and then functionally differentiate repeatedly with respect to J.
My intent here is not so much to teach you nonequilibrium statistical mechanics as to
show you that quantum field theory can emerge in a variety of physical situations, including
those involving only purely classical physics. Note that the “quantum fluctuations” here
arise from the random driving term. Evidently, there is a close methodological connection
between random dynamics and quantum physics.
Exercises
VI.6.1
An exercise in elementary geometry: Draw a straight line tilted at an angle θ with respect to the horizontal.
The line represents a small segment of the surface at time t. Now draw a number of circles of diameter
d tangent to and on top of this line. Next draw another line tilted at angle θ with respect to the horizontal
and lying on top of the circles, namely tangent to them. This new line represents the segment of the
surface some time later (see fig. VI.6.1). Note that h = d/cos θ ≃d(1 + 1
2θ2). Show that this generates
the nonlinear term (λ/2)(∇h)2 in the KPZ equation (1). For applications of the KPZ equation, see for
example, T. Halpin–Healy and Y.-C. Zhang, Phys. Rep. 254: 215, 1995; A. L. Barabasi and H. E. Stanley,
Fractal Concepts in Surface Growth.
VI.6.2
Show that the scalar field h has the propagator 1/(ω2 + k4).
VI.6.3
Field theory can often be cast into apparently rather different forms by a change of variable. Show that
by writing U = e
1
2 gh we can change the action (7) to
S = 2
g2

dD⃗x dt

U−1 ∂
∂t U −U−1∇2U
2
(9)
a kind of nonlinear σ model.

VI.7
Disorder: Replicas and Grassmannian Symmetry
Impurities and random potential
An important area in condensed matter physics involves the study of disordered systems,
a subject that has been the focus of a tremendous amount of theoretical work over the
last few decades. Electrons in real materials scatter off the impurities inevitably present
and effectively move in a random potential. In the spirit of this book I will give you a brief
introduction to this fascinating subject, showing how the problem can be mapped into a
quantum field theory.
The prototype problem is that of a quantum particle obeying the Schr¨odinger equa-
tion Hψ = [−∇2 + V (x)]ψ = Eψ, where V (x) is a random potential (representing the
impurities) generated with the Gaussian white noise probability distribution P(V ) =
N e−
dDx(1/2g2)V (x)2 with the normalization factor N determined by

DV P(V ) = 1. The
parameter g measures the strength of the impurities: the larger g, the more disordered the
system. This of course represents an idealization in which interaction between electrons
and a number of other physical effects are neglected.
As in statistical mechanics we think of an ensemble of systems each of which is charac-
terized by a particular function V (x) taken from the distribution P(V ). We study the aver-
age or typical properties of the system. In particular, we might want to know the averaged
density of states defined by ρ(E) = ⟨tr δ(E −H)⟩= ⟨
i δ(E −Ei)⟩, where the sum runs
over the ith eigenstate of H with corresponding eigenvalue Ei. We denote by ⟨O(V )⟩≡

DV P(V )O(V ) the average of any functional O(V ) of V (x). Clearly,
 E∗+δE
E∗
dE ρ(E)
counts the number of states in the interval from E∗to E∗+ δE, an important quantity in,
for example, tunneling experiments.

VI.7. Disorder | 351
Anderson localization
Another important physical question is whether the wave functions at a particular energy
E extend over the entire system or are localized within a characteristic length scale ξ(E).
Clearly, this issue determines whether the material is a conductor or an insulator. At first
sight, you might think that we should study
S(x, y; E) ≡

i
δ(E −Ei)ψ∗
i (x)ψi(y)

which might tell us how the wave function at x is correlated with the wave function at
some other point y, but S is unsuitable because ψ∗
i (x)ψi(y) has a phase that depends on
V . Thus, S would vanish when averaged over disorder. Instead, the correct quantity to
study is
K(x −y; E) ≡

i
δ(E −Ei)ψ∗
i (x)ψi(y)ψ∗
i (y)ψi(x)

since ψ∗
i (x)ψi(y)ψ∗
i (y)ψi(x) is manifestly positive. Note that upon averaging over all possi-
ble V (x) we recover translation invariance so that K does not depend on x and y separately,
but only on the separation |x −y|. As |x −y| →∞, if K(x −y; E) ∼e−|x−y|/ξ(E) decreases
exponentially the wave functions around the energy E are localized over the so-called local-
ization length ξ(E). On the other hand, if K(x −y; E) decreases as a power law of |x −y|,
the wave functions are said to be extended.
Anderson and his collaborators made the surprising discovery that localization prop-
erties depend on D, the dimension of space, but not on the detailed form of P(V ) (an
example of the notion of universality). For D = 1 and 2 all wave functions are localized,
regardless of how weak the impurity potential might be. This is a highly nontrivial state-
ment since a priori you might think, as eminent physicists did at the time, that whether the
wave functions are localized or not depends on the strength of the potential. In contrast, for
D = 3, the wave functions are extended for E in the range (−Ec, Ec). As E approaches the
energy Ec (known as the mobility edge) from above, the localization length ξ(E) diverges
as ξ(E) ∼1/(E −Ec)μ with some critical exponent1 μ. Anderson received the Nobel Prize
for this work and for other contributions to condensed matter theory.
Physically, localization is due to destructive interference between the quantum waves
scattering off the random potential.
When a magnetic field is turned on perpendicular to the plane of a D = 2 electron gas
the situation changes dramatically: An extended wave function appears at E = 0. For non-
zero E, all wave functions are still localized, but with the localization length diverging as
ξ(E) ∼1/|E|ν. This accounts for one of the most striking features of the quantum Hall
effect (see chapter VI.2): The Hall conductivity stays constant as the Fermi energy increases
but then suddenly jumps by a discrete amount due to the contribution of the extended state
1 This is an example of a quantum phase transition. The entire discussion is at zero temperature. In contrast
to the phase transition discussed in chapter V.3, here we vary E instead of the temperature.

352 | VI. Field Theory and Condensed Matter
as the Fermi energy passes through E = 0. Understanding this behavior quantitatively
poses a major challenge for condensed matter theorists. Indeed, many consider an analytic
calculation of the critical exponent ν as one of the “Holy Grails” of condensed matter theory.
Green’s function formalism
So much for a lightning glimpse of localization theory. Fascinating though the localization
transition might be, what does quantum field theory have to do with it? This is after all a
field theory text. Before proceeding we need a bit of formalism. Consider the so-called
Green’s function G(z) ≡⟨tr[1/(z −H)]⟩in the complex z-plane. Since tr[1/(z −H)] =

i 1/(z −Ei), this function consists of a sum of poles at the eigenvalues Ei. Upon
averaging, the poles merge into a cut. Using the identity (I.2.13) lim
ε→0 Im[1/(x + iε)] =
−πδ(x), we see that
ρ(E) = −1
π lim
ε→0 Im G(E + iε)
(1)
So if we know G(z) we know the density of states.
The infamous denominator
I can now explain how quantum field theory enters into the problem. We start by taking
the logarithm of the identity (A.15)
J † . K−1 . J = log(

Dϕ†Dϕe−ϕ†.K.ϕ+J †.ϕ+ϕ†.J)
(where as usual we have dropped an irrelevant term). Differentiating with respect to J †
and J and then setting J † and J equal to 0 we obtain an integral representation for the
inverse of a hermitean matrix:
(K−1)ij =

Dϕ†Dϕe−ϕ†.K.ϕϕiϕ†
j

Dϕ†Dϕe−ϕ†.K.ϕ
(2)
(Incidentally, you may recognize this as essentially related to the formula (I.7.14) for the
propagator of a scalar field.) Now that we know how to represent 1/(z −H) we have to take
its trace, which means setting i = j in (2) and summing. In our problem, H = −∇2 + V (x)
and the index i corresponds to the continuous variable x and the summation to an
integration over space. Replacing K by i(z −H) (and taking care of the appropriate delta
function) we obtain
tr
−i
z −H =

dDy
⎧
⎨
⎩

Dϕ†Dϕei 
dDx{∂ϕ†∂ϕ+[V (x)−z]ϕ†ϕ}ϕ(y)ϕ†(y)

Dϕ†Dϕei 
dDx{∂ϕ†∂ϕ+[V (x)−z]ϕ†ϕ}
⎫
⎬
⎭
(3)

VI.7. Disorder | 353
This is starting to look like a scalar field theory in D-dimensional Euclidean space with the
action S =

dDx{∂ϕ†∂ϕ + [V (x) −z]ϕ†ϕ}. [Note that for (3) to be well defined z has to be
in the lower half-plane.]
But now we have to average over V (x), that is, integrate over V with the probability
distribution P(V ). We immediately run into the difficulty that confounded theorists for
a long time. The denominator in (3) stops us cold: If that denominator were not there,
then the functional integration over V (x) would just be the Gaussian integral you have
learned to do over and over again. Can we somehow lift this infamous denominator into
the numerator, so to speak? Clever minds have come up with two tricks, known as the
replica method and the supersymmetric method, respectively. If you can come up with
another trick, fame and fortune might be yours.
Replicas
The replica trick is based on the well-known identity (1/x) = lim
n→0 xn−1, which allows us to
write that much disliked denominator as
lim
n→0
 
Dϕ†Dϕei 
dDx{∂ϕ†∂ϕ+[V (x)−z]ϕ†ϕ}n−1
= lim
n→0

n

a=2
Dϕ†
aDϕaei 
dDx n
a=2{∂ϕ†
a∂ϕa+[V (x)−z]ϕ†
aϕa}
Thus (3) becomes
tr
1
z −H = lim
n→0 i

dDy
  n

a=1
Dϕ†
aDϕa

ei 
dDx n
a=1{∂ϕ†
a∂ϕa+[V (x)−z]ϕ†
aϕa}ϕ1(y)ϕ†
1(y)
(4)
Note that the functional integral is now over n complex scalar fields ϕa. The field ϕ has
been replicated. For positive integers, the integrals in (4) are well defined. We hope that
the limit n →0 will not blow up in our face.
Averaging over the random potential, we recover translation invariance; thus the in-
tegrand for

dDy does not depend on y and

dDy just produces the volume V of the
system. Using (A.13) we obtain

tr
1
z −H

= iV lim
n→0
  n

a=1
Dϕ†
aDϕa

ei 
dDxLϕ1(0)ϕ†
1(0)
(5)
where
L(ϕ) ≡
n

a=1
(∂ϕ†
a∂ϕa −zϕ†
aϕa) + ig2
2
 n

a=1
ϕ†
aϕa
2
(6)
We obtain a field theory (with a peculiar factor of i) of n scalar fields with a good old
ϕ4 interaction invariant under O(n) (known as the replica symmetry.) Note the wisdom of

354 | VI. Field Theory and Condensed Matter
replacing K by i(z −H); if we didn’t include the i the functional integral would diverge
at large ϕ, as you can easily check. For z in the upper half-plane we would replace K by
−i(z −H). The quantity from which we can extract the desired averaged density of states
is given by the propagator of the scalar field. Incidentally, we can replace ϕ1(0)ϕ†
1(0) in (5)
by the more symmetric expression (1/n) n
b=1 ϕ†
bϕb.
Absorbing V so that we are calculating the density of states per unit volume, we find
G(z) = i lim
n→0
  n

a=1
Dϕ†
aDϕa

eiS(ϕ)

1
n
n

b=1
ϕ†
b(0)ϕb(0)

(7)
For positive integer n the field theory is perfectly well defined, so the delicate step in the
replica approach is in taking the n →0 limit. There is a fascinating literature on this limit.
(Consult a book devoted to spin glasses.)
Some particle theorists used to speak disparagingly of condensed matter physics as dirt
physics, and indeed the influence of impurities and disorder on matter is one of the central
concerns of modern condensed matter physics. But as we see from this example, in many
respects there is no mathematical difference between averaging over randomness and
summing over quantum fluctuations. We end up with aϕ4 field theory of the type that many
particle theorists have devoted considerable effort to studying in the past. Furthermore,
Anderson’s surprising result that for D = 2 any amount of disorder, no matter how small,
localizes all states means that we have to understand the field theory defined by (6) in
a highly nontrivial way. The strength of the disorder shows up as the coupling g2, so
no amount of perturbation theory in g2 can help us understand localization. Anderson
localization is an intrinsically nonperturbative effect.
Grassmannian approach
As I mentioned earlier, people have dreamed up not one, but two, tricks in dealing with
the nasty denominator. The second trick is based on what we learned in chapter II.5 on
integration over Grassmann variables: Let η(x) and ¯η(x) be Grassmann fields, then

DηD ¯ηe−
d4x ¯ηKη = C det K = 
C

DϕDϕ†e−
d4xϕ
†Kϕ
−1
where C and 
C are two uninteresting constants that we can absorb into the definition of
DηD ¯η. With this identity we can write (3) as
tr
1
z −H = i

dDy

Dϕ†DϕDηD ¯ηei 
dDx{{∂ϕ†∂ϕ+[V (x)−z]ϕ†ϕ}+{∂¯η∂η+[V (x)−z]¯ηη}}ϕ(y)ϕ†(y) (8)
and then easily average over the disorder to obtain (per unit volume)

tr
1
z −H

= i

Dϕ†DϕDηD ¯ηei 
dDxL(¯η,η,ϕ†,ϕ)ϕ(0)ϕ†(0)
(9)
with
L(¯η, η, ϕ†, ϕ) = ∂ϕ†∂ϕ + ∂¯η∂η −z(ϕ†ϕ + ¯ηη) + ig2
2 (ϕ†ϕ + ¯ηη)2
(10)

VI.7. Disorder | 355
We end up with a field theory with bosonic (commuting) fields ϕ† and ϕ and fermionic
(anticommuting) fields ¯η and η interacting with a strength determined by the disorder. The
action S exhibits an obvious symmetry rotating bosonic fields into fermionic fields and
vice versa, and hence this approach is known in the condensed matter physics community
as the supersymmetric method. (It is perhaps worth emphasizing that ¯η and η are not
spinor fields, which we underline by not writing them as ¯ψ and ψ. The supersymmetry
here, perhaps better referred to as Grassmannian symmetry, is quite different from the
supersymmetry in particle physics to be discussed in chapter VIII.4.)
Both the replica and the supersymmetry approaches have their difficulties, and I was
not kidding when I said that if you manage to invent a new approach without some of these
difficulties it will be met with considerable excitement by condensed matter physicists.
Probing localization
I have shown you how to calculate the averaged density of states ρ(E). How do we study
localization? I will let you develop the answer in an exercise. From our earlier discussion
it should be clear that we have to study an object obtained from (3) by replacing ϕ(y)ϕ†(y)
by ϕ(x)ϕ†(y)ϕ(y)ϕ†(x). If we choose to think of the replica field theory in the language of
particle physics as describing the interaction of some scalar meson, then rather pleasingly,
we see that the density of states is determined by the meson propagator and localization
is determined by meson-meson scattering.
Exercises
VI.7.1
Work out the field theory that will allow you to study Anderson localization. [Hint: Consider the object

1
z −H

(x, y)

1
w −H

(y, x)

for two complex numbers z and w. You will have to introduce two sets of replica fields, commonly denoted
by ϕ+
a and ϕ−
a .] {Notation: [1/(z −H)](x, y) denotes the xy element of the matrix or operator [1/(z −H)].}
VI.7.2
As another example from the literature on disorder, consider the following problem. Place N points
randomly in a D-dimensional Euclidean space of volume V . Denote the locations of the points by
⃗xi (i = 1, . . . , N) . Let
f (⃗x) = (−)

dDk
(2π)D
ei⃗k⃗x
k2 + m2
Consider the N by N matrix Hij = f

⃗xi −⃗xj

. Calculate ρ(E), the density of eigenvalues of H as we
average over the ensemble of matrices, in the limit N →∞, V →∞, with the density of points ρ ≡N/V
(not to be confused with ρ(E) of course) held fixed. [Hint: Use the replica method and arrive at the field
theory action
S(ϕ) =

dDx
 n

a=1
(|∇ϕa|2 + m2|ϕa|2) −ρe−(1/z)n
a=1|ϕa|2

This problem is not entirely trivial; if you need help consult M. M´ezard et al., Nucl. Phy. B559: 689, 2000,
cond-mat/9906135.

VI.8
Renormalization Group Flow as a Natural Concept
in High Energy and Condensed Matter Physics
Therefore, conclusions based on the renormalization
group arguments . . . are dangerous and must be viewed
with due caution. So is it with all conclusions from local
relativistic field theories.
—J. Bjorken and S. Drell, 1965
It is not dangerous
The renormalization group represents the most important conceptual advance in quantum
field theory over the last three or four decades. The basic ideas were developed simultane-
ously in both the high energy and condensed matter physics communities, and in some
areas of research renormalization group flow has become part of the working language.
As you can easily imagine, this is an immensely rich and multifaceted subject, which we
can discuss from many different points of view, and a full exposition would require a book
in itself. Unfortunately, there has never been a completely satisfactory and comprehensive
treatment of the subject. The discussions in some of the older books are downright
misleading and confused, such as the well-known text from which I learned quantum field
theory and from which the quote above was taken. In the limited space available here, I
will attempt to give you a flavor of the subject rather than all the possible technical details.
I will first approach it from the point of view of high energy physics and then from that
of condensed matter physics. As ever, the emphasis will be on the conceptual rather than
the computational. As you will see, in spite of the order of my presentation, it is easier
to grasp the role of the renormalization group in condensed matter physics than in high
energy physics.
I laid the foundation for the renormalization group in chapter III.1—I do plan ahead!
Let us go back to our experimentalist friend with whom we were discussing λϕ4 theory.
We will continue to pretend that our world is described by a simple λϕ4 theory and that an
approximation to order λ2 suffices.

VI.8. Renormalization Group Flow | 357
What experimentalists insist on
Our experimentalist friend was not interested in the coupling constant λ we wrote down
on a piece of paper, a mere Greek letter to her. She insisted that she would accept only
quantities she and her experimental colleagues can actually measure, even if only in
principle. As a result of our discussion with her we sharpened our understanding of what
a coupling constant is and learned that we should define a physical coupling constant by
[see (III.1.4)]
λP(μ) = λ −3Cλ2 log
2
μ2

+ O(λ3)
(1)
At her insistence, we learned to express our result for physical amplitudes in terms of
λP(μ), and not in terms of the theoretical construct λ. In particular, we should write the
meson-meson scattering amplitude as
M = −iλP(μ) + iCλP(μ)2

log
μ2
s

+ log
μ2
t

+ log
μ2
u

+ O[λP(μ)3]
(2)
What is the physical significance of λP(μ)? To be sure, it measures the strength of
the interaction between mesons as reflected in (2). But why one particular choice of μ?
Clearly, from (2) we see that λP(μ) is particularly convenient for studying physics in the
regime in which the kinematic variables s, t, and u are all of order μ2. The scattering
amplitude is given by −iλP(μ) plus small logarithmic corrections. (Recall from a footnote
in chapter III.3 that the renormalization point s0 = t0 = u0 = μ2 is adopted purely for
theoretical convenience and cannot be reached in actual experiments. For our conceptual
understanding here this is not a relevant issue.) In short, λP(μ) is known as the coupling
constant appropriate for physics at the energy scale μ.
In contrast, if we were so idiotic as to use the coupling constant λP(μ′) while exploring
physics in the regime with s, t, and u of order μ2, with μ′ vastly different from μ, then we
would have a scattering amplitude
M = −iλP(μ′) + iCλP(μ′)2

log
μ′2
s

+ log
μ′2
t

+ log
μ′2
u

+ O[λP(μ′)3]
(3)
in which the second term [with log(μ′2/μ2) large] can be comparable to or larger than the
first term. The coupling constant λP(μ′) is not a convenient choice. Thus, for each energy
scale μ there is an “appropriate” coupling constant λP(μ).
Subtracting (2) from (3) we can easily relate λP(μ) and λP(μ′) for μ ∼μ′ :
λP(μ′) = λP(μ) + 3CλP(μ)2 log
μ′2
μ2

+ O[λP(μ)3]
(4)
We can express this as a differential “flow equation”
μ d
dμλP(μ) = 6CλP(μ)2 + O(λ3
P)
(5)

358 | VI. Field Theory and Condensed Matter
As you have already seen repeatedly, quantum field theory is full of historical misnomers.
The description of how λP(μ) changes with μ is known as the renormalization group.
The only appearance of a group concept here is the additive group of transformation
μ →μ + δμ.
For the conceptual discussion in chapter III.1 and here, we don’t need to know what
the constant C happens to be. If C happens to be negative, then the coupling λP(μ) will
decrease as the energy scale μ increases, and the opposite will occur if C happens to be
positive. (In fact, the sign is positive, so that as we increase the energy scale, λP flows away
from the origin.)
Flow of the electromagnetic coupling
The behavior of λ is typical of coupling constants in 4-dimensional quantum field theories.
For example, in quantum electrodynamics, the coupling e or equivalently α = e2/4π,
measures the strength of the electromagnetic interaction. The story is exactly as that told
for the λϕ4 theory: Our experimentalist friend is not interested in the Latin letter e, but
wants to know the actual interaction when the relevant momenta squared are of the order
μ2. Happily, we have already done the computation: We can read off the effective coupling
at momentum transferred squared q2 = μ2 from (III.7.14):
eP(μ)2 = e2
1
1 + e2(μ2) ≃e2[1 −e2(μ2) + O(e4)]
Take μ much larger than the electron mass m but much smaller than the cutoff mass M.
Then from (III.7.13)
μ d
dμeP(μ) = −1
2e3μ d
dμ(μ2) + O(e5) = +
1
12π2e3
P + O(e5
P)
(6)
We learn that the electromagnetic coupling increases as the energy scale increases.
Electromagnetism becomes stronger as we go to higher energies, or equivalently shorter
distances.
Physically, the origin of this phenomenon is closely related to the physics of dielectrics.
Consider a photon interacting with an electron, which we will call the test electron to
avoid confusion in what follows. Due to quantum fluctuations, as described way back in
chapter I.1, spacetime is full of electron-positron pairs, popping in and out of existence.
Near the test electron, the electrons in these virtual pairs are repelled by the test electron
and thus tend to move away from the test electron while the positrons tend to move toward
the test electron. Thus, at long distances, the charge of the test electron is shielded to some
extent by the cloud of positrons, causing a weaker coupling to the photon, while at short
distances the coupling to the photon becomes stronger. The quantum vacuum is just as
much a dielectric as a lump of actual material.
You may have noticed by now that the very name “coupling constant” is a terrible
misnomer due to the fact that historically much of physics was done at essentially one
energy scale, namely “almost zero”! In particular, people speak of the fine structure

VI.8. Renormalization Group Flow | 359
“constant” α = 1/137 and crackpots continue to try to “derive” the number 137 from
numerology or some fancier method. In fact, α is merely the coupling “constant” of the
electromagnetic interaction at very low energies. It is an experimental fact that α, more
properly written as αP(μ) ≡e2
P(μ)/4π, varies with the energy scale μ we are exploring.
But alas, we are probably stuck with the name “coupling constant.”
Renormalization group flow
In general, in a quantum field theory with a coupling constant g, we have the renormal-
ization group flow equation
μ dg
dμ = β(g)
(7)
which is sometimes written as dg/dt = β(g) upon defining t ≡log(μ/μ0). I will now
suppress the subscript P on physical coupling constants. If the theory happens to have
several coupling constants gi, i = 1, . . . , N, then we have
dgi
dt = βi(g1, . . . , gN)
(8)
We can think of (g1, . . . , gN) as the coordinate of a particle in N-dimensional space,
t as time, and βi(g1, . . . , gN) a position dependent velocity field. As we increase μ or t
we would like to study how the particle moves or flows. For notational simplicity, we will
now denote (g1, . . . , gN) collectively as g. Clearly, those couplings at which βi(g∗) (for all
i) happen to vanish are of particular interest: g∗is known as a fixed point. If the velocity
field around a fixed point g∗is such that the particle moves toward that point (and once
reaching it stays there since its velocity is now zero) the fixed point is known as attractive or
stable. Thus, to study the asymptotic behavior of a quantum field theory at high energies
we “merely” have to find all its attractive fixed points under the renormalization group
flow. In a given theory, we can typically see that some couplings are flowing toward larger
values while others are flowing toward zero.
Unfortunately, this wonderful theoretical picture is difficult to implement in practice
because we essentially have no way of calculating the functionsβi(g).In particular, g∗could
well be quite large, associated with what is known as a strong coupling fixed point, and
perturbation theory and Feynman diagrams are of no use in determining the properties
of the theory there. Indeed, we know the fixed point structure of very few theories.
Happily, we know of one particularly simple fixed point, namely g∗= 0, at which
perturbation theory is certainly applicable. We can always evaluate (8) perturbatively:
dgi/dt = cjk
i gjgk + djkl
i
gjgkgl + . . . . (In some theories, the series starts with quadratic
terms and in others, with cubic terms. Sometimes there is also a linear term.) Thus, as we
have already seen in a couple of examples, the asymptotic or high energy behavior of the
theory depends on the sign of βi in (8).
Let us now join the film “Physics History” already in progress. In the late 1960s,
experimentalists studying the so-called deep inelastic scattering of electrons on protons

360 | VI. Field Theory and Condensed Matter
discovered that their data seemed to indicate that after being hit by a highly energetic
electron, one of the quarks inside the proton would propagate freely without interacting
strongly with the other quarks. Normally, of course, the three quarks inside the proton are
strongly bound to each other to form the proton. Eventually, a few theorists realized that
this puzzling state of affairs could be explained if the theory of strong interaction is such
that the coupling flows toward the fixed point g∗= 0. If so, then the strong interaction
between quarks would actually weaken at higher and higher energy scales.
All of this is of course now “obvious” with the benefit of hindsight, but dear students,
remember that at that time field theory was pronounced as possibly unsuitable for young
minds and the renormalizable group was considered “dangerous” even in a field theory
text!
The theory of strong interaction was unknown. But if we were so bold as to accept the
dangerous renormalization group ideas then we might even find the theory of the strong
interaction by searching for asymptotically free theories, which is what theories with an
attractive fixed point at g∗= 0 became known as.
Asymptotically free theories are clearly wonderful. Their behavior at high energies can
be studied using perturbative methods. And so in this way the fundamental theory of the
strong interaction, now known as quantum chromodynamics, about which more later, was
found.
Looking at physics on different length scales
The need for renormalization groups is really transparent in condensed matter physics.
Instead of generalities, let me focus on a particularly clear example, namely surface
growth. Indeed, that was why I chose to introduce the Kardar-Parisi-Zhang equation in
chapter VI.6. We learned that to study surface growth we have to evaluate the functional
or path integral
Z() =


Dh e−S(h).
(9)
with, you will recall,
S(h) = 1
2

dD⃗x dt
∂h
∂t −∇2h −g
2 (∇h)2
2
.
(10)
This defines a field theory. As with any field theory, and as I indicate, a cutoff  has to be
introduced. We integrate over only those field configurations h(⃗x, t) that do not contain
Fourier components with ⃗k and ω larger than . (In principle, since this is a nonrelativistic
theory we should have different cutoffs for ⃗k and for ω, but for simplicity of exposition let
us just refer to them together generically as .) The appearance of the cutoff is completely
physical and necessary. At the very least, on length scales comparable to the size of the
relevant molecules, the continuum description in terms of the field h(⃗x, t) has long since
broken down.
Physically, since the random driving term η(⃗x, t) is a white noise, that is, η at ⃗x and
at ⃗x′ (and also at different times) are not correlated at all, we expect the surface to look

VI.8. Renormalization Group Flow | 361
(a)
(b)
Figure VI.8.1
very uneven on a microscopic scale, as depicted in figure VI.8.1a. But suppose we are not
interested in the detailed microscopic structure, but more in how the surface behaves on
a larger scale. In other words, we are content to put on blurry glasses so that the surface
appears as in figure VI.8.1b. This is a completely natural way to study a physical system,
one that we are totally familiar with from day one in studying physics. We may be interested
in physics over some length scale L and do not care about what happens on length scales
much less than L.
The renormalization group is the formalism that allows us to relate the physics on differ-
ent length scales or, equivalently, physics on different energy scales. In condensed matter
physics, one tends to think of length scales, and in particle physics, of energy scales. The
modern approach to renormalization groups came out of the study of critical phenomena
by Kadanoff, Fisher, Wilson, and others, as mentioned in chapter V.3. Consider, for exam-
ple, the Ising model, with the spin at each site either up or down and with a ferromagnetic
interaction between neighboring spins. At high temperatures, the spins point randomly
up and down. As the temperature drops toward the ferromagnetic transition point, islands
of up spins (we say up spins to be definite, we could just as easily talk of down spins) start
to appear. They grow ever larger in size until the critical temperature Tc at which all the
spins in the entire system point up. The characteristic length scale of the physics at any
particular temperature is given by the typical size of the islands. The physically motivated
block spin method of Kadanoff et al. treats blocks of up spin as one single effective up
spin, and similarly blocks of down spins. The notion of a renormalization group is then
the natural one for describing these effective spins by an effective Hamiltonian appropriate
to that length scale.
It is more or less clear how to implement this physical idea of changing length scales in
the functional integral (9). We are supposed to integrate over those h(⃗k, ω), with ⃗k and ω
less than . Suppose we do only a fraction of what we are supposed to do. Let us integrate

362 | VI. Field Theory and Condensed Matter
over those h(⃗k, ω) with ⃗k and ω larger than  −δ but smaller than . This is precisely
what we mean when we say that we don’t care about the fluctuations of h(⃗x, t) on length
and time scales less than ( −δ)−1.
Putting on blurry glasses
For the sake of simplicity, let us go back to our favorite, the λϕ4 theory, instead of the surface
growth problem. Recall from the preceding chapters the importance of the Euclidean λϕ4
theory in modern condensed matter theory. So, continue the λϕ4 theory to Euclidean space
and stare at the integral
Z() =


Dϕe−
ddxL(ϕ)
(11)
The notation

 instructs us to include only those field configurations ϕ(x) =

[ddk/(2π)d]eikxϕ(k) such that ϕ(k) = 0 for |k| ≡(d
i=1 k2
i )
1
2 larger than . As explained
in the text this amounts to putting on blurry glasses with resolution L = 1/: We do not
admit or see fluctuations with length scales less than L.
Evidently, the O(d) invariance, namely the Euclidean equivalent of Lorentz invariance,
will make our lives considerably easier. In contrast, for the surface growth problem we will
need special glasses that blur space and time differently.1
We are now ready to make our glasses blurrier by letting  → −δ (with δ > 0).
Write ϕ = ϕs + ϕw (s for “smooth” and w for “wriggly”), defined such that the Fourier
components ϕs(k) and ϕw(k) are nonzero only for |k| ≤( −δ) and ( −δ) ≤|k| ≤
, respectively. (Obviously, the designation “smooth” and “wriggly” is for convenience.)
Plugging into (11) we can write
Z() =

−δ
Dϕse−
ddxL(ϕs)

Dϕwe−
ddxL1(ϕs,ϕw)
(12)
where all the terms in L1(ϕs, ϕw) depend on ϕw. (What we are doing here is somewhat
reminiscent of what we did in chapter IV.3.) Imagine doing the integral over ϕw. Call the
result
e−
ddxδL(ϕs) ≡

Dϕwe−
ddxL1(ϕs,ϕw)
and thus we have
Z() =

−δ
Dϕse−
ddx[L(ϕs)+δL(ϕs)]
(13)
There, we have done it! We have rewritten the theory in terms of the “smooth” field ϕs.
Of course, this is all formal, since in practice the integral over ϕw can only be done
perturbatively assuming that the relevant couplings are small. If we could do the integral
1 In condensed matter physics, the so-called dynamical exponent z measures this difference. More precisely,
in the context of the surface growth problem, the correlator (introduced in chapter VI.6) satisfies the dynamic
scaling form given in (VI.6.3). Naively, the dynamical exponent z should be 2. (For a brief review of all this, see
M. Kardar and A. Zee, Nucl. Phys. B464[FS]: 449, 1996, cond-mat/9507112.)

VI.8. Renormalization Group Flow | 363
over ϕw exactly, we might as well just do the integral over ϕ and then we would have no
need for all this renormalization group stuff.
For pedagogical purposes, consider more generally L = 1
2(∂ϕ)2 + 
n λnϕn + . . . (so
that λ2 is the usual 1
2m2 and λ4 the usual λ.) Since terms such as ∂ϕs∂ϕw integrate to zero,
we have

ddxL1(ϕs, ϕw) =

ddx
1
2(∂ϕw)2 + 1
2m2ϕ2
w + . . .

with ϕs hiding in the (. . .). This describes a field ϕw interacting with both itself and a
background field ϕs(x). By symmetry considerations δL(ϕs) has the same form as L(ϕs)
but with different coefficients. Adding δL(ϕs) to L(ϕs) thus shifts2 the couplings λn [and the
coefficient of 1
2(∂ϕs)2.] These shifts generate the flow in the space of couplings I described
earlier.
We could have perfectly well left (13) as our end result. But suppose we want to compare
(13) with (11). Then we would like to change the

−δ in (13) to

 . For convenience,
introduce the real number b < 1 by  −δ = b. In

−δ we are told to integrate over
fields with |k| ≤b. So all we have to do is make a trivial change of variable: Let k = bk′
so that |k′| ≤. But then correspondingly we have to change x = x′/b so that eikx = eik′x′.
Plugging in, we obtain

ddxL(ϕs) =

ddx′b−d

1
2b2(∂′ϕs)2 +

n
λnϕn
s + . . .

(14)
where ∂′ = ∂/∂x′ = (1/b)∂/∂x. Define ϕ′ by b2−d(∂′ϕs)2 = (∂′ϕ′)2 or in other words ϕ′ =
b
1
2(2−d)ϕs. Then (14) becomes

ddx′

1
2(∂′ϕ′)2 +

n
λnb−d+(n/2)(d−2)ϕ′n + . . .

Thus, if we define the coefficient of ϕ′n as λ′
n we have
λ′
n = b(n/2)(d−2)−dλn
(15)
an important result in renormalization group theory.
Relevant, irrelevant, and marginal
Let us absorb what this means. (For the time being, let us ignore δL(ϕs) to keep the
discussion simple.) As we put on blurrier glasses, in other words, as we become interested
in physics over longer distance scales, we can once again write Z() as in (11) except that
the couplings λn have to be replaced by λ′
n. Since b < 1 we see from (15) that the λn’s with
(n/2)(d −2) −d > 0 get smaller and smaller and can eventually be neglected. A dose of
jargon here: The corresponding operators ϕn (for historical reasons we revert for an instant
2 Terms such as (∂ϕ)4 can also be generated and that is why I wrote L(ϕ) with the (. . .) under which terms such
as these can be swept. You can check later that for most applications these terms are irrelevant in the technical
sense to be defined below.

364 | VI. Field Theory and Condensed Matter
from the functional integral language to the operator language) are called irrelevant. They
are the losers. Conversely, the winners, namely the ϕn’s for which (n/2)(d −2) −d < 0,
are called relevant. Operators for which (n/2)(d −2) −d = 0 are called marginal.
For example, take n = 2 : m′2 = b−2m2 and the mass term is always relevant in any
dimension. On the other hand, take n = 4, and we see that λ′ = bd−4λ and ϕ4 is relevant
for d < 4, irrelevant for d > 4, and marginal at d = 4. Similarly, λ′
6 = b2d−6λ and ϕ6 is
marginal at d = 3 and becomes irrelevant for d > 3.
We also see that d = 2 is special: All the ϕn’s are relevant.
Now all this may ring a bell if you did the exercises religiously. In exercise III.2.1
you showed that the coupling λn has mass dimension [λn] = (n/2)(2 −d) + d. Thus, the
quantity (n/2)(d −2) −d is just the length dimension of λn. For example, for d = 4,
λ6 has mass dimension −2 and thus as explained in chapter III.2 the ϕ6 interaction is
nonrenormalizable, namely that it has nasty behavior at high energy. But condensed matter
physicists are interested in the long distance limit, the opposite limit from the one that
interests particle physicsts. Thus, it is the nasty guys like ϕ6 that become irrelevant in the
long distance limit.
One more piece of jargon: Given a scalar field theory, the dimension d at which the most
relevant interaction becomes marginal is known as the critical dimension in condensed
matter physics. For example, the critical dimension for a ϕ6 theory is 3. It is now just
a matter of “high school arithmetic” to translate (15) into differential form. Write λ′
n =
λn + δλn; then from b = 1 −(δ/) we have δλn = −[ n
2(d −2) −d]λn(δ/).
Let us now be extra careful about signs. As I have already remarked, for (n/2)(d −2) −
d > 0 the coupling λn (which, for definiteness, we will think of as positive) get smaller,
as is evident from (15). But since we are decreasing  to  −δ, a positive δ actually
corresponds to the resolution of our blurry glasses L = −1 changing to L + L(δ/).
Thus we obtain
Ldλn
dL = −
n
2(d −2) −d

λn,
(16)
so that for (n/2)(d −2) −d > 0 a positive λn would decrease as L increases.3
In particular, for n = 4, L(dλ/dL) = (4 −d)λ. In most condensed matter physics appli-
cations, d ≤3 and so λ increases as the length scale of the physics under study increases.
The ϕ4 coupling is relevant as noted above.
The δL(ϕs), which we provisionally neglected, contributes an additional term, which we
call dynamical in contrast to the geometrical or “trivial” term displayed, to the right-hand
side of (16). Thus, in general L(dλn/dL) = −[(n/2)(d −2) −d] λn + K(d, n, . . . , λj , . . .),
with the dynamical term K depending not only on d and n, but also on all the other
couplings. [For example, in (5) the “trivial” term vanishes since we are in 4-dimensional
spacetime; there is only a dynamical contribution.]
3 Note that what appears on the right-hand side is minus the length dimension of λn, not the length dimension
(n/2)(d −2) −d as one might have guessed naively.

VI.8. Renormalization Group Flow | 365
As you can see from this discussion, a more descriptive name for the renormalization
group might be “the trick of doing an integral a little bit at a time.”
Exploiting symmetry
To determine the renormalization group flow of the coupling g in the surface growth
problem we can repeat the same type of computation we did to determine the flow of the
coupling λ and of e in our two previous examples, namely we would calculate, to use the
language of particle physics, the amplitude for h-h scattering to one loop order. But instead,
let us follow the physical picture of Kadanoff et al. In Z() =

Dh e−S(h) we integrate over
only those h(⃗k, ω) with ⃗k and ω larger than  −δ but less than .
I will now show you how to exploit the symmetry of the problem to minimize our labor.
The important thing is not necessarily to learn about the dynamics of surface growth,
but to learn the methodology that will serve you well in other situations. I have picked
a particularly “difficult” nonrelativistic problem whose symmetries are not manifest, so
that if you master the renormalization group for this problem you will be ready for almost
anything.
Imagine having done this partial integration and call the result

Dh e−˜S(h). At this point
you should work out the symmetries of the problem as indicated in the exercises. Then
you can argue that ˜S(h) must have the form
˜S(h) = 1
2

dDx dt

α ∂
∂t −β∇2

h −α g
2 (∇h)2
2
+ . . . ,
(17)
depending on two parameters α and β. The (. . .) indicates terms involving higher powers
of h and its derivatives. The simplifying observation is that the same coefficient α multiplies
both ∂h/∂t and (g/2)(∇h)2. Once we know α and β then by suitable rescaling we can
bring the action ˜S(h) back into the same form as S(h) and thus find out how g changes.
Therefore, it suffices to look at the (∂h/∂t)2 and (∇2h)2 terms in the action, or equivalently
at the propagator, which is considerably simpler to calculate. As Rudolf Peierls once said4
to the young Hans Bethe, “Erst kommt das Denken, dann das Integral.” (Roughly, “First
think, then do the integral.”) We will not do the computation here. Suffice it to note that g
has the high school dimension of (length)
1
2(D−2) (see exercise VI.8.5). Thus, according to
the preceding discussion we should have
L dg
dL = 1
2(2 −D)g + cDg3 + . . .
(18)
A detailed calculation is needed to determine the coefficient cD, which obviously
depends on the dimension of space D since the Feynman integrals depend on D.
The equation tells us how g, an effective measure of nonlinearity in the physics of
4 John Wheeler gave me similar advice when I was a student: “Never calculate without first knowing the
answer.”

366 | VI. Field Theory and Condensed Matter
surface growth, changes when we change the length scale L. For the record, cD =
[S(D)/4(2π)D](2D −3)/D, with S(D) the D-dimensional solid angle. The interesting
factor is of course (2D −3), changing sign between5 D = 1 and 2.
Localization
As I said earlier, renormalization group flow has literally become part of the language of
condensed matter and high energy physics. Let me give you another example of the power
of the renormalization group. Go back to Anderson localization (chapter VI.7), which so
astonished the community at the time. People were surprised that the localization behavior
depends so drastically on the dimension of space D, and perhaps even more so, that for
D = 2 all states are localized no matter how weak the strength of the disorder. Our usual
physical intuition would say that there is a critical strength. As we will now see, both
features are quite naturally accounted for in the renormalization group language. Already,
you see in (18) that D enters in an essential way.
I now offer you a heuristic but beautiful (at least to me) argument given by Abra-
hams, Anderson, Licciardello, and Ramakrishnan, who as a result became known to the
condensed matter community as the “Gang of Four.” First, you have to understand the
difference between conductivity σ and conductance G in solid state physics lingo. Conduc-
tivity6 is defined by ⃗J = σ ⃗E, where ⃗J measures the number of electrons passing through
a unit area per unit time. Conductance G is the inverse of resistance (the mnemonic: the
two words rhyme). Resistance R is the property of a lump of material and defined in high
school physics by V = IR, where the current I measures the number of electrons passing
by per unit time. To relate σ and G, consider a lump of material, taken to be a cube of size
L, with a voltage drop V across it. Then I = JL2 = σEL2 = σ(V/L)L2 = σLV and thus7
G(L) = 1/R = I/V = σL. Next, let us go to two dimensions. Consider a thin sheet of ma-
terial of length and width L and thickness a ≪L. (We are doing real high school physics,
not talking about some sophisticated field theorist’s idea of two dimensional space!) Again,
apply a voltage drop V over the length L : I = J(aL) = σEaL = σ(V/L)aL = σV a and so
G(L) = 1/R = I/V = σa. I will let you go on to one dimension: Consider a wire of length
L and width and thickness a. In this way, we obtain G(L) ∝LD−2. Incidentally, condensed
matter physicists customarily define a dimensionless conductance g(L) ≡ℏG(L)/e2.
5 Incidentally, the theory is exactly solvable for D = 1 (with methods not discussed in this book).
6 Over the years I have asked a number of high energy theorists how is it possible to obtain ⃗J = σ ⃗E, which
manifestly violates time reversal invariance, if the microscopic physics of an electron scattering on an impurity
atom perfectly well respects time reversal invariance. Very few knew the answer. The resolution of this apparent
paradox is in the order of limits! Condensed matter theorists calculate a frequency and wave vector dependent
conductivity σ(ω, ⃗k) and then take the limit ω, ⃗k →0 and ⃗k2/ω →0. Before the limit is taken, time reversal
invariance holds. The time it takes the particle to find out that it is in a box of size of order 1/k is of order 1/(Dk2)
(with D the diffusion constant). The physics is that this time has to be much longer than the observation time
∼1/ω.
7 Sam Treiman told me that when he joined the U.S. Army as a radio operator he was taught that there were
three forms of Ohm’s law: V = IR, I = V/R, and R = V/I . In the second equality here we use the fourth form.

VI.8. Renormalization Group Flow | 367
1
−1
β(g)
gc
g
D = 3
D = 2
D = 1
Figure VI.8.2
We also know the behavior of g(L) when g(L) is small or, in other words, when the
material is an insulator for which we expect g(L) ∼ce−L/ξ, with ξ some length charac-
teristic of the material and determined by the microscopic physics. Thus, for g(L) small,
L(dg/dL) = −(L/ξ)g(L) = g(L)[log g(L) −log c], where the constant log c is negligible
in the regime under consideration.
Putting things together, we obtain
β(g) ≡L
g
dg
dL =
 (D −2) + . . . for large g
log g + . . . for small g
(19)
First, a trivial note: in different subjects, people define β(g) differently (without affecting
the physics of course). In localization theory, β(g) is traditionally defined as d log g/d log L
as indicated here. Given (19) we can now make a “most plausible” plot of β(g) as shown
in figure VI.8.2. You see that for D = 2 (and D = 1) the conductance g(L) always flows
toward 0 as we go to long distances (macroscopic measurements on macroscopic materials)
regardless of where we start. In contrast, for D = 3, if g0 the initial value of g is greater than
a critical gc then g(L) flows to infinity (presumably cut off by physics we haven’t included)
and the material is a metal, while if g0 < gc, the material is an insulator. Incidentally,
condensed matter theorists often speak of a critical dimension Dc at which the long
distance behavior of a system changes drastically; in this case Dc = 2.
Effective description
In a sense, the renormalization group goes back to a basic notion of physics, that the
effective description can and should change as we move from one length scale to another.
For example, in hydrodynamics we do not have to keep track of the detailed interaction

368 | VI. Field Theory and Condensed Matter
among water molecules. Similarly, when we apply the renormalization group flow to the
strong interaction, starting at high energies and moving toward low energies, the effective
description goes from a theory of quarks and gluons to a theory of nucleons and mesons.
In this more general picture then, we no longer think of flowing in a space of coupling
constants, but in “the space of Hamiltonians” that some condensed matter physicists like
to talk about.
Exercises
VI.8.1
Show that the solution of dg/dt = −bg3 + . . . is given by
1
α(t) =
1
α(0) + 8πbt + . . .
(20)
where we defined α(t) = g(t)2/4π.
VI.8.2
In our discussion of the renormalization group, in λϕ4 theory or in QED, for the sake of simplicity
we assumed that the mass m of the particle is much smaller than μ and thus set m equal to zero. But
nothing in the renormalization group idea tells us that we can’t flow to a mass scale below m. Indeed, in
particle physics many orders of magnitude separate the top quark mass mt from the up quark mass mu.
We might want to study how the strong interaction coupling flows from some mass scale far above mt
down to some mass scale μ below mt but still large compared to mu. As a crude approximation, people
often set any mass m below μ equal to zero and any m above μ to infinity (i.e., not contributing to the
renormalization group flow). In reality, as μ approaches m from above the particle starts to contribute
less and drops out as μ becomes much less than m. Taking either the λϕ4 theory or QED study this
so-called threshold effect.
VI.8.3
Show that (10) is invariant under the so-called Galilean transformation
h(⃗x, t) →h′(⃗x, t) = h

⃗x + g⃗ut, t

+ ⃗u . ⃗x + g
2 u2t
(21)
Show that because of this symmetry only two parameters α and β appear in (17).
VI.8.4
In ˜S(h) only derivatives of the field h can appear and not the field itself. (Since the transformation
h(⃗x, t) →h(⃗x, t) + c with c a constant corresponds to a trivial shift of where we measure the surface
height from, the physics must be invariant under this transformation.) Terms involving only one power
of h cannot appear since they are all total divergences. Thus, ˜S(h) must start with terms quadratic in h.
Verify that the ˜S(h) given in (17) is indeed the most general. A term proportional to (∇h)2 is also allowed
by symmetries and is in fact generated. However, such a term can be eliminated by transforming to a
moving coordinate frame h →h + ct.
VI.8.5
Show that g has the high school dimension of (length)
1
2 (D−2). [Hint: The form of S(h) implies that t has
the dimension of length squared and so h has the dimension (length)
1
2 (2−D).] Comparing the terms ∇2h
and g(∇h)2 we determine the dimension of g.]
VI.8.6
Calculate the h propagator to one loop order. Extract the coefficients of the ω2 and k4 terms in a low
frequency and wave number expansion of the inverse propagator and determine α and β.
VI.8.7
Study the renormalization group flow of g for D = 1, 2, 3.

Part VII
Grand Unification

This page intentionally left blank

VII.1
Quantizing Yang-Mills Theory
and Lattice Gauge Theory
One reason that Yang-Mills theory was not immediately taken up by physicists is that
people did not know how to calculate with it. At the very least, we should be able to
write down the Feynman rules and calculate perturbatively. Feynman himself took up the
challenge and concluded, after looking at various diagrams, that extra fields with ghostlike
properties had to be introduced for the theory to be consistent. Nowadays we know how
to derive this result more systematically.
The story goes that Feynman wanted to quantize gravity but Gell-Mann suggested to
him to first quantize Yang-Mills theory as a warm-up exercise.
Consider pure Yang-Mills theory—it will be easy to add matter fields later. Follow what
we have learned. Split the Lagrangian L = L0 + L1 as usual into two pieces (we also choose
to scale A →gA):
L0 = −1
4(∂μAa
ν −∂νAa
μ)2
(1)
and
L1 = −1
2g(∂μAa
ν −∂νAa
μ)f abcAbμAcν −1
4g2f abcf adeAb
μAc
νAdμAeν
(2)
Then invert the differential operator in the quadratic piece (1) to obtain the propagator.
This part looks the same as the corresponding procedure for quantum electrodynamics,
except for the occurrence of the index a. Just as in electrodynamics, the inverse does not
exist and we have to fix a gauge.
I built up the elaborate Faddeev-Popov method to quantize quantum electrodynamics
and as I noted, it was a bit of overkill in that context. But here comes the payoff: We can now
turn the crank. Recall from chapter III.4 that the Faddeev-Popov method would give us
Z =

DAeiS(A)(A)δ[f (A)]
(3)
with (A) ≡{

Dgδ[f (Ag)]}−1 and S(A) =

d4xL the Yang-Mills action. (As in chap-
ter III.4, Ag ≡gAg−1 −i(∂g)g−1 denotes the gauge transform of A. Here g ≡g(x) denotes

372 | VII. Grand Unification
the group element that defines the gauge transformation at x and is obviously not to be
confused with the coupling constant.)
Since (A) appears in (3) multiplied by δ[f (A)], in the integral over g we expect, for
a reasonable choice of f (A), only infinitesimal g to be relevant. Let us choose f (A) =
∂A −σ . Under an infinitesimal transformation, Aa
μ →Aa
μ −f abcθbAc
μ + ∂μθa and thus
(A) = {

Dθδ[∂Aa −σ a −∂μ(f abcθbAc
μ −∂μθa)]}−1
(4)
“ = ” {

Dθδ[∂μ(f abcθbAc
μ −∂μθa)]}−1.
where the “effectively equal sign” follows since (A) is to be multiplied later by δ[f (A)].
Let us write formally
∂μ(f abcθbAc
μ −∂μθa) =

d4yKab(x, y)θb(y)
(5)
thus defining the operator Kab(x, y) = ∂μ(f abcAc
μ −∂μδab)δ(4)(x −y). Note that in con-
trast to electromagnetism here K depends on the gauge potential. The elementary result

dθδ(Kθ) = 1/K for θ and K real numbers can be generalized to

dθδ(Kθ) = 1/ det K
for θ a real vector and K a nonsingular matrix. Regarding Kab(x, y) as a matrix, we ob-
tain (A) = det K, but we know from chapter II.5 how to represent the determinant as a
functional integral over Grassmann variables: Write (A) =

DcDc†eiSghost(c†,c), with
Sghost(c†, c) =

d4xd4yc†
a(x)Kab(x, y)cb(y)
=

d4x[∂c†
a(x)∂ca(x) −∂μc†
a(x)f abcAc
μ(x)cb(x)]
=

d4x∂c†
a(x)Dca(x)
(6)
and with D the covariant derivative for the adjoint representation, to which the fields ca
and c†
a belong just like Aa
μ. The fields ca and c†
a are known as ghost fields because they
violate the spin-statistics connection: Though scalar, they are treated as anticommuting.
This “violation” is acceptable because they are not associated with physical particles and
are introduced merely to represent (A) in a convenient form.
This takes care of the (A) factor in (3). As for the δ[f (A)] factor, we use the same trick
as in chapter III.4 and integrate Z over σ a(x) with a Gaussian weight e−(i/2ξ) 
d4xσ a(x)2
so that δ[f (A)] gets replaced by e−(i/2ξ) 
d4x(∂Aa)2.
Putting it all together, we obtain
Z =

DADcDc†eiS(A)−(i/2ξ) 
d4x(∂A)2+iSghost(c†,c)
(7)
with ξ a gauge parameter. Comparing with the corresponding expression for an abelian
gauge theory in chapter III.4, we see that in nonabelian gauge theories we have a ghost
action Sghost in addition to the Yang-Mills action. Thus, L0 and L1 are changed to
L0 = −1
4(∂μAa
ν −∂νAa
μ)2 −1
2ξ (∂μAa
μ)2 + ∂c†
a∂ca
(8)

VII.1. Quantizing Yang-Mills Theory | 373
a,μ
c,λ
b,ν
k1
k3
k2
a,μ
b,ν
d,ρ
c,λ
c,μ
a
b
p
(a)
(b)
(c)
Figure VII.1.1
and
L1 = −1
2g(∂μAa
ν −∂νAa
μ)f abcAbμAcν + 1
4g2f abcf adeAb
μAc
νAdμAeν −∂μc†
agf abcAc
μcb(x)
(9)
We can now read off the propagators for the gauge boson and for the ghost field imme-
diately from (8). In particular, we see that except for the group index a the terms quadratic
in the gauge potential are exactly the same as the terms quadratic in the electromagnetic
gauge potential in (III.4.8). Thus, the gauge boson propagator is
(−i)
k2

gνλ −(1 −ξ)kνkλ
k2

δab
(10)
Compare with (III.4.9). From the term ∂c†
a∂ca in (8) we find the ghost propagator to be
(i/k2)δab.
From L1 we see that there is a cubic and a quartic interaction between the gauge
bosons, and an interaction between the gauge boson and the ghost field, as illustrated
in figure VII.1.1. The cubic and the quartic couplings can be easily read off as
gf abc[gμν(k1 −k2)λ + gνλ(k2 −k3)μ + gλμ(k3 −k1)ν]
(11)
and
−ig2[f abef cde(gμλgνρ −gμρgνλ) + f adef cbe(gμλgνρ −gμνgρλ)
+ f acef bde(gμνgλρ −gμρgνλ)]
(12)
respectively. The coupling to the ghost field is
gf abcpμ
(13)

374 | VII. Grand Unification
Obviously, we can exploit various permutation symmetries in writing these down. For
instance, in (12) the second term is obtained from the first by the interchange {c, λ} ↔
{d, ρ}, and the third and fourth terms are obtained from the first and second by the
interchange {a, μ} ↔{c, λ}.
Unnatural act
In a highly symmetric theory such as Yang-Mills, perturbating is clearly an unnatural
act as it involves brutally splitting L into two parts: a part quadratic in the fields and
the rest. Consider, for example, an exactly soluble single particle quantum mechanics
problem, such as the Schr¨odinger equation with V (x) = 1 −(1/ cosh x)2. Imagine writing
V (x) = 1
2x2 + W(x) and treating W(x) as a perturbation on the harmonic oscillator. You
would have a hard time reproducing the exact spectrum, but this is exactly how we brutalize
Yang-Mills theory in the perturbative approach: We took the “holistic entity” tr FμνF μν and
split it up into the “harmonic oscillator” piece tr(∂μAν −∂νAμ)2 and a “perturbation.”
If Yang-Mills theory ever proves to be exactly soluble, the perturbative approach with its
mangling of gauge invariance is clearly not the way to do it.
Lattice gauge theory
Wilson proposed a way out: Do violence to Lorentz invariance rather than to gauge in-
variance. Let us formulate Yang-Mills theory on a hypercubic lattice in 4-dimensional
Euclidean spacetime. As the lattice spacing a →0 we expect to recover 4-dimensional
rotational invariance and (by a Wick rotation) Lorentz invariance. Wilson’s formulation,
known as lattice gauge theory, is easy to understand, but the notation is a bit awkward, due
to the lack of rotational invariance. Denote the location of the lattice sites by the vector xi.
On each link, say the one going from xi to one of its nearest neighbors xj , we associate an
N by N simple unitary matrix Uij. Consider the square, known as a plaquette, bounded
by the four corners xi, xj , xk, and xl (with these nearest neighbors to each other.) See
figure VII.1.2. For each plaquette P we associate the quantity S(P) = Re tr UijUjkUklUli,
constructed to be invariant under the local transformation
Uij →V †
i UijVj
(14)
The symmetry is local because for each site xi we can associate an independent Vi.
Wilson defined Yang-Mills theory by
Z =

dUe(1/2f 2) 
P S(P)
(15)
where the sum is taken over all the plaquettes in the lattice. The coupling strength f
controls how wildly the unitary matrices Uij’s fluctuate. For small f , large values of S(P)
are favored, and so the Uij’s are all approximately equal to the unit matrix (up to an
irrelevant global transformation.)

VII.1. Quantizing Yang-Mills Theory | 375
xi
xj
xl
xk
Uli
Ujk
Ukl
Uij
Figure VII.1.2
Without doing any arithmetic, we can argue by symmetry that in the continuum limit
a →0, Yang-Mills theory as we know it must emerge: The action is manifestly invariant
under local SU(N) transformation. To actually see this, define a field Aμ(x) with μ =
1, 2, 3, 4, permeating the 4-dimensional Euclidean space the lattice lives in, by
Uij = V †
i eiaAμ(x)Vj
(16)
where x = 1
2(xi+ xj) (namely the midpoint of the link Uij lives on) and μ is the direction
connecting xi to xj (namely ˆμ ≡(xj −xi)/a is the unit vector in the μ direction.) The V ’s
just reflect the gauge freedom in (14) and obviously do not enter into the plaquette action
S(P) by construction. I will let you show in an exercise that
tr UijUjkUklUli = tr eia2Fμν+O(a3)
(17)
with Fμν the Yang-Mills field strength evaluated at the center of the plaquette. Indeed, we
could have discovered the Yang-Mills field strength in this way. I hope that you start to
see the deep geometric significance of Fμν. Continuing the exercise you will find that the
action on each plaquette comes out to be
S(P) = Re tr eia2Fμν+O(a3)
= Re tr[1 + ia2Fμν −1
2a4FμνFμν + O(a5)] = tr 1 −1
2a4 tr FμνFμν + . . .
(18)
and so up to an irrelevant additive constant we recover in (15) the Yang-Mills action in the
continuum limit. Again, it is worth emphasizing that without going through any arithmetic
we could have fixed the a4 term in (18) (up to an overall constant) by dimensional analysis
and gauge invariance.1
1 The sign can be easily checked against the abelian case.

376 | VII. Grand Unification
The Wilson formulation is beautiful in that none of the hand-wringing over gauge
fixing, Faddeev-Popov determinant, ghost fields, and so forth is necessary for (15) to make
sense. Recalling chapter V.3 you see that (15) defines a statistical mechanics problem
like any other. Instead of integrating over some spin variables say, we integrate over the
group SU(N) for each link. Most importantly, the lattice gauge formulation opens up
the possibility of computing the properties of a highly nontrivial quantum field theory
numerically. Lattice gauge theory is a thriving area of research. For a challenge, try to
incorporate fermions into lattice gauge theory: This is a difficult and ongoing problem
because fermions and spinor fields are naturally associated with SO(4), which does not
sit well on a lattice.
Wilson loop
Field theorists usually deal with local observables, that is, observables defined at a space-
time point x, such as J μ(x) or tr Fμν(x)F μν(x), but of course we can also deal with
nonlocal observables, such as ei 
C dxμAμ in electromagnetism, where the line integral is
evaluated over a closed curve C. The gauge invariant quantity in the exponential is equal
to the electromagnetic flux going through the surface bounded by C. (Indeed, recall chap-
ter IV.4.)
Wilson pointed out that lattice gauge theory contains a natural gauge invariant but
nonlocal observable W(C) ≡tr UijUjk . . . UnmUmi, where the set of links connecting xi
to xj to xk et cetera and eventually to xm and back to xi traces out a loop called C. Referring
to (16) we see that W(C), known as the Wilson loop, is the trace of a product of many
factors of eiaAμ. Thus, in the continuum limit a →0, we have evidently
W(C) ≡tr Pei 
C dxμAμ
(19)
with C now an arbitrary curve in Euclidean spacetime. Here P denotes path ordering,
clearly necessary since the Aμ’s associated with different segments of C, being matrices,
do not commute with each other. [Indeed, P is defined by the lattice definition of W(C).]
To understand the physical meaning of the Wilson loop, Recall chapters I.4 and I.5. To
obtain the potential energy E between two oppositely charged lumps we have to compute
lim
T →∞
1
Z

DAeiSMaxwell(A)+i 
d4xAμJ μ = e−iET
For two lumps held at a distance R apart we plug in
J μ(x) = ημ0{δ(3)(⃗x)−δ(3)[⃗x −(R, 0, 0)]}
and see that we are actually computing the expectation value ⟨e
i(
C1 dxμAμ−
C2 dxμAμ)⟩in
a fluctuating electromagnetic field, where C1 and C2 denote two straight line segments
at ⃗x = (0, 0, 0) and ⃗x = (R, 0, 0), respectively. It is convenient to imagine bringing the
two lumps together in the far future (and similarly in the far past). Then we deal instead
with the manifestly gauge invariant quantity ⟨ei 
C dxμAμ⟩, where C is the rectangle shown

VII.1. Quantizing Yang-Mills Theory | 377
T
R
Time
Space
C
Figure VII.1.3
in figure VII.1.3. Note that for T large log⟨ei 
C dxμAμ⟩∼−iE(R)T , which is essentially
proportional to the perimeter length of the rectangle C.
As we will discuss in chapter VII.3 and as you have undoubtedly heard, the currently
accepted theory of the strong interaction involves quarks coupled to a nonabelian Yang-
Mills gauge potential Aμ. Thus, to determine the potential energy E(R) between a quark
and an antiquark held fixed at a distance R from each other we “merely” have to compute
the expectation value of the Wilson loop
⟨W(C)⟩= 1
Z

dUe−(1/2f 2) 
P S(P )W(C)
(20)
In lattice gauge theory we could compute log⟨W(C)⟩for C the large rectangle in fig-
ure VII.1.3 numerically, and extract E(R). (We lost the i because we are living in Euclidean
spacetime for the purpose of this discussion.)
Quark confinement
You have also undoubtedly heard that since free quarks have not been observed, quarks are
generally believed to be permanently confined. In particular, it is believed that the potential
energy between a quark and an antiquark grows linearly with separation E(R) ∼σR.
One imagines a string tying the quark to the antiquark with a string tension σ . If this
conjecture is correct, then log⟨W(C)⟩∼σRT should go as the area RT enclosed by C.
Wilson calls this behavior the area law, in contrast to the perimeter law characteristic of
familiar theories such as electromagnetism. To prove the area law in Yang-Mills theory is
one of the outstanding challenges of theoretical physics.

378 | VII. Grand Unification
Exercises
VII.1.1
The gauge choice in the text preserves Lorentz invariance. It is often useful to choose a gauge that breaks
Lorentz invariance, for example, f (A) = nμAμ(x) with n some fixed 4-vector. This class of gauge choices,
known as the axial gauge, contains various popular gauges, each of which corresponds to a particular
choice of n. For instance, in light-cone gauge, n = (1, 0, 0, 1), in space-cone gauge, n = (0, 1, i, 0). Show
that for any given A(x) we can find a gauge transformation so that n . A′(x) = 0.
VII.1.2
Derive (17) and relate f to the coupling g in the continuum formulation of Yang-Mills theory. [Hint: Use
the Baker-Campbell-Hausdorff formula
eAeB = eA+B+ 1
2 [A,B]+ 1
12 ([A,[A,B]]+[B,[B,A]])+...
VII.1.3
Consider a lattice gauge theory in (D + 1)-dimensional space with the lattice spacing a in D-dimensional
space and b in the extra dimension. Obtain the continuum D-dimensional field theory in the limit a →0
with b kept fixed.
VII.1.4 Study in (2) the alternative limit b →0 with a kept fixed so that you obtain a theory on a spatial lattice
but with continuous time.
VII.1.5
Show that for lattice gauge theory the Wilson area law holds in the limit of strong coupling. [Hint: Expand
(20) in powers of f −2.]

VII.2
Electroweak Unification
The scourge of massless spin 1 particles
With the benefit of hindsight, we now know that Nature likes Yang-Mills theory. In the
late 1960s and early 1970s, the electromagnetic and weak interactions were unified into
an electroweak interaction, described by a nonabelian gauge theory based on the group
SU(2) ⊗U(1). Somewhat later, in the early 1970s, it was realized that the strong interaction
can be described by a nonabelian gauge theory based on the group SU(3). Nature literally
consists of a web of interacting Yang-Mills fields.
But when the theory was first proposed in 1954, it seemed to be totally inconsistent with
observations as they were interpreted at that time. As Yang and Mills themselves pointed
out in their paper, the theory contains massless spin 1 particles, which were certainly not
known experimentally. Thus, except for interest on the part of a few theorists (Schwinger,
Glashow, Bludman, and others) who found the mathematical structure elegantly attractive
and felt that nonabelian gauge theory must somehow be relevant for the weak interaction,
the theory gradually sank into oblivion and was not part of the standard graduate curricu-
lum in particle physics in the 1960s.
Again with the benefit of hindsight, it would seem that there are only two logical
solutions to the difficulty that experimentalists do not see any massless spin 1 particles
except for the photon: (1) the Yang-Mills particles somehow acquire mass, or (2) the Yang-
Mills particles are in fact massless but are somehow not observed. We now know that the
first possibility was realized in the electroweak interaction and the second in the strong
interaction.
Constructing the electroweak theory
We now discuss electroweak unification. It is perhaps pedagogically clearest to motivate
how we would go about constructing such a theory. As I have said before, this is not a

380 | VII. Grand Unification
textbook on particle physics and I necessarily will have to keep the discussion of particle
physics to the bare minimum. I gave you a brief introduction to the structure of the weak
interaction in chapter IV.2. The other salient fact is that weak interaction violates parity,
as mentioned in chapter II.1. In particular, the left handed electron field eL and the right
handed electron field eR, which transform into each other under parity, enter into the weak
interaction quite differently.
Let us start with the weak decay of the muon, μ−→e−+ ¯ν + ν′, with ν and ν′ the
electron neutrino and muon neutrino, respectively. The relevant term in the Lagrangian
is ¯ν′
Lγ μμL¯eLγμνL, with the left hand electron field eL, the electron neutrino field (which
is left handed) νL, and so forth. The field μL annihilates a muon, the field ¯eL creates an
electron, and so on. (Henceforth, we will suppress the word field.) As you probably know,
the elementary constituents of matter form three families, with the first family consisting
of ν, e, and the up u and down d quarks, the second of ν′, μ, and the charm c and strange
s quarks, and so on. For our purposes here, we will restrict our attention to the first family.
Thus, we start with ¯νLγ μeL¯eLγμνL.
As I remarked in chapter III.2, a Fermi interaction of this type can be generated by the
exchange of an intermediate vector boson W + with the coupling W +
μ ¯νLγ μeL + W −
μ ¯eLγμνL.
The idea is then to consider an SU(2) gauge theory with a triplet of gauge bosons denoted
by W a
μ, with a = 1, 2, 3. Put νL and eL into the doublet representation and the right handed
electron field eR into a singlet representation, thus
ψL ≡
 ν
e

L
, eR
(1)
(The notation is such that the upper component of ψL is νL and the lower component is
eL.)
The fields νL and eL, but not eR, listen to the gauge bosons W a
μ. Indeed, according to
(IV.5.21) the Lagrangian contains
W a
μ ¯ψLτ aγ μψL = (W 1−i2
μ
¯ψL
1
2τ 1+i2γ μψL + h.c.) + W 3
μ ¯ψLτ 3γ μψL
where W 1−i2
μ
≡W 1
μ −iW 2
μ and so forth. We recognize τ 1+i2 ≡τ 1 + iτ 2 as the raising
operator and the first two terms as (W 1−i2
μ
¯νLγ μeL + h.c.), precisely what we want. By
design, the exchange of W ±
μ generates the desired term ¯νLγ μeL¯eLγμνL.
We need more room
We would hope that the boson W 3 we were forced to introduce would turn out to be the pho-
ton so that electromagnetism is included. But alas, W 3 couples to the current ¯ψLτ 3γ μψL =
(¯νLγ μνL −¯eLγμeL), not the electromagnetic current −(¯eLγμeL + ¯eRγμeR). Oops!
Another problem lurks. To generate a mass term for the electron, we need a doublet
Higgs field ϕ ≡
 ϕ+
ϕ0

in order to construct the SU(2) invariant term f ¯ψLϕeR in the
Lagrangian so that when ϕ acquires the vacuum expectation value
 0
v

we will have

VII.2. Electroweak Unification | 381
f ¯ψLϕeR →f (¯ν, ¯e)L
 0
v

eR = f v¯eLeR
(2)
But none of the SU(2) transformations leaves
 0
v

invariant: The vacuum expectation value
of ϕ spontaneously breaks the entire SU(2) symmetry, leaving all three W bosons massive.
There is no room for the photon in this failed theory. Aagh!
We need more room. Remarkably, we can avoid both the oops and the aagh by extending
the gauge symmetry to SU(2) ⊗U(1). Denoting the generator of U(1) by 1
2Y (called the
hypercharge) and the associated gauge potential by Bμ [and their counterparts T a and W a
μ
for SU(2)]we have the covariant derivative Dμ = ∂μ −igW a
μT a −ig′Bμ
Y
2 . With four gauge
bosons, we dare to hope that one of them might turn out to be the photon.
The gauge potentials are normalized by the corresponding kinetic energy terms,
L = −1
4(Bμν)2 −1
4(W a
μν)2 + . . . with the abelian Bμν = ∂μBν −∂νBμ and nonabelian field
strength W a
μν = ∂μW a
ν −∂νW a
μ + εabcW b
μW c
ν . The generators T a are of course normalized
by the commutation relations that define SU(2). In contrast, there is no commutation
relation in the abelian algebra U(1) to fix the normalization of the generator 1
2Y . Until this
is fixed, the normalization of the U(1) gauge coupling g′ is not fixed.
How do we fix the normalization of the generator 1
2Y? By construction, we want spon-
taneous symmetry breaking to leave a linear combination of T3 and 1
2Y invariant, to be
identified as the generator the massless photon couples to, namely the charge operator Q.
Thus, we write
Q = T3 + 1
2Y
(3)
Once we know T3 and
1
2Y of any field, this equation tells us its charge. For example,
Q(νL) = 1
2 + 1
2Y(νL) and Q(eL) = −1
2 + 1
2Y(eL). In particular, we see that the coefficient
of T3 in (3) must be 1 since the charges of νL and eL differ by 1. The relation (3) fixes the
normalization of 1
2Y .
Determining the hypercharge
The next step is to determine the hypercharge of various multiplets in the theory, which in
turn determines how Bμ couples to these multiplets. Consider ψL. For eL to have charge
−1, the doublet ψL must have 1
2Y = −1
2. In contrast, the field eR has 1
2Y = −1 since T3 = 0
on eR.
Given the hypercharge of ψL and eR we see that the invariance of the term f ¯ψLϕeR
under SU(2) ⊗U(1) forces the Higgs field ϕ to have 1
2Y = + 1
2. Thus, according to (3)
the upper component of ϕ has electric charge Q = + 1
2 + 1
2 = +1and the lower component
Q = −1
2 + 1
2 = 0. Thus, we write ϕ =
 ϕ+
ϕ0

. Recall that ϕ has the vacuum expectation value
 0
v

. The fact that the electrically neutral field ϕ0 acquires a vacuum expectation value but
the charged field ϕ+ does not provide a consistency check.

382 | VII. Grand Unification
The theory works itself out
Now that the couplings of the gauge bosons to the various fields, in particular, the Higgs
field, are determined, we can easily work out the mass spectrum of the gauge bosons, as
indeed, let me remind you, you have already done in exercise IV.6.3!
Upon spontaneous symmetry breaking ϕ →(1/
√
2)
 0
v

(the normalization is conven-
tional): We simply plug in
L = (Dμϕ)†(Dμϕ) →g2v2
4
W +
μ W −μ + v2
8 (gW 3
μ −g′Bμ)2
(4)
I trust that this is what you got! Thus, the linear combinationgW 3
μ −g′Bμ becomes massive
while the orthogonal combination remains massless and is identified with the photon. It
is clearly convenient to define the angle θ by tan θ = g′/g. Then,
Zμ = cos θW 3
μ −sin θBμ
(5)
describes a massive gauge boson known as the Z boson, while the electromagnetic po-
tential is given by Aμ = sin θW 3
μ + cos θBμ. Combine (4) and (5) and verify that the mass
squared of the Z boson is M2
Z = v2(g2 + g′2)/4, and thus by elementary trigonometry ob-
tain the relation
MW = MZ cos θ
(6)
The exchange of the W boson generates the Fermi weak interaction
L = −g2
2M2
W
¯νLγ μeL¯eLγμνL = −4G
√
2
¯νLγ μeL¯eLγμνL
where the second equality merely gives the historical definition of the Fermi coupling G.
Thus,
G
√
2
=
g2
8M2
W
(7)
Next, we write the relevant piece of the covariant derivative
gW 3
μT 3 + g′Bμ
Y
2 = g(cos θZμ + sin θAμ)T 3 + g′(−sin θZμ + cos θAμ)Y
2
in terms of the physically observed Z and A. The coefficient of Aμ works out to be
g sin θT 3 + g′ cos θ(Y/2) = g sin θ(T 3 + Y/2); the fact that the combination Q = T 3 +
Y/2 emerges provides a nice check on the formalism. Furthermore, we obtain
e = g sin θ
(8)
Meanwhile, it is convenient to write g cos θT 3 −g′ sin θ(Y/2), the coefficient of Zμ in
the covariant derivative, in terms of the physically familiar electric charge Q rather than
the theoretical hypercharge Y: Thus,
g cos θT 3 −g′ sin θ(Q −T 3) =
g
cos θ (T 3 −sin2 θQ)

VII.2. Electroweak Unification | 383
In other words, we have determined the coupling of the Z boson to an arbitrary fermion
field  in the theory:
L =
g
cos θ Zμ ¯γ μ(T 3 −sin2 θQ)
(9)
For example, using (9) we can immediately write the coupling of Z to leptons:
L =
g
cos θ Zμ[ 1
2(¯νLγ μνL −¯eLγ μeL) + sin2 θ ¯eγ μe]
(10)
Including quarks
How to include the hadrons is now almost self evident. Given that only left handed
fields participate in the weak interaction, we put the quarks of the first generation into
SU(2) ⊗U(1) multiplets as follows:
qα
L ≡
 uα
dα

L
, uα
R, dα
R
(11)
where α = 1, 2, 3 denotes the color index, which I will discuss in the next chapter. The
right handed quarks uα
R and dα
R are put into singlets so that they do not hear the weak
bosons W a. Recall that the up quark u and the down quark d have electric charges 2
3 and
−1
3 respectively. Referring to (3) we see 1
2Y = 1
6 , 2
3, and −1
3 for qα
L, uα
R, and dα
R, respectively.
From (9) we can immediately read off the coupling of the Z boson to the quarks:
L =
g
cos θ Zμ[ 1
2(¯uLγ μuL −¯dLγ μdL) −sin2 θJ μ
em]
(12)
Finally, I leave it to you to verify that of the four degrees of freedom contained in ϕ
(since ϕ+ and ϕ0 are complex) three are eaten by the W and Z bosons, leaving one physical
degree of freedom H corresponding to the elusive Higgs particle that experimenters are
still searching for as of this writing.
The neutral current
By virtue of its elegantly economical gauge group structure, this SU(2) ⊗U(1) electroweak
theory of Glashow, Salam, and Weinberg ushered in the last great predictive era of theo-
retical particle physics. Writing (10) and (12) as
L =
g
cos θ Zμ(J μ
leptons+ J μ
quarks)
and using (6) we see that Z boson exchange generates a hitherto unknown neutral current
interaction
Lneutral current = −g2
2M2
W
(Jleptons + Jquarks)μ(Jleptons + Jquarks)μ
between leptons and quarks. By studying various processes described by Lneutral current we
can determine the weak angle θ. Once θ is determined, we can predict g from (8). Once g

384 | VII. Grand Unification
is determined, we can predict MW from (7). Once MW is determined, we can predict MZ
from (6).
Concluding remarks
As I mentioned, there are three families of leptons and quarks in Nature, consisting
of (νe, e, u, d), (νμ, μ, c, s), and (ντ , τ , t, b). The appearance of this repetitive family
structure, about which the SU(2) ⊗U(1) theory has nothing to say, represents one of
the great unsolved puzzles of particle physics. The three families, with the appropriate
rotation angles between them, are simply incorporated into the theory by repeating what
we wrote above.
A more logical approach than the one given here would be to start with an SU(2) ⊗U(1)
theory with a doublet Higgs field with some hypercharge, and to say, “Behold, upon
spontaneous symmetry breaking, one linear combination of generators remains unbroken
with a corresponding massless gauge field.” I think that our quasi-historical approach is
clearer.
As I have mentioned on several occasions, Fermi’s theory of the weak interaction is
nonrenormalizable. In 1999, ’t Hooft and Veltman were awarded the Nobel Prize for
showing that the SU(2) ⊗U(1) electroweak theory is renormalizable, thus paving the way
for the triumph of nonabelian gauge theories in describing the strong, electromagnetic,
and weak interactions. I cannot go into the details of their proof here, but I would like
to mention that the key is to start with the nonabelian analog of the unitary gauge (recall
chapter IV.6) and proceed to the Rξ gauge. At large momenta, the massive gauge boson
propagators go as ∼(kμkν/k2) in the unitary gauge, but as ∼(1/k2) in the Rξ gauge. The
theory is then renormalizable by power counting.
Exercises
VII.2.1
Unfortunately, the mass of the elusive Higgs particle H depends on the parameters in the double well
potential V = −μ2ϕ†ϕ + λ(ϕ†ϕ)2 responsible for the spontaneous symmetry breaking. Assuming that
H is massive enough to decay into W + + W −and Z + Z, determine the rates for H to decay into various
modes.
VII.2.2 Show that it is possible to stay with the SU(2) gauge group and to identify W 3 as the photon A, but at
the cost of inventing some experimentally unobserved lepton fields. This theory does not describe our
world: For one thing, it is essentially impossible to incorporate the quarks. Show this! [Hint: We have to
put the leptons into a triplet of SU(2) instead of a doublet.]

VII.3
Quantum Chromodynamics
Quarks
Quarks come in six flavors, known as up, down, strange, charm, bottom, and top, denoted
by u, d, s, c, b, and t. The proton, for example, is made of two up quarks and a down quark
∼(uud), while the neutral pion corresponds to ∼(u¯u −d ¯d)/
√
2. Please consult any text
on particle physics for details.
By the late 1960s the notion of quarks was gaining wide acceptance, but two separate
lines of evidence indicated that a crucial element was missing. In studying how hadrons
are made of quarks, people realized that the wave function of the quarks in a nucleon does
not come out to be antisymmetric under the interchange of any pair of quarks, as required
by the Pauli exclusion principle. At around the same time, it was realized that in the ideal
world we used to derive the Goldberger-Treiman relation and in which the pion is massless
we can calculate the decay rate for the process π0 →γ + γ , as mentioned in chapter IV.7.
Puzzlingly enough, the calculated rate came out smaller than the observed rate by a factor
of 9 = 32.
Both puzzles could be resolved in one stroke by having quarks carry a hitherto unknown
internal degree of freedom that Gell-Mann called color. For any specified flavor, a quark
comes in one of three colors. Thus, the up quark can be red, blue, or yellow. In a nucleon,
the wave function of the three quarks will then contain a factor referring to color, besides
the factors referring to orbital motion, spin, and so on. We merely have to make the color
part of the wave function antisymmetric; in fact, we simply take it to be εαβγ, where α, β,
and γ denote the colors carried by the three quarks. With quarks in three colors, we have to
multiply the amplitude for π0 decay by a factor of 3, thus neatly resolving the discrepancy
between theory and experiment.

386 | VII. Grand Unification
Asymptotic freedom
As I mentioned in chapter VI.6, the essential clue came from studying deep inelastic scat-
tering of electrons off nucleons. Experimentalists made the intriguing discovery that when
hit hard the quarks in the nucleons act as if they hardly interact with each other, in other
words, as if they are free. On the other hand, since quarks are never seen as isolated enti-
ties, they appear to be tightly bound to each other within the nucleon. As I have explained,
this puzzling and apparently contradictory behavior of the quarks can be understood if the
strong interaction coupling flows to zero in the large momentum (ultraviolet) limit and to
infinity or at least to some large value in the small momentum (infrared) limit. A number
of theorists proposed searching for theories whose couplings would flow to zero in the
ultraviolet limit, now known as asymptotic free theories. Eventually, Gross, Wilczek, and
Politzer discovered that Yang-Mills theory is asymptotically free.
This result dovetails perfectly with the realization that quarks carry color. The nonabelian
gauge transformation would take a quark of one color into a quark of another color. Thus, to
write down the theory of the strong interaction we simply take the result of exercise IV.5.6,
L = −1
4g2F a
μνF aμν + ¯q(iγ μDμ −m)q
(1)
with the covariant derivative Dμ = ∂μ −iAμ. The gauge group is SU(3) with the quark field
q in the fundamental representation. In other words, the gauge fields Aμ = Aa
μT a, where
T a (a = 1, . . . , 8) are traceless hermitean 3 by 3 matrices. Explicitly, (Aμq)α = Aa
μ(T a)α
βqβ,
where α, β = 1, 2, 3. The theory is known as quantum chromodynamics, or QCD for short,
and the nonabelian gauge bosons are known as gluons. To incorporate flavor, we simply
write f
j=1 ¯qj(iγ μDμ −mj)qj for the second term in (1), where the index j goes over the
f flavors. Note that quarks of different flavors have different masses.
Infrared slavery
The flip side of asymptotic freedom is infrared slavery. We cannot follow the renormaliza-
tion group flow all the way down to the low momentum scale characteristic of the quarks
bound inside hadrons since the coupling g becomes ever stronger and our perturbative cal-
culation of β(g) is no longer adequate. Nevertheless, it is plausible although never proven
that g goes to infinity and that the gluons keep the quarks and themselves in permanent
confinement. The Wilson loop introduced in chapter VII.1 provides the order parameter
for confinement.
In elementary physics forces decrease with the separation between interacting objects,
so permanent confinement is a rather bizarre concept. Are there any other instances of
permanent confinement?
Consider a magnetic monopole in a superconductor. We get to combine what we learned
in chapters IV.4 and V.4 (and even VI.2)! A quantized amount of magnetic flux comes out
of the monopole, but according to the Meissner effect a superconductor expels magnetic
flux. Thus, a single magnetic monopole cannot live inside a superconductor.

VII.3. Quantum Chromodynamics | 387
M
M
R
Figure VII.3.1
Now consider an antimonopole a distance R away (figure VII.3.1). The magnetic flux
coming out of the monopole can go into the antimonopole, forming a tube connecting
the monopole and the antimonopole and obliging the superconductor to give up being a
superconductor in the region of the flux tube. In the language of chapter V.4, it is no longer
energetically favorable for the field or order parameter ϕ to be constant everywhere; instead
it vanishes in the region of the flux tube. The energy cost of this arrangement evidently
grows as R (consistent with Wilson’s area law).
In other words, an experimentalist living inside a superconductor would find that
it costs more and more energy to pull a monopole and an antimonopole apart. This
confinement of monopoles inside a superconductor is often taken to be a model of the yet-
to-be-proven confinement of quarks. Invoking electromagnetic duality we can imagine
a magnetic superconductor in contrast to the usual electric superconductor. Inside a
magnetic superconductor, electric charges would be permanently confined. Our universe
may be likened to a color magnetic superconductor in which quarks (the analog of electric
charges) are confined.
On distance scales large compared to the radius of the color flux tube connecting a quark
to an antiquark, the tube can be thought of as a string. Historically, that was how string
theory originated. The challenge, boys and girls, is to prove that the ground state or vacuum
of (1) is a color magnetic superconductor.
Symmetries of the strong interaction
Now that we have a theory of the strong interaction, we can understand the origin of the
symmetries of the strong interaction, namely the isospin symmetry of Heisenberg and the
chiral symmetry that when spontaneously broken leads to the appearance of the pion as a
Nambu-Goldstone boson (as discussed in chapters IV.2 and VI.4).
Consider a world with two flavors, which is all that is relevant for a discussion of the pion.
Introduce the notation u ≡q1, d ≡q2, and q =
 u
d

so that we can write the Lagrangian as
L = −1
4g2F a
μνF aμν + ¯q(iγ μDμ −m)q
with
m =
 mu
0
0
md


388 | VII. Grand Unification
where mu and md are the masses of the up and down quarks, respectively. If mu = md,
the Lagrangian is invariant under q →eiθ.τq, corresponding to Heisenberg’s isospin
symmetry.
In the limit in which mu and md vanish, the Lagrangian is invariant under q →eiϕ.τγ5q,
known as the chiral SU(2) symmetry, chiral because the right handed quarks qR and the
left handed quarks qL transform differently. To the extent that mu and md are both much
smaller than the energy scale of the strong interaction, chiral SU(2) is an approximate
symmetry.
The pion is the Nambu-Goldstone boson associated with the spontaneous breaking
of the chiral SU(2). Indeed, this is an example of dynamical symmetry breaking since
there is no elementary scalar field around to acquire a vacuum expectation. Instead, the
strong interaction dynamics is supposed to drive the composite scalar fields ¯uu and ¯dd to
“condense into the vacuum” so that ⟨0| ¯uu|0⟩= ⟨0| ¯dd |0⟩become nonvanishing, where the
equality between the two vacuum expectation values ensures that Heisenberg’s isospin is
not spontaneously broken, an experimental fact since there are no corresponding Nambu-
Goldstone bosons. In terms of the doublet field q, the QCD vacuum is supposed to be such
that ⟨0| ¯qq |0⟩̸= 0 while ⟨0| ¯q ⃗τq |0⟩= 0.
Renormalization group flow
The renormalization group flow of the QCD coupling is governed by
dg
dt = β(g) = −11
3 T2(G) g3
16π2
(2)
with the all-crucial minus sign. Here
T2(G)δab = f acdf bcd
(3)
I will not go through the calculation of β(g) here, but having mastered chapters VI.8
and VII.1 you should feel that you can do it if you want to.1 At the very least, you should
understand the factor g3 and T2(G) by drawing the relevant Feynman diagrams.
When fermions are included,
dg
dt = β(g) =
 
−11
3 T2(G) + 4
3T2(F)
!
g3
16π2
(4)
where
T2(F)δab = tr[T a(F)T b(F)]
(5)
I do expect you to derive (4) given (2). For SU(N) T2(F) = 1
2 for each fermion in the
fundamental representation. Note that asymptotic freedom is lost when there are too many
fermions.
1 For a detailed calculation, see, e.g., S. Weinberg, The Quantum Theory of Fields, Vol. 2, sec. 18.7.

VII.3. Quantum Chromodynamics | 389
γ
e–
e+
Figure VII.3.2
You already solved an equation like (4) in exercise VI.8.1. Let us define, in analogy to
quantum electrodynamics, αS(μ) ≡g(μ)2/4π, the strong coupling at the momentum scale
μ. From (4) we obtain2
αS(Q) =
αS(μ)
1 + (1/4π)(11 −2
3nf )αS(μ) log(Q2/μ2)
(6)
showing explicitly that αS(Q) →0 logarithmically as Q →∞.
Electron-positron annihilation
I have space to show you only one physical application. Experimentalists have measured
the cross section σ of e+e−annihilation into hadrons as a function of the total center-of-
mass energy E. The amplitude is shown in figure VII.3.2. To calculate the cross section in
terms of the amplitude, we have to go through what some people call “boring kinematics,”
such as normalizing everything correctly, dividing by the flux of the two beams, and so
forth (see the appendix to chapter II.6). For the good of your soul, you should certainly go
through this type of calculation at least once. Believe me, I did it more times than I care
to remember. But happily, as I will now show you, we can avoid most of this grunge labor.
First, consider the ratio
R(E) ≡σ(e+e−→hadrons)
σ(e+e−→μ+μ−)
The kinematic stuff cancels out. In figure VII.3.2 the half of the diagram involving the
electron positron lines and the photon propagator also appears in the Feynman diagram
e+e−→μ+μ−(figure VII.3.3) and so cancels out in R(E). The blob in figure VII.3.2, which
hides all the complexity of the strong interaction, is given by ⟨0|J μ(0)|h⟩, where J μ is the
2 For the accumulated experimental evidence on αS(Q), see figure 14.3 in F. Wilczek, in: V. Fitch et al., eds.,
Critical Problems in Physics, p. 281.

390 | VII. Grand Unification
γ
e−
e+
μ−
μ+
Figure VII.3.3
electromagnetic current and the state |h⟩can contain any number of hadrons. To obtain
the cross section we have to square the amplitude, include a δ-function for momentum
conservation, and sum over all |h⟩, thus arriving at

h
(2π)4δ4(ph −pe+ −pe−)⟨0|J μ(0)|h⟩⟨h|J ν(0)|0⟩
(7)
[with q ≡pe+ + pe−= (E, ⃗0)]. This quantity can be written as

d4xeiqx⟨0|J μ(x)J ν(0)|0⟩=

d4xeiqx⟨0|[J μ(x), J ν(0)]|0⟩
= 2 Im(i

d4xeiqx⟨0|T J μ(x)J ν(0)|0⟩)
(The first equality follows from E > 0 and the second was explained in chapter III.8.)
To determine this quantity, we would have to calculate an infinite number of Feynman
diagrams involving lots of quarks and gluons. A typical diagram is shown in figure VII.3.4.
Completely hopeless!
This is where asymptotic freedom rides to the rescue! From chapter VI.7 you learned
that for a process at energy E the appropriate coupling strength to use is g(E). But as we
crank up E, g(E) gets smaller and smaller. Thus diagrams such as figure VII.3.4 involving
many powers of g(E) all fall away, leaving us with the diagrams with no power of g(E)
(fig. VII.3.5a) and two powers of g(E) (figs. VII.3.5b,c,d). No calculation is necessary to
obtain the leading term in R(E), since the diagram in figure VII.3.5a is the same one
that enters into e+e−→μ+μ−: We merely replace the quark propagator by the muon
propagator (quark and muon masses are negligible compared to E). At high energy, the
quarks are free and R(E) merely counts the square of the charge Qa of the various quarks
contributing at that energy. We predict
R(E) −→
E→∞3

a
Q2
a
(8)
The factor of 3 accounts for color.

VII.3. Quantum Chromodynamics | 391
γ
γ
Figure VII.3.4
Not only does QCD turn itself off at high energies, it tells us how fast it is turning itself
off. Thus, we can determine how the limit in (8) is approached:
R(E) =

3

a
Q2
a
 
1 + C
2
(11 −2
3nf ) log(E/μ)
+ . . .

(9)
I will leave it to you to calculate C.
Dreams of exact solubility
An analytic solution of quantum chromodynamics is something of a “Holy Grail” for
field theorists (a grail that now carries a prize of one million dollars: see www.ams.org/
claymath/). Many field theorists have dreamed that at least “pure” QCD, that is QCD
without quarks, might be exactly soluble. After all, if any 4-dimensional quantum field
(a)
(b)
(c)
(d)
γ
γ
Figure VII.3.5

392 | VII. Grand Unification
1
QCD
μ
g(μ)2
4π
Figure VII.3.6
theory turns out to be exactly soluble, pure Yang-Mills, with all its fabulous symmetries,
is the most likely possibility. (Perhaps an even more likely candidate for solubility is
supersymmetric Yang-Mills theory. We will touch on supersymmetry in chapter VIII.4.)
Let me be specific about what it means to solve QCD. Consider a world with only up
and down quarks with mu and md both set equal to zero, namely a world described by
L = −1
4g2F a
μνF aμν + ¯qiγ μDμq
(10)
The goal would be to calculate something like the ratio of the mass of the ρ meson mρ to
the mass of the proton mP.
To make progress, theoretical physicists typically need to have a small parameter to
expand in, but in trying to solve (10) we are confronted with the immediate difficulty
that there is no such parameter. You might think that g is a parameter, but you would
be mistaken. The renormalization group analysis taught us that g(μ) is a function of the
energy scale μ at which it is measured. Thus, there is no particular dimensionless number
we can point to and say that it measures the strength of QCD. Instead, the best we can do
is to point to the value of μ at which (g(μ)2/4π) becomes of order 1. This is the energy,
known as QCD, at which the strong interaction becomes strong as we come down from
high energy (fig. VII.3.6). But QCD merely sets the scale against which other quantities
are to be measured. In other words, if you manage to calculate mP it better come out
proportional to QCD since QCD is the only quantity with dimension of mass around.
Similarly for mρ. Put in precise terms, if you publish a paper with a formula giving mρ/mP
in terms of pure numbers such as 2 and π, the field theory community will hail you as a
conquering hero who has solved QCD exactly.
The apparent trade of a dimensionless coupling g for a dimensional mass scale QCD
is known as dimensional transmutation, of which we will see another example in the next
chapter.

VII.3. Quantum Chromodynamics | 393
Exercises
VII.3.1
Calculate C in (9). [Hint: If you need help, consult T. Appelquist and H. Georgi, Phys. Rev. D8: 4000, 1973;
and A. Zee, Phys. Rev. D8: 4038, 1973.]
VII.3.2 Calculate (2).

VII.4
Large N Expansion
Inventing an expansion parameter
Quantum chromodynamics is a zero-parameter theory, so it is difficult to give even a first
approximation. In desperation, field theorists invented a parameter in which to expand
QCD. Suppose instead of three colors we have N colors. ’t Hooft1 noticed that as N →∞
remarkable simplifications occur. The idea is that if we can calculate mρ/mP, for example,
in the large N limit the result may be close to the actual value. People sometimes joke that
particle physicists regard 3 as a large number, but actually the correction to the large N
limit is typically of order 1/N2, about 10% in the real world. Particle physicists would be
more than happy to be able to calculate hadron masses to this degree of accuracy.
As with spontaneous symmetry breaking and a number of other important concepts, the
large N expansion came out of condensed matter physics but nowadays is used routinely
in all sorts of contexts. For example, people have tried a large N approach to solve high-
temperature superconductivity and to fold RNA.2
Scaling the QCD coupling
So, let the color group be U(N) and write
L = −Na
2g2 tr FμνF μν + ¯ψ[i( ̸∂−i̸A) −m]ψ
(1)
Note that we have replaced g2 by g2/Na. For finite N this change has no essential signifi-
cance. The point is to choose the power a so that interesting simplifications occur in the
limit N →∞with g2 held fixed. The cubic and quartic interaction vertices of the gluons
1 G. ’t Hooft, Under the Spell of the Gauge Principle, p. 378.
2 M. Bon, G. Vernizzi, H. Orland, and A. Zee, “Topological classification of RNA structures,” J. Mol. Biol.
379:900, 2008.

VII.4. Large N Expansion | 395
γ
γ
γ
γ
(a)
(b)
Figure VII.4.1
are proportional to Na. On the other hand, since the gluon propagator goes as the inverse
of the quadratic terms in L, it is proportional to 1/Na. The coupling of the gluon to the
quark does not depend on N.
To fix a, let us focus on a specific application, the calculation of σ(e+e−→hadrons)
discussed in the last chapter. Suppose we want to calculate this cross section at low
energies. Consider the two-gluon exchange diagrams shown in figures VII.4.1a and b.
The two diagrams are of order g4 and we would have to calculate both. Note that 1b is
nonplanar: Since one gluon crosses over the other, the diagram cannot be drawn on the
plane if we insist that lines cannot go through each other.
Now the double-line formalism introduced in chapter IV.5 shines. In this formalism
the diagrams figure VII.4.1a and b are redrawn as in figure VII.4.2a and b. The two gluon
propagators common to both diagrams give a factor 1/N2a. Now comes the punchline.
We sum over three independent color indices in 2a, thus getting a factor N3. Grab some
crayons and try to color each line in 2a with a different color: you will need three crayons.
In contrast, we sum over only one independent index in 2b, getting only a factor of N. In
other words, 2a dominates 2b by a factor N2. In the large N limit we can throw 2b away.
Clearly, the rule is to associate one factor of N with each loop. Thus, the lowest order
diagram, shown in 2c, with N different colors circulating in it, scales as N; 2a scales as
N3/N2a. We want 2a and 2c to scale in the same way and thus we choose a = 1.
(a)
(b)
(c)
(d)
Figure VII.4.2

396 | VII. Grand Unification
By drawing more diagrams [e.g., 2d scales as N(1/N4)N4, with the three factors coming
from the quartic coupling, the propagators, and the sum over colors, respectively], you can
convince yourself that planar diagrams dominate in the large N limit, all scaling as N. For
a challenge, try to prove it. Evidently, there is a topological flavor to all this.
The reduction to planar diagrams is a vast simplification but there are still an infinite
number of diagrams. At this stage in our mastery of field theory, we still can’t solve large
N QCD. (As I started writing this book, there were tantalizing clues, based on insight and
techniques developed in string theory, that a solution of large N QCD might be within
sight. As I now go through the final revision, that hope has faded.)
The double-line formalism has a natural interpretation. Group theoretically, the matrix
gauge potential Ai
j transforms just like ¯qiqj (but assuredly we are not saying that the gluon
is a quark-antiquark bound state) and the two lines may be thought of as describing a quark
and an antiquark propagating along, with the arrows showing the direction in which color
is flowing.
Random matrix theory
There is a much simpler theory, structurally similar to large N QCD, that actually can be
solved. I am referring to random matrix theory.
Exaggerating a bit, we can say that quantum mechanics consists of writing down a
matrix known as the Hamiltonian and then finding its eigenvalues and eigenvectors. In the
early 1950s, when confronted with the problem of studying the properties of complicated
atomic nuclei, Eugene Wigner proposed that instead of solving the true Hamiltonian in
some dubious approximation we might generate large matrices randomly and study the
distribution of the eigenvalues—a sort of statistical quantum mechanics. Random matrix
theory has since become a rich and flourishing subject, with an enormous and growing
literature and applications to numerous areas of theoretical physics and even to pure
mathematics (such as operator algebra and number theory.)3 It has obvious applications
to disordered condensed matter systems and less obvious applications to random surfaces
and hence even to string theory. Here I will content myself with showing how ’t Hooft’s
observation about planar diagrams works in the context of random matrix theory.
Let us generate N by N hermitean matrices ϕ randomly according to the probability
P(ϕ) = 1
Z e−N tr V (ϕ)
(2)
with V (ϕ) a polynomial in ϕ. For example, let V (ϕ) = 1
2m2ϕ2 + gϕ4. The normalization

dϕP(ϕ) = 1 fixes
Z =

dϕe−N tr V (ϕ)
(3)
The limit N →∞is always understood.
3 For a glimpse of the mathematical literature, see D. Voiculescu, ed., Free Probability Theory.

VII.4. Large N Expansion | 397
As in chapter VI.7 we are interested in ρ(E), the density of eigenvalues of ϕ. To make
sure that you understand what is actually meant, let me describe what we would do were
we to evaluate ρ(E) numerically. For some large integer N, we would ask the computer to
generate a hermitean matrix ϕ with the probability P(ϕ) and then to solve the eigenvalue
equation ϕv = Ev.After this procedure had been repeated many times, the computer could
plot the distribution of eigenvalues in a histogram that eventually approaches a smooth
curve, called the density of eigenvalues ρ(E).
We already developed the formalism to compute ρ(E) in (VI.7.1): Compute the real
analytic function G(z) ≡⟨(1/N) tr[1/(z −ϕ)]⟩and ρ(E) = −(1/π) lim
ε→0 Im G(E + iε). The
average ⟨. . .⟩is taken with the probability P(ϕ):
⟨O(ϕ)⟩= 1
Z

Dϕe−NtrV (ϕ)O(ϕ)
You see that my choice of notation, ϕ for the matrix and V (ϕ) = 1
2m2ϕ2 + gϕ4 as an
example, is meant to be provocative. The evaluation of Z is just like the evaluation of a path
integral, but for an action S(ϕ) = N tr V (ϕ) that does not involve

ddx. Random matrix
theory can be thought of as a quantum field theory in (0 + 0)-dimensional spacetime!
Various field theoretic methods, such as Feynman diagrams, can all be applied to
random matrix theory. But life is sweet in (0 + 0)-dimensional spacetime: There is no
space, no time, no energy, and no momentum and hence no integral to do in evaluating
Feynman diagrams.
The Wigner semicircle law
Let us see how this works for the simple case V (ϕ) = 1
2m2ϕ2 (we can always absorb m into
ϕ but we won’t). Instead of G(z), it is slightly easier to calculate
Gi
j(z) ≡
"
1
z −ϕ
i
j
#
= δi
jG(z)
The last equality follows from invariance under unitary transformations:
P(ϕ) = P (U†ϕU)
(4)
Expand
Gi
j(z) =
∞

n=0
1
z2n+1⟨(ϕ2n)i
j⟩
(5)
Do the Gaussian integral
1
Z

dϕe−N tr 1
2 m2ϕ2ϕi
kϕl
j = 1
Z

dϕe−N 1
2 m2 
p, q ϕp
q ϕq
pϕi
kϕl
j = δi
jδl
k
1
Nm2
(6)
Setting k = l and summing, we find the n = 1 term in (5) is equal to (1/z3)δi
j(1/m2).
Just as in any field theory we can associate a Feynman diagram with each of the terms
in (5). For the n = 1 term, we have figure VII.4.3. The matrix character of ϕ lends itself
naturally to ’t Hooft’s double-line formalism and thus we can speak of quark and gluon

398 | VII. Grand Unification
j
l
k
i
Figure VII.4.3
propagators with a good deal of ease. The Feynman rules are given in figure VII.4.4. We
recognize ϕ as the gluon field and (5) as the gluon propagator. Indeed, we can formulate
our problem as follows: Given the bare quark propagator 1/z, compute the true quark
propagator G(z) with all interaction effects taken into account.
Let us now look at the n = 2 term in (5) 1/z5 < ϕi
hϕh
kϕk
l ϕl
j >, which we represent in
figure VII.4.5a. With a bit of thought you can see that the index i can be contracted with
k, l, or j , thus giving rise to figures VII.4.5b, c, d. Summing over color indices, just as in
QCD, we see that the planar diagrams in 5b and 5d dominate the diagram in 5c by a factor
N2. We can take over ’t Hooft’s observation that planar diagrams dominate.
Incidentally, in this example, you see how large N is essential, allowing us to get rid of
nonplanar diagrams. After all, if I ask you to calculate the density of eigenvalues for say
N = 7 you would of course protest saying that the general formula for solving a degree-7
polynomial equation is not even known.
The simple example in figure VII.4.5 already indicates how all possible diagrams could
be constructed. In 5b the same “unit” is repeated, while in 5d the same “unit” is nested
inside a more basic diagram. A more complicated example is shown in 5e. You can convince
yourself that for N = ∞all diagrams contributing to G(z) can be generated by either
“nesting” existing diagrams inside an overarching gluon propagator or “repeating” an
i
k
j
l
1
z
1
Nm2 δ
i
j δ
l
k
1
Figure VII.4.4

VII.4. Large N Expansion | 399
i
h
j
l
k
(a)
(b)
(c)
(d)
(e)
Figure VII.4.5
existing structure over and over again. Translate the preceding sentence into two equations:
“Repeat” (see figure VII.4.6a),
G(z) = 1
z + 1
z(z)1
z + 1
z(z)1
z(z)1
z + . . .
=
1
z −(z)
(7)
and “nest” (see figure VII.4.6b),
(z) = 1
m2G(z)
(8)

400 | VII. Grand Unification
+
=
+
+
G
Σ
Σ
Σ
Σ
G
(a)
(b)
=
Figure VII.4.6
Combining these two equations we obtain a simple quadratic equation for G(z) that we
can immediately solve to obtain
G(z) = m2
2

z −
$
z2 −4
m2

(9)
(From the definition of G(z) we see that G(z) →1/z for large z and thus we choose the
negative root.) We immediately deduce that
ρ(E) =
2
πa2
%
a2 −E2
(10)
where a2 = 4/m2. This is a famous result known as Wigner’s semicircle law.
The Dyson gas
I hope that you are struck by the elegance of the large N planar diagram approach. But you
might have also noticed that the gluons do not interact. It is as if we have solved quantum
electrodynamics while we have to solve quantum chromodynamics. What if we have to
deal with V (ϕ) = 1
2m2ϕ2 + gϕ4? The gϕ4 term causes the gluons to interact with each
other, generating horrible diagrams such as the one in figure VII.4.7. Clearly, diagrams
proliferate and as far as I know nobody has ever been able to calculate G(z) using the
Feynman diagram approach.
Happily, G(z) can be evaluated using another method known as the Dyson gas approach.
The key is to write
ϕ = U†U
(11)

VII.4. Large N Expansion | 401
Figure VII.4.7
where  denotes the N by N diagonal matrix with diagonal elements equal to λi, i =
1, . . . , N. Change the integration variable in (3) from ϕ to U and :
Z =

dU
 
idλi

Je−N 
k V (λk)
(12)
with J the Jacobian. Since the integrand does not depend on U we can throw away the
integral over U. It just gives the volume of the group SU(N). Does this remind you of
chapter VII.1? Indeed, in (11) U corresponds to the unphysical gauge degrees of freedom—
the relevant degrees of freedom are the eigenvalues {λi}. As an exercise you can use the
Faddeev-Popov method to calculate J.
Instead, we will follow the more elegant tack of determining J by arguing from general
principles. The change of integration variables in (11) is ill defined when any two of the λi’s
are equal, at which point J must vanish. (Recall that the change from Cartesian coordinates
to spherical coordinates is ill defined at the north and south poles and indeed the Jacobian
in sin θdθdϕ vanishes at θ = 0 and π.) Since the λi’s are created equal, interchange
symmetry dictates that J = [m>n(λm −λn)]β. The power β can be fixed by dimensional
analysis. With N2 matrix elements dϕ obviously has dimension λN2 while (idλi)J has
dimension λNλβN(N−1)/2; thus β = 2.
Having determined J, let us rewrite (12) as
Z =

(idλi)[m>n(λm −λn)]2e
−N 
k
V (λk)
=

(idλi)e−N 
k V (λk)+ 1
2

m̸=n log(λm−λn)2
(13)
Dyson pointed out that in this form Z =

(idλi)e−NE(λ1, ...,λN) is just the partition
function of a classical 1-dimensional gas (recall chapter V.2). Think of λi, a real number,
as the position of the ith molecule. The energy of a configuration
E(λ1, . . . , λN) =

k
V (λk) −1
2N

m̸=n
log(λm −λn)2
(14)
consists of two terms with obvious physical interpretations. The gas is confined in a
potential well V (x) and the molecules repel4 each other with the two-body potential
−(1/N) log(x −y)2. Note that the two terms in E are of the same order in N since each
4 Note that this corresponds to the repulsion between energy levels in quantum mechanics.

402 | VII. Grand Unification
sum counts for a power of N. In the large N limit (we can think of N as the inverse
temperature), we evaluate Z by steepest descent and minimize E, obtaining
V ′(λk) = 2
N

n̸=k
1
λk −λn
(15)
which in the continuum limit, as the poles in (15) merge into a cut, becomes V ′(λ) =
2P

dμ[ρ(μ)/(λ −μ)], where ρ(μ) is the unknown function we want to solve for and P
denotes principal value.
Defining as before G(z) =

dμ[ρ(μ)/(z −μ)] we see that our equation for ρ(μ) can be
written as Re G(λ + iε) = 1
2V ′(λ). In other words, G(z) is a real analytic function with cuts
along the real axis. We are given the real part of G(z) on the cut and are to solve for the
imaginary part. Br´ezin, Itzykson, Parisi, and Zuber have given an elegant solution of this
problem. Assume for simplicity that V (z) is an even polynomial and that there is only one
cut (see exercise VII.4.7). Invoke symmetry and, incorporating what we know, postulate
the form
G(z) = 1
2

V ′(z) −P(z)
	
z2 −a2

with P(z) an unknown even polynomial. Remarkably, the requirement G(z) →1/z for
large z completely determines P(z). Pedagogically, it is clearest to go to a specific example,
say V (z) = 1
2m2z2 + gz4. Since V ′(z) is a cubic polynomial in z, P(z) has to be a quadratic
(even) polynomial in z. Taking the limit z →∞and requiring the coefficients of z3 and
of z in G(z) to vanish and the coefficient of 1/z to be 1 gives us three equations for three
unknowns [namely a and the two unknowns in P(z)]. The density of eigenvalues is then
determined to be ρ(E) = (1/π)P(E)
√
a2 −E2.
I think the lesson to take away here is that Feynman diagrams, in spite of their historical
importance in quantum electrodynamics and their usefulness in helping us visualize what
is going on, are vastly overrated. Surely, nobody imagines that QCD, even large N QCD,
will one day be solved by summing Feynman diagrams. What is needed is the analog of
the Dyson gas approach for large N QCD. Conversely, if a reader of this book manages to
calculate G(z) by summing planar diagrams (after all, the answer is known!), the insight
he or she gains might conceivably be useful in seeing how to deal with planar diagrams
in large N QCD.
Field theories in the large N limit
A number of field theories have also been solved in the large N expansion. I will tell you
about one example, the Gross-Neveu model, partly because it has some of the flavor of
QCD. The model is defined by
S(ψ) =

d2x
⎡
⎣
N

a=1
¯ψai̸∂ψa + g2
2N
 N

a=1
¯ψaψa
2⎤
⎦
(16)
Recall from chapter III.3 that this theory should be renormalizable in (1 + 1)-dimensional
spacetime. For some finite N, say N = 3, this theory certainly appears no easier to solve

VII.4. Large N Expansion | 403
than any other fully interacting field theory. But as we will see, as N →∞we can extract
a lot of interesting physics.
Using the identity (A.14) we can rewrite the theory as
S(ψ, σ) =

d2x
 N

a=1
¯ψa(i̸∂−σ)ψa −N
2g2σ 2

(17)
By introducing the scalar field σ(x) we have “undone” the four-fermion interaction. (Recall
that we used the same trick in chapter III.5.) You will note that the physics involved is
similar to that behind the introduction of the weak boson to generate the Fermi interaction.
Using what we learned in chapters II.5 and IV.3 we can immediately integrate out the
fermion fields to obtain an action written purely in terms of the σ field
S(σ) = −

d2x N
2g2σ 2 −iN tr log(i̸∂−σ)
(18)
Note the factor of N in front of the tr log term coming from the integration over N fermion
fields. With the malice of forethought we, or rather Gross and Neveu, have introduced an
explicit factor of 1/N in the coupling strength in (16), so that the two terms in (18) both scale
as N. Thus, the path integral Z =

DσeiS(σ) may be evaluated by the steepest descent or
stationary phase method in the large N limit. We simply extremize S(σ).
Incidentally, we can see the judiciousness of the choice a = 1 in large N QCD in the
same way. Integrating out the quarks in (1) we get
S = −

d4x N
2g2 tr FμνF μν + N tr log(i(̸∂−i̸A) −m)
and thus the two terms both scale as N and can balance each other. The increase in the
number of degrees of freedom has to be offset by a weakening of the coupling.
To study the ground state behavior of the theory, we restrict our attention to field
configurations σ(x) that do not depend on x. (In other words, we are not expecting
translation symmetry to be spontaneously broken.) We can immediately take over the result
you got in exercise IV.3.3 and write the effective potential
1
N V (σ) =
1
2g(μ)2σ 2 + 1
4π σ 2

log σ 2
μ2 −3

(19)
We have imposed the condition (1/N)[d2V (σ)/dσ 2]|σ=μ = 1/g(μ)2 as the definition of
the mass scale dependent coupling g(μ) (compare IV.3.18). The statement that V (σ) is
independent of μ immediately gives
1
g(μ)2 −
1
g(μ′)2 = 1
π log μ
μ′
(20)
As μ →∞, g(μ) →0. Remarkably, this theory is asymptotically free, just like QCD. If we
want to, we can work backward to find the flow equation
μ d
dμg(μ) = −1
2π g(μ)3 + . . .
(21)
The theory in its different incarnations, (16), (17), and (18), enjoys a discrete Z2 symme-
try under which ψa →γ 5ψa and σ →−σ . As in chapter IV.3, this symmetry is dynamically

404 | VII. Grand Unification
broken by quantum fluctuations. The minimum of V (σ) occurs at σmin = μe1−π/g(μ)2 and
so according to (17) the fermions acquire a mass
mF = σmin = μe1−π/g(μ)2
(22)
Note that this highly nontrivial result can hardly be seen by staring at (16) and we have no
way of proving it for finite N. In the spirit of the large N approach, however, we expect that
the fermion mass might be given by mF = μe1−π/g(μ)2 + O(1/N2) so that (22) would be a
decent approximation even for say, N = 3. Since mF is physically measurable, it better not
depend on μ. You can check that.
This theory also exhibits dimensional transmutation as described in the previous chap-
ter. We start out with a theory with a dimensionless coupling g and end up with a dimen-
sional fermion mass mF . Indeed, any other quantity with dimension of mass would have
to be equal to mF times a pure number.
Dynamically generated kinks
I discuss the existence of kinks and solitons in chapter V.6. You clearly understood that the
existence of such objects follows from general considerations of symmetry and topology,
rather than from detailed dynamics. Here we have a (1 + 1)-dimensional theory with a
discrete Z2 symmetry, so we certainly expect a kink, namely a time independent configu-
ration σ(x) (henceforth x will denote only the spatial coordinate and will no longer label
a generic point in spacetime) such that σ(−∞) = −σmin and σ(+∞) = σmin. [Obviously,
there is also the antikink with σ(−∞) = σmin and σ(+∞) = −σmin.]
At first sight, it would seem almost impossible to determine the precise shape of the
kink. In principle, we have to evaluate tr log[i̸∂−σ(x)] for an arbitrary function σ(x) such
that σ(+∞) = −σ(−∞) (and as I explained in chapter IV.3, this involves finding all the
eigenvalues of the operator i̸∂−σ(x), summing over the logarithm of the eigenvalues),
and then varying this functional of σ(x) to find the optimal shape of the kink.
Remarkably, the shape can actually be determined thanks to a clever observation.5 In
analogy with the steps leading to (IV.3.24) we note that
tr log[i̸∂−σ(x)] = tr log γ 5[i̸∂−σ(x)]γ 5 = tr log(−1)[i̸∂+ σ(x)]
and thus up to an irrelevant additive constant
tr log(i̸∂−σ(x)) = 1
2 tr log[i̸∂−σ(x)][i̸∂+ σ(x)]
= 1
2 tr log

−∂2 + iγ 1σ ′(x) −[σ(x)]2
(23)
5 C. Callan, S. Coleman, D. Gross, and A. Zee, (unpublished). See D. J. Gross, “Applications of the Renormal-
ization Group to High-Energy Physics,” in: R. Balian and J. Zinn-Justin, eds., Methods in Field Theory, p. 247. By
the way, I recommend this book to students of field theory.

VII.4. Large N Expansion | 405
Since γ 1 has eigenvalues ±i, this is equal to
1
2

tr log{−∂2 + σ ′(x) −[σ(x)]2} + tr log{−∂2 −σ ′(x) −[σ(x)]2}

but these two terms are equal by parity (space reflection) and hence
tr log[i̸∂−σ(x)] = tr log{−∂2 −σ ′(x) −[σ(x)]2}
Referring to (18) we see that S(σ) is the sum of two terms, a term quadratic in σ(x)
and a term that depends only on the combination σ ′(x) + [σ(x)]2. But we know that σmin
minimizes S(σ). Thus, the soliton is given by the solution of the ordinary differential
equation
σ ′(x) + [σ(x)]2 = σ 2
min
(24)
namely σ(x) = σmin tanh σminx. The soliton would be observed as an object of size
1/σmin = 1/mF. I leave it to you to show that its mass is given by
mS = N
π mF
(25)
Precisely as theorized in the last chapter, the ratio mS/mF comes out to be a pure number,
N/π, as it must.
By an even more clever method that I do not have space to describe, Dashen, Hasslacher,
and Neveu were able to study time dependent configurations of σ and determine the mass
spectrum of this model.
Exercises
VII.4.1 Since the number of gluons only differs by one, it is generally argued that it does not make any difference
whether we choose to study the U(N) theory or the SU(N) theory. Discuss how the gluon propagator in
a U(N) theory differs from the gluon propagator in an SU(N) theory and decide which one is easier.
VII.4.2 As a challenge, solve large N QCD in (1 + 1)-dimensional spacetime. [Hint: The key is that in (1 + 1)-
dimensional spacetime with a suitable gauge choice we can integrate out the gauge potential Aμ.] For
help, see ’t Hooft, Under the Spell of the Gauge Principle, p. 443.
VII.4.3 Show that if we had chosen to calculate G(z) ≡⟨(1/N) tr(1/z −ϕ)⟩, we would have to connect the two
open ends of the quark propagator. We see that figures VII.4.5b and d lead to the same diagram. Complete
the calculation of G(z) in this way.
VII.4.4 Suppose the random matrix ϕ is real symmetric rather than hermitean. Show that the Feynman rules
are more complicated. Calculate the density of eigenvalues. [Hint: The double-line propagator can twist.]
VII.4.5 For hermitean random matrices ϕ, calculate
Gc(z, w) ≡
 1
N tr
1
z −ϕ
1
N tr
1
w −ϕ

−
 1
N tr
1
z −ϕ
  1
N tr
1
w −ϕ

for V (ϕ) = 1
2m2ϕ2 using Feynman diagrams. [Note that this is a much simpler object to study than the
object we need to study in order to learn about localization (see exercise VI.6.1).] Show that by taking
suitable imaginary parts we can extract the correlation of the density of eigenvalues with itself. For help,
see E. Br´ezin and A. Zee, Phys. Rev. E51: p. 5442, 1995.

406 | VII. Grand Unification
VII.4.6 Use the Faddeev-Popov method to calculate J in the Dyson gas approach.
VII.4.7 For V (ϕ) = 1
2m2ϕ2 + gϕ4, determine ρ(E). For m2 sufficiently negative (the double well potential again)
we expect the density of eigenvalues to split into two pieces. This is evident from the Dyson gas picture.
Find the critical value m2
c. For m2 < m2
c the assumption of G(z) having only one cut used in the text fails.
Show how to calculate ρ(E) in this regime.
VII.4.8 Calculate the mass of the soliton (25).

VII.5
Grand Unification
Crying out for unification
A gauge theory is specified by a group and the representations the matter fields belong
to. Let us go back to chapter VII.2 and make a catalogue for the SU(3) ⊗SU(2) ⊗U(1)
theory. For example, the left handed up and down quarks are in a doublet
 uα
dα

L with
hypercharge 1
2Y = 1
6. Let us denote this by (3, 2, 1
6)L, with the three numbers indicating
how these fields transform under SU(3) ⊗SU(2) ⊗U(1). Similarly, the right handed up
quark is (3, 1, 2
3)R. The leptons are (1, 2, −1
2)L and (1, 1, −1)R, where the “1” in the first
entry indicates that these fields do not participate in the strong interaction. Writing it all
down, we see that the quarks and leptons of each family are placed in
(3, 2, 1
6)L, (3, 1, 2
3)R, (3, 1, −1
3)R, (1, 2, −1
2)L, and (1, 1, −1)R
(1)
This motley collection of representations practically cries out for further unification.
Who would have constructed the universe by throwing this strange looking list down?
What we would like to have is a larger gauge group G containing SU(3) ⊗SU(2) ⊗
U(1), such that this laundry list of representations is unified into (ideally) one great big
representation. The gauge bosons in G [but not in SU(3) ⊗SU(2) ⊗U(1) of course] would
couple the representations in (1) to each other.
Before we start searching for G, note that since gauge transformations commute with
the Lorentz group, these desired gauge transformations cannot change left handed fields
to right handed fields. So let us change all the fields in (1) to left handed fields. Recall from
exercise II.1.9 that charge conjugation changes left handed fields to right handed fields
and vice versa. Thus, instead of (1) we can write
(3, 2, 1
6), (3∗, 1, −2
3), (3∗, 1, 1
3), (1, 2, −1
2), and (1, 1, 1)
(2)
We now omit the subscripts L and R: everybody is left handed.

408 | VII. Grand Unification
A perfect fit
The smallest group that contains SU(3) ⊗SU(2) ⊗U(1) is SU(5). (If you are shaky
about group theory, study appendix B now.) Recall that SU(5) has 52 −1 = 24 generators.
Explicitly, the generators are represented by 5 by 5 hermitean traceless matrices acting on
five objects we denote by ψμ with μ = 1, 2, . . . , 5. [These five objects form the fundamental
or defining representation of SU(5).]
It is now obvious how we can fit SU(3) and SU(2) into SU(5). Of the 24 matrices that
generate SU(5), eight have the form
 A 0
0 0

and three the form
 0 0
0 B

, where A represents
3 by 3 hermitean traceless matrices (of which there are 32 −1 = 8, the so-called Gell-
Mann matrices) and B represents 2 by 2 hermitean traceless matrices (of which there
are 22 −1 = 3, namely the Pauli matrices). Clearly, the former generate an SU(3) and the
latter an SU(2). Furthermore, the 5 by 5 hermitean traceless matrix
1
2Y =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
−1
3
0
0
0
0
0
−1
3
0
0
0
0
0
−1
3
0
0
0
0
0
1
2
0
0
0
0
0
1
2
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
(3)
generates a U(1). Without being coy about it, we have already called this matrix the
hypercharge 1
2Y.
In other words, if we separate the index μ = {α, i} with α = 1, 2, 3 and i = 4, 5, then
the SU(3) acts on the index α and the SU(2) acts on the index i. Thus, the three objects
ψα transform as a 3-dimensional representation under SU(3) and hence could be a 3
or a 3∗. Let us choose ψα as transforming as 3; we will see shortly that this is the right
choice with Y/2 given as in (3). The three objects ψα do not transform under SU(2)
and hence each of them belongs to the singlet 1 representation. Furthermore, they carry
hypercharge −1
3 as we can read off from (3). To sum up, ψα transform as (3, 1, −1
3)
under SU(3) ⊗SU(2) ⊗U(1). On the other hand, the two objects ψi transform as 1under
SU(3) and 2 under SU(2), and carry hypercharge 1
2; thus they transform as (1, 2, 1
2). In
other words, we embed SU(3) ⊗SU(2) ⊗U(1) into SU(5) by specifying how the defining
representation of SU(5) decomposes into representations of SU(3) ⊗SU(2) ⊗U(1)
5 →(3, 1, −1
3) ⊕(1, 2, 1
2)
(4)
Taking the conjugate we see that
5∗→(3∗, 1, 1
3) ⊕(1, 2, −1
2)
(5)
Inspecting (2), we see that (3∗, 1, 1
3) and (1, 2, −1
2) appear on the list. We are on the right
track! The fields in these two representations fit snugly into 5∗.
This accounts for five of the fields contained in (2); we still have the ten fields
(3, 2, 1
6), (3∗, 1, −2
3), and (1, 1, 1)
(6)

VII.5. Grand Unification | 409
Consider the next representation of SU(5) in order of size, namely the antisymmetric
tensor representation ψμν . Its dimension is (5 × 4)/2 = 10, precisely the number we want,
if only the quantum numbers under SU(3) ⊗SU(2) ⊗U(1) work out!
Since we know that 5 →(3, 1, −1
3) ⊕(1, 2, 1
2), we simply (again, see appendix B!) have to
work out the antisymmetric product of (3, 1, −1
3) ⊕(1, 2, 1
2) with itself, namely the direct
sum of (where ⊗A denotes the antisymmetric product)
(3, 1, −1
3) ⊗A (3, 1, −1
3) = (3∗, 1, −2
3)
(7)
(3, 1, −1
3) ⊗A (1, 2, 1
2) = (3, 2, −1
3 + 1
2) = (3, 2, 1
6)
(8)
and
(1, 2, 1
2) ⊗A (1, 2, 1
2) = (1, 1, 1)
(9)
[I will walk you through (7): In SU(3) 3 ⊗A 3 = 3∗(remember εijk from appendix B?), in
SU(2) 1 ⊗A 1 = 1, and in U(1) the hypercharges simply add −1
3 −1
3 = −2
3.]
Lo and behold, these SU(3) ⊗SU(2) ⊗U(1) representations form exactly the collection
of representations in (6). In other words,
10 →(3, 2, 1
6) ⊕(3∗, 1, −2
3) ⊕(1, 1, 1)
(10)
The known quark and lepton fields in a given family fit perfectly into the 5∗and 10
representations of SU(5)!
I have just described the SU(5) grand unified theory of Georgi and Glashow. In spite of
the fact that the theory has not been directly verified by experiment, it is extremely difficult
for me and for many other physicists not to believe that SU(5) is at least structurally correct,
in view of the perfect group theoretic fit.
It is often convenient to display the contents of the representation 5∗and 10, using the
names given to the various fields historically. We write 5∗as a column vector
ψμ =
 ψα
ψi

=
⎛
⎜⎜⎝
¯dα
ν
e
⎞
⎟⎟⎠
(11)
and the 10 as an antisymmetric matrix
ψμν = {ψαβ, ψαi, ψij}
=
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
0
¯u
−¯u
d
u
−¯u
0
¯u
d
u
¯u
−¯u
0
d
u
−d
−d
−d
0
¯e
−u
−u
−u
−¯e
0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
(12)
(I suppressed the color indices.)

410 | VII. Grand Unification
Deepening our understanding of physics
Aside from its esthetic appeal, grand unification deepens our understanding of physics
enormously.
1. Ever wondered why electric charge is quantized? Why don’t we see particles with
charge equal to √π times the electron’s charge? In quantum electrodynamics, you could
perfectly well write down
L = ¯ψ[i(̸ ∂−i̸A) −m]ψ + ¯ψ′[i(̸ ∂−i√π ̸A) −m′]ψ′ + . . .
(13)
In contrast, in grand unified theory Aμ couples to a generator of the grand unifying
gauge group, and you know that the generators of any group such as SU(N) (that is
not given by the direct product of U(1) with other groups) are forced by the nontrivial
commutation relations [Ta, Tb] = ifabcTc to assume quantized values. For example, the
eigenvalues of T3 in SU(2), which depend on the representation of course, must be
multiples of 1
2. Within SU(3) × SU(2) × U(1), we cannot understand charge quantization:
The generator of U(1) is not quantized. But upon grand unification into SU(5) [or more
generally any group without U(1) factors] electric charge is quantized.
The result here is deeply connected to Dirac’s remark (chapter IV.4) that electric charge is
quantized if the magnetic monopole exists. We know from chapter V.7 that spontaneously
broken nonabelian gauge theories such as the SU(5) theory contain the monopole.
2. Ever wondered why the proton charge is exactly equal and opposite to the electron
charge? This important fact allows us to construct the universe as we know it. Atoms must
be electrically neutral to some fantastic degree of accuracy for standard cosmology to work;
otherwise, electrostatic forces between macroscopic matter would tear the universe apart.
This remarkable fact is nicely incorporated into SU(5). It is fun to see how it goes.
Evaluating tr Q = 0 over the 5∗implies that 3Q ¯d = −Qe−. I have used the fact that the
strong interaction commutes with electromagnetism and hence quarks with different color
have the same charge. Now let us calculate the proton charge QP:
QP = 2Qu + Qd = 2(Qd + 1) + Qd = 3Qd + 2 = Qe−+ 2
(14)
If Qe−= −1, then QP = −Qe−, as is indeed the case!
3. Recall that in electroweak theory we defined tan θ = g1/g2, with the coupling of the
gauge bosons g2Aa
μTa + g1Bμ(Y/2). Since the normalization of Aa
μ and Bμ is fixed by
their respective kinetic energy term, the relative strength of g2 and g1 is determined by
the normalization of Y/2 relative to T3. Let us evaluate tr T 2
3 and tr(Y/2)2 on the defining
representation 5 : tr T 2
3 = ( 1
2)2 + ( 1
2)2 = 1
2 and tr(Y/2)2 = ( 1
3)23 + ( 1
2)22 = 5
6.
Thus, T3 and
	
3/5(Y/2) are normalized equally. So the correct grand unified combina-
tion is Aa
μTa + Bμ
	
3/5(Y/2), and therefore tan θ = g1/g2 =
	
3/5 or
sin2 θ = 3
8
(15)

VII.5. Grand Unification | 411
at the grand unification scale. To compare with the experimental value of sin2 θ we would
have to study how the couplings g2 and g1 flow under the renormalization group down to
low energies. We will postpone this discussion until the next chapter.
Freedom from anomaly
Recall from chapter VII.2 that the key to proving renormalizability of nonabelian gauge
theory is the ability to pass freely between the unitary gauge and the Rξ gauge. The
crucial ingredient is gauge invariance and the resulting Ward-Takahashi identities (see
chapter II.7).
Suddenly you start to worry. What about the chiral anomaly? The existence of the
anomaly means that some Ward-Takahashi identities fail to hold. For our theories to make
sense, they had better be free from anomalies. I remarked in chapter IV.7 that the historical
name “anomaly” makes it sound like some kind of sickness. Well, in a way, it is.
We should have already checked the SU(3) ⊗SU(2) ⊗U(1) theory for anomalies, but
we didn’t. I will let you do it as an exercise. Here I will show that the SU(5) theory is healthy.
If the SU(5) theory is anomaly-free, then a fortiori so is the SU(3) ⊗SU(2) ⊗U(1) theory.
In chapter IV.7 I computed the anomaly in an abelian theory but as I remarked there
clearly all we have to do to generalize to a nonabelian theory is to insert a generator Ta
of the gauge group at each vertex of the triangle diagram in figure IV.7.1. Summing over
the various fermions running around the loop, we see that the anomaly is proportional
to Aabc(R) ≡tr(Ta{Tb, Tc}), where R denotes the representation to which the fermions
belong. We have to sum Aabc(R) over all the representations in the theory, remembering
to associate opposite signs to left handed and right handed fermion fields. (It may be
helpful to remind yourself of remark 3 in chapter IV.7 and exercise IV.7.6.)
We are now ready to give the SU(5) theory a health check. First, all fermion fields in (2)
are left handed. Second, convince yourself (simply imagine calculating Aabc for all possible
abc) that it suffices to set Ta, Tb, and Tc all equal to
T ≡
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
2
0
0
0
0
0
2
0
0
0
0
0
2
0
0
0
0
0
−3
0
0
0
0
0
−3
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
a multiple of the hypercharge. Let us now evaluate tr T 3 on the 5∗representation,
tr T 3|5∗= 3(−2)3 + 2(+3)3 = 30
(16)
and on the 10,
tr T 3|10 = 3(+4)3 + 6(−1)3 + (−6)3 = −30
(17)
An apparent miracle! The anomaly cancels.

412 | VII. Grand Unification
This remarkable cancellation between sums of cubes of a strange list of numbers
suggests strongly, to say the least, that SU(5) is not the end of the story. Besides, it would
be nice if the 5∗and 10 could be unified into a single representation.
Exercises
VII.5.1
Write down the charge operator Q acting on 5, the defining representation ψμ. Work out the charge
content of the 10 = ψμν and identify the various fields contained therein.
VII.5.2 Show that for any grand unified theory, as long as it is based on a simple group, we have at the unification
scale
sin2 θ =
 T 2
3
 Q2
(18)
where the sum is taken over all fermions.
VII.5.3
Check that the SU(3) ⊗SU(2) ⊗U(1) theory is anomaly-free. [Hint: The calculation is more involved
than in SU(5) since there are more independent generators. First show that you only have to evaluate
tr Y{Ta, Tb} and tr Y 3, with Ta and Y the generators of SU(2) and U(1), respectively.]
VII.5.4 Construct grand unified theories based on SU(6), SU(7), SU(8), . . . , until you get tired of the game.
People used to get tenure doing this. [Hint: You would have to invent fermions yet to be experimentally
discovered.]

VII.6
Protons Are Not Forever
Proton decay
Charge conservation guarantees the stability of the electron, but what about the stability of
the proton? Charge conservation allows p →π0 + e+. No fundamental principle says that
the proton lives forever, but yet the proton is known for its longevity: It has been around
essentially since the universe began.
The stability of the proton had to be decreed by an authority figure: Eugene Wigner was
the first to proclaim the law of baryon number conservation. The story goes that when
Wigner was asked how he knew that the proton lives forever he quipped, “I can feel it in
my bones.” I take the remark to mean that just from the fact that we do not glow in the
dark we can set a fairly good lower bound on the proton’s life span.
As soon as we start grand unifying, we better start worrying. Generically, when we grand
unify we put quarks and leptons into the same representation of some gauge group [see
(VII.5.11 and VII.5.12)]. This miscegenation immediately implies that there are gauge
bosons transforming quarks into leptons and vice versa. The bag of three quarks known
as the proton could very well get turned into leptons upon the exchange of these gauge
bosons. In other words, the proton, the rock on which our world is built upon, may not be
forever! Thus, grand unification runs the risk of being immediately falsified.
Let MX denote generically the masses of those gauge bosons transforming quarks into
leptons and vice versa. Then the amplitude for proton decay is of order g2/M2
X, with g
the coupling strength of the grand unifying gauge group, and the proton decay rate  is
given by (g2/M2
X)2 times a phase space factor controlled essentially by the proton mass
mP since the pion and positron masses are negligible compared to the proton mass. By
dimensional analysis, we determine that  ∼(g2/M2
X)2m5
P . Since the proton is known to
live for something like at least 1031 years, MX had better be huge compared to the kind of
energy scales we can reach experimentally.
The mass MX is of the same order as the mass scale MGUT at which the grand unified
theory is spontaneously broken down to SU(3) ⊗SU(2) ⊗U(1). Specifically, in the SU(5)

414 | VII. Grand Unification
μ
3
5(      )
4π
g2
4π
g2
4π
g2
4π
g2
MGUT
1
2
3
Figure VII.6.1
theory, a Higgs field H μ
ν transforming as the adjoint 24, with its vacuum expectation value
⟨H μ
ν ⟩equal to the diagonal matrix with elements (−1
3, −1
3, −1
3, 1
2, 1
2) times some v, can
do the job, as was discussed in chapter IV.6. The gauge bosons in SU(3) ⊗SU(2) ⊗U(1)
remain massless while the other gauge bosons acquire mass MX of order gv.
To determine MGUT, we apply renormalization group flow to g3, g2, and g1, the cou-
plings of SU(3), SU(2), and U(1), respectively. The idea is that as we move up in the
mass or energy scale μ the two asymptotically free couplings g3(μ) and g2(μ) decrease
while g1(μ) increases. Thus, at some mass scale MGUT they will meet and that is where
SU(3) ⊗SU(2) ⊗U(1) is unified into SU(5) (see figure VII.6.1). Because of the extremely
slow logarithmic running (it should be called walking or even crawling but again for his-
torical reasons we are stuck with running) of the coupling constant, we anticipate that the
unification mass scale MGUT will come out to be much larger than any scale we were used
to in particle physics prior to grand unification. In fact, MGUT will turn out to have an
enormous value of the order 1014−15Gev and the idea of grand unification passes its first
hurdle.
Stability of the world implies the weakness of electromagnetism
Using the result of exercise VI.8.1 we obtain (here αS ≡g2
3/4π and αGUT ≡g2/4π denote
the strong interaction and grand unification analog of the fine structure constant α,
respectively, with F the number of families)
4π
[g3(μ)]2 ≡
1
αS(μ) =
1
αGUT
+ 1
6π (4F −33) log MGUT
μ
(1)
4π
[g2(μ)]2 ≡sin2 θ(μ)
α(μ)
=
1
αGUT
+ 1
6π (4F −22) log MGUT
μ
(2)
3
5
4π
[g1(μ)]2 ≡3
5
cos2 θ(μ)
α(μ)
=
1
αGUT
+ 1
6π 4F log MGUT
μ
(3)

VII.6. Protons Are Not Forever | 415
By θ(μ) we mean the value of θ at the scale μ. At μ = MGUT, the three couplings are related
through SU(5).
We evaluate these equations for some experimentally accessible value of μ, plugging in
measured values of αS and α. With three equations, we not only manage to determine the
unification scale MGUT and coupling αGUT, but we can predict θ. In other words, unless
the ratio g1 to g2 is precisely right, the three lines in figure VII.6.1 will not meet at one
point.
Note that the number of fermion families F contributes equally to (1), (2), and (3). This is
as it should be since the fermions are effectively massless for the purpose of this calculation
and do not “know” that the unifying group has been broken into SU(3) ⊗SU(2) ⊗U(1).
These equations are derived assuming that all fermion masses are small compared to μ.
Rearranging these equations somewhat, we find
sin2 θ = 1
6 + 5α(μ)
9αS(μ)
(4)
sin2 θ
α(μ) =
1
αS(μ) + 1
6π 11 log MGUT
μ
(5)
1
α(μ) = 8
3
1
αGUT
+ 1
6π
32
3 F −22

log MGUT
μ
(6)
We obtain in (4) a prediction for sin2 θ(μ) independent of MGUT and of the number of
families.
Note that (5) gives the bound
1
α(μ) ≥1
6π 11 log MGUT
μ
(7)
A lower bound on the proton lifetime (and hence on MGUT) translates into an upper bound
on the fine structure constant. Amusingly, the stability of the world implies the weakness
of electromagnetism.
As I noted earlier, plugging in the measured value of αS, we obtain a huge value for
MGUT. I regard this as a triumph of grand unification: MGUT could have come out to have
a much lower scale, leading to an immediate contradiction with the observed stability of the
proton, but it didn’t. Another way of looking at it is that if we are somehow given MGUT and
αGUT, grand unification fixes the couplings of all three nongravitational interactions! The
point is not that this simplest try at grand unification doesn’t quite agree with experiment:
The miracle is that it works at all.
It is beyond the scope of this book to discuss in detail the comparison of (4), (5), and
(6) with experiment. To do serious phenomenology, one has to include threshold effects
(see exercise VII.6.1), higher order corrections, and so on. To make a long story short,
after grand unified theory came out there was enormous excitement over the possibility
of proton decay. Alas, the experimental lower bound on the proton lifetime was eventually
pushed above the prediction. This certainly does not mean the demise of the notion of
grand unification. Indeed, as I mentioned earlier, the perfect fit is enough to convince
most particle theorists of the essential correctness of the idea. Over the years people have
proposed adding various hypothetical particles to the theory to promote proton longevity.

416 | VII. Grand Unification
The idea is that these particles would affect the renormalization group flow and hence
MGUT. The proton lifetime is actually not the most critical issue. With more accurate
measurements of αS and of θ, it was found that the three couplings do not quite meet at
a point. Indeed, for believers in low energy supersymmetry, part of their faith is founded
on the fact that with supersymmetric particles included, the three coupling constants do
meet.1 But skeptics of course can point to the extra freedom to maneuver.
Branching ratios
You may have realized that (1), (2), and (3) are not specific for SU(5): they hold as long
as SU(3) ⊗SU(2) ⊗U(1) is unified into some simple group (simple so that there is only
one gauge coupling g).
Let us now focus on SU(5). Recall that we decompose the SU(5) index μ, which can
take on five values, into two types. In other words, the index μ is labeled by {α, i}, where α
takes on three values and i takes on two values. The gauge bosons in SU(5) correspond to
the 24 independent components of the traceless hermitean field Aμ
ν (μ, ν = 1, 2, . . . , 5)
transforming as the adjoint representation. Focusing on the group theory of SU(5), we
will suppress Lorentz indices, spinor indices, etc. Clearly, the eight gauge bosons in SU(3)
transform an index of type α into an index of type α, while the three gauge bosons in SU(2)
transform an index of type i into an index of type i. Then there is the U(1) gauge boson
that couples to the hypercharge 1
2Y . (Of course, you know what I mean by my somewhat
loose language: The SU(3) gauge bosons transform fields carrying a color index into a
field carrying a color index.)
The fun comes with the gauge bosons Aα
i and Ai
α, which transform the index α into
the index i and vice versa. Since α takes on three values, and i takes on two values, there
are 6 + 6 = 12 such gauge bosons, thus accounting for all the gauge bosons in SU(5). In
other words, 24 →(8, 1) + (1, 3) + (1, 1) + (3, 2) + (3∗, 2). We will now see explicitly that
the exchange of these bosons between quarks and leptons leads to proton decay.
We merely have to write down the terms in the Lagrangian involving the coupling of
the bosons Aα
i and Ai
α to fermions and draw the appropriate Feynman diagrams. I will
go through part of the group theoretic analysis, leaving you to work out the rest. Simply
by contracting indices we see that the boson Aμ
ν acting on ψμ takes it to ψν and acting on
ψνρ takes it to ψμρ. Let us look at what A5
α does, using your result from exercise VII.5.1.
It takes
ψ5 = e−→ψα = ¯d
(8)
ψαβ = ¯u →ψ5β = u
(9)
and
ψα4 = d →ψ54 = e+
(10)
1 See, e.g., F. Wilczek, in: V. Fitch et al., eds., Critical Problems in Physics, p. 297.

VII.6. Protons Are Not Forever | 417
 d
e+
 u
 u
 d
e+
 u
 u
 u
 u
Figure VII.6.2
Thus, the exchange of A5
α generates the process (figure VII.6.2) u + d →¯u + e+, leading to
proton decay p(uud) →π0(u¯u) + e+. Observe that while the decay p →π0 + e+ violates
both baryon number B and lepton number L, it conserves the combination B −L.
In exercise VII.6.2 you will work out the branching ratios for various decay modes. Too
bad experimentalists have not yet measured them.
Fermion masses
We might hope that with grand unification we would gain new understanding of quark
and lepton masses. Unfortunately, the situation on fermion masses in SU(5) is muddled,
and to this day nobody understands the origin of quark and lepton masses.
Introducing a Higgs field ϕμ transforming as the 5 (as indicated by the notation) we can
write the coupling
ψμCψμνϕν
(11)
and
ψμνCψλρϕσεμνλρσ
(12)
(with ϕν the conjugate 5∗), reflecting the group theoretic fact (see appendix C) that 5∗⊗10
contains the 5 and 10 ⊗10 contains the 5∗.
Since 5 →(3, 1, −1
3) ⊕(1, 2, 1
2) we see that this Higgs field is just the natural extension
of the SU(2) ⊗U(1) Higgs doublet (1, 2, 1
2). Not wanting to break electromagnetism, we
allow only the electrically neutral fourth component of ϕ to acquire a vacuum expectation
value. Setting ⟨ϕ4⟩= v, we obtain (up to uninteresting overall constants)
ψαCψα4 + ψ5Cψ54 ⇒md = me
(13)
and
ψαβCψγ 5εαβγ ⇒mu ̸= 0
(14)

418 | VII. Grand Unification
The larger symmetry yields a mass relation md = me at the unification scale; we again
have to apply the renormalization group flow. It is worth noting that the mass relation
md = me comes about because as far as the fermions are concerned, SU(5) has been only
broken down to SU(4) by ϕ. The trouble is that we obtain more or less the same relation
for each of the three families, since most of the running occurs between the unification
scale MGUT and the top quark mass so that threshold effects give only a small correction.
Putting in numbers one gets something like
mb
mτ
∼ms
mμ
∼md
me
∼3
(15)
Let us use this to predict the down sector quark masses in terms of the lepton masses.
The formula mb ∼3mτ works rather well and provides indirect evidence that there can
only be three families since the renormalization group flow depends on F . The formula
ms ∼3mμ is more or less in the ballpark, depending on what “experimental” value one
takes for ms. The formula for md, on the other hand, is downright embarrassing. People
mumble something about the first family being so light and hence other effects, such as
one-loop corrections might be important. At the cost of making the theory uglier, people
also concoct various schemes by introducing more Higgs fields, such as the 45, to give
mass to fermions.
Note that in one respect SU(5) is not as “economical” as SU(2) ⊗U(1), in which the
same Higgs field that gives mass to the gauge bosons also gives mass to the fermions.
The universe is not empty, but almost
I mention in passing another triumph of grand unification: its ability to explain the origin
of matter in our universe. It has long behooved physicists to understand two fundamental
facts about the universe: (1) the universe is not empty, and (2) the universe is almost empty.
To physicists, (1) means that the universe is not symmetric between matter and antimatter,
that is, the net baryon number NB is nonzero; and (2) is quantified by the strikingly small
observed value NB/Nγ ∼10−10 of the ratio of the number of baryons to the number of
photons.
Suppose we start with a universe with equal quantities of matter and antimatter. For the
universe to evolve into the observed matter dominated universe, three conditions must be
satisfied: (1) The laws of the universe must be asymmetric between matter and antimatter.
(2) The relevant physical processes had to be out of equilibrium so that there was an arrow
of time. (3) Baryon number must be violated.
We know for a fact that conditions (1) and (2) indeed hold in the world: There is
CP violation in the weak interaction and the early universe expanded rapidly. As for
(3), grand unification naturally violates baryon number. Furthermore, while proton decay
(suppressed by a factor of 1/M2
GUT in amplitude) proceeds at an agonizingly slow rate (for
those involved in the proton decay experiment!), in the early universe, when the X and
Y bosons are produced in abundance, their fast decays could easily drive baryon number

VII.6. Protons Are Not Forever | 419
violation. The suppression factor 1/M2
GUT does not come in. I have no doubt that eventually
the number 10−10 measuring “the amount of dirt in the universe” will be calculated in
some grand unified theory.
Hierarchy
I promised you that the Weisskopf phenomenon would come back to haunt us. That the
grand unification mass scale MGUT naturally comes out so large counts as a triumph,
but it also leads to a problem known as the hierarchy problem. The hierarchy refers to
the enormous ratio MGUT/MEW, where MEW denotes the electroweak unification scale, of
order 102 Gev. I will sketch this rather murky subject. Look at the Higgs field ϕ respon-
sible for breaking electroweak theory. We don’t know its renormalized or physical mass
precisely, but we do know that it is of order MEW. Imagine calculating the bare pertur-
bation series in some grand unified theory—the precise theory does not enter into the
discussion—starting with some bare mass μ0 for ϕ. The Weisskopf phenomenon tells
us that quantum correction shifts μ2
0 by a huge quadratically cutoff dependent amount
δμ2
0 ∼f 22 ∼f 2M2
GUT, where we have substituted for  the only natural mass scale
around, namely MGUT, and where f denotes some dimensionless coupling. To have the
physical mass squared μ2 = μ2
0 + δμ2
0 come out to be of order M2
EW, something like 28 or-
ders of magnitude smaller than M2
GUT, would require an extremely fine-tuned and highly
unnatural cancellation between μ2
0 and δμ2
0. How this could happen “naturally” poses a
severe challenge to theoretical physicists.
Naturalness
The hierarchy problem is closely connected with the notion of naturalness dear to the the-
oretical physics community. We naturally expect that dimensionless ratios of parameters
in our theories should be of order unity, where the phrase “order unity” is interpreted lib-
erally between friends, say anywhere from 10−2 or 10−3 to 102 or 103. Following ’t Hooft,
we can formulate a technical definition of naturalness: The smallness of a dimensionless
parameter η would be considered natural only if a symmetry emerges in the limit η →0.
Thus, fermion masses could be naturally small, since, as you will recall from chapter II.1,
a chiral symmetry emerges when a fermion mass is set equal to zero. On the other hand,
no particular symmetry emerges when we set either the bare or renormalized mass of a
scalar field equal to zero. This represents the essence of the hierarchy problem.
Exercises
VII.6.1 Suppose there are F ′ new families of quarks and leptons with masses of order M′. Adopting the crude
approximation described in exercise VI.8.2 of ignoring these families for μ below M′ and of treating M′

420 | VII. Grand Unification
as negligible for μ above M′, run the renormalization group flow and discuss how various predictions,
such as proton lifetime, are changed.
VII.6.2 Work out proton decay in detail. Derive relations between the following decay rates: (p →π0e+),
(p →π+¯ν), (n →π−e+), and (n →π0¯ν).
VII.6.3 Show that SU(5) conserves the combination B −L. For a challenge, invent a grand unified theory that
violates B −L.

VII.7
SO(10) Unification
Each family into a single representation
At the end of chapter VII.5 we felt we had good reason to think that SU(5) unification is
not the end of the story. Let us ask if we might be able to fit the 5 and 10∗into a single
representation of a bigger group G containing SU(5).
It turns out that there is a natural embedding of SU(5) into the orthogonal SO(10)
that works,1 but to explain that I have to teach you some group theory. The starting point
is perhaps somewhat surprising: We go back to chapter II.3, where we learned that the
Lorentz group SO(3, 1), or its Euclidean cousin SO(4), has spinor representations. We
will now generalize the concept of spinors to d-dimensional Euclidean space. I will work
out the details for d even and leave the odd dimensions as an exercise for you. You might
also want to review appendix B now.
Clifford algebra and spinor representations
Start with an assertion. For any integer n we claim that we can find 2n hermitean matrices
γi (i = 1, 2, . . . , 2n) that satisfy the Clifford algebra
{γi, γj} = 2δij
(1)
In other words, to prove our claim we have to produce 2n hermitean matrices γi that
anticommute with each other and square to the identity matrix. We will refer to the γi’s as
the γ matrices for SO(2n).
For n = 1, it is a breeze: γ1 = τ1 and γ2 = τ2. There you are.
1 Howard Georgi told me that he actually found SO(10) before SU(5).

422 | VII. Grand Unification
Now iterate. Given the 2n γ matrices for SO(2n) we construct the (2n + 2) γ matrices
for SO(2n + 2) as follows
γ (n+1)
j
= γ (n)
j
⊗τ3 =
 γ (n)
j
0
0
−γ (n)
j

, j = 1, 2, . . . , 2n
(2)
γ (n+1)
2n+1 = 1 ⊗τ1 =
 0
1
1
0

(3)
γ (n+1)
2n+2 = 1 ⊗τ2 =
 0
−i
i
0

(4)
(Throughout this book 1 denotes a unit matrix of the appropriate size.) The superscript in
parentheses is obviously for us to keep track of which set of γ matrices we are talking about.
Verify that if the γ (n)’s satisfy the Clifford algebra, the γ (n+1)’s do as well. For example,
{γ (n+1)
j
, γ (n+1)
2n+1 } = (γ (n)
j
⊗τ3) . (1 ⊗τ1) + (1 ⊗τ1) . (γ (n)
j
⊗τ3)
= γ (n)
j
⊗{τ3, τ1} = 0
This iterative construction yields for SO(2n) the γ matrices
γ2k−1 = 1 ⊗1 ⊗. . . ⊗1 ⊗τ1 ⊗τ3 ⊗τ3 ⊗. . . ⊗τ3
(5)
and
γ2k = 1 ⊗1 ⊗. . . ⊗1 ⊗τ2 ⊗τ3 ⊗τ3 ⊗. . . ⊗τ3
(6)
with 1 appearing k −1 times and τ3 appearing n −k times. The γ ’s are evidently 2n by 2n
matrices. When and if you feel confused at any point in this discussion you should work
things out explicitly for SO(4), SO(6), and so on.
In analogy with the Lorentz group, we define 2n(2n −1)/2 = n(2n −1) hermitean
matrices
σij ≡i
2[γi, γj]
(7)
Note that σij is equal to iγiγj for i ̸= j and vanishes for i = j. The commutation of the σ’s
with each other is thus easy to work out. For example,
[σ12, σ23] = −[γ1γ2, γ2γ3] = −γ1γ2γ2γ3 + γ2γ3γ1γ2 = −[γ1, γ3] = 2iσ13
Roughly speaking, the γ2’s in σ12 and σ23 knock each other out. Thus, you see that the
1
2σij’s satisfy the same commutation relations as the generators J ij’s of SO(2n) (as given
in appendix B). The 1
2σij’s represent the J ij’s.
As 2n by 2n matrices, the σ’s act on an object ψ with 2n components that we will call the
spinor ψ. Consider the unitary transformation ψ →eiωijσijψ with ωij = −ωji a set of real
numbers. Then
ψ†γkψ →ψ†e−iωijσijγkeiωijσijψ = ψ†γkψ −iωijψ†[σij , γk]ψ + . . .
for ωij infinitesimal. Using the Clifford algebra we easily evaluate the commutator as
[σij , γk] = −2i(δikγj −δjkγi). (If k is not equal to either i or j then γk clearly commutes

VII.7. SO(10) Unification | 423
with σij , and if k is equal to either i or j , then we use γ 2
k = 1.) We see that the set of objects
vk ≡ψ†γkψ, k = 1, . . . , 2n transforms as a vector in 2n-dimensional space, with 4ωij the
infinitesimal rotation angle in the ij plane:
vk →vk −2(ωkjvj −ωikvi) = vk −4ωkjvj
(8)
(in complete analogy to ¯ψγ μψ transforming as a vector under the Lorentz group.) This
gives an alternative proof that 1
2σij represents the generators of SO(2n).
We define the matrix γ FIVE = (−i)nγ1γ2 . . . γ2n, which in the basis we are using has the
explicit form
γ FIVE = τ3 ⊗τ3 ⊗. . . ⊗τ3
(9)
with τ3 appearing n times. By analogy with the Lorentz group we define the “left handed”
spinor ψL ≡1
2(1 −γ FIVE)ψ and the “right handed” spinor ψR ≡1
2(1 + γ FIVE)ψ, such that
γ FIVEψL = −ψL and γ FIVEψR = ψR. Under ψ →eiωijσijψ, we have ψL →eiωijσijψL and
ψR →eiωijσijψR since γ FIVE commutes with σij. The projection into left and right handed
spinors cut the number of components into halves and thus we arrive at the important
conclusion that the two irreducible spinor representations of SO(2n) have dimension 2n−1.
(Convince yourself that the representation cannot be reduced further.) In particular, the
spinor representation of SO(10) is 210/2−1 = 24 = 16−dimensional. We will see that the
5∗and 10 of SU(5) can be fit into the 16 of SO(10).
Embedding unitary groups into orthogonal groups
The unitary group SU(5) can be naturally embedded into the orthogonal group SO(10).
In fact, I will now show you that embedding SU(n) into SO(2n) is as easy as z = x + iy.
Consider
the
2n-dimensional
real
vectors
x = (x1, . . . , xn, y1, . . . , yn)
and
x′ = (x′
1, . . . , x′
n, y′
1, . . . , y′
n). By definition, SO(2n) consists of linear transformations
on these two real vectors leaving their scalar product x′x = n
j=1(x′
jxj + y′
jyj) invariant.
Now out of these two real vectors we can construct two n-dimensional complex vectors
z = (x1 + iy1, . . . , xn + iyn) and z′ = (x′
1 + iy′
1, . . . , x′
n + iy′
n). The group U(n) consists of
transformations on the two n-dimensional complex vectors z and z′ leaving invariant their
scalar product
(z′)∗z =
n

j=1
(x′
j + iy′
j)∗(xj + iyj)
=
n

j=1
(x′
jxj + y′
jyj) + i
n

j=1
(x′
jyj −y′
jxj)
In other words, SO(2n) leaves n
j=1(x′
jxj + y′
jyj) invariant, but U(n) consists of the
subset of those transformations in SO(2n) that leave invariant not only n
j=1(x′
jxj + y′
jyj)
but also n
j=1(x′
jyj −y′
jxj).
Now that we understand this natural embedding of U(n) into SO(2n), we see that the
defining or vector representation of SO(2n), which we will call simply 2n, decomposes

424 | VII. Grand Unification
upon restriction to U(n) into the two defining representations of U(n), n and n∗; thus
2n →n ⊕n∗
(10)
In other words, (x1, . . . , xn, y1, . . . , yn) can be written as (x1 + iy1, . . . , xn + iyn) and
(x1 −iy1, . . . , xn −iyn) Note that this is the analog of (VII.5.4) indicating that the defining
representation of SU(5) decomposes into representations of SU(3) ⊗SU(2) ⊗U(1):
5 →(3∗, 1, 1
3) ⊕(1, 2, −1
2).
(11)
Given the decomposition law (10), we can now figure out how other representations of
SO(2n) decompose when restricted to the natural subgroup U(n). The tensor representa-
tions of SO(2n) are easy, since they are constructed out of the vector representation. [This is
precisely what we did in going from (VII.5.4) to (VII.5.7, 8, and 9).] For example, the adjoint
representation of SO(2n), which has dimension 2n(2n −1)/2 = n(2n −1), transforms as
an antisymmetric 2-index tensor 2n ⊗A 2n and so decomposes into
2n ⊗A 2n →(n ⊕n∗) ⊗A (n ⊕n∗)
(12)
according to (10). The antisymmetric product ⊗A on the right hand side is, of course, to
be evaluated within U(n). For instance, n ⊗A n is the n(n −1)/2 representation of U(n).
In this way, we see that
n(2n −1) →n2 −1 (the adjoint)
⊕1 (the singlet)
⊕n(n −1)/2
⊕(n(n −1)/2)∗
(13)
As a check, the total dimension of the representations of U(n) on the right hand side adds
up to (n2 −1) + 1 + 2n(n −1)/2 = n(2n −1). In particular, for SO(10) ⊃SU(5), we have
45 →24 ⊕1 ⊕10 ⊕10∗and of course 24 + 1 + 10 + 10 = 45.
Decomposing the spinor
It is more difficult to figure out how the spinor representation of SO(2n) decompose
upon restriction to U(n). I give here a heuristic argument that satisfies most physicists,
but certainly not mathematicians. I will just do SO(10) ⊃SU(5) and let you work out
the general case. The question is how the 16 falls apart. Just from numerology and from
knowing the dimensions of the smaller representations of SU(5) (1, 5, 10, 15) we see there
are only so many possibilities, some of them rather unlikely, for example, the 16 falling
apart into 16 1’s.
Picture the spinor 16 of SO(10) breaking up into a bunch of representations of SU(5).
By definition, the 45 generators of SO(10) scramble all these representations together. Let
us ask what the various pieces of 45, namely 24 ⊕1⊕10 ⊕10∗, do to these representations.
The 24 transform each of the representations of SU(5) into itself, of course, because they
are the 24 generators of SU(5) and that is what generators were born to do. The generator

VII.7. SO(10) Unification | 425
1 can only multiply each of these representations by a real number. (In other words, the
corresponding group element multiplies each of the representations by a phase factor.)
What does the 10, which as you recall from chapter VII.5 is represented as an antisym-
metric tensor with two upper indices and hence also known as [2], do to these represen-
tations? Suppose the bunch of representations that S breaks up into contains the singlet
[0] = 1of SU(5). The 10 = [2]acting on [0]gives the [2] = 10. (Almost too obvious for words!
An antisymmetric tensor of two indices combined with a tensor with no indices is an anti-
symmetric tensor of two indices.) What about 10 = [2] acting on [2]? The result is a tensor
with four upper indices. It certainly contains the [4], which is equivalent to [1]∗= 5∗. But
look, 1 ⊕10 ⊕5∗already add up to 16. Thus, we have accounted for everybody. There can’t
be more. So we conclude
S+ →[0] ⊕[2] ⊕[4] = 1 ⊕10 ⊕5∗
(14)
The 5∗and the 10 of SU(5) fit inside the 16+ of SO(10)!
We will learn later that the two spinor representations of SO(10) are conjugate to each
other. Indeed, you may have noticed that I snuck a superscript plus on the letter S. The
conjugate spinor S−breaks up into the conjugate of the representations in (14):
S−→[1] ⊕[3] ⊕[5] = 5 ⊕10∗⊕1∗
(15)
The long lost antineutrino
The fit would be perfect if we introduce one more field transforming as a 1, that is, a singlet
under SU(5) and hence a fortiori a singlet under SU(3) ⊗SU(2) ⊗U(1). In other words,
this field does not participate in the strong, weak, and electromagnetic interactions, or in
plain English, it describes a lepton with no electric charge and is not involved in the known
weak interaction. Thus, this field can be identified as the “long lost” antineutrino field νc
L.
This guy does not listen to any of the known gauge bosons.
Recall that we are using a convention in which all fermion fields are left handed, and
hence we have written νc
L. By a conjugate transformation, as explained earlier, this is
equivalent to the right handed neutrino field νR.
Since νR is an SU(5) singlet, we can give it a Majorana mass M without breaking SU(5).
Hence we expect M to be larger than or of the same order of magnitude as the mass scale
at which SU(5) is broken, which as we saw in chapter VII.5 is much higher than the mass
scales that have been explored experimentally. This explains why νR has not been seen.
On the other hand, with the presence of νR we can have a Dirac mass term m(¯νLνR +
h.c.). Since this term breaks SU(2) ⊗U(1) just like the mass terms for the quarks and
leptons we know, we expect m to be of the same order of magnitude2 as the known quark
and lepton masses (which for reasons unknown span an enormous range).
2 Explicitly, with νR now available we can add to the SU(2) ⊗U(1) theory of chapter VII.2 the term f ′ ˜ϕ¯νRψL,
where ˜ϕ ≡τ 2ϕ†. In the absence of any indication to the contrary, we might suppose that f ′ is of the same order
of magntiude as the coupling f that leads to the electron mass.

426 | VII. Grand Unification
Thus, in the space spanned by (ν, νc) we have the (Majorana) mass matrix
M =
 0
m
m
M

(16)
with M ≫m. Since the trace and determinant of M are M and −m2, respectively, M has a
large eigenvalue ∼M and a small eigenvalue ∼m2/M. A tiny mass ∼m2/M, suppressed
relative to the usual quark and lepton masses by the factor m/M, is naturally generated
for the (observed) left handed neutrino. This rather attractive scenario, known as the
seesaw mechanism for obvious reason, was discovered independently by Minkowski and
by Glashow, and somewhat later by Yanagida and by Gell-Mann, Ramond, and Slansky.
Again, the tight fit of the 5∗and the 10 of SU(5) inside the 16+ of SO(10) has convinced
many physicists that it is surely right.
A binary code for the world
Given the product form of the γ matrices in (5) and (6), and hence of σij , we can write the
states of the spinor representations as
|ε1ε2 . . . εn⟩
(17)
where each of the ε’s takes on the values ±1. For example, for n = 1, τ1| + ⟩= | −⟩and
τ1| −⟩= | + ⟩, while τ2| + ⟩= i | −⟩and τ2| −⟩= −i | + ⟩. From (9) we see that
γ FIVE|ε1ε2 . . . εn⟩= (n
j=1εj)|ε1ε2 . . . εn⟩
(18)
The right handed spinor S+ consists of those states |ε1ε2 . . . εn⟩with (n
j=1εj) = +1, and
the left handed spinor S−those states with (n
j=1εj) = −1. Indeed, the spinor represen-
tations have dimension 2n−1.
Thus, in SO(10) unification the fundamental quarks and leptons are described by a five-
bit binary code, with states such as | + + −−+ ⟩and | −+ −−−⟩. Personally, I find
this a rather pleasing picture of the world.
Let us work out the states explicitly. This also gives me a chance to make sure that
you understand the group theory presented in this chapter. Start with the much simpler
case of SO(4). The spinor S+ consists of | + +⟩and | −−⟩while the spinor S−consists
of | + −⟩and | −+⟩. As discussed in chapter II.3, SO(4) contains two distinct SU(2)
subgroups. Removing a few factors of i from the discussion in chapter II.3 we see that
the third generator of SU(2), call it σ3, can be taken to be either σ12 −σ34 or σ12 + σ34.
The two choices correspond to the two distinct SU(2) subgroups. We choose (arbitrarily)
σ3 = 1
2(σ12 −σ34). From (5) and (6) we have σ12 = iγ1γ2 = i(τ1 ⊗τ3)(τ2 ⊗τ3) = −τ3 ⊗1and
σ34 = −1 ⊗τ3, and so σ3 = 1
2(−τ3 ⊗1 + 1 ⊗τ3). To figure out how the four states | + +⟩,
| −−⟩, | + −⟩, and | −+⟩transform under our chosen SU(2), let us act on them with σ3.
For example,
σ3| + +⟩= 1
2(−τ3 ⊗1 + 1 ⊗τ3)| + +⟩= 1
2(−1 + 1)| + +⟩= 0

VII.7. SO(10) Unification | 427
and
σ3| −+⟩= 1
2(−τ3 ⊗1 + 1 ⊗τ3)| −+⟩= 1
2(1 + 1)| −+⟩= | −+⟩
Aha, under SU(2) | + +⟩and | −−⟩are two singlets while | + −⟩and | −+⟩make up a
doublet.
Note that this is consistent with the generalization of (14) and (15), namely that upon
the restriction of SO(2n) to U(n) the spinors decompose as
S+ →[0] ⊕[2] ⊕. . .
(19)
and
S−→[1] ⊕[3] ⊕. . .
(20)
I have not indicated the end of the two sequences: A moment’s reflection indicates that it
depends on whether n is even or odd. In our example, n = 2,and thus 2+ →[0] ⊕[2] = 1⊕1
and 2−→[1] = 2. Similarly, for n = 3, upon the restriction of SO(6) to U(3), 4+ →
[0] ⊕[2] = 1 ⊕3∗and 4−→[1] ⊕[3] = 3 ⊕1. (Our choice of which triplet representation
of U(3) to call 3 or 3∗is made to conform to common usage, as we will see presently.)
We are now ready to figure out the identity of each of the 16 states such as | + + −−+ ⟩
in SO(10) unification. First of all, (18) tells us that under the subgroup SO(4) ⊗SO(6) of
SO(10) the spinor 16+ decomposes as (since 5
j=1εj = +1 implies ε1ε2 = ε3ε4ε5)
16+ →(2+, 4+) ⊕(2−, 4−)
(21)
We identify the natural SU(2) subgroup of SO(4) as the SU(2) of the electroweak interac-
tion and the natural SU(3) subgroup of SO(6) as the color SU(3) of the strong interaction.
Thus, according to the preceding discussion, (2+, 4+) are the SU(2) singlets of the stan-
dard U(1) ⊗SU(2) ⊗SU(3) model, while (2−, 4−) are the SU(2) doublets. Here is the
lineup (all fields being left handed as usual):
SU(2) doublets:
ν = | −+ −−−⟩
e−= | + −−−−⟩
u = | −+ + + −⟩, | −+ + −+ ⟩, and | −+ −+ + ⟩
d = | + −+ + −⟩, | + −+ −+ ⟩, and | + −−+ + ⟩
SU(2) singlets:
νc = | + + + + + ⟩
e+ = | −−+ + + ⟩
uc = | + + + −−⟩, | + + −+ −⟩, and | + + −−+ ⟩
dc = | −−+ −−⟩, | −−−+ −⟩, and | −−−−+ ⟩.
I assure you that this is a lot of fun to work out and I urge you to reconstruct this
table without looking at it. Here are a few hints if you need help. From our discussion

428 | VII. Grand Unification
of SU(2) I know that ν = | −+ε3ε4ε5⟩and e−= | + −ε3ε4ε5⟩, but how do I know that
ε3 = ε4 = ε5 = −1? First, I know that ε3ε4ε5 = −1. I also know that 4−→3 ⊕1 upon
restricting SO(6) to color SU(3). Well, of the four states | −−−⟩, | + + −⟩, | + −+ ⟩,
and | −+ + ⟩the “odd man out” is clearly | −−−⟩. By the same heuristic argument,
among the 16 possible states | + + + + + ⟩is the “odd man out” and so must be νc.
There are lots of consistency checks. For example, once I identify ν = | −+ −−−⟩,
e−= | + −−−−⟩, and νc = | + + + + + ⟩, I can figure out the electric charge Q,
which, since it transforms as a singlet under color SU(3), must have the value Q =
aε1 + bε2 + c(ε3 + ε4 + ε5) when acting on the state |ε1ε2ε3ε4ε5⟩. The constants a, b, and
c can be determined from the three equations Q(ν) = −a + b −3c = 0, Q(e−) = −1, and
Q(νc) = 0. Thus, Q = −1
2ε1 + 1
6(ε3 + ε4 + ε5).
Living in the computer age, I find it intriguing that the fundamental constituents
of matter are coded by five bits. You can tell your condensed matter colleagues that
their beloved electron is composed of the binary strings + −−−−and −−+ + +. An
intriguing possibility3 suggests itself, that quarks and leptons may be composed of five
different species of fundamental fermionic objects. We construct composites, writing a
+ if that species is present, and a −if it is absent. For example, from the expression for
Q given above, we see that species 1 carries electric charge −1
2 , species 2 is neutral, and
species 3, 4, and 5 carry charge 1
6. A more or less concrete model can even be imagined by
binding these fundamental fermionic objects to a magnetic monopole.
I emphasize that particles transforming in 16−, such as | + −+ + + ⟩, have not been
observed experimentally.
A speculation on the origin of families
One of the great unsolved puzzles in particle physics is the family problem. Why do quarks
and leptons come in three generations {νe, e, u, d}, {νμ, μ, c, s}, and {ντ , τ , t, b}? The way
we incorporate this experimental fact into our present day theory can only be described
as pathetic: We repeat the fermionic sector of the Lagrangian three times without any
understanding whatsoever. Three generations living together gives rise to a nagging family
problem.
Our binary code view of the world suggests a wildly speculative (perhaps too speculative
to mention in a textbook?) approach to the family problem: We add more bits. To me,
a reasonable possibility is to “hyperunify” into an SO(18) theory, putting all fermions
into a single spinorial representation S+ = 256+, which upon the breaking of SO(18) to
SO(10) ⊗SO(8) decomposes as
256+ →(16+, 8+) ⊕(16−, 8−)
(22)
We have a lot of 16+’s. Unhappily, we see that group theory [see also (21)] dictates that we
also get a bunch of unwanted 16−’s. One suggestion is that Nature might repeat the trick
3 For further details, see F. Wilczek and A. Zee, Phys. Rev. D25: 553, 1982, Section IV.

VII.7. SO(10) Unification | 429
She uses with color SU(3), whose strong force confines fields that are not color singlets
(chapter VII.3). Interestingly, we can exploit a striking feature of SO(8), which some people
regard as the most beautiful of all groups. In particular, the two spinorial representations
8± have the same dimension as the vectorial representation 8v (the equation 2n−1 = 2n
has the unique solution n = 4). There is a transformation that cyclically rotates these three
representations 8+, 8−, and 8v into each other (in the jargon, the group SO(8) admits an
outer automorphism). Thus, there exists a subgroup SO(5) of SO(8) such that when we
break SO(8) into that SO(5) 8+ behaves like 8v while 8−behaves like a spinor, namely
8+ →5 ⊕1 ⊕1 ⊕1
and
8−→4 ⊕4∗
(23)
If we call this4 SO(5) hypercolor and assumes that the strong force associated with it con-
fines all fields that are not hypercolor singlets, then only three 16+’s remain! Unfortunately,
as the relevant physics occurs in the energy regime above grand unification, our knowl-
edge of the dynamics of symmetry breaking is far too paltry for us to make any further
statements.
Charge conjugation
The product ⊗notation we use here allows us to construct the conjugation matrix C explic-
itly. By definition C−1σ ∗
ijC = −σij (so that C changes eiθijσij into its complex conjugate.)
From (2), (3), and (4) we see that we can construct
C(n+1) = {
C(n) ⊗τ1
if
n odd
C(n) ⊗τ2
if
n even
(24)
You can check that this gives C−1γ ∗
j C = (−1)nγj and hence the desired result.
Explicitly, C is a direct product of an alternating sequence of τ1 and τ2 and so we deduce
an important property. Acting on |ε1ε2 . . . εn⟩, C flips the sign of all the ε’s. Thus C
changes the sign of (n
j=1εj) for n odd, and does not for n even. For n odd, the two
spinor representations S+ and S−are conjugates of each other, while for n even, they
are conjugates of themselves, or in other words, they are real. This can also be seen
directly from C−1γ FIVEC = (−1)nγ FIVE. You can check this with all the explicit examples
we have encountered: SO(2), SO(4), SO(6), SO(8), SO(10), and SO(18). See also
exercise VII.7.3.
Anomalies
What about anomalies in SO(2n) grand unification? According to the discussion in chap-
ter VII.5 we have to evaluate Aijklmn ≡tr(J ij {J kl, J mn}) over the fermion representation.
4 The reader savvy with group theory would recognize that SO(5) is isomorphic with the symplectic group
Sp(4) and that the Dynkin diagram of SO(8) is the most symmetric of all.

430 | VII. Grand Unification
Applying an SO(2n) transformation J ij →OT J ijO we see easily that Aijklmn is an invari-
ant tensor. Can we construct an invariant 6-index tensor with the appropriate symmetry
properties (e.g., Aijklmn = −Ajiklmn) in SO(2n)? We can’t, except in SO(6), for which we
have εijklmn. Thus, Aijklmn vanishes except in SO(6), where it is proportional to εijklmn.
An elegant one line proof that any grand unified theory based on SO(2n) for n ̸= 3 is free
from anomaly!
The cancellation of the anomaly between 5∗and 10 at the end of chapter VII.5 doesn’t
seem so miraculous any more. Miracles tend to fade away as we gain deeper understanding.
Amusingly, by discussing a physics question, namely whether a gauge theory is renor-
malizable or not, we have discovered a mathematical fact. What is so special about SO(6)?
See exercise VII.7.5.
Exercises
VII.7.1
Work out the Clifford algebra in d-dimensional space for d odd.
VII.7.2 Work out the Clifford algebra in d-dimensional Minkowski space.
VII.7.3 Show that the Clifford algebra for d = 4k and for d = 4k + 2 have somewhat different properties. (If you
need help with this and the two preceding exercises, look up F. Wilczek and A. Zee, Phys. Rev. D25: 553,
1982.)
VII.7.4 Discuss the Higgs sector of the SO(10). What do you need to give mass to the quarks and leptons?
VII.7.5
The group SO(6) has 6(6 −1)/2 = 15 generators. Notice that the group SU(4) also has 42 −1 = 15
generators. Substantiate your suspicion that SO(6) and SU(4) are isomorphic. Identify some low
dimensional representations.
VII.7.6 Show that (unfortunately) the number of families we get in SO(18) depends on which subgroup of SO(8)
we take to be hypercolor.
VII.7.7 If you want to grow up to be a string theorist, you need to be familiar with the Dirac equation in various
dimensions but especially in 10. As a warm up, study the Dirac equation in 2-dimensional spacetime.
Then proceed to study the Dirac equation in 10-dimensional spacetime.

Part VIII
Gravity and Beyond

This page intentionally left blank

VIII.1
Gravity as a Field Theory
and the Kaluza-Klein Picture
Including gravity
Field theory texts written a generation ago typically do not even mention gravity. The
gravitational interaction, being so much weaker than the other three interactions, was
simply not included in the education of particle physicists. The situation has changed with
a vengeance: The main drive of theoretical high energy physics today is the unification of
gravity with the other three interactions, with string theory the main candidate for a unified
theory.
From a course on general relativity you would have learned about the Einstein-Hilbert
action for gravity
S =
1
16πG

d4x√−gR ≡

d4x√−gM2
PR
(1)
where g = det gμν denotes the determinant of the curved metric gμν of spacetime, R is
the scalar curvature, and G is Newton’s constant. Let me remind you that the Riemann
curvature tensor
Rλ
μνκ = ∂νλ
μκ −∂κλ
μν + σ
μκλ
νσ −σ
μνλ
κσ
(2)
is constructed out of the Riemann-Christoffel symbol (recall chapter I.11):
λ
μν = 1
2gλρ(∂νgρμ + ∂μgρν −∂ρgμν)
(3)
The Ricci tensor is defined by Rμκ = Rν
μνκ and the scalar curvature by R = gμνRμν. Varying
S gives us1 the Einstein field equation
Rμν −1
2gμνR = −8πGTμν
(4)
The Einstein-Hilbert action is uniquely determined if we require the action to be coor-
dinate invariant and to involve two powers of spacetime derivative. As you can see from
1 See, e.g., S. Weinberg, Gravitation and Cosmology, p. 364.

434 | VIII. Gravity and Beyond
(2) and (3) the scalar curvature R involves two powers of derivative and the dimensionless
field gμν and thus has mass dimension 2. Hence G−1 must have mass dimension 2. The
second form in (1) emphasizes this point and is often preferred in modern work on grav-
ity. (The modified Planck mass MP ≡1/
√
16πG differs from the usual Planck mass by a
trivial factor, much like the relation between h and ℏ.)
The theory sprang from Einstein’s profound intuition regarding the curvature of space-
time and is manifestly formulated in terms of geometric concepts. In many textbooks,
Einstein’s theory is developed, and rightly so, in purely geometric terms.
On the other hand, as I hinted back in chapter I.6, gravity can be treated on the same
footing as the other interactions. After all, the graviton may be regarded as just another
elementary particle like the photon. The action (1), however, does not look anything like
the field theories we have studied thus far. I will now show you that in fact it does have the
same kind of structure.
Gravity as a field theory
Let us write gμν = ημν + hμν, where ημν denotes the flat Minkowski metric and hμν the
deviation from the flat metric. Expand the action in powers of hμν. In order not to drown
in a sea of Lorentz indices, let us suppress them for a first go-around. Merely from the
fact that the scalar curvature R involves two derivatives ∂in its definition, we see that the
expansion must have the schematic form
S =

d4x
1
16πG(∂h∂h + h∂h∂h + h2∂h∂h + . . .)
(5)
after dropping total divergences. As I remarked in chapter I.11, the field hμν(x) describes
a graviton in flat space and is to be treated like any other field. The first term ∂h∂h, which
governs how the graviton propagates, is conceptually no different than the first term in the
action for a scalar field ∂ϕ∂ϕ or for the photon field ∂A∂A. The terms cubic and higher in
h determine the interaction of the graviton with itself.
The Einstein-Hilbert action in the weak field expansion is structurally reminiscent of the
Yang-Mills action, which may be written in schematic form as S =

d4x(1/g2)(∂A∂A +
A2∂A + A4). As I explained in chapter IV.5, we understand the self interaction of the Yang-
Mills bosons physically: The bosons themselves carry the charge to which they couple.
We can understand the self interaction of the graviton similarly: The graviton couples to
anything carrying energy and momentum, and it certainly carries energy and momentum.
In contrast, the photon does not couple to itself.
We say that Yang-Mills and Einstein theories are nonlinear, while Maxwell theory is
linear. The former are hard, the latter easy.
But while the Yang-Mills action terminates, the Einstein-Hilbert action, because of the
presence of √−g and of the inverse of gμν, is an infinite series in the graviton field hμν.
The other major difference is that while Yang-Mills theory is renormalizable, gravity is
notoriously nonrenormalizable, as we argued by dimensional analysis in chapter III.2. We
are now in a position to see this explicitly. Consider the self energy correction to the graviton

VIII.1. Gravity as a Field Theory | 435
(a)
(b)
Figure VIII.1.1
propagator shown in figure VIII.1.1a. We see from the second term in (5) that the three-
graviton coupling involves two powers of momentum. Thus the Feynman integral goes as

d4k(kkkk/k2k2), with four powers of k in the numerator from the two vertices and four
powers in the denominator from the propagators. Taking out two powers of momentum to
extract the coefficient of ∂h∂h, we see that the correction to 1/G is quadratically divergent.
Because of the explicit powers of momentum in the coupling, the divergence gets worse
and worse as we go to higher and higher order. Compare figure VIII.1.1b to 1a: We have
three more propagators, worth ∼1/k6, and one more loop integration

d4k, but two more
vertices ∼k4. The degree of divergence goes up by 2. Of course we already knew all this
by dimensional analysis.
As mentioned in chapter I.11 the fundamental definition
T μν(x) = −
2
√−g
δSM
δgμν(x)
tells us that coupling of the graviton to matter (in the weak field limit) can be included by
adding the term
−

d4x 1
2hμνT μν
(6)
to the action, where T μν stands for the (flat spacetime) stress-energy tensor of all the matter
fields of the world, a matter field being any field that is not the graviton field. Thus, with
the inclusion of matter (5) is modified schematically2 to
S =

d4x[
1
16πG(∂h∂h + h∂h∂h + h2∂h∂h + . . .) + (hT + . . .)]
(7)
In chapter IV.5 I noted that we can bring Yang-Mills theory into the same convention
commonly used in Maxwell theory by a trivial rescaling A →gA. Similarly, we can also
bring Einstein theory into the same convention by rescaling the graviton field hμν →
√
Ghμν so that the action becomes (to ease writing we absorb 16π into G whenever we
feel like it)
S =

d4x (∂h∂h +
√
Gh∂h∂h + Gh2∂h∂h + . . . +
√
GhT )
2 If this is to represent an expansion of S in powers of h, then strictly speaking, if we display the terms cubic
and quartic in the Einstein-Hilbert action, we should also display the contribution coming from the terms of
higher order in h contained in T μν(x) = −(2/√−g)δSM/δgμν(x).

436 | VIII. Gravity and Beyond
We see explicitly that
√
16πG = 1/MP measures the strength of the graviton coupling to
itself and to all other fields. Once again, the enormity of MP (compared to the scale of the
strong interaction, say) indicates the feebleness of gravity.
Here we expanded gμν around a flat metric but we could just as well expand gμν =
¯gμν + hμν, with ¯gμν a curved metric, that of a black hole (see chapter V.7) for instance.
Determining the weak field action
After this index free survey we are ready to tackle the indices. We would like to determine
the first term ∂h∂h in (7) so that we can obtain the graviton propagator. Thus, we have to
expand the action S ≡M2
P

d4x√−ggμνRμν up to and including order h2. From (2) and
(3) we see that the Ricci tensor Rμν starts in O(h) so that it suffices to evaluate √−ggμν to
O(h). That’s easy: As we have already seen in chapter I.11, g = −[1 + ημνhμν + O(h2)]and
gμν = ημν −hμν + O(h2) so that √−ggμν = ημν −hμν + 1
2ημνh + O(h2), where we have
defined h ≡ημνhμν. We now must calculate Rμν to O(h2), a straightforward but tedious
task starting from (2) and (3).
In line with the spirit of this book, which is to avoid tedious calculation whenever
possible, I will now show you how to get around this. We invoke symmetry considerations!
Under a general coordinate transformation xμ →x′μ = xμ −εμ(x) the metric changes
to g′μν = (∂x′μ/∂xσ)(∂x′ν/∂xτ)gστ. Plugging in gμν = ημν −hμν + . . ., lowering the in-
dices (with ημν to this order), and using (∂x′μ/∂xσ) = δμ
σ −∂σεμ, we find, treating ∂μεν as
of the same order as hμν:
h′
μν = hμν + ∂μεν + ∂νεμ
(8)
Note the structural similarity to the electromagnetic gauge transformation A′
μ = Aμ −
∂μ. Very nice! We will explore the sense in which gravity can be regarded as a gauge
theory in more detail later.
We are looking for the terms in the action quadratic in h and quadratic in ∂. Lorentz
invariance tells us that there are four possible terms (To see this, first write down terms
with the indices on the two ∂matching, then the terms with the index on a ∂matching an
index on an h, and so on):
S =

d4x(a∂λhμν∂λhμν + b∂λhμ
μ∂λhν
ν + c∂λhλν∂μhμν + dhλ
λ∂μ∂νhμν)
with four unknown constants a, b, c, and d. Now vary S with δhμν = ∂μεν + ∂νεμ, inte-
grating by parts freely. For example,
δ(∂λhμν∂λhμν) = 2[∂λ(2∂μεν)](∂λhμν)“ = ”4εν∂2∂μhμν
Since there are three objects linear in h, linear in ε, and cubic in ∂(namely εν∂2∂νh and
εν∂ν∂λ∂μhλμ in addition to the one already shown) the condition δS = 0 gives three equa-
tions, just enough to fix the action up to an overall constant, corresponding to Newton’s
constant. The invariant combination turns out to be
I ≡1
2∂λhμν∂λhμν −1
2∂λhμ
μ∂λhν
ν −∂λhλν∂μhμν + ∂νhλ
λ∂μhμν
(9)

VIII.1. Gravity as a Field Theory | 437
Thus, even if we had never heard of the Einstein-Hilbert action we could still determine
the action for gravity in the weak field limit by requiring that the action be invariant under
the transformation (8). This is hardly surprising since coordinate invariance determines
the Einstein-Hilbert action. Still, it is nice to construct gravity “from scratch.”
Referring to (6), we can now write the weak field expansion of S as
Swfg =

d4x

1
32πGI −1
2hμνT μν

without having to expand R to O(h2). The coefficient of I is fixed by the requirement that
we reproduce the usual Newtonian gravity (see later).
The graviton propagator
As we anticipated in (5) the action Swfg indeed has the same quadratic structure of all
the field theories we have studied, and so as usual the graviton propagator is just the
inverse of a differential operator. But just as in Maxwell and Yang-Mills theories the relevant
differential operator in Einstein-Hilbert theory does not have an inverse because of the
“gauge invariance” in (8).
No problem. We have already developed the Faddeev-Popov method to deal with this
difficulty. In fact, for my limited purposes here, to derive the graviton propagator in flat
spacetime, I don’t even need the full-blown Faddeev-Popov formalism with ghosts and all.3
Indeed, recall from chapter III.4 that for the Feynman gauge (ξ = 1) we simply add (∂A)2
to the invariant
1
2F μνFμν = ∂μAν(∂μAν −∂νAμ)“ = ” −Aμημν∂2Aν −(∂A)2
thus canceling the last term. Inverting the differential operator −ημν∂2 we obtain the
photon propagator in the Feynman gauge −iημν/k2. We play the same “trick” for gravity.
After staring at
I = 1
2∂λhμν∂λhμν −1
2∂λhμ
μ∂λhν
ν −∂λhλν∂μhμν + ∂νhλ
λ∂μhμν
for a while, we see that by adding (∂μhμν −1
2∂νhλ
λ)2 we can knock off the last two terms in
I so that Swfg effectively becomes
Swfg =

d4x 1
2

1
32πG

∂λhμν∂λhμν −1
2∂λh∂λh

−hμνT μν
 
(10)
In other words, the freedom in choosing hμν in (8) allows us to impose the so-called
harmonic gauge condition
∂μhμ
ν = 1
2∂νhλ
λ
(11)
(the linearized version of ∂μ(√−ggμν) = 0.)
3 This is because (8) does not involve the field hμν, just as in the Maxwell case but unlike the Yang-Mills
case. Since we do not intend to calculate loop diagrams in quantum gravity, we do not need the full power of the
Faddeev-Popov method.

438 | VIII. Gravity and Beyond
Writing (10) in the form
S =
1
32πG

d4x

hμνKμν;λσ(−∂2)hλσ + O(h3)

we see that we have to invert the matrix
Kμν;λσ ≡1
2(ημληνσ + ημσηνλ −ημνηλσ)
regarding μν and λσ as the two indices. Note that we have to maintain the symmetry of
hμν. In other words, we are dealing with matrices acting in a linear space spanned by
symmetric two-index tensors. Thus, the identity matrix is actually
Iμν;λσ ≡1
2(ημληνσ + ημσηνλ)
You can check that Kμν;λσKλσ
;ρω = Iμν;ρω so that K−1 = K. Thus, in the harmonic gauge
the graviton propagator in flat spacetime is given by (scaling out Newton’s constant)
Dμν,λσ(k) = 1
2
ημληνσ + ημσηνλ −ημνηλσ
k2 + iε
(12)
Newton from Einstein
Varying (10) with respect to hμν we obtain the Euler-Lagrange equation of motion4
1
32πG(−2∂2hμν + ημν∂2h) −Tμν = 0. Taking the trace, we find ∂2h = 16πGT (with T ≡
ημνT μν) and so we obtain5
∂2hμν = −16πG(Tμν −1
2ημνT )
(13)
In the static limit, T00 is the dominant component6 of the stress-energy tensor and (13)
reduces to ⃗∇2φ = 4πGT00 upon recalling from chapter I.5 that the Newtonian gravitational
potential φ ≡1
2h00. We have just derived Poisson’s equation for φ.
Incidentally, this suggests another way of avoiding the tedious task of expanding the
Einstein-Hilbert action (and hence R) to O(h2) if you are willing to accept the Einstein
field equation (4) as given. You need expand Rμν only to O(h) to obtain (13) from (4), and
from (13) you can reconstruct the action to O(h2). Indeed, from (2) and (3) you easily get
Rμν = 1
2(−∂2hμν + ∂μ∂λhλ
ν + ∂ν∂λhλ
μ −∂μ∂νhλ
λ) + O(h2) →−1
2∂2hμν + O(h2)
with the further simplification in harmonic gauge. But this is not quite fair since con-
siderable technology7 (Palatini identity and all the rest) is needed to derive (4) from (1).
4 Note that the flat spacetime energy momentum conservation ∂μTμν = 0 together with the equation of motion
implies ∂2(∂μhμν −1
2∂νh) = 0.
5 Thus, the Einstein equation in vacuum Rμν = 0 reduces to ∂2hμν = 0; hence the name “harmonic.”
6 Note that, in contrast to T00, h00 does not dominate the other components of hμν.
7 See S. Weinberg, Gravitation and Cosmology, pp. 290 and 364.

VIII.1. Gravity as a Field Theory | 439
Einstein’s theory and the deflection of light
Consider two particles with stress-energy tensors T μν
(1) and T μν
(2) respectively interacting via
the exchange of a graviton. The scattering amplitude is then (up to some overall constant
not essential for our purposes here) given by
GT μν
(1) Dμν,λσ(k)T λσ
(2) = G
2k2(2T μν
(1) T(2)μν −T(1)T(2))
For nonrelativistic matter T 00 is much larger than the other components T 0j and T ij (as
I have just remarked), so the scattering amplitude between two lumps of nonrelativistic
matter (say, the earth and you) is proportional to
G
2k2(2T 00
(1)T 00
(2) −T 00
(1)T 00
(2)) = G
2k2T 00
(1)T 00
(2)
As explained way back in chapters I.4 and I.5, the interaction potential is given by the
Fourier transform of the scattering amplitude, namely
G
 
d3xd3x′T (1)00(x)T (2)00(x′)

d3kei⃗k.(⃗x−⃗x′) 1
⃗k2
and thus for two well-separated objects we recover the Newtonian potential GM(1)M(2)/r.
We are now able to address the issue raised at the end of chapter I.5. Suppose a particle
theorist, Dr. Gravity, wants to propose a theory of gravity to rival Einstein’s theory. Dr. G
claims that gravity is due to the exchange of a spin 2 particle with a teeny mass mG coupled
to the stress-energy tensor T μν. In chapter I.5 we worked out the propagator of a massive
spin 2 particle, namely
Dspin 2
μν,λσ(k) = 1
2(GμλGνσ + GμσGνλ −2
3GμνGλσ)/(k2 −m2
G + iε)
with Gμν = ημν −kμkν/m2
G (after a trivial notational adjustment). Since the particle is
coupled to a conserved source kμT μν = 0 we can replace Gμν by ημν. Thus, in the limit
mG →0 we have the propagator
Dspin 2
μν,λσ(k) = 1
2
ημληνσ + ημσηνλ −2
3ημνηλσ
k2 + iε
(14)
Compare this with (12). Dr. G’s propagator differs from Einstein’s: 2
3 versus 1. Remarkably,
gravity is not generated by an almost massless spin 2 particle. The “ 2
3 discontinuity”
between (12) and (14) was discovered in 1970 independently by Iwasaki, by van Dam and
Veltman, and by Zakharov.
In Dr. G’s theory (with his own gravitational coupling GG), the interaction between two
particles is given by
GGT μν
(1) Dμν,λσ(k)T λσ
(2) = GG
2k2 (2T μν
(1) T(2)μν −2
3T(1)T(2))
For two lumps of nonrelativistic matter this becomes
GG
2k2 (2T 00
(1)T 00
(2) −2
3T 00
(1)T 00
(2)) = 4
3
GG
2k2 T 00
(1)T 00
(2)
Dr. G simply takes his GG = 3
4G and his theory passes all experimental tests.

440 | VIII. Gravity and Beyond
But wait! There is also the famous 1919 observation of the deflection of starlight by
the sun, and the photon is definitely not a lump of nonrelativistic matter. Indeed, recall
from chapter I.11 (or from your course on electromagnetism) that T ≡T μ
μ vanishes for
the photon. Thus, taking T μν
(1) and T μν
(2) to be the stress-energy tensor of the sun and of the
photon respectively, Einstein would have for the scattering amplitude (G/2k2)2T μν
(1) T(2)μν
while Dr. G would have (GG/2k2)2T μν
(1) T(2)μν = 3
4(G/2k2)2T μν
(1) T(2)μν. Dr. G would have
predicted a deflection angle of 3GM/R instead of 4GM/R (with M and R the mass
and radius of the sun). On the Brazilian island of Sobral in 1919 Einstein triumphed
over Dr. G.
As explained in chapter I.5, while a massive spin 2 particle has 5 degrees of freedom the
massless graviton has only 2. (I give an analysis of the helicity ±2 structure of one graviton
exchange in appendix 2.) The 5 degrees of freedom may be thought of as consisting of the
helicity ±2 degrees of freedom we want plus 2 helicity ±1 and a helicity 0 degrees of
freedom. The coupling of the helicity ±1 degrees of freedom vanishes because kμT μν = 0.
Thus, effectively, we are left with an extra scalar coupling to the trace T ≡ημνT μν of the
stress-energy tensor; as we can see plainly the discrepancy indeed resides in the last term
of (12) and (14).
You should be disturbed that a measurement of the deflection of starlight can show
that a physical quantity, the graviton mass mG, is mathematically zero rather than less
than some extremely small value. This apparent paradox was resolved by A. Vainshtein in
1972.8 He found that Dr. G’s theory contains a distance scale
rV =

GM
m4
G
 1
5
in the gravitational field around a body of mass M. The helicity 0 degree of freedom
becomes effective only on the distance scales r ≫rV . Inside the Vainshtein radius rV , the
gravitational field is the same as in Einstein’s theory and experiments cannot distinguish
between Einstein’s and Dr. G’s theories. With the current astrophysical bound mG ≪
(1024 cm)−1 and M the mass of the sun, rV comes out to be much larger than the size
of the solar system. In other words, the apparent paradox arose because of an interchange
of limits: We can take either the characteristic distance of the measurement robs (the radius
of the sun in the deflection of starlight) or the Vainshtein radius rV to infinity first.
So all is well: Dr. G’s theory is consistent with current measurements provided that
he takes mG small enough. What he is not allowed to do is use the one graviton exchange
approximation. Instead, he should solve the massive analog of Einstein’s field equation (4)
around a massive body such as the sun, as Vainshtein did. This is equivalent to expanding
to all orders in the graviton field h and resumming: In Feynman diagram language we
8 A. I. Vainshtein, Phys. Lett. 39B:393, 1972; see also C. Deffayet, G. Dvali, G. Gabadadze, and A. I. Vainshtein,
Phys. Rev. D65:044026, 2002.

VIII.1. Gravity as a Field Theory | 441
q
k1
k2
p1
p2
Figure VIII.1.2
have an infinite number of diagrams corresponding to the sun emitting 1, 2, 3, . . . , ∞
gravitons respectively. The paradox is formally resolved by noting that the higher orders
are increasingly singular as mG →0.
The gravity of light
At this point, you are ready to do perturbative quantum gravity: You have the graviton
propagator (12), and you can read off the interaction between gravitons from the detailed
version of (7) and the interaction between the graviton and any other field from the term
−1
2hμνT μν. The only trouble is that you might “drown in a sea of indices” if you don’t watch
out, as I have already warned you.
I know of one calculation (in fact one of my favorites in theoretical physics) in which
we can beat the indices down easily. An interesting question: Einstein said that light
is deflected by a massive object, but is light deflected gravitationally by light? Tolman,
Ehrenfest, and Podolsky discovered that in the weak field limit two light beams moving
in the same direction do not interact gravitationally, but two light beams moving in the
opposite directions do. Surprising, eh?
The scattering of two photons k1 + k2 →p1 + p2 via the exchange of a graviton is given
by the Feynman diagram in figure VIII.1.2, with the momentum transfer q ≡p1 −k1, plus
another diagram with p1 and p2 interchanged. The Feynman rule for coupling a graviton
to two photons can be read off from
hμνTμν = −hμν(FμλFν
λ −1
4ημνFρλF ρλ)
but all we need is that the interaction involve two powers of spacetime derivatives ∂acting
on the electromagnetic potential Aμ so that the graviton-photon-photon vertex involves
2 powers of momenta, one from each photon. Hence the scattering amplitude (with all
Lorentz indices suppressed) has the schematic form ∼(k1p1)D(k2p2). The η’s in the
graviton propagator D tie the indices on (k1p1) and (k2p2) together. (We have suppressed
the polarization vectors of the photons, imagining that they are to be averaged over in
the amplitude squared.) Referring to (12), we see that the amplitude is the sum of three
terms such as ∼(k1 . p1)(k2 . p2)/q2, ∼(k1 . k2)(p1 . p2)/q2, and ∼(k1 . p2)(k2 . p1)/q2.
Since according to Fourier the long distance part of the interaction potential is given by

442 | VIII. Gravity and Beyond
the small q behavior of the scattering amplitude, we need only evaluate these terms in the
limit q →0. We can throw almost everything away! For example,
k1 . p1 →k1 . k1 = 0,
k1 . p2 = k1 . (k1 + k2 −p1) →k1 . k2
Just imagining contracting all those indices in our heads is good enough: We obtain the
amplitude ∼(k1 . k2)(p1 . p2)/q2.
If k1 and k2 point in the same direction, k1 . k2 ∝k1 . k1 = 0. Two photons moving in the
same direction do not interact gravitationally.
Of course, this result is not of any practical importance since electromagnetic effects are
far more important, but this is not an engineering text. In appendix 1 I give an alternative
derivation of this amusing result.
Kaluza-Klein compactification
You have probably read about how excited Einstein was when he heard of the proposal of
Kaluza and of Klein to extend the dimension of spacetime to 5 and thus unify electromag-
netism and gravity. The 5th dimension is supposed to be compactified into a tiny circle of
radius a far smaller than what experimentalists can see; in other words, x5 is an angular
variable with x5 = x5 + 2πa. You have surely heard that string theory, at least in some ver-
sion, is based on the Kaluza-Klein idea. Strings live in 10-dimensional spacetime, with 6
of the dimensions compactified.
I can now show you how the Kaluza-Klein mechanism works. Start with the action
S =
1
16πG5

d5x
	
−g5R5
(15)
in 5-dimensional spacetime. The subscript 5 serves to indicate the 5-dimensional quanti-
ties. We denote the 5-dimensional metric by gAB with the indices A and B running over
0, 1, 2, 3, 5.
Assume that gAB does not depend on x5. Plug into S, integrate over x5, and compute
the effective 4-dimensional action. Since R5 and the 4-dimensional scalar curvature R
both involve two powers of ∂and gAB contains gμν, we must have (exercise VIII.1.5)
R5 = R + . . .. Thus, (15) contains the Einstein-Hilbert action with Newton’s gravitational
constant G ∼G5/a.
What else do we get? We don’t even have to work through the arithmetic. We can
argue by symmetry. Under the 5-dimensional coordinate transformation xA →x′A =
xA + εA(x), we have [see (8)] h′
AB = hAB −∂AεB −∂BεA. Let us choose εμ = 0 and ε5(x) to
be independent of x5: We go around and rotate each of the tiny circles attached to every point
in our spacetime a tiny bit. Well, we have h′
μν = hμν and h′
55 = h55, but h′
μ5 = hμ5 −∂με5.
But if we give the Lorentz 4-vector hμ5 and 4-scalar ε5 new names, call them Aμ and ,
this just says A′
μ = Aμ −∂μ, the usual electromagnetic gauge transformation!
Since we know that the 5-dimensional action (15) is invariant under xA →x′A = xA +
εA(x), the resulting 4-dimensional action must be invariant under Aμ →A′
μ = Aμ −∂μ

VIII.1. Gravity as a Field Theory | 443
and hence must contain the Maxwell action. Note once again the power of symmetry
considerations. No need to do tedious calculations.
Electromagnetism comes out of gravity!
Differential geometry of Riemannian manifolds
I hinted earlier at a deep connection between general coordinate transformation and gauge
transformation. Let us flesh this out by looking at differential geometry and gravity. For
this sketch we will consider locally Euclidean (rather than Minkowskian) spaces.
The differential geometry of Riemannian manifolds can be elegantly summarized in
the language of differential forms. Consider a Riemannian manifold (such as a sphere)
with the metric gμν(x). Locally, the manifold is Euclidean by definition, which means
gμν(x) = ea
μ(x)δabeb
ν(x)
(16)
where the matrix e(x) may be thought of as a similarity transformation that diagonalizes
gμν and scales it to the unit matrix. Thus, for a D-dimensional manifold there exist D
“world vectors” ea
μ(x) obviously dependent on x and labeled by the index a = 1, 2, . . . , D.
The functions ea
μ(x) are known as “vielbeins” (meaning “many legs” in German, vierbeins
= four legs for D = 4, dreibeins = three legs for D = 3, and so on.) In some sense, the
vielbeins can be thought as the “square root” of the metric.
Let us clarify by a simple example. The familiar two-sphere (of unit radius) has the line
element9 ds2 = dθ2 + sin2 θdϕ2. From the metric (gθθ = 1, gϕϕ = sin2 θ) we can read off
e1
θ = 1 and e2
ϕ = sin θ (all other components are zero). We are invited to define D 1-forms
ea = ea
μdxμ. (In our example, e1 = dθ, e2 = sin θdϕ.)
On a curved manifold, when we parallel transport a vector, the vector changes when
expressed in terms of the locally Euclidean coordinate frame. (This is just the familiar
statement that on a curved manifold such as the surface of the earth the notion of a vector
pointing straight north is a local concept: When we move infinitesimally away keeping our
“north vector” pointing in the same direction, it will end up being infinitesimally rotated
away from the “north vector” defined at the point we have just moved to.) This infinitesimal
rotation of the vielbeins is described by
dea = −ωabeb
(17)
Note that since ω generates an infinitesimal rotation it is an antisymmetric matrix: ωab =
−ωba. Since dea is a 2-form, ω is a 1-form, known as the connection: It “connects” the
locally Euclidean frames at nearby points. (Since the indices a, b, etc. are associated with
the Euclidean metric δab we do not have to distinguish between upper and lower indices.
When we do write upper or lower indices a, b, etc. it is for typographical convenience.) In
9 Note that this represents the square of an infinitesimal distance element and not an area element, and so a
quantity such as dθ2 is literally the square of dθ and not the wedge product dθdθ (of chapter IV.4), which would
have been identically zero.

444 | VIII. Gravity and Beyond
the simple example of the sphere, de1 = 0 and de2 = cos θ dθ dϕ and so the connection
has only one nonvanishing component ω12 = −ω21 = −cos θ dϕ.
At any point, we are free to rotate the vielbeins: If you use the vielbeins ea
μ I am free to use
some other vielbeins e′a
μ instead, as long as mine are related to yours by a rotation ea
μ(x) =
Oa
b(x)e′b
μ(x). [You can check that gμν(x) = ea
μ(x)δabeb
ν(x) = e′a
μ(x)δabe′b
ν (x) if OT O = 1.]
The connection ω′ is defined by de′a = −ω′abe′b. You can readily work out that (suppressing
indices)
ω = Oω′OT −(dO)OT
(18)
The local curvature of the manifold is a measure of how the connection varies from
point to point. We would like the curvature to be invariant under the local rotation O (or at
least to transform as a tensor so that by contracting it with vectors we can form a scalar).
The desired object is the 2-form Rab = dωab + ωacωcb. You can check that R = OR′OT .
(For the sphere, R12 = dω12 + ω1cωc2 = sin θ dθ dϕ.) Written out in components, Rab =
Rab
μνdxμdxν. I leave it to you to verify that Rab
μνeλ
aeσ
b is the usual Riemann curvature tensor
Rλσ
μν, where eλ
a is the inverse of the matrix ea
λ. In particular, Rab
μνeμ
a eν
b is the scalar curvature,
which in our convention works out to be +1 for the sphere.
Thus, Riemannian geometry can be elegantly summarized by the two statements (again
suppressing indices)
de + ωe = 0
(19)
and
R = dω + ω2
(20)
Look familiar? You should be struck by the similarity between (20) and the expression
for the field strength in nonabelian gauge theories F = dA + A2. Note ω transforms [see
(18)] exactly the same way as the gauge potential A. But one nagging difference, namely
the lack of an analog of e in gauge theory, has long bothered some theoretical physicists
(but is shrugged off by most as inconsequential). Also, note that Einstein theory is linear
in R while Yang-Mills theory is quadratic in F .
Gravity and Yang-Mills
We can make the connection between gravity and Yang-Mills theory more explicit by
looking at the derivative of a vector field. Yang-Mills theory was born of the requirement
that a field ϕ and its derivative ∂μϕ transform in the same way under a spacetime-
dependent internal symmetry transformation (IV.5.1). In Einstein gravity a vector field
W μ(x) transforms as W ′μ(x′) = Sμ
ν (x)W ν(x) with Sμ
ν (x) = ∂x′μ/∂xν. Since the matrix S
depends on the spacetime coordinate x, we see that ∂λW μ could not possibly transform
like a tensor with one upper and one lower index, as we would like naively just by looking
at indices. We would have to introduce a covariant derivative. Not surprisingly, this closely

VIII.1. Gravity as a Field Theory | 445
parallels the discussion in chapter IV.5. Historically, Yang and Mills were inspired by
Einstein gravity.
Using the chain rule and the product rule, we have
∂′
λW ′μ(x′) = ∂W ′μ(x′)
∂x′λ
= ∂xρ
∂x′λ
∂
∂xρ [Sμ
ν (x)W ν(x)] = (S−1)
ρ
λSμ
ν ∂ρW ν + [(S−1)
ρ
λ∂ρSμ
ν ]W ν
(21)
Were the second term in (21), which comes from differentiating S, not there, the naive
guess, that ∂λW μ transforms like a tensor, would be valid. The fact that the transformation
S varies from place to place has negated the naive guess.
What is happening is quite clear: as the vector W varies from a given point to a neighbor-
ing point, the coordinate axes that define the components of W also change. This suggests
that we could define a more suitable derivative, called the covariant derivative and written
as DλW μ, to take this effect into account, so that DλW μ would indeed transform like a
tensor. Exactly as in Yang-Mills theory (IV.5.1), we have to add an extra term to knock out
the second term in (21).
Just the way the indices hang together immediately suggests the correct construction.
The factor (S−1)ρ
λ∂ρSμ
ν in the unwanted second term in (21) has one upper index and two
lower indices, so we need an object with this set of indices. Lo, the Riemann-Christoffel
symbol μ
λν in (3) (and introduced in chapter I.11) fits the bill perfectly. I will let you have
the fun of verifying that the covariant derivative defined by
DλW μ ≡∂λW μ + μ
λνW ν
(22)
indeed transforms like a tensor (note that  was normalized correctly for this purpose).
I end with a technical remark about the coupling of gravity to spin
1
2 fields. First,
we of course have to Wick rotate so that the vierbein ea
μ erects a locally Minkowskian
rather than a Euclidean coordinate frame. The indices a, b, etc. are now contracted with
the Minkowskian metric ηab. The slight subtlety is that the Dirac gamma matrices γ a
are associated with the Lorentz rotation of the vierbein ea
μ(x) = Oa
b(x)e′b
μ(x′) and thus
carry the Lorentz index a rather than the “world” index μ. Similarly, the Dirac spinor
ψ(x) is defined relative to the local Lorentz frame specified by the vierbein, and thus
its covariant derivative has to be defined in terms of the connection ω rather than the
symbol . Hence the flat space Dirac action

d4x ¯ψ(iγ μ∂μ −m)ψ must be general-
ized to

d4x√−g ¯ψ(iγ aηabebμDμ −m)ψ, where the covariant derivative Dμψ = ∂μψ −
i
4ωμabσ abψ expresses the rotation of the local Lorentz frame as we move from a point x to
a neighboring point. In contrast to the action for integer spin fields in curved spacetime
(see chapter I.11), the Dirac action in curved spacetime involves the vierbein explicitly.
Appendix 1: Light on light again
The stress-energy tensor T μν of a light beam moving in the x-direction has four nonzero components: the
energy density T 00 of course, then T 0x = T 00 since photons carry the same energy and momentum, next
T x0 = T 0x by symmetry, and finally T xx = T 00 since the stress-energy tensor of the electromagnetic field is
traceless (chapter I.11). Without having to solve Einstein’s equations in the weak field limit (13) explicitly we
know immediately that h00 = h0x = hx0 = hxx ≡h. The metric around the light beam is given by g00 = 1 + h,

446 | VIII. Gravity and Beyond
g0x = gx0 = −h, and gxx = −1 + h (and of course gyy = gzz = −1 plus a bunch of vanishing components).
Consider a photon moving parallel to the light beam. Its worldline is determined by (recall chapter I.11)
d2xρ
dζ 2 = −ρ
μν
dxμ
dζ
dxν
dζ
Let’s calculate d2y/dζ 2 and d2z/dζ 2 with (dy/dζ), (dz/dζ) ≪(dt/dζ), (dx/dζ). Using (3) we find (with μ, ν
restricted to 0, x)
d2y
dζ 2 = 1
2(∂νgyμ + ∂μgyν −∂ygμν)dxμ
dζ
dxν
dζ
= −1
2(∂yh)

( dt
dζ )2 + (dx
dζ )2 −2 dt
dζ
dx
dζ
 
= −1
2(∂yh)( dt
dζ −dx
dζ )2
For a photon moving in the same direction as the light beam dt = dx and d2y/dζ 2 = d2z/dζ 2 = 0. We have once
again derived the Tolman-Ehrenfest-Podolsky effect. Note we never had to solve for h.
Incidentally, if you are a bit unsure of dt = dx, the condition ds = 0 for a light beam moving in the x-direction
amounts to (1+ h)dt2 −2hdtdx −(1−h)dx2 = 0. Upon division by dt2 we obtain −(1+ h) + 2hv + (1−h)v2 =
0, with v ≡dx/dt. The quadratic equation has two roots v = ∓(1 ± h)/(1 −h). The negative root gives v = 1,
and thus for a photon moving in the same direction as the light beam dx/dt = 1. In contrast, the positive root
v = −(1 + h)/(1 −h) describes a photon moving in the opposite direction.
Appendix 2: The helicity structure of gravity
To gain a deeper understanding of the difference between Einstein’s and Dr. G’s theories let us look at the
helicity structure of the interaction in the two cases. To warm up, consider the interaction between two conserved
currents due to the exchange of a spin 1 particle of momentum k and mass m : J μ
(1)J(2)μ = J 0
(1)J 0
(2) −J i
(1)J i
(2). Use
current conservation kμJ μ = 0 to eliminate J 0 = kiJ i/ω (with ω ≡k0). We obtain (kikj/ω2 −δij)J i
(1)J j
(2). Let ⃗k
point in the 3rd direction and use ⃗k2 = ω2 −m2 to write this as −[(m2/ω2)J 3
(1)J 3
(2) + J 1
(1)J 1
(2) + J 2
(1)J 2
(2)]. We see
that as m →0 the longitudinal component of the current J 3 indeed decouples as explained in chapter II.7 and
we obtain −1
2(J 1+i2
(1)
J 1−i2
(2)
+ J 1−i2
(1)
J 1+i2
(2)
), showing explicitly that the photon has helicity ±1. (Obvious notation:
J 1+i2 ≡J 1 + iJ 2 etc.)
Onward to gravity. Consider the interaction T μν
(1) T(2)μν −ξT(1)T(2), where ξ = 1
2 for Einstein and 1
3 for Dr. G.
For ease of writing I will now omit the subscripts (1) and (2). Conservation kμT μν = 0 allows us to eliminate
T 0i = kjT ji/ω and T 00 = kjklT jl/ω2. Again taking ⃗k to point in the 3rd direction we obtain the mess
m
ω
4
T 33T 33 + 2
m
ω
2
(T 13T 13 + T 23T 23) + T 11T 11 + T 22T 22 + 2T 12T 12
−ξ
m
ω
2
T 33 + T 11 + T 22
 m
ω
2
T 33 + T 11 + T 22

which simplifies in the limit m →0 to
T 11T 11 + T 22T 22 + 2T 12T 12 −ξ(T 11 + T 22)(T 11 + T 22)
In Einstein’s theory, ξ = 1
2 and this becomes
1
2(T 11 −T 22)(T 11 −T 22) + 2T 12T 12
which lo and behold is equal to 1
2(T 1+i2,1+i2T 1−i2,1−i2 + T 1−i2,1−i2T 1+i2,1+i2), showing that indeed the graviton
carries helicity ±2. In Dr. G’s theory, this would not be the case.

VIII.1. Gravity as a Field Theory | 447
Exercises
VIII.1.1 Work out T μν for a scalar field. Draw the Feynman diagram for the contribution of one-graviton exchange
to the scattering of two scalar mesons. Calculate the amplitude and extract the interaction energy between
two mesons sitting at rest, thus deriving Newton’s law of gravity.
VIII.1.2 Work out T μν for the Yang-Mills field.
VIII.1.3 Show that if hμν does not satisfy the harmonic gauge, we can always make a gauge transformation with
εν determined by ∂2εν = ∂μhμ
ν −1
2∂νhλ
λ so that it does. All of this should be conceptually familiar from
your study of electromagnetism.
VIII.1.4 Count the number of degrees of polarization of a graviton. [Hint: Consider a plane wave hμν(x) =
hμν(k)eikx just because it is a bit easier to work in momentum space. A symmetric tensor has 10
components and the harmonic gauge kμhμ
ν = 1
2kνhλ
λ imposes 4 conditions. Oops, we are left with 6
degrees of freedom. What is going on?] [Hint: You can make a further gauge transformation and still
stay in the harmonic gauge. The graviton should have only 2 degrees of polarization.]
VIII.1.5 The Kaluza-Klein result that we argued by symmetry considerations can of course be derived explicitly.
Let me sketch the calculation for you. Consider the metric
ds2 = gμνdxμdxν −a2[dθ + Aμ(x)dxμ]2
where θ denotes an angular variable 0 ≤θ < 2π. With Aμ = 0, this is just the metric of a curved spacetime,
whichhasacircleofradius a attached at every point. The transformation θ →θ + (x) leavesds invariant
provided that we also transform Aμ(x) →Aμ(x) −∂μ(x). Calculate the 5-dimensional scalar curvature
R5 and show that R5 = R4 −1
4 a2FμνF μν. Except for the precise coefficient 1
4 this result follows entirely
from symmetry considerations and from the fact that R5 involves two derivatives on the 5-dimensional
metric, as explained in the text. After some suitable rescaling this is the usual action for gravity plus
electromagnetism. Note that the 5-dimensional metric has the explicit form
g5
AB =
 gμν −a2AμAν
−a2Aμ
−a2Aν
−a2

(23)
VIII.1.6 Generalize the Kaluza-Klein construction by replacing the circles by higher dimensional spheres. Show
that Yang-Mills fields emerge.
VIII.1.7 Starting with the connection 1-form ω12 = −cos θdϕ for the sphere, show that the scalar curvature is a
constant independent of θ and ϕ.
VIII.1.8 The vielbeins for a spacetime with Minkowski metric is defined by gμν(x) = ea
μ(x)ηabeb
ν(x), where the
Minkowski metric ηab replaces the Euclidean metric δab. The indices a and b are to be contracted with
ηab. For example, Rab = dωab + ωacηcdωdb. Show that everything goes through as expected.

VIII.2
The Cosmological Constant Problem
and the Cosmic Coincidence Problems
The force that knows too much
The word paradox has been debased by loose usage in the physics literature. A real paradox
should involve a major and clear-cut discrepancy between theoretical expectation and
experimental measurement. The ultraviolet catastrophe, for example, is a paradox, the
resolution of which around the dawn of the twentieth century ushered in quantum physics.
I now come to the most egregious paradox of present day physics.
The electromagnetic force knows about the particles carrying charge, and the strong
force knows about the particles carrying color. And the gravitational force? It knows
everybody! More precisely, anybody carrying energy and momentum.
Within a particle physics frame of mind, which is the only frame of mind we have
in exploring the fundamental structure of physics, the graviton can be regarded as just
another particle. Indeed, given that a massless spin 2 particle couples to the stress-energy
tensor, one can reconstruct Einstein’s theory.
Nevertheless, there is an uncomfortable feel to this whole picture. Gravity has to do with
the curvature of spacetime, the arena in which all fields and particles live. The graviton is
not just another particle.
This in essence is the root origin1 of the paradox of the cosmological constant. The
graviton is not just another particle—it knows too much!
The cosmological constant
In the absence of gravity, the addition of a constant  to the Lagrangian L →L − has
no effect whatsoever. In classical physics the Euler-Lagrange equations of motion depend
1 For more along this line, see A. Zee, hep-th/0805.2183 in Proceedings of the Conference in Honor of C. N. Yang’s
85th Birthday, World Scientific, Singapore 2008, p. 131.

VIII.2. Cosmic Coincidence Problem | 449
only on the variation of the Lagrangian. In quantum field theory we have to evaluate the
functional integral Z =

Dϕei 
d4xL(x), which upon the inclusion of  merely acquires
a multiplicative factor. As we have seen repeatedly, a multiplicative factor in Z does not
enter into the calculation of Green’s function and scattering amplitudes.
Gravity, however, knows about . Physically, the inclusion of  corresponds to a shift
in the Hamiltonian H →H +

d3x. Thus, the “cosmological constant”  describes a
constant energy or mass per unit volume permeating the universe, and of course gravity
knows about it.
More technically, the term in the action −

d4x is not invariant under a coordinate
transformation x →x′(x). In the presence of gravity, general coordinate invariance re-
quires that the term −

d4x in the action S be modified to −

d4x√g, as I explained
way back in chapter I.11. Thus, the gravitational field gμν knows about , the infamous
cosmological constant introduced by Einstein and lamented by him as his biggest mistake.
This often quoted lament is itself a mistake. The introduction of the cosmological constant
is not a mistake: It should be there.
Symmetry breaking generates vacuum energy
In our discussion on spontaneous symmetry breaking, we repeatedly ignored an additive
term μ4/4λ that appears in L.
Particle physics is built on a series of spontaneous symmetry breaking. As the universe
cools, grand unified symmetry is spontaneously broken, followed by electroweak symme-
try breaking, then chiral symmetry breaking, just to mention a few that we have discussed.
At every stage a term like μ4/4λ appears in the Lagrangian, and gravity duly takes note.
How large do we expect the cosmological constant  to be? As we will see, for our
purposes the roughest order of magnitude estimate suffices. Let us take λ to be of order
1. As for μ, for the three kinds of symmetry breaking I just mentioned, μ is of order 1017,
102, and 1 Gev, respectively. We thus expect the cosmological constant  to be roughly
μ4 = μ/(μ−1)3, where the last form of writing μ4 reminds us that  is a mass or energy
density: An energy of order μ packed into a cube of size μ−1. But this is outrageous even if
we take the smallest value for μ: We know that the universe is not permeated with a mass
density of the order of 1 Gev in every cube of size 1 (Gev)−1.
We don’t have to put in actual numbers to see that there is a humongous discrepancy be-
tween theoretical expectation and observational reality. If you want numbers, the current
observational bound on the cosmological constant is <∼(10−3ev)4. With the grand unifi-
cation energy scale, we are off by (17+9+3)× 4 = 116 orders of magnitude. This is the
mother of all discrepancies!
With the Planck mass MPl ∼1019Gev the natural scale of gravity, we would expect
 ∼M4
Pl if it is of gravitational origin. We are then off by 124 orders of magnitude. We
are not talking about the crummy calculation of some pitiful theorist not fitting some
experimental curve by a factor of 2.

450 | VIII. Gravity and Beyond
We can imagine the universe starting out with a negative cosmological constant, fined
tuned to cancel the cosmological constant generated by the various episodes of sponta-
neous symmetry breaking. Or there must be a dynamical mechanism that adjusts the
cosmological constant to zero.
Notice I say zero, because the cosmological constant problem is basically an enormous
mismatchbetweentheunitsnaturaltoparticlephysicsandnaturaltocosmology.Measured
in units of Gev4 the cosmological constant is so incredibly tiny that particle physicists
have traditionally assumed that it must be zero and have looked in vain for a plausible
mechanism to drive it to zero. One of the disappointments of string theory is its inability
to resolve the cosmological constant problem. As of the writing of this chapter around the
turn of the millennium, the brane world scenarios (chapter I.6) have generated a great deal
of excitement by offering a glimmer of a hope. Roughly, the idea is that the gravitational
dynamics of the larger space that our universe is embedded in may cancel the effect of the
cosmological constant.
Cosmic coincidence
But Nature has a big surprise for us. While theorists racked their brains trying to come up
with a convincing argument that  = 0, observational cosmologists steadily refined their
measurements and discovered dark energy. The “cleanest” explanation of dark energy by
far is that it represents the cosmological constant. Assuming that this is the case (and
who knows?), the upper bound on the cosmological constant would be changed to an
approximate equality
 ∼(10−3ev)4!!!
(1)
The cosmological constant paradox deepens. Theoretically, it is easier to explain why some
quantity is mathematically 0 than why it happens to be ∼10−124 in the units natural (?) to
the problem.
To make things worse, (10−3ev)4 happens to be the same order of magnitude as the
present matter density of the universe ρM. More precisely, dark energy accounts for ∼74%
of the mass content of the universe, dark matter for ∼22%, and ordinary matter for ∼4%.
First, the ordinary matter we know and love is reduced to an almost negligibly small
component of the universe. Second, why should ρM be comparable to  to within a factor
of 3? This is sometimes referred to as the cosmic coincidence problem.
Now the cosmological constant  is, within our present understanding, a parameter in
the Lagrangian. On the other hand, since most of the mass density of the universe resides
in rest mass, as the universe expands ρM(t) decreases as [1/R(t)]3, where R(t) denotes
the scale size of the universe.2 In the far past, ρM was much larger than , and in the
2 For an easy introduction to cosmology, see A. Zee, Unity of Forces in the Universe, vol. II, chap. 10.

VIII.2. Cosmic Coincidence Problem | 451
far future, it will be much smaller. It just so happens that, in this particular epoch of the
universe, when you and I are around, ρM ∼. Or to be less anthropocentric, the epoch
when ρM ∼ happens to be when galaxy formation has been largely completed.
Very bizarre!
In their desperation, some theorists have even been driven to invoke anthropic
selection.3
3 For a recent review, see A. Vilenkin, hep-th/0106083.

VIII.3
Effective Field Theory Approach
to Understanding Nature
Low energy manifestation
The pioneers of quantum field theory, Dirac for example, tended to regard field theory
as a fundamental description of Nature, complete in itself. As I have mentioned several
times, in the 1950s, after the success of quantum electrodynamics many leading particle
physicists rejected quantum field theory as incapable of dealing with the strong and weak
interactions, not to mention gravity. Then came the great triumph of field theory in the early
1970s. But after particle physicists retrieved field theory from the dust bin of theoretical
physics, they realized that the field theories they were studying might be “merely” the low
energy manifestation of a deeper structure, a structure first identified as a grand unified
theory and later as a string theory. Thus was developed an outlook known as the effective
field theory approach, pace Dirac.
The general idea is that we can use field theory to say something about physics at low
energies or equivalently long distances even if we don’t know anything about the ultimate
theory, be it a theory built on strings or some as yet undreamed of structure. An important
consequence of this paradigm shift was that nonrenormalizable field theories became
acceptable. I will illuminate these remarks with specific examples.
The emergence of this effective field theory philosophy, championed especially by Wil-
son, marks another example of cross fertilization between condensed matter and particle
physics. Toward the late 1960s, Wilson and others developed a powerful effective field the-
ory approach to understanding critical phenomena, culminating in his Nobel Prize. The
situation in condensed matter physics is in many ways the opposite of that in particle phys-
ics at least as particle physics was understood in the 1960s. Condensed matter physicists
know the short distance physics, namely the quantum mechanics of electrons and ions.
But it certainly doesn’t help in most cases to write down the Schr¨odinger equation for the
electrons and ions. Rather, what one would like to have is an effective description of how
a system would respond when probed at low frequency and small wave vector. A striking
example is the effective theory of the quantum Hall fluid as described in chapter VI.2: The

VIII.3. Effective Field Theory | 453
relevant degree of freedom is a gauge field, certainly a far cry from the underlying elec-
tron. As in the σ model description (chapter VI.4) of quantum chromodynamics, it is fair
to say that without experimental guidance theorists would have a terribly hard time de-
ciding what the relevant low energy long distance degrees of freedom might be. You have
seen numerous other examples in condensed matter physics, from the Landau-Ginzburg
theory of superconductivity to Peierls instability.
The threshold of ignorance
In our discussion of renormalization, I espouse the philosophy that a quantum field
theory provides an effective description of physics up to a certain energy scale , a
threshold of ignorance beyond which physics not included in the theory comes into
play. In a nonrenormalizable theory, various physical quantities that we might wish to
calculate will come out dependent on , thus indicating that the physics at or beyond
the scale  is essential for understanding the low energy physics we are interested in.
Nonrenormalizable theories suffer from not being totally predictive, but nevertheless they
may be useful. After all, the Fermi theory of the weak interaction described experiments
and even foretold its own demise.
In a renormalizable theory, various physical quantities come out independent of ,
provided that the calculated results are expressed in terms of physical coupling constants
and masses, rather than in terms of some not particularly meaningful bare coupling
constants and masses. Low energy physics is not sensitive to what happens at high
energies, and we are able to parametrize our ignorance of high energy physics in terms of
a few physical constants.
From the late 1960s to the 1970s, one main thrust of fundamental physics was to
classify and study renormalizable theories. As we know, this program was “more than
spectacularly successful.” It allowed us to pin down the theory of the strong, the weak, and
the electromagnetic interactions.
Renormalization group flow and dimensional analysis
The effective field theory philosophy is intrinsically tied to renormalization group flow.
In a given field theory, as we flow toward low energies, some couplings may tend to zero
while others do not (and if they tend to infinity as in QCD, then we are unable to figure
out the effective theory without experimental input). Thus, the first step is to calculate the
renormalization group flow. A simple example is given in exercise VIII.3.1.
In many cases, we can simply use dimensional analysis. As I explained in our earlier
discussion on renormalization theory, couplings with negative dimensions of mass are
not important at low energies. To be specific, suppose we add a gϕ6 term to a λϕ4 theory.
The coupling g has the dimension of inverse mass squared. Let us define M2 ≡1/g. At
low energies, the effect of the gϕ6 term is suppressed by (E/M)2.

454 | VIII. Gravity and Beyond
How do we understand Schwinger’s spectacular calculation of the anomalous magnetic
moment of the electron in the effective field theory philosophy?
Let me first tell the traditional (i.e., pre-Wilsonian) version of the story. A student could
have asked, “Professor Schwinger, why didn’t you include the term (1/M) ¯ψσ μνψFμν in
the Lagrangian?”
The answer is that we better not. Otherwise, we would lose our prediction for the
anomalous magnetic moment; it would depend on M. Recall that [ψ] = 3
2 and [Aμ] = 1,
and hence ¯ψσ μνψFμν has mass dimension 3
2 + 3
2 + 1 + 1 = 5 > 4. The requirement of
renormalizability, that the Lagrangian be restricted to contain operators of dimension 4 or
less, provides the rationale for excluding this term.
Actually, the “real” punchline of my story is that Schwinger probably would not have
answered the question. When I took Schwinger’s field theory class, it was well known
among the students that it was forbidden to ask questions. Schwinger would simply
ignore any raised hands. There was no opportunity to ask questions after class either:
As he uttered his last sentence of an invariably beautifully prepared lecture, he would sail
majestically out of the room. Dirac dealt with questions differently. I was too young to have
witnessed it, but the story goes that when a student asked, “Professor Dirac, I did not under-
stand . . . ,” Dirac replied, “That is an assertion, not a question.”
The modern retelling of the magnetic moment story turns it around. We now regard the
Lagrangian of quantum electrodynamics as an effective Lagrangian which should include
an infinite sequence of terms of ever higher dimensions, with coefficients parametrizing
our threshold of ignorance. The physics of electrons and photons is now described by
L = ¯ψ(iγ μ(∂μ −ieAμ) −m)ψ −1
4FμνF μν + 1
M
¯ψσ μνψFμν + . . .
Yes, the term (1/M) ¯ψσ μνψFμν is there, with some unknown M having the dimension of
a
mass.
Schwinger’s
result,
that
quantum
fluctuations
generate
a
term
(α/2π)(1/2me) ¯ψσ μνψFμν, should then be interpreted as saying that the anomalous
magnetic moment of the electron is predicted to be [(α/2π)(1/2me) + 1/M]. The close
agreement of (α/2π)(1/2me) with the experimental value of the anomalous magnetic
moment can then be turned around to set a lower bound on M ≫(4π/α)me.
Equivalently, Schwinger’s result predicts the anomalous magnetic moment of the elec-
tron if we have independent evidence that M is much larger than [(α/2π)(1/2me)]−1. I
want to emphasize that all of this makes total physical sense. For example, if you speculate
that the electron has some finite size a, then you would expect M ∼1/a. The anomalous
magnetic moment calculation gives an upper bound for a, telling us that the electron must
be pointlike down to some small scale. Alternatively, we could have had independent evi-
dence, from electron scattering for example, that a has to be smaller than a certain length,
thus giving us a lower bound on M.
To underscore this point, imagine that in 1948 we followed Schwinger and quickly
calculated the anomalous magnetic moment of the proton. We could literally have done
it in 3 seconds, since all we have to do is replace me by mp in the Lagrangian, thus
obtaining (α/2π)(1/2mp) ¯ψσ μνψFμν, which would of course disagree resoundingly with

VIII.3. Effective Field Theory | 455
experiment. The disagreement tells us that we had not included all the relevant physics,
namely that the proton interacts strongly and is not pointlike. Indeed, we now know that
the anomalous magnetic moment of the proton gets contributions from the anomalous
magnetic moments and the orbital motion of the quarks inside the proton.
Effective theory of proton decay
It may seem that with the effective field theory approach we lose some predictive power. But
effective field theories can also be surprisingly predictive. Let me give a specific example.
Suppose we had never heard of grand unified theory. All we know is the SU(3) ⊗SU(2) ⊗
U(1) theory. An experimentalist tells us that he is planning to see if the proton would decay.
Without the foggiest notion about what would cause the proton to decay we can still
write down a field theory to describe proton decay. The Lagrangian L is to be constructed
out of quark q and lepton l fields and must satisfy the symmetries that we know. Three
quarks disappear, so we write down schematically qqq, but three spinors do not a Lorentz
scalar make. We have to include a lepton field and write qqql.
Since four fermion fields are involved, the terms qqql have mass dimension 6 and so in
L they have to appear as (1/M2)qqql with some mass M, corresponding to the mass scale
of the physics responsible for proton decay. The experimental lower bound on the lifetime
of the proton sets a lower bound on M.
It is instructive to contrast this analysis with an (imagined) effective field theory analysis
of proton decay long before the concept of quarks was invented, say around 1950. We would
construct an effective Lagrangian out of the available fields, namely the proton field p,
the electron field e, and the pion field π, and thus write down the dimension 4 operator
f ¯pe+π0 with some dimensionless constant f . To estimate f , we would naively compare
this operator with the one describing pion-nucleon coupling (chapter IV.2) g ¯pnπ+ in the
effective Lagrangian. Since f ¯pe+π0 violates isospin invariance, we might expect f ∼αg,
namely the same order as g multiplied by some measure of isospin breaking, say the fine
structure constant. But this would give an unacceptably short lifetime to the proton. We
are forced to set f to a ridiculously small number, which seems highly unnatural. Thus, at
least in hindsight, we can say that the extremely long lifetime of the proton almost points
to the existence of quarks. The key, as we saw above, is to promote of the mass dimension
of the term in the effective Lagrangian responsible for proton decay from 4 to 6. (Can the
cosmological constant puzzle be solved in the same way?)
Another way of saying this is that SU(3) ⊗SU(2) ⊗U(1) plus renormalizability predicts
one of the most striking facts of the universe, the stability of the proton. In contrast, the
old pion-nucleon theory glaringly failed to explain this experimental fact.
In accordance with our philosophy, L must be invariant under SU(3) ⊗SU(2) ⊗U(1),
under which quark and lepton fields transform rather idiosyncratically, as we saw in
chapter VII.5. To construct L we have to sit down and list all Lorentz invariant SU(3) ⊗
SU(2) ⊗U(1) terms of the form qqql.

456 | VIII. Gravity and Beyond
Sitting down, we would find that, assuming only one family of quarks and leptons for
simplicity, there are only four terms we can write down for proton decay, which I list here
for the sake of completeness: (lLCqL)(uRCdR), (eRCuR)(qLCqL), (lLCqL)(qLCqL), and
(eRCuR)(uRCdR). Here lL =
 ν
e

L and qL =
 u
d

L denote the lepton and quark doublet
of SU(2) ⊗U(1), the twiddle is defined by lj = liεij with SU(2) indices i, j = 1, 2 (see
appendix B), and C denotes the charge conjugation matrix. Color indices on the quark
fields are contracted in the only possible way. The effective Lagrangian is then given by the
sum of these four terms, with four unknown coefficients.
The effective field theory tells us that all possible baryon number violating decay pro-
cesses can be determined in terms of four unknowns. We expect that these predictions will
hold to an accuracy of order (MW/M)2. (If MW were zero, SU(3) ⊗SU(2) ⊗U(1) would
be exact.)
Of course, we can increase our predictive power by making further assumptions. For
example, if we think that proton decay is mediated by a vector particle, as in a generic grand
unified theory, then only the first two terms in the above list are allowed. In a specific grand
unified theory, such as the SU(5) theory, the two unknown coefficients are determined in
terms of the grand unified coupling and the mass of the X boson.
To appreciate the predictive power of the effective field theory approach, inspect the
list of the four possible operators. We can immediately predict that while proton decay
violates both baryon number B and lepton number L, it conserves the combination B −L.
I emphasize that this is not at all obvious before doing the analysis. Could you have told
the experimentalist which of the two possible modes n →e+π−or n →e−π+ he should
expect? A priori, it could well be that B + L is conserved.
Note that Fermi’s theory of the weak interaction would be called an effective field theory
these days. Of course, in contrast to proton decay, beta decay was actually seen, and the
prediction from this sort of symmetry analysis, namely the existence of the neutrino, was
triumphantly confirmed.
Along the same line, we could construct an effective field theory of neutrino masses.
Surely one of the most exciting experimental discoveries in particle physics of recent
years was that neutrinos are not massless. Let us construct an SU(2) ⊗U(1) invariant
effective theory. Since νL resides inside lL, without doing any detailed analysis we can see
that a dimension-5 operator is required: schematically lLlL contains the desired neutrino
bilinear but it carries hypercharge Y/2 = −1; on the other hand, the Higgs doublet ϕ
carries hypercharge + 1
2, and so the lowest dimensional operator we can form is of the
form llϕϕ with dimension 3
2 + 3
2 + 1 + 1 = 5. Thus, the effective L must contain a term
(1/M)llϕϕ, with M the mass scale of the new physics responsible for the neutrino mass.
Thus, by dimensional analysis we can estimate mν ∼m2
l /M, with ml some typical charged
lepton mass. If we take ml to be the muon mass ∼102Mev and mν ∼10−1ev, we find
M ∼(102Mev)2/10−1(10−6Mev) = 108Gev.
The philosophy of effective field theories valid up to a certain energy scale  seems
so obvious by now that it is almost difficult to imagine that at one time many eminent
physicists demanded much more of quantum field theory: that it be fundamental up to
arbitrarily high energy scales.

VIII.3. Effective Field Theory | 457
Indeed, we now regard all quantum field theories as effective field theory. For all we
know, spacetime on some short distance does consist of a lattice, and so the Yang-Mills
action is but the leading term in an expansion of the Wilson lattice action. The Einstein-
Hilbert Lagrangian, being nonrenormalizable, is a fortiori “merely" the leading term in
an effective field theory
L = √−g(M4
 + M2
PR + c1R2 + c2RμνRμν + c3RμνσρRμνσρ +
1
M2(d1R3 + . . .) + . . .)
Here c1,2,3 and d1 are dimensionless numbers presumably of order 1. The three terms
quadratic in the curvature involve four powers of derivatives versus the two powers in
the Einstein-Hilbert term, and hence their effects relative to the leading terms are sup-
pressed by (E/MP)2 with E an energy scale characteristic of the process we are studying.
Thus, these so-called Weyl-Eddington terms could be safely ignored in any conceivable
experiment. [A technical aside: The Gauss-Bonnet theorem implies that the combination
(R2 −4RμνRμν + RμνσρRμνσρ) is a total derivative, so c3 can be effectively set to 0, but that
is besides the point here.] We have indicated only one representative dimension 6 term
R3 (out of many). Its coefficient, in accordance with high school dimensional analysis, is
suppressed by two powers of some mass M.
What do we expect the mass scale M to be? Suppose we live in a universe with only gravity
(and of course we don’t, actually) then once again, we could risk being presumptuous and
take M to be the intrinsic mass scale of gravity, namely the Planck mass MP, but we have
not yet recovered from our third-degree burn from supposing that M ∼MP. If we could
ignore the cosmological constant problem for a moment, then the standard (but quite
possibly wrong!) consensus is that in a universe of pure gravity our theory of gravity is an
effective expansion in powers of (E/MP)2.
Alternatively, we could treat L as the effective theory of gravity after we integrate out all
the matter degree of freedom. In that case, M would be of order me (imagine gravitons
coupled to an electron loop; see exercise VIII.3.5), or perhaps even mν (generated by a
neutrino loop).
Effective field theory of the blue sky
As another application of the effective field theory philosophy, consider the scattering of
electromagnetic waves on an electrically neutral spinless particle described by a scalar field
. Since  is neutral, the lowest dimension gauge invariant term that can be added to
L = ∂†∂ + m2† + . . . is (1/M2)†FμνF μν. A factor of 1/M2, with M some mass
scale, has to be included with the dimension 1 + 1 + 2 + 2 = 6 operator to bring the high
school dimension down to 4. The two powers of derivative in FμνF μν tell us immediately
that the amplitude for photon scattering on this neutral particle goes like M ∝ω2, with
ω the frequency of the electromagnetic wave. Thus we conclude that the scattering cross
section varies like σ(ω) ∝ω4.

458 | VIII. Gravity and Beyond
We have arrived at Rayleigh’s celebrated explanation of the color of the sky. In passing
through the atmosphere red light scatters less than blue light on air molecules and hence
the sky is blue.
For application to spinless atoms or molecules, we can pass to the nonrelativistic limit
as described in chapter III.5, setting  = (1/
√
2m)e−imtϕ, so that the effective Lagrangian
now reads
L = ϕ†i∂0ϕ −1
2m∂iϕ†∂iϕ +
1
mM2ϕ†ϕ(c1 ⃗E2 −c2 ⃗B2) + . . .
In this case, since we understand the microscopic physics governing atoms and
molecules, we know perfectly well what the mass scale M represents. The coupling of
a photon to an electrically neutral system such as an atom or a molecule must vanish like
the characteristic size d of the system, since as d →0 the positive and negative charges are
on top of each other, giving a vanishing net coupling to the photon. Rotational invariance
implies that the coupling ∼⃗k . ⃗d. The scattering amplitude then goes like M ∝(ωd)2,
since the coupling has to act twice, once for the incoming photon and once for the out-
going photon. (Note that by rotational invariance the expectation value of the operator ⃗d
vanishes, but we are doing second order perturbation theory so that we have to evalu-
ate the expectation value of a quantity quadratic in ⃗d.)1 Squaring M and invoking some
elementary quantum mechanics and dimensional analysis, we obtain the cross section
σ(ω) ∼d6ω4.
Appendix: Reshuffling terms in effective field theory
The Lagrangian of an effective field theory consists of an infinite sequence of terms arranged in an orderly
progression of higher and higher mass dimension, constrained only by the assumed symmetries of the theory.
In fact, some terms could be effectively eliminated. To explain this, we focus on a toy example:
L = 1
2(∂ϕ)2 −λϕ4 +
1
M2(aϕ6 + bϕ3∂2ϕ + c(∂2ϕ)2) + O
 1
M4

(1)
We are secretly dealing with the action and thus we freely integrate by parts. For arithmetical simplicity, we did
not include a mass term, so that to leading order in 1/M the equation of motion reads simply ∂2ϕ = 0. The three
possible dimension 6 terms are shown explicitly [we integrate by parts to get rid of the term ϕ2(∂ϕ)2].
Are we allowed to use the equation of motion to eliminate the two dimension 6 terms that are proportional
to ∂2ϕ?
We know that we could make a field redefinition without changing the on shell amplitudes, so let us rede-
fine ϕ →ϕ + (1/M2)F. Then 1
2(∂ϕ)2 →1
2(∂ϕ)2 −(1/M2)F∂2ϕ + O(1/M4) and λϕ4 →λ(ϕ4 + (1/M2)ϕ3F +
O(1/M4)). Set F = pϕ3 + q∂2ϕ. We see that with an appropriate choice of p and q we can cancel off b and c.
Notice that in the process we also change a to some other value.
The answer to the question is yes, but the naive statement that the equation of motion ∂2ϕ = 0 empowers us
to simply set ∂2ϕ to zero in the nonleading terms in the effective field theory is, legalistically speaking, incorrect,
or at least misleading. We see that we actually generated O(1/M4) terms and changed the ϕ6 term. Thus, more
correctly, a field redefinition allows us to shuffle terms around and to higher order. The net effect, however, is
the same as if we trusted the naive statement and set ∂2ϕ to zero in the nonleading terms.
1 For details, see, for example, J. J. Sakurai, Advanced Quantum Mechanics, Addison-Wesley, New York, 1967,
p. 47.

VIII.3. Effective Field Theory | 459
This procedure works for fermions also. As an example, consider the effective Lagrangian L = ¯ψ(iγ μ∂μ −
m)ψ + (1/M3) ¯ψ(iγ μ∂μ −m)ψ( ¯ψψ) + . . . . Then the field redefinition ψ →ψ −(1/2M3)ψ( ¯ψψ) gets rid of the
dimension 7 term shown.
We could also apply what we just learned to the effective theory of gravity if without any understanding we
set the cosmological constant to zero. Also, use the Gauss-Bonnet theorem to get rid of the RμνσρRμνσρ term, so
that we have
L = √−g

M2
PR + c1R2 + c2RμνRμν +
1
M2(d1R3 + . . .) + . . .

(2)
Make a field redefinition gμν →gμν + δgμν and use
δ

d4x√−gR = −

d4x√−g(Rμν −1
2gμνR)δgμν
Set δgμν = pRμν + qgμνR. Then we can cancel off c1 and c2 with a judicious choice of p and q. I emphasize that
this works only if we set the cosmological constant to zero without any ado.
Exercises
VIII.3.1 Consider
L = 1
2

(∂ϕ1)2 + (∂ϕ2)2	
−λ(ϕ4
1 + ϕ4
2) −gϕ2
1ϕ2
2
(3)
We have taken the O(2) theory from chapter I.10 and broken the symmetry explicitly. Work out the
renormalization group flow in the (λ −g) plane and draw your own conclusions.
VIII.3.2 Assuming the nonexistence of the right handed neutrino field νR (i.e., assuming the minimal particle
content of the standard model) write down all SU(2) ⊗U(1) invariant terms that violate lepton number
L by 2 and hence construct an effective field theory of the neutrino mass. Of course, by constructing a
specific theory one can be much more predictive. Out of the product lLlL we can form a Lorentz scalar
transforming as either a singlet or triplet under SU(2). Take the singlet case and construct a theory. [Hint:
For help, see A. Zee, Phys. Lett. 93B: p. 389, 1980.]
VIII.3.3 Let A, B, C, D denote four spin 1
2 fields and label their handedness by a subscript: γ 5Ah = hAh with
h = ±1. Thus, A+ is right handed, A−left handed, and so on. Show that
(AhBh)(C−hD−h) = −1
2(Ahγ μD−h)(C−hγμBh)
(4)
This is an example of a broad class of identities known as Fierz identities (some of which we will need in
discussing supersymmetry.) Argue that if proton decay proceeds in lowest order from the exchange of a
vector particle then only the terms (lLCqL)(uRCdR) and (eRCuR)(qLCqL) are allowed in the Lagrangian.
VIII.3.4 Given the conclusion of the previous exercise show that the decay rate for the processes p →π+ + ¯ν,
p →π0 + e+, n →π0 + ¯ν, and n →π−+ e+ are proportional to each other, with the proportionality
factors determined by a single unknown constant [the ratio of the coefficients of (lLCqL)(uRCdR) and
(eRCuR)(qLCqL)].
For help on these last three exercises see S. Weinberg, Phys. Rev. Lett. 43: 1566, 1979; F. Wilczek and
A. Zee, ibid. p. 1571; H. A. Weldon and A. Zee, Nucl. Phys. B173: 269, 1980.
VIII.3.5 Imagine a mythical (and presumably impossible) race of physicists who only understand physics at
energies less than the electron mass me. They manage to write down the effective field theory for the one
particle they know, the photon,
L = −1
4FμνF μν + 1
m4
e
{a(FμνF μν)2 + b(Fμν ˜F μν)2} + . . .
(5)

460 | VIII. Gravity and Beyond
with ˜F μν = 1
2εμνρσFρσ the dual field strength as usual and a and b two dimensionless constants
presumably of order unity.
(a) Show that L respects charge conjugation (A →−A in this context), parity, and time reversal, (and
of course gauge invariance.)
(b) Draw the Feynman diagrams that give rise to the two dimension 8 terms shown. The coefficients
a and b were calculated by Euler and Kockel in 1935 and by Heisenberg and Euler in 1936, quite a
feat since they did not know about Feynman diagrams and any of the modern quantum field theory
set up.
(c) Explain why dimensional 6 terms are absent in L. [Hint: One possible term is ∂λFμν∂λF μν.]
(d) Our mythical physicists do not know about the electron, but they are getting excited. They are going
to start doing photon-photon scattering experiments with a machine called LPC that could produce
photons with energy greater than me. Discuss what they will see. Apply unitarity and the Cutkosky
rules.
VIII.3.6 Use the effective field theory approach to show that the scattering cross section of light on an electrically
neutral spin 1
2 particle (such as the neutron) goes like σ ∝ω2 to leading order, not ω4. Argue further that
the constant of proportionality can be fixed in terms of the magnetic moment μ of the particle. [Historical
note: This result was first obtained in 1954 by F. Low (Phys. Rev. 96: 1428) and by M. Gell-Mann and
Murph L. Goldberger (Phys. Rev. 96: 1433) using much more elaborate arguments.]

VIII.4
Supersymmetry: A Very Brief Introduction
Unifying bosons and fermions
Let me start with a few of the motivations for supersymmetry. (1) All experimentally known
symmetries relate bosons to bosons and fermions to fermions. We would like to have a
symmetry, supersymmetry, relating bosons and fermions. (2) It is natural for fermions to
be massless (recall chapter VII.6), but not for bosons. Perhaps by pairing the Higgs field
with a fermion field we can resolve the hierarchy problem mentioned in chapter VII.6.
(3) Recalling from chapter II.5 that fermions contribute negatively to the vacuum energy,
you might be tempted to speculate that the cosmological constant problem could be solved
if we could get the fermion contribution to cancel the boson contribution.
Disappointingly, it has been more than 30 years1 since the conception of supersymmetry
(Golfand and Likhtman constructed the first supersymmetric field theory in 1971) and
direct experimental evidence is still lacking. All existing supersymmetric theories pair
known bosons with unknown fermions and known fermions with unknown bosons.
Supersymmetry has to be broken at some mass scale M beyond the regime already explored
experimentally, but then (as explained in chapter VIII.2) we might expect a cosmological
constant of order M4.
Be that as it may, supersymmetric field theories have many nice properties (hardly
surprising since the relevant symmetry is much larger). Supersymmetry has thus attracted
a multitude of devotees. I give you here as brief an introduction to supersymmetry as I can
write. In the spirit of a first exposure, I will avoid mentioning any subtleties and caveats,
hoping that this brief introduction will be helpful to students before they tackle the tomes
out there.
1 For a fascinating account of the early history of supersymmetry, see G. Kane and M. Shifman, eds., The
Supersymmetric World: The Beginning of the Theory.

462 | VIII. Gravity and Beyond
Inventing supersymmetry
Suppose one day you woke up wanting to invent a field theory with a symmetry relating
bosons to fermions. The first thing you would need is the same number of fermionic and
bosonic degrees of freedom. The simplest fermion field is the two-component Weyl spinor
ψ. You would now have one complex degree of freedom,2 so you would have to throw in
a complex scalar field ϕ. You could proceed by trial and error: Write down a Lagrangian
including all terms with dimension up to four and then adjust the various parameters in
the Lagrangian until the desired symmetry appears. For instance, you might adjust μ in
the mass terms μ2ϕ†ϕ + m(ψψ + ¯ψ ¯ψ) until the theory becomes more symmetrical so
that the boson and the fermion have the same mass.
If you were to try to play the game by using a Dirac spinor  and a complex scalar
ϕ you would be doomed to failure from the very start since there would be twice as
many fermionic degrees of freedom as bosonic degrees of freedom. I believe that the
development of supersymmetry was very much retarded by the fact that until the early
1970s most field theorists, having grown up with Dirac spinors, had little knowledge of
Weyl spinors. That was a hint that now is the time for you to get thoroughly familiar with
the dotted and undotted notation of appendix E. To read this chapter, you need to be fluent
with that notation.
Supersymmetric algebra
It is perfectly feasible to construct this supersymmetric field theory, known as the Wess-
Zumino model, by trial and error, but instead I will show you an elegant but more abstract
approach known as the superspace and superfield formalism, invented by Salam and
Strathdee. We will have to develop a considerable amount of formal machinery. Everything
is very super here.
Write the supersymmetry generator taking us from ϕ to ψα as Qα (known as the
supercharge). The statement that Qα transforms as a Weyl spinor means [J μν, Qα] =
−i(σ μν)α βQβ, where J μν denotes the generators of the Lorentz group. Of course, since
Qα is independent of the spacetime coordinates [P μ, Qα] = 0. From appendix E we denote
the conjugate of Qα by ¯Q˙α and [J μν, ¯Q˙α] = −i(¯σ μν)˙α ˙β ¯Q ˙β.
We have to write down the anticommutation relation between the Grassman objects Qα
and ¯Q ˙β and now the work we did in appendix E really pays off. The supersymmetry algebra
is given by
{Qα, ¯Q ˙β} = 2(σ μ)α ˙βPμ
(1)
2 One complex degree of freedom on mass shell and two complex degrees of freedom off mass shell. See the
superfield formalism below.

VIII.4. Supersymmetry | 463
We argue by the “what else can it be?” method. The right-hand side must carry the indices
α and ˙β and we know that the only object that carries these indices is σ μ. The Lorentz
index μ has to be contracted and the only vector around is Pμ. The factor of 2 fixes the
normalization of Q.
By the same kind of argument we must have {Qα, Qβ} = c1(σ μν)α βJμν + c2δβ
α. Com-
muting with P λ we see that the constant c1 must vanish. Recalling that Qγ = εγβQβ, we
have {Qα, Qγ} = c2εγ α; but since the left-hand side is symmetric in α and γ we have c2 = 0.
Thus, {Qα, Qβ} = 0 and { ¯Q˙α, ¯Q ˙β} = 0 (see exercise VIII.4.2).
A basic theorem
An important physical fact follows immediately from (1). Contracting with (¯σ ν) ˙βα we
obtain
4P ν = (¯σ ν) ˙βα{Qα, ¯Q ˙β}
(2)
In particular the time component tells us about the Hamiltonian
4H =

α
{Qα, ¯Q˙α} =

α
{Qα, Q†
α} =

α
(QαQ†
α + Q†
αQα)
(3)
We obtain the important theorem that in a supersymmetric field theory any physical state
|S⟩must have nonnegative energy:
⟨S|H |S⟩= 1
2

α

S′
|⟨S′|Qα |S⟩|2 ≥0
(4)
Superspace
Now that we have constructed the supersymmetric algebra let us keep in mind our goal of
constructing supersymmetric field theories. To do that, we need to figure out and classify
how fields transform under this supersymmetric algebra. We have to go through a lot of
formalism, the necessity for which will become clear in due course.
Imagine that you are trying to invent the superspace formalism. Let us motivate it by
staring at the basic relation (1) {Qα, ¯Q ˙β} = 2(σ μ)α ˙βPμ. A supersymmetric transformation
Q followed by its conjugate ¯Q ˙β generates a translation Pμ. Hmm, let’s see, Pμ ≡i(∂/∂xμ)
generates translation in xμ, so perhaps Qα, being Grassmannian, would generate transla-
tion in some abstract Grassmannian coordinate θα? (Similarly, ¯Q ˙β would generate trans-
lation in ¯θ ˙β.)
Salam and Strathdee invented the notion of a superspace with bosonic and fermionic
coordinates {xμ, θα, ¯θ ˙β} with the supersymmetry algebra represented by translations in
this space.
So let us try Qα and ¯Q ˙β being something like ∂/∂θα and ∂/∂¯θ ˙β, respectively. But then
{Qα, ¯Q ˙β} = 0 and we don’t get (1). We have to keep playing around modifying Qα and ¯Q ˙β.
You may already see what we need. If we add a term such as θσ μ∂μ to ¯Q ˙β, then the ∂/∂θα

464 | VIII. Gravity and Beyond
in Qα acting on θσ μ∂μ will produce something like the right-hand side of (1). Similarly,
we will want to add a term such as ¯θσ μ∂μ to Qα. (Once again, the dotted and undotted
notation we worked hard to develop fixes what we must write, namely (σ μ)α ˙α ¯θ ˙α∂μ so that
the indices match and obey the “southwest to northeast” rule.) Thus, we represent the
supercharges as
Qα =
∂
∂θα −i(σ μ)α ˙α ¯θ ˙α∂μ
(5)
and
¯Q ˙β = −∂
∂¯θ ˙β + iθβ (σ μ)β ˙β∂μ
(6)
You see that (1) is now satisfied. Interestingly, when we translate in the fermionic direction
we have to translate a bit in the bosonic direction as well.
Superfield
A superfield (xμ, θα, ¯θ ˙β), as the name suggests, is just a field living in superspace. An
infinitesimal supersymmetry transformation takes
 →′ = (1 + iξαQα + i ¯ξ˙α ¯Q˙α)
(7)
with ξ and ¯ξ two Grassmannian parameters.
It turns out that we can impose some condition on  and restrict this rather broad
definition a bit. After staring at (5) and (6) for a while, you may realize that there are two
other objects,
Dα =
∂
∂θα + i(σ μ)α ˙α ¯θ ˙α∂μ
and
¯D ˙β = −
 ∂
∂¯θ ˙β + iθβ (σ μ)β ˙β∂μ

that we can define, sort of the combinations orthogonal to Qα and ¯Q ˙β. Clearly, Dα and
¯D ˙β anticommute with Qα and ¯Q ˙β. The significance of this fact is that if we impose the
condition ¯D ˙β = 0 on the superfield , then according to (7) its transform ′ also satisfies
the condition.
A superfield  satisfying the condition ¯D ˙β = 0 is known as a chiral superfield. The con-
dition is actually easy to implement:3 Observe that if we define yμ ≡(xμ + iθα (σ μ)α ˙α ¯θ ˙α)
(note we are adding two bosonic quantities here), then
¯D ˙βyμ = −
 ∂
∂¯θ ˙β + iθβ(σ ν)β ˙β∂ν

yμ = −

−iθα(σ μ)α ˙β + iθβ(σ μ)β ˙β
	
= 0
Thus, a superfield (y, θ) that depends on y and θ only is a chiral superfield.
3 This is analogous to the problem of constructing a function f (x, y) satisfying the condition Lf = 0 with
L ≡[x(∂/∂y) −y(∂/∂x)]. We define r ≡(x2 + y2)
1
2 and observe that Lr = 0. Then any f that only depends on
r satisfies the desired condition.

VIII.4. Supersymmetry | 465
Let us expand  in powers of θ holding y fixed. Remember that θ contains two compo-
nents (θ1, θ2). Thus, we can form an object with at most two powers of θ, namely θθ, which
you worked out in exercise E.3. Thus, as usual, power series in Grassmannian variables
terminate, and we have
(y, θ) = ϕ(y) +
√
2θψ(y) + θθF(y)
with ϕ(y), ψ(y), and F(y) merely coefficients in the series at this stage. We can Taylor
expand once more around x:
(y, θ) = ϕ(x) +
√
2θψ(x) + θθF(x)
+ iθσ μ ¯θ∂μϕ(x) −1
2θσ μ ¯θθσ ν ¯θ∂μ∂νϕ(x) +
√
2θiθσ μ ¯θ∂μψ(x)
(8)
We see that a chiral superfield  contains a Weyl fermion field ψ, and two complex scalar
fields ϕ and F .
Finding a total divergence
Let’s do a bit of dimensional analysis for fun and profit. Given that Pμ has the dimension
of mass, which we write as [Pμ] = 1 using the same notation as in chapter III.2, then (1),
(5), and (6) tell us that [Q] = [ ¯Q] = 1
2 and [θ] = [ ¯θ] = −1
2. Given [ϕ] = 1, then (8) tells us
[ψ] = 3
2, which we know already, and [F] = 2, which we didn’t know. In fact, we have never
met a Lorentz scalar field with mass dimension 2. How can we have a kinetic energy term
for F in L with dimension 4? We can’t. The term F †F already has dimension 4, and any
derivative is going to make the dimension even higher. Also, didn’t we say that with ϕ and
ψ we balance the same number of bosonic and fermionic degrees of freedom?
The field F(x) definitely has something strange about him. What is he doing in our
theory?
Under an infinitesimal supersymmetric transformation the superfield changes by δ =
i(ξQ + ¯ξ ¯Q). Referring to (8), (5), and (6), you can work out how the component fields ϕ,
ψ, and F transform (see exercise VIII.4.5). But we can go a long way invoking symmetry
and dimensional analysis. For example, δF is linear in ξ or ¯ξ, which by dimensional
analysis must multiply something with dimension [ 5
2] since [F] = 2 and [ξ] = [¯ξ] = −1
2.
The only thing around with dimension [ 5
2] is ∂μψ, which carries an undotted index. Note it
can’t be ∂μ ¯ψ since  does not contain ¯ψ. By Lorentz invariance we have to find something
carrying the index μ, and that can only be (σ μ)α ˙α. The dotted index on (σ μ)α ˙α can only be
contracted with ¯ξ. So everything is fixed except for an overall constant:
δF ∼∂μψα(σ μ)α ˙α ¯ξ ˙α
(9)
Arguing along the same lines you can easily show that δϕ ∼ξψ and δψ ∼ξF + ∂μϕσ μ¯ξ.
The important point here is not the overall constant in (9) but that δF is a total diver-
gence.
Given any superfield  let us denote by []F the coefficient of θθ in an expansion of 
[as in (8)]. What we have learned is that under a supersymmetric transformation δ([]F)
is a total divergence and thus

d4x[]F is invariant under supersymmetry.

466 | VIII. Gravity and Beyond
Our next observation is that if ¯D ˙β = 0, then ¯D ˙β2 = 0 also. In other words, if  is a
chiral superfield, then so is 2 (and by extension, 3, 4, and so forth).
Supersymmetric action
What do we want to achieve anyway? We want to construct an action invariant under
supersymmetry.
Finally, after all this formalism we are ready. In fact, it is almost staring us in the face:

d4x[ 1
2m2 + 1
3g3 + . . .]F is invariant under supersymmetry by virtue of the last two
paragraphs. Squaring (8) and extracting the coefficient of θθ we see by inspection that
[2]F = (2Fϕ −ψψ). Similarly, [3]F = 3(Fϕ2 −ϕψψ). Now do exercise VIII.4.6.
Looks like we have generated a mass term for the Weyl fermion ψ and its coupling to
the scalar field ϕ, but where are the kinetic energy terms, such as ¯ψ˙α(¯σ μ)˙αα∂μψα?
Vector superfield
The kinetic energy terms contain ¯ψ˙α, which does not appear in . To get the conjugate
field ¯ψ˙α, we obviously have to use †, and so we are led to consider †. More formalism
here! We call a superfield V (x, θ, ¯θ) a vector superfield if V = V †. For example, † is a
vector superfield.
Imagine expanding † = ϕ†ϕ + . . . or any vector superfield V in powers of θ and ¯θ.
The highest power is uniquely ¯θ ¯θθθ since by the properties of Grassmannian variables the
only object we can form is ¯θ ˙1¯θ ˙2θ1θ2. Any object quadratic in θ and quadratic in ¯θ, such as
(θσ μ ¯θ)(θσμ ¯θ), can be beaten down to ¯θ ¯θθθ by using the kind of identities you discovered
in the exercises in appendix E. Let [V ]D denote the coefficient of ¯θ ¯θθθ in the expansion
of V .
Again, dimensional analysis can carry us a long way. If V has mass dimension n,
then [V ]D has mass dimension n + 2 since θ and ¯θ each has mass dimension −1
2. Let
us study how [V ]D changes under an infinitesimal supersymmetry transformation δV =
i(ξQ + ¯ξ ¯Q)V . We use the same kind of argument as before: δ([V ]D) is linear in ξ or ¯ξ,
which by dimensional analysis must multiply something with dimension n + 5
2 since [ξ] =
[¯ξ] = −1
2. This can only be the derivative ∂of something with dimension n + 3
2, namely
the coefficients of ¯θ ¯θθ and ¯θθθ in the expansion of V . We conclude that δ([V ]D) has to
have the form ∂μ(. . .), namely that δ([V ]D) is a total divergence. This is the same type of
argument that allows us to conclude that δ([]F) is a total divergence.
Thus, the action

d4x[†]D is invariant under supersymmetry.
Staring at (8), which I repeat for your convenience,
(y, θ) = ϕ(x) +
√
2θψ(x) + θθF(x)
(10)
+ iθσ μ ¯θ∂μϕ(x) −1
2θσ μ ¯θθσ ν ¯θ∂μ∂νϕ(x) +
√
2θiθσ μ ¯θ∂μψ(x)

VIII.4. Supersymmetry | 467
we see that

d4x[†]D contains

d4xϕ†∂2ϕ (from multiplying the first term in † with
the fifth term in ),

d4x∂ϕ†∂ϕ (from multiplying the fourth term in † with the fourth
term in ) ,

d4x ¯ψ ¯σ μ∂μψ (from multiplying the second term in † with the sixth term
in ), and finally

d4xF †F (from multiplying the third term in † with the third term
in ). It is quite amusing how derivatives of fields arise in supersymmetric field theories:
Note that the action

d4x[†]D does not contain derivatives explicitly.
To summarize, given a chiral superfield  we have constructed the supersymmetric
action
S =

d4x{[†]D −([W()]F + h.c.)}
(11)
Explicitly, with the choice W() = 1
2m2 + 1
3g3, we have
S =

d4x{∂ϕ†∂ϕ + i ¯ψ ¯σ μ∂μψ + F †F −(mFϕ −1
2mψψ + gFϕ2 −gϕψψ + h.c.)}
(12)
An auxiliary field
From the very beginning the field F seemed strange. Since [F] = 2 we anticipated that it
cannot have a kinetic energy term with mass dimension 4 and indeed it doesn’t. We see that
it is not a dynamical field that propagates—it is an auxiliary field (just like σ in chapter III.5
and ξμ in chapter VI.3) and can be integrated out in the path integral

DF †DFeiS. Indeed,
collect the terms that depend on F in S, namely
F †F −F(mϕ + gϕ2) −F †(mϕ† + gϕ†2) = |F −(mϕ + gϕ2)†|2 −|mϕ + gϕ2|2
So, integrate over F and F † and get
S =

d4x{∂ϕ†∂ϕ + i ¯ψ ¯σ μ∂μψ −|mϕ + gϕ2|2 + ( 1
2mψψ −gϕψψ + h.c.)}
(13)
Note that the scalar potential V (ϕ†, ϕ) = |mϕ + gϕ2|2 ≥0 in accordance with (4) and
vanishes at its minimum, giving a zero cosmological constant. Note that we are no longer
free to add an arbitrary constant to V (ϕ†, ϕ) as we could in a nonsupersymmetric field
theory.
As expected, supersymmetric field theories are much more restrictive than ordinary
field theories, and, duh, also much more symmetric. The formalism described here can
be extended to construct supersymmetric Yang-Mills theory.
Another important generalization is to introduce, instead of one supercharge Qα, N su-
percharges QI
α, with I = 1, . . . , N (exercise VIII.4.2). Since each charge QI
α transforms
like the Sz = 1
2 component of a spin 1
2 operator, it takes a state with Sz = m in a super-
multiplet to a state with Sz = m + 1
2. Thus the integer N is bounded from above. For
supersymmetric Yang-Mills theory, the maximum number of supersymmetry generators
is N = 4 if we do not want to introduce fields with spin ≥1. Similarly, the most supersym-
metric supergravity theory we could construct (exercise VIII.4.3) has N = 8.

468 | VIII. Gravity and Beyond
As mentioned in chapter VII.3, if any nontrivial 4-dimensional quantum field theory
turned out to be exactly soluble, the supersymmetric N = 4 Yang-Mills theory is probably
our best bet. In all likelihood, the first relativistic quantum field theory to be solved exactly
would be N = 4 Yang-Mills in the planar large N limit of chapter VII.4.
I hope that this brief introduction gave you a flavor of supersymmetry and will enable
you to go on to specialized treatises.
Exercises
VIII.4.1 Construct the Wess-Zumino Lagrangian by the trial and error approach.
VIII.4.2 In general there may be N supercharges QI
α, with I = 1, . . . , N . Show that we can have {QI
α, QJ
β} =
εαβZIJ, where ZIJ denotes c-numbers known as central charges.
VIII.4.3 From the fact that we do not know how to write consistent quantum field theories with fields having
spin greater than 2 show that the N in the previous exercise cannot exceed 8. Theories with N = 8
supersymmetry are said to be maximally supersymmetric. Show that if we do not want to include gravity,
N cannot be greater than 4. Supersymmetric N = 4 Yang-Mills theory has many remarkable properties.
VIII.4.4 Show that ∂θα/∂θβ = εαβ.
VIII.4.5 Work out δϕ, δψ, and δF precisely by computing δ = i(ξαQα + ¯ξ˙α ¯Q˙α).
VIII.4.6 For any polynomial W() show that [W()]F = F[dW(ϕ)/dϕ] + terms not involving F . Show that for
the theory (11) the potential energy is given by V (ϕ†, ϕ) = |∂W(ϕ)/∂ϕ|2.
VIII.4.7 Construct a field theory in which supersymmetry is spontaneously broken. [Hint: You need at least three
chiral superfields.]
VIII.4.8 If we can construct supersymmetric quantum field theory, surely we can construct supersymmetric
quantum mechanics. Indeed, consider Q1 ≡1
2[σ1P + σ2W(x)] and Q2 ≡1
2[σ2P −σ1W(x)], where the
momentum operator P = −i(d/dx) as usual. Define Q ≡Q1 + iQ2. Study the properties of the Hamil-
tonian H defined by {Q, Q†} = 2H.

VIII.5
A Glimpse of String Theory
as a 2-Dimensional Field Theory
Geometrical action for the bosonic string
In this chapter, I will try to give you a tiny glimpse into string theory. Needless to say, you
can get only the merest whiff of the subject here, but fortunately excellent texts do exist and
I believe that this book has prepared you for them. My main purpose is to show you that
perhaps surprisingly the basic formulation of string theory is naturally phrased in terms
of a 2-dimensional field theory.
In chapter I.11 I described a point particle tracing out a world line given by Xμ(τ) in
D−dimensional spacetime. Recall that the action is given geometrically by the length of
the world line
S = −m

dτ

dXμ
dτ
dXμ
dτ
(1)
and remains unchanged under reparametrization τ →τ ′(τ). Recall also that classically, S
is equivalent to
Simp = −1
2

dτ
 1
γ
dXμ
dτ
dXμ
dτ
+ γ m2

(2)
Now consider a string sweeping out a world sheet given by Xμ(τ , σ) in D-dimensional
spacetime, which we have already encountered in chapter IV.4 in connection with differ-
ential forms. In analogy with (1), Nambu and Goto proposed an action given geometrically
by the area of the world sheet
SNG = T

dτdσ

det(∂aXμ∂bXμ)
(3)
where ∂1Xμ ≡∂Xμ/∂τ, ∂2Xμ ≡∂Xμ/∂σ, and (∂aXμ∂bXμ) denotes the ab element of a 2by
2matrix. Here, as in (1), μ ranges over D values: 0, 1, . . . , D −1. The constant T (≡1/2πα′
with α′ the slope of the Regge trajectory in particle phenomenology) corresponds to the
string tension since stretching the string to enlarge the world sheet costs an extra amount
of action proportional to T .

470 | VIII. Gravity and Beyond
In a precise parallel with the discussion for the point particle, it is preferable to avoid
the square root and instead use the action
S = 1
2T

dτdσγ
1
2γ ab(∂aXμ∂bXμ)
(4)
with γ = det γab in the path integral to quantize the string. We will now show that S is
equivalent classically to SNG.
As in (2), we vary S with respect to the auxiliary variable γab, which we then eliminate.
For a matrix M, δM−1 = −M−1(δM)M−1 and δ det M = δetr log M = etr log MtrM−1δM =
(det M)trM−1δM. Thus, δγ ab = −γ acδγcdγ db and δγ = γ γ baδγab. For ease of writing,
define hab ≡∂aXμ∂bXμ. The variation of the integrand in (4) thus gives
δ[γ
1
2γ abhab] = γ
1
2[ 1
2γ dcδγcd(γ abhab) −γ acδγcdγ dbhab]
Setting the coefficient of δγcd equal to 0 we obtain
hcd = 1
2γcd(γ abhab)
(5)
where the indices on h are raised and lowered by the metric γ . Multiplying (5) by hdc (and
summing over repeated indices) we find γ abhab = 2 and thus γcd = hcd. Plugging this into
(4) we find that S = T

dτdσ(det h)
1
2. Thus, S and SNG are indeed equivalent classically.
The action (4), first discovered by Brink, Di Vecchia, and Howe and by Deser and Zumino,
is known as the Polyakov action.
Note that (5) determines γab only up to an arbitrary local rescaling known as a Weyl
transformation:
γab(τ , σ) →e2ω(τ ,σ)γab(τ , σ)
(6)
Thus, the action (4) must be invariant under the Weyl transformation.
Staring at the string action (4), you will recognize that it is just the action for a quantum
field theory of D massless scalar fields Xμ(τ , σ) in 2-dimensional spacetime with coor-
dinates (τ , σ), albeit with some unusual signs. The index μ plays the role of an internal
index, and Poincar´e invariance in our original D-dimensional spacetime now appears as
an internal symmetry. Indeed, a good deal of string theory is devoted to the study of quan-
tum field theories in 2-dimensional spacetime! It is amusing how quantum field theory
manages to stay on the stage.
To this bosonic string theory we can add fermionic variables in such a way as to make
the action supersymmetric. The result, as you surely have heard, is superstring theory,
thought by some to be the theory of everything.1
1 “To understand macroscopic properties of matter based on understanding these microscopic laws is just
unrealistic. Even though the microscopic laws are, in a strict sense, controlling what happens at the larger scale,
they are not the right way to understand that. And that is why this phrase, “theory of everything,” sounds sleazy.”—
J. Schwarz, one of the founders of string theory.

VIII.5. A Glimpse of String Theory | 471
This infinitesimal introduction to string theory is all I can give you here, but I hope that
this book has prepared you adequately to begin studying various specialized texts on string
theory.2
2 For a brief but authoritative introduction, see E. Witten, “Reflections on the Fate of Spacetime,” Physics Today,
April 1996, p. 24.

This page intentionally left blank

Closing Words
As I confessed in the preface, I started out intending to write a concise introduction to
quantum field theory, but the book grew and grew. The subject is simply too rich. As I
mentioned, after a period of almost being abandoned, quantum field theory came roaring
back. To quote my thesis advisor Sidney Coleman, the triumph of quantum field theory
was veritably “a victory parade” that made “the spectator gasp with awe and laugh with
joy.”
String theory is beautiful and marvellous, but until it is verified, quantum field theory
remains the true theory of everything. All of physics can now be said to be derivable from
field theory. To start with, quantum field theory contains quantum mechanics as a (0 + 1)-
dimensional field theory, and to end (perhaps) with, string theory may be formulated as a
(1 + 1)-dimensional field theory.
Quantum field theory can arguably be regarded as the pinnacle of human thought.
(Hush, you hear the distant howls of the mathematicians, English professors, philoso-
phers, and perhaps even a few stuck-up musicologists?) It is a distillation of basic notions
from the very beginning of the physics: Newton’s realization that energy is the square of
momentum appears in field theory as the two powers of spatial derivative. But yet—you
knew that was coming, didn’t you, with field theory set up as the pinnacle et cetera?—
but yet, field theory in its present form is in my opinion still incomplete and surely some
bright young minds will see how to develop it further.
For one thing, field theory has not progressed much beyond the harmonic paradigm, as
I presaged in the first chapter. The discovery of the soliton and instanton opened up a new
vista, showing in no uncertain terms that Feynman diagrams ain’t everything, contrary
to what some field theorists thought. Duality offers one way of linking perturbative weak
coupling theory to strong coupling, but as yet practically nothing is known of the strong
coupling regime. When speaking of renormalization groups, we bravely speak of flowing
to a strong coupling fixed point, but we merely have the boat ticket: We have little idea of

474 | Closing Words
what the destination looks like. Perhaps in the not too distant future, lattice field theorists
can extract the field configurations that dominate.
Another restriction is to two powers of the derivative, a restriction going back to Newton
as I remarked above. In modern applications of field theory to problems far beyond particle
physics, there is no reason at all to impose this restriction. For example, in studying visual
perception, one encounters field theories much more involved than those we have studied
in this book. (See the appendix for a brief description.) These field theories are Euclidean
in any case and the corresponding functional integral with higher derivatives certainly
makes sense: It is only in Minkowskian theories that we do not know how to handle
higher derivatives. Newton again—certainly economists consider the rate of change of
the acceleration as well as acceleration. Another innovative application is the formulation1
of a class of problems in nonequilibrium statistical mechanics as field theories. Typically,
various objects wander around and react when they meet. This class of problems appears
in areas ranging from chemical reactions to population biology.
We can go far beyond the restriction on the number of derivatives in the Lagrangian.
Who said that we can only have integrands of the form “exponential of a spacetime
integral”? Most modifications you can think of might immediately run afoul of some basic
principles (for example,

Dϕe−
d4xL(ϕ)−[
d4x ˜L(ϕ)]2 would violate locality), but surely
others might not. Another speculative thought I like to entertain goes along the following
line: Classical and quantum physics are formulated in terms of differential equations
and functional integrals, respectively. But how are differential equations contained in
integrals? The answer is that the integrals

Dϕe−(1/ℏ) 
d4xL(ϕ) contain a parameter ℏso
that in the limit ℏgoing to zero the evaluation of the integrals amounts to solving partial
differential equations. Can we go beyond quantum field theory by finding a mathematical
operation that in the limit of some parameter ¯k going to zero reduces to doing the integral

Dϕe−(1/ℏ) 
d4xL(ϕ)?
The arena of local field theory has always been restricted to the set of d real numbers
xμ. The recent excitement over noncommutative field theory promises to take us beyond.
(I was tempted to discuss noncommutative field theory too, but then the nutshell would
truly burst.)
But perhaps the most unsatisfying feature of field theory is the present formulation of
gauge theories. Gauge “symmetry” does not relate two different physical states, but two
descriptions of the same physical state. We have this strange language full of redundancy
we can’t live without. We start with unneeded baggage that we then gauge-fix away. We even
know how to avoid this redundancy from the start but at the price of discretizing spacetime.
This redundancy of description is particularly glaring in the manufactured gauge theories
now fashionable in condensed matter physics, in which the gauge symmetry is not there
to begin with. Also, surely the way we calculate in nonabelian gauge theories by cutting
the Yang-Mills action up into pieces and doing violence to gauge invariance will be held
1 By M. Doi, L. Peliti, J. C. Cardy, and others. See for example J. C. Cardy, cond-mat/9607163, “Renormalisation
Group Approach to Reaction-Diffusion Problems,” in: J.-B. Zuber, ed., Mathematical Beauty of Physics, p. 113.

Closing Words | 475
up to ridicule a hundred years from now. I would not be surprised if a brilliant reader of
this book finds a more elegant formulation of what we now call gauge theories.
Look at the development of the very first field theory, namely Maxwell’s theory of
electromagnetism. By the end of the nineteenth century it had been thoroughly studied and
the overwhelming consensus was that at least the mathematical structure was completely
understood. Yet the big news of the early twentieth century was that the theory, surprise
surprise, contains two hidden symmetries, Lorentz invariance and gauge invariance: two
symmetries that, as we now know, literally hold the key to the secrets of the universe. Might
not our present day theory also contain some unknown hidden symmetries, symmetries
even more lovely than Lorentz and gauge invariance? I think that most physicists would
say that the nineteenth-century greats missed these two crucial symmetries because of
their lousy notation2 and tendency to use equations of motion instead of the action. Some
of these same people would doubt that we could significantly improve our notation and
formalism, but the dotted-undotted notation looks clunky to me and I have a nagging
feeling3 that a more powerful formalism will one day replace the path integral formalism.
Since the point of good pedagogy is to make things look easy, students sometimes do
not fully appreciate that symmetries do not literally leap out at you. If someone had written
a supersymmetric Yang-Mills theory in the mid-1950s, it would certainly have been a long
time before people realized that it contained a hidden symmetry. So it is entirely possible
that an insightful reader could find a hitherto unknown symmetry hidden in our well-
studied field theories.
It is not just a matter of clearer notation and formalism that caused the nineteenth-
century greats to miss two important symmetries; it is also that they did not possess
the mind set for symmetry. The old paradigm “experiments →action →symmetry” had
to be replaced4 in fundamental physics by the new paradigm “symmetry →action →
experiments,” the new paradigm being typified by grand unified theory and later by string
theory. Surely, some future physicists will remark archly that we of the early twenty-first
century did not possess the right mind set.
In physics textbooks, many subjects have a finished completed feel to them, but not
quantum field theory. Some people say to me, what else is there to say about field theory?
I would like to remind those people that a large portion of the material in this book was
unknown 30 years ago. Of course, while I feel that further developments are possible, I
have no idea what—otherwise I would have published it—so I can’t tell you what. But let me
mention two recent developments that I find extremely intriguing. (1) Some field theories
may be dual to string theories. (2) In dimensional deconstruction a d-dimensional field
theory may look (d + 1)-dimensional in some range of the energy scale: the field theory
can literally generate a spatial dimension. These developments suggest that quantum field
2 It is said, and I agree, that one of Einstein’s great contributions is the repeated indices summation convention.
Try to read Maxwell’s treatises and you will appreciate the importance of good notation.
3 I once asked Feynman how he would solve the finite square well using the path integral.
4 A. Zee, Fearful Symmetry, chap. 6.

476 | Closing Words
theories contain considerable hidden structures waiting to be uncovered. Perhaps another
golden age is in store for quantum field theory.
So boys and girls, the parade is over, and now it’s up to you to get another parade going.5
Appendix
An image presented to the visual system can be described as a 2-dimensional Euclidean field ϕ0(x), with ϕ0
representing the gray scale from black (ϕ0 = −∞) to white (ϕ0 = +∞). [You can see that color might be included
by going to a field ⃗ϕ transforming under some internal SO(2) group for example.] The image actually perceived,
ϕ(x), is the actual image ϕ0(x) distorted to ϕ0[y(x)] plus some noise η(x). Distortion is described by a map
x →y(x) of the 2-dimensional Euclidean plane. Your brain’s task is to decide whether the actual image is ϕ0(x)
or some other ϕ1(x). Your ability to discriminate between images depends on the functional integral
Z =

Dy(x)

Dη(x)e−W[y(x)]−(1/2C) 
d2xη(x)2δ{ϕ0[y(x)] + η(x) −ϕ(x)}
(1)
=

Dy(x)e−W[y(x)]−(1/2C) 
d2x{ϕ(x)−ϕ0[y(x)]}2
where for simplicity I have taken the noise, measured by the parameter C, to be Gaussian and white. The
weighting function W[y(x)] is presumably hard wired by evolution into our visual system, telling us that certain
distortions (translations, rotations, and dilations) are much more likely than others. Writing y(x) = x + A(x) we
note that Z defines a field theory of the 2-component field Ai(x), which can always be written as Ai = ∂iη + εij∂jχ.
Note that the field Ai(x) appears “inside” an “external” field ϕ0. From symmetry considerations we might argue
that
W = −

d2x
 1
g2η∂6η + 1
f 2χ∂6χ

with two coupling constants f and g. I can give here only the briefest of sketches and refer the interested reader
to the literature.6 Clearly, one can think of other examples. This particular example serves only to show that there
are many more field theories than those described in standard texts.
5 As the Beatles said, quantum fields forever!
6 W. Bialek and A. Zee, Statistical mechanics and invariant perception, Phys. Rev. Lett. 58: 741, 1987; Under-
standing the efficiency of human perception, Phys. Rev. Lett. 61: 1512, 1988.

Part N
While quantum field theory was discovered and developed in the twentieth century, I will
introduce in this part, added in the second edition of this text, some topics that have been
worked out in the twenty-first century. At the rate these topics are rapidly evolving, I may
be quite foolish to include them here. But I am taking the plunge as I think that I would
serve my readers better by letting them have a taste of the twenty-first century rather
than expanding on the twentieth. More likely than not, by the time this second edition
is published, there will be better ways of treating the material contained here. You should
read part N in this spirit and regard what is given here as an entry key to a fast growing1
research literature.
1 Indeed, by the time the manuscript was copyedited (April 2009) it had been discovered that the amplitudes
discussed in chapters N.2–4 could be written even more simply using a twistor and dual twistor formalism. See
p. 494 and N. Arkani-Hamed, P. Cachazo, C. Cheung, and J. Kaplan, arXiv:09032110.

This page intentionally left blank

N.1
Gravitational Waves and Effective Field Theory
An unfinished symphony
One astounding prediction of Einstein gravity is the existence of ripples crisscrossing the
fabric of spacetime, what one writer refers to as Einstein’s unfinished symphony.1 Massive
detectors have been built, with more to come, in a human “curious George” effort to tune
in to the song of the cosmos.
Consider a black hole of size rS = 2Gm (its Schwarzschild radius—see chapter I.10, with
m its mass) a distance rO from another black hole, moving with velocity v. As the black
holes spiral into each other they emit gravitational waves, with a characteristic wavelength
determined by the orbital period λ = 2πrO/v. Thus the physics contains three distance
scales: rS, rO, and λ. We will stay within the simple post Newtonian regime rS ≪rO ≪λ.
Toward the end, as rO ≃rS and v ≃1, relativistic effects rear their nasty heads, from which
we will prudently stay away.
In the Closing Words to the first edition of this text, I mention that one intriguing
development over the last few decades has been the use of effective field theory to describe
situations involving more than one energy scale (or equivalently, length and time scales).
The physics at the high energy scale M is then represented in the low energy effective
Lagrangian by higher dimensional terms, suppressed by powers of M but constrained by
the symmetries we know. Examples abound in this book, from the quantum Hall effect
to surface growth to proton decay. The latter provides a classic example: while we profess
ignorance of the physics responsible for proton decay, we can nevertheless make useful
predictions by adding 4-fermion interactions invariant under the low energy gauge group
SU(3) ⊗SU(2) ⊗U(1), as shown in chapter VIII.3.
An interesting recent development is an elegant description of the emission of gravi-
tational waves by inspiraling black holes using effective field theory. Here, in contrast to
proton decay, we actually know the short distance physics involved. Effective field theory
1 M. Bartusiak, Einstein’s Unfinished Symphony.

480 | Part N
nevertheless offers an efficient and sensible way to organize and compartmentalize physics
on the various distance scales. We will merely touch upon one aspect of this approach.
Finite size objects in general relativity
Since rS ≪rO, the leading approximation would be to treat the black hole as a point particle
using the action (I.11.12) Spp = −m

dτ = −m
 gμνdXμdXν = −m

dτ

gμν ˙Xμ ˙Xν,
where ˙Xμ = dXμ/dτ. Let us now include the corrections due to the finite size of the black
hole. As you will see, the following discussion actually applies not only to black holes but
to any finite sized object, including you.
In the spirit of effective field theory, we add to Spp higher dimensional terms to be formed
out of the point particle degree of freedom ˙Xμ and the ambient gμν the particle moves in,
subject to local coordinate invariance, of course. The invariant tensors we can form out of
gμν are, to leading order, the scalar curvature R, the Ricci curvature Rμν, and the Riemann
curvature tensor Rμλνρ. You might start with the scalar curvature and the Ricci curvature,
and add to Spp the terms Sdrop =

dτ(cSR(X) + cRRμν(X) ˙Xμ ˙Xν). The curvatures R(X)
and Rμν(X) are evaluated on the worldline Xμ(τ) of the particle of course.
Einstein’s equation of motion Rμν −1
2gμνR = 0 implies Rμν(X) = 0 and thus also
R(X) = 0. Following the discussion in chapter VIII.3, we now show that, as we might
intuitively feel, we are allowed to drop Sdrop. For our problem we have the total action
S = SEH + Spp + Sdrop with the Einstein-Hilbert action (VIII.1.1) SEH =

d4x√−gM2
PR.
Under a field redefinition gμν →gμν + δgμν,
δSEH =

d4x√−gM2
P(Rμν −1
2gμνR)δgμν
(1)
Note that was how we would have derived the equation of motion for gravity, by varying gμν.
Here we are not making an arbitrary variation, but rather our goal is to choose a specific
δgμν so that the resulting δSEH negates Sdrop. Since Sdrop consists of an integral over the
worldline of the particle while δSEH is given by an integral over spacetime, we need a delta
function in δgμν to switch from one kind of integral to another. The choice
δgμν(x) =
1

−g(x)M2
P

dτδ4(x −X(τ))[agμν(X) + b ˙Xμ ˙Xν]
(2)
gives
δS =

dτ(−aR(X) + b

Rμν(X) −1
2gμνR(X)

˙Xμ ˙Xν)
(3)
So, with some appropriate values of a and b, we can indeed cancel off 2 Sdrop, thus
vindicating our intuition that the particle does not feel the Ricci and scalar curvatures
for the obvious reason that they vanish.
2 A technicality: field redefinition also induces a contact interaction of the form

dτ(1/√−g)δ4(X1(τ) −
X2(τ)) between the two massive objects. Going from field theory to the point particle description represents a
conceptual step backward, so that we should expect delta function effects at the location of the point particles.

N.1. Gravitational Waves | 481
How about terms we can construct out of the Riemann curvature tensor Rμλνρ? For your
convenience, I list its symmetry properties3 here: Rτρμν = −Rτρνμ = −Rρτμν, Rτρμν =
Rμντρ, and Rτρμν + Rτμνρ + Rτνρμ = 0. Thus, due to the antisymmetry, we are not able to
contract all four indices of Rμλνρ with ˙Xμ. We can contract at most two indices, to form
the two objects Eμν(X) ≡Rμλνρ(X) ˙Xλ ˙Xρ and Bμν(X) ≡˜Rμλνρ(X) ˙Xλ ˙Xρ, where
˜Rμλνρ(x) ≡
1
2√−g εμλσηRση
νρ(x)
denotes the dual of the curvature tensor. These are 2-indexed tensors and we need to square
them to form scalars to put into the action. Hence, to next order the particle action becomes
Sp =

dτ(−m + cEEμνEμν + cBBμνBμν + . . .)
(4)
Note that the unknown constants cE and cB have dimension of inverse mass cubed.
Before we explore the physical content of this effective action, let us understand the
meaning of E and B by retreating to the more familiar case of a point particle mov-
ing in an electromagnetic field Fμν (in flat space). Form Eμ ≡Fμν ˙Xν and Bμ ≡˜Fμν ˙Xν,
where ˜Fμν(x) ≡1
2εμνσηF ση. Going to the rest frame of the particle, where ˙X0 = 1 and
˙Xi = 0, we see that, as the notation suggests, this is just the familiar decomposition of
electromagnetism into electricity and magnetism. Similarly, Eμν and Bμν represent the
decomposition of curvature into its “electric” and “magnetic” components.
In chapter I.11 we varied the first term in (4) to obtain the standard geodesic equation
that is at the heart of Einstein’s theory. Here we obtain
d2Xρ
dτ 2 + ρ
μν(X(τ))dXμ
dτ
dXν
dτ
= f ρ(X(τ))
(5)
where f μ(X(τ)) comes from varying the E and B terms in (4). A finite sized body
experiences a tidal force f μ due to the varying gravitational force acting on it. It no longer
follows a geodesic.
The fact that we had to square the electric and magnetic components of the curvature
to form the effective action (4) means that the effects of these correction terms are highly
suppressed. Since Riemann curvature contains two derivatives, the correction terms in-
volve four derivatives. To estimate the magnitude of cE and cB we exploit a rather cute
argument as follows.
Consider the scattering of a graviton off this point particle (which, remember, is a
black hole in the problem we are studying) generated by the couplings in (4): iM ∼
. . . + icE,Bω4/M2
P + . . . where ω denotes the energy of the graviton. The powers of ω
follows from the four derivatives just mentioned. (If you don’t understand the powers
of MP you need to read chapter VIII.1 again.) Here cE,B denotes the two unknown
couplings cE ∼cB generically. Imagine calculating the total scattering cross section for
a graviton on a black hole. Squaring the amplitude M etc., we would end up with σ(ω) ∼
. . . + c2
E,Bω8/M4
P + . . ..
3 S. Weinberg, Gravitation and Cosmology, p. 141.

482 | Part N
This treatment of the black hole as a point particle is only valid for ωrS ≪1of course. The
(. . .) in iM represents diagrams we have not included, for example, the one originating
from the first term in (4) (namely the term responsible for keeping us down to earth!). A
nice feature of the argument I am about to give is that we don’t even need to know what
the terms in (. . .) are.
On the other hand, we argue that by dimensional analysis the cross section must have
the form σ(ω) = r2
Sf (ωrS) since the only length scale in the Schwarzschild metric is rS.
Expanding the unknown function f (ωrS) in powers of its argument we have σ(ω) =
. . . + αω8r10
S + . . . with α some constant. (A technical aside: the massless graviton could
produce infrared factors like log ωrS, which we ignore for our purposes.)
Requiring that the two expressions agree, we obtain cE,B ∼M2
Pr5
S. Indeed, as expected,
the couplings cE,B are highly suppressed as rS →0.
Exercise
N.1.1
Using considerations similar to those in the text, show that the scattering cross section for a photon of
frequency ω on an atom or a molecule vanishes like ω4 as ω →0, a result which, as mentioned in chapter
VIII.3, underlies the well-known explanation of why the sky is blue.

N.2
Gluon Scattering in Pure Yang-Mills Theory
Boil and toil with Feynman diagrams
You might think that after some 50 years, there could not possibly be any novelty in
calculating Feynman amplitudes. But you would be wrong. Over the last dozen years or so,
and largely since the first edition of this text, a group of intrepid searchers have found some
amazingly powerful methods of tackling Feynman diagrams. As I said at the beginning of
chapters VIII.4 and 5, I can only give you an introduction to this subject, telling you just
enough for you to explore this fast-growing literature.
To best appreciate this new development, you should do a little calculation before reading
further. Consider pure Yang-Mills theory, by consensus the nicest field theory we have,
simple to write down and perfumed with symmetries. Not even any fermions around to
mess things up. Call the gauge bosons gluons for convenience. Now calculate 5-gluon
scattering at tree level as shown in figure N.2.1. No loops, just trees. The Feynman rules
are given in chapter VII.1 and also in appendix C.
You really must calculate before reading on. I will wait for you. You think to yourself,
this is easy, just a bunch of tree diagrams. In fact, to make it easier, put all the external
gluons on-shell, that is, set p2
i = 0, i = 1, 2, . . . , 5.
This calculation is not merely an idle exercise, but is in fact phenomenologically im-
portant. At an accelerator such as the soon-to-be-operational Large Hadron Collider, two


...
Figure N.2.1

484 | Part N
Result of a brute force calculation (actually only a small part of it):
k1  k42  k11  34  5
Figure N.2.2
protons are smashed together at high energies. Two gluons, one from each proton, collide
and produce three gluons, which then materialize into three jets of hadrons. Because of
asymptotic freedom, at high energies the effective coupling g becomes small enough for
perturbative field theory to be relevant, and the tree amplitude you are busily calculating
provides a key ingredient for the phenomenological models used to study the experimental
measurements.
Time’s up! A small part of the answer is shown in figure N.2.2, taken from a lecture by
Zvi Bern.1 You really should take a look in order to appreciate, to be grateful for even, the
formalism to be explained in this chapter. You know that the amplitude is linear in each
of the five polarization vectors ϵi. The 3-gluon vertex (VII.1.11) is linear in momentum
and there are three of them in a typical diagram. Thus a typical term in the numerator
of the Feynman amplitude would be, as shown in the figure, p1 . p4ϵ2 . p1ϵ1 . ϵ3ϵ4 . ϵ5. A
rough estimate shows that there are almost 10,000 such terms. That’s why, in spite of my
admonition, you didn’t finish the calculation before reading ahead. Incidentally, you could
see that even 4-gluon scattering at tree level, though doable by hand, is rather involved.
1 Z. Bern, “Magic Tricks for Scattering Amplitudes,” http://online.itp.ucsb.edu/online/colloq/bern1/pdf/
Bern1.pdf.

N.2. Gluon Scattering | 485
New technology for Feynman diagrams
In practice, phenomenologists studying jet production have developed elaborate computer
codes based on numerical recursion and these prove to be quite efficient. In this introduc-
tory text, however, we are not after numerical efficiency but a deeper understanding of the
structure of multi-gluon amplitudes. I have set you up so that, surely, after your abortive
attempt to calculate the 5-gluon amplitude you now fully appreciate the need for new ways
of approaching Feynman diagrams. I will now explain some of the novel methods people
have invented over the last 15 years or so.
A relatively simple first step is to strip the color off the amplitude. Evidently, it is much
better to use the matrix notation of (IV.5.16) than the index notation of (IV.5.17). Instead
of the structure constants f abc and their products in the “indexed” Feynman rules in
(VII.1.11–13) we have colored Feynman rules (read appendix 1 now) with objects like
tr(T a[T b, T c]) and tr([T a, T b][T c, T d]) for the cubic and quartic coupling vertex, respec-
tively, where T a denotes the matrix representing the suitably normalized generators of the
gauge group. Denote the color matrices carried by the external gluons by T a1, T a2, . . . T an
(with n = 5 in the example you failed to do).
In calculating a multi-gluon scattering amplitude in tree approximation, you would find
each term multiplied by the product of a bunch of color traces, such as tr(T eA)tr(T eB)
where A and B denote products of T ’s. Here the index e is carried by a virtual gluon and
hence is summed over. We now use the group theoretic identity (with e summed over) for
the gauge group SU(N) [recall (IV.5.19)]
(T e)i
j(T e)k
l = 1
2

δi
lδk
j −1
N δi
jδk
l

(1)
(Here e = 1, . . . , N2 −1and the indices i, j , k, l = 1, . . . , N, of course.) The second term
takes care of the traceless condition tr T e = 0. However, we can drop it, since if we extend
the gauge group to U(N), that extra gluon does not couple to the other gluons anyway. Thus
tr(T eA)tr(T eB) = 1
2tr(AB). Repeating this procedure, we reduce the product of traces to
a single trace of n T a’s multiplied together in some specific order.
Indeed, the astute reader will have noted that had we used the double-line formalism of
figure IV.5.2, this entire discussion would not even have been necessary. As we also saw
in chapter VII.4, the double-line formalism does offer many advantages.
The other simplifying step is to specify the helicity of the gluon instead of writing
the amplitude in terms of polarization vectors. You recall, from way back when, that a
massless spin 1 particle moving along the third-direction k = ω(1, 0, 0, 1) can have helicity
h = +, corresponding to the polarization vector ϵ = 1/(
√
2)(0, 1, i, 0), or helicity h = −,
corresponding to the polarization vector ϵ = (1/
√
2)(0, 1, −i, 0). We specify the external
gluons by momentum, helicity, and color: (p1, h1, a1, p2, h2, a2, . . . , pn, hn, an).
Thus we can write the n-gluon amplitude as
M = i

permutations
tr(T a1T a2 . . . T an)A(1, 2, . . . , n)
(2)

486 | Part N
Following the literature, we have compressed the notation further and denote {pi, hi} by i.
The sum is over all possible permutations of the n gluons. We can now focus on the “color
stripped” amplitude A(1, 2, . . . , n).
First, a triviality. It is convenient to treat the gluons as all outgoing (or if you prefer, as
all incoming), so that 
i pi = 0 and the time component of some of the momenta can be
negative. We can then obtain the physically desired amplitude by crossing. Keep in mind
that under crossing p →−p and ϵ →ϵ∗, that is, the helicity flips.
The spinor helicity formalism
Now we are ready to return to the expression in figure N.2.2. The technical term for this
expression is an “unholy mess.” It turns out that the key to unraveling this hopeless morass
can be found in exercise II.3.1: that the Lorentz vector sits in the representation ( 1
2, 1
2) and
thus can be constructed as a product of two spinors, one from the representation ( 1
2, 0),
the other from (0, 1
2). You did the exercise, didn’t you? So you know how to write, for
example, the momentum vector pμ as a product of two spinors. To go on, you should also
read appendices B and E.
I am now ready to explain the spinor helicity formalism designed to exploit this peculiar
property of the Lorentz vector. Or, to say it a bit more mysteriously, I am going to show
you how to take the square root of the momentum.
Now you appreciate the power of the undotted-dotted notation introduced in appendix E.
The undotted index goes with ( 1
2, 0), and the dotted with (0, 1
2). We are looking for an object
transforming like ( 1
2, 0) ⊗(0, 1
2) to represent a vector. The problem can then be stated as
follows: instead of writing momentum as pμ, we want to write it as pα ˙α, an object carrying
an undotted and a dotted index, namely a 2 by 2 matrix in cruder language.
We merely have to flip through appendix E and look for an object carrying the desired
indices. There it is, (σ μ)α ˙α, and indeed, its μ index is begging to be contracted with pμ.
Thus, with no further work, we can write [since σ μ = (I , ⃗σ)]
pα ˙α ≡pμ(σ μ)α ˙α = (p0I −piσ i)α ˙α =
 (p0 −p3)
−(p1 −ip2)
−(p1 + ip2)
(p0 + p3)

α ˙α
(3)
We have succeeded in writing the momentum as a 2 by 2 matrix. You may recognize this
as nothing but the matrix XM (with some trivial change in notation) used in appendix B
to construct the covering of SO(3, 1) by SL(2, C).
Given two vectors p and q, their scalar product is given by
p . q = εαβε ˙α ˙βpα ˙αqβ ˙β
(4)
which you can check explicitly, writing the right-hand side as a trace and once again using
σ2σ T
i = −σiσ2, as we did in appendix E. For q = p, this reduces to p . p = εαβε ˙α ˙βpα ˙αpβ ˙β =
det p; here we recognized a definition of the determinant. [Of course, you could also eval-
uate the determinant of (3) by inspection, or recall that this was also used in appendix B.]

N.2. Gluon Scattering | 487
Clearly, there is an unavoidable notational overload: the single letter p denotes both the
vector and the matrix, but you should be able to tell from the context which object is being
referred to.
Here we are going to apply this formalism to massless gluons with lightlike momenta.
Things simplify considerably: for p lightlike, det p = 0 and thus the matrix p generically
has one 0 eigenvalue. (In fancy talk, the matrix has rank 1 rather than 2.) From elementary
linear algebra we recall that a 2 by 2 matrix m of rank 1 can always be written as mij = viwj,
with v and w two 2-component vectors, (obviously since the vector orthogonal to w provides
the 0 eigenvector.) Thus, for a lightlike vector, we can write
pα ˙α = λα˜λ˙α
(5)
in terms of two 2-component spinors λ and ˜λ.
For physical momentum, the components pμ are real, of course. I invite you to verify,
however, that everything we just did from (3) to (5) goes through even if pμ are complex.
It turns out that in the next chapters we will find it convenient to consider complex
momentum.
Upon first exposure, the formalism appears quite opaque, but actually, like a lot of
formalisms, it is fairly simple or perhaps even trivial. If you are confused at any point in
the following exposition, just work things out explicitly. For example, consider a physical
momentum with p0 = E > 0. With no loss of generality, you can choose ⃗p to point along
the third direction, so that (with a trivial abuse of notation p = | ⃗p|)
p =
 E −p
0
0
E + p

which for p lightlike collapses to the rank 1 matrix
p = 2E
 0
0
0
1

= 2E
 0
1

(0 1)
Thus, in this case, λ and ˜λ are both equal to
√
2E
 0
1

numerically. (To make sure you get it, work this out for ⃗p pointing in some other direction.)
You can think of the Pauli spinors λ and ˜λ as the “square root” of the Lorentz vector pμ.
Note how the group theory discussion in chapter II.3 foreordained this rather nontrivial
possibility. After all, there we saw how a Lorentz vector can be constructed out of two Dirac
spinors u and u′.
Interestingly, in discussing ferromagnets and antiferromagnets in chapter VI.5, we used
a poor man’s version of (3), namely ⃗n = z†⃗σz.
You learned in school that the ordinary square root has a sign ambiguity. Analogously,
in (5) p does not determine λ and ˜λ uniquely. We can always rescale λ →uλ and ˜λ →1
u ˜λ
for any complex number u. (You might have wondered what fixed the overall constant in
λ and ˜λ in the simple example above: I made an arbitrary choice.)

488 | Part N
For real momentum, the matrix pα ˙α = pμ(σ μ)α ˙α is hermitean, which implies that ˜λ = λ∗
is the complex conjugate of λ. The spinor ˜λ is not independent of λ, and so the rescaling
parameter u is restricted to be a phase factor eiγ. [Also, recall from appendix B how XM
transforms under SL(2, C) and you will see that it is all consistent.] In this case, the
condition that p has rank 1 allows for two solutions: pα ˙α = ±λα˜λ˙α, with the two possible
signs corresponding to whether p0 > 0 or not.
A side remark at this point: We will see that it is useful to consider the group SO(2, 2)
instead of the Lorentz group SO(3, 1). Thus, as the discussion in appendix B indicates,
you can also take the square root of an SO(2, 2) vector and write pα ˙α = λα˜λ˙α, but with λ
and ˜λ two independent real spinors, as is consistent with the local isomorphism between
SO(2, 2) and SL(2, R) ⊗SL(2, R). The rescaling mentioned above is now restricted to u
being a real number.
It is instructive to count the number of real degrees of freedom for these different
cases. A complex lightlike momentum depends on 4 × 2 −2 = 6 real numbers, since the
condition p2 now amounts to two real conditions, while λ and ˜λ each contains 2 complex
numbers, but with rescaling we are left with 2 × 2 −1 = 3 complex numbers, that is, 6
real numbers. A real lightlike momentum depends on 4 −1 = 3 real numbers, but now
˜λ is tied to λ containing 2 complex numbers, which get reduced to 3 real numbers after
rescaling by a phase factor. For a (real) lightlike vector transforming under SO(2, 2), we
have 2 real spinors, which after rescaling contains 3 real numbers. So it all works out, of
course.
I mention all this here for future use. It should be evident to you, for the rest of
this chapter, which statements hold for complex momenta and which hold only for real
momenta. At the end of the day, when we arrive at a physical quantity, such as the
amplitude, we will of course set the momenta contained therein to be real.
For two lightlike vectors p and q, write pα ˙α = λα˜λ˙α and qα ˙α = μα ˜μ˙α, then we have
p . q = (εαβλαμβ)(ε ˙α ˙β ˜λ˙α ˜μ ˙β) ≡⟨λ, μ⟩[˜λ, ˜μ]
(6)
Here we have defined the two Lorentz invariants
⟨λ, μ⟩≡εαβλαμβ = −⟨μ, λ⟩
(7)
and
[˜λ, ˜μ] ≡ε ˙α ˙β ˜λ˙α ˜μ ˙β = −[ ˜μ, ˜λ]
(8)
(treating the spinors as c-number objects.) Note in passing that with our convention,
λ1 = λ2 and λ2 = −λ1, and so ⟨λ, μ⟩= −λ1μ2 + λ2μ1 = −εαβλαμβ.
We have already verified in (E.13) that ⟨λ, μ⟩is invariant, but for the sake of total
pedagogical clarity let us check it once more, this time using infinitesimal transformations.
Write (E.4) more compactly as δλα = σ β
α λβ, where σ denotes some linear combination
of Pauli matrices. Noting that ⟨λ, μ⟩is nothing but λσ2μ up to some irrelevant overall
constant, we have indeed δ(λσ2μ) = (λσ T σ2μ + λσ2σμ) = 0.
A notational remark: the twiddles in [˜λ, ˜μ] are redundant. The square bracket is defined
only for spinors transforming like (0, 1
2). Henceforth, we will write [λ, μ] ≡ε ˙α ˙β ˜λ˙α ˜μ ˙β.

N.2. Gluon Scattering | 489
For real physical momenta, ˜λ = λ∗so that ⟨λ, μ⟩= [λ, μ]∗. Then p . q = ⟨λ, μ⟩[λ, μ]
implies that ⟨λ, μ⟩= √p . qeiφ and [λ, μ] = √p . qe−iφ, with some phase factor eiφ. We
thus conclude that the two spinorial products may be regarded as the (two) square roots
of the Lorentz dot product p . q up to a phase factor.
You could now raise an interesting question: how do we write the polarization vectors
ϵ(p) of a massless gluon?
The requirement that ϵ(p) . p = 0 can be satisfied, according to (4), by setting ϵα ˙α =
d−1λα ˜μ˙α, for an arbitrary ˜μ˙α and with the factor d determined as follows. We require that,
for an arbitrary complex number w, scaling ˜μ →w ˜μ does not change ϵ (since ˜μ is arbitrary
after all). Thus d has to be linear in ˜μ. The further requirement that d be Lorentz invariant
implies, as we just learned, that d = [x, μ], where ˜x is some (0, 1
2) spinor. The only spinor
available is ˜λ and hence we obtain
ϵ−
α ˙α = λα ˜μ˙α
[λ, μ]
(9)
By convention, we will call this polarization negative helicity.
The arbitrary choice of ˜μ˙α represents the freedom inherent in a gauge theory. Indeed,
we see that gauge transformation corresponds to the spinorial shift ˜μ →˜μ + y˜λ (for some
arbitrary number y) under which ϵα ˙α →ϵα ˙α + yλα˜λ˙α, which translates into the usual shift
of ϵ by some multiple of p.
The positive helicity polarization is given by the other possible choice
ϵ+
α ˙α = μα˜λ˙α
⟨μ, λ⟩
(10)
Check that it works. Gauge transformation now corresponds to the shift μ →μ + yλ. Note
that the polarization vectors are normalized as ϵ+ . ϵ−= ⟨μλ⟩[μλ]/(⟨μλ⟩[μλ]) = 1.
Taming the unholy mess
Consider the tree-level scattering amplitude with n ≥4 outgoing massless gluons. (In this
and the next sections, we can take all momenta to be real.) The color-stripped amplitude
is then characterized by a string of helicities (h1, . . . , hn). Take for example the amplitude
with (+ + + . . . + +). Upon crossing, it describes two gluons, each with helicity −, going
into n −2 gluons all with helicity +. Both incoming gluons flip their helicity and thus
this amplitude is said to be maximal helicity violating. Your intuition may tell you that
this amplitude ought to be suppressed, since highly energetic massless particles tend to
maintain their helicities. If you try to verify this using traditional Feynman diagrams, you
would once again encounter a big mess.
The spinor helicity formalism rides to the rescue. Consider the amplitude A(h1, . . . , hn).
For each of the n gluons, we have piα ˙α = λiα˜λi ˙α, and an arbitrary spinor that we are
free to choose (subject to some conditions), namely either μiα or ˜μi ˙α, depending on
whether the corresponding helicity is + or −, respectively. There are quite a few indices,
but fortunately, in computing amplitudes, we encounter only Lorentz invariants, such as

490 | Part N
ϵi . ϵj = εαβε ˙α ˙βϵiα ˙αϵjβ ˙β (be sure to distinguish between the two varieties of epsilon here!),
and thus the spinor indices will be contracted over and disappear. In particular, we have
(omitting the comma in the angled and square brackets)
ϵ+
i . ϵ+
j =
⟨μiμj⟩[λiλj]
⟨μiλi⟩⟨μjλj⟩
(11)
ϵ−
i . ϵ−
j =
⟨λiλj⟩[μiμj]
[λiμi][λjμj]
(12)
ϵ−
i . ϵ+
j =
⟨λiμj⟩[μiλj]
[λiμi]⟨μjλj⟩
(13)
We also list for convenience
ϵ+
i . pj =
⟨μiλj⟩[λiλj]
⟨μiλi⟩
(14)
and
ϵ−
i . pj =
⟨λiλj⟩[μiλj]
[λiμi]
(15)
Evidently, in this formalism, flipping helicity corresponds to interchanging the brackets
⟨. . .⟩and [. . .].
We need one more important observation. Obviously, in a tree-level diagram for n-gluon
scattering, you cannot have as many 3-gluon vertices as you like. Draw the tree diagrams
for n = 4 for example (see figure N.2.3). The number of 3-gluon vertices could be either
0 or 2. In general, the number of 3-gluon vertices can be at most n −2. You are asked to
verify this in exercise N.2.2. As remarked earlier, while the 4-gluon vertex does not involve
momentum, the 3-gluon vertex is linear in momentum. Thus, in the numerator of the
Feynman amplitude, we have n polarization vectors ϵi but at most n −2 momenta. We are
to form a scalar out of these Lorentz vectors by taking dot products. Clearly, there are at
least two polarization vectors who have to dance with each other. Therefore we conclude
that the tree amplitude must contain at least one power of ϵi . ϵj. (In the n = 5 case that
power was actually 2, as we saw.)
Now we are ready to rock. For the amplitude A(+ + . . . +) (suppressing the momentum
labels), we simply choose the spinors μi representing the gauge degrees of freedom to all
be equal. Then all dot products ϵ+
i . ϵ+
j between polarization vectors vanish according to
(11). But we just argued that the tree amplitude must contain at least one power of ϵi . ϵj.
Remarkably, we have shown that the maximal helicity-violating amplitude vanishes for any
n! Our intuition suggested that these amplitudes are suppressed, but in fact they vanish.
What about the next-to-maximal helicity-violating amplitudes with one negative helicity,
namely A(−+ + . . . + +)? Label the gluon with negative helicity as 1. Once again, for
i = 2, . . . n, choose μi all equal to λ1. Then ϵ+
i . ϵ+
j ∝⟨μiμj⟩= 0, for i, j ̸= 1. Furthermore,
ϵ−
1 . ϵ+
i ∝⟨λ1μi⟩= ⟨λ1λ1⟩= 0 for i ̸= 1. The amplitude A(−+ + . . . + +) also vanishes!
Clearly, this “cheap” trick of exploiting gauge freedom no longer works for the next
amplitude with two negative helicities. To see why the trick does not work any more, look
at A(−−+ . . . + +) for instance. Once again we could, for i = 3, . . . n, choose μi all equal

N.2. Gluon Scattering | 491
(a)
3
2
4
1
3
2
4
1
3
2
4
1
(b)
(c)
Figure N.2.3
so that ϵ+
i . ϵ+
j = 0 for i, j ≥3, but then we don’t have enough freedom to make all the other
polarization dot products vanish. In fact, at some point, we better have some nonvanishing
amplitudes. In the literature, these amplitudes with two negative helicities are called
maximal helicity-violating amplitudes. Upon crossing two of the gluons, they describe
two gluons producing n −2 gluons, with helicities ++ →+ + . . . +, −+ →−+ . . . +,
and −−→−−+ . . . +.
Explicit calculation of A(1,2,3,4)
The n = 4 case is the simplest. Take a deep breath and try to calculate A(1−, 2−, 3+, 4+)
and A(1−, 2+, 3−, 4+). For 4-gluon scattering these two are the only nonvanishing tree
amplitudes, since by parity the amplitudes with three minuses are related to the amplitudes
with three pluses (which we know vanish), and so on.
The bad news is that the calculation is fairly involved. The good news is that we can still
exploit gauge freedom mercilessly and that the final answer is surprisingly simple.
Tackle A(1−, 2−, 3+, 4+) first. The relevant diagrams are shown in figure N.2.3. Let us
simplify the notation as much as possible: write ⟨12⟩= ⟨λ1λ2⟩, [12] = [λ1λ2], and so forth.
Now we need the colored Feynman rules in the form given in appendix 1. In line with
the preceding discussion let us choose ˜μ1 = ˜μ2 = ˜λ3 and μ3 = μ4 = λ2. Then all but one
of the polarization dot products vanish. For instance, ϵ−
2 . ϵ+
3 ∝⟨λ2μ3⟩[μ2λ3] ∝⟨λ2λ2⟩= 0.
The only nonzero product is ϵ−
1 . ϵ+
4 = ⟨λ1μ4⟩[μ1λ4]/([λ1μ1]⟨μ4λ4⟩) = ⟨12⟩[34]/([13]⟨24⟩),
where the second equality follows from our gauge choice. This implies that the quartic
diagram N.2.3a vanishes, since it involves the product of two polarization dot products.
We notice that there are only two more diagrams (fig. N.2.3b,c) rather than three. With
the traditional Feynman rules there is a diagram with 1 and 3 on the same cubic vertex.
Here we see another advantage of color stripping. We are looking at the coefficient of
tr(T a1T a2T a3T a4). The diagram we just described has T a1 next to T a3 and so does not
contribute to this particular color ordering.
Next, the diagram in figure N.2.3b vanishes. Look at the cubic vertex involving 2, 3, and
v (for the virtual gluon): (ϵ2 . ϵ3ϵv . p2 + ϵ3 . ϵvϵ2 . p3 + ϵv . ϵ2ϵ3 . pv), with ϵv understood
as a “placeholder” to be contracted with the ϵ∗
v from the other cubic vertex. The first term

492 | Part N
vanishes because ϵ2 . ϵ3 = 0, the second term because ϵ2 . p3 ∝[μ2λ3] = [λ3λ3] = 0, and the
third term because ϵ3 . pv = −ϵ3 . (p2 + p3) = −ϵ3 . p2 ∝⟨μ3λ2⟩= ⟨λ2λ2⟩= 0. Our gauge
choice was wise indeed!
Only one diagram (fig. N.2.3c) left to calculate. The cubic vertex (ϵ1 . ϵ2ϵv . p1 + ϵ2 . ϵvϵ1 .
p2 + ϵv . ϵ1ϵ2 . pv) is to be contracted with the other cubic vertex (ϵ3 . ϵ4ϵ∗
v . p3 + ϵ4 . ϵ∗
vϵ3 .
p4 + ϵ∗
v . ϵ3ϵ4 . (−pv)). In each of these vertices, the first term vanishes, since the only
nonzero polarization product is ϵ1 . ϵ4. To obtain the amplitude we replace the polarization
product ϵρ
v ϵω∗
v for the placeholder by the propagator −igρω/(p1 + p2)2 = −igρω/(2p1 . p2).
Again, since all but one of the polarization dot products vanish, only one term survives
the contraction with gρω. We obtain A(1−, 2−, 3+, 4+) = ϵ1 . ϵ4ϵ2 . p1ϵ3 . p4/p1 . p2.
Since we are after conceptual understanding more than anything else, now and hence-
forth, in this and the next two chapters, we will suppress overall factors to keep various
expressions as uncluttered as possible.
We have already calculated ϵ1 . ϵ4, so it remains to evaluate ϵ2 . p1 = ⟨21⟩[31]/[23], ϵ3 .
p4 = ⟨24⟩[34]/⟨23⟩, and p1 . p2 = ⟨12⟩[12]. Thus A = ⟨12⟩[34]2/([12][23]⟨23⟩).
We can now use various identities to write this in a more symmetric form. First, momen-
tum conservation gives 
i p(i)
α ˙α = 
i λ(i)
α ˜λ(i)
˙α = 0. Multiplying this by εβαε ˙α ˙γλ(j)
β ˜λ(k)
˙γ we ob-
tain 
i⟨ji⟩[ik] = 0 for any j and k. Second, we have ⟨34⟩[34] = p3 . p4 = p1 . p2 = ⟨12⟩[12].
Finally, the spinors can be regarded as 2-dimensional vectors and so any two spinors μ and
ν span the space. Thus a third spinor λ can always be expanded as a linear combination of
the other two, viz, λ = (⟨λν⟩μ −⟨λμ⟩ν)/⟨μν⟩, with the coefficients determined easily by
contracting with μ and ν. Contracting with a fourth spinor η then yields
⟨λη⟩⟨μν⟩= ⟨λν⟩⟨μη⟩−⟨λμ⟩⟨νη⟩
(16)
known as the Schouten identity.
Using these identities we now massage A into shape. Multiply the numerator and
denominator of A by ⟨34⟩to obtain ⟨12⟩2[34]/(⟨23⟩⟨34⟩[23]). Next, multiply the numerator
and denominator by ⟨12⟩2. In the denominator write ⟨12⟩[23] = −⟨14⟩[43]. Finally, we
obtain (suppressing overall phase factors, as promised)
A(1−, 2−, 3+, 4+) =
⟨12⟩4
⟨12⟩⟨23⟩⟨34⟩⟨41⟩= p1 . p2
p2 . p3
(17)
Compare this with figure N.2.2. You should be impressed, even though here we are doing
the n = 4 rather than the n = 5 case.
Recall that we have another amplitude A(1−, 2+, 3−, 4+) yet to calculate, in which the
two negative-helicity gluons are not adjacent in color. You should work this out as an
exercise, but it turns out that we can use a trick. Write the analog of (2) for 4-gluon scattering
M = i

permutations
tr(T a1T a2T a3T a4)A(1−, 2+, 3−, 4+)
(18)
We have already remarked that if we extend the gauge group from SU(N) to U(N), the
extra gluon (known in the literature, perhaps confusingly, as the “photon”) does not couple
to the other gluons (because the couplings in Yang-Mills theory all involve commutators;
see appendix 1.) Thus if we replace, say T a2, by the identity matrix, the entire sum should
vanish. The six terms in the sum then break up into two groups, multipled by either

N.2. Gluon Scattering | 493
tr(T a1T a3T a4) or tr(T a1T a4T a3). Since the two traces are independent, the two groups
vanish separately. The traces in the three terms tr(T a1T a2T a3T a4)A(1−, 2+, 3−, 4+) +
tr(T a1T a3T a2T a4)A(1−, 3−, 2+, 4+) + tr(T a1T a3T a4T a2)A(1−, 3−, 4+, 2+)
all
become
tr(T a1T a3T a4). We thus obtain the so-called photon decoupling identity A(1−, 2+, 3−, 4+)
+A(1−, 3−, 2+, 4+) + A(1−, 3−, 4+, 2+) = 0, relating the desired amplitude to two ampli-
tudes already known from (17). Thus
A(1−, 2+, 3−, 4+) = −(A(1−, 3−, 2+, 4+) + A(1−, 3−, 4+, 2+))
= −⟨13⟩4

1
⟨13⟩⟨32⟩⟨24⟩⟨41⟩+
1
⟨13⟩⟨34⟩⟨42⟩⟨21⟩

=
⟨13⟩4
⟨12⟩⟨23⟩⟨34⟩⟨41⟩
(19)
where we used the Schouten identity.
Remarkably, the two amplitudes A(1−, 2−, 3+, 4+) and A(1−, 2+, 3−, 4+) have the same
form. It is tempting to conjecture that for n-gluon scattering, the maximal helicity-violating
amplitudes in which two of the gluons carry negative helicity and the rest positive helicity
is given by the elegant expression (for n ≥4)
A(1+, 2+, . . . j−, . . . , k−. . . n+) =
⟨jk⟩4
⟨12⟩⟨23⟩⟨34⟩. . . ⟨(n −1)n⟩⟨n1⟩
(20)
This conjecture was first put forward by Parke and Taylor and proved by Berends and Giele
(using an off-shell recursion method and a precursor to the on-shell recursion method to
be explained in the next chapter.) We will prove it in the next chapter.
Meanwhile, we note that one way of arguing for the conjecture’s validity is to verify
that the proposed amplitude satisfies all the symmetry requirements. Besides Lorentz
invariance (obviously satisfied), amplitudes at tree level in a massless theory like pure
Yang-Mills should also satisfy scale and conformal invariance.
One interesting check is to count, for each i, the powers of λi minus the powers of ˜λi.
Call this quantity i. Then since momentum has the form ∼λ˜λ, it contributes 0 to i. In
contrast, for negative helicity ϵ−
α ˙α = λα ˜μ˙α/[λ, μ] ∼λ/˜λ. For positive helicity we have the
opposite: ϵ+
α ˙α = μα˜λ˙α/⟨μ, λ⟩∼˜λ/λ. Thus we have i = −2hi.
We checked that indeed, in (20), we have i = 2 for i = j , k and i = −2 for i ̸= j , k.
Keeping track of i during the calculation also provides us with a useful check.
Note that the n = 5 scattering amplitude, which we started this chapter with, is
completely determined, since there are only two independent nonzero amplitudes:
A(1−, 2−, 3+, 4+, 5+) and A(1−, 2+, 3−, 4+, 5+).
Further developments
The astonishing simplicity of (20) has sparked a surge of interest and further develop-
ments. Here I will be content to mention some of them.
Once the tree amplitudes are done, one can calculate loop amplitudes by using a
more sophisticated version of the unitarity methods and of the Cutkosky cutting rules
of chapter II.8. Proceeding in this way, various authors have bootstrapped their way up to

494 | Part N
multiloop amplitudes. While the actual computational labor can quickly get out of hand,
it is still enormously less than the labor needed with traditional Feynman methods.
What about the basic cubic vertex of the theory? We will work it out in appendix 2 and
show that it fits nicely into the form in (20) with one important caveat.
Surely you, the astute reader, feel that there must be some deep reason for the aston-
ishing simplification from the mess in figure (1) to the elegant expression in (20). Indeed,
tree amplitudes in gauge theories (and in gravity) turn out to be even simpler when writ-
ten in terms of the twistors studied by Penrose decades ago. As this exciting development2
occurred while this book was going to press, I have to balance my desire to make the book
as up-to-date as possible against pagination constraints. Thus I can provide here only an
ultra-concise (and hence perhaps somewhat cryptic) key to the literature, giving you no
more than a flavor of what is involved.
Include the momentum conservation delta function with the amplitudes of the type
studied here and define M(. . . , λi, ˜λi, . . .) ≡A(λ, ˜λ)δ(4)(n
j=1 λj ˜λj). Due to space con-
straints, I will suppress the kinematic dependence of M on all but the particle i and write
simply M(λi, ˜λi). Let us Fourier transform M in two possible ways (and overuse the letter
M somewhat):
M(Wi) =

d2λi exp(i ˜μα
i λiα)M(λi, ˜λi).
(21a)
and
M(Zi) =

d2˜λi exp(iμ˙α
i ˜λi ˙α)M(λi, ˜λi).
(21b)
where W ≡( ˜μ, ˜λ) and Z ≡(λ, μ) denote two 4−component objects which may be re-
garded for the time being as column “vectors.” The intent here is to transform M se-
quentially for i = 1, 2, . . . n using either (21a) or (21b). Consider SO(2, 2) here instead of
SO(3, 1), so that the spinors λ and ˜λ are real, and hence we can take μ and ˜μ to be real
as well. Thus, these integral transforms are no more and no less than the Fourier trans-
forms you have long been familiar with, and the variable μ is conjugate to the variable ˜λ
in the same sense that p is conjugate to q in quantum mechanics. The objects W and Z,
known as a twistor and a dual twistor and conjugate to each other, each consisting of 4
real components, naturally transform under the group SL(4, R) (namely the set of all 4 by
4 matrices with real entries and unit determinant), with the invariant W . Z = ˜μλ + ˜λμ.
Given more than one W’s and Z’s we also have the Lorentz invariants Z1IZ2 ≡< λ1, λ2 >
and W1IW2 ≡[λ1, λ2]. (Here I, in a slightly abused notation used in the literature, evidently
denotes the 4 by 4 matrix containing the 2 by 2 identity matrix either in its upper left corner
or in its lower right corner depending on whether it acts on W or Z, with all other entries
equal to zero.)
We have (displaying the helicity h of particle i while suppressing the index i) M(tW , h) =

d2λ exp(it ˜μλ)M(λ, t ˜λ, h) = t−2 
d2λ′ exp(i ˜μλ′)M(t−1λ′, t ˜λ, h) = t2(h−1)M(W , h)
where we used the observation earlier that  = −2h, namely that M(t−1λ, t ˜λ) =
t2hM(λ, ˜λ). Similarly, M(tZ, h) = t−2(h+1)M(Z, h). This scaling result, which you realize
comes from the little group (see p. 186), indicates that we should favor a mixed or am-
2 The literature on twistors could be traced starting with the paper mentioned on p. 477.

N.2. Gluon Scattering | 495
bitwistor representation for the scattering amplitude, using W when the particle carries
+ helicity and Z when the particle carries −helicity.
For example, for the basic Yang-Mills cubic vertex with helicities (+ + −) (see appendix
2) we write M(W +
1 , W +
2 , Z−
3 ). The scaling relation just derived imposes powerful con-
straints on this amplitude, namely M(W1, W2, Z3) = M(tW1, W2, Z3) = M(W1, tW2, Z3) =
M(W1, W2, tZ3), which implies that in the ambitwistor representation the defining ver-
tex for Yang-Mills theory is apparently, up to an irrelevant overall constant, just 1! More
precisely, M(W1, W2, Z3) depends on the three possible invariants W1 . Z3, W2 . Z3, and
W1IW2. The scaling relations (note that t could be either positive or negative) then force
M to have the amazingly simple form
M(W +
1 , W +
2 , Z−
3 ) = sign(W1 . Z3)sign(W2 . Z3)sign(W1IW2)
In different kinematic regions, the basic Yang-Mills vertex is numerically equal to ±1.
Tree amplitudes live naturally in ambitwistor space. As another example, the 4-gluon
scattering amplitude (19) we worked hard to get becomes simply
M(W +
1 , Z−
2 , W +
3 , Z−
4 ) = sign(W1 . Z2)sign(Z2 . W3)sign(W3 . Z4)sign(Z4 . W1)
Let’s anticipate a bit and write the basic cubic vertex for gravity to be given in (N.3.20)
in this ambitwistor representation. Indeed, the scaling relations derived above could
be immediately applied to the graviton, for which h = ±2. We obtain M(tW , ++) =
t2M(W , ++) and M(tZ, −−) = t2M(Z, −−), thus immediately fixing the cubic vertex
for gravity to be
M(W ++
1
, W ++
2
, Z−−
3
) = |(W1 . Z3)(W2 . Z3)(W1IW2)|
Going from Yang-Mills to Einstein-Hilbert, we merely have to replace the sign function by
the absolute value!
Clearly, the take-home message is that quantum field theory possesses hidden structures
that the traditional Feynman diagram approach would likely have no hope of uncovering.
Appendix 1: Colored Feynman rules for Yang-Mills theory
Using the double line formalism of chapter IV.5, we can draw the cubic and quartic vertices in Yang-Mills theory
as in figure IV.5.2. Our conventions for the generators of SU(N) are [T a, T b] = if abcT c and tr(T aT b) = 1
2δab.
Thus f abc = −2itr([T a, T b]T c). Start with the Feynman rule for the quartic vertex given in chapter VII.1 and
appendix C. First, f abef cde = −4tr([T a, T b][T c, T d]). Next we multiply by polarization vectors and obtain the
colored rule for the quartic vertex:
4ig2tr(T aT bT cT d)(ϵ1 . ϵ2ϵ3 . ϵ4 −ϵ4 . ϵ1ϵ2 . ϵ3)
(22)
The two other terms are obtained by permutation. Similarly, the cubic vertex in (C.18) becomes (with a trivial
change k →p)
−4igtr(T aT bT c)(ϵ1 . ϵ2ϵ3 . p1 + ϵ2 . ϵ3ϵ1 . p2 + ϵ3 . ϵ1ϵ2 . p3)
(23)
As described in the text, we can now strip off the color factors tr(T aT bT c) and tr(T aT bT cT d).
Color stripped amplitudes satisfy a number of useful identities. For example, the color stripped amplitude for
n-gluon scattering satisfies the reflection identity A(1, 2, . . . , n) = (−1)nA(n, . . . , 2, 1). To show this, note that
the stripped quartic vertex (ϵ1 . ϵ2ϵ3 . ϵ4 −ϵ4 . ϵ1ϵ2 . ϵ3) does not change sign under the reflection 1234 →4321,
while the stripped cubic vertex changes sign under 123 →321. From exercise N.2.2, V3 + 2V4 = n −2, and thus
V3 is odd or even according to whether n is odd or even.

496 | Part N
Appendix 2: The cubic vertex in the spinor helicity formalism
A rather natural question to ask is what the cubic vertex (23) looks like in the spinor helicity formalism.
The first observation is that if we put all momenta on shell, p2
1 = p2
2 = p2
3 = 0, then the cubic vertex actually
vanishes. By momentum conservation, we have p2
1 = (p2 + p3)2 = p2 . p3 = 0. The conditions pi . pj = 0 then
imply all three lightlike momenta point in the same direction, so that pi = Ei(1, 0, 0, 1), i = 1, 2, 3. But this
means that, for example, ϵ3 . p1 ∝ϵ3 . p3 = 0, and thus the cubic vertex (23) vanishes.
Now you see the motivation for allowing the momenta to be complex. Then the conditions pi . pj = 0 no
longer force all three lightlike momenta to point in the same direction, and we can have a nonvanishing cubic
vertex on shell. As explained in the text, to complexify momentum, we simply remove the constraint ˜λ = λ∗. By
the way, by complexifying the momenta here, we are anticipating the discussion in the next chapter a bit.
As always, we are free to choose the μ spinors to our advantage. A good choice here is μ1 = μ2 and μ3 =
λ1. Referring to (12) and (13), we then have ϵ−
1 . ϵ−
2 ∝[μ1μ2] = 0 and ϵ−
1 . ϵ+
3 ∝⟨λ1μ3⟩= 0. The cubic vertex
collapses to
A(1−, 2−, 3+) = ϵ−
2 . ϵ+
3 ϵ−
1 . p2 =
⟨λ2μ3⟩[μ2λ3]
[λ2μ2]⟨μ3λ3⟩
 ⟨λ1λ2⟩[μ1λ2]
[λ1μ1]

= ⟨12⟩2
⟨13⟩
[μ1λ3]
[μ1λ1]
(24)
As in the text, we are ignoring all overall factors.
To get rid of the unphysical μ1, we need a variant of the momentum conservation identity given in the text.
Multiplying 
i p(i)
α ˙α = 
i λ(i)
α ˜λ(i)
˙α = 0 by εβαε ˙α ˙γ λ(j)
β ˜μ ˙γ , we obtain 
i[μλi]⟨λiλj⟩= 0 for any j, which for j = 2
implies [μ1λ3]⟨λ3λ2⟩= −[μ1λ1]⟨λ1λ2⟩.
Multiplying (24) by ⟨λ3λ2⟩/⟨λ3λ2⟩and applying the identity just derived we finally obtain the “mostly minus”
cubic vertex
A(1−, 2−, 3+) =
⟨12⟩4
⟨12⟩⟨23⟩⟨31⟩
(25)
Satisfyingly, we have obtained an expression consistent with (20) (which we have not yet proven) but keep in
mind that (25) holds only for complex momenta. I leave it to you to obtain the “mostly plus” cubic vertex
A(1+, 2+, 3−) =
[12]4
[12][23][31]
(26)
which also follows from the rule about flipping helicities stated in the text.
What about the “all plus” and “all minus” vertices? By now you should be able to determine them as a simple
exercise.
Exercises
N.2.1
Work out the two polarization vectors for general μ and ˜μ for a gluon moving along the third direction.
N.2.2
Show that the number of cubic vertices in tree-level n-gluon scattering can be at most n −2.
N.2.3
Show that the result in (17) satisfies the reflection identity A(1−, 2−, 3+, 4+) = A(4+, 3+, 2−, 1−).
N.2.4
Show that the “all plus” and “all minus” cubic Yang-Mills vertices (see appendix 2) vanish. [Hint: Choose
the μ spinors wisely.]
N.2.5
Why doesn’t the argument in the text that A(−+ + . . . + +) vanish apply to A(−+ +)?
N.2.6
Insert the expression for the cubic vertex into (21) and derive M(W +
1 , W +
2 , Z−
3 ).
N.2.7
Show that M(W +
1 , Z−
2 , W +
3 , Z−
4 ) reproduces (19).
N.2.8
Show that SL(4, R) is locally isomorphic to the conformal group. [Hint: Identify the 15 = 42 −1 genera-
tors of the conformal group (3 rotations J i, 3 boosts Ki, 1 dilation D, 4 translations P μ, and 4 conformal
transformations Kμ) with the 15 traceless real 4 by 4 matrices.]

N.3
Subterranean Connections in Gauge Theories
Excess baggage
This text, like all texts on field theory, sings the praise of gauge theories—hey, Nature loves
them regardless of what physicists like—but, unlike many texts, emphasizes repeatedly
that gauge symmetry is strictly speaking not a symmetry, but a redundancy in description.
Extra degrees of freedom are introduced only to be gauge fixed away. In the first edition of
this book, I expressed in the Closing Words the hope that in the future physics will find
a more elegant way of formulating this peculiar concept of local invariance. Perhaps that
hope is being realized sooner rather than later!
In our current formulation of gauge theories, for a process involving n massless gauge
bosons (photons or gluons) we are instructed to laboriously calculate an off-shell amplitude
Mμ1μ2...μn.
But experimentalists don’t know about amplitudes carrying Lorentz indices! SE from
chapter III.1 speaks up again. “My gauge bosons are specified by their helicities hi, i =
1, . . . n, not a Lorentz index.”
Come to think of it, we theorists do go through a strange two-step procedure involving
a lot of excess baggage. After toiling to obtain Mμ1μ2...μn with external momenta off
shell, we then set external momenta on shell and contract with polarization vectors to
determine the scattering amplitude for gluons in specified polarization states Mλ1λ2...λn ≡
ϵλ1
μ1ϵλ2
μ2 . . . ϵλn
μnMμ1μ2...μn|onshell. In effect, in step 2 we wash away much of the unnecessary
information in Mμ1μ2...μn we worked hard to get in step 1.
The cancellation in the 5-gluon scattering in the preceding chapter, with ∼10,000 terms
boiling down to a single term, should have convinced you that the traditional Feynman
way may not be so good. In your study of physics, you surely have had the pleasure of
watching terms canceling against each other toward the end of a calculation, but 10,000
terms down to 1, that was the mother of all cancellations.
The key is that in gauge theories there is a kind of secret subterranean connection
between different Feynman diagrams, and cancellations are routine. Gauge invariance tells

498 | Part N
us that p1
μ1(ϵ2
μ2 . . . ϵn
μnMμ1μ2...μn|onshell), for example, vanishes. Thus, the many diagrams
that go into Mμ1μ2...μn must know about each other in some intricate way. (We saw a
glimpse of that way back in chapter II.7 when we proved gauge invariance.)
The S-matrix reloaded
In spite of the tremendous difficulties lying ahead, I feel
that S-matrix theory is far from dead and that . . . much
new interesting mathematics will be created by attempting
to formalize it.
—T. Regge1
The garbage of the past often becomes the treasure of the
present (and vice versa).
—A.Polyakov2
As discussed in chapter III.8, back in the 1950s and 1960s, dispersion theorists3 tried
to forge ahead by studying the analytic properties of various amplitudes as functions
of their external Lorentz invariants, namely the Mandelstam variables s and t for 2-to-
2 scattering and q2 in our simple vacuum polarization example. But once one gets past
2-to-2 scattering, the analytic structure becomes unwieldy. The program failed and was
swept into the dustbin of physics history. (However, you might know that, through a rather
convoluted process, this massive effort eventually gave birth to string theory.)
Remarkably, some features of this program are being revived. In particular, in this
chapter we will discuss the notion of complexifying physical variables. In an interesting
twist, it turns out to be better to complexify the external momenta (to be explained below)
rather than invariants like s and t. A historical aside: Landau apparently suggested on one
occasion that it might be useful to consider complex momenta.
Consider the amplitude M(pi, hi) for tree-level scattering of n massless particles with
momentum and helicity (pi, hi), i = 1, . . . , n, with p2
i = 0. (For a gauge theory, we will
define the amplitude with the color factors already stripped away. Also, suppress the trivial
multiplicative coupling constant dependence and drop all such overall factors as we move
along.)
The novel idea is to pick two external momenta pr, ps, complexifying them while
keeping them on shell and maintaining momentum conservation. We take all momenta
as incoming. At this stage we can keep the discussion general and not even specify the
theory except to stipulate that it contains only massless particles. But to fix ideas, you can
imagine a gauge theory. For some complex number z, replace pr and ps by
pr(z) = pr + zq
and
ps(z) = ps −zq
(1)
1 T. Regge, Publ. RIMS, Kyoto University, 12 suppl.: pp. 367–375, 1977.
2 A. Polyakov, Gauge Fields and Strings, CRC, 1987, p. 1.
3 See, for example, G. Barton, Dispersion Techniques in Field Theory, W. A. Benjamin, 1965.

N.3. Connections in Gauge Theories | 499
R
ps(z)
L
pr(z)
PL(z)
Figure N.3.1
To keep pr(z)2 = 0 and ps(z)2 = 0, we need q . pr,s = 0 and q2 = 0, which is possible only
if we make q complex. To be explicit, go to a frame in which pr + ps has only a time
component and use units so that the time component is equal to 2. Then
pr = (1, 0, 0, 1),
ps = (1, 0, 0, −1),
q = (0, 1, i, 0)
(2)
A technical aside. This is why I mentioned SO(2, 2) in appendix B and in the preceding
chapter: with a (+ + −−) signature one could satisfy the on-shell constraint without having
a complex q. Here I will stick with the more physical SO(3, 1) and consider complex
momenta as explained in the preceding chapter. Another side remark: As you will see,
the discussion goes through for any spacetime dimension d ≥4.
With this set up the scattering amplitude M(z) becomes an analytic function of z. Think
of the complex momentum zq flowing into the diagram with pr(z), cruising through some
of the internal lines, and then flowing out with −ps(z). Let us turn on our pole detector.
At tree level, a pole can arise only from a propagator carrying momentum zq + . . .. Thus
the tree amplitude M(z) has only simple poles, coming from diagrams of the type shown
in figure N.3.1. Divide pi into two sets L and R, with those in L flowing into a blob on
the left-hand side and those in R flowing into a blob on the right-hand side. The two
blobs are connected by a single propagator carrying momentum PL(z), which by arbitrary
convention we choose to flow into blob L. The two blobs are themselves tree amplitudes in
the theory. Let nL and nR be the number of external momenta in sets L and R, respectively
(with nL + nR = n, of course, and nL ≥2, nR ≥2). Then the left-hand blob represents tree
scattering of nL + 1 particles, with nL particles on shell and one particle with momentum
PL(z) off shell, with an amplitude ML(z). Similarly, the right-hand blob represents tree
scattering of nR + 1 particles, with nR particles on shell and one particle with momentum
−PL(z) off shell, with an amplitude MR(z).

500 | Part N
Clearly, the momentum PL(z) depends on z only if pr(z) and ps(z) do not appear in
the same set. With no loss of generality let pr(z) belong to the set L and ps(z) to the set
R. Then PL(z) = −((
iϵL pi) + zq) = PL(0) −zq and PL(z)2 = PL(0)2 −2zq . PL(0) =
−2q . PL(0)(z −zL), where zL = PL(0)2/(2q . PL(0)). Thus Mhas a pole at z = zL, which,
since q is complex, is in general complex.
The amplitude M has poles all over the complex z-plane, at z = zL, one for each
valid partition of the external momenta into L + R. The residue has the factorized form
RL = ML(zL)MR(zL)/(2q . PL(0)), where ML(zL) and MR(zL) are now both on-shell
amplitudes, since the particle carrying momentum PL(zL) is now on shell. As always, we
suppress all inessential overall factors.
If, and that is a crucial if, M(z) →0 as z →∞, then

C(dz/z)M(z) = 0, where the
contour C is a circle of infinite radius running along infinity. We then shrink the contour,
picking up the pole at z = 0, which contributes M(0) to the contour integral, and a bunch
of poles at z = zL, contributing a sum of terms consisting of the residue at each pole,
multiplied by 1/zL. We thus determine the scattering amplitude to be
M(0) = −

L,h
RL
zL
= −

L,h
ML(zL)MR(zL)
PL(0)2
(3)
Note that the sum also runs over the helicity h carried by the intermediate particle PL.
The notation has been a bit compact, but suffices to get the essential point across
without cluttering the page with bloated expressions. But let us now make the notation
a bit more precise. To start with, zL of course depends on the specific partition L through
the momentum PL. To make sure you follow, let us describe ML(zL) more explicitly. It is
an on-shell amplitude with (nL + 1) particles coming in, respectively carrying momentum
and helicity (pr(zL), hr), (pi, hi) for i ϵ L, i ̸= r, and (PL(zL), h). Two of the momenta are
complex, namely pr(zL) and PL(zL). Let us emphasize that by construction PL(zL)2 = 0
and so all particles are on shell. Similarly, MR(zL) is an on-shell amplitude with (nR + 1)
particles coming in, respectively carrying momentum and helicity (ps(zL), hs), (pi, hi) for
i ϵ R, i ̸= s, and (−PL(zL), −h).
The crucial point is that, amazingly, as was discovered by Britto, Cachazo, Feng, and
Witten, we can determine the n-point tree amplitude M(z) in terms of lower point on-shell
tree amplitudes, specifically (3) as a sum over products of the (nL + 1)-point amplitude
ML(zL) and (nR + 1)-point amplitude MR(zL). Note that n −1 ≥nL + 1 ≥3 (similarly
for nR + 1), and thus by applying these so-called BCFW recursion relations repeatedly, we
can calculate any on-shell tree amplitude in Yang-Mills theory and in gravity in terms of an
irreducible 3-point amplitude. Furthermore, in the primitive 3-point on-shell amplitude, all
Lorentz invariants constructed out of the momenta vanish, since pi . pj = 1
2(pi + pj)2 = 0.
To determine the loop amplitudes, Bern, Dixon, and Kosower have generalized the
unitarity methods sketched earlier in this text and alluded to in the preceding chapter. With
these methods, one can calculate all amplitudes, trees and loops, and thus determine the
theory completely in terms of the helicity dependence of the 3-point on-shell amplitude.

N.3. Connections in Gauge Theories | 501
Amazingly, the old dream of the S-matrix school comes true! Everything within pertur-
bation theory is determined without our ever having to refer to a Lagrangian.
Note that to obtain physical amplitudes we need only M(z = 0) but to recurse to higher
point amplitudes we need to know M(z ̸= 0). As we will see, once we have M(z = 0) we
can obtain M(z ̸= 0) by analytic continuation.
As emphasized in the preceding chapter, the decomposition of a lightlike vector in terms
of spinors
pα ˙α ≡pμ(σ μ)α ˙α = λα˜λ˙α
(4)
works equally well for complex lightlike vectors. In that case, as already explained in
chapter N.2, the two spinors λ and ˜λ are independent of each other.
Another side remark: The deformation (1) considered here has a nice form in the
helicity spinor formalism of the preceding chapter. Let pr = λr ˜λr and ps = λs ˜λs (with
spinor indices suppressed). Then the spinor deformation ˜λr →˜λr + z˜λs and λs →λs −zλr
(leaving λr and ˜λs unchanged) gives the desired momentum deformation with q = λr ˜λs,
which we see is not hermitean and hence corresponds to a complex momentum. This is
consistent with the discussion in the preceding chapter, since the deformation obviously
does not respect the equality between ˜λ and λ∗necessary for real momenta.
The naive person about to recurse
Imagine that you woke up one morning and had the wonderful idea of complexifying
momentum. Then suppose you had enough wits, after a bow to Cauchy, to discover these
marvellous recursion relations. But after you calmed down, you wanted to try the recursion
out on some theory. Naturally, you first chose a scalar field theory, say a ϕ3 or a ϕ4 theory.
Your enthusiasm dies immediately. In these theories, the basic vertex is just a number,
the coupling. For an n-point amplitude, there are always some Feynman diagrams in which
pr(z) and ps(z) meet at one of the basic vertices, and the entire diagram does not even
depend on z. The crucial assumption that M(z) →0 as z →∞is simply not true.
Most physicists might give up at this point, but suppose you were possessed of strength
of character and decided to take a look at Yang-Mills theory, thinking that, after all, it seemed
much more fundamental than some dumb scalar field theory. But a quick look convinces
you that things are even worse. Consider the diagram in figure N.3.2a contributing to the n-
gluon amplitude. Put pr(z) and ps(z) as “far apart” as possible to maximize the number of
propagators between them. There are (n −3) propagators, contributing a factor of 1/zn−3
to the amplitude as z →∞. But alas, this is overwhelmed by (n −2) cubic vertices with
each vertex linear in momentum, thus contributing a factor of zn−2.
You have not yet included the polarization vectors, which for z = 0 are given by ϵ−
r =
q, ϵ+
r = q∗and ϵ−
s = q∗, ϵ+
s = q (note that q ↔q∗under r ↔s, since the two momenta

502 | Part N
(a)
(b)
(c)
ps(z)
pr(z)
ps(z)
pr(z)
ps(z)
pr(z)
n2
Figure N.3.2

N.3. Connections in Gauge Theories | 503
point in opposite directions). We also have to deform them to maintain their orthogonality
with the corresponding momentum vectors:
ϵ−
r (z) = q, ϵ+
r (z) = q∗+ zps
(5)
and
ϵ−
s (z) = q∗−zpr, ϵ+
s (z) = q
(6)
You should check that all conditions are satisfied, for example, ϵ+
r (z) . pr(z) = (q∗+
zps)(pr + zq) = z(q∗q + pspr) = 0. [In the notation of (N.2.9, 10), the polarization vectors
here correspond to the choice μr(z) = μr(0) = λs, ˜μr(z) = ˜μr(0) = ˜λs, μs(z) = μs(0) =
λr, ˜μs(z) = ˜μs(0) = ˜λr. The first equal sign in each relation simply emphasizes that we
choose not to deform the μ’s and ˜μ’s.]
Note the peculiar asymmetry between r and s after deformation: in particular, two of the
polarization vectors, ϵ+
r and ϵ−
s , grow with z and thus worsen the large z behavior. Putting
it all together and referring to (5) and (6), you would conclude [with the notation Mhrhs(z)]
that
M−+
naive(z) →zn−2
zn−3 = z, M−−or++
naive
(z) →z2, M+−
naive(z) →z3
(7)
which most certainly do not →0.
A seemingly unimportant comment that will become important later: Of course, some
of the gluons other than r and s could first interact among themselves as shown in fig-
ure N.3.2b. This merely reduces the effective n in the discussion above for those particular
diagrams, and we reach the same naive estimates.
Reality more benign than expectation
Reality turns out to be much more benign than our naive expectation! Actually, amplitudes
in Yang-Mills theory behave better than amplitudes in scalar field theory, the opposite of
what we thought.
This fact is either astonishing or not so astonishing, depending on how jaded you are. I
have to admit that it sounds a bit less amazing after learning in the preceding chapter that
∼10,000 terms can cancel down to a single term.
We can even concoct a heuristic physical argument. Go back to Yang-Mills theory and
call the particles gluons, as before. Apply crossing to gluon s, so that we have an incoming
gluon r with a huge momentum pr(z) ∼zq in the large z limit, emerging as a gluon with
the huge momentum −ps(z) ∼zq. The other (n −2) gluons have fixed momenta and are
thus soft. We have a hard gluon blasting through a soft gluon background, something like
a high energy gamma ray blasting through a magnetic field, and thus we do not expect
much scattering as z →∞, and even less scattering that would flip the helicity of the hard
gluon. (The situation is conceptually similar to electron scattering in an external Coulomb
potential, discussed in chapter II.6, except that here the field excitation being scattered is
of the same type as the background field.)

504 | Part N
But not so fast! Even though you and I have studied physics for years, we haven’t built
up much intuition about complex momenta. At least I speak for myself. Alternatively, we
could go to SO(2, 2) and deal with real momenta, but we haven’t much experience with
signature (+ + −−) spacetime, either.
Background field method
Nevertheless, the picture of a hard gluon blasting through a soft background turns out
to be helpful in guiding us toward an elegant formulation of the problem. We split
the Yang-Mills gauge potential (which we write as A on this occasion) into two pieces,
A(x) = A(x) + a(x), a background potential A without high momentum components in
its Fourier transform and a fluctuating potential a with high momentum components. (You
would do exactly the same split when studying a laser beam passing through a laboratory
magnetic field.) To develop this so-called background field method (which is useful for
other problems besides this one), it pays to use the differential form notation used in
chapter IV.5.
We split the transformation law A →UAU
† + UdU
† into A →UAU
† + UdU
† and
a →UaU
†. In other words, the background A transforms like a Yang-Mills potential, while
the fluctuating a transforms like a matter field in the adjoint representation. Plugging into
the field strength F = dA + A2 = d(A + a) + (A + a)2, we find F equal to the sum of the
background field strength F = dA + A2 and the 2-form da + Aa + aA + a2 = (∂μaν +
[Aμ, aν] + aμaν)dxμdxν ≡1
2(Dμaν −Dνaμ + [aμ, aν])dxμdxν. Switching back from math
to physics notation and defining the shorthand notation D[μaν] ≡Dμaν −Dνaμ, we have
Fμν = Fμν + D[μaν] −i[aμ, aν]. Here Dμaν = ∂μaν −i[Aμ, aν] is the covariant derivative
(with respect to the background potential A) of the adjoint field a.
Since we have only two hard gluons interacting with the soft background, it suffices to
expand the Yang-Mills Lagrangian to quadratic order in a:
L = −1
2g2trFμνF μν
= −1
2g2tr

FμνF μν + D[μaν]D[μaν] + 2F μνD[μaν] −2iF μν[aμ, aν]

+ O(a3)
(8)
Since in the action we integrate L over spacetime, we are effectively allowed to inte-
grate by parts. Thus the third term in the parenthesis, tr(F μνDμaν) = tr(F μν(∂μaν −
i[Aμ, aν])) “=” tr((DμF μν)aν). Since the background field satisfies the field equation
DμF μν = 0, this term vanishes. (You should not be surprised that the term linear in a
in the action is linear in the field equation.)
Thus, to study the propagation of a through the background A, we can focus on the
Lagrangian quadratic in a: Lquad = −(1/g2)tr

(Dμaν −Dνaμ)Dμaν −iF μν[aμ, aν]

As
always, we need to fix the gauge. Upon integration by parts we have
trDνaμDμaν = tr(DμaμDνaν + iF μν[aμ, aν])
(9)

N.3. Connections in Gauge Theories | 505
Note that, unlike ordinary derivatives, when the gauge derivatives Dν and Dμ pass each
other, they produce the field strength F μ. [Verify this! You might recall the more mathe-
matical form (IV.5.13).] Thus a convenient way of fixing the gauge is to add tr(DμaμDνaν)
so that the gauge-fixed Lagrangian becomes
Lquad = −1
g2tr(DμaνDμaν −2iF μν[aμ, aν])
(10)
[Incidentally, this parallels precisely what was done in (III.4.8) to obtain the Feynman gauge
with ξ = 1.]
Return now to our problem of studying the large-z behavior of the scattering amplitude
Mλρ. Recall from (7) that we obtain Mλρ →zn−2/zn−3 = z. (Also recall that polarization
vectors have not yet been included, and they could multiply this behavior by z0, z1, or z2.)
The culprit is the derivative in the cubic vertex ∼Aa∂a sitting inside the first term in
(10). In contrast, the ∼AaAa piece in the first term and the second term trF μν[aμ, aν] in
(10) insert quartic vertices that do not grow with z.
The situation confronting us is now best discussed by the clever trick of renaming
indices. First, understand that Lorentz invariance is broken by the presence of the back-
ground field Aμ, to be regarded as given and fixed. (This is the same as in chapter VI.2: the
presence of a background magnetic field means that parity and time reversal are broken.)
But now suppose we simply relabel indices and write
Lquad = −1
g2tr(ηabDμaaDμab −2iF ab[aa, ab])
(11)
where ηab is nothing but the humble Minkowski metric.
The first term by itself enjoys a hidden “enhanced Lorentz” symmetry: an SO(3, 1)
transformation on the indices a, b leaves the Lagrangian invariant. We now exploit this
hidden symmetry. Since the leading behavior of Mab for large z comes from repeated
insertion of the cubic vertex ηabaaAμ∂μab contained in the first term in (11), we conclude
that the leading behavior must be proportional to ηab.
In contrast, with one insertion of the quartic vertex from the second term in (11), we
decrease the power of z by one, since it does not contain a derivative on the field a. But
we also break the hidden “enhanced Lorentz” symmetry, since F ab is fixed. On the other
hand, there is an extra bit of information: we know that it is antisymmetric in (ab). [Note
that an insertion of the quartic vertex ηabaaAμAμab contained in the first term in (11) also
decreases the power of z by one, but its contribution is proportional to ηab.]
Thus the hidden “enhanced Lorentz” symmetry tells us that the amplitude expanded in
powers of z must have the form
Mab = (cz + . . .)ηab + Aab + 1
zBab + . . .
(12)
with c some unknown constant. The only thing we know about the matrix Aab is that it is
antisymmetric in (ab). (I am following the notation in the literature. If you are confused
between this matrix A and the background gauge potential A(x) you need to go back to
square 1.)

506 | Part N
We
still
have
gauge
invariance
in
the
form
pra(z)Mab(z)εsb(z) = 0
and
εra(z)Mab(z)psb(z) = 0, giving us valuable information. For example, looking up the form
pr(z) = pr + zq, we obtain qaMab(z)εsb(z) = −(1/z)praMab(z)εsb(z), but since from (5)
ϵ−
r (z) = q, this means that ϵ−
ra(z)Mab(z)εsb(z) = −(1/z)praMab(z)εsb(z).
Let us now look at the specific helicity combinations for which we had naive expectations
in (7). Recall that we expected M−+(z) →z. In fact, since ϵ+
s (z) = q and pr . q = 0, we have
M−+(z) = ϵ−
ra(z)Mab(z)ε+
sb(z) = −1
zpra{(cz + . . .)ηab + Aab + 1
zBab + . . .}qb
= −1
zpraAabqb + O( 1
z2) →1
z
(13)
This amplitude behaves better than naive expectation by two powers of (1/z)!
Next, M−−(z) →z2 naively, but in fact
M−−(z) = ϵ−
ra(z)Mab(z)ε−
sb(z) = −1
zpra{(cz + . . .)ηab + Aab + 1
zBab + . . .}(q∗
b −zprb)
= −1
z(praAabq∗
b + praBabprb) + O( 1
z2) →1
z ,
(14)
three powers better than naive expectation. Similarly, M++(z) →1/z. Note that these
conclusions hold for any n. If you have the strength, you might want to witness the
cancellations by explicitly calculating the various M’s for low values of n.
But not all helicity amplitudes behave better than naive expectation. We finally come
to M+−(z), which →z3 naively. Looking at (5) and (6) we already see trouble, since both
ϵ+
ra(z) and ε−
sb(z) grow like z. Now we have
M+−(z) = ϵ+
ra(z)Mab(z)ε−
sb(z) = (q∗
a + zpsa){(cz + . . .)ηab + Aab + 1
zBab + . . .}(q∗
b −zprb)
= −cps . prz3 + O(z2) →z3
(15)
Incidentally, note that our intuition about complex momenta is a bit shaky. The helicity-
conserving amplitude (+ →+) [namely M+−(z) by crossing; recall that M was defined
with all momenta going in] behaves worse than the (+ →−) amplitude M++(z), the
(−→+) amplitude M−−(z), and the (−→−) amplitude M−+(z). The polarization
vectors are continued for complex momentum in a nonsymmetric fashion.
Confusio suddenly speaks up! “You haven’t yet exploited the gauge invariance of the
background field,” he says.
We forgot that he often appears in the company of SE. Indeed, he is right. Very good—
Confusio did not become an assistant professor for nothing.
Indeed, let us look at the cubic vertex in figure N.3.2a more carefully: we have a hard
gluon carrying momentum zq + . . . scattering off a background gluon carrying some
small momentum p into a hard gluon with momentum zq + . . .. The coupling comes
from the term tr∂μaν[Aμ, aν] in the Lagrangian, and thus to leading order in z the vertex is
proportional to zqμ . Aμ(p). According to exercise VII.1.1, we can choose a gauge in which
qμ . Aμ(p) = A2+i3(p) = 0, known as the Chalmers-Siegel space cone gauge.
We should check to see if this is possible, but to streamline the exposition let us
merely do the abelian case. With Aμ(x) →Aμ(x) −∂μ(x), the desired gauge choice

N.3. Connections in Gauge Theories | 507
requires q . A(p) = iq . p(p), and thus we can solve for (p) as long as q . p ̸= 0. While
q . pr,s = 0 by construction, generically there is no reason for q . pi to vanish for i ̸= r, s.
So we conclude that indeed we can get rid of the offending cubic vertex.
But not so fast! What about figure N.3.2c, in which all the soft gluons interact with
each other to form one single soft gluon carrying momentum 
i̸=r,s pi = −(pr + ps)?
Since q . (pr + ps) = 0, we cannot set q . A(pr + ps) = 0 and the diagram in figure N.3.2c
remains. Thus, even though we managed to get rid of the cubic vertices in figure N.3.2a, b,
our previous conclusion about the large-z behavior of M still stands.
“Wait! What about the color factor?” Confusio yells. Let us look at the color structure
we stripped off. From figure IV.5.2b we see that the cubic vertex in figure N.3.2c requires
that the two hard gluons be adjacent in color. It is easiest to explain the terminology by
an example: a red-green gluon and a blue-yellow gluon are not adjacent in color, but they
are both adjacent to a red-yellow gluon (and to a blue-green gluon). Note that the coupling
trF μν[aμ, aν] also requires that the two hard gluons be color adjacent.
Thus, if the two hard gluons are not color adjacent, the large-z behavior of M is
somewhat better, since now c = 0 and Aab = O(1/z). Then M−+ →1/z2 instead of 1/z,
M+−→z2 instead of z3, while M−−and M++ are not improved. Confusio deserves credit
for his partial triumph, and perhaps eventually should be given tenure.
The bottom line is that, contrary to naive expectation, amplitudes in gauge theory behave
well enough for the BCFW recursion program to work. We don’t even mind that M+−
behaves badly; it suffices for the program that M−,any helicity vanishes for large z. In
particular, in appendix 1 we will show how to complete the calculation started in the
preceding chapter.
As indicated earlier, once we determine the tree amplitudes, we can in principle obtain
all loop amplitudes by using unitarity. In this modern revival of the S-matrix spirit, we deal
with only on-shell amplitudes. The message here is that traditional Feynman diagrams
carry around an enormous amount of unnecessary off-shell baggage. A dramatic example
is furnished by this innocuous looking Feynman integral

d4l
(2π)4
lμlνlρlλ
l2(l −k)2(l −p)2(l −q)2
(16)
which you can evaluate most conveniently using dimensional regularization. Try it. The in-
tegral looks similar to the integrals we did back in chapters III.6,7, but looks are deceptive.
The answer, if printed on a page, is a total black smudge (see http://online.kitp.ucsb.edu/
online/colloq/bern2/oh/05.html). After all, this integral is just one piece of a physical am-
plitude and by itself does not possess any nice qualities, such as gauge invariance.
All possible Lorentz invariant theories
Remarkably, not only does BCFW recursion allow us to determine all n-point on-shell
amplitudes in terms of a primitive 3-point on-shell amplitude, it also restricts all possible
theories for which the recursion works. Let us sketch how this is possible. We anticipate

508 | Part N
here, as we will explain in the next chapter, that the recursion program works for massless
spin 2 as well as for spin 1 particles. Consider a 4-point on-shell amplitude M. The point is
that we are free to deform different pairs (r, s) to determine M. Suppose we pick (r, s) =
(1, 4). Then Mis the sum of two pieces, one with a pole in s = (p1 + p2)2 = (p3 + p4)2 and
another with a pole in t = (p1 + p3)2 = (p2 + p4)2. But we could have also picked (1, 2) for
example. That the physical 4-point on-shell amplitude M(z = 0) constructed in different
ways must agree imposes powerful self-consistency conditions on the primitive 3-point
on-shell amplitude.
Perhaps not surprisingly, for spin 2 massless particles, Einstein gravity is the only
possible theory, while for spin 1 massless particles, Yang-Mills gauge theory. Indeed, this
result was proven long ago by Weinberg using rather general arguments. But it is still
instructive to see how the same result emerges from a strikingly different formalism.
These self-consistency conditions also allow one to explore and search for other possible
theories.
It is crucial that the primitive 3-point on-shell amplitude M3 is evaluated for complex
momenta, which allow more freedom than garden-variety everyday real lightlike momenta.
(As already noted in appendix 1 to chapter N.2, the Yang-Mills cubic vertex vanishes
for real lightlike momenta.) I remind you again that for complex momenta pi = λi ˜λi,
the two spinors λi and ˜λi are independent of each other. Recall from chapter N.2 that
⟨ij⟩= ⟨λiλj⟩≡εαβλiαλjβ and [ij] = [λiλj] = [˜λi ˜λj] ≡ε ˙α ˙β ˜λi ˙α˜λj ˙β. Also, pi . pj = ⟨ij⟩[ij].
The on-mass shell conditions pi . pj = 0 then become ⟨12⟩[12] = 0, ⟨23⟩[23] = 0, and
⟨31⟩[31] = 0. Apparently there are several possible solutions. For example, we could have
all three square brackets vanish with all three angled brackets nonzero, or we could have
two square brackets vanish, say [12] = [23] = 0, with ⟨31⟩= 0. But there are only two
independent 2-component spinors, so three spinors cannot be linearly independent [take
˜λ1 ∝(0, 1) and ˜λ2 ∝(1, w), then the third spinor ˜λ3 is necessarily a linear combination
of the other two]. Thus, [12] = 0 and [23] = 0 mean that ˜λ1 ∝˜λ2 and ˜λ2 ∝˜λ3, respectively,
which implies that ˜λ3 ∝˜λ1 and [31] = 0. Of course, the discussion can be repeated with
square and angled brackets interchanged. Thus we conclude that
either ⟨12⟩= ⟨23⟩= ⟨31⟩= 0 or [12] = [23] = [31] = 0
(17)
(For example, if [12] = [23] = [31] = 0, then ˜λ2 = α2˜λ1 and ˜λ3 = α3˜λ1, and momentum
conservation 
i pi = 
i λi ˜λi = 0 implies λ1 + α2λ2 + α3λ3 = 0. The information here
is in the coefficients, since three 2-component spinors are always linearly dependent.)
Thus, depending on the helicities, either M3 = MH(⟨12⟩, ⟨23⟩, ⟨31⟩) or M3 =
MA([12], [23], [31]).
Recall from the preceding chapter that i = −2hi, where i counts the powers of λi
minus the powers of ˜λi. But acting on MH, this just counts the powers of λi. Write
MH = ⟨12⟩d3⟨23⟩d1⟨31⟩d2 and solve for the unknown d’s using 1 = d2 + d3 = −2hi, etc.
Then d1 = h1 −h2 −h3, d2 = h2 −h3 −h1, and d3 = h3 −h1 −h2. For example, suppose

N.3. Connections in Gauge Theories | 509
the theory contains spin 1 massless particles, with different varieties labeled by an index
a whose range we need not specify. Then we have, for example,
M3(1−
a , 2−
b , 3+
c ) = fabc
 ⟨12⟩3
⟨23⟩⟨31⟩
	
(18)
since the helicities h1 = h2 = −1 and h3 = +1 imply that d1 = d2 = −1 and d3 = 3. At this
stage fabc is some unknown coefficient that depends on the particle variety. As required,
we have two positive powers of λ1 and λ2 and two negative powers of λ3. This confirms
what we obtained in appendix 1 to the preceding chapter.
Several remarks follow.
1. From pi = λi ˜λi the spinors λ and ˜λ have mass dimension 1
2. Thus M3 has mass dimension 1,
as expected (recall that the cubic coupling in gauge theory has the form ∼ϵ . ϵϵ . p).
2. We obtain the 3-point amplitude
M3(1+
a , 2+
b , 3−
c ) = fabc

[12]3
[23][31]

(19)
by flipping helicities, which, as we have learned in the preceding chapter, amounts to
interchanging the roles played by λ and ˜λ, so that it given by square instead of angled
brackets.
3. Note the power of the spinor helicity formalism. We can immediately generalize to higher
integer spin s by scaling the i’s and hence the d’s up by a factor of s. Thus we simply raise
the round parenthesis in M3(1−
a , 2−
b , 3+
c ) to power s. The cubic vertex for spin 2 is thus
given by M3(1−−
a
, 2−−
b
, 3++
c
) = fabc(⟨12⟩3/(⟨23⟩⟨31⟩))2.
4. Interchanging 1and 2, we see that fabc = −fbac for s odd. Thus for s odd (s = 1, for example),
we cannot have a theory with only one variety of particles. We are compelled to introduce
the index a (and call it color!).
5. For s even (s = 2, for example) we can get away with only one variety. Call it the graviton. The
coefficient fabc can be omitted and one of the two basic cubic vertices for Einstein gravity
is simply given by
M3(1−−, 2−−, 3++) =
 ⟨12⟩3
⟨23⟩⟨31⟩
	2
(20)
(The other vertex is of course obtained by replacing angled brackets by square brackets.)
More on the 3-graviton vertex in appendix 2.
6. Check out the power of the self-consistency argument sketched above. Consider the 4-point
amplitude M(1a, 2b, 3c, 4d) in a theory with a variety of spin 1 massless particles. Apply
the recursion to construct M as the sum of an amplitude with an s channel pole, evidently
proportional to fabefcde with an implicit sum over the label e of the intermediate particle,
and an amplitude with a t channel pole proportional to facefbde. Requiring M constructed
with different choices of (r, s) in the recursion to be the same then gives the constraint
fabefcde + facefbde + fadefbce = 0
(21)

510 | Part N
K
j
2
3
n
4
1
Figure N.3.3
But we recognize this as just the defining relation (B.19) for the generators of a Lie algebra
[T a, T b] = ifabcT c written out in the adjoint representation! The coefficients fabc that appear
in the primitive 3-point on-shell amplitude are the structure constants of the algebra. If this
is too abstract for you, verify it for SU(2).
The recursion program produces Einstein gravity and Yang-Mills theory as the unique
low energy theory for massless spin 2 and spin 1 particles, respectively, with sufficiently
good large-z behavior for the recursion relations to be valid. Of course, we also know that
in the Lagrangian formalism, the powerful constraints of local coordinate invariance and
local gauge invariance fix the actions for Einstein gravity and Yang-Mills completely.
Appendix 1
Here, as promised, we use the recursion approach to prove the result conjectured in the preceding chapter, that
for n-gluon scattering, the maximal helicity-violating amplitude is given by
A(1+, 2+, . . . j−, . . . , n−) =
⟨jn⟩4
⟨12⟩⟨23⟩⟨34⟩. . . ⟨(n −1)n⟩⟨n1⟩
(22)
(Using the cyclicity of the amplitude, we have with no loss of generality let gluon n carry negative helicity.)
We take r = n and s = 1, and deform ˜λn →˜λn + z˜λ1 and λ1 →λ1 −zλn (leaving λn and ˜λ1 unchanged), in
other words, pn →pn + zq and p1 →p1 −zq with q = λn˜λ1. Write (3) as (see fig. N.3.3)
A(1+, 2+, . . . j−, . . . , n−) = A3(ˆ1+, 2+, ˆK−)An−1(−ˆK+, 3+, . . . , j−, . . . , ˆn−)/PL(0)2
(23)
Here we define K(z) = PL(z) to simplify writing. We use a hat to indicate that the corresponding momentum
has been complexified. Thus ˆ1, ˆn, ˆK remind us that p1(z), pn(z), and K(z) = −(p1(z) + p2) (evaluated at z = zL)
are the three complex momenta in the problem.
In the spirit of recursion, we are supposing that A3 and An−1 are given by (22) (and the corresponding
expression with all helicities flipped and angled brackets replaced by square brackets). Note that (22) does not
refer to any possible relation between the untwiddled λ and twiddled ˜λ spinors and thus makes sense for both
complex and real momenta. Notice that the sum over partition L and over h in (3) collapses to one term in (23).
We have used the result A(+ + . . . +) = 0 and A(−+ . . . +) = 0, and the second half of (17) to eliminate a
diagram similar to that in fig. N.3.3 but with particles (n −1) and n participating in the cubic vertex instead of 1
and 2.

N.3. Connections in Gauge Theories | 511
Recursing and using PL(0)2 = 2p1 . p2 = 2⟨12⟩[12], we obtain [see (19)]
A(1+, 2+, . . . j−, . . . , n−) =
[ˆ12]3
[2, ˆK][ ˆK, ˆ1]
⟨j ˆn⟩4
⟨ˆK3⟩⟨34⟩. . . ⟨(n −1)ˆn⟩⟨ˆn ˆK⟩
1
⟨12⟩[12]
(24)
As before, we suppress overall constants.
The trick consists of taking various hats off or leaving them on. Since ˜λ1 is unchanged, we can remove the
hat on ˆ1 when it appears in a square bracket. Similarly, since λn is unchanged, we can remove the hat on ˆn when
it appears in an angled bracket. On the other hand, we should leave the hat on ˆK. Instead, we use momentum
conservation −λK ˜λK = λ1˜λ1 + λ2˜λ2 so that ⟨ˆK, 3⟩[ ˆK, 1] = −⟨3, ˆK⟩[ ˆK, 1] = ⟨32⟩[21] since [11] = 0. (You might
note that this is the same sort of manipulation used to derive the first identity we needed to massage A4 into
shape in the preceding chapter.) Similarly, ⟨n ˆK⟩[2, ˆK] = −⟨n ˆK⟩[ ˆK, 2] = ⟨n1⟩[12].
Doing all this to (24) we obtain
A(1+, 2+, . . . j−, . . . , n−) =
[12]3⟨jn⟩4
⟨12⟩[12]⟨n1⟩[12]⟨32⟩[21]⟨34⟩. . . ⟨(n −1)n⟩
=
⟨jn⟩4
⟨12⟩⟨23⟩⟨34⟩. . . ⟨(n −1)n⟩⟨n1⟩,
(25)
precisely the conjectured result.
Note how much more powerful the recursion approach is compared to the explicit spinor helicity calculation
we did to obtain A(1, 2, 3, 4) in the preceding chapter, which in turn is so much more powerful than the traditional
Feynman diagram calculation. Thus theoretical physics marches on.
You might be puzzled that the quartic vertex (figure IV.5.1c) of Yang-Mills theory is not needed in the recursion
program. Does this nonparticipation in the program mean that we can multiply the quartic term in the Lagrangian
by an arbitrary coefficient (including 0)? The resolution of this apparent paradox can be traced to the fact that
the (perturbative) physical states of the gluon are built into the recursion relations. The quartic term is needed
to guarantee gauge invariance and hence the two helicity states of the gluon.
Appendix 2
By showing you the mess in figure N.2.2 I have already plenty impressed upon you that the traditional Feynman
diagram approach is almost hopeless when it comes to gluons. The situation with gravity is far worse. Consider
the 3-graviton vertex. Conceptually it is easy to understand: we write gμν = ημν + hμν and expand the Einstein-
Hilbert action (VIII.1.1) to O(h3). There it is, with indices suppressed, the cubic term h∂h∂h in (VIII.1.5). Of
course, this actually represents many terms with the eight indices contracted every which way, but which you
can readily work out. Next, pick the harmonic gauge for example, and derive the Feynman rule for the 3-graviton
vertex Gμα,νβ,σγ (p1, p2, p3), namely the analog of the 3-gluon vertex in (C.18). Each of the three gravitons, say
the one carrying momentum p1, can be created by any one of the three h’s in h∂h∂h, and thus many terms are
generated simply by permuting. The two derivatives give two powers of momentum. Thus, a typical term has
the form p1βp2μηανησγ .
Keep working! In all, Gμα,νβ,σγ (p1, p2, p3) contains about 100 terms. Now imagine calculating the one-loop
contribution to graviton-graviton scattering. You get the point.
By now, you fully appreciate that the traditional Feynman approach carries an enormous amount of unneces-
sary off-shell information. Already, if we put p1, p2, and p3 on shell and contract Gμα,νβ,σγ (p1, p2, p3) with the
polarization vectors ϵμα
1 , ϵνβ
2 , and ϵσγ
3 , the 3-graviton vertex simplifies enormously to
G(p1, p2, p3) = ϵμα
1 ϵνβ
2 ϵσγ
3 (p1σημν + cyclic)(p1γηαβ + cyclic)
(26)
Quite naturally, we can write the polarization vector for a spin 2 massless particle in terms of the polarization
vector for a spin 1 massless particle: ϵμα(p) = ϵμ(p)ϵα(p). This form satisfies all that is required of a polarization
vector for spin 2: ϵμα(p)pμ = 0, ϵμα(p) = ϵαμ(p), and ημαϵμα(p) = 0. Thus, indeed, the 3-graviton vertex
G(p1, p2, p3) = [ϵμ
1 ϵν
2ϵσ
3 (p1σημν + cyclic)]2 is the square of the 3-gluon vertex (N.2.23), in confirmation of (20),
which of course is just the same statement couched in another notation.

512 | Part N
Exercises
N.3.1
Show that the structure of Lie algebra (21) emerges naturally.
N.3.2
In appendix 1 we recursed by complexifying the momenta of two external lines with helicity + and −.
In the derivation of the recursion relation (3) we could have picked any two external lines to complexify.
Determine the amplitude calculated directly in chapter N.2, namely A(1−, 2−, 3+, 4+), by complexifying
lines 1 and 2. This is an example of the self-consistency argument sketched in the text.
Particle physics experimentalists are fond of saying that yesterday’s spectacular discovery is today’s
calibration and tomorrow’s annoying background. The canonical example is the Nobel-winning discovery
of the CP -violating decay of the KL meson into two pions. In theoretical physics, yesterday’s discovery is
today’s homework exercise and tomorrow’s trivium.
N.3.3
Using the explicit forms given for A(1−, 2−, 3+, 4+) and A(1−, 2+, 3−, 4+) in the preceding chapter,
check the estimated large z behavior in (13–15).
N.3.4
Worry about the sloppy handling of factors of 2 in appendix 1. [Hint: The final result is correct because
the polarization vectors in (5–6) are normalized to |ε|2 = 2 for convenience.]

N.4
Is Einstein Gravity Secretly
the Square of Yang-Mills Theory?
Gravity and gauge theory
Quantum gravity has baffled generations of theoretical physicists, as you have no doubt
heard. One aspect of this puzzle is the relationship between gravity and gauge theory,
which describes the other fundamental interactions. While gravity and gauge theory are
both born of local invariance, the Einstein-Hilbert action

d4x√−gR and the Yang-Mills
action

d4xtr(FμνF μν) look completely different.
Perturbatively, gravity is afflicted with an infinite number of interaction terms, as was
explained in chapter VIII.1, and hence gravity is not renormalizable, in stark contrast to
gauge theory. On the other hand, the two field theories enjoy many conceptual similarities
between them. Yang-Mills theory is the unique low energy effective theory of a spin 1
massless field, just as Einstein gravity is the unique low energy effective theory of a spin 2
massless field.
String theory unifies gravity and gauge theory. This remarkable fact alone points to a
deep connection between gravity and gauge theory, even though within field theory the
connection is totally obscure. One important clue is that the oscillator spectrum of the open
string contains only the gauge field but not the graviton, which appears in the spectrum
of the closed string. However, the closed string spectrum could be described as two copies
of an open string spectrum, thus leading Kawai, Lewellen, and Tye to discover relations
between graviton scattering and gauge boson scattering.1 In the limit of the string energy
scale going to infinity, we know that string theory reduces to field theory and thus a shadow
of these KLT relations should survive in field theory. (As you might know, not all theorists
are convinced that string theory corresponds to reality. If string theory eventually fails,
its ultimate value might well turn out to be the light it sheds on the hidden structure of
quantum field theory.)
1 It is definitely beyond the scope of this book to explain these statements. See, for example, J. Polchinski,
String Theory, p. 27.

514 | Part N
In any case, the bottom line is that string theory strongly hints that graviton ampli-
tudes can be expressed as products of Yang-Mills amplitudes, schematically Mgravitons ∼
Mgauge × Mgauge. The first reaction of many theoretical physicists when first told this
is puzzled skepticism. How is this possible, they ask quite reasonably, since Yang-Mills
contains an internal symmetry group while gravity doesn’t?
Now that we have learned to strip color, a connection between amplitudes no longer
strikes us as so implausible, particularly if we stick to on-shell scattering amplitudes for
gluons in specified polarization states Mλ1λ2...λn, namely amplitudes that experimentalists
can measure, rather than amplitudes Mμ1μ2...μn carrying Lorentz indices that theorists
using traditional methods play with. As we saw in the preceding chapter, the color stripped
tree-level on-shell helicity amplitude for gauge boson scattering boils down to the ⟨. . .⟩
and [. . .] products of two component spinors. We did not do the analogous calculation of
the tree-level on-shell helicity amplitude for graviton scattering, but we could anticipate
that the result would again be expressed in terms of the ⟨. . .⟩and [. . .] products. The
spinor helicity formalism is intrinsic to the Lorentz group SO(3, 1), not tied to a specific
theory. In particular, the interaction vertices in Einstein gravity are again given in terms
of scalar products of momenta and polarization vectors. Quite suggestively, the graviton
polarization vectors can be written, as mentioned in appendix 1 to the preceding chapter,
as ϵμν = ϵμϵν, a product of the gauge theory polarization vectors.
Indeed, I have already given part of the mystery away in the preceding chapter. We saw
that the basic cubic interaction vertex of three gravitons (with complex momenta) is given
by the square of the corresponding quantity for three gluons.
In summary, thanks to our string theory friends, we now know that there exists a
secret structural connection between gravity and gauge theory that is totally opaque at
the Lagrangian level.
Deformed graviton polarizations
In this closing chapter, I give a brief introduction to the exciting quest for this secret
connection. I will be content to look at one specific calculation.
Go back to the BCFW recursion (chapter N.3). It would work for gravity if the com-
plexified scattering amplitude M(z) vanishes as z →∞. But naively, it would seem that
the situation for gravity is even worse than the situation for gauge theory, since the cubic
graviton vertex is quadratic in momentum and thus goes like z2. (Recall the two powers
of derivative in the scalar curvature; see chapter VIII.1.) Repeat the calculation in the pre-
ceding chapter for n-graviton on shell scattering. Go back to figure N.3.2 and interpret the
lines as gravitons. The (n −2) cubic vertices give a factor of z2(n−2) for large z, easily over-
whelming the factor of 1/zn−3 from the (n −3) propagators. This nasty behavior occurs
even before we include the polarization of the two hard gravitons.
The graviton carries helicity ±2 (appendix 2 of chapter VIII.1) and hence a polarization
“vector” ϵμν, given by a symmetric and traceless tensor. We can naturally construct ϵμν =

N.4. Gravity and Yang-Mills Theory | 515
ϵμϵν out of the polarization vectors for a massless spin 1 particle (as already explained in
the preceding chapter). Thus, after deformation,
ϵ++μν
r
(z) = ϵ+μ
r
ϵ+ν
r
= (q∗+ zps)μ(q∗+ zps)ν,
ϵ−−μν
r
(z) = ϵ−μ
r
ϵ−ν
r
= qμqν
(1)
and
ϵ++μν
s
(z) = ϵ+μ
s
ϵ+ν
s
= qμqν,
ϵ−−μν
s
(z) = ϵ−μ
s
ϵ−ν
s
= (q∗−zpr)μ(q∗−zpr)ν
(2)
Note that the ϵμν(z)’s are in fact traceless and could go as either z0 or z2 for large z.
Putting it together, we obtain the naive estimate
M−−,++
naive
(z) →z2(n−2)
zn−3
= zn−1,
M−−,−−or ++,++
naive
(z) →zn+1,
M++,−−
naive
(z) →zn+3
(3)
The escalating behavior as n increases is the hallmark of a nonrenormalizable theory, as
explained in chapter III.2.
Hard graviton in a soft spacetime
Once again, we hope that real life is cushier than naive expectation. By the same reasoning
used for gauge theory, we study a hard graviton blasting through a gravitational field, that
is, a background of soft gravitons. So write the metric of spacetime as Gμν = gμν + hμν.
Plug this into the Einstein-Hilbert action (VIII.1.1) and extract the terms quadratic in h.
While the calculation is straightforward, it does involve some heavy lifting. To avoid the
labor, we note that using the harmonic gauge, we did this calculation in (VIII.1.10) but
only for the special case gμν = ημν (in other words, we expanded around flat Minkowski
spacetime rather than a general curved spacetime). We had
L =
1
64πG(ημνηλρηστ∂μhλσ∂νhρτ −1
2ημν∂μh∂νh)
(4)
with the trace degree of freedom h ≡ημνhμν. Henceforth, we set 64πG = 1.
Armed with symmetry considerations and our knowledge of gravity (chapter VIII.1), we
can almost immediately guess that when we go from a flat ημν to a curved gμν background,
this quadratic Lagrangian generalizes to
L = √−g(gμνgλρgστDμhλσDνhρτ −1
2gμνDμhDνh −2Rλρστhλσhρτ)
(5)
with h now defined as h ≡gμνhμν. Here D denotes the covariant derivative with respect
to the curved metric gμν introduced in chapter VIII.1 and Rλρστ the Riemann curvature
tensor constructed out of gμν. I trust you not to confuse this D associated with the
curved background with the covariant derivative in Yang-Mills theory used in the preceding
chapter and mentioned below in passing.
Let us go through the various features of (5). The √−g goes with the spacetime volume
and is common to any Lagrangian in curved spacetime, as we learned way back in (I.11.2).
We also learned there to promote any Lagrangian from flat to curved spacetime by replacing
ημν with gμν and the ordinary derivative by a covariant derivative (see chapter IV.5). As you

516 | Part N
can see, everything pretty much works out in parallel with how things work out for gauge
theory. The new feature is the term involving the Riemann curvature tensor Rλρστ, which
vanishes upon restriction to flat spacetime. But you are not surprised that such a term
could pop up, given trF μν[aμ, aν] in (N.3.8). Indeed, the only thing we can’t determine
without doing the actual calculation is the numerical coefficient (−2) of this term. That
particular number will play no role in the following discussion.
Also, in the preceding chapter we dropped a term linear in aμ because of the equation
of motion DμF μν = 0. Here, analogously, we dropped a term linear in hμν because of
Einstein’s equation of motion Rμν = 0. This also explains why terms involving the Ricci
tensor Rμν and the scalar curvature R do not appear in (5).
We want to calculate the large-z behavior of various scattering amplitudes M−−,++,
etc., and compare with the naive expectation (3). We hope that the same trick we used
for the gauge theory case would also work for gravity. Now the string theory hint, that
Mgravitons ∼Mgauge × Mgauge, suggests a factorized structure in the graviton amplitude,
and so more or less naturally leads to the guess that the first index λ and the second index
σ of hλσ are somehow associated respectively with the two copies of Mgauge.
The key to breaking the problem apart is the Bern transformation unlinking these two
indices. Examining (5), we see that the only term that links the first index with the second
index of hλσ appears in the term gμνDμhDνh, since h = gμνhμν does precisely that. How
to get rid of this term? The trick, following Bern and Grant, is to introduce a scalar field φ
and add the term 2gμν∂μφ∂νφ. We are allowed to do this, since φ does not appear in the tree
level graviton scattering amplitude we are studying. (Of course, the theory is changed from
pure gravity, and φ does circulate in loop diagrams for graviton scattering. Some readers
may also know that in string theory the graviton appears with a scalar φ, the experimentally
unobserved dilaton.)
For pedagogical clarity in explaining what we are going to do next, it is best to retreat
to the case of the flat background. Focus on the parenthesis in (4), now modified to
(∂μhλσ∂μhλσ −1
2∂μh∂μh + 2∂μφ∂μφ). (The normalization of φ is, in this context, just
chosen for convenience.) Since we can always make a field redefinition (see the appendix to
chapter VIII.3) without affecting on-shell scattering amplitudes, we let hλσ →hλσ + ηλσφ
(and hence h →h + 4φ) and φ →φ + 1
2h. You can verify that our parenthesis changes to
(∂μhλσ∂μhλσ −2∂μφ∂μφ). Since in this manipulation the role of ηλσ is merely to convert
hλσ into h, the same transformation works when ηλσ is promoted to gλσ.
The upshot is that we can effectively rewrite (5) as
L = √−g(gμνgλρgστDμhλσDνhρτ −2Rλρστhλσhρτ)
(6)
Now that φ has done his job, we have unceremoniously thrown him out since he doesn’t
contribute to the on-shell tree amplitudes we are interested in. We have thus dropped the
term gμν∂μφ∂μφ.
There has been quite a bit of formal development and perhaps the reader has lost sight
of what we are trying to do. Recall that we want to study the amplitude of a hard graviton
blasting through spacetime. Although a multitude of indices have appeared, as is always
the case with gravity, you should recognize that this Lagrangian is conceptually simple: it

N.4. Gravity and Yang-Mills Theory | 517
is quadratic in the quantum field h describing the hard graviton and contains some given
c-number tensors gλρ(x) and Rλρστ(x) pertaining to the background.
Unlinked melody
The important point is that the two indices carried by hλσ are now unlinked from each
other in the first term in (6). In chapter VIII.1, we learned to trade a “world index” like
λ for a locally flat Lorentz index a by using the vierbein ea
λ(x). Here we are invited to
introduce two sets of vierbein, e and ˜e, with their associated connections ω and ˜ω, and
write hλσ ≡ea
λ˜e˜a
σha ˜a. In reality, of course e = ˜e and ω = ˜ω, but this notation keeps track of
the fact that the two sets of indices carried by hλσ are unlinked. Note that hλσ is treated in
our quadratic Lagrangian as just some tensor field living in a curved spacetime specified
by gλσ ≡ea
λ˜e˜a
σηa ˜a.
Also in chapter VIII.1 we emphasized that the covariant derivative acting on vectors
carrying a world index and on vectors carrying a locally flat Lorentz index assumes different
forms, DμVν = ∂μVν −λ
μνVλ and DμVa = ∂μVa −ωb
μaVb, respectively. For pedagogical
clarity, I will use two different symbols D and D to denote what is conceptually the same
operation. For our problem we have Dλhμν = ea
μ˜e˜a
νDλha ˜a, with Dλha ˜a = ∂λha ˜a −ωb
λahb˜a −
˜ω ˜b
λ˜aha ˜b.
With this notation, the relevant Lagrangian becomes
L = √−g(gμνηab ˜η˜a ˜bDμha ˜aDνhb ˜b −2Rab˜a ˜bha ˜ahb ˜b)
(7)
We are now ready to study the large z behavior of the scattering amplitude of a hard graviton
carrying momentum zq + . . . blasting through a curved background spacetime gμν.
The analysis proceeds much as in the Yang-Mills case discussed in the preceding chap-
ter. Focus on the first term: √−ggμνηab ˜η˜a ˜b(∂μha ˜a −ωc
μahc˜a −˜ω˜c
μ˜aha ˜c)(∂νhb ˜b −ωd
νbhd ˜b −
˜ω ˜d
ν ˜bhb ˜d). The leading O(z2) behavior comes from the piece containing two derivatives in
the first term, namely Llead ≡√−ggμνηab ˜η˜a ˜b∂μha ˜a∂νhb ˜b, and thus contributes to the am-
plitude a term proportional to ηab ˜η˜a ˜b. In the Yang-Mills case, the Lagrangian contains a
hidden “enhanced Lorentz” symmetry. Here the situation is even better: we have not one,
but two hidden “enhanced Lorentz” symmetries. The term Llead is evidently left invariant
by two separate SO(3, 1) Lorentz transformations, one operating on the a, b indices, the
other on the ˜a, ˜b indices.
The subleading O(z) behavior comes from the pieces in the first term containing one
derivative and one factor of either ω or ˜ω, for example √−ggμνηab ˜η˜a ˜b∂μha ˜a(ωd
νbhd ˜b +
˜ω ˜d
ν ˜bhb ˜d). In this way we find that Mab, ˜a ˜b →cz2ηab ˜η˜a ˜b + z(ηab ˜A˜a ˜b + Aab ˜η˜a ˜b) + . . ., with
Aab and ˜A˜a ˜b two matrices antisymmetric in their indices. To see this, consider for example
the piece involving ω (after some relabeling of indices): √−ggμνηac ˜η˜a ˜b(∂μha ˜a)ωb
νchb ˜b. This
gives rise to the term Aab ˜η˜a ˜b in Mab, ˜a ˜b. Note that since the matrix Aab depends on the
spin connection ωab
ν of the background, all we can say is that it is antisymmetric in its two
indices a b. Recall that this is quite analogous to what we did in the Yang-Mills case.

518 | Part N
Before reading further, you could now flex your mental muscle and push ahead to
obtain the sub-subleading O(z0) behavior. This comes from the pieces in the first term
containing two factors of ω and ˜ω, for example (again, after some relabeling of indices)
√−ggμνηcd ˜η˜a ˜bωa
μcha ˜aωb
νdhb ˜b. All we can now conclude is that this contributes to the scat-
tering amplitude a term of the form Bab ˜η˜a ˜b, with Bab an arbitrary matrix. To this order,
the second term in (7) also contributes, breaking the “enhanced Lorentz” symmetries com-
pletely. Nevertheless, we can still exploit the known symmetry properties of the Riemann
curvature tensor under interchange of its indices to say something about its contribution
to the scattering amplitude. Putting it all together we conclude that
Mab, ˜a ˜b →cz2ηab ˜η˜a ˜b + z(ηab ˜A˜a ˜b + Aab ˜η˜a ˜b) + Aab˜a ˜b + (ηab ˜B ˜a ˜b + Bab ˜η˜a ˜b) + O
1
z
	
(8)
Compare this with (N.3.12), which states that the amplitude for the scattering of a hard
gluon off a background of soft gluons goes like Mab = (cz + . . .)ηab + Aab + 1
zBab + . . ..
Amazingly, you can see that the large-z behavior for the scattering of a hard graviton off a
background of soft gravitons can be obtained by “squaring” the large-z behavior for the
scattering of a hard gluon off a background of soft gluons! In other words, Mab, ˜a ˜b ∼
MabM˜a ˜b, as far as the large-z behavior is concerned.
Just as in the Yang-Mills case, by exploiting gauge identities like pra(z)Ma ˜a,b ˜bϵsb ˜b(z) =
0, we can determine the large-z behavior of various helicity amplitudes. For your conve-
nience I remind you that (from the preceding chapter) pr(z) = pr + zq and ps(z) = ps −
zq.
Thus
the
gauge
identity
just
displayed
says
that
qaMa ˜a,b ˜bϵsb ˜b(z) =
−(1/z)praMa ˜a,b ˜bϵsb ˜b(z). Recalling [see (1)] that ϵ−−μν
r
(z) = qμqν we see that in calcu-
lating the amplitude M−−,h(z) we can effectively replace ϵ−−μν
r
(z) by (1/z2)pμ
r pν
r . Thus
we can immediately conclude, since ϵ++μν
s
(z) ∼z0 for large z [see (2], that for example
M−−,++(z) →1
z2
(9)
which is far better than the naive expectation M−−,++
naive
(z) →zn−1. Indeed, the horrible
ever-escalating behavior with increasing n has disappeared. Even more remarkably, the
large-z behavior of graviton scattering amplitudes is consistent with the string-inspired
notion that gravity is “the square of Yang-Mills.” Recall that in gauge theory M−+(z) →1/z.
Thus, for large z, indeed M−−,++(z) ∼(M−+(z))2.
The bottom line here is that the large-z behavior of gravity is surprisingly benign and
vanishes fast enough for the recursion program to work.
Gravity is a square?
So, is Einstein gravity secretly the square of Yang-Mills theory?
Already we have seen in the preceding chapter, anticipating that the recursion pro-
gram works, that the primitive 3-point amplitude for gravity (for one helicity configura-
tion) (⟨12⟩3/⟨23⟩⟨31⟩)2 is the square of the primitive 3-point amplitude for gauge theory

N.4. Gravity and Yang-Mills Theory | 519
(⟨12⟩3/⟨23⟩⟨31⟩), something that you could have never suspected by staring at √−gR and
trFμνF μν untill you are blue in the face.
The calculations in the previous section show that the large-z behavior for the scattering
of a hard graviton off a background of soft gravitons could be obtained by “squaring” the
large z behavior for the scattering of a hard gluon off a background of soft gluons, certainly
something that nobody could have anticipated by looking at Lagrangians.
Further evidence that the answer to the title of this chapter is “yes” comes from a recent
calculation by Bern, Carrasco, and Johansson. Interestingly, they do not strip the color
from a Yang-Mills theory, but instead show that they can write the “color-dressed” tree
amplitudes in the form
Atree(1, 2, . . . , n) =

a
naca
(jp2
j)a
(10)
It is beyond the scope of this book to explain in detail how this expression is obtained. I
merely state that the index a labels an individual diagram. For each diagram, the amplitude
may be written as the product of a kinematic function na of the momenta and a color factor
ca, divided by the product of the momenta pj carried by the internal lines. (I do not explain
here how na and ca are defined.) The tree amplitude is then given by a sum over all tree
diagrams.
Bern et al. then conjecture that the n-graviton scattering amplitude at the tree level is
given, amazingly, by
Mtree
gravity(1, 2, . . . , n) =

a
nana
(jp2
j)a
(11)
They have checked by explicit computation that their conjecture in fact holds up to n = 8.
Furthermore, they have also verified that the conjecture, suitably generalized, also holds
for the various supercousins of Einstein gravity and Yang-Mills theory.
Thus the evidence is extremely strong that, yes indeed, Einstein gravity is secretly the
square of Yang-Mills theory, at least at the level of tree amplitudes. However, as of this
writing (February 2009), there is no definitive understanding within field theory. The final
word on the subject has yet to be said, and it is not even clear what the final path to the final
word might be. I would be foolish indeed to discuss this further in a textbook when the
entire subject is being rapidly developed. By the time this book is published, the conjecture
that Einstein gravity is the square of Yang-Mills theory may well have been proved. If not,
then nothing would please me more than if a reader of this textbook could go on and prove
it, hopefully not just at the tree level, but to all orders.
What is the simplest field theory?
The uninitiated would likely answer ϕ4 theory. Indeed, field theory texts almost all start with
some kind of scalar field theory. Even I am not able to do any better. But the sophisticated,
namely you, now that you have reached the end of this text, realize that the more symmetry
the theory has the better. To theoretical physicists, simplicity actually secretly means

520 | Part N
symmetry. Incidentally, I have always hated scalar field theories, and have ventured to
say so publicly. It is hard to like the action L = 1
2(∂ϕ)2 −λϕ4, so barren of color and flavor.
Some of the major problems facing particle physics, such as the hierarchy problem, may
eventually turn out to stem from our not having mastered scalar field theory.
Of course, scalar field theory is the simplest in the superficial sense that you need to
know the least to approach it. As I said in chapter I.12, once one is familiar with scalar
field theory the rest consists of “merely” decorating the field with various indices describing
spacetime or internal symmetries. But the symmetry and the resulting structure provide
us with handles to grab on to. Both Yang-Mills theory and Einstein gravity have an internal
logic sorely lacking in scalar field theory. As I mentioned in chapters VII.3 and VIII.4,
the consensus view is that the first exactly soluble field theory would almost certainly be
N = 4 supersymmetric Yang-Mills theory, the supercousin of pure Yang-Mills theory. The
remarkable recent developments described in the last three chapters have only reinforced
this view. Almost beyond belief, even gravity may be simpler than we had long thought.
For large complexified momentum, graviton scattering for some helicity arrangements
actually behaves better than gluon scattering. The evidence is mounting that Einstein
gravity may in some sense be the square of Yang-Mills theory. So now we are left with the
amusing thought that the simplest field theory may well end up being gravity or N = 8
supergravity with its maximal supersymmetry. (At this point, a friend of mine who works
with N = 8 supergravity pipes up, “It sure doesn’t look simpler if you are the guy doing
the calculation!” It is clear from the simple dimensional argument of chapter III.2 that
as one goes to higher order, the numerator of the Feynman integrand quickly becomes
extremely involved.)
Only time will tell who will win the simplest field theory contest, but we do have two
convincing candidates.

More Closing Words
In the closing words to the first edition of this book, I wrote that Yang-Mills theory
was almost begging for a better notation that would lay bare the deeper structure of the
theory. Oy, the excess baggage we have to carry! Ten thousand terms instead of one. In
some respects, the spinor helicity formalism and the recursion program explained in
chapters N.2–N.4 provide a partial answer to that pious wish.
Imagine some theorist idly wondering, after 1865, if there were a better notation to
describe the six fields Ex, Ey, Ez, Bx, By, Bz for which Maxwell had written 20 equations
(since he did not use vector notation). We can even fantasize that by fooling around with
numerology (“Look, 4 . 3/2 = 6!”), this “crackpot” came up with an antisymmetric 4 by 4
matrix he called F. Shoehorning Maxwell’s equations in vacuum (some of them stating
that the time variation of E and B is related to the space variation of E and B) into this
strange notation, this guy could even stumble on a secret connection between space and
time.
The spinor helicity formalism and the recursion program, though elegant, are still
rooted in the perturbative expansion of the 1940s. Can they be pushed into the nonpertur-
bative regime? There have been attempts in that direction.
In all previous revolutions in physics, a formerly cherished concept has to be jettisoned.
If we are poised before another conceptual shift, something else might have to go. Lorentz
invariance, perhaps? More likely, we may have to abandon strict locality. Again, in closing
words I mumble something (from steepest descent to integral to what?) about modifying
the form of the path integral. The recursion program and the resuscitated S-matrix ap-
proach might be a step in this direction, formulating field theory while avoiding mention
of a local Lagrangian. But we need analyticity, and of course analyticity follows from local-
ity and causality, as far as we understand. We know also that even local field theory could
spawn non-local constructs, most notoriously the horizon of a black hole. But there the

522 | Closing Words to Part N
dynamics bends the causal structure of spacetime out of whack. The lack of strict locality
is not built into the laws of physics.
Of course, we also know how to imbue physics with non-locality right from the start.
We have Wilson’s lattice formulation of gauge theory, and more recently, Wen’s intriguing
lattice formulation of gravity.
When I showed the last three chapters to our friend SE, she mused, after some reflection,
“Now I see what theorists could always do when in doubt: enhance the symmetry and make
it local, complexify and bow to Cauchy, and take a square root when possible!”
I nodded, “These are the three ways of the warrior theorist: I call them the Einstein
way, the Heisenberg way, and the Dirac way. They were wildly successful in the past, and
perhaps they will work in the future as well.”
With this edition of my textbook, I can no doubt count on a new group of readers to
come up with fresh insights into field theory. As these new chapters suggest, there may
still be plenty of secret structures to uncover. And thus field theory marches on.
Finally, I reveal the origin of the quote at the start of the preface to the second edition. As a
kid, Feynman came across a calculus book1 that proclaimed “What one fool can do, another
can.” He was thus inspired to master calculus. Now that you have mastered quantum field
theory, you can switch from the “understand” in the preface to the “do” in these closing
words.
1 Silvanus P. Thompson (1851–1916), Calculus Made Easy, 1910, updated by Martin Gardner, St. Martin’s Press,
(1998). I am kind of trying to do for quantum field theory what Thompson did for calculus.

Appendix A
Gaussian Integration and the Central
Identity of Quantum Field Theory
The basic Gaussian:
 +∞
−∞
dxe−1
2 x2 =
√
2π
(1)
The scaled Gaussian:
 +∞
−∞
dxe−1
2 ax2 =
2π
a
	 1
2
(2)
Moments:
 +∞
−∞
dxe−1
2 ax2x2n =
2π
a
	 1
2 1
an (2n −1)(2n −3) . . . 5 . 3 . 1, n ≥1
(3)
Gaussian with source:
 +∞
−∞
dxe−1
2 ax2+Jx =
2π
a
	 1
2
eJ 2/2a
(4)
 +∞
−∞
dxe−1
2 ax2+iJx =
2π
a
	 1
2
e−J 2/2a
(5)
 +∞
−∞
dxe
1
2 iax2+iJx =
2πi
a
	 1
2
e−iJ 2/2a
(6)
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dx1dx2 . . . dxN e
i
2 x.A.x+iJ.x =
(2πi)N
det[A]
	 1
2
e−(i/2)J.A−1.J
(7)
 +∞
−∞
 +∞
−∞
. . .
 +∞
−∞
dx1dx2 . . . dxN e−1
2 x.A.x+J.x =
(2π)N
det[A]
	 1
2
e
1
2 J.A−1.J
(8)
In what follows, we omit an overall factor.
Central identity of quantum field theory:

Dϕe−1
2 ϕ.K.ϕ−V (ϕ)+J.ϕ = e−V (δ/δJ)e
1
2 J.K−1.J
(9)

524 | Appendix A. Gaussian Integration
A trivial variation:

Dϕe−1
2 ϕ.K.ϕ+J.ϕ = e
1
2 J.K−1.J
(10)
Variations:

Dϕe(i/2)ϕ.K.ϕ+iJ.ϕ = e−(i/2)J.K−1.J
(11)

Dϕei 
ddx[ 1
2 ϕ(x)Kϕ(x)+J(x)ϕ(x)] = ei 
ddx[−1
2 J(x)K−1J(x)]
(12)

Dϕe−
ddx[ 1
2 ϕ(x)Kϕ(x)+J(x)ϕ(x)] = e

ddx[ 1
2 J(x)K−1J(x)]
(13)
(where K or K−1 or both may be nonlocal)
A specific example:

Dϕei 
ddx[(λ/2)ϕ2+ϕ ¯ψψ] = ei 
ddx[−(1/2λ)( ¯ψψ)2]
(14)
For K hermitean with ϕ complex:

Dϕ†Dϕe−ϕ†.K.ϕ+J †.ϕ+ϕ†.J = eJ †.K−1.J
(15)
As noted earlier, various numerical factors have been swept under the integration measure. In applying these
formulas, be sure that these factors are not relevant for your purposes.

Appendix B
A Brief Review of Group Theory
I give here a brief review of the group theory I will need in the text. I assume that you have been exposed to some
group theory, otherwise this instant review might not be intelligible. Most of the concepts are illustrated with
examples, and it goes without saying that you should work out all the examples and verify the assertions made
without proof.
SO(N)
The special orthogonal group SO(N) consists of all N by N real matrices O that are orthogonal
OT O = 1
(1)
and have unit determinant
det O = 1
(2)
We denote the element in the ith row and jth column by Oij. The group SO(N) consists of rotations in N-
dimensional Euclidean space and its defining or fundamental representation is given by the N component vector
⃗v = {vj , j = 1, . . . , N}, which transforms under the action of the group element O according to (as always, all
repeated indices are summed over)
vi →v′i = Oijvj
(3)
We define tensors as objects that transform as if they are equal to the product of vectors. For example, the tensor
T ijk transforms according to
T ijk →T ′ijk = OilOjmOknT lmn
(4)
as if it is equal to the product vivjvk. The emphasis is on the phrase “as if”: T ijk is not to be thought of as being
equal to vivjvk.
It is important to develop some “feel” or intuition for groups and their representations. Some people find
it helpful to picture a certain number of objects being acted upon by the group and transformed into linear
combinations of each other. Thus, picture T ijk as N3 objects being scrambled together.
Tensors furnish representations of the group. In our particular example, each group element is represented
by an N3 by N3 matrix acting on the N3 objects T ijk. The number of objects in a tensor is called the dimension
of the representation.
It may well be that any given object in a representation does not transform, under all the elements of the group,
into a linear combination of all the other objects, but only into a subset of them. Let me illustrate with an example.

526 | Appendix B. Brief Review of Group Theory
Consider T ij →T ′ij = OilOjmT lm. Form the symmetric Sij ≡1
2(T ij + T ji) and antisymmetric combinations
Aij ≡1
2(T ij −T ji). The symmetric combination Sij transforms into OilOjmSlm, which is obviously symmetric.
Similarly, Aij transforms into OilOjmAlm, which is obviously antisymmetric . In other words, the set of N2
objects contained in T ij split into two sets: 1
2N(N + 1) objects contained in Sij and 1
2N(N −1) objects contained
in Aij. The Sij’s transform among themselves and the Aij’s transform among themselves.
The representation furnished by T ij is said to be reducible: It breaks apart into two representations. Obviously,
representations that do not break apart are called irreducible.
We just exploited the obvious fact that the symmetry properties of a tensor under permutation of its indices is
not changed by the group transformation, namely that the indices on a tensor transform independently, as in (4).
The various possible symmetry properties may be classified with Young tableaux, which is useful in a general
treatment of group theory. Fortunately, in the field theory literature one rarely encounters a tensor with such
complex symmetry properties that one has to learn about Young tableaux.
Another way of saying this is that we can restrict our attention to tensors with definite symmetry properties
under permutation of their indices. In our specific example, we can always take T ij to be either symmetric or
antisymmetric under the exchange of i and j.
We have yet to use the properties (1) and (2). Given a symmetric tensor T ij consider the combination
T ≡δijT ij, known as the trace. Then T →δijT ′ij = δijOilOjmT lm = (OT )liδijOjmT lm = δlmT lm = T , where
we used (1). In other words, T transforms into itself. We can subtract the trace from T ij forming the traceless
tensor Qij ≡T ij −(1/N)δijT . The 1
2N(N + 1) −1 objects contained in Qij transform among themselves.
To summarize, given two vectors v and w, we can form a tensor, and decompose the tensor into a symmetric
traceless combination, a trace, and an antisymmetric tensor. This process is written as
N ⊗N = [ 1
2N(N + 1) −1] ⊕1 ⊕1
2N(N −1)
(5)
In particular, for SO(3), 3 ⊗3 = 5 ⊕1 ⊕3, a relation you should be familiar with from courses on mechanics
and electromagnetism.
There are two conventions for naming representations. We can simply give the dimension of the representa-
tion. (This can occasionally be ambiguous: Two distinct representations may happen to have the same dimension.)
Alternatively, we can specify the symmetry properties of the tensor furnishing the representation. For instance,
the representation furnished by a totally antisymmetric tensor of n indices is often denoted by [n] and the rep-
resentation furnished by a totally symmetric traceless tensor of n indices by {n}. Obviously, [1] = {1}. In this
notation, the decomposition in (5) can be written as {1} ⊗{1} = {2} ⊕{0} ⊕[2]. For the group SO(3), with its
long standing in physics, the confusion over names is almost worse than in reading Russian novels: For instance,
{1} is also known as p and {2} as d.
We have yet to use (2). Using the antisymmetric symbol ε123...N, we write (2) as
εi1i2...iNOi11Oi22 . . . OiNN = 1
(6)
or equivalently
εi1i2...iNOi1j1Oi2j2 . . . OiNjN = εj1j2...jN
(7)
By multiplying (7) by OT repeatedly, we can obviously generate more identities. Instead of drowning in a sea of
indices, let me explain this point by specializing to say N = 3. Thus, multiplying (7) by (OT )jNkN , we obtain
εi1i2i3Oi1j1Oi2j2 = εj1j2j3(OT )j3i3
Speaking loosely, we can think of moving some of the O’s on the left hand side of (7) to the right hand side,
where they become OT ’s.
Using these identities, you can easily show that [n] is equivalent to [N −n], that is, these two representations
transform in the same way. For example, as is well known, in SO(3) the antisymmetric 2-index tensor is equivalent
to the vector. (The cross product of two vectors is a vector.)
Any orthogonal matrix can be written as O = eA. The conditions (1) and (2) imply that A is real and
antisymmetric, so that A may be expressed as a linear combination of N(N −1)/2 antisymmetric matrices
denoted by iJ ij: O = eiθijJ ij (with repeated indices summed over). We have defined J ij as imaginary and
antisymmetric and hence hermitean. Since the commutator [J ij , J kl] is antihermitean, it can be written as a
linear combination of the iJ’s.
Ironically, some students are confused at this point because of their familiarity with SO(3), which has special
properties that do not generalize to SO(N).
In speaking about rotations in 3-dimensional space we can specify a rotation as either around say the third
axis, with the corresponding generator J 3, or as in the (1-2)-plane, with the corresponding generator J 12 = −J 21.

Appendix B. Brief Review of Group Theory | 527
In higher dimensions, for example 10-dimensional space, we can speak of a rotation in the (6-7)-plane, with the
corresponding generator J 67 = −J 76, but it is nonsense to speak of a rotation around the fifth axis. Thus, to
generalize to higher dimensions we should write the standard commutation relation [J 1, J 2] = iJ 3 for SO(3) as
[J 23, J 31] = iJ 12, which can be generalized immediately to
[J ij , J kl] = i(δikJ jl −δjkJ il + δjlJ ik −δilJ jk)
(8)
The right hand side reflects the antisymmetric character of J ij = −J ji. A potential confusion some students
may have about the notation: J ij denotes a matrix generating rotation in the (i-j)-plane, a matrix with element
(J ij)kl in the k-th row and l-th column. The indices i, j , k, and l all run from 1 to N, but in (J ij)kl the set {ij}
and the set {kl} should be distinguished conceptually: The former labels the generator and the latter are matricial
indices when the generator is regarded as a matrix. As an exercise, write down (J ij)kl explicitly and obtain (8) by
direct computation.
In studying group theory, as I have already remarked, one source of confusion comes from the fact that
some of the smaller groups, which we tend to encounter first in our studies, have special properties that do not
generalize. The special property of SO(3) we just noted is due to the fact that the antisymmetric symbol εijk carries
three indices and thus J ij may be written as J k ≡1
2εijkJ ij. For SO(4) the antisymmetric symbol εijkl carries four
indices and we can form the combinations 1
2(J ij ± 1
2εijklJ kl). Define J 1
± ≡1
2(J 23 ± J 14), J 2
± ≡1
2(J 31 ± J 24), and
J 3
± ≡1
2(J 12 ± J 34). By explicit computation, show that [J i
+, J j
+] = iεijkJ k
+, [J i
−, J j
−] = iεijkJ k
−, and [J i
+, J j
−] = 0.
This proves the well-known theorem that SO(4) is locally isomorphic to SO(3) ⊗SO(3).
I assume that you know that SO(3) is locally isomorphic to SU(2). If you don’t, I give a brief review below.
With a few i’s included here and there, these two results prove the statement that the Lorentz group SO(3, 1)
is locally isomorphic to SU(2) ⊗SU(2), which we proved explicitly in chapter II.3. The Lorentz group can be
thought of as an “analytic continuation” of the rotation group SO(4). See below for a more precise statement.
One highly non-obvious result of group theory is that SO(N) contains representations other than vector and
tensor. I develop the relevant group theory for the spinor representations in chapter VII.7.
SU(N)
We next turn to the special unitary group SU(N) consisting of all N by N matrices U that are unitary
U†U = 1
(9)
and have unit determinant
det U = 1
(10)
The story of SU(N) has more or less the same plot as the story of SO(N) with the crucial difference that the
tensors of the unitary groups can carry both upper and lower indices. We denote the element in the ith row and
jth column by Ui
j; the wisdom of this notation will soon become apparent.
The defining or fundamental representation of SU(N) consists of N objects ϕj , j = 1, . . . , N, that transform
under the action of the group element U according to
ϕi →ϕ′i = Ui
jϕj
(11)
Taking the complex conjugate of (11) we have
ϕ∗i →(Ui
j)∗ϕ∗j = (U†)j
i ϕ∗j
(12)
We invite ourselves to define an object we write as ϕi that transforms in the same way as ϕ∗i; thus
ϕi →ϕ′
i = (U†)j
i ϕj
(13)
Note that we did not say that ϕi is equal to ϕ∗i; we merely said that ϕi and ϕ∗i transform in the same way.
As before, we can have tensors. The tensor ϕij
k , for example, transforms as if it is equal to the product ϕiϕjϕk :
ϕij
k →ϕ′ij
k = Ui
l Uj
m(U†)n
kϕlm
n
(14)

528 | Appendix B. Brief Review of Group Theory
Again, we emphasize that we did not say that ϕij
k is equal to ϕiϕjϕk. (In some books ϕi is called a covariant vector
and ϕi a contravariant vector. A tensor ϕ......
...
with m upper indices and n lower indices is defined to transform as
if it is equal to the product of m covariant vectors and n contravariant vectors.)
The possibility of complex conjugation in SU(N) leads naturally to having indices “upstairs” and “downstairs.”
Note that (9) can be written out explicitly as (U†)k
i Uj
k = δj
i and thus the Kronecker delta in SU(N) carries one
upper and one lower index. It is important when taking traces that we set an upper index equal to a lower index
and sum over them: for example, we can consider δk
jϕij
k ≡ϕij
j , which transforms as
ϕij
j →Ui
l Uj
m(U†)n
jϕlm
n = Ui
l ϕlm
m
(15)
where we have used (9). In other words, ϕij
j , the trace of ϕij
k , denote N objects that transform into linear
combinations of each other in the same way as ϕi. Thus, given a tensor, we can always subtract out its trace.
As in the discussion for SO(N), tensors furnish representations of the group. The discussion proceeds as
before. The symmetry properties of a tensor under permutation of its indices are not changed by the group
transformation.
Another way of saying this is that given a tensor we can always take it to have definite symmetry properties
under permutation of its upper indices and under permutation of its lower indices. In our specific example, we
can always take ϕij
k to be either symmetric or antisymmetric under the exchange of i and j and to be traceless.
Thus, the symmetric traceless tensor ϕij
k furnishes a representation with dimension 1
2N2(N + 1) −N and the
antisymmetric traceless tensor ϕij
k a representation with dimension 1
2N2(N −1) −N.
Thus, in summary, the irreducible representations of SU(N) are realized by traceless tensors with definite
symmetry properties under permutation of indices. For example, in SU(5), some commonly encountered
representations are ϕi, ϕij (antisymmetric), ϕij (symmetric), ϕi
j , ϕij
k (antisymmetric in the upper indices and
traceless) with dimensions 5, 10, 15, 24, and 45, respectively. Convince yourself that for SU(N) the dimensions
of the representations defined by these tensors are N, N(N −1)/2, N(N + 1)/2, N2 −1, and 1
2N2(N −1) −N,
respectively.
The representation defined by the traceless tensor ϕi
j is known as the adjoint representation. By definition,
it transforms according to ϕi
j →ϕ′i
j = Ui
l (U†)n
jϕl
n = Ui
l ϕl
n(U†)n
j. We are thus invited to regard ϕi
j as a matrix
transforming according to
ϕ →ϕ′ = UϕU†
(16)
Note that if ϕ is hermitean it stays hermitean, and thus we can take ϕ to be a hermitean traceless matrix. (If ϕ
is antihermitean we can always multiply it by i.) Another way of saying this is that given a hermitean traceless
matrix X, UXU† is also hermitean and traceless if U is an element of SU(N).
As in the SO(N) story, representations of SU(N) have many names. For example, we can refer to the
representation furnished by a tensor with m upper and n lower indices as (m, n). Alternatively, we can refer
to them by their dimensions, with an asterisk to distinguish representations with mostly lower indices from the
representations with mostly upper indices. For example, an alias for (1, 0) is N and for (0, 1) is N∗. A square
bracket is used to indicate that the indices are antisymmetric and a curly bracket indicate that the indices are
symmetric. Thus, the 10 of SU(5) is also known as [2, 0] = [2], where as indicated the 0 (no lower index) is
suppressed. Similarly, 10∗is also known as [0, 2] = [2]∗.
The condition (10) can be written as either
εi1i2...iNUi1
1 Ui2
2 . . . UiN
N = 1
(17)
or
εi1i2...iNU1
i1U2
i2 . . . UN
iN = 1
(18)
Thus, we have two antisymmetric symbols εi1i2...iN and εi1i2...iN that we can use to raise and lower indices. Again,
we can immediately generalize (17) to
εi1i2...iNUi1
j1Ui2
j2 . . . UiN
jN = εj1j2...jN
and multiplying this identity by (U†)jN
pN and summing over jN we obtain
εi1i2...pNUi1
j1Ui2
j2 . . . UiN−1
jN−1 = εj1j2...jN(U†)jN
pN

Appendix B. Brief Review of Group Theory | 529
Clearly, by repeating this process, we can peel off the U’s on the left hand side and put them back as U†’s on the
right hand side. We can play a similar game with (18).
To avoid drowning in a sea of indices, let me show you how to raise and lower indices in a specific example
rather than in general. Consider the tensor ϕij
k in SU(4). We expect that the tensor ϕkpq ≡ϕij
k εijpq will transform
as a tensor with three lower indices. Indeed,
ϕkpq ≡ϕij
k εijpq →εijpqUi
l Uj
m(U†)n
kϕlm
n = εlmst(U†)s
p(U†)t
q(U†)n
kϕlm
n = (U†)n
k(U†)s
p(U†)t
qϕnst
As in SO(N) we can look at the generators of SU(N) by noting that any unitary matrix can be written as
U = eiH, with H hermitean and traceless as required by (9) and (10). There are (N2 −1) linearly independent
N by N hermitean traceless matrices T a (a = 1, 2, . . . , N2 −1). Any N by N hermitean traceless matrix can be
written as a linear combination of the T a’s and thus we can write U = eiθaT a, where θa are real numbers and the
index a is summed over.
Since the commutator [T a, T b] is antihermitean and traceless, it can also be written as a linear combination
of the T a’s:
[T a, T b] = if abcT c
(19)
(with the index c summed over.) The commutation relations (19) define the Lie algebra of SU(N), and f abc are
known as the structure constants. For SU(2) the structure constants f abc are simply given by the antisymmetric
symbol εabc.
Sometimes students are confused by how the generators act. Consider an infinitesimal transformation
U ≃1 + iθaT a. On the defining representation, ϕi →Ui
jϕj ≃ϕi + iθa(T a)i
jϕj. Thus, the ath generator acting
on the defining representation gives T aϕ. Now consider the adjoint representation (16)
ϕ →ϕ′ ≃(1 + iθaT a)ϕ(1 + iθaT a)† ≃ϕ + iθaT aϕ −ϕiθaT a = ϕ + iθa[T a, ϕ]
(20)
In other words, the ath generator acting on the adjoint representation gives [T a, ϕ]. Perhaps some students are
confused by the fact that ϕ is used as a generic symbol to denote different objects.
Since the adjoint representation ϕ is hermitean and traceless it can also be written as a linear combination of
the generators, thus ϕ = ϕbT b. Using (19) we can thus also write (20) as ϕc →ϕ′c ≃ϕc −f abcθaϕb. In particular
for SU(2), the three objects ϕa transform as a 3-vector. (Note the notation: ϕa is not to be confused with ϕi : in
SU(2) the index a = 1, 2, 3 while i = 1, 2.)
This last remark essentially amounts to a proof that SU(2) is locally isomorphic to SO(3). I will now give a
somewhat more formal proof. Any 2 by 2 hermitean traceless matrix X can be written as a linear combination of
the three Pauli matrices X = ⃗x . ⃗σ with three real coefficients (x1, x2, x3), which we regard as the components of a
3-vector ⃗x. For any element U of SU(2), X′ ≡U†XU is hermitean and traceless, so that we can write X′ = ⃗x′ . ⃗σ .
Note that we have implicitly used the first defining property of an SU(2) matrix (9). By explicit computation,
we find detX = −⃗x2. Invoking the second defining property of an SU(2) matrix (10), we obtain detX′ = detX
and thus ⃗x′2 = ⃗x2. The 3-vector ⃗x is rotated into the 3-vector ⃗x′. Thus we can associate a rotation with any given
U. Since U and −U are associated with the same rotation, this gives a double covering of SO(3) by SU(2). A
physicist would just say that when a spin 1
2 particle is rotated through 2π, its wave function changes sign. The
map clearly preserves group multiplication: if two elements U1 and U2 of SU(2) are mapped to the rotations R1
and R2 respectively, then the element U1U2 is mapped to the rotation R1R2. Alternatively, noting that trX2 = ⃗x2
and trX′2 = trX2, we obtain the same conclusion.
Once again, the two special unitary groups that most students learn first, namely SU(2) and SU(3), have
special properties that do not generalize to SU(N), just as SO(3) has special properties that do not generalize to
SO(N), possibly leading to confusion.
For SU(2), because the antisymmetric symbol εij and εij carry two indices, it suffices to consider only tensors
with upper indices, all symmetrized: We can raise all lower indices of any tensor by contracting with εij repeatedly.
After this is done, we can remove any pair of indices in which the tensor is antisymmetric by contracting with
εij.
In particular, ϕi = εijϕj , which can be stated equivalently in terms of a special property of the Pauli matrices
σ2σ ∗
a σ2 = −σa
(21)

530 | Appendix B. Brief Review of Group Theory
so that
σ2(ei ⃗θ ⃗σ)∗σ2 = ei ⃗θ ⃗σ
(22)
For SU(2) (11) becomes
ϕi →ϕ′i = (ei ⃗θ ⃗σ)i
jϕj
Complex conjugating, we obtain
ϕ∗i →[(ei ⃗θ ⃗σ)i
j]∗ϕ∗j = [(−iσ2)ei ⃗θ ⃗σ(iσ2)]i
jϕ∗j
and so
iσ2ϕ∗→ei ⃗θ ⃗σ(iσ2ϕ∗)
We learn that iσ2ϕ∗transform in the same way as ϕ. Recall that we define ϕi to transform in the same way as ϕ∗i.
Thus, εijϕj transforms in the same way as ϕi. In the jargon, SU(2) is said to have only real and pseudoreal
representations, but not complex representations. A pseudoreal representation is equivalent to its complex
conjugate upon a similarity transformation. Recall that (21) figures into our discussion of charge conjugation in
chapter II.1 and of the Higgs doublet in chapter VII.2.
For SU(3) it suffices to consider only tensors with all their upper indices symmetrized and all their lower
indices symmetrized. Thus, the representations of SU(3) are uniquely labeled by two integers (m, n), where m
and n denote the number of upper and lower indices. The reason is that the antisymmetric symbols εijk and
εijk carry three indices. We can always trade a pair of lower indices in which the tensor is antisymmetric for one
upper index, and similarly for upper indices.
You can see easily that these special properties do not generalize beyond SU(2) and SU(3).
Multiplying representations together
In a course on quantum mechanics you learn how to combine angular momentum. We have already encountered
this concept in (5), which when specialized to SO(3), tells us that 3 ⊗3 = 5 ⊕1 ⊕3, as we noted. This is
sometimes described by saying that when we combine two angular momentum L = 1states we obtain L = 0, 1, 2.
Students are justifiably confused when this procedure is also known as addition of angular momentum.
Given two tensors ϕ and η of SU(N), with m upper and n lower indices and with m′ upper and n′ lower indices,
respectively, we can consider a tensor T with (m + m′) upper and (n + n′) lower indices that transforms in the
same way as the product ϕη. We can then reduce T by the various operations described above. This operation of
multiplying two representations together is of course of fundamental importance in physics. In quantum field
theory, for example, we multiply fields together to construct the Lagrangian.
As an example, multiply 5∗and 10 in SU(5). To reduce T ij
k = ϕkηij we separate out the trace ϕkηkj (which
transforms as a 5) after which there is nothing more we can do. Thus,
5∗⊗10 = 5 ⊕45
(23)
As another example, consider 10 ⊗10: ϕijηkl. It is easiest to write ηkl equivalently as a tensor with three lower
indices εmnhklηkl. The product 10 ⊗10 then carries two upper and three lower indices and we will write it as T ij
mnh.
Taking traces, we separate out T ij
mij, which we recognize as 5∗, and the traceless part of T ij
mnj, which we recognize
as 45∗(see above), thus obtaining:
10 ⊗10 = 5∗⊕45∗⊕50∗
(24)
As exercises you can work out
5 ⊗5 = 10 ⊕15
(25)
and
5 ⊗5∗= 1 ⊕24
(26)
You should recognize the 24 as the adjoint.

Appendix B. Brief Review of Group Theory | 531
In physics we are often called upon to multiply a tensor by itself. Statistics then plays a role. For instance,
SU(5) grand unification contains a scalar field ϕi transforming as 5. Because of Bose statistics, the product ϕiϕj
contains only the 15.
Restriction to subgroup
To explain the next group theoretic concept, let me take a physical example. The SU (3) of Gell-Mann and Ne’eman
transforms the three quarks u, d, and s into linear combinations of each other. It contains as a subgroup the
isospin SU(2) of Heisenberg, which transforms u and d, but leaves s alone. In other words, upon restriction to
the subgroup SU(2) the irreducible representation 3 of SU(3) decomposes as
3 →2 ⊕1
(27)
Consider an irreducible representation with dimension d of some group G. When we restrict our attention
to a subgroup H , the set of d objects will in general decompose into n subsets, containing d1, d2, . . . , dn objects,
such that the objects of each subset only transform among themselves under the action of H. This makes obvious
sense since there are fewer transformations in H than in G.
The decomposition of the fundamental or defining representation specifies how the subgroup H is embedded
in G. Since all representations may be built up as products of the fundamental representation, once we know
how the fundamental representation decomposes, we know how all representations decompose. For example,
in SU(3)
3 ⊗3∗= 8 ⊕1
(28)
while in SU(2)
(2 ⊕1) ⊗(2 ⊕1) = (3 ⊕1) ⊕2 ⊕2 ⊕1
(29)
Comparing (28) and (29) we learn that
8 →3 ⊕1 ⊕2 ⊕2.
(30)
Alternatively, we can simply look at the tensors involved. Consider ϕi of SU(3) where the index i takes on the
value 1, 2, 3. Let the index μ takes on the value 1, 2. Obviously, ϕi = {ϕμ, ϕ3} corresponds to an explicit display
of (27). Then ϕi
j = { ¯ϕμ
ν , ϕμ
3 , ϕ3
μ, ϕ3
3}, where the bar on ¯ϕμ
ν is to remind us that it is traceless. This corresponds
precisely to (30).
Actually, SU(3) also contains the larger subgroup SU(2) ⊗U(1), where the U(1) is generated by the traceless
hermitean matrix
⎛
⎜⎜⎝
−1
0
0
0
−1
0
0
0
2
⎞
⎟⎟⎠
We can then write (27) as 3 →(2, −1) ⊕(1, 2), where the notation is almost self-explanatory. Thus, (2, −1)
denotes a 2 under SU(2) with “charge” −1 under U(1).
In the text, we will decompose various representations of SU(5) and SO(10). Everything we do there will
simply be somewhat more elaborate versions of what we did here.
More on SO(4), SO(3,1), and SO(2,2)
In chapter II.3 you learned that acting on the two objects ψα with α = 1, 2 in the spinor representation ( 1
2 , 0),
the generators of rotation and boost are represented by Ji = 1
2σi and iKi = 1
2σi, respectively. I remind you that
the equal sign means “represented by.” For most purposes (for example, classifying quantum fields) and at the
level of rigor of this book, it suffices to think of the Lie algebra generated by commuting Ji and Ki. Occasionally,
however, it is useful to contemplate the actual group with group elements ei ⃗θ ⃗J and ei ⃗ϕ ⃗K.
In the spinor representation ( 1
2 , 0) the group elements are represented by ei ⃗θ ⃗σ
2 and e ⃗ϕ ⃗σ
2 . While ei ⃗θ ⃗σ
2 is special
unitary, the 2 by 2 matrix e ⃗ϕ ⃗σ
2 , bereft of the i, is merely special but not unitary. (Incidentally, to verify these and
subsequent statements, since you understand rotation thoroughly, you could, without loss of generality, choose

532 | Appendix B. Brief Review of Group Theory
⃗ϕ to point along the third axis, in which case e ⃗ϕ ⃗σ
2 is diagonal with elements e
ϕ
2 and e−ϕ
2 . Thus, while the matrix
is not unitary, its determinant is manifestly equal to 1.) This set of matrices defines the multiplicative group
SL(2, C), consisting of all 2 by 2 complex-valued matrices with unit determinant.
Let us count the number of generators of this group. Two conditions on the determinant (real part = 1,
imaginary part = 0) cut the four complex entries containing eight real numbers down to six numbers, which
accounts for the six generators of the Lorentz group SO(3, 1).
To exhibit the map explicitly, we extend the earlier discussion showing that SU(2) covers SO(3). Consider the
most general 2 by 2 hermitean matrix
XM = x0I −⃗x . ⃗σ =

 x0 −x3
x1 −ix2
x1 + ix2
x0 + x3

(31)
By explicit computation, detXM = (x0)2 −⃗x2. (To see this instantly, choose ⃗x to point along the third axis
and invoke rotational invariance.) Now consider X′
M = L†XML, with L an element of SL(2, C). Manifestly,
detX′
M = detXM and thus the transformation preserves (x0)2 −⃗x2 and hence corresponds to Lorentz transfor-
mations. Since L and −L give the same transformation x →x′, we see that SL(2, C) double covers SO(3, 1).
Mathematicians say that SO(3, 1) = SL(2, C)/Z2. If L is also unitary, then x0′ = x0 and the transformation is
a rotation. The SU(2) subgroup of SL(2, C) double covers the rotation subgroup SO(3) of the Lorentz group
SO(3, 1), that is, SO(3) = SU(2)/Z2.
Incidentally, if we introduce an i at a strategic location and define the 2 by 2 matrix XE = x4I + i⃗x . ⃗σ, regarding
(⃗x, x4) as a 4-dimensional vector, we have detXE = (x4)2 + ⃗x2, the Euclidean length squared of the 4-vector.
(Once again, choose ⃗x to point along the third axis so that XE is a diagonal matrix with elements x4 ± ix3.) Since
ei ⃗θ ⃗σ
2 = cos θ
2 + i sin θ
2 ( ˆθ . σ) with ˆθ a unit vector in the θ direction (to see this, once again choose ⃗θ to point along
the 3rd axis), we see that XE/((x4)2 + ⃗x2)
1
2 is an element of SU(2). (We will come back to this observation in the
next section.) Thus, for any two elements U and V of SU(2), the matrix X′
E = V †XEU can also be decomposed
in the form X′
E = x′4I + i⃗x′ . ⃗σ. Evidently, detX′
E = detXE. Thus the transformation preserves (x4)2 + ⃗x2 and
describes an element of SO(4). This shows explicitly that SO(4) is locally isomorphic to SU(2) ⊗SU(2). If
V = U, we have a rotation, and if V † = U, the Euclidean analog of a boost.
Note that while the rotation group SO(3) is compact, the Lorentz group SO(3, 1) is not, since the range of
the boost parameters ⃗ϕ is unbounded. In contrast, the group SO(4) is compact and thus can be covered by a
compact group, namely, SU(2) ⊗SU(2), but the noncompact group SO(3, 1) cannot be.
At this point, having done SO(4) and SO(3, 1), I might as well (with a wink toward the nuts who complained
that this book is not encyclopedic enough) throw in the group SO(2, 2) for use in part N. Let us strip the Pauli
matrix σ 2 (kind of a “troublemaker” or at least an odd man out) of his i and define (just for this paragraph)
σ 2 ≡

 0
−1
1
0

Any real 2 by 2 matrix XH could be decomposed as XH = x4I + ⃗x . ⃗σ. Now detXH = (x4)2 + (x2)2 −(x3)2 −(x1)2,
the quadratic form of a spacetime with two time and two space coordinates. The set of all linear transformations
(with unit determinant) on (x1, x2, x3, x4) that preserve this quadratic form defines the group SO(2, 2).
Introduce the multiplicative group SL(2, R) consisting of all 2 by 2 real-valued matrices with unit determinant.
For any two elements Ll and Lr of this group, consider the transformation X′
H = LlXHLr. Evidently, detX′
H =
detXH. This shows explicitly that the group SO(2, 2) is locally isomorphic to SL(2, R) ⊗SL(2, R). Although two-
timing theories are bound to be trouble, we could use SO(2, 2) formally in computing scattering amplitudes, as
we will see in chapter N.3.
Topological quantization of helicity
As promised, let us go back to the observation in the previous section that the matrix XE/((x4)2 + ⃗x2)
1
2 is an
element of SU(2). Define wA ≡xA/((x4)2 + ⃗x2)
1
2 for A = 1, 2, 3, 4. An arbitrary element of SU(2) can be written
as U = w4I + i ⃗w . ⃗σ, with det U = 1 = (w4)2 + ⃗w2. The 4-dimensional unit vector w = (w4, ⃗w) traces out the
3-sphere S3, the surface of the 4-ball B4 living in 4-dimensional Euclidean space. Thus the group manifold of
SU(2) is S3.
Next, recall that SU(2) double covers the rotation group SO(3), or in plain talk, two elements U and −U of
SU(2) corresponds to the same rotation. Thus the group manifold of SO(3) is S3/Z2, that is, the 3-sphere with
antipodal points identified.

Appendix B. Brief Review of Group Theory | 533
Consider closed paths in SO(3). Starting at some point P on S3, wander off a bit and come back to P. The
path you traced can evidently be continuously shrunk to a point. But suppose you go off to the other side of
the world and arrive at −P , the antipodal point of P. You also trace a closed path in SO(3) since P and −P
correspond to the same element of SO(3), but this closed path obviously cannot be shrunk to a point. On the
other hand, if after arriving at −P you keep going and eventually return to P, then the entire path you traced
can be continuously shrunk to a point. Using the language of homotopy groups introduced in chapter V.7, we
say that 1(SO(3)) = Z2: there are two topologically inequivalent classes of paths in the 3-dimensional rotation
group.
Now we can go back and tie up a loose end in chapter III.4. Back in school you learned that the nonlinear
algebraic structure of the Lie algebra [Ji, Jj] = iϵijkJk enforces quantization of angular momentum. But the little
group for a massless particle is merely O(2). In the “rich man’s approach” to gauge invariance, how do we get
the helicity of the photon and the graviton quantized?
The answer is that we invoke topological, rather than algebraic, quantization. A rotation through 4π is
represented by ei4πh on the helicity h state of the massless particle, but the path traced out by this rotation
can be continuously shrunk to a point. Hence, we must have ei4πh = 1 and h = 0, ± 1
2 , ±1, . . ..

Appendix C
Feynman Rules
Here we gather the Feynman rules given in various chapters.
Draw all possible diagrams. Label each line with a momentum. If applicable, also label each line with an
incoming and an outgoing Lorentz index (for a line describing a vector field), with an incoming and an outgoing
internal index (for a line describing a field transforming under an internal symmetry), so on and so forth.
Momentum is conserved at each vertex. Momenta associated with internal lines are to be integrated over with
the measure

[d4p/(2π)4]. A factor of (−1) is to be associated with each closed fermion loop. External lines
are to be amputated. For an incoming fermion line write u(p, s) and for an outgoing fermion line ¯u(p′, s′).
For an incoming antifermion, write ¯v(p, s), and for an outgoing antifermion, v(p′, s′). If there are symmetry
transformations leaving the diagram invariant, then we have to worry about the infamous symmetry factors.
Since I don’t trust the compilations in various textbooks I work out the symmetry factors from scratch, and that
is what I advise you to do.
Scalar field interacting with Dirac field
L = ¯ψ(iγ μ∂μ −m)ψ + 1
2[(∂ϕ)2 −μ2ϕ2] −λ
4!ϕ4 + f ϕ ¯ψψ
(1)
Scalar propagator:
k
i
k2 −μ2 + iε
(2)

Appendix C. Feynman Rules | 535
Scalar vertex:
−iλ
(3)
Fermion propagator:
p
i
̸p −m + iε = i
̸p + m
p2 −m2 + iε
(4)
Scalar fermion vertex:
if
(5)
Initial external fermion:
u(p, s)
(6)
Final external fermion:
¯u(p, s)
(7)
Initial external antifermion:
¯v(p, s)
(8)
Final external antifermion:
v(p, s)
(9)
Vector field interacting with Dirac field
L = ¯ψ(iγ μ(∂μ −ieAμ) −m)ψ −1
4FμνF μν −1
2μ2AμAμ
(10)
Vector boson propagator:
k
i
k2 −μ2
kμkν
μ2 −gμν
	
(11)
Photon propagator (with ξ an arbitrary gauge parameter):
k
i
k2

(1 −ξ)kμkν
k2
−gμν

(12)

536 | Appendix C. Feynman Rules
Vector boson fermion vertex:
μ
ieγ μ
(13)
Initial external vector boson:
εμ(k)
(14)
Final external vector boson:
εμ(k)∗
(15)
Nonabelian gauge theory
Gauge boson propagator:
k
i
k2

(1 −ξ)kμkν
k2
−gμν

δab
(16)
Ghost propagator:
k
i
k2δab
(17)
Cubic interaction between the gauge bosons:
a,μ
c,λ
b,ν
k1
k3
k2
gf abc[gμν(k1 −k2)λ + gνλ(k2 −k3)μ + gλμ(k3 −k1)ν]
(18)
Quartic interaction between the gauge bosons:
a,μ
b,ν
d,ρ
c,λ
−ig2[f abef cde(gμλgνρ −gμρgνλ)
+ f adef cbe(gμλgνρ −gμνgρλ)
+ f acef bde(gμνgλρ −gμρgνλ)]
(19)

Appendix C. Feynman Rules | 537
Gauge boson coupling to the ghost field:
c,μ
a
b
p
gf abcpμ
(20)
Cross sections and decay rates
Given the Feynman amplitude M for a process p1 + p2 →k1 + k2 + . . . + kn the differential cross section is
given by
dσ =
1
|⃗v1 −⃗v2|E(p1)E(p2)
d3k1
(2π)3E(k1) . . .
d3kn
(2π)3E(kn)(2π)4δ(4)(p1 + p2 −
n

i=1
ki)|M|2
(21)
Here ⃗v1 and ⃗v2 denote the velocities of the incoming particles. The energy factor E(p) = 2

⃗p2 + m2 for bosons
and E(p) =

⃗p2 + m2/m for fermions come from the different normalization of the creation and annhilation
operators in chapters I.8 and II.2.
For a decay of a particle of mass M the differential decay rate in its rest frame is given by
d =
1
2M
d3k1
(2π)3E(k1) . . .
d3kn
(2π)3E(kn)(2π)4δ(4)(P −
n

i=1
ki)|M|2
(22)

Appendix D
Various Identities and Feynman Integrals
Gamma matrices
Identities for the trace of a product of an even number of gamma matrices:
trγ μγ ν = 4ημν
(1)
trγ μγ νγ λγ σ = 4(ημνηλσ −ημληνσ + ημσηνλ)
(2)
We define the totally antisymmetric symbol εμνλσ by ε0123 = +1 (note ε0123 = −1). Then with our definition
γ 5 ≡iγ 0γ 1γ 2γ 3, we have
trγ 5γ μγ νγ λγ σ = −4iεμνλσ
(3)
Identities that follow from the basic Clifford identity:
γ μ̸pγμ = −2̸p
(4)
γ μ̸p ̸ qγμ = 4p . q
(5)
γ μ̸p ̸q ̸rγμ = −2̸r ̸q ̸p
(6)
I leave it to you to derive these identities. For example, to obtain (4) keep moving γ μ to the right in the expression
γ μ̸pγμ = (2pμ −̸pγ μ)γμ = 2̸p −4 ̸p = −2̸p.
Evaluating Feynman diagrams
Over the years, a number of tricks and identities have been developed for evaluating the integrals associated with
Feynman diagrams.
Let us evaluate
I =

d4k
(2π)4
1
(k2 −m2 + iε)3 =

d3k
(2π)3

dk0
2π
1
[k2
0 −(⃗k2 + m2) + iε]3
Focus on the k0 integral. Draw where the poles are in the complex k0-plane and you will see that the integration
contour can be rotated anticlockwise so that [we denote the integrand by f (k0)]
 +∞
−∞
dk0f (k0) =
 +i∞
−i∞
dk0f (k0) = i
 +∞
−∞
dk4f (ik4)
(7)

Appendix D. Identities and Feynman Integrals | 539
where in the last step we define k0 = ik4 (corresponding to the Wick rotation mentioned in chapters I.2 and V.2.)
Thus,
I = i(−1)3

d4
Ek
(2π)4
1
(k2
E + m2)3
where d4
Ek is the integration element in Euclidean 4-dimensional space and k2
E ≡k2
4 + ⃗k2 the square of a Euclidean
4-vector. The infinitesimal ε can now be set equal to zero. We can integrate immediately over the three angles
since the integrand does not depend on them. You can look up the angular element in Euclidean space in a book,
but we will use a neat trick instead.
I will do the more general d-dimensional integral H =

ddkF(k2), where k2 = k2
1 + k2
2 + . . . + k2
d and F can
be any function as long as the integral converges. (I now drop the subscript E; the context makes clear that we
are in Euclidean space.) We can of course set d equal to 4 at the end. The result for arbitrary d will be useful to
us in regularizing dimensionally (chapter III.1).
We
imagine
integrating
over
the
(d −1)
angular
variables
to
obtain
H = C(d)
 ∞
0
dk
kd−1F(k2). To determine C(d) we will do the integral J =

ddke−1
2 k2 in two different ways. Using (I.2.8) we
have J = (
√
2π)d. Alternatively,
J = C(d)
 ∞
0
dk kd−1e−1
2 k2 = C(d)2
d
2 −1
 ∞
0
dx x
d
2 −1e−x = C(d)2
d
2 −1(d
2 )
where we changed integration variables and recognized the integral representation of the gamma function
(z + 1) ≡
 ∞
0
dx xze−x. (Recall that upon integration by parts we obtain (z + 1) = z(z), so that (n) = (n −1)!
for n an integer.) Therefore C(d) = 2πd/2/ (d/2) and

ddkF(k2) = 2πd/2
(d/2)
 ∞
0
dk kd−1F(k2)
(8)
Setting d = 1 in (8) we determine ( 1
2) = π
1
2 , and setting F(k2) = δ(k −1) we see that the area of the (d −1)-
dimensional sphere is equal to C(d), thus recovering various results you learned in school about circles and
spheres: C(2) = 2π and C(3) = 4π.
The new result you need as a budding field theorist is for d = 4 :

d4kF(k2) = π2
 ∞
0
dk2k2F(k2)
(9)
So finally we have
I =
−i
16π2
 ∞
0
dk2k2
1
(k2 + m2)3 =
−i
16π2
1
2m2
(10)
We have derived the basic formula for doing Feynman integrals:

d4k
(2π)4
1
(k2 −m2 + iε)3 =
−i
32π2m2
(11)
(With the telltale iε we have evidently moved back to Minkowski space.) As an exercise you can go through the
same steps to find
 
d4k
(2π)4
1
(k2 −m2 + iε)2 =
i
16π2

log
2
m2
	
−1 + . . .

(12)
Here a cutoff is needed, which we introduce by setting the upper limit in the integral over k2 in the analog of
(10) to 2. As a check, differentiate (12) with respect to m2 to recover (11). As another exercise show that
 
d4k
(2π)4
k2
(k2 −m2 + iε)2 =
−i
16π2

2 −2m2 log
2
m2
	
+ m2 + . . .

(13)
In (12) and (13) (. . .) denote terms that vanish for 2 ≫m2. In some texts, the (−1) in (12) is dropped by absorbing
it into 2. But then we have to be careful to adjust (13) accordingly if it appears in the same calculation.

540 | Appendix D. Identities and Feynman Integrals
A useful identity in combining denominators is
1
x1x2 . . . xn
= (n −1)!
 1
0
 1
0
. . .
 1
0
dα1dα2 . . . dαn
δ
⎛
⎝1 −
n

j
αj
⎞
⎠
1
(α1x1 + α2x2 + . . . + αnxn)n
(14)
For n = 2,
1
xy =
 1
0
dα
1
[αx + (1 −α)y]2
(15)
and for n = 3,
1
xyz = 2
 1
0
 1
0
 1
0
dαdβdγ δ(α + β + γ −1)
1
(αx + βy + γ z)3
(16)
= 2
 
triangle
dαdβ
1
[z + α(x −z) + β(y −z)]3
where the integration region is the triangle in the α-β plane bounded by 0 ≤β ≤1 −α and 0 ≤α ≤1.

Appendix E
Dotted and Undotted Indices and the Majorana Spinor
We develop the dotted and undotted notation introduced in chapter II.3 for further use in discussing supersym-
metry in chapter VIII.4 and in part N. In essence, the appearance of undotted and dotted indices can be traced
back to the fact that the algebra of the Lorentz group SO(3, 1), with the generators ⃗J + i ⃗K and ⃗J −i ⃗K, breaks
up into two pieces, each isomorphic to the algebra of SU(2). The absence or presence of the dot allows us to keep
track of which SU(2) we are talking about.
Here I will use extensively results from chapter II.3 and from the exercises (do them!) there without bothering
to write them down again here.
In the Weyl basis of chapter II.1
γ μ =

 0
σ μ
¯σ μ
0

(1)
where σ μ = (I , ⃗σ) and ¯σ μ = (I , −⃗σ). Knowing that γ μ acts on
 =

 ψα
¯χ ˙α

we see that σ μ and ¯σ μ carry indices as follows:
(σ μ)α ˙α and (¯σ μ)˙αα
(2)
This is consistent with what you know: the Lorentz vector transforms like ( 1
2 , 1
2) and thus straddles the two
SU(2)’s. The matrices σ μ and ¯σ μ mix dotted and undotted indices. We will make good use of this observation
later.
Let us check that the Lorentz transformation property of the Dirac spinor  is consistent with what was
discussed in chapter II.1. There we learned that  →e−i
4 ωμνμν, where μν ≡i
2[γ μ, γ ν]. (We want to use the
symbol σ μν for some other quantity, hence the change of notation.) Using (1) we obtain
μν = 2i

 σ μν
0
0
¯σ μν

where σ μν ≡1
4 (σ μ ¯σ ν −σ ν ¯σ μ) and ¯σ μν ≡1
4 (¯σ μσ ν −¯σ νσ μ). From (2) we see that these two matrices carry indices
as follows:
(σ μν) β
α and (¯σ μν)˙α
˙β
(3)

542 | Appendix E. Indices and the Majorana Spinor
Again, this reflects the fact that the antisymmetric tensor (such as the electromagnetic field Fμν) transforms like
(1, 0) + (0, 1).
The matrices σ μν and ¯σ μν may seem alien, but recall that they are manufactured out of the familiar Pauli
matrices and so they are simply Pauli matrices (what else could they be?) themselves. In particular,
σ 0i = −¯σ 0i = −1
2σ i
and
σ ij = ¯σ ij = −i
2 εijkσ k
Note that these relations are consistent with (σ μν)† = −(¯σ μν), which in turn follows from (μν)† = γ 0μνγ 0.
Mother Nature is kind to the students of quantum field theory. The relativistic spinor  breaks up into two
2-component spinors acted on by the Pauli matrices. What you learned in nonrelativistic quantum mechanics
continues to be relevant here.
Thus under an infinitesimal Lorentz transformation
ψα →

I + 1
2ωμνσ μν β
α ψβ
(4)
and
¯χ ˙α →

I + 1
2ωμν ¯σ μν˙α
˙β ¯χ ˙β
(5)
You should check that it all works out according to plan. Everything is consistent with what we learned in chapter
II.3, in particular, that boosts act oppositely on ( 1
2 , 0) and (0, 1
2), but rotations act the same.
Thus far, on the spinor fields ψα and ¯χ ˙α, the dotted indices always live upstairs and the undotted indices
downstairs. What would get them to change floors? Charge conjugation.
Recall from chapter II.1 that the charge conjugated field is defined by c ≡C ¯T [where T denotes transpose,
¯ means †γ 0, and C−1γ μC = −(γ μ)T .] In the Weyl basis, we can choose
C = ζγ 0γ 2 = ζ

 −σ2
0
0
σ2

(6)
The condition (c)c =  implies |ζ| = 1. We choose ζ = −i. Explicitly,
c =

 iσ2 ¯χ∗
−iσ2ψ∗

We now introduce some notation, the wisdom of which will soon become clear. Given ψα and ¯χ ˙α, define
¯ψ˙α ≡(ψα)∗and χα ≡( ¯χ ˙α)∗
(7)
Weird, complex conjugation puts on a dot and a bar.
We raise and lower undotted indices as follows: ψα = εαβψβ and ψβ = εβγ ψγ which implies that εαβεβγ = δ γ
α .
Thus, if we choose
εαβ =

 0
1
−1
0

= (iσ2)αβ
then
εβγ =

 0
−1
1
0

= (−iσ2)βγ
We are forced to define ε12 = +1 and ε12 = −1 to have opposite signs, a fact to keep in mind.
You should realize by now that what we are doing can again be traced back to that peculiar fact about Pauli
matrices (appendix B):
(iσ2)σ ∗
i (−iσ2) = −σi
(8)
or equivalently
σ2σ T
i σ2 = −σi
(9)

Appendix E. Indices and the Majorana Spinor | 543
an identity in one guise or another familiar from quantum mechanics. We have used it again and again, in
appendix B and in the text (for example, in connection with Majorana masses and with the Higgs field). From
(8) we have (iσ2)σ μ∗(−iσ2) = ¯σ μ and hence
(iσ2)(σ μν)∗(−iσ2) = ¯σ μν
(10)
Analogously, we raise and lower dotted indices as follows: ¯ψ˙α = ε˙α ˙β ¯ψ ˙β and ¯ψ ˙β = ε ˙β ˙γ ¯ψ ˙γ . Referring to (7) we
see that ε˙α ˙β is numerically the same as εαβ, and ε ˙β ˙γ is numerically the same as εβγ .
You now see the rationale of these apparently capricious choices: we can now write
c =

 χα
¯ψ ˙α

(11)
Referring to
 =

 ψα
¯χ ˙α

(12)
we see that the point of the notation is that ψα and χα transform in the same way and are the same kind of
creature (and similarly for ¯χ ˙α and ¯ψ ˙α.)
We now come to the all-important concept of a Majorana spinor. Ettore Majorana, a brilliant physicist,
mysteriously disappeared early in his career. Fermi supposedly described Majorana as “a towering giant without
any common sense.”1
Given a Dirac spinor , if  = c, then  is said to be a Majorana spinor.
Comparing (12) and (11), we see that a Majorana spinor has the form
M =

 ψα
¯ψ ˙α

(13)
An obvious remark but a handy mnemonic: Given a Weyl spinor ψα we can construct a Majorana spinor, and
given two Weyl spinors we can construct a Dirac spinor: one Weyl equals one Majorana, and two Weyls equal
one Dirac.
Incidentally, another way of seeing that complex conjugation puts on a dot is that (see chapter II.3) conjugation
interchanges ⃗J + i ⃗K and ⃗J −i ⃗K.
The point to remember is simply that given a spinor λα, then λ˙α transforms like (λα)∗. You should verify this,
keeping in mind (10).
The utility of the notation is similar to that of the covariant and contravariant (or upper and lower) indices in
special and general relativity. We always contract an upper index with a lower index. Here we have the additional
rule that an undotted upper index can only be contracted with an undotted lower index, but never with a dotted
lower index, (obviously, since they belong to different algebras.) It is easy to verify these rules. For example, let
us show that ηαψα is invariant. Using (4) we proceed with laboriously careful pedagogy:
ηα →η′α = εαβη′
β = εαβ(e
1
2 ωσ) γ
β ηγ = εαβ(e
1
2 ωσ) γ
β εγρηρ = (e−1
2 ωσ T )α
ρηρ
(14)
where we used once again the identity (9). Then ηαψα →η(e−1
2 ωσ T )T (e
1
2 ωσ)ψ = ηψ, which is indeed an invariant.
In special and general relativity we raise and lower indices with the metric, which is of course symmetric.
Here we raise and lower indices with the antisymmetric ε symbol and as a result signs pop up here and there.
For example, ηαψα = εαβηβψα = ηβ(−εβα)ψα = −ηβψβ. Contrast this with the scalar product of two vectors
vμwμ = vμwμ. If we want to suppress indices and write ηψ, we must decide once and for all what that means.
The standard convention is to define
ηψ ≡ηαψα
(15)
and not ηβψβ. This rule is sometimes stated by saying that in contracting undotted indices we always go from
the northwest to the southeast, and never from southeast to northwest. As we learned in chapter II.5, spinor
fields are to be treated as anticommuting Grassman variables under the path integral, so that −ηβψβ = ψβηβ.
We end up with the nice rule ηψ = ψη.
1 M. Gell-Mann, private communication. Incidentally, the name Ettore corresponds to Hector in English.

544 | Appendix E. Indices and the Majorana Spinor
Similarly, we define
¯χ ¯ξ ≡¯χ˙α ¯ξ ˙α = ¯ξ ¯χ
(16)
In contracting dotted indices we always go from southwest to northeast. Of course, none of this “Santa Barbara
to Cambridge” convention is needed if the indices are displayed explicitly.
Just as in special and general relativity, where the upper and lower indices are very useful in telling us
whether expressions we write down make sense, the undotted and dotted upper and lower indices allow us
to see immediately that ηψ and ησ μνψ make sense, but that ησ μψ does not. [Look at (2) and (3) and notice the
kind of indices that appear.] The notation of course just codifies in a convenient way the group theory fact that
( 1
2 , 0) ⊗( 1
2 , 0) = (0, 0) ⊕(1, 0), namely, that out of two Weyl spinors we can make a scalar and a tensor but not
a vector.
As always, notation should be driven by physics and computational convenience (which is intimately con-
nected to elegance).
To gain familiarity with the dotted and undotted 2-component notation, you should work out some of the
identities in the exercises. These identities are useful when working with supersymmetric field theories.
Exercises
E.1
Show that ησ μνψ = −ψσ μνη and ¯χ ¯σ μψ = −ψσ μ ¯χ.
E.2
Show that (θϕ)( ¯χ ¯ξ) = −1
2(θσ μ¯ξ)( ¯χ ¯σμϕ).
E.3
Show that θαθβ = 1
2(θθ)δα
β. [Hint: simply evaluate the two sides for all possible cases.]

Solutions to Selected Exercises
Part I
I.3.1
From the text we have for x0 = 0,
D(x) = −i

d3k
(2π)32

⃗k2 + m2e−i⃗k.⃗x
= −
i
2(2π)2
 ∞
0
dkk2

⃗k2 + m2
 +1
−1
d(cos θ)e−ikr cos θ
= −
1
2(2π)2r
 ∞
0
dkk

⃗k2 + m2(eikr −e−ikr) = −
1
8π2r
 ∞
−∞
dkk

⃗k2 + m2eikr
=
i
8π2r
∂
∂r
 ∞
−∞
dk

⃗k2 + m2eikr
The integrand in I ≡
 ∞
−∞(dk/

⃗k2 + m2)eikr has a cut along the imaginary axis going from im to i∞(and
another cut we don’t care about.) So fold the contour around the cut and change variable to k = i(m + y):
I = 2
 ∞
0
dye−(y+m)r
1

(y + m)2 −m2
= 2
 ∞
1
due−mru
1
√
u2 −1
= 2
 ∞
0
dte−mr cosh t.

546 | Solutions to Selected Exercises
At this point you can look in a table and find that this is some Bessel function and read off the large r
behavior, but it is more stylish to press on and descend steeply: we obtain
D(x) = −im
4π2r
 ∞
0
dt(cosh t)e−mr cosh t
= −im
4π2r
 ∞
0
d(sinh t)e−mr cosh t
= −im
4π2r
 ∞
0
dse−mr√
s2+1 ≃−im
4π2r
 ∞
0
dse−mr(1+ 1
2 s2)
= −im2
4π2 (
π
2(mr)3)
1
2e−mr,
using the Gaussian integral from the appendix of chapter I.2.
I.3.2
We evaluate
D(x) =

d2k
(2π)2
eikx
k2 −m2 + iε
by contours as in the text and obtain
D(x) = −i

dk
(2π)2ωk
[e−i(ωkt−kx)θ(x0) + ei(ωkt−kx)θ(−x0)]
For x0 = 0, we recognize the integral
D(x) = −i
 +∞
−∞
dk
(2π)2

⃗k2 + m2e−ikx
as a Bessel function from exercise I.3.1:
D(x) = −i
2π K0(m|x|) →−i
2π

π
2m|x|e−m|x|
with the expected exponential decay for large x.
I.7.2
Expanding and keeping only the desired terms
Z(J) →C

1 + 1
2!

−i
4!λ
	2  
d4w1d4w2

δ
iδJ(w1)
4 
δ
iδJ(w2)
4
1
6!

−i
2
 
d4xd4yJ(x)D(x −y)J(y)
6
Just keep on differentiating.
I.7.4
Write k1 = (
√
k2 + m2, 0, 0, k) and k2 = (
√
k2 + m2, 0, 0, −k). Then E = 2
√
k2 + m2 ≥2m. Physically, a
pair of mesons can be produced when E ≥2m.
I.8.1
Do the k0 integral on the left-hand side of (I.8.14):

dk0δ((k0)2 −ω2
k)θ(k0)f (k0, ⃗k), where ωk ≡
+

⃗k + m2. Using (I.2.12) and picking up the positive root because of the step function, we obtain
 ∞
0
dk0(δ(k0 −ωk)/(2k0))f (k0, ⃗k) = f (ωk, ⃗k)/(2ωk).
To verify the invariance explicitly, boost in the x direction and drop the subscript on ωk: kx →
sinh φ ω + cosh φ kx and ω →cosh φ ω + sinh φ kx. Then, using ω2 = (kx)2 + . . . and hence ωdω =
kxdkx, we have dkx →(sinh φ (kx/ω) + cosh φ)dkx. Hence dkx/ω →dkx/ω.

Solutions to Selected Exercises | 547
I.8.2
Clearly, only the terms aa† and a†a in H contributes to < ⃗k′|H|⃗k > . Extract these two types of terms in

dDxϕ(x)2
=

dDx
 
dDq

(2π)D2ωq
dDq′

(2π)D2ωq′
[a(⃗q)a†(⃗q′)e−i(ωqt−⃗q.⃗x)ei(ωq′t−⃗q′.⃗x) + h.c.]
=
 dDq
2ωq
[a(⃗q)a†(⃗q) + a†(⃗q)a(⃗q)]
and so H is for our purposes effectively equal to

dDq
ωq
2 [a(⃗q)a†(⃗q) + a†(⃗q) a(⃗q)], which upon using
the commutation relation is equal to

dDq
ωq
2 [δ(D)(⃗0) + 2a†(⃗q)a(⃗q)]. We recognize the first term as the
vacuum calculated in the text. Note that the definition of the delta function (2π)Dδ(D)(⃗k) =

dDxei⃗k.⃗x
implies δ(D)(⃗0) = [1/(2π)D]

dDx = V/(2π)D. Thus, subtracting off the vacuum energy, we have H
effectively equal to

dDqωqa†(⃗q)a(⃗q), which just says that a mode of momentum ⃗q carries energy ωq.
In particular, using the commutation relation twice we have < ⃗k′|H|⃗k >= δ(D)(⃗k′ −⃗k)ωk. The energy of
a particle of momentum ⃗k is ωk relative to the vacuum.
I.8.4
Q =

dDxJ0(x) =

dDx(ϕ
†i∂0ϕ −i(∂0ϕ
†)ϕ). Focus on the first term:

dDx
 
dDk′

(2π)D2ωk′
dDk

(2π)D2ωk
[a†(⃗k′)ei(ωk′t−⃗k′.⃗x) + b(⃗k′)e−i(ωk′t−⃗k′.⃗x)]ωk[a(⃗k)e−i(ωkt−⃗k.⃗x) −b†(⃗k)ei(ωkt−⃗k.⃗x)]
Note that i∂0 brings down a factor of ωk and produces a relative sign between a and b†. As in exercise I.8.2
the integral over x produces a delta function that collapses the two k integrals into one, giving

dDk 1
2(a†(⃗k)a(⃗k) −b(⃗k)b†(⃗k) −a†(−⃗k)b†(⃗k)e2iωkt + b(−⃗k)a(⃗k)e−2iωkt)
The second term in −i(∂0ϕ†)ϕ in J0(x) is just the hermitean conjugate of the first term ϕ†i∂0ϕ. Thus,
adding the hermitean conjugate of what we have just obtained, we find
Q =

dDk[a†(⃗k)a(⃗k) −b(⃗k)b†(⃗k)]
=

dDk[a†(⃗k)a(⃗k) −b†(⃗k)b(⃗k)] + δ(D)(⃗0)

dDk
The infinite additive constant is to be subtracted out much like the vacuum energy. In some texts a normal
ordering operation, denoted by a pair of colons, is defined as follows: If you see : (. . .) : you are instructed
to move all the creation operators in the expression (. . .) to the left of the annihilation operators. In other
words, by fiat : b(⃗k)b†(⃗k) : ≡b†(⃗k)b(⃗k). The current is then defined by Jμ(x) ≡: (ϕ†i∂μϕ −i(∂μϕ†)ϕ) :.
Since the normal ordered current differs from the naively defined current by a c-number the most crucial
property of the current, namely current conservation ∂μJ μ = 0, is not affected. This is of course just a
formal way of saying that the value of the charge in the vacuum state is to be subtracted. In any case, the
result Q =

dDk[a†(⃗k)a(⃗k) −b†(⃗k)b(⃗k)] shows that a and b annihilate positive and negative charges,
respectively.
I.10.2
We have (repeated indices summed)
Raa′Rbb′iDa′b′(x) =

DϕRaa′ϕa′(x)Rbb′ϕb′(0)eiS
But we can change the integration variable from ϕ to Rϕ. Since the action S and the measure Dϕ are
both invariant under SO(N) rotations, this is equal to

Dϕϕa(x)ϕb(0)eiS = iDab(x). Thus, we obtain
Dab = Raa′Rbb′Da′b′. The properties of the rotation group are such that the only solution of this equation
is Dab proportional to δab.

548 | Solutions to Selected Exercises
I.10.3
The field ϕ transforms as a symmetric traceless tensor (see appendix B) under SO(3), that is, with all
indices displayed, ϕab →Raa′Rbb′ϕa′b′ = Raa′ϕa′b′RT
b′b = (RϕRT )ab. As suggested in the hint, writing ϕ
as a 3 by 3 symmetric traceless matrix we have ϕ →RϕRT and thus the invariants are (up to quartic
order in ϕ) tr(∂μϕ)2, tr ϕ2, tr ϕ4, and (tr ϕ2)2. Remarkably, you can prove that tr ϕ4 and (tr ϕ2)2 actually
amount to only one invariant by diagonalizing
ϕ =
⎛
⎜⎜⎝
α
0
0
0
β
0
0
0
−(α + β)
⎞
⎟⎟⎠
You can see by computation tr ϕ4 and (tr ϕ2)2 are both proportional to [α2 + β2 + (α + β)2]2. Thus, if
we restrict ourselves to quartic terms the Lagrangian L = 1
2 tr(∂μϕ)2 −1
2m2 tr ϕ2 −λ(tr ϕ2)2 actually has
an SO(5) symmetry (since ϕ has 5 components.) This is an example of what is known as “accidental
symmetry.” Convince yourself that this holds only to quartic order in ϕ.
I.11.2
Varying gμρgρλ = δμ
λ we have (δgμρ)gρλ = −gμρ(δgρλ), which upon multiplication by gλν becomes
δgμν = −gμρ(δgρλ)gλν. You may recognize this as just the statement δM−1 = −M−1(δM)M−1 for a
matrix M. To evaluate δg we use the important identity det M = eTr log M, which you can prove easily
by diagonalizing M with a similarity transformation. The left hand side is equal to the product of the
eigenvalues of M, while the right hand side is equal to the exponential of the sum of logarithms of the
eigenvalues. {You can define the logarithm of a matrix by expanding log[I + (M −I)] in a power series
in (M −I).}
Thus, δ det M = (det M) tr M−1δM and so δg = ggνμδgμν. We are now ready to vary
S =

d4x√−g 1
2(gμν∂μϕ∂νϕ −m2ϕ2) ≡

d4x√−gL
Plugging in, we have
δS =

d4x√−g[ 1
2gνμδgμνL−gμρ(δgρλ)gλν 1
2∂μϕ∂νϕ]
Thus,
T μν = −
2
√−g
δS
δgμν
= gμρgνλ∂ρϕ∂λϕ −gμνL
In the flat spacetime limit
T 00 = (∂0ϕ)2 −L = 1
2((∂0ϕ)2 + ( ⃗∇ϕ)2 + m2ϕ2)
precisely the energy density as promised.
I.11.3
Using the expression for T μν from the preceding exercise, we have
P i =

d3xT 0i = −

d3x∂0ϕ∂iϕ
and
[P i, ϕ(x)] = −

d3y[∂0ϕ(y), ϕ(x)]∂iϕ(y) = i∂iϕ(x)
Thus, combined with the fact that P 0 = H , we have [P μ, ϕ(x)] = −i∂μϕ(x), which just reflects the fact
that P μ and xν are conjugate variables.
I.11.4
Evaluating Tμν = −FμλF λ
ν −ημνL, we have
Tij = −FiλF λ
j + 1
2δij( ⃗E2 −⃗B2) = −EiEj + FikFjk + 1
2δij( ⃗E2 −⃗B2)

Solutions to Selected Exercises | 549
Since FikFjk = εikmεjknBmBn = δij ⃗B2 −BiBj , we obtain the announced result. Note that δijTij = 1
2( ⃗E2 +
⃗B2) = T00 and hence T = 0.
Part II
II.1.1
Continuing the hint, we have
δ( ¯ψγ μγ 5ψ) = ¯ψ i
4ωλρ[σ λρ, γ μγ 5]ψ = ¯ψ i
4ωλρ[σ λρ, γ μ]γ 5ψ
since γ 5 anticommutes with gamma matrices and hence commutes with the product of two gamma
matrices. Inserting [σ λρ, γ μ] as given in the text we have δ( ¯ψγ μγ 5ψ) = ωμ
λ ¯ψγ λγ 5ψ, which is precisely
how a vector transforms. Under parity ¯ψγ μγ 5ψ →¯ψγ 0γ μγ 5γ 0ψ which equals ¯ψγ 5γ 0ψ = −¯ψγ 0γ 5ψ
for μ = 0, and ¯ψγ 0γ iγ 5γ 0ψ = ¯ψγ iγ 5ψ for μ = i. The time component flips sign while the spatial
components do not. Thus, the behavior under parity is opposite to that of a normal vector: ¯ψγ μγ 5ψ
is an axial vector. The other cases proceed similarly.
II.1.2
From ψL = 1
2(1 −γ 5)ψ and ψR = 1
2(1 + γ 5)ψ, we find ¯ψL = ψ†
Lγ 0 = ψ† 1
2(1 −γ 5)γ 0 = ¯ψ 1
2(1 + γ 5) and
¯ψR = ¯ψ 1
2(1−γ 5). We then just use the properties of PL and PR repeatedly. For example, ¯ψLψR = ¯ψ 1
2(1+
γ 5)ψ and ¯ψRψL = ¯ψ 1
2(1−γ 5)ψ, or equivalently, ¯ψψ = ¯ψLψR + ¯ψRψL and ¯ψγ 5ψ = ¯ψLψR −¯ψRψL. As
another example, ¯ψLγ μψL = ¯ψ 1
2(1 + γ 5)γ μ 1
2(1 −γ 5)ψ = ¯ψγ μ 1
2(1 −γ 5)ψ and ¯ψRγ μψR = ¯ψγ μ 1
2(1 +
γ 5)ψ. Note that various combinations vanish, for example, ¯ψLψL = 0, ¯ψLγ μψR = 0, and so on. Complete
the exercise.
II.1.3–4 In the appropriate basis the Dirac equation becomes

 E −m
pσ3
−pσ3
−E −m
 
 φ
χ

= 0
that is, (E −m)φ + pσ3χ = 0 and −pσ3φ −(E + m)χ = 0. The second equation informs us that χ =
−[p/(E + m)]σ3φ. For a slow electron χ ≃−(p/2m)σ3φ, so that χ is smaller than φ by the factor p/2m.
The first equation then reduces to (E −m −p2/2m)φ = 0, which just reminds us of the relation between
energy and momentum in the nonrelativistic limit.
II.1.5
In the Weyl basis the Dirac equation for a relativistic electron moving along the 3-axis E(γ 0 −γ 3)ψ = 0
becomes

0
I −σ 3
I + σ 3
0
 
 ψL
ψR

= 0
Since
σ 12 ≡i
2[γ 1, γ 2] = −i
2[σ 1, σ 2] ⊗I = σ 3 ⊗I =

 σ 3
0
0
σ 3

under a rotation around the 3-axis, ψL →e−(i/4)ωσ 3ψL = e+(i/4)ωψL while ψR →e−(i/4)ωσ 3ψR =
e−(i/4)ωψR. Indeed, the left and right handed fields rotate in opposite directions.
II.1.6
In the Weyl basis, the Dirac equation γ . pu = 0 becomes σ μpμη = 0, and ¯σ μpμχ = 0, with
u =

 χ
η

The solutions are
η =

 p1 −ip2
p0 −p3

and
η =

 p0 + p3
p1 + ip2


550 | Solutions to Selected Exercises
for the two possible helicities. The corresponding solutions for χ may be obtained by ⃗p ↔−⃗p. We have
¯uu = p . p = 0. For a particle moving in the +3 direction, η = 0 and
χ = 2E

 0
1

and
η = 2E

 1
0

and χ = 0. The Lorentz vector ¯uγ μu = (2E)2(1, 0, 0, 1). (What other direction could it point in?) For
a particle moving in the −3 direction, η and χ exchange roles. This exercise shows explicitly that for
massless particles we can use 2-component spinors. (What happens if parity is broken?)
II.1.8
In either the Dirac or the Weyl basis, (ψc)c = γ 2(γ 2ψ∗)∗= ψ.
II.1.9
It is easiest to work in either the Dirac or the Weyl basis. Let ψ be left handed, that is (1 + γ 5)ψ = 0.
Then (1 −γ 5)ψc = (1 −γ 5)γ 2ψ∗= γ 2(1 + γ 5)ψ∗= 0 since γ 5 is real.
II.1.10
ψCψ →ψe−i
4 ωλρ(σ λρ)T Ce−i
4 ωμνσ μνψ = ψCψ since (σ λρ)T C = −Cσ λρ.
II.1.12
Under parity or reflection in a mirror, x1 →x1 and x2 →−x2. Choose γ 0 = σ 3, γ 0γ 1 = σ 1, and γ 0γ 2 =
σ 2. Multiply the Dirac equation (iγ μ∂μ −m)ψ = 0 by γ 0 and write [i(∂0 + γ 0γ i∂i) −γ 0m]ψ = 0. Then
multiplying by σ 1 reverses the sign of the ∂2 term, but also the mass term. I leave it to you to discuss
time reversal.
II.2.1
Apply Noether for the transformation
ψ →eiθψ = (1 + iθ)ψ
Then
δL
δ(∂μψ)δψ +
δL
δ(∂μ ¯ψ)δ ¯ψ = ¯ψiγ μ(iθψ)
Note that formally L does not depend on ∂μ ¯ψ. Thus, up to overall factors we can choose J μ = ¯ψγ μψ
with the corresponding charge Q =

d3x ¯ψγ 0ψ into which we plug (II.2.10)
ψ(x) =

d3p
(2π)3/2(Ep/m)1/2

s
[b(p, s)u(p, s)e−ipx + d†(p, s)v(p, s)eipx]
At this point, the calculation pretty much parallels what you did in exercise I.8.4. The integration

d3x
over space produces a delta function that sets the momentum variables in ψ and in ¯ψ equal to one
another. The new feature here is that we encounter objects such as ¯uγ 0u. Invoking Lorentz invariance and
referring to the rest frame form of u and v we have ¯u(p, s)γ μu(p, s′) = δss′pμ/m, ¯u(p, s)γ μv(p, s′) = 0,
and so on. We obtain
Q =

d3p
(2π)3(Ep/m)

s
[b†(p, s)b(p, s) + d(p, s)d†(p, s)]
As in exercise I.8.4 we have to move the creation operator d† to the left of the annihilation operator d
and subtract off an infinite constant. Thus, finally
Q =

d3p
(2π)3(Ep/m)

s
[b†(p, s)b(p, s) −d†(p, s)d(p, s)]
showing clearly that b annihilates a negative charge and d a positive charge.

Solutions to Selected Exercises | 551
To calculate [Q, ψ(0)] =

d3x[ ¯ψ(x)γ 0ψ(x), ψ(0)] we use the identity [AB, C] = A{B, C} −{A, C}B
and the canonical anticommutation relation (II.2.4). We find [Q, ψ(0)] = −ψ(0), thus showing that b
and d† must carry the same charge.
II.3.4
The desired equations are γ μαμ = 0 (this takes out 4 components since α takes on 4 values) and
(̸p −m)β
αβμ = 0 (for each μ this takes out 2 components and so altogether 4 × 2 = 8 components.)
Thus, 16 −4 −8 = 4 components as desired. Another way of saying this is that γ μαμ is a Dirac spinor
and hence the spin 1
2 part of the vector-spinor αμ.
II.6.4
It is good practice to be as symmetrical as one can in calculations. So define p3 ≡−P1 and p4 ≡−P2 and
add the 6 (not 3) combinations appearing in the definitions of s, t, and u, thus obtaining
2(s + t + u) = (p1 + p2)2 + (p3 + p4)2 + (p3 + p1)2 + (p4 + p2)2 + (p4 + p1)2 + (p3 + p2)2
= 3
4

i=1
m2
i + 2(p1 . p2 + p3 . p4 + p1 . p3 + p2 . p4 + p1 . p4 + p2 . p3)
The second group of terms on the right-hand side collect into (4
i=1 pi)2 −4
i=1 m2
i . (Obviously, we
have for convenience changed notation slightly, setting m3 = M1 and m4 = M2.)
II.6.5
Referring to (C.11) we see that in dσ the factor
1
|⃗v1 −⃗v2|E(p1)E(p2)
1
(2π)3E(k1) . . .
1
(2π)3E(kn)(2π)4
reduces to 1
2(m/E)4[1/(2π)2]. Integrating the factor d3P1d3P2δ(4) (p1 + p2 −P1 −P2) over ⃗P2 we knock
off 3 of the delta functions, leaving us with d
dP1P 2
1 δ(2E −E1), and so the integral over P1gives d
 1
2E2.
Finally, the factor containing the “real physics” is 1
2

s

S
|M|2 = (e4/4m4)f (θ). Multiplying the three
factors together and dividing by d
, we obtain dσ/d
 = ( 1
2)5[e4/(2π)2](1/E2)f (θ), as given in the text.
Note that m cancels out as expected. We should be able to take the limit m →0 compared to the energies
without the cross section either blowing up or vanishing.
II.6.7
 = |M|2
2M

d3k
(2π)32ω
d3k′
(2π)32ω′ (2π)4δ4(k + k′ −q)
Knock off the ⃗k′ integral and do the angular part of the ⃗k integral to obtain
 = |M|2
8πM

dkk2
ωω′ δ(

k2 + m2 +

k′2 + m2 −M)
Using (I.2.12), we evaluate the integral as (k2/ωω′)(1/( k
ω + k
ω′ )) = k/M. Solving
√
k2 + m2+
√
k′2 + m2 =
M for k we obtain the stated result.
Part III
III.1.2
The amplitude should become nonanalytic when both denominators of the integrand
(k2 −m2 + iε)((K −k)2 −m2 + iε)
vanish, namely when k2 = m2 and (K −k)2 = m2. But we found the condition in exercise I.7.4, namely
that K2 ≥4m2. Referring to (III.1.14)
M = iλ2
32π2
 1
0
dα log

2
α(1 −α)K2 −m2 + iε

we see that the log has a cut starting at K2 = m2/α(1 −α). As α ranges from 0 to 1, the minimum value
of m2/α(1 −α) is attained at α = 1
2. So indeed, the cut starts at K2 = 4m2.

552 | Solutions to Selected Exercises
III.1.3
Under the indicated change, log  →log eε = log  + ε, and so δM = −iδλ + iCλ23(2ε) + O(λ3).
Thus, δM = 0 implies δλ = 6Cλ2ε + O(λ3) = 6Cλ2δ log  + O(λ3) giving the stated result for
(dλ/d).
III.2.1
For

ddx(∂ϕ)2 to be dimensionless, we need [ϕ] = (d −2)/2. Thus [ϕn] = n(d −2)/2 and so in order for

ddxλnϕn to be dimensionless, we must have [λn] = n(2 −d)/2 + d.
III.3.3
When we set m = 0, the integrand is manifestly a linear combination of γ matrices. The integral cannot
produce a term independent of the γ matrices, which is what B is. For electrodynamics, the integral is
changed to
(ie)2i2

d4k
(2π)4
1
k2[(1 −ξ)kμkν
k2
−gμν]γ μ
̸p + ̸k + m
(p + k)2 −m2γ ν
≡A(p2) ̸p + B(p2)
When m = 0, the integrand is a linear combination of the product of three γ matrices, which can only
reduce to one γ matrix, not to none. Incidentally, an alternative way of seeing the results stated here is
to recall from chapter II.1 that with m = 0 the Lagrangian is invariant under the chiral transformation
ψ →eiθγ 5ψ.
III.3.4
This essentially follows from D = 4 −BE −3
2FE for BE = 0 and FE = 2. Then D = 1 but the linear
divergence is reduced to logarithmic divergence by the symmetry argument given in the text.
III.5.2
Basically, you have already done this problem in exercises II.1.3 and II.1.4. You merely have to replace
E and ⃗p by ∂/∂t and ⃗∇(see also chapter III.6).
III.5.3
In nonrelativistic quantum mechanics, the scattering amplitude is given in the Born approximation by
i times the Fourier transform of the potential: i

d3xei⃗k.⃗xU(⃗x). The scattering amplitude owing to the
exchange of a scalar meson of mass m is just i/(k2 −m2) ≃−i/(⃗k2 + m2). Thus, we just repeat the
calculation in chapter I.4, obtaining
U(⃗x) = −

d3k
(2π)3
ei⃗k.⃗x
⃗k2 + m2 = −1
4πr e−mr
III.6.1
¯u(p′)(̸p′γ μ + γ μ ̸p)u(p) = 2m¯u(p′)γ μu(p) by the equation of motion, but using γ μγ ν = 1
2{γ μ, γ ν} +
1
2[γ μ, γ ν] = ημν −iσ μν we can also write (̸p′γ μ + γ μ ̸p) = (p′ + p)μ + iσ μν(p′ −p)ν. We thus obtain
the Gordon decomposition.
III.6.2
We compute
qμ ¯u(p′)[γ μF1(q2) + iσ μνqν
2m
F2(q2)]u(p) = ¯u(p′) ̸qu(p)F1(q2)
= ¯u(p′)(̸p′ −̸p)u(p)F1(q2)
= ¯u(p′)(m −m)u(p)F1(q2) = 0
where the first and third equality follows from the antisymmetry of σ and the equation of motion,
respectively.
III.7.1
Proceeding as in the text but living in d−dimensional spacetime, we obtain iμν(q) = −i

ddl
(2π)d
Nμν
D
where 1
D =
 1
0 dα 1
D with D = (l2 + α(1 −α)q2 −m2 + iε)2 as before but with Nμν now effectively equal
to −d((1 −2
d )gμνl2 + α(1 −α)(2qμqν −gμνq2) −m2gμν). Rotating to Euclidean space we see that we
have to do the integrals (with c2 ≡m2 −α(1 −α)q2)

dd
El
(2π)d
1
(l2+c2)2 and

dd
El
(2π)d
l2
(l2+c2)2 =

dd
El
(2π)d
1
(l2+c2) −
c2 
dd
El
(2π)d
1
(l2+c2)2 . I did the first of these integrals for you in appendix II in chapter III.1. Generalizing
slightly we have
 ∞
0
dlld−1
1
(l2+c2)a = 1
2cd−2a  1
0 dx(1 −x)
d
2 −1xa−1−d
2 . I will let you carry on from here.

Solutions to Selected Exercises | 553
Part IV
IV.1.1
Write ⃗ϕ = (ϕ1, ϕ2, . . . , v + ϕ′
N). We compute 1
2μ2 ⃗ϕ2 −(λ/4)(⃗ϕ2)2 up to O(ϕ3) and find (upon dropping
the ′)
1
2μ2(v2 + 2vϕN + ⃗ϕ2) −λ
4 (v4 + 4v2ϕ2
N + 4v3ϕN + 2v2⃗ϕ2)
The condition of no linear term in ϕN fixes v2 = μ2/λ and so the coefficient of ⃗ϕ2 is equal to 1
2μ2 −
λ/4(2v2) = 0. The (N −1) fields ϕ1, ϕ2, . . . , ϕN−1 are massless.
IV.3.1
We have
 ∞
0
dk log[(k2+a2)/k2] = πa and so Veff(ϕ) = V (ϕ) + ℏ√V ′′(ϕ)/2 + O(ℏ2). For L = 1
2(∂ϕ)2 −
1
2ω2ϕ2, the quantum oscillator with ϕ identified as position, we have Veff(0) = 1
2ℏω.
IV.3.3
We have
m(ϕ) = f ϕ in VF(ϕ) = 2i

d2p
(2π)2 log p2−m(ϕ)2
p2
which after Wick rotation becomes
−2

d2pE
(2π)2 log p2
E + m(ϕ)2
p2
E
= −1
2π
 ∞
0
dx log x + m(ϕ)2
x
After cutting off the integral at 2 and adding a counterterm Bϕ2 we obtain
VF = 1
2π (f ϕ)2 log ϕ2
M2
IV.3.4
Veff = i ∞
n=1

d4k/(2π)4(1/2n)[V ′′(ϕ)/k2]n. For V ′′(ϕ) = 1
2λϕ2 the corresponding Feynman diagrams
consist of a circle with n V ’s attached to the circumference, where the 2n is the infamous symmetry
factor that I tried to avoid talking about in chapter I.7.
IV.4.1
With H an arbitrary p-form,
ddH =
1
(p + 1)!
1
p!∂λ∂νHμ1μ2...μpdxλdxνdxμ1dxμ2 . . . dxμp
= 1
2
1
(p + 1)!
1
p![∂λ, ∂ν]Hμ1μ2...μpdxλdxνdxμ1dxμ2 . . . dxμp = 0
IV.5.1
If you have done all the exercises thus far (see exercise I.10.3), you have already made the acquaintance of
the I = 2 scalar field transforming as ϕab →RacRbdϕcd = Racϕcd(RT )db = (RϕRT )ab, which thus can
be written as a traceless 3 by 3 symmetric matrix ϕ →RϕRT . Now you merely have to write out the
covariant derivative Dμϕ (see IV.5.20) explicitly. [Hint: The action of the generators on ϕ is similar to
what is shown in (B.20).]
IV.5.2
dF = d(dA + A2) = dAA −AdA and [A, F] = AdA −dAA and so dF + [A, F] = 0. Explicitly with
indices, this reads εμνλσ(∂νFλσ + [Aν, Fλσ]) = 0. In the abelian case, we have, for μ = 0, εijk∂iFjk =
⃗∇. ⃗B = 0 (recall chapter IV.4!), and for μ = i, εijk(−∂0Fjk + ∂jF0k −∂jFk0) = −∂0Bi + ( ⃗∇× ⃗E)i = 0.
IV.5.4
From the general arguments mentioned in the problem we know that tr F 2 must be the “d of some-
thing.” Now d tr AdA = tr dAdA and d tr 2
3A3 = 2
3 tr(dAA2 −AdAA + A2dA) = 2 tr dAA2 but on the
other hand tr F 2 = tr(dA + A2)(dA + A2) = tr(dAdA + 2dAA2) since tr A4 = tr A3A = −tr AA3 =
−tr A4 = 0. In electromagnetism, tr A3 = 0, and d tr AdA when written out in elementary notation
is just ∂μ(εμνλσAν∂λAσ) = 1
4 εμνλσFμνFλσ.

554 | Solutions to Selected Exercises
IV.5.6
We simply plug in the general expression in the text and obtain
L = −1
4g2F a
μνF aμν + ¯q(iγ μDμ −m)q
with the covariant derivative Dμ = ∂μ −iAμ = ∂μ −iAa
μT a, where T a (a = 1, . . . , 8) are traceless her-
mitean 3 by 3 matrices. Explicitly, (Aμq)α = Aa
μ(T a)α
βqβ, with α, β = 1, 2, 3 (see chapter VII.3).
IV.6.3
Observe
Aa
μτ a =
	 A3
μ
A1−i2
μ
A1+i2
μ
−A3
μ

with the obvious notation A1±i2
μ
≡A1
μ ± iA2
μ. Let ⟨ϕ⟩=

0
v

so that
Dμϕ = ∂μϕ −i(gAa
μ
τa
2 + g′Bμ
1
2)ϕ →−i
2v
	
gA1−i2
μ
−gA3
μ + g′Bμ

Thus, |Dμϕ|2 contains v2[g2A1+i2
μ
A1−i2
μ
+ (−gA3
μ + g′Bμ)2]. The combinations A1+i2
μ
, A1−i2
μ
, and
(−gA3
μ + g′Bμ) acquire mass while (g′A3
μ + gBμ) remain massless.
IV.7.4
We have
μν(k1, k2) = i

d4p
(2π)4
Nμν
D
+ {μ, k1 ↔ν, k2}
where
Nμν ≡tr γ 5(̸p −̸q + M)γ ν(̸p −̸k1 + M)γ μ(̸p + M)
Only the term linear in M in Nμν does not vanish, giving Nμν = 4iMεμνστk1σk2τ . Since we are interested
only in terms of O(k1k2) we can set D →(p2 −M2)3 so that
μν(k1, k2) = −8Mεμνστk1σk2τ

d4p
(2π)4
1
(p2 −M2)3 =
i
4π2M εμνστk1σk2τ
with a dependence on M as stated in the problem. The effect of the regulator, like some unsavory
acquaintance, remains even after we have sent him to infinity.
IV.7.5
We will sketch the solution. The details may be found in the lectures given by S. Adler at the 1970
Brandeis Summer School. The point is to imagine a regularization scheme that preserves the various
relevant symmetries, namely Lorentz invariance, vector current conservation, and Bose statistics. As you
will see, we don’t actually have to specify the regularization. By Lorentz invariance, we have
λμν(k1, k2) = ελμνσk1σA1 + ελμνσk2σA2 + ελμστk1σk2τkν
1A3
+ ελμστk1σk2τkν
2A4 + ελνστk1σk2τkμ
1 A5
+ ελνστk1σk2τkμ
2 A6 + εμνστk1σk2τkλ
1A7
+ εμνστk1σk2τkλ
2A8
Since the Feynman integral representing λμν is superficially linearly divergent, we see that A3, . . . , A8
are all convergent since we have to pull out three powers of momentum to extract them. In contrast, A1
and A2 are logarithmically divergent. But we can relate them to A3, . . . , A8 by vector current conservation
since 0 = k1μλμν = ελνστk1σk2τ(−A2 + k2
1A5 + k1 . k2A6) and thus A2 = k2
1A5 + k1 . k2A6. Similarly for
A1. Rationalizing the Feynman integrand and evaluating the trace in the numerator, we can systematically
ignore terms that contribute only to A1 and A2. Furthermore, Bose statistics gives us relations such as
A3(k2
1, k2
2, q2) = −A6(k2
2, k2
1, q2).

Solutions to Selected Exercises | 555
Part V
V.1.1
We dropped the term h2∂0θ but kept the term 4g2 ¯ρh2. This requires ∂0θ ≪g2 ¯ρ, that is, ω ≪g2 ¯ρ, but
since in our solution ω ∼g√¯ρ/mk this requires k ≪g√m ¯ρ, which is consistent with what we assumed
about k. Looking at the terms −2√¯ρh∂0θ −4g2 ¯ρh2 in L we see that h ∼∂0θ/(g2√¯ρ) ≪√¯ρ, which is
also consistent.
V.5.1
With γ 5 = σ3, 1
2(I ± γ 5) clearly projects out the top and bottom component of ψ =

ψL
ψR

, respectively.
Everything is formally the same as in chapter II.1, but we can also work things out explicitly in the
specific representation given here. Thus, ¯ψψ = ψ†σ2ψ = i(ψ†
RψL −ψ†
LψR) and ¯ψγ 5ψ = ψ†σ2σ3ψ =
i(ψ†
RψL + ψ†
LψR). Under the transformation ψ →eiθγ 5ψ, ψL →eiθψL and ψR →e−iθψR, and the
massless Dirac Lagrangian
L = iψ†
R( ∂
∂t + vF
∂
∂x )ψR + iψ†
L( ∂
∂t −vF
∂
∂x )ψL
clearly does not change.
V.6.1
This of course just follows from Lorentz invariance. We have
∂tϕ( x −vt
√
1 −v2) =
−v
√
1 −v2ϕ′( x −vt
√
1 −v2)
and
∂xϕ( x −vt
√
1 −v2) =
1
√
1 −v2ϕ′( x −vt
√
1 −v2)
and thus the equation
(∂2
t −∂2
x)ϕ( x −vt
√
1 −v2) + V ′[ϕ( x −vt
√
1 −v2)] = 0
becomes
ϕ′′( x −vt
√
1 −v2) −V ′[ϕ( x −vt
√
1 −v2)] = 0
Note that this does not depend on the form of V . For any relativistic theory, the soliton moves like a
relativistic particle (obviously!).
V.6.2
The sine-Gordon theory has an infinite number of vacua occurring at ϕ = (2n + 1)π/β. Thus, there
exists a whole spectrum of solitons, such that ϕ(±∞) = (2n± + 1)π/β. The topological current is
J μ = (β/2π)εμν∂νϕ with the corresponding charge Q = (n+ −n−). The Q = 2 soliton decays into two
Q = 1 solitons.
V.7.4
(i/2π)

S1 gdg† = (i/2π)

S1 eiνθde−iνθ = (i/2π)

S1(−iνdθ) = (ν/2π)
 2π
0
dθ = ν, which indeed counts
the number of times eiνθ winds around the circle. What mathematicians call the winding number is
indeed just the magnetic flux of the physicist.
V.7.5
Within a region small enough so that we can treat ϕa = vδa3 as constant, using (Dμϕ)b = ∂μϕb +
eεbcdAc
μϕd we have (Dμϕ)1 = evA2
μ and (Dμϕ)2 = −evA1
μ and thus
Fμν ≡
F a
μνϕa
|ϕ|
−(1/e)εabcϕa(Dμϕ)b(Dνϕ)c
|ϕ|3
→F 3
μν + e(A2
μA1
ν −A2
νA1
μ) = ∂μA3
ν −∂νA3
μ
precisely the electromagnetic field strength since A3
μ is the massless component of the Yang-Mills field.
Let us compute Bk = εijkFij far from the magnetic monopole. To calculate the magnetic charge we are

556 | Solutions to Selected Exercises
interested only in the term of order 1/r2 in ⃗B. Since Dμϕ →O(1/r2) by construction we can drop the
second term in Fij. Thus, we merely have to compute F a
ij ≡∂iAa
j −∂jAa
i + eεabcAb
i Ac
j. Since F a
ij will
eventually be contracted with the unit vector ϕa/|ϕ| = xa/r, we can effectively drop some of the terms
in F a
ij, thus simplifying the computation. We have
∂iAa
j = ∂i(1
e εajl xl
r2)“ = "1
e εaji 1
r2
and
eεabcAb
i Ac
j = (1/e)εabcεbimεcjnxmxn
r4
= (1/e)(δciδam −δcmδai)εcjnxmxn
r4
=
1
er4 εijnxaxn
so that
F a
ijϕa
|ϕ|
=
F a
ijxa
r
= 1
er3(−2 + 1)εaijxa = −1
er3εaijxa
and hence Bk = −(1/er2)ˆxk. The magnetic charge g = −4π/e.
Our result appears to differ from Dirac’s quantization condition (IV.4.10) by a factor of 2. The
resolution of this apparent paradox is instructive. In fact, we can always introduce into this theory a
field  (which could be a Bose or a Fermi field) transforming in the I = 1
2 representation with the
corresponding covariant derivative Dμ = ∂μ −ie( 1
2τ a)Aa
μ. The field  carries electric charge 1
2e.
Thus, the fundamental unit of electric charge is actually 1
2e, not e, and our result g = −4π/e = −2π/(e/2)
is actually nothing but the Dirac quanization condition. (The sign is trivial: just a question of which one
we call the monopole and which the antimonopole.)
V.7.7
Plugging in the Ansatz ϕa = (H(r)/er)(xa/r) and Ab
i = [1−K(r)]εbij(xj/er2) [so that H(r) −→
r→∞evr and
K(r) −→
r→∞0 in accordance with the asymptotic behavior (V.7.5) and (V.7.6)] into M =

d3x{ 1
4 ( ⃗Fij)2 +
1
2(Di ⃗ϕ)2 + V (⃗ϕ)} we get M as a functional of H and K. Minimizing M gives (with H ′ = dH/dr etc) the
equations r2H ′′ = 2HK2 + (λ/e2)[H 3 −(ev)2r2H] and r2K′′ = K(K2 −1) + KH 2. For help, see M. K.
Prasad and C. M. Sommerfeld, Phys. Rev. Lett. 35: 760, 1975.
V.7.8
The BPS solution corresponds to setting λ = 0 in the two equations in exercise V.7.7, rendering the
equations soluble, with the solution H(r) = evr(coth evr) −1 and K(r) = evr/(sinh evr). Ask yourself
why H(r) and K(r) approach their asymptotic values exponentially. What determines the length scale?
V.7.9
For help, see B. Julia and A. Zee, Phys. Rev. D11: 2227, 1975.
V.7.11
We derived the lower bound for the mass of the magnetic monopole 4πv|g| ∼4π(ev)/e2 ∼MW/α.
V.7.12
Near the identity element g = ei ⃗θ.⃗σ ≃1 + i ⃗θ . ⃗σ and thus gdg† ≃−id ⃗θ . ⃗σ . In a small neighborhood of
the identity element the group manifold is locally Euclidean and so
tr(gdg†)3 = i tr(σ iσ jσ k)dθidθjdθk = −12dθ1dθ2dθ3
is manifestly proportional to the volume element on S3. For g = ei(θ1σ1+θ2σ2+mθ3σ3), tr(gdg†)3 =
−12mdθ1dθ2dθ3.
V.7.13

d4x(∂μJ μ
5 ) =

d3xJ 0
5 |t=+∞−

d3xJ 0
5 |t=−∞. Recalling that J 0
5 = ψ†
RψR −ψ†
LψL, we see that the two
spatial integrals just count the number of right moving fermion quanta minus the number of left moving
fermion quanta at t = ±∞respectively. So

d4x(∂μJ μ
5 ) is an integer. On the other hand, in the text we
proved that

tr F 2 is a topological invariant. In other words, with suitable normalization, evidently
1/(4π)2,the integral [1/(4π)2]

d4xεμνλσ tr FμνFλσ is an integer. Thus, the coefficient 1/(4π)2 cannot
be shifted even a little bit by quantum fluctuations.

Solutions to Selected Exercises | 557
Part VI
VI.4.2
The quartic interaction term (1/2f 2)(⃗π . ∂⃗π)2 in L gives the amplitude i(1/2f 2)i2δabδcd(k1k3 + k1k4 +
k2k3 + k2k4) + permutations = (i/2f 2)δabδcd (k1 + k2)2 + permutations for the 4-pion interaction vertex
(where for convenience we have labeled all the momenta as going outward so that k1 + k2 + k3 + k4 = 0).
VI.4.3
After writing σ = v + σ ′, we find, as in chapter IV.1, that L = −1
2(2μ2)σ ′2 −λvσ ′ ⃗π2 −1
4 λ(⃗π2)2 +
. . . , where we have displayed only terms relevant for our purposes. The diagrams contributing to
four-pion interaction are of two types, those involving the λ(⃗π2)2 term and those invoking σ ′ ex-
change. The former gives for the amplitude (−i
4 λ)2 . 2(δabδcd + δacδbd + δadδbc) while the latter gives
(−iλv)2{2i/[(k1 + k2)2 −m2
σ ′]}δabδcd. Thus, expanding to first order in momenta squared we find the
coefficient of δabδcd:
−iλ −2iλ2v2

−1
m2
σ ′

(1 + (k1 + k2)2
m2
σ ′
) = −iλ + 2iλ2v2
2μ2

1 + (k1 + k2)2
2μ2

= iλ
2μ2(k1 + k2)2
To compare with exercise VI.4.2 we remember that f 2 = v2 = μ2/λ so that the amplitude here is also
equal to (i/2f 2)δabδcd(k1 + k2)2 + permutations, as we had anticipated in the text.
VI.4.4
We will track down factors of 2 carefully but not factors of i and −1. Let us go back to the chiral
transformations ψ →[1 + i ⃗θ . (⃗τ/2)γ 5]ψ and ¯ψ →¯ψ[1 + i ⃗θ . (⃗τ/2)γ 5]. Thus, δ( ¯ψψ) = θa ¯ψiγ 5τ aψ and
δ( ¯ψiγ 5τ aψ) = −θa ¯ψψ. Hence, for L = ¯ψ{iγ ∂+ g(σ + i⃗τ . ⃗πγ5)}ψ + L(σ , ⃗π) to be invariant we must
have δσ = θaπa and δπa = −θaσ. Applying Noether’s theorem Jμ = (δL/δ∂μϕ)δϕ, we obtain the current
J a
μ5 = ¯ψiγμγ5(τ a/2)ψ + πa∂μσ −σ∂μπa written in the text. Comparing the term ¯piγμγ5n contained in
J 1+i2
μ5
≡J 1
μ5 + iJ 2
μ5 with the current J5μ defined in chapter IV.2, we see that J5μ = −iJ 1+i2
μ5
. The normal-
ized state |π−⟩= (1/
√
2)(|π1⟩−i |π2⟩) so that ⟨0|π1+i2 |π−⟩= 2/
√
2. The current J 1+i2
μ5
contains the
term −v∂μπ1+i2 and thus f =
√
2v. Next, we have to work out the pion-nucleon coupling gπNN as de-
fined in chapter IV.2. Here L contains g ¯ψi⃗τ . ⃗πγ5ψ, which contains
√
2g ¯piγ5nπ−since π1−i2 =
√
2π−.
Thus, gπNN =
√
2g. Putting it together, we see that M = gv translates to 2M = fgπNN in agreement
with chapter IV.2.
VI.6.1
See figure VI.6.1. From h = (d/cos θ) ≃d(1 + 1
2θ2) and (∂h/∂x) = tan θ ≃θ, we have (∂h/∂t) ∝θ2 ∝
(∂h/∂x)2, thus giving rise to the term (λ/2)( ⃗∇h)2. It all goes back to Mr. Pythagoras.
VI.6.2
We integrate the term 1
2

dD⃗x dt[((∂/∂t) −⃗∇2)h]2 in S(h) by parts to obtain −1
2

dD⃗x dt[h((∂/∂t) +
⃗∇2)((∂/∂t) −⃗∇2)h]. Thus, the propagator is the inverse of the operator (∂/∂t + ⃗∇2)(∂/∂t −⃗∇2) =
∂2/∂t2 −( ⃗∇2)2, the Fourier transform of which is −(ω2 + k4).
VI.8.3
With h′(⃗x, t) = h

⃗x + g⃗ut, t

+ ⃗u . ⃗x + g
2 u2t, we have ∂h′/∂t = ∂h/∂t + g⃗u . ⃗∇h + (g/2)u2 and ⃗∇h′ =
⃗∇h + ⃗u. Thus the combination (∂h/∂t) −g
2 ( ⃗∇h)2 is invariant, as is (obviously) ⃗∇2h. In other words,
˜S(h) must be constructed out of these two invariant combinations.
VI.8.5
Look at the action S(h) = 1
2

dD⃗x dt [(∂h/∂t) −∇2h −g(∇h)2/2]2. Comparing ∂h/∂t −∇2h we see that
time has the dimension of length squared: T ∼L2. From the term

dD⃗x dt (∂h/∂t)2 and the fact that
S is dimensionless, we have [h]2 ∼T 2/(LDT ) ∼1/LD−2 and so h has the dimension of (1/LD−2)
1
2 .
Comparing ⃗∇2h with g( ⃗∇h)2 we see that g has the dimension of 1/h, that is, L(D−2)/2.
VI.8.7
We are told that L(dg/dL) = (2 −D)g/2 + (2D −3)fDg3 + . . . . We are assuming that the terms
(. . .) can be neglected. Thus (in what follows a2 and b2 are two generic positive numbers) for D = 1,
L(dg/dL) = a2g −b2g3 and g flows toward the fixed point g∗= a/b. (Incidentally, the KPZ equation
is soluble for D = 1 by methods not explained in this text and both z and χ are known exactly.) For
D = 2, L(dg/dL) = b2g3 and g flows toward some unknown strong (presumably) coupling fixed point.
For D = 3, L(dg/dL) = −a2g + b2g3. The fixed point g∗= a/b is unstable. For g < g∗, g flows toward
the trivial (i.e., free, or Gaussian) fixed point. Since the theory at the fixed point is free we know the

558 | Solutions to Selected Exercises
critical exponents exactly: z = 2 and χ = (2 −D)/2. For g > g∗, g flows toward some unknown strong
(presumably) coupling fixed point.
Part VII
VII.1.1. Set nμA′
μ(x) = 0 with A′
μ = U†AμU + iU†∂μU, so that n . ∂U(x) = in . A(x)U(x). Define λ(x) =
r . x/(r . n) for any 4-vector r and write x = λ(x)n + x⊥, so that r . x⊥= 0. Then
U(x) = Pei  λ(x)
0
dσn.A(σn+x⊥)
(with a path ordering) solves the differential equation, since n . ∂λ = 1 by construction.
VII.1.2
Using the BHC formula given, we have (the V ’s are clearly irrelevant)
UijUjk = eiaAμeiaAν = eia(Aμ+Aν)−1
2 a2[Aμ,Aν]+a3C+a4D+O(a5)
Similarly,
UklUli = e−iaA′
μe−iaA′
ν = e−ia(A′
μ+A′
ν)−1
2 a2[Aμ,Aν]+a3E+a4F+O(a5) :
the prime reminding us that the Aμ and Aν in this expression is to be evaluated on the “north” and
“west” side of the plaquette in figure VII.1.2, respectively, in contrast to the Aμ and Aν in UijUjk which are
evaluated on the “south” and “east” side, respectively. Here C, D, E, and F denote various commutators,
which we drag along merely to show that they eventually drop out in what interests us. (Note how the
different terms are associated with different powers of a, as indicated. Note also that in some places we
have dropped the prime on A and absorbed the “error” in doing so into terms of higher order in a.) Thus,
UklUli = e−ia(Aμ+Aν)−ia2(∂νAμ−∂μAν−1
2 i[Aμ,Aν])+a3G+a4H+O(a5)
where G and H denote sums of commutators and terms such as ∂ν∂νAμ and ∂ν∂ν∂νAμ. Applying the
BHC formula again to the order indicated we have
UijUjkUklUli = eia2(∂μAν−∂νAμ)−a2[Aμ,Aν]+O(a4) = eia2Fμν+a3I+a4J+O(a5)
with Fμν = ∂μAν −∂νAμ + i[Aμ, Aν]. The same remarks on G and H apply to I and J. The Yang-Mills
field strength emerges naturally, as we would anticipate. Since the traces of commutators and of A vanish,
when we apply the trace all the junk drops out to O(a5) and we have
S(P ) = Re tr[1 −1
2a4FμνFμν + O(a5)]
By gauge invariance, the corrections must be of even order in a but for our purposes we don’t care about
them anyway. Evidently, f and g are related by some uninteresting factors of a.
Part VIII
VIII.1.7 R12 = dω12 = d(−cos θdϕ) = sin θdθdϕ = 2R12
θϕdθdϕ ⇒R12
θϕ = 1
2 sin θ. Since eθ
1 = 1, eϕ
2 = 1/ sin θ,
we obtain R ≡Rab
μνeμ
a eν
b = 2R12
θϕeθ
1eϕ
2 = 1, independent of θ and ϕ as expected.
Part N
N.1.1.
The effective action for an electrically neutral system is given in the point particle limit by S =

dτ(−m +
bEEμEμ + bBBμBμ + . . .), with Eμ and Bμ defined in the text. The interaction terms involve two powers
of derivatives, which translate into two powers of ω in the scattering amplitude and hence four powers
of ω in the scattering cross section. (Note that a possible term like

dτFμνF μν can be absorbed into the
two terms already displayed.)
N.3.2.
As in (III.3.7) we have 3V3 + 4V4 = 2I + n where I denotes the number of internal lines. The number
of loops (III.3.6) L = I −(V3 + V4 −1) is 0 in a tree diagram. Thus V3 = n −2 −2V4 ≤n −2.

Further Reading
Books on field theory
This is a list of field theory textbooks that I know about. I do not necessarily recommend them all.
In food as in books, each has his or her own taste.
T. Banks, Modern Quantum Field Theory, Cambridge University Press, New York, 2008.
J. D. Bjorken and S. D. Drell, Relativistic Quantum Mechanics, McGraw-Hill, New York, 1964.
———, Relativistic Quantum Fields, McGraw-Hill, New York, 1965.
L. S. Brown, Quantum Field Theory, Cambridge University Press, New York, 1992.
S. J. Chang, Introduction to Quantum Field Theory, World Scientific, Singapore, 1990.
T. P. Cheng and L. F. Li, Gauge Theory of Elementary Particle Physics, Clarendon Press, Oxford, 1984.
F. Dyson and D. Derbes, Advanced Quantum Mechanics, World Scientific, Singapore, 2007.
R. P. Feynman, Quantum Electrodynamics, W. A. Benjamin, New York, 1962.
K. Huang, Quantum Field Theory, John Wiley & Sons, New York, 1998.
C. Itzykson and J-B. Zuber, Quantum Field Theory, McGraw-Hill, New York,1980.
T. D. Lee, Particle Physics and Introduction to Field Theory, Taylor & Francis, New York, 1981.
V. P. Nair, Quantum Field Theory, Springer, New York, 2005.
M. E. Peskin and D. V. Schroeder, An Introduction to Quantum Field Theory, Perseus, Reading MA,
1995.
L. H. Ryder, Quantum Field Theory, 2nd Ed., Cambridge University Press, New York, 1996.
M. Stednicki, Quantum Field Theory, Cambridge University Press, New York, 2007.
G. Sterman, An Introduction to Quantum Field Theory, Cambridge University Press, New York, 1993.
S. Weinberg, Quantum Theory of Fields, Vols. 1 & 2, Cambridge University Press, New York, 1996.
X. G. Wen, Quantum Field Theory of Many-Body Systems, Oxford University Press, New York, 2007.
and finally, of course,
F. Mandl, Introduction to Quantum Field Theory, Interscience, New York, 1959.

560 | Further Reading
Books on various topics mentioned
A. A. Abrikosov, L. Gorkov, and A. Dzyaloshinski, Methods of Quantum Field Theory in Statistical
Physics, Prentice Hall, Englewood Cliffs, NJ, 1963.
S. L. Adler, “Perturbation Theory Anomalies,” in: Lectures on Elementary Particles and Quantum Field
Theory, 1970, Brandeis University Summer Institute in Theoretical Physics, S. Deser et al, ed.,
MIT Press, Cambridge, 1970.
P. Anderson, Basic Notions of Condensed Matter Physics, Benjamin-Cummings, Menlo Park, CA 1984.
D. Bailin and A. Love, Supersymmetric Gauge Field Theory and String Theory, IOP Publishing, Bristol
and Philadelphia, 1994.
R. Balian and J. Zinn-Justin, eds., Methods in Field Theory, North Holland Publishing, Amsterdam,
and World Scientific, Singapore, 1981.
A. L. Barabasi and H. E. Stanley, Fractal Concepts in Surface Growth, Cambridge University Press,
Cambridge, 1995.
D. Budker, S. J. Freedman, and P. H. Bucksbaum, eds., Art and Symmetry in Experimental Physics:
Festschrift for Eugene D. Commins, American Institute of Physics, New York, 2001.
J. Cardy, Scaling and Renormalization in Statistical Physics, Cambridge University Press, New York,
1996.
S. Coleman, Aspects of Symmetry, Cambridge University Press, Cambridge, 1985.
J. Collins, Renormalization, Cambridge University Press, Cambridge, 1985.
E. D. Commins, Weak Interactions, McGraw-Hill, New York, 1973.
E. D. Commins and P. H. Bucksbaum, Weak Interactions of Leptons and Quarks, Cambridge University
Press, Cambridge, 2000.
M. Creutz, Quarks, Gluons and Lattices, Cambridge University Press, Cambridge, 1983.
P. A. M. Dirac, The Principles of Quantum Mechanics, Oxford University Press, Oxford, 1935. (On
p. 253 he explained why he wanted the equation of motion for the electron to be first order in time
derivative.)
A. Dobado et al., Effective Lagrangians for the Standard Model, Springer-Verlag, Berlin, 1997.
O.J.P. ´Eboli et al., Particle Physics, World Scientific, Singapore 1992.
R. P. Feynman, Statistical Mechanics, Perseus Publishing, Reading, MA, 1998.
R. P. Feynman and A. R. Hibbs, Quantum Mechanics and Path Integrals, McGraw-Hill, New York,
1965.
J. M. Figueroa-O’ Farrill, Electromagnetic Duality for Children, on the World Wide Web 1998.
V. Fitch et al., eds., Critical Problems in Physics, Princeton University Press, Princeton, 1997.
M. Gell-Mann and Y. Ne’eman, The Eightfold Way, W. A. Benjamin, New York, 1964.
H. B. Geyer, ed., Field Theory, Topology and Condensed Matter Physics, Springer, 1995 (A. Zee,
“Quantum Hall Fluids.”)
M. L. Goldberger and K. M. Watson, Collision Theory, Dover, New York, 2004.
N. Goldenfeld, Lectures on Phase Transitions and the Renormalization Group, Addison-Wesley, Read-
ing, MA, 1992.
F. Guerra and N. Robotti, Ettore Majorana: Aspects of His Scientific and Academic Activity, Springer,
New York, 2008.
C. Itzykson and J-M. Drouffe, Statistical Field Theory, Cambridge University Press, Cambridge, 1989.
S. Iyanaga and Y. Kawada, eds., Encyclopedic Dictionary of Mathematics, MIT Press, Cambridge, 1980.
L. Kadanoff, Statistical Physics, World Scientific, Singapore, 2000.
G. Kane and M. Shifman, eds., The Supersymmetric World: The Beginning of the Theory, World
Scientific, Singapore, 2000.
J. I. Kapusta, Finite-Temperature Field Theory, Cambridge University Press, Cambridge, 1989.
L. D. Landau and E. M. Lifschitz, Statistical Physics, Addison-Wesley, Reading, MA, 1974.
S. K. Ma, Modern Theory of Critical Phenomena, Benjamin/Cummings, Reading, MA, 1976.

Further Reading | 561
H. J. W. M¨uller-Kirsten and A. Wiedemann, Supersymmetry, World Scientific, Singapore 1987.
T. Muta, Foundations of Quantum Chromodynamics, World Scientific, Singapore, 1998.
D. I. Olive and P. C. West, eds., Duality and Supersymmetric Theories, Cambridge University Press,
Cambridge, 1999.
J. Polchinski, String Theory, Cambridge University Press, Cambridge, 1998.
J. J. Sakurai, Invariance Principles and Elementary Particles, Princeton University Press, Princeton,
1964.
L. Schulman, Techniques and Applications of Path Integrals, John Wiley & Sons, New York, 1981.
R. F. Streater and A. S. Wightman, PCT, Spin Statistics, and All That, W. B. Benjamin, New York,
1968.
G. ’t Hooft, Under the Spell of the Gauge Principle, Word Scientific, Singapore, 1994.
G. ’t Hooft et al., eds. Recent Developments in Gauge Theories, Plenum, New York, 1980.
D. Voiculescu, ed., Free Probability Theory, American Mathematical Society, Providence, R.I., 1997.
S. Weinberg, Gravitation and Cosmology, John Wiley & Sons, New York, 1972.
C. N. Yang, Selected Papers 1945–1980 with Commentary, W. H. Freeman, San Francisco, 1983.
A. Zee, Unity of Forces in the Universe, World Scientific, Singapore, 1982.
J.-B. Zuber, ed., Mathematical Beauty of Physics, World Scientific, Singapore, 1997.
Some popular books and books on the history of quantum field theory
M. Bartusiak, Einstein’s Unfinished Symphony, Joseph Henry Press, Washington, D.C., 2000.
I. Duck and E. C. G. Sudarshan, Pauli and the Spin-Statistics Theorem, World Scientific, Singapore
1997.
R. P. Feynman, QED: The Strange Theory of Light and Matter, Princeton University Press, Princeton,
2006.
D. Kaiser, Drawing Theories Apart, University of Chicago Press, Chicago, 2005.
A. I. Miller, Early Quantum Electrodynamics, Cambridge University Press, Cambridge, 1994.
L. O’Raifeartaigh, The Dawning of Gauge Theory, Princeton University Press, Princeton, 1997.
S. S. Schweber, QED and the Men Who Made It: Dyson, Feynman, Schwinger, and Tomonaga, Princeton
University Press, Princeton, 1994.
A. Zee, Fearful Symmetry, Princeton University Press, Princeton, 1999.
———, Einstein’s Universe, Oxford University Press, New York, 2001.
———, Swallowing Clouds, University of Washington Press, Seattle, 2002.
Further Reading for Part N
In writing a textbook, the author has the luxury of not preparing a detailed scholarly bibliography
(unless he or she chooses to follow the example of S. Weinberg, who is, in my opinion, most
admirable in this regard). Even more extravagant is the freedom accorded to authors of popular
books who in most cases give their unsuspecting and gullible readers the impression that the physics
of an entire era was done by two or three greats, individuals worthy of their own personality cults.
Presenting recent developments still in flux, I am faced with the dilemma of whether to give proper
credit. In scholarly publications, conscientious referencing is of course ethically mandated, but this
is a textbook. Fortunately, in this age of omniscient search engines, the reader could easily compile
a bibliography more exhaustive than even a myopic humanist used to be able to muster in half a
lifetime. I could do the same, but it is of little help to you for me to merely list the names of those

562 | Further Reading
responsible for, say, the new way of computing amplitudes using the spinor helicity formalism.1
Instead, I can best serve the typical reader by listing a few papers and review articles starting from
which you can track down the literature to your scholarly heart’s desire. To those who feel that they
should be mentioned, I apologize and refer you to Glashow’s description of a tapestry in the preface.
W. Goldberger and I. Z. Rothstein, arXiv: hep-th/0409156v2.
Z. Bern, L. J. Dixon, D. C. Dunbar, D. A. Kosower, arXiv: hep-ph/9602280.
N. Arkani-Hamed and J. Kaplan, arXiv: hep-th/0801.2385.
E. Witten, arXiv: hep-th/0312171.
1 F. A. Berends, Z. Bern, L. Chang, P. De Causmaecker, L. J. Dixon, D. C. Dunbar, R. Gastmans, W. Giele,
J. F. Gunion, R. Kleiss, D. A. Kosower, Z. Kunszt, M. Mangano, A. G. Morgan, S. J. Parke, W. J. Stirling, T. R.
Taylor, W. Troost, T. T. Wu, Z. Xu, D. H. Zhang, and many many others. I know how to copy and paste also! Please
forgive me if I inadvertently left you off this list.

Index
Page numbers followed by letters f and n refer to figures and notes, respectively.
Abrahams, Elihu, 366
accelerators, 42, 483
Adler, Steve, 277
Aharonov-Bohm effect, 251–252, 261, 317, 320
amplitudes: as analytic functions, 208–209;
symmetry in, 78. See also meson-meson scattering
amplitude
“amputating the external legs,” 55
analyticity, in quantum field theory, 207–209, 211,
217, 219. See also nonanalyticity
Anderson, Phil: in “Gang of Four,” 366; Nobel Prize
for, 351
Anderson localization, 351, 354; in renormalization
group language, 366–367
Anderson mechanism, 264
angular momentum, addition of, 530
anharmonicity, in field theory, 43, 89
anomaly (axial anomaly/chiral anomaly), 270, 275;
alternative ways of deriving, 279; consequences of,
275–278; Feynman diagram calculation revealing,
270–274; grand unification and freedom from,
411–412, 429; higher-order quantum fluctuations
and, 310; in nonabelian gauge theory, 276;
nonrenormalization of, 277; and path integral
formalism, 278
anthropic selection, 451
anticommutation: spin-statistics connection and,
122, 123; wave function of electrons and, 107
antiferromagnet(s): effective low energy description
of, 344–345; magnetic moments in, 344; N´eel
state for, 346
antikink(s), 304, 305f
antimatter: discovery of, 101; requirement of, 157
antineutrino field, in SO (10) unification, 425–426
antiunitary operator, time reversal as, 103
anyon(s), 315; interchanging, 316; statistics between,
317
approximation, steepest-descent, 16
area law, 377, 387
asymptotically free theories, 360, 386, 390;
Gross-Neveu model as, 403
atom(s), interaction with radiation, 3
attraction: quantum field theory on, 35–36; spin 1
particle and, 36–37; spin 2 particle and, 36
auxiliary field, 192, 467–468
axial anomaly. See anomaly
axial current conservation, quantum fluctuations
destroying, 274–275
axial gauge, 378
background field method, 504–507
Bardeen, Bill, 277
bare perturbation theory, 175
baryon number conservation, law of, 413; grand
unification and violation of, 418
BCFW recursion, 500, 507, 514
Berends, F. A., 493
Bern, Zvi, 484, 484f, 516, 519

564 | Index
Bern transformation, 516
Berry’s phase, nonabelian, 261, 346
Berry’s phase term, in ferromagnets and
antiferromagnets, 345, 346
beta decay, 456
Bethe, Hans, 365
Bianchi identity, 247, 261
Bjorken, James, 356
black hole(s): gravitational waves in, 479–482;
Hawking radiation from, 290–291; Schwarzschild,
311
Bludman, Sid, Yang-Mills theory and, 379
blue sky, effective field theory of, 457–458
Bogoliubov, N. N., 192
Bogoliubov calculation, of gapless mode, 284
Bogomol’nyi inequality, 305; for mass of monopole,
309
Bogomol’nyi-Prasad-Sommerfeld (BPS) states, 309
Bohr, Niels, 252
Boltzmann, Ludwig, 150, 287; on entropy, 311
Bose-Einstein condensation, 295
Bose-Einstein statistics, 120
Bose field, mass correction to, divergence of, 180
boson(s): “bad” behavior of, 180; electron pairing
into, 295; and fermions, unification of, 461;
gapless mode in, 284; gauge (see gauge boson[s]);
intermediate vector, and Fermi theory of the
weak interaction, 171–172, 309; Lorentz invariant
scalar field theory on, 190; mass correction for,
divergence of, 180; massless, emergence of, 226–
227; Nambu-Goldstone (see Nambu-Goldstone
boson[s]); nonabelian gauge (Yang-Mills), 257,
386, 434; in nonrelativistic theory, 192–193;
repulsion of, 283, 337
BPS (Bogomol’nyi-Prasad-Sommerfeld) states, 309
brane world scenarios, 40–42, 450
Br´ezin, Edouard, 402
Brillouin zone, 298
Brink, Lars, 470
Britto, Ruth, 500
Burgoyne, N., 121
Cachazo, F. A., 500
canonical formalism, 61–69; and degrees of freedom,
67; and Feynman diagrams, 43; vs. path integral
formalism, 44, 61, 67; propagator in, 67–68; time
ordering in, 67–68
Carrasco, J. J., 519
Casimir force, between two plates, 70–75, 71f
Cauchy’s theorem, 209
central identity of quantum field theory, 182, 524
chain rule, 445
charge: in dual theory, vortices as, 332–334; as
generator, 80; of quasiparticles, 327. See also
electric charge; magnetic charge
charge conjugation, 101–102; in grand unification,
429
charge quantization, deducing, 121
Chern-Simons term, 317; gauge invariance of, 328;
for Hall fluid, 326; massive Dirac fermions and,
319–320; and Maxwell term, 320; in nonrelativistic
theory, 320
Chern-Simons theory, 318–319; effective theory of
Hall fluid as, 324
Chew, Geoff, 105
chiral anomaly. See anomaly
chiral superfield, 464, 466
chiral symmetry: condition for, 419; conserved
current associated with, 100; of strong interaction,
234, 387–388
classical limit, path integral formalism for taking, 19
classical physics, symmetry of, 270
Clifford algebra: and Dirac bilinears, 97; and Dirac
equation, 94–95
closed forms, 247
coherence length, 296
Coleman, Sidney, 252, 473
Coleman-Mermin-Wagner theorem, 230
Coleman-Weinberg effective potential, 240
color, quark, 385, 386
complex plane, 207, 208
Compton, Arthur, 154
Compton scattering, 152–157
condensation, and superconductivity, 295
condensed matter physics: critical dimension in,
364, 367; disordered systems studied by, 350, 354;
goal of, 328; Goldstone’s theorem in, 229–230;
impurities studied by, 354; length scales in, 169;
momentum density in, 191; number conjugate
to phase angle in, 192; particle physics and, 281,
452–453; quantum field theory and, 5, 190, 281;
quantum Hall effect and, 351–352; quasiparticles
in, 326; renormalization group in, 360–363;
spin-statistics rule and, 120
conductivity, vs. conductance, 366–367
connected graphs, vs. disconnected graphs, 29, 47
conserved current: charge associated with, 80; and
chiral symmetry, 100; and continuous symmetry,
78–79; momentum space version of, 133
continuous symmetry, 77–78, 226; conserved current
and, 78–79
continuous symmetry breaking, 226; Coleman-
Mermin-Wagner theorem on, 230; and massless
fields, 228–229
Cooper pairs of electrons, 295
coordinate transformations, 81–82

Index | 565
cosmic coincidence problem, 450
cosmological constant, 448–449; measured in units
of Gev4, 449–450; order of magnitude, 449
cosmological constant problem, 450; approach
to, 455; root of, 448; string theory’s inability to
resolve, 450; supersymmetry as solution to, 461
Coulomb potential, 133–134, 143; modification of,
205
Coulomb’s electric force: and Newton’s gravitational
force, comparison of, 29; quantum field theory on,
32–33
counterterms: cutoff dependence absorbed by,
241; in Feynman diagrams, 175–176, 176f;
nonrenormalizable theories and, 179, 241
coupling, electromagnetic, 358
coupling constant(s), 164, 173; dimensionless,
170; of electromagnetic interaction, 359; hadron
proliferation and, 231; as misnomer, 358–359;
pion-nucleon, 235; renormalized, 166; Yang-Mills,
258–259
coupling renormalization, 173–174
CPT theorem, 104
critical dimension, in condensed matter physics,
364, 367
critical phenomena, 292; complete theory of, 293;
Landau-Ginzburg theory of, 293–294
crossing, 156
cubic vertex, in spinor helicity formalism, 496
current conservation. See conserved current
curved spacetime: Dirac action in, 445; introduction
to, 84–86; quantum field theory in, 82, 290
Cutkosky cutting rule, 215–216, 217, 219, 493
cutoff dependence, 163; avoiding in physical
perturbation theory, 176; counterterms absorbing,
241; disappearance of, 166, 167; of meson-meson
scattering amplitude, 173
dark energy, 450
dark matter, 450
Dashen, Roger, 405
decay rate, 139–141, 212
Deser, Stanley, 470
differential forms, 246–247; use in nonabelian gauge
theory, 255, 256
differential operator, propagator as inverse of, 23
dilatation invariance, 84n
dimensional analysis, 169–170, 453; on meson-
meson scattering amplitude, 173
dimensional regularization, 167, 168, 204
Dirac, Paul, 105; on electric charge, quantizing of,
410; on magnetic monopole, 308; metaphorical
language of, 113; on path integral formalism,
10–13; on positron, 5; on quantum mechanics
and magnetic monopoles, 245; on spinor
representation, 117; teaching style of, 454
Dirac basis vs. Weyl basis, 98–99
Dirac bilinears, 97
Dirac equation, 93–105; Clifford algebra and, 94–
95; in curved spacetime, 444; and degrees of
freedom, reduction in, 95; derivation of, 118;
electromagnetic field and, 101; handedness and,
100; Lorentz transformation and, 96–97; magnetic
moment of electron in, 194–195; origins of, 93–
94; parity and, 98; in solid state physics, 298, 299;
solving, 98; time reversal and, 104
Dirac field: interacting with scalar field, Feynman
rules for, 53–54, 534–535; interacting with vector
field, 100; interacting with vector field, Feynman
rules for, 129, 129f, 535–536; propagator for,
127; quantizing, 107–113, 122; quantizing by
Grassmann path integral, 127; vacuum energy of,
111–112, 125
Dirac operator, 113
Dirac spinor, 94, 96; components of, 117; and
supersymmetry, 114
disorder: Anderson localization of, 351, 354;
condensed matter physics and study of, 350, 354;
Grassmannian approach to, 354
dispersion relations, 208–210, 217–218, 235
Di Vecchia, Paolo, 470
divergence(s): degree of, 176–178; dependence on
dimension of spacetime, 179; with fermions, 178–
179; logarithmic, 175, 176–177; in quantum field
theory, 57–58, 161–162; superficial degree of,
176, 179; total, supersymmetric transformation,
465–466
dotted and undotted notation, 116–117, 541–544;
replacing, 475
double-line formalism, 395, 396
double-slit experiment, 7, 8f; expansion of, 7–9, 8f, 9f
double-well potential, 224, 224f
Drell, Sid, 356
duality: in (2 + 1)-dimensional spacetime, 335;
concept of, 331, 332; electromagnetic, 249; and
linking of perturbative weak coupling to strong
coupling, 473; of monopoles, 334; nonrelativistic
treatment of, 336–337; relativistic treatment of,
335–336; of string theories, 334; vortex, 334
dual theory, vortices as charges in, 332–334
dynamical symmetry breaking, 230; example of, 388
dynamical variable, in quantum field theory, 19
dyon, 309
Dyson, Freeman, 60
Dyson gas approach, 400–402
effective field theory: of blue sky, 457–458;

566 | Index
effective field theory (continued)
development of, 452; Fermi theory of the weak
interaction as, 456; gravitational waves and, 479–
482; of Hall fluid, 324–325, 452–453; of neutrino
masses, 456; predictive power of, 456–459; of
proton decay, 455–457; recent developments in,
479–482; and renormalization group flow, 453;
reshuffling terms in, 458–459
effective potential, 238–239; Coleman-Weinberg,
240; generated by quantum fluctuations, 243
Ehrenfest, P., 441
Einstein, Albert: and cosmological constant, 449; and
repeated indices summation convention, 475n
Einstein-Hilbert action for gravity, 433–434;
Newtonian gravity derived from, 438; Yang-Mills
action compared with, 434–435
Einstein Lagrangian, linearized, 34
Einstein’s theory of gravity, 81, 83; and deflection of
light, 439–440; gravitational waves in, 479–481;
nonrenormalizability of, 172; Yang-Mills theory
compared with, 444–445, 513–520
electric charge: quantized, grand unification on,
410; quantum fluctuations and, 204, 205;
renormalization of, 205
electric force: and gravitational force, comparison of,
29; quantum field theory on, 32–33
electromagnetic coupling, flow of, 358
electromagnetic duality, 249
electromagnetic field: Dirac equation in presence of,
101; as quantum field, 3–4; stress-energy tensor
of, 83–84
electromagnetic force: between like charges, 33;
knowledge of, 448
electromagnetic wave, degrees of freedom of, 38
electromagnetism: Faddeev-Popov method applied to,
185–186; and gravity, unification of, 442; Maxwell
on (see Maxwell theory of electromagnetism);
weakness of, 414–415
electron(s): absolute identity of, 120–121, 134; binary
strings in, 428; Bose-Einstein statistics for, 120;
in condensed matter system, 281; Cooper pairs
of, 295; degrees of freedom of, 95, 99; effect
of magnetic field on, 251–252; energy levels
available to, 5; Fermi-Dirac statistics for, 120;
as fermions, 322; fractional Hall state of, 324;
magnetic moment of (see magnetic moment
of electron); mass of, in classical physics, 180;
noninteractive hopping, 298–299, 298f, 299f;
pairing into bosons, 295; photon fluctuation into,
200–202, 201f; photon scattering on, 152–157,
153f, 157f; requirements of antisymmetric wave
function, 107; stability of, 413
electron-positron annihilation, 155–156, 389–391
electron scattering, 132–143; cross sections for, 137–
143; off electrons, 134–138, 135f; off nucleons,
deep inelastic, 386; off protons, 132–134, 133f,
199; off protons, deep inelastic, 359; off protons,
Schr¨odinger equation for, 3; to order e4, 145–149,
145–147f, 148f; potential, 133–134, 134f
electroweak theory, 170–171, 379; construction of,
379–383; renormalizability of, 384
energy: dark, 450; fundamental definition of, 83;
of mass, 35; quantum mechanics and special
relativity on, 3; of vacuum (see vacuum energy)
energy density, 35
energy-momentum tensor, 319
energy scales: in particle physics, 169;
renormalization group and, 361
entropy, Boltzmann on, 311
Euclidean path integral, 12
Euclidean quantum field theory, 287–288; and high-
temperature quantum statistical mechanics, 289;
and quantum statistical mechanics, 289
Euler, Leonhard, 460
Euler-Lagrange equation, 12, 80, 438, 448
exact forms, 247
Fadeev-Popov method, 183–185, 267, 371; applying
to electromagnetism, 185–186; and derivation of
graviton propagator, 437
Feng, Bo, 500
Fermi, Enrico, 105, 137
Fermi coupling, 170
Fermi-Dirac statistics, 120
Fermi field, mass correction to, divergence of, 180
Fermi liquid, gapless modes in, 285
fermion(s): and bosons, unification of, 461; degree
of divergence with, 178–179; electrons as, 322;
Feynman rules for, 128–131, 128f; in lattice gauge
theory, 376; mass correction for, divergence of,
180; massive Dirac, and Chern-Simons term,
319–320
fermion-fermion scattering, Feynman diagram for,
172, 172f
fermion masses: in grand unification, 417–418;
naturally small, 419
fermion normalization factors, 134
fermion propagator, 112
Fermi theory of the weak interaction, 232; as effective
field theory, 456; intermediate vector boson and,
171–172; nonrenormalizability of, 170, 179, 384;
predictive power of, 453; within electroweak
theory, 171
ferromagnet(s), 229; effective low energy description
of, 344–345; low energy modes in, 345–346;
magnetic moments in, 344; order in, 328
ferromagnetic transition, 295
Feynman, Richard: contribution of, 43; on difficulty

Index | 567
of quantum electrodynamics, 61; on Dirac, 105;
metaphorical language of, 113; on path integral
formalism, 7–10; study of calculus by, 522; on
trace products of gamma matrices, 137; Yang-Mills
theory and, 371
Feynman diagrams: beginning of, 29, 30f; breaking
shackles of, 311; canonical formalism and, 43;
childish game generating, 53, 53f; connected
vs. disconnected, 29, 47; counterterms in, 175–
176, 176f; Cutkosky cutting rule for, 215–216,
217, 219; discovering, 43–51, 45f, 46f; dominance
of, 302; for electron scattering, 132–134, 133f,
134f, 135f; evaluating, 538–539; for fermion-
fermion scattering, 172, 172f; finite temperature,
289; function of, 50; imaginary part of, 207–219,
208f, 213f; limitations of, 67; loop, 45, 57–58,
57f, 58f, 181, 494; in momentum space, 54; new
approaches to, 483–486; orientation of, 54; path
integral formalism and, 44; in perturbation theory,
55, 56f; for photon scattering, 152, 153f, 155, 155f;
regularization of, alternative ways of, 166; relating
infinite sets of, 234–235; in spacetime, 54, 58, 213
Feynman gauge, 149
Feynman rules, 534–537; colored, 485, 491, 495;
discovery of, 60; for fermions, 128–131, 128f; in
nonabelian gauge theory, 536–537; in physical
perturbation theory, 175–176, 176f; for quantum
electrodynamics, derivation of, 144–150; in
random matrix theory, 397, 398f; for scalar field,
54–55, 534–535; in spontaneously broken gauge
theories, 266–267; for vector field, 129, 130f,
535–536; in Yang-Mills theory, 257, 257f, 494–495
field redefinition, 68–69, 218, 342
field renormalization, 175
field strength, construction of, 255–257
Fierz, M., 121
Fierz identities, 459
Fisher, Matthew P. A., 336n
Fisher, Michael, 293; and renormalization groups,
361
fixed point(s), strong coupling, 359
flux: fundamental unit of, 324; gauge potential and,
334
force: origin of, 29; particle and, 27–29. See also
specific force
forms: closed vs. exact, 247–248; geometric character
of, 250–251, 250f
fractional Hall effect, 323–324
fractional (anyon) statistics, 315; coupling to
gauge potential, 316–317; gauge boson and, 320;
misleading nature of term, 317; and quasiparticles,
327
freedom, degrees of, 37–38; canonical formalism
and, 67; Dirac equation and reduction in, 95; of
electron, 95, 99; gauge invariance as redundancy
in, 268; longitudinal, in massive gauge field, 264;
of photon, 186–187
free field theory (Gaussian theory), 21–23, 43; in
terms of Fourier transform, 26
Fujikawa, Kazuo, 278
gamma matrices, 94, 117, 538; products of, 95–
96; trace products of, evaluating, 136–137,
153–154
Gamow, George, 120n
“Gang of Four,” 366
gapless mode, 284; Bogoliubov calculation of, 284;
linearly dispersing, 284–285
gauge boson(s): and fractional statistics, 320; and
intermediate vector boson, 309; mass spectrum
of, 266
gauge fixing, 183
gauge invariance, 83n, 144, 475; of Chern-Simons
term, 328; and Dirac quantization of magnetic
charge, 248; discovery of, 144n; in lattice
gauge theory, 376; in nonabelian gauge theory,
preserving, 204; origin of, 183; proof of, 145–150,
203–204; as redundancy in degrees of freedom,
268; regularization respecting, 202–204; and
renormalizability, 411
gauge potential, 251; flux associated with, 334;
fractional statistics and, 316–317; in Hall fluid,
325–326, 329; nonabelian, 254, 255
gauge theory(ies): Faddeev-Popov quantization of,
183–185, 267; and fiber bundles, correspondence
between, 256; gravity, as, 436; lattice, 374–376;
recent developments in, 497–512; redundancy
in, 183–185, 189; S-matrix theory and, 498–
501; spontaneously broken, Feynman rules
for, 266–267; spontaneously broken, magnetic
monopoles in, 309; and superconductivity
theory, 296; symmetry breaking in, 263–265,
268, 296; unsatisfactory formulation of, 474,
497; vortex in, 307. See also nonabelian gauge
theory(ies)
gauge transformation (local transformation), 187,
254; and general coordinate transformation,
443
Gauss-Bonnet theorem, 457, 459
Gaussian integration, 14, 523
Gaussian theory (free field theory), 21–23, 43; in
terms of Fourier transform, 26
Gell-Mann, Murray: and effective field theory, 460;
on quark color, 385; and seesaw mechanism, 426;
σ model of, 340–341; SU (3) of, 531; Yang-Mills
theory and, 371
Gell-Mann matrices, 265
general coordinate invariance, 36

568 | Index
general coordinate transformation, and gauge
transformation, connection between, 443
general covariance, principle of, 81
general relativity: finite size objects in, 480–482; and
quantum mechanics marriage of, 6; review of,
84–86
generator, charge as, 80
Georgi, Howard, 421n; grand unification theory of,
407–409
ghost fields, 372–374
Giele, W., 493
Ginzburg, V., 264; on London penetration length,
296; on second-order transitions, 292; on
superconductivity, 295
Girvin, Steve, 328
Glashow, Sheldon, 171; electroweak theory of, 383;
grand unification theory of, 407–409; and seesaw
mechanism, 426; Yang-Mills theory and, 379
gluon(s), 386; origins of concept, 235
gluon scattering, 483–496; approaches to calculation
of, 483–493, 484f, 491f; spinor helicity formalism
and, 486–491, 496
Goldberger, Murph L., 105, 137, 460
Goldberger-Treiman relation, 235, 342
Goldstone’s theorem, 228–229; in condensed matter
physics, 229
Golfand, Yu. A., 461
Gordon decomposition, 195
Goto, T., 469
grand unification, 452; binary code in, 426–
428; charge conjugation in, 429; and deeper
understanding of physics, 410–411; fermion
masses in, 417–418; and freedom from anomaly,
411–412, 429; and hierarchy problem, 419;
need for, 407; and origin of matter, explanation
for, 418; and proton decay, 413–414, 415,
456; SO (10): antineutrino field in, 425–426;
SO (18), 428; spinor representation of, 421–
423, 424, 426; SU (5), 531; SU (5), Georgi
and Glashow theory of, 407–409; triumph of,
415–416
Grant, A. K., 516
Grassmannian symmetry, 355
Grassmann integration, 126–127
Grassmann number(s), 123, 126; in path integral for
spinor field, 124
Grassmann variables, 246
gravitational force. See gravity
gravitational interaction, 36
gravitational waves, and effective field theory,
479–482
gravition propagator, 437–438
graviton: coupling to matter, 435; definition of, 83;
deformed polarizations of, 514–515; as elementary
particle, 434, 448; force associated with, 29; in
(n + 3 + 1)-dimensional universe, 41–42; recent
developments on, 513–520; self-interaction of,
434; in spacetime, 515–517; spin of, 35, 39; in
string theory, 513–514, 516
gravity: Einstein-Hilbert action for, 433–434;
Einstein on (see Einstein’s theory of gravity);
and electromagnetism, unification of, 442;
as field theory, 434–436; as gauge theory,
436; helicity structure of, 446; of light, 441;
Newton on (see Newton’s gravitational force);
nonrenormalizability of, 434; weak field action
for, 436–437
Green’s function(s), 47, 55, 352; generating, 50;
propagator related to, 23
Gross, David, 386
Gross-Neveu model, 402–404
ground state, in quantum field theory, 37, 225
ground state degeneracy, 319
group theory, review of, 525–533. See also special
orthogonal group SO (N); special unitary group
SU (N)
hadron(s): electron-positron annihilation into, 389–
391; in electroweak unification, 383; experimental
observation of, 231; quarks as components of, 385
Hall effect, 351–352; fractional, 323–324; integer, 323
Hall fluid(s), 322–330; Chern-Simons term for,
326; effective field theory of, 324–325, 452–
453; electron tunneling in, 329; five general
statements/principles of, 325, 329; gauge potential
in, 325–326, 329; incompressibility of, 323, 328;
Laughlin odd-denominator, 327; order in, 328
handedness, field, 100; charge conjugation and, 101
Hansson, T., 324
harmonic paradigm, 5
Hasslacher, Brosl, 405
Hawking radiation, 290–291
Heaviside, O., 24, 245
hedgehog, 308
Heisenberg, Werner: approach to quantum
mechanics, 61–62; and effective field theory, 460;
isospin SU (2) of, 531; isospin symmetry of, 387,
388; on neutron and proton, symmetry of, 77
helicity, topological quantization of, 532–533
helicity formalism, spinor, 486–491, 496, 501, 521
hierarchy problem, grand unification and, 419
Higgs field, covariant derivative of, 266
Higgs particle, mass of, 384
high energy physics: renormalization group in,
359–360
high frequency behavior, 208–210
Hofstadter, R., 199
homotopy groups, 307

Index | 569
Hopf term, 318; non-local, 329
Howe, P., 470
Hubbard-Stratonovich transformation, 192
identity, absolute, 120–121, 134
imaginary part, of Feynman diagrams, 207–219,
208f, 213f
impurities, 323; condensed matter physics and study
of, 354; and random potential, 350
infinities, in quantum field theory, 161–162
instanton(s), 309; discovery of, 473
integer Hall effect, 323
integration measure, in path integral formalism, 67
integration variables, shifting, 272
interchange symmetry, 77
internal symmetry, 77
inverse square law, 40
irrelevant operators, 363
Ising model, 361
isospin symmetry of Heisenberg, 387, 388
Itzykson, Claude, 402
Iwasaki, Y., 439
Johansson, H., 519
Jona-Lasinio, G., 237
Jordan, P., 107
Josephson junction, fundamental relation
underlying, 192
Kadanoff, Leo, 361; and renormalization groups,
361
Kaluza-Klein compactification, 442–443; derivation
of, 447
Kardar-Parisi-Zhang equation, 347
Kawai, H., 513
kinks. See solitons
Kivelson, Steve, 324
Klein-Gordon equation, 21, 93, 95, 190; Schr¨odinger
equation derived from, 190
Klein-Gordon operator, 113
Klein-Nishina formula, 155
Kockel, B., 460
Kosterlitz-Thouless transition, 310
Kramer’s degeneracy, 103
Lagrangian: Dirac (see Dirac equation); gauge
invariant, 253–254; Maxwell (see Maxwell
Lagrangian); Meissner, 332, 335; as mnemonic,
340, 342; for quantum electrodynamics, 101, 144;
symmetries of breaking, 223; weak interaction,
100; Yang-Mills, 257
Lamb shift in atomic spectroscopy, 205
Landau, L. D., 264; on complex momenta, 498; on
London penetration length, 296; on second-order
transitions, 292; on superconductivity, 295; on
superfluidity, 284
Landau gauge, 149
Landau-Ginzburg approach to quantum field theory,
18
Landau-Ginzburg theory (mean field theory),
292–294; order in, 328
Landau levels, 323
Laplace, P.-S., 290
Large Hadron Collider, 483
large N expansion, 394–396; Dyson gas approach to,
400–402; field theories in, 402–404
Larmor circle, 322, 323
lattice gauge theory, 374–376; Wilson loop in,
376–377, 457
Laughlin odd-denominator Hall fluids, 327
Lee, B., 173
Lee, D. H., 336n
Lee, Tsung-dao, 100
Legendre transform, 238–239
Leinaas, J., 315
length scales: in condensed matter physics, 169;
renormalization group and, 361–362
leptons: families of, 384; generations of, 428; and
quarks, neutral current interaction between, 383
L´evy, M., σ model of, 340–341
Lewellen, David C., 513
Licciardello, D., 366
light, gravity of, 441
light beam, stress-energy tensor of, 445
Likhtman, E. P., 461
linearly dispersing mode, 284; velocity of, 285
local field theory, 474, 521–522
localization: Anderson, 351, 354; Anderson, in
renormalization group language, 366–367; study
of, 355
local transformation (see gauge transformation)
logarithmic divergence, 175, 176–177
London penetration length, 296
loop diagrams, 45, 57–58, 57f, 58f, 181, 494
Lorentz algebra, 114–116
Lorentz boosts, 114–115
Lorentz group: defining representation of, 116;
generators of, algebra for, 115–116; spinor
representation of, 116–118
Lorentz invariance, 475; canonical formalism and,
63, 66–67; Euclidean equivalent of, 362; in
quantum field theory, 18, 24; recent developments
in, 507–510
Lorentz transformation: and Dirac equation, 96–97
Low, F., 460
L¨uders, G., 121
MacDonald, Alan, 328

570 | Index
magnetic charge (monopole), 249, 309; confinement
in superconductor, 386–387; Dirac quantization
of, 248–249, 252; duality of, 334; electrically
charged (dyon), 309; mass of, 309; and Maxwell’s
equations, 249; quantum mechanics and, 245; in
spontaneously broken gauge theory, 309
magnetic moment of electron: anomaly in, 196;
calculation of, 454; in Dirac equation, 194–195;
Schwinger on, 196–198, 454
magnetic moment of ferromagnet and
antiferromagnet, 344
magnetic moment of proton, anomaly in, 454–455
Majorana, Ettore, 102n, 543
Majorana equation, 102
Majorana mass, 102; for neutrino, 102
Majorana spinor, 102, 543
Mandelstam variables, 137–138, 498
marginal operators, 364
mass(es): attraction between, 35–36; of electron,
180; energy of, 35; of gauge boson, 266; of Higgs
particle, 384; of magnetic charge (monopole), 309;
Majorana, 102; of neutrino, 102; of nucleon, 341;
Planck, 41–42, 434; of soliton (kink), 305
massive gauge field, Nambu-Goldstone boson and,
264–265
massive spin 1 field, vs. massless spin 1 field, 183
massive spin 1 particle: degrees of freedom of, 38;
degrees of polarization of, 34; field theory of,
32–33; propagator for, 34; in Yang-Mills theory,
379
massive spin 2 particle: degrees of polarization of,
35; propagator for, 35, 439
mass renormalization, 174
matrix (matrices): gamma (see gamma matrices);
Gell-Mann, 265; Pauli, 265; without inverse,
182–183
matter: dark, 450; origin of, explanation for, 418;
states of, 328
mattress model of scalar field theory, 4–5, 4f;
disturbing, 21, 21f; path integral description of,
17–19
Maxwell, James Clerk, 521
Maxwell action, 182
Maxwell equations, magnetic charges and, 249
Maxwell Lagrangian, 32, 34, 84; bypassing, 33–34;
derivation of, 38
Maxwell term, 320, 329
Maxwell theory of electromagnetism: development
of, 474–476; Yang-Mills theory compared with,
257
mean field theory (Landau-Ginzburg theory),
293–294; order in, 328
Meissner effect, 296, 386
Meissner Lagrangian, 332, 335
meson(s): birth of, quantum field theory on, 55–56,
56f; π (see pion[s]); σ, 341, 342; soliton compared
with, 304; vector, field theory of, 32–33. See also
massive spin 1 particle
meson-meson scattering amplitude, 357; canonical
formalism and, 64–65; cutoff dependence of,
173; dimensional analysis on, 173; divergence
of, 161–162; path integral formulation of, 166;
regularization and, 163; renormalization and,
164–166
Michell, John, 290
Mills, Robert, and nonabelian gauge theory, 253,
255
Minkowski, Peter, and seesaw mechanism, 426
Minkowskian path integral, 287
Minkowskian spacetime, 36
momentum: complex, 498–501, 499f; fundamental
definition of, 83; orbital angular, Dirac equation
on, 194–195; spin angular, Dirac equation on, 195;
square root of, 486–489
momentum density, in nonrelativistic theory, 191
momentum space, 26; fermion propagator in, 113;
Feynman diagrams in, 54
monopole. See magnetic charge
Montonen, J., 334
muon, weak decay of, 380
Myrheim, J., 315
Nambu, Yoichiro, 297, 469; Nobel prize for, 228n
Nambu-Goldstone boson(s), 228–229; gapless mode
as, 284; in massive gauge field, 264–265; π
mesons (pions) as, 234, 387, 388; in relativistic vs.
nonrelativistic theories, 285
naturalness, notion of, 419
N´eel state, for antiferromagnet, 346
Ne’eman, Y., SU (3) of, 531
neutral current interaction, 383
neutrino(s): handedness of, 101; mass of, 102
neutrino masses, effective field theory of, 456
neutron(s): β decay of, 231–232; electric dipole
moment for, 259; and proton, internal symmetry
of, 77
Neveu, Andr´e, 402, 405
Newton’s gravitational force: and Coulomb’s electric
force, comparison of, 29; derived from Einstein-
Hilbert action, 438; quantum field theory on, 32,
33–36
Noether current, 191, 234
Noether’s theorem, 78–79, 100, 341; elaborate
formulation of, 80
nonabelian Berry’s phase, 261, 346
nonabelian gauge potential, 254, 255; coupling to a
fermion field, 260
nonabelian gauge theory(ies), 253–260; chiral

Index | 571
anomaly in, 276; differential forms in, 255,
256; Feynman rules in, 536–537; gauge
invariance in, preserving, 204; ghost action
in, 372; redundancy of, Faddeev-Popov
approach to, 183; renormalizability of, 173,
411; strong interaction described by, 259, 379;
’t Hooft double-line formalism and, 258–259;
unsatisfactory features of, 474. See also Yang-Mills
theory
nonanalyticity: emergence of, 292; symmetry
breaking and, 293
noncommutative field theory, 474
nonrenormalizable theory(ies), 169, 179, 453;
counterterms in, 179, 241; Einstein’s theory
of gravity as, 172; Fermi’s theory of the weak
interaction, 170, 179
nonrenormalization of the anomaly, 277
notation, dotted and undotted, 116–117, 541–544;
replacing, 475
nucleon(s): attraction between, 28; electron scattering
off of, deep inelastic, 386; mass of, 341; and pions,
interaction between, 340–341; wave function of
quarks in, 385
Olive, D. I., 334
optical theorem, 215–216, 219
orbital angular momentum, Dirac equation on,
194–195
order parameters, 295
orthogonal groups, embedding unitary groups into,
423–424
Parisi, Giorgio, 402
parity, 98; Dirac equation and, 98; and Dirac spinor,
117; weak interaction and, 100, 379–380
Parke, S. J., 493
particle(s): birth and death of, 4–5; birth of, quantum
field theory on, 55–56; field associated with, 26–
27; force associated with, 27–29; interchanging,
315–316, 316f; propagation of, describing, 48–
49, 50; scattering of (see scattering of particles);
sources and sinks for, 20. See also specific particles
particle physics: and condensed matter physics, 281,
452–453; energy scales in, 169; family problem in,
428; spontaneous symmetry breaking in, 292, 297,
449
partition function, in quantum statistical mechanics,
288–289
path integral formalism: vs. canonical formalism,
44, 61, 67; chiral anomaly and, 278; and classical
limit, 19; derivation of, 44; description of mattress
model, 17–19; Dirac on, 10–13; Feynman on, 7–
10; Grassmann math and, 127; history of, 60;
integration measure in, 67; replacing, 475; for
spinor field, 124; and vacuum energy, calculation
of, 123–125
Pauli, Wolfgang, on spin-statistics connection, 121
Pauli exclusion principle, 120, 323; history of, 120n
Pauli-Hopf identity, 345
Pauli matrices, 265
Pauli-Villars regularization, 75, 166–168
Peierls, Rudolf, 365
Peierls instability, 300
pentagon anomaly, 276, 277f
perturbation theory, 49–51; bare, 175; Feynman
diagrams in, 55, 56f; finite temperature, 289;
physical (renormalized/dressed), 175–176, 176f
perturbative quantum gravity, 441
ϕ4 theory, renormalizability of, 173, 175
phonon(s), 5, 284
photon(s): absence of rest frame for, 186–189; birth
and death of, 4; Bose-Einstein statistics for, 120;
degrees of freedom of, 186–187; electron-positron
annihilation into, 155; emission and absorption of,
150; fluctuation into electron and positron, 200–
202, 201f; force associated with, 29; longitudinal
mode of, 150; spin of, 36, 39
photon propagation: charge as measure of, 204;
quantum fluctuations and, 200–202, 201f
photon propagator, 149–150; Fourier transform of,
205; physical (renormalized), 201, 201f
photon scattering, 152–157; cross sections for,
152–155; on electrons, 152–157, 153f, 157f
physical perturbation theory, 175–176, 176f
pion(s) (π meson): massless, 235, 341; Nambu-
Goldstone boson, 388; as Nambu-Goldstone
boson, 234, 387; and nucleons, interaction
between, 340–341; prediction regarding, 29;
quarks as components of, 385; weak decay of,
231–233
pion-nucleon coupling constant, 235
Planck mass: modified, 434; for (n + 3 + 1)-
dimensional universe, 41–42
Planck’s constant, 181
Podolsky, B., 441
Poincar´e lemma, 247
point particle: action of, constructing, 84–86; stress
energy of, calculating, 86; world line traced out by,
length of, 84, 85f
Poisson equation, 438
polarization, degrees of, 34
Politzer, H. D., on Yang-Mills theory, 386
Polyakov, Alexander (Sasha), 498; on magnetic
monopoles, 309
Polyakov action, 470
Pontryagin index, 310
positron(s): Dirac’s conception of, 5; photon
fluctuation into, 200–202, 201f

572 | Index
potential energy, double-well, 224, 224f
power counting theorem, 176–178
preons, theories about, 278
product rule, 445
propagation of particles, describing, 48–49, 50
propagator, 23–25; in canonical formalism, 67–68;
for Dirac field, 127; fermion, 112; graviton, 437–
438; for massive spin 1 particle, 34; for massive
spin 2 particle, 35, 439; photon, 149–150
proton(s): charge of, grand unification on, 410;
electron scattering off of, 132–134, 133f, 199;
electron scattering off of, deep inelastic, 359;
electron scattering off of, Schr¨odinger equation
for, 3; magnetic moment of, anomaly in, 454–455;
and neutron, internal symmetry of, 77; quarks as
components of, 385; stability of, 413
proton decay: branching ratios for, 416–417; effective
theory of, 455–457; grand unification and,
413–414, 415, 456; slow rate of, 418
quantum chromodynamics (QCD), 360, 386; analytic
solution of, search for, 391; at high energies, 391;
large N expansion of, 394–396; renormalization
group flow of, 388–389
quantum electrodynamics (QED), 32; coupling
constant of, 164; coupling in, 358; electromagnetic
gauge transformation in, 189; Feynman on
difficulty of, 61; Feynman rules for, derivation
of, 144–150; intellectual incompleteness of, 121;
Lagrangian for, 101, 144; renormalizability of,
173
quantum field theory(ies): in (0 + 0)-dimensional
spacetime, 397; in 2-dimensional spacetime,
470; anharmonicity in, 43, 89; asymptotic
behavior of, study of, 359–360; central identity
of, 182, 523; and condensed matter physics,
5, 190, 281; crisis of, 231, 340, 452; in curved
spacetime, 82, 290; divergences in, 57–58, 161–
162; Euclidean, 287–288, 289, 290; at finite
density, 291; at finite temperature, 289–290;
gravity as, 434–436; ground state in, 37, 225;
harmonic paradigm and, 5; hidden structures
in, 476; history of, 60; infinities in, 161–162;
innovative applications of, 473–474, 476; integral
of, 88–89; low energy manifestation of, 162, 169,
452; mattress model and, 17–19; motivation
for constructing, 55; need for, 3–5, 6, 123;
nonrelativistic limit of, 190–191; relativistic
vs. nonrelativistic, 191–193; renormalizable
vs. nonrenormalizable, 169; on repulsion and
attraction, 32–36; restrictions within, 474; steps
toward, 235; strong and weak interactions
applied to, 231; of strong interaction, 340;
supersymmetric, 461, 467–468; surface growth
and, 347–349; symmetry breaking in, 225–226;
theories subsumed by, 473; threshold of ignorance
in, 162–163, 453; triumph of, 452, 473; vacuum
in, 20
quantum fluctuations: axial current conservation
destroyed by, 274–275; effective potential
generated by, 243; and electric charge, 204, 205;
first order in, 239–240; higher order, and chiral
anomaly, 310; and photon propagation, 200–202,
201f; and symmetry breaking, 229, 237, 242, 270
quantum Hall fluid. See Hall fluid(s)
quantum Hall system, 281
quantum mechanics: antimatter as requirement
in, 157; and general relativity, marriage of, 6;
harmonic oscillator in, solving, 43; Heisenberg’s
approach to, 61–62; and magnetic monopoles,
245; partition function in, 288–289; path integral
formalism of, 7–12; quantum field theory as
generalization of, 88–89, 473; and relativistic
physics, joining in spin-statistics connection,
122; and special relativity, marriage of, 3, 6,
121; symmetry breaking in, 225–226; symmetry
of, 270; time reversal in, 102–104; and vector
potential, need for, 245
quantum statistics, 120
quantum vacuum, 358
quark(s): color of, 385, 386; confinement of, 377,
386–387; in electroweak unification, 383; families
of, 384; flavors of, 385; generations of, 428; and
leptons, neutral current interaction between,
383; origins of concept, 235; strong interaction
between, weakening of, 360
quasiparticle(s), 326; charge of, 327; fractional
statistics and, 327; as vortex, 328
radiation: and atoms, interaction between, 3;
Hawking radiation, 290–291
Ramakrishnan, T. V., 366
Ramond, Pierre, and seesaw mechanism, 426
random dynamics, and quantum physics, 349
random matrix theory, 396–397; Feynman rules in,
397, 398f
random potential, impurities and, 350
Rarita-Schwinger equations, 119
Rayleigh, Lord, 458
recursion, 501–503, 507–512, 521; BCFW, 500, 507,
514
redundancy, Faddeev-Popov approach to, 183–185
reflection symmetry, 76, 226; breaking, 223, 224,
225
Regge, T., 498
regularization, 163; Casimir force and, 71–75;
dimensional, 167, 168, 204; gauge invariance
respected by, 202–204; Pauli-Villars, 75, 166–167
relativistic physics: equations of motion in, unified
view of, 95; language of, 26; and quantum physics,

Index | 573
joining in spin-statistics connection, 122. See also
general relativity; special relativity
relativistic quantum field theory: correctness of,
establishment of, 196; vs. nonrelativistic quantum
field theory, 191–193
relevant operators, 363
renormalizable conditions, imposing, 241–242
renormalizable theory(ies), 169, 173, 453; electroweak
theory as, 384; nonabelian gauge theory as, 173,
411; ϕ4 theory as, 173, 175, 178–179; Yukawa
theory as, 179
renormalization, 161, 164–166; coupling, 173–174;
of electric charge, 205; field, 175; mass, 174; wave
function, 175
renormalization group, 356, 358; and Anderson
localization, 366–367; in condensed matter
physics, 360–363; and effective description,
367; effective field theory philosophy and, 453;
in high energy physics, 359–360; in quantum
chromodynamics, 388–389
renormalization theory, application of, 240–241
renormalized coupling constant, 166
renormalized (dressed) perturbation theory, 175–176,
176f
reparametrization invariance, 84
replica method, 353–354
representations: conventions for naming, 526;
multiplying, 530–531
repulsion: of bosons, 192–193, 283, 337; quantum
field theory on, 32–33; spin 1 particle and, 36–37;
of vortices, 338
rest frames, for photons, absence of, 186–189
Ricci tensor, 433
Riemann-Christoffel symbol, 85, 445
Riemann curvature tensor, 433, 480–481, 515–516
Riemannian manifolds, differential geometry of,
443–444
Rosenbluth, Marshall, 105
rotation group, 114; and Lorentz group, symmetry
of, 118
Rξ gauge, 267, 268
Salam, Abdus, 171; electroweak theory of, 383;
superspace and superfield formalism of, 462, 463
scalar boson operator, 113
scalar field: complex, 65–66; Feynman rules for, 54–
55, 534–535; quantizing in curved spacetime, 82;
and vacuum energy, 66
scalar field theory: classical field equation in, 20;
Euclidean functional integral and, 287; Euclidean
version of, 293; massless version of, 284; simplicity
of, 519–520
scalar potentials, 245
scattering of particles: describing, 51–53, 51f, 52f;
fermion-fermion, Feynman diagram for, 172;
meson-meson (see meson-meson scattering
amplitude); reflection symmetry in, 76; and
vacuum fluctuations, 124. See also electron
scattering
Schouten identity, 492, 493
Schrieffer, Bob, 297
Schr¨odinger equation: electromagnetic gauge
transformation in, 189; Klein-Gordon equation
and, 21n, 190; limitations of, 3; Yang-Mills
structure in, 261
Schwarz, John, on string theory, 470n
Schwarzschild black hole, 311
Schwarzschild solution, for Hawking radiation, 290
Schwinger, Julian: on complex plane, 208;
and effective potential, 237; on Feynman’s
contribution, 43, 50, 56; on magnetic moment
of electron, 196–198, 454; on path integral
formalism, 60; at Pocono conference (1948), 105;
teaching style of, 454; Yang-Mills theory and,
379
second-order phase transitions, 292
seesaw mechanism, 37, 426
Seiberg, Nathan, 334
self-dual theory, 337
semions, 315
σ meson, 341, 342
σ model, 340–341; for ferromagnets and
antiferromagnets, 345, 346; nonlinear, 342, 346
sky color, effective field theory of, 457–458
Slansky, Dick, and seesaw mechanism, 426
S-matrix theory, 68, 235, 340, 498–501
solid state physics, Dirac equation in, 298, 299
solitons (kinks): discovery of, 302–304, 473;
dynamically generated, 400–405; mass of, 304;
topological stability of, 304; unifying language for
discussing, 307
SO (N). See special orthogonal group
sources and sinks, creating, 20, 51, 51f
spacetime: curved (see curved spacetime); dimension
of, and symmetry breaking, 229; discretizing, 22;
Feynman diagrams in, 54, 58, 213; gravitational
waves in, 479–482; graviton in, 515–517; symmetry
of, Lorentz invariance as, 76
special orthogonal group SO(N), 525–527; binary
code in, 427–428; review of, 531–532; SO(3), 526–
527; SO(10) grand unification, antineutrino field
in, 425–426; SO(18), 428; spinor representation
of, 421–423, 424, 426
special relativity: antimatter as requirement in, 157;
and quantum mechanics, marriage of, 3, 6, 121
special unitary group SU (N), 527–530; decomposing
representations of, 531; of Heisenberg, 531; SU
(2), 529–530; SU (3), 529, 530; SU (3), of Gell-
Mann and Ne’eman, 531; SU (5), 531; SU (5),
Georgi and Glashow theory of, 407–409

574 | Index
spin angular momentum, Dirac equation on, 195
spinor(s): Dirac, 94, 96, 114, 117; Majorana, 102;
representations of, 116–117; Weyl, 117, 462
spinor field: deriving, 125–127; path integral for, 123;
path integral for, Grassmann numbers in, 124;
vacuum energy of, 111–112, 125
spinor helicity formalism, 486–491, 496, 501, 521
spin-statistics rule, 120–121; and anticommutation
relations, 122, 123; price of violating, 121–122
spin wave, 229
spontaneous symmetry breaking, 224, 225, 227;
continuous: and massless fields, 228–229; in
gauge theories, 263–265; in particle physics,
292, 297, 449; quantum fluctuations and, 229;
of reflection symmetry, 225; in relativistic vs.
nonrelativistic theories, 285; second-order phase
transitions and, 292; and superfluidity, 283–284
square anomaly, 276, 277f
square root of momentum, 486–489
steepest-descent approximation, 16
Stokes’ theorem, 307
Stoner, E. C., 120n
Strathdee, J., superspace and superfield formalism
of, 462, 463
stress-energy tensor, 35; definition of, 83; of light
beam, 445; properties of, 84
string theory: 2-dimensional field theory, 469–
470; as candidate for unified theory, 433, 452;
and cosmological constant problem, inability
to resolve, 450; duality of, 334; future of, 513;
graviton in, 515–517; Kaluza-Klein idea and, 442;
origins of, 6, 387; p-forms in, 251; in quantum
field theory, 473; Schwarz on, 470n
strong coupling: fixed point in, 359; linking to
perturbative weak coupling, 473
strong interaction: chiral symmetry of, 234; currently
accepted theory of, 379; fundamental theory
of, 360; hadronic, 36; at low energies, 340–341;
nonabelian gauge theory on, 259, 379; quantum
field theory of, 235, 340; renormalization group
flow applied to, 368; symmetries of, 234, 387–388
SU (N). See special unitary group
supercharges, 464
superconductivity, 295–297; and Meissner effect, 296
superconductor(s): monopole confinement in,
386–387; type II, flux tube in, 307
superfield, 464–465; chiral, 464, 466; vector, 466–467
superfluidity, 192; gapless excitations and, 284–285;
Lagrangian summarizing, 284; linearly dispersing
mode of, 284; spontaneous symmetry breaking
and, 283–284
superspace and superfield formalism, 462–463
superstring theory, 470
supersymmetric action, 466
supersymmetric algebra, 462–463
supersymmetric field theories, 461, 467–468;
Yang-Mills, 392, 467–468
supersymmetric method, 355
supersymmetric transformation, total divergence
under, 465–466
supersymmetry, 112; Dirac spinor and, 114;
inventing, 462; motivations for, 461
surface growth, 347, 360; and quantum field theory,
348–349
Swieca, Jorge, 230n
symmetry, 76–80; in amplitudes, 78; breaking,
226; chiral, 234, 387, 388, 419; classical vs.
quantum, 270–271; conserved current and, 78–
79; continuous, 77–78, 226; in field theories,
475; Grassmannian, 355; Heisenberg isospin,
387, 388; interchange, 77; internal, 77; power
of, 18, 76, 118; reflection, 76, 226; replica, 353;
of spacetime, Lorentz invariance as, 76; strong
interaction, 234, 387–388; tensors and, 526, 528.
See also supersymmetry
symmetry breaking, 223–230; continuous symmetry
and, 226; dimension of spacetime and, 229;
dynamical, 230, 388; in gauge theories, 263–
265, 268, 296; and nonanalyticity, 293; quantum
fluctuations and, 229, 237, 242, 270; in quantum
mechanics vs. quantum field theory, 225–226;
reflection symmetry and, 223, 224, 225; and
superfluidity, 283–284; and vacuum energy, 449.
See also spontaneous symmetry breaking
Taylor, T. R., 493
Teller, Edward, 105
temperature: black hole, 290; and cyclic imaginary
time, 289; finite, quantum field theory at, 289–290
tensor(s): energy-momentum, 319; of light beam,
445; of orthogonal group, 525–526; Ricci, 433;
Riemann curvature, 433; stress-energy, 35, 83–
84; symmetry properties of, 526, 528; of unitary
group, 527–528; vacuum polarization, 200, 201f,
204, 208, 209f, 211, 216, 218
tensor field, 35, 83
θ term, 259
Thomas precession, 115
’t Hooft, Gerardus, 173; on electroweak theory,
384; on large N expansion, 394; on magnetic
monopoles, 309
’t Hooft double-line formalism, 258–259
3-brane, 40–42
time ordering in canonical formalism, 67–68
time reversal, 102–104; and Dirac equation, 104
Tolman, R., 441
Tolman-Ehrenfest-Podolsky effect, 441, 446
Tomonaga, Shin-Itiro, 60

Index | 575
topological current, 304
topological field theory, 318
topological objects, 306; discovery of, shock of, 311.
See also specific objects
topological order, 328
topological quantum fluids, 322. See also Hall fluid
total divergence, under supersymmetric
transformation, 465–466
trace, 526
tree diagrams, 45, 483–484, 491–494
Treiman, Sam, 236. See also Goldberger-Treiman
relation
triangle anomaly, 271f, 276
twistor space, 494–495
Tye, Henry, 513
ultraviolet catastrophe, 448
ultraviolet divergence, 162
uncertainty principle, 3, 290
unification. See grand unification
unitarity, 215–216, 500
unitary gauge, 267
unitary groups, embedding into orthogonal groups,
423–424
universe: 3-brane, 40–42; early, 290; formation of
structure in, 36
vacuum: disturbing of, 20, 21f, 70–73; quantum, 20,
358
vacuum energy: calculation of, using path integral
fomalism, 123–125; disturbance of vacuum and,
70–73; of free scalar field, 66; of free spinor field
(Dirac field), 111–112, 125; Grassmann path
integral for, 127; symmetry breaking and, 449
vacuum expectation value, 226
vacuum fluctuations, 59–60, 59f; Feynmann diagram
corresponding to, 129; scattering of particles and,
123
vacuum polarization tensor, 200, 201, 204, 208, 209f,
211, 216, 218
van Dam, H., 439
van der Waerden notation. See dotted and undotted
notation
vector field, interacting with Dirac field, 100;
Feynman rules for, 129, 129f, 535–536
vector meson (massive spin 1 meson): field theory
of, 32–33. See also massive spin 1 particle
vector potential, 245
vector superfield, 466–467
Veltman, Tini, 173, 439; on electroweak theory, 384
vielbeins, 443
visual perception, application of field theory to, 476
vortex (vortices), 306, 331–332; as charges in dual
theory, 332–334; density of, 333; duality of, 334;
as flux tube, 307; motion in fluid, 338–339, 338f;
paired with antivortex, 310–311, 339; quasiparticle
as, 328; repulsion of, 337
Ward-Takahashi identity, 149, 411
wave function(s), Anderson localization of, 351, 354
wave function renormalization, 175
wave packets, in mattress model, 4–5, 4f
weak interaction, 37; intermediate vector boson of,
171–172, 309; and parity, 100, 379–380; quantum
field theory applied to, 231. See also Fermi theory
of the weak interaction
weak interaction Lagrangian, 100
Weinberg, Steve, 171, 508; electroweak theory of, 383
Weisskopf phenomenon, 180–181; grand unification
and, 419
Wen, Xiao-gang, 324, 328; and topological order, 328
Wentzel, Gregory, 105
Wess-Zumino model, 462
Weyl basis, 98–99, 118
Weyl-Eddington terms, 457
Weyl spinors, 117; and supersymmetry, 462
Wheeler, John, 365n
Wick, Gian Carlo, 14
Wick contractions, 14–16, 47
Wick rotation, 12, 287
Wick theorem, 14
Wigner, Eugene: on antisymmetric wave function
of electron, 107; and law of baryon number
conservation, 413; and random matrix theory, 396;
on time reversal, 102
Wigner semicircle law, 397–400
Wilczek, Frank, 315, 316; on Yang-Mills theory, 386
Wilson, Ken, 161; and complete theory of critical
phenomena, 293; and effective field theory
approach, 452; and lattice gauge theory, 374–376;
and renormalization groups, 361
Wilson loop, 261; in lattice gauge theory, 376–377,
457; and quark confinement, 386
Witten, Ed, 334, 500
Wu, Tai-tsun, 248
Yanagida, T., and seesaw mechanism, 426
Yang, Chen-Ning, 100, 105, 248; and nonabelian
gauge theory, 253, 255
Yang-Mills bosons, 257, 386; self-interaction of,
434
Yang-Mills coupling constant, 258–259
Yang-Mills Lagrangian, 257
Yang-Mills theory, 257–258; area law in, 377;
asymptotically free, 386; Einstein-Hilbert action
compared with, 434–435; Einstein’s theory
of gravity compared with, 444–445, 513–520;
Feynman rules in, 257, 257f, 494–495;

576 | Index
Yang-Mills theory (continued)
gluon scattering in, 483–496; original response
to, 371, 379; perturbative approach to, 374;
quantizing, 371–373; recent developments
in, 483–496, 501–504, 513–520; recursion in,
501–503; Schr¨odinger equation and, 260–
261; supersymmetric, 392, 467–468; Wilson
formulation of, 374–376
Young tableaux, 526
Yukawa, H., 28–29, 171
Yukawa coupling, 170
Yukawa theory, renormalizability of, 178–
179
Zakharov, V., 439
Zee, A., 316
Zhang, Shou-cheng, 324
Zinn-Justin, Jean, 173
Zuber, Jean-Bernard, 402
Zumino, Bruno, 121, 470

