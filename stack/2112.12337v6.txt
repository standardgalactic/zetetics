Cooperative Learning for Multiview Analysis
Daisy Yi Ding2, Shuangning Li1, Balasubramanian Narasimhan1,2, and Robert Tibshirani1,2
1Department of Statistics, Stanford University
2Department of Biomedical Data Science, Stanford University
Abstract
We propose a new method for supervised learning with multiple sets of features (“views”). The multiview
problem is especially important in biology and medicine, where “-omics” data such as genomics, proteomics
and radiomics are measured on a common set of samples. Cooperative learning combines the usual squared
error loss of predictions with an “agreement” penalty to encourage the predictions from diﬀerent data views
to agree. By varying the weight of the agreement penalty, we get a continuum of solutions that include
the well-known early and late fusion approaches.
Cooperative learning chooses the degree of agreement
(or fusion) in an adaptive manner, using a validation set or cross-validation to estimate test set prediction
error. One version of our ﬁtting procedure is modular, where one can choose diﬀerent ﬁtting mechanisms
(e.g. lasso, random forests, boosting, neural networks) appropriate for diﬀerent data views. In the setting
of cooperative regularized linear regression, the method combines the lasso penalty with the agreement
penalty, yielding feature sparsity. The method can be especially powerful when the diﬀerent data views
share some underlying relationship in their signals that can be exploited to boost the signals. We show that
cooperative learning achieves higher predictive accuracy on simulated data and a real multiomics example
of labor onset prediction. Leveraging aligned signals and allowing ﬂexible ﬁtting mechanisms for diﬀerent
modalities, cooperative learning oﬀers a powerful approach to multiomics data fusion.
1
Introduction
With new technologies in biomedicine, we are able to generate and collect data of various modalities, including
genomics, epigenomics, transcriptomics, proteomics, and metabolomics (Fig. 1A). Integrating heterogeneous
features on a common set of observations provides a unique opportunity to gain a comprehensive understanding
of an outcome of interest. It oﬀers the potential for making discoveries that are hidden in data analyses of a
single modality and achieving more accurate predictions of the outcome (Kristensen et al. 2014, Ritchie et al.
2015, Robinson et al. 2017, Karczewski & Snyder 2018, Ma et al. 2020, Hao et al. 2021). While “multiview data
analysis” can mean diﬀerent things, we use it here in the context of supervised learning, where the goal is to
fuse diﬀerent data views to model an outcome of interest.
To give a concrete example, assume that a researcher wants to predict cancer outcomes from RNA expression
and DNA methylation measurements for a set of patients. The researcher suspects that: (1) both data views
potentially have prognostic value; (2) the two views share some underlying relationship with each other, as DNA
methylation regulates gene expression and can repress the expression of tumor suppressor genes or promote the
expression of oncogenes. Should the researcher use both data views for downstream prediction, or just use one
view or the other? If using both views, how can the researcher leverage their underlying relationship in making
more accurate prediction? Is there a way to strengthen the shared signals in the two data views while reducing
idiosyncratic noise?
1
arXiv:2112.12337v6  [stat.ME]  3 Sep 2022

Genomics 
Me3 
Me3 
Epigenomics 
Transcriptomics 
Proteomics 
Radiomics 
A 
... 
B 
View X 
View Z 
Combined View 
Predictive model 
fit to target y 
Early Fusion 
Late Fusion 
Cooperative Learning 
X Predictive model 
fit to target y 
Z Predictive model 
fit to target y 
Combine into 
final prediction 
Multiomics Data Fusion 
Sample 1 
Sample 2 
Sample n 
Gene 1 
Gene 2 
Gene s 
... 
... 
Sample 1 
Sample 2 
Sample n 
... 
Protein 1 
Protein 2 
Protein t 
... 
View Z 
Sample 1 
Sample 2 
Sample n 
... 
Protein 1 
Protein 2 
Protein t 
... 
Sample 1 
Sample 2 
Sample n 
Gene 1 
Gene 2 
Gene s 
... 
... 
View X 
Figure 1: Framework for multiomics data fusion. (A) Advances in biotechnologies have enabled the collection of a myriad of
“-omics” data ranging from genomics to proteomics measured on a common set of samples. These data capture the molecular
variations of human health at multiple levels and can help us understand complex biological systems in a more comprehensive way.
Fusing the data oﬀers the potential to improve predictive accuracy of disease phenotypes and treatment response, thus enabling
better diagnostics and therapeutics. However, multiview analysis of omics data presents challenges such as increased dimensionality,
noise and complexity. (B) Commonly-used approaches to the problem can be broadly categorized into early and late fusion. Early
fusion begins by transforming all datasets into a single representation, which is then used as the input to a supervised learning
model of choice. Late fusion works by developing ﬁrst-level models from individual data views and then combining the predictions
by training a second-level model as the ﬁnal predictor. Encompassing early and late fusion, cooperative learning combines the usual
squared error loss of predictions with an agreement penalty term to encourage the predictions from diﬀerent data views to align.
There are two broad categories of existing “data fusion methods” for the multiview problem (Fig. 1B). They
diﬀer in the stage at which the “fusion” of predictors takes place, namely early fusion and late fusion. Early
fusion works by transforming the multiple data views into a single representation before feeding the aggregated
representation into a supervised learning model of choice (Yuan et al. 2014, Gentles et al. 2015, Perkins et al.
2018, Chaudhary et al. 2018). The simplest approach is to column-wise concatenate the M datasets X1, . . . , XM
to obtain a combined matrix X, which is then used as the input to a supervised learning model. Another type of
early fusion approach projects each high-dimensional dataset into a low-dimensional space using methods such
as principal component analysis or autoencoders (Wold et al. 1987, Vincent et al. 2010). Then one combines the
low-dimensional representations through aggregation and feed the aggregated matrix into a supervised learning
model. Early fusion approaches have an important limitation that they do not explicitly leverage the underlying
relationship across data views. Late fusion, or “integration”, refers to methods where individual models are
ﬁrst built from the distinct data views, and then the predictions of the individual models are combined into the
ﬁnal predictor (Yang et al. 2010, Zhao et al. 2019, Chen, Lu, Wang, Williamson, Rodig, Lindeman & Mahmood
2020, Chabon et al. 2020, Wu et al. 2020).
In this paper, we propose a new method to multiview data analysis called cooperative learning, a supervised
learning approach that fuses the diﬀerent views in a systematic way. The method combines the usual squared
error loss of predictions with an “agreement” penalty that encourages the predictions from diﬀerent data views
to align. By varying the weight of the agreement penalty, we get a continuum of solutions that include the
commonly-used early and late fusion approaches. Our proposal can be especially powerful when the diﬀerent
data views share some underlying relationship in their signals that can be leveraged to strengthen the signals.
The rest of the paper is organized as follows. In Section 2, we introduce cooperative learning and characterize
2

its solution. This involves the iterative algorithm for general form of cooperative learning and the explicit closed-
form solution for cooperative regularized linear regression. We discuss its relation with early and late fusion,
as well as other existing approaches, and establish theoretical underpinnings of our approach. In Section 3, we
extend cooperative learning to settings when we have more than two data views. We demonstrate in Section 4
the eﬀectiveness of cooperative learning in simulation studies, where we compare it to several commonly-used
approaches. In Section 5, we apply cooperative learning on a real multiomics example and show that it achieves
higher predictive accuracy on labor onset prediction. In Section 6, we discuss how cooperative learning can be
extended to generalized linear models and Cox proportional hazards models. We outline how the framework
can be extended to paired features and interaction models in Section 7. The paper ends with a discussion and
an appendix.
2
Cooperative learning
2.1
Cooperative learning with two data views
We begin with a simple form of our proposal for the population (random variable) setting. Let X ∈Rn×px,
Z ∈Rn×pz — representing two data views — and y ∈Rn be a real-valued random variable (the target). Fixing
the hyperparameter ρ ≥0, we propose to minimize the population quantity:
min E
h1
2(y −fX(X) −fZ(Z))2 + ρ
2(fX(X) −fZ(Z))2i
.
(1)
The ﬁrst term above is the usual prediction error, while the second term is an “agreement” penalty, en-
couraging the predictions from diﬀerent views to agree. This penalty term is related to “contrastive learning”
(Chen, Kornblith, Norouzi & Hinton 2020, Khosla et al. 2020), which we discuss in more detail in Section 2.7.
The solution to (1) has ﬁxed points:
fX(X)
=
E
h
y
1 + ρ −(1 −ρ)fZ(Z)
(1 + ρ)
|X
i
,
fZ(Z)
=
E
h
y
1 + ρ −(1 −ρ)fX(X)
(1 + ρ)
|Z
i
.
(2)
We can optimize the objective by repeatedly updating the ﬁt for each data view in turn, holding the other
view ﬁxed. When updating a function, this approach allows us to apply the ﬁtting method for that data view
to a penalty-adjusted “partial residual”. For more than two views, this generalizes easily, with details given in
Section 3.
The following relationships to early and late fusion can be seen immediately:
• If ρ = 0, from (1) we see that cooperative learning chooses a functional form for fX and fZ and ﬁts them
together. If these functions are additive (for example, linear) then it yields a simple form of early fusion,
where we simply use the combined set of features in a supervised learning procedure.
• If ρ = 1, then from (2) we see that the solutions are the average of the marginal ﬁts for X and Z. This is
a simple form of late fusion.
3

We explore the relation of cooperative learning to early/late fusion in more detail in Section 2.4, in the setting
of regularized linear regression.
Note that this “one-at-a-time” ﬁtting procedure is modular, so that we can choose a ﬁtting mechanism
appropriate for each data view. Speciﬁcally:
• For quantitative features like gene expression, copy number variation, or methylation: regularized regres-
sion (lasso, elastic net), a generalized additive model, boosting, random forests, or neural networks.
• For images: a convolutional neural network.
• For time series data: an auto-regressive model or a recurrent neural network.
We illustrate this on a simulated image and omics example in Section 4.2.
2.2
Cooperative regularized linear regression
We make our proposal more concrete in the setting of cooperative regularized linear regression. Consider feature
matrices X ∈Rn×px, Z ∈Rn×pz, and our target y ∈Rn. We assume that the columns of X and Z have been
standardized, and y has mean 0 (hence we can omit the intercept below). For a ﬁxed value of the hyperparameter
ρ ≥0, we want to ﬁnd θx ∈Rpx and θz ∈Rpz that minimize:
J(θx, θz) = 1
2||y −Xθx −Zθz||2 + ρ
2||(Xθx −Zθz)||2 + λxP x(θx) + λzP z(θz),
(3)
where ρ is the hyperparameter that controls the relative importance of the agreement term ||(Xθx −Zθz)||2 in
the objective, and P x and P z are penalty functions. Most commonly, we use ℓ1 penalties, giving the objective
function:
J(θx, θz) = 1
2||y −Xθx −Zθz||2 + ρ
2||(Xθx −Zθz)||2 + λx||θx||1 + λz||θz||1.
(4)
Note that when ρ = 0, this reduces to early fusion, where we simply concatenate the columns of X and Z and
apply lasso. Furthermore, in Section 2.4, we show that ρ = 1 yields a late fusion estimate.
In our experiments, we standardize the features and simply take λx = λz = λ. We have found that generally
there is often no advantage to allowing diﬀerent λ values for diﬀerent views. However, for completeness, in
Appendix Section A, we outline an adaptive strategy for optimizing over λx and λz. We call this adaptive
cooperative learning in our studies.
With a common λ, the objective becomes
J(θx, θz) = 1
2||y −Xθx −Zθz||2 + ρ
2||(Xθx −Zθz)||2 + λ(||θx||1 + ||θz||1),
(5)
and we can compute a regularization path of solutions indexed by λ.
Problem (5) is convex, and the solution can be computed as follows. Letting
˜X =

X
Z
−√ρX
√ρZ

, ˜y =

y
0

, ˜β =
θx
θz

,
(6)
4

Algorithm 1 Direct algorithm for cooperative regularized regression.
Input: X ∈Rn×px and Z ∈Rn×pz, the response y ∈Rn, and a grid of hyperparameter values (ρmin, . . . , ρmax).
for ρ ←ρmin, . . . , ρmax do
Set
˜X =

X
Z
−√ρX
√ρZ

, ˜y =
y
0

.
Solve Lasso( ˜X, ˜y, λ) over a decreasing grid of λ values.
end
Select the optimal value of ρ∗based on the CV error and get the ﬁnal ﬁt.
then the equivalent problem to (5) is
J(θx, θz) = 1
2||˜y −˜X ˜β||2 + λ(||θx||1 + ||θz||1).
(7)
This is a form of the lasso, and can be computed, for example by the glmnet package (Friedman et al. 2010).
This new problem has 2n observations and px + pz features.
Let Lasso(X, y, λ) denote the generic problem:
minβ
1
2∥y −Xβ∥2 + λ∥β∥1.
(8)
We outline the direct algorithm for cooperative regularized regression in Algorithm 1.
Remark A. We note that for cross-validation (CV) to estimate λ and ρ, we do not form folds from the
rows of ˜X, but instead form folds from the rows of X and Z and then construct the corresponding ˜X.
Remark B. We can add ℓ2 penalties to the objective in (5), replacing λ(||θx||1 + ||θz||1) by the elastic net
form
λ
h
(1 −α)(||θx||1 + ||θz||1) + α(||θx||2
2/2 + ||θz||2
2/2)
i
.
(9)
This leads to elastic net ﬁtting, in place of the lasso, in the last step of the algorithm. This option is included
in our publicly available software implementation of cooperative learning.
We show here an illustrative simulation study of cooperative learning in the regression setting in Figure 2A.
We will discuss more comprehensive studies in Section 4. In Figure 2A, the ﬁrst and second plots correspond to
the settings where the two data views X and Z are correlated, while in the third plot X and Z are uncorrelated.
We see that when the data views are correlated, cooperative learning oﬀers signiﬁcant performance gains over
the early and late fusion methods, by encouraging the predictions from diﬀerent views to agree. When the data
views are uncorrelated and only one view X contains signal as in the third plot, early and late fusion methods
hurt performance as compared to the separate model ﬁt on only X, while adaptive cooperative learning is able
to perform on par with the separate model.
2.3
One-at-a-time algorithm for cooperative regularized linear regression
As an alternative, one can optimize (4) by iteratively optimizing over θx and θz, ﬁxing one and optimizing over
the other. The updates are as follows:
5

B
A
Figure 2: An illustrative simulation study of cooperative learning in the regression setting, and sparsity of the solution. (A)
Cooperative learning achieves superior prediction accuracy on a test set when the data views X and Z are correlated. The y-axis
shows the mean squared error (MSE) on a test set. The methods in comparison from left to right in each panel correspond to (1)
Separate X: lasso applied on the data view X only; (2) Separate Z: lasso applied on the data view Z only; (3) Early fusion: lasso
applied on the concatenated data views of X and Z; (4) Late fusion: separate lasso models are ﬁt on X and Z independently and
the predictors are then combined through linear least squares; (5) Coop: cooperative learning as outlined in Algorithm 1; (6) Adap
Coop: adaptive cooperative learning as outlined in Algorithm 4 (see Appendix Section A). Note that the test MSE in each panel
is of a diﬀerent scale because we experiment with simulating the data of diﬀerent signal-to-noise ratios (SNR). We conducted each
simulation experiment 10 times. (B) The number of non-zero coeﬃcients as a function of the ℓ1 norm of the solution with diﬀerent
values of the weight on the agreement penalty term ρ: the solution becomes less sparse as ρ increases.
ˆ
θx
=
Lasso(X, y∗
x, λx) , where y∗
x =
y
1 + ρ −(1 −ρ)Zθz
(1 + ρ)
,
ˆθz
=
Lasso(Z, y∗
z, λz) , where y∗
z =
y
1 + ρ −(1 −ρ)Xθx
(1 + ρ)
.
(10)
This is analogous to the general iterative procedure in (2). It is summarized in Algorithm 2.
Algorithm 2 One-at-a-time algorithm for cooperative regularized regression.
Input: X ∈Rn×px and Z ∈Rn×pz, the response y ∈Rn, and a grid of hyperparameter values
(ρmin, . . . , ρmax).
Fix the lasso penalty weights λx and λz, for ρ ←ρmin, . . . , ρmax do
Initialize θ(0)
x
∈Rpx and θ(0)
z
∈Rpz.
for k ←0, 1, 2, . . . until convergence do
1. Set y∗
x =
y
1+ρ −(1−ρ)Zθz
(1+ρ)
. Solve Lasso(X, y∗
x, λx) and update θ(k+1)
x
to be the solution.
2. Set y∗
z =
y
1+ρ −(1−ρ)Xθx
(1+ρ)
. Solve Lasso(Z, y∗
z, λz) and update θ(k+1)
z
to be the solution.
end
end
Select the optimal value of ρ∗based on the sum of the CV errors and get the ﬁnal ﬁt.
By iterating back and forth between the two lasso problems, we can ﬁnd the optimal solution to (4). When
both X and Z have full column rank, the problem (4) is strictly convex and each iteration decreases the overall
objective value. Therefore, the one-at-a-time procedure is guaranteed to converge. In general, it can be shown
to converge to some stationary point, using results such as those in Tibshirani (2017). This algorithm uses ﬁxed
6

values for λx, λz: we need to run the algorithm over a grid of such values, or use CV to choose λx, λz within
each iteration.
With just two views, there seems to be no advantage to this approach over the direct solution given in
Algorithm 1. However, for a larger number of views, there can be a computational advantage, which we will
discuss in Section 3.
2.4
Relation to early/late fusion
From the objective functions (3) and (4), when the weight on the agreement term ρ is set to 0, cooperative
learning (regression) reduces to a form of early fusion: we simply concatenate the columns of diﬀerent views
and apply lasso or another regularized regression method.
Next we discuss the relation of cooperative learning to late fusion. Let X and Z have centered columns and
y centered, from (6) we obtain
˜XT ˜X =
XT X(1 + ρ)
XT Z(1 −ρ)
ZT X(1 −ρ)
ZT Z(1 + ρ)

.
(11)
Assuming X and Z have full rank, and omitting the ℓ1 penalties, we obtain the least squares estimates
ˆθx
ˆθz

=
XT X(1 + ρ)
XT Z(1 −ρ)
ZT X(1 −ρ)
ZT Z(1 + ρ)
−1 XT y
ZT y

.
(12)
If XT Z = 0 (uncorrelated features between the views), this reduces to a linear combination of the least squares
estimates for each block; when ρ = 1, it is simply the average of the least squares estimates for each block. The
above relation also holds when we include the ℓ1 penalties.
This calculation suggests that restricting ρ to be in [0, 1] would be natural. However, we have found that
values larger than one can sometimes yield lower prediction error (see the simulation studies in Section 4).
2.5
Sparsity of the solution
We explore how the sparsity of the solution depends on the agreement hyperparameter ρ in Figure 2B. We did
100 simulations of Gaussian data with n = 100 and p = 20 in each of two views, with all coeﬃcients equal to
2.0. The standard deviation (SD) of the errors was chosen so that the SNR was about 2. The ﬁgure shows the
number of non-zero coeﬃcients as a function of the overall ℓ1 of the solutions, for diﬀerent values of ρ. Note
that the lasso parameter λ is varying along the horizontal axis; we chose to plot against the ℓ1 norm, a more
meaningful quantity. We see that the solutions become less sparse as ρ increases, much like the behavior that
one sees in the elastic net.
2.6
Theoretical analysis under the latent factor model
To understand the role of the agreement penalty from a theoretical perspective, we consider the following
latent factor model. Let u = (U1, U2, . . . , Un) be a vector of n i.i.d. random variables with Ui ∼N(0, 1), y =
(y1, . . . , yn), x = (X1, . . . , Xn), and z = (Z1, . . . , Zn), with yi = γyUi+εyi, Xi = γxUi+εxi and Zi = γzUi+εzi,
where εyi ∼N
 0, σ2
y

, εxi ∼N
 0, σ2
x

, εzi ∼N
 0, σ2
z

independently. We show that the mean squared error
7

(MSE) of the predictions from cooperative learning is a decreasing function of ρ around 0 with high probability
(see details in Appendix Section D). Therefore, the agreement penalty oﬀers an advantage in reducing MSE of
the predictions under the latent factor model.
2.7
Relation to existing approaches
We have mentioned the close connection of cooperative learning to early and late fusion: setting ρ = 0 or 1 gives
a version of each of these, respectively. There are many variations of late fusion, including the use of stacked
generalization to combine the predictions at the last stage (Garcia-Ceja et al. 2018).
Cooperative learning is also related to collaborative regression (Gross & Tibshirani 2015). This method uses
an objective function of the form
bxy
2 ||y −Xθx||2 + bzy
2 ||y −Zθz||2 + bxz
2 ||Xθx −Zθz||2.
(13)
With ℓ1 penalties added, this is proposed as a method for sparse supervised canonical correlation analysis. It
is diﬀerent from cooperative learning in an important way: here X and Z are not ﬁt jointly to the target.
The authors state that collaborative regression is not well suited to the prediction task.
We note that if
bxy = bzy = bxz = 1, each of ˆθx, ˆθz are the one-half of the least squares (LS) estimates on X, Z respectively.
Hence the overall prediction ˆy is the average of the individual LS predictions. This late fusion estimate is
the same as that obtained from cooperative learning with ρ = 1. In addition, a related framework based on
optimizing measures of agreement between data views was also proposed in Sindhwani et al. (2005), but it is
diﬀerent from cooperative learning in the sense that the data views are not used jointly to model the target.
Cooperative learning also has connections with contrastive learning (Chen, Kornblith, Norouzi & Hinton
2020, Khosla et al. 2020). This method is an unsupervised learning technique ﬁrst proposed for learning visual
representations. Without the supervision of y, it learns representations of images by maximizing agreement
between diﬀerently augmented “views” of the same data example. While both contrastive learning and coop-
erative learning have a term in the objective that encourages agreement between correlated views, our method
combines the agreement term with the usual prediction error loss and is thus supervised.
Moreover, the iteration (2) looks much like the backﬁtting algorithm for generalized additive models (Hastie &
Tibshirani 1990). In that setting, each of fX and fZ are typically functions of one-dimensional features X and Z,
and the backﬁtting algorithm iterations correspond to (2) with ρ = 0. In the additive model setting, backﬁtting
is a special case of the Gauss-Seidel algorithm (Hastie & Tibshirani 1990). In cooperative learning, each of
X, Z are views with multiple features; we could use an additive model for each view, i.e. fX(X) = P
i gi(Xi),
fZ(Z) = P
j hj(Zj), where i and j are column indices of X and Z, respectively. Then each of the iterations in
(2) could be solved using a backﬁtting algorithm, leading to a nested procedure.
We next discuss the relation of cooperative learning to a recently proposed method for multiview analysis
called sparse integrative discriminant analysis (SIDA) (Safo et al. 2021). This method aims to identify vari-
ables that are associated across views while also able to optimally separate data points into diﬀerent classes.
Speciﬁcally, it combines canonical correlation analysis and linear discriminate analysis by solving the following
optimization problem. Let Xk = (x1k, . . . , xnk,k)T ∈Rnk×p, xk ∈Rp be the data matrix for class k, where
k = 1, . . . , K, and nk is the number of samples in class k. Then, the mean vector for class k is ˆµk =
1
nk
Pnk
i=1 xik;
the common variance matrix for all classes is Sw = PK
k=1
Pn
i=1(xik −ˆµk)(xik −ˆµk)T ; the between class covari-
ance matrix is Sb = PK
k=1 nk(ˆµk −ˆµ)(ˆµk −ˆµ)T , where ˆµ = 1
n
PK
k=1 nkˆµk is the combined class mean vector.
Assume that we have two data views X ∈Rn×px and Z ∈Rn×pz with centered columns, we want to ﬁnd
A = [a1, . . . , aK−1] and B = [b1, . . . , bK−1] such that
8

max ρ · tr(AT Sx
b A + BT Sz
b B) + (1 −ρ) · tr(AT SxzBBT ST
xzA)
s.t. tr(AT Sx
wA)/(K −1) = 1 & tr(BT Sz
wB)/(K −1) = 1,
where Sxz ∈Rpx×pz is the sample cross-covariance matrix between X and Z. Here, tr(·) is the trace function,
and ρ is the parameter that controls the relative importance of the “separation” term and the “association”
terms in the objective. While SIDA also considers the association across data views by choosing vectors that
are associated and able to separate data points into classes, it solves the problem in a “backward” manner, that
is the features are modeled as a function of the outcome. Cooperative learning, in contrast, solves the problem
in a “forward” manner (Y ∼X, Z), which is more suitable for prediction.
We also note the connection between cooperative learning (regression) with the standardized group lasso
(Simon & Tibshirani 2012). This method is a variation of the group lasso (Yuan & Lin 2006), and uses
∥Xθx∥2 + ∥Zθz∥2
(14)
as the penalty term, rather than the sum of squared two norms. It encourages group-level sparsity by eliminating
entire blocks of features at a time. In the group lasso, each block is a group of features, and we do not expect
each block to be predictive on its own. This is diﬀerent from cooperative learning, where each feature block is a
data view and we generally do not want to eliminate an entire view for prediction. In addition, the standardized
group lasso does not have an agreement penalty. One could in fact add the standardized group lasso penalty
(14) to the cooperative learning objective, which would allow elimination of entire data views.
3
Cooperative learning with more than two data views
When we have more than two views of the data, X1 ∈Rn×p1, X2 ∈Rn×p2, . . . , XM ∈Rn×pM , the population
quantity that we want to minimize becomes
min E
h1
2(y −
M
X
m=1
fXm(Xm))2 + ρ
2
X
m<m′
(fXm(Xm) −fXm′(Xm′))2i
.
(15)
We can also have diﬀerent weights on the agreement penalties for distinct pairs of data views, forcing some
pairs to agree more than others. In addition, we can incorporate prior knowledge in determining the relative
strength of the agreement penalty for each pair of data views.
As with two views, this can be optimized with an iterative algorithm that updates each fXm(Xm) as follows:
fXm(Xm) = E
h
y
1 + (M −1)ρ −
(1 −ρ) P
m′̸=m fXm′(Xm′)
1 + (M −1)ρ
|Xm
i
.
(16)
As in the two-view setup above, the ﬁtter E(·|Xm) can be tailored to the data type of each view.
For regularized linear regression with more than two views, the objective becomes
J(θ1, θ2, . . . , θM) = 1
2||y −
M
X
m=1
Xmθm||2 + ρ
2
X
m<m′
||(Xmθm −Xm′θm′)||2 +
M
X
m=1
λm∥θm||1.
(17)
This is again a convex problem. The optimal solution can be found by forming augmented data matrices as
before in (6) and (7).
9

Let
˜X =












X1
X2
...
XM−1
XM
−√ρX1
√ρX2
...
0
0
−√ρX1
0
...
√ρXM−1
0
−√ρX1
0
...
0
√ρXM
0
−√ρX2
...
√ρXM−1
0
0
−√ρX2
...
0
√ρXM
...
...
...
...
...
0
0
...
−√ρXM−1
√ρXM












,
˜y =
 y
0
...
0T , ˜β =
 θ1
θ2
...
θM
T ,
(18)
then the equivalent problem to (17) becomes
1
2||˜y −˜X ˜β||2 +
M
X
m=1
λm∥θm||1.
(19)
With M views, the augmented matrix in (18) has n+
 M
2

·n rows, which could be computationally challenging
to solve. Alternatively, the optimal solution ˆθ1, ˆθ2, . . . , ˆ
θM has ﬁxed points
ˆθm
=
Lasso(X, y∗
m, λm) , where y∗
m =
y
1 + (M −1)ρ −
(1 −ρ) P
m′̸=m Xm′θm′
1 + (M −1)ρ
.
(20)
This leads to an iterative algorithm, where we successively solve each subproblem, until convergence. For
a large number of views, this can be a more eﬃcient procedure than the direct approach in (19) above. We
include simulation studies on cooperative learning for more than two views in Appendix Section C.
4
Simulation studies
4.1
Simulation studies on cooperative regularized linear regression
Here we compare cooperative learning in the regression setting with early and late fusion methods in simulations.
The set up is as follows. Given values for parameters n, px, pz, pu, su, tx, tz, βu, σ, we generate data according
to the following procedure:
1. xj ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , px.
2. zj ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , pz.
3. For i = 1, 2, . . . , pu (pu corresponds to the number of latent factors, pu < px and pu < pz):
(a) ui ∈Rn distributed i.i.d. MVN(0, s2
uIn);
(b) xi = xi + tx ∗ui;
(c) zi = zi + tz ∗ui.
4. X = [x1, x2, . . . , xpx], Z = [z1, z2, . . . , zpz].
5. U = [u1, u2, . . . , upu], y = Uβu + ϵ where ϵ ∈Rn distributed i.i.d. MVN(0, σ2In).
10

A
X and Z correlated (medium correlation) - Both contain signal - SNR 1.8
B
X and Z correlated (high correlation) - X contains more signal than Z - SNR 0.6
C
X and Z uncorrelated - Only X contains signal - SNR 3.5
Figure 3: Simulation studies on cooperative regularized linear regression. (A) Simulation results when X and Z have a medium
level of correlation and both contain signal (tx = tz = 2), n = 200, p = 1000, SNR = 1.8. The ﬁrst panel shows MSE on a test set;
the second panel shows the MSE diﬀerence on the test set relative to early fusion; the third panel shows the number of features
selected; the fourth panel shows the ρ values selected by CV in cooperative learning. Here “Coop” refers to cooperative learning
outlined in Algorithm 1 and “Adap Coop” refers to adaptive cooperative learning outlined in Algorithm 4 (see Appendix Section
A). (B) Simulation results when X and Z have a high level of correlation and X contains more signal than Z (tx = 6, tz = 1),
n = 200, p = 1000, SNR = 0.6. (C) Simulation results when X and Z have no correlation; only X contains signal (tx = 2, tz = 0),
n = 200, p = 1000, SNR = 3.5.
There is sparsity in the solution since a subset of columns of X and Z are independent of the latent factors
used to generate y. Data sets are simulated with diﬀerent levels of correlation between the two data views X
and Z, diﬀerent contributions of X and Z to the signal, and diﬀerent signal-to-noise ratios (SNR). We consider
the settings of both small p and large p regimes, and of both low and high SNR ratios. We use 10-fold CV to
select the optimal values of hyperparameters. We compare the following methods:
11

• Separate X and separate Z: The standard lasso is applied on the separate data views of X and Z with
10-fold CV.
• Early fusion: The standard lasso is applied on the concatenated data views of X and Z with 10-fold CV.
Note that this is equivalent to cooperative learning with ρ = 0.
• Late fusion: Separate lasso models are ﬁrst ﬁtted on X and Z independently with 10-fold CV, and the
two resulting predictors are then combined through linear least squares for the ﬁnal prediction.
• Cooperative learning (regression) and adaptive cooperative learning.
We evaluated the performance based on the mean-squared error (MSE) on a test set. We conducted each
simulation experiment 10 times.
Overall, the simulation results can be summarized as follows:
• Cooperative learning performs the best in terms of test MSE across the range of SNR and correlation
settings. It is most helpful when the data views are correlated and both contain signal (as in Figure 3A
and Figure 3B). When the correlation between data views is higher, higher values of ρ are more likely to
be selected.
• When only one view contains signal and the views are not correlated (as in Figure 3C), cooperative learning
is outperformed by the separate model ﬁt on the view containing the signal, but adaptive cooperative
learning is able to perform on par with the separate model, outperforming early and late fusion.
• Moreover, we also ﬁnd that cooperative learning tends to yield a less sparse model, as expected from the
results of Section 2.5.
We include more comprehensive results across a wider range of simulation settings in Section B in the Appendix.
4.2
Simulation studies on cooperative learning with imaging and “omics” data
Here we extend the simulation studies for cooperative learning to the setting where we have two data views of
more distinct data modalities, such as imaging and omics data (e.g. transcriptomics and proteomics). We tailor
the ﬁtter suitable to each view, i.e. convolutional neural networks (CNN) for images and lasso for omics. We
simulate the “omics” data (X) and the “imaging” data (Z) such that they share some common factors. These
factors are also used to generate the signal in the response y. We use a factor model to generate the data, as it
is a natural way to create correlations between X, Z, and y. In Appendix Section F, we outline the full details
of the simulation procedure. Figure 4 shows some examples of the synthetic images generated for this study.
Our task is to use the omics and imaging data to predict if a patient has a certain disease. We use CNN
for modeling the imaging data and lasso for the omics data, and optimize the objective for the general form of
cooperative learning as in Algorithm 1 with the iterative “one-at-a-time” algorithm outlined in Algorithm 2.
We compare cooperative learning to the following methods: (1) Only images: a simple one-layer CNN with
max pooling and rectiﬁed linear unit (ReLU) activation is applied on the imaging data only; (2) Only omics:
the standard lasso is applied on the omics data only; (3) Late fusion: separate models (CNN and lasso) are ﬁrst
ﬁt on the imaging and omics data, respectively, and the resulting predictors are then combined through linear
least squares using a validation set. We evaluated the performance based on the misclassiﬁcation error on a test
12

Healthy Sample 
Disease Sample 
Pixel 
Intensity 
Figure 4: Generated images for “healthy” and “disease” samples. One can think of the image as an abstract form of a patient’s
lung, with the darker spots corresponding to the tumor sites. The intensity of the dark spots on the disease samples is generated
to correlate with the omics data and the signal in the outcome.
set, as well as the diﬀerence in misclassiﬁcation error relative to late fusion∗. We consider both low and high
SNR settings†. We conducted each simulation experiment 10 times.
The results are shown in Figure 5. We ﬁnd that (1) late fusion achieves a lower misclassiﬁcation error on the
test set than the separate models; (2) cooperative learning outperforms late fusion and achieves the lowest test
error by encouraging the predictions from the two views to agree; (3) cooperative learning is especially helpful
when the SNR is low, while its beneﬁt is less pronounced when the SNR is higher. The last observation makes
sense, because when the SNR is lower the marginal beneﬁt of leveraging the other view(s) in strengthening
signal becomes larger.
5
Real multiomics studies
We applied cooperative learning (regression) to a data set of labor onset, collected from a cohort of women who
went into labor spontaneously, as described in Stelzer et al. (2021). Proteome and metabolome were measured
from blood samples collected from the patients during the last 120 days of pregnancy. The goal of the analysis
is to predict time to spontaneous labor using proteomics and metabolomics data.
The proteomics data contained measurements for 1,322 proteins and the metabolomics data contained mea-
surements for 3,529 metabolites. We split the dataset of 53 patients into training and test sets of 40 and 13
patients, respectively‡. Both the proteomics and metabolomics measurements were screened by their variance
across the subjects. We extracted the ﬁrst time point for each patient from the longitudinal study and predicted
the corresponding time to labor. We conducted the same set of experiments across 10 diﬀerent random splits
of the training and test sets.
The results are shown in Table 1. The model ﬁt on the metabolomics data achieves lower test MSE than
the one ﬁt on the proteomics data. Early and late fusion hurt performance as compared to the model ﬁt on
only metabolomics. Cooperative learning gives performance gains over the model ﬁt only on metabolomics,
outperforming both early and late fusion and achieving the lowest MSE on the test set.
∗Early fusion is not applicable in this setting.
†The SNR is calculated based on the logits of the probabilities used to generate the class labels.
‡The cohort consisted of 63 patients as described in Stelzer et al. (2021), but in the public dataset we only found 53 patients
with matched proteomics and metabolomics data.
13

A 
B 
SNR Low (~1) 
SNR High (~6) 
Figure 5: Simulation studies on cooperative learning with imaging and “omics” data. Panel (A) corresponds to the relatively
low SNR setting (SNR = 1) and panel (B) to the higher SNR setting (SNR = 6).
For each setting, the left panel shows the
misclassiﬁcation error on the test set for CNN on only images, lasso on only omics, late fusion, and cooperative learning; the right
panel shows the diﬀerence in misclassiﬁcation error relative to late fusion. Here “Coop” refers to cooperative learning. For both
settings, the range of ρ values for cooperative learning to select from is (0,20). The average ρ selected in the low SNR setting is 6.8
and in the high SNR setting is 8.0.
We examined the selected features from cooperative learning and the other methods by comparing the ranking
of the features based on the magnitude of their coeﬃcients. All methods rank sialic acid binding immunoglobulin
like lectin-6 (Siglec-6), a protein highly expressed by the placenta (Brinkman-Van der Linden et al. 2007), as
the most important feature for predicting labor onset. As compared to the other methods, cooperative learning
boosts up the ranking of features such as plexin-B2 (PLXNB2), which is a protein expressed by the fetal
membranes (Singh & Aplin 2015), and Activin-A, which is highly expressed by the placenta as well (Stelzer
et al. 2021). While factors such as Siglec-6, PLXNB2 and Activin-A have previously also been discovered by
Stelzer et al. (2021) for labor onset prediction, C1q was only identiﬁed by cooperative learning as one of the top
ten features. C1q is an important factor involved in the complement cascade, which inﬂuences implantation and
fetal development (Girardi et al. 2020), and worth further investigation for its role in predicting labor onset.
Methods
Test MSE
Relative to Early Fusion
Number of
Features Selected
Mean
SD
Mean
SD
Mean
Separate Proteomics
475.51
80.89
69.14
81.44
26
Separate Metabolomics
381.13
36.88
-25.24
30.91
11
Early fusion
406.37
44.77
0
0
15
Late fusion
493.34
63.44
86.97
68.13
21
Cooperative learning
335.84
38.51
-70.53
32.60
52
Table 1: Multiomics studies on labor onset prediction. The ﬁrst two columns in the table show the mean and standard deviation
(SD) of MSE on the test set across diﬀerent splits of the training and test sets; the third and fourth column show the MSE
diﬀerence relative to early fusion; the last column shows the average number of features selected. The methods include (1) separate
proteomics: the standard lasso is applied on the proteomics data only; (2) separate metabolomics: the standard lasso is applied on
the metabolomics data only; (3) early fusion: the standard lasso is applied on the concatenated data of proteomics and metabolomics
data; (4) late fusion: separate lasso models are ﬁrst ﬁt on proteomics and metabolomics independently and the predictors are then
combined through linear least squares; (5) cooperative learning (Algorithm 1).
The average of the selected ρ values is 0.9 for
cooperative learning.
14

6
Cooperative generalized linear models and Cox regression
We next describe how cooperative learning can be extended to generalized linear models (GLMs) (Nelder &
Wedderburn 1972) and Cox proportional hazards models (Cox 1972).
Consider a GLM, consisting of 3 components: (1) a linear predictor: η = Xβ; (2) a link function g such that
E(Y |X) = g−1(η); (3) a variance function as a function of the mean: V = V (E(Y |X)). For cooperative GLMs,
we have the linear predictor as η = Xθx + Zθz, and an additional agreement penalty term ρ||(Xθx −Zθz)||2
with the following objective to be minimized:
J(θx, θz) = ℓ(Xθx + Zθz, y) + ρ
2||(Xθx −Zθz)||2 + λx||θx||1 + λz||θz||1,
(21)
where ℓis the negative log likelihood (NLL) of the data. For Cox proportional hazards models, ℓbecomes the
negative log partial likelihood of the data.
We make the usual quadratic approximation to (21), reducing the minimization problem to a weighted least
squares (WLS) problem, which yields
min 1
2[||W(z −Xθx −Zθz)||2 + ρ||(Xθx −Zθz)||2] + λx||θx||1 + λz||θz||1,
(22)
where z is the adjusted dependent variable and W is the diagonal weight matrix, both of which are functions
of θx and θz.
This leads to an iteratively reweighted least squares (IRLS) algorithm:
• Outer loop: Update the quadratic approximation using the current parameter ˆθx and ˆθz, i.e. update the
working response z and the weight matrix W.
• Inner loop: Letting
˜X =

W 1/2X
W 1/2Z
−√ρX
√ρZ

, ˜z =

W 1/2z
0

, ˜β =

θx
θz

,
(23)
solve the following problem
J(θx, θz) = 1
2||˜z −˜X ˜β||2 + λx||θx||1 + λz||θz||1,
(24)
which is equivalent to (22).
7
Some extensions
7.1
Paired features from diﬀerent views
One can extend cooperative learning to the setting where a feature in one view is naturally paired with a
feature in another view. For example, if the jth column Xj of X is the gene expression for gene j, and Zk is
the expression of the protein k for which gene j codes. In that setup, we would like to encourage agreement
between Xjθxj and Zkθzk. This pairing need not exist for all features, but can occur for a subset of features.
15

Looking back at our objective function (4) for two views in the linear case, we add to this objective a pairwise
agreement penalty of the form
ρ2
X
j,k∈P
(Xjθxj −Zkθzk)2
(25)
where P is the set of indices of the paired features.
This additional penalty can be handled easily in the optimization framework.
For the direct algorithm
(Algorithm 1), we simply add a new row to ˜X and ˜y for each pairwise constraint, while the one-at-a-time
algorithm (Algorithm 2) can be similarly modiﬁed.
7.2
Modeling interactions between views
In our general objective function (1), we can capture interactions between features in the same view, by using
methods such as random forests or boosting for the learners fX and fZ. However, this framework does not allow
for interactions between features in diﬀerent views. Here is an objective function to facilitate such interactions:
min E
h1
2(y −fX(X) −fZ(Z) −fXZ(X, Z))2 + ρ
2(fX(X) −fZ(Z))2 +
ρ
2(1 −ρ)f 2
XZ(X, Z)
i
,
(26)
where fXZ(X, Z) is a joint function of X and Z, including for example, interactions between the features in
each view.
The solution to (26) has ﬁxed points:
fX(X)
=
E
h
y
1 + ρ −(1 −ρ)fZ(Z)
(1 + ρ)
−fXZ(X, Z)
1 + ρ
|X
i
,
fZ(Z)
=
E
h
y
1 + ρ −(1 −ρ)fX(X)
(1 + ρ)
−fXZ(X, Z)
1 + ρ
|Z
i
,
fXZ(X, Z)
=
E
h
(1 −ρ)(y −fX(X) −fZ(Z))|X, Z
i
.
(27)
When ρ = 0, from (26) the solution reduces to the additive model fX(X) + fZ(Z) + fXZ(X, Z). As ρ →1,
the joint term fXY →0 and we again get the late fusion estimate as the average of the marginal predictions
ˆfX(X) and ˆfZ(Z). To implement this in practice, we simply insert learners such as random forest or boosting
for fX, fZ and fXZ. The ﬁrst two use only features from X and Z, while the last uses features from both.
8
Discussion
In this paper, we introduce a new method called cooperative learning for supervised learning with multiple
set of features, or “data views”. The method encourages the predictions from diﬀerent data views to align
through an agreement penalty. By varying the weight of the agreement penalty in the objective, we obtain a
spectrum of solutions that include the commonly-used early and late fusion methods. The method can choose
the degree of agreement (or fusion) in an data-adaptive manner. Cooperative learning provides a powerful
tool for multiomics data fusion by strengthening aligned signals across modalities and allowing ﬂexible ﬁtting
mechanisms for diﬀerent modalities.
The eﬀectiveness of our methodology has implications for improving
diagnostics and therapeutics in an increasingly multiomic world.
Furthermore, cooperative learning could be extended to the semi-supervised setting when we have additional
matched data views on samples that are unlabeled. The agreement penalty allows us to leverage the signals
16

in the matched unlabeled samples to our advantage. In addition, when we have missing values in some data
views, the agreement penalty also allows us to impute one view from the other(s). Lastly, the method can be
easily extended to binary, count and survival data. An open-source R language package for cooperative learning
called multiview is available on the CRAN repository.
Acknowledgments. We would like to thank Olivier Gevaert, Trevor Hastie, Ryan Tibshirani, and Samson
Mataraso for helpful discussions, and two referees whose comments greatly improved this manuscript. D.Y.D was
supported by the Stanford Graduate Fellowship (SGF). B.N. was supported by Stanford Clinical & Translational
Science Award grant 5UL1TR003142-02 from the NIH National Center for Advancing Translational Sciences
(NCATS). R.T. was supported by the National Institutes of Health (5R01 EB001988-16) and the National
Science Foundation (19 DMS1208164).
References
Brinkman-Van der Linden, E. C., Hurtado-Ziola, N., Hayakawa, T., Wiggleton, L., Benirschke, K., Varki, A. &
Varki, N. (2007), ‘Human-speciﬁc expression of siglec-6 in the placenta’, Glycobiology 17(9), 922–931.
Chabon, J. J., Hamilton, E. G., Kurtz, D. M., Esfahani, M. S., Moding, E. J., Stehr, H., Schroers-Martin, J.,
Nabet, B. Y., Chen, B., Chaudhuri, A. A. et al. (2020), ‘Integrating genomic features for non-invasive early
lung cancer detection’, Nature 580(7802), 245–251.
Chaudhary, K., Poirion, O. B., Lu, L. & Garmire, L. X. (2018), ‘Deep learning–based multi-omics integration
robustly predicts survival in liver cancer’, Clinical Cancer Research 24(6), 1248–1259.
Chen, R. J., Lu, M. Y., Wang, J., Williamson, D. F., Rodig, S. J., Lindeman, N. I. & Mahmood, F. (2020),
‘Pathomic fusion: an integrated framework for fusing histopathology and genomic features for cancer diagnosis
and prognosis’, IEEE Transactions on Medical Imaging .
Chen, T., Kornblith, S., Norouzi, M. & Hinton, G. (2020), A simple framework for contrastive learning of visual
representations, in ‘International Conference on Machine Learning’, PMLR, pp. 1597–1607.
Cox, D. R. (1972), ‘Regression models and life-tables’, Journal of the Royal Statistical Society: Series B (Method-
ological) 34(2), 187–202.
Friedman, J., Hastie, T. & Tibshirani, R. (2010), ‘Regularization paths for generalized linear models via coor-
dinate descent’, Journal of Statistical Software 33, 1–22.
Garcia-Ceja, E., Galv´an-Tejada, C. E. & Brena, R. (2018), ‘Multi-view stacking for activity recognition with
sound and accelerometer data’, Information Fusion 40, 45–56.
Gentles, A. J., Bratman, S. V., Lee, L. J., Harris, J. P., Feng, W., Nair, R. V., Shultz, D. B., Nair, V. S., Hoang,
C. D., West, R. B. et al. (2015), ‘Integrating tumor and stromal gene expression signatures with clinical
indices for survival stratiﬁcation of early-stage non–small cell lung cancer’, JNCI: Journal of the National
Cancer Institute 107(10).
Girardi, G., Lingo, J. J., Fleming, S. D. & Regal, J. F. (2020), ‘Essential role of complement in pregnancy:
From implantation to parturition and beyond’, Frontiers in immunology p. 1681.
Gross, S. M. & Tibshirani, R. (2015), ‘Collaborative regression’, Biostatistics 16(2), 326–338.
Hao, Y., Hao, S., Andersen-Nissen, E., Mauck III, W. M., Zheng, S., Butler, A., Lee, M. J., Wilk, A. J., Darby,
C., Zager, M. et al. (2021), ‘Integrated analysis of multimodal single-cell data’, Cell 184(13), 3573–3587.
Hastie, T. J. & Tibshirani, R. J. (1990), Generalized additive models, CRC Press.
17

Karczewski, K. J. & Snyder, M. P. (2018), ‘Integrative omics for health and disease’, Nature Reviews Genetics
19(5), 299.
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Liu, C. & Krishnan, D. (2020),
Supervised contrastive learning, in ‘Proceedings of the 34th Conference on Neural Information Processing
Systems’.
Kristensen, V. N., Lingjærde, O. C., Russnes, H. G., Vollan, H. K. M., Frigessi, A. & Børresen-Dale, A.-L. (2014),
‘Principles and methods of integrative genomic analyses in cancer’, Nature Reviews Cancer 14(5), 299–313.
Ma, A., McDermaid, A., Xu, J., Chang, Y. & Ma, Q. (2020), ‘Integrative methods and practical challenges for
single-cell multi-omics’, Trends in Biotechnology .
Nelder, J. A. & Wedderburn, R. W. (1972), ‘Generalized linear models’, Journal of the Royal Statistical Society:
Series A (General) 135(3), 370–384.
Perkins, B. A., Caskey, C. T., Brar, P., Dec, E., Karow, D. S., Kahn, A. M., Hou, Y.-C. C., Shah, N., Boeldt,
D., Coughlin, E. et al. (2018), ‘Precision medicine screening using whole-genome sequencing and advanced
imaging to identify disease risk in adults’, Proceedings of the National Academy of Sciences 115(14), 3686–
3691.
Ritchie, M. D., Holzinger, E. R., Li, R., Pendergrass, S. A. & Kim, D. (2015), ‘Methods of integrating data to
uncover genotype–phenotype interactions’, Nature Reviews Genetics 16(2), 85–97.
Robinson, D. R., Wu, Y.-M., Lonigro, R. J., Vats, P., Cobain, E., Everett, J., Cao, X., Rabban, E., Kumar-Sinha,
C., Raymond, V. et al. (2017), ‘Integrative clinical genomics of metastatic cancer’, Nature 548(7667), 297–303.
Safo, S. E., Min, E. J. & Haine, L. (2021), ‘Sparse linear discriminant analysis for multiview structured data’,
Biometrics .
Simon, N. & Tibshirani, R. (2012), ‘Standardization and the group lasso penalty’, Statistica Sinica 22(3), 983.
Sindhwani, V., Niyogi, P. & Belkin, M. (2005), A co-regularization approach to semi-supervised learning with
multiple views, in ‘Proceedings of ICML workshop on learning with multiple views’, Vol. 2005, Citeseer,
pp. 74–79.
Singh, H. & Aplin, J. (2015), ‘Endometrial apical glycoproteomic analysis reveals roles for cadherin 6,
desmoglein-2 and plexin b2 in epithelial integrity’, Molecular Human Reproduction 21(1), 81–94.
Stelzer, I. A., Ghaemi, M. S., Han, X., Ando, K., H´edou, J. J., Feyaerts, D., Peterson, L. S., Rumer, K. K.,
Tsai, E. S., Ganio, E. A. et al. (2021), ‘Integrated trajectories of the maternal metabolome, proteome, and
immunome predict labor onset’, Science Translational Medicine 13(592), eabd9898.
Tibshirani, R. J. (2017), ‘Dykstra’s algorithm, admm, and coordinate descent: Connections, insights, and
extensions’, arXiv preprint arXiv:1705.04768 .
Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A. & Bottou, L. (2010), ‘Stacked denoising
autoencoders: Learning useful representations in a deep network with a local denoising criterion.’, Journal of
Machine Learning Research 11(12).
Wold, S., Esbensen, K. & Geladi, P. (1987), ‘Principal component analysis’, Chemometrics and Intelligent
Laboratory Systems 2(1-3), 37–52.
Wu, L., Yang, Y., Guo, X., Shu, X.-O., Cai, Q., Shu, X., Li, B., Tao, R., Wu, C., Nikas, J. B. et al. (2020), ‘An
integrative multi-omics analysis to identify candidate dna methylation biomarkers related to prostate cancer
risk’, Nature Communications 11(1), 1–11.
18

Yang, P., Hwa Yang, Y., B Zhou, B. & Y Zomaya, A. (2010), ‘A review of ensemble methods in bioinformatics’,
Current Bioinformatics 5(4), 296–308.
Yuan, M. & Lin, Y. (2006), ‘Model selection and estimation in regression with grouped variables’, Journal of
the Royal Statistical Society: Series B (Statistical Methodology) 68(1), 49–67.
Yuan, Y., Van Allen, E. M., Omberg, L., Wagle, N., Amin-Mansour, A., Sokolov, A., Byers, L. A., Xu, Y.,
Hess, K. R., Diao, L. et al. (2014), ‘Assessing the clinical utility of cancer genomic and proteomic data across
tumor types’, Nature Biotechnology 32(7), 644–652.
Zhao, J., Feng, Q., Wu, P., Lupu, R. A., Wilke, R. A., Wells, Q. S., Denny, J. C. & Wei, W.-Q. (2019),
‘Learning from longitudinal data in electronic health record and genetic data to improve cardiovascular event
prediction’, Scientiﬁc Reports 9(1), 1–10.
19

A
Adaptive cooperative learning
In this section, we outline an adaptive strategy for optimizing over λx and λz for diﬀerent data views. We call
this adaptive cooperative learning. The method incorporates the values of λx and λz that have been adaptively
optimized by the one-at-a-time algorithm (Algorithm 3) as a penalty factor in the direct algorithm (Algorithm
4). In the two-dimensional grid of λx and λz, our proposed strategy works by iteratively searching along one
axis of λ while ﬁxing the other constant.
Algorithm 3 One-at-a-time algorithm for adaptive cooperative learning (regression).
Input: X ∈Rn×px and Z ∈Rn×pz, the response y ∈Rn, and a ﬁxed hyperparameter ρ ∈R.
Output: ˆ
θx and ˆθz from the last iteration, along with the hyperparameters λ∗
x and λ∗
z and the corresponding
CV errors.
1. Initialize θ(0)
x
∈Rpx and θ(0)
z
∈Rpz.
2. For k = 0, 1, 2, . . . until convergence:
(a) Set y∗
x =
y
1+ρ −(1−ρ)Zθz
(1+ρ)
. Solve Lasso(X, y∗
x, λ) over a decreasing grid of λ values. Update θ(k+1)
x
to
be the solution and record the hyperparameter λ∗
x that minimizes the CV error.
(b) Set y∗
z =
y
1+ρ −(1−ρ)Xθx
(1+ρ)
. Solve Lasso(Z, y∗
z, λ) over a decreasing grid of λ values. Update θ(k+1)
z
to
be the solution and record the hyperparameter λ∗
z that minimizes the CV error.
Algorithm 4 Direct algorithm for adaptive cooperative learning (regression).
Input: X ∈Rn×px and Z ∈Rn×pz, the response y ∈Rn, and a grid of hyperparameter values (ρmin, . . . , ρmax).
for ρ ←ρmin, . . . , ρmax do
Run Algorithm 3 with both (X,Z) and (Z,X) with the same folds for CV. Select the one with the lower
sum of the two CV errors. Get the corresponding λ∗
x and λ∗
z.
Set
˜X =

X
Z
−√ρX
√ρZ

, ˜y =

y
0

.
Solve Lasso( ˜X, ˜y, λ) over a decreasing grid of λ values, with a penalty factor of (1, . . . , 1, λ∗
z
λ∗x , . . . , λ∗
z
λ∗x ). Note
that we form folds from the rows of X and Z and then construct the corresponding ˜X.
end
Select the optimal value of ρ based on the CV error and get the ﬁnal ﬁt.
B
More comprehensive simulation studies on cooperative regular-
ized regression
B.1
More simulation results of the high-dimensional settings (p = 1000, n = 200)
20

A
B
C
Figure 6: Simulation studies on cooperative regularized linear regression when X and Z are high-dimensional and have a high
level of correlation with each other. (A) Simulation results when X and Z have a high level of correlation and both contain signal
(tx = tz = 6), n = 200, p = 1000, SNR = 1.0. The ﬁrst panel shows MSE on a test set; the second panel shows the MSE diﬀerence
on the test set relative to early fusion; the third panel shows the number of features selected; the fourth panel shows the ρ values
selected by CV in cooperative learning. Here “Coop” refers to cooperative learning outlined in Algorithm 1 and “Adap Coop” refers
to adaptive cooperative learning outlined in Algorithm 4. (B) Simulation results when X and Z have a high level of correlation
and both contain signal (tx = tz = 6), n = 200, p = 1000, SNR = 0.6. (C) Simulation results when X and Z have a high level of
correlation, X contains more signal than Z (tx = 4, tz = 2), n = 200, p = 1000, SNR = 0.6.
21

A
B
C
Figure 7: Simulation studies on cooperative regularized linear regression when X and Z are high-dimensional and have a medium
level of correlation with each other. (A) Simulation results when X and Z have a medium level of correlation and both contain
signal (tx = tz = 2), n = 200, p = 1000, SNR = 3.5. The setup is the same as in Figure 6. (B) Simulation results when X and Z
have a medium level of correlation and both contain signal (tx = tz = 2), n = 200, p = 1000, SNR = 1.6. (C) Simulation results
when X and Z have a medium level of correlation, and Z contains more signal than X (tx = 2, tz = 3), n = 200, p = 1000, SNR
= 1.5.
22

A
B
C
Figure 8:
Simulation studies on cooperative regularized linear regression when X and Z are high-dimensional and have no
correlation. (A) Simulation results when X and Z have no correlation, and both X and Z contain signal (here we generated y as
a linear combination of X and Z instead of the latent factors), n = 200, p = 1000, SNR = 1.0. The setup is the same as in Figure
6. (B) Simulation results when X and Z have no correlation; X contains more signal than Z (here we generated y as a linear
combination of X and Z instead of the latent factors), n = 200, p = 1000, SNR = 1.1. (C) Simulation results when X and Z have
no correlation; only X contains signal (tx = 2, tz = 0), n = 200, p = 1000, SNR = 3.5.
23

B.2
Simulation results of the lower-dimensional settings (p = 200, n = 500)
A
B
Figure 9: Simulation studies on cooperative regularized linear regression when X and Z are of a lower dimension and have a
high level of correlation with each other. (A) Simulation results when X and Z have a high level of correlation and both contain
signal (tx = tz = 6), n = 500, p = 200, SNR = 1.2. The ﬁrst panel shows MSE on a test set; the second panel shows the MSE
diﬀerence on the test set relative to early fusion; the third panel shows the number of features selected; the fourth panel shows the
ρ values selected by CV in cooperative learning. Here “Coop” refers to cooperative learning outlined in Algorithm 1 and “Adap
Coop” refers to adaptive cooperative learning outlined in Algorithm 4. (B) Simulation results when X and Z have a high level of
correlation and X contains more signal than Z (tx = 5, tz = 3), n = 500, p = 200, SNR = 0.7.
24

A
B
Figure 10: Simulation studies on cooperative regularized linear regression when X and Z are of a lower dimension and have a
medium level of correlation with each other. (A) Simulation results when X and Z have a medium level of correlation and both
contain signal (tx = tz = 1), n = 500, p = 200, SNR = 0.8. The setup is the same as in Figure 9. (B) Simulation results when X
and Z have a medium level of correlation, and Z contains more signal than X (tx = 0.6, tz = 0.9), n = 500, p = 200, SNR = 0.5.
25

A
B
Figure 11: Simulation studies on cooperative regularized linear regression when X and Z are of a lower dimension and have
no correlation with each other. (A) Simulation results when X and Z have no correlation (tx = tz = 0), and both X and Z
contain signal (here we generated y as a linear combination of X and Z instead of the latent factors), n = 500, p = 200, SNR
= 0.3. The setup is the same as in Figure 9. (B) Simulation results when X and Z have no correlation and only X contains signal
(tx = 2, tz = 0), n = 500, p = 200, SNR = 3.0.
C
Simulation studies on cooperative learning for more than two
data views
Here we conduct simulation studies on cooperative learning for more than two data views. Speciﬁcally, we
consider the setting of three data views, and this generalizes easily to more data views. We generated Gaussian
data with n = 200 and p = 300 in each of the views X1, X2 and X3, and created correlation between them
using latent factors. The response y was generated as a linear combination of the latent factors, corrupted by
Gaussian noise.
C.1
Simulation procedure for more than two data views
The simulation for 3 data views is set up as follows.
Given values for parameters n, px1, px2, px3, pu, su, tx1, tx2, tx3, βu, σ, we generate data according to the
26

following procedure:
1. x1j ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , px1.
2. x2j ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , px2.
3. x3j ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , px3.
4. For i = 1, 2, . . . , pu (pu corresponds to the number of latent factors):
(a) ui ∈Rn distributed i.i.d. MVN(0, s2
uIn);
(b) x1i = x1i + tx1 ∗ui;
(c) x2i = x2i + tx2 ∗ui;
(d) x3i = x3i + tx3 ∗ui.
5. X1 = [x11, x12, . . . , x1px1], X2 = [x21, x22, . . . , x2px2], X3 = [x31, x32, . . . , x3px3].
6. U = [u1, u2, . . . , upu], y = Uβu + ϵ where ϵ ∈Rn distributed i.i.d. MVN(0, σ2In).
We compare the following methods: (1) separate X1, separate X2, and separate X3: the standard lasso is
applied on the separate data views of X1, X2 and X3 with 10-fold CV; (2) early fusion: the standard lasso
is applied on the concatenated data views of X1, X2 and X3 with 10-fold CV (note that this is equivalent
to cooperative learning with ρ = 0); (3) late fusion: separate lasso models are ﬁrst ﬁtted on X1, X2 and X3
independently with 10-fold CV, and the three resulting predictors are then combined through linear least squares
for the ﬁnal prediction; (4) cooperative learning (regression) and adaptive cooperative learning.
We evaluated the performance based on the mean-squared error (MSE) on a test set and conducted each
simulation experiment 10 times.
C.2
Simulation results for more than two data views
Figure 12 and 13 show the simulation results for 3 data views. Overall, the simulation results can be summarized
as follows:
• Cooperative learning performs the best in terms of test MSE across the range of SNR and correlation
settings. It is most helpful when the data views are correlated and contain signal (as in Figure 12A and
Figure 13A). When the correlation between data views is higher, higher values of ρ are more likely to be
selected.
• When only two data views are correlated and contain signal (as in Figure 12B and Figure 13C), cooperative
learning also gives performance gains by leveraging the correlation through the agreement penalty, while
early fusion can be outperformed by the separate models ﬁt on the data views containing the signal.
• When only one view contains signal and the views are not correlated (as in Figure 12C), cooperative learn-
ing is outperformed by the separate model ﬁt on the view containing the signal, but adaptive cooperative
learning is able to perform on par with the separate model, outperforming early and late fusion.
27

A
B
C
Figure 12: Simulation studies on cooperative regularized linear regression for more than two data views. (A) Simulation results
when X1, X2 and X3 are correlated and all contain signal (tx1 = tx2 = tx3 = 2), n = 200, p = 900, SNR = 1.5. The ﬁrst panel
shows MSE on a test set; the second panel shows the MSE diﬀerence on the test set relative to early fusion; the third panel shows
the number of features selected; the fourth panel shows the ρ values selected by CV in cooperative learning. Here “Coop” refers
to cooperative learning outlined in Algorithm 1 and “Adap Coop” refers to adaptive cooperative learning outlined in Algorithm
4. (B) Simulation results when only X1 and X2 are correlated and contain signal (tx1 = tx2 = 2, tx3 = 0), n = 200, p = 900,
SNR = 1.5. (C) Simulation results when X1, X2 and X3 are uncorrelated, and only X1 contains signal (tx1 = 2, tx2 = tx3 = 0),
n = 200, p = 900, SNR = 1.5.
28

A
B
C
Figure 13: Simulation studies on cooperative regularized linear regression for more than two data views. (A) Simulation results
when X1, X2 and X3 are correlated and all contain signal (tx1 = tx2 = tx3 = 2), n = 200, p = 900, SNR = 2.5. The ﬁrst panel
shows MSE on a test set; the second panel shows the MSE diﬀerence on the test set relative to early fusion; the third panel shows
the number of features selected; the fourth panel shows the ρ values selected by CV in cooperative learning. Here “Coop” refers
to cooperative learning outlined in Algorithm 1 and “Adap Coop” refers to adaptive cooperative learning outlined in Algorithm 4.
(B) Simulation results when X1, X2 and X3 are correlated and all contain signal (tx1 = tx2 = tx3 = 2), n = 200, p = 900, SNR
= 0.6. (c) Simulation results when only X1 and X3 are correlated; X1 contains more signal than X3, X2 does not contain signal
(tx1 = 2, tx2 = 0, tx3 = 1.5), n = 200, p = 900, SNR = 1.0.
29

D
Theoretical analysis under the factor model
To understand the role of the agreement penalty from a theoretical perspective, we consider the following latent
factor model.
Let u = (U1, U2, . . . , Un) be a vector of n i.i.d.
random variables with Ui ∼N(0, 1).
Let
y = (Y1, . . . , Yn), x = (X1, . . . , Xn), and z = (Z1, . . . , Zn), with
Yi = γyUi + εyi,
Xi = γxUi + εxi,
and
Zi = γzUi + εzi,
(28)
where εyi ∼N
 0, σ2
y

, εxi ∼N
 0, σ2
x

, εzi ∼N
 0, σ2
z

independently.
In this section, we study the mean squared error (MSE) of the cooperative learning algorithm. More precisely,
let
ˆθ = argminθ
n
X
i=1
1
2 (Yi −Xiθx −Ziθz)2 + ρ
2 (Xiθx −Ziθz)2

.
(29)
Let Unew, Xnew, Ynew, Znew be some new random variables generated from (28) independently of the previous
data, i.e.,
Ynew = γyUnew + εy new,
Xnew = γxUnew + εx new,
and
Znew = γzUnew + εz new,
(30)
where Unew ∼N(0, 1), εy new ∼N
 0, σ2
y

, εx new ∼N
 0, σ2
x

, εz new ∼N
 0, σ2
z

independently. We focus on
the MSE conditioning on x and z:
MSE(x, z; ρ) = E

Ynew −

Xnewˆθx + Znewˆθz
2
| x, z

.
(31)
The case of ρ = 0 corresponds to the linear regression with no agreement penalty. We will study the behavior
of MSE(x, z; ρ) when ρ is around 0.
Proposition 1. The derivative of MSE(x, z; ρ) satisﬁes
d
dρ [MSE(x, z; ρ)] |ρ=0 = σ⋆2(C2B1 −2C1B2)/C3
2,
(32)
where
σ⋆2 =
γ2
y
1 + γ2x/σ2x + γ2z/σ2z
+ σ2
y,
C1 =

(γ2
x + σ2
x)(z
Tz) + (γ2
z + σ2
z)(x
Tx) −2γxγz(x
Tz)

((x
Tx)(z
Tz) −(x
Tz)2),
B1 = 2

(γ2
x + σ2
x)(z
Tz) + (γ2
z + σ2
z)(x
Tx) + 2γxγz(x
Tz)

((x
Tx)(z
Tz) −(x
Tz)2),
C2 = (x
Tx)(z
Tz) −(x
Tz)2,
B2 = 2
 (x
Tx)(z
Tz) + (x
Tz)2
.
(33)
Proposition 2. The derivative of MSE(x, z; ρ) at ρ = 0 satisﬁes
d
dρ [MSE(x, z; ρ)] |ρ=0 = −4
n

1 +
2γ2
xγ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z
  
σ2
y +
γ2
yσ2
xσ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z
!
+ Op

n−3
2

.
(34)
Here the notation Op(·) is used with the following meaning: Xn = Op (an) as n →∞means that for any ε > 0,
there exists a ﬁnite M > 0 and a ﬁnite N > 0 such that P [|Xn/an| > M] < ε, ∀n > N.
30

The proposition establishes that the MSE is a decreasing function of ρ around 0 with high probability. In
other words, the agreement penalty is helpful in reducing the mean squared error. To further interpret the
above results, we study the ratio of the derivative to the MSE itself.
Proposition 3. The ratio of the derivative of MSE(x, z; ρ) at ρ = 0 and MSE(x, z; 0) satisﬁes
d
dρ [MSE(x, z; ρ)] |ρ=0
MSE(x, z; 0)
= −4
n

1 +
2γ2
xγ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z

+ Op

n−3
2

.
(35)
Here the notation Op(·) is used with the same meaning as in Proposition 2.
Proposition 3 presents a simple form of the ratio of the derivative to the MSE itself. The ratio quantiﬁes
by what percentage the “agreement” penalty decreases the MSE. It can been seen from this representation that
this ratio depends on the structure of the factor model, and that the agreement penalty is more helpful when
the sample size n is smaller. In the extreme case, when we have inﬁnite data, i.e., when n = ∞, the derivative
of the MSE is 0; in this case, we learn all the signals from the data even without the agreement penalty.
D.1
Proof of Proposition 1
Here we present a lemma that is used in the proof of Proposition 1.
Lemma 1. Assume that c2 > 0. Let g(ρ) = (a1ρ2 + b1ρ + c1)/(a2ρ2 + b2ρ + c2)2, then
g′(ρ)|ρ=0 = b1c2 −2b2c1
c3
2
.
(36)
Proof. We compute the derivative of the function g:
g′(ρ) = (2a1ρ + b1)(a2ρ2 + b2ρ + c2) −2(2a2ρ + b2)(a1ρ2 + b1ρ + c1)
(a2ρ2 + b2ρ + c2)3
.
(37)
Evaluating at ρ = 0, we get
g′(ρ)|ρ=0 = b1c2 −2b2c1
c3
2
.
(38)
With this lemma, we are ready to prove the proposition. We start with writing down an explicit expression
for the estimator ˆθ. Let
˜X =

x
z
−√ρx
√ρz

,
˜y =
y
0

.
(39)
Then (29) implies that ˆθ = (ˆθx, ˆθz)T takes the following form:
ˆθ =

˜X
T ˜X
−1 
˜X
T ˜y

.
(40)
In particular,
˜X
T ˜X =
(1 + ρ)xTx
(1 −ρ)xTz
(1 −ρ)xTz
(1 + ρ)zTz

,
(41)
31

and
˜X
T ˜y = (x
Ty, z
Ty)
T.
(42)
Therefore,
ˆθ =
ˆθx
ˆθz

=

(1 + ρ)xTx
(1 −ρ)xTz
(1 −ρ)xTz
(1 + ρ)zTz
−1 
xTy
zTy

=
1
det

(1 + ρ)zTz
−(1 −ρ)xTz
−(1 −ρ)xTz
(1 + ρ)xTx
 
xTy
zTy

=
1
det
(1 + ρ)(zTz)(xTy) −(1 −ρ)(xTz)(zTy)
(1 + ρ)(xTx)(zTy) −(1 −ρ)(xTz)(xTy)

,
(43)
where det = (1 + ρ)2(xTx)(zTz) −(1 −ρ)2(xTz)2.
We then move on to analyze the conditional distribution of u and y on x and z. By (28), we can write
down a joint distribution of (Ui, Xi, Zi):


Ui
Xi
Zi

∼N




0
0
0

,


1
γx
γz
γx
γ2
x + σ2
x
γxγz
γz
γxγz
γ2
z + σ2
z



.
(44)
Using formulas from conditional distribution of multivariate gaussian, we get that
Ui | Xi, Zi ∼N(E [Ui | Xi, Zi] , Var [Ui | Xi, Zi]),
(45)
where
E [Ui | Xi, Zi] =
 γx
γz
 
γ2
x + σ2
x
γxγz
γxγz
γ2
z + σ2
z
−1 
Xi
Zi

=
1
σ2xσ2z + γ2xσ2z + γ2zσ2x
 γx
γz
 γ2
z + σ2
z
−γxγz
−γxγz
γ2
x + σ2
x
 Xi
Zi

=
γxXi
σ2x + γ2x + γ2zσ2x/σ2z
+
γzZi
σ2z + γ2z + γ2xσ2z/σ2x
,
(46)
and
Var [Ui | Xi, Zi] = 1 −
 γx
γz
 γ2
x + σ2
x
γxγz
γxγz
γ2
z + σ2
z
−1 γx
γz

= 1 −
1
σ2xσ2z + γ2xσ2z + γ2zσ2x
 γx
γz
 γ2
z + σ2
z
−γxγz
−γxγz
γ2
x + σ2
x
 γx
γz

= 1 −
γ2
xσ2
z + γ2
zσ2
x
σ2xσ2z + γ2xσ2z + γ2zσ2x
=
1
1 + γ2x/σ2x + γ2z/σ2z
.
(47)
Since Yi = γyUi + εyi, the above analysis implies that
Yi | Xi, Zi ∼N(E [Yi | Xi, Zi] , Var [Yi | Xi, Zi]),
(48)
where
E [Yi | Xi, Zi] = γyE [Ui | Xi, Zi] =
γxγyXi
σ2x + γ2x + γ2zσ2x/σ2z
+
γzγyZi
σ2z + γ2z + γ2xσ2z/σ2x
,
(49)
and
Var [Yi | Xi, Zi] = γ2
y Var [Ui | Xi, Zi] + σ2
y =
γ2
y
1 + γ2x/σ2x + γ2z/σ2z
+ σ2
y.
(50)
Let
θ⋆
x =
γxγy
σ2x + γ2x + γ2zσ2x/σ2z
,
θ⋆
z =
γzγy
σ2z + γ2z + γ2xσ2z/σ2x
,
σ⋆2 =
γ2
y
1 + γ2x/σ2x + γ2z/σ2z
+ σ2
y,
(51)
32

then the above shows that we can express Yi as
Yi = θ⋆
xXi + θ⋆
zZi + ε⋆
i ,
(52)
where ε⋆
i
|=
(Xi, Zi) and ε⋆
i ∼N(0, σ⋆2). In words, Yi can be decomposed into two independent terms: a linear
combination of Xi and Zi, and an error term independent of (Xi, Zi).
With the above tools, we are ready to study the MSE. Using (52), we can write
MSE(x, z; ρ) = E

Ynew −

Xnewˆθx + Znewˆθz
2
| x, z

= E

θ⋆
xXnew + θ⋆
zZnew + ε⋆
new −

Xnewˆθx + Znewˆθz
2
| x, z

= E

(θ⋆
x −ˆθx)Xnew + (θ⋆
z −ˆθz)Znew + ε⋆
new
2
| x, z

= E

(θ⋆
x −ˆθx)Xnew + (θ⋆
z −ˆθz)Znew
2
| x, z

+ E
h
ε⋆
new
2 | x, z
i
= E

(θ⋆
x −ˆθx)Xnew + (θ⋆
z −ˆθz)Znew
2
| x, z

+ σ⋆2.
(53)
Here the cross terms vanish because ε⋆
new
|=
(Xnew, Znew). Since the new dataset is independent of the training
dataset, we can further simply the above:
MSE(x, z; ρ) = E

(θ⋆
x −ˆθx)Xnew
2
| x, z

+ E

(θ⋆
z −ˆθz)Znew
2
| x, z

+ 2E
h
θ⋆
z −ˆθz
 
ˆθx −θ⋆
x

ZnewXnew | x, z
i
+ σ⋆2
= E

ˆθx −θ⋆
x
2
| x, z

E

X2
new

+ E

ˆθz −θ⋆
z
2
| x, z

E

Z2
new

+ 2E
h
ˆθz −θ⋆
z
 
ˆθx −θ⋆
x

| x, z
i
E [ZnewXnew] + σ⋆2
= E

ˆθx −θ⋆
x
2
| x, z

(γ2
x + σ2
x) + E

ˆθz −θ⋆
z
2
| x, z
  γ2
z + σ2
z

+ 2E
h
ˆθz −θ⋆
z
 
ˆθx −θ⋆
x

| x, z
i
(γxγz) + σ⋆2.
(54)
We can then further decompose the terms into squared bias plus variance.
MSE(x, z; ρ) = E
h
ˆθx −θ⋆
x | x, z
i2
(γ2
x + σ2
x) + Var
h
ˆθx | x, z
i
(γ2
x + σ2
x)
+ E
h
ˆθz −θ⋆
z | x, z
i2  γ2
z + σ2
z

+ Var
h
ˆθz | x, z
i  γ2
z + σ2
z

+ 2E
h
ˆθz −θ⋆
z | x, z
i
E
h
ˆθx −θ⋆
x | x, z
i
(γxγz) + 2 Cov
h
ˆθz, ˆθx | x, z
i
(γxγz) + σ⋆2
= B2(x, z; ρ) + V (x, z; ρ) + σ⋆2,
(55)
where B2(x, z; ρ) = E
h
ˆθx −θ⋆
x | x, z
i2
(γ2
x+σ2
x)+E
h
ˆθz −θ⋆
z | x, z
i2  γ2
z + σ2
z

+2E
h
ˆθz −θ⋆
z | x, z
i
E
h
ˆθx −θ⋆
x | x, z
i
(γxγz)
and V (x, z; ρ) = Var
h
ˆθx | x, z
i
(γ2
x + σ2
x) + Var
h
ˆθz | x, z
i  γ2
z + σ2
z

+ 2 Cov
h
ˆθz, ˆθx | x, z
i
(γxγz) are the sum
of bias related terms and the sum of variance related terms, respectively.
33

We can then use (48) - (50) to study the bias and variance of the estimators ˆθx and ˆθz. We start with the
bias. By (52), we have E [y | x, z] = θ⋆
xx + θ⋆
zz. Therefore,
E
h
ˆθx | x, z
i
= E
 1
det ((1 + ρ)(z
Tz)(x
Ty) −(1 −ρ)(x
Tz)(z
Ty)) | x, z

=
1
det ((1 + ρ)(z
Tz)(x
TE [y | x, z]) −(1 −ρ)(x
Tz)(z
TE [y | x, z]))
=
1
det ((1 + ρ)(z
Tz)(x
T (θ⋆
xx + θ⋆
zz)) −(1 −ρ)(x
Tz)(z
T (θ⋆
xx + θ⋆
zz)))
=
1
det
 (1 + ρ) [θ⋆
x(x
Tx)(z
Tz) + θ⋆
z(z
Tz)(x
Tz)] −(1 −ρ)

θ⋆
x(x
Tz)2 + θ⋆
z(x
Tz)(z
Tz)

=
1
det
 θ⋆
x

(x
Tx)(z
Tz) −(x
Tz)2
+ ρ
 θ⋆
x

(z
Tz)(x
Tx) + (x
Tz)2
+ 2θ⋆
z(x
Tz)(z
Tz)

.
(56)
Note that
det = (1 + ρ)2(x
Tx)(z
Tz) −(1 −ρ)2(x
Tz)2
= (x
Tx)(z
Tz) −(x
Tz)2 + 2ρ

(x
Tx)(z
Tz) + (x
Tz)2
+ ρ2 
(x
Tx)(z
Tz) −(x
Tz)2
.
(57)
Therefore,
E
h
ˆθx −θ⋆
x | x, z
i
= θ⋆
x

(xTx)(zTz) −(xTz)2
+ ρ
 θ⋆
x

(zTz)(xTx) + (xTz)2
+ 2θ⋆
z(xTz)(zTz)

(xTx)(zTz) −(xTz)2 + 2ρ [(xTx)(zTz) + (xTz)2] + ρ2 [(xTx)(zTz) −(xTz)2] −θ⋆
x
= ρ
 θ⋆
x

−(zTz)(xTx) −(xTz)2
+ 2θ⋆
z(xTz)(zTz)

−ρ2θ⋆
x

(xTx)(zTz) −(xTz)2
(xTx)(zTz) −(xTz)2 + 2ρ [(xTx)(zTz) + (xTz)2] + ρ2 [(xTx)(zTz) −(xTz)2]
=
b1ρ + a1ρ2
c2 + b2ρ + a2ρ2 ,
(58)
where b1, a1, c2, b2, a2 are expressions depending on x and z but not on ρ. We can then clearly see that when
ρ = 0, E
h
ˆθx −θ⋆
x | x, z
i
= 0. By symmetry, we have the same property for E
h
ˆθz −θ⋆
z | x, z
i
. Therefore,
d
dρB2(x, z; ρ) = (γ2
x + σ2
x) d
dρE
h
ˆθx −θ⋆
x | x, z
i2
|ρ=0 +
 γ2
z + σ2
z
 d
dρE
h
ˆθz −θ⋆
z | x, z
i2
|ρ=0
+ 2 (γxγz) d
dρ

E
h
ˆθz −θ⋆
z | x, z
i
E
h
ˆθx −θ⋆
x | x, z
i
|ρ=0
= 2(γ2
x + σ2
x)

E
h
ˆθx −θ⋆
x | x, z
i
|ρ=0
 d
dρE
h
ˆθx −θ⋆
x | x, z
i
|ρ=0
+ 2
 γ2
z + σ2
z
 
E
h
ˆθz −θ⋆
z | x, z
i
|ρ=0
 d
dρE
h
ˆθz −θ⋆
z | x, z
i
|ρ=0
+ 2 (γxγz)

E
h
ˆθz −θ⋆
z | x, z
i
|ρ=0
 d
dρE
h
ˆθx −θ⋆
x | x, z
i
|ρ=0
+ 2 (γxγz)

E
h
ˆθx −θ⋆
x | x, z
i
|ρ=0
 d
dρE
h
ˆθz −θ⋆
z | x, z
i
|ρ=0.
(59)
Since E
h
ˆθx −θ⋆
x | x, z
i
|ρ=0 = E
h
ˆθz −θ⋆
z | x, z
i
|ρ=0 = 0, we have
d
dρB2(x, z; ρ) = 0.
(60)
34

It remains to study
d
dρV (x, z; ρ). From the form of ˆθx, we can get that
Var
h
ˆθx | x, z
i
= σ⋆2
det2 ∥(1 + ρ)(z
Tz)x −(1 −ρ)(x
Tz)z∥2
2
= σ⋆2
det2

(1 + ρ)2(z
Tz)2(x
Tx) + (1 −ρ)2(x
Tz)2(z
Tz) −2(1 + ρ)(1 −ρ)(x
Tz)2(z
Tz)

= σ⋆2(zTz)
det2
 
(x
Tx)(z
Tz) −(x
Tz)2
+ 2

(x
Tx)(z
Tz) −(x
Tz)2
ρ + av1ρ2
,
(61)
for some av1 depending on x and z but not on ρ. Similarly, we get that
Var
h
ˆθz | x, z
i
= σ⋆2(xTx)
det2
 
(x
Tx)(z
Tz) −(x
Tz)2
+ 2

(x
Tx)(z
Tz) −(x
Tz)2
ρ + av2ρ2
,
(62)
for some av2 depending on x and z but not on ρ. For the covariance term,
Cov
h
ˆθx, ˆθz | x, z
i
= σ⋆2
det2 [(1 + ρ)(z
Tz)x −(1 −ρ)(x
Tz)z]
T [(1 + ρ)(x
Tx)z −(1 −ρ)(z
Tx)x]
= σ⋆2
det2
 (−1 + 3ρ)(1 + ρ)(x
Tx)(z
Tz)(x
Tz) + (1 −ρ)2(x
Tz)3
= σ⋆2(xTz)
det2
 −

(x
Tx)(z
Tz) −(x
Tz)2
+ 2

(x
Tx)(z
Tz) −(x
Tz)2
ρ + av3ρ2
,
(63)
for some av3 depending on x and z but not on ρ. Combining the three terms, we get
V (x, z; ρ) = Var
h
ˆθx | x, z
i
(γ2
x + σ2
x) + Var
h
ˆθz | x, z
i  γ2
z + σ2
z

+ Cov
h
ˆθz, ˆθx | x, z
i
(γxγz)
= σ⋆2 C1 + B1ρ + A1ρ2
det2
= σ⋆2 C1 + B1ρ + A1ρ2
(C2 + B2ρ + A2ρ2)2 ,
(64)
where
C1 =

(γ2
x + σ2
x)(z
Tz) + (γ2
z + σ2
z)(x
Tx) −2γxγz(x
Tz)

((x
Tx)(z
Tz) −(x
Tz)2),
B1 = 2

(γ2
x + σ2
x)(z
Tz) + (γ2
z + σ2
z)(x
Tx) + 2γxγz(x
Tz)

((x
Tx)(z
Tz) −(x
Tz)2),
C2 = (x
Tx)(z
Tz) −(x
Tz)2,
B2 = 2
 (x
Tx)(z
Tz) + (x
Tz)2
.
(65)
By Lemma 1,
d
dρV (x, z; ρ)|ρ=0 = σ⋆2(C2B1 −2C1B2)/C3
2.
Finally by (55)
d
dρ MSE(x, z; ρ)|ρ=0 = d
dρB2(x, z; ρ)|ρ=0 + d
dρV (x, z; ρ)|ρ=0
= d
dρV (x, z; ρ)|ρ=0 = σ⋆2(C2B1 −2C1B2)/C3
2.
(66)
D.2
Proof of Proposition 2
By the central limit theorem, we have that
x
Tx = n
 γ2
x + σ2
x

+ Op
 √n

,
z
Tz = n
 γ2
z + σ2
z

+ Op
 √n

,
x
Tz = n (γxγz) + Op
 √n

.
(67)
35

Plugging into (33) gives
C1 = 2n3 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
2 + Op

n5/2
,
B1 = 4n3 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z

+ Op

n5/2
,
C2 = n2 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z

+ Op

n3/2
,
B2 = 2n2 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z

+ Op

n3/2
.
(68)
Thus we have that
C1B2 = 4n5 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
2 + Op

n9/2
,
C2B1 = 4n5 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
2 + Op

n9/2
.
(69)
Therefore,
C2B1 −2C1B2 = −4n5 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
2 + Op

n9/2
.
(70)
Now we also know that
C3
2 = n6 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
3 + Op

n11/2
.
(71)
Hence
d
dρ [MSE(x, z; ρ)] |ρ=0
= σ⋆2(C2B1 −2C1B2)/C3
2
= −4n5 
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
 
(γ2
x + σ2
x)(γ2
z + σ2
z) −γ2
xγ2
z
2
n6 [(γ2x + σ2x)(γ2z + σ2z) −γ2xγ2z]3
σ⋆2 + Op

n−3/2
= −4
n
(γ2
x + σ2
x)(γ2
z + σ2
z) + γ2
xγ2
z
(γ2x + σ2x)(γ2z + σ2z) −γ2xγ2z
σ⋆2 + Op

n−3/2
= −4
n

1 +
2γ2
xγ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z

σ⋆2 + Op

n−3/2
= −4
n

1 +
2γ2
xγ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z
  
σ2
y +
γ2
yσ2
xσ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z
!
+ Op

n−3/2
.
(72)
D.3
Proof of Proposition 3
For MSE(x, z; 0), we have that by (55),
MSE(x, z; 0) = B2(x, z; 0) + V (x, z; 0) + σ⋆2 = V (x, z; 0) + σ⋆2.
(73)
Here we make use of the fact that when ρ = 0, E
h
ˆθx −θ⋆
x | x, z
i
= E
h
ˆθz −θ⋆
z | x, z
i
= 0 and that B2(x, z; 0) =
0. For V (x, z; 0), we have that by (64) and (67),
V (x, z; 0) = σ⋆2 C1
C2
2
= 4σ⋆2
n
+ Op

n−3/2
= Op
 1
n

.
(74)
36

Therefore,
MSE(x, z; 0) = V (x, z; 0) + σ⋆2 = σ⋆2 + Op
 1
n

.
(75)
Thus, together with the result in Proposition 2, we have
d
dρ [MSE(x, z; ρ)] |ρ=0
MSE(x, z; 0)
= −4
n

1 +
2γ2
xγ2
z
σ2xγ2z + σ2zγ2x + σ2xσ2z

+ Op

n−3
2

.
(76)
E
Distribution of predicted versus true time to delivery for the labor
onset prediction example
We show in Figure 14 the distribution of predicted and true time to delivery for each patient, which gives a
better sense of the quality of the predictions for the regression task. The left plot shows the distribution of time
to delivery for all patients at their ﬁrst time points in the longitudinal study; the right plot shows the predicted
versus true time to delivery for the training and test samples. This is based on one random split of the training
and test sets of 40 and 13 patients, respectively.
Distribution of Time to Delivery
Time to Delivery (days)
Counts
−100
−80
−60
−40
−20
0
1
2
3
4
5
6
7
−100
−80
−60
−40
−20
−100
−80
−60
−40
−20
Predicted vs. True Time to Delivery
Time to Delivery (days)
Prediction (days)
Training Sample
Test Sample
Figure 14: Distribution of time to delivery and predicted versus true time to delivery for training and test samples. The predictions
were derived from cooperative learning.
F
Procedure for generating the imaging and “omics” data
Here we outline the detailed procedure for data generation in the simulation study with imaging and “omics”
data in Algorithm 5. The “omics” data (X), imaging data (Z), and the response y are generated such that
there are correlations between X, Z, and y.
37

Algorithm 5 Simulation procedure for generating the imaging and “omics” data.
Input: Parameters n, px, pu, su, t, σ, βu, Imax, ndim, threshold.
Output: X ∈Rn×px (omics), Z ∈Rn×ndim×ndim×1 (images assuming one color channel), y ∈Rn.
1. xj ∈Rn distributed i.i.d. MVN(0, In) for j = 1, 2, . . . , px
2. For i = 1, 2, . . . , pu (pu < px, where pu corresponds to the number of factors):
(a) ui ∈Rn distributed i.i.d. MVN(0, s2
uIn)
(b) xi = xi + t ∗ui
3. U = [u1, u2, . . . , upu], X = [x1, x2, . . . , xpx]
4. yu = Uβu + ϵ where ϵ ∈Rn distributed i.i.d. MVN(0, σ2In)
5. For i = 1, 2, . . . , n:
(a) Pi =
1
1+exp(yui), yi ∼Bernoulli(Pi)
(b) Generate a 2D pixel matrix of image Zi ∈Rdim×dim×1
(c) Generate a polygon PGi inside Zi, deﬁned by 4 vertices [v1, v2, v3, v4] on the axes, i.e. v1 = [0, a1], v2 =
[0, a2], v3 = [a3, 0], v4 = [a4, 0], where a1 ∼Unif( ndim
2
, ndim), a2 ∼Unif(−ndim, −ndim
2
), a3 ∼
Unif( ndim
2
, ndim), a4 ∼Unif(−ndim, −ndim
2
)
(d) Randomly sample points from Zi: if the point [x′, y′] falls inside the polygon PGi, i.e. [x′, y′] ∈PGi,
then Zi[x′, y′] ∼Unif(0, 1)
(e) If yi = 1, Idisease = Imax × yui, where Imax is the maximum intensity of pixel values for images,
• For x′ = 1, 2, . . . , ndim:
– For y′ = 1, 2, . . . , ndim:
∗P(x′, y′) ∼Unif(0, 1)
∗If [x′, y′] ∈PGi and P(x′, y′) < threshold, Zi[x′, y′] = Idisease
38

