NAS-X: Neural Adaptive Smoothing via Twisting
Dieterich Lawson∗, Michael Y. Li∗, Scott W. Linderman
{jdlawson, michaelyli, scott.linderman}@stanford.edu
Stanford University
August 30, 2023
Abstract
We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning
and inference in sequential latent variable models based on reweighted wake-sleep (RWS).
NAS-X works with both discrete and continuous latent variables, and leverages smoothing
SMC to fit a broader range of models than traditional RWS methods. We test NAS-X
on discrete and continuous tasks and find that it substantially outperforms previous
variational and RWS-based methods in inference and parameter recovery.
1
Introduction
Sequential latent variable models are an important class of models that include sequential
variational autoencoders [1–5], financial volatility models [6], and biophysical models of
neural activity [7]. Both inference and model learning in nonlinear latent variable models are
analytically intractable, and approximate approaches that ignore structure in the problem
can scale poorly with sequence length.
One common approach for inference in these models is Sequential Monte Carlo (SMC),
which produces a weighted particle approximation to the true posterior and an unbiased
estimator of the marginal likelihood. SMC is often used as a substep within a broader model
learning algorithm like Particle EM, which uses SMC’s particle approximations within a
Expectation-Maximization framework [8]. On the other hand, gradient-based variational
inference (VI) methods perform model learning by performing stochastic gradient ascent on
SMC’s lower bound on the log marginal likelihood [9–12].
As with standard importance sampling, the choice of proposal within SMC is crucial.
There are two main options for proposal learning. One option, adopted by VI-based methods,
is to perform stochastic gradient ascent on the SMC bound with respect to the proposal
parameters in addition to the model parameters. On the other hand, Reweighted Wake
Sleep (RWS) methods minimize the inclusive KL divergence with respect to the proposal
parameters, using Monte Carlo gradient estimates [13, 14].
Previous approaches for model and proposal learning with SMC have important lim-
itations. VI-based methods are challenging to apply to discrete latent variable models
∗Equal contribution.
1
arXiv:2308.14864v1  [cs.LG]  28 Aug 2023

because they require differentiating through the proposal’s discrete sampling operations,
whereas RWS-based methods can be directly applied since the proposal is optimized using the
inclusive KL [15, 16] . On the other hand, RWS based methods like Neural Adaptive SMC
(NASMC) [13] can suffer from high variance estimates due to particle degeneracy, whereas
recent VI-based methods like SIXO [12] avoid these issues by leveraging smoothing SMC.
We introduce Neural Adaptive Smoothing via Twisting (NAS-X), a new approach for
model learning and inference in sequential latent variable models, that combines the techniques
of previous VI and RWS based approaches. In short, NAS-X extends RWS to the sequential
setting by using smoothing SMC to approximate intractable posterior expectations. NAS-X
can be viewed as an RWS-based alternative to SIXO, a recent VI based method that uses
smoothing SMC [12]. We thoroughly evaluate NAS-X on a range of experiments including
model learning and inference in discrete latent variable models as well as ODE-based
mechanistic models of neural dynamics.
2
Background
This work considers model learning and inference in nonlinear sequential latent variable
models with Markovian structure; i.e. models that factor as
pθ(x1:T , y1:T ) = pθ(x1)pθ(y1 | x1)
T
Y
t=2
pθ(xt | xt−1)pθ(yt | xt),
(1)
with latent variables x1:T ∈X T , observations y1:T ∈YT , and global parameters θ ∈Θ.
By nonlinear, we mean the conditional distributions pθ(xt | xt−1) and pθ(yt | xt) depend
nonlinearly on xt−1 and xt, respectively.
Estimating the marginal likelihood pθ(y1:T ) and posterior pθ(x1:T | y1:T ) for this model
class is difficult because it requires computing an intractable integral over the latents,
pθ(y1:T ) =
Z
X T pθ(y1:T , x1:T ) dx1:T ,
We begin by introducing two algorithms, Reweighted Wake Sleep (RWS) [14, 17] and
smoothing sequential Monte Carlo [12], that are crucial for understanding our approach.
2.1
Reweighted Wake Sleep
Our goal is to fit a model pθ by maximizing the marginal likelihood. RWS uses a two-step
coordinate ascent method to accomplish this. First, RWS estimates the gradients of the
log marginal likelihood using self-normalized importance sampling (SNIS) with a proposal
distribution qϕ. Second, to improve the quality of those gradient estimates, RWS optimizes
the proposal qϕ by minimizing the inclusive Kullback-Leibler (KL) divergence from the
posterior to the proposal which RWS also estimates with SNIS. Importantly, the gradients
for both steps can be written as posterior expectations, which RWS estimates using an SNIS
particle approximation to the true posterior.
2

Let qϕ(x1:T | y1:T ) be a proposal distribution. RWS approximates the posterior distribu-
tion pθ(x1:T | y1:T ) with N weighted particles sampled from qϕ,
ˆp(x1:T | y1:T ) =
N
X
i=1
w(i)δx(i)
1:T (x1:T ),
x(i)
1:T ∼qϕ(x1:T | y1:T ),
w(i) = pθ(x(i)
1:T , y1:T )
qϕ(x(i)
1:T | y1:T )
(2)
where w(i) are unnormalized weights formed from a ratio of likelihoods and w(i) are their
self-normalized counterparts; i.e., PN
i=1 w(i) = 1.
RWS fits the proposal distribution qϕ by descending estimates of the gradients of the
inclusive KL divergence,
∇ϕKL(pθ || qϕ) = −Epθ(x1:T |y1:T ) [∇ϕ log qϕ(x1:T | y1:T )] ≈−
N
X
i=1
w(i)∇ϕ log qϕ(x(i)
1:T | y1:T ).
(3)
The weighted sum of gradients in eq. 3 is a biased but consistent Monte Carlo estimate of
the expectation as the number of particles goes to infinity [18].
The model pθ is fit using a particle approximation to the gradients of the log marginal
likelihood,
∇θ log pθ(y1:T ) = Epθ(x1:T |y1:T ) [∇θ log pθ(x1:T , y1:T )] ≈
N
X
i=1
w(i)∇θ log pθ(x(i)
1:T , y1:T ).
(4)
For a derivation of these identities, see the Appendix.
2.2
Estimating Posterior Expectations with Smoothing Sequential Monte
Carlo
As we saw in Equations 3 and 4, key quantities in RWS can be expressed as expectations
under the posterior. Standard RWS uses SNIS to approximate these expectations, but in
sequence models the variance of the SNIS estimator can scale exponentially in the sequence
length. In this section, we review sequential Monte Carlo (SMC) [19, 20], an inference
algorithm that can produce estimators of posterior expectations with linear or even sub-linear
variance scaling.
SMC approximates the posterior pθ(x1:T | y1:T ) with a set of N weighted particles x1:N
1:T
constructed by sampling from a sequence of target distributions {πt(x1:t)}T
t=1. Since these
intermediate targets are often only known up to some unknown normalizing constant Zt, SMC
uses the unnormalized targets {γt(x1:t)}T
t=1, where πt(x1:t) = γt(x1:t)/Zt. Provided mild
technical conditions are met and γT (x1:T ) ∝pθ(x1:T , y1:T ), SMC returns weighted particles
that approximate the posterior pθ(x1:T | y1:T ) [19, 20]. These weighted particles can be
used to compute biased but consistent estimates of expectations under the posterior, similar
to SNIS.
SMC repeats three steps. First, sample latents x1:N
1:t from a proposal distribution qϕ(x1:t |
y1:T ). Then, weight each particle using the unnormalized target γt to form an empirical
approximation to the normalized target distribution πt. Finally, draw new particles x1:N
1:t
3

from this approximation in the resampling step. By sampling away latent trajectories with
low weight and focusing on promising particles, SMC can produce lower variance estimates
than SNIS. For a thorough review of SMC, see Doucet and Johansen [19], Naesseth et al.
[20], and Del Moral [21].
The most common choice of targets are the filtering distributions πt(x1:t) = pθ(x1:t | y1:t),
and when SMC is run with these distributions as targets the resulting algorithm is known
as filtering SMC. Filtering SMC has been used to estimate posterior expectations within
the RWS framework in Neural Adaptive Sequential Monte Carlo (NASMC) [13], but a
major disadvantage of filtering SMC is that it ignores future observations yt+1:T . Ignoring
future observations can lead to particle degeneracy and high-variance estimates of test
function integrals, frustrating approaches that use filtering SMC for model learning and
inference [9, 22, 23].
We could avoid these issues by using the smoothing distributions as targets, setting
πt(x1:t) = pθ(x1:t | y1:T ), but unfortunately the smoothing distributions are not available from
the model. We can approximate the smoothing distributions by observing that pθ(x1:t, y1:T )
is proportional to the filtering distributions, pθ(x1:t, y1:t), times the lookahead distribu-
tions, pθ(yt+1:T | xt). If the lookahead distributions are well-approximated by a sequence of
twists {r(yt+1:T , xt)}T
t=1, then running SMC with targets γt(x1:t) = pθ(x1:t, y1:t) r(yt+1:T , xt)
approximates smoothing SMC [22].
Learning the twists can be extremely challenging [9, 11, 24]. To tackle these challenges,
SIXO [12] leverages a density-ratio estimation approach [25]. This method is motivated by
the observation that the lookahead distribution is proportional to a ratio of densities,
pθ(yt+1:T | xt) = pθ(xt | yt+1:T ) pθ(yt+1:T )
pθ(xt)
∝pθ(xt | yt+1:T )
pθ(xt)
.
(5)
Therefore, the logits of a classifier trained to distinguish between samples from these densities
will approximate the twists. We summarize the process for training twists below.
˜x1:T ∼pθ(x1:T ),
x1:T , y1:T ∼pθ(x1:T , y1:T )
LDRE(ψ) =
1
T −1
T−1
X
t=1
log σ(log rψ(yt+1:T , xt)) + log(1 −σ(log rψ(yt+1:T , ˜xt)))
(6)
Importantly, SIXO returns a sequence of particle approximations that approximate the
smoothing distributions, a crucial fact we will leverage in NAS-X.
3
NAS-X: Neural Adaptive Smoothing via Twisting
NAS-X uses SIXO’s sequence of particle approximations of the smoothing distributions,
ˆp(x1:t | y1:T ) =
N
X
i=1
w(i)
t δx(i)
1:t(x1:t),
t = 1, . . . , T
(7)
4

to estimate the posterior expectations required by the RWS framework. Specifically, NAS-X
computes the gradients of the inclusive KL divergence for learning the proposal qϕ as
−Ep(x1:T |y1:T ) [∇ϕ log qϕ(x1:T | y1:T )] ≈−
T
X
t=1
N
X
i=1
w(i)
t ∇ϕ log qϕ(x(i)
t
| x(i)
t−1, yt:T )
(8)
and computes the gradients of the model as
Epθ(x1:T |y1:T ) [∇θ log pθ(x1:T , y1:T )] ≈
T
X
t=1
N
X
i=1
w(i)
t ∇θ log pθ(x(i)
t , yt | x(i)
t−1).
(9)
The particle weights w(i)
t
are directly available from running SMC with the twists.
The full procedure is summarized in Algorithm 1. We train a twisting function rψ
using density ratio estimation with samples drawn from the current model pθ. We then
run approximate smoothing SMC with the current model parameters pθ and the current
twist rψ to obtain a sequence of particle approximations to the smoothing distributions as in
eq. (7). We then use this sequence of particle approximations to update qϕ via eq. (8) and
(optionally) pθ via eq. (9).
Algorithm 1: NAS-X
Procedure NAS-X(θ0, ϕ0, ψ0, y1:T )
while not converged do
ψ ←tilt-training(θ, ψ)
x1:N
1:T , w1:N
1:T ←SMC({pθ(x1:t, y1:t), rψ(xt, yt+1:T )}T
t=1)
∆θ = PT
t=1
PN
i=1 w(i)
t ∇θ log pθ(x(i)
t , yt | x(i)
t−1)
∆ϕ = −PT
t=1
PN
i=1 w(i)
t ∇ϕ log qϕ(x(i)
t
| x(i)
t−1, yt:T )
θ = grad-step(θ, ∆θ)
ϕ = grad-step(ϕ, ∆ϕ)
end
return θ′, ϕ′
4
Related Work
VI Methods
There is a large literature on model learning via stochastic gradient ascent
on an evidence lower bound (ELBO) [26, 27, 2, 28]. Subsequent works have considered
surrogate objectives defined by the normalizing constant estimates from multiple importance
sampling [29], nested importance sampling, [30, 31], rejection sampling and Hamiltonian
Monte Carlo [4]. Most relevant to our work is the literature that uses SMC’s estimates
of the normalizing constant as a surrogate objective. There are a number of VI methods
that use filtering SMC [9, 10, 32], and smoothing SMC based approaches [11, 33, 34, 12, 23].
Filtering SMC approaches can suffer from particle degeneracy which results in high variance
estimates [11, 12]. To avoid these issues, we adapt SIXO, an approach to smoothing SMC
that uses density ratio estimation for twist learning [12]. These VI methods optimize the
5

proposal using the exclusive KL divergence whereas NAS-X optimizes the proposal using the
inclusive KL divergence.
Reweighted Wake Sleep Methods
The wake-sleep algorithm was introduced in Hinton
et al. [17] as a way to train deep directed graphical models. Bornschein and Bengio [14]
interpreted the wake-sleep algorithm through the lens of self-normalized importance sampling
and proposed reweighted wake-sleep, which uses SNIS to approximate the gradients of the
inclusive KL divergence and log marginal likelihood. Neural Adaptive Sequential Monte
Carlo (NASMC) extends the RWS framework to sequential settings by using SMC to
approximate posterior expectations instead of SNIS, which scales poorly with sequence
length [13]. However, to reduce the variance of filtering SMC’s estimates, NASMC employ
a filtering approximation to the gradient of the inclusive KL divergence, which introduces
bias. In NAS-X, we avoid this issue by learning twist functions and running approximate
smoothing SMC as in SIXO [12].
5
Experiments
The combination of SIXO and RWS confers several distinct advantages that we validate in
our experiments.
• By using the approximate smoothing distributions as targets for proposal learning,
NAS-X can learn proposals that match the true posterior marginals, while NASMC
cannot. We illustrate this in Section 5.1, in a setting where the true posterior is
tractable. We illustrate the practical benefits on inference in nonlinear mechanistic
models in Section 5.3.
• By optimizing the proposal within the RWS framework (e.g., descending the inclusive
KL), NAS-X can handle model learning and inference in discrete latent variables, which
SIXO cannot. We explore this in Section 5.2.
• We explore the practical benefits of this combination in a challenging setting in
Section 5.3, where we show NAS-X can fit ODE-based mechanistic models of neural
dynamics with 38 model parameters and an 18-dimensional latent state.
5.1
Linear Gaussian State Space Model
We first consider a one-dimensional linear Gaussian state space model with joint distribution
p(x1:T , y1:T ) = N(x1; 0, σ2
x)
T
Y
t=2
N(xt+1; xt, σ2
x)
T
Y
t=1
N(yt; xt, σ2
y).
(10)
We compare NAS-X and NASMC by evaluating log marginal likelihood estimates and
recovery of the true posterior. For both methods we use a mean-field Gaussian proposal
factored over time, q(x1:T ) = QT
t=1 qt(xt) = QT
t=1 N(xt; µt, σ2
t ), with parameters µ1:T and
σ2
1:T corresponding to the means and variances at each time-step. We parameterize the twist
6

0
10
20
30
40
50
Model timestep
−4
−2
0
2
4
6
µ value
µ recovery
NAS-X
NASMC
True
0
10
20
30
40
50
Model timestep
0.40
0.45
0.50
0.55
0.60
σ2 value
σ2 recovery
NAS-X
NASMC
True
0
200
400
600
Proposal training steps (1000s)
10−2
10−1
100
101
102
log p(y1:T) −L128
Bound comparison
NAS-X
NASMC
Figure 1: Comparison of NAS-X vs NASMC on Inference in LG-SSM. (left)
Comparison of learned proposal means. (middle) Comparison of learned proposal variances.
(right) Comparison of log-marginal likelihood bounds (lower is better). NAS-X’s learned
proposal captures the true posterior mean and variance and achieves tighter estimates of the
log marginal likelihood.
as a quadratic function in xt whose coefficients are functions of the observations and time
step. We chose this form to match the functional form of the analytic log density ratio.
In the left and middle panels of Figure 1, we compare the posteriors learned by NAS-X
and NASMC against the true posterior which can be obtained in closed form. NASMC’s
learned proposal fails to capture the true posterior distribution because it employs a filtering
approximation, while NAS-X recovers the true posterior. In the right panel of Figure 1, we
compare NAS-X and NASMC’s bound gap, the difference between the true log marginal
likelihood and the estimated log marginal likelihood. NAS-X’s bound gap is lower, indicating
it performs more accurate inference than NASMC. For details see the appendix.
5.2
Switching Linear Dynamical Systems
To explore NAS-X’s ability to handle discrete latent variables, we consider a switching
linear dynamical system (SLDS) model [35, 36]. Specifically, we adapt the recurent SLDS
example from Linderman et al. [36] in which the latent dynamics trace ovals in a manner that
resembles cars racing on a NASCAR track. There are two coupled sets of latent variables: a
discrete state zt, with K = 4 possible values, and a two-dimensional continuous state xt that
follows linear dynamics that depend on zt. The observations are a noisy projection of xt into
a ten-dimensional observation space. There are 1000 observations in total. For model details
see the appendix and [36].
For the proposal, we factor q over both time and the continuous and discrete states. The
continuous distributions are parameterized by Gaussians, and categorical distributions are
used for the discrete latent variables. For details on the proposal and twist, see the appendix.
In the top of Figure 2, we compare NAS-X and NASMC on inference in the SLDS model.
We report (average) posterior parameter recovery for the continuous and discrete latent
states across 5 random samples from the generative model. NAS-X systematically recovers
better estimates of both the discrete and continuous latent states.
We present qualitative results from joint model learning and inference in the bottom
of Figure 2. We compare the learned dynamics for NAS-X, NASMC, and a Laplace-EM
algorithm designed specifically for recurrent state space models [37]. In each panel, we
plot the vector field of the learned dynamics and the posterior means, with different colors
corresponding to the four discrete states. In Table 1, we quantitatively compare the model
7

0
100
200
300
400
500
Proposal training steps (100s)
0.2
0.4
0.6
0.8
1.0
1.2
1.4
zt absolute error
NAS-X, σ2
O = 0.1
NASMC, σ2
O = 0.1
0
100
200
300
400
500
Proposal training steps (100s)
0.2
0.4
0.6
0.8
1.0
xt absolute error
NAS-X, σ2
O = 0.1
NASMC, σ2
O = 0.1
−2
0
2
x1
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
x2
Ground truth
−2
0
2
x1
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
x2
NAS-X
−2
0
2
x1
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
x2
NASMC
−2
0
2
x1
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
x2
Laplace EM
Figure 2: Inference and model learning in switching linear dynamical systems
(SLDS). (top) Posterior parameter recovery in the inference setting. (bottom) Comparison
of learned dynamics and inferred latent states in model learning. Laplace EM sometimes
learns incorrect segmentations, as seen here.
Table 1: Train L1024
BPF for rSLDS.
Method
σ2
O = 0.001
σ2
O = 0.01
σ2
O = 0.1
NAS-X
19.837 ± 0.0234
8.63 ± 0.0015
−2.79 ± 0.0009
NASMC
19.834 ± 0.0018
8.53 ± 0.001
−2.874 ± 0.0007
Laplace EM
19.154 ± 0.057
8.54 ± 0.0039
−2.765 ± 0.0012
RWS
17.148 ± 0.087
6.314 ± 0.023
−5.78 ± 0.0026
learning performances across these three approaches by running a bootstrap proposal with
the learned models and the true dynamics and observation variances. We normalize the
bounds by the sequence length. NAS-X outperforms or performs on par with both NASMC
and Laplace EM across the different observation noises σ2
O.
5.3
Biophysical Models of Neuronal Dynamics
For our final experiment we consider inference and parameter learning in Hodgkin-Huxley
(HH) models [7, 38] — mechanistic models of voltage dynamics in neurons. These models use
systems of coupled nonlinear differential equations to describe the evolution of the voltage
difference across a neuronal membrane as it changes in response to external stimuli such
as injected current. Understanding how voltage propagates throughout a cell is central to
understanding electrical signaling and computation in the brain.
Voltage dynamics are governed by the flow of charged ions across the cell membrane,
which is in turn mediated by the opening and closing of ion channels and pumps. HH models
capture the states of these ion channels as well as the concentrations of ions and the overall
8

voltage, resulting in a complex dynamical system with many free parameters and a high
dimensional latent state space. Model learning and inference in this setting can be extremely
challenging due to the dimensionality, noisy data, and expensive and brittle simulators that
fail for many parameter settings.
Model Description
We give a brief introduction to the models used in this section and
defer a full description to the appendix. We are concerned with modeling the potential
difference across a neuronal cell membrane, v, which changes in response to currents flowing
through a set of ion channels, c ∈C. Each ion channel c has an activation which represents a
percentage of the maximum current that can flow through the channel and is computed as a
nonlinear function gc of the channel state λc, with gc(λc) ∈[0, 1]. This activation specifies
the time-varying conductance of the channel as a fraction of the maximum conductance of
the channel, gc. Altogether, the dynamics for the voltage v can be written as
cm
dv
dt = Iext
S
−
X
c∈C
gcgc(λc)(v −Ecion)
(11)
where cm is the specific membrane capacitance, Iext is the external current applied to the
cell, S is the cell membrane surface area, cion is the ion transported by channel c, and Ecion
is that ion’s reversal potential. In addition to the voltage dynamics, the ion channel states
{λc}c∈C evolve as
dλc
dt = A(v)λc + b(v)
∀c ∈C
(12)
where A(v) and b(v) are nonlinear functions of the membrane potential that produce matrices
and vectors, respectively. Together, equations (11) and (12) define a conditionally linear
system of first-order ordinary differential equations (ODEs), meaning that the voltage
dynamics are linear if the channel states are known and vice-versa.
Following Lawson et al. [12], we augment the deterministic dynamics with zero-mean,
additive Gaussian noise to the voltage v and unconstrained gate states logit(λc) at each
integration time-step. The observations are produced by adding Gaussian noise to the
instantaneous membrane potential.
Proposal and Twist Parameterization
For all models in this section we amortize
proposal and twist learning across datapoints. SIXO and NAS-X proposals used bidirectional
recurrent neural networks (RNNs) [39, 40] with a hidden size of 64 units to process the raw
observations and external current stimuli, and then fed the processed observations, previous
latent state, and a transformer positional encoding [41] into a 64-unit single-layer MLP
that produced the parameters of an isotropic Gaussian distribution over the current latent
state. Twists were similarly parameterized with an RNN run in reverse across observations,
combined with an MLP that accepts the rnn outputs and latent state and produces the twist
values.
Integration via Strang Splitting
The HH ODEs are stiff, meaning they are challenging
to integrate at large step sizes because their state can change rapidly. While small step sizes
9

4
8
16
32
64
128
256
Eval Num Particles
-167
-174
-181
-188
-195
-203
-211
Log-likelihood lower bound
NASMC
SIXO
NAS-X
(a) HH inference performance
across different numbers of par-
ticles. Log-likelihood lower bounds
for proposals trained with 4 parti-
cles and evaluated across a range of
particle numbers. NAS-X is roughly
twice as particle efficient as SIXO,
and outperforms SIXO by roughly
34 nats at 4 particles.
−50
0
50
Voltage (mV)
SIXO
True Voltage
Inferred Voltage
Resampling Event
0
5
10
15
20
25
30
35
40
45
50
Time (ms)
−50
0
50
Voltage (mV)
NAS-X
(b) Inferred voltage traces for SIXO and NAS-X.
(top) SIXO generates a high number of resampling events lead-
ing to particle degeneracy and a single mistimed spike. (bot-
tom) NAS-X perfectly infers the latent voltage with no mist-
imed spikes, and resamples very infrequently. For NASMC’s
traces, see the appendix.
Figure 3: Inference in Mechanistic HH Model
can ensure numerical stability, they also make methods prohibitively slow. For example,
many voltage dynamics of interest unfold over hundreds of milliseconds, which could take
upwards of 40,000 integration steps at the standard 0.005 milliseconds per step. Because
running our models for even 10,000 steps would be too costly, we developed new numerical
integration techniques based on an explicit Strang splitting approach that allowed us to
stably integrate at 0.1 milliseconds per step, a 20-time speedup [42]. For details, see the
appendix.
5.3.1
Hodgkin-Huxley Inference Results
First, we evaluated NAS-X, NASMC, and SIXO in their ability to infer underlying voltages
and channel states from noisy voltage observations. For this task we sampled 10,000 noisy
voltage traces from a probabilistic Hodgkin-Huxley model of the squid giant axon [7], and used
each method to train proposals (and twists for NAS-X and SIXO) to compute the marginal
likelihood assigned to the data under the true model. As in [12], we sampled trajectories
of length 50 milliseconds, with a single noisy voltage observation every millisecond. The
stability of the Strang splitting based ODE integrator allowed us to integrate at dt = 0.1ms,
meaning there were 10 latent states per observation.
In Figure (3a) we plot the performance of proposals and twists trained with 4 particles and
evaluated across a range of particle numbers. All methods perform roughly the same when
evaluated with 256 particles, but with lower numbers of evaluation particles the smoothing
methods emerge as more particle-efficient than the filtering methods. To achieve NAS-X’s
inference performance with 4 particles, NASMC would need 256 particles, a 64x increase,
and NAS-X is also on average 2x more particle-efficient than SIXO.
In Figure 3b we further investigate these results by examining the inferred voltage traces
of NAS-X and SIXO. SIXO accurately infers the timing of most spikes but resamples at
a high rate, which can lead to particle degeneracy and poor bound performance. NAS-X
10

0
20
40
60
80
100
120
140
160
180
200
Time (ms)
True Voltage
SIXO Samples
NAS-X Samples
Method
L32
BPF
# Spikes Err.
Rest Voltage Err.
Cross-Corr.
% Runs Failed
NAS-X
−686.4 ± 6.8
0.76 ± 0.15
2.74 ± 0.1
6258 ± 11
18.9
SIXO
−660.6 ± 4.4
1.88 ± 0.41
1.8 ± 0.2
6055 ± 22
25.2
Figure 4: Model learning in HH model of a mouse pyramidal neuron (top) Samples
drawn from learned models when stimulated with a square pulse of 250 picoamps beginning
at 20 milliseconds (vertical grey dashed line). NAS-X’s samples are noisier than SIXO’s, but
spike more consistently. (bottom) A comparison of NAS-X- and SIXO-trained models along
various evaluation metrics. SIXO’s models achieve higher bounds, but are less stable and
capture overall spike count more poorly than NAS-X-trained models. All errors are absolute
errors. For more metrics and detailed comparisons see the appendix.
correctly infers the voltage across the whole trace with no spurious or mistimed spikes and
almost no resampling events, indicating it has learned a high-quality proposal that does
not generate poor particles that must be resampled away. These qualitative results support
the quantitative results in Figure 3a: SIXO’s high resampling rate and NASMC’s filtering
approach lead to lower bound values.
These results highlight a benefit of RWS-based methods over VI methods: when the model
is correctly specified, it can be beneficial to have a more deterministic proposal. Empirically,
we find that maximizing the variational lower bound encourages the proposal to have high
entropy, which in this case resulted in SIXO’s poorer performance relative to NAS-X. In the
next section, we explore the implications of this on model learning.
5.3.2
Hodgkin-Huxley Model Learning Results
In this section, we assess NAS-X and SIXO’s ability to fit model parameters in a more
complex, biophysically realistic model of a pyramidal neuron from the mouse visual cortex.
This model was taken from the Allen Institute Brain Atlas [43] and includes 9 different
voltage-gated ion channels as well as a calcium pump/buffer subsystem and a calcium-gated
potassium ion channel. In total, the model had 38 free parameters and an 18-dimensional
latent state space, in contrast to the 1 free parameter and 4-dimensional state space of the
11

model considered by Lawson et al. [12]. For full details of the models, see the appendix.
We fit these models to voltage traces gathered from a real mouse neuron by the Allen
Institute, but downsampled and noised the data to simulate a more common voltage imaging
setting. We ran a hyperparameter sweep over learning rates and initial values of the voltage
and observation noise variances (270 hyperparameter settings in all), and selected the best
performing model via early stopping on the train log marginal likelihood lower bound. Each
hyperparameter setting was run for 5 seeds, and each seed was run for 2 days on a single
CPU core with 7 Gb of memory. Because of the inherent instability of these models, many
seeds failed, and we discarded hyperparameter settings with more than 2 failed runs.
In Figure 4 (bottom), we compare NAS-X and SIXO-trained models with respect to test
set log-likelihood lower bounds as well as biophysically relevant metrics. To compute the
biophsyical metrics, we sampled 32 voltage traces for each input stimulus trace in the test set,
and averaged the feature errors over the samples and test set. NAS-X better captures the
number of spikes, an important feature of the traces, and attains a higher cross correlation.
Both methods capture the resting voltage well, although SIXO attains a slightly lower error
and outperforms NAS-X in terms of log-likelihood lower bound.
Finally, we include the percentage of runs that failed for each method. SIXO’s more
entropic proposals more frequently generate biophysically implausible latent states, causing
the ODE integrator to return NaNs. In contrast, fewer of NAS-X’s runs suffer from numerical
instability issues, a great advantage when working with mechanistic models.
6
Conclusion
In this work we presented NAS-X, a new method for model learning and inference in
sequential latent variable models, that generalizes the Reweighted Wake Sleep framework
via approximate smoothing SMC. Our approach involves learning twist functions to use in
smoothing SMC, and then running smoothing SMC to approximate gradients of the log
marginal likelihood with respect to the model parameters and gradients of the inclusive
KL divergence with respect to the proposal parameters. We validated our approach in
three experiments including model learning and inference for discrete latent variable models
and mechanistic models of neural dynamics, demonstrating that NAS-X offers compelling
advantages in many settings.
Acknowledgements
This work was supported in part by the Stanford Data Science
Fellowship, along with grants from the Simons Collaboration on the Global Brain (SCGB
697092), the NIH (U19NS113201, R01NS113119, and R01NS130789), the Sloan Foundation,
the McKnight Foundation, and the Stanford Center for Human and Artificial Intelligence.
We thank Andy Warrington for helpful comments and suggestions.
12

References
[1] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropaga-
tion and approximate inference in deep generative models. In International Conference
on Machine Learning, pages 1278–1286. PMLR, 2014.
[2] Diederik Kingma and Max Welling. Auto-encoding variational Bayes. In 2nd Interna-
tional Conference on Learning Representations, 2014.
[3] Rahul G Krishnan, Uri Shalit, and David Sontag. Deep Kalman filters. arXiv preprint
arXiv:1511.05121, 2015.
[4] Dieterich Lawson, George Tucker, Bo Dai, and Rajesh Ranganath. Energy-inspired
models: Learning with sampler-induced distributions. Advances in Neural Information
Processing Systems, 32, 2019.
[5] Dieterich Lawson, Chung-Cheng Chiu, George Tucker, Colin Raffel, Kevin Swersky, and
Navdeep Jaitly. Learning hard alignments with variational inference. In 2018 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages
5799–5803. IEEE, 2018.
[6] Siddhartha Chib, Yasuhiro Omori, and Manabu Asai. Multivariate stochastic volatility.
In Handbook of Financial Time Series, pages 365–400. Springer, 2009.
[7] Alan L. Hodgkin and Andrew F. Huxley. A quantitative description of membrane current
and its application to conduction and excitation in nerve. The Journal of Physiology,
117(4):500, 1952.
[8] Simo Särkkä. Bayesian filtering and smoothing. Number 3. Cambridge university press,
2013.
[9] Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi,
Andriy Mnih, Arnaud Doucet, and Yee Whye Teh. Filtering variational objectives.
Advances in Neural Information Processing Systems, 30, 2017.
[10] Christian A. Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational
Sequential Monte Carlo. In International Conference on Artificial Intelligence and
Statistics, pages 968–977. PMLR, 2018.
[11] Dieterich Lawson, George Tucker, Christian A. Naesseth, Chris Maddison, Ryan P.
Adams, and Yee Whye Teh. Twisted Variational Sequential Monte Carlo. In Third
workshop on Bayesian Deep Learning (NeurIPS), 2018.
[12] Dieterich Lawson, Allan Raventós, Andrew Warrington, and Scott Linderman. SIXO:
Smoothing Inference with Twisted Objectives. In Alice H. Oh, Alekh Agarwal, Danielle
Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing
Systems, 2022.
[13] Shixiang Shane Gu, Zoubin Ghahramani, and Richard E. Turner. Neural Adaptive
Sequential Monte Carlo. Advances in Neural Information Processing Systems, 28, 2015.
13

[14] Jörg Bornschein and Yoshua Bengio.
Reweighted Wake-Sleep.
arXiv preprint
arXiv:1406.2751, 2014.
[15] Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A
continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712,
2016.
[16] Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with Gumbel-
Softmax. arXiv preprint arXiv:1611.01144, 2016.
[17] Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The “wake-sleep”
algorithm for unsupervised neural networks. Science, 268(5214):1158–1161, 1995.
[18] Art B Owen. Monte Carlo Theory, Methods and Examples. Stanford, 2013.
[19] Arnaud Doucet and Adam M. Johansen. A tutorial on particle filtering and smoothing:
Fifteen years later. In Dan Crisan and Boris Rozovsky, editors, The Oxford Handbook
of Nonlinear Filtering, pages 656–704. Oxford University Press, 2011.
[20] Christian A. Naesseth, Fredrik Lindsten, Thomas B. Schön, et al. Elements of Sequential
Monte Carlo. Foundations and Trends® in Machine Learning, 12(3):307–392, 2019.
[21] Pierre Del Moral. Feynman-Kac formulae: genealogical and interacting particle systems
with applications, volume 88. Springer, 2004.
[22] Nick Whiteley and Anthony Lee. Twisted particle filters. The Annals of Statistics, 42
(1):115–141, 2014.
[23] Mark Briers, Arnaud Doucet, and Simon Maskell. Smoothing algorithms for state–space
models. Annals of the Institute of Statistical Mathematics, 62(1):61–89, 2010.
[24] Pieralberto Guarniero, Adam M. Johansen, and Anthony Lee. The iterated auxiliary
particle filter. Journal of the American Statistical Association, 112(520):1636–1647,
2017.
[25] Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio estimation in
machine learning. Cambridge University Press, 2012.
[26] Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In
International Conference on Artificial Intelligence and Statistics, pages 814–822. PMLR,
2014.
[27] Matthew D. Hoffman, David Blei, Chong Wang, and John Paisley. Stochastic variational
inference. Journal of Machine Learning Research, 2013.
[28] Andriy Mnih and Danilo Rezende. Variational inference for Monte Carlo objectives. In
International Conference on Machine Learning, pages 2188–2196. PMLR, 2016.
[29] Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders.
In 4th International Conference on Learning Representations, 2016.
14

[30] Christian Naesseth, Fredrik Lindsten, and Thomas Schon. Nested Sequential Monte
Carlo Methods. In International Conference on Machine Learning, pages 1292–1301.
PMLR, 2015.
[31] Heiko Zimmermann, Hao Wu, Babak Esmaeili, and Jan-Willem van de Meent. Nested
variational inference. Advances in Neural Information Processing Systems, 34:20423–
20435, 2021.
[32] Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-encoding
Sequential Monte Carlo. In 6th International Conference on Learning Representations,
2018.
[33] Antonio Moretti, Zizhao Wang, Luhuan Wu, Iddo Drori, and Itsik Pe’er. Variational
objectives for Markovian dynamics with backward simulation. In ECAI 2020, pages
1371–1378. IOS Press, 2020.
[34] Antonio Moretti, Zizhao Wang, Luhuan Wu, and Itsik Pe’er. Smoothing nonlinear
variational objectives with sequential Monte Carlo. ICLR Workshop: Deep Generative
Models for Highly Structured Data, 2019.
[35] Emily Fox, Erik Sudderth, Michael Jordan, and Alan Willsky. Nonparametric Bayesian
Learning of Switching Linear Dynamical systems. In D. Koller, D. Schuurmans, Y. Bengio,
and L. Bottou, editors, Advances in Neural Information Processing Systems, volume 21.
Curran Associates, Inc., 2008.
[36] Scott W. Linderman, Matthew J. Johnson, Andrew C. Miller, Ryan P. Adams, David M.
Blei, and Liam Paninski. Bayesian learning and inference in recurrent switching linear
dynamical systems. In Proceedings of the 20th International Conference on Artificial
Intelligence and Statistics (AISTATS), 2017.
[37] David Zoltowski, Jonathan Pillow, and Scott Linderman. A general recurrent state space
framework for modeling neural dynamics during decision-making. In Hal Daumé III
and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine
Learning, volume 119 of Proceedings of Machine Learning Research, pages 11680–11691.
PMLR, 13–18 Jul 2020.
[38] Peter Dayan and Laurence F. Abbott. Theoretical Neuroscience: Computational and
Mathematical Modeling of Neural Systems. MIT press, 2005.
[39] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning internal
representations by error propagation. Technical report, California Univ San Diego La
Jolla Inst for Cognitive Science, 1985.
[40] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computa-
tion, 9(8):1735–1780, 1997.
[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N
Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is All You Need. Advances in
Neural Information Processing Systems, 30, 2017.
15

[42] Zhengdao Chen, Baranidharan Raman, and Ari Stern. Structure-preserving numerical
integrators for Hodgkin–Huxley-type systems. SIAM Journal on Scientific Computing,
42(1):B273–B298, 2020.
[43] Quanxin Wang, Song-Lin Ding, Yang Li, Josh Royall, David Feng, Phil Lesnar, Nile
Graddis, Maitham Naeemi, Benjamin Facer, Anh Ho, et al. The Allen mouse brain
common coordinate framework: a 3d reference atlas. Cell, 181(4):936–953, 2020.
[44] Michael I Jordan. Serial order: A parallel distributed processing approach. In Advances
in psychology, volume 121, pages 471–495. Elsevier, 1997.
[45] Diederik Kingma, Jimmy Ba, Yoshua Bengio, and Yann LeCun. Adam: A method for
stochastic optimization. In 3rd International Conference on Learning Representations,
2015.
[46] Marco Fraccaro, Søren Kaae Sønderby, Ulrich Paquet, and Ole Winther. Sequential
neural models with stochastic layers. Advances in Neural Information Processing Systems,
29, 2016.
[47] AIBS.
Biophysical modeling — perisomatic.
Technical report, Allen Institute for
Brain Science, 10 2017.
URL http://help.brain-map.org/display/celltypes/
Documentation.
[48] Costa M Colbert and Enhui Pan. Ion channel properties underlying axonal action
potential initiation in pyramidal neurons. Nature neuroscience, 5(6):533–538, 2002.
[49] Jacopo Magistretti and Angel Alonso. Biophysical properties and slow voltage-dependent
inactivation of a sustained sodium current in entorhinal cortex layer-ii principal neurons:
a whole-cell and single-channel study. The Journal of general physiology, 114(4):491–509,
1999.
[50] Maarten HP Kole, Stefan Hallermann, and Greg J Stuart.
Single ih channels in
pyramidal neuron dendrites: properties, distribution, and impact on action potential
output. Journal of Neuroscience, 26(6):1677–1687, 2006.
[51] I Reuveni, A Friedman, Y Amitai, and Michael J Gutnick. Stepwise repolarization from
ca2+ plateaus in neocortical pyramidal cells: evidence for nonhomogeneous distribution
of hva ca2+ channels in dendrites. Journal of Neuroscience, 13(11):4609–4621, 1993.
[52] Robert B Avery and Daniel Johnston. Multiple channel types contribute to the low-
voltage-activated calcium current in hippocampal ca3 pyramidal neurons. Journal of
Neuroscience, 16(18):5567–5582, 1996.
[53] AD Randall and RW Tsien. Contrasting biophysical and pharmacological properties of
t-type and r-type calcium channels. Neuropharmacology, 36(7):879–893, 1997.
[54] PR Adams, DA Brown, and A Constanti. M-currents and other potassium currents in
bullfrog sympathetic neurones. The Journal of Physiology, 330(1):537–572, 1982.
16

[55] Alon Korngreen and Bert Sakmann. Voltage-gated k+ channels in layer 5 neocortical
pyramidal neurones from young rats: subtypes and gradients. The Journal of physiology,
525(3):621–639, 2000.
[56] M Köhler, B Hirschberg, CT Bond, John Mark Kinzie, NV Marrion, James Maylie, and
JP Adelman. Small-conductance, calcium-activated potassium channels from mammalian
brain. Science, 273(5282):1709–1714, 1996.
17

7
Derivations
Gradient of Inclusive KL Divergence
Below, we derive the gradient of the inclusive
KL divergence for a generic Markovian model. In this derivation, we assume there are no
shared parameters between the proposal and model.
−∇ϕKL(pθ||qϕ) = ∇ϕ
Z
pθ(x1:T |y1:T ) log qϕ(x1:T |y1:T )dx1:T
(13)
=
Z
pθ(x1:T |y1:T )∇ϕ log qϕ(x1:T |y1:T )dx1:T
(14)
=
Z
pθ(x1:T |y1:T )∇ϕ
 X
t
log qϕ(xt|xt−1, yt:T )
!
dx1:T
(15)
=
X
t
Z
pθ(x1:T |y1:T )∇ϕ log qϕ(xt|xt−1, yt:T )dx1:T
(16)
=
X
t
Epθ(x1:T |y1:T ) [∇ϕ log qϕ(xt|xt−1, yt:T )]
(17)
We use the assumption that there are no shared parameters in the second equality.
Gradient of the Marginal Likelihood
We derive the gradients for the marginal likelihood.
This identity is known as Fisher’s identity.
∇θ log p(y1:T ) = ∇θ log
Z
pθ(x1:T , y1:T )dy1:T
(18)
=
1
pθ(y1:T )∇θ
Z
pθ(x1:T , y1:T )dx1:T
(19)
=
1
pθ(y1:T )
Z
∇θpθ(x1:T , y1:T )dx1:T
(20)
=
1
pθ(y1:T )
Z
pθ(x1:T , y1:T )∇θ log pθ(x1:T , y1:T )dx1:T
(21)
=
Z
pθ(x1:T |y1:T )∇θ log pθ(x1:T , y1:T )dx1:T
(22)
=
Z
pθ(x1:T |y1:T )∇θ
X
t
log pθ(yt, xt|xt−1)dx1:T
(23)
=
X
t
Z
pθ(x1:T |y1:T )∇θ log pθ(yt, xt|xt−1)dx1:T
(24)
=
X
t
Epθ(x1:T |y1:T ) [∇θ log pθ(yt, xt|xt−1)]
(25)
The key steps were the log-derivative trick and Bayes rule.
18

8
LGSSM
Model Details
We consider a one-dimensional linear Gaussian state space model with
joint distribution
p(x1:T , y1:T ) = N(x1; 0, σ2
x)
T
Y
t=2
N(xt+1; xt, σ2
x)
T
Y
t=1
N(yt; xt, σ2
y).
(26)
In our experiments we set the dynamics variance σ2
x = 1.0 and the observation variance
σ2
y = 1.0.
Proposal Parameterization
For both NAS-X and NASMC, we use a mean-field Gaussian
proposal factored over time
q(x1:T ) =
T
Y
t=1
qt(xt) =
T
Y
t=1
N(xt; µt, σ2
t ),
(27)
with parameters µ1:T and σ2
1:T corresponding to the means and variances at each timestep.
In total, we learn 2T proposal parameters.
Twist Parametrization
We parameterize the twist as a quadratic function in xt whose
coefficients are functions of the observations and time step and are learned via the density
ratio estimation procedure described in [12]. We chose this form to match the analytic
log density ratio for the model defined in Eq 26. Given that p(x1:T , y1:T ) is a multivariate
Gaussian, we know that p(xt | yt+1:T ) and p(xt) are both marginally Gaussian. Let
p(xt | yt+1:T ) ≜N(µ1, σ2
1)
p(xt) ≜N(0, σ2
1)
Then,
log
p(xt | yt+1:T )
p(xt)

= log N(xt; µ1, σ2
1) −log N(xt; 0, σ2
2)
= log Z(σ1) −
1
2σ2
1
x2
t + µ1
σ2
1
xt −µ2
1
2σ2
1
−log Z(σ2) +
1
2σ2 x2
t
where Z(σ) =
1
σ
√
2π, so log Z(σ) = −log(σ
√
2π).
Collecting terms gives:
−log(σ1
√
2π) + log(σ2
√
2π)
−1
2
 1
σ2
1
−1
σ2
2

x2
t
+µ1
σ2
1
xt
−µ2
1
2σ2
1
19

So we’ll define
a ≜−1
2
 1
σ2
1
−1
σ2
2

b ≜µ1
σ2
1
c ≜−µ2
1
2σ2
1
−log(σ1
√
2π) + log(σ2
√
2π)
We’ll explicitly model log σ2
1, log σ2
2 and µ1. Both log σ2
1 and log σ2
2 are only functions of t,
not of yt+1:T , so those can be vectors of shape T initialized at 0. µ1 is a linear function of
yt+1:T and t, so that can be parameterized by a set of T × T weights, initialized to 1/T and
T biases initialized to 0.
Training Details
We use a batch size of 32 for the density ratio estimation step. Since
we do not perform model learning, we do not repeatedly alternate between tilt training and
proposal training for NAS-X. Instead, we first train the tilt for 3,000,000 iterations with
a batch size of 32 using samples from the model. We then train the proposal for 750, 000
iterations. For the tilt, we used Adam with a learning rate schedule that starts with a
constant learning rate of 1e −3, decays the learning by 0.3 and 0.33 at 100, 000 and 300, 000
iterations. For the proposal, we used Adam with a constant learning rate of 1e −3. For
NASMC, we only train the proposal.
Evaluation
In the right panel of Figure 1, we compare the bound gaps of NAS-X and
NASMC averaged across 20 different samples from the generative model. To obtain the
bound gap for NAS-X, we run SMC 16 times with 128 particles and with the learned proposal
and twists. We then record the average log marginal likelihood. For NASMC, we run SMC
with the current learned proposal (without any twists).
9
rSLDS
Model details
The generative model is as follows. At each time t, there is a discrete
latent state zt ∈{1, . . . , 4} as well as a two-dimensional continuous latent state xt ∈R2. The
discrete state transition probabilities are given by
p(zt+1 = i | zt = j, xt) ∝exp
 ri + RT
i xt−1

(28)
Here Ri and ri are weights for the discrete state zi.
These discrete latent states dictates two-dimensional latent state xt ∈R2 which evolves
according to linear Gaussian dynamics.
xt+1 = Azt+1xt + bzt+1 + vt,
vt ∼iid N(0, Qzt+1)
(29)
Here Ak, Qk ∈R2x2 and bk ∈R2. Importantly, from Equations 29 and 28 we see that the
dynamics of the continuous latent states and discrete latents are coupled. The discrete latent
20

states index into specific linear dynamics and the discrete transition probabilities depend on
the continuous latent state.
The observations yt ∈R10 are linear projections of the continuous latent state xt with
some additive Gaussian noise.
yt = Cxt + d + wt,
vt ∼iid N(0, S)
(30)
Here C, S ∈R10x10 and d ∈R10.
Proposal Parameterization
We use a mean-field proposal distribution factorized over
the discrete and continuous latent variables (i.e. q(z1:T , x1:T ) = q(z1:T )q(x1:T )). For the
continuous states, q(x1:T ) is a Gaussian factorized over time with parameters µ1:T and σ2
1:T .
For the discrete states, q(z1:T ) is a Categorical distribution over K categories factorized over
time with parameters p1:K
1:T . In total, we learn 2T + TK proposal parameters.
Twist Parameterization
We parameterize the twists using a recurrent neural network
(RNN) that is trained using density ratio estimation. To produce the twist values at each
timestep, we first run a RNN backwards over the observations y1:T to produce a sequence of
encodings e1:T−1. We then concatenate the encodings of xt and zt into a single vector and
pass that vector into an MLP which outputs the twist values at each timestep. The RNN
has one layer with 128 hidden units. The MLP has 131 hidden units and ReLU activations.
Model Parameter Evaluation
We closely follow the parameter initialization strategy
employed by Linderman et al. [36]. First, we use PCA to obtain a set of continuous latent
states and initialize the matrices C and d. We then fit an autoregressive HMM to the
estimated continuous latent states in order to initialize the dynamics matrices {Ak, bk}.
Importantly, we do not initialize the proposal with the continuous latent states described
above.
Training Details
We use a batch size of 32 for the density ratio estimation step. We
alternate between 100 steps of tilt training and 100 steps of proposal training for a total
of 50,000 training steps in total. We used Adam and considered a grid search over the
model, proposal, and tilt learning rates. In particular, we considered learning rates of
1e −4, 1e −3, 1e −2 for the model, proposal, and tilt.
Bootstrap Bound Evaluation
To obtain the log marginal likelihood bounds and standard
deviations in Table 1, we ran a bootstrapped particle filter (BPF) with the learned model
parameters for all three methods (NAS-X, NASMC, Laplace EM) using 1024 particles. We
repeat this across 30 random seeds. Initialization of the latent states was important for a
fair comparison. To initialize the latent states, for NAS-X and NASMC, we simply sampled
from the learned proposal at time t = 0. To initialize the latent state for Laplace EM, we
sampled from a Gaussian distribution with the learned dynamics variance at t = 0.
21

10
Inference in Squid Giant Axon Model
10.1
HH Model Definition
For the inference experiments (Section 5.3.1) we used a probabilistic version of the squid
giant axon model [7, 38]. Our experimental setup was constructed to broadly match [12],
and used a single-compartment model with dynamics defined by
Cm
dv
dt = Iext −gNam3h(v −ENa) −¯gKn4(v −EK) −gleak(v −Eleak)
(31)
dm
dt = αm(v)(1 −m) −βm(v)m
(32)
dh
dt = αh(v)(1 −h) −βh(v)h
(33)
dn
dt = αn(v)(1 −n) −βn(v)n
(34)
where Cm is the membrane capacitance; v is the potential difference across the membrane;
Iext is the external current; ¯gNa, ¯gK, and ¯gleak are the maximum conductances for sodium,
potassium, and leak channels; ENa, EK, and Eleak are the reversal potentials for the sodium,
potassium, and leak channels; m and h are subunit states for the sodium channels and n
is the subunit state for the potassium channels. The functions α and β that define the
dynamics for n, m, and h are defined as
αm(v) =
−4 −v/10
exp(−4 −v/10) −1,
βm(v) = 4 · exp((−65 −v)/18)
(35)
αh(v) = 0.07 · exp((−65 −v)/20),
βh(v) =
1
exp(−3.5 −v/10) + 1
(36)
αn(v) =
−5.5 −v/10
exp(−5.5 −v/10) −1,
βn(v) = 0.125 · exp((−65 −v)/80)
(37)
This system of ordinary differential equations defines a nonlinear dynamical system with
a four-dimensional state space: the instantaneous membrane potential v and the ion gate
subunit states n, m, and h.
As in [12], we use a probabilistic version of the original HH model that adds zero-mean
Gaussian noise to both the membrane voltage v and the “unconstrained” subunit states.
The observations are produced by adding Gaussian noise with variance σ2
y to the membrane
potential v.
Specifically, let xt be the state vector of the system at time t containing (vt, mt, ht, nt),
and let φdt(x) be a function that integrates the system of ODEs defined above for a step of
length dt. Then the probabilistic HH model can be written as
p(x1:T , y1:T ) = p(x1)
T
Y
t=2
p(xt | φdt(xt−1))
T
Y
t=1
N(yt; xt,1, σ2
y)
(38)
where the 4-D state distributions p(x1) and p(xt | φdt(xt−1)) are defined as
p(xt | φdt(xt−1)) = N(xt,1; φdt(xt−1)1, σ2
x,1)
4
Y
i=2
LogitNormal(xt,i; φdt(xt−1)i, σ2
x,i).
(39)
22

In words, we add Gaussian noise to the voltage (xt,1) and logit-normal noise to the gate
states n, m, and h. The logit-normal is defined as the distribution of a random variable
whose logit has a Gaussian distribution, or equivalently it is a Gaussian transformed by
the sigmoid function and renormalized. We chose the logit-normal because its values are
bounded between 0 and 1, which is necessary for the gate states.
Problem Setting
For the inference experiments we sampled 10,000 noisy voltage traces
from a fixed model and used each method to train proposals (and possibly twists) to compute
the marginal likelihood assigned to the data under the true model.
As in [12], we sampled trajectories of length 50 milliseconds, with a single noisy voltage
observation every millisecond. The stability of our ODE integrator allowed us to integrate at
dt = 0.1ms, meaning that there were 10 latent states per observation.
Proposal and Twist Details
Each proposal was parameterized using the combination
of a bidirectional recurrent neural network (RNN) that conditioned on all observed noisy
voltages as well as a dense network that conditioned on the RNN hidden state and the
previous latent state xt−1 [40, 44]. The twists for SIXO and NAS-X were parameterized
using an RNN run in reverse over the observations combined with a dense network that
conditioned on the reverse RNN hidden state and the latent being ‘twisted’, xt. Both the
proposal and twists were learned in an amortized manner, i.e. they were shared across all
trajectories. All RNNs had a single hidden layer of size 64, as did the dense networks. All
models were fit with ADAM [45] with proposal learning rate of 10−4 and tilt learning rate of
10−3.
A crucial aspect of fitting the proposals was defining them in terms of a ‘residual’ from
the prior, a technique known as Resq [46]. In our setting, we defined the true proposal density
as proportional to the product of a unit-variance Gaussian centered at φ(xt) and a Gaussian
with parameters output from the RNN proposal.
10.2
Experimental Results
In Figure 5 we plot the performance of proposals and twists trained with 4 particles and
evaluated across a range of particle numbers. All methods except FIVO perform roughly
the same when evaluated with 256 particles, but with lower numbers of evaluation particles
the smoothing methods emerge as more particle-efficient than the filtering methods. To
achieve NAS-X’s inference performance with 4 particles, NASMC would need 256 particles,
a 64-times increase. NAS-X is also more particle-efficient than SIXO, achieving on average a
2x particle efficiency improvement.
The FIVO method with a parametric proposal drastically underperformed all smoothing
methods as well as NASMC, indicating that the combination of filtering SMC and the exclusive
KL divergence leads to problems optimizing the proposal parameters. To compensate, we
also evaluated the performance of “FIVO-BS", a filtering method that uses a bootstrap
proposal. This method is identical to a bootstrap particle filter, i.e. it proposes from the
model and has no trainable parameters. FIVO-BS far outperforms standard FIVO, and is
only marginally worse than NASMC in this setting.
23

4
8
16
32
64
128
256
Num Particles
-148
-197
-262
-347
-461
-612
-812
Log-likelihood lower bound
Inference in Hodgkin-Huxley
50ms trace, 1 obs/ms, σ2
y = 20
FIVO-BS
FIVO
NASMC
SIXO
NAS-X
4
8
16
32
64
128
256
Num Particles
-167
-174
-181
-188
-195
-203
-211
Log-likelihood lower bound
SIXO vs NAS-X
50ms trace, 1 obs/ms, σ2
y = 20
SIXO
NAS-X
Figure 5: HH inference performance across different numbers of particles.
(left) Log-likelihood lower bounds for proposals trained with 4 particles and evaluated across
a range of particle numbers. NAS-X’s inference performance decays only minimally as the
number of particles is decreased, while all other methods experience significant performance
degradation. (right) A comparison of SIXO and NAS-X containing the same values as
the left panel, but zoomed in. NAS-X is roughly twice as particle efficient as SIXO, and
outperforms SIXO by roughly 34 nats at 4 particles.
In Figure 6 we investigate these results qualitatively by examining the inferred voltage
traces of each method. We see that NASMC struggles to produce accurate spike timings and
generates many spurious spikes, likely because it is unable to incorporate future information
into its proposal or resampling method. SIXO performs better than NASMC, accurately
inferring the timing of most spikes but resampling at a high rate. High numbers of resampling
events can lead to particle degeneracy and poor inferences. NAS-X is able to correctly infer
the voltage across the whole trace with no suprious or mistimed spikes. Furthermore NAS-X
rarely resamples, indicating it has learned a high-quality proposal that does not generate
low-quality particles that must be resampled away. These qualitative results seem to support
the quantitative results in Figure 5 — SIXO’s high resampling rate and NASMC’s filtering
approach lead to lower bound values.
Table 2: Train Bound comparison
Metric
NAS-X
SIXO
L256
BPF
−660.7003
−636.2579
L4
train
−664.3528
−668.6865
L8
train
−662.8712
−653.6352
L16
train
−662.0753
−644.8764
L32
train
−661.5387
−639.5388
L64
train
−660.8040
−636.5131
L128
train
−660.5102
−633.7875
L256
train
−660.3423
−632.1377
24

0
5
10
15
20
25
30
35
40
45
50
80
60
40
20
0
20
40
Voltage (mV)
True Voltage
Inferred Voltage
Resampling Event
NASMC
−50
0
50
Voltage (mV)
SIXO
True Voltage
Inferred Voltage
Resampling Event
0
5
10
15
20
25
30
35
40
45
50
Time (ms)
−50
0
50
Voltage (mV)
NAS-X
Figure 6: Inferred voltage traces for NASMC, SIXO, and NAS-X.
(top) NASMC exhibits poor performance, incorrectly inferring the timing of most spikes.
(middle) SIXO’s inferred voltage traces are more accurate than NASMC’s with only a single
mistimed spike, but SIXO generates a high number of resampling events leading to particle
degeneracy. (bottom) NAS-X perfectly infers the latent voltage with no mistimed spikes,
and resamples very infrequently.
25

11
Model Learning in Mouse Pyramidal Neuron Model
11.1
Model Definition
For the model learning experiments in Section 5.3.2 we used a generalization of the Hodgkin-
Huxley model developed for modeling mouse visual cortex neurons by the Allen Institute
for Brain Science [43, 47]. Specifically we used the perisomatic model with ID 482657528
developed to model cell 480169178. The model is detailed in the whitepaper [47] and the
accompanying code, but we reproduce the details here to ensure our work is self-contained.
Similar to the squid giant axon model, the mouse visual cortex model is composed of
ion channels that affect the current flowing in and out of the cell. Let I be the set of ions
{Na+, Ca2+, K+}. Each ion has associated with it
1. A set of channels that transport that ion, denoted Ci for i ∈I.
2. A reversal potential, Ei.
3. An instantaneous current density, Ii, which is computed by summing the current density
flowing through each channel that transports that ion.
Correspondingly, let C be the set of all ion channels so that C = S
i∈I Ci. Each c ∈C has
associated with it
1. A maximum conductance density, gc.
2. A set of subunit states, referred to collectively as the vector λc. Let λc ∈[0, 1]dc, i.e.
λc is a dc-dimensional vector of values in the interval [0, 1].
3. A function gc that combines the gate values to produce a number in [0, 1] that weights
the maximum conductance density, gc · gc(λc).
4. Functions Ac(·) and bc(·) which compute the matrix and vector used in the ODE
describing λc dynamics. Ac and bc are functions of both the current membrane voltage
v and calcium concentration inside the cell [Ca2+]i. If the number of subunits (i.e.
the dimensionality of λc) is dc, then the output of Ac(v, [Ca2+]i) is a dc × dc diagonal
matrix and the output of bc(v, [Ca2+]i) is a dc-dimensional vector.
With this notation we can write the system of ODEs
Cm
dv
dt = Iext
SA −gleak(v −Eleak) −
X
i∈ions
Ii
(40)
Ii =
X
c∈Ci
gcgc(λc)(v −Ei)
(41)
dλc
dt = Ac(v, [Ca2+]i)λc + bc(v, [Ca2+]i)
∀c ∈C
(42)
d[Ca2+]i
dt
= −kICa2+ −[Ca2+]i −[Ca2+]min
τ
.
(43)
Most symbols are as described earlier, SA is the membrane surface area of the neuron,
[Ca2+]i is the calcium concentration inside the cell, [Ca2+]min is the minimum interior
26

calcium concentration with a value of 1 nanomolar, τ is the rate of removal of calcium with
a value of 80 milliseconds, and k and is a constant with value
k = 10000 ·
γ
2 · F · depth
(44)
where 10000 is a dimensional constant, γ is the percent of unbuffered free calcium, F is
Faraday’s constant, and depth is the depth of the calcium buffer with a value of 0.1 microns.
Because the concentration of calcium changes over time, this model calculates the reversal
potential for calcium ECa2+ using the Nernst equation
ECa2+ = G · T
2 · F log
[Ca2+]o
[Ca2+]i

(45)
where G is the gas constant, T is the temperature in Kelvin (308.15◦), F is Faraday’s constant,
and [Ca2+]o is the extracellular calcium ion concentration which was set to 2 millimolar.
Probabilistic Model
The probabilistic version of the deterministic ODEs was constructed
similarly to the probabilistic squid giant axon model — Gaussian noise was added to the
voltage and unconstrained gate states. One difference is that the system state now includes
[Ca2+]i which is constrained to be greater than 0. To noise [Ca2+]i we added Gaussian noise
in the log space, analagous to the logit-space noise for the gate states.
Model Size
The 38 learnable parameters of the model include:
1. Conductances g for all ion channels (10 parameters).
2. Reversal potentials of sodium, potassium, and the non-specific cation: EK+, ENa+, and
ENSC+.
3. The membrane surface area and specific capacitance.
4. Leak channel reversal potential and max conductance density.
5. The calcium decay rate and free calcium percent.
6. Gaussian noise variances for the voltage v and interior calcium concentration [Ca2+]i.
7. Gaussian noise variances for all subunit states (16 parameters).
8. Observation noise variance.
The 18-dimensional state includes:
1. Voltage v
2. Interior calcium concentration [Ca2+]i
3. All subunit states (16 dimensions)
27

11.2
Channel Definitions
In this section we provide a list of all ion channels used in the model. In the following
equations we often use the function exprel which is defined as
exprel(x) =



1
if
x = 0
exp(x) −1
x
otherwise
(46)
A numerically stable implementation of this function was critical to training our models.
Additionally, many of the channel equations below contain a ‘temperature correction’ qt
that adjusts for the fact that the original experiments and Allen Institute experiments were
not done at the same temperature. In those equations, T is the temperature in Celsius which
was 35◦.
11.2.1
Transient Na+
From Colbert and Pan [48].
λc = (m, h),
gc(λc) = m3h
1
qt
dm
dt = αm(v)(1 −m) −βm(v)m
1
qt
dh
dt = αh(v)(1 −h) −βh(v)h
qt = 2.3( T −23
10 )
αm(v) =
0.182 · 6
exprel(−(v + 40)/6),
βm(v) =
0.124 · 6
exprel((v + 40)/6)
αh(v) =
0.015 · 6
exprel((v + 66)/6),
βh(v) =
0.015 · 6
exprel(−(v + 66)/6)
11.2.2
Persistent Na+
From Magistretti and Alonso [49].
λc = h,
gc(λc) = m∞h
m∞=
1
1 + exp(−(v + 52.6)/4.6)
1
qt
dh
dt = αh(v)(1 −h) −βh(v)h
qt = 2.3( T −21
10 )
αh(v) =
2.88 × 10−6 · 4.63
exprel((v + 17.013)/4.63),
βh(v) =
6.94 × 10−6 · 2.63
exprel(−(v + 64.4)/2.63)
28

11.2.3
Hyperpolarization-activated cation conductance
From Kole et al. [50]. This channel uses a ‘nonspecific cation current’ meaning it can transport
any cation. In practice, this is modeled by giving it its own special ion NSC+ with resting
potential ENSC+.
λc = m,
gc(λc) = m
ENSC+ = −45.0
dm
dt = αm(v)(1 −m) −βm(v)m
αm(v) =
0.001 · 6.43 · 11.9
exprel((v + 154.9)/11.9),
βm(v) = 0.001 · 193 · exp(v/33.1)
11.2.4
High-voltage-activated Ca2+ conductance
From Reuveni et al. [51]
λc = (m, h),
gc(λc) = m2h
dm
dt = αm(v)(1 −m) −βm(v)m
dh
dt = αh(v)(1 −h) −βh(v)h
αm(v) =
0.055 · 3.8
exprel(−(v + 27)/3.8),
βm(v) = 0.94 · exp(−(v + 75)/17)
αh(v) = 0.000457 · exp(−(v + 13)/50),
βh(v) =
0.0065
exp(−(v + 15)/28) + 1
11.2.5
Low-voltage-activated Ca2+ conductance
From Avery and Johnston [52], Randall and Tsien [53].
λc = (m, h),
gc(λc) = m2h
1
qt
dm
dt = m∞−m
mτ
1
qt
dh
dt = h∞−h
hτ
qt =2.3(T−21)/10
m∞=
1
1 + exp(−(v + 40)/6),
mτ = 5 +
20
1 + exp((v + 35)/5)
h∞=
1
1 + exp((v + 90)/6.4),
hτ = 20 +
50
1 + exp((v + 50)/7)
29

11.2.6
M-type (Kv7) K+ conductance
From Adams et al. [54].
λc = m,
gc(λc) = m
1
qt
dm
dt = αm(v)(1 −m) −βm(v)m
qt = 2.3( T −21
10 )
αm(v) = 0.0033 exp(0.1(v + 35)),
βm(v) = 0.0033 · exp(−0.1(v + 35))
11.2.7
Kv3-like K+ conductance
λc = m,
gc(λc) = m
dm
dt = m∞−m
mτ
m∞=
1
1 + exp(−(v −18.7)/9.7),
mτ =
4
1 + exp(−(v + 46.56)/44.14)
11.2.8
Fast inactivating (transient, Kv4-like) K+ conductance
From Korngreen and Sakmann [55].
λc = (m, h),
gc(λc) = m4h
1
qt
dm
dt = m∞−m
mτ
1
qt
dh
dt = h∞−h
hτ
qt =2.3(T−21)/10
m∞=
1
1 + exp(−(v + 47)/29),
mτ = 0.34 +
0.92
exp(((v + 71)/59)2)
h∞=
1
1 + exp((v + 66)/10),
hτ = 8 +
49
exp(((v + 73)/23)2)
g = 1 × 10−5
11.2.9
Slow inactivating (persistent) K+ conductance
From Korngreen and Sakmann [55].
λc = (m, h),
gc(λc) = m2h
1
qt
dm
dt = m∞−m
mτ
1
qt
dh
dt = h∞−h
hτ
qt =2.3(T−21)/10
30

m∞=
1
1 + exp(−(v + 14.3)/14.6)
mτ =
(
1.25 + 175.03 · e0.026v,
if v < −50
1.25 + 13 · e−0.026v,
if v ≥−50
h∞=
1
1 + exp((v + 54)/11)
hτ =
24v + 2690
exp(((v + 75)/48)2)
g = 1 × 10−5
11.2.10
SK-type calcium-activated K+ conductance
From Köhler et al. [56]. Note this is the only calcium-gated ion channel in the model.
λc = z,
gc(λc) = z
dz
dt = z∞−z
zτ
z∞=
1
1 + (0.00043/[Ca2+]i)4.8 ,
zτ = 1
11.3
Training Details
Dataset
The dataset used to fit the model was a subset of the stimulus/response pairs
available from the Allen Institute. First, all stimuli and responses were downloaded for cell
480169178. Then, sections of length 200 milliseconds were extracted from a subset of the
stimuli types. The stimuli types and sections were chosen so that the neuron was at rest and
unstimulated at the beginning of the trace. We list the exclusion criteria below.
1. Any “Hold” stimuli: Excluded because these traces were collected under voltage clamp
conditions which we did not model.
2. Test: Excluded because the stimulus is 0 mV for the entire trace.
3. Ramp/Ramp to Rheobase: Excluded because the cell is only at rest at the very
beginning of the trace.
4. Short Square: 250 ms to 450 ms.
5. Short Square — Triple: 1250 ms to 1450 ms.
6. Noise 1 and Noise 2: 1250 ms to 1450 ms, 9250 ms to 9450 ms, 17250 ms to 17450 ms.
7. Long Square: 250 ms to 450 ms.
8. Square — 0.5ms Subthreshold: The entire trace.
9. Square — 2s Suprathreshold: 250 ms to 450 ms.
31

10. All others: Excluded.
For cell 480169178, the criteria above selected 95 stimulus/response pairs of 200 millisec-
onds each. Each trace pair was then downsampled to 1 ms (from the original 0.005 ms per
step) and corrupted with mean-zero Gaussian noise of variance 20 mV2 to simulate voltage
imaging conditions. Finally, the 95 traces were randomly split into 72 training traces and 23
test traces.
Proposal and Twist
The proposal and twist hyperparameters were broadly similar to
the squid axon experiments, with the proposal being parameterized by a bidirectional RNN
with a single hidden layer of size 64 and an MLP with a single hidden layer of size 64. The
RNN was conditioned on the observed response and stimulus voltages at each timestep,
and the MLP accepted the RNN hidden state, the previous latent state, and a transformer
positional encoding of the number of steps since the last voltage response observation. The
twist was similarly parameterized using an RNN run in reverse across the stimulus and
response, combined with an MLP that accepted the RNN hidden state, the latent state being
evaluated, and a transformer positional encoding of the number of steps elapsed since the
last voltage response observation. The positional encodings were used to inform the twist
and proposal of the number of steps elapsed since the last observation because the model was
integrated with a stepsize of 0.1ms while observations were received once every millisecond.
Hyperparameter Sweeps
To evaluate the methods we swept across the parameters
1. Initial observation variance: e2, e3, e5
2. Initial voltage dynamics variance: e, e2, e3
3. Bias added to scales produced by the proposal: e2, e5
We also evaluated the models across three different data noise variances (20, 10, and 5) but
the results were similar for all values, so we reported only the results for variance 20. This
amounted to 3 · 3 · 3 · 2 different hyperparameter settings, and 5 seeds were run for each
setting yielding a total of 270 runs.
When computing final performance, a hyperparameter setting was only evaluated if it had
at least 3 runs that achieved 250,000 steps without NaN-ing out. For each hyperparameter
setting selected for evaluation, all successful seeds were evaluated using early stopping on
the train 4-particle log likelihood lower bound.
12
Strang Splitting for Hodgkin-Huxley Models
Because the Hodgkin-Huxley model is a stiff ODE, integrating it can be a challenge, especially
at large step sizes. The traditional solution is to use an implicit integration scheme with
varying step size, allowing the algorithm to take large steps when the voltage is not spiking.
However, because our model adds noise to the ODE state at each timestep adaptive step-size
methods are not viable as the different stepsizes would change the noise distribution.
Instead, we sought an explicit, fixed step-size method that could be stably integrated
at relatively large stepsizes. Inspired by Chen et al. [42], we developed a splitting approach
32

that exploits the conditional linearity of the system. The system of ODEs describing the
model can be split into two subsystems of linear first-order ODEs when conditioned on
the state of the other subsystem. Specifically, the dynamics of the channel subunit states
{λc | c ∈C} is a system of linear first-order ODEs when conditioned on the voltage v and
interior calcium concentration [Ca2+]i. Similarly, the dynamics for v and [Ca2+]i is a system
of linear first-order ODEs when conditioned on the subunit states.
Because the conditional dynamics of each subsystem are linear first-order ODEs, an
exact solution to each subsystem is possible under the assumption that the states being
conditioned on are constant for the duration of the step. Our integration approach uses
these exact updates in an alternating fashion, first performing an exact update to the voltage
and interior calcium concentration while holding the subunit states constant, and then
performing an exact update to the subunit states while holding the voltage and interior
calcium concentration constant. For details on Strang and other splitting methods applied
to Hodgkin-Huxley type ODEs, see [42].
33

