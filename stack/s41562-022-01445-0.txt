Articles
https://doi.org/10.1038/s41562-022-01445-0
1Laboratoire de Neurosciences Cognitives et Computationnelles, Institut National de la Santé et de la Recherche Médicale (Inserm), Paris, France. 
2Département d’Études Cognitives, École Normale Supérieure, Université PSL, Paris, France. 3Department of Neurobiology, Harvard Medical School, 
Boston, MA, USA. ✉e-mail: julie.drevet@ens.fr; valentin.wyart@ens.fr
E
fficient decision-making about the cause of noisy or ambigu-
ous observations requires the accumulation of multiple pieces 
of evidence to form accurate beliefs1,2, a process typically 
referred to as ‘statistical inference’. In stable environments, accu-
mulating evidence across observations reduces uncertainty about 
their cause. There is ample experimental evidence that humans 
and other animals perform near-optimal inference in such condi-
tions. However, human inference is subject to two main sources of 
internal noise: sensory noise, which limits the amount of evidence 
provided by each observation3, and computation noise, which arises 
during the imprecise combination of incoming sensory evidence 
with the current belief4–6. Both sources of noise trigger trial-to-trial 
variability in beliefs and behaviour.
In volatile environments, the cause of noisy observations changes 
over time, and statistical inference requires the appropriate weight-
ing of the current belief against incoming sensory evidence7. Recent 
findings suggest that humans and other animals are capable of per-
forming near-optimal inference even in volatile environments8. 
However, in these conditions, the trial-to-trial variability in beliefs 
triggered by internal sources of noise has even larger costs for effi-
cient decision-making. Indeed, noisy sensory observations may be 
mistaken for genuine changes in their latent cause. Similarly, impre-
cise inference may trigger unwarranted changes-of-mind when 
incoming sensory evidence is combined imprecisely with internal 
beliefs. Whether and how humans may mitigate these important 
cognitive costs in volatile environments remain unknown.
Here we addressed this question by studying human statistical 
inference in a volatile decision-making task based on noisy visual 
stimuli (Fig. 1). Tested participants (n = 60 across two experiments) 
were presented with sequences of marbles which could be drawn 
either from a light bag containing dominantly light marbles or a 
dark bag containing dominantly dark marbles (Fig. 1a). The light 
and dark areas of each marble were spatially scrambled, and the 
light/dark fractions of dominantly light and dark marbles were 
adjusted using an adaptive titration procedure (Fig. 1b), such that 
20% of dominantly light marbles (that is, marbles from the light 
bag) were perceived as dark and vice versa (Fig. 1c and Methods). 
After each marble, participants were asked to identify the bag from 
which it was drawn (Fig. 1d). Importantly, marbles were not drawn 
randomly and independently across successive trials, but rather in 
episodes of multiple draws from the same bag. Decision-making in 
the presence of such temporal structure can benefit from statistical 
inference that integrates uncertain visual information provided by 
each new marble with internal beliefs about the bag that is currently 
being drawn from.
To analyse human behaviour in this task, we developed a 
process-level model of statistical inference derived from norma-
tive Bayesian computations7, which hypothesizes distinct sources of 
internal noise at sensory, inference and response selection stages4. 
Across two experiments, we fitted this model to human behaviour to 
determine whether and how tested participants adopted strategies to 
compensate for the costs of imprecise statistical inference identified 
above. To do so, we formulated and compared different strategies by 
which participants could mitigate the variability of beliefs formed 
through statistical inference. We obtained converging evidence 
that human observers control statistical inference in a cost-efficient 
fashion, by updating their internal beliefs based on incoming inputs 
only when the noisy sensory observations are deemed sufficiently 
reliable. This metacognitive strategy not only reduces the costs of 
internal sources of variability affecting inference, but also, counter-
intuitively, increases the accuracy of resulting decisions.
Results
Characterizing the suboptimality of statistical inference. We first 
assessed participants’ performance by comparing their reversal 
behaviour to the one predicted by the optimal Bayesian inference 
process7 (Methods, Eqs. 1 and 2). Importantly, this normative pro-
cess accounts for sensory errors due to visual noise. As expected 
from previous work4,5, optimal inference substantially outperformed 
participants (Fig. 1e,g; overall accuracy, optimal inference: 0.870; 
participants: 0.769 ± 0.011, mean ± s.e.m., paired two-sided t-test, 
difference: t28 = 9.5, P < 0.001, Cohen’s d = 1.858, 95% confidence  
Efficient stabilization of imprecise statistical 
inference through conditional belief updating
Julie Drevet   1,2 ✉, Jan Drugowitsch   3 and Valentin Wyart   1,2 ✉
Statistical inference is the optimal process for forming and maintaining accurate beliefs about uncertain environments. However, 
human inference comes with costs due to its associated biases and limited precision. Indeed, biased or imprecise inference can 
trigger variable beliefs and unwarranted changes in behaviour. Here, by studying decisions in a sequential categorization task 
based on noisy visual stimuli, we obtained converging evidence that humans reduce the variability of their beliefs by updat-
ing them only when the reliability of incoming sensory information is judged as sufficiently strong. Instead of integrating the 
evidence provided by all stimuli, participants actively discarded as much as a third of stimuli. This conditional belief updating 
strategy shows good test–retest reliability, correlates with perceptual confidence and explains human behaviour better than 
previously described strategies. This seemingly suboptimal strategy not only reduces the costs of imprecise computations but 
also, counterintuitively, increases the accuracy of resulting decisions.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1691

Articles
NaTure Human BehavIour
interval (CI) (0.079, 0.123)). To characterize this suboptimality, we 
started from the optimal model but corrupted the inference with 
imprecise computations by adding normally distributed noise on 
the result of each update step (Eq. 4). This suboptimal Bayesian 
inference model is controlled by two free parameters: (1) the haz-
ard rate h, that is, the subjective rate of reversals of the bag from 
Optimal
Noisy
0
0.1
0.2
0.3
0.4
0.5
Overall switch rate
80%
correctly perceived
Experiment 1
From which bag was the
marble drawn?
a
c
0.4
0.5
0.6
Marble luminance
20%
80%
Fraction perceived
as light
Psychophysical
titration procedure
d
Warning cue
333 ms
Choice
until response
Response
167 ms
Stimulus
83 ms
Fixation
667 ms
Delay
167 ms
Delay
500 ms
b
Trial in current block
60
10
20
30
40
50
70
80
1
–4 –3 –2 –1
1
2
3
4
Trial position from reversal
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
–4 –3 –2 –1
1
2
3
4
Trial position from reversal
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
e
f
g
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
–4 –3 –2 –1
1
2
3
4
Optimal inference
Human
Model
Human
Model
–4 –3 –2 –1
1
2
3
4
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
Noisy inference
Optimal
Noisy
0.5
0.6
0.7
0.8
0.9
1.0
Overall accuracy
Human
+
+
+
+
+
+
Inference
Staircase 1
Staircase 2
Fig. 1 | Description of experiment 1 (n = 30). a, Structure of the volatile decision-making task. Each block of trials features alternations between  
draws from the light and dark bags. b, Visual stimuli. The overall marble luminance is titrated such that 20% of presented marbles are miscategorized. 
c, Adaptive titration procedure. Top: psychometric curves estimated by the titration procedure (thin lines, participants; thick line, group-level average). 
Bottom: distributions of marble luminance presented by the staircases titrating the dark and light marbles. d, Trial description: 500 ms after a warning cue, 
a marble stimulus is presented for 83 ms, after which the participant indicates the bag from which marbles are currently drawn. e, Predictions of optimal 
inference. Top: response reversal curves indicating the fraction of correct responses towards the new drawn bag surrounding each reversal. Bottom: 
response switch curves indicating the fraction of trial-to-trial response switches surrounding the same reversals. The reversal is represented by the thin 
dotted line. Dots indicate human data (group-level average), whereas lines indicate predictions of optimal inference. Error bars correspond to s.e.m.  
f, Predictions of the noisy inference model. Top: response reversal curve predicted by the best-fitting noisy inference model (blue line). Bottom: response 
switch curve predicted by the best-fitting noisy inference model (blue line). Noisy inference captures well the accuracy of behaviour surrounding reversals 
(top) but overestimates the variability of the same behaviour (bottom). Same conventions as in e. Shaded areas correspond to s.e.m. g, Discrepancies 
between models and human behaviour. Top: overall accuracy of participants (grey dot with error bar indicates the mean and s.d. of all participants, light 
grey dots indicate single participants), optimal inference (red bar) and noisy inference (blue bar). Bottom: overall switch rate of participants, optimal 
inference and noisy inference. Despite their suboptimal accuracy, participants make response switches as often as optimal inference. Error bars on 
simulated noisy inference model (blue bars) correspond to s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1692

Articles
NaTure Human BehavIour
which marbles are drawn, and (2) the inference noise σ, that is, the 
standard deviation (s.d.) of these computation errors in the statisti-
cal inference process. On each trial, the model updates imprecisely 
its belief regarding the drawn bag by combining its prior belief in 
that trial with the imperfect information provided by the new visual 
stimulus—that is, its likely bag based on its perceived lightness 
(Methods).
We fitted this noisy inference model to two characteristic fea-
tures of human reversal behaviour simultaneously, each evaluated 
as a function of the time step from a change in hidden state (that 
is, a reversal) on four trials preceding and four trials following each 
reversal (Fig. 1f and Methods): (1) the response reversal curve, cor-
responding to the fraction of correctly reversed responses regard-
ing the new hidden state after reversal, and (2) the response switch 
curve, corresponding to the fraction of participants’ response 
switches regarding their own response on the previous trial. These 
two behavioural effects of interest are not independent, but each 
accounts for a separate behavioural dimension: the response rever-
sal curve measures the accuracy of participants’ responses regarding 
the bag being drawn after a reversal, whereas the response switch 
curve measures the stability of participants’ responses across suc-
cessive trials9.
Simulations of the best-fitting noisy inference model provided 
a good fit to participants’ response reversal curves, but a poor fit to 
the same participants’ response switch curves when both features 
were fitted simultaneously. Indeed, the model showed the same 
overall accuracy as participants (Fig. 1g; 0.765 ± 0.008, difference: 
t28 = 0.8, P = 0.416, Cohen’s d = 0.153, 95% CI (–0.015, 0.006), Bayes 
Factor in favor of a null effect BF01 = 3.707), but larger overall switch 
rate (Fig. 1g; 0.201 ± 0.007; participants: 0.146 ± 0.007; difference: 
t28 = 10.0, P < 0.001, Cohen’s d = 1.858, 95% CI (0.044, 0.066)). 
Despite their suboptimal accuracy, participants showed a similar 
switch rate as optimal inference (Fig. 1g; 0.141; difference: t28 = 0.6, 
P = 0.553, Cohen’s d = 0.111, 95% CI (−0.020, 0.011), BF01 = 4.294). 
This discrepancy between the humans’ and the noisy inference 
model’s overall switch rates suggests that participants deployed an 
additional strategy to compensate for the variability of beliefs due 
to imprecise inference.
Before assessing the nature of this ‘response stabilization’ strat-
egy, we validated that participants’ suboptimal performance is 
due to imprecise inference. First, the hazard rate h inferred from 
the participants’ choices (0.081 ± 0.010) does not differ statisti-
cally from the true hazard rate of drawn bags (0.081; difference: 
t28 = 0.0, P = 0.999, Cohen’s d = 0.0002, 95% CI (−0.020, 0.020), 
BF01 = 5.066). This suggests that participants do not have a biased 
perception of the volatility of the task. Second, we ruled out noise 
in response selection as an alternative source of behavioural vari-
ability (Supplementary Fig. 1a). Inference noise provides a better fit 
to behaviour than selection noise (exceedance P > 0.999), a result 
which we validated through model recovery (Methods). Third, 
we verified that participants’ suboptimal behaviour was not best 
explained by a leaky integration process (Methods, Eq. 3) rather 
than by the normative one (Methods, Eq. 2). This linear approxi-
mation7—even with additive inference noise—fails to better pre-
dict participants’ reversal behaviour, and the suboptimal Bayesian 
model provides a better fit to both metrics as revealed by Bayesian 
model selection (Supplementary Fig. 2, exceedance P > 0.999).
Comparing belief stabilization strategies for imprecise inference. 
We sought to characterize the cognitive strategy used by participants 
to make their responses more stable across successive trials. For this 
purpose, we derived five candidate strategies that implement such 
‘stabilization’ at different processing stages in the noisy inference 
model described above (Fig. 2) and compared them by simulating 
their specific effects surrounding reversals (Fig. 3). The first candi-
date strategy we considered is a perceptual bias (Fig. 2a), in which 
the sensory representation of each noisy stimulus is shifted in direc-
tion of prior beliefs following Bayes’ rule, resulting in a biased per-
ception of the bag to which each stimulus belongs10–12 (Methods, 
Eq. 5). This perceptual bias, operating before inference, leads to less 
variable beliefs at the expense of slower response reversals (Fig. 3).
The next two strategies we considered operate directly at the 
inference stage (Fig. 2b). Instead of updating beliefs based on every 
noisy stimulus, we considered that participants may occasionally 
not update their beliefs, effectively ignoring the information pro-
vided by the presented stimulus and sticking to their prior beliefs 
(and their previous response) until the next trial. We contrasted 
two possible strategies resulting in such inference ‘omission’: (1) a 
fraction of inference lapses during which participants are distracted 
from the task (Methods, Eq. 6), or (2) a conditional inference strat-
egy where participants update their beliefs only when the strength 
of the noisy sensory signal associated with the presented stimulus 
exceeds a certain threshold (Methods, Eqs. 7 and 8). Although both 
strategies lead to less variable beliefs, making statistical inference 
contingent on the reliability of sensory representations does not 
delay response reversals by only discarding the stimuli that are more 
likely to be misperceived (Fig. 3, middle column).
The last two considered strategies operate at the response selec-
tion stage, following the inference stage (Fig. 2c): (1) a repetition 
bias which shifts participants’ response criterion in favour of the 
previous response (Methods, Eq. 9), and (2) a fraction of response 
lapses associated with ‘blind’ response repetitions (disconnected 
from current beliefs, see Methods, Eq. 10). Like the perceptual bias 
and the inference lapses described above, these last two candidate 
strategies decrease the trial-to-trial variability of responses at the 
expense of slower adaptation to reversals (Fig. 3).
Before identifying which of these candidate strategies best 
explains human behaviour surrounding reversals (correspond-
ing to the response reversal and switch curves described above), 
we assessed the ability to arbitrate between them through model 
recovery (Methods). We generated synthetic data from each model 
and verified the ability to correctly recover the ‘ground-truth’ 
model through Bayesian model selection (Fig. 4a and Methods; all 
exceedance P > 0.95). We then compared the five response stabiliza-
tion strategies in terms of their ability to fit response reversal and 
response switch curves: (1) quantitatively through Bayesian model 
selection (Fig. 4b and Methods) and (2) qualitatively by examin-
ing their best-fitting response reversal and switch curves (Fig. 4c).  
Bayesian model selection revealed that the conditional inference 
strategy stands out by explaining simultaneously the accuracy 
(response reversal curve) and stability (response switch curve) of 
participants’ behaviour surrounding reversals (Fig. 4b; exceedance 
P > 0.999). Qualitatively speaking, while all five candidate strategies 
reproduce participants’ response reversal curves, only the condi-
tional inference strategy explains the large and transient increase 
in response switches on the first trial following each reversal  
(Fig. 4c). Besides, we confirmed that the alternative suboptimal 
models (selection noise and leaky accumulation), even when sta-
bilized with conditional inference, could not explain participants’ 
reversal behaviour better than the noisy Bayesian inference model 
with conditional inference (Supplementary Figs. 1b and 2b). These 
findings suggest that participants decrease the trial-to-trial vari-
ability of their beliefs by updating them only when the incoming 
sensory information is deemed sufficiently reliable—thereby dis-
carding unreliable information that could otherwise trigger unwar-
ranted changes-of-mind. In practice, the best-fitting reliability 
threshold δ (1.030 ± 0.122, mean ± s.e.m.) suggests that participants 
discard as many as 32.5% of presented stimuli as unreliable.
Validating specific predictions of conditional inference. To 
provide further evidence in favour of conditional inference, we 
designed and ran a second experiment (n = 30 new participants) 
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1693

Articles
NaTure Human BehavIour
which allowed: (1) replicating the findings obtained in experiment 1 
and (2) validating two specific predictions of conditional inference. 
First, we reasoned that if participants discard less reliable stimulus 
information, they should do so more often when the stimulus is dif-
ficult to categorize as light or dark—and hence triggers a weaker 
sensory signal. To test this first prediction, we had each bag contain 
marbles of three levels of difficulty (stimulus strength, correspond-
ing to different proportions of light and dark areas) determined 
through the same titration procedure to achieve correct stimulus 
categorization of 70%, 80% and 90% (Fig. 5a). We predicted that 
participants should discard more difficult stimuli more often than 
easier stimuli.
Second, we hypothesized that the reliability threshold used by 
participants to discard sensory information should decrease with 
participants’ confidence at categorizing isolated stimuli as light 
or dark. In other words, more confident participants should dis-
card fewer stimuli as unreliable. For this purpose, we asked par-
ticipants to provide confidence reports when categorizing stimuli 
during the titration procedure (Fig. 5b and Methods). These 
confidence reports showed classical signatures of decision evalu-
ation (Fig. 5c): lower accuracy for decisions made with low con-
fidence (repeated-measures ANOVA, F1,29 = 84.9, P < 0.001, effect 
size η2
p = 0.745), and a selective increase in confidence as a func-
tion of stimulus strength for correct decisions but not errors (cor-
rect: F3,87 = 61.8, P < 0.001, η2 = 0.681; error: F3,87 = 1.5, P = 0.241, 
η2 = 0.048).
As in experiment 1, participants showed suboptimal performance 
(Fig. 5d) and imprecise inference overestimated the trial-to-trial 
variability of participants’ responses (Fig. 5e), which was again closer 
to the overall behavioural variability of optimal inference (Fig. 5f). 
In contrast to experiment 1, we could split response reversal and 
response switch curves as a function of stimulus strength on the 
first trial following each reversal. Model simulations showed that 
conditional inference increases the degree of separation between 
these curves (Supplementary Fig. 3). This is because the growing 
fraction of discarded stimuli with categorization difficulty results 
in missed reversals when they are followed by a difficult stimulus. 
Model recovery confirmed that the conditional inference model is 
in principle identifiable from behaviour (Supplementary Fig. 4a; 
conditional inference M3: exceedance P > 0.99), and Bayesian model 
selection yielded strong evidence in favour of conditional inference 
(Supplementary Fig. 4b; exceedance P > 0.999). As in experiment 
1, conditional inference is the only strategy that can explain the 
dynamics of participants’ response switches surrounding reversals 
(Supplementary Figs. 3 and 4c).
To validate our first prediction that participants discard more 
difficult stimuli more often than easier ones, we fitted a separate 
reliability threshold for each stimulus strength. The reliability 
threshold is expressed in abstract units, and a more tangible metric 
of conditional inference corresponds to the associated ‘discard rate’: 
the overall fraction of discarded stimuli predicted by the model 
(Methods). The proposed conditional inference strategy predicts 
that the reliability threshold should not vary with stimulus strength 
(which varies from one trial to the next). We found that the reli-
ability threshold remains indeed approximately constant (Fig. 6a; 
F2,58 = 2.6, P = 0.095, η2 = 0.081), resulting in a decreasing discard 
rate with stimulus strength—from 33.3 ± 3.8% (mean ± s.e.m.) for 
difficult stimuli categorized with 70% accuracy down to 13.6 ± 1.2% 
for easy stimuli categorized with 90% accuracy (F2,58 = 14.6, 
P < 0.001, η2 = 0.335). This finding supports the notion that partici-
pants control inference by ignoring the sensory information below 
a fixed reliability threshold.
To validate our second prediction that the reliability threshold 
used to discard unreliable sensory information should decrease with 
s
c
h*
ĉ
x
σsel
σinf
ŝ
σsen
ρ
Category
(bag)
Inference
Perception
Selection
Stimulus
(marble)
δ
Conditional
inference
Inference
lapses
h
λ
Perceptual
bias
0
λ
Sensory
response
Light
Dark
0
δ
Sensory
response
Light
Dark
0
β
Inferred
belief
Light
Dark
β
ε
Response
lapses
Repetition
bias
Sensory
percept
Current
belief
Category
response
Previous
response
ĉ = light
Current belief
x > 0
a
b
c
Unreliable
input
Perceptual bias
prior on sensory percept
Conditional inference
discard unreliable input
Repetition bias
biased response selection
Fig. 2 | Candidate response stabilization strategies. A marble (stimulus s) is drawn from a given bag (category c, light or dark) at each trial. a, At the 
perception stage, the continuous sensory response to the stimulus, corrupted by sensory noise σsen, is categorized into a binary sensory percept ˆs (light 
or dark). A perceptual bias, controlled by parameter λ, biases the perceptual categorization towards the current belief x at stimulus onset by shifting the 
categorization criterion. b, At the inference stage, the current belief x (expressed as the log-posterior odds ratio between the two bags) is updated as a 
function of the hazard rate h (prior term) and the incoming sensory percept ˆs (likelihood term). The inference process is corrupted by inference noise σinf. 
Belief stabilization is achieved either through conditional inference, by discarding stimuli whose associated sensory responses do not exceed a reliability 
threshold δ, or through a random fraction ρ of random inference lapses during which the current belief is not updated. c, At the selection stage, the current 
belief x is sampled with selection noise σsel to obtain a category response ˆc, corresponding to the bag perceived as being currently active (light or dark). 
Response stabilization is achieved either through a repetition bias towards the previous category response, controlled by parameter β, or through a random 
fraction ε of blind response repetitions (response lapses).
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1694

Articles
NaTure Human BehavIour
confidence across participants, we fitted the confidence threshold δC 
of each participant during the titration procedure (Supplementary 
Fig. 5 and Methods). We then regressed this confidence param-
eter—which decreases with confidence—against the parameters 
of the conditional inference model fitted to the same participants 
during the main task. As predicted, we found a positive relation 
between the confidence threshold and the reliability threshold 
across participants (Fig. 6b; linear correlation coefficient r = 0.392, 
P = 0.033, 95% CI (0.037, 0.659)). This positive relation remained 
significant when accounting for the apparent internal variability in 
confidence reports (Supplementary Fig. 5c; regression coefficient 
b = 0.250 ± 0.089, P = 0.009, 95% CI (0.075, 0.425)). This second 
finding suggests that the reliability threshold used to discard unre-
liable sensory information depends on the confidence with which 
participants categorize individual stimuli.
Identifying individual differences in conditional inference. 
To provide further support for conditional inference, we studied 
whether the reliability threshold used to discard stimuli shows spe-
cific individual differences across participants. We reasoned that, if 
individual differences in reliability threshold δ reflect genuine dif-
ferences in conditional inference, then these differences should fol-
low a behavioural ‘gradient’ that is distinct from the ones associated 
with the other two parameters in the model (the hazard rate h and 
the inference noise σ). More specifically, individual differences in δ 
should mainly affect the variability of participants’ responses sur-
rounding reversals—that is, their response switch curves.
First, we observed that all three parameters show large individual 
differences (Fig. 7a). Importantly, these parameters are only moder-
ately correlated with each other (Fig. 7b)—with at most 10% of shared 
pairwise variance—and each of them shows significant test–retest  
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
–4 –3 –2 –1
1
2
3
4
Trial position
from reversal
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
–4 –3 –2 –1
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
Bias
strength
λ = 0.250
Lapse
rate
ρ = 0.422
Reliability
threshold
δ = 1.090
Bias
strength
β = 0.670
Lapse
rate
ε = 0.388
Bias strength λ
0
0.2
0.4
0
0.1
0.2
0.3
0.4
Fraction switch
First after
Last before
Reliability threshold δ
0
1
2
First after
Last before
Lapse rate ρ
0
0.2
0.4
0.6
First after
Last before
Bias strength β
0
0.5
1.0
1.5
First after
Last before
Lapse rate ε
0
0.2
0.4
0.6
First after
Last before
Perceptual
bias
Inference
lapses
Conditional
inference
Repetition
bias
Response
lapses
a
Perceptual
bias
Inference
lapses
Conditional
inference
Repetition
bias
Response
lapses
b
Trial position
from reversal
Trial position
from reversal
Trial position
from reversal
Trial position
from reversal
Noisy inference model without belief stabilization
Fig. 3 | Predicted effects of response stabilization strategies. a, Simulated effects of the five candidate strategies on response switch curves (top row) 
and response reversal curves (bottom row). The parameters controlling each response stabilization strategy (λ, δ, ρ, β, ε) are set to match participants’ 
overall switch rate. The other parameters (h, σsen, σinf, σsel) are fixed to their best-fitting values for the noisy inference model without response stabilization. 
Solid coloured lines correspond to the reversal behaviour of each candidate model, whereas dotted grey lines correspond to the reversal behaviour of the 
noisy inference model without response stabilization (same for all panels). The conditional inference strategy stands out from other strategies on the first 
trial after reversal (arrow). b, Simulated effects of the five candidate strategies on response switches just before and after a reversal. Fraction of response 
switches on the last trial before each reversal (dotted lines) and the first trial after each reversal (solid lines) for each response stabilization strategy. Dots 
correspond to stabilization parameters set as in a. All candidate strategies reduce simultaneously response switches before and after reversals, except for 
conditional inference which reduces response switches only before reversals (that is, when they are not warranted). Shaded areas around curves in a and b 
correspond to s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1695

Articles
NaTure Human BehavIour
reliability across the two experimental sessions performed by each 
participant on separate days (hazard rate h:r = 0.698, P < 0.001, 
95% CI (0.538, 0.809); inference noise σ:r = 0.308, P = 0.018, 95% 
CI (0.056, 0.523); reliability threshold δ:r = 0.574, P < 0.001, 95% CI 
(0.373, 0.724); Supplementary Fig. 6 and Methods). To test whether 
each parameter is associated with a specific behavioural gradient, 
we split participants into two groups as a function of the best-fitting 
value of the parameter being considered and plotted the response 
reversal and switch curves for each group (Fig. 7c and Methods). 
We found that the behavioural gradient associated with the hazard 
rate h explains 48.7% of individual differences in response rever-
sal curves, with a clear effect on the reversal time constant. The 
behavioural gradient associated with inference noise σ explains 
22.5% of individual differences in response reversal curves, with a 
distinct effect on the overall accuracy of responses. By contrast, the  
behavioural gradient associated with the reliability threshold δ 
explains only 4.2% of individual differences in response rever-
sal curves, but 24.8% of individual differences in response switch 
curves. In line with the conditional inference model, participants 
with higher reliability thresholds show less variable responses but 
equally rapid adaptation to reversals (Fig. 7c).
To validate the existence of this behavioural gradient in a 
‘bottom-up’ fashion, independently of fits of the conditional infer-
ence model, we performed a principal component analysis (PCA) 
of participants’ response reversal and switch curves (Supplementary 
Fig. 7 and Methods). Strikingly, the three first principal components 
(PC) obtained using this variance partitioning procedure map on 
the three parameters of the conditional inference model. The third 
PC (PC3) is associated with individual differences in response 
switch curves (16.4%), but little to no variability in response reversal  
δ = 1.030
δ ± 0.122
–4 –3 –2 –1
1
2
3
4
ρ = 0.197
p ± 0.026
–4 –3 –2 –1
1
2
3
4
β = 0.488
β ± 0.062
–4 –3 –2 –1
1
2
3
4
ε = 0.200
β ± 0.027
–4 –3 –2 –1
1
2
3
4
λ = 0.745
λ ± 0.076
–4 –3 –2 –1
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
–4 –3 –2 –1
1
2
3
4
Trial position
from reversal
–4 –3 –2 –1
1
2
3
4
Trial position
from reversal
–4 –3 –2 –1
1
2
3
4
Trial position
from reversal
Fraction reversed
–4 –3 –2 –1
1
2
3
4
0
0.2
0.4
0.6
0.8
1.0
Trial position
from reversal
–4 –3 –2 –1
1
2
3
4
Trial position
from reversal
M1: perceptual bias
M2: inference lapses
M3: conditional inference
M4: repetition bias
M5: response lapses
Simulated model
0.99
0.98
0.99
0.97
0.97
Fitted model
Model
0
0.2
0.4
0.6
0.8
1.0
Model probability
0.999
Exceedance
probability
a
b
Simulated data
Human data (n = 30)
c
M1
M1
M2
M2
M3
M3
M4
M4
M5
M5
M1
M2
M3
M4
M5
Fig. 4 | Belief stabilization through conditional inference (n = 30). a, Confusion matrix between response stabilization strategies depicting exceedance 
probabilities pexc obtained from ex ante model recovery. The ‘ground-truth’ response stabilization strategy used to simulate synthetic behaviour was 
correctly recovered with pexc > 0.97 for all five strategies, including conditional inference (the model that best describes participants’ behaviour) with 
pexc > 0.99. b, Random-effects Bayesian model selection of the best-fitting strategy in participants’ data. Bars indicate the estimated model probabilities 
for the five candidate strategies. The conditional inference model (M3) best describes the behaviour of more participants than other candidate strategies 
with pexc > 0.999. Model probabilities are presented as mean and s.d. of the estimated Dirichlet distribution. The dashed line corresponds to the uniform 
distribution. c, Simulations of response stabilization strategies fitted to participants’ data. Simulated response switch curves (top row) and response 
reversal curves (bottom row) based on the best-fitting parameters of each model. The mean best-fitting parameter (mean ± s.e.m.) is shown in the top-left 
corner for each subpanel. Solid coloured lines correspond to the reversal behaviour of each stabilized model, whereas dotted grey lines correspond to the 
reversal behaviour of the noisy inference model without response stabilization (same for all panels). Dots indicate human data (group-level average). Only 
the conditional inference model reproduces participants’ reversal behaviour. Shaded areas and error bars correspond to s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1696

Articles
NaTure Human BehavIour
curves (3.4%). Accordingly, participant-specific scores on this PC 
correlate selectively with reliability thresholds fitted with the con-
ditional inference model (r2 = 0.348, exceedance P = 0.861, 95% 
CI (0.168, 0.551)). Together, these top-down (model-based) and 
bottom-up (PCA-based) findings provide additional evidence for 
conditional inference by identifying a behavioural gradient charac-
teristic of conditional belief updating across tested participants.
Measuring cognitive benefits of conditional inference. The 
reduced trial-to-trial variability of beliefs triggered by conditional 
inference mitigates the negative effects of external (unreliable sen-
sory information) and internal (imprecise computations) sources of 
variability during statistical inference, by discarding the incoming 
stimulus information that does not exceed a minimum reliability 
level. We thus tested whether conditional inference may not only 
–4 –3 –2 –1
1
2
3
4
Trial position from reversal
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
0.6
–4 –3 –2 –1
1
2
3
4
Trial position from reversal
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
0.6
Optimal
Noisy
0.5
0.6
0.7
0.8
0.9
1.0
Overall accuracy
Human
Optimal
Noisy
0
0.1
0.2
0.3
0.4
0.5
Overall switch rate
Optimal inference
d
e
f
Noisy inference
–4 –3 –2 –1
1
2
3
4
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
–4 –3 –2 –1
1
2
3
4
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
Response + feedback
Rather confident
Rather unconfident
Stimulus
83 ms
Response
167 ms
Choice
until 
response
Correctly perceived
70%
80%
90%
+
+
Experiment 2
Inference
b
Was the marble light or dark?
a
c
50
75
100
Fraction
correct (%)
–0.5
0
0.5
Relative 
confidence
Marble luminance
(binned)
Confident
Unconfident
Correct
Error
Human
Model
Stimulus
strength
Human
Model
Stimulus
strength
Fig. 5 | Description of experiment 2 (n = 30). a, Visual stimuli. Each bag is filled with three types of marbles, corresponding respectively to 70%, 80% 
and 90% of correctly categorized stimuli, using the same adaptive titration procedure as in experiment 1. b, Titration trials with confidence reports. 
Participants were asked to categorize the presented marble as light or dark, and report simultaneously their confidence level as rather high or rather low. 
Participants received auditory feedback after each titration trial. c, Relation between decision confidence and accuracy in titration trials. For each binned 
luminance, participants’ fraction of correct decisions for confident (green) and unconfident (red) trials (top panel), and participants’ fraction of confident 
decisions for correct (solid line) and error (thick dashed line) trials (bottom panel). Confidence is expressed relative to each participant’s mean confidence 
(thin dashed line). Shaded areas correspond to s.e.m. d, Predictions of optimal inference as a function of stimulus strength on the first trial following each 
reversal. Top: response reversal curves indicating the fraction of responses towards the new drawn bag surrounding each reversal. Bottom: response 
switch curves indicating the fraction of trial-to-trial response switches surrounding the same reversals. The reversal is represented by the thin dotted line. 
Dots indicate human data (group-level average), whereas lines indicate predictions of optimal inference. Error bars correspond to s.e.m. e, Predictions 
of the noisy inference model as a function of stimulus strength on the first trial following each reversal. Noisy inference captures well the accuracy of 
behaviour surrounding reversals (top), but overestimates the variability of behaviour (bottom). Same conventions as in d. Shaded areas correspond to 
s.e.m. f, Discrepancies between models and human behaviour. Top: overall accuracy of participants (grey dot with error bar indicate the mean and s.d. 
of all participants, light grey dots indicate single participants), optimal inference (red bar) and noisy inference (blue bar). Bottom: overall switch rate of 
participants, optimal inference and noisy inference. Despite their suboptimal accuracy, participants make response switches as often as optimal inference. 
Error bars on simulated noisy inference model (blue bars) correspond to s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1697

Articles
NaTure Human BehavIour
decrease the variability of beliefs and resulting responses, but also, 
counterintuitively, increases accuracy. For this purpose, we com-
pared the effects of the five tested belief stabilization strategies 
on accuracy across both experiments through simulations (Fig. 
8a). We found that all strategies decrease behavioural variability 
at the expense of lower accuracy, except for conditional inference 
which shows an inverted U-shaped relation with accuracy. The 
accuracy-optimizing value δ* of the reliability threshold (δ* = 1.281, 
associated with 5.5% more accurate responses) is associated with 
as much as 41.3% of discarded stimuli categorized with an over-
all 80% accuracy (Supplementary Fig. 8). This performance benefit 
of conditional inference is due to the combination of less variable 
beliefs (and responses) at the end of ‘episodes’—that is, successive 
draws from the same bag—and equally fast adaptation to reversals 
(Supplementary Fig. 8). By contrast, other belief stabilization strate-
gies trade less variable responses against slower adaptation to rever-
sals. A ‘soft’ version of the conditional inference model (Methods) 
that downweights the evidence that falls below the reliability thresh-
old rather than discarding it also predicts an inverted U-shaped 
relation with accuracy. However, it fails at predicting a decreased 
behavioural variability and explains human behaviour less accu-
rately than the conditional inference model (exceedance P < 0.001; 
Supplementary Figs. 9 and 10).
We measured this performance benefit of conditional inference in 
participants’ data by fitting a multiple regression model of accuracy 
as a function of each parameter: the hazard rate h (entered as a qua-
dratic effect as it is expected to show an inverted U-shaped relation 
with accuracy, maximal accuracy expected around the true value of 
the hazard rate, see Methods), the inference noise σinf (entered as a 
linear effect as it is expected to show a negative relation with accu-
racy) and the reliability threshold δ (entered as a quadratic effect 
as it is also expected to show an inverted U-shaped relation with 
accuracy; Fig. 8a). This multiple regression model provides an accu-
rate fit to participants’ data (Fig. 8b; r2 = 0.859, d.f. = 53, P < 0.001), 
and confirms the inverted U-shaped relation between reliability 
threshold and accuracy (quadratic coefficient b5 = −0.028 ± 0.009, 
mean ± s.e.m., t53 = −3.2, P = 0.002, 95% CI (−0.046, −0.011)). The 
accuracy-optimizing value of the reliability threshold estimated 
from the best-fitting model (δ* = 1.042 ± 0.174, mean ± s.e.m.) 
is consistent with simulations (Fig. 8a). We confirmed that the 
quadratic relation between reliability threshold observed in par-
ticipants’ data is predicted by simulations of the best-fitting condi-
tional inference model, by replacing participants’ accuracy with the  
accuracy of model simulations (Fig. 8c; b5 = −0.025 ± 0.006, 
t53 = −3.9, P < 0.001, 95% CI (−0.0383, −0.0123)). Implementing 
conditional inference with the optimal reliability threshold δ* is 
associated with comparable performance improvements in partici-
pants and simulations (participants: +3.2%; simulations: +5.5%). 
These findings confirm that conditional inference not only miti-
gates the variability of beliefs arising from imprecise inference, but 
also improves the accuracy of these beliefs by trading the costs of 
inference against its expected benefits based on the reliability of 
incoming sensory information.
Discussion
Human observers combine multiple pieces of sensory evidence 
to form or revise beliefs about the current uncertain state of their 
environment. These beliefs remain nonetheless imprecise, not only 
because of the expected uncertainty associated with each piece of 
evidence or the unexpected uncertainty associated with transitions 
between states13, but also due to the imprecision of the inference pro-
cess itself4–6. Variability in beliefs might therefore help adapt to new 
contingencies, but might also be mistaken for genuine changes in 
the environment and trigger unwarranted changes-of-mind. Here, 
we investigated whether and how human observers mitigate the 
trial-to-trial variability of their imprecise beliefs, by studying human 
behaviour in a volatile decision-making task. Using computational 
modelling, we found that humans stabilize their imprecise beliefs 
using an efficient ‘conditional’ strategy—whereby they discard pieces 
of sensory evidence that are not deemed as sufficiently reliable. We 
show that this conditional belief updating strategy is associated with 
large individual differences linked to participants’ perceptual confi-
dence, and improves the accuracy of resulting decisions.
It is well-known that human decisions show a suboptimal 
trial-to-trial variability under uncertainty5,6. This behavioural vari-
ability can arise from internal ‘noise’ located at different stages of 
information processing. Classical cognitive models consider behav-
ioural variability as a consequence of noise corrupting either sensory 
processing or the decision policy, in this later case by introducing a 
softmax at the action selection stage7,14,15. However, recent findings 
have shown that the large fraction of the observed behavioural vari-
ability arises from computation noise in inference4,6,16. Both policy 
noise and inference noise generate behavioural variability, but these 
two sources of noise differ regarding the trial-to-trial variability 
of underlying beliefs. Indeed, policy noise does not generate any 
trial-to-trial variability in beliefs but only variability in behaviour. 
70%
80%
90%
Stimulus strength
0
1.0
2.0
Reliability threshold δ
3.0
a
b
70%
80%
90%
Stimulus strength
0
0.2
0.4
0.6
0.8
1.0
Discard rate
0.879
0.892
0.640
r = 0.392
P = 0.033
–2.0
0
2.0
4.0
Confidence threshold δC
0
1.0
2.0
Reliability threshold δ
h
σ
δ
Model parameter
0
0.1
0.2
0.3
Variance explained
33.3%
28.3%
13.6%
0.800
Relation with confidence
Fig. 6 | Validation of specific predictions of conditional inference (n = 30). a, Decrease in evidence discard rate with stimulus strength. The reliability 
threshold does not vary with stimulus strength, resulting in discard rates that decrease with stimulus strength (one blue dot per participant). Black  
dots represent group-level means and error bars represent their associated standard deviations. Horizontal blue lines represent group-level medians.  
b, Selective relation between reliability and confidence criteria. Left: correlation between confidence threshold and reliability threshold across participants. 
As predicted by conditional inference, the reliability threshold estimated in the volatile decision-making task correlates positively with the confidence 
threshold estimated when categorizing isolated stimuli. Parameters are presented as mean ± s.d. of posterior distributions of each fit. Shaded area 
corresponds to the 95% confidence interval for the regression line. Right: variance of confidence threshold explained by each model parameter. The 
reliability threshold shares more variance with the confidence threshold than the other two model parameters. Bars correspond to r2 and error bars to the 
interquartile ranges of each r2 measure obtained through bootstrapping (n = 104).
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1698

Articles
NaTure Human BehavIour
By contrast, inference noise generates trial-to-trial variability in 
both beliefs and behaviour. Recent neurophysiological findings sup-
port the idea that the large moment-to-moment variability of neural 
activity in cortical areas which reflects evidence accumulation cor-
responds to genuine variability in beliefs17.
Large moment-to-moment fluctuations in beliefs are likely to 
be costly, both psychologically and neurally. At the psychological 
level, changes-of-mind require changes in behaviour, which entail 
increased cognitive control and slower response latencies. At the 
neural level, previous studies have shown that changes-of-mind are 
associated with strong increases in neural activity in the prefrontal 
cortex in humans18 and rodents19. We thus reasoned that humans 
may rely on a form of ‘belief stabilization’ strategy to mitigate the 
impact of inference noise on belief variability and prevent unwar-
ranted changes-of-mind. We found that human behaviour is less 
variable than what is predicted from the amount of inference noise 
that matches behavioural accuracy. To characterize how humans 
reduce the variability of their behaviour, we compared several sta-
bilization strategies at different processing stages. Some of them 
mitigate the variability of behaviour but not beliefs, whereas others 
stabilize the underlying beliefs11,12. We found that human observ-
ers use a ‘conditional’ strategy to stabilize their beliefs. This means 
that humans discard (ignore) a fraction of the available sensory 
evidence judged as too weak and unreliable. Interestingly, this 
strategy challenges the idea that more information is always bet-
ter in the presence of inference noise when performing a volatile 
decision-making task.
Previously described strategies typically reduce the variability 
of beliefs through some form of ‘confirmation bias’, either by shift-
ing the perception of sensory evidence in the direction of prior 
beliefs as in the ‘perceptual bias’ model that we have considered 
among alternative stabilization strategies, or by underweighting 
(or even discarding) the sensory evidence that is inconsistent with 
prior beliefs. In particular, recent work20,21 has identified such a 
‘stimulus-consistency’ bias mechanism during sequential cue com-
bination. This bias, which resembles a similar bias described dur-
ing reinforcement learning22, was observed in stable environments. 
In these conditions where the latent cause does not change, it was 
shown to increase accuracy by reducing decision sensitivity to mis-
leading sensory observations. By contrast, in volatile environments, 
the same bias typically decreases accuracy because inconsistent 
observations can signal a change in their latent cause, and should 
therefore not be underweighted23. Future work should further 
investigate the effect of task parameters on the stabilization strate-
gies deployed by humans to mitigate the negative effects of infer-
ence noise.
0.817
0
1.0
2.0
3.0
Reliability threshold δ
1.143
0
1.0
2.0
3.0
4.0
Inference noise σ
0.131
0.1
0.2
0.3
0.4
Hazard rate h
0
Probability density
0
1.0
2.0
3.0
Reliability threshold δ
0
0.1
0.2
0.3
0.4
Hazard rate h
r 2 = 0.050
P = 0.089
0
1.0
2.0
3.0
4.0
Inference noise σ
0
1.0
2.0
3.0
Reliability threshold δ
r 2 = 0.102
P = 0.014
0
0.1
0.2
0.3
0.4
Hazard rate h
0
1.0
2.0
3.0
4.0
Inference noise σ
r 2 = 0.109
P = 0.011
a
b
–4 –3 –2 –1 1
2
3
4
Trial position from reversal
4.2%
–4 –3 –2 –1 1
2
3
4
Trial position from reversal
22.5%
–4 –3 –2 –1 1
2
3
4
Trial position from reversal
0
0.2
0.4
0.6
0.8
1.0
Fraction reversed
48.7%
Reliability threshold
Hazard rate
Inference noise
c
–4 –3 –2 –1 1
2
3
4
24.8%
–4 –3 –2 –1 1
2
3
4
Low σ
High σ
14.0%
–4 –3 –2 –1 1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
Fraction switch
Low h
High h
41.1%
Low δ
High δ
Fig. 7 | Interindividual variability in conditional inference (n = 60). a, Distribution of conditional inference model parameter values across participants 
from both experiments. Best-fitting parameters and their median value (dotted lines) with density approximation (solid blue lines). b, Pairwise relations 
between the parameters of the conditional inference model. Parameters are only mildly correlated with one another. Parameters are presented as 
mean ± s.d. of posterior distributions of each fit. c, Distinct gradients of behavioural variability associated with each parameter of the conditional inference 
model (left: hazard rate; middle: inference noise; right: reliability threshold). Response switch curves (top) and response reversal curves (bottom) obtained 
by sorting participants in two median-split groups as a function of the best-fitting value of each parameter. Lines correspond to simulations of the 
best-fitting conditional inference model, whereas dots correspond to participants’ behaviour. Percentages indicate the variance in response switch curves 
(top row) and response reversal curves (bottom row) explained by each parameter. Shaded areas and error bars correspond to s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1699

Articles
NaTure Human BehavIour
In our task, tested participants discard about a third of presented 
stimuli, a surprisingly large fraction for stimuli categorized in isola-
tion with 80% overall accuracy in a forced-choice task. Importantly, 
the ‘lapse’ rate measured in the condition where participants cat-
egorize isolated stimuli is widely smaller than the ‘conditional dis-
card’ rate measured in the main task (lapse rate: 9.3%; conditional 
discard rate: 28.9%). This means that the conditional inference 
strategy observed in our task does not reflect lapses in attention. 
Consistently with the idea that apparent lapses in behaviour not 
only reflect inattention, recent work in mice has shown that lapses 
measured during perceptual decisions can reflect exploration24 or 
alternations between discrete behavioural strategies25. In our task, 
we propose that the discarding of unreliable stimuli is controlled 
by a general metacognitive process linked to perceptual confidence. 
Indeed, the reliability threshold used for discarding stimuli corre-
lates with the confidence threshold measured in the same partici-
pants during an independent task.
In addition, tethering inference to the reliability of incoming sen-
sory evidence shows positive effects as it reduces the cognitive costs 
of imprecise inference, in terms of unwarranted changes-of-mind 
as already mentioned, but also in terms of mental effort by waiv-
ing inference on a substantial fraction of trials. The fact that mental 
effort can be aversive enough for people to accept non-negligible 
levels of physical pain26 can thus partially explain why humans rely 
Human data: accuracy ~ b0 + b1 · h + b2 · h2 + b3 · σ + b4 · δ + b5 · δ2 
b
Bias strength λ
+0.1%
0
0.5
1.0
1.5
0.5
0.6
0.7
0.8
0.9
Fraction correct
Perceptual
bias
Lapse rate ρ
0
1.0
0.5
0.6
0.7
0.8
0.9
Inference
lapses
0.5
Reliability threshold δ
δ* = 1.281
+5.5%
0
1.0
2.0
3.0
0.5
0.6
0.7
0.8
0.9
Conditional
inference
Bias strength β
0
1.0
2.0
3.0
0.5
0.6
0.7
0.8
0.9
Repetition
bias
Lapse rate ε
0
1.0
0.5
0.6
0.7
0.8
0.9
Response
lapses
0.5
a
h* = 0.20
0
1.0
2.0
3.0
Reliability threshold δ
0.6
0.7
0.8
0.9
δ* = 1.04
0
1.0
2.0
3.0
4.0
Inference noise σ
0.6
0.7
0.8
0.9
0
0.1
0.2
0.3
0.4
Hazard rate h
0.6
0.7
0.8
0.9
Fraction correct
h* = 0.19
c
Model simulations: accuracy ~ b0 + b1 · h + b2 · h2 + b3 · σ + b4 · δ + b5 · δ2 
–0.04
–0.02
0
–0.04
–0.02
0
–0.04
–0.02
0
b2
b2
b3
b3
b5
b5
–4
–2
0
0
0.1
0.2
0.3
0.4
0.6
0.7
0.8
0.9
Fraction correct
Hazard rate h
0
1.0
2.0
3.0
4.0
0.6
0.7
0.8
0.9
Inference noise σ
0
1.0
2.0
3.0
0.6
0.7
0.8
0.9
Reliability threshold δ
δ* = 1.42
–0.02
0
–0.04
–2
–1
0
Fig. 8 | Increased decision accuracy through conditional inference. a, Simulated effects of response stabilization strategies on decision accuracy. Fraction 
of overall correct responses when increasing each stabilization parameter drops for all models except for the conditional inference model, for which it 
increases the accuracy by +5.5% for δ* = 1.28. Dots correspond to the best simulated accuracy. b, Observed effects of best-fitting model parameters on 
human decision accuracy. For each best-fitting conditional inference model parameter, corresponding human accuracy (dots) and robust regression (solid 
blue lines, r2 = 0.859, P < 0.001). Inverted U-shaped relation between reliability threshold and accuracy (negative quadratic coefficient b5, P = 0.002). 
Shaded area corresponds to the 95% confidence interval for predicted values. Parameters are presented as mean ± s.d. of posterior distributions and 
human accuracy as mean ± s.d. given the number of trials provided. Top right insets correspond to estimated regression coefficients presented as 
mean ± s.e.m. c, Predicted effects of best-fitting model parameters on modelled decision accuracy. For each best-fitting conditional inference model 
parameter, corresponding conditional inference model predicted accuracy (diamonds) and robust regression (solid blue lines). Inverted U-shaped relation 
between reliability threshold and accuracy (negative quadratic coefficient b5, P < 0.001). Shaded areas correspond to the 95% confidence interval for 
predicted values. Parameters are presented as mean ± s.d. of posterior distributions and vertical error bars correspond to the accuracy s.d. of best-fitting 
model simulations. Top right insets correspond to estimated regression coefficients presented as mean ± s.e.m.
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1700

Articles
NaTure Human BehavIour
on an efficient metacognitive strategy to reduce mental effort. We 
further show that conditional inference simultaneously increases 
the accuracy of decisions while decreasing mental effort, making it 
a win–win strategy in our standard reversal learning task.
Like most decision parameters27, conditional inference shows 
large individual differences across tested participants. We observed 
that the reliability threshold used to discard unreliable stimuli is 
associated with a specific behavioural gradient across participants. 
The fact that the position of individual participants on this gradient 
remains relatively stable across both experimental sessions indicates 
a genuine trait-like parameter. One important question concerns 
the relation between this trait-like parameter and other cognitive 
traits. We have shown that the reliability threshold used to discard 
stimuli correlates with the confidence threshold adopted by the 
same participants in a different task—another trait-like parameter 
which shows high test–retest reliability across experimental ses-
sions. This means that the reliability threshold could be related to 
transdiagnostic psychiatric symptom dimensions28 known to cor-
relate with confidence threshold in various tasks29.
In our task, we introduced expected uncertainty by degrad-
ing stimuli using sensory noise, but this is not the only way by 
which expected uncertainty can be introduced in decision tasks12. 
Indeed, existing tasks often introduce uncertainty by reducing the 
information conveyed by a single stimulus about its generative 
category—a form of uncertainty referred to as category ambigu-
ity. The reliability-contingent control of inference observed in our 
task has not been identified in previous tasks where, unlike the 
present task, the sensory reliability of presented stimuli is large 
and it is category ambiguity that is low4. Future work could inves-
tigate more explicitly the different strategies deployed for mitigat-
ing the impact of imprecise beliefs in conditions of high sensory 
noise versus high category ambiguity. Another important question 
concerns the neural processes that may underlie this conditional 
inference strategy. Our model is purely conceptual and suggests a 
form of hierarchical inference, in line with other proposed belief 
stabilization strategies11,12. In our model, this means that beliefs 
are updated downstream (and separately from) the categorization 
and evaluation of individual stimuli. Future work will be needed 
to investigate the possible neural mechanism underlying condi-
tional inference, which may be a form of ‘gating’—an all-or-none, 
non-linear filtering mechanism—that requires sufficiently large 
sensory responses to trigger changes in the downstream decision 
(belief updating) circuit.
Taken together, our results show that humans condition the 
imprecise update of their beliefs to the reliability of incoming sen-
sory information—an efficient metacognitive control process which 
not only prevents unwarranted changes-of-mind, but also reduces 
mental effort by waiving belief updating. Avoiding the mental effort 
spent on cognitive computations that are less likely to pay off (in 
this case, based on unreliable evidence) proves a surprisingly effec-
tive strategy that simultaneously increases the objective accuracy 
of resulting decisions—thereby bypassing the general cognitive 
trade-offs between the benefits and costs of cognitive operations 
described in the literature30.
Methods
Participants. Sixty healthy adult participants (30 females, age: 25.8 ± 3.9 years, all 
right-handed, experiment 1: n = 30, 15 females, age: 24.7 ± 3.9 years; experiment 
2: n = 30, 15 females, age: 27.16 ± 3.7 years) took part in the study. One participant 
was excluded from analyses due to poor performance (overall decision accuracy 
more than 3.5 s.d. below the group-level mean). Participants were screened for 
the absence of any history of neurological and psychiatric disease or any current 
psychiatric medication. All participants provided written informed consent, and 
received 45 euros as compensation for their participation after completing the 
second experimental session. The study followed guidelines from the Declaration 
of Helsinki and specific procedures which received ethical approval from relevant 
authorities (Comité de Protection des Personnes Ile-de-France VI, ID RCB: 
2007-A01125-48, 2017-A01778-45).
Task and procedure. Both experiments were based on the same reversal learning 
task. In repeated trials, participants were presented with visual cues described 
as ‘marbles’, which could be drawn either from a bag containing light marbles or 
a bag containing dark marbles. Participants had to infer the bag the marble was 
drawn from (light or dark). Participants were instructed that marbles were not 
drawn randomly and independently across trials, but from the same bag for a 
certain number of successive trials (that is, an episode) before being drawn from 
the other bag (that is, a generative category reversal). Participants were herewith 
instructed about the presence of reversal but did not know the number of trials (or 
episode length) before a reversal. The length of these episodes was drawn from a 
bounded exponential distribution, resulting in an approximately flat hazard rate—a 
procedure equivalent to a Markov process with fixed transition probability. Each 
marble corresponded to a two-tone disc with light and dark shades of grey, in 
different proportions and spatially scrambled over the surface of the disc. The disc 
was generated using Gaussian noise filtered through a two-dimensional Gaussian 
smoothing filter and eventually binarized accordingly to the expected proportions 
between the light and dark shades of grey. All stimuli were presented on a uniform 
medium grey background. In experiment 1, the relative proportions of light and 
dark shades of grey were adjusted using a titration procedure to reach 80% of 
marbles perceived as light for the light bag, and 80% of marbles perceived as dark 
for the dark bag. In experiment 2, three levels of difficulty were titrated for each 
bag to achieve correct stimulus identification of 70%, 80% and 90%, respectively. 
In this second experiment, participants were not explicitly instructed of the three 
difficulty levels.
The titration procedure preceded each reversal learning block, and 
corresponded to two adaptive psychophysical staircases31 adjusting the relative 
proportions of light and dark shades of grey in presented marbles. We ran two 
separate staircases because no symmetry was assumed: participants could have 
a biased perception towards the light or the dark category. The trials of the two 
staircases were randomly interleaved during the procedure. In experiment 1, each 
staircase converged towards a light/dark proportion, one proportion was used to 
generate the marbles populating the light and the other for marbles populating the 
dark bag, each corresponding to 80% accuracy (light bag: 52.3 ± 1.1%; dark bag: 
47.6 ± 1.0%). In experiment 2, an additional logistic regression was performed to 
extrapolate the light/dark proportions corresponding to 70% and 90% accuracy 
levels from the light/dark proportions corresponding to 80% accuracy (light bag: 
51.6 ± 1.4% for 70% accuracy, 52.6 ± 1.5% for 80% accuracy, 54.1 ± 1.7% for 90% 
accuracy; dark bag: 48.40 ± 1.3% for 70% accuracy, 47.4 ± 1.4% for 80% accuracy, 
45.9 ± 1.5% for 90% accuracy). The titration blocks were presented to participants as 
a distinct game (‘game 1’): participants were instructed to sort individual marbles, 
and informed that marbles were presented in random order (unlike the main task). 
Auditory feedback was provided at the end of each trial in titration blocks.
The reversal learning blocks were presented as ‘game 2’ with instructions to 
report whether the computer is drawing marbles from the light or the dark bag 
after the presentation of each marble. Unlike the titration blocks, no feedback 
was provided during the reversal learning blocks. The experiment consisted of 
16 blocks (eight blocks from the task condition described above, and eight blocks 
of another task condition not relevant for the current study), divided into two 
experimental sessions of eight blocks, each session lasting approximately 90 min 
and taking place on different days. Each reversal learning block consisted of 
80 trials. Experiment 1 consisted of two types of blocks: ‘low volatility’ blocks 
containing five reversals (that is, hazard rate h = 1/16) and ‘high volatility’ blocks 
containing 10 reversals (that is, hazard rate h = 1/8). Experiment 2 consisted 
of ‘high volatility’ blocks only. The first generative category of each block was 
counterbalanced pseudo-randomly across blocks and participants.
Participants were instructed that each marble consisted of both light and dark 
shades of grey spatially scrambled. They were also instructed that all marbles 
contained in the light bag were predominantly light, whereas all marbles contained 
in the dark bag were predominantly dark (Supplementary Fig. 12). Before the 
experiment, they performed a short training for both ‘games’ (titration and reversal 
learning blocks) to get familiarized with the stimuli and the difficulty of identifying 
this predominant dark/light colour due to the spatial scrambling and the short 
stimulus presentation time (83 ms).
The experiment was coded in MATLAB and run using Psychtoolbox-3 (ref. 32).  
Participants performed the experiment in a soundproof booth with their head 
positioned on a chin rest at 75 cm from a 24-inch LCD screen operating at 60 Hz 
with a resolution of 1920 × 1080 pixels.
Bayes-optimal inference. For each trial t, the decision-maker tries to find the 
associated hidden state corresponding to one of the two alternative categories c, 
ct = +1/ −1 (light or dark bag). At each trial, the belief about the current value of 
the hidden state is updated by combining the prior belief with the new incoming 
evidence according to Bayes rule. The normalized model of decisions between 
two alternatives is formalized in ref. 7, with the belief at trial t, Lt, defined as the 
logarithm of the posterior odds of the alternative categories accumulated until 
this trial. The sign of the log-odds belief indicates which category is more likely, 
whereas the magnitude of the log-odds belief indicates the strength of the belief in 
favour of the more likely hidden state. The update rule combining prior belief Lt−1 
and new incoming evidence LLRt is defined as follows:
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1701

Articles
NaTure Human BehavIour
Lt = ψ (Lt−1, h) + LLRt,
(1)
with ψ the time-varying prior expectation defined by
ψ (Lt−1, h) = Lt−1 + log
[
1−h
h
+ exp (−Lt−1)
]
−log
[
1−h
h
+ exp (Lt−1)
]
,
(2)
and h the hazard rate, the expected probability at each trial t that the category will 
switch, which corresponds to a non-linear integration leak. We also considered a 
linear approximation of the prior expectation function7 (Eq. 2) turning the model 
into a leaky evidence accumulator (Supplementary Fig. 2):
ψ (Lt−1, h) ≈(1 −2h) × Lt−1.
(3)
Suboptimal Bayesian inference. Each update of the log-odds belief with new 
stochastic incoming evidence LLRt is corrupted by internal Gaussian noise—
inference noise—with s.d. σinf turning the deterministic belief update equation 
(Eq. 1) into a stochastic draw from a normally distributed random variable:4,33
Lt ∼N (ψ (Lt−1, h) + LLRt, σ2
inf
) .
(4)
Model-based analysis of behaviour and stabilization strategies. We modelled 
human behaviour in the experimental condition using a hierarchical suboptimal 
Bayesian model with two free parameters h and σinf and with an additional 
model-specific stabilization parameter. We consider the sensory response to the 
stimulus presented at trial t as a normally distributed random variable generated 
by N (±1, σ2
sensory), depending on the true underlying category of the presented 
stimulus (+1 for light, –1 for dark). The s.d. of sensory noise σsensory is set to 
correspond to 80% of correct categorization—achieved through the online titration 
procedure.
In the first (‘categorized’) version of the model, this sensory response is then 
categorized as light (ct = +1) or dark (ct = −1) and expressed as a log-odds ratio. 
By design of the task, with p(ˆst > 0|ct = +1) being the conditional probability 
of the sensory response ˆst being positive given that the true category is light 
(ct = +1), and p(ˆst > 0|ct = −1) being the conditional probability of the same 
sensory response ˆst being positive given that the true category is dark (ct = −1), 
the log-likelihood ratio is ideally LLRt = log p(ˆst>0|ct=+1)
p(ˆst>0|ct=−1) = log 0.8
0.2 for evidence 
towards ct = +1 and, respectively, log 0.2
0.8 for evidence towards ct = −1. In the 
second (‘non-categorized’) version of the model, the log-odds LLRt is computed 
using the continuous normally distributed stimulus sensory response without any 
explicit categorization (Supplementary Fig. 9). The log-odds ratio between 
two symmetrical Gaussian distributions N (+1, σ2
sensory) and N (−1, σ2
sensory) 
or vice versa, simplifies to a scaled version of the sensory response by a factor 
2/σ2
sensory thus normally distributed with mean equal to ±2/σ2
sensory and s.d. equal 
to 2/σsensory. The combination of the evidence provided by the stimulus (LLRt) and 
the prior belief (Lt−1, also expressed as log-odds ratio and updated according to 
hazard rate h) is then corrupted by Gaussian inference noise of s.d. σinf following 
Eq. 4. Inference noise captures both internal variability in the perceived log-odds 
ratio LLRt and variability in the update of the belief Lt.
The response selection policy is based on the sign of the decision variable:  
the newly formed belief Lt. We considered a normative, ‘greedy’ selection process 
and a noisy selection process (Supplementary Fig. 1) modelled by sampling 
responses from the sign of a normally distributed decision variable with mean Lt 
and variance σ2
sel.
We introduced stabilizing parameters to the suboptimal Bayesian inference 
process described above, operating at different stages of information processing.
1. The perceptual bias model, controlled by a prior bias strength λ, shifts 
the sensory representation of the stimulus already expressed as log-odds 
ˆs ∼N
(
±2/σ2
sensory, (2/σsensory
)2)
 towards the prior belief Lt−1:
ˆs ∼N
(
±2/σ2
sensory, (2/σsensory
)2)
+ λ × Lt−1.
(5)
In this case, the log-likelihood ratio differs from ideal as the integration range 
is shifted by λ × Lt−1.
2. The inference lapse model, controlled by a fraction of lapses ρlapse, ignores a 
fraction of the stimuli whose evidence is not used to update the current belief:
Ltlapse = ψ (Ltlapse−1, h) .
(6)
3. The conditional inference model, controlled by a reliability threshold δ, 
uses only the stimuli whose sensory responses exceed a fixed threshold, |ˆs| > δ, to 
update the current belief:
Lt|ˆs|>δ = ψ
(
Lt|ˆs|>δ , h
)
+ LLRt.
(7)
In this case, the log-likelihood ratio LLRt accounts for the presence of the 
reliability threshold by integrating conditional likelihoods above the reliability 
threshold (instead of zero for the standard model). If the sensory response does not 
exceed the reliability threshold, the stimulus is ignored, leading to:
Lt|ˆs|<δ = ψ
(
Lt|ˆs|<δ−1, h
)
.
(8)
A discard rate—corresponding to the fraction of unreliable evidence not used 
for belief update—can be derived by integrating the normal distribution function 
N (±2/σ2
sensory, (2/σsensory
)2) on the remaining range [−δ; + δ].
4. The confirmation bias model, controlled by a bias strength β, operates at 
the selection stage by systematically shifting the decision criterion in favour of the 
previous response:
rt = sign (Lt −β × rt−1) .
(9)
5. The response lapse model, controlled by a lapse rate ε, makes a fraction of 
‘blind’ repetitions of the previous response irrespective of the current belief:
rtlapse = rtlapse−1.
(10)
We considered a ‘soft’ version of the conditional inference model 
(Supplementary Figs. 9 and 10), controlled by the same reliability threshold δ, not 
discarding but downweighting the stimuli whose sensory responses do not exceed 
the threshold. In this model, inference is performed at every trial but with two 
distinctly weighted log-likelihood ratio LLRt, the first integrating likelihoods below 
and the second integrating likelihoods above the reliability threshold.
Fitting procedure. Due to the presence of internal noise during sensory processing 
and hidden-state inference, which propagates across trials, no solution for model 
likelihoods can be derived analytically. We therefore used simulation-based 
methods to obtain noisy likelihoods for tested sets of parameter values, which 
were fed to specific fitting algorithms capable of handling such noisy likelihood 
functions.
Instead of fitting the candidate models to all choices using simulation-based 
methods, we focused on the two behavioural signatures characteristic of reversal 
learning behaviour: the response reversal curve and the response switch curve. 
This focused fitting procedure aimed at testing which of the tested candidate 
models can best explain specifically our behavioural effects of interest. Note 
that fits to all choices yield the same results (Supplementary Fig. 11). We fitted 
the parameter values (h, σinf and the optional stabilizing parameter) which best 
explained these two psychometric curves, both evaluated on four trials preceding 
and four trials following a reversal, for a total of eight trials per reversal for each 
metric. We conducted model recovery analyses, detailed below, to ensure the 
reliability of the simulation-based fitting method outlined above.
In practice, we simulated model responses (n = 1,000) to the sequences of 
trials presented to participants, we then derived the corresponding mean and 
s.d. of reversal and switch curves (modelled as normally distributed variables at 
each trial) and estimated the log-likelihood of observed (participant) reversal and 
switch curves given model simulations. We combined the log-likelihood estimate 
with prior distributions on parameter values to get a log-posterior estimate, whose 
prior distributions over parameters were defined as truncated β and γ distributions 
(h: β distribution with shape parameters α = 2 and β = 18, range [0,0.5]; σinf
: γ distribution with shape parameter k = 4 and scale parameter θ = 0.25, range 
[0,5]; λ and δ: γ distribution with shape parameter k = 1 and scale parameter 
θ = 0.75, range [0,5]; ρlapse and ε: β distribution with shape parameters α = 1 
and β = 9, range [0,1]; β: γ distribution with shape parameter k = 1 and scale 
parameter θ = 0.25, range [0,5]). In the first experiment, we verified for the 
winning model that using looser prior distributions did not change the best-fitting 
parameter values (Spearman correlations: h: ρ = 0.779, P < 0.001, 95% CI (0.650, 
0.784); σinf: ρ = 0.854, P < 0.001, 95% CI (0.763, 0.862); δ: ρ = 0.834, P < 0.001, 95% 
CI (0.670, 0.843); differences: h: t28 = 0.508, P = 0.615, Cohen’s d = 0.094, 95% CI 
(−0.022, 0.013), BF01 = 4.497; σinf: t28 = 0.863, P = 0.395, Cohen’s d = 0.16, 95% CI 
(−0.349, 0.142), BF01 = 3.603; δ: t28 = 1.152, P = 0.259, Cohen’s d = 0.214, 95% CI 
(−0.326, 0.091), BF01 = 2.778).
The unnormalized log-posterior is given as argument for the Variational 
Bayesian Monte Carlo (VBMC) algorithm34 (version 1.0; https://github.com/
lacerbi/vbmc) returning a variational approximation of the full posterior and 
a lower bound on the log-marginal likelihood. The VBMC algorithm supports 
stochastic estimates of the log-posterior and we provide estimates of its s.d. by 
bootstrapping the s.d. of the estimated log-likelihood. We finally take the posterior 
mean to obtain best-fitting parameter values.
For the second experiment, we computed three distinct reversal curves and 
three distinct switch curves depending on the strength of the stimulus presented 
on the first trial following a reversal, for both model simulations and human data. 
We summed the log-likelihood across these six metrics.
We used the lower bound of the marginal likelihood as model evidence 
for Bayesian Model Selection (BMS) analysis. BMS was conducted using a 
random-effects approaches assuming that different participants may rely 
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1702

Articles
NaTure Human BehavIour
on different models, and consists of estimating the distribution over models 
that participants draw from. We used the Dirichlet parameterization of the 
random-effects approach implemented in SPM12 (refs. 35,36) with default Dirichlet 
prior set to one—corresponding to a uniform distribution (http://www.fil.ion.ucl.
ac.uk/spm).
Our approach focusses on behaviour around reversals through the two 
psychometric curves described above. Alternatively, we considered fitting human 
data using per-trial choice log-likelihoods using a particle filter and the same 
VBMC algorithm. In this case, each trial—and not only trials around reversals—
equally contributes to the goodness of fit, rather than focusing on our behavioural 
effects of interest around reversals. Yet, the more responses considered, the more 
likely a response can reflect a lapse and be a blind repetition of the previous 
response. To prevent the fitting procedure to try to fit those responses with the 
same importance as the other responses—especially the ones around reversal—
ergo to prevent those lapse responses to corrupt the goodness of fit, we included a 
lapse rate parameter ε as additional parameter to each of the first four stabilizing 
models (the fifth previously described candidate model being fully formalized by 
the lapse rate parameter ε). The prior distributions on parameter values remain the 
same as previously reported, except for the additional parameter ε meant to be kept 
low (β distribution with shape parameters α = 1 and β = 39, range [0,1]). The 
analysis of model fits to all choices using the same BMS yielded the same results 
as the ones obtained from model fits to behavioural effects of interest using our 
simulation-based approach (Supplementary Fig. 11).
Model recovery procedure. Model simulations were done for each participant’s 
true stimulus sequences using parameters corresponding to the mean of their 
respective prior distributions. We used prior distribution to have an ex ante 
assessment that the constructed models are well-posed. Each simulation was fitted 
by a given model and we used the Dirichlet parameterization as described above 
to estimate the distribution over recovered models. We then sampled 106 times 
from the estimated Dirichlet distributions and computed column-wise (for each 
recovered model) the exceedance probability of each simulated model.
Confidence fitting procedure. We modelled human behaviour in titration trials 
using three free parameters, the sensory noise s.d. σsensory, the confidence noise 
s.d. σconfidence and the confidence threshold δconfidence. Each stimulus sensory 
response at trial t is modelled as a normally distributed random variable generated 
by N (+1 or −1, σ2
sensory) depending on the staircase it originates from. Based on 
this sensory response, the noisy confidence is reported with respect to a confidence 
threshold δconfidence. We fitted this model using a particle filter (n = 1,000) to the 
factorized responses to titration trials (light and unconfident; light and confident; 
dark and unconfident; dark and confident) using VBMC to maximize the 
log-likelihood of factorized response probabilities.
PCA. PCA was performed on participants’ response reversal and response switch 
curves using MATLAB in-built function which centres the data and uses the 
singular value decomposition algorithm. Based on the first three obtained PC 
scores, we estimated the explained variance in reversal and switch curves through 
bootstrapping (n = 10,000).
Multiple regression model. We predicted human and conditional inference model 
accuracies as a function of each parameter using a multiple regression model. 
We chose to include the perceived hazard rate h and the reliability threshold δ 
up to the second-order in the multiple regression, but the inference noise σinf 
appears only up to the first-order as it only corrupts accumulation of evidence. 
Second-order dependencies, if any, allow exhibition of inverted U-shaped relations 
with accuracy—ergo a beneficial effect on accuracy. As we investigate the benefits 
of the conditional inference strategy, the reliability threshold δ was included up to 
the second-order, and showed indeed an inverted U-shaped relation with accuracy, 
no discarding of evidence corresponding to a classical suboptimal inference model 
and a large δ implying omission of almost all evidence. The multiple regression 
model was fitted using the MATLAB in-built function fitnlm.m with robust fitting 
(weighted least-squares).
Statistical testing and reproducibility. Unless noted otherwise, statistical analyses 
of differences between scalar metrics in both experiments relied on two-tailed 
parametric tests (classical and Bayesian paired t-tests, repeated-measures ANOVA) 
between tested participants and model predictions in a paired manner using 
MATLAB functions, simple_mixed_anova.m37 and JASP38. For repeated-measures 
ANOVA, reported P values are Greenhouse–Geisser corrected. Given our sample 
sizes, these statistical tests were applied outside the small-sample regime. Data 
were not explicitly tested for normality. Reported statistics are not corrected for 
multiple comparisons. Given the absence of prior effect sizes, we chose a sample 
size (n = 30 for each experiment) that exceeded the average sample size used in 
human psychophysical studies with similar trial number per participant (n = 640 
across two sessions).
Reporting summary. Further information on research design is available in the 
Nature Research Reporting Summary linked to this article.
Data availability
The datasets generated during and analysed during the current study are freely 
available online on figshare: https://figshare.com/projects/Efficient_stabilization_
of_imprecise_statistical_inference_through_conditional_belief_updating/140170. 
Source data are provided with this paper.
Code availability
The analysis code supporting the reported findings is freely available online on 
github: https://github.com/juliedrevet/CONDINF.
Received: 19 July 2021; Accepted: 11 August 2022;  
Published online: 22 September 2022
References
	1.	 Wald, A. & Wolfowitz, J. Optimum character of the sequential probability 
ratio test. Ann. Math. Stat. 19, 326–339 (1948).
	2.	 Bogacz, R., Brown, E., Moehlis, J., Holmes, P. & Cohen, J. D. The physics of 
optimal decision making: a formal analysis of models of performance in 
two-alternative forced-choice tasks. Psychol. Rev. 113, 700–765 (2006).
	3.	 Green, D. M. & Swets, J. A. Signal Detection Theory and Psychophysics (John 
Wiley, 1966).
	4.	 Drugowitsch, J., Wyart, V., Devauchelle, A.-D. & Koechlin, E. Computational 
precision of mental inference as critical source of human choice 
suboptimality. Neuron 92, 1398–1411 (2016).
	5.	 Wyart, V. & Koechlin, E. Choice variability and suboptimality in uncertain 
environments. Curr. Opin. Behav. Sci. 11, 109–115 (2016).
	6.	 Findling, C. & Wyart, V. Computation noise in human learning and 
decision-making: origin, impact, function. Curr. Opin. Behav. Sci. 38,  
124–132 (2021).
	7.	 Glaze, C. M., Kable, J. W. & Gold, J. I. Normative evidence accumulation in 
unpredictable environments. eLife 4, 1–27 (2015).
	8.	 Murphy, P. R., Wilming, N., Hernandez-Bocanegra, D. C., Prat-Ortega, G. & 
Donner, T. H. Adaptive circuit dynamics across human cortex during 
evidence accumulation in changing environments. Nat. Neurosci. 24,  
987–997 (2021).
	9.	 Palminteri, S., Wyart, V. & Koechlin, E. The importance of falsification in 
computational cognitive modeling. Trends Cogn. Sci. 21, 425–433 (2017).
	10.	Stocker, A. A. & Simoncelli, E. P. Noise characteristics and prior expectations 
in human visual speed perception. Nat. Neurosci. 9, 578–585 (2006).
	11.	Luu, L. & Stocker, A. A. Post-decision biases reveal a self-consistency 
principle in perceptual inference. eLife 7, e33334 (2018).
	12.	Lange, R. D., Chattoraj, A., Beck, J. M., Yates, J. L. & Haefner, R. M. A 
confirmation bias in perceptual decision-making due to hierarchical 
approximate inference. PLoS Comput. Biol. 17, e1009517 (2021).
	13.	Soltani, A. & Izquierdo, A. Adaptive learning under expected and unexpected 
uncertainty. Nat. Rev. Neurosci. 20, 635–644 (2019).
	14.	Griffiths, T. L. & Tenenbaum, J. B. Optimal predictions in everyday cognition. 
Psychol. Sci. 17, 767–773 (2006).
	15.	Sutton, R. S. & Barto, A. G. Reinforcement Learning: An Introduction (MIT 
Press, 1998).
	16.	Findling, C., Skvortsova, V., Dromnelle, R., Palminteri, S. & Wyart, V. 
Computational noise in reward-guided learning drives behavioral variability 
in volatile environments. Nat. Neurosci. 22, 2066–2077 (2019).
	17.	Peixoto, D. et al. Decoding and perturbing decision states in real time. Nature 
591, 604–609 (2021).
	18.	Donoso, M., Collins, A. G. E. & Koechlin, E. Foundations of human 
reasoning in the prefrontal cortex. Science 344, 1481–1486 (2014).
	19.	Karlsson, M. P., Tervo, D. G. R. & Karpova, A. Y. Network resets in medial 
prefrontal cortex mark the onset of behavioral uncertainty. Science 338, 
135–139 (2012).
	20.	Glickman, M., Moran, R. & Usher, M. Evidence integration and decision 
confidence are modulated by stimulus consistency. Nat. Hum. Behav. 6, 
988–999 (2022).
	21.	Salvador, A. et al. Premature commitment to uncertain decisions during 
human NMDA receptor hypofunction. Nat. Commun. 13, 338 (2022).
	22.	Lefebvre, G., Lebreton, M., Meyniel, F., Bourgeois-Gironde, S. & Palminteri, 
S. Behavioural and neural characterization of optimistic reinforcement 
learning. Nat. Hum. Behav. 1, 1–9 (2017).
	23.	Lefebvre, G., Summerfield, C. & Bogacz, R. A normative account of 
confirmation bias during reinforcement learning. Neural Comput. 34, 
307–337 (2022).
	24.	Pisupati, S., Chartarifsky-Lynn, L., Khanal, A. & Churchland, A. K. Lapses in 
perceptual decisions reflect exploration. eLife 10, e55490 (2021).
	25.	Ashwood, Z. C. et al. Mice alternate between discrete strategies during 
perceptual decision-making. Nat. Neurosci. 25, 201–212 (2022).
	26.	Vogel, T. A., Savelson, Z. M., Otto, A. R. & Roy, M. Forced choices  
reveal a trade-off between cognitive effort and physical pain. eLife 9,  
e59410 (2020).
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1703

Articles
NaTure Human BehavIour
	27.	Moutoussis, M. et al. Decision-making ability, psychopathology, and brain 
connectivity. Neuron 109, 2025–2040.e7 (2021).
	28.	Gillan, C. M., Kosinski, M., Whelan, R., Phelps, E. A. & Daw, N. D. 
Characterizing a psychiatric symptom dimension related to deficits in 
goal-directed control. eLife 5, e11305 (2016).
	29.	Rouault, M., Seow, T., Gillan, C. M. & Fleming, S. M. Psychiatric symptom 
dimensions are associated with dissociable shifts in metacognition but not 
task performance. Biol. Psychiatry 84, 443–451 (2018).
	30.	Shenhav, A., Botvinick, M. M. & Cohen, J. D. The expected value of control: 
an integrative theory of anterior cingulate cortex function. Neuron 79, 
217–240 (2013).
	31.	Kaernbach, C. Simple adaptive testing with the weighted up-down method. 
Percept. Psychophys. 49, 227–229 (1991).
	32.	Kleiner, M. et al. What’s new in Psychtoolbox-3. Perception 36, 1–16 (2007).
	33.	Weiss, A., Chambon, V., Lee, J. K., Drugowitsch, J. & Wyart, V. Interacting 
with volatile environments stabilizes hidden-state inference and its brain 
signatures. Nat. Commun. 12, 2228 (2021).
	34.	Acerbi, L. in Advances in Neural Information Processing Systems 33 (eds 
Larochelle, H. et al.) 8211–8222 (Curran Associates, 2020).
	35.	Stephan, K. E., Penny, W. D., Daunizeau, J., Moran, R. J. & Friston,  
K. J. Bayesian model selection for group studies. NeuroImage 46,  
1004–1017 (2009).
	36.	Rigoux, L., Stephan, K. E., Friston, K. J. & Daunizeau, J. Bayesian model 
selection for group studies - revisited. NeuroImage 84, 971–985 (2014).
	37.	Caplette, L. Simple RM/Mixed ANOVA for any design. MATLAB Central File 
Exchange https://www.mathworks.com/matlabcentral/fileexchange/64980-simp
le-rm-mixed-anova-for-any-design (2022).
	38.	JASP Team. JASP v.0.16 https://jasp-stats.org/ (2021).
Acknowledgements
We thank B. De Martino and M. Usher for their insightful comments and suggestions 
during peer review. This work was supported by the European Research Council 
(starting grant No. ERC-StG-759341 to V.W.), the National Institute of Mental Health 
(US–France collaborative research grant No. 1R01MH115554-01 to J.Drugowitsch and 
V.W.) and the Agence Nationale de la Recherche (grant No. ANR-17-NEUC-0001-02 to 
J.Drugowitsch and V.W., and a department-wide grant No. ANR-17-EURE-0017). The 
funders had no role in study design, data collection and analysis, decision to publish or 
preparation of the manuscript.
Author contributions
J.Drevet contributed to conceptualization, methodology, software, validation, formal 
analysis, investigation, resources, data curation, writing—original draft, writing—
review and editing, and visualization. J.Drugowitsch contributed to conceptualization, 
methodology, writing—review and editing, supervision, project administration and 
funding acquisition. V.W. contributed to conceptualization, methodology, software, 
validation, formal analysis, resources, writing—original draft, writing—review and 
editing, visualization, supervision, project administration and funding acquisition.
Competing interests
The authors declare no competing interests.
Additional information
Supplementary information The online version contains supplementary material 
available at https://doi.org/10.1038/s41562-022-01445-0.
Correspondence and requests for materials should be addressed to Julie Drevet or  
Valentin Wyart.
Peer review information Nature Human Behaviour thanks Benedetto De Martino and 
Marius Usher for their contribution to the peer review of this work. Peer reviewer reports 
are available.
Reprints and permissions information is available at www.nature.com/reprints.
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in 
published maps and institutional affiliations.
Springer Nature or its licensor holds exclusive rights to this article under a publishing 
agreement with the author(s) or other rightsholder(s); author self-archiving of the 
accepted manuscript version of this article is solely governed by the terms of such 
publishing agreement and applicable law.
© The Author(s), under exclusive licence to Springer Nature Limited 2022
Nature Human Behaviour | VOL 6 | December 2022 | 1691–1704 | www.nature.com/nathumbehav
1704

1
nature portfolio  |  reporting summary
March 2021
Corresponding author(s):
Julie Drevet 
Valentin Wyart
Last updated by author(s): Jul 5, 2022
Reporting Summary
Nature Portfolio wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency 
in reporting. For further information on Nature Portfolio policies, see our Editorial Policies and the Editorial Policy Checklist.
Statistics
For all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.
n/a Confirmed
The exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement
A statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly
The statistical test(s) used AND whether they are one- or two-sided 
Only common tests should be described solely by name; describe more complex techniques in the Methods section.
A description of all covariates tested
A description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons
A full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) 
AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals)
For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted 
Give P values as exact values whenever suitable.
For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings
For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes
Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated
Our web collection on statistics for biologists contains articles on many of the points above.
Software and code
Policy information about availability of computer code
Data collection
The experiment was coded in MATLAB R2018b and run using Psychtoolbox-3 (Kleiner et al., 2007). Participants performed the experiment in a 
soundproof booth with their head positioned on a chin rest at 75 cm from a 24-inch LCD screen operating at 60 Hz with a resolution of 1920 × 
1080 pixels.
Data analysis
The model parameters were fitted using the Variational Bayesian Monte Carlo (VBMC) algorithm (version 1.0; Acerbi, 2020; https:// 
github.com/lacerbi/vbmc). The random-effects Bayesian model selection procedure was implemented in SPM12 (Wellcome Center for Human 
Neuroimaging; http://www.fil.ion.ucl.ac.uk/spm). The custom scripts used to analyze the behavioral data were written using MATLAB R2018b-
R2020a and are freely available on github: https://github.com/juliedrevet/CONDINF.
For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and 
reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Portfolio guidelines for submitting code & software for further information.

2
nature portfolio  |  reporting summary
March 2021
Data
Policy information about availability of data
All manuscripts must include a data availability statement. This statement should provide the following information, where applicable: 
- Accession codes, unique identifiers, or web links for publicly available datasets 
- A description of any restrictions on data availability 
- For clinical datasets or third party data, please ensure that the statement adheres to our policy 
 
The datasets generated during and analyzed during the current study is freely available online on figshare: 
https://figshare.com/projects/Efficient_stabilization_of_imprecise_statistical_inference_through_conditional_belief_updating/140170
Human research participants
Policy information about studies involving human research participants and Sex and Gender in Research. 
Reporting on sex and gender
Sixty healthy adult participants (30 females, age: 25.8 ± 3.9 years, all right-handed) took part in the study: 
Experiment 1: N = 30, 15 females (self-reported gender), age: 24.7 ± 3.9 years. 
Experiment 2: N = 30, 15 females (self-reported gender), age: 27.16 ± 3.7 years. 
Participants were screened for the absence of any history of neurological and psychiatric disease or any current psychiatric 
medication. All subjects had normal or corrected-to-normal vision. 
No sex- and gender-based analyses have been performed because we compare conditions in a within-subject design.
Population characteristics
See above.
Recruitment
Participants were recruited through online posting on the public mailing list from the Relais d'Information en Sciences 
Cognitives (RISC) in France. Subscribers to the public mailing list are typically young adults (university students in particular) 
in the age range that was targeted for our experiment (18-35 years). We do not expect any self-selection biases that could 
impact results.
Ethics oversight
All participants provided written informed consent. The study followed guidelines from the Declaration of Helsinki and 
specific procedures which received ethical approval from relevant authorities (Comité de Protection des Personnes Ile-de- 
France VI, ID RCB: 2017-A01778-45).
Note that full information on the approval of the study protocol must also be provided in the manuscript.
Field-specific reporting
Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.
Life sciences
Behavioural & social sciences
 Ecological, evolutionary & environmental sciences
For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf
Behavioural & social sciences study design
All studies must disclose on these points even when the disclosure is negative.
Study description
Across two independent datasets, participants were asked to play a sequential categorization reversal learning task based on 
carefully titrated noisy visual stimuli. The staircase procedure took place on separate blocks. To investigate how participants mitigate 
the significant costs of imprecise cognitive computations, we used computational modelling based on a noisy Bayesian inference 
process and compared participants' reversal learning behavior both qualitatively and quantitatively to the one predicted by five 
candidate models.
Research sample
Sixty healthy adult participants (30 females, age: 25.8 ± 3.9 years, all right-handed, Experiment 1: N = 30; Experiment 2: N = 30) took 
part in the study. One participant was excluded from analyses due to poor performance (overall decision accuracy more than 3.5 s.d. 
below the group-level mean). Participants were screened for the absence of any history of neurological and psychiatric disease or any 
current psychiatric medication. All subjects had normal or corrected-to-normal vision. No statistical methods were used to pre-
determine sample sizes but our sample sizes are similar or larger to those reported in previous publications (Drugowitsch, J., Wyart, V 
et al., 2016; Urai, A.E. et al. 2017).
Sampling strategy
No statistical methods were used to pre-determine sample sizes but our sample size (N = 30 for each experiments) matches the 
commonly accepted good practices in this field. In particular, the chosen sample size was determined a priori for both experiments. 
The eight blocks of the main task consisted of 640 trials and were interleaved with eight blocks for the titration procedure (400 trials 
on the first session block and 60 trials for the remaining blocks). The first generative category was counter-balanced pseudorandomly 
across blocks and participants. Given the absence of prior effect sizes, we chose a sample size (N = 30 for each experiment) which 

3
nature portfolio  |  reporting summary
March 2021
exceeded the average sample size used in human psychophysical studies with similar trial number per participant (N = 640 across two 
sessions).
Data collection
The experiment was coded in MATLAB R2018b and run using Psychtoolbox-3 (Kleiner et al., 2007). Participants performed the 
experiment in a soundproof booth with their head positioned on a chin rest at 75 cm from a 24-inch LCD screen operating at 60 Hz 
with a resolution of 1920 × 1080 pixels. Pupillometric signals were collected using an eye-tracker EyeLink-1000 (SR Reasearch). 
Pupillometric signals were not analyzed in this paper. No one was present besides the experimenter and the participant during data 
collection. The experimenter was not blinded to experimental condition or study hypothesis. 
Timing
The data for experiment 1 (N = 30 participants) was collected between November 2018 and January 2019. 
The data for experiment 2 (N = 30 participants) was collected between August 2019 and September 2019.
Data exclusions
One participant was excluded from analyses due to poor performance (overall decision accuracy more than 3.5 s.d. below the 
grouplevel mean).
Non-participation
N=3 participants dropped out after the first session of the experiment because of very low-quality pupillometric signals (unable to 
reduce blinks, pupillometry wad not analyzed in the current paper). They were compensated for their participation.
Randomization
Participants were not allocated into distinct experimental groups.  
We used a within-subject design, the main task blocks and the titration blocks were distinct in the instructions provided to the 
participants, and they were thus by definition not blind to participants.
Reporting for specific materials, systems and methods
We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, 
system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response. 
Materials & experimental systems
n/a Involved in the study
Antibodies
Eukaryotic cell lines
Palaeontology and archaeology
Animals and other organisms
Clinical data
Dual use research of concern
Methods
n/a Involved in the study
ChIP-seq
Flow cytometry
MRI-based neuroimaging

