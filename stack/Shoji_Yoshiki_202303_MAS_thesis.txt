A maximum entropy principle for the brain
by
Yoshiki Shoji
Supervised by Professor Gabriele M. T. D’Eleuterio
A thesis submitted in conformity with the requirements
for the degree of Masters of Applied Science
Institute for Aerospace Studies
University of Toronto
© Copyright 2023 by Yoshiki Shoji

A maximum entropy principle for the brain
Yoshiki Shoji
Masters of Applied Science
Institute for Aerospace Studies
University of Toronto
2023
Abstract
In this work, we attempt to provide a theoretical rationale, rooted on biological grounds, for the
anatomical organization of neurons in the brain. We propose a maximum entropy principle
for the brain, inspired by Merzenich’s work on neuroplasticity and Hebb’s and Edelman’s
postulate for brain development. We show that when one maximizes the joint entropy of
neuronal diameter and length constrained by neurophysiological elements of power, resource,
space, and time, one arrives at a maximum entropy joint distribution conforming to a joint
gamma distribution often reported in the literature. Then, using graph theory, we show how
biological neuronal networks may self-organize topologically to maximize entropy and exhibit
properties of a Rentian scaled small-world architecture to accompany learning and memory
formation often observed in in vivo and in vitro neuronal networks across different species.
This thesis is an attempt to show how the brain unfolds in a structured and lawful manner
such that it embeds these laws into its anatomy to make learning and memory formation
possible. It attempts to show that these fundamental elements of everyday life are mapped to
the structural and topological level, which can be explained through an inference model from
maximizing Shannon’s entropy subject to biological constraints. In the hope of advancing
the engineering of truly intelligent robotics, we believe that translating brain dynamics with
mathematical and physical laws can pave the way for the future.
ii

Acknowledgements
The research included in this thesis could not have been performed if not for the assistance,
patience, and support of many individuals. I would like to extend my gratitude, first and
foremost, to my thesis advisor, Professor Gabriele M. T. D’Eleuterio, for mentoring me over
the course of my undergraduate and graduate studies. It was because of him I was exposed
to the elegance of abstract mathematics, reaching the fields of robotics and dynamics. He
has also helped me through difficult times over the course of the analysis and the writing of
the thesis, and for that, I sincerely thank him for his confidence in me. Without Gabe, this
research would not have been possible. Finally, with the support of my peers and family, who
both made sacrifices for me to pursue my academic career, I sincerely thank you. Enjoy!
iii

Contents
1
Introduction
2
2
Architecture of the mind
6
2.1
The dynamic brain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.2
What is a neuron?
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.3
Myelinated and unmyelinated neurons
. . . . . . . . . . . . . . . . . . . . . .
10
2.4
Brain maps
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.4.1
Topographic organization of brain maps
. . . . . . . . . . . . . . . . .
11
2.4.2
Neuroplasticity: The dynamics governing brain maps . . . . . . . . . .
13
2.5
Homeostasis, plasticity, and the brain . . . . . . . . . . . . . . . . . . . . . . .
15
3
Designing the mind
17
3.1
Hebbian theory: A guide for learning and memory . . . . . . . . . . . . . . . .
17
3.2
Edelman’s theory: A guide to the global functioning of brain networks . . . . .
19
3.3
Bridging Hebb’s and Edelman’s theory of brain development . . . . . . . . . .
22
4
Connectomics: Graph theory of neuronal networks
24
4.1
A primer on graph theory
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
4.2
Path-length . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
4.3
Clustering coefficient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
4.4
Rent’s rule: Rentian scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
4.5
Watts–Strogatz model: The small-world network . . . . . . . . . . . . . . . . .
32
4.6
The next line of attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
5
Shannon’s entropy – A mathematical treatise on information
35
5.1
A Primer on probability theory
. . . . . . . . . . . . . . . . . . . . . . . . . .
37
5.2
Defining Shannon’s entropy
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
5.2.1
Shannon’s discrete entropy . . . . . . . . . . . . . . . . . . . . . . . . .
38
5.2.2
Example: Intuition . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
iv

5.2.3
Example: Entropy of a discrete uniform distribution . . . . . . . . . . .
39
5.2.4
Shannon’s differential entropy . . . . . . . . . . . . . . . . . . . . . . .
40
5.2.5
Example: Entropy of an independent random point process . . . . . . .
41
5.3
Mutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
5.3.1
Example: Mutual information of Gaussian channels . . . . . . . . . . .
42
6
Constraining the brain
44
6.1
Principle of constrained maximum entropy . . . . . . . . . . . . . . . . . . . .
45
6.1.1
Example: The maximum entropy distribution subject to constrained
variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
6.1.2
Example: A universal model of single-unit sensory receptor action . . .
48
6.2
Neurobiological constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
6.2.1
Action potential power constraint . . . . . . . . . . . . . . . . . . . . .
51
6.2.2
The Oka-Ikeda g-ratio constraint: Quantifying the tradeoff between un-
myelinated and myelinated neurons . . . . . . . . . . . . . . . . . . . .
57
6.2.3
Distance-dependent synaptic connectivity constraint . . . . . . . . . . .
58
6.2.4
Timescale-dependent synaptic connectivity constraint . . . . . . . . . .
60
6.3
The next line of attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
7
A Maximum entropy principle for the brain
65
7.1
Set of theoretical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
7.2
Testing theory against in vivo and in vitro empirical data . . . . . . . . . . . .
70
7.2.1
Maximum entropy axonal diameter distribution of myelinated neurons .
71
7.2.2
Maximum entropy axonal length distribution of myelinated and un-
myelinated neurons . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
7.2.3
Mapping Lagrange multipliers to biological constraints
. . . . . . . . .
78
8
Designing biologically plausible neural networks
82
8.1
Simulation of a Rentian scaled small-world network . . . . . . . . . . . . . . .
83
9
Conclusion
87
9.1
Future direction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
A
89
A.1 Properties of the gamma distribution . . . . . . . . . . . . . . . . . . . . . . .
89
A.2 Relationship between Π, G, ¯λg, and ¯λπ of p∗
m(s) . . . . . . . . . . . . . . . . .
89
A.3 Relationship between L, W, ¯λc, and ¯λw of p∗(ℓ) . . . . . . . . . . . . . . . . .
90
v

An illustration by Galen Dara in the Scientific American
1

Chapter 1
Introduction
As engineers and researchers, we believe some mysteries of the universe, once solved, can
unpack extraordinary evolutionary consequences that can play a significant role in advancing
human civilization.
One question that has yet to be solved, perhaps at its most nascent
form, dates back to the times of French philosopher Ren´e Descartes: What is consciousness?1
Illustration from Ren´e Descartes (1596-
1650), “Treatise of Man,” illustrating the
function of the pineal gland. Inputs are
passed by the sensory organs to the pineal
gland and, from there, to the immaterial
spirit.
Answers to such questions undoubtedly have the
potential not only to explain the miraculous sen-
sations of human perception, which indeed feels
all so real but also contain the potential to explain
what true (biological) intelligence is. To gain a
better sense and appreciation to the question of
consciousness, we can allude to a famous remark
in Lessons on Elementary Physiology (1866) given
by Thomas Henry Huxley, considered one of the
first adherents of Darwin’s theory of Natural Se-
lection:
“How is it that anything so remark-
able as a state of consciousness comes
about as a result of irritating nervous
tissue is just as unaccountable as the
appearance of the Djinn when Aladdin
rubbed his lamp?”
Thomas points out from his observations that the remarkable “unaccountable appearance,”
or consciousness, enables us to navigate, (re)act, and make decisions with the external world
1This question is also embodied in Descartes’ famous quote Cogito, Ergo Sum; I think, therefore I am.
2

CHAPTER 1. INTRODUCTION
3
by directing our attention, focus, and energy to survive – a result of billions of neurons
communicating with one another in the brain. In essence, Thomas gives us a glimpse into
how one might theorize the field of consciousness.
If we were to indeed take Thomas’ approach as a stepping stone – analyzing the interaction
among billions of neurons that make up the brain – this may first, to any general reader, seem
like an intractable task. How can we possibly measure consciousness from the interactions
between billions of neurons?
Indeed, many might argue that theorizing a framework for
consciousness by default is meaningless – theorizing what cannot be (for now) measured is
impractical. Indeed, as researchers, we must never forget to be practical so that any good
theory can be used for the greater good. Therefore, we investigate in this work the anatomical
organization of neurons in the brain, which may ultimately help in understanding two main
aspects of consciousness: Learning and memory.
Learning is the most fundamental feature in human activity that gives us the ability to
acquire new memory from experience [1]: learning and memory shapes the self. However,
in engineering applications such as artificial intelligence, models of artificial neural networks
of supervised and unsupervised learning, reinforcement learning, optimal control theory, and
Bayesian-driven models of the brain often lack biological motivations and are established
completely on theoretical but artificial grounds. The mathematical formulations often overlook
the underlying elementary forms of biological mechanisms at a cellular and genetic level that
govern such processes. It is by synthesizing the use of proper mathematics with underlying
mechanisms governing biological neurons at a cellular and genetic level that one can then hope
to define principles characterizing how learning and memory form into such intelligence.
It is important to note that although there have been many attempts over the years since
the time of Descartes, there is yet to be a concrete theoretical framework that explains the
qualitative and quantitative aspects of the brain in one coherent picture from an axiomatic
approach to explain learning and memory. So, while there is no fundamental difficulty in
studying neurons (or the brain), the real difficulty lies in unifying many of the concepts
developed throughout the years in neuroscience. The modern challenge lies instead in the
following areas:
1. How should one organize the many mathematical relationships (especially dynamics,
probability theory, and information theory) into a complete and cohesive whole?
2. How does one maintain maximum generality in the analysis? To be more specific, how
can one retain:
(a) The many biological observed phenomena with the most minimal assumptions?
(b) A biologically plausible model for the brain or neurons?

CHAPTER 1. INTRODUCTION
4
(c) A model that is testable and can repeatedly produce close results to
experiments?
(d) A model that can infer more than what it intends to do and be experimentally
verified?
To tackle many aspects of the problems above, this thesis illustrates how ideas from statistical
physics – specifically, Shannon’s theory of entropy or information – can help understand the
structure and dynamics of biological neuronal networks that make up the brain, shaped from
learning and memory formation through experience. It should be emphasized that this is, in
its entirety, not a completely rigorous treatment but one approach to help provide fresh and
interesting perspectives on how the brain might function to learn and form memory. To help
guide and motivate the analysis, we first give a brief digression of Michael Merzenich’s [2,3]
work on neuroplasticity – the brain’s ability to change dynamically in structure and function
throughout one’s lifetime in response to experience. In essence, neuroplasticity states that all
biological systems, and in particular the brain, that show configurational order self-organize
to achieve homeostasis: The brain’s natural tendency to achieve equilibrium [4–6]. Why such
equilibrium conditions must exist to influence the structural and topological organization of
neurons and neuronal networks to learn and form memory in a biological fashion is the subject
of this thesis.
To motivate how the emergence of the structural and topological organization of neurons in
the brain can be translated into a constrained optimization problem of Shannon’s entropy, we
give an extensive literature review on Donald Hebb’s [7] and Gerald Edelman’s [8–12] theories
on brain development which have shaped neuroscientific theories for over 6 decades. Hebbs’
theory allows one to explain how the brain develops highly functional neuronal networks
through the strengthening (or weakening) of synaptic connections between presynaptic and
postsynaptic neurons. Such formations of synaptic connections in the brain shape the topology
of neuronal networks that are molded by experience and shape precepts constituting thoughts
[7,13]. Edelmans’ theory allows one to explain why only a subset of neuroanatomical structures
and neuronal networks are selected among a myriad number of other possible candidates that
form functional circuitries with highly cognitive functions when operating on a global scale
[8–12].
If one combines the concept of neuroplasticity with Hebb’s and Edelman’s ideas about
brain dynamics in terms of modern-day theories, one arrives at a maximum entropy principle
for the brain that sufficiently explains, as a result of an inference model, how neurons must
structurally evolve to communicate efficiently, and why connections between neurons are not
randomly formed but are highly self-organized to make learning and memory formation pos-
sible. With the most minimal assumptions, we show how two physical quantities – neuronal

CHAPTER 1. INTRODUCTION
5
diameter and length – are related to the biological functioning of the brain [14, 15, 17–20].
In particular, we show that with only four constraints consisting of action potential power,
g-ratio, distance-dependent synaptic connectivity, and timescale of action potentials, when
cast into an entropy maximization framework, one necessarily arrives at a maximum joint
entropy distribution of neuronal diameter and length from first principles.
The payoff for adopting this mathematical treatment to explain how learning and memory
are mapped to the structural and topological level of neurons and neuronal networks is that
many diverse aspects of brain dynamics can be understood in the most elementary forms of
physical laws – entropy. As a result, we shall see how the maximum entropy principle for
the brain unifies neuronal diameter and length distributions in a biologically plausible fashion
to arrive at marginal distributions conforming to the gamma distribution, often reported in
the literature [21–23]. By testing theory against in vivo and in vitro datasets of biological
neuronal and regional networks of different species, we find from numerical analysis that the
theory can sufficiently infer the biological constraints, which compare favorably well to values
reported in the literature. Lastly, we shall see how the principle can explain why the Rentian
scaled small-world architecture, regarded as one of the most biologically and topologically
efficient networks observed in species such as the C. elegans neuronal network must naturally
occur in the brain due to entropy maximization by performing simple simulation experiments
using graph theory [24–28]. The principle thus suggests that the brain’s innate ability to
strategically self-organize its structural and topological properties can be achieved through
entropy maximization [29].
This thesis attempts to show how the use of physical laws, when applied to neuroscience
through mathematics, can unpack interesting insights on brain dynamics, such that one day
we can apply these concepts to find novel ways to reverse engineer the brain for the engineering
community.

Chapter 2
Architecture of the mind
Who will lead me into that still more hidden and dimmer region where thought
weds fact, where the mental operation of the mathematician and the physical
action of the molecules are seen in their true relation? Does not the way pass
through the very den of the metaphysician, strewed with the remains of former
explorers?
James Clerk Maxwell, 1831-1879
2.1
The dynamic brain
The starting point lies in envisioning how the brain functions with its external and internal
milieu. By external milieu, we mean any element constituting the individual’s external social
environment, such as light. In contrast, by internal milieu, we mean any element constituting
the individual’s internal environment, mainly comprised of organs that function together that
make up the anatomy.1 This concept is best illustrated in Figure 2.1. We immediately see
that the brain is the sole organ that governs all biological processes necessary to sustain life.
The brain reacts to its external and internal milieu and produces outputs most suitable to
the individual’s lifestyle. For example, the outputs can be changes in the individual’s emo-
tional state or habitual patterns. Ultimately, the brain must constantly use energy supplied
from food sources transformed into molecules of Adenosine Triphosphate (ATP) used for all
metabolic processes to achieve homeostasis: Any self-regulating process by which biological
systems tend to maintain stability while adjusting to conditions that are optimal for survival
1The internal environment – or milieu int´erieur in French – was first coined by Walter Bradford Cannon
[30] in the 19th century to describe how mechanisms of interstitial fluid ensure protective stability for the
tissues and organs of multicellular organisms.
6

CHAPTER 2. ARCHITECTURE OF THE MIND
7
[31].2
Figure 2.1: The continuous life cycle of the brain interacting with the internal and external
milieu from early life events. Pre-birth, the brain is organized through genetic means. After
birth, the brain is able to regulate chemical and cellular processes to maintain life while
simultaneously interacting with its environment, or the external milieu. Any interaction that
elicits mental or physical activity that is favorable to the individuals lifestyle, from cognitive
functioning that controls mood and stress, intakes energy taken from natural resources that is
then expended to regulate nutrients to achieve homeostasis. Image from Broskey et al. [32].
The biological aspect of homeostasis – optimal self-adjusting systems – is all around us,
from the swarming of birds or insects, swinging pendulums, chemical reactions, and even
the planets that make up the solar system. It is clear that each system, if treated individu-
ally, must eventually stabilize and maintain its stability to function. For example, starlings
match the direction and speed of the nearest seven neighbors rather than responding to the
movements of all nearby birds around them, eventually stabilizing to display actions of mur-
muration. A swinging pendulum, due to gravity, will stabilize by losing energy from friction
or elastic deformations and eventually come to rest. Chemical reactions achieve thermody-
namic stability by using and releasing energy. The positioning and circulation of stars have
stabilized to make up the solar system throughout evolution to make all life possible today.
The examples are countless.
Indeed, we shall soon see that the brain is no different: It embodies all the mechanisms
necessary to make sense of the world through learning and memory and create meaning from
abstract concepts throughout an individual’s lifetime – a universal property of intelligent,
biological systems that is achieved through homeostasis. In subsequent chapters, as much of
2Historically, the word “homeostasis” was first coined by Walter Bradford Cannon in 1926, but the concept
was first introduced by French physiologist Claude Bernard in 1849 [30]. Then in 1932, Joseph Barcroft [33],
a British physiologist, was the first to propose that higher brain function required the most stable internal
environment. Thus, to Barcroft, homeostasis served the brain much like how physical laws, such as gravitation,
serve to regulate the movement of stars.

CHAPTER 2. ARCHITECTURE OF THE MIND
8
the following discussions will be contingent on empirical observations of brain dynamics, it is
first paramount to understand what a neuron is and how it functions to communicate with
neighboring neurons. Thus, we now ask the question: What is a neuron?
2.2
What is a neuron?
The very structure of a single neuron is simple, as seen on the left side of Figure 2.2. It is
composed of the soma housing the nucleus that sprouts tree-like branches known as dendrites.
The dendrites form many smaller or longer branches on which synapses are located, which are
the contact points where signals from other neurons arrive. The signals from the soma then
travel down the axon in a unidirectional fashion, ultimately reaching its terminal, as indicated
by the arrows, to propagate signals in a neuronal network.
Figure 2.2: Anatomy of a biological neuron seen on the left, and action potential dynamics is
seen on the right. Image modified from Betts et al. [34].
How does the basic neuronal anatomy allow neurons to function?
When a neuron is
at rest, it maintains a state of equilibrium where a negative electric potential exists inside
the membrane relative to its outer environment, measured in units of voltage. The electric
potentials are created by the differences in the concentration of various positively or negatively
charged ions, such as potassium or calcium ions, that flow in and out through the opening
and closing of ion channels located on the axonal membrane. By inserting an electric probe
to measure the neuron’s action potential, one would see a dynamic behavior similar to that
of a spike with its maximum value achieved in less than a millisecond once the threshold
is met, as seen on the right side of Figure 2.2. (Typically, a maximum value of 100mV is
commonly used in the literature.) Once an action potential is generated, the neuron enters a
state of hyperpolarization when the potential is lower than that of the resting potential and
returns to its resting potential by balancing the chemical gradient using ion channels acting
as “gates” for ions to travel through the membrane. Thus, neurons ultimately function by

CHAPTER 2. ARCHITECTURE OF THE MIND
9
communicating information about the internal and external milieu through electrical signals,
referred to as action potentials.
Understanding how a single neuron functions now leads to the question: How do multiple
neurons communicate with one another? Let us now turn to Figure 2.3. The right side of
Figure 2.3 shows the interaction between the presynaptic neuron (top), which stimulates its
adjacent partner, the postsynaptic neuron (bottom), initially at rest. The first stage of com-
munication occurs at the dendrites, or more specifically, at the synapse – the site where the
connection is formed between the presynaptic and postsynaptic neurons.3 The synapse, more-
over, is the main site for transporting neurotransmitters from the presynaptic neuron, such
as dopamine or acetylcholine, which ultimately excites or inhibits the postsynaptic neuron.
Figure 2.3: Suppose we insert a microelectrode at the axon hillock or the site of action potential
initiation. As the neuron sums or integrates all the excitatory or inhibitory signals from its
neighboring partners, we will see a rise in membrane voltage (EPSP) or a decrease in membrane
potential (IPSP). If the total sum of EPSP and IPSP reaches the potential threshold, then
an action potential is generated and propagates from the presynaptic to postsynaptic neuron.
Image adapted using Anderberg et al. [35].
Excitation or inhibition due to neurotransmitters increases or decreases, respectively, the
postsynaptic potential through the dynamics that govern the inflow and outflow of negative
and positive ions, which can, for instance, be modeled with the Hodgkin-Huxley formulations
3The word “synapse” is more than a century old, having been coined in 1897 by the English physiologist Sir
Charles S. Sherrington. (Actually, Sherrington wanted to call the junction between neurons a “syndesm,” but
a classicist acquaintance persuaded him to combine the Greek word syn, meaning “together,” with haptein,
for “to clasp.”)

CHAPTER 2. ARCHITECTURE OF THE MIND
10
for conductance-based electrical signaling [36].4
Excitatory neurotransmitters increase the
membrane potential before it reaches the threshold, referred to as excitatory postsynaptic
potentials (EPSPs), as indicated by the increasing “bumps” on the left graph of Figure 2.3.
In contrast, inhibitory neurotransmitters decrease the membrane potential before it reaches
the threshold as indicated by the decreasing “bumps”, and are referred to as inhibitory post-
synaptic potentials (IPSPs). For neurons to communicate with one another, the synapses of
the postsynaptic neuron integrates (or sums) all EPSPs and IPSPs elicited by neighboring
presynaptic neurons – synaptic integration.5 If the total integration of the EPSPs and IPSPs
reaches the potential threshold, an action potential is generated, propagating down the axon
until it reaches the end of the postsynaptic neuron. The property to overcome the potential
threshold before neurons can generate action potentials results in the all or none law:6 No
matter how much stimulus is applied, if the total integration of EPSPs and IPSPs does not
overcome the potential threshold, the neuron will remain at its resting state.
2.3
Myelinated and unmyelinated neurons
There are mainly two types of neurons that exist in the brain: Myelinated and unmyelinated
neurons. The axons of myelinated neurons are coated with electrical insulators or myelin
sheaths, as seen in Figure 2.4, which is comprised of Schwann cells wrapped around the axon
as many as 100 times. Myelin sheaths essentially provide a fatty layer to prevent any ions from
leaking across the axon’s membrane, thus generating action potentials at greater conduction
velocities in comparison to unmyelinated neurons which are not coated. Physically, action
potentials in myelinated neurons do not propagate along the axon but rather jumps from
node to node. This node to node propagation is said to be saltatory.7
4Notably, the Hodgkin-Huxley electric model of a neuron is the “gold standard” model that is often used to
study neuronal dynamics. For example, Hodgkin and Huxley’s work has been modified and extended to study
chaotic nonlinear dynamics from Fitzhugh-Nagumo’s model [37] of a neuron and, in some cases, extended
using fractional calculus to analyze how neuronal dynamics change when perturbed by external forces to
model neurons from traumatic events motivated by Hamilton’s principle in physics [38].
5The integration of stimuli was first postulated by Charles S. Sherrington in 1906 in his work, The Integrative
Action of the Nervous System, as “the activity of one set of exciting muscles is integrated with another set of
inhibited muscles”.
6The concept of the all or none law was first proposed in 1871 by the physiologist Henry P. Bowditch,
who experimented with heart muscles to empirically find a relationship between the stimulus intensity to the
difference in muscle contraction. This work was later carried on in the 19th century by another physiologist,
Edgar Adrian [39]. Adrian developed methods for measuring electric signals in the nervous system, and in
1928 he found empirical evidence of the all or none law taking place in nerves: More stimulus does not equate
to stronger signals, but rather, signals of higher frequency that are sent more often through more nerve fibers.
Adrian, alongside Sir Charles Sherrington, was awarded the joint Nobel prize in Physiology or Medicine in
1932 for their work on the function of nerves.
7From the Latin word saltare, meaning to leap or to dance.

CHAPTER 2. ARCHITECTURE OF THE MIND
11
Figure 2.4: (a) A diagram of a myelinated neuron. A neuron’s axon covered in fatty coatings
of myelin sheaths in fixed intervals. The “gap” between each myelin sheath is called the node
of Ranvier; (b): A cross-section of a myelinated axon. Image adapted from Heath et al. [40].
Myelination is vital for the following two main reasons: (1) action potentials travel at
faster rates which implies a faster rate of communicating and transferring information; (2)
Schwann cells play a vital and active role in the repair and function of peripheral nerves,
which are then used to bridge and repair nerve gaps caused by injury or diseases. Damages
to Schwann cells can directly lead to cognitive decline, and memory deficits in the forms of
multiple sclerosis and Alzheimer’s disease [41].
Armed with the concepts that drive neuronal communication, we are now in a position to
begin discussing how groups of neurons must function together to make all the learning and
memory formation possible.8 In the next section, we begin by exploring empirical evidence
that entails a direct relationship between how the brain maintains its structural integrity with
homeostatic mechanisms and its relation to learning and memory formation. We now begin
the discussion of brain maps.
2.4
Brain maps
2.4.1
Topographic organization of brain maps
To understand what we mean by brain maps, we must first have a clear picture of them. Brain
maps were first made vivid by the neurosurgeon Wilder Penfield in the 1930s. To Penfield
[42], mapping a brain meant identifying where in the brain different parts of the body were
8By groups of neurons we mean at least a pair of connected neurons that transmits action potentials in a
unidirectional or bidirectional fashion.

CHAPTER 2. ARCHITECTURE OF THE MIND
12
located. Penfield spent years mapping sensory and motor parts of the brain by performing
brain surgery and discovered that when he touched parts of the epilepsy patient’s sensory
brain map with an electric probe, it triggered sensations felt in the patient’s body. Penfield
also discovered that the same parts of the brain map induced sensations consistently to the
same body part. Penfield’s most significant discovery was that sensory and motor maps, like
geographical maps, are topographical [2, 42]; that is, brain maps of adjacent areas on the
body’s surface are generally adjacent to each other, as seen in Figure 2.5.
Figure 2.5: The topographic organization of individual brain maps is a universal characteristic
of many species. Each brain map has a vital role in functioning optimally, in forms of action
and perception, to communicate and interact with the internal and external milieu. For exam-
ple, the corpus callosum found deep within the brain’s center is a “communication channel”
between the frontal lobe involved in planning and the parietal lobe involved in controlling
movement. For this reason, the brain maps of the frontal lobe, motor, and sensory cortex are
topographically adjacent to one another. Image from Allen et al. [43].
The explicit depiction of the brain developing toward functional and topographical maps
– each map learning and memorizing specific tasks – reveals that the brain, throughout its
development, is self-organized to be most “economically” practical: it is better to have parts
of the body that are close to each other also be close to each other’s brain maps. This is why,
for example, the brain maps that govern the activity of the index finger and middle finger,
which are seen side by side on the hand’s surface, are also seen side by side in the brain [42].
Furthermore, the topographical organization of the brain does not have to be constrained to
body surfaces but also applies to anything the brain can perceive [2, 42]. For instance, the
auditory map – the brain map responsible for hearing – is formed like an instrument. Its brain
map contains subsets of other maps responsible for picking up low frequency on one end and
increases until it reaches the end picking up the high frequency. Penfield would also find in
his experiments that, in some cases, exciting some areas of the brain would trigger long-lost
memories or dreamlike scenes indicating mental activities were also mapped in the brain.

CHAPTER 2. ARCHITECTURE OF THE MIND
13
To move forward, however, we require a stronger insight. Understanding the topographical
nature of the brain alone is insufficient to explain how the brain exploits and utilizes its home-
ostatic mechanisms for learning and memory. The key to bridging the concept of homeostasis
to the brain and the emergence of the topographic brain maps, which makes all the learning
and memory formation possible, lies in one fundamental property: The brain is inherently a
dynamic organ.
2.4.2
Neuroplasticity: The dynamics governing brain maps
Brain dynamics affect us all. For example, sensory neurons react to signals from photons,
and motor neurons react to any muscular movement. Furthermore, individual thoughts are
collectively organized for constructing logical reasons to navigate the world through any prac-
tical means. Such observations lead to the question: How does the brain use homeostasis
to dynamically learn and form memory to shape the brain into a highly functional neuronal
network? The answer, we argue, lies in the field of neuroplasticity.
Until the arrival of Merzenich’s work in neuroplasticity, many neuroscientists agreed that
the brain is fundamentally an aplastic organ [2,3]. That is, neuronal connections eventually
become fixed. Thus, at least macroscopically, any strengthening or weakening of neuronal
connections was incapable of producing any significant observable changes in brain maps. At
first glance, this is a reasonable presumption, as we are commonly taught that it becomes
harder to learn and memorize with age. We grow up assuming that most of our learning and
memorizing “rules” to life are nurtured and developed at a young age during a “critical” period,
in which most learning and memorizing must occur if we wish to carry it onto adulthood.
Indeed, the biological property of a critical period in the brain was first discovered in the
1960s by two neurophysiologists, David Hubel and Torsten Wiesel [44]. In Hubel and Torsten’s
experiment, they sewed shut one eyelid of the kitten during its critical period – from the third
to the eighth week of its life – and inserted microelectrodes into the visual cortex to study
short and long-term effects when the brain map associated with vision was deprived of input.9
They found that the brain map associated with the blind eye failed to develop, leaving the
kitten blind for life in that eye. However, Hubel and Torsten also discovered that the brain
map associated with the shut-eye began to process inputs from the brain map of the open eye.
In other words, the functional brain map of the open eye invaded the area of the unused map
space that failed to develop. The brain during the critical period is fundamentally plastic.
9These microelectrodes are fundamentally different from the electric probes that Penfield used. Microelec-
trodes are so sensitive that they can stimulate and record neuronal signals from single neurons at a time.
In contrast, the probes used during the time of Penfield were only able to excite, but not record, multiple
neuronal signals at a time.

CHAPTER 2. ARCHITECTURE OF THE MIND
14
That is, the very structure of the kitten’s brain was literally shaped by experience. For this
discovery, Hubel and Torsten shared a Nobel Prize in 1981.
Although Hubel and Torsten’s discovery of plasticity during the critical period opened the
possibility that perhaps it could carry into adulthood, they opposed the idea. They believed,
like many neuroscientists at that time, that the brain is essentially hardwired from birth and
becomes incapable of any significant development after some point in adulthood [2,44]. They
believed that once critical connections were established in their mature form, they stayed in
place permanently; the adult brain is fundamentally aplastic. This view, however, was entirely
changed when Michael Merzenich experimented with adult monkeys to investigate plasticity
directly in the late 1980s. Merzenich’s experiment with another neuroscientist, Jon Kaas, was
simple in principle. Like a human hand, a monkey’s hand has three main nerves that send
signals to the brain. The two nerves, radial and ulnar, mainly convey sensations from either
end of the hand, whereas the medial nerve conveys sensations mainly from the middle portion
of the hand. Merzenich and Jon Kaas decided to cut the medial nerve, essentially depriving
its brain map of all input signals, and decided to return two months later to remap the brain
[3].
As expected, the brain map associated with the medial nerve showed no activity when
the middle portion of the hand was stroked. However, Merzenich and Jon Kaas also found
something shocking. When they stroked the outsides of the monkey’s hand, the median nerve
map lit up. They found the brain maps for the ulnar and radial nerves effectively doubled in
size and invaded what used to be the medial nerve brain map! A clear demonstration of adult
plasticity. Norman Doige, a Canadian psychiatrist, earning a medical degree at the University
of Toronto, elegantly summarizes the findings of Merzenich’s work from his book The Brain
That Changes Itself [2], and puts it thus:
“The competitive nature of plasticity affects us all. There is an endless war of
nerves going on inside each of our brains. If we stop exercising our mental skills,
we do not just forget them: The brain map space for those skills is turned over
to the skills we practice instead.
If you ever ask yourself, “How often must I
practice French, or guitar, or math to keep on top of it?” You are asking a question
about competitive plasticity. You are asking how frequently you must practice one
activity to make sure its brain map space is not lost to one another.”

CHAPTER 2. ARCHITECTURE OF THE MIND
15
The brain is fundamentally a homeostatic plastic organ.10
2.5
Homeostasis, plasticity, and the brain
The experiments from Penfield to Merzenich provide us with an empirical foundation that will
serve as bedrocks in moving forward. By adopting the framework that the brain self-organizes
through neuroplasticity to achieve a state of equilibrium, or homeostasis, one can now be-
gin to see these as necessary mechanisms of brain dynamics. That is, the brain constantly
remodels and self-adjusts, constantly learning and forming memory, which self-organizes and
self-stabilizes to a structural system that allows one to navigate and interact with its external
and internal milieu.
Homeostasis and plasticity are two sides of the same coin when used in the context of brain
dynamics. Homeostasis is a necessary condition that entails the nature of the fierce competi-
tion for resources and space, and plasticity bridges homeostasis to the inherent dynamics of
the brain. It is by combining these two elements the brain is able to strategically self-organize
approximately 100 billion neurons, shaping neuronal networks that stabilize with highly func-
tional capabilities to optimize survival [45].11
To put this in perspective, the number of
observable stars in the Milky Way galaxy has about 100 billion stars. In this astronomical
sense, organizing neurons in the brain is analogous to organizing the stars in the milky way
galaxy. That is, just like how the Milky Way galaxy is organized according to the principles of
gravitation, the brain, which we shall theoretically argue in subsequent chapters, is organized
10It is worth mentioning to the reader that there is a key difference in plasticity that occurs during the
critical period (or adolescence) and adulthood. The degree of plasticity is regulated by what is known as
BDNFs, or brain-derived neurotrophic factors.
BDNFs are responsible for neuronal growth and reinforce
plastic changes made in the brain. It consolidates connections between neurons that communicate with one
another using action potentials. During the critical period, the BDNFs turn on the nucleus basalis, or the
modulatory control system of plasticity, and is kept on during the entire critical period. It is like a teacher in
the brain saying, “Now this is really important – this you have to know for the exam of life” [2]. Thus, turning
on the nucleus basalis creates the illusion of “effortless” learning during the critical period. However, the
nucleus basalis is turned off once we transition into adulthood. This is the primary reason why, as teenagers
and adults, we need to actively put in the effort and focus our attention on any mental or physical tasks to
learn and memorize effectively. This is especially true if we were to acquire completely new skills like learning
a new language. A new language is not processed in the same brain map as the native tongue; hence, we are
prone to developing an accent when speaking a new language. Interested readers can refer to [2].
11In literature, it is often said that the adult brain has approximately 100 billion neurons. However, in 2009,
neuroscientist Suzana Herculano-Houzel [45] and her team in Brazil questioned where the number came from,
and it was nowhere to be found.“We found that, on average, the human brain has 86 billion neurons. And
not one (of the brains) that we looked at so far has the 100 billion. Even though it may sound like a small
difference, the 14 billion neurons amount to pretty much the number of neurons that a baboon brain has or
almost half the number of neurons in the gorilla brain. So that’s a pretty large difference.” In the thesis, we
have decided to approximate the brain with an average of 100 billion neurons, as 80 billion vs. 100 billion
only differ by one order of magnitude.

CHAPTER 2. ARCHITECTURE OF THE MIND
16
according to an entropy principle to embed mechanisms of homeostasis and plasticity to its
anatomy. To motivate the analysis, let us now discuss Hebb’s and Edelman’s theory of brain
development.

Chapter 3
Designing the mind
“It is not within the power of practitioners of demonstrative sciences to change
opinion at will, choosing now this and now that one; there is a great difference
between giving orders to a mathematician or a philosopher and giving them to
a merchant or a lawyer; and demonstrated conclusions about natural and
celestial phenomena cannot be changed with the same ease as opinions about
what is or is not legitimate in a contract, rental, or in commerce”
Galileo Galilei, letter to the Grand Duchess Christina of Tuscany, 1615
3.1
Hebbian theory: A guide for learning and memory
In 1949, a Canadian psychologist Donald O. Hebb introduced in his work, Organization and
Behavior – A Neuropsychological Theory, the first compelling theory to explain how biological
functions of the brain can be connected to human perception.1 As a theory to map observed
behavior to the firing activity of action potentials between neurons to explain changes in
synaptic strength from the persistent repetitions of a reverberatory activity that tends to
induce lasting cellular changes that add to its stability, Hebb states [7]:
“When an axon of cell A is near enough to excite cell B and repeatedly or per-
sistently takes part in firing it, some growth process or metabolic change takes
place in one or both cells such that, A’s efficiency, as one of the cells firing B, is
1Actually, Hebbs’ theory can be said to date back to 1932, in his M.A. Thesis, Conditioned and Uncondi-
tioned Reflexes and Inhibition motivated by psychophysics using the works of Charles Sherrington and Ivan
Pavlov. In this report, however, we resort to the 1949 version as it is Hebb’s final revision to the theory.
17

CHAPTER 3. DESIGNING THE MIND
18
increased.2
Figure 3.1: Biological model of two adjacent presynaptic (cell A) and postsynaptic (cell B)
neurons. Image from James Photis [46].
A careful reading of Hebb’s theory reveals a relationship between causality and consis-
tency. That is, a presynaptic neuron repeatedly (consistency) taking part in firing (causality)
a postsynaptic neuron will increase the efficiency of synaptic connectivity [47]. In essence, neu-
rons adapt to one another that participate in specific learning processes. Hebb describes the
mechanism of synaptic plasticity, where strengthening connections increases synaptic efficacy
from the presynaptic cell’s (cell A) repeated and consistent stimulation to the postsynaptic
cell (cell B), as illustrated in Figure 3.1. Hebb’s theory, as a mnemonic, is neatly summarized
by neuroscientist Carla Shatz as “neurons that fire together, wire together”, and its corollary,
“those that fire out of sync, lose their link.” [48] In other words, where there is electrical
activity in the brain, connections between neurons are built up, while others are pruned away.
At the heart of Hebb’s postulate is a correlation-based learning rule between neurons that
learn and form memory which shape network topology through mechanisms of synaptic plas-
ticity. Indeed, almost half a decade later, Eric Kandel demonstrated cellular mechanisms
governing the learning and memory process of defensive gill-retraction reflex in the sea slug
Aplysia followed Hebbian rules of synaptic plasticity [49–51]. Kandel first identified the neu-
ronal circuitry associated with the learning and memory processes governing the defensive
reflex of the Aplysia. The neuronal circuitry consisted of a single presynaptic sensory neuron
detecting the external stimulus sent to the single postsynaptic motor neuron producing the
behavioral response of gill retraction [50]. With repeated electrical stimulations, an increase
in the duration of gill retraction was seen and thus indicated a form of short-term memory. At
a neuronal level, short-term memory effects were accompanied by increased neurotransmitters
2The reader may have noticed that Hebb’s postulate does not explicitly state where exactly the growth
process or metabolic change in the neurons. This was due to the limitations of the scarce empirical data
available at that time. Nevertheless, in the paragraph right after his postulate, he conjectures what we might
see if such changes were to take place. He states,“The most obvious and I believe much the most probable
suggestion concerning the way in which one cell could become more capable of firing another is that synaptic
knobs develop and increase the area of contact between the afferent axon and efferent soma. There is certainly
no direct evidence that this is so [7].” In retrospect, Hebb’s was spot on.

CHAPTER 3. DESIGNING THE MIND
19
released between the sensory and motor neurons, thus increasing the amplitude of EPSPs.
With sufficiently repeated electrical stimulations, longer gill retraction duration was seen,
indicating a form of long-term memory accompanied, in addition to an increase in EPSPs,
accompanied by the new growth of synapses forming new connections [51]. Kandel’s experi-
ment highlights that transitioning between short-term and long-term memory is structurally
mapped to the synapses. For this discovery, Eric Kandel was awarded the Nobel Prize in
Physiology or Medicine in 2000.
3.2
Edelman’s theory: A guide to the global functioning
of brain networks
A recipient of the shared Nobel Prize in 1972 for his work on the immune system, Gerald
Edelman announced in 1978 in his book, Neural Darwinism, a theory to model the global
function of the brain using a close analogy between natural selection and evolution [8–10].
In order to provide a theoretical framework sufficiently broad enough to connect biology and
psychology in a fashion consistent with developmental and evolutionary mechanisms, Edelman
proposed the following tenets, which lay down the foundation for his theory of neuronal group
selection (NGST) [9,10]:
• Variability: Individual nervous systems (particularly those of vertebrate species) show
enormous structural and functional variability. Variability occurs at molecular, cellular,
anatomical, physiological, and behavioral levels.
• Non-computation: Although there is an obvious commonality of neuronal structure
within the same species, the degree of individual variability far exceeds any tolerance
for any reliable performance in any machine.
• Selection: The world of stimuli encountered by a newborn animal cannot be adequately
described as preexisting, unambiguous information ready to be used following rules sim-
ilar to a computer. To survive in its external milieu, an organism must either inherit or
create criteria that enable it to partition the external and internal milieu into percep-
tional categorization according to its adaptive needs. The world becomes “labeled” or
perceptually categorized from selection upon variation.
The three tenets above will now play a key role in constructing NGST, which differs from
Hebbs’ theory by the following key assumption: Brain development is based on a selectional
system rather than a purely instructional system and can be described by the use of a reper-
toire. In Edelman’s sense, a repertoire is a collection of structurally variant neuronal groups,

CHAPTER 3. DESIGNING THE MIND
20
with each neuronal group consisting of hundreds or thousands of neurons that inherently share
the same functionality and are closely related in their intrinsic circuitry [9,11]. Unlike Hebb’s
postulate of an instructional system where the repertoire is produced by interaction, in a se-
lectional system, the repertoire exists from the beginning, and the brain merely selects those
with higher survival values [8,9]. This idea is the foundation to NGST.
NGST states that there are three fundamental stages to brain development: (1) the se-
lectional development and formation of primary repertoires, (2) experiential selection and
formation of secondary repertoires through intervention, and (3) reentry [9]. Within the first
stage of selectional development and the formation of primary neuronal repertoires, Edelman
proposes that the basic neuroanatomy is determined by neuronal elements, such as the cell
body, axons, dendrites, synapses, and neurotransmitters. These neuronal elements are first
genetically determined and compete among other neurons to connect and change the timing
and amplitude of the firing sequences of action potentials they contact. It is through compe-
tition among these elements that give variation in neuroanatomical structures [10,11]. These
variations that include the branching of neurons in all sorts of directions using axons and den-
drites can also arise from the fierce competition in cell division, migration, adhesion, death of
cells, formation, and retraction of synapses, and are all necessary to provide diverse neuronal
circuitry during fetal development which then leads to enormous local neuroanatomical vari-
ation. It is this unavoidable generation of diversity that results in neuronal groups consisting
of hundreds of thousands of strongly interconnected neurons that begin to act as functional
units, as seen in the first row of Figure 3.2.
Such neuronal groups, when functioning together during selectional development, are the
primary neuronal repertoires. It is essential to remember that these connected neuronal groups
initially develop by genetic instructions and are, in a sense, “degenerate.” The primary neu-
ronal repertoires contain a broad range of functionality and a significant number of nonidenti-
cal variant groups [9,10]. Thus, the resulting system can only yield low cognitive capabilities
that we see with newborns through simple species-specific yet unique behaviors. These be-
haviors include an abstract preference for the human face, making noise with the mouth, and
sucking and rooting on fists or nipples [9].
To explain higher cognitive capabilities in mammals, Edelman proposed the second stage
of brain development – experiential selection – imposing a condition that each neuronal group
must have survival value and the capacity to adapt to the environment. With constant inter-
actions with the external and internal milieu, connections between neuronal groups begin to
stabilize, and a secondary repertoire of purely functional neuronal circuits develops, selecting
only the neuronal groups from the primary repertoire proven to have value for the infant
that meet task requirements efficiently, as seen on the second row of Figure 3.2 [9,10]. (The

CHAPTER 3. DESIGNING THE MIND
21
Figure 3.2: An illustration for NGST. The first row represents the development selection and
the formation of the primary neuronal repertoire, with each circle representing a neuronal
group. The primary repertoire is mainly developed during the fetal stage through genetic
instruction at Time 1. Then from processes such as cell division and cell death, neuronal
groups form connections with each other and are subject to change at Time 2. The bottom
row represents experiential selection, where one’s experience and interaction with the internal
and external milieu creates stimuli and either strengthens or weakens the connections between
neuronal groups from the primary repertoire, as seen at Time 1. This is where we first begin
to see the development of a secondary neuronal repertoire. In essence, changes in synaptic
strength create strong connections, represented as bold lines, and weakened connections are
represented by dashed lines at Time 2. Image from Edelman [9].
secondary repertoires are essentially the network of brain maps discussed in Chapter 2.) For
example, the thalamus – a secondary neuronal group – found above the brain stem, consti-
tutes a part of the secondary neuronal repertoire that is specifically responsible for sending
sensory information to the cerebral cortex, or the brain’s main control center. Hence, we now
clearly see that transitioning from primary to secondary repertoires is essential, as experience
is unique to each individual. The transition from the primary to the secondary repertoire
provides a sufficient learning and memory-based system.
To bridge the development of functional secondary repertoires to how the brain functions
as a collective whole, Edelman proposed the last stage of brain development, namely reentry.
Reentry signifies the ongoing parallel signaling between separate neuronal groups occurring
between large numbers of ordered anatomical connections in a bidirectional fashion [9], as seen
in Figure 3.3. It selects those neuronal groups that show synchronizing behavior which, for
example, is seen between the right and left cortex of the brain being connected by the corpus
callosum, as seen in Figure 3.4.
Reentry is key in explaining how integrated networks of
neuronal groups communicate to form cognition, as it requires a system of remarkable parallel
connectivity to support its plasticity and its temporal coherence.

CHAPTER 3. DESIGNING THE MIND
22
Figure 3.3: An illustration for reentry. Initially, at Time 1, brain map 1, which represents
some local region of the brain containing neuronal groups, is excited due to a stimulus. These
neuronal groups send signals to brain map 2, which is found in another local region of the
brain, separate from brain map 1. In parallel, brain map 2 is also excited and its neuronal
groups send signals to brain map 1. At a later time, Time 2, this continual process of signal
reentry enforces and strengthens connections between specific neuronal groups between the
two maps. Image from Edelman [9].
Figure 3.4: An illustration for reentry in the brain on a global scale. We see bidirectional ar-
rows indicating the process of a temporally ongoing parallel signaling between neuronal groups
along ordered paths of connections. Notice that the inner region of the brain represents the
corpus callosum. The corpus callosum is essentially a large communication channel between
the outer regions of the brain. Image from Edelman & Tonini [12].
3.3
Bridging Hebb’s and Edelman’s theory of brain de-
velopment
The central premise behind adopting the framework that the brain self-organizes to achieve
homeostasis lies in its ability to explain Hebb’s and Edelman’s theory of brain development
in a unified manner.
In order for the brain to achieve homeostasis – the brain’s state of
equilibrium – it must be a self-adjusting and organizing system that evolves under constraints
due to limited energy, space, and time. In this sense, from the virtue of Hebb’s theory, stability
is achieved when neurons learn to transmit as much information from the source mapped to
synaptic connections. When memory, to some degree, is consolidated, this is mapped to the

CHAPTER 3. DESIGNING THE MIND
23
topology of neuronal networks. From the virtue of Edelman’s theory, at a global scale, this
constitutes brain networks that function together to produce highly cognitive functions. Our
objective now is to show how this stability arises that is reflected in neuronal structure and
the topology of neuronal networks can be explained through the concept of Shannon’s entropy.
However, before proceeding further, we must have a way to model the brain and its neuronal
networks. Let us now study connectomics.

Chapter 4
Connectomics: Graph theory of
neuronal networks
“Beginning at the beginning”, the king said gravely, “and go on till you come
to the end; then stop.”
Lewis Carroll, Alice in Wonderland
4.1
A primer on graph theory
This chapter explores how one can model neuronal networks that make up the brain. In par-
ticular, as we wish to study and analyze the properties exhibited in the network’s topology,
we shall utilize connectomics. Connectomics is a branch of neuroscience that analyzes com-
prehensive maps, or “wiring diagrams”, of neuronal connections in the brain. These wiring
diagrams can be complex, where every fiber and structure can be visualized using MRI trac-
tography or can be made simpler by reducing the physical details of neurons. The choice
depends on the scope of the analysis. Specifically, in this thesis, we have resorted to using
graph theory for its simplicity [52].
In graph theory, neurons are modeled as nodes, and synaptic connections exist between
any pair of neurons if an edge connects them, as seen in Figure 4.1. It is also important to
note that nodes, at times, can represent neuronal groups or brain maps. The arrows indicate
the direction in which action potentials travel. For example, in Figure 4.1, we see that neurons
1 and 4 communicate bidirectionally, as indicated by the doubled arrow edge. In contrast,
neurons 4 and 5 communicate unidirectionally, with neuron 4 being the only one sending
action potentials to neuron 5, as indicated by the single arrow edge. Networks such as the one
in Figure 4.1 are called directed graphs, i.e., they contain both unidirectional and bidirectional
24

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
25
edges. If a graph contains only bidirectional edges, it is said to be an undirected graph.
Figure 4.1: A visual representation of a neuronal network using graph theory. Neurons are
represented as circles or nodes, and a synaptic connection exists between pairs of neurons if
there is an edge connecting them. Edges with arrows indicate the direction in which action
potentials travel.
Bidirectional communication is represented by doubles arrows, as seen
between neurons 1 and 4. Unidirectional communication is represented by edges with single
arrows, as seen between neurons 4 and 5.
Connections between neurons are mathematically represented using adjacency matrices.
That is, if a network contains a total of N neurons, then the adjacency matrix A is defined as
A =


0
a1,2
· · ·
a1,N
a2,1
0
· · ·
a2,N
...
...
...
...
aN,1
aN,2
· · ·
0


∈RN×N,
(4.1)
where aij = 1 indicates a synaptic connection between the pair of neurons i and j, with an
action potential traveling from neuron i to neuron j. Conversely, if aij = 0, then a synaptic
connection does not exist – i.e., the pair is disconnected. Note that by default, every diagonal
entry is set to null to prevent any self-connections. The adjacency matrix for the network
seen in Figure 4.1 renders as
A =


0
0
1
1
0
0
0
0
0
1
1
0
0
0
0
0
0
1
1
0
1
0
1
1
0
0
0
0
0
0
0
0
0
0
0
0


∈R6×6.
(4.2)
As a general remark, we wish to note that although adjacency matrices for directed graphs
are not symmetric, the adjacency matrices for undirected graphs are always symmetric (i.e.,

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
26
A = AT, where (·)T is the transpose operator). Let us now define two different topological
properties of any given network: Path-length, clustering coefficient, Rentian scaling, and the
small-world architecture.
4.2
Path-length
With over 100 trillion connections in the human brain, it is no question that there are many
paths of different lengths an action potential can travel through from its source to destination.
For example, in Figure 4.2, there are three different path-lengths an action potential can travel
from neurons #2 to #6:
Figure 4.2: A visual representation of a neuronal network using graph theory with neurons
represented as nodes and synaptic connections represented as edges.
Path-length of 4 neurons: #2 →#4 →#1 →#3 →#6,
Path-length of 3 neurons: #2 →#4 →#3 →#6,
Path-length of 2 neurons: #2 →#4 →#6.
When there is more than one path-length that an action potential can travel through from
the same source to destination, the shortest path-length is known as the distance, measured
in units of neurons. Following our example, the distance from neuron #2 to #6 is 2 neurons.
Analyzing path-lengths allows one to sufficiently describe how “wide” (or “tight”) the
network is, using the average path-length ¯ψ defined as
¯ψ =
1
2Emax
X
i̸=j
dij,
(4.3)
where the maximum number of edges Emax each neuron can make is defined as
Emax = N(N −1),
(4.4)

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
27
and dij is the distance from neuron i to neuron j, for i ̸= j [59].
The study of path-lengths has an important biological implication: Path-length approx-
imates the physical distance between neurons and plays an important factor to control the
time it takes for an action potential to travel from one neuron to another; it controls the
rate of information flow. Thus, shorter path-lengths result in lower signal propagation time,
and, conversely, longer path-lengths result in higher signal propagation time. In a biological
context, path-length distributions in biological neuronal networks follow binomial-like dis-
tributions with skewness. For example, we see below in Figures 4.3(a) and 4.3(b) that the
neuronal network of the nematode C. elegans and the cortical connectivity of different brain
maps of the macaque monkey, respectively, follow binomial-like distributions.
(a)
(b)
Figure 4.3: (a) Path-length distribution of the nervous system of C. elegans from a total of
277 neurons. The average path-length is roughly 4 “nodes” or neurons. Data obtained from
Dynamics Connectome Lab [61,62]. (b): Path-length distribution of the cortical connectivity
of different brain maps in the brain of the macaque monkey from a total of 94 different brain
maps. The average path-length is roughly 2 “nodes” or brain maps. Data obtained from
Dynamics Connectome Lab [64].

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
28
4.3
Clustering coefficient
In social networks, groups can be seen everywhere. Groups with individuals that share mutual
interests tend to have “tighter” relationships compared to groups filled with random individ-
uals without common interests [57]. For example, the relationship between individuals who
share the same interest in a music genre will tend to form a “tighter” relationship than those
who do not. This forming of “groups” is analogous to how the brain operates. Instead of
social networks, the brain contains a large collection of brain maps, such as the prefrontal
cortex, which acts as a support center for planning, decision making, and controlling certain
aspects of speech and language [16,58].
To measure such tightness in neuronal networks, we shall use the clustering coefficient
proposed by Duncan J. Watts and Steven Strogatz in 1998 as a means to study networks that
exhibited the small-world properties [24]. There are two ways to measure clustering: Locally
or globally. The local clustering coefficient Ci of neuron i with degree ki is defined as
Ci =
ei
ki(ki −1)/2,
(4.5)
where ei is the total number of edges between neighbors of neuron i [59]. Intuitively, the
clustering coefficient measures the relative proportion of possible interconnections between
the neighbors of neuron i. For this reason, 0 ≤Ci ≤1. For example, in Figure 4.4, the local
Figure 4.4: Measuring the clustering coefficient Ci for three different types of networks, (a),
(b), and (c). In network (a), neuron i and all of its neighbors are connected, indicating the
maximum clustering coefficient of Ci = 1; In network (c), Ci = 0 as none of neuron (i)’s
neighbors are connected even though neuron (i) is connected to all of its neighbors; Network
(b) lies within the two extremes of networks (a) and (c), with a clustering coefficient of
Ci = 1/2. Image from Zhihu [60].

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
29
clustering coefficient of neuron i in network (a) is
Ci =
ei
ki(ki −1)/2
=
6
4(4 −1)/2
= 1,
(4.6)
indicating neuron i is highly clustered. In network (c), however, since none of the neighbors
are connected (i.e., ei = 0), this implies Ci = 0 and network (b) lies within both of these
extremes. The global clustering coefficient, ¯C, is defined as the average of the local clustering
coefficient, given by
¯C = 1
N
X
i
Ci.
(4.7)
4.4
Rent’s rule: Rentian scaling
In social networking, communication between social groups gathering together for an event,
conservatively speaking, primarily depends on two factors: The number of people that make
up the group and how many of these individuals have (external) connections outside the group.
Intuitively, if the number of individuals in a group with external connections increases, the
chances of that group communicating with another group increases [27]. That is, a friend
of your friend is also likely to become your friend. This is no different when it comes to
brain networks that develop towards a cost-efficient system that embeds a high dimensional
functional (interconnected) topology in a low dimensional physical space with economical
wiring costs [27] – an aspect of a Rentian scaled network. In other words, Rentian scaled
networks are organized in such a way to compensate for the tradeoff between space, time, and
resources to the flow of information.
First observed by E. F. Rent in the 1960s, Rentian scaling has helped modernize circuits
in terms of size and computational power. Generally, circuits with greater logical capacity
exhibit higher values of the Rent exponent, indicating more complex wiring or higher dimen-
sionality of circuit topology [27]. Rentian scaling is one aspect of self-similar network design
principles that are reflected, for example, in Very-Large-Scale-Integrated (VLSI) circuits. Min-
imizing wiring costs in VLSI circuits has played an important role in modernizing commercial
economics, enabling the development of complex semiconductor and telecommunication tech-
nologies. In the development of VLSI circuits, a simple power law, known as Rent’s rule,
has been discovered to define a scaling relationship between the number of external signal

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
30
connections e that crosses the boundary of a block consisting of N logic gates, given by the
relationship
e = kN r
(4.8)
where 0 < r ≤1 is the Rent exponent and k is the Rent coefficient [27]. In essence, Rentian
scaling states that when an abstract topological architecture has been efficiently embedded
into a physical space, the number of external signal connections that cross the boundaries
of integrated circuit designs scales linearly as r in log–log space with the number of internal
components N. In the context of the brain, the block of circuit consisting of N logic gates is
analogous to N neurons in the neuronal network.
To estimate Rent’s exponent, we shall follow the approach of Bassett et al. [27] who have
shown using biological systems such as the C. elegans neuronal network and human brain
networks from MRI and DSI follow Rentian scaling. To estimate Rent’s exponent, randomly
sized cubes are randomly placed in the network, as seen in Figure 4.5(a). Each cube contains
Figure 4.5: An illustrative walk-through of estimating the Rent exponent r of any network.
Using the human brain network in anatomical space as an example; first, randomly sized cubes
are placed in the network (a). Second, we count the number of nodes n contained in every
cube placed in the network and the number of edges e crossing the boundary of the cube, as
seen in (b). Lastly, the Rent exponent is estimated using a sufficient number of cubes as data
points, and then a plot of n vs. e is determined. If a linear relationship holds between the
two variables on a logarithmic axis, the Rent exponent is the slope of the line, as seen in (c).
Image from Bassett et al. [27].
a total of n nodes and e edges intersecting the boundary or the surface of the cube, which is
then used to estimate Rent’s exponent by plotting the two variables on a logarithmic axis as
seen in Figure 4.5(b) and (c). If a linear relationship holds between log(n) and log(e), Rent’s
exponent amounts to the slope of the line. Rent’s exponent of various biological networks can
be found in Table 4.1.
Lastly, we wish to emphasize that if a system displays Rentian scaling, it does not necessar-
ily imply that the system is cost-efficiently embedded in space. That is, it does not necessarily
imply that the system can maintain highly complex topology in face of heavy constraints on

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
31
Table 4.1: Measures of Rent’s exponent in neuronal and brain regional networks [27].
Species
Area
Type of network
Number of nodes
Rent’s exponent
H. sapien
Brain (MRI)
Brain regional network
104
0.83
H. sapien
Brain (DSI)
Brain regional network
1000
0.78
C. elegans
Nervous system
Neuronal network
277
0.74
wiring due to limited sources of energy, space, and time [27]. This is an important aspect
of designing biological networks, as the organization of synaptic connections influences and
shapes how action potentials propagate in the brain, which shapes the network’s topology. Fi-
nal validation is done by comparing the inferred Rent’s exponent r with the minimum possible
physical Rent exponent rmin associated with the most efficient possible physical placement.
These two elements are theoretically related by the following relationship:
rmin = max
 
1 −1
De
, r
!
,
(4.9)
where De is the Euclidean dimension the nodes are placed in. Thus, if r > 1 −
1
De, then
the network is said to be cost-efficiently embedded in physical space. In particular, r = 1
corresponds to a random arrangement of external connections with no placement optimization.
However, for many biological (and engineered) networks, Rent’s exponent falls to less than
one (i.e., r < 1), which suggests that neurons, and thus the brain, biologically evolves with
some preferential selection of neuronal connectivity. (This also supports Edelman’s theory of
brain development, discussed in Chapter 3.) Rent’s exponent thus provides a useful measure
to determine if a network is efficiently economized.

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
32
4.5
Watts–Strogatz model: The small-world network
Small-world networks were first rigorously analyzed by Duncan Watts and Steve Strogatz
in 1998 in their work, Collective dynamics of “small-world” networks, popularly known as
six-degrees of separation [24].1
Networks that exhibit properties of a small-world network
are characterized by their high clustering coefficient and low path-length. Such models of
dynamical systems with small-world architecture display enhanced signal-propagation speed,
computational power, and synchronizability. The neuronal network of the C. elegans, the
power grid of the western United States, and the collaboration graph of film actors are all
examples of a small-world network.
To understand the evolutionary advantage of a small-world network, let us now consider
three main types of networks – regular, small-world, and random network – as seen in Figure
4.6 below.
In a regular network, every neuron has the same number of connections and
exhibits high clustering and path-length coefficients. The regular network, however, would
render the brain at a biological disadvantage as signal propagation becomes time-costly due
to high path-lengths. How would the brain then behave if it exhibited properties of a random
network? In this case, one would find a network with the lowest clustering coefficient and
path-length. However, this again would render the brain at a biological disadvantage: Vital
neuronal connections may not form, which may lead to brain disorders [63]. For example, a
vital connection between the blue and red neurons that would have existed otherwise in the
regular or small-world network would not exist in the random network, as seen in Figure 4.6.
Thus, to compromise the tradeoffs between resource, space, and time, brain networks tend to
lie between the extremes of a regular and random network: A small-world network.
A small-world network exhibits properties of high clustering and low path-lengths – a
hallmark of a high-performance network [66, 67]. High clustering is necessary to form local
neuronal networks, which contain hundreds to thousands of highly function-specific neurons.
These local neuronal networks communicate efficiently with neighboring local neuronal net-
works in a timely manner due to action potentials traveling across low path-lengths; these
1The idea of a Small-World network dates back to Stanley Milgram, a social psychologist, in 1962, to prove
his curiosity about how even in locally clustered networks there must be some underlying dynamics in how
messages are sent among social workers [65]. The experiment was to randomly choose a total of 160 “starter”
individuals in Omaha and ask them to try forwarding a letter to a designated “target” person living in the
suburb of Boston. Milgram provided the target’s name, address, occupation, and personal information but
demanded that the participants not mail the letter directly. Instead, each participant could only advance the
letter by forwarding it to a single acquaintance they knew on a first-name basis to reach the target as quickly
as possible. Overall, Milgram found that even within a clustered social network, messages between individuals
travel rather quickly by judicious choices of mutual acquaintances, or “common neighbors,” with an average
of 6 intermediate acquaintances the mail had to travel through. Milgram’s experiment is famously known as
“Six Degrees of Separation.”

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
33
Figure 4.6: Three different types of network topology using a lattice structure. Starting from
the left, a regular network will have high clustering and high path-length compared to a
random network seen on the far right with low clustering and low path-length. A small-world
network, seen in the middle, will have high clustering but low path-length and lies between
the regular and random network topologies. Image adapted from Watts and Strogatz [24].
neuronal networks, when functioning together, constitute the neuronal groups in Edelman’s
sense. The small-world architecture is not only crucial for efficient signal propagation, but
its existence in itself has a significant biological implication. That is, synaptic connections
between neurons are not randomly formed but are instead highly organized to achieve home-
ostasis – or the brain’s state of equilibrium – and tends to stabilize into a small-world network
using the mechanisms of neuroplasticity.
To assess if a network is small-world, we utilize Humphries et al.’s [26] approach by assess-
ing the small-world index based on the tradeoff between the average clustering and path-length
coefficients between the network of interest and a random network with the equivalent number
of neurons and the average number of connections. The small-world index S∆
WI is defined as
S∆
WI = γ∆
g
ω∆
g
; γ∆
g =
¯Cg
¯Crand
;
ω∆
g =
¯ψg
¯ψrand
,
(4.10)
where ¯Cg and ¯Crand are the average clustering coefficient of the (generated) network of interest
and its equivalent random network, respectively. Similarly, ¯ψg and ¯ψrand are the average path-
lengths of the (generated) network of interest and its equivalent random network, respectively.
Now, by taking the relative ratio between each quantity reflected by the terms γ∆
g and ω∆
g , if
S∆
WI > 1, then the network is considered small-world [26]. Small-world index values of different
species can be found in Table 4.2.

CHAPTER 4. CONNECTOMICS: GRAPH THEORY OF NEURONAL NETWORKS
34
Table 4.2: Small-world index of various species [26].
Species
Network
Network type
S∆
WI
C. elegans
Nervous system (277 neurons)
Neuronal network
4.51
M. mulatta
Cortex (95 regions)
Brain regional network
1.69
H. sapien
Functional cortical network (90 regions)
Brain regional network
4.32
4.6
The next line of attack
In later chapters, we will utilize graph theory to perform simulations to generate biologically
plausible neural networks, which, as we shall argue, can be statistically modeled using a
maximum entropy principle. Graph theory will provide us with a useful methodology for
analyzing network topology that may play an important role in memory formation; memory
is stored in the network’s topology through learning and experience [13]. Let us now begin a
rigorous treatment to define entropy, or information, in the sense of Shannon.

Chapter 5
Shannon’s entropy – A mathematical
treatise on information
The law that entropy always increases holds, I think, the supreme position
among the laws of Nature. If someone points out to you that your pet theory of
the universe is in disagreement with Maxwell’s equations – then so much the
worse for Maxwell’s equations. If it is found to be contradicted by observation
– well, these experimentalists do bungle things sometimes. But, if your theory
is found to be against the second law of thermodynamics, I can give you no
hope; there is nothing for it but to collapse in deepest humiliation.
Sir Arthur Stanley Eddington, The Nature of the Physical World, 1927
What is the difference between a rock and the brain? Despite the apparent solidity of
a rock, on average, it contains approximately 1025 atoms in a kilogram of matter which
are all extremely active. The atoms are in constant interaction, with electrons constantly
bombarding each other held together by weak-nuclear forces, changing particle spins and
generating electromagnetic fields [68]. By analyzing the microscopic behaviors of atoms that
make up the rock, it is estimated that a rock, on average, at any moment represents at least
1027 bits of memory or information [68].1
At first, the apparent anomaly of the rock representing any bits of memory is uncanny. If
the rock can “store” memory, how is it unable to, to some degree, show any signs of intelli-
gence? The answer lies in the following fundamental observation: At the atomic level, the rock
is not meaningfully organized like the brain; unlike the brain, the connections between atoms
1Atoms can store information at a density of greater than one bit per atom.
University of Oklahoma
researchers have stored 1024 bits in the magnetic interactions between protons of a single molecule containing
19 hydrogen atoms [69,70].
35

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
36
are randomly fixed (ideal rigid body) and cannot change throughout its lifetime. The brain,
however, self-organizes to achieve homeostasis – the equilibrium state. It is also noteworthy
that the mechanisms of self-organization that shape the system’s network topology are not
only apparent in the brain but are also exhibited in other biological systems that lack a cen-
tral nervous system, such as slime molds Physarum polycephalum, that can form comparable
efficiency, fault tolerance, and cost to those of real-world infrastructure networks similar to
that of the Tokyo subway system as seen in Figure 5.1 [29]. What makes the brain so unique
Figure 5.1: A comparison of the Tokyo subway system with the network of slime molds. The
network on the left shows the theoretical graph representation of the actual subway system of
Tokyo. On the right, 36 slime molds with food bits were placed on the spots of the cities of
Tokyo. After 26 hours, slime molds created a series of tubular connections that matched, to
a great extent, the efficient, well-designed Tokyo subway system. Image from Tero et al. [29].
from any other biological system lies in its inherent ability to strategically self-organize to pro-
cess information about its surroundings from perception and produce appropriate responses
through physical activity or thought. These observations lead to the question: How does one
define information?
At first, how one should define “information” is not apparent. For example, in finance,
the term information is used to represent numerical data such as stocks, and in biology, the
genetic sequences of DNA are said to carry information. It is evident that the use of the
term “information” depends on the nature of the subject, whether applied in finance, biology,
engineering, or physics. In this view, constructing a theory for universal information seems
impossible. How is it possible to define “information” without losing generality? To answer
this question, we will use Shannon’s information theory, developed in 1948 by Claude Shannon
in his seminal paper, A mathematical theory of communication, where entropy or information,

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
37
in its most abstract sense, is the negative reciprocal of probability or uncertainty [71, 73].2
Furthermore, to prevent confusion, whenever we use the term “information”, we shall mean
Shannon’s entropy for the remainder of the thesis.
5.1
A Primer on probability theory
To understand Shannon’s entropy, we must first understand probability theory [74, 75]. In
probability theory, outcomes of events can be broadly categorized into two cases: Discrete
and continuous events. By discrete events, we mean any countable event. For example, the
total number of all possible outcomes from throwing a 6-sided fair die is countable; that is,
there is a finite number of possible outcomes: {1, 2, 3, 4, 5, 6}. By contrast, by continuous
events, we mean any uncountable event. For example, the total number of possible outcomes
from randomly choosing a real number from 0 to 1 is uncountable; that is, there are infinite
possible outcomes.
The cumulative distribution function (CDF), denoted by FX, is defined as the probability
that a continuous random variable X takes on a value less than x. That is,
FX(x) = Pr[X ≤x],
−∞< x < ∞,
(5.1)
where FX is a monotonic increasing function with the property that
lim
x→−∞FX(x) = 0 and
lim
x→∞FX(x) = 1. Probability distributions for continuous cases are called probability den-
sity functions (PDFs), denoted by f(x), and can be calculated from the CDF by taking its
derivative with respect to its continuous random variable, defined by
f(x) = dFX(x)
dx
.
(5.2)
There are three conditions all PDFs must always satisfy:
2The name “Shannon’s entropy” is derived from historical literature. The concept of entropy was originated
in the study of heat in the late 18th century through the work of Rudolph Clausius, with the word itself deriving
from the Greek word trope meaning to change to illustrate the process of converting heat to work. Later,
Ludwig Von Boltzmann extended Clausius’ work and gave the first statistical definition of the second law
of thermodynamics or entropy. Claude Shannon then built upon Boltzmann’s work and used the concept of
entropy or information to develop a theory of communication [71]. Interestingly, there is also an alternative
way to interpret entropy or information. In an interview for the Scientific American magazine in 1971, Shannon
said he first decided to call the quantity “uncertainty function” but was later persuaded by John von Neumann
to call it entropy. Neumann was able to persuade Shannon for two reasons: One, because the name was already
used in statistical mechanics and, two, because no one really knew what entropy was, and in a debate, Shannon
would have the upper hand.

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
38
(I) Normalisation:
R ∞
−∞f(x)dx = 1,
(II) Non-negativity: f(x) ≥0,
(III) Units: [1/x].
The probability distributions for discrete events are called probability mass functions
(PMFs), denoted by p(x), and similar to PDFs, PMFs must always satisfy the three con-
ditions below:
(I) Normalisation:
∞
P
i=1
p(xi) = 1,
(II) Non-negativity: p(xi) ≥0 or 0 ≤p(xi) ≤1, ∀i
(III) Unit: dimensionless.
We immediately see that the critical distinction between PMFs and PDFs lies in property (III).
That is, PMFs are inherently dimensionless quantities, but PDFs always have units of [1/x].
Hence the term “density” for PDFs.
5.2
Defining Shannon’s entropy
5.2.1
Shannon’s discrete entropy
Let X be a discrete random variable with p(x) denoting its PMF. Shannon’s entropy of a
single discrete event is defined by the natural logarithm of the reciprocal of its probability.
That is,
Hi = ln
1
p(xi),
(5.3)
for i = 1, ..., n in units of nat or natural units of information [71, 76].3 Let us pause for a
moment and see the intuition behind equation (5.3). From the properties of logarithms, we
find that the more likely an event will occur, the less we will be surprised if we are to observe
it and hence have less information or less entropy. Conversely, the more unlikely an event is,
the more we will be surprised to observe it and hence, have greater information or greater
entropy. A plot of entropy vs. probability can be seen in Figure 5.2 below, where the entropy
decreases as probability increases.
3With the emergence of computers, it is common in the literature to define Shannon’s entropy using the
logarithm of base 2, in units of bits or binary units. In the thesis, however, we have resorted to using the
natural logarithm with units of nat, sometimes called nit or nipit. The base change from natural logarithm
and base 2 merely amounts to a multiplication by a constant, ln(2).

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
39
Figure 5.2: Entropy vs. probability using equation (5.3).
As the general reader may have noticed, the entropy associated with equation (5.3) can
only quantify single discrete events. As we are interested in quantifying entropy of multiple
events from the same distribution, we must extend equation (5.3) to quantify the average
entropy – or the entropy over the entire PMF. In other words, we must sum equation (5.3)
over all events for i = 1, ..., n, given as
H = −
X
i
p(xi) ln p(xi),
(5.4)
in units of nats, where the negative sign is owing to the property of logarithms. Let us now
study some examples.
5.2.2
Example: Intuition
Let X represent a Bernoulli process of two events labelled as “success” or “failure,” such that
p(X = x0) = 0 and p(X = x1) = 1. If we know an event cannot occur, then that means there
is no uncertainty or information with this event; and if we know an event does occur, then
again, that means there is no information with this event. Hence, H = −0 ln(0) −1 ln(1) = 0.
5.2.3
Example: Entropy of a discrete uniform distribution
Consider throwing a 6-sided fair die. Let X represent the outcome following a uniform distri-
bution. The possible outcomes for X are {1, 2, 3, 4, 5, 6} with each outcome having an equal
probability of 1/6. Shannon’s discrete entropy for this system yields

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
40
H = −
6
X
i=1
p(xi) ln p(xi)
= 6
 
1
6 ln(6)
!
= ln(6) [nats].
5.2.4
Shannon’s differential entropy
Shannon’s differential entropy for continuous events is defined as
Hdifferential(x) = −
Z ∞
−∞
f(x) ln f(x)dx,
(5.5)
in units of nats [71]. It is important to note equation (5.5), unlike its discrete form in equation
(5.4), is not a formal definition to continuous random variables based on axiomatic laws [71,72].
However, to a considerable extent, Shannon’s entropy for continuous events can be obtained
through a limiting process from the discrete case by dividing a PMF, p(xi), into small regions
and approximating an underlying PDF, f(x) [73]. The procedures are analogous to changing
Riemann sums (discrete functions) to Riemann integrals (continuous functions), often done
in calculus. In general, we can write
p(xi) = f(xi)(xi+1 −xi) = f(xi)∆x,
(5.6)
where ∆x is the constant bin size. Substituting equation (5.6) into equation (5.4), we obtain
Hdiscrete = −
X
i
f(xk) ln f(xk)∆x −ln ∆x,
(5.7)
where in the limiting case as ∆x →0.
Hcontinuous = −
Z ∞
−∞
f(x) ln f(x)dx −lim
x→0 ln[∆x].
(5.8)
This definition of continuous information is problematic because of the divergent term on the
right-hand side. However, if we define differential entropy as equation (5.5), we have a way to
measure entropy that must be calculated relative to some reference value representing the zero
point of entropy, a technique analogous to measuring electric potentials in electromagnetism
theory [75].
Lastly, we wish to note from hereonforth the subscript “differential” will be
omitted for continuous events.

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
41
5.2.5
Example: Entropy of an independent random point process
Consider the amount of time a postal clerk spends with his or her customer during work
shifts. Let X be a continuous random variable that represents the amount of time, in minutes,
following a memory-less exponential distribution, with the average amount of time spent with
each store clerk of 4 minutes. Hence, the exponential distribution is given by f(x) = λe−λx
with rate parameter of λ = 1/4. The differential entropy of the system yields
H = −
Z ∞
−∞
f(x) ln f(x)dx
= −
Z ∞
0
f(x) ln(λe−λx)dx
= −
Z ∞
0
f(x)[ln(λ) −λx]dx
= 1 −ln(λ)
= 1 + ln(4)
≈2.39 [nats].
5.3
Mutual information
The idea of Shannon’s entropy can be extended and applied to communication channels that
are similar to those seen in Figure 5.3 below. Here, an information source, or an input X,
is transmitted to a receiver Y . Ideally, messages are transmitted without error; in reality,
information is lost due to noise inherent in the system. The loss to noise is referred to as the
system’s equivocation, and the transmitted information can, in general, be calculated as
transmitted information = information source - equivocation.
Figure 5.3: A communication channel. Image from Shannon [71].
The expression for the net transmitted information, or the system’s mutual information,
is defined as
I(X : Y ) = H(X) −H(X|Y ),
(5.9)

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
42
where H(X|Y ) is the conditioned entropy between the input X and the receiver Y , given by
H(X|Y ) = −
X
y
p(y)
X
x
p(x|y) ln p(x|y)
= −
X
x,y
p(x, y) ln p(x|y).
(5.10)
For continuous events, the conditioned entropy becomes
H(X|Y ) = −
Z ∞
−∞
p(Y )
Z ∞
−∞
p(X|Y ) ln p(X|Y )dxdy.
(5.11)
Now, by substituting equations (5.10) or (5.11) into equation (5.9) for discrete and continuous
events, receptively, the explicit equation for mutual information for discrete events renders as
I(X : Y )discrete = −
X
x,y
p(X, Y ) ln p(X)
p(X|Y ),
(5.12)
and for continuous events, mutual information renders as
I(X : Y )continuous = −
Z ∞
−∞
Z ∞
−∞
p(X, Y ) ln p(X)
p(X|Y )dxdy.
(5.13)
Two important properties of mutual information applicable to both continuous and discrete
events include:
(I) Non-negativity: I(X : Y ) ≥0,
(II) Symmetry: I(X : Y ) = I(Y : X).
5.3.1
Example: Mutual information of Gaussian channels
Consider a Gaussian channel, where the output y is a superposition of the input x and noise
η, which are both independently drawn from a Gaussian distribution with x ∼N(µx, σ2
x) and
η ∼N(µη, σ2
η), respectively. Given that y = x+η, the sum of two Gaussian random variables
also results in a Gaussian with its variance given by σ2
y = σ2
x + σ2
η. The mutual information is
given by
I(X : Y ) = H(Y ) −H(Y |X)
= H(Y ) −H(η)
= 1
2 ln

2πe(σ2
x + σ2
η)

−1
2 ln[2πe(σ2
η)]
= 1
2 ln
 
1 + σ2
x
σ2
η
!
,

CHAPTER 5. SHANNON’S ENTROPY – A MATHEMATICAL TREATISE ON INFORMATION
43
where the ratio σ2
x
σ2η is commonly referred to as the signal-to-noise ratio [14].

Chapter 6
Constraining the brain
Since the late nineteenth century, it has been recognized that many aspects of brain orga-
nization can be accounted for by a parsimonious principle aimed at minimizing the wiring
cost involved in the anatomical organization of neuronal connections to constitute circuits of
neuronal networks or brain maps [14–16]. This insight was perhaps first articulated by Ram´on
y Cajal in 1899 on the basis of his microscopic studies of Golgi-stained neurons [77]:1
“All of the various conformations of the neuron and its various components are
simply morphological adaptations governed by laws of conservation for energy,
space, and time.”
These “Cajal conservation principles” have endured and have been supported experimentally
for over a century. However, over time they have been restated in more contemporary terms
as constraints of wiring cost (space and energy), conduction speed (time), and cytoplasmic
volume (material).
Motivated by Cajal’s conservation principles, we begin this chapter by introducing Ed-
win T. Jaynes’ theory behind the principle of constrained maximum entropy. We then argue
how one can mathematically map physical neuronal elements of axonal diameter and length to
action potential energy and how the spatial distribution of neurons and timing of action poten-
tials shape synaptic connectivity. These biological ingredients are then cast into a constrained
maximum entropy framework to derive joint probability distributions that statistically model
the structural and neuroanatomical arrangement of neurons and neuronal networks in the
brain.
1Santiago Ram´on y Cajal was a Spanish neuroscientist, pathologist, and histologist specializing in neu-
roanatomy and the central nervous system. He shared the Nobel Prize in Physiology or Medicine in 1906
together with the Italian scientist Camillo Golgi in recognition of their work on the structure of the nervous
system.
44

CHAPTER 6. CONSTRAINING THE BRAIN
45
6.1
Principle of constrained maximum entropy
The principle of constrained maximum entropy was made famous by a physicist, Edwin T.
Jaynes, in statistical mechanics. In his paper, Information Theory and Statistical Mechanics
published in 1954, Jaynes argued that
“...the fact that a certain probability distribution maximizes entropy subject to
certain constraints representing our incomplete information, is the fundamental
property which justifies the use of that distribution for inference. It agrees with
everything that is known but carefully avoids assuming anything unknown. It is
a transcription into the mathematics of an ancient principle of wisdom... [78]”
Therefore, in light of Jaynes’ argument, we shall also argue that this is the most principled
choice from a biological perspective as we wish to make the most minimal assumptions to
model the brain.
The technique that we will use is the calculus of variations.2 To find the distribution that
maximizes entropy, we pose a constraint optimization problem and introduce constants, or
Lagrange multipliers, associated with each constraint. We then find the maximal solution
by perturbing the distribution subject to the constraints.
In general, we must include a
normalization constraint which acts as one constraint to satisfy the normalization property of
probability distributions.
Let us first analyze the constrained entropy maximization problem subject only to a nor-
malization constraint, with its Lagrange multiplier denoted by λN. In this case, the Lagrangian
L becomes
L (p(x); λN) = −
Z
x
p(x) ln p(x)dx
|
{z
}
Shannon’s entropy
+λN
 Z
x
p(x)dx −1
!
|
{z
}
Normalization constraint
,
(6.1)
2The development of the calculus of variations was, to a great extent, propelled by studies in mechanics. It
was born out of necessity as a solution to the brachistochrone problem, involving mathematical optimization
to extremize functionals, proposed by Johann Bernoulli in 1696 as an open challenge to mathematicians [79].
Bernoulli wrote the problem statement as given two points A and B in a vertical plane, what is the curve traced
out by a point acted on only by gravity, which starts at A and reaches B in the shortest time? In the end, five
mathematicians – Isaac Newton, Jakob Bernoulli, Gottfried Leibniz, Ehrenfried Walther von Tschirnhaus and
Guillaume de L’Hˆopital – solved the problem independently, and four of the solutions (excluding L’Hˆopital’s)
were published in the same edition of the journal as Johann Bernoulli’s. In his paper, Jakob Bernoulli gave
proof to the brachistochrone problem showing that its solution is a cycloid or the brachistochrone curve.
Interestingly, a solution to a similar problem, called the tautochrone (isochrone) problem, was first proposed
by Christian Huygens in 1673 as a geometric proof to show that the curve for which the time taken by an
object sliding without friction in uniform gravity to its lowest point is independent of its starting point on the
curve is also a cycloid [80].

CHAPTER 6. CONSTRAINING THE BRAIN
46
where the first term on the right hand side is Shannon’s entropy, and the second term is from
the normalization constraint.3 The maximal solution is found by first taking the first variation
with respect to p(x), which yields4
δL =
Z
x
 
−ln p(x) + (−1 + λN)
!
dxδp(x).
(6.2)
Now, in order to find the maximal solution, the terms inside the brackets of equation (6.2)
must satisfy the stationary condition, that is,
δL = 0.
(6.3)
Thus, the maximum entropy distribution subject only to a normalization constraint can be
found by solving for p(x), and must satisfy the condition
−ln p(x) + (−1 + λN) = 0,
(6.4)
and solving for p(x), we obtain
p(x) = exp

−1 + λN

.
(6.5)
Equation (6.5), however, is not complete. To find the general closed form solution to equation
(6.5), we must cast it into the normalization constraint equation and explicitly solve for the
Lagrange multiplier λN in terms of its constraint. In general, if constraints form a system of
linear equations, then we can derive an explicit closed-form solution for p(x). In this case,
where we maximize entropy subject to a normalization constraint, p(x) is none other than the
uniform distribution [71].
Extending the analysis above, now constraining the mean µ of the distribution and by
denoting its Lagrange multiplier as λµ, the Lagrangian becomes
3The term Lagrangian here is not used in the dynamic’s sense, where it is traditionally defined as the dif-
ference between kinetic and potential energy. In fact, in his original paper, Information Theory and Statistical
Mechanics, Jaynes never used the term “Lagrangian” but still decided to refer the constraint constants as
“Lagrange multipliers.” However, it is common in the literature to find authors using the term Lagrangian for
equations such as equation (6.1). We believe this is most likely because in Karush and Khun’s original paper
in optimization theory, equations such as equation (6.1) and alike were also referred to as the Lagrangian
and may have been lost in translation over the years which prompts confusion. Thus, in the thesis, we have
decided to go with “Lagrangian” in the sense of Karush and Khun [81].
4The existence and uniqueness of the solution p(x) is justified by considering KKT (Karush-Kuhn-Tucker)
conditions but these will not be discussed here, as it lies within the realm of convex optimization theory.
However, for those interested, the papers are found in [81].

CHAPTER 6. CONSTRAINING THE BRAIN
47
L (p(x); λN, λµ) = −
Z
x
p(x) ln p(x)dx + λN
 Z
x
p(x)dx −1
!
+ λµ
 Z
x
xp(x)dx −µ
!
|
{z
}
Mean constraint
. (6.6)
Once again, by following similar procedures outlined above, we obtain
p(x) = exp

−1 + λN

exp

λµx

.
(6.7)
By substituting equation (6.7) into the normalization and mean constraints, the resulting
distribution p(x) that maximizes its entropy is the exponential distribution [14,71].
In general, constraint optimization problems can have an arbitrary number of constraints.
We will see in the upcoming section that the idea is to pose a constrained optimization problem
of Shannon’s entropy using biological constraints of the neuron’s action potential power and
synaptic connectivity. For now, we lay out the general equation given below:
L (p(x); λN, λi) = −
Z
x
p(x) ln p(x)dx
|
{z
}
Shannon’s entropy
+λN
 Z
x
p(x)dx −1
!
|
{z
}
Normalization constraint
+
X
i
λi
 Z
x
fi(x)p(x)dx −ci
!
|
{z
}
Miscellaneous constraints
,
(6.8)
where the last term in equation (6.8) represents all the constraints with its associated Lagrange
multiplier λi, and fi(x) is a function associated with constraints where ci denotes its constant
values. Now, solving for p(x) in equation (6.8), we obtain a general solution to the maximum
entropy distribution subject to an arbitrary number of constraints given by
p(x) = exp

−1 + λN

exp
 X
i
λifi(x)

.
(6.9)
It is important to note that although we have found a solution that maximizes entropy,
we have not yet shown whether this is truly a maximum solution. In order to check for this
condition, we must examine the second variation of the Lagrangian with respect to p(x). This
yields
∂2L
∂p(x)∂p(x) = −1
p(x),
(6.10)
where p(x) is a maximum solution if (6.10) is always be negative for the defined ranges of x.
Notice that this condition holds as p(x) is always positive. Hence, p(x) is the solution that
maximizes entropy.

CHAPTER 6. CONSTRAINING THE BRAIN
48
6.1.1
Example: The maximum entropy distribution subject to con-
strained variance
We wish to maximize
L =
Z ∞
−∞
p(x) ln p(x)dx + λN
 Z ∞
−∞
p(x)dx −1

+ λv
 Z ∞
−∞
(x −µ)2p(x)dx −σ2

,
(6.11)
subject to
Normalization constraint:
Z ∞
−∞
p(x)dx = 1,
Variance constraint:
Z ∞
−∞
(x −µ)2p(x)dx = σ2,
where µ is the mean and σ2 is the variance of the distribution p(x), with its associated Lagrange
multipliers λ1 and λ2, respectively. The first variation of equation (6.11) with respect to p(x)
leads to the stationary condition,
−1 −ln p(x) + λN + λv(x −µ)2 = 0.
Solving for p(x), we obtain
p(x) = exp
h
−1 + λN + λv(x −µ)2i
.
Lastly, λN and λv must be found using the two constraints. Thus, the distribution that yields
maximum entropy subject to a constrained mean is the normal or Gaussian distribution.
6.1.2
Example: A universal model of single-unit sensory receptor
action
We now present an example that bridges much of what we have discussed thus far to show
the utility of Shannon’s entropy in the context of biological learning and memory of sensory
adaptation [82]. The Sensory Neural Entropy equation developed by Kenneth Norwich and
Willy Wong at the University of Toronto in 1994 are motivated by a constrained maximization
framework of Shannon’s entropy.

CHAPTER 6. CONSTRAINING THE BRAIN
49
We begin by considering “isolated” sensory receptors, or any sensory receptor that func-
tions independently of other sensory receptors, connected to its primary afferent neuron –
neurons that carry sensory stimuli to the brain. For example, a photoreceptor connected to
its sensory ganglion neuron, which is responsible for detecting light, or photons are responsible
for sending signals in forms of action potentials to the brain for sight. The Sensory Neural
Entropy equation is based on the premise that information is conserved when transmitted by
an efficient sensory channel [82].
The system’s input, or stimulus, is the intensity of a sensory signal, I, be it chemical,
optical, or in other forms, and the output is the impulse frequency in units of spikes/second.
We will regard the stimulus signal to the system to have statistical properties. For example,
the incoming signal of light due to photons can be sufficiently governed, statistically, by
a Gaussian or Poisson process [82]. In general, we shall denote σ2
s as the variance of the
stimulus that is governed by such processes. Since the stimulus is always compounded with
noise drawn independently from a Gaussian distribution of variance σ2
n, the total variance of
stimulus is the linear combination of the two variances, σ2
s + σ2
n. Thus, when the stimulus
signal and noise are Gaussian, the entropy is given by (recall Part 5)
H = 1
2 ln
 
σ2
s + σ2
n
σ2
n
!
.
(6.12)
We will now assume the receptor to be sampling its stimulus signal. If the receptor regards
its stimulus as providing a stationary time series of signal intensity over some interval of time
during which it has made m samplings of the stimulus intensity, then, by the central limit
theorem, the variance of the mean stimulus will be σ2
s/m. Upon substitution, we obtain
H = 1
2 ln
 
σ2
s/m + σ2
n
σ2
n
!
.
(6.13)
For physical systems, such as energy, pressure, concentration, and density, the variance can
be related to the mean signal intensity, I, using a relationship of the form,
σ2 ∝Ik
(6.14)

CHAPTER 6. CONSTRAINING THE BRAIN
50
where k is some positive number found experimentally.5 For example, the molecular density
of a dilute gas is a fluctuating quantity governed by the Poisson distribution, whose variance
is equal to its mean signal intensity. That is, σ2 = I with k = 1.
To proceed further, we will now model the rate of sampling of stimulus m from the sensory
receptor as a linear differential equation in equation (6.13) proposed by Wong and Norwich,
known as the relaxation model, given in the form
dm
dt = −a(m −meq), a > 0.
(6.15)
In this example, we shall only consider cases when meq is a positive constant for the sake of
simplifying the analysis. With meq held as a constant, the general solution to the equation
above is given by
m(t) = m(0)e−at + meq(1 −e−at), t ≥0.
(6.16)
Let us now pause and see what equation (6.16) entails in the context of sensory receptors.
At initial time, t = 0, m(0) represents the receptors initial “memory” at the beginning of a
new stimulus. Over time, the receptor learns and becomes habituated due to stimulation and
eventually relaxes and stabilizes to its equilibrium value, meq. Now, for the case where the
receptor is adapted to a very small stimulus, or when m(0) ≈0, the equation simplifies to
m(t) = meq(1 −e−at), t ≥0.
(6.17)
Thus, by combining equation (6.17) with equations (6.13) and (6.14), we obtain
H = 1
2 ln
"
1 +
βIn
meq(1 −e−at)
#
, t ≥0.
(6.18)
The fundamental assumption of the entropy theory of sensation states that the impulse
frequency F in the primary afferent neuron issuing from a sensory receptor is directly propor-
tional to the entropy H [84]. That is,
5Equation (6.14) is attributed to Steven’s power law, named after psychophysicist Stanley Smith Stevens
[83] for publishing a body of psychophysical data to support it in 1957. This law defines an empirical relation-
ship between the increased intensity of the physical stimulus and the perceived magnitude of the sensation
created by the stimulus. Mathematically, the general form is given by Ψ(I) = αIk, where I is the intensity of
stimulus in units such as decibels for loudness or frequency for vibration, and Ψ(I) is a mapping from stimulus
intensity I to the magnitude of the sensation caused by the stimulus, where k is the exponent that depends
on the type of stimulation, and α is the proportionality constant.

CHAPTER 6. CONSTRAINING THE BRAIN
51
F = kH
= 1
2k ln
"
1 +
βIn
meq(1 −e−at)
#
, t ≥0
(6.19)
where k > 0 is the proportionality constant, and the remaining parameters {β, a, k, n} are all
found experimentally through numerical analysis. It is also important to note that the stimulus
I is constant, such as the step function, as we have assumed meq is a positive constant.
Equation (6.19), or the Sensory Neural Entropy equation, has been able to successfully
explain empirical sensory adaptation data [82]. For example, by making use of Taylor series
approximations for exponential functions, one can derive Fechner’s Law from equation (6.19)
that has been used to describe impulse responses in a primary afferent since the paper of
Hartline and Graham [85, 86].
Moreover, by making use of Taylor series approximations
for logarithmic functions, one can derive the “power law of sensation” from equation (6.19)
championed by S. S. Stevens and is commonly used in the literature to describe sensory data
[87].
6.2
Neurobiological constraints
Armed with Jaynes’ principle of constrained entropy maximization, we are now in a position
to identify the set of neurobiological constraints using equation (6.8) to complete our analysis.
In particular, we seek functions fi(s, ℓ) associated with constraints ci that are functionally
related to the neuron’s axonal diameter s and length ℓ, which, as we shall see, are essential
neuroanatomical features that mediate action potentials and synaptic connectivity in the brain
that ultimately change the shape and type of distribution which results from maximizing
entropy. Thus, the objective now is to translate how constraints of energy, space, and time
are reflected in the organizational structure of the neuron’s axonal diameter and length that
can be modeled statistically by the joint distribution p(s, ℓ) subject to biological constraints.
6.2.1
Action potential power constraint
A primer on nonlinear cable theory
The starting point lies in modeling a neuron using nonlinear cable theory [88], as seen in Fig-
ure 6.1. The top diagram of Figure 6.1 shows the directional flow of membrane current Im(x)
that travels across the membrane and the internal axial current Ii(x) flowing unidirectionally
along the axial direction x of the axon, measured in units of amperes per unit distance.
Both currents flow in successive order, from segment #1 to #3 of the axon, assumed to

CHAPTER 6. CONSTRAINING THE BRAIN
52
Figure 6.1: Electromechanical model of a neuronal axon using cable theory.
Image from
Keener [88].
be cylindrical in shape, which is by and large an estimation to simplify the analysis. The
dynamics of action potentials are modeled using the neuronal circuit found on the bottom
diagram of Figure 6.1, which includes the membrane’s capacitance Cm measured in farads
per unit area, gating channel functions, and ionic current Iion(x) measured in amperes per
perimeter. Now, using Kirchoff’s current conservation law, we obtain a second-order partial
differential equation of the form
τm
∂V
∂t + RmIion(V, t) = λ2
m
∂2V
∂x2 ,
(6.20)
where constant τm is known as the time constant in units of time, and λm is the space
constants in units of length. The space and time constants, denoted by λm and τm, respectively,
expressed in terms of measurable biological properties, are given as
λm =
r
Rms
4Rc
,
τm = RmCm,
(6.21)
where Rm is the membrane resistivity and Rc is the axon’s cytoplasmic resistivity both in
units of ohm times unit length, and s is the axon’s diameter in units of length.
Equation (6.20) is known as the nonlinear cable equation and has been extensively applied
to analyze cable properties of nervous systems [90].6
The nonlinearity aspect is because
all cellular mechanisms associated with the activity of ion channels embedded in Iion(V, t)
6To derive the linear cable equation [88], this amounts to setting Iion(V, t) = 0. Physically, this models the
action potential dynamics of a completely naked neuron without any ion channels. For this reason, the linear
cable equation is referred to as the “passive” cable equation and the nonlinear cable equation as the “active”
cable equation because, unlike passive cables, ion channels are active.

CHAPTER 6. CONSTRAINING THE BRAIN
53
are nonlinear functions of membrane potential V and time t. For example, if we substitute
Iion(V, t) with functions conforming to empirical observations governing the flow of sodium
and potassium ions, one can derive the Hodgkin-Huxley equations [36].
To move forward, we will now treat action potentials as traveling waves. By a traveling
wave, we mean a solution to equation (6.20) that travels at constant velocity with a fixed shape
[89]. (The wave is also minuscule in width, effectively representing the “spiking” in action
potentials.) In the next section, we shall see how modeling action potentials as traveling
waves can be bridged to measure conduction velocity, which will then be used to measure
action potential power.
The bistable equation and traveling waves: Bridging cable theory to conduction
velocity of action potentials
To bridge the nonlinear cable equation to the conduction velocity of action potentials, we
shall first nondimensionalize equation (6.20) to simplify the analysis.
First rescaling the
ionic current by defining Iion = −y(V, t)/Rm for some function y(V, t), which is dependent
on membrane potential V and time t, and then defining X = x/λm and T = t/τm, upon
substitution we obtain the nondimensionalized nonlinear cable equation of the form
∂V
∂T = ∂2V
∂X2 + y(V, t).
(6.22)
Although y in general is a function of membrane potential and time, it is sufficient to
simplify it to a function of membrane potential only, which then yields a special case of the
nonlinear cable equation – the bistable equation. Namely,
∂V
∂T = ∂2V
∂X2 + y(V ).
(6.23)
The bistable equation is so named because it has two stable points, i.e., the two zeros of the
nonlinear function y(V ), and it is related to the Fitzhugh-Nagumo model without recovery,
which describes the chaotic dynamics of an excitable system [89]. An example of such functions
used in the literature are the cubic polynomial
y(V ) = αV (V −1)(α −V ),
0 < α < 1,
(6.24)
and the piecewise linear function
y(V ) = −V + h(V + α),
0 < α < 1,
(6.25)
where h(V ) is the Heaviside or unit-step function. Equation (6.25) is particularly useful in
the study of traveling wave solutions of bistable equations because it is analytically tractable

CHAPTER 6. CONSTRAINING THE BRAIN
54
and retains many important qualitative features [89].
By a traveling wave solution, we mean a solution that is translation-invariant to equation
(6.23) that provides bistability and travels with constant speed.
In particular, we seek a
solution of the form
V (X, T) = U(X + cT) = U(ξ),
(6.26)
for some (yet to be determined) values of c. The new variable ξ, called the traveling wave
variable, has the property that fixed values move in spacetime with fixed speed v [89]. Unpa-
rameterizing equation (6.26), we obtain
V (x, t) = U
 
x
λm
+ c t
τm
!
.
(6.27)
Since the wave travels a distance of λm over a time interval τm, the speed v is readily inferred
as
vu(s) = cλm
τm
=
c
2Cm
r
s
RmRc
.
(6.28)
Equation (6.28), however, is not yet complete. Recall from Chapter 2 that neurons come in
two flavors: myelinated or unmyelinated. Equation (6.28) assumes that a neuron is unmyeli-
nated and thus measures the conduction velocity of an action potential traveling across an
unmyelinated neuron; hence, we have placed a subscript u.
To derive the expression to measure the saltatory conduction velocity of a myelinated
neuron – the speed it takes the action potential to jump between successive nodes – we
modify equation (6.28) with additional parameters: The length of the node, denoted by µ,
and the length of the myelin sheath between the nodes, denoted by L. The resulting equation
yields a discrete bistable equation, and the saltatory conduction velocity is given by7
vm(s) = L + µ
√
uL
vu(s).
(6.29)
Although it is tempting to leave equation (6.29) as is, it is vital to ask whether the parameters
L and µ have functional dependencies of neuronal diameter or other properties such as axonal
length. Indeed, it was found that the length of myelin sheath between nodes L is proportional
to axonal diameter, but the nodal length µ does not have any dependencies on neuronal
structure [89,91]. Thus, we can unfold equation (6.29) as
7The derivation can be found in [89] for those interested.

CHAPTER 6. CONSTRAINING THE BRAIN
55
vm(s) = L + µ
√µL
c
2Cm
r
s
RmRc
= βs + µ
√µβ
c
2Cm
r
1
RmRc
,
(6.30)
where L = βs for some positive constant β found experimentally.
The key observation lies in noticing that vu(s) grows with the square root of axonal di-
ameter, and vm(s) grows linearly with axonal diameter. This is why, for example, neurons
below 0.5µm are usually unmyelinated in the optic nerve of guinea pigs, and above that
point, neurons are usually myelinated [21,22]. See Figure 6.2 below for further comparisons
of conduction velocity across different species in the animal kingdom.
Figure 6.2: A plot of conduction velocity [m/s] vs. axonal diameter [µm] of myelinated or
unmyelinated neurons observed across different species in the animal kingdom on a logarithmic
scale. Image from Bullock and & Horridge [92].
Lastly, equation (6.28) in the literature is at times approximated with
vu(s) = √s m/s.
(6.31)
For example, if we substitute s = 500µm – the axonal diameter of the squid’s giant axon – into
equation (6.31), we obtain an action potential speed of 22.4 m/s, which compares favorably to
the measured value of 21.2 m/s from the Hodgkin and Huxley experiment [36]. Furthermore,
it has been empirically shown that the increase in conduction velocity of a myelinated axon
compared to an unmyelinated axon increase by a factor of 6√s, and thus equation (6.31)
becomes

CHAPTER 6. CONSTRAINING THE BRAIN
56
vm(s) = 6s m/s.
(6.32)
Bridging conduction velocity to action potential power
Action potentials travel along neurons at various speeds through axons of various axonal
diameters and lengths, each demanding different amounts of power to function. The derivation
that bridges conduction velocity and action potential power is inspired by Perge et al. [14,
15, 21] with the study of the adult male guinea pig. Within each ganglion cell of the optic
nerve of the guinea pig, it was found that every action potential requires some amount of
ATP molecules for each micrometer of the axon, and each ATP generates some amount of
energy. From previous sections, since we can assume that the action potential is traveling
with a constant finite speed from the bistable equation, the power required to sustain a single
action potential is given by
˜π(s) = σπAv(s),
(6.33)
where σ is the amount of energy per ATP molecule, measured in units of joules per ATP; πA
is the amount of ATP molecules for each micrometer of axon, measured in units of ATP per
micrometer of axon; and v(s) is the conduction velocity of an action potential, measured in
units of micrometer of axon per unit time.
If F is the frequency of action potentials in units of spikes/second, then the total number
of action potentials n over a duration of time t is given by n = FT. Thus, the power required
to generate n action potentials becomes [14]
π(s) = n˜π(s) = σnπAv(s).
(6.34)
As conduction velocity can differ depending on whether neurons are myelinated or not,
we shall decompose equation (6.34) into two equations, and differentiate the amount of power
required to generate n action potentials between unmyelinated and myelinated neurons as
π(s) =





σunπA,uvu(s),
if unmyelinated axon
σmnπA,mvm(s),
if myelinated axon
(6.35)
It is evident that equation (6.35) quantifies the amount of power required for an active neu-
ron to generate n action potentials. We can now define the action potential power constraint
as

CHAPTER 6. CONSTRAINING THE BRAIN
57
Z
s,ℓ
f2(s, ℓ)p(s, ℓ)dsdℓ=
Z
s,ℓ
π(s)p(s, ℓ)dsdℓ= Π
(6.36)
where Π is the average amount of power required to generate action potentials in the network
due to limited resources of ATP molecules.
6.2.2
The Oka-Ikeda g-ratio constraint: Quantifying the tradeoff
between unmyelinated and myelinated neurons
The brain contains, on average, 100 billion neurons that fire action potentials at different
velocities.
The velocity of action potentials not only contributes to the amount of power
involved in using ATP molecules but, as discussed in Chapter 3, the rate at which action
potentials fire also constitutes the speed of thought. How does the brain make sense of action
potentials that all fire at different velocities? We argue that the brain must balance a tradeoff
between the number of myelinated or unmyelinated neurons to compensate for the limited
amount of material, such as myelin or Schwann cells or ion channels. The brain, therefore,
compensates for limited materials by structurally and topographically segregating the brain
into two large subregions: gray matter and white matter.8
Gray matter consists primarily of unmyelinated neurons, and white matter consists pri-
marily of myelinated neurons. Roughly 40% of the human brain is gray matter and 60% of
white matter [94]. White matter is found mainly in the central region of the brain and is re-
sponsible for communication between the various gray matter regions. From an evolutionary
perspective, the brain has evolved to communicate white matter to gray matter to process
information much faster to prevent any loss of “useful” information from interacting with the
external milieu to maximize survival.
How does the brain maintain its structural integrity through the distributions of unmyeli-
nated and myelinated neurons to diversify rates of communication? To capture such tradeoffs
between unmyelinated or myelinated neurons, we will use the concept of the g-ratio – the
ratio between the axon diameter of the neuron to its fiber diameter (i.e., axon diameter plus
myelin sheath thickness). In its simplest form, the g-ratio is given by
g = s
D, D > 0,
(6.37)
where s is the axonal diameter and D is the fiber diameter.
8In 1543, in the seventh book of his monumental work, De humani corporis fabrica, the Renaissance
anatomist Andreas Vesalius [93] was the first to distinguish clearly between white matter and the gray matter
that overlay regions of the cerebral cortex.

CHAPTER 6. CONSTRAINING THE BRAIN
58
Equation (6.37), however, presents a problem: The g-ratio is a function dependent on both
diameter s and fiber D, and we are after a relationship that is dependent on only diameter,
axonal length, or both. To proceed further, we will now extend the definition of the g-ratio
with the works of Oka and Ikeda [96] with the in-vivo study of motor nerve conduction velocity
and neuronal regeneration of Sprague-Dawley rats. That is, the relationship between the g-
ratio was found to be strictly a function only of axonal diameter s following a logarithm
relationship of the form
g(s) = c1 ln(s) + c2,
(6.38)
where c1, c2 are constants found experimentally during model fitting. Typical parameter values
can be found in Table 6.1 below. Lastly, equation (6.38) shall be referred to as the Oka-Ikeda
g-ratio to prevent confusion in later chapters with the traditional definition of the g-ratio
given by equation (6.37). To capture the g-ratio property of biological neuronal networks in
the brain, we define the Oka-Ikeda g-ratio constraint as
Z
s,ℓ
f3(s, ℓ)p(s, ℓ)dsdℓ=
Z
s,ℓ
g(s)p(s, ℓ)dsdℓ= G
(6.39)
where G is the average g-ratio in the network due to the limited amount of resources for
myelination, such as ATP molecules and Schwann cells that surround the neuron with myelin
for proper brain development. (Recall §2.3.)
Table 6.1: G-ratio parameters of the Sprague-Dawley rats. Thirty rats were divided into five
equal groups, one control group and four groups subject to nerve transection and immediate
suturing, followed by 50, 100, 150, and 200 days of regeneration. Fitted parameters c1 and c2
of each group were shown to be positively correlated to the g-ratio, with correlation coefficients
ranging from 0.735 to 0.910 [96].
Days of regeneration
Total number of neurons in each group
c1
c2
50
2065
0.39
0.56
100
3993
0.38
0.86
150
4520
0.40
0.84
200
3532
0.42
0.91
Control
1763
0.22
0.51
6.2.3
Distance-dependent synaptic connectivity constraint
Where and how neurons are placed locally in neuronal networks and globally in the brain is an
important feature that must be captured due to inherent constraints of material and resources.
The distance-dependent synaptic connectivity constraint limits the number of synaptic con-

CHAPTER 6. CONSTRAINING THE BRAIN
59
nections by constraining the relative distance between neurons, i.e., how far apart neurons
are relatively placed in the neuronal network from one another. Microscopically, the spa-
tial distance between hundred or thousands of neurons in a given network constitutes the
neuronal groups, in Edelman’s sense, which forms the primary neuronal repertoire in postna-
tal development, and then stabilizes into a secondary neuronal group with highly functional
capabilities.
To formulate our argument, let us consider Markram et al.’s [13] simple experiment from
individual simultaneous recordings of pyramidal neurons in Wistar rats’ somatosensory cortical
slices (300 µm thick), as seen in Figures 6.3(A) and (B).
Figure 6.3: (A-B) Region of the somatosensory cortex where recordings were carried out on
the Wistar rat indicated by the red dot; (C): Graph theoretical representation of the neuronal
network found in A; (D): Experimental recordings of spikes from individual neurons. For
example, in the first row, we see neuron 1 (red) activates neurons 7 and 10 (light green and
dark blue, respectively) indicating existing connections between the three neurons [Scale bars:
horizontal, 100 ms; vertical, 1 mV (15 mV for action potentials)]; (E-G): Connection as a
function of intersomatic or Euclidean distance between neurons. Image from Markram et al.
[13]
These connections were first determined by exciting a single neuron and observing the
relative activity of other neighboring neurons, and was then graphically mapped to model the
neuronal network, as seen in Figure 6.3(C) and (D). It was found that in postnatal development
(14-16 days after birth), synaptic connections between pyramidal neurons were not formed at
random, but follow genetically prescribed rules of distance-dependent connectivity that decays
with intersomatic distance for unidirectional and bidirectional connections, reminiscent of a
power-law or exponential distribution, as seen in Figures 6.3(E)-(G). Thus, to capture such

CHAPTER 6. CONSTRAINING THE BRAIN
60
distance-dependent connectivity properties of biological neuronal networks which shape the
network topology, we shall define a simple distance-dependent synaptic connectivity constraint
of the form
Z
s,ℓ
f4(s, ℓ)p(s, ℓ)dsdℓ=
Z
s,ℓ
ℓp(s, ℓ)dsdℓ= L
(6.40)
where ℓapproximates the axonal length of a neuron; in a neuronal network, ℓapproximates
the Euclidean intersomatic distance between a pair of neurons that are cylindrical in shape as
previously assumed in §6.2.1. Hence, L, on average, measures the Euclidean intersomatic dis-
tance between neurons in a neuronal network; L effectively constrains the spatial distribution
of neurons in the brain due to differences in energy use – longer neurons require more power
(ATP molecules), and shorter neurons require less power. Furthermore, notice that when
equation (6.40) is cast into an entropy maximization framework, it results in a maximum en-
tropy exponential distribution (due to constrained mean) and captures the distance-dependent
synaptic connectivity profile curves reported by Markram et al. [13], as seen in Figures 6.3(E)-
(G). To move forward, however, we require one last constraint, as using equation (6.40) alone
will lead to an insufficient explanation for biological neuronal networks that exhibit skewed
synaptic connectivity distributions. Thus, in the next section, we shall add one last constraint:
Timescale-dependent synaptic connectivity.
6.2.4
Timescale-dependent synaptic connectivity constraint
The timescale-dependent synaptic connectivity constraint limits the number of neurons that
each neuron can communicate to in the brain; at a macroscopic level, this is observed in the
limited number of brain maps each brain map can communicate to in the brain. In other
words, it prevents the development of fully connected networks. How can one mathematically
model a timescale-dependent synaptic connectivity that inherently satisfies Hebbs’ postulate,
wherein by timescale, we mean the relative spike timing of action potentials?9 To answer this
question, we shall use Castelluzo et al.’s [19,20] definition of synaptic connectivity to define
a relationship between timescale and the logarithm of Euclidean distance of brain regions to
synaptic connectivity, wherein we extend this concept to neuronal networks. This approach
complements our discussion thus far since §6.2.1, as we have assumed neurons are cylindrical in
9The reader may question why we have decided to use the name timescale dependent synaptic connectivity
versus. spike-timing dependent synaptic connectivity. This is because, in the neuroscience literature, spike-
timing dependent plasticity is commonly associated with the piecewise exponential model empirically inspired
by Markram et al.’s [97–99] work on the effects of activity-based driven forms of short-term and long-term
memory affects between neurons in the neocortex. Thus, we have resorted to using the term timescale in
substitution for spike-timing to prevent confusion.

CHAPTER 6. CONSTRAINING THE BRAIN
61
shape, and thus, the distance that separates any pair of neurons is the Euclidean intersomatic
distance ℓ.
There are two main approaches to study how spike timing shapes neuronal connectivity.
The first is to study an active brain executing demanding cognitive tasks, such as performing
a new skill for the first time, and the second is to study a brain at its resting state.
In
particular, we will focus on analyzing the brain’s resting state not only to simplify the analysis
but also because, since the discovery of resting state networks, such as the Default Mode
Network, analyzing resting-state brain activity has been used to probe general properties of
brain networks [19].
To analyze the relationship between spike timing and neuronal connections, we will use
Castelluzo et al.’s [19] study of the brain at resting state from magnetoencephalography (MEG)
recordings of 72 functional brain maps found within the cerebral cortex, as seen in Figure 6.4.
These brain maps were selected from inter-hemisphere and intra-hemisphere parts of the brain
Figure 6.4: The different brain maps used in the study of Castelluzo et al., indicated as
numbered nodes [19].
that all possess unique functionality. Connections between brain maps were determined using a
zero-delay Pearson cross-correlation to measure how closely synchronized relative spike timings
were between brain maps, as seen in Figure 6.5. In essence, the Pearson correlation signifies
Hebb’s theory of brain development at a brain map level: Brain maps that fire together, wire
together, or brain maps that are closely in sync succeed to link.
As the derivation is a little tedious, we shall outline the methodology by Castelluzzo et
al. [19] to determine the relationship between distance-dependent synaptic connectivity and
relative spike timing of action potentials. First, the sample Pearson correlation coefficient is
determined from all possible combinations of connections between the 72 brain maps. The
sample Pearson correlation coefficient is evaluated on a moving window of width w centered
on some time. The window width is then used to obtain a p-value diagram often used in
statistics to test a null hypothesis, or specifically, in this case, to test the probability if a

CHAPTER 6. CONSTRAINING THE BRAIN
62
Figure 6.5: Brain activity reconstruction using raw MEG recordings (286 sensors) of two
brain maps. Signal intensity in auxiliary units of amperes (by “auxiliary”, we mean MEG
data were obtained from empty-room noise recordings) are computed with a power time series
of recordings passed through a high-pass filter to minimize noise contributions inherent in the
sensors. The plot shows two burst-like oscillations from two brain maps, with the bottom plot
magnifying the two. The magnification ultimately indicates that connections exist between
the brain maps assessed with the Pearson correlation coefficient. Image from Perinelli et al.
[20].
connection exists or not [19]. The p-value is ultimately used to evaluate an efficiency function,
η(w), which is dependent on the window width, w. The window width W at which η first
crosses a threshold η0 is assumed to be the minimum timescale for which a pair of brain
maps is considered to be functionally correlated or connected. (Castelluzzo et al. has used
η0 = 0.5.) The minimum timescale W, which indicates a connection, is known as the timescale
of observability.
The Pearson correlation coefficient and its p-value diagram are ultimately used to de-
termine what functional relationship between W and ℓbest models cortical activity data
reconstructed out of MEG resting state time series recordings.10 The three cases tested were:
When W grows linearly with ℓ, when the logarithm of W grows logarithmically with ℓ, and
when W grows with logarithmically with ℓ. These three cases result in three different joint
probability density functions: f(W, ℓ), f(ln W, ln ℓ), and f(W, ln ℓ). These density functions
are then all marginalized, yielding conditional density functions of form f(W|ℓ), f(ln W|ln ℓ),
and f(W|ln ℓ) [19]. When these conditional probability density functions are projected onto
the (W, ℓ) plane, we obtain results such as Figure 6.6. Here, we see that when f(W|ln ℓ) of W
given ln ℓis projected onto the (W, ℓ) plane, it yields the set of white dotted lines that repre-
10These datasets were collected from 20 healthy subjects available in the Human Connectome Project
database.

CHAPTER 6. CONSTRAINING THE BRAIN
63
sent the average value of W given ln ℓ. The black solid lines stem from a best-fit procedure
concerning a piecewise-linear relationship between four different cases of network connectivity:
A network containing all 72 brain maps, a network with pairs of brain maps located only in the
left hemisphere, a network with pairs of brain maps located only in the right hemisphere, and
a network with pairs of located in each part of the hemisphere. Among all of these different
functional cases analyzed, a logarithmic relationship of the kind
Figure 6.6: Image taken from Castelluzo et al. [19] where d is ℓin this case, and the ℓaxis is in
log scale. Conditional density function f(W|ln ℓ) of W given ln(ℓ). obtained by partitioning
both the ln(ℓ) range and the W range in 50 bins. White dots show the average value W of W
given ln(ℓ). White dashed lines bound the 68% confidence region for W, namely the region
within one standard deviation from the average W. Black solid lines stem from a best-fit
procedure concerning a piecewise-linear relationship between W and ln(ℓ). Black dashed lines
correspond to the ln(ℓ) values at which the slope of the piecewise-linear relationship changes.
w(ℓ) = c3 ln(ℓ) + c4.
(6.41)
best describes the functional relationship between W and ℓ[19].
While the timescale of observability, W = W(ℓ), measures the timescale of action potential
signals in the brain, it is not related to the conduction velocity. The source of correlation are
segments of pairs of action potentials between different networks that are strong enough to
overcome a noisy background; that is, the contributions of noise inherent in generating action
potentials themselves and the noise inherent in the MEG recordings. As the signal-to-noise
(SNR) ratio of the action potentials is generally more significant than that of the noise inherent
in MEG recordings, the timescale of observability can be viewed as the inverse of the action
potential’s SNR ratio.
Thus, two networks having maximum connectivity – or indicating
a strong correlation – correspond to sequences of action potentials nearly identical in time,
corresponding to a vanishing timescale of observability w.
In contrast, two disconnected
networks produce an infinite w. Typical parameter values of equation (6.41) can be found in

CHAPTER 6. CONSTRAINING THE BRAIN
64
Table 6.2 below.
Table 6.2: Fitted parameter values from [19] using network seen in Figure 6.4. The hemisphere
column contains four sets of data: The first set contains all the nodes in the network; the
second set contains links for which both nodes are located in the left hemisphere (left-left); a
third set made of links for which each node belongs to an opposite hemisphere (left-right); the
last set made of links for which both nodes are located in the right hemisphere (right-right).
The three different cases correspond to three different regimes wherein functional connectivity
was observed.
Hemispheres
Parameters case 1
Parameters case 2
Parameters case 3
c3 [s]
c4 [mm]
c3 [s]
c4 [mm]
c3 [s]
c4 [mm]
All links
7.0
0
19.1
44
6.7
68.3
Left-Left
7.0
0
19.0
44
5.3
71
Left-Right
8.0
0
19.4
46
6.9
67.5
Right-Right
6.9
0
19.1
44
8.8
67
To capture such timescales of brain regional and neuronal networks, we now define the last
constraint of the form
Z
s,ℓ
f5(s, ℓ)p(s, ℓ)dsdℓ=
Z
s,ℓ
w(ℓ)p(s, ℓ)dsdℓ= W
(6.42)
where W is the average timescale of observability in the network which constrains the relative
spike timing of action potentials between brain regions or neurons due to constraints of space
and time.
6.3
The next line of attack
Armed with the knowledge of Jaynes’ principle of constrained entropy and the set of biological
constraints from the previous sections, we are now in a position to formulate our arguments in
mathematical terms to derive a set of statistical inference models that govern the organization
of neuronal structure and network topology, which play an important role in biological learning
and memory perhaps across all if not many biological systems that exhibit some form of
intelligence. Let us now formulate a maximum entropy principle for the brain.

Chapter 7
A Maximum entropy principle for the
brain
Inspired by the works of Michael Merzenich, Donald Hebb, and Gerald Edelman on brain
dynamics that constitute learning and memory from the mechanisms of homeostasis and
neuroplasticity, we present a maximum entropy principle for the brain:
From the set of all possible joint distributions p(s, ℓ) of a neuron’s axonal length ℓand
diameter s, the joint maximum entropy distribution p∗(s, ℓ) of the joint entropy H(s, ℓ)
subject to action potential power π(s), Oka-Ikeda’s g-ratio g(s), distance ℓand timescale
w(ℓ) dependent synaptic connectivity constraints statistically and sufficiently models the
neuroanatomical organization of neuronal structure and network topology in the brain.
Before we present the set of theoretical results, let us briefly discuss what the joint max-
imum entropy distribution p∗(s, ℓ) physically entails in a sensory-input to action-output con-
text. If we observe Figure 7.1, beginning from (a), we see that the brain receives information
about its external and internal milieu from sensory-inputs mapped into forms of action-output.
For example, the brain receives information about its visual scenery from the activity of pho-
toreceptors, wherein this information is processed and mapped into actions that are meaningful
to the individual, thus allowing one to act accordingly to maximize survival. For instance, this
can result in active eye movement. When repeatedly executed, any action, whether mental or
physical, is learned and formed as memory, as indicated by (b). The arrows that perpetually
flow between (a) and (b) naturally enforces the endless cycle of learning and memory forma-
tion. This universal aspect of learning and memory across many, if not all species, is possible
because the structural self-organization of neurons, and the topological self-organization of
neuronal networks, are designed to maximize entropy shaped through homeostasis and neu-
65

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
66
roplasticity.1 In other words, learning is biologically possible because neurons communicate
using action potentials that are functionally dependent on s; memory is biologically possible
because neuronal connections are functionally dependent on ℓ, which leads to the highly self-
organized shaping of network topology. Thus, the joint maximum entropy distribution p∗(s, ℓ)
inherently allows the brain to structurally and topologically unfold as an information-theoretic
organ in a lawful manner.
7.1
Set of theoretical results
The maximum entropy principle for the brain presents us with a problem in constrained
optimization: Solve for the joint maximum entropy distribution p∗(s, ℓ) of H(s, ℓ). That is,
p∗(s, ℓ) = argmax
p(s,ℓ)∈Λ
h
−
Z
s,ℓ
p(s, ℓ) ln p(s, ℓ)dsdℓ
i
,
(7.1)
where s ∈[0, ∞) and ℓ∈[0, ∞), and Λ is the set containing all possible unique joint distri-
butions p(s, ℓ) with its constraints, defined as
Λ = {p(s, ℓ) | fi(s, ℓ) = ci for i = 1, .., n},
(7.2)
where fi(s, ℓ) is the ith constraint as a function of neuronal diameter s and length ℓ, and n is the
total number of constraints. From Chapter 6, we obtain a total of four biological constraints,
and with the normalization constraint, we obtain the full set of constraint equations given by:
C1 =
Z
s,ℓ
p(s, ℓ)dsdℓ= 1,
C2 =
Z
s,ℓ
π(s)p(s, ℓ)dsdℓ= Π,
C3 =
Z
s,ℓ
g(s)p(s, ℓ)dsdℓ= G,
C4 =
Z
s,ℓ
ℓp(s, ℓ)dsdℓ= L,
C5 =
Z
s,ℓ
w(ℓ)p(s, ℓ)dsdℓ= W,
(7.3)
where n = 5. Let us now explain the intuition behind equations (7.3):
• First, the constraint C1 ensures the unity axiom of probability distributions are satisfied.
1It is worth mentioning that the development of neurons and neuronal networks is governed by genetic
processes. For example, from Kandel’s [1] experiment with the sea slug, it was shown that synaptic connections
from learning and memory consolidation are governed, at a molecular level, by messenger molecules, such as
Cyclic-AMP. Cyclic-AMP is specifically activated when short-term memory transitions to long-term memory,
where it activates a protein kinase molecule that activates transcription factors that bind to specific DNA
sequences. This binding activates the neuron’s gene, which triggers the growth of new synaptic connections.
Therefore, such systematic genetic processes may be “designed” to maximize entropy; however, to the best of
our knowledge, literature to support this empirically is scarce.

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
67
Figure 7.1: An illustration of the maximum entropy principle for the brain in a sensory-input
to action-output context. (a) and (b): The perpetual cycle of executing actions, whether
mental or physical, from sensory inputs creates a natural process for learning and memory
formation in the brain; (c) The perpetual cycle is what constitutes the maximum entropy
principle for the brain; (d): Neurons structurally evolve to biologically support learning and
memory. Distance-dependent and timescale-dependent synaptic connectivity constraints gov-
ern the topological self-organization of neuronal networks. Action potential power and Oda-
Ikeda’s g-ratio constraints govern the speed of information flow in the neuronal network. These
are governed by p∗(s, ℓ), the joint maximum entropy distribution of neuronal diameter s and
length ℓ, which maximizes the brain’s entropy for biological functioning. Image modified and
adapted from Karl Friston [119].
• Second, the constraint C2 constrains, on average, the amount of power neurons can
consume, given by Π, due to the limited number of action potentials a neuron can
generate.
• Third, the constraint C3 constrains, on average, the amount of resources and material to
myelinate neurons, measured with the Oda-Ikeda g-ratio, given by G, due to the limited
amount of resources for myelination.
• Fourth, the constraint C4 constrains, on average, the Euclidean intersomatic distance
between neurons, given by L, due to limited space and resources.
• Lastly, the constraint C5 constrains, on average, the timescale of action potentials be-

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
68
tween neurons, given by W, due to the limited amount of time an action potential can
travel between connected pairs of neurons.
Now, casting the five constraint equations from equation (7.3) into a Lagrangian L with a
total of 5 Lagrange multipliers, its first variation with respect to p(s, ℓ) yields
δL =
Z
s,ℓ
"
(−ln p(s, ℓ) −1) + λN + λππ(s) + λww(ℓ) + λgg(s) + λcc(ℓ)
#
δpdsdℓ.
(7.4)
The joint maximum entropy distribution p∗(s, ℓ) of equation (7.4) must be a stationary and
nontrivial solution to equation (7.4), i.e., δL = 0. Thus, the terms inside the brackets of
equation (7.4) must render to null, thus yielding
p∗(ℓ, s) = eξ+λππ(s)+λwc3 ln(ℓ)+λgc1 ln(s)+λcκℓ
= ηeλππ(s)+¯λw ln(ℓ)+¯λg ln(s)+¯λcℓ
= ηs
¯λgeλππ(s)ℓ
¯λwe
¯λcℓ,
(7.5)
where η is the normalization constant, ¯λw = c3λw, ¯λg = c1λg, and ¯λc = κλc.
From inspecting equation (7.5), it is readily apparent we can separate out terms that are
dependent on the random variables s and ℓ, and factor the normalization constant η = η1η2
such that we can obtain the marginalized maximum entropy distributions of p∗(s) and p∗(ℓ).
Hence,
p∗(s, ℓ) = ηs
¯λgeλππ(s)ℓ
¯λwe
¯λcℓ
= η1η2s
¯λgeλππ(s)ℓ
¯λwe
¯λcℓ
=
h
η1s
¯λgeλππ(s)i
·
h
η2ℓ
¯λwe
¯λcℓi
= p∗(s) · p∗(ℓ),
(7.6)
where the last line of equation (7.6) reveals that p∗(s) and p∗(ℓ) are statistically independent.
Let us now take a brief moment to discuss the physical intuition behind H(s, ℓ) – the
neuronal joint entropy of diameter s and length ℓ– from an analytical perspective using
equation (7.6). Since the random variables s and ℓare statistically independent, H(s, ℓ) can
be decomposed into two terms, such that
H(s, ℓ)
| {z }
Maximum entropy neuronal joint entropy of diameter and length
=
H(s)
| {z }
Entropy of conduction velocity
+
H(ℓ).
| {z }
Entropy of network topology
(7.7)

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
69
From a biological standpoint, equation (7.7) reveals that the brain inherently operates by
summing the amount of entropy independently from H(s) and H(ℓ). Since the conduction
velocity v of action potentials grows linearly with neuronal diameter s, H(s) quantifies the
amount of entropy that is conveyed by an action potential with speed v and diameter s.
In other words, thicker axons transmit action potentials at higher rates and thus contribute
to more information or entropy. Physiologically, this can be associated with one’s speed of
thought. In contrast, since synaptic connectivity is distance-dependent and has a functional
dependence on ℓ, H(ℓ) quantifies the amount of entropy that a neuron learns from physical
or mental tasks, which is stored in the network’s topology as memory. For example, neurons
involved in playing games of chess become more “efficient” by communicating much faster
to internally calculate the next set of moves to beat the opponent, governed by H(s). From
multiple training sessions, neurons have learned and stored chess openings and endgames as
memory reflected in the topology of the neuronal network, governed by H(ℓ). Thus, when
these two independent terms are added together, they constitute mechanisms that govern
learning which then organizes the network’s topology stored as memory. At a macroscopic
level, these result in functional brain maps and neuronal groups.
Now, to complete our analysis further, let us marginalize equation (7.6) such that
Z
ℓ
p∗(s, ℓ)dℓ=
Z
ℓ
p∗(ℓ)p∗(s)dℓ⇒p∗(s) = η1s
¯λgeλππ(s),
(7.8)
Z
s
p∗(s, ℓ)ds =
Z
s
p∗(ℓ)p∗(s)dℓ= p∗(ℓ) ⇒p∗(ℓ) = η2ℓ
¯λwe
¯λcℓ.
(7.9)
By substituting πm(s) for myelinated neurons in equation (7.8), we obtain independent dis-
tributions of p∗
m(s) and p∗(ℓ) each conforming to the gamma distribution, given by
p∗
m(s) = η1s
¯λge−¯λπs , s ≥0 for ¯λg > −1, λπ > 0,
(7.10)
and
p∗(ℓ) = η2ℓ
¯λwe−¯λcℓ, ℓ≥0 for ¯λw > −1, ¯λc > 0.
(7.11)
Equations (7.10) and (7.11) are consistent with empirical observations reported in the
literature [22,94,95]. Details on gamma distributions can be found in Appendix A.1. Let us
now test equations (7.10) and (7.11) against empirical data.

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
70
7.2
Testing theory against in vivo and in vitro empiri-
cal data
To test the maximum entropy distributions conforming to equations (7.10) and (7.11) against
empirical data, the axonal diameter distribution datasets were acquired from the UCL Camino
Diffusion MRI Toolkit available online using the ActiveAx technique – a computer vision appli-
cation – to measure MRI data [100–102]. The axonal length (Euclidean intersomatic distance)
distribution datasets were acquired from the Dynamics Connectome Lab available online. For
axonal diameter, we use myelinated diameter measurements of four different regions found in
the H. sapien’s corpus callosum [103], and the myelinated diameter measurements of three
different regions in the rhesus macaque M. mulatta’s corpus callosum [104]. For axonal length
datasets, we use empirical data of the C. elegan’s neuronal network of the nervous system [61],
the M. mulatta’s regional brain network for one hemisphere of the brain [64], the mushroom
body neuronal network of the Drosophila [23], and the entire regional brain network of the H.
sapien’s brain [64].
The testing is carried out in two stages. The first stage involves fitting Lagrange mul-
tipliers to empirical data, wherein for each dataset, histogram equalization was performed
to estimate the underlying PDF. Histogram equalization approximates the underlying PDF
by partitioning the dataset into bins of equal width. To calculate the optimal bin size, we
employed the Freedman-Diaconis rule [105] as it minimizes the mean squared integral error
of the true PDF and estimated PDF. Then, the method of maximum likelihood estimates
was employed to fit the Lagrange multiplier terms in equations (7.10) and (7.11) done with
Matlab’s distribution fitter toolkit. The second stage involves validating whether or not the
fitted Lagrange multiplier terms are biologically plausible by approximating each biological
constraint terms in equation (7.3) and testing it against available biophysical measurements.

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
71
7.2.1
Maximum entropy axonal diameter distribution of myelinated
neurons
The maximum entropy axonal diameter distribution of myelinated neurons p∗
m(s) is obtained
by using the linear relationship of action potential power to axonal diameter πm(s) given by
p∗
m(s) =
¯λ
¯λg+1
π
Γ(¯λg + 1)s
¯λge−¯λπs, s ≥0,
(7.12)
for ¯λg > −1 and ¯λπ > 0. The derivation is contained in Appendix A.2. To test equation
(7.12) against empirical data, we use Abbott et al.’s [103] dataset of 4 different regions, each
consisting of 100 nerves, found in the H. sapien’s corpus callosum in the brain – the splenium,
the posterior, anterior body, and midbody regions. See Figure 7.2 for an illustration of the
splenium found in the H. sapien’s corpus callosum.
Figure 7.2: An illustration of the H. sapien’s corpus callosum indicated in blue. Image from
Andrew Tran at the FlintRehab institution.
The results can be found in Figures 7.3 and 7.4, where the purple bars in each figure result
from histogram equalization using empirical data, and the red curves are obtained using
equation (7.12) with fitted Lagrange multipliers from the method of maximum likelihood.
The values are found in Table 7.1.
Similarly, using LaMantia et al.’s [104] dataset of 3
different regions, each consisting of 100 nerves, found in the M. mulatta’s corpus callosum
– the entire anterior (AC), the hippocampal (HC), and the basal telenchephalic commisures
(BTC). The results can be found in Figures 7.5 and 7.6, with fitted parameters found in Table
7.1. By comparing the empirical histogram distribution to the theoretical curves obtained
from equation (7.12), we find that, indeed, the theory is able to sufficiently model a wide
range of the emerging skewness property of myelinated axonal diameter distributions in the
brain across different species. The skewness ultimately reflects the dynamics governed by the
constraints of action potential power and the Oka-Ikeda g-ratio.

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
72
(a)
(b)
Figure 7.3: (a) Empirical vs. theoretical maximum entropy axonal diameter distribution of
the splenium brain map found in the H. sapien’s corpus callosum consisting of 100 nerves.
Data obtained from UCL Camino lab [100, 103]. (b): Empirical vs. theoretical maximum
entropy axonal diameter distribution of the posterior brain map found in the H. sapien’s
corpus callosum consisting of 100 nerves. Data obtained from UCL Camino lab [100,103].
Table 7.1: Fitted parameters using the method of maximum likelihood for fitting ¯λπ and ¯λg
using equation (7.12).
Species
Brain map area in corpus callosum
¯λπ [1/µm]
¯λg
H. sapien
splenium
4.30
4.58
H. sapien
posterior
2.36
3.47
H. sapien
anterior body
3.19
3.08
H. sapien
midbody
1.68
1.60
M. mulatta
AC
12.40
7.50
M. mulatta
HC
14.90
11.10
M. mulatta
BTC
41.08
19.12

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
73
(a)
(b)
Figure 7.4: (a) Empirical vs. theoretical maximum entropy axonal diameter distribution of the
anterior body brain map found in the H. sapien’s corpus callosum consisting of 100 nerves.
Data obtained from UCL Camino lab [100, 103]. (b): Empirical vs. theoretical maximum
entropy axonal diameter distribution of the midbody brain map found in the H. sapien’s
corpus callosum consisting of 100 nerves. Data obtained from UCL Camino lab [100,103]
(a)
(b)
Figure 7.5: (a) Empirical vs. theoretical maximum entropy axonal diameter distribution of
the anterior brain map found in the M. mulatta’s corpus callosum consisting of 100 nerves.
Data obtained from UCL Camino lab [100, 104]. (b): Empirical vs. theoretical maximum
entropy axonal diameter distribution of the posterior brain map found in the M. mulatta’s
corpus callosum consisting of 100 nerves. Data obtained from UCL Camino lab [100,104]

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
74
Figure 7.6: Empirical vs. theoretical maximum entropy axonal diameter distribution of the
BTC map found in the M. mulatta’s corpus callosum consisting of 100 nerves. Data obtained
from UCL Camino lab [100,104]

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
75
7.2.2
Maximum entropy axonal length distribution of myelinated
and unmyelinated neurons
Let us first analyze the special case of the maximum entropy axonal length distribution of
myelinated and unmyelinated neurons when the distribution decays in behavior. In this case,
the set of governing equations is given by
p∗(ℓ) =
¯λ
¯λw+1
c
Γ(λw + 1)ℓ
¯λwe−¯λcℓ, ℓ≥0
(7.13)
where ¯λw ∈(−1, 0) and ¯λc > 0. Testing equation (7.13) with the connectome data of the
nervous system of the C. elegans, we see that the theory is able to sufficiently model empirical
data, as seen in Figure 7.7(a). The graph theoretical representation of the neuronal network
can be seen in Figure 7.7(b), and the fitted parameters can be found in Table 7.2.
(a)
(b)
Figure 7.7: (a) Empirical vs. theoretical maximum entropy axonal length distribution of the
nervous of the nematode C. elegan’s consisting of a total of 277 neurons and 2105 synapses.
The blue curve is obtained from histogram equalization, and the red curve is obtained using
equation (7.13); (b): Connectome of (a), with neurons indicated as red nodes, and arrows
indicating unidirectional or bidirectional connections. Data obtained from Dynamics Connec-
tome Lab [61].
Table 7.2: Fitted parameters using the method of maximum likelihood for fitting ¯λw and ¯λc
using equation (7.13).
Species
Area
Network type
¯λc
¯λw
C. elegans
Nervous system
Neuronal network
0.40
-0.48
D. melanogaster
Mushroom body
Neuronal network
3.11
1.58
Ma. mulatta
Hemisphere
Regional network
0.14
1.98
H. sapien
Global brain
Regional network
0.08
4.90

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
76
To test equation (7.13) when distributions are skewed, we necessarily have ¯λw > 0 and
¯λc > 0. Using in vivo data of the neuronal network of the mushroom body in the fruit fly
D. melanogaster with a total of 21142 synapses, the cortical network in the rhesus macaque
M. mulatta consisting of a total of 94 different brain maps and the interregional connectivity
network of the human brain with a total of 68 different brain regions. Comparisons of theory
to empirical data can be found in Figures (7.8)-(7.10) below, where we find that the theory can
sufficiently explain a wide range of the emerging skewness property of synaptic connectivity as
a function of axonal and interregional length between neurons and brain maps, respectively,
across different species. Fitted parameters can be found in Table 7.2.
(a)
(b)
Figure 7.8: (a) Empirical vs. theoretical maximum entropy axonal length distribution of the
mushroom body of fruit fly, D. melanogaster. The mushroom body or corpora pedunculata
are a pair of structures in the brain of insects, and other arthropods and some annelids are
known to play a role in olfactory learning and memory. It consists of a total of 1072 neurons
and 21142 synapses; (b): Connectome of (a), with neurons indicated as red nodes and arrows
indicating unidirectional or bidirectional connections. Data obtained from Fruit Fly Brain
Observatory Lab [23].

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
77
(a)
(b)
Figure 7.9: (a) Empirical vs. theoretical maximum entropy interregional length distribution
of the cortical network of the rhesus monkey, M. mulatta. It consists of a total of 94 different
brain maps or regions and 2390 regional synapses; (b): Connectome of (a), with brain maps
indicated as red nodes and arrows indicating unidirectional or bidirectional connections. Data
obtained from the Dynamics Connectome Lab [64].
(a)
(b)
Figure 7.10: (a) Empirical vs. theoretical maximum entropy interregional length distribution
of the entire human brain. It consists of a total of 68 different brain maps or regions and
2278 regional synapses; (b): Connectome of (a), with brain maps indicated as red nodes
and arrows indicating unidirectional or bidirectional connections. Data obtained from the
Dynamics Connectome Lab [64].

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
78
7.2.3
Mapping Lagrange multipliers to biological constraints
In practical applications, Lagrange multipliers are used to “fit” parameters such that proba-
bility distributions or optimal functions derived for other applications, such as control theory,
can fit most closely to the empirical data at hand. However, this leads to a conundrum: Such
constants are without physical biological meaning. For example, Sinisa et al.’s [106] theo-
retical approach to deriving optimal axonal diameter distributions (p∗(s)) is based on coding
capacity, and Song et al.’s [107] theoretical approach to derive optimal wiring distributions
(p∗(ℓ)) infers the Lagrange multipliers using convex optimization theory. Such approaches are
incapable of reflecting the physical and intuitive meaning behind what these constants entail.
The maximum entropy distributions conforming to equations (7.10) and (7.11) are funda-
mentally rooted on biological grounds which allow us to map each of the Lagrange multipliers
to each of the biological constraints found in equation (7.3). In other words, to test if such
Lagrange multipliers are, indeed, biologically plausible, we use the fitted Lagrange multipliers
found in Tables 7.1 and 7.2 to approximate Π, G, L, and W. To measure Π and G, we simply
substitute the maximum entropy distribution of axonal diameter p∗
m(s) of myelinated neurons
into Shannon’s definition of entropy, thus yielding
Π = 6nπA,m
 ¯λg + 1
¯λπ
!
× 106,
G = c1[ψ(¯λg + 1) −ln(¯λπ)] + c2,
(7.14)
where the full derivation can be found in Appendix A.2. To estimate the average power Π, we
use in vitro measurements from Perge et al.’s [21] work with myelinated ganglion neurons of
the optic nerve in the guinea pig C. porcellus, where each action potential travels, on average,
at a speed of 6 m/s requires, which requires roughly 400 ATP molecules for each micrometer
of a myelinated neuron, and each molecule of ATP provides roughly 10−19 joules of energy.
We emphasize that using this as part of the calculation primarily serves as an approximation
to illustrate the utility of the maximum entropy principle for the brain. Now, the amount of
action potential power required for each micrometer of the myelinated axon is given by
πA,m = 400 · 10−19 [J/µm].
(7.15)
To simplify the analysis further, we assume that n = 1. This assumption is valid as the mean
firing rates of neurons typically fall within the range of one to two orders of magnitude [108].
To estimate the average Oda-Ikeda’s g-ratio G, we use the parameter values c1 and c2 from
Table 6.1 in §6.2.2. Thus, using the fitted Lagrange multipliers contained in Table 7.1 from
§7.2.1, we can approximate the biological constraints Π and G across different species. The
results are contained in Table 7.3 below

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
79
Table 7.3: Estimating biological parameters of average action potential power Π and average
Oda-Ikeda g-ratio G by substituting the fitted Lagrange multipliers ¯λπ and ¯λg values into
equation (7.14). Parameter values for the corpus callosum of the H. sapien are c1 = 0.393,
c2 = 0.555, and n=1. Parameter values for the corpus callosum of the M. mulatta are c1 =
0.402, c2 = 0.839, and n=1.
Species
Area in corpus callosum
¯λπ [1/µm]
¯λg
Π [J/s]
G
H. sapien
splenium
4.30
4.58
3.11 × 10−10
0.62
H. sapien
posterior
2.36
3.47
4.53 × 10−10
0.76
H. sapien
anterior body
3.19
3.08
3.07 × 10−10
0.60
H. sapien
midbody
1.68
1.60
3.70 × 10−10
0.65
M. mulatta
AC
12.40
7.50
1.65 × 10−10
0.66
M. mulatta
HC
14.90
11.07
1.94 × 10−10
0.74
M. mulatta
BTC
41.08
19.12
1.18 × 10−10
0.54
Testing the approximated Π values found in Table 7.3 against empirical data found in Table
7.4, we find the approximated values are consistent on the order of magnitude with biophysical
measurements from other species. For example, Attwell et al.’s [109] estimate using anatomic
and physiological data to analyze the energy expenditure on different components of excitatory
signaling in the CNS white matter of the rodent’s brain where neurons fire an action potential
with a mean firing rate of 4Hz converts to roughly 1.38 × 10−10 J/s. Although it is apparent
that such comparisons are made with species other than the H. sapien and M. mulatta, it is
noteworthy that there is a high possibility that comparing Π values in this manner is valid for
two reasons. One, neurons across different species function and develop in a similar manner
biochemically. That is, action potentials require the consumption of ATP molecules that are
driven by the same chemical processes which govern the activation of ion channels, such as
calcium or potassium ion channels (recall Part 2). And two, as a species, we share, to some
degree, the same ancestral genetics as rodents and flies, which highly suggests that biological
functions of the brain develop in a similar manner and thus may consume the same amount
of power to the same or similar orders of magnitude. For example, the genetic similarity
between rodents and humans is about 85%, and Tables 7.3 and 7.4 show that the H. sapien
and Rodentia’s power consumption is of the same order of magnitude; similarly, the genetic
similarity between flies and humans is roughly 61%, and once again, the tables show that
these species consume power to the same order of magnitude [110]. However, it should be
emphasized that further validation is required in the future when more empirical data is
available to directly compare the power terms to the same species.
Now, to test G against empirical data, let us observe Table 7.5. We find that Stikov et
al.’s [113] in vivo work on the histology of the myelin g-ratio from the crab-eating macaque
monkey M. fascicularis in eight different regions of the corpus callosum ranged from 0.60-0.74,

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
80
Table 7.4: Estimated Π values from in vitro and in vivo biophysical measurements of different
species.
Species
Area
Π [J/s]
Ref
Calliphoridae
Retina
7.50 × 10−10
[112]
C. porcellus
Optic nerve
2.40 × 10−10
[14]
Rodentia
CNS White Matter
1.38 × 10−10
[109]
R. norvegicus
Neocortex
8.00 × 10−11
[111]
which compares favorably to the estimated theoretical G values in Table 7.3 for the macaque
monkey M. mulatta. Similarly, in vivo measurements from Mohammadi et al.’s [115] study of
healthy adult patients is roughly 0.70, which compares favorably well to the g-ratio values of
the H. sapien in Table 7.3. Furthermore, these values are also consistent with Rushton’s [117]
and Chomiak et al.’s [116] work based on theoretical analysis, which estimates an optimal
g-ratio of 0.60-0.70. Other reported g-ratio values reported are around 0.81 for guinea pigs
[114]. Thus, the maximum entropy axonal diameter distribution is sufficiently, with available
data, able to infer biologically plausible Π and G values.
Table 7.5: Estimated g-ratio values of different species from electron microscopy recordings,
MRI records, and theoretical analysis.
Species
Region
Area
G
Ref
M. fascicularis
corpus callosum
Inferior genu
0.69
[113]
M. fascicularis
corpus callosum
Superior genu
0.68
[113]
M. fascicularis
corpus callosum
Posterior genu
0.64
[113]
M. fascicularis
corpus callosum
Anterior midbody
0.69
[113]
M. fascicularis
corpus callosum
Middle midbody
0.72
[113]
M. fascicularis
corpus callosum
Posterior midbody
0.64
[113]
M. fascicularis
corpus callosum
Isthmus
0.60
[113]
M. fascicularis
corpus callosum
Splenium
0.74
[113]
C. porcellus
Optic nerve
N/A
0.81
[114]
H. Sapien
Whole brain
N/A
0.70
[115]
N/A
N/A
N/A
0.60-0.70
[116,117]
Carrying out similar procedures to estimate biological constraints of L and W using the
fitted Lagrange multipliers associated with p∗(ℓ), we obtain the equations
¯λw + 1
¯λc
= L,
W = c3[ψ(¯λw + 1) −ln(¯λc)] + c4,
(7.16)
with the derivation found in Appendix A.3, and the results found in Table 7.6. As L
models the average Euclidean distance between neurons or brain regions, we find that the
inferred values conform to intuition. For instance, the C. elgans is roughly 1mm in length,

CHAPTER 7. A MAXIMUM ENTROPY PRINCIPLE FOR THE BRAIN
81
the D. melanogaster’s brain is roughly the size of a poppy seed which is roughly 1 mm
thick. Furthermore, The width of the macaque monkey’s brain is roughly 50mm, and lastly,
the average brain width of a human is roughly 140mm. Thus, the inferred values of L are
biologically plausible as they are consistent with physical measurements. Unlike Π, G, and L,
however, since the concept of the average timescale of observability W has been introduced
in recent years, data to test the theoretically estimated values of W is scarce. However, it
is noteworthy that Castelluzo et al. [19] has reported the maximum average timescale to
be roughly 30s for human brain networks, which is consistent with the order of magnitude
found in Table 7.6. Thus, these results suggest that the Lagrange multipliers of the maximum
entropy axonal and interregional distribution from theory are biologically plausible, but further
validation will be required in the future to ascertain the biological plausibility of the estimated
values of W.
Table 7.6: Estimated biological parameters of average Euclidean distance L and timescale
W of neuronal or regional networks across different species by substituting ¯λc and ¯λw into
equation (7.16). The parameter values are c3 = 8.8 and c4 = 67 for neuronal networks, and
c3 = 6.7 and c4 = 68.3 for regional networks obtained from [19].
Species
Area
Network type
¯λc
¯λw
L [mm]
W [s]
C. elegans
Nervous system
Neuronal network
0.40
-0.48
0.25
44.30
D. melanogaster
Mushroom body
Neuronal network
3.11
1.58
0.83
36.50
M. mulatta
Hemisphere
Regional network
0.14
1.98
21.00
87.51
H. sapien
Global brain
Regional network
0.08
4.90
76.21
96.75

Chapter 8
Designing biologically plausible neural
networks
The central premise behind designing a biologically plausible neural network based on the
maximum entropy principle of the brain is to provide one basis, out of the many, to explain how
the brain and its functional brain maps might develop. In a simplified model, this development
involves the growth of synapses, axons, and synaptic connections between neurons, which
shapes network topology. This idea is explored by fully utilizing the maximum entropy axonal
length distribution p∗(ℓ) to generate, in a simulation experiment, biologically plausible Rentian
scaled small-world architecture that maximizes entropy just from p∗(ℓ) alone.
This method of exploring how neuronal network topology is shaped from the principles
of constrained entropy leads to an interesting view. If we were to take an algorithmic ap-
proach to analyze how neuronal connections are formed in artificial neural networks, such as
backpropagation, or using biologically inspired neural networks, such as the implementation
of a 12-million Hodgkin-Huxley neuron network on a single chip, these approaches are unable
to sufficiently explain the existence of the complex neuronal network topology in the brain.
However, if we adopt an information-theoretic treatise to brain dynamics, connections between
neurons are shaped to maximize the entropy of network topology to perhaps support learning
and memory formation.
The simulation experiment is carried out with the following two steps:
I. Generation of a primary neuronal repertoire: A network with a total of n nodes, or
neurons, are randomly placed in a 3D cube.
II. A synaptic connection is formed between neurons i and j for i ̸= j if the p∗(ℓ) overcomes
a threshold, ˜p. In all simulations, we have used a default of ˜p = 0.5.
82

CHAPTER 8. DESIGNING BIOLOGICALLY PLAUSIBLE NEURAL NETWORKS
83
The first step (I) simulates a primary neuronal repertoire in Edelman’s sense. The primary
neuronal repertoire models a nascent brain map, with neurons potentially able to form synap-
tic connections with any other neuron in the network. Step (II) utilizes p∗(ℓ) to model how the
brain strategically self-organizes in a structurally lawful way to maximize entropy to support
learning and memory formation in a biologically plausible fashion. That is, connections are
not formed randomly but are self-organized to satisfy the maximum entropy principle for the
brain. At the heart of this chapter, we provide one basis to show, not from a computational
perspective that involves artificial neural networks, but from an information-theoretical per-
spective to show how neuronal connections may be self-organized in the brain that is reflected
in the network’s topology.
Using the simulated network, its adjacency matrix is determined to measure the average
clustering and path-length coefficients to determine if the simulated network exhibits a small-
world architecture by assessing the small-world index, and lastly, we analyze if the network is
indeed Rentian scaled. The network’s biological plausibility is then assessed by comparing the
small-world index and the inferred Rent’s exponent to biophysical measurements of different
species previously discussed in Chapter 4.
8.1
Simulation of a Rentian scaled small-world network
The simulation experiment consists of a total of 300 nodes placed inside a 1000µm3 cube,
where connections are inferred using p∗(ℓ) which follows a skewed gamma distribution, as
seen in Figures 8.1(a) and 8.1(b), respectively, with gamma parameters found in Table 8.1.
The skewness, for example, is present in biological neuronal networks such as the mushroom
body of the D. melanogaster, as we have seen in §7.2.2.
Table 8.1: Free variables of the Type I network.
The free variables are parameters that
control the total number of neurons in the network, the volume size housing nodes, the gamma
parameters that shape p∗(ℓ), and the bin size of p∗(ℓ).
Total number of neurons
Volume size [µm3]
Gamma parameter, {¯λw, ¯λc}
Bin size [µm]
300
1000
{2,1}
0.95
The resulting primary neuronal repertoire exhibits a high average clustering coefficient of
0.43 and a low average path-length of 5.22 neurons, as seen in Figure 8.2(a). To test if the
generated network indeed exhibits small-world topology, we evaluate the small-world index
S∆
WI by also generating the equivalent random network with the same number of nodes and
the average number of connections, as seen in Figure 8.2(b). The equations associated with
the small-world index is given by

CHAPTER 8. DESIGNING BIOLOGICALLY PLAUSIBLE NEURAL NETWORKS
84
S∆
WI = γ∆
g
ω∆
g
; γ∆
g =
¯Cg
¯Crand
;
ω∆
g =
¯ψg
¯ψrand
.
(8.1)
Thus, using the average clustering and path-length coefficients found in Table 8.2, we obtain
the small-world index value of
S∆
WI = 10.15.
(8.2)
As S∆
WI > 1, the resulting primary neuronal repertoire exhibits the small-world topology falling
within similar orders of magnitude of various species found in Table 4.2.
Table 8.2: Average clustering and path-length coefficients of the simulated network and its
equivalent simulated random network.
Network
Average clustering coefficient,
¯C
Average path-length coefficient,
¯ψ
Simulated network
0.43
5.22
Simulated random network
0.02
2.95
Lastly, to check if the network is Rentian scaled, we calculate Rent’s exponent, using
Bassett et al.’s [27] approach using the Brain Connectivity Toolbox kit implemented in Matlab.
By testing the minimum possible physical Rent exponent rmin using equation (4.9) to the
inferred Rent’s exponent value of r = 0.8, as seen in Figure 8.3, we have
rmin = max

1 −1
De
, r

= max

1 −1
3, r

= max

0.67, 0.8

,
(8.3)
where we find that r = rmin, indicating that the simulated primary neuronal repertoire is
cost-efficiently embedded in space and consistent with values reported for biological neuronal
networks found in Table 4.1. Thus, the simulated network results in a biologically plausible
Rentian-scaled small-world network which maximizes network entropy.

(a)
(b)
Figure 8.1: (a) The Initial state of the network with a total of 300 neurons, or nodes, randomly
placed in a cube of size 1000 µm3. (b): Connections are formed using p∗(ℓ) following a gamma
distribution.
(a)
(b)
Figure 8.2: (a) The primary neuronal repertoire with connections formed between neurons.
(b): The equivalent random network with the same number of nodes and the average number
of connections.
85

Figure 8.3: A plot of Rent’s exponent on a loglog scale of the number of partitions versus the
number of edges crossing the boundary of partitions. Here, Rent’s exponent amounts to the
slope of the red line crossing the data points represented as blue asterisks, with r ≈0.8.
86

Chapter 9
Conclusion
In this thesis, we have considered the characteristics of biological systems in relation to adap-
tive self-organizing systems. The brain, in particular, is a unique information-theoretic organ
that is influenced in response to interactions with its external and internal milieu to maintain
structural and topological order. This self-organizational property of brain dynamics can be
formalized in terms of an optimization problem of Shannon’s entropy subject to 4 biological
constraints embedded with physical meaning correlated to the communication and connec-
tivity of neurons. As a consequence of constrained entropy maximization, it is revealed that
the brain may selectively choose to self-organize, based on an inference model adequately ex-
plained by the maximum entropy joint distribution of neuronal diameter and length, to shape
its structure and topology. Thus, maximizing the brain’s entropy may be a necessary, if not
sufficient, condition for the brain to learn and form memory biologically.
This thesis attempts to replace difficult questions on how the organization, reflected in
neuronal structure and the topology of network networks, emerges with what organizational
principle they must exhibit to exist. The maximum entropy principle for the brain is one such
principle that attempts to explain how such biological characteristics must arise in the brain.
By casting these constraints to derive a maximum entropy joint distribution of axonal diameter
and length, we arrived at a joint maximum entropy distribution that can sufficiently model
in vitro and in vivo empirical data of different species, conforming to gamma distributions.
Using the maximum entropy axonal length distribution, the principle is also able to explain,
utilizing graph theory, from simple simulation experiments how the brain might strategically
organize neuronal networks that stabilize to a Rentian scaled small-world architecture.
The ideas presented in this thesis have a long history, dating back to the notions of con-
sciousness from the French philosopher, Ren´e Descartes, and covering the ideas on how the
brain develops using concepts derived from Shannon’s entropy. The scientific contribution of
this thesis is to provide new and fresh insights that we hope can aid the neuroscience and en-
87

CHAPTER 9. CONCLUSION
88
gineering communities to rigorously formalize how the brain dynamically unfolds to learn and
form memories that make everyday life possible. Furthermore, this formulation can be used to
help connect constructs from modern theories of artificial intelligence and statistical physics
with ideas from theories of neuroanatomical evolution, neurobiology, and sensory cybernetics.
9.1
Future direction
An interesting possibility of a future direction is to explore the maximum entropy principle for
the brain with applications such as artificial intelligence or machine learning. For example, we
can extend and modify artificial neural networks based on Hebbian mechanisms where infor-
mation and memory are assumed to be stored in real-valued “weights” associated with each
neuron, such as the Hopfield network [118]. By adopting an information-theoretic framework,
we can replace the artificial weights with H(si, ℓij) to measure how much information, in a bi-
ological sense, is transmitted between a presynaptic neuron i of diameter s to its postsynaptic
neuron j, where each neuron i and neuron j are separated by a distance ℓij. Thus, if neuron
i is artificially activated in a computational sense, it may be possible to train the network
to learn, for example, images such as dogs and cats through an algorithmic process such as
backpropagation or reinforcement learning, which can model artificial memory reflected in the
network’s topology.
Another interesting possibility of a future direction is to explore if the maximum entropy
principle for the brain can be (re)derived using other existing principles for the brain, such
as the free energy principle [119].1 This is analogous to deriving Newton’s law of universal
gravitation with Keplar’s laws of planetary motion – the laws are two sides of the same
coin, just expressed in a different manner [79]. Thus, if the distributions from the maximum
entropy principle can be (re)derived using other principles, it makes a stronger argument for
arguing its biological plausibility and, furthermore, allows one to unify mathematical concepts
in neuroscience.
1The “free energy” in this sense is not to be confused with energy in the dynamical sense. That is, it is
not measured in units of joules. The free energy principle essentially analyzes brain dynamics using another
concept of entropy – the Kullback–Leibler divergence – and generates a Lyapunov function for the brain using
what Karl Friston calls a “Markov blanket,” in the Bayesian probabilistic sense. Interested readers can refer
to [119].

Appendix A
A.1
Properties of the gamma distribution
The general form of a gamma distribution of a random variable x is given by
f(x) =
βα
Γ(α)xα−1e−βx, x ∈(0, ∞), {α, β} > 0.
(A.1)
Useful properties of equation (A.1) include:
α
β = µx,
α
β2 = σ2
x,
E[ln(x)] = ψ(α) −ln(β),
(A.2)
where µx and σ2
x is the mean and variance of the gamma distribution, respectively, and E[ln(x)]
is the expectation of the logarithm of the random variable x [74].
The entropy of the gamma distribution is given by
H(x) = α −ln(β) + ln Γ(α) −(α −1)ψ(α),
(A.3)
where
Γ(α) = (α −1)! =
Z ∞
0
xα−1e−xdx
(A.4)
is the gamma function and (·)! is the factorial operator, and
ψ(α) = d ln Γ(α)
dα
= Γ
′(α)
Γ(α)
(A.5)
is the digamma function.
A.2
Relationship between Π, G, ¯λg, and ¯λπ of p∗
m(s)
The maximum entropy axonal diameter distribution of myelinated neurons p∗
m(s) is given by
89

APPENDIX A.
90
p∗
m(s) = η1s
¯λgeλππm(s), s ≥0
= η1s
¯λg exp[λπnπA,mvm(s)]
= η1s
¯λg exp[6λπnπA,ms × 106]
= η1s
¯λge
¯λπs,
(A.6)
where the factor 106 appears due to unit conversion of m/s to µm/s, and η1 is the normalization
constant and ¯λπ = 6λπnπA,m × 106. The normalization constant η1 can be readily inferred as
p∗
m(s) =
¯λ
¯λg+1
π
Γ(¯λg + 1)s
¯λge−¯λπs, s ≥0.
(A.7)
Now, using the power constraint with gamma distribution properties found in equation
(A.2), we obtain
Z
s
πm(s)pm(s)ds = 6nπA,m
 Z
s
spm(s)ds
!
× 106
= Π =⇒6nπA,m
 ¯λg + 1
¯λπ
!
× 106 = Π.
(A.8)
Furthermore, using Oka-Ikeda’s g-ratio constraint, we have
Z
s
g(s)p∗
m(s)ds =
Z
s
[c1 ln(s) + c2]pm(s)ds =⇒c1[ψ(¯λg + 1) −ln(¯λπ] + c2 = G.
(A.9)
A.3
Relationship between L, W, ¯λc, and ¯λw of p∗(ℓ)
To obtain the Lagrange multiplier terms associated with the maximum entropy distribution
of axonal length p∗
ℓ, we follow the same steps as appendix A.2. Thus,
p(ℓ) = η2ℓ
¯λwe
¯λcℓ, ℓ≥0
=
¯λ
¯λw+1
c
Γ(¯λw + 1)ℓ
¯λwe−¯λcℓ,
(A.10)
for ¯λw > −1 and ¯λc > 0. Now, from the distance-dependent synaptic connectivity constraint,
we obtain
Z
ℓ
ℓp(ℓ)dℓ=
Z
ℓ
ℓp(ℓ)dℓ=⇒
¯λw + 1
¯λc
= L
(A.11)
and from the timescale constraint, we obtain

APPENDIX A.
91
Z
ℓ
w(ℓ)p(ℓ)dℓ=
Z
ℓ
[c3 ln(ℓ) + c4]p(ℓ)dℓ=⇒c3[ψ(¯λw + 1) −ln(¯λc)] + c4
= W
(A.12)

Bibliography
[1] Eric R. K., The molecular biology of memory storage: a dialog between genes and synapses, Bioscience
Reports 21 (2001), no. 5, pp.392-412.
[2] Norman D., The brain that changes itself: stories of personal triumph from the frontiers of brain science,
Penguin books Inc (2007), pp.1-92.
[3] M. M. Merzenich, J.H. Kaas , J. Wall, R.J. Nelson, M. Sur, D. Felleman, Topographic reorganization of
somatosensory cortical areas 3b and 1 in adult monkeys following restricted deafferentation, Neuroscience
8 (2009), no. 1, pp.33-55.
[4] Vergara R. C., Jaramillo-Riveri S., Luarte A., Mo¨enne-Loccoz C., Fuentes R., Couve A., & Maldonado
P. E., The Energy Homeostasis Principle: Neuronal Energy Regulation Drives Local Network Dynamics
Generating Behavior. Frontiers in computational neuroscience, Frontiers in computational neuroscience
39 (2019), no. 13, pp.1-18.
[5] Turner J. S., Homeostasis as a fundamental principle for a coherent theory of brains, Philosophical
transactions of the Royal Society of London. Series B, Biological sciences 364 (2019), no. 1774, pp.1-8.
[6] Roh E., Song D. K., & Kim M. S., Emerging role of the brain in the homeostatic regulation of energy
and glucose metabolism, Experimental & molecular medicine 48 (2016), no. 3, pp.1-12.
[7] Donald O. Hebb, The organization of behavior: A neuropsychological postulate, John Wiley and Sons Inc
2 (1942), no. 1, pp.62-74.
[8] Gerald M. Edelman, Neural Darwinism: The Theory of Neuronal Group Selection, New York:Basic Books
(1978).
[9] Gerald M. Edelman, Neural Darwinism Review Selection and Reentrant Signaling in Higher Brain Func-
tion, Cell Press Review 10 (1978), no. 2, pp.115-125.
[10] Stephen W. Smoliar, Review of Neural Darwinism, Book review: Artificial Intelligence 39 (1989), no. 1,
pp.121-136.
[11] Francis C., Neural Endelmanism, Trends in Neuroscience 12 (1989), no. 7, pp.240-248.
[12] Gerald M. Edelman, Giulio Tononi, A Universe of Consciousness: How Matter Becomes Imagination,
Basic Books (2000).
[13] Henry Markram, Rodrigo Perin, Thomas K. Berger, A synaptic organizing principle for cortical neuronal
groups, Proceedings of the National Academy of Sciences of United States of America 108 (2011), no. 13,
pp.5419–5424.
92

BIBLIOGRAPHY
93
[14] James V. Stone, Principles of Neural Information Theory: Computational Neuroscience and Metabolic
Efficiency, Sebtel Press 1 (2018), no. 1, pp.9-62.
[15] Peter Sterling & Simon Laughlin, Principles of Neural Design, Cambridge: The MIT Press (2015).
[16] Christopher W. Lynn & Danielle S. Bassett, The physics of brain network structure, function and control,
Nature Reviews 1 (2019), pp.318-332.
[17] Peter Lennie, The Cost of Cortical Computation, Brief Communication 13 (2003), no. 6, pp.493-497.
[18] Simon B. Laughlin & David Attwell, An Energy Budget for Signaling in the gray Matter of the Brain,
Journal of Cerebral Blood Flow and Metabolism 21 (2001), no. 1, pp.1133–1145.
[19] Castelluzzo M., Perinelli A., Tabarelli D., & Ricci L., Dependence of Connectivity on the Logarithm of
Geometric Distance in Brain Networks, Dependence of Connectivity on the Logarithm of Geometric
Distance in Brain Networks 11 (2021), no. 611125, pp.1-13.
[20] L. Perinelli A., Chiari D. E., & Ricci, Correlation in brain networks at different timescale resolution,
Chaos (Woodbury, N.Y.) 28 (2018), no. 6, pp.1-10.
[21] J´anos A. Perge, Kristin Koch, Robert Miller, Peter Sterling, & Vijay Balasubramanian, How the Optic
Nerve Allocates Space, Energy Capacity, and Information, The Journal of Neuroscience 29 (2009), no. 24,
pp.7917-7928.
[22] J´anos A. Perge, Jeremy E. Niven, Enrico Mugnaini, Vijay Balasubramanian, & Peter Sterling, Why Do
Axons Differ in Caliber?, The Journal of Neuroscience 32 (2012), no. 2, pp.626-638.
[23] D., Ortiz C.L., Huang Y., Wang C., Richmond P., Lo C., Coca D., Chiang A., & Lazar A.A. Ukani
N. H., Yeh C., Tomkins A. R., Zhou Y., Florescu, The Fruit Fly Brain Observatory: From Structure to
Function, bioRxiv.
[24] Watts D., Strogatz S., Collective dynamics of “small-world” networks, Nature
393 (2010), no. 6684,
pp.440–442.
[25] M. E. J. Newman, The Structure and Function of Complex Networks, SIAM review 45 (2003), no. 2,
pp.167-256.
[26] Gurney K. Humphries MD., Network “Small-World-Ness”: A Quantitative Method for Determining
Canonical Network Equivalence, Nature 3 (2008), no. 4, pp.1-10.
[27] Bassett D. S., Greenfield D. L., Meyer-Lindenberg A., Weinberger, D. R., Moore S. W., & Bullmore E.
T., Efficient physical embedding of topologically complex information processing networks in brains and
computer circuits, PLoS computational biology 6 (2010), no. 4, pp.1-14.
[28] How J. J., & Navlakha S., Evidence of Rentian Scaling of Functional Modules in Diverse Biological
Networks, Neural computation 30 (2018), no. 8, pp.2210-2244.
[29] Tero A., Takagi S., Saigusa T., Ito K., Bebber D. P., Fricker M. D., Yumiki K., Kobayashi R., & Nakagaki
T, Rules for biologically inspired adaptive network design, Science (New York, N.Y.) 327 (2010), no. 5964,
pp.439-442.
[30] Cannon W. B., Physiological regulation of normal states: some tentative postulates concerning biological
homeostatics, In A. Pettit (ed.). A Charles Riches amis, ses coll`egues, ses ´el`eves (in French). Paris: Les
´Editions M´edicales. (1926), pp.91.

BIBLIOGRAPHY
94
[31] Billman G. E., Homeostasis: The Underappreciated and Far Too Often Ignored Central Organizing Prin-
ciple of Physiology, Frontiers in physiology 11 (2020), no. 200, pp.1-12.
[32] Broskey N. T., Johannsen D., Redman L., Regulation of Body Weight in Humans, Endotext, edited by
Kenneth R Feingold et. al., MDText.com (2016), pp.1-17.
[33] Smith G. P., Unacknowledged contributions of Pavlov and Barcroft to Cannon’s theory of homeostasis,
Appetite 51 (2008), no. 3, pp.428-432.
[34] J. Gordon Betts, Kelly A. Young, James A. Wise, Eddie Johnson, Brandon Poe, Dean H. Kruse, Oksana
Korol, Jody E. Johnson, Mark Womble, Peter DeSaix, Anatomy
Physiology, Communication between
neurons: Figure 2, OpenStax College (2013).
[35] Anderberg L., Aldskogius H., & Holtz A., Spinal cord injury–scientific challenges for the unknown future,
Upsala journal of medical sciences 112 (2007), no. 3, pp.259–288.
[36] Hodgkin A.L, Huxley A.F, A quantitative description of membrane current and its application to con-
duction and excitation in nerve, Journal of Physiology 4 (1952), no. 117, pp.500-544.
[37] Fitzhugh R., Impulses and Physiological States in Theoretical Models of Nerve Membrane, Biophysical
journal 1 (1961), no. 6, pp.445-466.
[38] Corina D., Corrigendum: An electromechanical model of neuronal dynamics using Hamilton’s principle,
Frontiers in Cellular Neuroscience 9 (2015), no. 271, pp.1-8.
[39] Edgar A., The activity of nerve fibres, A Nobel Prize Lecture (1932).
[40] Heath C. A., & Rutkowski G. E., The development of bioartificial nerve grafts for peripheral-nerve
regeneration, Trends in biotechnology 16 (1998), no. 4, pp.163-168.
[41] Papu´c E., & Rejdak K., The role of myelin damage in Alzheimer’s disease pathology, Archives of medical
science:AMS 16 (2018), no. 2, pp.345–351.
[42] Wilder P., Edwin B., Somatic motor and sensory representation in the cerebral cortex of man as studied
by electrical stimulation, Journal of Brain 60 (1937), no. 4, pp.389–443.
[43] Allen B., David G., Your Brain and What It Does: A diagram of how the brain works, from Building
Mental Muscle, Brain Waves, 2nd Ed. (2003).
[44] David H. Hubel, Torsten N. Wiesel, Effects of monocular deprivation in kittens, Naunyn-Schmiedebergs
Archiv for Experimentelle Pathologie und Pharmakologie 8 (1964), no. 1, pp.492-497.
[45] Herculano-Houzel Suzana, The human brain in numbers: a linearly scaled-up primate brain, Frontiers in
Human Neuroscience 3 (2009), no. 1, pp.1-31.
[46] James Photis, Neurons, Brain Chemistry, and Neurotransmission, JP-Development (2022).
[47] Keysers C., & Gazzola V., Hebbian learning and predictive mirror neurons for actions, sensations and
emotions, Philosophical transactions of the Royal Society of London. Series B, Biological sciences 369
(2014), no. 1644, pp.1-11.
[48] Shatz C J., The developing brain, Scientific American 267 (1992), no. 3, pp.60-67.
[49] Eric R. Kandel, The molecular biology of memory storage: a dialog between genes and synapses, Bio-
science Reports 21 (2001), no. 5, pp.392-412.

BIBLIOGRAPHY
95
[50] Frost W.N., Castellucci V.F., Hawkinds R.D., Eric R.K., Monosynaptic connections made by the sensory
neurons of the gill and siphon withdrawal reflex in the Aplysia participate in the storage of long-term
memory for sensitization, Proceedings of National Academy of Sciences 82 (2001), no. 82, pp.8266-8269.
[51] W.S. Sossin, J.C. Lacaille, V.F. Castellucci, S. Belleville, Synaptic remodeling, synaptic growth and the
storage of long-term memory in Aplysia, Progress in Brain Research 169 (2008), no. 0079-6123, pp.186-
189.
[52] Allan Bickle, Fundamentals of graph theory, American Mathematical Soc. (2020), pp.1-336.
[53] Demertzi A., Tagliazucchi E., Dehaene S., Deco G., Barttfeld P., Raimondo F., Martial C., Fern´andez-
Espejo D., Rohaut B., Voss H. U., Schiff N. D., Owen A. M., Laureys S., Naccache L., & Sitt J. D.,
Human consciousness is supported by dynamic complex patterns of brain signal coordination, Science
advances 5 (2019), no. 2, pp.1-11.
[54] Albert R., Jeong H. & Barab´asi, Diameter of the World-Wide Web, Nature 401 (199), pp.130-131.
[55] C. Castillo, Effective Web Crawling, PdD Thesis, PloS one, University of Chile (2004).
[56] Monteiro R. L., Carneiro T. K., Fontoura J. R., da Silva V. L., Moret M. A., & Pereira H. B., A Model
for Improving the Learning Curves of Artificial Neural Networks, PloS one 11 (2016), no. 2, pp.1-11.
[57] Jin E. M., Girvan M., & Newman M. E., Structure of growing social networks, Physical review. E,
Statistical, nonlinear, and soft matter physics 64 (2001), no. 4 PT.2, pp.046132.
[58] Yang Y., & Raine A., Prefrontal structural and functional brain imaging findings in antisocial, violent,
and psychopathic individuals: a meta-analysis, Psychiatry research 17 (2009), no. 2, pp.81–88.
[59] Pavlopoulos G. A., Secrier M., Moschopoulos C. N., Soldatos T. G., Kossidam S., Aerts J.Schneider
R., & Bagos P. G., Using graph theory to analyze biological networks, BioData mining 4 (2011), no. 10,
pp.1-27.
[60] Z. Zhihu, CS224 – small world – lecture notes, h (2019), pp.1–35.
[61] Varier S, Kaiser M, Neural development features: Spatio-temporal development of the C. elegans neuronal
network, PLoS Computational Biology 7:e1001044 (2011), pp.921.9.
[62] Choe Y., McCormick BH, Koh W., Network connectivity analysis on the temporally augmented C. elegans
web: A pilot study, Society of Neuroscience Abstracts 30 (2004), pp.921.9.
[63] Van Essen D. C., & Barch D. M., The human connectome in health and psychopathology, World psychiatry
: official journal of the World Psychiatric Association (WPA) 14 (2010), no. 2, pp.154–157.
[64] K¨otter R, Online retrieval, processing, and visualization of primate connectivity data from the CoCoMac
database, Neuroinformatics 2 (2004), no. 2, pp.127-144.
[65] Stanley M., The Small-World problem, Psychology Today 1 (1967), no. 1, pp.61-67.
[66] Latora V., & Marchiori M., Efficient behavior of small-world networks, Physical review letters 87 (2010),
no. 19, pp.1-4.
[67] Danielle S. Bassett & Edward T. Bullmore, Small-World Brain Networks Revisited, Review: The Neu-
roscientist 23 (2016), no. 5, pp.500-516.

BIBLIOGRAPHY
96
[68] Ray Kurzweil, The Singularity Is Near: When Humans Transcend Biology, New York: Viking, Print
(2005), pp.111-142.
[69] Will Knight, Digital Image Stored in Single Molecule, NewScientist.com (2002).
[70] Anatoly K. Khitrin, Vladimir L. Ermakov, and B. M. Fung, Nuclear magnetic resonance molecular
photography, The Journal of Chemical Physics 117 (2002), no. 15, pp.6903-6906.
[71] Claude E. Shannon, A Mathematical Theory of Communication, Bell Systems Technical Journal 27
(1948), no. 3, pp.379–423.
[72] A. Feinstein, Foundations of Information Theory, Prentice Hall, New York (1958).
[73] Cover Thomas M. & Thomas Joy A., Elements of Information Theory (Wiley Series in Telecommuni-
cations and Signal Processing, Wiley Interscience 27 (2006), no. 3, pp.243-256.
[74] Vijay K. Rohatgi, A. K. Md. Ehsanes Saleh, An Introduction to Probability and Statistics, Third Edition,
John Wiley & Sons, Inc. (2015).
[75] Willy Wong, Lecture 1 Review of probability theory, ECE1774 Sensory Cybernetics Lecture notes (2018),
pp.1-8.
[76] Willy Wong., Lecture 2 The mathematics of entropy, ECE1774 Sensory Cybernetics Lecture notes (2018),
pp.1-8.
[77] Ram´on y Cajal S., Comparative Study of the Sensory Areas of the Human Cortex, Clark University
(1899), pp.311-382.
[78] Edward T. Jaynes, Information Theory and Statistical Mechanics, Physical Review Journal 106 (1957),
no. 4, pp.620-630.
[79] Gabriele M. T. D’Eleuterio, Glenn R. Heppler, Newton’s Second Law And All That: A TREATMENT
OF CLASSICAL MECHANICS, University of Toronto (2016), pp.421-455.
[80] Richard J. Blackwell, Christiaan Huygens’ The Pendulum Clock, Part II, Proposition XX, Iowa: Iowa
State University Press (1986), pp.69.
[81] Kuhn H. W., Tucker A. W., Nonlinear Programming, Proceedings of the Second Berkeley Symposium
on Mathematical Statistics and Probability, University of California Press 2 (1951), no. 1, pp.481-492.
[82] Kenneth H. Norwich & Willy Wong, A Universal Model of Single-Unit Sensory Receptor Action, Math-
ematical Biosciences 125 (1995), no. 1, pp.83-108.
[83] Stevens S.S, On the psychophysical law, Psychological Review 64 (1957), no. 3, pp.151-181.
[84] Norwich K. H., On the information received by sensory receptors, Bulletin of mathematical biology 39
(1977), no. 4, pp.453–461.
[85] Hartline H. K. & Graham C. H., Nerve impulses from single receptors in the eye, Journal of Cellular &
Comparative Physiology 1 (1932), no. 1, pp.277–295.
[86] Hartline H. K. & Ratliff F., Inhibitory interaction of receptor units in the eye of Limulus, The Journal
of general physiology 4 (1957), no. 3, pp.357–376.
[87] R.F.Schmidt, Somatovisceral sensibility in Fundamentals of Sensory Physiology, 3rd ed, Springer-Verlag,
New York (1986), pp.89.

BIBLIOGRAPHY
97
[88] Keener J., Sneyd J., Passive Electrical Flow in Neurons. In: Keener, J., Sneyd, J. (eds) Mathematical
Physiology. Interdisciplinary Applied Mathematics, Springer, New York, NY 8 (2009), no. 1, pp.175-194.
[89] Keener J., Sneyd J., Nonlinear Wave Propagation. In: Keener, J., Sneyd, J. (eds) Mathematical Physi-
ology. Interdisciplinary Applied Mathematics, Springer, New York, NY 8 (2009), no. 1, pp.269-296.
[90] Wilfred Rall, Core conductor theory and cable properties of neurons in the Handbook of Physiology: The
Nervous System, Chapter 3, The Journal of physiology 1 (1977), pp.39-97.
[91] Villal´on E., Barry D. M., Byers N., Frizzi K., Jones M. R., Landayan D. S., Dale J. M., Downer N. L.,
Calcutt N. A., & Garcia M. L., Internode length is reduced during myelination and remyelination by neu-
rofilament medium phosphorylation in motor axons., Experimental neurology 306 (2018), pp.158–168.
[92] Bullock T., & Horridge G.A., Structure and function in the nervous systems of invertebrates., Freeman:
San Francisco (1965).
[93] Vesalius A., De Humani Corporis Fabrica : Basel, 1543, Palo Alto, CA :Octavo, 1998.
[94] Daniel Liewald, Robert Miller, Nikos Logothetis, Hans-Joachim Wagner, Almut Sch¨uz, Distribution of
axon diameters in cortical white matter: an electron-microscopic study on three human brains and a
macaque, Max Planck Institute for Biological Cybernetics 108 (2014), no. 5, pp.541–557.
[95] Lex C. Towns, Matthew W. Wagers, Krysta D. Wyatt Samuel S. H. Wang, Jennifer R. Shultz, Mark J.
Burish, Kimberly H. Harrison, Patrick R. Hof, Functional Trade-Offs in White Matter Axonal Scaling,
The Journal of Neuroscience 28 (2008), no. 15, pp.4047-4056.
[96] Masayoshi I., Yoshinori O., The relationship between nerve conduction velocity and fiber morphology
during peripheral nerve regeneration, Brain and behavior 2 (2012), no. 4, pp.382-390.
[97] Markram H., L¨ubke J., Frotscher M., & Sakmann B., Regulation of synaptic efficacy by coincidence of
postsynaptic APs and EPSPs, Science (New York, N.Y.) 275 (1997), no. 5297, pp.213-215.
[98] Bi G. Q., & Poo M. M., Synaptic modifications in cultured hippocampal neurons: dependence on spike
timing, synaptic strength, and postsynaptic cell type., The Journal of neuroscience : the official journal
of the Society for Neuroscience 18 (1998), no. 24, pp.10464–10472.
[99] R. Cai W., Ellinger F., & Tetzlaff, Neuronal synapse as a memristor: modeling pair- and triplet-based
STDP rule, IEEE transactions on biomedical circuits and systems 9 (2015), no. 1, pp.87-95.
[100] Y. Bai, S. Nedjati-Gilani, K. K. Seunarine P. A. Cook M. G. Hall, G. J. Parker, Camino: Open-Source
Diffusion-MRI Reconstruction and Processing, 14th Scientific Meeting of the International Society for
Magnetic Resonance in Medicine Seattle, WA,USA 291 (2010), no. 2006, pp.2759.
[101] Alexander DC, Hubbard PL, Hall MG, Moore EA, Ptito M, Parker GJ, Dyrby TB., Orientationally
invariant indices of axon diameter and density from diffusion, MRI Neuroimage 291 (2010), pp.1374-
1389.
[102] Dyrby TB, Baar´e WF, Alexander DC, Jelsing J, Garde E, Søgaard LV, An ex vivo imaging pipeline for
producing high-quality and high-resolution diffusion weighted imaging datasets, Human Brain mapping,
Human Brain mapping 291 (2011).
[103] E. Aboitiz F., Scheibel A. B., Fisher R. S., & Zaidel, Fiber composition of the human corpus callosum,
Brain research 598 (1992), no. 1-2, pp.143–153.

BIBLIOGRAPHY
98
[104] LaMantia A., & Raki´c, P., Cytological and quantitative characteristics of four cerebral commissures in
the rhesus monkey, Journal of Comparative Neurology 291 (1990).
[105] David Freedman and Persi Diaconis, On the histogram as a density estimator:L2 theory, Zeitschrift f¨ur
Wahrscheinlichkeitstheorie und Verwandte Gebiete 57 (1981), pp.453-476.
[106] Sinisa Pajevic, Peter J. Basser, An Optimum Principle Predicts the Distribution of Axon Diameters in
Normal White Matter, PLoS One 8 (2013), no. 1, pp.1-10.
[107] Song Y., Zhou D., & Li S., Maximum Entropy Principle Underlies Wiring Length Distribution in Brain
Networks, Cerebral cortex (New York, N.Y. : 1991) 31 (2021), no. 10, pp.4628–4641.
[108] Baddeley R., Abbott L. F., Booth, M. C., Sengpiel F., Freeman T., Wakeman E. A., & Rolls E. T.,
esponses of neurons in primary and inferior temporal visual cortices to natural scenes, Proceedings of
Biological sciences 264 (1997), no. 1389, pp.1775–1783.
[109] Attwell D., & Laughlin S. B., An energy budget for signaling in the grey matter of the brain. Journal of
cerebral blood flow and metabolism, official journal of the International Society of Cerebral Blood Flow
and Metabolism 21 (2001), no. 10, pp.1133–1145.
[110] Eric D. Green, National Human Genome Research Institute (NHGRI)., [online] Available at:
http://www.genome.gov/27534788/about-the-institute/ (2015).
[111] Milo R., Jorgensen P., Moran U., Weber G., & Springer M., BioNumbers–the database of key numbers
in molecular and cell biology, Nucleic acids research 38 (2010), no. Database issue, D750–D753.
[112] Laughlin S. B., de Ruyter van Steveninck, R. R., & Anderson J. C., The metabolic cost of neural
information, Nature neuroscience 1 (1998), no. 1, pp.36–41.
[113] Stikov N., Campbell J. S., Stroh T., Lavel´ee M., Frey S., Novek, J., Nuara S., Ho M. K., Bedell B. J.,
Dougherty R. F., Leppert, I. R., Boudreau M., Narayanan, S., Duval T., Cohen-Adad, J., Picard, P.
A., Gasecka A., Cˆot´e D., & Pike G. B., In vivo histology of the myelin g-ratio with magnetic resonance
imaging, NeuroImage 118 (2015), pp.397–405.
[114] Guy J., Ellis E. A., Kelley K., & Hope G. M., Spectra of G ratio, myelin sheath thickness, and axon and
fiber diameter in the guinea pig optic nerve, The Journal of comparative neurology 287 (1989), no. 4,
pp.446–454.
[115] Mohammadi S., Carey D., Dick F., Diedrichsen J., Sereno M. I., Reisert M., Callaghan M. F., & Weiskopf
N., Whole-Brain In-vivo Measurements of the Axonal G-Ratio in a Group of 37 Healthy Volunteers,
Frontiers in neuroscience 9 (2015), no. 441, pp.397–405.
[116] Chomiak T., & Hu B., What is the optimal value of the g-ratio for myelinated fibers in the rat CNS? A
theoretical approach, PloS one 4 (2009), no. 11, pp.1-7.
[117] Rushton W. A., A theory of the effects of fibre size in medullated nerve, The Journal of physiology 115
(1951), no. 1, pp.101-122.
[118] Hopfield J. J., Neural networks and physical systems with emergent collective computational abilities,
Proceedings of the National Academy of Sciences of the United States of America 78 (1982), no. 8,
pp.2554–2558.
[119] Karl Friston, James Kilner, Lee Harrison, A free energy principle for the brain, Journal of Physiology -
Paris 10 (2006), pp.70-87.

