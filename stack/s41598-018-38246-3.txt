1
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
www.nature.com/scientificreports
Neuronal message passing using 
Mean-field, Bethe, and Marginal 
approximations
ThomasÂ Parr1, DimitrijeÂ Markovic2, StefanÂ J.Â Kiebel2 & KarlÂ J.Â Fristonâ€Š â€Š1
Neuronal computations rely upon local interactions across synapses. For a neuronal network to perform 
inference, it must integrate information from locally computed messages that are propagated among 
elements of that network. We review the form of two popular (Bayesian) message passing schemes 
and consider their plausibility as descriptions of inference in biological networks. These are variational 
message passing and belief propagation â€“ each of which is derived from a free energy functional that 
relies upon different approximations (mean-field and Bethe respectively). We begin with an overview 
of these schemes and illustrate the form of the messages required to perform inference using Hidden 
Markov Models as generative models. Throughout, we use factor graphs to show the form of the 
generative models and of the messages they entail. We consider how these messages might manifest 
neuronally and simulate the inferences they perform. While variational message passing offers a simple 
and neuronally plausible architecture, it falls short of the inferential performance of belief propagation. 
In contrast, belief propagation allows exact computation of marginal posteriors at the expense of 
the architectural simplicity of variational message passing. As a compromise between these two 
extremes, we offer a third approach â€“ marginal message passing â€“ that features a simple architecture, 
while approximating the performance of belief propagation. Finally, we link formal considerations to 
accounts of neurological and psychiatric syndromes in terms of aberrant message passing.
Recent work in theoretical neurobiology calls on the notion that the brain performs Bayesian inference1â€“5. This 
view treats perceptions as hypotheses about the causes of sensations6,7. Under this perspective, perceptual infer-
ence is the accumulation of evidence to confirm or refute various explanations for sensory data. As neuronal 
processing relies upon local signalling, the form of the inferences performed by the brain must involve the pass-
ing of local messages8. Here, we compare two forms of Bayesian message passing that have been used to explain 
cognitive phenomena. We consider their plausibility as accounts of neural processing, with a special focus on 
the anatomy of neural architectures that could implement these schemes. This calls for a set of criteria by which 
the plausibility of each scheme can be evaluated. Ultimately, this requires an evaluation of the evidence for each 
alternative process afforded by neurobiological data, considering prior constraints upon neural systems. Our 
focus here is upon the latter, and within this upon two important criteria. First, the computational architectures 
required for neuronal networks to perform inference should be as simple as possible. This is motivated by the 
spatial and metabolic constraints upon biological systems, and by Occamâ€™s razor (i.e. in trying to explain brain 
function, we should adopt the simplest explanation that is consistent with observed data). The second feature, 
which must be balanced against the first, is that these networks should be able to make accurate inferences about 
the causes of incoming sensory data.
This paper builds upon recent work that compares Bayesian message passing schemes in a simulated planning 
and decision making task9. The approach here complements this, but has a different focus. In this paper, our focus 
is upon the form and dynamics of the neuronal networks that are needed to perform inference under alternative 
message passing schemes. The novel aspects of this work include the specification of belief propagation in terms 
of a continuous gradient descent (for comparison with the dynamics previously used for variational message 
passing schemes10) and a neuronal network architecture that performs this gradient descent. This affords the 
opportunity to compare the dynamics of belief-updating under existing schemes. We then unpack a novel scheme â€“  
1Wellcome Centre for Human Neuroimaging, Institute of Neurology, University College London, London, WC1N 
3BG, UK. 2Chair of Neuroimaging, Psychology Department, Technische UniversitÃ¤t Dresden, Dresden, Germany. 
Correspondence and requests for materials should be addressed to T.P. (email: thomas.parr.12@ucl.ac.uk)
Received: 11 July 2018
Accepted: 19 December 2018
Published: xx xx xxxx
OPEN

www.nature.com/scientificreports/
2
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
marginal message passing, and argue that this offers a plausible compromise between the two criteria (simplicity 
and performance) considered above.
Local message passing schemes make use of simple update rules that can be applied to a probabilistic gen-
erative model11,12. The simplicity of these update rules can be illustrated using probabilistic graphical models â€“  
specifically, using normal factor graphs13â€“15. We will leverage the flexibility of these graphs in representing proba-
bilistic models: this serves to illustrate that many common statistical inference procedures may be performed by 
passing local messages on factor graphs. However, different message passing algorithms differ in the approximate 
solution they provide â€“ and in the computational complexity of the scheme. An interesting question then arises; 
which scheme might explain the ability of biological neural networks to perform statistical procedures such as 
blind source separation16. While we focus upon a hidden Markov model for illustrative purposes (as these have 
been used extensively in modelling perceptual inference e.g.17â€“19), the discussion here generalises to other gen-
erative models.
Factor Graphs
We begin with an overview of inferential message passing, before specifying the message passing rules in detail. 
We consider plausible neuronal network architectures that could implement these schemes, and simulate the 
associated inferences. Finally, we consider the implications of each of these schemes for pathologies of neural 
computation.
To map a probabilistic generative model to a factor graph, we follow the steps illustrated in Fig.Â 1â€‰20. We start 
with a generative model that expresses a joint probability distribution over all the random variables in that model. 
We then factorise the joint probability distribution to show the conditional dependencies implied by the model. 
Each factor is represented graphically by a square node. If two factors are functions of the same random varia-
ble, we connect these factors with an edge representing that variable. Any probabilistic generative model can be 
specified in this way13. To illustrate the flexibility of factor graphs FigsÂ 2 and 3 provides factor graph formulations 
of some commonly used generative models in data analysis and machine learning21. Inference about any of these 
models can be performed through local message passing algorithms.
By message passing, we mean that each factor (square node) can synthesise the information coming in from 
one (or more) edge, and pass on this information in the form of a message along another edge. It is interesting to 
consider the relationship of this formal description of inference as message passing, and the informal notion that 
one part of the brain may communicate with another by sending a message. For the purposes of this paper, we 
equate the two, and associate the passing of messages between populations of neurons with inferential messages. 
These populations may be within a brain region, or may sit in different cortical areas. If the latter, the factor across 
which messages are passed is associated with the white matter tracts containing the axons that enable inter-areal 
communication.
Figure 1.â€‚ A graphical representation of a probabilistic model. For a generative model, expressed as a joint 
probability distribution, it is possible to write down the associated factor graph by following a few simple steps. 
First, the model may be expressed in terms of the factors (prior and conditional distributions) that make up 
the joint probability. Square nodes are then associated with each of these factors. These nodes are connected 
whenever they are functions of the same random variable. The result is known as a normal factor graph13,20. 
For comparison, we present the same generative model expressed according to two alternative graphical 
representations. The Bayes net shown on the left places random variables in circular nodes and connects these 
with arrows corresponding to the conditional distributions. An alternative factor graph representation is shown 
on the right. This combines the normal factor graph formalism with that of the Bayes net; incorporating both 
factor and variable nodes. For the rest of this paper, we adopt the normal factor graph formalism as this provides 
a natural way to think about the form of local message passing.

www.nature.com/scientificreports/
3
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
The connection between message passing on a factor graph and effective connectivity in the brain may seem 
a little difficult to intuit, in relation to some theoretical accounts of cortical communication. Communication 
between brain areas is sometimes framed in terms of oscillatory processes, where coherence of oscillations deter-
mines the influence of one set of neurons over another22. While the link between this and a message passed 
across a given factor may not be immediately apparent, the two may be reconciled if we treat the coherence as 
parametrising the precision (inverse variance) associated with this factor. If we imagine the connection between 
two brain regions represents factor 1 in Fig.Â 1, greater coherence between those regions representing x and those 
representing w would enhance the precision of P(w|x), increasing the amount of information transmitted from 
factor 1 to the x-edge following an observation w.
FigureÂ 2 shows the generative models that underwrite inferences about static latent variables. This includes 
dimensionality reduction techniques such as factor analysis and principal component analysis. From a generative 
Figure 2.â€‚ Commonly used (static) generative models as factor graphs. This figure illustrates the generative 
models that underwrite many common inferential procedures. In each factor graph, small blue squares indicate 
observable data, while squares with an equality sign relate their adjoining edges via a delta function factor 
(shown explicitly in lower right inset in Fig.Â 3 - Hidden Markov model). Numbered squares relate factors to 
those in the probabilistic models in the blue panels. This Figure illustrates static models of the sort that underlie 
factor analysis (FA), probabilistic principle component analysis (PPCA), and principal component analysis 
(PCA)21. Each of these dimensionality reduction techniques relies upon the same generative model, but with 
different assumptions about the covariance structure of latent causes or sources. Adding in non-linear functions 
allows this generative model to be extended to incorporate independent component analysis (ICA)94, while 
using two different linear transforms leads to probabilistic canonical variates analysis (CVA)95. Incorporating 
discrete random variables gives mixture models including mixtures of Gaussians (MoG), which form the basis 
of many clustering algorithms96. The notation N indicates a normal (Gaussian) distribution, while Cat means a 
categorical distribution.

www.nature.com/scientificreports/
4
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
modelling approach, these may be thought of as inferences about a low dimensional latent variable that gen-
erates relatively high dimensional data (with different assumptions about the covariance structure of this pro-
cess). Similarly, independent components analysis, used to separate out data into different sets of causes, may be 
thought of as inferring the parameters of the mapping from a non-linear transform of a latent variable to data of 
the same dimension. Canonical variates analysis, a technique used to find linear transforms of two sets of mul-
tivariate data that render them maximally correlated, may be thought of as inferring the set of hidden states that 
best explain (i.e. could have generated) both datasets. Finally, clustering procedures, which are used to separate 
data into distinct clusters, are often based upon a â€˜mixture-of-Gaussiansâ€™ generative model, that assumes data are 
generated from several different Gaussian distributions. Operations of this sort are important in inferring (and 
learning) the structure of our environment from sensory data. By framing these operations in terms of probabil-
istic inference, we can express them as local message passing procedures across appropriate factor graphs.
Figure 3.â€‚ Commonly used (dynamic) generative models. This shows the dynamic generative models that 
support Kalman filtering97 and generalised filtering98 (the basis of predictive coding schemes99 and inversion of 
dynamic causal models100). A discrete state space model that exhibits temporal dynamics is a hidden Markov 
model. This is the generative model we will take as our example for the remainder of this paper and, for this 
reason, we have expressed this in full, with a sequence of transitions over time. The notation N indicates a 
normal (Gaussian) distribution, while Cat means a categorical distribution.

www.nature.com/scientificreports/
5
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
The procedures above may underwrite inferences the brain can draw about unchanging aspects of its envi-
ronment. However, much of our environment is not static. As such, the brain must also make use of models like 
those of Fig.Â 3 that account for temporal dynamics. In the following, we focus upon Hidden Markov Models, as 
these provide a simple example of a dynamical generative model. Although we have chosen to illustrate the ideas 
in this paper using this example, we do not mean to imply that this is the best or only form of generative model 
used by the brain. FiguresÂ 2 and 3 make the point that, if the brain uses a particular local update rule defined on 
a factor graph, a whole range of inferential operations may be performed simply by applying these local rules to 
alternative factor graphs.
Two Bayesian Message Passing Schemes
Bayesian message passing schemes work by passing messages from factor nodes (computed from the information 
at edges adjoining to that node) to each edge. The two messages arriving at each edge are multiplied together 
to obtain the posterior probability associated with the random variable at that edge. While these methods have 
found applications in engineering and machine learning23,24, we focus upon their biological implications. In the 
following, we consider two sorts of message. The first are those associated with belief propagation25,26. Often 
referred to as the â€˜sum-productâ€™ approach, belief propagation is a method used to perform exact Bayesian infer-
ence for marginal distributions on acyclic graphical models and approximate inference on cyclic graphs.
Belief propagation is at the heart of the circular inference account of neuronal computation4,27. Circular infer-
ence offers a biological implementation of belief propagation, and derives its name from the circular patterns of 
inhibitory connections it requires. This scheme additionally underwrites some theoretical accounts of the anat-
omy of cortical micro-circuitry28, and has been implemented in populations of simulated (spiking) neurons15,29.
A generic account of brain function that subsumes the Bayesian brain â€“ and various forms of predictive pro-
cessing such as predictive coding â€“ is active inference30. This account derives from the imperative for living crea-
tures to maximise Bayesian model evidence or, more simply, engage in self-evidencing31. This is equivalent to 
minimising their variational free energy3. One process theory associated with active inference32 proposes that 
communication between populations of neurons occurs through an architecture based upon variational message 
passing12,33.
Both belief propagation and variational message passing have had some success in reproducing aspects of 
cognitive function, e.g.4,27,34â€“39 but lead to rather different interpretations of false inference in neurological and 
psychiatric disorders.
Inferential Message Passing
To illustrate the concepts we describe here, we use a Hidden Markov Model (HMM). This is a ubiquitous discrete 
state space model that also forms an important part of a Markov Decision Process. We chose the HMM as a 
showcase example for this study as it represents an important class of generative models used both in reinforce-
ment learning40,41 and active inference19,30,36. Both techniques have been used when modelling behaviour and, 
in general, are suited to describe processes that evolve through time â€“ something that is crucial for biological 
(as well as robotic42) systems. The inferential message passing in an HMM takes a simple form that is related to 
schemes used in engineering, such as the Baum-Welch (forward-backward) algorithm23. The key aspect of these 
generative models is that hidden states are represented at each point in time over a sequence of outcomes. In other 
words, the hidden state at the beginning of a sequence is distinct from the same state at the end. Although we have 
selected an HMM for illustrative purposes, the two message passing methods we review here are applicable to any 
probabilistic generative model.
FigureÂ 3 (lower half) shows the form of an HMM as a normal factor graph10,13,14,33. This is a representation of 
a joint probability distribution in terms of its factors. It involves two types of random variable â€“ observable out-
comes ( Ï„o ) and hidden states ( Ï„s ). Hidden states evolve through time in a Markov chain. This means that each state 
depends only upon the state at the previous time. At each time, hidden states give rise to an outcome. The sparsity 
of conditional dependencies in this (and other) generative models allows for efficient local message passing 
schemes to be derived. This is because the messages used to compute beliefs about a variable come only from the 
constituents of the variableâ€™s Markov blanket11. The Markov blanket of a given hidden state in an HMM contains 
the state in the immediate past, the state in the immediate future, and observable data at the present.
This is illustrated in Fig.Â 4, where messages are indicated as arrows across factor nodes (large squares) to the 
edges (lines connecting factors) that represent the random variables. Each message can be computed from locally 
available information. The normalised product of incoming messages to an edge is the approximate posterior 
probability distribution over the random variable represented by that edge. The following sections overview two 
established message passing schemes â€“ belief propagation and variational message passing. In addition, we intro-
duce a third scheme â€“ marginal message passing â€“ that combines some of the key advantages of the previous two. 
We consider biologically plausible neuronal networks that could realise these schemes and simulate their behav-
iour when presented with sequential observations.
Belief Propagation
Sum-product belief propagation arises naturally in directed acyclic graphs25 but can also be applied to cyclic 
graphs as the belief update rules correspond to the fixed points of the Bethe free energy26, see the appendix for 
details. The message passing can be expressed in the following way (with messages Î¼ used to compute approxi-
mate posterior beliefs Q about states s at time Ï„)

www.nature.com/scientificreports/
6
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
âˆ‘
âˆ‘
âˆ‘
âˆ‘
Î¼
Î¼
Î¼
Î¼
Î¼
Î¼
Î¼
Î¼
Î¼
Î¼
â‰ˆ
|
âˆ
|
âˆ
â†’
â†
=
|
â†’
=
|
â†’
â†
=
|
â†
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
â€¦
<
<
â€¦
>
>
âˆ’
âˆ’
âˆ’
+
+
+
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
+
+
âˆ’
+
ï‚°
Â·
Â·
Q s
P s o
P o s
P s
o
P s
s
o
Q s
s
s
s
s
P o s
s
P s s
s
s
s
P s
s
s
s
( )
(
)
(
)
(
,
)
( ,
,
)
( )
( )
( )
( )
( )
(
)
( )
(
)
(
)
(
)
( )
(
)
(
)
(
)
(1)
s s
s
t
t
s
s
s
t
t
A
B
B
A
B
s
B
A
B
s
B
A
,
,
,
,
1
1
1
1
1
1
T
1
2
1
1
2
1
1
Figure 4.â€‚ Message passing in a hidden Markov model. This schematic illustrates the scheduling of belief 
propagation (left) and variational message passing (right) in a hidden Markov model. Each row shows a single 
step in a round of message passing, ordered from top to bottom. Under belief propagation, for a message to be 
sent across a factor to an edge, the factor requires all of the other adjoining edges to provide a message. Initially, 
in the first step, this is only true for likelihood factors (that compute their message from the data), and priors 
(that are associated with just one edge). This enforces a strict scheduling that starts with the computation of 
messages at the extremities of the graph. More proximal factors then use these messages from the extremes to 
compute their own. Eventually, when all factors have passed their message, the incoming messages to each edge 
can be combined to compute the marginal posterior belief (Q) about the associated random variable (last row). 
For directed acyclic graphs, one round of message passing is sufficient. For cyclic graphs, multiple rounds may 
be required. In contrast, variational message passing computes messages from the current beliefs associated 
with each edge, and not from other incoming messages. This means that variational message passing simply 
alternates between message passing (of all messages in parallel) and updating posterior expectations.

www.nature.com/scientificreports/
7
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
The first line of this equation uses an approximate equality, as Q is not always equal to the marginal posterior 
(although it is in the absence of cycles in a graph). The second line expresses a proportional relationship, as the 
product of messages needs normalisation. For consistency with the HMM shown in Fig.Â 3, we use a subscript A 
to indicate the messages being passed across a likelihood factor, and subscript B to indicate those passed across 
those factors representing transition probabilities (with a right-pointing arrow indicating a message derived from 
beliefs about the past, and a left-pointing arrow indicating a message from the future). One way to think about 
this scheme is that a message from a given region of the factor graph is the partition function of that region43. 
Each partition function is computed using the partition function of a sub-region within that region, and so on. 
The recursive computation of these messages would be problematic for a network of neurons representing mar-
ginal beliefs, as messages are derived from other messages to an edge (neuronal population), not from the mar-
ginal belief (neuronal activity) itself. This imposes strict constraints on the scheduling of message passing as 
illustrated in Fig.Â 4, where a factor does not pass a message on to a given edge until it has received messages from 
all the other edges connected to it. Technically, this constraint can be removed by using a â€˜loopyâ€™ belief propa-
gation scheme44, or equivalently to rearrange the equations above so that messages depend upon the marginal4.
Î¼
Î¼
Î¼
â†’
âˆ
âˆ’
âˆ’
â†
Ï„
Ï„
Ï„
Ï„
s
Q s
s
s
( )
exp(ln
( )
ln
( )
ln
( ))
(2)
B
A
B
To retain the conditional dependencies of the generative model, we update the marginals through the follow-
ing equation (which is obtained from the second line of EquationÂ 1 by substituting in the message definitions on 
the final three lines)
(
)
Q s
P o s
E
P s s
E
P s
s
( )
exp ln (
)
ln
[ (
)]
ln
[ (
)]
(3)
s
s
s
s
(
)
(
)
1
(
)
(
)
1
B
A
B
A
1
1
1
1
âˆ
|
+
|
+
|
Ï„
Ï„
Ï„
Î¼
Î¼
Ï„
Ï„
Î¼
Î¼
Ï„
Ï„
â†’
âˆ’
â†
+
Ï„
Ï„
Ï„
Ï„
âˆ’
âˆ’
+
+
The â€˜expectationâ€™ notation is used heuristically here, as the messages are not probability distributions. We use 
this notation to mean a summation, where every element of the sum is weighted by the subscripted term (i.e. a 
linear combination of the terms within the expectation). Note that we could have written the above more simply 
as a product of the terms within the logarithms (similar to the second line of EquationÂ 1). However, we have opted 
to express this as an exponential of the sum of three logarithms for consistency with the form of the equations for 
the other message passing schemes presented later. Once we have expressed the equations in this form, the mar-
ginals begin to play an important part in the message passing. Expressing the updates in the form of a gradient 
descent, we arrive at neuronally plausible updates as shown in Fig.Â 5. To obtain these equations we compute an 
error term (Îµ) that is the difference between (the log of) the current estimate of the posterior probability (s) and 
the right hand side of EquationÂ 3. We then construct a differential equation that changes s and has an Îµ of zero 
at its fixed (attracting) point. The softmax (normalised exponential) functions have a high degree of biophysical 
plausibility, as the density dynamics of spiking neuron populations have a similar form45, where synaptic input 
is converted into firing rates that can be propagated along axons to other neural populations. For an interpreta-
tion of belief propagation in terms of spiking neurons, see46,47. The probability matrices now become connectiv-
ity matrices, lending a clear biological interpretation to the inferential equations above. Note that the gradient 
Figure 5.â€‚ Belief propagation as neuronal message passing. The equations on the left show the form of belief 
propagation (EquationsÂ 2 and 3) when expressed in a neuronally plausible form. These equations are written in 
terms of the sufficient statistics of the probability distributions and auxiliary variables representing prediction 
errors (ÎµÏ„) and membrane potentials ( Ï„v ). The softmax (Ïƒ) functions act as neuronal transfer functions, 
converting presynaptic potentials to firing rates ( Ï„s ), which represent the sufficient statistics of the posterior 
beliefs. Forwards and backwards messages across the transition factors (B) are written as Âµ
Âµ
Ï„
Ï„
ï£§â†’
â†ï£§
,
B
B respectively. 
Red indicates an excitatory connection, while blue is inhibitory. The starred connection represents the 
subtraction of the ascending message from that passed on to other neuronal populations. This plays the role of 
an ascending â€˜loopâ€™, as in circular inference accounts of neuronal computation4,37. The analogous descending 
loops are the inhibitory connections between the neurons representing messages in opposite directions. This 
formulation assumes that the neurons representing the messages have much shorter time constants than those 
representing marginal beliefs, allowing the former to be â€˜enslavedâ€™ by the latter15,101. Although omitted here (and 
in later figures) for simplicity, the normalisation induced by the softmax functions could be mediated via 
recurrent inhibitory connections within a layer of neurons.

www.nature.com/scientificreports/
8
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
descent described by the differential equation occurs over a faster time scale than the frequency at which obser-
vations change. Biologically, this is consistent with things like the fast neuronal processing (gradient descent) that 
intervenes between saccadic eye movements (mediating changes in sensory input).
The use of separate populations of neurons that represent messages and marginals resembles previous 
accounts of belief propagation in neuronal networks15,48. An alternative is that one abandons any explicit rep-
resentation of marginal probabilities, and that neurons represent the messages15,49 only. This interpretation has 
two drawbacks. First, it runs into the same scheduling issues described above. Second, explicit representations 
of the marginal beliefs are essential in performing inferential operations including model comparison, model 
selection, and model averaging. This is because these operations require evaluation of approximations to model 
evidence (and expected model evidence) that depend upon these posteriors. Importantly, to properly estimate 
model evidence as a minimum of the Bethe free energy (see below) besides the singleton marginals, a neuronal 
network implementing belief propagation would also have to represent the pairwise marginals, which would add 
additional degrees of complexity to the network illustrated in Fig.Â 5. Model comparison, model selection, and 
model averaging are thought to underwrite the evaluation of behavioural policies that support active engagement 
with the sensorium50,51 and inference with hierarchical models10.
Variational Message Passing
Variational message passing takes a superficially similar form to belief propagation. Marginals of the posterior 
distribution are computed by the product of messages from neighbouring factors12,33.
Î½
Î½
Î½
Î½
Î½
Î½
âˆ
â‹…â†’
â‹…â†
=
|
â†’
=
|
â†
=
|
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
+
Ï„
Ï„
âˆ’
+
Q s
s
s
s
s
P o s
s
E
P s s
s
E
P s
s
( )
( )
( )
( )
ln
( )
ln (
)
ln
( )
[ ln (
)]
ln
( )
[ ln (
)]
(4)
A
B
B
A
B
Q s
B
Q s
(
)
1
(
)
1
1
1
In contrast to belief propagation, the messages (Î½) here are derived from the posterior marginal beliefs at 
each edge. This means that we do not need to wait for all of the incoming messages. Instead, we can iterate 
between computing messages (at all factor nodes in parallel) and updating posterior beliefs. Using a gradient 
ascent ensures we can combine these steps into a single differential equation, as in Fig.Â 6, without any need to 
manipulate the form of the messages as with belief propagation. This leads naturally to the simple neuronal net-
work illustrated here; for which connectivity matrices are log probabilities. The structure in Fig.Â 6 forms part of 
the cortical microcircuit proposed for active inference in Markov decision processes52, and can be extended for 
generative models associated with precision parameters53, and for continuous state space models10.
If we used a generative model that contained n types of hidden state, that could take on m possible values, for 
t time-steps, the architecture of Fig.Â 6 would require 2â€‰Ã—â€‰nâ€‰Ã—â€‰mâ€‰Ã—â€‰t neuronal populations. On comparing this to 
the 4â€‰Ã—â€‰nâ€‰Ã—â€‰mâ€‰Ã—â€‰t populations required for the architecture of Fig.Â 5, it is clear that there is a substantial saving to 
adopting the architecture of Fig.Â 6 for any sizable generative model. Appealing to minimum wire length princi-
ples54 and taking note of the metabolic55 and therefore informational56 costs of individual neurons, this network 
has a substantial structural advantage over that given by belief propagation. However, dendritic computations57 
may have the potential to rescue belief propagation in this regard; i.e., it is possible that forwards and backwards 
Figure 6.â€‚ Variational (and marginal) message passing. The equations on the left show variational message 
passing (upper panel) and marginal message passing (lower panel) expressed as gradient descents on the 
variational (or marginal) free energy. These equations are implemented by the neuronal network shown on the 
right. Notably, this is much simpler than the network of Fig.Â 5, requiring fewer neurons and a simpler 
connectivity structure. The primary reason for the simplicity of this structure is that these schemes take into 
account the current marginal beliefs of adjacent variables. The messages do not need to be recursively computed 
from other messages, Fig.Â 5. This limits the number of auxiliary variables required. We have introduced the 
notation â€ 
B  for the transpose of the transition matrix with normalised columns.

www.nature.com/scientificreports/
9
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
messages could be represented in different parts of the dendritic tree, eliminating the need for additional â€˜mes-
sageâ€™ neurons.
Marginal Message Passing
A third approach to inference combines the simplicity offered by variational message passing with the sophis-
tication of belief propagation. This aims to approximate the messages from the former, but to do so using only 
the locally available marginal beliefs. This was first described as an alternative to variational message passing for 
active inference in Appendix C of32. Marginal message passing recapitulates the pattern from EquationsÂ 1 and 4, 
with marginal posteriors expressed as the product of messages (Î·) from their Markov blanket:
Î·
Î·
Î·
Î·
Î·
Î·
âˆ
â‹…â†’
â‹…â†
=
|
â†’
=
|
â†
=
|
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
+
Ï„
Ï„
âˆ’
+
Q s
s
s
s
s
P o s
s
E
P s s
s
E
P s s
( )
( )
( )
( )
ln
( )
ln (
)
ln
( )
ln
[ (
)]
ln
( )
ln
[ (
)]
(5)
A
B
B
A
B
Q s
B
Q s
1
2
(
)
1
1
2
(
)
1
1
1
Like belief propagation, the expectation sits within the logarithm. Like variational message passing, the mes-
sages are derived from adjacent marginals. A comparison with equationÂ 4 shows that this approach implicitly 
assumes the following relation.
|
â‰ˆ
|
Ï„
Ï„
Ï„
Ï„
Î¼
âˆ’
|
...
âˆ’
â†’
Ï„
Ï„
Ï„
Ï„
âˆ’
âˆ’
âˆ’





E
P s s
E
P s s
ln
[ (
)]
ln
[ (
)]
(6)
Q s
P s
o o
o
s
1
2
(
)
1
(
,
,
)
1
(
)
B
1
1
1
2
1
Intuitively, as 
Ï„âˆ’
Q s(
)
1  approximates the posterior following all available observations, it will be more precise 
(i.e. have a lower Shannon entropy) than 
|
...
Ï„
Ï„
âˆ’
âˆ’
P s
o
o
o
(
,
,
)
1
1
2
1 . This is because the latter represents a partial pos-
terior that considers only past observations. Halving the log message computed using the approximate posterior 
reduces the precision of the resulting message, better approximating the belief propagation message. The motiva-
tion for using Â½ will become more apparent when we describe the underlying free energy functional in the next 
section. However, it would also be possible to treat this corrective factor as a parameter that itself could be opti-
mised in relation to data. Variational message passing fails to attenuate the precision of this message and leads to 
overconfidence in estimating posteriors, as we will illustrate below using simulations. The marginal approach 
retains the simplicity of the variational architecture but eludes this overconfidence issue. An interesting feature of 
this scheme is that backwards messages use transitions from the future to the past â€“ something not seen in the 
other two approaches. We will unpack this in more detail in the following section.
Model Evidence and Free Energies
Both variational message passing, and belief propagation can be shown to represent fixed points for approxi-
mations to model evidence26. In each case, these approximations take the form of free energy functions. In this 
section, we briefly outline the relationship between free energy and model evidence. We then specify the free 
energies that act as the landscapes upon which these inferential optimisations take place. In brief, the variational 
free energy (under the mean-field approximation) approximates model evidence using a relatively simple form 
for the approximate posterior, in which one assumes no interactions between random variables. For belief propa-
gation, the Bethe approximation uses a more sophisticated approximate posterior which takes into account pair-
wise interaction, but under specific conditions sometimes found in cyclic graphs may lead to erroneous estimates 
of the free energy.
Given that belief propagation may be motivated as in EquationÂ 1, it might seem a little redundant to addition-
ally motivate it in terms of the Bethe approximation. However, the Bethe approximation is crucial in understand-
ing how these different message passing schemes relate to one another â€“ as all are free energy minimising schemes 
that maximise a lower bound on model evidence. It is also important in understanding the approximations that 
belief propagation makes in a general setting, and in justifying the generalisation of belief propagation to settings 
beyond acyclic graphs.
In a typical inference problem, one is interested in determining posterior beliefs over hidden states 
=
â€¦
ï‚°s
s
s
( ,
,
)
T
1
 given some set of observations 
=
â€¦
ï‚°o
o
o
(
,
,
)
T
1
 using Bayesâ€™ rule
|
=
ï‚°
ï‚°
ï‚°
ï‚°
ï‚°
P s o
P o s
P o
(
)
( ,
)
( )
(7)
For a general inference problem, the above relation is analytically intractable. First, the denominator on the 
right-hand side (also known as model evidence or marginal likelihood) can be only estimated using approximate 
numerical methods. Second, the posterior probability distribution 
|ï‚°ï‚°
P s o
(
) might not have a known analytic form. 
Variational inference resolves these difficulties using the following approximate scheme for probabilistic infer-
ence: (i) Map the true posterior to a tractable parametric family of probability distributions 
ï‚°
Q s( ). (ii) Find the 
approximate estimate of the true posterior at the minimum of a free energy approximation to the negative model 
evidence.
Model evidence is related to free energy through Jensenâ€™s inequality58.

www.nature.com/scientificreports/
10
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3






 










âˆ’
=
ï£®
ï£°
ï£¯ï£¯
ï£¹
ï£»
ï£ºï£ºâ‰¤
ï£®
ï£°
ï£¯ï£¯
ï£¹
ï£»
ï£ºï£º=
â€²
F
P o s
Q s
P o s
Q s
P o
E
ln
( ,
)
( )
lnE
( ,
)
( )
ln ( )
(8)
Q
Q
s
Negative Free Energy
Jensen
inequality
logevidence
The first of these equations indicates that the (negative) free energy is a lower bound on the evidence for a 
generative model (known in machine learning as an evidence lower bound or ELBO).
We are concerned with the optimisation of this bound, that is, with finding 
ï‚°
Q s( ) which minimises free energy. 
The minimum of the free energy corresponds to the best approximation to the true posterior and closest estimate 
of the model evidence, within the given family of probability distributions. A rearrangement of the terms in the 
left-hand side of the inequality above gives
= âˆ’
+
||
|
= âˆ’
âˆ’
 

























F
P o
D
Q s
P s o
E
P o s
H Q s
ln ( )
[ ( )
(
)]
[ ln ( ,
)]
[ ( )]
(9)
KL
Q
Evidence
Divergence
Energy
Entropy
The first line shows that the bound between the free energy and model evidence is the KL-Divergence between Q 
and the posterior distribution (i.e. the best approximation to the posterior is at the free energy minimum). The 
second shows the free energy expressed as an energy minus entropy (Shannon entropy of the approximate poste-
rior). The minimum of the free energy F is obtained for 
=
|
ï‚°
ï‚°ï‚°
Q s
P s o
( )
(
), in which case the free energy is equal to 
the negative log-model evidence. However, a difficulty here is to find a good approximation to the true posterior 
which makes computation of both the energy and the entropy analytically tractable59,60.
The mean-field and the Bethe approximations choose different forms for the distribution Q. The mean-field 
approximation61 assumes fully factorised posterior probability (although the same principles apply to structured 
mean-field factorisations33).
âˆ
=
Ï„
Ï„
ï‚°
Q s
Q s
( )
( )
(10)
The Bethe approximation is more nuanced, and accounts for the pairwise interactions between variables.
âˆ
âˆ
=
Ï„
Ï„
Ï„ Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
âˆ’
âˆ’
ï‚°
Q s
Q s
Q s
s
Q s Q s
( )
( )
( ,
)
( ) (
)
(11)
,
1
1
1
Returning to the energy-entropy expression, we can write the variational free energy (for a HMM) as
âˆ‘
âˆ‘
= âˆ’
|
+
|
âˆ’
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
Ï„
Ï„
Ï„
âˆ’










F
E
P s s
E
P o s
H Q s
(
[ ln (
)]
[ ln (
)])
[ ( )]
(12)
Q s
Q s
Q s
(
) (
)
1
(
)
Energy
Entropy
1
We then write the Bethe free energy (free energy under the Bethe approximation) as
âˆ‘
âˆ‘
= âˆ’
|
+
|
âˆ’
âˆ’
||
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
âˆ’
âˆ’
Ï„
Ï„
Ï„
âˆ’










F
E
P s s
E
P o s
H Q s
D
Q s
s
Q s Q s
(
[ ln (
)]
[ ln (
)])
( [ ( )]
[ ( ,
)
( ) (
)])
(13)
Q s s
Q s
KL
(
,
)
1
(
)
Energy
1
1
Bethe entropy
1
Although the energy component of the Bethe free energy preserves pairwise interactions between temporally 
proximate states in the expectation, this makes the entropy term a little more complicated. We can express the 
Bethe entropy in terms of the entropy of the marginal factors, but then subtract the mutual information between 
these and the joint factors. This approximates the true entropy (entropy of the exact posterior) by taking into 
account only the pairwise interactions between the variables and ignoring any higher order dependencies. For 
directed acyclic graphs (of the sort considered in this paper), the Bethe energy is always exact and the Bethe 
entropy, although approximate, will always correspond to the entropy of the joint probability distribution 
ï‚°
Q s( ).
However, for a cyclic graph the Bethe energy is approximate, and the Bethe entropy might return suboptimal 
estimates of the entropy of the joint posterior, under certain conditions. This can happen when the solutions that 
satisfy the relation between the singleton Q s( )
t  and pairwise marginals 
âˆ’
Q s s
( ,
)
t
t
1  are implausible for a given cyclic 
graph. Importantly, in such cases, the Bethe free energy might produce strange behaviour (e.g. convergence to a 
limit cycle or improbable configurations of the marginal posterior) and anomalous free energy estimates. To 
mitigate these issues, higher order approximations have been proposed that are based on cluster variational meth-
ods and the Kikuchi approximation59,62,63.
The reason for the differences in convergence behaviours in mean-field and Bethe approaches is related to the 
convexity (or non-convexity) of their respective free energy functionals, specifically the entropy terms. A negative 
entropy is a convex functional, with a positive curvature. However, the negative Bethe entropy has contributions 

www.nature.com/scientificreports/
11
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
from the negative pairwise (convex) and positive singleton (non-convex) entropies. While overlapping pairwise 
marginals are sufficient to characterise the posterior, the Bethe entropy will always be convex. If interactions 
between three or more variables contain information that cannot be captured in overlapping pairwise interac-
tions, the singleton entropies could dominate the pairwise entropies in some parts of the free energy landscape, 
inducing non-convexities that impede convergence. The mean-field entropy is not subject to this problem, as it 
comprises only positive entropy terms. This is a slightly simplistic explanation, to aid intuition. Interested readers 
are referred to60,64 for more formal treatments of this issue.
Despite these convergence issues, the Bethe free energy is often a better approximation to the log evidence 
than the variational free energy (when a mean-field approximation is employed). Under the mean-field approx-
imation both the energy and entropy terms are approximations of the energy and entropy terms that would be 
obtained by setting the approximate posterior equal to the true posterior. For this reason, we ideally want to 
make inferences that are as close as possible to those obtained using belief propagation. The marginal free energy 
offers a way to do this, while retaining the architecture of variational message passing. Marginal message passing 
(EquationÂ 5) is the scheme obtained at the fixed point of the maringal free energy.
Unlike the mean-field or Bethe approaches, marginal message passing makes no claim as to the form of the 
full posterior belief. Instead, it relies upon locally defined free energy functionals to optimise marginals of the 
posterior at each time, while remaining agnostic about how these combine to form a global free energy. FigureÂ 7 
illustrates the idea behind this functional. First, we divide the generative model into two overlapping parts â€“ past 
and future â€“ around the variable we wish to estimate. We then sum (or integrate) over all other hidden states. This 
leads to two marginal generative models, the first with an empirical prior derived from the past and the second 
with an empirical prior derived from the future.










|
â€¦
=
|
|
|
â€¦
=
|
|
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
|
â€¦
âˆ’
|
...
+
|
â€¦
+
|
â€¦
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
âˆ’
âˆ’
+
+
+
+
P o
s o
o
P o s
E
P s s
P o
s o
o
P o s
E
P s s
(
,
,
)
(
)
[ (
)]
(
,
,
)
(
)
[ (
)]
(14)
P s
o
o
P s o
o
T
P s
o
o
P s
o
o
1
1
(
,
)
1
(
,
)
1
(
,
)
1
(
,
)
T
T
1
1
1
1
1
1
1
1
1
To ensure that the empirical prior from the future sums to one, we have normalised the transition probabilities 
so that the future causes the past. This implies the HMM could be run in reverse, consistent with the conserva-
tion of probability mass. Although the empirical priors cannot be computed without resorting to the recursive 
approach of belief propagation, we can approximate these, to give the following (forwards and backwards) free 
energies.
Figure 7.â€‚ Marginal (forward-backward) models. This schematic illustrates the steps that motivate the marginal 
free energy. On the left, we show an HMM that is divided in two different ways. For the future part (lower row), 
we reverse the direction of the transition probabilities by normalising with respect to the earlier times. On the 
right, we take these partitioned generative models and sum over all variables within the dashed boxes. This leads 
to two, marginal, generative models â€“ one that progresses from the past to the future, and one that reverses this. 
By approximating the free energies for each model, and mixing them in equal parts, we define a marginal free 
energy with empirical priors that are independently constrained by the future and the past.

www.nature.com/scientificreports/
12
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
Ï„
Ï„
= âˆ’
|
+
|
âˆ’
= âˆ’
|
+
|
âˆ’
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
+
Ï„
Ï„
Ï„
Ï„
âˆ’
+




















F
E
P o s
E
P s s
H Q s
F
E
P o s
E
P s s
H Q s
( )
[ ln (
)
ln
[ (
)]]
[ ( )]
( )
[ ln (
)
ln
[ (
)]]
[ ( )]
(15)
F
Q s
Q s
B
Q s
Q s
(
)
(
)
1
Energy
Entropy
(
)
(
)
1
Energy
Entropy
1
1
We conjecture, but offer no proof for, the inequality:
Ï„
Ï„
+
â‰¥âˆ’
|
âˆ’
Ï„
Ï„
Ï„
Ï„
Ï„
ï‚°
F
F
E
P o
s o
H Q s
( )
( )
[ ln (
,
)]
[ ( )]
(16)
B
F
Q s(
)
\
This suggests we can define an (approximate) marginal free energy as the mixture of forwards and backwards 
free energies.
Ï„ = âˆ’
|
+
|
+
|
âˆ’
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
âˆ’
+
Ï„
Ï„
Ï„
âˆ’
+
F
E
E
P s s
E
P s s
P o s
H Q s
( )
[
ln
[ (
)]
ln
[ (
)]
ln (
)]
[ ( )]
(17)
Q s
Q s
Q s
(
)
1
2
(
)
1
1
2
(
)
1
1
1
This can then be optimised at each time-step. Minimising the marginal free energy can be thought of as apply-
ing variational filters in forwards and backwards directions and combining the results. This is subtly different to 
the mean-field and Bethe approaches, that each apply a single Bayesian smoother. The mixture in the marginal 
approach ensures we do not overestimate the precision of forwards or backwards messages, as could happen when 
optimising a mean-field posterior.
We hope that we will be able to provide a formal proof of EquationÂ 16 in future work, and to be able to specify 
the conditions under which (if any) the inequality may fail. However, even in the absence of this, it is possible to 
motivate EquationÂ 17 on heuristic grounds. The overconfidence of variational message passing depends upon 
the way in which beliefs about factors of the approximate posterior constrain one another. In EquationÂ 17, the 
contribution of terms that depend upon other factors has been attenuated relative to those that do not mediate 
this influence. Notably, this means that the entropy of posterior beliefs (final term) offers a greater contribution 
to the free energy gradients than it would under a mean-field approach. This favours solutions with more uncer-
tainty (i.e. minima with lower curvature in the free energy landscape65) than can be achieved through variational 
message passing; thereby, finessing the overconfidence problem.
Belief propagation represents the message passing scheme obtained at the stationary point of the Bethe free 
energy, variational message passing is the scheme found at the stationary point of the variational free energy, and 
marginal message passing represents the minimum of the marginal free energies at each time (see Appendix). On 
acyclic graphs they all act as lower bounds for the evidence for a model and could be utilised by a self-evidencing 
biological system. As such, all three forms of neuronal message passing are consistent with the principles that 
underwrite active inference9. The efficiency of these algorithms makes them especially suitable in biological set-
ting, as they can ensure the minimisation of the free energy, and its time integral in an efficient manner.
Simulations
To compare the behaviour of each of these message passing schemes during online inference, we simulated their 
responses while presenting data sequentially. In other words, the scheme accumulates evidence for different hid-
den states by assimilating successive outcomes into posterior beliefs. We used an HMM employing the probability 
distributions specified in Fig.Â 8. This contains two hidden state factors (shapes of different colours) with data 
conditionally dependent upon only one. The purpose of this is to illustrate the behaviour of each scheme in the 
presence of informative and uninformative sensory input. Each of these hidden states starts with a defined shape 
(blue triangle, green square), but undergoes stochastic transitions. This means that the future should always be 
more uncertain than the past. In what follows, we use belief propagation as a gold standard for inferential per-
formance, against which the other two schemes are compared. Our aim here is to illustrate the overconfidence of 
mean-field inference relative to the exact marginal inference of the Bethe approach, and to show how marginal 
approximations mitigate this, achieving a better approximation to belief propagation.
FigureÂ 9 shows the results of simulating inference via the three forms of neuronal message passing outlined 
above. This illustrates some cardinal features of the three schemes. The trajectories of beliefs following each out-
come show that the majority of belief updating occurs very early in variational message passing, before the pres-
entation of most of the data. While a few revisions to these beliefs occur at later stages, it does not take long to 
arrive at highly confident beliefs about future states â€“ this over-confidence of posterior beliefs is a well-recognised 
feature of variational inference under the mean-field approximation66. In contrast, belief propagation and mar-
ginal message passing take a more restrained approach, with each new observation driving updating. This more 
tentative approach pays off, as they make fewer errors in estimating the true states that generated the data. This is 
consistent with the fact that belief propagation offers an exact estimate of marginal beliefs for these models, while 
the variational approach is only ever approximate.
The over-confidence of the variational approach manifests clearly in the posterior beliefs about the green 
shapes. Given the stochastic transitions, and the absence of any informative data about these states, posterior 
beliefs about the green shapes should become increasingly uncertain with distance from the (deterministic) initial 
state. The Bethe approach clearly shows this, but the variational scheme does not, with highly confident beliefs 
about even the penultimate state. Marginal message passing compensates for this overconfidence issue, providing 
a much better approximation to an exact inference scheme than under the mean-field approach. In fact, it slightly 
overcompensates in the absence of precise data, leading to posteriors that are less confident than the belief propa-
gation marginals. The temporal dynamics of belief updating (the upper plots) further illustrate the overconfidence 
of variational message passing relative to the other two schemes. Within the first time-step, the sufficient statistics 
of beliefs about the states over time (each represented as a line) approach extreme (zero or one) values. This means 

www.nature.com/scientificreports/
13
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
that, with only one observation, the mean-field variational approach exhibits an excessive confidence about pres-
ent and future states, that is maintained as new observations are made. In contrast, the belief propagation and 
marginal message passing schemes afford more modest belief updates â€“ following the first observation â€“ that 
become more confident as new data are acquired.
Notably, the three schemes share some of the same errors (four errors in steps 2, 4, 9 and 10). By errors, we 
mean that the inferred state (darkest shade) at a given time-step does not match the state that actually generated 
the data (red dot). These errors happen when very unlikely events occur, such as a dark blue square generated by 
a light blue triangle. Although incorrect, an inference that the light blue square caused the dark blue one is still 
Bayes optimal under the generative model we employed. In contrast, the additional four errors of variational mes-
sage passing in steps 5, 8, 12 and 13 occur even though the data are highly consistent with the hidden states (e.g., 
a dark blue circle generated by a light blue circle). These errors reflect the excessive weight given to the empirical 
priors in variational message passing â€“ it assumes the most probable a priori transition, ignoring the conflicting 
observation. It is important to note that increasing the dimensionality of the space state would further emphasise 
the failings of the mean-field approximation relative to the other two approximations.
To quantify the performance of the mean-field and marginal approaches, we can exploit the fact that the Bethe 
approach is exact for the marginal posteriors for this inference problem. A simple way to do this is to compute 
the KL-Divergence between the marginal posteriors obtained through belief propagation and the solutions of the 
other two schemes. The smaller this divergence, the better the approximation to exact marginal beliefs. For the 
simulations of Fig.Â 9, the divergences summed over marginal posteriors give the following:
âˆ‘
âˆ‘
||
=
.
||
=
.
Ï„
Ï„
Ï„
Ï„
Ï„
Ï„
D
Q
s
Q
s
nats
D
Q
s
Q
s
nats
[
( )
( )]
86 0563
[
( )
( )]
3 7874
KL
BP
VMP
KL
BP
MMP
This demonstrates quantitatively that, even for the relatively simple inference problem used here, there is a 
much greater divergence between the exact marginal posterior beliefs and those obtained using variational mes-
sage passing, relative to marginal message passing.
Although we have presented this as a single simulation, the way in which the generative model is defined, and 
the sequential presentation of the data, actually induce several distinct inference problems that we have implic-
itly appealed to above in characterising these schemes. First, the factorisation of the hidden state-space into two 
different types of latent variable (the light blue and light green shapes of FigsÂ 8 and 9) allows us to compare the 
extreme case in which data are uninformative about the latent variable (light green shapes) with the case in which 
there is only moderate uncertainty about the relationship between (light blue) states and the (dark blue) data. 
FigureÂ 9 shows that, while marginal and Bethe approaches attenuate their confidence â€“ when data is uninforma-
tive compared to informative â€“ the mean-field approach furnishes confident inferences in both cases. Note that 
these differences rely upon there being some uncertainty in the transitions from one state to the next. If we were 
Figure 8.â€‚ Probability distributions for simulated HMM. The probability distributions here make up the 
generative model we used to simulate neuronal message passing under both schemes. These probabilities have 
been chosen to make several points. Firstly, we separated the hidden state into two distinct state factors (light 
blue shapes and light green shapes). This allowed us to generate data (darker blue shapes) that depends upon 
only one of these (light blue). The likelihood mapping illustrates how data are (probabilistically) generated from 
these states (
= |
=
=
Ï„
Ï„
P o
i s
j
A
(
)
ij). We used deterministic priors for the initial states (
=
=
P s
i
D
(
)
i
1
) and 
stochastic transitions (
= |
=
=
Ï„
Ï„
+
P s
i s
j
B
(
)
ij
1
).

www.nature.com/scientificreports/
14
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
to use deterministic transition probabilities, the differences between these schemes would be largely abolished as 
all would make confident inferences.
The second comparison we have used relies upon sequential presentation of the outcomes. This means that 
each time-step represents a distinct inference problem, with more data available at later times than earlier. This is 
where the dynamics shown in the upper row of Fig.Â 9 are revealing. At each successive time point, the inference 
problem becomes more constrained, as an additional observation is made. This allows us to compare the confi-
dence using a small amount of data (at the start of the trial) with the confidence after more data have been seen 
(near the end of the trial). After making the first observation, variational message passing shows a fairly consistent 
level of confidence until the end of the trial. This can be seen in the plot by noting that the distribution of lines 
in the vertical direction is relatively constant throughout the horizontal (temporal) axis. This contrasts with the 
other two schemes that show a greater proportion of lines reaching extreme values with each new observation.
Discussion
This paper considers local computations that lend a biological plausibility to a range of inference schemes. We ini-
tially outlined two approaches to solving inference problems â€“ variational message passing and belief propagation. 
Both can be expressed in a neurobiologically plausible form, but the former features a much simpler neuronal 
network structure. This simplicity comes at the cost of overconfidence, in comparison with the exact solutions 
obtained using belief propagation. The relative advantages of each motivated a third scheme; namely, â€˜marginal 
message passingâ€™ that uses a simple architecture but compensates for the problem of overconfidence. The temporal 
dynamics of inference reflect this, with variational message passing showing much earlier and exuberant changes 
in beliefs about those variables that are yet to give rise to observations, compared to the latter two schemes.
Crucially, we have expressed all three schemes in terms of differential equations describing evolution of beliefs 
over time (FigsÂ 5 and 6). In addition to exposing the temporal dynamics of these approaches, and enabling a 
direct comparison, the resulting schemes also resemble the sorts of expressions that underwrite neural mass 
Figure 9.â€‚ Simulated neuronal message passing for the three schemes: variational message passing, belief 
propagation and Marginal message passing. These plots show the consequences of generating data from the 
model described in Fig.Â 8 and solving the equations of FigsÂ 5 and 6 for these data. The upper plots show the 
beliefs (Ëœs) throughout the trial in terms of the sufficient statistics of the categorical distributions (i.e. probability 
of each alternative state at each time). These depict belief updating in terms of expectations about the two 
hidden factors, each with three levels. Crucially, these beliefs are about each hidden state at (15) different points 
in time. Each line is then the posterior probability that a given hidden state at a given time takes on a specific 
value. The colour-coding of these lines is consistent between the plots along the upper row. These plots are 
important in that they give a sense of the time-course of belief updating. While variational message passing 
shows rapid changes at the very start of the simulation (nearly every line reaches an extreme value within the 
first time-step) and few thereafter, the updates of belief propagation and marginal message passing happen over 
a much longer time scale. The beliefs after each successive outcome are shown in the second and third rows 
(with blackâ€‰=â€‰1 and whiteâ€‰=â€‰0). Each line in the plots in the first row therefore represents a cell in the second or 
third row â€“ drawn at the time point encoded by each line. Red dots indicate the â€˜trueâ€™ states used to generate the 
data. Note that there are no red dots associated with green circles, as these never occur when the initial green 
state is a square (see the transition matrix in Fig.Â 8). The final row shows the sequence of observations presented 
to each message passing scheme. The second and third rows show the posterior beliefs about the two factors 
comprising the hidden state space as shown in Fig.Â 8.

www.nature.com/scientificreports/
15
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
models67. In other words, the neuronal dynamics implied by all three schemes are determined by a mixture of the 
activity of other populations of neurons. This mixture of input determines the rate of change of a log probability, 
which may be thought of as a membrane potential. The membrane potential itself determines the influence of a 
neuronal population on other populations through a softmax function, and this can be seen as analogous to the 
translation of a membrane potential into an average firing rate. In short, all three schemes have a potential biolog-
ical validity in that belief dynamics can be expressed in a form closely related to that of neuronal mass dynamics 
(please see32 for further details).
Note that the classical â€˜forward-backwardâ€™ algorithm68 is a special case of the belief propagation applied to an 
HMM. This algorithm computes a set of forward probabilities and backwards probabilities before combining the 
results to give marginal posterior probability distributions. Marginal message passing can therefore be regarded 
as an approximation to the inference steps used in these schemes.
The â€˜forward-backwardâ€™ algorithm (hence belief propagation) is also used in the inference step of the 
Baum-Welch algorithm69. However, the Baum-Welch algorithm has an additional step that distinguishes it from 
belief propagation and other variational approaches. This is a maximum likelihood update of the parameters 
of the generative model. The alternation between an inference step and a maximum likelihood update in the 
Baum-Welch algorithm underwrites its formal equivalence with the Expectation-Maximisation70 algorithm (as 
applied to an HMM), although the latter is rarely articulated in terms of message passing.
In contrast, the three variational schemes we have discussed here are (approximately) Bayesian, and so do not 
permit maximum likelihood updating. Instead, to draw inferences about parameters in these schemes, we need 
to specify prior distributions over the parameter values and use these to compute posterior beliefs58,71. From the 
perspective of Bayesian message passing, this just means extending the factor graph to include parameters, and 
passing additional messages. From the perspective of neurobiology, updates in beliefs about transition or likeli-
hood probabilities would manifest as plastic changes in the efficacy of synapses connecting neuronal populations. 
This would allow for rewiring72 of the network to deal with a different (HMM) generative model if the way in 
which data were generated changed. Note that, once the generative model has been learned (as is assumed in the 
simulations here), the inference task depends only upon the neuronal activities, and does not require changes in 
connectivity in response to new data.
The particular form of message passing has implications for empirical studies, as disambiguating between 
alternative mechanisms that underwrite biological inference may be important in understanding psychopa-
thology; e.g., hallucinations and delusions. All three message passing schemes make clear predictions about the 
time-course of electrophysiological responses at different time points following an outcome; i.e., within a trial. 
To adjudicate along different belief updating schemes, one could present participants with a sequence like that 
above, after exposing them to previous sequences so that they have learned the probabilistic structure of the task. 
If the brain employs variational message passing, we would anticipate greater evoked responses for the first few 
stimuli, given the greater rate of belief updating at these times. On immediate recall of the sequence, one might 
expect participants to make errors consistent with those found here â€“ overestimating the precision of transitions.
To better accommodate behavioural responses, we could equip the schemes above with an active component3, 
and fit the resulting model to human behaviour36. It is more difficult to distinguish between belief propagation 
and a scheme (like marginal message passing) that seeks to emulate it in a simpler architecture. However, there are 
several forms of data that could be brought to bear on this question. First, one could appeal to a similar task as that 
above and fit the evoked responses with neural mass models67 that mimic the architectures of FigsÂ 5 and 6. If addi-
tional neurons with fast time constants, representing the messages, improve the accuracy of the fit in excess of any 
increase in complexity, this would offer evidence in favour of belief propagation. Decreased accuracy, or preserved 
accuracy in the presence of an increased complexity, would instead favour a simpler architecture like marginal mes-
sage passing. Further evidence could be garnered from tract tracing studies; e.g.73, or from single unit recordings â€“  
to ask whether they are better explained as representing messages rather than the sufficient statistics of marginal 
beliefs. Alternatively, one could compare the ability of simulated belief trajectories to explain electrophysiological 
responses. Current circuit-level research shows a high degree of consistency with the form of the neuronal networks 
presented here74â€“76, but these data are not sufficient to confidently disambiguate between the two architectures. 
Sensory input (via the thalamus) predominantly targets granular layers of cortex77,78, which excite more superficial 
cells and are disynaptically inhibited by them in turn79. This is consistent with FigsÂ 5 and 6. The belief propagation 
architecture of Fig.Â 5 calls for another set of neurons (those representing the messages) that are inhibited by input 
from sensory streams and that excite the granular cells. Reversing the signs (excitation-inhibition), it is plausible 
that inhibitory interneurons in layer IV in receipt of sensory input74 could play this role; inducing an inhibition in 
the granular cells in response to sensory input (as opposed to exciting them in its absence). Apart from the empirical 
question, which of the neuronal schemes is supported by empirical data, there is also an important theoretical issue: 
we have focussed upon the neuronal manifestations of inference, but there are many other examples of biological 
inference that depend upon similar local interactions. It will be interesting to see whether the same principles of 
local message passing can be scaled up to collective behaviour80,81, with individuals exchanging information with 
their neighbours; or whether it can be scaled down to the computations performed by biochemical networks82.
Many neurological and psychiatric syndromes can be thought of in terms of false inference83. The form of 
healthy computation may be important for understanding the types of pathology that might affect it. Broadly 
speaking, computational pathologies can be described in terms of optimal inference using a suboptimal genera-
tive model84â€“87, or as broken inferential machinery4,37. An account of a pathology in terms of a suboptimal gen-
erative model transcends specific Bayesian message passing schemes and could be reproduced using variational 
message passing or belief propagation (or any other scheme). Theories of schizophrenia86, autism88,89, and visual 
neglect87 (among others) that appeal to pathological prior beliefs may be interpreted as deficits in any of the 
message passing schemes described here. In contrast, an account based on broken message passing commits to a 
specific neuronal implementation and is only meaningful if formulation of belief updating is correct.

www.nature.com/scientificreports/
16
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
An example of the latter is a recent theory that aims to account for inferential deficits that underwrite per-
ceptual changes in schizophrenia. This posits ascending and descending inferential â€˜loopsâ€™, and that disruption of 
these could lead to an â€˜overcountingâ€™ of a message4. To build some intuition for this idea, imagine we were to cut 
the starred connection in Fig.Â 5. This connection subtracts the ascending message from the forward message. A 
failure to subtract this message means the forward message will also contain the ascending message. The neurons 
representing the marginal then receive two copies of the ascending message; i.e., it is overcounted37. This could 
lead to an oversensitivity to sensory information90, and a failure to contextualise it using prior beliefs. That this 
is due to a failure of subtraction by an inhibitory interneuron is consistent with data suggesting disruptions in 
the balance of excitatory and inhibitory synaptic activity91â€“93 in patients with psychosis. Crucially, this account 
relies upon belief propagation implemented in a specific way â€“ and does not generalise to marginal or variational 
message passing schemes.
Conclusion
Variational message passing and belief propagation both represent means of performing Bayesian inference using 
local computations, consistent with the computations of biological neuronal networks. Both minimise free energy 
functionals, so are consistent with active inference â€“ or the minimisation of free energy through action and 
perception. There are notable differences between the two schemes. While belief propagation represents exact 
Bayesian inference (for many generative models), variational approaches yield approximate inference. The latter 
tends towards excessive confidence in the face of uncertainty, deviating from exact Bayesian optimality. However, 
the kinds of neuronal network that support belief propagation appear to require a greater number of neurons and 
axons to achieve biological plausibility. This suggests a trade-off between inferential accuracy (belief propagation) 
and a complexity cost (variational message passing). Drawing from the relative benefits and drawbacks, we have 
introduced a third possibility. The brain may approximate belief propagation, using circuitry consistent with 
variational message passing. We hope to disambiguate between these possibilities in future work. An interesting 
conceptual issue that arises from these considerations is how best to understand the false inferences that under-
write neurological and psychiatric disease. Appealing to broken generative models enables one to be agnostic 
about the exact form of message passing, while hypothetical lesions to the inferential machinery depend upon the 
validity of that machinery.
Data Availability
The script used for the simulations is available at https://github.com/tejparr/nmpassing.
References
	 1.	 Knill, D. C. & Pouget, A. The Bayesian brain: the role of uncertainty in neural coding and computation. TRENDS in Neurosciences 
27, 712â€“719 (2004).
	 2.	 Doya, K. Bayesian brain: Probabilistic approaches to neural coding. (MIT press, 2007).
	 3.	 Friston, K. J., Daunizeau, J., Kilner, J. & Kiebel, S. J. Action and behavior: a free-energy formulation. Biological Cybernetics 102, 
227â€“260, https://doi.org/10.1007/s00422-010-0364-z (2010).
	 4.	 Jardri, R. & DenÃ¨ve, S. Circular inferences in schizophrenia. Brain 136, 3227â€“3241, https://doi.org/10.1093/brain/awt257 (2013).
	 5.	 MarkoviÄ‡, D. & Kiebel, S. J. Comparative Analysis of Behavioral Models for Adaptive Learning in Changing Environments. 
Frontiers in Computational Neuroscience, 10, https://doi.org/10.3389/fncom.2016.00033 (2016).
	 6.	 Gregory, R. L. Perceptions as Hypotheses. Philosophical Transactions of the Royal Society of London. B, Biological Sciences 290, 181 (1980).
	 7.	 Von Helmholtz, H. Handbuch der physiologischen Optik. Vol. 9 (Voss, 1867).
	 8.	 Rao, R. P. Neural Models of Bayesian Belief Propagation. Bayesian brain: Probabilistic approaches to neural coding, 239 (2007).
	 9.	 SchwÃ¶bel, S., Kiebel, S. & MarkoviÄ‡, D. Active Inference, Belief Propagation, and the Bethe Approximation. Neural computation, 
1â€“38 (2018).
	 10.	 Friston, K. J., Parr, T. & Vries, B. D. The graphical brain: belief propagation and active inference. Network Neuroscience 0, 1â€“78, 
https://doi.org/10.1162/NETN_a_00018 (2017).
	 11.	 Pearl, J. Graphical models for probabilistic and causal reasoning (1997).
	 12.	 Winn, J. & Bishop, C. M. Variational message passing. Journal of Machine Learning Research 6, 661â€“694 (2005).
	 13.	 Forney, G. D. Codes on graphs: Normal realizations. IEEE Transactions on Information Theory 47, 520â€“548 (2001).
	 14.	 Loeliger, H. A. et al. The Factor Graph Approach to Model-Based Signal Processing. Proceedings of the IEEE 95, 1295â€“1322, https://
doi.org/10.1109/JPROC.2007.896497 (2007).
	 15.	 Steimer, A., Maass, W. & Douglas, R. Belief Propagation in Networks of Spiking Neurons. Neural Computation 21, 2502â€“2523, 
https://doi.org/10.1162/neco.2009.08-08-837 (2009).
	 16.	 Isomura, T., Kotani, K. & Jimbo, Y. Cultured Cortical Neurons Can Perform Blind Source Separation According to the Free-Energy 
Principle. PLOS Computational Biology 11, e1004643, https://doi.org/10.1371/journal.pcbi.1004643 (2015).
	 17.	 Angela, J. Y. & Dayan, P. Acetylcholine in cortical inference. Neural Networks 15, 719â€“730 (2002).
	 18.	 Beck, J. M. & Pouget, A. Exact inferences in a neural implementation of a hidden Markov model. Neural computation 19, 
1344â€“1361 (2007).
	 19.	 Friston, K. & Samothrakis, S. & Montague, R. Active inference and agency: optimal control without cost functions. Biological 
Cybernetics 106, 523â€“541, https://doi.org/10.1007/s00422-012-0512-8 (2012).
	 20.	 Loeliger, H. A. An introduction to factor graphs. IEEE Signal Processing Magazine 21, 28â€“41, https://doi.org/10.1109/
MSP.2004.1267047 (2004).
	 21.	 Roweis, S. & Ghahramani, Z. A Unifying Review of Linear Gaussian Models. Neural Computation 11, 305â€“345, https://doi.
org/10.1162/089976699300016674 (1999).
	 22.	 Fries, P. Rhythms For Cognition: Communication Through Coherence. Neuron 88, 220â€“235, https://doi.org/10.1016/j.
neuron.2015.09.034 (2015).
	 23.	 Welch, L. R. Hidden Markov models and the Baum-Welch algorithm. IEEE Information Theory Society Newsletter 53, 10â€“13 (2003).
	 24.	 Winn, J. M. Variational message passing and its applications, Citeseer (2004).
	 25.	 Pearl, J. Probabilistic reasoning in intelligent systems: networks of plausible inference. (Elsevier, 2014).
	 26.	 Yedidia, J. S., Freeman, W. T. & Weiss, Y. Constructing free-energy approximations and generalized belief propagation algorithms. 
IEEE Transactions on Information Theory 51, 2282â€“2312 (2005).

www.nature.com/scientificreports/
17
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
	 27.	 Jardri, R., Duverne, S., Litvinova, A. S. & DenÃ¨ve, S. Experimental evidence for circular inference in schizophrenia. Nature 
Communications 8, 14218, https://doi.org/10.1038/ncomms14218, https://www.nature.com/articles/ncomms14218#supplementary-
information (2017).
	 28.	 George, D. & Hawkins, J. Belief propagation and wiring length optimization as organizing principles for cortical microcircuits. 
(Technical report, Numenta, http://www.numenta.com, 2006).
	 29.	 Deneve, S. In Advances in neural information processing systems. 353â€“360.
	 30.	 Friston, K. et al. Active inference and epistemic value. Cognitive Neuroscience 6, 187â€“214, https://doi.org/10.1080/17588928.2015.
1020053 (2015).
	 31.	 Hohwy, J. The Self-Evidencing Brain. NoÃ»s 50, 259â€“285, https://doi.org/10.1111/nous.12062 (2016).
	 32.	 Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P. & Pezzulo, G. Active Inference: A Process Theory. Neural Comput 29, 1â€“49, 
https://doi.org/10.1162/NECO_a_00912 (2017).
	 33.	 Dauwels, J. In Information Theory, 2007. ISIT 2007. IEEE International Symposium on. 2546â€“2550 (IEEE).
	 34.	 Parr, T. & Friston, K. J. Working memory, attention, and salience in active inference. Scientific reports 7, 14678, https://doi.
org/10.1038/s41598-017-15249-0 (2017).
	 35.	 Perrinet, L. U., Adams, R. A. & Friston, K. J. Active inference, eye movements and oculomotor delays. Biological Cybernetics 108, 
777â€“801, https://doi.org/10.1007/s00422-014-0620-8 (2014).
	 36.	 Mirza, M. B., Adams, R. A., Mathys, C. & Friston, K. J. Human visual exploration reduces uncertainty about the sensed world. 
PLOS ONE 13, e0190429, https://doi.org/10.1371/journal.pone.0190429 (2018).
	 37.	 Leptourgos, P., DenÃ¨ve, S. & Jardri, R. Can circular inference relate the neuropathological and behavioral aspects of schizophrenia? 
Current Opinion in Neurobiology 46, 154â€“161, https://doi.org/10.1016/j.conb.2017.08.012 (2017).
	 38.	 Kaplan, R. & Friston, K. J. Planning and navigation as active inference. Biological Cybernetics, https://doi.org/10.1007/s00422-018-
0753-2 (2018).
	 39.	 Friston, K. J. et al. Active inference, curiosity and insight. Neural Computation (2017).
	 40.	 Jaakkola, T., Singh, S. P. & Jordan, M. I. In Advances in neural information processing systems. 345â€“352.
	 41.	 Sutton, R. S. & Barto, A. G. Reinforcement learning: An introduction. Vol. 1 (MIT press Cambridge, 1998).
	 42.	 Tani, J. Self-Organization and Compositionality in Cognitive Brains: A Neurorobotics Study. Proceedings of the IEEE 102, 586â€“605, 
https://doi.org/10.1109/JPROC.2014.2308604 (2014).
	 43.	 Forney, G. D. Jr. & Vontobel, P. O. Partition functions of normal factor graphs. arXiv preprint arXiv:1102.0316 (2011).
	 44.	 Heskes, T. In Advances in neural information processing systems. 359â€“366.
	 45.	 Deco, G., Jirsa, V. K., Robinson, P. A., Breakspear, M. & Friston, K. The Dynamic Brain: From Spiking Neurons to Neural Masses 
and Cortical Fields. PLOS Computational Biology 4, e1000092, https://doi.org/10.1371/journal.pcbi.1000092 (2008).
	 46.	 Buesing, L., Bill, J., Nessler, B. & Maass, W. Neural dynamics as sampling: a model for stochastic computation in recurrent networks 
of spiking neurons. PLoS computational biology 7, e1002211 (2011).
	 47.	 Pecevski, D., Buesing, L. & Maass, W. Probabilistic inference in general graphical models through sampling in stochastic networks 
of spiking neurons. PLoS computational biology 7, e1002294 (2011).
	 48.	 George, D. & Hawkins, J. Towards a Mathematical Theory of Cortical Micro-circuits. PLOS Computational Biology 5, e1000532, 
https://doi.org/10.1371/journal.pcbi.1000532 (2009).
	 49.	 Steimer, A. & Douglas, R. Spike-based probabilistic inference in analog graphical models using interspike-interval coding. Neural 
computation 25, 2303â€“2354 (2013).
	 50.	 Mirza, M. B., Adams, R. A., Mathys, C. D. & Friston, K. J. Scene Construction, Visual Foraging, and Active Inference. Frontiers in 
Computational Neuroscience10, https://doi.org/10.3389/fncom.2016.00056 (2016).
	 51.	 FitzGerald, T., Dolan, R. & Friston, K. Model averaging, optimal inference, and habit formation. Front. Hum. Neurosci, https://doi.
org/10.3389/fnhum.2014.00457 (2014).
	 52.	 Friston, K. J., Rosch, R., Parr, T., Price, C. & Bowman, H. Deep temporal models and active inference. Neuroscience & Biobehavioral 
Reviews 77, 388â€“402, https://doi.org/10.1016/j.neubiorev.2017.04.009 (2017).
	 53.	 Parr, T. & Friston, K. J. Uncertainty, epistemics and active inference. Journal of The Royal Society Interface 14 (2017).
	 54.	 Laughlin, S. B. & Sejnowski, T. J. Communication in Neuronal Networks. Science (New York, N.Y.) 301, 1870â€“1874, https://doi.
org/10.1126/science.1089662 (2003).
	 55.	 Lennie, P. The Cost of Cortical Computation. Current Biology 13, 493â€“497, https://doi.org/10.1016/S0960-9822(03)00135-0 (2003).
	 56.	 Landauer, R. Irreversibility and heat generation in the computing process. IBM journal of research and development 5, 183â€“191 
(1961).
	 57.	 London, M. & HÃ¤usser, M. DENDRITIC COMPUTATION. Annual Review of Neuroscience 28, 503â€“532, https://doi.org/10.1146/
annurev.neuro.28.061604.135703 (2005).
	 58.	 Beal, M. J. (University of London United Kingdom, 2003).
	 59.	 Wainwright, M. J. & Jordan, M. I. Graphical models, exponential families, and variational inference. Foundations and TrendsÂ® in 
Machine Learning 1, 1â€“305 (2008).
	 60.	 Heskes, T. Convexity arguments for efficient minimization of the Bethe and Kikuchi free energies. Journal of Artificial Intelligence 
Research 26, 153â€“190 (2006).
	 61.	 Feynman, R. P. Statistical Mechanics: A Set Of Lectures. (Avalon Publishing, 1998).
	 62.	 Mohri, T. Cluster Variation Method. Jom 65, 1510â€“1522 (2013).
	 63.	 Maren, A. J. The Cluster Variation Method: A Primer for Neuroscientists. Brain Sciences 6, 44, https://doi.org/10.3390/
brainsci6040044 (2016).
	 64.	 Weller, A., Tang, K., Sontag, D. & Jebara, T. In 30th Conference on Uncertainty in Artificial Intelligence, UAI. (AUAI Press, 2014).
	 65.	 Friston, K., Breakspear, M. & Deco, G. Perception and self-organized instability. Frontiers in Computational Neuroscience 6, https://
doi.org/10.3389/fncom.2012.00044 (2012).
	 66.	 Consonni, G. & Marin, J.-M. Mean-field variational approximate Bayesian inference for latent variable models. Computational 
Statistics & Data Analysis 52, 790â€“798, https://doi.org/10.1016/j.csda.2006.10.028 (2007).
	 67.	 Moran, R., Pinotsis, D. A. & Friston, K. Neural masses and fields in dynamic causal modeling. Frontiers in Computational 
Neuroscience 7, 57, https://doi.org/10.3389/fncom.2013.00057 (2013).
	 68.	 Rabiner, L. R. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE 77, 
257â€“286, https://doi.org/10.1109/5.18626 (1989).
	 69.	 Baum, L. E. & Eagon, J. A. An inequality with applications to statistical estimation for probabilistic functions of Markov processes 
and to a model for ecology. Bull. Amer. Math. Soc. 73, 360â€“363 (1967).
	 70.	 Dempster, A. P., Laird, N. M. & Rubin, D. B. Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the 
Royal Statistical Society. Series B (Methodological) 39, 1â€“38 (1977).
	 71.	 Friston, K. et al. Active inference and learning. Neuroscience & Biobehavioral Reviews 68, 862â€“879, https://doi.org/10.1016/j.
neubiorev.2016.06.022 (2016).
	 72.	 Mastrogiuseppe, F. & Ostojic, S. Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks. 
Neuron 99, 609â€“623.e629, https://doi.org/10.1016/j.neuron.2018.07.003 (2018).
	 73.	 VÃ©lez-Fort, M. et al. The Stimulus Selectivity and Connectivity of Layer Six Principal Cells Reveals Cortical Microcircuits 
Underlying Visual Processing. Neuron 83, 1431â€“1443, https://doi.org/10.1016/j.neuron.2014.08.001 (2014).

www.nature.com/scientificreports/
18
Scientific Reports |          (2019) 9:1889  | https://doi.org/10.1038/s41598-018-38246-3
	 74.	 Haeusler, S. & Maass, W. A Statistical Analysis of Information-Processing Properties of Lamina-Specific Cortical Microcircuit 
Models. Cerebral Cortex 17, 149â€“162, https://doi.org/10.1093/cercor/bhj132 (2007).
	 75.	 Bastos, A. M. et al. Canonical microcircuits for predictive coding. Neuron 76, 695â€“711, https://doi.org/10.1016/j.neuron.2012.10.038 
(2012).
	 76.	 Shipp, S. Neural Elements for Predictive Coding. Frontiers in Psychology 7, 1792, https://doi.org/10.3389/fpsyg.2016.01792 (2016).
	 77.	 Miller, K. D. Understanding Layer 4 of the Cortical Circuit: A Model Based on Cat V1. Cerebral Cortex 13, 73â€“82, https://doi.
org/10.1093/cercor/13.1.73 (2003).
	 78.	 Shipp, S. Structure and function of the cerebral cortex. Current Biology 17, R443â€“R449, https://doi.org/10.1016/j.cub.2007.03.044 (2007).
	 79.	 Thomson, A. M., West, D. C., Wang, Y. & Bannister, A. P. Synaptic Connections and Small Circuits Involving Excitatory and 
Inhibitory Neurons in Layers 2â€“5 of Adult Rat and Cat Neocortex: Triple Intracellular Recordings and Biocytin Labelling In Vitro. 
Cerebral Cortex 12, 936â€“953, https://doi.org/10.1093/cercor/12.9.936 (2002).
	 80.	 Herbert-Read, J. E. et al. Inferring the rules of interaction of shoaling fish. Proceedings of the National Academy of Sciences 108, 
18726â€“18731, https://doi.org/10.1073/pnas.1109355108 (2011).
	 81.	 Mann, R. P. & Garnett, R. The entropic basis of collective behaviour. Journal of The Royal Society Interface 12 (2015).
	 82.	 Genot, A. J., Fujii, T. & Rondelez, Y. Computing with Competition in Biochemical Networks. Physical Review Letters 109, 208102 (2012).
	 83.	 Parr, T., Rees, G. & Friston, K. J. Computational Neuropsychology and Bayesian Inference. Frontiers in Human Neuroscience 12, 
https://doi.org/10.3389/fnhum.2018.00061 (2018).
	 84.	 Daunizeau, J. et al. Observing the Observer (I): Meta-Bayesian Models of Learning and Decision-Making. PLOS ONE 5, e15554, 
https://doi.org/10.1371/journal.pone.0015554 (2010).
	 85.	 Schwartenbeck, P. et al. Optimal inference with suboptimal models: addiction and active Bayesian inference. Medical hypotheses 
84, 109â€“117, https://doi.org/10.1016/j.mehy.2014.12.007 (2015).
	 86.	 Adams, R. A., Stephan, K. E., Brown, H. R., Frith, C. D. & Friston, K. J. The Computational Anatomy of Psychosis. Frontiers in 
Psychiatry 4, 47, https://doi.org/10.3389/fpsyt.2013.00047 (2013).
	 87.	 Parr, T. & Friston, K. J. The Computational Anatomy of Visual Neglect. Cerebral Cortex, 1â€“14, https://doi.org/10.1093/cercor/
bhx316 (2017).
	 88.	 Lawson, R. P., Rees, G. & Friston, K. J. An aberrant precision account of autism. Frontiers in Human Neuroscience 8, 302, https://
doi.org/10.3389/fnhum.2014.00302 (2014).
	 89.	 Lawson, R. P., Mathys, C. & Rees, G. Adults with autism overestimate the volatility of the sensory environment. Nat Neurosci 20, 
1293â€“1299, https://doi.org/10.1038/nn.4615, http://www.nature.com/neuro/journal/v20/n9/abs/nn.4615.html#supplementary-
information (2017).
	 90.	 Shergill, S. S., Samson, G., Bays, P. M., Frith, C. D. & Wolpert, D. M. Evidence for Sensory Prediction Deficits in Schizophrenia. 
American Journal of Psychiatry 162, 2384â€“2386, https://doi.org/10.1176/appi.ajp.162.12.2384 (2005).
	 91.	 Lisman, J. E. et al. Circuit-based framework for understanding neurotransmitter and risk gene interactions in schizophrenia. 
Trends in neurosciences 31, 234â€“242, https://doi.org/10.1016/j.tins.2008.02.005 (2008).
	 92.	 Perry, T., Buchanan, J., Kish, S. & Hansen, S. Î³-Aminobutyric-acid deficiency in brain of schizophrenic patients. The Lancet 313, 
237â€“239 (1979).
	 93.	 Blum, B. P. & Mann, J. J. The GABAergic system in schizophrenia. International Journal of Neuropsychopharmacology 5, 159â€“179 (2002).
	 94.	 Bell, A. J. & Sejnowski, T. J. An information-maximization approach to blind separation and blind deconvolution. Neural 
computation 7, 1129â€“1159 (1995).
	 95.	 Bach, F. R. & Jordan, M. I. A probabilistic interpretation of canonical correlation analysis (2005).
	 96.	 Nowlan, S. J. In Advances in neural information processing systems. 574â€“582.
	 97.	 Kalman, R. E. A new approach to linear filtering and prediction problems. Journal of basic Engineering 82, 35â€“45 (1960).
	 98.	 Friston, K., Stephan, K., Li, B. & Daunizeau, J. Generalised filtering. Mathematical Problems in Engineering 2010 (2010).
	 99.	 Friston, K. & Kiebel, S. Predictive coding under the free-energy principle. Philosophical Transactions of the Royal Society B: 
Biological Sciences 364, 1211 (2009).
	100.	 Li, B. et al. Generalised filtering and stochastic DCM for fMRI. NeuroImage 58, 442â€“457, https://doi.org/10.1016/j.
neuroimage.2011.01.085 (2011).
	101.	 Haken, H. Slaving principle revisited. Physica D: Nonlinear Phenomena 97, 95â€“103, https://doi.org/10.1016/0167-2789(96)00080-2 
(1996).
Acknowledgements
TP is supported by the Rosetrees Trust (Award Number 173346). KJF is a Wellcome Principal Research Fellow 
(Ref: 088130/Z/09/Z). This work was supported by the Deutsche Forschungsgemeinschaft (SFB 940/2, Project 
A9) and by the TU Dresden Graduate Academy.
Author Contributions
T.P., D.M., S.K., K.J.F. contribution to writing. T.P. and D.M. performed the simulations.
Additional Information
Supplementary information accompanies this paper at https://doi.org/10.1038/s41598-018-38246-3.
Competing Interests: The authors declare no competing interests.
Publisherâ€™s note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and 
institutional affiliations.
Open Access This article is licensed under a Creative Commons Attribution 4.0 International 
License, which permits use, sharing, adaptation, distribution and reproduction in any medium or 
format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Cre-
ative Commons license, and indicate if changes were made. The images or other third party material in this 
article are included in the articleâ€™s Creative Commons license, unless indicated otherwise in a credit line to the 
material. If material is not included in the articleâ€™s Creative Commons license and your intended use is not per-
mitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the 
copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
 
Â© The Author(s) 2019

