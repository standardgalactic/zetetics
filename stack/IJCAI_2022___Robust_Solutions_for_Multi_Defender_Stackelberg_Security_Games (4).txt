Robust Solutions for Multi-Defender Stackelberg
Security Games*
Dolev Mutzari Yonatan Aumann Sarit Kraus
Department of Computer Science, Bar Ilan University, Ramat Gan,
Israel
dolevmu@gmail.com, aumann@cs.biu.ac.il, sarit@cs.biu.ac.il
Abstract
Multi-defender Stackelberg Security Games (MSSG) have recently gained in-
creasing attention in the literature. However, the solutions offered to date are
highly sensitive, wherein even small perturbations in the attacker’s utility or slight
uncertainties thereof can dramatically change the defenders’ resulting payoffs and
alter the equilibrium. In this paper, we introduce a robust model for MSSGs,
which admits solutions that are resistant to small perturbations or uncertainties
in the game’s parameters. First, we formally define the notion of robustness, as
well as the robust MSSG model. Then, for the non-cooperative setting, we prove
the existence of a robust approximate equilibrium in any such game, and provide
an efficient construction thereof. For the cooperative setting, we show that any
such game admits a robust approximate α-core, provide an efficient construction
thereof, and prove that stronger types of the core may be empty. Interestingly, the
robust solutions can substantially increase the defenders’ utilities over those of the
non-robust ones.
1
Introduction
Stackelberg Security Games (SSGs) have attracted much attention in multi-agent com-
munity [Paruchuri et al., 2008b, Tambe, 2011, Nguyen et al., 2013, An and Tambe, 2017].
They were applied to a variety of security problems, including the allocation of secu-
rity resources at the Los Angeles International Airport [Pita et al., 2008], and protect-
ing biodiversity in conservation areas [Basak et al., 2016] (see [Sinha et al., 2018] for
an overview). The original SSG model postulates a single defender facing a single at-
tacker. In many applications, however, different targets may be valuable — to varying
extents — to multiple disparate parties, each of which is interested in defending its tar-
gets of interest. Accordingly, the model of Multi-defender Stackelberg Security Games
*This research has been partly supported by the Israel Science Foundation under grant 1958/20 and the
EU Project TAILOR under grant 952215.
1

(MSSGs), wherein multiple defenders (leaders) protect a set of targets against a strate-
gic attacker (follower) who is their common enemy, has recently gained increasing
attention. Solution concepts for this game were developed over time, starting from ζ-
Nash Equilibrium (NE) [Gan et al., 2018], coordination mechanism [Gan et al., 2020],
coalition formation [Mutzari et al., 2021] and correlated equilibrium (CE) via negotia-
tion [Castiglioni et al., 2021].
However, for reasons we will detail shortly, to date, the solutions offered for MSSGs
are highly sensitive, wherein small perturbations in the attacker’s utility, or slight un-
certainties thereof, can dramatically alter the defenders’ resulting payoffs and alter the
equilibrium.
Tie-Breaking and Discontinuity.
The key, and somewhat subtle, reason for the high
sensitivity of the previous solutions has to do with the issue of tie-breaking. Typically,
in SSGs, at equilibrium, the attacker has several equally attractive targets. Indeed,
otherwise the defender(s) could shift resources from the overly protected targets to
increase the protection of the attacker’s chosen target. So, as ties are ubiquitous, the
attacker’s tie-breaking behaviour plays a crucial role in the analysis. Different works
have considered different tie-breaking policies. In the case of a single defender, it is
commonly assumed that the attacker breaks ties in favor of the defender, the reason
being that the defender can essentially enforce his choice by shifting an arbitrarily
small amount of resources away from his desirable target, absorbing only an arbitrarily
small utility loss.
In the case of multiple heterogeneous defenders, however, optimistic tie-breaking
is not well-defined (and not justified), as the best target for each defender may be differ-
ent. Hence, [Gan et al., 2018] use pessimistic tie-breaking, wherein each defender acts
as if (among its choices) the attacker will attack the target that is worst for the defender.
So, different defenders act as if the attacker, deterministically, attacks a different tar-
get. This tie-breaking rule, however, is not only overly pessimistic and unrealistic (as
the attacker cannot simultaneously attack multiple targets), but also results in a sharp
non-continuity in the defenders’ payoffs. This is because the pessimistic tie-breaking
occurs only at the point of exactly identical utilities (of the attacker) for the disparate
targets. If the attacker’s utility is slightly perturbed (or if there is even a slight uncer-
tainty with regards to the attacker’s true utilities), then the pessimistic tie-breaking is
no longer relevant and the defenders’ payoff may change dramatically. This disconti-
nuity in payoff, in turn, shapes the structure of the solution concepts, which also tend
to exhibit a discontinuity at the exact equilibrium point. Indeed, this sensitivity, and
discontinuity, is the core reason why, in the existing MSSG models, exact-NE need not
exist (see Example D.3).
In practice, however, such sharp discontinuity is often hard to justify. Indeed, while
it is standard in game theory to assume that players’ utilities are common knowledge,
it is unrealistic to assume that these utilities are known accurately to any level of pre-
cision. Evidently, the defenders must somehow infer the attacker’s utilities using some
combination of data and reasoning, but this data (and reasoning) may be incomplete,
imprecise, or noisy. Additionally, the attacker itself may have bounded computational
resources, or be subject to other forms of noise, and thus not operate exactly as dictated
2

by infinite precision calculations. Finally, the attacker’s strategy is also determined by
its knowledge/belief of the defender’s coverage strategies, which the attacker needs to
somehow infer from possibly incomplete and noisy data.
Robustness in MSSGs.
Accordingly, as detailed in the related work, in the single
defender setting, a whole line of research is devoted to addressing uncertainties (see
[Nguyen et al., 2014]). Most of these papers tackle uncertainty by applying robust opti-
mization techniques ([Pita et al., 2009, Jiang et al., 2013, Qian et al., 2015, Nguyen et al., 2014]).
Some works consider a Bayesian approach [Kiekintveld et al., 2011, Yin and Tambe, 2012,
Yang et al., 2012, Amin et al., 2016]. We believe, however, that this avenue is ill-suited
for the multi-defender setting, with its tie-breaking subtlety. Robust optimization takes
a worst-case approach: if some parameters are only known to lay within some set, then
one assumes — pessimistically — that these parameters obtain values that minimize
the objective function. In the multi-defender setting, however, there is no one worst
case; the worst-case for one defender may well be good for another. So, worst-case
robustness is not well defined in this setting. We note that one could possibly pro-
pose a multi-player worst case analysis wherein each defender acts as if the parameters
are worst for itself. But, coupled with pessimistic tie-breaking, this would result in
an unreasonably, doubly pessimistic and unrealistic perspective, wherein different de-
fenders postulate attackers with different parameters, attacking different targets; as if
they inhabit parallel universes. The multi-defender setting therefore calls for a different
approach.
Our Contribution.
In this paper, we offer a robust model for the analysis of MSSGs.
First, we formally define the notion of a robust solution, which formalizes the notion
that the game solutions (e.g. Nash equilibrium, core) remain valid even after small
perturbations or uncertainties in the game’s parameters. We then introduce a formal
model wherein small perturbations in the attacker’s utility result in only small changes
in the attacker’s expected behavior, and hence also in that of the defenders. Essentially,
we model the attacker’s behavior as being probabilistic, with a continuous distribution
concentrated around the behavior dictated by the presumed (and possibly inaccurate)
utility. Importantly, we do not suppose any specific form for this distribution, only that
it is concentrated as stated. Thus, this one model captures and unifies many possible
scenarios and sources of noise and uncertainty.
Once we have formally defined the notions of robustness and the robust MSSG
model, we show that the robust model indeed offers robust solutions. For the non-
cooperative setting, we provide an efficient algorithm for constructing a robust approx-
imate NE. For the cooperative setting, we consider the core of the game, for different
variants of the core (α, γ). For the α version, we prove that the robust approximate
core is always non-empty, and give an efficient algorithm for finding solutions therein.
Importantly, since the utility of the defenders is no longer determined by their pes-
simistic beliefs, the resulting core solutions allow greater utility for the defenders than
in previous models. Finally, we show that the γ-core may be empty.
We note that an additional benefit of the model, besides robustness, is that it renders
moot the entire issue of tie-breaking — optimistic or pessimistic. With a continuous
3

probability distribution, there is zero probability for ties.
Selected Related Work.
Robust analysis of the single-defender case has attracted
considerable attention. Many of these employ robust optimization techniques to ad-
dress uncertainties, while others model uncertainties using Bayesian models. Robust
optimization is employed by: [Kiekintveld et al., 2013] in a setting where the attacker’s
utilities are known to lay in some interval, but the exact value is not known; and by
[Pita et al., 2009] is a settings wherein the attacker may exhibit bounded rationality; by
[Jiang et al., 2013] in a setting wherein the attacker’s type is only known to be mono-
tone. [Qian et al., 2015] consider a worst-case approach for studying risk-averse at-
tackers, for which the level of risk-adverseness is unknown. Finally, [Nguyen et al., 2014]
offer a unified framework and methods for simultaneously addressing multiple types
of uncertainties in single defender SSGs using robust optimization. As detailed in the
introduction, we argue that the worst-case approach of robust optimization is ill-suited
for the multi-defender setting, wherein there is no one worst-case for all defenders.
Other works, still in the single defender setting, employ a Bayesian approach to
address uncertainties (as we do for the multi-defender setting). A general analysis of a
single defender Bayesian SSG was introduced in [Paruchuri et al., 2008a]. [Kiekintveld et al., 2011]
study Bayesian SSGs with a continuous payoff distribution for the attacker. They
demonstrate scenarios where there are too many possible attacker types to consider, and
known solutions for a finite number of attacker types don’t scale well. [Yin and Tambe, 2012]
provide a unified Bayesian approach to handling both discrete and continuous uncer-
tainty in attacker types. [Yang et al., 2012] model human adversaries with bounded
rationality as quantal response adversaries, which with some probability do not choose
the best response. They specifically assume that the attacker’s strategy is determined
by a scaled soft-max function of the expected utilities of the attacker on each target,
and utilize the specific structure of the soft-max function to obtain a solution for the
setting (see also [Amin et al., 2016], who consider general SGs).
Our work differs from all of the above in that it considers the multi-defender case.
The Bayesian modeling we introduce is also different. On the one hand, unlike the un-
restricted, general Bayesian models (e.g. [Paruchuri et al., 2008a, Kiekintveld et al., 2011,
Yin and Tambe, 2012]), [Paruchuri et al., 2008a, Yin and Tambe, 2012]), we assume a
concentrated distribution (Definition 3.2). This, we believe, adequately models most
frequent sources of uncertainty, including noisy and imprecise information, bounded
computation power, and most incarnations of bounded rationality. On the other hand,
we do not suppose any specific form for this concentrated distribution (e.g. soft-max),
as such an assumption would fail to model many real-world uncertainties.
2
Defining Robustness
The main objective of this work is to develop a robust MSSG framework. We now
formally define the notion of robustness. We deliberately do so in the most general
terms, not confining the definition to the specific game, or solution concepts that we
consider. We later show how the model we offer indeed exhibits robustness as defined
here.
4

Solution Concepts.
Consider the Nash equilibrium solution concept. Technically,
given a game G, there is a set NE(G) of strategy profiles for which the NE property
holds. Similarly, the core of G is a set of coalition structures core(G), for which the
core properties hold. Thus, in the most general sense, a solution concept is a function
X from the set of games (of some class) to some space S, which maps each game G (of
the class) to the corresponding structures for which the specific property of the solution
concept holds.
Nearness.
Conceptually, robustness of a solution x states that x remains a solution
even under “small” perturbations in game parameters. This requires a notion of dis-
tance amongst games. Given a distance function d(·, ·) over game pairs, say that games
G, ˆG are η-near if d(G, ˆG) ≤η (later, d will be instantiated based on the MSSG’s spe-
cific parameters).
Definition 2.1 (Robust Solution). Let X be a solution concept, G a game, and x ∈
X(G). We say that x is an η-robust X of G, if x ∈X( ˆG) for any ˆG that is η-near to G.
Thus, for example, a strategy profile x is said to be an η-robust ϵ-NE of G if it is an
ϵ-NE of any ˆG that is η-near to G (G itself included).
3
The Robust MSSG Model
The Standard model.
In an MSSG, there is a set N = {1, . . . , n} of defenders, a
set T = {t1, . . . , tm} of targets that the defenders wish to protect, and an attacker,
who seeks to attack the targets. Each defender i ∈N has ki ∈N security resources,
each of which can be allocated to protect a target. The attacker chooses one target to
attack. The attack is successful if the target is unprotected by any security resource. A
successful (res. unsuccessful) attack at t yields utility ra(t) (res. pa(t)) to the attacker
and pd
i (t) (res. rd
i (t)) to defender i, for all i (rd
i (t) > pd
i (t), ra(t) > pa(t)).
An MSSG is thus a 5-tuple G = (N, T , K, R, P), where K = (k1, . . . , kn) are
the numbers of security resources of the defenders, R is the sequence of rewards, R =
(ra(t1), . . . , ra(tm), rd
1(t1), . . . , rd
n(tm)), and similarly P is the sequence of penalties.
The defenders’ allocation of security resources to the targets may be randomized.
Specifically, each defender i chooses a coverage vector xi ∈Cki (where Ck = {x ∈
[0, 1]m| P xt ≤k}). Here, xi,t is the probability that target t is protected by one of
defender i’s security resources.1 We denote by X = (xi)i∈N .
If the defenders are uncoordinated, the probability that target t ∈T is protected is
ct = covt(X) = 1 −Q
i∈N (1 −xi,t).
The overall coverage vector c = (ct)t∈T is assumed to be known to the attacker, which
chooses its action after the defenders have committed to their distribution. Thus, the
1Provably, any such coverage vector can be implemented by a distribution over deterministic allocation
strategies, each employing at most k resources.
5

attacker and defenders’ utilities upon an attack at t are:
U a(c, t) = U a(ct, t) = (1 −ct) · ra(t) + ct · pa(t)
(1)
U d
i (c, t) = U d
i (ct, t) = ct · rd
i (t) + (1 −ct) · pd
i (t)
(2)
In the classic (non-robust) model, all players are assumed to be rational. As such, the
attacker’s best response is to attack a target in the set BR(c) := arg maxt∈T U a(c, t),
which maximizes its expected utility. However, as discussed in the introduction, BR(c)
typically consists of multiple targets, which brings about the issues of tie-breaking and
discontinuity.
The Robust Model.
The non-robustness of the standard MSSG model arises from
the assumption of exact deterministic behavior of the attacker, whereby it always plays
the exact optimal play, even if the difference between the optimal play and the next
in line is minuscule. Therefore, small changes in the attacker’s utility function may
lead to abrupt changes in the attacker’s strategy, in turn causing abrupt changes in the
defender’s utilities. Accordingly, to obtain a robust model, we model the attacker’s
behavior as being probabilistic, with a continuous distribution concentrated around the
deterministic behavior dictated by the presumed (possibly inaccurate) utility. Impor-
tantly, we seek a general model which can capture the multitude of possible reasons for
the mentioned perturbations. The formal details follow.
Given a coverage vector c, and the resultant attacker’s utility vector u = u(c) =
(U a(c, t))t∈T (over the different targets), the attacker’s actual behavior is assumed to
be determined by a probability distribution ω(u) ∈[0, 1]m, specifying the probability
that the attacker will actually attack each target. The function ω is termed the Attacker’s
Behavior Function, and is assumed to have the following properties:
Definition 3.1 (Attacker’s Behaviour Function (ABF)). A continuously differen-
tiable function ω : Rm
+ →Rm
+ is an attacker’s behaviour function if the following
axioms hold:
1. ω(u) is a probability distribution.
2. ω is monotone increasing at each coordinate.
3. For each ∅̸= S ⊆T and t ∈S :
ωt(u)
P
t′∈S ωt′(u) is independent of any ut′, t′ ̸∈S.
Axiom 3 states that, given that the attack is within the set S, the conditional prob-
ability of an attack on any specific target t ∈S is only determined by the inter-
relationships between the utilities of targets within S.
Thus, given a coverage vector c, inducing attacker utilities u(c), and ABF ω, de-
fender i’s expected utility is given by:
U d
i (c) =
X
t∈T
U d
i (c, t)ωt(u(c))
(3)
The following definition provides that the attacker’s behavior is centered around the
optimal deterministic one.
6

Definition 3.2 ((δ, ϵ)-ABF). Let G be an (M)SSG, and δ, ϵ > 0. An ABF ω is a
(δ, ϵ)-ABF if:
ut′ < ut −δ ⇒ωt′(u) < ϵ
(4)
Thus, with a (δ, ϵ)-ABF, any target offering a utility δ less than the optimal one will
be attacked with probability < ϵ. In Appendix D.1, we show that one example of an
ABF is the softmax function σ(x), and that for any δ, ϵ, there exists a constant d, such
that σ(d·) is a (δ, ϵ)-ABF.
We believe this (δ, ϵ)-ABF formulation captures, under one unifying definition, the
many possible sources for noise and uncertainty in the attacker’s utility, as discussed in
the introduction. With these definitions, a robust MSSG is a pair G = ⟨G, ω⟩, where G
is a MSSG and ω is a (δ, ϵ)-ABF.2
4
Solution Concepts
For completeness, we review the MSSG solution concepts, as defined in previous
works. Throughout, we consider the approximate versions.
ζ-Nash Equilibrium.
Given the players’ utility functions, the definitions of approx-
imate NE is standard:
Definition 4.1 (ζ-Nash Equilibrium). A strategy profile X = (xi)i∈N is an ζ-NE if
for any defender i ∈N and any strategy x′
i of i:
U d
i (cov(X)) ≥U d
i (cov(⟨x′
i, X−i⟩)) −ζ.
(5)
Coalitions.
When the defenders are uncoordinated, independent choices may result
in inefficient resource use. Therefore, [Mutzari et al., 2021] consider a model for coali-
tion formation in MSSG, which we adopt. Any subset P ⊆N of defenders may form
a coalition, in which case they act as a single defender with kP = P
i∈P ki resources.
The coalition consisting of all of the defenders is called the grand coalition.
Coalitions partition the set of defenders: N = {P1, . . . , Pℓ}. Each coalition Pi
chooses a coverage vector xj ∈CkPj }. Denoting X = (x1, . . . , xℓ), the probability
that target t is protected is:
ct = covt(X) := 1 −Qℓ
i=1 (1 −xi,t) .
(6)
Given a strategy profile X and a target t, the defenders’ utilities are defined in the same
way as in (3). A coalition structure is any such pair CS⟨P, X⟩.
Since CS includes a coverage vector X that (by (6)) induces the overall coverage
vector cov(X), for notational simplicity, the players’ utilities can be viewed as a func-
tion of the coalition structure, which we simply denote U d
i (CS).
2We note that inevitably the proper values for δ, ϵ are dependent on G. The reason is that δ must be small
compared to the attacker’s utilities, thus must be scaled in accordance, and ϵ must depend on the number of
targets as it has to be small relative to 1/m.
7

Deviations.
Given a coalition structure CS, a subset of defenders may choose to de-
viate and form a new coalition. In such a case, one must define the strategy played by all
defenders. Following [Moulin and Peleg, 1982, Chalkiadakis et al., 2011, Shapley, 1973],
the assumption is that in order to protect the status quo, the remaining defenders take
revenge against the deviators, employing a strategy that makes at least one not gain
by the deviation. It is assumed that this revenge strategy is chosen after the deviators
choose their strategy. The deviation is successful if no such revenge is possible.
Definition 4.2 (ζ-successful deviation). A deviation (D, xD) from a coalition struc-
ture CS is ζ-successful if for any deviator i ∈D and for any revenge strategy xR,
U d
i (cov(⟨xD, xR⟩)) > U d
i (cov(CS)) + ζ.
Definition 4.3 (ζ-approximate core). A coalition structure CS is in the ζ-approximate
α-core if it admits no ζ-approximate successful deviation.
So, in the ζ-approximate core, a deviation cannot add more than ζ to the utility of
at least one of the deviation’s members.
5
The Robustness Theorem
We now provide the central robustness theorem, which essentially states that in the
robust MSSG model, any approximate-NE or approximate-core automatically trans-
lates to their respective robust counterparts. We note that, technically, the theorem
essentially follows directly from the continuity of ω, but the result is exactly what is
necessary.
First, recall that the definition of a robust solution (Definition 2.1) requires a dis-
tance function between games. In MSSG, for G = (N, T , K, R, P), ˆG = (N, T , K, ˆR, ˆP),
and G = (G, ω), ˆG = ( ˆG, ˆω), we define:
d(G, ˆG) =
max{∥R −ˆR∥∞, ∥P −ˆP∥∞, ∥ω −ˆω∥∞}
The following lemma bounds the change in utility arising from small changes in the
game parameters.
Lemma 5.1. Let G be a robust MSSG and let η > 0. Then there exists a constant b
such that, for any coverage vector c and any game ˆG η-near to G, the following holds:
| ˆU d
i (c) −U d
i (c)| ≤b
2η,
where ˆU d
i (c), U d
i (c) are the utilities of defender i in games ˆG, G respectively.
The proof, which essentially follows from the continuity of the ABF is provided in
the Appendix A.
Theorem 5.2. Let G be a MSSG. With b of Lemma 5.1, for any η:
1. any ζ-NE of G is also an η-robust (ζ + bη)-NE of G.
8

2. any ζ core of G is also an η-robust (ζ + bη)-core of G (for all three variants of
the core α, β, γ).
Proof. We prove (1), and the proof of (2) is analogous. Let X be a ζ-NE of G, and ˆG
η-near to G. Then, for any possible x′
i of player i
ˆU d
i (cov(⟨x′
i, X−i⟩)) ≥U d
i (cov(⟨x′
i, X−i⟩)) −bη/2
(7)
≥U d
i (cov(⟨xi, X−i⟩)) −ζ −bη/2
(8)
≥ˆU d
i (cov(⟨xi, X−i⟩)) −ζ −bη
(9)
where we use Lemma 5.1 for (7) and (9), and (8) follows by the definition of ζ-NE.
Accordingly, in order to find robust solutions in our model it suffices to find regular
solutions in the model, and robustness then follows automatically. The remainder of
the paper is thus dedicated to finding such solutions.
6
Nash Equilibrium in Robust MSSGs
We now show how to compute an approximate NE in robust MSSGs. For simplicity,
we restrict the discussion to non-saturated games. A robust MSSG G is α-saturated
if there exists a coverage c ∈CkN and t ∈T s.t. ct ≥1 −α and ωt(c) ≥ϵ. In a
saturated game, there are sufficient resources to induce an attack that is almost surely
caught. The results can be extended to saturated games using a similar approach to the
one used by [Gan et al., 2018].
Theorem 6.1. There exists a polynomial algorithm, such that for any G there exist
A, B, C, ϵ0, δ0 s.t. for any (δ, ϵ)-ABF ω with ϵ < ϵ0, δ < δ0, on input (G, ω) the
algorithm outputs a strategy profile X that is a ζ-NE, for ζ = Bδ + Cϵ (provided
(G, ω) is not Aδ-saturated).
The exact constants, together with a detailed proof, appear in the Appendix B. The
proof builds upon the techniques of [Gan et al., 2018], but requires significant adapta-
tions for our setting. For simplicity, in the main body of the paper we consider the case
where all targets carry identical penalties and identical rewards for the attacker (but not
the defenders). This case allows us to explain the core elements of the construction
and the proof, while avoiding the technicalities. Note that in the explanation we do not
seek to obtain the best constants. Better bounds are offered in the complete proof.
For the case we are considering, we can further normalize the attacker’s utilities so
that pa(t) = 0 and ra(t) = 1 for all t. With this assumption, U a(c, t) = 1 −ct, for all
c, t.
The core procedure underlying the algorithm is ALLOC (Algorithm 1). ALLOC
gets as input a parameter c, and aims to have ct = c, for all targets. To this end, the
defenders — one by one in order — iterate through the targets, allocating resources
until either (i) the c level is reached, or (ii) their resources are fully depleted. This
allocation is performed in Line 4, where xi,t = 1−1−c
1−ct brings the coverage to exactly
c, and xi,t = ki depletes the defender’s resources. Importantly, each defender considers
9

Algorithm 1 ALLOC
Input: value c, ˜c ∈[0, 1], G = (N, T , K, P, R)
Output: a strategy profile X = (xi,t)
1: ct ←0, for all t
2: for i ∈N do
3:
for t ∈T by reverse ⪯˜c
i precedence order do
4:
xi,t ←min{1 −1−c
1−ct , ki}
5:
ki ←ki −xi,t
6:
ct ←1 −(1 −ct)(1 −xi,t);
the targets in reverse preference order of its expected utility from the target, assuming
some identical coverage level ˜c (with ˜c possibly different from c) . Specifically, for
targets t, t′, we denote t ⪯˜c
i t′ if U d
i (˜c, t) ≤U d
i (˜c, t′). In ALLOC, defenders iterate
through the targets from the least to the highest in the ⪯˜c
i order.
Clearly, the actual coverage level obtained by ALLOC is determined by c: if c is
too small then ALLOC may complete without depleting the defenders’ resources, and
if c is too big then some targets my have ct < c. However, there exists a ¯c for which the
algorithm completes with ct = ¯c for all targets (assuming the game is non-saturated).
This ¯c can be approximated to within any level of accuracy by binary search, with
multiple runs of ALLOC. Set β = (1 −¯c)/2.
Set ˇc = ¯c + mδ/β. For δ sufficiently small, ˇc < 1 −β. Consider the outcome
of running ALLOC with c = ˇc and ˜c = ¯c. Let ˆX be the resultant allocation, and for
each t, let ˆct be the resultant coverage of target t. Since ˇc > ¯c, there will necessarily
be targets t for which ˆct < ¯c, but for δ sufficiently small there will be only one such
target. Denote this target t∗. For all other t’s, ˆct = ˇc.
We now argue that ˆX is a ζ-NE for ζ = Bδ + Cϵ, for some constants B, C depen-
dant only on G.
In the following, we focus on the attacker’s behavior occurring with probability
≥ϵ. For ease of exposition, we say that an event is likely if it happens with probability
≥ϵ.
If all defenders play by ˆX then an attack is only likely at t∗. This is since ˆct −ˆct∗≥
δ, and hence ˆut∗−ˆut ≥δ, for all t, and ω is a (δ, ϵ)-ABF. Consider a deviation of
defender i, and let c′ be the coverage vector resulted from this deviation. We now
explain why c′ cannot “substantially” increase the utility of i. Let: L be the targets -
aside from t∗to which i allocated resources, L+ = L ∪{t∗}, and H = T \ L+. We
consider what c′ can do to attacks on H, L and t∗.
Attacks on H.
We argue that under c′ the attacker is unlikely to attack any target of
H. The reason is that since i did not allocate resources to H, the only way that it can
induce an attack on H is by increasing the coverage of all targets in L+ to ˇc + δ. But,
since ct∗< ¯c = ˇc −mδ/β, bringing t∗’s coverage to ˇc + δ can only be accomplished
by taking coverage from the members of L. In doing so, at least one will result with
coverage less than ˇc −δ (the value of ˇc was so chosen).
10

Attacks on L.
A deviation can induce attacks on L. However, it cannot provide i
substantially more than it originally obtained, where substantially means adding more
than δB utility. The reason is that since t∗is not ˇc covered, it must be that t∗was
considered by i after all elements of L - or else i would either bring t∗’s coverage to ˇc
or fully deplete its resources. So, t ⪯¯c
i t∗, for all t ∈L. This means that - at coverage
level ¯c - attacks on targets of L offer i no more utility than attacks on t∗. So, if ¯c where
the coverage, then inducing an attack on L would offer no gain to i. In practice, the
elements of c′ and ˆc are not exactly ¯c, but they are O(δ) away. So, since U d
i (c, t) is
linear in c, the differences in utility can also be only O(δ). So attacks on L cannot offer
substantially more utility than what t∗initially offered.
Attack on t∗.
A deviation can also possibly increase the coverage of t∗, thus offering
more utility if and when attacked. However, one can only add O(δ) coverage (while
keeping an attack on t∗likely), so that this addition cannot add more than O(δ) utility.
Putting It All Together.
We obtain that with probability 1 −ϵ the added utility due
to the deviation is at most δB, for some constant B. With probability ϵ the increase
can be larger, but clearly bounded by C = maxj,t rd
j (t). So, the utility increase is
bounded by ζ = δB + ϵC. This completes the construction of ζ-NE. By Theorem 5.2,
this strategy is also an η-robust (ζ + bη)-NE, for any η.
7
The Robust Core
In this section we explain the algorithm to construct a robust ζ-approximate α-core.
Importantly, we only outline the construction and proof ideas. Full details appear in
Appendix C.
Resistance to Subset Deviations.
With minor adaptations, the ALLOC procedure
can be applied to the cooperative setting (wherein probabilities are additive rather than
multiplicative). Also, the procedure can easily be configured to accept a target utility
level u as input (rather than target coverage c) - see Algorithm 4. As before, repeated
calls to ALLOC allow us to find a ¯u and strategy ¯X such that all targets offer utility ¯u
to the attacker (except for those with ra(t) < ¯u), using all resources. Next, we re-run
ALLOC with ˇu = ¯u −mO(δ). Let ˆX be the resulted strategy profile, ˆc = cov( ˆX),
and t∗the target not covered to ˇu. Then, U a(ˆc, t∗) > ¯u + δ and U a(ˆc, t) = ˇu for all
other t. So, the attacker is only likely to attack t∗.
We argue that ˆX is resilient to any deviation xD of any proper subset D ⊂N of
defenders. Set c′ = cov( ˆX−D, xD). Let L be the targets, aside from t∗, to which D
allocated resources in ˆX, and L+ = L ∪{t∗}. Then, analogously to the NE case, no
deviation of D can induce a likely attack outside L ∪{t∗}. They may, however, be
able to alter the attack probabilities within L+. Let A be the targets that are likely to
be attacked under xD. So, |U a(c′, ti) −U a(c′, tj)| < δ, for any ti, tj ∈A. Now,
recall that given D and xD, the remaining defenders - ¯D - can change their strategy.
So, using only O(δ) resources per target, ¯D can raise the coverage of all but one target
11

of t0 ∈A, so that t0 offers at least δ more utility than all other targets. Since t0 ∈L+,
there exists at least one i ∈D for which t0 ⪯cov(X)
i
t∗. So, for this i, the deviation
does not offer any (substantial) gain.
Resistance to Grand Coalition Deviations.
We now show how transform the above
strategy to one resistant to grand coalition deviations. Let ˆud
i be the utility of defender
i under ˆX. Consider the following linear program (with variables pt):
max
X
t∈T
X
i∈N
pt · U d
i (ˆc, t)
s.t.
X
t∈T
pt · U d
i (ˆc, t) ≥ˆud
i ,
i = 1, . . . , n
X
t∈T
pt = 1; pt ≥0,
t = 1, . . . , m
Let p∗= (p∗
t )m
t=1 the solution provided by the programs (there necessarily exists a
solution, since p = ω(u(ˆc)) is a feasible one). The following proposition (proved in
Appendix C.3) provides that with small changes to ¯u = (¯u, . . . , ¯u) the distribution p∗
can (essentially) be induced.
Proposition 7.1. For any probability distribution p and any u > 0, there exists a utility
vector u s.t. ∥ω(u) −p∥∞< m2ϵ , and u ≤ut < u + 2mδ for all t ∈T .
Let ¯u∗be the utility vector provided by invoking Proposition 7.1 with u = ¯u and
p = p∗. Since ¯u is implementable (by ¯X) and ¯u∗
t ≥¯u for all t, then ¯u∗is also
implementable, by some strategy ¯X∗. We now argue that ¯X∗is an the ζ-approximate
α-core, for ζ = Aϵ + Bδ (for some constants A, B fully determined in the full proof).
In the following arguments, interpret all statements “up to at most ζ gains”.
To see that ¯X∗resists grand coalition deviations, first note that we may assume that
in any such deviation X′, all elements of u′ = u(cov(X′)) are close (within O(δ)) to
¯u. Otherwise, there must be targets that are more than δ apart in their utility, in which
case it is possible to shift resources from the those with lesser u′
t to the higher ones,
without substantially changing the attack distribution (by Proposition 7.1). Now, any
target where u′
t > ¯u is not substantially better for any deviator, and any target where
u′
t < ¯u −δ is not likely to be attacked. By construction, p∗maximizes the sum of
defender utilities, subject to each getting at least as in ˆX. So, it is impossible that all
defenders simultaneously get even more.
For subset deviations, consider D ⊂N and suppose they have a deviation xD that
guarantees all members of D more than in ¯X∗(regardless of how the others play). But
¯X∗offers essentially as much as the output of the linear program, which, by its con-
straints, offers each defender as much as ˆX. So, xD would also constitute a successful
deviation from ˆX, which we proved cannot be. We thus obtain:
Theorem 7.2. There exists a polynomial algorithm, such that for any G there exist
A, B, C, ϵ0, δ0 s.t. for any (δ, ϵ)-ABF ω with ϵ < ϵ0, δ < δ0, on input (G, ω) the
algorithm outputs a strategy profile X that is a ζ-approximate α-core, for ζ = Bδ+Cϵ
(provided that (G, ω) is not Aδ-saturated).
12

By Theorem 5.2, for any η > 0, any such solution is also an η-robust (ζ + bη)-
approximate α-core.
γ-Core.
Unlike the α-core, the approximate γ-core (see [Chander, 2010], Defini-
tion D.6) may be empty.
Player
t1
t2
t3
t4
t5
t6
k
Defender 1,2
1, 0
1, 0
1, 0
6, 5
6, 5
6, 5
1
Defender 3,4
6, 5
6, 5
6, 5
1, 0
1, 0
1, 0
1
Attacker
1, 0
1, 0
1, 0
1, 0
1, 0
1, 0
–
Table 1: Example of a MSSG where the approximate γ-core is empty
Basically, defenders 1, 2 can always γ-deviate and get a utility ≥4 each, as can
defenders 3, 4, but no coalition structure can yield all defenders ≥4 utility. See a full
explanation in Appendix D.7.
References
[Amin et al., 2016] K. Amin, S. Singh, and M. P Wellman.
Gradient methods for
stackelberg security games. In Proc. of UAI, pages 2–11, 2016.
[An and Tambe, 2017] B. An and M. Tambe. Stackelberg Security Games (SSG) Ba-
sics and Application Overview, pages 485–507. Cambridge U. Press, 2017.
[Basak et al., 2016] A. Basak, F. Fang, T. H. Nguyen, and C. Kiekintveld. Abstraction
methods for solving graph-based security games. In AAMAS, pages 13–33, 2016.
[Castiglioni et al., 2021] M. Castiglioni, A. Marchesi, and N. Gatti. Committing to
correlated strategies with multiple leaders.
Artificial Intelligence, page 103549,
2021.
[Chalkiadakis et al., 2011] G. Chalkiadakis, E. Elkind, and M. Wooldridge. Compu-
tational aspects of cooperative game theory. Synthesis Lectures on AI and ML, 5(6),
2011.
[Chander and Tulkens, 2006] Parkash Chander and Henry Tulkens. Cooperation, sta-
bility and self-enforcement in international environmental agreements: a conceptual
discussion. Technical report, AgEcon Search, 2006.
[Chander, 2007] Parkash Chander. The gamma-core and coalition formation. Interna-
tional Journal of Game Theory, 35(4):539–556, 2007.
[Chander, 2010] Parkash Chander. Cores of games with positive externalities. CORE
DP, 4:2010, 2010.
[Gan et al., 2018] J. Gan, E. Elkind, and M. Wooldridge. Stackelberg security games
with multiple uncoordinated defenders. In AAMAS. ACM Press, 2018.
13

[Gan et al., 2020] J. Gan, E. Elkind, S. Kraus, and Mi. Wooldridge. Mechanism design
for defense coordination in security games. In AAMAS, pages 402–410, 2020.
[Jiang et al., 2013] A. X. Jiang, Thanh H. Nguyen, M. Tambe, and A. D Procaccia.
Monotonic maximin: A robust stackelberg solution against boundedly rational fol-
lowers. In Sajal K. Das, Cristina Nita-Rotaru, and Murat Kantarcioglu, editors,
Decision and Game Theory for Security, pages 119–139, 2013.
[Kiekintveld et al., 2011] C. Kiekintveld, J. Marecki, and M. Tambe. Approximation
methods for infinite bayesian stackelberg games: Modeling distributional payoff
uncertainty. In AAMAS, pages 1005–1012, 2011.
[Kiekintveld et al., 2013] C. Kiekintveld, T. Islam, and Vl. Kreinovich.
Security
games with interval uncertainty. In AAMAS, page 231–238, 2013.
[Moulin and Peleg, 1982] H Moulin and B Peleg. Cores of effectivity functions and
implementation theory. Journal of Mathematical Economics, 10(1):115 – 145, 1982.
[Mutzari et al., 2021] D. Mutzari, J. Gan, and S. Kraus. Coalition formation in multi-
defender security games. In AAAI, volume 35, pages 5603–5610, 2021.
[Nguyen et al., 2013] Thanh Hong Nguyen, Rong Yang, Amos Azaria, Sarit Kraus,
and Milind Tambe. Analyzing the effectiveness of adversary modeling in security
games. In AAAI, 2013.
[Nguyen et al., 2014] Thanh Hong Nguyen, Albert Xin Jiang, and Milind Tambe. Stop
the compartmentalization: unified robust algorithms for handling uncertainties in
security games. In AAMAS, pages 317–324, 2014.
[Paruchuri et al., 2008a] Praveen Paruchuri, Sarit Kraus, Jonathan P Pearce, Janusz
Marecki, Milind Tambe, and Fernando Ordonez. Playing games for security: An
efficient exact algorithm for solving bayesian stackelberg games. Proceedings of the
7th international joint conference on Autonomous agents and multiagent systems,
2008.
[Paruchuri et al., 2008b] Praveen Paruchuri, Jonathan P Pearce, Janusz Marecki,
Milind Tambe, Fernando Ordonez, and Sarit Kraus. Efficient algorithms to solve
bayesian stackelberg games for security applications. In AAAI, pages 1559–1562,
2008.
[Pita et al., 2008] James Pita, Manish Jain, Janusz Marecki, Fernando Ord´o˜nez,
Christopher Portway, Milind Tambe, Craig Western, Praveen Paruchuri, and Sarit
Kraus. Deployed armor protection: the application of a game theoretic model for
security at the los angeles international airport. In Proceedings of the 7th interna-
tional joint conference on Autonomous agents and multiagent systems: industrial
track, pages 125–132, 2008.
[Pita et al., 2009] James Pita, Manish Jain, Fernando Ord´o˜nez, Milind Tambe, Sarit
Kraus, and Reuma Magori-Cohen. Effective solutions for real-world stackelberg
games: When agents must deal with human uncertainties. In Proceedings of The 8th
14

International Conference on Autonomous Agents and Multiagent Systems - Volume
1, AAMAS ’09, page 369–376, 2009.
[Qian et al., 2015] Yundi Qian, B William, and Milind Tambe. Robust strategy against
unknown risk-averse attackers in security games. In AAMAS, pages 1341–1349,
2015.
[Shapley, 1973] Shubik Shapley. Game Theory in Economics - Chapter 6: Character-
istic Function, Core and Stable Set. RAND Corporation, 1973.
[Sinha et al., 2018] Arunesh Sinha, Fei Fang, Bo An, Christopher Kiekintveld, and
Milind Tambe. Stackelberg security games: Looking beyond a decade of success.
In Proceedings of the Twenty-Seventh International Joint Conference on Artificial
Intelligence. IJCAI, 2018.
[Tambe, 2011] Milind Tambe. Security and game theory: algorithms, deployed sys-
tems, lessons learned. Cambridge University Press, 2011.
[Yang et al., 2012] Rong Yang, Fernando Ordonez, and Milind Tambe. Computing
optimal strategy against quantal response in security games. In AAMAS, pages 847–
854, 2012.
[Yin and Tambe, 2012] Zhengyu Yin and Milind Tambe. A unified method for han-
dling discrete and continuous uncertainty in bayesian stackelberg games. In Pro-
ceedings of the 11th International Conference on Autonomous Agents and Multia-
gent Systems, AAMAS ’12, page 855–862, 2012.
15

Appendix
A
Proof of Lemma 5.1
Proof. The change of utility can be bounded, using the triangular inequality, by three
additive factors in the following manner:
| ˆU d
i (c)−ˆU d
i (c)| =
|
X
t∈T
ˆU d
i (ct, t) · ˆωt(ˆu(c)) −
X
t∈T
U d
i (ct, t) · ωt(u(c))| ≤
|
X
t∈T
ˆU d
i (ct, t)ˆωt(ˆu(c)) −
X
t∈T
U d
i (ct, t)ˆωt(ˆu(c))|
(10)
+|
X
t∈T
U d
i (ct, t)ˆωt(ˆu(c)) −
X
t∈T
U d
i (ct, t)ωt(ˆu(c))|
(11)
+|
X
t∈T
U d
i (ct, t)ωt(ˆu(c)) −
X
t∈T
U d
i (ct, t)ωt(u(c))|
(12)
Intuitively, each term corresponds to the contribution of the change defender i’s
parameters, the attacker’s behaviour function, and the attacker’s reward and penalty
parameters, to the overall change of utility.
We now bound each of (10)-(12). For (10):
X
t∈T
| ˆU d
i (ct, t) −U d
i (ct, t))| · ˆωt(ˆu(c)) ≤
X
t∈T
η ˆωt(ˆu(c)) = η
For (11):
X
t∈T U d
i (ct, t)|ˆωt(ˆu(c)) −ωt(ˆu(c))|
≤η
X
t∈T
U d
i (ct, t) ≤η
X
t∈T
rd
i (t)
For (12) we must first understand how a change in the attacker’s utility vector
alters the attack distribution of the targets. Consider ω restricted to the domain is
Q
t∈T [max(0, pa(t) −η), ra(t) + η] which is closed and bounded and therefore com-
pact. Therefore, since ω is continuously differentiable, |∇ω| is continuous and there-
fore bounded, say by some constant K (in other words, ω is K-Lipschitz continuous).3
Thus, by the mean value theorem,
∥ω(ˆu(c)) −ω(u(c))∥∞≤∥ω(ˆu(c)) −ω(u(c))∥2
≤K∥ˆu(c) −u(c)∥2
≤K√m∥ˆu(c) −u(c)∥∞
3Note that K can depend on η, but we are only interested in η, which is small relative to the game
parameters, so this is negligible.
16

Therefore, for (12):
X
t∈T
U d
i (ct, t)|ωt(ˆu(c)) −ωt(u(c))|
≤
X
t∈T
U d
i (ct, t)K√m∥ˆu(c)) −u(c))∥∞
≤
X
t∈T
U d
i (ct, t)K√mη ≤K√m
X
t∈T
rd
i (t)η
Putting it all together, we get:
| ˆU d
i (c) −ˆU d
i (c)| ≤η(1 + (1 + K√m)
X
t∈T
rd
i (t)))
B
Approximate Nash Equilibrium
In order to describe our construction in detail, we will first introduce some definitions
and notations. First, since all defenders prefer targets to be protected, we expect that in
NE the defenders would utilize all of their resources. We call such a strategy profile an
efficient strategy profile.
Definition B.1 (Efficient Strategy Profile). A strategy profile X is efficient if for each
defender i ∈N, P
t∈T xi,t = ki.
Indeed, if a strategy profile X is not efficient, then a defender can increase the cov-
erage of all targets and gain more utility. However, if a target is already fully covered,
this may not be possible. Therefore, for simplicity, in the the paper we assume that
the game is not δ/b-saturated, for b = mint∈T ra(t) −pa(t). This follows the ideas
from [Mutzari et al., 2021] (they assume the game is canonical, which is equivalent to
assuming that the game is not (0,0) saturated).
Definition B.2 (Height of a Coverage). The height of a coverage vector c ∈[0, 1]m,
denoted height(c), is the optimal attacker utility it yields, height(c) := maxt∈T U a(c, t).
Definition B.3 (Mini-Max Height). We denote the min-max attacker height by
u = min
c∈CkN
height(c) = min
c∈CkN
max
t∈T U a(c, t)
Note that in the uncoordinated case scenario, there might not exist any strategy
profile X where height(cov(X)) = u, because the lack of cooperation introduces
inefficiencies.
Lastly, we formally define the preference profile induced by a coverage vector,
which captures the heterogeneous preferences of the defenders.
17

Algorithm 2 ALLOC
Input: u, ˜u ∈(p, r);
Parameter: a canonical SSG G;
Output: a strategy profile X = ⟨xi,t⟩;
1: Set xi,t ←0, ∆t ←covt(u) and ct ←0 for all i, t;
2: for i ∈G.N do
3:
for t in G.Ji(˜u) = ti1, . . . , tim do
4:
xi,t ←min {∆t, G.ki −P
t′∈T xi,t′};
5:
ct ←1 −(1 −ct)(1 −xi,t);
6:
if ct = 1 then ∆t ←0 else ∆t ←covt(u)−ct
1−ct
;
7:
if xi,t > 0 then t∗←t;
8: return X, t∗;
Definition B.4 (Induced Preference Profile). A preference profile J induced by a cov-
erage vector c is a list of binary relations ⟨⪯J
i ⟩i∈N such that t1 ⪯J
i t2 iff U d
i (c, t1) ≤
U d
i (c, t2). For any p < u < r := maxt∈T ra(t), we define cov(u) to be the coverage
vector such that on every target t ∈T , U a(cov(u), t) = min(u, pa(t)). Overloading
notations, the preference profile induced at u is J(u) := J(cov(u)).
We are now ready to describe [Gan et al., 2018]’s procedure, ALLOC, for canon-
ical games, depicted in Algorithm 2. The algorithm gets as an input an attacker utility
value u. In a greedy fashion, each defender i in his turn allocates resources to targets
according to his induced preference profile J(u), ti1 ⪯i ti2 ⪯i · · · ⪯i tim, covering
each target so that the attacker’s utility on it gets down to u, or until he runs out of
resources.
The main observation of [Gan et al., 2018] for canonical games can be phrased as
follows: there exists an input u∗such that ALLOC(u∗) outputs an efficient strategy
profile X and cov(X) = cov(u∗). They also describe how to find u∗efficiently. We
denote by t∗the last target that is covered in ALLOC(u∗). Next, if the last target is
covered up to height u∗−Aζ for A being dependent regarding the game parameters
only, then the resulting strategy profile X is an ζ-NSE, which means it’s an ζ-NE as-
suming pessimistic defender beliefs. Provably, this works because any of the following
deviation attempts fail:
1. A defender cannot induce the attacker to attack targets to which he didn’t allocate
resources. This is because it would require him to overly cover all of the other
targets, which would require too many resources for the efficiency of X.
2. A defender can induce the attacker to attack a target he covered by reducing its
coverage, but by construction such targets give him less utility than t∗.
3. A defender can increase the coverage of the target t∗, but it is possible to choose
an A such that this will not give him > ζ utility gain.
Although using the same construction ensures that deviation attempts of type 2
and 3 still fail in our model, deviation type 1 becomes possible, since equally covered
18

Algorithm 3 CALCζ-NE
Parameter: (1) δ, ϵ > 0;
(2) a δ-canonical game G = (G, ω);
Output: a ζ-NE X = ⟨xi,t⟩, ζ;
1: right ←G.r, left ←G.p;
2: while right - left > δ2 do
3:
u ←(left + right) / 2;
4:
X, t = ALLOC(u,u);
5:
if U d
i (X, t) > u then left ←u else right ←u;
6: ζ ←G.B * ϵ + G.C * δ;
7: return ALLOC(u - G.A * δ,u), ζ;
targets can both be attacked with significant probability. The lack of pessimistic belief
forces us to make some adaptations to [Gan et al., 2018] in order to make it work (see
Algorithm 3).
B.1
Proof of Theorem 6.1
In this subsection we formally proof Theorem 6.1.
Proof. We divide into cases. Let ¯p := maxt∈T pa(t), and ¯t will be some target with
attacker penalty ¯p. In the first case, calling procedure ALLOC with input (u < ¯p+δ, ·)
gives a level coverage. In this case, increasing the attacker utility on target ¯t by δ will
make any other target be attacked with probability < ϵ, and hence ¯t is attacked with
probability ≥1 −(m −1)ϵ. This is in contradiction to the assumption that the game is
not (δ/b, ϵ)-saturated, for b = mint∈T (ra(t) −pa(t)).
Next, since cov(ALLOC(u, u)) is continuous with u, there exists some height
u∗≥¯p + δ for which X∗= ALLOC(u∗, u∗) forms a level coverage c∗= cov(X∗)
of height u∗. This means that for any target t ∈T , if u∗< pa(t) then c∗
t = 0, and
otherwise U a(c∗, t) = u∗. This u∗can easily be found using binary search up to any
fixed precision.
For the second case, denote by a = maxt∈T (ra(t) −pa(t)), and g := mint∈T (u∗−pa(t)) ≥
δ > 0. Note that g ≥δ only for this second case. Fix the following values for A, B, C:
• A := 4ma2
bg
•
B := max
i∈N (rd
i (t∗) −pd
i (t∗))·
(8ma3 P
t∈T (ra(t) −pa(t))
bg2
+ A)
• C := maxi∈N,t∈T rd
i (t∗) + maxi∈N
P
t∈T rd
i (t)
19

We also fix ϵ0 := 1/m and δ0 :=
bg2
8ma2 and assume that δ < δ0 and ϵ < ϵ0.
Consider X = ALLOC(u∗−Aδ, u∗) and denote by c = cov(X) and by u =
(U a(c, t))t∈T . We divide further into two cases, where in the first case, g > Aδ.
For δ sufficiently small, there is only a single target t∗that yields an attacker utility
greater than u∗, which is also the last target covered in ALLOC(u∗,u∗). For any other
target t, if pa(t) > u∗−Aδ then ct = 0, and otherwise ut = u∗−Aδ. We argue that
X is a ζ-NE for ζ = Bδ + Cϵ for some constants B, C depdant only on G.
Since A > 1, this means that with probability ≥1 −mϵ, target t∗is being attacked
and each defender gets a utility of U d
i (ct∗, t∗). Let i ∈N be some defender who
deviates with some strategy x′
i. Let X′ = ⟨X−i, x′
i⟩be the resulted strategy profile
and c′, u′ the resulted coverage vector and attacker utility vector respectively. Let S be
the subset of targets not covered by defender i in X, that is, t ∈S
⇐⇒xi,t = 0.
Note that BR(X) = {t∗} by construction. Also note that, the targets covered by
defender i are less favorable for him by construction at height u∗, than target t∗. That
is ∀t ̸∈S : t ⪯i t∗, meaning ∀t ̸∈S : U d
i (u∗, t) ≤U d
i (u∗, t∗).
If the target t∗is the most favorable target for defender i at height u∗, then the
maximum defender i can do is increase the coverage of target t∗while keeping the
probability the attacker will attack target t∗large. Since X is efficient, meaning utilizes
all the resources of all defenders, we know that the resulted height of X is at most
height(X) ≥u∗−Aδ, therefore we can bound the utility after such a deviation by
U d
i (cov(u∗−Aδ), t∗) + O(ϵ). Formally:
U d
i (X′) ≤U d
i (cov(u∗−Aδ), t∗) + ϵ
X
t∈T
rd
i (t)
= U d
i (X, t∗) + rd
i (t∗) −pd
i (t∗)
ra(t∗) −pa(t∗)(δ′ + Aδ) + ϵ
X
t∈T
rd
i (t)
≤U d
i (X) + max
t∈T rd
i (t)ϵ + rd
i (t∗) −pd
i (t∗)
ra(t∗) −pa(t∗)(δ′ + Aδ)
+ ϵ
X
t∈T
rd
i (t)
(13)
Where U a(X, t∗) −u∗= δ′ and the second inequality follows directly from Ax-
iom 4 because Aδ + δ′ > δ, which is indeed the case since we take A > 1, since a ≥b
and a ≥g.
Next, assume that there are targets in S \ {t∗} that are more favorable for defender
i. We will show that for any strategy he takes, in the resulting coverage vector c′,
there will be at least one target t′ ̸∈S such that for every target s ∈S, U a(c′, t′) >
U a(c′, s) + δ, and hence all targets in t′ will be attacked with probability at most ϵ.
Indeed, assume the contrary. If defender i tries to minimize
∆(c′) :=
min
t̸∈S,s∈S U a(c′, t) −U a(c′, s),
he will allocate all of his resources to T \ S, resulting with equal attacker utility on all
of those targets, utilizing all of his resources. We will denote this utility by u=. Indeed,
otherwise, he could simply shift resources from the more protected targets to the less
ones in T \ S, and reduce ∆. Therefore, we know that:
20

1. P
j̸∈S xij = P
j̸∈S x′
ij = ki
2. ∀j ∈T \ {t∗} : 1 −(1 −xij)(1 −c−j) = ra(j)−(u∗−Aδ)
ra(j)−pa(j)
3. 1 −(1 −xi,t∗)(1 −c−t∗) = ra(t∗)−(u∗+δ′)
ra(t∗)−pa(t∗)
4. ∀j ̸∈S : 1 −(1 −x′
ij)(1 −c−j) =
ra(j)−u=
ra(j)−pa(j)
We want to claim that u∗+ Aδ −u= > δ. Let’s simplify:
1. P
j̸∈S xij = P
j̸∈S x′
ij = ki
2. ∀j ∈T \ {t∗} : 1 −xij =
1
1−c−j · u∗−Aδ−pa(j)
ra(j)−pa(j)
3. 1 −xi,t∗=
1
1−c−t∗· u∗+δ′−pa(t∗)
ra(t∗)−pa(t∗)
4. ∀j ̸∈S : 1 −x′
ij =
1
1−c−j ·
u=−pa(j)
ra(j)−pa(j)
Therefore, subtracting c −c′, we get that:
1. P
j̸∈S xij = P
j̸∈S x′
ij = ki
2. ∀j ̸∈S \ {t∗} : xij −x′
ij =
1
1−c−j · u=−u∗+Aδ
ra(j)−pa(j)
3. xi,t∗−x′
i,t∗= −
1
1−c−t∗·
u∗+δ′−u=
ra(t∗)−pa(t∗)
Next, summing up all the equations in 2 and equation 3, and substituting equation
1, we get:
X
j∈S\{t∗}
1
1 −c−j
· u= −u∗+ Aδ
ra(j) −pa(j)
−
1
1 −c−t∗· u∗+ δ′ −u=
ra(t∗) −pa(t∗) = ki −ki = 0
(14)
Next, note that ∆= u= −(u∗−Aδ). Therefore:
∆·
X
j̸∈S
1
1 −c−j
·
1
ra(j) −pa(j) =
1
1 −c−t∗·
δ′ + Aδ
ra(t∗) −pa(t∗)
Therefore, simplifying we get:
∆≥
b(δ′ + Aδ)
a(1 −c−t∗) · P
j̸∈S
1
1−c−j
Next, we remember that 0 ≤c−j ≤ra(j)−u+Aδ
ra(j)−pa(j) , since we covered up to height
u′ = u −Aδ. Therefore, 1 ≥1 −c−j ≥
u−Aδ−pa(j)
ra(j)−pa(j) , and we get 1 ≤
1
1−c−j ≤
ra(j)−pa(j)
u−Aδ−pa(j) ≤
a
g−Aδ ≤2a
g for Aδ ≤Aδ0 = g/2. Therefore, we get that:
21

∆≥bg(δ′ + Aδ)
2a2|T|
Now we only need to verify Aδ, δ′ are large enough so that bg(δ′+Aδ)
2ma2
> δ. We can
do that by taking Aδ = 4ma2
bg δ ∈O(δ). Now that ∆is at least δ, targets outside of S
are attacked with probability at most ϵ.
Lastly, for the case where g > Aδ, we have to show that δ′ ∈O(δ) in order to
bound the advantage of deviation. Intuitively, since the height u∗+ δ′ is a continuous
function of the height of the rest of the targets, namely u∗−Aδ, if Aδ is small enough
then δ′ is also small enough, therefore the utility loss from this NLE solution is O(δ +
ϵ). We would want to give a concrete bound however, so let’s look at the resource
count.
In order to decrease an attacker utility by Aδ one needs to increase the cover-
age of this target by (ra(t) −pa(t))Aδ.
The cost of increasing the coverage by
(ra(t) −pa(t))Aδ from a value of ct by a single defender is
1
1−ct (ra(t) −pa(t))Aδ ≤
2a(ra(t)−pa(t)
g
Aδ. However, a single defender may not have that amount of resource
left by this stage. In worst case, we may assume that all of the defenders allocate this
same amount of resource, which will always be enough to decrease the coverage by
Aδ.
Therefore, the maximal resource loss we get from increasing the coverage to height
u∗−Aδ is m · 2a P
t(ra(t)−pa(t))
g
Aδ, which will give an attacker utility decrease of
δ′ ≤(ra(t∗) −pa(t∗)) 2am P
t(ra(t)−pa(t))
g
Aδ.
For the last part of the proof, we have that δ ≤g < Aδ. For this case, calling
ALLOC with input (u∗−Aδ, u∗), will lead to cases where some of the targets get fully
covered and still the height u∗−Aδ is not reached. Denote the set of those targets by
M. Then by the assumption that the game is not saturated, by definition defender i
cannot induce an attack on targets in S ∩M, because they will stay fully covered. As
for targets in S \M, again defender i will not have enough security resources to induce
an attack on them. That is because now targets in M \ S free him only less security
resources to utilize.
C
Approximate α-Core
C.1
Proof of Resistance to Subset Deviations
In this subsection we prove the first step of our construction: resistance to deviations
of coalitions other than the grand coalition. The adaption of ALLOC to the cooperative
case is provided in Algorithm GC-ALLOC is explicitly described in 4.
Theorem C.1. There exist A, B, C, δ0, ϵ0 > 0 s.t. for any (δ, ϵ)-ABF ω with ϵ < ϵ0,
δ < δ0, the coalition structure CS generated by Algorithm GC-ALLOC with input
(u = u −Aδ, u), is resistant to any deviation of a coalition D ⊂N. That is, D has no
ζ = Bϵ + Cδ successful deviation from CS.
22

Algorithm 4 GC-ALLOC
Input: u, ˜u ∈[p, r];
Parameter: (1) a canonical game ⟨ra, pa, rd, pd, k⟩;
(2) δ, ϵ > 0 and a (δ, ϵ)-ABF ω;
Output: a coalition structure CS = ⟨N, X⟩
1: Set xi,t ←0, ∆t ←covt(u) and ct ←0, for all i, t;
2: for i ∈N do
3:
for t = ti1, . . . , tim in Ji(˜u) do
4:
xi,t ←min {∆t, ki −P
t′∈T xi,t′};
5:
ct ←ct + xi,t;
6:
if ct = 1 then ∆t ←0 else ∆t ←covt(u) −ct;
7: return X;
Proof. We divide into cases. Let ¯p := maxt∈T pa(t), and ¯t will be some target with
attacker penalty ¯p. In the first case, calling procedure ALLOC with input (u < ¯p + δ, u
gives a level coverage. In this case, increasing the attacker utility on target ¯t by δ will
make any other target be attacked with probability < ϵ, and hence ¯t is attacked with
probability ≥1 −(m −1)ϵ. This is in contradiction to the assumption that the game is
not (δ/b, ϵ)-saturated, for b = mint∈T (ra(t) −pa(t)).
For the second case, denote by a = maxt∈T (ra(t) −pa(t)), and g := mint∈T (u∗−pa(t)) ≥
δ > 0. Note that g ≥δ only for this second case. Fix the following values for
A, B, C, δ0, ϵ0:
• A := 1 +
P
t(ra(t)−pa(t))−1
mint (ra(t)−pa(t))−1
• B := maxi∈N (rd
i (t∗) −pd
i (t∗))·[(ra(t∗)−pa(t∗))−1+P
t (ra(t) −pa(t))−1+
(P
t (ra(t)−pa(t))−1)2
ra(t∗)−pa(t∗)
]
• C := maxi∈N
P
t∈T rd
i (t)
• δ0 = (P
t (ra(t) −pa(t))−1)−1
• ϵ0 = 1/m
We divide further into two cases, where in the first case, g > Aδ. For δ sufficiently
small, there is only a single target t∗that yields an attacker utility greater than u,
which is also the last target covered in ALLOC(u −Aδ,u). For any other target t, if
pa(t) > u −Aδ then ct = 0, and otherwise ut = u −Aδ. We argue that X is a ζ-NE
for ζ = Bδ + Cϵ for some constants B, C dependant only on G.
In contradiction, let (D, c′
D) be an ϵ′-successful deviation. Let TD be the set of
targets such that cD(t) > 0, and TR = TD. For each target t ̸∈TD, we fix the revenge
takers coverage to the value that will give the attacker a utility of u −δ. As u is the
mini-max height, this means that after the deviation targets on TD will be attacked with
probability at most ϵ. Indeed, if the contrary is true, then the height of the coverage
must be smaller than u, the height of the mini-max coverage, a contradiction.
23

Next, observe the resulted coverage vector, and define Tϵ to be the set of targets
that have an attack probability of at least ϵ. Note that Tϵ ⊆TD as mentioned. Let
tBR ∈BR ⊆Tϵ ⊆TD be some target.
Next, consider two cases. In the first, |TR| ≥1. In this case, the revengers will
use the resources left to make any target in TD other than tBR have an attacker utility
smaller than U a(c′
D, tBR)−δ. We will now verify that because of the choice of A, they
have enough resources for the revengers to do that.
For each target t ∈TR, the coverage cR(t) required to get to an attacker utility u
is: cR(t) =
ra(t)−u
ra(t)−pa(t). Therefore, since (u −δ) −(u −Aδ) =
P
t(ra(t)−pa(t))−1
mint(ra(t)−pa(t))−1 δ,
the resources that the revengers save from decreasing the coverage of the targets in TR
is:
∆K+
R =
X
t′∈TR
(ra(t′) −pa(t′))−1
P
t (ra(t) −pa(t))−1
mint (ra(t) −pa(t))−1 δ
And since there is at least one target in TR, it is lower bounded by:
∆K+
R ≥min
t′ (ra(t′) −pa(t′))−1 ·
P
t(ra(t) −pa(t))−1
mint(ra(t) −pa(t))−1 δ
=
X
t
(ra(t) −pa(t))−1δ
(15)
On the other hand, the amount of resource required to decrease all targets in TD \
{tBR} to have an attacker utility smaller than U a(cD, tBR) −δ. However, this can be
upper bounded by the cost of increasing all of the targets by δ attacker utility:
∆K−
R ≤
X
t
(ra(t) −pa(t))−1δ
Therefore, ∆K+
R ≥∆K−
R, and there are enough security resources to do so.
In the second case, TR = ∅, therefore TD = T. This means that the deviators have
allocated resources to every target. Then once again, if the revengers allocate resources
to every target t other than tBR in order to make its attack probability less than ϵ,
this will require at most ∆K−
R ≤P
t (ra(t) −pa(t))−1δ resources, and therefore for
δ ≤δ0 = (P
t (ra(t) −pa(t))−1)−1, this requires ∆K−
R ≤1 resources, which we
assume the revengers have.
In any case, we see that the revengers can induce the attacker to attack a single
target with probability greater than ϵ, and that this target is in TD. However, consider
a deviator i ∈D who allocated resources to target t. Therefore, if we denote by CS′
the coalition structure of the deviation and revenge coalitions described above, then the
utility of defender i can be bounded by:
U d
i (CS′) ≤U d
i (CS′, tBR) + ϵ
X
t
rd
i (t)
However, since tBR ∈BR and u is the height of the level coverage, then target tBR
cannot be covered such that the attacker utility on it is lower than u. Therefore, by
construction and since defender i covered target tBR before target t∗, we have:
U d
i (CS′, tBR) ≤U d
i (CS, t∗)
24

where CS is a level coverage of height u −δ. Finally:
U d
i (CS, t∗) = U d
i (CS, t∗) + rd
i (t∗) −pd
i (t∗)
ra(t∗) −pa(t∗)(δ + δ′)
Where u + δ′ is the height of CS, meaning the utility of the attacker on target t∗in
CS. Putting this altogether, we get that:
U d
i (CS′) −U d
i (CS) ≤ϵ
X
t
rd
i (t) + rd
i (t∗) −pd
i (t∗)
ra(t∗) −pa(t∗)(δ + δ′)
All that is left is compute δ′. We know that CS utilizes all K resources, and so is a
level coverage of height u. Therefore:
K =
X
t
ra(t) −u
ra(t) −pa(t)
=
X
t̸=t∗
ra(t) −(u −δ′)
ra(t) −pa(t)
+ ra(t∗) −(u + δ′)
ra(t∗) −pa(t∗)
(16)
Simplifying this gives:
δ′ = δ′(ra(t∗) −pa(t∗))
X
t̸=t∗
(ra(t) −pa(t))−1
Where δ′ = δ +
P
t (ra(t)−pa(t))−1
mint (ra(t)−pa(t))−1 δ
Therefore,
δ′/δ ≤(ra(t∗) −pa(t∗))
X
t
(ra(t) −pa(t))−1
+ (
X
t
(ra(t) −pa(t))−1)2
(17)
Thus, there are no ζ successful deviations where KD < D, if
ζ ≥ϵ
X
t
rd
i (t)
+ δ max
i
(rd
i (t∗) −pd
i (t∗)) · [
(ra(t∗) −pa(t∗))−1+
X
t
(ra(t) −pa(t))−1+
(P
t (ra(t) −pa(t))−1)2
ra(t∗) −pa(t∗)
]
(18)
This completes the proof for g > Aδ. Lastly, exactly by the same argument in the
proof of Theorem 6.1, there are no ζ successful deviations in the case where g ≤Aδ.
25

C.2
Resistance to Grand Coalition Deviations
In order to obtain resistance to the grand coalition, by definition, it suffices that the
solution is Pareto-efficient (see Definition C.2).
Definition C.2 (Pareto-efficient Element). Let m ∈N and S ⊆Rm
+ be some set. A
vector u ∈S is Pareto efficient in S if there doesn’t exist another vector u′ ∈S such
that u′
t ≥ut on each coordinate and there exist 1 ≤t ≤m s.t. u′
t > ut. We denote the
subset of Pareto efficient elements by SP E.
Lemma C.3. Let U be the set of possible utility vectors for defenders in N. That is,
u ∈U if there exist a coverage vector c ∈CkN such that u = (U d
i (c))i∈N . Let
u ∈UP E, and let c ∈CN be a coverage vector inducing u. Then CS = ⟨N, c⟩is a
coalition structure resistant to any successful deviation of the grand coalition D = N.
Proof. Assume in contradiction that there exist a successful deviation of (N, xD). De-
note by u′ = (U d
i (xD))i∈N . Then by definition of a successful deviation, for every
deviator i ∈N, u′
i > ui, contradicting the Pareto efficiency of u, since u′ ∈UN as
well.
C.3
Inducing Arbitrary Attack Distributions
Reasonably, a coalition structure in the core should still result with a coverage vector c
with height(c) ≈u, by the same logic that strategy profiles in NE should be efficient.
Namely, if height(c) ≫u, the defenders may increase the height of the coverage and
improve their utility, since all of the targets are more protected.
However, due to the presence of our ABF, allegedly it may be the case that some
attack distribution ω(c) = p that can be generated at height(c) = u, cannot be approx-
imated by any coverage vector of height u ≤height(c) ≤u + O(δ). We claim that
this is never the case. Formally, we prove Proposition 7.1.
Proof. For any subset S ⊆T , we denote by ωS(u) = P
t∈S ωt(u) the probability
that the attack will take place in S. For every t ∈S, we denote by ω|S,t (u) :=
ωt(u)/ωS(u) the probability that the attacker will attack target t given that the attack
will take place in S. We denote for every m′ ∈N the set [m′] := {1, . . . , m′}. We also
denote by pS := P
t∈S pt and p|S,t := pt/pS.
W.L.O.G assume that p1 ≤· · · ≤pm. We prove by induction on m the following:
for every 1 ≤m′ ≤m, there exists a utility vector u such that:
1. ∥ω|[m′],t(u) −p(t|[m′])∥∞≤0.5m′(m′ −1)ϵ
2. ∀t ∈[m′] : u ≤ut < u + 2m′δ
3. |ω|[m′],m′ −p|[m′],m′| ≤(m′ −1)ϵ
4. ∀t ∈[m′] : |ut −(u + mδ)| < m′δ
If m′ = 1 the claim is trivial taking u = (u + m′δ, 0, . . . , 0). Assume the claim is
true for m′ −1, and let u be such a utility vector.
26

By Axiom 3, if we extend u′ to a utility vector u′ = (u1, . . . , um′−1, um′, 0, . . . , 0),
we still have that ω|[m′−1],t(u′) = ω|[m′−1],t(u) for every target t ∈[m′ −1].
If we take um′ = um′−1 + δ then ω|[m′],m′(u′) > 1 −(m′ −1)ϵ, as all the rest of
the targets are attacked w.p. < ϵ.
If um′ = um′−1 −δ, then by Definition 4 ω|[m′],m′(u′) < ϵ.
Therefore, by continuity, there exists a value um′ satisfying |um′ −um′−1| < δ
such that ω|[m′],m′(u′) is any value in the range [ϵ, 1 −(m′ −1)ϵ]. Therefore, there
exists such a value satisfying |ω|[m′],m′(u′)−p|[m′],m′| < (m′ −1)ϵ, as desired. Since
by induction hypothesis |um′−1 −(u + mδ)| < (m′ −1)δ, by triangular inequality we
have that |um′ −(u+mδ)| < m′δ as desired. Since we didn’t change the values of the
rest of the targets in [m′], the only part left to check is that they also have the desired
probabilities. Let t < m′ be some target. Then:
|ω|[m′],t(u′) −p|[m′],t| = |ω|[m′−1],t(u′)
ω|[m′−1](u′) ω|[m′−1](u′)
−p|[m′],t|
≤|ω|[m′−1],t(u)
ω|[m′−1](u) −p|[m′−1],t| · ω|[m′−1](u)
+ |ω|[m′−1](u) −p|[m′−1]| · p|[m′−1],t
≤0.5(m′ −1)(m′ −2)ϵ + (m′ −1)ϵ
= 0.5m′(m′ −1)ϵ
(19)
Therefore, we get that ∥ω(u′) −p(·|t ≤m′)∥∞≤0.5m′(m′ −1)ϵ. Therefore, by
induction, the claim is also true for m′ = m, which completes the proof.
This proves that if cov(v) is feasible, then by decreasing the coverage of each target
by O(δ), it is possible to O(ϵ) approximate any attack distribution p. This will result
with an O(δ + ϵ) utility loss for each defender. In what follows we combine all of our
observations to construct stable solutions.
C.4
A Construction of an α ζ-Core Solution
By this stage, we have everything needed to construct a solution to the α ζ-core. We
first introduce an approximation-preserving reduction into a simpler problem which
can be solved accurately. To do so we again overload notations and define the utility
when the attack probability is specified:
Definition C.4 (Defender Utility for Specified Attack Distribution). Let p be some
probability distribution over m targets, let i ∈N be some defender and c ∈Cki. Then
U d
i (c, p) := P
t∈T p(t) · U d
i (c, t).
Lemma C.5. Fix CSGC to be the grand coalition structure with min-max height. There
exist A, B, δ0, ϵ0 > 0 s.t. for every δ < δ0, ϵ < ϵ0, the following is true:
• ∀probability distribution p, ∃coalition structure CS s.t. ∀i ∈N : U d
i (CSGC, p) ≤
U d
i (CS) + Aϵ + Bδ.
27

• ∀coalition structure CS, ∃probability distribution p s.t. ∀i ∈N : U d
i (CS) ≤
U d
i (CSGC, p) + Aϵ + Bδ.
Proof. Note that the proof is constructive, and the reductions are efficient. Basically,
the first direction follows from Proposition 7.1, and it is efficient due to Axiom 2. As
for the second direction, take p := ω(cov(CS)). Any target t ∈T with U a(CS, t) <
u −δ is attacked with probability less than ϵ, therefore it would contribute a utility loss
bounded by rd
i (t)ϵ. For the rest of the targets, since height(CSGC) = u, the utility loss
is bounded by δ.
Theorem C.6. There exists a game dependent A, B, δ0, ϵ0 > 0 such that for every
0 < δ < δ0, 0 < ϵ < ϵ0 and every (δ, ϵ)-ABF, the α ζ = (Aϵ + Bδ)-core is non-empty,
and there exists an efficient algorithm that finds stable solutions in it.
The main idea is the following: we start with a CS resistant to any deviation set
D ⊆N with kD < kN resources. Denote by u0 := (U d
i (CS))i∈N+. We then search
for a Pareto efficient solution in UP r := {(U d
i (CSGC, p))i∈N+|p is a probability distribution}
which satisfies the constraints U d
i (CSGC, p) ≥u0
i for each defender i ∈N+. We know
such a solution CS′ exists, since p = 1t∗satisfies the constraints. There are three key
steps left to finish the proof:
• The solution CS′ is resistant to any ϵ′ successful deviation of any D ⊆N de-
fenders with kD < kN resources. ϵ′ is the same as in Theorem C.1. This follows
directly from the fact that CS′ realizes the constraints and because CS is resistant
to such deviations.
• The solution CS′ is resistant to any deviation set D ⊆N of kD = kN resources.
This follows directly from the Pareto efficiency of the solution.
• The solution CS′ can be found efficiently. In order to see that, denote for each
t ∈T by ud
t := (U d
i (CSGC, t)i∈N+. Then UP r is a polytope with vertices at
{ud
t |t ∈T } (or a subset of that). Furthermore, the constraints for the defenders
are linear with the variables p(t) which span this polytope. Therefore, if we
take any vector α := (αi)i∈N+ with all entries > 0, then maximizing ⟨α, u⟩
for u ∈UP r under the specified constraints is an LP optimization problem with
O(m + n) constraints and m variables, therefore it can be solved efficiently, and
yield the resulting solution.
The last step is to perform our approximation reduction step using Lemma C.5. In
this step we gain an additional O(δ + ϵ) utility loss, and the constants add-up.
D
Examples
D.1
Example of an ABF
As mentioned, a well studied private case for an attacker ABF is the soft-max function:
soft-maxt(u) :=
eut
P
t′∈T eut′
28

In the domain of security games it is often called quantal response, as the more utility
the attacker gets from a target, the more the likelihood of being attacked increases,
respectively.
Proposition D.1. The quantal response function ω is an ABF.
Proof.
Probability Distribution
Let u be some attacker utility vector and let t ∈T . Denot-
ing by A = P
t∈T eut:
X
t∈T
ωt(u) =
X
t∈T
eut/A = A/A = 1
and also 0 ≤ωt(u) ≤1 since exp(x) ≥0 for any x ∈R.
Monotonous
Let δ > 0, t ∈T and define u′ such that u′
t = ut + δ and ut′ = ut′
for any other t′ ∈T . Denote by A′ = P
t∈T eu′
t, then A′ > A. Also denote by
B = P
t̸=t′∈T eut = P
t̸=t′∈T eu′
t. Then:
ωt(u) = 1 −(1 −ωt(u)) = 1 −B/A < 1 −B/A′ = ωt(u′)
Independence
Let ∅̸= S ⊆T and let t ∈S. Let u′ be some attacker utility vector
such that for each t′ ̸∈S u′
t′ = ut′. Then, denoting by C = P
t∈S eut = P
t∈S eu′
t:
ωt(u)
P
t′∈S ωt′(u) = eut/A
C/A = eut′/A′
C/A′
=
ωt(u′)
P
t′∈S ωt′(u′)
Continuously Differentiable
Holds as a summation, division and composition of
continuously differentiable functions.
Note that this would have also worked for any ωt(u) =
f(ut)
P
t′∈T f(ut′) where f is a
one-dimensional monotonic continuously differentiable function into (0, ∞).
Next we will construct a δ, ϵ ABF.
Proposition D.2. Let δ, ϵ > 0. Then there exists a (δ, ϵ)-ABF.
Proof. Consider ω(u) := soft-max(nu) for some n ∈N to be determined later. By
Proposition D.2 ω is an ABF. Consider two targets t, t′ where ut′ < ut −δ, then:
ωt′(u) <
en(ut−δ)
P
s∈T enus < e−nδ
Therefore, we want e−nδ < ϵ, and so n > 1
δ ln 1
ϵ .
29

D.2
Example of an SSG with no NSE
Example D.3 (NSE may not Exist). Consider a single defender SSG with two targets.
The attacker is indifferent to the targets. Assume for instance that the reward and the
penalty of the attacker on both targets are 1, 0 respectively. The defender has two
security resources, and prefers target t1 over t2. Assume for instance that rd(t1) =
3 > pd(t1) = 2 > rd(t2) = 1 > pd(t2) = 0. Then, assuming the attacker breaks ties
in opposition to the defender, or even attacks randomly over BR, there is no NE for this
game.
Proof. First, observe that the defender can get a utility arbitrarily close to rd(t1) = 3.
Indeed, let 0 < ϵ < 1 and consider the coverage vector (1 −ϵ, 1), which is feasible for
the defender. Then BR = {t1}, therefore the utility of the defender will be 3 −ϵ.
We claim that there is no strategy for the defender to gain a utility ≥3. If that is
the case, then there is no NE, since the defender can always improve his utility to be a
little closer to 3.
Indeed, assume in contradiction that the defender gets a utility ≥3 playing some
strategy c. Let p be the probability that the attacker takes target t1. Then 3 ≤U d(c) =
p · U d(c, t1) + (1 −p) · U d(c, t2) ≤p · rd(t1) + (1 −p) · rd(t2) = 2p + 1 ≤3.
Therefore, p must be equal to 1 and so c1 < c2 ≤1. However, in that case, we get that
3 = U d(c, t1) = c1 · rd(t1) + (1 −c1) · pd(t1) = 2 + c1 < 3, which is a contradiction.
Note that the fact that the defender can get a utility arbitrarily close to 3, but cannot
get exactly 3, is due to the fact that the utility is not continuous. Specifically, we took
advantage of the fact that:
3 =
lim
c1→1−U d((c1, 1)) ̸= U d((1, 1)) = 1
In the case that the attacker plays randomly over equally appealing targets in BR,
we would still get U d((1, 1)) = 0.5·3+0.5·1 = 2 ̸= 1, and a similar argument works.
D.3
Example of a Robust Solution
Consider the game described in Example D.3. For single defender games, due to the
phenomena described in that example, it is well accepted that the attacker breaks ties
in favor of the defender. A NE under this assumption is called SSE; it is known to
exist and can efficiently be found using LP. However, as we will now demonstrate, it is
extremely sensitive and is not robust.
We begin by demonstrating how exactly this optimistic tie-breaking fails to form
robust solutions even for single defender games, and then show how our model for SSG
handles this problem.
Proposition D.4. Consider the game described in Example D.3, assuming that the
attacker breaks ties in favor of the defender. Let 0 < δ < 1. Then any NE of this game
is not δ-robust.
30

Proof. We have already shown that the utility of the defender is bounded by 3, and
now that we assume optimistic tie breaking there is also a unique strategy that achieves
that, namely cNE = (1, 1), which is therefore the only NE. Then if we assume, for
instance, that the parameters of the attacker on target t2 slightly change to be ra(t2) =
δ/2, pa(t2) = δ/2 and the parameters of target t1 stay the same, then in the resulting
game the defender gets a utility of δ/2, and therefore it’s not NE as the defender can
deviate and get a utility of 3.
This formally explains the more intuitive argument, that when a solution assumes
optimistic tie-breaking, a slight change in the attacker’s parameters can lead to major
utility loss for the defenders, altering the NE. This happens due to the non-continuity of
the defender’s utility at the equilibrium point. However, when the attacker follows an
ABF and when the two targets are covered equally, they are attacked with some prob-
abilities p, q (50%-50% in quantal response for example), and slightly changing the
attacker’s parameters (δ parameter) will only slightly change the attacker’s probability
of attacking each target (ϵ parameter). This is the property that leads to robustness.
Next we are going to demonstrate a robust approximate NE of the above game
following our constructive proof for Theorem 6.1. To make the game canonical for
the sake of simplicity, assume that the defender has a single resource. Therefore, u =
0.5 ∈(0, 1] = (p, r).
Following the constants of the proof, we have δ0 = 1/64 (maximal value of δ
such that the game is δ-canonical), ϵ0 = 1/2. With respect to the parameters of the
game, observe that these values are not that small, as solving with an accuracy of 2/3
of a decimal point for game parameters in the range of [0, 10] seems both common
and feasible. Therefore, assume that the attacker’s ABF for this game has parameters
δ = 0.01 < δ0 and ϵ = 0.1 < ϵ0. For example, consider ω(u) = soft-max(nu) with
n = 250 (see Proposition D.2). However, the proof itself doesn’t require knowing the
exact ABF ω, it is enough to know its parameters.
Therefore, we know from the proof that the solution would look something like
c0 = (0.5 −α, 0.5 + α) which, assuming α > δ/2, will induce the attacker to attack
target t1 with a probability of at least 1 −ϵ. Therefore the utility of the defender is at
least (1 −ϵ)(2 + (0.5 −α)) = 2.5 −2.5ϵ −α + αϵ > 2.5 −2.5ϵ −α, which we will
denote by U0.
Based on this theorem, we can bound the utility of a defender in this game by
U < max 2 + (0.5 + δ/2), 3ϵ + 1 = 2.5 + δ/2.
For this example game it is intuitive: either c1 < c2 −δ, in which case c1 is limited
to 0.5 + δ/2, or the opposite is true, which would mean that target t1 is attacked with a
probability of at most ϵ. We can bound the ωt1(c) by 1 in the first case, and U d
1 (c, t1)
by rd
1(t1) for the second case.
Therefore, taking for instance α = δ as the theorem suggests, c0 is a ζ = 2.5ϵ +
1.5δ = 0.265-NE. Thus, following Theorem 5.2, c0 is a δ = 0.01-robust ζ′ = 0.665-
NE.
Also note that as it is a single defender game, c0 is also a δ-Robust ζ′ solution to
the α-Core (and also β, γ-Cores which coincide for a single defender).
31

Example D.5 (Grand Coalition Deviation of Type 2). Consider the SSG depicted in
2. Let us now use procedure GC-ALLOC with input (u −Aδ, u). We claim that the
grand coalition has a deviation of type 2 from the resulted strategy profile.
Defender 1 will first cover target t1, which is the less favorable target for him, up
to height u. He will then cover part of target t3. Afterwards, defender 2 will cover
target t2, which is less favorable for him, and then he will use the rest of his resources
to cover target t3, which will result with an attacker height u + δ′.
We take Aδ > δ so that deviation of type 1 will yield up to O(ϵ) utility gain for
the defenders, but small enough such that 3 will yield up to O(δ) utility gain for the
defenders. For example, we can take Aδ = 2δ.
Player
t1
t2
t3
Ki
Defender 1
1,1
300,300 2,2
1
Defender 2
300,300 1,1
2,2
1
Attacker
1,0
1,0
1,0
Table 2: Example of an SSG where using GC-ALLOC doesn’t yeild a stable solution due to a
deviation of type 2
Unfortunately, the grand coalition still has a deviation of type 2 with Ω(1) utility
gain for both defenders. In the original CS, both defenders get a utility close to 2.
Consider a deviation of the grand coalition, with a coverage of (0, 0, 1). The utility that
each defender gets now is at least 0.5 ∗300 = 150 ≫2. Therefore, this is a successful
deviation.
Intuitively, the reason the method for the original game for finding the core doesn’t
work is that in this case defender 1 covers a target that defender 2 prefers over the
chosen target, and vice versa. Together, they can induce the attacker to attack these
preferred targets, each with probability 0.5. This wasn’t possible in the NLE for the
non-cooperative game by definition. Also, in the original model, every defender as-
sumed that the attacker attacks the target that is worst for him, so this wouldn’t be a
successful deviation there either.
Since the reward and penalties on each target are the same in this game, it is conve-
nient to specify which solutions are in the core by the distribution of the attacker. We
claim that the distribution (p, 1 −p, 0) is in the ϵ-core for any
2
300 ≤p ≤1 −
2
300.
Indeed, in such a strategy the defenders get utilities 300p, 300(1 −p) ≥2 respectively.
A deviation by a single defender i is not successful, since the other defender can block
the target t3−i and the utility of defender i is bounded by 2. A successful deviation of
the grand coalition means that u1 > 300p, u2 > 300(1 −p). If the coverage vector
of this deviation is (q1, q2, q3) then we must have q1 > p, q2 > (1 −p) and therefore
q1 + q2 + q3 > 1, which is impossible.
It seems as if the solutions we find are a subset of the Pareto efficient defender
utility vectors, specifically the Pareto efficient solutions where no subset of defenders
can deviate. This observation will turn out to be important for constructing an element
in the core.
32

D.4
An example of an SSG with an Empty Robust γ-Core
In γ-core (see Definition D.6), we assume that, after deviation, the rest of the defenders
are singletons and cannot cooperate, as suggested in [Chander, 2010]. There are usually
further limitations on the revenge takers’ response, such as that each revenge taker
best responds to a deviation [Chander and Tulkens, 2006] or that the resulting strategy
profile forms a NE [Chander, 2007]. However, without any of these assumptions, we
show that the γ-core of the game may be empty.
Definition D.6 (Robust γ-Core). Let CS be some coalition structure. A deviation
(D, xD) from CS is γ-successful if for every non-cooperative strategy profile of the
rest of the defenders Y = (yr)r∈R, the following holds for every deviator i ∈D:
U d
i (⟨xD, Y ⟩) > U d
i (CS)
CS is in the γ-core if it has no γ successful deviations.
We demonstrate that the γ-core may be empty.
Example D.7 (Empty γ-Core). The SSG depicted in Table 1 has an empty γ-core,
assuming ( 7−3
√
5
12
, 1
15)-ABF.
Basically, defenders 1, 2 can always γ-deviate and get a utility ≥4 each, as can
defenders 3, 4, but no coalition structure can yield all defenders ≥4 utility. Here is a
more formal and detailed explanation:
Proof. If defenders 1, 2 decide to play (2/3, 2/3, 2/3, 0, 0, 0) which can be imple-
mented as K{1,2} = 2, then no matter what defenders 3, 4 decide to do, a target
t ∈t1, t2, t3 is attacked w.p. at most 3ϵ. Indeed, if defenders 3, 4 want to incentivize
the attacker to attack targets in t1, t2, t3, they need to cover targets t4, t5, t6 and result
with a coverage with a diameter smaller than δ. The best they can do non-cooperatively
with their K3,4 = 2 resources is to play (0, 0, 0, α, α, α) where α = 1−α2. This leads
to an attacker height of 1 −α = 3−
√
5
2
. However, δ < 3−
√
5
2
−1
3.
Therefore, after deviation, defenders 1, 2 will get at least (1 −3ϵ) · pd
1(t4) = 5 ·
(1 −3ϵ) = 4.
On the other hand, by symmetry, it is easy to see that defenders 3, 4 can get at
least a utility of 4 after deviation as well, assuming defenders 1, 2 will respond without
coordination. Therefore, if a coalition structure CS was in the γ-core, then it must
yield a utility U d
1 (CS) = U d
2 (CS) ≥4, since otherwise, we proved that there exists a
deviation of defenders 1, 2. Note that since defenders 1, 2 are of the same type, their
utility is always equal. For the same reason, U d
3 (CS) = U d
4 (CS) ≥4. Denote by
p the probability that the attacker attacks a target in {t1, t2, t3}. On the one hand,
4 ≤U d
1 (CS) ≤p·1+(1−p)·6, therefore p ≥0.6. On the other hand, 4 ≤U d
3 (CS) ≤
p · 6 + (1 −p) · 1, therefore p ≤0.4, a contradiction. Thus, there always exists a
γ-successful deviation, and the γ-core is empty.
It is worth mentioning that the γ core for the original MSSG model is also empty,
by a similar example.
33

