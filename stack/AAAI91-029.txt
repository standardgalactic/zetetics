The Function of Ti 
perative Negotiations* 
Sarit Kraus 
Graduate School of Library Studies and 
Dept. of Computer Science 
Hebrew University, Jerusalem, 
91904 Israel 
e-mail: sarit@cs.huji.ac.il 
Abstract 
Work in distributed artificial intelligence (DAI) has, 
since its earliest years, been concerned with negotia- 
tion strategies. 
which can be used in building agents 
that are able to communicate to reach mutually bene- 
ficial agreements. 
In this paper we suggest a strategic 
model of negotiation that takes the passage of time 
during the negotiation 
process itself into considera- 
tion. Changes in the agent’s preferences over time will 
change their strategies in the negotiation and, as a re- 
sult the agreements they are willing to reach. We will 
show that in this model the delay in reaching agree- 
ments can be avoided. 
Introduction 
Research in distributed 
artificial 
intelligence 
(DAI) is 
concerned with how automated agents can be designed 
to interact effectively. 
One important 
capability 
that 
could aid inter-agent cooperation is negotiation; agents 
could be built that are able to communicate 
their re- 
spective desires and compromise to reach such mutu- 
ally beneficial agreements. 
Work in DA1 has been concerned with negotiation 
strategies [Davis and Smith 1983; Georgeff 1983; Mal- 
one et al. 1988; Durfee 1988; Rosenschein 
and Gene- 
sereth 1985; Sathi and Fox 1989; Conry et al. 1988; 
Zlotkin 
and Rosenschein 
19901 which can be used 
in building agents that are able to communicate 
to 
reach mutually beneficial agreements. 
Sycara ([Sycara 
1987]), using case-based 
reasoning, 
and Kraus et al. 
([Kraus et al. 19911) modeled negotiations from a cog- 
nitive standpoint. 
One of the main criticisms of using negotiations as a 
way of reaching mutual benefit is that negotiation is a 
costly and time-consuming 
process and, consequently, 
it may increase the overhead of coordination (see [Bond 
and Gasser 19881). In the presence of time constraints, 
*A preliminary version of this paper was presented at 
the 10th International 
Workshop on DAI. This work was 
partially completed while the first author was at the Insti- 
tute for Advanced Computer 
Studies and Dept. 
of Com- 
puter Science, University of Maryland, College Park. 
Jonathan 
Wilkenfeld 
Dept. of Government and Politics 
University of Maryland 
College Park, MD 20742 
e-mail:wilkenfeld@umd2.umd.edu 
planning and negotiation 
time should be taken into 
consideration 
The negotiation may be either about job 
sharing or resource allocation. 
In both cases we want to 
prevent the agents from spending too much time on ne- 
gotiation and therefore not keeping to their timetable 
for satisfying their goals. 
In this paper we suggest a strategic model of negoti- 
ation that takes the passage of time during the negoti- 
ation process itself into consideration. 
Changes in the 
agent’s preferences over time will change their strate- 
gies in the negotiation and, as a result the agreements 
they are willing to reach. We will show that the delay 
in reaching agreements can be avoided. 
Following 
[Rosenschein 
and 
Genesereth 
1985; 
Zlotkin and Rosenschein 
1990; Kraus and Wilkenfeld 
1990a] we examine negotiation 
using game theoretic 
techniques with appropriate modifications 
to fit artifi- 
cial intelligence situations. 
We will focus primarily on 
works in game theory and economics that have studied 
the effect of time preferences on the negotiation 
pro- 
cess, following the classic paper by Rubinstein 
([Rubin- 
stein 19821). 
Comparing our work to that of Zlotkin 
and Rosenchein, 
[Zlotkin and Rosenschein 
19901 we 
make no assumption about the protocol the agents use 
for negotiations. 
Also, our model takes the passage of 
time during the negotiation 
process itself into consid- 
eration, 
which in turn influences the outcome of the 
negotiations 
and avoids delays in reaching an agree- 
ment. 
Initial Setting 
Two autonomous agents A and B have a common goal 
they want to satisfy as soon as possible. In order to sat- 
isfy any goal, costly actions must be taken and an agent 
cannot satisfy the goal without reaching an agreement 
with the other agent. Each of the agents wants to min- 
imize its costs, i.e., prefers to do as little as possible. 
We note that even though the agents have the same 
goal (under our simplified assumptions), 
there is actu- 
ally a conflict of interests. 
The agents try to reach an 
agreement over the division of labor. We assume that 
each step in the negotiation takes time, and the agents 
have preferences for reaching agreements 
in different 
KRAUS & WILKENFELD 
179 
From: AAAI-91 Proceedings. Copyright ©1991, AAAI (www.aaai.org). All rights reserved. 

time periods. 
We make the following assumptions: 
1. Full information - each agent knows all relevant in- 
formation including the other agent’s preferences for 
the different outcomes over time. 
2. The agents are rational - they will behave according 
to their preferences. 
3. 
Commitments 
are enforced - if an agreement 
is 
reached both sides are forced to follow it. 
4. Assumptions 
(l)-(3) 
are common knowledge. 
We will also assume that there are no other agents 
in the environment which can help them.and that any 
division of the work that is needed to satisfy the goal 
is possible. 
We will relax the last assumptions 
later. 
In [Kraus and Wilkenfeld 19911 we examine the case of 
N agents, where N 2 3. 
Example 1 Two agents 
must paint a wall. 
One has 
the brush and the other has the paint. 
In order to paint 
the wall both the paint and the brush are needed. 
Paint- 
ing is a costly operation, 
and any delay in the painting 
is also costly to both sides. 
The Structure 
of Negotiations 
Our strategic 
model of negotiations 
is a model of Al- 
ternative Offers. ’ We utilize modified definitions from 
[Osborne and Rubinstein 
19901. 
Definition 1 Agreement: 
An agreement 
is a pair (SA, sg), 
in which si is agent 
i’s portion 
of the work? needed 
to satisfy the agents’ 
goal. The set of possible agreements 
is 
sequences 
of length t of elements 
in S and Y, N are de- 
fined above). 
F is the set of all strategies 
of the agent 
who starts the bargaining. 
Similarly, 
let G be the set of 
all strategies 
of the agent who, in the first move, has to 
respond 
to the other agent’s 
ogler; that is, G is the set 
of all sequences 
of functions 
g = (gt)~& 
such that for 
t even gt : St+’ 
+ (Y, N) 
and for t odd gt : St + S. 
Let a(f, g) b e a sequence of offers in which A starts 
the bargaining and adopts f E F, and B adopts g E G. 
Let L(f, g) be the length of ~(f, g) (where the length 
may be infinite). 
Let La(f, 
g) be the last element of 
a( f, g) (if there is such an element). 
We present a 
formal definition for the outcome of the negotiation. 
Definition 3 Qutcome of the negotiation: 
The outcome function 
of the negotiation 
is defined by 
P(f,g) 
= { 
&a(f,g), 
L(f,g) 
- 1) 
%ZZe= 
O” 
Thus, the outcome (s, t) where s E S is interpreted as 
the reaching of agreement s in period t and the symbol 
D indicates a perpetual disagreement. 
We note here that by defining an outcome to be ei- 
ther a pair (s, t) or D, we have made a restrictive 
as- 
sumption about the agents’ preferences. 
We assume 
that agents care only about the nature of the agree- 
ment, and the time at which the outcome is reached, 
and not about the sequence of offers and counteroffers 
that leads to the agreement, i.e., no “decision-regret” 
(see [Rsiffa 19821). 
The last component of the model is the preference 
of the a.gents on the set of outcomes. 
Each agent has 
preferences over agreements reached at various points 
S = {(sA, sg) E R2 : SA+SB = 1 and si 2 0, for i = A, B} 
in time.3 
The time preferences 
and the preferences 
_ - 
between agreements are the driving force of the model. 
The agents’ preferences over S are opposed. 
Each 
agent prefers to do less rather than more. 
That is, 
agent A prefers s1 E S to s2 E S if and only if si < sf . 
The negotiation 
procedure is as follows. The agents 
can take actions only at certain times in the set 7 = 
{ 0, 1,2. ..} . In each period t E 7 one agent, say i, 
proposes an agreement, and the other agent (j) either 
accepts the offer (Y) or rejects it (N). 
If the offer is 
accepted, then the negotiation ends, and the agreement 
is implemented 
(i.e. 
each of the agents does its part 
of the job). 
After a rejection, 
the rejecting agent then 
has to make a counter offer and so on. There are no 
rules which bind the agents to any previous offers and 
there is no limit on the number of periods. 
Definition 2 Negotiation 
Strategies: 
Let F 
be the set of all sequences 
of functions 
f 
= 
{f tIEo, 
where f” E S, for t even ft : St + 
S, 
and 
for t odd ft 
: St+’ 
-+ (Y, N) 
(St 
is the set of all 
/ 
‘See [Osborn e and Rubinstein 19901 
for a detailed re- 
view of the bargaining game of Alternating Offers. 
2A similar definition can be given concerning a division 
of resources. 
Formally, we assume that agent i = A, B has a pref- 
erence relation 2-i on the set {S x I} 
U (D}. 
Here we will concentrate 
on two utility functions 
that yield preference relations 
under the assumption 
that an agent wants to maximize its own utilities. 
Definition 4 Utility 
function 
with 
time 
con- 
stant discount rate 
Let (s,t) 
E S x 7 
be an outcome 
of the negotiation, 
then the Utilityi((s, 
t)} where i = A, B is defined to be 
68(1 - si), where 0 < 6i < 1, and Utilityi 
= -00. 
Definition 5 Utility 
function 
with a constant 
cost of delay 
Let (s, t) E S x 7 
be an outcome 
of the negotiation 
then the Utilityi((s, 
t)) 
where i = A, B is defined 
to 
be 1 - si - tit where ci > 0 and Utility:(D) 
= -OCI. 
Both of the above utility functions capture the gains 
of the agents as the difference between the work they 
3The way these p r e ferences are determined by the agents 
is beyond the scope of this paper. They can either be given 
to the agent with the specifications of its task, or it may 
be decided by the agent itself after analyzing his goals 
180 
FORMALISMS FOR COORDINATION 

agreed to perform and the whole work that is needed, 
and have a discount over time. 
How will a rational agent choose his strategy for the 
negotiation. 3 A useful notion is the Nash Equlibrium 
([Nash 1953; L uce and Raiffa 19571). A pair of strate- 
gies (a, r) is a Nash Equilibrium if, given 7, no strategy 
of A results in an outcome that A prefers to the out- 
come generated by (a, T) and, similarly, to B given 0. 
If there is a unique equilibrium, 
and if it is known that 
an agent is designed to use this strategy, no agent will 
prefer to use a strategy other than these ones. 
However, the use of Nash Equilibrium 
is not an ef- 
fective way of analyzing the outcomes of the models of 
Alternating 
Offers since it puts few restrictions 
on the 
outcome and yields too many equilibria 
points. 
(See 
([Rubinstein 
19821 for the proof). 
Therefore, 
we will 
use the stronger notion of (subgame 
perfect equi- 
librium (P.E.) ( see [Rubinstein 
1 
1982 ) which requires 
that the agents’ strategies induce an equilibrium at any 
stage of the negotiation, i.e., in each stage of the negoti- 
ation, assuming that an agent follows the P.E. strategy, 
the other agent does not have a better strategy than 
to follow its own P.E. strategy. 
So, if there is a unique 
perfect equilibrium, 
and if it is known that an agent 
is designed to use this strategy, no agent will prefer to 
use a strategy other than this one in each stage of the 
negotiations. 
The following theorem shows that there 
exists a unique P.E. which ends the negotiation 
after 
the first period. This unique solution is characterized 
by a pair of agreements X* and y*, that satisfies: 
(1) 
Agent A is indifferent between “y* today” and “x* to- 
morrow,” and (2) Agent B is indifferent between “x* 
today” and “y* tomorrow.” When a unique pair of x* 
and y* satisfies this statement, 
there exists a unique 
P.E. [Rubinstein 
19821. 
it terminates 
immediately. 
Similar results can be ob- 
tained using the utility function of constant delay de- 
fined in Definition 5, when CA # cg. 
These results 
demonstrate 
our idea that allowing time into the ne- 
gotiation process can lead to an efficient negotiation. 
Other elements that influence the outcome of the 
negotiation include the patience of the agents. If Al’s 
losses over time are greater than As’s then he will do 
more of the work. In addition, the agent who starts 
the negotiation has an advantage over the other agent 
(for example if both agents have the same rate of delay 
6 then the first one will do only S/(1 + S) of the job 
and the other will do l/( 1 +S)). 
A simple way to avoid 
this asymmetry in the model is the following (see [Os- 
borne and Rubinstein 
19901): at the beginning of each 
period each agent is chosen with probability 
l/2 (in- 
dependently across periods) to be the one to make the 
first offer. We return now to the agents from Example 
1, and demonstrate 
the above results. 
Example 2 
We denote the agent with the paint by P 
and the agent with the brush by B. 
Let an agreement 
be a pair (sp, sg) 
where si is the agreed portion 
of the 
wall agent i will paint and sp + sg = 1. 
Suppose 
agent B and agent P have the following util- 
ity function 
correspondingly: 
uB((s, 
t)} = O.gt(l-sB) 
and Up{(s, t)) = O@(l 
- sp). 
If agent B is designed 
to use the unique P.E. 
then agent P should use it too. 
Suppose 
agent P starts the negotiation. 
He will o$er 
((0.8 * O.l)/(l 
- 0.9 * 0.8),0.2/(1 
- 0.9 * 0.8)) 
which 
is approximately 
(0.286,0.714) 
and agent B will accept 
the offer immediately. 
Theorem 1 Suppose 
agent A starts the negotiations. 
Let 
Finite Set of Feasible Agreements 
Until now we have assumed that the agents can di- 
vide the work between them, in any way that they 
have agreed upon. Unfortunately, 
this cannot usually 
x* = ( SB(~-6~) 
1-6~ 
be done. If two agents need to carry blocks or to de- 
1 - SASB ’ 1 - SASB ) y* = ( 1 yiIiB, 
‘f(l 
a p)) 
liver packages, th’ is work can be divided only in a dis- 
-AB 
Crete manner and usually in a finite number of possible 
(f?g) 
is a subgame 
perfect 
equilibrium 
of the strategic 
model 
of Alternative 
O$ers 
where 
the agents’ 
utility 
function 
is defined in deJinition 
4 i$ 
&so, 
. . . . d-1) 
= x* for all (so, . . ..stM1) 
E St, 
if t is 
even, and 
&so, . . . . s”) = { ; 
;;:i 4 ;I 
1 
if t is odd. 
The strategy c of agent B has the same 
structure; 
the roles of x* and y* are reversed, 
the words 
“odd” and “even” are interchanged, 
and each subscript 
A is replaced by B. 
The outcome 
is that A proposes x* 
in period 0 and B immediately 
accepts this o$er. 
Proof: 
Similar to the proof in [Osborne and Rubin- 
stein 19901 with some small modifications. 
Even though the structure 
of the strategic model of 
Alternating 
Offers allows negotiation 
to continue in- 
definitely, in the unique subgame perfect equilibrium 
agreements. 
The strategic 
model of Alternative 
Offers is useful 
here also, if the preferences of the agents satisfy similar 
requirements 
as in the continuity case. An additional 
requirement is that the the length of a single period is 
fixed*. 
Here, we will demonstrate 
this case using the fol- 
lowing example. 
Suppose there are only three possi- 
ble agreements the agents can reach (a, b, c}. 
Let + 
i = A, B denote the preferences of the agents over the 
possible outcomes which satisfy the following assump- 
tions: 
Disagreement is the worst outcome: For every 
nt E 7 and s E {a, b, c}, (s, t) +a D where i E {A, B) 
Conflict of Interests: 
(a,O) %A (b,O) %A (c,O), 
(5 0) +B 
(b, 0) +B 
(a, 0). 
4The discrete case is not usually discussed in the game 
theory community, but see [Muthoo 19891 
KRAUS & WILKENFELD 
181 

Monotonicity 
in Time: 
time is valuable to both 
sides, i.e., for every tl, t2 E 7, 
i E (A, B}, 
and s E 
(a, b,c), iftl 
< t2 (01) 
t-i (02). 
S tationarity: 
preferences 
between 
(~1, tl) 
and 
(9, t2) depend only on sl, sz and the differences be- 
tween tl and t2, i.e. 
for every ~1, s2 E (a, b, c}, 
tl,h,t3 
E 7 i E (A,@ 
(sldl) 
ti (sdl) 
iff(sd) 
ti 
(a, 0) and if (~1, tl) 
t-i (ah 
+ t2) then 
(~1, t3) h:s 
(s19 f3 + t2). 
In addition (a, 1) -A 
(b,0)5 
and (b, 1) -A 
(c,O). 
(%0)-B 
(b, 1),(b,O)-B (c,2). 
Assuming that agent A starJs the negotiations, 
the 
strategies 
from Theorem 
1, (f, g) where x* = a and 
y* = b, is a perfect equilibrium. 
We may also con- 
elude that when the domain is discrete and finite, and 
only a finite number of possible agreements are feasi- 
ble, delay in reaching cooperation 
may be avoided by 
incorporating 
time into the model and by using the 
notion of subgame Perfect Equilibrium. 
The agents can opt out 
Until now we assumed that the agents must continue 
the negotiation 
since disagreement 
was the worst out- 
come to both sides. Let us consider the case in which 
one of the agents has the ability to opt out of the ne- 
gotiation. 
For example, suppose agent A has another 
goal he may satisfy (usually with lower priority); 
he 
can benefit from doing a different job than painting 
the wall; or, in the case in which agents negotiate in 
order to allocate resources and the agents can reach an 
agreement with another agent for another type of re- 
source allocation. 
The threat of leaving the negotiation 
may influence the outcome in some cases. 
We assume that there are W units of the work that 
should be divided by two agents. 
The set of possi- 
ble agreements, S, includes all the pairs (sA, sg) E N2 
where SA +.!?B = W. We modify the negotiation strate- 
gies (Definition 2) such that if agent i receives an offer 
from his partner he can opt out of the negotiation (0), 
in addition to accepting 
the offer (Y) or rejecting 
it 
(N). 
a(f, g), L(f, g), La(f, 
g) and the outcome of the 
negotiations are defined as in the previous sections, but 
La( f, g), which is the last element of a( f, g), can be ei- 
ther s E S or 0. Thus the outcome (0, t) is interpreted 
as one of the agents opting out of the negotiation 
at 
period t. We note that the length of the time periods 
is fixed. The agents’ preferences in this case are over 
agreements reached at various points in time, and over 
opting out at various points in time. 
The conditions 
on the preference 
relations 
of the 
agents are similar 
to those of the previous section. 
First we assume that the least-preferred 
outcome is 
disagreement 
(D). 
(AO) For every s E S and t E 7, 
(s, t) ti 
D and 
(W) 
ti D (D’ 
g 
isa reement is the worst outcome). 
5(a1, tl) pi (~2, tz), i E {A, B) indicates that agent i is 
indifferent between the two outcomes. 
182 
FORMALISMS FOR COORDINATION 
The next two conditions (Al), 
(A2) concern the be- 
havior of +i on S x 7, 
i.e. 
concerning 
agreements 
reached in different time periods. 
Condition (Al) 
re- 
quires that among agreements reached in the same pe- 
riod, agent i prefers smaller numbers of units si. 
(Al) if ri < si, then (r, t) ti (s, t). 
The next assumption greatly simplifies the structure 
of preferences among agreements. 
It requires that pref- 
erences between (~1, tl) and (sz, t2) depend only on 
si, s2 and the differences between tl and t2. 
(A2) For all r, s E S, t, tl, t2, S E N and i E {A, B}, 
(r, tl) ki (s, tl+S) 
iff (r, t2) & (s, t2+S) 
(Stationarity). 
We note that assumption (A2) does not hold for 0. 
We will consider the case in which any agent has a 
number ci > 0 i E {A, B} such that: 
(A3) (s, tl) ki (S, t2) iff si + ci * tl 5 Si + ci * t2. 
We also assume that both agents prefer to opt out 
sooner rather than later. Formally: 
(A4) If tl < tz then (0, tl) +i (0, tz), i E {A, B}. 
We do not make any assumption concerning the pref- 
erences of an agent for opting out versus an agreement. 
This enables us to consider different types of cases of 
opting out. For example, in the “wall painting” case, 
opting out may be giving up the goal, buying a brush 
or covering the wall with wallpaper. Formally, there is 
no fixed s E S such that for every t E 7, (s, t) N (0, t) 
as in [Shaked and Sutton 19841. 
Let us define the “outcome” of opting out as follows: 
Definition 6 For 
every t E 7 
and i E {A, B}, 
let 
Pot+ = (St 1 (St, t) 2-i (0, t)). 
If POS: is not empty we 
h. t 
define s2 
-t 
= minkA{tPosf), 
otherwise 
we define SA = 
(-l,W+l) 
andsB 
=(W+l,-1). 
We would like now to introduce two additional as- 
sumptions 
that will ensure that an agreement 
might 
be reached. 
(A5) For every t E 7 if s 
et+1 
ft 2 0 then (z”, t) +i (St, t) 
and if s* 
2 0 then (s 
i,jE{A,B} 
andi#j. 
7tf1, 
t + 1) >j 
(3’, 
t) where 
Assumption 
(A4) 
ensures that 
if there are some 
agreements agent i prefers in the next period over opt- 
ing out, then there is at least one of those agreements 
that agent j also prefers over opting out in this period. 
An additional assumption is necessary to ensure that 
an agreement is possible at least in the first period. 
(A6) ;ip 2 0 
ii0 is the worst agreement 
for agent i in period 0 
which is still better than opting out. So, the require- 
ment that this agreement will be at least zero, which is 
in S, ensures that there exists at least one agreement 
agent i prefers over opting out. 
In [Kraus and Wilkenfeld 1990b] we have proved that 
under the above assumptions, 
if there exists a period 
when one of the agents will prefer opting out over any 
agreement and the game has not ended in prior periods, 
then an agreement will be reached in the period prior 

to this period. 
This result is the basis to our main 
result in this case, which is described in the following 
theorem. 
Theorem 2 LeZ (f?$) b e a P.E. 
of a model satisbing 
AO-A6such 
that s>:-sGi 
< 2ci+cj, 
i, j E (A, B), i # j. 
If-: 
offers first then P(f?g) 
= ((s?: 
- 1 + CA, W - 
@*A 
- 
1 + 
cA)),o)) 
and if A oglers first P(fl$) 
= 
((W - (2; 
- 1 + CB), 2; 
- If 
cg), 0)) 
Proof: 
The proof of this theorem and the proof of 
Theorem 3 appear in [Kraus and Wilkenfeld 1990b]. 
Example 3 Suppose 
the area to be painted can be di- 
vided into 20 sub-pieces 
only, i.e. W = 20. And let us 
assume 
that cp = 2 and cg = 3. We also assume 
that 
the agent 
with the paint, 
P, 
prefers 
opting 
out over 
painting 
more than 14 pieces 
in the first period, 
i.e., 
s’;;” = (14,6), 
and F1 
= (13,7) 
and s’;;” = (15,5). 
Agent B prefers 
opting out over pzpting 
more than 
11 pieces 
in the first period, 
i.e, 
sB 
= (11,9) 
and 
2’ 
= (9,ll) 
and 3” 
= (8,12). 
If B starts 
the negotiations 
then he will paint 
IO 
pieces and agent A will do 10. If agent P starts then 
agent B will do 9 and agent P will do 11. In both cases 
the negotiations 
will end after the first period. 
Time is valuable only to one side 
Suppose one of the agents does not lose as time goes 
on and even gains at least in the early stages of the 
negotiation, 
For example, 
the agents need to reach 
an agreement 
on sharing a resource, 
but one of the 
agents continues to use this resource until the agree- 
ment is reached. One may suspect that the agent who 
gains over time will try to delay reaching an agree- 
ment. Nevertheless, 
if the other agent can opt out of 
the negotiation, 
agreement can be reached without a 
delay with conditions similar to what the losing agent 
can gain from opting out. (see [Kraus and Wilkenfeld 
199Oa]). 
Since we consider here the case of sharing resources 
we assume that the object is desirable, i.e. condition 
(Al) is as follows: 
(Al) if ri > si, then (T, t) +-i (s, t); 
We also modify condition (A3). 
Each agent has a number ci i E (A, B} such that: 
(A3) (s, tl) ki (S, t2) iff (si + ci + tr) > (Si + ci + t2). 
We assume that agent A gains over t’;me (CA > 0) 
and that agent B loses over time (cg < 0), i.e., agent 
B prefers to obtain any given number of units sooner 
rather than later, while agent A prefers to obtain any 
given number of units later rather than sooner. 
Furthermore, 
we assume that agent B prefers to opt 
out sooner rather than later and vice versa for agent 
A. Formally, 
(A4) if tl < t2 (o,tl) 
%B 
(0, 
t2) and (0, t2) %A 
(Wl). 
We also modify condition (A5). 
. 
, 
(A5) For every t E 7 (s 
At+1 
zt,t) 
+B (sB 
, t + 1) and 
if ~2: 
> 0 then (s zt,t) 
tA (o,t+ 
1). 
Assumption 
(A4) 
ensures that if there are some 
agreements agent B prefers over opting out, then there 
is at least one of those agreements that agent A also 
prefers over opting out in the next period. 
Our main results are summarized 
in the following 
theorem. 
Theorem 3 Let (f^, z) be a P.E. 
of a model sE:fy- 
ing AO-A6. 
Suppose 
agent B o#ers first and sBA - 
s3” 
-1 
A 
< 
CA* 
If ICBl 2 
CA + 
1, 
then 
P(f?z) 
= 
((33, 
+ 1 + CA& 
-I--cA),o) 
IfIcBj 
< 
cA+l, 
then P(A 5) = ((2:, 
FL), 
1). 
If A is the first agent then P(f^, $) = ((21, 
zi), 
0). 
The Application 
of the Theory 
in 
uilding Autonomous 
Agents 
How can one use the above theoretical results in build- 
ing agents capable of acting and negotiating under time 
constraints 
and complete information? 
We note that in each of the cases we have inves- 
tigated, 
the perfect-equilibrium 
strategies 
are deter- 
mined by parameters 
of the situation. 
For example, 
in the case in which the agents have utility functions 
with time constants 
discount rate the strategies 
are 
determined by those discount factors (6i). 
Or, for ex- 
ample, in the case in which the agents can opt out and 
they have constant delays (ci), the strategies 
depend 
on the constant delays and the worst agreement for a 
player which is still better for him than opting out in 
period one (Gl). 
So, one can supply agents with the appropriate 
strategies 
for each of the cases we have dealt with. 
When the agent participates 
in one of those situations, 
he will need to recognize which type of situation it is. 
Assuming the agent is given the appropriate arguments 
about the situation it is involved in (i.e. in the case the 
agents have utility functions with time constants what 
is the value of Si), he can construct the exact strategy 
for its specific case and use it in the negotiations. 
Since 
we provide the agents with unique perfect equilibrium 
strategies, 
if we announce it to the other agents in the 
environment, 
the other agents can not do better than 
to use their similar strategies. 
Conclusion 
and Future Work 
We have demonstrated 
how the incorporation 
of time 
into the negotiation 
procedure contributes 
to a more 
efficient negotiation 
process. 
We show that in differ- 
ent cases this model, together with the assumptions of 
KRAUS & WILKENFELD 
183 

complete information 
and that the agents’ strategies 
induce an equilibrium in any stage of the negotiation, 
may result in the agent being able to use negotiation 
strategies that will end the negotiation without a delay. 
We suggest that these results are useful in particular in 
situations with time constraints. 
We are in the process 
of using this model in developing agents that will par- 
ticipate in crisis situations where time is an important 
issues. 
The most obvious outstanding question concerns the 
relaxation of the assumption of complete information. 
In many situations 
the agents do not have full infor- 
mation concerning the other agents. 
Several works in 
game theory and economics have considered different 
versions of the model of Alternative 
Offers with incom- 
plete information. 
(See for example, [Rubinstein 
1985; 
Osborne and Rubinstein 
1990; Chatterjee 
and Samuel- 
son 19871). W e are in the process of modifying those 
results for use in DA1 environments. 
Acknowledgement 
We would like to thank 
K. 
Arrow, 
R. 
Aumann, 
B. Bueno de Mesquita, 
J. Oppenheimer, 
A. Rubin- 
stein and P. Young for helpful suggestions about game 
theory and negotiation. 
We would also like to thank 
J. Hendler and D. Perlis for helpful discussions. 
References 
Bond, A. H. and Gasser, 
L. 1988. 
An analysis of 
problems 
and research 
in DAI. 
In Bond, 
A. H. 
and Gasser, L., editors, Readings 
in Distributed 
Ar- 
tificial Intelligence. 
Morgan Kaufmann 
Publishers, 
Inc., San Mateo, California. 
3-35. 
Chatterjee, 
K. and Samuelson, 
L. 1987. 
Bargain- 
ing with two-sided incomplete 
information: 
An in- 
finite horizon model with alternating 
offers. Review 
of Economic 
Studies 54:175-192. 
Conry, 
S. E.; 
Meyer, 
R. A.; 
and Lesser, 
V. R. 
1988. 
Multistage 
negotiation 
in distributed 
plan- 
ning. In Bond, A. H. and Gasser, L., editors, Read- 
ings in Distributed 
Artificial 
Intelligence. 
Morgan 
Kaufmann 
Publishers, 
Inc., San Mateo, California. 
367-384. 
Davis, R. and Smith, R.G. 
1983. 
Negotiation 
as a 
metaphor for distributed problems solving. Artificial 
Intelligence 
20:63-109. 
Durfee, 
E. H. 1988. 
Coordination 
of Distributed 
Problem 
Solvers. 
Kluwer 
Academic 
Publishers, 
Boston. 
Georgeff, M. 1983. Communication 
and interaction 
in a multi-agent planning. In Proc. AAAI-83, 
Wash- 
ington, D.C. 125-129. 
Kraus, S. and Wilkenfeld, J. 1990a. 
An automated 
strategic 
model of negotiation: 
Extended 
abstract. 
In AAAI-90 
Workshop 
on Reasoning 
in Adversarial 
Domains, 
Boston. 
Kraus, S. and Wilkenfeld, J. 1990b. The function of 
time in cooperative 
negotiations. 
Technical 
Report 
IJMIACS 
TR 90-131 CS TR 2547, Institute for Ad- 
vanced Computer Studies, University of Maryland. 
Kraus, S. and Wilkenfeld, J. 1991. Negotiations over 
time in a multi agent environment: 
Preliminary 
re- 
port. In Proc. 
of IJCAI-91, 
Australia. 
To appear. 
Kraus, S.; Ephrati, 
E.; and Lehmann, D. 1991. Ne- 
gotiation in a non-cooperative 
environment. 
Jour- 
nal of Experimental 
and Theoretical 
Artificial 
Intel- 
ligence. 
Accepted for publication. 
Lute, R. D. and Raiffa, H. 1957. 
Games 
and Deci- 
sions. John Wiley and Sons. 
Malone, T. W.; Fikes, R. E.; and Howard, M. T. 
1988. 
Enterprise: 
A marketlike 
task schedule for 
distributed computing environments. 
In Huberman, 
B. A., editor 1988, 
The 
Ecology 
of Computation. 
North Holland. 
Muthoo, A. 1989. A note on bargaining over a finite 
number of feasible agreements. 
Unpublished paper, 
Department 
of Economics, 
University of Bristol. 
Nash, J. F. 1953. 
Two-person 
cooperative 
games. 
Econometrica 
21:128-140. 
Osborne, M. J. and Rubinstein, 
A. 1990. Bargaining 
and Markets. 
Academic Press Inc., California. 
Raiffa, H. 1982. The Art and Science 
of Negotiation. 
Harvard University Press. 
Rosenschein, 
J. and Genesereth, 
M.R. 1985. 
Deals 
among rational agents. 
In Proc. of IJCAI-85, 
Los 
Angeles, California. 
91-99. 
Rubinstein, 
A. 1982. 
Perfect equilibrium 
in a bar- 
gaining model. Econometrica 
50( 1):97-109. 
Rubinstein, 
A. 1985. 
A bargaining 
model with in- 
complete information about preferences. 
Economet- 
rica 53(5):1151-1172. 
Sathi, A. and Fox, M. S. 1989. Constraint-directed 
negotiation of resource reallocations. 
In r, L. Gasse 
and Huhns, M. N., editors, Distributed 
Artificial 
In- 
telligence, 
Volume 
II. Pitman/Morgan 
Kaufmann, 
London. 163-194. 
Shaked, A. and Sutton, J. 1984. Involuntary unem- 
ployment as a perfect equilibrium 
in a bargaining 
model. Econometrica 
52(6):1351-1364. 
Sycara, K.P 1987. 
Resolving 
Adversarial 
Conflicts: 
An Approach 
to Integrating 
Case-Based 
and Ana- 
lytic Methods. 
Ph.D. Dissertation, 
School of Infor- 
mation and Computer Science, Georgia Institute 
of 
Technology. 
Zlotkin, G. and Rosenschein, 
J. 1990. 
Negotiation 
and conflict resolution in non-cooperative 
domains. 
In Proceedings 
of AAAI-90, 
BostonMA. 
100-105. 
184 
FORMALISMS FOR COORDINATION 

