Quantum Physics
Eric D’Hoker
Department of Physics and Astronomy,
University of California, Los Angeles, CA 90095, USA
15 September 2012
1

Contents
1
Introduction
12
1.1
Brief History
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.2
Constants of Nature
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
1.3
Scales
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
1.4
Reductionism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2
Two-state quantum systems
16
2.1
Polarization of light . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.2
Polarization of photons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.3
General parametrization of the polarization of light . . . . . . . . . . . . . .
20
2.4
Mathematical formulation of the photon system . . . . . . . . . . . . . . . .
20
2.5
The Stern-Gerlach experiment on electron spin . . . . . . . . . . . . . . . . .
22
3
Mathematical Formalism of Quantum Physics
26
3.1
Hilbert spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
3.1.1
Triangle and Schwarz Inequalities . . . . . . . . . . . . . . . . . . . .
27
3.1.2
The construction of an orthonormal basis . . . . . . . . . . . . . . . .
27
3.1.3
Decomposition of an arbitrary vector . . . . . . . . . . . . . . . . . .
28
3.1.4
Finite-dimensional Hilbert spaces . . . . . . . . . . . . . . . . . . . .
29
3.1.5
Inﬁnite-dimensional Hilbert spaces
. . . . . . . . . . . . . . . . . . .
29
3.2
Linear operators on Hilbert space . . . . . . . . . . . . . . . . . . . . . . . .
31
3.2.1
Operators in ﬁnite-dimensional Hilbert spaces . . . . . . . . . . . . .
31
3.2.2
Operators in inﬁnite-dimensional Hilbert spaces . . . . . . . . . . . .
31
3.3
Special types of operators
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
3.4
Hermitian and unitary operators in ﬁnite-dimension . . . . . . . . . . . . . .
34
3.4.1
Unitary operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.4.2
The exponential map . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.5
Self-adjoint operators in inﬁnite-dimensional Hilbert spaces . . . . . . . . . .
37
4
The Principles of Quantum Physics
38
4.1
Conservation of probability . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
4.2
Compatible versus incompatible observables
. . . . . . . . . . . . . . . . . .
39
4.3
Expectation values and quantum ﬂuctuations
. . . . . . . . . . . . . . . . .
41
4.4
Incompatible observables, Heisenberg uncertainty relations . . . . . . . . . .
41
4.5
Complete sets of commuting observables
. . . . . . . . . . . . . . . . . . . .
43
2

5
Some Basic Examples of Quantum Systems
44
5.1
Propagation in a ﬁnite 1-dimensional lattice . . . . . . . . . . . . . . . . . .
44
5.1.1
Diagonalizing the translation operator
. . . . . . . . . . . . . . . . .
45
5.1.2
Position and translation operator algebra . . . . . . . . . . . . . . . .
46
5.1.3
The spectrum and generalized Hamiltonians . . . . . . . . . . . . . .
47
5.1.4
Bilateral and reﬂection symmetric lattices
. . . . . . . . . . . . . . .
47
5.2
Propagation in an inﬁnite 1-dimensional lattice
. . . . . . . . . . . . . . . .
48
5.3
Propagation on a circle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
5.4
Propagation on the full line
. . . . . . . . . . . . . . . . . . . . . . . . . . .
51
5.4.1
The Dirac δ-function . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
5.5
General position and momentum operators and eigenstates . . . . . . . . . .
53
5.6
The harmonic oscillator
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
5.6.1
Lowering and Raising operators . . . . . . . . . . . . . . . . . . . . .
56
5.6.2
Constructing the spectrum . . . . . . . . . . . . . . . . . . . . . . . .
57
5.6.3
Harmonic oscillator wave functions
. . . . . . . . . . . . . . . . . . .
57
5.7
The angular momentum algebra . . . . . . . . . . . . . . . . . . . . . . . . .
58
5.7.1
Complete set of commuting observables . . . . . . . . . . . . . . . . .
59
5.7.2
Lowering and raising operators
. . . . . . . . . . . . . . . . . . . . .
59
5.7.3
Constructing the spectrum . . . . . . . . . . . . . . . . . . . . . . . .
60
5.8
The Coulomb problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
5.8.1
Bound state spectrum
. . . . . . . . . . . . . . . . . . . . . . . . . .
62
5.8.2
Scattering spectrum
. . . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.9
Self-adjoint operators and boundary conditions . . . . . . . . . . . . . . . . .
64
5.9.1
Example 1:
One-dimensional Schr¨odinger operator on half-line . . .
64
5.9.2
Example 2:
One-dimensional momentum in a box . . . . . . . . . .
65
5.9.3
Example 3:
One-dimensional Dirac-like operator in a box . . . . . .
67
6
Quantum Mechanics Systems
68
6.1
Lagrangian mechanics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
6.2
Hamiltonian mechanics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
6.3
Constructing a quantum system from classical mechanics . . . . . . . . . . .
71
6.4
Schr¨odinger equation with a scalar potential . . . . . . . . . . . . . . . . . .
72
6.5
Uniqueness questions of the correspondence principle
. . . . . . . . . . . . .
73
7
Charged particle in an electro-magnetic ﬁeld
74
7.1
Gauge transformations and gauge invariance . . . . . . . . . . . . . . . . . .
74
7.2
Constant Magnetic ﬁelds . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
7.2.1
Map onto harmonic oscillators . . . . . . . . . . . . . . . . . . . . . .
76
7.3
Landau Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
7.3.1
Complex variables
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
3

7.4
The Aharonov-Bohm Eﬀect
. . . . . . . . . . . . . . . . . . . . . . . . . . .
79
7.4.1
The scattering Aharonov-Bohm eﬀect . . . . . . . . . . . . . . . . . .
79
7.4.2
The bound state Aharonov-Bohm eﬀect . . . . . . . . . . . . . . . . .
81
7.5
The Dirac magnetic monopole . . . . . . . . . . . . . . . . . . . . . . . . . .
83
8
Theory of Angular Momentum
86
8.1
Rotations
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
8.2
The Lie algebra of rotations – angular momentum . . . . . . . . . . . . . . .
88
8.3
General Groups and their Representations . . . . . . . . . . . . . . . . . . .
88
8.4
General Lie Algebras and their Representations
. . . . . . . . . . . . . . . .
89
8.5
Direct sum and reducibility of representations . . . . . . . . . . . . . . . . .
90
8.6
The irreducible representations of angular momentum . . . . . . . . . . . . .
90
8.7
Addition of two spin 1/2 angular momenta . . . . . . . . . . . . . . . . . . .
92
8.8
Addition of a spin 1/2 with a general angular momentum . . . . . . . . . . .
94
8.9
Addition of two general angular momenta
. . . . . . . . . . . . . . . . . . .
96
8.10 Systematics of Clebsch-Gordan coeﬃcients . . . . . . . . . . . . . . . . . . .
97
8.11 Spin Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
8.12 The Ising Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
8.13 Solution of the 1-dimensional Ising Model
. . . . . . . . . . . . . . . . . . .
100
8.14 Ordered versus disordered phases . . . . . . . . . . . . . . . . . . . . . . . .
102
9
Symmetries in Quantum Physics
104
9.1
Symmetries in classical mechanics . . . . . . . . . . . . . . . . . . . . . . . .
104
9.2
Noether’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
106
9.3
Group and Lie algebra structure of classical symmetries . . . . . . . . . . . .
107
9.4
Symmetries in Quantum Physics . . . . . . . . . . . . . . . . . . . . . . . . .
108
9.5
Examples of quantum symmetries . . . . . . . . . . . . . . . . . . . . . . . .
110
9.6
Symmetries of the multi-dimensional harmonic oscillator
. . . . . . . . . . .
110
9.6.1
The orthogonal group SO(N) . . . . . . . . . . . . . . . . . . . . . .
111
9.6.2
The unitary groups U(N) and SU(N)
. . . . . . . . . . . . . . . . .
113
9.6.3
The group Sp(2N) . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
9.7
Selection rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
9.8
Vector Observables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
9.9
Selection rules for vector observables
. . . . . . . . . . . . . . . . . . . . . .
118
9.10 Tensor Observables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
9.11 P, C, and T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
10 Bound State Perturbation Theory
124
10.1 The validity of perturbation theory . . . . . . . . . . . . . . . . . . . . . . .
125
10.1.1 Smallness of the coupling . . . . . . . . . . . . . . . . . . . . . . . . .
125
4

10.1.2 Convergence of the expansion for ﬁnite-dimensional systems
. . . . .
126
10.1.3 The asymptotic nature of the expansion for inﬁnite dimensional systems126
10.2 Non-degenerate perturbation theory . . . . . . . . . . . . . . . . . . . . . . .
128
10.3 Some linear algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
131
10.4 The Stark eﬀect for the ground state of the Hydrogen atom . . . . . . . . . .
132
10.5 Excited states and degenerate perturbation theory . . . . . . . . . . . . . . .
133
10.6 The Zeeman eﬀect
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
10.7 Spin orbit coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
10.8 General development of degenerate perturbation theory . . . . . . . . . . . .
135
10.8.1 Solution to ﬁrst order . . . . . . . . . . . . . . . . . . . . . . . . . . .
136
10.8.2 Solution to second order . . . . . . . . . . . . . . . . . . . . . . . . .
137
10.9 Periodic potentials and the formation of band structure . . . . . . . . . . . .
138
10.10Level Crossing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
11 External Magnetic Field Problems
142
11.1 Landau levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
11.2 Complex variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
11.3 Calculation of the density of states in each Landau level
. . . . . . . . . . .
145
11.4 The classical Hall eﬀect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
145
11.5 The quantum Hall eﬀect . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
146
12 Scattering Theory
151
12.1 Potential Scattering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
152
12.2 The iε prescription . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
153
12.3 The free particle propagator . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
12.4 The Lippmann-Schwinger equation in position space . . . . . . . . . . . . . .
155
12.5 Short range versus long range V and massless particles . . . . . . . . . . . .
156
12.6 The wave-function solution far from the target . . . . . . . . . . . . . . . . .
157
12.7 Calculation of the cross section
. . . . . . . . . . . . . . . . . . . . . . . . .
157
12.8 The Born approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
159
12.8.1 The case of the Coulomb potential
. . . . . . . . . . . . . . . . . . .
160
12.8.2 The case of the Yukawa potential . . . . . . . . . . . . . . . . . . . .
161
12.9 The optical Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
161
12.10Spherical potentials and partial wave expansion
. . . . . . . . . . . . . . . .
162
12.10.1Bessel Functions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
163
12.10.2Partial wave expansion of wave functions . . . . . . . . . . . . . . . .
164
12.10.3Calculating the radial Green function . . . . . . . . . . . . . . . . . .
165
12.11Phase shifts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
166
12.12The example of a hard sphere . . . . . . . . . . . . . . . . . . . . . . . . . .
168
12.13The hard spherical shell
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
170
5

12.14Resonance scattering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
13 Time-dependent Processes
173
13.1 Magnetic spin resonance and driven two-state systems . . . . . . . . . . . . .
173
13.2 The interaction picture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
13.3 Time-dependent perturbation theory
. . . . . . . . . . . . . . . . . . . . . .
177
13.4 Switching on an interaction
. . . . . . . . . . . . . . . . . . . . . . . . . . .
178
13.5 Sinusoidal perturbation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
180
14 Path Integral Formulation of Quantum Mechanics
181
14.1 The time-evolution operator . . . . . . . . . . . . . . . . . . . . . . . . . . .
181
14.2 The evolution operator for quantum mechanical systems
. . . . . . . . . . .
182
14.3 The evolution operator for a free massive particle
. . . . . . . . . . . . . . .
183
14.4 Derivation of the path integral . . . . . . . . . . . . . . . . . . . . . . . . . .
184
14.5 Integrating out the canonical momentum p . . . . . . . . . . . . . . . . . . .
187
14.6 Dominant paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
188
14.7 Stationary phase approximation . . . . . . . . . . . . . . . . . . . . . . . . .
188
14.8 Gaussian ﬂuctuations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
189
14.9 Gaussian integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
14.10Evaluating the contribution of Gaussian ﬂuctuations
. . . . . . . . . . . . .
191
15 Applications and Examples of Path Integrals
193
15.1 Path integral calculation for the harmonic oscillator . . . . . . . . . . . . . .
193
15.2 The Aharonov-Bohm Eﬀect
. . . . . . . . . . . . . . . . . . . . . . . . . . .
195
15.3 Imaginary time path Integrals . . . . . . . . . . . . . . . . . . . . . . . . . .
197
15.4 Quantum Statistical Mechanics
. . . . . . . . . . . . . . . . . . . . . . . . .
198
15.5 Path integral formulation of quantum statistical mechanics . . . . . . . . . .
199
15.6 Classical Statistical Mechanics as the high temperature limit . . . . . . . . .
200
16 Mixtures and Statistical Entropy
202
16.1 Polarized versus unpolarized beams . . . . . . . . . . . . . . . . . . . . . . .
202
16.2 The Density Operator
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
203
16.2.1 Ensemble averages of expectation values in mixtures . . . . . . . . . .
205
16.2.2 Time evolution of the density operator . . . . . . . . . . . . . . . . .
205
16.3 Example of the two-state system
. . . . . . . . . . . . . . . . . . . . . . . .
205
16.4 Non-uniqueness of state preparation . . . . . . . . . . . . . . . . . . . . . . .
207
16.5 Quantum Statistical Mechanics
. . . . . . . . . . . . . . . . . . . . . . . . .
208
16.5.1 Generalized equilibrium ensembles . . . . . . . . . . . . . . . . . . . .
209
16.6 Classical information and Shannon entropy
. . . . . . . . . . . . . . . . . .
210
16.7 Quantum statistical entropy . . . . . . . . . . . . . . . . . . . . . . . . . . .
211
6

16.7.1 Density matrix for a subsystem . . . . . . . . . . . . . . . . . . . . .
213
16.7.2 Example of relations between density matrices of subsystems . . . . .
213
16.7.3 Lemma 1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
214
16.7.4 Completing the proof of subadditivity . . . . . . . . . . . . . . . . . .
216
16.8 Examples of the use of statistical entropy . . . . . . . . . . . . . . . . . . . .
217
16.8.1 Second law of thermodynamics
. . . . . . . . . . . . . . . . . . . . .
218
16.8.2 Entropy resulting from coarse graining . . . . . . . . . . . . . . . . .
218
17 Entanglement, EPR, and Bell’s inequalities
219
17.1 Entangled States for two spin 1/2
. . . . . . . . . . . . . . . . . . . . . . .
219
17.2 Entangled states from non-entangled states . . . . . . . . . . . . . . . . . . .
221
17.3 The Schmidt puriﬁcation theorem . . . . . . . . . . . . . . . . . . . . . . . .
222
17.4 Generalized description of entangled states . . . . . . . . . . . . . . . . . . .
223
17.5 Entanglement entropy
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
224
17.6 The two-state system once more . . . . . . . . . . . . . . . . . . . . . . . . .
224
17.7 Entanglement in the EPR paradox
. . . . . . . . . . . . . . . . . . . . . . .
225
17.8 Einstein’s locality principle . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
17.9 Bell’s inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
17.10Quantum predictions for Bell’s inequalities . . . . . . . . . . . . . . . . . . .
229
17.11Three particle entangled states . . . . . . . . . . . . . . . . . . . . . . . . . .
232
18 Introductory Remarks on Quantized Fields
234
18.1 Relativity and quantum mechanics
. . . . . . . . . . . . . . . . . . . . . . .
235
18.2 Why Quantum Field Theory ? . . . . . . . . . . . . . . . . . . . . . . . . . .
235
18.3 Further conceptual changes required by relativity
. . . . . . . . . . . . . . .
236
18.4 Some History and present signiﬁcance of QFT . . . . . . . . . . . . . . . . .
237
19 Quantization of the Free Electro-magnetic Field
239
19.1 Classical Maxwell theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
239
19.2 Fourrier modes and radiation oscillators
. . . . . . . . . . . . . . . . . . . .
241
19.3 The Hamiltonian in terms of radiation oscillators
. . . . . . . . . . . . . . .
242
19.4 Momentum in terms of radiation oscillators . . . . . . . . . . . . . . . . . . .
245
19.5 Canonical quantization of electro-magnetic ﬁelds . . . . . . . . . . . . . . . .
245
19.6 Photons – the Hilbert space of states . . . . . . . . . . . . . . . . . . . . . .
246
19.6.1 The ground state or vacuum . . . . . . . . . . . . . . . . . . . . . . .
246
19.6.2 One-photon states
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
247
19.6.3 Multi-photon states . . . . . . . . . . . . . . . . . . . . . . . . . . . .
247
19.7 Bose-Einstein and Fermi-Dirac statistics
. . . . . . . . . . . . . . . . . . . .
249
19.8 The photon spin and helicity . . . . . . . . . . . . . . . . . . . . . . . . . . .
251
19.9 The Casimir Eﬀect on parallel plates . . . . . . . . . . . . . . . . . . . . . .
253
7

20 Photon Emission and Absorption
257
20.1 Setting up the general problem of photon emission/absorption . . . . . . . .
257
20.2 Single Photon Emission/Absorption . . . . . . . . . . . . . . . . . . . . . . .
258
20.3 Application to the decay rate of 2p state of atomic Hydrogen . . . . . . . . .
261
20.4 Absorption and emission of photons in a cavity
. . . . . . . . . . . . . . . .
261
20.5 Black-body radiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
263
21 Relativistic Field Equations
266
21.1 A brief review of special relativity . . . . . . . . . . . . . . . . . . . . . . . .
266
21.2 Lorentz vector and tensor notation
. . . . . . . . . . . . . . . . . . . . . . .
268
21.3 General Lorentz vectors and tensors . . . . . . . . . . . . . . . . . . . . . . .
269
21.3.1 Contravariant tensors . . . . . . . . . . . . . . . . . . . . . . . . . . .
269
21.3.2 Covariant tensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
270
21.3.3 Contraction and trace
. . . . . . . . . . . . . . . . . . . . . . . . . .
271
21.4 Classical relativistic kinematics and dynamics
. . . . . . . . . . . . . . . . .
271
21.5 Particle collider versus ﬁxed target experiments
. . . . . . . . . . . . . . . .
272
21.6 A physical application of time dilation
. . . . . . . . . . . . . . . . . . . . .
273
21.7 Relativistic invariance of the wave equation . . . . . . . . . . . . . . . . . . .
273
21.8 Relativistic invariance of Maxwell equations
. . . . . . . . . . . . . . . . . .
274
21.8.1 The gauge ﬁeld and ﬁeld strength . . . . . . . . . . . . . . . . . . . .
274
21.8.2 Maxwell’s equations in Lorentz covariant form . . . . . . . . . . . . .
275
21.9 Structure of the Poincar´e and Lorentz algebras . . . . . . . . . . . . . . . . .
277
21.10Representations of the Lorentz algebra . . . . . . . . . . . . . . . . . . . . .
279
22 The Dirac Field and the Dirac Equation
282
22.1 The Dirac-Cliﬀord algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . .
282
22.2 Explicit representation of the Dirac algebra . . . . . . . . . . . . . . . . . . .
284
22.3 Action of Lorentz transformations on γ-matrices . . . . . . . . . . . . . . . .
285
22.4 The Dirac equation and its relativistic invariance
. . . . . . . . . . . . . . .
286
22.5 Elementary solutions to the free Dirac equation
. . . . . . . . . . . . . . . .
288
22.6 The conserved current of fermion number . . . . . . . . . . . . . . . . . . . .
289
22.7 The free Dirac action and Hamiltonian . . . . . . . . . . . . . . . . . . . . .
291
22.8 Coupling to the electro-magnetic ﬁeld . . . . . . . . . . . . . . . . . . . . . .
291
23 Quantization of the Dirac Field
293
23.1 The basic free ﬁeld solution
. . . . . . . . . . . . . . . . . . . . . . . . . . .
293
23.2 Spinor Identities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
295
23.3 Evaluation of the electric charge operator and Hamiltonian . . . . . . . . . .
297
23.4 Quantization of fermion oscillators
. . . . . . . . . . . . . . . . . . . . . . .
298
23.5 Canonical anti-commutation relations for the Dirac ﬁeld
. . . . . . . . . . .
298
8

23.6 The fermion propagator
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
299
23.7 The concept of vacuum polarization . . . . . . . . . . . . . . . . . . . . . . .
300
Acknowledgements
It is a pleasure to thank John Estes, Yu Guo, Robert Maloney, Antonio Russo, Josh
Samani, and Jie Zhang for suggesting various useful corrections and clariﬁcations.
9

Bibliography
Course textbook
• Modern Quantum Mechanics, J.J. Sakurai, Revised Edition, Addison-Wesley (1994)
Reference on Classical Mechanics
• Classical Mechanics, H. Goldstein, Addison Wesley, (1980);
References on undergraduate Quantum Mechanics
• Introduction to Quantum Mechanics, D.J. Griﬃths, Pearson Prentice Hall (2005);
• The Feynman Lectures of Physics, Vol III, R.P Feynman, R.B. Leighton and M. Sands,
Addison-Wesley, (1965);
General References on Quantum Mechanics
• Quantum Physics, M. Le Bellac, Cambridge University Press (2006);
• Principles of Quantum Mechanics, R. Shankar, Plenum (1980);
• Quantum Mechanics, E. Abers, Pearson Prentice Hall (2004);
Classics
• The Principles of Quantum Mechanics, P.A.M. Dirac, Oxford (1968);
• Quantum Mechanics, Non-relativistic Theory, Course in Theoretical Physics, Vol 3,
L. Landau and E. Lifschitz, Butterworth Heinemann, (2004);
• Quantum Mechanics, C. Cohen-Tannoudji, B. Diu and F. Laloe, I & II, Wiley (1977),
[a very thorough classic, with extensive applications];
• Quantum Mechanics and Path Integrals, R.P. Feynman and A. Hibbs, MacGraw Hill;
• Quantum Mechanics, J. Schwinger, Springer Verlag (2001);
• Introduction to Quantum Mechanics, Vol I, K. Gottfried, Benjamin (1966);
Historical Developments
• The Conceptual Development of Quantum Mechanics, Max Jammer, McGraw Hill,
(1966), [a superb treatise on the foundations of quantum mechanics];
• Inward Bound; On Matter and Forces in the Physical World, A. Pais, Oxford, (1986);
10

Quantum Information
• Quantum Information and Quantum Computation, M. Le Bellac, Cambridge (2006);
• Quantum Computation, http://www.theory.caltech.edu/ preskill/ (1999).
Mathematics useful for quantum physics
• The Theory of groups and Quantum Mechanics, Hermann Weyl, 1931, reprinted by
Dover;
• Geometry, Topology and Physics, M. Nakahara, INstitute of Physics Publishing (IOP),
(1989) reprinted 2005;
• The Geometry of Physics, An Introduction, Theodore Frankel, Cambridge University
Press, 2004.
11

1
Introduction
Ancient Greek philosophers used to speculate (as early as 500 BC) on whether matter could
be divided at inﬁnitum or whether every material has a smallest part that still shares its
properties, the atom (or more generally, the molecule). It took until the late 19-th century to
answer this question aﬃrmatively and decisively, mostly via chemistry, statistical mechanics
and ﬁnally Brownian motion. Feynman was once asked the following question by a reporter:
if we wanted to send a single message to extra-terrestrial life, showing the achievements of
mankind on earth, what would it be ? His reply was “matter is composed of atoms”.
While a century ago, it was conclusively established that all matter is composed of atoms,
it remained an open question as to what atoms themselves looked like, and if they themselves
were composites of smaller parts, but whose nature is no longer the same as the atom itself.
Of course, we now know that atoms are composed of a nucleus and electrons, and that the
nucleus in turn is built from protons and neutrons, themselves built out of quarks and gluons.
Constructing a viable model for the electronic structure of atoms is what originally and
primarily drove the development of quantum mechanics. The existence and stability of atoms
is a purely quantum mechanical eﬀect. Without the Pauli exclusion principle and the shell
structure of electrons, we would loose the chemical and physical properties that distinguish
diﬀerent elements in the Mendeleev table, and there would be no chemistry as we know it.
Similarly, the molecular and collective properties of conductors and insulators of heat and
electricity have quantum origins, as do the semi-conductors used in building transistors and
integrated circuits. Atomic and molecular spectral lines, observed from distant stars and
nebulae, have allowed astronomers to conclude that the visible matter in the universe at
large is the same as that found on earth. The systematic displacements of these lines inform
us on the velocities and the distances of these objects. In summary, quantum physics and
quantum phenomena are pervasive in modern science and technology.
1.1
Brief History
Physics known at the end of the 19-th century falls into three ﬁelds,
• classical mechanics (Newton, Euler, Lagrange, Hamilton, Leverrier, ...)
• electro-magnetism (Coulomb, Faraday, Amp`ere, Gauss, Maxwell, Lorentz, ...)
• statistical mechanics and thermodynamics (Joule, Carnot, Boltzmann, ...)
Around that time, Lord Kelvin apparently stated that physics just had a few loose ends to
tie up, and that physics would be complete by 1900. Nothing
about by special relativity, which was invented to resolve a conﬂict between electro-
magnetism and mechanics, and in doing so profoundly altered our concepts of space and
time.
12

The most radical revolution, however, was quantum mechanics. The key experiments
that were crucial in the development of quantum theory may be summarized as follows,
• discrete emission and absorption spectra of simple atoms (Balmer, ...);
• existence of radioactivity (Becquerel 1896);
• frequency dependence of back body radiation (Planck 1900);
• photo-electric eﬀect (Einstein 1905);
• existence of a hard core (i.e. the nucleus) inside atoms (Rutherford 1909);
• incompatibility of the planetary atom with classical electrodynamics (Bohr 1913);
• discovery of strong and weak forces (Rutherford 1920);
• electrons diﬀract just as light does (de Broglie 1923);
• need for a Pauli exclusion principle in the Bohr model of atoms (Pauli 1925);
• Goudsmit and Uhlenbeck discover spin (1925).
This wealth of novel experimental facts and their apparent contradiction with (classical
mechanics and electromagnetic) theory led to the formal development of quantum mechanics,
• 1925 : Heisenberg introduces matrix mechanics, and quantized the harmonic oscillator;
• 1926 : Schr¨odinger invents wave mechanics (inspired by de Broglie’s particle/wave
duality), and shows the equivalence of matrix and wave mechanics;
• 1927 : Dirac gives what is to be the present day formulation of quantum mechanics.
Subsequent developments include primarily the development of quantum ﬁeld theory, a the-
ory which uniﬁes quantum mechanics and special relativity. Its foundations were laid in
1928 by Dirac, Heisenberg and Pauli, but its elaboration continues actively still today. It
is important to realize though that there has been no serious need since 1927 to alter the
fundamental principles of quantum mechanics, either for experimental or theoretical reasons.
For extensive accounts of the history and conceptual development of quantum mechanics,
the reader is referred to the books by Jammer and by Pais.
1.2
Constants of Nature
There are three fundamental dimensionful constants in Nature: the speed of light c, Planck’s
constant ¯h = h/2π, and Newton’s constant of gravity GN. Their values are given by
c
=
2.99792 × 108 m/s
¯h
=
1.05457 × 10−34 Js
GN
=
6.6732 × 10−11 Jm/(kg)2
13

Instead of Joules (J), one often uses electron-volts (eV ) to express energy; the two are related
by 1 eV = 1.60219 × 10−19 J. All other dimensionful constants are either artifacts of the
units used (such as the Boltzmann constant kB, which converts temperature to energy by
kBT) or composites (such as Stefan-Boltzmann’s constant σ = π2k4
B/60c2¯h3).
Using c to convert a frequency ν into a wavelength λ by λ = c/ν and vice-versa, and ¯h
to convert frequency into energy E by E = hν and vice-versa, all length scales, times and
energies may be converted into one another. Finally, with the help of Einstein’s relation
E = mc2, we may also convert a rest mass m into an energy E. It is therefore common
practice to describe masses, times and length-scales all in eV .
The role of Newton’s gravitational constant GN is actually to set an absolute scale (the
so-called Planck scale) of energy EP, (and thus of mass, length, and time), whose value is
EP = (¯hc/GN)1/2 = 1.22×1019 GeV . This energy scale is very much larger than the highest
energies reachable by particle accelerators today (only about 103 GeV ), and corresponds to
and energy where quantum eﬀects in gravity become strong. In this course, gravitational
eﬀects will always be neglected.
1.3
Scales
The orders of magnitude of the length scales of the known world are as follows,
Object
size in m
known Universe
1026
Milky Way
1021
Earth’s orbit around Sun
1011
Earth
107
human
1
grain of salt
10−4
wavelength of visible light
5 × 10−7
atom
10−10
Lead nucleus
10−14
strong interaction scale (mass of the proton)
10−15
weak interaction scale (mass of W ±/Z)
10−17
Planck length
10−34
Quantum mechanics is crucial to understand physics at atomic scales and smaller, but
may also govern certain larger objects. The macroscopic structure of a neutron star, for
example, is quantum mechanical. To date, there appear to be no compelling experimental
results that vitiate the validity of quantum mechanics at all length scales.
14

1.4
Reductionism
The success of modern science, including physics, is due to ever advancing experimentation,
as well as to the success of the reductionist approach to understanding the Universe. The
basic assumption is that the behavior of larger objects may be determined, at least in prin-
ciple, in terms of the dynamics and interactions of its constituents. Thus, the structure of a
molecule can be understood in terms of the dynamics of the atoms out of which it is built.
The structure of the atoms and the strength of their mutual interactions can, in principle,
be calculated from the quantum electro-dynamics of electrons and nuclei. The structure of
the nuclei is governed by the strong and electro-magnetic forces between their proton and
neutron constituents, whose own structure may be understood in terms of quarks and gluons.
Does this mean that we need to control the dynamics of quarks and gluons in order
to understand semi-conductors, for example ? Remarkably, the answer is no, at least in
most circumstances. The reason is that physics at two widely diﬀerent length scales (or
equivalently energy scales) tends to decouple from one another. For most of chemistry, you
do not need to know the detailed nuclear structure of the atoms in the molecules, and it is
enough to know their mass, charge and spin. Occasionally though, such as with radioactive
nuclei, the nuclear structure and its modiﬁcations under radioactivity do have chemical
consequences.
In summary, we shall be able to go a long way in describing Nature if we can understand
well various dramatically simpliﬁed approximations to a problem. Such simpliﬁed cases give
models for physical behavior. A good model will capture the essence of the physical phe-
nomenon while relaying to the background less important and/or more complicated aspects.
In this course, we shall use such simpliﬁed models throughout.
15

2
Two-state quantum systems
The conﬁguration of a quantum system is described in terms of a quantum state.
The
bound states of the electron in a Hydrogen atom, organized in various shells, all correspond
to diﬀerent quantum states which an electron can occupy, for example. Here, we shall start
the description of quantum states by specializing to the simplest non-trivial systems which
have only 2 quantum states. All the fundamental principles of quantum mechanics and of
quantum measurement can be dealt with simply and concisely, on the basis of this simple
example.
We shall look at two diﬀerent systems: the polarization of light, and the spin 1/2 degree
of freedom of the electron. Assuming the wave vector k of light to be ﬁxed, the photon can
be in precisely two polarization states; similarly, with the electron momentum p ﬁxed, the
electron has only the spin 1/2 degree of freedom left. As we shall see below, each system
will have just two states.
2.1
Polarization of light
Consider light propagating along the z direction, with wave number k = |k| and frequency
ω = ck. Classically, light is an electro-magnetic wave, whose electric and magnetic ﬁelds
are transverse to k, and thus lie in the xy plane. A polarizer is a planar material that,
when inserted into a beam1 and orthogonally to it, transmits only light whose electric ﬁeld
is along the direction of the polarizer. Light whose polarization direction is perpendicular
to the polarization direction is absorbed by the polarizer and converted into heat.
We shall denote this polarization direction by the angle θ with the x axis. The electric
ﬁeld E = (Ex, Ey, 0) of this wave is linearly polarized, and has
Ex
=
E0 cos θ cos(ωt −kz)
Ey
=
E0 sin θ cos(ωt −kz)
(2.1)
An analyzer is a second polarizer, but whose polarization direction is α, depicted in ﬁgure 1.
The electric ﬁeld of the light emerging from the analyzer is the result of projecting the electric
ﬁeld that emerges from the polarizer onto the polarization direction α of the analyzer,
Ex
=
E0 cos α cos(θ −α) cos(ωt −kz)
Ey
=
E0 sin α cos(θ −α) cos(ωt −kz)
(2.2)
If the light intensity emerging from the polarizer was N, then the light intensity emerging
from the analyzer will be N cos2(θ −a).
1Light in a beam is strictly speaking a wave packet, whose wave vector has a small dispersion around k.
16

Figure 1: Polarizer and analyzer set-up
A more elaborate tool is a birefringent plate, which may again be inserted into the beam
and orthogonally to it, and which now transmits light which is polarized parallel to the
optical axis along one path, but transmits light polarized perpendicularly to the optical axis
along a diﬀerent path.
Figure 2: Polarizer and birefringent plate set-up
Light emerging from the polarizer with polarization angle θ and intensity N, will be split by
the birefringent plate into two beams: one polarized along the x-direction, the other along
the y-direction. The intensities of these beams may be measured by two detectors Dx and
Dy, and are found to be,
Nx
=
N cos2 θ
Ny
=
N sin2 θ
(2.3)
Here, we are assuming an idealized birefringent plate, for which no light intensity is lost
during transmission, so that N = Nx + Ny. Note that a birefringent plate may be converted
into a polarizer by dumping one of its exit beams.
17

2.2
Polarization of photons
The entire discussion of the preceding subsection has concentrated on the behavior of classi-
cal waves. Einstein’s explanation of the photo-electric eﬀect (1905) demonstrates that light
is actually composed of individual quanta (photons), whose behavior is that of particles. If
the light intensity is suﬃciently reduced, it actually becomes possible to study individual
photons, and to access the quantum behavior of the polarization degree of freedom of pho-
tons.2 The intensity of a beam, such as N, is then given by the number of photons (per
second). A measurement will consist simply in counting the number of photons in a given
beam, and thereby yielding the intensity of that beam.
We now list the key experimental observations which point to the key ingredients of
quantum behavior.
(1) From observing individual photons, it is found that the detectors for x-polarization
and for y-polarization are never triggered simultaneously. Thus, we must conclude that the
entire photon emerging from the birefringent plate either has x-polarization or y-polarization.
(2) It is impossible to predict whether a photon incident on the birefringent plate will
trigger detector Dx or detector Dy (unless θ = 0, π, as we shall see later). Instead, a photon
will reach detector Dx and Dy with certain probabilities px and py. In the limit where the
number of photons N becomes very large, the probabilities are given by
px
=
lim
N→∞(Nx/N) = cos2 θ
py
=
lim
N→∞(Ny/N) = sin2 θ
(2.4)
The relation N = Nx + Ny, obtained previously for an ideal birefringent plate, translates
then to the conservation of probability px + py = 1.
(3) The rule according to which probabilities combine may be inferred from an experiment
in which the beam of photons is ﬁrst split and then recombined using two birefringent plates,
depicted in Fig. 3.
We assume that the intensity of the light beam emerging from the polarizer is N. The
ﬁrst birefringent plate splits the beams into x and y polarizations, which are recombined by
the second birefringent plate (whose optical axis is opposite to the one of the ﬁrst plate),
thus reproducing the original beam. From this consideration, it is clear that the intensity
2With present day technology of photo-multipliers and CCD (charge coupling devices), it is possible to
detect individual photons, one by one. Actually, even the human retina is capable of detecting single photons,
though very few of the photons that reach the retina will actually stimulate a molecule of visual pigment
(rhodopsin), producing a perception.
18

Figure 3: Experiment with two birefringent plates
found after the analyzer will be N cos2(θ −α). Translated into probabilities, the original
beam has probability 1, and the analyzer will ﬁnd polarization angle α with probability
ptot = cos2(θ −α)
(2.5)
But a diﬀerent way in which to evaluate this same probability is to combine the probabilities
as the light traverses the two birefringent plates.
If probabilities combined according to classical rules, we would ﬁnd the following se-
quence. After the ﬁrst, but before the second birefringent plate, the probability that the
photon has polarizations x or y is given by (2.4). After the second plate, the probabilities
that the x and y polarized beam yield polarization angle α in the analyzer is
p′
x
=
cos2 α
p′
y
=
sin2 α
(2.6)
According to the classical rules, the combined probability would be
p′
tot = pxp′
x + pyp′
y = cos2 θ cos2 α + sin2 θ sin2 α
(2.7)
which is in disagreement with ptot = cos2(θ −α) for general θ and α. In fact, we have
ptot −p′
tot = 2 cos θ sin θ cos α sin α. This is an interference term: it arises from the fact
that when the two beams from birefringent plate 1 recombine, they interfere, just as the
electric ﬁelds of electro-magnetic waves did. Although photons behave like particles in that
they form discrete quanta, their probabilities combine like waves. This is an aspect of the
particle/wave duality of quantum mechanics.
(4) The correct rule for the combination of probabilities is given in terms of the probability
amplitudes ax, ay, a′
x, a′
y, related to the previously deﬁned probabilities by
px = |ax|2
p′
x = |a′
x|2
py = |ay|2
p′
y = |a′
y|2
(2.8)
19

In our context, these are given by ax = cos θ, ay = sin θ, and a′
x = cos α, a′
y = sin α. The
total amplitude results from linearly combining these partial amplitudes,
atot
=
axa′
x + aya′
y
=
cos θ cos α + sin θ sin α
=
cos(θ −α)
(2.9)
Thus, the probability amplitudes satisfy a linear superposition principle.
The total probability ptot is given in terms of the probability amplitude atot by,
ptot = |atot|2 = cos2(θ −α)
(2.10)
which is now in agreement with the result from electro-magnetic wave theory.
2.3
General parametrization of the polarization of light
The polarization of light and photons described above is not the most general one. The most
general polarization (at ﬁxed wave vector k) has the electric ﬁeld given by
Ex
=
E0 cos θ cos(ωt −kz −δx) = E0Re(axe−iωt+ikz)
Ey
=
E0 sin θ cos(ωt −kz −δy) = E0Re(aye−iωt+ikz)
(2.11)
By time-translation and periodicity, it is clear that only the diﬀerence in phases δx −δy
modulo 2π is physically signiﬁcant. When θ = ±π/4, and δx −δy = ±π/2, this is circular
polarization, while for general values, it is elliptical, and we have
ax
=
cos θ eiδx
ay
=
sin θ eiδy
(2.12)
The complex two-component vector (ax, ay) obeys |ax|2+|ay|2 = 1 and its phase is physically
immaterial, thus leaving two real parameters.
2.4
Mathematical formulation of the photon system
The combination of the polarizer and birefringent plate demonstrates that photons with
polarization angle θ decompose into x- and y-polarization for all θ, the only diﬀerence being
the relative intensity of these components. The photon states with x- and y-polarizations
will be represented mathematically by two vectors |x⟩and |y⟩in a two-dimensional complex
vector space H. In the system of a polarizer and analyzer, the state |x⟩corresponds to the
20

polarization angle θ = α = 0, while the state |y⟩corresponds to θ = α = π/2. From this
correspondence, we deduce the probabilities, and probability amplitudes,
p (|x⟩→|x⟩) = p (|y⟩→|y⟩) = 1
⇒
⟨x|x⟩= ⟨y|y⟩= 1
p (|x⟩→|y⟩) = p (|y⟩→|x⟩) = 0
⇒
⟨x|y⟩= ⟨y|x⟩= 0
(2.13)
Here ⟨| ⟩denotes the Hermitian inner product in the two-dimensional complex vector space
H (we shall deﬁne this Dirac notation more carefully soon). Thus, the states |x⟩and |y⟩
form an orthonormal basis for H.
The polarizer-birefringent plate experiment, and the linear superposition principle, show
that a photon with arbitrary polarization angle θ corresponds to a state in H which is a
linear combination of the states |x⟩and |y⟩,
|θ⟩= ax|x⟩+ ay|y⟩
(2.14)
for complex coeﬃcients ax and ay.
As we have seen earlier, conservation of probability
requires the relation |ax|2 + |ay|2 = 1. Actually, the coeﬃcients ax and ay are nothing but
the probability amplitudes to ﬁnd the photon |θ⟩in either state |x⟩or state |y⟩, ax = ⟨x|θ⟩
and ay = ⟨y|θ⟩. Conservation of probability thus leads to
|⟨x|θ⟩|2 + |⟨y|θ⟩|2 = 1
(2.15)
so that the state |θ⟩has also unit norm, ⟨θ|θ⟩= 1. It follows that we have a formula for ⟨θ|,
for any values of ax and ay, given by
⟨θ| = a∗
x⟨x| + a∗
y⟨y|
(2.16)
where ∗denotes complex conjugation.
We are now in a position to give the mathematical formulation for all the polarizer-
analyzer-birefringent plate experiments described earlier. The polarizer and analyzer prepare
a photon in a deﬁnite state, given respectively by the state vectors
|θ⟩
=
cos θ |x⟩+ sin θ |y⟩
|α⟩
=
cos α |x⟩+ sin α |y⟩
(2.17)
The probability amplitude to observe the |θ⟩photon in the states |x⟩and |y⟩after the
birefringent plate, and |α⟩after the analyzer are given respectively by
ax
=
⟨x|θ⟩= cos θ
ay
=
⟨y|θ⟩= sin θ
atot
=
⟨α|θ⟩= cos(θ −α)
(2.18)
21

The instruments of the polarizer, analyzer (which, recall, is just a polarizer) and the bire-
fringent plate have mathematical interpretations as linear operators on H. Quite literally,
the analyzer transforms photons in the state |θ⟩to photons in state |α⟩with probability
amplitude ⟨θ|α⟩. Mathematically, this corresponds to a projection of the state |θ⟩onto the
state |α⟩, and may be represented by the operator,
Pα = |α⟩⟨α|
(2.19)
This is a projection operator because we have P 2
α = Pα, and applying Pα to |θ⟩yields
|α⟩⟨α|θ⟩. The birefringent plate transforms photons in state |θ⟩into two separate beams,
one corresponding to Px|θ⟩, the other to Py|θ⟩. Recombining the two beams with the second
birefringent plate, subject to the linear superposition principle of the photon states, yields
|θ⟩
→
(Px + Py) |θ⟩
(2.20)
but in view of PxPy = 0, the sum of the two projection operators is the unit matrix I in H,
namely Px + Py = I. Indeed, the beam emerging from the system of two birefringent plates
is really the same beam that went into that system.
2.5
The Stern-Gerlach experiment on electron spin
A number of other two-state quantum systems are often used to bring the key principles of
quantum physics to the fore. Feynman discusses the famous two-slit interference experiment
on electrons. Here, we shall concentrate on the Stern-Gerlach (SG) experiment in which the
two states are those of the spin 1/2 degree of freedom of an electron (carried by a silver
atom in the SG experiment). We choose this case because earlier we illustrated the photon
behavior of the classical electro-magnetic wave, while in SG, we illustrate the wave behavior
of a classical particle. The SG also diﬀers from the photon case in that the electron spin is
itself already a purely quantum phenomenon with no classical counterpart.
The physical system of interest is the spin and magnetic moment of the electron. Angular
momentum and magnetic moments of course also arise in classical mechanics, but they are
both invariably associated with orbital motion. As far as we know, the electron is a point-like
particle, with no room for internal orbital angular momentum. It is a purely quantum eﬀect
that the electron can nonetheless have non-vanishing angular momentum S, and magnetic
moment m. Both quantities are actually related by
m = g
 e
2mc

S
(2.21)
Here, e is the unit of electric charge, m is the mass, and g is the so-called g-factor, which
equals 2.00 for electrons, 5.58 for protons, and −3.82 for neutrons.
22

Figure 4: The Stern-Gerlach apparatus
SG deals with measuring S, or equivalently m. To measure m, we place it in a magnetic
ﬁeld B, which produces an energy dependence E and a force F on the electron, given by
E = −m · B
F = ⃗∇(m · B)
(2.22)
Thus, a magnetic moment placed in an inhomogeneous magnetic ﬁeld will experience a force,
which will lead to bending of the trajectory and is observable. To create an inhomogeneous
magnetic ﬁeld, one uses asymmetrical poles, as in the ﬁgure above. Henceforth, the entire
SG apparatus will simply be represented by a box, as in the ﬁgure. A beam of neutral silver
atoms is now sent trough the SG apparatus (along the x-axis) and the signal is received on
a screen placed perpendicularly to the beam.
Figure 5: The Stern-Gerlach experimental set-up
The experimental outcomes are as follows,
23

(1) With a strong magnetic ﬁeld, the signal of the individual atoms emerging from SG is
centered sharply on two outcomes, which correspond to opposite values of the magnetic
moment. The detectors counting the number of atoms for each outcome are never triggered
simultaneously. Thus each silver atom must have + or −value for the spin.
(2) The observed values of spin are along the z-axis (which is the N-S direction of the magnet
in SG), and take only two possible values,
Sz = ± ¯h/2
(2.23)
For a given atom entering the SG apparatus, it is impossible to predict whether the outcome
will be + or −. The SG apparatus on spin is precisely analogous to the birefringent plate for
the photon. The analog of a polarizer at angle θ for the photon is an SG apparatus rotated
by an angle θ with respect to the z-axis, and with one of the two outgoing beams blocked.
(3) The following experimental set-ups again exemplify the quantum behavior of the spins.
Figure 6: The Stern-Gerlach experiment with multiple SG separators
The ﬁrst set-up shows that a spin prepared in state Sz = +¯h/2 remains in state Sz =
+¯h/2. The second set-up shows that a spin prepared in state Sz = +¯h/2 yields with equal
24

probability spins Sx = ±¯h/2. The third set-up shows how successive SG apparatus in z, x
and then again in z directions regenerate spins with Sz = −¯h/2 from an incoming beam of
purely Sz = +¯h/2.
All these phenomena are accounted for quantitatively by describing the spin as a two-state
quantum system, built on a two-dimensional complex vector space with an inner product to
yield the transition amplitudes.
25

3
Mathematical Formalism of Quantum Physics
We begin by reviewing the mathematical formalism of quantum physics, including Hilbert
spaces of ﬁnite and inﬁnite dimensions, and of linear operators acting on Hilbert spaces.
Those in hand, we shall give the postulates of quantum physics in the next section.
3.1
Hilbert spaces
A Hilbert space H is a complex vector space, endowed with a Hermitian positive deﬁnite
inner product, denoted by (·, ·). For ﬁnite-dimensional H, this deﬁnition will be complete,
while for inﬁnite-dimensional H, some additional convergence properties will have to be
supplied. We shall use the Dirac notation, and denote the vectors in H by kets |u⟩, |v⟩etc.
• The fact that H is a complex vector space requires that
(α + β)|u⟩
=
α|u⟩+ β|u⟩
α(|u⟩+ |v⟩)
=
α|u⟩+ α|v⟩
(αβ)|u⟩
=
α(β|u⟩)
(3.1)
for all |u⟩, |v⟩∈H and for all α, β ∈C.
• A Hermitian inner product (·, ·) is a map from H × H →C, such that
(|v⟩, |u⟩)
=
(|u⟩, |v⟩)∗
(|u⟩, α|v⟩+ β|w⟩)
=
α (|u⟩, |v⟩) + β (|u⟩, |w⟩)
(α|u⟩+ β|v⟩, |w⟩)
=
α∗(|u⟩, |w⟩) + β∗(|v⟩, |w⟩)
(3.2)
The inner product is linear in the second entry, but anti-linear in the ﬁrst entry. The inner
product notation (·, ·) is primarily a notation of mathematicians. In physics instead, we use
the notation invented by Dirac,
⟨v|u⟩≡(|v⟩, |u⟩)
bra ket
(3.3)
This notation actually also has mathematical signiﬁcance, as it leads naturally to interpret a
bra ⟨v| as a linear form on H. The space of all (continuous) linear forms on H is by deﬁnition
the Hilbert space dual to H, and is denoted H+.
• Positive deﬁniteness of the inner product means that
⟨u|u⟩= (|u⟩, |u⟩) ≡||u||2
≥
0
for all |u⟩∈H
⟨u|u⟩= 0
⇒
|u⟩= 0
(3.4)
Here, |u⟩= 0 stands for the unit element 0 under the addition of the vector space H.
26

• The norm on H provides with a natural notion of distance, which induced the distance
topology on H, and allows us to investigate the convergence of sequences in H. The deﬁnition
of Hilbert space includes the requirement that H be a complete space.
By deﬁnition, a space H is complete if every Cauchy sequence {|un⟩}{n} ⊂H converges.
(Recall that a sequence {|un⟩}{n} ⊂H is a Cauchy sequence provided ||um −un|| →0 if
m, n →∞implies that there exists a |u⟩∈H such that the sequence converges to |u⟩,
namely ||un −u|| →0 as n →∞.) This property is automatic when the dimension of H is
ﬁnite, but is an extra requirement when the dimension is inﬁnite.
• The Hilbert spaces in quantum mechanics are required to be separable, which means
that they admit a countable orthonormal basis. If the number of orthormal basis vectors of
a separable Hilbert space H is N < ∞, then H is isomorphic to CN. On the other hand, all
separable Hilbert spaces of inﬁnite dimension are isomorphic to one another.
3.1.1
Triangle and Schwarz Inequalities
The distance deﬁned by the norm satisﬁes the triangle inequality,
||u + v|| ≤||u|| + ||v||
(3.5)
for all |u⟩, |v⟩∈H, which in turn implies the Schwarz inequality,
|⟨u|v⟩| ≤||u|| · ||v||
(3.6)
Both may be shown using the following arguments. If |v⟩= 0, both inequalities hold trivially.
Henceforth, we shall assume that |v⟩̸= 0. Positivity of the norm implies that for any complex
number λ, we have
0 ≤||u + λv||2 = ||u||2 + |λ|2||v||2 + λ⟨u|v⟩+ λ∗⟨u|v⟩∗
(3.7)
We now choose the phase of λ to be such that λ⟨u|v⟩is real and negative; as a result, λ⟨u|v⟩=
−|λ||⟨u|v⟩|. Using the fact that |v⟩̸= 0, we may choose |λ| = ||u||/||v||. Substituting the
corresponding value for λ into (3.7) immediately yields (3.6). Using now λ = 1 in (3.7) and
bounding |⟨u|v⟩| using the Schwarz inequality readily gives (3.5).
3.1.2
The construction of an orthonormal basis
Hilbert spaces of ﬁnite dimension and separable Hilbert spaces of inﬁnite dimension share the
property that one can construct an orthonormal basis using the Gramm-Schmidt procedure.
Let {|un⟩}n be a basis of H, where n either runs over the ﬁnite set {1, 2, · · ·, N} or over all
27

of N (the set of positive integers). The Gramm-Schmidt procedure goes as follows. We start
with the ﬁrst vector and normalize it,
|1⟩= |u1⟩/||u1||
(3.8)
To construct the second vector |2⟩of the orthonormal basis, we project |u2⟩onto the space
perpendicular to |1⟩, and normalize the resulting vector,
|v2⟩= |u2⟩−|1⟩⟨1|u2⟩
|2⟩= |v2⟩/||v2||
(3.9)
This process may be continued recursively as follows. Given the ﬁrst m orthonormal vectors
{|1⟩, |2⟩, · · ·, |m⟩}, one constructs |m + 1⟩by the same process,
|vm+1⟩= |um+1⟩−
m
X
i=1
|i⟩⟨i|um+1⟩
|m + 1⟩= |vm+1⟩/||vm+1||
(3.10)
When the dimension of H is ﬁnite, this process terminates. Separability of the Hilbert space
H in the inﬁnite-dimensional case guarantees that even in this case, the process will converge.
3.1.3
Decomposition of an arbitrary vector
Therefore in any ﬁnite-dimensional or separable inﬁnite dimensional Hilbert space, we may
decompose any vector |ϕ⟩onto a countable orthonormal basis,
|ϕ⟩=
X
n
cn|n⟩
(3.11)
where cn are complex numbers given by ⟨n|ϕ⟩. It is often convenient to leave the range
for n unspeciﬁed, so that we can simultaneously deal with the case of ﬁnite and inﬁnite
dimensions. Since by deﬁnition of the Hermitian inner product, we have ⟨ϕ|n⟩= ⟨n|ϕ⟩∗, we
immediately see that the bra ⟨ϕ| dual to the ket |ϕ⟩has the following decomposition,
⟨ϕ| =
X
n
c∗
n⟨n|
(3.12)
while the norm is given by
||ϕ||2 = ⟨ϕ|ϕ⟩=
X
n
|cn|2
(3.13)
In ﬁnite dimension, this norm is automatically ﬁnite for ﬁnite values of cn, but this is not so
in inﬁnite dimension. Vectors in H must have ﬁnite norm; the requirement of completeness
is necessary to guarantee that sequences with ﬁnite norm indeed converge to a vector in H
with ﬁnite norm. In particular, completeness means that if ||ϕ|| < ∞, then the sequence
|ϕN⟩=
N
X
n=1
cn|n⟩
(3.14)
converges to |ϕ⟩and may be used to approximate |ϕ⟩to arbitrary precision as N grows.
More precisely, for any ǫ > 0, there exists an N such that ||ϕ −ϕN|| < ǫ.
28

3.1.4
Finite-dimensional Hilbert spaces
All Hilbert spaces of ﬁnite dimension N are isomorphic to one another. Let {|n⟩}n=1,···,N be
an orthonormal basis in an N-dimensional Hilbert space H, satisfying ⟨m|n⟩= δmn. Every
vector |ϕ⟩in H may be represented by a 1 × N column matrix Φ whose matrix elements are
the complex numbers ϕn = ⟨n|ϕ⟩,
|ϕ⟩
↔
Φ =







ϕ1
ϕ2
·
·
ϕN







⟨ϕ|
↔
Φ† = ( ϕ∗
1 ϕ∗
2 · · · ϕ∗
N )
(3.15)
The inner product of two vectors is given by matrix contraction,
(|ψ⟩, |ϕ⟩) = ⟨ψ|ϕ⟩= Ψ†Φ =
N
X
n=1
ψ∗
nϕn
(3.16)
There is another combination that will be very useful,
|ψ⟩⟨ϕ|
↔
ΨΦ† =





ψ1ϕ∗
1 ψ1ϕ∗
2
· · ·
ψ1ϕ∗
N
ψ2ϕ∗
1 ψ2ϕ∗
2
· · ·
ψ2ϕ∗
N
· · ·
ψNϕ∗
1 ψNϕ∗
2
· · ·
ψNϕ∗
N





(3.17)
Notice that a basis vector |m⟩corresponds to a column matrix Φ whose entries are ϕn = δmn.
3.1.5
Inﬁnite-dimensional Hilbert spaces
A inﬁnite-dimensional Hilbert space H in quantum physics will be separable and have a
countable orthonormal basis {|n⟩}n∈N. All separable Hilbert spaces are isomorphic to one
another, but they may arise in diﬀerent ways. An arbitrary vector |ϕ⟩∈H may be repre-
sented by the expansion,
|ϕ⟩=
X
n
cn|n⟩
||ϕ||2 =
X
n
|cn|2 < ∞
(3.18)
where the sum is understood to be over N. The simplest example of an inﬁnite-dimensional
separable Hilbert space is given by,
L2 ≡{c = (c1, c2, c3, · · ·); cn ∈C}
(c, d) ≡
X
n∈N
c∗
ndn
(3.19)
29

A more complicated example is provided by spaces of square integrable complex functions
on some interval S (or all of) the real line R, deﬁned by
L2(S) ≡{f : S →C; (f, f) < ∞}
(f, g) ≡
Z
S dxf(x)∗g(x)
(3.20)
These spaces will be ubiquitous in quantum mechanics.
The Fourier transform gives a
convenient way of describing L2(S).
For example, on an interval S = [−πℓ, +πℓ] with
periodic boundary conditions (or equivalently a circe of radius ℓ), we have
f(x) =
X
m∈Z
fm
eimx/ℓ
√
2πℓ
(f, g) =
X
m∈Z
f ∗
mgm
(3.21)
where gm are the Fourier components of g. This shows that L2 and L2(S) are isomorphic.
The basis for L2(S) used here corresponds to
|m⟩∼eimx/ℓ
√
2πℓ
(3.22)
and is orthonormal in view of the relation,
Z +πℓ
−πℓdx

eimx/ℓ∗einx/ℓ= 2πℓδm,n
(3.23)
which is a standard relation of Fourier analysis.
The Hilbert space L2(R) must be handled with additional care. Fourier analysis (as well
as the limit ℓ→∞of the above example) suggests a basis given by exponentials exp(ikx)
with k ∈R. The problem is that these basis vectors are not square integrable and form a
basis which is not countable. Nonetheless, countable bases for L2(R) do exist. A familiar
example is provided by the orthonormal basis of wave functions for the harmonic oscillator,
Hn(x) e−x2/2 where Hn(x) are the Hermite polynomials. Equivalently, one can work with a
non-orthonormal but simpler basis given by xne−x2/2 for all n = 0, 1, 2, · · ·, ∞.
In the physical world, space is not inﬁnite. Using the entire real line R is an idealiza-
tion, which often simpliﬁes problems, such as in the thermodynamic limit. In practice, one
may resort to approximating R by a large interval [−πℓ, +πℓ], subject to certain boundary
conditions, and then take the limit.
Alternatively, we shall later on learn how to deal with such non-countable bases.
30

3.2
Linear operators on Hilbert space
A linear operator (or simply operator) A on H is a linear map from H to H. Its action on
a state |ϕ⟩∈H is denoted as follows,
A|ϕ⟩= |Aϕ⟩
(3.24)
Successive application of operators involves taking products of operators. The product of op-
erators is generally associative, A(BC) = (AB)C = ABC, but is not generally commutative,
allowing for AB ̸= BA.
3.2.1
Operators in ﬁnite-dimensional Hilbert spaces
Every linear operator A on an N-dimensional Hilbert space H is equivalent to an N × N
matrix, whose entries Amn may be obtained as matrix elements in a given basis, such as the
orthonormal basis {|n⟩}n=1,···,N constructed earlier,
Amn = ⟨m|A|n⟩
⟨m|n⟩= δmn
(3.25)
The product of operators maps to matrix multiplication. If Amn and Bmn are the matrix
elements of the operators A and B in a certain orthonormal basis {|n⟩} of H, then the matrix
elements (AB)mn of the product AB are analogously deﬁned by (AB)mn = ⟨m|AB|n⟩. Upon
inserting the completeness relation between A and B, we ﬁnd,
(AB)mn =
X
p
⟨m|A|p⟩⟨p|B|n⟩=
N
X
p=1
AmpBpn
(3.26)
which is nothing but the rule of matrix multiplication.
The product is associative and
generally non-commutative. There is an identity operator IH which is represented by the
unit matrix. A Hermitian operator is represented by a Hermitian matrix A† = A, whose
matrix elements satisfy
Amn = A∗
nm
(3.27)
for all m, n = 1, · · ·, N, while a unitary operator U is deﬁned to satisfy U†U = I.
3.2.2
Operators in inﬁnite-dimensional Hilbert spaces
When the dimension of H is inﬁnite, a linear operator may not be well-deﬁned on all elements
of H, but only on a dense subset, which is referred to as the domain D(A) of the operator
A. Take for example the Hilbert space L2, and consider the linear operator D which acts as
follows on the states |n⟩,
D|n⟩= n|n⟩
n ∈N
(3.28)
31

Clearly, D has a well-deﬁned action on every basis vector. But now consider its action on
a general vector |ϕ⟩∈H, with the decomposition of (3.18), and compute the norm of the
result. We ﬁnd,
||D|ϕ⟩||2 =
X
n
n2|cn|2
(3.29)
If only a ﬁnite number of cn are diﬀerent from zero, then this norm will be ﬁnite. But it is
perfectly possible to have ||ϕ⟩|| ﬁnite, but ||D|ϕ⟩|| = ∞. Take for example cn = 1/n, which
deﬁnes a normalizable vector |ϕ⟩, but for which D|ϕ⟩is not normalizable. In the isomorphic
Hilbert space L2([−πℓ, +πℓ]), this issue appears under a more familiar guise. A function f
for which ||f|| is ﬁnite is square normalizable; the operator D is equivalent to taking the
derivative of the function f in the Fourier basis. But we know very well that the derivative
of a square normalizable function need not be normalizable; in fact it need not be a function
at all but could be a Dirac δ-function.
There are many other facts and relations that hold generally true for operators on ﬁnite-
dimensional Hilbert spaces, but fail for inﬁnite-dimensional ones. A striking example has
to do with the nature of the commutator. For two ﬁnite dimensional matrices, we always
have tr[A, B] = 0, because trAB = trBA. But for operators in Hilbert space, this is more
tricky, as may be seen by taking the familiar position and momentum operators, for which
[x, p] = i¯h. The rhs of this equation is really multiplied by the identity operator, whose trace
is not expected to vanish !!
Subtleties, such as this one, associated with operators acting on inﬁnite dimensional
Hilbert spaces, will not be discussed in all generality here. Instead, we shall handle these
issues as they arise, more or less on a case by case basis. Beyond that, there is a vast mathe-
matics and mathematical-physics literature on the subject, and things get quite complicated.
3.3
Special types of operators
We now generalize and extend the role of certain special operators to a separable Hilbert
space H which may be of ﬁnite or of inﬁnite dimension.
• The identity operator in H, denoted by I or IH maps every |ϕ⟩∈H into itself,
IH|ϕ⟩= |ϕ⟩. In an orthonormal basis {|n⟩}n=1,···,N, it may be expressed as
IH =
X
n
|n⟩⟨n|
⟨m|n⟩= δmn
(3.30)
• A projection operator P is deﬁned to satisfy P 2 = P. The identity, and 0 operators
are trivially projection operators. A non-trivial projection operator will map all of H into
32

a non-trivial subspace E ⊂H, which is itself a Hilbert space. The associated projection
operator PE may be constructed uniquely in terms of an orthonormal basis {|ǫp⟩}{p} of E, by
PE =
X
p
|ǫp⟩⟨ǫp|
(3.31)
Of special interest is the projection operators onto a single vector |α⟩∈H, given by
Pα = |α⟩⟨α|
(3.32)
In quantum theory, Pα plays the role of the analyzer in the photon experiment.
• The inverse A−1 of an operator A is deﬁned as usual by A A−1 = A−1 A = IH.
• The adjoint of an operator is deﬁned as follows. Given an operator A, with domain
D(A), we deﬁne the adjoint operator A† to be such that for all |ϕ⟩∈D(A), we have3
(|ψ⟩, A|ϕ⟩) = (A†|ψ⟩, |ϕ⟩)
⇔
⟨ψ|A|ϕ⟩= ⟨ϕ|A†|ψ⟩∗
(3.33)
For general operators A, this relation may not hold for all |ψ⟩∈H, but will hold only for
a dense subset of H, which is, by deﬁnition, the domain D(A†) of the operator A†. For a
ﬁnite-dimensional Hilbert space, the adjoint A† of an operator A is the same as the Hermitian
conjugate of that operator, and we have A† = (A∗)t.
• A self-adjoint operator is an operator A whose adjoint A† satisﬁes A† = A, and whose
domain satisﬁes D(A†) = D(A). For a ﬁnite-dimensional Hilbert space, a self-adjoint op-
erator is simply a Hermitian operator satisfying A† = A. For inﬁnite dimensional Hilbert
spaces, self-adjoint is a stronger requirement than Hermitian as the domains have to coincide.
Every projection operator is self-adjoint.
• An operator A is a bounded operator provided that for all |ϕ⟩∈H, we have
||A|ϕ⟩||2 ≤CA||ϕ||2
(3.34)
Here, CA is a real positive constant which depends only on the operator A, and not on the
vector |ϕ⟩. Every operator in a ﬁnite-dimensional Hilbert space is automatically a bounded
operator.
In an inﬁnite-dimensional Hilbert space, bounded operators are the closest in
properties to ﬁnite-dimensional matrices. In particular, the domain of a bounded operator
is the entire Hilbert space D(A) = H, and its adjoint A† may be simply deﬁned by
(|ψ⟩, A|ϕ⟩) = (A†|ψ⟩, |ϕ⟩)
⇔
⟨ψ|A|ϕ⟩= ⟨ϕ|A†|ψ⟩∗
(3.35)
3The the sake of maximal clarity, we exhibit also the inner product notation here.
33

for all |ϕ⟩, |ψ⟩∈H, while a self-adjoint bounded operator satisﬁes ⟨ψ|A|ϕ⟩= ⟨ϕ|A|ψ⟩∗for all
|ϕ⟩, |ψ⟩∈H. A projection operator is always bounded. Unbounded operators will, however,
be pervasive in quantum mechanics, and will need to be dealt with.
• An operator U is a unitary operator provided that for all |ϕ⟩, |ψ⟩∈H, we have
(U|ψ⟩, U|ϕ⟩) = (|ψ⟩, |ϕ⟩)
(3.36)
for all |ϕ⟩, |ψ⟩∈H. Clearly, a unitary operator is a bounded operator with CU = 1, and
is invertible. The inverse U−1 may be deﬁned by setting U|ψ⟩= |u⟩, so that (|u⟩, U|ϕ⟩) =
(U−1|u⟩, |ϕ⟩) for all |ϕ⟩, |u⟩∈H. Using now the deﬁnition of the adjoint of U, we see that
for a unitary operator, we have
U−1 = U†
U†U = IH
(3.37)
Unitary operators will be key ingredients in quantum mechanics because unitary transfor-
mations will preserve transition amplitudes, and represent symmetries.
3.4
Hermitian and unitary operators in ﬁnite-dimension
Self-adjoint operators will play a central role in quantum mechanics. We now derive some
of their key properties. In a ﬁnite-dimensional Hilbert space, a Hermitian operator is self-
adjoint, and vice versa, and may be represented by a Hermitian matrix.
Theorem 1
(i) The eigenvalues of a self-adjoint operator are real.
(ii) Eigenvectors corresponding to two distinct eigenvalues are orthogonal to one another.
(iii) A self-adjoint operator may be written as a direct sum of mutually orthogonal projection
operators, weighted by the distinct eigenvalues.
Proof
(i) Let A be a Hermitian matrix with eigenvalue a and associated eigenvector |ϕ⟩̸= 0,
A|ϕ⟩= a|ϕ⟩
(3.38)
Taking the † of this equation gives ⟨ϕ|A† = a∗⟨ϕ|, and using the fact that A† = A, simpliﬁes
this equation to ⟨ϕ|A = a∗⟨ϕ|. Taking the inner product of this equation with |ϕ⟩and of
the eigenvalue equation with ⟨ϕ|, we obtain,
⟨ϕ|A|ϕ⟩= a⟨ϕ|ϕ⟩= a∗⟨ϕ|ϕ⟩
(3.39)
Since |ϕ⟩̸= 0, we have ⟨ϕ|ϕ⟩̸= 0, and hence a∗= a, which proves the ﬁrst assertion.
34

(ii) Next, let a′ ̸= a be two distinct eigenvalues (which are both real by (i)),
A|ϕ⟩
=
a|ϕ⟩
A|ϕ′⟩
=
a′|ϕ′⟩
(3.40)
Taking the inner product of the ﬁrst line with ⟨ϕ′| and of the second line by ⟨ϕ|, and using
⟨ϕ|ϕ′⟩= ⟨ϕ′|ϕ⟩∗, and ⟨ϕ|A|ϕ′⟩= ⟨ϕ′|A†|ϕ⟩∗= ⟨ϕ′|A|ϕ⟩, we ﬁnd that
⟨ϕ′|A|ϕ⟩= a⟨ϕ|ϕ′⟩= a′⟨ϕ|ϕ′⟩
(3.41)
Since a′ ̸= a, we must have ⟨ϕ′|ϕ⟩= 0 which proves (ii).
Constructing eigenvalues and eigenvectors in general is diﬃcult, even in ﬁnite dimension.
If A is an N × N matrix, the eigenvalues obey the characteristic equation,
det(aI −A) = aN + c1aN−1 + c2aN−2 + · · · + cN = 0
(3.42)
where c1 = −trA and cN = (−)NdetA. Clearly, for Hermitian A, all coeﬃcients cn are real,
and all roots are real. Assuming that, given A, the roots a1, a2, · · ·, aN of this algebraic
equation have been found (possibly numerically), then ﬁnding the associated eigenvectors
reduces to a linear problem,
(anI −A) |ϕ⟩= 0
(3.43)
which can be solved by standard methods of matrix algebra.
(iii) Finally, a given eigenvalue ai, may have one or several linearly independent eigenvectors,
which span the entire eigenspace Ei associated with ai. By the result of (ii), the eigenspaces
associated with distinct eigenvalues are also mutually orthogonal.
Therefore, the entire
Hermitian matrix equals,
A =
X
i
aiPi
ai ̸= aj
when
i ̸= j
(3.44)
where Pi represents the projection operator on eigenspace Ei.
The dimension dim Pi is
referred to as the degeneracy (or multiplicity) of the eigenvalue ai. This number clearly co-
incides with the degeneracy of the root ai in the characteristic equation. In matrix notation,
this produces a block-diagonal representation of A,
A =







a1I1
0
0
· · ·
0
0
a2I2
0
· · ·
0
0
0
a3I3
· · ·
0
· · ·
0
0
0
· · ·
amIm







(3.45)
This proves (iii).
35

3.4.1
Unitary operators
Unitary operators are very closely related to self-adjoint operators. In fact, one proves the
following theorem by completely analogous methods,
Theorem 2
(i) The eigenvalues of a unitary operator are pure phases.
(ii) Eigenvectors corresponding to two distinct eigenvalues are orthogonal to one another.
(iii) A unitary matrix may be written as a direct sum of mutually orthogonal projection
operators, weighted by the distinct eigenvalues.
Thus, a unitary operator U admits a decomposition very analogous to a Hermitian op-
erator, but only the nature of the eigenvalues diﬀers,
U =
X
i
eiθiPi =







eiθ1I1
0
0
· · ·
0
0
eiθ2I2
0
· · ·
0
0
0
eiθ3I3
· · ·
0
· · ·
0
0
0
· · ·
eiθmIm







(3.46)
where the angles θi are real and distinct mod 2π, and Ii is the identity matrix in the
eigenspace Ei, representing the orthogonal projection operator Pi onto the eigenspace of
U with eigenvalue eiθi.
3.4.2
The exponential map
For any N × N matrix, and any analytic function function f(x), we deﬁned f(A) by the
Taylor expansion of f,
f(A) =
∞
X
n=0
1
n!f (n)(0)An
(3.47)
where f (n)(x) is the n-th derivative of f(x). Using this deﬁnition, it is especially easy to
ﬁnd the function f evaluated on a Hermitian matrix A, with the decomposition in terms of
orthogonal projectors given in (3.45), and we have
f(A) =
X
i
f(ai)Pi
(3.48)
The relation between Hermitian and unitary operators may be made explicit by using the
exponential function. For any Hermitian matrix A, the matrix U, uniquely deﬁned by
U = eiA
(3.49)
36

is a unitary matrix. The statement is readily checked by computing U† = e−iA† = e−iA.
Conversely, any unitary matrix U may be written as the exponential of a Hermitiam matrix
A, as in (3.49), but the matrix A is not unique, as various shifts by 2π in A will produce
the same U. The easiest way to prove this statement is to decompose U into orthogonal
projection operators as in (3.46); it is then manifest that the matrix A is then given by (3.45)
with ai = φi mod 2π.
3.5
Self-adjoint operators in inﬁnite-dimensional Hilbert spaces
The statements of Theorem 1 have been written in such a way that they essentially also hold
for inﬁnite dimensional Hilbert spaces, though the proofs will now diﬀer. In particular, self-
adjoint operators will still have real eigenvalues. In statement (iii), the sum over projection
operators weighed by eigenvalues need not be a discrete sum, even in a separable Hilbert
space, but can have discrete and continuous parts, corresponding to the discrete and contin-
uous parts of the spectrum of an operator. Actually, this situation should be familiar from
analyzing the spectra of various Hamiltonians in quantum mechanics, such as the Hydrogen
atom.
The continuous spectrum arises because all the eigenvectors of an operator need not be
normalizable. The simplest case would be the Hamiltonian of the free particle on R, and its
associated eigenvalue problem,
H = −¯h2
2m
d2
dx2
HψE(x) = EψE(x)
(3.50)
whose eigenfunctions are eikx with E = ¯h2k2/2m. Although L2(R) is a perfectly separable
Hilbert space, and the operator H is perfectly self-adjoint, the eigenvectors ψE(x) are not
normalizable on R. This situation is characteristic of the continuous part of a spectrum.
The relation between self-adjoint and unitary operators remains valid for inﬁnite-dimensional
Hilbert spaces.
37

4
The Principles of Quantum Physics
The mathematical description of a physical quantum system is in terms of a separable Hilbert
space H and certain linear operators on H.
Principle 1
Every physical state of a quantum system is represented by a vector in H.
Two vectors, |ϕ⟩, |ϕ′⟩∈H correspond to the same physical state if and only if |ϕ′⟩= λ|ϕ⟩
for some non-zero λ ∈C. Using this equivalence, a physical state is really described by a
ray in H, and one often chooses ||ϕ|| = 1.
Principle 2
Every observable of a physical system is represented by a self-adjoint operator
on H. A state |φi⟩has a deﬁnite measured value ai for an observable A provided |φi⟩is an
eigenvector of A,
A|φi⟩= ai|φi⟩
(4.1)
In any quantum system, the outcomes of any experiment on the system are the possible
eigenvalues of various observables. States associated with diﬀerent eigenvalues are orthogonal
in view of the fact that A is self-adjoint.
Principle 3
Let |ϕ⟩be an arbitrary state in H, and let {|ψi⟩} denote a set of mutually or-
thogonal states, such as, for example, the eigenstates of an observable. Then, the probability
p for measuring the state |ϕ⟩in one of the states |ψi⟩are given by
p

|ϕ⟩→|ψi⟩

= |⟨ψi|ϕ⟩|2
(4.2)
for normalized states satisfying ⟨ϕ|ϕ⟩= 1 and ⟨ψi|ψj⟩= δi,j.
Principle 4 Time-evolution, also referred to as dynamics, of a quantum system is generated
by a self-adjoint Hamiltonian H, which is itself an observable associated with the total energy
of the system. In the Schr¨odinger picture of a closed system, the states of the system evolve
in time, and the observables are time independent. The Schr¨odinger equation gives the time
evolution of any state |ϕ(t)⟩, according to
i¯h ∂
∂t|ϕ(t)⟩= H |ϕ(t)⟩
(4.3)
In the Heisenberg formulation, the states remain time independent but the observables ac-
quire time-dependence, according to
i¯h d
dtA(t) = [A(t), H]
(4.4)
The Heisenberg and Schr¨odinger formulations are equivalent to one another, as we shall
conﬁrm shortly.
38

4.1
Conservation of probability
The combination of Principles 2 and 3 speciﬁes the nature of measurement of a general
observable A. If a quantum system has been prepared in an arbitrary state |ϕ⟩, the mea-
surement of the observable A proceeds as follows.
By Principle 2, only a single eigenvalue ai of A will be recorded during a single mea-
surement of the observable associated with A. (In the photon polarization experiment, any
single photon has polarization either along the x or y axis, but not both.) By principle 3,
the probability for eigenvalue ai to be recorded is given by
p

|ϕ⟩→|φi⟩

= |⟨φi|ϕ⟩|2
(4.5)
provided the eigenvalue ai is non-degenerate, i.e. has only a single eigenvector |φi⟩. Both
states |φi⟩and |ϕ⟩are assumed to be normalized here ||φi|| = ||ϕ|| = 1. More generally,
if the eigenvalue ai is degenerate, let Pi be the projection operator onto the eigenspace Ei
associated with the eigenvalue ai. The total probability p(ai|ϕ) to record the eigenvalue ai
for the observable A in the state |ϕ⟩is then given by
p(ai|ϕ) = p

|ϕ⟩→Ei

= ||Piϕ||2
(4.6)
The property of self-adjointness of any observable A guarantees that it admits a decom-
position into mutually orthogonal projection operators Pi weighted by the corresponding
eigenvalues ai of A,
A =
X
i
aiPi
X
i
Pi = IH
(4.7)
and the second identity guarantees that this decomposition is complete. As a result, the
sum of the probabilities for the state |ϕ⟩to be recorded in all possible outcomes is 1, since,
X
i
p(ai|ϕ) =
X
i
p

|ϕ⟩→Ei

=
X
i
||Piϕ||2 =
X
i
⟨ϕ|P †
i Pi|ϕ⟩
=
X
i
⟨ϕ|Pi|ϕ⟩= ⟨ϕ|ϕ⟩= 1
(4.8)
This result is, of course, a very important consistency check on the probabilistic interpreta-
tion of quantum mechanics.
4.2
Compatible versus incompatible observables
Two observables A and B are said to be compatible provided [A, B] = 0; if [A, B] ̸= 0,
the observable are incompatible. For example, the momentum components px and py are
39

compatible observables, [px, py] = 0, while the spin components Sx and Sy are not, [Sx, Sy] =
i¯hSz. The role played by compatibility of observables during measurement is expressed by
the following,
Theorem 3
(i) Two self-adjoint operators A and B, which satisfy [A, B] = 0, may be diagonalized in the
same basis, i.e. with common eigenspaces;
(ii) Two compatible observables may be observed simultaneously.
Proof
(i) Since A is self-adjoint, we may decompose it in a sum of projection operators,
A =
X
i
aiPi
X
i
Pi = IH
(4.9)
where by assumption, the eigenvalues satisfy ai ̸= aj when i ̸= j. By multiplying B to the
left and to the right by the identity operator IH, we also have
B =
X
i,j
PiBPj
(4.10)
The commutator relation is easily computed in this basis,
0 = [A, B] =
X
i,j
(ai −aj)PiBPj
(4.11)
which implies that PiBPj = 0 whenever i ̸= j, and as a result
B =
X
i
Bi
Bi = PiBPi
(4.12)
Inside the eigenspace Ei, the projection operator Pi reduces to the identity operator Ii (which
manifestly commutes with Bi). Since Bi is self-adjoint, it may be written as a direct sum of
projection operators weighted by its eigenvalues,
Bi =
X
mi
bi,miPi,mi
X
mi
Pi,mi = Ii
(4.13)
where mi is an index for matrix Bi which labels all the distinct eigenvalues bimi of Bi. The
decomposition of both operators is then given by
A =
X
i
X
mi
aiPi,mi
B =
X
i
X
mi
bi,miPi,mi
(4.14)
(ii) It is manifest that an observation of A will produce an eigenstate of A |φi⟩with eigenvalue
ai, which with probability 1 will produce one of the eigenstates of B in sector i, so that
simultaneous measurements of A and B can indeed be made.
40

4.3
Expectation values and quantum ﬂuctuations
If |ϕ⟩is an eigenstate of an observable A with eigenvalue a, then the probability for the
outcome a in a measurement of A is unity. If |ϕ⟩is not an eigenstate of A, then |ϕ⟩cannot
be associated with any one of the eigenvalues of A, but there is still a probabilistic expectation
value for the observable A. For a general state |ϕ⟩, any of the eigenvalues ai of A may be
the outcome of a measurement of A, but only with a certain probability p(ai|ϕ), computed
in the preceding subsection. The expected outcome in the state |ϕ⟩of a measurement on A
is then the probabilistic expectation value for any of the eigenvalues ai, given by
X
i
ai p(ai|ϕ) =
X
i
ai⟨ϕ|Pi|ϕ⟩= ⟨ϕ|A|ϕ⟩
(4.15)
The quantity ⟨ϕ|A|ϕ⟩, also denoted by ⟨A⟩ϕ, is referred to as the expectation value of A in
the state |ϕ⟩. As before, it is being assumed that ||ϕ|| = 1.
In probability theory one is interested in the standard deviation away from an average.
Similarly, in quantum physics one is interested in the average quantum ﬂuctuations away
from an expectation value. One deﬁnes the strength of these quantum ﬂuctuations as follows.
For any given state |ϕ⟩, subtract the expectation value of the observable to deﬁne a new
observable which has vanishing expectation value (still in the state |ϕ⟩),
Aϕ ≡A −⟨A⟩ϕIH
⟨ϕ|Aϕ|ϕ⟩= 0
(4.16)
The magnitude of the quantum ﬂuctuations is then deﬁned by
(∆ϕA)2 ≡⟨ϕ|(Aϕ)2|ϕ⟩=
X
i

ai −⟨A⟩ϕ
2 p(ai|ϕ)
(4.17)
Of course, for |ϕ⟩an eigenstate of the observable A, we have ∆ϕA = 0, and there are no
quantum ﬂuctuations of the observable A in this state.
4.4
Incompatible observables, Heisenberg uncertainty relations
Compatible observables may be measured simultaneously on all states. In particular, this
means that we can simultaneously have
∆ϕA = ∆ϕB = 0
(4.18)
for one and the same state |ϕ⟩, which is then an eigenstate of both A and B.
How about two incompatible observables, A and B, characterized by [A, B] ̸= 0 ? Al-
though incompatible observables cannot be measured simultaneously on all states, it may or
may not be possible to measure A and B simultaneously on some subset of all the states.
41

The degree to which this is possible is expressed by the Heisenberg uncertainty relations.
We begin by deﬁning the following two states,
|α⟩
=
Aϕ|ϕ⟩
|β⟩
=
Bϕ|ϕ⟩
(4.19)
The Schwarz inequality on these states |⟨α|β⟩|2 ≤||α||2 ||β||2 implies
⟨AϕBϕ⟩ϕ

2
≤⟨A2
ϕ⟩ϕ⟨B2
ϕ⟩ϕ = (∆ϕA)2(∆ϕB)2
(4.20)
where the last equality was obtained by using the deﬁnition of the quantum ﬂuctuations ∆ϕA
and ∆ϕB from (4.17). On the lhs, we use the decomposition of the product of operators into
commutator and anti-commutator,
AϕBϕ = 1
2[Aϕ, Bϕ] + 1
2{Aϕ, Bϕ}
(4.21)
It is standard that for self-adjoint operators A and B, the quantities i[A, B] and {A, B} are
both self-adjoint. Hence we have
⟨AϕBϕ⟩ϕ

2
= 1
4
⟨ϕ|[Aϕ, Bϕ]|ϕ⟩

2
+ 1
4
⟨ϕ|{Aϕ, Bϕ}|ϕ⟩

2
(4.22)
Using the earlier Schwarz inequality for the above relation in which we drop the anti-
commutator, and taking the square root gives the inequality,
1
2
⟨[A, B]⟩ϕ
 ≤(∆ϕA) (∆ϕB)
(4.23)
This inequality is the most general form of the Heisenberg uncertainty relations.
Examples:
A familiar example is when A and B are position x and momentum p
operators, satisfying [x, p] = i¯hIH. The resulting uncertainty relation is well-known,
1
2¯h ≤∆x ∆p
(4.24)
A less familiar example is provided by angular momentum [Jx, Jy] = i¯hJz and cyclic permu-
tations. Let |ϕ⟩= |j, m⟩with −j ≤m ≤j, then we have
1
2|m| ≤(∆ϕJx)(∆ϕJy)
(4.25)
In this case, the uncertainty relation clearly depend on the state |ϕ⟩, and quantum ﬂuctua-
tions grow with m. In the special states where m = 0, the operators Jx and Jy may actually
be observed simultaneously, since there 0 ≤(∆ϕJx)(∆ϕJy) even though the operators Jx and
Jy do not commute on all states.
42

4.5
Complete sets of commuting observables
For many simple quantum systems, the energy of a state completely speciﬁes that state of
the system. This is the case for the 1-dimensional harmonic oscillator, for example. But in
more complicated systems, this is no longer the case. At the cost of supplying additional
mutually commuting observables, however, it is possible to characterize the state uniquely
by the simultaneous eigenvalues of this set of observables.
This concept is familiar, for example, from the description of orbital angular momentum
states. An eigenvalue ℓ(ℓ+ 1), for ℓ= 0, 1, 2, · · ·, of the observable L2 does not uniquely
specify an angular momentum state (except when ℓ= 0) but leaves a 2ℓ+1-fold degeneration.
Supplying the additional observable Lz lifts this degeneracy completely as it supplements
ℓwith the eigenvalue m of Lz such that −ℓ≤m ≤+ℓ. The pair (ℓ, m) now completely
and uniquely speciﬁes all quantum states. Another example, which builds on this one, is
provided by the Hydrogen atom, whose states may be completely speciﬁed by the quantum
numbers (n, ℓ, m), ignoring the spins of the nucleus and of the electron.
The above construction may be generalized to more complicated quantum systems. One
deﬁnes a complete set of commuting observables of a system, as a set of observables,
A1, A2, · · · , An
(4.26)
(1) such that they mutually commute, [Ai, Aj] = 0 for all i, j = 1, · · ·, n;
(2) and such that the eigenspaces common to A1, A2, · · · , An are all one-dimensional.
The fact that the eigenspaces are all one-dimensional means precisely that there is a one-
to-one map between the simultaneous eigenvalues (a1, a2, · · · , an) and a basis of states in H.
The set of eigenvalues (a1, a2, · · ·, an) which describes the states of H uniquely is referred to
as the set of quantum numbers of that state.
Complete sets of commuting observables can be trivial. For example, given an orthonor-
mal basis of states |n⟩, for n ∈N, the following is a complete set of commuting observables,
Pn = |n⟩⟨n|
n ∈N
(4.27)
where Pn is the orthogonal projection operators on a single state |n⟩. The possible eigenvalues
of the operators are 0 and 1, and would provide a digital numbering of all the basis vectors
in H. Describing all the states of the harmonic oscillator this way would not be very eﬃcient.
Given an operator A, any function f(A) will commute with A. Also, given two mutually
commuting operators A1 and A2, the product A1A2 commutes with A1 and A2. Neither
f(A), nor A1A2, however, produce information not already contained in A, or in A1 and
A2. Therefore, the most interesting complete sets of commuting operator will be the most
economical ones in which the operators are functionally independent from one another.
43

5
Some Basic Examples of Quantum Systems
It is will be very useful for later studies to examine some of the most fundamental quantum
systems beyond the two-state models. They will include some ﬁnite systems with more than
2 states, time-dependent 2-state systems like NMR, the 1-dimensional harmonic oscillator,
and the angular momentum algebra.
5.1
Propagation in a ﬁnite 1-dimensional lattice
One of the most fundamental models consists of states propagating on a 1-dimensional lattice
consisting of N sites. We label the lattice sites by an integer n = 1, 2, · · ·, N. The Hilbert
space is spanned by the basis states |n⟩. A state |n⟩may be thought of as representing the
quantum system where the “particle” is at site n with probability 1, and probability 0 to
be on any of the N other sites. Such states are naturally orthogonal, and may be chosen
orthonormal, ⟨m|n⟩= δm,n for m, n = 1, 2, · · ·, N.
A simple example of such a system is provided by an electron propagating on a lattice
of atoms, ions or molecules. In reality, there will not just be one electron, but many. Also,
the electron will be free to move in more than one dimension, and will have electromagnetic
and spin interactions as well. In this model, all these extra eﬀects will be omitted in favor
of just to 1-dimensional location of the electron. An example with N = 6 is provided by the
Benzene molecule, where 3 electrons approximately freely move over a 6-atom ring. In this
case the lattice is naturally periodic. More generally, the model can describe propagation of
electrons along long chains of atoms, ions or molecules with N ≫1. If only bulk properties
are of interest, we are free to impose convenient boundary conditions on this lattice. We
choose these to be periodic, which allows for the simplest treatment. Therefore, it is often
convenient to identify |N + 1⟩= |1⟩.
The dynamics of the quantum system is governed by the Schr¨odinger equation, in terms
of a Hamiltonian H for the system. We want to use physical arguments to try and retain
only the most important dynamical information in H, and omit all else. To do this, we study
the Schr¨odinger equation. Any state |ψ(t)⟩may be decomposed onto the basis {|n⟩}n,
|ψ(t)⟩=
N
X
n=1
cn(t)|n⟩
cn(t) = ⟨n|ψ(t)⟩
(5.1)
The Schr¨odinger equation
i¯h ∂
∂t|ψ(t)⟩= H |ψ(t)⟩
(5.2)
determines the time-evolution of the probability amplitudes cn(t), as a function of the matrix
elements of the Hamiltonian.To show this, take the inner product of the above Schr¨odinger
44

equation with ⟨n|,
i¯h ∂
∂tcn(t) = ⟨n|H|ψ(t)⟩=
N
X
m=1
⟨n|H|m⟩cm(t)
(5.3)
To obtain the second equality, we have inserted the identity operator, represented as a sum
over the basis, I = P
m |m⟩⟨m|.
The simplest non-trivial Hamiltonian for a 1-dimensional periodic lattice retains only the
eﬀects of nearest neighbors in the lattice. For example, given that an electron is initially
on site |n⟩with probability 1, it is natural to include only the simplest eﬀects, namely that
there must be some probability for the electron the remain on site |n⟩, and some probability
to move the electron from site |n⟩to its nearest neighboring sites |n + 1⟩or |n −1⟩. The
simplest choice is such that
⟨n|H|n⟩
=
A0
⟨n|H|n ± 1⟩
=
−A1
(5.4)
where both A0 and A1 are real, and all other matrix elements are zero. It is convenient to
write the Hamiltonian as follows,
H = A0 I −A1 T −A1 T †
(5.5)
where I is the identity operator, and T, and T † are given by
T =
N
X
n=1
|n + 1⟩⟨n|
T † =
N
X
n=1
|n⟩⟨n + 1|
(5.6)
and where we continue to use the periodicity |N + 1⟩= |1⟩of the lattice.
5.1.1
Diagonalizing the translation operator
The operator T has a remarkably simple interpretation, which may be gathered by applying
T to an arbitrary state
T|n⟩
=
|n + 1⟩
n = 1, · · · , N −1
T|N⟩
=
|1⟩
(5.7)
Clearly, T translates the system by one lattice spacing forward, and T † = T −1 translates
it backwards by one lattice spacing.
As a result, we have T N = I.
Since [H, T] = 0,
translations are a symmetry of the Hamiltonian, as the physical picture indeed suggests.
It also means that the operators H and T may be diagonalized simultaneously. Since the
45

operator T is simpler than H, it will be advantageous to diagonalize it ﬁrst. Since T is
unitary, its eigenvalues are pure phases eiϕm. We shall denote the corresponding eigenstates
by |km; T⟩; we include the label T inside the state ket, because these kets will form a basis
in which T is diagonal and this basis is diﬀerent from the basis |n⟩. The label T is included
to make this distinction clear. Thus we have,
T|km; T⟩= e−iϕm|km; T⟩
(5.8)
From T N = I, we have Nϕm ≡0 (mod 2π). The eigenvalues are all distinct, and we have
ϕm = 2πm/N
m = 0, 1, · · ·, N −1
(5.9)
This leads to N orthogonal eigenstates (since T is unitary), and gives an explicit construction
of all the normalized eigenstates of T,
|km; T⟩=
1
√
N
N
X
n=1
e+inϕm|n⟩
m = 0, 1, · · ·, N −1
(5.10)
These states are usually referred to as Bloch states.
5.1.2
Position and translation operator algebra
We may deﬁne a position operator X on this ﬁnite lattice by introducing a physical lattice
spacing a into the problem. The origin of position is arbitrary, which allows us to leave an
arbitrary additive constant x0 in the eigenvalues,
X|n⟩= (an + x0)|n⟩
(5.11)
Clearly, this operator is self-adjoint and indeed corresponds to an observable. The physical
length of the lattice is then L = aN. The translation operator T now has the physical
interpretation of shifting the system forward by one lattice spacing a. Since the action of T
and X is known on all states, we can compute the action of T on X,
T †XT|n⟩
=
T †X|n + 1⟩= T †(a(n + 1) + x0)|n + 1⟩
=
(a(n + 1) + x0)|n⟩= (X + a)|n⟩
(5.12)
This equation being valid on all states, we conclude that
T †XT = X + aI
(5.13)
which makes full intuitive sense: the action of the translation generator indeed shifts the
position eigenvalues all by a. Of course, what is not well-accounted for here is the fact that
X is really a periodic variable, deﬁned only mod aN. To account for this periodicity, a more
appropriate operator would be e2πiX/(Na).
46

5.1.3
The spectrum and generalized Hamiltonians
We are guaranteed that H is diagonalizable in this basis; in fact it is already diagonal, and
we readily evaluate the eigenvalues of H:
H|km; T⟩= Em|km; T⟩
Em = A0 −2A1 cos ϕm
(5.14)
Remarkably, it is very easy to include next to nearest neighbor interactions and so on. We
would do this by including in H terms which have higher powers of the translation operator.
Including next to nearest neighbor interactions would produce the Hamiltonian,
H = A0 I −A1T −A1T −1 −A2T 2 −A2T −2
(5.15)
By construction, this Hamiltonian is also already diagonal in the basis |km; T⟩, and we may
read oﬀthe eigenvalues,
Em = A0 −2A1 cos ϕm −2A2 cos 2ϕm
(5.16)
5.1.4
Bilateral and reﬂection symmetric lattices
The periodic lattice has a natural reﬂection symmetry. This symmetry is often useful in
performing practical calculations. For example, in the subsequent subsections, we shall be
led to consider the limit N →∞, which is more easily represented in symmetric form. Here,
we shall recast the periodic lattice with N sites in a manifestly reﬂection symmetric way.
The rearrangement depends on whether N is even or odd; it will be convenient to deﬁne
ν ≡[N/2], where [ ] stands for the integer part. To exhibit the reﬂection symmetry of the
periodic lattice, it suﬃces to choose x0 of the preceding subsection as follows,
x0 = −νa
˜n = n −ν
(5.17)
Here, we have also shifted the label n to a symmetric label ˜n. For N odd, the states |ν⟩and
|−ν⟩are diﬀerent from one another, and the range of ˜n labeling independent states |˜n⟩is as
follows, −ν ≤˜n ≤ν. For N even, the states | −ν⟩and |ν⟩are to be identiﬁed | −ν⟩= |ν⟩,
and the range of ˜n labeling independent states |˜n⟩is instead −ν < ˜n ≤ν.
For example, when N is odd, we have N = 2ν + 1, and the phases ϕm may be chosen
symmetrically as follows,
ϕm = 2πm/N
m = −ν, · · · , 0, · · · , ν
(5.18)
The Bloch states are then given by
|km; T⟩=
1
√
N
ν
X
˜n=−ν
e+i˜nϕm|˜n⟩
m = −ν, · · · , 0, · · ·, ν
(5.19)
47

5.2
Propagation in an inﬁnite 1-dimensional lattice
Keeping the lattice spacing a ﬁxed, we may let the physical extent of the lattice become
inﬁnite by letting N →∞, so that also L = Na →∞. To do this symmetrically about
the origin, we use the results of the last subsection, but we shall drop the tildes on n. As
N →∞, the spectrum of the position operator remains discrete, with eigenstates |n⟩, and
linearly spaced by the lattice spacing a. Its only modiﬁcation as N →∞is that the spectrum
of X extends to larger and larger values.
The translation operator, however, now acquires a continuous spectrum, since its eigen-
values eiϕm = e2πim/N become increasingly dense on the unit circle. We represent the eigen-
values in terms of the physical quantity of momentum p, or equivalently, of wave number k,
which is related to momentum by p = ¯hk,
ϕm
a →k
−π
a ≤k ≤+π
a = kc
(5.20)
The range of the momentum or wave number is characteristic of propagation on a lattice,
and is referred to as the Brillouin zone. The eigenstates |k; T⟩of the translation operator
become labeled by a continuous parameter k.
To take the limit properly, however, the
discrete normalization of the states |km; T⟩must be changed to a continuum normalization,
|km; T⟩
√
Na = |k; T⟩
ka = ϕm
(5.21)
With this new normalization, the states |k; T⟩are now given by an inﬁnite sum,
|k; T⟩= √a
+∞
X
n=−∞
einak|n⟩
(5.22)
The completeness relation on the momentum states now involves an integral rather than a
discrete sum,
I =
Z +kc
−kc
dk
2π |k; T⟩⟨k; T|
(5.23)
It may be veriﬁed explicitly by using the expression for |k; T⟩in terms of |n⟩, and the formula,
Z +kc
−kc
dk
2π a eiak(n−n′) = δnn′
(5.24)
The normalization of the momentum states must now also be carried out in the continuum,
and may be deduced directly from the completeness relation itself. Applying the complete-
ness relation to an arbitrary state |k′; T⟩, we have
|k′; T⟩=
Z +kc
−kc
dk
2π |k; T⟩⟨k; T|k′; T⟩
(5.25)
48

This relation must hold for all states |k′; T⟩, and it means that
⟨k; T|k′; T⟩= 2πδ(k′ −k)
k, k′ ∈[−kc, kc]
(5.26)
where δ(k −k′) is the Dirac δ-function. It is generally deﬁned by the relation
f(x) =
Z
dy δ(x −y) f(y)
(5.27)
for any dense set of inﬁnitely diﬀerentiable functions f(x) (strictly speaking with the extra
technical assumption of compact support). It is instructive to verify this relation directly
from the expression of |k; T⟩in terms of |n⟩,
⟨k′; T|k; T⟩= a
+∞
X
n=−∞
eina(k−k′)
(5.28)
This gives us a convenient representation of the δ-function,
2πδ(k −k′) = a
+∞
X
n=−∞
eina(k−k′)
k, k′ ∈[−kc, kc]
(5.29)
We conclude by taking the limit of the energy eigenvalues of the lattice Hamiltonian in the
N →∞limit. It is given by
Ek = A0 −2A1 cos(ka) −2A2 cos(2ka)
k ∈[−kc, kc]
(5.30)
This is a very general result for the propagation of free waves on a lattice with spacing a.
5.3
Propagation on a circle
Another way of taking the limit N →∞is obtained by keeping the physical size of the system
Na = 2πL ﬁnite. For ﬁxed L, the lattice spacing must then tend to 0 as follows, a = 2πL/N.
This time, the momentum operator retains a discrete spectrum, and the position operator
acquires a continuous spectrum. We choose x0 = −π(N + 1)L, such that
an + x0 = x
−πL ≤x ≤+πL
(5.31)
It is clear from the conjugation relation of X and T that as a →0, the operator T approaches
the identity operator linearly in a. We deﬁne the momentum operator P by
T = I −ia
¯hP + O(a2)
(5.32)
49

The translation equation T †XT = X + aI then allows us to compute the commutator
[X, P] = i¯hI
(5.33)
The position eigenstates become labeled by the continuous eigenvalues of the position oper-
ator, and including the appropriate continuum normalization factor of N, we have
|n⟩
q
N/(2πL) = |x; X⟩
an + x0 = x
X|x; X⟩= x|x; X⟩
(5.34)
We have included the label X in the kets |x; X⟩to make it clear that the basis of states
corresponds to eigenstates of the operator X. Since the operator P is manifestly diagonal
in the same basis where T is diagonal, we may interchangeably use the notations |km; T⟩=
|km; P⟩. The relation between momentum and position eigenstates becomes,
P|km; P⟩= ¯hkm|km; P⟩
|km; P⟩=
Z +πL
−πL dx eixkm |x; X⟩
(5.35)
The momentum eigenvalues pm = ¯hkm remain ﬁnite and discrete during this limit, since
km = ϕm
a = 2πm
Na = m
L
m ∈Z
(5.36)
The completness relations are now,
I =
X
m∈Z
|km; P⟩⟨km; P| =
Z +πL
−πL dx |x; X⟩⟨x; X|
(5.37)
from which it follows that the inner product relations between |x; X⟩states are
⟨x; X|x′; X⟩= δ(x −x′)
(5.38)
We conclude by producing the energy levels for this problem. Since ϕm = akm, all the phases
tend to 0 as a →0, and all energy levels would be then degenerate. To make things more
interesting, we can choose a more interesting limit, where
A0 = 2A2 =
¯h2
Ma2
(5.39)
for a ﬁxed parameter M. As a result, the limiting energy levels are given by
Em = (pm)2
2M
(5.40)
which is the standard kinetic energy formula for a free particle on a circle, and the parameter
M should be thought of as the mass.
50

5.4
Propagation on the full line
In the problem of propagation on the circle, we may ﬁnally take the inﬁnite volume limit
where L →∞. This limit is identical to the limit where the lattice spacing a →0 is taken in
the problem of propagation on the inﬁnite lattice. Both position and momentum operators
now have continuous spectra,
[X, P] = i¯hI
X|x; X⟩= x|x; X⟩
x ∈R
P|k; P⟩= ¯hk|k; P⟩
k ∈R
(5.41)
Since the operators X and P are self-adjoint, their eigenvalues are real, and the eigenspaces
corresponding to diﬀerent eigenvalues are orthogonal to one another. The normalization of
each eigenstate may be chosen at will, since a quantum state corresponds to a vector in
Hilbert space, up to an overall complex multiplicative factor. The normalizations of the two
sets of basis vectors |x; X⟩and |k; P⟩may be chosen independently of one another. It will
be convenient to choose them as follows,
⟨x′; X|x; X⟩
=
δ(x′ −x)
⟨k′; Pk; P⟩
=
2πδ(k′ −k)
(5.42)
As a result, the completeness relations are completely determined (a complete derivation of
these results, for any Hamiltonian, will be given in section 5.5),
I =
Z
R dx |x; X⟩⟨x; X| =
Z
R
dk
2π |k; P⟩⟨k; P|
(5.43)
The overlap between a state in the X-basis, and a state in the P-basis, is given by,
⟨x; X|k; P⟩
=
e+ikx
⟨k; P|x; X⟩
=
e−ikx
(5.44)
The energy relation is
Ep = p2
2M
(5.45)
Notice that the completeness relation is just the formula for the Fourier transform.
⟨x′; X|x; X⟩= δ(x −x′) =
Z
R
dk
2π⟨x′; X|k; P⟩⟨k; P|x; X⟩=
Z
R
dk
2π eik(x′−x)
(5.46)
51

5.4.1
The Dirac δ-function
The deﬁning relation for the Dirac δ-function on the real line is such that for all test functions
f (a test function belongs to a dense set of C∞functions on R with compact support, often
called the Schwartz space), we have
Z +∞
−∞dxδ(x −y)f(x) = f(y)
(5.47)
It follows immediately that δ(x) has support only at x = 0, so that δ(x) = 0 unless x = 0,
so that xδ(x) = 0 for all x, and that
Z +∞
−∞dxδ(x −y) = 1
(5.48)
for all y. The Dirac δ-function may be viewed as a limit of a sequence of continuous or
smooth functions δn(x), which converge in the sense that their pairing against any function
in the Schwartz space converges. Examples of such sequences are
δn(x)
=
 0
|x| > 1/(2n)
n
|x| < 1/(2n)
δn(x)
=
n
√π e−n2x2
δn(x)
=
n
π
1
1 + n2x2
(5.49)
Derivatives of δ(x) may be deﬁned by using the rule that the derivative and the integral
commute with one another. Since the test functions have compact support, one may always
integrate by parts under the integral without producing boundary terms.
The deﬁning
relation of the derivative δ′(x −y) = ∂xδ(x −y) is by
Z +∞
−∞dxδ′(x −y)f(x) = −f ′(y)
(5.50)
As a result, we have for example,
xδ′(x) = −δ(x)
(5.51)
Dirac δ-functions may be multiplied under certain restricted conditions, essentially when
their supports are appropriately weighed. For example, we have the following integral for-
mulas,
Z +∞
−∞dy δ(x −y) δ(y −z) = δ(x −z)
(5.52)
but the product δ(x)δ(x) is not deﬁned.
52

5.5
General position and momentum operators and eigenstates
Given self-adjoint position and momentum operators, denoted respectively X and P, which
satisfy the canonical commutation relation [X, P] = i¯hI, there are a number of general
results that may be deduced without appeal to a speciﬁc Hamiltonian. These results will be
derived here in all generality.
• The translation operator T(a) is deﬁned for any real a ∈R by,
T(a) = exp

−ia
¯hP

(5.53)
Self-adjointness of P and reality of a and ¯h imply that T(a) is unitary, and satisﬁes
T(a)†T(a) = T(a)T(a)† = I
(5.54)
The properties of the exponential imply the following U(1) group composition property,
T(a)T(b) = T(a + b)
(5.55)
Using the Baker-Campbell-Haussdorﬀformula, eABe−A = eAdAB where the adjoint map is
deﬁned by AdAB = [A, B], the deﬁnition of T(a), and the canonical commutation relations,
it follows,
T(a)†XT(a) = X + aI
(5.56)
More generally, we have T(a)†f(X)T(a) = f(X + aI) for any analytic function f. Taking a
inﬁnitesimal, T(a) ∼I −iaP/¯h, or equivalently P, generates inﬁnitesimal translations in X.
• Since X and P are self-adjoint, each operator separately may be diagonalized, with
real eigenvalues. The corresponding eigenvalues will be denoted x and ¯hk respectively, and
the eigenstates will be denoted as follows,
X|x; X⟩
=
x|x; X⟩
P|k; P⟩
=
¯hk|k; P⟩
(5.57)
Self-adjointness also implies that orthogonality of eigenstates associated with distinct eigen-
values, namely ⟨x′; X|x; X⟩= 0 for x′ ̸= x, and ⟨k′; Pk; P⟩= 0 for k′ ̸= k. The normalization
of the states may be ﬁxed, in part, by choosing the following relations,
⟨x′; X|x; X⟩
=
δ(x′ −x)
⟨k′; P|k; P⟩
=
2πδ(k′ −k)
(5.58)
53

This choice of normalization uniquely determines the completeness relation, and we have4
I
=
Z
R dx |x; X⟩⟨x; X|
I
=
Z
R
dk
2π |k; P⟩⟨k; P|
(5.59)
Note that the normalization of (5.58) ﬁxes the “norm” of the states, but not their relative
phases, which are left undetermined. The proofs of both completeness relations are similar,
so we shall carry out explicitly only the ﬁrst one. Denote the result of the x-integral by A,
A =
Z
R dx |x; X⟩⟨x; X|
(5.60)
Now apply the operator to a ket |y; X⟩,
A|y; X⟩
=
Z
R dx |x; X⟩⟨x; X|y; X⟩
=
Z
R dx |x; X⟩δ(x −y) = |y; X⟩
(5.61)
In going from the ﬁrst line to the second, we have used the normalization of the position
eigenstates, deﬁned above. Since this relation holds for all y, and |y; X⟩spans a basis, it
must be that A = I by its very deﬁnition.
• The overlaps of the position and momentum eigenstates may be determined by com-
puting the matrix element ⟨k; P|T(x)|0; X⟩in two diﬀerent ways, namely by letting T(a) act
either on the left or on the right, and we ﬁnd,
⟨k; P|x; X⟩= ⟨k; P|T(x)|0; X⟩= e−ikxφ(k)
(5.62)
where φ(k) = ⟨k; P|0; X⟩. As a result, we have
⟨k; P|x; X⟩
=
φ(k) e−ikx
⟨x; X|k; P⟩
=
φ(k)∗e+ikx
(5.63)
The function φ(k) may be determined, in part, from the completeness relations, as follows,
⟨k′; P|k; P⟩
=
Z
R dx⟨k′; Px; X⟩⟨x; X|k; P⟩
=
φ(k′)∗φ(k)
Z
R dx ei(k−k′)x
=
2πδ(k′ −k)|φ(k)|2
(5.64)
4The choice of normalization in (5.58) is not unique. One might have multiplied δ(x′ −x) by function
f(x), and δ(k′ −k) by an independent function ˜f(k). As a result, the completeness relations of (5.59) will
be replaced by dx →dx/f(x) and dk →dk/ ˜f(k). The choice we have adopted in (5.58) is, for almost all
applications, the simplest one, and it is almost universally adopted in the literature. (One exception is when
R carries a general Riemannian metric, not just the ﬂat Euclidean metric as we have here.)
54

so that |φ(k)| = 1. The phase of φ(k) is not determined by the normalization conditions
(5.58). The simplest choice is given by φ(k) = 1, and it is this choice that we adopt.
• Matrix elements of the operators X and P between a general state |ψ⟩and the position
or momentum eigenstates may be derived in a similar manner. It is customary to deﬁne the
position and momentum space wave functions respectively by,
ψ(x)
≡
⟨x; X|ψ⟩
˜ψ(k)
≡
⟨k; P|ψ⟩
(5.65)
All other matrix elements may be expressed in terms of these wave functions. Thus, one has
for example,
⟨x; X|X|ψ⟩
=
xψ(x)
⟨k; P|P|ψ⟩
=
¯hk ˜ψ(k)
⟨x; X|P|ψ⟩
=
−i¯h ∂
∂xψ(x)
⟨k; P|X|ψ⟩
=
i ∂
∂k
˜ψ(k)
(5.66)
Matrix elements between general states |φ⟩and |ψ⟩, with wave functions respectively φ(x),
and ψ(x), may be calculated analogously,
⟨ψ|X|φ⟩
=
Z
R dx ψ(x)∗⟨x; X|X|φ⟩=
Z
R dx xψ(x)∗φ(x)
⟨ψ|P|φ⟩
=
Z
R dx ψ(x)∗⟨x; X|P|φ⟩= −i¯h
Z
R dx ψ(x)∗∂φ(x)
∂x
(5.67)
5.6
The harmonic oscillator
The 1-dimensional harmonic oscillator for the position X and momentum P operators is
given by the Hamiltonian
H =
1
2M P 2 + 1
2Mω2X2
(5.68)
where [X, P] = i¯h. The constants M and ω are respectively the mass and the frequency,
while the combination K = Mω2 is the spring constant. The importance of the harmonic
oscillator derives from the fact that it may be used as an approximation for the Hamiltonian
with a general potential V , considered around one of the minima x0 of V , where,
V (x) = V (x0) + 1
2V ′′(x0)(x −x0)2 + · · ·
(5.69)
55

The solution to the harmonic oscillator problem will then provide an approximation to the
problem for general potential V for reasonably low energies.
Of course, one may derive the spectrum of the harmonic oscillator by solving the Schr¨odinger
equation. The harmonic oscillator actually provides the perfect example of a system that may
be solved much more directly using operator methods. The techniques we shall present also
will also illustrate more directly how the principles of quantum mechanics may be applied.
5.6.1
Lowering and Raising operators
We begin by reformulating the harmonic oscillator in terms of lowering and raising operators
a and a†, deﬁned as follows,
a
=
1
√
2Mω¯h

Mω X + i P

a†
=
1
√
2Mω¯h

Mω X −i P

(5.70)
For self-adjoint operators X and P, clearly a† is the adjoint operator of a, as the notation
indeed indicates. This change of variables has been chosen so that
H = ¯hω

a†a + 1
2

[a, a†] = 1
(5.71)
The terminology of lowering and raising operators for a and a†, derives from the fact that
they satisfy the following commutation relations with the Hamiltonian H,
[H, a]
=
−¯hω a
[H, a†]
=
+¯hω a†
(5.72)
For this simple system, there are no possible degeneracies and the Hamiltonian by itself may
be used to span the complete set of commuting observables. One may verify that no operator
built from x and p commutes with H, lest it be functions of H. Thus, any state |n⟩may be
uniquely labeled by its energy En,
H|n⟩= En|n⟩
(5.73)
Applying the operators a and a† respectively lowers and raises the energy of a state by ¯hω,
H a |n⟩
=

a H + [H, a ]

|n⟩= (En −¯hω) a|n⟩
H a†|n⟩
=

a†H + [H, a†]

|n⟩= (En + ¯hω)a†|n⟩
(5.74)
56

Next, we show that the operator H is bounded from below by
1
2¯hω.
Indeed, take any
normalized state |ψ⟩, and compute the expectation value of H,
⟨ψ|H|ψ⟩= 1
2¯hω + ¯hω⟨ψ|a†a|ψ⟩= 1
2¯hω + ¯hω||aψ||2 ≥1
2¯hω
(5.75)
Hence all eigenvalues of H must be greater than or equal to 1
2¯hω.
5.6.2
Constructing the spectrum
Now here is the crucial step that will allow us to solve this system without ever solving a
diﬀerential equation. Consider a normalized state |n⟩with energy En. Since a lowers the
energy by ¯hω, it follows that ak|n⟩should have energy En −k¯hω. But for suﬃciently large
k, this energy would dip below the bound 1
2¯hω, which is not possible. Thus, it must be that
for some values of k > 0, the state ak|n⟩is actually zero, and the spectrum must contain a
state which is annihilated by a. We shall denote this state by |0⟩,
a|0⟩= 0
⇒
E0 = 1
2¯hω
(5.76)
The state |0⟩is the ground state; it is the unique state of lowest energy E0, which actually
saturates the lower bound on the expectation value of the Hamiltonian. All other states are
then obtained by multiple application of the raising operator a†, and we ﬁnd,
|n⟩∼

a†n |0⟩
⇒
En = ¯hω

n + 1
2

(5.77)
which is indeed the entire harmonic oscillator spectrum for n ≥0.
Since the states |En⟩for diﬀerent n belong to diﬀerent eigenvalues of the self-adjoint op-
erator H, they are automatically orthogonal. We shall also assume that they are normalized,
⟨m|n⟩= δm,n. The matrix elements of the operators a and a† are as follows,
a†|n⟩
=
√
n + 1 |n + 1⟩
a|n⟩
=
√n |n −1⟩
(5.78)
Or equivalently, we have ⟨m|a|n⟩= √nδm,n−1.
5.6.3
Harmonic oscillator wave functions
The wave function ψn(x) = ⟨x; X|n⟩for a state |n⟩may also be computed simply. We start
with the ground state, which satisﬁes
⟨x; X|a|0⟩=
1
√
2M¯hω⟨x; X|(MωX + iP)|0⟩= 0
(5.79)
57

Since we have (see section 5.5 for the derivation),
⟨x; X|X|ψ⟩= xψ(x)
⟨x; X|P|ψ⟩= −i¯h ∂
∂xψ(x)
(5.80)
The ground state wave function is found to obey the ﬁrst order diﬀerential equation,
 ∂
∂x + Mω
¯h x
!
ψ0(x) = 0
(5.81)
The unique solution is given by
ψ0(x) =
Mω
π¯h
 1
4
exp

−Mω
2¯h x2

(5.82)
where we have included the proper normalization factor.
Finally, recall that the wave functions for excited states are given by the ground state
wave function multiplied by Hermite polynomials. This can also be recovered directly from
the operator formalism. To simplify notation, we use the scaled coordinate z = x(Mω/¯h)
1
2,
in terms of which we have
a = 1
√
2
 
z + ∂
∂z
!
a† = 1
√
2
 
z −∂
∂z
!
(5.83)
As a result,
ψn(x) =
1
√
n! 2n
 
z −∂
∂z
!n
ψ0(z) ∼Hn(x)e−1
2 z2
(5.84)
and it follows that Hn+1(z) = 2zHn(z) −H′
n(z), which is a convenient way to deﬁne the
Hermite polynomials (up to an overall normalization).
5.7
The angular momentum algebra
Both orbital angular momentum and spin satisfy the same angular momentum algebra. We
shall denote the general operators of angular momentum by J, so that its components satisfy
the angular momentum algebra,
[Jx, Jy] = i¯hJz
[Jy, Jz] = i¯hJx
[Jz, Jx] = i¯hJy
(5.85)
A slightly more convenient notation is to use numerical subscripts for the axes, and let
J1 = Jx, J2 = Jy, and J3 = Jz, so that the algebra can be written in a single vector equation,
[Ji, Jj] = i¯h
3
X
k=1
εijkJk
(5.86)
58

where εijk is totally antisymmetric in i, j, k and is normalized to ε123 = 1.
We now study all possible quantum systems on which the angular momentum algebra
can be realized. Since the rotations generate symmetries of a quantum system, they must be
realized on the quantum system in terms of unitary operators. The inﬁnitesimal generators
of these unitary transformations are precisely the angular momentum operators J1, J2, J3
which must be self-adjoint operators, i.e. observables. The commutation relations of the J′s
indeed respect their self-adjointness.
5.7.1
Complete set of commuting observables
The angular momentum algebra possesses an operator (other than 0 or I) which commutes
with all three Ji, i = 1, 2, 3, namely the Casimir operator
J2 = J2
1 + J2
2 + J2
3
(5.87)
Any other operator which commutes with all three Ji, i = 1, 2, 3 must be functionally
dependent on J2. In this sense, J2 is unique. Given the self-adjointness of the Ji, i = 1, 2, 3,
it is manifest that J2 is also self-adjoint, and thus an observable.
To construct the Hilbert space H of a quantum system,we identify a complete set of
commuting observables, and then simultaneously diagonalize these observables to ﬁnd a basis
for H. Assuming that the Hilbert space H contains one and only one state associated with
each set of quantum numbers leads to an “irreducible quantum system”. Mathematically, this
means that we will ﬁnd an “irreducible representation” of the angular momentum algebra. A
general quantum system associated with the angular momentum algebra may be reducible,
i.e. it can be decomposed as a direct sum of a number of irreducible systems.
We choose one of the generators, say J3 as the ﬁrst observable. Clearly, no non-zero linear
combination of J1 and J2 commutes with J3, but the Casimir operator J2 does commute with
J3. This is a standard result that a complete basis for all angular momentum states may
be parametrized by the quantum numbers of J3 and J2. We shall label the states by |j, m⟩
where j, m ∈R, since they correspond to eigenvalues of observables.
J2|j, m⟩
=
λ(j)¯h2|j, m⟩
J3|j, m⟩
=
m¯h|j, m⟩
(5.88)
The factors of ¯h have been pulled out for later convenience.
5.7.2
Lowering and raising operators
We introduce lowering and raising operators as follows,
J± = J1 ± iJ2
(5.89)
59

Given that J1 and J2 are self-adjoint, the operators J± are not self-adjoint, but are instead
the adjoints of one another,
(J+)† = J−
(J−)† = J+
(5.90)
In terms of these operators, the angular momentum algebra assumes the form,
[J3, J±] = ±¯hJ±
⇔
J3J± = J±(J3 ± ¯h)
[J+, J−] = +2¯hJ3
(5.91)
Since J2 commutes with J±, the value j or λ(j) remains unchanged upon applying J± to a
state |λ(j), m⟩. The m-value will be lowered or raised, since
J3 J± |j, m⟩= ¯h(m ± 1)J±|j, m⟩
(5.92)
5.7.3
Constructing the spectrum
Our goal is to realize the angular momentum algebra of a Hilbert space. Since λ(j) and
m label diﬀerent eigenvalues of self-adjoint operators, the corresponding eigenstates are
orthogonal, and we may normalize them by requiring
⟨j, m|j′, m′⟩= δj,j′δm,m′
(5.93)
We shall now show that, given j, the range for the eigenvalue m must be bounded. To do
so, express J2 in terms of J3 and J±,
J2
=
1
2(J+J−+ J−J+) + J2
3
=
J+J−+ J2
3 −¯hJ3
=
J−J+ + J2
3 + ¯hJ3
(5.94)
Now, both the operators J+J−and J−J+ are positive, since for all j, m,
⟨j, m|J+J−|j, m⟩= ||J−|j, m⟩||2
=
¯h2[λ(j) −m2 + m] ≥0
⟨j, m|J−J+|j, m⟩= ||J+|j, m⟩||2
=
¯h2[λ(j) −m2 −m] ≥0
(5.95)
Clearly, given λ(j), the values of m are bounded from above and from below. But since
successive application of J+ would raise m indeﬁnitely, there must be a state with value
m = m+ which is annihilated by J+. Similarly, since successive application of J−would
lower m indeﬁnitely, there must be a state with value m = m−which is annihilated by J−.
By construction, we will have m+ ≥m−, and
J+|j, m+⟩= 0
⟨j, m+|j, m+⟩= 1
J−|j, m−⟩= 0
⟨j, m−|j, m−⟩= 1
(5.96)
60

The norms of J±|j, m±⟩were already computed earlier, and thus require that
λ(j) −m+(m+ + 1)
=
0
λ(j) −m−(m−−1)
=
0
(5.97)
Eliminating λ(j) gives a relation directly between m+ and m−, (m++m−)(m+−m−+1) = 0.
Since we have m+ −m−≥0, the second parenthesis never vanishes, and we must have
m−= −m+. We assumed that the quantum system was irreducible, so that for given j, all
states with diﬀerent m are mapped into one another under J±. Thus, successively applying
J−to |j, m+⟩must ultimately yield the state |j, m−⟩. Since the number of times J−is being
applied is of clearly an integer, we must have that m+ −m−= 2m+ is a positive or zero
integer. We deﬁne j to be this integer or half-integer j ≡m+, so that
λ(j) = j(j + 1)
2j + 1 ∈N
(5.98)
The integer 2j + 1 is the dimension of the Hilbert space Hj for this irreducible quantum
system, since the number of basis vectors |j, m⟩with m = −j, −j + 1, −j + 2, · · · , j −1, j is
precisely 2j + 1. For later convenience, we list the matrix elements of all the operators,
J2|j, m⟩
=
j(j + 1) ¯h2 |j, m⟩
J3|j, m⟩
=
m ¯h |j, m⟩
J+|j, m⟩
=
q
(j −m)(j + m + 1) ¯h |j, m + 1⟩
J−|j, m⟩
=
q
(j −m + 1)(j + m) ¯h |j, m −1⟩
(5.99)
5.8
The Coulomb problem
The Coulomb problem involves a single mobile charged particle in the electro-static poten-
tial of a ﬁxed central charge. In Hydrogen-like atoms, for example, the ﬁxed charge is a
nucleus and the mobile charge is an electron. The Coulomb potential is then attractive and
produces bound states. But it also covers systems in which the mobile charge is a proton or
a positron, so that no bound states exist. For the time being, eﬀects of spin are neglected.
The Schr¨odinger equation for the Coulomb problem with charges q1 and q2 is given by,
−¯h2
2m∆ψE(r) + q1q2
r ψE(r) = EψE(r)
(5.100)
As for any spherically symmetric problem, we work in spherical coordinates r, θ, φ, in terms
of which the Laplace operator takes the form,
∆= 1
r2
∂
∂r
 
r2 ∂
∂r
!
−L2
¯h2r2
(5.101)
61

The operator L2 may be expressed solely in terms of the coordinates θ and φ, but we shall not
need its explicit form here. Instead, we specialize to a deﬁnite eigenstate of L2, labeled by
its eigenvalue ¯h2ℓ(ℓ+ 1), with ℓ= 0, 1, 2, · · ·, corresponding to s, p, d-waves etc respectively.
The remaining equation for the radial wave function ϕℓ,E(r) takes the form,
−¯h2
2m
 
ϕ′′
ℓ,E + 2
rϕ′
ℓ,E −ℓ(ℓ+ 1)
r2
ϕℓ,E
!
+ q1q2
r ϕℓ,E = Eϕℓ,E
(5.102)
It is always a good idea to extract all dimensionful quantities, and leave a diﬀerential equation
in terms of dimensionless variables. To do so, we rescale r by
r = λx
λ2 = ± ¯h2
2mE
(5.103)
where we have the + sign for scattering states with E > 0, and −for bound states with
E < 0. The equation is then governed by a single dimensionless parameter for ﬁxed ℓ,
ε = 2mq1q2λ
¯h2
(5.104)
and takes the ﬁnal form in terms of the reduced radial wave function fℓ,ε(x) = ϕℓ,E(r)/r,
given as follows,
x2f ′′
ℓ,ε −ℓ(ℓ+ 1)fℓ,ε −εxfℓ,ε ± x2fℓ,ε = 0
(5.105)
5.8.1
Bound state spectrum
For the bound state problem, the sign is −, and solutions that are normalizable at ∞must
behave as e−x and at zero like xℓ+1. Extracting this behavior then leaves,
fℓ,ε(x) = gℓ,ε(x)xℓ+1e−x
(5.106)
where gℓ,ε(x) now satisﬁes the equation,
xg′′
ℓ,ε + (2ℓ+ 2 −2x)g′
ℓ,ε −(2 + 2ℓ−ε)gℓ,ε = 0
(5.107)
The solutions leading to normalizable wave functions are polynomial in x.
To admit a
polynomial solution of degree ν requires the relation
ε = 2(ℓ+ 1 + ν) ≡2n
(5.108)
We ﬁnd the well-known result that the spectrum of bound states of the Coulomb problem is
in fact independent of ℓ, and depends only on the principal quantum number n, as deﬁned
above. Substituting these values into the above formulas to obtain the energy, we ﬁnd,
En = −1
2mc2 1
n2
q2
1q2
2
¯h2c2
(5.109)
62

For an electron we have q1 = −e, and for a nucleus of with Z protons we have q2 = Ze. In
addition, in cgs units (which is what we have been using here), the combination
α = e2
¯hc
(5.110)
is dimensionless and is referred to as the ﬁne structure constant, with value approximately
given by α = 1/137.04. Thus, the bound state energy levels of this system are given by,
En = −1
2mc2α2Z2
(5.111)
which is equivalent to the standard formula.
The solutions gℓ,2n(x) for n integer are associated Laguerre polynomials, denoted Lp
q−p(x),
and given in terms of Laguerre polynomials Lq(x) by,
gℓ,2n(x)
=
L2ℓ+1
n−ℓ−1(x)
Lp
q−p(x)
=
(−1)p dp
dxpLq(x)
Lq(x)
=
ex dq
dxq

xqe−x
(5.112)
The spherical harmonics, which are the ﬁnal ingredient of the full wave functions of the
Coulomb problem, will be derived explicitly in the chapter on angular momentum.
5.8.2
Scattering spectrum
The equation is now,
x2f ′′
ℓ,ε −ℓ(ℓ+ 1)fℓ,ε −εxfℓ,ε + x2fℓ,ε = 0
(5.113)
The asymptotic behavior of the solutions as x →∞is given by an oscillatory exponential
e±ix, as is expected for a scattering problem. Since the diﬀerential equation is real, its two
independent solutions may be taken to be complex conjugates of one another, so we shall
choose the asymptotic behavior to be e−ix. Extracting also the familiar factor of xℓ+1 for
regularity at x = 0, we have
fℓ,ε(x) = gℓ,ε(x)xℓ+1eix
(5.114)
so that the equation becomes,
xg′′
ℓ,ε + (2ℓ+ 2 −2ix)g′
ℓ,ε −(2i(ℓ+ 1) + ε) gℓ,ε = 0
(5.115)
63

This equation is of a well-known form, namely that of a conﬂuent hypergeometric function,
or Kummer function,
gℓ,ε(x) = M

ℓ+ 1 −iε
2 , 2ℓ+ 2, 2ix

(5.116)
To get a better idea of what these functions are, it is useful to give an integral representation,
M(a, b, z) =
Γ(b)
Γ(b −a)Γ(a)
Z 1
0 dt etz ta−1(1 −t)b−a−1
(5.117)
Most of the essential properties of M, such as its asymptotics for large and small z, may be
read oﬀdirectly from this representation.
5.9
Self-adjoint operators and boundary conditions
The precise deﬁnition of self-adjointness is not just a matter of mathematical sophistication,
but instead has physical consequences. On the one hand, a given diﬀerential operator may
allow for inequivalent domains, resulting in inequivalent physical spectra. On the other hand,
an operator that “looks” self-adjoint, but is not actually self-adjoint, may not have a real
spectrum, and/or mutually orthogonal eigenspaces associated with distinct eigenvalues. We
illustrate these possibilities below with the help of some concrete examples.
5.9.1
Example 1:
One-dimensional Schr¨odinger operator on half-line
Consider a 1-dim quantum system given by the following Hamiltonian,
H1 = −¯h2
2m
d2
dx2 + V (x)
(5.118)
As an operator on complex functions on the real line, and for a “reasonable” potential V (x),
the Hamiltonian H1 is self-adjoint. The domain D(H1) may be taken to be the sub-space of
L2(R) consisting of inﬁnitely diﬀerentiable functions (denoted C∞) which vanish at x = ±∞.
Self-adjointness then follows from the fact that all functions in D(H1) vanish at x = ±∞.
As an operator on functions on x ∈[0, +∞], the Hamiltonian H1 may be self-adjoint for
certain choices of the domain, but not for others. The key relation is as follows,
(ψ, H1φ) −(H1ψ, φ) = ¯h2
2mj(0)
(5.119)
where j(x) is the probability current density, deﬁned by
j(x) = φ(x)dψ∗
dx (x) −ψ∗(x)dφ
dx(x)
(5.120)
64

The operator H1 will be self-adjoint if a domain D(H1) can be chosen for the functions ψ
and φ such that j(0) = 0 for any pair ψ, φ ∈D(H1). This will be the case if the domain is
deﬁned to be the subspace of C∞functions which obey
ψ(0) + λdψ
dx (0) = 0
(5.121)
for a given real constant λ. Note that λ = 0 and corresponds to Dirichlet boundary condi-
tions, while λ = ∞corresponds to Neumann boundary conditions. Thus, λ parametrizes an
interpolation between Dirichlet and Neumann boundary conditions, and for each value of λ,
H1 is self-adjoint.
The spectrum of H1 depends on λ even though, at face value, the diﬀerential operator H1
of (5.118) does not involve λ. Consider, for example, the problem with a potential V (x) = 0
for 0 ≤x < ℓ, and V (x) = +∞for x ≥ℓ, and solve for the eigenvalues E of H1. To satisfy
the vanishing boundary condition at x = ℓ, we must have
ψ(x) = sin k(x −ℓ)
E = ¯h2k2
2m
(5.122)
where k can be any positive real number. Enforcing also the λ-dependent boundary condition
(5.121) at x = 0 renders the spectrum of k discrete, and requires,
tg(kℓ) = λk
(5.123)
We recover the special cases,
λ = 0
kn = 2nπ
2ℓ
n = 1, 2, 3, · · ·
λ = ∞
kn = (2n −1)π
2ℓ
(5.124)
For intermediate values of λ, the solutions are transcendental, and may be determined graph-
ically. They clearly interpolate between the above cases. Thus, the spectrum depends on
the precise domain, through the boundary conditions.
5.9.2
Example 2:
One-dimensional momentum in a box
Next, consider the 1-dim quantum system given by the Hamiltonian,
H2 = i¯hc d
dx
(5.125)
As an operator on functions on the real line, H2 is self-adjoint. But what happens when we
attempt to put the system in a box ? For example, can H2 be self-adjoint when acting on
functions on the ﬁnite interval [0, ℓ] with ℓ> 0 ?
65

Before launching into any math, let’s solve the Schr¨odinger equation for H2,
i¯h ∂
∂tψ(t, x) = i¯hc ∂
∂xψ(t, x)
(5.126)
or equivalently
 ∂
∂t + c ∂
∂x
!
ψ(t, x) = 0
(5.127)
The general solution of this equation is ψ(t, x) = f(x−ct) for any function f of one variable.
The wave function corresponds to a purely right-moving particle. The Schr¨odinger equation
turns out to be so restrictive that no left-moving particles can be allowed in the spectrum.
We now immediately see why imposing a boundary condition on this Hamiltonian could
be problematic.
Both Dirichlet and Neumann boundary conditions would correspond to
a reﬂection of waves, which cannot happen. The only allowed boundary condition on an
interval would be periodic boundary conditions, since the right-moving wave could then
freely continue to travel without having to be reﬂected.
This may be seen concretely on the interval [0, ℓ], as follows,
(ψ, H2φ) −(H2ψ, φ) = i¯hc

ψ(x)∗φ(x)

x=ℓ
x=0
(5.128)
Self-adjointness of H2 requires the vanishing of the right hand side. If we require ψ(ℓ) =
ψ(0) = 0, then φ(ℓ) and φ(0) can take any values, so this choice of domain does not lead to
a self-adjoint H2. Assuming now that ψ(0) ̸= 0, and φ(0) ̸= 0, the vanishing of (5.128) is
equivalent to,
ψ∗(ℓ)
ψ∗(0)
φ(ℓ)
φ(0) = 1
(5.129)
whose general solution is given by the Bloch wave periodicity condition,
ψ(ℓ)
=
eiθψ(0)
φ(ℓ)
=
eiθφ(0)
(5.130)
for a real parameter θ. The spectrum of H2 again depends on θ, since the eigenstate wave
functions are given by
ψn(x) = eiknx
kn = (θ + 2πn)/ℓ
n ∈Z
(5.131)
The eigenvalues of H2 are then given by −¯hckn, and are real. Notice that the eigenfunctions
are also mutually orthogonal for distinct n, as we indeed expect from a self-adjoint operator.
66

5.9.3
Example 3:
One-dimensional Dirac-like operator in a box
A lesson we have learned from Example 2 is that the momentum operator corresponds to
a quantum system of left-movers only, (and no right-movers), a situation that vitiates the
possibility of imposing any reﬂecting boundary conditions. We may double the number of
degrees of freedom, however, and include one left-moving and one right-moving degree of
freedom. Thus, we consider doublets of wave functions ψ1 and ψ2,
ψ ≡
 ψ1
ψ2

φ ≡
 φ1
φ2

(5.132)
with Hermitean inner product,
(ψ, φ) =
Z ℓ
0 dx (ψ∗
1φ1 + ψ∗
2φ2) (x)
(5.133)
and Hamiltonian (here we use the standard notation ∂x ≡∂/∂x),
H3 = ¯hc
 0
∂x
−∂x
0

(5.134)
It is straightforward to evaluate the combinations,
(H3ψ, φ)
=
¯hc
Z ℓ
0 dx

∂xψ∗
2φ1 −∂xψ∗
1φ2

(x)
(ψ, H3φ)
=
¯hc
Z ℓ
0 dx

ψ∗
1∂xφ2 −ψ∗
2∂xφ1

(x)
(5.135)
and
(H3ψ, φ) −(ψ, H3φ) = ¯hc

ψ2φ1(ℓ) −ψ∗
1φ2(ℓ) −ψ2φ1(0) + ψ∗
1φ2(0)

(5.136)
Self-adjointness of H3 requires this combination to vanish. This may be achieved by imposing,
for example, the MIT bag boundary conditions (which were introduced to model quarks
conﬁned to nucleons),
φ2(ℓ) = λℓφ1(ℓ)
φ2(0) = λ0φ1(0)
ψ2(ℓ) = λℓψ1(ℓ)
ψ2(0) = λ0ψ1(0)
(5.137)
for two real independent constants λ0 and λℓ. The spectrum of H3 is now real, but does
depend upon λ0 and λℓ.
67

6
Quantum Mechanics Systems
Quantum systems associated with systems of classical mechanics are fundamental. In fact, it
is for these systems that we write the Schr¨odinger equation; they will also admit a formulation
in terms of functional integrations over all possible paths, to be discussed in 221B. It is useful
to begin with a brief review of Lagrangian and Hamiltonian mechanics.
6.1
Lagrangian mechanics
At a most basic level, we describe systems by the time-evolution of the individual particles
that make up the system. Particle n is characterized in classical mechanics by its position
rn(t) at any given time t. It is a fact of Nature that its basic laws involve equations that are
ﬁrst or second order in time derivatives, but not higher. Newton’s force law F = Ma, for
example, is second order in time derivatives. As a result, the initial conditions of a classical
system are the positions rn and velocities ˙rn of each of its constituent particles. The laws of
physics then yield the positions at later times.
The starting point of Lagrangian mechanics is a set of generalized positions qi with
i = 1, · · · , N, describing all the degrees of freedom of classical particles. For n particles
in 3-dimensional space, for example, we use N = 3n generalized position variables qi. The
associated generalized velocities are denoted by ˙qi = dqi/dt. Under the assumption of at most
second order time derivative evolution equations, Lagrangian mechanics will be completely
speciﬁed by a single function,
L(q, ˙q; t) = L(q1, · · · , qN, ˙q1, · · · , ˙qN; t)
(6.1)
referred to as the Lagrangian. The associated Euler-Lagrange equations
d
dt
 ∂L
∂˙qi
!
−∂L
∂qi
= 0
i = 1, · · ·, N
(6.2)
arise as the solution to a variational principle of the action functional
S[q] = S[q1, · · ·, qN] =
Z t2
t1
dtL(q1, · · · , qN, ˙q1, · · · , ˙qN; t)
(6.3)
The notation S[q1, · · · , qN] indicated that S is a functional of the path (q1(t), · · · , qN(t))
spanned for t ∈[t1, t2]. To derive the Euler-Lagrange equations from the action, we perform
a variation δqi(t) on the path qi(t), keeping the end points ﬁxed,
δqi(t1) = δqi(t2) = 0
(6.4)
68

The variation is then computed using standard chain rule,
δS[q]
=
S[q + δq] −S[q]
=
Z t2
t1
dt

L(q + δq, ˙q + δ ˙q; t) −L(q, ˙q; t)

=
Z t2
t1
dt
X
i
∂L
∂qi
δqi + ∂L
∂˙qi
δ ˙qi

(6.5)
Using now the fact that
δ ˙qi = d
dtδqi
(6.6)
integrating by parts and using the vanishing boundary conditions, we are left with
δS[q] =
Z t2
t1
dt
X
i

−d
dt
∂L
∂˙qi
+ ∂L
∂qi

δqi
(6.7)
Finally, requiring that a path be stationary amounts to requiring that a small variation
around the path leaves the action unchanged δS[q] = 0, which clearly is equivalent to the
Euler-Lagrange equations.
In the simplest examples, the Lagrangian is the diﬀerence between kinetic and potential
energy V of the generalized positions,
LV = 1
2
N
X
i=1
mi ˙q2
i −V (q1, · · · , qN)
(6.8)
for which the Euler-Lagrange equations are
mi¨qi = −∂V
∂qi
(6.9)
In a slightly more complicated example, we have the Lagrangian of a charged particle in
3 space dimensions in the presence of an electric E(r, t) and magnetic ﬁeld B(r, t), which
derive from an electric potential Φ(r, t) and vector ﬁeld A(r, t) as follows,
E = −⃗∇Φ −∂A
∂t
B = ⃗∇× A
(6.10)
The associated Lagrangian for a particle with electric charge e, mass m, and position r is,
LA = 1
2m˙r2 −eΦ(r, t) + eA(r, t) · ˙r
(6.11)
Check that the Euler-lagrange equation coincides with the Lorentz force law
m¨r = eE(r, t) + e˙r × B(r, t)
(6.12)
69

6.2
Hamiltonian mechanics
Returning to the general case, with Lagrangian L(q, ˙q; t), one deﬁnes the momentum pi
canonically conjugate to qi as follows,
pi = ∂L
∂˙qi
(6.13)
For the simplest systems, like the Lagrangian LV , the canonical momentum coincides with the
mechanical momentum, given by mass times velocity, pi = mi ˙qi. But for more complicated
Lagrangians, like LA, the two quantities diﬀer, and one has in this case p = m˙r + eA.
We shall assume that the relation pi = pi(q, ˙q; t) is invertible,5 so that the generalized
velocities can be obtained uniquely as a function of the generalized coordinates and momenta,
˙qi = ˙qi(q, p; t)
(6.14)
The Hamiltonian is now deﬁned as the Legendre transform of the Lagrangian,
H(q, p; t) =
N
X
i=1
pi ˙qi −L(q, ˙q; t)
(6.15)
with the understanding that the velocities are eliminated in favor of q and p on the rhs
using (6.14). The space of all allowed positions qi and momenta pi is referred to as phase
space. Hamiltonian mechanics is formulated in terms of time evolution equations (or ﬂows)
on phase space.
The Hamilton equations are obtained as follows. Under a general variation of q and p,
the rhs above transforms as,
δH =
X
i
 
δpi ˙qi + piδ ˙qi −∂L
∂qi
δqi −∂L
∂˙qi
δ ˙qi
!
(6.16)
Notice that the second and fourth terms on the rhs cancel by the very deﬁnition of pi.
Alternatively, the variation of H in terms p and q only gives,
δH =
X
i
 ∂H
∂qi
δqi + ∂H
∂pi
δpi
!
(6.17)
Comparing the two expressions for δH and using the Euler-Lagrange equation gives the
Hamilton equations,
∂H
∂qi
= −˙pi
∂H
∂pi
= ˙qi
(6.18)
5There are many physically interesting Lagrangians where this relation is not invertible. These systems
are referred to as having constraints.
70

Since the number of dynamical variables on phase space has been doubled up, Hamilton’s
equations are now ﬁrst order.
There is a somewhat formal structure on phase space, the Poisson bracket which is very
useful for quantum mechanics. For any two functions a(q, p) and b(q, p), it is deﬁned by
{a, b} ≡
N
X
i=1
 ∂a
∂qi
∂b
∂pi
−∂a
∂pi
∂b
∂qi
!
(6.19)
The Poisson bracket is linear in a and b, anti-symmetric under interchange of its arguments
{a, b} = −{b, a}, acts as a derivative in each argument,
{a, bc} = {a, b}c + {a, c}b
(6.20)
and satisﬁes the Jacobi identity,
{{a, b}, c} + {{b, c}, a} + {{c, a}, b} = 0
(6.21)
It also satisﬁes the elementary relation
{qi, pj} = δi,j
(6.22)
The time derivative of any function A(q, p; t) may be expressed simply via Poisson brackets,
d
dta(q, p; t) = ∂
∂ta(q, p; t) +
X
i
 ∂a
∂qi
˙qi + ∂a
∂pi
˙pi
!
(6.23)
Using Hamilton’s equations to obtain ˙qi and ˙pi, we have
d
dta(q, p; t) = ∂
∂ta(q, p; t) + {a, H}
(6.24)
In particular, Hamilton’s equations may be recast in the following form,
˙qi
=
{qi, H}
˙pi
=
{pi, H}
(6.25)
6.3
Constructing a quantum system from classical mechanics
There are two general procedures for associating a quantum system with a system of classical
mechanics. The ﬁrst is via the correspondence principle which produces a Hilbert space, a
set of observables and a Hamiltonian from a classical mechanics system in the Hamiltonian
71

formulation. A second is via the functional or path integral which directly produces prob-
ability amplitudes from a classical mechanics system in the Lagrangian formulation; this
method will be discussed in the next section.
Let the classical mechanics system be given by a Hamiltonian H(q, p) on a phase space
qi, pj, with i, j = 1, · · ·, N,
{qi, pj} = δi,j
˙a(q, p) = {a, H}
(6.26)
The correspondence principle states that, to this classical system, there corresponds a quan-
tum system with the following observables,
classical variable
Quantum Observable
qi
→
Qi
pi
→
Pi
a(p, q)
→
A(P, Q)
{a, b}
→
−i
¯h[A, B]
(6.27)
In particular, the classical Hamiltonian has a quantum counterpart H(P, Q), and the Poisson
bracket relations between qi and pj become the canonical commutation relations,
[Qi, Pj] = i¯hδi,j
[Qi, Qj] = [Pi, Pj] = 0
(6.28)
The correspondence principle maps the Hamilton time-evolution equations into the Schr¨odinger
equation for observables, i.e. given in the Heisenberg formulation,
i¯h d
dtA = [A, H] + i¯h ∂
∂tA
(6.29)
The evolution operator may be used to translate the Heisenberg formulation into the Schr¨odinger
formulation.
6.4
Schr¨odinger equation with a scalar potential
In the usual position realization of the canonical commutation relations, given by
Qi = qi
Pi = −i¯h ∂
∂qi
(6.30)
the Hilbert space is that of of square integrable functions of qi. The simplest non-relativistic
classical mechanical systems, given in terms of a potential V (q), with Hamiltonian,
H(q, p) = p2
2m + V (q)
(6.31)
72

have a unique quantum Hamiltonian, given by the correspondence principle,
H(Q, P) = P2
2m + V (Q)
(6.32)
In the position representation of Qi and Pi, the Hamiltonian becomes a diﬀerential operator
acting on wave functions. The time-dependent Schr¨odinger equation then becomes,
i¯h∂ψ(q, t)
∂t
= −¯h2
2m∆qψ(q.t) + V (q)ψ(q, t)
(6.33)
where ∆= ∆q is the standard Laplace operator on functions of ⃗q, deﬁned by
∆= ∆q ≡
N
X
i=1
∂2
∂qi∂qi
(6.34)
Specializing to energy eigenvalues and eigenfunctions,
ψ(q, t) = e−iEt/¯hψE(q)
(6.35)
we recover the standard time-independent Schr¨odinger equation,
−¯h2
2m∆ψE(q) + V (q)ψE(q) = EψE(q)
(6.36)
6.5
Uniqueness questions of the correspondence principle
But note that this standard realization is not unique. For example, we could just as well
have chosen the momentum realization of the canonical commutation relations, in which we
would have instead, Pi = pi and Qi = +i¯h∂/∂pi. The Hilbert space is simply the space of
square integrable functions of pi. Such alternative realizations are sometimes really useful.
Suppose we had to solve the very bizarre looking quantum system for the Hamiltonian,
H = C1
|P| + C2X2
(6.37)
In the momentum realization, the problem is actually just the Coulomb problem !!
For the simplest classical mechanical systems, the corresponding quantum system is
unique, but this need not be so in general. Suppose, for example, that the classical Hamilto-
nian contained not just a potential of q, but also an interaction of the type 2p2U(p) for some
function U. There are clearly two (and in fact an inﬁnite number) of inequivalent ways of
writing down a corresponding (self-adjoint) quantum interaction. For example,
2pU(q)p
̸=
p2U(q) + U(q)p2
(6.38)
From classical mechanics, there is no way to decide. On the quantum side, both produce
self-adjoint Hamiltonians. This ordering ambiguity almost never matters much in quantum
mechanics but it does play a crucial role in quantum ﬁeld theory.
73

7
Charged particle in an electro-magnetic ﬁeld
Of fundamental importance is the problem of an electrically charged particle in the presence
of electro-magnetic ﬁelds. To construct the Schr¨odinger equation for this system, we use
the correspondence principle. We start from the classical Lagrangian for a non-relativistic
particle with mass m, and electric charge e, in the presence of a general electro-magnetic
ﬁeld, given in terms of the electric potential Φ and the vector potential A,
L(r, ˙r, t) = 1
2m˙r2 −eΦ(r, t) + eA(r, t) · ˙r
(7.1)
We allow the electro-magnetic ﬁelds to be time-dependent as this would be required, for
example, when dealing with a charged particle in the presence of an electro-magnetic wave.
The momentum p canonically conjugate to r is given by,
p = ∂L
∂˙r = m˙r + eA(r, t)
(7.2)
The Hamiltonian is then obtained by eliminating ˙r in favor of p is the expression,
H = p · ˙r −L(r, ˙r, t)
(7.3)
This problem is algebraic; it is easily carried out explicitly, and we ﬁnd,
H(r, p, t) =
1
2m

p −eA(r, t)
2 + eΦ(r, t)
(7.4)
By the correspondence principle, we promote the classical variables r and p to operators
obeying canonical commutation relations. The time-dependent Schr¨odinger equation in the
position realization is then given by,
i¯h∂ψ(r, t)
∂t
=
1
2m

−i¯h∇r −eA(r, t)
2ψ(r, t) + eΦ(r, t)ψ(r, t)
(7.5)
In the remainder of this chapter, we proceed to exhibiting the gauge invariance of this
equation, and then studying applications to constant ﬁelds, Landau levels, the Aharonov-
Bohm eﬀect, and the quantization conditions for Dirac magnetic monopoles.
7.1
Gauge transformations and gauge invariance
Recall that the electric and magnetic ﬁelds are given in terms of Φ and A by
B = ∇× A
E = −∂A
∂t −∇Φ
(7.6)
74

Under gauge transformations,
A →A′ = A + ∇θ
Φ →Φ′ = Φ −∂θ
∂t
(7.7)
the ﬁelds B and E are invariant (i.e. B →B′ = B and E →E′ = E) for an arbitrary
function θ = θ(r, t). The classical Lagrangian transforms as follows,
L →L′ = L + e

˙r · ∇θ + ∂θ
∂t

= L′ + d(eθ)
dt
(7.8)
As a result, the classical action S =
R dt L is invariant (except for boundary eﬀects) and hence
the classical mechanics of a charged particle is invariant under such gauge transformations.
This is of course well-known, since the equations of motion reduce to
m¨r = eE(r, t) + e˙r × B(r, t)
(7.9)
which are manifestly gauge invariant.
The Schr¨odinger equation (7.5) is now invariant since the ﬁelds A and Φ are clearly
changed under the transformation, but (7.5) is instead covariant provided we also transform
the wave function by,
ψ(r, t) →ψ′(r, t) = eiγθψ(r, t)
(7.10)
for some constant γ, which remains to be determined. To see how this works, we use the
gauge transformation rules of (19.6) and (7.10) to derive the following intermediate formulas,

−i¯h∇r −eA′
ψ′
=
eiγθ
−i¯h∇r −eA

ψ + eiγθ(¯hγ + e)(∇θ)ψ

i¯h∂t −eΦ′
ψ′
=
eiγθ
i¯h∂t −eΦ(r, t)

ψ + eiγθ(¯hγ + e)(∂tθ)ψ
(7.11)
For the value
γ = −e
¯h
(7.12)
the second terms on the right hand side cancel, and we see that these particular combinations
(referred to as gauge covariant derivatives) transform exactly in the same manner that the
wave function ψ did in (19.6). As a result, the full Schr¨odinger equation transforms just as
ψ did, and this property is referred to as covariance of the equation.
75

7.2
Constant Magnetic ﬁelds
An important special case is when the electric and magnetic ﬁelds are constant in time, and
uniform in space, so that
A(r, t) = 1
2 B × r
Φ(r, t) = −E · r
(7.13)
Here, we have chosen a particular convenient gauge. The Hamiltonian is then time-independent,
and we may specialize to the eigenfunctions ψE(r) at ﬁxed energy E, which now obey the
time-independent Schr¨odinger equation,
1
2m

−i¯h∇r −1
2eB × r
2
ψE(r) −eE · rψE(r) = EψE(r)
(7.14)
This system is akin to a harmonic oscillator problem. Instead of trying to solve the Schr¨odinger
equation explicitly (in terms of Hermite polynomials etc), we shall fully exploit its relation
with the harmonic oscillator and solve for the spectrum using operator methods.
In fact, we will set E = 0, concentrating on the purely magnetic problem. Choosing the
z-axis to coincide with the direction of B, the problem may be reduced to a 2-dimensional
one, since motion along the z-direction is insensitive to the magnetic ﬁeld. To make the
problem even more interesting, we add a harmonic oscillator with frequency ω. Thus, the
eﬀective Hamiltonian of the system is now,
H =
1
2m

px + 1
2eBy
2
+ 1
2m

py −1
2eBx
2
+ 1
2mω2(x2 + y2)
(7.15)
Combining terms of the form x2 + y2, we may recast H as follows,
H =
1
2m(p2
x + p2
y) −eB
2m(xpy −ypx) + 1
2mω2
B(x2 + y2)
(7.16)
where we have deﬁned the frequency ωB by,
ω2
B = ω2 + e2B2
4m2
(7.17)
We recognize the middle term in H as the orbital angular momentum operator Lz. Clearly,
this term commutes with H and may be diagonalized simultaneously with H.
7.2.1
Map onto harmonic oscillators
To solve this system, we introduce the following harmonic oscillator combinations,
a1
=
1
√2m¯hωB
(ipx + mωBx)
a2
=
1
√2m¯hωB
(ipy + mωBy)
(7.18)
76

and their adjoints a†
1 and a†
2. By construction they obey canonical commutation relations
[ai, a†
j] = δij for i, j = 1, 2, while [a1, a2] = [a†
1, a†
2] = 0. Re-expressing the Hamiltonian in
terms of these oscillators, we ﬁnd,
H = ¯hωB

a†
1a1 + a†
2a2 + 1

+ ieB¯h
2m

a†
1a2 −a†
2a1

(7.19)
Finally, we make the following orthonormal change of variables from a1,2 to a±,
a± ≡1
√
2(a1 ± ia2)
(7.20)
and their conjugates. These oscillators still obey canonical commutation relations,
[ai, aj] = [a†
i, a†
j] = 0
[ai, a†
j] = δi,j
i, j = +, −
(7.21)
Using the following relations (the ± signs are correlated),
2a†
±a± = a†
1a1 + a†
2a2 ± i

a†
1a2 −a†
2a1

(7.22)
the Hamiltonian may be recast as follows,
H = 1
2¯hω+

1 + 2a†
+a+

+ 1
2¯hω−

1 + 2a†
−a−

(7.23)
where the combinations ω± are deﬁned by
ω± = ωB ±

eB
2m
 ≥0
(7.24)
We have now achieved our goal: the magnetic ﬁeld Hamiltonian has been expressed in terms
of two independent harmonic oscillator variables a, b.
To solve for the spectrum is straightforward. The ground state |0, 0⟩satisﬁes a±|0, 0⟩= 0,
and the excited states are given by
|n+, n−⟩= N (n+, n−) (a+)n+(a−)n−|0, 0⟩
n± ≥0
(7.25)
where N is the normalization factor. The corresponding eigenvalue is simply,
E(n+, n−) = 1
2¯hω+(1 + 2n+) + 1
2¯hω−(1 + 2n−)
(7.26)
Two diﬀerent states |n+, n−⟩and |n′
+, n′
−⟩will be degenerate provided
ω+(n′
+ −n+) + ω−(n′
−−n−) = 0
(7.27)
Since n±, n′
± are integers, this relation can have solutions if and only if ω−/ω+ is rational
(including the value 0). If this is the case, we write ω± = k±ω0 where k+ > 0 and k−≥0
are relatively prime integers. All states degenerate with |n+, n−⟩are then given by |n+ +
nk−, n−−nk+⟩for any integer n such that n−≥nk+. If ω−= 0, namely ω = 0, this
degeneracy is inﬁnite, as n can take an inﬁnite number of diﬀerent values, while if ω−> 0,
the degeneracy is necessarily ﬁnite.
77

7.3
Landau Levels
For a charged particle in a magnetic ﬁeld without the harmonic oscillator present, we have
ω = 0 and ω−= 0, and the spectrum becomes inﬁnitely degenerate, since the energies do
not depend upon n−any more. Alternatively, as ω = 0, we have
[H, a−] = [H, a†
−] = 0
(7.28)
For each value of n+, there is a Landau level with an inﬁnite degeneracy. The algebra of a−
and a†
−represent the symmetry algebra of this degeneracy. Of course, in any physical system,
space is not truly of inﬁnite extent and the magnetic ﬁeld is not quite uniform. Nonetheless,
this inﬁnite degeneracy makes the Landau levels an incredibly interesting phenomenon.
7.3.1
Complex variables
The wave functions in each Landau level exhibit remarkable properties. To exhibit these
properties, we change to complex variables. The x, y parts of the combinations a± correspond
to forming the complex variables
z = 1
√
2(x + iy)
pz = 1
√
2(px −ipy)
¯z = 1
√
2(x −iy)
p¯z = 1
√
2(px + ipy)
(7.29)
which satisfy the canonical commutation relations,
[z, pz] = [¯z, p¯z]
=
i¯h
[z, p¯z] = [¯z, pz]
=
0
(7.30)
and as a result,
pz = −i¯h ∂
∂z
p¯z = −i¯h ∂
∂¯z
(7.31)
The oscillators now become,
a+ =
1
√2m¯hωB

ip¯z + mωBz

a†
+ =
1
√2m¯hωB

−ipz + mωB¯z

a−=
1
√2m¯hωB

ipz + mωB¯z

a†
−=
1
√2m¯hωB

−ip¯z + mωBz

(7.32)
Since ω = 0, the Hamiltonian depends only on a+ and a†
+, H = ¯hωB(2a†
+a+ +1). The lowest
Landau level |0, n−⟩is characterized by a+|0, n−⟩= 0. The wave functions of the lowest
78

Landau level satisfy the diﬀerential equation
 ∂
∂¯z + mωB
¯h
z
!
ψ(0)(z, ¯z) = 0
(7.33)
Its general solution is straightforward (since as a diﬀerential equation in ¯z, you may think
of z as a constant coeﬃcient), and we get
ψ(z, ¯z) = ϕ(z)ψ(0)(z, ¯z)
ψ(0)(z, ¯z) = exp

−mωB
¯h
|z|2

(7.34)
where ϕ(z) is an arbitrary complex analytic function of z. Actually, ϕ(z) cannot has poles
since they would lead to non-square integrable wave functions. Also, assuming that ψ(z, ¯z)
is single-valued, it follows that ϕ(z) must be single-valued, and thus cannot have branch
cuts. Therefore, ϕ(z) must be single-valued and holomorphic throughout the complex plane.
A basis for such functions is obtained by polynomials (and square integrable Taylor expand-
able functions by completeness). Notice that all such polynomial functions are obtained by
applying a†
−repeatedly to the ground state ψ(0) of both a+ and a−, since we have
ψ(n−) ∼(a†
−)n−ψ(0)(z, ¯z) ∼zn−ψ(0)(z, ¯z)
(7.35)
This agrees with general principles that the group theory of a−, a†
−must precisely reproduce
the normalizable spectrum.
7.4
The Aharonov-Bohm Eﬀect
The classical equations of motion governing a charged particle in an electro-magnetic ﬁeld
involve the ﬁelds B and E, even though both the Lagrangian and the Hamiltonian must be
formulated not in terms of B and E, but rather in terms of the gauge potentials Φ and A.
The quantum equations are based on the Hamiltonian (or on the Lagrangian if one uses path
integral methods), and necessarily involves the gauge potentials Φ and A. This diﬀerence
leads to measurable eﬀects, of which the most striking are the Aharonov-Bohm eﬀects.
7.4.1
The scattering Aharonov-Bohm eﬀect
Consider a beam of particles of charge e, moving in a plane perpendicular to an inﬁnite
impenetrable straight solenoid with a non-zero magnetic ﬂux ΦB. One may realize impene-
trability by requiring the presence of a potential V (r) which is inﬁnite inside the solenoid,
and vanishes outside. Although the particles can propagate only outside the solenoid, where
B = 0, the presence of the solenoid produces measurable interference eﬀects. Outside the
79

solenoid, the gauge potential A must satisfy ∇× A = 0. Nonetheless, the gauge potential
cannot vanish outside, because we have in view of Stokes’ theorem,
I
C dl · A =
Z
d2s · B = ΦB
(7.36)
where the surface integral
R d2s is over the domain enclosed by the curve C, which includes
the inside of the solenoid (see ﬁgure 7).
Figure 7: Aharonov-Bohm scattering set-up
A simple solution for the gauge potential is given in cylindrical coordinates r, θ, z by
A(r) = nθΦB
2πr
(7.37)
where nθ is the unit vector along the direction of varying θ, and r is the distance from the
center of the solenoid. The wave function for the system is now determined by the following
Schr¨odinger equation,
1
2m

−i¯h∇−eA(r)
2ψ(r) + V (r)ψ(r) = Eψ(r)
(7.38)
To solve this equation, we notice that, outside of the solenoid, A is actually a gradient,
A(r) = ∇
 θΦB
2π
!
(7.39)
which in particular explains why B = 0 there. The transformation function is not, however,
a single-valued function, which is why A is not quite an honest gauge transformation of
80

A = 0. Nonetheless, we can use this property to solve the Schr¨odinger equation, by setting
ψ(r) = ψ0(r) exp

−iθeΦB
2π¯h

(7.40)
where ψ0(r) now satisﬁes the Schr¨odinger equation in the absence of any gauge ﬁelds,
1
2m

−i¯h∇
2ψ(r) + V (r)ψ(r) = Eψ(r)
(7.41)
Imagining now two localized wave packets, with wave functions ψ±(r) traveling parallel into
the solenoid from inﬁnity (where we shall choose θ = 0), one packet traveling on the left
and one traveling on the right of the solenoid. After passing the solenoid and proceeding
far away from the solenoid, the left wave packet is characterized by θ = π, which the right
packet is characterized by θ = −π. Thus asymptotically we have
ψ±(r) →ψ0(r) exp

∓ieΦB
2¯h

(7.42)
The total wave function ψ+ + ψ−exhibits interference, which is constructive when
eΦB = 2π¯hn
(7.43)
for any integer n, and destructive then n −1/2 is an integer. This is a measurable outcome,
which has been conﬁrmed by experiment.
7.4.2
The bound state Aharonov-Bohm eﬀect
In this set-up a spinless charged particle is constrained to move between two impenetra-
ble concentric cylinders with radii R+ > R−, impenetrability being again enforced by the
presence of a potential V (r) which vanishes for R−< |r| < R+ and is inﬁnite otherwise.
Inside the small cyclinder, we have a magnetic ﬂux ΦB, and in between the two cylinders,
the magnetic ﬁeld vanishes (see ﬁgure 8).
We shall show that, although the particle is always in a region with B = 0, nonetheless
its energy spectrum depends on ΦB. The gauge potential A is as in (7.37) and the wave
function satisﬁes (7.38). This time, we work out the Schr¨odinger equation is cyclindrical
coordinates r, θ. The gradient in these coordinates is given by
∇= nr
∂
∂r + nθ
r
∂
∂θ
(7.44)
where nr and nθ are unit vectors in the r and θ directions respectively.
The set-up is
invariant under rotations (i.e. translations in θ), so that the angular momentum operator
81

Figure 8: Aharonov-Bohm bound state set-up
Lz = −i¯h∂/∂θ commutes with the Hamiltonian, and may be diagonalized simultaneously.
Thus, we are interested in wave functions for ﬁxed angular momentum ℓ,
ψ(r) = ψℓ(r) eiℓθ
(7.45)
The covariant derivative acts as follows,
−i¯h∇ψ(r) −eA(r)ψ(r) = −i¯heiℓθ
 
nr
∂
∂r + nθ
r (iℓ+ iν)
!
ψℓ(r)
(7.46)
where we have deﬁned the combination
ν = eΦB
2π¯h
(7.47)
The radial part of the Schr¨odinger equation becomes,
r2ψ′′
ℓ+ rψ′
ℓ+

k2r2 −(ℓ+ ν)2
ψℓ= 0
(7.48)
The inﬁnite potential V outside R−< r < R+ imposes the following boundary conditions,
ψℓ(R+) = ψℓ(R−) = 0
(7.49)
The diﬀerential equation is of the Bessel kind, and can be easily solved in terms of those
functions. Before we do so, however, much can already be deduced from inspection of (7.48).
The most striking property is that the equation depends only on the combination ℓ+ ν, not
on ℓand ν separately. In particular, the eﬀect of adding a single ﬂux quantum, ν = 1, simply
has the eﬀect of moving the spectrum up by one unit of angular momentum, ℓ→ℓ+ 1, but
leaving the entire spectrum (for all angular momenta) unchanged. This conﬁrms our earlier
82

discovery for the scattering Aharonov-Bohm eﬀect, that the presence of an integer number of
basic ﬂux quanta has no measurable eﬀects. For a half ﬂux quantum ν = 1/2, the particle is
quantized as a spin 1/2 fermion ! Denoting by E0 the ground state energy for ℓ+ν = 0, then
adding angular momentum will increase the energy. In ﬁgure 9, we show a qualitative picture
of how the ground state energy depends on ν. Note that for |ν| < 1/2, the ground state has
ℓ= 0, but as ν is increased, the ground state is achieved successively for ℓ= −1, ℓ= −2, · · ·.
Figure 9: Energy of the ground state for the bound state Aharonov-Bohm eﬀect
Finally, for completeness, we obtain the full spectrum using Bessel functions. The two
linearly independent solutions of (7.48) are the Bessel functions J|ℓ+ν|(kr) and N|ℓ+ν|(kr),
with small r asymptotics given respectively by r|ℓ+ν| and r−|ℓ+ν|. The general solution to
(7.48) is then given by,
ψℓ(r) = αJ|ℓ+ν|(kr) + βN|ℓ+ν|(kr)
(7.50)
The boundary conditions impose a quantization condition on k,
J|ℓ+ν|(kR+)N|ℓ+ν|(kR−) −J|ℓ+ν|(kR−)N|ℓ+ν|(kR+) = 0
(7.51)
In the limit where the inner cylinder has small radius, R−→0, we may neglect the sec-
ond term in this equation, since J|ℓ+ν|(kR−) →0 then, and we are left with the condition
J|ℓ+ν|(kR+) = 0, so that kR+ is given by the zeros of the Bessel function J|ℓ+ν|. Analysis with
Maple, for example, readily conﬁrms numerically that the corresponding energies indeed do
depend upon ν.
7.5
The Dirac magnetic monopole
The existence of a fundamental quantum of magnetic ﬂux has an immediate application to
the theoretical existence of magnetic monopoles in quantum mechanics. One of Maxwell’s
equations, ⃗∇·B = 0, states that, classically, there exist no magnetic monopoles. The electric
counterpart of this equation is ⃗∇· E = ρ, where ρ is the electric charge density, which can
83

of course be non-zero. If we had a magnetic pointlike charge g at the origin x = 0, then its
magnetic ﬁeld would be given by
⃗∇· B = 4πgδ(3)(x)
B = g x
|x|3
(7.52)
where we usually refer to g as the magnetic charge. Of course, classical Maxwell’s equations
do not allow for g ̸= 0, and we conclude that magnetic monopoles cannot exists as solutions
to the classical Maxwell equations.
Dirac proposed that, nonetheless, magnetic monopoles can exist quantum mechanically.
To see this, imagine a magnetic ﬁeld pointing outward radially, as above, combined with
magnetic ﬂux brought in from ∞through an inﬁnitesimally thin solenoid, or Dirac string. If
the incoming ﬂux matches the outgoing radial ﬂux, then ﬂux is conserved and the magnetic
ﬁeld conﬁguration obeys ⃗∇· B = 0 everywhere.
Dirac’s remarkable observation is that if the magnetic ﬂux 4πg of the solenoid is actually
an integer multiple of the fundamental magnetic ﬂux quantum Φ(0)
B = 2π¯h/e, then the Dirac
string will be unobservable by any charged particle whose charge is an integer multiple of e.
This gives the famous Dirac quantization condition on the magnetic charge g,
4πg = nΦ(0)
B
⇔
g = n ¯h
2e
(7.53)
It is not too hard to write down the required gauge potential assuming that the Dirac string
is either along the positive z-axis (corresponding to potential A−which is regular in the
lower hemisphere) or the negative z-axis (corresponding to potential A+ which is regular in
the lower hemisphere),
A± = −g cos θ ∓1
r sin θ
nφ
(7.54)
in the usual spherical coordinates r, θ, φ, and nφ is the unit vector tangent to the direction
of φ variation. The diﬀerence between these two vector potentials is given by
A+ −A−=
2g
r sin θ nφ
(7.55)
Recalling the expression for the gradient in spherical coordinates,
⃗∇Λ = ∂Λ
∂r nr + 1
r
∂Λ
∂θ nθ +
1
r sin θ
∂Λ
∂φ nφ
(7.56)
we see that the diﬀerence is actually the gradient of the angle φ,
A+ −A−= ⃗∇Λ
Λ = 2gφ
(7.57)
84

In other words, the diﬀerence is a gauge transformation that moves the Dirac string from
one location to another. Wu and Yang gave an interpretation of this construction in terms of
ﬁber bundles. In particular, the Dirac magnetic monopole construction is closely related to
the Hopf ﬁbration of S2 by a circle S1 giving total space S3. Coincidentally, Dirac invented
the magnetic monopole in exactly the same year as Hopf did his work on ﬁber bundles. It
took about 40 years before the connection between these two problems was understood.
85

8
Theory of Angular Momentum
In a subsequent chapter, we shall study symmetry transformations in quantum systems in
a systematic manner. In this chapter, we shall concentrate on rotations, which is one of
the most important cases, both practically and conceptually, and work out the addition of
angular momentum.
8.1
Rotations
Rotations in 3-dimensional real space may be deﬁned as follows. Let X be the column matrix
of the real coordinates x1, x2, x3 of 3-dimensional space. The length squared ℓ2(X), or norm,
of X is deﬁned by,
ℓ2(X) = x2
1 + x2
2 + x2
3 = XtX
(8.1)
An orthogonal transformation is deﬁned to be a real linear map X →X′ = MX which
preserves the length of every vector X. This requires (X′)t(X′) = (MX)t(MX) = XtX, for
all X, or equivalently
MtM = I
(8.2)
The space of all M forms a group under multiplication, which is denoted by O(3).
Actually, the group O(3) consists of two disconnected components. To see this, we take
the determinant of MtM = I, which yields detM = ±1. The component with detM = 1
corresponds to rotations, which we shall henceforth denote by the letter R instead of M.
Thus, the group of rotations R in 3-dimensional space is deﬁned by,
RtR = I
detR = 1
(8.3)
and is usually referred to as SO(3). The O stands for orthogonal (expressed RtR = I), while
the S indicates the determinant condition. The element M = −I belongs to O(3), but not
to SO(3), since det(−I) = −1. Thus, M = −I is NOT a rotation. Instead, it is a space
parity transformation, usually denoted by P. As a result of the multiplicative property of
the determinant, any element M of O(3) with detM = −1 may be expressed as M = −R
where R is a rotation.
Rotations in n-dimensional real space may be deﬁned analogously. Let X be the column
matrix of the real coordinates x1, x2, · · ·, xn, and ℓ2(X) its norm, deﬁned by ℓ2(X) = XtX.
Orthogonal transformations are deﬁned as the linear maps X →X′ = MX which leave
ℓ2(X) invariant for all X, and form a group O(n) of n × n matrices M satisfying MtM = I.
Rotations R in n-dimensional space correspond to the component detR = 1, and form the
86

group SO(n). The element −I always belongs to O(n), and belongs to SO(n) for n even,
but not for n odd. Therefore, one may deﬁne a parity transformation P for all n as reﬂecting
only the last coordinate, leaving the others unchanged. Any M with detM = −1 may then
be decomposed as M = PR, where R is a proper rotation.
All rotations in SO(3) may be parametrized by 3 real parameters. A convenient way
of choosing those is to pick a direction around which to rotate by specifying a unit vector
n = (n1, n2, n3), and then further specify the angle ω by which to rotate around n. One may
write down the rotation matrix explicitly,
R(n, ω) = exp
n
ω n · T
o
(8.4)
where the matrices T1, T2, T3 are given by
T1 =



0
0
0
0
0
−1
0
1
0



T2 =



0
0
1
0
0
0
−1
0
0



T3 =



0
−1
0
1
0
0
0
0
0



(8.5)
The matrices T are real antisymmetric. The rotation R(n, ω) applied to an arbitrary vector
v is given by
R(n, ω)v
=
v cos ω + v(n · v) (1 −cos ω) + n × v sin ω
=
v + ω n × v + O(ω2)
(8.6)
Note that, because the matrices T1, T2, T3 are traceless, we automatically have detR(v, ω) = 1
for all v, ω. Thus, the operation of space parity reversal R = −I cannot be represented by
the above exponential parametrization. The reason is that the element with detR = 1 and
detR = −1 are disconnected from one another, and not continuously connected by rotations.
The matrices T1, T2, T3 satisfy the following commutation relations,
[T1, T2] = T3
[T2, T3] = T1
[T3, T1] = T2
(8.7)
It is convenient to summarize these relations by using the totally antisymmetric tensor εabc,
[Ta, Tb] =
3
X
c=1
εabcTc
ε123 = 1
(8.8)
where a, b, c = 1, 2, 3. It is more usual to work with Hermitean or self-adjoint operators, and
to include also a unit of ¯h for proper units of angular momentum,
[La, Lb] = i ¯h
3
X
c=1
εabcLc
La = i ¯h Ta
(8.9)
and the rotations are now represented by
R(n, ω) = exp

−i
¯hω n · L

(8.10)
It is in this form that we shall most often use rotations.
87

8.2
The Lie algebra of rotations – angular momentum
The rotation group SO(3) (as well as all SO(n) groups) is actually a Lie group, which means
that its group elements can be parametrized in a continuous and diﬀerentiable manner by
real parameters, such as ω and n, or also just by the entries of the matrices R.
The Norwegian mathematician Sophus Lie (1842 - 1899) proved two remarkable theorems
about Lie groups. Lie’s ﬁrst theorem states that if the group multiplication is continuous
and once diﬀerentiable, then it is real analytic (i.e. inﬁnitely diﬀerentiable and completely
given by its Taylor series expansion).
Lie’s second theorem is equally powerful. It states the equivalence (up to certain global
topological issues, which we will mention later) of Lie groups and Lie algebras.
A Lie algebra is obtained from a Lie group by Taylor series expanding the group around
its identity element. We are, of course, already familiar with doing this for rotations by a
small angle ω,
R(n, ω) = I −i
¯hω n · L + O(ω2)
(8.11)
The quantities L are the generators of the Lie algebra, and the multiplication law of SO(3)
matrices yielding again orthogonal matrices then translates into the commutation relations
(8.9), while the associativity translates into the Jacobi identity,
[La, [Lb, Lc]] + [Lb, [Lc, La]] + [Lc, [La, Lb]] = 0
(8.12)
Lie proved that, conversely, if we have a Lie algebra deﬁned by its commutation relations
(generalizing (8.9)) which satisfy the Jacobi identity, then there exists a unique globally well-
deﬁned simply connected Lie group, of which it is the Lie algebra. Practically, this means
that essentially all operations and constructions may be carried out at the level of the Lie
algebra, and we are then guaranteed that they will nicely carry over to the whole Lie group.
The advantage of the Lie algebra is that it is much much easier to handle.
8.3
General Groups and their Representations
A group G,∗consists of a set G and a multiplication law ∗satisfying the following axioms,
1. The multiplication closes: g1 ∗g2 ∈G for all g1, g2 ∈G;
2. Associativity, (g1 ∗g2) ∗g3 = g1 ∗(g2 ∗g3) = g1 ∗g2 ∗g3 for all g1, g2, g3 ∈G;
3. G contains an identity element e such that e ∗g = g ∗e = g for all g ∈G;
4. Every g ∈G has an inverse g−1 so that g ∗g−1 = g−1 ∗g = e.
88

Examples of groups include Z,+; Q,+; R,+; C,+; Q0,×; R0,×; C0,×; as well as the group
of all m × n matrices under addition, and the group of all invertible n × n matrices under
multiplication, a group denoted Gl(n). These groups are all inﬁnite groups, namely having
a inﬁnite set of elements. The quintessential example of a ﬁnite group is the group Sn of
permutations acting on any set of n distinct elements. The crystallographic groups are other
ﬁnite groups.
A representation ρ of dimension N of the group G is a map ρ from G into the group of
N × N invertible matrices, Gl(N),
1’ Group multiplication carries over to multiplication of matrices
ρ(g1 ∗g2) = ρ(g1)ρ(g2) for all g1, g2 ∈G;
2’ Associativity is automatic for matrices;
3’ The image of e is the unit matrix, ρ(e) = I;
4’ The image of the inverse is the inverse matrix, ρ(g−1) =

ρ(g)
−1.
In other words, a representation of a group G gives a representation of the elements of G
and of the group multiplication law ∗in terms of N × N matrices.
One distinguishes the following special types of representations,
• The trivial representation ρ(g) = I for all g ∈G;
• A faithful representation is such that the map ρ is injective;
• A real representation is such that ρ(g) is a real N × N matrix for all g ∈G;
• A complex representation is such that ρ(g) is complex for at least one g ∈G;
• A unitary representation is such that ρ(g)†ρ(g) = I for all g ∈G.
Representations allow us to represent the action of an abstract group concretely on a linear
vector space, such as a Hilbert space in quantum mechanics.
8.4
General Lie Algebras and their Representations
A Lie algebra G is a linear vector space, endowed with a bilinear pairing, usually denoted as
the commutator. The deﬁning properties are as follows; for all X1, X2, X3 ∈G, we have,
1. The commutator is antisymmetric, [X1, X2] = −[X2, X1], and belongs to G;
2. Bilinearity [λ1X1 + λ2X2, X3] = λ1[X1, X3] + λ2[X2, X3] for λ1, λ2 ∈C;
89

3. The Jacobi identity [X1, [X2, X3]] + [X2, [X3, X1]] + [X3, [X1, X2]] = 0 holds;
A representation D of a Lie algebra G is a map from G into N × N matrices such that
for all X1, X2 ∈G, we have,
1’ D([X1, X2]) = [D(X1), D(X2)];
2’ D(λ1X1 + λ2X2) = λ1D(X1) + λ2D(X2), and it follows that D(0) = 0;
3’ The Jacobi identity is automatically obeyed on matrices.
8.5
Direct sum and reducibility of representations
Consider two representations ρ(1) and ρ(2) of a group G, or any two representations D(1) and
D(2) of a Lie algebra G, with ρ(i), D(i) of dimension Ni. We form the direct sum representa-
tions as follows,

ρ(1) ⊕ρ(2)
(g)
=



ρ(1)(g)
0
0
ρ(2)(g)




D(1) ⊕D(2)
(X)
=



D(1)(X)
0
0
D(2)(X)



(8.13)
It is immediate to see that ρ(1) ⊕ρ(2) is a representation of G, and that D(1) ⊕D(2) is a
representation of G, both of dimension N = N1 + N2.
A representation ρ of G (similarly D of G) is reducible if ρ can be written as the direct
sum of two representations of G,
ρ = ρ(1) ⊕ρ(2)
dim ρ(1), dim ρ(2) ̸= 0
(8.14)
A representation ρ of G is irreducible if it is not reducible.
8.6
The irreducible representations of angular momentum
During our study of the quantum system of angular momentum, we have already identiﬁed all
the irreducible representations of SO(3). They are labeled by the total angular momentum
j, such that the eigenvalue of J2 is ¯h2j(j +1). We shall denote these representations by D(j).
Since they are representations, they satisfy the same algebra as the J,
h
D(j)(Ja), D(j)(Jb)
i
= i¯h
3
X
c=1
εabcD(j)(Jc)
dim D(j) = 2j + 1
(8.15)
90

By a widely used abuse of notation, one usually does not write the symbol D(j), and this
sometimes leads to some confusion as to what a representation really is.
It is a good exercise to compute the representation matrices in the lowest dimensional
representations. This is done with the help of the matrix elements,

D(j)(Ja)

m′,m = ⟨j, m′|Ja|j, m⟩
(8.16)
which in turn may be carried out by using the formulas6
J3|j, m⟩
=
m ¯h |j, m⟩
J±|j, m⟩
=
q
(j ∓m)(j ± m + 1) ¯h |j, m ± 1⟩
(8.17)
This allows us to compute

D(j)(J3)

m′,m
=
m¯hδm′,m

D(j)(J+)

m′,m
=
q
(j −m)(j + m + 1) ¯h δm′,m+1

D(j)(J−)

m′,m
=
q
(j + m)(j −m + 1) ¯h δm′,m−1
(8.18)
From these formula, it is manifest that each of these representations is irreducible.
We
obviously have D(0) = 0, the trivial representation. Next, we ﬁnd, for j = 1/2,

D( 1
2)(J3)

=
¯h
2
 1
0
0
−1


D( 1
2 )(J+)

=
¯h
 0
1
0
0


D( 1
2 )(J1)

= ¯h
2
 0
1
1
0


D( 1
2 )(J−)

=
¯h
 0
0
1
0


D( 1
2 )(J2)

= ¯h
2
 0
−i
i
0

(8.19)
which are just the Pauli matrices for spin 1/2. Next, for j = 1, we ﬁnd,

D(1)(J3)

=
¯h



1
0
0
0
0
0
0
0
−1




D(1)(J+)

=
√
2¯h



0
1
0
0
0
1
0
0
0




D(1)(J1)

= ¯h
√
2



0
1
0
1
0
1
0
1
0




D(1)(J−)

=
√
2¯h



0
0
0
1
0
0
0
1
0




D(1)(J2)

= ¯h
√
2



0
−i
0
i
0
−i
0
i
0


(8.20)
6Recall our notations of J± = J1 ± iJ2.
91

Finally, we need to make a change of basis to compare these representation matrices with
the ones found earlier, and we have
D(1)(Ja) = SLaS†
(8.21)
where the unitary change of basis is given by
S = 1
√
2



1
−i
0
0
0
−
√
2
−1
−i
0



(8.22)
8.7
Addition of two spin 1/2 angular momenta
We begin with the simplest case of two spin 1/2 angular momenta, S1 and S2. The basic
assumption is that the two spin 1/2 degrees of freedom are completely independent from one
another. We may think of the spins of two electrons, whose states are independent from one
another. The commutation relations are
[Sia, Sib]
=
i¯h
3
X
c=1
εabcSic
i = 1, 2
[S1a, S2b]
=
0
(8.23)
The Hilbert spaces of states Hi for each system admit the following basis vectors,
Hi
|i, ±⟩
i = 1, 2
(8.24)
The dimension of each Hilbert space is 2, and the total number of states for the combined
system of two spins is their product, namely 4. The Hilbert space of the total system H thus
has dimension 4. A natural basis of states for H is given by the tensor product of the basis
states for each spin 1/2 system,
H
|1, +⟩⊗|2, +⟩
|1, +⟩⊗|2, −⟩
|1, −⟩⊗|2, +⟩
|1, −⟩⊗|2, −⟩
(8.25)
The total Hilbert space H is thus the tensor product of the factors,
H = H1 ⊗H2
(8.26)
The spin operators extend to this tensor product Hilbert space as follows. The ﬁrst spin
operator S1 really only acts on the ﬁrst factor in the tensor product and it is the identity
92

in the second factor. For the second spin operator, the roles are reversed, and it acts as the
identity. One may summarize this by
S1
on
H1
→
S1 ⊗I2
on
H
S2
on
H2
→
I1 ⊗S2
on
H
(8.27)
In this way, both operators are now deﬁned on the same Hilbert space H, and may be added
to obtain total spin,
S = S1 ⊗I2 + I1 ⊗S2
or simply
S = S1 + S2
(8.28)
but the latter, although commonly used, is a bit of an abuse of notation.
It is straightforward to check that S satisﬁes the angular momentum algebra as well. By
deﬁnition, S gives a 4-dimensional representation of SO(3). The question is now whether
this representation is reducible or not, and if it is reducible what its irreducible components
are.
To shed light on this question, we ﬁrst calculate the total S3 = Sz of each basis state.
Fortunately, the states have been arranged so that they are eigenstates of S3, with eigenvalues
m, and we get
m = +1
|1, +⟩⊗|2, +⟩
m = 0
|1, +⟩⊗|2, −⟩, |1, −⟩⊗|2, +⟩
m = −1
|1, −⟩⊗|2, −⟩
(8.29)
There is a single state with m = ±1, which indicates that this 4-dimensional representation
contains the j = 1 irreducible representation of SO(3). Thus, we identify
|j = 1, m = +1⟩
=
|1, +⟩⊗|2, +⟩
|j = 1, m = −1⟩
=
|1, −⟩⊗|2, −⟩
(8.30)
The way we can get all the states of this representation is by starting with these states, and
applying S−successively. Since
Si−|i, +⟩= ¯h|i, −⟩
Si−|i, −⟩= 0
Si+|i, −⟩= ¯h|i, +⟩
Si+|i, +⟩= 0
(8.31)
we have
S−|j = 1, m = +1⟩
=
√
2¯h|j = 0, m = 0⟩
=
(S1−⊗I2 + I1 ⊗S2−)|1, +1⟩⊗|2, +⟩
=
¯h|1, −⟩⊗|2, +⟩+ ¯h|1, +⟩⊗|2, −⟩
(8.32)
93

As a result, we ﬁnd that the state |j = 1, m = 0⟩of the total system is given by
|j = 1, m = 0⟩= 1
√
2

|1, −⟩⊗|2, +⟩+ |1, +⟩⊗|2, −⟩

(8.33)
We may check the consistency of this process by applying S−once more,
S−|j = 1, m = 0⟩
=
¯h
√
2|j = 1, m = −1⟩
=
(S1−⊗I2 + I1 ⊗S2−) 1
√
2

|1, −⟩⊗|2, +⟩+ |1, +⟩⊗|2, −⟩

=
¯h
√
2|1, −⟩⊗|2, −⟩
(8.34)
and this is in agreement with our earlier identiﬁcation.
The remaining linear combination of the four states which is orthogonal to the three
j = 1 states may be normalized and is given by
1
√
2

|1, −⟩⊗|2, +⟩−|1, +⟩⊗|2, −⟩

(8.35)
This state is clearly annihilated by all three components of S, and thus corresponds to the
unique |j = 0, m = 0⟩state. Thus, we have proven by explicit calculation that
D(1/2) ⊗D(1/2) = D(1) ⊕D(0)
(8.36)
8.8
Addition of a spin 1/2 with a general angular momentum
We shall now study the addition of a spin 1/2 with a general angular momentum J1 and S2,
which commute with one another,
[J1a, S2b] = 0
a, b = 1, 2, 3
(8.37)
The system 1, we shall restrict attention to the irreducible representation of spin j1, while
for system 2, it is the irreducible representation of spin 1/2. The associated Hilbert spaces
H1 and H2 are of dimensions 2j1 + 1 and 2 respectively, and a canonical basis of states is
given by
H1
|j1, m1⟩
m1 = −j1, −j1 + 1, · · · , j1 −1, j1
H2
|2, ±⟩
(8.38)
A basis for the total Hilbert space H = H1 ⊗H2 is given by the tensor product of these basis
vectors,
H
|j1, m1⟩⊗|2, +⟩
m1 = −j1, −j1 + 1, · · ·, j1 −1, j1
|j1, m1⟩⊗|2, −⟩
(8.39)
94

Total angular momentum may be deﬁned on H just as we did when we added two spin 1/2
systems,
J = J1 ⊗I2 + I1 ⊗S2
(8.40)
The basis states of H may be organized according to eigenvalues m of J3 = Jz,
m = j1 + 1
2
|j1, j1⟩⊗|2, +⟩
m = j1 −1
2
|j1, j1⟩⊗|2, −⟩, |j1, j1 −1⟩⊗|2, +⟩
m = j1 −3
2
|j1, j1 −1⟩⊗|2, −⟩, |j1, j1 −2⟩⊗|2, +⟩
· · ·
· · ·
m = −j1 + 1
2
|j1, −j1 + 1⟩⊗|2, −⟩, |j1, −j1⟩⊗|2, +⟩
m = −j1 −1
2
|j1, −j1⟩⊗|2, −⟩
(8.41)
There is a unique highest J3 state with j = j1 + 1/2, so the tensor product contains once
the representation j = j1 + 1/2, and we identity
|j, +j⟩
=
|j1, +j1⟩⊗|2, +⟩
|j, −j⟩
=
|j1, −j1⟩⊗|2, −⟩
(8.42)
Acting with J−= J1−+S2−, we obtain all the states of this representation exactly once. For
example, at the level m = j1 −1/2, we obtain,
J−|j, +j⟩
=
¯h
q
2j1|j, j −1⟩
=

J1−⊗I2 + I1 ⊗S2−

|j1, j1⟩⊗|2, +⟩
=
¯h
q
2j1|j1, j1 −1⟩⊗|2, +⟩+ ¯h|j1, j1⟩⊗|2, −⟩
(8.43)
As a result, we obtain a formula for the state
|j, j −1⟩=
1
√2j
q
2j1|j1, j1 −1⟩⊗|2, +⟩+ |j1, j1⟩⊗|2, −⟩

(8.44)
At each value of m = −j, · · · , +j, there is exactly one state belonging to the representation
j. At m = j −1, the linear combination orthogonal to |j, j −1⟩is given by
1
√2j

|j1, j1 −1⟩⊗|2, +⟩−
q
2j1|j1, j1⟩⊗|2, −⟩

(8.45)
95

The state has m = j −1, but also is annihilated by J+, and so it is the highest m state of the
representation with total angular momentum j1 −1
2. Thus, the tensor product decomposes
as follows,
D(j1) ⊗D(1/2) = D(j1+1/2) ⊕D(j1−1/2)
j1 ≥1
2
(8.46)
8.9
Addition of two general angular momenta
We shall now carry out the addition of two general angular momenta, with irreducible
representations of spins j1 and j2, and associated Hilbert spaces H1 and H2. The tensor
product basis of the tensor product H = H1 ⊗H2 is given by
H1
|j1, m1⟩
m1 = −j1, −j1 + 1, · · ·, j1 −1, j1
H2
|j2, m2⟩
m2 = −j2, −j2 + 1, · · ·, j2 −1, j2
H
|j1, m1⟩⊗|j2, m2⟩
”
(8.47)
Total angular momentum J is deﬁned by
J = J1 ⊗I2 + I1 ⊗J2
(8.48)
At total J3 = Jz eigenvalue m, we have
m = j1 + j2
|j1, j1⟩⊗|j2, j2⟩
m = j1 + j2 −1
|j1, j1⟩⊗|j2, j2 −1⟩, |j1, j1 −1⟩⊗|j2, j2⟩
m = j1 + j2 −2
|j1, j1⟩⊗|j2, j2 −2⟩, |j1, j1 −1⟩⊗|j2, j2 −1⟩, |j1, j1 −2⟩⊗|j2, j2⟩
· · ·
· · ·
m = −j1 −j2
|j1, −j1⟩⊗|j2, −j2⟩
(8.49)
The unique state with the highest value of m = j1 + j2 belongs to the irreducible represen-
tation D(j) with j = j1 + j2. Thus, we may identify
|j, +j⟩
=
|j1, j1⟩⊗|j2, j2⟩
|j, −j⟩
=
|j1, −j1⟩⊗|j2, −j2⟩
(8.50)
By applying the lowering operator J−= J1−⊗I2 + I1 ⊗J2−to this state, we ﬁnd
J−|j, +j⟩
=
¯h
q
2j|j, j −1⟩
=

J1−⊗I2 + I1 ⊗J2−

|j1, j1⟩⊗|j2, j2⟩
=
¯h
q
2j1|j1, j1 −1⟩⊗|j2, j2⟩+ ¯h
q
2j2|j1, j1⟩⊗|j2, j2 −1⟩
(8.51)
96

As a result, we have
|j, j −1⟩=
1
√2j
q
2j1|j1, j1 −1⟩⊗|j2, j2⟩+
q
2j2|j1, j1⟩⊗|j2, j2 −1⟩

(8.52)
The remaining linear combination at level m = j −1 is given by
|j −1, j −1⟩=
1
√2j
q
2j2|j1, j1 −1⟩⊗|j2, j2⟩−
q
2j1|j1, j1⟩⊗|j2, j2 −1⟩

(8.53)
and is the highest m value for the irreducible representation j −1. One may pursue this
process recursively, and ﬁnd that
D(j1) ⊗D(j2) =
j1+j2
M
j=k
D(j)
(8.54)
It remains to determine the number k.
One could do this directly.
A convenient trick,
however, is to determine k by making sure that the dimensions work out correctly.
(2j1 + 1)(2j2 + 1) =
j1+j2
X
j=k
(2j + 1)
(8.55)
Using
N
X
ℓ=0
(2j + 1) = (N + 1)2
(8.56)
we readily ﬁnd that
(2j1 + 1)(2j2 + 1) = (j1 + j2 + 1)2 −k2
⇒
k2 = (j1 −j2)2
(8.57)
so that k = |j1 −j2|. We recover easily the previous case where j2 = 1
2.
8.10
Systematics of Clebsch-Gordan coeﬃcients
The above construction makes it clear that there are two ways of describing the states
of a system in which two angular momenta are added. The ﬁrst is as the eigenstates of
J2
1, J3
1, J2
2, J3
2, and we label these eigenstates as
|j1, m1⟩⊗|j2, m2⟩= |j1, j2; m1, m2⟩
(8.58)
But, alternatively, the same states may be label by the eigenvalues of an equivalent set of
commuting observables, J2
1, J2
2, J2, J3, and we label these states as
|j1, j2; j, m⟩
(8.59)
97

Each group of states forms an orthogonal basis for the same Hilbert space. It is convenient
to normalize the states as follows,
⟨j1, j2; m′
1, m′
2|j1, j2; m1, m2⟩
=
δm′
1,m1δm′
2,m2
⟨j1, j2; j′, m′|j1, j2; j, m⟩
=
δj′,jδm′,m
(8.60)
We have already show that
|j1, j2; j, +j⟩= |j1, j2; +j1, +j2⟩
j = j1 + j2
|j1, j2; j, −j⟩= |j1, j2; −j1, −j2⟩
(8.61)
More generally, the above orthonormality conditions imply that the passage from one basis
to the other is by a unitary matrix,
|j1, j2; j, m⟩=
X
m1
X
m2
|j1, j2; m1, m2⟩⟨|j1, j2; m1, m2|j1, j2; j, m⟩
(8.62)
By choosing the phases of the states in both bases, all coeﬃcients may in fact be chosen to
be real.
By applying the angular momentum generators Ja = Ja1 + J2a to both sides, we obtain
recursion relations between the matrix elements. Applying J3, we get
m|j1, j2; j, m⟩=
X
m1
X
m2
(m1 + m2)|j1, j2; m1, m2⟩⟨|j1, j2; m1, m2|j1, j2; j, m⟩
(8.63)
Taking the inner product with ⟨j1, j2; m′
1, m′
2|, we obtain,
(m −m1 −m2)⟨|j1, j2; m1, m2|j1, j2; j, m⟩= 0
(8.64)
Applying J± = J1± + J2±, we get
N±
j,m|j1, j2; j, m ± 1⟩
=
X
m1
X
m2
N±
j1,m1|j1, j2; m1 ± 1, m2⟩⟨|j1, j2; m1, m2|j1, j2; j, m⟩
+
X
m1
X
m2
N±
j2,m2|j1, j2; m1, m2 ± 1⟩⟨|j1, j2; m1, m2|j1, j2; j, m⟩
where
N±
j,m =
q
j(j + 1) −m(m ± 1) =
q
(j ∓m)(j ± m + 1)
(8.65)
Taking the inner product with ⟨j1, j2; m′
1, m′
2|, we obtain,
N±
j,m⟨j1, j2; m1, m2|j1, j2; j, m ± 1⟩
=
N±
j1,m1∓1⟨j1, j2; m1 ∓1, m2|j1, j2; j, m⟩
+N±
j2,m2∓1⟨j1, j2; m1, m2 ∓1|j1, j2; j, m⟩
(8.66)
98

Here, we have dropped the ′ on m1 and m2. The initial condition on this recursion relation
is the highest weight matrix element
⟨j1, j2; j, j|j1, j2; j1, j2⟩= 1
j = j1 + j2
(8.67)
A detailed discussion on how the above recursion relation ﬁxes all the Clebsch Gordan
coeﬃcients may be found in Sakurai.
8.11
Spin Models
A spin model is a statistical mechanical lattice model for which each lattice site has a two-
dimensional Hilbert space of states. (More generally, one could consider spin models with
higher angular momentum representations, and thus with higher dimensional Hilbert spaces
at each lattice point.) A natural way of realizing this two-dimensional Hilbert space is by a
spin 1/2 degree of freedom at each lattice site. The lattice Λ is usually a square lattice in
d dimensions, and the interactions are usually limited to nearest neighbor interactions only.
Spin often being responsible for the presence of a magnetic moment, one often also includes
a uniform magnetic ﬁeld B which acts as an external source. Schematically, the general
Hamiltonian is of the form,
H = −J
X
⟨i,j⟩,i,j∈Λ
SiSj −B
X
i∈Λ
Si
(8.68)
Here the notation ⟨i, j⟩stands for the inclusions of nearest neighbor pairs only, and i and j
run over all points of a lattice L. One such Hamiltonian is given by the Heisenberg model,
for which all three components of spin are retained,
H = −J
X
⟨i,j⟩
Si · Sj −B
X
i
Siz
(8.69)
where the B ﬁeld has been taken to be in the z direction.
8.12
The Ising Model
Henceforth, we shall concentrate on the simplest Hamiltonian, namely that of the Ising
model. Here, the spins Si are taken to be the z-component Sz
i of the spin operator S. The
Ising model Hamiltonian is given by
H = −J
X
⟨i,j⟩
SizSjz −B
X
i
Siz
(8.70)
99

Since all operators in the Hamiltonian mutually commute, the quantum system actually
behaves classically. Note that, for B = 0, the Hamiltonian is invariant under the unitary
operation R of simultaneous reversal of all spins
RSizR† = −Siz
(8.71)
A basis for all the quantum states is given by the tensor product of the states |i, σi⟩where
i runs through the lattice Λ and for each i, the variable σi = ±1, namely the eigenvalues of
Sz
i . The eigenvalue of the Hamiltonian on such a state is
H|σi, i ∈Λ⟩= E{σi}|σi, i ∈Λ⟩
|σi, i ∈Λ⟩=
O
i∈Λ
|i, σi⟩
(8.72)
and the energy eigenvalue is
E{σi} = −J
X
⟨i,j⟩
σiσj −B
X
i
σi
(8.73)
Under the operation of spin reversal R, the eigenvalues behave as R(σi) = −σi.
There are two important cases to distinguish between depending on the sign of J. If
J > 0 and B = 0, the ground (or minimum energy) state of the system is attained when all
spins are lined up in the same direction, either all up σi = +1 or all down σi = −1. This
interaction is referred to as ferromagnetic. If J < 0 and B = 0, the conﬁguration with all
spins aligned is actually maximum energy, so the minimum energy conﬁguration will have
alternation between spins up and down. This interaction is referred to as anti-ferromagnetic.
8.13
Solution of the 1-dimensional Ising Model
The simplest Ising model is in one dimension, in which case the Hamiltonian may be written
down even more explicitly,
H = −J
N
X
i=1
SizSi+1 z −B
N
X
i=1
Siz
(8.74)
and we use the periodicity convention SN+1 z = S1z. To compute Z, we write it as a sequential
product,
Z
=
tr

E1E2 · · · EN−1EN

Ei
=
exp

βJSizSi+1 z + 1
2βB (Siz + Si+1 z)

(8.75)
We deﬁne the identity operator
Ii =
X
σi=±1
|i, σi⟩⟨i, σi|
(8.76)
100

and insert the product I1 ⊗I2 ⊗· · · ⊗IN in between Ei−1 and Ei for all i. The problem now
becomes one of 2 × 2 matrix multiplication. To see this, we work out the matrix elements of
Ei that enter here,
Tσ′,σ = ⟨σ′|Ei|σ⟩= exp

βJσ′σ + 1
2βB(σ + σ′)

(8.77)
The partition function is then given by
Z =
X
{σi=±1}
Tσ1,σ2Tσ2,σ3 · · ·TσN ,σ1 = trTN
(8.78)
Written out explicitly, the matrix T is given by
T =
 eβJ+βB
e−βJ
e−βJ
eβJ−βB

(8.79)
Its eigenvalues λ± satisfy the equation,
λ2
± −2λ± eβJ ch(βB) + 2 sh(2βJ) = 0
(8.80)
which is solved by
λ± = eβJch(βB) ±
q
e2βJsh2(βB) + e−2βJ
(8.81)
Therefore, the partition function is given by
Z = λN
+ + λN
−
(8.82)
for all values of N, β, J, and B.
In statistical mechanics and thermodynamics, we are mostly interested in taking the
thermodynamics limit of the system, which here corresponds to taking N →∞. The number
of sites N plays the role of volume, and it is then more appropriate to consider the large
volume limit of intensive quantities, such as the free energy per unit volume etc. Thus, we
shall be interested in the limit,
f = lim
N→∞
F
N = −1
β lim
N→∞
1
N ln

λN
+ + λN
−

(8.83)
The value of the limit will depend on which of the eigenvalues λ± is the larger one. Clearly,
we have
λ+ > λ−
when
J > 0
λ+ < λ−
when
J < 0
(8.84)
101

and thus,
f = −1
β ln λ+
when
J > 0
f = −1
β ln |λ−|
when
J < 0
(8.85)
In both cases, these functions are analytic functions of β, so there are no phase transitions
for any ﬁnite value of β. In other words, the system is in the same thermodynamic phase
for all temperatures.
8.14
Ordered versus disordered phases
An important qualitative characteristic of the dynamics of statistical magnetic systems is
order versus disorder. For magnetic systems, this property may be understood systematically
in terms of the magnetization, deﬁned as the thermodynamic average of the spin,
Sz = lim
N→∞
1
N
X
i
Sz
i
(8.86)
The magnetization M(B) per unit volume is then deﬁned by
M(B)
=
Tr

Sze−βH
Tr (e−βH)
= −lim
N→∞
1
N
∂ln Z
∂(βB)
(8.87)
In the case of the 1-dimensional Ising model, and for B = 0, this quantity is easily computed
for both J > 0 or J < 0. The eigenvalues λ± both depend on βB through an even function
of βB, and thus, the magnetization M(B) at zero external magnetic ﬁeld always vanishes.
This result is interpreted as the fact that the spins in the system, on average, point in all
directions randomly, so that their total contribution to magnetization vanishes in the bulk.
When can a system be ordered then ? We have seen previously that for J > 0, the
minimum energy states are
|+⟩
σi = +1
i ∈Λ
|−⟩
σi = −1
i ∈Λ
(8.88)
Note that, these states are mapped into one another R|±⟩= |∓⟩by the spin reversal
symmetry R of the Hamiltonian for B = 0. At high temperatures, the spins are allowed
to ﬂuctuate away wildly from these minimum energy states, but one would expect that, as
temperature is lowered, that ﬂuctuations away from these ground states are suppressed.
102

If both ground states contribute to the partition function, then the total magnetization
will get wiped out, and the system will remain in a disordered phase. When the volume, or
N, is ﬁnite, this will always be the case. But when N →∞, it is possible for the system
to get stuck in one ground state or the other. The reason this only happens for inﬁnite
N is that it would then take an inﬁnite number of spin ﬂips to transition between the |+⟩
and |−⟩states, and this may get energetically impossible. When the system gets stuck in
one of its ground states, M(0) ̸= 0 and we have spontaneous magnetization, familiar from
ferromagnetism below the Curie temperature. The operation of spin reversal, which is a
symmetry of the Hamiltonian for B = 0 is then NOT a symmetry of the physical system
any more, as a deﬁnite non-zero value of M(0) is not invariant under R. The symmetry R
is said to be spontaneously broken, and the system is then in an ordered phase, close to one
of its ground states. We have already shown that, for the 1-dimensional Ising model, this
phenomenon does not take place.
The 2-dimensional Ising model, however, does exhibit an ordered phase below a critical
temperature Tc. This is known since the model was solved exactly by Lars Onsager in 1944,
and the critical temperature is known analytically,
sh(2Jβc) = 1
1
βc
= kBTc = 2J × 1.134542
(8.89)
The corresponding magnetization was computed by C.N. Yang,
M(0)
=
 
1 −
1
sh4(2Jβ)
!1/8
T < Tc
M(0)
=
0
T > Tc
(8.90)
Note that as T ր Tc, the expression M(0) vanishes and joins continuously with the T > Tc
result. The phase transition at T = Tc is actually second order.
Whether the 3-dimensional Ising model allows for an exact solution is one of the great
outstanding problems of statistical mechanics. Proposals have been made that the model
behaves as a theory of free fermionic random surfaces, but the details have never been
conclusive. Numerical studies of the model have shown however that it also admits a phase
transition between ordered (low temperature) and disordered (high temperature) phases.
103

9
Symmetries in Quantum Physics
Symmetry, as wide or as narrow as you may deﬁne its meaning,
is one idea by which man through the ages has tried to
comprehend and create order, beauty and perfection.
– Hermann Weyl –
Symmetries can manifest themselves in diﬀerent ways.
• A symmetries of an object is the oldest of the two concepts. The circle, the regular
hexagon, square, or triangle, for example, represent some of the deepest symbols of civiliza-
tion, mainly because of their high degree of symmetry. The most elementary deﬁnition of
symmetry then is that an object is symmetric if it will appear the same if viewed from a
transformed perspective. For all the above planar ﬁgures, their shapes will appear unchanged
after certain planar rotations about their centers.
• A symmetry of the laws of Nature is a more recent concept, which can be traced back to
the Renaissance. Galileo realized that the laws governing classical mechanics do not change
if we transform our observational frame in time or in space – in a uniform manner. This
property is referred to as Galilean relativity; it includes the symmetries of time translation
as well as space translation and rotations.
Einstein considerably extended the range of
applicability of the relativity principle to special and then general relativity. In the latter,
the laws of physics are unchanged under any transformation of our observational frame.
9.1
Symmetries in classical mechanics
Recall that in classical mechanics we encountered two types of symmetries, following the
model of the above discussion.
• Symmetries of the solutions of the Euler Lagrange equations
(such as, for example, symmetries of shapes of orbits);
• Symmetries of the Euler Lagrange equations themselves
(i.e. symmetries of the laws of Nature).
From the modern perspective on physics, the symmetries of the laws of Nature are considered
to be primordial. For example, translation and rotation invariance are ingrained in the basic
laws of Nature, and are associated with the conservation of energy, momentum and angular
momentum. The symmetries of the solutions, such as the symmetries of orbits, are viewed
to be less fundamental. In fact, while the orbits of most planets are roughly circular, closer
inspection reveals that they are really closer to elliptical, with further deviations from the
elliptical form. Thus the symmetries of the solutions are for the most only approximate and
104

not primordial. This lack of exact symmetry of orbits is what ultimately caused the downfall
of the Ptolemy model of the planets.
By deﬁnition, a symmetry of an equation is a transformation on the dynamical variables
that maps any solution to the equation to a solution of the same equation.
Symmetry
transformations may be
• discrete
(such as parity, time reversal, translation and rotation in a crystal);
• continuous, i.e. parametrized by continuous parameters
(such as translation and rotation invariance in the continuum).
It is well-known that time and space translation invariance imply conservation of energy
and momentum respectively and that rotation invariance implies conservation of angular
momentum. This connection between a continuous symmetry and an associated conserved
quantity or conserved charge is a general one thanks to a theorem by Emmy Noether.
We consider a mechanical system described by a Lagrangian L(q, ˙q; t) for positions qi(t)
with i = 1, · · · , N. Now consider a continuous symmetry acting on qi(t). A continuous
symmetry (such as a translation or a rotation) will depend upon a continuous parameter α,
which we shall assume to be real. Thus, the new positions ˜qi are given as a function of this
parameter, in such a way that
˜qi(t, α)
=
diﬀerentiable function of α
˜qi(t, 0)
=
qi(t)
(9.1)
For any given α, the transformation qi(t) →˜qi(t, α) is a symmetry provided every solution
qi(t) of the Euler-Lagrange equations is mapped into a solution ˜qi(t, α) of the same Euler-
Lagrange equations. In particular, this means that if qi(t) is a stationary trajectory of the
action S[q], then so is ˜qi(t, α). (Notice that the values of the end points qi(t1,2) will in general
be transformed into diﬀerent values qi(t1,2, α).) Since the symmetry is continuous, we may
restrict to an inﬁnitesimal version of the transformation, deﬁned by
δqi(t) = δqi(q, ˙q; t) = lim
α→0
˜qi(t, α) −˜qi(t, 0)
α
= ∂˜qi(t, α)
∂α
α=0
(9.2)
The inﬁnitesimal transformation δqi is a symmetry provided
δL =
X
i
 ∂L
∂qi
δqi + ∂L
∂˙qi
δ ˙qi
!
= d
dtX(q, ˙q; t)
(9.3)
Here, the variation must be carried out without using the Euler-Lagrange equations, and
the quantity X(q, ˙q; t) must be a function of qi(t) and ˙qi(t) which is local in time.
105

9.2
Noether’s Theorem
(1) If δqi(t) is a symmetry transformation, there exists a conserved charge C, given by
C =
X
i
piδqi −X
pi = ∂L
∂˙qi
(9.4)
The charge C is conserved, namely we have ˙C = dC/dt = 0, for any path qi(t) which obeys
the Euler-Lagrange equations. The result is proven by straightforward calculation, and the
use of the Euler-Lagrange equations.
(2) The conserved charge generates the inﬁnitesimal transformation as follows,
δqi = {qi, C}
(9.5)
This result is proven by starting from the δL =
˙X (which holds without the use of the
Euler-Lagrange equations), using it to compute ∂X/∂pi and ∂X/∂qi, and then using those
derivatives to evaluate {qi, C}. Note that conservation means ˙C = 0,
˙C = dC
dt = ∂C
∂t + {C, H} = 0
(9.6)
even though C may have explicit time dependence.
A ﬁrst simple example is provided by translations of the dynamical variables qi. The
ﬁnite transformation is ˜qi(t, α) = qi(t) + αvi where vi are constants. As a result, δqi(t) = vi,
and δ ˙qi = 0. Variation of the Lagrangian gives,
δL =
X
i
∂L
∂qi
vi
(9.7)
which expresses the derivative of L with respect to the combination
P
i qi(t)vi. For this to be
a symmetry, we need δL to be a total time derivative of a local quantity X, without using
the Euler-Lagrange equations. But this can happen only if δL = X = 0. in turn expressing
the fact that the Lagrangian does not actually depend on the combination P
i qi(t)vi. As a
result, the associated conserved charge is given by
Cv =
X
i
piδqi =
X
i
pivi
(9.8)
expressing the fact that the associated momentum in that direction is conserved.
A second example is provided by time translations, whose ﬁnite transformation is ˜qi(t, α) =
qi(t + α). The associated inﬁnitesimal transformation is δqi(t) = ˙qi(t), and we also have
δ ˙qi(t) = ¨qi(t). Now compute the variation of the Lagrangian,
δL =
X
i
 ∂L
∂qi
˙qi + ∂L
∂˙qi
¨qi
!
= dL
dt −∂L
∂t
(9.9)
106

The rhs is a total time derivative only if ∂L/∂t = 0, namely the Lagrangian has no explicit
time dependence. Assuming this to be the case, we see that X = L, the associated conserved
charge is readily computed, and found to be the Hamiltonian,
H =
X
i
pi ˙qi −L
(9.10)
which is what we expect: energy conservation results from time translation invariance.
9.3
Group and Lie algebra structure of classical symmetries
Transformations that permute the elements of a set form a group, which is generally a
subgroup of the full permutation group of the set in question. Generally, symmetry transfor-
mations act as permutations on the space of all solutions of an equation, and therefore also
form a group. It is actually in this context that groups were ﬁrst discovered by Galois in
his study of the behavior of solutions to polynomial equations under permutations of these
solutions.
Continuous symmetries depend diﬀerentiably on parameters and generally form Lie groups,
while their inﬁnitesimal versions form Lie algebras. This may be seen as follows. Suppose a
given Lagrangian system has two inﬁnitesimal transformations δ1qk(t) and δ2qk(t), both of
which generate inﬁnitesimal symmetries with associated conserved charges C1 and C2, both
of which are conserved. The sum of the two inﬁnitesimal transformations δ1qk(t) + δ2qk(t)
is then also a symmetry with associated conserved charge C1 + C2. But furthermore, as is
characteristic of a Lie algebra, there is an antisymmetric commutator of transformations
δ1

δ2qk(t)

−δ2

δ1qk(t)

(9.11)
which also produces a symmetry, with associated conserved charge {C1, C2}. To see this, we
work out the composition rule in terms of Poisson brackets, using the fact that δaqk(t) =
{qk(t), Ca}, and we ﬁnd,
δ1

δ2qk(t)

−δ2

δ1qk(t)

=
n
C1, {C2, qk(t)}
o
−
n
C2, {C1, qk(t)}
o
=
n
{C1, C2}, qk(t)
o
(9.12)
The last line was obtained from the ﬁrst by the use of the Jacobi identity which always holds
for the Poisson bracket.
As a ﬁnal remark, the charges C, discussed above always generate transformations of
the system, even if these transformations are not necessarily symmetries. For example, in a
mechanical system with degrees of freedom qk and pℓfor k, ℓ= 1, 2, 3 and canonical Poisson
brackets {qk, pℓ} = δkℓ, the (orbital) angular momentum generator, deﬁned by
La =
X
k,ℓ
εakℓqkpℓ
(9.13)
107

will always generate rotations
δaqℓ= {qℓ, La} =
X
m
εaℓmqm
(9.14)
whether or not rotations are actually a symmetry of a certain Lagrangian or not.
9.4
Symmetries in Quantum Physics
In quantum mechanics, the (only) quantities that can be measured are the eigenvalues of
observables, and the probabilities for one state to overlap with another state. A transfor-
mation in quantum mechanics is a linear (or anti-linear for time reversal) map from the
Hilbert space H into itself. A quantum mechanical symmetry must preserve the outcome
of all observations, and hence must leave all probabilities unchanged. In the case of linear
transformations, we must have the following transformation law on states,
|ϕ⟩→|ϕ′⟩= g|ϕ⟩
⟨ψ′|ϕ′⟩= ⟨ψ|g†g|ϕ⟩= ⟨ψ|ϕ⟩
|ψ⟩→|ψ′⟩= g|ψ⟩
g†g = I
(9.15)
Thus, to be a symmetry, a linear transformation must be unitary. On observables, the action
of g is by conjugation,
A →A′ = g†Ag
(9.16)
Since g is unitary, the set of all eigenvalues (i.e. the spectrum) of A′ exactly coincides with
the set of all eigenvalues of A.
From the above point of view, all unitary transformations are candidates to be sym-
metries, as they represent a general change of orthonormal basis in Hilbert space. Certain
authors (see Weinberg, volume I) indeed leave the deﬁnition of a symmetry this general.
Once the dynamics of the system is further determined by a Hamiltonian, however, it be-
comes more natural to have a more dynamics-related deﬁnition of symmetry. Dynamics may
be formulated either in the Schr¨odinger or in the Heisenberg pictures, and a symmetry then
operates as follows. In either case, we shall assume that we perform a unitary transformation
g which has no explicit time dependence.
In the Schr¨odinger picture, any state |ϕ(t)⟩satisfying the Schr¨odinger equation with the
Hamiltonian H, is transformed to a state g|ϕ(t)⟩which must satisfy the Schr¨odinger equation
for the same Hamiltonian. As a result, we must have for all states |ϕ(t)⟩,
i¯h ∂
∂t|ϕ(t)⟩
=
H|ϕ(t)⟩
i¯h ∂
∂t

g|ϕ(t)⟩

=
H

g|ϕ(t)⟩

(9.17)
108

Since, by assumption, g has no time dependence, this requires [g, H]|ϕ(t)⟩= 0 for all states
|ϕ(t)⟩, which can only happen is
[g, H] = 0
⇒
dg
dt = 0
(9.18)
in other words, g must be conserved in time.
The derivation in the Heisenberg picture is analogous. Any observable A(t) satisfying
the Heisenberg equation is transformed into an observable g†A(t)g which must also satisfy
the Heisenberg equation, so that
i¯h ∂
∂tA(t)
=
[A(t), H]
i¯h ∂
∂t

g†A(t)g

=
[gA(t)g†, H]
(9.19)
Since g has no explicit time dependence, this requires
h
A, g[g†, H]
i
= 0
(9.20)
which in turn again requires that [g, H] = 0. It is possible to extend this result to the case
where g does have explicit time dependence as well; the correct equation is then that ˙g = 0.
Continuous symmetries allow us to consider inﬁnitesimal symmetry transformations.
Since g is unitary and parametrized by a continuous parameter, we may expand the trans-
formation around the identity,
g = I −iεG + O(ε2)
(9.21)
where G must be a self-adjoint operator, and thus an observable. The transformation rule
on observables is deduced directly from the ﬁnite transformation law A →A′ = g†Ag, and
is given by
g†Ag −A = iε[G, A] + O(ε2)
(9.22)
One deﬁnes the inﬁnitesimal transformation by
δA = i[G, A]
(9.23)
The composition of two inﬁnitesimal symmetry transformations δ1 and δ2 is given by their
associated conserved charges G1 and G2 by,
(δ1δ2 −δ2δ1)A
=
−[G1, [G2, A]] + [G2, [G1, A]]
=
−i[G, A]
(9.24)
109

where the composition is given by
G = −i[G1, G2]
(9.25)
using the Jacobi identity. Thus the inﬁnitesimal symmetry transformations naturally form
a Lie algebra.
9.5
Examples of quantum symmetries
Many of the most important examples have already been encountered in the special cases that
we have studied. Here, we shall limit the enumeration to continuous symmetries. Important
discrete symmetries will be studied later on.
• space translation invariance; charge = momentum;
• time translation invariance; charge = energy;
• space rotation symmetry; charge = angular momentum;
• boosts in (non) relativistic mechanics; charge = Lorentz generators;
• U(1) phase rotations associated with gauge invariance; charge = electric charge;
• SU(3) rotations of the strong interactions; charge = color;
• SU(3) approximate symmetry between u, d, s quarks; charge = isospin and strangeness.
The existence of symmetries has important consequences;
* The states at a given energy level transform under a unitary representation of the sym-
metry group or of the symmetry Lie algebra;
* Selection rules imply relations between certain probability amplitudes and imply the van-
ishing of other probability amplitudes and expectation values.
In the subsequent subsections, we shall discuss examples of these phenomena.
9.6
Symmetries of the multi-dimensional harmonic oscillator
The N-dimensional harmonic oscillator provides an excellent laboratory for learning about
symmetries and their realizations. The dynamical variables are qi(t) and pi(t), and canonical
commutation relations [qi, pj] = i¯hδij, with i, j = 1, · · ·, N. The Hamiltonian is
H =
N
X
i=1
 1
2mp2
i + 1
2mω2q2
i

(9.26)
110

It is chosen to have maximal symmetry.7
9.6.1
The orthogonal group SO(N)
In the case of N = 3, we simply have the isotropic 3-dimensional harmonic oscillator,
N = 3
H =
1
2mp2 + 1
2mω2x2
(9.27)
It is of course well-known that this Hamiltonian is invariant under simultaneous rotations of
x and p, given by δx = ⃗ω × x and δp = ⃗ω × p. The associated conserved charges are the
three components of angular momentum L = x × p.
For general dimension N, the harmonic oscillator is invariant under orthogonal transfor-
mations in N-dimensional space. A convenient way to see this is by organizing the degrees
of freedom in column matrices,
Q =





q1
q2
·
qN





P =





p1
p2
·
pN





(9.28)
The Hamiltonian then takes the form,
H =
1
2mP tP + 1
2mω2QtQ
(9.29)
Orthogonal transformations in N-dim space are deﬁned as linear transformations which leave
the N-dimensional Euclidean norm QtQ invariant. On Q, we have,
Q →Q′ = MQ
such that
(Q′)tQ′ = QtQ
(9.30)
for a real N × N matrix M, and for all Q. This requires that MtM = I. The set of all real
matrices satisfying MtM = I forms a group under matrix multiplication, referred to as the
orthogonal group O(N). Indeed, if we have Mt
1M1 = Mt
2M2 = I then (M1M2)t(M1M2) =
Mt
2Mt
1M1M2 = I. The identity element is the unit matrix I and the inverse is the transpose
M−1 = Mt. Clearly, if we let Q →MQ and P →MP, then both the Hamiltonian and
the canonical commutation relations are invariant, and thus all orthogonal transformations,
which belong to O(N) are symmetries of the harmonic oscillator quantum system.
Rotations in N dimensional space are all orthogonal transformations, but all orthogonal
transformations are not rotations. A rotation is continuously connected to the identity or-
thogonal transformation, since one may think of a rotation as obtained by making a sequence
7A more general form of the N-dimensional harmonic oscillator would be obtained by replacing the
potential term by 1
2m PN
i,j=1 ω2
ijqiqj for some positive real matrix ω2.
111

of small incremental rotations starting from the identity. But the relation MtM = I implies
that detM = ±1. These two cases are not continuously connected to one another, and only
the set detM = +1 contains the identity matrix M = I. Hence, the matrices for which
detM = −1 are not rotations. One example of such a matrix is
(M0)ij = δij −2δiNδjN
(9.31)
Its eﬀect on Q is to reverse the sign of qN, leaving all other qi unchanged. This transformation
is a space parity transformation in the direction N, and is clearly not a rotation. Any matrix
M with detM = −1 may be written as M = M0M′ where now detM′ = 1. Thus, any
orthogonal transformation is either a rotation in N dimensions or the product of a rotation
by a parity transformation. The group of rotations consists of matrices M such that we have
both MtM = I and detM = +1, and is denoted by SO(N), the preﬁx S standing for the
condition of unit determinant.
It is also very useful to examine the inﬁnitesimal rotations in N-dim space. To do so, we
expand M around the identity I to linear order,
M = I + ̟ + O(̟2)
(9.32)
and insist on the relation MtM = I to this order. This requires that the matrix B be anti-
symmetric, i.e. ̟t = −̟. A real anti-symmetric N ×N matrix has N(N −1)/2 independent
entries, and this yields the dimension of the orthogonal groups,
dim SO(N) = dim O(N) = 1
2N(N −1)
(9.33)
Finally, inﬁnitesimal rotations are generated by the angular momentum operators,
Lij = qipj −qjpi
i, j = 1, · · ·, N
(9.34)
Since we have
[Lij, qk]
=
i¯h(δikqj −δjkqi)
(9.35)
the rotations are generated by the unitary operator
U = exp


−i
2¯h
N
X
i,j=1
̟ijLij



(9.36)
It is then easy to verify that
UqiU† = qi +
N
X
j=1
̟ijqj + O(̟2)
(9.37)
112

so that U indeed correctly generates a rotation by ̟. The rotation generators Lij have the
following commutation relations,
[Lij, Lkl] = i¯h(δikLjl −δjkLil −δilLjk + δjlLik)
(9.38)
Antisymmetry of ̟ij and Lij under i ↔j guarantees that the number of independent
rotations is N(N −1)/2.
9.6.2
The unitary groups U(N) and SU(N)
The N-dimensional harmonic oscillator actually has a symmetry larger than SO(N). This
is not so easy to see directly in qi, pi coordinates, but becomes apparent when we recast the
problem in terms of raising and lowering operators, deﬁned by
ai
=
1
√
2m¯hω

+ ipi + mωqi

a†
i
=
1
√
2m¯hω

−ipi + mωqi

(9.39)
for i = 1, · · ·, N. The Hamiltonian is then
H =
N
X
i=1
¯hω

a†
iai + 1
2

= 1
2¯hωN + ¯hω
N
X
i=1
a†
iai
(9.40)
while the canonical commutation relations are [ai, a†
j] = δij. Again, it is convenient to arrange
the ai and a†
i into matrices,
A =





a1
a2
·
aN





A† = ( a†
1
a†
2
·
a†
N )
(9.41)
The Hamiltonian then takes the form
H = 1
2¯hωN + ¯hωA†A
(9.42)
Since the observables ai are not self-adjoint, they are inherently complex variables, and linear
transformations between them should be allowed to take on complex values. Thus, we shall
now consider making linear transformations on A but with complex coeﬃcients,
A →A′ = MA
A† →(A′)† = A†M†
(9.43)
113

Here, M is now an N × N matrix with complex matrix elements. The hamiltonian will
be invariant provided the quadratic form A†A is invariant for all A, which requires A†A →
(A′)†A′ = A†M†MA = A†A, so that we must have
M†M = I
(9.44)
The set of complex matrices satisfying this relation forms the group of unitary N × N
matrices, usually referred to as U(N).
The identity of the group is simply the identity
matrix, while the inverse is given by the dagger : M−1 = M†.
Note that when M is
restricted to have real coeﬃcients, we recover the orthogonal transformations discussed in
the preceding subsection, and we thus ﬁnd that SO(N) is a subgroup of U(N).
The corresponding inﬁnitesimal transformations are obtained by linearizing M around
the identity matrix,
M = I + i̟ + O(̟2)
̟† = ̟
(9.45)
The inﬁnitesimal transformations are thus parametrized by general N×N Hermitian matrices
̟. The number of free (real) parameters of these Hermitian matrices is N2, so that
dim U(N) = N2
(9.46)
The corresponding conserved charges are as follows,
T i
j = a†
iaj
(9.47)
with commutation relations for the Lie algebra of U(N),
[T i
j, T k
ℓ] = δj
kT i
ℓ−δℓ
iT k
j
(9.48)
The generators T ij are actually not Hermitian, but suitable linear combinations may be
constructed which are Hermitian,
T +
ij
=
a†
iaj + a†
jai
T −
ij
=
−i

a†
iaj −a†
jai

(9.49)
The N(N −1)/2 combinations T −
ij satisfy the commutation relations of the subalgebra
SO(N) ⊂U(N), and we have the relation ¯hT −
ij = Lij.
Finally, note that the group U(N) is actually the product of two groups. Any unitary
matrix MC in U(N) which is proportional to the identity MC = εI for |ε| = 1, commutes
with all elements in U(N). The elements MC themselves form a group, namely U(1), and
we thus have
U(N) = U(1) × SU(N)
SU(N) ≡{M ∈U(N), detM = 1}
(9.50)
114

This immediately gives the real dimension dim SU(N) = N2 −1. [Note that SU(N) itself
still contains non-trivial elements MC which are proportional to the identity MC = εI as
long as εN = 1. The set of all such elements forms a ﬁnite group, ZN which is referred to as
the center of SU(N) since they commute with all elements of SU(N).]
9.6.3
The group Sp(2N)
Is U(N) the most general symmetry group leaving the Hamiltonian invariant ? In general, it
is a diﬃcult question to answer whether one has found the most general symmetry of a given
system. In particular, for the harmonic oscillator Hamiltonian, it would seem that we can
have a symmetry still larger than U(N). Introduce the following 2N-dimensional column
matrix X,
H =
1
2m XtX
X =
 mωQ
P

(9.51)
The Hamiltonian H is now clearly invariant under arbitrary orthogonal transformations
X →X′ = MX, where M ∈SO(2N). This group is larger than U(N), since we have
SO(N) ⊂U(N) ⊂SO(2N)
(9.52)
Actually, even though SO(2N) leaves the Hamiltonian invariant, it is not a symmetry of
the full quantum system, because the canonical commutation relations are not invariant.
Expressed on the components xα with α = 1, · · ·, 2N of the matrix X, the commutation
relations [qi, pj] = i¯hδij become,
[xα, xβ] = i¯hmωJαβ
J =
 0
+I
−I
0

(9.53)
Real linear transformations X →X′ = MX which leave these canonical commutation
relations invariant must obey
MtJM = J
(9.54)
The set of all real matrices M satisfying MtJM = J forms the symplectic group Sp(2N),
for which the inverse is given by M−1 = −JMtJ.
The Hamiltonian is invariant under SO(2N) while the canonical commutation relations
are invariant under Sp(2N).
The entire system will thus be invariant under the largest
common subgroup of SO(2N) and Sp(2N). This is the set of real 2N × 2N matrices M
which satisfy both MtM = 1 and MtJM = J, which requires that [M, J] = 0. As a result,
M must be of the form
M =
 A
B
−B
A

MtM = I
(9.55)
115

The N × N matrix U = A + iB is then automatically unitary and belongs to U(N). We
conclude that U(N) was indeed the largest symmetry group of the N-dimensional harmonic
oscillator, conﬁrming our earlier study from a diﬀerent point of view.
9.7
Selection rules
In interpreting the strengths of various physical transitions, it is often striking how diﬀerent
the rates for various processes turn out to be. The most important ones are that unless
energy and momentum are conserved in a process, the corresponding transition amplitude
must vanish. Such a condition is often referred to as a selection rule. In the case of energy
momentum conservation, the selection rule is exact and results from the exact symmetry
of the invariance of the laws of nature under translations in time and in space. Another
exact selection rule is the conservation of total angular momentum, associated with the
invariance of the laws of Nature under space rotations. Yet another exact selection rule
is the conservation of electric charge, which is the result of an exact gauge invariance of
electro-dynamics.
The conservation of energy, momentum, angular momentum and electric charge are by
now so well-established selection rules that they their validity is used to detect new forms
of matter. One of the oldest such examples was the discovery of the neutrino by Pauli. By
the 1930’s the neutron was known to decay into a proton and an electron. If these were
the only decay products, however, then angular momentum could not be conserved during
the process, since the spin of the neutron, proton and electron are all ¯h/2, and a ¯h/2 unit
of angular momentum is missing in the balance. An integer unit ¯h could be carried oﬀby
orbital angular momentum, but a half integer unit cannot. This lack of balance led Pauli to
conjecture the existence of a new particle, the neutrino, with spin ¯h/2.
Some selection rules are only approximate and result not in the vanishing of certain
transition probabilities but in their suppression instead.
In particle physics, a number of such approximate selection rules are associated with
symmetries of the strong and electro-magnetic interactions which, however, fail to be sym-
metries of the weak interactions. For example, the lightest strongly interacting particles are
the three pions π0 and π±. Their quark composition, mass and life-times are given by
π0 = (¯uu −¯dd)/
√
2
mπ0 = 135 MeV
τπ0 = 10−17s
π+ = ¯du
mπ+ = 140 MeV
τπ+ = 10−8s
π−= ¯ud
mπ−= 140 MeV
τπ−= 10−8s
(9.56)
The reason for the vast diﬀerence in life-times is that strong and electro-magnetic interactions
preserve individual quark number, while the weak interactions do not. The π0 can decay via
116

electro-magnetic interactions, which occurs fast, while the π± cannot, resulting in typical
weak scale life-times. Other approximate selection rules resulting from the eﬀects of the
weak interactions are as follows,
• individual quark number (up, down, charm, strange, top, bottom)
• individual lepton number (electron, µ, τ)
• parity
• CP (charge conjugation combined with parity)
In the remainder of this section, we shall explore the implications of the exact selection rule
of the conservation of angular momentum. The techniques developed here will be applicable,
however, also to selection rules that are only approximate.
9.8
Vector Observables
In practice, selection rules will often manifest their eﬀect through the vanishing of certain
probability amplitudes, which may emerge as the matrix elements of certain observables.
Here, we shall be interested in selection rules associated with rotation invariance. The states
of the system may be organized as combinations of angular momentum eigenstates |j, m⟩. It
readily follows from the action of the angular momentum generators Ja, a = 1, 2, 3 on these
states that
(1)
⟨j′, m′|Ja|j, m⟩= 0
if
j′ ̸= j
(2)
⟨j, m′|Ja|j, m⟩= 0
if
|m′ −m| > 1
(9.57)
These results may be viewed as a simple form of angular momentum selection rules.
Analogous selection rules may be derived for operators other than Ja.
The simplest
case is for vector observables. A vector observable is actually a triplet V = (V1, V2, V3) of
observables which under rotations transform exactly as angular momentum itself does. Let
R = exp{−i⃗ω · J} be any ﬁnite rotation, then a vector observable is deﬁned to obey the
transformation rule,
RVaR† =
3
X
b=1
Ra
bVb
(9.58)
with R a real 3 × 3 orthogonal matrix, i.e. satisfying RtR = I. It is more convenient to use
the inﬁnitesimal version of this equation, given by
[Ja, Vb] = i¯h
3
X
c=1
εabcVc
(9.59)
117

Examples of vector observables include the angular momentum generators J themselves, the
position operators x, and the momentum generators p. We shall now establish selection
rules for all vector observables.
We begin by decomposing V in the raising and lowering basis that we also use for J itself.
V0 = V3
V± = 1
√
2 (V1 ± iV2)
(9.60)
so that the commutator relations become,
[J3, Vq]
=
q¯hVq
q = −, 0, +
[J±, V0]
=
∓
√
2¯hV±
[J±, V±]
=
0
[J±, V∓]
=
±
√
2¯hV0
(9.61)
In fact, we can write this set of commutation relations in a way that will easily generalize to
tensor observables later,
[Ja, Vq] =
X
q′

D(1)(Ja)

q,q′Vq′
(9.62)
where q′ ranges over the values −, 0, +.
9.9
Selection rules for vector observables
We shall study relations between various matrix elements of V q, and obtain the following
results, which are often referred to as the Wigner-Eckardt theorem,
(1)
(m′ −m −q)⟨j′, m′, α′|Vq|j, m, α⟩= 0
(9.63)
(2)
⟨j′, m′, α′|Vq|j, m, α⟩= 0
whenever
|j′ −j| ≥2
(3)
matrix elements with j′ −j = 0, ±1 are all related to one another;
Here, α and α′ represent all the quantum numbers other than j and m. In the Coulomb
problem, for example, α would be the principal quantum number, which ﬁxes the energy of
the state. For the special vector observable Jq = Vq, the matrix elements ⟨j′, m′, α′|Vq|j, m, α⟩
will vanish unless we also have α′ = α, but for general vector observables, this need not be
the case.
• To prove (1), we take the matrix elements of [J3, Vq] = ¯hqVq, or
⟨j′, m′, α′|J3Vq −VqJ3|j, m, α⟩−¯hq⟨j′, m′, α′|Vq|j, m, α⟩= 0
(9.64)
118

Applying J3 on either side gives (1).
• To prove (2), we shall assume without loss of generality that j′ −j ≥2. Now consider the
matrix element of the vanishing operator [J+, V+] = 0,
⟨j′, j + 2, α′|[J+, V+]|j, j, α⟩= 0
(9.65)
In the commutator, the term with J+ on the right of V+ vanishes, so we are left with
q
j′(j′ + 1) −(j + 1)(j + 2) ⟨j′, j + 1, α′|V+|j, j, α⟩= 0
(9.66)
Since j′(j′ + 1) −(j + 1)(j + 2) ̸= 0 for j′ −j ≥2, it follows that
⟨j′, j + 1, α′|V+|j, j, α⟩= 0
(9.67)
Next, using [J+, V0] = −¯h
√
2V+, and then [J+, V−] =
√
2¯hV0, we also ﬁnd that
⟨j′, j, α′|V0|j, j, α⟩= ⟨j′, j −1, α′|V−|j, j, α⟩= 0
(9.68)
As a result, we then have
⟨j′, m, α′|Vq|j, j, α⟩= 0
(9.69)
for all q and all m. Next, we evaluate
q
2j⟨j′, m, α′|Vq|j, j −1, α⟩
=
⟨j′, m, α′|VqJ−|j, j, α⟩
=
⟨j′, m, α′|J−Vq|j, j, α⟩
−
X
q′
D(1)(J−)qq′⟨j′, m, α′|Vq′|j, j, α⟩
(9.70)
The second term on the right hand side vanishes in view of (9.69). The ﬁrst term may be
re-expressed in terms of ⟨j′, m + 1, α′|Vq|j, j, α⟩which vanishes in view of (9.69). Thus, we
also have ⟨j′, m, α′|Vq|j, j −1, α⟩= 0 for all m, q. It is now clear that this argument may be
recursively repeated and leads to
⟨j′, m′, α′|Vq|j, m, α⟩= 0
(9.71)
for all m, m′, q as long as j′ −j ≥2, which proves assertion (2).
• To prove (3), we ﬁrst show that the matrix elements of V± are related to those of V0, by
using the commutator relations [J±, V0] = ∓
√
2¯hV±, and we ﬁnd,
√
2⟨j′, m′, α′|V±|j, m, α⟩
=
±N±
j,m⟨j′, m′, α′|V0|j, m ± 1, α⟩
∓N∓
j′,m′⟨j′, m′ ∓1, α′|V0|j, m, α⟩
(9.72)
119

Thus, it remains to relate the diﬀerent matrix elements of V 0 to one another. This is done
using the double commutator relation,
[J+, [J−, V0]] = 2¯h2V0
(9.73)
Taking the matrix elements of this relation,
⟨j′, m′, α′|[J+, [J−, V0]]|j, m, α⟩= 2¯h2⟨j′, m′, α′|V0|j, m, α⟩
(9.74)
In view of (1), we know that only the matrix elements with m′ = m can be non-vanishing,
and we now specialize to this case without loss of generality. Working out the commutators
and applying the operators J± to the states, we obtain,

N−
j′,mN+
j′,m−1 + N+
j,mN−
j,m+1 −2

⟨j′, m, α′|V0|j, m, α⟩
(9.75)
= N−
j′,mN−
j,m⟨j′, m −1, α′|V0|j, m −1, α⟩+ N+
j′,mN+
j,m⟨j′, m + 1, α′|V0|j, m + 1, α⟩
This is a second order recursion relation. Without loss of generality we shall assume that
j′ ≥j. Taking m = j, we get

N−
j′,jN+
j′,j−1 −2

⟨j′, j, α′|V0|j, j, α⟩= N−
j′,jN−
j,j⟨j′, j −1, α′|V0|j, j −1, α⟩(9.76)
Given that we now have two initial data for the second order recursion relation, it fol-
lows that all matrix elements ⟨j′, m, α′|V0|j, m, α⟩are known as a function of the single one
⟨j′, j, α′|V0|j, j, α⟩, which proves (3).
9.10
Tensor Observables
Higher rank tensor observables sometimes occur as well, but it is rare that tensors of rank
higher than 2 are needed, and we restrict here to tensors of rank 2. Quadrupole moments
produce a tensor of rank 2 for example, xixj which is manifestly symmetric.
Generally,
tensor of rank 2 arise as sums of tensor products of vector observables, as is the case in the
quadrupole moments. Consider a single one of these tensor products,
Tij = UiVj
i, j = 1, 2, 3
(9.77)
where Ui and Vj are vector observables. Here we shall generally take the observables U and
V to be diﬀerent quantities, but they could be the same.
The tensor T ij admits a unique decomposition into its trace part T0, its anti-symmetric
part T1 and its symmetric traceless part T2, according to the following formula,
Tij = 1
3δijT 0 +
3
X
k=1
εijkT 1
k + T 2
ij
(9.78)
120

where
T 0
=
3
X
k=1
Tkk
T 1
k
=
3
X
i,j=1
1
2εkijTij
T 2
ij
=
1
2Tij + 1
2Tji −1
3δijT 0
(9.79)
The component T 0 is a scalar and transforms in the j = 0 representation of the rotation
algebra; T 1
i is a vector observable and transforms in the j = 1 representation of the rotation
algebra. Finally, the symmetric traceless tensor T 2
ij has 5 linearly independent components
T 2
++, T 2
+0, T 2
+−−T 2
00, T 2
0−, T 2
−−, and form an irreducible representation j = 2.
The Wigner-Eckardt theorem may be generalized to tensor observables. Let us illustrate
this by discussion point (2) of this theorem. Since we have
⟨j′, m′, α′|Uk|j′′, m′′, α′′⟩= 0
|j′ −j′′| ≥2
⟨j′′, m′′, α′′|Vℓ|j, m, α⟩= 0
|j −j′′| ≥2
(9.80)
it follows that
⟨j′, m′, α′|Tkℓ|j, m, α⟩= 0
|j′ −j| ≥3
(9.81)
This result follows by inserting the identity between Uk and Vℓand representing the identity
by the completeness relation I =
P
j′′,m′′,α′′ |j′′, m′′, α′′⟩⟨j′′, m′′, α′′|.
9.11
P, C, and T
The operations of reversal of space, P, reversal of time, T, and reversal of charges, C, are
discrete transformations which are all symmetries of quantum electrodynamics (QED), but
not necessarily of the other interactions. It is a very general result that, in any quantum
theory invariant under special relativity (as QED and the Standard Model of Particle Physics
are), the combined transformation CPT is a symmetry. This result is often referred to as
the CPT theorem, and goes back to Pauli, who gave a ﬁrst proof of the theorem. Of course,
it is ultimately an experimental question as to whether CPT is a symmetry of Nature, and
so far, no violations have been observed.
Parity is a symmetry of the strong interactions, but is violated (“maximally”) by the
weak interactions. The combined operation CP (equivalent to T in a theory with CPT
invariance) is also violated by the weak interactions. CP also appears to be a symmetry
121

of the strong interactions, though it is not well-understood why, as it would be natural to
violate CP also’in the strong interactions. This is often referred to as the strong CP problem,
and remains an active area of investigation in particle physics.
Parity is the operation which reverses an odd number of space-like direction. In 3 space
dimensions, it is convenient to take it to act by x →−x, a transformation which commutes
with rotations. On Hilbert space, the transformation acts by a linear operator P, which is
self-adjoint and has unit square P 2 = I. On states and operators, P acts as follows,
P x P † = −x
P|x⟩= | −x⟩
P p P † = −p
P|p⟩= | −p⟩
P L P † = +L
P|ℓ, m⟩= (−)ℓ|ℓ, m⟩
(9.82)
Because of the last equation, a state may be characterized by both its angular momentum
quantum numbers ℓ, m or j, m and its behavior under parity. It is important to note that
a state of any given integer spin may be even or odd under parity. For example, spin zero
states |α⟩fall into two categories,
π|α+⟩= +|α+⟩
|α+⟩= scalar
π|α−⟩= −|α−⟩
|α−⟩= pseudo-scalar
(9.83)
The need for both kinds of states may be seen direct from the existence of spin zero operators
which have, however, odd parity. For example,
[J, (x · S)] = 0
P (x · S) P † = −(x · S)
(9.84)
Therefore, if |α+⟩is a scalar state with even parity, and spin 0, then the state (x · S)|α+⟩
must also be spin zero, but have odd parity, and is thus a pseudo-scalar. Similarly, spin 1
states that are odd under parity are referred to as vector states, while spin 1 states that
are even under parity are referred to as pseudo-vectors or more commonly as axial vectors.
Parity provides with a single selection rule, given by
(1 −πOπαπβ)⟨β|O|α⟩= 0
P|α⟩= πα|α⟩
P|β⟩= πβ|β⟩
POP † = πOO
(9.85)
where π2
α = π2
β = π2
O = 1.
Charge conjugation, C, maps the electron into a state with the same mass and momen-
tum, but with opposite electric charge; this state is the positron. Similarly, C maps any
particle into its anti-particle. The existence of anti-particles is required by special relativity,
122

and may be viewed as a relativistic eﬀect. For this reason, this operation is not normally
encountered in non-relativistic quantum mechanics, and we shall introduce it only later when
we discuss the Dirac equation.
Time-reversal reverses the direction of time t →−t. In classical mechanics, time reversal
leaves position and energy unchanged, but reverses the sign of momentum and angular mo-
mentum. In electrodynamics, the electric ﬁeld and the electric charge density are unchanged,
but the sign of the magnetic ﬁeld and the electric current are reversed. Under these transfor-
mations, the laws of mechanics and electrodynamics are then invariant under time reversal.
On the other hand, the fundamental laws of quantum mechanics are expressed via operators
acting on Hilbert space and the Schr¨odinger equation. For example,
i¯h∂ψ
∂t = −¯h2
2m∆ψ + V ψ
(9.86)
This equation is not invariant under ψ(t, x) →ψ(−t, x). What is needed in addition is the
operation of complex conjugation. The Schr¨odinger equation is indeed invariant under
T : ψ(t, x) →ψ(−t, x)∗
(9.87)
Therefore, the operation of time reversal acts not by a linear transformation, but rather
by an anti-linear transformation, which involves an extra complex conjugation. We have
instead,
T|α⟩= |α′⟩
⟨β′|α′⟩= ⟨β|α⟩∗
T|β⟩= |β′⟩
|⟨β′|α′⟩|2 = |⟨β|α⟩|2
(9.88)
Thus, probability is unchanged under time reversal, though the probability amplitude is
changed. As a result, we have
T(a|α⟩) = a∗T|α⟩
(9.89)
for any complex number a.
123

10
Bound State Perturbation Theory
We have now solved exactly a number of quantum mechanical problems. Systems of physical
interest in Nature, however, are often more complex than these problems, and cannot be
solved exactly. Perturbation theory is the approximation technique that allows one to study
systems that may be viewed as small deviations (i.e. perturbations) away from exactly solved
ones. In principle, successively higher orders in perturbation theory will yield results closer
and closer to the solution of the full system. In practice, however, perturbation theory has
many limitations that we shall illustrate below.
One distinguishes the following broad classes of perturbation theory, in order of generally
increasing diﬃculty,
1. time independent perturbation theory
• bound state spectrum
• continuous spectrum (scattering theory)
2. time dependent perturbation theory
These distinctions are mostly of a technical nature, with bound state perturbation theory
resembling most closely the perturbation theory of ﬁnite systems.
The general problem may be posed as follows.
Let the Hamiltonian H0 be solvable
and denote its energy eigenvalues by E0
n and its eigenstates by |E0
n⟩. For any given E0
n,
there may be just a single state (regular perturbation theory) or several states (degenerate
perturbation theory). The question now is how to calculate the energy eigenvalues En(λ)
and the eigenstates |En(λ)⟩for the family of Hamiltonians
H = H0 + λH1
(10.1)
where λ is a real parameter, H0 and H1 are independent of λ, and we assume that H†
1 = H1.
The parameter λ may correspond to an adjustable quantity in an experiment, such as an
external electric ﬁeld (such as in the Stark eﬀect) or a magnetic ﬁeld (such as in the Zeeman
eﬀect). It may also be a ﬁxed quantity in which we decide to expand, such as for example
the coupling of a certain interaction. Thus, we have
H0|E0
n⟩
=
E0
n|E0
n⟩
(H0 + λH1)|En(λ)⟩
=
En(λ)|En(λ)⟩
(10.2)
We seek a solution of the type
En(λ)
=
E0
n + λE1
n + λ2E2
n + O(λ3)
|En(λ)⟩
=
|E0
n⟩+ λ|E1
n⟩+ λ2|E2
n⟩+ O(λ3)
(10.3)
124

10.1
The validity of perturbation theory
We shall address two questions here. First, in which physical problems can we expect to
have a small parameter naturally available in which to expand. Second, in what sense is the
perturbative expansion convergent.
10.1.1
Smallness of the coupling
There are four fundamental forces of Nature.
1. Electro-Magnetism and electrodynamics
2. Weak interactions
3. Strong interactions
4. Gravity
Compared to all the other forces, gravity is always weak at the quantum level, and we shall
ignore its eﬀects throughout. Electrodynamics is the foremost example of a system in which
there is a small dimensionless parameter, namely the ﬁne structure constant, α ∼1/137.036.
As a result, perturbation theory in electrodynamics can be carried out successfully in many
situations. One of the oldest and most famous ones is the calculation of the quantum correc-
tions to the electron and muon magnetic moments. The lowest order value results directly
from the Dirac equation, and the ﬁrst correction was evaluated by Tomonaga, Schwinger
and Feynman, a result for which they were awarded the Nobel prize. Since then higher
order corrections have been included as well, and certain relevant eﬀects due to the weak
and strong interactions, and the best value known to date is as follows,
µ = g
 e
2mc

gµ(exp′nt) = 2 × 1.001159652410(200)
gµ(theory) = 2 × 1.001159652359(282)
(10.4)
In view of the uniﬁcation of electro-magnetism and weak interactions in the Standard Model
of particle physics, the weak interactions also have roughly the coupling constant α, though at
energies well below the mass of the W ± (about 80 GeV), their strength is further suppressed.
Thus, the weak interactions may also be treated perturbatively.
The situation is diﬀerent for the strong interactions, as their name suggests. At low
energies, such as in nuclear physics, the strong force dominates all other forces, including
electromagnetic. Because of this, two protons can actually bind in a Helium nucleus. Re-
markably, however, the strong interactions decrease in strength at high energies, phenomenon
referred to as asymptotic freedom. Experimentally, this property was discovered in 1968 in
125

a famous MIT/SLAC experiment.
Theoretically, asymptotic freedom was found to be a
generic property of non-Abelian gauge theories (with not too many fermions), in a famous
calculation by Gross, Wilczek and Politzer (1973). Thus, perturbation theory can be used
also for the strong interactions, provided the energies involved are large.
10.1.2
Convergence of the expansion for ﬁnite-dimensional systems
One would hope, ideally, that the perturbative expansions of energy and state in (10.3)
form a convergent Taylor series. Is this really the case ? When the corresponding quantum
problem has a ﬁnite-dimensional Hilbert space, and H0, H1 may be represented by N × N
matrices (and |En⟩by an N-dimensional column matrix), the perturbative expansion of
(10.3) will in fact be convergent, with some ﬁnite radius of convergence. This is because the
energy eigenvalues are solutions to the characteristic equation,
det (En −H0 −λH1) = 0
n = 1, · · ·, N
(10.5)
and the eigenvalues depend analytically on the parameter λ. On the other hand, for quantum
systems with inﬁnite-dimensional Hilbert spaces, the situation is more complicated, and the
λ-dependence may not be analytic.
10.1.3
The asymptotic nature of the expansion for inﬁnite dimensional systems
It is instructive to consider how perturbation theory is carried out in the path integral in order
to shed light on the convergence issues. For a simple one-dimension quantum mechanical
system given by the following Hamiltonian or, equivalently, Lagrangian
H
=
p2
2m + 1
2mω2q2 + λV (q)
L
=
1
2m ˙q2 −1
2mω2q2 −λV (q)
(10.6)
with V (q) given, for example, by q4, the path integral for the partition function assumes the
form,
Z
Dq exp
(1
¯h
Z β¯h
0
dt L(q, ˙q)
)
(10.7)
This path integral is complicated, but for the sake of understanding the perturbative expan-
sion, we shall truncate it to the contributions of just the t-independent functions q(t), i.e.
constant q. This gives an ordinary integral, which is of the general form,
I(ω, λ) =
Z +∞
−∞dq exp{−ω2q2 −λq4}
(10.8)
126

Here we have absorbed various constants (such as ¯h, m) into ω and λ. The integral I(ω, λ)
retains just the basic structure of the path integral. Expanding the integrand in powers of
λ for ﬁxed ω gives,
I(ω, λ) =
∞
X
n=0
(−λ)n
n!
Z +∞
−∞dq q4n exp{−ω2q2}
(10.9)
The calculation of the individual integrals for given n are carried out by setting x = q2,
which reduces the integral to a Γ-function.
These functions are deﬁned by the integral
representation
Γ(z) =
Z ∞
0
dx xz−1 e−x
(10.10)
for all complex z such that Re(z) > 0. There, the function obeys
Γ(z + 1) = zΓ(z)
(10.11)
Using this relation throughout the plane allows one to analytically continue Γ(z) throughout
the complex plane. The resulting function is holomorphic throughout the complex plane,
except for simple poles at all negative integers, and at zero. On positive integers n, the Γ
function reduces to the factorial, Γ(n+1) = n!. Just as for the factorial, the large z behavior
of the Γ-function is given by Sterling’s formula,
Γ(z) = ez ln z−z
s
2π
z

1 +
1
12z +
1
288z2 + · · ·

| arg(z)| < π
(10.12)
For curiosity’s sake, we also expand I(ω, λ) for ﬁxed λ and small ω, and using the same
techniques as above, we ﬁnd,
I(ω, λ)
=
1
ω
∞
X
n=0
Γ

2n + 1
2

n!
 −λ
ω4
!n
small λ
I(ω, λ)
=
1
4λ1/4
∞
X
n=0
Γ

2n+1
4

n!
 −ω2
√
λ
!n
small ω
(10.13)
Using Sterling’s formula one may determine the radii of convergence of each of the above se-
ries expansions. The expansion for ﬁxed λ > 0 and small ω has inﬁnite radius of convergence.
The series for ﬁxed ω and small λ, however, has zero radius of convergence !
The interpretation of this result is very illuminating. Suppose we changed the sign of
λ and made λ < 0. The integral is then clearly divergent (at q →∞). If the integral
admitted a Taylor series expansion around λ = 0 with ﬁnite radius of convergence, then
127

the integral for negative but small λ would be well-deﬁned and ﬁnite. So, the fact that the
integral is divergent for any negative value of λ, no matter how small, forces us to have a
series expansion that must have zero radius of convergence.
On the other hand, changing the sign of ω2 in the integral may change its value, but not
its convergence properties, no matter how large ω2 is. This explains why the series expansion
on power of ω2 can have inﬁnite radius of convergence.
Another way of looking at this problem is that the non-convergence of the small λ ex-
pansion comes from the behavior of the integral at q →±∞. There, it is the q4 term that
dominates, and so expanding in its strength is a singular thing to do. Generally, expanding
in the dominant behavior will lead to non-convergent expansions.
Finally, note that the integral I(ω, λ) is a perfectly ﬁne function. In fact, it is given by
a modiﬁed Bessel function as follows,
I(ω, λ) = ω
√
λ e
ω4
4λ K 1
4
 ω4
4λ
!
(10.14)
Looking up the asymptotics of this function in a standard reference (Bateman Vol II, page
86, formula (7)), we recover the asymptotic expansion derived above.
10.2
Non-degenerate perturbation theory
The basic assumption is that the energy level which we want to study of the unperturbed
Hamiltonian H0 is non-degenerate (other energy levels may or may not be degenerate). We
also assume that the energy and the state have an expansion of the type (10.3). Thus, we
need to solve the following problem,
(H0 + λH1)|En⟩= (E0
n + ∆n)|En⟩
(10.15)
where we use the abbreviation ∆n = En −E0
n = λE1
n + λ2E2
n + O(λ3). Contracting both
sides of the ﬁrst equation with the unperturbed state ⟨E0
n|, we ﬁnd,
⟨E0
n|(H0 + λH1)|En⟩= ⟨E0
n|(E0
n + ∆n)|En⟩
(10.16)
Using now the self-adjointness of H0, we see that the ﬁrst term on the left of the equations
cancels with the ﬁrst term on the right. The remaining terms give us an expression for ∆n,
∆n = λ⟨E0
n|H1|En⟩
⟨E0
n|En⟩
(10.17)
We learn immediately from this that the calculation of the energy correction to a given order
requires the correction to the state to one lesser order. In fact, it is immediate to ﬁnd the
ﬁrst order energy correction,
E1
n = ⟨E0
n|H1|E0
n⟩
(10.18)
128

assuming that the state |E0
n⟩is normalized. The equation determining the ﬁrst order cor-
rection to the state are obtained by expanding (10.15) to order λ, and are given as follows,
(H0 −E0
n)|E1
n⟩= (E1
n −H1)|E0
n⟩
(10.19)
The operator H0−E0
n is not invertible, however, since it has a zero eigenvalue with eigenvector
|E0
n⟩. To solve this equation, we now contract with an arbitrary state ⟨E0
m|, and again use
the self-adjointness of H0,
(E0
m −E0
n)⟨E0
m|E1
n⟩= ⟨E0
m|(E1
n −H1)|E0
n⟩
(10.20)
When m = n, this equation is automatically satisﬁed, and thus yields no information on the
quantity ⟨E0
n|E1
n⟩. But all other matrix elements are uniquely determined and we have
⟨E0
m|E1
n⟩= −⟨E0
m|H1|E0
n⟩
E0m −E0n
m ̸= n
(10.21)
This result allows us to write down the solution, using the completeness relation on all the
states |E0
m⟩, and we have
|E1
n⟩= c|E0
n⟩−
X
m̸=n
|E0
m⟩⟨E0
m|H1|E0
n⟩
E0m −E0n
(10.22)
The coeﬃcient c is, at this time arbitrary and not determined by the equation. The correction
to the energy of second order in λ may be derived from by expanding (10.17) to second order
in λ, and we obtain,
E2
n = ⟨E0
n|H1|E1
n⟩−cE1
n
(10.23)
Substituting in here the ﬁrst order correction to the state, we obtain,
E2
n = −
X
m̸=n
|⟨E0
m|H1|E0
n⟩|2
E0
m −E0
n
(10.24)
Here, we have used the self-adjointness of H1 to relate ⟨E0
m|H1|E0
n⟩= ⟨E0
n|H1|E0
m⟩∗.
An important consequence of this formula is that the second order correction to the
ground state energy is always negative, since for the ground state we have E0
m −E0
n > 0 for
all m ̸= n, and numerator is manifestly positive.
129

Figure 10: Diﬀerent possible behaviors of bound state perturbation theory
130

10.3
Some linear algebra
It will be useful to analyze in a little more detail the procedure for solving equation (10.19)
above, as the generalization of this method will enter when we deal with degenerate pertur-
bation theory. It is best to illustrate the issues for an N-dimensional Hilbert space H, whose
vectors are represented by column vectors, and whose inner product is given by (u, v) = u†v
for all u, v ∈H. In this case, we have a Hermitian linear operator A, represented by an
N × N Hermitean matrix, and a vector b in Hilbert space. The relevant linear equation,
analogous to (10.19) is then,
Ax = b
(10.25)
where x ∈H is the unknown vector. When A is invertible, we have simply x = A−1b. When
A is not invertible, the above equation may still admit solution, under certain conditions.
When A is not invertible, it has a non-trivial null-space or kernel, and a non-trivial range,
deﬁned by
Ker A
=
{v ∈H such that Av = 0}
Range A
=
A H
(10.26)
Equation (10.25) has at least one solution if and only if b ∈Range A. This rather abstract
condition may be translated into a simple concrete criterion. To test whether a given b
belongs to Range A, we proceed as follows. If b belongs to Range A, then it follows that
(v, b) = (v, Ax) = (Av, x) = 0 for all v ∈Ker A. For any vector subspace V of H, we deﬁne
it orthogonal complement as follows,
V⊥= {v ∈H such that (u, v) = 0 for all u ∈V}
(10.27)
For any vector space we clearly have
V ⊕V⊥= H
(10.28)
The sum is direct since a vector belonging to both V and V⊥must necessarily vanish. From
this deﬁnition, we conclude that Range A ⊂(Ker A)⊥.
Conversely, if v ∈(Range A)⊥,
then we have (v, Ax) = (Av, x) = 0 for all x ∈H, so that v ∈Ker A, and we also have
(Range A)⊥⊂Ker A. As a result, we must have8
Range A = (Ker A)⊥
(10.29)
8For non-selfadjoint operators, the corresponding equation is analogously given by Range A† = (Ker A)⊥,
where A† is the adjoint operator to A.
131

Thus, we conclude that b ∈Range A if and only if
(v, b) = 0
for all
v ∈Ker A
(10.30)
If this condition is satisﬁed, equation (10.25) admits at least one solution which we denote
by x0. The general solution is then
x = x0 + u
for any
u ∈Ker A
(10.31)
The above discussion readily extends to inﬁnite-dimensional Hilbert spaces, as long as the
operator A is bounded. In general, if A is unbounded, subtle new issues may arise.
10.4
The Stark eﬀect for the ground state of the Hydrogen atom
Faraday investigated the eﬀect of electric and magnetic ﬁelds on light, in particular on
its polarization and wavelength (color). He discovered that polarization is inﬂuenced by
magnetic ﬁelds, but he found no change in color.
Actually, both electric and magnetic
ﬁelds change the energy levels of atoms and molecules, and will thus change the frequencies
of radiation emitted and absorbed. The eﬀects are so small, however, that more reﬁned
experimentation than Faraday disposed of in the mid 1800’s to observe the eﬀects. The
eﬀect of electric ﬁelds was established by Stark. We shall study it here as an example of how
to use perturbation theory, both non-degenerate and degenerate.
The correction to the Hamiltonian of an electron in the presence of an electric ﬁeld E
along the z axis is given by
H1(x) = eEz
(10.32)
where z is the coordinate along the z-axis, and −e is the charge of the electron. The electric
ﬁeld also interacts with the electrically positive nucleus, but since the mass of the nucleus is
much larger than that of the electron, this eﬀect may be safely neglected. Spin will similarly
be neglected. We shall concentrate on atoms with only a single electron, whose states are
labeled by the quantum numbers n, ℓ, m of the Coulomb problem, so the states are denoted
by |n, ℓ, m⟩with n ≥ℓ+ 1, and |m| ≤ℓ.
For n ≥2, each energy level is degenerate, so we shall have to develop degenerate
perturbation theory to handle this reliably. For the ground state, ﬁrst order perturbation
theory gives
E1
|1,0,0⟩= ⟨1, 0, 0|H1|1, 0, 0⟩= eE⟨1, 0, 0|z|1, 0, 0⟩= 0
(10.33)
The above matrix element vanishes by rotation invariance of the ground state. Second order
perturbation theory of the ground state always lowers the energy on general principles. We
cannot quite calculate this eﬀect here, though, because the summation over all states, which
enters second order perturbation theory, will involve here the bound state part, but also the
continuous spectrum part.
132

10.5
Excited states and degenerate perturbation theory
The energy of a state |n, ℓ, m⟩is
E0
n = −1
2n2mec2α2
(10.34)
and is independent of the angular momentum quantum numbers ℓ, m. To investigate the
Stark eﬀect on excited states, we begin by evaluating the matrix elements of H1 in the basis
|n, ℓ, m⟩. For simplicity, we shall concentrate on the ﬁrst excited states with n = 2. There
are 4 states, and we have the following matrix elements,
H1 = eE





0
M
0
0
M∗
0
0
0
0
0
0
0
0
0
0
0





|2, 0, 0⟩
|2, 1, 0⟩
|2, 1, +1⟩
|2, 1, −1⟩
(10.35)
Here, all diagonal matrix elements vanish because z has odd parity while the states |2, ℓ, m⟩
all have deﬁnite parity. The following 5 matrix elements vanish because of the Wigner-Eckard
theorem,
⟨2, 0, 0|z|2, 1, ±1⟩= ⟨2, 1, 0|z|2, 1, ±1⟩= ⟨2, 1, 1|z|2, 1, −1⟩= 0
(10.36)
The only remaining matrix elements are non-vanishing, and we set
⟨2, 0, 0|z|2, 1, 0⟩
=
M
⟨2, 1, 0|z|2, 0, 0⟩
=
M∗
(10.37)
This completes the calculation of the matrix elements of H1. The full Hamiltonian in this
basis is now given by putting together the contribution from the unperturbed Hamiltonian,
which gives E0
2 for all 4 states, with H1, and we get
H =





E0
2
eEM
0
0
eEM∗
E0
2
0
0
0
0
E0
2
0
0
0
0
E0
2





|2, 0, 0⟩
|2, 1, 0⟩
|2, 1, +1⟩
|2, 1, −1⟩
(10.38)
Diagonalizing this matrix, we obtain the 4 energy eigenvalues,
E2,1
=
E0
2 + eE|M|
E2,2
=
E0
2 −eE|M|
E2,3 = E2,4
=
E0
2
(10.39)
Note that a two-fold degeneracy remains on the last two states.
133

10.6
The Zeeman eﬀect
A magnetic ﬁeld on a (Hydrogen like) atom interacts with both the electron spin as well
as its orbital angular momentum generated magnetic moment. To ﬁrst order in a constant
magnetic ﬁeld B along the z axis, the perturbing Hamiltonian is given by
H1 = −eB
2mec(Lz + 2Sz)
(10.40)
The factor of 2 in front of spin is due to the fact that the gyro-magnetic ratio for the electron
is 2 (up to order α corrections). This time, spin needs to be taken into account, so we shall
label the states by |n, ℓ, mℓ, ms⟩where mℓis the orbital magnetic quantum number, satisfying
|mℓ| ≤ℓ, while ms is the spin magnetic quantum number given by ms = ±1/2.
Conveniently, H1 is diagonal in this basis. So, although in excited states this is degenerate
perturbation theory, it is straightforward to evaluate the corrections. The diagonal matrix elements
of H1 are given by
E1
|n,ℓ,mℓ,ms⟩
=
−eB
2mec⟨n, ℓ, mℓ, ms|(Lz + 2Sz)|n, ℓ, mℓ, ms⟩
=
−eB
2mec(mℓ+ 2ms)
(10.41)
This same correction may of course also be evaluated in the basis |j, ℓ, m⟩but the formula is slightly
more involved,
E1
|n,j,ℓ,m⟩
=
−eB
2mec⟨n, j, ℓ, m|(Jz + Sz)|n, j, ℓ, m⟩
=
−eB
2mec m

1 ±
1
2ℓ+ 1

(10.42)
where the above ± refers to the two cases j = ℓ± 1/2, and m = mℓ+ ms is the total magnetic
quantum number.
10.7
Spin orbit coupling
Alkali atoms, such as Li, Na, K, etc, show many of the properties of single electron atoms and
ions, because only one electron occurs on top of a completely ﬁlled shell (characteristic of the
noble gases). But the cloud of inner electrons does interact with the outer electron via spin orbit
coupling. The magnetic moment of the outer electron couples to the orbital magnetic moment, via
a perturbing Hamiltonian of the type
H1 = φ(r)L · S
(10.43)
In the basis of states given by the tensor product of the spin and orbital quantum numbers, this
Hamiltonian is not diagonal.
One could evaluate the matrix elements of H1 in this basis and
134

then diagonalize that matrix for each level of degeneracy n. Actually, it is much more convenient
to change basis and use the methods of addition of angular momentum. We shall use instead the
following maximal set of commuting observables (in addition to the Hamiltonian), J2, L2, Jz, where
J = L + S. The operator S2 need not be included since its value is ﬁxed at 3¯h2/4.
In the basis of these commuting observables, the states are labeled again by |n, j, ℓ, m⟩, and H1
is diagonal in this basis, since we have the following well-known formula,
2L · S = J2 −L2 −S2
(10.44)
so that we may evaluate the ﬁrst order perturbations in a straightforward manner, and we obtain,
E1
|n,j,ℓ,m⟩= 1
2

j(j + 1) −ℓ(ℓ+ 1) −3
4

¯h2⟨n, j, ℓ, m|φ(r)|n, j, ℓ, m⟩
(10.45)
The last matrix element must be evaluated using the radial wave-functions of the Coulomb problem.
10.8
General development of degenerate perturbation theory
We now develop the general perturbation theory of an energy level E0
d of H0 which admits an
N-fold degeneracy. We shall denote the unperturbed states by |E0
d; i⟩where i = 1, · · · , N, and E0
d
is the common unperturbed energy,
H0|E0
d; i⟩= E0
d|E0
d; i⟩
i = 1, · · · , N
(10.46)
Under the perturbation by λH1, the N degenerate levels will generally split and these energies will
be denoted by Ed,i = Ed,i(λ). The equation of interest is
(Ed,i −H0 −λH1)|Ed,i⟩= 0
(10.47)
Both the energy and the state admit an expansion in powers of λ,
Ed,i
=
E0
d + λE1
d,i + λ2E2
d,i + O(λ3)
|Ed,i >
=
|E0
d; i⟩+ λ|E1
d,i⟩+ λ2|E2
d,i⟩+ O(λ3)
(10.48)
The key idea is to rearrange the energy eigenvalue before starting to expand in powers of λ.
Let H0 denote the N-dimensional subspace of the full Hilbert space H generated by the degen-
erate states |E0
D, i⟩, and denote by P0 the projection operator onto H0. The orthogonal complement
of H0 is denoted H1 and consists of all the eigenstates of H0 with eigenvalue diﬀerent from E0
D.
Since H0 is self-adjoint, the spaces H0 and H1 are guaranteed to be orthogonal and their sum to
equal H. Let P1 denote the projection operator onto H1. We then have
H0 ⊕H1
=
H
P0P1 = P1P0 = 0
P0 + P1
=
I
P 2
0 = P0, P 2
1 = P1
(10.49)
The operators P0 and P1 commute with H0, by construction.
135

We will now use these projectors to decompose the eigenvalue equation (10.47). Inserting the
identity in front of the state gives,
(Ed,i −E0
d −λH1)P0|Ed,i⟩+ (Ed,i −H0 −λH1)P1|Ed,i⟩= 0
(10.50)
Here, we have used the fact that all states in P0|Ed,i⟩have eigenvalue E0
d under H0. Our next step
is to project this equation with P0 and P1, and we obtain,
P0

Ed,i −E0
d −λP0H1

P0|Ed,i⟩= λP0H1P1|Ed,i⟩
P1

Ed,i −H0 −λP1H1

P1|Ed,i⟩= λP1H1P0|Ed,i⟩
(10.51)
We shall deduce from these the equations that yield P0|Ed,i⟩and P1|Ed,i⟩.
The operator P1(Ed,i −H0 −λH1)P1 is invertible on H1 provided λ is suﬃciently small. The
reason is that for λ = 0, it reduces to the operator P1(E0
d −H0)P1 which is by construction invertible
on H1. Invertibility is an open condition, which means that in the space of all self-adjoint operators,
any operator in a suﬃciently small neighborhood of the invertible operator will also be invertible.
Concretely, a ﬁnite-dimensional matrix A is invertible if det A ̸= 0. But this means that if we
consider a family of operators A + λB for suﬃciently small λ, we will still have det(A + λB) ̸= 0.
Thus, perturbatively speaking, the operator P1(Ed,i −H0 −λH1)P1 will be invertible on H1. As a
result, we have
P1|Ed,i⟩= λ
 
1
Ed,i −H0 −λP1H1
!
H1
P1H1P0|Ed,i⟩
(10.52)
Here the subscript H1 stands for the inverse operator restricted to the subspace H1. It remains to
determine P0|Ed,i⟩and the corresponding energies Ed,i. To do so, we substitute the expression for
P0|Ed,i⟩, found above, into equation P0, and we ﬁnd,

Ed,i −E0
d −λP0H1

P0|Ed,i⟩= λ2P0H1P1
 
1
Ed,i −H0 −λP1H1
!
H1
P1H1P0|Ed,i⟩
(10.53)
To order O(λ0), this equation is satisﬁed trivially.
10.8.1
Solution to ﬁrst order
To order O(λ), the right hand side may be dropped, and the energy may be approximated by
Ed,i −E0
d = λE1
d,i + O(λ2). The resulting equation becomes,

E1
d,i −P0H1P0

|E0
d; i⟩= 0
(10.54)
The energy eigenvalues are determined by the eigenvalues of the operator P0H1P0 restricted to H0,
and are solutions of the characteristic equation,
det

E1
d,i −P0H1P0

H0 = 0
(10.55)
136

Note that the eigenstates that are being determined by this eigenvalue equation are the ones to
lowest order. They must be eigenvectors of the Hamiltonian P0H1P0. This is precisely the setting
that we had encountered already when dealing with the Stark eﬀect to this order.
Next, we derive the corrections to the states to order λ. The simplest part is given by (10.52),
and to order O(λ) results in,
P1

|E0
d; i⟩+ λ|E1
d,i⟩

= λ
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.56)
By construction, P1|E0
d; i⟩= 0, so that the remaining equation gives,
P1|E1
d,i⟩=
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.57)
The solution for P0|E1
d,i⟩needs to be handled at the same time as the second order correction to
the energy, which we proceed to do now.
10.8.2
Solution to second order
Determining P0|E1
d,i⟩proceeds analogously from (10.58), which we approximate up to order λ2
included. Retaining only O(λ2) contributions on the right hand side gives,

Ed,i −E0
d −λP0H1

P0|Ed,i⟩= λ2P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.58)
Expanding the left hand side to this order gives,

Ed,i −E0
d −λP0H1

P0|Ed,i⟩
=
λ(E1
d,i −P0H1)P0|E0
d; i⟩+ λ2E2
d,i|E0
d; i⟩
+λ2
E1
d,i −P0H1

P0|E1
d,i⟩
(10.59)
The ﬁrst term on the right hand side vanishes in view of our results for E1
d,i and |E0
d; i⟩. The other
terms are now all of the same order, λ2, as were the terms on the right hand side of (10.58). This
gives the ﬁnal equation,
E2
d,i|E0
d; i⟩+

E1
d,i −P0H1

P0|E1
d,i⟩= P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.60)
We ﬁrst determine E2
d,i by taking the product of the above equation with ⟨E0
d; i|. The second term
on the right hand side cancels out in this process in view of (10.54), and we have
E2
d,i = ⟨E0
d; i|P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.61)
137

This formula may be rendered more explicit by introducing a complete set of orthonormalized
eigenstates of H0 belonging to H1, which we denote by |E0
k⟩, and we have
E2
d,i = −
X
k
|⟨E0
d; i|H1|E0
k⟩|2
Ek −E0
d
(10.62)
Once E2
d,i is known, the equation for P0|E1
d,i⟩may be written as,

E1
d,i −P0H1

P0|E1
d,i⟩= E2
d,i|E0
d; i⟩+ P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.63)
By construction, this equation is now orthogonal to ⟨E1
d,i|.
If the eigenvalue E2
d,i is non-degenerate with any of the other eigenvalues E1
d,j, for j ̸= i, then
the operator on the left hand side may be inverted on the subspace of H0 which is orthogonal to
|E1
d,i⟩, and we get
P0|E1
d,i⟩=
N
X
j̸=i
|E1
d,j⟩
1
E1
d,i −E1
d,j
⟨E1
d,j|P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0|E0
d; i⟩
(10.64)
Introducing again a complete set of states |Ek⟩for H1, we may recast this formula as follows,
P0|E1
d,i⟩=
N
X
j̸=i
|E1
d,j⟩
1
E1
d,i −E1
d,j
X
k
⟨E1
d,j|H1|Ek⟩⟨Ek|H1|E0
d; i⟩
E0
d −Ek
(10.65)
If, on the other hand, the energy level E1
d,i remains degenerate, then the above formula cannot be
applied, since some of the denominators in E1
d,i −E1
d,j. When this happens, one needs to rearrange
the corresponding degenerate order λ0 states so as to be eigenstates of the second order perturbation
P0H1P1
 
1
E0
d −H0
!
H1
P1H1P0
(10.66)
as well. We shall not work out this case explicitly here.
10.9
Periodic potentials and the formation of band structure
The electronic structure in crystals is organized in bands. Empty or completely ﬁlled bands are
electronically inactive, while partially ﬁlled band allow for electronic conductivity, providing a
quantitative explanation for the fundamental distinction between insulators and conductors. Here,
we shall derive the basic mechanism responsible for the formation of bands.
For simplicity, we concentrate on one-dimensional systems. The crystalline structure translates
into a periodic potential for the electron, giving rise to a Hamiltonian of the form,
H = p2
2m + V (x)
V (x + a) = V (x)
(10.67)
138

Here, a is the lattice spacing of the crystal. As a result, the translation operator by a ﬁnite shift a,
denoted by T(a), and given by
T(a) = exp{iap/¯h}
(10.68)
must commute with H. We choose a basis of eigenstates for H which also diagonalizes T(a). The
eigenvalues of T(a) are phases speciﬁed by a wave-number k, so that
T(a)|k, n⟩
=
e−ika|k, n⟩
H|k, n⟩
=
Ek,n|k, n⟩
(10.69)
By construction, for given a, the wave-number is periodic with period k →k + 2π/a, so states are
labeled uniquely when k runs over and interval of length 2π/a, called a Brillouin zone, for example
the ﬁrst Brillouin zone is speciﬁed by
−π
a ≤k ≤π
a
(10.70)
The additional index n is a further quantum number needed to describe all the states.
It is useful to view the problem in a Schr¨odinger equation picture, for wave functions ψk,n(x) =
⟨x|k, n⟩, so that ψk,n(x + a) = eikaψk,n(x). Alternatively, the wave function may be expressed in
terms of a periodic wave function ϕk,n(x) and a phase factor,
ψk,n(x)
=
eikxϕk,n(x)
ϕk,n(x + a)
=
ϕk,n(x)
(10.71)
where the periodic wave function now obeys a k-dependent Schr¨odinger equations,
 
(p + ¯hk)2
2m
+ V (x)
!
ϕk,n(x) = Ek,nϕk,n(x)
(10.72)
The quantum number n now labels the discrete spectrum of this periodic equation.
For vanishing potential, V = 0, it is straightforward to solve this problem, and we have the
energy levels of a periodic free system,
pϕk,n = 2πn¯h
a
ϕk,n
n = 0, ±1, ±2, · · ·
(10.73)
so that the energies are
Ek,n = ¯h2
2m

k + 2πn
a
2
(10.74)
For certain values of k within the Brillouin zone, energy levels are be degenerate, namely
Ek,n′ = Ek,n
n′ ̸= n
(10.75)
139

This occurs when
2k = −2π
a (n′ + n)
(10.76)
Within the ﬁrst Brillouin zone, this occurs precisely when
k = 0
n′ = −n ̸= 0
k = ±π
a
n′ + n = ∓1
(10.77)
At each of those points, the spectrum of the free Hamiltonian is degenerate, since two states occur
with the same energy.
We concentrate on the degeneracies at the edge of the Brillouin zone, k = k += π/a, where
the levels n′ = −n −1 and n are degenerate. We now turn on any perturbation which mixes the
degenerate levels. We introduce the notation,
⟨k+, −n −1|V |k+, n⟩= V−+
⟨k+, n|V |k+, n⟩= V++
⟨k+, n|V |k+, n′⟩= V+−
⟨k+, −n −1|V |k+, −n −1⟩= V−−(10.78)
Self-adjointness of V implies V−+ = V ∗
+−, and we require that this mixing matrix element be
non-zero. The energy levels in the presence of the potential V for suﬃciently small V are then
determined by the equation
det
 E −E0 −V++
−V+−
−V−+
E −E0 −V−−

= 0
(10.79)
where E0 = Ek+,n = Ek,−n−1. This gives the following quadratic equation for the two energy levels,

E −E0 −1
2(V++ + V−−)
2 = |V+−|2 + 1
4(V++ −V−−)2
(10.80)
with solutions,
E = E0 + 1
2(V++ + V−−) ± 1
2
q
(V++ −V−−)2 + 4|V+−|2
(10.81)
This eﬀect opens an energy gap in the spectrum, and creates a band structure.
10.10
Level Crossing
The problem of electronic band formation, discussed in the preceding section, is fundamentally
a problem of level crossing.
In fact, the conclusion obtained above indicates that, as soon as
interactions are turned on, levels do not cross one another. This eﬀect is quite general, and we
shall now also prove it more generally.
We shall assume that two levels, with energies E0
n and E0
n′, are very close to one another, so
that E0
n′ −E0
n is small compared to the gaps between either E0
n or E0
n′ and any other energies in
140

the spectrum. We do not assume, however, that E0
n′ = E0
n, so that we can apply non-degenerate
perturbation theory. First order perturbation theory will split the levels signiﬁcantly and lift the
approximate degeneracy unless we have E1
n = E1
n′, namely when ⟨E0
n|H1|En⟩= ⟨E0
n′|H1|En′⟩. In
this case, we need to go to second order perturbation theory.
At second order perturbation theory, we may continue to use non-degenerate perturbation
theory to deduce those second order corrections, and they are given by
E2
n
=
−
X
m̸=n
|⟨E0
m|H1|E0
n⟩|2
E0m −E0n
E2
n′
=
−
X
m̸=n′
|⟨E0
m|H1|E0
n′⟩|2
E0m −E0
n′
(10.82)
This is a complicated sum, in general with an inﬁnite number of terms. The assumption that
|E0
n′ −E0
n| ≪|E0
m −E0
n| for all m ̸= n, n′, which we made above, however, allows us to retain the
essential contributions of these sums only. The smallness of E0
n′ −E0
n allows us to approximate
each sum by just a single term, and we get
E2
n
=
−|⟨E0
n′|H1|E0
n⟩|2
E0
n′ −E0n
+ O(1)
E2
n′
=
−|⟨E0
n|H1|E0
n′⟩|2
E0n −E0
n′
+ O(1)
(10.83)
where we neglected terms that have ﬁnite limits as E0
n′ −E0
n →0. We now read oﬀthe second
order behavior,
E0
n′ > E0
n
⇒
E2
n′ > 0,
E2
n < 0
E0
n′ < E0
n
⇒
E2
n′ < 0,
E2
n > 0
(10.84)
In either case, the levels repel one another. This eﬀect is sometimes referred to as the no-level
crossing Theorem.
There is, however, one very important exception to this eﬀect. We tacitly assumed that the
matrix element ⟨E0
n′|H1|E0
n⟩does not vanish in deriving the non-level crossing theorem. Naturally,
if this matrix element vanishes, then the degeneracy is not lifted, and levels can actually cross.
Putting together the conditions from ﬁrst and second order perturbation theory for levels to cross,
we have
⟨E0
n|H1|En⟩
=
⟨E0
n′|H1|En′⟩
⟨E0
n′|H1|E0
n⟩
=
0
(10.85)
which means that H1 restricted to the two-dimensional subspace of states |En⟩and |En′⟩is actually
proportional to the identity operator. The full Hamiltonian then necessarily has an SU(2) symmetry
which rotates these two states into one another.
Thus, we have discovered an important amendement to the no level crossing theorem, namely
that levels can cross if and only if the Hamiltonian H has a symmetry at the point where the levels
are to cross.
141

11
External Magnetic Field Problems
In the chapter on perturbation theory, we have studied the eﬀect of small magnetic ﬁelds on atoms
and ions via the Zeeman eﬀect. The application of strong magnetic ﬁelds produces further, and
remarkable eﬀects, such as the Quantized Hall Eﬀect. In this chapter, we shall solve (anew) the
general problem of charged particles in the presence of a strong magnetic ﬁeld, and then apply the
methods and results to the case of the quantized Hall Eﬀect.
11.1
Landau levels
In problem set 8 of 221A, we studied the problem of a 2-dimensional particle with electric charge
2e in the presence of a uniform magnetic ﬁeld, given by the following classical Lagrangian,
L(x, y, ˙x, ˙y) = 1
2m( ˙x2 + ˙y2) −1
2mω2(x2 + y2) + 1
2eB(x ˙y −y ˙x)
(11.1)
This Lagrangian essentially also applies to a 3-dimensional charged particle in a magnetic ﬁeld, since
the direction along the magnetic ﬁeld will be decoupled from the dynamics of the other directions.
The corresponding canonical momenta are
px
=
m ˙x −1
2eBy
py
=
m ˙y + 1
2eBx
(11.2)
The Hamiltonian is then given by
H(x, y, px, py) =
1
2m(px + 1
2eBy)2 + 1
2m(py −1
2eBx)2 + 1
2mω2(x2 + y2)
(11.3)
Note that since we are not assuming the magnetic ﬁeld to be small, we keep the term of order B2.
In problem set 8, functional methods were used to derive the partition function, and it was found
to be given by
Z = Tr e−βH =
e−1
2 β¯hω+
1 −e−β¯hω+ ×
e−1
2β¯hω−
1 −e−β¯hω−
(11.4)
where the frequencies ω± ≥0 are given by
ω± = ωB ±

eB
2m

ω2
B = ω2 + e2B2
4m2
(11.5)
The full spectrum is deduced by expanding the denominators in a Taylor series and we ﬁnd,
E(n+, n−) = 1
2¯hω+(1 + 2n+) + 1
2¯hω−(1 + 2n−)
(11.6)
for n± ≥0. Eﬀectively, the system decomposes into two independent harmonic oscillators, with
frequencies ω+ and ω−. Clearly, something interesting happens when ω →0, since then ω−→0,
142

and the partition function will diverge in this limit. Below, we investigate in the operator language,
the phenomenon that drives this divergence.
It is straightforward to recover this result in the operator formulation. We set ω = 0, so that
ωB = |eB/2m|, and introduce the following harmonic oscillator combinations,
a1
=
1
√2m¯hωB
(ipx + mωBx)
a2
=
1
√2m¯hωB
(ipy + mωBy)
(11.7)
and their Hermitian conjugates.
By construction they obey canonical commutation relations
[ai, a†
j] = δij for i, j = 1, 2. Re-expressing the Hamiltonian in terms of these oscillators,
H = ¯hωB

a†
1a1 + a†
2a2 + 1

+ ieB¯h
2m

a†
1a2 −a†
2a1

(11.8)
Finally, we make the following orthonormal change of variables,
a
≡
1
√
2(a1 + ia2)
b
≡
1
√
2(a1 −ia2)
(11.9)
and their conjugates. These oscillators still obey canonical commutation relations,
[a, b] = [a, b†]
=
0
[a†, b] = [a†, b†]
=
0
[a, a†] = [b, b†]
=
1
(11.10)
Using the following relations
2a†a
=
a†
1a1 + a†
2a2 + i

a†
1a2 −a†
2a1

2b†b
=
a†
1a1 + a†
2a2 −i

a†
1a2 −a†
2a1

(11.11)
the Hamiltonian may be recast as follows,
H = 1
2¯hω+(1 + 2a†a) + 1
2¯hω−(1 + 2b†b)
(11.12)
The above spectrum then follows at once.
As ω →0, the problem is reduced to that of a charged particle in a magnetic ﬁeld, and the
frequency ω−→0. Remarkably, as a result, the spectrum becomes inﬁnitely degenerate, since the
energies do not depend upon n−any more. Alternatively, as ω = 0, we have
[H, b] = [H, b†] = 0
(11.13)
For each value of n+, there is a Landau level with an inﬁnite degeneracy. The algebra of b and
b† represent the symmetry algebra of this degeneracy. Of course, in any physical system, space is
not truly of inﬁnite extent and the magnetic ﬁeld is not quite uniform. Nonetheless, this inﬁnite
degeneracy makes the Landau levels an incredibly interesting phenomenon.
143

11.2
Complex variables
The x, y parts of the combinations a and b correspond to forming the complex variables
z =
1
√
2(x + iy)
pz = 1
√
2(px −ipy)
¯z =
1
√
2(x −iy)
p¯z = 1
√
2(px + ipy)
(11.14)
which satisfy the canonical commutation relations,
[z, pz] = [¯z, p¯z]
=
i¯h
[z, p¯z] = [¯z, pz]
=
0
(11.15)
and as a result,
pz = −i¯h ∂
∂z
p¯z = −i¯h ∂
∂¯z
(11.16)
The oscillators now become,
a =
1
√2m¯hωB

ip¯z + mωBz

a† =
1
√2m¯hωB

−ipz + mωB¯z

b =
1
√2m¯hωB

ipz + mωB¯z

b† =
1
√2m¯hωB

−ip¯z + mωBz

(11.17)
Since we are assuming ω = 0, the Hamiltonian depends only on a and a†, H = ¯hωB(2a†a + 1).
The lowest Landau level |0, n−⟩is characterized by a|0, n−⟩= 0. The wave functions of the lowest
Landau level satisfy the diﬀerential equation
 ∂
∂¯z + mωB
¯h
z

ψ(z, ¯z) = 0
(11.18)
Its general solution is straightforward (since as a diﬀerential equation in ¯z, you may think of z as
a constant coeﬃcient), and we get
ψ(z, ¯z) = ϕ(z)ψ(0)(z, ¯z)
ψ(0)(z, ¯z) = exp

−mωB
¯h
|z|2

(11.19)
where ϕ(z) is an arbitrary complex analytic function of z. Actually, ϕ(z) cannot has poles since they
would lead to non-square integrable wave functions. Also, assuming that ψ(z, ¯z) is single-valued,
it follows that ϕ(z) must be single-valued, and thus cannot have branch cuts. Therefore, ϕ(z)
must be single-valued and holomorphic throughout the complex plane. A basis for such functions
is obtained by polynomials (and square integrable Taylor expandable functions by completeness).
Notice that all such polynomial functions are obtained by applying b† repeatedly to the ground
state ψ(0) of both a and b, since we have
ψ(0)
n−∼(b†)n−ψ0(z, ¯z) ∼zn−ψ0(z, ¯z)
(11.20)
This agrees with general principles that the group theory of b, b† must precisely reproduce the
normalizable spectrum.
144

11.3
Calculation of the density of states in each Landau level
An important characterization of the Landau levels is the number of quantum states that are
available. This is easy to compute as we have the explicit wave-functions available. Consider the
lowest Landau level ﬁrst. All states in this level are obtained by applying powers of b† to the ground
state with wave function ψ0(z, ¯z). The result is (the overall normalization will be immaterial),
ψ(0)
n (z, ¯z) ∼zn exp

−

eB
2¯h
 × |z|2

(11.21)
In terms of radial coordinates, x + iy = r eiθ, we have
ψ(0)
n (r, θ) ∼rneinθ × exp

−

eB
4¯h
 × r2

(11.22)
Clearly, because of the θ-dependence, states for diﬀerent n are orthogonal to one another. The
maximum of the probability density ψ(0)
n (r, θ) is attained at radius
r2
n = 2n

¯h
eB

(11.23)
But this means that a given area πR2 ≫|¯h/eB| will contain a number of states N given by
N = πR2

eB
2π¯h

(11.24)
Hence the density of states of the ﬁrst Landau level for magnetic ﬁeld B > 0 is given by
nB =
N
πR2 = eB
2π¯h
(11.25)
This is a classic result, you may ﬁnd in Landau and Lifschitz. In a higher Landau level, the wave
function will have an extra factor of ¯zn+. But for given, ﬁnite n+, this extra factor will not modify
the asymptotic behavior of the density of states found in the lowest Landau level, so that the
formula (11.25) is valid for any Landau level.
11.4
The classical Hall eﬀect
The set-up of the Hall eﬀect (classical or quantum) is a conductor subject to an electric ﬁeld E
and a perpendicular magnetic ﬁeld B. For zero magnetic ﬁeld, the electric ﬁeld creates an electric
current j which is parallel to E. The zero magnetic ﬁeld conductivity is denotes σ0 and relates
j = σ0E. If the current is produced by individual charge carriers such as electrons, then the current
is given by the density of carriers n and their electric charge e by j = nev.
When the magnetic ﬁeld is turned on, charge carriers are deviated and produce an electric
current, or Hall current, transverse to the electric ﬁeld.
The strength of this current may be
obtained from the Lorentz force formula,
me
dv
dt = eE + ev × B −ne2
meσ0
v
(11.26)
145

Here, me is the electron mass and v its velocity. The last term account for the dissipative processes
which lead to Ohm’s law, and we have deﬁned the relevant dissipation constant such that σ0 is the
conductivity in the absence of magnetic ﬁelds. In the stationary regime, we have a ﬂow of charge
carriers with constant velocity, so that dv/dt = 0, and we thus obtain,
nev = j = σ0 (E + v × B)
(11.27)
Eliminating v in favor of j gives,
j = σ0

E + 1
ne j × B

(11.28)
Choosing the z-axis along B with E in the xy-plane, the equation becomes,
jx
=
σ0Ex + σ0B
ne jy
jy
=
σ0Ey −σ0B
ne jx
(11.29)
Inverting this relation to get the resistivity as a function of the magnetic ﬁeld,
 Ex
Ey

=
 ρxx
ρxy
ρyx
ρyy
  jx
jy

RL = ρxx = ρyy
=
1
σ0
RH = ρxy = −ρyx
=
B
ne
(11.30)
Remarkably, the oﬀ-diagonal resistivity is independent of the normal conductivity and involves only
the density of carriers, besides fundamental constants and the magnetic ﬁeld itself.
11.5
The quantum Hall eﬀect
Although the above picture of the Hall eﬀect is applicable in the regime at room temperature and
for a large class of materials, there are special experimental settings where the Hall resistivity ρxy
is not just a linear function of B, but exhibits remarkable structure.9
The experimental conditions for the Quantum Hall Eﬀect (QHE) are as follows,
• A layer of electrons is trapped at the interface of two semi-conductors (a hetero-junction);
• The system is cooled to temperatures in the milli-Kelvin range;
• The system is very pure.
9There is extensive literature on both the integer and fractional quantum Hall eﬀects; a good source
with both experimental and theoretical contributions is in The Quantum Hall Eﬀect, R.E. Prange and S.M.
Girvin, Eds, Springer 1990.
146

Figure 11: Schematic representation of the Hall and regular conductivity in the integer
quantum Hall eﬀect. (from R.E. Prange in The quantum Hall eﬀect, Springer 1990).
A schematic rendition of the experimental observations characteristic of the (integer) Quantum
Hall Eﬀect (or QHE) is given in Figure 11. As the magnetic ﬁeld B is varied, it is observed that the
Hall resistivity RH = ρxy does not follow a linear law, as would be expected from the discussion of
the classical Hall eﬀect, but instead exhibits plateaux on which the resistivity stays constant for a
range of variations of B. Moreover, the values of the resistivity at the plateaux is observed to be
ρxy = 2π¯h
e2 × integer
(11.31)
How can this phenomenon be explained ?
The key is to recall the density of carriers in a Landau level, given by
nB = eB
2π¯h
(11.32)
The contribution to the conductivity of one Landau level is then obtained by including only the
density of states of one Landau level n = nB, for which we get
(ρxy)−1

1 Landau Level
= nBe
B
= e2
2π¯h
(11.33)
Thus, the eﬀect may be attributed to the contribution of ﬁlled Landau Levels, in which electrons
behave eﬀectively independently. Exactly why an entire Landau Level contributes, and not say 1.5
Landau Levels would require a more detailed discussion of which states are localized and which
states are extended, and would require analysis of band structure and so on.
147

The fundamental unit of 2-dimensional resistivity may be readily evaluated, using ¯h = 1.05457×
10−34Js and e = 1.60218 × 10−19C, and we ﬁnd,
2π¯h
e2
=
25, 812.63 Ω
(11.34)
The units work out as follows, Js/C2 = (J/C)(s/C) = V/A = Ω. Note that, by comparison, the
expression for the ﬁne structure constant is
α =
e2
4πǫ0¯hc =
1
137.04
(11.35)
Thus, we have, alternatively,
2π¯h
e2
=
1
2ǫ0cα
(11.36)
Measurement of the Hall resistivity now gives the most accurate determination of this combination
of the fundamental constants e and ¯h.
The actual experimental results are more complicated, and also even more interesting.
In
Figure 12, it is the Hall resistivity ρxy which is shown as a function of B directly. The resistivity is
expressed as a dimensionless coeﬃcient 1/ν times the fundamental unit of 2-dimensonal resistivity
2π¯h/e2, as follows,
ρxy = 1
ν × 2π¯h
e2
(11.37)
In the vicinity of the ν = 1 plateau, more plateaux are discovered. It turns out (as you can see
from Figure 12) that ν appears to always be a rational number whose denominator is an odd
integer. This is the Fractionally Quantum Hall Eﬀect (FQHE). The dynamics responsible for the
FQHE is no longer that of independent electrons, but now results from collective eﬀects, which are
fascinating, but into which we cannot go here.
It is nonetheless possible to make direct contact with the structure of Landau levels as follows.
We now consider the system to be governed by N electrons, subject to the external magnetic ﬁeld
B and to their mutual repulsive Coulomb interactions. It is impossible to solve such a system
exactly, but Robert Laughlin proposed an educated guess for the wave function of such a system
of N electrons. We denote the planar coordinates of each electron by the complex numbers zi,
i = 1, · · · , N. First of all, all of these electrons are assumed to be in the lowest Landau level, so
their wave function must be of the form, (we take eB > 0),
f(z1, · · · , zN) exp
(
−eB
2¯h
N
X
i=1
|zi|2
)
(11.38)
where f is a holomorphic function of all the zi. Now in a strong magnetic ﬁeld, spins up and down of
the electron will be split, so the lowest energy states will have all the spins aligned. This makes the
states symmetric in the spin quantum numbers, and Fermi-Dirac statistics then requires that the
148

Figure 12: Actual experimental results exhibiting integer and fractional quantum Hall eﬀects.
(from A.M. Chang in The quantum Hall eﬀect, Springer 1990).
149

wave function of the N electrons be anti-symmetric under the interchange of any two coordinates
zi and zj for j ̸= i. The following wave functions will always be anti-symmetric in this way,
Y
i<j
(zi −zj)m × exp
(
−eB
2¯h
N
X
i=1
|zi|2
)
(11.39)
whenever m is an odd positive integer. The density of states is reduced to ν = 1/m which gives an
explanation why only odd denominators occur.
150

12
Scattering Theory
Bound state perturbation theory, discussed in the preceding chapter, has allowed us to understand
the energy shifts and modiﬁcations to quantum states as corrections to the Hamiltonian are succes-
sively taken into account. Various outcomes of calculations may be compared with the outcomes of
various experiments, and used to check the theory. But, the parameters of the bound state problem
are essentially ﬁxed: we studied various discrete energy levels of various systems. The one way in
which we can bring in external parameters is by applying external electric and/or magnetic ﬁelds.
Perturbation theory of the continuous spectrum is physically even more important. The reason
is that in the continuous spectrum, the momentum or the energy of the incoming “probe” can
always be adjusted at will, and thus automatically provides us with a tunable free parameter. This
is called scattering theory. External electric and/or magnetic ﬁelds may also be present and will
then allow us to probe the system with even more parameters and thus with even more detail. The
free momentum of the incoming probe allows us to compare the outcome of theoretical calculations
with the outcome of experiments for entire ranges of momentum and energy values. We can now
compare entire functions of momentum as instead of isolated data points in the case of the discrete
spectrum. Furthermore, scattering allows us to introduce supplementary energy into the system,
and thus to access a range of excitations of the system beyond its ground state.
A large class of scattering problems may be approximated by scattering in the presence of a
time-independent or static source. In two body problems, this may be done by going to the center
of mass frame, and reducing the problem to a one-body problem in a potential, using translation
invariance.
Fixed-target experiments are one example of such scattering processes. They are the oldest
experimental set-ups for the systematic study of scattering. Here, a light probe (usually an electron,
proton, neutron or neutrino) is used and scattered oﬀa heavy target which is considered ﬁxed, in
as much as recoil eﬀects of the target are negligible. An alternative experimental set-up is provided
by particle colliders. In a collider experiment, two beams traveling in opposite directions are made
to interact in a localized interaction region. Most frequently, the beams are symmetric, in the
sense that they are composed of particle of the same mass and adjusted to have the same energy.
The most popular set-ups are e+e−colliders (SLAC), and p+p−colliders (CERN). The resulting
scattering products will then be evenly distributed in a 4π solid angle.10
At high energies E (much larger than the mass M of the target), (symmetric) collider experi-
ments are much more eﬃcient, due to relativistic eﬀects. This is because what really matters for
the strength of the interaction is the center of mass energy of the process. In a collider experiment,
two beams of opposite momenta and equal energy E produce a center of mass energy Ecm = 2E.
But in a ﬁxed target experiment, with a beam of particles of mass m and energy E incident on a
target of particles of mass M, the center of mass energy is given by E2
cm = 2EMc2 + (M2 −m2)c4,
10For certain experiments, there is actually an advantage to having an asymmetric set-up, with particle of
unequal masses and/or unequal energies. This set-up will produce scattering products carrying a momentum
peaked around a deﬁnite forward momentum which allows experimentalists to use a detector of less than 4π
solid angle coverage.
151

or Ecm ∼
√
2EMc2 for high energy. The linear energy dependence for a collider wins over the
square root dependence of the ﬁxed target experiment.
Again due to relativistic eﬀects, the number of particles in a scattering process need not be
conserved. Any interaction causes an acceleration, and if the probe particle carries electric charge,
acceleration will read to electro-magnetic radiation. Quantum mechanically, the interacting charged
particle emits a photon. The photon was not part of either the incoming probe or of the target,
and it as not hidden inside these bodies either: the photon is genuinely a newly created particle,
which did not exist in the system prior to interaction. Generally the number of particles may be
changed during the course of interactions, and this eﬀect is not limited to photons. For example,
in e+e−colliders, an interaction may cause the e+e−to annihilate and be transformed purely into
energy out of which new particles may be created, such as quarks, proton and anti-protons, W ± or
Z’s or even again e+e−pairs. These eﬀects are all relativistic, and their quantum description will
properly require the formalism and tools of quantum ﬁeld theory.
In this chapter, we shall limit attention to the non-relativistic case where the number of particles
is conserved. In this set-up, the incoming probe will merely be deﬂected. This case is often referred
to as potential scattering.
12.1
Potential Scattering
The fundamental problem of potential scattering is the resolution of the continuous part of the
spectrum of the Hamiltonian,
H = H0 + λH1
(12.1)
Here, H0 is the unperturbed Hamiltonian, whose solutions are assumed to be known exactly, H1
is the perturbing Hamiltonian, and λ is a small parameter, in terms of which perturbation theory
will be organized. The eigenstates of H0 will be denoted by |φk⟩, and obey
H0|φk⟩= E|φk⟩
E = ¯h2k2
2m
(12.2)
Here and later, it will be convenient to parametrized the energy eigenvalue E by the wave vector k
and the mass m. We then seek to solve for the eigenstates of the full Hamiltonian H at the same
energy eigenvalue E,
(H0 + λH1)|ψk⟩= E|ψk⟩
(12.3)
The rationale for using the same energy eigenvalue is that if H0 has a continuous spectrum in
the vicinity of energy E, then a small (regular) perturbation on the spectrum should produce a
continuous functional dependence on λ (see the discussion in bound state perturbation theory), so
that also H should admit a continuous spectrum in the vicinity of E. Possible exceptions would
include the case where E is an endpoint of the spectrum of H0, such as in the endpoint of an energy
band, in which case a more detailed study will be required.
152

To solve (12.3) perturbatively, we move the perturbative correction piece to the right hand side
of the equation,
(H0 −E)|ψk⟩= −λH1|ψk⟩
(12.4)
The operator H0 −E is not quite invertible, and precisely has the states |φk⟩for its null-space. In
the case of bound state perturbation theory, we remedied this situation by inverting H0 −E on
the subspace of the Hilbert space orthogonal to the its null-space. This was possible because the
null-space consisted of discrete states. In the case of the continuous spectrum, the natural way of
dealing with the null-space is as follows. We add a small imaginary part iε to the energy E. Since
H0 is self-adjoint, all its eigenvalues are real, and thus the modiﬁed operator H0 −E ± iε will now
be invertible, although the eigenvalue corresponding to states |φk⟩in the null-space will be tiny.
This procedure naturally produces two solutions to (12.3) and (12.4), given by
|ψ±
k ⟩= |φk⟩−
λ
H0 −E ∓iεH1|ψ±
k ⟩
ε > 0
(12.5)
This equation is known as the Lippmann-Schwinger equation. (Later on, we shall use an even more
drastic extension of this equation and let z = E ± iε take arbitrary values in the complex plane.)
Although ε was introduced here as a ﬁnite real positive number, it is understood that one must
take the limit ε →0. To understand this iε prescription in more detail, it will be helpful to study
its mathematical properties in some detail.
12.2
The iε prescription
The iε prescription is given by the limit
lim
ε→0
1
x −iε
x ∈R, ε > 0
(12.6)
should be understood as a generalized function (or distribution) similar to the Dirac δ-function. In
fact, it contains a δ-function, as may be seen by separating its real and imaginary parts,
1
x −iε =
x
x2 + ε2 +
iε
x2 + ε2
(12.7)
The limit of the ﬁrst term is, by deﬁnition, the sl principal value prescription PV(1/x), while the
limit of the second may be found by integrating it against a smooth test function f(x),
lim
ε→0
Z
R
dx
iε
x2 + ε2 f(x) = lim
ε→0
Z
R
dx
i
x2 + 1f(εx) = iπf(0)
(12.8)
Hence the limit of the second term is given by iπδ(x). Putting all together, we obtain,
lim
ε→0
1
x −iε = PV 1
x + iπδ(x)
(12.9)
This clearly demonstrates that the limit is a generalized function. It is customary when writing
the iε prescription to simply omit the limε→0 symbol in front.
153

12.3
The free particle propagator
In almost all cases,11 H0 will be the Hamiltonian for a free probe of mass m,
H0 = P2
2m
(12.10)
where P is the momentum operator. The eigenstates are |φk⟩= |k⟩with energy E = ¯h2k2/2m,
with wave function,
φk(x) = ⟨x|k⟩=
eik·x
(2π)3/2
(12.11)
The normalization has been chosen so that ⟨k′|k⟩= δ(3)(k′ −k), which may be veriﬁed by inserting
a complete set of position eigenstates
Z
d3x⟨k′|x⟩⟨x|k⟩= δ(3)(k′ −k)
(12.12)
In the position basis the Lippmann-Schwinger equation becomes,
⟨x|ψ±
k ⟩= ⟨x|φk⟩+ λ
Z
d3y ⟨x|
1
E −H0 ± iε|y⟩⟨y|H1|ψ±
k ⟩
(12.13)
One deﬁned the propagator or Green functions for the free non-relativistic particle as follows,
G±(x, y; k2) = ¯h2
2m⟨x|
1
E −H0 ± iε|y⟩
(12.14)
The factor of ¯h2/2m has been pulled out for later convenience and to make the propagator depend
only on k2, but not on m. Since H0 is diagonal in the momentum basis |ℓ⟩, the propagator may be
computed by inserting a complete set of momentum eigenstates,
G±(x, y; k2) =
Z
d3l ⟨x|
1
k2 −l2 ± iε|l⟩⟨l|y⟩=
Z
d3l
(2π)3
eil·(x−y)
k2 −l2 ± iε
(12.15)
One may either evaluate this Fourier integral directly, or use the fact that G± satsiﬁes,
(∆+ k2)G±(x, y; k2) = δ(3)(x −y)
(12.16)
For k = 0, G± is just the Coulomb equation for a δ-function charge with solution
G±(x, y; 0) = −1
4πr
r = |x −y|
(12.17)
11One notable exception is the Coulomb problem for which the exact solution is known, abeit complicated.
154

The factor of 4π gives the correct normalization for the δ-function. For k2 ̸= 0, rotation invariance
of the Fourier integral shows that G± depends only on the scalars k2 and r, so that, away from
x = y, G± must satisfy the radial equation
1
r2
∂
∂r

r2 ∂G±
∂r

+ k2G± = 0
(12.18)
where k = |k|. Using dimensional analysis, we must have G±(x, y; k2) = G±(x, y; 0)f(kr), where
f(kr) is a dimensionless function of the dimensionless combination kr. Substitution into the above
radial diﬀerential equations shows that
f ′′(kr) + f(kr) = 0
(12.19)
whose solutions are f(kr) = e±ikr. Putting all together, we obtain,
G±(x, y; k2) = −e±ik|x−y|
4π|x −y|
(12.20)
Note that, since the exponentials equal 1 when x = y, this result is automatically properly nor-
malized with respect to the δ-function source.
12.4
The Lippmann-Schwinger equation in position space
In many cases of interest, the perturbing Hamiltonian H1 is local in position space and actually
given by a potential V (x),
⟨x|H1|y⟩= δ(3)(x −y)V (x)
(12.21)
In terms of the incoming wave function φk(x) and the full wave function ψk(x), deﬁned by
⟨x|φk⟩= φk(x)
⟨x|ψ±
k ⟩= ψ±
k (x)
(12.22)
the Lippmann-Schwinger equation takes the form,
ψ±
k (x) = φk(x) +
Z
d3y G±(x, y; k2)U(y)ψ±
k (y)
(12.23)
where we have used the abbreviation
U(y) = 2mλ
¯h2 V (y)
(12.24)
so that U is automatically of order λ, and thus small. If we symbolically denote this notation by
ψ = φ + GUψ
(12.25)
then the solution may be obtained in a power series in λ by iterating the equation, i.e. substituting
the left hand side into the right hand side repeatedly. At the ﬁrst iteration, we obtain,
ψ = φ + GUφ + GUGUψ
(12.26)
155

and the solution to all orders is
ψ
=
φ + GUφ + GUGUφ + · · ·
=
φ +
∞
X
n=1
(GU)nφ
(12.27)
The interpretation of the ﬁrst term is free propagation; of the second term is a single interaction
with the potential; of the subsequent terms of higher order exchanges with the potential.
12.5
Short range versus long range V and massless particles
The basic assumption in scattering theory is that the potential V (x) tends to zero as |x| →∞. It
is under this condition that the above description of the scattering process oﬀa target really makes
sense. Namely, in the far past, we have a wave (or more physically, a wave packet) incoming from
spatial inﬁnity where its behavior is that of a free particle. At ﬁnite time, and a ﬁnite distance
away from the target, the particle interacts with the target, and then again moves out to spatial
inﬁnity at far future times, again behaving as a free particle.
But even if V (x) →0 as r = |x| →∞, the potential V may tend to zero at diﬀerent possible
rates. One distinguishes the following two behaviors,
• Short ranged: the potential V vanishes at least exponentially V (x) ∼e−r/ξ with distance r
outside a bounded region of space; this includes the case where V vanishes identically outside
a bounded region of space of linear size ξ. The smallest such ξ > 0 is called the range of the
potential. One example is the Yukawa potential, given by V (x) ∼e−r/ξ/r.
• Long Ranged: the potential V vanishes like a power V (x) ∼r−α of distance where α > 0
is called the exponent. One example is the Coulomb potential V (x) ∼1/r, for which the
exponent is α = 1.
The reason for this distinction has a deep physical underpinning. In relativistic quantum theories,
interactions cannot be instantaneous, and must be mediated by the exchange of signals that travel at
the speed of light or slower. In fact, these signals are particles themselves. In relativistic quantum
ﬁeld theory, the interaction potential may be obtained from summing up the contributions of
repeated exchanges of particles. If the mediator of the interaction is massless, then the resulting
interaction potential in the non-relativistic limit will always be long-ranged, while if the particle is
massive, the interaction potential will be short ranged. The range of the interaction is related to
the mass via the formula
ξ = ¯h
mc
(12.28)
namely, it is the Compton wave length.
The four forces of Nature behave as follows,
• Gravitational: long-ranged, since it also obeys the Coulomb potential; the mediator of the
gravity is the massless graviton.
156

• Electro-magnetic: long-ranged; the mediator is the massless photon.
• Weak interactions: short-ranged; the mediator are the massive W ± and Z bosons with masses
on the order of 80 GeV/c2 and 90 GeV/c2 respectively.
• Strong interactions: short-ranged in the following sense. Although the mediator of the strong
force in QCD is the massless gluon, conﬁnement makes the range of the strong interactions
short, the scale being set by the mass of the lightest strongly interacting particle, namely the
π± and π0, whose masses are approximately 135 MeV/c2.
12.6
The wave-function solution far from the target
In practice, one is interested in observing the scattering products far from the target, i.e. far from
the core of the potential. In this limit, the equations simplify considerably, and will yield physical
insight into the scattering process. The starting point is the integral equation (12.23), in the limit
of large r = |x| ≫|y|. We use the approximation,
|x −y| =
q
(x −y)2 = r −x · y
r
+ O(y2)
(12.29)
The propagator the becomes (we retain only the propagator G = G+),
G(x, y; k2) = −eikr
4πr × e−ik′·y
k′ = kx
r
(12.30)
The Lippmann-Schwnger equation is then solved by the following form of the wave function,
ψk(x) =
1
(2π)3/2
(
eik·x −eikr
r f(k′, k)
)
(12.31)
where the function f is given by
f(k′, k) = −(2π)3/2
4π
Z
d3y e−ik′·yU(y)ψk(y)
(12.32)
Note that from the deﬁnition of f, we may readily read oﬀthat its dimension is a length, a remark
that will come in very useful later.
12.7
Calculation of the cross section
Clearly, one of the key quantities we are going to be interested in is the intensity of the outgoing
ﬂux of particles, as a function of k and k′. The corresponding physical quantity is the cross section.
To evaluate it, we begin by obtaining a formula for the probability density ρ and for the probability
current density j,
ρ(t, x)
=
ψ∗(t, x)ψ(t, x)
j(t, x)
=
−i
2m

ψ∗(t, x)∇ψ(t, x) −ψ(t, x)∇ψ∗(t, x)

(12.33)
157

Using the time-dependent Schr¨odinger equation,
i¯h∂ψ
∂t = −¯h2
2m∆ψ + V ψ
(12.34)
one shows conservation of this current,
∂ρ
∂t + ∇· j = 0
(12.35)
The global form of the conservation of probability equation is that the time variation of the total
probability pv in some volume v plus the ﬂux φ∂v through the boundary ∂v of volume v vanishes,
dpv
dt + φv = 0
(12.36)
where we have
pv =
Z
v
d3xρ(t, x)
φ∂v =
I
∂v
d2S · j(t, x)
(12.37)
A scattering process is considered to be a steady state process in which some of the incoming ﬂux
due to the plane wave eik·x is scattered oﬀinto a spherical wave. The diﬀerential cross section
gives a quantitative evaluation of the strength of this scattering process, as a function of angle of
the outgoing beam.
Using the deﬁnition of the probability current, we readily ﬁnd that the incoming probability
current density is given by the velocity v of the particles in the incoming planar wave beam,
jincident =
v
(2π)3
(12.38)
where mv = ¯hk. The diﬀerential cross section is obtained by analyzing the probability ﬂow of the
outgoing wave as a function of angle, far away from the interaction region. Thus, we consider the
ﬂux through an inﬁnitesimal surface element d2S, at a point x which is a long distance r = |x|
away from the target. Fixing the solid angle to be dΩ, we have
d2S = r2dΩx
r
(12.39)
The ﬂux through the solid angle dΩis then given by
dφ
dΩ
=
d2S · jscattered
=
lim
r→∞r2 x
r · jscattered(x)
(12.40)
The current density is obtained by substituting (12.31) into the general expression, and is given by
jscattered
=
−i
2m
f(k′, k)∗
(2π)3
e−ikr
r
∇
 
f(k′, k)eikr
r
!
+ c.c.
(12.41)
158

where c.c. stands for the complex conjugate of the preceding term. In carrying out the ∇derivative
with respect to the variable x, several terms emerge. In view of the derivatives
∇i
1
r

= −xi
r3
∇i
 
xj
r
!
= r2δj
i −xjxi
r3
(12.42)
we see that the ∇derivatives of the 1/r factor and of the outgoing momentum k′ = kx/r will lead
to terms behaving like 1/r3 in j which will not contribute to the diﬀerential ﬂux dφ/dΩsince this
involves taking the large r limit. The only term that contributes is thus obtained by diﬀerentiating
the exponential factor, which gives,
jscattered ∼
k′
mr2
|f(k′, k)|2
(2π)3
(12.43)
The scattered diﬀerential ﬂux is then found to be
dφ
dΩ=
|v|
(2π)3 |f(k′, k)|2
(12.44)
The diﬀerential cross section is deﬁned as the ratio of the diﬀerential ﬂux by the total current
density. The factors of
|v|
(2π)3 cancel in both quantities and we are left with
dσ
dΩ= |f(k′, k)|2
(12.45)
Note that, because f has dimensions of length, the diﬀerential cross section has dimensions of
length square. The physical interpretation is that the cross section represents an eﬀective aspect
area for the target. This interpretation will be borne out in some simple examples that we shall
study. The total cross section of the process is the integral of the diﬀerential cross section over the
full range 4π of solid angle,
σ =
Z
4π
dΩdσ
dΩ
(12.46)
It again has dimension of length square.
A ﬁnal remark is in order. In evaluating the incoming and outgoing ﬂuxes, we seem to have
neglected the cross term between the incoming wave and the outgoing one. While this term would
contribute to the current density at any ﬁnite distance x, in the limit of large r, its oscillatory
behavior, given by eik·x−ikr, is responsible for the vanishing of its contribution to the diﬀerential
ﬂux.
12.8
The Born approximation
The Born approximation consists in retaining only a ﬁnite number of terms in the expansion in
powers of λ. The ﬁrst Born term is the one linear in λ, i.e. linear in the potential V . It is obtained
by setting ψ±
k (x) = φk(x) in the expression for f(k′, k) in (12.31), which yields,
f (1)(k′, k) = −1
4π
Z
d3y e−i(k′−k)·y U(y)
(12.47)
159

Its form is very simple, since f (1)(k′, k) is proportional to the Fourier transform of the potential
evaluated on k′ −bk which is proportional to the momentum transfer q = ¯h(k′ −k) of the process.
The ﬁrst Born term for any spherically symmetric potential U(r) may be computed as follows.
The starting point is the integral representation, which we express is spherical coordinates deﬁned
with respect to the incoming momentum direction k. We ﬁnd,
f (1)(q)
=
−1
4π
Z 2π
0
dφ
Z π
0
dθ sin θ
Z ∞
0
dr r2U(r) e−iqr cos θ
=
−1
q
Z ∞
0
dr r U(r) sin(qr)
(12.48)
Here, we use the notation q = |q|.
12.8.1
The case of the Coulomb potential
For the Coulomb potential, we have
U(r) = 2m
¯h2 V (r) = −2mZe2
¯h2
1
r
(12.49)
The ﬁrst Born term is given by
f (1)(k′, k) = mZe2
2π¯h2
Z
d3ye−i(k′−bk)·y
|y|
(12.50)
It is a standard result that
Z
d3yeik·y
|y| = 4π
k2
(12.51)
To derive it, note ﬁrst that the integral depends only on k2 in view of rotation invariance of the factor
d3y/|y|, and that it manifestly scales as 1/k2. Finally the constant factor may be determined by
multiplying both sides by q2, using the fact that q2 = −∆in the momentum space representation,
and the fact that ∆(1/|y|) = 4πδ(3)(y). Collecting all terms, we have,
f (1)(k′, k) =
2mZe2
¯h2(k′ −k)2
(12.52)
If we deﬁne the angle between k′ and k to be θ, and use the fact that |k′| = |k|, we obtain,
(k′ −k)2 = 4k2 sin2 θ
2
(12.53)
As a result, the cross section is given by
dσ
dΩ=
f (1)(k′, k)

2 = m2Z2e4
4q4 sin4 θ
2
(12.54)
160

Note that the scale of the cross section is set by the momentum transfer q, and the mass.
This formula exhibits singular behavior for forward scattering when θ ∼0. In fact, if one tried
to integrate this formula to get the total cross section, one would ﬁnd that it diverges because
of the singularity at θ = 0.
Since this divergence occurs for vanishing momentum transfer, it
amounts to an infrared (IR) problem. The fundamental cause for this problem is the fact that
the photon, which is the particle that mediates the Coulomb interaction, is massless. Massless
particles can be produced with very little momentum and energy. Thus, it is really not possible to
distinguish between a charged particle (say and electron) state and that state with an added very
low energy photon. Thus, the problem of Coulomb scattering is not strictly speaking one in which
the number of photons is conserved. A proper calculation would really include the eﬀects of this
photon production, but this requires quantum ﬁeld theory, and is beyond the scope of this course.
In practice, one does not necessarily scatter a charged particle oﬀa target that exhibits Coulomb
potential behavior all the way out to spatial inﬁnity. For example, if one scatters oﬀan electrically
neutral atom, then the cloud of electrons eﬀectively shields the Coulomb potential of the nucleus.
Beyond a distance on the scale of the size of the atom, the electric potential will in fact fall oﬀ
exponentially, since the electron wave functions do so in the Coulomb problem.
Finally, since the ﬁrst Born term was computed in perturbation theory, we cannot physically
take seriously its eﬀects if these become large. Thus, the Rutherford formula for diﬀerential cross
section should be trusted only for angles θ away from being to close to 0.
12.8.2
The case of the Yukawa potential
The typical potential for a short ranged potential is the Yukawa potential, given by
U(r) = −U0
e−µr
r
(12.55)
where 1/µ is the range of the potential. The ﬁrst Born term is then found to be
f (1)(q) = 2mU0
q2 + µ2
(12.56)
The ﬁnite range of this potential now makes its diﬀerential cross section ﬁnite at θ = 0, and this
eﬀect may be interpreted as the fact that the Yukawa potential arises fundamentally from massive
particle exchange.
12.9
The optical Theorem
A particularly simple and useful relation holds between the total cross section and the forward
scattering amplitude, which is referred to as the optical theorem (for historical reasons).
The
relation is expressed as follows,
σtot =
Z
4π
dΩ
 dσ
dΩ

= 4π
k Imf(k, k)
(12.57)
161

The fact that on the right hand side, the scattering amplitude is being evaluated for equal initial
and ﬁnal momenta is responsible for the name forward scattering.
To prove this result, we start from the form of the full wave function ψ in terms of the incoming
free wave function φ, and the scattered wave function χ, related by
ψ = φ + χ
(12.58)
The probability current, integrated across a large sphere S must vanish for this stationary problem
when we take the free part φ or the full wave function ψ, leading to the following equations,
I
S
d2S · Im(φ∗∇φ) =
I
S
d2S · Im(ψ∗∇ψ) = 0
(12.59)
The total cross section, on the other hand, is given by the integral of the probability current for
the scattered wave function χ, as follows,
m|v|
(2π)3 σtot = Im
I
S
d2S · χ∗∇χ
(12.60)
Finally, we use the identity
Im(ψ∗∇ψ) = Im(−φ∗∇φ + ψ∗∇φ −φ∇ψ∗+ χ∗∇χ)
(12.61)
Putting all together, and using Stokes’ theorem, we have,
Im
I
S
d2S · χ∗∇χ = Im
Z
d3x · (ψ∆φ∗−φ∗∆ψ)
(12.62)
We now use the Schr¨odinger equation for φ and ψ respectively,
∆φ
=
−2mEφ
∆ψ
=
−2mEψ + 2mV
(12.63)
The terms involving E cancel out, and we are left with
k σtot = 2m(2π)3Im
Z
d3x φV ψ∗= 4πImf(k, k)
(12.64)
The advantage of this formula is that the forward scattering amplitude is often easier to evaluate
than the full amplitude which then requires squaring to get the cross section and integrating over
all solid angles to get the total cross section.
12.10
Spherical potentials and partial wave expansion
Many potentials of interest, such as the Coulomb and Yukawa potentials, have spherical symmetry,
and only depend on a radial coordinate r, but not on the spherical angles θ and φ. The spherical
162

symmetry of the problem then allows one to decouple the system into partial waves, producing
conceptual and practical simpliﬁcations.
We consider a Hamiltonian of the form, expressed in coordinate representation,
H = −¯h2
2m∆+ V (r)
(12.65)
We assume that V (r) →0 as r →∞. In order to avoid trailing factors of ¯h and m, we express the
Schr¨odinger equation in terms of the following variables instead,
U(r) = 2m
¯h2 V (r)
E = ¯h2k2
2m
(12.66)
where k is a real wave number variable. Spherical symmetry now implies that L2 and Lz commute
with H, so that a basis of eigenfunctions ψℓm(r) of H may be chosen in a basis where L2 and Lz
are diagonal,
ψℓm(r) = Rℓ(r) Y m
ℓ(θ, φ)
(12.67)
The Schr¨odinger equation then becomes,
R′′
ℓ(r) + 2
r R′
ℓ(r) −ℓ(ℓ+ 1)
r2
Rℓ(r) + k2Rℓ(r) −U(r)Rℓ(r) = 0
(12.68)
It is this equation that we seek to solve perturbatively in powers of U.
12.10.1
Bessel Functions
For U = 0, (12.68) is the diﬀerential equation that deﬁned (spherical) Bessel functions. The two
linearly independent solutions of this second order diﬀerential equation are denoted by12
R(1)
ℓ(r) = jℓ(kr)
regular as r →0
R(2)
ℓ(r) = hℓ(kr)
singular as r →0
(12.69)
These functions admit convenient integral representations, and we have
jℓ(ρ)
=
ρℓ
2ℓ+1ℓ!
Z 1
−1
dz eiρz(1 −z2)ℓ
hℓ(ρ)
=
−ρℓ
2ℓℓ!
Z 1+i∞
1
dz eiρz(1 −z2)ℓ
(12.70)
12Note that if jℓis a solution, then so is j−1−ℓ. For ℓnot an integer, these solutions are linearly independent,
but for integer ℓthese two solutions are proportional to one another, however, and cannot be used as a basis
for both linearly independent solutions.
163

For real values of ρ, the function jℓ(ρ) is real, but hℓ(ρ) is complex. The asymptotic values of these
functions are as follows. As ρ →0, we have,
jℓ(ρ)
∼
ρℓ
(2ℓ+ 1)!!
hℓ(ρ)
∼
−i(2ℓ−1)!!
ρℓ+1
(12.71)
while for ρ →∞, we have,
jℓ(ρ)
∼
1
ρ cos

ρ −π
2 (ℓ+ 1)

hℓ(ρ)
∼
−i
ρ eiρ−iπℓ/2
(12.72)
Note that the function hℓ(ρ) is sometimes denoted as h(1)
ℓ(ρ), while h(2)(ρ) = (h(1)(ρ∗))∗.
12.10.2
Partial wave expansion of wave functions
The free wave solution φ(x) admits an expansion in terms of jℓ, given as follows,
eik·r = eikr cos θ =
∞
X
ℓ=0
(i)ℓ(2ℓ+ 1)jℓ(kr)Pℓ(cos θ)
(12.73)
where Pℓ(cos θ) are the Legendre polynomials, familiar from the structure of spherical harmonics.
More generally now, we can express any wave function for the spherical potential problem in such
an expansion in terms of spherical harmonics,
φk(r)
=
1
(2π)3/2
∞
X
ℓ=0
(i)ℓ(2ℓ+ 1)jℓ(kr)Pℓ(cos θ)
ψk(r)
=
1
(2π)3/2
∞
X
ℓ=0
(i)ℓ(2ℓ+ 1)Rℓ(kr)Pℓ(cos θ)
(12.74)
Note that the expansion involves only the spherical harmonics Y 0
ℓ. The reason is that while the
Schr¨odinger equation is invariant under all rotations, the initial conditions (namely given by the
incoming plane wave) break this symmetry to rotations around the incoming wave vector k only.
Thus, the wave functions can have no dependence on φ by symmetry, which prevents the occurrence
of Y m
ℓ
for m ̸= 0.
Instead of substituting these expressions into the integral equation we had derived earlier, it
turns out to be much more convenient to work from the initial Schr¨odinger equation, which we
express as follows,
 d2
dr2 + 2
r
d
dr −ℓ(ℓ+ 1)
r2
+ k2

Rℓ(r) = U(r)Rℓ(r)
(12.75)
164

Now, we know the solution jℓ(kr) for U = 0, and consider the full solution in a perturbative
expansion in U. We set
Rℓ(r) = jℓ(kr) + χℓ(r)
(12.76)
To solve this problem, we deﬁne the Green function for the 1-dimensional diﬀerential operator as
follows,
 d2
dr2 + 2
r
d
dr −ℓ(ℓ+ 1)
r2
+ k2

Gℓ(r, r′) = 1
r2 δ(r −r′)
(12.77)
The reason for the factor of 1/r2 on the rhs is that the integration measure is d3r = r2dr sin θdθ dφ,
and the δ-function in spherical coordinates thus inherits a compensating 1/r2 factor. In terms of
this Green function, the integral equation for Rℓbecomes,
Rℓ(r) = jℓ(kr) +
Z ∞
0
dr′ (r′)2Gℓ(r, r′)U(r′)Rℓ(r′)
(12.78)
This integral equation may again be solved recursively.
12.10.3
Calculating the radial Green function
There is a standard, and very powerful, method for calculating the Green function for linear diﬀer-
ential equations of second order in one variable. The method proceeds a s follows. When r ̸= r′, the
equation is just the homogeneous one, for which we know the two linearly independent solutions
jℓ(kr) and hℓ(kr). At r = r′, the presence of a δ-function requires the derivative in r of Gℓ(r, r′) to
be discontinuous, and thus the function Gℓ(r, r′) itself to be continuous. This may be achieved by
using diﬀerent linear combinations of the functions jℓand hℓfor r < r′ and for r > r′.
We shall choose these linear combinations such that Gℓ(r, r′) is automatically regular at r = 0,
and has the correct eikr behavior as r →∞. The function jℓ(kr) is regular at r = 0, while the
function hℓ(kr) behaves like eikr as r →∞. Therefore, we use the following form for Gℓ(r, r′),
Gℓ(r, r′) =
 Cℓjℓ(kr)hℓ(kr′)
r < r′
Cℓhℓ(kr)jℓ(kr′)
r′ < r
(12.79)
This expression guarantees continuity across r = r′ from the outset. We shall now recast this form
in a more helpful form using the Heaviside step function θ(x). It is deﬁned by
θ(x) =
 1
x > 0
0
x < 0
(12.80)
Its derivative is the δ-function, θ′(x) = δ(x). Using the Heaviside function, we now have
Gℓ(r, r′) = Cℓθ(r′ −r)jℓ(kr)hℓ(kr′) + Cℓθ(r −r′)hℓ(kr)jℓ(kr′)
(12.81)
In diﬀerentiating once, continuity of Gℓ(r, r′) across r = r′ guarantees that the resulting δ-functions
will cancel, and we obtain,
d
drGℓ(r, r′) = kCℓθ(r′ −r)j′
ℓ(kr)hℓ(kr′) + kCℓθ(r −r′)h′
ℓ(kr)jℓ(kr′)
(12.82)
165

Diﬀerentiating a second time, and substituting the result into the deﬁning equation (12.77) for
Gℓ(r, r′), we obtain,
 d2
dr2 + 2
r
d
dr −ℓ(ℓ+ 1)
r2
+ k2

Gℓ(r, r′) = 2kCℓδ(r −r′)W(kr)
(12.83)
where
W(x) = jℓ(x)h′
ℓ(x) −j′
ℓ(x)hℓ(x)
(12.84)
This quantity is the Wronskian for the Bessel equation. The key property of the Wronskian is that
it satisﬁes a ﬁrst order linear diﬀerential equation which may always be integrated. This diﬀerential
equation may be deduced directly from the second order equation, namely,
W ′(x) = jℓ(x)h′′
ℓ(x) −j′′
ℓ(x)hℓ(x) = −2
xW(x)
(12.85)
and solved by
W(x) = W0
x2
(12.86)
where W0 is a constant.
Actually, even this constant may be calculated, using the asymptotic
behavior of jℓand of hℓ, and we ﬁnd W0 = i/2. Putting all together, we ﬁnd that
 d2
dr2 + 2
r
d
dr −ℓ(ℓ+ 1)
r2
+ k2

Gℓ(r, r′) = kCℓδ(r −r′)
i
k2r2
(12.87)
Hence, the desired normalization for Gℓis recovered by setting Cℓ= −ik, and we have,
Gℓ(r, r′) = −ik

θ(r′ −r)jℓ(kr)hℓ(kr′) + θ(r −r′)hℓ(kr)jℓ(kr′)

(12.88)
12.11
Phase shifts
For asymptotically large distance r, and a potential that vanishes at inﬁnity V (r) →0 as r →∞,
it is only the second term in the Green function Gℓ(r, r′) of (12.88) that will contribute. This may
be seen by decomposing the integration region over r′ into two pieces,
Rℓ(r)
=
jℓ(kr) −ikhℓ(kr)
Z r
0
dr′ (r′)2jℓ(kr′)U(r′)Rℓ(r′)
−ikjℓ(kr)
Z ∞
r
dr′ (r′)2hℓ(kr′)U(r′)Rℓ(r′)
(12.89)
Since hℓ(kr′) and Rℓ(kr′) fall oﬀas 1/r′ as r′ →∞, we see that U(r′) should go to zero faster than
1/r′. Under this assumption, the second term may be neglected as r →∞, and we may use the
asymptotic behaviors of the Bessel functions to obtain, as r →∞,
Rℓ(r)
∼
1
kr sin

kr −ℓπ
2

−eikr−iπℓ/2
r
Z ∞
0
dr′ (r′)2jℓ(kr′)U(r′)Rℓ(r′)
(12.90)
∼
1
2ikr

−e−ikr+iπℓ/2 + eikr−iπℓ/2

1 −2ik
Z ∞
0
dr′ (r′)2jℓ(kr′)U(r′)Rℓ(r′)

166

The ﬁrst term represents a radially incoming wave, while the second represents a radially outgoing
wave. Because the potential V (r) is spherically symmetric, the probability in each of the partial
waves separately is conserved. Thus, the probability currents of the incoming and outgoing radial
waves have to be equal. This requires that the moduli of the incoming and outgoing waves coincide.
Therefore, the composite factor of the second term must in fact be a phase,
1 −2ik
Z ∞
0
dr′ (r′)2jℓ(kr′)U(r′)Rℓ(r′) = e2iδℓ(k)
(12.91)
for δℓ(k) a real function of k, for each ℓ. The asymptotic form of the wave function thus becomes,
Rℓ(r)
∼
1
2ikr
n
−e−ikr+iπℓ/2 + eikr−iπℓ/2+2iδℓ(k)o
∼
eiδℓ(k)
kr
sin

kr −πℓ
2 + δℓ(k)

(12.92)
The angles δℓ(k) are referred to as the phase shift for angular momentum ℓ.
Alternatively, we may expose in Rℓ(r) the contribution from the incoming plane wave, by
isolating the function jℓ(kr). As a result, we have, as r →∞,
Rℓ(r) ∼jℓ(kr) + eikr−iπℓ/2
r
× e2iδℓ(k) −1
2ik
(12.93)
Therefore, we may now derive a partial wave expansion for the scattering amplitude f(k′, k), by
comparing the general deﬁnition of f(k′, k) with the partial wave expansion obtained here. The
deﬁnition is given by the behavior of the wave function ψk(r) for large r,
ψk(r) ∼
1
(2π)3/2
(
eik·r + eikr
r f(k′, k)
)
(12.94)
The partial wave result in the same limit obtained here is given by,
ψk(r) −φk(r) =
eikr
(2π)3/2 2ikr
∞
X
ℓ=0
(2ℓ+ 1)

e2iδℓ(k) −1

Pℓ(cos θ)
(12.95)
As a result, we obtain the partial wave expansion of f(k′, k),
f(k′, k) =
1
2ik
∞
X
ℓ=0
(2ℓ+ 1)

e2iδℓ(k) −1

Pℓ(cos θ)
(12.96)
The total cross section may be computed by performing the angular integrations of |f(k′, k)|2. To
do so, we use the orthogonality of the Legendre polynomials as well as their normalizations,
Z
4π
dΩPℓ(cos θ)Pℓ′(cos θ) = 4πδℓ,ℓ′
2ℓ+ 1
(12.97)
167

The result is given by
σtot =
Z
4π
dΩ|f(k′, k)|2 = 4π
k2
∞
X
ℓ=0
(2ℓ+ 1) sin2 δℓ
(12.98)
It is readily checked that the optical theorem is obeyed for this cross section. This may be seen by
computing
Imf(k, k) = 1
2k
∞
X
ℓ=0
(2ℓ+ 1)

1 −cos 2δℓ(k)

Pℓ(1)
(12.99)
Using now the fact Pℓ(1) = 1 and that 1−cos 2δℓ(k) = 2 sin2 δℓ(k), it is easily seen that the relation
of the optical theorem holds.
12.12
The example of a hard sphere
Assume we scatter oﬀa spherical body with potential
V (r) = V0θ(b −r)
V0 > 0
(12.100)
for some radius b and let V0 →∞. This is a hard sphere of radius b. In this limit, clearly all the
partial waves Rℓ(kr) must vanish at r ≤b. Outside the hard sphere, for r > b, the solution is a
linear combination of the spherical Bessel functions jℓ(kr) and hℓ(kr),
Rℓ(r) = jℓ(kr) + cℓ(k)hℓ(kr)
(12.101)
where cℓ(k) is generally a complex function of k. Vanishing of Rℓ(b) provides cℓ(k),
cℓ(k) = −jℓ(kb)
hℓ(kb)
(12.102)
From the limit of hℓ(kr) as r →∞and the result for the phase shift (12.93), we ﬁnd that
eikr−iπℓ/2 × e2iδℓ(k) −1
2ik
= −jℓ(kb)
hℓ(kb)
1
keikr−i(ℓ+1)π/2
(12.103)
we ﬁnd that
e2iδℓ(k) −1 = −2 jℓ(kb)
hℓ(kb)
(12.104)
Using the relation
jℓ(kb) = 1
2 (hℓ(kb) + h∗
ℓ(kb))
(12.105)
168

the above relation becomes,
e2iδℓ(k) = −h∗
ℓ(kb)
hℓ(kb)
(12.106)
The phase shifts for the lowest values of ℓmay be computed explicitly, using the expressions for
the corresponding Hankel functions,
h0(ρ)
=
−ieiρ
ρ
h1(ρ)
=
−ieiρ
ρ2 (1 −iρ)
h2(ρ)
=
−ieiρ
ρ3

−3 + 3iρ + ρ2
(12.107)
As a result, we have
e2iδ0(k)
=
e−2ikb
e2iδ1(k)
=
e−2ikb × 1 + ikb
1 −ikb
e2iδ2(k)
=
e−2ikb × −3 −3ikb + k2b2
−3 + 3ikb + k2b2
(12.108)
or taking the logs,
δ0(k)
=
−kb
δ1(k)
=
−kb + Arctg(kb)
δ2(k)
=
−kb + Arctg

kb
1 −k2b2/3

(12.109)
Note that in the low momentum limit, kb →0, one may obtain an approximate result valid for all
ℓ, using the asymptotic expansions of the spherical Bessel functions,
jℓ(kb)
=
Re(hℓ(kb)) ∼
(kb)ℓ
(2ℓ+ 1)!!
nℓ(kb)
=
Im(hℓ(kb)) ∼−(2ℓ−1)!!
(kb)ℓ+1
(12.110)
Since jℓ(kb) ≪nℓ(kb) in this limit, we ﬁnd that
δℓ(k) ∼jℓ(kb)
nℓ(kb) ∼−
(kb)2ℓ+1
(2ℓ+ 1)!!(2ℓ−1)!!
(12.111)
Thus, for kb ≪1, it makes sense to neglect ℓ≥1 in the low momentum limit, and we ﬁnd
σtot ∼4π
k2 sin2 δ0 ∼4πb2
(12.112)
169

At high energy, the particles behave classically and see only the aspect disk with area πb2, but at
low energy, the s-wave scattering sees the entire surface area of the sphere, which is 4πb2.
In terms of the Bessel functions, it is possible to write down an exact expression for the cross
section, valid for all ranges of the momenta k,
σtot = 4π
k2
∞
X
ℓ=0
(2ℓ+ 1)(jℓ(kb))2
|hℓ(kb)|2
(12.113)
Collecting the ﬁrst two terms, ℓ≤1, we ﬁnd,
σtot = 4π
k2

k2b2 +
3
1 + k2b2 (−kb cos kb + sin kb)2

(12.114)
At very high momentum kb ≫1, we may use the asymptotic expressions for the Bessel functions
to evaluate the cross section, so that
(jℓ(kb))2
|hℓ(kb)|2 ∼sin2

kb −πℓ
2

(12.115)
Summing over ℓleads to a divergent total cross section ! This is now a UV eﬀect, operating at high
momentum scattering, and it is due to the fact that we are assuming that the sphere is perfectly
reﬂecting even to the highest momenta. Physically, this assumption is not valid in fact. Sakurai
proposes then to limit the sum over ℓto ℓℓmax < kb, and refers to this as a reasonable assumption.
Please judge for yourself.
12.13
The hard spherical shell
Another very interesting special case is for a δ-function shell of ﬁnite strength, given by
U(r) = −U0δ(r −b)
(12.116)
where U0 may be either positive or negative. To solve for the phase shifts, we use the potential
U(r) above in the integral equation (12.78). The integral over r′ is readily performed since the
δ(r′ −b) potential localizes the integral at r′ = b, and we ﬁnd,
Rℓ(r) = jℓ(kr) −U0b2Gℓ(r, b)Rℓ(b)
(12.117)
To determine Rℓ(b), we simply evaluate this equation at r = b, so that
Rℓ(b) =
jℓ(kb)
1 + iU0kb2jℓ(kb)hℓ(kb)
(12.118)
This result gives an exact expression for the partial wave functions Rℓ(r) outside the spherical
shell, where r > b (the inside region may be solved for as well but is immaterial for the scattering
problem), and we ﬁnd,
Rℓ(r) = jℓ(kr) +
iU0kb2jℓ(kb)2hℓ(kr)
1 −iU0kb2jℓ(kb)hℓ(kb)
(12.119)
170

Comparison of the asymptotics of this formula with the deﬁnition of the phase shifts in (12.93), we
ﬁnd, after some rearrangements, that
e2iδℓ(k) = 1 + iU0kb2jℓ(kb)h∗
ℓ(kb)
1 −iU0kb2jℓ(kb)hℓ(kb)
(12.120)
Gottfried has a nice discussion of the physics of this problem.
12.14
Resonance scattering
There is a very interesting case of scattering potentials where quasi-stable bound states exist and
aﬀect the scattering process. This occurs when the eﬀective potential
Veﬀ(r) = V (r) + ℓ(ℓ+ 1)
r2
(12.121)
has a local minimum which is not a global minimum.
Figure 13: Potential with unstable minimum in shaded area
During a scattering process, the incident particle excites the potential and creates a quasi-stable
bound state. This creates a resonance eﬀect, since it will take some time for this bound state to
decay, and the process is then referred to as resonance scattering. The scattering cross section in
this channel reaches then a maximum. Note that this will always occur, for given ℓ, when δℓ(k)
crosses the value π/2. Given the partial cross section
σ(ℓ)
tot = 4π
k2 (2ℓ+ 1) sin2 δℓ(k)
(12.122)
we see that this partial cross section takes its maximal value at δℓ(k) = π/2. Around this value,
we may linearize as a function of momentum k (or traditionally, more often as a function of energy
E), we have
cotgδℓ(k) = 2E −ER
Γ
+ O((E −ER)2)
E = ¯h2k2
2m
(12.123)
171

Since δℓ(k) is dimensionless, we need indeed two dimensionful parameters ER, the position of
the resonance, and Γ, the width of the resonance, to characterize the expansion to ﬁrst order.
Computing now the partial cross section, we use
sin2 δℓ(k) =
1
1 + cotg2δℓ(k) =
Γ2/4
(E −ER)2 + Γ2/4
(12.124)
and thus the partial cross section
σ(ℓ)
tot = 4π
k2
(2ℓ+ 1)Γ2/4
(E −ER)2 + Γ2/4
(12.125)
It turns out that this kind of curves ﬁt experimental observations of resonance scattering processes
very well.
Figure 14: Behavior of the phase shift δℓand of the partial cross section σℓnear a resonance
172

13
Time-dependent Processes
So far, we have studied problems in which the Hamiltonian is time-independent. This is suitable for
any isolated system, in which the total energy is conserved. In many physical problems, however,
it is inconvenient to treat the entire closed system, and views part of the system, instead, as an
external source, which may be time dependent. The Hamiltonian for such systems then often takes
the form of a sum of a time-independent unperturbed Hamiltonian H0, and a time time-dependent
perturbation V (t),
H = H0 + V (t)
(13.1)
and it will be assumed again that the spectrum and eigenstates of H0 is exactly known. Very few
such time dependent problems can be solved exactly, and often one will have to resort to carrying
out perturbation theory in the strength of the potential V (t).
13.1
Magnetic spin resonance and driven two-state systems
The problem of magnetic spin resonance is exactly solvable and is also of substantial practical
signiﬁcance. Actually, the problem is more general than magnetic spin would suggest, and the
same methods may be applied for any two-state system driven by an external periodic oscillation.
We deal with this problem ﬁrst and then develop perturbation theory. The Hamiltonian is of the
form
H0
=
ω0Sz
V (t)
=
ω1 cos(ωt)Sx + ω1 sin(ωt)Sy
(13.2)
Here, ω is the driving frequency. As a magnetic problem, this Hamiltonian arises from a particle
with spin S and magnetic moment M = γS in the presence of a constant magnetic ﬁeld B0 along
the z-axis, and an oscillating magnetic ﬁeld B1(t) = B1 cos(ωt)nx + B1 sin(ωt)ny in the xy-plane.
The frequencies are then given by
ω0
=
γB0
ω1
=
γB1
(13.3)
But the problem may be considered generally, without referring to the magnetic system.
Denote an orthonormal basis of the two state system by the vectors | + | > and |−⟩. In this
basis, the Hamiltonian is given by
H = ¯h
2

ω0
ω1e−iωt
ω1e+iωt
−ω0

(13.4)
A general state |ψ(t)⟩may be decomposed onto |+⟩and |−⟩,
|ψ(t)⟩= a+(t)|+⟩+ a−(t)|−⟩
(13.5)
173

The time-dependent Schr¨odinger equation for |ψ(t)⟩then reduces to the following set of equations
for a±,
i˙a+(t)
=
ω0
2 a+(t) + ω1
2 e−iωta−(t)
i˙a−(t)
=
ω1
2 e+iωta+(t) −ω0
2 a−(t)
(13.6)
In a comoving frame of states, deﬁned by
b+(t)
=
a+(t)e+iωt/2
b−(t)
=
a−(t)e−iωt/2
(13.7)
the equations simplify in that they no longer involve any explicit time dependence,
i˙b+(t)
=
ω0 −ω
2
b+(t) + ω1
2 b−(t)
i˙b−(t)
=
ω1
2 b+(t) −ω0 −ω
2
b−(t)
(13.8)
The time evolution of the b± variables is thus eﬀectively given by a reduced Hamiltonian,
˜H = ¯h
2
 ω0 −ω
ω1
ω1
−ω0 + ω

(13.9)
The eigenvalues of ˜H are ±¯hΩwith
Ω=
q
(ω0 −ω)2 + ω2
1
(13.10)
Thus, we get the following general solution,
 b+(t)
b−(t)

= γ+

ω1
Ω+ ω −ω0

e−iΩt/2 + γ−

ω1
−Ω+ ω −ω0

e+iΩt/2
(13.11)
where γ± are constants. This gives a complete solution of the problem.
We now introduce also physical initial conditions and a physical problem : suppose the system
at time t = 0 is in the state |+⟩, what is the probability of ﬁnding the system in the state |−⟩after
time t ? To solve this problem, we ﬁrst enforce the initial condition on the general solution. This
means that at time t = 0, we have a+(0) = b+(0) = 1 and a−(0) = b−(0) = 0, so that we must have
γ± =
1
2ω1

1 ± ω0 −ω
Ω

(13.12)
The desired probability is then given by
P+−(t) =
ω2
1
(ω −ω0)2 + ω2
1
sin2
q
(ω −ω0)2 + ω2
1
t
2

(13.13)
This is the Rabi formula for magnetic resonance. The resonance eﬀect occurs when ω ∼ω0, in
which case the probability for the spin ﬂip is maximal. In fact, when ω = ω0, then this formula
tells us that after a time t = π/ω1, the spin is ﬂipped with probability 1.
174

13.2
The interaction picture
We now turn to time dependent problems in the general case where H = H0 + V (t). We shall
assume that the eigenvalues and eigenstates of H0 are known as follows,
H0|n⟩= En|n⟩
(13.14)
For simplicity, we shall assume here that the spectrum of H0 is discrete, but it is not hard to
generalize to the continuous case, something we shall do later on. We prepare an initial state |φa⟩
at t = 0, which we may decompose in the basis of eigenstates |n⟩by
|φa⟩=
X
n
cn(0)|n⟩
(13.15)
In the absence of interaction potential, V (t) = 0, this state would evolve as follows,
|φa; t⟩=
X
n
cn(0)e−itEn/¯h|n⟩
(13.16)
On the other hand, once the interaction potential is turned on, the time evolution will be more
complicated, giving time dependence also to the coeﬃcients cn. The corresponding state will be
denoted |ψa; t⟩. It satisﬁes the full time dependent Schr¨odinger equation,
i¯h d
dt|ψa; t⟩= (H0 + V (t))|ψa; t⟩
(13.17)
and has the following decomposition,
|ψa; t⟩=
X
n
cn(t)e−itEn/¯h|n⟩
(13.18)
Notice that we can also write this time evolution as
|ψa; t⟩= e−itEn/¯h|ψa; t⟩I
(13.19)
where
|ψa; t⟩I =
X
n
cn(t)|n⟩
(13.20)
The subscript I has been added to indicate that this state is now considered in the interaction
picture, a method due to Dirac. The advantage is that the coeﬃcients cn now have time depen-
dence only through the eﬀects of the time-dependent interaction potential, the eﬀects of the free
Hamiltonian having been factored out.
More generally, if |ψa; t⟩S is a general state in the Schr¨odinger picture, satisfying the Schr¨odinger
equation,
i¯h d
dt|ψa; t⟩S =

H0 + V (t)

|ψa; t⟩S
(13.21)
175

then we deﬁne the corresponding state |ψa; t⟩I in the interaction picture by factoring out the time
dependence induced by H0 alone,
|ψa; t⟩I ≡eitH0/¯h|ψa; t⟩S
(13.22)
Correspondingly, any observable AS in the Schr¨odinger picture (which is by construction time
independent), maps to an observable AI in the interaction picture, by
AI(t) = eitH0/¯hASe−itH0/¯h
(13.23)
Thus, observables, in general, also become time dependent. The interaction picture is therefore
intermediate between the Heisenberg and Schr¨odinger pictures.
The time evolution of the states |ψa; t⟩I in the interaction picture may be deduced from their
deﬁnition and from the Schr¨odinger equation, and we ﬁnd,
i¯h d
dt|ψa; t⟩I = VI(t)|ψa; t⟩I
(13.24)
where the potential in the interaction picture is given by the relation between observables given
above,
VI(t) = eitH0/¯hV (t)e−itH0/¯h
(13.25)
The time-evolution of the coeﬃcients cn is now simply given by the matrix elements of VI(t).
Indeed, we have
|ψa; t⟩I =
X
n
cn(t)|n⟩
(13.26)
and
i¯h
X
n
˙cn(t)|n⟩=
X
m
cm(t)VI(t)|m⟩
(13.27)
Taking the matrix elements with ⟨n|,
i¯h˙cn(t)
=
X
m
cm(t)⟨n|VI(t)|m⟩
=
X
m
cm(t)e−it(Em−En)/¯h⟨n|V (t)|m⟩
(13.28)
In general, it is not possible to solve the resulting system of diﬀerential equations exactly (except
in very special cases, such as magnetic resonnace treated earlier). Thus, we resort to carrying out
a calculation which is perturbative in powers of VI.
176

13.3
Time-dependent perturbation theory
A systematic way of organizing time-dependent perturbation theory is through the use the evolution
operator in the interaction picture. After all, we have
|ψa; t⟩I = UI(t, t0)|ψa; t0⟩I
(13.29)
where
i¯h d
dtUI(t, t0)
=
VI(t)UI(t, t0)
UI(t0, t0)
=
I
(13.30)
Notice that, since VI is time dependent, we need to keep the initial and ﬁnal times in UI, and not
just their diﬀerence t −t0, as we had done in the time independent case.
The diﬀerential equation, together with the initial value condition at t0 may be reformulated
in terms of a single integral equation,
UI(t, t0) = I −i
¯h
Z t
t0
dt′ VI(t′) UI(t′, t0)
(13.31)
Clearly, the initial value problem is satisﬁed by this equation, and diﬀerentiation in t immediately
reproduces the diﬀerential equation. Its solution may be obtained order by order in perturbation
theory by successive substitution and iteration. A ﬁrst iteration gives
UI(t, t0) = I −i
¯h
Z t
t0
dt′ VI(t′) −1
¯h2
Z t
t0
dt′
Z t′
t0
dt′′VI(t′)VI(t′′)UI(t′′, t0)
(13.32)
Iterating again will yield the solution to second order in VI,
UI(t, t0) = I −i
¯h
Z t
t0
dt′ VI(t′) −1
¯h2
Z t
t0
dt′
Z t′
t0
dt′′VI(t′)VI(t′′) + · · ·
(13.33)
This is referred to as the Dyson series. Alternatively, we may derive an analogous formula directly
on the coeﬃcients cn, and we get
cn(t) = cn(0) −i
¯h
Z t
t0
dt′ X
m
⟨n|VI(t′)|m⟩cm(t′)
(13.34)
and then this formula may be iterated in turn.
The diﬃculty of this integral solution is that the potential VI(t) is an operator, and in general,
we will have
[VI(t′), VI(t′′)] ̸= 0
(13.35)
Generally, it is diﬃcult to go beyond the ﬁrst order in any expliciit way. For short time intervals
t −t0, the expansion should yield reliable results given by the contributions of the leading orders.
For long time evolution, however, predictions are much harder to come by. Below, we show that
it is possible to obtain new results already just from the ﬁrst order approximation to this formula.
Below, we shall treat a special case to illuminate the procedure.
177

13.4
Switching on an interaction
We consider perhaps the simples of time-dependent potentials,
V (t) = Vθ(t)
(13.36)
where θ(t) is the step function, and V is a time-independent operator. This potential represents
an interaction that is turned on abruptly at time t = 0 and then stays on. This circumstance is a
reasonable approximation to what happens in physical situations. For example, an atom prepared
in a certain excited energy eigenstate may decay under the inﬂuence of an external perturbation,
such as an incoming wave or a vacuum ﬂuctuation. Or a probe may hit a target in a scattering
experiment.
We use (13.34) to ﬁrst order to compute the time evolution. For simplicity, we shall assume
that the system has been prepared at time t = 0 in one of the eigenstates n = i, so that cn(0) = δn,i,
and we obtain,
cn(t)
=
δn,i −i
¯hVni
Z t
0
dt′eiωnit
=
Vni
En −Ei

1 −eiωnit
(13.37)
where we have used,
Vni
=
⟨n|V|i⟩
ωni
=
(En −Ei)/¯h
(13.38)
The probability for measuring the system in state n ̸= i after time t is then given by
Pni(t) = |cn(t)|2 =
4|Vni|2
(En −Ei)2 sin2 (En −Ei)t
2¯h
(13.39)
Clearly, this probability distribution is peaked towards the smallest values of |En −Ei|. To study
this behavior more closely, it is convenient to introduce the density of states ρ(E), so that we can
treat discrete and continuous spectra on the same footing. The density of states is deﬁned so that
ρ(E)dE equals the number of states between energies E and E +dE. The probability for the decay
of the initial state at energy Ei into a state En between E and E + dE is then given by
dP(E, t) = ρ(E)dE|cn(t)|2 = ρ(E)dE 4|VE,Ei|2
(E −Ei)2 sin2 (E −Ei)t
2¯h
(13.40)
This gives us the probability rate, per unit energy,
dP(E, t)
dE
= ρ(E) 4|VE,Ei|2
(E −Ei)2 sin2 (E −Ei)t
2¯h
(13.41)
Now, we are primarily interested in this probability for long time scales, where we mean long
compared to the transition energies E −Ei.
178

It is best to consider this problem mathematically ﬁrst. We set x = (E −Ei)/(2¯h), and thus
seek to obtain the following large t behavior (tx ≫1 for x ﬁxed)
lim
t→∞
sin2(tx)
tx2
(13.42)
Clearly, when x ̸= 0, this quantity tends to zero as t →∞. So, it can have support only at x = 0.
In fact, at x = 0, its value is just t, so we suspect that the limit is of the form δ(x). To prove this,
integrate the quantity against a smooth function f(x),
lim
t→∞
Z ∞
−∞
dxf(x)sin2(tx)
tx2
=
lim
t→∞
Z ∞
−∞
dyf(y/t)sin2 y
y2
=
f(0)
Z ∞
−∞
dysin2 y
y2
= πf(0)
(13.43)
As a result, we conclude that
lim
t→∞
sin2(tx)
tx2
= πδ(x)
(13.44)
The object of interest may now be handled as follows,
4
(E −Ei)2 sin2 (E −Ei)t
2¯h
∼t ×
4
(E −Ei)2t sin2 (E −Ei)t
2¯h
(13.45)
as t →∞. The second factor now has a limit, as computed above, and we have
4
t(E −Ei)2 sin2 (E −Ei)t
2¯h
∼t × 2π
¯h δ(E −Ei)
(13.46)
Putting all together, we obtain still for large t,
dP(E, t)
dE
∼t × 2π
¯h ρ(E) |VE,Ei|2δ(E −Ei)
(13.47)
It is customary to express this result in terms of the transition rate per unit time, by taking the
time derivative on both sides,
ωi→E = d2P(E, t)
dE dt
= 2π
¯h ρ(E) |VE,Ei|2δ(E −Ei)
(13.48)
This formula is referred to as Fermi’s Golden Rule.
The Fermi Golden Rule formula must be interpreted with some care. For ﬁnite t, as we are of
course always assuming, it is not strictly true that only a state with energy E = Ei will contribute.
This is a simple reﬂection of the energy time uncertainty relation,
∆t∆E ≥¯h
(13.49)
Thus, for ﬁnite time, we should really integrate over E in a range around Ei given by ∆E ∼¯h/t,
where t is large. The density of states may be assumed to be a smooth function of E, but the
matrix elements may or may not vary smoothly. Thus, one deﬁnes an average matrix element
squared |VE,Ei|2 in terms of which we have,
ωi→E = 2π
¯h ρ(E) |VE,Ei|2
(13.50)
179

13.5
Sinusoidal perturbation
Another very important special case, analogous to the problem of spin magnetic resonance, is when
the time dependence of the perturbing potential is sinusoidal,
V (t) = Veiωt + V†e−iωt
(13.51)
where V is a time independent operator. We again use the perturbative formula for the coeﬃcients
cn, given in (13.34), and assume that at time t = 0, the system has been prepared in one of the
eigenstates |i⟩of H0. We obtain,
cn(t)
=
δn,i −i
¯h
Z t
0
dt′

Veiωt′ + V†e−iωt′
eiωnit′
=
δn,i + 1 −ei(ωni+ω)t
¯h(ωni + ω) Vni + 1 −ei(ωni−ω)t
¯h(ωni −ω) V†
ni
(13.52)
We see that this formula is very similar to the switched on interaction, except that ωni →ωni ± ω.
Thus, the transition rate is supported not at ωni = 0 as in the case of the switched on interaction,
but rather at ωni ± ω = 0. Thus the rates are given by
ωi→E = d2P(E, t)
dE dt
= 2π
¯h ρ(E) |VE,Ei|2δ(E −Ei ± ¯hω)
(13.53)
The two cases correspond to absorption or emission a quantum with energy ¯h.
180

14
Path Integral Formulation of Quantum Mechanics
A quantum system associated with classical mechanics admits a formulation in terms of functional
integrations over all possible paths. This path-integral formulation was pioneered by Dirac in 1933,
and popularized by Feynman in the 1940’s. It is quite useful in modern quantum mechanics, but
it has become an indispensable tool especially in quantum ﬁeld theory.
The key intuitive idea behind the path integral construction of the probability amplitudes of
quantum mechanics is as follows. Classically, the system is deterministic, and we know the precise
path followed by a particle, given initial q and ﬁnal q′ conditions. Quantum mechanically, each
geometric path is a possible “trajectory” for the quantum particle, and its contribution to the full
quantum probability amplitude will be given by some weight factor which remains to be determined.
The full quantum probability amplitude will then be given by a sum over all possible paths, and a
weight factor for each path.
probability amplitude =
X
paths
weight factor for path
(14.1)
A sketch of the (unique) path followed by a classical particle and possible quantum paths is depicted
in the Figure below.
q
q’
Figure 15: The black line represents the classical trajectory; the red lines represent various
path which contribute to the path integral for the quantum probability amplitude.
In the present chapter, we shall give a detailed derivation of the sum over paths and the
associated weight factor. The standard reference is the book by Feynman and Hibbs, but I will
follow rather the more general derivation in phase space given originally by Dirac.
14.1
The time-evolution operator
Time evolution in the Schr¨odinger and Heisenberg pictures are given by a diﬀerential equation
respectively for states and observables,
i¯h d
dt|ϕ(t)⟩= H(t)|ϕ(t)⟩
Schroedinger picture
i¯h d
dtA(t) = [A(t), H(t)]
Heisenberg picture
(14.2)
181

Actually, the time-evolution equations in both pictures may be solved with the use of the time
evolution operator U(t). This operator is deﬁned to be unitary, and to satisfy,13
i¯h d
dtU(t) = H(t)U(t)
U(t)†U(t) = I
(14.3)
It is often convenient to give an initial condition on U such that at time ta, the operator is unity.
We shall denote this operator by U(t; ta). The solution to both equations in (14.2) may then be
presented as follows,
|ϕ(t)⟩
=
U(t; ta)|ϕ(ta)⟩
U(ta; ta) = I
A(t)
=
U(t; ta)†A(ta)U(t; ta)
(14.4)
This result may be veriﬁed by explicit calculation; to do so in the Heisenberg picture, the following
intermediate step will be helpful,
i¯h d
dtU(t)† = −U(t)†H(t)
(14.5)
For a time-independent Hamiltonian H, the evolution operator is given by the exponential,
U(t; ta) = U(t −ta)
U(t) = e−itH/¯h
(14.6)
The evolution operator U(t) now commutes with H at all times t, and manifestly satisﬁes the
following composition formula,
U(t1 + t2) = U(t1)U(t2)
(14.7)
14.2
The evolution operator for quantum mechanical systems
Let us consider a quantum system which is associated with a classical mechanical one. As discussed
in the preceding section, such systems may be formulated in terms of the position Q and momentum
P operators, in terms of which the Hamiltonian is expressed, H(Q, P). In general, we may have
several such pairs, Qi, Pi with i = 1, · · · , N. For simplicity, we shall start with the case N = 1; the
generalization to higher N will be straightforward. Recall the bases deﬁned by these operators,
Q|q⟩= q|q⟩
[Q, P] = i¯h
P|p⟩= p|p⟩
(14.8)
Orthonormality and completeness hold as follows,
⟨q′|q⟩= δ(q −q′)
I =
Z
dq |q⟩⟨q|
⟨p′|p⟩= 2π¯h δ(p −p′)
I =
Z
dp
2π¯h |p⟩⟨p|
(14.9)
13Note the deﬁnite order in the product of H(t) and U(t); generally these operators do not commute.
182

Translation operators in both bases satisfy
e+iaP/¯hQe−iaP/¯h = Q + a
e−iaP/¯h|q⟩= |q + a⟩
e−ibQ/¯hPe+ibQ/¯h = P + b
e+ibQ/¯h|p⟩= |p + b⟩
(14.10)
and their mutual overlap is
⟨q|p⟩
=
e+iqp/¯h
⟨p|q⟩
=
e−iqp/¯h
(14.11)
This summarizes all that will be needed to derive the functional integral representation.
We now use the position basis to express the time-evolution of the wave function ϕ(q, t) =
⟨q|ϕ(t)⟩associated with a general state |ϕ(t)⟩. It is given by
ϕ(qb, tb) = ⟨qb|U(tb −ta)|ϕ(ta)⟩=
Z
dqa⟨qb|U(tb −ta)|qa⟩ϕ(qa, ta)
(14.12)
Hence, the evolution of the wave function is given by the matrix elements of the evolution operator
in a position space basis. It is these matrix elements for which we shall derive a functional integral
formulation. We can split this evolution into the consecutive evolutions of two shorter time intervals,
tc −ta = (tc −tb) + (tb −ta), with tc > tb > ta. Inserting a complete set of position eigenstates in
the product on the right hand side of the formula U(tc −ta) = U(tc −tb)U(tb −ta), we obtain,
⟨qc|U(tc −ta)|qa⟩=
Z
dqb⟨qc|U(tc −tb)|qb⟩⟨qb|U(tb −ta)|qa⟩
(14.13)
Clearly this process can be repeated.
14.3
The evolution operator for a free massive particle
Before launching a full attack on this problem, let us calculate the matrix elements of the evolution
operator for a a free massless particle with Hamiltonian,
H =
1
2mP 2
(14.14)
Since H is diagonal in the momentum basis, we calculate as follows,
⟨qb|U(tb −ta)|qa⟩
=
Z
dpb
2π¯h
Z dpa
2π¯h⟨qb|pb⟩⟨pb|U(tb −ta)|pa⟩⟨pa|qa⟩
=
Z
dpb
2π¯h
Z dpa
2π¯hei(pbqb−paqa)/¯h ⟨pb|U(tb −ta)|pa⟩
(14.15)
Using the fact that U(tb −ta) is diagonal in the momentum basis, we ﬁnd,
⟨pb|U(tb −ta)|pa⟩= 2π¯hδ(pb −pa) e−i(tb−ta)p2
a/(2m¯h)
(14.16)
183

Putting all together, and using δ(pb −pa) to carry out the integration over pb, we have
⟨qb|U(tb −ta)|qa⟩
=
Z dpa
2π¯he−i(tb−ta)p2
a/(2m¯h) eipa(qb−qa)/¯h
=

m
2πi(tb −ta)¯h
 1
2 exp
(
im(qb −qa)2
2¯h(tb −ta)
)
(14.17)
The full signiﬁcance of the exponential factor will become clear later. Here, we notice simply that
the quantity
˙q = qb −qa
tb −ta
(14.18)
is the velocity needed for a free particle in uniform motion departing from position qa at time ta to
reach position the qb at time tb. Its energy E is just its kinetic energy, and the associated action S
are given by
E(qb, tb; qa, ta) = m(qb −qa)2
2(tb −ta)2
S(qb, tb; qa, ta) = m(qb −qa)2
2(tb −ta)
(14.19)
For the free particle, the matrix elements of the evolution operator are given by
⟨qb|U(tb −ta)|qa⟩∼exp{iS(qb, tb; qa, ta)/¯h}
(14.20)
Notice that for ﬁxed qa, qb and tb −ta →0, S is becomes very large, unless qa ∼qb. As tb −ta →0,
the evolution operator becomes local in q and tends towards δ(qb −qa).
14.4
Derivation of the path integral
We now seek a formula for ⟨qb|U(tb −ta)|qa⟩which will be valid for a general time-independent
Hamiltonian H(Q, P). It is convenient to begin by dividing the time interval tb −ta > 0 into N
consecutive segments of equal length ε = (tb −ta)/N. Using the multiplicative property of the
exponential, we have
U(tb −ta) = U(ε)N
(14.21)
Inserting N −1 times the identity operator, expressed as a completeness relation on position
eigenstates, we obtain,
⟨qb|U(tb −ta)|qa⟩=
 N−1
Y
n=1
Z
R
dqn
! N
Y
n=1
⟨qn|U(ε)|qn−1⟩
(14.22)
where we have set q0 ≡qa and qN ≡qb. The remaining qn for n = 1, · · · , N −1 are integrated over
in this formula, as may be seen schematically on the Figure below.
When N →∞and ε →0, we may expand the evolution operator in a power series in ε,
U(ε) = I −i ε
¯hH + O(ε2)
(14.23)
184

Figure 16: The evolution operator given as a summation over paths, qa = q and qb = q′
The problem will be, however, that the Hamiltonian H is not generally diagonal in the position basis
(as was clear from the free particle Hamiltonian already). Of course we could use the momentum
basis, in which the free particle Hamiltonian is diagonal, but a general Hamiltonian will not be
diagonal in this basis either. The trick is to use a mixed basis. Consider for example a general
potential type Hamiltonian, of the form,
H(Q, P) =
1
2mP 2 + V (Q)
(14.24)
It is manifest that we have ⟨q|H(Q, P)|p⟩= ⟨q|p⟩H(q, p), where H(q, p) is just the classical Hamil-
tonian. Now, given a general Hamiltonian, H(Q, P), it can always be rearranged so that all P
operators are on the right of all Q operators. It is in this form that we can use it to deﬁne the
classical Hamiltonian H(q, p) by,
⟨q|H(Q, P)|p⟩= ⟨q|p⟩H(q, p)
(14.25)
We are now in a position to complete our calculations. We shall deﬁne the classical Hamiltonian
by
⟨q|U(ε)|p⟩= ⟨q|p⟩

1 −i ε
¯hH(q, p) + O(ε2)

= ⟨q|p⟩exp

−i ε
¯hH(q, p)

(14.26)
and use this expression to compute the matrix element,
⟨qn|U(ε)|qn−1⟩
=
Z dpn
2π¯h⟨qn|U(ε)|pn⟩⟨pn|qn−1⟩
185

=
Z dpn
2π¯h⟨qn|pn⟩⟨pn|qn−1⟩exp

−i ε
¯hH(qn, pn)

=
Z dpn
2π¯h exp

i(qn −qn−1)pn/¯h −i ε
¯hH(qn, pn)

(14.27)
The ﬁnal step consists of a change of notation,
tn
=
t + nε
qn
=
q(tn)
pn
=
p(tn)
(14.28)
The argument of the exponential may now be recast as follows,
i
¯h(qn −qn−1)pn −i ε
¯hH(qn, pn)
=
i
¯hε
q(tn) −q(tn −ε)
ε
p(tn) −H(qn, pn)

=
i
¯h
Z tn
tn−1
dt

˙q(t)p(t) −H(q(t), p(t))

(14.29)
Putting all together,
⟨qb|U(tb −ta)|qa⟩=
Z
Dq
Z
Dp exp
 i
¯h
Z tb
ta
dt

˙q(t)p(t) −H(q(t), p(t))

(14.30)
where the measures are deﬁned by
Z
Dq
=
lim
N→∞
N−1
Y
n=1
Z
R
dq(tn)
Z
Dp
=
lim
N→∞
N
Y
n=1
Z
R
dp(tn)
2π¯h
(14.31)
and the paths satisfy the following “boundary conditions”
q(ta)
=
qa
q(tb)
=
qb
(14.32)
Notice that there are no boundary conditions on p(t). The combination ˙qp−H(q, p) is nothing but
the Lagrangian written in canonical coordinates q and p, and the integral over τ that enters the
path integral formula above is just the action in terms of q and p.
An alternative formula is obtained by expressing ⟨qb| as the Fourier transform of a momentum
state,
⟨pb|U(tb −ta)|qa⟩=
Z
Dq
Z
Dp exp
 i
¯h
Z tb
ta
dt

˙q(t)p(t) −H(q(t), p(t))

(14.33)
186

where the combine measure is deﬁned by
Z
Dq
Z
Dp = lim
N→∞
N−1
Y
n=1
Z
R
Z
R
dq(tn)dp(tn)
2π¯h
(14.34)
and the paths satisfy the following “boundary conditions”
q(ta)
=
qa
p(tb)
=
pb
(14.35)
while the boundary conditions on p(ta) and q(tb) are now free. This form is particularly geometrical
because the measure is intrinsic and invariant under canonical transformations. The volume element
dq(tn)dp(tn)
2π¯h
(14.36)
gives a measure for the elementary volume of phase space in a quantum system. By the uncertainty
relation, there is in some sense one state per elementary phase space volume element ∆q∆p. The
above measure naturally puts a measure on the number of quantum states for the system.
14.5
Integrating out the canonical momentum p
Whenever the Hamiltonian is simple enough so that its dependence on momentum and position
enter separately, momentum may be “integrated out”. Let us take the most customary form,
H = p2
2m + V (q)
(14.37)
The combination under the integration is
˙qp −H(q, p)
=
˙qp −p2
2m −V (q)
=
−1
2m(p −m ˙q)2 + 1
2m ˙q2 −V (q)
(14.38)
We now see that the integration over Dp does not depend on q any more, after an innocuous
translation by m ˙q. The Gaussian integral involves an inﬁnite number of integrations, so this gives
a constant, which we shall absorb into the deﬁnition of the integration measure Dq,
Z
Dq = lim
N→∞
N−1
Y
n=1
Z
R
dq(tn)
r
m
2πi¯hε

(14.39)
Our ﬁnal result is thus,
⟨qb|U(tb −ta)|qa⟩=
Z
Dq exp
 i
¯h
Z tb
ta
dtL(q, ˙q)

(14.40)
187

where L is the standard Lagrangian, formulated in terms of q and ˙q, and given by
L(q, ˙q)
=
1
2m ˙q2 −V (q)
(14.41)
The extra dynamics-dependent constant factor that appears in the measure after p has been inte-
grated out is a real nuisance and it is often “omitted”, in the sense that one gives up on computing
it. Instead, one writes that
⟨qb|U(tb −ta)|qa⟩= N
Z
Dq exp
 i
¯h
Z tb
ta
dtL(q, ˙q)

(14.42)
where N is a quantity which is independent of qa, qb. Often, N can be determined by considering
limits of qa or qb in which the integral simpliﬁes, but N remains unchanged.
14.6
Dominant paths
The space of all paths that contribute to the path integral is huge. Often, however, the physics of
the problem produces a natural distinction between the paths that contribute most and paths that
do not. We can see this by studying the free-particle weight factor in the path integral,
eiSm/¯h
Sm = m(qb −qa)2
2(tb −ta)
(14.43)
Consider a particle traveling a distance of qb −qa ∼1mm in a time of tb −ta ∼1sec. The phase
factors for a particle of mass m = 1g, for an electron of mass me ∼10−27g, and a proton of mass
mp ∼2 × 10−24g are,
Sm/¯h
∼
0.5 × 1025
≫π
Sme/¯h
∼
0.005
≪π
Smp/¯h
∼
1
∼π
(14.44)
Clearly, for the particle of mass 1g, the interference of all the paths but the classical one will cancel
one another out. For the electron, paths other than the classical path interfere strongly with the
contribution of the classical path, and the case of the proton is intermediate.
14.7
Stationary phase approximation
When the classical path has an action which is much larger than π, it makes sense to treat the
functional integral by approximations. It is useful to consider an example of a rapidly oscillating
integral ﬁrst.
Z +∞
−∞
dk ei(πak2−2πbk) = e−iπb2/a
√−ia
(14.45)
188

Of course, we knw how to do this integral exactly; it is just a Gaussian.
But if we were just
interested in the a ≫1 behavior of the integral, we can use stationary phase approximation. The
rule is to approximate the integral by the value it takes when the phase is stationary,
d
dk(πak2 −2πbk) = 0
(14.46)
which is also ak −b = 0. Hence, in this approximation, we get
Z +∞
−∞
dk ei(πak2−2πbk) ∼e−iπb2/a
(14.47)
Comparing with the exact result, we see that the exponential is correct, though the prefactor is
missing. The prefactor is subdominant to the exponential though when a ≪1, so this approxi-
mation is not too bad. The method is especially useful for integrals that we do not know how to
evaluate exactly, eg,
Z +∞
−∞
dk ei(πak4−2πbk) ∼e−3/2iπb(b/2a)1/3
(14.48)
Here, we have assume that only the real stationary phase solution of 2ak3 −b = 0 contributes.
In general, the issue of whether complex solutions contribute or not is a quite subtle one (see eg
Mathews and Walker).
We shall now be interested in applying the stationary phase method to the path integral
⟨qb|U(tb −ta)|qa⟩=
Z
Dq exp
 i
¯h
Z tb
ta
dt L(q, ˙q)

(14.49)
We begin by assuming that there exists a classical trajectory q0(t) such that
q0(ta)
=
qa
q0(tb)
=
qb
(14.50)
and such that q0(t) solves the Euler-Lagrange equations, and is thus a stationary path of the
action. For simplicity, we shall assume that the solution q0(t) is unique. The stationary phase
approximation to the path integral is then,
⟨qb|U(tb −ta)|qa⟩∼exp
 i
¯h
Z tb
ta
dt L(q0(t), ˙q0(t))

(14.51)
In the next subsection, we shall improve upon this result.
14.8
Gaussian ﬂuctuations
It is possible to systematically improve upon the stationary phase approximation. Here, we shall
discuss only the leading such correction, obtained by taking into account the Gaussian ﬂuctuations
189

of paths around the classical one. As before, we assume that we have a classical solution q0(t)
connecting initial and ﬁnal positions. If ¯h were zero, that is all there would be. So, it makes sense
to think of the quantum ﬂuctuations around q0(t) as small when S/¯h ≫π. The correct expansion
order is given by
q(t) = q0(t) +
√
¯hy(t)
y(ta) = y(tb) = 0
(14.52)
The contribution from the Gaussian ﬂuctuations is then obtained by expanding S[q0 +
√
¯hy] in
powers of ¯h. By the very fact that q0(t) is a classical solution, we know that the term of order
√
¯h
in this expansion must vanish. Hence, we have
S[q0 +
√
¯hy]
=
S[q0] + ¯hS2[y; q0] + O(¯h3/2)
S2[y; q0]
=
Z tb
ta
dt
1
2L ˙q ˙q ˙y2 + L ˙qq ˙yy + 1
2Lqqy2

(14.53)
where the coeﬃcients are given by
L ˙q ˙q = ∂2L
∂˙q2

q=q0
L ˙qq = ∂2L
∂˙q∂q

q=q0
Lqq = ∂2L
∂q2

q=q0
(14.54)
Notice that, for a general Lagrangian L, all three coeﬃcients L ˙q ˙q, L ˙qq, Lqq will be non-vanishing
and may be τ-dependent. In the case of the standard Lagrangian,
L = 1
2m ˙q2 −V (q)
(14.55)
the problem is much simpliﬁed though and we have
L ˙q ˙q = m
L ˙qq = 0
Lqq = −V ′′(q0(t))
(14.56)
The Gaussian action is then simply,
S2[y; q0]
=
Z tb
ta
dt
1
2m ˙y2 −1
2V ′′(q0)y2

=
1
2
Z tb
ta
dt y(t)
 
−m d2
dt2 −V ′′(q0(t))
!
y(t)
(14.57)
The energy levels and wave-functions of the harmonic oscillator could be recovered in this way (see
homework problem).
14.9
Gaussian integrals
We shall compute the Gaussian integrals for real and complex variables, and show that
Z
dNX exp
n
−πτXtMX
o
=
1
(det(τM))
1
2
Z
dNZdN ¯Z exp
n
−2πτZ†HZ
o
=
1
det(τH)
(14.58)
190

Here, X and Z are respectively a real and a complex column matrix of height N. These variables
and their associated measures may be parametrized as follows,
X =




x1
x2
·
xN




Z =




z1
z2
·
zN




dNX = dx1dx2 · · · dxN
dNZdN ¯Z = d2z1d2z2 · · · d2zN
(14.59)
The measure on z is deﬁned by d2z = dRe(z) dIm(z). The measures are invariant under orthogonal
rotations of X and unitary transformations of Z. The N × N matrices M and H are respectively
real symmetric and Hermitian. Both M and H are assumed to be positive, i.e. all their eigenvalues,
respectively mi and hi are positive. Finally, the complex parameter τ is required to have Re(τ) > 0
for absolute convergence of the integral.
We shall now prove the above Gaussian integral formulas. Using the fact that any real symmetric
matrix M can be diagonalized by an orthogonal change of basis, and that any Hermitian matrix
H may be diagonalized by a unitary change of basis, we have
Z
dNX exp
n
−πτXtMX
o
=
N
Y
i=1
Z
dxi e−πτmix2
i

Z
dNZdN ¯Z exp
n
−2πτZ†HZ
o
=
N
Y
i=1
Z
d2zi e−2πτhi|zi|2
(14.60)
It remains to carry out a single real or complex Gaussian integral. We do this ﬁrst for τ real and
then analytically continue in τ. The complex integral is readily carried out in polar coordinates,
zi = rieiφi for 0 ≤ri < ∞and 0 ≤φi < 2π. We ﬁnd,
Z
d2zi e−2πτhi|zi|2 = 2
Z 2π
0
dφi
Z ∞
0
dri ri e−2πτhir2
i =
1
τhi
(14.61)
Recasting this complex integral in real Cartesian coordinates, zi = (xi + iyi)/
√
2, we see that the
complex integral is the square of the real integral evaluated for mi = hi, and thus,
Z
dxi e−πτmix2
i =
1
√τmi
(14.62)
Using the deﬁnition of the determinants for τM and τH in terms of the products of their eigenvalues,
we immediately recover the desired integrals. Note that, as Re(τ) →0, we recover an integral which
is not absolutely convergent, but which is conditionally convergent. Its conditional convergence
prescription may be taken to be limit Re(τ) →0.
14.10
Evaluating the contribution of Gaussian ﬂuctuations
The contribution of Gaussian ﬂuctuations around a given dominant path q0(t) is given by the
Gaussian functional integral,
Z
Dy exp
 i
2
Z tb
ta
dt y(t)M(t)y(t)

(14.63)
191

for the operator M(t), deﬁned by
M(t) = −m d2
dt2 −V ′′(q0(t))
(14.64)
and subject to the boundary conditions y(ta) = y(tb) = 0. We will now show that, if the complete
spectrum of the self-adjoint operator M(t) (subject to the above boundary conditions) is known,
then this functional integral of Gaussian ﬂuctuations can be computed. Let the eigenfunctions
φn(t) satisfy
M(t)φn(t) = λnφn(t)
(14.65)
subject to φn(ta) = φn(tb) = 0. Since M(t) is self-adjoint, the eigenvalues λn are real and the
eigenfunctions φn(t) span an orthonormal basis of the function space for y(t). Since M(t) is actually
real, we may choose a basis of real functions φn(t), obeying
Z tb
ta
dt φn(t)φn′(t)
=
δn,n′
X
n
φn(t)φn(t′)
=
δ(t −t′)
ta ≤t, t′ ≤tb
(14.66)
The completeness of φn(t) allows us to expand
y(t) =
X
n
cnφn(t)
(14.67)
for real coeﬃcients cn. Since the metric on function space and on the cn are related by
Z tb
ta
dt δy(t)2 =
X
n
(δcn)2
(14.68)
the change of variables y(t) →{cn} has unit Jacobian, and we have
Dy =
Y
n
(dcn)
(14.69)
It is now also straightforward to evaluate
Z tb
ta
dt y(t)M(t)y(t) =
X
n
λn(cn)2
(14.70)
so that the entire functional integral over Gaussian ﬂuctuations becomes,
Z
Dy exp
 i
2
Z tb
ta
dt y(t)M(t)y(t)

=
Y
n
Z
dcn exp
 i
2λn(cn)2

=
Y
n
λ
−1
2
n
(14.71)
Relating the product of the eigenvalues to the determinant, one often writes,
Z
Dy exp
 i
2
Z tb
ta
dt y(t)M(t)y(t)

= Det
 
−m d2
dt2 −V ′′(q0(t))
!−1
2
(14.72)
192

15
Applications and Examples of Path Integrals
In this section, we shall illustrate the use of path integrals and give examples of their calculation
for simple examples. They include the harmonic oscillator, the Aharonov-Bohm eﬀect, the Dirac
magnetic monopole, imaginary time path integrals and the path integral formulation of statistical
mechanics. We shall end by introducing the Ising model and solving it for the one dimensional
case.
15.1
Path integral calculation for the harmonic oscillator
The classical Lagrangian is by now familiar,
L = 1
2m ˙q2 −1
2mω2q2
(15.1)
The dominant path is the classical trajectory between (qa, ta) and (qb, tb), which obeys the classical
equation ¨q0 + ω2q0 = 0, and is given by
q0(τ)
=
qa cos ω(t −ta) + B sin ω(t −ta)
qb
=
qa cos ωT + B sin ωT
(15.2)
where T = tb −ta, and the solution for B is
B = qb −qa cos ωT
sin ωT
(15.3)
The associated classical action may be evaluated by exploiting the extremality of the action,
S = m
2
Z tb
ta
dt
 d
dt(q0 ˙q0) −q0¨q0 −ω2q2
0

= m
2 (q0 ˙q0)(t)

t=tb
t=ta
(15.4)
which yields explicitly,
eiS/¯h = exp

imω
2¯h sin ωT
h
(q2
a + q2
b) cos ωT −2qaqb
i
(15.5)
To compute the functional determinant, we solve for the eigenfunctions of
−m d2
dt2 φn(t) −mω2φn(t) = λnφn(t)
(15.6)
subject to φn(ta) = φn(tb) = 0. The normalized solutions are
φn(t) =
r 2
T sin
nπ(t −ta)
T

n = 1, 2, 3, · · ·
(15.7)
and the eigenvalues are
λn = m
 
π2n2
T 2
−ω2
!
= mπ2n2
T 2
 
1 −ω2T 2
π2n2
!
(15.8)
193

The product of the eigenvalues may ﬁrst be deﬁned up to a level n ≤N,
N
Y
n=1
λn =
N
Y
n=1
"
mπ2n2
T 2
 
1 −ω2T 2
π2n2
!#
(15.9)
Clearly, the ﬁrst factor in the product is independent of ω, so we may write
N
Y
n=1
λn = NN
N
Y
n=1
 
1 −ω2T 2
π2n2
!
NN =
N
Y
n=1
 
mπ2n2
T 2
!
(15.10)
The N →∞limit of the inﬁnite product involving ω is convergent, and is related to the inﬁnite
product representation of the sin x function, which is given by
sin x = x
∞
Y
n=1
 
1 −π2x2
n2
!
(15.11)
Thus we have
N
Y
n=1
 
1 −ω2T 2
π2n2
!
= sin ωT
ωT
(15.12)
The N →∞limit of the product NN, however, does not converge. This divergence results from the
fact that a precise calculation of the absolute overall normalization of the path integral would have
required more care than we have applied here. But the most important property of NN is that it is
independent of ω for all values of N. Instead of attempting to calculate this proper normalization
from ﬁrst principles, we shall leave the overall normalization undetermined, and represent it by
a multiplicative factor N which is independent of ω. We shall then ﬁx N by matching with the
known case of the free particle corresponding to ω = 0. Putting all together, we have,
∞
Y
n=1
λn = N sin ωT
ωT
(15.13)
where N is independent of ω. Assembling the entire path integral representation of the matrix
elements of the evolution operator, and matching the overall normalization with that of the free
particle for ω = 0, given in (14.17), we ﬁnd N = 2πi¯h/m, and thus,
⟨qb|U(tb −ta)|qa⟩=

mω
2πi¯h sin ωT
 1
2 exp

imω
2¯h sin ωT
h
(q2
a + q2
b) cos ωT −2qaqb
i
(15.14)
It is good practice to double check this result in the following way. We compute the trace of the
evolution operators by integrating over q = qa = qb,
Tr

U(T)

=
Z
dq⟨q|U(T)|q⟩
=
Z
dq

mω
2πi¯h sin ωT
 1
2 exp
(
imωq2
¯h sin ωT (cos ωT −1)
)
=
−i
2 sin ωT/2 =
e−iωT/2
1 −e−iωT
(15.15)
194

Expanding in powers of the exponential, we ﬁnd,
Tr

U(T)

=
∞
X
n=0
e−iTEn/¯h
En = ¯hω

n + 1
2

(15.16)
and recover the energy levels of the harmonic oscillator, each one with multiplicity 1.
15.2
The Aharonov-Bohm Eﬀect
In classical electrodynamics, the motion of charged particles is completely determined by the electric
E and magnetic B ﬁeld strengths. This is because in classical physics, the equations of motion
completely determine the dynamics, and for charged particles, the force is completely speciﬁed by
the Lorentz formula,
F = eE + ev × B
(15.17)
Here, F is the force exerted on a particle of charge e and velocity v = dx/dt. The gauge potentials
(Φ, A) are usually introduced only as auxiliary variables, when deriving the ﬁeld equations from a
Lagrangian or from a Hamiltonian. Indeed, these quantities are given by
L
=
1
2mv2 + eA(t, x) · v −eΦ(t, x)
H
=
1
2m (p −eA(t, x))2 + eΦ(t, x)
(15.18)
We have local gauge invariance, under Φ →Φ −∂Λ/∂t and A →A + ⃗∇Λ. For example, the
Lagrangian transforms as follows, L →L + e dΛ/dt.
Figure 17: The Aharonov-Bohm set-up (ﬁgure from Sakurai)
In quantum mechanics, the dynamics of charged particles involves the vector potential in a
fundamental way, either in the Hamiltonian operator formulation or in the Lagrangian path integral
formulation. The Aharonov-Bohm eﬀect is one of the most striking examples of the fundamental
role played in quantum mechanics by the vector potential.
The set-up is as in Fig 9. Consider an inﬁnite cylinder along the z-axis, of which only a cross-
section in the x −y plane in shown in Fig 9. The cylinder is impenetrable, so the particle we study
195

can never penetrate inside. We assume vanishing electric ﬁeld throughout, so that Φ = 0. On the
outside of the cylinder, the magnetic ﬁeld vanishes identically. On the inside of the cylinder, there is
a time-independent magnetic ﬁeld B, which points in the z-direction, and produces a magnetic ﬂux
ΦB. Such a magnetic ﬁeld may be produced by an inﬁnite solenoid. Because of Stokes’ theorem,
the gauge potential outside the cylinder cannot vanish, because it must reproduce the total ﬂux
inside the cylinder,
I
C
A · dx = ΦB
(15.19)
where C is any curve encircling the impenetrable cylinder once.
Next, we compare the probability amplitude for the charged particle to travel from point A
to point B of Fig 9, either above or below the cylinder. We denote the paths above and below
respectively by C+ and C−. The amplitudes are given by
⟨B|U(tb −ta)|A⟩C± =
Z
Dx exp
 i
¯h
Z tb
ta
dt LC±

(15.20)
The actions may be compared by assuming that the path C−is exactly the mirror image of path
C+, so that the contribution of the kinetic terms in both are identical. The only diﬀerence is then
due to the magnetic term, so that
Z tb
ta
dt LC+ −
Z tb
ta
dt LC−
=
e
Z tb
ta
dt A(x) · dx
dt

C+−C−
=
e
Z tb
ta
A(x) · dx

C+−C−
=
e
Z
C
A(x) · dx = eΦB
(15.21)
where we have used the fact that C+ −C−= C. As a result,
⟨B|U(tb −ta)|A⟩C+ = ⟨B|U(tb −ta)|A⟩C−exp
ieΦB
¯h

(15.22)
For an arbitrary magnetic ﬂux, ΦB, and electric charge e, there will be a non-trivial phase diﬀer-
ence between the probability amplitudes along paths C+ and C−, and as a result, there will be
interference when these paths merge at point B. On the other hand, the solenoid will be quantum
mechanically unobservable provided the magnetic ﬂux is quantized, and takes on integer multiple
values of the basic magnetic ﬂux quantum (for the electron charge e) of
Φ(0)
B = 2π¯h
e
∼4.135 × 10−7 Gauss × cm2 = 4.135 × 10−15 Tm2
(15.23)
Note that the interference is purely quantum mechanical, it has no classical counterpart. Also, we
have never needed the explicit form of the vector potential, only its role in generating a non-zero
ﬂux. It is possible to solve this problem using the Schr¨odinger equation, but then a speciﬁc A must
be chosen.
196

15.3
Imaginary time path Integrals
If we formally replace t →−iτ and consider τ real, then we obtain the imaginary time or Euclidean
formulation of quantum mechanics. Often, one also refers to this procedure as analytic continuation
to imaginary time because the substitution t →−iτ can be regarded as an analytic continuation.
The evolution operator becomes
UE(τ) = e−τH/¯h
(15.24)
and is formally related to the customary evolution operator by UE(τ) = U(iτ). Notice, however,
that U(t) and UE(τ) are very diﬀerent objects: most importantly, UE(τ) is NOT a unitary operator
for real τ.
It is possible to obtain a path integral representation for the matrix elements of UE(τ), just as
we obtained one for U(t). Instead of working out this path integral representation from scratch,
we may simply obtain it by analytic continuation, t →−iτ,
⟨qb|UE(τb −τa)|qa⟩=
Z
Dq exp

−1
¯h
Z τb
τa
dτ LE(q, ˙q)

(15.25)
subject to the boundary conditions,
q(τa)
=
qa
q(τb)
=
qb
(15.26)
Here, the prefactor −1/¯h, and the Euclidean Lagrangian LE are obtained as follows. In view of
t →−iτ, we have,
Z
dt →−i
Z
dτ
(15.27)
and the Euclidean Lagrangian becomes,
L

q(t), dq(t)
dt

= −LE

q(τ), dq(τ)
dτ

(15.28)
Strictly speaking, we should also put a subscript E on the basic variables q, so that q(t) = qE(τ),
but we shall omit this to save some notation. For the simplest Lagrangians, we have,
L
=
1
2m
dq
dt
2
−V (q)
LE
=
1
2m
 dq
dτ
2
+ V (q)
(15.29)
Note that, at least for these simplest cases, the argument of the exponential in the path integral is
now real and generally leads to a damped fall-oﬀfor large q(τ). This renders the Euclidean path
integral well-deﬁned even to the standards of mathematical rigor !
197

For the free case (V = 0), we have LE = 1
2m ˙q2, so that
⟨qb|UE(τb −τa)|qa⟩=
s
m
2π¯h(τb −τa) exp
(
−m(qb −qa)2
2¯h(τb −τa)
)
(15.30)
which is truly a Gaussian. Notice that for the free particle, this matrix element satisﬁes the heat
equation,
 
∂
∂τ + ¯h
2m
∂2
∂q2
!
⟨q|UE(τ −τa)|qa⟩= 0
(15.31)
with the initial condition that
⟨q|UE(τa −τa)|qa⟩= δ(q −qa)
(15.32)
Its physical interpretation is as follows. We place a δ-function heat distribution at the point qa
at time ta, and then observe the heat diﬀuse over q as a function of time τ; this is given by the
function ⟨q|UE(τ −τa)|qa⟩.
15.4
Quantum Statistical Mechanics
The operator e−τH/¯h is closely related to the Boltzmann operator e−βH of statistical mechanics.
We introduce the standard notation,
β ≡
1
kBT
(15.33)
where T is temperature and kB is the Boltzmann constant. In any energy eigenstate |En⟩of H,
the Boltzmann operator takes on the deﬁnite value
e−βH|En⟩= e−βEn|En⟩
(15.34)
and thus provides the standard Boltzmann weight for a state with energy En.
The starting point of equilibrium statistical mechanics in the canonical ensemble is the partition
function, which is deﬁned by
Z ≡Tr

e−βH
=
X
n
e−βEn
(15.35)
In the second equality, we have expanded the trace in a basis of eigenstates of H which are labeled
by n, and whose energy is En. Their multiplicities are properly included by summing, for each En
over all the states with energy En. All other thermodynamic functions may be expressed in terms
of the partition function. The free energy F is deﬁned by
Z = e−βF
or
F = −1
β ln Z = −kBT ln Z
(15.36)
198

The internal energy E and the entropy S are related to the free energy by
F = E −TS
(15.37)
Both may be expressed in terms of the partition function as well,
E
=
−∂ln Z
∂β
S
=
−∂F
∂T
(15.38)
It is instructive to work out the internal energy in a basis of energy eigenstates,
E = 1
Z
X
n
Ene−βEn
(15.39)
A useful interpretation of these expressions is obtained by introducing the notion of the statistical
probability Pn for ﬁnding the system in a state n with energy En. The statistical probability is
deﬁned as the normalized Boltzmann weight,
Pn ≡e−βEn
Z
X
n
Pn = 1
(15.40)
The internal energy then takes on a natural form,
E =
X
n
EnPn
(15.41)
The entropy may also be conveniently expressed in terms of the Pn,
S = −kB
X
n
Pn ln Pn
(15.42)
Some authors (such as Feynman) actually take the last formula as the deﬁnition for the entropy.
This deﬁnition is also closely related to information theory deﬁnition of entropy (see Shannon).
15.5
Path integral formulation of quantum statistical mechanics
There is a simple and suggestive formula for the partition function (and in view of the preceding
subsection, thus for all thermodynamic quantities) in terms of the Euclidean path integral. The cor-
respondence between the Boltzmann operator e−βH and the Euclidean evolution operator e−τβH/¯h
is fully brought out by the equality
¯hβ = τβ
(15.43)
The trace, needed for the partition function, may be expressed as an integral over q,
Z = Tr e−βH =
Z
dq ⟨q|e−βH|q⟩
(15.44)
199

The general matrix elements of the Boltzmann operator may now be expressed using the Euclidean
path integral,
⟨q′|e−βH|q⟩=
Z
Dq exp
(
−1
¯h
Z ¯hβ
0
dτ LE(q, ˙q)
)
(15.45)
subject to the boundary conditions,
q(0)
=
q
q(¯hβ)
=
q′
(15.46)
Here, LE is the Euclidean Lagrangian corresponding to the Hamiltonian H.
To complete the
construction of the partition function, we need to set q′ = q and then integrate over all q. But this
instruction simply means that we should integrate in the path integral over all functions q(τ) which
are periodic in τ with period ¯hβ. Thus, we arrive at the following ﬁnal formula for the partition
function,
Z =
Z
Dq exp
(
−1
¯h
Z ¯hβ
0
dτ LE(q, ˙q)
)
q(¯hβ) = q(0)
(15.47)
and it is understood that the actual value of q(¯hβ) = q(0) is also integrated over, as part of the
functional integral
R Dq.
15.6
Classical Statistical Mechanics as the high temperature limit
In the large T (equivalently, small β) limit, many quantum states are occupied, and the system is
expected to behave classically. It is possible to recover this limit from the general path integral
formula given above. We carry out the limit here as an illustration of path integral methods.
In the limit β →0, the interval of periodicity of q(τ) becomes small. It is useful to decompose
q(τ) in an orthonormal basis of periodic functions on the interval [0, ¯hβ],
q(τ) =
+∞
X
n=−∞
cn e2πinτ/(¯hβ)
c∗
n = c−n
(15.48)
The reality condition c∗
n = c−n is needed to guarantee that the functions q(τ) be real. The thermal
or Matsubara frequencies
ωn = 2πn
¯hβ
(15.49)
govern the magnitude of the kinetic terms in LE. When β →0, the frequencies ωn become large as
long as n ̸= 0. The frequency ω0 vanishes for all β and requires zero cost in kinetic energy for this
mode. Thus, the kinetic energy will suppress all the modes with n ̸= 0, and only the mode n = 0
will survive at high temperature. We shall denote this mode by c0 = q. As a result,
Z(β →0) =
Z +∞
−∞
dq e−βV (q)
Z
D′q exp
(
−1
¯h
Z ¯hβ
0
dτ 1
2m ˙q2
)
(15.50)
200

The contribution of the second factor is being kept as a subdominant eﬀect, which may be evaluated
since it corresponds to the partition function of the free particle. Here, D′q stands for the instruction
that the constant mode corresponding to c0 has to be removed from this integration. In terms of
the Fourrier component modes, this measure is given by
D′q =
Y
n̸=0
dcn
(15.51)
We then have
Z
D′q exp
(
−1
¯h
Z ¯hβ
0
dτ 1
2m ˙q2
)
=
s
m
2π¯h2β
(15.52)
Comparing with the partition function of classical statistical mechanics,
Zclassical =
Z Z
dpdq e−βH(q,p) =
Z +∞
−∞
dq e−βV (q)
Z +∞
−∞
dp e−βp2/(2m)
(15.53)
we ﬁnd that
Z(β →0) =
1
√
2π2¯h2 Zclassical
(15.54)
The constant factor merely reﬂects an unphysical overall normalization. It implies that the classical
free energy diﬀers from the quantum one by a constant shift, which is physically unobservable.
201

16
Mixtures and Statistical Entropy
In this section, the notion of statistically mixed ensembles, of pure and mixed states, of coherent and
incoherent superpositions are introduced and the corresponding formalism of the density operator
or equivalently, of the density matrix is developed.
16.1
Polarized versus unpolarized beams
In chapter 2, we introduced the interference properties of quantum mechanics using the physical
examples of the polarization states of light or of a spin 1/2 particle.
In any of these set-ups,
the ﬁrst piece of apparatus used was always a polarizer, which was responsible for ﬁltering a
deﬁnite polarization out of an unpolarized beam. We have then obtained a complete mathematical
description of the polarized beam in terms of vectors in a Hilbert space of states. In particular,
a polarized beam of light should be viewed as an ensemble of photons which are all in the same
quantum state. Similarly, a polarized beam of Silver atoms in the Stern-Gerlach experiment should
be viewed as an ensemble of spins which are all in the same quantum state. In each case, the
quantum state of all particles in the beam are identical to one another. The phases of the various
individual photons are all the same, and the ensemble of states in the beam is said to be coherent.
What we have not yet given is a mathematical description for a beam which is unpolarized
(or partially polarized). The deﬁning property of an unpolarized beam of light is as follows. We
consider a beam propagating in the z-direction, and insert a (perfect) polarizer transverse to the
beam at an angle θ with respect to the x-axis. Next, we measure the probability Pθ for observing
photons as a function of the angle θ. (Recall that for a beam polarized in the x-direction, we have
Pθ = cos2 θ.) The beam is upolarized provided the probability Pθ is independent of the angle θ.
Analogously, the deﬁning property of an unpolarized beam of spin 1/2 particles is as follows.
Take a beam propagating in the x-direction, and insert a Stern-Gerlach apparatus oriented in a
direction n where n2 = 1. Next, we measure the probability Pn for observing the spins in the
quantum state n · S = +¯h/2 as a function of n. (Recall that for a beam of spins with Sz = +¯h/2,
this probability is n2
z.) The beam is unpolarized provided the probability for observing n·S = +¯h/2
is Pn = 1/2 for any angle n.
An unpolarized beam cannot be described mathematically as a state in Hilbert space. We can
easily see why for the spin 1/2 case, for example. If the unpolarized beam did correspond to a state
Ψ⟩in Hilbert space, then measuring the probability for observing the spins in a quantum state with
n · S = +¯h/2 would amount to
Pn = |⟨n|Ψ⟩|2
(16.1)
where |n⟩is the +¯h/2 eigenstate of n · S. If |Ψ⟩is a state in this same 2-dimensional Hilbert space,
then we may decompose it onto the basis |±⟩as well, |Ψ⟩= a|+⟩+ b|−⟩, with |a|2 + |b|2 = 1. Using
the result of Problem 1 in Problem set 2 of 221A, every unit vector n corresponds to a unitary
rotation U(n) in Hilbert space, n · S = U(n)SzU †(n), so that the eigenstate |n⟩of n · S with
eigenvalue +¯h/2 is concretely given by |n⟩= U(n)|+⟩. Parametrizing n by Euler angles, θ, ψ, we
202

get, up to an immaterial overall phase,
|n⟩= cos θ eiψ|+⟩+ sin θ e−iψ|−⟩
(16.2)
so that
Pn =
a cos θ e−iψ + b sin θ eiψ
2
(16.3)
Demanding that the probability be independent of n is tantamount to demanding that it be inde-
pendent of θ and ψ. Evaluating it for α = 0, π/2 gives |a| = |b|, so that we may set a = |a|eiα and
b = |a|eiβ, so that
Pn = |a|2 cos θ + sin θ e2iψ+iβ−iα
2 = |a|2
(16.4)
which requires |a|2 cos(2ψ + β −α) = 0, for all ψ. This is possible only if |a| = 0, but then we
would have |a|2 + |b|2 = 0, which contradicts the normalization of the state. We conclude that an
unpolarized beam cannot be described mathematically by a state in Hilbert space.
16.2
The Density Operator
A new mathematical tool is needed to describe the particles in both polarized, unpolarized and
partially polarized beams. This formalism was introduced by John von Neumann in 1927, and
the key object is referred to traditionally referred to as the density operator, but it is actually
more accurate to designate it as the state operator, since this object will characterize a state of a
quantum system.
A pure ensemble, by deﬁnition, is a collection of physical systems such that every member of
the ensemble is characterized by the same element |ψ⟩in Hilbert space.
A mixed ensemble, by deﬁnition, is a collection of physical systems such that a fraction of the
members is characterized by a pure state |ψ1⟩, another fraction of the members is characterized
by a pure state |ψ2⟩, and so on. We shall assume that each pure state ket |ψi⟩is normalized.
Thus, a mixed ensemble is characterized by a number N of pure states, |ψi⟩for i = 1, · · · , N. Each
pure state |ψi⟩enters into the mixed state with a population fraction wi ≥0, which quantitatively
indicates the proportion of state |ψi⟩in the mixture. The population fractions are normalized by
N
X
i=1
wi = 1
(16.5)
A mixture is an incoherent superposition of pure states which means that all relative phase infor-
mation of the pure states must be lost in the mixture. This is achieved by superimposing, not the
states |ψi⟩in Hilbert space, but rather the projection operators |ψi⟩⟨ψi| associated with each pure
state. The density operator ρ for an ensemble of N pure states |ψi⟩incoherently superimposed
with population fractions wi is deﬁned by
ρ =
N
X
i=1
|ψi⟩wi⟨ψi|
(16.6)
203

Since the superpositions involved here are incoherent, the weights wi may be thought of as classical
probability weights assigned to each population. Note that we do not require that the various
diﬀerent pure states |ψi⟩be orthogonal to one another, since it should certainly be possible to
superimpose pure states which are not orthogonal to one another.
The following properties of the density operator immediately result,
1. Self-adjointness : ρ† = ρ;
2. Unit trace : Tr(ρ) = 1;
3. Non-negative : ⟨ψ|ρ|ψ⟩≥0 for all |ψ⟩∈H.
Conversely, any operator in H with the above three properties is of the form of (16.6) with nor-
malization (16.5), but some subtleties must be noted. Self-adjointness guarantees that ρ can be
diagonalized in an orthonormal basis |φi⟩, with real eigenvalues pi,
ρ =
X
i
|φi⟩pi⟨φi|
(16.7)
Non-negativity then implies that pi ≥0 for all i, and unit trace forces
X
i
pi = 1
(16.8)
Note that |φi⟩need not coincide with |ψi⟩, not even up to a phase, and pi need not coincide with
wi. Thus, a given density operator will have several equivalent representations in terms of pure
states. We shall now illustrate this phenomenon by some examples.
Pure states are also described by the density operator formalism. A pure state |ψj⟩corresponds
to the case where the mixture actually consists of only a single pure state, wj = 1, and wi = 0 for
all i ̸= j. In that case, ρ2 = ρ, so that the density operator is a projection operator, namely onto
the pure state |ψj⟩. Conversely, a density operator ρ (i.e. an operator which satisﬁes the above
three properties) which is also a projection operator ρ2 = ρ correspond to a pure state. It is easiest
to show this in the orthonormal representation of ρ derived in (16.7). The condition ρ2 = ρ then
implies
X
i
|φi⟩pi(pi −1)⟨φi| = 0
(16.9)
As a result, we must have pi(pi −1) = 0 for all i, so that either pi = 0 or pi = 1. The normalization
condition (16.77) then implies that pi can be equal to 1 only for exactly a single pure state. Note
that the density operator is an economical way to describe pure states, since the normalization of
the states, and the omission of the overall phase have automatically been incorporated.
204

16.2.1
Ensemble averages of expectation values in mixtures
In a pure normalized state |ψ⟩, we deﬁned the expectation value of an observable A by the matrix
element ⟨ψ|A|ψ⟩= Tr

A|ψ⟩⟨ψ|

, a quantity that gives the quantum mechanical weighed probability
average of the eigenvalues of A.
In a mixed state, these quantum mechanical expectation values must be further weighed by
the population fraction of each pure state in the mixture. One deﬁnes the ensemble average of the
observable A by
Tr(ρA)
=
X
i
Tr

A|ψi⟩wi⟨ψi|

=
X
i
wi⟨ψi|A|ψi⟩
(16.10)
It follows from the properties of the density operator that the ensemble average of any self-adjoint
operator is real.
16.2.2
Time evolution of the density operator
Any quantum state |ψ(t)⟩in the Schr¨odinger picture evolves in time under the Schr¨odinger equation,
i¯h d
dt|ψ(t)⟩= H|ψ(t)⟩
(16.11)
Assuming that the population fractions wi and pi do not change in time during this evolution, the
density operator ρ(t) then obeys the following time evolution equation,
i¯h d
dtρ(t) = [H, ρ(t)]
(16.12)
To prove this formula, one ﬁrst derives the time evolution equation for |ψ(t)⟩⟨ψ(t)| and then takes
the weighed average with the time-indepenent population fractions. This time evolution may be
solved for in terms of the unitary evolution operator U(t) = e−itH/¯h, by
ρ(t) = U(t)ρ(0)U(t)†
(16.13)
Notice that the normalization condition Tr(ρ) = 1 is automatically preserved under time evolution.
16.3
Example of the two-state system
Consider the two-state system of a spin 1/2, expressed in the eigenbasis of Sz, given by the states
|z+⟩and |z−⟩. Below are three examples of the density matrix evaluated for pure states.
• Polarized along the Sz direction with eigenvalue +¯h/2, the state is |z+⟩, and the correspond-
ing density operator is ρ = |z+⟩⟨z + |. The ensemble averages are tr(ρSx) = tr(ρSy) = 0,
and tr(ρSz) = +¯h/2.
205

• Polarized along the Sz direction with eigenvalue −¯h/2, the state is |z−⟩, and the correspond-
ing density operator is ρ = |z−⟩⟨z −|.
• Polarized along the Sx direction with eigenvalue ±¯h/2, the state is |x±⟩= (|z+⟩±|z−⟩)/
√
2,
and the corresponding density operator is ρ = (|z+⟩± |z−⟩)(⟨z + | ± ⟨z −|)/2.
From these pure states, we construct mixed states, and their associated density operators. First,
we compute the density operators for unpolarized mixtures. Mixing 50% of |z+⟩and 50% of |z−⟩
states produces the density matrix
ρ
=
1
2|z+⟩⟨z + | + 1
2|z−⟩⟨z −|
=
1
2 I
(16.14)
Mixing 50% of |x+⟩and 50% of |x−⟩states produces the density matrix
ρ
=
1
2|x+⟩⟨x + | + 1
2|x−⟩⟨x −|
=
1
4

|z+⟩+ |z−⟩

⟨z + | + ⟨z −|

+ 1
4

|z+⟩−|z−⟩

⟨z + | −⟨z −|

=
1
2 I
(16.15)
We see that equal mixture of |z±⟩states produce the same quantum mechanical state as the
equal mixture of |x±⟩states.
This is good new, because after all, we aimed at constructing a
characterization of an unpolarized beam. The ensemble averages of S all vanish tr(ρS) = 0 in the
unpolarized state.
Finally, let us derive the density matrix for the mixture of 50% of |z+⟩and 50% of |x+⟩pure
states,
ρ = 1
2|z+⟩⟨z + | + 1
2|x+⟩⟨x + | =
 3
4
1
4
1
4
1
4

(16.16)
Even though the pure states |z+⟩and |x+⟩are not orthogonal to one another, the resulting density
matrix is perfectly ﬁne. The eigenvalues of ρ are (2±
√
2)/4 and represent the population fractions
in an orthonormal basis. The ensemble averages are tr(ρSx) = ¯h/4, tr(ρSy) = 0, and tr(ρSz) = ¯h/4,
indicating that the mixture is partially polarized.
The most general density matrix for the two-state system may be constructed by solving for its
axioms one by one. Hermiticity of a 2 × 2 matrix ρ allows us to put it in the following
ρ = 1
2

a0I + a1σ1 + a2σ2 + a3σ3
= 1
2

a0I + a · σ

(16.17)
where σ1,2,3 are the three Pauli matrices, and a0, a1, a2, a3 are real. The unit trace condition forces
a0 = 1. Finally, positivity of the the matrix is equivalent to positivity of its eigenvalues. Since
206

tr(ρ) = 1, at least one of the eigenvalues must be positive. The sign of the other eigenvalue is
then determined by the sign of det(ρ), since this is just the product of the two eigenvalues. The
determinant is readily computed, and we ﬁnd,
det(ρ) = 1
4(1 −a2)
(16.18)
Thus, positivity of the eigenvalues will be guaranteed by
ρ = 1
2

I + a · σ

|a| ≤1
(16.19)
This space is referred to as the Bloch ball, parametrized by |a| ≤1. Pure states, for which ρ is a
rank 1 projection operator, precisely correspond to the boundary |a| = 1 sphere, called the Bloch
sphere. On the other hand, any density operator with |a| < 1 corresponds to a mixed state. The
state is unpolarized |a| = 0, and partially polarized for 0 < |a| < 1. This gives a geometrical
presentation of the space of density matrices for the two-state system.
16.4
Non-uniqueness of state preparation
The set of all density operators for a given system forms a convex set. Thus, if ρ1 and ρ2 are two
arbitrary density operators, then the operator
ρ(λ) = λρ1 + (1 −λ)ρ2
(16.20)
is again a density operator for any λ such that 0 ≤λ ≤1. This is shown by verifying that ρ(λ)
indeed satisﬁes the three deﬁning properties of a density operator.
The physical interpretation of this property leads to one of the key distinctions between classical
and quantum information theory.
Consider an experimental set up where the system may be
prepared either in the state associated with ρ1 or in the state corresponding to ρ2. We assign a
probability λ that the system be prepared in state ρ1 and a probability 1 −λ that it be prepared
in state ρ2. The ensemble average of the expectation value of any observable A is then obtained
by taking the quantum mechanical expectation value, weighted by the probabilities for preparation
either in state ρ1 or in state ρ2,
⟨A⟩= λtr(ρ1A) + (1 −λ)tr(ρ2A) = tr

ρ(λ)A

(16.21)
Thus, the expectation value of any observable are indistinguishable from what we would obtain if
they had been computed directly in the state ρ(λ). In fact, our two-state example of the preceding
subsection illustrated already this property. The totally unpolarized density operator could have
been gotten either by equal populations of Sz = ±¯h/2, or equal populations of Sx = ±¯h/2, and in
the ﬁnal state, you could never tell the diﬀerence. Clearly, for any mixed state, there would be an
inﬁnite number of diﬀerent ways of preparing the state, unless the state was actually pure and then
there is only a single way. For the sake of completeness, we note that if the eigenvalues of ρ are
distinct, then there is a unique way of preparing the system in terms mutually orthogonal density
operators, but allowing for non-orthogonal density operators, the preparation is again not unique.
This situation is to be contrasted with the preparation of a classical ensemble, which is unique,
given the probabilities.
207

16.5
Quantum Statistical Mechanics
One particularly important special case of mixed states and ensembles is provided by equilibrium
quantum statistical mechanics. Consider a system described by a time independent Hamiltonian
H, whose eigenstates and eigenvalues will be denoted by |En; α⟩and En respectively. Here α stands
for additional quantum numbers which characterize diﬀerent states at the same energy En. The
states |En; α⟩will be assumed to be orthonormal. Already in Chapter 8 have we introduced the
standard statistical mechanical quantities such as the partition function Z, and the Boltzmann
weight pn of a state with energy En, given by
Z
=
Tr

e−βH
β =
1
kBT
pn
=
e−βEn
Z
(16.22)
From the Boltzmann weights, we can now compute the density operator,
ρ =
X
n,α
|En; α⟩pn⟨En; α|
(16.23)
Using the fact that in the orthonormal basis |En; α⟩we have,
X
n,α
|En; α⟩e−βEn⟨En; α| = e−βH
(16.24)
the density operator takes on a particularly simple form,
ρ =
e−βH
Tr (e−βH)
(16.25)
This expression makes the deﬁning properties of the density operator manifest; it is self-adjoint,
since H is; it has unit trace; and it is non-negative since H is self-adjoint and has only real
eigenvalues.
Other thermodynamic quantities similarly have simple expressions.
The internal
energy is the ensemble average of the Hamiltonian,
E = 1
Z
X
n,α
En e−βEn = Tr(ρE)
(16.26)
Similarly, the entropy is given by
S = −kB
X
n,α
pn ln pn = −kBTr

ρ ln ρ

(16.27)
In fact, one may take the entropy as the starting point for thermodynamics, and then use it to
derive the Boltzmann distribution. Working in the canonical ensemble, one keeps the energy ﬁxed
and maximizes the entropy given this constraint. The standard way of doing this in practice is to
208

introduce Lagrange multipliers for the constant energy condition, as well as for the condition of
unit trace of ρ. Thus, we extremize, as a function of ρ, the quantity
−Tr

ρ ln ρ

−βTr(ρH) −γTr(ρ)
(16.28)
under the condition that
Tr(ρ) = 1
(16.29)
The corresponding equation reads,
Trδρ

−ln ρ −I −βH + γI

= 0
(16.30)
The operator in parentheses is self-adjoint, and the variations δρ of ρ are also self-adjoint. Thus, if
the above variational equation is to hold for arbitrary self-adjoint variations δρ, we must have
ln ρ = −βH + constant × I
(16.31)
Enforcing now the unit trace condition guarantees that we recover (16.25), and that β is indeed
related to temperature as given above.
16.5.1
Generalized equilibrium ensembles
The derivation of the Boltzmann weights and associated density matrix corresponds to the canonical
ensemble, in which only the energy of the system is kept constant. In the grand canonical ensemble,
both the energy and the number of particles in the system is kept constant. More generally, we
consider an ensemble in which the ensemble average of a number of commuting observables Ai,
i = 1, · · · , K is kept constant. To compute the associated density operator ρ of this ensemble,
we extremize with respect to variations in ρ the entropy, under the constraint that the ensemble
averages Tr(ρAi) are kept constant. Using again Lagrange multipliers βi, i = 1, · · · , K, we extremize
−Tr

ρ ln ρ

−
K
X
i=1
βiTr(ρAi)
(16.32)
Upon enforcing the normalization Tr(ρ) = 1, this gives,
ρ
=
1
Z exp
(
−
K
X
i=1
βiAi
)
Z
=
Tr
 
exp
(
−
K
X
i=1
βiAi
)!
(16.33)
In the grand canonical ensemble, for example, these quantities are
ρ
=
1
Z e−βH−µN
Z
=
Tr

e−βH−µN
(16.34)
where N is the number operator and µ is the chemical potential. Other observables whose ensemble
averages are often kept ﬁxed in this way are electric charge, baryon number, electron number etc.
209

16.6
Classical information and Shannon entropy
Entropy may be given a meaning beyond traditional statistical mechanics. In developing a theory
of classical (non-quantum mechanical) information, Claude Shannon was led to a generalized notion
of entropy that characterizes the amount of missing information for a given ensemble. In the case
of information theory, the ensembles consist of messages, sent in words and sentences. To make
contact with the previous sections, a message may be viewed as a mixture of a certain number of
letters and words.
Consider an ensemble with n possible outcomes, for example, by the number of diﬀerent letters
or words in a text. A probability pi is assigned to each outcome i = 1, · · · , n, and total probability
is normalized to 1. This assignment of probabilities characterizes a macro-state. The statistical or
Shannon entropy associated with this macro-state is deﬁned by
S(p1, · · · , pn) = −k
n
X
i=1
pi ln pi
n
X
i=1
pi = 1
(16.35)
Here, k is a positive constant.
For statistical mechanics, k is the Boltzmann constant, but in
information theory, one usually sets k = 1.
Shannon derived this formula from a number of simple basic assumptions.
Here, we shall
contents ourselves by arguing that the formula follows from a large numbers approach to the
possible outcomes in a message. Suppose we have a message of length N formed out of n diﬀerent
letters ai, i = 1, · · · , n. We consider this problem in the limit where N ≫n. A message then takes
the form
ℓ1 ℓ2 ℓ3 · · · ℓN
(16.36)
Since the probability pi for the letter i to occur in this message is given, we expect the letter
i to occur piN times. The number Ωof distinct messages with this assignment of letters gives a
quantitative measure of the amount of missing information. Namely, if you are given the information
that the message contains the letter i precisely piN times, the more possible messages there are, the
more information is lacking. This number Ωof possible messages is also referred to as the number
of micro-states corresponding to a given probability assgnment.
With this mixture of letters, and the assumption that the occurrence of the letters in the
message is uncorrelated, Ωis given by the multinomial coeﬃcient.
To make contact with the
statistical entropy formula, we take its logarithm,
ln Ω= ln

N!
(p1N)!(p2N)! · · · (pnN)!

(16.37)
Since N ≫1, we can use the Sterling formula to approximate the factorial, ln k! = k(ln k −1), and
we get
ln Ω
=
N(ln N −1) −
n
X
i=1
(piN)

ln(piN) −1

=
−N
n
X
i=1
pi ln pi
(16.38)
210

Thus, the logarithm of the number of micro-states Ωis an extensive quantity, proportional to the
length N of the message. The statistical entropy is the corresponding intensive quantity, up to a
multiplicative factor.
Some basic properties of the statistical entropy are as follows.
1. Positivity, S(p1, · · · , pn) ≥0;
2. The minimum is S = 0, attained when all probability assignments are 0, except for a single
entry pj = 1;
3. The maximum is attained when all probabilities are equal, pi = 1/n, giving Smax = ln n.
16.7
Quantum statistical entropy
A quantum mechanical macro-state is characterized by the density operator ρ. The state may be
obtained as an incoherent mixture of orthogonal pure states |φi⟩, with population fractions pi, so
that
ρ =
X
i
|φi⟩pi⟨φi|
X
i
pi = 1
(16.39)
The population fractions pi may be measured simultaneously by the commuting (actually orthog-
onal) observables Pi = |φi⟩⟨φi|. Thus, the pi may be viewed essentially as classical probabilities,
and the statistical entropy may be generalized immediately,14
S(ρ) = −kTr

ρ ln ρ

(16.40)
Here again, k is a positive constant, left arbitrary in information theory, but equal to Boltzmann’s
constant kB for statistical mechanics. This is the statistical entropy for a macro-state speciﬁed by
the density operator ρ, and is sometimes referred to as the von Neumann entropy.
Some fundamental properties of the statistical entropy are given as follows,
1. Positivity, S(ρ) ≥0;
2. Minimum is S(ρ) = 0 attained if and only if ρ is a projection operator and thus corresponds
to a pure state;
3. Maximum is attained as follows. If the possible probabilities are non-zero for a subspace
Hn ⊂H of ﬁnite dimension n, then the maximum entropy is Smax = k ln n;
4. Invariance under conjugation of the density operator by a unitary transformation. In partic-
ular, the entropy is invariant under time evolution, under the assumption that the population
fractions remain unchanged in time;
14Note that when the density matrix is written as a weighted sum involving non-orthogonal states as in
(16.6), the weights wi cannot be measured simultaneously, as the corresponding states are not orthogonal.
Thus, the entropy is not equal to the replacement pi →wi.
211

5. Additivity upon combination of two subsystems which are statistically uncorrelated. Let
the systems be described by Hilbert spaces Ha and Hb, with density operators ρa and ρb
respectively, then the full Hilbert space is Hab = Ha ⊗Hb and the density matrix for the
combined system is ρab = ρa ⊗ρb. The entropy is then additive,
S(ρab) = S(ρa) + S(ρb)
(16.41)
6. Subadditivity upon dividing a system with Hilbert space Hab and density operator ρab into
two subsystems with Hilbert spaces Ha and Hb, and density matrices ρa and ρb which are
statistically correlated. The full density operator ρab is not the tensor product of ρa and ρb,
in view of the non-trivial statistical correlations between the two subsystems. Instead, one
only has an inequality,
S(ρab) ≤S(ρa) + S(ρb)
(16.42)
with equality being attained iﬀthere are no statistical correlations and ρab = ρa ⊗ρb.
7. Strong subadditivity upon dividing a system with density operator ρabc into three sub-
systems with density operators ρa, ρb, and ρc, and their pairwise combinations with density
operators ρab, ρbc, and ρac, the entropy satisﬁes
S(ρabc) + S(ρb) ≤S(ρab) + S(ρbc)
(16.43)
or any rearrangement thereof.
8. Concavity For λ1, λ2, · · · , λr ≥0, and λ1 + · · · + λr = 1, we have
S(λ1ρ1 + · · · + λrρr) ≥λ1S(ρ1) + · · · + λrS(ρr)
(16.44)
Properties 1, 2, 3, and 4 are straightforward. To prove property 5, we have to make careful use
of the deﬁnitions. Each density matrix is normalized,
TrHaρa = TrHbρb = 1
(16.45)
and the corresponding entropies are deﬁned by
S(ρa)
=
−kTrHa

ρa ln ρa

S(ρb)
=
−kTrHb

ρb ln ρb

(16.46)
The total entropy for the tensor product density operator ρab = ρa ⊗ρb is then given by
S(ρab)
=
−kTrHaTrHb

(ρa ⊗ρb) ln(ρa ⊗ρb)

=
−kTrHaTrHb

(ρa ⊗ρb)(ln ρa ⊗Ib) ⊕(ρa ⊗ρb)(Ia ⊗ln ρb)

=
−kTrHa

ρa ln ρa

−kTrHb

ρb ln ρb

(16.47)
which proves the formula of 5. To prove 6, we ﬁrst prove the following intermediate results.
212

16.7.1
Density matrix for a subsystem
Let Hab = Ha ⊗Hb be the Hilbert space organized as the tensor product of two subspaces Ha
and Hb. Let ρab be the density matrix corresponding to a state of the system. Suppose now that
we observe the system with observables that act only on the subsystem a. In all generality, such
observables are of the form,
A = Aa ⊗Ib
(16.48)
The expectation value of A of this type of operators in the full system reduces in a systematic
manner to the expectation value with respect to the density matrix of the subsystem. To see this,
we compute the expectation values,
⟨A⟩
=
TrHab

ρabA

= TrHaTrHb

ρab (Aa ⊗Ib)

=
TrHa

Aaρa

(16.49)
where
ρa = TrHb

ρab

(16.50)
Note that the normalization TrHa(ρa) = 1 as a result of the normalization of ρab. In particular, the
population fraction of a pure state |ψa⟩⟨ψa| is given by
pa = TrHa

ρa|ψa⟩⟨ψa|

= ⟨ψa|ρa|ψa⟩
(16.51)
16.7.2
Example of relations between density matrices of subsystems
It will be helpful to clarify the relations between ρab, ρa, ρb and the tensor product ρa ⊗ρb with the
help of an example involving two spin 1/2 systems. We denote the Pauli matrices for these systems
respectively by σi
a and σi
b where i = 1, 2, 3. Consider general density matrices for each subsystem,
ρa
=
1
2 (Ia + ⃗a · ⃗σa)
|⃗a| ≤1
ρb
=
1
2

Ib +⃗b · ⃗σb

|⃗b| ≤1
(16.52)
The tensor product is given by
ρa ⊗ρb = 1
4

Ia ⊗Ib + Ia ⊗(⃗b · ⃗σb) + (⃗a · ⃗σa) ⊗Ib + (⃗a · ⃗σa) ⊗(⃗b · ⃗σb)

(16.53)
Clearly, when we compute the partial traces, we recover the density matrices of the subsystems,
trHa(ρa ⊗ρb)
=
ρb
trHb(ρa ⊗ρb)
=
ρa
(16.54)
213

The general density matrix ρab of the combined system may be parametrized as follows,
ρab = ρa ⊗ρb +
3
X
i,j=1
Cijσi
a ⊗σj
b
(16.55)
where Cij is an arbitrary 3 × 3 real matrix. For any choice of Cij, we have
trHa(ρab)
=
ρb
trHb(ρab)
=
ρa
(16.56)
so that the reduced density matrices ρa and ρb are independent of Cij. Only for Cij = 0 is the
density matrix ρab the tensor product of ρa and ρb.
16.7.3
Lemma 1
For any two density operator ρ and ρ′ in the same Hilbert space H, we have the inequality,
S(ρ) ≤−kTr

ρ ln ρ′
(16.57)
with equality being attained iﬀρ′ = ρ.
To prove this, we write both density matrices in diagonal form, in orthonormal bases,
ρ
=
X
i
|φi⟩pi⟨φi|
ρ′
=
X
i
|φ′
i⟩p′
i⟨φ′
i|
(16.58)
The bases |φi⟩and |φ′
i⟩are in general diﬀerent. We now consider
S(ρ) + kTr

ρ ln ρ′
=
−k
X
i
pi ln pi + k
X
i,j
pi ln p′
j|⟨φi|φ′
j⟩|2
=
k
X
i,j
pi(ln p′
j −ln pi)|⟨φi|φ′
j⟩|2
(16.59)
where we have used the completeness relation P
j |φ′
j⟩⟨φ′
j| = I in recasting the simple sum on the
ﬁrst line in the form of a double sum on the last line. Next, we introduce the function
f(x) ≡x −1 −ln x
(16.60)
We set x = p′
j/pi and recast the above double sum in the following way,
S(ρ) + kTr

ρ ln ρ′
= k
X
i,j
pi
 
1 −p′
j
pi
−f
 
p′
j
pi
!!
|⟨φi|φ′
j⟩|2
(16.61)
214

The ﬁrst two terms on the right hand side simplify as follows,
X
i,j
(pi −p′
j)|⟨φi|φ′
j⟩|2 =
X
i
pi −
X
j′
pj′ = 0
(16.62)
in view of the completeness relations of the both orthonormal bases. This gives us an expression
directly in terms of the function f,
S(ρ) + kTr

ρ ln ρ′
= −k
X
i,j
pif
 p′
j
pi
!
|⟨φi|φ′
j⟩|2
(16.63)
To derive the lemma, we use the following simple properties of the function f(x),
• f(1) = 0;
• f(x) > 0 for all x ≥0 and x ̸= 1.
The ﬁrst property is obvious, the second may be established from the ﬁrst by noticing that f ′(x) < 0
for 0 ≤x < 1, and f ′(x) > 0 for 1 < x. Thus, we have f(x) ≥0 for all x ≥0, and as a result, we
have the inequality of the lemma, since in all terms we have pi|⟨φi|φ′
j⟩|2 ≥0.
To complete the proof of the lemma, we assume that the equality holds. Problems with possible
degeneracies of the population fractions force us to be more precise in our analysis. Thus, we shall
decompose the density matrices as follows,
ρ =
N
X
i=0
piPi
N
X
i=0
Pi = I
ρ′ =
N′
X
i=0
p′
iP ′
i
N′
X
i=0
P ′
i = I
(16.64)
where we shall now assume that all population fractions pi and distinct from one another, same for
p′
i, so that we can order them as follows,
p0 = 0 < p1 < p2 < · · · < pN
p′
0 = 0 < p′
1 < p′
2 < · · · < p′
N′
(16.65)
We shall also assume that each contribution for i ̸= 0 is non-trivial, in the sense that
dim(Pi)
=
tr(Pi) ≥1
i ≥1
dim(P ′
i)
=
tr(P ′
i) ≥1
i ≥1
(16.66)
In this notation, the combination of the lemma may be recast in the following form,
S(ρ) + kTr

ρ ln ρ′
= −k
X
i,j
 
p′
j −pi −pi ln
 
p′
j
pi
!!
tr

PiP ′
j

(16.67)
215

The combinations of projectors obeys
tr

PiP ′
j

≥0
(16.68)
As a result, every term in the double sum is either positive or zero. The equality in the lemma is
achieved if and only if every term separately vanishes for all i, j,
 
p′
j −pi −pi ln
 p′
j
pi
!!
tr

PiP ′
j

= 0
(16.69)
If tr(PiP ′
j) ̸= 0, then we must have p′
j = pi, even when pi = 0. Now ﬁx the index i, and let j
run through j = 0, 1, 2, · · · , N ′. If tr(PiP ′
j) = 0 for all values j, then dim(Pi) = 0, since P ′
j span
the entire Hilbert space. Thus, we must have i = 0, and dim(P0) = 0, in which case the result is
trivial. Thus, for all i ̸= 0, there must be a unique j such that tr(PiP ′
j) ̸= 0, and for which pi = p′
j.
Reversing the argument, ﬁxing j, and letting i run through the values i = 0, 1, 2, · · · , N, we see
that every j ̸= 0, there must be a unique i such that tr(PiP ′
j) ̸= 0 and p′
j = pi. Given the ordering
(16.65) that we assumed, this implies a one-to-one and onto map between the pi and the p′
i, so that
N ′ = N. As a result we have
ρ =
N
X
i=1
piPi
N
X
i=0
Pi = I
ρ′ =
N
X
i=1
piP ′
i
N
X
i=0
P ′
i = I
(16.70)
where
tr(PiP ′
j)
 = 0
j ̸= i
̸= 0
j = i
(16.71)
Finally, using these results, we compute
tr
 PiP ′
i
 = trPi −
X
j̸=i
tr(PiP ′
j)
(16.72)
Each term under the sum on the rhs vanishes, so that tr (Pi(I −P ′
i)) = 0 As a result, we have
P ′
i = Pi, and thus ρ′ = ρ, which completes the proof of the lemma.
16.7.4
Completing the proof of subadditivity
To complete the proof of 6, we proceed as follows.
First, deﬁne the density operators of the
subsystems a and b by
ρa
=
TrHb(ρ)
ρb
=
TrHa(ρ)
(16.73)
216

Next, we take ρ′ = ρa ⊗ρb, so that
S(ρab)
≤
−kTrHaTrHb

ρ(ln ρa ⊗Ib) ⊕ρ(Ia ⊗ln ρb)

≤
−kTrHa

ρa ln ρa

−kTrHb

ρb ln ρb

(16.74)
which proves 6. Properties 7 and 8 may be proven along the same lines of reasoning, and use of
the Lemma.
16.8
Examples of the use of statistical entropy
We illustrate the property of subadditivity, in 6, by considering a pure state of the full system, and
then viewing this pure state from the vantage point of a bi-partite subsystem. Thus we view the
full Hamiltonian Hab = Ha ⊗Hb, and construct the density operator
ρab
=
|ψ⟩⊗⟨ψ|
|ψ⟩
=
X
α,β
Cαβ|φα; a⟩⊗|φβ; b⟩
(16.75)
Here, |φα; a⟩is an orthonormal basis of Ha and |φβ; b⟩is an orthonormal basis of Hb. Since ρab
corresponds to a pure state, we clearly have S(ρab) = 0. By subadditivity, however, we only have
and inequality for S(ρa) and S(ρb),
0 ≤S(ρa) + S(ρb)
(16.76)
and neither quantity, in general, should be expected to have to vanish. Physically, this result may
be interpreted as follows. Even though the full system is in a pure quantum state, the fact that we
“average” over subspace Hb to get ρa (and “average” over subspace Ha to get ρb) means that the
quantum information contained in Hb has been lost and this translates into a non-zero value of the
statistical entropy.
It is instructive to work out the corresponding density operators, and check that they do not,
in general, correspond to pure states. We have,
ρa
=
TrHb(ρab) =
X
β
w(a)
β |ψβ; a⟩⊗⟨ψβ; a|
ρb
=
TrHa(ρab) =
X
α
w(b)
α |ψα; b⟩⊗⟨ψα; b|
(16.77)
Here, the weights w(a)
β
and w(b)
α
are positive and less or equal to 1, and |ψβ; a⟩, and |ψα; b⟩are
normalized pure states, deﬁned by

w(a)
β
 1
2 |ψβ; a⟩=
X
α
Cαβ|φα; a⟩
w(a)
β
=
X
α
|Cαβ|2

w(b)
α
 1
2 |ψα; b⟩=
X
β
Cαβ|φβ; b⟩
w(b)
α =
X
β
|Cαβ|2
(16.78)
217

The formulas for the population fractions directly result from the normalization of the pure states
|ψβ; a⟩, and |ψα; b⟩. Notice that states |ψβ; a⟩for diﬀerent values of β need not be orthogonal to
one another. The above result may be applied to two diﬀerent physical situations.
16.8.1
Second law of thermodynamics
First, suppose we view the entire universe as divided into a certain system a, in which we are
interested, and the environment b which we do not study directly. The Hilbert space of the entire
universe H = H ⊗Hb. Suppose a and b interact with one another, for example by exchanging
energy. Now, at an initial time t0, we prepare the system a in such a way that it has no statistical
correlations with the environment.
This is clearly an idealized set-up, which is certainly hard
to realize experimentally. But if we assume absence of correlations at time t0, then the density
operator of the universe ρ(t0) is a tensor product,
ρ(t0) = ρa ⊗ρb
(16.79)
From the property of additivity of the statistical entropy, we then have
S(ρ(t0)) = S(ρa) + S(ρb)
(16.80)
Unitary time evolution of the entire universe implies that at a later time t > t0, we will have
S(ρ(t)) = S(ρ(t0))
(16.81)
But the density matrices ρa(t) and ρb(t) at time t will not be the same as the density matrices
ρa = ρa(t0) and ρb = ρb(t0) respectively. In fact, they will not even be unitary evolutions of these
because the Hamiltonian will mix the time evolutions of states in Ha and Hb, since the system a
interacts with the environment. All we can do is use the deﬁnition of these density operators,
ρa(t)
=
TrHb(ρ(t))
ρb(t)
=
TrHa(ρ(t))
(16.82)
But now, in general, the system at time t will have statistical correlations with its environment b,
so that the density matrix ρ(t) will no longer be the tensor product of ρa(t) and ρb(t). As a result,
by the subadditivity property of the statistical entropy, we have,
S(ρ(t)) ≤S(ρa(t)) + S(ρb(t))
(16.83)
putting this together with (16.80) and (16.81), we obtain,
S(ρa(t0)) + S(ρb(t0)) ≤S(ρa(t)) + S(ρb(t))
(16.84)
for times t > t0. We have just derived the second law of thermodynamics, under the assumptions
we have advocated: the sum of the entropy of the system and of its environment cannot decrease
with time.
16.8.2
Entropy resulting from coarse graining
218

17
Entanglement, EPR, and Bell’s inequalities
Quantum systems exhibit correlations (entanglement) that appear counter-intuitive from the clas-
sical viewpoint. The examination of these questions can be traced back to a 1932 book by von
Neumann, but especially to a 1935 paper by Einstein-Podolsky-Rosen (EPR). Both addressed the
question as to whether quantum mechanics can be a complete theory of physical phenomena or
whether there exists a full theory with extra hidden variables. These investigations remained some-
what philosophical until John Bell (1964) derived concrete and experimentally testable predictions
(Bell’s inequalities) of hidden variables. In the early 1980’s, various experiments on the correlations
of photon systems by Aspect, Gragnier, and Roger have shown experimental agreement with quan-
tum mechanics, and contradictory to hidden variable theory. Since then, however, entanglement
has been explored as a fundamental property of quantum theory, and applied to physical processes,
such as quantum computation. Here, we shall concentrate on the basics.
17.1
Entangled States for two spin 1/2
Consider the spin degrees of freedom of a two-electron system. In fact, the analysis applies to the
tensor product Hab = Ha ⊗Hb of any two-state systems a and b, with respective Hilbert spaces
Ha and Hb, in the notation of the preceding section. For any unit vector n, we shall denote the
two eigenstates of n · S with eigenvalue ±¯h/2 by |n+⟩and |n−⟩. We use the notation n = x, y, z
for the unit vectors in the direction of the coordinate axes. The tensor product states for the two
electrons will be denoted by
|naα⟩⊗|nbβ⟩= |naα; nbβ⟩
α, β = ±
(17.1)
The state of 0 total spin, or singlet, corresponds to the following combination of the two electron
states,
|Φ⟩= 1
√
2

|z+; z−⟩−|z−; z+⟩

(17.2)
The state |Φ⟩has been expressed here with respect to the basis in which Sz is diagonal. Since |Φ⟩
has total spin zero, however, it is invariant under arbitrary rotations of the full system, so that
(Sa + Sb)|Φ⟩= 0. As a result, the state |Φ⟩may be expressed in the same way in terms of the
eigenstates of n · S for an arbitrary direction n,
|Φ⟩=
1
√
2

|n+; n−⟩−|n−; n+⟩

(17.3)
Thus, the preparation of the state |Φ⟩could have been made in terms of eigenstates along any
direction n. The three remaining states of the two-electron system are the triplet states
|T +⟩
=
|z+; z+⟩
|T 0⟩
=
1
√
2

|z+; z−⟩+ |z−; z+⟩

|T −⟩
=
|z−; z−⟩
(17.4)
219

expressed here with respect to the z-basis.
Basic observables in Ha and in Hb respectively are the spin na · Sa and nb · Sb. In addition, we
have observables deﬁned only in the full Hilbert space Hab, such as (na · Sa) ⊗(nb · Sb).
To understand the concept of entanglement of two states a and b, we begin by evaluating various
observables on the state |Φ⟩. First, |Φ⟩is an eigenstate of the observable Sz
a ⊗Sz
b ,
Sz
a ⊗Sz
b |Φ⟩= −¯h2
4 |Φ⟩
(17.5)
Thus, in the state |Φ⟩, the eigenvalues of Sz
a and of Sz
b are always opposite to one another (with
probability 1). Expressed alternatively, the spins of electrons a and b are perfectly correlated with
one another; when Sz
a is +, then Sz
b is −and vice-versa. The same correlation exists in the triplet
states,
Sz
a ⊗Sz
b |T 0⟩
=
−¯h2
4 |T 0⟩
Sz
a ⊗Sz
b |T ±⟩
=
+¯h2
4 |T ±⟩
(17.6)
The analysis could be repeated with respect to any orientation n.
The key distinction appears when we investigate observables measuring properties of only sub-
system a, but not b (or vice-versa).
Take for example the operator Sz
a = Sz
a ⊗Ib.
From the
construction of the states |T ±⟩, it is immediate that
Sz
a|T ±⟩= ±¯h
2|T ±⟩
(17.7)
When observed from the point of view of subsystem a alone, the states |T ±⟩behaves as pure states,
as if subsystem b were absent. These states are examples of non-entangled states (we shall present
a general deﬁnition of such states later on). On the other hand, applying the operator Sz
a to the
states |Φ⟩and |T 0⟩, we ﬁnd,
Sz
a|Φ⟩
=
¯h
2|T 0⟩
Sz
a|T 0⟩
=
¯h
2|Φ⟩
(17.8)
Neither |Φ⟩, nor |T 0⟩are eigenstates of Sz
a. Hence, measurements of Sz
a in the state |Φ⟩will give
both the results +¯h/2 and −¯h/2. By computing the expectation value of Sz
a in the state |Φ⟩, we
gain information on the quantum mechanical probabilities with which either eigenvalues ±¯h/2 will
be measured. The expectation values are given by
⟨Φ|Sz
a|Φ⟩= ⟨T 0|Sz
a|T 0⟩= 0
(17.9)
220

so that the probability for measuring the eigenvalues ±¯h/2 are actually equal to one another. This
is not really surprising, since both eigenstates ± of the electron a entered into the state |Φ⟩. In
fact, the expectation value of na · Sa in the state |Φ⟩vanishes for any na,
⟨Φ|

na · Sa

|Φ⟩= 0
(17.10)
This is an immediate result of the rotation invariance of the state |Φ⟩.
Therefore, the probabilities for measuring the eigenvalues ±¯h/2 for na · Sa are equal to one
another, for any orientation na. This behavior of the observable Sz
a, from the viewpoint of the
subsystem a, is unlike that of any pure state of a, but in fact precisely coincides with the behavior
of an unpolarized state of a.
We see that by summing, or “averaging”, over the states in the
subsystem b, the full system reduces to subsystem a, and the state |Φ⟩, which is a pure state of
the full system Hab, reduces to a mixed state of the subsystem a. Mathematically, this may be
expressed as follow,
⟨Φ|Sz
a|Φ⟩
=
trHab

|Φ⟩⟨Φ|Sz
a

=
trHatrHb

|Φ⟩⟨Φ|Sz
a

=
trHa

ρaSz
a

(17.11)
where we have deﬁned
ρa ≡trHb

|Φ⟩⟨Φ|

(17.12)
This quantity may be computed explicitly, using the form of |Φ⟩, and we get
ρa
=
1
2trHb

|z+; z−⟩−|z−; z+⟩

< z+; z −| −⟨z−; z + |

=
1
2

|z+⟩⟨z + | + |z−⟩⟨z −|

= 1
2 Ia
(17.13)
The value ρa = Ia/2 indeed conﬁrms that subsystem a appears in an unpolarized state. From the
point of view of subsystem a, the state |Φ⟩is entangled with subsystem b
17.2
Entangled states from non-entangled states
Entangled states naturally appear in the time evolution of a system that was originally in a non-
entangled state. This may be illustrated concretely in the above two spin 1/2 system as well. Let
the time evolution be determined by the simplest non-trivial Hamiltonian,
H = 2ω
¯h Sa · Sb = ω
¯h

S2 −3
2¯h2

(17.14)
221

where S = Sa +Sb is the total spin. The Hamiltonian is diagonal on the states |Φ⟩, and |T 0,±⟩, and
has eigenvalues −3¯hω/2 and ¯hω/2 respectively. Consider now a state |Ψ(t)⟩for which |Ψ(0)⟩=
|z+; z−⟩, then time evolution under Hamiltonian H produces
|Ψ(t)⟩= eiωt/2 (cos(ωt)|z+; z−⟩−i sin(ωt)|z−; z+⟩)
(17.15)
The state |Ψ(0)⟩was chosen to be non-entangled, but we see that time evolution entangles and
then un-entangles the state. In particular, we may compute the density matrix
ρa(t)
=
trHb|Ψ(t)⟩⟨Ψ(t)|
=
cos2(ωt)|z+⟩⟨z + | + sin2(ωt)|z−⟩⟨z −|
(17.16)
This state is non-entangled when t = kπ/(2ω) for any integer k, and maximally entangled (unpo-
larized) when t = π/(4ω) + kπ/(2ω) for any integer k.
17.3
The Schmidt puriﬁcation theorem
Consider now, more generally, a full quantum system with Hilbert space Hab, built out of two
subsystems a and b with respective Hilbert spaces Ha and Hb, so that Hab = Ha ⊗Hb. In this
general system, let |Ψ⟩be a pure state in Hab. The division of the system into the two subsystems
a and b allows us to deﬁne the two density operators,
ρa
≡
trHb (|Ψ⟩⟨Ψ|)
ρb
≡
trHa (|Ψ⟩⟨Ψ|)
(17.17)
By construction, ρa is a density operator for subsystem a, while ρb is a density matrix for subsystem
b. The density operators ρa and ρb are not independent. In particular, we always have rank(ρa) =
rank(ρb). In fact, even more precise relations hold between ρa and ρb, which we now exhibit.
The Schmidt puriﬁcation theorem states that, for any |Ψ⟩∈Hab, there exists an orthonormal
set |i, a⟩in Ha and an orthonormal set |i, b⟩in Hb, such that
|Ψ⟩=
X
i
√pi |i, a⟩⊗|i, b⟩
(17.18)
Notice that the sum is over a common index i, even though the Hilbert spaces Ha and Hb need not
have the same dimension. The numbers pi are real and satisfy 0 ≤pi ≤1. Finally, note that the
sets {|i, a⟩}i and {|i, b⟩}i depend on the state |Ψ⟩.
To prove this theorem, we begin by decomposing the pure state in an orthonromal basis |i, a⟩
of Ha and |m, b′⟩of Hb,
|Ψ⟩=
X
i,m
Cim|i, a⟩⊗|m, b′⟩
(17.19)
We choose the basis |i, a⟩to be such that ρa is diagonal in this basis, and given by the sum,
X
i
pi|i, a⟩⟨i, a|
(17.20)
222

where 0 ≤pi ≤1. In this special basis, we deﬁne the following states of Hb,
|i, b′′⟩≡
X
m
Cim|m, b′⟩
(17.21)
Note that these states need to be neither orthogonal to one another, nor normalized. Hence the
pure state may be expressed as
|Ψ⟩=
X
i
|i, a⟩⊗|i, b′′⟩
(17.22)
We now use this expression to evaluate the density operator ρa, and ﬁnd,
ρa =
X
i,j
⟨j, b′′|i, b′′⟩|i, a⟩⟨j, a|
(17.23)
But, we had already assume that ρa was actually diagonal in the basis |i, a⟩, with eigenvalues pi,
so that we must have
⟨j, b′′|i, b′′⟩= piδij
(17.24)
Thus, we conclude that the states |i, b′′⟩are in fact orthogonal to one another. It now suﬃces to
normalize the states by
|i, b⟩=
1
√pi
|i, b′′⟩
(17.25)
to recover the formula (17.18) of Schmidt’s theorem. In this basis now, we may compute also ρb,
and we ﬁnd,
ρb =
X
i
pi |i, b⟩⟨i, b|
(17.26)
Thus, the probability assignments of ρa and ρb, in this basis, are identically the same. In particular,
the rank of ρa coincides with the rank of ρb, and this is referred to as the Schmidt number. It is
obviously a positive integer.
17.4
Generalized description of entangled states
Consider again, as in the preceding subsection, a full quantum system with Hilbert space Hab, built
out of two subsystems a and b with respective Hilbert spaces Ha and Hb, so that Hab = Ha ⊗Hb.
By the Schmidt puriﬁcation theorem, we then have
ρa
=
s
X
i=1
pi|i, a⟩⟨i, a|
ρb
=
s
X
i=1
pi|i, b⟩⟨i, b|
|Ψ⟩
=
s
X
i=1
√pi|i, a⟩⊗|i, b⟩
(17.27)
223

Henceforth, we shall assume that pi > 0, and omit those contributions for which pI = 0 from the
sum. The number s is then the common rank of ρa and ρb, which is nothing but the Schmidt
number of the state |Ψ⟩,
s = rank(ρa) = rank(ρb)
(17.28)
• If s = 1, the state |Ψ⟩is non-entangled.
In this case, the density operators ρa and ρb
correspond to pure states of Ha and Hb respectively.
• If s > 1, the state |Ψ⟩is entangled. In this case, the density operators ρa and ρb do not
correspond to pure states of Ha and Hb respectively but represent a mixture instead.
17.5
Entanglement entropy
The Schmidt number gives a discrete measure of the degree of entanglement of a bipartite division.
But there is also value in having a continuously varying measure of the entanglement of a state.
This is provided by the entanglement entropy. Recall that the state |Ψ⟩in the full Hilbert space
is pure, so its statistical entropy vanishes. But when the state is considered from the point of view
of the bipartite division into systems a and b, it makes sense to talk about entropies S(ρa) and
S(ρb) associated with the density operators ρa or ρb. By the Schmidt puriﬁcation theorem, we have
S(ρa) = S(ρb), so that we may consistently deﬁned an entanglement entropy by
Sentang ≡S(ρa) = S(ρb) = −
s
X
i=1
pi ln pi
(17.29)
As the state |Ψ⟩approaches a non-entangled state |Ψ; j⟩(in which pi = 0 for all i ̸= j, and pj = 1),
the entanglement entropy of |Ψ⟩tends to 0 in a continuous manner.
17.6
The two-state system once more
Consider the following pure state in the system of two spin 1/2 particles,
|Ψ⟩= cos θ |z+, a; bz−, b⟩+ sin θ |z−, a; z+, b⟩
(17.30)
The density operators of the subsystems a and b are readily evaluated,
ρa
=
cos2 θ |z+, a⟩⟨z+, a| + sin2 θ |z−, a⟩⟨z−, a|
ρb
=
cos2 θ |z−, b⟩⟨z−, b| + sin2 θ |z+, b⟩⟨z+, b|
(17.31)
Note the reversal of probability assignments for spin + and spin −. The Schmidt number is
• s = 1 when sin(2θ) = 0: the state |Ψ⟩is not entangled;
• s = 2 when sin(2θ) ̸= 0: the state |Ψ⟩is entangled.
The entanglement entropy is given by
Sentang = −cos2 θ ln(cos2 θ) −sin2 θ ln(sin2 θ)
(17.32)
When θ →0, for example, we approach the non-entangled state |z+, a; bz−, b⟩, and the entangle-
ment entropy Sentang ∼−θ2 ln θ2 tends to zero in a smooth way.
224

17.7
Entanglement in the EPR paradox
Einstein Podolsky and Rosen (EPR) proposed a gedanken experiment in 1935 the outcome of which
they viewed as a paradox, namely a contradiction between the principles of causality in relativity
and the principles of quantum mechanics.
The set-up (as re-interpreted by David Bohm) is as follows. Consider a spin 0 particle which
decays into two stable particles a and b. To make this interesting, we consider a case where the
particles a and b have both spin 1 (typically photons) or spin 1/2 (electrons). Physical examples
are
π0
→
γ + γ
π0
→
e+ + e−
(17.33)
The ﬁrst is the dominant decay mode of the π0, whose life-time is 10−16s. The branching ratio for
the second decay is 10−7. Let us concentrate on the example of π0 →e+ + e−, so that the two
subsystems both correspond to spin 1/2.
Because the π0 has zero spin, and angular momentum is conserved, the spins of the electron
and positron must be opposite. This means that the electron/positron state produced by the decay
of π0 must be
|Φ⟩=
1
√
2

|z+; z−⟩−|z−; z+⟩

=
1
√
2

|n+; n−⟩−|n−; n+⟩

(17.34)
following the notations of the preceding sections. Here, we ignore all extra quantum numbers the
particles carry, such as energy, momentum, and electric charge.
Assuming that the e+ and e−can travel a long distance without any interaction with other
particles or with electric and magnetic ﬁelds, this correlation between the spins of e+ and e−will
persist, and the quantum state of the spins will remain |Φ⟩. We now imagine two observers A and
B far away in opposite directions from where the π0 decays. These observers can measure the spins
of the e+ and e−.
e+
e−
A < −−−−−−
π0
−−−−−−> B
(17.35)
Assume that A measures the spin of the electron along the Sz
a direction. The probability for A
to measure +¯h/2 is 50%, and the probability for A to measure −¯h/2 is also 50%. But now, if
A measures spin +¯h/2 in the Sz
a direction, then A knows for sure (with probability 1) that, if
B measures spin in the Sz
b direction as well, B must necessarily ﬁnd −¯h/2, since these spins are
opposite in the state |Φ⟩. The same would be true if A and B measured spin along any other
direction n.
At ﬁrst sight, one may conclude that because of these correlations, there must be some infor-
mation that can travel from B to A instantaneously. This would appear to be so because as soon
as A has measured spin Sz
a = +¯h/2, then the outcome of the measurement that B can perform
will be known to A instantaneously. This issue, however, is not where the EPR paradox lies. After
225

all, this is a question of causality in special relativity, and could be considered purely classically.
Suppose two travelers originating at π0 are each given a ball. Both travelers know that the ball
given to one of them is black, while the ball given to the other is white, but they do not know
whether the ball each one received is black or white. They now travel apart for a long long time,
until one of the travelers decides to open his present and ﬁnds out this his ball is black. He then
instantaneously knows that the other guy’s ball is white. Nonetheless, no information has really
traveled faster than light, and again, this is not the key problem in the EPR paradox. After all, if
both A and B only measure along commuting observables, such as Sz
a and Sz
b , their measurements
are analogous to classical ones.
The real distinction brought by quantum behavior is that one can make measurements along
Sz
a or along Sx
a, for example, and these operators do not commute. It is this realization that was
new in Bell’s work. If we allow for these observables to be measured, then the possible outcomes
are as given in Table 1 below.
spin component
result
spin component
result
measured by A
measured by B
z
+
z
−
z
−
z
+
z
+
x
+
z
+
x
−
z
−
x
+
z
−
x
−
x
+
x
−
x
−
x
+
x
+
z
+
x
+
z
−
x
−
z
+
x
−
z
−
For example,
1. If both A and B measure Sz or both measure Sx, the spins measured are opposite;
2. If A makes no measurement, then the measurements of B are 50% spin +¯h/2 and 50% spin
−¯h/2;
3. If A measures Sz
a and B measures Sx
b , there is completely random correlation between the
two measurements. Even if Sz
a is measured to be +¯h/2, the measurement of Sx
b will yield
50% spin + and 50% spin −.
Thus, the outcome of the measurements of B depend on what kind of measurement A decides to
perform. And A can decide to orient his measurement direction n long after the two particles have
separated. It is as though particle b knows which spin component of particle a is being measured.
226

The orthodox quantum interpretation of this situation is as follows. We must accept that when
A performs a measurement on the spin of one of the particles, this is really a measurement on the
entire system, even though it would appear that A is making a measurement on only part of the
system (namely only one of the two particles). If A makes a measurement of Sz
a, then the act of
performing the measurement will select an eigenstate of sz
a out of the full state |Φ⟩. Depending on
the eigenvalue of Sz
a observed, the state selected will be
Sz
a = +¯h
2
|z+; z−⟩
Sz
a = −¯h
2
|z−; z+⟩
(17.36)
This then explains why measuring then Sz
b gives perfectly anti-correlated outcomes, and why mea-
suring Sx
b gives 50% spin + and 50% spin −.
The real novelty in EPR is that the measurement at A changes the whole state and in particular
the state as B will measure it.
17.8
Einstein’s locality principle
Einstein Podolsky and Rosen could not accept as part of a complete theory the fact that a mea-
surement at A could change the state as measured by B in violation of macroscopic causality. To
quote them
If, without in any way disturbing a system, we can predict with certainty (i.e. with
probability equal to unity) the value of a physical reality, then there exists an element
of physical reality corresponding to this physical quantity.
and also
The real factual situation of the system B is independent of what is done with the
system A, which is spatially separated from B.
The ﬁrst principle led to theories with hidden variables, in which the measured values of Sx
b in an
eigenstate of Sz
a actually have a physical reality, but this reality remains hidden from us, and we
can probe these deterministic hidden variables only in a statistical sense. Hidden variable theories
seemed so generally possible that it seemed always possible to mimic the predictions of quantum
mechanics (and their experimental veriﬁcations) by introducing some extra degrees of freedom of
this type.
17.9
Bell’s inequalities
The situation changed dramatically in 1964, when John Bell made veriﬁable and falsiﬁable predic-
tions that could distinguish between quantum mechanics and theories of hidden variables.15 The
key is to trigger on these entanglements typical of quantum theory.
15J.S. Bell, Physics 1 (1964) 195; Speakable and unspeakable in quantum mechanics, Cambridge, 1991.
227

We all agree that Sz and Sx cannot be measured simultaneously. However, for a large number
of spin 1/2 particles, we can assign a fraction of them to have the following property
1. If Sz is measured, we obtain +¯h/2 with certainty;
2. If Sx is measured, we obtain −¯h/2 with certainty.
What this means is that if we measure Sz on one of these particles, we agree not to measure Sx on
that same particle, and if we measure Sx on another one of these particles, we agree not to measure
Sx on that particle. In this way, we are never led to actually measure Sz and Sx simultaneously,
since of course, we agreed that we cannot. We denote a particle of this type by (z+, x−). Even
though this model is very diﬀerent from quantum mechanics, it can actually reproduce the quantum
measurements of Sz and Sx, provided there are equal numbers of particles of type (z+, x+) as there
are particles of type (z+, x−).
Next, let us see how this model can reproduce the predictions of the spin-singlet correlated
measurements. For a particular pair, there should be a perfect match between particles 1 and 2.
For example,
1 :
type
(z+, x−)
←→
2 :
type
(z−, x+)
(17.37)
The results of correlations in Table 1 can be reproduced if particle 1 and 2 are matched as follows,
particle 1
particle 2
(z+, x−)
←→
(z−, x+)
(z+, x+)
←→
(z−, x−)
(z−, x+)
←→
(z+, x−)
(z−, x−)
←→
(z+, x+)
(17.38)
with equal populations, 25% for each pair. The key assumption, as always with hidden variable
theory, is that the results measured by A are predetermined independently of B’s choice of what
to measure.
So far, correlated measurements involving 2 directions can be accounted for by a theory of
hidden variables. But new things happen when we consider correlated measurements of 3 spins. To
do this, we consider again a problem of spin 1/2, but we now measure in three directions, indicated
by three unit vectors a, b, c, which, in general, need not be orthogonal to one another.
Extending the above analysis on two measurements, we now assume that the particles belong
to a deﬁnite type (a+, b−, c+). This means that on any given particle, one decides to measure
either a·S, or b·S or c·S, but never more than one of these for any given particle. The eigenvalues
are then given by the ± assignments. Now, to ensure conservation of total angular momentum,
there must again be a perfect match between the spins measured on particles 1 and 2. The particle
pair must then be a member of one of eight types, given this matching. In hidden variable theory,
these eight types are mutually exclusive, and the corresponding sets are mutually disjoint. They
228

are listed in the table below,
population
particle 1
particle 2
N1
(a+, b+, c+)
(a−, b−, c−)
N2
(a+, b+, c−)
(a−, b−, c+)
N3
(a+, b−, c+)
(a−, b+, c−)
N4
(a−, b+, c+)
(a+, b−, c−)
N5
(a+, b−, c−)
(a−, b+, c+)
N6
(a−, b+, c−)
(a+, b−, c+)
N7
(a−, b−, c+)
(a+, b+, c−)
N8
(a−, b−, c−)
(a+, b+, c+)
(17.39)
Needless to say, each population number is positive Ni ≥0 for i = 1, · · · , 8. Now, we consider pairs
of measurements by observers A and B in the following fashion.
Suppose A ﬁnds a · S1 to be +, and B ﬁnds b · S2 to be + as well. This can happen if the pair
of particles belongs to type 3 or to type 5. Hence the number of particles found for this particular
measurement will be N3 + N5. We can associate a probability with this particular measurement,
P(a+, b+) = (N3 + N5)/Ntot
Ntot =
8
X
i=1
Ni
(17.40)
In a similar manner, we have
P(a+, c+)
=
(N2 + N5)/Ntot
P(c+, b+)
=
(N3 + N7)/Ntot
(17.41)
Now, since N2, N7 ≥0, we ﬁnd that there must be an inequality obeyed by these probabilities,
P(a+, b+) ≤P(a+, c+) + P(c+, b+)
(17.42)
or more generally,
P(aα, bβ) ≤P(aα, cγ) + P(cγ, bβ)
(17.43)
where α, β, γ now take any values ±. These are the Bell inequalities for this system. They follow
from assigning an independent reality to the spin measured in each of the directions a, b, and c,
which in turn follows from Einstein’s locality argument.
17.10
Quantum predictions for Bell’s inequalities
We shall here calculate those same probabilities P(aα, bβ) etc. using the standard rules of quantum
theory. The state |Φ⟩, being a spin singlet, may be represented in either one of the following three
229

ways,
|Φ⟩
=
1
√
2|a+; a−⟩−1
√
2|a−; a+⟩
|Φ⟩
=
1
√
2|b+; b−⟩−1
√
2|b−; b+⟩
|Φ⟩
=
1
√
2|c+; c−⟩−1
√
2|c−; c+⟩
(17.44)
The probability amplitude for measuring |Φ⟩in a state |a+; b+⟩is given by
⟨a+; b + |Φ⟩=
1
√
2⟨a+; b + |a+; a−⟩−1
√
2⟨a+; b + |a−; a+⟩
(17.45)
The last term vanishes because it involves the inner product ⟨a + |a−⟩= 0 for the ﬁrst particle.
The ﬁrst term also simpliﬁes by using ⟨a + |a+⟩= 1 for the ﬁrst particle, and we are left with,
⟨a+; b + |Φ⟩=
1
√
2⟨b + |a−⟩
(17.46)
where the inner product is for the particle 2. Hence, the probability we seek is given by
P(a+, b+) = |⟨a+; b + |Φ⟩|2 = 1
2|⟨b + |a−⟩|2
(17.47)
To compute the last inner product, we express the states |bβ⟩in terms of the states |aα⟩. This
is the same formula as for expressing a general state |n±⟩in terms of |z±⟩, but now the angle θ
between n and z becomes the angle θab between the vectors a and b,
|b+⟩
=
cos θab
2 |a+⟩+ eiφ sin θab
2 |a−⟩
|b−⟩
=
cos θab
2 |a−⟩−e−iφ sin θab
2 |a+⟩
(17.48)
Here, we have omitted an overall phase which is immaterial in evaluating the probabilities, and we
ﬁnd the probability amplitude to be,
⟨a + |b−⟩= −e−iφ sin θab
2
(17.49)
and the probability,
P(a+, b+) = 1
2 sin2 θab
2
(17.50)
The phase φ is immaterial in calculating this probability. Note that, in the limit where b →a,
the probability P(a+, b+) →0. This is consistent with the fact that the spin must be perfectly
anti-correlated when measured along the same axis by A and B. Also, we have P(a+, b+) →1/2 as
230

b →−a, which is consistent with the fact that the spins measured by A and B should be perfectly
anti-correlated in the state |Φ⟩.
Are the Bell inequalities obeyed by quantum mechanics ? To ﬁnd that out, consider the com-
bination
P(a+, c+) + P(c+, b+) −P(a+, b+)
(17.51)
The Bell inequalities require that this combination be always ≥0.
The quantum mechanical
computation gives,
P(a+, c+) + P(c+, b+) −P(a+, b+) = 1
2

sin2 θac
2 + sin2 θcb
2 −sin2 θab
2

(17.52)
It is easiest to analyze the expression on the right hand side when the directions a, b, c are coplanar.
We then have
θab = θac + θcb
(17.53)
If the θab angle is taken to be the smallest angle subtended between the vectors a and b (i.e.
0 ≤θab ≤π), then the above planar relation between angles requires that
0 ≤θab ≤π
0 ≤θac ≤π
0 ≤θcb ≤π
(17.54)
In this sense, the direction c lies between a and b. Using
sin2 θab
2 = sin2 θac + θcb
2
=

sin θac
2 cos θcb
2 + sin θcb
2 cos θac
2
2
(17.55)
and combining with the other terms, we get
P(a+, c+) + P(c+, b+) −P(a+, b+) = −sin θac
2 sin θcb
2 cos θab
2
(17.56)
Given the ranges of the angles, the combination on the right is always negative or zero. Sakurai
quotes an even more special case where θab = 2θ and θac = θcb = θ. The above formula then
reduces to
P(a+, c+) + P(c+, b+) −P(a+, b+) = −sin2 θ
2 cos θ
(17.57)
which is manifestly negative when 0 ≤θ ≤π.
Thus, quantum mechanics gives a radically diﬀerent prediction for these combinations of prob-
abilities. The measurements can actually be carried out on pairs of linearly polarized photons,
produced in cascade decays of atoms such as Ca or Hg, excited by laser pumping.16 The experi-
ments clearly conﬁrm quantum mechanics and thus invalidate hidden variable theories.
16A. Aspect, P. Gragnier, G. Roger, Phys. Rev. Lett. 47 (1981) 460; Phys. Rev. Lett. 49 (1982) 91.
231

17.11
Three particle entangled states
Even more drastic violations of hidden variable type theories may be obtained by considering the
decay of an entangled state into three particles. We imagine a system of three spin 1/2 particles,
with associated 8-dimensional Hilbert space Habc = Ha ⊗Hb ⊗Hc. Instead of working with spin
components, we shall work directly with components of the Pauli matrices σi
a, σi
b and σi
c where
i = x, y, z.
A basis for all observables on this Hilbert space is given by 64 matrices σI
a ⊗σJ
b ⊗σK
c , where
J can take the values x, y, z or 0, and σ0 = I is the identity matrix. Of special interest are sets
of observables that mutually commute with one another. The maximal number is 3, excluding the
identity operator itself. For example, one could pick the set
Ia ⊗Ib ⊗σz
c
Ia ⊗σz
b ⊗Ic
σz
a ⊗Ib ⊗Ic
(17.58)
Any operator commuting with all three must be functionally dependent on these three, as may be
easily veriﬁed.
But it is possible to choose a more interesting set of mutually commuting observables that
shows some degree of entanglement. One may also choose,
Σa
=
σx
a ⊗σy
b ⊗σy
c
Σb
=
σy
a ⊗σx
b ⊗σy
c
Σc
=
σy
a ⊗σy
b ⊗σx
c
(17.59)
Using the commutation relations for the σi and the fact that the matrix product commutes with
the tensor product, such as for example, (σi
a ⊗σj
b)(σi′
a ⊗σj′
b ) = (σi
aσi′
a ) ⊗(σj
bσj′
b ). we easily verify
that these operators mutually commute,
[Σa, Σb] = [Σb, Σc] = [Σc, Σa] = 0
(17.60)
Furthermore, we have
(Σa)2 = (Σb)2 = (Σc)2 = I
(17.61)
so that each of these operators has eigenvalues ±1. We now deﬁne a state |Φ⟩which satisﬁes,
Σa|Φ⟩= Σb|Φ⟩= Σc|Φ⟩= +|Φ⟩
(17.62)
The condition becomes easier to solve if translated to the equivalent conditions
ΣaΣb|Φ⟩= ΣbΣc|Φ⟩= ΣcΣa|Φ⟩= +|Φ⟩
(17.63)
232

and
ΣaΣb
=
σz
a ⊗σz
b ⊗Ic
ΣbΣc
=
Ia ⊗σz
b ⊗σz
c
ΣcΣa
=
σz
a ⊗Ib ⊗σz
c
(17.64)
The eigenvalue conditions of ΣaΣb, ΣbΣc, and ΣcΣa,on |Φ⟩then translate to the fact that in a
basis where σz
a, σz
b, σz
c are diagonal, the eigenvalues of these three operators must be the same. This
allows for the states | + ++⟩and | −−−⟩. Separately, these states are not eigenstates of Σa, Σb,
and Σc, however, and only then combination
|Φ⟩=
1
√
2

| + ++⟩−| −−−⟩

(17.65)
satisﬁes the original conditions (17.62). This is an entangled 3-particle state of total spin 3/2. It is
referred to as a GHZ (Greenberger-Horne-Zeilinger) state. Such entangled states have remarkable
properties. They also allow one to exhibit the conﬂict between the predictions of quantum theory
and of hidden variable theory even more dramatically.
The product of the operators Σa, Σb, and Σc is also an observable,
Σ
=
σx
a ⊗σx
b ⊗σx
c
=
−ΣaΣbΣc
(17.66)
of which |Φ⟩is obviously an eigenstate with eigenvalue −1.
Now if the measurements of σx,y
a,b,c really had independent physical reality, as hidden variable
theory proclaims, then we can again make a list of all possible outcomes of measurements by three
observers A, B, C. Denoting these outcomes Ax, By, Cy etc, we are led to the following relations in
view of the fact that the state |Φ⟩measured here satisﬁes (17.62),
AxByCy
=
+1
AyBxCy
=
+1
AyByCx
=
+1
(17.67)
As a result, the measurement of the observable σx
a ⊗σx
b ⊗σx
c will yield
AxBxCx = (AxByCy)(AyBxCy)(AyByCx) = +1
(17.68)
since we have A2
y = B2
y = C2
y = +1. But this is in blatant contradiction with the eigenvalue of the
operator Σ which is −1.
233

18
Introductory Remarks on Quantized Fields
Quantum Field Theory (abbreviated QFT) deals with the quantization of ﬁelds. A familiar example
of a ﬁeld is provided by the electromagnetic ﬁeld. Classical electromagnetism describes the dynamics
of electric charges and currents, as well as electro-magnetic waves, such as radio waves and light,
in terms of Maxwell’s equations. At the atomic level, however, the quantum nature of atoms as
well as the quantum nature of electromagnetic radiation must be taken into account. Quantum
mechanically, electromagnetic waves turn out to be composed of quanta of light, whose individual
behavior is closer to that of a particle than to a wave.
Remarkably, the quantization of the
electromagnetic ﬁeld is in terms of the quanta of this ﬁeld, which are particles, also called photons.
In QFT, this ﬁeld particle correspondence is used both ways, and it is one of the key assumptions
of QFT that to every elementary particle, there corresponds a ﬁeld. Thus, the electron will have
its own ﬁeld, and so will every quark.
Quantum Field Theory provides an elaborate general formalism for the ﬁeld–particle correspon-
dence. The advantage of QFT will be that it can naturally account for the creation and annihilation
of particles, which ordinary quantum mechanics of the Schr¨odinger equation could not describe.
The fact that the number of particles in a system can change over time is a very important phe-
nomenon, which takes place continuously in everyone’s daily surroundings, but whose signiﬁcance
may not have been previously noticed.
In classical mechanics, the number of particles in a closed system is conserved, i.e. the total
number of particles is unchanged in time. To each pointlike particle, one associates a set of position
and momentum coordinates, the time evolution of which is governed by the dynamics of the system.
Quantum mechanics may be formulated in two stages.
1. The principles of quantum mechanics, such as the deﬁnitions of states, observables, are
general and do not make assumptions on whether the number of particles in the system is
conserved during time evolution.
2. The speciﬁc dynamics of the quantum system, described by the Hamiltonian, may or may
not assume particle number conservation. In introductory quantum mechanics, dynamics is
usually associated with non-relativistic mechanical systems (augmented with spin degrees of
freedom) and therefore assumes a ﬁxed number of particles. In many important quantum
systems, however, the number of particles is not conserved.
A familiar and ubiquitous example is that of electromagnetic radiation. An excited atom may
decay into its ground state by emitting a single quantum of light or photon. The photon was not
“inside” the excited atom prior to the emission; it was “created” by the excited atom during its
transition to the grounds state. This is well illustrated as follows. An atom in a state of suﬃciently
high excitation may decay to its ground state in a single step by emitting a single photon. However,
it may also emit a ﬁrst photon to a lower excited state which in turn re-emits one or more photons
in order to decay to the ground state (see Figure ??, (a) and (b)). Thus, given initial and ﬁnal
states, the number of photons emitted may vary, lending further support to the fact that no photons
are “inside” the excited state to begin with.
234

Other systems where particle number is not conserved involve phonons and spin waves in
condensed matter problems. Phonons are the quanta associated with vibrational modes of a crystal
or ﬂuid, while spin waves are associated with ﬂuctuating spins. The number of particles is also not
conserved in nuclear processes like fusion and ﬁssion.
18.1
Relativity and quantum mechanics
Special relativity invariably implies that the number of particles is not conserved. Indeed, one of
the key results of special relativity is the fact that mass is a form of energy. A particle at rest with
mass m has a rest energy given by the famous formula
E = mc2
(18.1)
The formula also implies that, given enough energy, one can create particles out of just energy –
kinetic energy for example. This mechanism is at work in ﬁre and light bulbs, where energy is
being provided from chemical combustion or electrical input to excite atoms which then emit light
in the form of photons. The mechanism is also being used in particle accelerators to produce new
particles through the collision of two incoming particles. In Figure ?? the example of a photon
scattering oﬀan electron is illustrated. In (c), a photon of low energy (≪mec2) is being scattered
elastically which results simply in a deﬂection of the photon and a recoil of the electron. In (d), a
photon of high energy (≫mec2) is being scattered inelastically, resulting not only in a deﬂection
of the photon and a recoil of the electron, but also in the production of new particles.
The particle data table also provides numerous examples of particles that are unstable and
decay. In each of these processes, the number of particles is not conserved. To list just a few,
n
→
p+ + e−+ ¯νe
π0
→
γ + γ
π+
→
µ+ + νµ
µ+
→
e+ + νe + ¯νµ
As already mentioned, nuclear processes such as fusion and ﬁssion are further examples of systems
in which the number of particles is not conserved.
18.2
Why Quantum Field Theory ?
Quantum Field Theory is a formulation of a quantum system in which the number of particles does
not have to be conserved but may vary freely. QFT does not require a change in the principles of
either quantum mechanics or relativity. QFT requires a diﬀerent formulation of the dynamics of
the particles involved in the system.
Clearly, such a description must go well beyond the usual Schr¨odinger equation, whose very
formulation requires that the number of particles in a system be ﬁxed. Quantum ﬁeld theory may
be formulated for non-relativistic systems in which the number of particles is not conserved, (recall
235

spin waves, phonons, spinons etc). Here, however, we shall concentrate on relativistic quantum ﬁeld
theory because relativity forces the number of particles not to be conserved. In addition, relativity
is one of the great fundamental principles of Nature, so that its incorporation into the theory is
mandated at a fundamental level.
18.3
Further conceptual changes required by relativity
Relativity introduces some further fundamental changes in both the nature and the formalism of
quantum mechanics. We shall just mention a few.
• Space versus time
In non-relativistic quantum mechanics, the position x, the momentum p and the energy E of
free or interacting particles are all observables. This means that each of these quantities separately
can be measured to arbitrary precision in an arbitrarily short time. By contrast, the accurarcy of
the simultaneous measurement of x and p is limited by the Heisenberg uncertainty relations,
∆x ∆p ∼¯h
There is also an energy-time uncertainty relation ∆E ∆t ∼¯h, but its interpretation is quite
diﬀerent from the relation ∆x ∆p ∼¯h, because in ordinary quantum mechanics, time is viewed
as a parameter and not as an observable. Instead the energy-time uncertainty relation governs
the time evolution of an interacting system. In relativistic dynamics, particle-antiparticle pairs
can always be created, which subjects an interacting particle always to a cloud of pairs, and thus
inherently to an uncertainty as to which particle one is describing. Therefore, the momentum itself
is no longer an instantaneous observable, but will be subject to the a momentum-time uncertainty
relation ∆p ∆t ∼¯h/c. As c →∞, this eﬀect would disappear, but it is relevant for relativistic
processes. Thus, momentum can only be observed with precision away from the interaction region.
Special relativity puts space and time on the same footing, so we have the choice of either
treating space and time both as observables (a bad idea, even in quantum mechanics) or to treat
them both as parameters, which is how QFT will be formulated.
• “Negative energy” solutions and anti-particles
The kinetic law for a relativistic particle of mass m is
E2 = m2c4 + p2c2
Positive and negative square roots for E naturally arise. Classically of course one may just keep
positive energy particles. Quantum mechanically, interactions induce transitions to negative energy
states, which therefore cannot be excluded arbitrarily. Following Feynman, the correct interpreta-
tion is that these solutions correspond to negative frequencies, which describe physical anti-particles
with positive energy traveling “backward in time”.
• Local Fields and Local Interactions
Instantaneous forces acting at a distance, such as appear in Newton’s gravitational force and
Coulomb’s electrostatic force, are incompatible with special relativity. No signal can travel faster
236

than the speed of light.
Instead, in a relativistic theory, the interaction must be mediated by
another particle. That particle is the graviton for the gravitational force and the photon for the
electromagnetic force. The true interaction then occurs at an instant in time and at a point in
space, thus expressing the forces in terms of local interactions only. Thus, the Coulomb force is
really a limit of relativistic “retarded” and “advanced” interactions, mediated by the exchange of
photons. The exchange is pictorially represented in Figure ??.
One may realize this picture concretely in terms of local ﬁelds, which have local couplings to
one another. The most basic prototype for such a ﬁeld is the electro-magnetic ﬁeld. Once a ﬁeld
has been associated to the photon, then it will become natural to associate a ﬁeld to every particle
that is viewed as elementary in the theory. Thus, electrons and positrons will have their (Dirac)
ﬁeld. There was a time that a ﬁeld was associated also to the proton, but we now know that the
proton is composite and thus, instead, there are now ﬁelds for quarks and gluons, which are the
elementary particles that make up a proton. The gluons are the analogs for the strong force of the
photon for the electro-magnetic force, namely the gluons mediate the strong force. Analogously,
the W ± and Z0 mediate the weak interactions.
18.4
Some History and present signiﬁcance of QFT
The quantization of the elctro-magnetic ﬁeld was initiated by Born, Heisenberg and Jordan in
1926, right after quantum mechanics had been given its deﬁnitive formulation by Heisenberg and
Schr¨odinger in 1925. The complete formulation of the dynamics was given by Dirac Heiseberg and
Pauli in 1927. Inﬁnities in perturbative corrections due to high energy (or UV – ultraviolet) eﬀects
were ﬁrst studied by Oppenheimer and Bethe in the 1930’s. It took until 1945-49 until Tomonaga,
Schwinger and Feynman gave a completely relativistic formulation of Quantum Electrodynamics
(or QED) and evaluated the radiative corrections to the magnetic moment of the electron. In 1950,
Dyson showed that the UV divergences of QED can be systematically dealt with by the process of
renormalization.
In the 1960’s Glashow, Weinberg and Salam formulated a renormalizable quantum ﬁeld theory
of the weak interactions in terms of a Yang-Mills theory.
Yang-Mills theory was shown to be
renormalizable by ‘t Hooft in 1971, a problem that was posed to him by his advisor Veltman. In
1973, Gross, Wilczek and Politzer discovered asymptotic freedom of certain Yang-Mills theories (the
fact that the strong force between quarks becomes weak at high energies) and using this unique clue,
they formulated (independently also Weinberg) the quantum ﬁeld theory of the strong interactions.
Thus, the elctro-magnetic, weak and strong forces are presently described – and very accurately
so – by quantum ﬁeld theory, speciﬁcally Yang-Mills theory, and this combined theory is usually
referred to as the STANDARD MODEL. To give just one example of the power of the quantum
ﬁeld theory approach, one may quote the experimentally measured and theoretically calculated
values of the muon magnetic dipole moment,
1
2gµ(exp)
=
1.001159652410(200)
1
2gµ(thy)
=
1.001159652359(282)
(18.2)
237

revealing an astounding degree of agreement.
The gravitational force, described classically by Einstein’s general relativity theory, does not
seem to lend itself to a QFT description. String theory appears to provide a more appropriate
description of the quantum theory of gravity. String theory is an extension of QFT, whose very
formulation is built squarely on QFT and which reduces to QFT in the low energy limit.
The devlopment of quantum ﬁeld theory has gone hand in hand with developments in Condensed
Matter theory and Statistical Mechanics, especially critical phenomena and phase transitions.
A ﬁnal remark is in order on QFT and mathematics. Contrarily to the situation with general
relativity and quantum mechanics, there is no good “axiomatic formulation” of QFT, i.e. one is very
hard pressed to lay down a set of simple postulates from which QFT may then be constructed in
a deductive manner. For many years, physicists and mathematicians have attempted to formulate
such a set of axioms, but the theories that could be ﬁt into this framework almost always seem
to miss the physically most relevant ones, such as Yang-Mills theory. Thus, to date, there is no
satsifactory mathematical “deﬁnition” of a QFT.
Conversely, however, QFT has had a remarkably strong inﬂuence on mathematics over the past
25 years, with the development of Yang-Mills theory, instantons, monopoles, conformal ﬁeld theory,
Chern-Simons theory, topological ﬁeld theory and superstring theory. Some developments is QFT
have led to revolutions in mathematics, such as Seiberg-Witten theory. It is suspected by some
that this is only the tip of the iceberg, and that we are only beginning to have a glimpse at the
powerful applications of quantum ﬁeld theory to mathematics.
238

19
Quantization of the Free Electro-magnetic Field
We shall begin by presenting a brief review of classical Maxwell theory, and then proceed to the
quantization of the free Maxwell ﬁeld.
19.1
Classical Maxwell theory
Maxwell’s equations for the electric ﬁeld E and the magnetic ﬁeld B, in the presence of an electric
charge density ρ and an electric charge current density j are usually divided into two groups. The
ﬁrst group of equations does not involve ρ and j and is given as follows,
∇× E
=
−∂tB
∇· B
=
0
(19.1)
while the second group depends on ρ and j, and is given by
∇× B
=
1
c2 ∂tE + µ0j
∇· E
=
1
ε0
ρ
(19.2)
Integrability of the equations in the second group (19.2) requires (local) electric charge conservation,
∇· j + ∂tρ = 0
(19.3)
Maxwell’s equations are inconsistent unless this equation holds. Notice that c2ε0µ0 = 1, where c, ε0,
and µ0 are respectively the speed of light, the electric permittivity and the magnetic permeability
in vacuum.
The two equations in (19.1) may be completely solved in terms of a scalar potential A0, and a
vector potential A, as follows,
E
=
∇A0 −∂tA
B
=
∇× A
(19.4)
Note that the customary electric potential Φ is related to A0 by A0 = −Φ. Given E and B, the
corresponding scalar and vector potentials are not unique, since E and B are invariant under the
following gauge transformations,
A0
→
A′
0 = A0 + ∂tΛ
A
→
A′ = A + ∇Λ
(19.5)
where Λ is an arbitrary function of t and x. This arbitrariness allows us to impose one extra scalar
condition on (A0, A), and such a condition is referred to as a gauge condition, or a gauge choice.
239

For the problems of radiation which we shall be interested in here, one particularly convenient
choice is the transverse or radiation gauge,
∇· A = 0
(19.6)
Given ﬁelds A0 and A, the explicit gauge transformation Λ that transform ∇·A obeys the following
relation, ∇· A −∆Λ = 0, whose general solution is given by,
Λ(t, x) =
Z
d3x′
1
4π|x′ −x| ∇· A(t, x′)
(19.7)
where we have used the basic Coulomb equation, ∆(1/|x|) = −4πδ(3)(x). This gauge transformation
is then to be carried out on both A0 and A. In transverse gauge, Gauss’s law, namely ∇·E = ρ/ε0
allow one to solve for the electric potential A0, and we ﬁnd,
A0(t, x) = −
Z
d3x′
1
4πε0|x′ −x| ρ(t, x′)
(19.8)
Since, in the transverse gauge, the ﬁeld A0, and its time-dependence, are completely determined by
the external source ρ, the ﬁeld A0 has no dynamics. The ﬁeld A may be solved for in an analogous
fashion. Expressing E and B in terms of A0 and A, using (19.4), the general relation
∇× (∇× A) = −∆A −∇(∇· A)
(19.9)
as well as the transverse gauge condition (19.6), we ﬁnd that A obeys the following wave-like
equation,
1
c2 ∂2
t A −∆A = µ0j −1
c2 ∂t∇A0
(19.10)
where A0 is now viewed as given in terms of ρ by (19.8). Because in ∂t∇A0, only the t-derivative
of ρ enters, we are free to use the charge conservation equation (19.3), and replace ∂tρ by −∇· j.
The result may be expressed as follows,
1
c2 ∂2
t A −∆A = µ0j⊥
(19.11)
where j⊥is given by
j⊥(t, x) = j(t, x) −∇
Z
d3x′
1
4π|x′ −x|∇· j(t, x′)
(19.12)
Since Maxwell’s equations, for given external sources ρ and j are linear, they may be solved explic-
itly.
The Lagrangian L and Hamiltonian H are given as integrals over the space of the Lagrangian
density L and Hamiltonian density H respectively as follows,
L =
Z
d3x L
L = 1
2ε0E2 −
1
2µ0
B2 + ρA0 + A · j
H =
Z
d3x H
H = 1
2ε0E2 +
1
2µ0
B2 −ρA0 −A · j
(19.13)
240

In the Hamiltonian formalism, the momentum Πi canonically conjugate to Ai is given by
Πi = ∂L
∂˙Ai
= ε0 ˙Ai = −ε0Ei
(19.14)
Now, in general, it is an enormous nuisance to keep the quantities ε0, µ0, and even c explicit. Thus,
henceforth, we shall set ε0 = µ0 = c = 1. Using dimensional analysis, these constants may always
be restored in a unique way.
19.2
Fourrier modes and radiation oscillators
We begin by considering and solving Maxwell’s equations without sources, namely for ρ = j = 0,
in which case we are left to solve the following equations,
∂2
t A −∆A
=
0
∇· A
=
0
(19.15)
Both are linear partial diﬀerential equations with constant coeﬃcients, and may be solved using
Fourrier analysis. It will be convenient to Fourrier transform only in space, but not in time; thus
we deﬁne this Fourier transform C(t, k) by,
A(t, x) =
Z
d3k
(2π)3 C(t, k) eik·x
(19.16)
so that (19.15) reduce to,
(∂2
t + k2)C(t, k)
=
0
k · C(t, k)
=
0
(19.17)
The Fourrier transform C(t, k) is a complex function. Thus, the reality of the ﬁeld A requires a
complex conjugation relation on C,
C(t, −k)∗= C(t, k)
(19.18)
The last equation of (19.17) implies that for any given k, the Fourrier transform C(t, k) is perpen-
dicular, or transverse, to the momentum k, whence the name for this gauge condition. Thus, for
given k, C(t, k) takes values in the 2-dimensional space orthogonal to k. It will be convenient to
choose a basis of two orthonormal vectors εα(k) for this transverse space,
k · εα(k)
=
0
ε∗
α(k) · εβ(k)
=
δα,β
α, β = 1, 2
(19.19)
The ﬁrst equation of (19.17) on C is a harmonic oscillator with frequency
ω = ωk = |k|
(19.20)
241

whose general solution is a linear combination of eiωt and e−iωt. Combining now the solution for
all equations on C, we have
C(t, k) =
1
√
2ω
X
α=1,2

εα(k)aα(k)e−iωt + ε′
α(k)a′
α(k)e+iωt

(19.21)
where aα(k) and α′
α(k) are arbitrary complex coeﬃcients. The overall normalization factor 1/
√
2ω
is not ﬁxed by the Maxwell’s equations, but has been introduced for later convenience. By con-
struction, this expression automatically solves both equations in (19.15). It remains to enforce the
complex conjugation condition. To this end, we compute,
C(t, −k)∗=
1
√
2ω
X
α=1,2

εα(−k)∗aα(−k)∗e+iωt + ε′
α(−k)∗a′
α(−k)∗e−iωt

(19.22)
Equating with C(t, k), as required by (19.18) requires that ε′
α(k)a′
α(k) = εα(−k)∗aα(−k)∗for all
k. Next, we make use of the fact that the basis ε′
α(k) may be related to the basis εα(bk), as long
as both obey the equations of (19.19). Thus, we have,
ε′
α(k)
=
εα(−k)∗
aα(k)′
=
aα(−k)∗
(19.23)
Putting all together, we have,
C(t, k) =
1
√
2ω
X
α=1,2

εα(k)aα(k)e−iωt + εα(−k)∗aα(−k)∗e+iωt

(19.24)
To complete our solution, we substitute this result into the Fourrier transform of (19.16),
A(t, x) =
Z
d3k
(2π)3
1
√
2ω
X
α=1,2

εα(k)aα(k)e−ik·x + εα(k)∗aα(k)∗e+ik·x

(19.25)
Here, we have started to use relativity notation for the inner product of the two 4-vectors k and x,
k · x ≡ωt −k · x
(19.26)
The expression (19.25) provides a complete solution for the vector potential to Maxwell’s equations
in transverse gauge.
19.3
The Hamiltonian in terms of radiation oscillators
In the absence of electric charge density and current, the Maxwell Hamiltonian is simply,
H =
Z
d3x
1
2E2 + 1
2B2

(19.27)
242

To evaluate H in terms of the vector potential, in transverse gauge, we use the expressions E =
−∂tA and B = ∇× A, which themselves may be expressed in terms of the oscillator variables
aα(k) as follows,
E(t, x)
=
−
Z
d3k
(2π)3 ∂tC(t, k) eik·x
B(t, x)
=
i
Z
d3k
(2π)3 k × C(t, k) eik·x
(19.28)
The electric contribution to the Hamiltonian is calculated as follows,
Z
d3x E2 =
Z
d3x
Z
d3k
(2π)3 ∂tC(t, k)eik·x
Z
d3k′
(2π)3 ∂tC(t, k′)eik′·x
(19.29)
The use of the Fourrier equation
Z
d3x ei(k+k′)·x = (2π)3δ(3)(k + k′)
(19.30)
implies that the k′-integral can be carried out explicitly, and results in the following expression for
the electric part of the Hamiltonian,
1
2
Z
d3x E2
=
1
2
Z
d3k
(2π)3 ∂tC(t, k) · ∂tC(t, −k)
=
1
2
Z
d3k
(2π)3 ∂tC(t, k) · ∂tC(t, k)∗
(19.31)
The magnetic part is computed analogously, and we ﬁnd,
1
2
Z
d3x B2
=
1
2
Z
d3k
(2π)3 k2C(t, k) · C(t, k)∗
(19.32)
As a result, the full Hamiltonian is given by
H = 1
2
Z
d3k
(2π)3

∂tC(t, k) · ∂tC(t, k)∗+ k2C(t, k) · C(t, k)∗

(19.33)
Next, we proceed to express H in terms of the oscillator degrees of freedom aα(k), with the help
of (19.24). First, evaluate
∂tC(t, k) · ∂tC(t, k)∗+ k2C(t, k) · C(t, k)∗
= |k|
X
α,β

εα(k) · εβ(k)∗aα(k)αβ(k)∗+ ε∗
α · εβ aα(−k)∗αβ(−k)

(19.34)
Using orthogonality εα · ε∗
β = δαβ, we ﬁnd,
∂tC(t, k) · ∂tC(t, k)∗+ k2C(t, k) · C(t, k)∗
= |k|
X
α

aα(k)αα(k)∗+ aα(−k)∗αα(−k)

(19.35)
243

so that we have the following expression for the full Hamiltonian,
H =
Z
d3k
(2π)3
X
α
|k| aα(k)∗αα(k)
(19.36)
The Poisson brackets of aα(k) with aα(k′) and with aα(k′)∗may be induced from the time evolution
equations for these oscillators, which are already available to us, namely,
aα(t, k) = aα(0, k) e−i|k|t
(19.37)
As a result, we have
∂taα(t, k) = −i|k|aα(t, k) = {H, aα(t, k)}
(19.38)
which is naturally realized in terms of
{aα(k), αβ(k′)}
=
0
{aα(k), αβ(k′)∗}
=
iδαβδ(3)(k′ −k)
(19.39)
One recognizes this Hamiltonian, and associated Poisson brackets as those corresponding to an
inﬁnite number of independent harmonic oscillators aα(k), labelled by the combined index (α, k).
One may pass, formally, to a more familiar notation for the harmonic oscillators in terms of real
degrees of freedom xα(k) and pα(k),
aα(k)
=
1
√
2ω

+ ipα(k) + ωxα(k)

aα(k)∗
=
1
√
2ω

−ipα(k) + ωxα(k)

(19.40)
in terms of which the Hamiltonian takes the form
H =
Z
d3k
(2π)3
X
α
1
2pα(k)2 + 1
2ω2 xα(k)2

(19.41)
where the Poisson brackets take the form,
{xα(k), pα(k′)}
=
δαβδ(3)(k′ −k)
{xα(k), xα(k′)}
=
0
{pα(k), pα(k′)}
=
0
(19.42)
Of course, it must be pointed out that xα and pα are not actual positions and momentum operators
of the photon. They are formal devices without direct physical meaning.
244

19.4
Momentum in terms of radiation oscillators
The classical electro-magnetic ﬁeld carries momentum, which may be expressed in terms of the
Poynting vector,
P =
Z
d2x E(t, x) × B(t, x)
(19.43)
This qunatity may be similarly expressed in terms of the radiation oscillators aα, in a manner
analogous to energy, and we have
P = i
Z
d3k
(2π)3 ∂tC(t, k) ×

k × C(t, k)

(19.44)
Expressing C in terms of aα and a∗
α, using the algebraic identity
A × (B × C) = B(A · C) −C(A · B)
(19.45)
applied to the problem at hand yields
εα(k) ×

k × εβ(−k)

= k εα(k) · εβ(−k)
(19.46)
The integral of (19.44) contains a part in e−2iωt, one in e2iωt, and ﬁnally one independent of t. The
ﬁrst one of these is proportional to
X
α,β
k εα(k) · εβ(−k)αα(k)αβ(−k)
(19.47)
which is odd in k, and whose integral over k thus vanishes. The second term similarly vanishes.
The t-independent term is the only one that contributes, and we have
P =
Z
d3k
(2π)3 k
X
α
αα(k)∗αα(k)
(19.48)
19.5
Canonical quantization of electro-magnetic ﬁelds
From the above classical discussion of the electro-magnetic ﬁelds, it is manifest that their dynamics
is equivalent to that of an inﬁnite number of harmonic oscillators
aα(k)
aα(k)∗
α = 1, 2
k ∈R3
(19.49)
We shall now quantize the electro-magnetic ﬁeld by canonically quantizing each of the harmonic
oscillators which build up the ﬁeld. Thus, aα(k) is to be viewed as an operator on (an until now
undetermined) Hilbert space. Together with its adjoint a†
α(k), the oscillators satisfy the following
canonical commutation relations,
[aα(k), aβ(k′)]
=
0
[a†
α(k), a†
β(k′)]
=
0
[aα(k), a†
β(k′)]
=
(2π)3δαβδ(3)(k −k′)
(19.50)
245

The only novelty here, as compared with systems of ﬁnite numbers of harmonic oscillators, is that
here, the oscillators are indexed by a continuous variable k, and the Kronecker δ in the commutation
relations is replaced by a Dirac δ-function.
The Hamiltonian and momentum operators take the following values,
H
=
Z
d3k
(2π)3 ω
X
α
a†
α(k)aα(k)
P
=
Z
d3k
(2π)3 k
X
α
a†
α(k)aα(k)
(19.51)
Note that the Hamiltonian, given above, involves a choice. The classical Hamiltonian was expressed
in terms of aα(k)∗aα(k), a quantity whose translation into an operator via the correspondence
principle, is ambiguous. In general, either ordering of the operators might have occurred, or any
linear combination of the two orderings, such as
Hλ =
Z
d3k
(2π)3 ω
X
α

(1 −λ)a†
α(k)aα(k) + λaα(k)a†
α(k)

(19.52)
so that the original Hamiltonian H corresponds to H = H0. Using the canonical commutations,
the diﬀerence between two Hamiltonians may be deduced from
Hλ −H = λ
Z
d3k
(2π)3 ω
X
α
[aα(k), a†
α(k)] = 2λ
Z
d3k ω δ(3)(0)
(19.53)
This energy shift is inﬁnite due to the space-volume inﬁnity δ(3)(0), as well as due to the momentum
volume space inﬁnity resulting from the integration over k extending out to ∞values of k. More
importantly, however, the shift is a constant independent of aα(k) and a†
α(k), which is unobservable
(only diﬀerences in energy are observable). For the momentum, the analogous shift involves an
integral over k, which is odd and vanishes.
19.6
Photons – the Hilbert space of states
It remains to construct the Hilbert space of states.
We have identiﬁed the observables xα(k)
and pα(k), and their non-self-adjoint equivalents aα(k) and aα(k)†, as the fundamental mutually
independent quantities to which the electro-magnetic ﬁelds are equivalent. Thus, the Hilbert space
may be faithfully constructed in terms of these harmonic oscillators.
19.6.1
The ground state or vacuum
The ground state, or the vacuum, is deﬁned to be the state of lowest energy of the total system.
Thus it must be the lowest energy state for each one of the harmonic oscillators, which requires
that this state must be annihilated by the operators aα(k) for all α = 1, 2 and for all k ∈R3,
aα(k)|∅⟩= 0
(19.54)
246

It will be assumed throughout that this state is unique and normalized as follows,
∥|∅⟩λ = ⟨∅|∅⟩= 1
(19.55)
As an immediate result of the expressions for the hamiltonian and momentum operators (19.51),
it follows that the ground state has zero energy and zero momentum,
H|∅⟩= P|∅⟩= 0
(19.56)
A diﬀerent convention for the ordering of the oscillators in H might have resulted in a non-zero
energy of the ground state.
19.6.2
One-photon states
Applying any raising operator a†
α(k) to the vacuum will raise the energy above zero. We deﬁne
these states as follows,
|k, α⟩≡a†
α(k)|∅⟩
(19.57)
The total energy and momentum of such states may be computed by applying the operators H and
P thereto, and we ﬁnd,
H|k, α⟩=
Z
d3k′
(2π)3 |k′|
X
β
a†
β(k′)[aβ(k′), a†
α(k)]|∅⟩
(19.58)
where we have used the relation aβ(k′)|∅⟩= 0 in exhibiting the commutator.
Using now the
canonical commutator, we ﬁnd,
H|k, α⟩
=
|k| |k, α⟩
P|k, α⟩
=
k |k, α⟩
(19.59)
The normalization of the one-particle states is that of the continuum, as is suitable for states
indexed by the continuous momentum k,
⟨k, α|k′, β⟩= (2π)3δ(3)(k′ −k)δαβ
(19.60)
Given the fact that the state |k, α⟩has total energy E = ¯h|k| and momentum p = ¯hk, its relativistic
invariant mass vanishes. We interpret these states as containing a single photon, of energy ¯h|k| and
momentum ¯hk. We shall see below what the nature is of states with higher numbers of photons.
They cannot, in general, have vanishing mass.
19.6.3
Multi-photon states
Applying now several raising operators to |0⟩, we obtain the following types of states,
|ψ⟩= |k1, α1; · · · ; kn, αn⟩≡a†
α1(k1) · · · a†
αn(kn)|∅⟩
(19.61)
247

whose energy and momentum is readily computed, and we have,
H|ψ⟩= E|ψ⟩
E = |k1| + · · · + |kn|
P|ψ⟩= p|ψ⟩
p = k1 + · · · + kn
(19.62)
Energy and momentum are simply the sums of the n one-particle energy and momentum values, a
superposition relation characteristic of non-interacting, or free particles. It is instructive to calculate
the relativistic invariant mass of a system of two free photons, for example. We ﬁnd,
m2 = (|k1| + |k2|)2 −(k1 + k2)2 = 2|k1| |k2|(1 −cos θ)
(19.63)
where θ is the angle between k1 and k2. For generic values of θ, we have m2 ̸= 0, signaling that they
form a genuine two-state system. For θ = 0, we have collinear photons, with m2 = 0. It may seem
that the state with two parallel photons or with one photon with exactly the same total energy are
really one and the same thing. But this is not so, because there exists in fact an operator whose
eigenvalues distinguish between these two cases. This is the photon number operator, deﬁned by
N =
Z
d3k′
(2π)3
X
α
a†
α(k)aα(k)
(19.64)
Its eigenvalue on a general state is given by,
N|k1, α1; · · · ; kn, αn⟩= n|k1, α1; · · · ; kn, αn⟩
(19.65)
and thus distinguished between states with identical energy and momentum but diﬀerent numbers
of photons. Note that, for free photons, we have
[N, H] = [N, P] = 0
(19.66)
so that the number of free photons is conserved during time evolution. Of course, once photons
interact, such as with charges particles or dipoles, then the number of photons will no longer remain
conserved and H will no longer commute with N.
Finally, we have seen how the operator a†
α(k) creates a photon with momentum k and polariza-
tion α. But similarly, the operator aα(k) annihilates a photon with momentum k and polarization
α out of any state. If the state contains no such photon, then the operator aα(k) produces 0. More
generally, we have
aα(k)|k1, α1; · · · ; kn, αn⟩=
n
X
i=1
(2π)3δα,αiδ(3)(k −ki)|k1, α1; · · · ; d
ki, αi; · · · ; kn, αn⟩
(19.67)
where the wide hat over ki, αi gives the instruction of deleting the entry ki, αi in the state descrip-
tion.
248

19.7
Bose-Einstein and Fermi-Dirac statistics
In classical mechanics, particles are distinguishable, namely each particle may be tagged and this
tagging survives throughout time evolution since particle identities are conserved.
In quantum mechanics, particles of the same species are indistinguishable, and cannot be tagged
individually. They can only be characterized by the quantum numbers of the state of the system.
Therefore, the operation of interchange of any two particles of the same species must be a symmetry
of the quantum system. The square of the interchange operation is the identity.17 As a result, the
quantum states must have deﬁnite symmetry properties under the interchange of two particles.
All particles in Nature are either bosons or fermions;
• BOSONS : the quantum state is symmetric under the interchange of any pair of particles
and obey Bose-Einstein statistics. Bosons have integer spin. For example, photons, W ±, Z0,
gluons and gravitons are bosonic elementary particles, while the Hydrogen atom, the He4
and deuterium nuclei are composite bosons.
• FERMIONS : the quantum state is anti-symmetric under the interchange of any pair of
particles and obey Fermi-Dirac statistics. Fermions have integer plus half spin. For example,
all quarks and leptons are fermionic elementary particles, while the proton, neutron and He3
nucleus are composite fermions.
Remarkably, the quantization of free scalars and free photons carried out in the preceeding
subsections has Bose-Einstein statistics built in. The bosonic creation and annihilation operators
are denoted by a†
σ(⃗k) and aσ(⃗k) for each species σ. The canonical commutation relations inform
us that all creation operators commute with one another [a†
σ(⃗k), a†
σ′(⃗k′)] = 0. As a result, two
states diﬀerening only by the interchange of two particle of the same species are identical quantum
mechanically,
a†
σ1(⃗k1) · · · a†
σi(⃗ki) · · · a†
σj(⃗kj) · · · a†
σn(⃗kn)|∅⟩
(19.68)
= a†
σ1(⃗k1) · · · a†
σj(⃗kj) · · · a†
σi(⃗ki) · · · a†
σn(⃗kn)|∅⟩
(19.69)
The famous CPT Theorem states that upon the quantization of a Poincar´e and CPT invariant
Lagrangian, integer spin ﬁelds will always produce particle states that obey Bose-Einstein statistics,
while integer plus half ﬁelds always produce states that obey Fermi-Dirac statistics.
• Fermi-Dirac Statistics
It remains to establish how integer plus half spin ﬁelds are to be quantized. This will be the
subject of the subsection on the Dirac equation. Here, we shall take a very simple approach whose
point of departure is the fact that fermions obey Fermi-Dirac statistics.
17This statement holds in 4 space-time dimensions but it does not hold generally. In 3 space-time dimen-
sions, the topology associated with the interchange of two particles allows for braiding and the square of this
operation is not 1. The corresponding particles are anyons.
249

First of all, a free fermion may be expected to be equivalent to a collection of oscillators, just
as bosonic free ﬁelds were. But they cannot quite be the usual harmonic oscillators, because we
have just shown above that harmonic operators produce Bose-Einstein statistics. Instead, the Pauli
exclusion principle states that only a single fermion is allowed to occupy a given quantum state.
This means that a fermion creation operator b† for given quantum numbers must square to 0.
Then, its repeated application to any state (which would create a quantum state with more than
one fermion particle with that species) will produce 0.
The smallest set of operators that can characterize a fermion state is given by the fermionic
oscillators b and b†, obeying the algebra
{b, b} = {b†, b†} = 0
{b, b†} = 1
(19.70)
In analogy with the bosonic oscillator, we consider the following simple Hamiltonian,
H = ω
2

b†b −bb†
= ω

b†b −1
2

(19.71)
Naturally, the ground state is deﬁned by b|0⟩= 0 and there are just two quantum states in this
system, namely |0⟩and b†|0⟩with energies −1
2ω and + 1
2ω respectively. A simple representation
of this algebra may be found by noticing that it is equivalent to the algebra of Pauli matrices or
Cliﬀord-Dirac algebra in 2 dimensions,
σ1 = b + b†
σ2 = ib −ib†
H = ω
2 σ3
(19.72)
Vice-versa, the γ-matrices in 4 dimensions are equivalent to two sets of fermionic oscillators bα and
b†
α, α = 1, 2. The above argumentation demsonstrates that its only irreducible representation is
4-dimensional, and spanned by the states |∅⟩, b†
1|∅⟩, b†
2|∅⟩, b†
1b†
2|∅⟩.
In terms of particles, we should aﬃx the quantum number of momentum ⃗k, so that we now
have oscillators bσ(⃗k) and b†
σ(⃗k), for some possible species index σ. Postulating anti-commutation
relations, we have
{bσ(⃗k), bσ′(⃗k′)} = {b†
σ(⃗k), b†
σ′(⃗k′)} = 0
{bσ(⃗k), b†
σ′(⃗k′)} = 2ωkδσσ′(2π)3δ(3)(⃗k −⃗k′)
(19.73)
where again ωk =
q
⃗k2 + m2. The Hamiltonian and momentum operators are naturally
H
=
Z
d3k
(2π)32ωk
ωk
X
σ
b†
σ(⃗k)bσ(⃗k)
⃗P
=
Z
d3k
(2π)32ωk
⃗k
X
σ
b†
σ(⃗k)bσ(⃗k)
(19.74)
The vacuum state |∅⟩is deﬁned by bσ(⃗k)|∅⟩= 0 and multiparticle states are obtained by applying
creation operators to the vacuum,
b†
σ1(⃗k1) · · · b†
σn(⃗kn)|0⟩
(19.75)
250

Using the fact that creation operators always anti-commute with one another, it is straightforward
to show that
b†
σ1(⃗k1) · · · b†
σi(⃗ki) · · · b†
σj(⃗kj) · · · b†
σn(⃗kn)|∅⟩
(19.76)
= −b†
σ1(⃗k1) · · · b†
σj(⃗kj) · · · b†
σi(⃗ki) · · · b†
σn(⃗kn)|∅⟩
(19.77)
so that the state obeys Fermi-Dirac statistics.
19.8
The photon spin and helicity
Just as we constructed the electro-magnetic momentum in terms of the Poynting vectors, so we
may also construct its total angular momentum,
J =
Z
d3x

x × (E × B)

(19.78)
Total angular momentum actually receives contributions from an orbital part L as well as from an
intrinsic photon spin part S, with the usual addition relation, J = L + S. We are concerned with
the spin part, and seek to separate it from L. This separation cannot in fact be achieved in a gauge
invariant way. The helicity of the photon, i.e. the projection of spin onto the photon momentum
is the only part of the spin which can be isolated in a gauge invariant way.
We begin by producing a gauge dependent construction of L and S, and we shall then extract
from these the gauge invariant helicity. Using B = ∇× A and the double cross product formula,
we have
E × B
=
X
i

Ei(∇Ai) −(∇iA)Ei

=
X
i

Ei(∇Ai) −∇i(AEi)

(19.79)
where we have used ∇· E = 0 in going from the ﬁrst to the second line. Next, we evaluate
x ×

E × B

=
X
i

Ei(x × ∇)Ai −∇i(x × AEi) + E × A

(19.80)
The second term is clearly a surface term, and does not contribute to the integral when evaluating
J. The ﬁrst term involves the orbital angular momentum operator x×∇, and naturally is associated
with orbital angular momentum, though it is not gauge invariant. Thus, we deﬁne,
L
=
Z
d3x
X
i
Ei

x × ∇

Ai
S
=
Z
d3x E × A
(19.81)
In transverse gauge, ∇· A = 0, the orbital part is automatically transverse to momentum, so we
shall use this gauge to evaluate spin. Expressing S in terms of C(t, k),
S =
Z
d3k
(2π)3 C(t, k) × ∂tC(t, k)
(19.82)
251

Expressing C in terms of the oscillator modes, we obtain t-dependent terms and t-independent
terms. The former vanish upon integration, as they are odd in k. The t-independent terms combine
as follows,
S = i
Z
d3k
(2π)3
X
α,β

εα(k) × ε∗
β(k)

aα(k)a†
β(k)
(19.83)
Note that the combination εα(k) × ε∗
β(k) is automatically anti-symmetric in α and β, and thus
parallel to k.
It is instructive to work out the Hilbert space of one-photon states at ﬁxed value of their
momentum. To do so, we choose the momentum along the z-axis, so that
k = (0, 0, k)
ε1(k) = (1, 0, 0)
ε2(k) = (0, 1, 0)
(19.84)
The polarization states may be denoted by
|k, 1⟩
=
a†
1(k)|∅⟩
|k, 2⟩
=
a†
2(k)|∅⟩
(19.85)
Measuring the z-component of spin (which is equivalent to helicity, since k points in the z-direction),
gives the following,
Sz|k, γ⟩
=
i
X
β

εγ(k) × ε∗
β(k)

za†
β(k)|∅⟩
=
i
X
β

εγ(k) × ε∗
β(k)

z|k, β⟩
(19.86)
Working this out separately for the cases γ = 1, 2, we obtain,
Sz|k, 1⟩
=
i

ε1(k) × ε∗
2(k)

z|k, 2⟩= +i|k, 2⟩
Sz|k, 2⟩
=
i

ε2(k) × ε∗
1(k)

z|k, 1⟩= −i|k, 2⟩
(19.87)
Forming the combinations with circular polarization gives the eigenstates of Sz, as follows,
Sz|k, ±⟩= ±|k, ±⟩
|k, ±⟩= 1
√
2

|k, 1⟩± i|k, 2⟩

(19.88)
As a result, the photon states contains just two spin states, with eigenvalues ±¯h, and we conclude
that the photon is spin 1.
252

19.9
The Casimir Eﬀect on parallel plates
Thus far, we have dealt with the quantization of the free electromagnetic ﬁelds ⃗E and ⃗B, Already
at this stage, it is possible to infer measurable predictions, such as the Casimir eﬀect. The Casimir
eﬀect is a purely quantum ﬁeld theory phenomenon in which the quantization of the electromagnetic
ﬁelds in the presence of a electric conductors results in a net force between these conductors.
The most famous example involves two conducting parallel plates, separated by a distance a, as
represented in Fig18(a).
-- a --
(a)
(b)
L
L
L
Ep =0
Figure 18: The Casimir eﬀect : (a) electromagnetic vacuum ﬂuctuations produce a force
between two parallel plates; (b) the problem in a space box.
The assumptions entering the set-up are as follows.
1. For a physical conductor, the electric ﬁeld ⃗Ep parallel to the plates will vanish for frequencies
much lower than the typical atomic scale ωc. At frequencies much higher than the atomic
scale, the conductor eﬀectively becomes transparent and no constraint is to be imposed on
the electric ﬁeld. In the frequency region comparable to the atomic scale ωc, the conductivity
is a complicated function of frequency, which we shall simply approximate by a step function
θ(ωc −ω).
2. The separation a should be taken much larger than interatomic distances, or aωc ≫1.
3. In order to regularize the problems associated with inﬁnite volume, we study the problem
in a square box in the form of a cube, with periodic boundary conditions, as depicted in
253

Fig18(b).
• Calculation of the frequencies
There are three distinct regimes in which the frequencies of the quantum oscillators need to be
computed. The momenta parallel to the plates are always of the following form,
kx = 2πnx
L
ky = 2πny
L
nx, ny ∈Z
(19.89)
Along the third direction, we distinguish three diﬀerent regimes, so that the frequency has three
diﬀerent branches,
ω(i) =
r
k2x + k2y + (k(i)
z )2
i = 1, 2, 3
(19.90)
The three regimes are as follows,
1. ω > ωc : the frequencies are the same as in the absence of the plates, since the plates are
acting as transparent objects,
k(1)
z
= 2πnz
L
nz ∈Z
2. ω < ωc & between the two plates.
k(2)
z
= πnz
a
0 ≤nz ∈Z
3. ω < ωc & outside the two plates.
k(3)
z
= πnz
L −a
0 ≤nz ∈Z
• Summing up the contributions of all frequencies
Finally, we are not interested in the total energy, but rather in the enrgy in the presence of the
plates minus the energy in the absence of the plates. Thus, when the frequencies exceed ωc, all
contributions to the enrgy cancel since the plates act as transparent bodies. Thus, we have
E(a) −E0 =
X
nx,ny,nz
1
2ω(2)(nx, ny, nz) + 1
2ω(3)(nx, ny, nz) −1
2ω(1)(nx, ny, nz)

(19.91)
When nz ̸= 0, two polarization modes have ⃗E with 2 components along the plates, while for nz = 0,
nx, ny ̸= 0, there is only one. Therefore, we isolate nz = 0,
E(a) −E0
=
1
2
X
nx,ny
ω(nx, ny, 0)
(19.92)
+
X
nx,ny
∞
X
nz=1

ω(2)(nx, ny, nz) + ω(3)(nx, ny, nz) −2ω(1)(nx, ny, nz)

254

Next, we are interested in taking the size of the box L very large compared to all other scales in
the problem. The levels in nx and ny then become very closely spaced and the sums over nx and
ny may be well-approximated by integrals, with the help of the following conversion process,
dnx = Ldkx
2π
dny = Lky
2π
(19.93)
so that
E(a) −E0
=
L2
4π2
Z +∞
−∞
dkx
Z +∞
−∞
dky
1
2ωθ(ωc −ω)
(19.94)
+
∞
X
nz=1

ω(2)θ(ωc −ω(2)) + ω(3)θ(ωc −ω(3)) −2ω(1)θ(ωc −ω(1))

(19.95)
Now, for ω(1) and ω(3), the frequency levels are also close together and the sum over nz may also
be approximated by an integral,
∞
X
nz=1
ω(2)θ(ωc −ω(2))
=
L −a
π
Z ∞
0
dkz
q
k2x + k2y + k2z θ(ωc −
q
k2x + k2y + k2z)
∞
X
nz=1
2ω(1) θ(ωc −ω(1))
=
L
2π 2
Z ∞
0
dkz
q
k2x + k2y + k2z θ(ωc −
q
k2x + k2y + k2z)
Introducing k2 = k2
x + k2
y, and in the last integral the continuous variable n = akz/π, we have
E(a) −E0
=
L2
2π
Z ∞
0
dk k
1
2kθ(ωc −k) +
∞
X
n=1
s
k2 + π2n2
a2
θ(ω2
c −k2 −π2n2
a2 )
−
Z ∞
0
dn
s
k2 + π2n2
a2
θ(ω2
c −k2 −π2n2
a2 )

Introducing the function
f(n) ≡
Z ∞
0
dk
2π k
s
k2 + π2n2
a2
θ(ω2
c −k2 −π2n2
a2 )
(19.96)
we have
E(a) −E0
L2
= 1
2f(0) +
∞
X
n=1
f(n) −
Z ∞
0
dnf(n)
(19.97)
Now, there is a famous formula that relates a sum of the values of a function at integers to the
integral of this function,
Z ∞
0
dnf(n) = 1
2f(0) +
∞
X
n=1
f(n) +
∞
X
p=1
B2p
(2p)!f (2p−1)(0)
(19.98)
255

where the Bernoulli numbers are deﬁned by
x
ex −1 =
∞
X
n=0
Bn
xn
n!
B2 = −1
6,
B4 = −1
30, · · ·
(19.99)
Assuming a sharp cutoﬀ, so that θ is a step function, we easily compute f(n),
f(n) = 1
6π

ω3
c −π3n3
a3

(19.100)
Thus, f (2p−1)(0) = 0 as soon as p > 2, while f (3)(0) = −π2/a3, and thus we have
E(a) −E0
L2
= π2
a3
B4
4! = −π2
720¯hcL2
a3
(19.101)
This represents a universal, attractive force proportional to 1/a4. To make their dependence ex-
plicit, we have restored the factors of ¯h and c.
256

20
Photon Emission and Absorption
In this chapter, we couple the quantized electro-magnetic ﬁeld to quantized matter, such as elec-
trons, protons, atoms and molecules.
The matter is assumed to be non-relativistic, and thus
described by the usual Hamiltonians where the number of matter particles is ﬁxed. We shall set
up the general problem of photon emission and absorption from matter, calculate the rate for a
single photon, apply this calculation to the case of the 2p state of atomic Hydrogen, and extend
the problem to black body radiation.
20.1
Setting up the general problem of photon emission/absorption
For simplicity, we shall consider here a pure matter Hamiltonian Hm for just a single particle of
mass is m, subject to a potential V ,
Hm = p2
2m + V (x)
(20.1)
Concretely, one may think of Hm as describing an electron bound to an atom or to an ion by the
potential V . We shall denote the Hilbert space of states for the pure matter system by Hm, and
denote its states by |ψ⟩m. Typically, we shall be interested in the system being initially in the pure
matter state |ψi⟩m, which is an eigenstate of Hm, and ﬁnally in the pure matter state |ψf⟩m plus
photons.
The quantized photons are governed by the Maxwell Hamiltonian HEM which was studied in
the preceding chapter. It is given by,
HEM =
Z
d3x
1
2E2 + 1
2B2

(20.2)
The Hilbert space of all photon states will be denoted by HEM. The photon states are labelled
by the momenta and the polarizations of the photons. For example, a state with one-photon of
momentum k and polarization α is labeled by |k, α⟩.
The full Hamiltonian is not just the sum of Hm and HEM, but requires the inclusion of the
couplings between matter and radiation.
These interactions are accounted for by including an
interaction Hamiltonian HI,
HI =
e
2m(A · p + p · A) + e2
2mA2 + µB · S
(20.3)
For spin 1/2 particles, the B · S term naturally arises from the non-relativistic approximation to
the Dirac equation, as we shall establish later. The full hamiltonian H = Hm + HEM + HI then
takes the form,
H =
1
2m(p + eA)2 + V (x) + µB · S +
Z
d3x
1
2E2 + 1
2B2

(20.4)
We recognize the ﬁrst three terms in H as identical to the Hamiltonian for a charged particle in
the presence of an external electro-magnetic ﬁeld. Thus, the coupling to the quantized ﬁelds is
257

obtained by simply promoting the classical A ﬁeld to a quantum operator. The Hilbert space H of
the full system is the tensor product of the Hilbert spaces of the matter and free radiation parts,
and given by H = Hm ⊗HEM.
20.2
Single Photon Emission/Absorption
Having developed the general set-up of the matter-radiation system, we shall now apply it to
the emission/absorption of a single photon. The initial state is assumed to correspond to a pure
matter state |ψi⟩m of Hm, and to have no photons. We shall denote this total state by |ψi; ∅⟩=
|ψi⟩m ⊗|∅⟩EM. We shall assume that |ψi⟩m is an eigenstate of Hm. This condition often constitutes
a good approximation to the situation in a real physical problem, in view of the fact that the electro-
magnetic coupling α = e2/¯hc is small. The ﬁnal state corresponds to a pure matter state |ψf⟩m,
but now has an extra photon. We shall denote this state by |ψf; k, α⟩= |ψf⟩m ⊗|k, α⟩EM, and
assume that also |ψf⟩m is an eigenstate of Hm. Since the coupling is weak, we shall use ﬁrst order
perturbation theory to evaluate the transition rate. To do so, the full Hamiltonian is separated
into a “free part” H0 = Hm + HEM and an interacting part HI. The initial states are eigenstates
of H0,
H0|ψi; ∅⟩
=
E(0)
i
|ψi; ∅⟩
H0|ψf; k, α⟩
=
(E(0)
f
+ ωk)|ψf; k, α⟩
(20.5)
where E(0)
i
and E(0)
f
are the energies of |ψi⟩m and |ψf⟩m respectively, and ωk = |k|.
First order perturbation theory allows us to compute the transition rate Γi→f from the initial
state |i⟩= |ψi; ∅⟩to the ﬁnal state |f⟩= |ψf; k, α⟩, under the time evolution governed by the full
Hamiltonian H = H0 + H1. The rate is given by Fermi’s golden rule formula,
Γi→f = 2π
⟨f|H1|ı⟩

2δ(Ef −Ei)
(20.6)
where Ef and Ei are the total energies of the ﬁnal and initial states respectively, and given by
Ei = E(0)
i
and Ef = E(0)
f
+ ωk. The rate Γi→f is often referred to as the exclusive rate because
the ﬁnal state is speciﬁed to be a photon with speciﬁc momentum k and polarization α. It is often
useful to consider the includive or total rate, obtained by summing over the contributions to all
possible ﬁnal states, obtained here by summing over all photon momenta and polarizations. The
total rate is given by
Γ =
X
f
Γi→f
(20.7)
To evaluate the rate in practice, we have to calculate the matrix element of H1 between the state
without photon and the state with one photon. As a result, the A2 term in H1 does not contribute,
since it has vanishing matrix elements.
The term involving the electron magnetic moment is
typically much smaller than the contribution from the orbital term, and will be neglected here. (Of
258

course, in cases where the orbital term gives vanishing contribution, the electron magnetic moment
term may become important, and will have to be included.) Hence, the sole remaining contribution
to the matrix element is given by,
⟨f|H1|i⟩
=

⟨ψf|m ⊗⟨∅|EMaα(k)
 e
2m

A · p + p · A

|ψi⟩m ⊗|∅⟩EM

(20.8)
We begin by evaluating the matrix element in HEM, with the help of the free electro-magnetic ﬁeld
A, in transverse gauge,
A(t, x) =
Z
d3k′
(2π)3
1
p
2|k′|
X
β

εβ(k′)aβ(k′)e−ik′·x + ε∗
β(k)a†
β(k′)eik′·x

(20.9)
where k′ · x = |k′|t −k′ · x. Using the canonical commutation relations of the radiation oscillators,
we readily ﬁnd that,
⟨∅|aα(k) A(t, x)|∅⟩=
1
p
2|k|ε∗
a(k)e−ik·x
(20.10)
Note that the ordering between A and p is immaterial here, since the commutator of the two terms
is proportional to ∇· A = 0 in transverse gauge. As a result, the full matrix element takes the
form,
⟨f|H1|i⟩=
e
m
√
2ω eiωt⟨ψf|ε∗
α(k) · p e−ik·x|ψi⟩
(20.11)
Upon taking the norm square, as needed to compute the rate, we have,
|⟨f|H1|i⟩|2 =
e2
2mω
⟨ψf|ε∗
α(k) · p e−ik·x|ψi⟩

2
(20.12)
Finally, the summation over all ﬁnal states, required to derive the total rate, amounts to an inte-
gration over all photon momenta and summation over both photon polarizations. This gives,
Γ = 2π
Z
d3k
(2π)3
e2
2mω
X
α
⟨ψf|ε∗
α(k) · p e−ik·x|ψi⟩

2
δ

E(0)
i
−E(0)
f
−ωk

(20.13)
The radial part of the k-integration may be easily carried out in view of the presence of the δ-
function on ωk = |k|, and we have d3k = ω2dω dΩ, where dΩis the solid angle volume element for
the direction k/|k|. Carrying out the ω integration gives,
Γ =
e2
8π2m

E(0)
i
−E(0)
f
 X
α
Z
dΩ
⟨ψf|ε∗
α(k) · p e−ik·x|ψi⟩

2
(20.14)
We simplify this formula one more step. If the rate is to correspond to the decay of an excited
atomic state to a lower energy state or the ground state, then the energy diﬀerences are of order
mc2α2 ∼c|k|. The typical size of the atom is the Bohr radius, which is given by |x| ∼a0 = ¯h/(mcα).
259

As a result, the product k · x ∼α is small compare to 1, and the exponential may be approximated
by 1, at the same order of approximation that we use when we neglected two photon exchanges.
The resulting formula for the total rate is,
Γ =
e2
8π2m

E(0)
i
−E(0)
f
 X
α
Z
dΩ
⟨ψf|ε∗
α(k) · p|ψi⟩

2
(20.15)
Finally, we shall perform the summation over polarizations, and the integral over directions, as
follows,
X
α
Z
dΩ
⟨ψf|ε∗
α(k) · p|ψi⟩

2
=
X
α
Z
dΩε∗
a(k)iεa(k)j ⟨ψf|pi|ψi⟩⟨ψf|pj|ψi⟩∗
(20.16)
Let n = k/|k|, so that n2 = 1, then we have
X
α
ε∗
a(k)iεa(k)j = δij −ninj
(20.17)
Note that this formula is in agreement with the fact that εα(k) is transverse to k and that this
space is 2-dimensional. The integration over Ωmay be evaluated as follows. The the result of
the integral must be, by construction, a rank 2 symmetric tensor in i, j which is rotation invariant
(since we integrate over all directions n with a rotation invariant measure). There is only one such
tensor, namely δij up to an overall multiplicative factor ℓ, so that
Z
dΩ

δij −ninj
= ℓδij
(20.18)
The value of ℓis determined by taking the trace over i, j, which gives 8π = 3ℓ. Putting all together,
we ﬁnd,
Γ =
e2
6πm2

E(0)
i
−E(0)
f
 ⟨ψf|p|ψi⟩

2
(20.19)
Finally, it is customary to recast the atomic matrix element in terms of the position operator x
instead of momentum. This may be achieved by noticing that
i¯h
mp = [x, Hm]
(20.20)
so that
Γ =
e2
6π¯h2

E(0)
i
−E(0)
f
3 ⟨ψf|x|ψi⟩

2
(20.21)
260

20.3
Application to the decay rate of 2p state of atomic Hydrogen
The simplest application of the above general formulation of single photon decay is to the decay of
the 2p state of atomic Hydrogen to its 1s ground state, |ψi⟩= |2p⟩, and |ψf⟩= |1s⟩. We have,
|⟨1s|z|2p⟩|2
=
8
9
5
1
m2α2
E(0)
2p −E(0)
1s
=
3
8 mc2α2
(20.22)
Combining these partial results, we ﬁnd,
Γ = mc2α5
τ = ¯h
Γ = 1.6 × 10−9sec
(20.23)
where τ stands for the life-time.
This is one instance where the rules of the Wigner-Eckart theorem come in handy. The position
operator x is a vector or j = 1 operator, and thus we know that the initial and ﬁnal total angular
momenta, respectively ji and jf, must obey,
ji −jf
 ≤1
(20.24)
In addition, there is a selection rule on the conservation of magnetic quantum number,
mi = mf ± 1
(20.25)
What happens for initial and ﬁnal states for which these conditions are not satisﬁed ? Is the state
|ψi⟩then stable ?
The answer to these questions can be gathered by realizing that in the above calculation, we
have made various approximations to the real situation. We considered only single photon decay,
and neglected the electron magnetic moment coupling.
When two or more photons are exchanged, the diﬀerence in total angular momentum is pretty
much arbitrary. Every additional photon produced, however, will require an extra factor of e in the
amplitude and thus an extra factor of α in the rate. Since α ∼1/137, the production of multiple
photons will be suppressed. Also, for multiple photons, less phase space becomes available, and in
general a suppression will result from phase space considerations as well. In summary, when the
above selection rules for single photon decay are not satisﬁed, the rate will be suppressed, and the
life-time of the 2p state will be prolonged.
20.4
Absorption and emission of photons in a cavity
By a cavity, we mean an enclosure whose walls are built of solid material, such as a metal or a
porcelain. The atoms and molecules of the cavity wall vibrate (increasingly so when the tempera-
ture increases), and emit and absorb photons. At equilibrium, a balance is achieved where photons
are being absorbed and emitted in a steady state process. The spectrum of photons (including the
261

spectrum of visible light) inside the cavity depends on the temperature. We know from experience
with ovens and ﬂames that at moderate temperatures a red glow is visible, while at higher tem-
perature colors move to the yellow, green and blue, namely to higher frequencies. In the present
section, we shall calculate the absorption rate of photons in the cavity from ﬁrst principles. The
emission rate may be calculated analogously.
We shall work in a cavity, thus in a spatial box of ﬁnite extent, so that photon momenta may
be labeled by discrete vectors k, and their number can be counted in a discrete manner. The
corresponding radiation oscillators satisfy the canonical commutation relations,
[aα(k), a†
β(k′)] = δα,βδk,k′
(20.26)
The rates for the diﬀerent possible values of the wave-vector k decouple from one another, and may
be treated separately. Thus, we concentrate on photons with a single value of the wave vector k.
We shall denote by |nα(k); α, k⟩the state with nα(k) photons of polarization α and wave number
k; these states are given by,
|nα(k); α, k⟩=
1
p
nα(k)!

a†
α(k)
nα(k) |∅⟩
(20.27)
The number nα(k) is referred to as the occupation number of the state of photon momentum k
and polarization α.
Absorption will send the atomic state |ψi⟩(which is often the ground state of the atomic
part of the system) to an excited atomic state |ψf⟩, and will diminish the number of photons.
Considering here the simplest case where absorption occurs of a single photon, we shall be interested
in transitions between the following total states,
|i⟩=
|ψi; nα(k), α, k⟩
≡
|ψi⟩⊗|nα(k), αk⟩
|f⟩= |ψf; nα(k) −1, α, k⟩
≡
|ψf⟩⊗|nα(k) −1, αk⟩
(20.28)
Using again the Fermi golden rule formula for the rate,
Γ = 2π
⟨ϕ|H1|i⟩

2δ(Ef −Ei)
(20.29)
where we use the same approximation for the photon-matter coupling that we used for the single
photon emission calculation,
H1 = e
m A · p
(20.30)
where the electro-magnetic ﬁeld A is in the transverse gauge. The ﬁrst part of the calculation
consists again in evaluating the matrix elements of the A-ﬁeld, but this time between two states
with multiple photons. To evaluate it, we need the following relation,
aβ(k′)|nα(k), α, k⟩= (nα(k))
1
2 |nα(k) −1, α, k⟩δα,βδ(3)(k′ −bk)
(20.31)
262

and we ﬁnd the following formulas for respectively absorption and emission,
⟨nα(k) −1, α, k|A(t, x)|nα(k), α, k⟩
=
(nα(k))
1
2 ε∗
α(k) eik·x
⟨nα(k) + 1, α, k|A(t, x)|nα(k), α, k⟩
=
(nα(k) + 1)
1
2 εα(k) e−ik·x
(20.32)
The extra factor of (nα(k))1/2 is the key diﬀerence with the calculation of the single-photon emission
rate. The diﬀerential rate for the absorption of a single photon is then,
dΓabs = 8π2
L3 nα(k)
α
2ωkm2
⟨ψf|εα(k) · p eik·x|ψi⟩

2
δ(Ef −Ei −ωk)dωk
(20.33)
while the rate for the emission of a photon is given by,
dΓemi = 8π2
L3 (nα(k) + 1)
α
2ωkm2
⟨ψf|ε∗
α(k) · p e−ik·x|ψi⟩

2
δ(Ef −Ei + ωk)dωk
(20.34)
20.5
Black-body radiation
Black body radiation assumes thermodynamic equilibrium between the emitted and absorbed pho-
tons and the cavity wall.
The process responsible for this thermalization may be depicted as
follows,
ψA ↔ψB + γ
(20.35)
The absorption and emissions rates, calculated previously, may be applied to this process alterna-
tively with the initial state |ψi⟩being |ψA⟩(for emission), and |ψB⟩for absorption, and the ﬁnal
state |ψf⟩being |ψA⟩for absorption, and |ψB⟩for emission.
The corresponding emission and absorption rates for the above process are then given by
wemi(α, k)
=
(nα(k) + 1)
⟨ψB|ε∗
α(k) · p e−ik·x|ψA⟩

2
wabs(α, k)
=
nα(k)
⟨ψA|εα(k) · p eik·x|ψB⟩

2
(20.36)
The matrix elements are related by complex conjugation,
⟨ψB|ε∗
α(k) · p e−ik·x|ψA⟩= ⟨ψA|εα(k) · p eik·x|ψB⟩∗
(20.37)
This relation requires commuting p with the exponential; since the commutator [p, eik·x] = ¯hk,
and εα(k) · k = 0, this commutator does not contribute. Since the rates involve the absolute value
square of these quantities, we ﬁnd that
wemi(α, k)
nα(k) + 1 = wabs(α, k)
nα(k)
(20.38)
263

This is clearly a very powerful relation, because it implies that the details of the absorption and
emission process, encoded in the detailed common matrix elements, are irrelevant in determining
the photon occupation numbers nα(k).
Next, we denote the population numbers of the states ψA and ψB by N(A) and N(B) respec-
tively. Thermodynamic equilibrium requires that the detailed balance equation for the process,
N(A) wemi(α, k) = N(B) wabs(α, k)
(20.39)
The ratio of these population numbers is given by the Boltzmann distribution formula,
N(A)
N(B) = e−(EA−EB)/(kBT) = e−¯hω/(kBT)
(20.40)
here kB is the Boltzmann constant, T is the temperature at equilibrium, and ω = c|k|. Combining
(20.39) and (20.40), and eliminating the ratios N(A)/N(B), and wemi/wabs, we ﬁnd,
N(A)
N(B) = wabs(α, k)
wemi(α, k) =
nα(k)
nα(k) + 1 = e−¯hω/(kBT)
(20.41)
The last equality may be readily solved for nα(k), and we ﬁnd,
nα(k) =
1
e¯hω/(kBT) −1
(20.42)
This formula is an example of the occupation numbers for particles obeying Bose-Einstein statistics.
From this formula, it is a small extra step to derive the Planck formula for the black body
radiation spectrum as a function of temperature. The contribution U(ω)dω to the internal energy
density of the distribution of photons in an inﬁnitesimal interval [ω, ω + dω] is given by
U(ω)dω = 1
L3 × 2 × ¯hω ×
1
e¯hω/(kBT) −1 ×
" L
2π
3
4πk2dk
#
(20.43)
The factor 1/L3 results from considering the energy density; the factor of 2 results from the sum
over both polarizations of the photon; the factor ¯hω is the energy contribution of a single photon
with wave number k; the denominator is the photon occupation number. Finally, the last factor, in
brackets, is the phase space factor giving the number of states in a spherical shell in wave-number
space of thickness dk. It may be evaluated as follows. The allowed wave numbers in a cubic box of
size L, with periodic boundary conditions, are
kx = 2πnx
ky = 2πny
kz = 2πnz
(20.44)
The number of states in an inﬁnitesimal volume element are then,
dnx dny dnz =
 L
2π
3
dkx dky dkz =
 L
2π
3
4π k2 dk
(20.45)
264

After some simpliﬁcations, the internal energy density per unit frequency is given by
U(ω) = 8π¯h
c3
 ω
2π
3
1
e¯hω/(kBT) −1
(20.46)
Expressing the formula alternatively in terms of frequency ν = ω/(2π), and “Planck’s constant”
h = 2π¯h, we have
U(ω) = W(ν) = 4hν3
c3
1
ehν/(kBT) −1
(20.47)
which is the original Planck black body radiation formula.
265

21
Relativistic Field Equations
In the preceding chapters matter, such as electrons and nuclei, was treated as non-relativistic
and distinguishable, while electro-magnetic radiation, in the form of emissions and absorptions,
is relativistic and was treated ﬁeld theoretically. Indeed, in ﬁeld theory, the number of particles,
such as photons, does not have to be conserved, while the number of non-relativistic electrons and
nuclei was conserved. Relativity, especially through its equivalence of matter and energy, makes it
impossible for the number of particles to be conserved, whether they be photons, electrons, protons,
neutrons or nuclei. For example, electrons and positrons can collide and annihilate one another
by producing photons, and leaving no charged particles behind. The same can happen to protons
and anti-protons, and even the collision of two protons at high energy can produce new particles,
including protons, electrons and positrons. Thus, the dynamics of electrons (and later on of all
particles) will have to be formulated ﬁeld theoretically, so that the number of electrons need not
be conserved throughout physical processes.
In this chapter, we shall begin by reviewing those aspects of special relativity that will be
needed here, and then proceed to constructing relativistic invariant ﬁeld theory equations in a
systematic manner, including Maxwell’s equations. The ﬁeld equations for electrons, namely the
Dirac equation, will be constructed in the subsequent chapter.
21.1
A brief review of special relativity
Special relativity is based on two basic postulates
1. The laws of Nature and the results of all experiments in any two inertial frames with relative
velocity v are the same.
2. The speed of light is independent of the relative speed v.
To make the consequences of these postulates explicit, we spell out the properties of inertial frames
and the relations between two such frames.
An inertial frame in special relativity is a coordinate system R(t, x) in which Maxwell’s equa-
tions in the absence of matter hold true. The coordinates of two inertial frames R(t, x) and R′(t′, x′)
are related to one another by aﬃne transformations, which include translations (the aﬃne part),
rotations and boosts the linear part).
To make this more precise, we deﬁne the Minkowski distance s2 between two events (t1, x1) and
(t2, x2),
s2 = −c2(t1 −t2)2 + (x1 −x2)2
(21.1)
The physical interpretation of ds2 depends upon its sign;
• s2 = 0, the events are causally related by the propagation of light;
• s2 > 0, the events are causally unrelated;
266

• s2 < 0, the events are causally related by the propagation of particles of any mass; one may
view τ, deﬁned by τ 2 = −s2/c2, as the proper time between the two events.
The coordinates of two inertial frames R(t, x) and R′(t′, x′) are related by an aﬃne transformation
which leaves the Minkowski distance s2 between any two events invariant,
−c2(t1 −t2)2 + (x1 −x2)2 = −c2(t′
1 −t′
2)2 + (x′
1 −x′
2)2
(21.2)
It is immediate that this construction automatically implies the second postulate that the speed
of light is c in all inertial frames. It is also immediate that space and time translations leave the
Minkowski distance invariant. Amongst the linear transformations, rotations leave s2 invariant as
well. The remaining transformations are boosts, which act linearly. Using rotation symmetry, any
boost may be rotated to the x-direction, leaving y and z-coordinates untransformed. We may then
parametrize a boost as follows,
ct′
=
Act + Bx
x′
=
Cct + Dx
y′
=
y
z′
=
z
(21.3)
Choosing two events as follows (t1, x1) = (t, x, 0, 0) and (t2, x2) = (0, 0, 0, 0), and requiring invari-
ance of the Minkowski distance between them, gives
−c2t2 + x2
=
−c2(t′)2 + (x′)2
=
−(Act + Bx)2 + (Cct + Dx)2
(21.4)
Since this relation must hold for all possible events, it must hold for all t, x, which requires
1
=
A2 −C2
1
=
−B2 + D2
0
=
−AB + CD
(21.5)
Parametrizing A = chφ, C = shφ, B = shψ, and D = chψ solves the ﬁrst two equations. The third
equation is solved by having ψ = φ. To gain better physical insight into the transformation, we set
B = C = −βγ
A = D = γ ≡
1
p
1 −β2
(21.6)
where β is viewed as the parameter taking all possible real values |β| < 1. The transformations of
(21.7) take the following form in this parametrization,
ct′
=
γ(ct −βx)
x′
=
γ(x −βct)
y′
=
y
z′
=
z
(21.7)
267

From this it is clear that βc must be interpreted as the relative velocity between the two frames.
Indeed, the point x′ = 0, which is ﬁxed in frame R′, travels with velocity v = x/t = βc from the
point of view of frame R, which is one way we may deﬁne the relative velocity between the frames.
The relativistic transformation properties of momentum, energy, mass, and of the electro-
magnetic ﬁelds may be derived analogously. It is much more eﬃcient, however, to obtain such
relations using the Lorentz vector and tensor notation, which we shall provide ﬁrst.
21.2
Lorentz vector and tensor notation
Just as we use vector notation in 3-dimensional space to collect the three coordinates (x, y, z) into
a vector x, so we use also 4-vector notation to collect the four coordinates of an event (ct, x, y, z) =
(ct, x) into a 4-vector x, denoted without bold face or arrow embellishment. Actually, one mostly
uses a slight variant of the 4-vector notation, with an index added,
xµ ≡(x0, x1, x2, x3) = (ct, x, y, z)
µ = 0, 1, 2, 3
(21.8)
The time direction being special through its special signature in the Minkowski distance, one
reserves the index “0” to denote it. The Minkowski distance may be easily cast in this notation,
s2 =
X
µ,ν=0,1,2,3
ηµν(xµ
1 −xµ
2)(xν
1 −xν
2)
(21.9)
where the Minkowski metric ηµν is deﬁned as follows,
ηµν ≡




−1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1




µν
(21.10)
Einstein introduced the repeated index summation convention, which instructs one to sum over one
repeated upper and one repeated lower index. With the Einstein index convention, we thus have,
s2 = ηµν(xµ
1 −xµ
2)(xν
1 −xν
2)
(21.11)
The precise distinction between upper and lower indices and their separate roles will be spelled out
later.
A relativistic transformation may be expressed in 4-index notation as well. A general aﬃne
transformation between the coordinates xµ and x′µ may be parametrized as follows,
xµ →x′µ = Λµνxν + aµ
(21.12)
Here, Λ is a 4 × 4 matrix with real entries, and the repeated ν-index is to be summed over. The
4-vector aµ is real, and parametrizes translations in time and space. Invariance of the Minkowski
distance s2 is tantamount to
ηµνxµxν
=
ηµνx′µx′ν
=
ηµνΛµρxρ Λνσxσ
=
ηρσΛρµxµ Λσνxν
(21.13)
268

In passing from the second to the third line, we have relabeled the summation indices so that as to
expose the combination xµxν in both cases. This relation has to hold for all xµ, so that we must
have
ηµν = ηρσΛρµΛσν
(21.14)
This relation deﬁnes all Lorentz transformations. It is instructive to count their number of in-
dependent parameters. The matrix Λ has 16 real components, but obeys 16 relations expressed
through the equation of two matrices which are both automatically symmetric. A real symmetric
4 × 4 matrix has 10 real independent components, so 16 −10 = 6 independent parameters, which
precisely accounts for 3 rotations and 3 boosts.
21.3
General Lorentz vectors and tensors
The starting point for introducing 4-vector notation in the preceding section was the quantity xµ,
which, under a Lorentz transformation Λ behaves linearly in xµ,
xµ →x′µ = Λµνxν
(21.15)
One refers to any object V µ = (V 0, V 1, V 2, V 3) which transforms under Λ by
Aµ →A′µ = ΛµνAν
(21.16)
as a Lorentz vector. To be more precise, one sometimes refers to Aµ as a Lorentz vector with upper
index, or a contravariant vector.
21.3.1
Contravariant tensors
The transformation law of the product of n vectors xµi
i
with i = 1, 2, · · · , n follows from the
transformation law of each vector, xµ
i →x′
i
µ = Λµνxν
i , and we have,
xµ1
1 · · · xµn
n →x′
1
µ1 · · · x′
n
µn = (Λµ1ν1 · · · Λµnνn) xν1
1 · · · xνn
n
(21.17)
The product xµ1
1 · · · xµn
n
is a tensor of rank n. One refers to any object Aµ1···µn which transforms
under Λ by
Aµ1···µn →A′µ1···µn = (Λµ1ν1 · · · Λµnνn) Aν1···νn
(21.18)
as a Lorentz tensor of rank n, or more precisely as a Lorentz tensor with upper indices or a
contravariant tensor of rank n. A special case is when n = 0, where we obtain,
A →A′ = A
(21.19)
namely a tensor of rank 0, more commonly referred to as a Lorentz scalar.
269

21.3.2
Covariant tensors
Every contravariant vector and tensor naturally has an associated covariant vector or tensor of the
same rank, which is obtained by lowering all upper indices using the Minkowski metric ηµν. The
simplest case is for a contravariant vector Aµ, where we deﬁne the associated covariant vector by
Aµ ≡ηµνAν
⇔
Aµ = ηµνAν
(21.20)
Under a Lorentz transformation Λ, the covariant vector Aµ is mapped as follows,
Aµ →A′
µ
=
ηµνA′ν
=
ηµν Λνρ Aρ
=
ηµν Λνρ ηρσ Aσ
(21.21)
By our standard conventions of raising and lowering indices, we adopt the following notation,
ηµν Λνρ ηρσ = Λµσ
(21.22)
Using the deﬁning relations of Lorentz transformations, ηµν = ηρσΛρµΛσν, we may reinterpret this
matrix as follows. contract the deﬁning relation with ηµτ gives,
δτ ν = ηρσΛρµηµτΛσν = ΛστΛσν
(21.23)
Hence, Λµν is the inverse of the matrix Λµν. Thus, another way of expressing the transofmration
law for a covariant vector is in terms of the inverse of Λ,
Aµ →A′
µ = Λµν Aν
(21.24)
Analogously, one refers to any object Aµ1···µn which transforms under Λ by
Aµ1···µn →A′µ1···µn = (Λµ1
ν1 · · · Λµn
νn) Aν1···νn
(21.25)
as a Lorentz tensor of rank n, or more precisely as a Lorentz tensor with lower indices or a covariant
tensor of rank n.
One very important example of a covariant vector is provided by the 4-derivative,
∂µ ≡
∂
∂xµ
(21.26)
In view of its deﬁning relation, [∂µ, xν] = δµν, it is clear that ∂µ transforms as a covariant vector,
∂′
µ =
∂
∂x′µ = Λµν ∂
∂xν = Λµν∂ν
(21.27)
270

21.3.3
Contraction and trace
Two vectors Aµ, Bµ may be contracted to form their Minkowski inner product,
A · B ≡ηµνAµBν = AµBµ = AµBµ
(21.28)
We have already encountered this inner product of two 4-vectors, one of position xµ = (ct, x), and
one of momentum kµ = (ω/c, k), which is given explicitly by,
k · x = −ωt + k · x
(21.29)
This inner product is invariant under Lorentz transformations. More generally, two tensors Aµ1···µn, Bµ1···µn
of the same rank n may be contracted to form a scalar,
A · B = Aµ1···µnBµ1···µn
(21.30)
One may also contract two tensors A, and B, of ranks m + p and n + p respectively over p indices
to yield a tensor of rank m + n,
Aµ1···µmρ1···ρpBν1···νnρ1···ρp = Cµ1···µm
ν1···νn
(21.31)
A particularly important contraction of this type consists in taking a trace by contracting a tensor
A of rank m+2 with the Minkowski metric tensor η(note that the pair of indices has to be speciﬁed)
to yield a tensor of rank m,
Aµ1···µi···µj···µmηµiµj = Bµ1···b
µi··· b
µj···µm
(21.32)
Later on, we shall describe further linear operations on tensors, namely symmetrization and anti-
symmetrizations, with the help of which general tensors may be decomposed into their irreducible
components.
21.4
Classical relativistic kinematics and dynamics
In non-relativistic mechanics, the relation between energy E, mass m, velocity v and momentum
p is given by
E = 1
2mv2 = p2
2m
(21.33)
To obtain the relativistic invariant modiﬁcation of these relations, we begin by identifying the
relevant Lorentz 4-vectors of the problem. It turns out that the correct 4-vector which generalizes
the 3-dimensional momentum vector p is
pµ = (E/c, p)
(21.34)
Under a Lorentz transformation Λ, pµ indeed transforms as a contravariant vector,
pµ →p′µ = Λµνpν
(21.35)
271

The transformation under rotations is standard, since p is a vector, while E is rotation-invariant.
Under a boost in the 1-direction, by a velocity v, we have
E′
=
γ

E −vp1
p′1
=
γ

p1 −vE/c2
p′2
=
p2
p′3
=
p3
(21.36)
where γ = (1 −v2/c2)−1/2. If this result is to agree with the non-relativistic limit where |v| ≪c,
and γ ∼1, we must have p′1 = p1 −mv, and this requires that as v →0, the energy of the particle
remain ﬁnite, and given by its rest mass,
E = mc2
(21.37)
which is Einstein’s famous relation.
A fully relativistic relation between energy and momentum is obtained by using the fact that pµ
is a 4-vector, and hence the “square” pµpµ must be Lorentz invariant. Since its value is independent
of the frame where it is being evaluated, we may evaluate it in the frame where the particle is at
rest, i.e. its momentum is zero, and its energy is mc2. This gives,
pµpµ = −E2/c2 + p2 = −m2c2
(21.38)
or alternatively written as a formula for energy,
E2 = m2c4 + p2c2
(21.39)
Energy-omentum conservation is then simply the statement that the 4-vector pµ is conserved.
21.5
Particle collider versus ﬁxed target experiments
Suppose we have two possible experimental set-ups for the collisions of particle os mass m onto one
another;
• Fixed target: one incoming particle has energy E, the other is at rest.
• Collider: the particles have opposite momenta, and each has energy E/2.
The question is now in which experiment one gets the most “bang for the buck”. Translated into
scientiﬁc terms, what this amounts to is the largest total energy in the rest frame.
For the Collider, the center of mass energy available is simply E, the sum of the energies of the
two particles.
To compute the center of mass energy Ecm for the ﬁxed target experiment, we use the fact
that the total momentum pµ has the same square in the ﬁxed target frame as in the center of mass
frame where, by deﬁnition, its momentum vanishes. This reads as follows,
pµpµ = −(E/c + mc)2 −p2c2 = −(Ecm/c)2
(21.40)
272

Here, p is the momentum of the incoming particle, which is related to the energy by E2 = p2c2 +
m2c4. Eliminating p2 between these two equations gives a formula for Ecm directly in terms of E
and m,
Ecm =
p
2m2c4 + 2mc2E
(21.41)
We see that for large energy (mc2 ≪E), the center of mass energy in the collider experiment gros
like E, while in the ﬁxed target experiment, it grows only like
√
E. Thus, the collider provides
much more bang for the buck !
21.6
A physical application of time dilation
There are all the funny applications of time dilation in relativity related to space-travel and the
twin paradox. But there are also very important and directly observable applications to particle
physics. Here, we shall provide one such example in terms of the observed life-time of unstable
particles.
For deﬁniteness, we consider the example of a muon µ−particle; it is very similar to the electron,
but it is 200 times heavier, namely mc2 ∼100MeV , and unstable against weak interactions, with a
life-time of approximately 2×10−6 sec. Muons are observed in cosmic ray showers. How far can the
muons travel since they were ﬁrst created ? Without taking time-dilation into account, they can
travel at most a distance 2 × 10−6 sec ×c = 600 m, certainly not enough to travel intergalactically.
But if the energy of the muon is actually E = mc2γ in the frame of observation, then they can
travel a distance γ times than 600 . For a muon of energy E ∼106 GeV , this comes to approximately
a distance of 107km, more in the range of intergalactic traveling distances.
21.7
Relativistic invariance of the wave equation
In the preceding sections, we have introduced scalars, vectors and tensors. Now we shall be inter-
ested in scalar ﬁelds, vector ﬁelds, and only rarely also in tensor ﬁelds. A function φ(x), where
xµ = (ct, x), is said to be a scalar ﬁeld is it behaves as follows under a Lorentz transformation,
φ(x) →φ′(x′) = φ(x)
x′µ = Λµνxν
(21.42)
In English, this means that the ﬁeld φ′ in the new frame with coordinates x′ equals to old ﬁeld φ
in the old frame with coordinates x.
A suitable Lorentz-invariant equation for the propagation of a scalar ﬁeld is given by the wave
equation,
 
−1
c2
∂2
∂t2 + ∆
!
φ(x) = ∂µ∂µφ(x) = 0
(21.43)
Note that there is no suitable Lorentz invarinat 1-st order diﬀerential equation for a scalar ﬁeld,
since ∂µφ = 0 would imply that φ is constant. An important generalization of the wave equation
273

is obtained by including a mass term,

¯h2∂µ∂µ −m2c2
φ(x) = 0
(21.44)
This equation for a massive scalar ﬁeld may be solved by Fourrier analysis, and we have
φk(x) = eik·x
¯h2kµkµ + m2c2 = 0
(21.45)
Since pµ = ¯hkµ, we see that this relation gives the energy - momentum relation for a relativistic
particle (or wave) with mass m. A further Lorentz-invariant generalization of the scalar ﬁeld wave
equation is obtained by adding an arbitrary function V ′(φ),
¯h2∂µ∂µφ −m2c2φ −V ′(φ) = 0
(21.46)
The latter may be derived via the action principle from the invariant Lagrangian density,
L = −1
2¯h2∂µφ∂µφ −1
2m2c2φ2 −V (φ)
(21.47)
The Higgs particle, for example, is an elementary scalar particle, which is described by a real scalar
ﬁeld φ, with a quartic potential V (φ). Of course, the Higgs particle couples to many other particles,
such as electrons, quarks and neutrinos, and this description will require additional ﬁelds in the
Lagrangian density.
21.8
Relativistic invariance of Maxwell equations
The prime example of a vector ﬁeld under Lorentz transformations is provided by Maxwell the-
ory of electro-magnetism.
A general (covariant) vector ﬁeld Vµ(x) is a collection of 4 ﬁelds
V0(x), V1(x), V2(x), V3(x) which behave as follows under a Lorentz transformation Λ,
Vµ(x) →V ′
µ(x′) = ΛµνVν(x)
(21.48)
and analogously for a contravariant vector ﬁeld.
21.8.1
The gauge ﬁeld and ﬁeld strength
In electro-magnetism, we encounter two vector ﬁelds, the gauge potential Aµ = (−Φ/c, A), and the
electric current density jµ = (ρc, j), where Φ is the electric potential, A the usual 3-dimensional
vector potential, ρ the charge density, and j the 3-dimensional electric current density. Consistency
of Maxwell’s equations requires the current density to be conserved,
∂µjµ = ∂ρ
∂t + ∇· j = 0
(21.49)
Maxwell’s equations are invariant under gauge transformations on the vector potential,
Aµ →A′
µ = Aµ + ∂µθ
(21.50)
274

for any scalar function θ. The electric and magnetic ﬁelds are ﬁrst order time and space-dervatives of
the electric potential and of the vector potential, and bot are gauge invariant. The most systematic
way to construct the electric and magnetic ﬁeld is to precisely take advantage of these two properties.
Computing the general ﬁrst order derivatives gives ∂µAν, which behaves as follows under a gauge
transformation of Aµ,
∂µAν →∂µA′
ν = ∂µAν + ∂µ∂νθ
(21.51)
Thus, the most general ﬁrst order derivative of Aµ is not gauge invariant. The gauge term ∂µ∂νθ,
however, is always symmetric under the interchange of µ and ν. Therefore, we are guaranteed that
anti-symmetric part of the derivative will be gauge invariant. The corresponding ﬁeld strength is
deﬁned by
Fµν = ∂µAν −∂νAµ
(21.52)
Counting the number of independent ﬁelds in the rank 2 anti-symmetric tensor Fµν = −Fνµ gives
4 × 3/2 = 6, which is precisely the correct number to incorporate the 3 components of E and
the three components of B. Decomposing Fµν according to its space and time indices, and using
anti-symmetry, we ﬁnd the following parts,
F0i
=
∂0Ai −∂iA0
Fij
=
∂iAj −∂jAi
i, j = 1, 2, 3
(21.53)
The standard electric and magnetic ﬁelds may now be identiﬁed as follows,
Fi0
=
Ei
Fij
=
3
X
k=1
εijkBk
(21.54)
As a matrix, the ﬁeld strength tensor has the following entries,
Fµν =




0
−E1
−E2
−E3
E1
0
B3
−B2
E2
−B3
0
B1
E3
B2
−B1
0




µν
(21.55)
21.8.2
Maxwell’s equations in Lorentz covariant form
Lorentz invariance of the equations dictates, to a large extent, the structure of the possible equations
we may have for the gauge ﬁeld Aµ, and its gauge invariant ﬁeld strength tensor Fµν. Maxwell’s
equations emerge in two groups; a ﬁrst set independent of the external electric current density jµ,
and a second set which does involve jµ.
The ﬁrst group of Maxwell’s equations results directly from the fact that Fµν is a “curl” in the
4-dimensional sense. From Fµν = ∂µAν −∂νAµ, it readily follows that
εµνρσ∂ρFµν = 2εµνρσ∂ρ∂µAν = 0
(21.56)
275

since the derivative ∂ρ∂µAν is symmetric in ρ, µ, while the εµνρσ is antisymmetric in all its indices,
and may be normalized to ε0123 = 1 (note that because of the Minkowski signature of the metric,
this implies that ε0123 = −1. Expressed in terms of E and B, this yields the ﬁrst group of Maxwell’s
equations, by considering separately the cases where σ = 0 and σ = i with i = 1, 2, 3,
εµνρ0∂ρFµν = 0
⇔
∇· B = 0
εµνρi∂ρFµν = 0
⇔
∂0B + ∇× E = 0
(21.57)
It is instructive to give the derivation of these formulas. On the ﬁrst line, the last index on ε
is a time-index, namely 0, so that the other three indices on ε must be space-indices, which we
shall rebaptize i, j, k.
Thus, the ﬁrst line becomes εijk0∂kFij = 0.
Using the deﬁnition of the
magnetic ﬁeld Fij = P
m εijmBm, the fact that, with our conventions, εijk0 = −εijk, and the double
contraction
εijkεijm = 2δk
m
(21.58)
we ﬁnd εijk0∂kFij = 2∂kBk = 2∇· B. On the second line, the last index is i, which is space-
like.
Thus, one and only one of the indices µ, ν, ρ must be 0.
Collecting all possibilities gives
εjk0i∂0Fjk + 2ε0jki∂kF0j = 0. Using the deﬁnitions of the electric and magnetic ﬁelds, ad the above
double contraction formula, we obtain ∂0Bi + εijk∂jEk = 0, which gives the formula quoted.
The second group of Maxwell equations are also linear and involve ﬁrst derivatives of the electric
and magnetic ﬁelds and are sourced by the current density. There is only one Lorentz-invariant
combination with these properties, up to an overall constant factor, namely
∂µF µν = −jν
(21.59)
Note that, because Fµν is antisymmetric in µ and ν, the current density must be conserved,
∂ν∂µF µν = ∂νjν = 0.
There are actually 4 equations encoded in (21.59), one for each of the
possible values of ν.
∂µF µ0 = −j0
⇔
∇· E = ρ
∂µF µi = −ji
⇔
∂0E −∇× B = j
(21.60)
In summary, the relativistic form of the two groups of Maxwell’s equations reduce to,
εµνρσ∂ρFµν
=
0
∂µF µν
=
−jν
(21.61)
These equations may be derived from an action principle. Considering Aµ as the fundamental
variable, and deﬁning Fµν = ∂µAν −∂νAµ, then a suitable action is given by,
S[A] =
Z
d4x

−1
4FµνF µν + Aµjµ

(21.62)
276

A variation δAµ of Aµ then yields the following variation of the action,
δS[A]
=
Z
d4x

−1
2F µνδFµν + δAµjµ

=
Z
d4x (F µν∂νδAµ + δAµjµ)
(21.63)
Integration by part of the ﬁrst term gives (surface terms vanish for variations δAµ with compact
support, and will be omitted here),
δS[A] =
Z
d4x δAµ (−∂νF µν + jµ)
(21.64)
Its vanishing for all δAµ requires the second group of Maxwell equations.
Maxwell’s equations may also be viewed directly as diﬀerential equations for Aµ with source
jµ. This is achieved by eliminating Fµν in terms of Aµ, so that
∂µ (∂µAν −∂νAµ) = −jν
(21.65)
In a relativistic framework, it is more convenient to choose a relativistic gauge condition than it
would be to choose the transverse gauge ∇· A = 0, which is not Lorentz invariant. A convenient
gauge is the Landau gauge, ∂µAµ = 0, in terms of which the ﬁeld equation for Aµ becomes the
wave equation with a source,
∂µ∂µAν = −jν
(21.66)
and current density conservation now holds in view of the gauge choice.
21.9
Structure of the Poincar´e and Lorentz algebras
The Lorentz algebra forms a 6-dimensional Lie algebra, parametrized by 3 rotations and 3 boosts.
The Poincar´e algebra is the semi-direct sum of the Lorentz algebra with the 4 translations of time
and space, so that the Poincar´e algebra is 10-dimensional. We begin by determining the structure
of the Lorentz algebra, by expanding the deﬁning relation of ﬁnite Lorentz transformations,
ηµν = ΛµρΛνσηρσ
(21.67)
around the identity,
λµρ = δµρ + ωµρ + O(ω2)
(21.68)
This relation implies the requirement that
ωνµ = −ωµν
(21.69)
277

Next, we determine the structure relations of the Lorentz algebra. To this end, we consider an
arbitrary representation D(Λ) of the Lorentz group, satisfying D(Λ1Λ2) = D(Λ1)D(Λ2) by deﬁni-
tion of a representation. Let Lµν be the representation matrices of the corresponding Lie algebra,
related to D(Λ) for Λ close to the identity in the following way,
D(Λ) = I + 1
2ωµνLµν + O(ω2)
(21.70)
By construction, we have Lνµ = −Lµν. The structure relations of the Lorentz algebra are deduced
by considering the following combination,
D(Λ)D(I + ω1)D(Λ)−1
=
D(I + ˜ω1) + O(ω2)
˜ωµν
1
=
ΛµρΛνσωρσ
1
(21.71)
Identifying terms of order ω, for all ﬁnite values of Λ, we ﬁnd the transformation law for the
generators Lµν under a Lorentz transformation Λ,
D(Λ)LµνD(Λ)−1 = ΛρµΛσνLρσ
(21.72)
Taking now the special case where Λ is inﬁnitesimally close to the identity, Λρµ = δρµ+ωρµ+O(ω2),
and retaining the terms to ﬁrst order in ω, we derive the structure constants of Lµν,
[Lκλ, Lµν] = +ηλµLκν −ηκµLλν + ηλνLµκ −ηκνLµλ
(21.73)
Alternatively, we may express the algebra in terms of rotations Jk, and boosts Kk, for i = 1, 2, 3,
where Lij corresponds to rotations Jk, provided we include a factor of i in its deﬁnition, and Lk0
corresponds to boosts Kk, for which we shall also include a factor of i,
J1 = −iL23
K1 = iL10
J2 = −iL31
K2 = iL20
J3 = −iL12
K3 = iL30
(21.74)
The commutation relation [L23, L31] = −L12 corresponds to the following commutator of the Jk,
[J1, J2] = iJ3, giving indeed the standard normalization of the commutation relations. Putting
together all structure relations in terms of Jk and Kk, we have,
[Ji, Jj]
=
iεijkJk
[Ji, Kj]
=
iεijkKk
[Ki, Kj]
=
−iεijkJk
(21.75)
A further change of variables of the basic generators reveals that the Lorentz algebra is actually a
direct sum of two algebras, provided we complexify the Lorentz algebra. Complexiﬁng means that
we consider the same generators as we had in the original algebra, but we allow linear combinations
with complex coeﬃcients. The resulting algebra no longer acts on real objects such as the real
278

coordinates of space-time, but usually, we may ultimately restrict to its real subalgebra when
needed. The relevant linear complexiﬁed combinations of Jk and Kk are given as follows,
Ak ≡1
2(Jk −iKk)
Jk = Ak + Bk
Bk ≡1
2(Jk + iKk)
Kk = i(Ak −Bk)
(21.76)
Their commutation relations are as follows,
[Ai, Bj]
=
0
[Ai, Aj]
=
iεijkAk
[Bi, Bj]
=
iεijkBk
(21.77)
The relation on the top line signiﬁes that the sets of generators A = {A1, A2, A3} and B =
{B1, B2, B3} mutually commute, so that the full complexiﬁed Lorentz algebra is a direct sum
of two SU(2) algebras, considered with complex coeﬃcients.
Finally, the representations of the Lorentz algebra have certain reality properties. If the ﬁnite-
dimensional representation, given by the generators Lµν is real, so that the matrices Lµν are
real, and D(Λ) is real for all Λ, then, the rotation and boost generators, Jk, Kk must be purely
imaginary. As a result of the standard commutation relations of angular momentum, the generators
Jk must be (equivalent to) Hermitian matrices. For boosts, however, the structure relations allow
for either anti-Hermitian Kk or Hermitian Kk. Hermitian Kk corresponds to the rotation algebra
in 4 dimensions, not the Lorentz algebra. The Lorentz algebra corresponds to the other alternative
: Hermitian Kk. As a result, we then have the following complex conjugation relation,
A†
k = Bk
(21.78)
Thus, the operation of complex conjugation interchanges the subalgebras A and B.
21.10
Representations of the Lorentz algebra
We have already encountered several representations of the Lorentz algebra,
scalar
dimension 1
φ
vector
dimension 4
xµ, ∂µ, Aµ
anti −symmetric rank 2 tensor
dimension 6
Fµν, Lµν
(21.79)
Here, we wish to construct all ﬁnite-dimensional representations of the Lorentz algebra in a sys-
tematic way. This problem is greatly simpliﬁed by the observation that the complexiﬁed Lorentz
algebra is a direct sum of two complexiﬁed SU(2) algebras. Thus, our procedure will consist in
ﬁrst constructing all complex ﬁnite-dimensional representations of the complexiﬁed Lorentz alge-
bra, and then restrict those complex representations to real ones, when possible. Note that, as a
279

result of the complexiﬁcation, the ﬁnite-dimensional representations we will obtain this way may
not be unitary.
The ﬁnite-dimensional representations of the algebras A and B are perfectly well-known. Each
is labeled by a non-negative integer or half-integer, which we shall denote by a for the algebra A,
and b for the algebra B. The corresponding magnetic quantum numbers will be denoted ma and
mb, and have the customary ranges,
−a ≤ma ≤+a
a −ma integer
−b ≤mb ≤+b
b −mb integer
(21.80)
The states may be labeled by a and ma, as follows, |a, ma⟩, and the quantum numbers are deﬁned
by
⃗A2|a, ma⟩
=
a(a + 1)|a, ma⟩
⃗B2|b, mb⟩
=
b(b + 1)|b, mb⟩
A3|a, ma⟩
=
ma|a, ma⟩
B3|b, mb⟩
=
mb|b, mb⟩
(21.81)
Thus, we may label the ﬁnite-dimensional representations of the Lorentz algebra by a pair of non-
negative integers or half-integers,
(a, b)
a, b ≥0,
, 2a, 2b ∈Z
(21.82)
Since ⃗A and ⃗B are neither Hermitian conjugates of one another, and not necessarily Hermitian
themselves, the representation (a, b) will in general be complex. However, the complex conjugate
of the representation (a, b) is eﬀectively obtained by interchanging ⃗A and ⃗B, and thus transforms
under the representation (b, a). One may thus identify these two representations,
(a, b)∗= (b, a)
(21.83)
In particular, this means that the following representations,
(a, a)
(a, b) + (b, a)
(21.84)
are always real, for any a, b. The dimension of a representation (a, b) is given by
dim(a, b) = (2a + 1)(2b + 1)
(21.85)
The representations (a, b) are genuine single-valued if a + b is integer, and they are double valued
when a + b is a half-integer, so that
bosons
(a, b)
a + b integer + 1
2
fermions
(a, b)
a + b integer
(21.86)
280

The lowest dimensional representations play an ubiquitous role in physics,
(0, 0)
dim = 1
real
scalar
(1
2, 0)
dim = 2
complex
left Weyl spinor
(0, 1
2)
dim = 2
complex
right Weyl spinor
(1
2, 1
2)
dim = 4
real
vector
(1, 0)
dim = 3
complex
self −dual antisymmetric tensor
(0, 1)
dim = 3
complex
anti −self −dual antisymmetric tensor
(1
2, 1)
dim = 6
complex
left gravitino
(1, 1
2)
dim = 6
complex
right gravitino
(1, 1)
dim = 9
real
graviton
(21.87)
In this course, we shall only need the scalar, the Weyl spinors, and the vector.
Note that the
combination
(1
2, 0) ⊕(0, 1
2)
(21.88)
corresponds to a 4-dimensional (complex) Dirac spinor if the two component representations are
unrelated, while it corresponds to a Majorana spinor if the representations are complex conjugates
of one another.
281

22
The Dirac Field and the Dirac Equation
Among the relativistic wave equations, we have not yet obtained one suitable for spin 1/2, doing
so is the object of the present chapter. From the preceding discussion, there are 3 cases,
1
2, 0

left Weyl spinor

0, 1
2

right Weyl spinor
1
2, 0

⊕

0, 1
2

Dirac spinor
(22.1)
(The case of a Majorana spinor will turn out to be equivalent to that of a Weyl spinor, and will
not be discussed further here.) It is actually convenient to treat all cases at once by concentrating
on the reducible case of the Dirac spinor. Historically, this is also what Dirac did.
The representation (1
2, 0) is well-known: it can be obtained in terms of the Pauli matrices.
Similarly, the case of the representation (0, 1
2) may be given in terms of the Pauli matrices as well;
(here and below, k = 1, 2, 3),
DL(Ak) = σk
2
DL(Bk) = 0
DR(Ak) = 0
DL(Bk) = σk
2
(22.2)
Of course, DL and DR act on two diﬀerent two-dimensional representation spaces, and so do the
corresponding Pauli matrices. To make this crystal clear, it is preferable to work on the direct sum
representation D = DL ⊕DR of the two spinors, so that the representation matrices are given as
follows,
D(Ak) =
 1
2σk
0
0
0

D(Bk) =
 0
0
0
1
2σk

(22.3)
or in terms of the original rotation and boost generators,
D(Jk) =
 1
2σk
0
0
1
2σk

D(Kk) =
 1
2σk
0
0
−1
2σk

(22.4)
It is not `a priori so easy to write down a Lorentz-covariant equation because the generators are
not labeled by Lorentz vector indices (such as tensors were), but rather by a novel type of spinor
index. To circumvent these problems, we introduce the Dirac matrices.
22.1
The Dirac-Cliﬀord algebra
One deﬁnes the Dirac-Cliﬀord algebra in space-time dimension 4 as an algebra of Dirac matrices
γµ, where µ = 0, 1, 2, 3, which satisfy the following deﬁning equation,
{γµ, γν} = γµγν + γνγµ = 2ηµνI
(22.5)
282

where I is the unit matrix in the Dirac representation space. Given the Dirac matrices, which we
shall realize shortly in explicit form, one automatically constructs the Dirac spinor representation
of the Lorentz algebra,
D(Lµν) ≡Sµν = 1
4[γµ, γν]
(22.6)
To show that Sµν indeed forms a representation of the Lorentz algebra, all we need to do is to
show that it satisﬁes the structure constants of (21.73).
To do so, it will be useful to recast
Sµν = 1
2γµγν −1
2ηµνI, since the term proportional to I will cancel out in the argument of the
commutator. Thus, we have
[Sκλ, Sµν]
=
1
4[γκγλ, γµγν] = 1
4 (γκγλγµγν −γµγνγκγλ)
(22.7)
=
1
4γκ (−γµγλ + 2ηµλ) γν −1
4γµ (−γκγν + 2ηκν) γλ
=
1
2ηµλγκγν −1
2ηκνγµγλ −1
4(2ηκµ −γµγκ)γλγν + 1
4γµγκ(2ηνλ −γλγν)
The terms quartic in γ-matrices cancel on the last line, and we are left with terms quadratic in γ
only. They become,
[Sκλ, Sµν]
=
1
2ηµλγκγν −1
2ηκνγµγλ −1
2ηκµγλγν + 1
2ηνλγµγκ
=
1
4ηµλ[γκ, γν] −1
4ηκν[γµ, γλ] −1
4ηκµ[γλ, γν] + 1
4ηνλ[γµ, γκ]
=
ηµλSκν −ηκνSµλ −ηκµSλν + ηνλSµκ
(22.8)
which is precisely the structure relation of the Lorentz algebra.
The representation Sµν obtained this way is always reducible.
This may be established by
constructing the famous chirality, or γ5-matrix, which is given by the product of all γ-matrices, up
to an overall complex multiple. We shall make the choice
γ5 ≡−iγ0γ1γ2γ3
(22.9)
so that its square equals the identity matrix,

γ52 = −γ0γ1γ2γ3γ0γ1γ2γ3 = γ0γ1γ2γ0γ1γ2 = γ0γ1γ0γ1 = −γ0γ0 = I
(22.10)
Furthermore, γ5 anti-commutes with all γµ,
{γ5, γµ} = 0
µ = 0, 1, 2, 3
(22.11)
and therefore must commute with the generators of the Lorentz algebra,
[γ5, Sµν] = 0
µ, ν = 0, 1, 2, 3
(22.12)
Since {γ5, γµ} = 0, the matrix γ5 cannot simply be proportional to the identity matrix. Thus, we
have a non-trivial matrix γ5 commuting with the entire representation Sµν, which implies that the
representation Sµν of the Lorentz algebra is a reducible representation. Note that, although the
representation of the Lorentz algebra is reduced by γ5, the Cliﬀord algebra of the γ-matrices is
irreducible.
283

22.2
Explicit representation of the Dirac algebra
From the deﬁnition of γ5, we have, tr(γ5) = −itr(γ0γ1γ2γ3). By using the cyclic property of the
trace, this quantity equals −itr(γ1γ2γ3γ0). On the other hand, by anti-commuting γ0 through the
matrices γ1γ2γ3, it also equals +itr(γ1γ2γ3γ0), and thus must vanish,
tr

γ5
= 0
(22.13)
Since we also have (γ5)2 = I, it follows that γ5 must have equal numbers of eigenvalues +1 and
−1. Thus, the representation space must have even dimension 2n, for n integer. In a basis where
γ5 is diagonal, we thus have
γ5 =
 In
0
0
−In

(22.14)
The matrix γ0 anti-commutes with γ5, and squares to −I2n; it may be chosen as follows,
γ0 =
 0
In
−In
0

(22.15)
Finally, the combinations γ0γi for i = 1, 2, 3 commute with γ5, and must thus be block-diagonal in
the basis where γ5 is diagonal,
γ0γi =
 ai
+
0
0
ai
−

(22.16)
From the Cliﬀord algebra relations, we also have
n
γ0γi, γ0γjo
= 2δijI2n
(22.17)
so that
n
ai
±, aj
±
o
= 2δijIn
(22.18)
But this last relation is the deﬁning equation for the Pauli matrices, of which the lowest-dimensional
representation has n = 2, and ai
± = ε±σi, with (ε±)2 = 1. We may choose ε+ = 1 without loss
of generality.
The value ε−= +1 then makes ai
+ = ai
−and results in [γ0, γi] = 0, which is
unacceptable. Thus, we are left with the unique solution ε−= −1. The γµ-matrices now take the
following explicit form in this basis,
γ0 =
 0
I2
−I2
0

γi =
 0
σi
σi
0

(22.19)
We check that
γ5 = −iγ0γ1γ2γ3 = −i
 σ1σ2σ3
0
0
−σ1σ2σ3

=
 I2
0
0
−I2

(22.20)
284

The generators of the Lorentz algebra in this basis are given by
S0i
=
1
2γ0γi = −1
2γ0γi = 1
2
 −σi
0
0
σi

Sij
=
Sij = 1
4
 [σi, σj]
0
0
[σi, σj]

= i
2εijk
 σk
0
0
σk

(22.21)
We may use these expressions to ﬁnd also the representations of the generators Jk and Kk in this
basis,
Jk = 1
2
 σk
0
0
σk

Kk = i
2
 σk
0
0
−σk

(22.22)
and from these we get
Ak = 1
2
 σk
0
0
0

Bk = 1
2
 0
0
0
σk

(22.23)
These expressions reveal that the subalgebras A and B indeed correspond to the reducibility of the
spinor representation.
22.3
Action of Lorentz transformations on γ-matrices
The Lorentz algebra in the Dirac spinor representation acts by the following inﬁnitesimal transfor-
mations,
Λµν
=
δµν + ωµν + O(ω2)
D(Λ)
=
I + 1
2ωµνSµν + O(ω2)
(22.24)
which allows us to compute the action of the Lorentz algebra on the γ-matrices,
D(Λ)γκD(Λ)−1
=

I + 1
2ωµνSµν

γκ

I −1
2ωµνSµν

+ O(ω2)
=
γκ + 1
2ωµν[Sµ,ν, γκ] + O(ω2)
(22.25)
The commutator may be evaluated using only the Cliﬀord algebra relations, and we ﬁnd,
[Sµ,ν, γκ] = ηκνγµ −ηκµγν
(22.26)
Asa result, we have
D(Λ)γκD(Λ)−1
=
γκ + ωµκγµ + O(ω2)
=
Λµκγµ
(22.27)
285

The relation, as it was derived above, holds for Λ close to the identity. Given the overall covariance
of the tensors of the last line, this relation must now be valid for ﬁnite Λ as well. Another way of
writing this relation is by contracting both sides with Λκλ, so that we get
λκλD(Λ)γκD(Λ)−1 = γλ
(22.28)
This relation signiﬁes that the γ-matrices are constants provided that we transform both their
vector index and their spinor indices. The Lorentz transformation property of the generators Sµν
themselves follows from that of the γ-matrices, and we have,
D(Λ)SκλD(Λ)−1 = ΛµκΛνλSµν
(22.29)
The structure relations may be recovered from this relation.
22.4
The Dirac equation and its relativistic invariance
We now have all the tools ready to construct relativistic invariant equations for ﬁelds which are
spinors of the Lorentz algebra. We shall work in the (reducible) Dirac representation, leaving the
Weyl and Majorana cases as a special case of the Dirac spinors.
The basic Dirac ﬁeld ψ(x) transforms as a 4-component representation of the form (1
2, 0)⊕(0, 1
2),
for which we have just constructed the representation matrices. The ﬁeld transforms as follows,
ψ(x) →ψ′(x′) = D(Λ)ψ(x)
(22.30)
where the inﬁnitesimal transformations were given in (22.24). We begin by constructing an equation
for a free ﬁeld, namely a linear equation for ψ. Of course, we could write down the free Klein-Gordon
equation for ψ,
(∂µ∂µ −m2)ψ(x) = 0
(22.31)
and this is a perfectly ﬁne free wave equation for a spinor. The correct equation, however, turns
out to be a ﬁrst order equation, namely the free Dirac equation,
(γµ∂µ −m) ψ(x) = 0
(22.32)
Note that the free Dirac equation implies the free Klein-Gordon equation. This may be seen by
multiplying the Dirac equation to the left by the operator (γν∂ν + m), which gives,

γν∂νγµ∂µ −m2
ψ = 0
(22.33)
Using the fact that the derivatives are symmetric under interchange of µ and ν, and using the
Cliﬀord relation, it is immediate that this equation coincides with the Klein-Gordon equation. The
converse is, however, not true, as a ﬁeld ψ satisfying (22.31) may be decomposed into solutions
of (γµ∂µ ± m)ψ = 0, with either ± sign. In fact, the Dirac equation has only half the number of
solutions of the Klein-Gordon equation (both for 4-component spinors).
286

We begin by checking that the free Dirac equation is indeed Lorentz invariant. We shall show
that

γµ∂′
µ −m

ψ′(x′) = D(Λ) (γµ∂µ −m) ψ(x)
(22.34)
To establish this relation, it suﬃces to compute the left hand side, using the following transformation
results,
ψ′(x′)
=
D(Λ)ψ(x)
∂′
µ
=
Λµν∂ν
γµΛµν
=
D(Λ)γνD(Λ)−1
(22.35)
If now (γµ∂µ −m) ψ(x) = 0, then it follows that also

γµ∂′
µ −m

ψ′(x′) = 0, and the equation is
covariant.
Group theoretically, the structure of the Dirac equation is organized as follows,
ψ
∼
1
2, 0

⊕

0, 1
2

∂
∼
1
2, 1
2

∂ψ
∼
1
2, 1
2

⊗
 1
2, 0

⊕

0, 1
2
 
=

0, 1
2

⊕

1, 1
2

⊕
1
2, 0

⊕
1
2, 1

(22.36)
The γ-matrix is responsible for projecting out the representations (1, 1
2) ⊕(1
2, 1) and retaining only
(1
2, 0) ⊕(0, 1
2). In the Weyl basis, we have
γ0 =
 0
I2
−I2
0

γi =
 0
σi
σi
0

γ5 =
 I2
0
0
−I2

(22.37)
It is customary to introduce the Pauli matrices with a Lorentz index, as follows,
σµ
≡
(+I2, σi)
¯σµ
≡
(−I2, σi)
(22.38)
The Dirac matrices may then be expressed in a manifestly Lorentz covariant way,
γµ =
 0
σµ
¯σµ
0

(22.39)
Decomposing now also the Dirac ﬁeld ψ into 2-component spinors ψL and ψR, referred to as the
left and the right Weyl spinors,
ψ =
 ψL
ψR

(22.40)
287

the free Dirac equation reads,
 −m
σµ∂µ
¯σµ∂µ
−m
  ψL
ψR

= 0
(22.41)
Separating the two components,
σµ∂µψR −mψL
=
0
¯σµ∂µψL −mψR
=
0
(22.42)
we see that the mass m produces a coupling or a mixing between the left and right Weyl spinors.
When the mass m vanishes, the equations for left and right Weyl spinors decouple, and we are
left with the Dirac equation for a massless spinor,
σµ∂µψR
=
0
¯σµ∂µψL
=
0
(22.43)
It is now consistent to retain only one of these 2-component spinors, and set the other to zero. For
example, setting ψR = 0 produces the left Weyl spinor equation,
σµ∂µψL = 0
(22.44)
Note that, by construction, this equation is also Lorentz-invariant, just as the full Dirac equation
was.
When m ̸= 0, it is of course inconsistent to set ψR = 0, since the Dirac equation then
automatically implies that also ψL = 0.
22.5
Elementary solutions to the free Dirac equation
The free Dirac equation, (γµ∂µ −m)ψ(x) = 0 is a linear partial diﬀerential equation with x-
independent coeﬃcients, and may thus be solved by Fourrier analysis. The elementary solutions
are labeled by the 4-momentum k,
ψk(x) = u(k) e−ik·x
(22.45)
where u(k) is a 4-component spinor which satisﬁes the algebraic equation
(iγµkµ + m)u(k) = 0
(22.46)
In the Weyl basis, we decompose u(k) into uL(k) and uR(k), for which the equation reads,

m
iσµkµ
i¯σµkµ
m
  uL
uR

= 0
(22.47)
or separating out space from time components,
i(−k0 + ⃗k · ⃗σ)uL + muR
=
0
i(+k0 + ⃗k · ⃗σ)uR + muL
=
0
(22.48)
288

Eliminating one or the other components, gives the standard energy-momentum-mass relation,
(k2
0 −⃗k2 −m2)uL,R(⃗k) = 0. To solve the Dirac equation, it is useful to separate the massless case
from the massive one. When m = 0, we may choose the momentum as follows, kµ = (k0, 0, 0, k)
where k0 = |k|. The equations for uL, uR then read,
(k0 −kσ3)uL
=
0
(k0 + kσ3)uR
=
0
(22.49)
The solutions depend on the sign of k, and we have,
k > 0
 uL2 = 0
uR1 = 0
k < 0
 uL1 = 0
uR2 = 0
(22.50)
For a left Weyl spinor, for example, with k > 0, there is a 1-dimensional space of solutions,
parametrized by uL1, corresponding to the deﬁnite helicity +1/2¯h.
For m ̸= 0, we have two
linearly independent solutions u(ℓ) for ℓ= 1, 2, which may be parametrized as follows,
u(ℓ)
R = i
m(k0 −⃗k · ⃗σ)u(ℓ)
L
u(1)
L =
 1
0

u(2)
L =
 0
1

(22.51)
22.6
The conserved current of fermion number
The Dirac equation is invariant under phase rotations of the ﬁeld ψ by an x-independent angle θ,
ψ(x) →ψ′(x) = eiθ ψ(x)
(22.52)
and the associated conserved current is given by
jµ = ψ†γ0γµψ
(22.53)
We begin by showing that jµ indeed transforms as a 4-vector under Lorentz transformations.
Group theoretically, this works as follows. We decompose ψ into its Weyl components, and recast
the fermion number current in terms of ψL,R,
jµ = ψ†
L¯σµψL + ψ†
RσµψR
(22.54)
Since ψL ∼(1
2, 0) and ψR ∼(0, 1
2), this combination does indeed give rise to a vector, since
ψ†
L ⊗ψL ∼(1
2, 1
2), as well as ψ†
R ⊗ψR ∼(1
2, 1
2). More precisely, we need the transformation matrices
for the complex conjugate of ψ, which can be obtained as follows,
ψ(x)
→
ψ′(x′) = D(Λ)ψ(x)
ψ(x)†
→
(ψ′(x))† = ψ(x)†D(Λ)†
¯ψ(x)
→
¯ψ′(x′) = ψ(x)†D(Λ)†γ0 = −¯ψ(x)γ0D(Λ)†γ0
(22.55)
289

To calculate the combination −γ0D(Λ)†γ0, we take Λ inﬁnitesimally close to the identity, so that
D(Λ)
=
I + 1
2ωµνSµν + O(ω2)
=
I + ω0iS0i + 1
2ωijSij + O(ω2)
D(Λ)†
=
I + ω0iS†
0i + 1
2ωijS†
ij + O(ω2)
(22.56)
From the explicit representations of Sµν, we have that
S†
0i
=
+S0i = γ0S0iγ0
S†
ij
=
−Sij = γ0Sijγ0
(22.57)
Thus, we have
D(Λ)†
=
I + ω0iγ0Si0γ0 + 1
2ωijγ0Sijγ0 + O(ω2)
=
−γ0

I −ω0iS0i −1
2ωijSij + O(ω2)

γ0
=
−γ0D(Λ)−1γ0
(22.58)
Using this expression in the transformation law for ¯ψ, we get
¯ψ(x) →¯ψ′(x′) = ¯ψ(x)D(Λ)−1
(22.59)
It is now straightforward to derive the transformation law of the fermion current,
jµ(x) →j′µ(x′)
=
¯ψ′(x′)γµψ′(x′)
=
¯ψ(x)D(Λ)−1γµD(Λ)ψ(x)
=
Λµνjν(x)
(22.60)
Finally, we check that the current is conserved,
∂µjµ = ∂µ( ¯ψγµψ) = ¯ψγµ∂µψ + (∂µ ¯ψ)γµψ
(22.61)
The ﬁrst term on the rhs is simpliﬁed by using the Dirac equation, γµ∂µψ = mψ, while the second
term can be handled using the conjugate of the Dirac equation,
(∂µψ)†(γµ)† −mψ† = 0
(22.62)
Using (γµ)† = γ0γµγ0, this becomes,
(∂µ ¯ψ)γµ + m ¯ψ = 0
(22.63)
Combining both equations gives ∂µjµ = 0.
290

22.7
The free Dirac action and Hamiltonian
The ﬁeld equations (γµ∂µ −m)ψ = 0 may be derived from an action principle. The action involves
the ﬁeld ψ, as well as the ﬁeld ¯ψ, which is being considered as independent from the ﬁeld ψ, in the
same sense that the complex variables z and ¯z are considered as being independent variables. The
action is given by
S[ψ, ¯ψ] =
Z
d4x ¯ψ(γµ∂µ −m)ψ
(22.64)
Varying ¯ψ produces the Dirac equation, while varying ψ produces its conjugate equation. The
action is manifestly Lorentz invariant, since we have already shown the transformation laws of
(γµ∂µ −m)ψ and ¯ψ to be inverse of one another.
Note: for the time being, ¯ψ should always be kept to the left of the ﬁeld ψ in the action.
Ultimately, we shall see that ψ and ¯ψ in the classical action are not ordinary complex-valued ﬁelds,
but rather Grassmann-valued.
The Hamiltonian formulation of the Dirac equation is rather intricate. The momentum conju-
gate to ψ is given by
Πψ =
∂L
∂∂0ψ = −¯ψγ0 = ψ†
(22.65)
but the momentum conjugate to ¯ψ vanishes ! This is a reﬂection of the fact that the Dirac system
is ﬁrst-order in time-derivatives. The Hamiltonian becomes,
H
=
Z
d3x (Πψ∂0ψ −L)
=
Z
d3x ¯ψ

−γi∂i + m

ψ
(22.66)
22.8
Coupling to the electro-magnetic ﬁeld
We now wish to include the interactions between the Dirac ﬁeld and electro-magnetism, represented
by the electro-magnetic vector potential Aµ, and we want the ﬁnal theory to be Lorentz invariant.
Recall from our discussion of Maxwell theory that Aµ must couple to a conserved electric current
density. We have already identiﬁed this current in Dirac theory : it must be proportional to ¯ψγµψ,
and the factor of proportionality q gives the strength of the coupling, which is nothing but the
electric charge of the unit element of the Dirac ﬁeld. The corresponding action is
S[ψ, ¯ψ, A] =
Z
d4x

−1
4F µνFµν + ¯ψ (γµ∂µ + iqγµAµ −m) ψ

(22.67)
This action is manifestly Lorentz-invariant. We shall now show that it is also gauge invariant. Under
a gauge transformation, ψ is multiplied by an x-dependent phase factor, while Aµ transforms as,
Aµ(x)
→
A′
µ(x) = Aµ(x) + ∂µθ(x)
ψ(x)
→
ψ′(x) = e−iqθ(x) ψ(x)
(22.68)
291

The key property is that the gauge covariant derivative Dµ = ∂µ + iqAµ of ψ transforms exactly
as ψ does under gauge transformations. Indeed, we have
Dµψ(x) →D′
µψ′(x) = (∂µ + iqA′
µ(x))ψ′(x) = e−iqθ(x)Dµψ(x)
(22.69)
The modiﬁed Dirac equation, in the presence of the electro-magnetic ﬁeld is obtained by varying
the action with respect to ¯ψ, and we ﬁnd,
(γµ∂µ + iqγµAµ −m) ψ = 0
(22.70)
It is very interesting to work out the non-relativistic limit of this equation. To do so, we multiply
the Dirac equation by the operator (γµ∂µ + iqγµAµ + m), to get a second order equation,

γµ∂µ + iqγµAµ + m

γµ∂µ + iqγµAµ −m

ψ = 0
(22.71)
or equivalently,

γµγν(∂µ + iqAµ)(∂ν + iqAν) −m2

ψ = 0
(22.72)
Using the decomposition of the product into symmetric and anti-symmetric tensors,
γµγν = ηµν + 2Sµν
Sµν = 1
4[γµ, γν]
(22.73)
the second order equation becomes,

(∂µ + iqAµ)(∂µ + iqAµ) + Sµν[∂µ + iqAµ, ∂ν + iqAν] −m2

ψ = 0
(22.74)
in view of the anti-symmetry in µ, ν of Sµν. The commutator is easily computed, and we have,
[∂µ + iqAµ, ∂ν + iqAν] = iqFµν
(22.75)
Hence, the second order equation becomes,

(∂µ + iqAµ)(∂µ + iqAµ) + iqFµνSµν −m2

ψ = 0
(22.76)
In the non-relativistic limit, we have i∂0ψ = (m + E)ψ with E ≪m. As a result, we have

2m(E + qA0) −(⃗p + q ⃗A)2 + iqFµνSµν

ψ = 0
(22.77)
The corresponding Schr¨odinger equation is then,
 1
2m(⃗p + q ⃗A)2 −iq
2mFµνSµν −qA0

ψ = Eψ
(22.78)
This gives ⃗B · ⃗S coupling µe = e/m.
292

23
Quantization of the Dirac Field
We proceed to quantizing ﬁrst the free Dirac ﬁeld, and shall then motivate the quantization of the
interacting ﬁeld. Recall that we have,
•

γµ∂µ −m

ψ = 0
•
H =
Z
d3xψ† 
−γ0γi∂i + mγ0
ψ
•
Q =
Z
d3xψ†ψ
(23.1)
Recall that the key new feature of the Dirac ﬁeld is that it must describe fermions, in contrast to
the scalar or electro-magnetic ﬁeld which describes bosons. The Fock space of states for the Dirac
ﬁeld should automatically reﬂect the the corresponding Fermi-Dirac statistic, just as the Fock space
for bosons automatically reﬂected Bose-Einstein statistics. While bosonic ﬁelds are decomposed
into bosonic oscillators, we should expect the Dirac ﬁeld to decompose into fermionic oscillators,
as had already been guessed in earlier sections.
23.1
The basic free ﬁeld solution
Recall that the general solution to the free Dirac equation is given by by a linear superposition of
Fourier modes of the form,
ψ(x)
=
u(k) e−ik·x
(ikµγµ + m) u(k)
=
0
(23.2)
with the “on-shell” condition kµkµ = k2 = m2. The equation for u(k) has solutions for both k0 > 0
and k0 < 0. It is conventional to reorganize the solutions with the help of the following notation,
ψ+(x)
=
u(k) e−ik·x
k0 > 0
ψ−(x)
=
v(k) e+ik·x
k0 < 0
(23.3)
where now,
(ikµγµ + m) u(k)
=
0
(ikµγµ −m) v(k)
=
0
(23.4)
Note that each equation actually has two linearly independent solutions, which we may label by an
extra index, s, standing for the spin of the particle. Thus, the 4 independent solutions to the Dirac
equation are us(k) and vs(k) for s = 1, 2. The solutions ψ+ admit the standard interpretation as
particle with positive energy.
Historically, the interpretation of the solutions ψ−and v(k) was at ﬁrst confusing, as they
seemed to correspond to particle with negative energy, which is absurd. The issue was ﬁrst clariﬁed
by Feynman in 1948. The solution ψ−cab be obtained formally from ψ+ by “reversing the arrow
293

of time”, instead of reversing the sign of the energy. Let us see how this would work in practice.
Creating a particle with positive energy would then be mapped into annihilating an anti-particle
with positive energy. Analogously, annihilating a particle with positive energy maps to creating an
anti-particle with positive energy. Thus, if the solution u(k) multiplies an annihilation operator for
a particle, then v(k) should multiply a creation operator for an anti-particle. Thus, the Dirac ﬁeld
decomposes as follows,
ψ(x)
=
X
k,s
n
us(k)bs(k)e−ik·x + vs(k)d†
s(k)e+ik·xo
ψ†(x)
=
X
k,s
n
u†
s(k)b†
s(k)e+ik·x + v†
s(k)ds(k)e−ik·xo
(23.5)
Here, we have expressed the superposition in k as a sum, but an integral over k should be used
instead on R3. The physical interpretation of the operators is as follows,
bs(k)
annihilation operator for a particle
d†
s(k)
creation operator for an anti-particle
b†
s(k)
creation operator for a particle
ds(k)
annihilation operator for an anti-particle
(23.6)
The Dirac spinor representation being complex, there is a priori no reality relation between the
oscillators bs(k) and ds(k). We shall see later on that a Lorentz invariant reality (or Majorana)
condition may be imposed consistently under certain assumptions, and in that restricted case we
have ds(k) = bs(k), so that the corresponding Majorana fermion particle coincides with its anti-
particle (just as the photon did).
From the above construction, we can immediately draw a conclusion on the electric charge
assignments of the particle and anti-particle. Recall that the electric charge is the N¨other charge
associated to phase rotation symmetry of the Dirac ﬁeld,
ψ(x) →ψ′(x) = eiθψ(x)
(23.7)
for constant phases θ. We conclude that the electric charges of bs(k) and d†
s(k) must be the same.
This means that the change in charge due to annihilating a particle must be the same as the
electric charge change due to creating an anti-particle. Thus, the electric charges of particle and
anti-particle must be opposite. As a corollary, only electrically neutral particle can be their own
anti-particles.
Dirac at ﬁrst did not know how to interpret the extra “negative energy solutions”, and neither
did anybody else for some time. In fact, Dirac originally proposed that the proton would be this
missing anti-particle to the electron, mainly because the electric charges of the proton and electron
are exactly opposite. This is actually incorrect, since we can clearly see from the Dirac equation
and its solutions that mass of the particle and anti-particle must be the same, while the masses of
the proton and the electron diﬀer by a factor of 2000.
294

The correct interpretation is that these “negative energy solutions” actually describe the anti-
particle of the electron, i.e. the positron. Its mass is exactly equal to that of the electron, and its
charge is exactly opposite. When the positron was discovered experimentally in the 1930s, Dirac’s
theory was immediately propelled to great fame.
We are now ready to writing the general solution of the free Dirac equation,
ψ(x)
=
Z
d3k
(2π)3 f(k0)
X
s=1,2
n
us(k)bs(k)e−ik·x + vs(k)d†
s(k)e+ik·xo
ψ†(x)
=
Z
d3k
(2π)3 f(k0)
X
s=1,2
n
u†
s(k)b†
s(k)e+ik·x + v†
s(k)ds(k)e−ik·xo
(23.8)
where kµ = (k0,⃗k) and k0 = +
q
⃗k2 + m2, and exhibits only positive energy solutions. Here we
have included a normalization factor f(k0) whose precise form will be ﬁxed by standard convention
later on.
Given the above expressions for the ﬁelds ψ and ψ†, we are in a position to evaluate physical
observables, such as the electric charge Q and the Hamiltonian H for the free Dirac ﬁeld. We
shall begin by working out the charge. Substituting ψ and ψ† given in (23.8) into the deﬁnition of
electric charge in (23.1), we ﬁnd,
Q
=
Z
d3x
Z
d3k
(2π)3
Z
d3k′
(2π)3 f(k0)f(k
′0)∗X
s,s′
n
u†
s′(k′)b†
s′(k′)e+ik′·x + v†
s′(k′)ds′(k′)e−ik′·xo
×
n
us(k)bs(k)e−ik·x + vs(k)d†
s(k)e+ik·xo
(23.9)
Carrying out the integration over x sets ⃗k′ = +⃗k in the direct terms, and ⃗k′ = −⃗k in the cross
terms. As a result, we have
Q
=
Z
d3k
(2π)3 |f(k0)|2 X
s,s′

u†
s′(k)us(k)b†
s′(k)bs(k) + v†
s′(k)vs(k)ds′(k)d†
s(k)
+u†
s′(−k)vs(k)b†
s′(−k)d†
s(k) + v†
s′(−k)us(k)ds′(−k)bs(k)

(23.10)
To simplify this expression further, we need a number of spinor identities, which we shall ﬁrst
develop.
23.2
Spinor Identities
The staring point is the deﬁning relations for the spinors us and vs,
(ikµγµ + m)us(k)
=
0
(ikµγµ −m)vs(k)
=
0
(23.11)
295

It will be convenient to parametrize the corresponding solutions in a basis where the chirality matrix
is diagonal. In this basis, we decompose the 4-component spinors into blocks of two-component
left- and right-spinors,
us(k) =
 uLs(k)
uRs(k)

vs(k) =
 vLs(k)
vRs(k)

(23.12)
The equations (23.11) then reduce to
 −im
k · σ
k · ¯σ
−im
  uLs(k)
uRs(k)

=
0
 +im
k · σ
k · ¯σ
+im
  vLs(k)
vRs(k)

=
0
(23.13)
or in components,
(k · σ)uRs(k)
=
+i m uLs(k)
(k · ¯σ)uLs(k)
=
+i m uRs(k)
(k · σ)vRs(k)
=
−i m uLs(k)
(k · ¯σ)vLs(k)
=
−i m uRs(k)
(23.14)
Since we have
(k · σ)(k · ¯σ) = m2I2
(23.15)
the general solutions to these equations may be parametrized by two pairs of independent 2-
component spinors ξs and ηs, by,
us(k) =
 (
√
k · σ)ξs
i(
√
k · ¯σ)ξs

vs(k) =
 (
√
k · σ)ηs
−i(
√
k · ¯σ)ηs

(23.16)
There is no problem in deﬁning the square roots of the matrices k · σ and k · ¯σ, since they are
Hermitian, and may be diagonalized. The spinors ξs and ηs are arbitrary basis vectors, and may
be conveniently chosen to obey the following normalization conditions,
ξ†
s′ξs = η†
s′ηs
=
δs′,s
ξ†
s′ηs = η†
s′ξs
=
0
(23.17)
One may then choose the following explicit basis,
ξ1 = η1 =
 1
0

ξ2 = η2 =
 0
1

(23.18)
With the help of these normalizations, it is now straightforward to evaluate
¯ur(k) us(k) = +2mδrs
¯ur(k)vs(k) = 0
¯vr(k) vs(k) = −2mδrs
¯vr(k)us(k) = 0
(23.19)
296

The calculation of the ﬁrst line, for example, proceeds as follows,
¯ur(k) us(k) = u†(k)γ0vs(k)
=
 ξ†
r(
√
k · σ)
−iξ†
r(
√
k · ¯σ)
t  0
I
−I
0
  (
√
k · σ)ξs
i(
√
k · ¯σ)ξs

=
iξ†
r
n
(
√
k · σ)(
√
k · ¯σ) + (
√
k · ¯σ)(
√
k · σ)
o
ξs
=
2i mξ†
rξs = 2i mδrs
(23.20)
These results may be used in turn to evaluate other spinor bilinears, such as the quantity ¯urγµus.
This is a 4-vector, which can only depend upon kµ, so that it must be of the form,
¯urγµus = kµMrs
(23.21)
The matrix Mrs, which in principle could depend on the Lorentz-invariant quantity m, is actually
independent of m on dimensional grounds. To evaluate Mrs, we contract both sides with kµ, and
obtain,
m2Mrs = ¯urkµγµus = −im¯urus = 2m2δrs
(23.22)
where we have used the deﬁning equation for us for the second equality. A similar calculation may
be carried out for vs, and we ﬁnd,
¯ur(k)γµus(k)
=
2kµδrs
¯vr(k)γµvs(k)
=
2kµδrs
(23.23)
Finally, we will also need
u†
r(k)vs(−k) = v†
r(k)us(−k) = 0
(23.24)
23.3
Evaluation of the electric charge operator and Hamiltonian
Using the above spinor identities, it is now straightforward to further simplify the expression for
the electric charge, and we ﬁnd,
Q =
Z
d3k
(2π)3
X
s=1,2
n
b†
s(k)bs(k) + ds(k)d†
s(k)
o
(23.25)
where we have made the following convenient choice for the normalization factor,
f(k0) =
1
√
2k0
(23.26)
To evaluate the Hamiltonian, we use the Dirac equation to recast its expression as follows,
H =
Z
d3xψ† 
−γi∂i + m

ψ =
Z
d3x i ψ†∂0ψ
(23.27)
297

Evaluating the time derivative, we ﬁnd,
i∂0ψ =
Z
d3k
(2π)3
1
√
2k0
X
s=1,2
n
k0us(k)bs(k)e−ik·x −k0vs(k)d†
s(k)e+ik·xo
(23.28)
and we ﬁnd,
H =
Z
d3k
(2π)3 k0 X
s=1,2
n
b†
s(k)bs(k) −ds(k)d†
s(k)
o
(23.29)
23.4
Quantization of fermion oscillators
We are now ready to proceed with quantization.
Recall that we had declared b† and d† to be
the creation operators for particles and anti-particles, having charges +1 and −1 respectively, and
both with positive energy. The oscillators b, d, b†, d† have to be quantized as fermions. As we have
seen earlier, this is done in terms of anti-commutation relations. It will turn out that the correct
relations are,
{br(k), bs(k′)} = {dr(k), ds(k′)}
=
0
{br(k), ds(k′)} = {br(k), d†
s(k′)}
=
0
{br(k), b†
s(k′)} = {dr(k), d†
s(k′)}
=
(2π)3δr,sδ(3)(k −k′)
(23.30)
as well as the adjoint relations of the ﬁrst two lines. Normal ordering now the expressions for
electric charge Q, Hamiltonian H, as well as the momentum ⃗P, we get,
Q
=
Z
d3k
(2π)3
X
s=1,2
n
b†
s(k)bs(k) −d†
s(k)ds(k)
o
H
=
Z
d3k
(2π)3 k0 X
s=1,2
n
b†
s(k)bs(k) + d†
s(k)ds(k)
o
⃗P
=
Z
d3k
(2π)3⃗k
X
s=1,2
n
b†
s(k)bs(k) + d†
s(k)ds(k)
o
(23.31)
23.5
Canonical anti-commutation relations for the Dirac ﬁeld
From the anti-commutation relations of the oscillators b, d, b†, d†, we deduce those of the Dirac ﬁelds
themselves. It is immediate that
{ψα(x), ψβ(y)} = {ψ†
α(x), ψ†
β(y)} = 0
(23.32)
where α, β run over the spinor components of the Dirac ﬁelds. It remains to compute
{ψ†
α(x), ψβ(y)}
=
Z
d3k
(2π)3
Z
d3k′
(2π)3
X
s,s′
1
2
√
k0k
′0

u†
sα(k)b†
s(k)eik·x + v†
sα(k)ds(k)e−ik·x,
us′β(k′)bs′(k′)e−ik′·y + vs′β(k′)d†
s′(k′)eik′·y

(23.33)
298

Using the anti-commutation relations and b and d oscillators, we obtain contributions of either 0
or δs,s′(2π)3δ(⃗k −⃗k′). The expression thus simpliﬁes to
{ψ†
α(x), ψβ(y)} =
Z
d3k
(2π)3
1
2k0
X
s

u†
sα(k)usβ(k)eik·(x−y) + v†
sα(k)vsβ(k)e+ik·(x−y)

(23.34)
It remains to obtain the ﬁnal spinor relation we need,
X
s
u†
sαusβ
=
(γµkµ + m)αβ
X
s
v†
sαvsβ
=
(γµkµ −m)αβ
(23.35)
Putting all together, we have
{ψ†
α(x), ψβ(y)} =
Z
d3k
(2π)3
1
2k0

(γµkµ + m)γ0eik·(x−y) + (γµkµ −m)γ0e+ik·(x−y)

αβ
(23.36)
Now, this is the expression for free fermions. Setting the time components equal to one another,
we have a relation which is independent of dynamics, and giving the canonical anti-commutation
relations of the ﬁelds,
{ψ†
α(x), ψβ(y)}δ(x0 −y0) = δαβδ(4)(x −y)
(23.37)
23.6
The fermion propagator
The free fermion propagator is the “inverse of the Dirac operator”. A useful way to look at this
quantity is from how it arises from the Dirac ﬁeld. The two pieces of information we need are
summarized as follows,
(γµ∂µ −m) ψ(x)
=
0
{ψ†
α(x), ψβ(y)}δ(x0 −y0)
=
δαβδ(x −y)
(23.38)
where the derivative operator acts as ∂µ = ∂/∂xµ. So, the Dirac ﬁeld may be viewed as a “homoge-
neous” solution to the Dirac equation. The Dirac propagator should thus satisfy the inhomogeneous
equation,
(γµ∂µ −m) S(x, y) = I4δ(4)(x −y)
(23.39)
where I4 is the identity matrix in the 4-component Dirac spinor space. On the one hand, this
equation may be solved (formally) by Fourier transform, and we ﬁnd,
Z
d4k
(2π)4
eik·(x−y)
iγµkµ −m
(23.40)
This is formal because the denominator will have a vanishing eigenvalue for a whole family of values
of k, namely those that obey kµkµ+m2 = 0. This problem is familiar from the Lippmann-Schwinger
299

equation for potential scattering, and was solved there by the introduction of a small imaginary
part. The same works here, and we replace the above formal expression by the following accurate
one,
S(x, y) =
Z
d4k
(2π)4
eik·(x−y)
iγµkµ −m + iε
(23.41)
for ε > 0. The actual value of the integral is complicated, except for m = 0, but will not be needed
explicitly here.
There is another way of expressing the free fermion propagator, which will be very useful in
carrying out perturbative calculations. It is based on the fact that to obtain the inverse of the Dirac
operator, it suﬃces to “patch together” two solutions to the homogeneous equation. This is done
by using the time-ordering operation that we had encountered when carrying out time-depenedent
perturbation theory. Consider the following object,
Tψα(x) ¯ψβ(y) ≡θ(x0 −y0)ψα(x) ¯ψβ(y) −θ(y0 −x0)ψβ(y) ¯ψα(x)
(23.42)
Note the minus sign used in the time-ordering of fermion operators.
Applying now the Dirac
operator in the coordinate x to both sides, we see that when the operator lands on the ﬁeld ψa(x),
the corresponding contribution cancels, in view of the fact that ψα(x) satisﬁes the Dirac equation.
So, the only non-zero contribution arises from when the time-derivative in the Dirac equation hits
the θ-function, and this contribution gives,
(γµ∂µ −m)γα
 Tψα(x) ¯ψβ(y)

=
δ(x0 −y0)(γ0)γα(γ0)δβ{ψα(x), ψ†
δ(y)}
=
(γ0)γα(γ0)δβδαδδ(4)(x −y)
=
δγβδ(4)(x −y)
(23.43)
Of course, Tψα(x) ¯ψβ(y) is an operator, not a number, but we can easily extract from it a pure
number, so that we ﬁnd,
Sαβ(x −y) = ⟨∅|Tψα(x) ¯ψβ(y)|∅⟩
(23.44)
where |∅⟩is the free-fermion vacuum state.
23.7
The concept of vacuum polarization
We are now ready to study one of the most basic eﬀects in interacting quantum ﬁeld theory,
namely vacuum polarization. We all know what a regular polarized medium is. For example, water
molecules exhibit an asymmetrical geometry, with the two Hydrogen atoms being on one side, and
the Oxygen atom being at the other side of the molecule.
−
O < H
H
+
(23.45)
300

This gives the molecule an electric dipole moment. An electric charge q inserted into water vapor,
will experience screening. A positive charge q > 0 located at a point P will preferentially orient the
water molecules so that their negative ends (the Oxygen) point towards the point P, while their
positive ends point away from P. The collective eﬀect produced by the systematic orientations of
the water molecules results in the screening of the charge q, so that the eﬀective charge observed
some distance away from q will be smaller than q.
Now introduce the electric charge q in the vacuum. At ﬁrst sight, it will seem that there is
no material available to screen this charge, since naively the vacuum is empty. In fact, we know
already from the Casimir eﬀect that vacuum ﬂuctuations of the quantum electro-magnetic ﬁeld
induces physically observable eﬀects. Here, it is the vacuum ﬂuctuations of the Dirac ﬁeld of the
electron and positron that will produce a measurable eﬀect. We begin by describing the eﬀect
qualitatively ﬁrst, and we will compute it in full in the subsequent subsections.
Qualitatively, the origin of vacuum polarization lies in the fact that vacuum ﬂuctuations of the
Dirac ﬁeld amount to the creation of virtual pairs of an electron and a positron. These particles
are virtual in the sense that there is not enough energy available to make them materialize as real
physical electron and positron. By the energy-time uncertainty relation, these particles can exist
only for a very short time, after which they must annihilate one another. But during their short
life-time, the pair forms a small electric dipole. And this (virtual) dipole has a screening eﬀect on
the electric charge which is completely analogous to the eﬀect produced by a real electric dipole
like water. As a result, if a charge q is introduced at a point P in the Dirac vacuum, then the
eﬀective charge felt must decrease with distance away from P.
Is it possible to have the opposite eﬀect ? Namely, could the eﬀective charge increase as the
distance increases ? Not in electro-dynamics. In non-Abelian gauge theories (Yang-Mills theories)
however, this is possible, and in fact generic within certain ranges of parameters, and this eﬀect is
equivalent to the property of asymptotic freedom.
301

