Michael Titelbaum, Quitting Certainties: A Bayesian Framework Modeling
Degrees of Belief. Oxford: Oxford University Press, 2013. xii þ345 pp.
Many philosophers have suggested that a fruitful way to think about belief and
uncertainty is through the framework of probability theory. The basic model for
this way of thinking, often called “Bayesian,” is that an agent’s degrees of belief
can be represented by a probability function, which changes by incorporating
new information as certain. The title of this book is a reference to the fact that it
includes a new Bayesian framework that can deal with the loss of certainties,
which can often happen either because of forgetting, or because of context
sensitivity. (For instance, I am now certain that it is Friday, but in a few hours I
won’t be, because it will be false in the new context.)
However, while this new framework is important, and makes this book
essential reading for people interested in the epistemology of these situations
(whether Bayesian or not), the ﬁrst seven chapters make an important contri-
bution of their own—one that deserves to be more broadly noted. In these
chapters, Titelbaum spells out one of the most systematic formulations of how
Bayesian epistemology should be applied. Many of the vexing problems for it (or
indeed for any attempt to use formal methods in any area of philosophy) are
made much less vexing by means of a careful setting up of the formal machinery.
Titelbaum is careful to distinguish the actual requirements of rationality
from the formal statements of his system, and chapter 2 provides some extensive
discussion of the possible relations between the two. Chapter 3 explicitly pres-
ents his formal system as a kind of model of the requirements of rationality—it is
not intended to represent precisely what these requirements actually are in all
cases but is instead supposed to give us a good idea of what the requirements are
like within a sort of “domain of applicability” of the model.
This way of thinking about a formal system is familiar from science: we
treat Newtonian mechanics as a good system for reasoning about the behavior of
certain types of objects, but we know that it will be bad in the presence of the very
large or small, extremely high velocities, and friction or other nongravitational
forces. Bayesianism originally arose in the philosophy of science, where this way
of thinking may have been more common, but epistemologists may ﬁnd this
idea of a model as approximation less familiar. I think Titelbaum provides a
valuable resource in showing that this is a way that philosophical inquiry can
proceed as well.
While this review can’t do full justice to Titelbaum’s formalism, I will give
a quick overview in order to help illustrate some of the insights it provides and
the way in which it should be extended. The basic idea is that when dealing with
a “story” (an informal description of a scenario in which some agent’s doxastic
state evolves over time), Titelbaum generates a “model,” which includes a
language (giving the set of claims for which the agent’s degrees of belief are
B O O K R E V I E W S
143
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

of interest), and a set of times at which we care about the agent’s degrees of
belief. Titelbaum then provides several “systematic constraints” and suggests
that we extract “extrasystematic constraints” from the story and use these con-
straints together to generate a function P assigning a value Pi (x) for each time i
in the time set and sentence x in the language. These assignments are called
“verdicts” of the model, and they are interpreted by saying that an agent whose
degrees of belief conﬂict with the verdicts of the model must be in violation of
some of the requirements of ideal rationality.
The distinction between systematic and extrasystematic constraints is
key to Titelbaum’s application of these models. He imposes just four systematic
constraints: Subjective Finite Additivity, the Ratio Formula, Generalized Con-
ditionalization, and the Proper Expansion Principle. (These are helpfully sum-
marized in a quick reference page at the beginning of the book. I will discuss
them as they come up.) However, he also requires that for each i and x, there is
either an extrasystematic constraint of the form Pi (x) ¼ 1 or one of the form
Pi (x) , 1, depending on whether our understanding of the story indicates that
the agent should be certain of x at that time or not. There may also be further
extrasystematic constraints if the story is one in which we think further rational
requirements may apply (for instance, symmetries of dice rolls or knowledge of
chances). Perhaps future developments of this framework will attempt to ac-
count for more of these constraints in a systematic manner, but for now this is an
honest way of dealing with the limitations of any formal framework.
The ﬁrst two systematic constraints are synchronic while the other two
constraints provide the diachronic rules that apply to updates over time. Finite
additivity, together with the extrasystematic constraints requiring probabilities
to either equal 1 or be less than 1, is equivalent to probabilism. His version
of the ratio formula says that if Pi ( , y) , 1, then the conditional probability
Pi (x j y) ¼ Pi (x & y)/Pi ( y), and it is undeﬁned otherwise. As Titelbaum notes,
it makes sense for conditional probabilities to be undeﬁned when one is certain
that the antecedent is false, which means that this framework is well designed
for stories in which rational agents have degree of belief 1 only in things of
which they are certain.
However, if we would like to include stories where there are inﬁnitely
many alternatives (for instance, for scientiﬁc reasoning about numerical
parameters), it would be useful to distinguish certainty from degree of belief
1. To describe his generalized conditionalization rule (which I will say more
about later), Titelbaum introduces the notion of a “certainty set” at a time i,
which he deﬁnes as the set of all the x such that Pi (x) ¼ 1. However, it
seems to me that a slightly more general form of the framework could be
deﬁned by taking certainty as a primitive, and adding three more systematic
constraints—one requiring certainties to be closed under logical deduction,
another saying that if an agent is certain of x at time i, then Pi (x) ¼ 1, and
another saying that for all i and x, Pi (x) $ 0. It is more natural to treat
B O O K R E V I E W S
144
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

certainty, rather than probability 1, as the feature that must come from
extrasystematic constraints, even if this requires further systematic con-
straints. We also need to modify the ratio formula constraint so that it says
that if ,y is certain at i, then Pi (x j y) is undeﬁned, and otherwise (following
Popper) it satisﬁes Pi (x & y) ¼ Pi (x j y)Pi ( y). I have worked through the
examples in Titelbaum’s book, and it looks like every case works out just
as well under this generalized framework, except for a few where a verdict of
“,” is replaced by one of “ # .”
Of course, the diachronic principles yield most of the interesting
insights of the framework. The principle of generalized conditionalization
says that if j and k are times whose certainty sets Cj and Ck are compatible,
then Pj (x jCk) ¼ Pk (x jCj). Among other things, this generates the traditional
requirement of update by conditionalization in the case where an agent learns
new certainties at a later time without losing any others. Furthermore, as Titel-
baum shows in chapter 6, this generalized principle can derive plausible verdicts
in various cases of memory loss. This chapter also tries to explain the failure of
the “reﬂection principle” in these cases, though I think this discussion is not
fully successful (particularly because reﬂection involves second-order beliefs
about one’s own beliefs, which his framework can’t accommodate).
At this point, before Titelbaum discusses the fourth systematic rule
(which is the one essential for treating many other cases of the sort suggested
by the title) comes chapter 7, which in my view poses some of the most interest-
ing and important questions in the book. This chapter discusses the notion of
diachronic consistency that is implicit in generalized conditionalization and
considers what justiﬁcation it could have. As Titelbaum shows, there are several
even stronger principles that entail it. For instance, if there is one objective
rational ur-prior probability distribution such that at any time, every rational
agent ought to have degrees of belief that equal the values of this distribution
conditionalized on their certainties, then rational agents will satisfy generalized
conditionalization. In fact, generalized conditionalization would even hold
when the degrees of belief at different times belong to different rational agents!
And in fact, many different views on which the evidence one has at a time
uniquely determines the rational degrees of belief to have at that time will justify
generalized conditionalization.
The more difﬁcult question is how to justify this norm of diachronic
consistency within a more permissive framework, on which one’s evidence does
not uniquely determine the degrees of belief one should have. It may be that
there is no requirement that one actually update in ways that satisfy this rule but
merely that one must be committed to updating in such a way. Or perhaps, that
updating in this way is part of what it takes to count as the same rational agent
over time. The question is not answered here, but I think this chapter raises
some very important considerations that all theories of diachronic rationality
must confront. Some of Titelbaum’s discussion here relies heavily on the work of
B O O K R E V I E W S
145
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

Isaac Levi, particularly from his book The Enterprise of Knowledge (1980). This
book has been underappreciated by philosophers working in the tradition of
Richard Jeffrey and David Lewis, and hopefully Titelbaum’s work will help draw
more attention to the insights contained within it and help make them more
accessible to new audiences.
The remainder of the book discusses the many issues that arise when
context sensitivity occurs in updating—either alone, or in combination with
actual or possible memory loss. Learning ﬁrst that it is Friday and later that it is
Saturday is not like an update involving new information. One is not learning
the unexpected thing that it is actually Saturday at the time that one once
thought was Friday but is in fact just learning that the eventually expected
change in context has now occurred.
The speciﬁc case of this sort that is most heavily discussed in recent
epistemology is that of Sleeping Beauty. In this case, Beauty is a participant in
a science ﬁction psychological experiment, and she knows in advance all the
details of how it will be structured. On Sunday night, the experimenters will ﬂip
a fair coin. On Monday, she will wake up and be debriefed by the experimenters.
On Monday night, when she is asleep, she will either be given drugs that cause
her to dreamlessly sleep all through the day on Tuesday to wake up on Wednes-
day (if the coin came up heads), or be given different drugs that erase her
memories of Monday, so that she wakes up on Tuesday in the same mental
state that she woke up in on Monday, and she will be debriefed by the exper-
imenters again. When she wakes up during the experiment, given what she has
been told, she does not know whether it is Monday or Tuesday, and she does not
know whether the coin came up heads or tails.
Some philosophers have argued that she has learned nothing relevant to
the coin toss, so she should have degree of belief ½ that the coin came up heads.
Others have argued that since she wakes up twice as many times if the coin comes
up tails, she should have degree of belief 1⁄3 that the coin came up heads.
Titelbaum gives one of the ﬁrst fully formal systems that allows one to calculate
the answer (1⁄3 ), rather than reasoning intuitively. (As he points out, there are
other formal systems now that give competing answers.)
Titelbaum’s answer comes from his “proper expansion principle.” To
explain this principle, we have to deﬁne the notion of an “epistemically context-
insensitive sentence.” This is a sentence in the language of the model such
that at every time in the model, the relevant agent is certain that the sen-
tence has the same truth value at all times in the model. Such a sentence
may in fact be context-sensitive, as long as the context sensitivity is not
relevant within the particular story being modeled. For instance, we might
consider a story that discusses Beauty’s degrees of belief on Monday, from
the morning when she ﬁrst wakes up, until the afternoon when she has been
told that it is Monday (but not how the coin came up). In this case, the
sentence “today is Monday” is epistemically context-insensitive, even though
B O O K R E V I E W S
146
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

it does use the context-sensitive expression “today.” It would be epistemically
context-sensitive in a story that includes either Sunday or Tuesday as well, so
this notion is relative to the story.
The proper expansion principle says that if every epistemically context-
sensitive sentence has insensitive replacements (meaning that at each time in
the story, there is some epistemically context-insensitive sentence such that at
that time, the agent is certain that the two sentences have the same truth-value),
then any verdict calculated in a model using just the epistemically context-in-
sensitive sentences will also be a verdict of the full model. Issues around ﬁnding
these replacements and stating exactly how this principle applies to a variety of
cases are too tricky to go into in great detail here, but Titelbaum discusses them
at length in the second half of the book.
One interesting feature of this book is that, unlike many other philo-
sophical works, it doesn’t try to derive its results from ﬁrst principles. Instead,
the major motivation Titelbaum gives for his framework is just that it is a system-
atic account that appears to give the right answer in many cases. Importantly, he
doesn’t just focus on the problem cases that have been central to the literature
but discusses many simple cases, like people losing track of time while their
alarm clocks fail. It is only after showing that he can properly account for
these cases that he then applies the framework to Sleeping Beauty. This is
related to the central idea that what he is doing here is “modeling” situations
within a certain domain of applicability. This may not be satisfying to philoso-
phers who are interested in giving full explanations, but this may be a necessary
trade-off for creating a workable formal system.
Still, given the way that the Proper Expansion Principle has been set up,
there are some beginnings of a justiﬁcation. In response to a challenge from
Sarah Moss (discussed toward the end of chapter 8), Titelbaum has modiﬁed
this principle from how it worked in his previous papers on the topic. Now the
claim is not that one can derive verdicts in any sublanguage where all removed
sentences have equivalents but rather only if the sublanguage consists of the
epistemically context-insensitive sentences. This suggests a motivation. One
might be able to argue that the epistemically context-insensitive claims are
the ones that drive our updates—these are the ones that reﬂect our information
about the world. But even without a full justiﬁcation, chapter 10 of this book
provides a useful summary and comparison of this system with those of Joseph
Halpern, Chris Meacham, Sarah Moss, and Robert Stalnaker.
Given the modiﬁcation I have suggested above to the way the system
treats certainty, I think it would also be interesting to see how well it can deal
with various inﬁnitary cases. For instance, Jacob Ross’s “St. Petersburg Sleeping
Beauty” case would be interesting to evaluate, to see if the reasoning he suggests
to lead toward violations of countable additivity does in fact go through on this
particular system.
B O O K R E V I E W S
147
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

In closing, this book provides an interesting and systematic account for
dealing with the gain and loss of certainties and explaining how they can ratio-
nally drive all the changes in degree of belief that an agent goes through over
time. Even if the system doesn’t turn out to be the right way to think about
updating of degrees of belief in light of memory loss and context sensitivity, I
think Titelbaum’s care in setting up the system makes it an admirable model for
any future development that aims to replace it, either for these purposes or even
for the more restricted purposes to which Bayesianism is usually applied.
Kenny Easwaran
Texas A&M University
Philosophical Review, Vol. 125, No. 1, 2016
DOI 10.1215/00318108-3321761
Kok-Chor Tan, Justice, Institutions, and Luck.
Oxford: Oxford University Press, 2012. ix þ198 pp.
Luck egalitarianism—the thought that unchosen forms of advantage are pre-
sumptively unjust—has not been the most fashionable view as of late. The rise of
the “democratic equality” of Elizabeth Anderson—along with the continuing
inﬂuence of John Rawls’s own political view of justice—have contributed to the
sense that luck egalitarianism is simply too blunt an instrument with which to
analyze social and political justice. Kok-Chor Tan attempts, in this recent book,
to develop a chastened and moderate luck egalitarianism, one that might dem-
onstrate why luck egalitarianism is attractive—and how it can defend itself
against its critics.
The book is a model of clarity and rigor; it is a thin volume, but it man-
ages to cover several decades of recent thinking about social justice, and do so
with grace and accuracy. It would be of use, even if Tan’s own arguments were
rejected, as a useful supplement to any class on recent political philosophy. Tan’s
own arguments, though, are the real heart of the book, and these arguments
amply repay close reading.
Tan develops his view with reference to three questions: where does dis-
tributive justice matter? Why should we care about economic inequality? And
among whom does justice hold? The ﬁrst question is taken up in the ﬁrst third of
Tan’s book; his answer is that distributive justice applies in the ﬁrst instance to
institutions—to those large-scale structures that transform natural facts into
inequalities of wealth and income. This part of the book argues that, contrary
to the arguments of G. A. Cohen, an institutional focus is not an abdication of
moral concern but a recognition of the possibility of value pluralism. Were
B O O K R E V I E W S
148
Downloaded from http://read.dukeupress.edu/the-philosophical-review/article-pdf/125/1/143/462796/143Easwaran.pdf by WIKIPEDIA LIBRARY user on 03 July 2023

