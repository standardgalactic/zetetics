The Architecture of Complexity
Herbert A. Simon
Proceedings of the American Philosophical Society, Vol. 106, No. 6. (Dec. 12, 1962), pp.
467-482.
Stable URL:
http://links.jstor.org/sici?sici=0003-049X%2819621212%29106%3A6%3C467%3ATAOC%3E2.0.CO%3B2-1
Proceedings of the American Philosophical Society is currently published by American Philosophical Society.
Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at
http://www.jstor.org/about/terms.html. JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtained
prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content in
the JSTOR archive only for your personal, non-commercial use.
Please contact the publisher regarding any further use of this work. Publisher contact information may be obtained at
http://www.jstor.org/journals/amps.html.
Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printed
page of such transmission.
JSTOR is an independent not-for-profit organization dedicated to and preserving a digital archive of scholarly journals. For
more information regarding JSTOR, please contact support@jstor.org.
http://www.jstor.org
Thu Apr 5 22:25:26 2007

THE ARCHITECTURE OF COMPLEXITY 
HERBERT A. SIMON* 
Professor of Administration, Carnegie Institute of Technology 
(Read April 26, 1962) 
A NUMBER of proposals have been advanced in 
recent years for the development of "general sys- 
tems theory" which, abstracting from properties 
peculiar to physical, biological, or social systems, 
would be applicable to all of them.l IVe might 
well feel that, while the goal is laudable, systems 
of such diverse kinds could hardly be expected to 
have any nontrivial properties in common. Meta-
phor and analogy can be helpful, or they can be 
misleading. 
All depends on whether the simi-
larities the metaphor captures are significant or 
superficial. 
It may not be entirely vain, however, to search 
for common properties anlong diverse kinds of 
complex systems. The ideas that go by the name 
of cybernetics constitute, if not a theory, at least 
a point of view that has been proving fruitful over 
a wide range of application^.^ It has been useful 
to look at the behavior of adaptive systems in 
terins of the concepts of feedback and homeostasis, 
*The ideas in this paper have been the topic of many 
conversations with my colleague, Allen Xewell. 
George 
\V. Corner suggested important improvements in biologi- 
cal content as well as editorial form. 
I am also 
indebted, for valuable comments on the manuscript, to 
Richard H. Meier, John R. Platt, and Warren Weaver. 
Some of the conjectures about the nearly decomposable 
structure of the nucleus-atom-molecule hierarchy were 
checked against the available quantitative data by Andrew 
Schoene and William Wise. My \vork in this area has 
been supported by a Ford Foundation grant for research 
in organizations and a Carnegie Corporation grant for 
research on cognitive processes. To all of the above, my 
warm thanks, and the usual absolution. 
See especially the yearbooks of the Society for Gen- 
eral Systems Research. Prominent among the exponents 
of general systems theory are L. von Bertalanffy, K. 
Boulding, R. W. Gerard, and J. G. Miller. For a more 
skeptical view-perhaps 
too skeptical in the light of the 
present discussion-see 
H. A. Simon and A. Newell, 
Models : their uses and limitations, in L. D. White, ed., 
The state of the social sciences, 66-83, Chicago, Univ. of 
Chicago Press, 1956. 
2 N. Wiener, Cybernetics, New E'ork, John Wiley & 
Sons, 1948. For an imaginative forerunner, see A. J. 
Lotka, Elelnetits of nzathelnatical Oiolog~~,New York, 
Dover Publications, 1951, first published in 1924 as Ele-
wzents of Physical biology. 
and to analyze adaptiveness in terms of the theory 
of selective inf~rmation.~ The ideas of feedback 
and information provide a frame of reference for 
viewing a wide range of situations, just as do the 
ideas of evolution, of relativism, of axiomatic 
method, and of operationalism. 
In this paper I should like to report on some 
things we have been learning about particular 
kinds of complex systems encountered in the be- 
havioral sciences. The develooments I shall dis- 
cuss arose in the context of specific phenomena, 
but the theoretical formulations themselves make 
little reference to details of structure. 
Instead 
they refer primarily to the complexity of the sys- 
tems under view without specifying the exact 
content of that complexity. 
Because of their 
abstractness, the theories may have relevance-
application would be too strong a term-to 
other 
kinds of complex systems that are observed in 
the social, biological, and physical sciences. 
In recounting these developments, I shall avoid 
technical detail, which can generally be found 
elsewhere. 
I shall describe each theory in the 
particular context in which it arose. Then, I shall 
cite some examples of complex systems, from 
areas of science other than the initial application, 
to which the theoretical framework appears rele- 
vant. In doing so, I shall make reference to areas 
of knowledge where I an1 not expert-perhaps 
not even literate. I feel quite comfortable in doing 
so before the members of this society, representing 
as it does the whole span of the scientific and 
scholarly endeavor. 
Collectively you 11-ill have 
little difficulty, I am sure, in distinguishing in-
stances based on idle fancy or sheer ignorance 
from instances that cast some light oil the ways 
in which complexity exhibits itself wherever it 
is found in nature. I shall leave to you the final 
judgment of relevance in your respective fields. 
I shall not undertake a formal definition of 
C. Shannon and W. Weaver, T h e  rnathematicnl theory 
of commttnicatioti, Urbana, Univ. of Illinois Press, 1949 ; 
W. R. Ashby, Dcsigtz for a brain, Kew York, John Wiley 
& Sons, 1952. 

468 
AMER.
HERBERT A. SIMON 
[PROC. 
PHIL.SOC. 
"complex systems." 
Roughly, by a complex 
system I mean one made up of a large number 
of parts that interact in a nonsimple way. In such 
systems, the whole is more than the sum of the 
parts, not in an ultimate, metaphysical sense, but 
in the important pragmatic sense that, given the 
properties of the parts and the laws of their inter- 
action, it is not a trivial matter to infer the prop- 
erties of the whole. 
In the face of complexity, 
an in-principle reductionist may be at the same 
time a pragmatic h o l i ~ t . ~  
The four sections that follow discuss four as-
pects of complexity. The first offers some com- 
inents on the frequency with which complexity 
takes the form of hierarchy-the 
complex system 
being composed of subsystems that, in turn, have 
their olvn subsystems, and so on. The second 
section theorizes about the relation between the 
structure of a complex system and the time re-
quired for it to emerge through evolutionary proc- 
esses : specifically, it argues that hierarchic systems 
will evolve far more quickly than non-hierarchic 
systems of comparable size. 
The third section 
explores the dynamic properties of hierarchically- 
organized systems, and shows how they can be 
decon~posed into subsystems in order to analyze 
their behavior. The fourth section examines the 
relation between coillplex systems and their de- 
scriptions. 
Thus, the central theme that runs through my 
reinarks is that complexity frequently takes the 
form of hierarchy, and that hierarchic systems 
have some common properties that are independent 
of their specific content. Hierarchy, I shall argue, 
is one of the central structural schemes that the 
architect of complexity uses. 
4 W. TVeaver, in: Science and complexity, .4merican 
Scie~ltist 36: 536, 1948, has distinguished two kinds of 
complexity, disorganized and organized. 
W e  shall be 
primarily concerned with organized complexity. 
5 See also John R. Platt, Properties of large molecules 
that go beyond the properties of their chemical sub-groups, 
Jolrr.. Tllrorrt. Biol. 1. 342-358, 1961. Since the reduc- 
tionism-holism issue is a major cazrse de gzlerre between 
scientists and humanists, perhaps we might even hope 
that peace could be negotiated between the two cultures 
along the lines of the compromise just suggested. As I 
go along, I shall have a little to say about complexity in 
the arts as well as in the natural sciences. I must empha- 
size the pragmatism of my holism to distinguish it sharply 
from the position taken by W. M. Elsasser in T h e  physi- 
cal fo~ct~datiofz 
of hiology, Xew York, Pergamon Press, 
1958. 
HIERARCHIC SYSTEMS 
By a hierarchic system, or hierarchy, I mean 
a system that is composed of interrelated sub-
systems, each of the latter being, in turn, hier-
archic in structure until we reach some lowest 
level of elementary subsystem. In most systems 
in nature, it is somewhat arbitrary as to where 
we leave off the partitioning, and what subsystems 
we take as elementary. Physics makes much use 
of the concept of "elementary particle" although 
particles have a disconcerting tendency not to 
remain elementary very long. 
Only a couple 
of generations ago, the atoms themselves were 
elementary particles; today, to the nuclear physi- 
cist they are complex systems. For certain pur- 
poses of astronomy, whole stars, or even galaxies, 
can be regarded as elementary subsystems. In one 
kind of biological research, a cell may be treated 
as an elementary subsystem; in another, a protein 
molecule; in still another, an amino acid residue. 
Just why a scientist has a right to treat as ele- 
mentary a subsystem that is in fact exceedingly 
complex is one of the questions we shall take up. 
For the moment, we shall accept the fact that 
scientists do this all the time, and that if they are 
careful scientists they usually get away with it. 
Etymologically, the word "hierarchy" has had 
a narrower meaning than I am giving it here. 
The term has generally been used to refer to a 
complex system in which each of the subsystems 
is subordinated by an authority relation to the 
system it belongs to. 
More exactly, in a hier-
archic formal organization, each system consists 
of a "boss" and a set of subordinate subsystems. 
Each of the subsystems has a "boss" who is the 
immediate subordinate of the boss of the system. 
\Ve shall want to consider systems in which the 
relations among subsystems are more complex 
than in the formal organizational hierarchy just 
described. IVe shall want to include systems in 
which there is no relation of subordination among 
subsystems. 
(In fact, even in human organiza- 
tions, the formal hierarchy exists only on paper; 
the real flesh-and-blood organization has many 
inter-part relations other than the lines of formal 
authority.) For lack of a better term, I shall use 
hierarchy in the broader sense introduced in the 
previous paragraphs, to refer to all complex sys- 
tems analyzable into successive sets of subsystems, 
and speak of "formal hierarchy" when I want to 
refer to the more specialized concept6 
6 The mathematical term "partitioning" will not do for 
what I call here a hierarchy; for the set of subsystems, 

VOL.106, KO.6, 19621 
T H E  ARCHITECTURE O F  COMPLEXITY 
469 
SOCIAL SYSTEXS 
tend to reserve the word hierarchy for a system 
I have already given an example of one kind of 
hierarchy that is frequently encountered in the 
social sciences : a formal organization. 
Business 
firins, governments, universities all have a clearly 
visible parts-within-parts structure. 
But formal 
organizations are not the only, or even the most 
cominon, kind of social hierarchy. 
Almost all 
societies have elementary units called families, 
which may be grouped into villages or tribes, and 
these into larger groupings, and so on. If we 
make a chart of social interactions, of who talks 
to whom, the clusters of dense interaction in the 
chart \\-ill identify a rather well-defined hierarchic 
structure. The groupings in this structure may 
be defined operationally by some measure of fre- 
quency of interaction in this sociometric matrix. 
BIOLOGICAL Ah-D PHYSICAL SYSTEhIS 
The hierarchical structure of biological systems 
is a failliliar fact. Taking the cell as the building 
block, we find cells organized into tissues, tissues 
into organs, organs into systems. Moving down- 
ward froill the cell, well-defined subsystems-for 
example, nucleus, cell membrane, microsomes, 
n~itochonclria, and so on-have 
been identified in 
animal cells. 
The hierarchic structure of many physical sys- 
tems is equally clear-cut. I have already men-
tioned the two main series. At the microscoDic 
level we have elementary particles, atoms, mole- 
cules. macromolecules. At the macroscopic level 
we have satellite systems, planetary systems, gal- 
axies. Matter is distributed throughout space in 
a strikingly non-uniform fashion. The most nearly 
random distributions we find, gases, are not ran-
dom distributions of elementary particles but 
random distributions of complex systems, i.e. 
molecules. 
a\  considerable range of structural types is sub- 
sunled under the term hierarchy as I have defined 
it. 
By this definition, a diamond is hierarchic, 
for it is a crystal structure of carbon atoms that 
can l ~ e  
further decon~posed into protons, neutrons, 
antl electrons. However, it is a very "flat" hier-
archy, in which the number of first-order sub-
syst=ms belonging to the crystal can be indefinitely 
large. 
volume of n~olecular gas is a flat hier- 
archy in the same sense. In ordinary usage, we 
and the successive subsets in each of these defines the 
partitioning, independently of any systems of relations 
among the subsets. By hierarchy I mean the partitioning 
in conjunction with the relations that hold among its 
parts. 
that is divided into a small or mdderate numbev 
of subsystems, each of which may be further sub- 
divided. Hence, we do not ordinarily think of or 
refer to a diamond or a gas as a hierarchic struc- 
ture. 
Similarly, a linear polymer is simply a 
chain, which may be very long, of identical sub- 
parts, the monomers. 
At the molecular level it 
is a very flat hierarchy. 
In discussing formal organizations, the number 
of subordinates who report directly to a single boss 
is called his span of co?ztvol. I will speak analo- 
gously of the spa% of a system, by which I shall 
mean the number of subsystems into which it is 
partitioned. 
Thus, a hierarchic system is flat at 
a given level if it has a wide span at that level. 
A diamond has a wide span at the crystal level, 
but not at the next level down, the molecular level. 
I n  most of our theory construction in the fol- 
lowing sections we shall focus our attention on 
hierarchies of moderate span, but from time to 
time I shall comment on the extent to which the 
theories might or might not be expected to apply to 
very flat hierarchies. 
There is one important difference between the 
physical and biological hierarchies, on the one 
hand, and social hierarchies, on the other. Most 
physical and biological hierarchies are described 
in spatial terms. Jj7e detect the organelles in a 
cell in the way we detect the raisins in a cake- 
they are "visibly" differentiated substructures lo- 
calized spatially in the larger structure. O n  the 
other hand, we propose to identify social hier- 
archies not by observing who lives close to whom 
but by observing who interacts with whom. These 
two points of view can be reconciled by defining 
hierarchy in terms of intensity of interaction, but 
observing that in most biological and physical sys- 
tems relatively intense interaction implies rela-
tive spatial propinquity. 
One of the interesting 
characteristics of nerve cells and telephone wires is 
that they permit very specific strong interactions 
at great distances. T o  the extent that interactions 
are channeled through specialized communications 
and transportation systems, spatial propinquity 
becomes less determinative of structure. 
SYMBOLIC SYSTEMS 
One very important class of systems has been 
onlitted from my examples thus far : systems of 
human synlbolic production. 
A book is a hier-
archy in the sense in which I am using that term. 
It is generally divided into chapters, the chapters 

470 
HERBERT A. SIMON  
[PKOC. AMEK. PHIL. SOC. 
into sections, the sections into paragraphs, the 
paragraphs into sentences, the sentences into 
clauses and phrases, the clauses and phrases into 
words. Jj7e may take the words as our elementary 
units, or further subdivide them, as the linguist 
often does, into smaller units. If the book is nar- 
rative in character, it may divide into "episodes" 
instead of sections, but divisions there will be. 
The hierarchic structure of music, based on such 
units as movements, parts, themes, phrases, is well 
known. The hierarchic structure of products of 
the pictorial arts is more difficult to characterize, 
but I shall have something to say about it later. 
T H E  EVOLGTIOX O F  COMPLEX SYSTEMS 
Let me introduce the topic of evolution with a 
parable. 
There once were two watchmakers, 
named Hora and Tempus, who manufactured very 
fine watches. Both of them were highly regarded, 
and the phones in their workshops rang frequently 
-new 
customers were constantly calling them. 
However, Hora prospered, while Tempus became 
poorer and poorer and finally lost his shop. JVhat 
was the reason? 
The watches the men made consisted of about 
1,000 parts each. Tempus had so constructed his 
that if he had one partly assembled and had to put 
it down-to 
answer the phone say-it 
immediately 
fell to pieces and had to be reassembled from the 
elements. 
The better the customers liked his 
watches, the more they phoned him, the more diffi- 
cult it became for him to find enough uninterrupted 
time to finish a watch. 
The watches that Hora made were no less com- 
plex than those of Tempus. But he had designed 
them so that he could put together subassemblies 
of about ten elements each. Ten of these subas- 
semblies, again, could be put together into a larger 
subassembly; and a system of ten of the latter sub- 
assemblies constituted the whole watch. 
Hence, 
when Hora had to put down a partly assembled 
watch in order to answer the phone, he lost only a 
small uart of his work, and he assembled his 
watches in only a fraction of the man-hours it 
took Tempus. 
It is rather easy to make a quantitative analysis 
of the relative difficulty of the tasks of Tempus 
and Hora: Suppose the probability that an inter- 
ruption will occur while a part is being added to 
an incomplete assembly is p. Then the probabil- 
ity that Tempus can complete a watch he has 
started without interruption is (l-pjlOoO-a very 
small number unless p is .001 or less. Each in- 
terruption will cost, on the average, the time to as- 
semble l/p parts (the expected number asselllhlecl 
before interruption). On the other hand, Hora 
has to complete one hundred eleven sub-assemblies 
of ten parts each. The probability that he will not 
be interrupted while completing i n y  one ot' these 
is (1-p)lO, and each interruption will cost only 
ahout the time required to assemble five parts.' 
Now if p is about .Ol-that 
is, there is one 
chance in a hundred that either watchmaker will 
he interrupted while adding any one part to an as- 
sembly-then 
a straightforward calculation shows 
that it will take Tempus, on the average, about 
four thousand times as long to assemble a watch 
as Hora. 
ll'e arrive at the estimate as follows : 
1.  Hora must make 111 times as many complete 
assemblies per watch as Tempus; but. 
2.  Tempus will lose on the average 20 times as 
much work for each interrupted assembly as 
Hora [lo0 parts, on the average, as against 5 1 ; 
and, 
Tempus will complete an assembly only 44 
times 
per 
million 
attempts 
(.99'(""' = 44 
x 
while Hora will complete nine out of 
ten (.991° = 9 x lo-'). 
Hence Tempus will 
have to make 20,000 as many attempts per 
completed assembly as Hora. ( 9  x lo-' ) '(44 
x 
= 2x lo4. 
~~ultiplyingthese three 
ratios, we get : 
1 , ' l l l  x 100/5 x .9910j.991000 
= 1/11 1 x 20 X 20,000 -- 4,000. 
7 The speculations on speed of evolution Lvere first sug- 
gested by H .  Jacobson's application of information theory 
to estimating the time required for biological evolution. 
See his paper, Information, reproduction, and the origin 
of life, in Americatz Scietztist 43: 119-127, January, 1955. 
From thermodynamic considerations it is possible to esti- 
mate the amount of increase in entropy that occurs when 
a complex system decomposes into its elements. 
t See, 
for example, R. B. Setlow and E. C. Pollard, Jlolcc~tlnr 
biophysics, 63-65, Reading, llass., Addison-LVesley Puh-
lishing Co., 1962, and references cited there.) But entropy 
is the logarithm of a probability, hence information, the 
negative of entropy, can be interpreted as the logarithm 
of the reciprocal of the probability-the 
"improbability," 
so to speak. The essential idea in Jacobson's model is 
that the expected time required for the system to reach 
a particular state is inversely proportional to the proha- 
bility of the state-hence 
increases exponentially with the 
amount of information (negentropy) of the state. 
Following this line of argument, but not introducing 
the notion of levels and stable subassemblies, Jacohson 
arrived at estimates of the time required for evolution so 
large as to make the event rather improbable. Our analy- 
sis, carried through in the same way, but with attention 
to  the stable intermediate forms, produces very much 
smaller estimates. 

VOL. 106, SO. 6 ,  19621 
THE ARCHITECTURE OF COMPLEXITY 
471 
BIOLOGICAL EVOLUTION 
What lessons can we draw from our parable 
for biological evolution? Let us interpret a par- 
tially completed subassembly of k elementary parts 
as the coexistence of k parts in a small volume- 
ignoring their relative orientations. 
The model 
assumes that parts are entering the volume at a 
constant rate,-but that there is a constant prob-
ability, p, that the part will be dispersed before 
another is added, unless the assembly reaches a 
stable state. These assumptions are not particu- 
larly realistic. 
They undoubtedly underestimate 
the decrease in probability of achieving the assem- 
bly with increase in the size of the assembly. 
Hence the assumptions understate-probably 
by a 
large factor-the 
relative advantage of a hier-
archic structure. 
Although we cannot, therefore, take the nu-
merical estimate seriously the lesson for biological 
evolution is quite clear and direct. The time re-
quired for the evolution of a complex form from 
simple elements depends critically bn the numbers 
and distribution of potential intermediate stable 
forms. In particular, if there exists a hierarchy 
of potential stable "subassenlblies," with about the 
same span, s, at each level of the hierarchy, then 
the time required for a subassemblv can be ex-
pected to be about the same at each level-that 
is 
proportional to l/(l-p)s. The time required for 
the assembly of a system of n elements will be 
proportional to logs n, that is, to the number of 
levels in the system. One would say-with 
more 
illustrative than literal intent-tllat 
the time re-
quired for the evolution of multi-celled organisms 
from single-celled organisms might be of the same 
order of magnitude as the time required for the 
evolution of single-celled organisms from macro-
molecules. The same argument could be applied 
to the evolution of proteins from amino acids, of 
molecules from atoms, of atoms from elementary 
particles. 
A whole host of objections to this oversimplified 
scheme will occur, I am sure, to every working 
biologist, chemist, and physicist. Before turning 
to matters I know more about, I shall mention 
three of these problems, leaving the rest to the 
attention of the specialists. 
First, in spite of the overtones of the watch- 
maker parable, the theory assumes no teleological 
n~echanisnl. The complex forms can arise from 
the simple ones by purely random processes. ( I  
shall propose another model in a moment that 
shows this clearly.) Direction is provided to the 
scheme by the stability of the complex forms, once 
these come into existence. 
But this is nothing 
more than survival of the fittest-i.e., 
of the stable. 
Second, not all large systems appear hierarchi- 
cal. For example, most polymers-e.g., 
nylon-
are simply linear chains of large numbers of 
identical components, the monomers. 
However, 
for present purposes we can simply regard such a 
structure as a hierarchv with a sDan of one-the 
limiting case. For a chain of any length repre- 
sents a state of relative equilibri~m.~ 
Third, the evolution of complex systems from 
simple elements implies nothing, one- way or the 
other, about the change in entropy of the entire 
system. If the process absorbs free energy, the 
complex system will have a smaller entropy than 
the elements; if it releases free energy, the oppo- 
site will be true. The former alternative is the 
one that holds for most biological systems, and 
the net inflow of free energy has to be supplied 
from the sun or some other source if the second 
law of thermodynamics is not to be violated. For 
the evolutionary process we are describing, the 
equilibria of the intermediate states need have only 
local and not global stability, and they may be 
stable only in the steady state-that 
is, as long as 
there is an external source of free energy that may 
be drawn u ~ o n . @  
Because organisms are not energetically closed 
systems, there is no way to deduce the direction, 
much less the rate, of evolution from classical 
thermodynamic considerations. All estimates in- 
dicate that the amount of entropy, measured in 
physical units, involved in the formation of a one- 
celled biological organism is trivially small-about 
-10-l1 cal/degree.1° The "improbability" of evo-
lution has nothing to do with this quantity of 
entropy, which is produced by every bacterial cell 
every generation. The irrelevance of quantity of 
8 There is a well-developed theory of polymer size, 
based on models of random assembly. See for example 
P. J. Flory, Principles of polymer chemistuy, ch. 8, 
Ithaca, Cornell Univ. Press, 1953. Since all subassem-
blies in the polymerization theory are stable, limitation 
of molecular growth depends on "poisoning" of terminal 
groups by impurities or formation of cycles rather than 
upon disruption of partially-formed chains. 
@This point has been made many times before, but it 
cannot be emphasized too strongly. For further discus- 
sion, see Setlow and Pollard, op. cit., 49-64; E. Schro-
dinger, W h a t  is life? Cambridge Univ. Press, 1945; and 
H. Linschitz, The information content of a bacterial cell, 
in H. Questler, ed., Infoutnation theory in biology, 251-
262, Urbana, Univ. of Illinois Press, 1953. 
1 0  See Linschitz, op. czt. 
This quantity, 10-11 cal/de-
gree, corresponds to obout 1013 bits of information. 

- 
- 
472 
HERBERT A. SIMON 
[PROC.AMER. PHIL. SOC. 
information, in this sense, to speed of evolution 
can also be seen from the fact that exactly as much 
information is required to "copy" a cell through 
the reproductive process as to produce the first cell 
through evolution. 
The effect of the existence of stable intermediate 
forms exercises a powerful effect on the evolution 
of complex forms that may be likened to the dra- 
matic effect of catalysts upon reaction rates and 
steady state distribution of reaction products in 
open systems.ll In neither case does the entropy 
change provide us with a guide to system behavior. 
PROBLEM SOLVIXG AS NATURAL SELECTION 
Let us turn now to some phenomena that have 
no obvious connectioil with biological evolution: 
human problem-solving processes. 
Consider, for 
example, the task of discovering the proof for a 
difficult theorem. The process can be-and 
often 
has been-described 
as -a search through a maze. 
Starting with the axioms and previously proved 
theorems, various transformations allowed by the 
rules of the mathematical systems are attempted, 
to obtain new expressions. These are modified in 
turn until, with persistence and good fortune, a 
sequence or path of transforn~ations is discovered 
that leads to the goal. 
The process usually involves a great deal of trial 
and error. 
Various paths are tried; some are 
abandoned, others are pushed further. Before a 
solution is found, a great many paths of the maze 
may be explored. The more difficult and novel 
the problem, the greater is likely to be the amount 
of trial and error required to find a solution. At 
the same time, the trial and error is not com-
pletely random or blind ; it is, in fact, rather highly 
selective. The new expressions that are obtained 
by transforming given ones are examined to see 
whether they represent progress toward the goal. 
Indications of progress spur further search in the 
same direction; lack of 
progress signals the 
abandonment of a line of search. Problem solving 
requires selective trial and error.'? 
11See H. Kacser, Some physico-chemical aspects of 
biological organization, Appendix, pp. 191-249 in C. H. 
Waddington, T h e  strategy of the getzes, London, George 
Allen & Unwin, 1957. 
See A. Newell, J. C. Shaw, and H. A. Simon, 
Empirical explorations of the logic theory machine, Pro-
ceedings of the 1957 Western Joint Cotnputer Colzferetzce, 
February, 1957, New York: Institute of Radio Engi-
neers; Chess-playing programs and the problem of com-
plexity, IBM Journal of Research and Developmetzt 2: 
320-335, October, 1958; and for a similar view of prob- 
lem solving, W. R. Ashby, Design for an intelligence 
A little reflection reveals that cues signaling 
progress play the same role in the problem-solving 
process that stable intermediate forms play in the 
biological evolutionary process. 
In fact, we can 
take over the watchmaker parable and apply it 
also to problem solving. 
In problem solving, a 
partial result that represents recognizable progress 
toward the goal plays the role of a stable sub- 
assembly. 
Suppose that the task is to open a safe whose 
lock has ten dials, each with one hundred possible 
settings, numbered from 0 to 99. How long will 
it take to open the safe by a blind trial-and-error 
search for the correct setting? Since there are 
10010 possible settings, we may expect to esamine 
about one-half of these, on the average, before 
finding the correct one-that 
is, fifty billion billion 
settings. Suppose, however, that the safe is de- 
fective, so that a click can be heard when any one 
dial is turned to the correct setting. Now each 
dial can be adjusted independently, and does not 
need to be touched again while the others are being 
set. The total number of settings that has to he 
tried is only 10 X 50, or five hundred. The task 
of opening the safe has been altered, by the cues 
the clicks provide, from a practically impossible 
one to a trivial one.13 
A considerable amount has been learned in the 
past five years about the nature of the mazes that 
represent common human problem-solving tasks- 
proving theorems, solving puzzles, playing chess, 
making investments, balancing assembly lines, to 
mention a few. 
All that we have learned about 
these mazes points to the same conclusioi~ : that 
human problem solving, from the most blundering 
to the most insightful, involves nothing more than 
varying mixtures of trial and error and selectivity. 
The selectivity derives from various rules of 
amplifier, 215-233 in C. E. Shannon and J. LlcCarthy, 
Automata studies, Princeton, Princeton Univ. Press, 
1956. 
13The clicking safe example was supplied by D. P. 
Simon. Ashby, op. cit., 230, has called the selectivity 
involved in situations of this kind "selection by compo- 
nents." 
The even greater reduction in time produced by 
hierarchization in the clicking safe example, as compared 
with the watchmaker's metaphor, is due to the fact that 
a random search for the correct combination is involved 
in the former case, while in the latter the parts come to- 
gether in the right order. It is not clear which of these 
metaphors provides the better model for biological evo-
lution, but we may be sure that the watchmaker's meta-
phor gives an exceedingly conservative estimate ot' the 
savings due to hierarchization. 
The safe may give ar. 
excessively high estimate because it assumes all possible 
arrangements of the elements to be equally probable. 

VOI,. 106, NO. 6 ,  19621 
T H E  ARCHITECTURE O F  COMP1,EXITY 
473 
thumb, or heuristics, that suggest which paths 
should be tried first and which leads are promising. 
We do not need to postulate processes more 
sophisticated than those involved in organic evo-
lution to explain how enormous problem mazes 
are cut down to quite reasonable size.14 
T H E  SOURCES OF SELECTIVITY 
When we examine the sources from which the 
problem-solving system, or the evolving system, 
as the case may be, derives its selectivity, we dis- 
cover that selectivity can always be equated with 
some kind of feedback of information from the 
environment. 
Let us consider the case of problem solving first. 
There are two basic kinds of selectivity. One we 
have already noted: various paths are tried out, 
the consequences of following them are noted, and 
this information is used to guide further search. 
In the same way, in organic evolution, various 
complexes come into being, at least evanescently, 
and those that are stable provide new building 
blocks for further construction. 
It is this infor- 
mation about stable configurations, and not free 
energy or negentropy from the sun, that guides 
the process of evolution and provides the selectivity 
that is essential to account for its rapidity. 
The second source of selectivity in problem 
solving is previous experience. We see this par- 
ticularly clearly when the problem to be solved is 
similar to one that has been solved before. Then, 
by sin~ply trying again the paths that led to the 
earlier solution, or their analogues, trial-and-error 
search is greatly reduced or altogether eliminated. 
What corresponds to this latter kind of informa- 
tion in organic evolution? The closest analogue 
is reproduction. Once we reach the level of self- 
reproducing systems, a complex system, when it 
has once been achieved, can be multiplied indefi- 
nitely. Reproduction in fact allows the inheritance 
of acquired characteristics, but at the level of 
genetic material, of course; i.e., only characteristics 
acquired by the genes can be inherited. We shall 
return to the topic of reproduction in the final 
section of this paper. 
ON EMPIRES AND EMPIRE-BUILDING 
We have not exhausted the categories of com-
plex systems to which the watchmaker argument 
can reasonably be applied. Philip assembled his 
l4A. Newell and H. A. Simon, Computer simulation 
of human thinking, Science 134: 2011-2017, December 22, 
1961. 
Macedonian empire and gave it to his son, to be 
later combined with the Persian subassembly and 
others into Alexander's greater system. On Alex- 
ander's death, his empire did not crumble to dust, 
but fragmented into some of the major subsystems 
that had composed it. 
The watchmaker argument implies that if one 
would be Alexander, one should be born into a 
world where large stable political systems already 
exist. Where this condition was not fulfilled, as 
on the Scythian and Indian frontiers, Alexander 
found empire building a slippery business. 
So 
too, T. E. Lawrence's organizing of the Arabian 
revolt against the Turks was limited by the charac- 
ter of his largest stable building blocks, the sepa- 
rate, suspicious desert tribes. 
The profession of history places a greater value 
upon the validated particular fact than upon ten- 
dentious generalization. I shall not elaborate upon 
my fancy, therefore, but will leave it to historians 
to decide whether anything can be learned for the 
interpretation of history from an abstract theory 
of hierarchic complex systems. 
CONCLUSION : T H E  EVOLUTIONARY EXPLAKATIOX 
OF HIERARCHY 
We have shown thus far that complex systems 
will evolve from simple systems much more rapidly 
if there are stable intermediate forms than if there 
are not. The resulting complex forms in the for- 
mer case will be hierarchic. We have only to turn 
the argument around to explain the observed pre- 
dominance of hierarchies among the complex sys- 
tems nature presents to us. 
Among possible 
complex forms, hierarchies are the ones that have 
the time to evolve. The hypothesis that complex- 
ity will be hierarchic makes no distinction among 
very flat hierarchies, like crystals, and tissues, and 
polymers, and the intermediate forms. Indeed, in 
the complex systems we encounter in nature, ex- 
amples of both forms are prominent. 
A more 
complete theory than the one we have developed 
here would presumably have something to say 
about the determinants of width of span in these 
systems. 
NEARLY DECOMPOSABLE SYSTEMS 
In hierarchic systems, we can distinguish be-
tween the interactions among subsystems, on the 
one hand, and the interactions within subsystems 
-i.e., 
among the parts of those s u b s y s t e m s ~ n  
the other. The interactions at the different levels 
may be, and often will be, of different orders of 

- - 
HERBERT A. SIMON  
FIG. 1. A hypothetical nearly-decomposable system. In 
terms of the heat-exchange example of the text, Al, 
X2, and A3 may be interpreted as cubicles in one 
room, B1 and B2 as cubicles in a second room, and C1, 
C2, and C3 as cubicles in a third. The matrix en- 
tries then are the heat diffusion coefficients between 
cubicles. 
magnitude. In a formal organization there will 
generally be more interaction, on the average, be- 
tween two employees who are members of the 
same department than between two employees 
from different departments. 
In organic sub-
stances, intermolecular forces will generally be 
weaker than molecular forces, and molecular forces 
than nuclear forces. 
In a rare gas, the intermolecular forces will be 
negligible compared to those binding the molecules 
-we 
can treat the individual particles, for many 
purposes, as if they were independent of each 
other. \Ye can describe such a system as decoi~z-
posable into the subsystems comprised of the indi- 
vidual particles. As the gas becomes denser, mo- 
lecular interactions become more significant. But 
over some range, we can treat the decomposable 
case as a limit, and as a first approximation. W e  
can use a theory of perfect gases. for example, to 
describe approxin~ately the behavior of actual 
gases if they are not too dense. As a second ap- 
proximation, we may move to a theory of nearly 
decomposable systems, in which the interactions 
among the subsystems are weak, but not negligible. 
At least some kinds of hierarchic systems can be 
approximated successfully as nearly decomposable 
systems. The main theoretical findings from the 
approach can be summed up in two propositions: 
( a )  in a nearly decomposable system, the short- 
run behavior of each of the component subsystems 
is approximately independent of the short-run be- 
havior of the other components; (b) in the long 
run, the behavior of any one of the components 
depends in only an aggregate way on the behavior 
of the other components. 
Let me provide a very concrete simple example 
of a nearly decomposable system.15 Consider a 
building whose outside walls provide perfect 
thermal insulation from the environment. 
W e  
shall take these walls as the boundary of our sys- 
tem. The building is divided into a large number 
of rooms, the walls between them being good, but 
not perfect, insulators. The walls between rooms 
are the boundaries of our major subsystems. Each 
room is divided by partitions into a number of 
cubicles, but the partitions are poor insulators. 
A thermometer hangs in each cubicle. 
Suppose 
that at the time of our first observation of the sys- 
tem there is a wide variation in temperature from 
cubicle to cubicle and from room to room-the 
various cubicles within the building are in a state 
of thermal disequilibrium. When we take new 
temperature readings several hours later, what 
shall we find? There will be very little variation 
in temperature among the cubicles within each 
single room, but there may still be large tempera- 
ture variations awzottg rooms. 
When we take 
readings again several days later, we find an al-
iliost uniform temperature throughout the build- 
ing; the temperature differences among rooms 
have virtually disappeared. 
W e  can describe the process of equilibration 
forillally by setting up the usual equations of heat 
flow. The equations can be represented by the 
matrix of their coefficients, rij, where rij is the rate 
at which heat flows from the ith cubicle to the jth 
cubicle per degree difference in their temperatures. 
If cubicles i and j do not have a common wall, 
rig will be zero. If cubicles i and i have a common 
wall, and are in the same room, ri, will be large. 
If cubicles i and j are separated by the wall of a 
l5 This discussion of 
near-decomposability is based 
upon H. -4.Simon and .A. .Ando, .Aggregation of variables 
in dynamic systems, Econovzetrica 29: 111-138, April, 
1961. The example is drawn from the same source, 
117-118. 
The theory has been further developed and 
applied to a variety of economic and political phenomena 
by Ando and F. M. Fisher. See F. M. Fisher, On the 
cost of approximate specification in simultaneous equation 
estimation, Economctrica 29: 139-170, .April, 1961, and 
F. hi. Fisher and A. Ando, TWO theorems on Ceteris 
Paribus in the analysis of dynamic systems, American 
Political Sciettce Revie.rc1 61 : 103-113, March, 1962. 

VOL.lob, SO. 6, 19621 
THE ARCHITECTURE OF COMPLEXITY 
475 
room, vij will be nonzero but small. Hence, by 
grouping all the cubicles together that are in the 
same room, we can arrange the matrix of coeffi- 
cients so that all its l a r ~ k  elements lie inside a
" 
string of square submatrices along the main di- 
agonal. All the elements outside these diagonal 
squares will be either zero or small (see figure 1). 
W e  may take some small number, E ,  as the upper 
bound of the extradiagonal elements. W e  shall 
call a matrix having these properties a nearly 
decot~zposablewzatrix. 
Now it has been proved that a dynamic system 
that can be described by a nearly decomposable 
matrix has the properties, stated above, of 
nearly 
decomposable system. In our simple example of 
heat flow this means that in the short run each 
room will reach an equilibrium temperature (an 
average of the initial temperatures of its offices) 
nearly independently of the others; and that each 
room will remain approximately in a state of equi- 
librium over the longer period during which an 
over-all temperature equilibrium is being estab-
lished throughout the building. After the intra- 
room short-run ecluilibria have been reached, a 
single thermometer in each room will be adequate 
to describe the dynamic behavior of the entire 
system-separate 
thermometers in each cubicle will 
be superfluous. 
XEAR DECOMPOSABILITY O F  SOCIAL SYSTEMS 
As a glance at figure 1 shows, near decomposa- 
bility is a rather strong property for a matrix to 
possess, and the matrices that have this property 
will describe very special dynamic systems-van- 
ishingly few systems out of all those that are 
thinkable. 
How few they will be depends, of 
course, on how good an approximation we insist 
up011. If we demand that epsilon be very small, 
correspondingly few dynamic systems will fit the 
definition. But we have already seen that in the 
natural world nearly decomposable systems are 
far from rare. On the contrary, systems in which 
each variable is linked with almost equal strength 
with almost all other parts of the system are far 
rarer and less typical. 
In economic dynamics, the main variables are 
the prices and quantities of commodities. It is 
empirically true that the price of any given com- 
modity and the rate at which it is exchanged de- 
pend to a significant extent only on the prices and 
quantities of a few other commodities, together 
with a few other aggregate magnitudes, like the 
average price level or some over-all measure of 
economic activity. The large linkage coefficients 
are associated, in general, with the main flows of 
raw materials and semi-finished products within 
and between industries. An input-output matrix 
of the economy, giving the magnitudes of these 
flows, reveals the nearly decomposable structure 
of the system-with 
one qualification. There is a 
consumption subsystem of the economy that is 
linked strongly to variables in most of the other 
subsystems. Hence, we have to modify our no-
tions of decomposability slightly to accommodate 
the special role of the consumption subsystem in 
our analysis of the dynamic behavior of the 
economy. 
In the dynamics of social systems, where mem- 
bers of a system communicate with and influence 
other members, near decomposability is generally 
very prominent. This is most obvious in formal 
organizations, where the formal authority rela-
tion connects each member of the organization 
with one immediate superior and with a small 
number of subordinates. Of course many com-
munications in organizations follow other channels 
than the lines of formal authoritv. But most of 
these channels lead from any particular individual 
to a very limited number of his superiors, sub- 
ordinates, and associates. 
Hence, departmental 
boundaries play very much the same role as the 
walls in our heat example. 
PHYSICO-CHEMICAL SYSTEMS 
In the complex systems familiar in biological 
chemistry, a similar structure is clearly visible. 
Take the atomic nuclei in such a system as the 
elementary parts of the system, and construct a 
matrix of bond strengths between elements. There 
will be matrix elements of quite different orders 
of magnitude. 
The largest will generally corre-
spond to the covalent bonds, the next to the ionic 
bonds, the third group to hydrogen bonds, still 
smaller linkages to van der Waals forces.16 If we 
select an epsilon just a little smaller than the mag- 
nitude of a covalent bond, the system will de-
compose into subsystems-the 
constituent mole- 
cules. The smaller linkages will correspond to the 
intermolecular bonds. 
It is well known that high-energy, high-fre- 
l6For a survey of the several classes of molecular and 
inter-molecular forces, and their dissociation energies 
see Setlow and Pollard, op. cit., chapter 6. The energies 
of typical covalent bonds are of the order of 80-100 k 
cal/mole, of the hydrogen bonds, 10 k cal/mole. 
Ionic 
bonds generally lie between these two levels, the bonds 
due to van der Waals forces are lower in energy. 

476 
HERBERT A. SIMON 
[PROC. 
PHIL.
AMER. 
SOC. 
quency vibrations are associated with the smaller 
physical 
subsystems, low-frequency 
vibrations 
with the larger systems into which the subsystems 
are assembled. 
For exam~le, the radiation fre- 
. . 
quencies associated with molecular vibrations are 
much lower than those associated with the vibra- 
tions of the planetary electrons of the atoms; the 
latter, in turn, are lower than those associated with 
nuclear processes.17 Molecular systems are nearly 
deconiposable systems, the short-run dynamics 
relating to the internal structures of the subsys- 
tems ; the long-run dynamics to the interactions of 
these subsystems. 
A number of the important approximations em- 
ployed in physics depend for their validity on the 
near-decomposability of the systems studied. The 
theory of the thermodynamics of irreversible proc- 
esses, for example, requires the assumption of 
macroscopic disequilibriun~ but microscopic equi- 
librium.ls exactli the situation described in our 
heat-exchange example. 
Similarly computations 
in quantum mechanics are often handled by treat- 
ing weak interactions as producing perturbations 
on a system of strong interactions. 
SOAIE OBSER\'ATIOh-S ON HIERARCHIC SPAN 
T o  understand why the span of hierarchies is 
sometimes very broad-as 
in crystals-sometimes 
narrow. we need to examine more detail of the in- 
teractions. 
In general, the critical consideration 
-
is the extent to which interaction between two (or 
a few) subsystems excludes interaction of these 
subsystems with the others. Let us examine first 
some physical examples. 
Consider a gas of identical molecules, each of 
which can form covalent bonds, in certain ways, 
with others. Let us suppose that we can associate 
with each atom a specific number of bonds that 
it is capable of maintaining simultaneously. (This 
number is obviously related to the number we usu- 
ally call its valence.) S o w  suppose that two atoms 
join, and that we can also associate with the com- 
bination a specific number of external bonds it is 
capable of maintaining. If this number is the same 
17Typical wave numbers for vibrations associated with 
various systems (the wave number is the reciprocal of 
wave length hence proportional to frequency) : 
steel wire under tensi~n-lO-~~ 
to lo-' cm-I 
molecular rotations-lo0 
to lo2 cm-l 
molecular vibrations-10' 
to lo3 cm-' 
planetary electrons-lo4 
to 10' cm-I 
nuclear rotations-10' 
to 1010 cm-I 
nuclear surface vibrations-1011 
to 1012 cm-l. 
1s S. R. de Groot, Thermodynanzics of irreversible proc- 
esses, 11-12, Xew York, Interscience Publishers, 1951. 
as the number associated with the individual atoms, 
the bonding process can go on indefinitely-the 
atoms can form crystals or polymers of indefinite 
extent. 
If the number of bonds of which the 
composite is capable is less than the number as-
sociated with each of the parts, then the process 
of agglomeration must come to a halt. 
We need only mention some elementary es-
amples. Ordinary gases show no tendency to ag- 
glomerate because the multiple bonding of atoms 
"uses up" their capacity to interact. While each 
oxygen atom has a valence of two, the O1 niole-
cules have a zero valence. Contrariwise, indefinite 
chains of single-bonded carbon atoms can be built 
up because a chain of any number of such atoms, 
each with two side groups, has a valence of es-
actly two. 
Now what happens if we have a systetii of ele- 
ments that possess both strong and weak inter- 
action capacities, and whose strong bonds are ex- 
haustible through combination? Subsystems will 
form, until all the capacity for strong interaction 
is utilized in their construction. Then these sub- 
systems will be linked by the weaker second-order 
bonds into larger systems. For example. a water 
molecule has essentially a valence of zero-all 
the 
potential covalent bonds are fully occupietl by the 
interaction of hydrogen and oxygen molecules. 
But the geometry of the molecule creates an elec- 
tric dipole that permits weak interaction between 
the water and salts dissolved in it-whence 
such 
phenomena as its electrolytic conductivity.'" 
Similarly, it has been observed that, although 
electrical forces are much stronger than gravita- 
tional forces, the latter are far more important 
than the former for systems on an astronomical 
scale. The explanation, of course, is that the elec- 
trical forces, being bipolar, are all "used up" in the 
linkages of the smaller subsystems, and that sig- 
nificant net balances of positive or negative charges 
are not generally found in regions of macroscopic 
size. 
In social as in physical systems there are gen- 
erally limits on the simultaneous interaction of 
large numbers of subsystems. In the social case, 
these limits are related to the fact that a human 
being is more nearly a serial than a parallel in- 
formation-processing system. 
H e  can carry on 
only one conversation at a time, and although this 
does not limit the size of the audience to which a 
mass communication can be addressed, it does 
1 9  See, for example, L. Pauling, General ch~inistry, 
ch. 15. 

VOL.106, NO. 6 ,  19621 
T H E  ARCHITECTURE OF COMPLEXITY 
limit the number of people simultaneously involved 
in most other forms of social interaction, Apart 
from requirements of direct interaction, most roles 
impose tasks and responsibilities that are time con- 
suming. One cannot, for example, enact the role 
of "friend" with large numbers of other people. 
It is probably true that in social as in physical 
systems, the higher frequency dynamics are associ- 
ated with the subsystems, the lower frequency dy- 
namics with the larger systems. It is generally 
believed, for example, that the relevant planning 
horizon of executives is longer the higher their 
location in the organizational hierarchy. 
It is 
probably also true that both the average duration 
of an interaction between executives and the aver- 
age interval between interactions is greater at 
higher than at lower levels. 
SUMMARY : NEAR DECOXPOSABILITY 
We have seen that hierarchies have the property 
of near-decomposability. 
Intra-component linlz-
ages are generally stronger than intercomponent 
linkages. This fact has the effect of separating 
the high-frequency dynamics of a hierarchy-in-
volving the internal structure of the components- 
from the low frequency dynamics-involving 
inter-
action among components. We shall turn next 
to some important consequences of this separation 
for the description and comprehension of complex 
systems. 
T H E  DESCRIPTIOS O F  COMPLEXITY 
If you ask a person to draw a complex object- 
e.g., a human face-he 
will almost always proceed 
in a hierarchic fashion.*O First he will outline 
the face. Then he will add or insert features: 
eyes, nose, mouth, ears, hair. If asked to elabo- 
rate, he will begin to develop details for each of 
the features-pupils, 
eyelids, lashes for the eyes, 
and so on-until 
he reaches the limits of his ana- 
tomical knowledge. 
His information about the 
object is arranged hierarchicly in memory, like 
a topical outline. 
When information is put in outline form, it is 
easy to include information about the relations 
among the major parts and information about the 
internal relations of parts in each of the subout- 
lines. Detailed information about the relations of 
subparts belonging to different parts has no place 
George ,4. Miller has collected protocols from sub- 
jects who were given the task of drawing faces, and finds 
that they behave in the manner described here (private 
communication). 
See also E. H. Gombrich, Art and 
illzrsion, 291-296, New York, Pantheon Books, 1960. 
in the outline and is likely to be lost. The loss of 
such information and the preservation mainly of 
information about hierarchic order is a salient 
characteristic that distinguishes the drawings of a 
child or someone untrained in representation from 
the drawing of a trained artist. ( I  am speaking of 
an artist who is striving for representation. ) 
NEAR DECOMPOSABILITY AND COXPREHENSIBILITY 
From our discussion of the dynamic properties 
of nearly decomposable systems, we have seen that 
comparatively little information is lost by repre- 
senting them as hierarchies. 
Subparts belonging 
to different parts only interact in an aggregative 
fashion-the 
detail of their interaction can be ig- 
nored. 
In studying the interaction of two large 
molecules, generally we do not need to consider 
in detail the interactions of nuclei of the atoms 
belonging to the one molecule with the nuclei of 
the atoms belonging to the other. In studying the 
interaction of two nations, we do not need to study 
in detail the interactions of each citizen of the 
first with each citizen of the second. 
The fact, then, that many complex systems 
have a nearly decomposable, hierarchic structure 
is a major facilitating factor enabling us to under- 
stand, to describe, and even to "see" such systems 
and their parts. 
O r  perhaps the proposition 
should be put the other way round. If there are 
important systems in the world that are complex 
without being hierarchic, they may to a consider- 
able extent escape our observation and our under- 
standing. Analysis of their behavior would in-
volve such detailed knowledge and calculation of 
the interactions of their elementary parts that it 
would be beyond our capacities of memory or 
c o m p u t a t i ~ n . ~ ~  
2 1  I believe the fallacy in the central thesis of W. hf. 
Elsasser's T h e  physical foundation of biology, mentioned 
earlier, lies in his ignoring the simplification in description 
of complex systems that derives from their hierarchic 
structure. 
Thus (p. 155) : "If we now apply similar 
arguments to the coupling of enzymatic reactions with 
the substratum of protein molecules, we see that over a 
sufficient period of time, the information corresponding to 
the structural details of these molecules will be commu-
nicated to the dynamics of the cell, to higher levels of 
organization as it were, and may influence such dynamics. 
While this reasoning is only qualitative, it lends credence 
to the assumption that in the living organism, unlike the 
inorganic crystal, the effects of microscopic structure can- 
not be simply averaged out; as time goes on this influ- 
ence will pervade the behavior of the cell 'at all levels.' " 
But from our discussion of near-decomposability it 
would appear that those aspects of microstructure that 
control the slow developmental aspects of organismic 

478 
HERBERT A. SIMOK 
[PROC. AMER.
PHIL.SOC. 
I shall not try to settle which is chicken and 
which is egg: whether we are able to understand 
the world because it is hierarchic, or whether it 
appears hierarchic because those aspects of it 
which are not elude our understanding and ob- 
servation. I have already given some reasons for 
supposing that the former is at least half the 
truth-that 
evolving complexity would tend to be 
hierarchic-but 
it may not be the whole truth. 
SIMPLE DESCRIPTIONS O F  COMPLEX SYSTEMS 
One might suppose that the description of a 
complex system would itself be a complex struc- 
ture of symbols-and 
indeed, it may be just that. 
But there is no conservation law that requires 
that the description be as cumbersome as the ob- 
ject described. A trivial example will show how 
a system can be described economically. Suppose 
the systenl is a two-dimensional array like this : 
A B M.1-RS H I  
C D O P T C ' J K  
M S A B H I  R S  
O P C D J K T C '  
R S H I  A B M S  
T C J  K C D O P  
H I  R S  M . l T A B  
J K T I W O P C D  
*WN 
Let us call the array 
a ,  the array 
I A B
1 
/ op 1 m,
CD  
the arrajr 
r, and the array 
h. Let us 
am w,and the array 
Then 
8 
8 
the entire array is simply 
I w x '  
. While the
I xw I 
original structure consisted of 64 symbols, it re- 
quires only 35 to write down its description: 
Live achieve the abbreviation by making use of 
the redundancy in the original structure. Since 
dynamics can be separated out from the aspects that con-
trol the more rapid cellular metabolic processes. 
For 
this reason we should not despair of unravelling the web 
of causes. 
See also J. R. Platt's review of Elsasser's 
book in Pcvspcctives in biology utzd wzedicitze 2 :  243-245, 
1959. 
AB
the pattern CD for example, occurs four times 
in the total pattern, it is economical to represent 
it by the single symbol, a. 
If a complex structure is completely unre-
dundant-if 
no aspect of its structure can be in- 
ferred from any other-then 
it is its own simplest 
description. 
W e  can exhibit it, but we cannot 
describe it by a simpler structure. The hierarchic 
structures we have been discussing have a high 
degree of redundancy, hence can often be described 
in economical terms. 
The redundancy takes a 
number of forms, of which I shall mention three: 
1. Hierarchic systems are usually composed of 
only a few different kinds of subsystems, in vari- 
ous combinations and arrangements. A familiar 
example is the proteins, their multitudinous vari- 
ety arising from arrangements of only twenty 
different amino acids. Similarly, the ninety-odd 
elements provide all the kinds of building blocks 
needed for an infinite variety of molecules. Hence, 
we can construct our description from a restricted 
alphabet of elementary terms corresponding to the 
basic set of elementary subsystems from which 
the complex system is generated. 
2. Hierarchic systems are, as we have seen, 
often nearly decomposable. 
Hence only aggre-
aative properties of their parts enter into the de- 
scriptiin 
of the interactions of those parts. 
A 
generalization of the notion of near-decomposabil- 
ity might be called the "empty world hypothesis" 
-most 
things are only weakly connected with 
most other things; for a tolerable description of 
reality only a tiny fraction of all possible interac- 
tions needs to be taken into account. By adopting 
a descriptive language that allows the absence of 
something to go unmentioned, a nearly empty 
world can be described quite concisely. Mother 
Hubbard did not have to check off the list of pos- 
sible contents to say that her cupboard was bare. 
3. By appropriate "recoding," the redundancy 
that is present but unobvious in the structure of 
a complex system can often be made patent. The 
most cornillon recoding of descriptions of dy-
namic systems consists in replacing a description 
of the time path with a description of a differential 
law that generates that path. The simplicity, that 
is, resides in a constant relation between the 
state of the system at any given time and the state 
of the system a short time later. Thus, the struc- 
ture of the sequence, 1 3 5 7 9 11 . . ., is most 
simply expressed by observing that each member 
is obtained by adding 2 to the previous one. But 

VOL. 106, NO. 6, 19621 
T H E  ARCHITECTURE OF COMPLEXITY 
479 
this is the sequence that Galileo found to describe 
the velocity at the end of successive time intervals 
of a ball rolling down an inclined plane. 
It is a familiar proposition that the task of sci- 
ence is to make use of the world's redundancy to 
describe that world simply. I shall not pursue the 
general methodological point here, but shall instead 
take a closer look at two main types of description 
that seem to be available to us in seeking an 
understanding of complex systen~s. I shall call 
these state description and process description, 
respectively. 
STATE DESCRIPTIONS AND PROCESS DESCRIPTIONS 
"A circle is the locus of all points equidistant 
from a given point." "To construct a circle, rotate 
a compass with one arm fixed until the other arm 
has returned to its starting point." 
It is implicit 
in Euclid that if you carry out the process speci- 
fied in the second sentence, you will produce an 
object that satisfies the definition of the first. 
The first sentence is a state description of a circle, 
the second a process description. 
These two modes of apprehending structure are 
the warp and weft of our experience. Pictures, 
blueprints, most diagrams, chemical structural 
formulae are state descriptions. 
Recipes, differ- 
ential equations, equations for chemical reactions 
are process descriptions. The former characterize 
the world as sensed; they provide the criteria for 
identifying objects, often by modeling the objects 
themselves. The latter characterize the world as 
acted upon; they provide the means for producing 
or generating objects having the desired charac- 
teristics. 
The distinction between the world as sensed and 
the world as acted upon defines the basic condition 
for the survival of adaptive organisms. The or- 
ganism must develop correlations between goals 
in the sensed world and actions in the world of 
process. \{'hen they are made conscious and ver- 
balized, these correlations correspond to what we 
usually call means-end analysis. Given a desired 
state of affairs and an existing state of affairs, the 
task of an adaptive organism is to find the differ- 
ence between these two states, and then to find 
the correlating process that will erase the differ- 
e n ~ e . ? ~  
Thus, problem solving requires continual trans- 
"See H. A. Simon and A. Newell, Simulation of 
human thinking, in M. Greenberger (ed.), Management 
and the computer of the future, 95-114, esp. pp 110 ff., 
New York, Wiley, 1962. 
lation between the state and process descriptions 
of the same complex reality. Plato, in the Meno, 
argued that all learning is remembering. 
H e  
could not otherwise explain how we can discover 
or recognize the answer to a problem unless we 
already know the answer.23 Our dual relation to 
the world is the source and solution of the para- 
dox. 
W e  pose a problem by giving the state 
description of the solution. The task is to dis- 
cover a sequence of processes that will produce 
the goal state from an initial state. Translation 
from the process description to the state descrip- 
tion enables us to recognize when we have suc-
ceeded. 
The solution is genuinely new to us-
and we do not need Plato's theory of remembering 
to explain how we recognize it. 
There is now a growing body of evidence that 
the activity called human problem solving is basi- 
cally a form of means-end analysis that aims at 
discovering a process description of the path that 
leads to a desired goal. The general paradigm is : 
given a blueprint, to find the corresponding 
recipe. 
Much of the activity of science is an 
application of that paradigm : given the descrip- 
tion of some natural phenomena, to find the differ- 
ential equations for processes that will produce 
the phenomena. 
THE DESCRIPTION O F  COMPLEXITY I N  
SELF-REPRODUCIxG SYSTEMS 
The problem of finding relatively simple descrip- 
tions for complex systems is of interest not only 
for an understanding of human knowledge of the 
world but also for an explanation of how a com-
plex system can reproduce itself. In my discus- 
sion of the evolution of complex systems, I touched 
only briefly on the role of self-reproduction. 
Atoms of high atomic weight and complex in- 
organic molecules are witnesses to the fact that the 
evolution of complexity does not imply self-
reproduction. 
If evolution of complesity from 
simplicity is sufficiently probable, it will occur 
repeatedly; the statistical equilibrium of the system 
will find a large fraction of the elementary par- 
ticles participating in complex systems. 
If, however, the existence of a particular com- 
plex form increased the probability of the creation 
of another form just like it, the equilibrium be- 
tween complexes and components could be greatly 
altered in favor of the former. If we have a de- 
scription of an object that is sufficiently clear and 
23 T h e  zuorks of Plato, B. Jowett, trans., 3: 26-35, New 
York, Dial Press. 

480 
HERBERT A. SIMOX 
[PROC. 
PHIL. SOC.
AMER. 
complete, we can reproduce the object from the 
description. 
Whatever the exact mechanism of 
reproduction, the description provides us with the 
necessarv information. 
S o w  we have seen that the descriptions of com- 
plex systems can take many forms. In particular, 
we can have state descriptions or we can have 
process descriptions ; blueprints or recipes. 
Re-
productive processes could be built around either 
of these sources of information. 
Perhaps the 
simplest possibility is for the complex system to 
serve as a description of itself-a 
template on 
which a copy can be formed. One of the most 
plausible current theories, for example, of the 
reproduction of deoxyribonucleic acid (DNA) 
proposes that a DNA molecule, in the form of a 
double helix of matching parts (each essentially 
a "negative" of the other), unwinds to allow each 
half of the helix to serve as a template on which 
a new matching half can form. 
On the other hand, our current knowledge of 
how D S X  controls the metabolism of the organ- 
ism suggests that reproduction by template is only 
one of the processes involved. According to the 
prevailing theory, D S X  serves as a template both 
for itself and for the related substance ribonucleic 
acid (RS-A). RNA, in turn, serves as a template 
for protein. But proteins-according 
to current 
knowledge-guide 
the organism's metabolism not 
by the template method but by serving as catalysts 
to govern reaction rates in the cell. IVhile RNA 
is a blueprint for protein, protein is a recipe for 
metabolisn~.'~ 
ONTOGENY RECAPITULATES PHYLOGENY 
The D S A  in the chromosomes of an organism 
contains some. and ~ e r h a ~ s  
most, of the informa- 
tion that is needed to determine its development 
and activity. IVe have seen that, if current theo- 
ries are even approximately correct, the informa- 
tion is recorded-not as a state descri~tion of the 
organism but as a series of "instructions" for the 
" 
construction and maintenance of the organism 
from nutrient materials. I have already used the 
metaphor of a recipe ; I could equally well compare 
it with a computer program, which is also a se-
quence of instructions, governing the construction 
14 C. B. Anfinsen, T h e  ?~zolcctllar basis of evolution, 
chs. 3 and 10, New York, Wiley, 1959, will qualify this 
sketchy, oversimplified account. For an imaginative dis- 
cussion of some mechanisms of process description that 
could govern molecular structure, see H. H. Pattee, On 
the origin of macromolecular sequences, Biophysical Jolrr- 
~ t a l1 :  683-710, 1961. 
of symbolic structures. Let me spin out some of 
the consequences of the latter comparison. 
If genetic material is a program-viewed 
in its 
relation to the organism-it 
is a program with 
special and peculiar properties. First, it is a self- 
reproducing program ; we have already considered 
its possible copying mechanism. Second, it is a 
program that has developed by Darwinian evolu- 
tion. On the basis of our watchmaker's argument, 
we may assert that many of its ancestors were also 
viable programs-programs 
for the subassemblies. 
Are there any other conjectures we can make 
about the structure of this program? There is a 
well-known generalization in biology that is ver- 
bally so neat that we would be reluctant to give 
it up even if the facts did not support it: ontogeny 
recapitulates phylogeny. The individual organism, 
in its development, goes through stages that re-
semble some of its ancestral forms. The fact that 
the human embryo develops gill bars and then 
modifies them for other purposes is a familiar 
particular belonging to the generalization. Biolo-
gists today like to emphasize the qualifications of 
the principle-that 
ontogeny recapitulates only the 
grossest aspects of phylogeny, and these only 
crudely. These qualifications should not make us 
lose sight of the fact that the generalization does 
hold in rough approximation-it 
does summarize 
a very significant set of facts about the organism's 
development. How can we interpret these facts? 
One way to solve a complex problem is to 
reduce it to a problem previously solved-to 
show 
what steps lead from the earlier solution to a solu- 
tion of the new problem. If, around the turn of 
the century, we wanted to instruct a workman 
to make an automobile, perhaps the simplest way 
would have been to tell him how to modify a 
wagon by removing the singletree and adding a 
motor and transmission. 
Similarly, a genetic 
program could be altered in the course of evolu-
tion by adding new processes that would modify 
a simpler form into a more complex one-to 
con-
struct a gastrula, take a blastula and alter it! 
The genetic description of a single cell may, 
therefore, take a quite different form from the 
genetic description that assembles cells into a 
multi-celled organism. Multiplication by cell divi- 
sion would require, as a minimum, a state descrip- 
tion (the DNA, say), and a simple "interpretive 
processn-to 
use the term from computer language 
-that 
copies this description as a part of the 
larger copying process of cell division. But such 
a mechanism clearly would not suffice for the 

VOL. 106, SO.6, 19621 
T H E  ARCHITECTURE O F  COMPLEXITY 
481 
differentiation of cells in development. It appears 
illore natural to conceptualize that mechanism as 
based on a process description, and a somewhat 
more conlplex interpretive process that produces 
the adult organism in a sequence of stages, each 
new stage in development representing the effect of 
an operator upon the previous one. 
It is harder to conceptualize the interrelation of 
these two descriptions. 
Interrelated they must 
be, for enough has been learned of gene-enzyme 
mechanisins to show that these play a major role 
in development as in cell metabolism. The single 
clue we obtain from our earlier discussion is that 
the description may itself be hierarchical, or nearly 
decomposable, in structure, the lower levels gov- 
erning the fast, "high-frequency" dynamics of the 
individual cell, the higher level interactions gov- 
erning the slow, "low-£requencyn dynamics of the 
developing multi-cellular organism. 
There are only bits of evidence, apart from the 
facts of recapitulation, that the genetic program is 
organized in this way, but such evidence as exists 
is compatible with this notion.25 To the extent 
that \ve can differentiate the genetic information 
that governs cell metabolism from the genetic in- 
fornlation that governs the developn~ent of differ- 
entiated cells in the multi-cellular organization, 
we simplify enormously-as 
we have already seen 
-our 
task of theoretical description. But I have 
perhaps pressed this speculation far enough. 
The generalization that in evolving systems 
whose descriptions are stored in a process lan-
guage, vie might expect ontogeny partially to re-
capitulate phylogeny has applications outside the 
25 There is considerable evidence that successive genes 
along a chromosome often determine enzymes controlling 
successive stages of protein syntheses. For a review of 
some oi this evidence, see P. E. Hartman, Transduction: 
a comparative review, in W. D. McElroy and B. Glass 
(eds.), T i ~ c  
chemical basis o f  heredzty, Baltimore, Johns 
Hopkins Press, 1957, at pp. 442-454. 
Evidence for dif- 
ferential activity of genes in different tissues and at differ- 
ent stages of development is discussed by J. G. Gall, 
Chromosomal Differentiation, ill W. D. McElroy and 
B. Glass (eds.), T h e  chenzical basis of developnzetzt, 
Baltimore, Johns Hopkins Press, 1958, at pp. 103-135. 
Finally, a model very like that proposed here has been 
independently, and far more fully, outlined by J. R. Platt, 
A 'book model' of genetic information transfer in cells 
and tissues, itz Kasha and Pullman (eds.), Hori,-otzs ipt 
bioi.hc~r~istry,New York, Academic Press, forthcoming. 
Of course, this kind of mechanism is not the only one in 
which development could be controlled by a process de- 
scription. Induction, in the form envisaged in Spemann's 
organizer theory, is based on process description, in which 
metabolites in already formed tissue control the next 
stages of development. 
realm of biology. 
It can be applied as readily, 
for example, to the transmission of knowledge in 
the educational process. 
In most subjects, par-
ticularly in the rapidly advancing sciences, the 
progress from elementary to advanced courses is 
to a considerable extent a progress through the 
conceptual history of the science itself. 
Fortu-
nately, the recapitulation is seldom literal-any 
more than it is in the biological case. \Ve do not 
teach the phlogiston theory in chemistry in order 
later to correct it. 
( I  am not sure I could not 
cite examples in other subjects where we do ex- 
actly that.) 
But curriculum revisions that rid us 
of the accumulations of the past are infrequent 
and painful. S o r  are they always desirable-par- 
tial recapitulation may, in many instances, provide 
the most expeditious route to advanced knowledge. 
SUMMARY : THE DESCRIPTION OF COMPLEXITY 
How complex or simple a structure is depends 
critically upon the way in which we describe it. 
Most of the complex structures found in the world 
are enormously redundant, and we can use this 
redundancy to simplify their description. But to 
use it, to achieve the sinlplification, we must find 
the right representation. 
The notion of substituting a process description 
for a state description of nature has played a cen- 
tral role in the development of modern science. 
Dynamic laws, expressed in the form of systems 
of differential or difference equations, have in a 
large number of cases provided the clue for the 
simple description of the complex. 
In the pre- 
ceding paragraphs I have tried to show that this 
characteristic of scientific inquiry is not accidental 
or superficial. The correlation between state de- 
scription and process description is basic to the 
functioning of any adaptive organism, to its ca-
pacity for acting purposefully upon its environ- 
ment. Our present-day understanding of genetic 
mechanisms suggests that even in describing itself 
the multi-cellular organism finds a process descrip- 
tion-a 
genetically encoded program-to 
be the 
parsimonious and useful representation. 
CONCLUSION 
Our speculations have carried us over a rather 
alarming array of topics, but that is the price we 
must pay if we wish to seek properties common 
to many sorts of complex systems. My thesis has 
been that one path to the construction of a non-
trivial theory of complex systems is by way of a 
theory of hierarchy. Empirically, a large propor- 
tion of the complex systems we observe in nature 

482 
HERBERT A. SIMON 
[PROC. 
PHIL.
AMER. 
SOC. 
exhibit hierarchic 
structure. 
On theoretical 
grounds we could expect complex systems to be 
hierarchies in a world in which complexity had to 
evolve from simplicity. 
In their dynamics, hier- 
archies have a property, near-decomposability, that 
greatly simplifies their behavior. 
Near-decom-
posability also simplifies the description of a com- 
plex system, and makes it easier to understand 
how the information needed for the development 
or reproduction of the system can be stored in 
reasonable compass. 
In both science and engineering, the study of 
"systems" is an increasingly popular activity. Its 
popularity is more a response to a pressing need 
for synthesizing and analyzing complexity than it 
is to any large development of a body of knowl- 
edge and technique for dealing with complexity. 
If this popularity is to be more than a fad, neces- 
sity will have to mother invention and provide 
substance to go with the name. The explorations 
reviewed here represent one particular direction 
of search for such substance. 

