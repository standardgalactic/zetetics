Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=tcpo20
Climate Policy
ISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/tcpo20
Developing an Ad Hominem typology for classifying
climate misinformation
Sergei A. Samoilenko & John Cook
To cite this article: Sergei A. Samoilenko & John Cook (2024) Developing an Ad Hominem
typology for classifying climate misinformation, Climate Policy, 24:1, 138-151, DOI:
10.1080/14693062.2023.2245792
To link to this article:  https://doi.org/10.1080/14693062.2023.2245792
View supplementary material 
Published online: 13 Aug 2023.
Submit your article to this journal 
Article views: 493
View related articles 
View Crossmark data

RESEARCH ARTICLE
Developing an Ad Hominem typology for classifying climate
misinformation
Sergei A. Samoilenkoa and John Cookb
aCommunication, George Mason University, Fairfax, VA, USA; bMelbourne Centre for Behaviour Change, University of
Melbourne, Melbourne, Australia
ABSTRACT
Misinformation produced by various interest groups is a signiﬁcant contributing
factor to public confusion about climate policy. Character assassination against
climate scientists and policymakers is the most common type of misinformation
strategy used by contrarians in climate debates (Coan, T. G., Boussalis, C., Cook, J.,
& Nanko, M. O. (2021). Computer-assisted classiﬁcation of contrarian claims about
climate change. Scientiﬁc Reports, 11(1), 22320). Despite its widespread use,
however,
character
assassination
remains
understudied
by
social
scientists,
especially in the context of climate change. This study adapts Douglas Walton’s
(1998. Ad hominem arguments. University of Alabama Press) typology of ‘ad
hominem’
attacks
–
personal
attacks
targeting
an
individual’s
character,
competence, or motives – to misinformation campaigns against the climate
community. We developed an original codebook for classifying ad hominem
arguments made by climate contrarians. Drawing on a 553-paragraph sample from
a corpus from 55 contrarian blogs and 15 conservative think-tank websites
published in English between 2008 and 2020, we then determined the relative
prominence of each type of attack using a consensus-coding approach. Bias
attacks, which entail accusing climate scientists of political partisanship or having
an ideological agenda, were the most common form of contrarian ad hominem
attack. The dominance of bias attacks can be explained by their strong relevance
for scientiﬁc credibility. The study found that ad hominem attacks, often with bias
and moral attacks clustered together, are the most common combination. The
article concludes by discussing the implications of these ﬁndings for climate policy
and future research.
Key Policy Insights:
.
Climate misinformation politicizes climate science, further amplifying ideological
conﬂict and fostering ideological polarization;
.
Climate misinformation campaigns feature a range of diﬀerent types of ad
hominem attacks designed to undermine the credibility of climate scientists;
.
The most common type of ad hominem attack on climate scientists in our sample
was bias attacks, which entail accusing climate scientists of political partisanship or
of having an ideological agenda;
.
Attacks on the moral character of climate scientists were the only type of ad
hominem that increased during the period under study (2008–2020);
.
Diﬀerent types of ad hominems often appeared together, with the most common
combination being bias and moral attacks;
.
Ad hominem attacks on climate scientists are part of misinformation campaigns
designed to stall discussion on climate change and delay the implementation of
climate policies.
ARTICLE HISTORY
Received 11 August 2022
Accepted 3 August 2023
KEYWORDS
Ad hominem; bias; moral
attack; climate science;
misinformation; climate
change policies
© 2023 Informa UK Limited, trading as Taylor & Francis Group
CONTACT Sergei A. Samoilenko
ssamoyle@gmu.edu
Supplemental data for this article can be accessed online at https://doi.org/10.1080/14693062.2023.2245792.
CLIMATE POLICY
2024, VOL. 24, NO. 1, 138–151
https://doi.org/10.1080/14693062.2023.2245792

1. Introduction
Climate misinformation leads to reduced climate literacy, with such negative implications for society as
reduced support for climate policy and environmental regulation (van der Linden et al., 2017). Misinforma-
tion can obtain signiﬁcant attention in the mainstream media (Elsasser & Dunlap, 2013) and polarize poli-
ticians when ampliﬁed in echo chambers (Jasny et al., 2018). Simply inserting a few misleading statistics
into the discussion can serve to reduce people’s acceptance of climate change as a phenomenon
(Ranney & Clark, 2016).
Contrarians routinely deny the evidence of environmental problems by exploiting scientiﬁc uncertainties,
misinterpreting peer-reviewed research, and spreading conspiracy theories (Jacques & Knox, 2016; Jacques
et al., 2008). According to McCright and Dunlap (2010), the American conservative movement has employed
several techniques to make climate change a non-issue and prevent progress on climate policymaking. It
has (1) obfuscated and suppressed the results of scientiﬁc research; (2) exploited existing media bias; and (3)
intimidated or threatened to sanction individual scientists, among other things. Conservative think tanks
(CTT) are the main producers of doubt, denial, and dismissal of the scientiﬁc consensus on climate change.
According to Xifra (2016), more than 90% of papers skeptical about climate change originate from CTTs. An
eﬀort to map the climate change counter-movement identiﬁed 4,556 individuals with overlapping network
ties to 164 organizations that are responsible for most eﬀorts to downplay the threat of climate change in
the United States (Farrell, 2016).
Coan et al. (2021) found that character assassination of climate scientists and policymakers is the most
popular type of misinformation strategy deployed by contrarians in climate debates. The use of character
attacks is common in politicized contexts and is considered instrumental to goal achievement (Benoit,
2017; Pfau & Kenski, 1990). Social media have made it easier for special interest groups and digital acti-
vists to produce smear campaigns by increasing connectivity and a greater number of individual and col-
lective contributors (Petkevic & Nai, 2022; Samoilenko & Jasper, 2023). Reputational attacks cause climate
scientists to be more cautious in communicating scientiﬁc results and discourage them from publicly
addressing politicized topics (Biddle & Leuschner, 2015; Lewandowsky et al., 2015; Lewandowsky et al.,
2019).
Argumentum ad hominem is a rhetorical strategy that attacks a person’s character instead of debating the
issue or the substance of an argument (Tedesco & Dunn, 2019). Attacks may include derogatory statements
about personal traits, moral standing, or expertise, as well as speculation about motives and special interests.
According to Walton (2002, p. 188), ‘the argument against the person is often so eﬀective and devastating
that it is a conversation-stopper, closing oﬀthe possibilities of objective argument and further reasonable
discussion of an issue.’ Previous studies indicate that ad hominem attacks may have the same degree of
impact as attacks on the empirical basis of scientiﬁc claims, and that allegations of conﬂict of interest
may be just as inﬂuential as allegations of outright fraud (Barnes et al., 2018). Despite their pervasiveness,
however, climate-related ad hominem attacks are understudied in misinformation research. This has impli-
cations for climate policy, as the ultimate purpose of climate misinformation is to delay climate action. Con-
sequently, understanding the sources and content of climate misinformation is vital to countering its
inﬂuence.
The purpose of our study was to identify the types of ad hominem attacks used in CTTs’ materials and the
frequency of each type of online attack. The study applies Douglas Walton’s argumentation approach
(Walton, 1998) to create a system for classifying ad hominems against climate scientists and environmental
leaders that appear in a content analysis of CTTs’ articles. The dataset was computer-generated by Coan
et al. (2021). Computational social science has been used actively in recent years to detect and understand
climate misinformation, ﬁnding that there are recurring thematic patterns (Farrell, 2019) and major themes in
CTTs’ articles (Boussalis & Coan, 2016). Studies demonstrate that machines can detect deceptive content
more reliably than most human judges (Atanasova et al., 2019). Along the same lines, researchers have
used machine learning to classify ad hominem fallacies (Delobelle et al., 2019). The ﬁndings of the
present study suggest directions for future research to expose the rhetorical weaknesses of such attacks
and develop critical responses.
CLIMATE POLICY
139

2. Theoretical background
The literature on argumentum ad hominem has identiﬁed several categories into which such attacks may fall
(Blair & Johnson, 2006; van Eemeren & Grootendorst, 1984; Walton, 1998). The direct (abusive) ad hominem
is used when the attacker claims that the target’s argument should not be accepted due to a certain personal
imperfection, whether a moral failing or a character ﬂaw. Guilt by association is a popular sub-type of direct
(abusive) ad hominem. It involves transferring alleged guilt to a person for their association with a supposedly
discreditable or socially demonized individual, group, or doctrine.
The bias ad hominem occurs when the accuser points out that the target is partisan or prejudiced in favour of
a particular cause. As such, the attack goes, they will not objectively consider the arguments presented to them,
instead seeking only to win at all costs. Finally, the circumstantial ad hominem is based on evidence of behav-
iour inconsistent with previous positions, convictions, or actions. Typically, an allegation of inconsistency takes
the form of an argument that the respondent ‘does not practice what he preaches.’
There is a dearth of research into ad hominem attacks on climate scientists, a striking lacuna given the
relative prominence of this form of misinformation. In his analysis of online publications by the CTT Heart-
land Institute, Cann (2015) found that the texts blended arguments about the scientiﬁc uncertainty of
climate change with attacks on the moral character of climate researchers. Character attacks targeting
scientists have been found to have an impact on public opinion comparable to attacks on the empirical
basis of scientiﬁc claims, with allegations of conﬂict of interest potentially just as inﬂuential as allegations
of outright fraud (Barnes et al., 2018). Allegations of misconduct, conﬂicts of interest, and incompetence on
the part of researchers can be used to attack and undercut science claims (DeAngelis, 2000; Wohn &
Normile, 2006).
Little is known about what type of ad hominem attacks are most frequently used to undercut climate science
claims. Research based on framing theory has limitations when it comes to explaining the pragmatics of such
attacks and their credibility with diﬀerent audiences in diﬀerent settings (Druckman, 2001; Knight & Greenberg,
2011). A diﬀerent conceptual framework is needed to understand and critically assess how and why these
attacks undermine scientiﬁc dialogue in a given context.
Next, we discuss Walton’s approach to ad hominem. This approach is similar to the critical thinking method-
ology used by Cook et al. (2018) to assess the validity of climate misinformation campaigns.
2.1. Walton’s approach to Ad Hominem
Traditionally, argumentum ad hominem has been described as an informal fallacy of argumentation when used
in situations where an opponent’s character is not relevant to the issue being discussed (Minot, 1981). This view
of ad hominem argument is challenged by Douglas Walton’s pragmatic theory.
Walton (1998) indicates that while some arguments grounded in personal attacks can deﬁnitely be judged
fallacious, many others are quite reasonable when evaluated in the appropriate context. There are also argu-
ments that should be evaluated as weak (insuﬃciently supported) but not fallacious. Ad hominem argument
can be legitimate when a character critique is directly or indirectly related to the point being articulated
(Walton, 1999). Similarly,Benoit (2017) argues that an attack on character can be useful when it exposes
wrong-doing and creates awareness of oﬀensive actions. This unwanted publicity is intended to embarrass per-
petrators and force them to change their behaviour. Persuasive attacks can also help voters make decisions in
contexts where criticism of political candidates is relevant and reasonable. In political contests, defending one’s
reputation and refuting attacks is celebrated as a critical skill. Hence, ad hominem attacks allow voters to see
how candidates perform under pressure. Finally, persuasive attacks can help consumers to think critically
about products and services; pointing out the weaknesses of a given product may inﬂuence consumers’
buying decisions.
Walton’s (1998) typology lists 21 types of ad hominem attacks (see Figure 1). Unlike related classiﬁcation
systems (e.g. Benoit & Harthcock, 1999), this typology is prescriptive in nature. It is also more comprehensive
than other similar frameworks (e.g. Benoit, 2017; van Eemeren & Grootendorst, 1984). Walton’s work has
been used to prepare legal arguments (Walton & Macagno, 2015), to counter irrelevant arguments in
140
S. A. SAMOILENKO AND J. COOK

debates regarding genetic engineering of humans (Walton, 2017), and to help develop artiﬁcial intelligence
(Walton, 2005).
Other studies support the view of ad hominem attacks as a pragmatic strategy (Walton et al., 2008). These
attacks can be especially damaging when they question the competence and integrity of scientists (Barnes
et al., 2018). By challenging a speaker’s authority, they undercut those arguments that depend for their credi-
bility on the expertise of the speaker (Macagno, 2013). Even if an ad hominem attack is considered fallacious, it
can still be eﬀective because it can undermine public trust in scientiﬁc expertise.
Despite the widespread nature of the phenomenon, the use of ad hominem attacks in contrarian misinfor-
mation campaigns and their eﬀects remain understudied by social scientists in the context of climate policy.
The present study attempts to ﬁll this void. Analyzing a sample of character attacks detected on contrarian
blogs and websites using a machine-learning approach, we aim to determine what types of attacks are used
and how frequently they occur. Online platforms are a popular means of disseminating misinformation, as plat-
forms can target audiences and users can self-select platforms, producing polarizing echo chambers (Treen
et al., 2020). The ﬁndings of the present study may inform eﬀorts to assist people in recognizing the ad
hominem attacks often lodged against climate scientists, thereby reducing the eﬀectiveness of future contrarian
misinformation campaigns.
3. Methodology
3.1. Materials
The ﬁnal sample for our content analysis was a set of 553 paragraphs containing attacks on climate scientists.
We derived this from a dataset produced by Coan et al. (2021), who created custom software to harvest a corpus
of 287,000 documents from 55 contrarian blogs and 15 North American CTT websites published in English
between 2008 and 2020. The list of contrarian blogs built upon an existing list of blogs that posted contrarian
Figure 1. Walton’s Typology of Ad hominem Arguments (amended for simplicity).
CLIMATE POLICY
141

content about climate change (Sharman, 2014). These blogs and think tanks are proliﬁc and inﬂuential sources
of climate misinformation that seek to discredit climate science and further free-market fundamentalism. In
Coan et al. (2021), a subset of climate misinformation was found to target four groups perceived to be part
of the climate movement: climate scientists (e.g. scientists publishing research about climate change), environ-
mentalists, politicians, and the media. For our content analysis, we used machine learning to identify 553 para-
graphs from this larger corpus that contained ad hominem attacks against people involved in the climate
movement.
Coding of narrative data is an established research method to improve the generalizability of ﬁndings,
ensuring that conclusions can be applied to other contexts (McLean & Syed, 2015). Quantitative content
analysis allows us to determine the prevalence of attacks on climate scientists. The paragraph was used
as a unit of analysis to identify, enumerate, and analyze occurrences of speciﬁc messages embedded in
texts. We coded more than one type of attack in each paragraph under study. Diﬀering types of ad
hominem attacks were seen to cluster together in distinct combinations (e.g. allegations of immorality
and bias).
The targets of attacks were environmentalists, climate scientists, journalists writing about climate issues, and
policymakers concerned about climate change (e.g. Al Gore). These four target types are discussed by Coan
et al. (2021) in more detail. We did not observe contrarian attacks targeting skeptics or CTT members.
Computer-assisted detection was used to identify those paragraphs with the highest probability of con-
taining ad hominem attacks. Coan et al. (2021) trained a machine-learning model to categorize climate mis-
information into diﬀerent categories of misinformation, with one sub-category being ‘Climate movement is
unreliable’ (with ‘climate movement’ including climate scientists, environmentalists, journalists, and poli-
ticians who accept mainstream climate science and support climate action). The machine-learning model
provided a sample of 4,506 paragraphs with the highest probability of containing ‘climate movement is
unreliable’ claims. From this sample, we randomly selected 650 paragraphs for our study: 50 paragraphs
per year between 2008 and 2015. The number of paragraphs was later reduced to 553 to eliminate dupli-
cates, paragraphs with garbled text due to scraping issues (that is, superﬂuous words such as page head-
ings), and paragraphs that did not meet the criteria of our coding book (e.g. not climate-related or not a
complete sentence).
3.2. Procedure
The theory-driven approach taken in this study involves deconstructing Walton’s (1998) argumentation theory
into codes that can be applied to the data (Marcia, 1966). Walton’s typology emerged in a humanistic scholarly
ﬁeld, namely argumentation (e.g. van Eemeren & Grootendorst, 1984); additional steps were therefore required
to transform his scholarship into a social-science instrument. Speciﬁcally, a codebook was needed to establish a
reliable system for classifying ad hominem arguments with acceptable intercoder reliability. To increase the
usability of Walton’s typology for social-scientiﬁc classiﬁcation of these attacks, we ﬁrst reviewed 21 forms of
argument signiﬁcant for deﬁning the various subtypes of ad hominem argument, as well as related forms of
argument. We then narrowed our scope to the relevant ad hominems, targeting the abovementioned four
target types. These ad hominem categories were subsequently scaled down and streamlined for content analy-
sis purposes.
The coding manual for this project was developed iteratively by the principal investigator and the second
coder for two years between May 2018 and May 2020. The process of developing a reliable coding scheme
involves balancing parsimony and nuance (Syed & Nelson, 2015). One of the most important decisions made
in coding development is the number of codes to be used. A large number of codes allows for greater complex-
ity but comes with the possible cost of decreased reliability. This decision must be made on a case-by-case
basis, with attention paid to the reliability and usefulness of the data (Campbell et al., 2013). Initial coding
attempts resulted in poor intercoder reliability, reﬂecting both the diﬃculty of the coding task and the need
to further reﬁne the codebook. The diﬃculty of the task was due to the nature of the corpus, with attacks
on scientists often containing incomplete sentences, innuendo, sarcasm, and ambiguity. The iterative
process continued until the codebook was suﬃciently reﬁned and intercoder reliability established. Walton’s
142
S. A. SAMOILENKO AND J. COOK

21 forms of ad hominem attacks were streamlined by selecting the attacks that were coded with the greatest
reliability.
From this process, we derived three major types of trait-focused attacks – that is, ad hominem attacks that
label a target with a speciﬁc negative trait (shown in Figure 2). These were allegations of incompetence, immor-
ality, and bias.
From this process, we derived three major types of trait-focused attacks – meaning ad hominem attacks that
paint a target with a negative trait (shown in Figure 2). They included allegations of incompetence, immorality,
and bias. Additionally, we identiﬁed two structural ad hominem arguments: inconsistent behaviour (circumstan-
tial guilt) and guilt by association. These attacks were structured in a certain way but could be used to label
targets with any type of negative trait. Two main types of circumstantial attack were detected: logical/prag-
matic inconsistency and group circumstantial.
The ﬁrst type of inconsistency can result from either logical mismatch or practical inconsistency between a
target’s words and his/her actions. Pragmatic inconsistency attacks entail contrasting the target’s current
behaviour or statements with past behaviour or statements in order to establish a lack of consistency. An
example in a climate context would be ‘the EPA and IPCC insist they rely entirely on scholarly peer-reviewed
source material. However, fully 30% of the papers and other references cited in the IPCCs Fourth Assessment
Report (AR4) were not peer reviewed; many IPCC lead authors were graduate students or environmental acti-
vists; and many sources were actually master’s degree theses or even anecdotal statements by hikers and
mountain guides.’
The second type of circumstantial attack, group circumstantial, involves contrasting the target with the
idealized behaviour of a group to which they belong. For example, ‘the IPCC is supposed to be an objective
scientiﬁc body, but […] writes forewords for Greenpeace publications and has accepted a green crusader
award.’ Table 1S summarizes documents the codebook developed for categorizing diﬀerent types of ad
hominem attacks (see Supplementary Material for the full version). The codebook included examples for
each category, as well as some exclusion examples of text that did not fall into that category.
3.3. Data analysis
The codebook was used to instruct coders how to assign values to content units. Coders practiced content
analysis on paragraphs that were not part of the main analysis until acceptable intercoder reliability was
established, then began coding study content (Krippendorﬀ, 2013). Two coders coded content units inde-
pendently of each other. The central challenge for the coders was deciding how to code when a paragraph
could be labelled in several diﬀerent ways. This is a typical problem during categorization, as codes included
in one category may also seem to be a ﬁt for another category. According to Erlingsson and Brysiewicz
(2017), overlap between initial categories is common when the data are voluminous and/or complex.
Since the reliability check involved two or more coders coding the same content, there were some
content units where coders assigned more than one value on which they disagreed. The process for resol-
ving disagreements included a discussion among the coders aimed at reaching consensus. In the event of
discrepancies, coders used a consensus-coding approach after each individual session. This enabled them to
discuss and reﬂect on their coding decisions and to reach consensus on the best way forward. Consensus
Figure 2. Typology of Ad Hominem Arguments Found in Climate Change Character Attacks.
CLIMATE POLICY
143

coding is an appropriate approach for establishing reliability when coding narrative data (Syed & Nelson,
2015).
4. Results
Intercoder reliability between the two coders for competence, moral, bias, guilt by association, and circumstan-
tial ad hominems is listed in Table 1. Given the imbalanced dataset, with some ad hominem types (bias and
moral) more highly represented than others, Gwet’s AC(1) was chosen as an appropriate intercoder reliability
measure (Wongpakaran et al., 2013). Reliability analysis was conducted in R using the irrCAC library (Gwet,
2014). To resolve discrepancies, the two coders deliberated and decided on consensus codings in cases
where there were disagreements. Table 1 reﬂects intercoder reliability before discrepancies were discussed
and resolved.
Figure 3 shows the total number of each type of ad hominem after the coders reached consensus. This ﬁgure
therefore depicts the relative prevalence of diﬀering types of ad hominem arguments. It shows the clear dom-
inance of bias attacks, followed by attacks on morality. When it comes to structural arguments, the circumstan-
tial structure is used more than the guilt by association structure. Attacks on scientists’ competence are the least
common form of ad hominem in our sample.
Figure 4 shows the prevalence of diﬀerent ad hominem argument types over time. While it likewise reﬂects
the dominance of bias attacks in the sample, it shows that these have remained relatively consistent over the
analysis period. Moral attacks, meanwhile, have increased (the only category of ad hominem attacks to do so),
Table 1. Summary Statistics for Coding (2008–2020).
Category of Ad Hominem Attack
Gwet’s AC(1)
Percentage Agreement
Competence
0.85
88
Moral
0.66
83
Bias
0.80
88
Association
0.77
83
Circumstantial
0.71
83
Figure 3. Percentage of Ad Hominem Types in Corpus.
144
S. A. SAMOILENKO AND J. COOK

becoming nearly as prominent as bias attacks by the end of the period under study. This supports the previous
observation that attacks targeting moral character have become more prominent in policy debates (Coan et al.,
2021).
Table 1S lists the ﬁve diﬀerent types of ad hominem attacks identiﬁed above and provides climate-relevant
examples (see Supplementary Material). The ﬁrst ad hominem type is bias. It occurs when the accuser points out
that the target is partisan or prejudiced in favour of a particular cause. The target may be also accused of having
an agenda/advocacy (typically due to his/her politicalaﬃliation/ideology/religion) or of promoting some sort of
propaganda or spreading alarmism.
The second type is moral. The attacker claims that the target’s argument should not be accepted due to the
latter’s moral failings or bad character. Such attacks may manifest as name-calling or applying ridiculing or demo-
nizing labels. Moral attacks imply that the target is deceptive/corrupt/unethical and deliberately harms others.
The third type is circumstantial. It is based on evidence of inconsistency with previous positions, convictions,
or actions. Contra van Eemeren and Grootendorst (1984, p. 190), the circumstantial ad hominem argument in
Walton’s classiﬁcation is always based on an allegation of inconsistency and not bias. Group circumstantial
arguments contrast the target’s behaviour/character with the idealized standards of the scientiﬁc/target’s com-
munity. Arguments of pragmatic/logical inconsistency claim that a target’s statement/behaviour conﬂicts with
his/her earlier statements/behaviour. Typically, this type of inconsistency takes the form of an argument that
the respondent ‘does not practice what he preaches.’
The fourth type is competence. The accuser states that target is wrong because he/she lacks knowledge/edu-
cation/competence/skill. The target is accused of making inaccurate predictions and is generally seen as
incompetent.
The ﬁfth type is guilt by association. It involves transferring alleged guilt to a person for his/her association
with a supposedly discreditable or socially demonized individual, group, or doctrine. It links the target with an
external group or individual that possesses a negative trait, thereby tarring the target with the same negative
trait.
Importantly, a single character attack often contains multiple types of ad hominems. Table 2 shows the most
common combinations of diﬀerent ad hominem attacks. The most common combination was bias and moral ad
Figure 4. Prevalence of Ad Hominem Types, 2008–2020.
CLIMATE POLICY
145

Table 2. Combination of ad hominems: prevalence, description, and examples.
Ad hominem
combinations
% of
paragraphs
Description
Examples
Bias, moral
29.8%
Claiming bias among climate scientists or
advocates for climate action motivated them
to commit immoral acts.
.
Deception (‘ … alarmists will go to incredible
lengths to manipulate and misrepresent objective
scientiﬁc facts for the cause of promoting their
alarmist Climate Delusion’)
.
Proﬁting from the climate issue (‘All of them have
turned their fearmongering to quite some
business’)
.
Impinging on citizens’ freedoms (‘Alarmists want to
impose a tyranny on others’).
Bias,
circumstantial
25.3%
Referring to external inconsistency (e.g. being
out of line with scientiﬁc standards) or internal
inconsistency (e.g. not practicing what one
preaches).
.
Comparing the climate movement to an objective
scientiﬁc approach (‘such attribution is more faith-
based than science-based’, ‘Climate change
alarmism is based entirely on speculation, not on
science’, ‘global warming advocates are more
interested in pushing a political agenda than actual
science’, ‘propagandists, not scientists’)
.
Pithy labels (‘junk science’, ‘anti-science’) combined
with bias attacks in the form of single words or
short phrases (‘alarmist pseudoscientiﬁc hype’).
.
Contrast with idealized behaviour was also applied
to other targets such as media outlets, accusing
them of bias (‘ … they don’t gather news and
information or present views with due
impartiality’).
Moral,
circumstantial
17.2%
Contrasting a moral scientiﬁc standard with
accusations of immoral activities by climate
scientists
.
Deception (‘Climate scientists are not scientists.
They are professional fraudsters’)
.
Fabricating data (‘replacing evidence-based policy-
making with policy-based evidence-making’)
.
Proﬁting (‘Climate science is not a science. It is a
criminal venture intended to extort money from
the public’).
.
Use of air quotes to imply that the target didn’t
meet scientiﬁc standards (‘Every single thing these
‘scientists’ said was fraudulent’).
Bias, guilt by
association
15.6%
Associating the target with a biased group, in
order to paint the original target with the
same negative trait.
Listing one or more targets with general climate
‘alarmists’ (‘Climate alarmists in government
agencies, in academia, and among radical
environmental groups’, ‘will the Times and its
fellow climate alarmists … ’, ‘ … an alarmist
narrative by the UN IPCC, Al Gore and other
vested interests … ’).
A common target was scientists, typically associated
with perceived biased groups such as left-
orientated politicians (‘scientists sought political
relevance and allowed policy makers to put a big
thumb on the scale of the scientiﬁc assessment’).
Moral, guilt by
association
10.5%
Accusing two or more groups of collaborating
on immoral activities
.
Deception (‘Climate scientists, Democrats, and the
press have reacted quite predictably by simply
ramping up their lies’, ‘ … an alarmist narrative by
the UN IPCC, Al Gore and other vested interests is
exposed as a deliberate misrepresentation of data
… ’)
.
Censoring or suppressing dissenting voices (‘ …
the BBC gathered a group of like-minded elite
(Continued)
146
S. A. SAMOILENKO AND J. COOK

hominems, reﬂecting the prevalence of the individual ad hominems. For all of the top ﬁve combinations, there is
a strong correlation between paragraphs that feature a combination and the individual ad hominems. For
example, there is a strong correlation between the presence of bias ad hominems and bias-plus-moral combi-
nations, r(551) = .38, p < .001, and a similarly strong correlation between the presence of moral ad hominems
and bias-plus-moral combinations, r(551) = .68, p < .001.
The next four most common combinations were structural ad hominems (e.g. circumstantial or guilt by
association) with ad hominems used to paint a particular negative trait (e.g. bias or immoral). Of these, the
most common combination was circumstantial ad hominems used to portray bias, followed by circumstantial
ad hominems used to paint a target as immoral. The fourth most common ad hominem combination was guilt
by association and bias, while the ﬁfth most common was guilt by association and immorality.
5. Discussion
In the present study, we identiﬁed the diﬀering types of ad hominem arguments used by contrarians in their
attacks on climate scientists. The three dominant arguments revealed in this study – attacks on scientists’ mor-
ality, alleged bias, and inconsistent behaviour (circumstantial guilt) – overlap with the similar categories
suggested by Walton (1998, p. 211) as fundamental to political debates. Bias attacks – accusing climate scien-
tists of political partisanship or ideological agendas – were found to be the most common form of contrarian ad
hominem, followed by attacks on scientists’ morality and accusations of inconsistent behaviour, respectively.
Guilt by association and attacks on competence appeared less frequently in contrarian climate-related
materials.
The study revealed the prevalence of ad hominem attacks over time, showing that they have been used
stably and consistently in the materials produced by contrarian think tanks. This supports previous ﬁndings
by Coan et al. (2021) demonstrating the steady prominence of character assassination as a contrarian strategy
in climate-related misinformation campaigns.
Ad hominem attacks are instrumental for contrarians because they shift the dialogue from a critical discus-
sion (which has a particular set of rules for debate) to a bargaining type of dialogue (with a diﬀerent set of rules)
in which the accused party must defend himself/herself and win over public opinion (Walton, 1998). Hence, ad
hominem attacks may lower the perceived status diﬀerences between the scientist and the rest of the public.
The dominance of bias ad hominems can be explained by the strong relevance of bias to scientiﬁc credibility.
The science – policy relationship requires trust between climate scientists and policymakers; this is often based
on the validity of evidence, which in turn depends on the appropriate application of scientiﬁc methods and
reporting of research ﬁndings (Lacey et al., 2018).
Table 2. Continued.
Ad hominem
combinations
% of
paragraphs
Description
Examples
greenies together and in secret session decided to
limit any reporting of science that suggested global
warming … was not caused predominately by CO2
… ’)
.
Proﬁting (‘ … various parasitical academics,
researchers, propagandists and otherwise
unemployable environmental studies graduates
and postgraduates on the climate change gravy
train’).
.
During the COVID-19 pandemic, health scientists
were also associated with climate scientists in order
to paint them with the same negative traits
(‘scientiﬁc dissent is not only being suppressed and
marginalized in Germany when it comes to climate
science but with virology and public health’).
CLIMATE POLICY
147

Accusations of bias challenge the authority of a speaker, thereby undercutting those arguments that depend
for their credibility on the expertise of the speaker (Macagno, 2013). If scholars are perceived as lacking objec-
tivity and as driven by extrinsic motivation, then they are not regarded as scientists and their advice is no longer
compelling. According to Walton (1998), bias ad hominems not only call into question a target’s impartiality, but
also attack the sincerity of the target’s participation in the collaborative dialogue. This supports the obser-
vations made by Gierth and Bromme (2020), who found that online comments attacking the motivations of
scientists were eﬀective in lowering scientists’ perceived integrity.
With so many science-based challenges facing the world, researchers – more than ever before – have a
responsibility to make the public and policymakers aware of their research (Woolston, 2016). There is disagree-
ment among scholars as to whether scientists can advocate in some contexts without reputational harm. Some
studies suggest that climate scientists who wish to engage in certain forms of advocacy have considerable lati-
tude to do so without risking harm to either their own credibility or the credibility of the scientiﬁc community
(Kotcher et al., 2017). Other studies indicate that overt displays of science advocacy may harm public percep-
tions because values generally cannot be eliminated from science (Gray & Campbell, 2009).
Taking a stand perceived as political may negatively aﬀect a researcher’s credibility in the eyes of the general
public. In the United States, surveys have found wide political diﬀerences on attitudes related to the environ-
ment, climate change, and energy, with Democrats and Republicans having diﬀerent degrees of faith in scien-
tists’ ability to be unbiased. Moreover, no more than two in ten Americans believe scientists are transparent
about potential conﬂicts of interest with industry all or most of the time (Funk et al., 2019). Awareness that
scientists receive funding for research has been shown to harm public trust in science (Critchley & Nicol,
2011; Hargreaves et al., 2003).
In addition, allegations of immorality and inconsistent behaviour (circumstantial ad hominem) were found to
be popular techniques of contrarian climate-related communication in this study. According to Walton (1998),
the public perception of scientists is often based on their social role and ability to demonstrate a stable com-
mitment to objective and value-free research. Any perceived violation of this commitment results in group cir-
cumstantial ad hominem, contrasting the target with the idealized behaviour of the scientiﬁc community to
which they belong. Some argue that when they ‘disregard scientiﬁc norms, scientists allow themselves to
become accomplices in the restriction of individual freedom and expansion of government control over
people’s lives’ (Knight & Greenberg, 2011, p. 336).
Some guilt-by-association attacks detected in the sample (e.g. Reductio ad Hitlerum) were used together
with other types of attacks, such as direct (abusive) personal attacks. This type of ad hominem was infrequent
compared to other categories. Most guilt by association attacks were equivocal, conspiratorial, and designed to
allow loyal supporters to conﬁrm their biases. Unfortunately, the argumentation literature does not provide a
detailed account of such combinations. Walton (1998) brieﬂy addresses the possibility of complex ad hominems
in the persuasion dialogues common in legal trials and political debates. He says that these attacks appear to be
elaborately prepared and to combine argumentation strategies that can be used simultaneously with loaded
and leading questions, push polls, and other tricks. In a similar vein, Macagno (2013) concludes that ad
hominem arguments should be considered as multifaceted and complex strategies that involve not a simple
argument but several tactics in combination.
In our study, accusations of incompetence were found to be less prevalent than the other three categories of
ad hominems discussed above. In this respect, it diverges from the ﬁndings of Knight and Greenberg (2011),
who demonstrated the popularity of adversarial framing targeting the expertise of participants in climate-
related debates. This discrepancy can be explained by the departure of CTTs from their original strategies –
which were based on participating in scientiﬁc debates and attacking policies and data – in favour of post-
truth politics, misinformation, and character assassination (Oreskes & Conway, 2010).
Future research oﬀers several promising lines of development. First, there is a need for experimentation
testing the eﬀectiveness of diﬀerent types of ad hominems, including those containing combined character
attacks. Clustered attacks require solid empirical investigation, especially in the context of interactive online
debates featuring diﬀerent levels of discursive complexity (Habernal et al., 2018). Sequential combination
attacks are examples of what we describe as Tetris character assassination. Just as Tetris games feature diﬀer-
ently conﬁgured tetromino pieces that accumulate and intertwine, solidifying into an ever-growing structure,
148
S. A. SAMOILENKO AND J. COOK

ad hominem attacks can be conﬁgured in diﬀerent combinations and multiple attacks can accumulate to build a
negative picture of the target. What reinforcing eﬀect might multiple ad hominem combinations have on
audiences?
Second, experimentation should test diﬀerent interventions to neutralize ad hominems through either
inoculation or reactive corrections. Preemptive inoculation has been found to be an eﬀective strategy for coun-
tering climate change misinformation (Cook, 2019). Alternatively, future research could address the application
of Walton’s argumentation schemes featuring a set of appropriate critical questions for debunking climate mis-
information (Walton, 1998). This process of deconstruction may weaken the intended eﬀect of complex attacks.
These schemes can be used both to identify fallacies and to respond to both sound and fallacious arguments.
Third, machine learning could be better utilized as a tool for detecting and categorizing ad hominem attacks
in online misinformation. Machine-learning models have already been eﬀective in detecting climate misinfor-
mation (Coan et al., 2021). There have also been attempts to automate the detection of logical fallacies, with ad
hominems notably among the fallacies that machines detect most reliably (Habernal et al., 2018). As climate
misinformation on online platforms is a big-data problem, machine learning oﬀers fruitful avenues for improv-
ing our understanding and real-time detection of ad hominem attacks in this context.
6. Conclusion
Ad hominem attacks against climate scientists, environmentalists, and policymakers are a dominant feature of
misinformation campaigns. Our ﬁndings suggest that responding to bias attacks should be considered a high
priority, given their prevalence and interplay with other attacks. They often act in combination with other types
of ad hominem attacks, with bias-plus-moral being the most frequent combination. These attacks have negative
consequences for climate science and climate policy, aﬀecting the credibility of scientists and their research, as
well as undermining public support for climate action. Interventions countering the inﬂuence of such ad
hominem attacks have yet to be explored in empirical studies. More research is needed to examine how char-
acter assassination strategies are employed in the climate change debate and to develop interventions that
neutralize or reverse the eﬀects of this misinformation.
Disclosure statement
No potential conﬂict of interest was reported by the author(s).
References
Atanasova, P., Nakov, P., Màrquez, L., Barrón-Cedeño, A., Karadzhov, G., Mihaylova, T. M. M., & Glass, J. (2019). Automatic fact-checking
using context and discourse information. Journal of Data and Information Quality, 11(3), 1–27. https://doi.org/10.1145/3297722
Barnes, R. M., Johnston, H. M., MacKenzie, N., Tobin, S. J., & Taglang, C. M. (2018). The eﬀect of ad hominem attacks on the evaluation
of claims promoted by scientists. PLoS ONE, 13(1), e0192025. https://doi.org/10.1371/journal.pone.0192025
Benoit, W. L. (2017). Criticism of actions and character: Strategies for persuasive attack. Extended Relevant Rhetoric, 8. https://bit.ly/
2Y0rqvC
Benoit, W. L., & Harthcock, A. (1999). Functions of the great debates: Acclaims, attacks, and defenses in the 1960 presidential debates.
Communication Monographs, 66(4), 341–357. https://doi.org/10.1080/03637759909376484
Biddle, J. B., & Leuschner, A. (2015). Climate skepticism and the manufacture of doubt: Can dissent in science be epistemically detri-
mental? European Journal for Philosophy of Science, 5(3), 261–278. https://doi.org/10.1007/s13194-014-0101-x
Blair, J. A., & Johnson, R. H. (2006). Logical self-defense. International Debate Education Association.
Boussalis, C., & Coan, T. G. (2016). Text-mining the signals of climate change doubt. Global Environmental Change, 36, 89–100. https://
doi.org/10.1016/j.gloenvcha.2015.12.001
Campbell, J. L., Quincy, C., Osserman, J., & Pedersen, O. K. (2013). Coding in-depth semi-structured interviews: Problems of unitization
and intercoder reliability and agreement. Sociological Methods & Research, 42(3), 294–320. https://doi.org/10.1177/
0049124113500475
Cann, H. W. (2015, April). Climate change, still challenged: Conservative think tanks and skeptic frames. In Annual Meeting of the
Western Political Science Association Las Vegas. http://www.wpsanet.org/papers/docs/wpsa15%20-%20cann.pdf
Coan, T. G., Boussalis, C., Cook, J., & Nanko, M. O. (2021). Computer-assisted classiﬁcation of contrarian claims about climate change.
Scientiﬁc Reports, 11(1), 22320. https://doi.org/10.1038/s41598-021-01714-4
CLIMATE POLICY
149

Cook, J. (2019). Understanding and countering misinformation about climate change. In I. E. Chiluwa, & S. A. Samoilenko (Eds.),
Handbook of research on deception, fake news, and misinformation online (pp. 281–306). IGI Global.
Cook, J., Ellerton, P., & Kinkead, D. (2018). Deconstructing climate misinformation to identify reasoning errors. Environmental Research
Letters, 13(2), 024018. https://doi.org/10.1088/1748-9326/aaa49f
Critchley, C. R., & Nicol, D. (2011). Understanding the impact of commercialization on public support for scientiﬁc research: Is it about
the funding source or the organization conducting the research? Public Understanding of Science, 20(3), 347–366. https://doi.org/
10.1177/0963662509346910
DeAngelis, C. (2000). Conﬂict of interest and the public trust. Journal of the American Medical Association, 284(17), 2237–2238. https://
doi.org/10.1001/jama.284.17.2237
Delobelle, P., Cunha, M., Cano, E. M., Peperkamp, J., & Berendt, B. (2019). Computational ad hominem detection. In Proceedings of the
57th conference of the association for computational linguistics: Student research workshop (pp. 203–209). Association for
Computational Linguistics.
Druckman, J. N. (2001). On the limits of framing eﬀects: Who Can frame? The Journal of Politics, 63(4), 1041–1066. http://www.jstor.
org/stable/2691806
Elsasser, S. W., & Dunlap, R. E. (2013). Leading voices in the denier choir: Conservative columnists’ dismissal of global warming and
denigration of climate science. American Behavioral Scientist, 57(6), 754–776. https://doi.org/10.1177/0002764212469800
Erlingsson, C., & Brysiewicz, P. (2017). A hands-on guide to doing content analysis. African Journal of Emergency Medicine, 7(3), 93–99.
https://doi.org/10.1016/j.afjem.2017.08.001
Farrell, J. (2016). Network structure and inﬂuence of the climate change counter-movement. Nature Climate Change, 6(4), 370–374.
https://doi.org/10.1038/nclimate2875
Farrell, J. (2019). The growth of climate change misinformation in US philanthropy: Evidence from natural language processing.
Environmental Research Letters, 14(3), 034013. https://doi.org/10.1088/1748-9326/aaf939
Funk, C., Heﬀeron, M., Kennedy, B., & Johnson, C. (2019, August 2). Trust and mistrust in Americans’ views of scientiﬁc experts. Pew
Research Center. https://pewrsr.ch/2AP4tl
Gierth, L., & Bromme, R. (2020). Attacking science on social media: How user comments aﬀect perceived trustworthiness and credi-
bility. Public Understanding of Science, 29(2), 230–247. https://doi.org/10.1177/0963662519889275
Gray, N. J., & Campbell, L. M. (2009). Science, policy advocacy, and marine protected areas. Conservation Biology, 23(2), 460–468.
https://doi.org/10.1111/j.1523-1739.2008.01093.x
Gwet, K. L. (2014). Handbook of inter-rater reliability: The deﬁnitive guide to measuring the extent of agreement among raters. Advanced
Analytics, LLC.
Habernal, I., Wachsmuth, H., Gurevych, I., & Stein, B. (2018). Before name-calling: Dynamics and triggers of ad hominem fallacies in web
argumentation. arXiv preprint arXiv:1802.06613.
Hargreaves, I., Lewis, J., & Spears, T. (2003). Towards a better map: Science, the public and the media. Economic and Social Research
Council.
Jacques, P. J., Dunlap, R. E., & Freeman, M. (2008). The organisation of denial: Conservative think tanks and environmental scepticism.
Environmental Politics, 17(3), 349–385. https://doi.org/10.1080/09644010802055576
Jacques, P. J., & Knox, C. C. (2016). Hurricanes and hegemony: A qualitative analysis of micro-level climate change denial discourses.
Environmental Politics, 25(5), 831–852. https://doi.org/10.1080/09644016.2016.1189233
Jasny, L., Dewey, A. M., Robertson, A. G., Yagatich, W., Dubin, A. H., Waggle, J. M., & Fisher, D. R. (2018). Shifting echo chambers in US
climate policy networks. PLoS ONE, 13(9), e0203463. https://doi.org/10.1371/journal.pone.0203463
Knight, G., & Greenberg, J. (2011). Talk of the enemy: Adversarial framing and climate change discourse. Social Movement Studies, 10
(4), 323–340. https://doi.org/10.1080/14742837.2011.614102
Kotcher, J. E., Myers, T. A., Vraga, E. K., Stenhouse, N., & Maibach, E. W. (2017). Does engagement in advocacy hurt the credibility of
scientists? Results from a randomized national survey experiment. Environmental Communication, 11(3), 415–429.
Krippendorﬀ, K. (2013). Content analysis: An introduction to its methodology. Sage.
Lacey, J., Howden, M., Cvitanovic, C., & Colvin, R. M. (2018). Understanding and managing trust at the climate science–policy inter-
face. Nature Climate Change, 8(1), 22–28. https://doi.org/10.1038/s41558-017-0010-z
Lewandowsky, S., Oreskes, N., Risbey, J. S., Newell, B. R., & Smithson, M. (2015). Seepage: Climate change denial and its eﬀect on the
scientiﬁc community. Global Environmental Change, 33, 1–13. https://doi.org/10.1016/j.gloenvcha.2015.02.013
Lewandowsky, S., Pilditch, T. D., Madsen, J. K., Oreskes, N., & Risbey, J. S. (2019). Inﬂuence and seepage: An evidence-resistant minority
can aﬀect public opinion and scientiﬁc belief formation. Cognition, 188, 124–139. https://doi.org/10.1016/j.cognition.2019.01.011
Macagno, F. (2013). Strategies of character attack. Argumentation, 27(4), 369–401. https://doi.org/10.1007/s10503-013-9291-1
Marcia, J. E. (1966). Development and validation of ego- identity status. Journal of Personality and Social Psychology, 5(5), 551–558.
https://doi.org/10.1037/h0023281
McCright, A. M., & Dunlap, R. E. (2010). Anti-reﬂexivity. Theory, Culture & Society, 27(2-3), 100–133. https://doi.org/10.1177/
0263276409356001
McLean, K. C., & Syed, M. (2015). The ﬁeld of identity development needs an identity: An introduction to The Oxford handbook of
identity development. In K. C. McLean & M. Syed (Eds.), The Oxford handbook of identity development (pp. 1–10). Oxford University
Press.
Minot, W. S. (1981). A rhetorical view of fallacies: Ad hominem and ad populum. Rhetoric Society Quarterly, 11(4), 222–235. https://doi.
org/10.1080/02773948109390615
150
S. A. SAMOILENKO AND J. COOK

Oreskes, N., & Conway, E. (2010). Merchants of doubt. Bloomsbury.
Petkevic, V., & Nai, A. (2022). Political attacks in 280 characters or less: A new tool for the automated classiﬁcation of campaign nega-
tivity on social media. American Politics Research, 50(3), 279–302. https://doi.org/10.1177/1532673X211055676
Pfau, M., & Kenski, H. C. (1990). Attack politics: Strategy and defense. Praeger.
Ranney, M. A., & Clark, D. (2016). Climate change conceptual change: Scientiﬁc information Can transform attitudes. Topics in
Cognitive Science, 8(1), 49–75. https://doi.org/10.1111/tops.12187
Samoilenko, S. A., & Jasper, J. M. (2023). The implications of character assassination and cancel culture for public relations theory. In C.
Botan & E. J. Sommerfeldt (Eds.), Public relations theory III (pp. 452–469). Routledge.
Sharman, A. (2014). Mapping the climate sceptical blogosphere. Global Environmental Change, 26, 159–170. https://doi.org/10.1016/j.
gloenvcha.2014.03.003
Syed, M., & Nelson, S. C. (2015). Guidelines for establishing reliability when coding narrative data. Emerging Adulthood, 3(6), 375–387.
https://doi.org/10.1177/2167696815587648
Tedesco, J. C., & Dunn, S. W. (2019). Political advertising in the 2016 U.S. Presidential election: Ad hominem ad nauseam. American
Behavioral Scientist, 63(7), 935–947. https://doi.org/10.1177/0002764218756919
Treen, K. M. D. I., Williams, H. T., & O’Neill, S. J. (2020). Online misinformation about climate change. Wiley Interdisciplinary Reviews:
Climate Change, 11(5), e665.
van der Linden, S., Leiserowitz, A., Rosenthal, S., & Maibach, E. (2017). Inoculating the public against misinformation about climate
change. Global Challenges, 1(2), 1600008. https://doi.org/10.1002/gch2.201600008
van Eemeren, F. H., & Grootendorst, R. (1984). Speech acts in argumentative discussions. Foris Publications.
Walton, D. (1998). Ad hominem arguments. University of Alabama Press.
Walton, D. (1999). Ethotic arguments and fallacies: The credibility function in multi-agent dialogue systems. Pragmatics and
Cognition, 7(1), 177–203. https://doi.org/10.1075/pc.7.1.08wal
Walton, D. (2002). Informal logic. A pragmatic approach. Cambridge University Press.
Walton, D. (2005). Argumentation methods for artiﬁcial intelligence in law. Springer.
Walton, D. (2017). The slippery slope argument in the ethical debate on genetic engineering of humans. Scientiﬁc Engineering Ethics,
23(6), 1507–1528. https://doi.org/10.1007/s11948-016-9861-3
Walton, D., & Macagno, F. (2015). The importance and trickiness of deﬁnitional strategies in legal and political argumentation. Journal
of Politics and Law, 8(1), 137–148. https://doi.org/10.5539/jpl.v8n1p137
Walton, D., Reed, C., & Macagno, F. (2008). Argumentation schemes. Cambridge University Press.
Wohn, D. Y., & Normile, D. (2006). Prosecutors allege elaborate deception and missing funds. Science, 312(5776), 980–981. https://doi.
org/10.1126/science.312.5776.980
Wongpakaran, N., Wongpakaran, T., Wedding, D., & Gwet, K. L. (2013). A comparison of Cohen’s Kappa and Gwet’s AC1 when calcu-
lating inter-rater reliability coeﬃcients: A study conducted with personality disorder samples. BMC Medical Research Methodology,
13(1), 1–7. https://doi.org/10.1186/1471-2288-13-61
Woolston, C. (2016). Science advocacy: Get involved. Nature, 540(7634), 611–612. https://doi.org/10.1038/nj7634-611a
Xifra, J. (2016). Climate change deniers and advocacy: A situational theory of publics approach. American Behavioral Scientist, 60(3),
276–287. https://doi.org/10.1177/0002764215613403
CLIMATE POLICY
151

