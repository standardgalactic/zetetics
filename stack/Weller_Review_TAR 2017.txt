BOOK REVIEW
The rationality quotient: toward a test of rational thinking, by Keith E.
Stanovich, Richard F. West, and Maggie E. Toplak, Cambridge, MA: The MIT
Press. 480pp. ISBN: 0262034840, 9780262034845. $39.00 USD (hbk)
As a graduate student in the early 2000s, I was ﬁrst introduced to Keith Stanovich's
book, Who is rational? studies of individual differences in reasoning by Keith Stanovich
(1999). It left an indelible mark in my research career, reinforcing and encouraging
ideas to meld the behavioural decision-making literature with individual differences
research. Until that time, this path had rarely been explored in the judgement and
decision-making ﬁeld; work was beginning to emerge, but the ﬁeld was signiﬁcantly
embedded in paradigms that involved between-subjects designs that treated vari-
ability more as error variance than potentially meaningful individual differences.
Stanovich and Richard West were early pioneers in this ﬁeld, creating a space for
aspiring young researchers to conduct research and begin to test the degree to
which individual differences in rational thinking exist, how different types of norma-
tive violations relate to one another, and whether the assessment of these individ-
ual differences predict real-world outcomes. In their new offering, The rationality
quotient: toward a test of rational thinking, Keith Stanovich, Richard West and Mag-
gie Toplak signiﬁcantly expand on this idea, not only summarising past work in the
ﬁeld, but also proposing a comprehensive new instrument to measure individual
differences in rational thinking. This book highlights an impressive body of work
undertaken in their laboratory, designed to address these research questions. I feel
that this book will encourage researchers, both established and new to the ﬁeld, to
consider individual differences in rational responding as an important factor that
has the ability to predict well-being across a variety of contexts, both at the per-
sonal and the societal levels.
The over-arching aim of this book is to establish the groundwork for an objec-
tive performance test of rational responding, an important component of thinking
skills that is believed to be overlooked by standard IQ tests. Such an endeavour is
challenging because of the multiple questions it needs to address, for instance:
What is the theoretical rationale for such a test? What components to include?
How to measure them? What is the phenotypic structure of rationality? The Ratio-
nality Quotient is comprehensive in its scope and aims to answer these questions.
They present a thorough theoretical rationale for a “Comprehensive Assessment
of Rational Thinking test (CART)” as a broad measure of rational thinking tenden-
cies, as well as empirical evidence that highlights the utility of such a test.
As with the development of any psychometric test, the ultimate aim is to con-
tinually establish construct validity. Cronbach and Meehl's (1955) original concep-
tualisation included three major steps to (1) establish theoretical concepts and
how they relate to one another, (2) develop ways to measure these concepts, and
(3) assess the hypothesised relationships between these concepts. Messick (1989)
THINKING & REASONING, 2017
VOL. 23, NO. 4, 497–502

further expanded on the necessities for establishing construct validity, proposing
that a test should be evaluated in terms of six criteria. First, the test must be
grounded in sound theory. As a necessary ﬁrst step in developing a new individual
differences scale, the test developer must clearly, conceptually deﬁne the con-
struct. Second, a test's content must reasonably match the theory of interest. After
all, a psychological test can be considered a test of theory. Third, tests should
exhibit structural validity; that is, the tested concepts should relate with one
another in theoretically predicted ways. Fourth, a test should demonstrate theo-
retically relevant convergent, discriminant and predictive validity. Fifth, the test
should be generalisable across different settings and groups. Finally, Messick
argued that a test should establish consequential validity. In other words, what
are the potential consequences of interpreting a test score, both positive and neg-
ative? If there are risks, then do the beneﬁts of a score outweigh the potential neg-
ative consequences of inappropriate interpretations or uses of test scores? Of
course, these criteria cannot be met by any single study or one research group.
Instead, the development of a new test, and a corresponding evaluation of con-
struct validity emerges as a new empirical journey undertaken by researchers and
theorists from a multitude of disciplines. With this in mind, The Rationality Quo-
tient aptly recognises this reality.
The Rationality Quotient ﬂows from the broad theory underlying the development
of the CART to empirical evidence that supports the test's external validity. Section
one provides a theoretical basis for the CART development, and detailed explanation
of particular theoretical subcomponents that may drive different irrational responses.
Grounded in dual-process theory, the authors distinguish between assessments of
rationality and intelligence, and highlight the need for tests of the former. In their the-
oretical conceptualisation, they propose moving towards a tripartite model of dual
processes, which separates “System 2” processing, into a reﬂective and algorithmic
mind, in addition to System 1 processes that encompass the automatic mind. Accord-
ing to the authors, this distinction in System 2 is vital for conceptualising individual
differences in rational thought, and distinguishing it from the type of mental abilities
that are assessed in intelligence tests. Whereas the algorithmic level refers to how
information processing systems of the mind (e.g., perceptions, motor responses,
working memory, etc.) contribute to behaviour, the reﬂective mind corresponds with
why an individual engages in such a behaviour. The reﬂective system is concerned
with making choices consistent with one's goals, motivations and beliefs. Rationality,
in the eyes of Stanovich and colleagues, arises from effective functioning in all con-
ceptualisations of the mind in the tripartite model. However, existing tests of intelli-
gence heavily assess the performance and capacity of the algorithmic mind, leaving
individual differences in reﬂective and automatic mind performance to be under-rep-
resented in traditional measures of general mental ability. It is this lack of content cov-
erage in current intelligence tests that motivates the group to develop this new
comprehensive assessment tool.
Building from this tripartite model, the authors then work towards outlining a
taxonomy of thinking errors with two broad categories, expanding on an earlier
theoretical taxonomy of thinking biases (Stanovich, Toplak, & West, 2008). The
miserly processing category can be further delineated into three qualitatively
498
BOOK REVIEW

different forms, involving (a) the detection of conﬂicting responses (e.g., responses
on the Cognitive Reﬂection Task; Frederick, 2005), (b) failure to override an auto-
matic response (e.g., syllogistic reasoning problems), and (c) relying too much on
the given context, which Stanovich et al. refer to as “serial associative cognition
with a focal bias (e.g., framing and anchoring effects). Similarly, irrational thought
that results from the second category, mindware problems, can arise from multiple
sources, including “gaps” in knowledge that may help to rationally answer a prob-
lem, or “contaminated mindware” that may promote irrational thought, such as
anti-science attitudes or superstitious thinking. Additionally, the Rationality Quotient
takes care to distinguish these sources of thinking errors from “thinking disposi-
tions” (e.g., Actively Open-minded Thinking; Baron, 1985; Stanovich & West, 2007).
Thinking dispositions refer to relatively stable cognitive styles reﬂecting, for
instance, one's tendency to deliberate on problems (vs. to act impulsively), or to
enjoy engaging in complex and effortful cognitive activities (i.e., Need for Cognition;
Cacioppo, Petty, Feinstein, & Jarvis, 1996). These tendencies, however, are not direct
measures of rationality, argues the authors, as they do not reﬂect maximising ten-
dencies directly. Chapter 11 details this proposed difference, and provides detailed
rationale for the inclusion of these dispositional measures. In order to gain a
broader picture of an individual's propensity to think rationally, the authors advo-
cate for administering four supplemental scales which reﬂect individual differences
in the tendency to (a) think ﬂexibly (Actively Open-Minded Thinking), (b) engage in
deliberative thought, (c) think about the future (Strathman, Gleicher, Boninger, &
Edwards, 1994), and (d) clearly identify and describe one's own feelings (similar to
Alexithymia scales; Bagby, Parker, & Taylor, 1994).
In Section two of the Rationality Quotient, the authors detail the creation of the
CART. The chapters in this section comprehensively detail the rationale for the
inclusion of particular indicators for each subcomponent of the CART, as well as
information about the psychometric properties of the tests. Scaffolding the tests
off their theoretical taxonomy of biases, they propose several subtests to measure
different components of rational thinking. The complete version of the CART
includes 20 subtests, along with four thinking disposition scales, and takes
approximately three hours to complete the entire assessment. The subtests
include competencies such as the avoidance of miserly processing (e.g., belief
bias, framing effects, temporal discounting), probabilistic and statistical reasoning,
scientiﬁc reasoning, numeracy, expected value sensitivity and tests assessing con-
taminated mindware (e.g., superstitious thinking, conspiratorial beliefs). In addi-
tion to the extensive descriptions of the subtests, this section highlights the
complexities involved with developing an individual difference measure that
effectively assesses rationality from a broad perspective. One of the main chal-
lenges of developing such a test has been the ability to adopt paradigms that
were traditionally assessed between-subjects; one must have conﬁdence that
administering them in within-subject design has the ability to elicit the same
effect without changing the psychological nature of the task (e.g., changing a
serial associative processing task into a response consistency task, as might hap-
pen in an anchoring paradigm; p. 149). Throughout this section, the authors dis-
cuss this important, and often under-appreciated, issue.
THINKING & REASONING
499

Section three shifts the discussion of the CART into an empirical examination of
the test. Chapters 12 and 13 are data-intensive and focus on an abbreviated form
of the CART. The creation, and subsequent validation, of an abbreviated CART is
an issue of vital importance. Although more details regarding the short-form
development would have been informative, overall, these chapters offer the
promise for a more practical measure that would increase the opportunity for test
use in experimental settings. The short-form assessment, which takes less than
two hours to complete, reduces the time spent on the full version by an hour, and
demonstrated comparable convergent validity with hypothesised variables of
interest, such as SAT scores and Actively Open-Minded Thinking (e.g., Baron,
1985) scores. Chapter 13 offers an empirical look at the full version of the CART,
providing descriptive statistics, correlations with theoretically related constructs
such as thinking dispositions, and gender differences.
The Rationality Quotient concludes with an engaging discussion about future
directions and important caveats (Chapter 14) as well as the social and practical
implications of a test (Chapter 15). I found these chapters to be particularly infor-
mative with respect to measurement issues and psychometric challenges that
arise when developing an assessment of this nature. Moreover, the authors
acknowledge other approaches to measure individual differences in “rational
thinking”, such as the Adult Decision Making Competence (Bruine de Bruin,
Parker, & Fischhoff, 2007) and the Halpern Critical Thinking Assessment (Halpern,
2010). In their discussion, they compare and contrast the CART with these assess-
ment batteries, highlighting the similarities between the measures, and how the
CART may represent an extension from these tests. Further, the authors address
other caveats that are equally as important. For instance, the authors raise an
important issue regarding whether rational thinking measures should be consid-
ered formative (i.e., a construct in which indicators, that may or may not be associ-
ated with one another, are combined to form an index, similar to an index of
socio-economic status) or reﬂective (i.e., a latent variable model in which variation
in the latent construct is believed to “cause” variation in the indicators, similar to a
personality trait). This discussion has implications for how the ﬁeld conceptualises
individual differences in rationality, how the tests are interpreted and its predic-
tive validity. Importantly, the authors make a point that psychometric issues con-
cerning the phenotypic structure of rational thinking skills should not supersede
the practical and theoretical importance of the concept (p. 286). Future research
and debate will accompany psychometric issues, and this should be seen as prog-
ress in order to reﬁne the measurement of a construct that has a great deal of
practical signiﬁcance.
In Chapter 15, the authors discuss the broader implications of developing a
rational thinking test. Ultimately, a psychological test and its components should
demonstrate predictive validity. Stanovich and colleagues summarise the associa-
tions between measures related to the CART components and real-life outcomes,
building their case for predictive validity of these component tasks. Although
sometimes critiqued for being too artiﬁcial in nature, emerging evidence suggests
that individual differences in rational thinking have real-life implications. These
outcomes can be at the individual level, affecting one's ﬁnancial, health or
500
BOOK REVIEW

psychosocial well-being. Even more broadly, irrational thinking may have impacts
at the societal level. For example, inaccurate risk knowledge (e.g., assuming that
risks and beneﬁts are inversely related, overweighting rare events or neglecting
that some risks may be dose-dependent) may lead to either an over-reaction or
inaction. Inaccurate risk assessment may lead to wasting valuable and ﬁnite
resources in order to eliminate a highly unlikely risk, when it could have been
used to mitigate a hazard that potentially affects more individuals. In addition to
the impact of incorrect risk assessment, this concluding chapter offers other
examples that help illustrate the utility of assessing individual differences in ratio-
nality. Understanding how rational responding contributes to real-world instances
of maladaptive behaviours offers the potential for more effective avenues by
which risk communication and policy efforts designed to promote health-effacing
behaviour can be developed.
This book is not merely a summary of past work or a “user's manual” for the
CART, but instead provides a space for future research in the study of individual
differences in rationality to be conducted. In their discussion, the authors are hon-
est of the limitations of the CART and provide detailed suggestions and ideas for
subsequent test development. By conducting more reﬁned psychometric analy-
ses, replicating factor structures, ﬁne-tuning measures when appropriate, and
continuing to establish its construct validity, researchers – basic and applied alike,
will potentially have an important tool to assess individual differences in rational
thinking. In sum, The Rationality Quotient provides an excellent starting point from
which researchers interested in the intersection between individual differences
and behavioural decision-making may launch.
References
Bagby, R. M., Parker, J. D. A., & Taylor, G. J. (1994). The twenty-item Toronto Alexithymia Scale—I.
Item selection and cross-validation of the factor structure. Journal of Psychosomatic Research,
38, 23–32.
Baron, J. (1985). Rationality and intelligence. Cambridge: Cambridge University Press.
Bruine de Bruin, W., Parker, A. M., & Fischhoff, B. (2007). Individual differences in adult deci-
sionmaking competence. Journal of Personality and Social Psychology, 92, 938–956.
Cacioppo, J. T., Petty, R. E., Feinstein, J., & Jarvis, W. (1996). Dispositional differences in cognitive
motivation: The life and times of individuals varying in need for cognition. Psychological Bulle-
tin, 119, 197–253.
Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. Psychological Bulle-
tin, 52, 281–302.
Frederick, S. (2005). Cognitive reﬂection and decision-making. Journal of Economic Perspectives, 19,
25–42.
Halpern, D. (2010). Halpern critical thinking assessment: Manual version 21 (3rd ed.). Modling: Schul-
fried GmbH.
Messick, S. (1989). Validity. In R. L. Linn (Ed.), Educational measurement (1st ed., pp. 13–103). New
York, NY: Macmillan.
Stanovich, K. E. (1999). Who is rational? Studies of individual differences in reasoning. Mahwah, NJ:
Lawrence Erlbaum.
Stanovich, K. E., Toplak, M. E., & West, R. F. (2008). The development of rational thought: A taxon-
omy of heuristics and biases. In R. V. Kail (Ed.), Advances in child development and behavior
(Vol 36, pp. 251–285). San Diego, CA: Elsevier Academic Press.
THINKING & REASONING
501

Stanovich, K. E., & West, R. F. (2007). Natural myside bias is independent of cognitive ability. Think-
ing & Reasoning, 13, 225–247.
Strathman, A., Gleicher, F., Boninger, D. S., & Edwards, C. S. (1994). The consideration of future con-
sequences: Weighing immediate and distant outcomes of behavior. Journal of Personality and
Social Psychology, 66, 742–752.
Joshua Weller
School of Social and Behavioral Sciences,
Tilburg University, Tilburg, The Netherlands
J.A.Weller@uvt.nl
© 2017 Informa UK Limited, trading as Taylor & Francis Group
https://doi.org/10.1080/13546783.2017.1346521
502
BOOK REVIEW

