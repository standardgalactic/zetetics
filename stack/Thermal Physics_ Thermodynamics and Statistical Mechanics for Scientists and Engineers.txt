
Thermal Physics


Thermal Physics
Thermodynamics and Statistical Mechanics
for Scientists and Engineers
Robert F. Sekerka
Carnegie Mellon University
Pittsburgh, PA 15213, USA
AMSTERDAM • BOSTON • HEIDELBERG • LONDON • NEW YORK • OXFORD
PARIS • SAN DIEGO • SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO

Elsevier
Radarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK
225 Wyman Street, Waltham, MA 02451, USA
Copyright © 2015 Elsevier Inc. All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any means, electronic or
mechanical, including photocopying, recording, or any information storage and retrieval system, without
permission in writing from the publisher. Details on how to seek permission, further information about the
Publisher’s permissions policies and our arrangements with organizations such as the Copyright Clearance
Center and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.
This book and the individual contributions contained in it are protected under copyright by the Publisher (other
than as may be noted herein).
Notices
Knowledge and best practice in this ﬁeld are constantly changing. As new research and experience broaden our
understanding, changes in research methods, professional practices, or medical treatment may become
necessary.
Practitioners and researchers must always rely on their own experience and knowledge in evaluating and using
any information, methods, compounds, or experiments described herein. In using such information or methods
they should be mindful of their own safety and the safety of others, including parties for whom they have a
professional responsibility.
To the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors, assume any
liability for any injury and/or damage to persons or property as a matter of products liability, negligence or
otherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the
material herein.
Library of Congress Cataloging-in-Publication Data
A catalog record for this book is available from the Library of Congress
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
For information on all Elsevier publications
visit our website at http://store.elsevier.com/
ISBN: 978-0-12-803304-3

Dedication
To Care . . . .
who cared about every word
and helped me write what I meant to say
rather than what I had written
v


Table of Contents 
About the Cover 
xv 
Preface 
XVII 
PART I Thermodynamic s 
1 
Intr oduct ion 
1.1 
Temper ature 
1.2 
Thermodynamics Versus Statistical Mechanics 
1.3 
Classification of State Variables 
1.4 
Energy in Mechanics 
1.5 
Elementary Kinetic Theory 
2 
First Law of Thermodynamics 
2.1 
Statement of the First Law 
2.2 
Quasistatic Work 
2.3 
Heat Capacities 
2.4 
Work Due to Expansion of an Ideal Gas 
2.5 
Enthalpy 
3 
Second Law of Thermod ynamics 
3.1 
Statement of the Second Law 
3.2 
Carnot Cycle and Engines 
3.3 
Calculation of th e Entropy Chang e 
3.4 
Combined First and Second Laws 
3.5 
Statistical Interpretation of Entrop y 
••• 
••• 
••• 
1 
3 
3 
5 
6 
8 
12 
15 
15 
17 
19 
24 
28 
31 
32 
35 
39 
41 
47 
vii 

viii Table of Contents 
4 
Third Law of Thermodynamics 
49 
4.1 
Statement of the Third Law 
49 
4.2 
Implications of the Third Law 
50 
5 
Open Systems 
53 
5.1 
Single Component Open System 
53 
5.2 
Multicomponent Open Systems 
55 
5.3 
Euler Theorem of Homogeneous Functions 
59 
5.4 
Chemical Potential of Real Gases, Fugacity 
64 
5.5 
Legen dre Transformations 
67 
5.6 
Partial Molar Quantities 
71 
5.7 
Entropy of Chemical Reaction 
75 
6 
Equilibrium and Thermodynamic Potentia ls 
79 
6.1 
Entropy Criterion 
79 
6.2 
Energy Criterion 
84 
6.3 
Other Equilibrium Criteria 
88 
6.4 
Summary of Criteria 
92 
7 
Requirements for Stabi lity 
95 
7.1 
Stability Requirements for Entrop y 
95 
7.2 
Stability Requirements for Internal Energy 
100 
7.3 
Stability Requirements for Other Potentials 
102 
7.4 
Consequences of Stability Requiremen ts 
105 
7.5 
Extension to Many Variables 
106 
7.6 
Principles of Le Chatlier and Le Chatlier-Braun 
107 
8 
Monocomponent 
Phase Equi librium 
109 
8.1 
Clausius-Clapeyron Equation 
110 
8.2 
Sketches of the Thermodynamic 
Function s 
115 
8.3 
Phas e Diagram in the v, p Plane 
118 

Table of Contents 
ix 
9 
Two -Phase Equilibrium for a van der Waa ls Fluid 
121 
9.1 
van der Waals Equation of State 
121 
9.2 
Thermodynamic Functions 
124 
9.3 
Phase Equilibrium and Miscibility Gap 
127 
9.4 
Gibbs Free Energy 
131 
10 
Binary Solutions 
137 
10.1 Thermodynamics of Binary Solutions 
137 
10.2 Ideal Soluti ons 
142 
10.3 Phase Diagram for an Ideal Solid and an Ideal Liquid 
145 
10.4 Regular Solution 
148 
10.5 General Binary Solutions 
153 
11 
Externa l Forces and Rotating Coordinate Systems 
155 
11.1 Conditions for Equilibrium 
155 
11.2 Uniform Gravitational Field 
157 
11.3 Non-Uniform Gravitational Field 
164 
11.4 Rotating Systems 
164 
11.5 Electric Fields 
166 
12 
Chemica l Reactions 
167 
12.1 Reactions at Constant Volume or Pressure 
168 
12.2 Standard States 
171 
12.3 Equilibr ium and Affinity 
173 
12.4 Explicit Equilibrium Conditions 
175 
12.5 Simul taneous Reactions 
182 
13 
Thermodynam ics of Fluid-Fluid Interf aces 
185 
13.1 Planar Interfaces in Fluids 
186 
13.2 Curved Interfaces in Fluids 
197 

x Table of Contents 
13.3 Interface Junctions and Contact Angles 
202 
13.4 Liquid Surface Shape in Gravity 
205 
14 
Thermodynamics of Solid-Flu iid Interfaces 
215 
14.1 Planar Solid-Fluid Interfaces 
216 
14.2 Anisotropy of y 
22 1 
14.3 Curved Solid-Fluid Interfaces 
227 
14.4 Faceting of a Large Planar Face 
233 
14.5 Equilibrium Shape from the~ -Vector 
236 
14.6 Herring Formula 
240 
14.7 Legendre Transform of the Equilibrium Shape 
241 
14.8 Remarks About Solid-Solid Interfaces 
242 
PART II Statistical Mechanics 
245 
15 
Entropy and Information Theory 
247 
15.1 Entropy as a Measure of Disorder 
247 
15.2 Boltzmann Eta Theorem 
251 
16 
Microcanonical Ensemble 
257 
16.1 Fundamenta l Hypothesis of Statistical Mechanics 
258 
16.2 Two-Stat e Subsystems 
261 
16.3 Harmonic Oscillators 
265 
16.4 Ideal Gas 
267 
16.5 Multicomponent Ideal Gas 
273 
17 
Classical Microcanonical Ensemble 
277 
17.1 Liouville's Theorem 
278 
17.2 Classical Microcanonical Ensemble 
280 

Tab le of Contents 
xi 
18 
Distinguishable Part icles with Negligible 
Interaction Energies 
285 
18.1 Derivation of the Boltzmann Distribution 
285 
18.2 Two-State Subsystems 
289 
18.3 Harmonic Oscillators 
293 
18.4 Rigid Linear Rotator 
303 
19 
Canonical Ensemble 
305 
19.1 Three Derivations 
305 
19.2 Factorizat ion Theorem 
312 
19.3 Classica l Idea l Gas 
313 
19.4 Maxwell-Boltzmann Distribution 
317 
19.5 Energy Dispersion 
320 
19.6 Paramagnetism 
321 
19.7 Partition Function and Densit y of States 
330 
20 
Classical Canonical Ensemble 
337 
20.1 Classical Ideal Gas 
338 
20.2 Law of Dulong and Petit 
342 
20.3 Averaging Theorem and Equipartition 
343 
20.4 Virial Theorem 
346 
20.5 Virial Coefficients 
348 
20.6 Use of Canonical Transforma tions 
354 
20.7 Rotating Rigid Polyatomi c Molecu les 
356 
21 
Grand Canonical Ensemble 
359 
21.1 Derivation from Microcanonical Ensemble 
360 
21.2 Ideal Systems: Orbitals and Factorization 
368 

xii Table of Contents 
21.3 Classical Ideal Gas with Internal Structure 
380 
21.4 Multicomponent Systems 
388 
21.5 Pressure Ensemb le 
389 
22 
Entropy for Any Ensemb le 
397 
22.1 General Ensemble 
397 
22.2 Summation over Energy Levels 
402 
23 
Unified Treatment of Idea l Fermi, Bose, and Classical Gases 
405 
23.1 Integr al Formulae 
406 
23.2 The Functions hv(A, a) 
408 
23.3 Virial Expansio ns for Ideal Fermi and Bose Gases 
410 
23.4 Heat Capacity 
412 
24 
Bose Condensat ion 
413 
24.l 
Bosons at Low Temperatures 
413 
24.2 Thermodynamic Functions 
416 
24.3 Condensate Region 
421 
25 
Degenerate Fermi Gas 
425 
25.1 Ideal Fermi Gas at Low Temperatures 
425 
25.2 Free Electron Model of a Metal 
428 
25.3 Thermal Activation of Electrons 
429 
25.4 Pauli Paramagnetism 
433 
25.5 Landau Diamagnetism 
436 
25.6 Thermionic Emission 
439 
25.7 Semiconductors 
442 
26 
Quantum Statistics 
451 
26.1 Pure States 
451 
26.2 Statistical States 
453 

Table of Contents 
xiii 
26.3 Random Phases and External Influ ence 
454 
26.4 Time Evoluti on 
455 
26.5 Densit y Operators for Specific Ensembles 
456 
26.6 Examp les of th e Density Matrix 
459 
26.7 Indi stinguishable Particles 
465 
27 
Ising Model 
469 
27.1 Ising Model, Mean Field Treatment 
470 
27.2 Pair Statistics 
477 
27.3 Soluti on in One Dimension for Zero Field 
479 
27.4 Transfer Matrix 
480 
27.5 Oth er Methods of Soluti on 
483 
27.6 Monte Carlo Simulation 
484 
PART Ill 
Appendices 
495 
A 
Stirl ing 's Approximation 
497 
A.l 
Elem entary Motivation ofEq. (A.l ) 
498 
A.2 
Asymptotic Series 
499 
B 
Use of Jacobians to Convert Partial Derivatives 
503 
B.l 
Properties of Jacobians 
503 
B.2 
Connect ion to Thermody namic s 
504 
C 
Differential Geometry of Surfaces 
509 
C.l 
Alterna tive Formulae for ~ Vector 
509 
C.2 
Surface Differe nti al Geome try 
511 
C.3 
~ Vector for Genera l Surfaces 
516 
C.4 
Herring Form ula 
518 
D 
Equilibrium of Two-State Systems 
523 

xiv Table of Contents 
E 
F 
Aspects of Canonical Transformations 
E.1 
Necessary and Sufficient Conditions 
E.2 
Restricted Canonical Transformations 
Rotation of Rigid Bodies 
El 
Moment oflnertia 
F.2 
Angular Momentum 
F.3 
Kinetic Energy 
F.4 
Time Derivatives 
F.5 
Rotating Coordinate System 
F.6 
Matrix Formulation 
F. 7 
Canonical Variables 
F.8 
Quantum Energy Levels for Diatomic Molecule 
G 
Thermodynamic Perturbation Theory 
G .1 
Classical Case 
G.2 
Quantum Case 
H 
Selected Mathematical Relations 
H.1 
Bernoulli Numbers and Polynomials 
H.2 
Euler-Maclaur in Sum Formula 
Creation and Annihilation Operators 
1.1 
Harmonic Oscillator 
1.2 
Boson Operators 
1.3 
Fermion Operators 
1.4 
Boson and Fermion Number Operators 
References 
Index 
529 
530 
534 
537 
537 
539 
540 
540 
541 
544 
546 
547 
549 
549 
550 
553 
553 
554 
559 
559 
560 
562 
563 
565 
569 

About the Cover
To represent the many scientists who have made major contributions to the foundations of
thermodynamics and statistical mechanics, the cover of this book depicts four signiﬁcant
scientists along with some equations and graphs associated with each of them.
•
James Clerk Maxwell (1831-1879) for his work on thermodynamics and especially the
kinetic theory of gases, including the Maxwell relations derived from perfect differen-
tials and the Maxwell-Boltzmann Gaussian distribution of gas velocities, a precursor of
ensemble theory (see Sections 5.2, 19.4, and 20.1).
•
Ludwig Boltzmann (1844-1906) for his statistical approach to mechanics of many
particle systems, including his Eta function that describes the decay to equilibrium
and his formula showing that the entropy of thermodynamics is proportional to the
logarithm of the number of microscopic realizations of a macrosystem (see Chapters
15–17).
•
J. Willard Gibbs (1839-1903) for his systematic theoretical development of the ther-
modynamics of heterogeneous systems and their interfaces, including the deﬁnition
of chemical potentials and free energy that revolutionized physical chemistry, as well
as his development of the ensemble theory of statistical mechanics, including the
canonical and grand canonical ensembles. The contributions of Gibbs are ubiquitous
in this book, but see especially Chapters 5–8, 12–14, 17, 20, and 21.
•
Max Planck (1858-1947, Nobel Prize 1918) for his quantum hypothesis of the energy of
cavity radiation (hohlraum blackbody radiation) that connected statistical mechanics
to what later became quantum mechanics (see Section 18.3.2); the Planck distribution
of radiation ﬂux versus frequency for a temperature 2.725 K describes the cosmic
microwave background, ﬁrst discovered in 1964 as a remnant of the Big Bang and later
measured by the COBE satellite launched by NASA in 1989.
The following is a partial list of many others who have also made major contributions
to the ﬁeld, all deceased. Recipients of a Nobel Prize (ﬁrst awarded in 1901) are denoted
by the letter “N” followed by the award year. For brief historical introductions to thermo-
dynamic and statistical mechanics, see Cropper [11, pp. 41-136] and Pathria and Beale [9,
pp. xxi-xxvi], respectively. The scientists are listed in the order of their year of birth:
Sadi Carnot (1796-1832); Julius von Mayer (1814-1878); James Joule (1818-1889);
Hermann von Helmholtz (1821-1894); Rudolf Clausius (1822-1888); William Thomson,
Lord Kelvin (1824-1907); Johannes van der Waals (1837-1923, N1910); Jacobus van’t
Hoff (1852-1911, N1901); Wilhelm Wien (1864-1928, N1911); Walther Nernst (1864-
1941, N1920); Arnold Sommerfeld (1868-1951); Théophile de Donder (1872-1957); Albert
xv

xvi
About the Cover
Einstein (1879-1955, N1921); Irving Langmuir (1881-1957, N1932); Erwin Schrödinger
(1887-1961, N1933); Satyendra Bose (1894-1974); Pyotr Kapitsa (1894-1984, N1978);
William Giauque (1895-1982, N1949); John van Vleck (1899-1980, N1977); Wolfgang Pauli
(1900-1958, N1945); Enrico Fermi (1901-1954, N1938); Paul Dirac (1902-1984, N1933);
Lars Onsager (1903-1976, N1968); John von Neumann (1903-1957); Lev Landau (1908-
1968, N1962); Claude Shannon (1916-2001); Ilya Prigogine (1917-2003, N1977); Kenneth
Wilson (1936-2013, N1982).

Preface
This book is based on lectures in courses that I taught from 2000 to 2011 in the Department
of Physics at Carnegie Mellon University to undergraduates (mostly juniors and seniors)
and graduate students (mostly ﬁrst and second year). Portions are also based on a
course that I taught to undergraduate engineers (mostly juniors) in the Department of
Metallurgical Engineering and Materials Science in the early 1970s. It began as class notes
but started to be organized as a book in 2004. As a work in progress, I made it available
on my website as a pdf, password protected for use by my students and a few interested
colleagues.
It is my version of what I learned from my own research and self-study of numerous
books and papers in preparation for my lectures. Prominent among these sources were
the books by Fermi [1], Callen [2], Gibbs [3, 4], Lupis [5], Kittel and Kroemer [6], Landau
and Lifshitz [7], and Pathria [8, 9], which are listed in the bibliography. Explicit references
to these and other sources are made throughout, but the source of much information is
beyond my memory.
Initially it was my intent to give an integrated mixture of thermodynamics and statis-
tical mechanics, but it soon became clear that most students had only a cursory under-
standing of thermodynamics, having encountered only a brief exposure in introductory
physics and chemistry courses. Moreover, I believe that thermodynamics can stand on
its own as a discipline based on only a few postulates, or so-called laws, that have stood
the test of time experimentally. Although statistical concepts can be used to motivate
thermodynamics, it still takes a bold leap to appreciate that thermodynamics is valid,
within its intended scope, independent of any statistical mechanical model. As stated by
Albert Einstein in Autobiographical Notes (1946) [10]:
“A theory is the more impressive the greater the simplicity of its premises is, the more
different kinds of things it relates, and the more extended is its area of applicability.
Therefore the deep impression which classical thermodynamics made on me. It is the
only physical theory of universal content concerning which I am convinced that within
the framework of the applicability of its basic concepts, it will never be overthrown.”
Of course thermodynamics only allows one to relate various measurable quantities to
one another and must appeal to experimental data to get actual values. In that respect,
models based on statistical mechanics can greatly enhance thermodynamics by providing
values that are independent of experimental measurements. But in the last analysis, any
model must be compatible with the laws of thermodynamics in the appropriate limit of
xvii

xviii
Preface
sufﬁciently large systems. Statistical mechanics, however, has the potential to treat smaller
systems for which thermodynamics is not applicable.
Consequently, I ﬁnally decided to present thermodynamics ﬁrst, with only a few
connections to statistical concepts, and then present statistical mechanics in that context.
That allowed me to better treat reversible and irreversible processes as well as to give a
thermodynamic treatment of such subjects as phase diagrams, chemical reactions, and
anisotropic surfaces and interfaces that are especially valuable to materials scientists and
engineers.
The treatment of statistical mechanics begins with a mathematical measure of disorder,
quantiﬁed by Shannon [48, 49] in the context of information theory. This measure is
put forward as a candidate for the entropy, which is formally developed in the context
of the microcanonical, canonical, and grand canonical ensembles. Ensembles are ﬁrst
treated from the viewpoint of quantum mechanics, which allows for explicit counting of
states. Subsequently, classical versions of the microcanonical and canonical ensembles
are presented in which integration over phase space replaces counting of states. Thus,
information is lost unless one establishes the number of states to be associated with a
phase space volume by requiring agreement with quantum treatments in the limit of high
temperatures. This is counter to the historical development of the subject, which was
in the context of classical mechanics. Later in the book I discuss the foundation of the
quantum mechanical treatment by means of the density operator to represent pure and
statistical (mixed) quantum states.
Throughout the book, a number of example problems are presented, immediately
followed by their solutions. This serves to clarify and reinforce the presentation but also
allows students to develop problem-solving techniques. For several reasons I did not
provide lists of problems for students to solve. Many such problems can be found in
textbooks now in print, and most of their solutions are on the internet. I leave it to teachers
to assign modiﬁcations of some of those problems or, even better, to devise new problems
whose solutions cannot yet be found on the internet.
The book also contains a number of appendices, mostly to make it self-contained but
also to cover technical items whose treatment in the chapters would tend to interrupt the
ﬂow of the presentation.
I view this book as an intermediate contribution to the vast subjects of thermody-
namics and statistical mechanics. Its level of presentation is intentionally more rigorous
and demanding than in introductory books. Its coverage of statistical mechanics is much
less extensive than in books that specialize in statistical mechanics, such as the recent
third edition of Pathria’s book, now authored by Pathria and Beale [9], that contains
several new and advanced topics. I suspect the present book will be useful for scientists,
particularly physicists and chemists, as well as engineers, particularly materials, chemical,
and mechanical engineers. If used as a textbook, many advanced topics can be omitted
to suit a one- or two-semester undergraduate course. If used as a graduate text, it could
easily provide for a one- or two-semester course. The level of mathematics needed in most
parts of the book is advanced calculus, particularly a strong grasp of functions of several

Preface
xix
variables, partial derivatives, and inﬁnite series as well as an elementary knowledge of
differential equations and their solutions. For the treatment of anisotropic surfaces and
interfaces, necessary relations of differential geometry are presented in an appendix. For
the statistical mechanics part, an appreciation of stationary quantum states, including
degenerate states, is essential, but the calculation of such states is not needed. In a few
places, I use the notation of the Dirac vector space, bras and kets, to represent quantum
states, but always with reference to other representations; the only exceptions are Chapter
26, Quantum Statistics, where the Dirac notation is used to treat the density operator, and
Appendix I, where creation and annihilation operators are treated.
I had originally considered additional information for this book, including more of my
own research on the thermodynamics of inhomogeneously stressed crystals and a few
more chapters on the statistical mechanical aspects of phase transformations. Treatment
of the liquid state, foams, and very small systems were other possibilities. I do not address
many-body theory, which I leave to other works. There is an introduction to Monte Carlo
simulation at the end of Chapter 27, which treats the Ising model. The renormalization
group approach is described brieﬂy but not covered in detail. Perhaps I will address some
of these topics in later writings, but for now I choose not to add to the already considerable
bulk of this work.
Over the years that I shared versions of this book with students, I received some
valuable feedback that stimulated revision or augmentation of topics. I thank all those
students. A few faculty at other universities used versions for self-study in connection with
courses they taught, and also gave me some valuable feedback. I thank these colleagues
as well. I am also grateful to my research friends and co-workers at NIST, where I have
been a consultant for nearly 45 years, whose questions and comments stimulated a lot
of critical thinking; the same applies to many stimulating discussions with my colleagues
at Carnegie-Mellon and throughout the world. Singular among those was my friend and
fellow CMU faculty member Prof. William W. Mullins who taught me by example the love,
joy and methodologies of science. There are other people I could thank individually for
contributing in some way to the content of this book but I will not attempt to present
such a list. Nevertheless, I alone am responsible for any misconceptions or outright errors
that remain in this book and would be grateful to anyone who would bring them to my
attention.
In bringing this book to fruition, I would especially like to thank my wife Carolyn for
her patience and encouragement and her meticulous proofreading. She is an attorney,
not a scientist, but the logic and intellect she brought to the task resulted in my rewriting
a number of obtuse sentences and even correcting a number of embarrassing typos and
inconsistent notation in the equations. I would also like to thank my friends Susan and
John of Cosgrove Communications for their guidance with respect to several aesthetic
aspects of this book. Thanks are also due to the folks at my publisher Elsevier: Acqui-
sitions Editor Dr. Anita Koch, who believed in the product and shepherded it through
technical review, marketing and ﬁnance committees to obtain publication approval;
Editorial Project Manager Amy Clark, who guided me though cover and format design as

xx
Preface
well as the creation of marketing material; and Production Project Manager Paul Prasad
Chandramohan, who patiently managed to respond positively to my requests for changes
in style and ﬁgure placements, as well as my last-minute corrections. Finally, I thank
Carnegie Mellon University for providing me with an intellectual home and the freedom
to undertake this work.
Robert F. Sekerka
Pittsburgh, PA



1
Introduction
Thermal physics deals with the quantitative physical analysis of macroscopic systems.
Such systems consist of a very large number, N, of atoms, typically N ∼1023. According
to classical mechanics, a detailed knowledge of the microscopic state of motion (say,
position ri and velocity vi) of each atom, i = 1, 2, . . . , N, at some time t, even if attainable,
would constitute an overwhelmingly huge database that would be practically useless.
More useful quantities would be averages, such as the average kinetic energy of an atom
in the system, which would be independent of time if the system were in equilibrium.
We might also be interested in knowing such things as the volume V of the system or
the pressure p that it exerts on the walls of a containing vessel. In other words, a useful
description of a macroscopic system is necessarily statistical and consists of knowledge of
a few macroscopic variables that describe the system to our satisfaction.
We shall be concerned primarily with macroscopic systems in a state of equilibrium.
An equilibrium state is one whose macroscopic parameters, which we shall call state vari-
ables, do not change with time. We accept the proposition, in accord with our experience,
that any macroscopic system subject to suitable constraints, such as conﬁnement to a
volume and isolation from external forces or sources of matter and energy, will eventually
come to a state of equilibrium. Our concept, or model, of the system will dictate the
number of state variables that constitute a complete description—a complete set of state
variables—of that system. For example, a gas consisting of a single atomic species might be
described by three state variables, its energy U, its volume V, and its number of atoms N.
Instead of its number of atoms, we usually avoid large numbers and specify its number
of moles, N := N/N A where NA = 6.02×1023 molecules/mol is Avogadro’s number.1
The state of a gas consisting of two atomic species, denoted by subscripts 1 and 2, would
require four variables, U, V, N1, and N2. A simple model of a crystalline solid consisting of
one atomic species would require eight variables; these could be taken to be U, V, N, and
ﬁve more variables needed to describe its state of shear strain.2
1.1 Temperature
A price we pay to describe a macroscopic system is the introduction of a state variable,
known as the temperature, that is related to statistical concepts and has no counterpart
in simple mechanical systems. For the moment, we shall regard the temperature to be an
1The notation A := B means A is deﬁned to be equal to B, and can be written alternatively as B =: A.
2This is true if the total number of unit cells of the crystal is able to adjust freely, for instance by means of
vacancy diffusion; otherwise, a total of nine variablesis required because one must add the volume per unit cell to
the list of variables. More complex macroscopic systems require more state variables for a complete description,
but usually the necessary number of state variables is small.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00001-6
3
Copyright © 2015 Elsevier Inc. All rights reserved.

4
THERMAL PHYSICS
empirical quantity, measured by a thermometer, such that temperature is proportional to
the expansion that occurs whenever energy is added to matter by means of heat transfer.
Examples of thermometers include thermal expansion of mercury in a long glass tube,
bending of a bimetallic strip, or expansion of a gas under the constraint of constant pres-
sure. Various thermometers can result in different scales of temperature corresponding to
the same physical states, but they can be calibrated to produce a correspondence. If two
systems are able to freely exchange energy with one another such that their temperatures
are equal and their other macroscopic state variables do not change with time, they are
said to be in equilibrium.
From a theoretical point of view, the most important of these empirical temperatures is
the temperature θ measured by a gas thermometer consisting of a ﬁxed number of moles
N of a dilute gas at volume V and low pressure p. This temperature θ is deﬁned to be
proportional to the volume at ﬁxed p and N by the equation
θ :=
p
RN V ,
(1.1)
where R is a constant. For variable p, Eq. (1.1) also embodies the laws of Boyle, Charles,
and Gay-Lussac. Provided that the gas is sufﬁciently dilute (small enough N/V), exper-
iment shows that θ is independent of the particular gas that is used. A gas under such
conditions is known as an ideal gas. The temperature θ is called an absolute temperature
because it is proportional to V, not just linear in V. If the constant R = 8.314 J/(mol K),
then θ is measured in degrees Kelvin, for which one uses the symbol K. On this scale,
the freezing point of water at one standard atmosphere of pressure is 273.15 K. Later,
in connection with the second law of thermodynamics, we will introduce a unique
thermodynamic deﬁnition of a temperature, T, that is independent of any particular
thermometer. Fermi [1, p. 42] uses a Carnot cycle that is based on an ideal gas as a working
substance to show that T = θ, so henceforth we shall use the symbol T for the absolute
temperature.3
Example Problem 1.1. The Fahrenheit scale ◦F, which is commonly used in the United States,
the United Kingdom, and some other related countries, is based on a smaller temperature
interval. At one standard atmosphere of pressure, the freezing point of water is 32 ◦F and the
boiling point of water is 212 ◦F. How large is the Fahrenheit degree compared to the Celsius
degree?
The Rankine scale R is an absolute temperature scale but based on the Fahrenheit degree. At
one standard atmosphere of pressure, what are the freezing and boiling points of water on the
Rankine scale? What is the value of the triple point of water on the Rankine scale, the Fahrenheit
scale and the Celsius scale? What is the value of absolute zero in ◦F?
3The Kelvin scale is deﬁned such that the triple point of water (solid-liquid-vapor equilibrium) is exactly
273.16 K. The Celsius scale, for which the unit is denoted ◦C, is deﬁned by T(◦C) = T(K) −273.15.

Chapter 1 • Introduction
5
Solution 1.1. The temperature interval between the boiling and freezing points of water at
one standard atmosphere is 100 ◦C or 212 −32 = 180 ◦F. Therefore, 1 ◦F = 100/180 = 5/9 ◦C =
(5/9) K. The freezing and boiling points of water are 273.15 × (9/5) = 491.67 R and 373.15 ×
(9/5) = 671.67R. The triple point of water is 273.16 × (9/5) = 491.688R = 32.018 ◦F = 0.01 ◦C.
The value of absolute zero in ◦F is −(491.67 −32) = −459.67 ◦F.
In the process of introducing temperature, we alluded to the intuitive concept of
heat transfer. At this stage, it sufﬁces to say that if two bodies at different temperatures
are brought into “thermal contact,” a process known as heat conduction can occur that
enables energy to be transferred between the bodies even though the bodies exchange
no matter and do no mechanical work on one another. This process results in a new
equilibrium state and a new common temperature for the combined body. It is common
to say that this process involves a “transfer of heat” from the hotter body (higher initial
temperature) to the colder body (lower initial temperature). This terminology, however,
can be misleading because a conserved quantity known as “heat” does not exist.4 We
should really replace the term “transfer of heat” by the longer phrase “transfer of energy
by means of a process known as heat transfer that does not involve mechanical work” but
we use the shorter phrase for simplicity, in agreement with common usage. The ﬁrst law
of thermodynamics will be used to quantify the amount of energy that can be transferred
between bodies without doing mechanical work. The second law of thermodynamics will
then be introduced to quantify the maximum amount of energy due to heat transfer
(loosely, “heat”) that can be transformed into mechanical work by some process. This
second law will involve a new state variable, the entropy S, which like the temperature
is entirely statistical in nature and has no mechanical counterpart.
1.2 Thermodynamics Versus Statistical Mechanics
Thermodynamics is the branch of thermal physics that deals with the interrelationship of
macroscopic state variables. It is traditionally based on three so-called laws (or a number
of postulates that lead to the same results, see Callen [2, chapter 1]). Based on these
laws, thermodynamics is independent of detailed models involving atoms and molecules.
It results in criteria involving state variables that must be true of systems that are in
equilibrium with one another. It allows us to develop relationships among measurable
quantities (e.g., thermal expansion, heat capacity, compressibility) that can be represented
by state variables and their derivatives. It also results in inequalities that must be obeyed by
any naturally occurring process. It does not, however, provide values of the quantities with
which it deals, only their interrelationship. Values must be provided by experiments or by
models based on statistical mechanics. For an historical introduction to thermodynamics,
see Cropper [11, p. 41].
4Such a quantity was once thought to exist and was called caloric.

6
THERMAL PHYSICS
Statistical mechanics is based on the application of statistics to large numbers of atoms
(or particles) that obey the laws of mechanics, strictly speaking quantum mechanics, but
in limiting cases, classical mechanics. It is based on postulates that relate certain types of
averages, known as ensemble averages, to measurable quantities and to thermodynamic
state variables, such as entropy mentioned above. Statistical mechanics can be used to
rationalize the laws of thermodynamics, although it is based on its own postulates which
were motivated by thermodynamics. By using statistical mechanics, speciﬁc models can
be analyzed to provide values of the quantities employed by thermodynamics and mea-
sured by experiments. In this sense, statistical mechanics appears to be more complete;
however, it must be borne in mind that the validity of its results depends on the validity
of the models. Statistical mechanics can, however, be used to describe systems that are
too small for thermodynamics to be applicable. For an excellent historical introduction to
statistical mechanics, see Pathria and Beale [9, pp. xxi-xxvi].
A crude analogy with aspects of mathematics may be helpful here: thermodynamics is
to statistical mechanics as Euclidean geometry is to analytic geometry and trigonometry.
Given the few postulates of Euclidean geometry, which allow things such as lengths
and angles to be compared but never measured, one can prove very useful and general
theorems involving the interrelationships of geometric forms, for example, congruence,
similarity, bisections, conditions for lines to be parallel or perpendicular, and conditions
for common tangency. But one cannot assign numbers to these geometrical quantities.
Analytic geometry and trigonometry provide quantitative measures of the ingredients of
Euclidean geometry. These measures must be compatible with Euclidean geometry but
they also supply precise information about such things as the length of a line or the size
of an angle. Moreover, trigonometric identities can be quite complicated and transcend
simple geometrical construction.
1.3 Classiﬁcation of State Variables
Much of our treatment will be concerned with homogeneous bulk systems in a state of
equilibrium. By bulk systems, we refer to large systems for which surfaces, either external
or internal, make negligible contributions. As a simple example, consider a sample in the
shape of a sphere of radius R and having volume V = (4/3)πR3 and surface area A = 4πR2.
If each atom in the sample occupies a volume a3, then for a ≪R, the ratio of the number
of surface atoms to the number of bulk atoms is approximately
r =
4π(R/a)2
(4/3)π(R/a)3 −4π(R/a)2 ∼3(a/R) ≪1.
(1.2)
For a sufﬁciently large sphere, the number of surface atoms is completely negligible
compared to the number of bulk atoms, and so presumably is their energy and other
properties. More generally, for a bulk sample having N atoms, roughly N 2/3 are near the
surface, so the ratio of surface to bulk atoms is roughly r ∼N −1/3. For a mole of atoms,
we have N ∼6 × 1023 and r ∼10−8. In deﬁning bulk samples, we must be careful to

Chapter 1 • Introduction
7
exclude samples such as thin ﬁlms or thin rods for which one or more dimension is small
compared to others. Thus, a thin ﬁlm of area L2 and thickness H ≪L contains roughly
N ∼L2H/a3 atoms, but about 2L2/a2 of these are on its surfaces. Thus, the ratio of surface
to bulk atoms is r ∼a/H which will not be negligible for a sufﬁciently thin ﬁlm. We must
also exclude samples that are ﬁnely subdivided, such as those containing many internal
cavities.
From the considerations of the preceding paragraph, atoms of bulk samples can be
regarded as being equivalent to one another, independent of location. It follows that
certain state variables needed to describe such systems are proportional to the number
of atoms. For example, for a homogeneous sample, total energy U
∝
N and total
volume V ∝N, provided we agree to exclude from consideration small values of N that
would violate the idealization of a bulk sample.5 State variables of a homogeneous bulk
thermodynamic system that are proportional to its number of atoms are called extensive
variables. They are proportional to the “extent” or “size” of the sample. For a homogeneous
gas consisting of three atomic species, a complete set of extensive state variables could
be taken to be U, V, N1, N2, and N3, where the Ni are the number of moles of atomic
species i.
There is a second kind of state variable that is independent of the “extent” of the sam-
ple. Such a variable is known as an intensive variable. An example of such a variable would
be a ratio of extensive variables, say U/V, because both numerator and denominator are
proportional to N. Another example of an intensive variable would be a derivative of some
extensive variable with respect to some other extensive variable. This follows because a
derivative is deﬁned to be a limit of a ratio, for example,
dU
dV = lim
V→0
U(V + V ) −U(V )
V
.
(1.3)
If other quantities are held constant during this differentiation, the result is a partial
derivative ∂U/∂V, which is also an intensive variable, but its value will depend on which
other variables are held constant. It will turn out that the pressure p, which is an intensive
state variable, can be expressed as
p = −∂U
∂V
(1.4)
provided that certain other variables are held constant; these variables are the entropy
S, an extensive variable alluded to previously, as well as all other extensive variables of a
remaining complete set. Another important intensive variable is the absolute temperature
T, which we shall see can also be expressed as a partial derivative of U with respect to the
entropy S while holding constant all other extensive variables of a remaining complete set.
Since the intensive variables are ratios or derivatives involving extensive variables, we
will not be surprised to learn that the total number of independent intensive variables is
one less than the total number of independent extensive variables. The total number of
5The symbol ∝means “proportional to.”

8
THERMAL PHYSICS
independent intensive variables of a thermodynamic system is known as its number of
degrees of freedom, usually a small number which should not be confused with the huge
number of microscopic degrees of freedom 6N for N particles that one would treat by
classical statistical mechanics.
In Chapter 5, we shall return to a systematic treatment of extensive and intensive
variables and their treatment via Euler’s theorem of homogeneous functions.
1.4 Energy in Mechanics
The concept of energy is usually introduced in the context of classical mechanics. We
review such considerations brieﬂy in order to shed light on some aspects of energy that
will be important in thermodynamics.
1.4.1 Single Particle in One Dimension
A single particle of mass m moving in one dimension, x, obeys Newton’s law
md2x
dt2 = F,
(1.5)
where t is the time and F(x) is the force acting on the particle when it is at position x. We
introduce the potential energy function
V(x) = −
 x
x0
F(u) du,
(1.6)
which is the negative of the work done by the force on the particle when the particle
moves from some position x0 to position x. Then the force F = −dV/dx can be written
in terms of the derivative of this potential function. We multiply Eq. (1.5) by dx/dt
to obtain
mdx
dt
d2x
dt2 + dV
dx
dx
dt = 0,
(1.7)
which can be rewritten as
d
dt
1
2mv2 + V

= 0,
(1.8)
where the velocity v := dx/dt. Equation (1.8) can then be integrated to obtain
1
2mv2 + V = E,
(1.9)
where E is independent of time and known as the total energy. The ﬁrst term in Eq. (1.9)
is known as the kinetic energy and the equation states that the sum of the kinetic and
potential energy is some constant, independent of time. It is important to note, however,
that the value of E is undetermined up to an additive constant. This arises as follows: If
some constant V0 is added to the potential energy V(x) to form a new potential ˜V := V +V0,
the same force results because

Chapter 1 • Introduction
9
−d ˜V
dx = −d
dx (V + V0) = −dV
dx = F.
(1.10)
Thus, Eq. (1.9) could equally well be written
1
2mv2 + ˜V = ˜E,
(1.11)
where ˜E is a new constant. Comparison of Eq. (1.11) with Eq. (1.9) shows that ˜E = E + V0,
so the total energy shifts by the constant amount V0. Therefore, only differences in energy
have physical meaning; to obtain a numerical value of the energy, one must always
measure energy relative to some well-deﬁned state of the particle or, what amounts to
the same thing, adopt the convention that the energy in some well-deﬁned state is equal
to zero. In view of Eq. (1.6), the potential energy V(x) will be zero when x = x0, but the
choice of x0 is arbitrary.
In classical mechanics, it is possible to consider more general force laws such as F(x, t)
in which case the force at point x depends explicitly on the time that the particle is at
point x. In that case, we can obtain (d/dt)(1/2)mv2 = Fv where Fv is the power supplied
by the force. Similar considerations apply for forces of the form F(x, v, t) that can depend
explicitly on velocity as well as time. In such cases, one must solve the problem explicitly
for the functions x(t) and v(t) before the power can be evaluated. In these cases, the total
energy of the system changes with time and it is not possible to obtain an energy integral
as given by Eq. (1.9).
1.4.2 Single Particle in Three Dimensions
The preceding one-dimensional treatment can be generalized to three dimensions with a
few modiﬁcations. In three dimensions, where we represent the position of a particle by
the vector r with Cartesian coordinates x, y, and z, Eq. (1.5) takes the form
md2r
dt2 = F,
(1.12)
where F(r) is now a vector force at the point r. The mechanical work done by the force on
the particle along a speciﬁed path leading from rA to rB is now given by
Wr A to r B =

path
F · dr.
(1.13)
According to the theorem of Stokes, one has

(∇× F) · dA =

F · dr,
closed loop,
(1.14)
where the integral on the right is a line integral around a closed loop and the integral on
the left is over an area that subtends that loop. For a force such that ∇× F = 0, we see
that the line integral around any closed loop is equal to zero. Thus, if we integrate from A
to B along path 1 and from B back to A along some other path 2 we get zero. But the latter
integral is just the negative of the integral from A to B along path 2, so the integral from A
to B is the same along path 1 as along path 2. For such a force, it follows that the work

10
THERMAL PHYSICS
WAB =
 rB
rA
F · dr,
any path,
(1.15)
is independent of path and depends only on the end points. Such a force is called a
conservative force and may be represented as the gradient of a potential
V (r) = −
 r
r0
F(r′) · dr′
(1.16)
such that F = −∇V. In this case, it follows that the work
WAB = −
 rB
rA
∇V · dr = −
 rB
rA
dV = V (rA) −V (rB).
(1.17)
For such a conservative force, we can dot the vector v := dr/dt into Eq. (1.12) to obtain
mdr
dt · d2r
dt2 + dr
dt · ∇V = 0.
(1.18)
Then by noting that
d
dt (1/2)m v · v = mdr
dt · d2r
dt2
and
dV
dt = dr
dt · ∇V ,
(1.19)
we are led immediately to Eq. (1.8) and its energy integral Eq. (1.9) just as in one
dimension, except now v2 = v · v in the kinetic energy.
1.4.3 System of Particles
We next consider a system of particles, k = 1, 2, . . . , N, having masses mk, positions rk, and
velocities vk = drk/dt. Each particle is assumed to be subjected to a conservative force
Fk = −∇kV(r1, r2, . . . , rN ),
(1.20)
where ∇k is a gradient operator that acts only on rk. Then by writing Newton’s equations
in the form of Eq. (1.12) for each value of k, summing over k and proceeding as above, we
obtain
d
dt [T + V ] = 0,
(1.21)
where the total kinetic energy
T :=
N

k=1
1
2mkvk · vk
(1.22)
and
dV
dt =
N

k=1
drk
dt · ∇kV .
(1.23)
Furthermore, we can suppose that the forces on each particle can be decomposed into
internal forces Fi due to the other particles in the system and to external forces Fe, that is,

Chapter 1 • Introduction
11
F = Fi + Fe. Since these forces are additive, we also have a decomposition of the potential,
V = V i + V e, into internal and external parts. The integral of Eq. (1.21) can therefore be
written in the form
T + V i + V e = E,
(1.24)
where E is the total energy constant. This suggests a related decomposition of T which we
proceed to explore.
We introduce the position vector of the center of mass of the system of particles,
deﬁned by
R := 1
M
N

k=1
mkrk,
(1.25)
where M := N
k=1 mk is the total mass of the system. The velocity of the center of mass is
V := dR
dt = 1
M
N

k=1
mkvk.
(1.26)
The kinetic energy relative to the center of mass, namely T i, can be written
T i := 1
2
N

k=1
mk(vk −V) · (vk −V) = T −1
2MV 2.
(1.27)
Eq. (1.27) may be veriﬁed readily by expanding the left-hand side to obtain four terms
and then using Eq. (1.26). The term (1/2)MV 2 is recognized as the kinetic energy asso-
ciated with motion of the center of mass of the system. Equation (1.24) can therefore
be written
T i + V i + 1
2MV 2 + V e = E.
(1.28)
The portion of this energy exclusive of the kinetic energy of the center of mass and the
external forces, namely U = T i + V i, is an internal energy of the system of particles and
is the energy usually dealt with in thermodynamics. Thus, when energies of a thermody-
namic system are compared, they are compared under the assumption that the state of
overall motion of the system, and hence its overall motional kinetic energy, (1/2)MV 2,
is unchanged. This is equivalent to supposing that the system is originally at rest and
remains at rest. Moreover, it is usually assumed that there are no external forces so the
interaction energy V e is just a constant. Thus, the energy integral is usually viewed in the
form
U =: T i + V i = E −1
2MV 2 −V e =: U0,
(1.29)
where U0 is a new constant. If such a system does interact with its environment, U is
no longer a constant. Indeed, if the system does work or if there is heat transfer from its
environment, U will change according to the ﬁrst law of thermodynamics, which is taken
up in Chapter 2.

12
THERMAL PHYSICS
Sometimes one chooses to include conservative external forces in the energy used in
thermodynamics. Such treatments require the use of a generalized energy that includes
potential energy due to conservative external forces, such as those associated with gravity
or an external electric ﬁeld. In that case, one deals with the quantity
˜U =: T i + V i + V e = E −1
2MV 2.
(1.30)
In terms of chemical potentials, which we shall discuss in Chapter 12, such external
forces give rise to gravitational chemical potentials and electrochemical potentials that
play the role [6, p. 122] of intrinsic chemical potentials when external ﬁelds are present.
It is also possible to treat uniformly rotating coordinate systems by including in the
thermodynamic energy the effective potential associated with ﬁctitious centrifugal forces
[7, p. 72].
1.5 Elementary Kinetic Theory
More insight into the state variables temperature T and pressure p can be gained by
considering the elementary kinetic theory of gases. We consider a monatomic ideal gas
having particles of mass m that do not interact and whose center of mass remains at rest.
Its kinetic energy is
T = 1
2
N

k=1
mdrk
dt · drk
dt = 1
2
N

k=1
mv2
k.
(1.31)
If the gas is in equilibrium, the time average T of this kinetic energy is a constant. This
kinetic energy represents the vigor of motion of the atoms, so it is natural to suppose that
it increases with temperature because temperature can be increased by adding energy due
to heat transfer. A simple and fruitful assumption is to assume that T is proportional to the
temperature. In particular, we postulate that the time average kinetic energy per atom is
related to the temperature by6
1
N T =
1
2N
N

k=1
mv2
k = 3
2kBT,
(1.32)
where kB is a constant known as Boltzmann’s constant. In fact, kB = R/NA where R is
the gas constant introduced in Eq. (1.1) and NA is Avogadro’s number. We shall see that
Eq. (1.32) makes sense by considering the pressure of an ideal gas.
The pressure p of an ideal gas is the force per unit area exerted on the walls of a
containing box. For simplicity, we treat a monatomic gas and assume for now that each
atom of the gas has the same speed v, although we know that there is really a distribution
of speeds given by the Maxwell distribution, to be discussed in Chapter 19. We consider
6If the center of mass of the gas were not at rest, Eq. (1.27) would apply and T would have to be replaced by
T
i. In other words, the kinetic energy (1/2)MV 2 of the center of mass makes no contribution to the temperature.

Chapter 1 • Introduction
13
an inﬁnitesimal area dA of a wall perpendicular to the x direction and gas atoms with
velocities that make an angle of θ with respect to the positive x direction. In a time dt,
all atoms in a volume v dt dA cos θ will strike the wall at dA, provided that 0 < θ < π/2.
Each atom will collide with the wall with momentum m v cos θ and be reﬂected with the
same momentum,7 so each collision will contribute a force (1/dt)2m v cos θ, which is the
time rate of change of momentum. The total pressure (force per unit area) is therefore
p = 1
2
n(v dt dA cos θ)(2m v cos θ)
dA dt
	
= nm⟨v2 cos2 θ⟩= nm⟨v2
x ⟩,
(1.33)
where n is the number of atoms per unit volume and the angular brackets denote an
average over time and all θ. The factor of 1/2 arises because of the restriction 0 < θ < π/2.
Since the gas is isotropic, ⟨v2
x ⟩= ⟨v2
y ⟩= ⟨v2
z ⟩= (1/3)⟨v2⟩. Therefore,8
p = 1
3nm⟨v2⟩= 2
3n T
N = nkBT = NR
V T,
(1.34)
where Eq. (1.32) has been used. Equation (1.34) is the well-known ideal gas law, in
agreement with Eq. (1.1) if the absolute temperature is denoted by T. In the case of an ideal
gas, all of the internal energy is kinetic, so the total internal energy is U = T . Eq. (1.34)
therefore leads to p = (2/3)(U/V), which is also true for an ideal monatomic gas.
These simple relations from elementary kinetic theory are often used in thermody-
namic examples and are borne out by statistical mechanics.
7Reﬂection with the same momentum would require specular reﬂection from perfectly reﬂecting walls, but
irrespective of the nature of actual walls, one must have reﬂection with the same momentum on average to avoid
a net exchange of energy.
8If we had accounted for a Maxwell distribution of speeds, this result would still hold provided that we
interpret ⟨v2⟩to be an average of the square of the velocity with respect to that distribution. See Eqs. (20.28-20.30)
for details.


2
First Law of Thermodynamics
The ﬁrst law of thermodynamics extends the concept of energy from mechanical systems
to thermodynamic systems, speciﬁcally recognizing that a process known as heat transfer
can result in a transfer of energy to the system in addition to energy transferred by
mechanical work. We ﬁrst state the law and then discuss the terminology used to express
it. As stated below, the law applies to a chemically closed system, by which we mean that
the system can exchange energy with its environment by means of heat transfer and work
but cannot exchange mass of any chemical species with its environment. This deﬁnition is
used by most chemists; many physicists and engineers use it as well but it is not universal.
Some authors, such as Callen [2] and Chandler [12], regard a closed system as one that
can exchange nothing with its environment. In this book, we refer to a system that can
exchange nothing with its environment as an isolated system.
2.1 Statement of the First Law
For a thermodynamic system, there exists an extensive function of state, U, called the
internal energy. Every equilibrium state of a system can be described by a complete
set of (macroscopic) state variables. The number of such state variables depends on the
complexity of the system and is usually small. For now we can suppose that U depends
on the temperature T and additional extensive state variables needed to form a complete
set.1 Alternatively, any equilibrium state can be described by a complete set of extensive
state variables that includes U. For a chemically closed system, the change U from an
initial to a ﬁnal state is equal to the heat, Q, added to the system minus the work, W, done
by the system, resulting in2
U = Q −W.
(2.1)
Q and W are not functions of state because they depend on the path taken during the
process that brings about the change, not on just the initial and ﬁnal states. Eq. (2.1)
1There are other possible choices of a complete set of state variables. For example, a homogeneous isotropic
ﬂuid composed a single chemical component can be described by three extensive variables, the internal energy
U, the volume V, and the number of moles N. One could also choose state variables T, V, and N and express U
as a function of them, and hence a function of state. Alternatively, U could be expressed as a function of T, the
pressure p, and N. In Chapter 3, we introduce an extensive state variable S, the entropy, in which case U can be
expressed as a function of a complete set of extensive variables including S, known as a fundamental equation.
2In agreement with common usage, we use the terminology “heat transferred to the system” or “heat added
to the system” in place of the longer phrase “energy transferred to the system by means of a process known as
heat transfer that does not involve mechanical work.”
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00002-8
15
Copyright © 2015 Elsevier Inc. All rights reserved.

16
THERMAL PHYSICS
actually deﬁnes Q, since U and W can be measured independently, as will be discussed
in detail in Section 2.1.1.
If there is an inﬁnitesimal amount of heat δQ transferred to the system and the system
does an inﬁnitesimal amount of work δW, the change in the internal energy is
dU = δQ −δW,
inﬁnitesimal change.
(2.2)
For an isolated system, U = 0, and for such a system, the internal energy is a
constant.
2.1.1 Discussion of the First Law
As explained in Chapter 1, the term internal energy usually excludes kinetic energy of
motion of the center of mass of the entire macroscopic system, as well as energy associated
with overall rotation (total angular momentum). The internal energy also usually excludes
the energy due to the presence of external ﬁelds, although it is sometimes redeﬁned to
include conservative potentials. We will only treat thermodynamic systems that are at rest
with respect to the observer (zero kinetic energy due to motion of the center of mass or
total angular momentum). For further discussion of this point, see Landau and Lifshitz
[7, p. 34].
We emphasize that W is positive if work is done by the system on its environment.
Many authors, however, state the ﬁrst law in terms of the work W = −W done by the
environment on the system by some external agent. In this case, the ﬁrst law would read
U = Q + W. This is especially common3 in Europe [14] and Russia [7].
The symbol  applied to any state function means the value of that function in the ﬁnal
state (after some process) minus the value of that function in the initial state. Speciﬁcally,
U := U(ﬁnal state) −U(initial state). As mentioned above, Q and W are not state
functions, although their difference is a state function. As will be illustrated below, Q and
W depend on the details of the process used to change the state function U. In other words,
Q and W depend on the path followed during a process. Therefore, it makes no sense to
apply the  symbol or the differential symbol d to Q or W. We use δQ and δW to denote
inﬁnitesimal transfers of energy to remind ourselves that Q and W are not state functions.
Some authors [6, 12] use a d with a superimposed strikethrough (d) instead of δ.
The ﬁrst law of thermodynamics is a theoretical generalization based on many ex-
periments. Particularly noteworthy are the experiments of Joule who found that for two
states of a closed thermodynamic system, say A and B, it is always possible to cause a
transition that connects A to B by a process in which the system is thermally insulated, so
δQ = 0 at every stage of the process. This also means that Q = 0 for the whole process.
3Fermi [1] uses the symbol L for the work done by the system; note that the Italian word for work is ‘lavoro’
(cognate labor). The introductory physics textbook by Young and Freedman [13] also states the ﬁrst law of
thermodynamics in terms of the work done by the system. Landau and Lifshitz [7] use the symbol R ≡−W
(‘rabota’) to denote the work done on the system. Chandler [12] and Kittel and Kroemer [6] use W ≡−W to
denote the work done on the system. This matter of notation and conventions can cause confusion, but we have
to live with it.

Chapter 2 • First Law of Thermodynamics
17
Thus by work alone, either the transformation A →B or the transformation B →A is
possible. Since the energy change due to work alone is well deﬁned in terms of mechanical
concepts, it is possible to establish either the energy difference UA −UB or its negative
UB −UA. The fact that one of these transformations might be impossible is related to
concepts of irreversibility, which we will discuss later in the context of the second law of
thermodynamics.
According to the ﬁrst law, as recognized by Rudolf Clausius in 1850, heat transfer
accounts for energy received by the system in forms other than work. Since U can be
measured and W can be determined for any mechanical process, Q is actually deﬁned by
Eq. (2.1). It is common to measure the amount of energy due to heat transfer in units of
calories. One calorie is the amount of heat necessary to raise the temperature of one gram
(10−3 kg) of water from 14 ◦C to 15 ◦C at standard atmospheric pressure. The mechanical
equivalent of this heat is 1 calorie = 4.184 J = 4.184×107 erg. The amount of heat required
to raise the temperature by T of an arbitrary amount of water is proportional to its mass.
It was once believed that heat was a conserved quantity called caloric, and hence the
unit calorie, but no such conserved quantity exists. This discovery is usually attributed
to Count Rumford who noticed that water used to cool a cannon during boring would
be brought to a boil more easily when the boring tool became dull, resulting in even
less removal of metal. Thus, “heat” appears to be able to be produced in virtually
unlimited amounts by doing mechanical work, and thus cannot be a conserved quantity.
Therefore, we must bear in mind that heat transfer refers to a process for energy transfer
and that there is actually no identiﬁable quantity, “heat,” that is transported. From an
atomistic point of view, we can think of conducted heat as energy transferred by means
of microscopic atomic or molecular collisions in processes that occur without the transfer
of matter and without changing the macroscopic physical boundaries of the system under
consideration. Heat can also be transferred by radiation that is emitted or absorbed by a
system.
We can enclose a system of interest and a heat source of known heat capacity (see
Section 2.3) by insulation to form a calorimeter, assumed to be an isolated system, and
allow the combined system to come to equilibrium. The temperature change of the heat
source will allow determination of the amount of energy transferred from it (or to it) by
means of heat transfer and this will equal the increase (or decrease) in energy of the system
of interest.4
2.2 Quasistatic Work
If a thermodynamic system changes its volume V by an amount dV and does work against
an external pressure pext, it does an inﬁnitesimal amount of work
δW = pext dV .
(2.3)
4If the heat source changes volume, it could exchange work with its environment and this would have to be
taken into account.

18
THERMAL PHYSICS
This external pressure can be established by purely mechanical means. For example, an
external force Fext acting on a piston of area A would give rise to an external pressure pext =
Fext/A. Note that Eq. (2.3) is valid for a ﬂuid system even if the process being considered
is so rapid and violent that an internal pressure of the system cannot be deﬁned during
the process. This equation can also be generalized for a more complex system as long as
one uses actual mechanical external forces and the distances through which they displace
portions of the system, for example, pushing on part of the system by a rod or pulling on
part of a system by a rope.
If an isotropic system (same in all directions, as would be true for a ﬂuid, a liquid or a
gas) expands or contracts sufﬁciently slowly (hence the term “quasistatic”) that the system
is practically in equilibrium at each instant of time, it will have a well-deﬁned internal
pressure p. Under such conditions, p ≈pext and the system will do an inﬁnitesimal
amount of work
δW = p dV ,
quasistatic work.
(2.4)
Note that δW and dV are positive if work is done by the system and both are negative if
work is done on the system by an external agent.
Eq. (2.4) applies only to an idealized process. For an actual change to take place, we
need p to be at least slightly different from pext to provide a net force in the proper
direction. This requires (p −pext) dV > 0. Thus pext dV < p dV which, in view of Eq. (2.3),
may be written
δW < p dV ,
actual process.
(2.5)
For the case of quasistatic work, it will be necessary for p to be slightly greater than pext
for the system to expand (dV > 0); conversely, it will be necessary for p to be slightly less
than pext for the system to contract. These small differences are assumed to be second
order and are ignored in writing Eq. (2.4). Consistent with this idealization, a process of
quasistatic expansion can be reversed to a process of quasistatic contraction by making
an inﬁnitesimal change in p. Therefore, quasistatic work is also called reversible work.5
We can combine Eq. (2.4) with Eq. (2.5) to obtain
δW ≤p dV
(2.6)
with the understanding that the inequality applies to all actual processes (which are irre-
versible) and the equality applies to the idealized process of reversible quasistatic work.
For a ﬁnite change of V, the quasistatic work can be computed by integration:
W =

path
p dV ,
quasistatic work.
(2.7)
To evaluate this integral, we must specify the path that connects the initial and ﬁnal states
of the system. It makes no sense to write this expression with lower and upper limits of
5A process involving quasistatic work will be reversible only if all other processes that go on in the system are
reversible. For example, an irreversible chemical reaction would be forbidden.

Chapter 2 • First Law of Thermodynamics
19
V
p
V1
V2
V1, p1
V2, p2
I
II
FIGURE 2–1 Illustration of quasistatic work for a system whose states can be represented by points in the V, p
plane. The system makes a quasistatic transition from a state at V1, p1 to a state V2, p2 by two different paths, I and
II. According to Eq. (2.7), the quasistatic work is the area under each curve and is obviously greater for path II. The
difference in work is the area between the paths. Since U for the two paths is the same, the difference in the heat
Q for the two paths is also equal to the area between the paths.
integration unless the path is clearly speciﬁed. For a system whose equilibrium states
can be represented by points in the V, p plane, the quasistatic work is represented by the
area under the curve that represents the path that connects the initial and ﬁnal states,
as illustrated in Figure 2–1. Since the areas under two curves that connect the same two
end points can be different, the quasistatic work W clearly depends on the path. Since
Q = U + W and U is independent of path, Q also depends on path.
If work and heat are exchanged with a system, it is important to recognize that the
internal energy of the system will not be partitioned in any way that allows part of it to be
associated with heat and part with work. That is because work and heat refer to processes
for changing the energy of a system and lose their identity once equilibrium is attained
and the energy of the system is established. On the other hand, other state variables of the
system can differ depending on the relative amounts of heat and work that bring about
the same change of internal energy. For example, consider two alternative processes in
which the internal energy of an ideal gas is increased by exactly the same amount, the
ﬁrst by means of only work done by a constant external pressure pext and the second by
means of only heat transfer. In the case of only work, the volume of the gas will necessarily
be decreased but in the case of only heat transfer, the volume of the system will not
be changed. Therefore, the two processes result in different thermodynamic states, even
though both result in the same internal energy.
2.3 Heat Capacities
We can deﬁne heat capacities for changes in which the work done by the system is the
quasistatic work given by Eq. (2.4). In that case, the ﬁrst law takes the form
dU = δQ −p dV .
(2.8)

20
THERMAL PHYSICS
The heat capacity at constant volume, CV , is deﬁned to be the ratio of the inﬁnitesimal
amount of heat δQ needed to raise the temperature by an inﬁnitesimal amount dT while
holding the volume constant, namely
CV :=
 δQ
dT

V
=
∂U
∂T

V
,
(2.9)
where the last expression, a partial derivative at constant volume, follows from Eq. (2.8).
The heat capacity is an extensive quantity and should not be confused with the speciﬁc
heat, which is the heat capacity per unit mass, which is intensive.6
The heat capacity at constant pressure, Cp, is deﬁned to be the ratio of the inﬁnites-
imal amount of heat δQ needed to raise the temperature by an inﬁnitesimal amount dT
while holding the pressure constant, namely
Cp :=
 δQ
dT

p
=
∂U
∂T

p
+ p
 ∂V
∂T

p
,
(2.10)
where the last expression again follows from Eq. (2.8). Note that the partial derivatives of
U in Eqs. (2.9) and (2.10) are not the same because different variables are held constant.
Thus
∂U
∂T

p
=
∂U
∂T

V
+
∂U
∂V

T
∂V
∂T

p
.
(2.11)
Example Problem 2.1. The speciﬁc heat of silver at 20 ◦C is 0.0558 cal g−1 K−1. Here we
ignore the small difference between constant volume and constant pressure for this condensed
phase. What is the heat capacity of 3 kg of silver? How many Joules of energy are needed to raise
the temperature of 3 kg of silver from 15 ◦C to 25 ◦C?
Solution 2.1. The heat capacity of 3 kg of silver is 3000 × 0.0558 = 167 cal K−1. The tempera-
ture interval is 10 K so the energy required is 1670 cal × 4.184 J/cal = 6990J. We only keep three
signiﬁcant ﬁgures because the speciﬁc heat was only given to three ﬁgures.
2.3.1 Heat Capacity of an Ideal Gas
One mole of an ideal gas obeys the equation of state
pV = RT,
one mole of ideal gas,
(2.12)
where T is the absolute temperature and R is the gas constant. Equation (2.12) is essen-
tially a deﬁnition of an ideal gas, based on experiments for real dilute gases that obey
Eq. (1.1) that was used to deﬁne the empirical temperature θ. For such a real dilute gas,
Joule conducted experiments in which the gas was conﬁned originally to a subvolume V1
of an insulated rigid container having overall volume V2. The remainder of the volume,
V2 −V1 was initially evacuated (see Figure 3–2). In these experiments, Q = 0 because the
6Analogous intensive quantities such as the heat capacity per atom, per molecule, or per mole are often used.

Chapter 2 • First Law of Thermodynamics
21
container is insulated and W = 0 because the overall container having volume V2 is rigid.
Therefore, by the ﬁrst law, the internal energy U remains constant. In the experiments, the
gas was allowed to expand internally from V1 to V2. Joule observed that the temperature T
of the gas remained practically unchanged during the process. More accurate experiments
were performed later by Thomson (Lord Kelvin) and Joule by causing the gas to expand
through a porous plug until a steady state is reached and measuring the temperature of the
exiting gas directly. For hydrogen, there was hardly appreciable change in temperature; see
the treatise by Planck [15, p. 50] for details. Therefore, the internal energy of such a dilute
gas is practically independent of its volume. For an ideal gas, we shall assume that U is
strictly independent of its volume, V, and therefore only a function of T. We shall see later
that this conclusion can be derived by applying the second law of thermodynamics for a
gas that obeys Eq. (2.12).7
Therefore, for an ideal gas, the second term on the right-hand side of Eq. (2.11) is
zero. The second term on the right of Eq. (2.10) can be evaluated by means of Eq. (2.12),
resulting in8
Cp = CV + R,
one mole of ideal gas.
(2.13)
We observe that Cp is larger than CV by an amount needed to supply the work p dV
done by the gas as it expands at constant pressure. The value of CV depends on the type
of gas under consideration and can be derived by means of statistical mechanics. For
a mole of gas, we shall see that each translational or rotational degree of freedom of a
gas molecule, made up of atoms that are considered to be point particles, contributes an
amount R/2 to CV . For a monatomic gas, each atom has three translational degrees of
freedom, translation along x, y, and z, so CV = 3R/2. A diatomic gas molecule would have
six total degrees of freedom (three translational degrees for each atom) but the distance of
separation of the two atoms remains practically constant due to strong chemical bonds.
The atoms of a diatomic gas can execute vibrations along the line joining them, but these
vibrations are hardly excited except at very high temperatures.9 Thus only ﬁve degrees of
freedom are usually active (three translational and two rotational) and CV = 5R/2 for a
diatomic gas. Similarly, if we neglect vibrational degrees of freedom for polyatomic gases,
six degrees of freedom are usually active (three translational and three rotational) and
CV = 3R. This leads to the values listed in Table 2–1.
7By calculating derivatives of the entropy, it can be shown that dU = CV dT + (Tα/κT −p)dV, where α is the
isobaric compressibility and κ is the isothermal compressibility. From the ideal gas law, α = 1/T and β = 1/p, so
the coefﬁcient of dV vanishes and U depends only on T.
8As deﬁned by Eqs. (2.9) and (2.10), the heat capacities CV and Cp are extensive. Thus they depend not only on
the substance under consideration but also on the amount of that substance. One can obtain intensive quantities
by dividing by the number of moles or the mass. These intensive quantities depend only on the substance under
consideration. Here we deal with one mole, which is equivalent to dividing the extensive heat capacities by the
number of moles being considered.
9If partially excited, the contribution of a vibrational degree of freedom would depend on temperature. If fully
excited, a vibrational degree of freedom would contribute R/2 for kinetic energy and R/2 for potential energy, for a
total of R. Polyatomic gases with linear molecules behave somewhat like diatomic molecules insofar as rotational
degrees of freedom are concerned. See Section 21.3 for a detailed discussion of ideal gases with internal structure.

22
THERMAL PHYSICS
Table
2–1
Heat
Capacities
per
Mole
of Ideal Gases
Molecule
CV
Cp
γ = Cp/CV
monatomic
3R/2
5R/2
5/3 ≈1.67
diatomic
5R/2
7R/2
7/5 = 1.40
polyatomic
3R
4R
4/3 ≈1.33
It is assumed that the atoms are point particles, translational and
rotational degrees of freedom are totally excited, and vibrational
degrees of freedom of diatomic and polyatomic gases are not
excited.
2.3.2 General Relationship of Cp to CV
By means of a general result of thermodynamics, it will turn out that Cp is always larger
than CV . For the moment, we state this result without proof but will derive it after we
cover the second and third laws of thermodynamics. First, we need to deﬁne two other
measurable quantities:
isobaric coefﬁcient of thermal expansion:
α := 1
V
∂V
∂T

p
,
(2.14)
isothermal compressibility:
κT := −1
V
∂V
∂p

T
.
(2.15)
The signs in Eqs. (2.14) and (2.15) have been chosen so that κT is positive and α is usually
positive.10 The general result (see Eq. (5.32)) is
Cp = CV + TV α2
κT
.
(2.16)
From the form of Eq. (2.16), we observe that Cp ≥CV for any substance, which is not
obvious from their deﬁnitions. From stability considerations, it will be shown in Section
7.4 that Cp ≥CV ≥0. For an ideal gas, we readily calculate from Eq. (2.12) that α = 1/T
and κT = 1/p, in which case Eq. (2.16) becomes Eq. (2.13) for N = 1 mole of gas. For
condensed phases, |α| ≪1/T and κT ≪1/p, but the second term in Eq. (2.16) is quadratic
in α so the difference between Cp and CV is very small. Thus, the difference between
Cp and CV is very important for gases but small and often negligible for liquids and
solids.
10This agrees with our intuition and with experiment. It can be proven from general thermodynamic stability
considerations (see Chapter 7) that κT is positive. α is usually positive but negative values of α are possible, for
example, for water below about 4 ◦C.

Chapter 2 • First Law of Thermodynamics
23
Example Problem 2.2. The equation of state for one mole of a van der Waals ﬂuid is
(p + a/v2)(v −b) = RT,
where p is the pressure, v is the volume per mole, T is the temperature, and a and b are
constants. Calculate the following quantities and show that they agree with the results for an
ideal gas in the limit a = b = 0:
(a) The isothermal compressibility, κT = −(1/v)(∂v/∂p)T
(b) The isobaric coefﬁcient of thermal expansion, α = (1/v)(∂v/∂T)p
(c) The molar heat capacity difference, (Cp −CV )/N
(d) Show directly that (∂p/∂T)v = α/κT. Why is this true?
Solution 2.2. We ﬁrst take the differential of the given equation to obtain
dp

v −b

+

p −a
v2 + 2 a b
v3

dv = R dT.
(a)
κT = −1
v
∂v
∂p

T
= 1
v

v −b
 
p −a
v2 + 2 a b
v3
−1
→1
p
for an ideal gas,
(b)
α = 1
v
 ∂v
∂T

p
= R
v

p −a
v2 + 2 a b
v3
−1
→R
pv = 1
T
for an ideal gas,
(c)
(Cp −CV )/N = Tvα2
κT
=
R2T

v −b


p −a
v2 + 2 a b
v3
−1
→R2T
pv
= R
for an ideal gas,
(d)
 ∂p
∂T

v
=
R
v −b = −
 ∂v
∂T

p
/
∂v
∂p

T
= α
κT
.
This relation is generally true, not just true for the van der Waals ﬂuid, as can be seen from the
differential
dv =
 ∂v
∂T

p
dT +
∂v
∂p

T
dp.

24
THERMAL PHYSICS
2.4 Work Due to Expansion of an Ideal Gas
We calculate the work due to expansion of one mole of an ideal gas that obeys the equation
of state Eq. (2.12). For simplicity, we will further assume that the gas has a constant heat
capacity CV at constant volume. According to Eq. (2.9), this results in
dU = CV dT;
U = CV T + constant.
(2.17)
2.4.1 Reversible Isothermal Process
For a reversible isothermal process, the path in the V, p plane is an equilateral hyperbola,
pV = constant, where the value of the constant depends on T. We assume that this path
joins two states that satisfy p1V1 = p2V2, so the quasistatic work is
W =

T= constant
p dV = RT
 V2
V1
dV
V
= RT ln(V2/V1),
one mole.
(2.18)
For V2 > V1 the gas expands and does positive work, as shown in Figure 2–2. For the reverse
transformation from V2 to V1, the gas contracts and does negative work; in this case, the
environment of the gas does positive work on the gas. Since U depends only on T, we have
U1 = U2 so U = 0. Therefore, by the ﬁrst law, Q = W for this process.
2.4.2 Reversible Isobaric Expansion Followed by Isochoric Transformation
We assume the path to be a reversible expansion from V1 to V2 at constant pressure
p1 (isobaric expansion) followed by lowering the pressure to p2 at constant volume
V2 (isochoric transformation). This is illustrated by the dashed line in Figure 2–3. The
quasistatic work is
W = p1
 V2
V1
dV +
 V2
V2
p dV = p1(V2 −V1)
(2.19)
because the second integral is zero. The temperature will change throughout this process.
In general, the end points will have different temperatures, T1 = p1V1/R and T2 = p2V2/R,
and the change in internal energy will be U = CV (T2 −T1). If the end points happen
to satisfy p1V1 = p2V2, then T1 = T2, but during the process T will not be constant. In
general, Q = U + W, but if T1 = T2, then U = 0 and Q = W. Then the work given by
Eq. (2.19) can also be written as RT1(V2 −V1)/V1 = RT2(V2 −V1)/V1 and is greater than
that given by Eq. (2.18) with T = T1 = T2. The reader is invited to prove this statement
mathematically.
2.4.3 Isochoric Transformation Followed by Reversible Isobaric
Expansion
We assume the path to consist of lowering the pressure to p2 at constant volume V1
followed by reversible expansion from V1 to V2 at constant pressure p2. This is illustrated
by the dot-dashed line in Figure 2–3. The quasistatic work is

Chapter 2 • First Law of Thermodynamics
25
V
p
V1
V2
V1, p1
V2, p2
FIGURE 2–2 Illustration of quasistatic work for isother-
mal expansion of one mole of an ideal gas. The
system makes a quasistatic transition from a state
at V1, p1 to a state V2, p2 such that pV = RT. The
work done by the gas is equal to the area under
the curve.
V
p
V1
V2
V1, p1
V2, p2
FIGURE 2–3 Illustration of quasistatic work for one
mole of an ideal gas. The dashed line represents
an isobaric expansion at pressure p1 followed by an
isochoric transformation at V2. The dot-dashed line
represents an isochoric transformation at V1 followed
by an isobaric transformation at pressure p2. The
full line represents an isothermal transformation from
V1, p1 to V2, p2, which is only possible if V1p1 = V2p2.
W =
 V1
V1
p dV + p2
 V2
V1
dV = p2(V2 −V1),
(2.20)
which is clearly smaller than that given by Eq. (2.19). If the end points happen to be at
the same temperature, the work given by Eq. (2.20) can be written RT1(V2 −V1)/V2 =
RT2(V2 −V1)/V2 and is less than that given by Eq. (2.18) with T = T1 = T2.
2.4.4 Reversible Adiabatic Expansion
We assume that the gas is perfectly insulated from its surroundings so that δQ = 0 at
each stage of the process. Such processes are called adiabatic processes.11 We allow the
gas to expand quasistatically, and therefore reversibly, from a state V2, p2 to a state V3, p3.
Applying the ﬁrst law to each stage of this process gives
CV dT = −p dV ,
(2.21)
which by Eq. (2.12) may be rewritten in the form
CV
dT
T + RdV
V
= 0,
one mole of ideal gas.
(2.22)
11Some authors use the word adiabatic to mean that δQ = 0 and that the process is reversible, but we use
adiabatic to mean only δQ = 0. An irreversible adiabatic process is illustrated in Section 2.4.5. See Eq. (3.13) for
the entropy change of an adiabatic process.

26
THERMAL PHYSICS
Taking the logarithmic derivative of Eq. (2.12) gives dT/T = dp/p + dV/V which allows
Eq. (2.22) to be recast in the form
CV
dp
p + (CV + R)dV
V
= 0.
(2.23)
Eq. (2.23) is a differential equation for the path in the V, p plane. It can be integrated to
give
ln p + γ ln V = constant,
(2.24)
where γ := (CV + R)/CV = Cp/CV > 1. Exponentiating Eq. (2.24) gives a more usual form
pV γ = p2V γ
2 = p3V γ
3 = K = constant.
(2.25)
The path of the system is represented by the solid line in Figure 2–4. The quasistatic work
is therefore
W = K
 V3
V2
V −γ dV = K V 1−γ
1 −γ

V3
V2
=

p3V3 −p2V2

1 −γ
= CV (T2 −T3).
(2.26)
We have labored to produce this result which, however, could have been derived simply
by applying the ﬁrst law with Q = 0 to give W = −U = −CV (T3 −T2). Nevertheless, we
see clearly how the quasistatic work integral depends on path.
Just as Eq. (2.23) is a differential equation for the path in the V, p plane, Eq. (2.22)
is the differential equation of the path in the T, V plane. It could be integrated di-
rectly, but the same result can be obtained by substitution of Eq. (2.12) into Eq. (2.25)
to obtain
TV γ −1 = constant.
(2.27)
V
p
V3
V ∗
3
V2, p2
V3, p3
V ∗
3 , p3
FIGURE 2–4 The solid line represents a reversible adiabatic expansion for one mole of an ideal gas for γ = 5/3.
The dotted line represents, for the sake of comparison, an isothermal expansion from the same initial state. The
point at V∗
3, p3 is the ﬁnal state for an irreversible adiabatic expansion at constant external pressure p3. In this
irreversible case, the system starts in the state V2, p2, “leaves the page” as it progresses through non-equilibrium
states, and “reenters the page,” ultimately coming to equilibrium at the state V∗
3, p3, which is represented by a
circled point.

Chapter 2 • First Law of Thermodynamics
27
Note that γ −1 = R/CV , consistent with Eq. (2.22). Similarly,
T
p(γ −1)/γ = constant.
(2.28)
2.4.5 Irreversible Adiabatic Expansion
Here again we assume that the gas is perfectly insulated from its surroundings so that
δQ = 0 at each stage of the process. We start out at the same state V2, p2 as for the
reversible adiabatic process treated above, but we allow the gas to expand suddenly
against a constant reduced external pressure p3 that is chosen to have the same value as
p3 for the ﬁnal state of the reversible adiabatic expansion considered above. During this
expansion, the pressure of the gas is not well-deﬁned, so we cannot represent this process
by a path in Figure 2–4. Because this process is irreversible, it will come to equilibrium
in a state having temperature T∗
3 and volume V ∗
3 different from those for the reversible
case. The work done will be W = p3(V ∗
3 −V2) and the change in internal energy will be
U = CV (T∗
3 −T2). Since Q = 0 we will have W = −U, which becomes
p3(V ∗
3 −V2) = CV (T2 −T∗
3).
(2.29)
By using Eq. (2.12), we can write p3V ∗
3 = RT∗
3 and p3V2 = RT2p3/p2, in which case Eq. (2.29)
can be written in the form
T∗
3
T2
= CV + R p3/p2
CV + R
= 1 −q + qr,
(2.30)
where r := p3/p2 and q := (γ −1)/γ . In this same notation, Eq. (2.28) for the reversible
adiabatic expansion leads to
T3
T2
= rq.
(2.31)
We shall see that T∗
3 > T3. This is illustrated in Figure 2–5.
0.5
1
1.5
2
0.6
0.8
1.2
1.4
T ∗
3 /T2
r
T3/T2
FIGURE 2–5 Graphs of T3/T2 for a reversible adiabatic process, Eq. (2.30), and T∗
3/T2 for an irreversible adiabatic
process, Eq. (2.31), versus r = p3/p2 for q = 2/5, which corresponds to γ = 5/3. The straight line corresponds to
T∗
3/T2 and shows that T∗
3 > T3 for r ̸= 1.

28
THERMAL PHYSICS
We ﬁrst note for r = 1 that T∗
3 = T3 = T2 as expected. Then we take derivatives with
respect to r to obtain
d
dr
T∗
3
T2

= q;
d
dr
T3
T2

= qrq−1.
(2.32)
These derivatives are also equal for r = 1, so the curve represented by Eq. (2.31) is tangent
to the line represented by Eq. (2.30) at r = 1. Since q −1 = −1/γ is negative, we see that
the slope of a graph of T∗
3 versus r is less than that of T3 versus r for any r < 1. Moreover,
the slope of a graph of T∗
3 versus r is greater than that of T3 versus r for any r > 1. Hence,
T∗
3 > T3 for any r ̸= 1, which means that the irreversible adiabatic expansion results in
a ﬁnal state with greater temperature than the reversible adiabatic expansion. The same
would be true for contraction, in which case V3 < V2 and r > 1. For the end points of the
two processes, Eq. (2.12) can be written p3V3 = RT3 and p3V ∗
3 = RT∗
3 . Taking the ratio of
these equations gives
V ∗
3
V3
= T∗
3
T3
.
(2.33)
From this result, we see that V ∗
3 > V3. In summary, irreversible adiabatic expansion or
contraction against a constant external pressure p3 results in a different ﬁnal state (larger
temperature and volume) than a reversible adiabatic expansion to a ﬁnal state12 having
pressure p3.
2.5 Enthalpy
The enthalpy (sometimes called the heat function) is deﬁned by
H := U + pV.
(2.34)
Since U, p, and V are all functions of state, H is also a function of state. In general,
dH = dU + p dV + V dp.
(2.35)
For quasistatic work such that Eq. (2.8) holds, Eq. (2.35) becomes
dH = δQ + V dp.
(2.36)
By combining Eqs. (2.10) and (2.36), we obtain
Cp :=
 δQ
dT

p
=
∂H
∂T

p
.
(2.37)
12The ﬁnal state depends on the details of the irreversible process. Here we have considered only a speciﬁc
case and demonstrated that the ﬁnal state is different from that for a reversible adiabatic process. Later we
shall introduce a new state variable S, the entropy, in which case it can be shown that the entropy change for
a reversible adiabatic process is zero but that for an irreversible adiabatic process is positive.

Chapter 2 • First Law of Thermodynamics
29
Comparison of Eq. (2.37) with Eq. (2.9) shows that H plays the same role at constant p as U
does at constant V. We will see that this role is very general after developing the second law
and studying Legendre transformations. In essence, the dependence of U on V is replaced
by the dependence of H on p. Thus, if Q = 0 and W = 0, we have U = 0, so energy
is conserved and U is a constant. From Eq. (2.36) we see that for δQ = 0 and constant p
we have dH = 0, so H is a constant. Actually, a less restrictive condition than constant
p sufﬁces for ﬁnite changes. If Q = 0 and the only work done by the system is against a
pressure reservoir with constant pressure pr, the ﬁrst law gives U = −prV which can
be written in the form
(U + prV ) = 0.
(2.38)
Then if p = pr in the initial and ﬁnal states of the system, Eq. (2.38) becomes
H = 0;
Q = 0 and p = pr in initial and ﬁnal states.
(2.39)
Example Problem 2.3. We saw above that the internal energy, U, of an ideal gas was inde-
pendent of volume, V , and therefore only a function of temperature, T. Use this information
together with the deﬁnition of H to show that

∂H/∂p

T = 0, which means that the enthalpy of
an ideal gas is a function of only the temperature, T.
Solution 2.3. We take the partial derivative of Eq. (2.34) while holding T constant to obtain
∂H
∂p

T
=
∂U
∂V

T
∂V
∂p

T
+ V + p
∂V
∂p

T
.
(2.40)
For an ideal gas, (∂U/∂V )T = 0 so the ﬁrst term on the right vanishes. From the ideal gas law
V = NRT/p we obtain
∂V
∂p

T
= −NRT
p2
= −V
p .
(2.41)
Hence the last two terms on the right of Eq. (2.40) cancel, and we are left with
∂H
∂p

T
= 0,
ideal gas.
(2.42)
Actually, Eq. (2.42) follows from more elementary considerations. Substitution of the ideal gas
law into Eq. (2.34) for one mole gives H = U(T) + RT, so we see immediately that H depends
only on T. Differentiation with respect to T gives our former result Cp = CV + R.
Example Problem 2.4.
As heat is supplied to ice at temperature 0 ◦C and atmospheric
pressure, the ice melts to become water, still at its melting point 0 ◦C, until all of the ice has
melted. The heat needed to melt the ice is 80 cal/g. How much does the enthalpy change if one

30
THERMAL PHYSICS
mole of ice is melted? Show that this is equivalent to an effective heat capacity that is a Dirac
delta function at the melting point.
What would you have to know to calculate the corresponding change of the internal energy
U and what would that change be?
Solution 2.4. Integration of Eq. (2.36) at constant p gives an enthalpy change H = Q.
One mole of ice has a mass of 18 g, so H = 18 g/mol × 80 cal/g = 1440cal/mol. Since
the temperature does not change during melting, an effective heat capacity can be deﬁned
formally by
Ceff
p
= H δ(T −TM),
(2.43)
where TM is the melting point and δ(T −TM) is the Dirac delta function. Equation (2.43) can be
justiﬁed by integration from TM −ϵ to TM + ϵ. From a different perspective, a graph of H versus
T has a discontinuous step at TM whose formal derivative is a delta function. See Section 3.4.1
for a more thorough discussion.
From Eq. (2.15) at constant p we obtain U = H −pV so we would have to know
V to evaluate U. We can estimate V as follows: The volume of ice shrinks about 9% on
melting and its density is about 1 g/cm3. So for one mole, V ≈−0.09 × 1 cm3/g × 18 g/mol =
−1.6 cm3/mol = −1.6 × 10−6 m3/mol. One standard atmosphere is p = 1.01 × 105 N/m2. Thus
pV = −0.16 J/mol = −0.04 cal/mol, which is a negligible correction. So U ≈H for melting
of ice. This is typical for melting of condensed phases. On the other hand, for the water-steam
transition, V ≈2.24 × 10−2 m3/mol, roughly 1000 times larger in magnitude than for melting.
So for evaporation, pV ≈6 cal/mol. But for the evaporation transition, H = 9720 cal/mol so
the difference between U and H is larger but still practically negligible.

3
Second Law of Thermodynamics
Even though the ﬁrst law of thermodynamics is obeyed, there are additional limitations
on processes that can occur naturally. The second law of thermodynamics deals quanti-
tatively with these limitations and is expressed in terms of an inequality that is obeyed
by changes of a new state function, the entropy S, which is postulated to exist. These
limitations are due to the fact that all natural processes in thermodynamic systems are
irreversible. The boundary between natural processes and processes that are forbidden by
thermodynamics can be characterized in terms of idealized processes that are reversible.
For an idealized reversible process, which is hypothetical, the entropy change obeys an
equality and this allows the entropy change to be calculated. If a system, by virtue of
suitable constraints, is such that all natural processes are forbidden by the second law,
it is in a state of thermodynamic equilibrium. This leads to a criterion for thermodynamic
equilibrium in terms of the entropy.
Historically, the entropy function was discovered by studying limitations that occur
during the process of transformation of heat into work, even though energy is con-
served. Theoretically, these processes were imagined to be accomplished by engines
that exchange heat with external heat sources, do mechanical work, and return to their
original thermodynamic state after each cycle. These processes were assumed to obey the
following postulates [1, p. 30]:
Postulate of Kelvin: “A transformation whose only ﬁnal result is to transfer into work
heat extracted from a source which is at the same temperature throughout is impossible.”
Postulate of Clausius: “A transformation whose only ﬁnal result is to transfer heat from
a body at a given temperature to a body at a higher temperature is impossible.”
These historical postulates forbid the existence of a process in which a virtually inﬁnite
amount of work can be obtained by extracting with 100% efﬁciency heat from a huge
thermal source (e.g., the ocean). An engine that would accomplish such a process is
sometimes called a perpetual motion machine of the second kind.1 In fact, many people
have come up with clever ideas and claims of such perpetual motion machines and have
attempted to patent them, but careful analysis has always shown that some irreversible
1A perpetual motion machine of the ﬁrst kind is one that would violate the conservation of energy itself,
which is already ruled out by the ﬁrst law of thermodynamics.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X
31
Copyright © 2015 Elsevier Inc. All rights reserved.

32
THERMAL PHYSICS
process occurs such that their efﬁciency cannot exceed the theoretical efﬁciency (see
Eq. (3.27)) allowed by the second law.
Fermi [1, pp. 31-34] has shown that the postulates of Kelvin and Clausius are equivalent.
The key phrase in each of them is “only ﬁnal result.” One can certainly transfer heat from a
refrigerator to a room at higher temperature, but other things must change in the process,
for example, work must be expended by a motor. Based on these postulates, a Carnot
engine, which is a hypothetical reversible engine, and other imagined irreversible engines
can be used [1, chapter IV] to develop a logical process that leads to a classical formula for
the entropy (see Eq. (3.33)).
Rather than dwell on this historical justiﬁcation of the second law, we shall state it as a
postulate in very general terms and then relate it to its historical roots.
3.1 Statement of the Second Law
For a thermodynamic system, there exists a function of state, S, called the entropy. S is a
function of a complete set of extensive state variables that includes the internal energy,
U. For all other extensive variables held ﬁxed, S is a monotonically increasing function of
the internal energy U. For a homogeneous system, S is an extensive function and its slope
∂S/∂U = 1/T, where the positive quantity T is the absolute temperature.2 If the system is
a composite system, S is the sum of the entropies of its constituent subsystems.
An isolated system is a chemically closed system for which δQ = 0 and δW = 0, so
dU = 0 and U is a constant. Therefore also Q = 0, W = 0, and U = 0. For an isolated
system, changes of S obey the inequality
S ≥0,
isolated system, allowed changes,
(3.1)
where the inequality corresponds to a natural irreversible process and the equality corre-
sponds to a hypothetical idealized reversible process.
If the entropy of an isolated system is a maximum subject to its internal and external
constraints, all natural irreversible processes are forbidden by Eq. (3.1) so the system is in
a state of equilibrium. This leads to the following equilibrium criterion:
Entropy criterionfor equilibrium: The criterion for an isolated thermodynamic system to
be in internal equilibrium is that its total entropy be a maximum with respect to variation
of its internal extensive parameters, subject to external constraints and any remaining
internal constraints. Isolation constitutes the external constraints of chemical closure,
perfect thermal insulation and zero external work, which require the internal energy to
be constant.
For example, consider an isolated composite system consisting of two subsystems
having different temperatures and separated by an insulating wall (internal constraint). If
2For a homogeneous system, the absolute thermodynamic temperature is deﬁned by a partial derivative
1/T : = ∂S/∂U or alternatively by T = ∂U/∂S, where all other members of the complete set of extensive variables
are held constant. Thus T exists independent of any particular measuring device (thermometer). See Fermi
[1, p. 45] for a related discussion in terms of the Carnot cycle.

Chapter 3 • Second Law of Thermodynamics
33
the wall is then allowed to conduct heat (removal of an internal constraint), the energies of
the two systems will change until the temperatures are equalized and a new equilibrium,
corresponding to a state of higher entropy, is established.
In Chapter 6 we will discuss the application of this entropy criterion for equilibrium
and deduce from it several alternative and useful criteria for equilibrium.
3.1.1 Discussion of the Second Law
The second law of thermodynamics is a postulate. The fact that it is believed to be true is
based on extensive experimental testing. It can be rationalized on the basis of statistical
mechanics, which of course is based on its own postulates. It can also be derived, as is
done in classical thermodynamics for chemically closed systems, from other postulates
of Kelvin or Clausius, as stated above. In order to make contact with the historical
development of the second law and to derive equations that allow calculation of the
entropy, we ﬁrst digress to apply Eq. (3.1) to a composite system consisting of sources of
heat and work.
We consider an isolated composite system having total entropy Stot and apply Eq. (3.1)
in the form
Stot ≥0,
isolated system, allowed changes.
(3.2)
We assume that our composite system consists of a chemically closed system of interest
having entropy S, a heat source having entropy Ss, and a purely mechanical system capable
only of exchanging work. By deﬁnition, there is no entropy associated with this purely
mechanical system, so the total entropy of our composite system is
Stot = S + Ss.
(3.3)
The heat source is assumed to be a homogeneous thermodynamic system whose only
function is to exchange heat; it does no work, has a ﬁxed number of moles of each
chemical component, a temperature Ts and an internal energy Us. Thus dSs = (1/Ts)dUs by
deﬁnition of the absolute temperature of the heat source. We denote by δQ a small amount
of heat extracted from the source.3 From the ﬁrst law we have −δQ = dUs, so dSs = −δQ/Ts.
Thus dStot = dS −δQ/Ts and for inﬁnitesimal changes, Eq. (3.2) becomes
dS ≥δQ
Ts
,
chemically closed system, allowed changes.
(3.4)
In Eq. (3.4), the term chemically closed system pertains to the system of interest, having
entropy S. The inequality pertains to a natural irreversible process and the equality
pertains to an idealized reversible process. Thus
dS > δQ
Ts
,
chemically closed system, natural irreversible changes.
(3.5)
3δQ is assumed to be so small and the heat source has, by deﬁnition, a sufﬁciently large heat capacity that it
remains practically unchanged during this process.

34
THERMAL PHYSICS
For reversible heat ﬂow, which is an idealization that separates irreversible heat ﬂow from
forbidden heat ﬂow, Ts can differ only inﬁnitesimally from T, the temperature of the
system, so we have
dS = δQ
T ,
chemically closed system, idealized reversible changes.
(3.6)
Equations (3.5) and (3.6) are sometimes offered as a statement of the second law, although
the distinction between Ts and T is not always made.4
If our system of interest were simply another heat source capable of no other change,
we would have dS = dU/T by deﬁnition of its absolute temperature. Then δW = 0 so
dU = δQ from the ﬁrst law and we would have dS = δQ/T. For spontaneous heat conduc-
tion, a natural irreversible process, we would need
dStot = dS + dSs = δQ
 1
T −1
Ts

> 0,
(3.7)
which results in δQ(Ts −T) > 0. This means that spontaneous heat conduction, with no
other change, occurs only from a higher temperature to a lower temperature, in agreement
with our intuition and the postulate of Clausius stated above.
For ﬁnite changes, we can integrate Eq. (3.4) to obtain
S ≥
 δQ
Ts
,
chemically closed system, allowed changes,
(3.8)
where the equality sign is for a reversible process and requires Ts = T. Our system of
interest can do work (on the mechanical subsystem) of amount
W = −U +

δQ,
(3.9)
provided that Eq. (3.8) is satisﬁed. We emphasize that our system of interest is not
isolated, so its entropy can be made to decrease by extracting heat reversibly. Therefore,
if a chemically closed system is not isolated, its entropy can increase or decrease, and the
process that brings about this change can be either reversible or irreversible, depending
on the relationship of S to

δQ/Ts for that process.
In classical thermodynamics, one often speaks of heat reservoirs. A heat reservoir is a
heat source with such a large heat capacity that its temperature remains constant.5 If the
heat source in Eq. (3.8) is replaced by a heat reservoir of temperature Tr from which an
amount of heat Qr is extracted, we obtain
S ≥Qr
Tr
,
chemically closed system, allowed changes.
(3.10)
4See the footnote on page 48 of Fermi [1] for further discussion of Ts. Some books [5, 16] write dS > δQ/T
which is more restrictive than Eq. (3.5); such an equation applies to a process in which the heat conduction
between the heat source and the system of interest is reversible but other processes that take place within the
system of interest are irreversible.
5For example, if a heat source has a constant heat capacity Cr and an amount of heat Qr is extracted from it,
its temperature would change by Tr = −Qr/Cr. For a reservoir, Cr is assumed to be so large that Tr can be
made arbitrarily small, and therefore zero for all practical purposes.

Chapter 3 • Second Law of Thermodynamics
35
If the heat source consists of a number of such reservoirs, Eq. (3.8) becomes
S ≥

r
Qr
Tr
,
chemically closed system, allowed changes
(3.11)
and Eq. (3.9) is replaced by
W = −U +

r
Qr.
(3.12)
If the amounts of heat Qr in Eqs. (3.11) and (3.12) are very small, the sums can be replaced
by integrals, and the result is essentially the same as Eqs. (3.8) and (3.9).
A system surrounded by perfectly insulating walls requires δQ = 0 and is said to be
adiabatic. For an adiabatic system, Eq. (3.8) becomes
S ≥0,
chemically closed adiabatic system, allowed changes.
(3.13)
But Eq. (3.9) yields W = −U, so such a system is not isolated and can still do work. Chan-
dler [12, p. 8] states the second law by means of Eq. (3.13) which applies to transformations
that are adiabatically accessible, those corresponding to the inequality being irreversible
and those corresponding to the equality being reversible.
For a cyclic process, the system returns to its original state after each cycle. Since S is a
state function, S = 0 for a cyclic process and Eq. (3.11) becomes
0 ≥

r
Qr
Tr
,
cyclic process, chemically closed system, allowed changes.
(3.14)
For a continuous distribution of reservoirs,
0 ≥
 δQ
Tr
,
cyclic process, chemically closed system, allowed changes.
(3.15)
For an adiabatic cyclic process, δQ = 0, so Eq. (3.15) becomes 0 ≥0 and compatibility
would require the equality sign to hold, consistent with the fact that an adiabatic cyclic
process is reversible.
3.2 Carnot Cycle and Engines
In classical thermodynamics, the second law of thermodynamics is usually rationalized by
considering processes involving the conversion of work to heat by engines that return to
their original thermodynamic state after one cycle. Comparison is made to a hypothetical
engine, known as a Carnot engine, which is imagined to execute a reversible cycle. The
Carnot cycle pertains to an idealized engine in which the working substance is one mole6
of an ideal gas. There are four segments to the cycle, as depicted in Figure 3–1. All segments
involve reversible processes, so the whole cycle is reversible. Segment AB is a reversible
isothermal expansion in which an amount of heat |Q2| = Q2 is extracted from a heat source
at a high temperature T2. Segment BC is a reversible adiabatic expansion. Segment CD
6We could also consider any ﬁxed number of moles of an ideal gas.

36
THERMAL PHYSICS
p
V
T2
T1
A
B
C
D
FIGURE 3–1 The Carnot cycle in the V, p plane. The working substance is an ideal gas and the cycle consists of
four reversible segments. AB is isothermal expansion at temperature T2, BC is adiabatic expansion, CD is isothermal
compression at temperature T1, and DA is adiabatic compression. The ﬁgure is drawn for γ = 5/3.
is a reversible isothermal compression in which an amount of heat |Q1| = −Q1 is given
up to a heat sink at temperature T1. Both the source and the sink are assumed to be
heat reservoirs, so their temperatures do not change. Finally, segment DA is a reversible
adiabatic compression. In order for these segments to form a closed cycle, we can apply
Eq. (2.27) to each of the adiabatic segments to obtain
T2V γ −1
B
= T1V γ −1
C
;
T2V γ −1
A
= T1V γ −1
D
.
(3.16)
Division of one of these equations by the other and extraction of the γ −1 root gives
VA
VB
= VD
VC
.
(3.17)
Combining Eq. (3.17) with the ideal gas law gives
pA
pB
= pD
pC
,
(3.18)
so the geometry of the cycle is completely known and simple to express.
On the adiabatic segment BC, δQ = 0 so we have WBC = −UBC = CV (T2 −T1). This
exactly cancels the work CV (T1 −T2) done by the gas on the other adiabatic segment. The
work done by the gas on the isothermal expansion segment AB is RT2 ln(VB/VA). Recalling
that U depends only on T for an ideal gas means that UAB = 0 for that segment, so
|Q2| = RT2 ln(VB/VA).
(3.19)
Similarly, for the isothermal compression segment CD, we obtain
|Q1| = −RT1 ln(VD/VC) = RT1 ln(VB/VA),
(3.20)
where Eq. (3.17) has been used in the last step. Dividing Eq. (3.19) by Eq. (3.20) we obtain
|Q1|
T1
= |Q2|
T2
.
(3.21)

Chapter 3 • Second Law of Thermodynamics
37
For the entire cycle, U = 0 so the total work done by the gas during the cycle is W = |Q2|−
|Q1|. The efﬁciency of the cycle is therefore
η := W
|Q2| = 1 −|Q1|
|Q2| = 1 −T1
T2
.
(3.22)
This efﬁciency is always less than unity except for a heat sink at absolute zero, which is
deemed to be impossible.
Let us examine the meaning of Eq. (3.21) in terms of the second law. Since the entropy
is a function of state, we have S = 0 for a cycle. Applying Eq. (3.11) with the equality, for
our reversible cycle, we obtain
0 = Q2
T2
+ Q1
T1
= |Q2|
T2
−|Q1|
T1
(3.23)
in agreement with Eq. (3.21).
Beginning with the Carnot cycle, Fermi [1, chapter IV] proves a number of other things
based on the Kelvin/Clausius postulates. These are used to rationalize the existence of the
entropy and to formulate the second law. Here, we take the opposite approach by quoting
the main results and demonstrating how they follow from the second law.
•
Any reversible engine working between the same two temperatures T2 and T1 has the
same efﬁciency as a Carnot engine. We follow the same procedure as we did in deriving
Eq. (3.23) except that the amounts of heat are now |Q′
2| and |Q′
1| which might differ from
those for a Carnot engine. Thus we obtain
0 = Q′
2
T2
+ Q′
1
T1
= |Q′
2|
T2
−|Q′
1|
T1
.
(3.24)
It follows that the ratio |Q′
1|/|Q′
2|
=
T1/T2 is the same as for a Carnot engine.
From Eq. (3.12) with U = 0, the amount of work done in the cycle is now W′ =
|Q′
2| −|Q′
1|, so
η′ := W′
|Q′
2| = 1 −|Q′
1|
|Q′
2| = 1 −T1
T2
= η.
(3.25)
•
Any irreversible engine working between the same two temperatures T2 and T1 has a
smaller efﬁciency than a Carnot engine. This result follows by applying Eq. (3.11) with
the inequality to obtain (superscript i for irreversible)
0 > Qi
2
T2
+ Qi
1
T1
= |Qi
2|
T2
−|Qi
1|
T1
,
(3.26)
which leads to |Qi
1|/|Qi
2| > T1/T2. The amount of work done in the cycle is now Wi =
|Qi
2| −|Qi
1|, resulting in
ηi := Wi
|Qi
2|
= 1 −|Qi
1|
|Qi
2|
< η.
(3.27)

38
THERMAL PHYSICS
•
In a cycle of any reversible engine that receives heat δQ from a number of sources at
temperature T,
 δQ
T = 0.
(3.28)
This follows from Eq. (3.8) with the equality by recognizing that S = 0 for a cycle. In
classical thermodynamics, Eq. (3.28) is deduced by arguing that any reversible cycle can
be approximated to arbitrary accuracy by a very large number of small Carnot cycles.
It is actually Eq. (3.28) that was used to deduce that a state function, now known as the
entropy, exists. By integrating from point A to point B along some reversible path and
the back again to A along some other reversible path, we create a reversible cycle. Since
the integral from B to A along the return path is the negative of the integral from A to B
along that path, it follows that
 B
A
δQ
T

reversible path I
=
 B
A
δQ
T

reversible path II
.
(3.29)
Since the values of the integrals in Eq. (3.29) depend only on their end points, their
integrand must be the differential of some function, namely dS = δQ/T, which is
Eq. (3.6). In mathematics, 1/T would be called an integrating factor for δQ.
•
In a cycle of any irreversible engine that receives heat δQ from a number of sources at
temperature Ts,
 δQ
Ts
< 0.
(3.30)
This follows from Eq. (3.11) with the inequality by recognizing that S = 0 for a cycle.
Example Problem 3.1. Analyze a Carnot refrigerator in which heat |Q1| = Q1 is extracted
(from the refrigerator) at a low temperature T1 and given to a Carnot engine running in
reverse; then |Q2| = −Q2 is extracted from that Carnot engine and given to a sink at higher
temperature T2.
Solution 3.1. The magnitudes |Q2| and |Q1| are still given, respectively, by Eqs. (3.19) and
(3.20), so Eq. (3.21) still applies. But now an amount of work W = −W > 0 must be done on the
system, where W = Q1 + Q2 = |Q1| −|Q2| = −W. Thus
|Q1|
W
=
T1
T2 −T1
.
(3.31)
We see that only a small amount of work W must be provided to extract |Q1| from the refrigerator
provided that T1 is not too much lower than T2. Since an amount of heat |Q2| = |Q1|(T2/T1)
must be given up to the source, the cooling of a refrigerator can result in a large amount of
heat given up to the surrounding room. Of course the process that takes place in an actual
refrigerator is irreversible, so even a larger ratio of the removed heat to the work W is required
than given by Eq. (3.31). Indeed, by using Eq. (3.26) for an irreversible engine, we obtain the
inequality |Qi
1|/W < T1/(T2 −T1).

Chapter 3 • Second Law of Thermodynamics
39
The considerations that led to Eq. (3.31) can also be applied to analyze a heat pump
that adds an incremental amount of heat from an inexpensive source at temperature T1 to
heat a room at temperature T2. In that case, a more meaningful quantity is
|Q2|
W
=
T2
T2 −T1
.
(3.32)
Thus the heat pump will require only a small amount of work to provide |Q2| if the source
temperature T1 is close to T2. For a real (irreversible) heat pump we would have |Qi
2|/W <
T2/(T2 −T1).
3.3 Calculation of the Entropy Change
From Eq. (3.29) it follows that the change in entropy of a system that begins in state A and
ends in state B is given by
S ≡S(B) −S(A) =
 B
A
δQ
T ,
any reversible path connecting A and B.
(3.33)
In Eq. (3.33), we emphasize that the path of integration is any reversible path. Since S is
function of state, the entropy change S(B)−S(A) will be the same no matter how the system
changes from A to B, for example by an irreversible process, but it can only be calculated
by using a reversible path. In practice, one uses some convenient reversible path to make
the computation simple. Equation (3.33) only deﬁnes the difference in entropy between
states. We could choose some standard state O and then calculate the differences S(A) −
S(O) and S(B) −S(O). Later we will encounter the third law of thermodynamics, according
to which there is a standard state whose entropy can be taken to be zero.
Example Problem 3.2. The heat capacity at constant volume of a number of substances can
be represented empirically by an equation of the form
CV = a + bT + cT2,
(3.34)
where a, b, and c are constants. Calculate the change in internal energy and the change in
entropy when the temperature changes from T1 to T2 at constant volume.
Solution 3.2. At constant volume, we have dU = CV dT and dU = δQ = T dS. Thus,
U = U2 −U1 =
 T2
T1
CV dT = aT + bT2/2 + cT3/3

T2
T1
(3.35)
and
S = S2 −S1 =
 T2
T1
CV /T dT = a ln T + bT + cT2/2

T2
T1
.
(3.36)

40
THERMAL PHYSICS
Example Problem 3.3. Consider an isolated composite system consisting of two subsystems,
(1) and (2) respectively, having ﬁxed volumes V1 and V2 and heat capacities at constant volume
at temperature T of C1(T) and C2(T). Suppose that the subsystems are separated initially by an
insulating wall and are at equilibrium with initial temperatures T1 < T2. Then let very small
amounts of energy pass very slowly through the wall by heat transfer so that each subsystem
passes through a series of equilibrium states until the system comes to a ﬁnal equilibrium state.
Calculate the temperatures of the subsystems at each stage of the process and study the total
entropy change until a maximum entropy has been reached.
Solution 3.3. At some intermediate stage of the process, the changes in energy and entropy
will be given by
0 = (U) =
 T∗
1
T1
C1(T) dT +
 T∗
2
T2
C2(T) dT
(3.37)
and
(S) =
 T∗
1
T1
C1(T)
T
dT +
 T∗
2
T2
C2(T)
T
dT ≥0.
(3.38)
Then take differentials of these expressions to obtain
0 = C1(T∗
1 ) dT∗
1 + C2(T∗
2 ) dT∗
2
(3.39)
and
d(S) = C1(T∗
1 )
T∗
1
dT∗
1 + C2(T∗
2 )
T∗
2
dT∗
2 ≥0.
(3.40)
Substitution of Eq. (3.39) into Eq. (3.40) gives
d(S) = C1(T∗
1 )
 1
T∗
1
−1
T∗
2

dT∗
1 ≥0,
(3.41)
which for positive dT∗
1 requires (1/T∗
1 −1/T∗
2 ) ≥0. In view of Eq. (3.37), this requires T1 <
T∗
1 ≤T∗
2 < T2 at each stage of the process. When T∗
1 increases to T∗
2 , d(S) = 0 and S will reach
its maximum value at some new equilibrium temperature T∗
1 = T∗
2 = Teq. This can be seen in
principle by integrating Eq. (3.41) from T1 to Teq, but that would require speciﬁcation of C1(T)
and C2(T) to enable T∗
2 to be expressed as a function of T∗
1 . Nevertheless, the ﬁnal result will
satisfy
0 = (U) =
 Teq
T1
C1(T) dT +
 Teq
T2
C2(T) dT
(3.42)
and
(S) =
 Teq
T1
C1(T)
T
dT +
 Teq
T2
C2(T)
T
dT > 0.
(3.43)
For the simple case when C1 and C2 are independent of T, the reader is invited to carry out
these calculations explicitly.

Chapter 3 • Second Law of Thermodynamics
41
3.4 Combined First and Second Laws
For a chemically closed system, the ﬁrst law gives
dU = δQ −δW.
(3.44)
For a simple7 homogeneous isotropic system for which U depends only on S and V,
dU =
∂U
∂S

V
dS +
∂U
∂V

S
dV .
(3.45)
For a reversible transformation in this system, for which the only work is the quasistatic
work, we have
δQ = T dS;
δW = p dV ;
reversible.
(3.46)
Substitution of Eq. (3.46) into Eq. (3.44) gives
dU = T dS −p dV .
(3.47)
We can therefore identify the derivatives
T =
∂U
∂S

V
;
−p =
∂U
∂V

S
.
(3.48)
We emphasize that Eq. (3.47) holds for all inﬁnitesimal changes of U(S, V) within the
ﬁeld of equilibrium states. Equation (3.46), which is only true for reversible processes, was
only used to identify the derivatives in Eq. (3.45). Equations that give explicit forms of the
functions T(S, V) and p(S, V) are known as equations of state. If all8 equations of state are
known, Eq. (3.47) can be integrated to recover the function U(S, V), except for an additive
constant which has to do with the arbitrary zero of energy. If the second partial derivatives
of U are continuous, as we shall assume to be the case for thermodynamic functions, the
order of partial differentiation does not matter and we obtain
 ∂T
∂V

S
= ∂2U
∂V ∂S = ∂2U
∂S∂V = −
∂p
∂S

V
.
(3.49)
(∂T/∂V)S = −
	
∂p/∂S

V is an example of a Maxwell relation. In Chapter 5 we will take up
Maxwell relations for systems that depend on several variables.
Since Eq. (3.44) holds even for irreversible transformations and Eq. (3.47) is generally
true, we can eliminate dU to obtain
p dV −δW = T dS −δQ.
(3.50)
7Note that Eqs. (3.45) and (3.47) hold only for a chemically closed system in which no chemical reactions
are occurring. If chemical reactions are allowed, U would depend on additional variables (progress variables
of the reactions). Equation (3.6) would not hold if these reactions were irreversible. See Eq. (5.128) for further
clariﬁcation.
8For open systems, one must include the numbers of moles of each chemical component, N1, N2, . . . , Nκ as
additional variables in U, in which case there are more equations of state (see Chapter 5). In general, U depends
on a complete set of extensive state variables.

42
THERMAL PHYSICS
For reversible transformations, Eq. (3.46) holds and both sides of Eq. (3.50) are zero. But for
an irreversible process, Eq. (3.46) no longer applies. Instead, Eq. (3.5) applies and Eq. (3.50)
leads to an interesting inequality. We divide Eq. (3.50) by T and rearrange to obtain
p dV −δW
T
+ δQ
T = dS.
(3.51)
Then we subtract δQ/Ts from both sides of Eq. (3.51) and apply Eq. (3.5) to obtain
p dV −δW
T
+ δQ
 1
T −1
Ts

= dS −δQ
Ts
> 0,
natural, irreversible.
(3.52)
The ﬁrst term on the left of Eq. (3.52) is due to the process of irreversible work and the
second term on the left is due to the irreversible process of heat conduction between
the external source and the system. These terms can be regarded [16, pp. 95-95] as repre-
senting entropy production during independent irreversible processes and are separately
positive. A positive value of the ﬁrst term leads to the inequality W < p dV, in agreement
with Eq. (2.5). If we substitute W = pext dV where pext is an effective pressure of purely
mechanical origin as in Eq. (2.3), this work inequality becomes (p −pext) dV > 0. The
second term is the same as in Eq. (3.7), derived for the case in which the system was
considered to be a heat source that could do no work.
We can rearrange Eq. (3.47) in the form
dS = 1
T dU + p
T dV
(3.53)
from which it follows that
1
T =
 ∂S
∂U

V
;
p
T =
 ∂S
∂V

U
.
(3.54)
Equations that give 1/T and p/T as functions of U and V are also equations of state. If
we know these functions, Eq. (3.53) can be integrated to recover S(U, V). We also have the
Maxwell relation (∂(1/T)/∂V)U =
	
∂(p/T)/∂U

V .
Since the entropy is postulated to be a monotonically increasing function of the
internal energy, the internal energy is also a monotonically increasing function of the
entropy. The inverse transformation between S(U, V) and U(S, V) is therefore unique,
and either of these functional forms can be chosen to give a complete representation
of the thermodynamic system.9 One speaks of the entropy representation S(U, V) or
the energy representation U(S, V). Either of these equations can be regarded as a fun-
damental equation of the system and either contains complete information about the
system.
9For more complicated systems, both S and U depend on an additional set of extensive variables, but these
behave just like V.

Chapter 3 • Second Law of Thermodynamics
43
Example Problem 3.4. For a hypothetical thermodynamic system, T = (4/A)(U/V )3/4 and
p = 3U/V , where A is a constant. Find the fundamental equation in the entropy representation.
Solution 3.4. We readily calculate 1/T = (A/4)(V /U)3/4 and p/T = (3A/4)(U/V )1/4 so
Eq. (3.53) takes the form
dS = (A/4)(V/U)3/4 dU + (3A/4)(U/V )1/4 dV ,
(3.55)
which integrates to give S = AU1/4V 3/4 + S0, where S0 is a constant.
Example Problem 3.5. This problem concerns one mole of an ideal monatomic gas that
obeys the equation pV
=
RT, where p is the pressure, V is the volume, T is absolute
temperature, and R is the universal gas constant. The gas has a heat capacity (per mole) at
constant volume of CV = (3/2)R. In its initial state, it is in equilibrium at temperature T1 and
volume V1 in the left chamber of a box, as shown in Figure 3–2. The right chamber of the box,
which has volume V2 −V1, is initially evacuated. The two chambers are surrounded by exterior
walls that are rigid and impenetrable. The chambers are separated initially by an interior wall
that is rigid, impenetrable, and insulating. Under various conditions detailed below, the gas is
allowed to expand and ﬁnally comes to equilibrium in the total volume V2.
Apply the ﬁrst and second laws of thermodynamics, the deﬁnition of CV , the ideal gas
equation of state, and integration to answer the following questions.
(a) Suppose, by whatever means, that the gas expands into the total volume V2 and comes to
equilibrium at temperature T2. What is the change, S, in entropy of the gas from its initial
to its ﬁnal state?
(b) The entire system is maintained at constant temperature T1 by contact with a heat reser-
voir. The gas is allowed to expand by means of an external agent that moves the internal
wall separating the chambers very slowly (such that the gas is practically in equilibrium
at each stage of the process) until the gas occupies the entire volume V2. What is the
change, U, in its internal energy? How much external work, W, does the system do on
the external agent that moves the wall? How much heat, Q, is added to the system during
this process? Compare Q to the relevant S and deduce whether this process is reversible
or irreversible.
V1
V2−V1
Ideal gas
Vacuum
FIGURE 3–2 A monatomic ideal gas at temperature T1 initially occupies the left chamber of the box. The right
chamber of the box, which has volume V2 −V1, is evacuated. The interior wall that separates the gas from the
evacuated chamber is rigid, impenetrable and insulating, but can be moved or ruptured.

44
THERMAL PHYSICS
(c) The entire system is insulated and the wall separating the chambers is suddenly ruptured,
allowing the gas to ﬁll the entire volume V2. How much external work, W, does the system
do? What is the ﬁnal temperature of the gas? Compare Q to the relevant S and deduce
whether this process is reversible or irreversible.
(d) The entire system is insulated. The gas is allowed to expand by means of an external
agent which moves the internal wall separating the chambers very slowly (such
that the gas is practically in equilibrium at each stage of the process) until the
gas occupies the entire volume V2. What is the ﬁnal temperature, T2, of the gas?
Compare Q to the relevant S and deduce whether this process is reversible or
irreversible.
Solution 3.5.
(a) Since S is a state function, S depends only on the initial and ﬁnal states of the system,
irrespective of how the system gets from the initial state to the ﬁnal state. We substitute the
ideal gas law and the equation dU = CV dT into Eq. (3.53) to obtain
dS = CV
dT
T + RdV
V ,
(3.56)
which integrates to give
S = CV ln(T2/T1) + R ln(V2/V1),
one mole of ideal gas.
(3.57)
(b) U depends only on T for an ideal gas, so U = 0. Thus from the ﬁrst law, W = Q. Since the
work is quasistatic, W =

p dV where the integral is to be carried out along an isothermal
path T = T1. Therefore we can use p = RT1/V and take the constants RT1 outside the
integral to obtain
Q = W = RT1
 V2
V1
dV
V
= RT1 ln(V2/V1).
(3.58)
Since T2 = T1 for this process, part (a) gives S = R ln(V2/V1) so
S = Q/T1
(3.59)
and the process is reversible (as expected for quasistatic work). Note that the entropy
increases for this reversible process. In this case, entropy increase does not automatically
imply irreversibility because the system is not isolated. Similarly, for reversible adiabatic
contraction, both Q and S are negative, and the entropy of the system decreases. This
does not violate Eq. (3.1) because the system is not isolated.
(c) W = 0 because the outer wall is rigid and there is no way to do mechanical work on the
environment of the system. Since Q = 0, we conclude from the ﬁrst law that U = 0.
Since U depends only on T, we have T2 = T1. (During the process itself, which we shall
see is irreversible, T is at best inhomogeneous and probably undeﬁned.) The change in
entropy, from part (a), is again S = R ln(V2/V1) > 0. Therefore, since δQ = 0 at every stage
of the process,
S >
 δQ
T = 0,
(3.60)
so the process is irreversible as expected.

Chapter 3 • Second Law of Thermodynamics
45
(d) Q = 0 because the system is insulated. The work is quasistatic so δW = p dV , and since
δQ = 0 at each stage of the process, the ﬁrst law gives dU + p dV = 0. Since dU = CV dT,
this becomes CV dT + RT dV /V = 0. Division by T (which is not constant in this process)
yields CV dT/T + R dV /V = 0 which integrates to give
CV ln(T2/T1) + R ln(V2/V1) = 0.
(3.61)
Thus, S = 0 and
S =
 δQ
T = 0,
so the process is reversible and isentropic, as expected for this quasistatic process with
adiabatic walls. By means of Eq. (2.27), the ﬁnal temperature can be written more succinctly
as T2 = T1(V1/V2)2/3, so the temperature drops, as expected, for this reversible adiabatic
expansion.
3.4.1 Latent Heat
When a substance melts or evaporates, heat must be supplied to partially or totally break
atomic bonds and rearrange structure, and hence to change the phase to a state of higher
disorder, which we shall see later is a state of higher entropy. Melting and vaporization pro-
cesses are generally carried out at constant pressure, for example, atmospheric pressure.
The heat needed to change the phase reversibly at constant pressure and temperature
is known as latent heat. Heat must be supplied when a solid melts to become a liquid
(heat of melting); the same amount is given up when a liquid freezes to become a solid
(latent heat of fusion). When a liquid becomes a gas, it is necessary to supply heat (heat
of vaporization); when a gas condenses to become a liquid, the same amount of heat is
given up (latent heat of condensation). These are generally reported as positive quantities,
usually per mole or per unit mass.
Consider, for example, the melting of ice, which takes place at atmospheric pressure
at a temperature of 0 ◦C = 273.15 K. As we supply heat to cold ice, it is warmed from
below its melting point to 273.15 K where melting occurs and water begins to form. As
heat continues to be supplied, the ice-water mixture remains at 273.15 K until all of the ice
melts. This requires 80 calories of heat per gram of ice, the latent heat of fusion. Further
heating causes the temperature of the water to rise.
Processes such as this, which take place at constant pressure, may be analyzed conve-
niently in terms of the enthalpy, H = U +pV previously introduced in connection with the
ﬁrst law (see Section 2.5). We saw that dH = dU + p dV + V dp which in view of Eq. (3.47)
becomes
dH = T dS + V dp.
(3.62)
But at constant pressure we have
dH = Cp dT,
(3.63)

46
THERMAL PHYSICS
where Cp is the heat capacity at constant pressure. Equation (3.63) applies in the absence
of phase change, say for TI ≤T < TM and also for TM < T ≤TW, where TI is the initial
temperature of the ice, TM is the melting point and TW is the ﬁnal temperature of the water.
At T = TM, H increases by the amount HM, the latent heat of fusion. The total change in
H is therefore
H =
 TM
TI
Cp(ice) dT + HM +
 TW
TM
Cp(water) dT.
(3.64)
H as a function of T is shown in Figure 3–3a. Formally, the effective heat capacity at
the melting point can be represented as a delta function (the formal derivative of a step
function) as shown in Example Problem 2.4.
By combining Eq. (3.62) with Eq. (3.63) at constant pressure, we obtain
dS = Cp
T dT,
(3.65)
which can be integrated to ﬁnd the entropy change that occurs prior to melting and
subsequent to melting. During the melting itself, we integrate10 Eq. (3.62) at constant p to
obtain SM = HM/TM, which is called the entropy of fusion. Therefore, the total change
of entropy is given by
S =
 TM
TI
Cp(ice)
T
dT + HM
TM
+
 TW
TM
Cp(water)
T
dT.
(3.66)
S as a function of T is shown in Figure 3–3b.
If the range of temperature is not large, Cp(ice) and Cp(water) can be considered to be
practically independent of T, so we have the simpliﬁcations
H ≈Cp(ice)(TM −TI) + HM + Cp(water)(TW −TM)
(3.67)
265
270
275
280
285
290
295
250
500
750
1000
1250
1500
1750
ΔHM
(a)
265
270
275
280
285
290
295
1
2
3
4
5
6
7
ΔSM
(b)
FIGURE 3–3 (a) Enthalpy change H in cal/mol and (b) entropy change S in cal/(mol K) as a function of temperature
T in K for melting of ice. The curvature of the logarithms in S is not apparent on this scale. The jumps are related
by HM = TMSM. (a) Enthalpy H versus T and (b) Entropy S versus T.
10We assume that the whole process is done slowly and carefully so that it is reversible.

Chapter 3 • Second Law of Thermodynamics
47
and
S ≈Cp(ice) ln TM
TI
+ HM
TM
+ Cp(water) ln TW
TM
.
(3.68)
To get an idea of the magnitudes involved, we approximate Cp(ice)≈Cp(water)≈1 cal/g K,
take TI = −10 ◦C and TW = 20 ◦C. Then for every mole of H2O (18 g/mol) we have
H = (189 + 1440 + 351) cal/mol = 1980 cal/mol
(3.69)
and
S = (0.67 + 5.27 + 1.27) cal/K mol = 7.21 cal/K mol.
(3.70)
For many monatomic substances, SM = HM/TM ∼R ≈2 cal/K mol, an empirical rule
known as Richard’s rule. For ice, the entropy of fusion is much larger (5.27 cal/K mol)
because of the complexity of the H2O molecule. For vaporization, a similar empirical rule
known as Trouton’s rule leads to the estimate SV = HV /TV ∼10.5R ≈21 cal/K mol,
as compared to 26 cal/K mol for water. The fact that the entropy of vaporization is larger
than the entropy of fusion is because essentially all atomic bonds must be broken for
evaporation and because of the large volume change from liquid to gas.
3.5 Statistical Interpretation of Entropy
The entropy S enters classical thermodynamics as a mysterious state function whose
changes can be calculated from Eq. (3.33). Unlike other state variables such as the internal
energy U or the pressure p, it has no roots in classical mechanics. Its existence is related
to the fact that the absolute temperature T is regarded in thermodynamics to be a state
variable, and the entropy S turns out to be its conjugate variable.11 A more thorough
understanding of entropy requires a statistical analysis. Later we will discuss entropy in
the context of the formal postulates that underlie statistical mechanics. For now, we give a
brief statistical interpretation based on a few simple ideas.
3.5.1 Relationship of Entropy to Microstates
In order to understand entropy, we must appreciate that for every macrostate of a system,
which corresponds to a ﬁxed energy and other extensive parameters, there are a number 
of compatible microstates, and the system could be in any one of them.12 In fact, it could
progress through a number of compatible microstates as time evolves. If we assume that
the probability of a given microstate is 1/, it is reasonable to postulate that the entropy
is a function of the number of microstates, that is,
S = f ().
(3.71)
11In the differential dU = T dS −p dV, T is said to be conjugate to S and −p is conjugate to V. For a more
general deﬁnition of conjugate variables, see Section 5.5.
12According to quantum mechanics, the system will have a discrete set of energy eigenstates, which are
actually countable. See Chapters 16 and 26 for details.

48
THERMAL PHYSICS
For an isolated system, natural processes are those that correspond to an increase in
S. Moreover, S is deﬁned to be an increasing function of the internal energy and we
would expect the number of compatible microstates to increase with energy. We therefore
anticipate that f () will be a monotonically increasing function of , which turns out to
be the case.
Once Eq. (3.71) is accepted, the form of the function f () can be determined by
considering an isolated composite system S made up of two subsystems having entropies
S1 and S2. Since S is assumed to be additive for composite systems, we have
S = S1 + S2.
(3.72)
If the number of microstates for S1 is 1 and that for S2 is 2, then for the total system S
the number of microstates is 12. Therefore, Eq. (3.72) may be written
f (12) = f (1) + f (2).
(3.73)
In Eq. (3.73), we ﬁrst set 2 = 1 to obtain
f (1) = f (1) + f (1),
(3.74)
from which we conclude that f (1) = 0. Then we differentiate Eq. (3.73) partially with
respect to 2 to get (the prime denotes the derivative with respect to the argument)
1f ′(12) = f ′(2)
(3.75)
and again set 2 = 1 to get
f ′(1) = k
1
,
(3.76)
where k = f ′(1) is a constant. We then integrate Eq. (3.76) to obtain f (1) = k ln 1 + C
where C is a constant. Since f (1) = 0, we conclude that C = 0. Therefore, returning to our
general notation, we have
S = k ln .
(3.77)
In order for S to be a monotonically increasing function of , we must choose k > 0.
For an isolated system, Eq. (3.77) is a fundamental equation that relates entropy to
statistical mechanical concepts. It states that the entropy is proportional to the logarithm
of the number of microstates that are compatible with a given macrostate. The constant of
proportionality k depends on the units used to measure S. In order to agree with classical
thermodynamics, we need to choose k = kB which is known as Boltzmann’s constant:
kB = 1.381 × 10−16 erg/K = 1.381 × 10−23 J/K = 3.301 × 10−24 cal/K.
(3.78)
It is related to the gas constant R = NAkB where NA = 6.022 mol−1 is Avogadro’s number
(also known as Loschmidt-Zahl in the German literature). Hence
R = 8.314 × 10−7 erg/(mol K) = 8.314 J/(mol K) = 1.987 cal/(mol K).
(3.79)
For a more rigorous justiﬁcation of Eq. (3.77) in the context of information theory and
the microcanonical ensemble, see Chapter 15, particularly Eq. (15.14), and Chapter 16.

4
Third Law of Thermodynamics
The third law of thermodynamics is the latest of the three laws of thermodynamics to
be developed. It insures that the entropy remains well-deﬁned at the absolute zero of
temperature and allows one to deﬁne a zero of entropy that is consistent with statistical
mechanics. This avoids having to deal with entropy differences; instead, we can deal with
entropies as absolute quantities, analogous to absolute temperature but unlike energy.
4.1 Statement of the Third Law
The entropy S of a thermodynamic system in internal equilibrium approaches a universal
constant S0, independent of phase, as the absolute temperature T tends to zero. Alter-
natively, one could say that S →S0 in a state for which the quantity (∂U/∂S){ext} →0,
where {ext} stands for the remaining members of a complete set of extensive variables.
By convention, and in agreement with statistical mechanics, the value of this universal
constant S →S0 is taken to be zero. Since entropy is a monotonically increasing function
of temperature, this convention results in the entropy being a positive quantity.
4.1.1 Discussion of the Third Law
According to statistical mechanics, as motivated by Eq. (3.77), the entropy of an isolated
system is given by
S = kB ln ,
(4.1)
where kB is Boltzmann’s constant and  is the number of microstates that correspond to a
given macrostate. If at absolute zero only a unique ground state of the system is occupied,
then  = 1 and S = 0. Possibly the ground state could be degenerate, in which case
 ̸= 1 even at T = 0. But this degeneracy would have to be massive to make a signiﬁcant
difference in the entropy of a macroscopic system at T = 0. Indeed, to get a contribution
S = 10−10R = 10−10kBNA for one mole at absolute zero would require the ground state
degeneracy 0 to satisfy 10−10NA = ln 0, where NA is Avogadro’s number. This yields
0 ∼e6×1013 ∼102.6×1013. But such a huge degeneracy is contrary to experience. As the
ground state of a quantum system is approached (as T →0), the number of accessible
quantum states decreases quite rapidly and is no longer of exponential order, even though
there could still be a ground state of much smaller degeneracy. An illuminating discussion
of this point has been presented by Benjamin Widom [17, chapter 5].
The third “law” is an extension by Max Planck [15, p. 273] of the so-called Nernst
postulate [2, p. 277] that was made in an attempt to justify an empirical rule of Thomsen
and Berthelot for chemical reactions that take place at constant temperature and pressure.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00004-1
49
Copyright © 2015 Elsevier Inc. All rights reserved.

50
THERMAL PHYSICS
Nernst conjectured that their empirical rule for equilibrium, which is equivalent to min-
imizing the enthalpy change H of the reaction, would be in agreement with the proper
thermodynamic criterion obtained by minimizing an appropriate change in free energy1
of the reaction, provided that the entropy change S tends to zero as T →0. This can be
interpreted to mean that the entropy S itself tends to some constant, independent of the
extent of the reaction, as T →0. For convenience, Planck set this entropy constant to zero,
which agrees with the convention used to deﬁne entropy in statistical mechanics. Callen
[2, p. 30] states the third law as an independent postulate, namely that S = 0 in a state
for which ∂U/∂S = 0 (which is true at absolute zero by deﬁnition of the thermodynamic
temperature). From the point of view of classical thermodynamics, one could deal with
entropy differences and it would not be necessary to adopt a state of zero entropy;
however, doing so leads to simplicity and builds a strong bridge to statistical mechanics.
4.2 Implications of the Third Law
The third law has certain implications regarding heat capacities and other properties of
materials as T →0. From Eq. (3.47) with dV = 0, we obtain CV dT = T dS where CV is the
heat capacity at constant volume. The change in entropy at constant volume from one
temperature to another is given by

CV /T dT. Thus
S(T1, V ) =
 T1
0
CV (T, V )
T
dT.
(4.2)
In order for this integral to converge, it is necessary for CV to depend on T in such a way
that CV →0 as T →0. Recall that CV was taken to be a constant for an ideal gas; clearly
such an ideal gas becomes impossible as T →0. For insulating solids, one ﬁnds both
theoretically and experimentally that CV ∝T3 as T →0. For metals, nearly free electrons
contribute to the heat capacity and CV ∝T as T →0. Similar considerations apply to the
heat capacity at constant pressure. From Eq. (3.62) with dp = 0, we obtain Cp dT = T dS,
where Cp is the heat capacity at constant pressure. Thus
S(T1, p) =
 T1
0
Cp(T, p)
T
dT
(4.3)
and it is necessary2 for Cp →0 as T →0.
An interesting experimental veriﬁcation of the third law has been discussed by Fermi
[1, p. 146]. At temperatures below T0 = 292 K, gray tin (α, diamond cubic) is the stable
form and above this temperature, white tin (β, tetragonal) is stable. These are allotropic
forms of pure tin. It turns out, however, that white tin can exist (in internal equilibrium)
below 292 K, even though it is unstable with respect to transformation to gray tin. It is also
1This is the change G of the Gibbs free energy of the reaction, whose deﬁnition and properties we explore
later.
2In order for the integrals in Eqs. (4.2) and (4.3) to converge at T = 0, it will sufﬁce for CV or Cp to go to zero
very weakly as T →0, for instance ∝Tϵ where ϵ > 0.

Chapter 4 • Third Law of Thermodynamics
51
S
Gray
White
292 K
0 K
T
FIGURE 4–1 Entropies S of gray and white tin as a function of absolute temperature T. Below T0 = 292K, gray
tin is stable and above this temperature white tin is stable. The full curves denote stable phases and the dashed
curves denote unstable phases. White tin can be supercooled below T0 so its heat capacity can be measured and its
entropy can be calculated. The jump in entropy at T0 between gray tin and white tin is due to the latent heat of
transformation.
possible to measure the heat capacities of both forms of tin down to very low tempera-
tures. One can therefore evaluate the entropy of white tin at 292 K in two different ways,
the ﬁrst by integrating its heat capacity from absolute zero and the second by integrating
the heat capacity of gray tin from absolute zero and then adding the entropy associated
with transformation to white tin at 292 K. See Figure 4–1 for a graphic illustration. Thus
(with subscripts g and w for gray and white), we have
Sw(292 K) =
 292 K
0
Cw(T)
T
dT = 12.30 cal/mol K,
(4.4)
and
Sg(292 K) =
 292 K
0
Cg(T)
T
dT = 10.53 cal/mol K.
(4.5)
The heat of transformation from gray to white tin is Hg→w = 535 cal/mol so the entropy
of transformation is Sg→w = Hg→w/T0 = 535/292 = 1.83 cal/mol K. Adding this to the
result of Eq. (4.5) gives 12.36 cal/mol K, in reasonable agreement with Eq. (4.4).
The third law can also shed light on the behavior of the coefﬁcient of thermal expan-
sion, α, and the compressibility, κT, as T →0. Since S →0 as T →0 independent of V or
p, one has
 ∂S
∂V

T=0
= 0;
 ∂S
∂p

T=0
= 0.
(4.6)
Through a Maxwell relation (see Eq. (5.90)), it can be shown that
 ∂S
∂p

T
= −
 ∂V
∂T

p
= −V α,
(4.7)
where α is the coefﬁcient of isobaric thermal expansion. Indeed, it has been veriﬁed
experimentally that α →0 as T →0. By means of another Maxwell relation (see Eq. (5.86))

52
THERMAL PHYSICS
 ∂S
∂V

T
=
 ∂p
∂T

V
= α/κT,
(4.8)
where κT is the coefﬁcient of isothermal compressibility. Thus, κT must either remain non-
zero as T →0 or go to zero more slowly than α.
See Lupis [5, pp. 21-23] for further discussion of experimental veriﬁcation of the third
law as well as a discussion of some of its other consequences, particularly consequences
concerning chemical reactions. See Fermi [1, p. 150] for an excellent discussion of the
entropy of mercury vapor.

5
Open Systems
Until now we have dealt with chemically closed thermodynamic systems in which there
is no exchange of chemical components with the environment. Such chemically closed
systems can receive heat Q from the environment and do work W on their environment.
Their change in internal energy is given by U = Q −W, which for inﬁnitesimal changes
is dU = δQ −δW. For reversible changes in a simple isotropic system, the (quasistatic)
work is δW = p dV, where p is the pressure and V is the volume. The heat received in a
reversible change is δQ = T dS, where T is the absolute temperature and S is the entropy.
If the mole numbers of each chemical component are constant (no chemical reactions),
the combined ﬁrst and second laws (see Chapter 3) lead to
dU = T dS −p dV .
(5.1)
Open systems can exchange chemical components with their environment. Conse-
quently the number of moles of each chemical component, Ni, for i = 1, 2, . . . , κ, are
variables. This requires several modiﬁcations. The ﬁrst law must be amended to read
U = Q −W + Ech,
(5.2)
where Ech is the energy (sometimes called chemical heat) that is added to the system when
chemical components are exchanged with its environment. Moreover, U now becomes a
function of S, T and all of the Ni, so additional terms are needed in Eq. (5.1). This also sets
the stage for changes of Ni due to chemical reactions within the system, which can even
occur for a chemically closed system for which Ech = 0. We shall ﬁrst treat an open system
having a single component and then go on to treat multicomponent systems.
5.1 Single Component Open System
If the simple chemically closed isotropic system discussed above has only one chemical
component and is now opened to allow exchange of that component with the environ-
ment, U must be regarded as a function of S, V, and N, the number of moles1 of that
component. Then the differential of the internal energy becomes
dU = T dS −p dV + μ dN,
(5.3)
where now
T =
∂U
∂S

V,N
;
−p =
∂U
∂V

S,N
;
μ =
∂U
∂N

S,V
.
(5.4)
1Instead of N, we could use the mass, M or the number of atoms N . Then the resulting chemical potentials
would be per unit mass or per atom instead of per mole.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00005-3
53
Copyright © 2015 Elsevier Inc. All rights reserved.

54
THERMAL PHYSICS
The quantity μ, introduced originally by Gibbs [3], is called the chemical potential, by
analogy to the thermal potential T. We shall see later that μ can be expressed as a function
of only p and T. It is the internal energy per mole2 of component added reversibly to the
system at constant S and V. Nevertheless, Eq. (5.3) is a relationship among state functions
and always holds for inﬁnitesimal changes within the ﬁeld of equilibrium states.
5.1.1 Ideal Gas
The chemical potential of a monocomponent ideal gas can be written in the form
μ(T, p) = μ∗(T) + RT ln p = RT ln
p
p∗(T),
(5.5)
where p∗(T) is a function of temperature with dimensions of pressure. In this standard
but misleading notation, μ∗(T) is a function of temperature only but does not have the
dimensions of an energy. This can be ﬁxed by writing μ∗(T) + RT ln p = μ∗(T) + RT ln p0 +
RT ln p/p0, where p0 is a reference pressure, usually taken to be one atmosphere. Then the
quantity μ0(T, p0) = μ∗(T) + RT ln p0 is the chemical potential of this ideal gas at p0 and
we can write Eq. (5.5) in the form
μ(T, p) = μ0(T, p0) + RT ln p/p0.
(5.6)
Moreover, if p0 is equal to one atmosphere, it is often omitted from formulas with the
understanding that all pressures are expressed in atmospheres. In this case, the term
RT ln p0 = 0, so numerically μ∗(T) = μ0(T, p0), even though the dimensions do not agree.
We avoid this shortcut in the interest of clarity, so pressures can be measured in any units.
Even though each term on the right of Eq. (5.6) depends on p0, their sum is independent
of p0. Even for a real gas, liquid, or solid, μ(T, p) must be independent of any reference
pressure such as p0.
Example Problem 5.1. For N moles of an ideal gas, the equation of state Eq. (2.12) takes the
form pV = NRT. Show that its chemical potential can be expressed as a function of only its
concentration c = N/V and the temperature. At the standard temperature T0 = 25 ◦C and a
pressure of one standard atmosphere (1.01325 × 105 Pa), the volume of one mole of an ideal gas
is 22.4 l. If one mole of gas remains at temperature T0 but is compressed so that it occupies only
2 l, how much does its chemical potential change compared to that at standard temperature
and pressure?
Solution 5.1. We substitute p = cRT into Eq. (5.5) to obtain
μ = μ∗(T) + RT ln cRT = μ∗(T) + RT ln RT + RT ln c.
(5.7)
2Since U is only deﬁned up to an additive constant, μ is similarly only deﬁned up to a compatible additive
constant. In practice, one usually adopts so-called standard states and deals with the quantities μ −μ0, where
μ0 refers to the standard state.

Chapter 5 • Open Systems
55
The change in chemical potential at temperature T0 is μ = RT0 ln c/c0 = RT0 ln(22.4/2) =
2.416RT0. We have T0 = 25 + 273.15 = 298.15K, so RT0 = 2479 J and μ = 5868J. Alternatively,
we could evaluate the new pressure, which would be p = 11.2 atmospheres, and use Eq. (5.6) to
get the same answer. At a given temperature, we see that the chemical potential of an ideal gas
is just a measure of concentration, or pressure, on a logarithmic scale.
Example Problem 5.2. According to statisticalmechanics, the chemical potential per atom of
a monatomic gas having atoms of mass m is given by kBT ln[n/nQ(T)], where kB is Boltzmann’s
constant, n is the number of atoms per unit volume, and nQ(T) is the quantum concentration
given by nQ(T) = (mkBT/2π¯h2)3/2, where ¯h = h/2π and h is Planck’s constant. This result
is based on a convention for the zero of energy used to deduce the quantum states of a free
particle; see Section 19.3.1 for details. Find explicit expressions for p∗(T) and μ∗(T) in Eq. (5.5).
Solution 5.2. To obtain the chemical potential per mole, we simply multiply the given
chemical potential per atom by Avogadro’s number NA and recall that NAkB = R. The ideal
gas law can similarly be converted to obtain p = nkBT. Therefore,
μ = RT ln
p
nQ(T)kBT
(5.8)
from which we identify
p∗(T) = nQ(T)kBT = (mkBT/2π¯h2)3/2kBT.
(5.9)
Of course μ∗(T) = −RT ln p∗(T). Formally, numerical evaluation of μ∗(T) involves taking the
logarithm of a quantity with dimensions of pressure, but the units in which pressures are
expressed will cancel when μ is evaluated, as illustrated by Eq. (5.8).
5.2 Multicomponent Open Systems
The generalization of Eq. (5.3) to open multicomponent systems is straightforward. U now
depends on the variable set S, V, N1, N2, . . . , Nκ for a system of κ chemical components.
Then
dU = T dS −p dV +
κ

i=1
μi dNi,
(5.10)
where
T =
∂U
∂S

V,{Ni}
;
−p =
∂U
∂V

S,{Ni}
;
μi =
 ∂U
∂Ni

S,V,{N′
i }
.
(5.11)
Here, {Ni} stands for the entire set N1, N2, . . . , Nκ, and {N′
i} stands for that same set but
with Ni missing. Since this notation is cumbersome, we will often omit these subscripts,
but they should always be borne in mind to avoid confusion. Equation (5.11) deﬁnes κ + 2
intensive variables (p, T, and κ chemical potentials, one for each chemical component),
although we shall see that only κ + 1 of them are independent (see Eq. (5.45)). One says

56
THERMAL PHYSICS
that such a thermodynamic system has κ + 1 degrees of freedom. These thermodynamic
degrees of freedom should not be confused with the number of degrees of freedom
(typically of order 1023) of the underlying microscopic system. Equation (5.11) is valid
for all inﬁnitesimal changes of S, V, {Ni} within the ﬁeld of equilibrium states and these
changes are reversible.
5.2.1 Maxwell Relations for Open Systems
In general, Maxwell relations are obtained by equating the mixed second derivatives of a
function of two or more variables. Suppose that we have some function f of three variables,
x, y, and z. Then
df =
∂f
∂x

y,z
dx +
∂f
∂y

z,x
dy +
∂f
∂z

x,y
dz
(5.12)
and3
∂2f
∂x∂y = ∂2f
∂y∂x ;
∂2f
∂y∂z = ∂2f
∂z∂y ;
∂2f
∂z∂x = ∂2f
∂x∂z .
(5.13)
Equations (5.12) and (5.13) can be extended to any number of dependent variables. If we
apply Eq. (5.13) to the ﬁrst two members of Eq. (5.10), we obtain
 ∂T
∂V

S,{Ni}
= −
 ∂p
∂S

V,{Ni}
.
(5.14)
Since all Ni are held constant in Eq. (5.14), it would also hold for a chemically closed system
in which there are no chemical reactions. For an open system, we have additional Maxwell
relations such as
 ∂T
∂Ni

S,V,{N′
i }
=
∂μi
∂S

V,{Ni}
,
(5.15)
−
 ∂p
∂Ni

S,V,{N′
i }
=
∂μi
∂V

S,{Ni}
,
(5.16)
and for i ̸= j
 ∂μi
∂Nj

S,V,{N′
j }
=
 ∂μj
∂Ni

S,V,{N′
i }
.
(5.17)
For a system having κ chemical components, the number of these Maxwell relations is
(κ + 2)(κ + 1)/2.
Additional Maxwell relations may be obtained by solving Eq. (5.10) for the differential
of another variable, for example,
3These relations are true if the derivatives exist and are continuous, which we will assume to be the case for
thermodynamic functions.

Chapter 5 • Open Systems
57
dS = 1
T dU + p
T dV −
κ

i=1
μi
T dNi.
(5.18)
Then
∂(1/T)
∂V

U,{Ni}
=
∂(p/T)
∂U

V,{Ni}
,
(5.19)
∂(1/T)
∂Ni

U,V{N′
i }
= −
 ∂(μi/T)
∂U

V,{Ni}
,
(5.20)
∂(p/T)
∂Ni

U,V{N′
i }
= −
 ∂(μi/T)
∂V

U,{Ni}
,
(5.21)
and for i ̸= j
∂(μi/T)
∂Nj

U,V,{N′
j }
=
∂(μj/T)
∂Ni

U,V,{N′
i }
.
(5.22)
Maxwell relations may be used to simplify thermodynamic expressions and also to derive
formulae for desired quantities in terms of experimentally measurable quantities.
Example: relationship of Cp to CV: A useful result of Maxwell relations is the general
formula (previously quoted in Eq. (2.16) without proof) that connects the heat capacity
at constant pressure Cp to that at constant volume, CV . Here, we deal with a chemically
closed system in the absence of chemical reactions, so we drop the subscripts {Ni} for
the sake of simplicity. From the deﬁnitions CV := (δQ/dT)V and Cp := (δQ/dT)p and
δQ = dU + p dV for quasistatic work, we have
CV =
∂U
∂T

V
and
(5.23)
CP =
∂U
∂T

p
+ p
 ∂V
∂T

p
=
∂U
∂T

V
+
∂U
∂V

T
∂V
∂T

p
+ p
 ∂V
∂T

p
.
(5.24)
Therefore,
Cp = CV +
∂U
∂V

T
+ p
 ∂V
∂T

p
.
(5.25)
To get the derivative (∂U/∂V)T, we make use of the fact that the entropy is a function of
state with differential
dS = 1
T dU + p
T dV = 1
T
∂U
∂T

V
dT +
 1
T
∂U
∂V

T
+ p
T

dV ,
(5.26)
where we now regard S to be a function of T and V. Therefore
 ∂
∂V
 1
T
∂U
∂T

V

T
=
 ∂
∂T
 1
T
∂U
∂V

T
+ p
T

V
,
(5.27)

58
THERMAL PHYSICS
which becomes
1
T
∂2U
∂V ∂T = 1
T
∂2U
∂T∂V −1
T2
∂U
∂V

T
+ p

+ 1
T
 ∂p
∂T

V
.
(5.28)
After cancellation of the mixed partial derivatives, Eq. (5.28) gives4
∂U
∂V

T
+ p

= T
 ∂p
∂T

V
,
(5.29)
which may be substituted into Eq. (5.25) to give
Cp = CV + T
 ∂p
∂T

V
∂V
∂T

p
.
(5.30)
Finally, we use the relation5
 ∂p
∂T

V
 ∂T
∂V

p
∂V
∂p

T
= −1
(5.31)
to eliminate
	
∂p/∂T

V . Then the deﬁnitions of the coefﬁcient of expansion α := (1/V)
(∂V/∂T)p and the compressibility κT := −(1/V)
	
∂V/∂p

T lead to
Cp = CV + TV α2
κT
,
(5.32)
which is the same as Eq. (2.16). The isothermal compressibility κT is always positive
whereas the coefﬁcient of thermal expansion α is usually positive but can be negative
or even zero, as it is for water near 4 ◦C. Since Eq. (5.32) depends on α2, we see that
Cp −CV ≥0. For gases, Cp can be considerably larger than CV but for condensed phases
the difference between them is relatively small.
Example: relationship of Cp to CV, alternative method: For a reversible change we have
δQ = T dS, so we can write
CV = T
 ∂S
∂T

V
and
(5.33)
Cp = T
 ∂S
∂T

p
= T
 ∂S
∂T

V
+ T
 ∂S
∂V

T
∂V
∂T

p
.
(5.34)
Thus
Cp = CV + T
 ∂S
∂V

T
∂V
∂T

p
.
(5.35)
4This is called the Helmholtz equation and sometimes written (∂U/∂V)T = T2	
∂(p/T)/∂T

V .
5This relation follows immediately from the differential dV = (∂V/∂T)p dT +
	
∂V/∂p

T dp by setting dV = 0
and solving for the remaining partial derivative.

Chapter 5 • Open Systems
59
To ﬁnd an expression for (∂S/∂V)T, we invent a new state function6 F := U −TS so that
dF = dU −T dS −S dT = −S dT −p dV .
(5.36)
Regarding F to be a function of T and V, we see that
 ∂S
∂V

T
=
 ∂p
∂T

V
,
(5.37)
so Eq. (5.35) becomes Eq. (5.30) and Eq. (5.32) follows as above.
5.2.2 Other Maxwell Relations
Maxwell relations can be obtained by equating the mixed second partial derivatives of
any state function. This is usually done by deﬁning other functions that are related to
U and S by means of Legendre transformations. A number of speciﬁc examples are
presented in Section 5.5.1. Tables of some Maxwell relations and a mnemonic diagram
for remembering them are given by Callen [2, chapter 7] but many others exist and can be
derived as needed.
5.3 Euler Theorem of Homogeneous Functions
A function f (x, y, z) is said to be a homogeneous function of degree n with respect to the
variables x, y, and z if
f (λx, λy, λz) = λnf (x, y, z),
(5.38)
where λ is some parameter. Note that Eq. (5.38) requires a very special type of function and
that many functions are not homogeneous. For a homogeneous function of degree n, the
Euler theorem states that
x
 ∂f
∂x

y,z
+ y
∂f
∂y

z,x
+ z
∂f
∂z

x,y
= nf (x, y, z).
(5.39)
This theorem, illustrated for three dependent variables, holds for any number of depen-
dent variables.
Proof. We differentiate Eq. (5.38) partially with respect to λ to obtain
∂f (λx, λy, λz)
∂(λx)
∂(λx)
∂λ
+ ∂f (λx, λy, λz)
∂(λy)
∂(λy)
∂λ
+ ∂f (λx, λy, λz)
∂(λz)
∂(λz)
∂λ
= nλn−1f (x, y, z)
(5.40)
and note that ∂(λx)/∂λ = x, ∂(λy)/∂λ = y and ∂(λz)/∂λ = z. After the differentiation is done,
we set λ = 1 in Eqs. (5.40) and (5.39) results. Note especially that if the function f depends
on additional variables, say u and v, such that
f (λx, λy, λz, u, v) = λnf (x, y, z, u, v),
(5.41)
6This state function is actually the Helmholtz free energy, a useful thermodynamic potential that we shall
deﬁne later. For now, it is just a convenient state function that will allow us to get the desired result.

60
THERMAL PHYSICS
Eq. (5.39) still holds, with no corresponding terms for u and v. In other words, Eq. (5.41)
should be interpreted to mean that f is homogeneous in the variables x, y, and z; the
variables u and v are held constant during differentiation and are simply irrelevant insofar
as homogeneity with respect to x, y, and z is concerned.
Examples: The function φ(x, y, z) := x2 + y2 + z4/(x2 + y2) is a homogeneous function of
degree 2 in x, y, and z. We have ∂φ/∂x = 2x −2xz4/(x2 +y2)2, ∂φ/∂y = 2y −2yz4/(x2 +y2)2,
and ∂φ/∂z = 4z3/(x2 + y2). Thus
x∂φ
∂x + y ∂φ
∂y + z∂φ
∂z = 2x2 −
2x2z4
(x2 + y2)2 + 2y2 −
2y2z4
(x2 + y2)2 +
4z3
x2 + y2 = 2φ.
The function ψ(x, y, z) := sin(x/y) + z2/x2 is a homogeneous function of degree zero
in x, y, and z. We have ∂ψ/∂x = (1/y) cos(x/y) −2z2/x3, ∂ψ/∂y = −(x/y2) cos(x/y) and
∂ψ/∂z = 2z/x2, which yields x∂ψ/∂x + y∂ψ/∂y + z∂ψ/∂z = 0.
The function η(x, y, z) := x3 +y3 +z2 is not a homogeneous function with respect to the
variables x, y, and z. The function ζ(x, y, z) := x3z + y3z2 is not a homogeneous function
with respect to the variables x, y, and z, but it is a homogeneous function of degree 3 in x
and y with z held constant. Then x(∂ζ/∂x)y,z + y
	
∂ζ/∂y

x,z = 3ζ.
Note that it is not necessary for n to be an integer, and that n can even be negative.
Thus, the function φ(x, y, z) := (x/yz)1/3 + (1/x)1/3 is a homogeneous function of degree
n = −1/3 in x, y, and z and Eq. (5.39) holds, as the reader may verify.
5.3.1 Euler Theorem Applied to Extensive Functions
We note that U, which is extensive, is a homogeneous function of degree one in the
extensive variables S, V, N1, N2, . . . , Nκ. Thus,
U(λS, λV, λN1, λN2, . . . , λNκ) = λU(S, V , N1, N2, . . . , Nκ).
(5.42)
For example, if we double all of the extensive variables on which U depends, we will obtain
a system that is twice as large but whose intensive variables are unchanged,7 so we will
have twice as much of the same thermodynamic state. Applying the Euler theorem for
n = 1, we obtain
U = TS −pV +
κ

i=1
μiNi.
(5.43)
We call this the Euler equation for U. By taking its differential, we obtain
dU = T dS + S dT −p dV −V dp +
κ

i=1
μi dNi +
κ

i=1
Ni dμi.
(5.44)
7This follows because the intensive variables are partial derivatives of the extensive variable U with respect
to the extensive variables on which U depends, so any constant multiple such as 2 will cancel.

Chapter 5 • Open Systems
61
By comparing with Eq. (5.10), we deduce that
0 = S dT −V dp +
κ

i=1
Ni dμi.
(5.45)
Eq. (5.45) is the Gibbs-Duhem equation for a multicomponent system. It shows that
T, p, and the μi are not independent intensive variables because changes in them are
related. Thus for a κ component system, there are only κ + 1 independent intensive
variables.
For a monocomponent system, there are two independent intensive variables, say p
and T, and μ(p, T) can be regarded to be a function of them.8 In that case, Eq. (5.45) can
be divided by N and written in the form
dμ = −s dT + v dp,
(5.46)
where s := S/N is the entropy per mole and v := V/N is volume per mole (molar volume).
If the functions s(T, p) and v(T, p) are known (these are the two equations of state of
the system), Eq. (5.46) can be integrated to determine μ up to an additive constant that
results from the arbitrary zero of energy. For a two component system, there would be
three independent intensive variables, say p, T, and μ1, and then μ2(p, T, μ1). For a three
component system, there would be four independent intensive variables, etc.
Example Problem 5.3. By using the chemical potential of an ideal gas given by Eqs. (5.5) and
(5.46), determine its equations of state. From these results, calculate the enthalpy per mole h
and the internal energy per mole u and comment on their dependence on pressure. Deduce
the relationship between the molar heat capacities cV and cp at constant volume and constant
pressure and compare with Eq. (2.13).
Solution 5.3. We have v =
	
∂μ/∂p

T = RT/p, which just reproduces the ideal gas law, which is
one equation of state. Also, s = −(∂μ/∂T)p = −dμ∗(T)/dT −R ln p, which is the other equation
of state. Thus, by dividing the Euler equation Eq. (5.43) for a single component by N, we obtain
u = Ts −pv + μ, so the molar enthalpy
h = u + pv = μ + Ts = μ∗(T) −T dμ∗(T)
dT
,
(5.47)
which is a function of only the temperature, independent of pressure. Moreover,
u = h −pv = μ∗(T) −T dμ∗(T)
dT
−RT,
(5.48)
which is also a function of only the temperature, independent of v. We readily compute cp =
dh/dT = −Td2μ∗(T)/dT2 and cv = du/dT = cp −R in agreement with Eq. (2.13), even if cp
and cv depend on T.
8We could make other choices, such as regarding T and μ as the independent variables, and then writing
p(T, μ).

62
THERMAL PHYSICS
Composition: For multicomponent systems, one often regards the independent intensive
variables as being p, T, and composition, where composition9 is designated by the κ −1
independent mole fractions
Xi := Ni/N,
(5.49)
where N = κ
i=1 Ni is the total number of moles. Note that the Xi are intensive variables,
because they are ratios of extensive variables. Moreover, we have
κ

i=1
Xi = 1
(5.50)
so only κ−1 of them are independent, as already stated. Taking the differential of Eq. (5.50)
gives
κ

i=1
dXi = 0
(5.51)
so we note that it is impossible to take a partial derivative with respect to one of the Xi while
holding all of the others constant. In particular, we cannot calculate chemical potentials
by taking a single partial derivative with respect to an Xi, that is,
μi ̸=
 ∂U
∂Xi

S,V,{X′
i }
(5.52)
because the right-hand side is meaningless.
For a system with two components, we could take a set of the independent inten-
sive variables to be p, T, and X1, in which case μ1(p, T, X1) and μ2(p, T, X1). For three
components, independent intensive variables could be p, T, X1, and X2, in which case
μ1(p, T, X1, X2), μ2(p, T, X1, X2), and μ3(p, T, X1, X2). To recover an extensive description,
we could add to these variable sets N or any one of the Ni.
Enthalpy of a multicomponent system: Recall that we deﬁned the enthalpy H := U + pV.
For a multicomponent system
dH = dU + p dV + V dp = T dS + V dp +
κ

i=1
μi dNi,
(5.53)
9For a mass based description, we can describe composition by the mass fractions ωi := Mi/M, where Mi is
the mass of the ith component and M = κ
i=1 Mi is the total mass. The relationship of the ωi to the Xi is nonlinear
and depends on the molecular masses, mi. Speciﬁcally, ωi = miXi/ 
j mjXj.

Chapter 5 • Open Systems
63
where Eq. (5.10) has been used. Thus, H is a natural function10 of S, p, and the Ni and we
have
T =
∂H
∂S

p,{Ni}
;
V =
∂H
∂p

S,{Ni}
;
μi =
 ∂H
∂Ni

S,p,{N′
i}
.
(5.54)
Furthermore, with regard to homogeneity, we see that
H(λS, p, λN1, λN2, . . . , λNκ) = λH(S, p, N1, N2, . . . , Nκ)
(5.55)
because p, being intensive, does not participate. Thus, application of the Euler theorem
gives
H = TS +
κ

i=1
μiNi
(5.56)
which is in agreement with Eq. (5.43) once the deﬁnition of H is used. So we actually get
nothing new (except self-consistency) and Eq. (5.45) follows as well.
5.3.2 Euler Theorem Applied to Intensive Functions
Intensive functions are homogeneous functions of degree zero with respect to extensive
variables. For example, the energy u := U/N per mole or the energy uV := U/V per unit
volume are intensive. They are therefore homogeneous functions of degree zero in the
variables S, V, N1, N2, . . . , Nκ, which means that they can depend only on ratios of these
variables, which ratios are themselves intensive. To see this formally, note that
u = U(S, V , N1, N2, . . . , Nκ)
N
= U(λS, λV, λN1, λN2, . . . , λNκ)
λN
(5.57)
and then choose λ = 1/N to deduce
u = U(s, v, X1, X2, . . . , Xκ),
(5.58)
where s = S/N is the entropy per mole and v = V/N is the volume per mole. But since
the Xi are not all independent we can omit the last of them and write, in terms of κ + 1
independent variables,
u = u(s, v, X1, X2, . . . , Xκ−1)
(5.59)
whose differential turns out to be
du = T ds −p dv +
κ−1

i=1
(μi −μκ) dXi.
(5.60)
10A natural function is a thermodynamic potential that contains information equivalent to a fundamental
equation (for U or S) and whose independent variables are either members of the original complete set of
extensive variables (on which U or S depends) or their conjugate variables (which are the partial derivatives
of U or S with respect to their extensive variables).

64
THERMAL PHYSICS
Equation (5.60) can be veriﬁed by taking the differential of Eq. (5.57) and using Eqs. (5.10)
and (5.43) to simplify the result. Thus
du = dU
N −U
N2 dN = 1
N

T dS −p dV +
κ

i=1
μi dNi

−1
N2

TS −pV +
κ

i=1
μiNi

dN.
(5.61)
But ds = dS/N −(S/N2) dN, dv = dV/N −(V/N2) dN and dXi = dNi/N −(Ni/N2) dN, so
Eq. (5.61) becomes
du = T ds −p dv +
κ

i=1
μi dXi,
(5.62)
which reduces to Eq. (5.60) after dXκ is eliminated. Note in this derivation that the total
number of moles N was treated as a variable, even though the result appears as if we just
treated it as a constant and divided by it.
In a similar way, we can deduce that
uV = u(sV , c1, c2, . . . , cκ),
(5.63)
where sV := S/V is the entropy per unit volume and the ci := Ni/V are the concentrations
of each component (in moles per unit volume). The corresponding differential is
duV = T dsV +
κ

i=1
μi dci.
(5.64)
Similar considerations apply to other intensive variables, such as the enthalpy h := H/N
per mole, which is a function of s, p, X1, X2, . . . , Xκ−1 and whose differential is
dh = T ds + v dp +
κ−1

i=1
(μi −μκ) dXi.
(5.65)
5.4 Chemical Potential of Real Gases, Fugacity
As a further application of Eq. (5.46), we treat the dependence of the chemical potential of
a pure non-ideal gas on temperature and pressure by means of a function known as the
fugacity (see, for example, Denbigh [18, p. 125]). To do this, we replace Eq. (5.5) by
μ(T, p) = μ∗(T) + RT ln f ;
f →p as p →0.
(5.66)
The fugacity f (T, p) is an effective pressure11 that replaces the pressure p of an ideal gas.
Equation (5.66) is based on the idea that all gases will tend toward ideal gas behavior if
sufﬁciently dilute, which will be the case for ﬁxed temperature at sufﬁciently low pressure.
Therefore, the function μ∗(T) is precisely the same function of T as for the corresponding
ideal gas.
11One can also employ a dimensionless fugacity f D = f /p0, where p0 is a reference pressure, by adding a term
RT ln p0 to μ∗(T). Then if p0 = 1 atmosphere and pressures are measured in atmospheres, the term RT ln p0 = 0
numerically.

Chapter 5 • Open Systems
65
200
400
600
800
1000
200
400
600
800
1000
1200
1400
f
O2
CO2
p
Ideal
FIGURE 5–1 Fugacity f (atmospheres) versus pressure p (atmospheres) of O2 and CO2 at T = 200 ◦C based on a cubic
spline ﬁt of data of Darken and Gurry [19, p. 210]. The middle line is for an ideal gas for which f = p. The lowest
data points are for p = 50 atmospheres for which f = 50.5 atmospheres for O2 and 47.8 atmospheres for CO2.
The general dependence of the fugacity on pressure may be deduced by integrating the
equation
v(T, p) =
∂μ(T, p)
∂p

T
= RT
∂ln f
∂p

T
;
f →p as p →0.
(5.67)
In order to avoid a singularity and to incorporate the condition on f at low pressures, we
rewrite Eq. (5.67) in the form
∂ln(f /p)
∂p

T
= v(T, p)
RT
−1
p.
(5.68)
Then integration on pressure at constant temperature from 0 to p gives
ln(f /p) =
 p
0
v(T, p′)
RT
−1
p′

dp′.
(5.69)
If the gas is ideal, the integrand vanishes and one obtains simply f = p. Depending on the
temperature, many gases behave like ideal gases at atmospheric pressure p0, but at high
pressures the deviations from ideality can be quite signiﬁcant. Figure 5–1 shows a plot of
fugacity versus pressure for the gases O2 and CO2 at a temperature of 200 ◦C, as well as for
an ideal gas, for which f = p at all temperatures. Note the opposite deviations from ideality.
Example Problem 5.4. Suppose that a non-ideal gas has an expansion (called a virial
expansion) in terms of pressure of the form
v(T, p)
RT
= 1
p

1 + ˜Bp + ˜Cp2 + · · ·

= 1
p + ˜B + ˜Cp + · · · ,
(5.70)

66
THERMAL PHYSICS
where ˜B(T) and ˜C(T) are virial coefﬁcients that depend on the temperature. Calculate the
fugacity of this gas. For a simple model based on a potential consisting of a hard repulsive
core of diameter σ1, an attractive potential well of constant depth ε in the annular region
between a sphere of diameter σ2 and the repulsive core, and zero potential beyond, the ﬁrst
virial coefﬁcient is given by
˜B(T) = 2π
3

σ 3
1 −(eε/kBT −1)(σ 3
2 −σ 3
1 )
kBT

.
(5.71)
If this is the only important virial coefﬁcient, discuss brieﬂy the effect of temperature on the
fugacity.
Solution 5.4. Equation (5.69) becomes
ln[f (T, p)/p] =
 p
0
[˜B + ˜Cp′ + · · · ]dp′ = ˜B(T)p + ( ˜C(T)/2)p2 + · · · .
(5.72)
Thus,
f (T, p) = p exp[˜B(T)p + ( ˜C(T)/2)p2 + · · · ].
(5.73)
The ﬁrst virial coefﬁcient given by Eq. (5.71) becomes ˜B(T) = −(2π/3)(σ 3
2 −σ 3
1 )(eε/kBT/kBT)
at low temperatures and ˜B(T) = (2π/3)(σ 3
1 /kBT) at high temperatures. It therefore changes
sign from negative to positive as the temperature increases. If this is the only important virial
coefﬁcient, f < p and varies strongly with temperature for low temperatures and f > p and
varies weakly with temperature for high temperatures.
Example Problem 5.5. For the previous example, compare the chemical potential difference
μ(T, p) −μ(T, p0) for a real gas with that for a condensed phase (solid or liquid) for which the
molar volume is given approximately by v(T, p) = v(T, p0)[1−κT(p−p0)], where the isothermal
compressibility κT is evaluated at p0.
Solution 5.5. For the real gas,
μ(T, p) −μ(T, p0) = RT

ln(p/p0) + ˜B(T)(p −p0) + ( ˜C(T)/2)(p2 −p2
0) + · · ·

.
(5.74)
The term RT ln(p/p0) is very important and the other terms represent a small correction unless
the pressure is very large.
For a condensed phase, the integral of
	
∂μ(T, p)/∂p

T = v(T, p) at constant temperature
yields
μ(T, p) −μ(T, p0) = v(T, p0)[(p −p0) −(κT/2)(p −p0)2],
solid or liquid.
(5.75)
Except for very large pressure differences, this difference is small compared to RT.
Therefore, for gases the chemical potential has a signiﬁcant dependence on pressure but for
condensed phases it is practically independent of pressure.

Chapter 5 • Open Systems
67
5.5 Legendre Transformations
Legendre transformations are frequently used in thermodynamics to deﬁne new functions
that depend on a convenient variable set. An example is the enthalpy function H = U +pV
discussed in Chapter 2 with differential given by Eq. (5.53) for a multicomponent system.
In Chapter 6 we will show how some of these functions can be used to formulate useful
criteria for thermodynamic equilibrium. Here we cover some formal aspects of such
transformations.
We treat a system having κ chemical components and for which dU is given by
Eq. (5.10) which we write in the schematic form
dU =
κ+2

i=1
pi dEi.
(5.76)
The extensive variables E1 = S, E2 = V, and Ei+2 = Ni for i = 1, 2, . . . , κ. Evidently
pi =
∂U
∂Ei

{E′
i}
,
(5.77)
so the corresponding (intensive) potentials are p1 = T, p2 = −p, and pi+2 = μi for
i = 1, 2, . . . , κ. The variables pi and Ei are called conjugate variables. We now deﬁne a
Legendre transform by means of the function
Lj := U −pjEj = U −Ej
 ∂U
∂Ej

{E′
j}
,
(5.78)
obtained by subtracting from U the product of the conjugate variables pj and Ej. We
obtain
dLj = dU −pj dEj −Ej dpj = −Ej dpj +
κ+2

i̸=j
pi dEi.
(5.79)
We can regard Lj to be a function of pj and the remaining Ei for i ̸= j. In other words,
Lj depends on the slope of the function U with respect to Ej. Moreover, Lj itself is the
Ej = 0 intercept of a graph of U versus Ej. Since a curve may be deﬁned by the envelope
of its tangent lines, a knowledge of intercept Lj as a function of slope pj is equivalent to a
knowledge of U as a function of Ej, regarding all of the remaining Ei, for i ̸= j to be ﬁxed.
See Callen [2, p. 140] for an extended discussion of this equivalence. Given the function Lj,
Eq. (5.79) yields
Ej = −
 ∂Lj
∂pj

{E′
j}
.
(5.80)
We can therefore write the inverse of Eq. (5.78) in the form
U = Lj + pjEj = Lj −pj
 ∂Lj
∂pj

{E′
j}
.
(5.81)

68
THERMAL PHYSICS
We note the reciprocity (with appropriate sign changes) of the relationship between
U and Lj, so they can be regarded as Legendre transforms of one another.
We next obtain a useful relation between second derivatives of Legendre transforms.
We have
∂2U
∂E2
j
= ∂pj
∂Ej
= −
∂pj
∂(∂Lj/∂pj) = −1/∂2Lj
∂p2
j
.
(5.82)
Thus if U is a convex function (positive second derivative) of Ej, then Lj will be a concave
function (negative second derivative) of pj.
Simple example: For a single variable E, suppose that U = A + BE2, where A and B are
constants. Then p = ∂U/∂E = 2BE and L = U −pE = A−BE2 = A−p2/4B. For the inverse
transformation, we start with L(p) and obtain E = −∂L/∂p = p/2B. Then U = L + pE =
A + p2/4B = A + BE2. We also have ∂2U/∂E2 = 2B and ∂2L/∂p2 = −1/(2B).
We could make an additional Legendre transformation by selecting a second pair of
conjugate variables, say pkEk, and subtracting from Lj. This produces a function
Ljk := Lj −pkEk = U −pjEj −pkEk = Lk −pjEj := Lkj,
(5.83)
which can be thought of as a double Legendre transform of the original U. We will then
have
dLjk = −Ej dpj −Ek dpk +
κ+2

i̸=j,k
pi dEi
(5.84)
and we can regard Ljk to be a function of pj, pk and the remaining Ei, where i ̸= j, k.
This process can be continued up to κ + 1 successive Legendre transforms. Since the
Euler equation is U = κ+2
i=1 piEi, we see that κ + 2 Legendre transforms of U would lead
identically to zero. The total number of possible transforms is therefore 2κ+2 −2.
5.5.1 Speciﬁc Legendre Transforms
We end this section by identifying several speciﬁc Legendre transforms that play an
important role in thermodynamics and statistical mechanics.
Helmholtz free energy F: We deﬁne the Helmholtz free energy by the Legendre transfor-
mation
F := U −TS
(5.85)
with differential
dF = −S dT −p dV +
κ

i=1
μi dNi.
(5.86)
Effectively, the dependence of U on S is replaced by the dependence of F on T, whereas
both U and F depend on V and {Ni}. Thus, F is useful in situations where T is a control

Chapter 5 • Open Systems
69
variable. We note that S = −(∂F/∂T)V,Ni and ∂2U/∂S2 = −1/(∂2F/∂T2). A number of
Maxwell relations can be deduced from dF, one being (∂S/∂V)T,{Ni} =
	
∂p/∂T

V,{Ni}.
Enthalpy H: We have previously mentioned the enthalpy deﬁned by
H := U + pV
(5.87)
with differential
dH = T dS + V dp +
κ

i=1
μi dNi.
(5.88)
Effectively, the dependence of U on V is replaced by the dependence of H on p. We note
that V =
	
∂H/∂p

S,Ni and ∂2U/∂V 2 = −1/(∂2H/∂p2). A Maxwell relation is
	
∂T/∂p

S,{Ni} =
(∂V/∂S)p,{Ni}.
Gibbs free energy G: The Gibbs free energy is a double Legendre transformation from U
or a single Legendre transformation from F or H and is deﬁned by
G := U −TS + pV = F + pV = H −TS.
(5.89)
It has a differential
dG = −S dT + V dp +
κ

i=1
μi dNi.
(5.90)
The control variables for G are T and p as opposed to S and V for U. G is especially
important for the study of chemical reactions that take place at various temperatures
and atmospheric pressure. We note that S
=
−(∂G/∂T)p,Ni and V
=
	
∂G/∂p

T,Ni
as well as ∂2H/∂S2
=
−1/(∂2G/∂T2) and ∂2F/∂V 2
=
−1/(∂2G/∂p2). One Maxwell
relation is
	
∂S/∂p

T,{Ni} = −(∂V/∂T)p,{Ni}. Other useful Maxwell relations involving the
chemical potentials are
	
∂μi/∂p

T,{Ni} = (∂V/∂Ni)T,p,{N′
i} =:
¯Vi and (∂μi/∂T)p,{Ni} =
−(∂S/∂Ni)T,p,{N′
i} =: ¯Si. The quantities ¯Vi and ¯Si are known respectively as the partial
molar volume and the partial molar entropy and are examples of partial molar quantities
discussed in Section 5.6.
Kramers potential K: The Kramers potential, also known as the grand potential and often
denoted by , is obtained by transforming all variables in U except V. It is deﬁned by
K := U −TS −
κ

i=1
μiNi
(5.91)
and has a differential
dK = −S dT −p dV −
κ

i=1
Ni dμi.
(5.92)

70
THERMAL PHYSICS
K depends on T, V, and all of the chemical potentials μi. We note that S = −(∂K/∂T)V,{μi}
and Ni = −(∂K/∂μi)T,V,{μ′
i}, where {μ′
i} stands for the entire set {μi} of chemical potentials
but with μi missing. The potential K is closely related to the grand canonical ensemble of
statistical mechanics and is also useful in problems involving surfaces and interfaces.
Massieu functions: The functions F, H, G, and K, which are known as thermodynamic
potentials, are all Legendre transforms of the internal energy U. One can also begin with
the entropy whose differential is given by Eq. (5.10), namely
dS = (1/T) dU + (p/T) dV −
κ

i=1
(μi/T) dNi.
(5.93)
Its Legendre transforms are known as Massieu functions. For example,12
M1(1/T, V, {Ni}) := S −(1/T)U ≡S[1/T],
(5.94)
where the last notation has been used by Callen [2, p. 151]. It has a differential
dM1 = −U d(1/T) + (p/T) dV −
κ

i=1
(μi/T) dNi.
(5.95)
This differential leads to the Maxwell relation
∂U
∂V

1/T,{Ni}
= −
 ∂(p/T)
∂(1/T)

V,{Ni}
= −p + T
 ∂p
∂T

V,{Ni}
,
(5.96)
which is the same as Eq. (5.29). For an ideal gas, p/T = NR/V and Eq. (5.96) yields
(∂U/∂V)T,{Ni} = 0. Thus, the fact that U depends only on T for an ideal gas, which was
deduced on the basis of experiments on dilute gases, follows from the ideal gas equation
of state and the second law. Some other Massieu functions are
M2(U, p/T, {Ni}) : = S −(p/T)V ≡S[p/T];
(5.97)
dM2 = (1/T) dU −V d(p/T) −
κ

i=1
(μi/T) dNi
and13
M3(1/T, p/T, {Ni}) : = S −(1/T)U −(p/T)V ≡S[(1/T, p/T];
(5.98)
dM3 = −U d(1/T) −V d(p/T) −
κ

i=1
(μi/T) dNi.
One could also add quantities such as μ1/T to S to obtain a function S[μ1/T] that depends
on μ1/T instead of N1. The total number of possible transforms of the entropy is 2κ+2 −2,
just as for the transforms of the thermodynamic potentials.
12M1 is sometimes denoted by  and called the Helmholtz free entropy.
13M3 is sometimes denoted by  (or  by Planck) and is called the Gibbs free entropy.

Chapter 5 • Open Systems
71
Natural variables: The natural variables of a thermodynamic potential are the set of
independent variables that give complete information about the system under consid-
eration. For isotropic multicomponent ﬂuids, the natural variables of the entropy are the
set of extensive variables U, V, {Ni}, where {Ni} = N1, N2, . . . , Nκ. For the internal energy,
the natural variables are S, V, and {Ni}. Since S is a monotonically increasing function
of U with other extensive variables held constant, one can always transform uniquely
from S(U, V, {Ni}) to U(S, V, {Ni}) and vice versa for these fundamental equations. For
the thermodynamic potentials, the natural variables are those independent variables that
result from Legendre transformation. For example, any of the functions F(T, V, {Ni}),
H(U, p, {Ni}), G(T, p, {Ni}), K(T, V, {μi}), M3(1/T, p/T, {Ni}) contain complete information
about a system. It is possible and sometimes useful to express these functions in terms of
other variable sets, as discussed in the next section.
5.6 Partial Molar Quantities
This section applies to any extensive state function that can be expressed in terms
of the complete variable set T, p, {Ni} for a homogeneous system having κ chemical
components. For example, we could consider the internal energy U(T, p, {Ni}), even
though the natural variables for U are the set S, V, {Ni}. We could also consider the
entropy S(T, p, {Ni}) or the enthalpy H(T, p, {Ni}), etc. Of course a transformation of
variables is necessary to convert from the set of natural variables of a function to the
set T, p, {Ni}, except for G(T, p, {Ni}) where these are also its natural variables. As we shall
see in Chapter 6, the temperature T and the pressure p are uniform for phases in mutual
equilibrium, so functions expressed in terms of these intensive variables are particularly
important.
For the generic extensive function Y (T, p, N1, N2, . . . , Nκ), the partial molar quantities
˜Yi are deﬁned as derivatives14
¯Yi :=
 ∂Y
∂Ni

T,p,{N′
i}
.
(5.99)
Since Y is an extensive function in the variables N1, N2, . . . , Nκ, we have
Y(T, p, λN1, λN2, . . . , λNκ) = λY(T, p, N1, N2, . . . , Nκ)
(5.100)
so the Euler theorem gives
Y =
κ

i=1
¯YiNi.
(5.101)
Since T and p are held constant in the deﬁnition Eq. (5.99), we can differentiate
the equations that deﬁne H, F, and G to obtain ¯Hi =
¯Ui + p ¯Vi, ¯Fi =
¯Ui −T ¯Si, and
14Instead of the mole numbers Ni, we could use the masses Mi of each chemical component. Then one could
develop a parallel treatment in terms of partial speciﬁc quantities deﬁned by ˜Yi := (∂Y/∂Mi)T,p,{M′
i}.

72
THERMAL PHYSICS
¯Gi = ¯Ui −T ¯Si + p ¯Vi. Therefore, these partial molar quantities obey the same algebra as
their deﬁnitions. Since the natural variables for G are T, p, {Ni}, we observe that ¯Gi ≡μi,
which is just a special symbol for this very important partial molar quantity. By the same
reasoning as for Y , the corresponding Euler equations in terms of partial molar quantities
are H = 
i ¯HiNi, F = 
i ¯FiNi, and G = 
i ¯GiNi = 
i μiNi. Given the algebra of the
partial molar quantities just mentioned, the ﬁrst two of these are in agreement with the
Euler equations H = TS + 
i μiNi and F = −pV + 
i μiNi.
For our further development, we take the volume V(T, p, N1, N2, . . . , Nκ) as a spe-
ciﬁc example, but the procedure is quite general and applies to any extensive function
Y (T, p, N1, N2, . . . , Nκ). If the partial molar volumes ¯Vi were constants, Eq. (5.101) for
V would have the obvious interpretation that ¯Vi was the volume per mole actually
occupied by species i, in which case the total volume would be a linear function of
the Ni. But Eq. (5.101) for Y
= V is true even when the ¯Vi vary with composition
as well as T and p. From the form of Eq. (5.99), it is clear that the ¯Vi are intensive
variables, so they can only depend on the ratios of the Ni. Thus, they can be expressed
as functions of the independent variable set T, p, X1, X2, . . . , Xκ−1. Written out in full, we
have
V(T, p, N1, N2, . . . , Nκ) =
κ

i=1
¯Vi(T, p, X1, X2, . . . , Xκ−1)Ni.
(5.102)
The differential of V is
dV = Vα dT −V κT dp +
κ

i=1
¯Vi dNi,
(5.103)
but from V = 
i ¯ViNi it can also be written
dV =
κ

i=1
¯Vi dNi +
κ

i=1
Ni d ¯Vi.
(5.104)
Comparison of Eqs. (5.103) and (5.104) shows that
κ

i=1
Ni d ¯Vi = V α dT −V κT dp,
(5.105)
which is an equation of Gibbs-Duhem type. We can divide Eq. (5.101) by N to obtain an
equation for the molar volume
v := V
N =
κ

i=1
¯ViXi.
(5.106)
For a single component material there is only one partial molar volume, ¯V1=(∂V/∂N)T,p
and it depends only on T and p. In that case, Eq. (5.106) takes the form
v = V
N =
 ∂V
∂N

T,p
,
single component.
(5.107)

Chapter 5 • Open Systems
73
In this simple case, the derivative with respect to N becomes just the ratio V/N. Equa-
tion (5.105) becomes dv = vα dT −vκT dp which can be rewritten
d ln v = α dT −κT dp,
single component.
(5.108)
Thus
α =
∂ln v
∂T

p
;
κT = −
 ∂ln v
∂p

T
,
single component.
(5.109)
For a multicomponent material, we see from Eq. (5.106) that Eq. (5.107) must be
replaced by
v = V
N =
 ∂V
∂N

T,p,{Xi}
,
multicomponent.
(5.110)
To obtain Eq. (5.110), we hold the composition constant, in addition to T and p, in
Eq. (5.102) and just allow the total number of moles N to vary, so dNi = Xi dN. On the
other hand, Eq. (5.108) is insufﬁcient and must be replaced by
dv = dV
N −V
N2 dN = vα dT −vκT dp +
κ

i=1
¯Vi dXi
= vα dT −vκT dp +
κ−1

i=1
( ¯Vi −¯Vκ) dXi,
(5.111)
where the second form is written in terms of the differentials of κ + 1 independent
variables. Instead of Eq. (5.109), we now have
α =
∂ln v
∂T

p,{Xi}
;
κT = −
∂ln v
∂p

T,{Xi}
.
(5.112)
5.6.1 Method of Intercepts
The method of intercepts provides a useful graphical representation of partial molar
quantities. We illustrate it for partial molar volumes, but it applies to any partial molar
quantities. We ﬁrst illustrate it for a binary system and then derive the general formulae
for a multicomponent system.
Binary system: For a binary system, there are only two chemical components, so we
choose an independent variable set p, T, X2. Since X1 is not a member of this set, X2 is
allowed to vary freely, so we can take partial derivatives with respect to T, p, or X2 while
holding the other pair constant. For a binary system, Eq. (5.106) becomes
v = ¯V1X1 + ¯V2X2 = ¯V1(1 −X2) + ¯V2X2
(5.113)
and from Eq. (5.111), with dX1 = −dX2, we obtain
 ∂v
∂X2

T,p
= ¯V2 −¯V1.
(5.114)

74
THERMAL PHYSICS
v
¯V1
¯V2
X2
X2
∗
T,p
FIGURE 5–2 Illustration of the method of intercepts to calculate partial molar volumes for a system of two
components. We plot a graph of v versus X2 at ﬁxed p and T. Then the partial molar volumes for some composition
X∗
2 are given by the intercepts of the tangent to v at X∗
2. ¯V1(T, p, X∗
2) is the intercept at X2 = 0 which corresponds to
pure component 1. ¯V2(T, p, X∗
2) is the intercept at X2 = 1 which corresponds to pure component 2.
We solve Eqs. (5.113) and (5.114) simultaneously for ¯V1 and ¯V2 to obtain
¯V1 = v −X2
 ∂v
∂X2

T,p
;
(5.115)
¯V2 = v + (1 −X2)
 ∂v
∂X2

T,p
.
(5.116)
Equations (5.115) and (5.116) are illustrated in Figure 5–2. On a graph of v versus X2 (at
ﬁxed T and p) we see that the partial molar volumes for some composition X∗
2 are given by
the intercepts, at X2 = 0 and X2 = 1, of the tangent to v at X∗
2. This graphic construction
allows one to see immediately how ¯V1 and ¯V2 vary with composition X∗
2.
For example, if V is a linear function of X2, its tangent is coincident with V itself and
¯V1 and ¯V2 are independent of X2. In that case, one can imagine that each component of
the solution has a ﬁxed physical volume. Moreover, if the curve V versus X2 is convex,
instead of concave as in Figure 5–2, a partial molar volume could be negative! In that case,
it makes no sense to think of a partial molar volume as a physical volume; instead, it is
only a manifestation of the slope of the V versus X2 curve, even though Eq. (5.113) still
holds.
Multicomponent system: For multicomponent systems, we use the second form of
Eq. (5.111) which depends on the set of independent variables p, T, X1, X2, . . . , Xκ−1.
Within this reduced variable set, we can take the partial derivative with respect to Xi to
obtain
 ∂v
∂Xi

T,p,{X′
i}
= ( ¯Vi −¯Vκ);
i = 1, 2, . . . , κ −1.
(5.117)

Chapter 5 • Open Systems
75
We multiply Eq. (5.117) by Xi and sum to get
κ−1

i=1
Xi
 ∂v
∂Xi

T,p,{X′
i}
=
κ−1

i=1
Xi ¯Vi −¯Vκ
κ−1

i=1
Xi
(5.118)
=
κ−1

i=1
Xi ¯Vi + Xκ ¯Vκ −¯Vκ.
Then by using Eq. (5.106), Eq. (5.118) becomes
¯Vκ = v −
κ−1

i=1
Xi
 ∂v
∂Xi

T,p,{X′
i}
.
(5.119)
Equation (5.119) can be interpreted geometrically by imagining v to be plotted as a
hypersurface in the coordinates X1, X2, . . . , Xκ−1. The quantity on its right-hand side is
then seen to be the intercept on the v axis, at the origin of the Xi, of a hyperplane that
is tangent to v at composition X1, X2, . . . , Xκ−1. Unlike the case of two components, this is
not particularly easy to visualize.
Example Problem 5.6. A solution of A and B atoms at constant temperature and pressure has
a molar volume v = 3 + 2XB −X2
B cm3/mol, where XB is the mole fraction of B atoms.
(a) Use the method of intercepts to calculate the partial molar volumes ¯VA and ¯VB.
(b) Show explicitly from your results that v = XA ¯VA + XB ¯VB, where XA = 1 −XB is the mole
fraction of A atoms. Why is such a relation true?
(c) Show explicitly from your results that 0 = XA(d ¯VA/dXB) + XB(d ¯VB/dXB). Why is such a
relation true?
Solution 5.6.
(a) We calculate ¯VA = v(XB) −XBdv/dXB = X3
B −3 and ¯VB = v(XB) + (1 −XB)dv/dXB =
X2
B −2XB + 5.
(b) We can easily check that v = XA ¯VA + XB ¯VB, where XA = 1 −XB. This is just a special case of
Eq. (5.106).
(c)
We readily compute ∂¯VA/∂XB = 2XB and ∂¯VB/∂XB = 2XB −2 = −2XA so XA∂¯VA/∂XB +
XB∂¯VB/∂XB = 0. This result follows from Eq. (5.105) for constant T and p after division by N.
5.7 Entropy of Chemical Reaction
Before leaving this chapter, we show how the formalism developed for open systems
can be used to treat chemically closed systems in which the mole numbers can vary
by means of chemical reactions. Then we proceed to calculate the entropy due to a
chemical reaction. See Chapter 12 for a more complete treatment of chemical reactions
that includes heats of reaction and detailed conditions for equilibrium.

76
THERMAL PHYSICS
We begin with Eq. (5.10) and write
dNi = dintNi + dextNi,
(5.120)
where dextNi denotes changes in Ni due to exchanges of chemical species with the external
environment and dintNi denotes changes due to chemical reactions internal to the system.
For simplicity, we treat only one chemical reaction, which we write in the symbolic form

i
νiAi = 0,
(5.121)
where Ai is the symbol (such as C, CO, CO2, H, H2, etc.) of the chemical species i and νi
is its stoichiometric coefﬁcient in the reaction. We regard νi to be negative for reactants
and positive for products. For example, reaction of carbon and oxygen to form carbon
monoxide, namely
C + (1/2)O2 →CO
(5.122)
could be written in the form of Eq. (5.121) with A1 = C, A2 = O2, A3 = CO and ν1 = −1,
ν2 = −1/2, ν3 = 1. We can therefore write
dintNi = νi d ˜N,
(5.123)
where ˜N is a progress variable that represents the extent to which the reaction has taken
place. Equation (5.10) therefore becomes
dU = T dS −p dV +
κ

i=1
μiνi d ˜N +
κ

i=1
μi dextNi.
(5.124)
A special case of Eq. (5.124) is a chemically closed system for which dextNi = 0, in which
case it becomes
dU = T dS −p dV +
κ

i=1
μiνi d ˜N.
(5.125)
Equation (5.125) replaces Eq. (3.47) when there is a chemical reaction. Combining
Eq. (5.125) with the ﬁrst law dU = δQ −δW and eliminating dU, we obtain
δQ
T + p dV −δW
T
−
κ

i=1
μiνi
T
d ˜N = dS.
(5.126)
Subtracting δQ/Ts from both sides of Eq. (5.126) and applying the second law in the form
of Eq. (3.4), we obtain
δQ
 1
T −1
Ts

+ p dV −δW
T
−
κ

i=1
μiνi
T
d ˜N = dS −δQ
Ts
≥0,
(5.127)
where the inequality holds for natural irreversible processes and the equal sign holds for
an idealized reversible process. Comparison with Eq. (3.52) reveals an additional term that
can represent irreversible entropy production due to chemical reaction.

Chapter 5 • Open Systems
77
If only quasistatic work is done so that δW = p dV, and T = Ts so there is no entropy
production due to irreversible heat transfer, Eq. (5.127) becomes
dS = δQ
T −
κ

i=1
μiνi
T
d ˜N ≥0.
(5.128)
For a reversible process, the equal sign holds in Eq. (5.128) and Eq. (3.6) also holds, so
dS = δQ/T, which would require the second term on the right-hand side of Eq. (5.128)
to vanish. For d ˜N ̸= 0, this would require κ
i μiνi = 0, which turns out to be the
condition that the reaction is in equilibrium. For an irreversible process, the inequality
sign in Eq. (5.128) holds, so
dS −δQ
T = −
κ

i=1
μiνi
T
d ˜N > 0,
(5.129)
which results in entropy production due to an irreversible chemical reaction. In that case,
Eq. (3.6) would no longer hold. Such a reaction will continue until equilibrium is reached
or until at least one of the reactants in the system is used up, which will occur when
d ˜N = 0.
In their book Modern Thermodynamics, Kondepudi and Prigogine [16] break the
entropy change dS into external and internal parts by writing15 dS = dextS + dintS, where
dextS = δQ/T and dintS ≥0. The inequality applies to a natural irreversible process and
the equality applies to an idealized reversible process. This leads to
dintS = −
κ

i=1
μiνi
T
d ˜N ≥0.
(5.130)
This interpretation is consistent with our more general Eqs. (5.127) and (5.128) in the
special case of Ts = T (no irreversible heat ﬂow) and no irreversible work.
For a cyclic process,
0 =

dS =

dextS +

dintS,
(5.131)
which requires
−

dextS = −
 δQ
T =

dintS ≥0.
(5.132)
Equation (5.132) is in agreement with Eq. (3.15) for a cyclic process during which T = Tr.
When Eq. (5.130) holds, we also have

dintS = −

κ

i=1
μiνi
T
d ˜N ≥0.
(5.133)
15As shown below, dextS and dintS are not exact differentials because their integrals around a closed path are
not necessarily equal to zero.

78
THERMAL PHYSICS
Since S depends on U, V, and ˜N for this system, these quantities must return to their
original values for a cyclic process. This means that any chemical reaction that takes place
during part of a cycle must be reversed during another part of the cycle. If the inequality
holds in Eq. (5.133), the chemical reaction is irreversible and entropy is produced; this
requires heat to be exchanged with the system in such a way that Eq. (5.132) holds, so an
equal amount of entropy is extracted from the system.

6
Equilibrium and Thermodynamic
Potentials
In Chapter 3 we introduced the criterion for thermodynamic equilibrium for an isolated
system in terms of the entropy. We now develop alternative criteria for equilibrium in
terms of the internal energy and other thermodynamic potentials, the latter being related
to the internal energy by Legendre transformations. Each of these potentials depends on
a speciﬁc set of natural variables. The various resulting equilibrium criteria are useful
for a situation in which a particular variable set is subject to control in an experiment.
For example, many experiments on gases are conducted in a ﬁxed volume V at constant
temperature T. In this case, heat must be exchanged with the environment to keep the
temperature constant. Experiments on liquids or solids are often conducted at ﬁxed T
and ﬁxed pressure p, in which case both heat and work must be exchanged with the
environment to insure that these quantities remain constant. Therefore, our alternative
equilibrium criteria will generally pertain to systems that are not isolated.
6.1 Entropy Criterion
We ﬁrst review the criterion for equilibrium in terms of the entropy, S. This criterion is
based on the second law for an isolated system, according to which
S ≥0,
isolated system, allowed changes.
(6.1)
For an isolated system, we have chemical closure, δQ = 0 and δW = 0, so dU = 0. The
inequality in Eq. (6.1) pertains to a natural irreversible process and the equality corre-
sponds to a hypothetical idealized process that is reversible. Thus for natural irreversible
processes, we have
S > 0,
isolated system, natural irreversible changes.
(6.2)
Equilibrium pertains to a situation in which all natural irreversible processes are
forbidden.
Suppose that a composite system, which consists of a number of parts, is initially
in equilibrium by virtue of some internal constraints, such as rigid, insulating, and
impenetrable walls that separate its parts. When some of these constraints are removed,
transformations to which Eq. (6.2) applies can occur, and the entropy can continue to
increase as much as allowed by any remaining constraints until S achieves a maximum
value. When this maximum value is reached, the system will no longer be able to undergo
irreversible changes, and it will be in a new equilibrium state. We need not worry about
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00006-5
79
Copyright © 2015 Elsevier Inc. All rights reserved.

80
THERMAL PHYSICS
S
U
U1, S1
U2, S2
U∗,S∗
FIGURE 6–1 Curve of entropy S versus internal energy U for a system in internal equilibrium. The state U∗, S∗is an
equilibrium state of the same system but with constraints on some internal extensive variables. U∗= U2 and S∗< S2
since, according to the entropy criterion, the equilibrium state of the unconstrained system is higher. But this implies
the existence of an equilibrium state U1, S1 with the same entropy S1 = S∗as the constrained state but lower internal
energy, U1 < U∗, in agreement with the energy criterion.
the equality in Eq. (6.1) which corresponds to idealized reversible changes, because there
are no driving forces for such changes to occur. This approach to equilibrium can be
understood with reference to Figure 6–1 in which the curved line represents entropy S
as a function of internal energy U for the equilibrium state of the system, with other
extensive variables ﬁxed. We recall that S is a monotonically increasing function of U,
in agreement with the way that the curve is drawn. We focus on the equilibrium state
U2, S2. The state U∗, S∗is also an equilibrium state for the same system except that
some of its internal extensive variables are constrained to have different values from
those of the state U2, S2. It has the same energy U∗= U2 but a lower entropy S∗< S2
as compared to the equilibrium state. As constraints are removed, natural irreversible
processes occur, the internal extensive variables change, and the entropy increases toward
S2. After all internal constraints are removed, except for those present for the state U2, S2,
the entropy rises to its ﬁnal value S2 and the internal extensive variables reach their ﬁnal
values.
The foregoing considerations suggest the following test to ﬁnd the equilibrium state.
We select a state having ﬁxed energy and other constraints on its extensive variables
that are necessary for an isolated system. The selected state corresponds to some ﬁxed
values of the internal extensive variables of the system. We then imagine the internal
extensive variables of the selected state to vary, resulting in a varied state. If any varied
state has higher entropy than the original selected state, the selected state is not the correct
equilibrium state. But if all such varied states have lower entropy, the selected state has the
maximum possible entropy and is the equilibrium state. When a varied state has lower
entropy than the selected state, that varied state cannot be reached from the selected

Chapter 6 • Equilibrium and Thermodynamic Potentials
81
state by means of a natural irreversible process. We can therefore think of the variations
that lower the entropy as virtual variations, since they are allowed by the constraints but
forbidden by the second law of thermodynamics.
This approach leads to the following criterion, already stated in Section 3.1:
Entropy criterion: The criterion for an isolated thermodynamic system to be in internal
equilibrium is that its total entropy be a maximum with respect to variation of its internal
extensive parameters, subject to external constraints and any remaining internal con-
straints. Isolation constitutes the external constraints of chemical closure, perfect thermal
insulation and zero external work, which require the internal energy to be constant. In this
chapter, we will discuss the application of this criterion and deduce from it other useful
and equivalent criteria for equilibrium.
For a system sufﬁciently simple that constant total volume V guarantees that there is
no external work, and in which there are no chemical reactions such that constant values
of {Ni} guarantee that the system is chemically closed, the entropy criterion can be based
on the relation
(S)U,V,{Ni} ≥0,
isolated system, allowed changes.
(6.3)
Such a thermodynamic system will be in internal equilibrium if its entropy is a maximum
subject to the constraints of constant internal energy, constant volume, and constant mole
numbers.
6.1.1 Conditions for Equilibrium, Multicomponent Subsystems
We can apply the entropy criterion for equilibrium to a composite system consisting of two
subsystems, I and II, having respective entropies SI(UI, V I, {NI
i }), and SII(UII, V II, {NII
i })
with differentials1
dSI = (1/TI) dUI + (pI/TI) dV I −
κ

i=1
(μI
i/TI) dNI
i ;
(6.4)
dSII = (1/TII) dUII + (pII/TII) dV II −
κ

i=1
(μII
i /TII) dNII
i .
(6.5)
Equation (6.3) applies to ﬁnite entropy changes that we designate by S. Of course it also
applies to inﬁnitesimal changes2 that we designate by dS. For such an inﬁnitesimal change
of the total entropy S = SI + SII, allowed changes must obey
0 ≤dS = dSI + dSII, constraints U, V , {Ni} held constant.
(6.6)
1These apply to bulk systems in the absence of chemical reactions.
2Examination of inﬁnitesimal entropy changes will lead to an extremum of the entropy, but not necessarily
a maximum. We must examine ﬁnite entropy changes, sometimes possible by examining higher derivatives, to
guarantee that we have a maximum of entropy and hence that the equilibrium is stable. This leads to stability
conditions we shall examine in Chapter 7.

82
THERMAL PHYSICS
These constraints require
dUI = −dUII;
dV I = −dV II;
dNI
i = −dNII
i ,
for i = 1, 2, . . . , κ.
(6.7)
Thus Eq. (6.6) becomes
0 ≤(1/TI −1/TII) dUI + (pI/TI −pII/TII) dV I −
κ

i=1
(μI
i/TI −μII
i /TII) dNI
i .
(6.8)
The key to extracting detailed conditions for equilibrium from Eq. (6.8) is to recognize
that it must be true for arbitrary and independent changes dUI, dV I and dNI
i of either
sign3 including zero. We can therefore get information about equilibrium by considering
a number of special variations such as
dUI = arbitrary ±;
dV I = 0;
dNI
i = 0 for i = 1, 2, . . . , κ,
(6.9)
which leads to
0 ≤(1/TI −1/TII) dUI,
allowed changes.
(6.10)
In view of Eq. (6.10), the only way to achieve equilibrium is to prevent an actual irreversible
process (which obeys the inequality) in which a change dUI of either sign can occur, and
this requires
TI = TII.
(6.11)
If TI > TII, then a natural irreversible process dUI < 0 can occur; whereas for TI < TII,
a natural irreversible process dUI > 0 can occur. These processes are consistent with the
notion that there will be spontaneous heat transfer from hot to cold, and their prevention
leads to the equilibrium condition of equal temperatures.
We now use Eq. (6.11) to recast Eq. (6.8) in the form
0 ≤(1/TI)(pI −pII) dV I −(1/TI)
κ

i=1
(μI
i −μII
i ) dNI
i .
(6.12)
We then apply the special variation
dV I = arbitrary ±;
dNI
i = 0 for i = 1, 2, . . . , κ,
(6.13)
to Eq. (6.12) to obtain
0 ≤(1/TI)(pI −pII) dV I,
(6.14)
from which we deduce the equilibrium condition
pI = pII.
(6.15)
3One can consider more general constraints that allow one-way changes only, for example dV I ≥0. These
lead to equilibrium conditions that are inequalities, for example, pII ≥pI instead of pII = pI which would result if
dV I could have either sign. Similarly, one-way constraints on the dNI
i correspond to semipermeable membranes.

Chapter 6 • Equilibrium and Thermodynamic Potentials
83
If pI > pII, an irreversible process in which dV I > 0 can occur, and if pI < pII, an
irreversible process in which dV I < 0 can occur, in agreement with the notion that the
volume corresponding to the system having higher pressure will expand.
Proceeding in this manner, we consider a variation in which only dNI
j ̸= 0, which
leads to
0 ≤−(1/TI)(μI
j −μII
j ) dNI
j ,
(6.16)
from which we deduce the equilibrium conditions
μI
j = μII
j for each j = 1, 2, . . . , κ.
(6.17)
If μI
j > μII
j , a natural irreversible process in which dNI
j < 0 can occur, and if μI
j < μII
j , a
natural irreversible process in which dNI
j > 0 can occur, in agreement with the notion that
there will be diffusion from high chemical potential to low chemical potential for the jth
chemical component.
This leads to the following conditions for equilibrium:
Conditions for equilibrium: The conditions for thermodynamic equilibrium for two
systems capable of freely exchanging energy, volume, and chemical components with
one another are: equality of temperature, equality of pressure, and equality of chemical
potential of each chemical component. For a system of κ components, these condi-
tions are expressed by κ + 2 equations, namely Eqs. (6.11), (6.15), and (6.17). Note
that these conditions imply uniformity of temperature, pressure, and chemical potential
of each chemical component within any system. This follows because any two por-
tions of a system can be regarded as subsystems that must be in equilibrium with one
another.
6.1.2 Phase Rule
If there are more than two subsystems in a given system, we can consider their equilibria
in pairs and eventually arrive at the same conclusions for all of them. If each subsystem
having κ chemical components corresponds to a different phase (e.g., solid with crystal
structure α, solid with crystal structure β, liquid, vapor) we can count the number of
independent intensive variables, subtract from it the number of equations needed to
specify equilibrium, and get the number of free variables (if any) that remain. Requiring
the number of free variables f to be positive or zero puts a limitation on the number of
phases, n, that can exist in equilibrium. The result is the Gibbs phase rule which can be
derived as follows:
number of independent intensive variables = n(κ + 1),
number of equilibrium equations = (n −1)(κ + 2),
number of free variables = f = n(κ + 1) −(n −1)(κ + 2) = κ + 2 −n.
(6.18)

84
THERMAL PHYSICS
Thus, for a monocomponent system, κ = 1 and the only possibilities are n = 1, 2, and 3.
n = 1 corresponds to a single phase region for which the number of free variables is f = 2,
so the pressure p and temperature T can be chosen independently. n = 2 corresponds to
a coexistence curve (say between solid and liquid) and on such a curve, f = 1 so p is a
function of T. n = 3 corresponds to a triple point where, for example, solid, liquid, and
vapor are at equilibrium; since f = 0, both p and T are ﬁxed. See Chapter 8 and especially
Figure 8–1 for more detail. There could be more than one triple point, for example,
one where two solid phases having different crystal structures and a liquid phase are at
equilibrium.
For a binary system, κ = 2 and the only possibilities are n = 1, 2, 3, and 4 corresponding
to f = 3, 2, 1, and 0, respectively. The possibilities become more numerous as κ increases.
6.2 Energy Criterion
From the entropy criterion for equilibrium, one can derive an equilibrium criterion in
terms of the internal energy with the entropy held constant. Such a criterion is suggested
by Figure 6–1 by consideration of the state U1, S1 which is also an equilibrium state of
the system. This state has the same entropy S1 = S∗as the internally constrained state
U∗, S∗but a lower energy, U1 < U∗. According to the entropy criterion, all constrained
states having the same entropy S∗lie below the equilibrium curve. Therefore, as internal
constraints are removed at constant entropy S∗, the system can lower its energy to U1 but
no lower, and we see that the equilibrium state U1, S1 has the minimum possible energy at
ﬁxed entropy. The state U1, S1 is a different equilibrium state from U2, S2 which was found
by applying the entropy criterion beginning with the state U∗, S∗, but this is only because
U∗= U2. Had we begun with a state U∗∗, S∗∗with S∗∗= S2 and U∗∗> U2, then as internal
constraints are removed at constant entropy S2, the system can lower its energy to U2 but
no lower. The equilibrium state U2, S2 found in this manner is the same as that found by
applying the entropy criterion starting from U∗, S∗.
This leads to the following criterion for equilibrium:
Energy criterion: The criterion for a chemically closed thermodynamic system to be in
internal equilibrium is that its total internal energy be a minimum with respect to variation
of its internal extensive parameters, subject to any remaining internal constraints and the
constraint of constant total entropy and no external work.
Paradox: The entropy criterion applies to an isolated system, for which the internal energy
cannot change. The equilibrium state U1, S1 can therefore be found by applying the
entropy criterion at ﬁxed energy U1, so it is an equilibrium state for an isolated system.
On the other hand, application of the energy criterion to ﬁnd the state U1, S1 requires
the energy to change, which is impossible for an isolated system! So how do we apply
the energy criterion? We have no choice but to deal with a system that is not isolated. In
principle, we must put our system in contact with a hypothetical external system that has

Chapter 6 • Equilibrium and Thermodynamic Potentials
85
the unusual capability of exchanging heat in such a way as to maintain a constant entropy
of our system. Physically, it is difﬁcult if not impossible to imagine such a system, but
mathematically the result of applying the energy criterion gives the desired result.
To see this in more detail, we develop a general inequality that applies to a chemically
closed system that can exchange both heat and work at constant entropy. If S is constant
during a process, then dS = 0 at every inﬁnitesimal stage of the process. We can then
combine the differential forms of the ﬁrst and second laws, Eqs. (2.2) and (3.4), to
obtain
δW + dU = δQ ≤Ts dS = 0,
constant S,
(6.19)
where Ts is the temperature of an external heat source. Equation (6.19) can be integrated
over the path of the process to obtain
W + U = Q ≤0,
(6.20)
from which it follows that
W ≤−U,
constant S.
(6.21)
The maximum amount of work that can be done in such a process is equal to the decrease
in internal energy and occurs for the reversible process for which the equality holds
in Eqs. (6.19) and (6.21). In that case, δQ = 0 and Q = 0, so no heat is exchanged with
the system and W = −U. This would be true for a purely mechanical system. For an
irreversible isentropic process, Eq. (6.21) shows that the actual amount of work done is
W < −U; in such a case, Q < 0 so heat was extracted from the system to keep its entropy
constant. If W = 0 in Eq. (6.21), we have
U ≤0,
W = 0 and constant S,
(6.22)
and equilibrium corresponds to a minimum of U, compatible with constraints.
We pause here to emphasize a subtle point. Constant S certainly guarantees S = 0 but
S = 0 does not guarantee constant S, because S can still vary throughout the process. If
we only know that S = 0 for a process, it is possible to have δQ > 0 for some parts of the
process which can lead to Q > 0 and violation of Eq. (6.20). This fact is easy to illustrate
for a process in which the system exchanges heat with only two reservoirs. In that case, we
must only satisfy Eq. (3.11) for S = 0, which results in
Q1
T1
+ Q2
T2
≤0.
(6.23)
If Q1 ≤0 and Q2 ≤0, then Q ≤0 and Eq. (6.20) is not violated. But suppose T2 > T1,
Q2 = |Q2| > 0, and Q1 = −|Q1| < 0. If then we choose |Q2| = (T1 + T2)/(2T1)|Q1|, a little
algebra shows that
Q1
T1
+ Q2
T2
= T1 −T2
2T1T2
|Q1| < 0;
Q = Q1 + Q2 = T2 −T1
2T1
|Q1| > 0.
(6.24)
Thus Eq. (6.23) will be satisﬁed but Eq. (6.20) will be violated.

86
THERMAL PHYSICS
In the next two sections, we proceed to give further motivation and ﬁnally an indirect
proof, due to Gibbs, that the energy criterion and the entropy criterion are equivalent.
6.2.1 Local Energy Criterion
We ﬁrst follow closely a calculation by Callen [2, p. 134] to show that a local maximum of
the entropy S at constant internal energy U implies a local minimum of U at constant S. To
simplify the notation, we consider S to depend on U and some internal extensive variable
 and suppress all of the other extensive variables on which S depends. Then if S is a local
maximum at constant U when  = 0, we have
 ∂S
∂

U
= 0;
 = 0
(6.25)
and
 ∂2S
∂2

U
< 0;
 = 0.
(6.26)
Since S is a monotonically increasing function of U at constant  (and constant values
of the suppressed parameters as well), it has a unique inverse function U(S, ). Such a
functional relationship among three variables implies that
∂U
∂

S
∂
∂S

U
 ∂S
∂U


= −1,
(6.27)
which can be rewritten
∂U
∂

S
= −
 ∂S
∂

U
/
 ∂S
∂U


=: P(, U).
(6.28)
The fact that S is a monotonically increasing function of U requires (∂S/∂U) > 0, so
evaluation of Eq. (6.28) at  = 0 shows that
∂U
∂

S
= 0;
 = 0.
(6.29)
We proceed to examine the second derivative of U, namely
∂2U
∂2

S
=
 ∂P
∂

U
+
 ∂P
∂U


∂U
∂

S
.
(6.30)
By using Eq. (6.29), we see that the second term in Eq. (6.30) vanishes at  = 0. The ﬁrst
term on the right-hand side can be written
 ∂P
∂

U
= −
 ∂2S
∂2

U
/
 ∂S
∂U


+
 ∂S
∂

U
∂2S
∂U∂/
 ∂S
∂U
2

.
(6.31)
By using Eq. (6.25), we see that the second term in Eq. (6.31) also vanishes at  = 0,
resulting in
∂2U
∂2

S
= −
 ∂2S
∂2

U
/
 ∂S
∂U


;
 = 0.
(6.32)

Chapter 6 • Equilibrium and Thermodynamic Potentials
87
Since (∂S/∂U) > 0 as discussed above, the use of Eq. (6.26) in Eq. (6.32) shows that
∂2U
∂2

S
> 0;
 = 0.
(6.33)
From Eqs. (6.29) and (6.33), we conclude that U has a local minimum at  = 0.
This local analysis suggests that the energy criterion is true. A general proof requires
one to prove that a global maximum of S at constant U corresponds to a global minimum
of U at constant S.
6.2.2 Equivalence of Entropy and Energy Criteria
We shall prove that the entropy criterion and the energy criterion are equivalent. Both
S(U, {	}) and U(S, {	}) (where {	} stands for all other extensive variables of a complete
set) are fundamental equations; if one is known, the other can be found because S
is a monotonically increasing function of U and vice versa. The procedure to obtain
detailed conditions for equilibrium of systems by minimizing U is analogous to that for
maximizing S, and the resulting conditions (uniformity of temperature, pressure, and
chemical potential of each chemical component) are the same.
This equivalence was recognized and emphasized by Gibbs [3, p. 56] who stated
“That these two theorems [of entropy maximization at constant energy and energy
minimization at constant entropy] are equivalent will appear from the consideration
that it is always possible to increase both the energy and entropy of the system, or to
decrease both together, viz., by imparting heat to any part of the system or by taking it
away.”
A key word in this statement is “both” and this relates to the fact that S is a mono-
tonically increasing function of U and vice versa, as already stated. As had been stated
previously by Gibbs [3, p. 55]:
“For by mechanical and thermodynamic contrivances, supposed theoretically perfect,
any supply of work and heat may be transformed into any other which does not differ
from it either in the amount of work and heat taken together [which is equal to U] or
in the value of the integral

δQ/T.”
Based on these statements of Gibbs, one can prove the equivalence of the entropy
criterion and the energy criterion as follows:
•
First, suppose that for the equilibrium state, the entropy criterion is true but that the
energy criterion is not true, that is, the entropy is a maximum at constant energy but the
internal energy is not a minimum at constant entropy. Then there exists a state of the
system with lower energy and the same entropy. We can therefore use a combination of
heat and work to raise both the internal energy and the entropy of this state, and thus

88
THERMAL PHYSICS
achieve a state having the original internal energy but higher entropy. This contradicts
the fact that the entropy is a maximum at constant internal energy.
•
Second, suppose that for the equilibrium state, the energy criterion is true but that
the entropy criterion is not true, that is, the internal energy is a minimum at constant
entropy but the entropy is not a maximum at constant internal energy. Then there exists
a state of the system with higher entropy and the same internal energy. We can therefore
use a combination of heat and work to lower both the internal energy and the entropy of
this state, and thus achieve a state having the original entropy but lower internal energy.
This contradicts the fact that the internal energy is a minimum at constant entropy.
6.3 Other Equilibrium Criteria
We have shown that the entropy criterion and the internal energy criterion are equivalent.
By means of Legendre transformations, one can use other so-called “thermodynamic
potentials” (such as Helmholtz free energy, Gibbs free energy, enthalpy) for which an
equilibrium criterion of minimization exists, but with other variables (some intensive)
held constant. This is taken up in the following sections.
6.3.1 Helmholtz Free Energy Criterion
If a chemically closed thermodynamic system is in contact with a heat reservoir having
constant temperature Tr, then Eq. (3.10) becomes Qr ≤TrS. Combining this with the
ﬁrst law, we obtain
U + W = Qr ≤TrS,
(6.34)
which may be rewritten
W ≤−(U −TrS).
(6.35)
Equation (6.35) is a formula for the maximum work that a system in contact with a heat
reservoir at constant Tr can do. We deﬁne the Helmholtz free energy4 by the Legendre
transformation
F := U −TS.
(6.36)
If T = Tr in the initial and ﬁnal states of a process,5 Eq. (6.35) can be written
W ≤−F;
T = Tr in initial and ﬁnal states.
(6.37)
4Many books denote the Helmholtz free energy by the symbol A and use F for the Gibbs free energy. We
denote the Gibbs free energy by G := U −TS + pV = H + pV.
5Note that Eqs. (6.37) and (6.38) hold even if the temperature of the system is undeﬁned during the process.
Of course they also hold if T = Tr throughout the process, which is the case treated in most books. Fermi
[1, p. 78] gives a careful discussion of this more general treatment, which is also mentioned by Landau and Lifshitz
[7, p. 59].

Chapter 6 • Equilibrium and Thermodynamic Potentials
89
Hence the name “free” energy because the decrease in F is the energy that is free to do
work for a system that exchanges heat with a heat reservoir at constant temperature Tr. If
W = 0, Eq. (6.37) becomes
F ≤0;
W = 0 and T = Tr in initial and ﬁnal states.
(6.38)
For a chemically closed system that does no external work and is held at constant
temperature T = Tr in its initial and ﬁnal states, the Helmholtz free energy can only
decrease, and equilibrium is achieved when F reaches its minimum, compatible with
constraints. This leads to the following equilibrium criterion:
Helmholtz free energy criterion: The criterion for a chemically closed thermodynamic
system held at constant temperature T = Tr in its initial and ﬁnal states and which does no
external work to be in internal equilibrium is that its Helmholtz free energy be a minimum
with respect to variations of its internal extensive parameters.
If there are no chemical reactions such that constant values of {Ni} guarantee that the
system is chemically closed, the system is sufﬁciently simple that constant total volume V
guarantees that there is no external work, and the system temperature T is held constant
by an external source, Eq. (6.38) reduces to
(F)T,V,{Ni} ≤0,
allowed changes.
(6.39)
Such a thermodynamic system will be in internal equilibrium if its Helmholtz free energy
is a minimum subject to the constraints of constant temperature, constant volume, and
constant mole numbers.
6.3.2 Gibbs Free Energy Criterion
If a chemically closed thermodynamic system is in contact with a heat reservoir having
constant temperature Tr and a pressure reservoir having pressure pr and against which it
does work pr V, then Eq. (6.34) becomes
U + Wxs + pr V = Qr ≤TrS,
(6.40)
where Wxs is any excess external work that the system can do in addition to that done on
the reservoir.6 Equation (6.40) can be rewritten
Wxs ≤−[U −Tr S + pr V ].
(6.41)
We deﬁne the Gibbs free energy7 by the Legendre transformation
G := U −TS + pV = H −TS,
(6.42)
6In order to have Wxs ̸= 0, the system must be sufﬁciently complex to do work by means other than just
expanding against an external pressure.
7Note that G has the same relationship to H as F does to U. Consequently, G is sometimes called the free
enthalpy, rather than the Gibbs free energy.

90
THERMAL PHYSICS
where T and p are temperature and pressure of the system. If T = Tr and p = pr in the
initial and ﬁnal states of a process,8 then Eq. (6.41) can be written
Wxs ≤−G,
T = Tr and p = pr in initial and ﬁnal states.
(6.43)
Equation (6.43) gives the maximum excess work (useful work) that a system in contact
with a pressure reservoir can do at constant temperature. If Wxs = 0, Eq. (6.43) becomes
G ≤0,
Wxs = 0, T = Tr and p = pr in initial and ﬁnal states.
(6.44)
For a chemically closed system held in its initial and ﬁnal states at constant temperature
T = Tr and constant pressure p = pr that does external work only on a pressure reservoir
at pressure pr, the Gibbs free energy can only decrease, and equilibrium is achieved
whenever G reaches its minimum, compatible with constraints. This leads to the following
equilibrium criterion:
Gibbs free energy criterion: The criterion for a chemically closed thermodynamic system
held in its initial and ﬁnal states at constant temperature T = Tr and constant pressure
p = pr which only does external work pr V to be in internal equilibrium is that its Gibbs
free energy be a minimum with respect to variations of its internal extensive parameters. If
there are no chemical reactions such that constant values of {Ni} guarantee that the system
is chemically closed, Eq. (6.44) becomes
(G)T,p,{Ni} ≤0,
allowed changes.
(6.45)
Such a thermodynamic system will be in internal equilibrium if its Gibbs free energy is
a minimum subject to the constraints of constant temperature, constant pressure, and
constant mole numbers.
6.3.3 Enthalpy Criterion
If we apply Eq. (6.21) to a chemically closed system in contact with a pressure reservoir at
pressure pr and against which it does work prV, we obtain
Wxs + prV ≤−U,
constant S,
(6.46)
where Wxs is any excess external work that the system can do in addition to that done on
the reservoir. Equation (6.46) can be rewritten
Wxs ≤= −(U + prV ),
constant S.
(6.47)
The enthalpy is deﬁned by the Legendre transformation
H := U + pV,
(6.48)
8Note that Eqs. (6.43) and (6.44) hold even if the temperature and pressure of the system are undeﬁned during
the process. Of course they also hold if T = Tr and p = pr throughout the process, which is the case treated in
most books.

Chapter 6 • Equilibrium and Thermodynamic Potentials
91
where p is the pressure of the system. If p = pr in the initial and ﬁnal state of the system,
Eq. (6.47) becomes
Wxs ≤−H,
constant S and p = pr in initial and ﬁnal states.
(6.49)
Thus the maximum excess work that can be done under these conditions is given by the
decrease in the enthalpy. If Wxs = 0, we obtain
H ≤0,
Wxs = 0, constant S and p = pr in initial and ﬁnal states.
(6.50)
Under these conditions, the enthalpy can only decrease, and equilibrium is achieved when
H reaches its minimum, compatible with constraints. We are therefore led to the following
equilibrium criterion:
Enthalpy criterion: The criterion for a chemically closed thermodynamic system held at
constant pressure p = pr in its initial and ﬁnal states which only does external work pr V
to be in internal equilibrium is that its enthalpy be a minimum with respect to variations
of its internal extensive parameters, subject to the constraint of constant entropy.
If there are no chemical reactions such that constant values of {Ni} guarantee that the
system is chemically closed, Eq. (6.50) becomes
(H)S,p,{Ni} ≤0,
allowed changes.
(6.51)
Such a thermodynamic system will be in internal equilibrium if its enthalpy is a minimum
subject to the constraints of constant entropy, constant pressure, and constant mole
numbers.
6.3.4 Kramers Potential Criterion
A somewhat different criterion for equilibrium can be obtained in terms of the Kramers
potential (also known as the grand potential, and often denoted by 
),
K = F −
κ

i=1
μiNi,
(6.52)
introduced by Eq. (5.91). We consider a set9 of chemical reservoirs, each having ﬁxed
temperature and volume and respective chemical potential μri for chemical component i.
We apply Eq. (6.38) to a composite system having total Helmholtz free energy Ftot and
consisting of the system of interest and all of the reservoirs. The total system is chemically
closed and we forbid chemical reactions, so that Ni + Nri = constant, where Nri is the
number of moles of component i in its reservoir. Then
Ftot = F +
κ

i=1
μriNri = F −
κ

i=1
μriNi,
(6.53)
9The reservoirs need not be separate systems. In fact, this criterion is often used where the system of interest
is a surface and the bulk of the system is the reservoir.

92
THERMAL PHYSICS
where for each reservoir, dFri = μri dNri, has been integrated. If μi = μir, at least in the
initial and ﬁnal states, we have Ftot = K, so minimization of Ftot at constant T and
no external work is the same as minimization of K at constant T, no external work and
constant chemical potentials equal to those of the reservoirs. This leads to the following
criterion:
Kramers potential criterion: The criterion for a thermodynamic system to be in equi-
librium at constant temperature and a constant value of each of its chemical poten-
tials is that its Kramers potential be a minimum with respect to variations of its inter-
nal extensive parameters under the constraints of no external work and no chemical
reactions.
If there are no chemical reactions, the system is sufﬁciently simple that constant total
volume guarantees no external work, and if the system temperature T and its chemical
potentials {μi} are held constant by external reservoirs, the equilibrium criterion for
the Kramers potential reduces to a minimization of the Kramers potential at constant
temperature, constant volume, and constant chemical potentials.
6.4 Summary of Criteria
For cases in which V = 0 guarantees W = 0, or for p constant in which the only
external work is p V (so Wxs = 0), and no chemical reactions such that constant values
of {Ni} guarantee that the system is chemically closed, or for constant {μi} imposed by
external chemical reservoirs, the criteria for equilibrium can be summarized by ﬁrst noting
the natural variable set10 on which the various thermodynamic functions depend. For
the entropy and the thermodynamic potentials discussed above, these variable sets are
summarized in Table 6–1.
Then for internal equilibrium, S is a maximum, and each thermodynamic potential is a
minimum, with respect to variations of its internal extensive variables, with all designated
Table 6–1
Natural Variable Sets of Thermodynamic Functions
Function
Variable →
S
U
V
{Ni}
T
p
{µi}
Entropy
S
×
×
×
Internal Energy
U
×
×
×
Helmholtz Free Energy
F
×
×
×
Gibbs Free Energy
G
×
×
×
Enthalpy
H
×
×
×
Kramers (Grand) Potential
K
×
×
×
10This is the variable set that gives complete information about the system, namely extensive variables for U
and S and variables obtained by Legendre transformations in the case of F, G and H. For further discussion of
this point in the context of Legendre transformations, see Callen [2, pp. 137-145].

Chapter 6 • Equilibrium and Thermodynamic Potentials
93
variables held constant for the overall system. We emphasize that these are alternative
criteria for equilibrium, each applicable for different constraints.
6.4.1 Equilibrium Conditions
No matter which of these criteria are applied, the conditions for mutual equilibrium of
subsystems of a composite system will be the same as those derived from the entropy
condition in Section 6.1.1. For a composite system containing more than two subsystems,
the systems may be considered in pairs. These conditions are uniformity, throughout the
entire system, of the temperature T, the pressure p, and each chemical potential μi. For
the potentials, this can be seen by carrying out the same kind of variations as in Section
6.1.1 for only the subset of variables that are unconstrained. For the Gibbs free energy,
for example, T and p are already uniform and assumed to be held constant by external
reservoirs, so only exchanges of the {Nsub
i
} among the subsystems need to be considered.
This leads to uniformity of the μi.
6.4.2 Extension to Chemical Reactions
In event that chemical reactions are allowed, one must revert to an equilibrium criterion
that allows variations of the {Ni} due to those reactions. Thus, to apply the entropy
criterion for a single chemical reaction, one would have to vary the progress variable
˜N that appears in Eq. (5.125). Then according to the discussion of Eq. (5.128), there
would be an additional condition 
i μiνi = 0 that the chemical potentials must satisfy
for that chemical reaction to be in equilibrium. That same condition would apply to
all subsystems because the chemical potentials must be uniform at equilibrium. This
additional condition would lower the number of degrees of freedom in the phase rule,
Eq. (6.18), by one. If there were c independent chemical reactions, the phase rule would
take the modiﬁed form
f = (κ −c) + 2 −n,
(6.54)
where κ−c ≥1 is the number ofindependent chemical components. See Darken and Gurry
[19, p. 287] for a discussion of the phase rule for a variety of conditions, including “frozen
reactions,” in the context of the thermochemistry of metals.

This page intentionally left blank 

7
Requirements for Stability
In Chapter 6 we discussed the criterion for thermodynamic equilibrium of an isolated
system, namely that its entropy, S, be a maximum with respect to variations of its internal
extensive variables. If  is such an internal extensive variable, then dS/d = 0 at equi-
librium. But this condition could correspond to a maximum, a minimum or a horizontal
point of inﬂection in a graph of S versus . We must therefore examine higher derivatives
in order to insure that S is a local maximum, and ﬁnite changes  to ascertain if S is
a global maximum. In this chapter, we examine the requirements for stable equilibrium,
particularly with respect to the stability of homogeneous systems. We pose the question of
whether a homogeneous system is stable with respect to breakup into a composite system
consisting of two (or more) subsystems, each of which is homogeneous. This will lead to
requirements concerning the functional dependence of S on its complete set of extensive
variables.
In Chapter 6 we also discussed equilibrium criteria in terms of minimization of the
internal energy, U, and its Legendre transforms, subject to suitable overall constraints
on the system. Here again, criteria such as dU = 0 can lead to an extremum, but not
necessarily a minimum, and we must examine higher derivatives or ﬁnite changes in order
to ascertain requirements for stability. Similar considerations apply to stability criteria
based on minimization of other thermodynamic potentials such as F, G, and H, but some
of the natural variables on which these potentials depend are intensive, so their behavior
with respect to stability must be ascertained by relating to extensive variables by means of
Legendre transforms.
Examination of these requirements will also result in useful information about the signs
of various physical quantities, such as heat capacities, and compressibilities, as well as
inequalities that restrict the relative magnitudes or ratios of these quantities.
7.1 Stability Requirements for Entropy
For simplicity, we consider a homogeneous system having entropy S(U, V, N) and assume
that constant values of U, V, and N will guarantee isolation. We ﬁrst follow Callen [2,
p. 203] based on an analysis by Grifﬁths [20] and pose the question of whether this
system is stable with respect to breakup into two homogeneous subsystems, each having
a volume V/2 and number of moles N/2, one having energy (U −U)/2 and the other
having energy (U + U)/2. The energy of the combined subsystems is (1/2)(U −U) +
(1/2)(U + U) = U. Since S is a homogeneous function of degree one in these extensive
variables, the corresponding entropies of the subsystems are (1/2)S(U −U, V, N) and
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00007-7
95
Copyright © 2015 Elsevier Inc. All rights reserved.

96
THERMAL PHYSICS
(1/2)S(U + U, V, N). Therefore, the homogeneous system will be stable with respect to
this breakup by an irreversible process if
(1/2)S(U −U, V , N) + (1/2)S(U + U, V , N) ≤S(U, V , N).
(7.1)
This requirement is represented graphically in Figure 7–1. By rewriting the left-hand side
of Eq. (7.1) in the form
S(U −U, V, N) + (1/2)[S(U + U, V , N) −S(U −U, V , N)] ≤S(U, V , N),
(7.2)
we verify that the entropy of the composite system lies on the straight line (chord) joining
(1/2)S(U −U, V, N) and (1/2)S(U + U, V, N) at the value U, midway between U −U
and U + U. Thus, stability for all values of U requires S to be a concave function of U (as
viewed from below). Thus, the situation in Figure 7–1a is stable, and that in Figure 7–1b is
unstable. The equal sign in Eq. (7.2) would correspond to a situation of neutral stability
that would involve a hypothetical reversible process. We will discuss this possibility in
Chapters 9 and 10 in connection with phase transformations.
For inﬁnitesimal changes U →δU, we can expand the entropies in Eq. (7.1) to obtain
S(U ± δU, V, N) = S(U, V, N) ± SU(U, V , N)δU + (1/2)SUU(δU)2 + · · · ,
(7.3)
where the subscripts U represent partial differentiation.1 Then neglecting terms of the
third order and higher, Eq. (7.1) becomes, after division by (δU)2/2,
SUU ≡
 ∂2S
∂U2

V,N
≤0.
(7.4)
S
U
U + ΔU
U − ΔU
(a)
S
U
U + Δ U
U − ΔU
(b)
FIGURE 7–1 Conditions for S(U, V, N), represented by the solid curves, for stability (a) or instability (b). To be stable,
S(U, V, N) must be a concave function of U at ﬁxed V and N. A composite system having the same values of U, V,
and N would have an entropy represented by the intersection of the chord with the vertical line at U. (a) Stable
(concave) and (b) Unstable (convex).
1In this chapter, subscripts that indicate partial derivatives imply the natural variable sets for each function,
explicitly S(U, V, N), U(S, V, N), H(S, p, N), F(T, V, N), and G(T, p, N).

Chapter 7 • Requirements for Stability
97
Equation (7.4) is a requirement for local stability because it corresponds to inﬁnitesimal
changes. If SUU = 0, we could examine higher derivatives. For example, we would need
SUUU = 0 and SUUUU < 0, but such a requirement would still be local.
The situation depicted in Figure 7–2 is more complicated because the second derivative
SUU changes sign at the so-called spinodal points US1 and US2. The region between points
US1 and US2 is clearly unstable with respect to inﬁnitesimal variations δU. The remainder
of the curve is stable with respect to inﬁnitesimal variations. The states between U1 and
US1 and between US2, and U2, where U1 and U2 are points of common tangency, are more
difﬁcult to analyze because the above analysis requires values of U −U and U +U that
are symmetrically situated and can span distant portions of the curve.
We therefore resort to the following modiﬁed analysis. We represent the entropy,
internal energy, and volume per mole by the lower case letters s, u, and v, respectively. The
original system has N moles, entropy S(U, V, N) = Ns(u, v), internal energy Nu, and vol-
ume Nv. We consider breakup onto a composite system consisting of two homogeneous
systems, one having (1 −f )N moles and intensive parameters u1, v, s(u1, v), and the other
having fN moles and intensive parameters u2, v, s(u2, v), where
1 −f = u2 −u
u2 −u1
;
f = u −u1
u2 −u1
.
(7.5)
Without loss of generality we take u2 > u1. The volume of the composite system is
N(1 −f )v + Nf v = Nv = V and its number of moles is N(1 −f ) + Nf = N. It has energy
N(1 −f )u1 + Nfu2 =
N
u2 −u1
[(u2 −u)u1 + (u −u1)u2] = Nu = U.
(7.6)
The entropies of the subsystems are (1−f )Ns(u1, v) and fNs(u2, v). After division by N, the
requirement for stability becomes
(1 −f )s(u1, v) + fs(u2, v) ≤s(u, v),
(7.7)
S
US1
US2
U1
U2
FIGURE 7–2 S(U, V, N) versus U under conditions for which some states are locally stable and others are locally
unstable. The states between the spinodal points US1 and US2 are locally unstable and states outside these points are
locally stable. But states between U1 and US1 and between US2 and U2 are globally unstable, so they are metastable.

98
THERMAL PHYSICS
which can be rewritten
s(u1, v) + u −u1
u2 −u1
[s(u2, v) −s(u1, v)] ≤s(u, v).
(7.8)
The requirement represented by Eq. (7.8) is shown in Figure 7–3, from which we see that
the entropy per mole of the composite system is represented by the intersection of a
vertical line at u with a chord joining any points s(u1, v) and s(u2, v), as long as u2 > u > u1
is satisﬁed. This criterion shows that the general requirement for stability is concavity of
s(u, v) as a function of u at ﬁxed v. Since S(U, V, N) = Ns(u, v) = Ns(U/N, V/N), we see
for stability that S(U, V, N) is a concave function of U at ﬁxed V and N. Thus the states
in Figure 7–2 between U1 and US1 and between US2 and U2, although locally stable, are
globally unstable and are termed metastable. By letting u1 = u −δu, u2 = u + δu and
expanding Eq. (7.8) for small δu, one obtains ∂2s/∂u2 ≤0 as a local stability condition,
consistent with Eq. (7.4).
Returning to the general analysis of S(U, V, N), we can inquire about stability against
breakup into two homogeneous subsystems, each having the same energy U/2 and mole
numbers N/2, but different volumes (V −V)/2 and (V + V)/2. By the same reasoning
as above, stability requires
(1/2)S(U, V −V , N) + (1/2)S(U, V + U, N) ≤S(U, V , N).
(7.9)
For inﬁnitesimal changes δV
SVV ≡
 ∂2S
∂V 2

U,N
≤0.
(7.10)
The same reasoning applies to changes of N or to any other extensive variables on which
S could depend.
s
u
u2
u1
FIGURE 7–3 s(u, v) versus u under conditions for which some states are locally stable and others are locally unstable.
At constant v, we test the state at u against breakup into a composite system consisting of states having molar
energies u1 and u2 that are not equidistant from u. The entropy per mole of the composite system lies on the
straight line at position u and exceeds s(u, v) which lies on the curve. Therefore, the state at u is globally unstable,
even though it is locally stable.

Chapter 7 • Requirements for Stability
99
If both U and V are different for the subsystems, we obtain
(1/2)S(U −U, V −V , N) + (1/2)S(U + U, V + U, N) ≤S(U, V , N).
(7.11)
For inﬁnitesimal changes in U and V, Eq. (7.11) becomes
SUU(δU)2 + 2SUV δUδV + SVV (δV )2 ≤0,
(7.12)
where the derivatives are evaluated at U, V, N. Testing Eq. (7.12) for δV = 0 or δU = 0
recovers SUU ≤0 and SVV ≤0 as above. But for general δV and δU, a new condition
emerges. We can write Eq. (7.12) in the matrix form

δU δV
 
SUU SUV
SUV
SVV
 
δU
δV

≤0,
(7.13)
which involves a real symmetric matrix that can be diagonalized. Its eigenvalues λ satisfy
det
 SUU −λ SUV
SUV
SVV −λ

= 0,
(7.14)
which leads to a quadratic equation with roots
λ± = SUU + SVV
2
±
SUU + SVV
2
2
+ S2
UV −SUUSVV
(7.15)
= SUU + SVV
2
±
SUU −SVV
2
2
+ S2
UV .
From the second form, we see that both roots are real, which is a general property for the
eigenvalues of any real symmetric matrix. From the ﬁrst form, and recalling that SUU ≤0
and SVV ≤0, we see that there are no positive roots provided that
SUUSVV −S2
UV ≥0.
(7.16)
After diagonalization, Eq. (7.13) can be rewritten in the form
λ+(δX1)2 + λ−(δX2)2 ≤0,
(7.17)
where λ± ≤0 and δX1 and δX2 are linear combinations of δU and δV that can be found
by calculating the eigenvectors of the matrix. Thus, SUU ≤0 and SVV ≤0 together with
Eq. (7.16) guarantee that Eq. (7.12) is satisﬁed.2 They insure locally that the surface S will
not lie above its local tangent plane. Callen [2, p. 206] refers to Eq. (7.16) as a “ﬂuting
condition.”
By a procedure similar to that used to derive Eq. (7.8), we can test a system with entropy
Ns(u, v) with respect to breakup into a composite of three systems having entropies
Nf1s(u1, v1), Nf2s(u2, v2), and Nf3s(u3, v3), where f1, f2, and f3 are positive fractions that
sum to unity, chosen such that total energy and total volume are conserved. This leads to
a stability criterion of the form
f1(u, v)s(u1, v1) + f2(u, v)s(u2, v2) + f3(u, v)s(u3, v3) ≤s(u, v),
(7.18)
2For an alternative procedure that would lead to Eq. (7.16), see Section 7.2.

100
THERMAL PHYSICS
where the fi satisfy the following linear equations:
f1 + f2 + f3
= 1,
f1u1 + f2u2 + f3u3 = u,
f1v1 + f2v2 + f3v3 = v.
(7.19)
We could use Cramer’s rule to solve Eq. (7.19) by means of determinants, but the actual
expressions are cumbersome and not needed as long as we note the following properties.
A solution is only possible if the determinant of the coefﬁcients of the fi is not zero, which
will be true if the points (u1, v1), (u2, v2), and (u3, v3) lie at the vertices of a non-degenerate
triangle in the u, v plane. We shall refer to these vertices as 1, 2, and 3, respectively, in which
case that determinantis equal to 2A123, where A123 > 0 is the area of that triangle. As shown
below, the point (u, v) where s(u, v) is to be tested for stability must be chosen within or on
that triangle. With (u1, v1), (u2, v2), and (u3, v3) ﬁxed, the fi will be linear functions of u and
v that can be written in the form fi(u, v), as already indicated in Eq. (7.19); furthermore,
they will satisfy
fi(uj, vj) = δij;
fi(u0, v0) = A0jk/A123,
(7.20)
where δij is the Kronecker delta, i, j, k, are cyclic permutations of 123, and the quantities
A0jk are areas of triangles deﬁned below. The ﬁrst member of Eq. (7.20) follows from
Cramer’s rule because the determinant of a matrix having two identical columns is zero. If
the point (u0, v0) is referred to as point zero, Cramer’s rule can also be used to show that
A0jk is the area of triangle 0jk. Consistent with A123 > 0, the areas A0jk ≥0 are positive as
long as (u0, v0) lies inside or on triangle 123. If (u0, v0) were to lie outside triangle 123, at
least one of the fi will be negative, which is unacceptable. See Figure 8–11 that pertains to
an isomorphous problem.
From these properties of the fi(u, v), it follows that the left-hand side of Eq. (7.18) rep-
resents a plane that passes through the points s(u1, v1), s(u2, v2), and s(u3, v3). Therefore,
geometrically, the global stability criterion represented by Eq. (7.18) states that s(u, v)
lies above or on any such plane. In other words, for stability s(u, v) must be a concave
function of u and v. If s(u, v) violates Eq. (7.18) for any such plane, that state will be globally
unstable, but would be locally stable if Eq. (7.12) were satisﬁed.
7.2 Stability Requirements for Internal Energy
We can establish similar requirements for stability in terms of the internal energy U since
at equilibrium it is a minimum at constant entropy and other extensive variables. For
example, for U(S, V, N) we have the stability requirement
(1/2)U(S −S, V, N) + (1/2)U(S + S, V , N) ≥U(S, V , N),
(7.21)
which for inﬁnitesimal changes in S gives the local condition
∂2U
∂S2

V,N
≥0.
(7.22)

Chapter 7 • Requirements for Stability
101
U
S
S + ΔS
S − ΔS
(a)
U
S
S + ΔS
S − ΔS
(b)
FIGURE 7–4 Conditions for U(S, V, N), represented by the solid curves, for stability (a) or instability (b). To be stable,
U(S, V, N) must be a convex function of S at ﬁxed V and N. A composite system having the same values of S, V, and
N would have an energy represented by the intersection of the chord with the vertical line at S. (a) Stable (convex)
and (b) Unstable (concave).
Similar equations would apply for the other extensive variables V and N on which U de-
pends. Thus, for stability, U is a convex function of S, V, and N (and of its other extensive
variables for more complicated systems). This requirement is represented graphically in
Figure 7–4.
If both S and V are different for members of the composite system, stability requires
(1/2)U(S −S, V −V , N) + (1/2)U(S + S, V + V , N) ≥U(S, V , N).
(7.23)
For inﬁnitesimal changes, Eq. (7.23) yields the stability requirement
USS(δS)2 + UVV (δV )2 + 2USV δSδV ≥0.
(7.24)
We can proceed as in the case of Eq. (7.12) to examine eigenvalues and to ﬁnd the
condition that both are non-negative. In addition to USS ≥0 and UVV ≥0, this leads
to the ﬂuting condition
D ≡USSUVV −U2
SV ≥0,
(7.25)
which has the same sense of the inequality as Eq. (7.16). We can also deduce Eq. (7.25)
by another method as follows. We multiply Eq. (7.24) by the non-negative quantity USS to
deduce
(USSδS + USV δV )2 + D(δV )2 ≥0.
(7.26)
For given δV, the ﬁrst term can be made equal to zero by choice of δS, so the second term
must be non-negative, thus resulting in Eq. (7.25). Moreover, if Eq. (7.25) holds, Eq. (7.26)
is always satisﬁed, so Eq. (7.25) is both necessary and sufﬁcient. A similar technique can be
applied to analyze Eq. (7.12); in that case, one multiplies ﬁrst by the non-positive quantity
SUU which reverses the sense of the inequality. Thus,

102
THERMAL PHYSICS
(SUUU + SUV V)2 + (SUUSVV −S2
UV )(V )2 ≥0,
(7.27)
which results in Eq. (7.16). For the internal energy we could also carry out the same
procedure that led to Eq. (7.18), resulting in the stability requirement
g1(s, v)u(s1, v1) + g2(s, v)u(s2, v2) + g3(s, v)s(u3, v3) ≥u(s, v).
(7.28)
Here, the fractions gi(s, v) are linear functions of s and v that satisfy gi(sj, vj) = δij.
Equation (7.28) shows that u(s, v) must lie below any plane represented by its left-hand
side, so u(s, v) must be a convex function for global stability.
7.3 Stability Requirements for Other Potentials
We can also obtain stability requirements for other potentials, such as H, F, and G, which
are Legendre transforms of U. An important distinction arises, however, because some of
the natural variables on which these functions depend are intensive.
7.3.1 Enthalpy
For the enthalpy H(S, p, N), stability requires
(1/2)H(S −S, p, N) + (1/2)H(S + S, p, N) ≥H(S, p, N).
(7.29)
For inﬁnitesimal changes δS, the local stability requirement is
HSS :=
∂2H
∂S2

p,N
≥0.
(7.30)
But there is no equation analogous to Eq. (7.29) involving changes p because p is
intensive and therefore must be the same in each member of the composite system that
we compare to H(S, p, N). We therefore deduce an inequality for Hpp by relating to a partial
derivative of its Legendre transform U. As shown in Section 5.5, we have
Hpp :=
∂2H
∂p2

S,N
= −
1
UVV
≤0.
(7.31)
Thus for local stability, H is a locally convex function of the extensive variable S but a
locally concave function of the intensive variable p. As a result of this, the ﬂuting condition
HSSHpp −H2
Sp ≤0 is true by default because both terms are non-positive. The fact that this
inequality has the correct sense can also be seen as follows. We suppress N for simplicity
of notation. Then (∂U/∂S)V = T = (∂H/∂S)p, so
∂2U
∂S2

V
=

∂
∂S
∂H
∂S

p

V
= HSS + HSp
∂p
∂S

V
.
(7.32)
But
∂p
∂S

V
= −
(∂V /∂S)p

∂V /∂p

S
= −HSp
Hpp
.
(7.33)

Chapter 7 • Requirements for Stability
103
Therefore
USS =
HSSHpp −H2
Sp
Hpp
.
(7.34)
Since USS ≥0, HSS ≥0, and Hpp ≤0, we see consistently that HSSHpp −H2
Sp ≤0.
In a similar manner, we can show that
HSS = USSUVV −U2
SV
UVV
=
D
UVV
,
(7.35)
so the fact that D ≥0 could have been deduced from HSS ≥0 and UVV ≥0. It is generally
the case that all ﬂuting conditions can be deduced from conditions on non-mixed second
derivatives provided that appropriate Legendre transforms are considered.
7.3.2 Helmholtz Free Energy
For the Helmholtz free energy F(T, V, N), we have an equation analogous to Eq. (7.29)
but involving V and this leads directly to the local requirement FVV ≥0. We also have
FTT = −1/USS ≤0. So for local stability, F is a locally convex function of the extensive
variable V and a locally concave function of the intensive variable T. By methods similar
to those discussed for the enthalpy, we have the local stability requirement
UVV = FVV FTT −F2
VT
FTT
(7.36)
so FVV FTT −F2
VT ≤0, which is no contest because FTT ≤0 so both terms are non-positive.
We also have
FVV =
D
USS
≥0,
(7.37)
another redundancy.
7.3.3 Gibbs Free Energy
For the Gibbs free energy G(T, p, N), both T and p are intensive, so local stability re-
quirements involving their derivatives must be obtained indirectly from their Legendre
transforms. We have GTT = −1/HSS ≤0 and Gpp = −1/FVV ≤0 as anticipated for both
principal second partial derivatives with respect to intensive variables. In this case, the
ﬂuting condition is not trivial. It is most easily related to derivatives of F or H, which differ
from it by a single Legendre transform. Thus we can use either
FTT =
GTTGpp −G2
Tp
Gpp
(7.38)
or
Hpp =
GTTGpp −G2
Tp
GTT
,
(7.39)

104
THERMAL PHYSICS
either of which shows that
GTTGpp −G2
Tp ≥0.
(7.40)
A somewhat more involved calculation3 shows that Gpp = −USS/D, GTT = −UVV /D, and
GTp = −USV /D which results in
GTTGpp −G2
Tp =
1
USSUVV −U2
SV
≥0,
(7.41)
so the two non-trivial ﬂuting conditions are just reciprocals of one another.
7.3.4 Summary of Stability Requirements
By means similar to those discussed above, we can extend the stability requirements to
any number of variables. For stability of a homogeneous system:
•
The entropy, S, must be a concave function of its natural extensive variables.
•
The internal energy, U, must be a convex function of its natural extensive variables.
•
Legendre transforms of U, such as H, F, and G, must be convex functions of their
natural extensive variables and concave functions of their natural intensive variables.
We did not discuss the Massieu functions, which are Legendre transforms of the entropy,
but they must be concave functions of their extensive variables and convex functions of
their intensive variables.
Fluting conditions involve mixed partial derivatives, but are always redundant with
requirements on non-mixed second partial derivatives of S, U, or some Legendre trans-
form of U.
It is possible to consider thermodynamic functions, perhaps derived from some model,
for which the requirements for local stability are true for some range of variables but for
which the requirements for global stability are violated. Such situations can occur when
different phases of a composite system are in equilibrium but in which phase transitions
can occur. We shall illustrate this in Chapter 9 by means of the van der Waals model.
In applying the above requirements, it is extremely important to note that they only
apply to the extensive thermodynamic functions and the natural variables, extensive and
intensive, on which they depend. Moreover, if one uses a “density” of some extensive
variable, such as the Helmholtz free energy per mole, f = F/N, one ﬁnds that df = −s
dT −p dv where v = V/N is also a “density,” namely the volume per mole. Although f
and v are certainly intensive, they still behave from the point of view of stability like the
extensive variables F and V from which they originate. In other words,

∂2f /∂v2
T ≥0
for local stability, corresponding to f being a convex function of v, just as F is a convex
function of V. But T is not a “density” so

∂2f /∂T2
v ≤0 for local stability, meaning that
f is a concave function of T. This peculiarity arises because the local stability condition
3For instance, GTT = −1/(∂US/∂S)p, (∂US/∂S)p = USS + USV (∂V/∂S)p, and (∂V/∂S)p = −UVS/UVV .

Chapter 7 • Requirements for Stability
105
for an intensive variable such as T is derived from a Legendre transformation, rather than
splitting a system into parts having different values of T, as was done for V.
7.4 Consequences of Stability Requirements
By using the stability requirements previously derived, we can deduce several useful rela-
tionships about the signs and relative magnitudes of some measurable physical properties
of stable homogeneous phases. Thus
USS =
∂T
∂S

V,N
= T/CV ≥0
(7.42)
so the heat capacity at constant volume CV ≥0. Similarly
HSS =
∂T
∂S

p,N
= T/Cp ≥0
(7.43)
so the heat capacity at constant pressure Cp ≥0. We also have
FVV = −
 ∂p
∂V

T,N
= 1/(V κT) ≥0
(7.44)
so the isothermal compressibility κT ≥0. From Eq. (5.32) we have
Cp −CV = TV α2/κT
(7.45)
so
Cp ≥CV ≥0.
(7.46)
We can deﬁne a compressibility at constant entropy4 by the relation
κS := −1
V
∂V
∂p

S,N
.
(7.47)
Since UVV = −

∂p/∂V

S,N ≥0, we see that κS ≥0. It can be related to κT as follows. We
have (with constant N suppressed for simplicity)
−VκS =
∂V
∂p

T
+
∂V
∂T

p
∂T
∂p

S
(7.48)
so
κS = κT −α
∂T
∂p

S
.
(7.49)
Then from

∂T/∂p

S

∂p/∂S

T(∂S/∂T)p = −1 we deduce
∂T
∂p

S
= −

∂S/∂p

T
(∂S/∂T)p
=
V α
Cp/T ,
(7.50)
4This is sometimes called the adiabatic compressibility, but strictly speaking it is isentropic.

106
THERMAL PHYSICS
where the Maxwell relation −

∂S/∂p

T = (∂V/∂T)p from the differential dG has been used.
Combining these relations gives
κT −κS = TV α2/CP.
(7.51)
We therefore see that
κT ≥κS ≥0.
(7.52)
In fact, combination of Eqs. (7.45) and (7.51) gives the interesting relation
κS/κT = CV /Cp.
(7.53)
For an alternative derivation of Eq. (7.53) that involves Jacobians, see Appendix B.
7.5 Extension to Many Variables
A number of other relationships can be derived in the same manner as illustrated above.
We illustrate these beginning with the internal energy as a function of many extensive
variables. If we write dU in the form
dU =
n
	
j=1
pj dEj,
(7.54)
where the Ej are extensive variables and the pj are their conjugate intensive variables, local
stability with respect to a single variable will require

∂2U
∂E2
i

{E′
i}
=
∂pi
∂Ei

{E′
i}
≥0,
(7.55)
where {E′
i} is the set {Ei} with Ei missing. If all of the extensive variables are allowed
to change by inﬁnitesimal amounts, the generalization of the local stability condition
Eq. (7.24) is
	
i,j
δUi Uij δUj ≥0;
Uij =
∂2U
∂Ei∂Ej
= Uji.
(7.56)
We could proceed to diagonalize the real symmetric matrix U = {Uij}, in which case
Eq. (7.56) would become
	
i
λi (δXi)2 ≥0,
(7.57)
where λi are its eigenvalues and δXi are linear combinations of the δUj that depend on
the eigenvectors of U. The condition for all eigenvalues of U to be positive deﬁnite is that
the determinants of all of its principal minors be positive deﬁnite. Its principal minor of
order r is the square symmetric matrix obtained from {Uij} by eliminating all of its rows for
i > r and all of its columns for j > r. If U is an n × n matrix, there are n of these principal
minors, the largest being the entire matrix U. For the simple case in which only δU1 and

Chapter 7 • Requirements for Stability
107
δU2 are non-zero, the minor of order r = 1 gives U11 > 0 and the minor of order r = 2
gives U11U22 −U2
12 > 0, in agreement with Eq. (7.25).
For the entropy as a function of many extensive variables, the corresponding local
stability criterion is a little trickier. In that case, one wants the eigenvalues of the matrix
{Sij} to be non-positive. In order for such eigenvalues to be negative deﬁnite, one needs the
determinants of the principal minors of odd order to be negative and those of even order to
be positive. Thus, if only δS1 and δS2 are non-zero, one needs S11 < 0 but S11S22 −S2
12 > 0,
in agreement with Eq. (7.16).
If we consider the Legendre transform
L = U −
n
	
k=r+1
pkEk
(7.58)
with differential
dL =
r
	
j=1
pj dEj −
n
	
k=r+1
Ek dpk,
(7.59)
we get either a stability requirement of the type
∂L
∂Ej
=
∂pj
∂Ej

{E′
j},{pk}
≥0;
j = 1, . . . , r;
k = r + 1, . . . , n,
(7.60)
or
∂L
∂pk
= −
 ∂Ek
∂pk

{Ej},{p′
k}
≤0;
j = 1, . . . , r;
k = r + 1, . . . , n.
(7.61)
Comparison of Eq. (7.60) with Eq. (7.55) shows that a partial derivative of an intensive vari-
able with respect to its conjugate extensive variable is non-negative, but different variables
can be held constant in the partial differentiations. For instance,

∂μj/∂Nj

S,V,{N′
j} ≥0 but
also

∂μj/∂Nj

S,p,{N′
j} ≥0,

∂μj/∂Nj

T,V,{N′
j } ≥0, and

∂μj/∂Nj

T,p,{N′
j } ≥0 follow from
consideration of U, H, F, and G, respectively.
7.6 Principles of Le Chatlier and Le Chatlier-Braun
Before leaving the subject of stability, we mention some general principles that govern
the approach of systems to equilibrium. The ﬁrst, due to Le Chatlier, states that if some
extensive variable ﬂuctuates from its equilibrium value, its conjugate intensive variable
will change in such a way as to restore that extensive variable to its equilibrium value.
The second, due to Le Chatlier-Braun, states that if some extensive variable ﬂuctuates and
also produces changes in non-conjugate intensive variables, secondary induced processes
occur in such a way as to oppose the change in the conjugate intensive variable associated
with the original extensive variable. Thus, any ﬂuctuations of a stable state will tend to
decay in such a way as to restore equilibrium values. For formal treatments, see Landau
and Lifshitz [7, p. 63] or Callen [2, p. 212].

This page intentionally left blank 

8
Monocomponent Phase Equilibrium
In this Chapter, we examine equilibrium for a monocomponent system for the simple
case in which the solid phase has only a single crystal structure. The situation can
be described by means of a phase diagram in the T, p plane, such as sketched in
Figure 8–1. This diagram divides the plane into regions where the phases solid (S), liquid
(L), and vapor1 (V) are stable. Therefore, the only lines that appear on the diagram are
curves where pairs of these phases are in equilibrium. These are called coexistence curves
and we shall proceed to develop equations that describe them.
According to the thermodynamics of open monocomponent systems, the conditions
for phases to be in equilibrium (see Chapter 6) are for them to have the same temperature
T, the same pressure p, and the same chemical potential μ. But according to Eq. (5.45),
the Gibbs-Duhem equation, these variables are not independent and one can regard the
chemical potential μ(T, p) to be a function of temperature and pressure. This function is
not the same for different phases, so the coexistence curves are given by the following
equations:
μS(T, p) = μL(T, p),
solid-liquid coexistence curve,
(8.1)
μS(T, p) = μV(T, p),
solid-vapor coexistence curve,
(8.2)
μL(T, p) = μV(T, p),
liquid-vapor coexistence curve.
(8.3)
According to the Gibbs phase rule for a monocomponent system, the number of ther-
modynamic degrees of freedom is 3 −n where n is the number of phases. A single phase
region, such as the solid, is represented by an area; accordingly, n = 1 and there are two
degrees of freedom, p and T, that may be chosen independently throughout this area.
Along each of the coexistence curves, p = 2 so there is one degree of freedom along these
curves. Thus, if T is speciﬁed, p is known from the curve. For either solid-vapor or solid-
liquid equilibrium, the corresponding pressure of the vapor for a given value of T is known
as the vapor pressure. If n = 3, there are no degrees of freedom; this happens at a point
known as the triple point where solid, liquid, and vapor are in mutual equilibrium with
each other. Thus we have
μS(T, p) = μL(T, p) = μV(T, p),
triple point.
(8.4)
Equation (8.4) represents two equations in two unknowns; their solution determines Tt
and pt, the unique coordinates of the triple point. It turns out that the liquid-vapor
coexistence curve actually ends at a point Tc and pc known as the critical point. Thus,
1A vapor is a gaseous phase that can be condensed to form a liquid or solid. Sometimes the word “gas” is used
interchangeably with “vapor,” but an ideal gas cannot undergo a phase transformation.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00008-9
109
Copyright © 2015 Elsevier Inc. All rights reserved.

110
THERMAL PHYSICS
p
T
Tt, pt
Tc, pc
S
L
V
FIGURE 8–1 Sketch (not to scale) of a phase diagram for a monocomponent system. The curves are coexistence
curves for pairs of the phases solid (S), liquid (L), and vapor (V). All three phases coexist in mutual equilibrium at the
triple point Tt, pt. The liquid-vapor coexistence curve ends at the critical point Tc, pc. This diagram pertains to the
usual case in which the molar volume of the solid is less than that of the liquid from which it freezes. See Figure 8–3
for the unusual case.
for T > Tc or p > pc, liquid and vapor become indistinguishable. In Chapter 9 we will see
how such a behavior follows from the van der Waals model of a ﬂuid.
Phase diagrams for monocomponent systems can have great variety because the
crystalline solids can have different crystal structures, each considered to be a phase. For
example, if the solid can have two crystal structures, say α and β, there can be more than
one triple point, for example, for equilibrium among (α, L, V) and (α, β, L). See deHoff [21,
chapter 7] for some speciﬁc examples as well as geometrical details of chemical potential
surfaces.
8.1 Clausius-Clapeyron Equation
We proceed to ﬁnd a differential equation for one of the coexistence curves; we choose the
liquid-vapor coexistence curve as a speciﬁc example. We take the differential of Eq. (8.3)
to obtain
∂μL
∂T

p
dT +
∂μL
∂p

T
dp =
∂μV
∂T

p
dT +
∂μV
∂p

T
dp.
(8.5)
The derivatives in Eq. (8.5) can be identiﬁed by noting for a monocomponent system
that the chemical potential μ is equal to g := G/N, the Gibbs free energy per mole. This
follows because the Euler equation is just G = μN for a monocomponent system. Since
dG = −S dT + V dp + μ dN, we readily verify that
dμ = dg = −s dT + v dp,
monocomponent system,
(8.6)
where s is the entropy per mole and v is the volume per mole. Thus,
 ∂μ
∂T

p
= −s;
∂μ
∂p

T
= v.
(8.7)

Chapter 8 • Monocomponent Phase Equilibrium
111
Therefore, Eq. (8.5) becomes
dp
dT = sV −sL
vV −vL
.
(8.8)
We can further transform Eq. (8.8) by recalling that G = H −TS so that g = h −Ts where h
is the enthalpy per mole. Thus
μ = h −Ts,
monocomponent system,
(8.9)
and Eq. (8.3) leads to
sV −sL = hV −hL
T
(8.10)
along the coexistence curve. The quantity hV −hL is the latent heat of vaporization per
mole from liquid to vapor. Similarly, the quantity sV −sL is the entropy of vaporization per
mole from liquid to vapor. According to Eq. (8.3), μ is continuous at a coexistence curve.
But its ﬁrst partial derivatives −s and v are not continuous. They have jumps from liquid
to vapor that are related by Eq. (8.10). Thus, it turn out that both sV −sL and hV −hL are
positive quantities.2 Substitution of Eq. (8.10) into Eq. (8.8) leads to
dp
dT =
hV −hL
T(vV −vL),
(8.11)
which is known as the Clausius-Clapeyron equation.3 It is a differential equation for
the liquid-vapor coexistence curve. It is generally more useful than Eq. (8.3) because the
quantities on the right-hand side of Eq. (8.11) are better understood than μ itself and can
be measured experimentally. Since vV −vL > 0, the vapor pressure curve of p versus T has
a positive slope, so vapor pressure clearly increases with increasing T. To get the actual
shape of the vapor pressure curve, we must know how hV −hL and vV −vL depend on T
and v. Equations of the same form apply to the other coexistence curves.
8.1.1 Approximate Vapor Pressure Curve
We can integrate Eq. (8.11) by making the following approximations:
•
The latent heat h := hV −hL is a positive constant.
•
The molar volume of the vapor is much greater than that of the liquid, so vV −vL ≈vV.
•
We can approximate the volume of the vapor by using the ideal gas law, vV ≈RT/p.
These approximations are terrible near the critical point, but otherwise they are not too
bad over a limited range of T. Of course, an ideal vapor will not condense to form a liquid,
but the ideal gas law can still give a reasonable estimate of the molar volume of a real
vapor. With these approximations, Eq. (8.11) becomes
2Experiment as well as elementary considerations of statistical mechanics lead to the fact that a mole of vapor
has a higher entropy (more disorder) than a mole of liquid. For similar reasons, sV−sS, hV −hS, sL −sS, and hL −hS
are all positive quantities.
3According to Planck [15, p. 149] this equation was deduced by Clapeyron from Carnot’s incorrect theory, but
ﬁrst rigorously proved by Clausius.

112
THERMAL PHYSICS
dp
dT = ph
RT2 .
(8.12)
The variables separate to give
dp
p = h
R
dT
T2 ,
(8.13)
which integrates to yield
ln p = −h
RT + ln C,
(8.14)
where C is a constant. We can exponentiate Eq. (8.14) to obtain
p = C exp

−h
RT

.
(8.15)
The constant C can be determined by relating to one point, T0, p0, on the coexistence
curve, resulting in
p = p0 exp

−h
R
 1
T −1
T0

.
(8.16)
The exponential form of Eq. (8.15) indicates that the vapor pressure p increases very
rapidly as T increases. Consequently, it is often represented graphically by reverting to
Eq. (8.14) and plotting ln p as a function of 1/T, which yields a straight line of slope −h/R,
as illustrated in Figure 8–2. Such a plot of vapor pressure data could be used to determine
experimentally a value of h. Any process that obeys an equation of the general form
of Eq. (8.14) is known as an activated process and is said to have Arrhenius form. The
quantity h is often referred to as an activation energy, although it is really an enthalpy
difference. The reason that many processes are activated will become apparent from
statistical mechanics.
The same approximations can be made for the vapor pressure along the solid-vapor
coexistence curve, resulting in Eq. (8.16) with h = hV −hS. The process of formation
ln p
1/T
FIGURE 8–2 Plot of the logarithm of the vapor pressure p versus 1/T according to Eq. (8.14). The slope of the line
is −h/R. Quantities that depend on temperature in this way are said to have Arrhenius form with an activation
energy of h.

Chapter 8 • Monocomponent Phase Equilibrium
113
of a vapor directly from a solid is called sublimation, so this could also be called the
sublimation pressure, but vapor pressure is a more common usage.
8.1.2 Approximate Solid-Liquid Coexistence Curve
For the solid-liquid coexistence curve, the Clausius-Clapeyron equation becomes
dp
dT =
hL −hS
T(vL −vS)
(8.17)
and a different set of approximations applies as follows:
•
The entropy of fusion s = h/T := (hL −hS)/T is a positive constant.
•
The molar volume of the liquid is comparable to that of the solid, typically only a few
percent different. But vL −vS can have either sign. For most materials, vL −vS is positive,
resulting in p increasing with T. But for some materials, including H20, and semi-metals
such as antimony and bismuth, vL −vS is negative and p decreases as T increases.
•
v := vL −vS is constant.
With these approximations, Eq. (8.17) becomes
dp
dT ≈s
v ,
(8.18)
which integrates to give
p −p0 = s
v (T −T0).
(8.19)
Thus the solid-liquid coexistence curve is nearly a straight line with steep slope. In the case
for which v is positive, the phase diagram looks like Figure 8–1, but when it is negative,
as it is for H2O, the phase diagram resembles Figure 8–3.
p
T
Tt, pt
Tc, pc
S
L
V
FIGURE 8–3 Sketch (not to scale) of a phase diagram for a monocomponent system for the unusual case for which
the molar volume of the solid exceeds that of the liquid from which it freezes. The curves are coexistence curves for
pairs of the phases solid (S), liquid (L), and vapor (V). See Figure 8–1 for the usual case and other notation.

114
THERMAL PHYSICS
Example Problem 8.1. At atmospheric pressure, silver melts at T = 1235 K and its volume
expands about 4%, the actual volume change being about 0.4 cm3/mol. Its latent heat of fusion
is 11,950 J/mol. How much must the pressure increase to raise its melting point by 1 K?
Solution 8.1. Inserting this data into Eq. (8.17), we obtain
dp
dT =
11,950
1235 × 0.4 × 10−6 = 2.38 × 107 Pa/K = 2.38 × 102 atm/K.
(8.20)
Thus, an enormous pressure of about 240 atmospheres would be required to raise the melting
point of by 1 K. We conclude that the melting point of silver is practically insensitive to pressure,
which is typical of other substances as well. On the other hand, as will be shown below, boiling
points are quite sensitive to pressure because the molar volumes of gaseous phases depend
strongly on pressure and are many times larger than the molar volumes of condensed phases.
8.1.3 Approximate Relative Magnitudes
The approximations used to obtain Eqs. (8.16) and (8.19) are rather crude and only meant
to be illustrative. Although they lead to results that resemble the phase diagrams for real
systems, they are no substitute for accurate experimental data. We can, however, gain
some insight into the relative magnitudes of the slopes dp/dT by using empirical rules
to estimate the latent heats. At atmospheric pressure, for many simple metals, we have
Trouton’s rule that estimates h/(RT) = 10.5 for vaporization and Richard’s rule that
estimates h/(RT) = 1.0 for melting. By using these rules, Eq. (8.11) becomes
dp
dT ≈10.5R
vV
,
vaporization at atmospheric pressure,
(8.21)
and Eq. (8.17) becomes
dp
dT ≈1.0R
v ,
melting at atmospheric pressure.
(8.22)
By taking the ratio of Eq. (8.21) to Eq. (8.22) we obtain
 dp
dT

vaporization

 dp
dT

melting

−1
≈10.5|v|
vV
≪1,
(8.23)
where the inequality applies because vV is typically many orders of magnitude larger
than |v| for melting. Therefore, the slope of the solid-liquid coexistence curve is much
steeper for melting than for vaporization. For vaporization of water at 373.1 K = 100 ◦C,
Fermi [1, p. 67] estimates dp/dT = 2.7 cm Hg/K = 0.036 atm/K, whereas for melting of ice at
273.1 K = 0 ◦C he estimates4 dp/dT = −134 atm/K. The ratio of these slopes is −2.7×10−4.
4This temperature is 100 K lower than for vaporization, but dp/dT is nearly constant along the line of solid-
liquid coexistence.

Chapter 8 • Monocomponent Phase Equilibrium
115
If we compute this ratio using Eq. (8.23), we get −5.5 × 10−4. But the latent heats of H2O
deviate signiﬁcantly from those given by Trouton’s rule and Richard’s rule as given above
because of the complexity of the water molecule and the structure of ice. For H2O, 10.5 for
Trouton’s rule should be replaced by 13.0 and for 1.0 for Richard’s rule should be replaced
by 2.64. This has the net effect of replacing 10.5 in Eq. (8.23) by 13.0/2.64 = 4.92, so the
corrected value of the slope ratio for H2O is −2.6 × 10−4, in reasonable agreement.
8.2 Sketches of the Thermodynamic Functions
We can gain more insight into monocomponent systems by sketching the thermodynamic
functions μ, h, and s as functions of p and T. For a phase diagram of the form of Figure 8–1,
we choose three constant pressures, p1, p2, and p3 as indicated in Figure 8–4, and then
discuss μ, h, and s as a function T at each of these pressures.
Along a line of constant p, μ is a continuous function of T. According to Eq. (8.7), its
slope is −s. But s is discontinuous at a coexistence curve, so μ has a discontinuity of slope
as T crosses a coexistence curve. Figure 8–5 shows a sketch of μ as a function of T along
the line p1 in Figure 8–4.
To quantify the behavior of s and h, we must view them as functions of T and p. Within
a bulk phase,
ds =
 ∂s
∂T

p
dT +
 ∂s
∂p

T
dp = cp
T dT +
 ∂s
∂p

T
dp,
(8.24)
where cp is the heat capacity per mole at constant pressure. From Eq. (8.7) we have the
Maxwell relation
 ∂s
∂p

T
= −
 ∂v
∂T

p
= −vα,
(8.25)
p
T
Tt,pt
Tc,pc
S
L
V
p1
p2
p3
FIGURE 8–4 Constant pressure paths p1, p2, and p3 on a phase diagram for the monocomponent system of Figure
8–1. The chemical potential μ is continuous along these paths, but its slope, −s, changes as T crosses a coexistence
curve.

116
THERMAL PHYSICS
µ
TSV
T
S
V
FIGURE 8–5 Sketch of the chemical potential μ as a function of T along the line p = p1 in Figure 8–4. The full
line corresponds to the stable solid and vapor phases. The dashed lines are extrapolations into unstable regions of
superheated solid and supercooled vapor, intended to emphasize the discontinuity of slope of the full line at the
phase transition. The stable phase is solid (S) for T ≤TSV and vapor (V) for T ≥TSV.
where α is the coefﬁcient of expansion. Thus
ds = cp
T dT −vα dp.
(8.26)
For the enthalpy per mole, we have
dh = T ds + v dp = T
 ∂s
∂T

p
dT +

T
 ∂s
∂p

T
+ v

dp.
(8.27)
Thus
dh = cp dT + v(1 −Tα) dp.
(8.28)
For the sake of consistency of Eqs. (8.26) and (8.28), note that substitution into dμ = dh −
s dT −T ds leads back to Eq. (8.6). Thus within a single phase at constant pressure we have
h(T2) −h(T1) =
 T2
T1
cp dT ≈cp(T2 −T1);
(8.29)
s(T2) −s(T1) =
 T2
T1
cp
T dT ≈cp ln(T2/T1),
(8.30)
where the approximate expressions hold if cp is a constant. Figure 8–6 shows sketches of h
and s as a function of T along the line p = p1 in Figure 8–4.
Along the line p = p2, there are two phase transitions, from S to L and from L to V, so μ
has a discontinuity of slope at each transition, and h and s have jumps at each transition.
Along the line p = p3, there is only one phase transition, because p3 > pc and there is no
distinction between liquid and vapor above the critical pressure.
Next, we choose three constant temperatures T1, T2, and T3, as indicated in Figure 8–7.
Along a line of constant T, μ is continuous and within a single phase, according to
Eq. (8.7), it has a slope of v. Figure 8–8 is a sketch of μ versus p at T = T1. We observe
the discontinuity of slope as the vapor-solid coexistence curve is crossed.

h
TSV
T
Δh
S
V
s
TSV
T
Δs
S
V
FIGURE 8–6 Sketches of the enthalpy h per mole and entropy s per mole as a function of T along the line p = p1
in Figure 8–4. The full line corresponds to the stable solid and vapor phases. The stable phase is solid (S) for T ≤TSV
and vapor (V) for T ≥TSV. The dashed lines are extrapolations into unstable regions of superheated solid and
supercooled vapor. The jump h in enthalpy is the latent heat of vaporization per mole and the jump s is the
entropy of vaporization per mole. These jumps are related by h = Ts so there is no jump in μ, consistent with
Figure 8–5.
p
T
Tt, pt
Tc, pc
S
L
V
T1
T2
T3
FIGURE 8–7 Constant temperature paths T1, T2, and T3 on a phase diagram for the monocomponent system of
Figure 8–1. The chemical potential μ is continuous along these paths, but its slope, v, changes as p crosses a
coexistence curve.
µ
pSV
p
V
S
FIGURE 8–8 Sketch of the chemical potential μ as a function of p along the line T = T1 in Figure 8–7. The full
line corresponds to the stable solid and vapor phases. The dashed lines are extrapolations into unstable regions of
superheated solid and supercooled vapor, intended to emphasize the discontinuity of slope of the full line at the
phase transition. The stable phase is vapor (V) for p ≤pSV and solid (S) for p ≥pSV.

118
THERMAL PHYSICS
h
Δh
pSV
p
V
S
s
Δs
pSV
p
V
S
FIGURE 8–9 Sketches of the enthalpy h per mole and the entropy s per mole as a function of p along the line
T = T1 in Figure 8–7. The full line corresponds to the stable solid and vapor phases. The stable phase is vapor (V) for
p ≤pSV and solid (S) for p ≥pSV. The dashed lines are extrapolations into unstable regions of superheated solid and
supercooled vapor. The jump h is the latent heat of vaporization and the jump s is the entropy of vaporization.
These jumps are related by h = Ts so there is no jump in μ.
The behaviors of h and s versus p within a single phase can be ascertained from
Eqs. (8.26) and (8.28) which along a line of constant T lead to
h(p2) −h(p1) =
 p2
p1
v(1 −Tα) dp;
(8.31)
s(p2) −s(p1) =
 p2
p1
−vα dp.
(8.32)
For an ideal vapor, Tα = 1 which gives
h(p2) −h(p1) = 0;
s(p2) −s(p1) =
 p2
p1
−v
T dp = −R ln(p2/p1).
(8.33)
For the solid phase, Tα ≪1, so for constant v we have5
h(p2) −h(p1) ≈v(p2 −p1);
s(p2) −s(p1) ≈0.
(8.34)
Figure 8–9 shows sketches of h and s as functions of p along a line T = T1 in Figure 8–7.
Along the line T = T2 in Figure 8–7, there are two phase transitions, from V to L and from
L to S, so μ has a discontinuity of slope at each transition and h and s have jumps at each
transition. Along the line T = T3, the liquid-vapor phase transition is absent because T3 >
Tc and there is no distinction between liquid and vapor above the critical temperature.
8.3 Phase Diagram in the v, p Plane
In the v, p plane, the phase diagram of a monocomponent system is sketched in
Figure 8–10. The regions where single phases are stable are separated by miscibility gaps.
5The same approximation would be true for a liquid.

Chapter 8 • Monocomponent Phase Equilibrium
119
p
pc
pt
L
vc
vS
vV
vt
v
V
S
FIGURE 8–10 Sketch of the phase diagram for a monocomponent system in the v, p plane. The solid S is stable to
the left of all lines. The liquid L is stable in the region of distorted triangular shape, the bottom vertex of which is at
the triple point vt, pt. The triple point of the p, T phase diagram actually becomes a triple line on the v, p diagram
and extends from vS to vV. Thus vt also represents the molar volume vL of the liquid phase that is in equilibrium with
solid of molar volume vS and vapor of molar volume vV. The vapor V is stable to the right of all lines. The critical
point vc, pc is at the top of the miscibility gap that separates L from V. For p > pc, there is no distinction between
liquid and vapor. The regions of stable phases are separated by miscibility gaps. A point within a miscibility gap can
represent a composite made up of stable phases at its boundaries having the same pressure. This diagram is not to
scale. Typically, the difference in molar volume of L and S is a few percent, whereas the molar volume of a vapor in
equilibrium with S or L can be thousands of times larger.
These gaps occur because of the jumps in molar volumes between phases that are in
equilibrium with one another. A point within a miscibility gap could correspond to an
unstable single phase, for example, a supersaturated vapor that, for kinetic reasons, has
not yet transformed to precipitate some liquid. At equilibrium, a point within a miscibility
gap can represent a composite made up of stable phases at its boundaries having the same
pressure. Most points within a miscibility gap correspond to only two stable phases that lie
along a coexistence curve of a T, p phase diagram. But along the line p = pt, three phases
can coexist in equilibrium. The amounts of these three phases cannot be determined by
specifying the overall molar volume v alone, except for the special cases v = vS and v = vV
which correspond to the ends of the triple line. However, the three phases have different
molar enthalpies, hS, hL, and hV, so we could also specify the overall molar enthalpy, h. If
we denote the phases S, L, V by the indices 1, 2, 3, then their mole fractions fi must satisfy
f1 + f2 + f3 = 1,
f1v1 + f2v2 + f3v3 = v,
f1h1 + f2h2 + f3h3 = h.
(8.35)
But Eq. (8.12) is isomorphous with Eq. (8.35), so the fi(v, h) will have analogous properties
to the fi(s, v) discussed in Chapter 7. In particular, to get positive values of fi(v, h), the point
v, h must be chosen within or on the non-degeneratetriangle with vertices (vS, hS), (vL, hL),
and (vV, hV). The values of the fi(v, h) are given by the triangle construction in Figure 8–11.

120
THERMAL PHYSICS
h
A3
2
A2
3
v
A1
1
FIGURE 8–11 Triangle construction for solution of the fi(v, h) in Eq. (8.35). The vertices (1,2,3) are located at the
states (vS, hS), (vL, hL), and (vV, hV), respectively. The point within triangle 123 where the dashed lines meet has
coordinates (h, v) where the total molar volume and total molar enthalpy are speciﬁed. If we designate the area of
triangle 123 by A123, then fi(u, v) = Ai/A123, where Ai denotes the area of the inner triangle opposite to the vertex i.
The diagram is not to scale because typically vV −vS ≫vL −vS and hV −hS ≫hL −hS. If u, v lies on one of the sides
of triangle 123, only two phases will be present.

9
Two-Phase Equilibrium for
a van der Waals Fluid
In this chapter, we use the van der Waals model of a ﬂuid to develop the methods that en-
able one to analyze the thermodynamics of two-phase equilibrium for a monocomponent
system. This model will also serve to illustrate why the Helmholtz and Gibbs free energies
are useful thermodynamic functions. We will focus particular attention on two graphical
constructions, the common tangent and the chord, that will enable us to see easily the
conditions under which two phases can exist in equilibrium as well as identify regions of
stability and metastability. We will also derive Maxwell’s construction that allows one to
determine the miscibility gap in the v, p plane. Although we have used the simple model
of a van der Waals ﬂuid, the methods developed in this chapter are general and apply to
more realistic models or data.
9.1 van der Waals Equation of State
A simple model for a monocomponent system that exhibits a liquid-vapor phase transi-
tion and a critical point is based on a generalized1 equation of state, due to van der Waals,
of the form
(p + a
v2 )(v −b) = RT,
(9.1)
which holds for one mole of a van der Waals ﬂuid. In Eq. (9.1), p is the pressure, v is the
molar volume, T is the absolute temperature, R is the gas constant, and a and b are positive
constants. Equation (9.1) can be rewritten in the form
p =
RT
v −b −a
v2 ,
(9.2)
which becomes the equation of state for one mole of an ideal gas for a = 0 and b = 0. The
constant b accounts for the ﬁnite size of vapor molecules, so v −b is the volume per mole
that is free for occupancy. The constant a accounts for an attractive force between vapor
molecules, which for sufﬁciently low temperatures will lead to condensation to a liquid.
The explicit form of the term −a/v2 in the pressure can be justiﬁed on the basis of mean
ﬁeld theory, but we postpone this connection until Section 9.2.
1Strictly speaking, an equation of state expresses a partial derivative of a fundamental equation (for S or U)
with respect to one of its dependent extensive variables as a function of its complete set of extensive variables. In
this generalized equation of state, we have a relation among intensive variables which gives the partial derivative,
−p, of the Helmholtz free energy per mole, f , with respect to the molar volume v as a function of T and v.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00009-0
121
Copyright © 2015 Elsevier Inc. All rights reserved.

122
THERMAL PHYSICS
The van der Walls ﬂuid is a useful model because it is tractable and gives rise to an
approximate phase diagram that exhibits many of the features of real phase diagrams.
Nevertheless, it is wrong in detail, especially near the critical point where correlations
become important and mean ﬁeld models fail. We shall examine this model with these
shortcomings in mind, but with the aim of illustrating important constructions that allow
one to analyze graphs of the Helmholtz and Gibbs free energies.
9.1.1 Isotherms
Insight about the van der Waals ﬂuid can be gained by using Eq. (9.2) to plot isotherms
in the v, p plane, as sketched below in Figure 9–1. In doing this, we make the restriction
v > b in order to avoid inﬁnite values of p. For high T, the term in a is negligible and the
isotherms resemble those for an ideal gas, except shifted to the right by b. For sufﬁciently
low T, p is not a monotonically decreasing function of v and there are three values of v for
a given p (see Figure 9–1b which shows such an isotherm on an exaggerated scale). These
values are roots of the cubic equation
pv3 −(pb + RT)v2 + av −ab = 0,
(9.3)
which is equivalent to Eq. (9.2). For T sufﬁciently low, one root of Eq. (9.3) can be small (of
the order of b) and will be associated with a liquid; another can be large (of the order of
RT/p) and can be associated with a vapor, and a middle sized root is spurious and can be
associated with an unstable phase.
To ﬁnd out when the isotherms display a non-monotonic behavior, we look for a
maximum and minimum of p by examining
v
p
T1
T2
Tc
T3
T4
v
p
pmin
pmax
κT < 0
FIGURE 9–1 (a) Sketch of isotherms in the v, p plane according to Eq. (9.2), for T4 > T3 > Tc > T2 > T1. For
sufﬁciently high temperatures, the isotherms are monotonically decreasing functions of v, as they would be for an
ideal gas. Tc is the critical temperature and its isotherm has a horizontal point of inﬂection. For sufﬁciently low
temperatures, the isotherms display multiple values of v for the same value of p. (b) A low temperature isotherm
on an exaggerated scale, illustrating a maximum and a minimum value of p. The curve between the maximum and
minimum values, pmax and pmin, corresponds to unstable states having negative compressibility, κT < 0.

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
123
(v−b)2
v3
RTc
2a
RT2
2a
RT1
2a
vc
v
FIGURE 9–2 Graphical solution to Eq. (9.5). The straight horizontal lines represent values of RT/(2a). For values of
RT/(2a) above the maximum of the curve, there are no real roots. For RTc/(2a) corresponding to the maximum of
the curve, there is one real root, and this deﬁnes the critical temperature Tc. Below the critical temperature, there
are two real roots, and these lie on the spinodal curve of Figure 9–3.
∂p
∂v

T
= −
RT
(v −b)2 + 2a
v3 = 0.
(9.4)
Eq. (9.4) may be rewritten in the form
(v −b)2
v3
= RT
2a ,
(9.5)
which admits a graphic solution depicted in Figure 9–2. For T > Tc where Tc is a critical
value of temperature, there are no real roots, so p versus v is monotonic; for T = Tc, there
is one real root at the critical molar volume vc; and for T < Tc there are two real roots, the
smaller corresponding to a minimum of p and the larger to a maximum of p. By setting
the derivative of (v −b)2/v3 to zero, its maximum is found to occur at vc = 3b and has the
value (vc −b)2/v3
c = 4/(27b). Therefore
Tc =
8a
27bR,
(9.6)
and the corresponding critical pressure is2
pc =
RTc
vc −b −a
v2c
=
a
27b2 .
(9.7)
Returning to Eq. (9.4), we note that the partial derivative (∂p/∂v)T = −1/(vκT) where
κT := −(1/v)(∂v/∂p)T is the isothermal compressibility. Therefore, the maximum and
minimum of p as a function of v correspond to points of inﬁnite compressibility, and the
values of v in between to a region of negative compressibility. As discussed in Chapter 7,
this region of negative compressibility corresponds to an unstable phase, which is an
artifact of the van der Waals model.
2These results are the same as those obtained by Fermi [1, p. 73] by using the clever method of ﬁnding a triple
root of v for Eq. (9.3) when p = pc and T = Tc. Thus Eq. (9.3) can be written pc(v −vc)3 = 0 and comparison of
coefﬁcients of powers of v gives three simultaneous equations.

124
THERMAL PHYSICS
Another consideration of the van der Walls model is the need to restrict T to prevent
negative pressures. Setting p = 0 in Eq. (9.2) and solving the resulting quadratic equation
for v yields
v = a ±
√
a2 −4abRT
2RT
,
(9.8)
which has a double root, corresponding to the minimum of a p versus v curve just touching
zero, whenever a2−4abRT = 0. This gives T = 27Tc/32. The restriction T > 27Tc/32 would
seem to allow only a narrow range of temperature, but we must recall that we are dealing
here with absolute temperatures. For H20, for example, Tc = 647 K, so 27Tc/32 = 546 K,
allowing a range of 100 K. If one restricts the model to temperatures above which stable
phases have positive pressure, even lower temperatures are possible.
9.1.2 Spinodal Curve
The locus in the v, p plane of the maximum and minimum of p as a function of v is known
as the spinodal. It separates the (unstable) region of negative compressibility from that of
positive compressibility (where states can be either stable or metastable, as we shall see
later). A simple equation for this spinodal curve can be obtained by substituting Eq. (9.5)
into Eq. (9.2) to eliminate T and thus obtaining
p = a(v −2b)
v3
,
spinodal curve,
(9.9)
which yields positive values for v > 2b, which is equivalent to v > 2vc/3. The value
v = 2vc/3 corresponds to T = 27Tc/32, obtained above. In terms of the dimension-
less pressure y := p/pc and the dimensionless volume ν
:= v/vc, Eq. (9.9) can be
written
y = 3ν −2
ν3
,
spinodal curve,
(9.10)
which is depicted by the dashed curve in Figure 9–3. Note the asymmetry of the plot
relative to its maximum. This asymmetry is due to the fact that the liquid always has a
molar volume of the order of vc, whereas the vapor has a large volume as well as a large
range of volume, depending on its pressure p.
9.2 Thermodynamic Functions
We now calculate thermodynamic functions for the van der Waals ﬂuid. Since Eq. (9.2)
gives p as a function of v and T, the most natural function to deal with is the Helmholtz
free energy per mole, f := F/N. Its differential is
df = −s dT −p dv,
(9.11)

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
125
y
ν
Spinodal curve
FIGURE 9–3 Plot of dimensionless pressure y = p/pc as a function of dimensionless molar volume ν = v/vc.
The dashed curve is the spinodal given by Eq. (9.10) and the solid curves are isotherms. From top to bottom,
T/Tc = 32/28, 32/30, 1, 30/32, 28/32, 27/32. The lowest isotherm touches zero pressure at ν = 2/3, which is the
same as v = 2b.
so
−p =
 ∂f
∂v

T
= a
v2 −
RT
v −b.
(9.12)
We can therefore integrate Eq. (9.12) at constant T to obtain
f = −a
v −RT ln(v/b −1) + f0(T),
(9.13)
where the function (“constant” as far as v is concerned) of integration f0(T) depends on
T and we have used the degree of freedom provided by it to make the argument of the
logarithm dimensionless. Then by differentiation we can calculate the entropy
s = −
 ∂f
∂T

v
= R ln(v/b −1) −f ′
0(T),
(9.14)
where f ′
0(T) denotes the derivative of f0(T). From Eq. (9.14) it follows that the heat capacity
at constant volume
cv = T
 ∂s
∂T

v
= −Tf ′′
0 (T)
(9.15)
so it depends only on T. The internal energy per mole is
u = f + Ts = −a
v + f0(T) −Tf ′
0(T).
(9.16)
Note from Eq. (9.16) that u depends on both v and T, whereas for an ideal gas, a = 0 and
u is a function of only T, as we know.
In the following, we shall be concerned with the behavior of f as a function of v at
various ﬁxed values of T, so the unknown function f0(T) will either just shift the origin of
f or drop out entirely when values of f are compared at ﬁxed T for different v.

126
THERMAL PHYSICS
Example Problem 9.1. In many treatments of the van der Waals ﬂuid, cv is taken to be
a constant. In that case, ﬁnd an explicit form of f0(t) by integrating Eq. (9.15) and intro-
ducing any necessary constants of integration. Then calculate the corresponding values of
s and u.
Solution 9.1. We integrate f ′′
0 (T) = −cv /T once to obtain f ′
0(T) = −cv ln T + c1 where c1 is a
constant of integration. Then we integrate again to obtain f0(T) = −cv T ln T + cv T + c1T −u00
where u00 is another constant of integration. For convenience we choose the form of c1 so that
f0(T) = −cv T ln(T/Tc)−s00T +u00 where s00 is a new constant with the dimensions of entropy.
Then s = R ln(v/b −1) + cv [ln(T/Tc) + 1] + s00 and u = −a/v + cv T + u00.
9.2.1 Origin of the Constant a
As mentioned above, the constant a accounts for an attractive force between vapor
molecules. We proceed to explain this interpretation on the basis of mean ﬁeld theory.
We assume the potential energy for interaction of a vapor molecule, located at the origin
r = 0, with another molecule of the vapor at distance r to be given by a function ϕ(r) such
as sketched in Figure 9–4. For a system of N molecules, there are N(N −1)/2 ≈N 2/2
distinct pairs, so the attractive energy associated with these pairs is
Ua ≈N 2
2V
 ∞
rb
ϕ(r) 4πr2 dr,
(9.17)
where V is the volume and we have taken the integral to inﬁnity provided the potential
cuts off sufﬁciently rapidly. The mean ﬁeld approximation is implicit in Eq. (9.17) because
the factor N 2/V is taken outside the integral as a constant, whereas in reality, there are
correlations among the vapor molecules and their density is not uniform. Introducing the
r
rb
0
ϕ
FIGURE 9–4 Sketch of the potential function ϕ(r) as a function of r. For small r, say r = rb, corresponding roughly
to the excluded volume b, ϕ(r) is large and positive, resulting in strong repulsion, while for larger values of r, ϕ(r) is
negative, resulting in mild attraction.

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
127
number of moles N = N/NA, where NA is Avogadro’s number, the molar volume v = V/N,
and the molar energy change ua = Ua/N, Eq. (9.17) can be rewritten in the form
ua = −a
v
with
a = −N 2
A
2
 ∞
rb
ϕ(r) 4πr2 dr > 0.
(9.18)
Equation (9.18) has the same form as the ﬁrst term in Eq. (9.13). Some values of a and b for
a variety of van der Walls ﬂuids are given by Callen [2, p. 77].
9.3 Phase Equilibrium and Miscibility Gap
Armed with a knowledge of f , we shall now use several methods to examine the conditions
for phase equilibrium, particularly the representation in the v, p plane of the coexistence
curve (in the T, p plane) for these phases. Coexistence in the v, p plane is represented by
two regions, one in which the equilibrium state is a single phase and the other, known
as the miscibility gap, in which the equilibrium state is a composite system consisting
of two phases. The spinodal curve derived above lies entirely within the miscibility gap
except at the critical point where the two intersect. Outside the miscibility gap, the ﬂuid
is stable; between the miscibility gap and the spinodal, the ﬂuid is metastable; and within
the spinodal, it is unstable. We shall use several methods to illustrate these points.
9.3.1 Common Tangent Construction
The common tangent construction is a useful method that provides a graphical solution
to phase equilibrium problems. We develop it in general, and then apply it speciﬁcally to
the van der Waals ﬂuid.
We consider a composite system at uniform temperature T and consisting of two
homogeneous phases of the same substance, one having mole number N1, volume V1,
and molar volume v1 = V1/N1 and the other having N2, V2 and v2 = V2/N2. The total
Helmholtz free energy of the system is
F = N1f (T, v1) + N2f (T, v2).
(9.19)
If these phases are in equilibrium, F must be a minimum with respect to changes of the
internal extensive variables N1, V1, N2, V2 subject to the constraints N1 + N2 = constant,
and V1 + V2 = constant.
We ﬁrst hold N1 and N2 constant and set the differential dF = 0 to obtain
N1
∂f (T, v1)
∂v1

T
 ∂v1
∂V1

N1
dV1 + N2
∂f (T, v2)
∂v2

T
 ∂v2
∂V2

N2
dV2 = 0.
(9.20)
Since (∂v1/∂V1)N1 = 1/N1, (∂v2/∂V2)N2 = 1/N2, and dV1 = −dV2 from a constraint,
Eq. (9.20) becomes
∂f (T, v1)
∂v1

T
=
∂f (T, v2)
∂v2

T
.
(9.21)

128
THERMAL PHYSICS
In view of the left-handequality in Eq. (9.12), Eq. (9.21) is recognized as equality of pressure
for two phases at the same temperature, one having molar volume v1 and the other having
molar volume v2. Thus Eq. (9.21) could be rewritten
p(T, v1) = p(T, v2).
(9.22)
This result is not to be unexpected!
Next, we hold V1 and V2 constant and set the differential dF = 0 to obtain

f (T, v1) + N1
∂f (T, v1)
∂v1

T
 ∂v1
∂N1

V1

dN1 +

f (T, v2) + N2
∂f (T, v2)
∂v2

T
 ∂v2
∂N2

V2

dN2 = 0.
(9.23)
Since (∂v1/∂N1)V1 = −V1/N2
1, (∂v2/∂N2)V2 = −V2/N2
2, and dN1 = −dN2 from a constraint,
Eq. (9.23) becomes
f (T, v1) −
∂f (T, v1)
∂v1

T
v1 = f (T, v2) −
∂f (T, v2)
∂v2

T
v2.
(9.24)
We identify the members on the left-hand and right-hand sides of Eq. (9.24) as chemical
potentials, that is,
f (T, v) −
∂f (T, v)
∂v

T
v = f (T, v) + p(T, v)v =: μ(T, v).
(9.25)
This enables Eq. (9.24) to be rewritten
μ(T, v1) = μ(T, v2).
(9.26)
From general considerations, Eq. (9.26) is also not to be unexpected!
We seem to have labored to obtain what amounts to Eqs. (9.22) and (9.26), which we
might have just written down from general considerations. Nevertheless, the chemical
potential μ, which for a monocomponent system is equal to the Gibbs free energy per
mole, g, is ordinarily regarded as a function of T and p, not T and v. The variables T and
v are the natural variables of f , not μ. We therefore return to Eqs. (9.21) and (9.24) and
establish the following geometrical interpretation: According to Eq. (9.21), a graph of f
versus v has the same slope at two values of v, namely at v1 and v2. There can be many pairs
of v1 and v2 for which this is true. But either the left or the right member of Eq. (9.24) can
be interpreted as the intercept, on the f axis (v = 0), of a tangent to a graph of f versus v at
v1 and v2. So Eq. (9.21) requires parallel tangents and Eq. (9.24) requires equal intercepts. It
follows that the simultaneous solution to Eqs. (9.21) and (9.24) requires a common tangent
at v1 and v2, as illustrated in Figure 9–5a.
Another important feature of Figure 9–5a is noteworthy. A composite system consisting
of the two phases having molar volumes v1 and v2 at its common tangent has a total molar
free energy that lies along the tangent line joining the points of tangency. To see this,
consider ﬁrst a homogeneous system consisting of N moles and having molar volume v∗.
For our composite system to have the same volume, we would need N1 + N2 = N and

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
129
f
μ
v∗
v2
v1
(a)
f
vS1
vS2 v2
v1
A
B C
D
(b)
FIGURE 9–5 (a) Common tangent construction and (b) chord construction. The curves represent the Helmholtz free
energy per mole, f = F/N, versus the molar volume v. For the common tangent construction, the dashed line is
tangent to the curve at v1 and v2. Its slope is the negative of the common pressure and its intercept is μ, the common
value of the chemical potential. The free energy per mole of a composite state having total molar volume v ∗lies
along the tangent line at v ∗and is lower than the free energy of a single phase having v ∗. Hence, the composite
system is more stable than a homogeneous system. The chord construction can be used to investigate the local or
global stability of a homogeneous phase. If the chord lies above the curve, as for the chord AB, the homogeneous
phases along the curve AB are stable with respect to a composite, whereas if it lies below the curve, as for the chord
CD, the homogeneous phases along the curve CD are unstable. vS1 and vS2 mark the spinodal points S1 and S2 at
which ∂2f/∂v 2 = 0.
N1v1+N2v2 = Nv∗. This results in N1/N = (v2−v∗)/(v2−v1) and N2/N = (v∗−v1)/(v2−v1)
which is known as the lever rule. Inserting these values in Eq. (9.19) gives
F/N = [(v2 −v∗)/(v2 −v1)]f (T, v1) + [(v∗−v1)/(v2 −v1)]f (T, v2)
(9.27)
= f (T, v1) + [(v∗−v1)/(v2 −v1)][f (T, v2) −f (T, v1)],
composite system.
Comparing this value with that for the homogeneous system having molar volume v∗, we
see that the free energy of the composite system is lower for all v∗between v1 and v2.
Thus, for these values of v∗, the composite system is the equilibrium state. Put another way,
given the opportunity, the homogeneous system will decompose to form the equilibrium
composite system consisting of two phases that are in equilibrium with each other.
9.3.2 Chord Construction
We can also use the reasoning that led to Eq. (9.27) to establish another valuable construc-
tion which we shall call the chord construction. Indeed, Eq. (9.27) is still valid if v1 and v2
correspond to any two points along the curve, provided only that v1 < v2. We can therefore
apply it to various points along the curve, such as the pair AB or the pair CD, as illustrated
in Figure 9–5b. For chord AB, the free energy of a composite lies along the chord, which is
above the curve AB, so a homogeneous phase along the curve AB is stable with respect to
a composite consisting of its end points. But for CD, the free energy of a composite lies on
a chord of f that is below f , so the single phase is unstable with respect to that particular

130
THERMAL PHYSICS
composite. Any homogeneous state that lies above the chord corresponding to the com-
mon tangent is unstable, but some of those states are locally stable. Local stability or in-
stability requires the chord construction to be applied to neighboring points. The spinodal
points where −∂p/∂v = ∂2f /∂v2 = 0 separate locally stable states from locally unstable
states. States that are locally stable but globally unstable are said to be metastable.
9.3.3 Summary for f(v) Curves
We can summarize this situation as follows: With respect to a curve of f versus v for a
monocomponent system, portions of the curve that are convex (as viewed from below)
correspond to locally stable states; portions of the curve that are concave (as viewed from
below) correspond to locally unstable states. All states that lie above the common tangent
between v1 and v2 are ultimately unstable. Thus there are three kinds of states:
unstable locally unstable (locally concave) and also above the common tangent be-
tween v1 and v2; therefore, locally unstable and globally unstable;
metastable locally stable (locally convex) but above the common tangent between v1 and
v2; therefore, locally stable but globally unstable;
stable locally stable (locally convex) but outside the common tangent region, i.e.,
v ≤v1 or v ≥v2; therefore, locally stable and globally stable.
The concave and convex regions are separated by points, S1 and S2, at which the second
partial derivative (∂2f /∂v2)T
= 0. But since (∂2f /∂v2)T
= −(∂p/∂v)T, these points
also correspond to maxima and minima of p, which means that they correspond to the
spinodal curve in the v, p plane. Thus the spinodal curve separates the metastable region
from the unstable region. On the other hand, the locus of the points of common tangency
in the v, p plane separate the stable region from the metastable region; the region inside
this curve is called the miscibility gap because within it a composite mixture of phases
located at the ends of the common tangent, rather than a homogeneous phase, is globally
stable.
9.3.4 Explicit Equations for van der Waals Miscibility Gap
For the van der Waals ﬂuid, the explicit forms of Eqs. (9.21) and (9.24) are
RT
v1 −b −a
v2
1
=
RT
v2 −b −a
v2
2
(9.28)
and
−2a
v1
−RT ln(v1/b −1) + RTv1
v1 −b = −2a
v2
−RT ln(v2/b −1) + RTv2
v2 −b.
(9.29)
For a given value of T, the simultaneous equations (9.28) and (9.29) can be solved for
v1 and v2 and then p can be evaluated by using Eq. (9.2). In principle, such a solution
determines the shape of the miscibility gap, but these equations would have to be solved
numerically because they are not tractable analytically. A graphical representation of their

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
131
1
2
3
4
-2.2
-1.8
-1.6
f/(RTc)
f/(RTc)
v/vc
(a)
2
4
6
8
10
12
14
-2.4
-2.2
-1.8
-1.6
-1.4
v/vc
(b)
FIGURE 9–6 Graphical representation of simultaneous solution of Eqs. (9.28) and (9.29). (a) T/Tc = 27/32, v/vc =
0.548 for the liquid and 3.241 for the vapor. The pressure is p/pc = 0.183. (b) T/Tc = 20/32, v/vc = 0.440 for the
liquid and 13.585 for the vapor. The pressure is p/pc = 0.0411.
solution is presented in Figure 9–6. Since the liquid and vapor have quite different molar
volumes, the curve of f becomes quite ﬂat at large values of v and such a solution is not
very practical. We therefore turn to other methods to demonstrate the nature of these
solutions.
9.4 Gibbs Free Energy
For the van der Waals ﬂuid, the Gibbs free energy per mole is g = f + pv, which is also
equal to the chemical potential μ for this monocomponent system. It can be written in
the form
g = −2a
v −RT ln(v/b −1) + vRT
v −b + f0(T),
(9.30)
where Eqs. (9.2) and (9.13) have been used. Equation (9.30) gives g as a function of T and v,
but this is not very useful information because the equilibrium criterion for g is that it be a
minimum for given values of T and p. Equation (9.2) for p could be solved for v(p). But
since v is a root of the cubic Eq. (9.3), one would have to write analytical expressions
for its three roots by using the cubic formula and then substitute into Eq. (9.30). This
would result in unwieldy expressions for g whose functional behavior would not be easy to
analyze. A much more useful procedure is to regard Eqs. (9.30) and (9.2) to be a parametric
representation3 of g(T, p), with v as a parameter. This can be done by assigning a ﬁxed
value to T and then allowing v to range through a set of numerical values. For each
numerical value of v, one can calculate a pair of numerical values of g −f0(T) and p,
and ultimately construct a graph of g versus p, such as shown in Figure 9–7a. Note that
3A parametric representation is a very powerful way of representing a function, especially if it is multiple
valued. A simple example would be the ellipse x2/a2 + y2/b2 = 1 which can be represented parametrically by
x = a cos ψ and y = b sin ψ, where ψ is a parameter that ranges from 0 to 2π as the ellipse is traversed once in the
counterclockwise direction. Powerful software packages, such as ParametricPlot of Mathematica R⃝, can be used
to construct plots of such functions with ease.

132
THERMAL PHYSICS
g
p0
p
A
B
C
D
E
F
G
(a)
p
p0
v
G
F
E
D
C
B
(b)
FIGURE 9–7 (a) Isotherms in the p, g plane for two temperatures below Tc, one at Tc and one above Tc. The labeled
curve is for the lowest temperature, T/Tc = 27/32. (b) Isotherms in the v, p plane for temperatures corresponding
to those in (a). The isotherm with labeled points is for T/Tc = 27/32 . The dashed curve is the spinodal. Point A is
outside the ﬁgure to the right on the labeled isotherm in (b). The segment AB is stable vapor, BC is metastable vapor,
CDE is unstable ﬂuid, EF is metastable liquid, and FG is stable liquid. The pressure p0 intersects the T/Tc = 27/32
isotherm at points F and B, corresponding to the miscibility gap, and also at point D on the unstable branch. Points
C and E lie along the spinodal curve.
there are three values of g for a range of p between the maximum and minimum values
of p that correspond to an isotherm in the p, v plane. These triple roots end at cusps of g
that correspond to points on the spinodal curve. Points along the curve EDC correspond
to unstable4 ﬂuid states inside the spinodal. Points along BC or EF represent metastable
states; they are outside the spinodal region but inside the miscibility gap (gap separating
stable phases, to be deﬁned more precisely in the following section). States along AB and
FG are stable and lie outside the boundary of the miscibility gap.
At constant T, dg = v dp, and since v > 0, the isotherms of g are monotonically
increasing functions of p. But for T < Tc, v is a multiple valued function of p, so the
corresponding isotherms of g have three monotonic branches that join as shown in Figure
9–7. For values of T ≥Tc, there is a single branch. For T ≫Tc, the isotherms begin to
resemble those for an ideal gas,
g(p, T) = RT ln(p/p0) + g(p0, T),
ideal gas,
(9.31)
where p0 is some reference pressure. For the van der Waals ﬂuid at any ﬁxed T, one
could integrate dg = v dp at constant T by parts, which would lead to the already-known
Eq. (9.30).
4We can draw this conclusion based on the fact that EDC in Figure 9–7a corresponds to the convex region of a
curve of f as a function of v for ﬁxed T. Note, however, that the curves ABC and EFG are concave. This is because
p is an intensive variable. By the methods of Chapter 7, we know that g is a convex function of p for an unstable
state but a concave function of p for an unstable state. Speciﬁcally, ∂2f /∂v2 = −1/∂2g/∂p2.

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
133
9.4.1 Maxwell Construction
A miscibility gap is a two-phase region that separates stable phases. For the van der Walls
ﬂuid, this gap separates stable liquid from stable vapor. A point within that miscibility gap
does not represent a homogeneous phase but instead a mixture of liquid and vapor in
proportions given by the lever rule discussed immediately above Eq. (9.27). A simple way
to determine the miscibility gap graphically is the equal area construction of Maxwell.
According to this construction, the horizontal line p = p0 that makes equal areas with
an isotherm in the v, p plane intersects that isotherm at the boundaries, v1 and v2, of the
miscibility gap, as illustrated in Figure 9–8. To prove this construction, we rewrite Eq. (9.13)
in the form
f (v, T) = −
 v
v0
p(T, v′) dv′ + f (v0, T),
(9.32)
where v0 is some reference molar volume and the function p(T, v) is given by Eq. (9.2). For
a ﬁxed pressure p0, equality of the molar Gibbs free energies at two different volumes, v1
and v2, that lie on the miscibility gap, gives
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
p/pc
p0/pc
v2/vc
v/vc
v1/vc
FIGURE 9–8 Maxwell’s equal area construction for determining the miscibility gap. The isotherms from top to
bottom are T/Tc = 32/30, 1, 30/32, 28/32. The dashed curve is the spinodal and the dotted curve is the miscibility
gap, computed numerically as discussed in the example problem. The dashed horizontal line at p0/pc illustrates
the equal-area construction for the lowest isotherm and the shorter horizontal line illustrates the equal area
construction for the next lowest isotherm.

134
THERMAL PHYSICS
−
 v1
v0
p(T, v) dv + f (v0, T) + p0v1 = −
 v2
v0
p(T, v) dv + f (v0, T) + p0v2.
(9.33)
After canceling f (v0, T), Eq. (9.33) can be rewritten in the form
 v2
v1
p(T, v) dv −p0(v2 −v1) = 0,
(9.34)
where we shall take v2 > v1 to correspond to Figure 9–8. But p0(v1−v2) =
 v2
v1 p0 dv because
p0 is a constant, so Eq. (9.34) becomes
 v2
v1
[p(T, v) −p0] dv = 0.
(9.35)
In Eq. (9.35), regions of integration where p(T, v) > p0 give positive contributions whereas
regions where p(T, v) < p0 give negative contributions. If p0 is chosen to satisfy Eq. (9.35),
the areas between the p(T, v) curve and p0 will be equal. This proves the Maxwell
construction which holds for the van der Waals ﬂuid.
However, the
Maxwell construction holds generally for any ﬂuid for which the
isotherms in the v, p plane have the qualitative features of the van der Waals ﬂuid.
This can be seen in a simple way from Fermi’s observation [1, p. 71] that the reversible
work W done by the system in a cyclic reversible isothermal process is zero. That
observation follows from the fact that Eq. (3.28) (which is the same as Eq. (3.33) for a
reversible cycle) holds for such a process and T can be taken outside the integral to give

δQ = 0, which requires Q = 0. But for a cyclic process, U = 0, so by the ﬁrst law,
W = 0. Thus
	
p dv = W = 0.
(9.36)
One can therefore integrate from one side of the miscibility gap to the other side along
the curve p(v, T) and then return to the ﬁrst side along the line p = p0, thus proving the
Maxwell construction generally.
Example Problem 9.2. Although the Maxwell construction allows one to visualize the mis-
cibility gap, it does not provide an accurate quantitative determination. Solve simultaneously
Eqs. (9.28) and (9.29) to determine the miscibility gap and discuss the relationship of pressure
to temperature on the miscibility gap.
Solution 9.2. This can only be done numerically because of the transcendental form of
Eq. (9.29). Rather than choosing speciﬁc values of the constants a and b, we introduce the
dimensionless variables t
= T/Tc, ν1
= v1/vc, and ν2
= v2/vc and the corresponding
dimensionless pressure y = p/pc. The equivalent dimensionless equations are
8t
3ν1 −1 −3
ν2
1
=
8t
3ν2 −1 −3
ν2
2
= y
(9.37)
and

Chapter 9 • Two-Phase Equilibrium for a van der Waals Fluid
135
−6
ν1
−8t
3 ln(3ν1 −1) +
8tν1
3ν1 −1 = −6
ν2
−8t
3 ln(3ν2 −1) +
8tν2
3ν2 −1.
(9.38)
Forgetting about y for the moment, we specify a value of t which leads to two simultaneous
equations in ν1 and ν2 that can be solved numerically, for example by using a procedure such
as FindRoot in Mathematica R⃝. To do this, one must specify guesses for ν1 and ν2 which serve
as a starting point for an iterative procedure; the Maxwell construction is useful in this respect.
Then one can compute the value of y for that temperature and repeat the whole process for a
number of temperatures. The result is the dotted curve in Figure 9–8. Along the miscibility gap,
T is an increasing function of p so there will also be a miscibility gap in the v, T plane where the
corresponding spinodal curve will be given by Eq. (9.5), as illustrated in Figure 9–2.

This page intentionally left blank 

10
Binary Solutions
One commonly thinks of solutions as liquids, such as salt or sugar dissolved in water. In
thermodynamics, we regard a solution more generally as being a homogeneous phase
consisting of more than one chemical species, intermixed on an atomic scale, and thus
mutually soluble. Solutions can be solids, liquids, or gases, and can contain any number
of chemical components. Binary solutions consist of two chemical components, A and B,
which for simplicity we will refer to as atoms, even though they may actually be molecules
that do not dissociate. In a solution, chemical components can interact but cannot form
new molecules. A solution should not be confused with a mixture of more than one phase.
In this chapter we consider binary solutions and their phase equilibria. A given amount
of a solution of chemical components A and B can characterized by a set of state variables
consisting of the temperature T, the pressure p and the composition that can be expressed
by one of the mole fractions, say XB. Although vapor phases could be considered, we
shall conﬁne ourselves to the important case of condensed phases (solids and liquids) for
which the thermodynamic functions, in particular the Gibbs free energy g per mole, are
insensitive to the pressure except for very large applied pressures of many atmospheres.
This is true because ∂g/∂p = v, the molar volume, which is quite small relative to that of
a gaseous phase. Therefore, the problem reduces to one in which g effectively depends on
only two important variables, T and XB, similar to the case of monocomponent systems
for which the molar Helmholtz free energy f depends on only the two variables T and
v. As a result, we will be able to analyze two-phase equilibria in terms of a common
tangent construction and a chord construction, analogous to those for monocomponent
systems. We will illustrate our treatment with simple models, namely ideal solutions and
so-called regular solutions, recognizing that the subject of binary phase diagrams for real
materials is huge and quite complex. The interested reader is referred to the materials
science literature for a thorough analysis of real systems.
10.1 Thermodynamics of Binary Solutions
We consider a binary solution made up of chemical components A and B. The internal
energy U of such a solution is a function of the entropy S, the volume V, and the mole
numbers NA and NB. Its differential is
dU = T dS −p dV + μA dNA + μB dNB,
(10.1)
where T is the temperature, p is the pressure, μA is the chemical potential of component
A and μB is the chemical potential of component B. U = ˜U(S, V, NA, NB) is a fundamental
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00010-7
137
Copyright © 2015 Elsevier Inc. All rights reserved.

138
THERMAL PHYSICS
equation,1 so it contains complete information about the system. The Euler equation for
U is
U = TS −pV + μANA + μBNB
(10.2)
and the Gibbs-Duhem equation is
0 = S dT −V dp + NA dμA + NB dμB.
(10.3)
There are four equations of state, which give T, p, μA, and μB as functions of S, V, NA, and
NB. Thus
T = ˜T(S, V , NA, NB);
p = ˜p(S, V , NA, NB);
(10.4)
μA = ˜μA(S, V , NA, NB);
μB = ˜μB(S, V , NA, NB).
Note, however, that T, p, μA, and μB are intensive variables so they can only depend on the
ratios of the extensive variables S, V, NA, and NB, of which only three are independent.
A convenient way to make the reduction to three independent intensive variables is
to introduce the per mole quantities u := U/N, s := S/N, v := V/N, XA = NA/N, and
XB = NB/N. Since the mole fractions satisfy XA + XB = 1, we only need to keep one of
them, so we retain the three independent variables s, v, and XB. Then Eqs. (10.1)–(10.3)
become
du = T ds −p dv + (μB −μA) dXB;
(10.5)
u = Ts −pv + μA(1 −XB) + μBXB;
(10.6)
0 = s dT −v dp + (1 −XB) dμA + XB dμB.
(10.7)
The equations of state can be written
T = ˜T(s, v, XB);
p = ˜p(s, v, XB);
(10.8)
μA = ˜μA(s, v, XB);
μB = ˜μB(s, v, XB).
Since s, v, and XB are independent, it is possible to take partial derivatives with respect
to one of them while holding the other two constant. For example, from Eq. (10.5) we
obtain2
 ∂u
∂XB

s,v
= (μB −μA).
(10.9)
To obtain μA and μB separately, we would have to solve Eq. (10.9) simultaneously with
Eq. (10.6). The result is
μA = u −Ts + pv −XB
 ∂u
∂XB

s,v
;
μB = u −Ts + pv + (1 −XB)
 ∂u
∂XB

s,v
.
(10.10)
1Here, we use the more elaborate functional notation U = ˜U(S, V, NA, NB) to distinguish the value U from
its functional form ˜U. In cases where there is no confusion between these quantities, we use the abbreviated
functional notation U = U(S, V, NA, NB).
2Note well that XA is not held constant in this differentiation.

Chapter 10 • Binary Solutions
139
10.1.1 Molar Gibbs Free Energy
In working with binary solutions, we shall often be concerned with situations in which
T and p are speciﬁed and uniform throughout the system. The natural function to use
to discuss this situation is the Gibbs free energy G := U −TS + pV or the Gibbs free
energy per mole g := G/N = u −Ts + pv. This is because complete information about the
system is contained in the function G = ˜G(T, p, NA, NB) or, for one mole, in the function
g = ˜g(T, p, XB). Since g is related to u by Legendre transformations, we obtain
dg = −s dT + v dp + (μB −μA) dXB;
(10.11)
g = μA(1 −XB) + μBXB;
(10.12)
0 = s dT −v dp + (1 −XB) dμA + XB dμB,
(10.13)
and the equations of state
s = ˜s(T, p, XB);
v = ˜v(T, p, XB);
(10.14)
μA = ˜μA(T, p, XB);
μB = ˜μB(T, p, XB).
Note that Eq. (10.13) is the same as Eq. (10.7) but in Eqs. (10.12) and (10.13) the indepen-
dent variable set is T, p, and XB rather than s, v, and XB in Eqs. (10.5) and (10.6).
By partial differentiation of Eq. (10.11) we obtain
 ∂g
∂XB

T,p
= (μB −μA),
(10.15)
which resembles Eq. (10.9) except that g replaces u and the variables T and p are now held
constant in the differentiation. Simultaneous solution of Eqs. (10.15) and (10.12) gives
μA = g −XB
 ∂g
∂XB

T,p
;
μB = g + (1 −XB)
 ∂g
∂XB

T,p
.
(10.16)
10.1.2 Intercept and Common Tangent Constructions
Unlike Eq. (10.10), Eq. (10.16) contains the same function g and its partial derivative with
respect to XB, so these equations can be interpreted geometrically. This is illustrated in
Figure 10–1a from which it can be seen that μA is just the intercept at XB = 0 of the tangent
to a graph of g versus XB at constant T and p. Similarly, μB is the intercept at XB = 1 of
that same tangent. As the point of tangency slides along the curve, one obtains from the
intercepts of the tangent an appreciation for μA and μB as a function of the value of XB at
the point of tangency. This procedure is known as the method of intercepts.3
3This famous construction, known as the method of intercepts, works for the molar value y := Y/N of any
extensive function Y = ˜Y (T, p, NA, NB). The partial derivatives ¯YA := (∂Y/∂NA)T,p,NB and ¯YB := (∂Y/∂NB)T,p,NA,
which are analogous to the chemical potentials, are known as partial molar values of Y. ¯YA and ¯YB are then
given by the intercepts to the tangent of a graph of y as a function of XB for ﬁxed T and p. In fact, the method
can be generalized to multicomponent systems for which the relevant intercepts are those of tangent planes or
hyperplanes. See Section 5.6.1 for more detail.

140
THERMAL PHYSICS
0.0
1.0
XB
XB
∗
g
μA
μB
(a)
0.
1
0
.0
XB
β
XB
α
XB
g
μA
μB
α
β
(b)
FIGURE 10–1 (a) Sketch of g(T, p, XB), in arbitrary units, as a function of XB for ﬁxed T and p illustrating the method
of intercepts. The XB = 0 and XB = 1 intercepts of the tangent give the values of μA and μB, respectively, at the
point of tangency X∗
B. (b) Common tangent construction. The chemical potentials of each component are equal for
α and β phases having compositions Xα
B and Xβ
B at points of common tangency. The α phase is stable for XB < Xα
B
and the β phase is stable for XB > Xβ
B. The region Xα
B < XB < Xβ
B is a miscibility gap.
From Figure 10–1b, we note that the graph of g versus XB is not convex, as will be the
case when an unstable phase and more than one stable phase are involved.4 In such a
case, the common tangent intersects the curve at values of XB that satisfy
μA(T, p, Xα
B ) = μA(T, p, Xβ
B );
μB(T, p, Xα
B ) = μB(T, p, Xβ
B ),
common tangent,
(10.17)
where Xα
B and Xβ
B are the values of XB at which common tangency occurs. This common
tangent construction solves the equilibrium problem for phases of a binary system. It is
the analog of the common tangent construction for the molar Helmholtz free energy, f ,
treated in Chapter 9. The α phase is stable for XB < Xα
B and the β phase5 is stable for
XB > Xβ
B . The region Xα
B < XB < Xβ
B is a miscibility gap where no homogeneous phase
is stable; it is a two-phase region where a mixture of α with composition Xα
B and β with
composition Xβ
B is globally stable.
Example Problem 10.1. Show that the values of XB that correspond to a common tangent
construction of a non-convex g, such as depicted in Figure 10–1b, are unchanged if a linear
function of XB is added to g.
Solution 10.1. For the function g(x), the values of XB subtended by a common tangent are
solutions to the simultaneous equations
4In Chapter 7 we showed for stability that the extensive Gibbs free energy G must be a convex function of
each of its extensive variables. For a binary solution we could regard G to depend on the variable set T, p, NB, N,
so with N constant, g = G/N must be a convex function of XB = NB/N for stability.
5The fact that the present g-curve is continuous and has a continuous derivative implies that there is not a
change of structure as XB increases from 0 to 1. Therefore, one could rename the β phase α′ since it only differs
from α by composition. If there were a change in structure, there could be two separate curves that cross.

Chapter 10 • Binary Solutions
141
g′(x) = g′(y);
g(x) −xg′(x) = g(y) −yg′(y),
(10.18)
where the prime denotes differentiation and ﬁxed values of p and T have been suppressed. Let
˜g(x) = g(x) + ax + b where a and b are constants. Then
˜g′(x) = g′(x) + a;
˜g(x) −x˜g′(x) = g(x) −xg′(x) + b.
(10.19)
Therefore, if ˜g is substituted for g in Eq. (10.18), the constants a and b cancel. This happens
because a straight line is its own common tangent.
10.1.3 Chord Construction
We also have a chord construction for a binary system. Consider a composite system
consisting of one mole and made up of a mole fraction f1 of material having composition
XB1 and a mole fraction f2 of material having composition XB2. Suppose that the total
composite has X∗
B moles of component B, where XB1 ≤X∗
B ≤XB2. This requires f1 + f2 = 1
and f1XB1 + f2XB2 = X∗
B. The fractions f1 and f2 are therefore given by the lever rule:
f1 = XB2 −X∗
B
XB2 −XB1
;
f2 = X∗
B −XB1
XB2 −XB1
;
lever rule.
(10.20)
The molar Gibbs free energy of the composite is
gc = f1 g(T, p, XB1) + f2 g(T, p, XB2)
= g(T, p, XB1) + XB2 −X∗
B
XB2 −XB1
[g(T, p, XB1) −g(T, p, XB2)].
(10.21)
From Eq. (10.21), we see that gc lies on the chord connecting g(T, p, XB1) with g(T, p, XB2)
on a graph of g versus XB at ﬁxed T and p, as illustrated in Figure 10–2a. Since that chord
is below the curve, the homogeneous state with g(T, p, X∗
B) is unstable with respect to the
composite, which has lower energy gc. If a chord is above the curve, the homogeneous
states below it are at least locally stable. They are only globally stable if they lie outside
the common tangent chord BE. A state that is locally stable but globally unstable is said
to be metastable and can exist for signiﬁcant periods of time if kinetics of nucleation of a
new phase are slow. Thus, the g-curve can be divided into stable, metastable, and unstable
regions, as illustrated in Figure 10–2b. The situation is similar to the analysis of f (T, v) as
a function of v for ﬁxed T, but there are some differences. For one thing, the phase rule
for a binary system allows up to four phases to coexist at equilibrium, not just three as
for a monocomponent system. Second, we now have three independent variables, rather
than two. As a consequence, one often conﬁnes analysis of condensed binary systems to
atmospheric pressure and studies phase stability as T and XB are varied. Such a procedure
is fairly general because condensed phases have sufﬁciently small molar volumes and
are practically incompressible, resulting in a very weak dependence of g on pressure.
For gaseous phases, which have relatively large molar volumes that are approximately
inversely proportional to pressure at constant temperature, the dependence of g on
pressure is large and cannot be ignored.

142
THERMAL PHYSICS
XB2
XB1 XB
∗
g
gc
μA
μB
B
E
(a)
1.0
A
B
C
D
E
F
XB
g
μA
μB
α
β
(b)
1.0
0.0
0.0
FIGURE 10–2 (a) Graph of g versus XB at ﬁxed T and p illustrating the chord construction. The energy gc of a
composite system having compositions XB1 and XB2 lies along the chord where it intersects the composition X∗
B
and is lower than g(T, p, X∗
B) of homogeneous material, which is unstable. The chord to the left of one point B
of common tangency lies above the curve, so the states below it are stable. The chord near the other point E of
common tangency lies above the curve, so the states below it are locally stable, but those to the left of E are only
metastable because a composite along BE would have lower energy. (b) C and D are points of inﬂection where
∂2g/∂X2
B = 0. Branch AB is stable phase α, BC is metastable α, CD is an unstable branch, DE is metastable β and EF is
stable phase β.
10.2 Ideal Solutions
We shall ﬁrst give a brief description of an ideal binary solution from the point of view of
elementary statistical mechanics.6 Let NA be the number of moles of A, NB the number of
moles of B, and N = NA + NB the total number of moles. We could equally well describe
the system in terms of the numbers, NA and NB, of atoms of A and B, respectively, and
N = NA + NB the total number of atoms. This latter description relates better to statistical
mechanics, which we can see in the following way. Suppose we have an ideal solution, in
which A and B atoms are mixed but do not interact chemically. The number of ways that
we can arrange these atoms is
 =
N!
NA!NB!.
(10.22)
According to Eq. (3.77), this leads to an entropy of mixing
Sideal = kB ln
N!
NA!NB! ∼kB[N ln N −NA ln NA −NB ln NB],
(10.23)
where Stirling’s approximation ln N ∼N ln N −N, valid for large numbers, has been
used.7 The symbol  is used here to remind us that this entropy is in addition to the
entropy of the same number of A and B atoms in their undissolved states. By introducing
6For a detailed treatment of the ideal entropy of mixing, see Section 16.5.1.
7See Appendix A.

Chapter 10 • Binary Solutions
143
the mole (or atom) fractions XA = NA/N = NA/N and XB = NB/N = NB/N, Eq. (10.2)
becomes
Sideal = −NkB[XA ln XA + XB ln XB] = −NR[XA ln XA + XB ln XB],
(10.24)
which is known as the ideal entropy of mixing.
In terms of extensive variables, Eq. (10.24) can be written in the form
Sideal = −R

NA ln(NA/N) + NB ln(NB/N)

,
(10.25)
which could be taken as a deﬁnition, irrespective of its derivation from statistical mechan-
ics. An ideal solution is one in which Sideal is the only entropy in addition to that of the
undissolved components, and for which the enthalpy of mixing H, also known as the
“heat of mixing,” is zero. This requires that there be no chemical interaction between the
components A and B. Thus
Hideal = 0.
(10.26)
If there is chemical interaction in addition to mechanical mixing of A and B, H ̸= 0 and
the solution is not ideal. We shall deal with a model of such a solution in Section 10.4.
The entire Gibbs free energy of an ideal solution is therefore
G = NAμ0
A(T, p) + NBμ0
B(T, p) −TSideal
(10.27)
= NAμ0
A(T, p) + NBμ0
B(T, p) + RT

NA ln(NA/N) + NB ln(NB/N)

,
where μ0
A(T, p) = gA(T, p) is the Gibbs free energy per mole of pure A and μ0
B(T, p) =
gB(T, p) is the Gibbs free energy per mole of pure B.8 The chemical potentials are
μA =
 ∂G
∂NA

T,p,NB
= μ0
A(T, p) + RT ln(NA/N),
(10.28)
μB =
 ∂G
∂NB

T,p,NA
= μ0
B(T, p) + RT ln(NB/N).
(10.29)
For any Gibbs free energy, we have
∂(G/T)
∂(1/T)

p,NA,NB
= H,
(10.30)
which can be proven by noting that G/T = H/T −S and carrying out the required
differentiation. Applying Eq. (10.30) to Eq. (10.27) shows that Sideal does not contribute
to H, consistent with Eq. (10.26), so we obtain
H = NA

∂(μ0
A/T)
∂(1/T)

p,NA,NB
+ NB

∂(μ0
B/T)
∂(1/T)

p,NA,NB
= NAhA + NBhB,
(10.31)
where hA and hB are the molar enthalpies of A and B, respectively.
8The chemical potentials μ0
A(T, p) and μ0
B(T, p) refer to so-called “reference states” which we have chosen to
be pure A and pure B, respectively. One can also make solutions whose constituents are molecules, such as AB or
AB2, or even by combining other solutions. For a general discussion, see Lupis [5, pp. 179-184].

144
THERMAL PHYSICS
On a per mole basis, the ideal entropy of mixing is
sideal = −R

XA ln XA + XB ln XB

= −R

(1 −XB) ln(1 −XB) + XB ln XB

(10.32)
and the corresponding molar Gibbs free energy is
g = (1 −XB)μ0
A(T, p) + XBμ0
B(T, p) + RT

(1 −XB) ln(1 −XB) + XB ln XB

.
(10.33)
Figure 10–3a shows a plot of g as a function of XB. We could obtain the chemical
potentials graphically from the method of intercepts. We could also use the analytic
formulae Eq. (10.16), which are the basis of the common tangent construction, to obtain
μA = μ0
A(T, p) + RT ln(1 −XB);
μB = μ0
B(T, p) + RT ln XB.
(10.34)
The chemical potentials in Eq. (10.34) are the same as in Eqs. (10.28) and (10.29) except for
notation. Note that μB = −∞for XB = 0. This can be traced back to the fact that Sideal
has an inﬁnite slope at NB = 0. More precisely, the ﬁrst member on the right-hand side of
Eq. (10.23) shows that Sideal = 0 for NB = 0 and Sideal = kB ln N for NB = 1. Its slope at
NB = 0 is therefore kB ln N which is actually ﬁnite but diverges logarithmically as N →∞
in the thermodynamic limit. Similarly, μA = −∞for XB = 1.
From Figure 10–3a we see that g is a convex function of XB, so there is a stable
homogeneous phase for every value of XB; in other words, there is a complete range of
mutual solubility. In particular, such a homogeneous solution is stable with respect to
phase separation to a composite state. At temperatures for which pure A and pure B are
both crystalline solids, they can only form solid solutions for all XB if they have the same
crystal structure. Examples are silicon and germanium (Si, Ge) which are both diamond
cubic, or nickel and copper (Ni, Cu) which are both face centered cubic. The solid solutions
of these pairs of elements formed by substituting one atom for the other on the same
crystalline lattice are ideal solutions to a ﬁrst approximation. Similarly, if T is above the
melting points of both pure A and pure B, one could possibly have an ideal liquid.
0.
1
0
.0
XB
0.6
g
μA
0
μA
μB
0
μB
(a)
0.
1
0
.0
XB
0.6
0.0
Δg
ΔμA
ΔμB
(b)
FIGURE 10–3 (a) Plot of g versus XB for an ideal solution according to Eq. (10.33). The chemical potentials of the
pure components are μ0
A and μ0
B. At XB = 0.6, intercepts of the tangent give the chemical potentials μA and μB.
(b) Plot of g versus XB for an ideal solution according to Eq. (10.35). At XB = 0.6, intercepts of the tangent give
the chemical potential differences μA = μA −μ0
A and μB = μB −μ0
B.

Chapter 10 • Binary Solutions
145
It is often convenient to eliminate consideration of unmixed constituents by deﬁning
g := g −(1 −XB)μ0
A(T, p) −XBμ0
B(T, p) = RT

(1 −XB) ln(1 −XB) + XB ln XB

.
(10.35)
Figure 10–3b shows a plot of g as a function of XB. Its minimum value occurs for XB = 0.5
and has the value −RT ln 2 = −0.693RT. Applying the method of intercepts to g gives the
chemical potential differences μA = μA −μ0
A and μB = μB −μ0
B.
10.3 Phase Diagram for an Ideal Solid and an Ideal Liquid
As we have seen above, g or g for an ideal binary solution is a convex function of XB,
and this could happen either below or above the melting points of the pure components.
The interesting question is: What happens for temperatures between the melting points
of the pure elements? For example, Si melts at 1685 K and Ge melts at 1210.4 K. Moreover,
Ni melts at 1736 K and Cu melts at 1356.5 K.
The answer is that there is a miscibility gap and phase separation into a composite,
part solid and part liquid. We analyze this situation as an application of the ideal solution
model, and arbitrarily take A to be the component having the higher melting point, TA.
Thus TA > TB, where TB is the melting point of pure B. For the ideal liquid, we have
μL
A = μ0L
A (T, p) + RT ln(1 −XB);
μL
B = μ0L
B (T, p) + RT ln XB,
(10.36)
and for the ideal solid
μS
A = μ0S
A (T, p) + RT ln(1 −XB);
μS
B = μ0S
B (T, p) + RT ln XB,
(10.37)
where the superscripts L and S denoting liquid and solid have been added to Eq. (10.34).
For a temperature T that satisﬁes TA > T > TB, we know that μ0L
A (T, p) > μ0S
A (T, p) and
μ0L
B (T, p) < μ0S
B (T, p). Therefore, graphs of gL = μL
A(1 −XB) + μL
BXB and gS = μS
A(1 −XB) +
μS
BXB result in two curves that cross, as shown in Figure 10–4. By applying the common
μ0L
A
μ0S
A
μS
A = μL
A
gS
gL
μ0S
B
μ0L
B
μS
B = μL
B
0.
1
0
.0
XL
B
XS
B
FIGURE 10–4 Curves of gL for an ideal liquid solution and gS for an ideal solid solution versus XB for a temperature
T between the melting points of pure A and pure B. The common tangent construction applies, with tangency at
XS
B and XL
B. As the temperature changes, the curves shift, resulting in a change of the points of common tangency.

146
THERMAL PHYSICS
tangent construction to Figure 10–4, we see that there is a miscibility gap for XS
B < XB < XL
B.
Here, XS
B and XL
B are the compositions at which common tangency occurs for the value of
T corresponding to the ﬁgure. As T varies, these curves shift and we can trace out the
miscibility gap in the XB, T plane. The result is a “lens type” binary phase diagram, such as
plotted in Figure 10–5.
10.3.1 Equations for the Miscibility Gap
Equations to determine the values of XS
B and XL
B that correspond to the boundary of the
miscibility gap in the XB, T plane can be determined by equating chemical potentials:
μL
A(T, p, XL
B) = μS
A(T, p, XS
B);
μL
B(T, p, XL
B) = μS
B(T, p, XS
B).
(10.38)
Substitution of Eqs. (10.36) and (10.37) into Eq. (10.38) gives:
μ0L
A (T, p) −μ0S
A (T, p) = RT ln

1 −XS
B
1 −XL
B

;
μ0L
B (T, p) −μ0S
B (T, p) = RT ln

XS
B
XL
B

.
(10.39)
In order to proceed further, we need a model to evaluate the chemical potential differences
on the left of Eq. (10.39). We write these in the forms
μA : = μ0L
A (T, p) −μ0S
A (T, p) = hA −TsA;
μB : = μ0L
B (T, p) −μ0S
B (T, p) = hB −TsB,
(10.40)
where hA and hB are enthalpy differences (liquid minus solid) and sA and sB are the
corresponding entropy differences. We assume as an approximation that these enthalpy
and entropy differences are constants that we relate by requiring μA = 0 at T = TA and
μB = 0 at T = TB. This gives hA = TAsA and hB = TBsB, so Eqs. 10.40 become
approximately
μA = hA(1 −T/TA);
μB = hB(1 −T/TB).
(10.41)
We recognize hA and hB as the respective latent heats of fusion per mole and observe
that Eqs. (10.41) have the expected algebraic signs, that is, μA > 0 and μB < 0 for
TA > T > TB. An alternative view of Eqs. (10.41) is to assume that they are the leading
terms in expansions in the variables (T −TA)/TA and (T −TB)/TB.
Substitution of Eqs. (10.41) into Eqs. (10.39) shows that XS
B < XL
B as expected and
1 −XL
B
1 −XS
B
= exp

−hA
R
 1
T −1
TA
	
≡EA(T);
XS
B
XL
B
= exp
hB
R
 1
T −1
TB
	
≡EB(T).
(10.42)
For TA > T > TB, we note that 0 < EA(T) < 1 and 0 < EB(T) < 1. Solving Eq. (10.42) for XS
B
and XL
B gives

Chapter 10 • Binary Solutions
147
0.0
0.2
0.4
0.6
0.8
1.0
1200 K
1400 K
1600 K
TA
Solid (crystal)
Liquid
XS
B (T)
XL
B (T )
S + L
XB
TB
FIGURE 10–5 Computed phase diagram for an ideal solid solution and an ideal liquid solution for physical constants
that resemble A = Si and B = Ge. The plot shows XS
B and XL
B as functions of T according to Eq. (10.43). TA = 1685K
and TB = 1210.4 K.
XS
B = EB(T)
1 −EA(T)
1 −EA(T)EB(T);
XL
B =
1 −EA(T)
1 −EA(T)EB(T).
(10.43)
We observe from Eq. (10.43) that XS
B and XL
B increase from 0 to 1 with XS
B ≤XL
B as T
decreases from TA to TB.
In order to make a plot of Eq. (10.43) we need some numerical values of the physical
constants. If A were Si and B were Ge, then hA/(RTA) = 3.59 and hB/(RTB) = 3.14.
Figure 10–5 shows a plot of the resulting phase diagram. There is a miscibility gap with
a “lens shape” connecting the melting points of pure A and B. Above the miscibility gap,
the liquid solution is stable, and below it the solid solution is stable. The curve XS
B(T) is
called the solidus and XL
B(T) is called the liquidus. For a point within the miscibility gap, a
homogeneous solution is unstable, so the corresponding equilibrium state is a composite,
consisting of part liquid solution and part solid solution. The amounts of solid and liquid
in this composite are governed by the lever rule.
Example Problem 10.2. For the phase diagram depicted in Figure 10–5, what is the mole
fraction of solid in equilibrium with liquid at T = 1600 K if the overall composition is XB = 0.22
mole fraction? By how much does the chemical potential of A in this solid differ from that of
pure solid A at T = 1600 K?

148
THERMAL PHYSICS
Solution 10.2. At T = 1600K, the compositions at the solidus and liquidus are estimated to be
0.13 and 0.28.By the lever rule, the mole fraction of solid is (0.28−0.22)/(0.28−0.13) = 0.4. From
the ﬁrst of Eqs. (10.37) we obtain μS
A −μ0S
A = RT ln(1 −XB) = 3200ln(1 −0.13) = −456 cal/mol.
Example Problem 10.3. For a very dilute ideal solution XB ≪1, develop approximate
formulae for the distribution coefﬁcient k := XS
B/XL
B and the slope dXL
B/dT.
Solution 10.3. From the second of Eqs. (10.42) we can approximate T = TA to obtain k =
EB(TA) = constant < 1. Then we take the derivative of the ﬁrst of Eqs. (10.42) with respect to T
and evaluate the result at XS
B = XL
B = 0 and T = TA to obtain
d(XL
B −XS
B)
dT
= −hA
RT2
A
.
(10.44)
Then use of k to eliminate XS
B gives
dXL
B
dT = −
hA
(1 −k)RT2
A
.
(10.45)
This result is related to J. H. van’t Hoff’s law of freezing point lowering for a dilute solid solution
[22, p. 235]. Similar formulae can be obtained at the other end of the phase diagram for XA ≪1.
The results are k′ := XS
A/XL
A = 1/EA(TB) = constant > 1 and dXL
A/dT = hB/[(k′ −1)RT2
B].
10.4 Regular Solution
A so-called regular solution is a solution having an ideal entropy of mixing, but also a heat
of mixing of the form
Hreg = ˜ XAXB = ˜(1 −XB)XB,
(10.46)
where ˜ is a constant. In a quasichemical approximation [23], this heat of mixing arises
from interactions among A and B atoms in a mean ﬁeld approximation. If correlations
among atoms are neglected, the probabilities of AA, AB, and BB interactions are just the
terms on the right-hand side of the expression
1 = (XA + XB)2 = X2
A + 2XAXB + X2
B.
(10.47)
If EAA, EAB, and EBB are the respective interaction energies,9 then the energy of formation
of a solution of A and B from pure A and pure B is proportional to
EAAX2
A + 2EABXAXB + EBBX2
B −EAAXA −EBBXB = 2XAXB[EAB −(1/2)(EAA + EBB)].
(10.48)
To get the actual energy for N moles, we need to multiply by (1/2)Nz, where z is the
coordination number (number of signiﬁcant, probably nearest) of neighbors, which we
9These energies are negative for attraction and positive for repulsion. We deal here with condensed phases at
constant pressure, so the distinction between energy and enthalpy is not important.

Chapter 10 • Binary Solutions
149
0.
1
0
.0
−0.7
0.0
XB
Δg
(a)
0.
1
0
.0
−0.2
0.0
XB
Δg
(b)
FIGURE 10–6 Plots of g versus XB for a regular solution according to Eq. (10.51). (a) For RT/ω = −3/8, −1/2, −5/8
for top to bottom curves, there is relative attraction of A and B, and g is convex. (b) For RT/ω = 3/8, 1/2, 5/8 for
top to bottom curves, there is relative repulsion of A and B. g is convex at high T but develops a concave portion
at low T, resulting in a miscibility gap given by the common tangent construction. The critical temperature satisﬁes
RTc/ω = 1/2. Note the different vertical scales (units of |ω|). (a) g, regular solution attractive and (b) g, regular
solution repulsive.
assume to be the same for the pure components and the solution. The factor of (1/2) arises
to avoid double counting. This results in
˜ ≈Nz[EAB −(1/2)(EAA + EBB)].
(10.49)
The main thing we learn from Eq. (10.49) is that ˜ will be negative if A atoms are attracted
to B atoms more than these atoms are attracted to their own kind. Otherwise, there will be
net repulsion of A and B atoms, and ˜ will be positive. If ˜ is positive, we anticipate that a
miscibility gap will form at sufﬁciently low temperatures.
We therefore regard ˜ as an empirical parameter of the regular solution model and
proceed to analyze the thermodynamics. The total free energy of mixing is
G = Hreg −TSideal = ˜ XAXB + RT

NA ln(NA/N) + NB ln(NB/N)

.
(10.50)
For one mole, this becomes
g = ω XB(1 −XB) + RT

(1 −XB) ln(1 −XB) + XB ln XB

,
(10.51)
where ω := ˜/N is the value of the interaction parameter per mole.
Figure 10–6 shows some plots of g versus XB for a few temperatures and values of
ω. For ω < 0 (relative attraction of A and B) g is convex. In this case, A and B are
mutually soluble for all XB, just as for an ideal solution. For ω > 0 (relative repulsion of
A and B) g is convex at high T but develops a concave portion at low T. Therefore a
miscibility gap develops at sufﬁciently low T and its boundary is given by the common
tangent construction.
Within the miscibility gap is a spinodal curve, which is the locus in the XB, T plane of
the points where g changes from convex to concave. To compute the spinodal curve, we
solve

150
THERMAL PHYSICS
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
T/Tc
X
α
α
FIGURE 10–7 Miscibility gap boundary (solid curve) and spinodal curve (dashed curve) for a regular solution. For
T > Tc there is a stable solid phase α with a complete range of solid solubility. For T < Tc, the stable phases are α′
and α′′ which have the same crystal structure as α but different compositions. A point between the miscibility gap
and the spinodal curve represents either metastable α′ for XB < 1/2 or metastable α′′ for XB > 1/2. A point within
the spinodal curve represents an unstable phase. An unstable or metastable phase will eventually transform to a
composite consisting of α′ and α′′ phases that lie on the miscibility gap at the same temperature and in proportion
given by the lever rule.
∂2g
∂X2
B
= −2ω + RT
 1
XB
+
1
1 −XB

= 0,
(10.52)
which yields
XB(1 −XB) = RT/(2ω);
spinodal.
(10.53)
The maximum value of XB(1 −XB) is 1/4 and occurs at XB = 1/2. The top of the spinodal
curve occurs at the critical temperature
Tc = ω/(2R)
(10.54)
because for higher temperatures Eq. (10.53) has no allowable roots. From the form of
Eq. (10.53), we see that the spinodal curve is symmetric with respect to XB = 1/2. By
making the substitution XB = 1/2 −X we can write the equation of the spinodal in the
form
T/Tc = 1 −4X2,
(10.55)
which is a parabola that ranges from X = −1/2 to X = 1/2 with its maximum at T = Tc.
The spinodal is represented by the dashed curve in Figure 10–7.
To compute the boundary of the miscibility gap, we need the chemical potentials.
These can be obtained by differentiation of the extensive10 G given by Eq. (10.50) with
10Note that one must write ˜XAXB = ωNANB/(NA + NB) before performing the differentiation.

Chapter 10 • Binary Solutions
151
respect to NA and NB or by using the intensive g given by Eq. (10.51) and the method of
intercepts. The results are
μA −μ0
A(T, p) = RT ln(1 −XB) + ωX2
B;
μB −μ0
B(T, p) = RT ln XB + ω(1 −XB)2.
(10.56)
Note that by working with G or g rather than G or g, we get μA = μA −μ0
A(T, p) and
μB = μB −μ0
B(T, p). Equating chemical potentials for A and B at XB1 and XB2 gives
RT ln(1 −XB1) + ωX2
B1 = RT ln(1 −XB2) + ωX2
B2;
RT ln XB1 + ω(1 −XB1)2 = RT ln XB2 + ω(1 −XB2)2.
(10.57)
Solving Eq. 10.57 appears to be formidable at ﬁrst sight, but study of their symmetry
reveals that the boundary of the miscibility gap is symmetric with respect to XB = 1/2.
This can be demonstrated by making the substitutions XB1 = 1/2 −X and XB2 = 1/2 + X,
in which case they both become11
RT ln
1
2 + X

+ ω
1
2 −X
2
= RT ln
1
2 −X

+ ω
1
2 + X
2
.
(10.58)
Equation (10.58) can be rearranged to yield
ln

 1
2 + X
1
2 −X

= 4(Tc/T) X,
(10.59)
where Eq. (10.54) has been used. The function on the left-hand side of Eq. (10.59) is
sketched in Figure 10–8 along with three possibilities for the right-hand side. For T = Tc,
the full line is tangent to the curve at X = 0, which corresponds to the top of the miscibility
gap at XB = 1/2. For T > Tc there is just one root at X = 0 which corresponds to the stable
state XB = 1/2 on a convex g curve. For T < Tc there are two unequal roots, being of
equal magnitude but opposite sign, and corresponding to distinct values of XB1 and XB2
on the miscibility gap. The root at X = 0 for T < Tc corresponds to an unstable state
at XB = 1/2 on the upper curve of Figure 10–6b. Thus for T < Tc the equilibrium state
of the system is a composite consisting of one phase12 α′ having composition 1/2 −|X|
and another phase α′′ having composition 1/2 + |X|, where X is a root of Eq. (10.59). The
boundary of the resulting miscibility gap is shown in Figure 10–7.
Note from Figure 10–7 that the top of the miscibility gap is ﬂatter than the spinodal
curve. Expansion of Eq. (10.59) in powers of X shows for small X that
T
Tc
= 1 −(4/3)X2 −(64/45)X4 · · · ,
(10.60)
11A shorter determination of the miscibility gap can be made by noting from Figure 10–6b that the common
tangent has a slope of zero. Thus we could solve ∂2g/∂X2
B = 0 which would also lead to Eq. (10.59). We follow
a more general procedure, however, because other models of solutions do not have such high symmetry and the
slope of the common tangent is not zero.
12As mentioned above, the regular solution model only makes sense for solid phases if they have the same
crystal structure. When a miscibility gap develops, the phases in the equilibrium composite still have the same
crystal structure, but different composition. Hence we denote one by α′ and the other by α′′, reserving the
notation α and β for models in which different crystal structures occur. For systems having liquid miscibility
gaps, one usually uses L′ and L′′.

152
THERMAL PHYSICS
−0.4
−0.2
0.0
0.2
0.4
−4
−2
0
2
4
=
T < Tc
T > Tc
T    Tc
X
FIGURE 10–8 Plot of ln

1
2 + X

/

1
2 −X

versus X and comparison to 4(Tc/T) X. The full line is for T = Tc and is
tangent to the curve at X = 0, which corresponds to the top of the miscibility gap. For T > Tc, illustrated by the
line with large dashes for T = 2Tc, there is only a root at X = 0, which corresponds to a stable state on a convex g
curve. For T < Tc, illustrated by the line with small dashes for T = (2/3)Tc, Eq. (10.59) has two non-zero roots that
lie on the miscibility gap; its root at X = 0 corresponds to an unstable state at XB = 1/2.
which should be compared to Eq. (10.55). For the regular solution, the top of the miscibility
gap occurs at temperature Tc and composition XB = 1/2 and the ﬁrst three partial
derivatives of g with respect to XB are equal to zero there. This is not general, however,
because the vanishing of the ﬁrst derivative is only due to the symmetry of the regular
solution model.
For a general solution model, we know that the spinodal curve is the locus of the points
of inﬂection of g and is therefore given by
∂2g
∂X2
B
= 0.
(10.61)
At the top of the spinodal, two such inﬂection points coalesce, which requires
∂3g
∂X3
B
= 0.
(10.62)
Therefore, at the top of the miscibility gap, both the second and third partial deriva-
tives of g with respect to XB vanish simultaneously. This determines Tc and the
corresponding Xc. Since g differs from g only by a linear function of XB, Eqs. (10.61)
and (10.62) also hold if g is replaced by g.

Chapter 10 • Binary Solutions
153
10.5 General Binary Solutions
We have barely scratched the surface of the subject of binary solutions and their phase di-
agrams. In general, binary phase diagrams are much more complicated and display intri-
cate topologies including eutectics, peritectics, and the occurrence of several intermediate
phases. The interested reader is referred to Lupis [5, chapter VIII] for a very thorough
discussion of binary phase diagrams, with particular attention to their relationship to free
energy curves. The book by DeHoff [21] devotes several detailed chapters to this subject
and goes on to treat multicomponent solutions, which are of great practical importance
to the understanding of commercial alloys. Nevertheless we have covered all of the
essential physics and the most important constructions (method of intercepts, common
tangent, lever rule, chord construction) that allow analysis of more general models. For
a compendium of information about the phase diagrams of real materials, the reader is
referred to three volumes edited by Massalski [24].

This page intentionally left blank 

11
External Forces and Rotating
Coordinate Systems
In Chapter 6 we developed criteria for equilibrium of a thermodynamic system under vari-
ous conditions. In the absence of external forces, those criteria included the minimization
of the internal energy U for a system that does no work at constant entropy S and the
minimization of the Helmholtz free energy F for a system that does no work at constant
temperature, T. In this chapter, we generalize these equilibrium conditions to include
external forces, such as gravity and electromagnetic forces, that can exert body forces and
do work on a system.
At equilibrium, such systems will usually be inhomogeneous. For example, in the case
of gravity, the pressure, and the chemical potentials will be functions of position within
a sample.1 We shall restrict our development to conservative external forces that can be
derived from a potential function. Then the equilibrium conditions can be expressed
conveniently in terms of new potentials, such as gravitational chemical potentials and
electrochemical potentials that are uniform at equilibrium.
We examine in detail the equilibrium conditions for multicomponent ideal gases and
binary liquids in a uniform gravitational ﬁeld. Then we treat rotating systems by means
of a potential that relates to centrifugal force. Finally, we give a brief treatment of applied
electric ﬁelds.
11.1 Conditions for Equilibrium
We begin with the inequality Eq. (6.19) which we rewrite in the form
dU + δW < 0,
constant S, natural process, chemically closed,
(11.1)
where we have written a strict inequality to conﬁne our attention to actual processes that
are always natural and irreversible. This eliminates hypothetical reversible processes for
which there is really no driving force. To have equilibrium, all such natural irreversible
processes must be prevented. A state will therefore be in equilibrium if all virtual varia-
tions of the system, which we indicate by δ applied to U, violate Eq. (11.1), that is,
δU + δW ≥0,
constant S, chemically closed, all virtual variations.
(11.2)
1In this chapter, we make use of methods of the calculus of variations to treat inhomogeneous systems. This
subject is treated in many standard references, for example [25, p. 198] and [26, p. 164]. The main results, however,
can be appreciated and in many cases applied without a complete understanding of their derivation.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00011-9
155
Copyright © 2015 Elsevier Inc. All rights reserved.

156
THERMAL PHYSICS
By a virtual variation, we mean any imagined variation that is compatible with the
constraints of the system but does not necessarily satisfy the laws of thermodynamics.
If all virtual variations satisfy Eq. (11.2), they all violate the laws of thermodynamics, so no
natural irreversible processes are possible and the system is in equilibrium.
We next conﬁne ourselves to the case in which the only work is done against conser-
vative external forces. Thus, there exists a potential function  such that δW = δ and in
which the δ applied to  denotes a change in  due to a virtual variation, unlike the general
meaning of the symbol δW which means a small amount of work, not a change of work. We
shall assume that the overall volume of the system is constant. Our equilibrium criterion
Eq. (11.2) therefore becomes
δ(U + ) ≥0,
constant S and V, chemically closed, all virtual variations.
(11.3)
Although Eq. (11.3) is a valid criterion for equilibrium, it would be difﬁcult if not
impossible to realize it experimentally because one would have to devise a way to hold
the entropy constant. Theoretically, however, one can satisfy the constraint of constant
entropy by means of a Lagrange multiplier λ and consider virtual variations of the form
δ(U +  −λS), but we must also insure that the system is chemically closed. For simplicity
we ﬁrst forbid chemical reactions. Therefore, we also introduce additional Lagrange
multipliers λi for each chemical component and obtain
δ(U +  −λS −

i
λiNi) ≥0,
constant V , all virtual variations.
(11.4)
As is usual with Lagrange multipliers, we could choose λ and the λi later to satisfy the con-
straints of constant entropy and constant mole numbers.2 By following this methodology,
one ﬁnds, not surprisingly, that λ = T at equilibrium, so the absolute temperature of the
system is a constant.
An alternative approach is to assume at the outset that the system in question is in
contact with a heat reservoir having constant temperature T and that the system is main-
tained at temperature T throughout any process under consideration. Then returning to
Eq. (6.19) with Ts = T but allowing S to vary gives
dF + δW < 0,
constant T, natural process, chemically closed,
(11.5)
where F = U −TS is the Helmholtz free energy. Then if there exists a potential function
 such that the only work done is δW = δ, as discussed above, one can use Lagrange
multipliers λi to insure the chemical closure. This results in the equilibrium criterion
δ

F +  −

i
λiNi

≥0,
constant T and V , all virtual variations.
(11.6)
2We could equally well constrain the masses Mi of each chemical component since Mi = miNi, where mi are
molecular weights. This would change the values of the λi but not the fact that they are just constants. This is
often done when the force under consideration is due to gravity, which acts on the masses, and was preferred by
Gibbs [3, p. 144].

Chapter 11 • External Forces and Rotating Coordinate Systems
157
We proceed to illustrate the use of the equilibrium criteria, Eq. (11.4) or Eq. (11.6),
extensively for the case of gravitational forces and then discuss several other forces.
11.2 Uniform Gravitational Field
We ﬁrst consider the case of a uniform gravitational ﬁeld that exerts a constant downward
acceleration g per unit mass on any chemical species. We take the z axis of a cartesian
coordinate system to be vertically upward, “up” deﬁned as antiparallel to the acceleration
due to gravity. In that case,
 =

V
ρgz d3x + constant,
(11.7)
where ρ = 
i ρi is the local mass density and the integral is over the constant volume V
of the system. We use masses rather than moles to simplify the form of the potential for
gravity.3 The total internal energy, entropy, and masses of each species are given by
U =

V
uV d3x;
S =

V
sV d3x;
Mi =

V
ρi d3x,
(11.8)
where the internal energy density, entropy density, and mass densities are denoted by uV ,
sV , and ρi, respectively.
We treat a multicomponent ﬂuid for which duV is given by Eq. (5.64) except we use
partial densities ρi instead of the mole concentrations ci, resulting in
duV = T dsV +
κ

i=1
μm
i dρi.
(11.9)
Then the general equilibrium criterion Eq. (11.4) becomes
 
∂uV
∂sv
δsV +
κ

i=1
∂uV
∂ρi
δρi + gzδρ −λδsV −
κ

i=1
λm
i δρi

d3x ≥0.
(11.10)
By identifying the partial derivatives, using δρ = κ
i=1 δρi and grouping terms, Eq. (11.10)
becomes
 
(T −λ)δsV +
κ

i=1
(μm
i + gz −λm
i )δρi

d3x ≥0.
(11.11)
Then by requiring Eq. (11.11) to be true for all independent and arbitrary virtual variations
δsV and δρi, both positive and negative, the only possibility is for their coefﬁcients to be
zero. Thus we obtain the κ + 1 conditions
T = λ
(11.12)
3The corresponding chemical potentials μm
i
are per unit mass and are related to those per mole by
μm
i = μi/mi, where the mi are molecular weights. Consistent with this change, we use total masses Mi =
	
ρid3x
instead of total mole numbers Ni, so the Lagrange multipliers λm
i will have corresponding units.

158
THERMAL PHYSICS
and4
μm
i + gz = λm
i ;
i = 1, 2, . . . , κ.
(11.13)
Therefore, at equilibrium, the temperature is constant and uniform, as anticipated in the
discussion of Eq. (11.4), but the chemical potentials μm
i
of each chemical component
are no longer uniform. Instead, the quantities μm
i
+ gz, which are often referred to as
gravitational chemical potentials, are uniform. For this reason, the μm
i are often referred
to as intrinsic chemical potentials because they are the same as those in the absence of
external forces. Of course one could also incorporate the potential  with U to form a new
potential ˜U = U +  whose density would have a differential
d˜uV = T dsV +
κ

i=1
(μm
i + gz) dρi
(11.14)
in which the gravitational chemical potentials appear directly.
According to Eq. (11.13), values of the intrinsic chemical potentials will depend linearly
on z at equilibrium. Through the Gibbs-Duhem equation, we can relate this to a depen-
dence of the pressure on z. The Euler equation (see Eq. (5.43)) per unit volume can be
written
uV = TsV −p +
κ

i=1
μm
i ρi.
(11.15)
By taking the differential of Eq. (11.15) and subtracting Eq. (11.9), the required Gibbs-
Duhem equation is found to be
sV dT −dp +
κ

i=1
ρi dμm
i = 0.
(11.16)
However, we already know that the temperature is constant, so
dp =
κ

i=1
ρi dμm
i .
(11.17)
From Eq. (11.13), dμm
i = −g dz, so Eq. (11.17) yields
dp = −
κ

i=1
ρig dz = −ρg dz,
(11.18)
where the total density ρ depends on pressure and the local composition. Of course
Eq. (11.17) can be invoked on the basis of mechanical equilibrium by using the mechanical
interpretation of pressure, but here it arises naturally as a consequence of applying the
laws of thermodynamics. For a single component liquid with negligible compressibility, ρ
can often be treated as a constant and Eq. (11.18) can be integrated to give p = ρgz + p0,
4In terms of chemical potentials per mole, Eq. (11.13) would be μi + migz = λi.

Chapter 11 • External Forces and Rotating Coordinate Systems
159
where p0 is the pressure at z = 0. In the case of a single component ideal gas of molecular
weight m, ρ = mp/RT and Eq. (11.18) can be integrated to give
p = p0 exp

−mgz/RT

,
(11.19)
which is often called the law of atmospheres. Of course the atmosphere of the Earth is not
a single component ideal gas and its temperature is not uniform, so Eq. (11.19) would only
provide a crude approximation to the decrease of its pressure with height.
Had we used Eq. (11.6) at the outset, with T presumed to be imposed and uniform from
the start, we could use the differential
dfV =
κ

i=1
μm
i dρi
(11.20)
and obtain
  κ

i=1
(μm
i + gz −λm
i )δρi

d3x ≥0,
(11.21)
which for arbitrary δρi of either sign leads immediately to Eq. (11.13).
Example Problem 11.1. If a single chemical reaction is allowed, show that the conditions for
equilibrium in a uniform gravitational ﬁeld are the same as in the absence of such a reaction
but there is an additional condition for the reaction to be in equilibrium.
Solution 11.1. When a chemical reaction is allowed in a homogeneous system, the differential
of the number of moles of component i is given by combining Eqs. (5.120) and (5.123) to obtain
dNi = νi d ˜N +dNext
i
, where νi is the stoichiometric coefﬁcient for the reaction, d ˜N is the change
in the progress variable of the reaction, and dNext
i
is the number of moles of component i
that enter the system from its exterior. For an inhomogeneous system having constant volume,
we have
δNext
i
=

V
[δci −νiδ˜c] d3x,
(11.22)
where ci is the concentration of component i in moles per unit volume and ˜c is the progress
variable per unit volume. In order to assure chemical closure of our system, Eq. (11.4) must be
replaced by
δ(U +  −λS −

i
λiNext
i
) ≥0,
constant V , all virtual variations.
(11.23)
Given that the chemical reaction is expressed in terms of moles, it is expedient to express all
other quantities in terms of the ci instead of the ρi. For example, the density in Eq. (11.7) for 
should be replaced by ρ = κ
i mici. Thus Eq. (11.23) becomes
 
(T −λ)δsV +
κ

i=1
(μi + migz −λi)δci +
κ

i=1
λiνiδ˜c

d3x ≥0.
(11.24)

160
THERMAL PHYSICS
Arbitrary variation of sV gives Eq. (11.12) whereas arbitrary variation of ci gives μi + migz = λi,
which is the same as Eq. (11.13) divided by mi. Arbitrary variation of ˜c gives an additional
condition
0 =
κ

i=1
λiνi =
κ

i=1
[μi + migz]νi,
(11.25)
which is the condition for the chemical reaction to be in equilibrium. But since mass is con-
served in a chemical reaction, we have κ
i=1 miνi = 0, so Eq. (11.25) reduces to κ
i=1 μiνi = 0,
which is the same as obtained in Section 5.7 (and also later in Chapter 12, Eq. (12.29)) in
the absence of gravity. Nevertheless, the quantities μi + migz in Eq. (11.25) are uniform in
equilibrium, which shows clearly that the chemical reaction is in equilibrium at every height
z, even though each μi varies linearly with z.
11.2.1 Multicomponent Ideal Gas in Gravity
A multicomponent ideal gas is an ideal solution (see Section 10.2) of chemical compo-
nents, each of which obeys the ideal gas law, pi = niRT, where pi is the partial pressure
of gas i and ni is its concentration in moles per unit volume. Its total pressure is
p = κ
i=1 pi = NRT/V. By a Maxwell relation readily obtained from dG, one has
∂μi
∂p

T,{Ni}
= (∂V /∂Ni)T,p,{N′
i} = RT
p ,
(11.26)
where {Ni} denotes the entire set of mole numbers and {N′
i} denotes the same set with
Ni missing. If the Ni are constant, the compositions Xi are constant so we can integrate
Eq. (11.26) at constant composition and temperature to obtain
μi = RT ln p + w(T, {Xi}),
(11.27)
where w(T, {Xi}) is a function of integration. But the chemical potential of an ideal solution
has the form μi = μ0
i (p, T) + RT ln Xi, where Xi = Ni/N is the mole fraction of component
i. Therefore, this chemical potential has the form
μi = RT ln p + RT ln Xi + qi(T),
(11.28)
where qi(T) is a function of only the temperature. In fact, Denbigh [18, p. 115] takes
Eq. (11.28) to be the deﬁnition of an ideal gas mixture.
Since pi = pXi, Eq. (11.28) divided by the molecular weight mi gives
μm
i = RT
mi
ln pi + qm
i (T)
(11.29)
for the chemical potential per unit mass of an ideal gas. Here, qm
i (T) = qi(T)/mi. We take
its differential at constant T and substitute into the differential of Eq. (11.13) to obtain
RT
mi
ln dpi
pi
= −g dz.
(11.30)

Chapter 11 • External Forces and Rotating Coordinate Systems
161
Equation (11.30) can then be integrated to give
pi = pi0 exp(−migz/RT),
(11.31)
where pi0 is the partial pressure in the plane z = 0. The total pressure is therefore
p =
κ

i=1
pi0 exp(−migz/RT).
(11.32)
The composition at z is given by
Xi = pi
p =
pi0 exp(−migz/RT)
κ
j=1 pj0 exp(−mjgz/RT).
(11.33)
In terms of the composition Xi0 = pi0/p0, where p0 is the pressure in the plane z = 0,
Eq. (11.33) can be written in the form5
Xi =
Xi0 exp(−migz/RT)
κ
j=1 Xj0 exp(−mjgz/RT)
(11.34)
and the total pressure can therefore be written
p = p0
κ

i=1
Xi0 exp(−migz/RT).
(11.35)
Equation (11.32) should be compared to the simple result Eq. (11.19) for the monocom-
ponent ideal gas. The molar density is given by n = p/(RT) but the total mass density is a
little more complicated because
ρ =
κ

i=1
mini = n
κ

i=1
miXi = p0
RT
κ

i=1
miXi0 exp(−migz/RT).
(11.36)
The reader is invited to verify that Eq. (11.18) is satisﬁed.
Although Eq. (11.34) correctly describes the gravitational segregation of the chemical
components of an ideal gas that have different molecular weights, it has been expressed
in terms of composition in the plane z = 0. If the overall mole numbers Ni00 of a sample
were known, one would have to integrate ni = pi/(RT) over z with due respect to the
dependence of cross sectional area A(z) on z and solve to determine the quantities Xi0.
For a sample of height H, this gives
Ni00 = p0
RT
 H
0
A(z)Xi0 exp(−migz/RT) dz.
(11.37)
If A(z) is independent of z, it may be factored out and the integral performed to yield
Ni00 = Ap0Xi0
mig

1 −exp(−migH/RT)

.
(11.38)
5For future reference, we remark that the structure of Eq. (11.34) is exactly what one would expect from
the canonical ensemble of statistical mechanics (see Chapters 18 and 19) in which case the denominator is
analogous to a canonical partition function for degenerate states.

162
THERMAL PHYSICS
Then by using κ
i=1 Xi0 = 1, we can solve for the pressure in the plane z = 0 to obtain
p0 = 1
A
κ

i=1
miNi00 g

1 −exp(−migH/RT)
.
(11.39)
This expression for p0 can be substituted into Eq. (11.38) to obtain
Xi0 =
miNi00

1 −exp(−migH/RT)

⎧
⎨
⎩
κ

j=1
mjNj00

1 −exp(−mjgH/RT)

⎫
⎬
⎭
−1
.
(11.40)
Then by substitution of Eqs. (11.39) and (11.40) into Eqs. (11.34) and (11.35), one can
determine exactly the composition and the pressure as a function of z.
For samples of laboratory size, however, it is important to recognize that the effect
of gravitational segregation on gases is extremely small. For example, for H = 1 m and
T = 300 K one has gH/RT = 3.93 × 10−3 mol/kg. Thus for N2 (mi = 28 g/mol) and O2
(mi = 32 g/mol) one would have migH/RT equal to 1.1×10−4 and 1.26×10−4, respectively.
Even for a heavy gas such as uranium hexaﬂuoride UF6 (mi = 352 g/mol) one would have
migH/RT = 1.4 × 10−3. Therefore, for samples of laboratory size, one has migH/RT ≪1
and the above expressions for ideal gases can be expanded in these small quantities. If
we keep only linear terms in migH/RT and migz/RT, the pressure and the compositions
become linear functions of z. The results can be written in terms of a few new symbols: the
total number of moles N00 := κ
i=1 Ni00, the total mass M00 := κ
i=1 miNi00, the average
molecular weight ¯m = M00/N00, and the volume of the system V = AH. Then some algebra
yields
p ≈N00RT
V
+ M00g
A
1
2 −z
H

= N00RT
V

1 + ¯mgH
RT
1
2 −z
H

;
(11.41)
Xi ≈Ni00
N00

1 + (mi −¯m)gH
RT
1
2 −z
H

.
(11.42)
Equation (11.41) shows that the pressure, largest at the bottom and smallest at the top, is
equal to its value in the absence of gravity plus a linear correction related to the mass of the
gas. According to Eq. (11.42), the composition is given by the overall composition times a
linear function that either decreases or increases with height depending on whether the
molecular weight is smaller or larger than the average molecular weight.
11.2.2 Binary Liquid in Gravity
A binary liquid in a uniform gravitational ﬁeld will also undergo segregation of its A and
B species but the situation is different from that of a gas because a liquid is much denser
and comparatively incompressible. We carry out the calculation for an ideal solution for
which
μm
A = μm0
A (p, T) + RT
mA
ln XA;
(11.43)
μm
B = μm0
B (p, T) + RT
mB
ln XB,
(11.44)

Chapter 11 • External Forces and Rotating Coordinate Systems
163
where μm0
A (p, T) and μm0
B (p, T) correspond to standard states of pure A and B, respectively.
We substitute into Eq. (11.13) and identify the Lagrange multipliers by setting z = 0, where
we denote the pressure by p0 and the compositions by XA0 and XB0, to obtain
μm0
A (p, T) −μm0
A (p0, T) + RT
mA
ln(XA/XA0) + gz = 0;
(11.45)
μm0
B (p, T) −μm0
B (p0, T) + RT
mB
ln(XB/XB0) + gz = 0.
(11.46)
From the differential of the Gibbs free energy, we note that the partial speciﬁc volumes are
given by ∂μm
A /∂p = ∂μm0
A /∂p = 1/ρA and similarly for B. Although the quantities ρA and ρB
depend on p and T, the temperature T is constant and the dependence on p is very weak
because liquids have such small compressibilities. We shall therefore treat ρA and ρB as
constants in order to obtain a tractable problem. This results in
1
ρA
(p −p0) + RT
mA
ln(XA/XA0) + gz = 0;
(11.47)
1
ρB
(p −p0) + RT
mB
ln(XB/XB0) + gz = 0.
(11.48)
Since XB = 1 −XA we could solve Eqs. (11.47) and (11.48) simultaneously for XA and
p as functions of z but the results are cumbersome so we take advantage immediately of
the fact that mgz/RT is very small, where m characterizes mA or mB or the combination of
them given by Eq. (11.52). Thus we expand the logarithms to ﬁrst order to obtain the linear
equations
(p −p0) + ρART
mA
(XA −XA0)
XA0
+ ρAgz = 0;
(11.49)
(p −p0) −ρBRT
mB
(XA −XA0)
XB0
+ ρBgz = 0.
(11.50)
We then subtract to eliminate p −p0 and obtain
(XA −XA0)
 f
XA0
+ 1 −f
XB0

= −m∗gz
RT ,
(11.51)
where
f =
ρA/mA
ρA/mA + ρB/mB
;
m∗=
ρA −ρB
ρA/mA + ρB/mB
.
(11.52)
If ρA > ρB, we observe that XA decreases with increasing z as would be expected. Finally,
we can solve Eqs. (11.49) and (11.50) for p −p0 to obtain
p −p0 = −ρ∗gz,
(11.53)
where
ρ∗= ρAρB(mAXA0 + mBXB0)
ρAmBXB0 + ρBmAXA0
.
(11.54)

164
THERMAL PHYSICS
Thus the pressure always decreases linearly with height z, but the weighting of densities
is not obvious. Incidentally, if ρA = ρB, there is no segregation and the pressure increases
with ρ∗equal to their common density. As compared to a binary ideal gas, the magnitude
of the segregation is comparable but the magnitude of the pressure change is much larger
for the binary liquid because the effective density is much larger than for the gas.
11.3 Non-Uniform Gravitational Field
For a non-uniform gravitational ﬁeld, Eq. (11.7) can be written
 =

V
ρ ϕ(r) d3x + constant,
(11.55)
where ϕ(r) is the gravitational potential (potential energy per unit mass) at position r. For
example, the gravitational potential due to attraction by the Earth, whose center of mass
is assumed to be located at the origin, would be
ϕ(r) = −MG
r ,
(11.56)
where r = |r|, M is the mass of the Earth and G = 6.67 × 10−11 m3 kg−1 s−2 is the universal
gravitational constant. Since ϕ(r) is the same for all chemical species, Eq. (11.13) becomes
simply
μm
i + ϕ(r) = λm
i ;
i = 1, 2, . . . , κ.
(11.57)
Thus for the potential given by Eq. (11.56), Eq. (11.31) for the partial pressure of a
multicomponent gas would be replaced by
pi = pi0 exp

−miMG
RT
 1
r0
−1
r

,
(11.58)
where r is the distance to the center of gravity of the Earth and r0 is a reference distance
where the partial pressure is pi0. This result is not signiﬁcantly different from Eq. (11.31)
for a constant gravitational acceleration unless r varies by large distances compared to r0.
Indeed, for |(r −r0)/r0| ≪1, the effective gravitational acceleration would be g = MG/r2
0.
11.4 Rotating Systems
A system undergoing uniform rotation at an angular velocity ω about some axis behaves
as if it were in a non-uniform gravitational ﬁeld with potential (potential energy per unit
mass) ϕ = −r2
⊥ω2/2, where r⊥is the distance from the axis of rotation. This result follows
because the corresponding force per unit mass would be −dϕ/dr⊥= r⊥ω2 and would be
directed radially outward. This is just the centrifugal acceleration (centrifugal force per
unit mass) that is experienced in a rotating coordinate system. The work done by this
external force when a mass m moves from r⊥= 0 to r⊥is just

Chapter 11 • External Forces and Rotating Coordinate Systems
165
 r⊥
0
mr′
⊥ω2 dr′
⊥= mr2
⊥ω2/2 = −mϕ.
(11.59)
Thus Eq. (11.57) becomes
μm
i −r2
⊥ω2/2 = λm
i ;
i = 1, 2, . . . , κ.
(11.60)
For the partial pressure of a multicomponent ideal gas, one therefore obtains
pi = pi0 exp(mir2
⊥ω2/2RT),
(11.61)
which differs from Eq. (11.31) in two important ways: the exponential depends on the
square of the distance r⊥and ω2 can be quite large in the sense that r⊥ω2 ≫g. Thus, in
a fast centrifuge, the components of such a gas with sufﬁciently different mi can undergo
signiﬁcant segregation of components. To achieve signiﬁcant segregation of components
with only slightly different mi, such as isotopes, one would have to make r2
⊥ω2 as large as
practical and employ a multi-stage process wherein the enriched portion of each stage is
used as the starting sample for the next stage.
Example Problem 11.2. A circular cylinder with axis of symmetry along the z axis contains a
monocomponent liquid that is practically incompressible and therefore has constant density
ρ. The cylinder is rotated at constant angular velocity ω. The liquid is also in a constant
gravitational ﬁeld g directed downward, antiparallel to z. Find the pressure of the liquid as a
function of position in the cylinder. Determine the shape of the isobars and comment on the
shape of the upper free surface of the liquid if it is open to the atmosphere and evaporation is
negligible.
Solution 11.2. The governing equation for the chemical potential is
μm −(x2 + y2)ω2/2 + gz = λm.
(11.62)
By taking x = y = z = 0, we identify λm as the chemical potential at the origin where we take
the pressure to be p0. Then by integration of Eq. (11.17) for a single component and constant ρ,
we obtain μm −λm = (p −p0)/ρ. Thus, Eq. (11.62) becomes
p −p0 = ρ

(x2 + y2)ω2/2 −gz

.
(11.63)
The isobars satisfy
z = ω2
2g (x2 + y2) + p0 −p
ρ
(11.64)
and each has the shape of a parabola of revolution whose lowest point is along the axis of
rotation. The upper free surface of the liquid will also have this parabolic shape with p = 1
atmosphere to the extent that capillary effects (see Chapter 13) are negligible.

166
THERMAL PHYSICS
11.5 Electric Fields
We consider a single phase multicomponent ﬂuid in the presence of an electric ﬁeld
E = −∇φ, where φ(r) is the electrical potential. If species i carries an electric charge
zi|e|, the work done by the ﬁeld in moving that charge from a reference position r0 to
position r is
 r
r0
zi|e|E · dr = zi|e|[φ(r0) −φ(r)] = −W.
(11.65)
In electrochemistry, zi is regarded to be the valence of each species. For convenience we
take the reference potential φ(r0) = 0 in which case the total potential of Eq. (11.6) can be
written in the form
 =

V

i
zi|e|φ(r)NAci d3x =

V

i
ziφ(r)Fci d3x,
(11.66)
where ci is the concentration of species i in moles per unit volume, NA is Avogadro’s
number and F = |e|NA = 96,485 coulomb/mol is the Faraday constant. Then Eq. (11.21)
can be replaced by

V

i
[μi + ziφ(r)F −λi] δci d3x ≥0
(11.67)
which leads to the equilibrium equations
μi + ziφ(r)F = λi.
(11.68)
In this case we see that the electrochemical potentials μi + ziφ(r)F are uniform at
equilibrium. It is often convenient to use the chemical potential per atom (or molecule)
instead of per mole. If we designate this quantity by μa
i , the equilibrium equations can be
written in the form
μa
i + qiφ(r) = λa
i ,
(11.69)
where qi is the charge carried by species i.
When dealing with heterogeneous equilibrium among phases of various composition,
a word of caution is in order because relative electrical potentials can become ill-deﬁned
due to surface potentials and different chemical environments that a test charge encoun-
ters when entering a material from inﬁnity, where the potential is taken to be zero. For a
discussion of the equilibrium for transfer between phases, see Denbigh [18, p. 86].

12
Chemical Reactions
We regard chemical reactions to be the formation or dissociation of chemical molecules
or compounds in which no chemical elements are created or destroyed. In other words,
we exclude nuclear reactions in which new nuclei can form and during which there
is a change m0 in the rest mass m0, resulting in a change of energy given by the
Einstein relation E = m0c2 where c is the speed of light. By excluding nuclear reactions,
both mass and energy are separately conserved during chemical reactions and the ﬁrst
law of thermodynamics, which embodies the conservation of energy, applies in the
form presented in Chapter 2 for a chemically closed system. Therefore, if a chemical
reaction occurs in an isolated system, the change in internal energy from initial to
ﬁnal state ifU := Uf −Ui = 0.1 Microscopically this makes sense because the internal
energy consists of kinetic energy and potential energy associated with chemical bonds
or intermolecular forces. The making or breaking of chemical bonds during chemical
reactions in an isolated system involves a redistribution of kinetic and potential energy,
but no net change of energy.
As in Section 5.7 where we brieﬂy introduced chemical reactions, we break dNi into two
parts, dNi = dintNi + dextNi, where dintNi is due to chemical reactions and dextNi is due to
exchanges with the environment. We write a chemical reaction in the symbolic form

i
νiAi = 0,
(12.1)
where the Ai are chemical symbols and the νi are stoichiometric coefﬁcients that are
positive for products (on the right-hand side of the reaction equation) and negative for
reactants (on the left-hand side of the reaction equation); see Eq. (5.121) and the related
example. Then if ˜N is the progress variable for the reaction, we will have2
dNint
i
= νi d ˜N.
(12.2)
Here, ˜N has the dimensions of moles; it is zero when the reaction begins and ˜Nﬁnal
when the reaction ends. In this chapter, we consider only chemically closed systems, so
dextNi = 0 and dNi = dNint
i
.
1In this section we add subscripts to quantities such as ifU and ifH to emphasize that these symbols
denote the change from initial to ﬁnal states. This is to avoid confusion with the standard notation for such
quantities as H in Eq. (12.13), which is actually a derivative of H with respect to the progress variable ˜N.
2The generalization to multiple chemical reactions is straightforward. One needs only to add a superscript s
to both quantities on the right hand-side and sum to obtain dintNi = 
s νs
i d ˜Ns.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00012-0
167
Copyright © 2015 Elsevier Inc. All rights reserved.

168
THERMAL PHYSICS
12.1 Reactions at Constant Volume or Pressure
Chemical reactions are typically carried out either at constant volume or at constant
pressure. Those involving gases can usually be carried out easily at constant volume
because the gases can be contained in a strong and nearly inert solid container. Then the
work W = 0, so the change in internal energy of the gases is
ifU = Q,
constant volume, chemically closed,
(12.3)
where the heat Q is positive if added to the gases and negative if extracted from the
gases. If the reaction vessel is thermally insulated, the reaction will result in a change of
temperature that can be measured. For example, a bomb calorimeter is a rigid vessel
with a known heat capacity Ccal that is large compared to the heat capacity of the gases
undergoing reaction. Typically it is ﬁlled with oxygen at high pressure and some fuel that
is burned to completion during the reaction. If the calorimeter is well insulated from its
surroundings and its temperature changes by ifT, then Q = −CifT, where C is the heat
capacity of the calorimeter and the gases. To extent that the heat capacity of the gases can
be neglected, CcalifT represents the energy that is converted from chemical bond energy
as a result of the reaction.
Of great practical importance, however, are chemical reactions that are carried out such
that the only work done is against a constant external pressure pext. In such reactions, there
is a volume change ifV and there is no attempt to impose the constraint of constant
volume, which might be very difﬁcult if only condensed phases are involved. Moreover,
the atmosphere might provide the constant external pressure in industrial reactions. The
work done by the system will then be W = pextifV and from the ﬁrst law we will have
ifU + pextifV = Q.
(12.4)
If the pressure p = pext in the initial and ﬁnal states of the system, we can introduce the
enthalpy H = U + pV in which case Eq. (12.4) takes the form
ifH = Q,
constant pressure, chemically closed,
(12.5)
where Q is the heat added to the reacting system. Thus the enthalpy H plays the same role
at constant pressure as the internal energy U plays at constant volume. In general, one can
regard the enthalpy to be a function of its natural variables, in which case
dH = T dS + V dp +

i
μi dNi.
(12.6)
However, for practical purposes it is more convenient to use the temperature instead of
the entropy, which results in
dH =
∂H
∂T

p,Ni
dT +
∂H
∂p

T,Ni
dp +

i
¯Hi dNi,
(12.7)

Chapter 12 • Chemical Reactions
169
where the quantities ¯Hi are the partial molar enthalpies. We recognize (∂H/∂T)p,Ni =
T(∂S/∂T)p,Ni = Cp as the heat capacity at constant pressure. Furthermore, regarding S
to depend on T, p, Ni, we readily establish that ¯Hi = μi −T ¯Si and

∂H/∂p

T,Ni = V +
T

∂S/∂p

T,Ni. A Maxwell relation based on the differential dG = −S dT + V dp + 
i μidNi
readily yields

∂S/∂p

T,Ni = −(∂V/∂T)p,Ni = −Vα, where α is the coefﬁcient of thermal
expansion. Thus Eq. (12.7) can be written
dH = Cp dT + V (1 −αT) dp +

i
¯Hi dNi.
(12.8)
For the chemically closed systems we are considering, Eq. (12.8) takes the form
dH = Cp dT + V (1 −αT) dp + (

i
νi ¯Hi) d ˜N.
(12.9)
Since T and p are intensive variables, the Euler equation for the enthalpy (see
Eq. (5.101)) is just
H =

i
Ni ¯Hi.
(12.10)
We emphasize that Eq. (12.10) holds as a function of p, T, and Ni, provided that the ¯Hi
are evaluated at p, T and the corresponding composition. At any stage of the reaction,
Ni = N0
i + νi ˜N, where N0
i is the initial value of Ni. The Euler equation (12.10) becomes
H(T, p, Ni) =

i
(N0
i + νi ˜N) ¯Hi,
(12.11)
where it is understood that the ¯Hi are to be evaluated at the corresponding composition,
temperature, and pressure.
Example Problem 12.1. For the chemical reaction given by Eq. (5.122), namely C+(1/2)O2 →
CO, assume initially that the mole numbers are N0
C = 3, N0
O2 = 1, and N0
CO = 2. If conditions
are such that the reaction goes to the right until one of the reactants is completely used, what
is the value of ˜Nﬁnal and how many moles of each component will there be? Answer the same
question under different conditions for which the reaction goes to the left until all of the CO is
used.
Solution 12.1. The stoichiometric coefﬁcients νi for C, O2, and CO are −1, −1/2, and 1,
respectively. For either the forward or backward reaction we have NC = 3−˜N, NO2 = 1−(1/2) ˜N,
and NCO = 2 + ˜N. The reaction can go to the right until ˜Nﬁnal = 2 =
˜Nmax in which case
NC = 1, NO2 = 0, and NCO = 3. The reaction can go to the left until ˜Nﬁnal = −1 =
˜Nmin in
which case NC = 4, NO2 = 3/2, and NCO = 0. The actual direction of the reaction and the extent
of reaction will depend on the conditions under which the reaction is carried out, particularly
the temperature. For conditions to be discussed below, the reaction may reach equilibrium at
some value ˜Nmin ≤˜Nﬁnal ≤˜Nmax.

170
THERMAL PHYSICS
12.1.1 Heat of Reaction
According to Eq. (12.5), the heat Qp = −Q liberated to the environment by the reacting
system at constant pressure p is given by
−Qp = H(Tﬁnal, p, N0
i + νi ˜Nﬁnal) −H(Tinitial, p, N0
i ).
(12.12)
But Qp is not a very useful way to characterize a reaction because it depends speciﬁcally
on the initial conditions. A much more useful quantity is the derivative of H with respect
to the progress variable ˜N at constant temperature and pressure, namely
H ≡−Q ˜N :=

i
νi ¯Hi =
∂H
∂˜N

T,p
.
(12.13)
This quantity is commonly called “the H of the reaction” but that is somewhat of a
misnomer because it is a derivative. In particular, H should not be confused with −Qp
for a speciﬁc reaction, which is the difference in enthalpy between ﬁnal and initial states
given by Eq. (12.12). Q ˜N = −H is the heat liberated by the reaction per unit change
of the progress variable at constant p and T. Callen [2, p. 170] refers to H as the heat of
reaction and suggests that it be evaluated near the equilibrium state; however, depending
on conditions, a speciﬁc reaction might go to completion before the equilibrium state
is reached. For Q ˜N
= −H > 0, the reaction is said to be exothermic whereas for
Q ˜N = −H < 0, the reaction is said to be endothermic.3 In Section 12.3 we will relate
H to the G of the reaction.
For the special but often treated case for which the reactants and the products are not
in solution, or if gaseous they form an ideal solution, one has ¯Hi = Hi(p, T), where Hi(p, T)
is the enthalpy per mole of the respective pure component. This follows for a solution of
ideal gases because the chemical potentials
μi(T, p, Xi) = μi(T, p) + RT ln Xi,
(12.14)
where μi(T, p) corresponds to the pure component and Xi is the mole fraction. Note that
the total pressure is p and the partial pressure is pi = pXi. Thus,
¯Hi = ∂(μi(T, p, Xi)/T)
∂(1/T)
= ∂(μi(T, p)/T)
∂(1/T)
= Hi(T, p),
(12.15)
so there is no heat of mixing for an ideal solution. Under these conditions, the initial
and ﬁnal states can be expressed in terms of heterogeneous components and Eq. (12.13)
becomes simply
H =

i
νiHi(T, p),
heterogeneous components,
(12.16)
for which there is extensive tabulation of data as discussed in the next section.
3Unfortunately, various authors use different terminology. Kondepudi and Prigogine [14, p. 53] associate the
quantity

∂U/∂˜N
	
T,V = 
i νi ¯Ui with endothermic and exothermic reactions. Lupis [5, p. 10] and Kondepudi
and Prigogine [14, p. 52] treat H for the case in which the constituents are not in solution.

Chapter 12 • Chemical Reactions
171
12.2 Standard States
We shall deﬁne the standard state of an element or compound to be its most stable
state at a pressure p0 = 101,325 Pa = 1 standard atmosphere and at the temperature
T of relevance.4 The enthalpy of one mole of an element or compound in its standard
state is denoted by H0(T, p0). However, we must remember that enthalpy, like energy,
is undeﬁned up to an additive constant. Thus for enthalpy, it is customary to tabulate
H0(T, p0) −H0(T0, p0) for elements and compounds as a function of temperature, where
T0 = 298.15 K = 25 ◦C. Here, the superscript 0 reminds us that the element or compound
is in its standard state at pressure p0 at both T and T0.
It follows that the H given by Eq. (12.16) for a heterogeneous reaction can be related to
H0(T, p0) =

i
νiH0
i (T, p0).
(12.17)
Note that
H0(T, p0) =
∂H
∂˜N

T,p0
,
all constituents in their standard states.
(12.18)
If two reactions are added to form a third reaction, H0(T, p0) is additive since it is a state
function. This was discovered empirically and is known as Hess’s law. A quantity that is
tabulated extensively is
H0(T0, p0) =

i
νiH0
i (T0, p0),
(12.19)
which is the value of H0 at both standard temperature T0 and pressure p0. It follows that
H0(T, p0) = H0(T0, p0) +

i
νi[H0
i (T, p0) −H0
i (T0, p0)].
(12.20)
The quantity H0(T0, p0) is especially valuable because for many reactions, the gases in
the reaction behave approximately as ideal gases in an ideal solution (even though they
react occasionally due to collisions) so the partial molar quantities ¯Hi are very nearly equal
to the molar values Hi(T, p) for pure constituents (see Eq. (12.15)). Second, for ideal gases,
α = 1/T, so the term V(1 −αT) in Eq. (12.8) vanishes, and would be expected to be
small even for real gases. For heterogeneous solids and liquids that are not in solution,
we again have ¯Hi = Hi(T, p) and the dependence on pressure is weak because now the
molar volume Vi in the term Vi(1 −αiT) is small. Therefore, for such reactions,
H0(T0, p) =

i
νiHi(T0, p) ≈

i
νiHi(T0, p0) = H0(T0, p0).
(12.21)
4For gases, the standard state is usually deﬁned as the state in which the fugacity is equal to the pressure p,
as p →0, which would make a small difference if the gas did not behave like an ideal gas at p0. Other deﬁnitions
of standard states, such as solutions of a speciﬁed concentration, are sometimes used. We could also deﬁne a
standard state to be the most stable state of the pure constituent at temperature T and pressure p.

172
THERMAL PHYSICS
Of course one could correct for the small difference due to pressure if compressibility data
were available. If heat capacity data are known, the difference in heat capacity between
reactants and products is
Cp =

i
νi Cpi,
(12.22)
where the Cpi are heat capacities at constant pressure of the pure reactants and products.
Then
H0(T, p) ≈H0(T0, p0) +

 T
T0
Cp dT.
(12.23)
12.2.1 Heat of Formation
The enthalpy required to produce one mole of a compound from its elements at temper-
ature T, everything in its standard state at pressure p0, is called the heat of formation
and is designated by H0
f (T, p0). Since elements cannot be created by chemical reaction,5 it
follows that the heat of formation of an element is zero. Moreover,
H0(T, p0) =

i
νiH0
f (T, p0).
(12.24)
Note in the sum that the only contribution comes from compounds.
Example Problem 12.2. The heats of formation H0
f at T0 = 298.15K of H2O, CO2, and CO
are −285.8 kJ/mol, −393.5 kJ/mol, and −110 kJ/mol, respectively. Discuss the relevant chemical
reactions. Then compute H0(T0, p0) for the reaction
H2(gas) + CO2(gas) →CO(gas) + H2O(liquid).
(12.25)
Solution 12.2. The relevant reactions for compound formation are:
H2(gas) + (1/2)O2(gas) →H2O(liquid),
C(graphite) + O2(gas) →CO2(gas),
C(graphite) + (1/2)O2(gas) →CO(gas).
For the reaction given by Eq. (12.25), we have
H0(T0, p0) = (−285.8 −110 + 393.5) kJ/mol = −2 kJ/mol.
(12.26)
Note the sign change for CO2 because it is a reactant in Eq. (12.25).
5Recall that nuclear reactions are excluded. If 2 moles of deuterium react to form one mole of 3He and a
neutron, about 3 × 108 kJ/mol are released. Heats of formation of most chemical compounds are typically only
several hundred kJ/mol.

Chapter 12 • Chemical Reactions
173
12.3 Equilibrium and Afﬁnity
We now examine the conditions under which a chemical reaction is in equilibrium and the
direction that the reaction will proceed if it is not in equilibrium. For a multicomponent
system, the differential of the Gibbs free energy (see Eq. (5.90)) is
dG = −S dT + V dp +

i
μi dNi.
(12.27)
As before, we assume that dNi = dintNi + dextNi, that the system is chemically closed so
that dextNi = 0, and that dNi = dintNi = νid ˜N due to chemical reaction, as in Eq. (12.2).
Then6
dG = −S dT + V dp + (

i
νiμi) d ˜N.
(12.28)
For a chemically closed system at constant p and T, we know that G is a minimum at
equilibrium. Therefore, the criterion for equilibrium of a chemical reaction is
 ∂G
∂˜N

p,T
=

i
νiμi = 0.
(12.29)
The notations
G ≡−A :=

i
νiμi =
 ∂G
∂˜N

p,T
(12.30)
are common. A is called the afﬁnity7 of the reaction and is usually used in irreversible
thermodynamics. The other notation, “the G of the reaction” is somewhat of a misnomer
because it is really a derivative of G with respect to the progress variable ˜N and should not
be confused with the actual change in G from beginning to end of the reaction, which
depends on the initial values N0
i and the extent of reaction, possibly limited because of
the depletion of some component. The change in the Gibbs free energy for a small change
in ˜N at constant p and T is therefore
(dG)T,p = G d ˜N = −A d ˜N ≤0,
(12.31)
where the inequality holds for a natural irreversible process. Thus if G < 0 (A > 0) the
reaction will proceed to the right and for G > 0 (A < 0) the reaction will proceed to the
left. For G = −A = 0, which corresponds to a minimum of G, the reaction will be in
equilibrium. See Figure 12–1 for a sketch of G and A near equilibrium. Equilibrium can
6Eq. (12.27) implies that G is a function of T, p and the Ni in the ﬁeld of equilibrium states. If a chemical
reaction can occur, the system will not be in an equilibrium state but we can imagine, for thermodynamic
purposes, that the reaction proceeds slowly through a set of constrained equilibrium states. It is generally
assumed that Eq. (12.28) is valid for small deviations from equilibrium. The same assumption was implicit in
Eq. (12.9).
7We use a calligraphic symbol A to avoid confusion with A which in some books is used to denote the
Helmholtz free energy, which we denote by F. The name “afﬁnity” is due to T. De Donder, who founded the
Belgian school of thermodynamics [14, p. 104].

174
THERMAL PHYSICS
G
Geq
˜Neq
˜N
A
0
˜Neq
˜N
FIGURE 12–1 Sketches of the Gibbs free energy G and the afﬁnity A as a function of the progress variable ˜N near
its equilibrium value ˜Neq. At a given value of ˜N, the afﬁnity is the negative of the slope of G. If G is nearly parabolic
near its minimum value Geq, the afﬁnity A will be nearly linear. Equilibrium will occur at ˜Neq provided that the
initial values N0
i of the constituents of the reaction are such that ˜Nmin ≤˜Neq ≤˜Nmax. Otherwise, the reaction will
proceed in the direction of ˜Neq but will stop when ˜Nmin or ˜Nmax is reached.
occur at the value of ˜N = ˜Neq that satisﬁes Eq. (12.29). In an actual situation, equilibrium
at this minimum value of G will be achieved provided that the values of the initial mole
numbers N0
i are such that ˜Nmin ≤
˜Neq ≤
˜Nmax. Otherwise the reaction will come to
equilibrium at the lowest value of G subject to the constraint that no mole numbers can
be negative. Note that the positive quantity ˜Nmax occurs if one of the reactants goes to zero
and the negative quantity ˜Nmin occurs if one of the products becomes zero. See Example
Problem 12.2 for a speciﬁc reaction.
The role of the afﬁnity A can be better understood in terms of entropy production in a
chemically closed system. For the case of reversible work, δW = p dV and reversible heat
ﬂow, Tr = T, Eq. (5.127) applies, so
dS = δQ
T −

i
νiμi d ˜N = δQ
T + A
T d ˜N > 0
(12.32)
for a natural irreversible process. Then according to irreversible thermodynamics, one
writes dS = dextS + dintS, where dextS = δQ/T is the entropy exchanged reversibly with
the environment and dintS > 0 applies to an internal irreversible process. This leads to an
entropy production due to chemical reaction given by
dintS = A
T d ˜N > 0,
natural irreversible process.
(12.33)
Again, A > 0 leads to reaction to the right (d ˜N > 0) whereas A < 0 leads to reaction to the
left (d ˜N < 0). Equilibrium requires prevention of a natural irreversible process for both
possible signs of d ˜N, which requires A = 0.
We can relate G =

∂G/∂˜N
	
T,p of a reaction to H =

∂H/∂˜N
	
T,p that pertains to
the heat of reaction by regarding G, H, and S to be functions of T, p, and ˜N. Then by taking

∂/∂˜N
	
T,p of G = H −TS, we verify that G = H −TS, where S =

∂S/∂˜N
	
T,p. Hence
we have the relations
H =
∂(G/T)
∂(1/T)

p, ˜N
= G −T
∂G
∂T

p, ˜N
;
S = −
∂G
∂T

p, ˜N
.
(12.34)

Chapter 12 • Chemical Reactions
175
Note that Sd ˜N = (∂A/∂T) d ˜N is not the same as dintS = A/T d ˜N. This arises because
dS = Cp dT −V α dp + S d ˜N,
(12.35)
whereas (see Eq. (12.32))
dS = dU/T + (p/T) dV + (A/T) d ˜N,
(12.36)
so different variables are held constant when ˜N changes in these expressions.
12.4 Explicit Equilibrium Conditions
Explicit conditions for equilibrium can be obtained by referring the chemical potentials to
standard states for pure elements or compounds. For the standard state at p0, T discussed
in Section 12.2, one may express a chemical potential in the form
μi = μ0
i (T, p) + RT ln ai = μ0
i (T, p0) + [μ0
i (T, p) −μ0
i (T, p0)] + RT ln ai,
(12.37)
where ai is a dimensionless quantity called the activity. In general, μi(T, p, X) and
ai(T, p, X) depend on temperature, pressure, and composition which we symbolize by
the vector X. The quantities μ0
i (T, p) and μ0
i (T, p0) are the chemical potentials of the
pure component i for the most stable phase at the given temperature and pressures.8
The activity ai = 1 in the standard state μ0
i (T, p).9 Thus, ai accounts primarily for the
dependence of the chemical potential on composition.
For the pure component i, whether solid, liquid, or gas, we deﬁne a dimensionless
quantity that we call the fugacity ratio10
˜fi(T, p, p0) := exp{[μ0
i (T, p) −μ0
i (T, p0)]/RT}.
(12.38)
Thus Eq. (12.37) can be written in the form
μi(T, p, X) = μ0
i (T, p0) + RT ln[˜fi(T, p, p0)ai(T, p, X)].
(12.39)
In general,

∂μ0
i (T, p)
∂p

T
= V 0
i (T, p),
(12.40)
8There could possibly be a phase change between p0 and p in which case the chemical potential will be a
continuous function of pressure but its pressure derivative will be discontinuous at the pressure at which the
phase change takes place.
9Some authors, such as Kondepudi and Prigogine [14, p. 235], refer the activity to the state μ0(T, p0). Here we
follow Lupis [5, p. 108] and refer the activity to the state μ0(T, p). One can also employ standard states in which
some constituents are in solution.
10Note that Eq. (12.38) does not deﬁne a fugacity itself. We take this approach because the standard state for
the fugacity of a gas is deﬁned to be a state for which the pressure goes to zero; however, for a condensed phase
(solid or liquid) it is a state at pressure p0. In terms of individual fugacities fi, deﬁned in Section 5.4, one would
have ˜fi(T, p, p0) = fi(T, p)/fi(T, p0).

176
THERMAL PHYSICS
where V 0
i (T, p) is the molar volume in the standard state. Thus
μ0
i (T, p) −μ0
i (T, p0) =

 p
p0
V 0
i (T, p′) dp′.
(12.41)
For condensed phases (solids and liquids), usually pV 0
i /RT ≪1 in the range of integration
so ˜fi(T, p, p0) ≈1 and the dependence on pressure is unimportant. For an ideal gas, one
has V 0
i (T, p)/RT = 1/p so
˜fi(T, p, p0) = p/p0
(12.42)
and there is considerable dependence on pressure. See Section 5.4 for a more complete
discussion of fugacities for real gases and condensed phases. Unless one is dealing with
very large pressure differences |p −p0|, the quantity |μ0
i (T, p) −μ0
i (T, p0)|/RT is small
and usually negligible for solids and liquids but is important and varies considerably
with pressure for gases. For condensed phases, usually ˜fiai ≈ai and the dependence on
pressure is unimportant. If these condensed phases are not in solution, ai = 1 so ˜fiai ≈1.
For an ideal solution of ideal gases, ai = Xi, the mole fraction, so ˜fiai = Xip/p0 = pi/p0,
where pi := Xip is the partial pressure of gas i.
Substitution of Eq. (12.39) into the equilibrium condition Eq. (12.29) gives
G =

i
νiμ0
i (T, p0) + RT

i
νi ln[˜fi(T, p, p0)ai(T, p, X)] = 0.
(12.43)
The ﬁrst term
G0(T, p0) ≡

i
νiμ0
i (T, p0) ≡−RT ln K(T, p0)
(12.44)
refers to the standard states at pressure p0 and the dimensionless quantity K(T, p0) is
called the equilibrium constant.11 The second term in Eq. (12.43) can be rewritten in
the form
RT

i
νi ln[˜fi(T, p, p0)ai(T, p, X)] = RT ln

i
[˜fi(T, p, p0)ai(T, p, X)]νi.
(12.45)
The condition Eq. (12.43) for equilibrium becomes

i
[˜fi(T, p, p0)ai(T, p, X)]νi = K(T, p0).
(12.46)
The quantity on the left-hand side, often called the reaction product, can also be written12

i
[˜fi(T, p, p0)ai(T, p, X)]νi =
products
i
[˜fi(T, p, p0)ai(T, p, X)]νi
reactants
i
[˜fi(T, p, p0)ai(T, p, X)]|νi|
(12.47)
11Most authors would write just K(T) instead of K(T, p0) because p0 is ﬁxed at one atmosphere. We carry the
extra symbol p0 to remind ourselves of the standard state that has been used. Our equilibrium constant K(T, p0)
is dimensionless.
12Here, a product is on the right-hand side of the chemical equation and has a positive νi whereas a reactant
is on the left-hand side and has a negative νi.

Chapter 12 • Chemical Reactions
177
and is sometimes called the reaction quotient.
A parallel development can be made in terms of an equilibrium constant that depends
on p instead of p0. In that case, the equilibrium condition Eq. (12.43) is replaced by
G =

i
νiμ0
i (T, p) + RT

i
νi ln ai = 0.
(12.48)
Then one can deﬁne
G0(T, p) ≡

i
νiμ0
i (T, p) ≡−RT ln K(T, p)
(12.49)
and the condition for equilibrium becomes13

i
aνi
i = K(T, p).
(12.50)
12.4.1 Reactions among Gases
The molecules of ideal gases do not react chemically; however, if all reactants and products
are gases whose fugacities and activities can be approximated as if they were ideal gases,
we have ˜fiai ≈pi/p0, where pi is the partial pressure of gas i, and the equilibrium condition
Eq. (12.46) becomes

i
(pi/p0)νi =
products
i
(pi/p0)νi
reactants
i
(pi/p0)|νi| = K(T, p0).
(12.51)
In terms of mole fractions Xi, which are a measure of composition, Eq. (12.51) becomes

i
Xνi
i
=
products
i
Xνi
i
reactants
i
X|νi|
i
=
 p
p0
−
i νi
K(T, p0),
(12.52)
which exhibits the role of overall pressure on the reaction. This result also follows from
Eq. (12.50) by substitution of ai = Xi. We see in this case that
K(T, p) =
 p
p0
−
i νi
K(T, p0),
ideal gases.
(12.53)
For a given reaction, it follows that an increase in the overall pressure p will favor the
reaction if −
i νi > 0, meaning that the number of moles of reactant gases exceeds
the number of moles of product gases. If −
i νi < 0, an increase of pressure will favor
the reverse reaction. The reaction will be independent of pressure if 
i νi = 0.
13This equation illustrates clearly that the equilibrium condition does not depend on the value of p0. Other
conditions that appear to contain p0 are also independent of p0 but their individual parts depend on p0 because
data are tabulated at that pressure.

178
THERMAL PHYSICS
Example Problem 12.3. Discuss the dependence on overall pressure of the reactions
H2(gas) + CO2(gas)
→
CO(gas) + H2O(gas), CO(gas) + (1/2)O2(gas)
→
CO2(gas) and
A2(gas) →2A(gas).
Solution 12.3. For the ﬁrst reaction, νH2 = −1, νCO2 = −1, νCO = 1, and νH2O = 1, so
−
i νi = 0 and that reaction is independent of pressure. For the second reaction, νCO = −1,
νO2 = −1/2, and νCO2 = 1, so −
i νi = 1/2 and that reaction is favored by an increase in
pressure because K(T, p) =

p/p0
1/2 K(T, p0). For the third, νA2 = −1 and νA = 2 so K(T, p) =

p/p0
−1 K(T,p0). In this last case, we see that the dissociation of argon is impeded by a high
pressure, which can be thought of heuristically as a force tending to hold the argon molecule
together.
Example Problem 12.4. For the reaction H2(gas) + CO2(gas) →CO(gas) + H2O(gas), some
values of the equilibrium constant are K(1130K, 1 atm) = 1.0 and K(1500K, 1 atm) = 2.16.
Suppose initially that there is one mole of each gas. What will be the composition at equilibrium
at 1130 K and 1500K?
Solution 12.4. After the reaction has progressed by an amount ˜N, the numbers of moles of
each component will be NH2 = 1 −˜N, NCO2 = 1 −˜N, NCO = 1 + ˜N, and NH2O = 1 + ˜N so
Eq. (12.52) becomes
[(1 + ˜N)/4]2
[(1 −˜N)/4]2 = K(T, p0).
(12.54)
For K(1130K, 1 atm) = 1.0, the solution is ˜N = 0; the mole fraction of each gas is 0.25 and the
reaction was in equilibrium initially. For K(1500K, 1 atm) = 2.16, the solutions to Eq. (12.54) are
˜N = 0.19 and ˜N = 5.26 but the latter is unacceptable because it would lead to a negative value
of 1 −˜N, which would correspond to a negative value of NH2. Therefore, the composition at
equilibrium is XH2 = XCO2 = 0.20 and XCO = XH2O = 0.30.
In terms of concentrations [i] ≡Ni/V, one has pi = [i]RT and Eq. (12.51) becomes

i
[i]νi =
products
i
[i]νi
reactants
i
[i]|νi| =
RT
p0
−
i νi
K(T, p0) ≡Kc(T, p0),
(12.55)
where Kc(T, p0) is a new equilibrium constant that will not be dimensionless unless

i νi = 0.
Any of these forms for ideal gases, especially Eq. (12.55), are referred to as the law of
mass action. This follows because the rate of gaseous reactions depends on collisions and
the collision rate would be expected to depend on a product of concentrations. The rate of
forward reaction would be
Rf = kf (T, p0)
reactants

i
[i]|νi|,
(12.56)

Chapter 12 • Chemical Reactions
179
where kf (T, p0) is a constant of proportionality. Similarly, the rate of backward reaction
would be
Rb = kb(T, p0)
products

i
[i]νi.
(12.57)
At equilibrium, Rf = Rb leads to Eq. (12.55) with Kc(T, p0) = kf (T, p0)/kb(T, p0). This
relationship of thermodynamics to kinetics holds provided that the given reaction actually
proceeds by an elementary step involving the collisions embodied in Eqs. (12.56) and
(12.57). On the other hand, if the reaction actually takes place by means of a combination
of elementary steps, Kc(T, p0) can be related to the rate constants of all of these elemen-
tary steps. Nevertheless, the value of Kc(T, p0), since it is a thermodynamic quantity, is
independent of the details of the kinetics of the reaction. See Kondepudi and Prigogine
[14, p. 241] for further discussion of this point in terms of the principle of detailed balance.
12.4.2 Heterogeneous Solids and Liquids with Gases
Heterogeneous reactions constitute an important special case in which gases react with
immiscible solids and liquids. In this case, the activities of the liquids and solids are equal
to one. Moreover, as stated in connection with Eq. (12.41), we can neglect the dependence
of the chemical potentials of solids and liquids on the overall pressure p. Furthermore, if
the gases can be treated as ideal, one arrives at an equation similar to Eq. (12.52) except
the reaction product is only over the gases, that is,
gases

i
Xνi
i
=
 p
p0
−
i νi
K(T, p0).
(12.58)
This can also be written in terms of partial pressures in a form similar to Eq. (12.52),
namely
gases

i
(pi/p0)νi = K(T, p0).
(12.59)
Example Problem 12.5. For the reaction C(graphite) + O2(gas) →CO2(gas) one has
G0 = −394.4 kJ/mol, practically independent of temperature. The gas constant R = 8.314 J/mol.
What is the equilibrium constant K(T,p0) of this reaction? What is the composition of the gas
at equilibrium? What is the fraction of O2 at 1000 K?
Solution 12.5. We have
XCO2
XO2
= pCO2
pO2
= K(T, p0) = exp(−G0/RT)
(12.60)
with G0/R = −47,440 K. At 1000 K we would have
XO2
1 −XO2
= exp(−47.44) = 2.5 × 10−21,
(12.61)

180
THERMAL PHYSICS
so this is also practically the value of XO2. If only graphite and O2 were present initially, practi-
cally all of the oxygen would react to form CO2 if enough graphite were present. Otherwise, the
reaction would stop when all of the graphite is consumed.
12.4.3 Dependence of K(T, p0) on Temperature
We begin with Eq. (10.30), generalized to a multicomponent system, namely
∂(G/T)
∂(1/T)

p,Ni
= H
(12.62)
in which the Gibbs free energy G and the enthalpy H are expressed in terms of the variable
set T, p, Ni. This equation also holds for any chemical component in its standard state, and
therefore holds if G is replaced by the sum
G0(T, p0) ≡

i
νiμ0
i (T, p0)
(12.63)
and H is replaced by the sum
H0(T, p0) ≡

i
νiH0
i (T, p0).
(12.64)
We therefore obtain
∂(G0(T, p0)/T)
∂(1/T)
= H0(T, p0).
(12.65)
Since ∂/∂(1/T) = −T2∂/∂T, Eq. (12.65) can also be written
∂(G0(T, p0)/T)
∂T
= −H0(T, p0)
T2
.
(12.66)
Recalling the deﬁnition of K(T, p0) from Eq. (12.44), we obtain
∂ln K(T, p0)
∂T
= H0(T, p0)
RT2
,
(12.67)
which is known as the van’t Hoff equation.
Example Problem 12.6. For many chemical reactions, the quantity H0(T, p0) does not
depend strongly on T over a signiﬁcant temperature range and may be treated as a constant,
say H0
0. Determine the dependence of K(T, p0) on T under these circumstances. Discuss the
dependence on temperature for endothermic and exothermic reactions. What is the depen-
dence on temperature of G0(T, p0) in this case?
Solution 12.6. We integrate Eq. (12.67) from T0 to T to obtain
ln K(T, p0) = ln K(T0, p0) −H0
0
R
 1
T −1
T0

.
(12.68)

Chapter 12 • Chemical Reactions
181
Exponentiation gives
K(T, p0) = K(T0, p0)eH0
0/RT0 e−H0
0/RT,
(12.69)
so K increases strongly with temperature for an endothermic reaction H0
0 > 0 and decreases
strongly with temperature for an exothermic reaction H0
0
< 0. This type of exponential
dependence is said to be of Arrhenius form and H0
0 plays the role of an activation energy.
Integration of Eq. (12.65) for constant H0 gives
G0(T, p0)
T
= G0(T0, p0)
T0
+ H0
0
 1
T −1
T0

.
(12.70)
Multiplication by T and rearrangement gives
G0(T, p0) = H0
0 + T
T0
[G0(T0, p0) −H0
0(T0, p0)] = H0
0 −TS0(T0, p0).
(12.71)
We see in this case that G0(T, p0) is linear in T. In general, ∂G0(T, p0)/∂T = S0(T, p0)
so we see from differentiation of Eq. (12.71) with respect to T that S0(T, p0) = S0(T0, p0). In
other words, the standard entropy difference is also independent of T in this case.
Example Problem 12.7. For the formation of Cu2O, H0
f (T0, p0) = −168.6 kJ/mol and
G0
f (T0, p0) = −146.0 kJ/mol. For the formation of Al2O3, H0
f (T0, p0) = −1675.7kJ/mol
and G0
f (T0, p0) = −1582.3kJ/mol. In both cases, the metal and its oxide are solids, not in
solution, and the oxygen can be treated as an ideal gas. Write chemical equations for the
two reactions. Assume that H0(T, p0) can be treated as a constant equal to H0
f (T0, p0).
Determine the equilibrium constants K(T, p0) as a function of temperature and then determine
the equilibrium pressures of oxygen for each reaction at 1000 K.
Solution 12.7. The relevant reactions are 2Cu(solid) + (1/2)O2(gas) →Cu2O(solid) and
2Al(solid) + (3/2)O2(gas) →Al2O3(solid). From Eq. (12.71),
K(T, p0) = exp[(H0
f (T0, p0) −G0
f (T0, p0))/RT0] exp(−H0
f /RT).
(12.72)
For the oxidation of copper,
K(T, p0) = 1.098 × 10−4 exp(20,280 K/T),
(12.73)
so K(1000 K, p0) = 2.018 × 1010. From Eq. (12.59), we see that (pO2/p0)−1/2 = K, so we obtain
pO2 = 2002 × 10−10 atm.
For the oxidation of aluminum,
K(T, p0) = 4.326 × 10−17 exp(201,550 K/T),
(12.74)
so K(1000 K, p0) = 1.475 × 1071. For this reaction, (pO2/p0)−3/2 = K, so we obtain pO2 =
3.58 × 10−48 atm.
Both of these oxygen pressures are very small but their relative values indicate that
aluminum oxide is much more stable than copper oxide; an extremely low oxygen pressure
would be needed to reduce aluminum oxide to the metallic state.

182
THERMAL PHYSICS
12.4.4 Dependence of K(T, p) on Pressure
Since ∂G/∂p = V we have ∂μ0
i (T, p)/∂p = V 0
i (T, p), which is the molar volume of each
constituent in its standard state.14 Therefore,
∂G0(T, p)
∂p
=

i
νi
∂μ0
i (T, p)
∂p
=

i
νiV 0
i (T, p) ≡V 0(T, p).
(12.75)
Thus,
∂ln K(T, p)
∂p
= −V 0(T, p)
RT
= −

i
νi
V 0
i (T, p)
RT
.
(12.76)
As remarked previously, V 0
i (T, p)/RT = 1/p for ideal gases and V 0
i (T, p)/RT ≪1/p for
condensed phases, so the only really important correction is for gases. If all gases can be
treated as ideal,
∂ln K(T, p)
∂p
= −
gases

i
νi
p ,
(12.77)
which can be integrated to give
ln K(T, p)
K(T, p0) = −
gases

i
νi ln p
p0
= ln
 p
p0
−gases
i
νi
.
(12.78)
Exponentiation of this expression gives agreement with Eq. (12.53). If better information
is available for non-ideal gases, one could integrate Eq. (12.76).
12.5 Simultaneous Reactions
As mentioned in connection with Eq. (12.2), it is possible to have simultaneous reactions.
In that case, there is a progress variable ˜Ns for each reaction and we will have
dintNi =

s
νs
i d ˜Ns.
(12.79)
Then for a chemically closed system,
dGT,p =

i
μi dintNi =

i
μi

s
νs
i d ˜Ns = −

s
As d ˜Ns ≤0,
(12.80)
where As
=

i νs
i μi is the afﬁnity of the reaction s. The corresponding entropy
production is
dintS =

s
As
T d ˜Ns ≥0.
(12.81)
14Here as above, we extend the meaning of standard state to mean the most stable phase of the pure
constituent at T and p. A stricter deﬁnition (see Lupis [5, p. 120]) that restricts the standard state to T and p0
for chemical reactions would lead to ∂G0(T, p0)/∂p = 0, in which case ∂K(T, p0)/∂p = 0.

Chapter 12 • Chemical Reactions
183
Since these chemical reactions can take place at the same spatial position, they may be
coupled and it is only necessary that the sum be positive during the reaction. See Lupis
[5, p. 122] for examples of uncoupled simultaneous reactions and Kondepudi and
Prigogine [14, p. 369] for a discussion of coupled simultaneous reactions in the context of
entropy production.

This page intentionally left blank 

13
Thermodynamics
of Fluid-Fluid Interfaces
Until now we have dealt primarily with homogeneous phases or with composite systems
consisting of several homogeneous phases. In all of these cases, we have ignored the
thermodynamics of the surfaces of these phases or the interfaces that separate them. This
was done on the basis that we were interested in the bulk properties of sufﬁciently large
phases that the contributions of surfaces and interfaces could be neglected. Nevertheless,
there are many familiar instances where the properties of surfaces cannot be ignored. For
example, a glass of water in a gravitational ﬁeld can be ﬁlled somewhat beyond its capacity
without spilling; the surface of the water bulges above the top of the glass but is held in
place by a force due to “surface tension” that supports the water above the glass. Roughly
speaking, the surface of the water has a free energy per unit area in excess of the free energy
of the bulk. Thus, the creation of more area requires an increase in free energy and hence
to a force per unit length around the perimeter of the area that tries to keep the area from
increasing. Another example is the substantial rise (typically a few centimeters) of water
in a capillary tube immersed vertically in a large vessel.
In this chapter, we explore in more detail the thermodynamic properties of the thin
transition regions that exit in actual systems near these idealized surfaces of discontinuity.
We do this under conditions for which the change from one homogeneous phase to
another takes place over a region that is thin compared to the extent of the homogeneous
phases.1 We begin by considering a model developed by Gibbs [3, p. 223] that is based
on the concept of a dividing surface. Such a surface has zero thickness, so it is a
mathematical abstraction. By means of a clever formalism, Gibbs was able to account for
the thermodynamic properties of the actual transition region by associating it with the
dividing surface. We ﬁrst consider the Gibbs dividing surface model of planar interfaces
in ﬂuid systems, for which the surface tension can be deﬁned unambiguously. Then for
planar interfaces, we present Cahn’s layer model which allows one to express physically
meaningful surface quantities in terms of determinants whose properties illustrate clearly
their invariance with respect to the thickness or location of the layer that contains
the region of discontinuity. The Gibbs model is seen to be a special case of Cahn’s
model.
Next, we discuss curved interfaces for ﬂuids, for which the location of the dividing
surface must be ﬁxed by some convention, in particular the Gibbs “surface of tension”
that we deﬁne later. We illustrate surface tension phenomena by examples such as rise or
1For curved surfaces, the region of discontinuity must also be thin relative to its radii of curvature.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00013-2
185
Copyright © 2015 Elsevier Inc. All rights reserved.

186
THERMAL PHYSICS
depression in a capillary tube, the meniscus that forms at the edge of a submerged plate, a
variety of interface shapes for two-dimensional problems, and the shapes of pendant and
sessile drops in three dimensions.
13.1 Planar Interfaces in Fluids
We begin by considering a planar interface, such as depicted in Figure 13–1, that separates
two essentially homogeneous ﬂuid phases that we denote by superscripts α and β.
The transition region between the phases is assumed to be thin compared to the extent
of the phases themselves. The entire system, which is chemically closed, has an internal
energy U, entropy S, volume V, and mole numbers Ni of its chemical components. It
is assumed to be in equilibrium and to have a temperature T and chemical potentials
μi that are uniform throughout. Gibbs discusses the need for this uniformity in great
detail by imagining the system to be divided into three subsystems by means of imaginary
parallel walls that are similarly situated with respect to the transition region. These walls
are on opposite sides of a layer L that contains the transition region; they are assumed to
be near that region but sufﬁciently far from it that they are in practically homogeneous
regions. They separate the actual thin layer containing the transition region from two
homogeneous phases, αH and βH. For immobile walls, Gibbs assumes that an inﬁnitesimal
variation of the energy of the layer L is given by
δUL = TLδSL +

i
μL
i δNL
i ,
(13.1)
where SL is the entropy of the layer and NL
i is the number of moles of component i in the
layer. Gibbs deﬁnes TL to be its temperature and the μL
i to be its chemical potentials.2 He
then proceeds to show that they must be equal to the temperature and chemical potentials
of the bulk phases.
For immobile walls, the energies of the homogeneous subsystems αH and βH can vary
according to δUα = TαδSα + 
i μα
i δNα
i and δUβ = TβδSβ + 
i μβ
i δNβ
i . Then by studying
α
β
FIGURE 13–1 Schematic diagram showing a planar interface, which is a region of discontinuity (located near the
innermost dotted lines) between bulk α and β phases. The dashed lines, which are located near the region of
discontinuity but practically in homogeneous regions, are imaginary walls that deﬁne a layer that contains the
region of discontinuity. This is the same layer L used by Gibbs to deﬁne TL and μL
i in Eq. (13.1) and used in Cahn’s
layer model in Section 13.1.3 to establish Eq. (13.11). The Gibbs dividing surface is any plane parallel to the walls of
the layer and can be inside or outside the layer.
2Gibbs deals with the masses of the components rather than the number of moles, so his chemical potentials
are per unit mass and differ from ours by factors of the molecular weights.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
187
special variations of entropy and mole numbers of each component among the layer L and
the homogeneous subsystems αH and βH and requiring the total energy U = Uα+UL+Uβ
to be a minimum at constant total entropy and total mole numbers, Gibbs reasons for
variations that can have either sign that the temperature and chemical potentials must be
uniform, just as they would be for three bulk systems in heterogeneous equilibrium.
For example, for a special variation in which component j is exchanged between α
and L but there is no other change, one has δU = μα
j δNα
j + μL
j δNL
j = (μα
j −μL
j )δNα
j .
Then for variations δNα
j of either sign, one must have μα
j −μL
j = 0 to prevent δU from
being negative, which would violate the fact that U must be a minimum at equilibrium.
Gibbs also deals carefully with the manner in which extensive quantities can be deﬁned
during such variations, which involve inﬁnitesimal discontinuities at the walls [3, p. 224].
Ultimately, Tα = TL = Tβ and μα
i = μL
i = μβ
i for each component i.
The pressures in the bulk phases are also uniform and equal to one another. This
must be true for mechanical equilibrium and can be established by means of a variation
in which the
entire layer L is translated by an inﬁnitesimal distance in a direction
perpendicular to its walls without any change in the layer L itself. This gives rise to a
change in volume δV of one homogeneous system and −δV of the other, just as if the
layer L were absent. Thus the variation of the internal energy of the whole system will be
δU = δV(pα −pβ), so (pα −pβ) must vanish for arbitrary δV of either sign. Therefore, the
pressures of the bulk systems must be equal (we shall hereafter denote them both by p) as
they would be for bulk systems in heterogeneous equilibrium.3
13.1.1 Gibbs Dividing Surface Model
Following Gibbs, we replace the actual system by a model system consisting of two strictly
homogeneous phases separated by a single mathematical plane, known as the Gibbs
dividing surface. In this model system, the homogeneous phases extend uniformly until
they meet at the dividing surface. This plane is similarly situated with respect to the
transition region. For the moment, we assume that it is located anywhere in the system, not
necessarily in the transition layer, and discuss later the implications of its actual location.
One then deﬁnes surface excess quantities by subtracting the extensive properties of the
homogeneous parts of the model system from the corresponding actual parts:
Uxs := U −Uα −Uβ;
(13.2)
Sxs := S −Sα −Sβ;
(13.3)
Nxs
i
:= Ni −Nα
i −Nβ
i ;
(13.4)
0 := V −V α −V β.
(13.5)
3Note that this treatment avoids discussion of the pressure of the subsystem L. In fact, that subsystem is
inhomogeneous, so on a microscopic scale it could be characterized by a pressure tensor pij. If the z direction
is perpendicular to the walls of the layer, then pzz must be uniform and equal to the common pressure p of
the homogeneous phases. The components pxx = pyy will vary from p near the homogenous phases to negative
values within the discontinuity itself, giving rise to a surface tension σ =

(p −pxx)dz > 0, where the integration
includes the region of discontinuity. See [27, p. 44] for a derivation.

188
THERMAL PHYSICS
Equation (13.5) is different from the previous three equations because there is no excess
volume, due to the fact that the homogeneous phases of the model system meet at the
dividing surface, which has no thickness. Since the temperature is uniform, one can
also deﬁne excesses of the thermodynamic potentials, such as the Helmholtz free energy
F = U −TS, for which
Fxs := F −Fα −Fβ.
(13.6)
It follows that all excess quantities follow the same algebra as their bulk counterparts.
Although these excess quantities can be deﬁned, they usually do not have physical
signiﬁcance because they depend on the location of the dividing surface. This is easily
illustrated for the case of a single component material in which one bulk phase is a liquid
having molar density nℓand the other is a gas having molar density ng. Then if the dividing
surface is located such that the gas has volume V g and the liquid has volume V −V g, where
V is the total volume, it follows that
Nxs = N −nℓV + (nℓ−ng)V g.
(13.7)
For nℓ−ng > 0, the sum of the ﬁrst two terms on the right is negative and independent
of the location of the dividing surface whereas the last term on the right is positive
and depends linearly on V g and hence linearly on the position of the dividing surface.
Thus, Nxs varies with the position of the dividing surface and can be positive, negative,
or zero. Therefore, Nxs has no physical signiﬁcance. One could ﬁx the position of the
dividing surface by convention by choosing its location so that Nxs = 0; this is known as
the equimolar surface. Nevertheless, this choice is still artiﬁcial. Moreover, in a multi-
component system one could only choose the dividing surface to be equimolar relative to
one of the components. Similarly, it follows that Uxs, Sxs, and Fxs depend on the location
of the dividing surface.
On the other hand, the excess of the Kramers potential4 K = F −
i μiNi, namely
K xs := K −K α −K β = Fxs −

i
μiNxs
i
(13.8)
turns out to be independent of the location of the dividing surface. This can be seen by
noting for a bulk phase that F −
i μiNi = F −G = −pV, so K α = −pV α and K β = −pV β.
Therefore
K xs = K + p(V α + V β) = K + pV,
(13.9)
where Eq. (13.5) has been used. The right-hand side of Eq. (13.9) is independent of the
location of the dividing surface, so K xs is also independent of that location and has
4This is also called the grand potential and is often denoted by .

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
189
physical meaning. We can therefore divide by the area A of the dividing surface to deﬁne
the surface free energy5 (per unit area of interface)
γ := K xs
A = Fxs −
i μiNxs
i
A
= K + pV
A
,
(13.10)
which will be independent of the choice of the location of the dividing surface for a planar
region of discontinuity.
We now approach the same problem from a different vantage point by considering
small reversible changes of the same planar system in contact with a thermal reservoir at
temperature T, a pressure reservoir at pressure p, and chemical reservoirs at potentials μi.
In particular, we allow the system to undergo an inﬁnitesimal change in which its length is
unchanged but its cross-sectional area changes by an amount dA. In order to account for
work done “by the surface” we write the reversible work done by the system in the form
δW = p dV −σ dA, where p dV is the usual quasistatic work done by the pressure and σ dA
is the extra work done on the system because of the surface of discontinuity. The quantity
σ is the surface (interfacial) tension, which is a force per unit length that must be applied
by an external agent to extend the surface. Thus
dU = T dS −p dV + σ dA +

i
μi dNi.
(13.11)
We shall proceed to show that σ = γ . Indeed, for the bulk systems we have
dUα = T dSα −p dV α +

i
μi dNα
i ;
(13.12)
dUβ = T dSβ −p dV β +

i
μi dNβ
i .
(13.13)
We subtract both of these equations from Eq. (13.11) to obtain
dUxs = T dSxs +

i
μi dNxs
i
+ σ dA.
(13.14)
Equation (13.14) illustrates that Uxs can be regarded as a function of Sxs, Nxs
i , and A.
Moreover, by considering systems that have the same values of T, μi, and σ but simply
different cross-sectional areas, we deduce that
Uxs(λSxs, λNxs
i , λA) = λUxs(Sxs, Nxs
i , A)
(13.15)
5The name surface free energy is commonly used, but it is important to remember that the relevant free
energy is the Kramers potential. For the case of planar interfaces that is treated here, the pressure is the same in
both bulk phases so one can deﬁne a Gibbs free energy G = U −TS+pV and note that K +pV = G−
i μiNi. Then
γ A can be thought of as an excess Gibbs free energy relative to a homogeneous system. For curved surfaces, the
pressures in the bulk phases are not equal, so one must resort to the Kramers potential. For the very special case
of a single component material with the dividing surface chosen to be the equimolar surface, one has γ = Fxs/A
which is the surface excess of the Helmholtz free energy. The name surface tension is perfectly applicable for
γ for a surface of discontinuity between ﬂuids because it can be shown to be the force per unit length needed
to extend the surface. For solids, this would be a misnomer because surface can be created but also stretched
elastically.

190
THERMAL PHYSICS
for any positive λ. Thus by the Euler theorem of homogeneous functions of degree one
(see Eq. (5.39)), we deduce that
Uxs = TSxs +

i
μiNxs
i
+ σA.
(13.16)
Equation (13.15) can be solved for σ to deduce
σ = Uxs −TSxs −
i μiNxs
i
A
= γ .
(13.17)
Equation (13.17) together with Eq. (13.11) show that the reversible work associated with an
increase in surface area is just γ dA, where γ is the surface excess of the Kramers potential.
13.1.2 Gibbs Adsorption Equation
Differentiation of Eq. (13.16) with σ replaced by γ gives
dUxs = T dSxs + Sxs dT +

i
μi dNxs
i
+

i
Nxs
i dμi + γ dA + A dγ .
(13.18)
Comparison with Eq. (13.14), again with σ = γ , gives
A dγ = −Sxs dT −

i
Nxs
i dμi.
(13.19)
We divide Eq. (13.19) by A and denote the excess entropy per unit area by sA := Sxs/A and
the excess mole numbers per unit area by 
i := Nxs
i /A to obtain the Gibbs adsorption
equation
dγ = −sA dT −

i

i dμi.
(13.20)
If we deﬁne uA = Uxs/A and combine Eq. (13.20) with the differential of γ from Eq. (13.17),
we obtain
duA = T dsA +

i
μi d
i,
(13.21)
which resembles Eq. (13.1) because the special variation considered there was for ﬁxed A
and immobile walls.
Equation (13.20) must be handled with great care because the quantities sA and 
i de-
pend on the location of the dividing surface and are therefore not of physical signiﬁcance.
For example, one might be tempted to try to calculate sA as a derivative (∂γ/∂T)μi but such
a derivative does not exist in this case of planar surfaces. The reason is that the variable set
T, {μi} is not independent because the bulk phases are each governed by Gibbs-Duhem
equations
Sα dT −V α dp +

i
Nα
i dμi = 0;
(13.22)
Sβ dT −V β dp +

i
Nβ
i dμi = 0.
(13.23)

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
191
Introducing the entropy density sV and the concentrations ci = Ni/V for bulk α and β and
then eliminating dp gives
(sα
V −sβ
V ) dT +
κ

i=1
(cα
i −cβ
i ) dμi = 0.
(13.24)
Therefore, only κ of the κ + 1 variables T, {μi} are independent. Elimination of one of
these variables enables dγ to be expressed in terms of independent variables, and then
the corresponding derivatives have physical meaning.
Example Problem 13.1. For the case of a single component, evaluate dγ /dT and interpret
the result physically.
Solution 13.1. Equation (13.20) becomes
dγ = −sA dT −
xs dμ
(13.25)
and Eq. (13.24) yields
dμ = −(sα
V −sβ
V )
(cα −cβ) dT.
(13.26)
Elimination of dμ from Eq. (13.25) gives
dγ = −

sA −
xs sα
V −sβ
V
cα −cβ

dT.
(13.27)
The required derivative dγ /dT is the negative of the expression in square brackets. The bulk
phases are only in equilibrium along a coexistence curve, say p = ˜f (T), which is a solution of
μα(T, p) = μβ(T, p), so μ depends only on T. The quantity in brackets is an effective surface
entropy that governs the dependence of γ on T. It is therefore independent of the choice of the
dividing surface. If one adopts the convention of the equimolar surface, then 
xs = 0. In that
case, the effective surface entropy reduces to sA, the equimolar surface entropy.
It is now obvious that we could have used Eq. (13.26) to eliminate dT instead of dμ in
Eq. (13.25). In that case
dγ = −


xs −sA
cα −cβ
sα
V −sβ
V

dμ.
(13.28)
Now μ is the only independent variable and the quantity in brackets is an effective surface
adsorption, which has physical signiﬁcance independent of the choice of dividing surface.
In the general case, we can solve Eq. (13.24) for dμ1 and then substitute into Eq. (13.20)
to obtain
dγ = −

sA −
1
sα
V −sβ
V
cα
1 −cβ
1

dT −
κ

i=2


i −
1
cα
i −cβ
i
cα
1 −cβ
1

dμi.
(13.29)

192
THERMAL PHYSICS
Now the variables T, μ2, μ3, . . . , μκ are independent, so one may take partial derivatives
of γ with respect to them and obtain the quantities in square brackets, which must be
independent of the location of the dividing surface.6
Gibbs [3, p. 234] discusses Eq. (13.20) by locating the dividing surface to be the
equimolar surface for component 1, so that 
1 = 0. He then writes
dγ = −sA(1) dT −
κ

i=2

i(1) dμi,
(13.30)
where the extra subscript reminds us of that choice. By comparison of partial derivatives
of Eqs. (13.29) and (13.30), it is evident for any dividing surface that
sA(1) =

sA −
1
sα
V −sβ
V
cα
1 −cβ
1

;
(13.31)

i(1) =


i −
1
cα
i −cβ
i
cα
1 −cβ
1

.
(13.32)
It should be clear at this stage that other choices of the set of κ independent variables
are possible. This freedom of choice is obvious from the generalization developed in the
next section.
13.1.3 Cahn’s Layer Model
For planar interfaces, Cahn [28] or [29, pp. 379-399] developed a layer model that treats
an interfacial region of ﬁnite thickness and for which physically meaningful surface
quantities can be represented by determinants which are manifestly invariant with respect
to the thickness and location of the layer. The layer in Cahn’s theory can be taken to
be the layer we called L in Section 13.1 and employed by Gibbs (see Figure 13–1). It is
only necessary that the planes that bound the layer be sufﬁciently far from the transition
region that they lie in regions that are essentially homogeneous. Outside the layer, one
has homogeneous phases αH and βH as in Section 13.1. These homogeneous phases are
characterized by the same uniform intensive variables T, p, μi as in the Gibbs theory but
their amounts can differ because they do not occupy the entire volume.7 Then one can
deﬁne the content of the various extensive quantities in the layer by
UL := U −UαH −UβH ,
(13.33)
SL := S −SαH −SβH,
(13.34)
NL
i := Ni −NαH
i
−NβH
i
,
(13.35)
V L := V −V αH −V βH .
(13.36)
6The fact that they are independent of the location of the dividing surface is not obvious from the given
expressions, but they can be rewritten in terms of determinants, as shown in Section 13.1.3, in which case their
independence is obvious.
7This is consistent with the Cahn theory but not essential; one could equally well extend the uniform phases
until they met each other at a dividing surface, just as in the Gibbs case, but then the quantity V L would be zero.
In the Cahn theory, [V] := V L/A depends on the layer thickness, so it is not a fundamental physical quantity.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
193
Note the similarity to Eqs. (13.2)–(13.5) for the excess quantities of Gibbs, with the main
exception being that the layer now has a non-vanishing volume V L and the homogeneous
regions do not meet. Following Cahn, we denote the extensive quantities of the layer per
unit area by symbols in square brackets, explicitly [U] := UL/A, [S] := SL/A, [Ni] := NL
i /A,
and [V] := V L/A, with similar notations for other extensive quantities. Since [U], [S], [Ni],
and [V] depend on the position of the walls that bound the layer, they are not fundamental
physical quantities.
On the other hand, we know that the quantity γ = (K + pV)/A does not depend on any
division of the system into L, αH, and βH. Moreover, by substitution of Eqs. (13.33)–(13.36)
we have8
γ = U −TS −
i μiNi + pV
A
= UL −TSL −
i μiNL
i + pV L
A
,
(13.37)
where we have used the Euler equations for the bulk phases:
UαH −TSαH + pV αH −

i
μiNαH
i
= 0;
(13.38)
UβH −TSβH + pV βH −

i
μiNβH
i
= 0.
(13.39)
Therefore
γ = [U] −T[S] + p[V] −

i
μi[Ni].
(13.40)
Note especially that the p that multiplies [V] is the pressure of the bulk phases. The layer
L is inhomogeneous and in a non-hydrostatic state of stress.
For the layer model, one also has γ = σ, the surface tension that enters Eq. (13.11). We
can see this by writing Eqs. (13.12) and (13.13) for αH and βH and subtracting both from
Eq. (13.11) to get
dUL = T dSL −p dV L +

i
μi dNL
i + σ dA.
(13.41)
Note that Eq. (13.14) has no counterpart to the term p dV L because the Gibbs dividing
surface has no volume. Equation (13.40) can be integrated in the same manner as used to
obtain Eq. (13.17) and then divided by A to obtain
σ = UL −TSL + pV L −
i μiNL
i
A
= [U] −T[S] + p[V] −

i
μi[Ni] = γ .
(13.42)
In Eq. (13.41), one can employ the deﬁnitions of the layer quantities per unit area and use
Eq. (13.42) to eliminate the coefﬁcient of dA, resulting in
d[U] = T d[S] −p d[V] +

i
μi d[Ni].
(13.43)
8Note that this is precisely the same deﬁnition of γ as for the Gibbs dividing surface, Eq. (13.10). In the present
case, however, K L = K −K αH −K βH = K + p(V αH + V αH ) = K + pV −pV L = Aγ −pV L ̸= Aγ because V L ̸= 0.

194
THERMAL PHYSICS
Combining Eq. (13.43) with the differential of Eq. (13.40) yields
dγ = −[S] dT + [V ] dp −

i
[Ni] dμi,
(13.44)
which is the counterpart to Eq. (13.20), the Gibbs adsorption equation.
As was the case with the Gibbs dividing surface, the κ +2 quantities T, p, {μi, i = 1 · · · κ}
cannot be varied independently due to the bulk Gibbs-Duhem equations, Eqs. (13.22) and
(13.23). Cahn handles this in an elegant and ﬂexible way by solving the set Eq. (13.44),
Eq. (13.22), and Eq. (13.23) simultaneously for dγ and the differentials of two distinct
members of the set T, p, {μi, i = 1 · · · κ} which are regarded as dependent variables. This
results in an expression for dγ in terms of the differentials of the remaining κ independent
variables of the set. By means of straightforward application of Cramer’s rule, the result
can be expressed in terms of determinants of the form9

Z/XY

≡
						
[Z] [X] [Y]
Zα
Xα
Y α
Zβ
Xβ
Y β
						
				
Xα Y α
Xβ Y β
				
,
(13.45)
where X, Y , and Z are members of the set S, V, {Ni} and X and Y are not the same. In
particular, X and Y are the extensive conjugates to the two intensive variables that are
chosen to be dependent. The result is
dγ = −[S/XY] dT + [V /XY] dp −
κ

i=1
[Ni/XY] dμi
(13.46)
in which differentials of the entire variable set T, p, {μi, i = 1 · · · κ} appear but in which
two of the coefﬁcients are zero because of the structure of the determinant Eq. (13.45).
For example, if X = V and Y = N1, one sees that [V/VN1] = 0 and [N1/VN1] = 0 because
two columns in the determinants of their numerators are the same. With that choice, the
coefﬁcients of dp and dμ1 drop out and one is left with
dγ = −[S/VN1] dT −
κ

i=2
[Ni/VN1] dμi.
(13.47)
Equation (13.47) is the same as Eq. (13.29) or Eq. (13.30) of the Gibbs theory, but here we
see from the determinant structure of Eq. (13.45) that the coefﬁcients of these indepen-
dently variable differentials do not depend on the location of the planes that bound Cahn’s
9Equations (13.22) and (13.23) were written in terms of amounts of homogeneous α and homogeneous β that
meet at the Gibbs dividing surface whereas Cahn’s layer theory pertains to homogenous phases αH and βH that
lie outside the layer. But Eqs. (13.22) and (13.23) are homogeneous so they can be multiplied by any numbers nα
and nβ to increase or reduce the amount of each phase. This will leave the ratio of determinants in Eq. (13.45)
unchanged because both numerator and denominator will contain a factor nαnβ which will cancel.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
195
layer or the location of the dividing surface of Gibbs. For a one component system, we can
choose the dependent variables to be p and μ, in which case
dγ = −[S/VN] dT,
(13.48)
so γ depends only on the temperature, as in Eq. (13.27).
At a liquid-vapor interface, γ must go to zero at the critical temperature Tc, at which
liquid and vapor become indistinguishable. According to an empirical equation (see [22,
p. 474]),
γ (T) ≈γ0(1 −T/Tc)11/9,
(13.49)
where γ0 is a constant. This would correspond to an effective surface entropy,
[S/VN] ≈11
9
γ0
Tc
(1 −T/Tc)2/9,
(13.50)
which is nearly constant for T ≪Tc but ﬁnally becomes zero at T = Tc.
We can see the independence of the layer bounds even more clearly by noting that
						
[Z] [X] [Y]
Zα
Xα
Y α
Zβ
Xβ
Y β
						
= 1
A
						
ZL XL Y L
Zα Xα Y α
Zβ Xβ Y β
						
= 1
A
						
Z
X
Y
Zα Xα Y α
Zβ Xβ Y β
						
,
(13.51)
where Z, X, Y pertain to the entire system. The last step is true because we can add to
the ﬁrst row whatever multiples of the second and third rows that are needed without
changing the value of the determinant. Therefore, we may write
[Z/XY] = 1
A
						
Z
X
Y
Zα Xα Y α
Zβ Xβ Y β
						
				
Xα Y α
Xβ Y β
				
,
(13.52)
which clearly relates to the entire system and has nothing whatsoever to do with the
location of any bounding planes of a layer or of a dividing surface. As pointed out in the
previous footnote, this expression is independent of the amounts of the homogeneous
phases, which must be the case for a physically meaningful interfacial quantity.
As Cahn points out from the structure of Eq. (13.45), the quantity [Z/XY ] is the
difference, per unit area, in the amount of Z in the layer and portions of homogeneous
α and β that, in combination, would have the same values of X and Y as the layer. In other
words, if kα and kβ are chosen so that kαXα + kβXβ = A[X] and kαY α + kβY β = A[Y ], then
[Z/XY ] = [Z] −(kαZα + kβZβ)/A. It follows from Eq. (13.52) that the same interpretation
is true if one considers the entire system instead of the layer.
The foregoing theory is easily extended to the case of planar systems in which multiple
homogeneous phases are separated by interfaces. For example, suppose that three phases
α, β, and η are in equilibrium with one another. These phases could be separated by two
interfaces, one separating α from β and a second separating β from η. Somewhere in the
β phase, but very far from both interfaces, one could place an imaginary plane that would

196
THERMAL PHYSICS
divide the system into two parts, one that we will refer to with superscripts αβ and the
other with superscripts βη. Then the quantities
γ αβ := K αβ + pV αβ
A
= Uαβ −TSαβ + pV αβ −μiNαβ
i
A
;
(13.53)
γ βη := K βη + pV βη
A
= Uβη −TSβη + pV βη −μiNβη
i
A
(13.54)
will be well deﬁned. Both γ αβ and γ βη will depend on the set of intensive variables
T, p, {μi} which will be uniform throughout the system. But in addition to the Gibbs-
Duhem equations (13.22) and (13.23) for the bulk phases α and β, there will be a similar
Gibbs-Duhem equation for the bulk η phase. These will constrain three of the intensive
variables to be dependent on any others. For a single component material, there are only
three variables, T, p, μ, so all would be determined and incapable of change; an equation
like Eq. (13.43) would lead to the trivial conclusion dγ αβ = 0 and dγ βη = 0. So we consider
at least a binary system, in which case there will be one free variable. Then we will have
dγ αβ = −[Sαβ/XYZ] dT + [V αβ/XYZ] dp −
κ

i=1
[Nαβ
i
/XYZ] dμi;
(13.55)
dγ βη = −[Sβη/XYZ] dT + [V βη/XYZ] dp −
κ

i=1
[Nβη
i
/XYZ] dμi,
(13.56)
where now
[W αβ/XYZ] = 1
A
								
W αβ Xαβ Y αβ Zαβ
W α
Xα
Y α
Zα
W β
Xβ
Y β
Zβ
W γ
Xγ
Y γ
Zγ
								
						
Xα Y α Zα
Xβ Y β Zβ
Xγ Y γ Zγ
						
(13.57)
with a similar expression for [W βη/XYZ]. Here, X, Y , Z must be distinct members of the set
S, V, {Ni} and W can be any member of the set. Now, three of the coefﬁcients in each of
Eqs. (13.55) and (13.56) will be zero. Thus for a binary system there would be only one free
variable, say T.
The special case of a single phase interface could occur if the α and β phases are the
same but can be distinguished in some other way. Such boundaries can occur in solids,
examples being grain boundaries and antiphase boundaries. Although we have not yet
discussed the case of solid phases, which involve considerations of surface strain and
stress as well as anisotropy, the consequences of having only one Gibbs-Duhem equation
will lead to a result of the form
dγ = −[S/X] dT + [V /X] dp −
κ

i=1
[Ni/X] dμi
(13.58)

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
197
in which X is any member of the set S, V, {Ni}. We note that
[Z/X] = 1
A
				
Z
X
Zα Xα
				
Xα
= Z −XZα/Xα
A
(13.59)
which obviously does not depend on the total amount of α phase.
Example Problem 13.2. Prove that Cahn’s interpretation of the quantity [Z/XY] in the
paragraph following Eq. (13.52) is correct.
Solution 13.2. First we choose kα and kβ so that kαXα + kβXβ = XL and kαY α + kβY β = Y L.
Then we substitute for XL and Y L into the middle form of Eq. (13.51) to obtain
						
ZL XL Y L
Zα Xα Y α
Zβ Xβ Y β
						
=
						
ZL kαXα + kβXβ kαY α + kβY β
Zα
Xα
Y α
Zβ
Xβ
Y β
						
.
(13.60)
We multiply the second row by kα and the third row by kβ and subtract the resulting rows from
the ﬁrst row to obtain
						
ZL XL Y L
Zα Xα Y α
Zβ Xβ Y β
						
=
						
ZL −kαZα −kβZβ
0
0
Zα
Xα Y α
Zβ
Xβ Y β
						
= (ZL −kαZα −kβZβ)
				
Xα Y α
Xβ Y β
				 .
(13.61)
When we insert this result into the deﬁnition of [Z/XY], the 2 × 2 determinant cancels and we
are left with
[Z/XY] = (ZL −kαZα −kβZβ)/A,
(13.62)
which was to be proven.
13.2 Curved Interfaces in Fluids
To treat curved interfaces in ﬂuids, we return to the comparison system of Gibbs based
on a dividing surface. Our main reason for doing this is that the interfacial area can be
unambiguously deﬁned; however, for a layer model, one would have to decide what area
to use. One side of the dividing surface in the comparison system is assumed to be ﬁlled
by a homogeneous phase α and the other side by a homogeneous phase β. As in the
case of a planar interface, the temperature T and the chemical potentials μi are uniform
throughout the system. This can be established by considering a layer that extends into the
homogeneous phases, similar to the planar case, and studying variations in which there
are no changes in the position of the layer. Then one invokes Eq. (13.1) to deﬁne T and
μi within this ﬁxed layer and then follows the same procedure as for a planar interface to
establish uniformity of T and the μi throughout the system. Unlike the case of a planar
interface, however, the homogeneous phases can have different pressures, pα and pβ.

198
THERMAL PHYSICS
Relative to the dividing surface, one can deﬁne excess extensive quantities by the
same equations, Eqs. (13.2)–(13.6), as in the planar case. Equation (13.8) for the Kramers
potential holds as well, but now K α = −pαV α and K β = −pβV β so Eq. (13.9) becomes
K xs = K + pαV α + pβV β = K + pαV + (pβ −pα)V β.
(13.63)
We now deﬁne
γ := K xs
A
= K + pαV α + pβV β
A
= K + pαV + (pβ −pα)V β
A
.
(13.64)
Unlike the case for a planar interface, γ for a curved interface depends on the choice of
the location of the dividing surface.
We can illustrate this dependence quite simply for the case in which the β phase is a
sphere of radius r surrounded by the α phase. Then A = 4πr2 and V β = (4/3)πr3 so
γ = K + pαV
4π
1
r2 + (pβ −pα)
3
r,
(13.65)
where the coefﬁcients of 1/r2 and r are constants for a given physical system. Figure 13–2
shows a sketch of γ as a function of r. We note that γ has a minimum value10 γt at some
value rt. We multiply Eq. (13.65) by r2 and take its variation with respect to r for a ﬁxed
physical system, so K + pαV and pβ −pα have no variation with r. This results in
(pβ −pα) = 2γ
r + ∂γ
∂r .
(13.66)
We can now choose r = rt at which ∂γ/∂r = 0 and γ = γt, its minimum value. Then
Eq. (13.66) reduces to
(pβ −pα) = 2γt
rt
.
(13.67)
γ
γt
r
rt
FIGURE 13–2 Plot of γ versus r according to Eq. (13.65) in arbitrary units (top curve). The lower curve and the
straight line represent the individual terms. The minimum occurs at the surface of tension where r = rt and γ = γt
and leads to Eq. (13.67) instead of Eq. (13.66).
10From stability considerations, γ must be positive. Otherwise, the system could lower its free energy
indeﬁnitely by creating an inﬁnite amount of area. For an extensive discussion of stability, see Gibbs
[3, pp. 237-252].

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
199
This special choice is the so-called surface of tension which was introduced by Gibbs
following another course of reasoning that we describe below.
Before doing so, however, we derive the counterpart to Eq. (13.67) for a more general
surface having principal curvatures c1 = 1/R1 and c2 = 1/R2, where R1 and R2 are principal
radii of curvature. We return to Eq. (13.64) and identify a set of dividing surfaces by
means of a parameter λ. One such surface is chosen to be very near the physical region
of discontinuity and similarly situated with respect to it, while the others are obtained by
shifting a constant distance δλ along the normals to that chosen surface. Thus, A, V β, and
γ become functions of λ. Multiplying Eq. (13.64) by A and taking its variation with respect
to λ, we obtain
A∂γ
∂λ δλ + γ δA = (pβ −pα)δV β,
(13.68)
where from differential geometry11
δV β = Aδλ;
δA = (c1 + c2)Aδλ.
(13.69)
We therefore obtain
pβ −pα = γ (c1 + c2) + ∂γ
∂λ .
(13.70)
If we choose the dividing surface to correspond to the generalized surface of tension where
∂γ/∂λ = 0, Eq. (13.70) becomes12
pβ −pα = γt

 1
R1t
+ 1
R2t

.
(13.71)
In the special case of a spherical surface, R1t = R2t = rt and we recover Eq. (13.67).
An equation of the form of Eq. (13.71) (without the subscripts t) is attributed to Laplace
and pertains to a membrane of zero thickness that has the following property: If dτ is
any inﬁnitesimal vector in that membrane, the membrane on one side of it exerts an
attractive force per unit length γ on other side that is perpendicular to dτ and tangential
to the surface. Equation (13.71) shows that such a relation results from thermodynamic
considerations, provided we evaluate the excess surface free energy γ at the surface of
tension. As we shall see below, Gibbs arrived at the same equation as an approximation
based on the idea that the explicit dependenceof γ on the curvature of the dividing surface
can be ignored for a dividing surface that is very close to the region of transition, provided
that the thickness of the region of transition is small relative to either of its principal radii
of curvature. In practice, γ is measured experimentally by assuming it to be equal to γt
in Eq. (13.71) and by assuming that the principal radii of curvature measured by some
technique, usually optical, are essentially the same as R1t and R2t.
11These are special cases of the integral formulae δV β =

δλ dA and δA =

(c1 + c2)δλ dA that hold for a
normal shift δλ that is a function of position on the surface.
12The quantity that multiplies γt in Eq. (13.71) is called the mean curvature, with the sign convention that the
radius is positive for a sphere of the β phase, or for a more general surface if the β phase is on the side of the
interface that has net concavity.

200
THERMAL PHYSICS
Example Problem 13.3. Estimate the capillary rise of water and the capillary depression
of mercury in a vertical glass capillary tube of inner diameter 2r0 = 1.0 mm at a temperature
of 20 ◦C. Take γ = 0.073J/m2 for water and 0.47 J/m2 for mercury. Assume that the density
is 1 g/cm3 for water and 13.55 g/cm3 for mercury. See Figure 13–3 for an illustration of the
geometry and the contact angle θ where the water meets the glass. For now, assume that the
contact angle is an empirical parameter; later in Section 13.3 we provide some theoretical basis
for it. The water wets the glass with a contact angle of nearly zero degrees. Mercury does not
wet the glass and has an obtuse contact angle of 140◦. Assume that the shape of the liquid-gas
interface is approximately a portion of a sphere (undistorted by gravity) and that the system
is open to the atmosphere at a pressure of pA. Also assume that these liquids are locally in
equilibrium with their vapors but that the rate of evaporation, the solubilityof air in either liquid
and the density of air are negligible. Take the gravitational acceleration to be 9.8 m/s2. What
would be the corresponding results if the liquids were between large parallel vertical plates
separated by a small distance 2x0?
Solution 13.3. From the ﬁgure, we see that the radius of curvature of the spherical interface
is given by rt = r0/ cos θ, so 1/R1 + 1/R2 = 2/r0 for water and 1/R1 + 1/R2 = 2 cos(140◦)/r0 = −
1.45/r0 for mercury. For either substance, the pressure ph in the liquid at capillary rise height h
is given by pA −ph = ρgh = 2γ cos θ/r0. Here, ρgh is due to hydrostatic pressure, as explained in
Section 11.2. Thus the capillary rise is
h = 2γ
ρg
cos θ
r0
= a2 cos θ
r0
,
(13.72)
where
a :=

2γ /ρg
(13.73)
z=h
z=0
θ
FIGURE 13–3 Sketch of the rise of a liquid in a capillary tube of internal diameter 2r0. The rise h is deﬁned to be the
distance from the horizontal surface of the bulk liquid to the bottom of the meniscus. The contact angle θ is the
angle between the tangent to the meniscus at the tube wall and the tube itself (see Section 13.3). For an obtuse
angle θ, the liquid would be depressed below the surface of the bulk liquid.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
201
has dimensions of length and is known as the capillary length.13 At 20 ◦C, a ≈5.5 mm for water
and a ≈3.8 mm for mercury. The quantity a sets the length scale of capillary phenomena. For
the example of capillary rise just given, h = (a2/r0) cos θ. For r0 = 0.5 mm, h = 3 cm for water and
h = −1.4 cm for mercury.
For large parallel plates separated by a small distance 2x0, one radius of curvature would be
inﬁnite and the other would be cos θ/x0 so h = (1/2)(a2/x0) cos θ. For x0 = r0, the magnitude of
h would be half as large for parallel plates as for a tube.
13.2.1 Gibbs Coefﬁcients of Curvatures
Gibbs [3, p. 225] proceeded somewhat differently by assuming that the variation of the
excess internal energy from a state of equilibrium is given by
δUxs = TδSxs + μiδNxs
i
+ σδA + C1δc1 + C2δc2,
(13.74)
where C1 and C2 are coefﬁcients of the curvatures. He then employed the identity
C1δc1 + C2δc2 = (1/2)(C1 + C2)δ(c1 + c2) + (1/2)(C1 −C2)δ(c1 −c2).
(13.75)
By considering a spherical surface (so that C1 −C2 = 0) and two different choices of
the dividing surface that are essentially parallel to one another but separated by a small
distance, he proceeded to show [3, p. 227] that the coefﬁcient C1 + C2 can be made to
change sign by means of a small shift of the dividing surface. Therefore, one can choose a
dividing surface such that C1 + C2 = 0. He then argued that since C1 −C2 = 0 for a planar
interface, it should not differ much from zero for an interface that does not differ too
much from planarity, as would be the case if both principal radii of curvature are large
compared to the thickness of the inhomogeneous region. On this basis, he neglected the
term (1/2)(C1 −C2)δ(c1 −c2), ultimately resulting in
δUxs = TδSxs +

i
μiδNxs
i
+ σδA,
(13.76)
where σ is now dependent on the choice of the dividing surface. Provided that both
principal radii of curvature are large compared to the thickness of the inhomogeneous
region, this dividing surface will be quite close to the inhomogeneous region as measured
optically in an experiment.
Essentially, the Gibbs argument boils down to the following: The position of the
dividing surface can be chosen such that the dependence of Uxs on warping due to
curvatures that are not too large can be neglected. Curvatures only affect Uxs indirectly
through their inﬂuence on δA.
We can compare our approach to that of Gibbs as follows. We return to Eq. (13.74) and
integrate at constant T, μi, c1, and c2, by just making the system larger,14 to obtain the
Euler equation
13More accurately one should write a2 = 2γ/[(ρℓ−ρair)g] but the density ρair is usually negligible.
14For example, for a system consisting of a spherical surface and bulk systems inside a cone with its apex at
the center of the sphere, all extensive quantities will be proportional to the size of the cone.

202
THERMAL PHYSICS
Uxs = TSxs +

i
μiNxs
i
+ σA.
(13.77)
Combining this with the Euler equations for the homogeneous phases, we deduce that
σ = Uxs −TSxs −
i μiNxs
i
A
= U −TS −
i μiNi + pαV α + pβV β
A
,
(13.78)
so σ = γ as given by Eq. (13.64).
Next, we take the total variation of U = Uxs + Uα + Uβ with σ replaced by γ to obtain
δU = TδS −pαδVα −pβδV β +

i
μiδNi + γ δA + C1δc1 + C2δc2.
(13.79)
If we now consider a variation at constant external volume V = V α + V β, constant S, and
constant Ni, the condition for equilibrium becomes δU = 0 so
(pα −pβ)δV β + γ δA + C1δc1 + C2δc2 = 0.
(13.80)
For a normal shift of the interface by an amount δλ, as considered in the derivation of
Eq. (13.70), we have Eq. (13.69) and also δc1 = −c2
1δλ and δc2 = −c2
2δλ. Thus for arbitrary
δλ Eq. (13.80) becomes
(pβ −pα) = (c1 + c2)γ −C1
A c2
1 −C2
A c2
2.
(13.81)
Substitution of Eq. (13.81) into Eq. (13.70) gives
∂γ
∂λ = −(C1 + C2)
2A
(c2
1 + c2
2) −(C1 −C2)
2A
(c2
1 −c2
2).
(13.82)
From Eq. (13.82) we see that the Gibbs choice of location of the dividing surface to make
C1 + C2 = 0 and his neglect of the term in C1 −C2 is equivalent to choosing the dividing
surface to satisfy ∂γ/∂λ = 0, which leads to Eq. (13.71).
13.3 Interface Junctions and Contact Angles
In this section we investigate brieﬂy the mechanical conditions that must be satisﬁed
at the junctions where several ﬂuid phases meet. We begin by considering the two-
dimensional problem of a triple junction where three phases, α, β, and η meet along a line,
as illustrated in Figure 13–4. The line where the phases meet is known as a triple line and is
perpendicular to the plane of the ﬁgure. Our objective is to determine the dihedral angles
θα, θβ, and θη where these phases meet. By studying a simple variation of the position of
the triple junction, we shall see that the three tensions satisfy a simple force balance law
of the form15
γ αβ ˆτ αβ + γ βη ˆτ βη + γ ηα ˆτ ηα = 0,
(13.83)
15This equation also follows from a more general result of Gibbs [3, equation 615, p. 281] that holds for curved
contact lines and was obtained as part of a complete variation of the system.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
203
β
η
α
θβ
θη
θα
π −θα
π −θη
π −θβ
γβη
γηα
γαβ
FIGURE 13–4 Three phases α, β, and η that meet at a triple line (left) where they make dihedral angles θα, θβ, and
θη. On the right is the corresponding force triangle with forces of magnitudes γ αβ, γ βη, and γ ηα that are directed
away from the triple junction, so their vector sum is zero.
where ˆτ αβ is a unit vector perpendicular to the line of intersection of the three phases,
locally tangent to the αβ interface at the line of intersection, and pointing away from the η
phase. The other unit vectors ˆτ βη and ˆτ ηα are similarly deﬁned with respect to their phases.
One can interpret Eq. (13.83) by regarding the quantity γ αβ ˆτ αβ to be a force per unit length
that acts on the triple line along the α −β interface, and similarly γ βη ˆτβη, and γ ηα ˆτηα are
forces per unit length that act on the triple line along their respective interfaces. Thus,
Eq. (13.83) is the condition for zero force acting on the triple line.
It also follows that the vectors γ αβ ˆτ αβ, γ βη ˆτ βη, and γ ηα ˆτ ηα form a triangle, as shown in
Figure 13–4, whose internal angles are π −θα, π −θβ, and π −θη. This triangle is known
as a Neumann triangle and is often drawn in an orientation such that each of its sides is
perpendicular to the respective interface. This can be seen by taking the cross product of
Eq. (13.83) with a unit vector along the triple line. From the law of sines, and the fact that
sin(π −θ) = sin θ, it follows that
sin θα
γ βη
= sin θβ
γ ηα
= sin θη
γ αβ .
(13.84)
For such a Neumann triangle to exist, it is necessary for each of its sides to be less than the
sum of the other two sides, for example γ βη < γ ηα + γ αβ.
Equation (13.83) can also be generalized to junctions where more than three phases
meet, but such conﬁgurations might not be stable [3, p. 287]. If crystalline solids are
involved, we shall see that γ is anisotropic so Eq. (13.83) must be modiﬁed to account
for torque terms.
To derive Eq. (13.83) from a variational principle, we suppose that all interfaces are
pinned at distances that are far from the triple line and vary the position of the triple line by
moving it parallel to itself in the direction of a small vector ϵ. If ℓαβ is the pinning distance
from the α −β interface to the original triple line, the distance from the varied triple line is
|ℓαβταβ −ϵ| =

(ℓαβ)2 −2ϵ · ˆτ αβℓαβ + ϵ2 = ℓαβ −ϵ · ˆτ αβ
(13.85)
to ﬁrst order in ϵ/ℓαβ. The corresponding change in distance is therefore −ϵ · ˆταβ. By
treating the other interfaces in a similar way, we see that the total change in energy per
unit length for such a variation is

204
THERMAL PHYSICS
−ϵ · (ˆταβγ αβ + ˆτ βηγ βη + ˆτ ηαγ ηα) = 0,
(13.86)
which has been equated to zero as a condition for equilibrium. For arbitrary ϵ, the quantity
in parentheses must vanish, resulting in Eq. (13.83).
It is important to recognize that knowledge of the angles θα, θβ, and θη will allow one to
determine only the ratios of the quantities γ αβ, γ βη, and γ ηα. This can be seen by noting
that multiplication of each of these interfacial energies by some positive number would
result in a triangle similar, but different in size, to that depicted in Figure 13–4, so the
angles would be unchanged. However, if the ratios of γ αβ, γ βη, and γ ηα are speciﬁed, all
three angles are determined uniquely. This can be seen analytically by applying the law of
cosines to the triangle in Figure 13–4 to obtain
cos θα = (γ βη)2 −(γ ηα)2 −(γ αβ)2
γ ηαγ αβ
(13.87)
and similar expressions for cos β and cos η.
13.3.1 Contact Angle
The variational derivation that underlies the force balances represented by Eq. (13.83)
must be modiﬁed for anisotropic interfaces because the orientation of interfaces can
change locally when the position of the triple line is varied. This results in additional
torque terms. Nevertheless, the concept of force balances can be used to understand
contact angles made by ﬂuids with a rigid amorphous solid. Figure 13–5 shows a triple
junction between a liquid L and a gas g on a solid substrate s under conditions for which
we assume that γ ℓg, γ sg, and γ sℓcan be deﬁned.16 Then a variation that involves sliding
the triple line along the solid results in the equilibrium condition
γ sg = γ ℓg cos θ + γ sℓ,
(13.88)
Amorphous solid
Gas
Liquid
Liquid
Gas
θ
γsg
γsl
γlg
θ
γsg
γsl
γlg
Amorphous solid
FIGURE 13–5 Contact angle θ for two ﬂuids in contact with a rigid inert amorphous solid. On the left, θ is acute and
the liquid is said to wet the solid. On the right, θ is obtuse and the liquid does not wet the solid.
16These conditions could deviate considerably from the global equilibrium conditions discussed previously.
The solid should behave as if chemically inert, with no solubility of the substances of the liquid or the gas. The
gas could contain a substance insoluble in the liquid, and the vapor of the liquid can be in local equilibrium at
the solid-liquid interface provided there is negligible evaporation during some period of observation. See Gibbs
[3, p. 326] for further discussion.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
205
which may be solved to yield
cos θ = γ sg −γ sℓ
γ ℓg
.
(13.89)
Equation (13.89) is known as Young’s equation for the contact angle θ and represents a
balance of horizontal forces. Real values of θ only exist when the right-hand side has a
magnitude less than or equal to one, which requires |γ sg −γ sℓ| ≤γ ℓg. If θ exists and γ sg −
γ sℓ> 0, θ ≤π/2 and the liquid is said to wet the solid. For kerosene on glass, one has
θ ≈26◦. Complete wetting occurs for θ = 0, which is approximately the case for water on
clean glass. If θ exists and γ sg −γ sℓ< 0, θ > π/2 and the liquid does not wet the solid.
For mercury on glass, one has θ ≈140◦. As long as the solid remains rigid and inert, no
vertical variation of the contact line is possible, although it is generally supposed that the
solid provides a force of adhesion equal to γ ℓg sin θ to prevent the ℓg interface from pulling
away.
Although Young’s equation helps us understand the origin of the contact angle, its
derivation suffers from a lack of rigor. Moreover, experimentally measured contact angles
are difﬁcult to reproduce and can depend sensitively on impurities as well as surface
conditions of the solid. Nevertheless, the use of an empirically measured contact angle
can enable one to model liquid shapes in situations of practical importance.
13.4 Liquid Surface Shape in Gravity
The shape of a liquid surface in a uniform gravitational ﬁeld provides more insight
regarding the role of surface tension as well as methods of measuring surface tension
experimentally. We shall explore surface shapes for some two-dimensional problems and
for some three dimensional problems with axial symmetry.
In all cases we assume that Eq. (13.71) applies and drop the subscripts t with the
understanding that, strictly speaking, we are dealing with the surface of tension. For a
Cartesian coordinate system with a z axis antiparallel to gravity, we represent the liquid-
gas interface by the function z = z(x, y), in which case differential geometry (see Section
C.4 of Appendix C for a derivation) leads to a total curvature
K ≡1
R1
+ 1
R2
= −

zxx(1 + z2
y) −2zxzyzxy + zyy(1 + z2
x)

1 + z2x + z2y
3/2
,
(13.90)
where subscripts on z denote partial differentiation. We treat an isothermal case and single
component ﬂuids of densities ρg and ρℓand neglect any dependence of γ on the pressure
difference17 pℓ−pg. Moreover, we have d(pℓ−pg) = −(ρℓ−ρg)g dz. Over the small
distances that are important in capillary phenomena (see the capillary length deﬁned by
17This is equivalent to eliminating the terms C1δc1 + C2δc2 in Eq. (13.74) by choice of the surface of tension
or an equivalent approximation.

206
THERMAL PHYSICS
Eq. (13.73)) the densities ρℓand ρg can be taken to be constants.18 Thus, to an excellent
approximation,
pℓ−pg = −(ρℓ−ρg)gz + C,
(13.91)
where C is a constant equal to the value of pℓ−pg in the plane z = 0. Equation (13.71)
therefore becomes19
±

zxx(1 + z2
y) −2zxzyzxy + zyy(1 + z2
x)


1 + z2x + z2y
3/2
= −(ρℓ−ρg)gz
γ
+ C.
(13.92)
The ± sign in Eq. (13.92) must be chosen in accordance with the sign convention inherent
in Eq. (13.71), namely that for net positive K, the ﬂuid with the greater pressure is on the
side of the interface with the greater concavity. Moreover, z could be positive or negative
or even change sign in the domain of interest. One can treat shapes for which the liquid
is above the gas or below the gas. In many cases, z(x, y) will be a multiple valued function
of x and y so one must be careful to treat each portion of the surface separately. Explicit
choices of the correct sign are best left to examples.
13.4.1 Examples in Two Dimensions
For two-dimensional problems, there is only one ﬁnite radius of curvature and Eq. (13.92)
can be simpliﬁed to the form
zxx

1 + z2x
3/2 = 2
a2 z,
(13.93)
where a2 = 2γ/[(ρℓ−ρg)g]. In Eq. (13.93), the sign of the curvature term has been chosen
so that for z > 0 one must have zxx > 0, which will be the case for a gas at essentially
constant pressure pg on the upper concave side of an interface with a liquid on the lower
side whose pressure pℓ≤pg is decreasing with increasing z. Alternatively one could have
z < 0 and zxx < 0, which will be the case for a gas at essentially constant pressure pg on the
upper convex side of an interface with a liquid on the lower side whose pressure pℓ≥pg is
increasing with decreasing z. We substitute p = zx and note that zxx = p dp/dz to obtain
p dp
1 + p23/2 = 2
a2 z dz,
(13.94)
which may be integrated to yield
−
1

1 + p21/2 = z2
a2 −1;
z2 ≤a2.
(13.95)
Here, the constant of integration was evaluated by setting p = 0 for z = 0.
18For liquids, the compressibility is very small. For an ideal gas, ρ ∝exp(−mgz/kBT) and kBT/mg is the order
of magnitude of 10 m. Usually ρℓ≫ρg so we could neglect ρg but we retain it in the formulae which would still
be valid if the gas were replaced by a nearly incompressible liquid.
19In a gravitational ﬁeld, γ can depend implicitly on z (see Eqs. (613-614) of Gibbs [3, p. 281]) but this weak
dependence is usually negligible.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
207
Example Problem 13.4. Calculate the height zmax of the meniscus at the contact line for a
large plate of glass immersed vertically in a pool of liquid of density ρ for a contact angle 0 ≤
θ ≤π/2. This situation is depicted in Figure 13–6 (vertical plate case). Calculate the depression
if π/2 ≤θ ≤π.
Solution 13.4. Since the plate is large, we ignore end effects and treat the problem as two
dimensional. First we treat the case 0 ≤θ ≤π/2. At the line of contact with the glass, p = cot θ ≥
0 so (1 + p2)−1/2 = sin θ ≥0. Thus, Eq. (13.95) yields
zmax = a

1 −sin θ =

2γ
(ρℓ−ρg)g

1 −sin θ.
(13.96)
For π/2 ≤θ ≤π, p = cot θ ≤0 at the line of contact. For this contact angle, sin θ ≥0 but
cos θ ≤0. Equation (13.95) still applies and can be solved for z2 but we must now take the
negative square root to obtain
zmin = −a

1 −sin θ = −

2γ
(ρℓ−ρg)g

1 −sin θ.
(13.97)
For the same value of sin θ, the interface shapes for acute and obtuse contact angles are mirror
images of one another in the plane z = 0.
Unfortunately, the right-hand side of Eq. (13.95) changes sign at z = a so it cannot
hold for both z2 > a2 and z2 < a2. This can be handled by introducing the angle ψ where
sin ψ = dz/ds and cos ψ = dx/ds where s is arc length. Then Eq. (13.93) takes the form
dψ
ds = 2
a2 z.
(13.98)
In this parametric representation, ψ will continue to increase as z and s increase, so the
curvature dψ/ds will remain positive as z increases from zero, or remain negative as z
decreases from zero. We can now scale all lengths with a by deﬁning X = x/a, Z = z/a, and
S = s/a to get the following set of parametric equations:
1
2
3
4
5
6
7
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Z
θ
θ
X
X0
φ
FIGURE 13–6 Shape of the meniscus of a ﬂuid drawn up by a vertical plate at some distance X0 along the X axis. Of
course the actual curve stops at X0 where it makes the appropriate contact angle θ with the plate. The maximum
height, Zmax =
√
1 −sin θ, occurs at the line of contact. By removing the vertical plate, the same curve can be used
to treat a plate that makes an angle φ with the X axis. If the contact angle is obtuse, one uses a downward sloping
curve that is the mirror reﬂection Z →−Z. ψ is the angle made by a tangent to the curve and the X axis.

208
THERMAL PHYSICS
dψ
dS = 2Z;
(13.99)
dX
dS = cos ψ;
(13.100)
dZ
dS = sin ψ.
(13.101)
One could integrate the set Eqs. (13.99)–(13.101) by starting from some contact angle
where cos ψ = sin θ, sin ψ = ± cos θ, and Z = ± (1 −sin θ)1/2, but a more useful approach
is to begin at a very small value Z = ϵ at X = Z = S = 0 and to integrate numerically.
This gives a universal curve that can be stopped at any value of X that corresponds to the
correct contact angle. To get started, however, one needs a compatible starting value of ψ.
This can be obtained by combining Eqs. (13.99) and (13.101) to obtain dψ/dZ = 2Z/ sin ψ
which can be readily integrated to give cos ψ = 1−Z2. Thus, the starting values for ψ satisfy
cos ψ = 1 −ϵ2 and sin ψ = ϵ(2 −ϵ2)1/2. The result of numerical integration is shown in
Figure 13–6.
Equations (13.96) and (13.97) can be generalized for a large plate that makes an angle
φ with the surface of the bulk ﬂuid, as shown in Figure 13–6. We still have the solution
Z2 = 1 −cos ψ. For an acute contact angle θ, we have ψ = π −(φ + θ) ≥0 so instead of
Eq. (13.96) we have
zmax = a

1 + cos(φ + θ).
(13.102)
In Eq. (13.102), the values of φ are limited because we need ψ ≥0 which requires φ ≤π −θ.
In fact, when φ = π −θ, zmax = 0 and the interface remains ﬂat. The opposite limit is φ = 0,
which yields zmax = a
√
1 + cos θ. As is evident from Figure 13–6, a value of φ very near to
zero corresponds to a case where the X coordinate of the intersection of the plate with
Z = 0 tends to X →∞. In other words, moving the plate toward φ = 0 “squeezes” the ﬂuid
above z > 0 in the negative X direction.
For an obtuse contact angle θ′ > π/2, the corresponding relation at the contact line is
ψ = π −(φ + θ′) ≤0. Thus zmin = −a√1 + cos(φ + θ′). For θ = π −θ′ and φ →π −φ, we
have zmin = −zmax where the latter is given by Eq. (13.102).
The detailed shape of the meniscus for two-dimensional problems can be expressed
analytically in terms of incomplete elliptic integrals but such a solution is not very
enlightening because those integrals must ultimately be evaluated numerically. With the
availability of fast computers and software such as NDSolve in MathematicaTM, it is a
simple matter to integrate a ﬁrst order system such as Eqs. (13.99)–(13.101) numerically
and then use a parametric plotting routine to display the result. A number of interesting
solutions can be obtained by choosing ψ = α at the origin X = Z = S = 0, where 0 ≤α ≤π.
In view of Eq. (13.99), the curvature is zero at Z = 0 and changes sign along any curve that
passes through Z = 0, where the curve has an inﬂection. Such an inﬂection point might
not appear on a curve of physical interest, but portions of the remainder of the curve may
be relevant. Since the equations are nonlinear, the behavior as α changes is quire diverse
as illustrated in the next few ﬁgures.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
209
-2
-1
1
2
–1
-0.5
0.5
1
Z
X
-0.4
-0.2
0.20.4
-1
-0.5
0.5
1
Z
X
FIGURE 13–7 Two-dimensional interfaces obtained by numerical integration of the system Eqs. (13.99)–(13.101) for
α = 0.25 (left) and α = 0.86 (right). At about α = 0.86, the upper and lower loops meet at the origin. For either
value of α, the upper loop could represent a two-dimensional bubble and the lower loop could represent a two-
dimensional drop. Either of these could be cut off by horizontal surfaces at appropriate contact angles. A portion of
the curve for α = 0.25 could represent the interface between two vertical plates, the right plate wetted (acute con-
tact angle) and the left plate not wetted (obtuse contact angle) and the inﬂection somewhere between the plates.
-1
-0.5
0.5
1
-1
-0.5
0.5
1
Z
X
-1
-0.5
0.5
1
-1
-0.5
0.5
1
Z
X
FIGURE 13–8 Two-dimensional interfaces obtained by numerical integration of the system Eqs. (13.99)–(13.101) for
α = 1.09 (left) and α = 1.20 (right). The loops that nearly coalesced for α = 0.86 separate. For α = 1.20, portions of
the curve can be used to represent a two-dimensional bubble or a two-dimensional drop with a neck. For α = 1.09,
the neck nearly vanishes.
Figure 13–7 shows some results for a small and intermediate value of α. The nature
of the curve changes for about α = 0.86 where the loops coalesce. Only a portion of any
curve will be needed to satisfy wetting conditions at bounding surfaces. Part of an upper
loop could represent a two-dimensional bubble and part of a lower loop could represent a
two-dimensional drop. As α increases, the character of the solution changes, as illustrated
in Figure 13–8. Portions of curves could represent a two-dimensional bubble or a two-
dimensional drop with a neck. Curves for still larger values of α are depicted in Figure
13–9. By using an obtuse angle α, one can rename variables to get equations of the same
form as Eqs. (13.99)–(13.101) except for a relative minus sign in Eq. (13.99). Portions of
these curves could represent an inverted meniscus (liquid on top) between wetted and
non-wetted vertical plates with the inﬂection occurring between the plates.

210
THERMAL PHYSICS
-1
-0.5
0.5
1
-1
-0.5
0.5
1
Z
X
-2
-1
1
2
-0.4
-0.2
0.2
0.4
Z
X
FIGURE 13–9 Two-dimensional interfaces obtained by numerical integration of the system Eqs. (13.99)–(13.101) for
α = π/2 = 1.5708 (left) and α = 3π/4 = 2.3562 (right). The neck seen for α = 1.20 vanishes at α = π/2 where the curve
has vertical points of inﬂection. For α = 3π/4 the inﬂection is no longer vertical and the amplitude has decreased.
The amplitude would decrease to zero at α = π. Portions of curves that contain the inﬂection could represent an
inverted meniscus (liquid on top) between wetted and non-wetted vertical plates with the inﬂection occurring
between the plates. Other portions that do not contain the inﬂection could represent two-dimensional bubbles or
drops.
13.4.2 Examples in Three Dimensions
For three-dimensional interfaces, both principal curvatures, 1/R2 and 1/R2, must be
taken into account. In the general case, one must return to Eq. (13.92) which presents
considerable difﬁculty. We therefore explore brieﬂy the special case where there is axial
symmetry about the z axis. In that case, z depends only on r =

x2 + y2, so

zxx(1 + z2
y) −2zxzyzxy + zyy(1 + z2
x)


1 + z2x + z2y
3/2
=
zrr

1 + z2r
3/2 + 1
r
zr

1 + z2r
1/2 .
(13.103)
The individual terms on the right-hand side of Eq. (13.103) are principal curvatures, the
ﬁrst being the curvature in the r, z plane and the second being in a perpendicular plane.
The center of curvature of this second curvature lies on the z axis, as is well known.
The problem associated with z being a multiple-valued function on different parts of the
surface can be alleviated by introducing the angle ψ between the tangent to the surface
and the r axis, speciﬁcally by dr/ds = cos ψ and dz/ds = sin ψ, where s is arc length
measured from the origin r = z = 0. With this parametric representation, the right-hand
side of Eq. (13.103) takes the form
dψ
ds + sin ψ
r
,
(13.104)
which is valid even when z is a multiple-valued function of r.
For a pendant drop, which is a liquid drop hanging from a syringe and surrounded by
a gas, we take z = 0 at the bottom of the drop so z is positive on the actual interface.

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
211
In Eq. (13.92), the constant C = 2/R0 > 0 where R0 is the radius of curvature at the drop
tip,20 so we obtain
dψ
ds + sin ψ
r
= −2 z
a2 + 2
R0
(13.105)
with 0 ≤ψ ≤π and a2 = 2γ/[(ρℓ−ρg)g]. For a sessile drop, which is a liquid drop resting
on a solid surface and surrounded by a gas, we take z = 0 to correspond to the maximum
height of the drop, so z will be negative on the actual interface and C = −2/R0 < 0. Then
Eq. (13.92) becomes
dψ
ds + sin ψ
r
= −2 z
a2 −2
R0
(13.106)
with 0 ≥ψ ≥−π. Rather than work with negative z and ψ in Eq. (13.106), one can make
the transformation z →−z and ψ →−ψ and then multiply the equation through by −1
to get an equation for the shape of a “sessile bubble.” Then one can combine this equation
with Eq. (13.105) to obtain
dψ
ds + sin ψ
r
= ±2 z
a2 + 2
R0
;
−for a pendant drop
+ for a sessile bubble
(13.107)
with z ≥0 and 0 ≤ψ ≤π.
Equation (13.107) is a nonlinear differential equation that must be integrated numeri-
cally to determine the detailed shape of the drop. To do this, we introduce dimensionless
length variables R := r/R0, Z := z/R0, and S : = s/R0 to obtain the following set of
parametric equations:
dψ
dS = 2 −sin ψ
R
± 2R2
0
a2 Z;
(13.108)
dR
dS = cos ψ;
(13.109)
dZ
dS = sin ψ.
(13.110)
This set of ﬁrst order equations can be integrated numerically from starting values ψ = 0,
Z = S = 0 and the limiting value (sin ψ)/R →1 as R →0 to produce a shape that
depends on the shape parameter R2
0/a2. By ﬁtting to an experimentally measured shape
and measuring the value of R0, one can determine the capillary length a, and hence γ . For
a very small drop or bubble, R02/a2 ≪1, the last term in Eq. (13.108) becomes very small
and the shape becomes nearly spherical. For a very large drop or bubble, R02/a2 ≫1 and
the shapes will be nearly ﬂat at their tips.
Several sessile shapes computed by numerical integration of Eqs. (13.108)–(13.110)
with the plus sign are shown in Figure 13–10. Of course the actual shapes stop when they
20At the drop tip, the second term in Eq. (13.104) is not easy to evaluate because r →0 but also sin ψ →0.
By symmetry, both radii of curvature are equal at the drop tip, so the total curvature there is just twice the
curvature in the r, z plane. Alternatively, one can see this from the Cartesian representation on the left-hand
side of Eq. (13.103).

212
THERMAL PHYSICS
0.2
0.4
0.6
0.8
0.25
0.5
0.75
1
1.25
1.5
Z
R
0.5
1
1.5
2
2.5
3
3.5
0.5
1
1.5
2
2.5
3
3.5
z
r
FIGURE 13–10 Curves on the left represent sessile shapes in dimensionless coordinates R, Z scaled with the radius of
curvature R0 at the drop tip. The top curve is for R2
0/a2 = 0.1 and the middle and bottom curves are for R0 larger by
factors of 2.5 and 5, respectively. Note that the shape becomes less spherical for larger R0. The curves on the right
(which occur in inverted order) are rescaled to reﬂect true distance in units of a/
√
10 = a/3.16, about 1.74 mm for
water. The orientation shown is for sessile bubbles; if they are turned upside down they represent sessile drops.
0.5
1
1.5
2
2.5
3
1
2
3
4
5
Z
R
1
2
3
4
5
6
7
1
2
3
4
5
6
7
z
r
FIGURE 13–11 Curves on the left represent pendant shapes in dimensionless coordinates R, Z scaled with the radius
of curvature R0 at the drop tip. The top curve is for R2
0/a2 = 0.225, the middle curve for R2
0/a2 = 0.300 and bottom
curve for R2
0/a2 = 0.625. Note that the shape develops a neck for approximately R2
0/a2 < 0.300. The curves on the
right (that occur in the same order) are rescaled to reﬂect true distance in units of a/
√
10 = a/3.16, about 1.74 mm for
water. The orientation shown is for pendant drops; if they are turned upside down they represent pendant bubbles.
reach some bounding surface. For the orientation shown, the shapes represent sessile
bubbles attached to the top of some container. If they are turned upside down, they
represent sessile drops that rest on a bottom surface.
Several pendant shapes computed by numerical integration of Eqs. (13.108)–(13.110)
with the minus sign are shown in Figure 13–11. In this case, a sufﬁciently small value of

Chapter 13 • Thermodynamics of Fluid-Fluid Interfaces
213
approximately R2
0/a2 < 0.300 gives rise to a drop shape with a neck. As shown, the curves
pertain to pendant drops hanging from a syringe; if they are turned upside down they
represent “pendant bubbles” that could be produced by means of a syringe that injects
gas at the bottom of a liquid.
For a discussion of many other possible shapes of three-dimensional interfaces, includ-
ing shapes that do not intersect the z axis, which is the axis of revolution, see Princen [30,
chapter 1].

This page intentionally left blank 

14
Thermodynamics of Solid-Fluid
Interfaces
In this chapter, we take up solid-ﬂuid interfaces which are regions of discontinuity
between an amorphous solid or a crystal and a ﬂuid. This is an advanced topic whose
detailed treatment requires some knowledge of elasticity tensors and surface differential
geometry. Those not familiar with elasticity tensors can skip Sections 14.1.1 and 14.1.2, the
results of which are not used in the remainder of the chapter. Needed aspects of surface
differential geometry are covered in Appendix C.
Many aspects of solid-ﬂuid interfaces are the same as those for ﬂuid-ﬂuid interfaces
treated in Chapter 13. Nevertheless, some aspects are very different because solids are
quite rigid and can support states of shear over considerable periods of time. In other
words, they can behave elastically, except at very high temperatures where they can
deform plastically by creep. Consequently, the mechanical properties of solids must be
described in terms of stress and strain tensors. Moreover, crystalline solids are anisotropic,
which results in anisotropy of the interfacial free energy, γ . Solid surfaces can change their
areas in two distinct ways, by stretching and by accretion at their boundaries. Therefore,
they must be characterized by strain variables absent for a ﬂuid.
We begin by considering planar solid-ﬂuid interfaces, essentially parallel to our treat-
ment of ﬂuid-ﬂuid interfaces but with new complications, including the fact that the
interfacial free energy can be referenced to the area of either a stretched or an unstretched
interface. The corresponding Gibbs adsorption equation contains the surface stress tensor
that must be deﬁned carefully with respect to the state of strain of the solid. This surface
stress tensor is anisotropic for a crystal. Anisotropy of γ is treated by means of an auxiliary
vector ﬁeld, the ξ-vector ﬁeld, introduced by Gibbs, whose properties were developed by
Hoffman and Cahn. Anisotropy gives rise to torques that arise when the orientation of
a surface element is changed. These torques affect the equilibrium conditions at triple
junctions where phases meet. The ξ-vector formalism can be extended to orientations
for which the derivatives of γ are not well deﬁned by identifying ξ with the diameter
of a Herring sphere used to determine the Gibbs-Wulff equilibrium shape of a small
crystal. Large planar crystal surfaces whose surface orientations are not present on the
equilibrium shape can lower their surface free energy by faceting. General conditions for
equilibrium at curved surfaces of crystals, described parametrically, are derived by using a
variational technique. The equilibrium shape is shown to be similar to that of a polar plot
of the ξ-vector, suitably truncated to form a convex body. By using a Monge representation
of a crystal surface, the Herring formula for local equilibrium is derived. It is shown that
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00014-4
215
Copyright © 2015 Elsevier Inc. All rights reserved.

216
THERMAL PHYSICS
the surface free energy, per unit area of a reference plane from which the surface height is
measured, is the Legendre transform of the equilibrium shape, and vice versa.
Finally, we make a few remarks about solid-solid interfaces.
14.1 Planar Solid-Fluid Interfaces
We now treat planar interfaces, such as depicted in Figure 13–1, except that one phase is
a solid (superscript s) and the other is a ﬂuid (superscript F). The bulk solid is assumed
to be homogeneous; in particular, it is in a state of homogeneous stress and strain. If the
solid is a crystal, we treat a constrained equilibrium such that the planar interface has a
deﬁnite direction with respect to the crystallographic axes. Such an interface might not
be stable with respect to breakup into a hill and valley structure (made up of facets) but
we will examine this possibility later in Section 14.4. For amorphous solids, stability of a
planar interface with respect to faceting is not an issue.
When a bulk solid is in equilibrium at temperature T with a bulk ﬂuid across a
hypothetical surface element with normal ˆn pointing from solid to ﬂuid, the following
boundary conditions are valid at that surface element [31–33]:
us
v −Tss
v −

i
μF
i ρs
i = −pF;
(14.1)

α
nβσαβ = −pFnβ,
(14.2)
where usv is the internal energy density of the solid, with α and β representing Cartesian
coordinates, ssv is the entropy density of the solid, ρs
i is the partial density of chemical
component i in the solid, σαβ is the symmetric Cauchy stress tensor in the solid, pF
is the pressure of the ﬂuid, and μF
i is the chemical potential of component i in the
ﬂuid. Equation (14.2) is just a balance of forces at the surface element. If we take the
surface element to be perpendicular to the z-axis, it becomes σzz = −pF, σxz = σyz = 0,
consistent with the fact that a ﬂuid in equilibrium cannot support shear. Equation (14.1)
is a thermodynamic condition. If the mobility of the chemical components of the solid was
unrestricted and the solid was in chemical equilibrium,1 its chemical potentials μs
i = μF
i .
If the solid behaved like a ﬂuid, it would be in a state of hydrostatic stress, so σαβ = −psδαβ
and the left-hand side of Eq. (14.1), via its Euler equation, would be the negative of its
1Generally speaking, solids are quite rigid and mobility of chemical components within them is quite slow,
although not zero. On practical time scales, mobility of such components can sometimes be ignored. This
leads to the concept of a Gibbs solid in which the “substance of the solid” is ﬁxed and immobile. Alternatively,
movement of solid components can be allowed to occur but restricted to obey certain rules. For example, in
a Larché-Cahn (LC) solid [31, 32], components that can only reside on a lattice are allowed to move only by
virtue of exchange with point defects, namely lattice vacancies. For the LC solid, and with vacancies assumed to
be a conserved species within a single crystal, LC deﬁne diffusion potentials Mi that are formally equal to the
differences of chemical potentials of chemical components and chemical potentials of vacancies, calculated in
that extended description. So for an LC solid, their Mi would be equal to our μs
i.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
217
pressure ps. In that case, Eqs. (14.1) and (14.2) would coalesce and become simply ps = pF.
But a solid in a general state of stress has no such simple Euler equation.
For a homogeneous solid, however, the left-hand side of Eq. (14.1) is uniform (indepen-
dent of position) so one can multiply by the volume of the solid V s to obtain
Us −TSs −μF
i Ns
i = −pFV s,
pseudo-Euler, homogeneous cylindrical solid,
(14.3)
which resembles an Euler equation except that μF
i and pF pertain to the ﬂuid. If such a
homogeneous solid were surrounded by a ﬂuid, Eq. (14.2) would compel the solid to be in
a state of hydrostatic stress. On the other hand, for a constrained equilibrium in which
a homogeneous cylindrical solid that is only in contact with the ﬂuid across a planar
interface perpendicular to the generators of its cylindrical surface, Eq. (14.3) applies and
the solid can be in a state of nonhydrostatic stress. The fact that Eq. (14.3) also applies to
a homogeneous solid and a homogeneous liquid separated by an actual planar region of
discontinuity can be seen by considering a layer bounded by imaginary planes located in
homogeneous phases on opposite sides of the region of discontinuity, just as was done
for ﬂuid-ﬂuid interfaces. Then one can study variations in which the layer is unchanged
but translates intact in either direction perpendicular to the planes that bound it. For such
variations, changes of the homogeneous phases are the same as if the layer did not exist
and were replaced by a mathematical plane.
Armed with the pseudo-Euler Eq. (14.3), we can deﬁne an excess pseudo-Kramers
potential for a system having a homogeneous solid and a homogeneous liquid and a
planar solid-ﬂuid planar Gibbs dividing surface by means of the equation
K xs = U −TS −

i
μF
i Ni −(Us −TSs −μF
i Ns
i ) −(UF −TSF −μF
i NF
i )
= Uxs −TSxs −

i
μF
i Nxs
i
= U −TS −

i
μF
i Ni + pFV ,
(14.4)
where the last expression is clearly independent of the location of the dividing surface that
separates the homogeneous solid from the homogeneous ﬂuid. Here, Uxs = U −Us −UF,
Sxs = S −Ss −SF, and Nxs
i
= Ni −Ns
i −NF
i but V xs = V −V s −V F = 0, since the bulk
phases meet at the dividing surface. Then we can deﬁne an excess potential per unit area
by dividing by a suitable area. Following Cahn [28] or [29, pp. 379-399], we distinguish two
cases, γ obtained by dividing by the area A of the actual strained state and γ0 obtained
by dividing by the area A0 of a homogeneous reference state of the solid, by deﬁnition the
state of zero strain. Speciﬁcally,
γ A = γ0A0 = U −TS −

i
μF
i Ni + pFV = Uxs −TSxs −

i
μF
i Nxs
i .
(14.5)
We could also use these same deﬁnitions of γ and γ0 for a layer model, similar to that
for the ﬂuid-ﬂuid case, Eqs. (13.33)–(13.36), which gives
γ A = γ0A0 = U −TS −

i
μF
i Ni + pFV = UL −TSL −

i
μF
i NL
i + pFV L,
(14.6)

218
THERMAL PHYSICS
where the bulk phases only extend to the imaginary planes that bound the layer, so V L =
V −V s −V F ̸= 0. As in the ﬂuid case, most of these excess quantities and layer quantities
have no physical meaning because they depend on the location of the dividing surface
or the bounding planes, but their combinations used to form γ or γ0 are independent of
these locations and do have physical meaning.
We treat the more general layer model ﬁrst and then indicate the slight modiﬁcation
needed to treat the dividing surface model. To do this, we adopt an equation for dUL of
the form
dUL = TdSL −pFdV L +

i
μF
i dNL
i + A

αβ
f L
αβdεαβ,
(14.7)
which is similar to Eq. (13.41) except for the last term. This last term accounts for stretching
of the interface that accompanies straining of the bulk solid and replaces γ dA for a
ﬂuid-ﬂuid interface. Here, the Cartesian indices α and β take on the values x and y
for an interface perpendicular to the z-direction, as above. The 2 × 2 tensor εαβ is a
symmetric strain tensor (see Eq. (14.17)) measured in the bulk homogeneous solid and f L
αβ
is a symmetric stress tensor. This stress tensor must be consistent with the symmetry of
the underlying solid, anisotropic if crystalline and isotropic if amorphous.
14.1.1 Adsorption Equation in the Reference State
By combining Eq. (14.7) with the differential of Eq. (14.6), and recognizing that dA0 = 0,
we obtain
dγ0 = −SL
A0
dT + V L
A0
dpF −

i
NL
i
A0
dμF
i + A
A0

α,β
f L
αβ dεαβ,
(14.8)
which is the counterpart to the Gibbs adsorption equation for ﬂuids, Eq. (13.44). Similar
to the ﬂuid case, the variables T, μF
i , pF, and εαβ are not independent because of the
equations of bulk equilibrium of the solid and ﬂuid phases. Two of these can be chosen
as dependent variables and their differentials expressed in terms of the differentials of the
others, most elegantly by using the determinant formalism discussed in terms of Cahn’s
layer model of ﬂuids in Section 13.1.3. To do this, we need a Gibbs-Duhem equation for
the ﬂuid, which is just
SF dT −V F dpF +

i
NF
i dμF
i = 0,
(14.9)
but also an equivalent Gibbs-Duhem equation for a cylinder of homogeneous bulk solid
in equilibrium with that ﬂuid across a plane perpendicular to the z-axis. This equation can
be written in the form
Ss dT −V s dpF +

i
Ns
i dμF
i −V s 
αβ
σ lat
αβ dεαβ = 0,
(14.10)
where

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
219
σ lat
α,β ≡

κ,λ
∂x′
α
∂xκ
(σκλ + pFδκλ)
∂x′
β
∂xλ
.
(14.11)
The last term in Eq. (14.10), in which all sums are only over x and y coordinates, is present
because for a cylindrical solid in a nonhydrostatic homogeneous state of stress, the forces
needed to stretch it laterally are different from those needed to stretch it longitudinally.
Here, σκλ is the Cauchy stress tensor of the homogeneous solid, the coordinates x′ are those
of a hydrostatic reference state, and the coordinates x are those of the actual state. If the
solid were in a state of hydrostatic stress in its actual state, σκλ = −pFδκλ and the last term
would vanish. We can therefore write (with a notation similar to Eq. (13.46))
dγ0 = −[(SL/A0)/XY] dT + [(V L/A0)/XY] dpF −
κ

i=1
[(NL
i /A0)/XY] dμF
i +

α,β
f C
αβ dεαβ,
(14.12)
where X and Y are the extensive conjugates to two distinct intensive variables of the set T,
μF
i , pF that are chosen to be dependent variables.2 As with ﬂuids, the two coefﬁcients of
the dependent intensive variables will vanish. Here,
f C
αβ ≡1
A0

Af L
αβ
XL Y L
V sσ lat
αβ
Xs
Y s
0
XF Y F


Xs
Y s
XF Y F

(14.13)
and is independent of the choice of the planes that bound the layer, although it does
depend on the choice of independent variables. Consequently,
 ∂γ0
∂εαβ

A0 and κ independent intensive variables
= f C
αβ.
(14.14)
The 2 × 2 tensor f C
αβ is the surface stress deﬁned by Cahn [28] or [29, pp. 379-399]. As he
points out, the application of tractions to the bulk solid usually produces only a small
shift in the other intensive variables and can frequently be ignored. If the actual state of
the solid is hydrostatic, σ lat
αβ = 0 and we have simply f C
αβ = (A/A0)f L
αβ. If the actual state
is taken to be a state of zero strain (coincident with a hydrostatic reference state), then
f C
αβ = f L
αβ.
Note that Eq. (14.12) also holds formally for the Gibbs excess quantities with the
understanding that V L = 0, which does not require the coefﬁcient of dpF to be zero unless
either X or Y is chosen to be V.
2We retain εαβ as independent variables because the application of tractions to the solid makes only a small
second-order change to the relationships among the set T, μF
i , pF. An estimate by Sekerka and Cahn [34] for a
single component Gibbs solid shows that the equilibrium temperature would be lowered by about 10−3 K for a
shear stress of the order of 10 MPa.

220
THERMAL PHYSICS
14.1.2 Adsorption Equation in the Actual State
We now examine the parallel development when γ is deﬁned with reference to the area
A of the actual state. For the layer model, we combine the differential of Eq. (14.6) with
Eq. (14.7) to obtain
dγ = −SL
A dT + V L
A dpF −

i
NL
i
A dμF
i +

α,β
f L
αβdεαβ −γ dA
A .
(14.15)
From a well-known relation [35, p. 16] in elasticity theory with coordinates x in the actual
state and x′ in the reference state, one has (in a 2 × 2 space)
dA
A = d ln A = d ln det

∂xα
∂x′
β

=

κλ
∂x′
λ
∂xκ
d∂xκ
∂x′
λ
=

κλν
∂x′
λ
∂xκ
∂x′
ν
∂xκ
dελν,
(14.16)
where
ελν = 1
2
∂xρ
∂x′
λ
∂xρ
∂x′ν
−δλν
	
= 1
2

∂uν
∂x′
λ
+ ∂uλ
∂x′ν
+

ρ
∂uρ
∂x′
λ
∂uρ
∂x′ν

(14.17)
is the full nonlinear strain tensor and u = x −x′ is the displacement. Thus, the last two
terms in Eq. (14.15) can be combined to yield

α,β
f L
αβdεαβ −γ dA
A =

α,β

f L
αβ −γ

κ
∂x′
α
∂xκ
∂x′
β
∂xκ

dεαβ.
(14.18)
Then the counterpart to Eq. (14.12) is
dγ = −[(SL/A)/XY] dT + [(V L/A)/XY] dpF −
κ

i=1
[(NL
i /A)/XY] dμF
i +

α,β
f A
αβ dεαβ,
(14.19)
where
f A
αβ ≡1
A

A[f L
αβ −γ 
κ(∂x′
α/∂xκ)(∂x′
β/∂xκ)] XL Y L
V sσ lat
αβ
Xs
Y s
0
XF Y F


Xs
Y s
XF Y F

.
(14.20)
Consequently
 ∂γ
∂εαβ

A0 and κ independent intensive variables
= f A
αβ.
(14.21)
If the actual state of the solid is chosen to be hydrostatic, we have noted previously that
σ lat
αβ = 0, in which case f A
αβ = f L
αβ −γ 
κ(∂x′
α/∂xκ)(∂x′
β/∂xκ). If the actual state of the bulk
solid is coincident with a hydrostatic reference state, then simply f A
αβ = f L
αβ −γ δαβ.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
221
Returning to the general case, we can expand the determinant in the numerator of
Eq. (14.20) to obtain
Af A
αβ =

Af L
αβ
XL Y L
V sσ lat
αβ
Xs
Y s
0
XF Y F


Xs
Y s
XF Y F

−Aγ

κ
∂x′
α
∂xκ
∂x′
β
∂xκ
.
(14.22)
Then comparison with Eq. (14.13) shows that
f C
αβ = A
A0

γ

κ
∂x′
α
∂xκ
∂x′
β
∂xκ
+ f A
αβ

,
(14.23)
which can also be written
∂γ0
∂εαβ
= A
A0

γ

κ
∂x′
α
∂xκ
∂x′
β
∂xκ
+ ∂γ
∂εαβ

.
(14.24)
In the case that the actual state of the bulk solid is coincident with a hydrostatic reference
state, Eq. (14.24) becomes
∂γ0
∂εαβ
= γ δαβ + ∂γ
∂εαβ
.
(14.25)
If the solid behaved like a ﬂuid, then ∂γ/∂εαβ = 0 and the surface stress would be isotropic
and equal to γ , as we found previously for a ﬂuid-ﬂuid interface.
As Cahn points out, the relationship Eq. (14.25) can be based on the fact that γ0A0 = γ A
and the geometrical relationship of A to A0 because of strain. Then by using A0dγ0 = γ dA+
dγ and Eq. (14.16), one would obtain the full nonlinear result Eq. (14.24). For small strain,
one has simply A/A0 = 1 + 
ν ενν so
∂γ0
∂εαβ
≈

1 +

ν
ενν
 
γ (δαβ −2εαβ) + ∂γ
∂εαβ
	
≈γ δαβ + ∂γ
∂εαβ
(14.26)
to lowest order. This is a linearized version of Eq. (14.24) and happens to agree with the
exact Eq. (14.25) for the special states chosen in that case. So Eq. (14.23) and equivalently
Eq. (14.24) are always true for geometrical reasons, even in the nonlinear case. Note,
however, that these derivatives of γ0 and of γ are only simply related to f L
αβ when σ lat
αβ is
zero unless the actual bulk solid is hydrostatic or the small effect of shear stress on the
bulk equilibrium (embodied by V sσ lat
αβ ) is negligible.
14.2 Anisotropy of γ
In Section 14.1, we deﬁned the excess free energy γ for a constrained equilibrium such
that the planar interface of a homogeneous bulk crystal in equilibrium with a ﬂuid has
a deﬁnite direction with respect to the crystallographic axes. In this section, we treat the

222
THERMAL PHYSICS
explicit dependence of γ on the interface orientation, which we characterize by its unit
normal vector ˆn. Thus we write γ ( ˆn), where ˆn points from crystal3 to ﬂuid, and in which
all other variables that γ depends on have been suppressed.4 Since n2
x + n2
y + n2
z = 1,
the components of ˆn are not independent, so one cannot take partial derivatives with
respect to one of them while holding the other two constant. Therefore, to treat the angular
derivatives of γ (n) in a manner that is independent of any coordinate system, we resort to
an auxiliary vector ﬁeld ξ that was introduced by Gibbs [3] and whose properties were
developed in detail by Hoffman and Cahn [36, 37].
In order to facilitate the deﬁnition of ξ, we introduce a three-dimensional vector ﬁeld
P := P ˆn,
(14.27)
where the magnitude P of P can vary. Then one deﬁnes a function
˜γ (P) := Pγ (ˆn) = Pγ (P/P),
(14.28)
which is a homogeneous function of degree 1 in the components Pα of P. Thus, by means
of the Euler theorem of homogeneous functions, one can take partial derivatives of ˜γ (P)
to obtain5

α
Pα
∂˜γ (P)
∂Pα
= ˜γ (P).
(14.29)
We now deﬁne the vector ﬁeld
ξα(ˆn) := ∂˜γ (P)
∂Pα
(14.30)
or more succinctly
ξ(ˆn) := ∇P ˜γ (P) = ∇P[Pγ (P/P)],
(14.31)
where the operator ∇P is the gradient in P space. The fact that ξ depends only on ˆn follows
because it is a homogenous function of degree 0 in the Pα. Then combining Eqs. (14.29)
and (14.30) gives ˜γ = P · ξ from which
n · ξ = γ (ˆn).
(14.32)
Moreover,
d ˜γ = ξ · dP + P · dξ,
(14.33)
but also
d ˜γ =

α
∂˜γ (P)
∂Pα
dPα = ξ · dP,
(14.34)
3For some crystals, γ ( ˆn) ̸= γ (−ˆn) in which case one needs to distinguish which interface is being considered.
4These are the independent variables that appear in Eq. (14.19). In this section, we write dγ for brevity but it
should be understood that the only variable that is allowed to change is the orientation ˆn.
5For now we assume that γ ( ˆn) is differentiable with continuous derivatives and later discuss the implications
of discontinuities in its derivatives.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
223
by Eq. (14.30), so the second term on the right of Eq. (14.33) must vanish. Thus
ˆn · dξ = 0.
(14.35)
By combining Eq. (14.35) with the differential of Eq. (14.32), we deduce that
dγ (ˆn) = ξ · dˆn.
(14.36)
Equation (14.32) plus either Eq. (14.35) or Eq. (14.36) completely deﬁnes the vector
ﬁeld ξ( ˆn), although Eq. (14.31) is convenient for its actual calculation. We observe that
the normal component of ξ is γ ( ˆn) itself and since dˆn is perpendicular to ˆn, we see that
the tangential component of ξ shows how γ ( ˆn) varies with orientation.
Example Problem 14.1. For a crystal having cubic symmetry,
γ (ˆn) = γ0 + γ4(n4
x + n4
y + n4
z),
(14.37)
where γ0 and γ4 are constants, represents the lowest order anisotropy in the components of
ˆn. No anisotropy is possible to second order because n2x + n2y + n2z = 1. Calculate ξ(ˆn) and
demonstrate explicitly that Eqs. (14.32), (14.35), and (14.36) are satisﬁed.
Solution 14.1. We have
˜γ (P) = γ0P + γ4
(P4
x + P4
y + P4
z)
P3
,
(14.38)
so
∇P ˜γ (P) = γ0
P
P −3γ4
P
P
(P4
x + P4
y + P4
z)
P4
+ 4γ4
1
P3 (P3
x ˆi + P3
y ˆj + P3
z ˆk).
(14.39)
Thus,
ξ(ˆn) = γ0 ˆn −3γ4 ˆn(n4
x + n4
y + n4
z) + 4γ4(n3
x ˆi + n3
y ˆj + n3
z ˆk)
= ˆn γ (ˆn) + 4γ4

(n3
x ˆi + n3
y ˆj + n3
z ˆk) −ˆn(n4
x + n4
y + n4
z)

,
(14.40)
where the term with square brackets in the second line is the part of ξ that is perpendicular to ˆn.
Obviously Eq. (14.32) is satisﬁed. We calculate
dξ = γ0 d ˆn −3γ4(n4
x + n4
y + n4
z) d ˆn −12γ4 ˆn(n3
x dnx + n3
y dny + n3
z dnz)
+ 12γ4(n2
x ˆi dnx + n3
y ˆj dny + n3
z ˆk dnz).
(14.41)
When we dot ˆn into dξ, the ﬁrst two terms vanish because ˆn is perpendicular to d ˆn and
the remaining terms cancel one another, so Eq. (14.35) is satisﬁed. Of course d ˆn = ˆi dnx +
ˆj dny + ˆk dnz so
ξ · d ˆn = 4γ4(n3
x dnx + n3
y dny + n3
z dnz) = dγ ,
(14.42)
and Eq. (14.36) is satisﬁed.

224
THERMAL PHYSICS
ξt
ˆt
ˆt
ˆtξ
ψ
ˆn
dˆn
dθt
(a)
(b)
FIGURE 14–1 (a) Illustration of dθt, the angle between the surface normal ˆn and n + dˆn. The unit vector ˆt is in the
direction of dˆn. (b) View looking along −ˆn showing the relationship of ˆt to the unit vector ˆtξ that lies along the
tangential component ξt of the ξ-vector.
Let dθt be the angle between ˆn + d ˆn and ˆn and ˆt be a unit vector tangent to dˆn, as
illustrated in Figure 14–1. Then
dˆn = ˆt dθt
(14.43)
and Eq. (14.36) can be written
∂γ (ˆn)
∂θt
= ξ · ˆt = ξt · ˆt,
(14.44)
where the part of ξ that is tangential to the surface is
ξ t = ξ −ˆn(ˆn · ξ) = ξ −ˆnγ .
(14.45)
If we denote the special value of ˆt in the direction of ξt by ˆtξ and the corresponding value
of θt by θξ , it follows that
ξ t = |ξ t|ˆtξ = ∂γ (ˆn)
∂θξ
ˆtξ.
(14.46)
Then Eq. (14.44) can be written
∂γ (ˆn)
∂θt
= ∂γ (ˆn)
∂θξ
ˆtξ · ˆt = ∂γ (ˆn)
∂θξ
cos ψ,
(14.47)
where ψ is the angle between ˆt and ˆtξ, as illustrated in Figure 14–1. It follows that ∂γ ( ˆn)/∂θξ
is the maximum value of ∂γ ( ˆn)/∂θt.
Consider next a small planar element of area A having normal ˆn and deﬁne A = ˆnA. Its
free energy is γ A = ξ · A. The work that must be done by an external agent to change its
area and its orientation by inﬁnitesimal amounts is
δw = d(γ A) = d(ξ · A) = ξ · dA,
(14.48)
because A · dξ = 0. But
ξ · dA = ξ · (ˆn dA + A dˆn) = ξn · ˆn dA + A ξt · dˆn,
(14.49)
where ξn = γ ˆn is the part of ξ parallel to ˆn. The ﬁrst term
ξn · ˆn dA = γ dA
(14.50)

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
225
is the work necessary to change6 the area A. The second term
A ξt · dˆn = A∂γ (ˆn)
∂θt
dθt = A∂γ (ˆn)
∂θξ
cos ψ dθt
(14.51)
is the work needed to rotate the element of area. The quantity ∂γ ( ˆn)/∂θt given by
Eq. (14.47) is the torque per unit area and depends on the axis of rotation n×ˆt. This torque
is largest for rotation about the axis n × ˆtξ.
The forces that give rise to these free energy changes can be understood by considering
the case of a planar area A = L1 × L2, where L1 and L2 are two sides of a parallelogram,
as depicted in Figure 14–2. If L2 is replaced by L′
2 = L2 + dS, where dS is an inﬁnitesimal
vector, one can form a rotated and stretched planar area A′ = L1 × L′
2, where L1 and L′
2 are
two sides of a new parallelogram. The work required to do this will be
δw = d(γ A) = ξ · dA = ξ · (A′ −A) = ξ · L1 × dS = (ξ × L1) · dS.
(14.52)
The external force needed to translate one side of the original parallelogram L1 is therefore
ξ × L1. Let ˆℓ1 be a unit vector along L1. Then the force per unit length needed to translate
ˆℓ1 will be
σ = ξ × ˆℓ1.
(14.53)
As pointed out by Hoffman and Cahn [36], the tip of σ traces out an ellipse in a plane
perpendicular to ξ as the tip of ˆℓ1 traces out a circle in the plane of the original surface
element. This can be seen by taking ξ along the z-axis and assuming that the plane in
which ˆℓ1 rotates by an angle θ is tilted by an acute angle φ by means of rotation about
the y-axis. Then the x component of ˆℓ1 can be written cos θ cos φ, its y component can be
written sin θ, and its z component is irrelevant. We therefore compute
σ = −ξ sin θ ˆi + ξ cos θ cos φ ˆj,
(14.54)
which, as θ varies over 2π, describes an ellipse with major axis ξ and minor axis ξ cos φ.
L1
L1
L1
L2
L2
L2
L2
dS
FIGURE 14–2 Planar surface in the shape of a parallelogram bounded by vectors L1 and L2 and then rotated and
stretched to form another parallelogram bounded by vectors L1 and L′
2, where L′
2 = L2 + dS.
6This change must be done without straining the underlying solid; otherwise surface strain terms as in
Eq. (14.19) must be taken into account.

226
THERMAL PHYSICS
We can also decompose σ as follows:
σ = (ξn + ξt) × ˆℓ1 = γ ˆn × ˆℓ1 + ∂γ (ˆn)
∂θξ
ˆtξ × ˆℓ1.
(14.55)
Since ˆn and ˆℓ1 are perpendicular, ˆt1 := ˆn × ˆℓ1 is a unit vector in the plane of the surface
element and is perpendicular ˆn and ˆℓ1. The force per unit length γ ˆn × ˆℓ1 = γ ˆt1 therefore
has magnitude γ and is the isotropic force per unit length encountered in Eq. (14.50) and
needed to enlarge the area of the element. On the other hand, both ˆtξ and ˆℓ1 lie in the
plane of the surface element so ˆtξ × ˆℓ1 lies along ± ˆn. Since ˆℓ1 = ˆt1 × ˆn, we readily compute
ˆtξ × ˆℓ1 = −(ˆtξ · ˆt1) ˆn. Therefore, the force per unit area in Eq. (14.55) related to ξt can be
expressed as
ξt × ˆℓ1 = ∂γ (ˆn)
∂θξ
ˆtξ × ˆℓ1 = −∂γ (ˆn)
∂θξ
(ˆtξ · ˆt1) ˆn.
(14.56)
Its magnitude is similar in form to that of the torque per unit area given by Eq. (14.47).7
The total force per unit length can therefore be written in the form
σ = γ ˆt1 −(ξ t · ˆt1) ˆn = γ ˆt1 −∂γ (ˆn)
∂θξ
(ˆtξ · ˆt1) ˆn.
(14.57)
Note especially that ˆt1 is perpendicular to ˆℓ1 and points away from the area being
considered. In this respect, the sign convention that applies to Eq. (14.53) should be
considered carefully, namely ˆℓ1 = ˆt1 × ˆn. This is opposite to the sign convention used
for the Stokes theorem in which positive circulation on a curve with line elements dℓthat
bounds an area having normal ˆn is in the direction of the right-hand rule. In that case, the
unit vector ˆℓ:= dℓ/dℓsatisﬁes ˆℓ= −ˆt1 × ˆn. Thus, ˆℓ1 = −ˆℓand Eq. (14.53) would become
σ = −ξ × ˆℓ.
(14.58)
We point this out because use of the calculus of variations for curved surfaces, which we
will consider later, shows that Eq. (14.57) or its equivalent Eq. (14.58) apply generally, not
just for the edge of a planar element.
The equilibrium conditions at triple junctions are also affected by anisotropy, which
requires Eq. (13.83) to be modiﬁed. By requiring that no work be done by any small
translation of the triple line where three phases meet, one concludes that the net force
must be zero, resulting in
σ αβ + σ βη + σ ηα = 0.
(14.59)
From Eq. (14.57), we see that this balance equation accounts for forces due to both
tensions and torques, as discussed by Herring [38, p. 157]. By using Eq. (14.58), Eq. (14.59)
can be written in the form
7Great care must be made in comparing these formulae, even though they look very much alike. In Eq. (14.47),
ˆt is ﬁxed for the entire area in the direction of d ˆn, but in Eq. (14.56) ˆt1 is related to the orientation of ˆℓ1 by
ˆt1 = ˆn × ˆℓ1.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
227
(ξαβ + ξ βη + ξ ηα) × ˆℓ
αβη = 0,
(14.60)
where the normals to the surfaces must be chosen consistently to point from the ﬁrst
named phase to the second. Here, ˆℓ
αβη is a unit vector along the line of the triple junction.
Thus the vector (ξαβ + ξβη + ξηα) has no component perpendicular to the triple line. For a
detailed discussion of a quad junction where four phases meet, see Hoffman and Cahn [36,
Eq. (28)].
14.3 Curved Solid-Fluid Interfaces
For an inﬁnitesimal area of a curved solid-ﬂuid interface, one can assume that γ is
approximately the same as it would be for a planar solid-ﬂuid interface having the same
normal ˆn, provided that the thickness of the region of discontinuity is small compared
to the local radii of curvature. This is similar to what is done for ﬂuid-ﬂuid interfaces
except in that case one is able to locate the interface at the surface of tension. No such
surface of tension is identiﬁed for a curved solid-ﬂuid interface, which is assumed to
be located within the physical region of discontinuity with sufﬁcient accuracy. If more
rigor is required, the interface could possibly be located at the equimolar surface of some
component.
A polar plot
r = ˆn γ (ˆn)
(14.61)
is commonly known as a gamma-plot, or γ -plot for short. It gives a pictorial representa-
tion of γ as a function of the orientation of ˆn and has a unique positive value for each ˆn. In
spherical coordinates, its equation is r = γ (θ, ϕ), so γ is the distance from the origin to the
γ -plot at given θ and ϕ. Since ξ is a function of ˆn, one can also obtain a corresponding
xi-plot, or ξ-plot for short, by allowing ˆn to take on all orientations. In this case, the
magnitude ξ of ξ can be a multiple-valued function of the unit vector ˆN = ξ/ξ that points
in the direction of ξ. An example in two dimensions is shown in Figure 14–3. We shall
prove in Section 14.5 that the inner convex hull of the ξ-plot has the same shape as the
equilibrium shape of a crystal. Note especially that ξ( ˆn) is a parametric representation of
ξ in terms of the orientation of its surface normal ˆn. In particular, it is not a representation
of ξ in terms of its own orientation ˆN.
The equilibrium shape of a crystal, also known as the Gibbs-Wulff shape or sometimes
simply the Wulff shape, is that shape taken on by a crystal by minimizing its total surface
free energy subject to the constraint of ﬁxed volume. For kinetic reasons, only small
crystals can achieve this shape in a reasonable time. For a given γ -plot, this shape can
be found by means of the following construction due to Wulff [39]. At every point ˆnγ ( ˆn)
of the γ -plot, erect a plane perpendicular to ˆn and passing through that point. Then the
inner convex hull of those Wulff planes is the equilibrium shape. This so-called Wulff
theorem was stated without proof by Wulff in the context of polyhedral shapes but has
since been studied extensively and applies also to curved shapes. In Section 14.5, we

228
THERMAL PHYSICS
−1.5
−1.0
−0.5
0.5
1.0
1.5
−1.5
−1.0
−0.5
0.5
1.0
1.5
(a)
(b)
−0.5
0.5
−0.5
0.5
FIGURE 14–3 (a) Illustration of a γ -plot and a ξ-plot in two dimensions for γ = 1 +

2n2xn2y + 0.08 in arbitrary
units. The ξ-plot is not a single-valued function of its polar angle in this case but has “ears” that must be truncated
leaving a convex body that would have the equilibrium shape of a two-dimensional crystal. (b) Inverted γ -plot (full
curve) whose properties are discussed in Section 14.3.2. The dashed lines are added to “convexify” (to make convex)
the plot.
derive an analytical formula for this shape in terms of the ξ-vector for differentiable
γ ( ˆn). Immediately below, we show how ξ can be deﬁned for cases for which γ ( ˆn) is not
differentiable. Moreover, the analysis of faceting in Section 14.4 can be used to show that
a surface whose orientation does not appear on the Gibbs-Wulff shape is unstable with
respect to faceting, consistent with the Gibbs-Wulff shape being the equilibrium shape.
14.3.1 Discontinuous Derivatives of γ
The deﬁnition of ξ, and hence the ξ-plot, can be extended to cover cases in which the
derivatives of γ are discontinuous. In particular, γ ( ˆn) can have sharp grooves (knife edges)
or inwardly directed sharp points, including cusps, at special orientations that correspond
to low index planes in three dimensions.8 One way of handling this situation is to consider
a slight rounding of the grooves or sharp points and then take the limit as this rounding
tends to zero. For example, in the vicinity of nx ≪1, ny ≈1, and nz ≪1, suppose that
γ (ˆn) = γ0

1 + α

n2x + ϵ2
	
,
(14.62)
where γ0, α, and ϵ ≪1 are positive constants. Then one readily calculates
8In strictly two dimensions, these grooves or sharp points become rounded at ﬁnite temperatures due to
entropic effects. See Mullins [40, p. 28] and Herring [41, p. 18] for further discussion.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
229
ξx = γ0
⎡
⎣nx + αnx
1 + ϵ2

n2x + ϵ2
⎤
⎦≈γ0

nx + α nx
|nx|
	
;
(14.63)
ξy = γ0
⎡
⎣ny + αny
ϵ2

n2x + ϵ2
⎤
⎦≈γ0ny;
(14.64)
ξz = γ0
⎡
⎣nz + αnz
ϵ2

n2x + ϵ2
⎤
⎦≈γ0nz,
(14.65)
where the approximate forms are in the limit ϵ = 0, where γ = γ0[1 + α|nx|]. In this limit,
we see that γ is continuous but ξx is discontinuous at nx = 0, where it jumps from −γ0α to
γ0α. In the plane nz = 0, we see for ﬁnite but small ϵ that ξy ≈γ0(1 −n2
x)1/2 is very nearly
equal to γ0 for small nx while ξx changes considerably as nx makes small changes near
zero, as shown in Figure 14–4. As ϵ becomes very small, the γ -plot tends toward a V-shaped
groove and the tips of the ξ-vector lie nearly along a straight line segment corresponding to
ξy = γ0 that extends from −γ0α to γ0α. Thus it would be natural for a sharp groove (ε = 0)
to deﬁne ξ, for nx = 0, to be multiple-valued, namely the fan of vectors having ξz = 0,
ξy = γ0, and −γ0α ≤ξx ≤γ0α. The tails of these vectors are at the origin and their tips lie
along a straight line. The corresponding three-dimensional portion of the ξ-plot would be
a ruled surface. By analogous reasoning, the ξ-vectors corresponding to a sharp inwardly
directed point of γ would form a cone whose tips lie along a portion of a plane, a facet of
the ξ-plot.
An elegant way of deﬁning ξ for general γ that is fully consistent with the foregoing
limiting arguments can be based on the famous sphere construction of Herring, as
illustrated in Figure 14–5. The Herring sphere construction is based on the fact that any
(a)
(b)
γ-plot
ξ-plot
FIGURE 14–4 Portions of a γ -plot and the corresponding ξ-plot near a groove for three values of ϵ in the plane
nz = 0 according to Eqs. (14.62)–(14.64). For plotting purposes, γ0 = 1, α =
√
2/2, and ϵ = 0.1, 0.05, and 0.01 from
top to bottom. (a) The upper curves are plots of γ versus nx with the origin located at the root of the V-shaped
groove. (b) The lower curves are parametric plots of ξy versus ξx for very small changes of nx near nx = 0.

230
THERMAL PHYSICS
γ
ξ
V
γ
ˆnγ
ξ/2
O
FIGURE 14–5 Herring sphere (actually a circle in two dimension) tangent to a segment of the γ -plot and passing
through its origin, O. The ξ-vector lies along a diameter and the center of the sphere is located at ξ/2. The vector V
has magnitude ξ/2 and is perpendicular to the local tangent plane.
angle inscribed in a hemisphere is a right angle. Therefore, according to the Wulff theorem,
any point on the surface of an equilibrium shape must be located at end of the diameter
ξ( ˆn) of a sphere that passes through the origin of the γ -plot and satisﬁes ξ · ˆn = γ .
Furthermore, this sphere must either be tangent to the γ -plot at a place where its tangent
is well deﬁned or else touch the γ -plot at some sharp groove or sharp point where the
tangent to the γ -plot is not well deﬁned. For a surface element with deﬁnite orientation
to actually appear on the equilibrium shape, it is necessary and sufﬁcient that no portion
of the γ -plot lies inside the Herring sphere corresponding to that orientation. This is true
because a Wulff plane corresponding to a portion of the γ -plot that lies inside the Herring
sphere would cut through its diameter and exclude that orientation from the inner convex
hull. As shown below, the resulting equilibrium shape can have curved sections and ﬂat
sections, as well as edges and sharp corners that correspond to missing orientations.
Therefore, at any point on the γ -plot for some orientation ˆn at which its derivatives
are well deﬁned and continuous, one can erect a Herring sphere that passes through the
origin and is tangent to the γ -plot at that point. Then the vector ξ is the unique vector
from the origin of the γ -plot that passes through the center of that sphere and terminates
on its opposite side. For points on the γ -plot for which its derivatives are undeﬁned, ξ
is multiple-valued because one can construct a continuum of Herring spheres that pass
through that point and the origin of the γ -plot and deﬁne a fan or cone of ξ-vectors,
as illustrated in Figure 14–6. This leads to a ξ-plot that can have curved surfaces, ruled
surfaces, and planar sections. The resulting ξ-plot can be nonconvex and have “ears” that
must, however, be truncated to form the equilibrium shape, which is convex.
Since any angle inscribed in a hemisphere is a right angle, this extended deﬁnition of ξ
will satisfy γ = ξ · ˆn. Other relations can be established as follows. For any point r = ˆnγ ( ˆn)
on the γ -plot, one can erect a vector V that points from the center of a Herring sphere to r
and passes through the origin of the γ -plot. This construction satisﬁes
ξ
2 + V = γ ˆn = r
(14.66)

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
231
γ
α
γ
α
ξL
ξR
C
O
FIGURE 14–6 Fan of ξ-vectors corresponding to a V-shaped portion of a γ -plot. Five Herring spheres (actually circles
in two dimensions) that pass through the origin O of the γ -plot and the point C are shown along with the ξ-vectors
that lie along their diameters. The two largest circles are tangent to the γ -plot at C. The other three circles pass
through C but are not tangent to the γ -plot; there is a continuum of such circles that would have that same property.
The tips of the ξ-vectors lie along a line of length 2γc cos α that stretches from ξL to ξR, where γc is the value of γ at
the point C where each segment of the V-shaped plot makes an angle α with the horizontal.
with |V| = |ξ|/2. For a particular point corresponding to ˆn0, suppose that the γ -plot has a
well-deﬁned tangent plane whose equation is (r−r0)·V0 = 0. For a small change dr = r−r0
in this plane, we will have
dr · V0 = 0.
(14.67)
But since this plane is tangent to the γ -plot, we also have dr = d(γ ˆn) = γ0dˆn + ˆn0dγ . By
substituting for V0 from Eq. (14.66), Eq. (14.67) can be written
(γ0 dˆn + ˆn0 dγ ) · (γ0 ˆn0 −ξ0/2) = 0.
(14.68)
By computing the dot products and dividing by γ0/2 ̸= 0 we obtain
dγ = ξ · d ˆn,
γ -plot has well-deﬁned tangent plane,
(14.69)
where we have dropped the subscript 0 on ξ with the understanding that it is to be
evaluated at dˆn = 0. Then by using dγ = d(ξ · ˆn), we can use Eq. (14.69) to obtain
ˆn·dξ = 0. Thus, wherever the γ -plot has a well-deﬁned tangent plane, Eqs. (14.32), (14.35),
and (14.36) are all satisﬁed, as expected.
On the other hand, if a Herring sphere that passes through the origin touches the γ -plot
at a point where it does not have a well-deﬁned tangent plane, the position of its center
and its size can vary while holding γ and ˆn constant. In other words, ξ can vary while
holding γ and ˆn constant. Thus we can take the differential of γ = ξ · ˆn to obtain
ˆn · dξ = 0,
always,
(14.70)
which is the same as for a well-deﬁned tangent plane. But now the vector V touches the
γ -plot but it is no longer normal to it at the point of touching. Thus Eq. (14.67) must be
replaced by
dr · V0 ≥0,
where the γ -plot has no well-deﬁned tangent plane.
(14.71)

232
THERMAL PHYSICS
The equality holds only if dr lies along and is tangent to the curve of a knife edge.
Accordingly, Eq. (14.69) is replaced by
dγ ≥ξ · d ˆn,
where the γ -plot has no well-deﬁned tangent plane.
(14.72)
If we write dˆn = ˆtdθt as in Eq. (14.43), Eq. (14.72) becomes
∂γ (ˆn)
∂θt
≥ξ t · ˆt,
where the γ -plot has no well-deﬁned tangent plane.
(14.73)
In this case, Eq. (14.73) replaces Eq. (14.44). Thus, the multiple values of ξt that are
associated with a ruled or ﬂat portion of a surface determine the range of torques that
can be supported.
14.3.2 Inverted γ -Plot
The Herring sphere criterion can be used to determine which orientations are missing on
the equilibrium shape. This is easy to state but hard to apply. An equivalent criterion that
is much easier to apply has been discussed by Frank [42]. It can be obtained by considering
the inverted gamma-plot, namely the polar plot
R = ˆn
1
γ (ˆn),
(14.74)
or simply R = 1/γ ( ˆn). On inversion through the origin, a sphere becomes a plane.9 Thus
a Herring sphere that is tangent to the γ -plot becomes a tangent plane to the 1/γ -plot.
Any portion of a γ -plot that lies inside a Herring sphere will contribute to planes that cut
the 1/γ -plot. It follows that for all orientations to appear on the equilibrium shape, it is
necessary and sufﬁcient that the 1/γ -plot be convex. Furthermore, if the 1/γ -plot is not
convex, one can form a convex body by means of enveloping it by portions of touching
planes that do not cut the plot. See Figure 14–3b for an example in two dimensions, where
the dashed lines are added to “convexify” the plot. The orientations on the nonconvex
1/γ -plot that do not appear on the enveloped convex plot are those that are missing from
the equilibrium shape. They actually appear on the ears of the ξ-plot.
It is easy to show that the normal to the 1/γ ( ˆn)-plot is in the direction ξ( ˆn). Indeed, the
equation of the 1/γ ( ˆn)-plot can be written in the form Rγ ( ˆn) = 1 with ˆn = R/R. Then we
can let R play the role of P in Eq. (14.31) to obtain
ξ(ˆn) = ∇R [R γ (R/R)],
(14.75)
which is clearly in the direction of the normal to the 1/γ ( ˆn)-plot. This expression can be
used to compute the Gauss curvature of the 1/γ ( ˆn)-plot and determine when it changes
sign, which deﬁnes the limits of its convexity. This gives an analytical criterion for the
onset of missing orientations on a three-dimensional equilibrium shape [43]. Herring [44]
9In particular, consider the sphere r = ˆn( ˆn·ξ), where ˆn varies for ﬁxed ξ. When inverted, this sphere becomes
Q = ˆn( ˆn · ξ)−1 or Q · ξ = 1, which is linear in the components of Q. Thus it is a plane that passes through the
point Q = ξ/ξ2.

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
233
has given an extensive discussion of the qualitative characteristics of the γ -plot and the
resulting equilibrium shapes, with particular attention to corners, cylindrical portions,
and facets.
14.4 Faceting of a Large Planar Face
Herring [44] has also considered the possibility that a large planar surface of a crystal
could break up into a hill-and-valley structure composed of facets. Such a consideration
is important for kinetic reasons because a large amount of transport would be required
to convert a large crystal to its equilibrium shape. It therefore makes sense to consider a
state that could occur on a time scale that is very short compared to the time needed to
transform an entire crystal to its equilibrium shape.
To analyze this problem, consider a small area a0 on the planar face of a large crystal
having unit normal ˆn0 and free energy γ ( ˆn0) ≡γ0 per unit area. We then investigate the
stability of this planar area with respect to being replaced by a pyramid10 having three
noncoplanar orientations ˆn1, ˆn2, and ˆn3, corresponding to facets having respective areas
a1, a2, and a3, as illustrated in Figure 14–7. From Gauss’s theorem in the form

V ∇·k d3x =

A k · ˆn d2x, where k is an arbitrary but constant vector, we can deduce that

A ˆn d2x = 0.
By applying this result to the pyramid just described, we obtain
ˆn0 = f1 ˆn1 + f2 ˆn2 + f3 ˆn3,
(14.76)
where fi = ai/a0 are area fractions.11 By using reciprocal vectors τ i deﬁned such that τ i ·
ˆnj = δij for i, j = 1, 2, 3, we deduce that fi = τi · ˆn0. Thus the τ i, but not necessarily the ˆni
as required by Herring [45], must have positive projections on ˆn0 in order to obtain a real
pyramid with positive fi. The free energy associated with the three faces of the pyramid,
measured per unit area of the large planar face, is
γh = f1γ1 + f2γ2 + f3γ3.
(14.77)
Thus
γh = c · ˆn0,
(14.78)
ˆn1
ˆn2
ˆn1
ˆn2
ˆn3
ˆn0
a3
a2
a1
a0
(a)
(b)
FIGURE 14–7 (a) Typical pyramid for faceting of a surface. The ˆni are unit normals and ai are respective areas of the
faces. (b) Faceted surface in two dimensions, showing facets of different sizes but the same orientation.
10For the entire planar face, this is to be done by using many pyramids but without a change in volume.
11Note that ˆn0 is the outward normal to the large planar face so it is an inner normal to the pyramid.

234
THERMAL PHYSICS
where c := τ iγ1 + τiγ2 + τ iγ3 can be interpreted geometrically as the vector from the
origin of the γ -plot to a point deﬁned by the intersections of three Wulff planes drawn
perpendicular to ˆn1, ˆn2, and ˆn3 at the points where they intersect the γ -plot. This
interpretation follows because c · ˆni = γi for i = 1, 2, 3. We observe that c lies along
the diameter of a sphere that passes through four points, ˆn1γ1, ˆn2γ2, ˆn3γ3, and the
origin.
From the above considerations, it follows that the large planar face will be stable against
faceting if γh > γ0, which means that the point (c · ˆn0) ˆn0 = γh ˆn0 will lie outside the γ -plot.
On the other hand, if the point γh ˆn0 lies inside the γ -plot, the large planar face will be
unstable with respect to this type of faceting. However, if the orientation ˆn0 occurs on
the equilibrium shape, it is impossible for point γh ˆn0 to lie inside the γ -plot because at
least one of the Wulff planes corresponding to ˆn1, ˆn2, or ˆn3 would cut it off. This results in
Herring’s theorem [44]:
If a given macroscopic surface of a crystal does not coincide in orientation with some
portion of the boundary of the equilibrium shape, there will always exist a hill-and-
valley structure which has a lower free energy than a ﬂat surface, while if the given
surface does occur in the equilibrium shape, no hill-and-valley structure can be more
stable.
With keen geometrical insight, Frank [42] observed that Herring’s faceting criterion has
a very simple interpretation in terms of the inverted γ -plot. In particular, the tip of the
inverted vector ˆn/γh lies on the plane that passes through the points ˆn1/γ1, ˆn2/γ2, and
ˆn3/γ3. To see this, let ˆp be a unit vector perpendicular to that plane and pointing away from
the origin. Then the distance from the origin to that plane is given by d = ˆp · ˆn1/γ1 = ˆp ·
ˆn2/γ2 = ˆp· ˆn3/γ3, from which we deduce that ˆp = d(τ iγ1+τ iγ2+τ iγ3) = c d. Thus ˆp· ˆn/γh =
d, conﬁrming Frank’s observation. Therefore, we can compare ˆn/γh with ˆn/γ and deduce
that the free energy will be lowered by faceting only if ˆn/γ lies inside the plane (nearer to
the origin) that passes through ˆn1/γ1, ˆn2/γ2, and ˆn3/γ3. This analysis also clariﬁes that the
orientations that are unstable with respect to faceting are those that lie on the ears of the
ξ-plot, which result from nonconvex portions of the 1/γ -plot. Indeed, the very notion of
a value of γ for unstable orientations requires the concept of a constrained equilibrium
state for which faceting is prevented.
Herring’s analysis was extended by Mullins and Sekerka [45] by using linear program-
ming theory to analyze faceting into shapes having an arbitrary number of orientations. It
was shown that a minimum value of γh can always be obtained by using no more than three
orientations; however, degeneracies can occur such that more than three orientations can
lead to the same minimum value of γh. Moreover, the minimum value of γh that can
be achieved by faceting corresponds to the distance ( ˆn) from the origin to a so-called
contact plane of the Gibbs-Wulff shape, the latter being a plane that is perpendicular to
ˆn and touches but does not cut that shape. In fact, ˆn( ˆn) is the minimum gamma-plot
(contained in all others) that gives the same Gibbs-Wulff shape as γ ( ˆn). Figure 14–8

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
235
−1.5
−1.0
−0.5
0.5
1.0
1.5
−1.5
−1.0
−0.5
0.5
1.0
1.5
γ
Γ
ξ
FIGURE 14–8 A γ -plot (outer curve) and a ξ-plot (inner curve) in two dimensions for γ = 1 +

2n2xn2y + 0.08 in
arbitrary units. The equilibrium Gibbs-Wulff shape is the convex shape found by truncating the ears of the ξ-plot.
The middle curve is the -plot, which is the smallest that will lead to the same Gibbs-Wulff shape. The distance
along any ˆn between γ (ˆn) and (ˆn) represents the maximum possible energy reduction by faceting. Orientations
for which this difference is zero appear on the Gibbs-Wulff shape.
illustrates γ ( ˆn), ( ˆn), and ξ( ˆn) in two dimensions. For orientations such that a contact
plane is actually tangent to the Gibbs-Wulff shape, that orientation appears on the shape
and the corresponding plane is not unstable with respect to faceting. The inverted plot
ˆn( ˆn) is just the convex plot obtained by enveloping the plot ˆn/γ ( ˆn) by portions of planes,
as illustrated in Figure 14–3b. The portions of planes invert to portions of spheres on ( ˆn)
that correspond to orientations for which the contact plane is not tangent to the Gibbs-
Wulff shape.
It is important to recognize that this analysis of faceting provides no size scale for the
facets; it deals only with their orientation. In other words, surfaces with large facets have
the same free energy as those with small facets. However, one would expect there to be a
mixture of facet sizes on a given surface (e.g., colonies of large facets and small facets, as
suggested by Figure 14–7b in two dimensions) and the resulting conﬁgurational entropy
would further lower the free energy of a faceted surface. Modiﬁcation of the theory to allow
for excess energies at edges and corners would change the invariance to size scale. Of
course it would also require modiﬁcation of our concept of an equilibrium shape, which
would only be valid for crystals sufﬁciently large that excess energies at edges and corners
are negligible.

236
THERMAL PHYSICS
14.5 Equilibrium Shape from the ξ-Vector
Provided that γ ( ˆn) is differentiable, we can proceed to ﬁnd an analytical formula for the
equilibrium shape of a solid in contact with a ﬂuid. Places where it is not differentiable can
be handled as limiting cases as explained in Section 14.3.1. We proceed to minimize the
grand potential K for the entire solid, assumed to be constrained to have a ﬁxed volume
and maintained at ﬁxed temperature T and chemical potentials μi. We write this potential
in the form
K =

Vs
ωs
v dV +

VF
ωF
v dV +

A
γ (ˆn) dA,
(14.79)
where ωsv is the grand potential per unit volume in the solid, which may be crystalline
or amorphous, ωFv is the grand potential per unit volume in the ﬂuid, Vs is the volume
of the solid, VF is the volume of the ﬂuid, A is the area of the interface that separates
the solid from the ﬂuid, and ˆn points from solid to ﬂuid. For the moment, we assume
that the area A is bounded by some closed curve C. We presume that the interface can be
represented in terms of parameters u, v by the equation r = r(u, v), as discussed in detail in
Appendix C, Section C.2. We write the equilibrium shape in the form r = r0(u, v) and make
an inﬁnitesimal normal variation to a new position,
r = r0(u, v) + ˆn0(u, v)η(u, v) ≡r0(u, v) + δr(u, v),
(14.80)
where the inﬁnitesimal quantity η(u, v) is arbitrary but differentiable. Then the variation
of the total Kramers (grand) potential is
δK =

A
(ωs
v −ωF
v )η(u, v) dA + δ

A
ξ · ˆn dA,
(14.81)
where we have replaced γ by ξ · ˆn. The second area integral can be written in the form
δ

A
ξ · ˆn dA = δ

u,v
ξ · H du dv,
(14.82)
where H = ru × rv, with ru = ∂r/∂u and rv = ∂r/∂v. Note that ˆn = H/H. The second
integral in Eq. (14.82) is over a ﬁxed domain in u, v space. Thus we can take δ inside the
integral to obtain
δ

u,v
ξ · H du dv =

u,v
ξ · δH du dv,
(14.83)
where H · δξ = 0 because of Eq. (14.35). Then, as shown by Eq. (C.46) in Appendix C,
Eq. (14.80) leads to
δH = ˆn0(u, v)H0(u, v)η(u, v) K0(u, v) −H0(u, v)∇sη(u, v),
(14.84)
where K0(u, v) is the mean curvature of the surface in the unvaried state (see Eq. (C.28)
for a general formula) and ∇s is the surface gradient operator deﬁned by Eq. (C.35). Thus
Eq. (14.81) becomes
δK =

A
(ωs
v −ωF
v )η(u, v) dA +

A
γ K η(u, v) −ξ · ∇sη(u, v) dA,
(14.85)

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
237
where we have dropped the zero subscripts. Next, we prepare to integrate by parts by
writing
−ξ · ∇sη(u, v) = −∇s · [ξη(u, v)] + η(u, v)∇s · ξ,
(14.86)
where the terms on the right-hand side contain the surface divergence. According to the
surface divergence theorem, Eq. (C.49), we have

A
∇s · [ξη(u, v)] dA =

C
ξt · ˆtη(u, v) dℓ+

A
γ Kη(u, v) dA,
(14.87)
where ˆt is a unit tangent vector pointing out of the area along the curve C, speciﬁcally
ˆt dℓ= dℓ× ˆn, where the direction of ˆtdℓis determined by the right-hand rule. Thus
δK =

A

(ωs
v −ωF
v ) + ∇s · ξ

η(u, v) dA −

C
ξt · ˆt η(u, v) dℓ.
(14.88)
To guarantee that no work is done along the curve C, we can take η(u, v) = 0 along C and
the equilibrium criterion becomes
0 = δK =

A

(ωs
v −ωF
v ) + ∇s · ξ

η(u, v) dA.
(14.89)
Then since η(u, v) is arbitrary over the area A, the integrand must vanish, and we obtain
the equilibrium condition
ωF
v −ωs
v = ∇s · ξ.
(14.90)
If the solid is amorphous and therefore isotropic, ξ = γ ˆn, ∇s · ξ = γ K by Eq. (C.38), and
ωFv −ωsv = ps −pF, so the Laplace equation (Eq. (13.71)) for ﬂuids would apply.
Equation (14.90) is a nonlinear partial differential equation for the solid-ﬂuid interface
shape, so one would have to ﬁnd a solution that attached to the bounding curve C, a
difﬁcult task. On the other hand, for a closed surface, the curve C closes back on itself and
the line integral in Eq. (14.88) vanishes without restriction on η(u, v). Then, since ∇s · r = 2
(see Eq. (C.41)) an obvious solution to Eq. (14.90) is
r =
2
(ωFv −ωsv) ξ,
(14.91)
which is the equation for the equilibrium shape of a crystal.12 Note that a result of the
same form would be obtained if one varied only the shape of the body while holding its
volume constant. This could be done by using a Lagrange multiplier to put in the volume
constraint. The present method identiﬁes that Lagrange multiplier in terms of physical
quantities so we obtain the size of the crystal in addition to its shape.
Let us return to Eq. (14.88) for a bounding curve C that can move in a manner described
by Eq. (14.80). Then the work done by an external force work fL per unit length is given by
12As explained in connection with the Wulff theorem, one must truncate the ears to get a convex body if there
are missing orientations. Note in two dimensions that ∇s · r = 1, so the factor of 2 would be missing.

238
THERMAL PHYSICS
δW =

C
fL · ˆn η(u, v) dℓ.
(14.92)
The equilibrium criterion now becomes δK −δW = 0. Equation (14.90) still holds over the
area, but along the curve C we would need
−

C
ξ t · ˆt η(u, v) dℓ−

C
fL · ˆn η(u, v) dℓ= 0.
(14.93)
By using ˆt dℓ= dℓ× ˆn in the ﬁrst integral, Eq. (14.93) becomes

C

ξ t × (dℓ/dℓ) + fL

· ˆn η(u, v) dℓ= 0.
(14.94)
Since η(u, v) is arbitrary along C, we conclude that

fL + ξt × (dℓ/dℓ)

· ˆn = 0,
(14.95)
which gives a normal force for curved surfaces that is the same as given by Eq. (14.58)
for a planar surface. By considering a variation of the curve C in the tangential direction
ˆt instead of Eq. (14.80) one can obtain the tangential component of Eq. (14.58). It must
be borne in mind, however, that this is only valid if the state of strain of the solid is not
affected by the variation; otherwise, one would obtain the surface stress instead of γ for a
tangential force per unit length, as discussed in Section 14.1.2.
To evaluate the quantity ωFv −ωsv for a single component, one usually uses
d(ωF
v −ωs
v) = −(sFnF −ssns) dT −(nF −ns) dμ,
(14.96)
which is only valid if the effect of shear strain in the solid can be ignored. Here, sF is
the entropy per mole of the ﬂuid, ss is the entropy per mole of the solid, nF is the molar
density of the ﬂuid, ns is the molar density of the solid, T is temperature, and μ is chemical
potential. For the ﬂuid, one also has
dμ = −sF dT + (1/nF) dpF,
(14.97)
where pF is the pressure of the ﬂuid. Then
d(ωF
v −ωs
v) = −ns(sF −ss) dT −(nF −ns)
nF
dpF.
(14.98)
We can examine two states, both at the same value of pF. One such state corresponds
to a planar interface for an inﬁnite crystal, so ωFv −ωsv = 0 and T becomes the nominal
melting point TM for that chosen pressure, where we have chosen the ﬂuid to be a liquid
for the sake of illustration. The other state corresponds to the equilibrium state of a small
crystal in equilibrium with its liquid melt at temperature T. Then integration of Eq. (14.98)
with LV := ns(sF −ss)TM, the latent heat per unit volume of solid, assumed to be constant,
gives

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
239
(ωF
v −ωs
v) = LV
(TM −T)
TM
.
(14.99)
Thus Eq. (14.90) becomes
T = TM −(TM/LV)∇s · ξ,
(14.100)
which is a form of the Gibbs-Thomson equation for anisotropic γ . For isotropic γ it
becomes
T = TM −(TMγ /LV)K,
(14.101)
which is well known.
Another important option is to keep T ﬁxed in Eq. (14.96) but allow μ to vary from its
value μ∞for an inﬁnite crystal with ωFv −ωsv = 0 to its value μ for a ﬁnite crystal. Then by
treating 0 =: (ns −nF)−1 as a constant, Eq. (14.98) can be integrated to obtain
μ = μ∞+ 0∇s · ξ.
(14.102)
If ∇s · ξ is evaluated at a point on the surface, Eq. (14.100) is equivalent to the Herring
equation, which usually pertains to the case in which the ﬂuid is a gas with negligible
density, so that 0
≈(ns)−1. In the next section, we will develop that equation in
detail.
The derivation of Eq. (14.90) was carried out in the context of global equilibrium
between a crystal and a ﬂuid, so that Eq. (14.91) is an equation for the equilibrium shape
of the crystal. Under those conditions, the ﬂuid is homogeneous, so its temperature
and chemical potentials are uniform. On the other hand, Eqs. (14.100) and (14.102) are
frequently regarded as local equilibrium conditions that apply at the surface of a crystal
having any shape. In that case, for example, Eq. (14.102) would lead to a chemical potential
that varied along the surface of the crystal. Such a nonuniform chemical potential would
provide a driving force for diffusion processes that would lead to shape changes of the
crystal and eventually to an equilibrium shape and a uniform chemical potential. For
multicomponent systems, an equation similar in form to Eq. (14.100) can be obtained
if the chemical potentials μF
i of the ﬂuid can be maintained at ﬁxed values. Then only
the term in dT in Eq. (14.96) survives and Eq. (14.100) applies with LV replaced by
L′
V = (sFnF −ssns)TM, where now TM is understood to be the local bulk melting point
of the multicomponent alloy. Note that it is not so easy to extend Eq. (14.102) to a
multicomponent system because ω = uV −TsV −
 μini, so more than one chemical
potential is involved. Such an extension is sometimes made, however, to the case of a
Gibbs solid that has a ﬁxed composition (Gibbs called this the substance of the solid)
and does not contain other chemical components (if any) that are contained in the ﬂuid.
For such a solid, the chemical potential μA of the substance of the solid (regarded as
a supercomponent A that is made up of appropriate components of the ﬂuid in ﬁxed
proportions) would obey Eq. (14.102) at its surface. The chemical potentials of any other
components of the ﬂuid would be unconstrained.

240
THERMAL PHYSICS
14.6 Herring Formula
By explicitly evaluating the quantity ∇s · ξ that appears in Eq. (14.90) at some point on
a surface, one can obtain a formula due to Herring that is often used to calculate local
equilibrium at a crystal-ﬂuid interface. This can be accomplished by going to a Monge
representation of the surface which requires one to adopt a speciﬁc parameterization of
the surface of the form
x = u;
y = v;
z = w(u, v),
(14.103)
where x, y, and z are Cartesian coordinates, as in Section C.3 of Appendix C. This amounts
to writing z = z(x, y), where z on the right represents the function w of x and y whereas z
on the left represents the value of that function, a common shorthand notation. Then with
p = zx and q = zy, where the subscripts denote partial derivatives (see Eq. (C.70)),
ωF
v −ωs
v = ∇s · ξ = −(ppzxx + 2pqzxy + qqzyy),
(14.104)
where (p, q) = γ (p, q)

1 + p2 + q2 is the value of the surface free energy γ per unit
area of the x, y plane and subscripts indicate partial derivatives. Explicit values of the
derivatives of  are given by Eq. (C.71). Equation (14.104) is a rather complicated nonlinear
partial differential equation for the shape of the surface z = z(x, y).
A formula that applies at a given point x0, y0 on the surface can be obtained by choosing
the z-axis to lie along the normal ˆn0 at that point with the x, y plane locally tangent
to the shape. In that case, p = q = 0 when evaluated at the chosen point, which
gives
ωF
v −ωs
v = −(γ + γpp)zxx −2γpqzxy −(γ + γqq)zyy,
at a point x0, y0, z along ˆn0,
(14.105)
where the derivatives are to be evaluated at p = q = 0, x = x0, and y = y0. This is a more
general than the Herring formula because it does not require location of the principal axes
of the shape under consideration.
If x and y are chosen along principal axes, Eq. (14.105) can be simpliﬁed further because
zxy = 0. Then −zxx = K1 = 1/R1 and −zyy = K2 = 1/R2 are principal curvatures. Thus
ωF
v −ωs
v = γ + γpp
R1
+ γ + γqq
R2
,
at a point x0, y0, z along ˆn0, principal axes.
(14.106)
The Herring formula can be obtained by rewriting Eq. (14.106) in terms of the angles θ1
and θ2 made between the normal n and n0 near x0, y0 and measured in principal planes.
Speciﬁcally, tan θ1 = ±p and tanθ2 = ±q. This results in
ωF
v −ωs
v = γ + γθ1θ1
R1
+ γ + γθ2θ2
R2
,
at a point x0, y0, principal planes,
(14.107)

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
241
which is a somewhat more general version of Herring’s result. (See Section C.4 for details
of this variable change.) The original Herring formula [38, 41] pertained to the case of a
solid-vapor interface for a single component for which Eq. (14.102) becomes13
μ = μ∞+ 0
γ + γθ1θ1
R1
+ γ + γθ2θ2
R2
	
,
at a point x0, y0, principal planes.
(14.108)
It should be emphasized that the Herring formula applies only at a point on the surface. In
particular, it is not a partial differential equation for the surface shape, such as Eq. (14.104).
It can, however, serve as a local equilibrium condition for a nonequilibrium shape, as
discussed at the end of Section 14.5.
14.7 Legendre Transform of the Equilibrium Shape
In a Monge representation, z = z(x, y) as introduced in Eq. (14.103), an interesting recipro-
cal relationship exists between equilibrium shape and the interfacial free energy expressed
per unit area of the x, y plane, namely the quantity14
(p, q) = γ
nz
=
γ
cos θ = γ (p, q)

1 + p2 + q2,
(14.109)
where p = zx and q = zy as introduced previously in connection with Eq. (14.104). We shall
see that (p, q) and z = z(x, y) are essentially Legendre transforms of one another, with an
appropriate constant scale factor λ. According to Eq. (14.91), which we write in the form
ξ = λr with λ = (ωFv −ωsv)/2, we could equally well represent the equilibrium shape in a
Monge representation of the form Z = Z(X, Y ), where X ≡ξx, Y ≡ξy, and Z ≡ξz. With
this notation we shall show that
 = Z −pX −qY = Z −X ∂Z
∂X −Y ∂Z
∂Y ,
(14.110)
whose inverse is
Z =  + pX + qY =  −p∂
∂p −q∂
∂q .
(14.111)
To relate directly to the equilibrium shape, just substitute X = λx, Y = λy, and Z = λz.
We begin with Eq. (14.35) which we write in the form
nx dX + ny dY + nz dZ = 0.
(14.112)
Then we calculate
p =
 ∂Z
∂X

Y
= −nx
nz
;
q =
 ∂Z
∂Y

X
= −ny
nz
,
(14.113)
13Herring actually treated a substitutional crystal with atoms and vacancies located on lattice sites, so μ
here is actually equal to the difference between his chemical potential of atoms and his chemical potential of
vacancies in an extended variable set. μ is also equal to the chemical potential of atoms in the vapor.
14With a Monge representation, it is necessary to use single-valued functions to represent various parts of a
body, which amounts to choosing the sign of nz = cos θ. Here we choose cos θ > 0 to obtain a positive value of
, with the understanding that the square root is positive.

242
THERMAL PHYSICS
which allows Eq. (14.112) to be written in the form
dZ = p dX + q dY.
(14.114)
By using Eq. (14.32), we deduce
 = nxX + nyY + nzZ
nz
= Z −pX −qY,
(14.115)
which establishes Eq. (14.110). Note that n2
z = 1 −n2
x −n2
y = 1 −n2
z(p2 + q2) which can be
solved for nz, resulting in
1/nz =

1 + p2 + q2,
(14.116)
consistent with Eq. (14.109). To establish the inverse transform, we calculate
d = dZ −p dX −X dp −q dY −Y dq = −X dp −Y dq,
(14.117)
where Eq. (14.114) has been used. From this differential we calculate
X = −
∂
∂p

q
;
Y = −
 ∂
∂q

p
,
(14.118)
which justiﬁes the second part of Eq. (14.111).
These Legendre transforms can also be established without using the ξ-vector by using
the calculus of variations with the surface represented by a Monge representation, as
shown in Appendix C, Section C.4.1.
14.8 Remarks About Solid-Solid Interfaces
Solid-solid interfaces are quite complicated if both phases are crystals, which are
anisotropic. For example, speciﬁcation of the interface between two crystals has ﬁve
degrees of freedom (geometrical parameters), three to specify the relative orientations of
the crystals (say, three Euler angles) and two to specify the orientation of the interface
(grain boundary) that separates them. Structure and properties vary considerably with
these ﬁve parameters because certain angles give rise to special lattice matchings.
Moreover, most such interfaces are characterized by rather intricate dislocation arrays.
The situation would be much simpler if one or both solids were amorphous.
For a detailed treatment of crystal-crystal interfaces, the reader is referred to Interfaces
in Crystalline Materials by Sutton and Balluﬁ[46]. The ﬁrst four chapters are devoted to
interface structure and are well beyond the scope of the present book. Chapter 5 is devoted
to thermodynamics of interfaces. Much of the formalism resembles that for ﬂuid-ﬂuid
and solid-ﬂuid interfaces but the variable set T, p, {μi} must be augmented by interfacial
strain variables εαβ and the geometrical parameters mentioned above. Considerations of
excess free energies and forces that are used for ﬂuid-ﬂuid and solid-ﬂuid interfaces can
sometimes be used for solid-solid interfaces; however, they should be used with great
care and might be completely inapplicable in some cases. For reasons of stability against

Chapter 14 • Thermodynamics of Solid-Fluid Interfaces
243
cleavage, the size of γ for a solid-solid interface cannot exceed the sum of the free energies
per unit area of the individual free surfaces. Heterophase interfaces typically have values
of γ that are several times larger than those for homophase interfaces. Grain boundary
free energies per unit area are usually less than those of a free surface because the number
of nearest neighbors of an atom in a grain boundary is comparable to that of an atom in
the bulk.

This page intentionally left blank 


This page intentionally left blank 

15
Entropy and Information Theory
The entropy S, which was introduced in Chapter 3 as a state function in connection
with the second law of thermodynamics, plays a special role in statistical mechanics.
Unlike the internal energy U, whose existence is an extension, although not a trivial one,
of the concept of energy in mechanics, the entropy is intrinsically statistical and has no
counterpart in mechanics. In thermodynamics, it is the conjugate variable to the absolute
temperature, which also has no counterpart in mechanics. Nevertheless, the entropy,
known since the time of Rudolf Clausius circa 1854, has its roots in information theory.
This connection had been appreciated for a long time but not quantiﬁed. In a letter to
Irving Langmuir, August 5, 1930, Gilbert Norton Lewis wrote [47, p. 400]:
It is not easy for a person brought up in the ways of classical thermodynamics to come
around to the idea that the gain of entropy eventually is nothing more nor less than loss
of information.
The quantiﬁcation of information in the context of communication theory was developed
somewhat later (1948) by Claude Shannon [48, 49]. Subsequently, Shannon’s communica-
tion theory was given a ﬁrm basis in probability theory by A.I. Khinchin [50].
15.1 Entropy as a Measure of Disorder
In order to understand the physical basis of entropy, it is often stated that entropy is a
measure of disorder in a system, although this concept is sometimes objected to on the
basis that common notions of disorder can disagree. Nevertheless, Shannon’s information
function, which we shall represent by the symbol D and refer to as the disorder function,
gives a mathematically precise deﬁnition of information, the opposite of which is disorder.
This disorder function is in complete agreement with the entropy of statistical mechanics,
for all of its ensembles, except for the value of a multiplicative constant that simply
accounts for units that are compatible with those chosen for energy and temperature.
In addition, the function D plays the same role (except for opposite sign) as the dynamical
function H(t) (also denoted by E(t) in Boltzmann’s writings) that enters Boltzmann’s Eta
theorem [51].
15.1.1 The Disorder Function
We consider a set of mutually exclusive events Ai for i = 1, 2, . . . , N that have respective
probabilities pi. Mutual exclusivity means that only one of them can occur for a given trial.
Khinchin calls this a “ﬁnite scheme.” We introduce a disorder function
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00015-6
247
Copyright © 2015 Elsevier Inc. All rights reserved.

248
THERMAL PHYSICS
D{pi} ≡D(p1, p2, . . . , pN)
(15.1)
that depends only on the set of probabilities {pi} and has the following additional
properties:
1. D{pi} takes on its minimum value, zero, when one of the pi is equal to unity and all of
the others are zero. This makes sense because the outcome of a trial is then certain, so
there is complete information and therefore no disorder.
2. D{pi} takes on its maximum value J(N) when the probabilities are all equal, that is,
pi = 1/N for all i. This is reasonable because the outcome of any trial could equally well
result in any of the possible events, so as little as possible is known about the outcome.
Speciﬁcally,
J(N) := D(1/N, 1/N, . . . , 1/N).
(15.2)
3. J(N) should be a monotonically increasing function of N because a measure of disorder
(lack of information) should increase if there is a larger possible number of outcomes.
4. The measure D should be independent of any manner in which the events are batched
and the disorder of the batching is added to the weighted respective disorders of the
batches. Thus if there are B batches (necessarily B ≤N) labeled by an index j with each
batch having a probability qj, then
D{pi} = D{qj} +
B

j=1
qjD{pi/qj}pi⊂qj.
(15.3)
Here, the notation pi ⊂qj means that pi belongs to the batch qj in which case qj =
pi⊂qj
i
pi. It therefore follows that pi⊂qj
i
pi/qj = 1, so pi/qj is the probability of Ai
within the batch j. For example, for N = 5 such a batching might be q1 = p1 + p2 and
q2 = p3 + p4 + p5, so p1/q1 = p1/(p1 + p2), p2/q1 = p2/(p1 + p2), etc.
Under these conditions, we shall proceed to demonstrate that the disorder function is
D{pi} = −k

i
pi ln pi,
(15.4)
where k is a positive constant. For a rigorous proof that this result is unique provided that
D{pi} is continuous with respect to all of its arguments, see Khinchin [50, p. 9].
We ﬁrst consider a special case of Eq. (15.3) for which all pi = 1/(BN) where B and N are
integers, so D{pi} = J(BN). We divide into B batches, each with N elements, so qj = (1/B)
and pi/qj = 1/N. Thus Eq. (15.3) becomes
J(BN) = J(B) +
B

j=1
1
BJ(N),
(15.5)
so
J(BN) = J(B) + J(N).
(15.6)

Chapter 15 • Entropy and Information Theory
249
We differentiate Eq. (15.6) partially with respect to B and then set B = 1 in the result to
obtain
NJ′(N) = J′(1) ≡k = constant,
(15.7)
where the prime indicates the derivative of a function with respect to its argument. The
solution to this differential equation, subject to J(1) = 0 which follows from condition
(1), is1
J(N) = k ln N.
(15.8)
Armed with the functional form Eq. (15.8), we return to Eq. (15.3) with pi = 1/N for all
i but with arbitrary batches having probabilities qj, in which case it becomes
J(N) = D{qj} +

j
qjJ(Nqj)
(15.9)
or
k ln N = D{qj} +

j
qj(k ln qj + k ln N).
(15.10)
After cancellation of the term k ln N, Eq. (15.10) becomes
D{qj} = −k

j
qj ln qj,
(15.11)
in agreement with Eq. (15.4).
From Eq. (15.11), condition (2) can be demonstrated by setting the result of partial
differentiation with respect to qi equal to zero, subject to the constraint 
j qj = 1, which
is easily handled by means of a Lagrange multiplier λ, that is, ∂/∂qi[D{qj} −λ 
j qj] = 0.
Details are left to the reader to show that all qi will be equal.
Since logarithms to any base are simply proportional to those for any other base, it is
customary in information theory to use logarithms to the base two and then to set the
overall constant equal to unity, resulting in the function
H2{pj} = −

j
pj log2 pj,
(15.12)
in which case the units of H2 are known as bits. For the 128 ASCII characters, the maximum
value of H2 would be J(128) = log2 128 = 7 bits.
To obtain the entropy function of statistical mechanics, one retains the natural loga-
rithm but chooses k to be Boltzmann’s constant kB = 1.38065 × 10−23 J K−1. Thus the
entropy
S{pj} = −kB

j
pj ln pj,
(15.13)
1Since we seek only to discover a functional form, we have treated B as a continuous variable but the result
also satisﬁes Eq. (15.6) when B is an integer.

250
THERMAL PHYSICS
where the pj are the probabilities of the quantum microstates of the system subject to
the constraints of the ensemble under consideration. For example, for the microcanonical
ensemble to be considered in Chapter 16, one considers an isolated system having known
energy E and makes the assumption that all compatible stationary quantum microstates,
which number , are equally probable. Then pj = 1/ for all j, so
S{pj} = −kB


j=1
(1/) ln(1/) = kB ln .
(15.14)
For the canonical ensemble (see Chapter 19), one ﬁnds that each pj is proportional to its
Boltzmann factor, which results in S = (U −F)/T, a valid thermodynamic equation. In
Chapter 22, we examine in detail the relationship between the disorder function D and
the entropy S for any ensemble, with due respect to the constraints of that ensemble.
Example Problem 15.1. Suppose2 that Eq. (15.13) gives the entropy of two systems, (1) and
(2), so
S(1) = −kB

i
p(1)
i
ln p(1)
i ;
S(2) = −kB

j
p(2)
j
ln p(2)
j ,
(15.15)
where p(1)
i
is the probability of state i for system (1) and p(2)
j
is the probability of state j for
system (2). If these two systems are combined to form a composite system having states ij with
probabilities Pij, the entropy of the composite system will be
S = −kB

ij
Pij ln Pij.
(15.16)
If the subsystems (1) and (2) are very weakly interacting, show that the entropy is additive,
S = S(1) + S(2).
Solution 15.1. If the systems interact sufﬁciently weakly that they are statistically indepen-
dent, then Pij = p(1)
i
p(2)
j
so
S = −kB

ij
p(1)
i p(2)
j

ln p(1)
i
+ ln p(2)
j

= −kB
⎡
⎣
i
p(1)
i
ln p(1)
i
+

j
p(2)
j
ln p(2)
j
⎤
⎦,
(15.17)
where we have used the normalizations 
i p(1)
i
= 1 and 
j p(2)
j
= 1.
Example Problem 15.2. Suppose Eqs. (15.15) and (15.16) apply but the systems interact such
that they are no longer statistically independent, so there are correlations and Pij ̸= p(1)
i
p(2)
j
.
Show that S < S(1) + S(2).
2This example and the one immediately following are based on problems in the book by Reif [52, p. 236].

Chapter 15 • Entropy and Information Theory
251
Solution 15.2. We can use the general relations
p(1)
i
=

j
Pij;
p(2)
j
=

i
Pij;

ij
Pij = 1.
(15.18)
We have
S −S(1) −S(2)
kB
= −

ij
Pij ln Pij +

i
p(1)
i
ln p(1)
i
+

j
p(2)
j
ln p(2)
j .
(15.19)
The second two terms on the right can be converted to double sums, so

i
p(1)
i
ln p(1)
i
+

j
p(2)
j
ln p(2)
j
=

ij

Pij ln p(1)
i
+ Pij ln p(2)
j

.
(15.20)
Thus,
S −S(1) −S(2)
kB
=

ij
Pij ln
⎛
⎝p(1)
i p(2)
j
Pij
⎞
⎠.
(15.21)
However, the inequality ln x ≤(x −1) holds for all positive x with equality only for x = 1. This
is true because x = 1 is also a point of tangency with slope 1 of the line y = 1 −x and the curve
y = ln x, but elsewhere the slope of ln x, namely 1/x, is less than 1 for x > 0 and greater than 1
for x < 0. Therefore
S −S(1) −S(2)
kB
≤

ij
Pij
⎛
⎝p(1)
i p(2)
j
Pij
−1
⎞
⎠=

ij

p(1)
i p(2)
j
−Pij

= 0,
(15.22)
with equality holding only for the uncorrelated case Pij = p(1)
i
p(2)
j
. We see that correlations
reduce the disorder, and therefore lead to a smaller entropy S of the composite system.
15.2 Boltzmann Eta Theorem
In 1872, Ludwig Boltzmann (1838-1906), one of the pioneers of statistical mechanics,
proved an important theorem, known as the Eta theorem, relating to the dynamics of an
ideal gas of hard spheres as it approaches equilibrium by means of elastic collisions [51].
The treatment was, of course, classical since quantum mechanics did not emerge until
about 1925. Boltzmann therefore described a homogenous gas in terms of a distribution
function f (v, t) such that3
3A more general Boltzmann equation for a nonhomogeneous gas can be based on a distribution function
f (r, v, t) such that f (r, v, t) d3r d3v is the probability that a sphere will have a position located in a volume element
d3r centered about position r and a velocity located in a volume element d3v centered about velocity v. See Reif
[52, p. 523] for such a treatment.

252
THERMAL PHYSICS
f (v, t) d3v
(15.23)
is the number of hard spheres per unit volume of actual space that have a velocity located
in a volume element d3v in velocity space centered about velocity v.
15.2.1 Boltzmann Equation
Boltzmann proceeded to derive a differential equation, known today as the Boltzmann
equation, to describe the time evolution of the gas as it approached equilibrium. He
assumed that only binary collisions occur and that the probability distribution function
for pairs is given by f (v1, v2, t) = f (v1, t)f (v2, t) which he based on an assumption of
“molecular chaos,” which we discuss later. He then set up a balance equation according to
which
∂f (v, t)
∂t
= rsi −rso,
(15.24)
where rsid3v is the rate per unit volume of actual space at which spheres are scattered
into d3v centered about v and rsod3v is the rate per unit volume of actual space at which
spheres are scattered out of the volume element d3v in velocity space, all by means of
binary elastic collisions.
To treat a hard sphere gas, we ﬁrst consider only two hard spheres, subscripts 1 and
2, having velocities v1 and v2 before a collision and v′
1 and v′
2 after that collision. Each
sphere is assumed to have the same diameter a. Later we will integrate over all possible
collisions.
Since energy and momentum are conserved for elastic collision of hard spheres, we
have
v2
1 + v2
2 = v′2
1 + v′2
2
(15.25)
and
v1 + v2 = v′
1 + v′
2.
(15.26)
Collisions can be understood better, however, in terms of the relative velocities before and
after collision, namely
g = v2 −v1;
g′ = v′
2 −v′
1.
(15.27)
By squaring g and g′ as well as squaring Eq. (15.26) and using Eq. (15.25), one sees readily
that g2 −g′2 = 0, so g and g′ have the same magnitude but differ in direction, as expected
for an elastic collision. Let ˆℓbe a unit vector along the line of centers of the spheres at the
time of collision. Then an elastic collision satisﬁes
g · ˆℓ= −g′ · ˆℓ;
g × ˆℓ= g′ × ˆℓ.
(15.28)
By crossing ˆℓinto the second member of Eq. (15.28), one readily obtains g′ = g −2(g · ˆℓ)ˆℓ,
so the second member of Eq. (15.27) becomes
v′
2 −v′
1 = g −2(g · ˆℓ)ˆℓ.
(15.29)

Chapter 15 • Entropy and Information Theory
253
Equation (15.29) can now be solved simultaneously with Eq. (15.26) to obtain
v′
1 = v1 + [(v2 −v1) · ˆℓ]ˆℓ
(15.30)
v′
2 = v2 −[(v2 −v1) · ˆℓ]ˆℓ,
(15.31)
which completely determines v′
1 and v′
2 as functions of v1 and v2 and two spherical angles,
θ and φ, that determine the unit vector ˆℓ.
Next we integrate over all possible collisions. In an inﬁnitesimal increment dt of time,
all spheres 2 in a cylinder of real space of length |g| dt and cross sectional area (a2/4) d
will collide with sphere 1 and scatter into solid angle d = sin θ dθ dφ, so4
rsod3v1 = a2
4

d

d3v2

|v2 −v1| f (v2, t)

f (v1, t) d3v1
(15.32)
rsid3v1 = a2
4

d

d3v′
2

|v′
2 −v′
1| f (v′
2, t)f (v′
1, t)

d3v′
1.
(15.33)
In Eq. (15.32), the integrations are only over  and v2 with v1 ﬁxed. In Eq. (15.33), the
integrations are only over  and v′
2 with v1 ﬁxed. Thus in Eq. (15.33), we need to think of
v′
1 as a function of v′
2, v1, and ˆℓthrough the relation v′
1 = v1 −[(v′
2 −v′
1) · ˆℓ]ˆℓ.
By differentiation of Eqs. (15.30) and (15.31), however, one can show that
dv
′2
1 + dv
′2
2 = dv2
1 + dv2
2 ,
(15.34)
which means that the transformation is orthogonal and has Jacobian unity. Thus, the
volume element d3v′
1 d3v′
2 = d3v1 d3v2. This is to be expected because it is a linear
transformation that is length preserving (see Eq. (15.25)), actually a rotation in a six-
dimensional space. We therefore obtain (after cancellation of d3v1)
rso = a2
4

d

d3v2

|v2 −v1| f (v2, t)f (v1, t)

(15.35)
rsi = a2
4

d

d3v2

|v2 −v1| f (v′
2, t)f (v′
1, t)

.
(15.36)
In Eq. (15.36), v′
1 and v′
2 are to be regarded as functions of v1, v2, and ˆℓ. Substitution into
Eq. (15.24) then leads to the Boltzmann equation
∂f (v1, t)
∂t
= a2
4

d

d3v2
|v2 −v1| [f (v′
2, t)f (v′
1, t) −f (v2, t)f (v1, t)] .
(15.37)
This is a complicated equation and its solution is a ﬁeld of study unto itself. See Reif
[52, chapters 13-14] for more detail on its derivation and approximate solution. It can be
generalized to treat inhomogeneous systems as well as particles other than hard spheres.
We shall follow Boltzmann by using the simpliﬁed Boltzman equation (Eq. (15.37)) to
prove a very important theorem.
4See [53] for a more detailed discussion of the collision geometry that leads to the factor a2/4. For collision
of particles other than hard spheres, this factor can be replaced by the collision cross section A(g, θ) under the
integral sign.

254
THERMAL PHYSICS
15.2.2 Eta Theorem
We follow Boltzmann in assuming that f (v, t) is a solution to the Boltzmann equation and
deﬁning the function of time
Eta(t) ≡E(t) ≡H(t) =

d3vf (v, t) ln f (v, t).
(15.38)
Then by clever manipulation, Boltzmann showed that
dH(t)
dt
≤0.
(15.39)
Thus the function H(t) decays to a minimum value, which corresponds to equilibrium.
We recognize that H(t) is a dynamical analog of the negative of the disorder function D{pj}
of the previous section. In other words, H(t) is expected to relate to the negative of the
entropy.
To prove Eq. (15.39), we ﬁrst differentiate Eq. (15.38) to obtain
dH(t)
dt
=

d3v1
∂f (v1, t)
∂t

1 + ln f (v1, t)

.
(15.40)
Then we substitute for the time derivative of f from the Boltzmann equation to obtain
dH(t)
dt
=a2
4

d3v1

d3v2

d

|v2 −v1| [f (v′
2, t)f (v′
1, t)
(15.41)
−f (v2, t)f (v1, t)]
 
1 + ln f (v1, t)

.
Because of the symmetry of the portion of the integrand in brackets {}, we can get the same
result by interchanging v1 and v2. Thus the integrand can also be written

|v2 −v1| [f (v′
2, t)f (v′
1, t) −f (v2, t)f (v1, t)]
 
1 + ln f (v2, t)

.
(15.42)
Adding these results and dividing by 2 gives
dH(t)
dt
=a2
4

d3v1

d3v2

d1
2

|v2 −v1| [f (v′
2, t)f (v′
1, t)
(15.43)
−f (v2, t)f (v1, t)]
 
2 + ln f (v1, t)f (v2, t)

.
Next we exchange the primed with the unprimed velocities but recall that |v′
2 −v′
1| =
|v2 −v1| and d3v′
1d3v′
2 = d3v1d3v2. Thus, the integrand in Eq. (15.43) can be written
1
2
|v2 −v1| [f (v2, t)f (v1, t) −f (v′
2, t)f (v′
1, t)]
 
2 + ln f (v′
1, t)f (v′
2, t)

.
(15.44)
By adding the forms given by Eqs. (15.43) and (15.44) and again dividing by 2, we obtain
dH(t)
dt
=a2
4

d3v1

d3v2

d1
4
|v2 −v1| [f (v′
2, t)f (v′
1, t)
(15.45)
−f (v2, t)f (v1, t)] ln f (v1, t)f (v2, t) −ln f (v′
1, t)f (v′
2, t) .

Chapter 15 • Entropy and Information Theory
255
The integrand of Eq. (15.45) has the form (x −y)(ln y −ln x) ≤0 for any positive x and y,
with equality only holding for x = y. Therefore, Eq. (15.39) is proven.
At equilibrium, dH/dt = 0 and the distribution functions f (v, t) become independent
of time, so we designate them by f0(v), resulting in the equilibrium condition
f0(v ′
2)f0(v ′
1) = f0(v2)f0(v1).
(15.46)
By taking the logarithm of Eq. (15.46), we obtain
ln f0(v′
2) + ln f0(v′
1) = ln f0(v2) + ln f0(v1),
(15.47)
which looks like a conservation condition for some property of spheres 1 and 2 before and
after collision. It must be related to the conservation of energy and momentum during a
collision.
Example Problem 15.3. Show that Eq. (15.47) is satisﬁed by the Maxwell-Boltzmann distri-
bution function
M(v −vr) = A exp[−(m/2kBT)(v −vr)2];
A = [m/(2πkBT)]3/2,
(15.48)
where vr is some reference velocity. This is a slight generalization of Eq. (19.70) that we derive
later for the case vr = 0.
Solution 15.3. We substitute Eq. (15.48) into Eq. (15.47). The quantity 2 ln A appears on both
sides and can be canceled. Then we divide both sides by −(m/2kBT) to obtain (v′
2 −vr)2 +
(v′
1 −vr)2 = (v2 −vr)2 + (v1 −vr)2. Multiplying out the squares and canceling v2r gives
(v′
1)2 + (v′
2)2 + 2vr · (v ′
2 + v ′
1) = (v1)2 + (v2)2 + 2vr · (v2 + v1).
(15.49)
In Eq. (15.49), the squared terms cancel by conservation of energy, Eq. (15.25), and the terms
dotted into vr cancel by conservation of momentum, Eq. (15.26).
In Boltzmann’s day, there were many objections to his Eta theorem on the grounds
that the equations of classical mechanics are invariant under time reversal. What was not
recognized, however, was that Boltzmann’s assumption of molecular chaos, f (v1, v2, t) =
f (v1, t)f (v2, t), (Stosszahlansatz in German, which literally means collision frequency
assumption) was a statistical assumption, not based on mechanics. For a detailed discus-
sion, see [53, p. 20]. The assumption of molecular chaos, not deterministic mechanics,
causes the system to evolve to a more probable state.
The Eta theorem as presented here should be regarded as a demonstration that for a
simple system there is a function −H(t), given by the negative of Eq. (15.38), that can only
increase in time for an isolated system, which of course would have constant energy. This
function has the same characteristics that we ascribe to the thermodynamic function S,
the entropy, that can only increase for an isolated system that changes from one state to

256
THERMAL PHYSICS
another. Note also that −H(t) has the same structure as the disorder function D{qj} given
by Eq. (15.11). The Eta theorem therefore demonstrates that the assumption of molecular
chaos leads to evolution to a more probable state. It is not a substitute for the second
law of thermodynamics, for which the entropy of any isolated thermodynamic system is
postulated to increase, subject to any internal constraints, until it reaches its maximum
possible value at equilibrium. The validity of the second law can be bolstered by statistical
analysis of more complex systems, but ultimately rests on agreement with experiments.

16
Microcanonical Ensemble
The general approach to statistical mechanics is based on the idea of an ensemble. An
ensemble is an imaginary collection of microstates that are compatible with a speciﬁed
macrostate of a thermodynamic system. A macrostate is speciﬁed by giving a complete
set of macroscopic state variables. The number of state variables necessary to constitute
a complete set depends on the complexity of the system; usually only a few are necessary.
The members (microstates) of the ensemble differ from one another microscopically and
are usually extremely large in number, approaching inﬁnity in the thermodynamic limit.
Each microstate that makes up an ensemble occurs with a probability that depends
on which set of macroscopic state variables are used to specify the macrostate. This
probability is chosen so that the ensemble represents, in a statistical sense, the macrostate.
Speciﬁcally, the ensemble is chosen such that averages of measurable quantities com-
puted by using it will lead to values representative of the macrostate. Such an approach
is necessary in statistical mechanics because speciﬁcation of a macrostate constitutes
incomplete information.
We believe that quantum mechanics ultimately governs all systems, even if classical
mechanics is a good approximation for some purposes. Therefore, we identify the mi-
crostates of a system in equilibrium with a set of stationary quantum states of that system.
Since we specify a macroscopic system by a small number of state variables, we cannot
know the total wave function of the system, which would constitute a speciﬁc knowledge
of a linear combination (time-dependent) of its stationary states; such a state is called
a pure state. All we will know for a system in equilibrium is a set of probabilities of
its stationary states. We will delay the formal quantum mechanical description of such
quantum systems until Chapter 26 where we introduce density operators and use them to
describe pure states and statistical states, also known as mixed states. Until then, it will
sufﬁce to know only the set of probabilities of the stationary states of an ensemble.
A classical system is described by speciﬁcation of the coordinates and momenta of
every particle in the system at some given time. As time evolves, the particles will move
and the system can be imagined to progress through other microstates that are compatible
with the given set of macroscopic state variables. Clearly there is a continuum of such
microstates, which are inﬁnite in number. Therefore, for a classical system it will only
be possible to specify a probability density function for a given hypervolume of phase
space (the space of all coordinates and momenta) since the probability of having a speciﬁc
classical microstate would be 0.
In the present chapter, we present the microcanonical ensemble which is applicable to
an isolated system whose macrostate is speciﬁed by its total energy and additional exten-
sive macrovariables, such as volume and number of particles, that altogether constitute
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00016-8
257
Copyright © 2015 Elsevier Inc. All rights reserved.

258
THERMAL PHYSICS
a complete set. This ensemble is of fundamental theoretical importance but its practical
usefulness is limited because of the complexity of computations required to enumerate
the microstates. In later chapters, we will introduce other more useful ensembles such as
the canonical ensemble, where temperature instead of energy is speciﬁed, and the grand
canonical ensemble where temperature instead of energy and chemical potential instead
of particle number are speciﬁed.
16.1 Fundamental Hypothesis of Statistical Mechanics
For an isolated thermodynamical system, we consider all microstates compatible with a
macrostate. For the sake of illustration, we will specify this macrostate by its total energy1
E, its volume V, and its number of particles N; more complex systems can be treated by
adding additional extensive state variables, specifying subsystems, etc. We consider our
system to be governed by quantum mechanics and therefore associate each microstate
with a stationary quantum state for the given quantities E, V, N. Since our system is
macroscopic, the difference between E and the energy levels of one of its particles is very
large compared to the differences among the energy levels of a particle. Thus, there is
massive degeneracy and hence a huge number of microstates for each macrostate. This
ensemble is usually referred to as the microcanonical ensemble.
The fundamental hypothesis is that every microstate of an isolated thermodynamic
system that is compatible with a given macrostate of such a system is equally probable. If 
is the total number of compatible microstates for a given macrostate, then the probability
of each microstate is 1/.
It follows from this hypothesis that the expected value ⟨y⟩of any property y of the
system is given by
⟨y⟩= (1/)


ν=1
yν,
(16.1)
where yν is the value of y in the microstate with label ν. Furthermore, the entropy of the
system is deﬁned to be
S = kB ln ,
(16.2)
where kB is Boltzmann’s constant. Equation (16.2) is exactly the function given by
Eq. (15.14) that was based on the disorder function D{pi} for the case pi = 1/. The
classical counterpart to Eq. (16.2) was proposed by Boltzmann and will be discussed
in the next chapter.
Since S is a monotonically increasing function of , maximizing  is consistent with
the second law of thermodynamics, according to which S for an isolated system will be a
1This is the total internal energy of the system which excludes macroscopic kinetic energy associated with
motion of the center of mass. Here, we use the symbol E instead of U to make a subtle distinction because we
specify the energy rather than calculating its average value from a knowledge of other state variables, for example,
the temperature.

Chapter 16 • Microcanonical Ensemble
259
maximum at equilibrium, with respect to variations of its internal extensive parameters
and subject to any internal constraints. To better illustrate what this means, we consider a
composite system made up of two subsystems with energies E1 and E2, volumes V1 and V2,
and particle numbers N1 and N2. Furthermore, we assume that the subsystems are very
weakly interacting and statistically independent so that  = 1(E1, V1, N1)2(E2, V2, N2),
where the total quantities E = E1+E2, V = V1+V2, and N = N1+N2. So even with E, V, and
N held constant, (E, V, N, E1, V1, N1) still depends on the partitioning of energy, volume,
and particle numbers between the two subsystems. Since  = 12, the total entropy is
simply additive, resulting in
S = kB ln  = kB ln(12) = kB ln(1) + kB ln(2) = S1 + S2.
(16.3)
With E, V, N, V1, and N1 held constant, maximizing ln  with respect to E1 gives
∂ln 
∂E1
= 1
1
∂1
∂E1
+ 1
2
∂2
∂E2
∂E2
∂E1
= 1
1
∂1
∂E1
−1
2
∂2
∂E2
= 0.
(16.4)
But (1/1)∂1/∂E1 = (1/kB)∂S1/∂E1 = T1/kB and similarly (1/2)∂2/∂E2 = T2/kB, so
Eq. (16.4) is equivalent to equality of absolute temperature, T1 = T2. Similarly, maximizing
with respect to V1 gives equality of pressure, and maximizing with respect to N1 gives
equality of chemical potential. If a system cannot be decomposed into statistically
independent subsystems,  will not factor and it will be difﬁcult to enumerate the
microstates, but the maximization of  and hence S will still be a valid criterion for
equilibrium.
The considerations of the preceding paragraph are still valid if the two subsystems
are actually portions of the same system that are initially isolated from one another
by constraints that forbid exchange of energy, volume, and mole numbers. Then
 = 
′(E
′, V
′, N
′)
′′(E
′′, V
′′, N
′′). As these constraints are gradually relaxed, each subsys-
tem can proceed through a series of equilibrium states until  = 
′′′ is maximized. We
can therefore say that  is proportional to the probability of a macrostate. The quantity
1/ is the probability of each microstate of the ensemble that represents that macrostate.
For further support that  is proportional to the probability of a macrostate, the reader is
referred to Section 19.1.3 in which the number of ways Wens of constructing an ensemble
from members, each of which is in a single eigenstate i, is related to the probability Pi
of occurrence of that eigenstate in the ensemble. If every member of the ensemble has
the same energy, as it would for the microcanonical ensemble, Wens will be a maximum
when all probabilities are equal. See also Chapter 22 where the entropy of any ensemble
is discussed in terms of maximizing a probability. Moreover, since S given by Eq. (16.2) is
proportional to the maximum value of the disorder function D{qi} given by Eq. (15.11),
a macrostate of maximum entropy, and hence maximum , is a state of maximum
disorder, equivalent to a state with minimum information content, compatible with
constraints.
In some books on statistical mechanics, there is an attempt to justify the fundamental
assumption of equal probability of each compatible microstate from other considerations.

260
THERMAL PHYSICS
The basic idea for classical systems, see Landau and Lifshitz [7], is that a macroscopic
system in equilibrium is assumed to progress in time through phase space so that it visits
every allowed volume of phase space with equal probability. This is sometimes called the
ergodic hypothesis. The quantum analog would be to assume that every microstate is
visited with equal probability over a time τ that is long compared to some characteristic
relaxation time. The measurement of some physical property of a thermodynamic system
is given by a time average of the form
¯y = 1
τ
 τ
0
y(t) dt.
(16.5)
Thus, the time average would be equal to the ensemble average, that is,
⟨y⟩= ¯y
(16.6)
for a system in equilibrium. In this book, we shall assume that Eq. (16.6) is true. In the last
analysis, Eqs. (16.1), (16.2), and (16.6) are hypotheses that have borne up under the test of
experiment. In Chapter 26, we introduce the statistical density operator and give a more
detailed discussion of ensemble averages and time averages in the context of quantum
mechanics.
Under conditions for which a macroscopic system can be described approximately
by a set of N particles that obey classical mechanics, we do not have access to the
concept of stationary quantum states. As discussed in the next chapter, we take  to be
proportional to the volume of phase space (volume of momentum space times volume
of actual space) in a thin shell near a hypersurface that corresponds to the total energy,
E. It turns out that the volume of the shell itself is not important. Indeed, isolation of a
system is only an idealization and therefore an approximation, so there will always be
a small uncertainty in its energy. Landau and Lifshitz [7] refer to such systems as being
quasi-isolated. Nevertheless, to agree ultimately with quantum mechanics, it is necessary
to assume that the number of microstates in a volume element (dp dq)3N is given by
(dp dq/h)3N where h is Planck’s constant.2 This is an artiﬁcial prescription that has no
real basis in classical mechanics, for which Planck’s constant is effectively 0.
The microcanonical ensemble is easy to deﬁne but very hard to use because of
the difﬁculty in cataloging and enumerating the microstates that are compatible with
speciﬁcation of the macrostate. For simple systems this is possible, as we shall illustrate
for two-state subsystems, simple harmonic oscillators and ideal gases. The main value
of the microcanonical ensemble is its theoretical importance, and we shall use it later to
derive the canonical ensemble and the grand canonical ensemble which are much more
tractable.
2This result holds for identical but distinguishable particles. For an ideal gas, the number of microstates is
approximately (dp dq/h)3N (1/N !) at high temperature and low density. The extra Gibbs factor of 1/N ! is needed
to make the entropy an extensive function and follows from quantum mechanics for identical indistinguishable
particles. See Section 16.4 for further details.

Chapter 16 • Microcanonical Ensemble
261
16.2 Two-State Subsystems
We consider a system consisting of N subsystems (particles) ﬁxed in a solid, each having
two quantum states that correspond to nondegenerate energy levels, 0 and ε. The particles
are assumed to be identical except for their locations (their positions in the solid) which
makes them distinguishable. We might think of each particle as a quantum system having
spin 1/2 under conditions for which the two states “spin up” and “spin down” have
different energies, perhaps because of an externally applied magnetic ﬁeld. The particles
are assumed to interact very weakly, so that their interaction energy is negligible but still
sufﬁcient to enable them to come to equilibrium with one another.
If we consider a quantum state of the system in which M particles are in the state with
energy ε, the total energy of that quantum state is E = Mε and the number of microstates
(its degeneracy) is
(N, E) =
N!
(N −M)!M! = g(N, M).
(16.7)
The quantity g(N, M) is sometimes called the multiplicity function. Thus
S = kB ln  = kB[ln N! −ln(N −M)! −ln M!].
(16.8)
By using the ﬁrst two terms in Stirling’s approximation in the form of Eq. (A.1), we obtain
S ∼kB[N ln N −(N −M) ln(N −M) −M ln M].
(16.9)
Note that the second term in Stirling’s approximation (see Appendix A) makes no contribu-
tion to this result because of an exact cancellation. Other terms in Stirling’s approximation
have been dropped because they would lead to sub-extensive results of order ln N or
smaller.
To see that the entropy given by Eq. (16.9) is an extensive function, we can write it in
the form
S = −NkB[(1 −M/N) ln(1 −M/N) + (M/N) ln(M/N)],
(16.10)
in which the substitution M = E/ε yields the fundamental equation, S(E, N), of the
system. The ratios M/N = E/(εN) are intensive3 variables, so the form of Eq. (16.10)
shows it to be the product of an extensive quantity N and an intensive quantity in square
brackets, which shows explicitly that S is extensive. This is not apparent from Eq. (16.9)
because expressions such as N ln N are not extensive.
Figure 16–1 shows a plot of S/(NkB) versus M/N. For convenience we show a contin-
uous curve, although only integer values of M are allowed. This is justiﬁed because N is
very large, perhaps of order 1020, so changes of M/N are of order 10−20 as M changes
by unity. We observe that the curve is symmetric about its maximum, which occurs at
M/N = 1/2. It has a positive slope for M/N ≤1/2, zero slope for M = 1/2, and a negative
3We know that Stirling’s approximation is only valid for large numbers, so one might worry about small values
of M. However, only values of M that are comparable to N ≫1 will lead to signiﬁcant results. Therefore,
M = E/ε must be regarded as an extensive quantity.

262
THERMAL PHYSICS
0.2
0.4
0.6
0.8
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
S/(NkB)
M/N
FIGURE 16–1 Dimensionless entropy S/(N kB) versus dimensionless energy M/N = E/(N ε) for a two-state system
according to Eq. (16.10). The portion of the curve for M/N > 1/2 corresponds to negative temperatures, which do
not represent equilibrium states in thermodynamics.
slope for M/N > 1/2. As we shall see subsequently, this slope is proportional to 1/T so
only 0 < M/N < 1/2 corresponds to positive ﬁnite temperatures. Indeed, M/N = 1/2
corresponds to T = ∞. The range of values 1/2 < M/N < 1 corresponds to negative
temperatures, which are not allowed in thermodynamics.4
Since M is a nearly continuous variable, we can calculate the absolute temperature as
a derivative,
1
T =
 ∂S
∂E

N
= kB
dM
dE
∂ln g
∂M

N
= −kB
ε ln

M/N
1 −M/N

.
(16.11)
Figure 16–2 shows a plot of kBT/ε as a function of M/N. We see that only the range
M/N < 1/2 leads to positive values of T, as anticipated above. Equation (16.11) can be
solved to yield
0.2
0.4
0.6
0.8
1
-30
-20
-10
10
20
30
kBT/ε
M/N
FIGURE 16–2 Dimensionless temperature kBT/ε versus dimensionless energy M/N = E/(N ε) for a two-state system
according to Eq. (16.11). Only positive values of T are thermodynamically signiﬁcant and these correspond to
M/N < 1/2. See Figure 16–3 for better resolution of the shape near T = 0.
4Fictitious negative temperatures are sometimes used to characterize nonequilibrium states in which the
populations of states having high energies are greater than those having lower energies.

Chapter 16 • Microcanonical Ensemble
263
p1 := M
N =
exp(−ε/kBT)
1 + exp(−ε/kBT)
(16.12)
for the probability p1 of occupation of the state ε. The probability of occupation of the
ground state is
p0 := N −M
N
= 1 −p1 =
1
1 + exp(−ε/kBT).
(16.13)
The quantity exp(−ε/kBT) is called a Boltzmann factor; it is very small for low temper-
atures and nearly equal to 1 at very high temperatures. Thus, at very high temperatures,
p0 = p1 = 1/2 and the levels have equal population, a condition known as equipartition.
Negative values of T correspond to nonequilibrium states in which the population is
inverted, that is, p1 > p0. Such states do not occur naturally at equilibrium but can be
brought about by “pumping” of the upper state from some higher state that decays, as
might take place in a laser.
Substitution of M = E/ε into Eq. (16.12) gives the energy5 of the system as a function
of temperature, namely
E = Nε
exp(−ε/kBT)
1 + exp(−ε/kBT).
(16.14)
As T increases from 0, the energy increases from 0 to Nε/2, as shown in Figure 16–3. An
expression for the entropy as a function of temperature can be obtained by substitution of
Eqs. (16.12) and (16.13) into Eq. (16.10) to obtain
S = −NkB(p0 ln p0 + p1 ln p1).
(16.15)
A plot of S versus T is shown in Figure 16–4. As T increases from 0, we see that S
increases from 0, in agreement with the third law of thermodynamics, and becomes equal
to NkB ln 2 at very high temperatures.
0.5
1
1.5
2
2.5
3
3.5
4
0.1
0.2
0.3
0.4
0.5
E/(Nε)
kBT/ε
FIGURE 16–3 Dimensionless energy E/(N ε) versus dimensionless temperature kBT/ε for a two-state system
according to Eq. (16.14). At T = 0, all particles are in the ground state. As T →∞, the states become equally
populated so that the average energy per particle is ε/2.
5If the ground state of the particle had been at energy ε0, its excited state would have energy ε0 + ε and the
total energy E would contain an additional term N ε0.

264
THERMAL PHYSICS
1
2
3
4
0.1
0.2
0.3
0.4
0.5
0.6
0.7
S/(NkB)
kBT/ε
FIGURE 16–4 Dimensionless entropy S/(N kB) versus dimensionless temperature kBT/ε for a two-state system
according to Eq. (16.15). At T = 0, all particles are in the ground state and S = 0. As T →∞, the states become
equally populated so S/(N kB) →ln 2 = 0.693.
The case of two-state subsystems is sufﬁciently simple that one can calculate explicitly
the relationship between the multiplicity functions of two subsystems and the multiplicity
function of the combined system that results when these subsystems are combined and
come to thermal equilibrium. In their book Thermal Physics [6], Kittel and Kroemer show
that the multiplicity function for a spin system is highly peaked about the value s = 0
where s = N/2 −M is called the spin excess of the ground state. Thus, 2s is the number
of spins in the ground state (“spin up”) minus the number of spins in the state having
higher energy (“spin down”). When two spin subsystems are combined and come to
thermal equilibrium, the combined system will have a multiplicity function that depends
on the narrow region of overlap between the high peaks of the subsystems. We follow
Kittel and Kroemer and carry out this calculation in more detail in Appendix D where
we also demonstrate explicitly the additivity of entropy when two such systems are
combined.
Example Problem 16.1. Consider an isolated system having energy E and consisting of N
identical but distinguishable subsystems, each having two energy levels that are degenerate.
One level has energy 0 and degeneracy d0 and the other level has energy ε and degeneracy d1.
Use the microcanonical ensemble to compute the entropy of this system and then compute its
temperature and the probability of occupation of the level with energy ε.
Solution 16.1. If M = E/ε is the number of particles in the level having energy ε, the
multiplicity function is
d(N, E) =
N!
(N −M)!M!(N −M)d0(M)d1.
(16.16)
Thus the entropy is given by
S/kB = N ln N −(N −M) ln(N −M) −M ln M + (N −M) ln d0 + M ln d1.
(16.17)

Chapter 16 • Microcanonical Ensemble
265
The temperature is given by
1
kBT = ∂d
∂E = 1
ε ln
(N −M)d0
Md1

,
(16.18)
which can be solved for M to give the required probability
M
N =
d1 exp(−ε/kBT)
d0 + d1 exp(−ε/kBT).
(16.19)
The form of this result can be understood by using the canonical ensemble, Chapter 19.
16.3 Harmonic Oscillators
We consider a system of N harmonic oscillators, each ﬁxed in a solid and having an inﬁnite
number of nondegenerate energy levels6 εn = nε = n¯hω where the integer n = 0, 1, 2, . . . .
The symbol ¯h = h/2π, where h = 6.626069 × 10−34 J s is Planck’s constant, is pronounced
“h-bar” and appears frequently in the equations of quantum mechanics. It has the value
¯h = 1.054572 × 10−34 J s = 1.054572 × 10−27 erg s. A useful related constant is ¯h/kB =
7.638234 K s. See http://physics.nist.gov/cuu/constants for the latest internationally rec-
ommended values of physical constants. We consider a macrostate of the system having
total energy E = Mε and denote the multiplicity function for this state by gH(N, M).
We can calculate gH by means of the following device illustrated in Figure 16–5.
Between ﬁxed ends of a box, we place N −1 movable partitions. These partitions divide the
box into N intervals, each interval representing a particle. The number of X symbols in an
interval designates the energy of that particle in units of ε. The total energy is E = Mε,
where M is the total number of X symbols. The multiplicity function gH(N, M) is the
number of distinct arrangements of the X symbols and the movable partitions, namely
(N, E) = (N −1 + M)!
(N −1)!M!
= gH(N, M).
(16.20)
en
e
d
nd
X
X
X
X
X
X
X
X
X
X
X
X
FIGURE 16–5 Diagram illustrating an algorithm for calculating the multiplicity function for the harmonic oscillator.
Between ﬁxed ends of a box (long lines) we place N −1 = 15 movable partitions (short lines). These partitions divide
the box into N = 16 intervals, each representing a particle. The number of X symbols in an interval designates the
energy of that particle in units of ε. The total energy is E = Mε = 12ε, where M = 12 is the number of X symbols.
As shown, there are eight particles with energy 0, ﬁve particles with energy ε, two particles with energy 2ε, and one
particle with energy 3ε. The multiplicity function gH(N , M) = gH(16, 12) is the number of distinct arrangements of
the X symbols and the movable partitions, namely 27!/(15! 12!) = 17,383,860.
6We omit the zero point energy ¯hω/2 for simplicity since it only shifts the overall energy by N ¯hω/2.

266
THERMAL PHYSICS
This same result can be derived by using a generating function, as shown below in
Section 16.3.1.
For a thermodynamic system consisting of N harmonic oscillators, the entropy will be
S = kB ln gH(N, M);
M = E/ε.
(16.21)
Therefore,
S = kB[ln(N −1 + M)! −ln(N −1)! −M ln M!].
(16.22)
Again we use Stirling’s approximation and consistent with this we approximate N −1 ≈N
to obtain7
S ∼kB[(N + M) ln(N + M) −N ln N −M ln M]
= −NkB
M
N ln
M
N + M + ln
N
N + M

,
(16.23)
where the second form demonstrates that S is extensive.
Thus the absolute temperature can be calculated from
1
T =
 ∂S
∂E

N
= ∂M
∂E
 ∂S
∂M

N
= kB
ε ln N + M
M
,
(16.24)
where we have used the ﬁrst form of Eq. (16.23) to ease calculation of the derivative with
respect to M. Hence, Eq. (16.24) yields
M
N =
1
exp(ε/kBT) −1,
(16.25)
or equivalently
E = Nε
1
exp(ε/kBT) −1.
(16.26)
Since M is equal to the sum of the actual number of quantum numbers n of a single
oscillator, the average quantum number of an oscillator is given by
⟨n(T)⟩:= M
N =
1
exp(ε/kBT) −1.
(16.27)
As T increases from 0, ⟨n⟩increases very slowly and tends to the value kBT/ε as T becomes
large. Since a given oscillator has an inﬁnite number of states, both ⟨n⟩and E continue to
increase linearly with T at large T. In fact, E ≈NkBT independent of ε for large T. This is
consistent with the fact that the average thermal energy of a classical harmonic oscillator
is independent of its oscillation frequency, as will be seen later.
By returning to Eq. (16.23), we can write the entropy in the form
S = −NkB

ln

1
1 + ⟨n⟩

+ ⟨n⟩ln

⟨n⟩
1 + ⟨n⟩

.
(16.28)
7By using Stirling’s approximation, we are already assuming that N ≫1 and dropping terms of order ln N
and smaller relative to N . It would be inconsistent to keep 1 relative to N .

Chapter 16 • Microcanonical Ensemble
267
This expression can also be written in the form
S = −NkB

ln(1 −e−x) −
x e−x
(1 −e−x)

,
(16.29)
where x = ε/kBT. As T increases from 0, S increases slowly from 0. For large T, x becomes
very small and we can expand Eq. (16.29) to obtain
S ≈NkB

−ln x + 1
	
= NkB

ln(kBT/ε) + 1
	
.
(16.30)
Thus, due to the availability of an inﬁnite number of energy levels of a given oscillator, the
entropy continues to increase with T. See Section 18.3 for an alternative derivation and
relevant graphs.
16.3.1 Generating Function
As mentioned above, we can derive the multiplicity function gH(N, M), given by
Eq. (16.20) for the simple harmonic oscillator, by another method involving a generating
function. We observe that gH(N, M) is the coefﬁcient of tM in the series expansion
⎛
⎝
∞

j=0
tj
⎞
⎠
N
= (1 + t + t2 + · · · )N =

M
gH(N, M)tM.
(16.31)
But
∞

j=0
tj =
1
1 −t ,
(16.32)
so we have
gH(N, M) =
1
M!
 d
dt
M 
1
1 −t
N 
t=0
.
(16.33)
Carrying out the required differentiation and evaluation at t = 0 readily yields Eq. (16.20).
In principle, this method can also be used for subsystems having any ﬁnite number of
states equally spaced in energy, but the results can be cumbersome. Thus, for two-state
subsystems one could ﬁnd the coefﬁcient of tM in the expansion of (1 + t)N which would
lead immediately to Eq. (16.7). For subsystems with three equally spaced states, one would
require the coefﬁcient of tM in the expansion of (1 + t + t2)N .
16.4 Ideal Gas
The monatomic ideal gas is a tractable example of a system of identical indistinguishable
particles that can be treated by means of the microcanonical ensemble. It is especially
important because it serves as a link between quantum statistical mechanics and classical
statistical mechanics, as we shall see in Chapter 17. Atoms of the gas are conﬁned to a box
of volume V that they share. Therefore, our macroscopic view of the system precludes

268
THERMAL PHYSICS
knowledge of which atoms occupy any particular sub-volume of the box. This is quite
different from the case of identical particles in a solid that are essentially immobile and
may be distinguished by virtue of their position.
An important advance in proper counting of such microstates was made by Gibbs in
the context of classical statistical mechanics. For a monatomic gas of N particles, Gibbs
reasoned that one should divide the volume of phase space occupied by the particles by
N! to correct for the fact that there are N! permutations of the particles that do not lead
to states of the system that can be distinguished macroscopically. Without this division by
N!, the calculated entropy is not an extensive function, so it is surely incorrect and leads
to an inconsistency known as the Gibbs paradox.8 As we shall see, we can readily count
the states of N free quantum particles in a box as if the particles were distinguishable. If
we use the Gibbs correction factor of 1/N! to correct this count, we obtain an entropy that
is extensive. This is satisfying and gives a good result for an ideal gas at high temperatures
and low density. It is, however, not a correct quantum mechanical result under other
conditions. To get a correct quantum mechanical result, one must construct a total
wave function of the gas that is either an antisymmetric or a symmetric function on
interchange of any two particles, depending on whether they are fermions or bosons,
respectively. This will result in corrections that are important at low temperatures and high
number densities. We defer detailed treatment of such quantum statistical effects until
Section 26.7. Here, we give only an approximate treatment based on the Gibbs correction
factor.
16.4.1 Monatomic Ideal Gas with Gibbs Correction Factor
We give a pseudo-quantum mechanical treatment of a monatomic ideal gas, including the
Gibbs correction factor. We use periodic boundary conditions and wave functions that are
also eigenfunctions of the momentum operator. For a single free particle in a cubical box
of volume V, the wave function is
ψk(r) = V −1/2 exp(ik · r),
(16.34)
which satisﬁes
ˆHψk = εkψk
(16.35)
with εk = ¯h2k2/(2m). Here, ˆH = ˆp2/2m, where ˆp = (¯h/i)∇is the momentum operator. For
periodic boundary conditions, the allowed values of k are
k = 2π
V 1/3 [nx ˆi + ny ˆj + nz ˆk],
(16.36)
8According to the Gibbs paradox, the additional entropy from mixing identical gases, each having the same
temperature and pressure as the ﬁnal mixture, turns out to be positive rather than zero, as it should be for a
process that is clearly reversible. See Pathria [8, p. 22] for details.

Chapter 16 • Microcanonical Ensemble
269
where ˆi, ˆj, ˆk are the Cartesian unit vectors and nx, ny, nz are positive and negative integers
and zero. The states of a single particle of energy ε lie on the surface of the sphere
n2
x + n2
y + n2
z = 2mε V 2/3/h2.
(16.37)
The total energy E will be the sum of the energies of the individual particles because
particles of an ideal gas do not, by deﬁnition, have an interaction energy. The number of
quantum states for N distinguishable particles is therefore equal to the number of allowed
solutions to9
3N

r=1
n2
r = 2mE V 2/3/h2 = R2,
(16.38)
where R := (2mE V 2/3/h2)1/2 is the dimensionless radius of a hypersphere in 3N-
dimensional space. Allowed solutions are those for which each nr is a positive or
negative integer or zero. Of course no such solutions exist unless R2 is an integer, but to
circumvent this technicality we shall actually count solutions in a thin shell corresponding
to energies between E −
E and E, or equivalently between R −
R and R, where

R/R ≈
E/(2E).
The number of solutions to Eq. (16.38) for any radius less than or equal to R will be equal
to the volume VR of the hypersphere given by Eq. (16.38). Obviously this volume will be
proportional to R3N but the proportionality constant will depend on the dimensionality
3N of the space. A simple derivation is given by Pathria [8, p. 504] and results in
VR =
π3N /2
(3N/2)!R3N = V N (mE/2π¯h2)3N /2
(3N/2)!
.
(16.39)
Here, (3N/2)! should be interpreted as the gamma function (3N/2 + 1) in case N is an
odd integer. Since, however, 3N is extremely large, almost all of these solutions lie near the
surface of the hypersphere. In fact, the fraction of the volume of the hypersphere that lies
within 
R of the surface is just
F := 1 −

1 −
R
R
3N
≈1 −exp(−3N
R/R) ≈1 −exp(−3N 
E/2E).
(16.40)
The number of solutions to Eq. (16.38) in the thin shell near E is therefore
0 = FVR = [1 −exp(−3N
E/2E)]VR ≈VR.
(16.41)
9To simplify the notation, for particle number 1 we let nx = n1, ny = n2, nz = n3 and for particle number 2
we let nx = n4, ny = n5, nz = n6, etc. The wave function of the whole system can be made up of products of the
wave functions of the individual particles, consistent with the additivity of particle energies. Nevertheless, true
quantum mechanical considerations also restrict the symmetry of the wave function under an interchange of
identical particles, which is discussed in detail in Section 26.7. Here, in the spirit of treating a classical ideal gas,
we omit that complication but make up for it by using the Gibbs factor N ! in Eq. (16.44) to correct approximately
the count of the number of microstates.

270
THERMAL PHYSICS
Thus,10
ln 0 = ln VR + ln[1 −exp(−3N
E/2E)] ≈ln VR −exp(−3N
E/2E).
(16.42)
The second term is clearly negligible, so substitution of Eq. (16.39) and use of Stirling’s
approximation gives
ln 0 ≈ln VR ∼N ln

V

mE
3π¯h2N
3/2
+ 3
2N,
(16.43)
essentially independent of any reasonable choice for 
E. As shown in the following
example and elsewhere [8, p. 17], this result is the same as would be obtained for wave
functions that vanish on the walls of the box.
One might be tempted to equate the entropy to kB ln 0 but that would be incorrect
because ln 0 is not an extensive function. The argument of the logarithm contains the
ratio E/N which is intensive, but it also contains V without N. To get a corrected value
for the number of states, we must account for the fact in observing such a system we have
no way of distinguishing the particles. We follow Gibbs and divide 0 by the number of
indistinguishable states N! to get the corrected number of microstates
 ≈0
N! = V N (mE/2π¯h2)3N /2
N!(3N/2)!
.
(16.44)
Thus
S = kB ln  ≈kB[ln 0 −N ln N + N]
(16.45)
(where Stirling’s approximation has been used), which results in
S = NkB ln

V
N

mE
3π¯h2N
3/2
+ 5
2NkB.
(16.46)
The entropy given by Eq. (16.46) is clearly an extensive function. The temperature is
given by 1/T = (∂S/∂E)V,N = (3/2)NkB/E, so in terms of the temperature we can write
the entropy in the form
S = NkB ln nQ/n + 5
2NkB,
(16.47)
where
10Many treatments take the volume of the spherical shell to be (dVR/dR)
R = VR3N 
R/R = VR 3N 
E/2E
and then argue that ln(VR 3N 
E/2E) ≈ln VR. That result would be obtained if the exponential in the expression
for F were expanded, which procedure is incorrect for huge N . A more accurate expression can be obtained by
setting y = (1 −
R/R)3N so ln y = 3N ln(1 −
R/R) ≈−3N 
R/R, and then exponentiating. In fact, isolation
of a system is only an idealization which is the rationale for some ﬁnite 
E, notwithstanding implications of the
uncertainty principle. Thus if atoms near the surface of a body were to interact weakly with its environment, one
might expect 
E/E ∼N 2/3/N = N −1/3 so 3N 
E/2E ∼N 2/3 which is huge. After taking ln 0, the additive term
ln F is negligible with respect to ln VR, so ultimately one arrives at the same result as usually quoted. Our more
precise analysis shows that the neglected term is much smaller than usually claimed.

Chapter 16 • Microcanonical Ensemble
271
nQ(T) :=
mkBT
2π¯h2
3/2
(16.48)
is known as the quantum concentration and n := N/V is the actual concentration. Divi-
sion of 0 by N! is a good approximation to  if the probability of multiple occupation
of single particle states is negligible. Thus, Eq. (16.47) is valid provided that the actual
concentration n is small compared to the quantum concentration nQ. This will be the
case at sufﬁciently high temperatures and low densities and will be borne out by a
complete quantum mechanical analysis. From Eq. (16.46), we can calculate the chemical
potential
μ = −T
 ∂S
∂N

E,V
= kBT ln(n/nQ) = kBT ln[p/(nQkBT)].
(16.49)
The quantity nQkBT can be thought of as a quantum pressure. Note that (∂S/∂N)E,V ̸=
(∂S/∂N)T,V because E = (3/2)NkBT. On the other hand, the relationship between E and
T does not involve V for an ideal gas. Thus the pressure of an ideal gas can be computed
by holding either E or T constant, resulting in
p/T =
 ∂S
∂V

N ,E
=
 ∂S
∂V

N ,T
= NkB/V ,
(16.50)
which is the familiar ideal gas equation of state.
Example Problem 16.2. Show for an ideal gas in a box having the shape of a rectangular
parallelepiped with dimensions H, K, L that one obtains the same result for 0 as given by
Eq. (16.41) for periodic boundary conditions and for boundary conditions for which the wave
function ψ = 0 on the walls of the box.
Solution 16.2. We still have ε = ¯h2k2/2m and for periodic boundary conditions,
k = 2π
nx
H
ˆi + ny
K
ˆj + nz
L
ˆk

,
(16.51)
where nx, ny, nz are positiveand negative integers and zero. For ψ = 0 on the walls, the solutions
are of the form ψ ∝sin(kxx) sin(kyy) sin(kzz) with
k = π
nx
H
ˆi + ny
K
ˆj + nz
L
ˆk

,
(16.52)
but now nx, ny, nz are only positive integers (because negative integers would only result
in a change of phase, not a linearly independent eigenfunction). In the case of Eq. (16.51),

nx
ny
nz = HKL/(2π)3
kx
ky
kz so the density of states in k space for a single particle
is V /(2π)3 where the volume V = HKL. For N particles, the density of states is therefore

V /(2π)3N
. In the case of Eq. (16.52), 
nx
ny
nz = HKL/(π)3
kx
ky
kz so the density of
states in k space for a single particle is V /(π)3, and for N particles it is [V /(π)3]N . The volume
of an entire hypersphere in 3N-dimensional k space with radius (2mE/¯h2)1/2 is

272
THERMAL PHYSICS
Vk = π3N /2
(3N/2)!(2mE/¯h2)3N /2.
(16.53)
To get the corresponding number of states in the case for periodic boundary conditions, we
multiply Vk by

V /(2π)3N
. But for the case of ψ = 0 on the walls, only positive values of ki are
allowed, so we must ﬁrst multiply Vk by (1/23)N and then by [V /(π)3]N , resulting in the same
net factor [V /(2π)3]N of Vk. So in either case, the number of states (not yet corrected by the
Gibbs factor) is

V
(2π)3
N
Vk = V N (mE/2π¯h2)3N /2
(3N/2)!
,
(16.54)
the same as VR given by Eq. (16.39).
16.4.2 Scaling Analysis
As noted by Pathria [8, p. 16], many important results for the ideal gas can be ascertained
from a simple scaling analysis without actually calculating  in detail. For E and N ﬁxed,
it can be argued that the number of states for a single particle is proportional to V, so for
N particles we expect  to be proportional to V N . Moreover, the form of Eq. (16.38) shows
that  will depend on E and V only in the combination EV 2/3, so we can immediately
express  in the functional form
 = ˜(N)V N E(3N /2),
(16.55)
where ˜(N) is some unknown function of N. Then from
S = kB[ln ˜(N) + N ln V + (3N/2) ln E],
(16.56)
we readily deduce the following:
1. From 1/T = (∂S/∂E)V,N = (3NkB/2E), we see that E is independent of V and has
the form
E = (3N/2)kBT.
(16.57)
2. From p/T = (∂S/∂V)E,N = NkB/V, we deduce the familiar ideal gas law
pV = NkBT.
(16.58)
Combining Eqs. (16.57) and (16.58) gives p = (2/3)(E/V), which relates pressure to
energy density.
3. For an isentropic transformation at constant N, the constancy of S requires VE3/2 =
constant. If we differentiate this equation, we deduce
dE = −(2/3)(E/V ) dV = −p dV ,
(16.59)
so the only change in energy for this reversible adiabatic transformation comes
from reversible work δW = p dV done by the system. By eliminating E from VE3/2 =

Chapter 16 • Microcanonical Ensemble
273
constant, we also deduce the scaling laws VT3/2 = constant, T5/2/p = constant, and
pV 5/3 = constant for an isentropic transformation of a monatomic ideal gas.
4. The enthalpy H = E + pV = (5/3)E = (5/2)NkBT. Therefore, the heat capacities are
CV = (∂E/∂T)V,N = (3/2)NkB;
Cp = (∂H/∂T)p,N = (5/2)NkB,
(16.60)
so Cp/CV = 5/3.
16.5 Multicomponent Ideal Gas
We next treat a multicomponent ideal gas in the same approximation used above for a
monocomponent gas. It will sufﬁce to treat only a gas having A and B atoms because
generalization to a larger number of chemical components is straightforward.
We consider NA atoms of A, each with mass mA, giving rise to a total energy EA for all A
atoms, and similarly for B atoms. Applying Eq. (16.44) to each gas we obtain
A =
 V
h3
NA (2πmAEA)3NA/2
NA!(3NA/2)!
;
B =
 V
h3
NB (2πmBEB)3NB/2
NB!(3NB/2)!
.
(16.61)
What we would like to calculate is (E) for the whole system where E = EA +EB is the total
energy; however, we do not yet know how the energies of A and B are partitioned. Hence,
we will have to accept all possible partitions of energy and sum over them to obtain
(E) =

EB
A(E −EB)B(EB)
(16.62)
in an abbreviated notation where symbols other than the energy are suppressed. This
would appear to be a very difﬁcult calculation were it not for the fact that all we
need is a sufﬁcient approximation to ln  which is given by the largest term in the
sum. McQuarrie [54, p. 25] refers to this approximation as the maximum term method.
Following McQuarrie, we let Tmax be the largest term in a sum S of M positive terms. Then
Tmax ≤S ≤MTmax. Thus
ln Tmax ≤ln S ≤ln Tmax + ln M.
(16.63)
If, in order of magnitude, Tmax ∼AM where A = O(1) and M ≫1, we have ln Tmax ∼
M ln A. Therefore, for sufﬁciently large M, the term ln M is negligible with respect to
M ln A and
ln S ≈ln Tmax.
(16.64)
In our case, each term in the sum is proportional to
E3NA/2
A
E3NB/2
B
= (E −EB)3NA/2E3NB/2
B
(16.65)
and NA and NB are huge numbers for all cases of interest. To ﬁnd a maximum, we
differentiate partially with respect to EB holding E constant to obtain
−(3NA/2) E(3NA/2)−1
A
E3NB/2
B
+ (3NB/2) E3NA/2
A
E(3NB/2)−1
B
= 0,
(16.66)

274
THERMAL PHYSICS
which simpliﬁes to
NA/EA = NB/EB = N/E,
(16.67)
where the last equality follows from the properties of proportions. Thus we have
EA = ENA/N and EB = ENB/N where N = NA + NB, in which case11
S = k ln

A

E NA
N

B

E NB
N

= k ln A

E NA
N

+ k ln B

E NB
N

= NAk ln

V
NA
4πmAE
3h2N
3/2
+ 5
2NAk + NBk ln

V
NB
4πmBE
3h2N
3/2
+ 5
2NBk.
(16.68)
From Eq. (16.68) we compute the temperature:
1
T =
 ∂S
∂E

V,NA,NB
= 3
2k N
E ,
(16.69)
which leads immediately to
S(T, V, NA, NB) = NAk ln
 V
NA
nQA

+ NBk ln
 V
NB
nQB

+ 5
2Nk,
(16.70)
where nQA := [mAkT/(2π¯h2)]3/2 = [2πmAkT/h2]3/2 is the quantum concentration of A and
nQB is deﬁned similarly.
Examination of Eq. (16.70) in view of Eq. (16.47) allows for an immediate physical
interpretation, namely that the entropy of the combined ideal gases of A and B atoms at
temperature T in a volume V is the sum of the entropies they would have if each were
at temperature T and occupied the volume V separately. According to Callen [2, p. 69],
this is often referred to as Gibbs’s theorem.12 In fact, Eq. (16.67) is precisely the condition
that gases A and B have the same temperature.13 This treatment clearly generalizes to
multicomponent ideal gases.
The pressure p of the gas mixture may be computed from Eq. (16.68), resulting in
p
T =
 ∂S
∂V

E,NA,NB
= k N
V ,
(16.71)
so pV = NkT, the same as for a monocomponent gas. From Eq. (16.50), we see that the
pressures of A and B separately in volume V would be pA = NAkT/V = (NA/N)p and pB =
NBkT/V = (NB/N)p. These are called partial pressures of A and B. Such an additivity of
partial pressures is unique to ideal gases because they do not interact.
11In this and the next section, we deal with A and B gases so we drop the subscript B on the Boltzmann
constant kB to avoid confusion.
12An equivalent statement is that the Helmholtz free energy of a mixture of ideal gases at temperature T in a
volume V is additive, that is, F(T, V, NA, NB) = FA(T, V, NA) + FB(T, V, NB). It would be incorrect to apply this
formula to a pure gas by assuming that A and B atoms are identical. The correct procedure would be to let NB = 0
to get a pure gas of A atoms.
13From Eq. (16.67), it follows that NA/EA = NB/EB = N /E = 2/(3kBT).

Chapter 16 • Microcanonical Ensemble
275
Similarly, one can compute the chemical potential of A and B in the mixture or,
alternatively, as if each gas occupied the volume V separately. In either case, the result
turns out to be the same and one obtains
μA = −T
 ∂S
∂NA

E,V,NB
= −T
∂SA(EA, V , NA)
∂NA

EA,V
= kT ln

pA
nQAkT

.
(16.72)
Thus, from the standpoint of chemical potential, the presence of another species in a
mixture of ideal gases in a volume V at temperature T is irrelevant.14
16.5.1 Entropy of Mixing
The entropy of mixing of ideal gases is deﬁned to be the entropy of the mixture of gases at
temperature T and volume V minus the entropies of the separate gases (unmixed state)
each at temperature T but conﬁned to separate sub-volumes of V such that each has the
same pressure p as the mixture. Equal pressure is guaranteed by equal number density.
Thus, in the case of our mixture of A and B atoms, the A atoms would need to be conﬁned
to a sub-volume VA = VNA/N and they would have entropy
SA(EA, VA, NA) = NAk ln

VA
NA
4πmAEA
3h2NA
3/2
+ 5
2NAk.
(16.73)
The reciprocal temperature of these A atoms would be
 ∂SA
∂EA

VA,NA
= 3
2k NA
EA
= 3
2k N
E = 1
T
(16.74)
and the ratio of their pressure to their temperature would be
 ∂SA
∂VA

EA,NA
= k NA
VA
= k N
V = p
T .
(16.75)
They therefore have the same temperature and pressure as the mixture. We write
SA(T, VA, NA) = NAk ln
 VA
NA
nQA

+ 5
2NAk
(16.76)
and similarly for SB(T, VB, NB) with VB = VNB/N. The entropy of mixing is therefore
given by

Smix := S(T, V , NA, NB) −SA(T, VA, NA) −SB(T, VB, NB)
= NAk ln(V /VA) + NBk ln(V /VB)
= −k

NA ln(NA/N) + NB ln(NB/N)
	
> 0.
(16.77)
14This statement may seem counterintuitive to those familiar with solution chemistry but a different scenario
is used in that case. In solution chemistry, one generally considers the difference between the chemical potential
of a pure gas A at some temperature T and pressure p (a “standard state”) and a mixture of gases at temperature
T and total pressure p. In a mixture of ideal gases, the gas of atoms A has only a partial pressure pA = pNA/N so
the difference in chemical potential per atom, compared to the standard state, is kT ln(pA/p) = kT ln(NA/N ). In
our case above, the gas of NA atoms in volume V has the same pressure pA whether it is alone or in the presence
of other gases.

276
THERMAL PHYSICS
This result should be compared to the case when a monocomponent gas occupies the
entire volume V, in which case its entropy is given by Eq. (16.47) which we symbolize in
the form
S(T, V , N) = Nk ln
 V
N nQ

+ 5
2Nk.
(16.78)
If such a gas is partitioned such that N ′ + N ′′ = N with N ′ atoms occupying volume
V ′ = VN ′/N and N ′′ atoms occupying V ′′ = VN ′′/N, both the unpartitioned gas and
the partitioned gases will have the same pressure because V ′/N′ = V ′′/N′′ = V/N. The
entropies of the partitioned gases will be
S′(T, V ′, N ′) = N ′k ln
 V ′
N ′ nQ

+ 5
2N ′k
(16.79)
and
S′′(T, V ′′, N ′′) = N ′′k ln
 V ′′
N ′′ nQl

+ 5
2N ′′k.
(16.80)
The entropy change when the partitioned gases are mixed will then be

S = S(T, V , N) −S′(T, V ′, N ′) −S′′(T, V ′′, N ′′) = 0,
(16.81)
as expected.
More insight about the entropy of mixing of ideal gases can be gained by the following.
If we start with unmixed gases of A and B atoms, each at temperature T and pressure p and
form from them a mixed gas having the same T and p, the number of conﬁgurations of NA
atoms of A and NB atoms of B that can be obtained by arranging particles is
mix =
N!
NA!NB!,
(16.82)
where N = NA + NB. Then with Stirling’s approximation,

Smix = k ln mix = −k

NA ln(NA/N) + NB ln(NB/N)
	
,
(16.83)
which is the same as given by Eq. (16.77). In other words, the ideal entropy of mixing
results simply from the number of distinct conﬁgurations of A and B atoms at temperature
T and pressure p. We note that 
Smix is exactly the same quantity that we called 
Sideal in
Section 10.2 where we treated so-called ideal solutions thermodynamically.

17
Classical Microcanonical Ensemble
In Chapter 16, we explored the microcanonical ensemble in the context of quantum
statistical mechanics. First of all, we believe that quantum mechanics is correct whereas
classical mechanics is just an asymptotic (but very useful) approximation. Second, how-
ever, quantum statistical mechanics is easier to understand because implementing the
fundamental hypothesis is, in principle, a matter of counting quantum states and deciding
on their statistical weight (e.g., equally probable for the microcanonical ensemble). In
classical mechanics, however, we deal with continuous variables so we have to replace
counting with integration over a continuous weighting function. On the other hand,
classical statistical mechanics was the ﬁrst to be developed and its study allows us to gain
some physical intuition about statistical mechanics without dealing with the abstractions
and statistical nature of quantum mechanics itself. Moreover, there are systems and
situations for which quantum effects are not important and for which a treatment by
classical statistical mechanics is more tractable. We shall therefore discuss brieﬂy the
foundations of classical statistical mechanics and explore brieﬂy the classical version of
the microcanonical ensemble.
We consider a three-dimensional classical system consisting of N identical particles
and characterized by generalized coordinates q = q1, q2, . . . , qi, . . . , q3N and generalized
conjugate momenta p = p1, p2, . . . , pi, . . . , p3N . These variables span a 6N-dimensional
space known as phase space. We denote them collectively by a 6N-dimensional vector ω.
We write the volume element in this space in the form d3N p d3N q ≡dp dq ≡dω. We
denote the Hamiltonian for this system by H(p, q; t). Then the system evolves in time
according to Hamilton’s equations
˙qi = ∂H
∂pi
;
˙pi = −∂H
∂qi
,
(17.1)
where a dot above a variable denotes differentiation with respect to time. As time evolves,
the point p, q traces out a trajectory in phase space. For the case H(p, q; t) = H(p, q),
explicitly independent of time, the total energy E is conserved and this trajectory lies
on the hypersurface H(p, q) = E. For an isolated system, the energy will be constant
and a fundamental assumption of classical statistical mechanics is that all points on
that hypersurface are equally probable.1 This leads to the classical microcanonical
ensemble.
1In fact, one usually considers a thin hypershell such that E −E ≤H(p, q) ≤E and then assumes that
every volume element in that hypershell is equally probable. The entropy is assumed to be proportional to the
logarithm of the volume of that hypershell.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00017-X
277
Copyright © 2015 Elsevier Inc. All rights reserved.

278
THERMAL PHYSICS
17.1 Liouville’s Theorem
To gain more insight into the basis for classical statistical mechanics, we digress to discuss
Liouville’s theorem. We consider an ensemble of identical classical systems governed by
Hamilton’s equations. Each member of the ensemble corresponds to the same macrostate
of some macroscopic system under consideration, but the members of the ensemble
differ from one another microscopically, that is, they represent different microstates. Each
member of the ensemble is represented by a point in phase space that moves in time from
its initial point, which will differ for each member of the ensemble. We assume that there
is an enormous number of such points that form a virtual continuum in all accessible
parts of phase space. To quantify this swarm of points, we denote by ρ(p, q; t) ≡ρ(ω; t)
a distribution function such that ρ(p, q; t) dp dq ≡ρ(ω; t) dω is the number of members
of the ensemble in the phase space volume element dω. For a macroscopic system of
interest, we take the point of view that observed quantities can be calculated by means
of an ensemble average. Thus if y(ω) is some property that depends on the coordinates
and momenta of the particles, its ensemble average would be
⟨y⟩=

y(ω)ρ(ω; t) dω

ρ(ω; t) dω
.
(17.2)
In this case,

ρ(ω; t) dω = Nens, the total number of members of the ensemble. We
could equally well regard ρ to be a probability density function, in which case it would be
normalized such that

ρ(ω; t) dω = 1. In that case, the denominator in Eq. (17.2) would
not be needed. Interpretation as a probability density is necessary in the limit Nens →∞
Liouville’s theorem deals with the evolution of ρ in phase space. We consider some ﬁxed
sub-volume ω′ of phase space and equate the time rate of change of microsystems in that
volume to the net rate at which microsystems enter that volume. Thus
d
dt

ω′ ρ(ω; t) dω = −

a′ ρ(ω; t) ˙ω · ˆn da′,
(17.3)
where a′ is the area of the sub-volume ω′ and ˆn is its unit outward normal. Here, ˙ω is the
time rate of change of the 6N-dimensional vector ω, so that ρ(ω; t) ˙ω represents the ﬂux of
systems in phase space. We apply Gauss’s theorem to the right-hand member of Eq. (17.3)
and take the time derivative of the left-hand member inside the integral to obtain

ω′
∂ρ
∂t + ∇ω · (ρ ˙ω)

dω = 0,
(17.4)
where ∇ω acts on the components of the vector ω. We assert that Eq. (17.4) is true for any
arbitrary sub-volume of phase space, so the integrand itself must vanish, which gives
∂ρ
∂t + ∇ω · (ρ ˙ω) = 0.
(17.5)
We note that Eq. (17.5) is analogous to the continuity equation for conservation of mass
of a classical ﬂuid; in that case, ρ represents the density of the ﬂuid and ˙ω represents the
barycentric ﬂuid velocity v.

Chapter 17 • Classical Microcanonical Ensemble
279
The second term in Eq. (17.5) can be expanded to obtain
∇ω · (ρ ˙ω) = ˙ω · ∇ωρ + ρ∇ω · ˙ω.
(17.6)
We shall proceed to show that the second term on the right in Eq. (17.6) vanishes. Indeed,
∇ω · ˙ω =
3N

i=1
 ∂
∂pi
˙pi + ∂
∂qi
˙qi

=
3N

i=1

−∂2H
∂pi∂qi
+
∂2H
∂qi∂pi

= 0,
(17.7)
where Hamilton’s equations (Eq. (17.1)) have been used. Equation (17.7) is analogous
to the equation of classical ﬂuid dynamics, ∇· v = 0, which is often referred to as
incompressible ﬂow. Its interpretation is that the ﬂuid ﬂows in closed loops, which is
known as solenoidal ﬂow. The ﬁrst term on the right in Eq. (17.6) can also be written in
terms of p and q in the form
˙ω · ∇ωρ =
3N

i=1
 ∂ρ
∂qi
∂H
∂pi
−∂ρ
∂pi
∂H
∂qi

≡{ρ, H}
(17.8)
and is known in classical mechanics as a Poisson bracket. It is analogous to a commutator
in quantum mechanics. Equation (17.5) can therefore be written in the form
Dρ
Dt ≡∂ρ
∂t + ˙ω · ∇ωρ = ∂ρ
∂t + {ρ, H} = 0.
(17.9)
The quantity Dρ/Dt is a total time derivative of ρ as one follows members of the en-
semble through phase space; it is analogous to the substantial derivative of classical ﬂuid
dynamics, which is a total time derivative as one follows mass through real space. Equa-
tion (17.9), which is essentially Liouville’s theorem, states that the density of members of
the ensemble, as they move through phase space, does not change. An equivalent inter-
pretation is that the volume of phase space occupied by a dense set of points representing
members of the ensemble does not change with time, although it can change position and
shape.
Further information can be obtained from Eq. (17.9) if one requires ρ to correspond to
a state of equilibrium, in which case it should not depend on time explicitly. Then
∂ρ
∂t = 0,
equilibrium ensemble,
(17.10)
and Eq. (17.9) yields
{ρ, H} = 0.
(17.11)
For a system in equilibrium, we shall require ρ(ω; t) = ρ(ω), explicitly independent of t.
Physical measurements of such a system, which will disturb the system slightly, are really
time averages over times that are large compared to the time it takes a system to relax to
equilibrium. The system therefore passes through an enormous number of “equilibrium”
states during a physical measurement, and its initial state is irrelevant. The time average
of an ensemble average is therefore the same as the ensemble average of a time average

280
THERMAL PHYSICS
[8, p. 37]. In statistical mechanics, one adopts the hypothesis that the observed value
of y(ω) in some macroscopic equilibrium state is its ensemble average. For further
discussion, see [7, chapter 1].
17.2 Classical Microcanonical Ensemble
Equation (17.11) is a requirement for an acceptable distribution function and shows the
close relationship of ρ to H, and hence to the energy E. One way to satisfy Eq. (17.11) is
to take ρ to be a constant. If the energy is precisely ﬁxed at the value E, the members of
the ensemble move in phase space on a subspace of phase space that we can regard as
an energy hypersurface. We could represent ρ as a delta function, with some constant
strength, that vanishes except on that energy hypersurface. Alternatively, and what is
usually done, is to consider a thin shell of width  near the energy surface, that is,
E −E ≤H ≤E and then take ρ to be a constant within that shell and zero elsewhere.
This choice actually corresponds to the classical microcanonical ensemble. The constant
value of ρ, which depends on the normalization of ρ, cancels in Eq. (17.2) which becomes
⟨y⟩=
1
ω

ω
y(ω) dω.
(17.12)
Here, ω corresponds to the volume of phase space within the energy shell where ρ is not
equal to zero. Equation (17.12) is the classical analog of the quantum mechanical formula
(see Eq. (16.1))
⟨y⟩= 1



ν=1
yν,
(17.13)
where  is the degeneracy (multiplicity function) for a ﬁxed energy and ν labels the
compatible quantum states of the system, for which y has values yν.
It remains to establish a relationship between ω, which is some measure of the
volume of phase space available to the system, and the entropy S. From the quantum
mechanical point of view, we need to relate ω to the number of allowed microstates of the
system. In other words, we need to know what volume ω0 of phase space corresponds to
one microstate. Classical mechanics provides no answer to this question. We could write
S = kB ln(ω/ω0),
(17.14)
where kB is Boltzmann’s constant, but the entropy would still remain undetermined up to
an additive “constant,” although we would expect ω0 to depend on N. We can, however,
appeal to quantum mechanics and choose ω0 so that classical mechanics and quantum
mechanics will agree in the asymptotic limit where classical mechanics is valid. This can
only be done for simple systems, for which the problem is tractable, but presumably ω0 will
be the same for all systems, so we can determine it in a simple case. For an ideal gas, one
can work out both the classical and quantum mechanical cases and make a comparison
(see also Pathria [8, p. 39] and Chandler [12, p. 191]), as we do in the next section.

Chapter 17 • Classical Microcanonical Ensemble
281
17.2.1 Classical Ideal Gas
To treat a classical ideal gas conﬁned to a volume V in the microcanonical ensemble,
we calculate the volume of phase space in a thin energy shell between energies E −E
and E. This volume is
ω =

d3N q d3N p = V N

d3N p,
(17.15)
where the momentum integral is over the hyperspherical shell
2m(E −E) ≤
3N

r=1
p2
r ≤2mE
(17.16)
of outer radius (2mE)1/2. Proceeding as in the pseudo-quantum mechanical case, we know
that the volume of this hyperspherical shell is just the factor F in Eq. (16.40) times the
volume of the entire hypersphere, so
ω = V N F (2πmE)3N /2
(3N/2)!
≈V N (2πmE)3N /2
(3N/2)!
.
(17.17)
The entropy is given by Eq. (17.14) with
ω
ω0
= V N
ω0
(2πmE)3N /2
(3N/2)!
.
(17.18)
To agree with our pseudo-quantum mechanical treatment, speciﬁcally Eq. (16.44) for ,
we deduce that
ω0 = h3N N!,
identical and indistinguishable particles.
(17.19)
The factor h3N in Eq. (17.19) has the same dimensions as the volume of phase space
and can be thought of as dividing phase space into cells. The volume of each cell would
be h3 per particle, consistent with the Heisenberg uncertainty principle. The factor h3N
will make the ratio (ω/ω0) dimensionless. The factor of N! is the Gibbs correction factor
that corrects for indistinguishable particles and makes the entropy an extensive function.
For a dilute gas at high temperatures, it would occur automatically from quantum
mechanical considerations that are designed from the start to deal systematically with
indistinguishable particles.
Although we have derived this factor for an ideal gas, it is presumed to be a universal
factor for all classical statistical systems consisting of indistinguishable particles. Of course
the N! factor is to be omitted for classical identical but distinguishable particles such as
identical classical harmonic oscillators imbedded in a solid and distinguished by their
positions.
Since ω0 depends only on N, it will make no contribution to the calculation of 1/T =
(∂S/∂E)V,N or to p/T = (∂S/∂V)E,N , but a knowledge of ω0(N) is necessary to get the
quantum mechanically correct entropy or any of the thermodynamic potentials such as F
and G that depend on S.

282
THERMAL PHYSICS
For future reference, we remark that this same factor appears in the corrected expres-
sion for the classical partition function in the canonical ensemble, as given by Eq. (20.7),
which can also be written as
Z∗
C =
1
h3N N!

exp[−β H(ω)] dω =

exp[−β H(ω)] d(ω/ω0).
(17.20)
This dimensionless partition function is the analog of the quantum partition function
Z =

ν
exp[−β Eν].
(17.21)
Example Problem 17.1. Consider a classical harmonic oscillator with spring constant k in
one dimension x for a particle of mass m having linear momentum p. Its energy E is given by
E = p2
2m + 1
2kx2 = p2
2m + mω2
2
x2,
(17.22)
where ω =

k/m is its angular frequency. The well-known solution to this equation has the form
x = A sin(ωt + ϕ), where t is the time and A and ϕ are constants. Show that the trajectory of the
particle orbit in phase space is an ellipse and determine the sizes of its semiaxes. Then compute
the area of the shell in phase space that lies between energies E and E −E and compare with
the corresponding energy E for a quantum harmonic oscillator having quantized energies
E = (n + 1/2)¯hω. From your result, determine the number of quantum states per area of phase
space.
Solution 17.1. Equation (17.22) can be written in the form
p2
a2 + x2
b2 = 1,
(17.23)
which is the equation of an ellipse with semiaxes a =
√
2mE and b =

2E/mω2. The
momentum p = mdx/dt = mAω cos(ωt + ϕ), with A =

2E/mω2, so an elliptical trajectory
is traversed periodically as time increases. The area of the ellipse is πab = 2πE/ω. The phase
space area in a shell between E and E −E is therefore
2πE/ω −2π(E −E)/ω = 2πE/ω.
(17.24)
For a quantum oscillator, the corresponding energy increment is
E = (n + 1/2)¯hω = ¯hωn.
(17.25)
The number of quantum states per area of phase space is therefore
n
2πE/ω =
1
2π¯h = 1
h.
(17.26)

Chapter 17 • Classical Microcanonical Ensemble
283
17.2.2 Classical Harmonic Oscillators in Three Dimensions
For N classical harmonic oscillators at ﬁxed locations in three-dimensional space, the
Hamiltonian is
H =
3N

i=1
p2
i
2m + mω2
2
3N

i=1
x2
i .
(17.27)
The volume of phase space for H ≤E can be computed by mapping the hyperellipsoid
described by Eq. (17.27) into a unit hypersphere S1 given by
6N

i=1
X2
i = 1,
(17.28)
by means of the transformation
Xi =
pi
√
2mE
;
Xi+3N = xi

mω2/2E;
i = 1, 2, . . . , 3N.
(17.29)
The corresponding volume of phase space within the entire hyperellipsoid is therefore

E
d3N p d3N x =

S1
Jd6N X = J π6N /2
(6N/2)!,
(17.30)
where the Jacobian J
= (
√
2mE)3N (

2E/mω2)3N
= (2E/ω)3N . As was the case for
a hypersphere (see Eq. (17.17)), the volume ω of a hyperellipsoidal shell between
energies E
≥
H
≥
E −E is practically the same as the volume of the entire
hyperellipsoid, so
ω ≈(2πE/ω)3N
(3N)!
.
(17.31)
The entropy is therefore
S
kB
= ln ω
ω0
= ln (2πE/ω)3N
h3N (3N)! = 3N

ln
	
E
3N¯hω

+ 1

,
(17.32)
where Stirling’s approximation has been used in the last step. Here, we have used
ω0 = h3N ,
identical but distinguishable particles,
(17.33)
because the oscillators are distinguishable due to their ﬁxed locations. The temperature is
therefore given by 1/T = (∂S/∂E)N , resulting in
E = 3NkBT.
(17.34)

284
THERMAL PHYSICS
In terms of temperature, the entropy is
S = 3NkB

ln
	kBT
¯hω

+ 1

.
(17.35)
Comparison with Eqs. (16.26) and (16.29) shows that Eqs. (17.34) and (17.35) are only valid
at high temperatures, quantum effects having been lost in the classical limit.2
2The dependence of Eq. (17.35) on ¯h results from identiﬁcation of ω0 = h3N from quantum mechanical
considerations. From a strictly classical point of view, ω0 would be unknown so the entropy would only be
determined up to an additive constant, namely S = 3N kB ln T + constant. The factor of 3 would be absent
for one-dimensional oscillators.

18
Distinguishable Particles with
Negligible Interaction Energies
In Chapters 16 and 17, we introduced the microcanonical ensemble. This ensemble was
useful for stating the fundamental postulates on which statistical mechanics is based,
but not useful for practical calculations. From the microcanonical ensemble, we can
derive other ensembles, such as the canonical ensemble (Chapter 19) and the grand
canonical ensemble (Chapter 21) that are more tractable. Before doing so, however, we
pause to develop the special case of the statistical mechanics at constant temperature
T of identical but distinguishable particles having negligible interaction energies. This
is a special case of the canonical ensemble and allows us to quickly and easily obtain a
number of useful results of practical importance without complication. In Chapter 19, we
will derive the canonical ensemble from the microcanonical ensemble for a large system
in contact with a heat reservoir at temperature T. In Section 19.2.1, we will show that the
results in the current chapter can be deduced by means of the factorization theorem. A
more sophisticated reader can skip this chapter temporarily and go directly to Chapter 19.
We consider a system consisting of N identical but distinguishable quantum subsys-
tems that we shall refer to as “particles.” Each particle has stationary states having energies
ε1, ε2, . . . , εi, . . .. The particles are assumed to be distinguishable because of their ﬁxed
location (e.g., in a solid) but are otherwise the same. The states of each particle may be
ﬁnite or inﬁnite in number, and some of them may be degenerate.1 Moreover, the energies
εi could possibly depend on the volume V of the system. In the derivation that follows,
we shall suppress any dependence of εi on V until needed. The particles are assumed to
interact sufﬁciently weakly that their interaction energy is negligible, but to a degree that
will allow them eventually to come to equilibrium.
18.1 Derivation of the Boltzmann Distribution
We examine a conﬁguration {Ni} = N1, N2, . . . , Nκ of the system such that N1 particles
are in a quantum state2 with energy ε1, N2 particles are in a quantum state with energy ε2,
etc. Such a conﬁguration is subject to the constraints
1Degeneracy arises when there are stationary states of the subsystems having the same energy but a different
set of quantum numbers.
2For brevity we use a single index to denote a quantum state but in fact many quantum numbers may be
necessary. Moreover, there can be degeneracy if different quantum states have the same energy.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00018-1
285
Copyright © 2015 Elsevier Inc. All rights reserved.

286
THERMAL PHYSICS

i
Ni = N
(18.1)
and

i
Niεi = E,
(18.2)
where E is the total energy of the system. Since the particles are distinguishable, the
number of ways of making a given conﬁguration is3
W{Ni} :=
N!
N1!N2! · · · Nκ!.
(18.3)
We proceed to maximize W{Ni}, considered to be a function of the Ni, subject to the
constraints expressed by Eqs. (18.1) and (18.2). Since ln x is a monotonically increasing
function of x, we actually maximize ln W subject to these same constraints. To handle the
constraints, we introduce Lagrange multipliers β and α and solve the problem
∂
∂Nj
[ln W{Ni} −βE −αN] = 0.
(18.4)
By virtue of the Lagrange multipliers, all Nj in Eq. (18.4) can be regarded as independent
variables, which will turn out to be functions of β and α. We can then choose β and α to
satisfy the constraints.
In order to differentiate ln W{Ni}, we use Stirling’s approximation (see Appendix A) and
obtain
∂
∂Nj
ln W{Ni} ∼
∂
∂Nj

N ln N −

i
Ni ln Ni

= −ln Nj
N .
(18.5)
Thus Eq. (18.4) becomes
−ln Nj
N −βεj −α = 0.
(18.6)
The solution to Eq. (18.6) is
Nj
N = e−αe−βεj.
(18.7)
Applying the constraint Eq. (18.1) we obtain
1 =

j
Nj
N = e−α 
j
e−βεj,
(18.8)
which results in
e−α = 1/z,
(18.9)
3Here, W plays the same role as  for the microcanonical ensemble, but we use a different notation because
 corresponds to constrained values of E and N . In the present case, these constraints are replaced by Eqs. (18.1)
and (18.2). Ultimately we will specify the temperature T and then determine E from the probabilities pi of
occupation of the quantum states.

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
287
where
z =

j
e−βεj
(18.10)
is known as the partition function.4 Thus Eq. (18.7) becomes
pi := Ni
N = e−βεi
z
,
(18.11)
where we have also introduced the symbol pi, the probability of occupation of the ith state
of a particle.
The internal energy can now be determined from Eq. (18.2) to be5
U := ⟨E⟩= N

i
piεi = N

i
εie−βεi
z
= −N
z
∂z
∂β = −N ∂ln z
∂β .
(18.12)
To obtain the entropy, we use6
S = kB ln W{Ni}
(18.13)
with Ni given by Eq. (18.11). With the aid of Stirling’s approximation, Eq. (18.13) becomes
S = kB

N ln N −

i
Ni ln Ni

= −kB

i
Ni ln(Ni/N) = −NkB

i
pi ln pi.
(18.14)
We now proceed to identify the remaining Lagrange multiplier β. In principle, we
could do this by specifying the total energy and solving Eq. (18.2) for β, with Ni given
by Eq. (18.11), but this would necessitate solving a complicated transcendental equation.
Instead, we suppose that our system is in equilibrium at ﬁxed temperature T and appeal
to thermodynamics to identify β. We do this by relating the above expressions for U and
S by means of the thermodynamic equation dU = T dS −p dV which holds at constant
N for a system that can do reversible work p dV.7 From Eq. (18.12), the differential of the
internal energy is
dU = N

i
εi dpi + N

i
pidεi = N

i
εi dpi + N

i
pi
∂εi
∂V dV ,
(18.15)
4In Eq. (18.10), z is the partition function for an individual particle. We reserve the symbol Z for the partition
function of the whole system that we shall later relate to z.
5Since the pi are probabilities, Eq. (18.12) actually gives the most probable value ⟨E⟩of energy which we
identify with the internal energy U that we will ultimately compute from a knowledge of the temperature.
6To get the entropy, we should really compute the logarithm of the total number of microstates by summing
all values of ln W{Ni} that are compatible with the constraints. Instead, we approximate this sum by its
overwhelmingly largest term.
7See Section 19.1.3 for a similar treatment for a more general system.

288
THERMAL PHYSICS
where we have assumed that the energies of the states depend on the volume of the
system. From Eq. (18.14), the differential of the entropy is
dS = −NkB

i
(ln pi + 1) dpi = −NkB

i
ln pi dpi
= −NkB

i
(−βεi −ln z) dpi = NkBβ

i
εi dpi,
(18.16)
where we have used 
i dpi = 0 because 
i pi = 1. By combining Eq. (18.15) with
Eq. (18.16) we obtain
dU =
1
kBβ dS + N

i
pi
∂εi
∂V dV .
(18.17)
Comparison with dU = T dS −p dV shows that
β =
1
kBT .
(18.18)
We also obtain a useful equation for the pressure, namely
p = −N

i
pi
∂εi
∂V ,
(18.19)
which by means of Eq. (18.17) with dS = 0 is seen to be equivalent to p = −(∂U/∂V)S,N
with U = N 
i piεi. By using Eq. (18.11) to rewrite ln pi, the entropy given by Eq. (18.14)
can be written in the form
S = U
T + NkB ln z.
(18.20)
Equation (18.20) can then be combined with the equation F = U −TS to deduce a useful
formula for the Helmholtz free energy
F = −NkBT ln z = −N
β ln z.
(18.21)
In Section 19.1.3, this derivation will be generalized to an ensemble of complicated
systems (instead of a collection of weakly interacting particles). Such an ensemble is
known as a canonical ensemble and allows for each complicated system to consist of
many interacting particles. For such complicated systems, determination of the quantum
states and the resulting partition functions can be quite difﬁcult.
18.1.1 Summary of Results
The probability pi of occupation of the i state is
pi := Ni
N = e−βεi
z
,
(18.22)

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
289
where β = 1/(kBT), kB is Boltzmann’s constant, T is the absolute temperature, and
z =

j
e−βεj
(18.23)
is the partition function. The entropy is
S = −NkB

i=1
pi ln pi = −NkBβ2 ∂
∂β
ln z
β

.
(18.24)
The internal energy is
U = N

i=1
piεi = −N ∂
∂β ln z
(18.25)
and the Helmholtz free energy is
F = −N
β ln z.
(18.26)
In solving problems, one usually proceeds as follows:
•
Determine the subsystem states i having energies εi from a model or from experimental
data.
•
Calculate the partition function z and deduce the Helmholtz free energy F by using
Eq. (18.26).
•
Obtain the entropy from S = −(∂F/∂T)V,N or from Eq. (18.24).
•
Obtain the internal energy from U = F + TS or from Eq. (18.25).
•
Obtain the chemical potential per particle from μ = (∂F/∂N)T,V .
•
If the dependence of the εi on volume V is known, determine the pressure from p =
−(∂F/∂V)T,N .
In following this procedure, it should be recognized that Eq. (18.26) yields F as a func-
tion of its natural variables T, V, and N, where N = N/N A is the mole number of particles,
NA being Avogadro’s number. We therefore recover the usual thermodynamic description
of a monocomponent system. The volume V might enter because each particle occupies
a volume V/N on which the energy levels εi might depend. These particles, although
identical, are supposed to be distinguishable by virtue of their position. If all particles
were to share the same volume and were identical, they would not be distinguishable.
Such would be the case for a monatomic ideal gas, so to treat such a system the above
equations would have to be modiﬁed.
18.2 Two-State Subsystems
We apply the results of the previous section to a number N of identical but distinguishable
two-state subsystems, each having nondegenerate energy levels ε1 and ε2. These subsys-
tems are distinguishable because each is assumed to have a ﬁxed location. In order to fo-
cus ideas, we consider the case in which each of our two-state systems is a particle having

290
THERMAL PHYSICS
ε
0
ε2 = m0B
ε1 = −m0B
B
FIGURE 18–1 Energy levels ε1 = −m0B and ε2 = m0B due to splitting by a magnetic ﬁeld B for a spin 1/2 particle
having magnetic moment m0 > 0 for “spin up.”
spin 1/2 in a magnetic ﬁeld of strength B. Each particle can exist in two states, a state with
“spin up” having energy ε1 = −m0B and a state with “spin down” having energy ε2 = m0B,
where the magnetic moment m0 > 0.8 See Figure 18–1 for an energy level diagram.
From Eq. (18.23), the partition function is
z = e−βε1 + e−βε2 = em0Bβ + e−m0Bβ.
(18.27)
From Eq. (18.22), the probabilities of occupation of each state are
p1 = e−βε1
z
=
em0Bβ
em0Bβ + e−m0Bβ =
1
1 + e−2m0Bβ
(18.28)
and
p2 = e−βε2
z
=
e−m0Bβ
em0Bβ + e−m0Bβ =
e−2m0Bβ
1 + e−2m0Bβ .
(18.29)
The latter expressions in Eqs. (18.28) and (18.29) involve only the energy gap ε := 2m0B
between the states and could be obtained directly by shifting the zero of energy so that the
ground state would have zero energy9 and the excited state would have energy ε. The ratio
of these populations is
p2
p1
= e−2m0Bβ = e−2m0B/kBT = e−βε →
 0 as T →0
1 as T →∞.
(18.30)
Thus at high temperatures, p1 = p2 = 1/2 and the states are equally probable.10
8We regard the state with “spin up” as having its magnetic moment in the same direction as the magnetic ﬁeld,
and hence the lower energy. This unambiguous sign convention avoids the question of the connection between
direction of the spin and the sign of the charge of a particle having spin.
9From the forms of Eqs. (18.22) and (18.23), it is clear for any system that the probabilities pi are invariant if
εi →εi + ε for all energies, so the pi are independent of the zero of energy.
10A common misconception by new students of statistical mechanics is that all of the subsystems will be in
their highest energy state as T →∞. Nothing could be further from the truth! At sufﬁciently high temperatures,
the entropy dominates the free energy F, and the internal energy becomes irrelevant. A state in which p2 > p1
would correspond formally to a negative temperature. Negative temperatures have been used to represent
nonequilibrium states in which the population of the excited state has been “pumped” to some high level by
means of some external stimulation, but such negative temperatures are outside the scope of conventional
thermodynamics.

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
291
2
4
6
8
10
-1
-0.8
-0.6
-0.4
-0.2
U/(Nm0B)
k T/(m0B)
B
FIGURE 18–2 Dimensionless internal energy U/(N m0B) versus dimensionless temperature kBT/(m0B) for a two-state
magnetic system according to Eq. (18.31). At T = 0, all spins are aligned with the magnetic ﬁeld. As T →∞, half of
the spins are aligned with the ﬁeld and half are aligned opposite to the ﬁeld, so their energies cancel.
The energy can be calculated directly from Eq. (18.2), resulting in
U = N
	
−m0B em0Bβ + m0B e−m0Bβ
em0Bβ + e−m0Bβ
= −Nm0B tanh(x),
(18.31)
where x = m0Bβ = m0B/kBT and tanh(x) = sinh(x)/ cosh(x) is the hyperbolic tangent
function, sinh x := (ex −e−x)/2 is the hyperbolic sine function, and cosh x := (ex + e−x)/2
is the hyperbolic cosine function. Figure 18–2 shows a plot of U versus temperature in
dimensionless units. We observe that
U →

−Nm0B as T →0
0
as T →∞.
(18.32)
For this simple system, the magnetic moment M is given by11
M = −U
B = M0 tanh(x),
(18.33)
where M0 := Nm0 is called the saturation magnetic moment. M decreases from M0 at
T = 0 to zero as T →∞, as shown in Figure 18–3. This type of magnetism, for which the
interaction energy between subsystems having a magnetic moment is negligible, in known
as paramagnetism. For B = 0, there is no splitting of the states, and no net magnetic mo-
ment. Ferromagnetic systems, in which there are strong interactions between magnetic
subsystems, can have a magnetic moment without an applied magnetic ﬁeld B.
The entropy can be calculated from Eq. (18.24), resulting in
S = NkB

x + ln(1 + e−2x) −x tanh(x)

.
(18.34)
Figure 18–4 shows a plot of S versus T in dimensionless units. We observe that
11See Section 19.6 for a general deﬁnition of the magnetic moment, M = −(∂F/∂B)T = −(∂U/∂B)S.

292
THERMAL PHYSICS
2
4
6
8
10
0.2
0.4
0.6
0.8
1
M/M0
k T/(m0B)
B
FIGURE
18–3 Dimensionless
magnetic
moment
M/M0 versus dimensionless temperature kBT/(m0B)
= 1/x for a two-state magnetic system according to
Eq. (18.33). At T = 0, all spins are aligned with the
magnetic ﬁeld, so M = M0. As T increases, more
spins are promoted to the upper state so the magnetic
moment weakens. For large T, M is approximately
proportional to 1/T, which is known as Curie’s law.
1
2
3
4
5
0.1
0.2
0.3
0.4
0.5
0.6
S/(Nk )
B
k T/(m0B)
B
FIGURE 18–4 Dimensionless entropy S/(N kB) versus
dimensionless temperature kBT/(m0B) = 1/x for a
two-state magnetic system according to Eq. (18.34). At
T = 0, all spins are aligned with the magnetic ﬁeld, so
S = 0. As T →∞, half of the spins are aligned with
the ﬁeld and half are aligned opposite to the ﬁeld, so
S/(N kB) →ln 2 = 0.693.
S →
 0
as T →0
NkB ln 2 as T →∞.
(18.35)
This last result can be obtained easily by substituting p1 = p2 = 1/2 into the middle
member of Eq. (18.24).12
Alternatively, we can use Eq. (18.26) to obtain the Helmholtz free energy
F = −NkBT ln(ex + e−x) = −NkBT[x + ln(1 + e−2x)].
(18.36)
Note that Eq. (18.36) also results from F = U −TS with U given by Eq. (18.31) and S given
by Eq. (18.34). We can also differentiate Eq. (18.36) with respect to T to obtain −S, and then
obtain the internal energy from U = F + TS. A plot of F versus T in dimensionless units13
is shown in Figure 18–5.
We note that
F →
 −Nm0B
as T →0
−NkBT ln 2 as T →∞.
(18.37)
At low temperatures, F behaves like the internal energy; however, at high temperatures, it
behaves like −TS and becomes linear in T as S saturates to a constant value.
12For a system having q states, p1 →1/q as T →∞. Then the middle member of Eq. (18.24) yields S =
N kB ln q.
13Note from Eq. (18.36) that F/(N m0B) = −(1/x)[x + ln(1 + e−2x)].

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
293
1
2
3
4
5
-3.5
-2.5
-2
-1.5
-1
F/(Nm0B)
k T/(m0B)
B
FIGURE 18–5 Dimensionless Helmholtz free energy
F/(N m0B)
versus
dimensionless
temperature
kBT/(m0B) = 1/x for a two-state magnetic system
according to Eq. (18.36). At T = 0, F is equal to U.
For large T, F is nearly equal to −TS with S nearly
constant.
1
2
3
4
5
0.1
0.2
0.3
0.4
C /(Nk )
B
V
k T/(m0B)
B
FIGURE 18–6 Dimensionless heat capacity CV/(N kB)
versus dimensionless temperature kBT/(m0B) = 1/x for
a two-state magnetic system according to Eq. (18.38).
A Schottky peak occurs at kBT/(m0B) ≈0.834 as spins
are promoted to the upper state with increasing T.
As T becomes very large, the population of the upper
state becomes nearly equal to that of the lower state
and can increase very little as T increases, resulting in
CV decreasing to zero.
Finally, we can differentiate U with respect to T to obtain the heat capacity CV at
constant volume, resulting in
CV = NkB
4x2
(ex + e−x)2 = NkBx2sech2(x),
(18.38)
where sech x = 1/ cosh x is the hyperbolic secant function. A plot of CV versus T in
dimensionless units is shown in Figure 18–6.
The peak14 near m0B = kBT is called a Schottky peak and occurs when the population
of the upper level increases at maximum rate with increasing T. At high T, CV →0 because
the populations of the states become equal and no more increase in energy is possible as
T increases.
18.3 Harmonic Oscillators
We consider the case in which each of our particles is a one-dimensional harmonic
oscillator, ﬁxed in location, with Hamiltonian
H = p2
2m + 1
2kx2,
(18.39)
where p is the momentum, x is the coordinate, m is the mass, and k is the spring constant.
The quantum energy levels of such an oscillator can be obtained in the Schrödinger
14The actual position of the peak occurs at the positive root of tanh x = 1/x, which we estimate to be x =
1.19968.

294
THERMAL PHYSICS
picture by using the momentum operator p = −i¯h∂/∂x and solving the time-independent
Schrödinger equation
Hψn =

−¯h2
2m
∂2
∂x2 + 1
2kx2

ψn = ϵnψn
(18.40)
to determine the wave functions ψn and the energies ϵn of the stationary states. The fact
that the wave functions ψn have to go to zero far outside the potential well (k/2)x2 leads
to a set of allowable wave functions having parity (−1)n, where n = 0, 1, 2, . . . is zero or a
positive integer and nondegenerate energy levels15
ϵn = ¯hω(n + 1/2),
(18.41)
where ω :=

k/m is the classical angular frequency of the oscillator. The quantity ¯hω/2 is
known as the zero-point energy. Since energies in thermodynamics have an arbitrary zero,
we will calculate the thermodynamic functions by using the shifted set of energy levels
εn = ¯hωn.
(18.42)
Using Eq. (18.42) rather than Eq. (18.41) will affect the partition function but will not affect
the probabilities pn or the entropy S. The internal energy and all other thermodynamic
potentials will be lowered by the constant amount N¯hω/2.
The partition function
z =
∞

n=0
exp(−βεn) =
∞

n=0
exp(−β¯hωn) =
∞

n=0
yn,
(18.43)
where β = 1/(kBT) and y := e−x, with x := β¯hω. The geometric series in Eq. (18.43) can be
summed by noting16 that yz = z −1 which leads to z = 1/(1 −y) or
z =
1
1 −e−x .
(18.44)
From Eq. (18.26), we determine the Helmholtz free energy to be
F = NkBT ln(1 −e−x).
(18.45)
The entropy is therefore
S = −∂F
∂T = −NkB

ln(1 −e−x) −
x e−x
1 −e−x

,
(18.46)
where we have used ∂x/∂T = −x/T. The internal energy is
U = F + TS = NkBT x e−x
1 −e−x = N¯hω
1
ex −1.
(18.47)
15See practically any book on quantum mechanics for details. See Appendix I for an algebraic solution by
means of creation and annihilation operators.
16For any ﬁnite temperature, e−x < 1, so the series converges.

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
295
Equation (18.47) was derived originally by Planck [55]. In view of Eq. (18.42), the
quantity
⟨n(T)⟩:=
1
ex −1 =
1
exp(¯hω/kBT) −1
(18.48)
can be thought of as the thermal average ⟨n(T)⟩of the quantum number n. At low
temperatures, ⟨n(T)⟩≈exp(−¯hω/kBT), so
U ≈N¯hω exp(−¯hω/kBT),
low T.
(18.49)
At high T, we have
⟨n(T)⟩=
1
1 + x + x2/2 + · · · −1 =
1
x + x2/2 + · · · ≈1
x = kBT
¯hω .
(18.50)
Thus
U ≈NkBT,
high T.
(18.51)
Note that Eq. (18.51) is independent of ω and so would be true for any one-dimensional
harmonic oscillator, irrespective of mass or force constant. We shall see later that the
result given by Eq. (18.51) is the same as would be given by classical statistical mechanics
(continuum of energies, no quantum states) at all temperatures. Indeed, as ω →0 we have
x →0 so the expansion in Eq. (18.50) would be valid for any T > 0. Planck recognized that
the result at low temperatures would be signiﬁcantly different if the energy levels were
quantized.
Figure 18–7 shows a plot of the internal energy versus temperature. At low temper-
atures, hardly any oscillators can be excited to the ﬁrst excited state, so ⟨n(T)⟩≪1.
Therefore, U remains very small until x ≈1, or kBT ≈¯hω, at which temperature U begins
to rise signiﬁcantly, ultimately becoming linear in T as more and more quantum states
become signiﬁcantly occupied.
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
2.5
U/(N¯hω)
k T/(¯hω)
B
FIGURE 18–7 Dimensionless internal energy U/(N ¯hω) = ⟨n(T)⟩versus dimensionless temperature kBT/(¯hω) = 1/x for
one-dimensional harmonic oscillators according to Eq. (18.47). As T increases from zero, Eq. (18.49) shows that U
increases very little. For large T, Eq. (18.51) shows that U increases nearly linearly with T.

296
THERMAL PHYSICS
Example Problem 18.1. Calculate the probability pn that a single oscillator is the quantum
state n. Then calculate directly the average value of n and hence verify directly Eq. (18.48).
Solution 18.1. From Eqs. (18.11), (18.42), and (18.44) we have
pn = exp[nβ¯hω]/z = e−nx/z = e−nx(1 −e−x),
(18.52)
where x = β¯hω. Thus
⟨n⟩=
∞

n=0
npn = z−1
∞

n=0
n e−nx = −z−1 ∂
∂x z = −∂
∂x ln z = 1/(ex −1).
(18.53)
Equation (18.53) is equivalent to calculating the average energy of a single oscillator from
−∂/∂β ln z and then dividing by ¯hω. Indeed, Eq. (18.12) could have been used to calculate U
in Eq. (18.47) directly from ln z rather than from F and S.
The heat capacity of N one-dimensional harmonic oscillators is
CV = NkB
x2 ex
(ex −1)2 ,
(18.54)
which is plotted in Figure 18–8. Note at high temperatures that CV approaches the
constant value NkB. Unlike the two-state system, the harmonic oscillator has an inﬁnite
number of states, so U continues to increase with T as described by Eq. (18.51).
Similarly, the entropy does not saturate as T increases, as it would for subsystems
having a ﬁnite number of states. Figure 18–9 shows a plot of entropy versus temperature.
As T increases from zero, S remains practically zero until the ﬁrst excited state becomes
signiﬁcantly occupied. Equation (18.46) shows that
0.5
1
1.5
2
2.5
3
0.2
0.4
0.6
0.8
1
CV /(Nk )
k T/(¯hω)
B
B
FIGURE 18–8 Dimensionless heat capacity CV/(N kB)
versus dimensionless temperature kBT/(¯hω)
=
1/x
for one-dimensional harmonic oscillators according
to Eq. (18.54). At high temperatures, CV tends to a
constant, N kB, a behavior very different from that of
two-state subsystems, Figure 18–6.
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
S/(Nk )
k T/(¯hω)
B
B
FIGURE
18–9 Dimensionless
entropy
S/(N kB)
versus
dimensionless
temperature
kBT/(¯hω)
for
one-dimensional harmonic oscillators according to
Eq. (18.46). At low temperatures, S remains near
zero until the ﬁrst excited state is populated. At high
temperatures, S continues to increase with T because
there is an inﬁnite number of states to occupy.

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
297
0.5
1
1.5
2
2.5
3
-2
-1.5
-1
-0.5
F/(N¯hω)
k T/(¯hω)
B
FIGURE 18–10 Dimensionless Helmholtz free energy F/(N ¯hω) versus dimensionless temperature kBT/(¯hω) for one-
dimensional harmonic oscillators according to Eq. (18.45). F decreases with increasing T at an ever increasing rate,
as described by Eq. (18.56).
S ≈NkB

1 + ln(kBT/¯hω)

,
high T.
(18.55)
Figure 18–10 shows a plot of the Helmholtz free energy versus temperature. Since ∂F/∂T =
−S < 0, F decreases with increasing T. From Eq. (18.45) we see that it diverges logarithmi-
cally, that is,
F ≈−NkBT ln(kBT/¯hω),
high T.
(18.56)
18.3.1 Application: Heat Capacity of a Crystal
The heat capacity of a one-dimensional crystal can be modeled by considering a system
made up of one-dimensional harmonic oscillators. Atoms in a crystal vibrate about
their equilibrium positions with increasing amplitudes as the temperature increases.
The Einstein model is a simple model based on the idea that the solid can be characterized
by a harmonic oscillator of a single effective frequency, ωE, the Einstein frequency. Thus
the heat capacity CE is given by Eq. (18.54) which we rewrite in the form
CE = NkB
x2
E exp(xE)
[exp(xE) −1]2 ;
xE := TE
T ,
(18.57)
where the Einstein temperature TE := ¯hωE/kB. Of course a graph of CE/(NkB) versus T/TE
looks just like Figure 18–8. The point of inﬂection is located at about T = 0.4261TE, so TE is
roughly at the knee of the curve, after which CE is practically constant. The Einstein model
yields a curve with about the right shape, but it is wrong in detail at low temperatures. For
a three-dimensional solid, the corresponding heat capacity would be larger by a factor of
3 because oscillations in different directions are decoupled.
A better model can be based on a treatment that allows for vibrating atoms to be
coupled to one another. In solid state physics courses, it is shown that oscillations of the
atoms can be described in terms of a set of spatially delocalized waves, each with its own

298
THERMAL PHYSICS
frequency. Furthermore, each of these waves has the same nondegenerate energy levels
as a one-dimensional harmonic oscillator at some appropriate frequency. For nearest
neighbor interactions only, it can be shown that the allowed angular frequencies are
distributed according to a distribution function
D(ω) = 2N
π
1

1 −(ω/ω0)2
1
ω0
for ω ≤ω0;
D(ω) = 0 for ω > ω0.
(18.58)
Thus, the number of oscillators that have frequencies between ω and ω + dω is D(ω) dω.
Here, ω0 represents the maximum frequency of any oscillator, and can be related to the
“spring constant” and mass of a vibrating atom. The function D(ω) is normalized so that
 ω0
0
D(ω) dω = N.
(18.59)
To get the total internal energy, we form the integral
U =
 ω0
0
D(ω)⟨n⟩¯hω dω =
 ω0
0
D(ω)
¯hω
exp(¯hω/kBT) −1 dω,
(18.60)
where Eq. (18.48) has been used. At high temperatures, we can expand the exponential in
Eq. (18.60) to get
U ≈
 ω0
0
D(ω) kBT dω = NkBT,
(18.61)
independent of the details of D(ω), the same result as Eq. (18.51).
At any temperature, we can calculate the heat capacity
C = ∂U
∂T = kB
 ω0
0
D(ω)
exp(¯hω/kBT)
(exp(¯hω/kBT) −1)2
 ¯hω
kBT
2
dω.
(18.62)
By substituting y = ¯hω/kBT into this integral, we obtain
C = NkB
2
π
kBT
¯hω0
  y0
0
y2 ey
(ey −1)2
1

1 −(y/y0)2 dy,
(18.63)
where y0 = ¯hω0/kBT. At very low temperatures, we have y0 ≈∞and the integral can be
evaluated to yield π2/3. Therefore, we obtain
C = NkB
2π
3
kBT
¯hω0

,
low T.
(18.64)
Equation (18.64) shows that C is linear in T at low T and not exponentially small, as
it would be for the Einstein model (see Eq. (18.54) for large x). In three dimensions,
calculations along similar lines show that C = 3NkBT at high T and C ∝T3 at low T.
18.3.2 Application: Blackbody Radiation
Planck [55, 56] reasoned that radiation from a very small hole in a cavity, which is known as
blackbody radiation, could be treated by assuming that the radiation was in equilibrium

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
299
with harmonic oscillators that make up the vibrating atoms of the cavity. In particular,
Planck assumed that the energy of that radiation at frequency ν could only be emitted in
amounts hν where h = 6.626 × 10−34 m2 kg s−1 is what we now call Planck’s constant. This
turned out to be an inspired guess that can now be fully justiﬁed by quantum mechanics.
The name “blackbody” stems from the fact that any radiation that enters the very small
hole will reﬂect many times from the cavity walls and is very unlikely to exit, so the body
behaves like a nearly perfect absorber.17
Radiation is made up of electromagnetic waves having electric and magnetic vectors
perpendicular to their direction of propagation. The electric ﬁeld for such a wave can be
represented in complex notation by
E = E0 ei(k·r−ωt),
(18.65)
where it is understood that we will take the real part to get the actual ﬁeld. Here, E0 is
a complex amplitude, r = (x, y, z) is the position vector in Cartesian coordinates, k =
(kx, ky, kz) is a wave vector that points in the direction of propagation, ω is an angular
frequency, and t is time. This ﬁeld must satisfy the wave equation
∇2E = 1
c2
∂2E
∂t2 ,
(18.66)
which results in18
ω = ck,
(18.67)
where k = (k2
x + k2
y + k2
z)1/2 is the magnitude of the wave vector. The electric ﬁeld must
also satisfy ∇· E = 0 which requires k · E0 = 0, so E is perpendicular to the direction
of propagation. Thus, there are two independent modes, known as polarizations, corre-
sponding to two orthogonal orientations of the electric ﬁeld in the plane perpendicular
to the direction of propagation. Accompanying the electric ﬁeld given by Eq. (18.65) is a
magnetic ﬁeld B that can be written in the same form. Then from the Maxwell equation
∇× E = −(1/c)∂B/∂t, we can deduce B = ˆk × E, where ˆk = k/k is a unit vector in
the direction of propagation. This shows that the corresponding magnetic ﬁeld is at right
angles to the electric ﬁeld and in phase.
We must also apply boundary conditions to account for the walls of the cavity. This can
be done simply by assuming the cavity to be a cubical box of edge length L whose edges are
parallel to Cartesian axes. This idealization is meaningful because the radiation emitted by
two different blackbodies at the same temperature must be the same; otherwise, radiant
energy could be transmitted from one body to another in the absence of a temperature
difference, a violation of the second law of thermodynamics. Moreover, this must be true
in each frequency range by means of the same argument with the addition of a ﬁlter to
eliminate other frequencies. We could use real functions for the ﬁelds and make them
vanish on the walls of the box, but for traveling waves of the form of Eq. (18.65) it easier
17In German, it is known as hohlraum, literally hollow space, or cavity.
18By working in Cartesian coordinates, it is easy to show that ∇· E = ik · E, ∇2E = −k2E and ∇× E = ik × E.

300
THERMAL PHYSICS
to use periodic boundary conditions. Thus, we require E(x, y, z, t) = E(x + L, y, z, t) and
similarly for the y- and z-directions to deduce
kx = 2πnx/L;
ky = 2πny/L;
kz = 2πnz/L,
(18.68)
where nx, ny, and nz are integers, both positive and negative.19 Thus, the frequencies
ω(k) = ω(|k|) of the modes are known and form a discrete set. However, it is important
to recognize that this is all based on classical electromagnetic theory and has nothing to
do with quantum mechanics. The quantization actually enters from the quantum theory
of ﬁelds which is beyond the scope of this book.20 According to that theory, the allowed
energies of each mode are given by nhν = n¯hω, where n = 0, 1, 2, . . . is an integer, just
as for a harmonic oscillator of that same angular frequency, in agreement with Planck’s
inspired hypothesis.
We can therefore use Eq. (18.48) for the thermal average, ⟨n(T)⟩, of the quantum
number n. Thus, the thermal energy of the radiation is given by
U = 2

k
¯hω(|k|)
exp(¯hω(|k|)/kBT) −1,
(18.69)
where ω(|k|) is the frequency of an electromagnetic wave having wave vector k. This
sum can be converted to an integral by recognizing that for sufﬁciently large L the
allowed values of k are closely spaced and therefore virtually continuous. According to
Eq. (18.67), for each polarization there will be one mode for each volume of k space of
size kxkykz = (2π/L)3 = (2π)3/V, where V is the volume of the box. Thus, for some
function F(k),

k
F(k) =

kx

ky

kz
V
(2π)3 kxkykz F(k) →
V
(2π)3

all k
d3k F(k).
(18.70)
But for the special case in which F depends only on the magnitude of k, we can use
spherical coordinates in k space with volume element d3k = 4πk2 dk to obtain the well-
known result

k
F(|k|) →
V
(2π)3
 ∞
0
4πk2 dk F(|k|).
(18.71)
Finally, in the case that F(|k|) = f (ω(|k|)), we can convert to an integral over ω = ck by
using dk = (dk/dω) dω = dω/c to obtain

k
F(|k|) →
V
2π2
1
c3
 ∞
0
ω2 dωf (ω).
(18.72)
19If real functions that vanish at the walls of the box are used, these wave vectors are reduced by a factor of 2,
but the integers are only positive. This leads to a different density of modes in k space that is eight times larger,
so the ﬁnal outcome of calculations will be the same. See Example Problem 16.2 and Section 23.1 for treatment
of a rectangular box and more detail in a related context.
20See, for example, Schiff [57, p. 517].

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
301
Thus, Eq. (18.69) becomes
U = V
π2
1
c3
 ∞
0
ω2 dω
¯hω
exp(¯hω/kBT) −1.
(18.73)
We substitute x = ¯hω/kBT in this integral to obtain
U = V(kBT)4
π2c3¯h3
 ∞
0
dx
x3
ex −1.
(18.74)
The value of the integral turns out to be π4/15, so the energy density
uV := U
V = (kBT)4π2
15c3¯h3 .
(18.75)
Equation (18.74) can be used to calculate the ﬂux, J, of blackbody radiation from a small
hole in the cavity by recognizing that the radiation propagates at speed c and falls onto a
given area from all directions that point from a hemisphere to its center. The ﬂux results
from the normal component of that radiation, so J = cuV fgeo, where the geometrical factor
fgeo := 1
4π
 2π
0
dϕ
 π/2
0
sin θ cos θ dθ = 1
4.
(18.76)
Thus
J = 1
4cuV = σSBT4,
(18.77)
where
σSB := π2k4
B
60¯h3c2 = 4.67 × 10−8 watt m2 K−4
(18.78)
is known as the Stefan-Boltzmann constant. This T4 law for blackbody radiation has been
conﬁrmed experimentally.
We can also deduce the spectral distribution of blackbody radiation by multiplying
Eq. (18.73) by c/4V and extracting the integrand to obtain
jω =
¯h
4π2c2
ω3
exp(¯hω/kBT) −1;
 ∞
0
jω dω = J.
(18.79)
The quantity jω dω is therefore the power per unit area of radiation emitted in the angular
frequency interval dω centered about ω.
We can investigate the shape of this spectral distribution as a function of tempera-
ture by introducing an arbitrary reference temperature T0, a dimensionless temperature
t := T/T0, and a dimensionless angular frequency W := ¯hω/kBT0. Then
jω dω = JW dW = 15
π4 σSBT4
0
W 3
exp(W/t) −1 dW.
(18.80)
Figure 18–11 shows a plot of the dimensionless spectral distribution of radiation according
to Eq. (18.80) as a function of dimensionless frequency, W, for three dimensionless

302
THERMAL PHYSICS
2
4
6
8
10
1
2
3
4
W 3
exp(W/t)−1
W
t = 1
t = 1.25
t = 1.5
FIGURE 18–11 Plot of the dimensionless spectral distribution according to Eq. (18.80) as a function of dimensionless
frequency, W, for three dimensionless temperatures, t = 1, t = 1.25, and t = 1.5. The peaks of these curves increase
in height as 1.42 t3, broaden in proportion to t, and move to higher frequencies W = 2.82 t with increasing t. The
area under each curve is (π4/15)t4.
temperatures, t. As t increases, the peaks of these curves increase in height and move to
higher frequencies. The peaks occur for ¯hω/kBT = W/t = 2.82, which is evident from the
lower curve for which T = T0. This is sometimes referred to as Wien’s displacement law
and can be used to estimate the temperature of stars from their dominant frequency of
radiation. The peak heights of the curves in Figure 18–11 are 1.42 t3 and the area under
each curve is (π4/15)t4, so
 ∞
0 JW dW = σSBT4 = J, in agreement with Eq. (18.77).
Note that the spectral distribution of radiation given by Eq. (18.80) is in agreement with
the following familiar observation: As a body is heated to higher and higher temperatures,
it begins to glow, ﬁrst a dull cherry red, then a somewhat brighter orange, then yellow, then
white, then bluish white, with ever increasing intensity.
Returning to Eq. (18.79), we note in the classical limit ¯h →0 that ¯hω/[exp(¯hω/kBT) −
1] →kBT, so
 ∞
0
jω dω =
1
4π2c2
 ∞
0
kBTω2 dω = 2πc
 ∞
0
kBTλ−4 dλ,
(18.81)
where the wavelength λ = 2πc/ω. These integrals do not converge, the former at ω →∞
and the latter at λ →0. Prior to the advent of quantum mechanics, this was known as
the ultraviolet catastrophe. Quantum mechanics resolves this problem at large ω because
jω ∼ω3 exp(−¯hω/kBT) which is strongly damped because of the extremely low probability
of exciting the high energy quanta ¯hω. Planck’s energy quantization hypothesis [55, 56] was
the key to removing this singularity and stimulated the development of quantum theory.21
21The citation of Planck’s 1918 Nobel Prize in Physics reads: “In recognition of the services he rendered to the
advancement of Physics by his discovery of energy quanta.”

Chapter 18 • Distinguishable Particles with Negligible Interaction Energies
303
18.4 Rigid Linear Rotator
We consider a system for which each particle is a rigid linear rotator, such as a diatomic
molecule with only two degrees of rotational freedom. See Section 21.3.2 and Appendix F
for context and more detail. The quantized energy levels are
ε(j) = j(j + 1)ε0,
(18.82)
where j is zero or a positive integer, that is, j = 0, 1, 2, . . . and the constant ε0 = ¯h2/2I.
Here, I is the moment of inertia22 of the rotator with two degrees of freedom having
principal moments of inertia (I, I, 0). In this case, the energy levels are degenerate, each
corresponding to 2j + 1 states. The partition function for each particle is therefore
z =
∞

j=0
(2j + 1) exp[−j(j + 1)x],
(18.83)
where x := ε0/kBT. In Eq. (18.83), it is important to note that the degeneracy factor 2j + 1
appears because the partition function is a sum over quantum states, not just energy
levels.
For high temperatures, x is small and the energy levels are practically continuous. We
can therefore replace the sum over j by an integral. Thus
z ≈
 ∞
0
(2j + 1) exp[−j(j + 1)x] dj.
(18.84)
We set y = j(j + 1)x in which case dy = (2j + 1)x dj and Eq. (18.84) becomes
z = 1
x
 ∞
0
exp[−y] dy = 1
x = kBT
ε0
=
1
βε0
.
(18.85)
This result can also be derived from classical statistical mechanics (see Eq. (20.123)). From
Eq. (18.25) we readily obtain
U = N ∂
∂β (ln β + ln ε0) = N
β = NkBT
(18.86)
independent of ε0. This turns out to be the same result as would be obtained for a classical
rotator. The corresponding heat capacity is C = NkB, which explains why diatomic gases
have a correspondingly higher heat capacity (by R per mole) than monatomic gases.
For low temperatures, x is very large and the exponential series cuts off very quickly,
which leads to
z ≈1 + 3e−2x + 5e−6x + · · · .
(18.87)
From Eq. (18.25), we obtain
U
Nε0
= −∂
∂x ln z =
6e−2x + 30e−6x
1 + 3e−2x + 5e−6x + · · · .
(18.88)
22For a diatomic molecule made up of point masses m1 and m2 separated by a distance ℓ0, I = ℓ2
0m1m2/
(m1 + m2).

304
THERMAL PHYSICS
0.5
1
1.5
2
2.5
3
0.2
0.4
0.6
0.8
1
C/(Nk )
k T/ε0
B
B
FIGURE 18–12 Plot of the dimensionless heat capacity C/(N kB) versus dimensionless temperature kBT/ε0 for a linear
rigid rotator. Note especially the overshoot of the asymptotic value, which is quite different from the monotonic
increase of C for the harmonic oscillator.
To leading order, the low-temperature heat capacity is
C = 12NkBx2e−2x.
(18.89)
We observe that C vanishes exponentially as T →0 and therefore rises very slowly as T
ﬁrst increases.
For intermediate values of the temperature, one must resort to series expansions or
numerical computations. A plot of the dimensionless heat capacity versus dimensionless
temperature is shown in Figure 18–12. Unlike the heat capacity of the harmonic oscillator,
which increases monotonically with T, C for the rigid rotator passes through a maximum
before becoming asymptotic to its value at high temperatures.
An approximate solution at high temperatures can be obtained by using the Euler-
Maclaurin sum formula discussed in Appendix H and results in
C
NkB
=

1 + x2
45 + 16x3
945 + O(x4)

.
(18.90)
Eq. (18.90) shows clearly that C asymptotes NkB from larger values as T →∞.

19
Canonical Ensemble
In Chapter 16, we introduced the microcanonical ensemble which is based on the fun-
damental hypothesis that all microstates of an isolated system, compatible with a given
macrostate and having a ﬁxed energy and other speciﬁed macrovariables, are equally
probable. This ensemble is of great theoretical importance but difﬁcult to use because
of the formidable problem of counting the number of microstates. We shall therefore use
it to derive a more useful ensemble, known as the canonical ensemble, that is much more
tractable. To do this, we give up a precise knowledge of the energy of our system of interest
and specify instead its temperature. Nevertheless, its average energy will still be known
to high precision and will play the role of the internal energy of thermodynamics. The
temperature of our system can be imposed by contact with a heat reservoir, in which
case our system is not isolated. The classical version of this ensemble, discussed in the
next chapter, was developed by Gibbs who named it “the distribution of phase called
canonical” [4, p. 32].
19.1 Three Derivations
The canonical ensemble can be derived in a number of ways, all of which lead to the same
ﬁnal result in the thermodynamic limit. Because of the importance of this ensemble, we
present three derivations, each of which emphasizes an aspect of the ensemble that is
not transparent from the others. The methodology of the second derivation will be used
in Chapter 21 to derive the grand canonical ensemble and the methodology of the third
derivation will be used in Chapter 22 to derive a number of ensembles from a general
expression for the entropy.
19.1.1 Derivation from Microcanonical Ensemble I
We derive the canonical ensemble from the microcanonical ensemble by applying the
fundamental hypothesis to an isolated total system with ﬁxed energy ET, consisting of a
reservoir R and a system I of interest. The system I may, itself, be very large and consist
of a number of subsystems, or particles, that may interact with one another. We assume
that the system I has quantum states Ei and that its extensive macrovariables, other than
energy, are ﬁxed. The index i indicates a speciﬁc quantum state, so it actually represents a
complete set of quantum numbers.
Suppose that the system I is in a deﬁnite quantum state i having energy Ei. Then
the reservoir has energy ET −Ei. For the total system, the number of microstates can be
expressed as a product of the number of microstates of the reservoir, R, and the number
of microstates of the system of interest, , in the form
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00019-3
305
Copyright © 2015 Elsevier Inc. All rights reserved.

306
THERMAL PHYSICS
i
T = R(ET −Ei)(Ei) = R(ET −Ei) × 1 = R(ET −Ei).
(19.1)
In other words, the system I is in a single deﬁnite microstate, so for the system of interest,
(Ei) = 1; therefore, only the number of microstates of the reservoir must be counted. An
equation similar to Eq. (19.1) holds if the system I is in the quantum state j. As explained in
Section 16.1, the probability of a system being in a given macrostate with energy E, volume
V, and number of particles N is proportional to (E, V, N), which is the sum of its number
of equally probable microstates. Therefore, the ratio of the probability Pi of system I being
in the eigenstate i to the probability Pj of system I being in the eigenstate j is
Pi
Pj
= R(ET −Ei)
R(ET −Ej) = exp[SR(ET −Ei)/kB]
exp[SR(ET −Ej)/kB],
(19.2)
where SR(ER) is the entropy of the reservoir in a state having energy ER. We now assume
that the reservoir R is very large so that |Ej −Ei| ≪|ET −Ej| for any states of I. Then by
expanding in a Taylor series we obtain1
SR(ET −Ei) = SR[(ET −Ej) + (Ej −Ei)] = SR(ET −Ej) + (Ej −Ei) ∂SR
∂ER
+ · · ·
= SR(ET −Ej) + Ej −Ei
TR
+ · · · ,
(19.3)
where TR is the temperature of the reservoir. Substitution into Eq. (19.2) and cancellation
of the factor exp[SR(ET −Ej)/kB] gives
Pi
Pj
= exp(−Ei/kBTR)
exp(−Ej/kBTR) .
(19.4)
Equation (19.4) states that the probability Pi of system I being in eigenstate i is
proportional to its Boltzmann factor exp(−Ei/kBT) where we have dropped the subscript
R on T for simplicity.2 We can obtain a normalized probability by dividing by the total
partition function
Z =

j
exp(−βEj)
(19.5)
to obtain
Pi = exp(−βEi)
Z
,
(19.6)
where β = 1/(kBT). In Eq. (19.5), the sum is over all of the quantum states of the system of
interest. Equation (19.5) resembles our former equation for the occupation probabilities
pi = exp(−βεi)/z of weakly interacting distinguishable subsystems except that we are now
1The ratio of the second-order term to the ﬁrst-order term is −(Ej −Ei)/(2CRTR), where CR is the heat capacity
of the reservoir. We assume that CR is so large that this term and higher order terms are negligible. This is
essentially the deﬁnition of a heat reservoir.
2We must still bear in mind, however, that the canonical ensemble applies to a system in contact with a heat
reservoir of constant temperature T. Given that other extensive variables of the system are held constant in this
derivation, the canonical ensemble will relate thermodynamically to the Helmholtz free energy.

Chapter 19 • Canonical Ensemble
307
dealing with the states and energy levels of a whole system. The internal energy of our
system is
U =

i
PiEi = −∂ln Z
∂β
,
(19.7)
which resembles U = −N∂ln z/∂β except that the factor of N is now missing because we
are dealing with Z for the whole system.
Finally, we obtain the Helmholtz free energy F of system I. Since F = U −TS and
S = −∂F/∂T, we see that F satisﬁes the differential equation
F −T ∂F
∂T = U,
(19.8)
which, in terms of β, can be rewritten in the form
F + β ∂F
∂β = −∂ln Z
∂β
.
(19.9)
The left-hand side of Eq. (19.9) is recognized immediately to be ∂(βF)/∂β, so it may be
integrated to obtain
F = −1
β ln Z + a
β ,
(19.10)
where a is a function of integration (independent of β). The entropy is therefore
S = U −F
T
= U
T + kB ln Z −kBa.
(19.11)
But when T →0, only the ground state with degeneracy g0 and energy E0 is occupied, so
Z →g0 exp(−βE0) and ln Z →ln g0−βE0. Similarly, as T →0 we have U →E0, so Eq. (19.11)
becomes
S(T →0) = kB ln g0 −kBa.
(19.12)
Consistent with Eq. (16.2), however, we require3
S(T →0) = kB ln g0,
(19.13)
which means that the function of integration a = 0. Thus Eq. (19.10) becomes
F = −1
β ln Z
(19.14)
3Note that the value of S(T →0) according to Eq. (19.13) is not zero due to the possibility of degeneracy of
the ground state. It would be strictly zero for a nondegenerate ground state for which g0 = 1. If this degeneracy
were massive, say of order g0 = qN , where q is some integer and N is the number of subsystems or “particles” in
the system, then S(T →0) would be N kB ln q which would be extensive and signiﬁcant. Otherwise, S(T →0) is
practically zero.

308
THERMAL PHYSICS
which resembles our former result for weakly interacting identical but distinguishable
subsystems with N missing and z replaced by Z. Equation (19.14) can also be written in
the form

j
exp(−βEj) = exp(−βF),
(19.15)
which shows the relationship between the microscopic picture (on the left) and the
macroscopic picture (on the right). Moreover,
S = U
T −F
T = kBβU + kB ln Z = −kB
κ

i=1
Pi ln Pi = −kBβ2 ∂
∂β
ln Z
β

.
(19.16)
Note that the quantity −κ
i=1 Pi ln Pi = D{Pi} is the disorder function of information
theory discussed in Section 15.1.
19.1.2 Derivation from Microcanonical Ensemble II
We give an alternative derivation of the canonical ensemble from the microcanonical
ensemble by following the procedure of the preceding section but calculating directly the
probability Pi of a given microstate of the system of interest. This probability is the ratio
of i
T given by Eq. (19.1) to the total number of microstates T(ET) when the system of
interest is not restricted to a speciﬁc microstate. Thus
Pi =
i
T
T(ET) = R(ET −Ei)
T(ET)
= exp[SR(ET −Ei)/kB]
exp[ST(ET)/kB]
.
(19.17)
Since the entropy of a composite system is additive, we have
ST(ET) = SR(ET −U) + S(U),
(19.18)
where U is the (average) internal energy of the system of interest at equilibrium in its
unrestricted state. We can therefore recast Eq. (19.17) in the form
Pi = exp[−S(U)/kB] exp[SR(ET −Ei)/kB]
exp[SR(ET −U)/kB]
.
(19.19)
But
SR [ET −Ei] = SR[(ET −U) + (U −Ei)] = SR(ET −U) + U −Ei
TR
+ · · · ,
(19.20)
where we have expanded on the basis that |U −Ei|/|ET −U| ≪1. Substitution into
Eq. (19.19) yields
Pi = exp[−S(U)/kB] exp[U/kBTR] exp[−Ei/kBTR].
(19.21)
Dropping the subscript on TR and using β = 1/kBT, Eq. (19.21) can be written in the
succinct form
Pi = exp(βF) exp(−βEi),
(19.22)

Chapter 19 • Canonical Ensemble
309
where F = U −TS is the Helmholtz free energy. Since 
i Pi = 1, Eq. (19.22) yields
exp(−βF) =

i
exp(−βEi) = Z
(19.23)
in agreement with our previous results, Eqs. (19.14) and (19.15).
19.1.3 Derivation III: Most Probable Distribution
In this section, we give yet another derivation of the canonical ensemble but from the
point of view of the most probable distribution. We consider a large number Nens of
identical systems, each having the same volume V and the same number of particles
N, and each in a stationary quantum state.4 These systems constitute the ensemble and
they share a constant total energy Nens ¯E, where ¯E is the average energy per system. Ni
members of the ensemble are in an eigenstate having energy Ei such that the probability
of occurrence of that eigenstate is Pi = Ni/Nens. The set {Ni} = N1, N2, . . . , Nr is such that
r
i = 1 Ni = Nens which is equivalent to5
r

i=1
Pi = 1.
(19.24)
Since r
i=1 NiEi = Nens ¯E, we also have
r

i=1
PiEi = ¯E.
(19.25)
The number of ways of constructing such an ensemble is
Wens{Ni} :=
Nens!
N1!N2! · · · Nr!.
(19.26)
We would like to choose the set {Ni} to maximize Wens{Ni} subject to the constraints above
to give the most probable distribution. Since d ln x = (1/x)dx, the maximum of ln x occurs
at the same value of x as the maximum of x. Therefore, for convenience, we maximize
ln Wens. With the aid of Stirling’s approximation we have
ln Wens = Nens ln Nens −
r

i=1
Ni ln Ni = −Nens
r

i=1
Pi ln Pi.
(19.27)
Since Nens is a constant, we can just maximize the function
D{Pi} = −
r

i=1
Pi ln Pi,
(19.28)
4If other extensive variables are necessary to specify our system of interest, they are also the same for all
members of the ensemble.
5If a system has a number of eigenstates r, we certainly need Ni > r to represent the ensemble. But ultimately
we can take the limit Nens →∞in such a way that Ni →∞but the ratio Pi = NiNens remains ﬁnite. Thus, there
is essentially no problem even if r →∞.

310
THERMAL PHYSICS
subject to the constraints Eqs. (19.24) and (19.25). Once the set {Ni} is determined, Wens is
the number of microstates of the whole ensemble, so kB ln Wens represents the entropy
of the whole ensemble. Thus, S = (1/Nens)kB ln Wens is the entropy per system of the
ensemble. It therefore plays the role of the thermodynamic entropy of the system that the
ensemble represents. We therefore have
S = −kB
r

i=1
Pi ln Pi = kBD{Pi},
(19.29)
where D{Pi} is seen to be a dimensionless measure of the entropy. We note that D{Pi}
is the same as the disorder function of Section 15.1, where we have shown (see the ﬁrst
example problem) from its form that it is additive for a composite system. But here we are
maximizing D{Pi} subject to the additional constraint Eq. (19.25) on the average energy of
members of an ensemble that have different energies. For the microcanonical ensemble,
all members of the ensemble have the same energy.
In the maximization process, we handle the constraints by means of Lagrange multi-
pliers β and α and solve the problem
∂
∂Pj

−
r

i=1
Pi ln Pi −β
r

i=1
PiEi −α
r

i=1
Pi

= 0
(19.30)
with each Pj now (temporarily) considered to be an independent variable. We obtain
−ln Pj −1 −βEj −α = 0,
(19.31)
which may be exponentiated to give
Pj = e−α−1 e−βEj.
(19.32)
Summing Eq. (19.32) over all values of j and applying the constraint Eq. (19.24) allows us
to determine that exp(−α −1) = 1/Z, where Z = 
j exp(−βEj) is the partition function as
given by Eq. (19.5). Therefore, Eq. (19.32) becomes
Pj = exp(−βEj)
Z
.
(19.33)
It remains to determine the Lagrange multiplier β. Formally, this could be done in
terms of ¯E by satisfying the constraint Eq. (19.25) but this would lead to a difﬁcult
transcendental equation for β. Therefore, one takes instead an alternative approach by
appealing to thermodynamics which allows β to be identiﬁed as a physical quantity.
To strengthen this identiﬁcation, we recognize that the energies Ei of the eigenstates
depend on the volume V of the system6 and its number of particles N. Then
6This is convenient but not essential to the identiﬁcation of β. It simply allows the system to do reversible
work δW = p dV. If Ei were to depend on a set of extensive mechanical parameters Yj instead of just V, one could
write the reversible work in the form 
j fj dYj, where the fj are generalized forces. Then fj = −
i Pi∂Ei/∂Yj.

Chapter 19 • Canonical Ensemble
311
d ¯E =
r

i=1
Ei dPi +
r

i=1
Pi dEi =

i
Ei dPi +
r

i=1
Pi
∂Ei
∂V dV +
r

i=1
Pi
∂Ei
∂N dN.
(19.34)
From Eq. (19.29), the differential of the entropy is
dS = −kB
r

i=1
(1 + ln Pi) dPi = −kB
r

i=1
ln Pi dPi = kBβ
r

i=1
Ei dPi,
(19.35)
where 
i dPi = 0 has been used in the second and third steps. Substitution of Eq. (19.35)
into Eq. (19.34) then gives
d ¯E = (kBβ)−1 dS +
r

i=1
Pi
∂Ei
∂V dV +
r

i=1
Pi
∂Ei
∂N dN.
(19.36)
Comparison of Eq. (19.36) with dU = T dS −p dV + μ dN and the identiﬁcation ¯E = U
shows that β = 1/(kBT) as expected. We also deduce
p = −
r

i=1
Pi
∂Ei
∂V ;
μ =
r

i=1
Pi
∂Ei
∂N .
(19.37)
According to Eq. (19.37), the pressure p can be interpreted heuristically as if ∂Ei/∂V were
a force per unit area associated with each state and ∂Ei/∂N were an energy per particle
associated with each state. From the forms of Eqs. (19.35) and (19.36), we see that a change
dS in entropy results from a change in populations Pi at ﬁxed Ei; however, reversible work
results from a change d ¯E of energy at constant S, and therefore from a change of Ei at
constant population Pi and ﬁxed particle number N. Similarly, the chemical potential μ
results from a change in Ei with N at constant population Pi and ﬁxed V.
Recognizing that the philosophy of this ensemble is to specify T and take whatever
¯E corresponds, we return to the notation of thermodynamics and write Eq. (19.25) in
the form
U =
r

i=1
PiEi,
(19.38)
where the summation is over all states. From Eqs. (19.29) and (19.33) we deduce that
TS = −kBT
r

i=1
Pi(−βEi −ln Z) = U + kBT ln Z.
(19.39)
Thus the Helmholtz free energy
F = U −TS = −kBT ln Z
(19.40)
in agreement with Eq. (19.14) or (19.23).
As an alternative procedure, we could have identiﬁed β by comparing dU with dS at
constant V and N, in which case dU = T dS. Then we could calculate S from Eq. (19.39)
and the results in Eq. (19.37) could be obtained from p = −∂F/∂V, μ = −∂F/∂N and
Eq. (19.33).

312
THERMAL PHYSICS
Before leaving this section, we remark that instead of the most probable values of Pj
or, equivalently Nj = NensPj, we could deal with the mean values ⟨Nj⟩with respect to the
quantities Wens{Ni} given by Eq. (19.26). Speciﬁcally,
⟨Nj⟩=

{Ni} NjWens{Ni}

{Ni} Wens{Ni} ,
(19.41)
where the sums are to be taken over all values of the set {Ni} that are compatible with the
constraint Eqs. (19.24) and (19.25), written in terms of the Ni. By means of a somewhat
technical and lengthy calculation (e.g., see Schrödinger [99, p. 27] or Pathria [8, p. 46]), it
can be shown that ⟨Nj⟩and Nj calculated for the most probable distribution are the same
in the limit Nens →∞.
19.2 Factorization Theorem
If our system of interest can be decomposed into a number M of distinguishable ele-
ments that have negligible interaction energy and whose quantum states can be occupied
independently of the occupation of the quantum states of the other elements, then the
partition function of the system factors into the product of partition functions of the
elements. Thus
Z =
M

ℓ=1
Z(ℓ),
(19.42)
where Z(ℓ) is the partition function of the element (ℓ).
We shall prove this theorem for two elements but the result can clearly be extended
to any number of elements by further decomposition. We replace the single quantum
number i by the composite quantum numbers jk and write
Ejk = E(1)
j
+ E(2)
k ,
(19.43)
where the superscripts pertain to the two elements. The partition function becomes
Z =

jk
exp[−βEjk] =

jk
exp[−βE(1)
j
] exp[−βE(2)
k ] = Z(1)Z(2),
(19.44)
where
Z(1) =

j
exp[−βE(1)
j
];
Z(2) =

k
exp[−βE(2)
k ].
(19.45)
19.2.1 Distinguishable Particles with Negligible Interaction
We can recover our former results (Chapter 18) for N very weakly interacting (meaning
negligible energy of interaction) identical but distinguishable particles (subsystems) by

Chapter 19 • Canonical Ensemble
313
noting that the energy Ei of each state is a sum of energies ε(m)
n
of individual particles m in
quantum states n. Thus
Z =

i
exp(−βEi) =

jkℓ···
exp[−β(ε(1)
j
+ ε(2)
k
+ ε(3)
ℓ
+ · · · )] =
N

m

n
exp(−βε(m)
n
) = zN .
(19.46)
From Eq. (19.46), we obtain
ln Z = N ln z,
identical distinguishable particles,
(19.47)
and our former equations (see Section 18.1.1 for a summary) for identical but distinguish-
able particles with negligible interaction energies are recovered. The reader is encouraged
to study the numerous examples in Chapter 18.
If the particles are identical but not distinguishable, for example particles of an ideal
gas that share the same volume, then occupation of individual particle states does not
constitute an independent state and the factorization theorem requires modiﬁcation, as
illustrated in the next section for a classical ideal gas. If the particles are identical fermions
or identical bosons, their wave functions must obey quantum statistics so the occupation
of their quantum states is correlated and factorization of the canonical partition function
is not possible. In Chapter 21, we introduce the grand canonical ensemble which enables
factorization of the grand partition function for ideal Fermi and Bose gases.
19.3 Classical Ideal Gas
For a classical ideal gas, the identical particles do not interact, but since they share the
same volume they are not distinguishable. In this case, the simple decomposition that
led to Eq. (19.46) is not applicable. This is because an interchange of particles does not
constitute a new quantum state. Nevertheless, if the gas is very dilute, in the sense that the
number of particles is much smaller than the number of accessible single particle quan-
tum states, the probability of multiply-occupied states will be very small. By accessible
quantum state, we mean a state whose Boltzmann factor makes a signiﬁcant contribution
to the single-particle partition function at the temperature under consideration. We can
therefore correct Eq. (19.46) by dividing by N! which is the number of permutations of N
particles among N distinct single particle states. Then approximately
Z ≈zN
N! ,
dilute indistinguishable particles,
(19.48)
so that
ln Z ≈N ln z −ln N! ≈N ln(z/N) + N,
dilute indistinguishable particles,
(19.49)
where Stirling’s approximation for ln N! has been used.
Note that Eq. (19.48) is based on
Ei →ε(1)
j
+ ε(2)
k
+ ε(3)
ℓ
+ · · ·
(19.50)

314
THERMAL PHYSICS
and the fact that it no longer matters which particles (subsystems) are in a given state. If
all of the terms on the right-hand side of Eq. (19.50) correspond to different single particle
states, the result in Eq. (19.46) would be too large by exactly a factor of N!. If some of
the single particle states are the same, then N! would be an overestimate. If, however,
the system is dilute in the sense that the probability of multiple occupation of a single
particle state is negligible, then N! is a good estimate of the overcount and Eq. (19.48) holds
approximately.7 The factor 1/N! is the same Gibbs correction factor that we discussed
in Section 16.4.1 in connection with the microcanonical ensemble, but now we are in a
position to better understand the conditions for its applicability.
19.3.1 Free Particle in a Box
A structureless free particle of mass m in a rectangular box of dimensions H, K, L has
eigenstates with energies ε
= ¯h2k2/2m as discussed in Section 16.4.1. For periodic
boundary conditions ψ(x + H, y, z) = ψ(x, y, z), ψ(x, y + K, z) = ψ(x, y, z), and ψ(x, y, z +
L) = ψ(x, y, z), the wave vector k is given by Eq. (16.51). We expand our notation and write
εnx,ny,nz = ¯h2
2m(2π)2
	
nx
H
2
+
ny
K
2
+

nz
L
2
.
(19.51)
Then the single particle partition function is
z =

nx,ny,nz
exp(−βεnx,ny,nz)
=

nx
exp
	
−β ¯h2
2m
2πnx
H
2 
ny
exp
	
−β ¯h2
2m
2πny
K
2 
nz
exp
	
−β ¯h2
2m
2πnz
L
2
=

kx
exp

−β ¯h2
2mk2
x
 
ky
exp

−β ¯h2
2mk2
y
 
kz
exp

−β ¯h2
2mk2
z

.
(19.52)
Equation (19.52) shows that the single particle partition function factors, one factor for
each direction in three-dimensional space. Moreover, if kBT is large compared to the
splittings between states, the sums in Eq. (19.52) can be approximated by integrals, viz.,

nx
exp
	
−β ¯h2
2m
2πnx
H
2
=

kx
exp

−β ¯h2
2mk2
x

≈H
2π
 ∞
−∞
dkx exp

−β ¯h2
2mk2
x

.
(19.53)
The factor of H/(2π) on the right-hand side of Eq. (19.53) arises because kx changes by
2π/H as nx changes by one. Applying Eq. (19.53) to each of the products in Eq. (19.52)
gives
7An alternative derivation of this result can be based on use of the grand canonical ensemble, which allows
the number of particles to be indeﬁnite but speciﬁes the chemical potential. See Section 21.2.4 and Chandler
[12, pp. 100-103] for further discussion.

Chapter 19 • Canonical Ensemble
315
z = HKL
(2π)3
 ∞
−∞
dkx exp

−β ¯h2
2mk2
x
  ∞
−∞
dky exp

−β ¯h2
2mk2
y
  ∞
−∞
dkz exp

−β ¯h2
2mk2
z

=
V
(2π)3

k
d3k exp

−β ¯h2
2mk2

= V
mkBT
2π¯h2
3/2
.
(19.54)
In Eq. (19.54), the integral on the second line is over all of k space. To get the ﬁnal
result, one can either do the individual Cartesian integrals, each of which has the same
value (mkBT/2π¯h2)1/2, or do the three-dimensional integral in polar coordinates. The
prescription
1
V

k
→
1
(2π)3

k
d3k,
(19.55)
which is valid when the state energies are closely spaced compared to kBT, becomes exact
in the limit V →∞, in which case the sum on the left-hand side is over an inﬁnite number
of states whose separations tend to zero.
Our result in Eq. (19.54) can be written in the form
z = VnQ,
(19.56)
where
nQ :=
mkBT
2π¯h2
3/2
(19.57)
is known as the quantum concentration. The de Broglie wavelength is λB = 2π¯h/p, where
p is the momentum of a particle. If we estimate p2/(2m) ∼πkBT, we obtain the thermal
wavelength
λB ∼λT :=
 2π¯h2
mkBT
1/2
,
(19.58)
which leads to
nQ = 1
λ3
T
.
(19.59)
To see when our approximation of a dilute gas is valid, we note that the magnitude of
the partition function z is a rough measure of the number of single particle quantum
states accessible to a particle at a given temperature. We therefore want z to be much
greater than the number of particles, that is, z/N ≫1. By substituting z from Eq. (19.56),
we obtain nQ ≫N/V =: n or alternatively (λ3
T) ≪V/N = 1/n. In other words, the
concentration of the gas must be sufﬁciently low that the volume per particle, 1/n is
very large compared to the cube of the thermal wavelength. For situations in which this
inequality is not satisﬁed, quantum effects become important and the particles must be
treated either as fermions or bosons, depending on whether their spin is half integral or
integral.

316
THERMAL PHYSICS
Substitution of Eq. (19.56) into Eq. (19.49) yields
ln Z = N ln(V /N) + N ln nQ + N,
ideal gas.
(19.60)
The Helmholtz free energy is therefore
F = −NkBT ln(V /N) −NkBT ln nQ −NkBT,
ideal gas,
(19.61)
which is an extensive function, as required. By applying Eq. (19.7) to ln Z expressed by
Eq. (19.60), we obtain
U = −∂
∂β [N ln(V /N) + N ln nQ + N] = 3
2N ∂ln β
∂β
= 3
2NkBT,
ideal gas,
(19.62)
consistent with a constant heat capacity of CV = (3/2)NkB as expected. Note that only the
term in nQ contributes to Eq. (19.62) so this same result would have been obtained if we
had used the (incorrect) partition function Z = zN . The pressure can be determined by
differentiation of Eq. (19.61) to obtain
p = −∂F
∂V = NkBT ∂ln V
∂V
= NkBT
V
= NRT
V
,
ideal gas,
(19.63)
which is recognized as the ideal gas law. Again, this same result would have been obtained
if we had used the (incorrect) partition function Z = zN . On the other hand, the entropy
can be obtained by differentiation of Eq. (19.61) to obtain
S = −∂F
∂T = NkB[ln(nQV /N) + (5/2)],
ideal gas.
(19.64)
Equation (19.64) is known as the Sackur-Tetrode equation and requires use of the correct
partition function Z = zN /N!. The entropy constant in Eq. (19.64) has been veriﬁed by
experiment.8 Note that this constant depends on ¯h (through nQ) so its origin is quantum
mechanical. Classical thermodynamics alone would yield
S = NkB[ln(V /N) + (3/2) ln T] + Ns0,
ideal gas,
(19.65)
and it would not be possible to determine the constant s0. Similarly, the chemical potential
(per particle) is
μ = ∂F
∂N = kBT ln[N/(VnQ)] = kBT ln[p/(nQkBT)],
ideal gas,
(19.66)
and requires use of the correct partition function. In the second form of this expression,
the quantity pQ := nQkBT ∝T5/2 plays the role of a quantum pressure.
8See Fermi [1, chapter VIII] for an excellent discussion of the entropy of mercury vapor.

Chapter 19 • Canonical Ensemble
317
19.4 Maxwell-Boltzmann Distribution
We can obtain the well-known Maxwell-Boltzmann (MB) distribution function for the
velocities of ideal gas molecules by using Eq. (19.51) in the classical limit
¯h2k2
2m →1
2mv2,
(19.67)
where v2 = v2
x + v2
y + v2
z . By the argument following Eq. (19.50), we note that the ap-
proximate correction factor 1/N! gives equal weighting to every single particle state, so
it can be ignored in calculating the probability density function M(v) for the velocity
v = vxˆi + vyˆj + vz ˆk of a single particle, which takes the form
M(v) = A exp

−mv2
2kBT

.
(19.68)
The constant A is to be chosen by normalization. Speciﬁcally, M(v) d3v is the probability of
a gas molecule having a velocity in the inﬁnitesimal volume element d3v centered about v.
Therefore, the normalization is
1 =

M(v) d3v = 4πA
 ∞
0
v2 exp

−mv2
2kBT

dv = A
2πkBT
m
3/2
,
(19.69)
which leads to
M(v) =

m
2πkBT
3/2
exp

−mv2
2kBT

.
(19.70)
As shown in Section 20.1, Eq. (19.70) can also be obtained by using the classical canonical
ensemble rather than from the classical limit of the quantum mechanical result as
presented here.
Equation (19.70) is sketched as a function of |v| in Figure 19–1a. Note that M(v) is
isotropic, and hence depends only on v, the magnitude of v, which we refer to as the
-3
-2
-1
1
2
3
0.025
0.05
0.075
0.1
0.125
0.15
0.175
(a)
|v|
−|v|
M (v)
0.5
1
1.5
2
2.5
3
0.01
0.02
0.03
0.04
0.05
0.06
(b)
v
˜
M (v)
FIGURE 19–1 Maxwell-Boltzmann distributions for an ideal gas. (a) The velocity distribution, M(v), according to
Eq. (19.70). (b) The speed distribution ˜M(v) according to Eq. (19.75). In both (a) and (b), for the sake of illustration,
the curves with the higher peaks correspond to 2kBT/m = 1 and those with the lower peaks to 2kBT/m = 2, in
arbitrary units.

318
THERMAL PHYSICS
speed. The form on the right-hand side of Eq. (19.70) is known as a normalized Gaussian
distribution. The mean velocity is
⟨v⟩:=

v M(v) d3v =

m
2πkBT
3/2 
v exp

−mv2
2kBT

d3v = 0.
(19.71)
This can be seen by writing v = vxˆi+vyˆj+vz ˆk, v2 = v2
x +v2
y +v2
z , d3v = dvx dvy dvz and doing
the integrals in Cartesian coordinates, viz.,
 ∞
−∞
vx exp

−mv2
x
2kBT

dvx = 0.
(19.72)
The integral vanishes because the integrand is a product of an odd function and an
even function of vx. In fact, the velocity distribution factors into normalized distribution
functions for each Cartesian velocity component:9
M(v) d3v =

i=x,y,z

m
2πkBT
1/2
exp

−mv2
i
2kBT

dvi.
(19.73)
Therefore, the average value of any odd power of a velocity component will vanish. The
mean squared velocity is
⟨v2⟩:=

v2 M(v) d3v
(19.74)
and does not vanish. Since v2 is independent of direction, we can do the integral in
spherical polar coordinates, as we did in Eq. (19.69). To facilitate this approach, we write
the volume element in the form v2 sin  d d dv and integrate over angles to deﬁne the
speed distribution function
˜M(v) :=
 2π
0
d
 π
0
sin  d v2M(v) = 4π

m
2πkBT
3/2
v2 exp

−mv2
2kBT

.
(19.75)
˜M(v) is normalized such that
 ∞
0
˜M(v) dv = 1.
(19.76)
The speed distribution function ˜M(v) is sketched in Figure 19–1b. Note that this function
peaks at a positive value of v because of the v2 that comes from the volume element d3v.
˜M(v) dv is therefore the probability of ﬁnding a particle with speed between v and v +
dv, or alternatively the probability of ﬁnding a particle with velocity in a spherical shell
of inner radius v and outer radius v + dv. Equation (19.74) may therefore be written in
the form
9Given N numbers a1, . . . , aN, their product is denoted by N
j=1aj = a1×a2×· · ·×aN . Note that if α is constant,
this implies that N
j=1αaj = αNN
j=1aj.

Chapter 19 • Canonical Ensemble
319
⟨v2⟩=
 ∞
0
v2 ˜M(v) dv = 4π

m
2πkBT
3/2  ∞
0
v4 exp

−mv2
2kBT

dv = 3kBT
m
.
(19.77)
In view of Eq. (19.73), we have ⟨v2
x ⟩= ⟨v2
y ⟩= ⟨v2
z ⟩= (1/3)⟨v2⟩= kBT/m. According to
Eq. (19.77), the average kinetic energy is
1
2m⟨v2⟩= 3
2kBT.
(19.78)
Equation (19.78) can be interpreted to mean that there is (1/2)kBT of average kinetic
energy associated with each of the translational degrees of freedom in the three Cartesian
(x, y, z) directions, which is consistent with the principle of equipartition of energy which
is valid in the classical limit of high temperatures (see Sections 20.2 and 20.3). The heat
capacity of one mole of an ideal gas would therefore be 3R/2, or about 3 cal/mol. Recall
that the average energy of a one-dimensional harmonic oscillator at high temperature is
kBT; in this case, there is also equipartition of energy, but (1/2)kBT comes from kinetic
energy and (1/2)kBT comes from potential energy. Thus the heat capacity of one mole of a
solid, which behaves as if each atom were a three-dimensional harmonic oscillator, would
be 3R, or about 6 cal/mol at high temperatures.
Example Problem 19.1. Find the average speed of a particle according to the MB
distribution.
Solution 19.1. We use the speed distribution function given by Eq. (19.75) to obtain
⟨v⟩=
 ∞
0
v ˜M(v) dv = 4π

m
2πkBT
3/2  ∞
0
v3 exp

−mv2
2kBT

dv =
8kBT
πm
1/2
.
(19.79)
Although the average velocity vanishes, the average of the always-positive speed does not.
Example Problem 19.2. Find the average speed of a particle that moves only in the x-
direction according to the MB distribution.
Solution 19.2. We integrate over vy and vz the velocity distribution function given by
Eq. (19.73) to obtain
M(vx) dvx =

m
2πkBT
1/2
exp

−mv2
x
2kBT

dvx.
(19.80)
Here, M(vx) is a velocity distribution function for velocity in the x-direction, normalized on the
interval −∞to ∞. The speed in the x-direction is |vx| so its average is
⟨|vx|⟩=
 ∞
−∞
|vx|M(vx) dvx = 2
 ∞
0
vx

m
2πkBT
1/2
exp

−mv2
x
2kBT

dvx.
(19.81)
This is equivalent to using only positive vx and renormalizing. The result for the average speed
in the x-direction is ⟨|vx|⟩=

2kBT/πm
1/2, which is not simply related to the average speed in
three dimensions because v =

v2x + v2y + v2z .

320
THERMAL PHYSICS
19.5 Energy Dispersion
The canonical ensemble is applicable to a system in equilibrium with a heat reservoir such
that its temperature T is the same as that of the reservoir. Therefore, the energy of such a
system is not precisely ﬁxed, even though its average energy ⟨E⟩, which we identify as the
internal energy of thermodynamics U, is known and given by Eq. (19.7). In other words,
the energy of a system held at constant T has some dispersion and can deviate from its
average value, ⟨E⟩=U. Dynamically speaking, we can think of the energy of such a system
as ﬂuctuating in time. This dispersion can be quantiﬁed by calculating higher moments of
the energy with respect to the probabilities given by Eq. (19.6). We proceed to calculate its
second moment relative to its average value, namely
⟨(E)2⟩:= ⟨(E −U)2⟩= ⟨E2 −2EU + U2⟩= ⟨E2⟩−U2,
(19.82)
where
⟨E2⟩=

i
E2
i Pi.
(19.83)
By differentiation of Eq. (19.5), we note that
∂2Z
∂β2 =

i
E2
i exp(−βEi),
(19.84)
which yields
⟨E2⟩= 1
Z
∂2Z
∂β2

N ,V
.
(19.85)
Therefore,
⟨(E)2⟩= 1
Z
∂2Z
∂β2 −1
Z2
∂Z
∂β
2
= ∂2 ln Z
∂β2
= −
∂U
∂β

N ,V
.
(19.86)
Since dT/dβ = −kBT2, this result can also be written
⟨(E)2⟩= kBT2CV ,
(19.87)
where the heat capacity CV = ∂U/∂T.
For a system having a large number N of particles, we can see that this dispersion is
quite small in the following sense. We deﬁne the heat capacity per particle as cV := CV /N
and take the square root of Eq. (19.87) to obtain

⟨(E)2⟩
N
=

kBT2cV
√
N
,
(19.88)
where the expression on the left is a measure of the dispersion of energy per particle.
Typically, cV is of the order of kB, so the right-hand side of Eq. (19.88) is of the order of
kBT/
√
N = 10−11kBT for N = 1022. For example, for a monatomic ideal gas, cV = (3/2)kB
and Eq. (19.88) becomes

Chapter 19 • Canonical Ensemble
321

⟨(E)2⟩
N
=

3/2 kBT
√
N
.
(19.89)
Alternatively for a monatomic ideal gas, we have U = (3/2)NkBT relative to a zero of
energy such that U = 0 when T = 0. In that case, Eq. (19.87) leads to

⟨(E)2⟩
U
=

2/3
1
√
N
.
(19.90)
In any case, as N →∞, there is no dispersion of energy, which is the limit in which
thermodynamics becomes precise. For the microcanonical ensemble, we regard the
energy to be ﬁxed precisely, so the temperature is not precisely deﬁned. Later we shall
consider the grand canonical ensemble, for which even the number of particles of a
system has dispersion about its average value. In the thermodynamic limit, however, this
dispersion also tends to zero.
19.6 Paramagnetism
The phenomenon of paramagnetism pertains to systems that have no net magnetic
moment in the absence of an applied magnetic ﬁeld but acquire a net magnetic moment
in the direction of an applied magnetic ﬁeld. Roughly speaking, it can be thought of as
resulting from the alignment of magnetic dipoles when a magnetic ﬁeld is applied. As
the temperature increases at ﬁxed magnetic ﬁeld strength, entropic effects become more
important, the degree of alignment decreases and the net magnetic moment decreases.
We consider a system having a number of particles N for which the internal energy
U(S, V, B, N) can be expressed as a function of the entropy S, the volume V, and the
magnetic ﬁeld strength10 B. Thus,
dU = T dS −p dV +
∂U
∂B

S,V,N
dB + μ dN.
(19.91)
The differential of the Helmholtz free energy F = U −TS is therefore
dF = −S dT −p dV +
∂U
∂B

S,V,N
dB + μ dN,
(19.92)
from which we see that
∂F
∂B

T,V,N
=
∂U
∂B

S,V,N
.
(19.93)
Accordingly, we deﬁne the net magnetic moment
M := −
∂F
∂B

T,V,N
= −
∂U
∂B

S,V,N
,
(19.94)
10The magnetic ﬁeld is a vector but for simplicity we consider a magnetically isotropic system and represent
the z component of the magnetic ﬁeld by B.

322
THERMAL PHYSICS
which is an extensive thermodynamic quantity. The above differentials therefore become
dU = T dS −p dV −M dB + μ dN;
(19.95)
dF = −S dT −p dV −M dB + μ dN.
(19.96)
B is an intensive variable, so the corresponding Euler equations are U = TS−pV +μN and
F = −pV + μN, which have the same form as in the absence of a magnetic ﬁeld.
One can also employ potentials ˜U := U + BM and ˜F := ˜U −TS = U −TS + BM which
are Legendre transforms of U and F. Then
d ˜U = T dS −p dV + B dM + μ dN;
(19.97)
d ˜F = −S dT −p dV + B dM + μ dN,
(19.98)
with corresponding Euler equations ˜U = TS −pV + BM + μN and ˜F = −pV + BM + μN.
One often treats the special case in which the partition function depends on β and B
only as a product βB, so Z = Q(βB), where Q is some differentiable function. Then
F = −(1/β) ln Q(βB)
(19.99)
from which we readily compute
M = 1
β
∂ln Z
∂B

T,V,N
= Q′(βB)
Q(βB) ;
U = −
 ∂ln Z
∂β

B,V,N
= −Q′(βB)
Q(βB) B.
(19.100)
Here, Q′ is just the derivative of Q with respect to its argument. Thus, in this special case,
we have
M = −U
B ,
(19.101)
which is a ratio rather than a derivative. For more general systems, however, Eq. (19.101)
does not hold and one must compute M by differentiation, according to Eq. (19.94).
Note in this special case that the Legendre transformed potentials ˜U = 0 and ˜F = −TS.
This occurs because the functional form Z = Q(βB) is valid whenever the only relevant
energy levels have energies that are proportional to B. For a more detailed discussion of
energy in magnetic systems, see Callen [2, appendix B], but note that his U is the same as
our ˜U.
19.6.1 Classical Treatment
For historical reasons, we ﬁrst calculate the magnetization by means of classical statistical
mechanics.11 The classical energy of a dipole of magnetic moment µc that makes an angle
θ with a magnetic ﬁeld B is
εθ = −µc · B = −μcB cos θ.
(19.102)
11See Eq. (20.3) and Chapter 20 for details of the classical partition function. For present purposes, we only
need to integrate the relevant Boltzmann factor over angles in phase space and the overall constant is irrelevant.

Chapter 19 • Canonical Ensemble
323
Thus, the classical partition function of a single dipole is
zc = const
 2π
0
dϕ
 π
0
sin θ dθ exp(βμcB cos θ) = const 4π sinh(βμcB)
βμcB
.
(19.103)
Accordingly, for N identical but independent distinguishable dipoles, the total partition
function ZC = zN
c so F = −(N/β) ln zc. Thus
M = N
β
∂
∂B ln sinh(βμcB)
βμcB
= NμcL(xc),
(19.104)
where xc := βμcB and the Langevin function
L(x) := coth x −1/x.
(19.105)
The Langevin function has the properties
L(x) =
⎧
⎪⎪⎨
⎪⎪⎩
x
3 −x3
45 + 2x5
945 + O(x7) x ≪1
1 −1
x + 2 e−2x
x ≫1
(19.106)
and is depicted in Figure 19–2. At very low temperatures or very high magnetic ﬁelds,
xc ≫1 and the magnetic moment saturates at a value M = Nμc. For high temperatures
or very very weak ﬁelds, xc ≪1 and
M ≈Nμ2
c
3kBT B.
(19.107)
The magnetic susceptibility is then given by Curie’s law,
χ := ∂M
∂B = Nμ2
c
3kBT = C
T ,
(19.108)
where C := Nμ2
c/(3kBT) is known as the Curie constant. The fact that χ varies inversely
with T at high temperatures is well known experimentally and enables μc to be deter-
5
10
15
20
0.2
0.4
0.6
0.8
1
µcB/(kBT)
L(xc)
0.5
1
1.5
2
2.5
3
0.2
0.4
0.6
0.8
1
kBT/(µcB)
L(xc)
FIGURE 19–2 The Langevin function L(xc) given by Eq. (19.105) with xc = μcB/(kBT). The plot on the left can
be interpreted as the dimensionless magnetic moment as a function of dimensionless magnetic ﬁeld strength at
constant T. The plot on the right is against 1/xc and can be interpreted as the dimensionless magnetic moment
versus dimensionless temperature at ﬁxed B; it gives incorrect results at small T, including a nonzero slope, because
it does not account properly for quantum effects.

324
THERMAL PHYSICS
mined. From the quantum mechanical treatment to follow, we shall see that the Langevin
function gives incorrect answers at low temperatures, so the saturation magnetic moment
Nμc and the shape of the curve at low temperatures are incorrect.
19.6.2 Quantum Treatment
For an atom12 in a uniform magnetic ﬁeld B along the z-axis, the part of the Hamiltonian
that depends on B can be written in Gaussian units in the form13
H′
B =
e¯h
2mc (L + 2S) · B + e2B2
8mc2

i
(x2
i + y2
i ),
(19.109)
where e is the magnitude of the charge on the electron, c is the speed of light, L is the
total orbital angular momentum, and S is the total spin angular momentum. Both angular
momenta are measured in units of ¯h and are therefore dimensionless. The sum on i is over
all electrons. The term in B2 contributes to diamagnetism, but here we deal only the linear
term in B, which is usually written in the form
HB = μB(L + 2S) · B,
(19.110)
where the quantity μB := e¯h/(2mc) is known as the Bohr magneton.14 Furthermore, we
shall conﬁne our treatment to cases for which the only important states of the atom are its
ground states that are degenerate in the absence of a magnetic ﬁeld and are eigenstates of
the operators ˆL2, ˆS2, ˆJ2, and ˆJz, where ˆJ = ˆL + ˆS. Such states |LSJM⟩satisfy the relations
ˆL2|LSJM⟩= L(L + 1)|LSJM⟩;
ˆJ2|LSJM⟩= J(J + 1)|LSJM⟩
ˆS2|LSJM⟩= S(S + 1)|LSJM⟩;
ˆJz|LSJM⟩= M|LSJM⟩
(19.111)
and have a degeneracy of 2J + 1 because M = −J, −J + 1, . . . , J −1, J. Based on addition
theorems for angular momenta,15 one can show that
⟨LSJM′|ˆLz + 2ˆSz|LSJM⟩= gM δMM′,
(19.112)
where
g := 3
2 + 1
2
S(S + 1) −L(L + 1)
J(J + 1)

(19.113)
12We use the word atom but we will frequently actually treat an ion in some crystal. For example, the rare
earth elements (atomic numbers 58-71) have similar chemistry governed by a pair of 6s valence electrons. They
form salts that contain rare earth ions, each having from 1 to 14 electrons in their inner f -shells. These ions have
net magnetic moments that can be aligned by a magnetic ﬁeld. For a table summarizing details, see Ashcroft and
Mermin [58, p. 652]. For an extensive discussion, see van Vleck [100, p. 228].
13For a derivation, see [58, p. 646]. To covert to SI units, replace eB/c by eB. The g-factor for spin, which is
approximately 2.0023, has been taken to be exactly 2 for simplicity.
14μB = 9.274 × 10−21 erg/gauss. In SI units, μB = e¯h/2m = 9.274 × 10−24 joule/tesla.
15The proof is based on the Wigner-Eckart theorem which leads to operator equivalents [59, p. 707]. For a
thorough discussion of the allowable ground states and examples of ions having partially ﬁlled d- or f -shells that
can be treated by Hund’s rules, see Ashcroft and Mermin [58, p. 650].

Chapter 19 • Canonical Ensemble
325
is known as the Lande g-factor. In fact, within the subspace of such states having the same
values of L, S, J, and M, one has the operator equivalence
ˆL + 2ˆS = gˆJ
(19.114)
for all vector components. Therefore, one can deﬁne a magnetic moment operator
ˆµ := −μBgˆJ
(19.115)
in terms of which the Hamiltonian
ˆHB = −ˆµ · B,
(19.116)
which resembles the classical expression for the energy of a dipole of magnetic moment µ
in a magnetic ﬁeld B. For a magnetic ﬁeld along the z-axis, we therefore have
ˆHB|LSJM⟩= μBgMB|LSJM⟩,
(19.117)
so the J(J + 1) degenerate16 states for zero magnetic ﬁeld are split into states having
energies μBgBM that are equally spaced.
The canonical partition function for a single atom is therefore
z =
J

M=−J
exp(βμBgBM) =
J

M=−J
[ex/J]M,
(19.118)
where x = βμBgBJ. The variable x is equal to βB times the maximum eigenvalue μBgJ of the
magnetic moment operator ˆμz. We shall see that x plays almost the same role as xc in the
classical treatment, but they are somewhat different. The geometric series in Eq. (19.118)
can be readily summed to yield
z = sinh

x

1 + 1
2J
 
sinh
 x
2J

.
(19.119)
From the total partition function Z = zN and Eq. (19.100), we readily compute
M = NμBgJBJ(x),
(19.120)
where
BJ(x) =

1 + 1
2J

coth

x

1 + 1
2J

−
 1
2J

coth
 x
2J

;
J ̸= 0,
(19.121)
is called the Brillouin function. It is depicted in Figure 19–3 and has the following
properties:
16For the special case J = 0, one has no degeneracy, M = 0 and there is no ﬁrst-order effect of a magnetic
ﬁeld. In that case, the ground state has no magnetic moment and one must consider interaction with excited
states as well as the second-order term in Eq. (19.109).

326
THERMAL PHYSICS
5
10
15
20
0.2
0.4
0.6
0.8
1
µBgJB/(kBT )
BJ(x)
BJ(x)
1
2
3
4
5
0.2
0.4
0.6
0.8
1
kBT/(µBgJB)
FIGURE 19–3 The Brillouin function BJ(x) given by Eq. (19.121) with x = μBgJB/(kBT). From the top down, the
curves are for J = 1/2, J = 1, and J = 2. The bottom curve is the Langevin function L(x). The plot on the left can
be interpreted as the dimensionless magnetic moment as a function of dimensionless magnetic ﬁeld strength at
constant T. The plot on the right is against 1/x and can be thought of as the dimensionless magnetic moment versus
dimensionless temperature at ﬁxed B. Note that the Brillouin function versus T has zero slope at T = 0 because
quantum effects result in a very small population of the ﬁrst excited state at low temperatures.
BJ(x) = 1
3

1 + 1
J

x −1
45

1 + 2
J +
3
2J2 + 1
2J3

x3 + O(x5);
x ≪1,
(19.122)
BJ(x) = 1 −1
J exp(−x/J);
x ≫1 with J ﬁnite,
(19.123)
BJ(x) = L(x);
J →∞with x ﬁnite.
(19.124)
For high temperatures, Eq. (19.122) is valid and the ﬁrst term gives
M = Nμ2
Bg2J(J + 1)
3kBT
B.
(19.125)
Comparison with Eq. (19.107) for the classical treatment gives the correspondence
μc = μBg

J(J + 1).
(19.126)
Equation (19.126) is the correct relationship between the quantum mechanical treatment
and the classical treatment because the latter is only valid at high temperatures. It leads to
the correspondence
xc = x

(J + 1)/J.
(19.127)
It would be incorrect to make a comparison by matching the saturation magnetic mo-
ments at low temperatures and high magnetic ﬁeld strengths, in which case both x and
xc become very large, because the classical treatment is not valid under those conditions.
The saturation magnetic moment for the quantum treatment is NμBgJ whereas for the
classical treatment it is Nμc. By using Eq. (19.126), we see that Nμc is a factor of √(J + 1)/J
larger than the quantum mechanical value NμBgJ.
We can make a comparison between quantum results and classical results as follows.
We ﬁx the value of μc and choose the product g√J(J + 1) so that Eq. (19.126) is satisﬁed.

Chapter 19 • Canonical Ensemble
327
0.2
0.4
0.6
0.8
1
1.2
1.4
0.2
0.4
0.6
0.8
1
M/(Nµc)
kBT/µcB
FIGURE 19–4 Comparison of quantum and classical results under the constraint that both agree at high tempera-
tures. The top curve is the Langevin function L(xc). The other curves are calculated from the Brillouin function in the
form of Eq. (19.128). From the bottom up, they correspond to J = 1/2, 1, 2, 4. The respective saturation values for
the quantum results are

J/(J + 1) = 0.57735, 0.707107,0.816497,0.894427.
This will make quantum and classical results agree for high temperatures. Then x will be
related to xc by Eq. (19.127), which allows Eq. (19.120) to be written
M = Nμc

J/(J + 1)BJ

xc

J/(J + 1)

.
(19.128)
Figure 19–4 shows a plot of M/Nμc versus 1/xc = kBT/(μcB) for the classical result
(Langevin function) and for quantum results for several values of J. For ﬁxed high tem-
perature moment μc, we see that the quantum results saturate at smaller values than the
classical result, the smallest occurring for J = 1/2. Of course the actual quantum saturation
values are
M∗= NμBgJ = NμB
3J
2 + 1
2
S(S + 1) −L(L + 1)
J + 1

,
(19.129)
where Eq. (19.113) has been used, so one should take great care in discussing general
trends with J.
19.6.3 Properties of Paramagnetic Systems
We digress here to explore some useful properties of the paramagnetic system treated in
Section 19.6.2 that are not necessarily obvious. The ﬁrst concerns the sign of the magnetic
moment M. From Eq. (19.101), we see for this particular model that M = −U/B so M
has the opposite sign of the internal energy U. In general, the internal energy is undeﬁned
up to an additive constant, so it can be positive or negative, but Eq. (19.101) is only true
because the partition function depends on B and β only in the combination y = Bβ, as

328
THERMAL PHYSICS
in Eq. (19.99). This arises because the energies of the states given by Eq. (19.117) are of
the form εi = aiB such that for every value of i there is also a state with energy εi = −aiB.
Therefore, the partition function for a single particle can be written the form
z =

i
eβaiB = 1
2

i
(eβaiB + e−βaiB) =

i
cosh(aiy).
(19.130)
Thus,
U = −N ∂
∂β ln z = −N
z

i
ai tanh(aiy)B ≤0
(19.131)
and it follows that M ≥0 with the equal sign corresponding to B = 0 or T = ∞.
Next, we turn to the magnetic susceptibility χ = ∂M/∂B and show that χ ≥0. We could
do this for the speciﬁc model of Section 19.6.2 but instead we proceed to derive a more
general relation that is even more interesting. We consider a many-particle system with
Hamiltonian H and deﬁne a total magnetic moment operator ˆM = −∂H/∂B = Nμz. For
clarity, we now denote the magnetic moment itself by ⟨ˆM⟩, which is the thermal average of
ˆM in the canonical ensemble. Then it follows that
tr[e−βH( ˆM −⟨ˆM⟩)]
tr[e−βH]
= ⟨ˆM −⟨ˆM⟩⟩= 0.
(19.132)
Here, to achieve more generality, we have used the trace, denoted by tr, to write thermal
averages in an invariant form whereas until now we have used only the energy representa-
tion (see Chapter 26 for more detail). We now differentiate the numerator of the ﬁrst term
in Eq. (19.132) with respect to B to obtain
∂
∂Btr[e−βH( ˆM −⟨ˆM⟩)] = tr[e−βHβ ˆM( ˆM −⟨ˆM⟩) −e−βH∂⟨ˆM⟩/∂B] = 0.
(19.133)
We then divide by tr[e−βH] and recognize ∂⟨ˆM⟩/∂B = χ, the susceptibility, to obtain
⟨ˆM2⟩−⟨ˆM⟩2 = χ/β,
(19.134)
where ⟨ˆM2⟩denotes the thermal average of
ˆM2. But we know that ⟨ˆM2⟩−⟨ˆM⟩2 =
⟨( ˆM −⟨ˆM⟩)2⟩, which leads to
χ/β = ⟨( ˆM −⟨ˆM⟩)2⟩> 0.
(19.135)
Thus the susceptibility χ is positive at any ﬁnite temperature. We note the similarity of
Eqs. (19.87)–(19.135) for the heat capacity in terms of the dispersion of energy, which
could have been derived in the same way. One subtle difference, however, is that the
Hamiltonian always commutes with itself but there could be cases for which parts of the
Hamiltonian do not commute with the magnetic moment operator, in which case the
above derivation would not hold. We remark that for the special case we have been treating
for which M ≡⟨ˆM⟩depends only on y = Bβ, Eq. (19.135) becomes
dM
dy = ⟨( ˆM −M)2⟩> 0.
(19.136)

Chapter 19 • Canonical Ensemble
329
Finally, we shall show for the model of Section 19.6.2 that the entropy S is a mono-
tonically increasing function of 1/y = kBT/B. To do this, we substitute U = −MB into
Eq. (19.95) at constant V and N to obtain
−d(MB) = T dS −M dB,
(19.137)
which yields
dS/kB = −y dM = −y dM
dy dy = y3 dM
dy d(1/y).
(19.138)
From Eq. (19.136) we see that the coefﬁcient of d(1/y) in Eq. (19.138) is positive, so S is
a monotonically increasing function of 1/y = kBT/B. This result will be used in the next
section.
19.6.4 Adiabatic Demagnetization
Adiabatic demagnetization is an experimental technique that can be used to cool mag-
netic samples to extremely low temperatures. A sample is ﬁrst cooled and maintained at
a very low temperature T0, for example, by contact with liquid helium, while an extremely
strong magnetic ﬁeld B0 is applied. Then the sample is thermally insulated and the
magnetic ﬁeld is slowly and carefully lowered to as small a value as possible,17 say BE.
As we shall show subsequently, the temperature of the sample will be lowered to
TE = T0 BE/B0.
(19.139)
This simple result can be understood by examining the entropy S of the sample. Since
S = (U −F)/T, we can use Eqs. (19.99) and (19.100) to obtain
S/kB = ln Q(βB) −(βB)Q′(βB)/Q(βB).
(19.140)
The entropy is therefore only a function of the product βB, or for our purposes the
ratio T/B. The stage of the process in which the sample is thermally insulated and the
magnetic ﬁeld is slowly and carefully lowered is adiabatic and practically reversible,
so it is approximately isentropic, that is, S = constant. If T/B is constant, then surely
S will be constant. In Section 19.6.3, however, we showed that S is a monotonically
increasing function of 1/y = kBT/B. Therefore, if S is constant, T/B will also be constant
and Eq. (19.139) follows.
We can gain more insight by examining the details of a simple case. For example, for
the case J = 1/2, Eq. (19.119) simpliﬁes to z = 2 cosh x and Eq. (19.140) yields
S/(NkB) = ln(2 cosh x) −x tanh x
(19.141)
as illustrated in Figure 19–5. Results for other values of J are qualitatively similar. During
reversible adiabatic demagnetization from the point 0, the dimensionless entropy would
remain at the value 0.6 and the temperature would drop in proportion to the ﬁeld strength.
17The lowest possible ﬁeld BE will probably be the order of the magnetic ﬁeld of the Earth, about 0.5
gauss = 5 × 10−5 tesla.

330
THERMAL PHYSICS
0.5
1
1.5
2
2.5
3
0.1
0.2
0.3
0.4
0.5
0.6
0.7
S/(NkB)
2kBT/(µBgB0)
E
I
0
FIGURE 19–5 Entropy as a function of temperature for J = 1/2. From right to left, the curves are for B = B0, B0/2,
and B0/10. For sufﬁciently high T, all curves would saturate at ln 2 = 0.693. In a hypothetical process of adiabatic
demagnetization, suppose that the sample were magnetized in a strong ﬁeld B0 at temperature T0, so that it is
represented by the point 0 which has dimensionless entropy 0.6. If the sample were now insulated and reversibly
demagnetized isentropically to the point I, its temperature would become T0/2. If the isentropic demagnetization
were continued to the point E, its temperature would become T0/10.
One might wonder how the temperature of the system could drop without extracting
heat. The answer to this mystery lies in the initial stage of the process wherein the system
is magnetized by applying the high ﬁeld B0. If the cooling ﬂuid is able to maintain the
system at temperature T0 throughout this process, and if the process is reversible, an
amount of heat |Q| = −T0S would be extracted from the system. We know that S < 0
because S increases with T at ﬁxed B and therefore S decreases with B at ﬁxed T. If the
initial magnetization process is not reversible, even more heat would have to be extracted.
Similarly, if the demagnetization process is not quite reversible, the entropy of the system
will go up slightly and one will achieve a ﬁnal temperature slightly higher than that
calculated for the reversible process.
19.7 Partition Function and Density of States
Under suitable circumstances, the energy levels of the quantum states of a system can
be treated as quasi-continuous. Speciﬁcally, the spacing between levels must be small
compared to kBT, which is often possible for large systems if the temperature is not too
low. Under those circumstances, the sum over states that is used to calculate the partition
function, namely18
Z(β) =

j
exp(−βEj),
(19.142)
18Z will generally depend on other parameters such as the volume V but we suppress these variables for
simplicity.

Chapter 19 • Canonical Ensemble
331
can be approximated by an integral of the form
Z(β) =
 ∞
0
e−βE D(E) dE,
(19.143)
where D(E) is known as the density of states and accounts for the spacing and degeneracy
of the quantum states. Speciﬁcally, D(E) is a distribution function such that D(E) dE is the
number of quantum states in the energy interval between E and E +dE. Equation (19.143)
has the same form as a Laplace transform with transform variable β. Therefore, one can
use the Laplace inversion formula
D(E) =
1
2πi

Br
eβEZ(β) dβ
(19.144)
to compute D(E) from a knowledge of Z(β). In Eq. (19.144), β is regarded as a complex vari-
able and the integration is over a contour Br in the complex plane known as the Bromwich
contour. This contour starts out at β = −i∞, goes to the right of all singularities19 of Z(β)
and ends up at β = i∞. One can use Cauchy’s theorem to deform the contour and thus
calculate D(E) by standard methods of contour integration.
Example Problem 19.3. Calculate the Laplace transform Z(β) of the partition function for N
atoms of a monotonic ideal gas to determine its density of states D(E) and relate D(E) to the
corresponding function (E) of the microcanonical ensemble.
Solution 19.3. By combining Eq. (19.48) with Eq. (19.56), we see that the partition function
for N atoms of a monatomic ideal gas is given by
Z(β) = (VnQ)N
N!
= V N
N!

m
2π¯h2β
3N /2
.
(19.145)
Thus,
D(E) = V N
N!

m
2π¯h2
3N /2
1
2πi

Br
eβE
β3N /2 dβ.
(19.146)
The integrand certainly has a singularity at β = 0 but if N is an odd integer, one also needs a
branch cut, usually taken from β = 0 to β = −∞along the real axis to make it analytic. But N
is large so we do not really care if it is odd or even. Therefore, we temporarily pretend that it is
even, in which case the integrand has a pole of order 3N/2 at the origin. We can therefore close
the contour in the left half plane and apply Cauchy’s theorem to shrink the contour to a small
circle around β = 0. The result of integration is then well known to be

Br
eβE
β3N /2 dβ = 2πi Residue
 eβE
β3N /2

= 2πi
E3N /2−1
(3N/2 −1)!,
(19.147)
where Residue means to extract the coefﬁcient of 1/β. Thus,
D(E) =
V N
N!(3N/2 −1)!
 mE
2π¯h2
3N /2 1
E .
(19.148)
19Such singularities are poles where Z(β) becomes inﬁnite or branch cuts needed to make it single-valued.

332
THERMAL PHYSICS
We note that D(E) has dimensions of 1/E so that D(E)dE is dimensionless, as a probability
should be. In the present case, we can easily check our result because Eq. (16.44) gives
an expression for , which is the total number of microstates having energies less than E.
Differentiation with respect to E shows that (∂/∂E)N ,V = D(E) as it should (see Eq. (19.154)
for more detail).
Note that Eq. (19.148) can be written in terms of the gamma function in the form
D(E) =
V N
N!(3N/2)
 mE
2π¯h2
3N /2 1
E .
(19.149)
Of course (3N/2) makes sense even when 3N/2 is a half integer, so we suspect that Eq. (19.149)
might hold in general. Substitution into Eq. (19.143) shows that this conjecture is true.
We remark that this same Laplace transform relationship holds between the density of
states D1(ε) of a single particle and its partition function z(β). Thus for an ideal gas,
z(β) = VnQ = V

m
2π¯h2β
3/2
,
(19.150)
so
D1(ε) =
V
(3/2)

 mε
2π¯h2
3/2 1
ε =
V
(1/2)π1/2

 mε
2π¯h2
3/2 1
ε ,
no spin degeneracy,
(19.151)
where we have used (x + 1) = x(x) and (1/2) = π1/2. This result is the same as the
density of states G(ε)/2 given by Eq. (25.13), where the division by 2 is necessary because
G(ε) contains a factor of 2 due to spin degeneracy. Since D1(ε) is proportional to V, one
often deals with the intensive quantity
D1(ε)
V
=
1
(1/2)π1/2

 mε
2π¯h2
3/2 1
ε ,
(19.152)
which is also called the density of states and has units of (volume energy)−1. One must
therefore be careful to ascertain from the context just what density of states is being used!
Strictly speaking, one should have D(E) = (1/N!) ∂VR/∂E, where VR given by Eq. (16.39)
is the total number of microstates for all energies ≤E. But (1/N!) VR = (E)/F, where F
is given by Eq. (16.40). Therefore,
D(E) = ∂(/F)
∂E
= 1
F
∂
∂E + 
F2
3NE
2E2
exp

−3NE
2E

.
(19.153)
The second term in Eq. (19.153) is negligible compared to the ﬁrst (because of the
exponential) and F ≈1, so
D(E) ≈∂(E)
∂E
(19.154)
to an excellent approximation.

Chapter 19 • Canonical Ensemble
333
Finally, we make one more connection between the microcanonical ensemble and the
canonical ensemble as follows. For the microcanonical ensemble, we have S = kB ln (E);
however, for the canonical ensemble
S = U −F
T
= kB

ln Z +
U
kBT

= kB ln

Z eU/kBT
.
(19.155)
If E and U are nearly the same, we should have
ln((E)) ∼ln( ˜(U)) ≡ln(Z eU/kBT).
(19.156)
However, Eq. (19.156) must be interpreted very carefully because the systems being
compared are not quite the same. (E) relates to the microcanonical ensemble
for which the energy E of each microstate is speciﬁed, whereas
˜(U) relates to
the canonical ensemble for which the temperature is speciﬁed, so only the average
energy U(T) is speciﬁed. Therefore, if we exponentiate both sides of Eq. (19.156) we
obtain
(E) ∼˜(U) ≡Z eU/kBT,
(19.157)
which only holds to the extent that ln (E) ∼ln ˜(U) when sub-extensive terms are
neglected.
For example, for an ideal gas, for which U = (3/2)NkBT, we have
˜(U) = 1
N!V N

mU
3π¯h2N
3N /2
e3N /2.
(19.158)
According to Eq. (16.44), we have
(E) = V N (mE/2π¯h2)3N /2
N!(3N/2)!
.
(19.159)
We observe that the factors that multiply U3N /2 and E3N /2 are not quite the same, but
since N is large we can use (3N/2)! ∼N 3N /2 e−3N /2√
3πN to write Eq. (19.158) in the
form
˜(U) ∼
√
3πN V N (mU/2π¯h2)3N /2
N!(3N/2)!
.
(19.160)
Thus, in the thermodynamic limit of extremely large N, we have
ln ˜(U) = ln (E) + (1/2) ln(3πN)
(19.161)
in which the last term is sub-extensive, and therefore negligible. It is also illuminating to
use Eq. (19.148) with E →U to express ˜(U) in terms of the density of states evaluated at
energy U, which results in
˜(U) ∼
√
2π
U
√3N/2 D(U) =
√
2π

3N/2 kBT D(U).
(19.162)

334
THERMAL PHYSICS
In view of Eq. (19.89), we recognize the factor √3N/2 kBT =

⟨(E)2⟩to be a measure of
the spread of energy at temperature T. Thus Eq. (19.162) can be written
˜(U) ∼
√
2π

⟨(E)2⟩D(U),
(19.163)
which demonstrates clearly that the density of states D(U) must be multiplied by the
spread of energy to approximate the number of microstates ˜(U).
For a single ideal gas particle, the correspondence implied by Eq. (19.157) would give
1(ε) ∼z exp(⟨ε⟩/kBT) = z e3/2,
(19.164)
which illustrates that z is essentially a measure of the number of states available to an
individual particle at temperature T.
Another way of evaluating ˜ in Eq. (19.157) is to evaluate approximately the partition
function
Z =
 ∞
0
D(E) e−βE dE =
 ∞
0
e[−βE+ln D(E)] dE
(19.165)
by expanding about the most probable state. To do this, we recognize that D(E) is a rapidly
increasing function of E and e−βE is a rapidly decreasing function of E. Thus the integrand
has a sharp maximum at the most probable value E∗that satisﬁes
0 = ∂
∂E [−βE + ln D(E)]E∗= −β + [ln D(E∗)]′,
(19.166)
where the prime indicates a derivative. We can therefore expand the exponent in the right-
hand integrand in Eq. (19.165) to second order to obtain
−βE + ln D(E) = −βE∗+ ln D(E∗) −(1/2)α(E −E∗)2 + · · · ,
(19.167)
where
α := −[ln D(E∗)]′′ > 0
(19.168)
is positive because E∗corresponds to a sharp maximum. Thus with ξ = E −E∗,
Z ≈D(E∗) e−βE∗ ∞
−E∗e−(α/2)ξ2 dξ ≈
√
2π 1
√α D(E∗) e−βE∗,
(19.169)
where the lower limit in the second integral has been approximated by −∞because the
peak is so sharp. See Widom [17, Eq. 1.25] for an equivalent result with his δE = √2/α. Thus
˜ ∼
√
2π 1
√α D(E∗) e−β(E∗−U).
(19.170)
But the difference20 between E∗and U is of order kBT, so the exponential in Eq. (19.170)
gives a numerical factor of order 1 and the result greatly resembles Eq. (19.162).
20In this Gaussian approximation, there is negligible difference between E∗and U if the lower limit of the
integral in Eq. (19.169) can be approximated by −∞.

Chapter 19 • Canonical Ensemble
335
Speciﬁcally for a monatomic ideal gas, Eq. (19.148) shows that D(E) = AE3N /2−1 so
E∗= (3N/2 −1)kBT and α = (3N/2 −1)/(E∗)2. Since U = (3N/2)kBT, Eq. (19.170) becomes
˜ ∼
√
2π
E∗
√3N/2 −1D(E∗) e =
√
2π
U
√3N/2 −1D(U) e (E∗/U)3N /2.
(19.171)
But
(E∗/U)3N /2 =
3N/2 −1
3N/2
3N /2
=

1 −
2
3N
3N /2
∼

e−2/3N 3N /2
= e−1.
(19.172)
Therefore, Eq. (19.170) reduces to
˜ ∼
√
2π
U
√3N/2 −1D(U) =
√
2π

⟨(E)2⟩D(U),
(19.173)
in excellent agreement with Eq. (19.163) because the 1 in the square root is negligible.

This page intentionally left blank 

20
Classical Canonical Ensemble
For the canonical ensemble,1 the temperature rather than the energy is ﬁxed. Therefore,
the members of the ensemble have various energies. Members of the ensemble having a
given energy must still obey the Liouville theorem and hence Eq. (17.11). This possibility
can be accommodated by choosing the density ρ in phase space to be some function of
the classical Hamiltonian H, in which case Eq. (17.11) becomes
{ρ(H), H} = dρ
dH{H, H} = 0.
(20.1)
Proceeding with the same arguments as in the quantum mechanical case, it can be
inferred for a system in contact with a heat reservoir at temperature T that the probability
of a system having energy E is proportional to the Boltzmann factor exp(−βE), where
β = 1/(kBT) as usual. Since H = E for such a system, the appropriate probability
distribution function is
P(p, q) := exp[−β H(p, q)]
ZC
,
(20.2)
where where p and q are 3N-dimensional vectors representing the canonical momenta
and coordinates, respectively. The function
ZC :=

exp[−β H(p, q)] dω,
(20.3)
where dω ≡d3N p d3N q and the integration is over all phase space. P(p, q) dω is the
probability that the system will be in the volume element dω of phase space centered
about the point p, q. The factor ZC in the denominator of Eq. (20.2) is needed to insure
normalization, that is,

P(p, q) dω = 1.
(20.4)
If Y (p, q) is some function of p and q, then the average value of Y is
⟨Y⟩:=

Y(p, q) P(p, q) dω.
(20.5)
1Those interested in the historical development of classical statistical mechanics are encouraged to read the
original work of J.W. Gibbs [4]. Based on Hamilton’s classical dynamical equations that we discussed in Chapter
17, Gibbs developed the classical canonical ensemble in Chapter IV, the microcanonical ensemble in Chapter X,
and the grand canonical ensemble in Chapter XV. The integral form of Liouville’s theorem that we presented in
Section 17.1 is what Gibbs called the “conservation of probability of phase.” If ρ = eη is the probability density
function in phase space, Gibbs called η the “index of probability.” Then he referred to a “canonical distribution”
as one in which the index of probability is a linear function of the energy.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00020-X
337
Copyright © 2015 Elsevier Inc. All rights reserved.

338
THERMAL PHYSICS
Comparison of Eqs. (20.2) and (20.3) with Eqs. (19.5) and (19.6) shows that the function
ZC plays the role of a classical partition function. In fact, the formula Eq. (19.7) for the
average internal energy has exactly the same form in the classical case. Thus,
U := ⟨H⟩=

H(p, q) P(p, q) dω = −1
ZC
∂ZC
∂β
= −∂ln ZC
∂β
.
(20.6)
But in some other respects, the correspondence of ZC with the quantum mechanical parti-
tion function is incorrect. Unlike the quantum partition function, ZC is not dimensionless
and does not account for the number of quantum states that need to be associated with
a volume of phase space. For N identical particles that occupy the same volume, one can
deﬁne a dimensionless classical partition function
Z∗
C := ZC
ω0
= 1
ω0

exp[−β H(p, q)] dω.
(20.7)
The factor ω0 is the same factor as in Eq. (17.14) that allows us to convert from volume
of phase space to microscopic states. For identical distinguishable particles we have ω0 =
h3N and for identical indistinguishable classical particles we have approximately ω0 =
h3N N!. In other words, dω has been replaced by the dimensionless quantity dω/ω0, which
is the differential of the number of microscopic states. Doing this gives rise to the correct
entropy constant at high temperatures, where classical statistics are valid approximately.
In this respect, we could view Eq. (20.2) in the form
P(p, q) dω = exp[−β H(p, q)]
Z∗
C
dω
ω0

.
(20.8)
In this manner, we can also relate properly to the Helmholtz free energy, namely
F = −kBT log Z∗
C,
(20.9)
and the entropy will be correctly given by
S = −∂F
∂T .
(20.10)
20.1 Classical Ideal Gas
To illustrate the classical canonical ensemble, we shall treat a classical ideal gas and re-
derive the Maxwell-Boltzmann distribution function. The Hamiltonian is
H =
3N

i=1
p2
i
2m
(20.11)
for N particles of mass m. The pi are just the Cartesian momenta of the particles. We
can use Eq. (20.2) to calculate the average value of some function f (v1) = f (p1/m) of the
velocity of particle number 1, resulting in
⟨f (v1)⟩=

f (p1/m) P(p, q) dω =

f (p1/m) exp[−β H(p, q)]
ZC
d3N p d3N q.
(20.12)

Chapter 20 • Classical Canonical Ensemble
339
In Eq. (20.12), all integrals relating to q and to particles other than particle number 1 cancel
with the corresponding factors in ZC. We therefore obtain
⟨f (v1)⟩=

f (p1/m) exp[−β p2
1/2m] d3p1

exp[−β p2
1/2m] d3p1
=

f (v1) exp[−β mv2
1 /2] d3v1

exp[−β mv2
1 /2] d3v1
.
(20.13)
The denominator on the right-hand side can be evaluated to give

exp[−β mv2
1 /2] d3v1 =
2πkBT
m
3/2
.
(20.14)
Thus
⟨f (v1)⟩=

m
2πkBT
3/2  ∞
−∞
f (v1) exp[−β mv2
1 /2] d3v1.
(20.15)
A similar result would be obtained for any other particle since they are all equivalent. The
normalized distribution function for the velocity v of any particle is therefore
M(v) =

m
2πkBT
3/2
exp[−mv2/2kBT],
(20.16)
in agreement with Eq. (19.70) and known as the Maxwell-Boltzmann distribution
function.
Note that Eq. (20.16) can be factored into normalized distributions for each Cartesian
component by writing v2 = v2
x + v2
y + v2
z and apportioning the normalization factor,
resulting in
M(v) =

i=x,y,z

m
2πkBT
1/2
exp[−mv2
i /2kBT],
(20.17)
which is the same as Eq. (19.73).
Example Problem 20.1. Find the distribution function for the speed v⊥for motion perpen-
dicular to the z-axis.
Solution 20.1. First, we calculate the distribution function for velocity v⊥perpendicular to
the z-axis by integrating M(v) over vz, which we no longer care about. This gives
M(v⊥) =
 ∞
−∞
M(v) dvz =

i=x,y

m
2πkBT
1/2
exp[−mv2
i /2kBT].
(20.18)
Then we go to polar coordinates so that vx = v⊥cos φ and vy = v⊥sin φ to obtain
M(v⊥) dvx dvy =

m
2πkBT

exp[−mv2
⊥/2kBT] dφ v⊥dv⊥.
(20.19)
Next we integrate on φ from 0 to 2π to get the speed distribution function
ˇM(v⊥) =
 m
kBT

exp[−mv2
⊥/2kBT] v⊥.
(20.20)

340
THERMAL PHYSICS
Thus the average speed for motion perpendicular to the z-axis is
⟨v⊥⟩=
 ∞
0
ˇM(v⊥)v⊥dv⊥=
 ∞
0
 m
kBT

exp[−mv2
⊥/2kBT] v2
⊥dv⊥=
πkBT
2m
1/2
.
(20.21)
We can also evaluate the partition function Z∗
C by substitution of Eq. (20.11) into
Eq. (20.7). The integral over q just gives a factor of V N and the integral over p can be
performed in Cartesian coordinates, resulting in
Z∗
C =
V N
h3N N!

exp[−βp2/(2m)] dp
	3N
=
V N
h3N N!

2πmkBT
3N /2 .
(20.22)
To evaluate ln Z∗
C, we use Stirling’s approximation for ln N! to obtain
ln Z∗
C = N ln(V /N) + N ln nQ + N,
(20.23)
where the quantum concentration
nQ =
2πmkBT
h2
3/2
=
mkBT
2π¯h2
3/2
.
(20.24)
Equations (20.23) and (20.24) are the same as Eqs. (19.57) and (19.60) derived from
quantum statistical mechanics in the high temperature limit. For high temperatures, the
resulting thermodynamic functions are therefore the same as derived in Chapter 19.
20.1.1 Effusion of an Ideal Classical Gas
The slow leaking of a gas through a small hole in a box containing the gas is a process
known as effusion. The hole is assumed to be so small that the gas inside the box
can be assumed to be practically in equilibrium at each instant of time, as described
by the Maxwell-Boltzmann velocity distribution function M(v) given by Eq. (20.16). For
convenience, we treat a monatomic gas and assume that the hole has an area a in a plane
perpendicular to the z-axis. Let J be the ﬂux of gas atoms that exit the hole; J has units
of atoms/(area time) so that Ja dt is the number of atoms that effuse (exit the box) in an
inﬁnitesimal time dt. These atoms can have any values of vx and vy but they must have
vz > 0. In an inﬁnitesimal time dt, atoms in a rectangular parallelepiped of volume avz dt
will exit. Thus if n is the number density of the gas, the ﬂux will be given by
J = n
 ∞
−∞
dvx
 ∞
−∞
dvy
 ∞
0
dvz vzM(v).
(20.25)
We now transform to spherical coordinates for which the volume element is v2 sin θ dϕ dθ dv
and also write vz = v cos θ. This gives
J = n
 2π
0
dϕ
 ∞
0
dv v2
 π/2
0
dθ v cos θ sin θM(v).
(20.26)
Since M(v) depends only on v2 and is therefore independent of θ and ϕ, the trigonometric
integrals give factors of 2π and 1/2. We therefore obtain

Chapter 20 • Classical Canonical Ensemble
341
J = nπ
 ∞
0
dv v3M(v) = n
4
 ∞
0
dv v 4πv2M(v) = n
4
 ∞
0
dv v ˜M(v),
(20.27)
where ˜M(v) = 4πv2M(v) is the speed distribution function given by Eq. (19.75). We
readily compute J = n(kBT/2πm)1/2. This result could have been obtained more easily
by just evaluating Eq. (20.25) in Cartesian coordinates, but the weighting of the speed in
Eq. (20.27) would hold for any gas (e.g., an ultra-relativistic gas) for which M(v) depends
only on |v|, as pointed out by Pathria [8, p. 139].
A similar calculation can be used to obtain an expression for the pressure of the gas.
Instead of effusing, each gas atom that strikes an area a of a closed box will rebound and
have the z-component of its momentum reversed.2 This requires the wall of the box to
exert a force 2mvz. Therefore, the pressure is given by
p = n
 ∞
−∞
dvx
 ∞
−∞
dvy
 ∞
0
dvz vz2mvzM(v).
(20.28)
Converting to polar coordinates as above gives
p = n
 2π
0
dϕ
 ∞
0
dv v2
 π/2
0
dθ 2mv2 cos2 θ sin θM(v).
(20.29)
Therefore,
p = 4πn
3
 ∞
0
dv mv4M(v) = n
3
 ∞
0
dv mv2 ˜M(v) = nkBT.
(20.30)
Example Problem 20.2. Compute the energy ﬂux JE associated with effusion.
Solution 20.2. Each atom will carry an energy (1/2)mv2 so
JE = n
 ∞
−∞
dvx
 ∞
−∞
dvy
 ∞
0
dvz vz(1/2)mv2M(v).
(20.31)
By using spherical polar coordinates as above, we readily obtain
JE = n
4
 ∞
0
dv(1/2)mv2v ˜M(v) = 2kBT n(kBT/2πm)1/2.
(20.32)
We note that the average energy per effused atom is JE/J = 2kBT, which is greater than the
average energy (3/2)kBT per atom of gas in the box. This arises because there is a preference for
the faster atoms to effuse.
Example Problem 20.3. How would the ﬂuxes J and JE for effusion be modiﬁed if instead of
a monatomic gas we have a molecular gas?
Solution 20.3. As long as the partition function for a molecule can be factored into a trans-
lational partition function and an internal partition function (see Section 21.3 for details), the
2This assumption appears to attribute special properties to the walls of the box, such as specular reﬂection,
but it must be true on average in order to maintain equilibrium.

342
THERMAL PHYSICS
Maxwell-Boltzmann distribution for the velocity will still apply. Therefore, J given by Eq. (20.27)
is still valid except the mass in the distribution function ˜M(v) must be replaced by the mass
of the molecule. On the other hand, Eqs. (20.31) and (20.32) must be modiﬁed by replacing
(1/2)mv2 with (1/2)mv2 + uint, where uint is the energy per molecule due to internal degrees of
freedom. Thus,
JE = n
4
 ∞
0
dv v[(1/2)mv2 + uint] ˜M(v).
(20.33)
The crucial difference is that uint is independent of v, so we obtain simply
JE = n(2π)−1/22m(kBT/m)3/2 + Juint.
(20.34)
In this case, the average energy per effused atom is JE/J = 2kBT + uint and we see that there is
no enhancement of the internal energy per molecule, as there is for the kinetic energy.
Example Problem 20.4. For the case of a monatomic gas without internal structure, how
would the number of atoms and the temperature of the gas in the box decay with time due to
effusion?
Solution 20.4. We have
dN
dt = aJ;
dU
dt = 3
2NkB
dT
dt + 3
2kBT dN
dt = aJE.
(20.35)
One can eliminate dN/dt from the second equation to get an ordinary differential equation for
T that can be integrated subject to the initial condition T = T0. This can be used to obtain
an ordinary differential equation for N that can be integrated subject to the initial condition
N = N0. The results are
T
T0
=
1
(1 + rt)2 ;
N
N0
=
1
(1 + rt)6 ,
(20.36)
where r = (a/6V )(2π)−1/2(kBT0/m)1/2 and V is the volume of the box. Of course we need
rt ≪1 for the effusion to be slow enough for the quasi-equilibrium assumption to hold.
20.2 Law of Dulong and Petit
An important application of classical statistical mechanics pertains to the heat capacity of
a system for which the Hamiltonian is a quadratic function of both the pi and the qi:
H =

i
p2
i
2m +

i,j
qiLijqj.
(20.37)
Here, m is the particle mass and the Lij are coupling constants. To a ﬁrst approximation,
the energy of a solid, in excess of its equilibrium potential (binding) energy, can be
approximated by Eq. (20.37), which is known as a harmonic Hamiltonian.

Chapter 20 • Classical Canonical Ensemble
343
We proceed to evaluate the classical partition function ZC by substitution of Eq. (20.37)
into Eq. (20.3). To do this, we use scaled variables Pi := pi
√β and Qi = qi
√β. Then
ZC = β−3N

exp
⎧
⎨
⎩−
⎡
⎣
i
P2
i
2m +

i,j
QiLijQj
⎤
⎦
⎫
⎬
⎭d3N P d3N Q.
(20.38)
With respect to β, the integral in Eq. (20.38) is just a constant which we do not need to
evaluate! Hence Eq. (20.6) becomes
U = −∂
∂β [−3N ln β + constant] = 3NkBT.
(20.39)
This amazingly simple result is independent of the mass and the coupling constants!
The corresponding heat capacity is therefore
CV =
∂U
∂T

V,N
= 3NkB,
(20.40)
which is called the law of Dulong and Petit. Of course it is only valid at high temperatures
and for a Hamiltonian that is strictly a quadratic function of the momenta and coordinates
(i.e., strictly harmonic). It is exactly twice the heat capacity of an ideal gas. It is in
agreement with the equipartition principle, according to which each translational degree
of freedom contributes (1/2)kB per particle and each vibrational degree of freedom also
contributes (1/2)kB per particle. The factor of 3 comes from the dimensionality of space.
For one mole of such a solid, CV = 3R = 5.96 cal/(mol K) ≈6 cal/(mol K), a good number
to remember. Experimental values of CV approach but generally lie a bit below the value
given by the law of Dulong and Petit, even at very high temperatures, presumably due to
anharmonic effects. Moreover, quantum effects, which lower CV to zero as T →0, may still
persist at apparently high temperatures as one approaches the melting point of a solid. See
[58, p. 428] for some experimental curves for noble-gas solids.
20.3 Averaging Theorem and Equipartition
The law of Dulong and Petit is actually a special case of a more general theorem that con-
cerns classical thermal averages. We shall proceed to show that under suitable conditions

ωi
∂H
∂ωj

= δijkBT,
(20.41)
where ωk is a component of the 6N-dimensional vector ω composed of the 3N coordinates
q and the 3N momenta p. Explicit versions of Eq. (20.41) are therefore

qi
∂H
∂qj

= −

qi ˙pj

= δijkBT,
(20.42)

qi
∂H
∂pj

=

qi ˙qj

= 0,
(20.43)

344
THERMAL PHYSICS

pi
∂H
∂qj

= −

pi ˙pj

= 0,
(20.44)

pi
∂H
∂pj

=

pi ˙qj

= δijkBT,
(20.45)
where Hamilton’s equations (Eq. (17.1)) have been used.
To prove Eq. (20.41), we note that

ωi
∂H
∂ωj

= 1
ZC

ωi
∂H
∂ωj
e−βH dω = −1
βZC

ωi
∂e−βH
∂ωj
dω
= −1
βZC
  ∂
∂ωj

ωie−βH
−δije−βH
	
dω
= −1
βZC

ωi e−βH
ω∗∗
j
ω∗
j
dω(j) + δijkBT,
(20.46)
where ω∗
j and ω∗∗
j represent the limits of integration of ωj and dω(j) denotes the phase space
volume element dω with dωj missing. Under suitable conditions, the ﬁrst term on the last
line will vanish. This could occur if H →∞at ω∗
j and ω∗∗
j . In such cases, Eq. (20.41) will
hold. In other cases, however, the integrated term will not vanish or else the integration by
parts makes no sense. For example, in the case of a free particle, H is independent3 of all
coordinates qj so ∂H/∂qj = 0 and Eq. (20.42) would not hold.
Example Problem 20.5. Calculate the average kinetic energy for a Hamiltonian of the form
H =
3N

i=1
p2
i
2m + V(q1, q2, . . . , q3N ),
(20.47)
where the ﬁrst term is the kinetic energy T and the second term is the potential energy due to
interactions among N particles.
Solution 20.5. We note that ∂H/∂pj = pj/m so from Eq. (20.45) we obtain ⟨p2
j /m⟩= kBT.
Therefore,
⟨T ⟩=
3N

i=1
p2
i
2m

= 3
2NkBT.
(20.48)
Note especially that this result holds not only for an ideal gas but for any system governed by
classical statistical mechanics, even when there are interactions among the particles, provided
that the potential energy depends only on the coordinates qi.
3For a free particle conﬁned to a box, one could modify H to account for forces due to the walls of the box,
but this is better handled by the virial theorem discussed in Section 20.4.

Chapter 20 • Classical Canonical Ensemble
345
A Hamiltonian of the form of Eq. (20.37) is a homogeneous function of degree 2 in the
variables ω. In other words, H(λω) = λ2H(ω). Applying Euler’s theorem (which amounts
to differentiating with respect to λ and then setting λ = 1) gives

i
ωi
∂H
∂ωi
= 2H.
(20.49)
Thus,
⟨H⟩= 1
2kBTfs,
(20.50)
where fs is the number of active degrees of freedom, which is equal to the number of
nonvanishing terms in the sum in Eq. (20.49). If only the kinetic energy terms contribute,
as would be the case if the potential energy were zero, we would have fs = 3N and the
result would be ⟨H⟩= (3/2)NkBT, as for the classical ideal gas. If all coordinates and
momenta contributed, we would have fs = 6N, and ⟨H⟩= 3NkBT, in agreement with
the law of Dulong and Petit in Section 20.2. In the general case, one would have to use a
canonical transformation to transform Eq. (20.37) into diagonal form for all generalized
coordinates and momenta to see if any terms are missing [8, p. 64]. Moreover, we should
eliminate any degrees of freedom that are not activated for quantum mechanical reasons,
namely when the corresponding energy levels are so far apart that no excited states
are appreciably occupied. For example, consider the degrees of freedom of a diatomic
molecule consisting of two point particles. Two point particles would have six degrees
of freedom, three translational degrees for each, so one might expect to have fs = 6N.
However, if the particles of the molecule are strongly bound together at some ﬁxed
separation ℓ0, the molecule will behave like a rigid rotator. It has three translational
degrees of freedom and it can rotate. Therefore, fs = 5N and ⟨H⟩= (5/2)NkBT, leading
to the well-known heat capacity CV = (5/2)NkB. See Section 21.3 for a more detailed
discussion, including the possibility of a vibrational degree of freedom4 if the distance
between the particles varies from the constant ℓ0.
If the particles are not point particles, one might think of including a rotational degree
of freedom that amounts to spinning about the axis connecting the particles. However, the
moment of inertia for spinning of actual atoms about the axis that connects their centers is
so small that the associated quantum energy levels, which are proportional to its inverse,
are very high above the ground state. Therefore, only two rotational degrees of freedom
are activated at any reasonable temperature. For a detailed analysis, see Section F.8 in
Appendix F.
4It is worth noting that the vibrational zero point energy ¯hω/2 per molecule cannot be avoided, even if ¯hω ≫
kBT so that excited vibrational states are negligible. This, however, just adds a constant N ¯hω/2 to the total energy
and does not contribute to the heat capacity, so it is seldom mentioned.

346
THERMAL PHYSICS
20.4 Virial Theorem
A topic that is closely related to the averaging results in Section 20.3 is the virial theorem.
The results of Section 20.3, however, are based on ensemble averages computed from the
classical canonical ensemble. The virial theorem, on the other hand, is based on time
averages in a classical system. Comparison of these results helps to substantiate that
ensemble averages are equivalent to time averages for systems in equilibrium.
We begin by considering the quantity
G :=
3N

i=1
qi pi,
(20.51)
where qi are the canonical coordinates and pi are the canonical momenta for a classical
system of N particles in three dimensions. Then differentiation with respect to time yields
dG
dt =
3N

i=1
˙qi pi +
3N

i=1
qi ˙pi.
(20.52)
We deﬁne the time average of any function Q(t) of time by the equation
Q := 1
τ
 τ
0
Q(t) dt.
(20.53)
Accordingly, the time average of dG/dt is
dG
dt = G(τ) −G(0)
τ
.
(20.54)
We now assume that G is bounded, which it certainly will be if the coordinates and
momenta themselves are bounded. We also take τ to be arbitrarily large. Since the quantity
G(τ) −G(0) will also be bounded, we obtain
lim
τ→∞
dG
dt = G(τ) −G(0)
τ
= 0.
(20.55)
Under these circumstances, Eq. (20.52) becomes5
3N

i=1
˙qi pi = −
3N

i=1
qi ˙pi.
(20.56)
According to Eq. (20.45), we would have ⟨3N
i=1 ˙qi pi⟩= 3NkBT and from Eq. (20.42) we
would have ⟨3N
i=1 qi ˙pi⟩= −3NkBT. Therefore, Eq. (20.56) is consistent with the results
of Section 20.3 for systems in equilibrium if the time averages are replaced by ensemble
averages.
5Textbooks and other references are quite inconsistent on which quantity is called the virial. Some consider
the quantity G to be the virial; others consider the right-hand side of Eq. (20.56) or half that quantity or the
negative of that quantity to be the virial. We avoid these inconsistencies by not deﬁning any quantity to be the
virial and allowing the equations to speak for themselves.

Chapter 20 • Classical Canonical Ensemble
347
By means of Hamilton’s equations, we note that Eq. (20.56) can also be written in the
form
3N

i=1
pi
∂H
∂pi
=
3N

i=1
qi
∂H
∂qi
.
(20.57)
For example, for a Hamiltonian that is homogeneous of degree 2 in all of its coordinates
and momenta, Eq. (20.49) applies and its time average gives
H = 1
2
⎡
⎣
3N

i=1
pi
∂H
∂pi
+
3N

i=1
qi
∂H
∂qi
⎤
⎦.
(20.58)
According to Eq. (20.57), each sum contributes equally to H. If time averages were replaced
by ensemble averages, each sum would contribute 3NkBT.
Equation (20.56) can be interpreted readily if we use Cartesian coordinates and a vector
notation, in which case it takes the form
N

i=1
mi
dri
dt
2
= −
N

i=1
mi ri · d2ri
dt2 = −
N

i=1
ri · fi,
(20.59)
where fi is the force on particle i having mass mi. We recognize the left-hand side as twice
the time average of the kinetic energy, namely 2T , which yields
T = −1
2
N

i=1
ri · fi.
(20.60)
In the form of Eq. (20.59), the virial theorem is often used to relate the average kinetic
energy to a total potential V(r1, r2, . . . , rN ) from which the force can be derived. If
fi = −∇iV ≡−∂V
∂ri
,
(20.61)
Equation (20.60) takes the form
T = 1
2
N

i=1
ri · ∂V
∂ri
.
(20.62)
In the case that V is a homogeneous function of degree α in the coordinates, Eq. (20.62)
takes the simple form
T = α
2 V,
(20.63)
which relates the average total kinetic energy to the average total potential energy. For the
case of a harmonic potential, such as given by Eq. (20.37), we would have α = 2 which
would lead to T = V = E/2, where E is the constant total energy. This is a well-known
result for a simple harmonic oscillator but we see here that it is also true for coupled
harmonic motion of a number of oscillators.

348
THERMAL PHYSICS
For the case of gravitational forces, we can take α = −1, as shown below, and obtain the
often quoted result
T = −1
2 V.
(20.64)
Then the total energy, which is a constant, would be
E = T + V = T −2T = −T < 0.
(20.65)
In this latter case of gravitation, one often sees derivations of Eq. (20.64) in which
the interparticle forces are written out explicitly in terms of the relative coordinates of
particles, but the result also follows directly from a slightly modiﬁed version of the Euler
theorem applied to the gravitational potential. Indeed, for gravitational interaction among
particles, one can take
V(r1, r2, . . . , rN ) = −1
2

j̸=k
Gmjmk
|ri −rk|,
(20.66)
where G is the gravitational constant. For λ ̸= 0 it follows that
V(λr1, λr2, . . . , λrN ) = −1
2

j̸=k
Gmjmk
|λri −λrk| = 1
|λ|V(r1, r2, . . . , rN ).
(20.67)
Therefore,6
∂
∂λ
N

i=1
V(λr1, λr2, . . . , λrN ) =
N

i=1
ri · ∂V(λr1, λr2, . . . , λrN )
∂(λri)
= −λ
|λ|3 V(r1, r2, . . . , rN ).
(20.68)
Setting λ = 1 then gives
N

i=1
ri · ∂V(r1, r2, . . . , rN )
∂ri
= −V(r1, r2, . . . , rN ),
(20.69)
which is needed to obtain Eq. (20.64) from Eq. (20.62).
20.5 Virial Coefﬁcients
We can use the virial theorem to compute the lowest order correction to the pressure of
a classical monatomic gas that accounts approximately for the effect of pairwise forces
between atoms. This amounts to calculating what is known as the second virial coefﬁcient
B2(T) in a virial expansion of the form
p
nkBT = 1 +
∞

ν=2
Bν(T)nν−1.
(20.70)
The ﬁrst virial coefﬁcient is B1 = 1 and is seldom mentioned.
6We use |λ| = limϵ→0
√
λ2 + ϵ2 to take the derivative of 1/|λ| on the right-hand side of Eq. (20.67).

Chapter 20 • Classical Canonical Ensemble
349
We begin by considering a gas in equilibrium in a box of volume V at temperature T
to which Eqs. (20.48) and (20.60) apply. Combining these equations by equating the time
average and the ensemble average gives
3
2NkBT = −1
2
N

i=1
ri · fi.
(20.71)
Next, we recognize that the forces fi come from the walls of the box and from internal
forces due to interparticle interactions. The time average forces due to the walls can be
accounted for by means of an average pressure p so that
−1
2
N

i=1
ri · fwalls
i
= p1
2

A
r·ˆn dA = p1
2

V
∇· r dV = 3
2pV.
(20.72)
Thus, Eq. (20.71) becomes
p = nkBT + 1
3V
N

i=1
ri · fint
i ,
(20.73)
where n = N/V is the number density and fint
i
are the internal forces due to interparticle
interactions.
We proceed to compute the effect of these internal forces for pairwise interactions and
central forces between particles i and j that may be calculated from a potential u(|ri −rj|).
Each pair i, j of particles contributes
−ri · ∇iu −rj · ∇ju = −∂u
∂rij

ri · (ri −rj)
rij
+ rj · (rj −ri)
rij
	
= −rij
∂u(rij)
∂rij
,
(20.74)
where rij = |ri −rj|. Therefore, the interaction term may be written in the form
1
3V
N

i=1
ri · fint
i
= N
3V

j̸=0
r0 · fint
j→0 = −N
6V

j̸=0
r0j
∂u(r0j)
∂r0j
,
(20.75)
where r0 designates a speciﬁc particle and fint
j→0 designates the forces on it due to all other
particles j. To compute this average, we introduce the pair distribution function g(r)
deﬁned such that the average number density of particles at a distance r from the center
of a particle located at r = 0 is ng(r), where n = N/V is the overall number density. In
other words, the average number of particles in a small cube of volume d3r located at a
distance r from the center of a given particle is ng(r) d3r. Thus

j̸=0
r0j
∂u(r0j)
∂r0j
=

V
r ∂u(r)
∂r
ng(r) d3r = n
 ∞
0
r ∂u(r)
∂r
4πr2g(r) dr.
(20.76)
We therefore ﬁnd
p
nkBT = 1 −
n
6kBT
 ∞
0
r ∂u(r)
∂r
4πr2g(r) dr.
(20.77)

350
THERMAL PHYSICS
0
1
2
3
4
5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
g(r)
r
FIGURE 20–1 Sketch of the pair distribution function g(r) versus r for r measured in units of the atomic diameter.
For a gas of hard spheres, the rise at r = 1 would be vertical and the ﬁrst peak would be sharp.
The quantity n4πr2g(r) is the number of particles in a spherical shell between r and
r + dr. It is worth noting that the dependence of the second term in Eq. (20.77) on T
is more complicated than is apparent because the distribution function g(r) depends
on T. At lowest order for a dilute gas, correlations among particles are negligible so
g(r) = exp(−βu) is given by the Boltzmann distribution for the pair potential u(r), with
the convention u(∞) = 0. Thus, g(∞) = 1 and g(r) ≈1 for r greater than the range of
the potential where u(r) ≈0. More generally, g(r) = exp(−βu) + ng1(r) + n2g2(r) + · · · .
Figure 20–1 shows a sketch of g(r) versus r. Typically, g(r) is zero at r = 0 and remains
at that value until r approaches the atomic diameter; then it rises rapidly to a maximum
and undergoes decaying oscillations about the value 1 for a few more atomic diameters,
ﬁnally decaying to the value 1 for larger r. These oscillations are due to short-range order
as rings of neighbors, second nearest neighbors, etc. are reached. For a general deﬁnition
of the pair distribution function as well as graphs for a hard sphere gas and for argon, see
Pathria and Beale [9, p. 332]. For its connection to the direct correlation function and the
Ornstein-Zernike equation, see McQuarrie [54, p. 268].
Example Problem 20.6. If the pair distribution function is given to lowest order in n by g(r) =
e−βu, show that p can be expressed in terms of a volume integral of the Mayer function f (r) =
e−βu −1.
Solution 20.6. We note that ∂f /∂r = −βg(r)∂u/∂r and substitute into the second term in
Eq. (20.77) to obtain
 ∞
0
∂u(r)
∂r
g(r) r3 dr = −1
β
 ∞
0
∂f
∂r r3 dr = 3
β
 ∞
0
f r2 dr,
(20.78)

Chapter 20 • Classical Canonical Ensemble
351
where we have integrated by parts in the last step and noted that r3f (r) vanishes at both r = 0
and r = ∞. Therefore,
p
nkBT = 1 −n
2
 ∞
0
f (r) 4πr2 dr.
(20.79)
Example Problem 20.7. Calculate B2(r) for a gas of hard spheres of diameter σ. When
two such spheres just touch, their centers are at a distance σ from each other, which can be
accounted for by assuming that there is an inﬁnite potential within a radius r = σ from the
center of a given sphere.
Solution 20.7. The relevant functions are shown in the following table:
Region
r < σ
σ < r
u(r)
∞
0
g(r)
0
1
f (r)
−1
0
Thus,
B2(T) = −1
2
 ∞
0
f (r)4πr2 dr = 2π
 σ
0
r2 dr = 2π
3 σ 3 = 4v0,
(20.80)
where v0 is the volume of a single hard sphere. In this case, p = nkBT(1 + 4v0n) ≈NkBT/(V −
4Nv0), which has the form of an ideal gas with an excluded volume equal to four times the
volume of all the hard spheres.
Example Problem 20.8. Calculate B2(r) for a gas having a potential that is inﬁnite for r < σ,
has a square well of depth ε for r between σ and σ + a, and is zero for r > σ + a.
Solution 20.8. The relevant functions are shown in the following table:
Region
r < σ
σ < r < σ + a
σ + a < r
u(r)
∞
−ε
0
g(r)
0
exp(βε)
1
f (r)
−1
exp(βε) −1
0
The integrations are straightforward and result in
B2(T) = 2π
3 σ 3

1 −(eβε −1)(σ + a)3 −σ 3
σ 3
	
,
(20.81)
which agrees with the hard sphere gas for a = 0. For βε ≪1, we can expand the exponential to
get the high-temperature result
B2(T) = 2π
3 σ 3

1 −
ε
kBT
(σ + a)3 −σ 3
σ 3
	
.
(20.82)

352
THERMAL PHYSICS
Then the equation for p can be written approximately in the van der Waals form
p + a0/v2 = kBT/(v −b0),
(20.83)
where v = 1/n, a0 = ε(2π/3)[(σ + a)3 −σ 3], and b0 = (2π/3)σ 3.
An alternative deﬁnition of the pair distribution function is that
g(|r2 −r1|)d3r1
V
d3r2
V
(20.84)
is the probability of ﬁnding a pair of particles (any particles) in volumes d3r1 and d3r2,
respectively, that are separated by a distance |r2−r1|. It follows that ng(r) d3r is the average
number of particles in d3r located at r, given that there is a particle at the origin. Thus an
alternative way of evaluating the left-hand term in Eq. (20.75) is
1
3V
N

i=1
ri · fint
i
= −1
3V

pairs
rij
∂u(rij)
∂rij
.
(20.85)
The number of pairs is N(N −1)/2 ≈N 2/2 so
−1
3V

pairs
rij
∂u(rij)
∂rij
= −N 2
6V
 d3r1
V
 d3r2
V
g(|r2 −r1|)r12
∂u(r12)
∂r12
.
(20.86)
To do the integrals, one uses the relative coordinate r = r2−r1 and the coordinate r1. Then

d3r1/V = 1 and we are left with
−1
3V

pairs
rij
∂u(rij)
∂rij
= −N 2
6V 2

d3rg(r)r ∂u(r)
∂r
= −n2
6
 ∞
0
r ∂u(r)
∂r
4πr2g(r) dr,
(20.87)
in agreement with the second term of Eq. (20.77) multiplied by nkBT.
With the use of Eq. (20.84), we can write an expression for the internal energy per
particle due to particle-particle interactions. This energy Uint/N is the difference between
the total internal energy U/N per particle and the energy per particle (3/2)kBT of an ideal
gas and is given by
Uint
N
= N
2
 d3r1
V
 d3r2
V
u(r12)g(|r2 −r1|) = n
2
 ∞
0
u(r)4πr2g(r) dr.
(20.88)
Example Problem 20.9. Beginning with the virial expansion Eq. (20.70) and the fact that one
obtains an ideal gas if all Br(T) = 0 for r ≥2, determine series expansions for the following: the
Helmholtz free energy per particle, f ; the entropy per particle, s; the internal energy per particle,
u; the heat capacity (at constant volume) per particle, c; and the chemical potential, μ.
Solution 20.9. We begin with
df = −s dT −p dv = −s dT + (p/n2) dn
(20.89)

Chapter 20 • Classical Canonical Ensemble
353
and integrate p/n2 over n at constant T. This yields
f = kBT ln n + w(T) + kBT
∞

r=2
Br(T) nr−1
r −1,
(20.90)
where w(T) is a function of integration that depends only on T. We determine w(T) by
recognizing that kBT ln n + w(T) must be the value f ideal = (μ −pv)ideal for an ideal gas. Thus
f = kBT[ln(n/nQ) −1] + kBT
∞

r=2
Br(T) nr−1
r −1,
(20.91)
where nQ = (mkBT/2π¯h2)3/2 is the quantum concentration. Thus,
s = −

∂f /∂T

n = kB[ln(nQ/n) + 5/2] −kB
∞

r=2
d[TBr(T)]
dT
nr−1
r −1,
(20.92)
u = f + Ts = (3/2)kBT −kBT2
∞

r=2
dBr(T)
dT
nr−1
r −1,
(20.93)
c = (∂u/∂T)n = (3/2)kB −kBT
∞

r=2
d2[TBr(T)]
dT2
nr−1
r −1,
(20.94)
μ = f + p/n = kBT ln(n/nQ) + kBT
∞

r=2
Br(T)r nr−1
r −1 .
(20.95)
Example Problem 20.10. Show that the pressure given by Eq. (20.79)and the particle-particle
interaction energy given by Eq. (20.88) are compatible with the r = 2 terms in the general
expansions Eqs. (20.70) and (20.93).
Solution 20.10. Agreement of the interaction energies given by Eqs. (20.88) and (20.93)
requires
−kBT2 dB2(T)
dT
= 1
2
 ∞
0
u(r)4πr2g(r) dr.
(20.96)
Agreement of the pressures given by Eqs. (20.70) and (20.79) requires
B2(T) = −1
2
 ∞
0
f (r) 4πr2 dr.
(20.97)
By differentiation of Eq. (20.97) we obtain
dB2(T)
dT
= −1
2
 ∞
0
∂f (r)
∂T
4πr2 dr = −
1
2kBT2
 ∞
0
u(r) 4πr2g(r) dr,
(20.98)
in agreement with Eq. (20.96). Note that we had to use the explicit form g(r) = eβu, which gives
the correct second-order virial coefﬁcient. More generally, this is only the leading term in an
expansion of g(r) in powers of n. Including such terms would lead to virial coefﬁcients of higher
order.

354
THERMAL PHYSICS
20.6 Use of Canonical Transformations
Evaluation of the classical partition function can be facilitated greatly by using canonical
transformations to perform the required integrals. Such transformations leave the form
of Hamilton’s equations unchanged. Simple examples of canonical transformations are
coordinate transformations, such as from Cartesian to cylindrical or spherical coordi-
nates. General canonical transformations are discussed in Appendix E. In particular, one
transforms from one set of generalized coordinates q = q1, q2, . . . , qN and their conjugate
momenta p = p1, p2, . . . , pN to another independent set Q = Q1, Q2, . . . , QN and P =
P1, P2, . . . , PN according to relations of the form7
qi = qi(Q, P);
pi = pi(Q, P).
(20.99)
The corresponding transformation of the partition function would be
ZC =

exp[−β H(p, q)] dp dq =

exp[−β K(P, Q)]|J| dP dQ,
(20.100)
where K(P, Q) is the new Hamiltonian and |J| is the absolute value of the Jacobian of the
transformation. See Eq. (E.4) for an explicit representation of J. As shown in Appendix E,
canonical transformations are members of the symplectic group for which it is shown
(see Eq. (E.32)) that J = ±1. Thus |J| = 1 and the transformation of the partition function
integral becomes simply
ZC =

exp[−β H(p, q)] dp dq =

exp[−β K(P, Q)] dP dQ.
(20.101)
The simple form of Eq. (20.101) might seem strange to those accustomed to seeing
scale factors such as r2 sin θ appearing in Jacobians that arise in transformation of volume
integrals from Cartesian to spherical polar coordinates. But for canonical transforma-
tions, both the coordinates and the momenta transform in just such a way that the
corresponding volumes in phase space are the same. Nevertheless, it is frequently the
case that familiar scale factors for the coordinate integrals will appear after perform-
ing the momentum integrals. Finally, it is sometimes expedient to use transformations
that are not canonical to do the necessary integrals. See the next section for explicit
examples.
7In Appendix E, we allow these transformations to depend explicitly on time as well, but here we are interested
in equilibrium ensembles so we omit explicit dependence on time. Such transformations are called restricted
canonical transformations and are treated explicitly in Section E.2. For restricted canonical transformations, the
old and new Hamiltonians are numerically equal at corresponding points.

Chapter 20 • Classical Canonical Ensemble
355
Example Problem 20.11. Compute the classical partition function Z∗
C for a single diatomic
molecule consisting of point particles having masses m1 and m2 separated by a ﬁxed distance ℓ
(no vibrational mode) and having a magnetic moment μB that makes an angle θ with an applied
magnetic ﬁeld B. The molecule is conﬁned to a box of volume V and its Hamiltonian has the
form (which we need to write in terms of canonical momenta)
H = m1
2 ˙r2
1 + m2
2 ˙r2
2 −μBB cos θ.
(20.102)
Solution 20.11. We make a canonical transformation to a center of mass coordinate R =
(m1r1 + m2r2)/(m1 + m2) and a relative coordinate r = r1 −r2 but then an additional
transformation of the relative coordinate into spherical polar coordinates with ﬁxed radius
r = ℓ, azimuthal angle ϕ and polar angle θ. The kinetic energy in H takes the well-known form
m1
2 ˙r2
1 + m2
2 ˙r2
2 = M
2
˙R2 + μred
2
[ℓ2 ˙θ2 + ℓ2 sin2 θ ˙ϕ2],
(20.103)
where M = m1 + m2 is the total mass and μred = m1m2/M is the reduced mass. The canonical
momenta are Pi = ∂H/∂˙Ri = M ˙Ri, pθ = ∂H/∂˙θ = μℓ2 ˙θ, and pϕ = ∂H/∂˙ϕ = μℓ2 sin2 θ ˙ϕ, so the
Hamiltonian becomes
H =
3

i=1
P2
i
2M + p2
θ
2I +
p2
ϕ
2I sin2 θ
−μBB cos θ,
(20.104)
where I = μredℓ2 is the moment of inertia about the center of mass of the molecule. See Section
F.1.1 in Appendix F for an explicit evaluation of I. Since the transformation is canonical, the
partition function is
Z∗
C = 1
h5

exp[−βH] dP1 dP2 dP3 dR1 dR2 dR3 dpθ dpϕ dθ dϕ.
(20.105)
The factor of h−5, rather than h−6, arises because the magnitude of ℓhas been assumed to be
constant (no vibrational mode). Since exp[−βH] factors, we can perform the R and P integrals
immediately to obtain
1
h3

exp
 
−β
3

i=1
P2
i
2M
!
dP1 dP2 dP3 dR1 dR2 dR3 = VnQ,
(20.106)
where nQ
= (MkBT/2π¯h2)3/2. The integrals over dpθ and dpϕ are well-known Gaussian
integrals, resulting in
1
h

exp
 
−β p2
θ
2I
!
dpθ =
 2πI
h2β
1/2
;
1
h

exp
 
−β
p2
ϕ
2I sin2 θ
!
dpϕ = sin θ
 2πI
h2β
1/2
.
(20.107)
The crucial point to note is that the scale factor sin θ gets trapped inside the remaining θ
integral, resulting in
Z∗
C = VnQ
 2πI
h2β
 
exp[βμBB cos θ] sin θ dθ dϕ = VnQ
 2I
¯h2β
 sinh(βμBB)
βμBB
.
(20.108)

356
THERMAL PHYSICS
We see that the partition function is the product of three factors, VnQ which is the partition
function for translation of a structureless ideal gas of molecules having molecular mass M, a
factor (2I/¯h2β), which is the partition function for a rigid diatomic molecule rotating about its
center of mass, and a factor sinh(βμBB)/βμBB which is the partition function for a magnetic
dipole.
20.7 Rotating Rigid Polyatomic Molecules
In the approximation of classical statistical mechanics, we can calculate the partition
function by integrating over canonical coordinates and momenta in phase space and
dividing by appropriate powers of h. Such a partition function should agree with a
quantum mechanical result at high temperatures. Rigid rotation of a polyatomic molecule
is a three-dimensional problem for a body that can have three different principal moments
of inertia, I1, I2, and I3. See Appendix F for details. As shown in Section F.6, the orientation
of the molecule can be expressed in terms of three Euler angles, φ, θ, and ψ, where we have
adopted the notation and convention of Goldstein [60, p. 107]. As shown in Section F.7, the
Hamiltonian can be written in the forms
H = 1
2(I1ω2
1 + I2ω2
2 + I3ω2
3) = L2
1
2I1
+ L2
2
2I2
+ L2
3
2I3
.
(20.109)
Here, ω1, ω2, and ω3 are principal angular velocities and Li = Iiωi are the corresponding
principal angular momenta. The ωi can be expressed in terms of the Euler angles and
their time derivatives (see Eq. (F.59)). Then the canonical momenta, pφ, pθ, and pψ, can
be calculated by differentiation and are given explicitly by Eqs. (F.61)–(F.63). Thus
z = 1
h3

exp(−βH) dpφ dpθ dpψ dφ dθ dψ.
(20.110)
One could proceed by solving Eqs. (F.61)–(F.63) for L1, L2, L3 and using the results to
eliminate these quantities from Eq. (20.109). This results in a very cumbersome expression
for H as a function of the canonical momenta and the Euler angles and poses a rather
unwieldy integration. An alternative procedure is to transform the integration variables to
L1, L2, L3, φ, θ, ψ by means of a Jacobian Jpoly so that
z = 1
h3

exp(−βH) |Jpoly| dL1 dL2 dL3 dφ dθ dψ,
(20.111)
where
|Jpoly| =

∂

pφ, pθ, pψ, φ, θ, ψ

∂(L1, L2, L3, φ, θ, ψ)
 =

∂

pφ, pθ, pψ

∂(L1, L2, L3)
 .
(20.112)
This is not a canonical transformation, so the magnitude of the Jacobian is
|Jpoly| =

det
⎛
⎝
sin θ sin ψ sin θ cos ψ cos θ
cos ψ
−sin ψ
0
0
0
1
⎞
⎠

= | −sin θ| = sin θ.
(20.113)

Chapter 20 • Classical Canonical Ensemble
357
The partition function therefore becomes8
z = 1
h3

exp(−βH) sin θ dL1 dL2 dL3 dφ dθ dψ
= 8π2
h3

exp
 
−β
&
L2
1
2I1
+ L2
2
2I2
+ L2
3
2I3
'!
dL1 dL2 dL3.
(20.114)
We are left with the product of three Gaussian integrals of the form
 ∞
−∞
exp[−βL2
1/(2I1)] dL1 =

2πI1kBT
1/2 .
(20.115)
We therefore obtain
z = π1/2
2I1kBT
¯h2
1/2 2I2kBT
¯h2
1/2 2I3kBT
¯h2
1/2
.
(20.116)
This result will be used in Section 21.3.3 in the context of a gas of polyatomic molecules
that can also vibrate.
For a diatomic molecule, only two degrees of freedom are considered because I3 is
essentially zero9 and the two remaining moments of inertia are equal, say to I. Thus
H = I
2 (ω2
1 + ω2
2) = I
2 (sin2 θ ˙φ2 + ˙θ2) = 1
2I (L2
1 + L2
2).
(20.117)
Now the only canonical momenta are10
pφ = I sin2 θ ˙φ = L1 sin θ sin ψ + L2 sin θ cos ψ
(20.118)
and
pθ = I ˙θ = L1 cos ψ −L2 sin ψ.
(20.119)
Therefore,
zdia = 1
h2

exp(−βH) dpφ dpθ dφ dθ = 1
h2

exp(−βH)|Jdia| dL1 dL2 dφ dθ,
(20.120)
where the magnitude of the Jacobian
|Jdia| =

∂

pφ, pθ

∂(L1, L2)
 = sin θ.
(20.121)
The integrals over φ and θ give a factor of 4π and we obtain
zdia = 4π
h2

exp
 
−β
&
L2
1
2I + L2
2
2I
'!
dL1 dL2.
(20.122)
8The ranges of the Euler angles are 0 ≤φ ≤2π, 0 ≤θ ≤π, and 0 ≤ψ ≤2π. Landau and Lifshitz [7, p. 149]
give a verbal argument that an integral over three unspeciﬁed angles gives a factor of 8π2 and then proceed to
integrate over only L1, L2, L3, but no justiﬁcation in terms of canonical momenta is given.
9As shown in Section F.8 of Appendix F, the quantum states associated with I3 have such high energies that
they are not excited at any reasonable temperature.
10Here, we continue to use the same Euler angles as for the polyatomic molecule for the sake of a parallel
treatment.

358
THERMAL PHYSICS
Integration results in two equal factors having the form of Eq. (20.115) which yields the
result
zdia = 2IkBT
¯h2
,
(20.123)
in agreement with the high-temperature quantum mechanical result given by Eq. (18.85).
In this simple case, the Hamiltonian can be written in terms of the canonical momenta
in the form
H = 1
2I
&
p2
φ
sin2 θ
+ p2
θ
'
,
(20.124)
so there is not much advantage in transforming to an integral over L1 and L2.
On the other hand, when I1, I2, and I3 are all different, there is great simpliﬁcation in
transforming to L1, L2, L3. For example, a normalized probability distribution function for
the angular momenta Li would be
M(L) =

β
2πI1
1/2 
β
2πI2
1/2 
β
2πI3
1/2
exp
 
−β
&
L2
1
2I1
+ L2
2
2I2
+ L2
3
2I3
'!
.
(20.125)
The quantity M(L) dL1 dL2 dL3 is the probability of ﬁnding an angular momentum in a
cube of inﬁnitesimal volume dL1 dL2 dL3 centered at L. The average square of the angular
momentum is
⟨L2⟩=

M(L)(L2
1 + L2
2 + L2
3) dL1 dL2 dL3 = kBT(I1 + I2 + I3).
(20.126)
Alternatively, we can transform the integration variables to ω1, ω2, ω3, φ, θ, ψ in the
partition function Eq. (20.110) by means of the Jacobian
|Jω| =

∂

pφ, pθ, pψ

∂(ω1, ω2, ω3)
 = I1I2I3 sin θ.
(20.127)
This leads to the same partition function as in Eq. (20.116) but we can also deduce that the
normalized distribution function for the ωi is
M∗(ω) =
βI1
2π
1/2 βI2
2π
1/2 βI3
2π
1/2
exp
 
−β
&
I1ω2
1
2
+ I2ω2
2
2
+ I3ω2
3
2
'!
.
(20.128)
This leads to an average value
⟨ω2⟩=

M∗(ω)(ω2
1 + ω2
2 + ω2
3) dω1 dω2 dω3 = kBT
 1
I1
+ 1
I2
+ 1
I3

.
(20.129)
It is interesting and physically reasonable that average values of the squares of the
principal angular velocities are inversely proportional to their respective moments of
inertia.

21
Grand Canonical Ensemble
In Chapter 19, we derived the canonical ensemble by starting with the microcanonical
ensemble. The microcanonical ensemble applies to an isolated system which therefore
has a ﬁxed energy; on the other hand, the canonical ensemble applies to a system that has
a ﬁxed temperature. The derivation is accomplished by considering the system of interest
to be a subsystem of a total system that is isolated and to which the microcanonical
ensemble applies. The remainder of the total system, exclusive of the system of interest,
acts as a heat reservoir whose temperature is imposed on the system of interest.
In the present chapter, we introduce the grand canonical ensemble (GCE) which
applies to a system having a ﬁxed temperature and a ﬁxed chemical potential, but not
a ﬁxed energy or a ﬁxed number of particles. Other extensive parameters of the system,
which we take to be only the volume V in the development that follows, are ﬁxed.1 Our
system of interest is again considered to be a subsystem of a total system that is isolated
and therefore has a ﬁxed energy and a ﬁxed number of particles. In this case, the remainder
of the total system, exclusive of the system of interest, acts as both a heat reservoir and
a particle reservoir for the system of interest. Thus, it imposes its temperature and its
chemical potential on the system of interest. But the system of interest will have an average
energy, U, and an average number of particles, ⟨N⟩, which together with its volume V will
be sufﬁcient for its thermodynamic description.
By using the GCE for which the number of particles is not speciﬁed, we gain the
ﬂexibility to treat systems that have quantum mechanical constraints on the number of
particles that can occupy a quantum state. We shall use it to treat ideal Fermi and Bose
gases whose wave functions must be antisymmetric or symmetric, respectively, when its
identical particles are interchanged. For such quantum ideal gases, the grand canonical
partition function factors, which is not the case for the canonical partition function. The
classical ideal gas will be shown to be a limiting case of either a Fermi gas or a Bose gas.
Thus the approximations used to treat the classical ideal gas by means of the canonical
ensemble with the Gibbs correction factor N! can be clariﬁed. Accordingly we treat a
classical ideal gas of molecules having internal structure. Dilute systems for which the
constituents can be regarded as independent subsystems can also be treated by a grand
canonical partition function that factors. We shall illustrate its use to treat adsorption
from a gas that imposes its chemical potential on a surface having dilute adsorption
1These are usually the parameters that allow the system to do work. A system without a volume might have
an area or a length that is relevant. A system could also have a ﬁxed number of sites that can be occupied by
particles.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00021-1
359
Copyright © 2015 Elsevier Inc. All rights reserved.

360
THERMAL PHYSICS
sites. Finally, we use the same methodology as used to derive the GCE to develop a
pressure ensemble that we illustrate by treating point defects in crystals under conditions
of constant temperature and pressure.
21.1 Derivation from Microcanonical Ensemble
We derive the GCE from the microcanonical ensemble by generalization of the second
derivation of the canonical ensemble given in Section 19.1.2. For an alternative treatment
based on the evaluation of an integral by the method of steepest descent, see Schrödinger
[99, p. 41]. We consider a total isolated system (subscript “T”) having a ﬁxed energy ET
and a ﬁxed number of particles NT. We regard the total system to consist of a reservoir R
and a system I of interest. The system I may, itself, be very large. We consider a situation
in which the system I is in a quantum state having a speciﬁc number of particles Ns and
quantum states Ers(V) ≡Er(Ns, V), where its volume V is ﬁxed. For simplicity of notation,
we will suppress the argument V in the development that follows.
When the system of interest is in a speciﬁc quantum state, the energy of the reservoir
will be ET −Ers and its number of particles will be NT −Ns. Then we represent the
multiplicity function (number of microstates) of the reservoir by the symbol R(ET −
Ers, NT −Ns). This is also equal to the multiplicity function of the total system because
the system of interest is in a deﬁnite quantum state, so its multiplicity function is
(Ers, Ns) = 1. Symbolically,
rs
T = R(ET −Ers, NT −Ns)(Ers, Ns) = R(ET −Ers, NT −Ns),
(21.1)
which is a generalization of Eq. (19.1). The probability of the system of interest being in
this deﬁnite quantum state is therefore
Prs =
rs
T
T(ET, NT) = R(ET −Ers, NT −Ns)
T(ET, NT)
= exp[SR(ET −Ers, NT −Ns)/kB]
exp[ST(ET, NT)/kB]
,
(21.2)
which is a generalization of Eq. (19.17). Since the entropy of a composite system is additive,
we have
ST(ET, NT) = SR(ET −U, NT −⟨N⟩) + S(U, ⟨N⟩),
(21.3)
where U = ⟨E⟩is the average internal energy of the system of interest and ⟨N⟩is its average
number of particles in its unrestricted state in equilibrium with the reservoir. We can
therefore recast Eq. (21.2) in the form
Prs = exp[−S(U, ⟨N⟩)/kB] exp[SR(ET −Ers, NT −Ns)/kB]
exp[SR(ET −U, NT −⟨N⟩)/kB]
.
(21.4)
We write
SR [ET −Ers, NT −Ns] = SR [(ET −U) + (U −Ers), (NT −⟨N⟩) + (⟨N⟩−Ns)]
(21.5)
and then expand on the basis that |U −Ers|/|ET −U| ≪1 and |⟨N⟩−Ns|/|NT −⟨N⟩| ≪1 to
obtain

Chapter 21 • Grand Canonical Ensemble
361
SR(ET −Ers, NT −Ns) = SR(ET −U, NT −⟨N⟩) + U −Ers
TR
−μR
TR
(⟨N⟩−Ns) + · · · .
(21.6)
Substitution into Eq. (21.4) yields
Prs = exp[(U −TRS −μR⟨N⟩)/(kBTR)] exp[−Ers/(kBTR)] exp[μRNs/(kBTR)].
(21.7)
Dropping the subscripts on TR and μR and deﬁning the Kramers potential (also known as
the grand potential),
K := U −TS −μ⟨N⟩= F −μ⟨N⟩,
(21.8)
Equation (21.7) can be written in the form
Prs = exp(βK) exp(−βErs) exp(βμNs),
(21.9)
where β = 1/(kBT) as usual. The quantity exp(−βErs) exp(βμNs) is referred to as a Gibbs
factor by Kittel and Kroemer [6], by analogy to a Boltzmann factor.
At constant T and μ, we see that the ratio of the probabilities of any two states is equal to
the ratio of their Gibbs factors. We recall for the canonical ensemble that at constant T and
N, the ratio of the probabilities of any two states is equal to the ratio of their Boltzmann
factors.
If we sum the probabilities Prs over all values of Ers and Ns (which Kittel and Kroemer [6]
call “all states and numbers,” abbreviated by “ASN”), Eq. (21.9) yields
1 = exp(βK)

rs
exp(−βErs) exp(βμNs).
(21.10)
This allows us to deﬁne a grand partition function (also known as the Gibbs sum [6] over
ASN),
Z :=

rs
exp(−βErs) exp(βμNs) = exp(−βK).
(21.11)
For the GCE, Eq. (21.11) deﬁnes a grand partition function Z that plays the same role as
the canonical partition function Z. The probabilities can be written in the form
Prs = exp(−βErs) exp(βμNs)
Z
,
(21.12)
which is similar in form to Eq. (19.6).
In order to recover the thermodynamic functions, we write Eq. (21.11) in the form
K = −kBT ln Z
(21.13)
and note2 from the Legendre transformation K = F −μ⟨N⟩and the differential dF that
dK = −S dT −p dV −⟨N⟩dμ.
(21.14)
2In dealing with the canonical ensemble, to which F is related, we regard the number of particles N to be
speciﬁed; however, for the GCE, we relate K to the average number of particles ⟨N ⟩. In thermodynamics, we can
ignore the distinction between N and ⟨N ⟩, but for the GCE, this distinction must be made, so we write ⟨N ⟩in
Eq. (21.14).

362
THERMAL PHYSICS
Thus we have3
S = −
 ∂K
∂T

V,μ
;
p = −
 ∂K
∂V

T,μ
;
⟨N⟩= −
∂K
∂μ

T,V
.
(21.15)
The last of these equations can be used to ﬁnd ⟨N⟩if μ is known, but for a thermodynamic
system, one usually regards ⟨N⟩to be known. In principle, one can take this point of view,
specify ⟨N⟩and solve for μ, but since μ is contained in a transcendental equation, this can
only be done approximately.
To get an expression for the internal energy U, we return to Eq. (21.8) and use Eq. (21.15)
to obtain
U = K −T
∂K
∂T

V,μ
−μ
∂K
∂μ

T,V
.
(21.16)
Substitution of Eq. (21.13) into Eq. (21.16) then leads to
U = kBT2
∂ln Z
∂T

V,μ
+ kBTμ
∂ln Z
∂μ

T,V
= −
∂ln Z
∂β

V,μ
+ μ
β
∂ln Z
∂μ

β,V
.
(21.17)
We will obtain a more convenient expression for U in terms of other variables.
Several remarks about the interpretation and structure of the grand partition function
are in order:
1. Since Ers ≡Er(Ns), the double sum in Eq. (21.11) can ﬁrst be performed on r to yield
Z =

s
exp(βμNs)

r
exp(−βErs) =

s
exp(βμNs)ZNs,
(21.18)
where, according to Eq. (19.5),
ZNs :=

r
exp(−βErs)
(21.19)
is the canonical partition function for a system having exactly Ns particles.
2. We need to specify clearly the variable set on which Z and K depend. Until now, as
reﬂected by Eq. (21.14), we have considered the variable set to be T, μ, and V or, since
kB is a constant, the equivalent set β, μ, and V. But one can also introduce the absolute
activity
λ := exp(βμ)
(21.20)
and consider instead the variable set T, λ, and V or equivalently β, λ, and V. Then
Eq. (21.18) can be written in the form of a power series
Z =

s
λNs 
r
exp(−βErs) =

Ns
λNsZNs
(21.21)
3Strictly speaking, S is an average entropy and p is an average pressure, but we have omitted the averaging
brackets because they were absent in Eq. (21.14) which is of thermodynamic origin. In the thermodynamic limit,
the distinction is irrelevant.

Chapter 21 • Grand Canonical Ensemble
363
whose coefﬁcients are just the canonical partition functions that can be extracted by
means of the formula
ZNs =
1
Ns!
 ∂
∂λ
Ns
Z

λ=0
.
(21.22)
Then the probabilities can be written in the form
Prs = λNs exp(−βErs)
Z
.
(21.23)
3. In the expression for Z, it is often convenient to run the sum formally from Ns = 0 to
Ns = ∞which would require a reservoir of inﬁnite size. This does not give rise to a
problem because we are interested in systems with ﬁnite ⟨N⟩and we shall see that the
important values of Ns are those near ⟨N⟩because

⟨(Ns −⟨N⟩)2⟩
⟨N⟩
∼
1
√⟨N⟩
(21.24)
which turns out to be exact for an ideal gas (see Eqs. (21.51) and (21.52)). For a system
having a ﬁnite number of absorption sites (see Section 21.2.1), the sum is ﬁnite.
4. The state with Ns = 0 is known as the vacuum state. We regard it to be a nondegenerate
state having zero energy, Z(Ns = 0) = 1. Then Eq. (21.18) can be written in the form
Z = 1 +

Ns
λNsZNs.
(21.25)
All other energies are to be measured relative to the vacuum state. This convention
is consistent with representation of many particle states by means of occupation
numbers of orbitals, which are quantum states of single particles (see Eq. (21.63)).
21.1.1 Kramers Function
Somewhat more transparent results for the thermodynamic functions can be written in
terms of the Kramers dimensionless function4
q(β, V , λ) := ln Z,
(21.26)
where Z is expressed in terms of the variables β, λ , and V according to Eq. (21.21). Since
(∂λ/∂β)V,μ = λμ and (∂λ/∂μ)V,β = λβ, we ﬁnd
∂ln Z
∂β

V,μ
=
∂q
∂β

V,λ
+ λμ
∂q
∂λ

V,β
(21.27)
and
∂ln Z
∂μ

V,β
= λβ
∂q
∂λ

V,β
.
(21.28)
4The Kramers potential (grand potential) K is related to the dimensionless Kramers function q by the equation
K = −kBTq, but the variables on which they are usually regarded to depend are different.

364
THERMAL PHYSICS
Thus Eq. (21.17) becomes
U = −
 ∂q
∂β

V,λ
.
(21.29)
Similar conversion of the derivatives in Eq. (21.15) gives
⟨N⟩= kBT
∂ln Z
∂μ

V,β
= λ
∂q
∂λ

V,β
(21.30)
and
p = kBT
∂ln Z
∂V

β,μ
= 1
β
 ∂q
∂V

β,λ
.
(21.31)
These results can be summarized in terms of the differential
dq = −U dβ + βp dV + ⟨N⟩
λ
dλ.
(21.32)
Note that Eqs. (21.29) and (21.30) could have been obtained directly from deﬁnitions of
average quantities in terms of the probabilities Prs = λNs exp(−βErs)/Z with Z expressed
as a function of β, λ, and V. For example, U = 
rs PrsErs =

∂ln Z/∂β
	
λ,V because differen-
tiation with respect to β introduces Ers inside the sum.
Equations (21.29) and (21.30) can be written as weighted averages by using the explicit
form of Eq. (21.21) for q, namely
q = ln
⎡
⎣
Ns
λNsZNs
⎤
⎦.
(21.33)
We recall that the average energy for a system of exactly Ns particles in the canonical
ensemble is
UNs = −1
ZNs
∂ZNs
∂β

V,Ns
.
(21.34)
Thus Eq. (21.29) takes the form
U =

Ns λNsZNsUNs

Ns λNsZNs
,
(21.35)
which is a weighed average of UNs with weighting factors λNsZNs. Equation (21.30) takes a
similar form
⟨N⟩=

Ns λNsZNsNs

Ns λNsZNs
.
(21.36)
In fact, Eqs. (21.35) and (21.36) follow directly from the probabilities given by Eq. (21.12).
The reader is invited to show that the pressure is a similar weighted average
of the pressures, calculated from the canonical ensemble, for systems having deﬁnite
values of Ns.

Chapter 21 • Grand Canonical Ensemble
365
The pressure can also be related directly to the q function by an algebraic equation. The
only extensive variable on which K depends is V, so its Euler equation is just
K = −pV,
(21.37)
which is consistent with U = TS −pV + μ⟨N⟩. Therefore,
q = pV
kBT .
(21.38)
Both K and q are extensive variables that depend on β, λ, and V, but β and λ are intensive,
so both K and q must be proportional to V.
Indeed, comparison of Eq. (21.38) with Eq. (21.31) requires
 ∂q
∂V

β,λ
= q
V ,
(21.39)
which can be integrated at constant β and λ to give
ln q = ln V + ln q0(β, λ).
(21.40)
The last term in Eq. (21.40) is a function of integration, independent of V, that could
equally well depend on T and μ. Therefore, q is of the form
q = Vq0(β, λ),
(21.41)
which is proportional to V. Comparison with Eq. (21.38) shows that
p = kBTq0(β, λ),
(21.42)
so the intensive variable p can be expressed in terms of only the intensive variables β and
λ, or equivalently T and μ, independent of V as expected.
It sometimes happens that the GCE is used to treat systems that do not contain the
volume V as a variable, in which case Z, and therefore q and K, are independent of
V. Examples of such systems would be identical spins or harmonic oscillators, ﬁxed in
position and distinguishable by virtue of their position, as in a rigid solid, or a set of
adsorption sites on a surface. In such cases, equations such as Eqs. (21.31) and (21.37)–
(21.42) are not applicable. Formally, such systems have zero pressure or equivalents to
pressure that can be deﬁned in spaces of lower dimensionality. As long as these systems
are well deﬁned, we can still use equations such as Eqs. (21.35) and (21.36), or their
equivalents, because they can be justiﬁed on the basis of
U =

r,s
PrsErs = −
 ∂q
∂β

λ
(21.43)
and
⟨N⟩=

r,s
PrsNs = λ
∂q
∂λ

β
.
(21.44)

366
THERMAL PHYSICS
Example Problem 21.1. Show that the entropy can be expressed in the form
S = −kB

rs
Prs ln Prs.
(21.45)
Solution 21.1. Whether or not there is dependence on V , we have K = U −TS −μ⟨N⟩so
S/kB = q + βU −⟨N⟩ln λ. But
−

rs
Prs ln Prs = −

rs
Prs[−q −βErs + Ns ln λ] = q + βU −⟨N⟩ln λ.
The entropy takes the same form as Eq. (21.45) in any ensemble.
21.1.2 Particle Number Dispersion
In Section 19.5, we showed for the canonical ensemble that there was dispersion of the
internal energy for a system held at constant temperature. This is also true for the GCE;
however, for the GCE, the chemical potential is held constant and equal to that of a
reservoir. Therefore, for a system described by the GCE, there is also dispersion of the
number of particles relative to the average number of particles ⟨N⟩= (1/β)

∂ln Z/∂μ
	
β,V
given by Eq. (21.15).
We can quantify this dispersion of particle number by calculating its second moment
relative to its average value, namely
⟨(N)2⟩:= ⟨(N −⟨N⟩)2⟩= ⟨N 2⟩−⟨N⟩2,
(21.46)
where
⟨N 2⟩=

rs
N 2
s Prs,
(21.47)
with Prs given by Eq. (21.12). By differentiation of Eq. (21.11), we note that
∂2Z
∂μ2 = β2 
rs
N 2
s exp(−βErs) exp(βμNs),
(21.48)
which yields
⟨N 2⟩= 1
β2
1
Z
∂2Z
∂μ2

β,V
.
(21.49)
Therefore,
⟨(N)2⟩= 1
β2
1
Z
∂2Z
∂μ2 −1
β2
1
Z2
∂Z
∂μ
2
= 1
β2
∂2 ln Z
∂μ2
= 1
β
∂⟨N⟩
∂μ

β,V
.
(21.50)
Since μ and β are intensive, the right-hand side of Eq. (21.50) is O(⟨N⟩). Therefore, in
agreement with Eq. (21.24), we have

⟨(N)2⟩
⟨N⟩
= O

1
√⟨N⟩

.
(21.51)

Chapter 21 • Grand Canonical Ensemble
367
For an ideal gas, Eq. (19.66) applies,5 so ∂⟨N⟩/∂μ = β⟨N⟩and we have exactly

⟨(N)2⟩
⟨N⟩
=
1
√⟨N⟩.
(21.52)
For a system having a large number of particles, we see that this dispersion is quite
small.
The result in Eq. (21.50) can be related to the isothermal compressibility, κT = (1/v)

∂v/∂p
	
β, where v := V/⟨N⟩is the volume per particle. At constant β, one has dμ = v dp,
where p is the pressure. Thus
∂μ
∂v

β
= v
∂p
∂v

β
= −1/κT.
(21.53)
Therefore,
∂⟨N⟩
∂μ

β,V
=
∂(V/v)
∂μ

β,V
= −V
v2
 ∂v
∂μ

β
= ⟨N⟩
v
κT.
(21.54)
Substitution into Eq. (21.50) leads to

⟨(N)2⟩
⟨N⟩
=

kBTκT
v⟨N⟩
(21.55)
in agreement with Eq. (21.51). For an ideal gas, κT = 1/p and kBT/(pv) = 1, so Eq. (21.55)
becomes Eq. (21.52). Since v⟨N⟩= V, we observe that ﬂuctuations in particle numbers
could be large if very small sub-volume of a large volume of gas is observed.
21.1.3 Energy Dispersion
Energy dispersion in the GCE is different from that calculated for the canonical ensem-
ble in Section 19.5 because in the GCE the number of particles has dispersion. From
Eq. (21.29) we have U = ⟨E⟩= −(1/Z)(∂Z/∂β)λ,V . By analogy to Eq. (19.85) we have
⟨E2⟩=

rs
E2
rsPrs = 1
Z
∂2Z
∂β2

λ,V
.
(21.56)
Then by following a procedure similar to that in Section 19.5, we ﬁnd
⟨(E)2⟩= ⟨E2⟩−⟨E⟩2 =
∂ln Z
∂β2

λ,V
= −
∂U
∂β

λ,V
.
(21.57)
We can relate the derivative in Eq. (21.57) to the heat capacity at constant volume, CV , by
thinking of U as a function of β, V, and ⟨N⟩and writing
∂U
∂β

λ,V
=
∂U
∂β

⟨N ⟩,V
+
 ∂U
∂⟨N⟩

β,V
∂⟨N⟩
∂β

λ,V
.
(21.58)
5Equation (19.66) applies to the canonical ensemble, for which the system is regarded as having an exact
number of particles N , which therefore corresponds to the symbol ⟨N ⟩of the GCE.

368
THERMAL PHYSICS
The ﬁrst term in Eq. (21.58) is just −kBT2CV and if substituted alone into Eq. (21.57) would
give Eq. (19.87) for the canonical ensemble. To evaluate the remaining terms in Eq. (21.58),
we make use of a Maxwell relation derived from Eq. (21.32), namely
∂(⟨N⟩/λ)
∂β

λ,V
= −
 ∂U
∂λ

β,V
,
(21.59)
which becomes
∂⟨N⟩
∂β

λ,V
= −
 ∂U
∂ln λ

β,V
= −1
β
∂U
∂μ

β,V
.
(21.60)
But
∂U
∂μ

β,V
=
 ∂U
∂⟨N⟩

β,V
∂⟨N⟩
∂μ

β,V
=
 ∂U
∂⟨N⟩

β,V
β⟨(N)2⟩,
(21.61)
where Eq. (21.50) has been used in the last step. We therefore obtain ﬁnally
⟨(E)2⟩= kBT2CV +
 ∂U
∂⟨N⟩

β,V
2
⟨(N)2⟩.
(21.62)
Equation (21.62) shows that the energy dispersion is the sum of two terms, the ﬁrst term
being the same as for the canonical ensemble and the second term arising from dispersion
of the number of particles in the system.
21.2 Ideal Systems: Orbitals and Factorization
The GCE can be used to treat the important case of ideal systems of identical particles that
can be described in terms of single-particle quantum states called orbitals. As deﬁned
by Kittel and Kroemer [6, p. 152], an orbital is a term often used by chemists to denote
a single-particle quantum state characterized by speciﬁcation of the quantum numbers
of its spatial wave function and its spin. A system for which particles interact very weakly
can be approximated by an ideal system in which the particles do not interact at all. For a
system having Ns noninteracting particles, the total wave function can be formed as a sum
of products of the wave functions of the orbitals, [8, p. 116], which requires speciﬁcation
of the numbers (called occupation numbers) of particles that occupy each orbital.
Frequently there is an inﬁnite number of possible orbitals. If the particles are fermions
(half integral spin), the total wave function must be antisymmetric under interchange
of particles, which requires that each orbital be either unoccupied or occupied by only
one particle (the Pauli exclusion principle). If the particles are bosons, the total wave
function must be symmetric under interchange of particles, which allows each orbital to
be unoccupied or multiply-occupied. Classical particles are an approximation to fermions
or bosons in a dilute limit to be discussed below.
We denote each orbital by the single symbol ε which denotes its energy but also carries
the information about all of its quantum numbers, including spin. The number of such
orbitals in a quantum state r of the whole system having Ns particles is denoted by nrs
ε .

Chapter 21 • Grand Canonical Ensemble
369
These occupation numbers, nrs
ε , completely specify the state of the system. Since the
particles are identical, we cannot distinguish which particles are in a given orbital. The
energy of a quantum state having Ns particles is then given by6
Ers =

ε
nrs
ε ε,
(21.63)
where

ε
nrs
ε = Ns,
all allowed states r.
(21.64)
The grand partition function is therefore
Z =

s
λNs
∗

r
exp

−β

ε
nrs
ε ε

=

s
∗

r

ε
[λ exp (−βε)]nrs
ε .
(21.65)
For ﬁxed Ns, the allowed values of nrs
ε are constrained by Eq. (21.64) and also by the
constraints for fermions or bosons. The asterisk “∗” on the r sum is intended to remind us
of those constraints. Since, however, all values of r and s are summed over in Eq. (21.65), we
do not need to correlate the values of nrs
ε for a given orbital ε. The double sum over s and the
restricted sum over r can therefore be replaced a single sum over quantum-mechanically
allowed occupation numbers that are uncorrelated for each orbital ε. The remaining sum
and the product commute, so we obtain
Z =

ε

n
[λ exp (−βε)]n

.
(21.66)
In other words, Z factors into the product of the grand partition functions for the
individual orbitals, each of the form
Z1(ε) :=

n
[λ exp (−βε)]n.
(21.67)
In Eq. (21.67), n is only constrained by the rules for occupation of orbitals by fermions
(n = 0, 1) or bosons (n = 0, 1, 2, 3, . . .), depending on which kind of particles we are
considering. Speciﬁcally,
Z =

ε
Z1(ε),
(21.68)
so contributions of the orbitals to ln Z and physical properties are simply additive. Any
restrictions of orbital occupation were already taken into account in computing Z1(ε).
Alternatively, Eq. (21.68) can be justiﬁed on physical grounds, a point of view taken by
Kittel and Kroemer [6, p. 154]. They consider all but one orbital to be part of the reservoir
6Here, we have used a shorthand notation Ers ≡Er(Ns) and nrs
ε ≡nr
ε(Ns). For the vacuum state Ns = 0, all
occupation numbers nr
ε(Ns = 0) = 0, in which case Eq. (21.63) gives Er(Ns = 0) = 0. This is consistent with the
convention Z(Ns = 0) = 1 used to establish Eq. (21.25).

370
THERMAL PHYSICS
with which that orbital interacts, and thus calculate its grand partition function separately.
For the entire system, they appeal to additivity over ε of ln Z1(ε), so that
ln Z =

ε
ln Z1(ε),
(21.69)
which is equivalent to Eq. (21.68). In a similar spirit, they also present examples [6, pp. 140-
146] in which the general formula for Z is applied to noninteracting subsystems that can
be unoccupied or occupied by one or two particles. The resulting partition function is
used to calculate the probability of each state. A similar example is presented by Callen [2,
p. 389] in which sites on a surface can be empty, singly occupied or doubly occupied
by adsorbed gas molecules, and factorization of the grand partition function is assumed
because the sites are so sparsely distributed that they do not interact.
We can generalize these examples as follows. If Z(ν)(β, λ) are the grand partition
functions for a set of subsystems labeled by ν and such subsystems are independent and
have negligible interaction energy, the grand partition function for the entire system is
Z =

ν
Z(ν)(β, λ);
ln Z =

ν
ln Z(ν)(β, λ),
(21.70)
where
Z(ν)(β, λ) =

n
λn 
r
exp(−βε(ν)
r n).
(21.71)
Each subsystem is in equilibrium with the reservoir and therefore with each other. Note
that Eq. (21.71) is more general than Eq. (21.67) because the energies ε(ν)
r n do not have to be
multiples of the same quantity ε.
21.2.1 Factorization for Independent Sites
In this section, we present several examples of factorization of the grand partition function
for cases in which particles can reside on a number Ntot of noninteracting sites that
can be occupied by one or more particles. This would be expected if such sites are
sufﬁciently dilute; they are separated by distances that are large relative to the range of
forces applicable to each site. In these examples, we shall suppose for simplicity that the
chemical potential μ, and hence the activity λ = exp(βμ) is imposed by a classical ideal
monatomic gas.
Example Problem 21.2. Calculate the probability of adsorption of an ideal gas on Ntot
independent sites that are either unoccupied, with energy zero, or singly occupied with
energy ε1.
Solution 21.2. The grand partition function for a single site is Z(1) = 1 + λ e−βε1 so the total
grand partition function is Z = (Z(1))Ntot. The average number of adsorbed atoms, which in
this case happens to equal the number of occupied sites, is

Chapter 21 • Grand Canonical Ensemble
371
⟨N⟩= λ∂q
∂λ = Ntot
λ e−βε1
1 + λ e−βε1
(21.72)
and the average energy is
U = −∂q
∂β = Ntot
ε1λ e−βε1
1 + λ e−βε1 .
(21.73)
Except for the very important factors of λ, Eq. (21.73) resembles the energy for independent two-
state systems. In order for the gas to adsorb at low temperatures, we want ε1 < 0. The fraction of
occupied sites is θ = ⟨N⟩/Ntot, so
θ =
λ e−βε1
1 + λ e−βε1 = λ e−βε1
Z(1)
.
(21.74)
Of course the fraction of unoccupied sites is 1 −θ = 1/Z(1), so these results could have
been deduced entirely from the ratios of the corresponding terms in Z(1) to Z(1) itself. From
Eq. (19.66), the chemical potential of an ideal gas is μ = kBT ln(n/nQ) = kBT ln(p/(nQkBT)),
where n is the number density and nQ(T) = (mkBT/2π¯h2)3/2 is the quantum concentration.
The absolute activity is therefore
λ =
n
nQ(T) =
p
nQ(T)kBT ,
(21.75)
which is the ratio of the actual pressure to a quantum pressure. We can therefore deﬁne a
temperature-dependent pressure
p0(T) := nQ(T)kBT eβε1 = nQ(T)kBT e−β|ε1|,
(21.76)
for ε1 < 0, which increases with temperature. Then Eq. (21.74) takes the simple form
θ =
p
p0 + p.
(21.77)
Equation (21.77) has the form of a Langmuir adsorption isotherm and is plotted in Figure 21–1.
See Kittel and Kroemer [6, p. 142] for a plot of data for adsorption of an oxygen molecule by a
heme group of myoglobin, which closely follows such an isotherm.
2
4
6
8
10
0.2
0.4
0.6
0.8
1
p/p0
θ
θ
2
4
6
8
10
0.2
0.4
0.6
0.8
1
p, arbitrary units
FIGURE 21–1 Langmuir adsorption isotherms for the fractional adsorption of an ideal gas on Ntot independent
sites. The curves on the right correspond to temperatures in the ratios 1:4:8, from left to right.

372
THERMAL PHYSICS
Example Problem 21.3. Calculate the probability of adsorption of an ideal gas on Ntot in-
dependent sites that are either unoccupied, with energy zero, or singly occupied with partition
function z(T). What is the canonical partition function ZN for a system having N occupied
sites?
Solution 21.3. The grand partition function for a single site is
Z(1) = 1 + λz(T),
(21.78)
so Eq. (21.77) still applies; however, the pressure in Eq. (21.76) is replaced by
p0(T) := nQkBT/z(T).
(21.79)
The canonical partition function for N
adsorbed atoms is the coefﬁcient of λN
in
Z = (Z(1))Ntot which is readily found from the binomial theorem to be
ZN =
Ntot!
N!(Ntot −N)![z(T)]N .
(21.80)
The binomial coefﬁcient accounts for the degeneracy that arises because we do not know which
of the Ntot sites are occupied, but they are distinguishable by virtue of their position. The reader
is invited to verify that the chemical potential for such a system is
μ = −kBT ∂ln ZN
∂N
= kBT ln

N
Ntot −N
1
z(T)

= kBT ln

θ
1 −θ
1
z(T)

.
(21.81)
Equating this μ to that of a classical ideal gas, Eq. (21.75), gives p/p0(T) = θ/(1 −θ)
with p0(T) given by Eq. (21.79). Then solving for θ gives the consistent result Eq. (21.77).
Example Problem 21.4. Calculate the probability of adsorption of a monatomic ideal gas
on Ntot independent sites that are either unoccupied with energy zero or singly occupied with
energy ε1 or doubly occupied with energy ε2. Note that ε2 is not necessarily equal to 2ε1, so
atoms on a doubly-occupied site can interact.
Solution 21.4. The grand partition function for a single site is Z(1) = 1 + λ e−βε1 + λ2 e−βε2.
The probabilities of a site being unoccupied, singly occupied, or doubly occupied are
p0 = 1/Z(1);
p1 = λ e−βε1/Z(1);
p2 = λ2 e−βε2/Z(1).
(21.82)
The average number of adsorbed gas atoms is therefore ⟨N⟩= Ntot(p1 + 2p2), where the factor
of 2 enters because of the double occupancy. Alternatively, one can use the total grand partition
function Z = [Z(1)]Ntot to calculate
⟨N⟩= λ∂q
∂λ = Ntot
λ e−βε1 + 2λ2 e−βε2
1 + λ e−βε1 + λ2 e−βε2 ,
(21.83)

Chapter 21 • Grand Canonical Ensemble
373
where the factor of 2 occurs automatically, or
U = −
 ∂q
∂β

λ
= Ntot
ε1λ e−βε1 + ε2λ2 e−βε2
1 + λ e−βε1 + λ2 e−βε2
(21.84)
where there is no such factor of 2.
Example Problem 21.5. Calculate the probability of adsorption of either an A atom or a B
atom on Ntot independent sites that are either unoccupied with energy zero or singly occupied
with energies εA and εB, respectively.
Solution 21.5. See Eq. (21.169) for an obvious generalization of the GCE to a binary system.
In the present case, we have
Z(1) = 1 + λA e−βεA + λB e−βεB.
(21.85)
Thus the fractional occupations are
θA =
λA e−βεA
1 + λA e−βεA + λB e−βεB ;
θB =
λB e−βεB
1 + λA e−βεA + λB e−βεB ,
(21.86)
and the fraction of unoccupied sites is 1 −θA −θB. We would have to determine λA and λB from
the chemical potentials of the environment, say ideal gases of A and B. We see in this case that
the A and B atoms compete for occupancy of the sites. Moreover, a small difference between εA
and εB can make an enormous difference between the relative adsorption of A and B if |βεi| ≫1.
For the examples in this section, Z = (Z(1))Ntot, so viewed as a series in powers of λ,
the series cuts off after a ﬁnite number of terms. For the ﬁrst two examples, the highest
power is (λ)Ntot and for the third example it is (λ)2Ntot. These cutoffs occur because of the
restrictions on maximum occupancy of a site. In terms of the general formula Eq. (21.21),
they can be imposed formally by assuming that any state of the entire system having
greater occupancy than allowed would have an inﬁnite energy, so its Boltzmann factor
would be zero. On the other hand, for ideal Fermi and Bose gases, there are an inﬁnite
number of orbitals available for occupation, so the expression for Z for those gases
contains all powers of λ, as shown in the next section.
21.2.2 Fermi-Dirac Distribution
For a single orbital of a gas of noninteracting fermions, Eq. (21.67) becomes
Z1(ε) :=

n=0,1
[λ exp (−βε)]n = 1 + λ exp (−βε).
(21.87)
The average number of particles that occupy that orbital is therefore
fFD(ε) :=
λ exp (−βε)
1 + λ exp (−βε) =
1
λ−1 exp(βε) + 1 =
1
exp[β(ε −μ)] + 1,
(21.88)

374
THERMAL PHYSICS
which is known as the Fermi-Dirac distribution function. Equation (21.88) can be de-
duced by inspection or by applying Eq. (21.30) to Z1(ε). If the fermions each have spin
s and no magnetic ﬁeld is present, there will be 2s + 1 orbitals as compared to orbitals
with spin degeneracy ignored. Thus Eq. (21.66) will contain a factor of [Z1(ε)]2s+1 for each
orbital with spin degeneracy ignored, which will contribute (2s + 1) ln Z1(ε) to ln Z. The
total average number of particles in the entire system is therefore
⟨N⟩=

ε
fFD(ε) = (2s + 1)
′

ε
fFD(ε),
(21.89)
where the primed sum is over orbitals with spin degeneracy ignored. In practice, ⟨N⟩is
usually speciﬁed and Eq. (21.89) is used to determine the chemical potential μ, which
turns out to be a function of β and ⟨N⟩/V because the sum will turn out to be proportional
to V. By similar reasoning, the total internal energy is given by
U =

ε
εfFD(ε) = (2s + 1)
′

ε
εfFD(ε).
(21.90)
For the important case of a free electron gas, s = 1/2 so 2s + 1 = 2.
21.2.3 Bose-Einstein Distribution
For a single orbital of a gas of noninteracting bosons, Eq. (21.67) becomes
Z1(ε) :=
∞

n=0
[λ exp (−βε)]n =
1
1 −λ exp (−βε),
(21.91)
where the sum only converges for λ exp (−βε) < 1. The average number of particles that
occupy that orbital can be deduced by applying Eq. (21.30) to Z1(ε) to obtain
fBE(ε) :=
λ exp (−βε)
1 −λ exp (−βε) =
1
λ−1 exp(βε) −1 =
1
exp[β(ε −μ)] −1,
(21.92)
which is known as the Bose-Einstein distribution function. We note that fBE(ε) differs
from fFD(ε) only by a sign, but this difference is crucial. For example, fFD(ε) ≤1 but
fBE(ε) can be greater than 1, reﬂecting the possible multiple occupancy of boson orbitals.
Moreover, for ε = μ, fFD = 1/2, which presents no problem, but fBE = ∞, which cannot be
allowed.7 In the absence of a magnetic ﬁeld, each energy level has a degeneracy of 2s + 1
due to spin, which can be treated in a manner similar to that for fermions. We therefore
have
⟨N⟩=

ε
fBE(ε) = (2s + 1)
′

ε
fBE(ε)
(21.93)
and
U =

ε
εfBE(ε) = (2s + 1)
′

ε
εfBE(ε).
(21.94)
7The minimum value of ε −μ can be related to the phenomenon of Bose condensation in the ground state.

Chapter 21 • Grand Canonical Ensemble
375
21.2.4 Classical Ideal Gas
A classical ideal gas can be thought of as a quantum ideal gas, of either fermions or bosons,
in the limit of high temperature and low density. In particular, the temperature must be
so high (β so small) and the density so low that the ratio of the number of particles to
the number of accessible single particle states is very small. In other words, the average
number of particles that occupy a single orbital must be small. This will be true for either
fFD or fBE provided that
λ−1 exp(βε) = exp[β(ε −μ)] ≫1
(21.95)
for all ε at small β. This restriction is most severe for ε = 0, so it requires λ = exp(μβ) ≪1
in the limit of small β and low density. If Eq. (21.95) holds, then either fFD or fBE becomes
the classical occupation number
fCL(ε) = exp(βμ) exp(−βε).
(21.96)
We can evaluate the factor exp(βμ) by applying Eq. (21.89) or (21.93) but for fCL. Thus
⟨N⟩=

ε
fCL(ε) = exp(βμ)

ε
exp(−βε),
(21.97)
which yields
exp(βμ) = ⟨N⟩
z ,
(21.98)
where
z =

ε
exp(−βε) = (2s + 1)
′

ε
exp(−βε)
(21.99)
is the canonical partition function for a single particle. Hence,
fCL(ε)
⟨N⟩
= exp(−βε)
z
.
(21.100)
The left-hand side of Eq. (21.100) is the probability of ﬁnding a particle in the orbital
(quantum state including spin) corresponding to ε and the right-hand side is the familiar
Boltzmann distribution, the same as given by Eq. (18.11).
As a further bonus, we can use Eq. (19.56) that applies for particles without spin to
give the single free particle partition function z = (2s + 1)VnQ, where V is the volume and
nQ(T) = (mkBT/2π¯h2)3/2 is the quantum concentration. Substitution into Eq. (21.98) gives
βμ = ln
⟨N⟩
V
1
nQ(T)

−ln(2s + 1)
(21.101)
in agreement with Eq. (19.66) for s = 0. The second term in Eq. (21.101) arises because
of the spin degeneracy, which has no classical counterpart and which also contributes a
term NkB ln(2s + 1) to the entropy. The above condition λ = exp(βμ) ≪1 is seen to be
equivalent to ⟨N⟩/(VnQ) ≪1, which is true if the actual concentration n = ⟨N⟩/V is small
compared with the quantum concentration nQ(T). This will be true for low density and

376
THERMAL PHYSICS
high temperature. It serves to quantify the sense in which the gas is dilute, which is the
same condition discussed immediately following Eq. (19.59).
In this same approximation, we can evaluate the canonical partition function ZN for a
system having exactly N particles. For a Fermi gas, we have
ln Z = ln

ε
{1 + exp[β(μ −ε)]} ,
(21.102)
whereas for a Bose gas
ln Z = ln

ε
1
{1 −exp[β(μ −ε)]}.
(21.103)
These can be combined and rewritten in the form
ln Z = ±

ε
ln {1 ± exp[β(μ −ε)]} .
(21.104)
For a classical ideal gas for which λ ≪1 holds, we can expand the logarithm in Eq. (21.104)
to obtain
ln Z =

ε
exp[β(μ −ε)] = λz = ⟨N⟩,
(21.105)
where Eq. (21.98) has been used in the last step. Therefore,
Z = eλz =
∞

N =0
λN zN
N! .
(21.106)
Comparison with Eq. (21.21) shows that
ZN = zN
N!
(21.107)
in agreement with Eq. (19.48). Since ln Z = pV/(kBT), we observe that Eq. (21.105) is
equivalent to the ideal gas law.
21.2.5 Fermi, Bose, and Classical Gases
As shown by Pathria [8, p. 134], the main results for ideal Fermi, Bose, and classical gases
can be summarized conveniently as follows. One invents a parameter a that takes on the
values a = 1 for the Fermi gas, a = −1 for the Bose gas, and a = 0 for the classical gas. Then
the distribution function
f (ε; a) :=
1
λ−1 exp(βε) + a =
1
exp[β(ε −μ)] + a
(21.108)
encompasses all three results. The three distribution functions are plotted as a function of
β(ε −μ) in Figure 21–2. The consolidated formula
ln Z = 1
a

ε
ln {1 + aλ exp(−βε)} = 1
a

ε
ln {1 + a exp[β(μ −ε)]}
(21.109)

Chapter 21 • Grand Canonical Ensemble
377
-2
-1
1
2
3
0.5
1
1.5
2
2.5
3
fFD(ε) = f(ε; 1 )
fCL(ε) = f(ε; 0 )
fBE(ε) = f(ε;−1)
β(ε−μ)
FIGURE 21–2 Plots of the distribution functions for ideal Fermi, classical, and Bose gases as a function of β(ε −μ).
Note that the three distributions merge for large values of β(ε −μ) which is the same as the limit λ−1 ≫1.
can be written for the function q = ln Z. For a = ± 1 we obtain Eq. (21.104) but for a →0
the formal limit is
ln Z =

ε
λ exp(−βε) = λz,
(21.110)
where z is the canonical partition function for a single particle, in agreement with
Eq. (21.105). Note that we need λ ≪1 to be in the classical limit.
Following Pathria [8, p. 137], we can use these consolidated formulae to get an
interesting general equation for the pressure of any of these gases. From Eq. (21.38) we
have
p =
1
βV q =
1
βV
1
a

ε
ln

1 + aλ exp(−βε)

.
(21.111)
For a system with very large volume, the energy levels are quasi-continuous and we can
replace the summation with integration over k according to Eq. (19.55), although we must
add a spin degeneracy factor g0 = 2s + 1. Thus we obtain
p =
g0
β(2π)3
1
a
 ∞
0
ln

1 + aλ e−βε(k)
4πk2 dk.
(21.112)
We write k2 = (d/dk)k3/3 and integrate by parts to obtain
p =
g0
2aβπ2

ln

1 + aλ e−βε(k) k3
3

∞
0
−
 ∞
0
k3
3
d
dk ln

1 + aλ e−βε(k)
dk

.
(21.113)
The integrated part vanishes and we are left with
p = g0
6π2
 ∞
0
λ e−βε(k)

1 + aλ e−βε(k)k dε(k)
dk k2 dk = g0
6π2
 ∞
0
f (ε; a)k dε(k)
dk k2 dk.
(21.114)

378
THERMAL PHYSICS
Similarly, from Eq. (21.30) we have
⟨N⟩= λ ∂
∂λ
1
a

ε
ln

1 + aλ exp(−βε)

= g0V
2π2
 ∞
0
f (ε; a) k2 dk.
(21.115)
Then Eqs. (21.114) and (21.115) can be combined to give
p = ⟨N⟩
3V

k dε(k)
dk

,
(21.116)
where

k dε(k)
dk

≡
 ∞
0 f (ε; a)[kdε(k)/dk]k2 dk
 ∞
0 f (ε; a)k2 dk
(21.117)
is an average value of kdε(k)/dk. In simple cases for which ε(k) ∝ks, where s is a constant,
we have kdε(k)/dk = sε(k) which yields
p = ⟨N⟩
3V s

ε(k)

= s
3u,
(21.118)
where u = U/V is the energy density. For a nonrelativistic particle in a box, s = 2 and we
have the result p = 2u/3. This result is familiar for a classical ideal gas (see Eq. (19.78)), for
which ⟨ε⟩= (3/2)kBT and p = NkBT/V, but we see that it is also true for an ideal Fermi
gas and an ideal Bose gas. For a particle in a box in the extreme relativistic limit, s = 1 and
we have the result p = u/3.
21.2.6 Orbital Populations for Ideal Gases
We can apply Eq. (21.30) for ⟨N⟩and Eq. (21.50) for ⟨(N)2⟩to the case of ideal Fermi
or Bose gases, for which the grand partition function factors, as represented generally by
Eq. (21.68). Since Z1(ε) is a function of only the variable β(μ −ε) and β is held constant in
the derivatives that follow, we note that
∂Z1(ε)
∂μ

V,β,ε
= −
 ∂Z1(ε)
∂ε

V,β,μ
.
(21.119)
Thus
⟨N⟩= 1
β
∂ln Z
∂μ
= 1
β

ε
∂ln Z1(ε)
∂μ
= −1
β

ε
∂qε
∂ε =

ε
⟨nε⟩,
(21.120)
where qε := ln Z1(ε) and
⟨nε⟩:= −1
β
∂qε
∂ε

V,β,μ
.
(21.121)
Similarly,
⟨(N)2⟩= 1
β2
∂2 ln Z
∂μ2
= 1
β2

ε
∂2 ln Z1(ε)
∂μ2
= 1
β2

ε
∂2qε
∂ε2 =

ε
⟨(nε)2⟩,
(21.122)

Chapter 21 • Grand Canonical Ensemble
379
where
⟨(nε)2⟩:= −1
β
∂⟨nε⟩
∂ε

V,β,μ
.
(21.123)
Thus the average number of particles and its variance are additive over the orbitals labeled
by ε. According to Eq. (21.104), we have explicitly8
⟨nε⟩=
1
exp[β(ε −μ)] ± 1
(21.124)
and
⟨(nε)2⟩
⟨nε⟩2
= exp[β(ε −μ)] =
1
⟨nε⟩∓1.
(21.125)
For a classical ideal gas, we would have ⟨nε⟩≪1 so the ∓1 in Eq. (21.125) is negligible.
This is called a normal ﬂuctuation. For fermions, the result is 1/⟨nε⟩−1 which nearly
vanishes for temperatures sufﬁciently low that kBT ≪μ −ε > 0, in which case ⟨nε⟩≈1.
Such ﬂuctuations are called infranormal or subnormal. For bosons, the result is 1/⟨nε⟩+ 1
which is above normal or extranormal.
For classical ideal gases, the populations follow a Poisson distribution. This can be
seen by returning to Eq. (21.105) from which we obtain
Z = exp⟨N⟩=
∞

N =0
⟨N⟩N
N!
.
(21.126)
Since ⟨N⟩is proportional to λ, the probability of exactly N, for the entire ensemble, is the
Nth term in this sum divided by Z, namely
PN = ⟨N⟩N
N!
exp(−⟨N⟩),
(21.127)
which is a Poisson distribution. From Eq. (21.110),
ln Z1(ε) = λ exp(−βε) = ⟨nε⟩
(21.128)
according to Eq. (21.124). Therefore,
Z1(ε) = e⟨nε⟩=

nε
⟨nε⟩nε
nε! .
(21.129)
The probability of occupation of the orbital ε is therefore
pnε = ⟨nε⟩nε
nε!
exp(−⟨nε⟩),
(21.130)
which is also a Poisson distribution.
8The upper sign is for fermions and the lower sign is for bosons.

380
THERMAL PHYSICS
Example Problem 21.6. Compare the occupation probabilities of orbitals for fermions,
bosons, and classical particles and discuss the limit where they become essentially the same.
Solution 21.6. For simplicity, we deﬁne γ = λ exp(−βε). For fermions, there are only two
probabilities, p0 = 1/(1+γ ) and p1 = γ /(1+γ ). For bosons, one has pn = γ n(1−γ ). For classical
particles pn = γ n exp(−γ )/n!. The result for classical particles is only valid for γ ≪1. In that
limit, all three distributions become approximately p0 = 1 −γ , p1 = γ , and pn = 0,n ≥1.
Thus, when conditions for a classical gas are valid, there is essentially no double occupancy
of orbitals, which explains why the Gibbs correction factor of N! leads to the correct partition
function.
21.3 Classical Ideal Gas with Internal Structure
In Sections 21.2.4 and 21.2.5, we treated ideal gases without internal structure, except for
spin, which was necessary to distinguish between Fermi and Bose gases and which led to
a degeneracy factor of 2s + 1. In the present section, we show how to treat gases whose
particles are atoms or molecules having internal structure, not only due to nuclear spin
but also due to electronic and molecular structure.
We return to Eq. (21.105) and expand the notation such that ε →εt + εi, where εt is the
energy due to translation and εi is due to internal structure, including nuclear spin and
electronic and molecular structure. We assume that these energies are separable, which
means that the internal degrees of freedom are not affected by translation and vice versa.
Thus we obtain
ln Z =

t,i
exp[β(μ −εt −εi)] = λzintzt = ⟨N⟩,
(21.131)
where the translational partition function is
zt =

t
exp(−βεt) = VnQ
(21.132)
and the internal partition function is
zint =

i
exp(−βεi).
(21.133)
Thus Eq. (21.107) holds with z replaced by zintzt, resulting in
Z = (zintzt)N
N!
.
(21.134)
The corresponding Helmholtz free energy is
F = −NkBT[ln(VnQ/N) + 1] −NkBT ln zint.
(21.135)

Chapter 21 • Grand Canonical Ensemble
381
We see that the effect of the internal structure is additive. In the case that zint is only due
to spin degeneracy, we have zint = 2s +1 and we can recover Eq. (21.101) by taking ∂/∂N of
Eq. (21.135).
For a gas of molecules or of atoms having structure, one usually assumes that the elec-
tronic, vibrational, rotational, and nuclear degrees of freedom are decoupled from each
other. This is based partly on the Born-Oppenheimer approximation, which is supposed to
hold because nucleons are more massive and move more slowly than electrons. Therefore,
the internal partition function factors to give
zint = zeleczvibznuczrot
(21.136)
so we have
ln zint = ln zelec + ln zvib + ln znuc + ln zrot.
(21.137)
In other words, the contributions of the internal degrees of freedom are additive. However,
in the case of homonuclear molecules (e.g., H2 that we treat later) it is important to
correlate the nuclear and rotational partition functions such that the product znuczrot is
replaced by znuc−rot which is based on antisymmetric wave functions for fermions and
symmetric ones for bosons.
21.3.1 Monatomic Gas
For a monatomic gas, we only have to deal with the nuclear and electronic partition
functions. To avoid any ambiguity, we choose the zero of energy to be the nuclear and
electronic ground state, as well as zero translational energy.
The hyperﬁne structure due to the nuclear spin has energy splittings that are very small
compared to kBT in most cases of interest, so znuc = 2I + 1, where I is the nuclear spin.
There is no contribution to the energy and the heat capacity, but the entropy is changed
by NkB ln(2I+1). The free energy and chemical potential are changed by −NkBT ln(2I+1)
and −kBT ln(2I + 1), respectively.
The value of zelec due to the electronic structure depends on the electronic orbital
angular momentum L and the electronic spin angular momentum S. If L = S = 0, the state
is nondegenerate and zelect = 1. If L = 0 but S ̸= 0, which is typical of alkali atoms such as
Na, K, and Rb, there is no ﬁne structure and we have zelect = 2S + 1 due to electronic spin
degeneracy. In the general case, L ̸= 0 and S ̸= 0, we have
zelect =

εelect
exp(−βεelect),
(21.138)
where the sum is over all electronic states, having energies εelect. Usually, only the ground
state of degeneracy g0e and the ﬁrst excited state of degeneracy g1e and energy e are
important because the rest of the states have such high energies that they are practically
unoccupied. It is therefore often sufﬁcient to take
zelect = g0e + g1e exp(−βe).
(21.139)

382
THERMAL PHYSICS
This leads to contributions to the energy and the heat capacity of the forms
Uelect = Ne
g1e exp(−βe)
g0e + g1e exp(−βe)
(21.140)
and
Celect = NkB(βe)2
g0eg1e exp(−βe)
[g0e + g1e exp(−βe)]2 .
(21.141)
This electronic heat capacity is zero at low temperatures, passes through a maximum, and
then decays again to zero at high temperatures, assuming that no higher energy levels
come into play. Contributions to the entropy and the chemical potential are
Select = NkB ln[g0e + g1e exp(−βe)] + NkBβe
g1e exp(−βe)
g0e + g1e exp(−βe)
(21.142)
and
μelect = −kBT ln[g0e + g1e exp(−βe)].
(21.143)
For future reference, the entire internal partition function is given approximately by
zint = zelectznuc = [g0e + g1e exp(−βe)](2I + 1).
(21.144)
21.3.2 Diatomic Molecular Gas
For diatomic molecules, we take the zero of energy to be the nuclei in their ground
states and the atoms to be in their electronic ground states for a completely dissociated
molecule, that is, inﬁnite separation of the atoms. Homonuclear diatomic molecules are
indistinguishable if rotated 180◦about their center of mass, thus exchanging identical
particles. Therefore, their nuclear and rotational partition functions must be correlated
to satisfy requirement of quantum statistics. No such requirements exist for heteronuclear
molecules because their nuclei are distinguishable. Therefore, we ﬁrst treat the simpler
case of heteronuclear molecules and then treat homonuclear molecules.
Heteronuclear Molecules
For heteronuclear diatomic molecules AB, composed of A and B atoms, the nuclei remain
in their ground states so the nuclear partition function znuc = (2IA + 1)(2IB + 1) only
accounts for degeneracy.
The relevant electronic structure is now that of the molecule. This is usually described
in terms of a potential that is strongly repulsive (positively inﬁnite) at short distances of
separation, becomes negative reaching the bottom of a potential well at a negative energy
ε0m = −D, and then rises to zero at inﬁnite separation. Usually one needs to consider
only the electronic ground state and the ﬁrst excited state, having energy ε1m, because

Chapter 21 • Grand Canonical Ensemble
383
occupation of higher molecular electronic states would lead to dissociation. Therefore,
the electronic partition function of the molecule can be represented approximately by
zelect = exp(βD)[g0m + g1m exp(−βm)],
(21.145)
where m = ε1m −ε0m is the separation between the ﬁrst excited electronic state and the
electronic ground state, and g0m and g1m are the respective degeneracies. This expression
resembles Eq. (21.139) for the monatomic gas except for the prefactor exp(βD) that arises
because of the depth of the potential well. Since
ln zelect = βD + ln[g0m + g1m exp(−βm)],
(21.146)
the only contribution of the factor exp(βD) is to add an energy −D per molecule. The
remaining term in Eq. (21.146) makes contributions exactly analogous to those made by
zelect for the monatomic case.
A new effect, however, comes from vibrations about the equilibrium separation of the
atoms, giving rise to quantum states that can be approximated by those of a harmonic
oscillator with nondegenerate energy levels (1/2 + n)¯hω0, where n is zero or a positive
integer and ω0 is the angular frequency of vibration. The partition function is
zvib = exp(−v/2T)
1
1 −exp(−v/T),
(21.147)
where v := ¯hω/kB is a characteristic temperature. The contribution to the total energy is
therefore
Uvib = NkBv/2 + N
kBv
exp(v/T) −1.
(21.148)
Here again, the prefactor exp(−v/2T) in the partition function just adds a constant
energy kBv/2 = ¯hω0/2 per molecule. The cumulative shift in the energy per molecule
from the dissociated state, which was taken as the zero of energy, is therefore −(D−¯hω0/2).
Typical measured values are D−¯hω0/2 ≈1 to 10 eV per molecule. The corresponding heat
capacity is given by Eq. (18.54) which we rewrite in the form
Cvib = NkB
(v/T)2 exp(v/T)
[exp(v/T) −1]2 .
(21.149)
Figure 18–8 depicts a graph of this heat capacity versus temperature. Typical values of
this characteristic vibration temperature are v = 1000 to 4000 K, which corresponds to
an energy of about 0.1-0.3 eV. For T ≪v, which is typical, we have Cvib ≈0 and the
vibrational mode is said to be “frozen out.” For high temperatures, Cvib ≈NkB and the heat
capacity would be increased by a constant amount. However, the molecule will probably
dissociate before one observes the maximum heat capacity due to vibration.
Most interesting are the rotational degrees of freedom, for which we will treat the atoms
as point particles. Classically, we can think of such a degree of freedom as a rotation of a
rigid diatomic molecule about an axis perpendicular to the line joining the atoms and
passing through the center of mass of the molecule. There are two degrees of freedom of

384
THERMAL PHYSICS
this rotation because we must consider rotations about two perpendicular axes, each also
perpendicular to the axis separating the atoms. The quantum energy levels are
εrot(j) = j(j + 1)ε0,
(21.150)
where ε0 = ¯h2/(2I) and the moment of inertia I = ℓ2
0m1m2/(m1 + m2) for atoms of masses
m1 and m2 separated by a distance ℓ0. Each energy level has degeneracy 2j + 1. This prob-
lem was treated in Section 18.4 and the corresponding heat capacity is depicted in Figure
18–12. We deﬁne r := ε0/kB = ¯h2/(2IkB). For T ≪r, Crot ≈0 and the rotation does
not contribute, whereas for T ≫r, Crot ≈NkB and the rotation contributes (1/2)kB per
molecule for each of its two rotational degrees of freedom, consistent with equipartition.
For most diatomic molecules, r is only a few Kelvin degrees [61, p. 92], so the rotational
mode is fully excited and the total heat capacity due to rotation is
Crot = NkB,
diatomic molecules, T ≫r.
(21.151)
Since typically r ≪v, the heat capacity at constant volume for a classical ideal gas
composed of diatomic molecules varies with temperature as follows: For temperatures
high enough to be treated as a classical gas, the heat capacity has the translational value
(3/2)NkB, rises after a slight overshoot9 to (5/2)NkB at temperatures above r, and
ﬁnally rises to (7/2)NkB for temperatures above v. This behavior is sketched in Figure
21–3 under conditions for which all temperature ranges are accessible. In a practical
temperature range, however, one might only observe the value (5/2)NkB.
CV/(NkB)
Rotation
Translation
Vibration
3/2
5/2
7/2
log T
FIGURE 21–3 Sketch of the heat capacity CV in units of N kB of a diatomic molecule as a function of log T. The
ﬁrst level at 3/2 at low temperatures T < r results from translational degrees of freedom. The second level at
5/2 at intermediate temperatures r < T < v results from translation plus rotation. The ﬁnal level at 7/2 at high
temperatures v < T results from translation, rotation, and vibration. Since r is typically a few degrees K and
v is typically a few thousand degrees K, only the middle value 5/2 is usually observed. This simple picture omits
corrections due to the electronic degrees of freedom, which are similar in form to those for a monatomic gas,
Eq. (21.142).
9See Section 18.4 for details and a graph.

Chapter 21 • Grand Canonical Ensemble
385
For an excellent and more detailed treatment of heteronuclear diatomic molecules,
including data for a number of actual molecules, see McQuerrie [54, p. 91].
Homonuclear Molecules
The situation for homonuclear molecules, such as hydrogen H2 or deuterium D2 is more
complicated because quantum statistics for fermions and bosons comes into play and
requires correlation of znuc and zrot to produce a net result znuc−rot that corresponds to
a wave function that has the correct symmetry under interchange of the nuclei. In case
the nuclei are fermions, as for H2, the Pauli exclusion principle applies so the total wave
function must be antisymmetric under interchange of the nuclei. This requires each net
spin state of the combined nuclei to be paired with a rotational state that has the correct
symmetry.
For H2, each nucleus has spin 1/2 so the combined nuclear spin states have spin
components |1⟩, |0⟩, and | −1⟩. The states corresponding to |1⟩and | −1⟩come from
|1/2, 1/2⟩and | −1/2, −1/2⟩and are symmetric. Of the states corresponding to |0⟩, one is
(|1/2, −1/2⟩+|−1/2, 1/2⟩)/
√
2 and is symmetric; the other is (|1/2, −1/2⟩−|−1/2, 1/2⟩)/
√
2
and is antisymmetric. Rotational states are symmetric and antisymmetric according to
whether j is even or odd. So we have to pair the three symmetric spin states with odd-j
rotational states and the one antisymmetric spin state with even-j rotational states. These
rotational partition functions are
zrot(even) :=

j=0,2,4,...
(2j + 1) exp[−βj(j + 1)ε0]
(21.152)
and
zrot(odd) :=

j=1,3,5,...
(2j + 1) exp[−βj(j + 1)ε0].
(21.153)
For H2, the combined partition function would be
znuc−rot(hydrogen) = 3zrot(odd) + zrot(even).
(21.154)
If each nucleus has spin I, then (I + 1)(2I + 1) of the combined spin states have even
symmetry and I(2I + 1) have odd symmetry under interchange of the nuclei.10
Thus more generally,
znuc−rot(fermions) = (I + 1)(2I + 1)zrot(odd) + I(2I + 1)zrot(even).
(21.155)
For the case of bosons, the total wave function must be symmetric under interchange
of atoms. Deuterium is a boson with spin 1; of the combined spin states, six are symmetric
and three are antisymmetric. Thus
znuc−rot(deuterium) = 6zrot(even) + 3zrot(odd).
(21.156)
10The rotational state that goes with the larger weight (I + 1)(2I + 1) is called ortho and the one that goes with
the smaller weight I(2I + 1) is called para.

386
THERMAL PHYSICS
More generally,
znuc−rot(bosons) = (I + 1)(2I + 1)zrot(even) + I(2I + 1)zrot(odd).
(21.157)
At high temperatures, zrot = T/r and zrot(odd) = zrot(even) = T/(2r). Thus at high
temperatures we have
znuc−rot(fermions) = znuc−rot(bosons) ≈(2I + 1)2T/(2r).
(21.158)
Therefore, at high temperatures, the only difference as compared to the heteronuclear
case is division by a factor of σ2 = 2, known as the symmetry number, which affects the
entropy but not the heat capacity.
At lower temperatures, however, the results for fermions and bosons would differ
from one another due to the differences in weightings in Eqs. (21.155) and (21.157). For
hydrogen, the internal energy per molecule due to rotation would be
unuc−rot = −∂ln znuc−rot(hydrogen)
∂β
= 3zrot(odd)urot(odd) + zrot(even)urot(even)
3zrot(odd) + zrot(even)
,
(21.159)
where
urot(odd) = −∂ln zrot(odd)/∂β;
urot(even) = −∂zrot(even)/∂β.
(21.160)
The heat capacity per hydrogen molecule would then be
cnuc−rot = ∂unuc−rot
∂T
= −kBβ2 ∂unuc−rot
∂β
.
(21.161)
Similar expressions for unuc−rot and cnuc−rot but based on Eq. (21.156) would pertain to
deuterium.
Ironically, it turns out that the heat capacity given by Eq. (21.161) does not lead
to agreement with experiments on the heat capacity of hydrogen. The situation for
deuterium is similar. This is apparently due to the fact that samples are prepared at room
temperature which is well above r and they do not re-equilibrate during subsequent
experiments at low temperatures [62]. At high temperatures, zr(odd) ≈zrot(even), so
the contribution to znuc−rot(hydrogen) comes 3/4 from molecules in odd rotational
states and 1/4 from molecules in even rotational states. But at low temperatures,
zrot(odd)/zrot(even) ≈3 exp(−2r/T) ≪1, so znuc−rot(hydrogen) comes almost entirely
from molecules in even rotational states. These molecules would be required to have
antisymmetric spin states. Thus, when hydrogen is cooled from high to low temperatures,
equilibrium would require 3/4 of all molecules to change their spin states from symmetric
to antisymmetric. Such a change requires molecules to collide at container walls [61,
p. 97] and is an extremely slow process. As a result, the gas behaves like a nonequilibrium
mixture in which the proportion of rotational states is the same as at high temperature.
The observed internal energy per molecule of hydrogen due to rotation would
then be
uneq
nuc−rot(hydrogen) = (3/4)urot(odd) + (1/4)urot(even).
(21.162)

Chapter 21 • Grand Canonical Ensemble
387
The corresponding heat capacity would be
cneq
nuc−rot(hydrogen) = (3/4)crot(odd) + (1/4)crot(even),
(21.163)
where
crot(odd) = −kBβ2∂urot(odd)/∂β;
crot(even) = −kBβ2∂zrot(even)/∂β.
(21.164)
For deuterium we would have
cneq
nuc−rot(deuterium) = (2/3)crot(even) + (1/3)crot(odd).
(21.165)
These nonequilibrium values agree with experiment.
21.3.3 Polyatomic Molecular Gas
Polyatomic gas molecules come in many varieties. Each atom has a nuclear spin and
the molecule has an electronic structure. A molecule consisting of n atoms has 3n −5
vibrational degrees of freedom if is a linear molecule (such as CO2) and 3n −6 vibrational
degrees of freedom if it is not a linear molecule (such as CH4 which has C at the center of a
regular tetrahedron with H atoms at each corner).11 The vibrational degrees of freedom
can sometimes be complex (e.g., torsional modes) but can often be treated as normal
modes of vibration, each of which leads to contributions to the energy and heat capacity
of the forms given by Eqs. (21.148) and (21.149).
Generally speaking, one still has T ≪v for all of these vibrational modes; they make
small contributions but must be taken into account to explain experimentally measured
heat capacities. One might also have to take into account a few molecular electronic states.
But the main contribution of the internal structure to the heat capacity usually comes
from the rotational modes. For linear polyatomic molecules, the rotational modes can
be treated in a similar way to diatomic molecules. For polyatomic molecules that are not
linear, there is usually considerable simpliﬁcation because the three principal moments
of inertia (see Appendix F), Ii, of polyatomic molecules are usually sufﬁciently large that
the energy quanta εi := ¯h2/(2Ii) are small compared with kBT. We can therefore evaluate
the partition function in the classical limit, as in Section 20.7. This results in a partition
function of the form (see Eq. (20.116))
zrot = π1/2
2I1kBT
¯h2
1/2 2I2kBT
¯h2
1/2 2I3kBT
¯h2
1/2
.
(21.166)
All we really need to know is that zrot ∝β−3/2 which leads immediately to
crot = −kBβ2 ∂2 ln zrot
∂β2
= 3
2kB
(21.167)
11In both cases, the total number of degrees of freedom is 3n and there are three translational degrees of
freedom. A linear molecule has two rotational degrees of freedom and a nonlinear molecule has three. The
remaining degrees of freedom are generally termed vibrational modes.

388
THERMAL PHYSICS
for each molecule. The total heat capacity of a polyatomic gas, to a good approximation,
is therefore
CV = N 3
2kB + N

vib
cvib + Ncelect + N 3
2kB = 3NkB
plus small corrections.
(21.168)
For molecules that are not heteronuclear, such as CO2 or CH4, one must correct the
partition function by dividing by a “symmetry number” σr that is equal to the number of
indistinguishable rotational states of the molecule, [54, p. 101], but this does not affect the
heat capacity in the high-temperature approximation used above. It does, however, affect
the entropy by an amount −NkB ln σr. For example, CO2 is a linear molecule with σr = 2
because of two indistinguishable rotations of π in orthogonal planes about the carbon
atom. For CH4, σr = 12 because of three indistinguishable rotations of 2π/3 about each of
the four C–H bonds that form a tetrahedron. For a more detailed discussion of polyatomic
molecules, see McQuarrie [54, p. 129].
For polyatomic molecules, it is also possible to deduce high-temperature distribution
functions for the principal angular momenta, Eq. (20.125), and for the vibrational frequen-
cies about the principal axes, Eq. (20.128).
21.4 Multicomponent Systems
The derivation in Section 21.1 can be generalized in a straightforward way to multicompo-
nent systems, which we illustrate for two components, A and B. The probabilities become
PrNA,NB = λNA
A λNB
B
exp[−ErNANB]/Z,
(21.169)
where λA = exp(βμA), λB = exp(βμB) and
Z =

NA

NB

r
λNA
A λNB
B
exp[−ErNANB].
(21.170)
If the interaction energy between A and B particles is negligible and their states can be
occupied independently, as would be the case for ideal gases, then ErNANB = ErANA +ErBNB
and we have factorization which results in
Z = ZAZB,
(21.171)
where
ZA =

NA

rA
λNA
A
exp[−ErANA];
ZB =

NB

rB
λNB
B
exp[−ErBNB].
(21.172)
In this case, the probabilities also factor, so
PrNA,NB = PrA,NAPrB,NB.
(21.173)
For classical ideal gases, we would have ZA = exp(λAzA) and ZB = exp(λBzB) so Eq. (21.171)
would become
Z = exp(λAzA) exp(λBzB) =

NA,NB
λNA
A λNB
B
zNA
A
NA!
zNB
B
NB!.
(21.174)

Chapter 21 • Grand Canonical Ensemble
389
The coefﬁcient of λNA
A λNB
B
is therefore the canonical partition function for exactly NA
particles of A and NB particles of B, namely
Z = zNA
A
NA!
zNB
B
NB!.
(21.175)
21.5 Pressure Ensemble
The pressure ensemble can be obtained by using the same procedure as used to derive the
GCE. It applies to a system of interest I with a deﬁnite number of particles N that is held at
constant temperature T and constant pressure p. Thus, the volume Vs of the system I can
vary. This is accomplished by putting I in contact with a thermal and pressure reservoir
R. The total system consisting of I and R is assumed to be isolated and has a ﬁxed energy
ET and a ﬁxed volume VT. The quantum states of I have energies Ers ≡Er(Vs, N). Not
surprisingly, the pressure ensemble will be associated with the thermodynamic function
G, the Gibbs free energy. Since N is ﬁxed, we suppress it in the arguments of the functions
below.
If the system of interest has a deﬁnite volume and is in a deﬁnite quantum state,
its multiplicity function will be (Ers, Vs) = 1, so the probability of that state will be
given by
Prs = R(ET −Ers, VT −Vs)
T(ET, VT)
= exp[SR(ET −Ers, VT −Vs)/kB]
exp[ST(ET, VT)/kB]
,
(21.176)
which should be compared to Eq. (21.2). The denominator pertains to an unrestricted
equilibrium state, so the entropy of the composite system is additive,
ST(ET, VT) = SR(ET −U, VT −V ) + S(U, V ),
(21.177)
where U ≡⟨E⟩is the average energy and V ≡⟨V⟩is the average volume of I. In the
numerator of Eq. (21.176), we write
SR [ET −Ers, VT −Vs] = SR [(ET −U) + (U −Ers), (VT −V ) + (V −Vs)] .
(21.178)
Then we expand in a Taylor series on the basis that |U −Ers|/|ET −U| ≪1 and |V −Vs|/
|VT −V| ≪1 to obtain
SR(ET −Ers, VT −Vs) = SR(ET −E, VT −V ) + (U −Ers)/T + p(V −Vs)/T,
(21.179)
where higher order terms are neglected. Substitution of Eqs. (21.177) and (21.179) into
Eq. (21.176) gives
Prs = exp[G/kBT] exp[−(Ers + pVs)/kBT],
(21.180)
where the Gibbs free energy
G = U −TS + pV.
(21.181)

390
THERMAL PHYSICS
Since Prs are probabilities, summation12 over all r and s gives 
rs Prs = 1, so Eq. (21.180)
yields
exp[−G/kBT] =

r,s
exp[−(Ers + pVs)/kBT] ≡Zp,
(21.182)
where Zp(T, p, N) is the partition function for the pressure ensemble. Then
G = −kBT ln Zp
(21.183)
allows for calculation of the other thermodynamic functions by differentiation, recogniz-
ing that
dG(T, p, N) = −S dT + V dp + μ dN.
(21.184)
From the Euler equation for the Gibbs free energy, G = μN, so the chemical potential is
also given by
μ = −(kBT/N) ln Zp,
(21.185)
which should be compared with the relationship of p to ln Z of the GCE.
Rather than working with G and its derivatives, we can deﬁne a new variable
λp := exp(−βp)
(21.186)
and write the partition function in the functional form
Zp(β, λp, N) =

s
λVs
p

r
exp(−βErs) =

s
λVs
p Z(T, Vs, N),
(21.187)
where Z(T, Vs, N) is the canonical partition function for a system having volume Vs. Note
the similarity of Eqs. (21.187) and (21.21). Then we can deﬁne a function
qp(β, λp, N) := ln Zp(β, λp, N)
(21.188)
whose differential is given by
dqp = −U dβ + (V /λp) dλp −βμ dN.
(21.189)
Equation (21.189) can be veriﬁed by using the chain rule of differentiation to convert
partial derivatives with respect to the set T, p, N to those for the set β, λp, N. This allows
us to calculate the internal energy from a single differentiation, namely,
U = −
∂qp
∂β

λp,N
.
(21.190)
The form of Eq. (21.189) is also obvious if Eq. (21.187) is used to compute averages, for
example,
λp
∂qp
∂λp
=

s λVs
p Vs

r exp(−βErs)

s λVs
p

r exp(−βErs)
=

rs
PrsVs = ⟨V ⟩= V .
(21.191)
12To treat Vs as a continuous variable, we would need to replace summation by integration with a probability
density function for Vs. We use summation here to parallel the treatment of the GCE.

Chapter 21 • Grand Canonical Ensemble
391
21.5.1 Vacancies in Monovalent Crystals
As an application of the pressure ensemble, we can calculate the number of vacan-
cies on substitutional sites in monovalent crystals having a Bravais lattice. Such va-
cancies are point defects known as Schottky defects. They can affect the properties
of crystals such as thermal expansion and diffusion by a vacancy mechanism. For the
sake of simplicity, we will conﬁne ourselves to metals in which ions occupy lattice
sites in a sea of shared electrons. This treatment is a modiﬁcation of that given by
Girifalco [63, p. 195].
For such a crystal at constant temperature T and constant pressure p and having N
ions and Nv vacancies on speciﬁc sites, the probability of being in the quantum state Ers
for a crystal of volume Vs is given by
Prs(N, Nv) =
1
Zp(N, Nv) exp[−β(Ers + pVs)].
(21.192)
By summing over all values of r and s as in Eq. (21.182), we can identify a Gibbs free energy
G0(N, Nv) given by
exp[−βG0(N, Nv)] =

r,s
exp[−β(Ers + pVs)] = Zp(N, Nv).
(21.193)
At this point, we assume that the vacancies are sufﬁciently dilute (to be justiﬁed later)
that they do not interact, so G0(N, Nv) does not depend on which sites are occupied.
However, since the N atoms and Nv vacancies are on speciﬁc sites, G0(N, Nv) does not
account for the conﬁgurational entropy
Sconf(N, Nv) = kB ln w(N, Nv);
w(N, Nv) = (N + Nv)!
N!Nv!
.
(21.194)
We can therefore construct a total Gibbs free energy of the form
G(N, Nv) = G0(N, Nv) −TSconf(N, Nv) = G0(N, Nv) −kBT ln w(N, Nv).
(21.195)
The equilibrium number of vacancies N eq
v
can now be determined by minimizing
G(N, Nv) with respect to Nv. With the aid of Stirling’s approximation, we differentiate with
respect to Nv to obtain
0 = ∂G(N, Nv)
∂Nv

N eq
v
= gv + kBT ln
 
N eq
v
N + N eq
v
!
,
(21.196)
where
gv := ∂G0(N, Nv)
∂Nv

N eq
v
≈∂G0(N, Nv)
∂Nv

Nv=0
.
(21.197)
The last expression follows because N eq
v /N ≪1 as we shall see. Thus
N eq
v
N + N eq
v
= exp[−gv/kBT].
(21.198)

392
THERMAL PHYSICS
Table 21–1
Vacancy and Divacancy Fractions at the
Melting Points of Some FCC Crystals Having N Atoms
(z = 12 Nearest Neighbors) According to Eqs. (21.199)
and (21.207)
FCC crystal
Cu
Ni
Al
TM
1358 K
1728 K
933 K
hv
1.05 eV
1.4 eV
0.65 eV
sv
0.4 kB
1.5 kB
0.8 kB
exp(sv/kB)
1.5
4.5
2.2
N eq
v /N at TM
1.9 ×10−4
3.6 ×10−4
6.8 ×10−4
hb
0.1 eV
0.3 eV
0.3 eV
sb
−
2 kB
1 kB
N eq
d /N at TM
−
8 ×10−7
4 ×10−5
fd
−
0.1%
10%
Notes: fd given by Eq. (21.208) is the fraction of vacant lattice sites due to divacancies.
Data for hv, sv, hb, and sb, where gb = hb −Tsb is the binding free energy of a divacancy,
are from Girifalco [63, p. 217].
The quantity gv is nearly independent of N eq
v
and can be thought of as the Gibbs free
energy needed to create a vacancy by moving an atom from a deﬁnite substitutional site
to the crystal surface. In order of magnitude, we expect gv ∼1 eV. At room temperature,
kBT ∼1/40 eV, so the right-hand side of Eq. (21.198) would be about 4 × 10−18. At
T = 900 K, it would increase to about 6 × 10−6.
Since N eq
v
≪N, it is usual to omit it in the denominator of Eq. (21.198). We can also
write gv = hv −Tsv, where hv is an enthalpy and sv is an entropy, both approximately
constant and associated with a single vacancy at a deﬁnite location. Then Eq. (21.198) can
be written approximately as
N eq
v
= N exp(sv/kB) exp(−hv/kBT),
(21.199)
where hv plays the role of an activation energy. Typically the prefactor exp(sv/kB) ∼1
and N eq
v /N ∼10−4 near the melting point of a crystal. Table 21–1 gives experimentally
determined values of hv and sv for some FCC metals as well as values of N eq
v
at their
melting points.
According to Eq. (21.197), gv is nearly independent of Nv in the range of interest where
vacancies are a dilute species, so G0(N, Nv) ≈G0(N, 0) + gvNv is nearly linear in Nv. Thus
Eq. (21.195) can be written
G(N, Nv) = gvNv −kBT ln w(N, Nv),
(21.200)
where G(N, Nv) ≡G(N, Nv) −G0(N, 0). Equation (21.200) is usually the starting point
of a simpliﬁed treatment of vacancies and will be used in the next section to explore other
point defects.
Nonequilibrium concentrations of vacancies can be obtained by such means as
quenching from a higher temperature or irradiation by neutrons. Such concentrations
might last for a long time, depending on the rate of vacancy diffusion and the proximity of

Chapter 21 • Grand Canonical Ensemble
393
vacancy sinks such as dislocations and grain boundaries. This can result in the formation
of voids. Line defects such as dislocations and area defects such as grain boundaries are
not equilibrium defects because the energy to create them is too large to be offset by
conﬁgurational entropy. They usually result from material preparation, for example, by
crystallization, or by mechanical deformation. Prolonged annealing at sufﬁciently high
temperatures can be used to eliminate some line and surface defects but such a process is
very slow.
21.5.2 Vacancies, Divacancies, and Interstitials
In monovalent crystals, vacancies (v), vacancies in adjacent lattice sites called “divacan-
cies” (d) and ions in voids of the substitutional lattice called “interstitials” (i) can be
considered as point defects. At equilibrium, all of these are dilute species, so we can
proceed with a generalization of Eq. (21.200), resulting in
G(N, Nv, Nd, Ni) = gvNv + gdNd + giNi −kBT ln W,
(21.201)
where kB ln W is a suitable conﬁgurational entropy. We expect gd < 2gv since fewer broken
bonds are needed to form a divacancy than to form two isolated vacancies. Interstitials
need to crowd surrounding ions, so we expect gi > gv, usually leading to interstitials being
the most dilute. The number of substitutional lattice sites is
S = N + Nv + 2Nd −Ni.
(21.202)
The total number of conﬁgurations can be expressed as a product of three factors,
W = wdwvwi, where wd is the number of ways that divacancies can be distributed on
the sites S; wv is the number of ways that isolated vacancies can be distributed on the
remaining substitutional sites; and wi is the number of ways that interstitials can be
distributed on I interstitial sites. Since we are treating a crystal with a Bravais lattice, we
take I = αS, where α is an integer, for example, 1 for FCC and 3 for BCC. Expressions for
wd, wv, and wi can be quite complex (see Girifalco [63, p. 214]) if proper counting is done
to insure, for example, that vacancies are not adjacent to divacancies. But given that all
species are dilute, we can make reasonable approximations immediately. For example, if
there are Nd divacancies, the isolated vacancies can reside on S −2Nd = N + Nv −Ni
sites, but not next to a divacancy or next to each other. But one makes negligible error
by assuming that isolated vacancies are distributed over N + Nv sites, or even over N
sites. Similarly, if z is the number of nearest neighbors of a lattice site, the number of
nearest neighbor pairs where a divacancy might reside is Sz/2 and some of these could be
adjacent. But with negligible error, we can replace Sz/2 by Nz/2 and ignore the possibility
of adjacent sites. Therefore, we adopt the following approximate quantities:13
wd ≈
(Nz/2)!
(Nz/2) −(Nd)!Nd!;
wv ≈(N + Nv)!
N!Nv!
;
wi ≈
(αN)!
(αN −Ni)!Ni!,
(21.203)
13In making these approximations, it is important to be sure each quantity has the form of a binomial
coefﬁcient.

394
THERMAL PHYSICS
which completely decouples different point defects. Then proceeding as with vacancies
only, we obtain
N eq
d ≈Nz
2 exp(−gd/kBT);
N eq
v
≈N exp(−gi/kBT);
N eq
i
≈αN exp(−gv/kBT).
(21.204)
These same results are obtained if the more accurate values of wd, wv, and wi are used,
provided that defect numbers are neglected in comparison with N in the ﬁnal results.
The most interesting result is for the divacancies. If we had simply gd = 2gv, we would
obtain
N eq
d
= (1/2)[N exp(−gv/kBT)][z exp(−gv/kBT)],
no binding energy,
(21.205)
which is simply the equilibrium number of vacancies times the probability that one of
the z nearest neighbor sites of a vacancy is also occupied by a vacancy, divided by 2 to
avoid double counting of pairs. But this does not account for the reduction in free energy
(binding energy) that results from the proximity of adjacent vacancies. Thus one can write
gd = 2gv −gb,
(21.206)
where gb = hv −Tsb > 0 is a binding (free) energy between adjacent vacancies. Then
N eq
d
= (z/2)N exp[−(2gv −gb)/kBT] = (z/2)N[exp(−gv/kBT)]2 exp(gb/kBT).
(21.207)
Numbers for gb are not very accurate so we give only some estimates of hb and sb to
one signiﬁcant ﬁgure in Table 21–1 for Ni and Al, along with calculations of N eq
d /N at
their melting points. A better comparison of divacancies to vacancies can be made by
recognizing that a divacancy results in two vacant sites, so the fraction of vacant sites due
to divacancies is
fd = 2N eq
d /(N eq
v
+ 2N eq
d ).
(21.208)
For Ni, fd is essentially negligible but for Al it is about 10% at its melting point.
21.5.3 Vacancies and Interstitials in Ionic Crystals
Vacancies and interstitials can occur in crystals with ionic bonding but their formation
is subject to additional constraints to insure charge neutrality. We shall illustrate these
considerations by treating alkali halides, such as NaCl, and silver halides with formulae of
the form AgX in which Ag has the oxidation state +1 and X is a halogen.14 We consider the
following types of point defects:
Positive ion vacancy Nv+ in number, each being a region of negative charge −e and
capable of existing on Nv+ sites.
Negative ion vacancy Nv−in number, each being a region of positive charge e and
capable of existing on Nv−sites.
14We exclude AgF2 in which Ag has the oxidation state +2. At this stage, we do not treat the possibility of color
centers in which localized electrons or holes can exist.

Chapter 21 • Grand Canonical Ensemble
395
Positive ion interstitial Ni+ in number, each being a region of positive charge e and
capable of existing on Ni+ sites.
Negative ion interstitial Ni−in number, each being a region of negative charge −e and
capable of existing on Ni−sites.
For the sake of simplicity, we will ﬁrst treat the case in which only pairs of defects are
needed to balance charge because the other two types of defects have values of Gibbs free
energy per defect that are much larger. For example, we will only need to consider positive
ion vacancies balancing the charge of negative ion vacancies if gi+ and gi−exceed gv+ and
gv−by amounts that are large compared to kBT. This will give rise to two types of vacancies,
also known as Schottky defects. On the other hand, we will only need to consider positive
ion vacancies balancing the charge of positive ion interstitials if gv−and gi−exceed gv+ and
gi+ by amounts that are large compared to kBT. Such vacancy-interstitial pairs are known
as Frenkel defects. In these cases, the constraints on charge neutrality could be applied by
immediately setting Nv+ = Nv−in the Schottky case and Nv+ = Ni+ in the Frenkel case,
but a general methodology that can be used if one needs to consider more than two defect
types is to use a Lagrange multiplier λ to apply the constraints.
Thus, for the Schottky case we can minimize the function
gv+Nv+ + gv+Nv+ −kBT ln Wvv −λ(Nv+ −Nv−),
(21.209)
where
Wvv =
Nv+!
(Nv+ −Nv+)!Nv+!
Nv−!
(Nv−−Nv−)!Nv−!.
(21.210)
This results in
N eq
v+ = Nv+ exp(−βgv+ + λ);
N eq
v−= Nv−exp(−βgv−−λ).
(21.211)
These can be multiplied to eliminate λ which yields
N eq
v+N eq
v−= Nv+Nv−exp

−β(gv+ + gv−)

.
(21.212)
But since the constraint requires N eq
v+ = N eq
v−, we obtain15
N eq
v+ = N eq
v−= (Nv+Nv−)1/2 exp −β(gv+ + gv−)/2 .
(21.213)
Equation (21.213) depends only on the average of gv+ and gv−, so the smaller of the two
compensates for the larger in establishing the effective activation energy. This case is
typical for alkali halides.
For the Frenkel case, we can proceed in a similar manner to obtain
N eq
v+ = N eq
i+ = (Nv+Ni+)1/2 exp

−β(gv+ + gi+)/2

.
(21.214)
This case typically occurs for silver halides. By replacing + with −in Eq. (21.214), we could
get a case in which negative ion vacancies and negative ion interstitials are the dominant
point defects. By replacing “v” with “i” in Eq. (21.213), we could get a case in which positive
15Alternatively we could have set N eq
v+ = N eq
v−in Eq. (21.211) and then solved for exp λ.

396
THERMAL PHYSICS
ion interstitials and negative ion interstitials are the dominant point defects, but this case
is not expected to occur because interstitials typically have higher activation energies than
vacancies.
Example Problem 21.7. Investigate the case in which gv−and gi+ differ from one another by
order kBT but gv+, gv−, gi+ ≪gi−. Thus, negative ion interstitials can be ignored, so there must
be charge balance among the remaining three types of defects.
Solution 21.7. In this case, we apply the charge balance constraint by adding λ(Nv+ −Nv−−
Ni+) to G and minimizing to obtain
N eq
v+ = Nv+ exp(−βgv+ + λ);
N eq
v−= Nv−exp(−βgv−−λ);
N eq
i+ = Ni+ exp(−βgi+ −λ).
(21.215)
By eliminating λ, we obtain
N eq
v+N eq
v−= Nv+Nv−exp

−β(gv+ + gv−)

;
N eq
v+N eq
i+ = Nv+Ni+ exp

−β(gv+ + gi+)

. (21.216)
Adding the two equations in Eq. (21.216) and applying the constraint N eq
v+ = N eq
v−+ N eq
i+ allows
us to solve for
N eq
v+ = (Nv+)1/2 exp(−βgv+/2)

Nv−exp(−βgv−) + N i+ exp(−βgi+)
1/2
.
(21.217)
Then combining this result with Eq. (21.216) gives
N eq
v−=
(Nv+)1/2 exp(−βgv+/2)

Nv−exp(−βgv−) + Ni+ exp(−βgi+)
1/2 Nv−exp(−βgv−)
(21.218)
and
N eq
i+ =
(Nv+)1/2 exp(−βgv+/2)

Nv−exp(−βgv−) + Ni+ exp(−βgi+)
1/2 Ni+ exp(−βgi+).
(21.219)
For ionic crystals, there are many other types of point defects, such as those that arise
when a small number of Ca++ ions are substituted for Na+ ions in NaCl, thus stimulating
the production of an equal number of Na+ vacancies. Such defects can strongly affect
electrical conductivity because of vacancy-assisted diffusion of ions. There is also the
possibility of color centers that involve localized electrons and holes that have a large
inﬂuence on optical adsorption. The reader is referred to the book by Ashcroft and
Mermin [58, p. 621] for a discussion of these and other defects.

22
Entropy for Any Ensemble
Until now we have introduced four ensembles that are used in statistical mechanics:
the microcanonical ensemble in Chapter 16, the canonical ensemble in Chapter 19,
the grand canonical ensemble in Chapter 21, and the pressure ensemble in Section
21.5 of Chapter 21. The canonical ensemble and the grand canonical ensemble were
derived from the microcanonical ensemble, although an alternative derivation of the
canonical ensemble was presented. Moreover, in Chapter 15, we introduced the dis-
order function D{pi} that gives a precise measure of information based on a set of
probabilities {pi} that can be used to characterize a system. In the present chapter,
we give a deﬁnition of the entropy of a system represented by any ensemble used
to deﬁne its thermodynamic state statistically. This deﬁnition will be based on the
methodology of the most probable distribution used in Section 19.1.3 to derive the
canonical ensemble. Our deﬁnition of entropy will enable us to relate systematically a
speciﬁc thermodynamic function with the logarithm of the partition function for that
ensemble.
22.1 General Ensemble
A general ensemble consists of a very large number Nens of immaginary systems, each in
some quantum state that we can index by a set of numbers, i, j, k, and a set of probabilities
Pijk such that a given state will appear Nijk = NensPijk times in the ensemble. For the sake
of illustration, we have assumed that the states of the ensemble can be characterized by
three numbers, but more or less could be used depending on the ensemble. In the case
of the ensembles heretofore treated, one number i or two numbers i, j is sufﬁcient. To
complete the deﬁnition of the ensemble, we must specify the set of constraints that must
be satisﬁed. One such constraint,

i,j,k
Pijk = 1,
(22.1)
comes from normalization of the set of probabilities and must always be satisﬁed. If it is
the only constraint, a single state index would sufﬁce. But other constraints might also
be relevant. These are best illustrated by example for which we select a grand canonical
ensemble with two kinds of particles, say A and B. Then we would characterize the states of
the ensemble as having N A
j of A particles, N B
k of B particles and eigenstates with energies
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00022-3
397
Copyright © 2015 Elsevier Inc. All rights reserved.

398
THERMAL PHYSICS
Eijk = Ei(N A
j , N B
k , V), where V is the volume of the system on which the energies of the
eigenstates could depend.1 In this case, the additional constraint equations would be2

i,j,k
Pijk Eijk = constant;
(22.2)

i,j,k
Pijk N A
j = constant;
(22.3)

i,j,k
Pijk N B
k = constant.
(22.4)
Given such a general ensemble, the number of ways that the ensemble can be
formed is
W =
Nens!

ijk Nijk! =
Nens!

ijk(NensPijk)!.
(22.5)
Then we maximize ln W subject to the constraints and assert that the entropy of the
system represented by the ensemble is given by
S = kB N −1
ens(ln W)max,
subject to constraints,
(22.6)
provided that all Lagrange multipliers employed to incorporate the constraints are
identiﬁed. Since Nens is large, we can use Stirling’s approximation to evaluate ln W,
resulting in
ln W = Nens ln Nens −

ijk
NensPijk ln(NensPijk) = −Nens

ijk
Pijk ln Pijk.
(22.7)
Thus
S = −kB
⎛
⎝
ijk
Pijk ln Pijk
⎞
⎠
max
,
subject to constraints,
(22.8)
where Lagrange multipliers associated with the constraints must still be identiﬁed.
Referring to Chapter 15, we see that Eq. (22.8) amounts to the maximization of the
disorder function, but with the important added information that one must maximize
the disorder function subject to the constraints of the ensemble under consideration.
Thus, Eq. (22.8) provides a general formula for the entropy of a system represented by
any ensemble in terms of maximization of the disorder function. The Lagrange multipliers
can be identiﬁed by comparison with the fundamental differential for dS according to
thermodynamics. For the example given above, this differential would be
dS = T−1 d⟨E⟩+ (p/T) dV −(μA/T) d⟨N A⟩−(μB/T) d⟨N B⟩,
(22.9)
1Instead of the volume, Eijk could depend on a whole set of mechanical variables Yℓif the system can do
reversible work by means of generalized forces pℓ= −
ijk Pijk ∂Eijk/∂Yℓ.
2These constraints could be multiplied by Nens in which case they are conservation laws for the entire
ensemble, which is how they actually originate.

Chapter 22 • Entropy for Any Ensemble
399
where T is the temperature, p is the pressure, μA is the chemical potential of A, μB is the
chemical potential of B, and ⟨· · · ⟩denotes ensemble averaging.
22.1.1 Example of the Maximization
We proceed to carry out this maximization for the example given above. Introducing
Lagrange multipliers α, β, γA, and γB, we calculate
0 =
∂
∂Prst
⎧
⎨
⎩−

ijk
Pijk ln Pijk −

ijk
Pijk[α + βEijk + γAN A
j + γBN B
k ]
⎫
⎬
⎭.
(22.10)
By carrying out the differentiation, we obtain
−1 −ln Prst −α −βErst −γAN A
s −γBN B
t = 0,
(22.11)
which yields (after a change of indices r, s, t →i, j, k)
Pijk = exp

−α −1 −βEijk −γAN A
j −γBN B
k

.
(22.12)
By applying the normalization constraint Eq. (22.1), we obtain
Pijk = Z−1 exp(−γAN A
j ) exp(−γBN B
k ) exp(−βEijk),
(22.13)
where the grand partition function
Z =

j
exp(−γAN A
j )

k
exp(−γBN B
k )

i
exp(−βEijk).
(22.14)
The differential of our expression Eq. (22.8) for the entropy yields
dS = −kB

ijk

1 + ln Pijk

dPijk
= kB

ijk

γAN A
j + γBN B
k + βEijk

dPijk,
(22.15)
where we have used 
ijk dPijk = 0. We also have
⟨E⟩=

ijk
PijkEijk;
d⟨E⟩=

ijk
Eijk dPijk +

ijk
Pijk
∂Eijk
∂V
dV ;
(22.16)
⟨N A⟩=

ijk
PijkN A
j ;
d⟨N A⟩=

ijk
N A
j dPijk;
(22.17)
⟨N B⟩=

ijk
PijkN B
k ;
d⟨N B⟩=

ijk
N B
k dPijk.
(22.18)

400
THERMAL PHYSICS
In writing Eq. (22.16), we have recognized that the eigenstates Eijk = Ei(N A
j , N B
k , V),
depend on the volume V of the system for a given set of the integers N A
j
and N B
k .
Substitution of Eqs. (22.16)–(22.18) into Eq. (22.15) gives
dS = kBγA d⟨NA⟩+ kBγB d⟨NB⟩+ kBβ d⟨E⟩−

ijk
Pijk
∂Eijk
∂V
dV .
(22.19)
Comparison with Eq. (22.9) allows identiﬁcation of the Lagrange multipliers
β =
1
kBT ;
γA = −μA
kBT ;
γB = −μB
kBT ,
(22.20)
as well as giving the relation
p = −

ijk
Pijk
∂Ei(N A
j , N B
k , V )
∂V
(22.21)
for the pressure.
Having now identiﬁed the Lagrange multipliers, we can return to Eq. (22.8) and
calculate the entropy, resulting in
S = −kB

ijk
Pijk

−γAN A
j −γBN B
k −βEijk −ln Z

= 1
T

−μA⟨N A⟩−μB⟨N B⟩+ ⟨E⟩+ kBT ln Z

.
(22.22)
Thus
−kBT ln Z = ⟨E⟩−TS −μA⟨N A⟩−μB⟨N B⟩≡K = −pV,
(22.23)
where the Euler equation for ⟨E⟩has been used in the last step. The Kramers function K
should be regarded as a function of its natural variables T, μA, μB, and V, on which this
ensemble depends. Equation (22.23) is an easy way of calculating the pressure in terms of
ln Z, although Eq. (22.21) reveals its physical origin.
22.1.2 Use of the Entropy Formula
The entropy formula Eq. (22.8) can be used practically by inspection to write down the
entropy of any ensemble.
For the microcanonical ensemble, there is only one constraint, the normalization of
the probabilities Eq. (22.1), for which a single subscript can be used to label the quantum
states, all having the same energy. Maximization of the entropy with that constraint shows
immediately that all of the Pi are equal, speciﬁcally Pi = 1/, where (E, V, N) is the
number of compatible microstates. Therefore, S(E, V, N) = −kB

(1/) ln(1/) =
kB ln , as we know for that ensemble.
For the canonical ensemble, there are two constraints, the normalization and the
energy constraint, so S = −kB

−β⟨E⟩−ln Z(T, V, N)

= ⟨E⟩/T + kB ln Z(T, V, N), where
Z(T, V, N) = 
i exp[−βEi(V, N)] is the canonical partition function. Thus, the Helmholtz

Chapter 22 • Entropy for Any Ensemble
401
free energy F(T, V, N) = −kBT ln Z. We also ﬁnd p = −
i Pi∂Ei(V, N)/∂V as well as
μ = 
i Pi∂Ei(V, N)/∂N , as in Section 19.1.3.
For the grand canonical ensemble, we have the results of the previous section.
For the pressure ensemble, which was treated in Section 21.5 by another method, we
have the normalization constraint, the energy constraint, and a volume constraint of the
form 
i,ℓPiℓVℓ= constant, where Vℓis the set of volumes on which the energy eigenstates
Ei(Vℓ, N) depend. The entropy is therefore S = −kB

−β⟨E⟩−βp⟨V⟩−ln Zp(T, p, N)

=
⟨E⟩/T + (p/T)⟨V⟩+ kB ln Zp(T, p, N), where the partition function
Zp(T, p, N) =

ℓ
exp(−βpVℓ)

i
exp

−βEi(Vℓ, N)

.
(22.24)
Thus, the Gibbs free energy G(T, p, N) = −kBT ln Zp. We also have μ = 
i,ℓPiℓ∂Ei
(Vℓ, N)/∂N .
For the sake of illustration, we invent another ensemble for which the normalizing
function for the probabilities can be related to a Massieu function of the system. The
energies of all of the eigenstates in the ensemble will have the same energy E, just as for
the microcanonical ensemble, so we have the normalization constraint but no additional
energy constraint. But we will allow the members of the ensemble to have a set of
volumes, Vℓas they did for the pressure ensemble. Thus we will have a volume constraint

i,ℓPiℓVℓ= constant. The probabilities will be given by
Piℓ= exp(−γ Vℓ)/∗,
(22.25)
where the normalizing function3
∗(E, γ , N) =

i,ℓ
exp(−γ Vℓ) =

ℓ
(E, Vℓ, N) exp(−γ Vℓ).
(22.26)
Here, γ is the Lagrange multiplier for the volume constraint and (E, Vℓ, N) is the number
of eigenstates having the given energy E and particle number N for a state with volume
Vℓ. The probabilities Piℓdepend on E, γ , and N, so to ﬁnd γ we allow it to vary at ﬁxed E
and N. In this case, the differential of the entropy is simply
dS =

i,ℓ
kBγ Vℓ
∂Piℓ
∂γ dγ .
(22.27)
For the average volume of the system, we have
⟨V⟩=

i,ℓ
PiℓVℓ;
d⟨V ⟩=

i,ℓ
Vℓ
∂Piℓ
∂γ dγ .
(22.28)
At ﬁxed E and N, dS = (p/T) d⟨V⟩, so
γ = p/(kBT).
(22.29)
3This normalizing function is the partition function for this ensemble but we give it a different notation
because of its close association with the microcanonical ensemble, as clariﬁed in the next section.

402
THERMAL PHYSICS
The entropy is therefore
S = −kB

−βp⟨V ⟩−ln Z(T, p, N)

= (p/T)⟨V ⟩+ kB ln ∗(E, p/T, N).
(22.30)
Thus
kB ln ∗(E, p/T, N) = S −(p/T)⟨V ⟩≡M2(E, p/V , N),
(22.31)
which is a Legendre transform of the entropy, ordinarily called a Massieu function. From
the differential of S, we ﬁnd
dM2(E, p/V, N) = (1/T) dE −⟨V ⟩d(p/T) −(μ/T) dN.
(22.32)
Thus from the partial derivatives of ∗(E, p/T, N), we are able to compute 1/T, −⟨V⟩, and
−(μ/T).
22.2 Summation over Energy Levels
As pointed out by Hill [64, p. 30], the partition function for all of these ensembles can
be written as sums over the extensive variables that are needed to characterize the
microcanonical ensemble provided that we sum over energy levels (instead of quantum
states) with an appropriate degeneracy factor for the energy eigenstates. For a single
component system, that factor is (E, V, N) which is the number of eigenstates having
energy E for a system with volume V and particle number N.
For the microcanonical ensemble, there is no summation and one has simply
ln (E, V, N) = S(E, V , N)/kB.
(22.33)
For the canonical ensemble,
ln

E
(E, V , N) exp(−βE) = −βF(β, V , N).
(22.34)
For the grand canonical ensemble
ln

E,N
(E, V, N) exp(−βE + βμN) = −βK(β, V , μ).
(22.35)
For the pressure ensemble
ln

E,V
(E, V , N) exp(−βE −βpV) = −βG(β, p, N).
(22.36)
For the ensemble related to the Massieu function discussed above,
ln

V
(E, V, N) exp(−βpV) = M2(E, p/T, N)/kB.
(22.37)
Note that the form of the right-hand sides of Eq. (22.37) and Eq. (22.33) depend on
E which is not summed over. In all of these cases, one could use distribution functions
for any of the variables that are summed over and then integrate over those variables.

Chapter 22 • Entropy for Any Ensemble
403
This is necessary if V is to be treated as a continuous variable in Eqs. (22.36) and (22.37).
Every ensemble involves a weighted sum of entropies of a microcanonical ensemble.
The extensive variables that are summed over are the ones that have dispersion in the
respective ensemble.

This page intentionally left blank 

23
Uniﬁed Treatment of Ideal Fermi,
Bose, and Classical Gases
In Chapter 21, we introduced the grand canonical ensemble which applies to a system
having a ﬁxed temperature and a ﬁxed chemical potential, but not a ﬁxed energy or a ﬁxed
number of particles. In Section 21.2.5, we discussed a uniﬁed treatment of orbitals of ideal
Fermi, Bose, and classical gases for which the grand partition function Z factored and
could be written formally in the form
Z =

ε

1 + aλ exp(−βε)
1/a ,
(23.1)
where the product is over all orbitals1 having energy ε, λ = exp(βμ) is the absolute activity
with chemical potential μ, and
a =
⎧
⎨
⎩
1
fermions
−1 bosons
0
classical.
(23.2)
This yields
ln Z = 1
a

ε
ln

1 + aλ exp(−βε)

.
(23.3)
The classical case must be interpreted as a limit a →0 to give
ln Z =

ε
λ exp(−βε) = λ z,
(23.4)
where z is the canonical partition function of a single particle. From Eq. (21.32) with q =
ln Z, we obtain
⟨N⟩= λ
	∂q
∂λ

β,V
=

ε
f (ε, a)
(23.5)
and
U = −
	 ∂q
∂β

λ,V
=

ε
εf (ε, a),
(23.6)
1As explained in Section 21.2, an orbital is a quantum state of a particle speciﬁed by all quantum numbers of
its spatial wave function and its spin, which we incorporate in the single symbol ε which is also the energy of that
state, usually degenerate.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00023-5
405
Copyright © 2015 Elsevier Inc. All rights reserved.

406
THERMAL PHYSICS
where
f (ε, a) :=
1
λ−1 exp(βε) + a =
1
exp[β(ε −μ)] + a.
(23.7)
Note that f (ε, a) agrees with Eq. (21.88) for a = 1 and Eq. (21.92) for a = −1. From
Eq. (21.38) we also obtain
pV
kBT = 1
a

ε
ln

1 + aλ exp(−βε)

.
(23.8)
23.1 Integral Formulae
If the temperature is not too low, the sums in Eqs. (23.5), (23.6), and (23.8) can be converted
to integrals because the spacings of the energy levels will be small compared with kBT and
ε will be quasi-continuous. However, conversion to an integral is insufﬁcient for bosons
below the condensation temperature, which we discuss in the next chapter. If every state
has a degeneracy g0 due to spin, then 
ε = g0
′
ε, where the primed sum is over states
with spin degeneracy ignored. For a free particle in a rectangular box of dimensions
H, K, L, these states can be expressed in terms of the wave vector k given by Eq. (16.51).
If one of the integers in that expression, say nx, changes by unity, the x component of k
changes by kx = 2π/H, and similarly the y and z components change by ky = 2π/K
and kz = 2π/L. Thus we have

ε
= g0
′

ε
= g0

k
= g0

kx

ky

kz
= g0
HKL
(2π)3

kx

ky

kz
kxkykz.
(23.9)
If we apply this to any nearly continuous function F(k) that does not vary signiﬁcantly
over the k-space volume element kxkykz, we can replace summation by integration
and obtain2
HKL
(2π)3

kx

ky

kz
kxkykz F(k) →
V
(2π)3

d3k F(k),
(23.10)
where HKL has been replaced by the volume V. Furthermore, if F(k) depends only on the
magnitude of k, as it would for an integrand of the form G(ε(|k|)), where ε = ¯h2|k|2/2m,
we would have
V
(2π)3

d3k G(ε(|k|)) =
V
(2π)3 4π
 ∞
0
k2 dk G(ε(|k|)) =
V
2π2
 ∞
0
G(ε) k2 dk
dε dε.
(23.11)
Since (1/2π2)k2dk/dε = (2/π1/2)(m/2π¯h2)3/2ε1/2, we ﬁnally obtain

ε
G(ε(|k|)) = g0VnQ(T)
1
(3/2)
 ∞
0
G(ε) β3/2ε1/2 dε,
(23.12)
where nQ(T) = (mkBT/2π¯h2)3/2 is the quantum concentration and the gamma function
(3/2) = (1/2)π1/2 has been introduced to unify subsequent notation.
2This would not be true for thin samples. For instance, if H were small, then kx would be large.

Chapter 23 • Uniﬁed Treatment of Ideal Fermi, Bose, and Classical Gases
407
With the use of Eq. (23.12) and the substitution u = βε, Eqs. (23.5) and (23.6) can be
written in the forms
n = g0nQ(T) h3/2(λ, a)
(23.13)
and
uV = (3/2)kBT g0nQ(T) h5/2(λ, a),
(23.14)
where n = ⟨N⟩/V is the average number of particles per unit volume, uV = U/V is the
energy per unit volume, and the function
hν(λ, a) :=
1
(ν)
 ∞
0
uν−1 du
λ−1 eu + a.
(23.15)
Equation (23.13) determines λ, or equivalently the chemical potential μ, as a function of n
and T which can then be substituted into Eq. (23.14) to determine uV. For the classical gas,
we have hν = λ for any ν > 0 so Eq. (23.13) becomes simply λ = n/(nQg0) and Eq. (23.14)
becomes the familiar uV = (3/2)nkBT. For a strictly classical gas, there is no spin degree of
freedom so g0 = 1.
Before exploring the behavior of the functions hν(λ, a), we return to Eq. (23.8) for the
pressure and convert the sum to an integral to obtain
p
kBT = 1
ag0nQ(T)
1
(3/2)
 ∞
0
ln(1 + aλ e−u)u1/2 du.
(23.16)
Then we use u1/2 = (2/3)(d/du)u3/2 to integrate by parts and obtain
1
a
 ∞
0
ln(1 + aλ e−u)u1/2 du =
2
3au3/2 ln(1 + aλ e−u)

∞
0
+ 2
3
 ∞
0
u3/2 du
λ−1 eu + a.
(23.17)
The integrated part vanishes at both limits and we obtain
p = kBTg0nQ(T)h5/2(λ, a) = (2/3)uV,
(23.18)
where (3/2)(3/2) = (5/2) has been used. In view of Eq. (23.3), the same integration by
parts can be used to evaluate the partition function, resulting in
ln Z = g0VnQ(T)h5/2(λ, a).
(23.19)
Therefore, the Kramers potential is
K = −kBTg0VnQ(T)h5/2(λ, a) = −(2/3)U = −pV
(23.20)
as expected.
The entropy can be determined by using Eq. (21.14) to obtain
S
kB
= ln Z −β
	∂ln Z
∂β

V,μ
.
(23.21)
This results in
S
kB
= (5/2)Vg0nQ(T)h5/2(λ, a) −βVg0nQ
	∂h5/2(λ, a)
∂β

V,μ
,
(23.22)

408
THERMAL PHYSICS
where we have recalled that nQ(T) ∝β−3/2. Since (∂λ/∂β)V,μ = μλ, Eq. (23.22) becomes
S
kBVg0nQ(T) = (5/2)h5/2(λ, a) −βμλ∂h5/2(λ, a)
∂λ
.
(23.23)
In the next section, we will show that λ∂h5/2(λ, a)/∂λ = h3/2(λ, a). Then noting that βμ =
ln λ, we obtain
S = kBVg0nQ(T)

(5/2)h5/2(λ, a) −ln λ h3/2(λ, a)

.
(23.24)
Alternatively we could compute the entropy from S/kB = β(U −K −μ⟨N⟩), which leads
to the same answer.
Thus, it remains to determine the behavior of the functions hν(λ, a) which we take up
in the next section.
23.2 The Functions hν(λ, a)
We ﬁrst derive the relation
λ∂hν(λ, a)
∂λ
= hν−1(λ, a);
ν > 1.
(23.25)
We begin with
λ∂hν(λ, a)
∂λ
= λ ∂
∂λ
1
(ν)
 ∞
0
uν−1 du
λ−1 eu + a
(23.26)
and note that
λ ∂
∂λ
1
λ−1 eu + a = −∂
∂u
1
λ−1 eu + a.
(23.27)
We integrate by parts to obtain
λ∂hν(λ, a)
∂λ
= −
1
(ν)
uν−1
λ−1 eu + a

∞
0
+ ν −1
(ν)
 ∞
0
uν−2 du
λ−1 eu + a.
(23.28)
The integrated term vanishes at both limits provided that ν > 1. In the second term, we
use (ν) = (ν −1)(ν −1), resulting in Eq. (23.25).
For 0 ≤λ < 1, we can obtain series expansions for hν(λ, a). Since λ = eβμ and βμ is
real, we certainly have λ ≥0. Returning to Eqs. (23.5) and (23.7), we see that f (ε, a) must be
ﬁnite and positive for all values of ε. If we examine the ground state ε = 0 for bosons, we
see that f (0, −1) = λ/(1 −λ), which means that λ < 1, or equivalently μ < 0. For fermions,
f (0, 1) = λ/(1 + λ) so no such restriction exists and 0 ≤λ < ∞. Therefore, our series
expansion will cover the range of 0 ≤λ < 1 but we will have to examine λ = 1 carefully.
For fermions, we will have to examine λ > 1 separately.

Chapter 23 • Uniﬁed Treatment of Ideal Fermi, Bose, and Classical Gases
409
From Eq. (23.15) we obtain
hν(λ, a) =
1
(ν)
 ∞
0
uν−1λ e−u du
1 + aλ e−u
=
1
(ν)
	 1
−a

 ∞

n=1
(−aλ)n
 ∞
0
uν−1 e−nu du
=
1
(ν)
	 1
−a

 ∞

n=1
(−aλ)n
nν
 ∞
0
vν−1 e−v dv =
	 1
−a

 ∞

n=1
(−aλ)n
nν
.
(23.29)
For bosons,
gν(λ) := hν(λ, −1) = λ + λ2
2ν + λ3
3ν + · · · =
∞

n=1
λn
nν
(23.30)
and for fermions,
fν(λ) := hν(λ, 1) = λ −λ2
2ν + λ3
3ν + · · · =
∞

n=1
λn
nν (−1)n+1.
(23.31)
For classical particles, hν(λ, 0) = λ for ν > 0 as mentioned previously.
The value λ = 1 must be handled with care. It turns out that
hν(1, −1) = gν(1) = 1 + 1
2ν + 1
3ν + · · · =
∞

n=1
1
nν = ζ(ν),
(23.32)
where
ζ(ν) :=
∞

k=1
k−ν,
ℜν > 1,
(23.33)
is the Riemann zeta function. For ν = 1, this is the well-known harmonic series and
diverges. Important values for our purposes are g3/2(1) = ζ(3/2) = 2.61238 and g5/2(1) =
ζ(5/2) = 1.34149. Since g1/2(1) = ∞, Eq. (23.25) shows that g3/2(λ) approaches g3/2(1) with
inﬁnite slope. For fermions, nothing special happens at λ = 1 because
hν(1, 1) = fν(1) = 1 −1
2ν + 1
3ν + · · · =
∞

n=1
1
nν (−1)n+1,
(23.34)
which is an alternating series with terms of decreasing size for positive ν. In fact, fν(1) =
(1 −21−ν)ζ(ν) for ν > 1, as the reader may verify by writing out the series.
Figure 23–1 shows some plots of hν(λ, a) as a function of λ, including values of λ > 1
which we have not yet discussed for fermions.
For fermions and λ > 1, one can either compute the integrals for hν(λ, 1) = fν(λ)
numerically or resort to an asymptotic expansion that is valid for large λ. This expansion,
known as the Sommerfeld expansion [65], is actually a series in (ln λ)−1 = (βμ)−1 =
kBT/μ and is useful at high temperatures to treat degenerate Fermi gases. For now we
only quote the ﬁrst few terms [8, p. 510]:

410
THERMAL PHYSICS
0.5
1
1.5
2
2.5
3
0.5
1
1.5
2
2.5
3
hν(λ,a)
h3/2(λ,−1)
h5/2(λ,−1)
h3/2(λ,1)
h5/2(λ,1)
a = 0
λ
FIGURE 23–1 Plots of the function hν(λ, a) for ideal Fermi, Bose, and classical gases as a function of λ. Note that all
plots merge for λ ≪1 which is the classical limit. The upper two curves are for bosons and the lower two are for
fermions. The middle line is for the classical case a = 0.
fν(λ) ∼
(ln λ)ν
(ν + 1)

1 + ν(ν −1)π2
6
	 1
ln λ

2
+ ν(ν −1)(ν −2)(ν −3)7π4
360
	 1
ln λ

4
+ · · ·

.
(23.35)
In Chapter 25, we shall examine a related expansion in more detail to treat the free-
electron model of metals.
23.3 Virial Expansions for Ideal Fermi and Bose Gases
We digress brieﬂy to discuss so-called virial expansions which are series expansions for
p/(nkBT) in powers of n. We ﬁrst discuss these expansions for very small values of λ and
then present some more general results.
From Eqs. (23.14) and (23.18) we have
y :=
p
g0nQkBT = h5/2(λ, a) =
	 1
−a

 ∞

n=1
(−aλ)n
n5/2
(23.36)
and Eq. (23.13) becomes
x :=
n
g0nQ
= h3/2(λ, a) =
	 1
−a

 ∞

n=1
(−aλ)n
n3/2
.
(23.37)
Dividing Eq. (23.36) by Eq. (23.37) we obtain
y
x =
p
nkBT = h5/2(λ, a)
h3/2(λ, a).
(23.38)
For a given value of a, p/(nkBT) depends only on λ and hence only on x. We can then
invert the series in Eq. (23.37) by successive approximations and obtain a series expansion
for p/(nkBT) in terms of x. For the classical case, a = 0, we have h5/2(λ, 0) = h3/2(λ, 0) = λ,
so Eq. (23.38) becomes simply

Chapter 23 • Uniﬁed Treatment of Ideal Fermi, Bose, and Classical Gases
411
p
nkBT = 1.
(23.39)
This turns out to be the leading term for a ̸= 0 for sufﬁciently small λ.
We illustrate the expansion procedure by calculating the next term in the series. For the
Fermi and Bose gases, we have, to order λ2, the expressions
y = λ −aλ2/25/2 + · · ·
(23.40)
and
x = λ −aλ2/23/2 + · · · .
(23.41)
To lowest order, we have λ = x which we substitute into the second-order term in
Eq. (23.41) to obtain λ = x + ax2/23/2 + · · · . Substitution into Eq. (23.40) gives y =
x + ax2/23/2 −ax2/25/2 · · · so to this order we have
y
x =
p
nkBT = 1 −ax
	
−
1
4
√
2

+ · · · = 1 −ax(−0.17678) + · · · .
(23.42)
As the concentration n, and therefore x, increases, we get a positive correction (compared
to a classical gas) for fermions (repulsive effect consistent with the exclusion principle)
and a negative correction for bosons. This iteration process can be carried out to higher
order and results in a virial expansion of the form (see [8, p. 160])
p
nkBT =
∞

ℓ=1
(−a)ℓ−1aℓxℓ−1,
(23.43)
where the ﬁrst few virial coefﬁcients are a1 = 1, a2 = −1/(4
√
2) = −0.17678, a3 =
−[2/(9
√
3) −1/8] = −0.00330, and a4 = −[3/32 + 5/(32
√
2) −1/(2
√
6)] = −0.00011. It
turns out that the higher order terms in the series are not very important and Eq. (23.42) is
accurate to within about 1% for fermions and about 5% for bosons even up to λ = 1.
Figure 23–2 shows a plot of p/(nkBT) versus x = n/(g0nQ) for ideal Fermi and Bose
gases up to values that correspond to λ = 1. The plot was constructed by evaluation of
0.5
1
1.5
2
2.5
0.5
0.6
0.7
0.8
0.9
1.1
p/(nkBT)
n/(g0nQ)
fermions
bosons
FIGURE 23–2 Plot of p/(nkBT) versus x = n/(g0nQ) for ideal Fermi and Bose gases up to values that correspond to
λ = 1. This plot was constructed by evaluation of the functions hν(λ, a) numerically and then using a parametric
plotting routine. Amazingly, the deviations from linearity are only a few percent.

412
THERMAL PHYSICS
the functions hν(λ, a) numerically as functions of λ and then using the parametric plotting
routine in Mathematica R⃝. The plot agrees extremely well with the series expansion up to
n/(g0nQ) = 0.5. By using values of λ > 1 it can be extended to larger values than shown
for fermions and deviates only slightly from a straight line. Therefore, Eq. (23.42) sufﬁces
approximately over a considerable range of x. We shall see later that Bose condensation
sets in very near to λ = 1, in agreement with the limited range of the plot for bosons.
23.4 Heat Capacity
We can compute the heat capacity at constant volume by partial differentiation of the
internal energy U with respect to T with V and ⟨N⟩held constant. From Eq. (23.14)
we have
CV = 15
4 VkBg0nQh5/2(λ, a) + 3
2VkBTg0nQ
∂h5/2(λ, a)
∂λ
	 ∂λ
∂T

V,⟨N ⟩
,
(23.44)
where we have recalled that nQ
∝
T3/2. To calculate (∂λ/∂T)V,⟨N ⟩we differentiate
Eq. (23.13) to obtain
0 = 3
2VkB
1
T g0nQh3/2(λ, a) + VkBTg0nQ
∂h3/2(λ, a)
∂λ
	 ∂λ
∂T

V,⟨N ⟩
.
(23.45)
Then after using Eq. (23.25) we solve for the required derivative to obtain
	 ∂λ
∂T

V,⟨N ⟩
= −3
2
λ
T
h3/2(λ, a)
h1/2(λ, a).
(23.46)
By substituting into Eq. (23.44) and again using Eq. (23.25), we obtain
CV = 3
2VkBg0nQ

5
2h5/2(λ, a) −3
2

h3/2(λ, a)
2
h1/2(λ, a)

.
(23.47)
Finally, we can use Eq. (23.13) for ⟨N⟩to obtain
CV = 3
2⟨N⟩kB
5
2
h5/2(λ, a)
h3/2(λ, a) −3
2
h3/2(λ, a)
h1/2(λ, a)

.
(23.48)
We caution, however, that Eqs. (23.4), (23.13), and (23.48) are not valid for bosons for
temperatures below the Bose condensation temperature that we treat in the next chapter.

24
Bose Condensation
An ideal Bose ﬂuid is one composed of noninteracting bosons, which are particles having
integral spin s = 0, 1, 2, . . . and orbitals ε. The partition function for a single orbital is
given by Eq. (21.91) and the average number of particles occupying that orbital is given
by Eq. (21.92). The average number of particles in the system is given by Eq. (21.93) but
ordinarily this number is speciﬁed and Eq. (21.93) is used to ﬁnd the absolute activity λ
or, equivalently, the chemical potential μ. If we take the lowest energy state to be ε = 0,
we see for systems having a ﬁnite number of bosons that λ < 1 (μ must be negative) to
prevent fBE(ε) from becoming inﬁnite.
In Chapter 23, we gave a uniﬁed treatment of ideal Fermi, Bose, and classical gases.
This treatment is applicable to bosons, for which a < 1, provided that the temperature is
above the so-called condensation temperature Tc, a critical temperature to be deﬁned in
the next section. For T < Tc, λ becomes very nearly equal to one and many of the results
in Chapter 23 for bosons require modiﬁcation. In some cases, it will no longer be possible
to convert sums over ε entirely to integrals. Instead, the ground state ε = 0 will have to be
treated by means of a separate term and the integrals in Chapter 23 will only be applicable
to the excited states.
To simplify the notation we will use
fBE(ε) := f (ε, −1) =
1
λ−1 exp(βε) −1 =
1
exp[β(ε −μ)] −1;
(24.1)
gν(ε) := hν(ε, −1) =
1
(ν)
 ∞
0
uν−1 du
λ−1 eu −1.
(24.2)
Hereafter in this chapter, we will also write N instead of ⟨N⟩with the understanding
that the average number of particles will be speciﬁed and λ (or equivalently μ) will be
determined consistently as a function of particle density and temperature.
24.1 Bosons at Low Temperatures
To focus attention on the problem that occurs at low temperatures, we recall Eq. (23.13)
which we now write in the form
N = Vg0nQ(T)g3/2(λ),
(24.3)
where we have written nQ(T) for the quantum concentration to emphasize its dependence
on temperature. Here, g0 = 2s + 1 accounts for degeneracy due to spin s that must be an
integer for bosons. The problem with this equation becomes evident when we examine
the function g3/2(λ) which is plotted in Figure 24–1. We see that g3/2(λ) is a monotonically
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00024-7
413
Copyright © 2015 Elsevier Inc. All rights reserved.

414
THERMAL PHYSICS
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
2.5
3
gν(λ)
ν = 1/2
ν = 3/2
ν = 5/2
2.61238
1.34149
λ
FIGURE 24–1 Plots of the functions gν(λ) given by Eq. (24.2). Recall from Chapter 23 that λg′
ν(λ) = gν−1(λ) and
gν(1) = ζ(ν), the Riemann zeta function. g1/2(1) = ∞so g3/2(λ) has an inﬁnite slope at λ = 1.
increasing function of λ which has its maximum value at λ = 1, namely g3/2(1) = 2.61238.
Inserting this value into Eq. (24.3) gives
N = Vg0nQ(T)g3/2(1).
(24.4)
Since nQ(T) ∝T3/2, the right-hand side of Eq. (24.4) gets smaller as T decreases. Therefore,
for a given value of n = N/V, there exists a critical temperature Tc below which all particles
cannot be accommodated. This temperature satisﬁes
n = g0
mkBTc
2π¯h2
3/2
g3/2(1).
(24.5)
This presents a problem because we must accommodate all particles, even at low temper-
atures! For T < Tc, Eq. (24.3) cannot be correct and must be modiﬁed.
The source of this problem is related to an approximation made in the conversion
of a sum to an integral. We therefore return to Eq. (23.5) for bosons which we write in
the form
N =

ϵ
1
λ−1 exp(βε) −1.
(24.6)
Examination of this sum shows that the term arising from ε = 0 contributes a number of
particles
N0 = g0
1
λ−1 −1 = g0
λ
1 −λ.
(24.7)
As λ →1 this term becomes inﬁnite, so for λ very slightly less than 1 it cannot be ignored.
If the sum in Eq. (24.7) were converted to an integral, as was done to obtain Eq. (24.4),
that integral would be unaffected by leaving out a single point, so it would not properly
include the nearly singular term given by Eq. (24.7). Thus, the right-hand side of Eq. (24.4)
accounts only for the number Ne of particles in the excited states. This is no problem for
T > Tc but for T < Tc we must account explicitly for particles that have “condensed” into
the ground state.

Chapter 24 • Bose Condensation
415
Accordingly, we replace Eq. (24.4) by
N = N0 + Ne = g0
λ
1 −λ + Vg0nQ(T)g3/2(1);
T < Tc.
(24.8)
The concentration of particles in excited states is therefore
ne := Ne
V
= g0nQ(T)g3/2(1) = g0
mkBT
2π¯h2
3/2
g3/2(1);
T < Tc.
(24.9)
Solving Eq. (24.7) for λ gives
λ =

1 + g0
N0
−1
.
(24.10)
There appears at ﬁrst to be an inconsistency between Eqs. (24.5) and (24.7) for the
following reason: λ has been set equal to 1 in the argument of g3/2 in both Eqs. (24.5)
and (24.8). But Eq. (24.5) is based on N0 = 0 and this would require λ = 0 according to
Eq. (24.7)! This turns out to be a false argument because N0 is never zero, but can still be
negligible with respect to N. All we need for Eq. (24.5) to hold for determination of Tc is
N0 ≪N. For example, suppose that N0 = 10−6N. Then Eq. (24.10) becomes
λ =

1 +
g0
10−6N
	−1
≈1 −
g0
10−6N ≈1
(24.11)
for any reasonably large value of N. One might expect N ∼1023, but even for a sample
so small that N ∼1012, λ is less than 1 by a few parts in a million. Thus we can safely set
λ = 1 in g3/2(λ) while letting it be a variable extremely close to 1 in Eqs. (24.7) and (24.8).
In terms of the chemical potential, Eq. (24.11) would become
μ ≈−kBT
g0
10−6N ,
(24.12)
which means that the chemical potential is negative and very slightly less than zero.1 If
N0 accounted for all of N, equations of the form of Eqs. (24.11) and (24.12) would hold
but without the factor of 10−6. Then λ would be even closer to 1 and μ would be even
closer to 0.
Dividing Eq. (24.9) by Eq. (24.5) and denoting the concentration of particles in the
ground state by n0 := N0/V, we obtain
ne = n
 T
Tc
3/2
(24.13)
and
n0 = n

1 −
 T
Tc
3/2
.
(24.14)
1The ground state energy has been set equal to 0 for convenience. Otherwise, μ would be slightly less than
the ground state energy ε0.

416
THERMAL PHYSICS
0.5
1
1.5
2
0.2
0.4
0.6
0.8
1
n0/n
ne/n
T/Tc
FIGURE 24–2 Plots of the fraction of condensate, n0/n associated with the ground state, and of the normal ﬂuid,
ne/n associated with the excited states, as a function of T/Tc according to Eqs. (24.13) and (24.14).
The concentrations (number densities) ne and n0 are represented graphically in
Figure 24–2. For an exact treatment that agrees with the present results in the
thermodynamic limit, see Pathria and Beale [9, Appendix F].
24.2 Thermodynamic Functions
To determine the thermodynamic functions for T ≤Tc, we return to the sum in Eq. (23.3)
for a = −1 and account explicitly for the ε = 0 term in ln Z, namely,
ln Z0 = −g0 ln(1 −λ).
(24.15)
This term contributes an amount
K0 = g0kBT ln(1 −λ)
(24.16)
to the Kramers potential K which must be added to the part of K that comes from the
excited states, calculated by converting the sum to an integral. Explicitly,
K = K0 + kBTVg0nQ(T)
1
(3/2)
 ∞
0
ln(1 −λ e−u)u1/2 du.
(24.17)
After integration by parts, as in Eq. (23.17), this becomes
K = K0 −kBTVg0nQ(T)g5/2(λ).
(24.18)
Fortunately, K0 is negligible except for computation of N, which we have already
considered.2 For example, since K = −pV, the term K0 would appear to produce an excess
pressure
p0 = −kBT
V g0 ln(1 −λ)
(24.19)
2Note that −(∂K0/∂μ)T,V = λ

∂ln Z0/∂λ

β,V = g0λ/(1 −λ) = N0 in agreement with Eq. (24.7).

Chapter 24 • Bose Condensation
417
over and above the pressure given by Eq. (23.18) for bosons, namely
p = kBTg0nQ(T)g5/2(λ).
(24.20)
But from Eq. (24.10) this excess pressure is
p0 = kBT
V g0 ln

(N0/g0) + 1

.
(24.21)
Since V ∝N, this term is of the order of N −1 ln N and should be neglected in the
thermodynamic limit of large N. Thus we have
p = g0nQ(T)kBTg5/2(λ);
T > Tc
(24.22)
and
p = g0nQ(T)kBTg5/2(1);
T ≤Tc.
(24.23)
Note especially that Eq. (24.23) shows that p depends only on T, independent of n.
Care must therefore be taken in expressing the pressure in terms of n because Eq. (24.3)
holds for T > Tc but Eq. (24.5) holds for T ≤Tc. Thus,
p = nkBT g5/2(λ)
g3/2(λ);
T > Tc.
(24.24)
but
p =
 T
Tc
3/2
nkBT g5/2(1)
g3/2(1) = nekBT g5/2(1)
g3/2(1);
T ≤Tc.
(24.25)
Equation (24.25) shows that the condensate makes no contribution to the pressure. Those
bosons in the ground state, the so-called condensate, exert no pressure. As written,
Eq. (24.25) appears to depend on n, thus contradicting Eq. (24.23), but it must be recalled
that T3/2
c
is proportional to n, so n actually cancels in Eq. (24.25) (see Eq. (24.9)).
Similar considerations pertain to the internal energy and the entropy, although the
calculations are more complicated because one must ﬁrst take derivatives. For the internal
energy, the situation is quite simple because the ground state has zero energy so the
condensate does not contribute (see Eq. (23.6)). This can be seen more formally by writing
q = ln Z = −βK which leads to
q = q0 + Vg0nQ(T)g5/2(λ),
(24.26)
where q0 = −g0 ln(1−λ). Then from U = −

∂q/∂β

λ, we see that q0 makes no contribution
and the second term gives
U = 3
2kBTVg0nQ(T)g5/2(λ)
(24.27)
in agreement with Eq. (23.14). Thus the energy density,
uV = 3
2nkBT g5/2(λ)
g3/2(λ);
T > Tc
(24.28)

418
THERMAL PHYSICS
but
uV =
 T
Tc
3/2 3
2nkBT g5/2(1)
g3/2(1) = 3
2nekBT g5/2(1)
g3/2(1);
T ≤Tc.
(24.29)
We see that the condensate makes no contribution to the internal energy for T < Tc. It
therefore follows that p = (2/3)uV holds at all temperatures.
Finally, the contribution of K0 to the entropy is
S0 = −
∂K0
∂T

μ,V
= −g0kB

ln(1 −λ) + λ ln λ
1 −λ

.
(24.30)
In view of Eq. (24.10), this becomes
S0 = kBg0

ln

(N0/g0) + 1

+ (N0/g0) ln[1 + (g0/N0)]

.
(24.31)
Provided that N0 is any reasonable fraction of N, we have g0/N0 ≪1 in which case
(N0/g0) ln[1 + (g0/N0)] ≈1; the remaining term in Eq. (24.31) is of order ln N and is also
negligible in the thermodynamic limit. Thus,
S = kBVg0nQ(T)

(5/2)g5/2(λ) −ln λ g3/2(λ)

,
(24.32)
in agreement with Eq. (23.24). This result can also be expressed in terms of the number
density, resulting in an entropy density
sV = kBn
5
2
g5/2(λ)
g3/2(λ) −ln λ

;
T > Tc,
(24.33)
but3
sV =
 T
Tc
3/2
nkB
5
2
g5/2(1)
g3/2(1) = nekB
5
2
g5/2(1)
g3/2(1);
T ≤Tc.
(24.34)
We observe that the bosons in the condensate make no contribution to the entropy.
For T > Tc the heat capacity is still given by either Eq. (23.47) or (23.48) for a = −1, in
which case the latter becomes
CV = 3
2NkB
5
2
g5/2(λ)
g3/2(λ) −3
2
g3/2(λ)
g1/2(λ)

;
T > Tc.
(24.35)
It would be wrong, however, to use Eq. (23.47) (or Eq. (23.48) which is derived from it) for
T ≤Tc because Eq. (23.47) is based on a temperature derivative of Eq. (23.13) which is
no longer valid. The correct result can be obtained by differentiating either Eq. (24.29) or
(24.34) with respect to T at constant N to obtain
CV =
 T
Tc
3/2
NkB
15
4
g5/2(1)
g3/2(1) = NekB
15
4
g5/2(1)
g3/2(1);
T ≤Tc.
(24.36)
3Note that the term in ln λ →0 for λ →1.

Chapter 24 • Bose Condensation
419
0.5
1
1.5
2
0.5
1
1.5
CV/(NkB)
1.924
Λ point
T/Tc
FIGURE 24–3 Heat capacity CV/(N kB) of an ideal Bose ﬂuid as a function of T/Tc. For T →∞, CV/(N kB) = 3/2,
the value for a classical ideal gas. The curve resembles the letter  and the peak of the curve, which is about 28%
higher than the classical value, occurs at the lambda point where T = Tc. The heat capacity of He4 displays a similar
behavior, although it is not an ideal Bose ﬂuid.
Since g1/2(1) = ∞, Eq. (24.35) for T = Tc yields the same result as Eq. (24.36), so CV
is continuous at Tc. On the other hand, its slope is discontinuous at Tc, as illustrated in
Figure 24–3. The CV versus T curve resembles the letter . Since the peak of the curve
corresponds to the condensation temperature, the corresponding transition in liquid He4
is said to occur at the “lambda point,” even though He4 atoms have attractive forces and
are only crudely approximated by an ideal Bose gas. Evaluated at the number density of
liquid He4, Tc ≈3 K; however, the lambda transition in liquid He4 takes place at about
2.17 K.
Equations (24.25), (24.29), and (24.34) show explicitly that the bosons that are “con-
densed” in the ground state do not contribute to the pressure, the internal energy, or the
entropy. This suggests that below Tc the ideal Bose ﬂuid behaves like a mixture of two
“phases,” the inactive condensate associated with the ground state and a normal ﬂuid
associated with the excited states. As the temperature is lowered from Tc to T = 0, it is as if
there is a “phase transition” from the normal ﬂuid to the condensate. For a brief discussion
of liquid helium as well as superﬂuidity, see Kittel and Kroemer [6, p. 20] and Pathria and
Beale [9, p. 108,215].
From the Euler equation, one has
Nμ = U −TS + pV.
(24.37)
Inserting Eqs. (24.25), (24.29), and (24.34) into Eq. (24.37) leads to μ = 0 for T ≤Tc, which
is only approximately true. In fact, μ can be found from Eq. (24.10) to be
μ = −kBT ln

1 + g0
N0

,
(24.38)
which is negative and very close to zero because g0 is of order 1 and N0 is of order N, even
if it is negligible in comparison to N, say 10−6N. See the argument in connection with
Eq. (24.12) for further detail.

420
THERMAL PHYSICS
24.2.1 Heat Capacity at Constant Pressure
Above Tc, the heat capacity at constant pressure can be calculated by differentiation of the
enthalpy H at constant N and p. First of all, we have
H = U + pV = U + (2/3)U = (5/3)U
(24.39)
and we can use Eq. (24.28) for U to obtain
Cp = 5
2NkB

g5/2(λ)
g3/2(λ) +
g3/2(λ)g′
5/2(λ) −g5/2(λ)g′
3/2(λ)
[g3/2(λ)]2
T
 ∂λ
∂T

N ,p

,
(24.40)
where the primes denote derivatives. Differentiation of Eq. (24.22) holding p constant then
leads to
 ∂λ
∂T

N ,p
= −5
2T
g5/2(λ)
g′
5/2(λ).
(24.41)
We recall that g′
5/2(λ) = λ−1g3/2(λ) and g′
3/2(λ) = λ−1g1/2(λ). Then substitution of
Eq. (24.41) into Eq. (24.40) leads to
Cp = 5
2NkB

5
2
[g5/2(λ)]2
[g3/2(λ)]2
g1/2(λ)
g3/2(λ) −3
2
g5/2(λ)
g3/2(λ)

;
T > Tc.
(24.42)
Dividing by Eq. (24.35) then yields
Cp
CV
= 5
3
g5/2(λ)g1/2(λ)
[g3/2(λ)]2
;
T > Tc.
(24.43)
For small λ, we recover the classical result Cp/CV = 5/3 but this ratio increases with λ
and for λ = 1 we obtain Cp/CV = ∞. Of course we never quite reach λ = 1 as shown by
Eq. (24.10), so the ratio remains ﬁnite but very large. With some algebra, Eq. (24.43) can be
rewritten in the form
Cp
CV
= 1 + 4
9
CV
NkB
g1/2(λ)
g3/2(λ),
(24.44)
which leads to
Cp −CV
NkB
= 4
9
 CV
NkB
2 g1/2(λ)
g3/2(λ).
(24.45)
Equation (24.45) shows that Cp > CV as expected.
For T ≤Tc, we see from Eq. (24.25) that p depends only on T. So in the approximation
λ = 1 inherent in this equation, constant p demands constant T. On the other hand, the
energy U and the enthalpy H = U + pV = (5/3)U = (5/2)pV depend on both T and V
or, alternatively, on both p and V. Therefore, at constant p and T, H can change linearly
with V. In other words, at constant p one can add or subtract heat from the system by
changing V and the system remains at constant T. The system therefore behaves as if it has
an inﬁnite heat capacity Cp. The same conclusion would be reached if we relate the heat

Chapter 24 • Bose Condensation
421
Q = TS to a change in the entropy S, since by Eq. (24.34) we see that S is also proportional
to V at constant T. In any event, when heat is added to the system at constant p and T,
the amount of condensate N0 changes. This becomes more evident if we use Eq. (24.5) to
rewrite Eq. (24.14) in the explicit form
N0 = N −Vg0
mkBT
2π¯h2
3/2
g3/2(1).
(24.46)
When heat is added to the system by increasing V at constant p and T, we see that N0
decreases linearly with V until N0 = 0, at which point the system will have a critical
volume Vc
Vc =
N
g0g3/2(1)
 2π¯h2
mkBT
3/2
.
(24.47)
For V > Vc at the same T, the ﬂuid will be entirely in the gaseous state in which virtually
all of the bosons are accommodated in the excited states. See Section 24.3 for a related
discussion.
24.3 Condensate Region
Except in the preceding section, we have regarded the volume V to be ﬁxed and focused
our discussion on temperature T relative to the critical temperature Tc. But Tc actually
depends on V, so in this section we take a broader approach.
24.3.1 In the v, T Plane
We return to Eq. (24.4) which we now write in the form
1
v = g0nQ(T)g3/2(1),
(24.48)
where v = V/N is the volume per particle. Equation (24.48) can be rewritten in the form
1
vT3/2 = g0(mkB/2π¯h2)3/2g3/2(1) =: C∗,
(24.49)
where C∗is a constant. If the quantity vT3/2 is too small, Eq. (24.49) cannot be satisﬁed,
and this deﬁnes the condensate region
vT3/2 < 1/C∗,
condensate region,
(24.50)
depicted in Figure 24–4 where the population in the ground state is so large that it must be
taken explicitly into account. This zone is bounded from above by the curve vT3/2 = 1/C∗
which can be solved to give either a critical temperature Tc(v) = (1/C∗)2/3(1/v)2/3 as a
function of v or a critical volume per particle vc(T) = (1/C∗)(1/T)3/2 as a function of T.

422
THERMAL PHYSICS
T
v
FIGURE 24–4 Condensate region (shaded) vT3/2 < 1/C∗for a Bose ﬂuid in arbitrary units. The dotted line is an
isobar (p = constant) that depends only on T in the condensate zone and asymptotes the dashed line T = pv/k for
a classical ideal gas at high temperatures and large volumes.
According to Eq. (24.23), the pressure p depends only on temperature in the condensate
region but in the normal region it follows a curved path that may be obtained by
eliminating λ between Eqs. (24.22) and (24.48), which cannot be done analytically. This
curved path may, however, be plotted parametrically by deﬁning variables
˜v = g0(m/2π¯h2)3/2;
˜t = kBT;
˜p = g−1
0 (m/2π¯h2)−3/2,
(24.51)
which allows Eqs. (24.22) and (24.48) in the forms
˜v−1˜t−3/2 = g3/2(λ);
˜p˜t−5/2 = g5/2(λ).
(24.52)
Then an isobar may be plotted from the parametric equations
˜v =
g5/2(λ)
˜p
3/5 
1
g3/2(λ)

;
˜t =

˜p
g5/2(λ)
2/5
(24.53)
by choosing some constant value of ˜p and letting λ range from very small values to 1.
For λ = 1, such an isobar will intersect the boundary of the condensate region given by
˜v−1˜t−3/2 = g3/2(1). We also observe that
˜p˜v
˜t
= g5/2(λ)
g3/2(λ) →1 as λ →0,
(24.54)
which is the classical ideal gas law that is approached asymptotically far from the conden-
sate region.
24.3.2 In the v, p Plane
Since Eq. (24.23) for the pressure may be rewritten in the form
p = kBC∗g5/2(1)T5/2/g3/2(1),
condensate region,
(24.55)

Chapter 24 • Bose Condensation
423
p
v
FIGURE 24–5 Condensate region (shaded) pv 5/3 < constant given by Eq. (24.56) for an ideal Bose ﬂuid in arbitrary
units. The dotted curve is an isotherm (T = constant) that depends only on p in the condensate zone and asymptotes
the dashed hyperbola p = kBT/v for a classical ideal gas at low pressures and large volumes.
we can combine it with Eq. (24.50) to rewrite the condensate region in the form pv5/3 <
kB(C∗)−2/3g5/2(1)/g3/2(1) or explicitly
pv5/3 < 2π¯h2
m
g5/2(1)
[g3/2(1)]5/3
1
g2/3
0
,
condensate region.
(24.56)
The condensate region given by Eq. (24.56) is depicted in Figure 24–5.
Inside the condensate region, an isotherm is independent of v and is therefore a
horizontal line at some value of p. Outside the condensate region, we can make a
parametric plot of an isotherm by using Eq. (24.52) and solving for ˜v and ˜p, resulting in
˜v = ˜t−3/2 
g3/2(λ)
−1 ;
˜p = ˜t5/2g5/2(λ).
(24.57)
Then for some ﬁxed value of ˜t, we let λ range from small values to 1. In these variables, the
condensate region is bounded by ˜p˜v5/2 = g5/2(1)

g3/2(1)
−5/3. Far from the condensate
region such an isotherm asymptotes the hyperbola ˜p˜v = ˜t for a classical ideal gas.
24.3.3 Isentropic Transformation
In a reversible adiabatic transformation, the number of particles N and the entropy S must
remain constant. For T > Tc, Eq. (24.33) applies, so constant N and S requires constant λ.
Then Eq. (24.3) shows that
vT3/2 = constant,
(24.58)
where v = V/N is the volume per particle. Similarly, Eq. (24.22) shows that
p/T5/2 = constant.
(24.59)
By eliminating T from Eqs. (24.58) and (24.59), we obtain
pv5/3 = constant.
(24.60)

424
THERMAL PHYSICS
Furthermore,
pv/T = constant,
(24.61)
which can be obtained by multiplying Eq. (24.58) by Eq. (24.59). These equations resemble
the equations for an isentropic transformation of a classical monatomic ideal gas for
which the exponent 5/3 = Cp/CV , but Eq. (24.43) for the ideal Bose gas shows that this
ratio is only equal to 5/3 in the classical limit.
For an isentropic transformation for T ≤Tc, Eq. (24.32) for λ = 1 yields Eq. (24.58)
whereas Eq. (24.23) for λ = 1 yields Eq. (24.59), so Eqs. (24.60) and (24.61) are still valid.
Comparison of Eq. (24.58) with Eq. (24.49) shows that the boundary of the condensate
region is an isentrope.

25
Degenerate Fermi Gas
In this chapter, we examine in more detail the behavior of an ideal Fermi gas. Even for
temperatures near absolute zero, the Pauli exclusion principle forces fermions into high
energy states, and the gas is said to be degenerate. Consequently, raising the temperature
causes only a small change in occupation of even higher energy states. This gives rise to a
heat capacity that is much smaller than for a classical gas. This and other phenomena are
illustrated for a simple model of a metal in which the valence electrons are treated as an
ideal Fermi gas. In the presence of a magnetic ﬁeld, the two spin states of each electron
have different energies which gives rise to weak magnetic behavior known as Pauli para-
magnetism. The magnetic ﬁeld also affects the nonspin states, which gives rise to weak
Landau diamagnetism. If sufﬁciently heated, some electrons can overcome an energy
barrier and leave the metal, a phenomenon known as thermionic emission. If an external
electric ﬁeld is applied, this energy barrier can be reduced and thermionic emission can be
enhanced. Electron emission can also be enhanced by radiation, the photoelectric effect.
Finally, we examine semiconductors that have densities of single electron quantum states
separated by a forbidden region of energy known as a band gap. Such states pertain to an
electron in an effective periodic potential that accounts approximately for interactions
with the lattice. With increase of temperature, some electrons can be excited to states
above that band gap, resulting in an overall increase in electron mobility and enhanced
electrical conductivity. Adding small amounts of impurities to such a metal, a process
known as doping, can cause major changes in the way electrons are thermally excited in
semiconductors.
25.1 Ideal Fermi Gas at Low Temperatures
For an ideal Fermi gas the average occupancy fFD(ε) (see Eq. (21.88)) of an orbital ε is given
by the bounded quantity
0 ≤
1
λ−1 eβε + 1 =
1
exp[β(ε −μ)] + 1 ≤1.
(25.1)
For an ideal Bose gas, the corresponding average occupancy becomes inﬁnite for ε = 0
as λ →1. However, for fermions, λ = eβμ can be any positive number, so 0 ≤λ ≤∞. In
particular, one does not have to take the ground state into account explicitly, so conversion
from a sum to an integral presents no problem. Therefore, for fermions, there is no critical
temperature, such as the condensation temperature Tc for bosons.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00025-9
425
Copyright © 2015 Elsevier Inc. All rights reserved.

426
THERMAL PHYSICS
At all temperatures (see Section 23.1 and Eq. (23.13) with fν(λ) = hν(λ, 1)), the particle
density n = N/V can be written in the form
n = g0nQ(T)f3/2(λ),
(25.2)
which can be regarded as an implicit equation for μ(n, T), with n speciﬁed. In
particular, the function f3/2(λ) is not bounded as λ →∞. As we shall see later,
f3/2(λ) →(ln λ)3/2/(5/2) = (βμ)3/2/(5/2)
as
λ →∞,
so
the
product
nQ(T)f3/2(λ)
becomes independentof T and proportional to μ3/2 as T →0. This leads to an equation for
μ(n, 0), the chemical potential at zero temperature, which is known as the Fermi energy,
εF ≡μ(n, 0).
This same T = 0 limit may be explored in an elementary way by returning to the sum
(see Eq. (21.89)) that led to Eq. (25.2), namely
N = g0
′

ε
1
exp[β(ε −μ)] + 1,
(25.3)
where g0 = 2s + 1 is the degeneracy due to spin s that is half integral for fermions. Thus,
the prime on the sum means that one should exclude the degeneracy g0 due to spin. As
T →0, β →∞, so μ →εF that depends only on n. Thus, fFD(ε) becomes a step function of
the form
lim
β→∞
1
exp[β(ε −μ)] + 1 =
 1 if ε < εF
0 if ε > εF.
(25.4)
In other words, all of the states for ε < εF are full and all of the states for ε > εF are empty.
So for T = 0, Eq. (25.3) takes the simple form
N = g0
′

ε<εF
1.
(25.5)
For the free particle and periodic boundary conditions, we know that ε = ¯h2k2/2m and that
the quantum states are distributed uniformly in k space with a density V/(2π)3. Therefore,
we only need to compute the volume in k space for which ε < εF, known as the volume of
the Fermi sphere. Speciﬁcally,
N = g0
V
(2π)3
 kF
0
4πk2 dk = g0
V
(2π)3
4
3πk3
F,
(25.6)
where the Fermi wavenumber kF satisﬁes εF = ¯h2k2
F/2m. We therefore obtain
kF = (6π2n/g0)1/3
(25.7)
and
εF = ¯h2
2m(6π2n/g0)2/3.
(25.8)
At T = 0 the energy is also easy to calculate because one can include a factor of ε in the
sum in Eq. (25.5) to obtain

Chapter 25 • Degenerate Fermi Gas
427
U0 = g0
′

ε<εF
ε = g0
¯h2
2m
V
(2π)3
 kF
0
4πk4 dk = 3
5NεF.
(25.9)
According to Eq. (23.18), the pressure is two-thirds of the energy density at all tempera-
tures, so the pressure at T = 0 is given by
p0 = 2
5nεF.
(25.10)
In summary, at T = 0, the fermions are forced by the Pauli exclusion principle to ﬁll
the states of lowest energy that can accommodate all of them. Thus, all states up to the
Fermi energy εF are occupied and all states above that energy are unoccupied. This forced
occupation of high energy states results in a cumulative energy given by Eq. (25.9) and a
corresponding pressure given by Eq. (25.10).
One can also deﬁne a Fermi temperature
TF := εF
kB
=
¯h2
2mkB
(6π2n/g0)2/3.
(25.11)
This may be rewritten in the form
n = g0
mkBTF
2π¯h2
3/2
4
3π1/2 ,
(25.12)
which greatly resembles Eq. (24.5) for the critical temperature Tc of an ideal Bose gas. We
emphasize, however, that TF is not a critical temperature but rather a temperature that
characterizes the degree to which fermions at T = 0 are forced into excited states by the
Pauli exclusion principle.
A word about the relative magnitudes of TF and Tc is relevant. If we consider fermions
or bosons that have comparable number densities and masses, say the masses of He3 (a
fermion with half integral spin) and He4 (a boson with integral spin), the magnitudes of
TF and Tc will be comparable. As we saw previously, Tc was typically a few K degrees at
the density of He4 near the lambda transition. But electrons are fermions and the electron
mass is about 1836 times smaller than the mass of a proton. Therefore, for free electron
gases in metals at their usual densities, TF is typically 50,000 K degrees. In such cases, one
has T ≪TF for any temperature of interest. We shall see that a Fermi gas at temperature
T > 0 but T ≪TF displays characteristics very similar to a Fermi gas at T = 0 except
a small fraction ∼T/TF of electrons is now in excited states. Consequently, a Fermi gas
at T ≪TF is usually referred to as a degenerate Fermi gas. Equivalent conditions for a
degenerate Fermi gas are therefore βμ ≫1, λ ≫1, or n/nQ(T) ≫1.
Before leaving this section, it is worth pointing out that the integrals in Eqs. (25.6) and
(25.9) could equally well have been written as integrals over ε by expressing k =

2mε/¯h2
and then using dk = (∂k/∂ε) dε. This leads to an intensive density of states of the form
g(ε) := G(ε)
V
:= g0
2
m
¯h2π2
2m
¯h2
1/2
ε1/2 = 3
2
n
εF
 ε
εF
1/2
.
(25.13)

428
THERMAL PHYSICS
Here, G(ε) dε is the number of states, including spin, with energy between ε and ε+dε and
g(ε) dε is the number of states per unit volume in that same interval. Then
n =
 εF
0
g(ε) dε
(25.14)
and the energy density
uV(T = 0) =
 εF
0
g(ε)ε dε = 3
5nεF.
(25.15)
25.2 Free Electron Model of a Metal
As an example of an ideal Fermi gas with spin s = 1/2, we treat the free electron model
of a metal. According to this model, each atom contributes zv valence electrons to a sea
of electrons that are shared by the remaining ion cores. Interactions among the valence
electrons as well as interactions with the ion cores are treated only on average. Speciﬁcally,
one assumes that each valence electron experiences an effective potential that is constant
(and set equal to zero for convenience) within the metal. The potential outside the metal
is assumed to be sufﬁciently large that the electrons are conﬁned to the volume V of the
metal. Thus, each valence electron behaves as if it were free but conﬁned to a box of
volume V. We shall see that the valence electrons constitute a very dense gas, typically
1000-10,000 times more dense than a classical gas, so quantum effects are important.
Even though the free electron model is quite naive, it works rather well for some elements,
especially the alkali metals.
The quantum statistics of such an electron gas are governed by the Fermi-Dirac
distribution function Eq. (25.1). Quantitative details for kBT ≪εF are handled by a series
expansion in kBT/μ due to Sommerfeld. We shall see that μ depends very weakly on T, so
ultimately results for μ and uV can be expressed as a series expansion in kBT/εF = T/TF.
This free electron model of a metal was the ﬁrst to explain why an electron gas in a
metal contributes only a small fraction of the heat capacity that it would if it were a
classical gas.
We estimate the number density of an electron gas in a metal. Consider a simple cubic
lattice with lattice constant a = 2.5 Å and only one valence electron per unit cell. The
number n of free electrons per unit volume is
n ∼1
a3 ∼
1
(2.5 × 10−8 cm)3 ∼6.4 × 1022 cm−3.
(25.16)
This should be compared to the number density nc of a classical ideal gas at standard
temperature and pressure, where one mole occupies 22.4 l. Thus
nc ∼
6.02 × 1023
22.4 × 103 cm3 ∼2.7 × 1019 cm−3.
(25.17)

Chapter 25 • Degenerate Fermi Gas
429
We see that the electron gas has a number density that is about 1000 times that of a
classical gas. For T = 273 K, we ﬁnd the quantum concentration nQ = (mkBT/2π¯h2)3/2 ∼
1.1 × 1019 cm−3 for electrons and 2.4 × 1024 cm−3 for hydrogen. Thus, n ≫nQ for
electrons, which are expected to behave like a dense quantum gas; however, for hydrogen
n ≪nQ so it behaves like a classical gas. For n ∼6.4 × 1022 cm−3, we have kF ∼1.1 ×
108 cm−1 which corresponds to a Fermi wavelength λF = 2π/kF ∼5.7 × 10−8 cm which is
comparable to the lattice constant a. The Fermi energy εF ∼7.7×10−12 erg ∼4.4 eV, which
corresponds to a Fermi temperature TF = εF/kB ∼51, 000 K. These numerical estimates are
typical values; for actual values for given materials, see table 2.1 of Ashcroft and Mermin
[58, p. 28]. In any case, it is important to recognize that for temperatures T of practical
interest for metals, one has T ≪TF, so only a small fraction ∼kBT/εF = T/TF of the free
electrons are thermally activated with respect to their energy levels for T = 0. This thermal
activation is governed by the Fermi-Dirac distribution function, as discussed in the
next section.
For now, we shall assume that no magnetic ﬁeld is present, so each state corresponding
to a given value of k is twofold degenerate because of spin. This degeneracy has already
been incorporated in g(ε) given by Eq. (25.13) with g0 = 2.
25.3 Thermal Activation of Electrons
The population of electronic orbitals for T > 0 is governed by the Fermi-Dirac distribution
function (see Eq. (21.88)),
fFD(ε) =
1
exp[(ε −μ)/kBT] + 1,
(25.18)
where μ is the chemical potential. This distribution function fFD(ε) gives the average
number of electrons in a single orbital having energy ε. The chemical potential at number
density n and temperature T is to be calculated from
n =
 ∞
0
g(ε)fFD(ε) dε.
(25.19)
The internal energy density is given by
uV =
 ∞
0
ε g(ε)fFD(ε) dε.
(25.20)
Equations of the forms of Eqs. (25.19) and (25.20) would hold even if g(ε) were for a more
general model in which the valence electrons were subject to an effective single-electron
potential due to a crystal lattice.
As
T →0,
Eq.
(25.4)
shows
that
fFD(ε)
is
a
step
function
as
depicted
in
Figure 25–1. For T > 0 but still T ≪TF, the corners of the step function become rounded
as also shown in Figure 25–1. In three dimensions, the value of μ becomes slightly less than

430
THERMAL PHYSICS
0.5
1
1.5
2
0.2
0.4
0.6
0.8
1
fFD(ε)
ε/μ
FIGURE 25–1 Plots of the Fermi-Dirac distribution function as a function of ε/μ for T = 0 (step function) and T > 0
but T ≪TF (curve). Note that μ also depends on T but is practically equal to εF (see Eq. (25.35)). Thus μ/kBT ≫1,
but μ/(kBT) = 30 was chosen for the sake of illustration.
εF in order to satisfy Eq. (25.19), for reasons to be discussed later. We note that fFD(μ) = 1/2
for any T > 0.
25.3.1 Sommerfeld Expansion
In order to treat Eqs. (25.19) and (25.20) in the general case of T > 0 but still T ≪TF, we
make use of an expansion due to Sommerfeld [65]. Either of these integrals is of the form
I :=
 ∞
0
w(ε)f (ε) dε,
(25.21)
where w(ε) is either g(ε) or ε g(ε). We deﬁne an auxiliary function
H(ε) =
 ε
0
w(η) dη,
(25.22)
which has the properties H(0) = 0 and
dH(ε)
dε
= w(ε).
(25.23)
Substitution into Eq. (25.21) gives
I =
 ∞
0
dH(ε)
dε
f (ε) dε = H(ε)f (ε)
∞
0 +
 ∞
0
H(ε)

−df (ε)
dε

dε.
(25.24)
The ﬁrst term on the right-hand side of Eq. (25.24) vanishes because of the properties of
H(ε) at the lower limit and f (ε) at the upper limit. The function −df /dε is highly peaked
near ε = μ and nearly 0 elsewhere because of the shape of f (ε). In fact, as T →0 it
tends toward a Dirac delta function, δ(ε −μ), which is the formal derivative of a unit step
function. We therefore realize that H(ε) is only important in the vicinity of ε = μ, so we
expand it in a power series near μ.
For convenience we make a change of variable to x := (ε −μ)/kBT which gives
I =
 ∞
−μ/kBT
H(μ + xkBT)

−df
dx

dx,
(25.25)

Chapter 25 • Degenerate Fermi Gas
431
where
−df
dx = −d
dx
1
ex + 1 =
ex
(ex + 1)2 = 1
4
1
cosh2(x/2)
,
(25.26)
which is an even function of x. Then we expand H in a Taylor series
H(xkBT + μ) = H(μ) + H′(μ)xkBT + 1
2!H′′(μ)(xkBT)2 + · · · ,
(25.27)
where a prime denotes the derivative with respect to the argument of a function. We
substitute Eq. (25.27) into Eq. (25.25) and perform the integrals over x. The lower limit in
Eq. (25.25) is essentially −∞, so integrals over odd powers of x are negligible to an excellent
asymptotic approximation. The integrals over even powers can be done analytically,1
resulting in
I = H(μ) + π2
6 w′(μ)(kBT)2 + · · · ,
(25.28)
where we have used w′(μ) = H′′(μ). Equations (25.19) and (25.20) therefore become
n =
 μ
0
g(η) dη + π2
6 g′(μ)(kBT)2 + · · · ;
(25.29)
uV =
 μ
0
ηg(η) dη + π2
6 [μg(μ)]′(kBT)2 + · · · .
(25.30)
Unfortunately we are still not done because Eqs. (25.29) and (25.30) depend on μ which
is still an unknown function of T and n. We therefore take advantage of the fact that |μ−εF|
is small compared to εF and expand again to obtain2
n =
 εF
0
g(η) dη + g(εF)(μ −εF) + π2
6 g′(εF)(kBT)2 + · · ·
(25.31)
and
uV =
 εF
0
ηg(η) dη + εFg(εF)(μ −εF) + π2
6 [εFg(εF)]′(kBT)2 + · · · .
(25.32)
By deﬁnition of the Fermi energy, the ﬁrst integral in Eq. (25.31) is equal to n. Therefore,
the remaining terms in Eq. (25.31) must vanish, resulting in
μ −εF = −π2
6
g′(εF)
g(εF) (kBT)2 + · · · .
(25.33)
1See Eq. (23.35) for additional terms. See Ashcroft and Mermin [58, appendix C] or Pathria [8, appendix E] for
details and even higher order terms of the expansion.
2Consistent to second order in kBT/εF, we do not need to expand the second-order term but simply evaluate
it at μ = εF.

432
THERMAL PHYSICS
Equation (25.33) shows that the chemical potential shifts from εF by a small amount in a
direction of opposite sign to g′(εF). Substitution of Eq. (25.33) into Eq. (25.32) gives
uV =
 εF
0
ηg(η) dη + π2
6 g(εF)(kBT)2 + · · · ,
(25.34)
which depends only on the value of g (not its derivative) at the Fermi energy. The ﬁrst term
in Eq. (25.34) is just the value of uV at T = 0 given by Eq. (25.9).
For the free electron model, for which g(ε) is given by Eq. (25.13), Eqs. (25.33) and
(25.34) become
μ = εF −π2
12 εF
kBT
εF
2
+ · · · ;
(25.35)
uV = 3
5εFn + π2
4
(kBT)2
εF
n + · · · .
(25.36)
The chemical potential (sometimes called the Fermi level) is therefore different from the
Fermi energy εF except at T = 0.
The shift in chemical potential relative to the Fermi energy can be understood by noting
that the Fermi-Dirac function given by Eq. (25.18) can be written in the form.
fFD = 1
2 −1
2 tanh[β(ε −μ)/2].
(25.37)
Thus for T > 0 but T ≪TF, the increase in the probability of occupancy with ε > μ is
exactly equal to the decrease in the probability of occupancy with ε < μ. But because
g(ε) ∝ε1/2, this change in probabilities would result in a greater number of electrons
having ε > μ with respect to the number lost from ε < μ. Thus, μ must decrease slightly
from εF in order to conserve the total number of electrons. The analytical result Eq. (25.33)
shows that the shift from εF has the same sign as g′(εF). In two dimensions, g(εF) is a
constant, so μ = εF+kBT ln[1−exp(−εF/kBT)]; thus there is no shift in chemical potential
to exponential order for εF/kBT ≫1. In one dimension, g(ε) ∝ε−1/2, so μ is slightly larger
than εF.
25.3.2 Heat Capacity
We differentiate Eq. (25.36) with respect to T to get the heat capacity per unit volume
cV = 3
2nkB
π2
3
kBT
εF
+ · · · .
(25.38)
We observe that cV depends linearly on T and is reduced from the heat capacity, 3nkB/2,
of a classical ideal gas by the small factor (π2/3)(kBT/εF). This factor arises because the
Pauli exclusion principle forces the electrons to occupy energy levels up to εF at T = 0.
Therefore, only a small fraction ∼kBT/εF of electrons are thermally activated for T ̸= 0
and each of these will have energy ∼(kBT) above εF. They will therefore lead to a heat
capacity cV ∼2nkB(kBT/εF), in agreement with Eq. (25.38) except for a numerical factor.

Chapter 25 • Degenerate Fermi Gas
433
At high T, the electronic heat capacity given by Eq. (25.38) is quite small compared with
the heat capacity ∼3nkB due to lattice vibrations,3 but at sufﬁciently low T it dominates
the heat capacity due to lattice vibrations, which is proportional to T3. Thus at low T, we
have a dependence of heat capacity on temperature of the form
cV =
 AT + BT3, electronic conductor,
BT3,
insulator,
at low T,
(25.39)
where A and B are constants.
25.4 Pauli Paramagnetism
In the presence of a magnetic ﬁeld B, we no longer have spin degeneracy so there are two
sets of states having energies:
¯h2k2
2m −μ∗B,
spin up;
¯h2k2
2m + μ∗B,
spin down,
(25.40)
where μ∗is the magnetic moment, taken to be positive. For N electrons, we have
N =

k
	
1
exp[β(¯h2k2/2m −μ∗B −μ)] + 1 +
1
exp[β(¯h2k2/2m + μ∗B −μ)] + 1

,
(25.41)
where μ is the chemical potential in the presence of the magnetic ﬁeld. For T = 0, both
of the Fermi functions become step functions and μ becomes the Fermi energy εF in the
presence of the magnetic ﬁeld. The sums can then be converted to integrals and we obtain
N =
V
(2π)3
 [(εF+μ∗B)2m/¯h2]1/2
0
4πk2 dk +
 [(εF−μ∗B)2m/¯h2]1/2
0
4πk2 dk

.
(25.42)
These integrals are over spheres in k space having slightly different radii. We obtain
n =
1
6π2
2m
¯h2
3/2 
(εF + μ∗B)3/2 + (εF −μ∗B)3/2
.
(25.43)
For B = 0, Eq. (25.43) yields
εF0 ≡εF(B = 0) = ¯h2
2m(3π2n)2/3,
(25.44)
which agrees with Eq. (25.8) for g0 = 2. For B ̸= 0 we can expand Eq. (25.43) in powers of
B. The linear term in B cancels and we are left, to second order in B, with
n =
1
3π2
2m
¯h2
3/2
ε3/2
F

1 + 3
8
μ∗B
εF
2
+ · · ·

.
(25.45)
3For lattice vibrations, n would be the number of lattice sites per unit volume, not the number of electrons
per unit volume. For the monovalent alkali metals, these number densities would be the same.

434
THERMAL PHYSICS
Then by substitution of Eq. (25.44) to eliminate n and expansion in B we ﬁnd
εF = εF0

1 −1
4
μ∗B
εF0
2
+ · · ·

.
(25.46)
Except for extremely large magnetic ﬁelds, (μ∗B/εF0)2 is negligible, so hereafter we will
take εF = εF0 and drop the extra subscript 0.
The magnetization mV (magnetic moment per unit volume) at T = 0 can now be
calculated easily by recognizing that the two terms in Eq. (25.43) come from spin up and
spin down electrons. We can therefore multiply the ﬁrst of them by μ∗and the second by
−μ∗to obtain
mV =
1
6π2
2m
¯h2
3/2 
(εF + μ∗B)3/2μ∗−(εF −μ∗B)3/2μ∗
.
(25.47)
We then expand in powers of B to obtain, to lowest order,
mV = 3
2n(μ∗)2 1
εF
B.
(25.48)
The corresponding susceptibility per unit volume is therefore
χ0 = ∂mV
∂B
= 3
2n(μ∗)2 1
εF
.
(25.49)
For high temperatures, the corresponding result for a spin 1/2 paramagnet can be calcu-
lated from Eq. (19.125) with μB = μ∗, g = 2 and J = 1/2, resulting in
χ∞= 1
V
∂M
∂B = n(μ∗)2
1
kBT .
(25.50)
Thus the electron gas has a susceptibility that is smaller by a factor of (3/2)(kBT/εF),
similar to the situation for the heat capacity. This weak paramagnetism is known as Pauli
paramagnetism.
We can give a more general treatment by returning to Eq. (25.41) and converting to
integrals, which leads to
n = nQ(T)[f3/2(λ+) + f3/2(λ−)],
(25.51)
where
λ± = exp[β(μ ± μ∗B)] = λ exp(±βμ∗B).
(25.52)
For B = 0, Eq. (25.51) becomes Eq. (25.2) for g0 = 2. Equation (23.20) can be generalized
in the same way to yield the Kramers potential
K = −kBTVnQ(T)[f5/2(λ+) + f5/2(λ−)].
(25.53)
To obtain the magnetic moment M, we note that K = F −μN and then use Eq. (19.96) to
obtain
dK = −S dT −p dV −M dB −N dμ
(25.54)

Chapter 25 • Degenerate Fermi Gas
435
from which
M = −
∂K
∂B

T,V,μ
.
(25.55)
Thus, the magnetization mV = M/V becomes
mV = nQ(T)[f3/2(λ+) −f3/2(λ−)]μ∗.
(25.56)
To compute the susceptibility χ per unit volume, we need to take the derivative of mV with
respect to B but holding T, V, N constant. This yields
χ = nQ(T)[f1/2(λ+) + f1/2(λ−)]β(μ∗)2
+ nQ(T)[f1/2(λ+) −f1/2(λ−)]μ∗β
∂μ
∂B

T,V,N
.
(25.57)
From Eq. (25.51) we compute the required derivative
∂μ
∂B

T,V,N
= −μ∗[f1/2(λ+) −f1/2(λ−)]
[f1/2(λ+) + f1/2(λ−)].
(25.58)
This results in a rather complicated expression for χ, but unless we are interested in the
very weak dependence of χ on magnetic ﬁeld, we can take the B = 0 limit in which case
both λ± can be replaced by λ = exp(βμ). Then ∂μ/∂B = 0 and Eq. (25.57) becomes
χ = 2nQ(T)β(μ∗)2f1/2(λ).
(25.59)
In this same B = 0 limit, Eq. (25.51) becomes
n = 2nQ(T)f3/2(λ).
(25.60)
Together, Eqs. (25.59) and (25.60) allow determination of χ and μ in the B = 0 limit at all
temperatures.
At low temperatures, T ≪TF, we will have λ ≫1 and we can use the asymptotic
expansion Eq. (23.35) for large λ to obtain
χ = nβ(μ∗)2 f1/2(λ)
f3/2(λ) = n(μ∗)2 3
2μ

1 −π2
6
kBT
μ
2
+ · · ·

.
(25.61)
Then Eq. (25.60) yields the same value of μ as given by Eq. (25.35) and we get our ﬁnal
answer at low temperatures,
χ = n(μ∗)2 3
2
1
εF

1 −π2
12
kBT
εF
2
+ · · ·

,
(25.62)
which agrees with Eq. (25.49) at T = 0.
At high temperatures, T ≫TF, if attainable for some spin 1/2 ideal Fermi gas, we would
have the classical case λ ≪1 and we can use the expansion Eq. (23.31) to obtain
χ = n(μ∗)2β
	
1 −
λ
23/2 + · · ·

.
(25.63)

436
THERMAL PHYSICS
It is then sufﬁcient to estimate (see Eq. (21.101)) λ = n/(2nQ(T)) and thus obtain the high
temperature result
χ = n(μ∗)2β
	
1 −
n
25/2nQ(T) + · · ·

.
(25.64)
Although we have calculated χ only for spin 1/2 particles, the same technique would
work for any half integral spin s, in which case one would have 2s + 1 different λi to
deal with.
25.5 Landau Diamagnetism
In Section 25.4, we treated Pauli paramagnetism that results from the splitting of electron
spin states in a magnetic ﬁeld. It turns out that a magnetic ﬁeld can also inﬂuence the
orbital states, which gives rise to a diamagnetic effect in which the magnetic moment
opposes the applied ﬁeld. In other words, the magnetic susceptibility for diamagnetism is
negative. We shall see that Landau diamagnetism gives rise to a susceptibility that is −1/3
the susceptibility for Pauli paramagnetism, provided that the effective orbital magnetic
moment is equal to that for spin.
For a magnetic ﬁeld applied along the z-axis, the velocity in the z-direction of a classical
particle of charge e is unaffected but its velocity in the x- and y-directions is affected by
the Lorentz force4 which acts perpendicular to z with magnitude Bev⊥/c. Thus, such a
classical charged particle would move in a spiral of radius R = mv⊥c/eB. Setting v⊥= Rω,
we see that its angular frequency would be ω = eB/mc. According to quantum mechanics,
however, this motion is quantized and gives rise to energy levels, in addition to those
associated with the free motion in the z-direction, that are spaced by ¯hω = (e¯h/mc)B,
namely,5
ε = e¯hB
mc

j + 1
2

+ ¯h2k2
z
2m ,
(25.65)
where j = 0, 1, 2, . . . .
The energy levels associated with the quantum number j are strongly degenerate,
which can be understood by relating them to a coalescence of states associated with free
x, y motion in the absence of a magnetic ﬁeld. In that case, we know for a rectangle of
dimensions Lx, Ly,

kx

ky
→LxLy
(2π)2

2πk⊥dk⊥= LxLy
(2π)2

2πk⊥
dk⊥
dε⊥
dε⊥= LxLy
h2
2πm

dε⊥,
(25.66)
4For SI units, set c =1 in this and subsequent formulas in this section.
5The quantity e¯h/mc is twice the Bohr magneton μB = e¯h/2mc that we introduced in Section 19.6.2. Except
for possible corrections for effective masses, μB = μ∗as used in Section 25.4. The given energy levels can be
obtained by mapping the x, y motion onto the problem for a harmonic oscillator.

Chapter 25 • Degenerate Fermi Gas
437
where we have used ε⊥= ¯h2k2
⊥/2m for energy associated with motion in the directions
perpendicular to z. If we then make the correspondence

dε⊥=

j
εj =

j
e¯hB
mc ,
(25.67)
we deduce that the degeneracy associated with each j level is
LxLy
h2
2πme¯hB
mc = LxLy
eB
hc.
(25.68)
This degeneracy, exclusive of spin, turns out to be correct based on a detailed solution of
the problem [66, p. 424].
We proceed to compute the grand partition function
ln Z = g0
′

ε
ln(1 + λ e−βε),
(25.69)
where the factor of g0 = 2 is due to spin degeneracy. In fact, the spin states are not
degenerate in the presence of B as we know from our treatment of Pauli paramagnetism in
Section 25.4, so we should really treat each spin state separately or, better yet, treat Landau
diamagnetism and Pauli paramagnetism simultaneously. But here we limit ourselves
to the calculation of the zero ﬁeld susceptibility, so we can treat each phenomenon
separately.6
We therefore obtain
ln Z = g0
V
2π
eB
hc
 ∞
−∞
dkz
∞

j=0
ln(1 + λ e−βε),
(25.70)
where we have replaced the sum over kz with an integral over kz and a factor of Lz/2π as
usual, recognizing that the volume V = LxLyLz. For e¯hB/mc ≪kBT, which we assume
to be the case, we might consider replacing the sum over j by an integral but this turns
out to give a result independent of B, as we shall see. We must use instead a form of the
Euler-Maclaurin sum formula
∞

j=0
g(j + 1
2) =
 ∞
0
g(x) dx + 1
24g′(0) + · · · ,
(25.71)
that is derived in Appendix H, Eq. (H.25), to obtain the ﬁrst term that depends on B. Thus,
∞

j=0
ln(1 + λ e−βε) =
 ∞
0
dx ln
	
1 + λ exp

−β e¯hB
mc x −β ¯h2k2
z
2m

−1
24β e¯hB
mc
1
λ−1 exp(β¯h2k2z/2m) + 1 + · · · .
(25.72)
6The decomposition represented later by Eq. (25.72) would still be valid if λ were replaced by λ± given by
Eq. (25.52).

438
THERMAL PHYSICS
The integral in Eq. (25.72) can be written
mc
e¯hB
 ∞
0
dy ln
	
1 + λ exp

−βy −β ¯h2k2
z
2m

= mc
e¯hB
¯h2
m
 ∞
0
k⊥dk⊥ln

1 + λ exp

−β ¯h2(k2
⊥+ k2
z)
2m

= mc
e¯hB
¯h2
m
1
2π
 ∞
0
dkx
 ∞
0
dky ln

1 + λ exp

−β
¯h2(k2
x + k2
y + k2
z)
2m

.
(25.73)
Therefore, the contribution of Eqs. (25.70)–(25.73) is
ln Z0 = g0
V
(2π)3

d3k ln[1 + λ exp(−β¯h2k2/2m)],
(25.74)
which is precisely the result for zero ﬁeld. It is therefore only the second term in Eq. (25.72),
which resulted from the discrete nature of the quantum number j, that leads to diamag-
netism. The contribution of that term to Eq. (25.70) is
ln ZB = −β
24
g0V
(2π)2
e2B2
mc2
 ∞
−∞
dkz
1
λ−1 exp(β¯h2k2z/2m) + 1
= −1
6
g0VnQ(T)
(kBT)2
(μ∗B)2f1/2(λ),
(25.75)
where μ∗= e¯h/2mc is the Bohr magneton, provided that the mass of the free electron in
the metal can be taken as the electron mass. The magnetization is
mV = kBT
V
∂ln ZB
∂B

V,μ
= −1
3
g0nQ(T)
kBT
(μ∗)2Bf1/2(λ) = −n(μ∗)2
3kBT
f1/2(λ)
f3/2(λ)B
(25.76)
to lowest order in B, where Eq. (25.2) has been used. The susceptibility per unit volume is
therefore
χ = kBT
V
∂ln ZB
∂B

V,μ
= −1
3
g0nQ(T)
kBT
(μ∗)2f1/2(λ) = −n(μ∗)2
3kBT
f1/2(λ)
f3/2(λ).
(25.77)
This diamagnetic susceptibility is −1/3 of the Pauli paramagnetic susceptibility given
by Eq. (25.61), provided of course that the values of μ∗are the same (no effective mass
corrections).
Example Problem 25.1. What is the total zero-ﬁeld susceptibility for T ≪TF due to Pauli
paramagnetism and Landau diamagnetism if there are effective mass corrections m →meff for
the translational energies ¯h2k2/2meff for both, and also a correction for the magnetic moment
for Landau diamagnetism?
Solution 25.1. For Pauli paramagnetism, we assume that μ∗= μB, the Bohr magneton. For
the Landau diamagnetism, we need μ∗= rμB, where r = m/meff. According to Eq. (25.8), the

Chapter 25 • Degenerate Fermi Gas
439
Fermi energy depends on mass, so we should use rεF in place of εF. In view of Eq. (25.62), we
have the low temperature result
χtot =

1 −r2
3
 3
2
n(μB)2
rεF

1 −π2
12
kBT
rεF
2
+ · · ·

.
(25.78)
25.6 Thermionic Emission
If a metal is heated, electrons can acquire sufﬁcient energy to escape, a process known as
thermionic emission. The process is somewhat similar to effusion, treated for a classical
gas in Section 20.1.1, except for effusion one calculates the slow rate of escape through a
small hole in a cavity. For thermionic emission, one considers the possibility that electrons
moving in a given direction, say the z-direction, can overcome a potential energy barrier
W ∗that keeps the otherwise free electrons in the metal to begin with. We measure W ∗from
the zero of energy used for free electrons inside the metal. We can think of W ∗as being
made up of two parts, a positive part W0 that would be necessary to remove an electron
very far from the metal in the absence of surface relaxation effects, and another positive
part Ws due to surface relaxation that accounts for a layer of surface dipoles (called the
double layer).7 What we actually calculate is the ﬂux J through an imaginary small window
of area a perpendicular to the z-direction, recognizing, however, that the electrons can
escape in all directions. Moreover, we assume that the rate of escape is so slow that the
system remains in quasi-equilibrium. We also assume that electrons are continuously
supplied to the metal by a suitable electrical circuit so that the metal remains electrically
neutral.
Since we know that electrons in a metal obey Fermi-Dirac statistics, they ﬁll energy
levels up to the Fermi energy εF even at T = 0. Therefore, we anticipate that they start out
with an energetic boost of approximately εF so that they only have a barrier W = W ∗−εF
to overcome. This turns out approximately to be the case, and follows naturally from a
formal treatment based on Fermi statistics. The quantity W is called the work function of
the metal.
We assume that the ﬂux can be written in the form
J = 2
V

kx

ky

kz>k∗z
1
exp {β[(¯h2k2/2m) −μ]} + 1
¯hkz
m ,
(25.79)
7Surface relaxation can be quite complicated and the value of the potential experienced by an electron
outside a metal can depend on surface condition and surface charges that depend on surface orientation. To
remove this complication in the case where all surfaces are not equivalent, one considers the electron to be
removed from the metal only to a point sufﬁciently far outside the double layer that the electron no longer
experiences any changes due to the presence of the double layer but not so far away as to be inﬂuenced by ﬁelds
external to the metal, for example due to surface charges. For a more comprehensive discussion see Ashcroft and
Mermin [58, p. 354].

440
THERMAL PHYSICS
where k∗
z = (2mW ∗/¯h2)1/2 is assumed to be the threshold value of kz needed for escape.
The quantity ¯hkz/m plays the role of velocity in the z-direction and the remainder of
the expression is the number density of eligible electrons. The factor of 2 is due to
spin degeneracy. This is the analog of Eq. (20.25) in the case of classical effusion. We
approximate summation by integration by means of a factor V/(2π)3 to obtain
J =
2
(2π)3
 ∞
−∞
dkx
 ∞
−∞
dky
 ∞
k∗z
dkz
1
exp {β[(¯h2k2/2m) −μ]} + 1
¯hkz
m .
(25.80)
We then pass to cylindrical coordinates ¯hkx = p′ cos ϕ, ¯hky = p′ sin ϕ, and ¯hkz = pz and do
the ϕ integral to obtain a factor of 2π. This results in
J = 4π
mh3
 ∞
0
p′ dp′
 ∞
p∗z
pz dpz
1
exp {β[(p′2/2m) + (p2z/2m) −μ]} + 1
,
(25.81)
where p∗
z = (2mW ∗)1/2. We perform the integral over p′ and change variables to εz = p2
z/2m
to obtain
J = 4πmkBT
h3
 ∞
W ∗dεz ln{1 + exp[−β(εz −μ)]}.
(25.82)
To proceed, we make the approximation that W ∗−μ ≫kBT which means that exp[−β(εz−
μ)] ≪1 in the range of integration. We can therefore expand the logarithm to obtain
J = 4πmkBT
h3
 ∞
W ∗dεz exp[−β(εz −μ)] = 4πm(kBT)2
h3
exp[−β(W ∗−μ)].
(25.83)
The chemical potential μ is given by Eq. (25.35) but in view of prior approximations, the
lowest order μ ≈εF will sufﬁce. We multiply by the magnitude |e| of the charge of the
electron to get the magnitude of the ﬂux of charge
Jq = |e|4πm(kBT)2
h3
exp(−βW),
(25.84)
where W = W ∗−εF is the work function of the metal, introduced previously. This result is
known as the Richardson-Dushman equation and is supported by experiment if reduced
by a transmission coefﬁcient that accounts for the surface condition of the metal and the
simplifying assumptions that have been made about the barrier for escape.
As anticipated, the energy barrier W ∗is reduced to W = W ∗−εF since at T = 0, the
electrons already occupy energy levels up to εF. If the electron gas had behaved like a
classical gas, we would have λ = exp(βμ) = n/2nQ(T) ≪1 which would result in a much
smaller ﬂux of charge8
Jclass
q
= |e|
 kBT
2πm
1/2
exp(−βW ∗)
(25.85)
with a higher activation energy W ∗and a prefactor proportional to T1/2 instead of T2.
8We write this formula only for the sake of comparison, recognizing that it is not true because n/nQ(T) ≫1 for
free electrons in metals at any reasonable temperature because of their high density and the small electron mass.

Chapter 25 • Degenerate Fermi Gas
441
25.6.1 Schottky Effect
An electric ﬁeld of strength E at the surface of a metal and directed toward the metal is
known to enhance thermionic emission. This is known as the Schottky effect, which is
reasonable to expect because an electron outside the metal, having a negative charge,
would experience a force in the opposite direction of the ﬁeld. If z measures distance
outside the metal, the electrical potential due to the electric ﬁeld is Ez and the potential
energy of an electron at distance z due to the ﬁeld is −eEz, all relative to the energy W0. But
an electron at distance z outside the metal creates an electric ﬁeld of its own that must be
canceled inside the metal by inducing a positive surface charge on the metal.9 Formally,
the effect of this surface charge can be handled by placing an imaginary image charge e at
a distance z inside the metal, in other words at location −z. The force on the electron due
to this image charge (really the induced surface charge) will be −e2/(2z)2, so the electron
will be attracted toward the metal. The potential energy felt by the electron due to this
image effect will be
 ∞
z
−e2/(2z)2 dz = −e2/(4z),
(25.86)
relative again to W0. The combined effect of these two potentials is −eEz −e2/4z which
has a maximum at z = (eE)1/2/2 where its value is −e(eE)1/2. The barrier for escape to
far distances from the surface at which the electric ﬁeld is applied therefore becomes
W0 + Ws −e(eE)1/2 = W ∗−e(eE)1/2, resulting in an effective work function
WE = W ∗−e(eE)1/2 −εF = W −e(eE)1/2
(25.87)
instead of W in Eq. (25.84). In SI units, −e(eE)1/2 →−e(eE/4πϵ0)1/2 = (1.44×10−9E)1/2 eV,
where E is measured in V/m. To reduce W by even 0.1 eV would require a large ﬁeld,
E ∼7 × 106 V/m. Typically, W is 2-4 eV.
25.6.2 Photoelectric Effect
If photons of monochromatic light of frequency ν enter a metal, they can collide with
electrons and reduce the barrier for emission from W ∗to W ∗−hν. If hν ≪W ∗, Eq. (25.84)
will apply with W replaced by W −hμ, analogous to the small reduction in the effective
work function caused by an applied electric ﬁeld. But in the case of sufﬁciently energetic
photons, hν can be comparable to W or even exceed W so we must return to Eq. (25.82)
which now becomes
J = 4πmkBT
h3
 ∞
W ∗−hν
dεz ln{1 + exp[−β(εz −μ)]}.
(25.88)
9Recall that we ignored the effect of surface charges and external ﬁelds in the result that led to the work
function W. The presence of the ﬁeld E itself also requires a positive surface charge on the metal to prevent
penetration of E into the metal.

442
THERMAL PHYSICS
We substitute εz = ukBT + W ∗−hν to obtain
J = 4πm(kBT)2
h3
 ∞
0
du ln{1 + exp[β(hν −W ∗+ μ) −u]}.
(25.89)
Then approximating W ∗−μ ≈W ∗−εF = W and deﬁning ν0 := W/h, we obtain
J = 4πm(kBT)2
h3
 ∞
0
du ln{1 + exp[βh(ν −ν0) −u]}.
(25.90)
We introduce the notation
λν := exp[βh(ν −ν0)]
(25.91)
and integrate by parts to obtain
 ∞
0
du ln[1 + λν e−u] =
 ∞
0
du
u
λ−1
ν
eu + 1
= f2(λν),
(25.92)
where f2(λν) = h2(λμ, 1) is given by Eq. (23.15). We therefore have
J = 4πm(kBT)2
h3
f2(λν).
(25.93)
Since f2(λν) is a monotonically increasing function of λν, we see that J increases mono-
tonically with ν −ν0 as one would expect. In the limit h(ν −ν0) ≫kBT, we can use the
asymptotic form (see Eq. (23.35)) f2(λν) ∼ln(λν)2/2 = β2h2(ν −ν0)2, so J saturates at a
value
Jsat = 2πm
h
(ν −ν0)2
(25.94)
that is independent of temperature.
25.7 Semiconductors
In this section, we treat the statistical mechanics of semiconductors based on single
particle states (orbitals) of an electron in an effective periodic potential due to interaction
with a crystal lattice. Thus the density of states is no longer given by the free electron result,
Eq. (25.13). As shown in a number of books on solid-state physics, the density of states can
have the following approximate form, as sketched in Figure 25–2:
g(ε) =
⎧
⎪⎪⎨
⎪⎪⎩
gv (ε) for 0 ≤ε ≤εv
0
for εv < ε < εc = εv + εg
gc(ε) for εc < ε.
(25.95)
The region of width εg = εc −εv, where g(ε) = 0 is known as a band gap that separates the
valence band gv(ε) from the conduction band gc(ε).
We consider a material for which the valence band is completely full and the conduc-
tion band is completely empty at T = 0. In this condition, each electron is in a deﬁnite
state and cannot move in response to an applied electric ﬁeld, so the material will behave

Chapter 25 • Degenerate Fermi Gas
443
g(ε)
gv(ε)
gc(ε)
εg
εv
εc
ε
FIGURE 25–2 Sketch of density of states g(ε) given by Eq. (25.95) versus electron energy ε for a simple semiconductor.
The size εg of the band gap is exaggerated for the sake of illustration.
as an insulator. For T > 0, some electrons will be excited into the conduction band, leaving
unoccupied states called holes in the valence band. Under these conditions, electrons in
both the valence and conduction bands can move in response to an electric ﬁeld and
the material can conduct electricity. Provided that εg ≫kBT, only a small number of
electrons will be excited to the conduction band. For T = 300 K, we have kBT = 0.026 eV. If
εg ≥10 eV, hardly any electrons will be excited into the conduction band and the material
will be a good insulator. However, if εg ∼1 eV or less, there will be a signiﬁcant number
of electrons excited to the conduction band, accompanied by a dramatic increase in
electrical conductivity at T = 300 K. Such a material is called an intrinsic semiconductor.
Certain dopants, which are foreign atoms of very low concentrations, can be substituted
for host atoms in the material and can greatly modify this behavior. Dopants referred to
as donors can lead to a greatly enhanced number of electrons in the conduction band
whereas so-called acceptors can lead to a greatly enhanced number of holes in the valence
band. Strongly doped materials are called extrinsic semiconductors. We ﬁrst treat the
intrinsic case and then show how dopants can be accounted for.
25.7.1 Intrinsic Semiconductors
In the absence of dopants and for a density of states given by Eq. (25.95), we assume that
N
V =
 εv
0
gv(ε) dε;
T = 0,
(25.96)
where N is the number of valence electrons. This will be true if the Fermi energy εF is
at εv or anywhere else within the band gap because there are no states in the gap. By
extrapolation from T > 0, we will see later that εF is located near the middle of the band
gap (see Eq. (25.108) for T = 0). For T > 0, the corresponding equation is
N
V =
 εv
0
gv(ε)
1
eβ(ε−μ) + 1dε +
 ∞
εc
gc(ε)
1
eβ(ε−μ) + 1 dε.
(25.97)

444
THERMAL PHYSICS
We subtract Eq. (25.96) from Eq. (25.97) to obtain
−
 εv
0
gv(ε)
1
1 + e−β(ε−μ) dε +
 ∞
εc
gc(ε)
1
eβ(ε−μ) + 1 dε = 0.
(25.98)
The second term in Eq. (25.97) is the concentration of electrons in the conduction band,
namely,
n =
 ∞
εc
gc(ε)
1
eβ(ε−μ) + 1 dε ≈
 ∞
εc
gc(ε)e−β(ε−μ) dε,
(25.99)
where the second approximate form follows, provided that ε −μ ≫kBT in the range of
integration, which we assume for now to be the case. Similarly, the negative of the ﬁrst
term in Eq. (25.98) is deﬁned to be the concentration p of holes, which are hypothetical
positive charge carriers in the valence band. Thus
p =
 εv
0
gv(ε)
1
1 + e−β(ε−μ) dε ≈
 εv
0
gv(ε)e−β(μ−ε) dε,
(25.100)
where now μ −ε ≫kBT in this range of integration. When the approximate forms in
Eqs. (25.99) and (25.100) are valid, which will be the case if εg ≫kBT and μ remains near
the center of the band gap, the semiconductor is said to be nondegenerate [6, p. 358]. See
Eqs. (25.129) and (25.131) for the degenerate case when these approximate forms are not
valid. Equation (25.98), which may be rewritten n −p = 0, can be thought of as expressing
overall charge neutrality.
By using the approximate forms for n and p, we see that
pn =
	 εv
0
gv(ε)eβε dε

 	 ∞
εc
gc(ε)e−βε dε

,
(25.101)
which is independent of μ. Equation (25.101) is independent of Eq. (25.98) provided
that n and p are given by the approximate forms on the right-hand sides of Eqs. (25.99)
and (25.100), respectively, and is known as the law of mass action.10 In the degenerate
case, pn is given by Eq. (25.134) of Section 25.7.3, where we also treat doped extrinsic
semiconductors.
In the integral for n we substitute ε = w + εc and in the integral for p we substitute
ε = εv −w which results in
n = e−βεceβμ
 ∞
0
gc(w + εc)e−βw dw
(25.102)
and
p = eβεve−βμ
 εv
0
gv(εv −w)e−βw dw.
(25.103)
10This is by analogy to a gaseous chemical reaction of the form AB = A + B; in the present case, we would
think of an electron-hole pair dissociating into an electron and a hole. In the event that the approximate forms of
Eqs. (25.99) and (25.100) do not hold, as is the case for degenerate semiconductors that result from high doping
levels, modiﬁcation is required because the full Fermi-Dirac distribution function must be used. See Section
25.7.3 and Kittel and Kroemer [6, p. 365] for details.

Chapter 25 • Degenerate Fermi Gas
445
The integrals in Eqs. (25.102) and (25.103) sample the densities of state only near the
band edges. They can be evaluated by following the conventional approximations of
semiconductor physics, according to which these densities of state near the band gap can
be approximated by those for a free electron but with the mass of the electron replaced
by an effective mass, either mn or mp. In that case, the speciﬁc forms (see Eq. (25.13))
would be
gc(w + εc) = 2
2
π1/2
 mn
2π¯h2
3/2
w1/2;
gv(εv −w) = 2
2
π1/2
 mp
2π¯h2
3/2
w1/2.
(25.104)
Then we obtain
n = n∗e−β(εc−μ);
p = p∗e−β(μ−εv),
(25.105)
where
n∗= 2
mnkBT
2π¯h2
3/2
;
p∗= 2
mpkBT
2π¯h2
3/2
.
(25.106)
We note that n∗and p∗each have the form of a quantum concentration of an ideal gas
times a factor of 2 for spin. Then Eq. (25.101) becomes
pn = p∗n∗e−βεg.
(25.107)
For an intrinsic semiconductor, Eq. (25.98) requires pi = ni, where we have added the
subscript “i” to denote the intrinsic case. Then from Eq. (25.105) we obtain
μi = εv + εc
2
+ kBT
2
ln
 p∗
n∗

= εv + 1
2εg + 3kBT
4
ln
mp
mn

,
(25.108)
which locates the chemical potential11 very near the middle of the band gap. If mn = mp,
μi is exactly in the middle of the band gap. As T →0, we have μi →εF so εF is regarded
as being near the middle of the band gap for a nondegenerate intrinsic semiconductor. By
taking the square root of Eq. (25.107), we ﬁnd the individual concentrations
ni = pi =

p∗n∗1/2 e−βεg/2.
(25.109)
Example Problem 25.2. For silicon, εg = 1.14 eV and at T = 300 K one has kBT = 0.0259 eV,
p∗= 1.1 × 1019 cm−3, and n∗= 2.7 × 1019 cm−3. Silicon is diamond cubic with a cube edge of
a = 3.57 × 10−8 cm; there are eight atoms in each cube and each has a valence of 4. Calculate
ni and compare with the total valence electron concentration N/V . Then calculate μi −εv and
compare with the middle of the band gap.
Solution 25.2. From Eq. (25.109) we calculate

p∗n∗1/2 = 1.7 × 1019 cm−3 and also
exp(−βεg/2) = 2.77 × 10−10. Thus ni = pi = 4.8 × 109 cm−3. Since N/V = 32/a3 = 7.0 ×
1023 cm−3, the ratio of ni to N/V is 6.8×10−15. We ﬁrst calculate (kBT/2) ln(p∗/n∗) = −0.012 eV
11In the semiconductor literature, the chemical potential μ is usually called the Fermi level, which should not
be confused with the Fermi energy, which is the value of μ at T = 0.

446
THERMAL PHYSICS
whereas εg/2 = 0.57 eV. Thus, μi −εv = 0.56 eV, about 2% lower than the middle of the
band gap.
25.7.2 Semiconductors with Dopants
As mentioned above, dopants known as donors and acceptors can be substituted for host
atoms to affect the carrier concentrations of electrons in the conduction band and holes
in the valence band. In the presence of dopants, we shall see that the equation n = p will
be replaced by
n −p = ,
(25.110)
where , to be discussed in the subsequent paragraph, depends on dopant concentrations
and temperature. Moreover, Eq. (25.107) can be written
pn = n2
i ,
(25.111)
where Eq. (25.109) has been used. Therefore, without yet knowing , we can write
n −n2
i
n = ,
(25.112)
which can be solved to yield
n =

n2
i + (/2)2 + /2;
p =

n2
i + (/2)2 −/2.
(25.113)
For (/2)2 ≫n2
i , the semiconductor is said to be extrinsic (dominated by dopants) and
n ≈( + ||)/2 + n2
i /||;
p ≈(− + ||)/2 + n2
i /||,
(25.114)
so n ∼ and p ∼0 if  > 0 and n ∼0 and p ∼|| if  < 0. A semiconductor is said to be
n-type or p-type depending on which is the dominant species.
By using the approximate forms in Eqs. (25.99) and (25.100), we can write
n = nieβ(μ−μi);
p = nie−β(μ−μi)
(25.115)
from which
/2 = ni sinh[β(μ −μi)].
(25.116)
For the approximate forms in Eq. (25.115) to be valid, we need |μ −μi| ≪εg/2, so
|/2| ≪ni sinh[βεg/2],
(25.117)
but this still allows |/2ni| to be fairly large. In the extrinsic limit, μ approaches either
εc or εv, shown in Figure 25–3, depending on the sign of ||. If || becomes comparable
to p∗or n∗, the chemical potential shifts so far from the center of the band gap that
the approximate forms of Eqs. (25.99) and (25.100) are no longer valid. See the Example
Problem 25.3 below for more detail.

Chapter 25 • Degenerate Fermi Gas
447
εv
Valence band
εa
εd
εc
Conduction band
εg
FIGURE 25–3 Schematic diagram of the valence and conduction bands with acceptor levels at εa just above the
valence band (which lies below εv), and donor levels at εd just below the conduction band (which lies above εc).
We now proceed to calculate . A donor12 provides one more valence electron than a
host atom, and this extra electron can possibly be added to the pool of electrons that are
subject, to a ﬁrst approximation, to the effective periodic potential. However, if the extra
electron is not localized near the donor site, the core of the donor atom, which consists
of its nucleus and other bound electrons, would appear to have a net positive charge
(relative to the host atoms). By analogy with the hydrogen atom, but in a medium with
a greatly altered dielectric constant, a donor can be regarded as a localized defect that
has a weakly bound state at an energy εd that is slightly below εc, as illustrated in Figure
25–3. We assume that the number of donors is Nd ≪N, where N is still the number
of valence electrons for the intrinsic case. Since these defects are quite dilute, they can
be treated by means of the grand canonical ensemble in which the bulk of the system
imposes a chemical potential μ, corresponding to an absolute activity λ = eβμ. There
are three possible states: The donor can be occupied with an electron of either spin (two
distinct quantum states) in which case its energy is εd or it can be in an unoccupied state
in which case its energy is 0. At temperature T, the number of donors that are occupied by
a localized electron is
Nd
2λe−βεd
1 + 2λe−βεd = Nd
1
(1/2)eβ(εd−μ) + 1 ≈Nd2e−β(εd−μ) ≪Nd,
(25.118)
provided that μ is still near the middle of the band gap and (εd−μ)/kBT ∼(εg/2)/kBT ≫1.
The number of electrons that are not locally bound to donors, and therefore the number
of positively charged (ionized) donors, is
N +
d ≡Nd
1
1 + 2λe−βεd = Nd
1
1 + 2e−β(εd−μ) ≈Nd(1 −2e−β(εd−μ)) ∼Nd.
(25.119)
In other words, if there are Nd donors, practically all of them will donate an electron to the
bands, provided that the given restrictions on μ are valid.
An acceptor13 provides one less electron than a host atom. Its core therefore appears
to have a net negative charge unless a hole is bound to the acceptor site. A hole bound
12For example, one could dope silicon with the donor phosphorus. For the host silicon, each Si atom, atomic
number 14, provides four valence electrons (3s23p2). Each donor atom P, atomic number 15, that is substituted
for Si provides ﬁve valence electrons (3s23p3).
13If the host atom is Si, each acceptor atom Al, atomic number 13, that is substituted for Si provides three
valence electrons (3s23p).

448
THERMAL PHYSICS
to an acceptor site essentially means that an electron is rejected from the site. If a hole is
not bound to the acceptor site, meaning an electron occupies the site, it gives rise to an
electronic energy level εa that lies slightly above εv. Such a state is a singlet because the
occupying electron and another electron with opposite spin from a host atom constitute
a bond. If a hole is bound to an acceptor site, an electron of either spin has left the site,
so such an unoccupied state is doubly degenerate and has energy zero. If there are Na
acceptors, the number of electrons that are bound to acceptor sites, and therefore the
number of negatively charged (ionized) acceptors, is
N −
a ≡Na
λe−βεa
2 + λe−βεa = Na
1
2eβ(εa−μ) + 1 ≈Na(1 −2e−β(μ−εa)) ∼Na,
(25.120)
and the number of acceptor sites that are not occupied by a valence electron is
Na
2
2 + λe−βεa = Na
1
1 + (1/2)eβ(μ−εa) ≈Na(e−β(μ−εa)) ≪Na.
(25.121)
Therefore, practically all of the acceptor sites will take on an electron from the bands (i.e.,
create holes in the bands), provided that μ remains near the center of the band gap.
We can now establish the following balance for electrons:
(Electrons in bands) = (Valence electrons if all sites were host atoms)
+ (Electrons freed from donors)
−(Electrons bound to acceptors).
(25.122)
The total number of valence electrons if all sites were host atoms is just N, so Eq. (25.122)
per unit volume takes the form
 εv
0
gv(ε)
1
eβ(ε−μ) + 1 dε +
 ∞
εc
gc(ε)
1
eβ(ε−μ) + 1 dε
= N
V + Nd
V
1
1 + 2e−β(εd−μ) −Na
V
1
2eβ(εa−μ) + 1.
(25.123)
We now subtract N/V from both sides and use Eq. (25.96) and the deﬁnitions of n and p
given by Eqs. (25.99) and (25.100) to obtain
 = n −p = n+
d −n−
a ,
(25.124)
where
n+
d =
N +
d
V
= nd
1
1 + 2e−β(εd−μ) ;
(25.125)
n−
a = N −
a
V
= na
1
2eβ(εa−μ) + 1.
(25.126)
The quantity on the right-hand side of Eq. (25.124) is called the net ionized donor
concentration. We note that Eq. (25.124) is just a statement of overall charge neutrality,
namely,
n + n−
a = p + n+
d .
(25.127)

Chapter 25 • Degenerate Fermi Gas
449
If  is not too large, we will have μ ∼μi ∼εv + εg/2 which gives approximately

=
nd −na to lowest order. See Kittel and Kroemer [6, p. 371] for an interest-
ing graphical solution for μ under conditions of rather large  for which μ becomes
comparable to εd.
Example Problem 25.3. Suppose that ni ≪ so that Eq. (25.114) holds. Then n ∼ and
p ∼0. Show that μ approaches the edge of the conduction band εc as  approaches n∗. Discuss
the breakdown of the approximation that leads to the second form of Eq. (25.99). Evaluate μ
under conditions for which  becomes sufﬁciently large that μ enters the conduction band.
Then examine the same problem except for  negative but of large magnitude.
Solution 25.3. From Eq. (25.105) with n =  we have
εc −μ = kBT ln(n∗/).
(25.128)
As  approaches n∗from below, we see that μ appears to approach εc from below. Examination
of Eq. (25.99) shows that the second form becomes invalid under these conditions because
exp[β(ε −μ)] will no longer be large in the range of integration. Thus, Eq. (25.105) is no longer
valid. From the ﬁrst form of Eq. (25.99) and with gc(ε) given by Eq. (25.104), we obtain
n = n∗
1
(3/2)
 ∞
0
u1/2
λ−1
c eu + 1
du = n∗f3/2(λc),
(25.129)
where λc = exp[β(μ −εc)] and f3/2 is a fermion function deﬁned in Chapter 23. If λc were
small, as it would be for μ near the middle of the band gap, one would have f3/2(λc) = λc and
Eq. (25.105) for n is recovered. But for heavy doping of donors, so that n ≈ ≫n∗, λc will be
large and we can use the asymptotic form f3/2(λc) = [β(μ −εc)]3/2/(5/2) to obtain
μ −εc =
¯h2
2mn

3π2
2/3
.
(25.130)
For  < 0 but || ≫p∗, one will have p ∼|| and n ∼0. Now (with βεv ≈∞in the upper
limit of the integral),
p = p∗
1
(3/2)
 ∞
0
u1/2
λ−1
v eu + 1
du = p∗f3/2(λv)
(25.131)
with λv = exp[β(εv −μ.)] The chemical potential will move into the valence band and
εv −μ =
¯h2
2mp

3π2||
2/3
.
(25.132)
25.7.3 Degenerate Semiconductors
Substitution of the more general expressions for n and p given by Eqs. (25.129) and (25.131)
into Eq. (25.124) gives

450
THERMAL PHYSICS
n∗f3/2(λc) −p∗f3/2(λv) =
nd
2λc + 1 −
na
2λv + 1,
(25.133)
where λc = exp[β(μ−εc)] and λv = exp[β(εv−μ)]. Since λvλc = exp(−βεg) < 1, Eq. (25.133)
can be solved to determine μ. When the doping is such that λc and λv are both small, the
semiconductor is said to be nondegenerate. Then μ is near the middle of the band gap,
f3/2(λc) ≈λc and f3/2(λv) ≈λv. Then one recovers the cases treated that are based on the
approximate expressions on the right-hand side of Eqs. (25.99) and (25.100). If the doping
is such that either λc or λv is not small, the semiconductor is said to be degenerate and the
f3/2 functions associated with the dominant carrier must be used. Alternatively, one could
replace Eq. (25.107) by
pn = p∗n∗f3/2(λv)f3/2(λc)
(25.134)
and then solve simultaneously with Eq. (25.124) by means of power series expansions,
such as the Joyce-Dixon approximation [6, p. 366].

26
Quantum Statistics
In this chapter, we discuss several formal aspects of the statistical mechanics of quan-
tum systems. Two types of averaging arise. The ﬁrst type pertains to the intrinsically
statistical nature of quantum mechanics itself and is present even when the system is
in a pure quantum state |ψ(t)⟩with wave function ψ(r, t) = ⟨r|ψ(t)⟩. The second type
of averaging pertains to averages over many quantum states related to an ensemble
used to represent a system for which complete information about its quantum state
is not known. Such an ensemble might be used to represent a system in a state of
thermodynamic equilibrium under some constraints, for example, near isolation or con-
tact with a temperature reservoir. To treat such systems, it is convenient to introduce
a statistical operator ˆρ that is known as the density operator. In terms of ˆρ, we shall
see that the expectation value of some observable having operator ˆf can be written in
the form of a trace, tr(ˆf ˆρ), which is invariant if calculated for any complete set of states
of the system. This allows us to express results in a manner independent of represen-
tation and also leads to approximation methods for problems that cannot be solved
exactly.
26.1 Pure States
If a quantum mechanical system is in a pure time-dependent state |ψ(t)⟩, the probability
density of ﬁnding the system at coordinate1 r is |ψ(r, t)|2, where the wave function is
assumed to be normalized, so
⟨ψ(t)|ψ(t)⟩=

ψ∗(r, t)ψ(r, t) dr = 1.
(26.1)
The expectation value of some operator ˆf in a pure state is
⟨f ⟩= ⟨ψ(t)|ˆf |ψ(t)⟩=

ψ∗(r, t)ˆf (r)ψ(r, t) dr,
(26.2)
where ˆf (r) is the corresponding operator (in general, a differential operator in the
Schrödinger representation).
1Here, the vector r denotes the coordinates of the entire system; for a system composed of N particles, r would
have 3N components. The function ψ(r, t) is also assumed to carry information about nonclassical variables
such as spin, but these variables are suppressed in the interest of simplicity.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00026-0
451
Copyright © 2015 Elsevier Inc. All rights reserved.

452
THERMAL PHYSICS
An alternative expression for ⟨f ⟩can be obtained by employing a complete set of states
|f ⟩in which ˆf is diagonal, that is, ˆf |f ⟩= f |f ⟩, where f is an eigenvalue. From closure, the
unit operator ˆ1 can be expressed in the form2
ˆ1 =

f
|f ⟩⟨f |.
(26.3)
Thus
⟨f ⟩= ⟨ψ(t)|ˆf |ψ(t)⟩=

f ,f ′
⟨ψ(t)|f ′⟩⟨f ′|ˆf |f ⟩⟨f |ψ(t)⟩=

f
|⟨f |ψ(t)⟩|2f .
(26.4)
The quantities ⟨f |ψ(t)⟩are just the expansion coefﬁcients for |ψ(t)⟩in the basis |f ⟩, that is,
|ψ(t)⟩=

f
|f ⟩⟨f |ψ(t)⟩.
(26.5)
By rearranging terms, Eq. (26.4) may be rewritten in the form
⟨f ⟩=

f ,f ′
⟨f |ψ(t)⟩⟨ψ(t)|f ′⟩⟨f ′|ˆf |f ⟩=

f
⟨f | ˆρˆf |f ⟩= tr( ˆρˆf ),
(26.6)
where the Hermitian operator
ˆρ := |ψ(t)⟩⟨ψ(t)|
(26.7)
is the density operator for the pure state |ψ(t)⟩. It is a projection operator onto the state
|ψ(t)⟩, so
ˆρ ˆρ = |ψ(t)⟩⟨ψ(t)|ψ(t)⟩⟨ψ(t)| = |ψ(t)⟩⟨ψ(t)| = ˆρ.
(26.8)
Since the trace of an operator is invariant if calculated in any representation, we can
calculate it with respect to an arbitrary, complete set of states |φn⟩. Because of the cyclic
properties of the trace, we have
⟨f ⟩= tr( ˆρˆf ) = tr(ˆf ˆρ) =

n
⟨φn|ˆf ˆρ|φn⟩
(26.9)
or in matrix form
⟨f ⟩=

m,n
fnmρmn,
(26.10)
where fnm = ⟨φn|ˆf |φm⟩and ρmn = ⟨φm|ψ(t)⟩⟨ψ(t)|φn⟩= ρ∗
nm. The quantities ρmn are
the elements of the density matrix ρ, which is the matrix representation of the density
operator, in this case for a pure state. By setting ˆf equal to the unit operator, Eq. (26.9)
shows that tr( ˆρ) = 1. Alternatively, Eq. (26.10) shows that 
n ρnn = 1.
2It is possible to have a continuous spectrum of states as well as discrete states in which case the closure
relation requires both integration over the complete spectrum as well as summation over the continuous
spectrum (see Dirac [67, p. 37]). Schiff [57, p. 156] uses the symbol Sf instead of a summation sign to indicate
this process. For simplicity we use only the summation sign with the implicit understanding that one must also
integrate over the continuous spectrum if relevant.

Chapter 26 • Quantum Statistics
453
26.2 Statistical States
Suppose we have incomplete knowledge of a quantum system. Instead of being sure that
the system is in some pure state |ψ(t)⟩, all we know is that the system has a probability
pi of being in the pure state |ψi(t)⟩, where i = 1, 2, . . .. Such a state is called a statistical
state, also known as a mixed state. For convenience, we take the set of states |ψi(t)⟩
to be mutually orthonormal, although not necessarily complete. From the results of the
preceding section, the average value in a statistical state of some observable represented
by the operator ˆf is therefore
⟨f ⟩=

i
pi ⟨ψi(t)|ˆf |ψi(t)⟩.
(26.11)
Note that Eq. (26.11) involves an averaging process for each quantum state |ψi(t)⟩as well
as a weighted average over the quantum states i = 1, 2, . . ., each with probability pi, that
make up the statistical state. By employing any complete set of states φn for which the unit
operator is 
n |φn⟩⟨φn|, this average may be written
⟨f ⟩=

i,n
pi ⟨ψi(t)|ˆf |φn⟩⟨φn|ψi(t)⟩=

i,n
pi ⟨φn|ψi(t)⟩⟨ψi(t)|ˆf |φn⟩= tr( ˆρS ˆf ),
(26.12)
where the Hermitian operator
ˆρS =

i
|ψi(t)⟩pi⟨ψi(t)|
(26.13)
is the density operator for a statistical state. For the special case in which |φn⟩are chosen
to be eigenstates |f ⟩of ˆf with eigenvalues f , we obtain
⟨f ⟩=

i,f
pi f |⟨f |ψi(t)⟩|2,
(26.14)
which illustrates that two averaging processes are involved. One is quantum mechanical
averaging with weighting factors |⟨f |ψi(t)⟩|2 given by the squares of the wave func-
tion for the pure state i; the second is statistical averaging with probabilities pi of
that state.
Since the pi are probabilities, we have pi ≥0 and 
i pi = 1. Thus,
tr( ˆρS) =

n
⟨φn|

i
|ψi(t)⟩pi⟨ψi(t)||φn⟩=

i
pi

n
⟨ψi(t)|φn⟩⟨φn|ψi(t)⟩= 1.
(26.15)
Moreover,
( ˆρS)2 =

i
|ψi(t)⟩pi⟨ψi(t)|

j
|ψj(t)⟩pj⟨ψj(t)| =

i
|ψi(t)⟩p2
i ⟨ψi(t)|.
(26.16)
Since Eq. (26.8) holds for a pure state, Eq. (26.16) show that ˆρS represents a pure state only
in the special case when one of the pi is equal to unity and the rest are zero. In general,
tr(( ˆρS)2) =

i
p2
i ≤1,
(26.17)

454
THERMAL PHYSICS
with the equality holding only for a pure state. For an arbitrary basis |φn⟩we would have
⟨f ⟩= tr( ˆρSˆf ) = tr(ˆf ˆρS) =

n
⟨φn|ˆf ˆρS|φn⟩=

m,n
fnmρS
mn,
(26.18)
where ρS
mn = 
i ⟨φm|ψi(t)⟩pi⟨ψi(t)|φn⟩= (ρS
nm)∗.
26.3 Random Phases and External Inﬂuence
A statistical density operator of the form of Eq. (26.13) can be rationalized in several ways.
We discuss two possibilities, for which the author is grateful for private discussions with
R.B. Grifﬁths.
The ﬁrst rationalization is based on the assumption of random phases, for example, see
[8, p. 109] and [68, chapter 9]. First, consider a normalized pure state of the form
|α(t)⟩=

j
pj exp(iαj)|ψj(t)⟩,
(26.19)
where the αj are a set of phases. Normalization requires 
i pi = 1. The projection operator
for such a state is
|α(t)⟩⟨α(t)| =

j,k
pjpk exp[i(αj −αk)]|ψj(t)⟩⟨ψk(t)|.
(26.20)
A density operator of the form of Eq. (26.13) can be obtained by averaging over the phases
αj with the assumption that the phases corresponding to different values of j are random.
Explicitly,
|α(t)⟩⟨α(t)| =

j,k
pjpk exp[i(αj −αk)] |ψj(t)⟩⟨ψk(t)|
=

j,k
pjpk δjk |ψj(t)⟩⟨ψk(t)| =

j
pj|ψj(t)⟩⟨ψj(t)|.
(26.21)
The second rationalization is based on a description of both the system and its
environment. We can represent the total normalized wave function of a system by a state
of the form
|ϵ(t)⟩=

j
|ϵj⟩⊗exp(iαj)pj |ψj(t)⟩,
(26.22)
where ⊗represents the outer product of the subspace spanned by an orthonormal set
(not necessarily complete) of external states |ϵj⟩and the states |ψj(t)⟩of the system. The
corresponding (total) projection operator is
|ϵ(t)⟩⟨ϵ(t)| =

j,k
|ϵj⟩⟨ϵk| ⊗exp[i(αj −αk)]pjpk |ψj(t)⟩⟨ψk(t)|.
(26.23)
A density operator for the system of interest of the form of Eq. (26.13) can be obtained by
taking the expectation value, and hence the trace, of this total projection operator with
respect to any complete set of orthonormal external states |φϵ⟩, resulting in

Chapter 26 • Quantum Statistics
455
trϵ(|ϵ(t)⟩⟨ϵ(t)|) =

j,k

φϵ
⟨φϵ|ϵj⟩⟨ϵk|φϵ⟩exp[i(αj −αk)]pjpk |ψj(t)⟩⟨φk(t)|
=

j,k
⟨ϵk|ϵj⟩exp[i(αj −αk)]pjpk |ψj(t)⟩⟨φk(t)|
=

j
pj|ψj(t)⟩⟨φj(t)|.
(26.24)
Either of these rationalizations demonstrates that the statistical operator describes a
quantum mechanical system for which there is incomplete information. The phases of
the associated quantum states are unknown but one can still average over those quantum
states by knowledge of their probabilities.
26.4 Time Evolution
One can calculate the time evolution of the statistical density operator by recognizing that
the probabilities pi are independent of time and making use of the evolution equations for
the states |ψi(t)⟩which evolve according to
i¯h d
dt |ψi(t)⟩= ˆH|ψi(t)⟩
(26.25)
and its Hermitian conjugate
−i¯h d
dt ⟨ψi(t)| = ⟨ψi(t)| ˆH,
(26.26)
where ˆH is the Hamiltonian operator (which, of course, is Hermitian). Thus
i¯h d
dt ˆρS = d
dt

i
|ψi(t)⟩pi⟨ψi(t)|
=

i

i¯h d
dt |ψi(t)⟩

pi⟨ψi(t)| + |ψi(t)⟩pi

i¯h d
dt ⟨ψi(t)|
	
=

i

ˆH|ψi(t)⟩pi⟨ψi(t)| −|ψi(t)⟩pi⟨ψi(t)| ˆH

.
(26.27)
Thus3
i¯h d
dt ˆρS = ˆH ˆρS −ˆρS ˆH ≡

ˆH, ˆρS
,
(26.28)
where the latter expression is a commutator. Equation (26.28) also applies to the density
operator for a pure state |ψi(t)⟩if pi = 1 and pj = 0 for j ̸= i.
3Here, the operator ˆρS is in the Schrödinger representation. The result in Eq. (26.28) should not be confused
with the time derivative of an operator in the Heisenberg representation, which contains a commutator with
opposite sign.

456
THERMAL PHYSICS
If ˆρS is the statistical operator for an equilibrium state, we need d ˆρS/dt
= 0 in
which case

ˆH, ˆρS
= 0,
(26.29)
that is, ˆρS commutes with the Hamiltonian. Equation (26.28) is the quantum mechanical
analog of the classical Liouville equation (Eq. (17.9)) for an equilibrium ensemble for
which the density in phase space has no explicit dependence on time, ∂ρ/∂t = 0. The
lack of explicit time dependence of the classical density function ρ is the counterpart of
the fact that the probabilities pi are independent of time. The classical analog to Eq. (26.29)
is Eq. (17.11), namely the vanishing of the Poisson bracket {ρ, H}.
The time derivative of the average value ⟨f ⟩of some observable may be computed in a
similar way as follows:4
d
dt ⟨f ⟩= d
dt tr( ˆρS ˆf ) = tr

d ˆρS
dt
ˆf

+ tr

ˆρS ∂ˆf
∂t

= 1
i¯htr

ˆH, ˆρS
ˆf

+ tr

ˆρS ∂ˆf
∂t

.
(26.30)
If the observable is explicitly independent of time, ∂ˆf /∂t = 0, and for an equilibrium state
Eq. (26.29) applies, so d⟨f ⟩/dt = 0, as expected.
26.5 Density Operators for Speciﬁc Ensembles
In this section, we present the statistical density operators for the three main ensembles,
microcanonical, canonical, and grand canonical, employed in statistical thermodynamics.
These ensembles pertain to equilibrium states, so Eq. (26.29) applies and can be satisﬁed
by choosing ˆρS to be a function of a Hamiltonian ˆH that is independent of time. ˆρS can
therefore be expressed in terms of a set of probabilities and the stationary eigenstates |En⟩
of ˆH. It is for this reason that we only had to deal with the stationary eigenstates of ˆH
in our previous description of statistical mechanics, beginning with the microcanonical
ensemble.
For brevity of notation we drop the superscript S in the rest of this section, but bear
in mind that we are dealing with a statistical operator for a system in equilibrium. The
results can therefore be expressed easily in the energy representation where the matrix
representations of ˆH, and therefore also ˆρ( ˆH), are diagonal. Speciﬁcally, we employ a
complete set of orthonormal stationary eigenstates |En⟩that satisfy ˆH|En⟩= En|En⟩. Note
especially that n labels states, not energies, so there can be many values of n for a given
energy in the case of degeneracy. For the case of the grand canonical ensemble, we will
employ states that are also eigenstates of the number operator ˆN . See Appendix I for more
information about number operators.
4The operator ˆf is in the Schrödinger representation so its only dependence on time is explicit; we therefore
use a partial derivative for its time rate of change.

Chapter 26 • Quantum Statistics
457
26.5.1 Microcanonical Ensemble
The microcanonical ensemble applies in principle to an isolated system having constant
total energy E. We recognize, however, that a truly isolated system is an impossibil-
ity because there will always be some interaction of a system with its environment,
even if ever so slight. Because of the uncertainty relation 
E ∼¯h/
t, a constant en-
ergy would require isolation for an inﬁnite time. Therefore, we actually treat a quasi-
isolated system (see [66, p. 14]) for which the energy lies in a very narrow range E −
E
to E. Within this range, the number of quantum states of the system is represented
by , and each is assumed to be equally probable. Then the density operator has
the form
ˆρ =

n
|En⟩pn⟨En| =


n=1
|En⟩1
⟨En|;
pn =
 1/ for E −
E ≤En ≤E.
0
otherwise.
(26.31)
The entropy is given by S = kB ln . In terms of ˆρ, it can be calculated from the formula
S = −kBtr( ˆρ ln ˆρ),
(26.32)
where the function ln ˆρ is to be understood as the operator whose eigenvalues, in a
representation where ˆρ is diagonal, are equal to the logarithm of the eigenvalues of ˆρ. The
quantity −tr( ˆρ ln ˆρ) in Eq. (26.32) is just the expectation value of −ln ˆρ in the statistical
state represented by ˆρ; in a representation where ˆρ can be represented by a diagonal matrix
with diagonal elements Pn, Eq. (26.32) gives the familiar result S = −kB

n Pn ln Pn. For
the microcanonical ensemble we can evaluate the trace in an arbitrary, complete set of
states |φm⟩to obtain
−tr( ˆρ ln ˆρ) = −

m
⟨φm|


n=1
|En⟩ln(1/)

⟨En||φm⟩
=


n=1

m
⟨En|φm⟩⟨φm|En⟩ln 

=


n=1
⟨En|En⟩ln 

= ln .
(26.33)
26.5.2 Canonical Ensemble
The canonical ensemble pertains to a system in contact with a heat reservoir that
maintains the system at temperature T. The corresponding probabilities in the
energy representation are just Pn
=
exp(−βEn)/Z, where β
=
1/(kBT) and Z
=

m exp(−βEm) is the canonical partition function. Thus we can write the density operator
in the form
ˆρ =

n
|En⟩exp(−βEn)
Z
⟨En| = exp(−β ˆH)
Z
=
exp(−β ˆH)
tr

exp(−β ˆH)
.
(26.34)
In this case, the sum is over all energy states, a complete set. From the last form of
Eq. (26.34), it is obvious that tr ˆρ = 1. In this case, Eq. (26.32) leads to the familiar formula

458
THERMAL PHYSICS
S/kB = −tr( ˆρ ln ˆρ) = −

m
⟨φm|

n
|En⟩Pn ln Pn⟨En||φm⟩= −

n
Pn ln Pn,
(26.35)
where Pn are the probabilities of occupation of the states. Of course the expectation value
of the energy itself is the internal energy
U = ⟨ˆH⟩= tr( ˆρ ˆH) =
tr

ˆH exp(−β ˆH)

tr

exp(−β ˆH)
 .
(26.36)
If the eigenvalues of ˆH cannot be calculated, the last expression in Eq. (26.36) can be
calculated, at least approximately, in any convenient representation. If the eigenvalues are
known, then we retrieve the familiar result
U =

n En exp(−βEn)

m exp(−βEm) .
(26.37)
26.5.3 Grand Canonical Ensemble
Based on the considerations of Chapter 21, the density operator in the grand canonical
ensemble will be diagonal in a set of states that are simultaneous eigenfunctions of the
number operator ˆN and the Hamiltonian operator ˆH for a system having N particles. Such
states |NsErs⟩satisfy
ˆH|NsErs⟩= Ers|NsErs⟩;
ˆN|NsErs⟩= Ns|NsErs⟩.
(26.38)
Thus with Prs being the probability of the state |NsErs⟩, we have
ˆρ =

r,s
|NsErs⟩Prs⟨NsErs| =

r,s
|NsErs⟩exp[−β(Ers −μNs)]
Z
⟨NsErs|
= exp[−β( ˆH −μ ˆN)]
Z
=
exp[−β( ˆH −μ ˆN)]
tr

exp[−β( ˆH −μ ˆN)]
,
(26.39)
where the grand partition function (see Eq. (21.21))
Z =

s
exp(βμNs)

r
exp(−βErs) =

s
λNs 
r
exp(−βErs).
(26.40)
Here, λ = exp(βμ) is the absolute activity. The expectation value of some observable
having operator ˆf is therefore
⟨f ⟩= (1/Z)tr

ˆf exp[−β( ˆH −μ ˆN)]

=

N λN ⟨f ⟩N ZN

N λN ZN
,
(26.41)
where ZN is the canonical partition function for a system of N particles and ⟨f ⟩N
is the canonical average of ˆf for that system. From Eq. (26.32), the entropy is just
S = −kB

r,s Prs ln Prs as expected.

Chapter 26 • Quantum Statistics
459
26.6 Examples of the Density Matrix
For the canonical ensemble, we calculate the matrix elements of the equilibrium statistical
density operator for several simple systems. First, we treat a free spinless particle in a box,
then a one-dimensional harmonic oscillator, and ﬁnally a spin 1/2 particle.
26.6.1 Single Free Particle
We consider a single free particle in a cubical box of dimension L and volume V = L3 with
periodic boundary conditions. The wave function is
ψk(r) = V −1/2 exp(ik · r),
(26.42)
which satisﬁes
ˆHψk = εkψk
(26.43)
with εk = ¯h2k2/(2m). Here, ˆH = ˆp2/2m, where ˆp = (¯h/i)∇is the momentum operator.
For periodic boundary conditions, ψk is also an eigenfunction of the momentum operator
with eigenvalue ¯hk, so we can label the energy eigenstates by k as well as εk. The allowed
values of k satisfy kα = 2nαπ/L, where α = x, y, z and nα are integers (positive, negative,
and zero). In terms of the eigenstates |εk⟩, for which ψk(r) = ⟨r|εk⟩, the relevant matrix
elements are
⟨εk| exp(−β ˆH)|εk′⟩= exp(−βεk) δkk′.
(26.44)
Thus
tr(exp(−β ˆH)) =

k
exp(−βεk) ≈
V
(2π)3

d3k exp[−β¯h2k2/(2m)]
=
V
(2π)3
 2m
β¯h2
1/2  ∞
−∞
dx exp(−x2)
3
= V /λ3
T.
(26.45)
Here, λT is the thermal wavelength given by
1
λ3
T
=

m
2π¯h2β
3/2
= nQ,
(26.46)
where nQ is the quantum concentration. Thus, in the energy representation, the density
operator for a single free particle is represented by the diagonal matrix
⟨εk| ˆρ|εk′⟩= (λ3
T/V ) exp(−βεk)δkk′.
(26.47)
Since these energy eigenstates are also eigenstates of the momentum operator, Eq. (26.47)
could also be written
⟨k| ˆρ|k′⟩= (λ3
T/V ) exp[−β¯h2k2/(2m)]δkk′.
(26.48)

460
THERMAL PHYSICS
We proceed to calculate the matrix elements of ˆρ in the coordinate representation |r⟩
where it is not diagonal. Thus
⟨r| ˆρ|r′⟩=

kk′
⟨r|k⟩⟨k| ˆρ|k′⟩⟨k′|r′⟩= λ3
T
V 2

k
exp[−β¯h2k2/(2m)] exp[ik · (r −r′)]
≈λ3
T
V 2
V
(2π)3

d3k exp[−β¯h2k2/(2m)] exp[ik · (r −r′)]
(26.49)
=
λ3
T
(2π)3V exp[−m|r −r′|2/(2β¯h2)]

d3k exp[−(β¯h2/2m)|k −i(m/β¯h2)(r −r′)|2]
=
λ3
T
(2π)3V exp[−m|r −r′|2/(2β¯h2)]
2πm
β¯h2
3/2
,
(26.50)
where we have completed the square in the argument of the exponential to get a Gaussian
integral. In terms of λT, this result can be written simply as
⟨r| ˆρ|r′⟩= 1
V exp[−π (|r −r′|/λT)2].
(26.51)
The diagonal element⟨r| ˆρ|r⟩= 1/V is independent of r and shows that there is a uniform
probability density of ﬁnding the particle anywhere in the box, as would be expected for
periodic boundary conditions. Of course tr ˆρ =

V ⟨r| ˆρ|r⟩d3r = V/V = 1.
One could also treat this problem with boundary conditions for which the wave func-
tion vanishes on the sides of the box. In that case, ψεk = (8/V)1/2 sin(kxx) sin(kyy) sin(kzz),
with k now given by Eq. (16.52). In that case, εk = ¯h2k2/2m, but ψεk is no longer an
eigenfunction of the momentum operator ˆp. As expected, ⟨r| ˆρ|r⟩goes to zero on the sides
of the box and increases to a maximum at the center of the box. For λT much smaller than
any edge length of the box, ⟨r| ˆρ|r⟩≈1/V except within a distance of order λT near the
walls of the box.
26.6.2 One-Dimensional Harmonic Oscillator
For a harmonic oscillator in one dimension, x, the energies are given by εn = ¯hω(n + 1/2)
and the partition function z = exp(−β¯hω/2)/[1 −exp(−β¯hω)]. Thus the probabilities are
pn = exp(−βεn)/z = exp(−nβ¯hω)[1 −exp(β¯hω)],
(26.52)
independent of the zero point energy. The density operator is therefore
ˆρ =
∞

n=0
|n⟩pn⟨n|.
(26.53)
The expectation value of x2 is given by
⟨x2⟩= tr( ˆρ ˆx2) =
∞

n=0
pn⟨n|ˆx2|n⟩.
(26.54)

Chapter 26 • Quantum Statistics
461
In Appendix I, it is shown by Eq. (I.10) that the operator ˆx2 can be expressed in terms of the
raising and lowering operators a† and a, resulting in
ˆx2 =
¯h
mω

a†a + 1
2 + aa + a†a†
2

.
(26.55)
The operators aa and a†a† have no diagonal elements, so ⟨n|ˆx2|n⟩= ¯h(n + 1/2)/(mω).
Therefore,
⟨x2⟩=
∞

n=0
pn¯h(n + 1/2)/(mω) =
∞

n=0
pnεn/(mω2) = ⟨H⟩/(mω2).
(26.56)
Here, ⟨H⟩= ¯hω[1/2 + (exp(β¯hω) −1)−1] is the average energy. Thus the average potential
energy is (1/2)mω2⟨x2⟩= (1/2)⟨H⟩just as for the time average of the potential energy
of a classical harmonic oscillator. The average of the kinetic energy is therefore ⟨H⟩−
(1/2)⟨H⟩= (1/2)⟨H⟩, the same as the time average of the kinetic energy of a classical
harmonic oscillator.
See Pathria [8, pp. 113-115] for a representation of this density matrix in the x represen-
tation, where it is also shown that ⟨x| ˆρ|x⟩follows a Gaussian distribution.
26.6.3 Spin 1/2 Particle
In the previous examples, we have not included spin, so we proceed here to treat electrons
having spin 1/2. We will begin by treating a pure state and then proceed to discuss a
statistical state. We represent the pure state by
|χ⟩= c1|α⟩+ c2|β⟩,
(26.57)
where, for some arbitrary z-axis, |α⟩corresponds to spin up, |β⟩corresponds to spin down,
and c1 and c2 are complex numbers. |χ⟩is assumed to be normalized, so |c1|2 + |c2|2 = 1.
The density operator is the projection operator
ˆρ = |χ⟩⟨χ| = |c1|2|α⟩⟨α| + c1c∗
2|α⟩⟨β| + c∗
1c2|β⟩⟨α| + |c2|2|β⟩⟨β|.
(26.58)
In a matrix notation, Eq. (26.57) can be written as a spinor
χ =
 c1
c2

= c1
 1
0

+ c2
 0
1

≡c1α + c2β,
(26.59)
so the density matrix corresponding to Eq. (26.58) is
ρ = χχ† =
 c1
c2

(c∗
1 c∗
2) =
 |c1|2 c1c∗
2
c∗
1c2 |c2|2

,
(26.60)
which is Hermitian.
It is usual to express ρ in terms of the Pauli spin matrices
σx =
 0 1
1 0

;
σy =
 0 −i
i
0

;
σz =
 1
0
0 −1

.
(26.61)

462
THERMAL PHYSICS
These have the properties
σxσy = −σyσx = iσz;
σyσz = −σzσy = iσx;
σzσx = −σxσz = iσy;
σ 2
x = σ 2
y = σ 2
z = E ≡

1 0
0 1

;
tr σx = tr σy = tr σz = 0.
(26.62)
The Pauli spin matrices can be related to fermion operators that anticommute, as devel-
oped in Section I.3 of Appendix I.
It is useful to deﬁne a quantity σ, whose x, y, and z components are the matrices σx,
σy, and σz. By studying the transformation of χ under rotations, it can be shown that
the expectation value of σx transforms like a vector [69, pp. 261-270]. In this sense, σ is
the matrix representation of a vector operator. Moreover, we recognize that σx, σy, σz,
and E constitute a linearly independent set in terms of which ρ can be expanded. This
results in
ρ = (1/2)[E + P · σ],
(26.63)
where
Px = c∗
1c2 + c1c∗
2 = 2ℜ(c∗
1c2),
Py = (c∗
1c2 −c1c∗
2)/i = 2ℑ(c∗
1c2)
Pz = |c1|2 −|c2|2,
(26.64)
which may be veriﬁed as follows. First, take the trace of Eq. (26.63) and recognize that
tr ρ = 1, tr E = 2 and tr σ = 0, which veriﬁes the term (1/2)E. Then multiply Eq. (26.63) by
σx and take the trace to obtain
⟨σx⟩= tr (σxρ) = (1/2)Px tr (σ 2
x ) = Px,
(26.65)
where Eq. (26.62) has been used. By using the explicit form Eq. (26.60) for ρ, we can
compute σxρ and take its trace, thus verifying Px in Eq. (26.64). Proceeding in a similar
way for the y and z components, we verify the expressions for Py and Pz and obtain the
result
⟨σ⟩= P.
(26.66)
It also turns out that P is a unit vector, which is known as the polarization vector for the
pure state χ under consideration. This can be seen readily by writing c1 = |c1|eiγ1 and
c2 = |c2|eiγ2 in which case c∗
1c2 = |c1||c2|eiγ , where γ = γ2 −γ1. Then Px = 2|c1||c2| cos γ
and Py = 2|c1||c2| sin γ . Thus
P2
x + P2
y + P2
z = 4|c1|2|c2|2 + (|c1|2 −|c2|2)2 = (|c1|2 + |c2|2)2 = 1.
(26.67)
We are now in a position to relate to the magnetic moment of an electron which has
spin (1/2). We associate the “spin up” state α with the spin component (1/2) and the “spin
down” state β with the spin component −(1/2). For simplicity, we approximate the g-
factor for spin (approximately 2.0023) by 2, so the magnetic moment for spin up would
be −2μB(1/2) = −μB, where μB = e¯h/(2mc) > 0 is the Bohr magneton and the minus sign
results from the negative charge of the electron. The magnetic moment operator in matrix
notation is therefore

Chapter 26 • Quantum Statistics
463
μ = −μBσ
(26.68)
and the Hamiltonian is5
H = −μ · B = μBσ·B.
(26.69)
More insight can be gained by noting that ρ given by Eq. (26.60) has eigenvalues λ = 1
and λ = 0. Moreover, χ is a normalized eigenvector of ρ corresponding to λ = 1, unique
except for an overall phase factor. An eigenvector of ρ that corresponds to λ = 0 must
be perpendicular to χ and can be taken to be χ⊥= c∗
2α −c∗
1β which is also normalized.
Operating on χ given by Eq. (26.59) yields
ρχ = χ = (1/2)[χ + P · σ χ]
(26.70)
from which we deduce that P·σ χ = χ, so χ is also an eigenvector of P·σ with eigenvector
1. Similarly, operating on χ⊥gives
ρχ⊥= 0 = (1/2)[χ⊥+ P · σ χ⊥],
(26.71)
so P·σ χ⊥= −χ⊥. This is equivalent to saying that χ⊥is an eigenstate of the operator
−P·σ with eigenvalue 1. Therefore, for an axis along P, χ corresponds to the “spin up”
state and χ⊥corresponds to the “spin down” state. This shows that the operator P·σ is
the spin operator for the direction P that corresponds to σz for our original but arbitrary
choice of the orientation of the z-axis, consistent with Eq. (26.68) for the magnetic moment
operator.
For a statistical state, all we know are the probabilities pα of being in the eigenstate |α⟩
and pβ of being in the eigenstate |β⟩. The density operator is
ˆρS = pα|α⟩⟨α| + pβ|β⟩⟨β|,
(26.72)
where |α⟩⟨α| and |β⟩⟨β| are projection operators for the respective states. The correspond-
ing density matrix
ρS =
 pα
0
0
pβ

(26.73)
is diagonal with elements equal to pα and pβ. We can rewrite Eq. (26.73) in the form
ρS = (1/2)[E + (pα −pβ)σz],
(26.74)
which is quite different from ρ for a pure state given by Eq. (26.60) for the case in which
|c1|2 = pα and |c2|2 = pβ. For the statistical state and the pure state, the expectation
value of α will be pα and that for β will be pβ. This is easily veriﬁed by taking the
5We often say that the spins tend to line up with the magnetic ﬁeld, but the low energy state for an electron,
due to its negative charge, occurs when its spin is opposite to the magnetic ﬁeld so its magnetic moment is along
the magnetic ﬁeld.

464
THERMAL PHYSICS
trace of the density matrix with the respective projection operator. For example, for the
pure state
tr( ˆρ|α⟩⟨α|) = ⟨α| ˆρ|α⟩+ ⟨β| ˆρ|α⟩⟨α|β⟩= ⟨α| ˆρ|α⟩= |c1|2 = pα.
(26.75)
But at least one of the quantities ⟨σx⟩= Px or ⟨σy⟩= Py will not be zero for the pure
state, except for the special values c1 = 0 or c2 = 0, in which cases both density matrices
represent the same pure state. On the other hand, for the statistical state ⟨σx⟩= ⟨σy⟩= 0.
We can also construct a statistical state based on the states χ and χ⊥with density
operator
ˆρS
χ = pχ|χ⟩⟨χ| + p⊥|χ⊥⟩⟨χ⊥|,
(26.76)
where pχ and p⊥are probabilities. By using Eq. (26.63) for each pure state and recalling
that −P corresponds to χ⊥, we deduce the corresponding density matrix
ρS
χ = (1/2)[E + (pχ −p⊥)P·σ].
(26.77)
Equation (26.77) resembles Eq. (26.74) but with respect to the P-axis, as opposed to our
original arbitrary z-axis. For P not along the z-axis, these represent different statistical
states except for the special values pα = pβ = pχ = p⊥= 1/2, in which case ρS = ρS
χ =
(1/2)E. Such a statistical state is isotropic in the sense that the expectation value for a state
of any orientation is equal to 1/2.
There is an interesting relationship for expectation values of χ and χ⊥for ρS and for α
and β in ρS
χ. Thus
tr(ρS|χ⟩⟨χ|) = pα|c2
1 + pβ|c2|2;
tr(ρS|χ⊥⟩⟨χ⊥|) = pα|c2|2 + pβ|c1|2,
(26.78)
which sum to 1 whereas
tr(ρS
χ|α⟩⟨α|) = pχ|c2
1 + p⊥|c2|2;
tr(ρS
χ|β⟩⟨β|) = pχ|c2|2 + p⊥|c1|2,
(26.79)
which also sum to 1. For the isotropic statistical state, each of these probabilities is equal
to 1/2. Equations (26.78) and (26.79) are special cases of Eq. (26.11) for which the operator
ˆf is a projection operator for some pure state.
For a magnetic ﬁeld B, which for convenience we can take to be along the z-axis, the
Hamiltonian will be H = μBBσz. The eigenstates are then just α and β with respective
energies μBB and −μBB. For thermal equilibrium, the probabilities would be
pα = e−w/(ew + e−w);
pβ = ew/(ew + e−w)
(26.80)
with w = βμBB. Then
⟨σz⟩= (pα −pβ) = (e−w −ew)/(ew + e−w) = −tanh w
(26.81)
and the magnetic moment is μz = −μB⟨σ⟩z = μB tanh w in the direction of B. Of course
we could have obtained this last result by elementary methods, so the use of the statistical
density matrix for this simple two-state problem is overkill. Nevertheless, in this simple
case, we see in detail the difference between a pure state and a statistical state.
See Schiff [57, p. 382] for a treatment of general spin s.

Chapter 26 • Quantum Statistics
465
Example Problem 26.1. Compare the isotropic statistical state (1/2)|α⟩⟨α| + (1/2)|β⟩⟨β| with
the pure states |φ1⟩= (1/
√
2)|α⟩+ (1/
√
2)|β⟩, |φ2⟩= (1/
√
2)|α⟩+ (i/
√
2)|β⟩, |φ3⟩= (1/
√
2)|α⟩+
(1/
√
2)eiγ |β⟩by computing and discussing their density matrices.
Solution 26.1. The respective density matrices are
ρS =
 1/2
0
0
1/2

(26.82)
and
ρ1 =
 1/2 1/2
1/2 1/2

;
ρ2 =
 1/2 −i/2
i/2
1/2

;
ρ3 =

1/2 e−iγ /2
eiγ /2
1/2

.
(26.83)
For all four, the probability of ﬁnding the system in |α⟩or |β⟩is 1/2. For the statistical state,
⟨σ⟩= 0. For |φ1⟩, Px = 1, Py = 1, and Pz = 0. For |φ2⟩, Px = 0, Py = 1, and Pz = 0. And for |φ3⟩,
Px = cos γ , Py = sin γ , and Pz = 0. For the three pure states, the vector P is perpendicular to the
z-axis, but spins in those eigenstates still have probabilities of 1/2 of being in either |α⟩or |β⟩.
Example Problem 26.2. Compare the statistical state (1/3)|α⟩⟨α| + (2/3)|β⟩⟨β| with the pure
state |φ⟩= √1/3|α⟩+ √2/3 eiγ |β⟩. What would be the value of P for a state |φ⊥⟩that is
perpendicular to |φ⟩and what would be its density matrix?
Solution 26.2. The respective density matrices are
ρS =
 1/3
0
0
2/3

;
ρ =

1/3 e−iγ √2/9
eiγ √2/9
2/3

.
(26.84)
For both, the probability of ﬁnding the system in |α⟩is 1/3 and in |β⟩it is 2/3. For the statistical
state, ⟨σx⟩= ⟨σy⟩= 0 and ⟨σz⟩= −1/3. For |φ⟩, Px = (2
√
2/3) cos γ , Py = (2
√
2/3) sin γ , and Pz =
−1/3. The value of P for |φ⊥⟩would be the negative of P for |φ⟩. Within an overall phase factor,
one could take |φ⊥⟩= √2/3 e−iγ |α⟩−√1/3|β⟩and its density matrix (which is independent of
the overall phase factor) would be
ρ⊥=

2/3 −e−iγ √2/9
−eiγ √2/9
1/3

.
(26.85)
26.7 Indistinguishable Particles
Suppose we have a set of identical particles that cannot be distinguished from one another
in the sense that interchange of any pair of particles will not lead to a new quantum state.6
We shall refer to such particles as indistinguishable particles. Then quantum mechan-
ical considerations require their quantum states to have certain symmetry properties,
6If identical particles were imbedded in a solid, they could be distinguished by their position in the solid, so
we would not regard them as indistinguishable. On the other hand, if they shared the same volume as they would
in a gas, they would be indistinguishable.

466
THERMAL PHYSICS
depending on whether they are bosons (integral spin) or fermions (half integral spin). If
they are bosons (fermions), their wave vectors must be symmetric (antisymmetric) under
interchange of any pair of particles. For a very thorough treatment of the general case, see
Messiah [59, chapter XIV]. See Appendix I for an introduction to creation and annihilation
operators that can be used to construct such states.
We proceed to illustrate this symmetry requirement for ideal Bose and Fermi gases for
which the interaction energies of particles are assumed to be negligible. The Hamiltonian
for such a system will be of the form
ˆH(ξ1, ξ2, . . . , ξN ) =
N

i=1
ˆh(ξi),
(26.86)
where ξi represents the coordinates, momenta, and spin of particle i and ˆh(ξ) is the
Hamiltonian for a single particle having coordinates ξ, the same function for each particle.
For each particle, we label the eigenstates of a complete set of commuting observables,
including ˆh, by a single number7 α, where α = 1, 2, . . .. Thus,
ˆh uα(ξ) = εαuα(ξ),
for ξ = ξ1, ξ2, . . . ,
(26.87)
or more succinctly ˆh|α⟩= εα|α⟩, where εα is the energy of the state α.
Each physically distinct quantum state of a system of N bosons or fermions can
be described by specifying a set {nα} of occupation numbers nα (sometimes called
a distribution) for each of the states |α⟩. Thus there will be n1 particles in the state
|α
= 1⟩, n2 particles in |α
= 2⟩, and so on, with the understanding that unoccu-
pied states will simply have nα
= 0. Since every particle will be in some state, we
shall have

α
nα = N
(26.88)
and

α
nαεα = E,
(26.89)
where E is the total energy.
Given a set of occupation numbers {nα}, we focus on only the subset of nonzero
occupation numbers, nα, nβ, . . . , nγ , where now α, β, . . . , γ represent speciﬁc eigenstates
of the single particle Hamiltonian ˆh. Since each of these occupation numbers will be at
least equal to 1, there can be at most N of them. A trial wave function of the form
ψ{nα}(ξ1, ξ2, . . . , ξN ) =
nα

i=1
uα(ξi)
nα+nβ

j=nα+1
uβ(ξj) · · ·
N

k=N −nγ
uγ (ξk),
(26.90)
7Generally, a set of quantum numbers is used to label each state, but we simply renumber these sets
sequentially according to some scheme.

Chapter 26 • Quantum Statistics
467
in which the ﬁrst nα factors are uα, the second nβ factors are uβ, and so on, will be an
eigenfunction of the total Hamiltonian ˆH with energy E, but it will not be acceptable
because it speciﬁes which particles are in a given state. We can, however, obtain from it a
wave function having the desired symmetry properties by summing over all permutations
of the ξi as follows:
For bosons, we apply the symmetrization operator
S := 1
N!

all
P,
(26.91)
where the sum is over all permutations and P is a permutation operator that permutes the
coordinates ξi. For fermions we apply the anti-symmetrization operator
A := 1
N!

all
P(−1)p,
(26.92)
where the factor (−1)p is +1 or −1 according to whether the permutation p generated
by P is even or odd. In applying A to ψ(ξ1, ξ2, . . . , ξN ) in Eq. (26.90), we see immediately
that the result is zero if any nα > 1. This follows because one possible permutation
would involve an interchange of two particles in the same state, which would produce
terms of opposite sign. To get a nonvanishing result for fermions, all of the states
belonging to the subset of nonvanishing occupation numbers must be different and
have occupation numbers equal to 1. Thus for fermions, the only possible occupation
numbers for the single particle states are 0 and 1, which is equivalent to the Pauli exclusion
principle.
Normalized wave functions can be obtained as follows:
bosons
B
{nα}(ξ1, ξ2, . . . , ξN ) =

N!
nα!nβ! · · · nγ !
	1/2
S
nα

i=1
uα(ξi)
nα+nβ

j=nα+1
uβ(ξj) · · ·
N

k=N −nγ
uγ (ξk).
(26.93)
In this case, the application of S produces the same function nα!nβ! · · · nγ ! times, so the
result can also be written
B
{nα}(ξ1, ξ2, . . . , ξN ) =
nα!nβ! · · · nγ !
N!
	1/2 
dis
P
nα

i=1
uα(ξi)
nα+nβ

j=nα+1
uβ(ξj) · · ·
N

k=N −nγ
uγ (ξk),
(26.94)
where now the sum is only over N!/(nα!nβ! · · · nγ !) distinct permutations.
fermions
F
{nα}(ξ1, ξ2, . . . , ξN ) = [N!]1/2 A uα(ξ1)uβ(ξ2) · · · uγ (ξN )
=
 1
N!
	1/2 
all
P(−1)p uα(ξ1)uβ(ξ2) · · · uγ (ξN ).
(26.95)

468
THERMAL PHYSICS
Consequently, for fermions, the wave function can be expressed as a Slater determinant:
F
{nα}(ξ1, ξ2, . . . , ξN ) =
 1
N!
	1/2
⎡
⎢⎢⎢⎣
uα(ξ1)
uβ(ξ1)
· · ·
uγ (ξ1)
uα(ξ2)
uβ(ξ2)
· · ·
uγ (ξ2)
...
...
...
...
uα(ξN ) uβ(ξN ) · · · uγ (ξN )
⎤
⎥⎥⎥⎦.
(26.96)
See Appendix I for an alternative way of representing boson and fermion states in Dirac
vector space by means of creation operators.
From the point of view of statistical mechanics, the counting of the number of mi-
crostates is quite different for systems of identical bosons, fermions, or classical particles,
which for brevity we will refer to as ‘boltzons’ since they are the sort of particle treated by
Maxwell-Boltzmann statistics. For a wave function of the type ψ{nα}(ξ1, ξ2, . . . , ξN ) given by
Eq. (26.90), the number of independent states would be
N!/(nα!nβ! · · · nγ !),
for identical but distinguishable boltzons.
(26.97)
For indistinguishable boltzons, this number could be reduced by N!, as suggested by
Gibbs, to give a weighting factor
WG = 1/(nα!nβ! · · · nγ !),
for indistinguishable boltzons.
(26.98)
This weighting factor WG < 1 unless nα = nβ = · · · = nγ = 1 (or 0, which means here
that the state is not included) in which case WG = 1. If the wave functions in Eq. (26.90)
were used to represent indistinguishable bosons, they would constitute only one quantum
state, as represented by Eq. (26.94). If the functions in Eq. (26.90) were used to represent
indistinguishable fermions, they could not represent a quantum state unless they were all
different, in which case they would represent only one state represented by Eq. (26.96).
Therefore, the weighting factors for any conﬁguration set {nα} that satisﬁes Eq. (26.88) are
WB = 1,
for indistinguishable bosons, any {nα}
(26.99)
and
WF = 1,
for indistinguishable fermions, {nα} = 0, 1.
(26.100)
One might ask under what circumstances systems of indistinguishable boltzons,
bosons, and fermions would lead to the same number of quantum states. The answer
is: under conditions for which the number of available single particle states is extremely
large compared to the total number of particles. A single particle state is deemed to
be accessible if its Boltzmann factor exp(−βε) is not negligibly small. Thus there will
be a huge number of accessible states at high temperature. Then if the system is also
sufﬁciently dilute, the probability of multiply-occupied states will be extremely small and
most states will be either unoccupied or singly occupied. Under these conditions, every
signiﬁcant set of occupation numbers will contain only ones and zeros, so the Gibbs-
boltzon weighting factor WG for such a state will be practically unity.

27
Ising Model
Until now we have conﬁned most of our treatments to systems of weakly interacting
particles. A number of new phenomena, generally referred to as cooperative phenomena,
arise whenever particles interact. These phenomena often include phase transitions, such
as liquiﬁcation of a gas as discussed from a thermodynamic viewpoint in connection
with the van der Waals model in Chapter 9. Another example would be an order-disorder
transition in a binary alloy.
The present chapter is devoted primarily to the study of a model known as the Ising
model which is a simple tractable model for a magnetic system. We begin by considering
a spin Hamiltonian of the form
H = −1
2

i,j
JijSi · Sj,
(27.1)
where the quantities Si play the role of spins situated on a lattice, the sums are over all
lattice sites, and Jij is a coupling constant. Such a spin Hamiltonian is a drastic simpliﬁ-
cation itself. The spins are actually pseudo-spins that might be combinations of spin and
orbital angular momenta. The interaction itself is primarily due to electrostatic energies
associated with the different orbital wave functions needed to construct, according to the
Pauli exclusion principle, antisymmetric wave functions for each electronic spin state.
For a simpliﬁed motivation of Eq. (27.1), the reader is referred to Ashcroft and Mermin
[58, p. 679]. A simpler version of a spin Hamiltonian is the Heisenberg model for which
H = −1
2J
nn

i,j
Si · Sj.
(27.2)
Here, there is just one coupling constant J and the sum is only over nearest neighbors.
An even simpler model is the Ising model wherein the spins are replaced by quantities
σi = ±1. This results in
H = −1
2J
nn

i,j
σiσj = −J
nnp

i,j
σiσj,
(27.3)
where the second sum is over nearest-neighbor pairs. This model gives rise to only two
energy states for a pair of nearest-neighbor spins, aligned neighbors (1, 1 or −1, −1) with
energy −J and opposite neighbors (1, −1 or −1, 1) with energy J. Despite this drastic
simpliﬁcation, the Ising model still presents some challenging problems, even though it
allows for exact solutions for lattices in one and two spatial dimensions.
Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00027-2
469
Copyright © 2015 Elsevier Inc. All rights reserved.

470
THERMAL PHYSICS
27.1 Ising Model, Mean Field Treatment
In the presence of a magnetic ﬁeld B, we write the Hamiltonian for the Ising model in the
form1
H = −1
2

i,j
Jijσiσj −μ∗B

i
σi,
(27.4)
where μ∗> 0 is a magnetic moment (not the chemical potential) and
Jij =

J > 0 if i and j are nearest neighbors.
0
otherwise.
(27.5)
There is still only one coupling constant J as in Eq. (27.3) but this change of notation will
facilitate the sums over nearest neighbors.
We denote by ⟨σi⟩the ensemble average value of σi. Then we substitute the identity
σi = (σi −⟨σi⟩) + ⟨σi⟩
(27.6)
and a similar one for σj to obtain
−1
2

i,j
Jijσiσj = 1
2

i,j
Jij⟨σi⟩⟨σj⟩−

i,j
Jijσi⟨σj⟩
−1
2

i,j
Jij(σi −⟨σi⟩)(σj −⟨σj⟩),
(27.7)
where cross terms have been combined after interchange of i and j to give a factor of
2 in the second term. We shall use periodic boundary conditions so all lattice sites are
equivalent. Thus ⟨σi⟩= ⟨σj⟩≡⟨σ⟩and Eq. (27.7) takes the form
−1
2

i,j
Jijσiσj = 1
2JNq⟨σ⟩2 −Jq⟨σ⟩

i
σi
−1
2

i,j
Jij(σi −⟨σ⟩)(σj −⟨σ⟩),
(27.8)
where N is the number of lattice sites and q is the number of nearest neighbors.
The term on the second line of Eq. (27.8) represents correlations between
nearest-neighbor spins. This may be seen because its average would vanish if ⟨σiσj⟩=
⟨σi⟩⟨σj⟩= ⟨σ⟩2 for i ̸= j. This can also be seen because the average of the ﬁrst two
terms is −(1/2)Jq⟨σ⟩2 which would not equal the average of the left-hand side unless
nearest-neighbor spins were uncorrelated. The second term on the right-hand side
resembles the term in Eq. (27.4) that contains the external magnetic ﬁeld B. This becomes
more evident if we introduce the notation
BJ := Jq⟨σ⟩/μ∗
(27.9)
1The factor of 1/2 avoids double counting of interactions. The reader is cautioned that Ising Hamiltonians
are often written without this factor of 1/2 and sometimes also with a factor of 2. If one sums only over nearest-
neighbor pairs, the factor of 1/2 should be omitted. The sign convention here is that μ∗σi is the magnetic moment
for this pseudo-spin.

Chapter 27 • Ising Model
471
in which case Eq. (27.4) takes the form
H = 1
2JNq⟨σ⟩2 −μ∗(B + BJ)

i
σi −1
2

i,j
Jij(σi −⟨σ⟩)(σj −⟨σ⟩).
(27.10)
The quantity BJ is seen to play the role of a mean ﬁeld experienced by a given spin due to
the presence of the other spins.
The mean-ﬁeld approximation2 consists of ignoring the correlation term, resulting in
a mean ﬁeld Hamiltonian
HM = 1
2JNq⟨σ⟩2 −μ∗(B + BJ)

i
σi.
(27.11)
Many books also ignore the ﬁrst term in Eq. (27.11) because it depends only on average
quantities and plays no role in computing the magnetization. Omitting it, however, leads
to an average energy for B = 0 that is too large by a factor of 2; this requires “patching” by
a factor of 1/2 in a somewhat ad hoc manner.
By using the mean ﬁeld Hamiltonian given by Eq. (27.11), we obtain a problem for
which the spins are formally independent. The canonical partition function for a single
spin is therefore
z = exp[−β(1/2)Jq⟨σ⟩2] 2 cosh[βμ∗(B + BJ)]
(27.12)
and the probabilities are
p+ =
exp[βμ∗(B + BJ)]
2 cosh[βμ∗(B + BJ)];
p−= exp[−βμ∗(B + BJ)]
2 cosh[βμ∗(B + BJ)]
(27.13)
for σi = ±1, respectively. Note that these probabilities do not depend on the exponential
factor in z, which came from the ﬁrst term in Eq. (27.11). The magnetization M = Nμ∗⟨σ⟩,
where
⟨σ⟩= p+ −p−= tanh[βμ∗(B + BJ)]
(27.14)
and the average energy is3
U = ⟨HM⟩= −1
2JNq⟨σ⟩2 −μ∗NB⟨σ⟩.
(27.15)
Since BJ is given by Eq. (27.9), we see that Eq. (27.14) can be rewritten in the form
⟨σ⟩= tanh[βμ∗(B + Jq⟨σ⟩/μ∗)],
(27.16)
which is a self-consistency equation for ⟨σ⟩. We can solve this equation graphically by
deﬁning a dimensionless parameter
x = βμ∗(B + Jq⟨σ⟩/μ∗).
(27.17)
2This is also known as the Bragg-Williams or the Weiss molecular ﬁeld approximation.
3Since BJ depends on ⟨σ⟩which in turn depends on β and B, the formulae M = −N kBT∂ln z/∂B and
U = −∂ln z/∂β will only work if ⟨σ⟩is held constant during the differentiation. This inconsistency of the mean
ﬁeld approximation arises because average quantities appear in the mean ﬁeld Hamiltonian.

472
THERMAL PHYSICS
-3
-2
-1
1
2
3
-1
-0.5
0.5
1
x
FIGURE 27–1 Graphical solution of Eq. (27.19) for B = 0. The curve is tanh x and the lines have slopes kBT/Jq
of 1.4, 1, and 0.6. There are only solutions for x ̸= 0 for kBT/Jq < 1.
Then
⟨σ⟩= −μ∗B
Jq
+ kBT
Jq x
(27.18)
and Eq. (27.16), which is now ⟨σ⟩= tanhx, becomes
−μ∗B
Jq + kBT
Jq x = tanh x.
(27.19)
Viewed as a function of x, the left-hand side of Eq. (27.19) is just a straight line of slope
kBT/Jq and intercept −μ∗B/Jq and the right-hand side is a curve that can be drawn once
and for all. The case B = 0 is of special importance and is illustrated in Figure 27–1. In that
case, x is just proportional to ⟨σ⟩. Since the slope of tanhx is one at x = 0, we see that there
are solutions for x ̸= 0 provided that kBT/Jq < 1 and otherwise no solutions. This deﬁnes
a critical temperature
Tc = qJ/kB
(27.20)
below which there is a spontaneous magnetization in the absence of an applied magnetic
ﬁeld.
Note that if x is a solution, −x is also a solution. This degeneracy arises because B = 0
so there is no preferred direction for the spontaneous magnetic ﬁeld. If we started with a
ﬁnite positive ﬁeld and then let it shrink to zero, we would create a bias for the positive
solution.
Graphical solutions for B > 0 are illustrated in Figure 27–2. We see that positive
solutions4 for x exist for all values of kBT/Jq, but those for large T correspond to small
values of x and therefore to small values of ⟨σ⟩= tanh x. Similar considerations lead to
negative solutions for all T when B < 0.
4For sufﬁciently small positive values of kBT/Jq, there can also be negative solutions. These can be shown
to correspond to metastable or unstable solutions that represent cases in which a magnetic ﬁeld is applied in a
direction opposite to the spontaneous magnetization that occurs in zero ﬁeld.

Chapter 27 • Ising Model
473
-3
-2
-1
1
2
3
-1
-0.5
0.5
1
x
FIGURE 27–2 Graphical solution of Eq. (27.19) for B > 0, namely μ∗B/Jq = 0.5 for the sake of illustration. The curve
is tanh x and the lines have slopes kBT/Jq of 1.4 and 0.6. There are positive solutions for all values of kBT/Jq but
those for large T correspond to small values of x and therefore to small values of ⟨σ⟩= tanh x. For B < 0, the lines
would have a positive intercept and the solutions for x would be negative.
The foregoing results in the mean ﬁeld approximation are suggestive but incorrect.
Indeed, it is possible to solve the Ising model exactly in one dimension and two dimen-
sions and numerically in three and higher dimensions. There are also better approximate
solutions for all dimensions. The most serious discrepancy occurs in one dimension
where the mean ﬁeld model leads to a critical temperature at kBTc/J = 2 but the exact
solution displays no spontaneous magnetization. In higher dimensions, there are critical
temperatures Tc > 0 but the numerical values of kBTc/J are different. For instance, the
exact two-dimensional solution for a square lattice, due to Onsager, gives
kBTc
J
=
2
ln(1 +
√
2)
= 2.26919,
(27.21)
whereas the mean ﬁeld approximation gives kBTc/J = 4. Some comparative values of
Tc are given in Table 27–1. We see that the mean ﬁeld model shows the general trend
with dimensionality but is certainly wrong in detail because correlations are neglected.
The cluster model of Boethe (see Pathria [8, p. 329]) takes into account the correlations
of a given spin with its neighbors but all other interactions (e.g., the interactions of its
neighbors with other neighbors) are taken into account by a mean ﬁeld. The critical
temperature for the Boethe model satisﬁes
kBTc
J
=
2
ln[q/(q −2)].
(27.22)
Table 27–1
Values of kBTc/J for the Ising Model for a “Simple Cubic”
Lattice of Various Dimensionality According to Several Theories
Dimensionality
1
2
3
4
5
6
7
Exact
0
2.26919
Numerical
2.26919
4.51153
6.68003
8.77739
10.8348
12.8690
Boethe
0
2.88539
4.93261
6.95212
8.96284
10.9696
12.9743
Mean ﬁeld
2
4
6
8
10
12
14
Note: Numerical results are from Galam and Mauger [70].

474
THERMAL PHYSICS
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6
0.2
0.4
0.6
0.8
1
T/Tc
σ
FIGURE 27–3 Dimensionless magnetization per spin, ⟨σ⟩= M/N μ∗, versus dimensionless temperature t = T/Tc for
B = 0 and b = μ∗B/Jq = 0.05 according to the parametric equations Eq. (27.23). For B = 0, the magnetization is zero
for T > Tc but for B > 0 it extends beyond Tc.
In one dimension, q = 2 so Eq. (27.22) gives Tc = 0, correctly showing that there is no phase
transition for any T > 0.
For the mean ﬁeld model, Figure 27–3 shows a plot of the dimensionless magnetization
per spin, M/Nμ∗= ⟨σ⟩, as a function of T/Tc for B = 0 and B > 0. These plots were
constructed by writing Eqs. (27.14) and (27.19) in the parametric form
⟨σ⟩= tanh x;
t = tanh x
x
+ b
x ,
(27.23)
where the dimensionless temperature t := T/Tc and the dimensionless magnetic ﬁeld
b := (μ∗B/Jq) = (μ∗B/kBTc). For a given value of b, one can assign values of the parameter
x and construct a plot of ⟨σ⟩versus t. For b = 0, we see that ⟨σ⟩= 0 for T > Tc but for b > 0
it extends beyond Tc, although its value is small.
For the case B = 0 we can get a series representation for 1/t in terms of m ≡⟨σ⟩as
follows: For B = 0 we can eliminate x from Eq. (27.23) to obtain
m = tanh(m/t) = e2m/t −1
e2m/t + 1.
(27.24)
We can then solve for m/t, which amounts to ﬁnding the inverse of the hyperbolic tangent
function to obtain
1
t =
1
2m ln
1 + m
1 −m

=
∞

p=0
m2p
2p + 1,
(27.25)
where the series converges for |m| < 1. Thus
t =
1
1 + m2/3 + m4/5 + · · · = 1 −m2/3 −4m4/45 + · · · ,
(27.26)
which can be solved to lowest order to give
m =
√
3(1 −t)1/2.
(27.27)

Chapter 27 • Ising Model
475
Equation (27.27) shows how the magnetization rises from zero as T decreases slightly from
Tc and the exponent of 1/2 is referred to as a critical exponent. In one dimension, we know
from the exact solution that Tc = 0, so there really is no critical exponent in that case. For
two dimensions, the correct critical exponent is 1/8 for a square lattice and approximately
0.313 for a simple cubic lattice in three dimensions. As was the case with Tc itself, the mean
ﬁeld theory shows some qualitative trends but is certainly wrong in detail.
By differentiation of U from Eq. (27.15) we can calculate the heat capacity, but we have
to remember that ⟨σ⟩≡m depends on T. Thus
CV = ∂U
∂T = −NJq(m + b)∂m
∂T .
(27.28)
To calculate the derivative of m, we write Eq. (27.16) in the form
m = tanh
1
t (b + m)

.
(27.29)
Then
∂m
∂T = sech2
1
t (b + m)
 1
t
∂m
∂T −
1
t2Tc
(b + m)

,
(27.30)
which we can solve to obtain
∂m
∂T = −(b + m)(1 −m2)
t2 −t(1 −m2)
1
Tc
,
(27.31)
where we have used sech2 
(b + m)/t
	
= 1 −m2. Combining Eqs. (27.28) and (27.31) gives
CV
NkB
= (b + m)2(1 −m2)
t2 −t(1 −m2)
.
(27.32)
Equation (27.32), however, is not very enlightening, so we introduce x = (b + m)/t as in
Eq. (27.23) and obtain, after some algebra, the parametric equations
t = tanh x
x
+ b
x ;
CV
NkB
= x2(tanh x + b) sech2x
(tanh x + b) −x sech2x
.
(27.33)
Figure 27–4 shows a plot of CV /NkB versus T/Tc for B = 0 and B > 0. For B = 0 there is a
sharp peak at CV /NkB = 3/2 at T = Tc and zero heat capacity for T > Tc. The height of
this peak is not obvious from Eq. (27.32) or (27.33) because the function is discontinuous
at T = Tc for b = 0. It can be computed easily, however, by substituting Eq. (27.27), which
holds for t ≈1, into Eq. (27.15) for B = 0 to obtain
U/N = −(1/2)Jqm2 = −(3/2)kB(Tc −T);
T ≈Tc,
(27.34)
and then differentiating with respect to T.
The same technique of implicit differentiation can be used to compute the magnetic
susceptibility
χ = ∂M
∂B = Nμ∗∂m
∂B = Nμ∗2
kBTc
1 −m2
t −(1 −m2).
(27.35)

476
THERMAL PHYSICS
0.2
0.4
0.6
0.8
1
1.2
1.4
0.25
0.5
0.75
1
1.25
1.5
1.75
T/Tc
CV /NkB
FIGURE 27–4 Dimensionless heat capacity per spin, CV/N kB, versus dimensionless temperature t = T/Tc for B = 0
and b = μ∗B/Jq = 0.05 according to the parametric equations Eq. (27.33). For B = 0, the heat capacity rises to a
sharp peak and then drops to zero for T > Tc, but for B > 0 it extends beyond Tc.
0.25 0.5 0.75
1
1.25 1.5 1.75
2
1
2
3
4
5
6
7
8
T/Tc
˜χ
FIGURE 27–5 Dimensionless magnetic susceptibility, ˜χ, versus dimensionless temperature t = T/Tc for b = μ∗
B/Jq = 0.05 (low peak) and b = 0.02 (high peak) according to the parametric equations Eq. (27.37). For B = 0, the
susceptibility diverges as T →Tc.
For t ≫1 we have m ≪1 so
χ ≈
Nμ∗2
kB(T −Tc),
(27.36)
which is known as the Curie-Weiss law. Parametric equations for the general case are
t = tanh x
x
+ b
x ;
˜χ := χkBTc
Nμ∗2 =
x sech2x
(tanh x + b) −x sech2x
.
(27.37)
Figure 27–5 shows a plot of the dimensionless susceptibility ˜χ as a function of t = T/Tc for
two positive magnetic ﬁelds. As the ﬁeld strength is decreased, the peak in the vicinity of
t = 1 becomes progressively higher and ultimately diverges as B →0. We can see the nature
of this divergence by substituting Eq. (27.27) into Eq. (27.35) to obtain
˜χ ≈1
2(1 −t)−1
for t < 1 and t ≈1.
(27.38)

Chapter 27 • Ising Model
477
Thus χ diverges like (1 −t)−γ with a critical exponent γ = 1. Although the mean ﬁeld
model is incorrect, this value of γ is close to values 1.2-1.4 measured for magnetic systems
[8, p. 336].
27.2 Pair Statistics
More insight about the Ising model can be gained by studying the statistics of nearest-
neighbor pairs. To do this, we follow Pathria [8, p. 318] and introduce the following
notation:
•
N = total number of spins
•
N+ = total number of “up” spins
•
N−= total number of “down” spins
•
N++ = total number of “up-up” nearest-neighbor pairs
•
N−−= total number of “down-down” nearest-neighbor pairs
•
N+−= total number of “opposite” nearest-neighbor pairs
In general, we certainly have N = N+ + N−. We treat the case of periodic boundary
conditions so that all lattice sites are equivalent. It follows that:
qN+ = 2N++ + N+−;
qN−= 2N−−+ N+−.
(27.39)
If we sum these equations we obtain qN/2 = N++ + N−−+ N+−which is a correct
expression for the total number of pairs. For a given N, we choose N+ and N++ to be
independent variables and obtain the remaining quantities:
N−= N −N+
(27.40)
N+−= qN+ −2N++
(27.41)
N−−= qN/2 + N++ −qN+.
(27.42)
The part of the Ising Hamiltonian that is independent of the magnetic ﬁeld is
−1
2

i,j
Jijσiσj = −J (N++ + N−−−N+−) = −J

qN/2 + 4N++ −2qN+

(27.43)
and the magnetic moment for such a conﬁguration is
M = μ∗(N+ −N−) = μ∗(2N+ −N) .
(27.44)
The difﬁculty of solving the Ising problem, even for zero magnetic ﬁeld, can be appreciated
by realizing that it amounts to enumerating all possible conﬁgurations of N+ and N++, a
difﬁcult combinatorial problem.
27.2.1 Average Pair Statistics for Mean Field
We can learn more about the nature of the mean ﬁeld approximation by taking averages of
the above equations. The average of Eq. (27.43) with correlations ignored, so ⟨σiσj⟩= ⟨σ⟩2,
gives
−qN⟨σ⟩2/2 = −J

qN/2 + 4⟨N++⟩−2q⟨N+⟩

(27.45)

478
THERMAL PHYSICS
and the average of Eq. (27.44) gives
N⟨σ⟩= 2⟨N+⟩−N.
(27.46)
We can therefore solve Eqs. (27.45) and (27.46) for ⟨N+⟩and ⟨N++⟩and use them to
compute averages ⟨N−⟩, ⟨N−−⟩, and ⟨N+−⟩from Eqs. (27.40) to (27.42). Then recalling that
the total number of pairs is Nq/2, we can compute the following probabilities:
p+ := ⟨N+⟩
N
= 1
2(1 + ⟨σ⟩),
(27.47)
p−:= ⟨N−⟩
N
= 1
2(1 −⟨σ⟩),
(27.48)
p++ := ⟨N++⟩
Nq/2 = 1
4(1 + ⟨σ⟩)2 = p2
+,
(27.49)
p+−:= ⟨N+−⟩
Nq/2 = 1
2(1 + ⟨σ⟩)(1 −⟨σ⟩) = 2p+p−,
(27.50)
p−−:= ⟨N−−⟩
Nq/2 = 1
4(1 −⟨σ⟩)2 = p2
−.
(27.51)
We observe that p++, p+−, and p−−are just the terms in the expansion of (p+ + p−)2. This
indicates that the spins are randomly distributed in the mean ﬁeld approximation and
further emphasizes that correlations have been ignored.
Plots of these probabilities as a function of temperature are shown in Figure 27–6 for
B →0 from positive values. At the critical temperature, ⟨σ⟩= 0 so p+ = p−= 1/2, p++ =
p−−= 1/4, and p+−= 1/2. From the shapes of the p+−and p−−plots, we see that the
“down” spins tend to form in isolation as the temperature rises and only form a signiﬁcant
number of “down-down” pairs near the critical temperature.
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
t
p+
p−
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
t
p+−
p++
p−−
FIGURE 27–6 Probabilities p+ and p−of up and down spins (left) and pairs p++, p+−, and p−−as a function of
dimensionless temperature t = T/Tc for the Ising model in the mean ﬁeld approximation for B →0 from positive
values.

Chapter 27 • Ising Model
479
27.3 Solution in One Dimension for Zero Field
In one dimension with periodic boundary conditions, it is possible to solve exactly the
Ising model for B = 0 by a rather elementary method that demonstrates explicitly the way
that correlations enter. We can write the Hamiltonian in the form
H = −1
2

i,j
Jijσiσj = −J
N

i=1
σiσi+1 = −J
N

i=1
τi,
(27.52)
where the pair operators τi := σiσi+1. For periodic boundary conditions, we have
σN +1 = σ1, so it is easy to see that the pair operators are correlated because
N

i=1
τi =
N

i=1
σiσi+1 =
N

i=1
σ 2
i = 1.
(27.53)
Note that the τi take on the values ±1. The canonical partition function for the whole
system is therefore
Z =

σ1
· · ·

σN
exp

y

i
σiσi+1

= 2

τ1
· · ·

τN
exp

y

i
τi

,
(27.54)
where the sums are constrained by Eq. (27.53) and y := βJ. The factor of 2 on the right-
hand side arises because as the set of the σi range over their values once, the set of τi range
over their values twice.5
At ﬁrst we ignore the constraint Eq. (27.53) and evaluate the right-hand side of
Eq. (27.54) to obtain
Z = 2

τ1
e yτ1 · · ·

τN
e yτN = 2(ey + e−y)N = 2(2 cosh y)N ,
no constraint.
(27.55)
Equation (27.55) would be correct for a chain of length N with open ends, except not all
spins would be equivalent for such a chain. This is, however, a very small effect for large N
since the fraction of nonequivalent spins is 2/N.
To account for the constraint Eq. (27.54) due to periodic boundary conditions, we
expand the binomial in Eq. (27.55) to obtain
2(ey + e−y)N = 2
N

r=1
N!
r!(N −r)!(e y)N −r(e−y)r.
(27.56)
Because of the constraint, what we should have instead is this same sum but with all of the
terms for odd values of r missing. To accomplish this, we note the related series
2(e y −e−y)N = 2
N

r=1
N!
r!(N −r)! (e y)N −r(−e−y)r
(27.57)
5Note that σiσi+1 = 1 when both factors are 1 and when both factors are −1; in each case, τi = 1.

480
THERMAL PHYSICS
in which all of the terms with odd r enter with a minus sign. If we add these two series, we
get twice the terms with even r, double what we want. The correct partition function for
periodic boundary conditions is therefore
Z = 2(e y + e−y)N + (e y −e−y)N
2
= (e y + e−y)N + (e y −e−y)N .
(27.58)
In terms of hyperbolic functions,
Z = (2 cosh y)N + (2 sinh y)N ,
(27.59)
which agrees with the exact result obtained by using a transfer matrix, which we present
in the next section.
27.4 Transfer Matrix
By using a computational technique known as the transfer matrix, we can obtain an exact
solution to the Ising model in one dimension even in the presence of a magnetic ﬁeld. For
periodic boundary conditions in one dimension, we can write the Ising Hamiltonian in
the form
H = −J
N

i=1
σiσi+1 −(1/2)μ∗B
N

i=1
(σi + σi+1).
(27.60)
Then
exp(−βH) = exp

y
N

i=1
σiσi+1 + (x/2)
N

i=1
(σi + σi+1)

,
(27.61)
where x := βμ∗B and y = βJ. The partition function is given by
Z =

{σi}=±1
exp(−βH) ≡

σ1=±1

σ2=±1
· · ·

σN =±1
exp(−βH).
(27.62)
Since the exponential of a sum can be written as a product of exponentials, Eq. (27.61) can
be written as a product of terms of the form
exp[yσiσi+1 + (x/2)(σi + σi+1)].
(27.63)
Such a term depends only on the product σiσi+1, which can take on only the values ±1,
and the sum σi + σi+1, which can take on only the values −2, 0, 2, irrespective of the value
of i. Therefore, for any value of i, the expression given by Eq. (27.63) can take on only the
values exp(x + y), exp(−y), and exp(x −y). Thus, the partition function can be written in
the form
Z =

{σi}=±1
⟨σ1| ˆP|σ2⟩⟨σ2| ˆP|σ3⟩· · · ⟨σN −1| ˆP|σN ⟩⟨σN | ˆP|σ1⟩,
(27.64)
where ˆP is an operator with matrix representation
P =
 e y+x
e−y
e−y
e y−x

.
(27.65)

Chapter 27 • Ising Model
481
In this matrix representation, the bra ⟨1| is represented by the row vector (1, 0), the bra
⟨−1| is represented by the row vector (0, 1), and the kets |1⟩and | −1⟩are represented by
their respective transposes, which are column vectors. For example,
⟨1| ˆP|1⟩=

1 0
  e y+x
e−y
e−y
e y−x
  1
0

=

1 0
  e y+x
e−y

= e y+x,
(27.66)
whereas
⟨−1| ˆP|1⟩=

0 1
  e y+x
e−y
e−y
e y−x
  1
0

=

0 1
  e y+x
e−y

= e−y.
(27.67)
Since 
σi=±1 |σi⟩⟨σi| = |1⟩⟨1| + | −1⟩⟨−1| is equal to the unit operator in a two-state space
for any value of i, we have
Z =

σ1=±1
⟨σ1| ˆPN |σ1⟩= trace ˆPN = λN
1 + λN
2 ,
(27.68)
where λ1 and λ2 are the eigenvalues of the matrix P.
The partition function can therefore be calculated by diagonalizing the matrix P, which
can be accomplished by solving
det

e y+x −λ
e−y
e−y
e y−x −λ
 = 0.
(27.69)
This results in
λ2 −2λe y cosh x + e2y −e−2y = 0,
(27.70)
which yields the eigenvalues
λ1,2 = e y cosh x ±

e2y sinh2 x + e−2y,
(27.71)
where the plus sign goes with subscript 1.
We ﬁrst examine limiting cases and then the general case. For y = 0, which is the case
of noninteracting spins in a magnetic ﬁeld, we obtain λ1 = 2 cosh x and λ2 = 0 resulting in
Z = (2 cosh x)N , which is the familiar result for a two-state paramagnetic system. In this
case, the internal energy is U/N = −μ∗B tanh x, the magnetization is M/Nμ∗= tanh x,
and the entropy is S/NkB = x −x tanhx + ln(1 + e−2x), which goes to 0 for T = 0 and to
ln 2 for T = ∞as expected.
For x = 0, which is the case of spin-spin interaction but in a zero magnetic ﬁeld, we
obtain λ1 = 2 cosh y and λ2 = 2 sinh y, resulting in
Z = (2 cosh y)N + (2 sinh y)N = (2 cosh y)N 
1 + (tanh y)N 
(27.72)
in agreement with Eq. (27.59). The factor [1 + (tanhy)N ] in Eq. (27.72) ranges in value
between 1 and 2 and turns out not to be important in calculating the energy, although it
could be kept for aesthetic reasons to get an entropy of S = kB ln 2 at T = 0 because of the
doubly degenerate ground state (all σi = 1 or all σi = −1). However, this small entropy at
T = 0 is not of order N and is an unimportant technicality, as we shall see subsequently.

482
THERMAL PHYSICS
The internal energy is
U = −∂ln Z
∂β
= −NJ

tanh y + (tanh y)N −1sech2y
1 + (tanh y)N

,
(27.73)
which may also be written
U = −∂ln Z
∂β
= −NJ tanh y

1 + aN −2
1 + aN

,
(27.74)
where a := tanhy. Since 0 ≤a ≤1, the term in square brackets involving a is nearly equal
to 1 for large N. For N > 2 it is equal to 1 at a = 0 and a = 1. It has a maximum6 value of
1 + 0.55693/N for very large N near a = 1. Therefore, the term in brackets in Eq. (27.74)
can be ignored and the internal energy for B = 0 becomes
U0 = −NJ tanh y.
(27.75)
The corresponding heat capacity for B = 0 is therefore
C0 = ∂U0
∂T = −NkB(βJ)2sech2y.
(27.76)
As T increases, C0 increases from zero, passes through a smooth peak, and then decreases
to zero at high T. Thus, there is no sign of a phase transition at any T > 0.
The entropy is given by
S/kB = βU + ln Z = βU + Ny + N ln(1 + e−2y) + ln

1 + (tanh y)N 
.
(27.77)
For T →∞, y →0, and S/kB →N ln 2 because the populations of σi = ±1 are equal. For
T →0, y →∞, βU →−Ny (which cancels the Ny term from ln Z), ln(1 + e−2y) →0
and tanh y →1, so only the last term contributes, resulting in S/kB →ln 2, because of
the doubly degenerate ground state mentioned above. Since, however, the last term in
Eq. (27.77) is not of order N, it can be dropped. Thus the entropy for B = 0 is given by
S0/kB = Ny(1 −tanh y) + N ln(1 + e−2y).
(27.78)
Of more interest is the magnetization which can be calculated from the full partition
function given by Eq. (27.68), namely from
M = kBT ∂
∂B ln[λN
1 + λN
2 ],
(27.79)
6The maximum occurs at values of a that satisfy N a2 +2aN = N −2. We can obtain an approximate solution
by setting a = 1 −b/N and noting that aN = e−b as N →∞. Thus a root occurs at approximately a2 =
1 −(2/N )(1 + e−b) or a = 1 −(1/N )(1 + e−b). This gives 1 + e−b = b whose solution is b = 1.27846. Then
the factor in brackets in Eq. (27.74) becomes approximately 1 + (1/N )(2be−b)/(1 + e−b) = 1 + 0.55693/N . A
numerical solution of the exact equations gives a corresponding value of 1 + 5.5684 × 10−6 for N = 105, in good
agreement.

Chapter 27 • Ising Model
483
which results in
M
Nμ∗= λN −1
1
∂λ1/∂x + λN −1
2
∂λ2/∂x
λN
1 + λN
2
.
(27.80)
But
∂λ1,2
∂x
= ±
ey sinh x

e2y sinh2 x + e−2y λ1,2,
(27.81)
where the plus sign goes with subscript 1 and the minus sign goes with subscript 2. The
magnetic moment is therefore given by
M
Nμ∗=
sinh x

sinh2 x + e−4y
λN
1 −λN
2
λN
1 + λN
2
.
(27.82)
The important thing to notice about Eq. (27.82) is that it is proportional to sinh x which
goes to zero as x →0, while all of the other factors remain ﬁnite. Since x = βμ∗B, this
means there is no spontaneous magnetization for B = 0 at any T > 0. In other words, this
exact solution to the one-dimensional Ising model displays no phase transition, contrary to
the mean ﬁeld model in one dimension. In this respect, the mean ﬁeld model is qualitatively
incorrect. The same conclusion would follow from neglecting the smaller eigenvalue λ2 in
comparison to λ1, in which case the last factor in Eq. (27.82) would be unity.
In the case that the interaction between spins is very strong, such that y = J/kBT ≫1,
one has approximately
λ1,2 ≈ey cosh x ± ey sinh x = e y±x.
(27.83)
In that case, as y →∞, Eq. (27.82) becomes
M ≈Nμ∗tanh Nx
(27.84)
which has a very large slope proportional to N 2 as x →0. This is sometimes interpreted
to suggest that a phase transition is about to happen at T = 0, that is, effectively Tc = 0.
An alternative interpretation would be to note that a very small magnetic ﬁeld would lead
to the saturation magnetization M = Nμ∗as T approaches zero. Such a ﬁeld would need
to satisfy μ∗B > kBT/N.
27.5 Other Methods of Solution
The Ising model has been solved exactly in two dimensions for several lattices and
approximately by various methods in spaces of higher dimensionality. See Pathria
and Beale [9, p. 488] for an extensive discussion of two-dimensional Ising models
and several related models. They report critical values of Kc
=
J/kbTc for several
exact solutions. For the Onsager solution of the square lattice, previously mentioned,
Kc = (1/2) sinh−1(1)
=
(1/2) ln(
√
2 + 1) ≈0.4407. For a triangular lattice, Kc =
(1/2) sinh−1(1/
√
3) ≈0.2747 and for a honeycomb lattice, Kc = (1/2) sinh−1(
√
3) ≈
0.6585. In three dimensions, numerical solutions [70] yield Kc = 0.36982, 0.15740, and

484
THERMAL PHYSICS
0.10209 for diamond cubic, FCC, and BCC lattices, respectively. In many cases, associated
critical exponents have been calculated.
Even though the Ising model is quite simple, it has stimulated a great deal of activity
and has led to important insight that is useful in understanding more realistic models.
Renormalization group (RG) methodology, discussed very brieﬂy below, has been used
extensively to simulate the Ising model and has led to major advances in the study of phase
transitions in more realistic models.
27.6 Monte Carlo Simulation
As we have seen, the solution of the Ising model by means of the mean ﬁeld approximation
is incorrect because correlations among the spins are not taken into account. Monte Carlo
(MC) simulation is an important tool that can be used to include such correlations. It can
also be used to solve many other problems in statistical physics as well as other ﬁelds. It is
a huge subject to which we can only give an introduction. For comprehensive treatments,
the reader is referred to a number of recent books, [71–74].
27.6.1 MC Simulation of the Ising Model
We introduce computer simulation by using MC methods to treat the Ising model in two
dimensions for a square lattice. The basic idea is to work with a square system having
n×n spins, each of which can take on the values si = ±1. We deﬁne a conﬁguration of the
system to be a speciﬁcation of the set {si} of N = n2 spin values. It is convenient to think
of {si} as a vector s with components s1, s2, . . . , sN . In the absence of a magnetic ﬁeld, the
energy of such a conﬁguration is taken to be
E(s) = −J
2
nn

i,j
sisj = −J
nnp

i,j
sisj,
(27.85)
where the ﬁrst sum is over nearest neighbors and the second sum is over nearest-neighbor
pairs. The objective of the simulation is to ﬁnd a set of conﬁgurations such that the
probability P(s) of any given conﬁguration is proportional to its Boltzmann factor,
P(s) ∝exp[−βE(s)].
(27.86)
This can be accomplished by taking a random walk through conﬁguration space in
steps called MC steps. At the end of the kth step, we suppose the conﬁguration to be
in a state s and then proceed by means of a rule, to be discussed below, to establish a
conﬁguration s′ at the next MC step, k + 1. This is accomplished by means of a Markov
process [75, p. 135], according to which the conditional transition probability Wk(s →s′)
to the state s′, given the occurrence of the state s at step k, depends only on the previous
state s, independent of any prior state s′′ at step p < k. This process is repeated a large
number of times, resulting in the generation of a so-called Markov chain. The steps in
conﬁguration space are often referred to as MC time steps that are imagined to take place

Chapter 27 • Ising Model
485
at equal intervals of some dimensionless (but not continuous) MC time, t = k. However,
the progression through conﬁguration space by means of MC time steps should not be
confused with following the dynamics of the system in real time, as would take place in a
simulation called molecular dynamics.7
We shall proceed to discuss a particular algorithm, usually referred to the Metropolis
algorithm [76]. This algorithm employs MC sampling methods for a Markov process that
leads to the Boltzmann distribution. It has been generalized by Hastings [77] to treat many
other problems by similar methods. The Metropolis algorithm can be implemented by
beginning with some arbitrary initial conﬁguration, say s, having energy E(s), randomly
selecting a given spin, reversing its value (1 →−1 or −1 →1) and calculating the
energy E(s′) of a trial conﬁguration at step 1. Such a spin can be selected by generating8
a pseudo-random number, r between 0 and 1, and comparing Nr with the number used
to label each spin, 1, 2, . . . , N, to see which is closest. In event that the selected spin is
on the border of the n × n square, one uses periodic boundary conditions (in the x- and
y-directions) to ascertain the spin of any missing nearest neighbor. Then at step 1 the trial
conﬁguration s′ is rejected or accepted according to the following rules depending on the
energy difference 	E(s′, s) = E(s′) −E(s):
•
If 	E(s′, s) < 0, the trial conﬁguration s′ is accepted and becomes the actual conﬁgura-
tion at the next MC time step (initially, time step 1).
•
If 	E(s′, s) ≥0, the conﬁguration at the next MC time step is the trial conﬁguration
s′ with probability exp[−β	E(s′, s)], but reverts to the former conﬁguration s with
probability [1−exp[−β	E(s′, s)]. This can be accomplished by comparison of a pseudo-
random number r′ between 0 and 1 with the Boltzmann factor exp[−β	E(s′, s)].
This same process is then repeated to progress from step 1 to step 2, etc., until a very large
number N ′ ≫N of MC steps has been taken. The MC chain will begin to follow a trajectory
in conﬁguration space that corresponds approximately to the Boltzmann distribution.9
Then by studying a correlation function between the conﬁguration s at step q and s′′ at
step q −m for sufﬁciently large q > N ′, an interval of m MC time steps can established
beyond which correlations become negligible. This establishes a dimensionless MC cor-
relation time, τ = m. At that stage, one can begin to store these statistically independent
conﬁgurations at intervals of p steps for some p > m and this set of conﬁgurations is
deemed to be representative of a Boltzmann distribution of conﬁgurations. From that
distribution, various quantities of interest can be computed; for example, the average
value of a spin or the correlation of spins separated by a given distance. As discussed below,
other considerations are necessary to obtain an efﬁcient simulation.
7For a classical system, molecular dynamics would be accomplished by integrating numerically Newton’s
equations for a system of N particles, given some initial condition.
8A number of algorithms for generating pseudo-random numbers are readily available. See [73, chapter 16]
for an extensive discussion.
9Theorems for MC chains [75, p. 142] exist to demonstrate some conditions for which this will occur.

486
THERMAL PHYSICS
So what is the physical basis of the Metropolis algorithm? It is based on a so-called
master equation of the form10
Pk+1(s) −Pk(s) =

s′

−Wk(s →s′)Pk(s) + Wk(s′ →s)Pk(s′)

.
(27.87)
In Eq. (27.69), the quantities Pk(s) represent the probability of being in the state s at step k.
However, once an equilibrium distribution has been established, Pk+1(s) −Pk(s) = 0, so
the quantities Pk(s) become independent of k. Speciﬁcally, we want them to tend to the
Boltzmann distribution
Pk(s) →P(s) = (1/Z) exp[−βE(s)],
(27.88)
where Z is the partition function needed to normalize P. Then Eq. (27.87) becomes
0 =

s′

−Wk(s →s′) exp[−βE(s)] + Wk(s′ →s) exp[−βE(s′)]

,
(27.89)
where the partition function has been canceled.
As a guide to ﬁnding an algorithm that will lead to the desired distribution, we want
to be sure that all states of the system are accessible, even though their probabilities may
be small. In the language of MC simulations, this is referred to as “ergodicity,” but should
not be confused with the ergodic hypothesis for the microcanonical ensemble in classical
statistical mechanics [14, p. 144]. We return brieﬂy to the master equation Eq. (27.87) and
note that 
s′ Wk(s →s′) = 1, so it can be rewritten as
Pk+1(s) =

s′
Wk(s′ →s)Pk(s′),
(27.90)
which has the form of a matrix equation except the matrix is stochastic. As k →∞, we
want P∞(s) to approach the Boltzmann distribution. But we want to avoid a so-called
limit cycle in which the system, which starts in some state P0(s′′), reaches a dynamic
equilibrium in which only a subset of states of the system are visited [73, p. 37].
With the foregoing considerations in mind, we need to remember that we are not
following the true dynamics of the system, so all we need is an algorithm that leads
efﬁciently to the correct distribution. This can be accomplished by making use of the
principle of detailed balance, according to which we satisfy Eq. (27.89) by making each
term in the sum equal to zero, resulting in
Wk(s →s′) exp[−βE(s)] = Wk(s′ →s) exp[−βE(s′)].
(27.91)
10In the MC literature, one often writes this equation with the notation Ps(t) ≡Pk(s), where t = k is
dimensionless MC time. Then Pk+1(s)−Pk(s) = Ps(t +1)−Ps(t). In that case, Ps(t +1)−Ps(t) would be the ﬁnite
forward difference approximation to the derivative dPs(t)/dt and Eq. (27.87) could be written as a differential
equation with the quantities W regarded as transition rates. Although this is common, it is misleading so we
avoid its use.

Chapter 27 • Ising Model
487
Although Eq. (27.91) is not necessary to satisfy Eq. (27.89), it is a sufﬁcient condition. It can
be written in the form
Wk(s →s′) = exp[−β	E(s′, s)]Wk(s′ →s),
(27.92)
where 	E(s′, s) = E(s′) −E(s), so we only have to deal with energy differences of
conﬁgurations. Since the factor exp[−β	E(s′, s)] is never zero, there will always be a
nonzero probability of returning from s′ to s if there is nonzero probability of going from s
to s′, so there is no possibility of a limit cycle.
The Metropolis algorithm is a convenient and efﬁcient way of satisfying Eq. (27.92).
As mentioned above, we start with a state s and select a state s′ at random. Then we can
choose to reject or accept that state such that the probability
Wk(s →s′) = W0
 1
for 	E(s′, s) < 0
exp[−β	E(s′, s)] for 	E(s′, s) ≥0.
(27.93)
Then evidently
Wk(s′ →s) = W0
 1
for 	E(s, s′) < 0 ⇒	E(s′, s) ≥0
exp[−β	E(s, s′)] for 	E(s, s′) ≥0 ⇒	E(s′, s) < 0.
(27.94)
For 	E(s′, s) < 0, we can substitute the top line of Eq. (27.93) and the bottom line of
Eq. (27.94) into Eq. (27.92) and see that it is satisﬁed. Similarly, for 	E(s′, s) ≥0, we can
substitute the bottom line of Eq. (27.93) and the top line of Eq. (27.94) into Eq. (27.92)
and see that it is satisﬁed. Since W0 ̸= 0 can be canceled after these substitutions, it
can be chosen for convenience. A very efﬁcient choice is W0 = 1, which leads to the
maximum probability that the new state will be accepted. With W0 = 1, Eq. (27.93) gives
the Metropolis algorithm.11
Although the above description of a MC simulation presents the basic methodology, it
omits many practical considerations. For example, even for a fairly small system with n =
50, N = n2 = 2500, so there are 22500 ≈10753 possible conﬁgurations. In principle, one
could calculate the Boltzmann factor for each of them, sum the results to get a partition
function, and hence calculate the Boltzmann probabilities for each, but that would involve
so much computation that it is absurd. Fortunately, most such conﬁgurations have much
higher energies than others, and therefore much smaller Boltzmann factors, so small
they are negligible. The Metropolis algorithm avoids this problem by sampling only
those conﬁgurations that have a signiﬁcant probability in the Boltzmann distribution
(Boltzmann sampling). This technique is an example of importance sampling which
makes MC simulation tractable for many other applications.
Nevertheless, one must still develop practical criteria to decide the number N ′ of
iterations that are needed for the Markov chain to settle into an approximation of the
Boltzmann distribution. Moreover, system size will be limited by the actual time and cost
that a computer must run to accurately compute and store the equilibrium distribution.
11Since we are using the condition of detailed balance, only two conﬁgurations are involved in updating from
MC step k to step k+1. So if s does not become s′ at step k+1, it remains s with probability [1−exp[−β	E(s′, s)]].

488
THERMAL PHYSICS
Fortunately, the problem has been well-studied and efﬁcient algorithms have been
devised. Some of these sample the spins in some order until all N spins have been sampled
at least once, a so-called MC sweep, and then rely on empirical rules to decide how many
MC sweeps are needed to calculate a MC Boltzmann chain with reasonable accuracy
[73, p. 55]. See also [78, 79] for some specialized techniques. Empirical rules can be
established by carrying out the simulation for systems for which analytical solutions
are available. See ﬁgure 16.1 of [9, p. 643] for a graph of the speciﬁc heat of the two-
dimensional Ising model calculated by MC simulation as compared to that calculated
from the exact solution. In that case, for n = 128, 105 sweeps gives good agreement except
near the critical temperature where 106 sweeps are necessary. In general, empirical rules
to decide the accuracy of a simulated equilibrium distribution must be established by
running the simulation even longer and comparing with previous results. In any case, one
should also run the simulation with different initial conditions to see if the results are
statistically equivalent.
Just looking at the conﬁgurations produced by MC simulation can reveal patterns that
are very different at high and low temperatures. At low temperatures, differences in the
energies of conﬁgurations are extremely important and one can see large islands of spins
of the same kind. At high temperatures, differences in energy of conﬁgurations are not
so important and the resulting patterns show much smaller clusters of each spin in no
particular arrangement. Results can also be analyzed quantitatively by generating a large
set {sMC
i
} of statistically independent conﬁgurations and taking the averages ⟨· · · ⟩MC of
various quantities with respect them, each weighted equally with probability 1/NMC. For
example, one could compute the average value of an individual spin,
⟨s⟩=
N
i=1 si
N

MC
=
1
NMC
NMC

i=1
N
j=1 sj
N

{sMC
i
}
.
(27.95)
To analyze patterns, one could choose Nij pairs of spins (sisj)d that are separated by a
distance d and compute a correlation function of the form
C(d) =

ij(sisj)d
Nij

MC
−⟨s⟩2.
(27.96)
Study of C(d) as a function of d would help to quantify the cluster sizes viewed in
patterns. It can also be used to establish a correlation length ξ beyond which C(ξ) becomes
negligibly small.
Near a critical point, MC simulations become difﬁcult because the correlation length
ξ becomes very large. Thus large systems and long-run times would be necessary to
obtain accuracy. This problem can be alleviated by using the renormalization group (RG)
approach. As suggested by Kadanoff in 1966 [80], the basic idea is to perform a length
scaling that leads to an approximately equivalent problem with scaled coupling constants,
such as J →J′, now known as a Kadanoff transformation. The success of the technique is
based on the idea that aspects of the problem, such as the existence of a phase transition,

Chapter 27 • Ising Model
489
are insensitive to the lattice constant a. Speciﬁcally, for a new lattice constant a′ = ℓa,
where ℓ> 1, there is insensitivity of results provided ℓa ≪ξ and conditions are close to
criticality. This scaling-up idea can also be viewed as removing spins from the system, or
more generally as reducing the number of degrees of freedom of a more general system,
a process known as decimation. A systematic way of handling transformations based on
this idea was developed later by Wilson [81, 82] by means of RG theory. By using such
techniques, one can begin with very weak coupling constants, for which an approximate
solution is possible. Then by successive scalings, one can use a recurrence relation to
step up to values of the coupling constants or other parameters that are of interest. A
successful application of this technique will result in successive transformations leading
to a ﬁxed point corresponding to criticality in parameter space. A detailed presentation of
RG techniques is beyond the scope of this book. For a lucid introduction see chapter 5 of
Chandler [12]; for a more extensive treatment, including the RG formulation, see chapter
14 of Pathria and Beale [9].
Other types of sampling can be accomplished by doing a MC simulation for a given
problem and using the conﬁgurations so obtained to simulate a different problem. We
illustrate this for two cases, the ﬁrst involving a different energy but the same temperature,
and the second involving a change in temperature for the same energy.
In the ﬁrst case, suppose that
E(s) = E0(s) + E1(s).
(27.97)
Then for E0(s) we have a probability and partition function given by
P0(s) = (Z0)−1 exp[−βE0(s)];
Z0 =

s
exp[−βE0(s)].
(27.98)
By using MC simulation, we obtain a set of conﬁgurations {s0
i }, i = 1, 2, . . . , NMC that
approximate P0(s) if they are equally weighted with probability 1/NMC. Then the average
value of some quantity R(s) is given by
⟨R⟩0 =

s
P0(s)R(s) ≈(NMC)−1
NMC

i=1
R({s0
i }).
(27.99)
For E(s) we have
P(s) = Z−1 exp[−βE(s)] = Z−1Z0P0(s) exp[−βE1(s)],
(27.100)
where
Z =

s
exp[−βE0(s)] exp[−βE1(s)] = Z0

s
P0(s) exp[−βE1(s)].
(27.101)
Thus,
P(s) =
P0(s) exp[−βE1(s)]

s P0(s) exp[−βE1(s)] = P0(s) exp[−βE1(s)]
⟨exp[−βE1(s)]⟩0
.
(27.102)

490
THERMAL PHYSICS
Then the average value of R(s) is given by
⟨R⟩=

s
P(s)R(s) = ⟨R(s) exp[−βE1(s)]⟩0
⟨exp[−βE1(s)]⟩0
.
(27.103)
When the averages ⟨· · · ⟩0 in Eq. (27.103) are computed by the right-hand member of
Eq. (27.99), which is only approximate, accurate results are only expected if E1(s) is a small
perturbation.
The second case is somewhat similar except we use MC simulation to approximate the
Boltzmann distribution
P(s, β) = [Z(β)]−1 exp[−βE(s)];
Z(β) =

s
exp[−βE(s)],
(27.104)
resulting in a set of conﬁgurations {si(β)}, i = 1, 2, . . . , NMC. The average value of some
R(s) corresponding to β is then
⟨R⟩β =

s
P(s, β)R(s) ≈(NMC)−1
NMC

i=1
R({si(β)}).
(27.105)
Then we change the temperature by changing β to β + 	β and seek to evaluate P(s, β +
	β). By using steps similar to those used to treat the ﬁrst case above, we ﬁnd
P(s, β + 	β) = P(s, β) exp[−	βE(s)]
⟨exp[−	βE(s)]⟩β
(27.106)
and
⟨R⟩(β+	β) = ⟨R(s) exp[−	βE(s)]⟩β
⟨exp[−	βE(s)]⟩β
.
(27.107)
When the averages ⟨· · · ⟩β are evaluated from MC simulations at β, Eq. (27.107) is likely to
be accurate only for small 	β.
Although the two cases above illustrate how the properties of the Boltzmann distri-
bution can be used to treat changes of the Hamiltonian, or of β, by MC sampling, they
should not be construed as efﬁcient algorithms. Histogram methods such as those used
by Ferrenburg and Swendsen [83, 84] are much more accurate, efﬁcient, and versatile.
These methods batch the results of MC simulation to generate histograms that depend on
parameters of the problem. For example, for the Ising model in the presence of a magnetic
ﬁeld, one has
EJ,B(s) = −J
nnp

i,j
sisj −μ∗B

i
si,
(27.108)
so the parameters K := βJ and h := βμ∗B enter the probability distribution. Associated
with given K and H, one can use MC simulation to calculate histograms of values of the
dimensionless spin-spin interaction, S = nnp
i,j
sisj, and the dimensionless magnetization,
M = 
i si. Those histograms can then be used to generate histograms of S and M for
K + 	K and h + 	h by methods similar to those discussed above.

Chapter 27 • Ising Model
491
Many other kinds of sampling can be used to treat speciﬁc problems. For an introduc-
tion to umbrella sampling, used to remove barriers or sample rare conﬁgurations, and
path integral quantum MC techniques, see Chandler [12, p. 170].
27.6.2 MC Simulation of Classical Particles
MC simulations are also useful to treat systems of N classical particles of mass m with a
Hamiltonian of the form
H = T (p) + V (q),
(27.109)
where p and q are 3N-dimensional vectors of momenta and coordinates, respectively. The
quantity
T (p) =
3N

i=1
p2
i /2m
(27.110)
is the kinetic energy and V(q) is the potential energy, usually taken to be a function of
pairwise interaction energies of particles. The classical partition function is12
Z∗
C = (h3N N!)−1

dpdq exp(−βH) =

dp exp(−βT (p))

dq exp(−βV (q)).
(27.111)
The integrals over the momenta factor into Gaussian integrals that are easily evaluated
to give
(h3N N!)−1

dp exp(−βT (p)) = (N!)−1(mkBT/2π¯h2)3N /2 = (N!)−1nN
Q ,
(27.112)
where nQ is the quantum concentration. The integral
Q :=

dq exp(−βV (q))
(27.113)
plays the role of a partition function for the coordinates. Thus the normalized distribution
function of any conﬁguration {qi} of the coordinates is given by
P({qi}) = Q−1 exp(−βV ({qi}).
(27.114)
Equation (27.114) is the Boltzmann distribution of coordinate conﬁgurations that can
be simulated by using the Metropolis algorithm, which can be done without knowledge
of Q. For example, one of the coordinates qi could be shifted by some small amount to
position q′
i to give a trial conﬁguration and then β	V = β(V ′ −V) can be evaluated
to decide whether to keep the trial conﬁguration. For short-range forces, this evaluation
would involve only a small number of particles. This is particularly simple for simulation
of particles that are hard spheres, since β	V is either zero or inﬁnity (the latter occur-
ring when the shift would cause hard spheres to overlap). Quantities such as the pair
12We have included a factor (h3N N !)−1 if appropriate to connect with quantum mechanics at high tempera-
tures, but such a factor is irrelevant to the simulation of particle conﬁgurations.

492
THERMAL PHYSICS
correlation function g(r) can be calculated from the conﬁgurations obtained from an MC
simulation.
As discussed in Section 20.5, the virial theorem can be used to relate g(r) to the equation
of state of a nonideal gas, as given by Eq. (20.77). This equation contains the derivative
∂u/∂r of the potential function u(r) for pairwise central-force interactions of the particles.
For a hard-sphere gas of particles having diameter σ, u(r) is a step function at σ, so
the formal derivative of u is a delta function and must be handled with care. As shown
by Widom [17, p. 126], a carefully taken limit leads to a hard-sphere gas pressure phsg
given by
phsg
nkBT = 1 −2
3πnσ 3g(σ +),
(27.115)
where g(σ +) is the value of the pair correlation function for a hard-sphere gas in the limit
that r approaches σ from larger values. See Figure 20–1 and the surrounding discussion of
g(r). g(σ +) can be evaluated from the results of computer simulation as a function of n.
An approximate analytical ﬁt to the data can be represented by the Carnahan-Starling [85]
equation of state
phsg
nkBT = 1 + y + y2 −y3
(1 −y)3
≡W(y),
hard-sphere gas,
(27.116)
where y = vsn = (π/6)σ 3n is the volume of hard spheres per total volume. The function
W(y) is in approximate agreement with an expansion of the pressure in terms of virial
coefﬁcients [9, p. 314].
One might wonder about the origin of the excess pressure, pxs, contained in phsg in
addition to that for an ideal gas. We shall proceed to show that pxs is related to the change
of excess conﬁgurational entropy when y changes. To do this, we write phsg = pi + pxs,
where pi = nkBT is the ideal gas pressure and
pxs = nkBT

W(y) −1
	
.
(27.117)
For the hard-sphere gas, there is no penetration of the spheres, so the molar internal
energy, u(T), depends only on the temperature, as is also the case for an ideal gas.
Therefore, the differential of the entropy becomes
ds = du
T + p
T dv = du(T)
dT
dT
T −
p
n2T dn = cv(T)
T
dT −p
nT
dy
y ,
(27.118)
where cv(T) is the molar heat capacity at constant volume. By integrating at constant T,
we obtain
s(y, T) = −kB ln y + ˜s(T) −kB
 y
0
W(x)
x
−1
x

dx,
(27.119)
where ˜s(T) is a function of integration. Since p = −nTy

∂s(y, T)/∂y

T, comparison of
the differential of Eq. (27.119) with Eq. (27.118) shows that d˜s(T) = cv(T)/T, so ˜s(T) =

[cv(T)/T] dT + constant, as expected. Thus, the ﬁrst term in Eq. (27.119) represents the

Chapter 27 • Ising Model
493
conﬁgurational molar entropy si(y) of an ideal gas and the last term represents the excess
conﬁgurational molar entropy sxs(y) of the hard-sphere gas. The lower limit of the integral
has been set equal to zero so that only si(y) + ˜s(T) remains as y →0. Evaluation of the
integral gives
sxs(y) = −kB
 y
0
W(x)
x
−1
x

dx = −kB
y(4 −3y)
(1 −y)2 .
(27.120)
The excess pressure is given by
pxs = −nyT ∂sxs(y)
∂y
= nkBT

W(y) −1
	
,
(27.121)
in agreement with Eq. (27.117).
Therefore, the excess pressure pxs of the hard-sphere gas arises because the excess
conﬁgurational molar entropy sxs(y) is a decreasing function of y. This decrease of sxs(y)
must be related to the decrease of unoccupied volume as y increases. Although we have
demonstrated this by using the Carnahan-Starling approximate function W(y), the same
conclusion would follow if a more accurate function were used.
Widom [17, p. 106] has shown that an approximate equation of state of a normal liquid
can be obtained by adding to the hard-sphere gas pressure a term −αn2, where −αn < 0
represents an average potential energy per atom due to binding forces. The essence of the
argument is that the attractive forces between liquid atoms nearly cancel for a given atom
but the associated potentials are additive and nearly uniform. The result is
p = kBTn1 + y + y2 −y3
(1 −y)3
−αn2,
(27.122)
in which the hard-sphere radius σ, contained in y, should be interpreted as an effective
radius related to the repulsive part of the actual potential. If the right-hand side of
Eq. (27.116) is expanded for small y to lowest order, the result is 1/(1 −4y) = 1/(1 −4vsn).
Then Eq. (27.122) becomes
p =
kBT
(n−1 −4vs) −αn2,
(27.123)
which is just another form of the van der Waals equation, Eq. (9.2), but in different units.13
Equation (27.122) can be analyzed by the same method used to analyze the van der Waals
ﬂuid. The spinodal curve in the y, T plane is given by vskBT/α = 2y/[yW(y)]′, where the
prime denotes the derivative with respect to y. The maximum of the spinodal curve occurs
at y = 0.1304 and the critical temperature is given by vskBT/α = 0.09433.
By means of computer simulation, one ﬁnds that the hard-sphere model displays a
phase transition between a hard-sphere gas at low volume fractions of the spheres and a
hard-sphere crystalline solid phase at high volume fractions (see ﬁgure 16.3 of [9, p. 649]).
13The correspondence can be made by setting n = NA/v, where NA is Avogadro’s number and v is the volume
per mole. Then b = 4NAvs and a = N 2
Aα.

494
THERMAL PHYSICS
The gas phase ends at y = 0.491 and the solid phase begins at y = 0.543, with co-existence
of phases for volume fractions in between. For y > 0.543, Speedy [86] gives the pressure
phsc of the hard-sphere crystal,
phsc
nkBT =
3
(1 −z) −0.5921(z −0.7072)
(z −0.601) ,
hard-sphere crystal,
(27.124)
in terms of the relative solid fraction z = nσ 3/
√
2 = y/ycp = 1.35y, where ycp = π
√
2/6 =
0.7405 corresponds to a close-packed FCC crystal. It is also possible to conduct simula-
tions [87] that avoid the transition from the hard-sphere gas to the hard-sphere crystal
and follow the disordered state into the metastable region where the pressure tends to
inﬁnity at z = 0.644 ± 0.005, which corresponds well with the Bernal [88] packing fraction
established experimentally.
The above simple example of the hard-sphere gas begins to illustrate the power of
computer simulation in describing the liquid state, something that is very limited by using
analytical methods alone. MC simulation has been used for simulation of many systems
that involve other classical particles for decades. A favorite for simulation is the Lennard-
Jones potential,
u(r) = 4ε
σ
r
 12
−
σ
r
 6
,
(27.125)
where ε > 0 is an energy parameter and σ is a length parameter. The ﬁrst term is
strongly repulsive and its form is selected for convenience; the second is attractive and
yields a force of the same form as that between electric dipoles. The potential minimum
occurs at rmin = 21/6σ = 1.12σ at which u = −ε. The Lennard-Jones potential was used for
simulations over 50 years ago that were compared to experimental results for argon [89].
More recent simulations using the Lennard-Jones potential have dealt with liquid-crystal
phase transitions [90], including those involving several crystal phases [91].
As computing power has improved exponentially over the years, MC simulation has
become a potent tool for the statistical study of models of materials with more realistic
potentials, resulting in greater variety and accuracy of results. The reader is referred to
several books cited above as well as the vast journal literature.


This page intentionally left blank 

A
Stirling’s Approximation
In the process of going from statistical mechanics to thermodynamics, we will often use
Stirling’s approximation in the form
ln(N!) ∼N ln N −N,
(A.1)
which is a good approximation when N is a large number. A good approximation for N!
itself is
N! ∼NNe−N(2πN)1/2.
(A.2)
Taking the logarithm of Eq. (A.2) gives
ln(N!) ∼N ln(N) −N + (1/2) ln(2πN),
(A.3)
but the last term in Eq. (A.3) is quite negligible for large N. For example, for N = 106,
the last term is 7.83 and the sum of the ﬁrst two terms is 12815510.56. In statistical
mechanics, we usually deal with ln N! and much larger values of N, so this extra term in
Eq. (A.3) is completely negligible. In Eq. (A.2), however, its counterpart (2πN)1/2 occurs as
a multiplicative factor and must be kept to achieve reasonable accuracy.
For N > 0, it can be shown [92, p. 253] that
N! = NNe−N(2πN)1/2eθ/(12N),
(A.4)
where 0 < θ < 1.
For the particular case of a polynomial coefﬁcient  = N!/(N1!N2! · · · Nr!) where N =
r
i=1 Ni, Eq. (A.1) leads to
ln  ∼N ln N −
r

i=1
Ni ln Ni −N +
r

i=1
Ni
= N ln N −
r

i=1
Ni ln Ni
= −
r

i=1
Ni ln(Ni/N),
(A.5)
which is an extensive function of the Ni. Note in this special case that the ﬁnal result would
have been obtained even if we had dropped the second term in Eq. (A.1). Expressions
of this type arise frequently in statistical mechanics and are used to represent extensive
thermodynamic functions, particularly the entropy.
One can use Mathematica R⃝to compute numerical values of N! either exactly or from
Stirling’s approximation and compare the results. Table A–1 gives some values of ln N! and
its approximations according to Eqs. (A.1) and (A.3). Table A–2 gives some values of N! and
497

498
THERMAL PHYSICS
Table A–1
Illustration of Accuracy of Stirling’s
Approximation for ln N!
N
ln N!
N ln N −N
N ln N −N + (1/2) ln(2πN)
10
15.10441257
13.02585093
15.09608201
100
363.7393756
360.5170186
363.7385422
1000
5912.128178
5907.755279
5912.128095
10,000
82108.92784
82103.40372
82108.92783
Table A–2
Illustration of Accuracy of Stirling’s
Approximation for N!
N
N!
(2πN)1/2NNe−N
(2πN)1/2NNe−N[1 + 1/(12N)]
1
1
0.9221370
0.9989818
2
2
1.919004
1.998963
5
120
118.0192
119.9862
10
3,628,800
3,598,696
3,628,685
its approximation by Eq. (A.2) and its correction to next order by a factor of [1 −1/(12N)].
Even for these small values of N, the results are quite reasonable. For numbers N > 1010
typical of thermodynamic systems, Stirling’s approximation is excellent.
One should still be cautious, however, in using Stirling’s approximation for ln N! to
evaluate complex expressions. For example, the probability p that a well-shufﬂed deck
of cards, when cut into two equal parts, will contain an equal number of red and black
cards in each part is given by p = (26!/13!)4/52! = 16232365000/74417546961 = 0.218126.
If Stirling’s approximation equation (A.1) is used to evaluate ln p, the result is ln p = 0
which would give the ridiculous result p = 1. By using Eq. (A.3), one obtains ln p = −(1/2)
ln(13π/2) which results in p = 0.221293, correct within 1.5%. This numerical example
illustrates that the use of Eq. (A.1) ignores the pre-factor (2πN)1/2 in Eq. (A.2), which
is ﬁne for calculating logarithms, but leads to inaccurate results when those results are
exponentiated to compute factorials themselves or ratios of them.
A.1 Elementary Motivation of Eq. (A.1)
Equation (A.1) can be motivated by elementary methods. We ﬁrst note that
I(q) :=
 q
1
ln u du = u ln u −u

q
1
= q ln q −q + 1.
(A.6)
For q = N, we can bound this integral from above and below by sums of rectangular areas
(upper and lower staircases) as illustrated in Figure A–1 for N = 10. We obtain
ln 1 + ln 2 + · · · + ln(N −1) < I(N) < ln 2 + ln 3 + · · · + ln N,
(A.7)

Appendix A • Stirling’s Approximation
499
0
2
4
6
8
10
0.0
0.5
1.0
1.5
2.0
u
FIGURE A–1 Staircase diagram used to illustrate bounds for the area under the curve ln u for 1 < u < 10. The area
under the upper staircase is larger than that under ln u while the area under the lower staircase (dashed) is smaller
than that under ln u.
which can be rewritten as
ln(N −1)! < N ln N −N + 1 < ln N!.
(A.8)
Subtracting ln N! + 1 from Eq. (A.8) and dividing by ln N! we obtain
−(1 + ln(N))
ln N!
< N ln N −N −ln N!
ln N!
< −
1
ln N!,
(A.9)
which shows that the fractional error in Eq. (A.1) is of order 1/N. Note also from Eq. (A.9)
that Eq. (A.1) will give a slight underestimate of ln N!.
A.2 Asymptotic Series
Equation (A.4) is based on Stirling’s asymptotic series [92, p. 253]
(x) ∼xxe−x(2π/x)1/2

1 +
1
12x +
1
288x2 −
139
51840x3 −
571
2488320x4 + O
 1
x5
	
(A.10)
for the gamma function, (x). The coefﬁcients in Eq. (A.10) are not very simple and are
related to Bernoulli numbers. The gamma function is deﬁned by the integral
(x) =
 ∞
0
tx−1e−t dt
(A.11)
for the continuous variable x > 0. In general, (x + 1) = x(x), which may be veriﬁed
for x > 0 by integration by parts in Eq. (A.11). For integer N, we have (N + 1) = N!.
Another special value worth noting is (1/2)
=
√π. The gamma function can be

500
THERMAL PHYSICS
-4
-3
-2
-1
1
2
3
4
-6
-4
-2
2
4
6
Γ(x)
x
FIGURE A–2 Graph of the function (x) versus x for continuous values of x. For x equal to a positive integer N(N) =
(N −1)!. For N equal to zero or a negative integer, (N) →±∞. Values of (x) for negative x are obtained by means
of analytic continuation using (x) = (x + 1)/x and values of the function deﬁned by Eq. (A.11). Note especially
(1) = 0! = 1, (2) = 1! = 1, (3) = 2! = 2, and (4) = 3! = 6.
extended to negative values of x and to complex variables by a process known as analytical
continuation. In general, z! ≡(z + 1) = z(z), where z = x + iy is a complex variable.
Figure A–2 shows a graph of the function (x) versus x for real continuous values of x.
A.2.1 Asymptotic Versus Convergent Series
Asymptotic series should be contrasted with convergent series. If we speak of a convergent
power series
f (z) =
∞

n=0
an zn,
(A.12)
we mean that the difference
 f (z) −
m

n=0
anzn

(A.13)

Appendix A • Stirling’s Approximation
501
can be made as small as desired for ﬁxed z by taking m sufﬁciently large. On the other
hand, if the series
F(z) ∼
∞

n=0
An
zn
(A.14)
is asymptotic, then [92, p. 151]
|z|m
F(z) −
m

n=0
An
zn

(A.15)
can be made as small as desired for ﬁxed m by taking |z| sufﬁciently large.1 Thus to
get more accuracy in Eq. (A.12), we take more terms; however, to get more accuracy in
Eq. (A.14) we cut off the series and take larger |z|. In fact, for ﬁxed z we usually must cut
off an asymptotic series because many asymptotic series do not converge, so taking more
terms might give a worse result.
A generalization of Eq. (A.14) is to say that if
F(z) = G(z)
H(z) ∼
∞

n=0
An
zn ,
(A.16)
then
G(z) ∼H(z)
∞

n=0
An
zn .
(A.17)
We note that Eq. (A.10) is actually of the form of Eq. (A.17). Equation (A.10) can be derived
by consecutive integration by parts and then proving that the remainder, after m terms,
satisﬁes Eq. (A.15). Equation (A.4) can be proven in a similar way.
1As a function of a complex variablez, these results only hold in some sector α < arg(z) < β. For our purposes,
we only need this sector to include z real and positive.

This page intentionally left blank 

B
Use of Jacobians to Convert
Partial Derivatives
Often in thermodynamics one is faced with the problem of converting partial derivatives
with certain quantities held constant to expressions involving other partial derivatives
with different quantities held constant. For example, one might want to relate the isother-
mal compressibility κT = V −1(∂V/∂P)T,N to the isentropic (sometimes called adiabatic)
compressibility κS = V −1(∂V/∂P)S,N. This can be done by trial and error by using the
chain rule of partial differentiation together with appropriate Maxwell relations. The use of
Jacobians, however, provides a systematic approach to this problem. For other treatments
of this topic, see Landau and Lifshitz [7, p. 50] and the ﬁrst edition of Callen [2].
B.1 Properties of Jacobians
We review brieﬂy the deﬁnition and main properties of Jacobians. We illustrate these for
three variables, but the results hold for any number of variables.
We consider the variables u, v, w that depend on x, y, z. A Jacobian is deﬁned as a
determinant of partial derivatives as follows:
∂(u, v, w)
∂

x, y, z
 =

∂u/∂x
∂u/∂y
∂u/∂z
∂v/∂x
∂v/∂y
∂v/∂z
∂w/∂x ∂w/∂y ∂w/∂z

=

∂u/∂x ∂v/∂x ∂w/∂x
∂u/∂y ∂v/∂y ∂w/∂y
∂u/∂z ∂v/∂z ∂w/∂z

.
(B.1)
Interchange of two rows or two columns of a determinant gives rise to an overall minus
sign. Thus, for example,
∂(u, v, w)
∂x, y, z = −∂(v, u, w)
∂x, y, z = ∂(v, u, w)
∂y, x, z = −∂(u, v, w)
∂y, x, z .
(B.2)
If A and B are square matrices, it is well known that the determinant of their matrix product
is the product of their determinants, that is, |AB| = |A||B|. Then by the chain rule of partial
differentiation it follows that
∂(u, v, w)
∂

x, y, z
 = ∂(u, v, w)
∂(r, s, t)
∂(r, s, t)
∂

x, y, z

(B.3)
and
∂(u, v, w)
∂

x, y, z
 = 1

∂

x, y, z

∂(u, v, w) .
(B.4)
Thus, determinants obey an algebra similar to fractions.
503

504
THERMAL PHYSICS
There is a simple connection of a determinant to a single partial derivative. Since
∂

u, y, z

∂

x, y, z
 =

∂u/∂x ∂u/∂y ∂u/∂z
∂y/∂x ∂y/∂y ∂y/∂z
∂z/∂x ∂z/∂y ∂z/∂z

=

∂u/∂x ∂u/∂y ∂u/∂z
0
1
0
0
0
1

,
(B.5)
it follows that
∂u
∂x

y,z
= ∂

u, y, z

∂

x, y, z
 .
(B.6)
B.2 Connection to Thermodynamics
One often wants to relate thermodynamic derivatives to measurable quantities such as
the heat capacity at constant pressure, Cp; the isobaric coefﬁcient of thermal expansion,
α; and the isothermal compressibility, κT, where
Cp = T
 ∂S
∂T

p,N
;
α = 1
V
∂V
∂T

p,N
;
κT = −1
V
∂V
∂p

T,N
.
(B.7)
Example 1 We ﬁrst relate the heat capacity at constant volume, namely
CV = T
 ∂S
∂T

V,N
,
(B.8)
to Cp. This was done in the text (see Eq. (5.32)) by elementary methods but we now use
determinants. Thus
CV = T ∂(S, V, N)
∂(T, V , N) = T ∂(S, V , N)
∂

T, p, N
 ∂

T, p, N

∂(T, V , N).
(B.9)
We recognize that
∂

T, p, N

∂(T, V, N) = 1
∂V
∂p

T,N
(B.10)
and readily compute1
∂(S, V, N)
∂

T, p, N
 =
 ∂S
∂T

p,N
∂V
∂p

T,N
−
 ∂S
∂p

T,N
∂V
∂T

p,N
.
(B.11)
This results in
CV = Cp −T
 ∂S
∂p

T,N
∂V
∂T

p,N
∂V
∂p

T,N
.
(B.12)
From the differential dG
=
−S dT + V dp + μ dN we obtain the Maxwell relation

∂S/∂p

T,N = −(∂V/∂T)p,N, so Eq. (B.12) becomes
1The last line of the 3 × 3 determinant is 0, 0, 1 so the result is a 2 × 2 determinant.

Appendix B • Use of Jacobians to Convert Partial Derivatives
505
CV = Cp + T
∂V
∂T

p,N
	2 ∂V
∂p

T,N
(B.13)
which may be rewritten
CV = Cp −TV α2/κT.
(B.14)
A result for this same quantity that looks somewhat different can be obtained by starting
with Cp. Thus, more brieﬂy,
Cp = T ∂

S, p, N

∂

T, p, N
 = T ∂

S, p, N

∂(T, V , N)
∂(T, V , N)
∂

T, p, N

= T
 ∂S
∂T

V,N
 ∂p
∂V

T,N
−
 ∂S
∂V

T,N
 ∂p
∂T

V,N
	 ∂V
∂p

T,N
= CV −T
 ∂p
∂T

V,N
	2 ∂V
∂p

T,N
.
(B.15)
So
Cp = CV + TV
 ∂p
∂T

V,N
	2
κT.
(B.16)
Both Eqs. (B.14) and (B.16) show that Cp ≥CV but they appear to be different. They can be
reconciled, however, by noting that
dV =
∂V
∂T

p,N
dT +
∂V
∂p

T,N
dp +
 ∂V
∂N

p,T
dN
(B.17)
from which we readily deduce that
 ∂p
∂T

V,N
= −
∂V
∂T

p,N
∂V
∂p

T,N
= α/κT.
(B.18)
Example 2 A more powerful use of Jacobians can be used to relate the isentropic
compressibility
κS = −1
V
∂V
∂p

S,N
(B.19)
to the isothermal compressibility κT. Thus,
∂V
∂p

S,N
= ∂(V , S, N)
∂p, S, N = ∂(V , S, N)
∂(V , T, N)
∂(V , T, N)
∂p, T, N ∂p, T, N
∂p, S, N .
(B.20)
In this case, each Jacobian can be identiﬁed as a single partial derivative and we readily
deduce
κS/κT = CV /Cp.
(B.21)
From this relationship, we see that κT ≥κS. Furthermore, division of Eq. (B.14) by Cp,
substitution of Eq. (B.21) and rearrangement leads to
κS = κT −TV α2/Cp.
(B.22)

506
THERMAL PHYSICS
Similarly, dividing Eq. (B.16) by CV and substituting of Eq. (B.21) gives
1
κS
= 1
κT
+ TV
 ∂p
∂T

V,N
	2 1
CV
= 1
κT
+ TV α2
κ2
TCV
.
(B.23)
Example 3 By analogy to Eq. (B.19), one can deﬁne an isentropic (sometimes called
adiabatic) coefﬁcient of expansion
αS = 1
V
∂V
∂T

S,N
(B.24)
and relate it to the isothermal coefﬁcient of expansion α. Thus
∂V
∂T

S,N
= ∂(V , S, N)
∂(T, S, N) = ∂(V , S, N)
∂(V , T, N)
∂(V , T, N)
∂(T, S, N) = −
 ∂S
∂T

V,N
∂V
∂S

T,N
.
(B.25)
We recognize (∂S/∂T)V,N = CV /T. From dF = −S dT −p dV +μ dN, we obtain the Maxwell
relation (∂S/∂V)T,N =

∂p/∂T

V,N = α/κT, where Eq. (B.18) has been used in the last step.
Putting everything together gives
αS = −CV κT
VTα .
(B.26)
This result shows unexpectedly that αS varies inversely with α and has the opposite sign.
For an ideal gas it becomes αS = −CV /pV
= −CV /NRT, which follows easily from
Eq. (3.56) for the entropy of one mole of an ideal gas.
Example 4 For
a
monocomponent
system,
the
Kramers
potential
K = U −
TS −μN so we have dK = −S dT −p dV −N dμ. The independent variables are T, V
and μ. As shown in Chapter 21, this potential is related to the grand partition function
Z by Eq. (21.13). We proceed to express the heat capacity at constant volume in terms of
derivatives with respect to these independent variables as follows:
CV = T
 ∂S
∂T

V,N
= T ∂(S, V , N)
∂(T, V , N) = T ∂(S, V , N)
∂(T, V , μ)
∂(T, V , μ)
∂(T, V , N)
= T
 ∂S
∂T

μ,V
∂N
∂μ

T,V
−
 ∂S
∂μ

T,V
∂N
∂T

μ,V
	  ∂μ
∂N

T,V
= T
 ∂S
∂T

μ,V
−T
 ∂S
∂μ

T,V
	2
/
∂N
∂μ

T,V
,
(B.27)
where the Maxwell relation (∂S/∂μ)T,V = (∂N/∂T)μ,V from dK has been used.
Example 5 If there is a functional relationship among three variables x, y, z, then
∂

x, y

∂(z, x)
∂

y, z

∂x, y ∂(z, x)
∂y, z = 1.
(B.28)
Interpreting each Jacobian as a partial derivative we obtain
[−∂y/∂z
x][−(∂z/∂x)y][−∂x/∂y
z] = 1
(B.29)

Appendix B • Use of Jacobians to Convert Partial Derivatives
507
or simply

∂y/∂z

x(∂z/∂x)y

∂x/∂y

z = −1.
(B.30)
Although the Jacobians in Eq. (B.28) behave like fractions, the corresponding partial
derivatives are each accompanied by a minus sign; therefore, they do not quite behave
like fractions, resulting in the net minus sign on the right of Eq. (B.30). Equation (5.31) is a
relation of this type where the independent variables are p, V, T with N being constant in
all derivatives and therefore irrelevant.

This page intentionally left blank 

C
Differential Geometry
of Surfaces
In this appendix, we develop some formulae based on the differential geometry of surfaces
that are useful in the treatment of surfaces and interfaces, as discussed in Chapters 13
and 14. We also explore some more aspects of the ξ vector used to treat anisotropic solid-
ﬂuid interfaces, as well as the calculus of variations needed to treat curved interfaces. For
convenience, we give the main differential and integral formulas that involve the surface
gradient ∇s, surface divergence ∇s· and surface curl ∇s× operators. This is followed by a
formula for ∇s·ξ that we use to derive a generalization of Herring’s formula for the chemical
potential at a point on curved surface, as well as a formula for the equilibrium shape. The
equilibrium shape is also calculated from a variational formulation that can be used to
prove the Wulff construction for differentiable anisotropic surface free energy.
C.1 Alternative Formulae for ξ Vector
In Chapter 14 (see Eqs. (14.30) and (14.31)) we deﬁned the vector
ξα(ˆn) := ∂˜γ (P)
∂Pα
;
ξ(ˆn) := ∇P ˜γ (P),
(C.1)
where ˜γ (P) = Pγ ( ˆn), P = P ˆn and γ ( ˆn) is the interfacial free energy per unit area as a
function of its unit normal ˆn, with other variables held constant and suppressed. We also
showed that γ = ξ · ˆn, dγ = ξ · d ˆn and ˆn · dξ = 0, where all derivatives are assumed to exist
and be continuous. Now we develop some alternative ways of calculating ξ( ˆn) directly
from derivatives with respect to ˆn.
First, we simply recognize that the chain rule of differentiation can be used to compen-
sate for the fact that the components of ˆn are not independent. Thus
ξα = ∂[Pγ (P/P)]
∂Pα
= γ Pα
P + P
3

β=1
∂γ
∂nβ
∂(Pβ/P)
∂Pα
,
(C.2)
where the partial derivatives with respect to nβ are formal derivatives taken as if the nβ
were independent. But
∂(Pβ/P)
∂Pα
= δαβ
P −PαPβ
P3
(C.3)
so
ξα = γ nα +
3

β=1
∂γ
∂nβ
(δαβ −nαnβ).
(C.4)
509

510
THERMAL PHYSICS
If we deﬁne a formal gradient operator ∇n whose components are ∂/∂nα, Eq. (C.4) can be
written in the vector form
ξ(ˆn) = γ ˆn + [∇nγ −ˆn(ˆn · ∇nγ )].
(C.5)
Given the various ways that γ can be expressed in terms of the components of ˆn, the
quantity ∇nγ is not unique but the quantity [∇nγ −ˆn( ˆn · ∇nγ )] is unique and represents
the tangential part ξt of ξ.
Another option can be used to simplify Eq. (C.5) even further. Given a function γ (nα)
of the components nα, one can always write it in the form
γh := γ

nα
(n2x + n2y + n2z)1/2

(C.6)
so that it is a homogeneous function of degree zero in the components of ˆn. Then from
Euler’s theorem,
3

β=1
nβ
∂γh
∂nβ
= 0
(C.7)
or more succinctly ˆn · ∇nγh = 0. Then Eq. (C.5) reduces to
ξ(ˆn) = γ ˆn + ∇nγh.
(C.8)
Example Problem C.1. For a crystal having cubic symmetry, the leading anisotropy is
γ (ˆn) = γ0 + γ4(n4
x + n4
y + n4
z),
(C.9)
where γ0 and γ4 are constants. Calculate ξ(ˆn) directly by differentiation with respect to the
components of ˆn.
Solution C.1. We write
γh = γ0 + γ4
(n4
x + n4
y + n4
z)
(n2x + n2y + n2z)2
(C.10)
so
∇nγh = 4γ4
(n3
xˆi + n3
yˆj + n3
z ˆk)
(n2x + n2y + n2z)2
−4γ4 ˆn
(n4
x + n4
y + n4
z)
(n2x + n2y + n2z)3 .
(C.11)
Now that the differentiation is ﬁnished, we can set both denominators equal to one. Thus
ξt = 4γ4[(n3
xˆi + n3
yˆj + n3
z ˆk) −4 ˆn(n4
x + n4
y + n4
z)]
(C.12)
and of course ξn = γ ˆn, in agreement with Eq. (14.40).
A popular alternative is to express P in terms of spherical polar coordinates with radius
r = P, where θ is the polar angle and ϕ is the azimuthal angle. Then the gradient operator
∇P becomes

Appendix C • Differential Geometry of Surfaces
511
∇r = ˆr ∂
∂r + 1
r

ˆθ ∂
∂θ + ˆϕ
1
sin θ
∂
∂ϕ

,
(C.13)
where the unit vectors
ˆr = sin θ cos ϕ ˆi + sin θ sin ϕ ˆj + cos θ ˆk;
ˆθ = cos θ cos ϕ ˆi + cos θ sin ϕ ˆj −sin θ ˆk;
ˆϕ = −sin ϕ ˆi + cos ϕ ˆj,
(C.14)
can be related to ˆi, ˆj, ˆk in a Cartesian space. Thus
ξ = ∇r[r γ (θ, ϕ)] = ˆrγ +

ˆθ ∂γ
∂θ + ˆϕ
1
sin θ
∂γ
∂ϕ

.
(C.15)
Here, ˆr must be identiﬁed with the local normal vector ˆn at a point on the surface of the
crystal, where ˆθ and ˆϕ are local unit tangent vectors. This representation can be confusing
because r is not the radius vector to some point on that surface unless that surface
happens to be a sphere of radius r. See Section C.3 for a representation that relates to a
general surface.
C.2 Surface Differential Geometry
We present some elements of surface differential geometry that are useful in treating
curved interfaces with anisotropic γ (n). We also introduce the surface gradient operator
∇s and give equations for the surface divergence ∇s·V and some of its properties. We follow
a straightforward treatment by Weatherburn [93, 94].
We deﬁne a surface in terms of parameters u and v by means of the parametric
equations x = x(u, v), y = y(u, v) and z = z(u, v), or brieﬂy r = r(u, v), where the involved
functions are assumed to have continuous ﬁrst and second derivatives. The vectors
ru := ∂r(u, v)
∂u
;
rv := ∂r(u, v)
∂v
(C.16)
are locally tangent to the surface at the point u, v; they are not collinear but they are not
necessarily orthogonal to one another. We choose the vectors ru, rv and ˆn to form a right-
handed triad, so the local unit outward normal is given by
ˆn = ru × rv
|ru × rv| = H
H ,
(C.17)
where the vector H := ru × rv and H = |ru × rv| is its magnitude. The vector area
element is
dA = ˆn dA = ˆn |ru × rv| du dv = ˆnH du dv = (ru × rv) du dv.
(C.18)
We note that H = ru × rv · ˆn and readily compute H2 = EG −F2 where
E := ru · ru;
F := ru · rv;
G := rv · rv.
(C.19)

512
THERMAL PHYSICS
In order to handle the possible non-orthogonality of ru and rv, we introduce the reciprocal
vectors
r†
u := rv × ˆn
H
;
r†
v := ˆn × ru
H
,
(C.20)
which are orthogonal to ˆn and satisfy
r†
u · ru = 1;
r†
u · rv = r†
v · ru = 0;
r†
v · rv = 1.
(C.21)
The manner in which ˆn changes as one moves along the surface can be related to its
local curvatures. We examine the derivatives1
ˆnu := ∂ˆn(u, v)
∂u
;
ˆnv := ∂ˆn(u, v)
∂v
(C.22)
which are necessarily normal to ˆn. They can therefore be resolved along ru and rv or
alternatively along r†
u and r†v. Moreover,
d ˆn = d
 H
H

= dH
H −HdH
H2 = dH
H −

ˆn · dH
H

ˆn.
(C.23)
Then if we write ˆnu = Lr†
u+Mr†v, we see that L = ru· ˆnu = ru·(∂H/∂u)/H and M = rv · ˆnu =
rv · (∂H/∂u)/H. Since ∂H/∂u = ruu × rv + ru × ruv, we readily compute L = −ˆn · ruu and
M = −ˆn · ruv. Similarly, we ﬁnd ˆnv = Mr†
u + Nr†v, where N = −n · rvv. These results can be
summarized in matrix notation by the equation
 ˆnu
ˆnv

=
 L
M
M N
 
r†
u
r†
v

=
 P R
Q S
  ru
rv

,
(C.24)
where
L := −ˆn · ruu;
M := −ˆn · ruv;
N := −ˆn · rvv
(C.25)
and
P = LG −MF
H2
; R = ME −LF
H2
;
Q = MG −NF
H2
; S = NE −MF
H2
.
(C.26)
The second matrix in Eq. (C.24) is obtained by using
r†
u = Gru −Frv
H2
;
r†
v = −Fru + Erv
H2
.
(C.27)
As shown by Weatherburn, the mean curvature and the Gaussian curvature are equal
to the trace and the determinant of the second matrix in Eq. (C.24), speciﬁcally
K ≡1
R1
+ 1
R2
= P + S;
G ≡1
R1
1
R2
= PS −QR = LN −M2
H2
,
(C.28)
where R1 and R2 are the principal radii of curvature measured in principal planes that
are orthogonal to each other and that contain ˆn. One could transform to coordinates in
1Note that ˆnu and ˆnv are not unit vectors; they are derivatives of unit vectors.

Appendix C • Differential Geometry of Surfaces
513
the principal planes by means of a series of linear transformations that would ultimately
result in transforming that matrix by means of a similarity transformation that preserves
the trace and the determinant.
One can see the connection to curvatures easily by supposing that u and v are already
orthogonal coordinates at the point of the surface under consideration and that they
have been oriented so that ruv = 0. Then F = 0, the line element would be ds2 =
E(du)2 + G(dv)2, r†
u = ru/E, r†v = rv/G, and both matrices in Eq. (C.24) would be diagonal.
Unit tangent vectors in the principal directions would be ˆtu = ru/E1/2 and ˆtv = rv/G1/2.
Equation (C.24) would become simply
ˆnu = Pru = (L/E)ru;
ˆnv = Srv = (N/G)rv .
(C.29)
For this special choice, the principal curvatures would be
1
R1
=
dθ
ds

u
=
ˆtu · ˆnu du
E1/2du
= L
E = P;
1
R2
=
dθ
ds

v
=
ˆtv · ˆnv dv
G1/2 dv
= N
G = S.
(C.30)
Thus we have
dˆn = 1
R1
ru du + 1
R2
rv dv,
principal axes,
(C.31)
which is equivalent to the formulae of Rodrigues.
In the general case, the principal curvatures are given by
1
R1,2
= P + S
2
±
	P −S
2
2
+ QR,
(C.32)
which can be found by determining the eigenvalues that correspond to the principal
axes. An outline of this transformation is the following: If we denote the second matrix
in Eq. (C.24) by P, it may be taken into diagonal form by a transformation of the form
Q−1PQ where the matrix Q = A
−1/2B encompasses three successive transformations.
The matrix A is orthogonal and takes the line element into diagonal form with positive
deﬁnite eigenvalues. 
 is the resulting diagonal eigenvalue matrix and 
1/2 is its square
root; it provides a stretching transformation. The combination of transformations A
−1/2
takes the line element into the form ds2 = dX2 +dY 2 and takes P into a symmetric matrix.
The ﬁnal matrix B is an orthogonal matrix that rotates the already orthogonal axes into the
principal axes. For future reference, we note for general parameters u, v that Eq. (C.28) can
be written
K = r†
u · ˆnu + r†
v · ˆnv;
G = n · ˆnu × ˆnv
H
.
(C.33)
C.2.1 Surface Differential Operators
The surface gradient operator ∇s is deﬁned such that
∇sφ · dr = dφ = ∂φ
∂u du + ∂φ
∂v dv,
(C.34)

514
THERMAL PHYSICS
where φ(u, v) is a scalar function deﬁned on the surface. Since dr = ru du+rv dv it follows
that
∇s = r†
u
∂
∂u + r†
v
∂
∂v .
(C.35)
For a vector of the form
V = V uru + V vrv + V n ˆn,
(C.36)
one can form a surface divergence
∇s · V = ∇s · (V uru + V vrv) + V n∇s · ˆn
(C.37)
in which there is no contribution from the derivatives of the component V n because r†
u
and r†v are perpendicular to ˆn. By the ﬁrst member of Eq. (C.33) we see that
∇s · ˆn = K,
(C.38)
so Eq. (C.37) becomes
∇s · V = ∇s · (V uru + V vrv) + V nK.
(C.39)
Note especially that the term V nK arises because the surface is curved; no such term
would be present for a divergence in the x, y plane of a Cartesian coordinate system. The
tangential components of V each lead to two terms because ru and rv are not constants.
After some algebra one obtains
∇s · V = 1
H
 ∂
∂u(HV u) + ∂
∂v (HV v)

+ V nK.
(C.40)
A case of special importance occurs when V = r(u, v), the position vector itself. Then
∇s · r =

r†
u
∂
∂u + r†
v
∂
∂v

· r = r†
u · ru + r†
v · rv = 2.
(C.41)
One can also deﬁne a surface Laplacian and a surface curl and obtain various vector
identities. The surface Laplacian is
∇2
s φ = ∇s · ∇sφ = 1
H
 ∂
∂u
Gφu −Fφv
H

+ ∂
∂v
Gφu −Fφv
H

.
(C.42)
As shown by Weatherburn, ∇2
s r = −K ˆn and ∇2
s ˆn = −(K2 −2G) ˆn + ∇sK. The surface curl is
given by
∇s × V = ˆn
H
 ∂
∂u

FV u + GV v −∂
∂v

EV u + FV v
+ 1
H

MV u + NV v
ru −

LV u + MV v
rv

−ˆn × ∇sV n.
(C.43)
A special case is ∇s × ˆn = 0. Moreover, ∇s × ∇sφ can be shown to be a vector in the
tangent plane, not necessarily zero; this is a signiﬁcant deviation from ∇× ∇φ = 0 in
three dimensions.

Appendix C • Differential Geometry of Surfaces
515
Before leaving this section we calculate the variation of H = ru × rv and ˆn = H/H for a
normal variation of the form
δr(u, v) := r −r0(u, v) = ˆn0(u, v) η(u, v),
(C.44)
where r0(u, v) is a point on some initial surface, r is the position on a neighboring varied
surface, ˆn0(u, v) is the unit normal on the original surface and the inﬁnitesimal quantity
η(u, v) is arbitrary but differentiable. Evidently
δH = ru × δrv −rv × δru = (r0u × ˆn0v −r0v × ˆn0u)η + (ru × ˆn0)ηv −(rv × ˆn0)ηu
(C.45)
to ﬁrst order in η. The coefﬁcient of η can be calculated by using Eq. (C.24) and carrying out
the cross products; it turns out to be H0 K0. The terms involving the derivatives of η can be
identiﬁed in terms of the surface gradient operator Eq. (C.35) applied to η. The result is
δH = H0 K0 η −H0∇sη.
(C.46)
Since d ˆn is perpendicular to ˆn, we see from Eq. (C.23) that the ﬁrst term in δH makes no
contribution to δ ˆn but the second term contributes to give the important result
δ ˆn = −∇sη.
(C.47)
C.2.2 Integral Theorems
The surface divergence theorem is similar to the Gauss divergence theorem except it
applies to a surface whose curvature must be accounted for. It applies to a curved surface
A having local unit normal ˆn surrounded by a closed skew curve C with vector line element
dℓwith the convention that positive circulation around the area is governed by the right-
hand rule. The outwardly directed unit tangent vector along that curve is denoted by ˆt and
points in the direction dℓ× ˆn. The theorem states that

A
∇s · V dA =

C
Vt · ˆt dℓ+

A
V nK dA,
(C.48)
where Vt = V uru + V vrv is the tangential part of V. Since ˆt dℓ= dℓ× ˆn, Eq. (C.48) can also
be written in the form

A
∇s · V dA =

C
ˆn · Vt × dℓ+

A
V nK dA.
(C.49)
The term involving the curvature K follows directly from the last term in Eq. (C.40) so we
have only to deal with

A
∇s · Vt dA =

u,v
(∇s · Vt)H du dv =

u,v
∂(HV u)
∂u
+ ∂(HV v )
∂v

du dv,
(C.50)
where the second two integrals are taken over the corresponding domain in u, v. But

u,v
∂(HV u)
∂u
+ ∂(HV v )
∂v

du dv =

u,v
HV u dv −

u,v
HV v du,
(C.51)

516
THERMAL PHYSICS
where the minus sign on the second term on the right arises because of a choice of positive
circulation according to the right-hand rule. The integrand in the line integral in Eq. (C.49)
can be written
Vt · dℓ× ˆn = (V uru + V vrv) · (ru du + rv dv) × ˆn
= (V uru + V vrv) · H(−r†
v du + r†
u dv) = HV u dv −HV v du,
(C.52)
the same as Eq. (C.51). Therefore, the tangential part of V contributes the line integral in
Eq. (C.48) or Eq. (C.49) and the normal component V n generates the term containing the
curvature K. In a ﬂat two-dimensional space, one would have only the line integral.
There is also a surface curl (Stokes) theorem, speciﬁcally

A
(∇s × V) · dA =

C
V · dℓ,
(C.53)
which is similar to the Stokes theorem for the three-dimensional curl.
C.3 ξ Vector for General Surfaces
We return to Eq. (C.1) and choose P = H, where H = ru ×rv for some crystal surface under
consideration, to obtain
ξ = ∇H[Hγ (H/H)] = γ ˆn + H∇H γ .
(C.54)
Then by using the relations from differential geometry from Section C.2, we ﬁnd
ξ = ξu ru + ξv rv + ξn ˆn,
(C.55)
where
ξu = r†
u · H∇H γ = (rv × ˆn) · ∇H γ ;
ξv = r†
v · H∇H γ = (ˆn × ru) · ∇H γ ;
ξn = γ .
(C.56)
To calculate ∇H γ , we write
γ = γ ∗(α, β),
(C.57)
where α = Hx/H, β = Hy/H, and Hz/H = ±

1 −α2 −β2 with the sign chosen locally to
make ˆn = H/H the outward normal of the crystal under consideration. Then
ξt = H∇H γ = ∂γ ∗
∂α

ˆi −α ˆn

+ ∂γ ∗
∂β

ˆj −β ˆn

,
(C.58)
which is perpendicular to ˆn as expected. Thus
ξu = ∂γ ∗
∂α

r†
u · ˆi

+ ∂γ ∗
∂β

r†
u · ˆj

;
(C.59)
ξv = ∂γ ∗
∂α

r†
v · ˆi

+ ∂γ ∗
∂β

r†
v · ˆj

.

Appendix C • Differential Geometry of Surfaces
517
To proceed further, we adopt a speciﬁc parameterization of the surface:
x = u;
y = v;
z = w(u, v).
(C.60)
Then with p := wu and q := wv we have
ru = ˆi + p ˆk;
rv = ˆj + q ˆk;
H = −p ˆi −q ˆj + ˆk
(C.61)
so that
H =

1 + p2 + q2;
α = −p/H;
β = −q/H.
(C.62)
We can also calculate the reciprocal vectors
r†
u = [(1 + q2) ˆi −pq ˆj + p ˆk]/H2;
r†
v = [−pq ˆi + (1 + p2) ˆj + q ˆk]/H2.
(C.63)
Then with γ (p, q) = γ ∗(α, β), Eq. (C.59) becomes
ξu = (1 + q2)
H2
∂γ ∗
∂α −pq
H2
∂γ ∗
∂β = −H ∂γ (p, q)
∂p
;
ξv = −pq
H2
∂γ ∗
∂α + (1 + q2)
H2
∂γ ∗
∂β = −H ∂γ (p, q)
∂q
.
(C.64)
We can use the general expression Eq. (C.40) to compute ∇s · ξ. To bear in mind the
speciﬁc parameterization of Eq. (C.60), we now use x and y instead of u and v and write
p = ∂z/∂x and q = ∂z/∂y, resulting in
∇s · ξ = −1
H
 ∂
∂x

H2 ∂γ
∂p

+ ∂
∂y

H2 ∂γ
∂q

+ γ K.
(C.65)
The curvature K can be calculated from Eq. (C.33) which can be simpliﬁed because ˆnu =
Hu/H −HHu/H2 and H is perpendicular to r†
u and r†v. Therefore, in general
K = r†
u · Hu + r†
v · Hv
H
.
(C.66)
In our special Cartesian representation,
K = −(1 + p)2zxx −2pqzxy + (1 + q)2zyy
H3
.
(C.67)
Straightforward algebra allows this curvature to be written in the form
K = −∂
∂x
∂H
∂p −∂
∂y
∂H
∂q .
(C.68)
Equation (C.68) can be combined with Eq. (C.65) to produce, after considerable algebra,
the compact result
∇s · ξ = −∂
∂x
∂
∂p −∂
∂y
∂
∂q ,
(C.69)

518
THERMAL PHYSICS
where  := Hγ . This result can be obtained more easily by means of a variational
calculation (see Section C.4.1) committed to our choice of a Monge representation from
the outset. Note particularly the form
∇s · ξ = −(ppzxx + 2pqzxy + qqzyy),
(C.70)
which displays the symmetry of the result.
C.4 Herring Formula
We proceed to derive a formula due to Herring at a point on an anisotropic surface. The
partial derivatives of  in Eq. (C.70) are given explicitly by
pp =
(1 + p2)γ
(1 + p2 + q2)3/2 +
2pγp
(1 + p2 + q2)1/2 + (1 + p2 + q2)1/2γpp;
pq = −
pqγ
(1 + p2 + q2)3/2 +
qγp + pγq
(1 + p2 + q2)1/2 + (1 + p2 + q2)1/2γpq;
qq =
(1 + q2)γ
(1 + p2 + q2)3/2 +
2qγq
(1 + p2 + q2)1/2 + (1 + p2 + q2)1/2γqq.
(C.71)
For the case in which γ is a constant, Eq. (C.70) must give just γ K, where K is the mean
curvature, so we obtain the well known formula
K = −(1 + q2)zxx −2pqzxy + (1 + p2)zyy
(1 + p2 + q2)3/2
(C.72)
for the sum of the principal curvatures. Simpliﬁcation of Eq. (C.70) for anisotropic γ can be
obtained by choosing very special Cartesian axes at each point of the equilibrium shape.
The z axis is chosen to be along the normal to the equilibrium shape with the x, y plane
locally tangent to the shape. In that case, p = q = 0 when evaluated at the chosen point,
which gives
∇s · ξ = −(γ + γpp)zxx −2γpqzxy −(γ + γqq)zyy,
at a point x0, y0, for z along ˆn0.
(C.73)
If, in addition, the x and y axes are oriented along the principal axes of curvature of the
surface, we have zxy = 0 and Eq. (C.73) reduces to
∇s · ξ = γ + γpp
R1
+ γ + γqq
R2
,
at a point x0, y0, for z along ˆn0, principal axes,
(C.74)
where 1/R1 = −∂2z/∂x2 = K1 and 1/R2 = −∂2z/∂y2 = K2 are principal curvatures.
In the vicinity of the surface point x0, y0 under consideration, the angle θ made by ˆn
with ˆn0 = ˆk is given by cos θ = ˆn · ˆk = (1 + p2 + q2)−1/2 so tan2 θ = p2 + q2. For principal
planes, tan θ1 = ±p and tanθ2 = ±q. With this notation, Eq. (C.74) can be written in the
Herring form
∇s · ξ = γ + γθ1θ1
R1
+ γ + γθ2θ2
R2
,
at a point x0, y0, principal planes,
(C.75)
where the derivatives are to be evaluated at θ1 = 0 and θ2 = 0.

Appendix C • Differential Geometry of Surfaces
519
By incorporating Eq. (C.75) in Eq. (14.90) of the text, we obtain
ωF
v −ωs
v = γ + γθ1θ1
R1
+ γ + γθ2θ2
R2
,
(C.76)
which is a somewhat more general version of Herring’s result. The original Herring formula
[38, 41] pertained to the case of a solid-vapor interface for a single component for which
Eq. (14.102) of the text becomes
μ = μ∞+ 0
γ + γθ1θ1
R1
+ γ + γθ2θ2
R2

.
(C.77)
Although the form of Eq. (C.76) is elegant, it is not very useful computationally because
it requires one to ﬁnd the principal axes of curvature beforehand. In particular, it is not
a differential equation for the equilibrium shape, since it applies only at a single point.
A more useful expression that still applies only at a point but does not require ﬁnding the
principal axes can be obtained by using Eq. (C.73), namely
ωF
v −ωs
v = −(γ + γpp)zxx −2γpqzxy −(γ + γqq)zyy.
(C.78)
An elegant geometrical interpretation of the terms γ + γθ1θ1 and γ + γθ2θ2 was given
by Johnson [95] for the case in which Eq. (C.77) is applied to give a local equilibrium
condition at the surface of a body that is not the equilibrium shape. In that case, R1 and R2
are principal radii of the non-equilibrium body at the point under consideration. Johnson
shows that γ + γθ1θ1 and γ + γθ2θ2 are proportional to the radii of curvature ρ1 and ρ2 of
the equilibrium shape projected onto principal planes of the non-equilibrium body. Since
the convex part of the ξ plot is similar to the equilibrium shape, it turns out that γ + γθ1θ1
and γ + γθ2θ2 are equal to the radii of curvature of the ξ plot, calculated in the respective
principal planes of the non-equilibrium body.
C.4.1 Variational Formulation
If we adopt a Monge representation z = z(x, y) of the interface, one can formulate the
variational problem for the equilibrium shape as follows.We minimize the interfacial free
energy

Axy
 dx dy,
(C.79)
where  = γ H = γ (p, q)

1 + p2 + q2, subject to the constraint of constant volume,

Axy
z(x, y) dx dy.
(C.80)
Here,  is the free energy per unit area of the x, y plane and the integration is over Axy, a
ﬁxed projected area in the x, y plane. By means of a Lagrange multiplier 2λ, we obtain the
variational problem

520
THERMAL PHYSICS
δ

Axy
[ −2λz] dx dy = 0.
(C.81)
By carrying out the variation, Eq. (C.81) becomes

Axy
∂
∂p δp + ∂
∂q δq −2λδz

dx dy = 0.
(C.82)
Then with δp = δ∂z/∂x = ∂(δz)/∂x and δq = δ∂z/∂y = ∂(δz)/∂y, we obtain

Axy
 ∂
∂x
∂
∂p δz

+ ∂
∂y
∂
∂q δz

−
 ∂
∂x
∂
∂p

+ ∂
∂y
∂
∂q

+ 2λ

δz

dx dy = 0.
(C.83)
The ﬁrst two terms can be integrated to the boundary where the result vanishes, either
because δz vanishes or because the boundary is closed. Since δz is arbitrary within Axy, its
coefﬁcient in the integral must vanish, resulting in
−∂
∂x
∂
∂p

−∂
∂y
∂
∂q

= 2λ.
(C.84)
In view of Eqs. (C.69) and (14.90), ∇s · ξ = 2λ = ωF −ωsv.
For a closed body, one can ﬁnd an integral of Eq. (C.84) by following a method outlined
by Landau and Lifshitz [7, p. 460]. We replace these derivatives by Jacobians as follows:
∂(∂/∂p)
∂x

y
= ∂

∂/∂p, y

∂

x, y

;
∂(∂/∂q)
∂y

x
= ∂

x, ∂/∂q

∂

x, y

.
(C.85)
We multiply the resulting expression by the Jacobian ∂(x, y)/∂(p, q) to obtain
−∂

∂/∂p, y

∂

p, q

−∂

x, ∂/∂q

∂

p, q

= 2λ ∂

x, y

∂

p, q
.
(C.86)
Then we introduce the function
φ(p, q) = z −xp −yq
(C.87)
whose differential
dφ = −x dp −y dq
(C.88)
follows because dz = p dx + q dy. Thus Eq. (C.86) becomes
∂
∂/∂p, ∂φ/∂q
∂

p, q

+ ∂
∂φ/∂p, ∂/∂q
∂

p, q

= 2λ∂
∂φ/∂p, ∂φ/∂q
∂

p, q

.
(C.89)
An obvious integral of Eq. (C.89) is  = λφ, so
(p, q)/λ = z −xp −yq = z −x ∂z
∂x −y ∂z
∂y ,
(C.90)
which has the form of a Legendre transform. According to Eq. (C.88)
d(/λ) = −x dp −y dq,
(C.91)

Appendix C • Differential Geometry of Surfaces
521
so
∂(/λ)
∂p

q
= −x;
∂(/λ)
∂q

p
= −y.
(C.92)
Therefore, the inverse of Eq. (C.90) is
z = (/λ) + px + yq = (/λ) −p∂(/λ)
∂p
−q∂(/λ)
∂q
(C.93)
which also has the form of a Legendre transform. The transformation X = λx, Y = λy and
Z = λz gives the forms of these equations developed in Section 14.7.
The form of Eq. (C.90) can be used to obtain the Wulff construction for the equilibrium
shape. It can be rewritten in the form
γ (p, q) = λ z −xp −yq

1 + p2 + q2 ,
(C.94)
which is a ﬁrst order nonlinear partial differential equation for z(x, y). The components of
the unit surface normal are
nx =
−p

1 + p2 + q2 ;
ny =
−q

1 + p2 + q2 ;
nz =
1

1 + p2 + q2 ,
(C.95)
in agreement with Eq. (C.62). Regarding p and q to be parameters, the right-hand side of
Eq. (C.94) represents a family of tangent planes to the equilibrium shape and the envelope
of such planes is the integral of that nonlinear partial differential equation for z(x, y). This
is the basis of the Wulff construction. This becomes more obvious if we write Eq. (C.94) in
the form
γ (ˆn) = λ r · ˆn
(C.96)
from which it is clear that γ is proportional to the so-called support function for the
equilibrium shape. In terms of the scaled coordinates R = λr, it is the support function
for the shape. In fact we know from Section 14.7 that ξ = λr so we can also write
γ (ˆn) = ξ · ˆn,
(C.97)
which we know to be one of the properties of the ξ vector. There is a subtle but important
difference between Eqs. (C.96) and (C.97) that is worth attention. If the equilibrium shape
has missing orientations, Eq. (C.96) only gives the true γ ( ˆn) for those orientations that
actually appear on the shape; for orientations that are missing it gives another function
that we called ( ˆn) in Section 14.4. On the other hand, if ξ were known for all orientations,
including the ears that must be truncated to give the equilibrium shape, one would obtain
γ ( ˆn) for all orientations from Eq. (C.97).

This page intentionally left blank 

D
Equilibrium of Two-State Systems
We use the microcanonical ensemble to make a detailed study of equilibrium of a
composite system consisting of two subsystems, each having different numbers of spin
1/2 particles. This will serve as an explicit demonstration of how the composite system
achieves its most probable state, as well as the approximations that lead to additivity of
entropy. We follow closely a treatment of two identical spin systems by Kittel and Kroemer
[6, p. 37] but allow each system to have a different number of spins and evaluate explicitly
the overlap integral to determine the entropy of the combined system.
First we consider a system made up of N spins, each ﬁxed in a solid and having two
non-degenerate energy levels. We examine a conﬁguration of the system in which the
lower state with energy −m0B (spin up) is occupied by n1 spins and the upper state with
energy m0B (spin down) is occupied by n2 = N −n1 spins. Here, m0 > 0 is the magnetic
moment of a spin and B is the strength of the magnetic ﬁeld. Following Kittel and Kroemer,
we introduce the spin excess, 2s, where
2s =: n1 −n2,
(D.1)
which results in
n1 = N
2 + s;
n2 = N
2 −s.
(D.2)
Here, s can be integral . . . , −3, −2, −1, 0, 1, 2, 3, . . . or half integral . . . , −5
2, −3
2, −1
2, 1
2, 3
2,
5
2, . . ., depending on whether N is even or odd. In any case, 2s will represent the excess1
number of spins in the ground state, and 0 ≤s ≤N/2. The energy of this state is
E = n1(−m0B) + n2(m0B) = −2sm0B.
(D.3)
We assume that these spins are identical but distinguishable by virtue of their ﬁxed
positions in a solid. Then the number of microstates of the system that corresponds to the
given conﬁguration is
N!
n1!n2! =
N!
n1!(N −n1)! =
N!
( N
2 + s)!( N
2 −s)!
=: ˜g(N; s),
(D.4)
where ˜g(N; s) is a multiplicity function that plays the same role as the multiplicity function
g(N, M) in Section 16.2 except in terms of a different variable, the correspondence being
s = N/2 −M. Thus, the entropy
1Kittel and Kroemer take N to be even, so s can be considered to be the number of spin ﬂips with respect to
equally populated states. Negative values of s correspond to states of the whole system in which the upper spin
state has a higher population than the lower one, and hence formally to negative temperatures, which we do not
allow. At inﬁnite temperature, the upper and lower spin states are equally populated and s = 0.
523

524
THERMAL PHYSICS
S = kB ln (N, E) = kB ln ˜g(N; s),
(D.5)
where kB is Boltzmann’s constant.
We proceed to illustrate explicitly what happens to the entropy when two spin systems,
one of size N1 and the other of size N2, combine to form a system of size N = N1 + N2. To
do this, we note that the coefﬁcients of tn in the binomial expansion
(1 + t)N =
N

n=0
N!
n!(N −n)!tn
(D.6)
are the same as those that enter into Eq. (D.4). In view of the relation
(1 + t)N1(1 + t)N2 = (1 + t)N ,
(D.7)
we seek to relate the multiplicity functions for the system with N spins to the multiplicity
functions of the systems having N1 and N2 spins by expanding each binomial and
equating the coefﬁcients of like powers of t. Thus
N1

r1=0
N1!
r1!(N1 −r1)!tr1
N2

r2=0
N2!
r2!(N2 −r2)!tr2 =
N

r=0
N!
r!(N −r)!tr.
(D.8)
Equating the coefﬁcient of tr results in

r1
N1!
r1!(N1 −r1)!
N2!
r2!(N2 −r2)! =
N!
r!(N −r)! ,
(D.9)
where the sum over r1 is restricted by2 the set of constraints r1 + r2 = r, 0 ≤r1 ≤N1 and
0 ≤r2 ≤N2, which also guarantees 0 ≤r ≤N. In terms of the multiplicity functions ˜g,
Eq. (D.9) can be written

s1
˜g(N1; s1)˜g(N2; s −s1) = ˜g(N; s);
N = N1 + N2,
(D.10)
where the sum over s1 has the additional restrictions 0 ≤s1 ≤N1/2 and 0 ≤s2 = s −s1 ≤
N2/2.
We know that s = s1+s2 because of conservation of energy. We are interested in systems
having a huge number of spins, say of order 1022, in which case Eq. (D.10) can be simpliﬁed
greatly because the sum on the left will be dominated by its largest terms. To see this, one
can use Stirling’s approximation3 which leads to
˜g(N; s) = ˜g(N; 0) e−2s2/N ,
(D.11)
2An equivalent way of restricting the sum over r1 is to require r1+r2 = r and replace the factorials with gamma
functions according the relation n!(n + 1). Then since (m) = ±∞when m is zero or a negative integer, one
can sum over all non-vanishing terms.
3We use N ! ∼N N e−N (2πN )1/2 for better accuracy, since we deal here with the factorial rather than its
logarithm. To obtain Eq. (D11) one must expand formally in the small variable 2|s|/N ; however, this Gaussian
approximation is accurate to quite large values of s as shown by the local DeMovire-Laplace theorem. See
Gnedenko [75, p. 94] for details.

Appendix D • Equilibrium of Two-State Systems
525
20
20
40
60
80
50
100
150
s∗
1
s1
FIGURE D–1 Illustration of the high and narrow peak resulting from the product of two Gaussian peaks of equal
height as a function of s1 for N1 = N2 = 100 and s = 60. Since the peaks are so high we have plotted their
logarithms to the base 10, speciﬁcally log10 ˜g(N1; s1), log10 ˜g(N2; s −s1), and log10[˜g(N1; s1)˜g(N2; s −s1)]. Even for
these small numbers, we see that the Gaussian peak due to overlap has a height of about 10120 and a width of
about 10 at half height.
where
˜g(N; 0) :=

2
πN 2N .
(D.12)
This is often referred to as the Gaussian approximation and applies also to ˜g(N1; s1) and
˜g(N2; s2). For huge N, the function ˜g(N; s) is highly peaked near s1 = 0 and is a quasi-
continuous function of s. The same is true for ˜g(N1; s1) and ˜g(N2; s2) as functions of s1 and
s2. We can therefore approximate the sum in Eq. (D.10) by an integral to obtain

ds1 ˜g(N1; 0)˜g(N2; 0)e−2s2
1/N1e−2(s−s1)2/N2 = ˜g(N; 0)e−2s2/N .
(D.13)
As illustrated in Figure D–1, the integral in Eq. (D.13) is over the region of overlap of two
Gaussians, one centered at s1 = 0 and the other centered at s2 = s −s1. The product of
these overlapping Gaussian peaks forms an even higher and narrower Gaussian peak. For
huge numbers of spins typical of a thermodynamic system, the overlap peak is so high and
narrow that it dominates the integral in Eq. (D.13).
The overlap peak occurs at the maximum of the product ˜g(N1; s1)˜g(N2; s2), with s2 =
s −s1. We can ﬁnd the position of this peak by differentiation of ˜g(N1; s1)˜g(N2; s2) with
respect to s1 or, more simply, by differentiating its logarithm with respect to s1 to obtain
∂ln ˜g(N1; s1)
∂s1
= ∂ln ˜g(N2; s2)
∂s2
;
s2 = s −s1.
(D.14)

526
THERMAL PHYSICS
Equation (D.14) determines values s∗
1 and s∗
2
= s −s∗
1 that correspond to the over-
lap peak. Therefore, s∗
1 and s∗
2 correspond to the dominant contributions of the ther-
modynamic macrostates of the subsystems. The total energy is divided between the
two subsystems so that Eq. (D.14) is satisﬁed, which is equivalent to equalizing their
temperatures.
In terms of the explicit representations of ˜g(N1; s1) and ˜g(N2; s2) (see Eqs. (D.11)
and (D.12)), we can write Eq. (D.14) in the form
∂
∂s1

ln ˜g(N1; 0) −2s2
1/N1

=
∂
∂s2

ln g(N2; 0) −2s2
2/N2

(D.15)
which results in
s∗
1
N1
= s∗
2
N2
= s
N ,
(D.16)
where the last equality follows because s∗
1 + s∗
2 = s and N1 + N2 = N.
We have yet to demonstrate the additivity of entropy when these subsystems are
combined. To do this, we return to Eq. (D.13) and introduce the variable δ = s1 −s∗
1 such
that δ = 0 corresponds to the peak of the product of the Gaussians. After some algebra and
the use of Eq. (D.16), the integrand in Eq. (D.13) can be written
˜g(N1; s1)˜g(N2; s −s1) = (˜g1 ˜g2)maxe−δ2/δ2
0,
(D.17)
where
(˜g1 ˜g2)max := ˜g(N1; s∗
1)˜g(N1; s∗
2) = ˜g(N1; 0)˜g(N2; 0)e−2s2/N
(D.18)
and
δ0 :=

N1N2
2N
.
(D.19)
Therefore Eq. (D.13) becomes approximately
(˜g1 ˜g2)max

e−δ2/δ2
0 dδ = ˜g(N; s).
(D.20)
Since the Gaussian peak represented by Eq. (D.17) is so high and narrow, the range of
integration of the integral in Eq. (D.20) can be taken to be −∞to ∞, in which case it
becomes √πδ0. Thus Eq. (D.20) becomes
√πδ0(˜g1 ˜g2)max = ˜g(N; s).
(D.21)
From Eq. (D.21), we see with the help of Eqs. (D.11) and (D.19) that (˜g1 ˜g2)max is not equal
to ˜g(N; s) because of the multiplicative factor √πδ0. But if we take the logarithm of both
sides to relate to the entropy, we see that
ln(˜g1 ˜g2)max + 1
2 ln π + 1
2 ln
N1N2
2N

= ln ˜g(N; s).
(D.22)

Appendix D • Equilibrium of Two-State Systems
527
In view of Eqs. (D.12) and (D.18), we see that the ﬁrst term in Eq. (D.22) is of order N, the
second is of order 1, and the third is of order ln N. The second two terms are negligible
compared to the ﬁrst, so we have
ln(˜g1 ˜g2)max = ln ˜g(N1; s∗
2) + ln ˜g(N2; s∗
1) = ln ˜g(N; s),
(D.23)
which demonstrates the additivity of the entropy.
In other words, in the thermodynamic limit of large numbers of spins, each of the spin
subsystems can be regarded as being in its most probable state, consistent with a common
temperature that governs how they share the total energy of their combined equilibrium
state. This is a general property, believed to be true of all thermodynamic systems. Here
we have only demonstrated it explicitly in a simple case.

This page intentionally left blank 

E
Aspects of Canonical
Transformations
We present some aspects of canonical transformations that are used in classical mechan-
ics to transform from one set of generalized coordinates q = q1, q2, . . . , qN and their
conjugate momenta p = p1, p2, . . . , pN to another independent set Q = Q1, Q2, . . . , QN
and P = P1, P2, . . . , PN according to relations of the form
qi = qi(Q, P, t);
pi = pi(Q, P, t).
(E.1)
In this somewhat compressed notation, we regard q, p, Q, and P to be N-dimensional
vectors which we do not write in bold face in order to avoid cumbersome expressions.
For N particles each moving in three dimensions, we would have N = 3N and the entire
phase space for the system would have dimension 6N, but we retain the more general
notation which could be applicable in a two-dimensional world, where N = 2N, or if
certain degrees of freedom are suppressed.
We shall treat the general case in which the Hamiltonian H(q, p, t) as well as the
transformation equations depend on time, even though our primary interest will be
applications to conservative systems for which there is no explicit dependence on time.
As is well known, the dynamical equations are given in the original variables by Hamilton’s
equations
˙qi = ∂H
∂pi
;
˙pi = −∂H
∂qi
.
(E.2)
Here, a dot above a variable denotes its total time derivative, d/dt. For a canonical
transformation, dynamical equations are given in terms of the new variables by equations
of the same form
˙Qi = ∂K
∂Pi
;
˙Pi = −∂K
∂Qi
,
(E.3)
where K(Q, P, t) is the new Hamiltonian.
Our treatment of this general case follows closely a treatment by Courant [96, p. 248]
but in the modern notation of classical mechanics, as in Goldstein [97, p. 378]. It also
includes a demonstration that the necessary and sufﬁcient conditions for a canoni-
cal transformation, to be derived below, lead explicitly to Hamilton’s equations for the
new variables. Courant proceeds to show that canonical transformations belong to the
529

530
THERMAL PHYSICS
so-called symplectic group, from which many properties follow easily.1 In particular, it
will be shown that the Jacobian
J = ∂

q, p

∂(Q, P) ≡∂

q1, q2, . . . , qN, p1, p2, . . . , pN

∂(Q1, Q2, . . . , QN, P1, P2, . . . , PN) = ±1.
(E.4)
Since the absolute value of this Jacobian |J| = 1, the volume element in phase space takes
the same form dQ1dQ2 · · · dQNdP1dP2 · · · dPN in terms of the transformed variables as it
did in terms of the original variables, namely dq1dq2 · · · dqNdp1dp2 · · · dpN. This fact can
sometimes be used to simplify the calculation of the classical partition function.
E.1 Necessary and Sufﬁcient Conditions
We begin by recalling that Hamilton’s equations can be derived by means of the variational
principle
δ
 t2
t1

i
pi ˙qi −H(q, p, t)

dt = 0,
(E.5)
where δ denotes virtual synchronous2 variations of the actual trajectory that connects a
ﬁxed point in phase space at time t1 to another ﬁxed point in phase space at time t2. The
resulting Euler-Lagrange equations, obtained by considering variations in coordinates and
momenta to be independent, are just the 2N ﬁrst order Hamilton equations, Eq. (E.2).
The transformation to the new variables will have the same form if a similar variational
principal holds, namely
δ
 t2
t1
⎡
⎣
k
Pk ˙Qk −K(Q, P, t)
⎤
⎦dt = 0.
(E.6)
We are, of course, free to add the total time derivative of some function F(Q, P, t) to the
integrand in Eq. (E.6) to obtain
δ
 t2
t1
⎡
⎣
k
Pk ˙Qk −K(Q, P, t) + dF(Q, P, t)
dt
⎤
⎦dt = 0
(E.7)
because the end points are ﬁxed, so
δ
 t2
t1
dF(Q, P, t)
dt
dt = δ F(Q, P, t)|t2
t1 = 0.
(E.8)
1The author would like to acknowledge David Kinderlehrer for bringing this to his attention and for
introducing him to the relevant literature.
2Here, synchronous means that the independent variations δq and δp are at a ﬁxed time. For details, see
Goldstein [60, p. 225].

Appendix E • Aspects of Canonical Transformations
531
By comparison of Eqs. (E.5) and (E.8), we deduce that a canonical transformation is
possible if functions K and F can be found such that the equation3

i
pi ˙qi −H(q, p, t) =

k
Pk ˙Qk −K(Q, P, t) + dF(Q, P, t)
dt
(E.9)
holds identically as a function of the variables Q, P, ˙Q, ˙P, t, where it is understood that the
left-hand side is to be evaluated by substitution of Eq. (E.1).
By carrying out the substitution and differentiation in Eq. (E.9), one obtains the
following set of equations from the coefﬁcients of ˙Qk, of ˙Pk and remaining terms:
∂F
∂Qk
=

i
pi
∂qi
∂Qk
−Pk;
(E.10)
∂F
∂Pk
=

i
pi
∂qi
∂Pk
;
(E.11)
∂F
∂t = K(Q, P, t) −H(q, p, t) +

i
pi
∂qi
∂t .
(E.12)
Since these equations determine the partial derivatives of F, they will be solvable if and
only if all second mixed partial derivatives are independent of the order of differentiation.
We ﬁrst deal with Eqs. (E.10) and (E.11) and then return later to Eq. (E.12) which can be
satisﬁed by a suitable choice of K(Q, P, t). We obtain:
∂2F
∂Pj∂Pk
−
∂2F
∂Pk∂Pj
=

i
 ∂qi
∂Pk
∂pi
∂Pj
−∂qi
∂Pj
∂pi
∂Pk

= 0;
(E.13)
∂2F
∂Pj∂Qk
−
∂2F
∂Qk∂Pj
=

i
 ∂qi
∂Qk
∂pi
∂Pj
−∂qi
∂Pj
∂pi
∂Qk

−δjk = 0;
(E.14)
∂2F
∂Qj∂Qk
−
∂2F
∂Qk∂Qj
=

i
 ∂qi
∂Qk
∂pi
∂Qj
−∂qi
∂Qj
∂pi
∂Qk

= 0.
(E.15)
Equations (E.13) to (E.15) are the necessary and sufﬁcient conditions for a canonical
transformation. They can be written in a compact form in terms of Lagrange brackets
[S, T]qp :=

i
∂qi
∂S
∂pi
∂T −∂qi
∂T
∂pi
∂S

,
(E.16)
where S and T are any two members of the set Q, P. In that case these conditions become
[Pk, Pj]qp = 0;
[Qk, Pj]qp = δkj;
[Qk, Qj]qp = 0.
(E.17)
3This treatment is different from treatments that involve generating functions that are functions of both the
old and new variables because the 2N variables Q, P in Eq. (E.1) are always independent. Thus if F(Q, P, t)
were replaced by F1(Q, q, t), one could obtain a canonical transformation only if the 2N variables Q, q were
independent, which would not be the case for a coordinate transformation alone. The present approach
therefore leads to general conditions that are necessary and sufﬁcient.

532
THERMAL PHYSICS
Of course we could carry out everything by interchanging the roles of the original and new
variables, in which case equivalent conditions would be
[pk, pj]QP = 0;
[qk, pj]QP = δkj;
[qk, qj]QP = 0.
(E.18)
We now return to consider the mixed second derivatives involving time. From Eq. (E.12)
we compute
∂2F
∂Pj∂t = ∂K
∂Pj
−

i
∂H
∂pi
∂pi
∂Pj
+ ∂H
∂qi
∂qi
∂Pj

+

i
∂pi
∂Pj
∂qi
∂t +

i
pi
∂2qi
∂Pj∂t
= ∂K
∂Pj
−

i

˙qi
∂pi
∂Pj
−˙pi
∂qi
∂Pj

+

i
∂pi
∂Pj
∂qi
∂t +

i
pi
∂2qi
∂Pj∂t
(E.19)
and from Eq. (E.11)
∂2F
∂t∂Pj
= ∂qi
∂Pj
∂pi
∂t +

i
pi
∂2qi
∂t∂Pj
.
(E.20)
Equating these mixed partials and solving for ∂K/∂Pj, we obtain
∂K
∂Pj
=

i

˙qi
∂pi
∂Pj
−˙pi
∂qi
∂Pj

−

i
∂pi
∂Pj
∂qi
∂t + ∂qi
∂Pj
∂pi
∂t
=

k
[Qk, Pj]qp ˙Qk +

k
[Pk, Pj]qp ˙Pk =

k
δjk ˙Qk = ˙Qj.
(E.21)
Similarly, from ∂2F/∂t∂Qj = ∂2F/∂Qj∂t we obtain
∂K
∂Qj
=

i

˙qi
∂pi
∂Qj
−˙pi
∂qi
∂Qj

−

i
∂pi
∂Qj
∂qi
∂t + ∂qi
∂Qj
∂pi
∂t
=

k
[Qk, Qj]qp ˙Qk +

k
[Pk, Qj]qp ˙Pk = −

k
δjk ˙Pk = −˙Pj.
(E.22)
Equations (E.21) and (E.22) show explicitly that the conditions Eq. (E.17) lead to Hamilton’s
equations in the new variables.
E.1.1 Symplectic Transformation
We now demonstrate that the conditions Eq. (E.17) can be written in the form of a
symplectic transformation. This can be accomplished by introducing two 2N × 2N
matrices
M =

∂q/∂Q ∂q/∂P
∂p/∂Q ∂p/∂P

;
S =

0
1
−1 0

,
(E.23)
where each entry is, itself, an N × N matrix. For example, ∂q/∂Q has matrix elements
(∂q/∂Q)ij = ∂qi/∂Qj. In particular, the Jacobian of the transformation, given by Eq. (E.4),
is just J = det M. In the matrix S, 1 is understood to be the N × N unit matrix and 0 is the
N × N null matrix. We observe that

Appendix E • Aspects of Canonical Transformations
533
S2 =
 0
1
−1 0
  0
1
−1 0

=
 −1
0
0
−1

= −
 1 0
0 1

,
(E.24)
so S plays the role of i =
√
−1 in this space. We also observe that
(det S)2 = det S2 = (−1)2N = 1,
(E.25)
so det S = ±1. Inspection shows that det S = −1 if N is odd and det S = 1 if N is even.
Evidently the inverse S−1 = ˜S, the transpose of S. We shall also need the transpose of M,
namely
˜M =


∂q/∂Q

∂p/∂Q

∂q/∂P

∂p/∂P

.
(E.26)
Then from the conditions given by Eq. (E.17) it follows that
˜MSM = S
(E.27)
and M is said to be a symplectic matrix. To see this, ﬁrst compute
SM =
 0
1
−1 0
  ∂q/∂Q ∂q/∂P
∂p/∂Q ∂p/∂P

=
 ∂p/∂Q
∂p/∂P
−∂q/∂Q −∂q/∂P

.
(E.28)
Then ˜MSM is given by


∂q/∂Q

∂p/∂Q

∂q/∂P

∂p/∂P
  ∂p/∂Q
∂p/∂P
−∂q/∂Q −∂q/∂P

=
 ((QQ)) ((QP))
((PQ)) ((PP))

,
(E.29)
where the symbols in double parentheses are N × N matrices given by the Lagrange
brackets as follows:
((PP))kj = [Pk, Pj]qp;
((QP))kj = [Qk, Pj]qp;
((QQ))kj = [Qk, Qj]qp
(E.30)
with ((QP)) = −((PQ)). Then by Eq. (E.17), we see that the right-hand side of Eq. (E.29) is
equal to S.
Having established Eq. (E.27), we can now easily compute the Jacobian for any canon-
ical transformation. We have
det ˜MSM = det ˜M det S det M = (det M)2 det S = det S.
(E.31)
Since det S = ±1, it can be canceled and we obtain (det M)2 = 1 from which
J = det M = ±1.
(E.32)
Thus, as stated above, for a canonical transformation the volume element in phase space
takes the same form dQ1dQ2 · · · dQN dP1dP2 · · · dPN in terms of the new variables as it did
in terms of the original variables, namely dq1dq2 · · · dqN dp1dp2 · · · dpN . This may seem
counterintuitive because one is so familiar with the fact that the volume element in real
Cartesian space is dxdydz, whereas in cylindrical coordinates it is r2 sin θdrdθdφ, which
contains scale factors. But for canonical transformations, we must remember that both
coordinates and their conjugate momenta are transformed. It often happens that after
integration over conjugate momenta, familiar scale factors for the coordinates appear.

534
THERMAL PHYSICS
Symplectic matrices form a group. Since det M = ±1, the inverse matrix M−1 exists.
Multiplication of Eq. (E.27) from the right by M−1 and from the left by ˜M−1 gives
S = ˜M−1SM−1 = 
(M−1)SM−1,
(E.33)
so M−1 is also symplectic. Furthermore, if M and W are symplectic, their product A = MW
is symplectic because
˜ASA = ˜W ˜MSMW = ˜WSW = S,
(E.34)
which establishes the group property. Multiplication pertains to successive canonical
transformations, which generate yet another canonical transformation.
E.2 Restricted Canonical Transformations
An important special case is a restricted canonical transformation in which the transfor-
mation from q, p to Q, P does not involve the time explicitly, namely,
qi = qi(Q, P);
pi = pi(Q, P).
(E.35)
Under these circumstances, the terms containing ∂qi/∂t on the right-hand side of
Eq. (E.12) will vanish and it will be possible to choose the function F to have no explicit
dependence on time, that is, F = F(Q, P). In that case, one can obtain a canonical
transformation in which
H(q, p, t) = K(Q, P, t),
(E.36)
so the new Hamiltonian can be obtained by substituting q(Q, P) and p(Q, P) in the original
Hamiltonian.
Of course the transformation will only be canonical if the conditions given by Eq. (E.17)
or, alternatively, Eq. (E.18) apply. For this restricted situation, however, we can follow
Goldstein [97, p. 391] to derive a simpler set of conditions that will guarantee that the
transformation will be canonical. Thus
∂K
∂Pi
=

k
 ∂H
∂qk
∂qk
∂Pi
+ ∂H
∂pk
∂pk
∂Pi

(E.37)
and
˙Qi =

k
∂Qi
∂qk
˙qk + ∂Qi
∂pk
˙pk

=

k

−∂H
∂qk
∂Qi
∂pk
+ ∂H
∂pk
∂Qi
∂qk

.
(E.38)
For the transformation to be canonical, we need ∂K/∂Pi = ˙Qi and for this to be true for
any function H(q, p, t), we see from comparison of Eq. (E.37) with Eq. (E.38) that
∂qk
∂Pi
= −∂Qi
∂pk
;
∂pk
∂Pi
= ∂Qi
∂qk
.
(E.39)

Appendix E • Aspects of Canonical Transformations
535
Similarly
∂K
∂Qi
=

k
 ∂H
∂qk
∂qk
∂Qi
+ ∂H
∂pk
∂pk
∂Qi

(E.40)
and
−˙Pi = −

k
 ∂Pi
∂qk
˙qk + ∂Pi
∂pk
˙pk

=

k
 ∂H
∂qk
∂Pi
∂pk
−∂H
∂pk
∂Pi
∂qk

.
(E.41)
So requiring ∂K/∂Qi = −˙Pi leads to
∂qk
∂Qi
= ∂Pi
∂pk
;
∂pk
∂Qi
= −∂Pi
∂qk
.
(E.42)
In Eqs. (E.39) and (E.42) it is important to bear in mind that the variable set for each of
these partial derivatives is either q, p or Q, P. Thus, in a somewhat expanded notation,
∂pk
∂Pi
≡
∂pk
∂Pi

Q
;
whereas
∂Pi
∂pk
≡
 ∂Pi
∂pk

q
,
(E.43)
so ∂pk/∂Pi is not the reciprocal of ∂Pi/∂pk.
By using Eqs. (E.39) and (E.42) it is easy to see that the general conditions for a
canonical transformation are satisﬁed. For example, for [Pk, Pj]qp we have

i
 ∂qi
∂Pk
∂pi
∂Pj
−∂qi
∂Pj
∂pi
∂Pk

=

i
 ∂qi
∂Pk
∂Qj
∂qi
+ ∂Qj
∂pk
∂pi
∂Pk

= ∂Qj
∂Pk
= 0,
(E.44)
where Eq. (E.39) has been used. Similarly, for [Qk, Pj]qp,

i
 ∂qi
∂Qk
∂pi
∂Pj
−∂qi
∂Pj
∂pi
∂Qk

=

i
 ∂qi
∂Qk
∂Qj
∂qi
+ ∂Qj
∂pi
∂pi
∂Qk

= ∂Qj
∂Qk
= δjk.
(E.45)
And ﬁnally for [Qk, Qj]qp,

i
 ∂qi
∂Qk
∂pi
∂Qj
−∂qi
∂Qj
∂pi
∂Qk

=

i
∂Pk
∂pi
∂pi
∂Qj
+ ∂qi
∂Qj
∂Pk
∂Qi

= ∂Pk
∂Qj
= 0.
(E.46)

This page intentionally left blank 

F
Rotation of Rigid Bodies
There is no such thing as a rigid body but under many circumstances, solid bodies can
often be treated to a good approximation as if they were rigid. Moreover, molecules can be
approximated by rigid bodies composed of point masses provided that vibrational modes
are not excited. We therefore summarize some useful properties of such bodies.
The formulae below pertain to bodies whose center of mass is at rest. We know that the
total kinetic energy of a body is the sum of the kinetic energy of the center of mass and the
kinetic energy with respect to the center of mass. Similarly, the total angular momentum
is the sum of the angular momentum with respect to the center of mass plus the angular
momentum of the center of mass with respect to the origin of coordinates. For this and
other reasons that afford simpliﬁcation, we treat only bodies whose centers of mass are
at rest.
We denote the coordinate of a point of such a body by the vector r. We shall write a
number of formulae for the continuum case for which mass is distributed according to a
density ρ(r). To obtain formulae for the case of discrete masses, one only needs to write
the density as a sum of delta functions, for example, ρ(r) = 
i miδ(r −ri) in which case
the integrals are replaced by sums.1
F.1 Moment of Inertia
The moment of inertia of a body with respect to some axis passing through its center of
mass is deﬁned by the formula
I :=

ρ(r) r2
⊥dV ,
(F.1)
where the integral is over the volume of the body and r⊥is the distance to a point in the
body measured perpendicular to the speciﬁed axis. We can specify the axis by supposing
it to lie along a unit vector ˆa in which case r2
⊥= |ˆa × r|2 = r2 −(r · ˆa)2. Thus Eq. (F.1) can
be written more explicitly as
I(ˆa) =

ρ(r) (r2 −(r · ˆa)2) dV = I(−ˆa) =

α,β
ˆaαIαβ ˆaβ,
(F.2)
1The notation ρ(r) is applicable if the body is at rest. In Section F.1 we discuss some cases of rotating bodies.
This is handled by treating discrete masses located at positions ri(t) that depend on time. In that case we should
write ρ(r(t)) but we will suppress the dependence on t for simplicity. In Section F.5 we use a rotating coordinate
system r′ in which the body is at rest, so in that case we write ρ(r′).
537

538
THERMAL PHYSICS
where α and β denote Cartesian coordinates and the symmetric moment of inertia tensor
Iαβ :=

ρ(r) (r2δαβ −xαxβ) dV .
(F.3)
For the case of a rigid body made up of discrete masses mi located at positions ri, as
mentioned previously, Eq. (F.3) becomes2
Iαβ :=

i
mi (r2
i δαβ −xiαxiβ).
(F.4)
In dyadic notation, this tensor could be written
I =

i
mi [r2
i 1 −riri],
(F.5)
where 1 corresponds to the unit tensor.
From its deﬁnition, it is clear that the actual components of Iαβ will depend on the
orientation of the body with respect to the chosen axes. If the body is at rest with respect to
these axes, these components will be constants. We observe that Iαβ = Iβα so this tensor
can be diagonalized by means of a choice of axes, rotated with respect to some original
choice of axes. Such a transformation can be accomplished by means of an orthogonal
transformation. It is worth noting, however, that the quantity I(ˆa) with respect to any ﬁxed
axis ˆa is unchanged if the body is rotated about that axis because it only depends on r⊥.
If the rigid body is in motion with respect to the axes of the chosen reference frame, the
components of the tensor Iαβ will generally depend on time. For reasons just mentioned,
however, the value of I(ˆa) will not depend on time as the body rotates about any ﬁxed axis.
This provides some simpliﬁcation of some of the formulae given below but also leads to
some complications in formulae in which time derivatives of Iαβ occur. In such cases, one
must either evaluate such time derivatives explicitly or employ a reformulation in which
two coordinate systems are used, one at rest with respect to the body and in which the
components of Iαβ will be constants, and another with respect to which the body can
rotate.
F.1.1 Diatomic Molecule
The moment of inertia tensor for a diatomic molecule consisting of two point particles
can be calculated from Eq. (F.3) by replacing the density by a sum of two delta functions,
ρ(r) = m1δ(r −r1) + m2δ(r −r2),
(F.6)
where one particle of mass m1 is located at r1 and the other particle of mass m2 is located
at r2. Thus
2If an origin other than the center of mass is used, it is apparent from Eq. (F.4) that one must add to Iαβ the
quantity M(R2δαβ −RαRβ), where M is the total mass and R is the vector from the new origin to the center of mass.
Cross terms vanish because of the deﬁnition of the center of mass. This tensor would contribute an additional
term M|ˆa × R|2 to I(ˆa).

Appendix F • Rotation of Rigid Bodies
539
Iαβ = m1

r2
1δαβ −x1αx1β

+ m2

r2
2δαβ −x2αx2β

.
(F.7)
We recall that the origin is to be located at the center of mass and proceed to calculate Iαβ
in a principal axis system x, y, z in which the coordinates of the particles are x1 = x2 =
y1 = y2 = 0, and
z1 =
m2
m1 + m2
ℓ0;
z2 = −
m1
m1 + m2
ℓ0,
(F.8)
where ℓ0 = |z1 −z2| is the distance of separation between particles. In this coordinate
system, r1 = z1 and r2 = z2 so we see immediately that Izz = 0 and
Ixx = Iyy = m1z2
1 + m2z2
2 =
ℓ2
0
(m1 + m2)2 (m1m2
2 + m2m2
1) = ℓ2
0
m1m2
m1 + m2
.
(F.9)
The quantity multiplying ℓ2
0 is known as the reduced mass, familiar from mechanics.
If the particles were not point particles, but spheres of radii a1 and a2 respectively, there
would be a small value of Izz = (2/5)(m1a2
1 + m2a2
2) and each of Ixx and Iyy would be
increased by this same amount. Since most of the mass of an atom resides in its nucleus,
say of radius r0, the ratio Izz/Ixx will be of the order of magnitude of (r0/ℓ0)2 ∼10−8. See
Section F.8 for a related discussion.
F.2 Angular Momentum
The angular momentum with respect to the center of mass is deﬁned by
L :=

ρ(r) r × v dV ,
(F.10)
where v is the velocity of the body at the point r. The quantity
ˆa · L =

ρ(r) ˆa · r × v dV =

ρ(r) ˆa × r · v dV =

ρ(r) r × v · ˆa dV = L · ˆa
(F.11)
is the angular momentum with respect to the axis ˆa. This follows because ˆa × r has
magnitude r⊥and a direction perpendicular to the plane made by ˆa and r. Its dot product
with v selects the component of v perpendicular to this plane in a direction related to the
ˆa axis in accordance with the right-hand rule.
We deﬁne a vector ω := ˆaω, where ω is an angular velocity. Then for rotation of a rigid
body about an axis ˆa, in the sense of the right-hand rule, we can write v = ω × r in which
case r × v = r × (ω × r) = [r2ω −(r · ω)r] = [r21 −rr] · ω, where 1 is the unit dyadic and rr
is a tensor product (dyadic). Substitution into Eq. (F.10) gives
L = I · ω,
(F.12)
where I is the moment of inertia tensor with components given by Eq. (F.3). We also
observe that ˆa · L = ˆa · I · ω = ˆa · I · ˆa ω = I(ˆa)ω.

540
THERMAL PHYSICS
F.3 Kinetic Energy
The kinetic energy with respect to the center of mass is3
T = 1
2

ρ(r) v · v dV .
(F.13)
For rigid rotation, v · v = (ω × r) · (ω × r) = ω · [r21 −rr] · ω, so
T = 1
2 ω · I · ω = 1
2 ω · L = 1
2 I(ˆa) ω2.
(F.14)
If we use a coordinate system in which I is momentarily diagonal, we would have4
T = 1
2

Ixx ω2
x + Iyy ω2
y + Izz ω2
z

(F.15)
and Eq. (F.12) becomes
Lx = Ixx ωx;
Ly = Iyy ωy;
Lz = Izz ωz.
(F.16)
Then Eq. (F.15) can be written in the form
T =
L2
x
2Ixx
+
L2
y
2Iyy
+ L2
z
2Izz
.
(F.17)
F.4 Time Derivatives
As remarked toward the end of Section F.1, the components of Iαβ will depend on time if
a body is rotating with respect to the coordinates of the reference frame. We ﬁrst calculate
the time derivative of Eq. (F.5) at a moment when the body is rotating with angular velocity
ω with respect to that reference frame. A vector ri(t) that locates point i of the body will
have a velocity vi = ω × ri in that frame. Thus dr2
i /dt = 2vi · ri = 0. On the other hand, the
time derivative of the dyadic riri is
d
dt (riri) = viri + rivi = (ω × ri)ri −ri(ri × ω) = ω × riri −riri × ω,
(F.18)
where the parentheses can be omitted without ambiguity. Substituting these results into
the time derivative of Eq. (F.5) gives
d
dt I = −

i
mi[ω × riri −riri × ω].
(F.19)
It also turns out that ω × 1 = 1 × ω, which can be shown by straightforward algebra by
writing 1 = ˆiˆi+ˆjˆj+ ˆkˆk in terms of the unit vectors of a Cartesian coordinate system. Hence
Eq. (F.19) can be written in the form
dI
dt = ω × I −I × ω.
(F.20)
3In Chapter 1 we called this quantity Ti to distinguish it from the total kinetic energy.
4If the axis of rotation remains ﬁxed, I(ˆa) would not change with time, as shown by Eq. (F.21).

Appendix F • Rotation of Rigid Bodies
541
For ω along a ﬁxed axis ˆa, we see from Eq. (F.2) that
d
dt I(ˆa) = ˆa · dI
dt · ˆa = ˆa · (ω × I −I × ω) · ˆa = 0
(F.21)
because we can interchange the dot and the cross on either side of I and the cross product
of ˆa with ω vanishes. This further supports our statement at the end of Section F.1 that I(ˆa)
is independent of time even for a body that rotates about a ﬁxed axis ˆa.
On the other hand, from Eq. (F.12) we see that
dL
dt = I · dω
dt + dI
dt · ω = I · dω
dt + ω × I · ω
(F.22)
or ﬁnally
dL
dt = I · dω
dt + ω × L.
(F.23)
The “extra” term ω ×L comes from the dependence of I on time when calculated in a ﬁxed
frame in which the body is rotating.
Turning to the kinetic energy given by Eq. (F.14) we see that
dT
dt = 1
2
dω
dt · I · ω + 1
2 ω · I · dω
dt + 1
2 ω · dI
dt · ω.
(F.24)
The last term vanishes after substitution of Eq. (F.20) and the other two combine to give
dT
dt = ω · I · dω
dt = L ·dω
dt ,
(F.25)
from which we see that the dependence of I on time does not result in an additional term.
We now return to Eq. (F.23) and recognize that the left-hand side is equal to the torque
N that may be applied to the body. If this torque vanishes, L is just a constant, and angular
momentum is conserved. If it does not, we can take the dot product with ω to obtain
ω · N = ω · I · dω
dt = dT
dt
(F.26)
from which we recognize that the left-hand side is the power supplied by the torque, which
is equal to the time rate of change of the kinetic energy. If the torque vanishes, the kinetic
energy is constant, as expected.
F.5 Rotating Coordinate System
Some of the complications of Section F.4 can be avoided by using two coordinate systems,
the unprimed system with coordinates x, y, z as dealt with above, which we here take to
be an inertial frame, and a primed system with coordinates x′, y′, z′ having the same origin
and coordinate axes imbedded in the rigid body. The axes of the primed system rotate
with the body. A point i in the body can be described by either a vector ri = xiˆi + yiˆj + zi ˆk
or a vector r′
i = x′
iˆi′ + y′
i ˆj′ + z′
i ˆk′, and since it is the same point, we have ri = r′
i. As the
body rotates, the coordinates xi, yi, zi change with time but the unit vectors ˆi, ˆj, ˆk remain

542
THERMAL PHYSICS
constant in time; on the other hand, the coordinates x′
i, y′
i, z′
i remain constant in time but
the unit vectors ˆi′, ˆj′, ˆk′ rotate with time.
It follows that the moment of inertia tensor, evaluated with respect to the primed
system, will have components that are independent of time, although the dyadic that
represents the tensor will depend on time through the unit vectors ˆi′, ˆj′, ˆk′. In particular,
one could choose the orientation of the primed axes with respect to the body, once and for
all, such that the moment of inertia tensor is diagonal, with diagonal elements I1 = Ix′x′,
I2 = Iy′y′, and I3 = Iz′z′ and with off diagonal elements Ix′y′ = Iy′z′ = Iz′x′ = 0. In such a
representation, the moment of inertia dyadic would be
I′ =

i
mi [r′2
i 1 −r′
ir′
i] = ˆi′I1ˆi′ + ˆj′I2ˆj′ + ˆk′I3 ˆk′.
(F.27)
In this notation, the prime on I′ is only a reminder that it is the moment of inertia dyadic
expressed in terms of the unit vectors ˆi′, ˆj′, ˆk′ rather than the unit vectors ˆi, ˆj, ˆk that are
independent of time. In fact, ironically, I = I′, just as ri = r′
i, but the tensor components of
these dyadics are different, those for I′ being independent of time.
Similarly, the angular momentum can be represented by L = Lxˆi + Lyˆj + Lz ˆk or
alternatively L′ = Lx′ˆi′ + Ly′ˆj′ + Lz′ ˆk′, with L = L′. Since L = I · ω we also have
L′ = I′ · ω′ = I1ωx′ˆi′ + I2ωy′ˆj′ + I3ωz′ ˆk′,
(F.28)
where ω = ωxˆi + ωyˆj + ωz ˆk or alternatively ω′ = ωx′ˆi′ + ωy′ˆj′ + ωz′ ˆk′, with ω = ω′.
F.5.1 Time Derivatives Revisited
We ﬁrst consider a general vector G = Gxˆi + Gyˆj + Gz ˆk or alternatively G′ = Gx′ˆi′ + Gy′ˆj′ +
Gz′ ˆk′, with G = G′, and where Gx′, Gy′, and Gz′ are not necessarily independent of time. Its
time derivative is
dG
dt = dGx
dt
ˆi + dGy
dt
ˆj + dGz
dt
ˆk
= dG′
x
dt
ˆi′ +
dG′
y
dt
ˆj′ + dG′
z
dt
ˆk′ + Gx′ dˆi′
dt + Gy′ dˆj′
dt + Gz′ dˆk′
dt = dG′
dt .
(F.29)
But dˆi′/dt = ω × ˆi′ and similarly for dˆj′/dt and dˆk′/dt, so
dG
dt = dG′
x
dt
ˆi′ +
dG′
y
dt
ˆj′ + dG′
z
dt
ˆk′ + ω × G′.
(F.30)
Equation (F.30) can be written in the form
	dG
dt

ﬁxed
=
	dG′
dt

rotating
+ ω × G′,
(F.31)
but this notation can be easily misinterpreted because in

dG′/dt

rotating one only differ-
entiates the components of G′, not the unit vectors. Another word of caution concerns the
interpretation of the expressions

Appendix F • Rotation of Rigid Bodies
543
ω × G = ω × G′ = ω′ × G = ω′ × G′.
(F.32)
The ﬁrst and the last are easy to evaluate in terms of the usual rule for cross products
and result in expressions in terms of unprimed and primed unit vectors, respectively; the
middle two are hybrid expressions and one of their members must be resolved along the
coordinates of the other in order to compute the cross product. For instance, the use of ω′×
G′ in Eq. (F.30) would lead directly to an expression for dG/dt resolved along the primed
vectors.
For the special case of G = r = r′, we recall that the components of r′ are constant in
the rotating frame, so
dr
dt = ω × r = ω′ × r′ = dr′
dt .
(F.33)
For the case of the angular momentum L, we see from Eq. (F.28) that
dL
dt = I1
dωx′
dt
ˆi′ + I2
dωy′
dt
ˆj′ + I3
dωz′
dt
ˆk′ + ω′ × L′
(F.34)
which should be compared to Eq. (F.23). On the right-hand side of Eq. (F.34), dL/dt =
dL′/dt is resolved along the components of the primed basis vectors that depend on time,
but the components I1, I2, and I3 are independent of time. Since the torque N = dL/dt,
the components of torque in the primed system are
N1 = I1 ˙ω1 + ω2ω3(I3 −I2);
N2 = I2 ˙ω2 + ω3ω1(I1 −I3);
N3 = I3 ˙ω3 + ω1ω2(I2 −I1),
(F.35)
where x′, y′, z′ →1, 2, 3 and ˙ω1 = dω1/dt, etc. Equations (F.35) are known as the Euler
equations of motion of a rigid body. The power delivered by the torque is then
ω′ · N′ = I1ω1 ˙ω1 + I2ω2 ˙ω2 + I3ω3 ˙ω3 = dT′
dt
(F.36)
which should be compared to Eq. (F.26) with
T′ = 1
2(I1ω2
1 + I2ω2
2 + I3ω2
3) = T.
(F.37)
In the unprimed frame, T is given by Eq. (F.14). The advantage of Eq. (F.37) is that the
components I1, I2 and I3 are independent of time.
By using the same reasoning that led to Eq. (F.30), we can deduce that
dI′
dt = ω′ × I′ −I′ × ω′
(F.38)
which, of course, has the same form as Eq. (F.20) and holds whether or not the principal
axes are used in the rotating frame. Thus,
dL′
dt = d
dt (I′ · ω′) = I′ · ˙ω′ + dI′
dt · ω′ = I′ · ˙ω′ + ω′ × I′ · ω′
(F.39)
which agrees with Eq. (F.34) if principal axes are used. Similarly,

544
THERMAL PHYSICS
dT′
dt = 1
2
d
dt (ω′ · I′ · ω′) = ω′ · I′ · ˙ω′
(F.40)
which agrees with Eq. (F.36) if principal axes are used.
F.6 Matrix Formulation
Our principal interest as far as classical statistical mechanics is concerned is to express
the Hamiltonian in terms of canonical coordinates and momenta. Since the energy is
provided by Eq. (F.37), it remains to express ω′ in terms of the transformation from the ﬁxed
to the rotating coordinate system. This can be done by writing the transformation in the
matrix form
x′ = Ax
(F.41)
with inverse
x = ATx′,
(F.42)
where x and x′ are column vectors. A is an orthogonal matrix that depends on time and
AT is its transpose, which is also its inverse. Following the notation and convention of
Goldstein [60, p. 107], we can write A in terms of the Euler angles φ, θ, and ψ as a product
of three successive rotations in the form
A = BCD,
(F.43)
where
D =
⎛
⎝
cos φ
sin φ 0
−sin φ cos φ 0
0
0
1
⎞
⎠;
C =
⎛
⎝
1
0
0
0
cos θ
sin θ
0 −sin θ cos θ
⎞
⎠;
B =
⎛
⎝
cos ψ
sin ψ 0
−sin ψ cos ψ 0
0
0
1
⎞
⎠.
(F.44)
When the matrix A multiplies the column vector x, matrix D causes a rotation by φ around
the z-axis; then C causes a rotation by θ about the rotated x-axis, resulting in the rotated z-
axis becoming the z′-axis; and ﬁnally B causes a rotation by ψ about the z′-axis to establish
the x′- and y′-axes. See Figures 4-6 of Goldstein [60].
Since the coordinates x′ are independent of time, differentiation of Eq. (F.42) with
respect to time gives
˙x = ˙ATx′ = ˙ATAx.
(F.45)
Since ATA = E, where E is the unit matrix whose time derivative is zero, we have
˙ATA = −AT ˙A = −(˙ATA)T,
(F.46)
so ˙ATA is an antisymmetric matrix that we can write in the form
˙ATA ≡ω =
⎛
⎝
0
ωxy
ωxz
−ωxy
0
ωyz
−ωxz −ωyz
0
⎞
⎠=
⎛
⎝
0
−ωz
ωy
ωz
0
−ωx
−ωy
ωx
0
⎞
⎠,
(F.47)
where ωx, ωy and ωz are components of a pseudovector ω. With this notation, we note that
Eq. (F.45) is the matrix representation of v = ω × r. Furthermore,

Appendix F • Rotation of Rigid Bodies
545
v2 = v · v = ˙xT ˙x = xTAT ˙A˙ATAx = xTωTωx.
(F.48)
Matrix multiplication shows readily that ωTω is a symmetric matrix with components
(ωTω)αβ = δαβ −ωαωβ,
(F.49)
where δαβ is the Kronecker delta (elements of the unit matrix). Inserting this result in
Eq. (F.48) with x now corresponding to the ith point of a rigid body, multiplying by the
mass mi and a factor of 1/2 and summing over all points of the body, one obtains the
kinetic energy
T = 1
2

μν
ωμIμνων
(F.50)
which is equivalent to Eq. (F.14).
A similar equation can be obtained in terms of the primed coordinates by returning to
Eq. (F.45) to obtain v2 = x′Tω′Tω′x′, where the antisymmetric matrix
A˙AT ≡ω′ =
⎛
⎝
0
−ωz′
ωy′
ωz′
0
−ωx′
−ωy′
ωx′
0
⎞
⎠.
(F.51)
Here, ωx′, ωy′, and ωz′ are to be regarded as the components of a pseudovector ω′. Then by
the same reasoning as in the unprimed case,
T = 1
2

μ′ν′
ωμ′Iμ′ν′ων′,
(F.52)
where the components of the moment of inertia tensor Iμ′ν′ are evaluated in the primed
frame, which rotates with the rigid body, and are therefore independent of time. If the axes
in the primed frame are chosen as principal axes of the body, then
T = 1
2(I1ω2
1 + I2ω2
2 + I3ω2
3)
(F.53)
as in Eq. (F.37).
The transformation from the matrix ω to the matrix ω′ is a similarity transformation
because
ω′ = A˙AT = A˙ATAAT = AωAT.
(F.54)
By expressing the antisymmetric matrices ω and ω′ in terms of the Levi-Cavita symbols
ϵαβγ , a rather lengthy calculation shows that
ω′
α = detA

λ
Aαλωλ
(F.55)
which deﬁnes the transformation of a pseudovector. For the matrix A given by Eq. (F.43),
det A = 1 so ω transforms as a vector.
It remains to express the components of ω and ω′ in terms of the Euler angles and their
time derivatives. This can be done in a straightforward way by appealing to the matrix
formulation just described. Thus we have

546
THERMAL PHYSICS
ω = ˙ATA = ( ˙DTCTBT + DT ˙CTBT + DTCT ˙BT)BCD
(F.56)
and
ω′ = A˙AT = BCD( ˙DTCTBT + DT ˙CTBT + DTCT ˙BT).
(F.57)
After an exercise in matrix algebra, we deduce
ωx = sin θ sin φ ˙ψ + cos φ ˙θ;
ωy = −sin θ cos φ ˙ψ + sin φ ˙θ;
ωz = cos θ ˙ψ + ˙φ
(F.58)
and
ωx′ = sin θ sin ψ ˙φ + cos ψ ˙θ;
ωy′ = sin θ cos ψ ˙φ −sin ψ ˙θ;
ωz′ = cos θ ˙φ + ˙ψ.
(F.59)
The results in the current section are used in Section 20.7 to calculate the classical
partition functions of polyatomic molecules.
F.7 Canonical Variables
For a free rotator, we are now in the position to write the Hamiltonian in the form
H = 1
2(I1ω2
1 + I2ω2
2 + I3ω2
3),
(F.60)
where ω1 ≡ωx′, ω2 ≡ωy′, ω3 ≡ωz′ are given by Eq. (F.59) with x′, y′, z′ understood
to correspond to the principal axes in the rotating frame of reference. The canoni-
cal momenta pφ, pθ, pψ conjugate to the three Euler angles φ, θ, ψ may be found by
differentiation5:
pφ = ∂H
∂˙φ = I1ω1 sin θ sin ψ + I2ω2 sin θ cos ψ + I3ω3 cos θ
= L1 sin θ sin ψ + L2 sin θ cos ψ + L3 cos θ.
(F.61)
Here, L1, L2, L3 are the principal angular momenta, which are components of the vector L′
given by Eq. (F.28). Similarly,
pθ = ∂H
∂˙θ = I1ω1 cos ψ −I2ω2 = L1 cos ψ −L2 sin ψ
(F.62)
and
pψ = ∂H
∂˙ψ = I3ω3 = L3.
(F.63)
In terms of the principal angular momenta, the Hamiltonian may be written
H = L2
1
2I1
+ L2
2
2I2
+ L2
3
2I3
.
(F.64)
5Since we are only dealing with the kinetic energy, H = L, where L is the Lagrangian.

Appendix F • Rotation of Rigid Bodies
547
F.8 Quantum Energy Levels for Diatomic Molecule
The quantum energy levels associated with a Hamiltonian of the form of Eq. (F.64) are
rather tricky to calculate because the angular momenta L1 and L2 relate to a rotating
coordinate system and because the vanishing of I3 is only an approximation based on the
assumption that each atom can be considered to be a point particle. To better understand
this problem, we examine the more general case in which the kinetic energy is given by
Eq. (F.64) with I1 = I2 ≡I and I3 ≪I but I3 ̸= 0. This is the problem of a symmetrical
top and is treated by Landau and Lifshitz [66, p. 383]. The Hamiltonian is
H = L2
1 + L2
2
2I
+ L2
3
2I3
= L2
2I + L2
3
2
	 1
I3
−1
I

,
(F.65)
where L2 = L2
1 + L2
2 + L2
3. They proceed to show that the commutation relations among the
Li are the same as for a non-rotating coordinate system except for complex conjugation,
which has no effect on the energy eigenvalues. Thus the eigenvalues of L2 are ¯h2j(j+1) and
those of L2
3 are ¯h2k2, where k = −j, . . . , −1, 0, 1, . . . , j. The energy eigenvalues are therefore
εjk = ¯h2
2I j(j + 1) + ¯h2
2
	 1
I3
−1
I

k2.
(F.66)
Since ±k lead to the same energy, all levels except for k = 0 are at least two-fold degenerate.
But for I3 ≈0, all levels except for k = 0 are extremely large! They are so large, in fact, that
they are not excited at any reasonable temperature before the molecule dissociates. So one
ordinarily just ignores these levels and deals only with
εj0 = ¯h2
2I j(j + 1),
(F.67)
which is the result quoted in the text, Eqs. (18.82) and (21.150). Moreover, with only k = 0,
these levels would appear to be non-degenerate. But here, the rotating coordinate system
comes into play. It introduces a degeneracy of 2j + 1 associated with the orientation of
these angular momenta with respect to a ﬁxed coordinate system [66, footnote on p. 384].
This is, ﬁnally, in agreement with the results quoted in the text and often related to a strictly
two-dimensional analysis.

This page intentionally left blank 

G
Thermodynamic Perturbation
Theory
For most problems in statistical mechanics, an exact analytical solution is impossible to
obtain, so we need methods to obtain approximate solutions. Fortunately, there are many
problems of interest in which the Hamiltonian can be expressed in the form
H = H0 + V
(G.1)
in which an exact solution is known for the unperturbed Hamiltonian H0 and where V is a
small correction, in a sense to be clariﬁed below. Under these circumstances, it is possible
to obtain an approximate solution in terms of averages of powers of V with respect to a
Boltzmann distribution for the unperturbed Hamiltonian.
This technique is called thermodynamic perturbation theory, which is a mixture
of perturbation theory and thermodynamic ensemble averaging. In this appendix, we
discuss this topic in the context of the canonical ensemble. We ﬁrst take up the classical
case and then the quantum case, which requires slightly different considerations. We
follow closely a treatment by Landau and Lifshitz [7, p. 93].
G.1 Classical Case
We write
H(p, q) = H0(p, q) + V (p, q)
(G.2)
and express the classical1 canonical partition function in the form
ZC(β) =

e−βH(p,q) dω =

e−β[H0(p,q)+V(p,q)] dω,
(G.3)
where p and q are each 3N-dimensional vectors and dω represents the volume element in
this 6N-dimensional phase space. We then expand the second exponential in powers of V
to second order to obtain
ZC(β) =

e−βH0(p,q)

1 −βV (p, q) + (βV (p, q))2
2

dω.
(G.4)
1To agree with quantum mechanics, we need to divide ZC by h3N for N particles or by h3N N ! for identical
indistinguishable particles, as in the case of a dilute ideal gas. Here we omit those factors for simplicity.
549

550
THERMAL PHYSICS
We deﬁne an averaging process of any quantity B(p, q) with respect to the unperturbed
distribution as follows:
⟨B⟩0 :=

e−βH0(p,q)B(p, q) dω

e−βH0(p,q) dω
.
(G.5)
Then Eq. (G.4) takes the form
ZC(β) = Z0(β)

1 −β⟨V ⟩0 + (1/2) β2⟨V 2⟩0

,
(G.6)
where the unperturbed partition function
Z0(β) :=

e−βH0(p,q) dω.
(G.7)
We now use the formula for the Helmholtz free energy F = −kBT ln ZC to obtain, again to
second order in V,
F = F0 −kBT ln

1 −β⟨V ⟩0 + (1/2) β2⟨V 2⟩0

= F0 + ⟨V ⟩0 −(1/2) β⟨V 2⟩0 + (1/2) β2⟨V ⟩2
0,
(G.8)
where F0 = −kBT ln Z0 is the unperturbed Helmholtz free energy. This result can be
written in the form
F = F0 + ⟨V ⟩0 −⟨(V −⟨V ⟩0)2⟩0
2kBT
.
(G.9)
Equation (G.9) shows that the free energy is ﬁrst changed by the average value of V and
then diminished by a second-order term proportional to the variance of V. Both the mean
and the variance are proportional to N, so the condition for the validity of the expansion
is that V per particle be small compared to kBT.
G.2 Quantum Case
According to second-order perturbation theory, the eigenvalues of the Hamiltonian in
Eq. (G.1) are
En = E0
n + Vnn +

m̸=n
|Vnm|2
E0n −E0m
,
(G.10)
where n stands for a set of quantum numbers that label the unperturbed states of the
system, E0
n are the unperturbed energies and Vnm ≡⟨n|V|m⟩are matrix elements of V
with respect to the unperturbed states. We expand the partition function
Z(β) =

n
e−βEn =

n
e−βE0
n
⎡
⎣1 −βVnn −β

m̸=n
|Vnm|2
E0n −E0m
+ (1/2)β2V 2
nn
⎤
⎦
(G.11)
to second order in V and deﬁne a quantum averaging process
⟨Tn⟩0 :=

n e−βE0
nTn

n e−βE0n
.
(G.12)

Appendix G • Thermodynamic Perturbation Theory
551
Then the partition function becomes
Z(β) = Z0(β)
⎡
⎣1 −β⟨Vnn⟩0 −β
 
m̸=n
|Vnm|2
E0n −E0m
+ (1/2)β2V 2
nn

0
⎤
⎦,
(G.13)
where
Z0(β) =

n
e−βE0
n.
(G.14)
The Helmholtz free energy then becomes
F = F0 + ⟨Vnn⟩0 +
 
m̸=n
|Vnm|2
E0n −E0m

0
−(1/2)β⟨V 2
nn⟩0 + (1/2)β⟨Vnn⟩2
0,
(G.15)
where F0 = −kBT ln Z0. This last result can be rewritten in the form
F = F0 + ⟨Vnn⟩0 +
 
m̸=n
|Vnm|2
E0n −E0m

0
−⟨(Vnn −⟨Vnn⟩0)2⟩0
2kBT
(G.16)
which has an extra term compared to its classical equivalent Eq. (G.9). This extra term can
be written in the form2
 
m̸=n
|Vnm|2
E0n −E0m

0
= 1
Z0

n

m̸=n
|Vnm|2
E0n −E0m
e−βE0
n = 1
Z0

m

n̸=m
|Vnm|2
E0m −E0n
e−βE0
m
= −1
2Z0

n

m̸=n
|Vnm|2
E0n −E0m

e−βE0
m −e−βE0
n

.
(G.17)
Since e−βE0m −e−βE0n and E0
n −E0
m have the same sign, this extra term is negative, so both
second order terms in Eq. (G.16) are negative.
If the unperturbed energy splittings E0
n −E0
m happen to be small compared to kBT, we
can further simplify Eq. (G.17) by expanding the exponentials. In that case
−1
2

n

m̸=n
|Vnm|2
E0n −E0m

e−βE0
m −e−βE0
n

= −1
2

n

m̸=n
|Vnm|2
E0n −E0m
e−βE0
n

e−β(E0
m−E0
n) −1

≈−1
2kT

n

m̸=n
|Vnm|2e−βE0
n.
(G.18)
Then Eq. (G.16) becomes
F = F0 + ⟨Vnn⟩0 −
1
2kT
⎡
⎣
 
m̸=n
|Vnm|2 + (Vnn −⟨Vnn⟩0)2

0
⎤
⎦.
(G.19)
2In making this identiﬁcation, note that 
n

m̸=n Amn = 
m

n̸=m Anm = the sum of all off-diagonal
elements of the matrix A.

552
THERMAL PHYSICS
The term in square brackets in Eq. (G.19) can be written
1
Z0

n
e−βE0
n
⎡
⎣
m̸=n
|Vnm|2 + V 2
nn −⟨Vnn⟩2
0
⎤
⎦.
(G.20)
But since V is Hermitian, the rules of matrix multiplication lead to

m̸=n
|Vnm|2 + V 2
nn =

m̸=n
VnmV ∗
nm + V 2
nn =

m̸=n
VnmVmn + V 2
nn =

m
VnmVmn =(V 2)nn.
(G.21)
Thus Eq. (G.20) reduces to
1
Z0

n
e−βE0
n

(V 2)nn −⟨Vnn⟩2
0

= ⟨(V 2)nn⟩0 −⟨Vnn⟩2
0
(G.22)
and Eq. (G.16) takes the form
F = F0 + ⟨Vnn⟩0 −⟨(V −⟨Vnn⟩0)2
nn⟩0
2kBT
(G.23)
which is similar to Eq. (G.9) for the classical case.
Finally, we remark that Eq. (G.23) can be expressed in an invariant form by using
properties of the trace. The unperturbed partition function is
Z0(β) =

n
e−βE0
n = tr e−βH0.
(G.24)
Furthermore, we can introduce the unperturbed density operator
ˆρ0 =
e−βH0
tr e−βH0 .
(G.25)
Then the averaging process expressed by Eq. (G.12) can be written in the form
⟨O⟩0 = tr ( ˆρ0O)
(G.26)
for any operator O. Thus
F = F0 + tr ( ˆρ0V ) −tr

ˆρ0[V −tr ( ˆρ0V )]2
2kBT
.
(G.27)
In this approximate form of Eq. (G.16) it is more obvious that the second-order correction
to F is negative, as in the classical case.

H
Selected Mathematical Relations
In this appendix we develop and summarize selected mathematical relations that are
employed in the text. We concentrate on simplicity of presentation and refer the reader
to the mathematical literature for rigorous proofs. We ﬁrst deﬁne Bernoulli numbers and
Bernoulli polynomials to clarify conventions used in the literature. Then we state the
Euler-Maclaurin sum formula in general terms, specialize it to approximate inﬁnite sums
with integrals, and give examples of its use in computing partition functions.
H.1 Bernoulli Numbers and Polynomials
Bernoulli numbers frequently appear as coefﬁcients in the representation of integrals by
asymptotic series as well as in formulae for the correction terms used to approximate
inﬁnite sums by integrals. Unfortunately there are alternative deﬁnitions and conventions
used to deﬁne Bernoulli numbers and the associated Bernoulli polynomials.
H.1.1 Bernoulli Numbers
An inﬁnite set of numbers known as Bernoulli numbers Bn for n = 1, 2, . . . may be deﬁned
as the expansion coefﬁcients in the series for |z| < 2π of the even function [92, p. 125])
z
2 cot z
2 = 1 −B1
z2
2! −B2
z4
4! −B3
z6
6! −· · ·
= 1 −
∞

n=1
Bn
z2n
(2n)!.
(H.1)
By setting z = t/i, it is easily seen for |t| < 2π that
t
et −1 = −t
2 + t
2i cot t
2i = 1 −t
2 + B1
t2
2! −B2
t4
4! + B3
t6
6! −· · ·
= 1 −t
2 +
∞

n=1
(−1)n+1Bn
t2n
(2n)!,
(H.2)
where the alternations in sign result from i2 = −1. Although it is not obvious from these
series expansions, it turns out that all Bn are positive numbers which can be established
by the integral representations [92, p. 126]1
1Whittaker and Watson [92] leave the last form as an exercise. It can be obtained by substituting x = 2πt and
then x = πt in the ﬁrst integral in Eq. (H.3) to obtain alternative expressions for Bn, solving for (22n −1)Bn and
simplifying the integrand.
553

554
THERMAL PHYSICS
Bn = 4n
 ∞
0
t2n−1
e2πt −1 dt =
2n
π2n(22n −1)
 ∞
0
x2n−1
sinh x dx > 0.
(H.3)
We use these positive Bn in this book, for example, B1 = 1/6, B2 = 1/30, B3 = 1/42, B4 =
1/30, B5 = 5/66, B6 = 691/2730, B7 = 7/6, etc., from which we note that the sequence is
not monotonic.
An alternative set of numbers ˜Bn, also called Bernoulli numbers, can be deﬁned
by [98, p. 804]
t
et −1 =
∞

n=0
˜Bn
tn
n!.
(H.4)
In this case, ˜B0 = 1, ˜B1 = −1
2, ˜B2p+1 = 0, and ˜B2p = (−1)p+1Bp for p ≥1. Another
convention is B∗
n = (−1)n+1Bn.
H.1.2 Bernoulli Polynomials
Bernoulli polynomials φn(z) for n ≥1 can be deﬁned by [92]
t(ezt −1)
et −1
=
∞

n=1
φn(z) tn
(n)!;
|t| < 2π.
(H.5)
Evidently φn(0) = 0 for all n ≥1, φn(1) = 0 for n > 1, but φ1(1) = 1. From the deﬁning
equation one can establish the difference equation
φn(z + 1) −φn(z) = nzn−1;
n ≥1.
(H.6)
Alternative Bernoulli polynomials Bn(z) for n ≥0 can be deﬁned by [98]
tezt
et −1 =
∞

n=1
Bn(z) tn
(n)!;
|t| < 2π.
(H.7)
In this case, B0(z) = 1 and the remaining polynomials can be shown to satisfy φn(z) =
Bn(z) −˜Bn, n ≥1, so there is no difference between these polynomials for odd n > 1.
H.2 Euler-Maclaurin Sum Formula
As shown by Whittaker and Watson [92, p. 128] a very general form of the Euler-Maclaurin
sum formula can be obtained by using Bernoulli polynomials and a formula due to
Darboux. That sum formula is
f (z) −f (a) =1
2(z −a)

f ′(z) + f ′(a)

+
p−1

k=1
(−1)k(z −a)2k Bk
(2k)!

f (2k)(z) −f (2k)(a)

+ (z −a)2p+1
(2p)!
 1
0
φ2p(t)f (2p+1)(a + t(z −a)),
(H.8)

Appendix H • Selected Mathematical Relations
555
where f (z) is analytic on a line from a to z, f ′(z) = df /dz and f (2k)(z) = d2kf /dz2k denotes
higher derivatives of even order. The last term is the remainder of the ﬁnite sum and
involves an integral over a Bernoulli polynomial. Following their procedure, we substitute
F(z) = f ′(z) and w = z −a into Eq. (H.8) to obtain
 a+w
a
F(x) dx =1
2w [F(a + w) + F(a)]
+
p−1

k=1
(−1)kw2k Bk
(2k)!

F(2k−1)(a + w) −F(2k−1)(a)

+ w2p+1
(2p)!
 1
0
φ2p(t)F(2p)(a + tw).
(H.9)
Then by letting a take the values a + w, a + 2w, . . . , a + (r −1)w and adding, we obtain
 a+rw
a
F(x) dx =w
1
2F(a + rw) + F(a + (r −1)w) + · · · + F(a + w) + 1
2F(a)
	
+
p−1

k=1
(−1)kw2k Bk
(2k)!

F(2k−1)(a + rw) −F(2k−1)(a)

+ w2p+1
(2p)!
 1
0
φ2p(t)
r−1

s=0
F(2p)(a + sw + tw).
(H.10)
Equation (H.10) may be used to approximate integrals by sums or vice versa. Under
suitable conditions, the remainder term on the last line vanishes as p →∞and the middle
term becomes an inﬁnite sum:
 a+rw
a
F(x) dx =w
r

ℓ=0
F(a + ℓw) −w
2 [F(a + rw) + F(a)]
+
∞

k=1
(−1)kw2k Bk
(2k)!

F(2k−1)(a + rw) −F(2k−1)(a)

.
(H.11)
If we let a + rw = b, we see that w is obtained by dividing the interval b −a into r equal
parts. For evaluation of sums, an important special case occurs when a and b are integers
and w = 1 which results in
b

ℓ=a
F(ℓ) =
 b
a
F(x)dx + 1
2

F(a) + F(b)

+
∞

k=1
(−1)k Bk
(2k)!

F(2k−1)(a) −F(2k−1)(b)

.
(H.12)
For the frequently occurring case a = 0 and b = ∞when both F and its derivatives vanish
at inﬁnity, we obtain
∞

ℓ=0
F(ℓ) =
 ∞
0
F(x)dx + 1
2F(0) +
∞

k=1
(−1)k Bk
(2k)!F(2k−1)(0).
(H.13)

556
THERMAL PHYSICS
This formula is only justiﬁed if the integral and both series converge. Alternatively, it might
give an asymptotic result in some parameter on which F depends.
H.2.1 Approximate Evaluation of Inﬁnite Sums
In statistical mechanics, especially in calculating partition functions, one frequently needs
to evaluate sums of the form 
∞
n=0 f (n), where f (n) is some function of an integer n.
Sometimes these sums can be done exactly, for example for a geometrical series, but in
many cases they cannot and approximation methods are needed. We demonstrate how
the Euler-Maclaurin sum formula in the form given by Eq. (H.13) can be used for this
purpose. With the change of notation F →f , it becomes explicitly
∞

n=0
f (n) =
 ∞
0
f (n) dn + 1
2f (0) +
∞

j=1
(−1)j Bj
(2j)!f (2j−1)(0)
=
 ∞
0
f (n) dn + 1
2f (0) −1
12f ′(0) +
1
720f ′′′(0) −
1
30240f (5)(0) + · · ·
(H.14)
As noted above, this expansion is only justiﬁed if the series converges. Otherwise, it might
give an asymptotic approximation.
Example Problem H.1. Evaluate approximately the partition function for a rigid rotator
(see Eq. (18.83))
z =
∞

j=0
(2j + 1) exp[−j(j + 1)x],
(H.15)
where x := ε0/kBT, correct to order (ε0/kBT)2 at high temperatures. Then compute the
corresponding heat capacity.
Solution H.1. The lowest order term is given by the integral and is just 1/x = kBT/ε0 (see
Eq. (18.85)). We compute f (0) = 1, f ′(0) = 2 −x, f ′′′(0) = −12x + 12x2 + O(x)3, f (5)(0) =
120x2 + O(x3), f (7)(0) = O(x3). Thus
z = 1
x + 1
3 + x
15 + 4x2
315 + O(x3).
(H.16)
ln z = ln
1
x

1 + x
3 + x2
15 + 4x3
315 + O(x4)
	
= −ln x + x
3 + x2
90 + 8x3
2835 + O(x4).
(H.17)
Therefore,
c = ∂
∂T

−∂ln z
∂β

= kBx2 ∂2 ln z
∂x2
= kB

1 + x2
45 + 16x3
945 + O(x4)

,
(H.18)
which shows clearly that c asymptotes kB from larger values as T →∞, as is evident from
Figure 18–12. Although the trend is clear, the accuracy is poor unless x is very small, so the
series appears to be asymptotic in ε0/kBT as T →∞. It has no hope of representing c near
T = 0 where the leading term is c = x2e−2x as x →∞.

Appendix H • Selected Mathematical Relations
557
In some applications the function f (n) = g(n + α), where 0 ≤α < 1, with α = 1/2 of
special importance. In that case, Eq. (H.14) becomes
∞

n=0
g(n + α) =
 ∞
0
g(n + α) dn + 1
2g(α) +
∞

j=1
Bj
(2j)!g(2j−1)(α)
=
 ∞
0
g(n + α) dn + 1
2g(α) −1
12g′(α) +
1
720g′′′(α) −
1
30240g(5)(α) + · · · .
(H.19)
With the substitution x = n + α, the integral term can be written
 ∞
0
g(n + α) dn =
 ∞
α
g(x) dx =
 ∞
0
g(x) dx −
 α
0
g(x)dx.
(H.20)
In the last integral, we expand g(x) in a series about x = 0 and integrate term by term to
obtain
 α
0
g(x)dx =
 α
0
∞

r=0
g(r)(0)xr
r! =
∞

r=0
g(r)(0) αr+1
(r + 1)!.
(H.21)
We also expand the other terms, g(j)(α), in Eq. (H.19) about α = 0 and combine results to
obtain
∞

n=0
g(n + α) =
 ∞
0
g(x)dx +
1
2 −α

g(0) +

−1
12 + α
2 −α2
2

g′(0)
+

−α
12 + α2
4 −α3
6

g′′(0) +
 1
720 −α2
24 + α3
12 −α4
24

g′′′(0) + · · · .
(H.22)
In the special case α
=
1/2, the coefﬁcients of g(0) and g′′(0) vanish and we are
left with
∞

n=0
g(n + 1
2) =
 ∞
0
g(x) dx + 1
24g′(0) −
7
5760g′′′(0) + · · · .
(H.23)
Example Problem H.2. Use Eq. (8.12) to evaluate approximately
∞

n=0
exp[−y(n + 1
2)] =
e−y/2
1 −e−y
(H.24)
for y ≪1 and compare with the exact result (right-hand side) which was obtained by summing
the geometric series.
Solution H.2. The leading term is
 ∞
0
e−y x dx = 1
y .
(H.25)

558
THERMAL PHYSICS
g′′(0) = −y and g′′′(0) = −y3 so
∞

n=0
exp[−y(n + 1
2)] = 1
y −y
24 + 7y3
5760 + · · · .
(H.26)
Expanding the exact result gives
e−y/2
1 −e−y = 1
y −y
24 + 7y3
5760 −
31y5
967680 + O(y7).
(H.27)

I
Creation and Annihilation Operators
In this appendix we derive some properties of creation and annihilation operators a and
a† that are useful in quantum mechanics and statistical mechanics. They are also used
to express the operators of quantized ﬁelds in terms of expansions. We ﬁrst motivate
the operators used to treat bosons by appealing to the quantum treatment of the simple
harmonic oscillator in a straightforward way. Then, having established the commutation
relations for a and a†, we derive by purely algebraic operations their properties as they
act on vectors in a Hilbert space. We then relate back to the quantum harmonic oscillator
and derive a few useful expressions for the coordinate and momentum operators, x and p.
Finally, we introduce the corresponding operators used to create bosons and fermions as
well as eigenstates for systems containing many of them.
I.1 Harmonic Oscillator
We consider a simple one-dimensional harmonic oscillator of mass m and frequency ω
described by the Hamiltonian
H = p2
2m + mω2
2
x2,
(I.1)
where p and x are operators that satisfy the well-known commutation relations
[p, x] ≡(px −xp) = −i¯h.
(I.2)
Of course p = p† and x = x† are Hermitian, where the superscript † denotes the Hermitian
conjugate.
We introduce the dimensionless creation operator
a =
mω
2¯h
1/2 
x +
i
mω p

(I.3)
and its Hermitian conjugate
a† =
mω
2¯h
1/2 
x −
i
mω p

(I.4)
which will play the role of an annihilation operator. Then the commutator
[a, a†] =
i
mω
mω
2¯h ([p, x] −[x, p]) = 1
(I.5)
559

560
THERMAL PHYSICS
and of course [a, a] = 0 and [a†, a†] = 0. Then a little algebra shows that
¯hω aa† = p2
2m + mω2
2
x2 + ¯hω
(I.6)
and
¯hω a†a = p2
2m + mω2
2
x2 −¯hω,
(I.7)
which can be added to deduce
H = 1
2¯hω(aa† + a†a) = ¯hω(aa† −1
2) = ¯hω(a†a + 1
2).
(I.8)
As will be shown below, the eigenvalues of a†a are the integers n = 0, 1, 2, 3, . . . and the
eigenvalues of aa† are also integers q = 1, 2, 3, . . . , starting at one instead of zero. The
eigenvalues of H are therefore ¯hω(n + 1/2) as is well known. Note that this result is based
on purely algebraic properties of the operators and did not require any discussion of the
Schrödinger wave functions.
Before leaving this section, we note a few useful relations. The inverses of Eqs. (I.3)
and (I.4) are
x =
 2¯h
mω
1/2 a + a†
2
;
p = mω
i
 2¯h
mω
1/2 a −a†
2
(I.9)
and a little algebra shows that
x2 =
¯h
mω

a†a + 1
2 + aa + a†a†
2

(I.10)
and
p2 = m¯hω

a†a + 1
2 −aa + a†a†
2

(I.11)
which, of course, are Hermitian. These results are used in Section 26.6.2.
I.2 Boson Operators
We proceed to ﬁnd the eigenvalues of the Hermitian operators aa† and a†a. From the
commutator Eq. (I.5), we see that aa† = a†a + 1, so multiplication from the left and
then from the right by a†a shows that the operators a†a and aa† commute and can be
simultaneously diagonalized. Furthermore, if |ψ⟩is an eigenvector of a†a with eigenvalue
λ, we have
a†a|ψ⟩= λ|ψ⟩,
(I.12)
where λ is some real number. But then
aa†|ψ⟩= (a†a + 1)|ψ⟩= (λ + 1)|ψ⟩,
(I.13)
so |ψ⟩is also an eigenvector of aa† with eigenvalue ˜λ = λ + 1.

Appendix I • Creation and Annihilation Operators
561
It is easy to see that λ can never be negative. Let a|ψ⟩= |φ⟩so that ⟨φ| = ⟨ψ|a†. Then
⟨φ|φ⟩= ⟨ψ|a†a|ψ⟩= ⟨ψ|λ|ψ⟩= λ⟨ψ|ψ⟩.
(I.14)
We therefore deduce
λ = ⟨φ|φ⟩
⟨ψ|ψ⟩≥0
(I.15)
with λ = 0 possible only if a|ψ⟩≡0. Thus, the eigenvalues of aa† will satisfy ˜λ = λ + 1 ≥1.
Next, we apply the operator a†a to a|ψ⟩to obtain
(a†a)a|ψ⟩= (aa† −1)a|ψ⟩= (a(a†a) −a)|ψ⟩= a(λ −1)|ψ⟩= (λ −1)a|ψ⟩.
(I.16)
From this we deduce that a|ψ⟩is an eigenstate of a†a with eigenvalue λ −1. Furthermore,
by continued application of a, we deduce that am|ψ⟩is an eigenstate of a†a with eigenvalue
λ−m. If λ were not an integer, we could choose m to be large enough to produce a negative
eigenvalue of a†a, which is impossible. Therefore, λ must be an integer, say λ = n, in which
case n applications of a will give
(a†a)an|ψ⟩= (λ −n)an|ψ⟩= (n −n)an|ψ⟩= 0.
(I.17)
Therefore, there exists an eigenvector |0⟩proportional to an|ψ⟩such that
a†a|0⟩= 0|0⟩.
(I.18)
Furthermore, since the state a|0⟩, if it existed, would be an eigenvector of a†a with
eigenvalue −1, which by Eq. (I.15) is impossible, it must be true that
a|0⟩≡0
(I.19)
to prevent such a state from existing.
At this stage, we have shown that the eigenvalues of a†a are n = 0, 1, 2, . . ., and we shall
denote their corresponding normalized eigenvectors by |n⟩so that
a†a|n⟩= n|n⟩;
⟨n|n⟩= 1.
(I.20)
The eigenvalues of aa† will then be n + 1 = 1, 2, 3, . . . and we will have
aa†|n⟩= (n + 1)|n⟩.
(I.21)
Next, we apply the operator a†a to the state a†|n⟩to obtain
(a†a)a†|n⟩= a†(aa†)|n⟩= (n + 1)a†|n⟩,
(I.22)
which shows that a†|n⟩is an eigenstate of a†a with eigenvalue n + 1, so it is proportional
to |n + 1⟩. Since ⟨n|aa†|n⟩= ⟨n|n + 1|n⟩= n + 1, we see that
|n + 1⟩=
1
(n + 1)1/2 a†|n⟩.
(I.23)
We can therefore generate all eigenvectors of a†a by successive application of a† to |0⟩to
obtain

562
THERMAL PHYSICS
|n⟩=
1
(n!)1/2 (a†)n|0⟩.
(I.24)
Similarly, we note that ⟨n|a†a|n⟩= n, so
|n −1⟩=
1
n1/2 a|n⟩.
(I.25)
It follows that repeated application of a to |n⟩gives
|n −m⟩=
(n −m)!
n!
1/2
an|n⟩;
m ≤n,
(I.26)
so
|0⟩=
1
(n!)1/2 an|n⟩
(I.27)
and an+1|n⟩= 0 because a|0⟩≡0. Given Eqs. (I.23) and (I.25), a† and a are often referred
to as raising and lowering operators, respectively.
I.3 Fermion Operators
In this section, we formally introduce operators that we shall call fermion operators. We
shall still denote them by a and a†, as is usual, despite the possible confusion with a and
a† for bosons. These operators obey the relations
{a, a†} = 1;
{a, a} = 0;
{a†, a†} = 0,
(I.28)
where the anticommutator {A, B} = AB+BA. The second two members of Eq. (I.28) actually
require
aa = −aa ≡0;
a†a† = −a†a† ≡0.
(I.29)
First, we note from Eq. (I.29) that a†aaa† = 0 and aa†a†a = 0, so the operators a†a and aa†
commute and have a common set of eigenvectors. Let |ψ⟩be an eigenvector of a†a with
eigenvalue λ so that
a†a|ψ⟩= λ|ψ⟩.
(I.30)
Applying a†a again and using the anticommutation relations we obtain
λ2|ψ⟩= a†aa†a|ψ⟩= (1 −aa†)a†a|ψ⟩= a†a|ψ⟩= λ|ψ⟩.
(I.31)
Therefore, λ2 = λ so the only possible eigenvalues of a†a are λ = 0 and λ = 1. We denote the
corresponding eigenvectors by |0⟩and |1⟩, respectively. Similarly, if | ˜ψ⟩is an eigenvector of
aa† with eigenvalue ˜λ, we have
˜λ2| ˜ψ⟩= aa†aa†| ˜ψ⟩= (1 −a†a)aa†| ˜ψ⟩= aa†| ˜ψ⟩= ˜λ| ˜ψ⟩,
(I.32)
so ˜λ2 = ˜λ and ˜λ = 0, 1 are the only possible eigenvalues of aa†.

Appendix I • Creation and Annihilation Operators
563
Next, we apply aa† to an eigenvector |ψ⟩of a†a to obtain
aa†|ψ⟩= (1 −a†a)|ψ⟩= (1 −λ)|ψ⟩.
(I.33)
It therefore follows that
a†a|0⟩= 0|0⟩
a†a|1⟩= 1|1⟩,
(I.34)
aa†|0⟩= 1|0⟩
aa†|1⟩= 0|1⟩.
(I.35)
Therefore, if a†a is regarded as a number operator, then aa† behaves like an antinumber
operator.
Now we apply a†a to the state a†|0⟩to obtain
(a†a)a†|0⟩= (1 −aa†)a†|0⟩= a†|0⟩,
(I.36)
from which we conclude that a†|0⟩= |1⟩, but of course a†|1⟩= a†a†|0⟩≡0. Then we apply
aa† to the state a|1⟩to obtain
(aa†)a|1⟩= (1 −a†a)a|1⟩= a|1⟩,
(I.37)
and use the left member of Eq. (I.35) to conclude that a|1⟩= |0⟩. Then we see that a|0⟩=
a2|1⟩≡0.
Summarizing, for fermions there are only two states, |0⟩and |1⟩, so a†|0⟩= |1⟩and
a†|1⟩≡0 whereas a|1⟩= |0⟩and a|0⟩≡0.
I.4 Boson and Fermion Number Operators
Having now established in detail the allowed eigenvalues and eigenvectors of a†a and aa†
for both bosons and fermions, we focus attention on the number operator
ˆN = a†a,
(I.38)
which in both cases has the property ˆN|n⟩= n. The only difference is that n = 0, 1, 2, 3, . . .
for bosons but n = 0, 1 only for fermions. For both bosons and fermions, ˆN satisﬁes the
commutation relations
[ ˆN, a] = −a
and
[ ˆN, a†] = a†.
(I.39)
Therefore
ˆNa|n⟩= (a ˆN −a)|n⟩= (n −1)a|n⟩
(I.40)
and
ˆNa†|n⟩= (a† ˆN + a†)|n⟩= (n + 1)a†|n⟩.
(I.41)
For both bosons and fermions, a|0⟩≡0, but for fermions, we also have a†|1⟩≡0. If we
regard n as being the number of particles in a state, then a applied to |n⟩results in a state,
if such a state |n −1⟩exists, having one less particle. Therefore, a is called an annihilation
operator. Similarly, since a† applied to |n⟩results in a state |n + 1⟩, if such a state exists,

564
THERMAL PHYSICS
having one more particle, a† is called a creation operator. In the case of fermions, and in
accordance with the Pauli exclusion principle, a state can have only zero or one particle.
These ideas can be generalized to a number of identical particles whose single-particle
states we denote by Greek subscripts. For bosons, the corresponding commutation rela-
tions become
[aα, a†
β] = δα,β;
[aα, aβ] = 0;
[a†
α, a†
β] = 0.
(I.42)
The number operator for the single-particle state α is ˆNα = a†
αaα and obviously ˆNα and
ˆNβ commute and can have a common set of eigenstates. The counterpart to Eq. (I.24)
becomes
|nα, nβ, nγ , . . .⟩=
1
(nα!nβ!nγ ! · · · )1/2 (a†
α)nα(a†
β)nβ (a†
γ )nγ · · · |0, 0, 0, . . .⟩,
(I.43)
where the ground state |0, 0, 0, . . .⟩is usually called the vacuum state.
For fermions, the anticommutation relations become
{aα, a†
β} = δα,β;
{aα, aβ} = 0;
{a†
α, a†
β} = 0.
(I.44)
In that case, aαaα = 0 and a†
αa†
α = 0 for all α, but for α ̸= β, we have aαaβ = −aβaα and
a†
αa†
β = −a†
βa†
α. For fermions as well, ˆNα and ˆNβ commute, although the fact that they do
is not as obvious as for bosons. The relation corresponding to Eq. (I.43) is simply
|nα, nβ, nγ , . . .⟩= (a†
α)nα(a†
β)nβ (a†
γ )nγ · · · |0, 0, 0, . . .⟩,
(I.45)
where the only allowed values of the nα are zero and one. Since these operators anticom-
mute, one can order them [8, p. 268] with increasing subscripts (α < β < γ < · · · ) to
prevent an uncertainty of ±1 in the phase.

References
[1] E. Fermi, Thermodynamics, Dover, New York, 1956.
[2] H.B. Callen, Thermodynamics, second ed., John Wiley, New York, 1985.
[3] J.W. Gibbs, The Scientiﬁc Papers of J. Willard Gibbs, vol. 1, Dover, New York, 1961.
[4] J.W. Gibbs, Elementary Principles in Statistical Mechanics, Ox Bow Press, Woodbridge, CT, 1891.
[5] C.H.P. Lupis, Thermodynamics of Materials, North Holland, New York, 1983.
[6] C. Kittel, H. Kroemer, Thermal Physics, W.H. Freeman, New York, 1980.
[7] L.D. Landau, E.M. Lifshitz, Statistical Physics, Addison-Wesley, Reading, MA, 1958.
[8] R.K. Pathria, Statistical Mechanics, second ed., Pergamon Press, New York, 1996.
[9] R.K. Pathria, P.D. Beale, Statistical Mechanics, third ed., Elsevier, New York, 2011.
[10] G. Holton, Y. Elkana, Albert Einstein: Historical and Cultural Perspectives, Dover, Mineola, NY, 1997.
[11] W.H. Cropper, Great Physicists, Oxford University Press, New York, 2004.
[12] D. Chandler, Introduction to Modern Statistical Mechanics, Oxford University Press, New York, 1987.
[13] H.D. Young, R.A. Freedman, University Physics, ninth ed., Addison-Wesley, New York, 1996.
[14] W. Greiner, L. Neise, H. Stöcker, Thermodynamics and Statistical Mechanics, Springer, New York,
2000.
[15] M. Planck, Treatise on Thermodynamics, third ed., Translation of Seventh German, Dover, Mineola,
NY, 1926.
[16] D. Kondepudi, I. Prigogine, Modern Thermodynamics, John Wiley, New York, 1999.
[17] B. Widom, Statistical Mechanics, Cambridge University Press, Cambridge, UK, 2002.
[18] K. Denbigh, Principles of Chemical Equilibrium, third ed., Cambridge University Press, London,
1971.
[19] L.S. Darken, R.W. Gurry, Physical Chemistry of Metals, McGraw-Hill, New York, 1953.
[20] R.B. Grifﬁths, A proof that the free energy of a spin system is extensive, J. Math. Phys. 5 (1964)
1215-1222.
[21] R.T. DeHoff, Thermodynamics in Materials Science, McGraw Hill, New York, 1993.
[22] G.N. Lewis, M. Randall, Thermodynamics, McGraw-Hill, New York, 1961 (revised by K.S. Pitzer, L.
Brewer).
[23] R.A. Swalin, Thermodynamics of Solids, John Wiley, New York, 1967.
[24] T.B. Massalski, Binary Phase Diagrams, vol. 1-3, ASM, Metals Park, OH, 1990.
[25] H. Margenau, G.M. Murphy, The Mathematics of Physics and Chemistry, second ed., D. Van
Nostrand, Princeton, NJ, 1956.
[26] R. Courant, D. Hilbert, Methods of Mathematical Physics, vol. I, seventh printing ed., Interscience,
Princeton, NJ, 1966.
[27] J.S. Rowlinson, B. Widom, Molecular Theory of Capillarity, McGraw-Hill, New York, 1982.
565

566
References
[28] J.W. Cahn, Thermodynamics of solid and ﬂuid interfaces, in: W.C. Johnson, J.M. Blakely (Eds.), In-
terfacial Segregation, ASM International, International Materials Park, OH, 1979, pp. 3-23 (reprinted
in The Selected Works of John W. Cahn, pp. 379-399).
[29] W.C. Carter, W.C. Johnson (Eds.), The Selected Works of John W. Cahn, TMS, Warrendale, PA, 1998.
[30] H.M. Princen, The equilibrium shape of interfaces, drops, and bubbles. Rigid and deformable
particles at interfaces, in: E. Matijevi´c (Ed.), Surface and Colloid Science, Wiley-Interscience, New
York, 1969.
[31] F. Larché, J.W. Cahn, A linear theory of thermochemical equilibrium of solids under stress, Acta
Metall. 21 (1973) 1051-1063.
[32] F. Larché, J.W. Cahn, A nonlinear theory of thermochemical equilibrium of solids under stress, Acta
Metall. 26 (1978) 53-60.
[33] W.W. Mullins, R.F. Sekerka, On the thermodynamics of crystalline solids, J. Chem. Phys. 82 (1985)
5192-5202.
[34] R.F. Sekerka, J.W. Cahn, Solid-liquid equilibrium for non-hydrostatic stress, Acta Mater. 52 (2004)
1663-1668.
[35] D.C. Wallace, Thermodynamics of Crystals, John Wiley, New York, 1972.
[36] D.W. Hoffman, J.W. Cahn, A vector thermodynamics for anisotropic surfaces, Surf. Sci. 31 (1985)
368-388.
[37] J.W. Cahn, D.W. Hoffman, A vector thermodynamics for anisotropic surfaces—II. Curved and
faceted surfaces, Acta Metall. 22 (1974) 1205-1214.
[38] C. Herring, Surface tension as a motivation for sintering, in: W.E. Kingston (Ed.), The Physics of
Powder Metallurgy, a Symposium Held at Bayside, L.I. New York, August 24-26, 1949, McGraw-Hill,
New York, 1951, pp. 143-179.
[39] G. Wulff, Zur Frage des Geschwindigkeit des Wachstums und der Auﬂösung der Kristallﬂächen, Z.
Kristallogr. Mineral. 34 (1901) 449-530.
[40] W.W. Mullins, Solid surface morphologies governed by capillarity, in: W.D. Robertson, N.A. Gjostein
(Eds.), Metal Surfaces: Structure, Energetics and Kinetics, ASM International, International Mate-
rials Park, OH, 1963, pp. 17-66 (papers presented at a joint symposium of the American Society of
Metals and the Metallurgical Society of AIME, October 1962).
[41] C. Herring, The use of classical macroscopic concepts in surface-energy problems, in: R. Gomer,
C.S. Smith (Eds.), Structure and Properties of Solid Surfaces, a Conference Arranged by the National
Research Council, Lake Geneva, WI, September 1952, University of Chicago Press, Chicago, IL, 1953,
pp. 5-81.
[42] F.C. Frank, Solid surface morphologies governed by capillarity, in: W.D. Robertson, N.A. Gjostein
(Eds.), Metal Surfaces: Structure, Energetics and Kinetics, ASM International, International Mate-
rials Park, OH, 1963, pp. 1-15, (papers presented at a joint symposium of the American Society of
Metals and the Metallurgical Society of AIME, October 1962).
[43] R.F. Sekerka, Analytical criteria for missing orientations on three-dimensional equilibrium shapes,
J. Cryst. Growth 275 (2005) 77-82.
[44] C. Herring, Some theorems on the free energies of crystal surfaces, Phys. Rev. 82 (1951) 87-93.
[45] W.W. Mullins, R.F. Sekerka, Application of linear programming theory to crystal faceting, J. Phys.
Chem. Solids 23 (1962) 801-803.
[46] A.P. Sutton, R.W. Balluﬁ, Interfaces in Crystalline Materials, Clarendon Press, Oxford, 1955.
[47] N. Reingold, Science in America: A Documentary History 1900-1939, University of Chicago Press,
Chicago, 1981.
[48] C.E. Shannon, A mathematical theory of communication, Bell Syst. Tech. J. 27 (1948) 379-423;
623-856.

References
567
[49] C.E. Shannon, W. Weaver, The Mathematical Theory of Communications, University of IllinoisPress,
Urbana, IL, 1949.
[50] A.I. Khinchin, The entropy concept in probability theory, in: R.A. Silverman, M.D. Friedman (Trans.,
Eds.), Mathematical Foundations of Information Theory, Dover, New York, 1957, pp. 2-28.
[51] L. Boltzmann, Weitere Studen über das Warmegleichgewicht unter Gasmolekölen, Wien Berichte
66 (1872) 275, reprinted in Boltzmann’s Abhandlungen, vol. 1, Barth, Leipzig, 1909, p. 316.
[52] F. Reif, Fundamentals of Statistical and Thermal Physics, second ed., Waveland Press, Long Grove,
IL, 2009.
[53] C.J. Thompson, Mathematical Statistical Mechanics, Princeton University Press, Princeton, NJ,
1972.
[54] D. McQuarrie, Statistical Mechanics, University Science Books, Sausalito, CA, 2000.
[55] M. Planck, Zur Theorie des Gesetzes der Energieverteilung im Normalspectrum, Verh. Dtsch. Phys.
Ges. 2 (1900) 237-245.
[56] M. Planck, Über eine Verbesserung der Wien’schen Spectral-gleichung, Verh. Dtsch. Phys. Ges. 2
(1900) 202-204.
[57] L.I. Schiff, Quantum Mechanics, third ed., Clarendon Press, Oxford, 1968.
[58] N.W. Ashcroft, N.D. Mermin, Solid State Physics, Saunders College Publishing, New York,
1976.
[59] A. Messiah, Quantum Mechanics, vol. 2, John Wiley, New York, 1962.
[60] H. Goldstein, Classical Mechanics, Addison-Wesley, Reading, MA, 1959.
[61] A.M. Guénault, Statistical Physics, Routledge, London, 1988.
[62] D.M. Dennison, A note on the speciﬁc heat of the hydrogen molecule, Proc. R. Soc. Lond. 115 (1927)
483.
[63] L.A. Girifalco, Statistical Physics of Materials, John Wiley, New York, 1973.
[64] T.L. Hill, An Introduction to Statistical Thermodynamics, Dover, Mineola, NY, 1986.
[65] A. Sommerfeld, Zur Elektronentheorie der Metalle auf Grund der Fermischen Statistik, Z. Phys. 47
(1928) 1-3.
[66] L.D. Landau, E.M. Lifshitz, Quantum Mechanics—Non-relativistic Theory, second ed., Addis-
on-Wesley, Reading, MA, 1965.
[67] P.A.M. Dirac, The Principles of Quantum Mechanics, fourth ed., Oxford University Press, London,
1958.
[68] K. Huang, Statistical Mechanics, John Wiley, New York, 1963.
[69] E. Merzbacher, Quantum Mechanics, John Wiley & Sons, New York, 1961.
[70] S. Galam, A. Mauger, A quasi-exact formula for Ising critical temperatures on hypercubic lattices,
Physica A 235 (1997) 573-576.
[71] K. Binder, D.W. Heermann, Monte Carlo Simulation in Statistical Physics, ﬁfth ed., Springer, New
York, 2013.
[72] D.P. Landau, K. Binder, Monte Carlo Simulations in Statistical Physics, third ed., Cambridge, New
York, 2009.
[73] M.E.J. Newman, G.T. Barkema, Monte Carlo Methods in Statistical Physics, Oxford University Press,
New York, 1999.
[74] L.M. Sander, Equilibrium Statistical Physics: With Computer Simulations in Python, ﬁrst ed.,
Leonard M. Sander, Middletown, DE, 2013.
[75] B.V. Gnedenko, The Theory of Probability and the Elements of Statistics, ﬁfth ed., Chelsey, New York,
1989.

568
References
[76] N. Metropolis, A.W. Rosenbluth, A.H. Teller, E. Teller, Equations of state calculations by fast comput-
ing machines, J. Chem. Phys. 21 (1953) 1087-1092.
[77] W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biomet-
rica 57 (1970) 97-109.
[78] R.H. Swendsen, J.-S. Wang, Nonuniversal critical dynamics in Monte Carlo simulations, Phys. Rev.
Lett. 58 (1987) 86-88.
[79] U. Wolff, Collective Monte Carlo updating for spin systems, Phys. Rev. Lett. 62 (1989) 361-363.
[80] L.P. Kadanoff, Scaling laws for Ising models near Tc, Physics 2 (1966) 263.
[81] K.G. Wilson, Renormalization group and critical phenomena. I. Renormalization group and
Kadanoff scaling picture, Phys. Rev. B 4 (1971) 3174.
[82] K.G. Wilson, Renormalization group and critical phenomena. II. Phase space cell analysis of critical
behavior, Phys. Rev. B 4 (1971) 3184.
[83] A.M. Ferrenberg, R.H. Swendsen, New Monte Carlo technique for studying phase transitions, Phys.
Rev. Lett. 61 (1988) 2635-2637.
[84] A.M. Ferrenberg, R.H. Swendsen, Optimized Monte Carlo data analysis, Phys. Rev. Lett. 63 (1989)
1195-1197.
[85] N.F. Carnahan, K.E. Starling, Equation of state for nonattracting rigid spheres, J. Chem. Phys. 51
(1969) 635-636.
[86] R.J. Speedy, Pressure of the metastable hard sphere ﬂuid, J. Phys. Condens. Matter 9 (1997)
8591-8599.
[87] M.D. Rintoul, S. Torquata, Computer simulations of dense hard sphere systems, J. Chem. Phys. 105
(1996) 9258.
[88] J.D. Bernal, J. Mason, Co-ordination of randomly packed spheres, Nature 385 (1960) 910-911.
[89] W.W. Wood, F.R. Parker, Monte Carlo simulation of state of molecules interacting with the
Lennard-Jones potential, J. Chem. Phys. 27 (1957) 720.
[90] J.-P. Hansen, L. Verlet, Phase transitions of the Lennard-Jones system, Phys. Rev. 184 (1969) 151.
[91] A. Travesset, Phase diagram of power law and Lennard-Jones systems: crystal phases, J. Chem. Phys.
141 (2014) 164501.
[92] E.T. Whittaker, G.N. Watson, A Course in Modern Analysis, fourth ed., Cambridge University Press,
London, UK, 1969.
[93] C.E. Weatherburn, On differential invariants in geometry of surfaces with some applications to
mathematical physics, Q. J. Pure Appl. Math. 50 (1925) 230-269.
[94] C.E. Weatherburn, On families of curves and surfaces, Q. J. Pure Appl. Math. 50 (1927) 350-361.
[95] C. Johnson, Generalization of the Gibbs-Thomson equation, Surf. Sci. 3 (1965) 429-444.
[96] R. Courant, Calculus of Variations, Courant Institute of Mathematical Sciences, New York University,
NY, 1962 (revised and amended by J. Moser).
[97] H. Goldstein, Classical Mechanics, second ed., Addison-Wesley, Reading, MA, 1981.
[98] M. Abramowitz, I.A. Stegun (Eds.), Handbook of Mathematical Functions, ninth ed., National
Bureau of Standards, Washington, DC, 1970.
[99] E. Schrödinger, Statistical Thermodynamics, second ed., Cambridge University Press, Cambridge,
1962.
[100] J.H. van Vleck, The Theory of Electric and Magnetic Susceptibilities, ﬁrst ed., Oxford University
Press, London, 1932.

Index
Note: Page numbers followed by f indicate ﬁgures, by t indicate tables, and by np indicate footnotes.
A
Absolute activity, 362–363, 371, 405–406,
413–416, 447, 458
Absolute temperature, 4, 7, 13, 20, 32–34, 43, 47,
49, 51f , 53, 121, 124, 156, 247, 259, 262,
266, 289
Absolute zero of temperature, 4–5, 37, 49–51, 425
Acceptors, 443, 446–448, 447f
Accessible quantum state, 49, 313
Activated process, 111–112
Activation energy, 111–112, 181, 392, 395, 440
Activity, 175
absolute, 362, 370–371, 405, 413–416, 447, 458
Actual state, 219
adsorption equation in, 220–221
Adiabatic demagnetization, 329–330f
Adiabatic, 25–28, 272
and Carnot cycle, 35, 36f
and isentropic process, 272
Bose gas, 423
coefﬁcient of expansion, 506
compressibility, 105, 503
cyclic process, 35
deﬁnition, 25np
demagnetization, 329, 330f
ideal gas expansion, irreversible,
27–28, 44
ideal gas expansion, reversible, 25–27
reversible contraction, 44
reversible isentropic for ideal
second law, entropy change, 34–35
with reversible work, 45
Adsorption equation of Gibbs
actual state, 220–221
reference state, 218–219
Afﬁnity, 173–175, 174f
Angular momentum, 537, 539–543
for paramagnetic system, 324
orbital, for electronic structure, 381
polyatomic molecule, 358
probability distribution for, 358
spin, for electronic structure, 381
Anisotropy
of crystal surface or interfacial free energy per
unit area, (γ), 196, 215, 221, 223–226,
510–511
illustration for cubic crystal, 223, 242
Annihilation operators, 559–564.
See also Creation operators
Anti-symmetric fermion states, 465–466
Anti-symmetrization operator, 467
Approximate
evaluation of inﬁnite sums, 556
evaluation of partition function (thermody-
namic perturbation theory), 549–552
Arrhenius form, 112f –113, 181
Asymptotic, 277–278, 304f , 422, 449
expansion, 409–410, 435
series, 499–501, 553–556
series, vs. convergent series, 500–501
Avogadro’s number, 3, 12, 48, 49, 126–127, 166,
289
B
Band gap, 425, 442, 443f , 445
Beale, Paul, xv, xviii, 6, 350, 416, 419, 483, 489
Bernoulli numbers and polynomials, 553–554
Binary liquid, in gravity, 162–164
Binary solutions
chemical components, 137
chemical potentials, 137–138
chord construction, 141
569

570
Index
Binary solutions (Continued)
Euler equation, 137–138
general solution, 153
Gibbs-Duhem equation, 137–138
graphical constructions, 139–141
ideal, 142–145
ideal solid and ideal liquid, 145–148
ideal solutions, 142–145
intercept and common tangent constructions,
139–141
lens type binary phase diagram, 145–146,
147–148
liquid in gravitational ﬁeld, 162–164
miscibility gap, 137–141, 142–148, 153
molar Gibbs free energy, 139
mutual solubility, 144
phase diagram, ideal solid-liquid,
145–148
regular solution, 148–152
thermodynamics of, 137–141
Binary system, see also Multicomponent system
partial molar quantities, 3, 74f , 75
Blackbody radiation, 298–302
Bohr magneton, 324–325, 437–439
Boltzmann, Ludwig, 251–252
constant kB, 12, 48, 49, 249–251
distribution, 285–289
equation, 252–253
Eta theorem, 247, 251–256
factor, 250, 263, 313, 322np, 337, 361, 373, 468,
484–485, 487
sampling, 487
Boltzons, 468
Bomb calorimeter, 168
Bose, Satyendra
condensation, 413
chemical potential below Tc, 413
condensate fraction, 416f
condensate region, 421–424
critical temperature Tc, 421
entropy below Tc, 417–418
heat capacity, 419f , 420–421
internal energy below Tc, 417–418
λ point, heat capacity, 420–421
pressure below Tc, 417
region in v, p plane, isotherms, 422–423
region in v, T plane, isotherms, 421–422
thermodynamic functions, 416–421
-Einstein distribution function, 374–375
ideal gas, 376–378, 410–412
Bosons, 465–468
at low temperatures, 413–416
operators, 560–562
number operators, 563–564
Bragg-Williams molecular ﬁeld approximation,
471np
Brillouin function, 325–326
Bromwich contour, 330–331
Bulk samples, homogeneous, 6–7
C
Cahn, John W., 185
determinants for surface invariants,
194–197
layer model, 185, 192–197
Calorie, 17
Canonical distribution, 337np
Canonical ensemble, 288, 457–458. See also
Classical canonical ensemble
Boltzmann factor, 337
canonical ensemble, classical
averaging and equipartition, 343–345
canonical transformations, 354–356,
529–535
effusion of ideal gas, 340–342
Maxwell-Boltzmann distribution, 338–339
classical ideal gas, 313–316, 338–342
Maxwell-Boltzmann distribution, 338–339
quantum concentration, 339–340
deﬁnition, 305
density of states, 330–331
derivation
from
microcanonical,
305–312,
360–368
energy dispersion, ﬂuctuation, 320–321,
367–368
factorization theorem, 312–313
grand, see Grand canonical ensemble (GCE)
Helmholtz free energy, 306np, 307–309, 311,
315–316, 321–322
Maxwell-Boltzmann distribution, 317–319

Index
571
as most probable distribution, 309–312
paramagnetism, 290–292, 321–330
adiabatic demagnetization, 329–330
classical treatment, 322–324
magnetic moment, 321–325
properties, 327–329
quantum treatment, 324–327
particles, negligible interaction energies, 285,
312–313
blackbody radiation, 298–302
harmonic oscillator, 293–302
heat capacity of a crystal, 297–298
rigid linear rotator, 303–304
two-state subsystems, 289–293
partition function, 330–331
diatomic molecular gas, 382–387
polyatomic molecule, 387–388
relation to density of states, 330–331
relation to Helmholtz free energy, 311,
315–316, 321–322
virial expansion coefﬁcients, 348–354
virial theorem for time averages, 346–348
Canonical partition function, 457–458
for single spin, 471–472
Canonical transformations
general transformation, 529–530
Jacobian value, 354–356, 529–530, 532–533
necessary and sufﬁcient conditions, 530–534
restricted transformation, 534–535
symplectic transformation, 532–534
use of, 354–356
Canonical variables for freely rotating poly-
atomic molecule, 546
Capillary
length, 201, 205–206, 211
rise in tube, 185, 200, 200f
Carnot, Sadi, 35–38
cycle, 4, 32np, 35–36
efﬁciency, 36–37
engines, 35–38, 36f
refrigerator, 38
Cauchy stress tensor, 216–217, 218–219
Celsius scale, 4np
Chemical heat, 53
Chemically closed system, 15, 32, 33, 41, 53, 75,
84, 89–90, 167, 168–169, 173, 174
Chemical potential, 12, 53–54, 55, 61, 64–66, 69,
83, 91–93
of binary solutions, 137, 139np, 140f ,
142–143, 145, 153
Bose gas below critical temperature, 413
electrochemical, 12, 155, 166
gravitational, 12, 155, 157–158
ideal gas, 54, 61
intrinsic, 12, 157–158
monatomic gas, 55
of monocomponent ideal gas, 54, 161
multicomponent systems, 53, 55, 171–172,
175–176
real gases, 64, 171, 176
Chemical reaction
afﬁnity, 173, 174f , 182
among ideal gases, 177, 178
at constant volume/pressure, 168
δ G (G) of, 173
δ H (H) of, 170
entropy production during, 75, 77, 174–175
equilibrium, 173–175
equilibrium conditions, explicit
equilibrium constant, K, 176, 176np, 178–181
alternative, Kc
dependence on pressure, 182
dependence on temperature, 180
extension of equilibrium conditions to
include, 93
heat of, 170
heterogeneous solids/liquids with gases,
171, 179
in isolated system, 167
reaction product and quotient, 176–177
simultaneous reactions, 182–183
standard states, 171–173
stoichiometric coefﬁcients, 76, 167
Chord construction, 129–130, 129f , 141,
142f , 153
binary solution, 141
Classical canonical ensemble, 337.
See also Canonical ensemble
averaging theorem and equipartition, 343

572
Index
Classical canonical ensemble (Continued)
classical ideal gas, 345
Cartesian coordinates, 340–341
effusion, 341, 342
Maxwell-Boltzmann distribution, 338–339
law of Dulong and Petit, 342–343, 345
rotating rigid polyatomic molecules, 356–358
use of canonical transformations, 354–356
virial coefﬁcients, 348, 353
virial theorem, 346–348
Classical ideal gas, 338–342
canonical ensemble, 313–316
free particle in box, 314–316
grand canonical ensemble, 375–378, 380–388
Classical microcanonical ensemble. See also
Microcanonical ensemble
classical harmonic oscillators in three
dimensions, 282, 283–284
classical ideal gas, 281–283
deﬁnition, 277
description, 280
Classical particles, Monte Carlo simulation,
491–494
Classical partition function, 337–338
evaluation, 342–343, 354
for single diatomic molecule, 355
Classical treatment of paramagnetism,
322–324
Clausius, Rudolf, 17
-Clapeyron equation, 110–115
ﬁrst recognition of entropy
postulate of, 31–34, 37
Closed system, 15
Coefﬁcients of curvatures, 201–202
Coexistence curves, 109
Common tangent construction, 127–129, 129f
of binary solutions, 139–141
Communication theory, 247
Composition, mole fractions, 62
Concave function, 95–96, 100
Concentrations, 64
Condensate region, Bose condensation
in v, p plane, 422–423, 423f
in v, T plane, 421–422, 422f
Conditions for equilibrium of composite
systems, 81–83, 87
multicomponent subsystems, 81–83
mutual equilibrium, 93
extension to chemical reactions, 93
Conduction band, 442–444, 446, 447f
Conﬁguration
distinguishable particles, 285–286
MC simulation, 484–491
Conjugate variable, 47, 67–68
Conservative external forces, 155
Constant pressure
chemical reactions at, 168–170
heat capacity at, 20, 22–23, 420–421
Constant
Boltzmann, 12, 48, 49, 249–251
Curie, 322–324
equilibrium, 175–182
ideal gas, 4
Planck, 55, 60, 68–69
Stefan-Boltzmann, 301
van der Waals ﬂuid, 126–127
Constant volume
chemical reactions at, 168–170
heat capacity at, 19–20, 22–23
Constrained equilibrium, 217
Construction, graphic
chord
binary, 141
monocomponent, 129–130
common tangent
binary, 139–141
monocomponent, 127–129
intercept, 139–141
Maxwell equal area, 133–134, 133f
Contact plane, 234–235
Convex function, 100–102
Correlations function
for hard-sphere gas, 492
Monte Carlo, 485
of spin, 484, 485
Creation and annihilation operators. See also
Annihilation operators
boson and fermion number operators,
563–564

Index
573
boson operators, 560–562
eigenstates of, 559, 561–562
fermion operators, 562–563
for harmonic oscillator, 559–560
vacuum state, 564
Critical exponent, 474–475
Critical point, 109
Critical temperature, 421–422
deﬁnition, 413, 471–472
Crystal
heat capacity of, 297–298
equilibrium shape, 215–216, 227–228, 233
Crystalline solids, 215–216
Curie constant, 322–324
Curie’s law, 292f , 322–324
Curie-Weiss law, 475–476
Curved interfaces in ﬂuids
capillary length, 200
constants, 198
contact angle, 204–205
dividing surface in comparison system, 197
Gibbs coefﬁcients of curvatures, 201–202
interface junctions and contact angles,
202–205
surface of tension, 198
Curved solid-ﬂuid interfaces. See also Planar
solid-ﬂuid interfaces
description, 227–228
discontinuous derivatives of γ, 228–232
inverted γ-plot, 232–233
D
Decimation, 488–489
de Donder, Théophile, 173np
concept of afﬁnity, 173
Degeneracy factor, 402
Degrees of freedom, 7–8, 55–56
Density
dispersion, ﬂuctuation, 367
matrix, 451–452
one-dimensional harmonic oscillator,
460–461
single free particle, 459–460
spin 1/2 particle, 461–465
operator, 451
assumption of random phases, 454
free particle, 459–460
grand canonical ensemble, 458
harmonic oscillator, 460–461
pure quantum state, 451–452
relationship to entropy, 47–48
statistical quantum state, 453
in terms of Pauli spin matrices,
461–462
time evolution, 455–456
various ensembles, 456–458
of states
canonical ensemble, 330–331
deﬁnition, 330–331, 332
Detailed balance, principle of, 486–487
Diatomic molecular gas, 382
heteronuclear molecules, 382–385
homonuclear molecules, 385–387
polyatomic molecular gas, 387–388
Diatomic molecule
moments of inertia, 303
quantum energy levels, 547
rigid linear rotator, 303
Dirac, Paul, 430
continuous spectrum, 452np
delta function, 30, 430
Fermi-Dirac distribution, 373–374, 428–432
in semiconductors, 444np
thermionic emission, 439
vector space, 468
Boson and Fermion number operators,
563–564
Boson operators, 560–562
eigenbras and eigenkets, 560–562
Fermion operators, 562–563
probability density ket, 51
Discontinuous derivatives of γ, 228–232
Disorder function, entropy, 247–251
Distinguishable particles, with negligible
interaction
blackbody (hohlraum) radiation, 298–302
canonical ensemble, 288
conﬁguration, 285–286
crystal, heat capacity of, 297–298
derivation of Boltzmann distribution, 285–289

574
Index
Distinguishable particles, with negligible
interaction (Continued)
ensemble, 288
factorization theorem, 312–313
harmonic oscillators, 293–302
identical but, 285
magnetic moment, 290–292
paramagnetism, 290–292
partition function, 286–287
rigid linear rotator, 303–304
Stirling’s approximation, 287
two-state subsystems, 289–293
Divacancies, 393–394
Donors, 442–443, 446–447
Dopants, 442–443, 446–449
E
Effusion
deﬁnition, 340–341
energy ﬂux with, 341
of ideal classical gas, 340–342
Eigenstates, 559, 561–562
Einstein, Albert
Bose-Einstein distribution, 374–375
heat capacity, 297
nuclear reactions, 167
quotation re thermodynamics, xvii
temperature, 297
Electric ﬁelds, external forces, 166
Electronic heat capacity, 381–382, 432–433.
See also Heat capacity
Elementary kinetic theory, of gases, 12–13
Elementary method, 498, 504–507
Endothermic reaction, 170
Energy, 3
criterion, 84–88
and entropy, equivalence, 87–88
local energy criterion, 86–87
dispersion
canonical ensemble, 320–321
grand canonical ensemble, 367–368
free, Gibbs, 69
free, Helmholtz, 68–69
internal, 11, 15–16
kinetic of center of mass, 11
lack of partitioning, 19
mechanical, 8–12
single particle
in one dimension, 8–9
in three dimensions, 9–10
as state function, 15–16
system of particles, 10–12
Ensembles, 257, 288
applied to point defects, 391–393
averages, 5–6
canonical, 457–458
grand canonical, 458
microcanonical, 457
pressure, 360, 389–390
Enthalpy, 28–29, 69
of chemical reaction, 75–78
criterion, 90–91
of melting, 29, 30
of multicomponent system, 62–63
of phase change, 46f
stability requirements for, 102–103
Entropy, 5, 31
of Bose condensation, 418, 419
change calculation, 39
change due to heat transfer, 32
change for adiabatic process, 25np
change for reversible path, 38
of chemical reaction, 75–78
criterion for equilibrium, 32, 79–84
equivalence to energy criterion, 87–88
Gibbs phase rule, 83, 93, 109, 141
disorder function, 247–251
disorder measurement, 247–251
elementary relationship to
microstates, 47–48
formula, 400–402
for general ensemble, 397–398
example of maximization, 399–400
summation over energy levels, 402–403
ideal gas, 44
information theory, 247–256
of mixing, ideal gases, 275–276
of phase change, 46
probability of microstate, 47–48
relationship to microstates, 47–48

Index
575
stability requirements for, 95–100
as state function, 31, 32
statistical interpretation, 47–48
of two systems, 250
Equations of state, 20, 23–24, 28,
41–43, 54, 61, 70, 98, 121,
138–139, 250
Equilibrium, 3
chemical reaction, 173–175
condensed phases, 175–176, 175np
conditions for subsystems, 81–83
constant for chemical reaction, 176–178,
180
criteria, 79–81, 84–93
dependence on pressure, 182–183
dominant contributions, 525–526
enthalpy criterion, 90–91
entropy additivity, 523, 526–527
entropy criterion, 32, 79–84
explicit conditions for, 175–182
with external forces, 155–157
Gibbs free energy criterion, 89–90
in gravitational ﬁeld, 157–164
Helmholtz free energy criterion, 88–89
heterogeneous reactions in gases, 179
internal energy criterion, 88
Kramers (grand) potential criterion,
91–92
multiplicity function, 523–524
of two-state systems, detailed study,
523-527
overlap integral, 523
phase rule, 83–84
pressure, dependence of K(T, p), 182
reactions in gases, 177, 178
rotating systems, 164–166
shape, 227–228
of crystal, 215–216, 227–228
global vs. local, 239
Legendre transforms, 241–242
from ξ-vector, 236–239
state, macroscopic systems, 3
Summary, 92t
temperature, dependence of K(T, p),
180, 181
Equimolar surface, 188
Equipartition, 263
averaging theorem and, 343–345
principle, 343
Ergodic hypothesis, 260
Eta theorem, 251–252, 254–256
Euclidean geometry, 6
Euler equation, 60–62, 68, 72, 110–111, 137–138,
158, 169, 193, 201–202, 216–217, 322, 365,
390, 400, 419, 543
Euler-Maclaurin sum formula, 437–439,
554–556
Euler theorem, 59–60
for extensive functions, 60–62
of homogeneous functions, 59–64
for intensive functions, 63–64
Excited states
concentration of particles, 414–415
function of T/Tc, 416f , 419
Exothermic reaction, 170
Extensive functions, Euler theorem for, 60–62
Extensive variables, 7
External forces
binary liquid, 162–164
centrifuge, 165–166
conditions for equilibrium, 155–157
electric ﬁelds, 166
electrochemical potentials, 155, 166
gravitational segregation, 161–162
inhomogeneous pressure, 155
Lagrange multipliers, 156
multicomponent ideal gas, 160–162
non-uniform gravitational ﬁeld, 164
rotating systems, 164–166
uniform gravitational ﬁeld, 157–164
Extrinsic semiconductors, 442–443
F
Faceting, of large planar face,
233–235, 233f
Factorization
for independent sites, 370–373
theorem, 312–313
Fahrenheit scale, 4
Fan of vectors, 228–229

576
Index
Fermi, Enrico
degenerate gas, 425
energy ϵF, 428–429
heat capacity, 432–433
Sommerfeld expansion, 430–432
sphere in k space, 433–434
temperature TF, 427
thermal activation, electrons,
429–433
thermionic emission of electrons,
439–442
wavenumber kF, 426
-Dirac distribution function, 373–374, 428,
429, 430f , 432
energy, 427, 428–429, 431–432, 433–434, 439,
443–444
ideal gas, 376–378, 410–412
level, 432
sphere, 426–427
wavenumber, 426–427
Fermion operators, 562–563
number operators, 563–564
Fermions, 425–450, 467–468. See Bosons
First law of thermodynamics
combined with second law, 41–47
discussion of, 16–17
enthalpy, 28–29
heat capacities, 19–23
ideal gas expansion, 24–28
quasistatic work, 17–19
statement of, 15–17
Fluid-ﬂuid interfaces
contact lines, 202np, 207
curved interfaces, 197–202
interface junctions and contact angles,
202–205
planar interfaces in, 186–197
sessile drops, 185–186, 210–211
surface shape in gravity, 205–213
three-dimensional problems, 210–213
two-dimensional problems, 206–209
Forces, external
conservative, equilibrium condition, 155
electrical, 166
non-uniform gravitational, 164
for rotating systems, 164–166
uniform gravitational, 157–164
Frenkel defects, 395
Fugacity, 64–67, 65f
ratio, chemical reactions, 175–176
Functions hv (λ, a), 408–410, 410f
Fundamental equation of system, 42, 43
Fundamental hypothesis, 258
statistical mechanics, 258–260
G
Gamma function, 499, 500f
Gamma-plot (γ -plot), 227, 228f
discontinuous derivatives of, 228–232
inverted gamma-plot, 232–233
minimum gamma plot (-plot),
234–235, 235f
Gauss divergence theorem on a surface,
515–516
Gaussian
approximation, 524–525
curvature, 512–513
distribution, 317–319, 461
integral, 459–460
GCE. See Grand canonical ensemble (GCE)
General ensemble, entropy for, 397–398
example of maximization, 399–400
summation over energy levels, 402–403
Giauque, William, xvi
Gibbs, J. Willard
adsorption equation, 190–192, 215–216
boltzon weighting factor, 468
coefﬁcients of curvatures, 201–202
correction factor for extensivity, 268–271
correction factor, monatomic ideal gas with,
268–271
distribution, 305
dividing surface, 185, 186f , 187–190
-Duhem equation, 61–62, 109–110, 218–219
factor, 360–361
free energy, 69, 173, 174f
binary solutions, 139
equilibrium criteria, 89–90
stability requirements for, 103–104
van der Waals ﬂuid, 129–130

Index
577
paradox, 268np
phase rule for equilibrium, 83–84
theorem for mixed ideal gases, 268np, 274
-Thomson equation, 238–239
-Wulff equilibrium shape, 215–216, 227–228,
234–235
Grand canonical ensemble (GCE), 405–406, 458
adsorption
Langmuir, Irving, 370–371
multiply occupied sites, 368
Bose-Einstein distribution, 374–375
Bose gases, 376–378
classical ideal gas, 375–378, 380–388
with internal structure, 380–388
limit, 359–360
consolidated distributions for ideal
gases, 376
derivation from microcanonical, 360–368
description, 359–360
diatomic molecular gas, 382–387
energy dispersion, ﬂuctuation, 367–368
factorization for independent sites,
370–373
Fermi-Dirac distribution, 373–374
Fermi gases, 376–378
Gibbs factor, 360–361
grand partition function, 361
factorization for ideal systems, 368–380
factorization for independent sites, 370–373
Kramers function, 363–366
for multicomponent systems, 388–389
power series in absolute activity, 362
relation to Kramers (grand) potential K, 416
grand (Kramers) potential, 416
Kramers function, 363–366
monatomic gas, 381–382
multicomponent systems, 388–389
occupation numbers, 368
orbital populations for ideal gases, 378–380
orbitals, 368
particle number dispersion, ﬂuctuation,
366–367
Pauli exclusion principle, 368
polyatomic gases, 387
pressure ensemble, 389–396
Grand partition function, 437
Gravitational chemical potentials, 155, 157–158
H
Hamiltonian, 277, 283–284, 466–467
kinetic energy for, 344
operator, 455
Hamilton’s equations, 277, 278–279
Harmonic Hamiltonian, 342
Harmonic oscillator, 265–267, 559–560
in canonical ensemble, 283–284
classical, in three dimensions, 282, 283–284
creation and annihilation operators, 559–560
description, 265–267
distinguishable particles, 293–302
generating function, 267
in microcanonical ensemble, 265–267
multiplicity function for, 265f
Heat, 3–4
caloric, 5np
capacity difference Cp – CV , 23
of chemical reaction, 170
conduction, 5
deﬁned by ﬁrst law, 15
derivation of, 57–59, 504–505
of formation, 172
general, 22
of ideal gas, 21
latent, 45–47, 51f , 111, 114–115, 117f , 118f ,
146, 238
of reaction, 170
reservoir, 34–35, 305, 306np, 320
transfer, 3–4, 5, 15, 17
of van der Waals ﬂuid, 23
Heat capacity, 17, 20
behavior near absolute zero, 50
for Bose condensate, 419f
at constant pressure Cp, 420
at constant volume CV , 420
of crystal, 297–298
deﬁnition, 20
of degenerate Fermi gas, 425, 432–433
of diatomic and polyatomic gases, 21
effective, due to phase transformation, 20
due to electronic structure, 381–382, 432–433

578
Index
Heat capacity (Continued)
and equipartition, 317–319
of a gas as a function of temperature, 384f
of harmonic oscillator, 296f
for hydrogen isotopes, 385–387
of ideal Fermi and Bose gases, 420
of ideal gas, 20–21, 22t
of linear rotator, 303, 304f
for polyatomic molecular gases, 387–388
for quadratic Hamiltonian, 342, 345
relationship of Cp to CV , 22, 57–59
relationship to energy dispersion
(ﬂuctuations), 320, 367–368
Schottky peak, 293f
van der Waals equation, 23
of van der Waals ﬂuid, 23, 125
Heisenberg, Werner
model for interacting spins, 469
Helmholtz, Hermann von, 88–89
equation, 58np
Helmholtz free energy, 59np, 68–69
canonical ensemble, 306np, 307–309, 311,
315–316, 321–322
equilibrium criteria, 88–89
maximum work, isothermal system, 88–89
relation to canonical ensemble,
307–308, 311
stability requirements for, 103
vs. temperature, 293f
Hermitian
conjugate, 455
operator, 451–452, 453
Herring, Conyers
formula, 240–241, 518–521
sphere, 215–216, 230f
construction, 229
discontinuous derivatives of γ, 229,
230–232
inverted γ-plot, 232
theorem for faceting, 234
Hess’s law, 171
Heterogeneous reaction in gases, 171–172, 179
Heteronuclear diatomic molecular gas, 382–385
Holes in semiconductors, 442–444
Homogeneous function, 59–64
Homonuclear diatomic molecular gas, 385–387
Hypersurface, 277
I
Ideal binary solution, 142–145
Ideal Bose gas, 425
entropy, 407–408
grand partition function, 405–406
heat capacity, 412
uniﬁed integrals and expansions, 406–408
virial expansions for, 410–412
Ideal entropy of mixing, 142–143
Ideal Fermi gas
entropy, 407–408
free electron model, metal, 428–429, 432
grand partition function, 405–406
heat capacity, 412
Landau diamagnetism, 436–439
at low temperatures, 425–428
Pauli paramagnetism, 433–436
semiconductors, 442–450
thermal activation of electrons, 429–433
thermionic emission, 439–442
uniﬁed integrals and expansions, 406–408
virial expansions for, 410–412
Ideal gas, 4
adiabatic expansion, irreversible, 27–28
adiabatic expansion, reversible, 25–27, 45
canonical ensemble, 313–316
chemical potential, 54–55
chemical reactions, 177
classical, 281–283
canonical ensemble, 338–342
Cartesian coordinates, 339–340
effusion, 340–342
grand canonical ensemble, 359–360,
375–378, 380–388
Maxwell-Boltzmann distribution, 338–339
constant R, 4
energy independent of volume, 20–21
enthalpy independent of pressure, 28–29
entropy of mixing, 275–276
equation of state, 20–21
heat capacities, 20–21
isobaric expansion, reversible, 24–25
isochoric transformation, 24–25

Index
579
isothermal process, reversible, 24
microcanonical ensemble, 267–273
monatomic, 267–271
multicomponent, 273–276
multicomponent in uniform gravity, 160–162
open systems, 54–55
orbital populations for, 378–380
pressure of, 12–13
scaling analysis, 272–273
standard states, 171–172
work due to expansion, 24–28
Ideal liquid, phase diagram for, 145–148
Ideal solid, phase diagram for, 145–148
Ideal solution, 142–145
Identical but distinguishable particles, 260np
Identical indistinguishable particles, 267–268
Importance sampling, 487
Independent extensive variables, 7–8
Independent intensive variables, 7–8
Index of probability, 337np
Indistinguishable particles, 465–468
bosons and fermions, 468
Gibbs correction factor, ideal gas, 270
Slater determinant, 467–468
wave functions, ideal Bose and Fermi
gases, 467
weighting factors for ideal gases, 468
Inﬁnitesimal transfers of energy, 16
Inﬁnite sums
approximate evaluation of, 556–558
convergence of, 408–409, 499–501
Information
disorder function, 247–251
relation to entropy, 247–256
Integral formulae for Fermi, Bose, and classical
gases, 406–410
Integral theorems for surfaces, 515–516
Intensive functions, Euler theorem to, 63–64
Intensive variables, 7
conjugate, 106–107
dependent, 218–219
Euler theorem, 60–62
independent, 7–8, 83, 138
locally concave function of, 102–103
non-conjugate Le Chatlier, 107
partial molar quantities, 71, 72
stability requirements, 104–105
Intercepts
for binary system, 73–74
monocomponent system, 128
for multicomponent system, 74–75
Interfaces, ﬂuid-ﬂuid
Cahn’s layer model, 192–197
capillary rise in tube, 185, 200, 200f
curved, 197–202
equimolar, 188–189, 191–192
Gibbs adsorption equation, ﬂuids, 190–192
Gibbs dividing surface, 187–190
Laplace equation, pressure difference related
to mean curvature, 199–200
meniscus on plate, 207, 207f
physical quantities independent of dividing
surface, 193
shape in gravity, 205–213
surface (interfacial) free energy γ, 187np,
193–194
surface (interfacial) tension σ, 189–190
surface of tension, 187np, 193–194, 198
three-dimensional drops and bubbles,
210–213
triple junctions, contact angles, 202–205
two-dimensional drops and bubbles,
208–209, 209f , 210f
Young’s equation, 204
Interfaces, solid-ﬂuid, 211
adsorption equation
actual state, 220–221
reference state, 218–219
anisotropy of surface free energy γ, 221–227,
240
anisotropy, ξ-vector formalism, 215–216
curved, 227–233
equilibrium shape from ξ-plot, 236–239
equilibrium shape, variational formulation,
509–511
equimolar, 191
faceting, Herring construction, 229
γ and ξ polar plots, 227
Gibbs-Thomson equation for anisotropic γ,
238–239

580
Index
Interfaces, solid-ﬂuid (Continued)
Gibbs-Wulff (equilibrium) shape, 215–216
γ with discontinuous derivatives, 228–232
γ with discontinuous derivatives ξ-vector for,
230f
Herring formula for surface chemical
potential, 240–241, 518–521
inverted γ-plot, 232–233
surface (interfacial) free energy γ, 215
surface stress, strain, 215–216
triple junctions, 226–227
Interfacial free energy, 215–218
anisotropy, 215–216, 242–245
Internal energy U, 11, 13, 15–16, 19, 21, 24, 27,
29–30, 32–33, 39, 42–43, 47–48, 53–54, 61,
70–71
equilibrium criterion for, 79–81, 84, 87–88, 92t
stability requirements for, 100–104
Interstitials
description, 393–394
in ionic crystals, 394–396
Intrinsic chemical potentials, 157–158
Intrinsic semiconductors, 442–443, 445–446
law of mass action, 444
Inverted gamma-plot, 232–233
Ionic crystals, 394–396
Irreversible adiabatic expansion, 27–28
Irreversible process, 31–32, 33–34, 39, 41–42,
43, 44
Isentropic compressibility, 504–507
Isentropic transformation, 423–424
Ising, Ernst, Model of two-state coupled
spins, 469
Boethe cluster model, 473
critical exponents, 483–484
exact solution in one dimension
magnetic ﬁeld, transfer matrix, 480–483
zero magnetic ﬁeld, 479–480, 483
heat capacity per spin vs. temperature, 476f
magnetic susceptibility vs. temperature, 476f
magnetization per spin vs. temperature, 474f
mean ﬁeld treatment
comparison with exact solutions, 473–474
critical temperature Tc, 471–472, 472–473f
heat capacity, 475, 476f
magnetic susceptibility, 476f
magnetization, 471, 474–477, 474f
neglect of correlations, 471
Onsager’s exact solution on two
dimensions, 473
pair statistics for, 477–478, 478f
Monte Carlo simulation, 484–491
“simple cubic” lattice, 473t
solution in one dimension for zero ﬁeld,
479–480
transfer matrix, 480–483
Isobaric coefﬁcient, 504–507
of thermal expansion, 22
van der Waals ﬂuid, 23
Isobaric expansion, reversible, 24–25
Isochoric transformation, 24–25
Isolated system, 15–17, 264, 305, 359–360,
389, 457
chemical reaction in, 167
entropy of, 32–35, 40, 44, 48–49, 250
equilibrium of, 79–84
Eta fu, 277
quasi-isolated, 260
stability of, 95
vacancies, 393, 457
Isothermal compressibility, 22, 504–507
Isothermal process, reversible, 24
Isotropic statistical state, 464, 465
J
Jacobian
for canonical transformations,
354–356
to convert partial derivatives, 503–507
deﬁnition of, 503
determinants, 503
properties of, 503–504
thermodynamics, connection, 504–507
to transform canonical momenta,
356–358
Joule, James, 16–17, 20–21
Joyce-Dixon approximation, 449–450
K
Kadanoff transformation, 488–489
Kapitsa, Pyotr, xvi

Index
581
Kelvin, Lord (Thomson, Sir William), 4
expansion of gas though porous plug, 21
postulate concerning second law, 31–33, 37
scale for temperature, 4np
Kinetic energy, 8–9, 540
of atom, 3
motional, 11
system of particles, 10–11
Kinetic theory, elementary, 12–13
Kramers, Hans
excess potential for interface, 188–190,
198
for equilibrium shape, 236
pseudi-Kramers, 217
function q for grand canonical ensemble,
363–366
potential K (grand potential), 69–70
equilibrium criterion, 91–92
for grand canonical ensemble, 361, 400
for ideal Fermi and Bose gases, 407, 416
and Jacobians, 506
for Pauli paramagnetism, 434
L
Lagrange brackets, 531–533
Lagrange multiplier, 237
Lambda point, 418–419, 419f
Landau, Lev, 436–439
diamagnetism, 436–439
Lande g-factor, 324–325
Langevin function, 322–324, 323f ,
326f , 327f
Langmuir, Irving
adsorption, 370–371, 371f
letter from Gilbert Norton Lewis, 247
Larché-Cahn (LC) solid, 216np
Latent heat, 45–47
Law of atmospheres, 158–159
Law of Dulong and Petit, 342–343
Law of mass action, 178–179, 444
Le Chatlier-Braun principle, 107
Le Chatlier principle, 107
Legendre transforms, 67–71
enthalpy, 69
equilibrium shape, 241–242
Gibbs free energy, 69
Helmholtz free energy, 68–69
Kramers potential, 69–70
Massieu functions, 70
natural variables, 71
relation to equilibrium shapes, 241–242
Lennard-Jones potential, 494
Lever rule, 128–129, 141
Liouville’s theorem, 278–280, 455–456
Liquidus, 147–148
Local equilibrium, 239
Lorentz force, 436
M
Macroscopic state variables, 3–4, 5
Macroscopic system, 3–4
in equilibrium state, 3
temperature, 3–5
Macrostate, 47–48, 257–258, 259, 260
Magnetic moment, 290–292
Magnetic susceptibility, vs.
temperature, 476f
Markov chain, 484–485
Markov process, 484–485
Massieu functions, 70
Matrix formulation, 544–546
Maximum term method, 273
Maxwell, James Clerk
-Boltzmann distribution, 255, 317–319,
338–340, 342
-Boltzmann statistics, 468
construction, 121, 133–135
distribution, 12–13
equation of electromagnetism, 299
relations, 41–42, 51–52, 56–57, 59, 69–70,
106, 115, 160
alternative method, 58–59
for open systems, 56–57
relationship of Cp to CV , 22, 57–59
relations among partial derivatives
monocomponent systems, 41
multicomponent systems, 55–59
MC, see Monte Carlo simulation (MC)
Mean curvature, 518
Mean-ﬁeld approximation, 471

582
Index
Mean ﬁeld model, 472–474, 482–483
Metastable, 129–130
Method of intercepts, 73–75, 139–141
Metropolis algorithm, 485
Microcanonical ensemble, 257, 258, 457. See also
Classical microcanonical ensemble
average vs. time average, 259–260
canonical ensemble derivation from,
305–312
classical systems, 257, 277
harmonic oscillators in 3-d, 283–284
ideal gas, 281–283
Liouville’s theorem, 278–280
state density of phase space, 277
deﬁnition, 258
entropy of mixing, 275–276
equilibrium of two-state systems, 523–527
fundamental hypothesis, 258–260
harmonic oscillator, 265–267
ideal gas, 267–273
Gibbs correction for extensivity, 268–271
isolated system, 257–258
two-state systems, 261–264
extensively of entropy, 261np
Microstates, 258
Minimum gamma-plot, 234–235
Miscibility gap
binary system, 139–141
solid-liquid, 146–148
solid-solid, 150f
equations for, 146–148
explicit equations for, 130–131
monocomponent system, 109, 118–119
phase equilibrium and, 127–131
Mixed state. See Statistical states
Mole fractions, 62
Moment of inertia, 537–539
diatomic molecule, 538–539
Monatomic ideal gas, 267–268, 381–382
with Gibbs correction factor, 268–271
Monocomponent, 111–113
Clausius-Clapeyron equation, 110–115
coexistence curves, 109–110, 113–114
critical point, 109–110
melting temperature vs. pressure, 114
miscibility gap, 118–119
phase diagram, v, p plane, 118–119
sketches of thermodynamic functions in
T, p plane, 115–118
system, 504–507
triple point, 109–110
vapor pressure, 111–113
Monocomponent phase equilibrium, 109–110
Clausius-Clapeyron equation, 110–115
miscibility gaps, 118–119, 119f
relative magnitudes, approximation,
114–115
single phase region, 109–110, 116–118
solid-liquid coexistence curve,
approximation, 113–114
thermodynamic functions, sketching,
115–118
two phase transitions, 116, 118
vapor pressure curve, approximation,
111–113
in v, p plane, 118–119
Monovalent crystals, 391–393
Monte Carlo (MC) simulation
of classical particles, 491–494
Ising model, 484–491
Multicomponent ideal gas, 273–276
in gravity, 160–162
Multicomponent open systems, 55–59
Multicomponent system
grand canonical ensemble, 388–389
partial molar quantities, 74–75
Multiplicity function, 261
for harmonic oscillators, 265f
Mutual exclusivity, 247–248
N
Natural function, 62–63, 63np
Natural irreversible process, 32, 33–34,
76, 77
Natural process, 31, 47–48
Natural variables, 62–63, 63np, 71–72, 95, 96,
96np, 102, 104–105
extensive/intensive, 104
sets of thermodynamic functions, 92–93
Negative ion interstitial, 395

Index
583
Negative ion vacancy, 394
Nernst, Walther, 49–50
postulate, 49–50
Net ionized donor concentration, 448
Neumann, John von, 203
Neumann triangle, 203
Non-uniform gravitational ﬁeld, 164
Normalized Gaussian distribution, 317–319
O
Occupation numbers, 368, 466–467, 468
One-dimensional harmonic oscillator, 460–461
Onsager, Lars
exact solution for two-dimensional Ising
model, square lattice, 472–474
for other two-dimensional lattices, 483–484
Open thermodynamic systems, 53
entropy of chemical reaction, 75–78
Euler theorem of homogeneous functions,
59–64
fugacity, 64–67, 65f
ideal gas, 54–55
legendre transformations, 67–71
Maxwell relations for, 56–59
multicomponent systems, 55–59
partial molar quantities, 71–75
single component system, 53–55
Orbitals, 368, 378–380
P
Pair distribution function, 349–350, 350f
Pair statistics
average for mean ﬁeld, 477–478
Ising model, 477–478
Paradox entropy vs. energy criteria, 84–85
Paramagnetism, 290–292
adiabatic demagnetization, 329–330
classical treatment, 322–324
Curie constant, 322–324
Langevin function, 322–324, 323f ,
326f , 327f
phenomenon, 321
properties, 327–329
quantum treatment, 324–327
Partial molar quantities, 71–75
binary system, 73–74
intercepts method, 73–75
multicomponent system, 74–75
Partial pressures, 274
Particle number dispersion, 366–367
Partition function, 286–287. See also Classical
partition function
approximate, thermodynamic perturbation
theory, 549–552
canonical ensemble, 330–331
Pathria, 5–6, 268np, 269–270, 272–273, 280,
311–312, 340–341, 349–350, 376, 377–378,
415–416, 419, 461, 472–474, 477, 483–484,
488–489
Pauli, Wolfgang
exclusion principle, 368, 385, 425, 427, 432
degenerate Fermi gas, 427
hydrogen nuclei, 385
paramagnetism, 434
of electrons, 425, 433–436, 438
high temperatures, 435–436
low temperatures, 435
magnetic ﬁeld, 433–434
magnetic moment, 433–435
magnetization, 434
spin matrices
deﬁnition and properties, 461–462
magnetic moment of electron,
433–435
polarization vector, 462
Periodic boundary condition, 459–460
Phase
diagram, 109
binary system, 137, 145–146, 153
for ideal liquid/solid, 145–148
ideal solid and liquid, 145–148
monocomponent system, 110,
110f , 115f
v, p plane, 118–119
equilibrium and miscibility gap,
127–131
rule, 83–84
Phase space,
257, 277
available, 280
state density, 277

584
Index
Planar interfaces in ﬂuid
Cahn’s layer model, 192–197
discontinuity region, 186f
Gibbs adsorption equation, 190–192
Gibbs dividing surface model, 185,
187–190
immobile walls, 186–187
Planar solid-ﬂuid interfaces, 215–221. See also
Curved solid-ﬂuid interfaces
Planck, Max, xv, 20, 299, 302
blackbody radiation, 298–302
energy quantization hypothesis, 299–302
Planck’s constant, 55, 260, 265, 281–283,
294–297
third law of thermodynamics, 49–50
Point defects, 391–396
Frenkel, 395
in ionic crystals, 394–396
Schottky, 391, 395
vacancies, divacancies and interstitials, 392t,
393–394
Poisson bracket, 279
Poisson distribution, 378–379
Polarization vector, 462
Polyatomic molecular gas, 387–388
Polynomial coefﬁcient, 497
Positive ion interstitial, 395
Positive ion vacancy, 394
Potential energy, 8–9
Pressure, 3. See also Constant pressure
dependence of K(T, p), 182
of ideal gas, 12–13
standard atmosphere, 4
Pressure ensemble, 389–390, 397, 401–402
Pressure, ideal gas, 12
Prigogine, Ilya, 77, 170np, 178–179, 182–183
Principle of detailed balance, 486–487
Probability density function, 337np
Probable distribution, 397
Progress variable
afﬁnity and, 174f
heat of reaction, 170
for reaction, 167, 167np
simultaneous reactions, 182–183
Projection operator, 451–452, 454–455, 461,
463–464
Pure state, 257, 451–452
Q
Quantum concentration, 270–271, 273–274, 315
Quantum energy levels, 547
Quantum mechanics, 257, 258, 268
complete analysis, 270–271
Quantum statistics, electron gas, 428
Quantum treatment, of paramagnetism,
324–327
Quasi-continuous energies, 406
Quasi-isolated systems, 260
Quasistatic work, 17–19. See also Reversible work
R
Rankine scale, 4–5
Reaction product, 176
Reaction quotient, 177
Real gases, chemical potential of, 64–67
Reference state, adsorption equation in, 218–219
Regular solution, 148–152
Relative magnitudes, approximation, 114–115
Renormalization group (RG), 488–489
Reversible adiabatic expansion, 25–27
Reversible isobaric expansion, 24–25
Reversible isothermal process, 24
Reversible work. See Quasistatic work
RG. See Renormalization group (RG)
Richardson-Dushman equation, 439–440
Richard’s rule, 46–47, 114–115
Rigid body
angular momentum, 539
canonical momenta, 546
canonical variables, 546
Euler angles, 544, 545–546
kinetic energy, 540
matrix formulation, 544–546
moment of inertia, 537–539
rotating coordinate system, 541–544
rotating rigid polyatomic molecules,
356–358
rotation of, 537–539, 540–546, 547
time derivatives, 540–541, 542–544
Rigid linear rotator, 303–304, 556

Index
585
Rotated surface element in shape of
parallelogram, 225, 225f
Rotating coordinate system, 541–544
Rotating systems, external forces, 164–166
S
Sackur-Tetrode equation, 315–316
Saturation magnetic moment, 290–292,
322–324, 326
Scaling analysis, ideal gas, 272–273
Schottky defects, 391
Schottky effect, 441
Schottky peak, 292–293
Schrödinger, Erwin, 293–294
representation, 451
Second law of thermodynamics
Carnot cycle and engines, 35–38
combined with ﬁrst law, 41–47
composite system, 32–34
discussion of, 33–35
entropy change, calculation, 39
entropy, statistical interpretation, 47–48
irreversible process, 31–32, 33–34, 37
latent heat, 45–47
statement of, 32–35
Semiconductors
acceptors from valence band, 442–443
band gap, 442
conduction band, 442–444, 446, 447f
degenerate, 449–450
density of states vs. electron
energy, 443f
donors to conduction band, 442–443
dopants, 446–449
with dopants, 446–449
electrons in conduction band, 442–443
holes in valence band, 442
intrinsic, 443–446
non-degenerate, 443–444
statistical mechanics of, 442
valence band, 442–444, 446, 447f
Series expansions, 408
virial expansions, 410
Sessile bubble, 210–211, 212f
Sessile drops, 185–186, 210–211
Shannon, Claude, 247
Shannon’s information function, 247
Single component open system, 53–55
Single free particle
momentum operator, 459, 460
periodic boundary condition, 459–460
Single particle
in one dimension, 8–9
in three dimensions, 9–10
Solenoidal ﬂow, 278–279
Solid-ﬂuid interfaces
aspects, 215
curved, 227–233
planar, 215–221
Solid-liquid coexistence curve, approximation,
113–114
Solid-solid interfaces, 242–243
Solidus, 147–148
Sommerfeld, Arnold, 409–410, 430–432
Sommerfeld expansion, 409–410, 430–432
Spectral distribution, blackbody radiation, 301
Spin excess, 263–264
Spin Hamiltonian, 469
Spinodal
curve, 124
and miscibility gap,
127–131
regular solution, 148–152
Spinodal curve, 149–150, 150f , 152
van der Waals ﬂuid, 124
Spinor for spin 1/2, 461
Spin-spin interaction, in zero magnetic
ﬁeld, 481
Stability
convexity vs. concavity of functions
enthalpy H, 102–103
entropy S, 104
Gibbs free energy G, 103–104
Helmholtz free energy F, 103
internal energy, U, 100–102
inequalities resulting from, 101–102
local condition, 100–101
metastable, 97–98, 124, 127, 129–130, 141,
493–494
thermodynamic, 95–107

586
Index
Stability requirements
concave function, 95–96, 100
consequences of, 105–106
convex function, 100–102
Cramer’s rule, 99–100
for enthalpy, 102–103
for entropy, 95–100
extension to many variables, 106–107
Gibbs free energy, 103–104
globally unstable, 97–98, 97f , 100
Helmholtz free energy, 103
for internal energy, 100–102
Le Chatlier and Le Chatlier-Braun principles,
107
locally stable, 97f , 98–99, 98f
metastable, 97f
Standard states, 171–173
explicit equilibrium conditions, 175
State, 3
equations of, 20–21, 23, 41, 42, 43–45, 54, 61,
121–124, 137–138, 139, 492, 493
equilibrium, 3
function, entropy, 32
function, internal energy, 15–16
variables, 3, 5
State function, 5–14, 15–17, 31, 35, 38,
44, 47
for inﬁnitesimal changes, 53
and Maxwell relations, 59
relation to partial molar quantities, 71
relation to chemical reactions and Hess’s law,
171
and information theory, 247–256
State variables, 15–16
classiﬁcation of, 6–8
Stationary quantum states, 257
Statistical density operator, 453, 454
assumption of random phases, 454
description of random phases/external
inﬂuence, 454–455
Statistical mechanics
fundamental hypothesis, 258–260
of quantum systems
density matrix, 459–465
indistinguishable particles, 465–468
orthonormal external states, 454–455
pure time-dependent state, 451–452
randomphases, 454–455
statistical density operators, 456–458
statistical states, 453–454
time evolution, 455–456
thermodynamics vs., 5–6
Statistical states, 257, 453
Stefan-Boltzmann constant, 301
Stirling’s approximation, 261, 261np, 286–287,
497–498
accuracy of, 498t
asymptotic vs. convergent series, 500–501
elementary motivation, 498–499
equation, 497, 498
gamma function, 499–500
harmonic oscillators, 266
two-state subsystems, 261
Stirling’s asymptotic series, 499–500
Stokes curl theorem on a surface, 516
Summation, over energy levels, 402–403
Surface
differential geometry, 509–521
differential operators, 513–515
dipoles, 439
divergence and curl theorems, 511
divergence theorem, 515–516
excess quantities, 187–188
free energy, 188–189, 189np
gradient, Laplacian, curl, 509
strain, 225np
stress tensor, 215–216
of tension, 198
Symmetric boson states, 465–466
Symmetry number, 386
Symplectic group, 354, 529–530
transformation, 532–534
System of particles, 10–12
T
Taylor series, 430–431
Temperature, 3–5
absolute, 4
thermodynamic deﬁnition, 32np
dependence of K(T, p), 180, 181

Index
587
empirical, 4
scales, 3–4
Theorem
Eta theorem of Boltzmann, 247, 254–256
Euler theorem of homogeneous functions,
59–60
applied to extensive functions, 60–61
applied to intensive functions, 63–64
factorization of partition function, 312–313
Gauss divergence, 515–516
Herring, 234
integral theorems for surfaces, 515–516
Liouville’s, 278–280, 456
virial, 346–348
Wigner-Eckart, 324np
Wulff, 227–228
Thermal activation of electrons
heat capacity, 432–433
sommerfeld expansion, 430–432
Thermal contact, 5
Thermal expansion, isobaric
coefﬁcient, 22
Thermionic emission, 439
photoelectric effect, 441–442
Schottky effect, 441
work function, 439
Thermodynamic functions
Bose condensation, 416–421
monocomponent systems, 115–118
for van der Waals ﬂuid, 124–127
Thermodynamic perturbation theory
classical case, 549–550
quantum case, 550–552
unperturbed Hamiltonian, 549
Thermodynamics, 5
of binary solutions, 137–141
curved solid-ﬂuid interfaces, 227–233
degrees of freedom, 7–8
planar solid-ﬂuid interfaces, 215–221
vs. statistical, 5–6
Thermometer, 3–4
Third law of thermodynamics
discussion of, 49–50
experimental veriﬁcation, 49–50
implications of, 50–52
implications re materials properties,
50–52
Maxwell relation, 51–52
statement of, 49–50
Thomson, Sir William (Lord Kelvin)
expansion of gas though porous plug, 21
postulate concerning second law, 31–33,
37
Time derivatives, 540–541
revisited, 542–544
Transfer matrix, 480–483
Transformations, canonical
general transformation, 529–530
Jacobian value, 354–356, 529–530, 532–533
necessary and sufﬁcient conditions,
530–534
restricted transformation, 534–535
symplectic transformation, 532–534
use of, 354–356
Triple junctions, 226–227
Triple line, 202–205
Triple point, 109, 119f
Trouton’s rule, 46–47, 114–115
Two-state subsystems, 261–264
entropy, 292f
entropy vs. temperature, 264f
equilibrium of, 523–527
magnetic moment, 290–292, 292f
paramagnetism, 290–292
spin 1/2, 289–290, 290f
temperature, 292f
temperature vs. energy, 262f , 263f
U
Uniform gravitational ﬁeld, 157–164
binary liquid, 162–164
multicomponent ideal gas, 160–162
Unperturbed Hamiltonian, 549
V
Vacancies, 393–394
deﬁnition, 391
ionic crystals, 394–396
in monovalent crystals, 391–393
Vacuum state, 363, 564
Valence band, 442–444, 446, 447f , 449

588
Index
van der Waals, Johannes, 121–131
van der Waals ﬂuid
chord construction, 129–130, 129f
common tangent construction, 127–129,
129f
constant a, 126–127
equation of state, 121–124
f(v) Curves, 130
Gibbs free energy, 129–130, 131–135
Helmholtz free energy, 124–125
isotherms, 122–124
isotherms in p, g plane, 132f
isotherms in v, p plane, 118–119
liquid vapor equilibrium, 121
Maxwell construction, 133–135
metastable, 130
miscibility gap, 130–131
non-monotonic isotherms, 122–123
phase equilibrium and miscibility gap,
127–131
spinodal curve, 124
stable, 130
thermodynamic functions, 124–127
unstable, 130
van’t Hoff, Jacobus, 180
van’t Hoff equation, 180
Vapor pressure
curve approximation, 111–113
monocomponent, 109–110
Variable, 5
conjugate, 47, 67–68
extensive, 7
intensive, 7
state, 3, 5
Variational formulation, 519–521
Virial
coefﬁcients
classical canonical ensemble, 348–354
pair distribution function, 349–350, 350f
expansion, 348, 352
for Fermi and Bose gases, 410–412
ideal Fermi and Bose gases, 410–412
series expansions, 410
theorem, 346–348
time averaging, 346
Virtual variation, 155–156
W
Weighting factors, 453, 468
Weiss molecular ﬁeld approximation, 471np
Wien, Wilhelm, 301–302
displacement law, 301–302
Wigner-Eckart theorem, 324np
Wilson, Kenneth, 488–489
Work, 9–10
dependence on path, 18–19
function, 439–440, 441
mechanical, 9–10, 15
quasistatic, reversible, 17–19
sign convention, 16np
Wulff construction, 227–228, 521
Wulff planes, 227–228
Wulff theorem, 227–228
X
Xi (ξ)-plot, 227, 228f
Xi (ξ)-vector, 215–216
alternative formulae for, 509–511
for discontinuous gamma-plot, 228–232
equilibrium shape from, 236–239
fan of vectors, 231f
for general surfaces, 516–519
Herring sphere, 230f
Y
Young’s equation, 204
Z
Zero ﬁeld, 479–480
Zero of energy, 8–9
Zero of entropy, 49–50

Values of Selected Physical Constants
Name and symbol
SI value and units
cgs value and units
Magnitude of electronic charge, e
1.602177×10−19 C
4.80324×10−2 esu
Electron volt, eV
1.602177×10−19 J
1.602177×10−12 erg
Boltzmann’s constant, kB
1.380649 ×10−23 J K−1
1.380649 ×10−16 erg K−1
Boltzmann’s constant, kB
8.6173 ×10−5 eV K−1
Planck’s constant, h
6.626070 ×10−34J s
6.626070 ×10−27 erg s
Planck’s constant, h
4.135668×10−15 eV s
Planck’s constant h-bar, ¯h = h/2π
1.054572 ×10−34 J s
1.054572 ×10−27 erg s
Planck’s constant h-bar, ¯h = h/2π
6.582120 ×10−16 eV s
Constant in ¯hω/kBT, ¯h/kB
7.638234 K s
7.638234 K s
Avogadro’s number, NA
6.022141 ×1023 mol−1
6.022141 ×1023 mol−1
Measure of heat, cal
1.05587 ×103 J
1.05587 ×107 erg
British thermal unit (mean), Btu
4.184 J
4.184 ×107 erg
Gas constant, R = NAkB
8.31446 J mol−1
8.31446 ×107 erg mol−1
Gas constant, R = NAkB
5.189 ×1019 eV mol−1
Gas constant, R = NAkB
1.987 calmol−1
1.987 calmol−1
Measure of pressure, Pa
1 N m−2
10 dyne cm−2
Standard atmosphere of pressure, atm
1.01325 ×105 Pa
1.01325 ×106dyne cm−2
cm of mercury, cmHg
1.333224×103 Pa
1.333224×104 dyne cm−2
Electron rest mass, m
9.109384×10−31 kg
9.109384×10−28 g
Proton rest mass, mp
1.6726×10−27 kg
1.6726×10−24 g
Neutron rest mass, mn
1.674920×10−27 kg
1.674920×10−24 g
Ratio of proton mass to electron mass, mp/m
1836.153
1836.153
Atomic mass unit amu, u
1.660539×10−27 kg
1.660539×10−24 g
Speed of light, c
2.99792458×108m s−1
2.99792458×1010cm s−1
Bohr magneton, μB = e ¯h/2m
9.2740×10−24 J T−1
Bohr magneton, μB = e ¯h/2m
5.788382 ×10−5 eV T−1
5.788382 ×10−9 eV G−1
Bohr magneton, μB = e ¯h/2mc
9.274 ×10−21 erg G −1
Nuclear magneton, μN = e ¯h/2mp
5.050784 ×10−27 J T−1
Nuclear magneton, μN = e ¯h/2mpc
5.050784 ×10−24erg G −1
Steffan-Boltzmann constant, σ = π2k4
B/(60 ¯h3c2)
5.670×10−8 W m−2 K −4
5.670×10−5 erg s−1 cm−2 K−4
Reciprocal ﬁne structure constant, α−1 = ¯hc/e2
137.036
137.036
Electron Compton wavelength, λe = ¯h2/mc
3.86159×10−15 m
3.86159 ×10−13 cm
Electron radius, re = e2/mc2
2.817940×10−13 m
2.817940 ×10−11 cm
kBT = 1 eV
T = 1.16 × 104 K
T = 1.16 × 104 K
hν = ¯hω = 1 eV
ν = 2.42 × 1014 Hz
ω = 2πν = 15.2 × 1014 s−1
Faraday constant, F = eNA
9.648670 ×104 C mol−1
9.648670 ×104 C mol−1
Universal gravitational constant, G
6.674 ×10−11 N m2 kg−2
6.674 ×10−8 dyne cm2g−2
Avogadro’s number is also known as Lodschmidt’s number, L. See http://physics.nist.gov/cuu/constants for the latest recommended
values. C= coulomb, cal = calorie, Pa = N m−2 = pascal, W = J/s = watt, G = gauss, T = tesla = 104 G, esu = electrostatic units.

