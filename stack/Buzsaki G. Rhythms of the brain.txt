Rhythms of the Brain
György Buzsáki
OXFORD UNIVERSITY PRESS

Rhythms of the Brain

This page intentionally left blank 

Rhythms of the
Brain
György Buzsáki
1
2006

3
Oxford University Press, Inc., publishes works that further
Oxford University’s objective of excellence
in research, scholarship, and education.
Oxford New York
Auckland Cape Town Dar es Salaam Hong Kong Karachi
Kuala Lumpur Madrid Melbourne Mexico City Nairobi
New Delhi Shanghai Taipei Toronto
With ofﬁces in
Argentina Austria Brazil Chile Czech Republic France Greece
Guatemala Hungary Italy Japan Poland Portugal Singapore
South Korea Switzerland Thailand Turkey Ukraine Vietnam
Copyright © 2006 by Oxford University Press, Inc.
Published by Oxford University Press, Inc.
198 Madison Avenue, New York, New York 10016
www.oup.com
Oxford is a registered trademark of Oxford University Press
All rights reserved. No part of this publication may be reproduced,
stored in a retrieval system, or transmitted, in any form or by any means,
electronic, mechanical, photocopying, recording, or otherwise,
without the prior permission of Oxford University Press.
Library of Congress Cataloging-in-Publication Data
Buzsáki, G.
Rhythms of the brain / György Buzsáki.
p.
cm.
Includes bibliographical references and index.
ISBN-13 978-0-19-530106-9
ISBN 0-19-530106-4
1. Brain—Physiology.
2. Oscillations.
3. Biological rhythms.
[DNLM:
1. Brain—physiology.
2. Cortical Synchronization.
3. Periodicity. WL 300 B992r 2006]
I. Title.
QP376.B88 2006
612.8'2—dc22
2006003082
9 8 7 6 5 4 3 2 1
Printed in the United States of America
on acid-free paper

To my loved ones.

This page intentionally left blank 

The short punch line of this book is that brains are foretelling devices and their
predictive powers emerge from the various rhythms they perpetually generate. At
the same time, brain activity can be tuned to become an ideal observer of the en-
vironment, due to an organized system of rhythms. The speciﬁc physiological
functions of brain rhythms vary from the obvious to the utterly impenetrable. A
simple but persuasive example is walking. Bipedal walking is a periodic series of
forward falls interrupted regularly by alternate extensions of each leg. It is almost
as natural to us as breathing. This effortless exercise is made possible by the pre-
dictive nature of spinal cord oscillators. On smooth terrain, the alternation of leg
movements can take us any distance. Perturbation of the clocking, on the other
hand, signals a change in the terrain. This general mechanism is the same in all
animals, including eight-legged scorpions and centipedes. The notion that oscilla-
tors or “central pattern generators”1 are responsible for the coordination of motor
If the brain were simple enough for us to understand it, we would be too sim-
ple to understand it.
—Ken Hill
Prelude
1. Neural circuits that produce self-sustaining patterns of behavior are called central pattern gen-
erators. The most studied central pattern generator is an intraspinal network of neurons responsible for
locomotion. Grillner (1985) summarizes the pros and cons of the pacemaker view of central pattern
generators in the spinal cord and brain. Stein et al. (1997) and Burke (2001) are nice updates on the
topic. Central pattern generators are also responsible for many other types of rhythmic movements,
e.g., peristaltic motor patterns of legless animals, rhythmic movement of the wings of crickets during
song production, respiration, heart control, movements of the stomach, and other parts of the digestive
system. My favorite review on this topic is Marder and Calabrese (1996).

patterns, such as breathing and walking, is old and well accepted in neuroscience.
But the tantalizing conjecture that neuronal oscillators can be exploited for a
plethora of other brain-generated functions, including cognition, is quite new and
controversial. And it is the latter topic, the contribution of oscillations to the in-
visible, inferred operations of the brain, that this book is mostly about.
Exposing the mechanisms that allow complicated things to happen in a coordi-
nated fashion in the brain has produced some of the most spectacular discoveries
of neuroscience. However, I do not want to mislead you from the outset. Clocks
are not thinking but ticking devices, no matter how precisely they can predict
time. Time needs to be ﬁlled with content, provided by the appropriate ﬁring pat-
terns of neurons, whose assembly activity, in turn, is regulated by brain oscilla-
tions. Interestingly, the neuronal assemblies that generate the content are often
the same as those that give rise to the time metric of oscillations that in turn orga-
nize the cell assembly pattern. This peculiar reciprocal causation, brought about
by the self-organized features of brain activity, begs for an explanation. A good
part of the volume is devoted to discussing experiments that attempt to elucidate
these emerging properties of neuronal networks.
At the physiological level, oscillators do a great service for the brain: they co-
ordinate or “synchronize” various operations within and across neuronal net-
works. Syn (meaning same) and chronos (meaning time) together make sure that
everyone is up to the job and no one is left behind, the way the conductor creates
temporal order among the large number of instruments in an orchestra. A close
view of Seiji Ozawa at the end of a concert, sweat falling from his face, is proof
that conducting an orchestra is a physically and mentally demanding job. In con-
trast, coupled oscillators perform the job of synchronization virtually effortlessly.
This feature is built into their nature. In fact, oscillators do not do much else. They
synchronize and predict. Yet, take away these features, and our brains will no
longer work. Compromise them, and we will be treated for epilepsy, Parkinson’s
disease, sleep disorders, and other rhythm-based cognitive maladies. As I point
out repeatedly in Cycles 1–13 of this volume, virtually no nervous function exists
without a time metric, be it the simplest motor or the most complex cognitive act.
While we know quite a bit about neurons, the building blocks of the brain, and
have extensive knowledge about their connectivity, we still know very little how
the modules and systems of modules work together. This is where oscillations of-
fer their invaluable services.
My connection with brain rhythms began in April 1970, during a physiology
lecture given by Endre Grastyán in the beautiful town of Pécs, on the sunny slopes
of the Mecsek mountains in Hungary. The University of Pécs, or Universitas
Quinque Ecclesiensis, as it was called when founded in 1367, has produced a re-
markable set of neuroscientists, including János Szentágothai, the legendary neu-
roanatomist; Béla Flerkó and Béla Halász, pioneers of neuroendocrinology;
György Székely, the renowned spinal cord physiologist; and Ferenc Gallyas, the
creator of the silver impregnation methods widely used for neuronal labeling.
Like many of us at a young age, in his twenties Grastyán could not quite make
up his mind about his future. Finding nothing too interesting or challenging initially,
viii
Prelude

he decided to train for the priesthood to get some orientation in philosophy. But
his mind, far too curious and questioning, prevented him from becoming a
preacher. He ended up in medical school during the stormy years after World War
II and became the assistant of Professor Kálmán Lissák. Lissák, a student of Otto
Loewi in Graz, Austria, and subsequently Walter Cannon’s assistant at Harvard,
had returned to Hungary to become Chair of Physiology just before the war.
Grastyán’s pairing with Lissák was fortunate because Lissák, of course, knew
quite a bit about rhythms from his years with Loewi, who provided the ﬁrst evi-
dence that a chemical—a neurotransmitter—is released at the junction (synapse)
between the vagus nerve and the heart muscle.2 Although Grastyán was perhaps
Lissák’s closest friend, the two were as different as can be. Lissák was a reserved
man, and his lectures were scarcely attended. In contrast, Grastyán was a per-
forming artist whose seminars were carefully composed and choreographed. The
huge lecture room in the medical school was always packed, and even students
from the neighboring law school came over to listen to his mesmerizing lectures.
He generated so much enthusiasm that we students became convinced that the
topics he discussed were among the most important in the whole universe.
In that particular lecture of April 1970, he talked about how the brain outputs,
such as movement and cognition, control its inputs, rather than the other way
around. His key idea was that control in living systems begins with the output. This
is the seed for further evolution of the brain. Even in the most complex animals,
the goal of cognition is the guidance of action. Indeed, the ﬁrst simple biological
systems did not have any inputs; they did not need them. They simply used an eco-
nomical motor output, a rhythmic contraction of muscles. This is, of course, is suf-
ﬁcient only when food is abundant in the sea environment. More complex forms of
life evolved form this simple solution by modifying the simple rhythmic output.
Sensation of direction and distance developed only after the “invention” of move-
ment through space. The idea of output control and feedback is a profound thought
even today. Back then, when Pavlovian sensory–sensory association was the dom-
inant ideology in the East and the stimulus–decision–response paradigm domi-
nated Western thinking, Grastyán’s teachings were unusual, to say the least.
After his lecture, I rushed home to read the relevant chapters in our ofﬁcial
Prelude
ix
2. Loewi called the chemical “Vagusstoff,” which Henry Hallett Dale from Cambridge, England,
identiﬁed later as acetylcholine, the ﬁrst neurotransmitter. They received the Nobel Prize for their dis-
coveries in 1936. I have heard various versions of the story behind the Vagustoff experiment from Lis-
sák. Here is one from Loewi’s own pen:
The night before Easter Sunday of that year I awoke, turned on the light, and jotted down a few
notes on a tiny slip of thin paper. Then I felt asleep again. It occurred to me at six o’clock in the
morning that I had written down something most important, but I was unable to decipher the scrawl.
The next night, at three o’clock, the idea returned. It was the experiment to determine whether or
not the hypothesis of chemical transmission that I had thought about years ago was correct. I got up
immediately, went to the laboratory, and performed a simple experiment on a frog heart according
to the nocturnal design. (Loewi, 1960, 15) 
Dale became better known about his “principle”: if a chemical is released in one synapse, the same
chemical is released in all the other synapses made by the same neuron.

textbook only to realize that there was not a single word there about what I had
heard that morning.3 Nevertheless, beginning with Grastyán’s introductory lec-
ture on the organization of the brain, my life in medical school acquired new
meaning. My original high school plan to become an electrical engineer was ve-
toed by my parents, who offered me the choice between medical school and law
school. While my friends were having fun at the School of Engineering in Bu-
dapest, learning exciting stories about radio transmission and electronic oscilla-
tors, I spent most of my time studying the unending details of bones and
ligaments. But in his physiology lecture, Grastyán was talking about some truly
intriguing questions that sparked my interest. I applied to become his apprentice
and spent most of my student life in his lab.
The best training in Grastyán’s laboratory occurred through my participation
in the regular lunch discussions that could go on for several hours, where topics
meandered chaotically from homeostatic regulations of the brain to complex
philosophical topics. It was during these lunch lessons where I ﬁrst learned about
the hippocampal “theta” rhythm, the oscillation that has become my obsession
ever since. My ﬁrst assignment in the Grastyán school, under the supervision of
György Karmos, was to examine the variability of the evoked responses in the
hippocampus and auditory cortex in response to sound stimuli as a function of be-
havior. In a nutshell, our main ﬁnding was that the most important factor in pre-
dicting the variability of the evoked brain responses was the variability of the
background brain activity. This was the ﬁrst time I faced the fascinating issues of
“state,” “context,” and “spontaneous” activity, problems that remained with me
forever.
As I have repeatedly discovered in my career, the informal lunch-seminar ap-
proach to science is hard to substitute with formal lectures or the reading of dense
scientiﬁc papers. Seminars are tailored for an average group of people with the
naive assumption that the audience retains all the details and follows and accepts
the fundamental logic of the lecturer. In contrast, the essence of lunch conversa-
tions is to question the fundamental logic, a quest for clariﬁcation and simpliﬁca-
tion, a search for explanations and answers without a rigid agenda, where the
focus is not on covering large chunks of material but on fully understanding even
the smallest details. Of course, one can follow up a lecture by ﬁnding and reading
the relevant published papers on the topic. However, most of the exciting ﬁndings
in neuroscience are hidden in the small print of specialty journals, often written in
a specialized and arcane language comprehensible to, at most, a handful of spe-
cialists. Overwhelmed with new and important discoveries in the various sub-
subspecialties, the practicing neuroscientist, such as myself, tends to forget that
x
Prelude
3. The idea that the brain’s main goal is to control movement has been repeatedly emphasized by
several outstanding individuals. Indeed, the brain’s only means of interacting with the world is via the
motor system, whether foraging for food or communicating by speech, gestures, writing a paper, or
sending an e-mail. The outstanding books by Gallistel (1980) and Llinás (2001) discuss this point elo-
quently. The “primacy” of movement has been emphasized by Hamburger et al. (1966) and Bullock
and Horridge (1965). For recent reviews on this topic, I suggest Hall and Oppenheim (1987), Wolpert
and Ghahramani (2000), and Robinson and Kleven (2005).

neuroscience is of startling relevance to a contemporary society wrestling with
complex issues such as social behavior, depression, and brain aging. It is hard to
predict which of the numerous fundamental discoveries could alter the face of
such large issues, and unless they are conveyed to others, they might be over-
looked without making an impact. This is mainly so because the explanations we
provide in papers to the superspecialists may be impenetrable to the uninitiated.
Without attempting to place our work into a larger context from time to time, we
deprive ourselves of the chance to be able connect to the more macroscopic and
microscopic levels of research. Yet, discoveries and insights realize their power
only when understood by others. Understanding this important connection is
what mostly motivated me to write this volume.
Neuroscience has provided us some astonishing breakthroughs, from noninva-
sive imaging of the human brain to uncovering the molecular mechanisms of
some complex processes and disease states. Nevertheless, what makes the brain
so special and fundamentally different from all other living tissue is its organized
action in time. This temporal domain is where the importance of research on neu-
ronal oscillators is indispensable, and it is this temporal domain that connects the
work discussed in this volume to all other areas of neuroscience.
Parallel with the amazing progress in neuroscience, another discipline has
emerged: complex systems, a new science that cuts across many ﬁelds. During the
past decade, I have learned as much about the brain by reading about novel
branches of physics, engineering, mathematics, and computer science as I did
from studying papers directly dealing with the nervous tissue. Rest assured, the
human brain is the most complicated machinery ever created by nature. Never-
theless, it is truly exciting looking for concepts, mechanisms, and explanations
that are common among many different systems and cut across the living/nonliv-
ing dichotomy. Seemingly unlikely sources such as fractals and Internet commu-
nication have provided novel clues for understanding neuronal networks. My goal
is to illustrate how this new knowledge is being incorporated into neuroscience at
a breathtakingly high speed and to convey fascinating discoveries to neuroscien-
tists, psychiatrists, neurologists, and the growing group of computational scien-
tists, physicists, engineers, and mathematicians interested in complex systems. A
covert agenda is that, along the way, describing these new discoveries will en-
courage outsiders to become brain rhythm enthusiasts.
Deciphering the code of the brain will have a lasting impact on our society. It
is not simply an intellectual exercise for a handful of esoteric individuals any-
more. It is also more than a “just” a brain-health–related issue, which affects mil-
lions in the United States and many more worldwide. As Robert Noyce, the
co-inventor of the integrated circuit, once put it: “In order to understand the brain,
we have used the computer as a model for it. Perhaps it is time to reverse this rea-
soning. To understand where we should go with the computer, we should look to
the brain for some clues.” Now that our economy, ﬁnancial institutions, education
system, research programs, distribution systems, human interactions, politics, and
defense have all become computer and Internet dependent, this quest is more
acute than ever. The hope is that the new knowledge about the brain will not only
Prelude
xi

inspire novel designs for computer architectures and a more efﬁcient and safer
electronic communication but also, at the same time, provide a better understand-
ing of ourselves. Books, computers, and Internet communication have external-
ized brain functions and provided virtually unlimited storage space for the
accumulated knowledge of humankind. However, this externalized information is
only as useful as its accessibility. Currently existing search engines, such as
Google and Yahoo, that provide access to this externalized knowledge are very in-
efﬁcient (even though they are the best available at present) compared to the
brain’s ability to retrieve episodic information, because neuronal networks utilize
fundamentally different strategies for the reconstruction of events and stories
from fragments than do search engines. Understanding the brain’s search strate-
gies may allow us individuals to have better access to the cumulative knowledge
of humankind.
Writing to a general audience interested in neuroscience is a much more ardu-
ous exercise than writing scientiﬁc papers. Scientists, rather than just the science
they have produced, and metaphors that are deliberately absent in specialty jour-
nals come to the fore. This process inevitably implies oversimpliﬁcation from the
experts’ viewpoint, occasional redundancies, and some rugged transitions for the
novice. To alleviate the inevitable, I have written a simpliﬁed main story, which I
hope to be a relatively easy read in most Cycles. Each Cycle ends with a brief
summary, which highlights the primary message of the Cycle. The main story is
supplemented by extensive footnotes, which serve partly to deﬁne novel terms. In
most cases, however, they provide further critical information for the more so-
phisticated reader, along with links to the appropriate literature. I have deliber-
ately chosen this format because it allowed me to interweave the main story and
its more complex ramiﬁcations without breaking the ﬂow of thought. The addi-
tional comments and citations in the footnotes give rise to an ever-growing tree
with intertwined branches of arguments, hypotheses, and discovery.
A couple of years ago, we hosted a painter in our house for the summer. His
determined goal was to survey and conquer the New York City art market. Yet, af-
ter a month or so, he plainly declared to us that every painting has already been
painted and the art dealers are aware of all potential innovators in case the market
is in need of such redundancy. He returned to Europe the next day. This is how I
felt while writing this book. Clarity, critical details, and giving proper credit com-
pete for space, and achieving the appropriate balance is the most difﬁcult thing in
writing a book. The more I explored the mysteries of brain oscillators and neu-
ronal functions, the more I realized that the fundamental ideas (some which I
thought were genuinely mine) have already been expressed, often repeatedly.
Many times the ideas have come up in studying systems other than the brain, or
they were expressed in a different context. But they existed. The deeper I ventured
into the problems, the further back in time I had to travel to discover the origin of
thoughts.
An oft-heard marketing slogan these days is that we have learned more about
the brain during the past decade that during the previous history of humankind.
This may be true regarding the volume of factual knowledge. But discoveries are
xii
Prelude

not ( just) facts. They are ideas that simplify large bags of factual knowledge.
Such fundamental ideas rarely pop up suddenly. Typically, they slowly emerge af-
ter appropriately long incubation periods and are shaped by numerous proponents
and critics. Fundamental ideas are rare, and probably as many have been con-
ceived prior to modern neuroscience as in the past few decades. One just has to
recognize and adapt the old thoughts to the new lingo and the ﬁndings we have re-
cently generated. My dear mentor advised me in my student days, “do not publish
when you have only data but when you have a novel idea.” If I followed his advice
strictly, I would perhaps still be writing my ﬁrst paper and this volume would not
exist. Although I honestly attempted to reach a balance between summarizing
large chunks of work by many, and crediting the deserved ones, I am aware that I
did not always succeed. I apologize for those whose works I unintentionally ig-
nored or missed. To claim innocence, I shall simply shift the responsibility onto
those who kindly read some parts of the manuscript at various stages and did not
complain (enough). These generous colleagues include Kamran Diba, Caroline
Geisler , Robert L. Isaacson, Kai Kaila, Christof Koch, Nancy Kopell, Rodolfo
Llinás, Stephan Marguet, Edvard Moser, Denis Paré, Marc Raichle, Wolf Singer,
Anton Sirota, Paula Tallal, Jim Tepper, and Roger Traub. My dear friend Mircea
Steriade took the trouble of reading the entire manuscript and provided invaluable
feedback. My special thanks to Mary Lynn Gage for her attempts to transpose my
Hungarian-Zombi idioms into comprehensible English. This may not have al-
ways succeeded, and I would like to publicly apologize for humiliating Shake-
speare’s beautiful language here and there.
At a more general level, I would like to express my gratitude to a number of
people whose examples, support, and encouragement sustained me in difﬁcult
times and whose collaborations, inspiring discussions, and criticism have served
as constant reminders of the wonderful collegiality of our profession—David
Amaral, Per Andersen, Albert-László Barabási, Reginald Bickford, Yehezkel Ben-
Ari, Anders Björklund, Brian Bland, Alex Borbely, Ted Bullock, Jan Bures, Gábor
Czéh, János Czopf, Eduardo Eidelberg, Jerome (Pete) Engel, Steve Fox, Walter
Freeman, Fred (Rusty) Gage, Mel Goodale, Charlie Gray, James McGaugh,
Michale Fee, Tamás Freund, Helmut Haas, Michael Häusser, Walter Heiligenberg,
Bob Isaacson, Michael Kahana, George Karmos, Nancy Kopell, Lóránd Kellényi,
Gilles Laurent, Joe LeDoux, Stan Leung, John Lisman, Rodolfo Llinás, Nikos Lo-
gothetis, Fernando Lopes da Silva, Jeff Magee, Joe Martinez, Bruce McEwen,
Bruce McNaughton, Richard Miles, István Mody, Robert Muller, John O’Keefe,
Marc Raichle, Jim Ranck, Menahem Segal, Terry Sejnowski, Larry Squire, Wolf
Singer, David Smith, Peter Somogyi, Mircea Steriade, Steve Strogatz, Karel Svo-
boda, David Tank, Jim Tepper, Alex Thomson, Giulio Tononi, Roger Traub, Cor-
nelius (Case) Vanderwolf, Olga Vinogradova, Ken Wise, Xiao-Jing Wang, and
Bob Wong. Over the years, some of these outstanding colleagues—Bob, Bruce,
David, Gábor, Helmut, István, Karel, Mircea, Peter, Rodolfo, Roger, Rusty, Ted,
Tamás, and Wolf—became my trusted, close friends. Most importantly, I would
like to thank my students and post-doctoral fellows without whose dedication and
hard work the many experiments discussed in this volume would not exist.
Prelude
xiii

Being a scientist is a dedication. Writing a book is a bit more. Oh yes, it is a lot
of fun, but it takes time, precious time that I had to steal from somewhere, mostly
from my family. My dear wife, Veronika, and my sweet daughters, Lili and
Hanna, forgive me for the many weekends you had to spend without me and for
my frequent mental absences at dinners and family events when only my body
was present. How fortunate I am to have you as my supporters. Without your un-
derstanding and encouragement, this venture would have been worthless.
Dear reader. Do not stop here! The rhythm begins only now.
xiv
Prelude

Contents
CYCLE 1:
Introduction
3
CYCLE 2:
Structure Deﬁnes Function
29
CYCLE 3:
Diversity of Cortical Functions Is Provided by Inhibition
61
CYCLE 4:
Windows on the Brain
80
CYCLE 5:
A System of Rhythms: From Simple to Complex Dynamics
111
CYCLE 6:
Synchronization by Oscillation
136
CYCLE 7:
The Brain’s Default State: Self-Organized Oscillations 
in Rest and Sleep
175
CYCLE 8:
Perturbation of the Default Patterns by Experience
206
CYCLE 9:
The Gamma Buzz: Gluing by Oscillations in the 
Waking Brain
231
CYCLE 10:
Perceptions and Actions Are Brain-State Dependent
262
CYCLE 11:
Oscillations in the “Other Cortex”: Navigation in Real 
and Memory Space
277
CYCLE 12:
Coupling of Systems by Oscillations
334
CYCLE 13:
Tough Problems
357
References
373
Index
433

This page intentionally left blank 

Rhythms of the Brain

This page intentionally left blank 

Cycle 11
Introduction
There is no good reason to assume that the brain is organized in accordance
with the concepts of folk psychology.
—Cornelius H. Vanderwolf
3
1. Telepathy (or the related terms precognition and clairvoyance) is the supposed ability to transfer
thoughts, feelings, desires, or images directly from the mind of one person to the mind of another by
extrasensory channels and without using known physical means.
It all began with a dream. A young ofﬁcer in the Prussian Army received a letter
from his sister. In it she wrote about a dream in which her beloved brother fell off
his horse and broke his leg. As it happened, the young ofﬁcer indeed fell off his
horse at about the time the letter was sent by his sister. The ofﬁcer, Herr Doktor
Hans Berger, already an established researcher on cerebral blood circulation at
the University Clinic for Psychiatry in Jena, Germany, thought that such coinci-
dence could only have happened through some mysterious communication be-
tween brains, via telepathy,1 as such alleged communications between brains are
better known.
After returning to Jena from active military duty, Berger was promoted to the
Chair of the Department of Psychiatry and Neurology in 1919 and devoted the
rest of his career to the study of the brain’s electrical activity. Berger reasoned
that the electromagnetic forces generated by the human brain could be the carrier
waves of telepathy, his true interest. Since even in that day telepathy was regarded
as an “occult” subject, his experiments were conducted in utter secrecy in a labo-
ratory located in a small building on the grounds of the clinic. Most of his initial
recordings were done on himself, his son Klaus, and patients with skull defects.

4
RHYTHMS OF THE BRAIN
2. Berger (1929). Berger was already familiar with the work of Richard Caton, a Liverpool sur-
geon who studied the electricity generated by the brains of rabbits and monkeys (Caton, 1875).
Berger’s international fame was boosted when his work was conﬁrmed and endorsed in by Edgar Dou-
glas Adrian and Bryan Harold Cabot Mathews of the Cambridge Physiological Laboratory. They sug-
gested calling the alpha waves the Berger rhythm, but Hans Berger modestly rejected the offer (Adrian
and Mathews, 1934).
3. It is tough to be ﬁrst in any ﬁeld of science, and the discovery of the electroencephalogram
(EEG) was no different. In addition to Caton’s work, Berger also knew about the published works of
the physiologists Adolf Beck of Poland and Vladimir Pravdich-Neminski (or W. W. Prawdicz-
Neminski in his native Ukrainian) of Russia. Neminski’s observations are perhaps most relevant since
his “electrocerebrogram” was obtained from the intact surface of dogs’ skulls (Neminski 1913). How-
ever, he was not the ﬁrst Russian in this area of research. Vasili Yakovlevich Danilevsky had described
observations similar to Caton’s in his doctoral thesis, and Nikolai Y. Wedensky had used a telephone
circuit to listen to electrical waves in the brains of cats and dogs. Fleischel von Marxow was also
among the ﬁrst discoverers of electrical ﬁelds of the brain. However, he placed his results in a sealed
letter in 1883 and revealed them only after he learned about Beck’s published results. What made
Berger’s observations stand out from the others were the numerous control experiments he provided
along with his observations. Brazier’s (1959) chapter is the best summary of the exciting early days in
the study of brain electricity and is a source for numerous references. Borck (2005) is another useful
source of historical materials.
He performed numerous experiments and, importantly, eliminated the possibility
that the voltage changes measured by his string galvanometer were an artifactual
consequence of blood pressure changes; nor did they arise from the scalp skin.
After ﬁve years of experimentation, he concluded that the most prominent elec-
trical activity could be recorded from the occipital (lower rear) part of the skull
when the subject’s eyes were closed. In his groundbreaking 1929 paper he wrote,
“The electroencephalogram represents a continuous curve with continuous oscil-
lations in which . . . one can distinguish larger ﬁrst order waves with an average
duration of 90 milliseconds and smaller second order waves of an average dura-
tion of 35 milliseconds. The larger deﬂections measure at most 150 to 200 micro-
volts. . . .”2 In other words, the electrical ﬁeld generated by millions of
discharging neurons in the cerebral cortex is 10,000 times smaller than that pro-
vided by an AA battery.
Berger called the large-amplitude rhythm (approximately 10 waves per sec-
ond, or 10 hertz), which was induced by eye closure in the awake, calm subject,
the “alpha” rhythm because he observed this rhythm ﬁrst. He named the faster,
smaller amplitude waves, present when the eyes were open, “beta” waves. Para-
doxically, Berger’s recordings provided ﬁrm physical evidence against his idea
that waves generated by one brain could somehow be detected by another brain.
The voltage changes that emerge from the cooperative activity of neurons in
the mammalian brain are just too small, and current propagation requires a low-
resistance conductor, so it cannot cross air, for example. Although he failed to
prove his hypothesis of telepathic communication between brains, his research
created a powerful scientiﬁc and clinical method for investigating quickly chang-
ing brain activity.3
Discovering a dynamic brain phenomenon is one thing. Understanding its
meaning and its role in behavior and cognition is quite another. Ever since Berger’s

Introduction
5
4. Nature, of course, has no laws, desires, goals, or drives. It simply generates certain regularities
that we conveniently assume are governed by some outside forces and use a third-person perspective
to refer to these regularities.
early observations, three questions have haunted neuroscientists: how are EEG
patterns generated, why are they oscillatory, and what is their content? Providing
answers to these questions is a major goal of this volume. I introduce the topic in
Cycles 2 and 3 by discussing the important issue of how the speed of communi-
cation in the cerebral cortex can be preserved despite the great size differences of
the brains of small and large mammals. Cycle 4 can be skipped by those who have
had an introductory class on methods in neurophysiology. It discusses the major
methods currently available for investigating brain activity patterns in living tis-
sue and the mechanisms that give rise to the ﬁeld EEG. Cycles 5 and 6 serve as an
introduction to the different types of oscillators and discuss the large family of
oscillations in the mammalian cortex. Cycles 7 and 8 are devoted to the “default”
states of the brain: sleep and early brain development. Tying the macroscopic fea-
tures of oscillations to neuronal mechanisms requires large-scale recordings of
numerous single neurons. Such techniques allow us to gain some insight into the
content of oscillations, which is described in Cycles 9–12. In Cycle 13 I examine
the structural and functional requirements of awareness by contrasting brain
structures that can and cannot support self-generated patterns and long-range
communication through global oscillations.
Periodic Phenomena in Nature
Nature is both periodic and perpetual. One of the most basic laws of the universe
is the law of periodicity.4 This law governs all manifestations of living and non-
living. In its broadest deﬁnition, periodicity refers to the quality, state, or fact of
being regularly recurrent: a repeating pattern or structure in time or space. What
goes up must come down. The sun rises and sets, and the days wax and wane.
Without periodicity, there is no time; without time, there is no past, present, or fu-
ture. In living systems, the periodicity of individual lives gives rise to the conti-
nuity of life on Earth. Our existence has meaning only when experienced in time.
The essence of music and dancing is rhythm. An important part of human culture
is the celebration of the periodicity of life. The Jewish and Muslim religions are
attuned to the lunar cycle. Christians adopted a solar calendar. Periodicity can be
seen in the monthly windows of opportunity for conception of human life.
Periodicity, oscillation, rhythm (from Latin meaning to ﬂow), and cyclic pro-
cess are synonyms that refer to the same physical phenomenon. Historically, dif-
ferent academic disciplines have adopted a preferred term to describe these
related phenomena. Periodicity is the term of choice in social and earth sciences.
Oscillation is the preferred term in physics, and engineers talk about cyclic or pe-
riod generators. Until recently, neurologists and neuroscientists used the term
“brain rhythms” almost exclusively when referring to the various brain patterns.

6
RHYTHMS OF THE BRAIN
5. It was the review by Steriade and Deschênes (1984) that popularized the term “neuronal oscil-
lator” in the mammalian nervous system. See also Steriade and Llinás (1988).
6. Hawking (1992) is an excellent introduction to this difﬁcult topic. Hall (1983) is another easy
read. A radically different deﬁnition of time is proposed by Leyton (1999). Leyton derives time from
spatial symmetry and its broken version: time is essentially symmetry breaking (e.g., asymmetric
representation of plane symmetry by oscillatory phase; see Cycle 11).
7. In physics, standard time interval (a second) is deﬁned by an oscillator: 9,192,631,770 hyperﬁne
transitions in the 133Cs atom.
Reference to oscillations is quite recent.5 The avoidance of the term “oscillator”
in brain research for so long perhaps reﬂected the tacit view that brain rhythms
may be qualitatively different from the oscillators discussed in physics textbooks.
Assuredly, neuronal oscillators are quite complex. Nevertheless, the principles
that govern their operation are not fundamentally different from those of oscilla-
tors in other physical systems. Today, it is widely recognized that the brain’s abil-
ity to generate and sense temporal information is a prerequisite for both action
and cognition. This temporal information is embedded in oscillations that exist at
many different time scales. Our creativity, mental experiences and motor perfor-
mance are modulated periodically both at short and long time scales. But how are
oscillatory states brought about, especially if they occur in the absence of external
inﬂuences? In Cycles 5 and 6 I propose some answers with illustrations from
physics and engineering.
Time and Periodicity
Neuroscientists work with time every day but rarely ask what it is. We take for
granted that time is “real” and that brains have mechanisms for tracking it. Since
time is a major concept in this book, I attempt to provide a working deﬁnition
without getting lost at the nebulous boundary between physics and philosophy.6
Newton held that time ﬂows in absolute intervals, independent of the physical
universe. According to Immanuel Kant, space and time are irreducible categories
through which reality is perceived by our brains. Albert Einstein combined space
and time into “spacetime.” According to him, time is a measure of motion and, as
such, is part of the physical universe and thus could be interpreted as its “prop-
erty”; space and time disappear along with the things. An opposite view is that
time is a subjective abstraction and does not exist in any physical substrate and
has no more reality than a mathematical axiom. In a broad sense, time is a mea-
sure of change, a metric of succession, a parameter that distinguishes separate
events. One practical deﬁnition is that “time is that which is measured by a clock,”
a pragmatic description adequate for most branches of physics and neuroscience.7
How we approach the problem of time largely determines our view of the out-
side world around us. First, we need to distinguish two aspects of time. Absolute
time is clock time, referring to a particular point in a time series, for example, your
birth date. Absolute time is a fundamental element of existence since everything

Introduction
7
8. The different types of oscillators are deﬁned and discussed in Cycle 6.
9. The quote is from the book of Ecclesiastes (chapter 1, verse 9, Revised Standard Version). The
concept of recurrence is prominent in Hinduism and Buddhism, among others. The spoked wheel of
life (dharma) is an endless cycle of birth, life, and death. The concept of recurrence is also prominent
in Friedrich Nietzsche’s philosophy (best expressed in Also Sprach Zarathustra. Ein Buch für Alle und
Keinen). A picture of nature as being in “balance” often prevails in both biological and religious dis-
cussions. Although a general equilibrium theory has never been explicitly formulated, environmental-
ists and conservationists tacitly assume that nature is in an eternally stable equilibrium; therefore, we
should keep it that way. However, if this were the case, how did we get here in the ﬁrst place?
exists in time. Duration refers to the change of time, the interval between two
points in time. Elapsed time is therefore relative, and it has an interval span (e.g.,
hour), whereas absolute time does not have a span (e.g., date). We make a similar
absolute versus relative distinction in space as well, when we talk about position
and distance. However, while distance can refer to many directions (vector) in
space, time has only one direction (scalar).
The intimate relationship between space and time is packaged into the concept
of “spacetime” (x, y, z, t dimensions). Oscillations can be conceived of and dis-
played in terms of either space or time. The phase-plane of a sinusoid harmonic
oscillator8 is a circle. We can walk the perimeter of the circle once, twice, or bil-
lion of times and yet we always get back to our starting point. “What has been is
what will be, and what has been done is what will be done; and there is nothing
new under the sun”9 This is the “circle of life,” and our walk on its perimeter is
measured as dislocation (ﬁgure 1.1, left).
An alternative to the periodicity view of the universe is to display periodicity
as a series of sine waves. Now we can walk along the troughs and peaks of the line
without ever returning to the starting point (ﬁgure 1.1, right). Time here is a con-
tinuum with the cycle as its metric. The cycles are identical in shape, and the start
and end points of the cycles form an inﬁnite path into the seemingly endless uni-
verse. This meandering line illustrates the basis of our time concept: linear
Figure 1.1. Oscillations illustrate the orthogonal relationship between frequency and time
and space and time. An event can repeat over and over, giving the impression of no change
(e.g., circle of life). Alternatively, the event evolves over time (pantha rei). The forward or-
der of succession is a main argument for causality. One period (right) corresponds to the
perimeter of the circle (left).

8
RHYTHMS OF THE BRAIN
10. The quote is attributed to Heracleitus of Ephesus (540 to circa 475 b.c.).
11. The average duration of syllables, the fundamental segmentation of speech in all languages, is
approximately 250 milliseconds. Syllables cannot be stretched or sped up at will in spoken language
beyond certain limits. Slowing down speech can be achieved only by introducing long pauses between
syllables. This is the reason why it is so difﬁcult to understand the text of arias.
12. Jacob (1994), p. 32.
13. Freeman (2000) explains that time exists in the material world but causality does not. Along
with physicists, he argues that time is a measure of motion, living and nonliving; therefore, it is an ob-
jective dimension. In contrast, cause is a measure of intent, and, according to Freeman, only humans
have intent.
change and a forward order of succession, features that are often used in argu-
ments of causality. A moment never repeats itself. Pantha rei—everything
ﬂows—according to the ancient Greek saying. “Upon those who step into the
same rivers, different and ever different waters ﬂow down.”10 Whichever model
we choose, the circle or the meandering line, in periodically changing systems the
past can predict the future (position or moment).
The hard problem to solve is whether time and space are situated in our minds
only or whether they in fact exist independently of us. Fortunately, most brain op-
erations, including predictions by brain rhythms, can be understood without ad-
dressing this hard problem. Clock time is sometimes referred to as objective time,
an absolute physical reality, independent of conscious brains and beyond our con-
trol. Clock time is what we use to calibrate our subjective experience of the pas-
sage of time and coordinate our thoughts and activities. Passage of time, that is,
its duration, is felt as a linear event, slipping from one moment to another. The
feeling of time is conﬁned to a relatively short span from tens of milliseconds to
tens of minutes. As shown in Cycle 5, this time span corresponds to the temporal
range of brain oscillators, which may serve as an internal metric for time calibra-
tion. Nobody can feel micro- and nanoseconds, and tracking time durations be-
yond the hour range requires body references such as hunger or feedback from the
environment. Our best temporal resolution is in the subsecond range, correspon-
ding to the duration of our typical motor actions, the tempo of music and
speech.11
Linear time is a major feature of our Western cultural world-view, and the ex-
perience of time ﬂowing between past, present, and future is intricately tied to
everyday logic, predictions, and linear causation. According to the great French
molecular biologist Francois Jacob, “one of the deepest, one of the most general
functions of living organisms is to look ahead, to produce future.”12 What I am
proposing in this volume is that neuronal oscillations are essential for these deep-
est and most general functions.
Time, Prediction, and Causation
Causality among world events is linked to our perception of time.13 Prediction, in-
ference, forecast, and deduction are used as synonyms in the context of proposed

Introduction
9
14. The most inﬂuential theory on prediction was put forward by Thomas Bayes (1763/1958). His
probability theory examines the possible outcomes of events in terms of their relative likelihoods and
distributions (Bernardo and Smith 1994). A “brain computation-relevant” treatment of the Bayesian
theory is discussed by Changizi (2003).
15. The second law also nicely illustrates the reductionistic nature of prediction: knowing all past
(upstream) events, the future probabilities can be calculated; no goals, desires, or teleology is in-
volved.
16. This is a classic experiment by Shallice (1964). See related arguments in Eagleman and Se-
jnowski (2000) and VanRullen and Koch (2003).
causality. They refer to an inductive process, which integrates information about
the past and present to calculate the following most probable outcome.14 Brains
help their owners to survive and prosper by predicting and deciphering events in
the world, including consequences of their own actions. Predictions and relation-
ships are constructed by ordering the succession of events according to elapsed
subjective time. We are usually able to say which of two events happened before
the other, with decreasing precision as time elapses. Causal-explanatory relation-
ships are usually considered a one-way process because such relationships are
embedded in the context of time and time is asymmetric and unidimensional. The
cause precedes the effect in time. If the discharge of neuron a consistently and re-
liably precedes the discharge of neuron b, and after destruction of neuron a neu-
ron b ceases to discharge, a causal relationship is suspected. Linear causation
works most of the time, and it is the foundation of many essential operations from
catching a ball to solving a mysterious murder case. Causation can also fail. For
example, in an oscillatory system, most or all neurons with reciprocal, one-way
connections or no direct connections may discharge with a zero time lag (i.e., si-
multaneously), making linear causation impossible, as illustrated in several sub-
sequent Cycles. Oftentimes, the reason for causation failing can be explained by
the discrepancy between objective or external time and subjective time registered
by the brain.
According to the second law of Newtonian mechanics, a body tends to re-
main in its state of rest or motion unless acted upon by an external force.15 The
force is the cause, an agent responsible for the motion of the body. When a mov-
ing billiard ball hits a stationary one, the latter begins to move. This happens be-
cause the kinetic energy of the moving ball exerts force on the stationary ball,
causing it to move. Now consider the following psychophysical experiment. A
ball is moving toward another one, this time not on a pool table but on a com-
puter screen. If the second ball starts moving in the same direction after the ar-
rival of the ﬁrst ball, we conclude from the timing of the events that the ﬁrst ball
caused the second one to move. However, derivation of such a conclusion de-
pends critically on the exact timing of the events. We make the inference of
causality only if the second ball begins to move within 70 milliseconds after the
ﬁrst ball reaches it. If at least 140 milliseconds elapse between the halting of the
ﬁrst ball and movement of the second ball, no causality is suspected. Between
70 and 140 milliseconds of delay, the two disks appear to stick together but
some indirect causality is still deducted.16 Thus, temporal context is critical for

10
RHYTHMS OF THE BRAIN
17. Libet (2004) gives an extensive analysis of “mind time,” a neuronal process evolving over
time, needed for conscious experience (see also Libet, 1973). Other experiments show that events reg-
istered by the brain shortly after the stimulus (<100 milliseconds) may be used to update motor pro-
grams even though the person does not subjectively experience them (Goodale et al., 1986).
perception, including the perception of causation. The brain “chunks” or segre-
gates perceived events according to its ability to package information in time,
and such packaging, I propose, can be achieved by neuronal oscillators (Cycles
9 and 11).
Here is another illustration of a “logical illusion” in which the brain falsely re-
constructs the order of events. You are driving on a highway and a deer crosses the
road. You slam on the brakes and avoid a collision. The mental reconstruction of
the events is as follows. You noticed a deer (cause) and realized that it would be
dangerous to hit the animal. So you decide to avoid it, push the brakes, and turn
the steering wheel (effects). Laboratory replication of such real-world actions of-
fers a different explanation. A deer appeared (ﬁrst event), you braked (second
event), and then you recognize the animal (third event). This sequence is proposed
because reaction time to an unexpected event is less than half a second, whereas
conscious recognition requires the recruitment of a large number of neurons in a
large, distributed complex brain circuit, which takes longer than half a second.17
The false logic emerges from the difference between external time and brain-
reconstructed time.
Although in this case a simple cause–effect (unexpected object–braking) rela-
tionship exists, mental reconstruction offers a different cause. The brain takes
into consideration the conduction velocities of its own hardware and compen-
sates for it. For example, touching your nose and toe at the same physical time
(or touching your nose with your toe) feels simultaneous even though neuronal
events in the cerebrum, representing the touch of two body parts, are delayed by
several tens of milliseconds. The conclusion that follows from this discussion is
that our time reconstruction is a consequence of an accumulation of past experi-
ence rather than a truthful representation of real time. Nevertheless, despite the
difﬁculty in deducting causality, the above examples are simple because they in-
volve a single well-deﬁned cause. In many cases, the causes are multiple and so
pointing to a single cause or agent is not possible. Deducing causality is particu-
larly difﬁcult when the cause involves a reciprocal relationship between parts
and wholes, as is often the case for neuronal oscillations and other properties of
complex systems.
Self-Organization Is a Fundamental Brain Operation
The brain is perpetually active, even in the absence of environmental and body-
derived stimuli. In fact, a main argument put forward in this book is that most of
the brain’s activity is generated from within, and perturbation of this default pattern

Introduction
11
18. Similar views have been repeatedly expressed by both philosophers and neuroscientists. Per-
haps the most explicit discussion on this issue is a comprehensive review by Llinás and Paré (1991).
However, I do not believe that any useful function would spontaneously emerge in an isolated brain.
As discussed in Cycle 8, environmental inputs are an absolute requirement for creating useful brain
activity.
19. It is not always easy to distinguish between “internal” and “external” operators. The brain, the
body, and the environment form a highly coupled dynamical system. They are mutually embedded
rather than internally and externally located with respect to one another. This embeddedness must
have a profound inﬂuence on all aspects of brain activity (Chiel and Beer, 1997).
20. An excellent introductory book on self-organization is Kampis (1991). The primary reference
on autopoiesis and autopoietic theory, with reference to the brain, is Maturana and Varela (1980).
by external inputs at any given time often causes only a minor departure from its
robust, internally controlled program.18Yet, these perturbations are absolutely es-
sential for adapting the brain’s internal operations to perform useful computa-
tions. Without adjusting internal connectivity and computations to the spatial and
temporal metrics of the external world, no constructive, “real-world” functions
can be generated by the brain.19 In engineering terms, this process can be referred
to as “calibration.” The self-reliance of brain circuits increases as we move to
higher levels in the brain, ones that have less and less contact with sensory inputs.
Due to its ability to give rise to spontaneous activity, the brain does not simply
process information but also generates information. As a result, the world outside
is not simply “coded” by meaningless “bits” of neuronal spikes but gets embed-
ded into a context, an important part of which is time. “Representation” of exter-
nal reality is therefore a continual adjustment of the brain’s self-generated
patterns by outside inﬂuences, a process called “experience” by psychologists.
From the above perspective, therefore, the engineering term “calibration” is syn-
onymous with “experience.”
Paradoxically, such a view is quite recent in neuroscience research and is, of
course, hard to defend if one subscribes to Aristotle’s thesis that nothing moves or
changes itself. The novel idea of a “self-cause”–governed principle has emerged
in several disciplines and is referred to by numerous synonyms, such as sponta-
neous, endogenous, autogenous, autochthonous, autopoietic, autocatakinetic,
self-organized, self-generated, self-assembled, and emergent. Systems with such
features are often called complex.20 The term “complex” does not simply mean
complicated but implies a nonlinear relationship between constituent components,
history dependence, fuzzy boundaries, and the presence of amplifying–damping
feedback loops. As a result, very small perturbations can cause large effects or no
effect at all. Systems in balance are simple and hard to perturb. Complex systems
are open, and information can be constantly exchanged across boundaries. De-
spite the appearance of tranquility and stability over long periods, perpetual
change is a deﬁning feature of complex systems. Oftentimes, not only does com-
plexity characterize the system as a whole, but also its constituents (e.g., neurons)
are complex adaptive systems themselves, forming hierarchies at multiple levels.
All these features are present in the brain’s dynamics because the brain is also a
complex system.

12
RHYTHMS OF THE BRAIN
21. For a concise exposition of Aquinas’s account of free choice, read MacDonald (1998).
22. In later Cycles I show that the waking brain is rich in rhythms. The “ﬂat” EEG is most often
composed of fast, low-amplitude gamma oscillations.
23. Ashby (1947). Implicitly, the idea of increasing order in nature can be traced back to Charles
Darwin, but the explicit concept of self-organization matured within physics.
24. The concepts of entropy and information are deeply related. Schrödinger’s negentropy (nega-
tive entropy) “is identical to information” declared Szilárd (1929/1990). In information theory, en-
tropy reﬂects the amount of randomness in the signal (Shannon, 1948).
Ever since electrical activity has been recorded in the brain without evidence
of an inducing external agent, it has been referred to as “spontaneous.” Sponta-
neous activity has proven to be a difﬁcult concept to tackle because the system
that generates it appears to act independently of outside inﬂuences, as if there
were an element of choice, directed goal, intention, or free will. Although the ob-
servation of spontaneous brain activity, in principle, offers a substitute for
Thomas Aquinas’s philosophical freedom of the self, two major obstacles have
remained.21 First, spontaneous activity is present in all brains, not only those of
humans, yet, according to Aquinas, only humans can choose between good and
bad. Second, the largest amplitude and most regular spontaneous oscillations in
the cerebral cortex occur at the “wrong” time, that is, during sleep or when the
brain is otherwise disengaged from the environment and body. In contrast, when
decisions are made by the human subject, brain activity often does not show
large-amplitude rhythms but instead appears “desynchronized” or “ﬂat” in con-
ventional scalp recordings.22 As a result of these considerations, neurophysiolo-
gists downgraded the signiﬁcance of spontaneous brain activity to “noise” and
“idling.” Ironically, although the term “self-organization” was introduced by the
British psychiatrist W. Ross Ashby,23 genuine interest in spontaneous brain activ-
ity was kindled by research and thinking that occurred in disciplines other than
neuroscience.
Emergence, Self-Causation, and Adaptation
The fundamental assumption of classical thermodynamics is destruction of struc-
ture, an inevitable temporal progression from organized to disorganized, charac-
terized by the monotonic increase of entropy.24 In the framework of classical
physics, order in nature must be created through external forces. When designing
a car, many rational considerations, such as power, size, appearance, cost, and
other goals, are ﬁrst evaluated. Prior to the car’s physical existence, its designers
can envision many of its characteristics. Such top-down effort requires an ex-
traordinary a priori knowledge of math, physics, engineering, computer graphics,
esthetics, marketing, and other complicated stuff. Can order as complex as the
brain’s emerge without a “designer” and explicit goals?
While nothing contradicts the second law of thermodynamics within the realm
of stable, closed systems, things are different in open, complex systems that exist

Introduction
13
25. Mathematically, chaos is deﬁned as the exponentially sensitive dependence of a system on its
initial conditions, implying that there is a fundamental limit on the predictability of the system. The
predictability of the system (or the lack of it) is quantiﬁed by the entropy, reﬂecting the rate at which
past history is lost. It is equal to the sum of all positive Lyapunov exponents. The positive value of the
Lyapunov exponent is the proof for the chaotic behavior of the system. A concise and excellent intro-
duction of nonlinear dynamics to neurobiology is Freeman (1992). For more in-depth treatment, con-
sult Prigogine and Stengers (1984), Glass and Mackey (1988), or James Gleick’s bestseller on chaos
(Gleick, 1987).
far from a state of equilibrium. In complex systems, the direction is typically
from disorganized to better organized, according to physicists. Indeed, extremely
complicated protein structures with multiple uses can be built by following stun-
ningly simple algorithmic steps dictated by the variation of just four nucleic acids
that form DNA. Could the “smartness” of brain organization and performance be
traced back to similarly simple algorithms? Cycles 5–8 discuss arguments in fa-
vor of such “minimalism.”
The new story in physics begins with the postulate of open systems, which op-
erate far from thermodynamic equilibrium, so that the system can exchange en-
ergy, matter, or entropy with its environment. Typical examples include
avalanches, earthquakes, galaxies, and, in fact, the evolution of the whole universe.
The Belgian-American chemist Ilya Prigogine introduced the term “dissipative
structures,” which refers to patterns that self-organize in far-from-equilibrium states.
The expression “far from equilibrium” means that the system cannot be described
by standard linear mathematical methods. Characterization of dissipative systems
requires nonlinear differential equations because there are no universal solutions.
These complex systems live by the rules of nonlinear dynamics, better known as
chaos theory.25 The immediate link between problems of neuronal communica-
tion and dynamical theory is that both are concerned with the fundamental as-
pects of change and the time context within which the change occurs. In complex
systems, the evolution of the system is described as a motion vector in a multidi-
mensional space. The sequentially visited points in the multidimensional state
space are called a “trajectory.” Applying this idea, for example, to visual percep-
tion, the trajectory corresponds to the ordered assemblies of neurons set into mo-
tion, from the retina to higher visual and memory systems. The spatiotemporal
trajectory of neuronal activity depends not only on the constellation of light im-
pinging on the retina but also on the perceiver’s brain state and past experience
with similar physical inputs. Hence, each time the same stimulus is presented, it
generates a somewhat different and unique trajectory in the neuronal space.
Complexity can be formally deﬁned as nonlinearity, and from nonlinear equa-
tions, unexpected solutions emerge. This is because the complex behavior of a
dynamic system cannot easily be predicted or deduced from the behavior of indi-
vidual lower level entities. The outcome is not simply caused by the summation of
some agents. The emergent order and structure arise from the manifold interac-
tions of the numerous constituents. At the same time, the emergent self-organized
dynamic, for example, a rhythm, imposes contextual constraints on its con-
stituents, thereby restricting their degrees of freedom. Because the constituents

14
RHYTHMS OF THE BRAIN
26. Haken (1984). Circular causation is an argument for causes directed both up and down. It is
neither paradoxical nor vicious. Democratic election of a governing body (the “order parameter”)
guarantees the majority rule (“enslavement” of the minority). The best exposure to the role of circular
causality in neuroscience is gained from Kelso (1995), an abbreviated version of which is Bressler and
Kelso (2001). Freeman (1999) goes even further and describes consciousness as an order parameter,
“a state variable-operator” (p. 12) in the brain that mediates the relations among neurons and, there-
fore, must play a crucial role in intentional behavior.
27. General system theory was ﬁrst articulated by the biologist Ludwig von Bertalanffy (1968) as
a response to the one-way, mechanistic cause–effect approach in living systems, including brain re-
search. His main claim was that living things do not exist in isolation but are embedded in an orderly
environment, and it is the interaction between the context and the organism that generates novel prop-
erties. A system’s organization is determined primarily by the predictable relations among its con-
stituents (e.g., synaptic connections) but can also be inﬂuenced by the components’ properties (e.g.,
intrinsic features of neurons).
are interdependent at many levels, the evolution of complex systems is not pre-
dictable by the sum of local interactions. The whole is based upon cooperation
and competition among its parts, and in the process certain constituents gain
dominance over the others. This dominance, or attractor property, as it is called
in chaos theory, can affect other constituents such that the degrees of freedom in
the system decrease. Such compression of the degrees of freedom of a complex
system, that is, the increase of its entropy, can be expressed as a collective vari-
able. These ideas have a profound effect on the interpretation of spontaneously
organized brain patterns (as discussed in Cycles 5–7).
Hermann Haken, a German laser physicist, refers to the relationship between
the elements and the collective variable as synergy (he also calls it the “order pa-
rameter”), the simultaneous action of emergence and downward causation. In
Haken’s system of synergetics, emergence through self-organization has two di-
rections. The upward direction is the local-to-global causation, through which
novel dynamics emerge. The downward direction is a global-to-local determina-
tion, whereby a global order parameter “enslaves” the constituents and effectively
governs local interactions. There is no supervisor or agent that causes order; the
system is self-organized. The spooky thing here, of course, is that while the parts
do cause the behavior of the whole, the behavior of the whole also constrains the
behavior of its parts according to a majority rule; it is a case of circular causation.
Crucially, the cause is not one or the other but is embedded in the conﬁguration of
relations. In fact, Haken argues that in synergetic systems the cause is always cir-
cular. Perhaps a better term would be “nonsymmetrical reciprocal causality.”26
Putting the philosophical issues aside for a moment, nonlinear dynamics
brought with it a novel kind of thinking about systems—not as mere aggregates of
parts but as a bidirectional interaction between parts and the whole.27 Systems
that can be perturbed from outside and incorporate external inﬂuences in their fu-
ture behavior possess a remarkable capacity for learning and growth even though
they live within boundaries deﬁned by simple rules. By adhering to these low-
level rules, something greater than the sum of parts can emerge. The emergent
level is thus qualitatively different from the level it springs from. If the compo-
nent relationships within the system become optimized for a particular task as a

Introduction
15
28. “Adaptation,” of course, inevitably invokes the philosophically charged terms “goal directed-
ness” and teleology. Here the causes are backward in time because actions are guided by downstream
goals, motivational targets, or desires (Edelman 1987).
result of external perturbations, the system is called adaptive. The brain is such an
adaptive complex system.28
Today’s systems neuroscience is an offspring of general systems theory, a sort
of modernized Gestalt concept in a quantitative disguise. Instead of looking at
discrete moments in time, the systems methodology allows us to see change as a
continuous process, embedded in a temporal context. Systems thinking and espe-
cially explorations in chaos have quickly identiﬁed an important application in
neuroscience by investigating the bioelectrical activity in the brain and have
claimed (premature) victory by stating that brain activity, and at times behavior,
reﬂects chaos. How does this claim relate to our introductory discussion that the
brain operates in an oscillatory mode, whose main task is prediction? Cycle 5
covers this important topic, followed by further discussion in subsequent Cycles
about the relationship between the internal complexity of neuronal networks and
the reliable predictions they can make about events external to the brain.
Where Does the Brain’s Smartness Come From? 
Even though spontaneous brain activity emerges without an external force, for a
brain to be useful it should adapt to the outside world. The brain has to be cali-
brated to the metrics of the environment it lives in, and its internal connections
should be modiﬁed accordingly. If the statistical features of the environment re-
ﬂect one particular constellation, the evolving brain should be able to adapt its in-
ternal structure so that its dynamics can predict most effectively the consequences
of the external perturbation forces. A great deal of this adaptive modiﬁcation for
each individual brain (i.e., its “smartness”) comes from interactions with con-
speciﬁcs, that is, other brains. In other words, the functional connectivity of the
brain and the algorithms generated by such continuous modiﬁcations are derived
from interactions with the body, the physical environment, and to a great extent,
other beings.
One can ask a similar question at the single-component level of the brain, as
well: how smart is a neuron? The answer depends on the baseline of the com-
parison and on the size of the brain the neuron is embedded in, because smart-
ness is a relative judgment. In a very small neuronal network, each neuron is
critical, and discernible functions can be assigned to each. In larger brains, the
complexity of single neurons tends to be underestimated largely because the
relative contribution of a single cell to the complex operation of the network ap-
pears small. The ratio of individual and collective “intelligence” decreases rad-
ically as the brain size grows. But it is not simply the number of neurons that
matters. Instead, it is the connectivity and the connectivity-conﬁned communica-
tion that largely determines the share single neurons have in brain computations.

16
RHYTHMS OF THE BRAIN
It is much like the smartness issue with us humans. Prior to our cultural evolu-
tion, as is the case in other animals, there was not much difference between in-
dividual and species knowledge. However, with the invention of books,
computers, and the Internet, an ever-increasing portion of knowledge has be-
come externalized from individual brains. As a result, the primary carrier of
species knowledge is no longer the individual or the collective wisdom of tribe
elders (i.e., their brains). Because of technology-enhanced externalization of in-
formation, the cumulative knowledge of humankind is constantly growing,
whereas the relative share of the average individual, sadly enough, is steadily
decreasing. Similarly, the relative smartness of individual neurons decreases
with brain growth, despite their preserved or even improved biophysical proper-
ties. The reason is that single neurons develop their smartness through their in-
teractions with local peers. With growing brain size, single cells get less and
less informed about system level and global decisions. In a strongly intercon-
nected system, such as the mammalian cerebral cortex, changes in a single neu-
ron or neuronal assembly can ripple throughout the entire cortex. However, the
impact of the distant effects decreases rapidly as brain size grows due to the ex-
pense of maintaining distant connections. The selective and speciﬁc response of
a single cell, that is, the degree of its “explicit” representation, is not a function
of its biophysical or morphological properties but depends largely on its func-
tional connectivity in the network. Thus, there are no smart neurons; their ex-
plicitness derives simply from being at the right place at the right time. A
special challenge, therefore, is to explain how brain complexity scales with the
size of growing networks while still preserving the useful functions of simpler
brains. Cycles 2 and 3 dealing with the anatomical architecture of the brain and
Cycles 5–11 addressing the statistical features of its global activity attempt to
illuminate these issues.
Causation and Deduction
An objection can be raised that the entire project of “dynamical systems” is guilty
of vicious circularity. It just explains away the real problem, the cause–effect
relationship. Self-emergence of spontaneous activity is indeed a difﬁcult con-
ception because there is always an element of a “goal” or “will.” One can adopt
the practical view that this implication is primarily verbal rather than philo-
sophical and perhaps need not be taken very seriously. Nevertheless, everyday
experience dictates that logic should follow the path of linear causation and
avoid circularity. But linear causation is not foolproof, either, as is amply illus-
trated by the fundamental deductive error made by the great master of logic
himself, Aristotle. He ﬂatly denied that the brain has anything to do with cogni-
tive and motor functions: “The seat of the soul and the control of voluntary
movement—in fact of nervous functions in general—are to be sought in the

Introduction
17
29. The quote from Aristotle is cited in Nussbaum (1986; p. 233). The quote from Hippocrates is
cited from Jones (1923, p. 331), Hippocrates (400 b.c.).
30. For further readings on the topic, I recommend Changeux (1985) and Vanderwolf (2003).
31. Marvin Minsky’s oft-cited quote “Logic does not apply to the real world” illustrates the para-
dox of Aristotelian logic and causation.
32. Several prophetic manifestos have been attempted in this direction (Walter, 1952; Amari,
1982; Freeman, 1991, 1992; Haken, 1984; McKenna et., 1994; Kelso, 1995). However, a substantive
experimental research effort is needed for real progress on the complexity problems of the brain.
heart. The brain is an organ of minor importance, perhaps necessary to cool the
blood.” This declaration was a major attack on the correct view, expressed al-
most a century earlier by Hippocrates: “Men ought to know that from the brain
and from the brain only arise our pleasures, joys, laughter and jests, as well as
our sorrows, pains, griefs and tears. Through it, we think, see, hear and distin-
guish the ugly from the good, the pleasant from the unpleasant. . . . To con-
sciousness the brain is messenger.”29 Aristotle’s linear causation managed to
suppress the correct view for more than a millennium. His revisions were based
on several deductive arguments. The heart is affected by emotion (the brain
does not react). All animals have a heart, and blood is necessary for sensation
(he thought the brain was bloodless). The heart is warm (he thought the brain
was cold). The heart communicates with all parts of the body (he was ignorant
of the cranial nerves). The heart is essential for life (the brain is not essential, he
thought). The heart is the ﬁrst organ to start working and last to stop (the brain
develops later—this is somewhat true). The heart is sensitive (the brain is not).
The heart is in the middle of the body and is well protected (the brain is ex-
posed). However, Aristotle was not unique in his views. The kings of Egypt
were prepared for the afterlife with virtually all body parts preserved, but the
brain was scooped out and tossed away. The Bible never mentions the brain and
relates emotional and moral behaviors foremost to the heart, the bowels, and the
kidneys. Interestingly, similar ideas about the importance of various organs oc-
curred in other cultures, as well. According to the Talmud, one kidney prompts
man to do good, and the other to do evil. “We red men think with the heart,”
claimed the Pueblo Indians.30
How can we argue against overwhelming intuitive “evidence,” such as the
“logical” examples cited above?31 Surely facts are needed, but facts are always in-
terpreted in context. Is the proper context linear time, brain-reconstructed time, or
something else? Of course, similar skepticism can be expressed within the frame-
work of dynamic complex systems. What does it mean to conjecture that the brain
is a pattern-forming, self-organized, nonequilibrium system governed by nonlin-
ear dynamical laws, and how should we prove or disprove this? The intuitively
simple concept of self-organization or spontaneous activity has proven notori-
ously difﬁcult to pin down formally.32 It has remained a challenging task for sys-
tems neuroscience to go beyond the most general types of explanations and
elucidate the brain-speciﬁc mechanisms. General systems theory and nonlinear

18
RHYTHMS OF THE BRAIN
33. It is important to distinguish between concepts and mechanisms. Concepts are substrate inde-
pendent, whereas particular mechanisms always depend on some kind of a substrate. Although con-
cepts borrowed from other disciplines can assist in addressing a problem or gaining a new insight,
understanding mechanisms always requires experiments on the relevant substrate (the brain, in our
case). Concepts can be developed by introspection, but their validity can be conﬁrmed or rejected only
by confronting them with mechanisms. A general problem in neuroscience is that the same terms are
often used interchangeably as concepts or mechanisms (e.g., inhibition of memory as a concept and
inhibition as a mechanism).
34. According to one of his students, János Komlós (personal communication), Erdös was not
happy with just any solution, and he did realize that there might be multiple solutions to the same
problems, just as a multitude of models can mimic various brain functions. Erdös believed that only
one, the simplest and most elegant, solution for each problem was in the “Book.”
dynamics have provided useful concepts and novel paths for thinking, but the
mechanism-level research is left for neuroscience.33
Adopting the systems view poses difﬁculties for an experimentalist; it is al-
ready a daunting task to understand the neurons and neural circuits in isolation.
Examining the relationship between the collective-order parameters and activity
of individual neurons in sufﬁciently large numbers, and taking into account their
past patterns—and doing it all at the same time—make the problem even harder.
Nevertheless, spectacular progress has been made on this front, which is reported
in Cycles 9–12. Unfortunately, it is not always practical to attempt to monitor and
interpret everything at once. Even if we are aware that interactions at multiple
levels subserve a physiological function, oftentimes progress can be made only
after simplifying either the hardware (by looking at small pieces of the brain) or
the operations (by anesthetizing the brain or keeping its environment constant).
The paramount importance of nonlinear dynamics notwithstanding, it is fair to
say that, to date, most of what we know about the brain in general, and about its
physiological operation in particular, has been discovered using simpliﬁed prepa-
rations and linear methods. Not surprisingly, the relationship between the parts
and the whole has been a much-debated topic in neuroscience, as well. Because
most studies in the past were carried out within either a top-down or bottom-up
framework, we should ﬁrst examine the merits of these approaches before declar-
ing them obsolete.
Scientiﬁc Vocabulary and the Direction of Logic
The ever-traveling great mathematician Paul Erdös fantasized that God was an ar-
chitect. Erdös contended that the architectural plan of God’s creation is detailed
in a hidden “Book,” whose teachings we have to discover using mathematics.
Every single problem mathematicians would ever encounter is detailed in the
“Book.” Thus, according to Erdös, and mathematicians siding with him, the sci-
ence of mathematics is not a human-invented universe of axiom-based relation-
ships but a “reality” that exists a priori and is independent of mathematicians.34
We just have to discover this reality. The alternative view, of course, is that math

Introduction
19
35. Vanderwolf (1969, 1988). The neurosurgeon John Hughlings Jackson distinguished voluntary
and automatic-reﬂexive movements. Voluntary is supposed to have a fully internal cause. For Plato
and St. Augustine, voluntary behavior is free in the sense of being totally unrelated to anything in the
external world. One can argue, however, that even the free choice of desire can be activated by exter-
nal objects, since the brain is embedded in the body–environmental context.
is simply invented by the human mind. We may ask a similar question within the
framework of neuroscience. Are our top-down concepts, such as thinking, con-
sciousness, motivation, emotions, and similar terms, “real,” and therefore can be
mapped onto corresponding brain mechanisms with similar boundaries as in our
language? Alternatively, do brain mechanisms generate relationships and quali-
ties different from these terms, which could be described properly only with new
words whose meanings have yet to be determined? Only the latter approach can
address the issue of whether the existing concepts are just introspective inventions
of philosophers and psychologists without any expected ties with brain mecha-
nisms. I believe that the issue of discovery versus invention is important enough
to merit illustration with a piece of neuroscience history.
If brain rhythms are important order parameters of large-scale neuronal be-
havior, it is tempting to relate them to cognitive processes. The ﬁrst rhythm that
acquired this distinguished role was the hippocampal “theta” oscillation (4–10
hertz in rodents). This large-amplitude, prominent rhythm was ﬁrst described in
the rabbit under anesthesia, but it became the focus of attention only after Endre
Grastyán demonstrated a relationship between theta oscillation and the orienting
reﬂex in behaving cats. His ﬁnding marked the beginning of ﬁve decades of
search for the correct term that unequivocally describes the behavioral correlate
of theta oscillations. By the time I became a postdoctoral fellow in Cornelius
(Case) Vanderwolf ’s laboratory at the University of Western Ontario, Canada, in
1981, virtually every conceivable overt and covert behavior had been advocated
as the best behavioral correlate, often followed by passionate debates among the
contenders. Following Grastyán’s pioneering work, many related terms and con-
cepts, such as attention, selective attention, arousal, information processing, vi-
sual search, and decision making, have been added to the ever-growing list. All
these studies shared the view that the hippocampal theta oscillation is associated
with some high-level processing of environmental inputs. At the other extreme of
the list were hypotheses suggesting an “output” or motor control role of hip-
pocampal theta. The most inﬂuential of these hypotheses has been the “voluntary
movement” hypothesis of Vanderwolf. His contention was that theta oscillations
occur during intentional or voluntary movement, as opposed to immobility and
“involuntary” movement, that is, stereotypic activity.35 The many postulated func-
tions of theta, across the spectrum from processing to production, included some
exotic functions, such as hypnosis, brain pulsation, temperature change, and sex-
ual behavior or, more precisely, mounting and copulation (ﬁgure 1.2). My best
hope of a claim to fame as a postdoctoral fellow seemed coming up with yet an-
other term that would be distinct from all the previous ones while remaining com-
patible in spirit to those introduced by my graduate and postdoctoral mentors.

20
RHYTHMS OF THE BRAIN
36. Grastyán dedicated the last decade of his life to understanding the neurophysiological sub-
strates of play behavior and concluded that theta is an invariant correlate of play. According to
Huizinga (1955), Grastyán’s favorite philosopher, play is “a voluntary activity or occupation executed
within certain limits of time and place.”
37. The long list of alleged cognitive and behavioral correlates of theta oscillations are discussed
in Miller (1991) and Buzsáki (2005b).
I soon realized the impossibility of such a task. Grastyán passionately opposed
the term “voluntary” because of its subjective nature, yet he could not avoid its
connotations.36 Vanderwolf used sophisticated ethological, ﬁne-grain analysis of
behavior and also tried to distance himself from subjective terms.37 Paradoxically,
with his introduction of the term “voluntary,” theta oscillation research uninten-
Figure 1.2. The temporal evolution of hypothesis building: time line of the hypotheses of
the behavioral correlates of hippocampal theta oscillations. Most ideas can be lumped as
reﬂecting an “input function,” such as Grastyán’s (left) “orienting response” hypothesis.
The most inﬂuential “output” hypothesis of theta oscillation has remained the “voluntary
movement” correlate by Cornelius (Case) H. Vanderwolf (right). Reprinted, with permis-
sion, from Buzsáki (2005b).

Introduction
21
38. The scholastic concept of intentionality contrasts the relationship between mental acts (“psy-
chical phenomena”) and the external world (“physical phenomena”). Accordingly, intention is the
deﬁning feature of several mental phenomena because physical phenomena lack intentionality alto-
gether (see, e.g., Dennett, 1987). Intentions, desires, motivation, and beliefs are intentional states with
direction (vector), whereas anxiety, depression, and emotions do not have direction (scalar). To be fair,
correlating electrical activity with overt movement was not Vanderwolf ’s ultimate program (Vander-
wolf, 1988, 2003). What we owe him for most is the important teaching that before declaring an ab-
stract cognitive correlate, one should make sure that overt behavior or an intermediate variable is not
an adequate descriptor of brain activity. E.g., if as a result of learning an eyeblink response develops,
neurons controlling eye movements show a perfect correlation with the learning process but without
contributing to it. The current ﬁeld of human brain imaging could beneﬁt a lot from his teachings.
39. William James’s Principles of Psychology (James, 1890) is a great monument in American
psychology. This two-volume encyclopedic work is as much psychology as it is philosophy.
40. James (1890), p. 403.
41. The most frequently used nominal deﬁnition method in Western cultures is the standard dic-
tionary deﬁnition (Deﬁnitio per genus proximum et differentia speciﬁca), going from general (hyper-
nym) to speciﬁc (hyponym). Circular deﬁnition, in contrast, always requires a context and proceeds by
exclusion of co-hyponyms and enumeration of hyponyms. Its circularity comes from the assumption
of a prior understanding of the deﬁned set. Using metaphors and especially models can be effective
when other deﬁnition methods fail (e.g., Cruse, 1986), but they do not always work, either. “The mind
is like a . . .”—unfortunately, it is hard to continue from here.
tionally entered the territory of “intentionality” and free will. Intention and voli-
tion, of course, are also part of orienting, attention, and other subjective acts.38
Despite seven decades of hard work on rabbits, rats, mice, gerbils, guinea pigs,
sheep, cats, dogs, Old World monkeys, chimpanzees, and humans by outstanding col-
leagues, to date, there is still no agreed term that would unequivocally describe behav-
ioral correlate(s) of hippocampal theta rhythms. Ironically, an inescapable conclusion
is that “will” plays a critical role in theta generation. An alternative, and perhaps more
sober, conclusion is that our behavioral-cognitive terms are simply working hypotheti-
cal constructs that do not necessarily correspond to any particular brain mechanism.
Where do the behavioral-cognitive concepts that contemporary cognitive neu-
roscience operates with come from? The answer is from Aristotle and his heart-
centered philosophy, not brain mechanisms. Aristotle’s terms were adopted by the
Christian philosophers and were extensively used by both Descartes and the
British empiricists John Locke and David Hume. To their credit, they used many
of the cognitive expressions only as hypothetical constructs. Concepts such as at-
tention, conception, association, memory, perception, reasoning, instinct, emo-
tions, and the will, better known as William James’s list of the mind, became
“real” only after James codiﬁed them in his famous Principles of Psychology.39
Today’s cognitive neuroscience lives more or less with James’s list as its ax-
iomatic system and also follows his top-down strategy. “Everybody knows what
attention is,” declared James in his attempt to deﬁne the shape and form of the
concept. To sound more precise and scholarly, he even added the necessary
“genus proximum,” as required by good old Aristotelian logic: “it is taking pos-
session by the mind.”40 Sure enough, this deductive general-to-speciﬁc approach
works well as long as the more general term (hypernym), the mind, in our case, is
deﬁned a priori.41 Precise knowledge and a deﬁnition of the conscious mind

22
RHYTHMS OF THE BRAIN
42. A recent honest and respectable attempt to deﬁne the neuronal correlates of consciousness is
Koch (2004). An argument in favor of the utility of such a top-down approach is molecular biology.
Imagine the Babel of vocabulary in biology without the discovery of DNA. Once the “code of the
mind” is deﬁned, the taxonomy of cognitive functions can be vastly simpliﬁed, and all cognitive fac-
ulties can be derived. I suspect the great success of the molecular biology model is the driving force
behind the “consciousness” program advocated by the two Nobel Laureates Gerald Edelman and the
late Sir Francis Crick.
would surely be helpful for working out strategies to understand the other alleged
cognitive faculties of the brain, including attention.42 James’s top-down program,
applied to contemporary cognitive neuroscience research, would proceed in the
following steps. The ﬁrst step involves ﬁnding neuronal correlates of conscious-
ness. The next step requires the identiﬁcation of the necessary and sufﬁcient neu-
ronal events and the mechanisms responsible for causing the mind’s derivatives
(i.e., James’s short list and other terms). The ﬁnal step is a mental rotation that in-
volves the assumption that the identiﬁed brain processes in fact give rise to the
perceived experience of the brain’s owner. After all, without brain there is no
mind. To me, this program appears to be applied, rather than fundamental,
research. This strategy assumes that philosophy and psychology have already
identiﬁed and deﬁned the independent variables (e.g., concepts of perception, vo-
lition), and thus, the major mission of neuroscience is to reveal brain mechanisms
(dependent variables) that generate them. This constitutes a paradox if we believe
that it is the brain (independent variable) that generates cognitive behavior (de-
pendent variable).
One would expect that the discovery versus invention question would have be-
come a cornerstone issue since the birth of neuroscience. Every new discipline,
from molecular biology to computational biology, just to name the most recent
ones, gained independence by creating its own vocabulary. Why is neuroscience,
especially cognitive neuroscience, so different? If James’s list was invented by
our historical mentors, what are our chances of ﬁguring out how these dreamt-up
concepts can map onto neuronal substrates and mechanisms? I suspect the reason
why such a debate has not yet erupted on a large scale is because brain-centered
research in the cognitive ﬁeld is nascent and the plain truth is that, to date, brain-
derived functions are too scarce for use in a major assault on the traditional ap-
proach. There is nothing wrong, of course, with using terms inherited from
philosophy and psychology, as long as we do not forget that these are hypotheti-
cal constructs. After all, it is the verbal terms that allow for conversations among
members of a discipline and that convey messages across the various scientiﬁc
ﬁelds. However, this communication works best if we are able to create a struc-
tured vocabulary that restricts terms to unambiguous meaning that can be objec-
tively communicated across laboratories, languages, and cultures without prior
philosophical connotations. Concepts can be veriﬁed or rejected only by studying
mechanisms. This is a difﬁcult task, given the historically charged terms we have
inherited from the inventors. Nevertheless, before declaring James’s program to
be a failure, let us see what else has been offered.

Introduction
23
43. Today’s visionaries talk about the emergence of a “global brain” for processing and storing in-
formation (e.g., Barabási, 2002). Kurzweil (1999) goes even further by giving a timetable for the
Worldwide Web to become self-aware. The discussion about the hippocampal “search engine” in Cy-
cle 12 should make it clear why such claims remain ludicrous for a good while. HTML-based web
communication is strictly feedforward, and without feedback connections neither oscillations nor
higher order phenomena can emerge. For further pro and contra arguments of “Internet’s mind,” read,
e.g., Johnson (2001).
44. Turing (1936). In neuroscience, David Marr was perhaps by far the most explicit follower of
Turing’s program. For Marr, computer implementation of a problem was a reasonable proof for a sim-
ilar algorithm in the brain (Marr, 1982). The fallacy of the Turing program, in my mind, is the failure
to distinguish between substrate-free concepts and substrate-dependent mechanisms.
45. The term “artiﬁcial intelligence” (AI) was coined by John McCarthy at the Massachusetts In-
stitute of Technology in 1956. In AI, the programs “live” independent of their realization in brain or
machines, somewhat analogously to the Hegelian spirit or Cartesian soul. Today, AI research is fo-
cused on more pragmatic issues, e.g., voice and pattern recognition, expert systems, robotics, neural
networks, and computer games. A great victory for AI research occurred in May 1997, when IBM’s
supercomputer Deep Blue defeated world chess champion Gary Kasparov. Of course, one might argue
that the computer was not “playing” chess but simply obeyed the algorithmic steps programmed by its
designers.
More Top-Down
Alan Turing was a ﬁne mathematician and a professional code breaker. But the
world remembers this eccentric young Cambridge don for his imaginary machine
that, according to him, could replicate logical human thought.43 Turing conﬁ-
dently claimed in 1950 that machines could match wits with humans by the end
of millennium. His top-down strategy was straightforward: comprehension of the
mind could be achieved by purely computational theories, without concern for the
details of their implementation details. This approach is even simpler and more
straightforward than the philosophy–psychology–neuroscience lineage. It offers a
seductive shortcut by avoiding the very difﬁcult task of deciphering the brain
hardware. To understand the brain, claimed Turing, all we have to do is to simu-
late its numerous functions by just writing enough code.44
To emphasize his seriousness about machine intelligence, Turing offered a
test: a machine is intelligent if, in conversing with it, one is unable to tell whether
one is talking to a human or a machine. Turing’s followers, the artiﬁcial intelli-
gence community, produced fancy and important results, such as chess-playing
programs that beat the best masters of the art and useful speech and character
recognition systems. Nevertheless, these remain in the domain of carefully
crafted algorithmic programs that perform a speciﬁc task. Human-made ma-
chines and the algorithms used to run them are designed for obedience rather than
originality. They never come up with an entertaining joke. Neither the ever-more
powerful computers nor increased software sophistication has yielded anything
resembling a thinking machine. The disillusionment with the “artiﬁcial intelli-
gence” approach to the mind is reﬂected not only by technical criticisms but also
by the epistemological dispute that has emerged in parallel.45 Jerry Fodor of Rut-
gers University, the most inﬂuential philosopher related to Turing’s computational

24
RHYTHMS OF THE BRAIN
46. Fodor (2000). pp. 36 and 125.
47. The philosophical claim of this practical reductionism is that the whole cannot be understood
completely without understanding its parts and the nature of their sum.
48. András Lörincz, personal communication.
49. Forward engineering begins with the requirements and goals, followed by the design and im-
plementation stages. Most computer networks are designed this way, with a clear function to be im-
plemented, using existing principles and formulas learned previously from other ﬁelds. In reverse
engineering, the process begins with the end product (e.g., the brain), and the task is to ﬁgure out how
the components and their relationships gives rise to its function. The major difﬁculty with reverse en-
gineering is that the implementation of the device’s programs may contain unknown principles that
must be discovered ﬁrst. Understanding the Egyptian hieroglyphs was done using the principles of re-
verse engineering.
theory of mind, noted recently that “so far, what our cognitive science has found
out about the mind is mostly that we don’t know how it works.” To add insult to
injury, he added, “the main achievement of cognitive science has been to “ ‘throw
light on how much dark there is.’ ”46 Disregarding the nuts and bolts of the sub-
strate often leaves us with so many alternatives that testing all options becomes
impractical. I think it is safe to conclude that even the über-enthusiasts who re-
peatedly make hubristic claims about soon conquering the “last frontiers of hu-
man understanding” agree that the top-down approach alone is unlikely to crack
the mysteries of brain algorithms. Nevertheless, Turing’s program added a novel
aspect to our thinking about the brain: how complex patterns, in our case sponta-
neous brain activity, may come into being by following simple algorithmic rules
(Cycle 5).
Bottom-Up Progress and Reverse Engineering
Despite the obstacles to understanding the brain, today’s neuroscientists have
reached a general consensus on the strategies to pursue. To grasp the complexities
of brain operations, we need a detailed and systematic understanding of at least
three main ingredients: the dynamic structural organization of the brain, the phys-
iological workings of its constituents, and the computational mode of operation
that enables its neurons in the given anatomical hardware to execute behavior.47 If
the top-down approach advocated by James and Turing is not adequate, let us try
to build up function from the bottom.
An alternative or, more precisely, complementary strategy to get an insight
into the operations of a system begins with the substrate from which it emanates.
Albert Szent-Györgyi formulated this approach plainly: “If structure does not tell
us anything about function, it only means we have not looked at it correctly.”48
The technical term characterizing such a working philosophy is reverse engineer-
ing.49 In practice, reverse engineering is taking apart an object to see how it works
in order to duplicate the object, often changing the parts but without altering their

Introduction
25
50. The car is a complicated but not complex system by deﬁnition. The car is a linear combination
of many components, which are combined and used in a predictable way, according to its blueprint
design.
true function. Continuing with our car analogy mentioned earlier, one can disas-
semble a Lotus Elise and examine its engine, brakes, steering, transmission, and
other components for the purpose of manufacturing a similarly performing sports
car. To be successful, in the process of reverse engineering one has to understand
how the components work separately and as part of the car.50 Applying this phi-
losophy to neuroscience research, deciphering the functions of the nuts and bolts
of the brain holds great promise for the ultimate understanding the whole brain.
Detailed knowledge of anatomical connections, biophysical properties of neu-
rons, pharmacological features of their connections, and the rules that govern
their operations can be built up systematically. The eventual synthesis of all this
knowledge is expected to explain the workings of the brain and the consequent
subjective experience that springs from it.
The political-military wisdom divide et impera is an effective tactic in science
as well. When confronted with a very complex problem, a sensible way to crack it
is to divide the complexity into manageable subproblems and defeat each of them
individually. One practical area where reverse engineering has been exploited re-
peatedly is the interpretation of brain waves and rhythm. As alluded to above,
brain waves are the large-scale representations of the interactions among myriads
of neurons, a collective-order parameter. Although they do show a predictable re-
lationship with overt and covert behaviors, without an explicit demonstration that
they are necessary for the brain’s performance, skeptics may dismiss their impor-
tance by claiming that they are just the epiphenomenal wiggling of the jelly brain.
Such a challenge can be dismissed only by examining the neuronal content of
brain waves within the framework of reverse engineering, an important topic ad-
dressed in Cycles 10 and 12. How far can we get with the bottom-up strategy of
examining neurons ﬁrst in isolation, local networks in small slices of the brain,
and then interactions between networks in conveniently anesthetized prepara-
tions, constantly building on knowledge gained at a lower level and moving up?
This approach provides comfort because causal explanations may be reached at
every level—separately. And this is the crux of the problem. It is almost certain
that the bottom-up strategy alone will never provide a full explanation for the
most complex operations of the brain. The reason, as the reader might predict by
now, is that the brain is a nonlinear device: break it up into its components and
you will never be able to put them back together again into a functional whole.
The full behavior of each component is not contained within the component but
derives from its interactions with the whole brain. Global network operations can-
not emerge from uncoordinated algorithms. We need to be in possession of the
overall algorithm, the “brain plan,” to understand the meaning of local pro-
cessing. This leads us back to William James. If we knew the “big plan,” the mind,
in the ﬁrst place, the rest would be easier.

26
RHYTHMS OF THE BRAIN
Outside-In and Inside-Out Strategies
A successful program in neuroscience has been probing the brain with sensory in-
puts and examining the reaction of its neurons one at a time, known as single-cell
physiology. David Hubel, Thorsten Wiesel, and Vernon Mountcastle applied the
single-neuron recording technique to the neocortex of cats and monkeys with
stunning results. With their elegant experiments, a new era of sensory cortex re-
search was ushered in. The greatest appeal of such an approach is its simplicity
and the ability of the experimenter to control the inputs. By recording the neu-
ronal responses to controlled inputs, one can begin to develop ideas about how the
presented stimuli are transformed into a neuronal representation.
Nevertheless, there are two fundamental problems with this outside-in feedfor-
ward strategy. First, such input-output analysis of neuronal networks is compli-
cated because the brain does not simply represent the environment in a different
format. Features of the physical world do not inherently convey whether, for a
brain, a situation is familiar or novel or whether a stimulus is pleasant or repellent.
What we may call unaccounted-for variability is perhaps in fact these very attrib-
utes embedding themselves in the neuronal responses to sensory input (Cycle 9).
Viewing it differently, the reason for this variability is that single neurons are not
independent elements in a feedforward stream but are embedded in networks
whose state exerts a strong and varying inﬂuence on its neurons. In other words,
the brain constantly feeds “information” to the recorded single neuron in the form
of spontaneous activity, and this variability cannot be accounted for by the input-
output analysis of stimulus–single-unit relationships. Ignoring such brain-derived
variability would be a great loss since this spontaneous coordinated variability
may be the essence of cognition, as I argue in several Cycles of this book. The en-
semble activity of neurons reﬂects the combination of some selected physical fea-
tures of the world and the brain’s interpretation of those features. Even if the
stimulus is invariant, the brain’s state is not (Cycle 10).
Another problem with the outside-in approach is the uncertain provenance of
biologically relevant stimuli. The “simple” stimulus is an abstraction, and the
stimulus conﬁguration presented to the brain in research laboratories may be re-
mote from what neuronal circuits are optimized for. Again, this problem becomes
increasingly more serious as one attempts to interpret neuronal responses several
steps removed from sensory inputs. Oftentimes, neural activity is shaped entirely
by the past experiences of the brain. Inspection of a wedding ring may bring up
memories of the pleasures of a wedding or the sorrows of a funeral, depending on
one’s past associations.
An alternative to the outside-in approach is to begin the explorations with the
“default,” relatively unperturbed brain states and with structures that possess high
levels of autonomy. This inside-out strategy does not require a priori knowledge
of the relevant stimuli because the focus of the inquiry is on the relationship be-
tween the single neuron constituents and the emergent functions generated by
their network-level interactions. In the process of exploration, once correlations

Introduction
27
are established, it is possible to perturb them in an attempt to discover the hints of
causality. I follow this inside-out approach in this volume not because it is the best
or only good method but because I have the most experience with it. Furthermore,
self-generated behavior and emergent large-scale oscillations tend to occur in the
unperturbed brain; therefore, this approach is also more didactic. Accordingly, in
Cycles 7 and 8 I discuss the ultimate self-organized brain behavior, sleep, and its
possible functions, followed by Cycles 9–12, which are dedicated to the waking
brain and its interactions with environmental inputs. The agenda of Cycle 13 is to
illustrate the intimate relationship between structural connectivity and global
function.
Scope and Coverage
A quick glance through the Cycles makes it clear that the title Rhythms of the
Brain is a bit grandiose relative to the modest content of the book. Many impor-
tant topics are omitted or glossed over. The vital oscillations generated by the
spinal cord and brainstem are completely ignored, and the bulk of the discussion
is centered on cortical systems of the mammalian brain. Circadian and other long-
period oscillations are discussed only as they pertain to the faster neuronal events.
Until recently, most other brain oscillations have had a bad reputation, associated
with such ailments as epilepsy, Parkinson’s disease, Huntington’s disease, essen-
tial and cerebellar tremors, coma, and psychiatric diseases. Each of these topics
would deserve a separate volume. Even after all these exclusions, however, there
is still a lot to talk about. Rhythms are an essential part of normal brain opera-
tions, and my goal is to convince the reader that neuronal oscillations are a funda-
mental physiological brain function. In turn, I hope that these foundations will
serve future progress in understanding pathological rhythms and drug-induced
changes on brain oscillations, both beneﬁcial and deleterious.
The Best Strategy
The discovery versus creation question of cognitive neuroscience does not have
an easy solution. When I criticize the shortcomings of introspection, philoso-
phy, and psychology, on the one hand, and reverse engineering and reduction-
ism, on the other, I do so not to condemn them but to emphasize the point that
there is no single good strategy to solve all complex problems. The “best” ap-
proach for progress always depends on the techniques available and the testabil-
ity of the concepts developed. The methods used, in turn, largely determine
what types of questions are asked for further inquiry. It is fair to state upfront
that a unifying theory of the brain or the mind that could lead the way is not on
the horizon yet. This does not mean that we should not strive to build one. The
topics discussed in this book—emergence of spontaneous order, oscillations,

28
RHYTHMS OF THE BRAIN
synchrony, structure–function relationships, and representation and storage by
cooperating cell assemblies—represent the middle grounds of brain activities be-
tween the microscopic mindless neurons and the wise, performing brain. My goal
is to disclose how the brain gains its smartness from the organized complexity of
its constituents. What follows is a progress report on the fascinating endeavors of
neuroscience, a tour of ﬁelds that are usually not linked together in a single piece
of scientiﬁc writing.

Cycle 22
Structure Deﬁnes Function
If we could document all the connections and wiring patterns in the brain of an in-
dividual, would we understand how they give rise to her behaviors?1 This is a
teasing question physiologists love to pose to hard-working morphologists. The
answer, of course, is no, with some qualiﬁcation: we can never discover brain
computation without revealing its basic connectivity. Understanding the perfor-
mance of the brain requires a two-pronged approach. First, we need to know the
basic “design” of its circuitry at both microscopic and macroscopic levels. Sec-
ond, we must decipher the rules governing interactions among neurons and neu-
ronal systems that give rise to overt and covert behaviors. The complexity and
precision of brain wiring make an experimental approach absolutely necessary.
No amount of introspection or algorithmic modeling can help without parallel
empirical exploration. Understanding the principles of neuronal connectivity is
important because this knowledge can guide our thinking about implementation
of function. Wiring a small number of neurons is relatively straightforward,
whereas the task of cabling the human brain is comparable to connecting all stars
in the universe. If the brains of all species were uniquely connected in fundamen-
tally different ways, the task would be hopeless. On the other hand, if connections
Architecture is the will of an epoch translated into space.
—Ludwig Mies van der Rohe
29
1. The term “wiring” is used synonymously with axonal connections but with the important quali-
ﬁcation that the ﬁne connectivity in the brain is ﬂexible and perpetually changing. As a result, no two
brains have identical connectivity, in contrast to the rigid, blueprint-determined wiring of machines.

30
RHYTHMS OF THE BRAIN
2. This Cycle is not meant to be an exhaustive description of the organization of the different cor-
tical regions but concentrates on the fundamental rules of local vs. long-range connections. The archi-
tecture of the neocortex is contrasted to the “random space” of the hippocampus in Cycle 11 and the
strictly local connectivity of the basal ganglia and cerebellum in Cycle 13.
3. Such capabilities are also present in single-cell organisms, e.g., Paramecium caudatum or
mammalian sperm cells.
4. Fractals are usually deﬁned in statistical or qualitative terms, loosely including anything that
“looks like itself ” when magniﬁed in space or time. According to Benoit Mandelbrot, who coined the
term “fractal geometry,” it is the geometry of deterministic chaos. Fractal graphics are excellent ex-
amples of reverse engineering translating the shapes of irregular objects into mathematical formulas,
from which the entire image can be reconstructed. Because, by deﬁnition, any piece of the fractal geo-
metric design contains a miniature of the entire design, fractals can be completely described by one
piece of the design and a rule that determines how the contiguous pieces ﬁt together. The scale invari-
ance of fractals implies that knowledge of the properties of a model system at any scale can be used to
predict the structure of the real system at larger or smaller scales (Vicsek, 1992; Mandelbrot, 1999;
Barabási and Stanley, 1995). Applying this knowledge to neuroscience, knowing the fundamental
properties of the organization of the cerebral cortex in any mammalian species and the rules of net-
work growth, the principal structural organization of smaller and larger brains can be predicted.
among neurons follow the same general algorithmic rules across species,
progress and understanding may be possible. Once in possession of such rules,
we can begin to understand how functions established in small brains can be pre-
served or exploited for other uses over the course of evolution as brain size
grows. This is the scaling problem of neuronal wiring, the main topic of this Cy-
cle. Here, I focus on the general problem of large-scale connectivity, as it applies
to the mammalian cerebral cortex.2 The architectural rules and constraints pre-
sented are believed to determine the local and global computation of the cerebral
cortex.
The Basic Circuit: Hierarchy of Multiple Parallel Loops
A universal function possessed by all brains is to move the body. Moving speciﬁc
body parts or the whole body can be useful even in the absence of sensory infor-
mation of biologic importance. Living in seawater with abundant food around, a
simple rhythmic movement was sufﬁcient to feed the simplest animals. Once
movement control was in place, these simple organisms began to develop sensors
that more efﬁciently guided movements for ﬁnding food, avoiding harmful stim-
uli and adjusting activity patterns to the day/night changes of light so as to maxi-
mize survival.3
The basic circuit capable of the aforementioned control functions is recogniz-
able in all vertebrate brains, small and large. During the course of evolution, the
basic circuit is not fundamentally modiﬁed, but instead, multiple parallel cir-
cuits, consisting of intermediate and longer chains of neurons, are superimposed
on the existing wiring. No matter what fraction of the brain web we are investi-
gating, neuronal loops are the principal organization at nearly all levels. A physi-
cist would call this multilevel, self-similar organization a fractal of loops.4 In

Structure Deﬁnes Function
31
Figure 2.1. The brain is organized in a hierarchy of multiple parallel loops. Intermediate-
and long-range connections link the various loops in the cerebral cortex. Sensory informa-
tion passes through the thalamus, which is under the control of neocortical feedback. The
hippocampus provides a relatively random synaptic space. The strictly parallel loops in the
basal ganglia and cerebellum are mainly inhibitory. The main pathways are genetically de-
termined, but ﬁne-tuning of connections (“calibration” by the output–input match) is under
the supervision of the body, environment, and interactions with other brains.
addition to the multiple parallel loops, links between lower and higher layers are
formed, generating a hierarchical form of organization among the parallel loops
(ﬁgure 2.1).
Building a house from scratch is often easier than expanding it. In principle,
this truism would apply to the brain, as well, if brains were to be built by some
a priori design. However, no blueprint is available for the brain of any newly
evolved species. “New” brains are modiﬁed versions of older ones, and the new
brain carries the major features of all previous versions. Much like the various
layers of an archeological site, the oldest circuits of the brain are located at the

32
RHYTHMS OF THE BRAIN
5. Startle reﬂex is an involuntary reaction to a sudden unexpected stimulus, which involves ﬂexion
of most skeletal muscles, a blink, and a variety of visceral reactions due to activation of the midbrain
paleocircuits. The latency of the acoustic startle reﬂex in the rat is a mere 8 milliseconds, measured
from tone onset to the beginning of the electromyographic response in the hind leg. This extremely
short-latency response involves the auditory nerve, ventral cochlear nucleus, nuclei of the lateral lem-
niscus, nucleus reticularis pontis caudalis, spinal interneurons, lower motor neurons, and muscles, all
connected by fast-conducting ﬁbers (see Swerdlow et al., 1999). An even simpler reﬂex is the patellar
reﬂex, which involves just one synapse in the spinal cord between the dorsal root ganglion sensory
neurons and the large motor neurons of the ventral horn of the cord. Activity in the superimposed
loops can often suppress the effectiveness of the patella reﬂex, e.g., by attending to it. In amphibians,
reptiles, and birds, sensory-motor switch time is brief, depending on one or two synapses, and the re-
sponses are more predictable (Bullock and Horridge, 1965) because there are only a few longer su-
perimposed loops that can interfere with the stereotypic, species-speciﬁc responses.
bottom. Subsequently developed levels rest in an intermediate position, while
the most recently developed structures are situated on top. These parallel layers
or loops interact with each other. The evolutionarily more recent layer can
suppress the progression of neuronal impulses in the short (older) loops and
reroute the trafﬁc to the longer, higher level loops. From this evolutionary per-
spective, the main difference between the brains of simple and complex animals
is merely the number of neuronal loops that link the outputs to the inputs. In
simple brains, there are few neuronal steps between sensation and action,
whereas in complex brains, the number of neuronal steps through which activ-
ity passes can vary from short through intermediate to long loops. Such simple
quantitative details of neuronal organization can largely account for the differ-
ent responses of phylogenetically older and younger organisms to the same
physical world.
Take the example of an unexpected loud noise that produces a startle reﬂex,
which involves the sudden contraction of many of your muscles. The neuronal
circuit responsible for such an ancient but important reﬂex, present in all mam-
malian species, is simple and well understood.5 However, the same kind of loud
sound embedded in a different context, for example, the timpani in Handel’s Mes-
siah, may induce a totally different reaction in the human brain. First of all, no
startle is elicited. Instead, the sound waves in your ears may trigger neuronal
representations of previous memorable performances. The circuitry involved in
the latter process is quite elaborate and not well understood. In short, the same
physical input can evoke very different outputs in complex brains, depending on
the context in which the stimulus is presented. It is important to emphasize again
that there is nothing in the physical world by itself that would predict a priori the
response of the brain to a stimulus. It is often largely the state of the brain that de-
termines the behavioral outcome. We all know this. What we do not know, how-
ever, are the neuronal processes underlying the word “state.” A part of this
volume is devoted to the exploration of this term.
Before proceeding further, we need to take another look at the loop organiza-
tion. The loops are not closed by brain wiring, but there is a “gap” between the
neuronal connections controlling the outputs and inputs that transmit information

Structure Deﬁnes Function
33
6. The central long-range loops between motor and sensory areas (serving the reafferenz prinzip or
corollary discharge) are likely formed under environmental supervision (see also Cycles 7 and 8).
These motor to sensory projections serve to distinguish, for example, movements of the visual world
from self-controlled movement of the eyes or head.
7. Estimates for the total number of neurons in the human brain vary between 10 billion and 1 tril-
lion (Williams and Herrup, 1988). Of these, the number of neocortical neurons ranges from 15 to 31
billion. Other forebrain structures, including the hippocampal region, basal ganglia, and thalamus,
contain an additional 5–8 billion, and fewer than 1 billion are in the brainstem and spinal cord com-
bined (Shariff, 1953; Lange, 1975; Pakkenberg and Gundersen, 1997). The largest variability in the
total number estimate involves the uncertainty about the number of granule cells in the cerebellum,
ranging from a few billion to 70 billion (Braitenberg and Atwood, 1958; Lange, 1975). Some other
species have more neurons than we do. The 6,000-gram brain of the elephant may have two to three
times as many neurons as does a 1,350-gram human brain (Jerison, 1985; Martin and Harvey, 1985).
For the distribution of neurons in various structures and other quantitative anatomic data, an excellent
source is Blinkov and Glezer (1968).
8. Synapses are the structural links between neurons that allow for unidirectional communication
between neurons (Peters et al., 1991).
9. For example, Ramón y Cajal (1909–1911), Nauta and Feirtag (1979), Szentágothai (1978),
Braitenberg and Schütz (1998), Allman (1999). In addition, more than 20,000 anatomical papers have
been published on the problem of brain connections.
from the sensors.6 The gap may be closed by actions exerted by the brain on the
body and the environment, a process that “calibrates” neuronal circuits to the
metric of the physical world and allows the brain to learn to sense. As a result of
this supervised teaching by the actions, the sensors can be directed meaningfully
and effectively. The ultimate outcome of this calibration-teaching process is that
from past experience the brain can calculate the potential outcomes and convey
this prediction to the effectors (e.g., the skeletal muscles). The consequences of
this action–brain–sensors arrangement on brain development is discussed in Cy-
cles 8 and 11.
Large-Scale Organization of the Brain Web
In any freshman course on the gross anatomy of the brain, one learns that the
human brain has about 100 billion (1011) neurons with an estimated 200 trillion
(2×1014) contacts between them.7 We also learn that, although neurons are
sparsely connected, they are within a few synaptic steps from all other neurons.8
What one does not learn is the general principles of organization that govern this
complex connectivity.
Although brain structure has been studied by generations of brilliant minds,9
the interconnection issue and especially its relation to function have remained an
unsolved mystery. Let me brieﬂy outline the heart of the problem and then exam-
ine it in some detail. Suppose that nature introduced a useful nervous function, for
example, a mechanism for controlling muscles. Because the contraction speed of
vertebrate muscles is determined by the properties of myosin, a contractile pro-
tein similar in all mammals, the speed of muscle coordination should be largely

34
RHYTHMS OF THE BRAIN
10. Myosin is a contractile protein found in skeletal muscles. Human myosin is only twofold
slower than the myosin of the 100-fold smaller rat (Szent-Györgyi, 1951).
preserved across species, independent of the size of the nervous system.10 Several
other temporal aspects of the physical world affect various mammals similarly;
therefore, often small and large brains must have to deal with problems of more
or less the same temporal scale.
While a general solution for temporal scale preservation may be trivial for an
electronic device where electric pulses travel at the speed of light, the slow con-
duction velocity of neuronal connections in the brain poses a challenging problem
for preserving the time necessary for getting from one neuron to any other, be-
cause in larger brains neurons are inevitably spaced further apart. In general, the
problem we have to address is how to preserve the temporal windows of action
and perceptions for functions to remain useful in brains of various sizes. As dis-
cussed in Cycle 6, the frequency bands of the various brain oscillators are kept
relatively constant throughout mammalian evolution even as the numbers of neu-
rons and their connections have increased enormously. The problem of preserving
a function and performing it at a constant temporal scale while multiplying the
number of contributing neurons does not have a straightforward solution. If all
neurons in the cerebral cortex are to be given an equal chance to contribute to a
global function, how should they be connected in small and very large brains?
The general principles of neuronal organization have yet to emerge. Nevertheless,
we can compare some brain facts with other known connected systems and learn
something along the way. Let us begin with the problem of connectivity.
Scaling Problems in Brains of Various Sizes
Let us go back to the 1011 neurons that are packed in our skull volume of 1.5
liters. Each neuron is a complex device, perhaps the most complicated cell type
nature has created. Neurons are treelike structures with branching patterns rang-
ing from those of small bonsais to the giant sequoias. This structural intricacy has
developed as an elegant and effective way to maximize the receptive surface area
for connections from other neurons. To further increase the number of sensors,
the branches, called dendrites, are covered by numerous spines in most neurons.
By growing branches and spines, a neuron can create between thousands and tens
of thousands of receptive contact sites, called postsynaptic receptors. Spine den-
sity and the extent of dendrites vary somewhat in brains at different levels of
mammalian evolution, but not much. The most prevalent neuronal type of the ce-
rebral cortex, the pyramidal cell, has 5,000–50,000 postsynaptic receiving sites. It
is through these appositions or synapses that neurons connect to each other. In the
human cerebral cortex, 90 percent of connections are established with other neo-
cortical pyramidal cells.
With this new information, we can generate another number. Assuming just

Structure Deﬁnes Function
35
11. Without the support of glial cells, neurons cannot survive. Furthermore, neurons are hungry
and must be constantly fed. For this reason, the brain is supplied by the highest density of blood ves-
sels in the body and uses 20 percent of the body’s blood-supplied oxygen and energy nutrients 24
hours a day, 7 days a week, even during sleep. The energy consumption of the newborn’s brain is even
more telling. As much as 40 percent of the body’s energy resources are devoted to the developing
brain. Even during hibernation, in those animals that can afford this luxury, brain metabolism is not
reduced appreciably (Meyer and Morrison, 1960).
12. A graph is a symbolic representation of a network, deﬁned abstractly as a set of linked nodes.
A node (also called vertex) is a terminal point or an intersection point of a graph, e.g., a neuron. Nodes
are connected by edges or links, e.g., an axon. In brain networks links are directed. The path is an un-
interrupted sequence of links. Finding all the possible paths in a graph is important to assess the ﬂow
of trafﬁc from node to node (in our case, neuron to neuron).
13. The ﬁrst graph problem was ﬁrst formally posed by the town folks of Königsberg: how to walk
across the seven bridges erected on the two branches of the Pregel river without crossing one twice.
The bridge problem was solved by the Swiss-born mathematician Leonhard Euler. Euler provided a
rigorous mathematical proof: it is not possible. What began as a simple mental exercise for Euler gave
birth to a new branch of mathematics: graph theory. A random graph (Erdös and Rényi, 1959) is one
in which one begins with n isolated nodes and makes a pass through the graph considering, for every
possible link, whether or not to create a link there, based on some probability p, where p is between
zero and one, inclusively. If p=0, all n nodes remain isolated and no links are formed. p=1 refers to a
complete graph, where every node is connected to all other nodes through at least one node. Connec-
tivity can be made to be sparse by reducing p. Random graphs do not form clusters, i.e., groups of
highly connected nodes. For an introduction to graph theory, I suggest Hayes (2000a,b). The detail-
rich graph book Bollobás (1985) is among the most frequently consulted by graph theorists.
5,000 connections per neuron, all neurons in the human brain (1011) would have
about 5×1015 connections via their thin and long processes, called axon collater-
als. Axons typically emerge from the cell body and take a long, convoluted jour-
ney to reach a few dozen or tens of thousands of nearby and distant neurons.
Axons occupy much more volume in the brain than do the cell bodies, dendrites,
and spines combined. However, we cannot afford the luxury of using all of our
skull space for only neurons and their connections. Neurons, including their ax-
ons, are surrounded by numerous glial cells and an extensive brain vessel system.11
These supporting structures require a lot of space. In fact, the real computational
elements of the brain, the neurons and their connections, occupy less than a liter
of volume.
For the moment, let us put aside the physical details and see how we can pro-
ceed with the issue of connectivity using the knowledge available to us from
mathematics. For the sake of simplicity, let us start with just 50 neurons. To link
each of these neurons to all other neurons would require 1,225 bidirectional con-
nections. But we know that this is not the brain’s choice. Neurons are not con-
nected to all other neurons but only to a fraction of them. What is the minimum
number of links that can connect each neuron to at least one of its partners? The
general solution to this sort of a problem is the most famous in graph theory.12 It
took the genius of two mathematicians, Paul Erdös and Alfréd Rényi, to solve this
puzzle.13 They showed, that using just 98 randomly placed links, a mere 8 percent
of the 1,225 all-to-all connections, we can connect all 50 nodes (neurons). Of
course, the math underlying random graph theory provides a solution for fully

36
RHYTHMS OF THE BRAIN
14. Interestingly, this misguided thinking about random graphs led Braitenberg and Schütz (1998)
to postulate that “any two neurons may communicate with each other via no more than 2 or 3 inter-
posed neurons” (p. 193). This statement is quite surprising since they emphasize the fact that most
cortical connections are local.
15. In the Erdös number graph the nodes are mathematicians, and a link connects mathematician
X to mathematician Y if X has written a paper with Y. The Erdös number of X is the length of the short-
est path in this graph connecting X with Erdös. (see http://www.oakland.edu/enp/).
connecting any number of neurons. The good news is that with increasing num-
bers of neurons, the fraction of the links required to connect nodes to the graph
drastically decreases. For example, for 1,000 neurons only 1 percent of all possi-
ble combinations are needed to connect every one. For a billion neurons, the num-
ber of links is less than 0.000001 percent of the possible total. Thus, building
larger and more complex brains with ever-increasing numbers of neurons does
not require a linear increase in connectivity, although it still requires a staggering
increase of wiring.
Now, in principle, we can easily wire up 1011 neurons with the available
5×1014 synapses so that no neuron is left out. In a random graph system, if each
neuron receives, say, 100 inputs, each neuron should give rise, on average, to 100
outputs, since the total convergence and divergence are identical. Based on the di-
vergence of an average cortical pyramidal neuron, each neuron can transmit in-
formation to 5×103 randomly selected peers. The second-order neurons,
connected randomly to their 5×103 peers, will connect us to 2.5×107 targets in
just two steps (synapses). Thus, according to the mathematical foundation of ran-
dom graphs, we can get from any neuron to any other neuron in the human brain
through just three synapses.14 By now, anyone who has read the book or seen the
movie Six Degrees of Separation or is familiar with such websites as the Erdös
Number Project may think that there is some parallel between the brain web and
these entirely different worlds.15 The sophisticated reader should suspect, how-
ever, that something went grossly wrong with the logic somewhere.
Our quick navigation through the jungle of the brain, using just three synapses,
appears too good to be real. Three degrees of neuronal separation are better than
the ﬁve or six synapses neuroanatomists have previously guessed. This discrep-
ancy is not such a big problem, however, because the neuroanatomists’ six
synapses refers to the claim of connectivity “from anywhere to anywhere,” that is,
the worst-case scenario. The mean degree of neuronal separation, therefore,
should be smaller. So the error of the underestimation must have occurred else-
where. In abstract mathematical space, connecting a node to neighbors or to any
distant nodes is done with equal ease, because there are no neighbors and distant
partners, and no physical wiring needs to be laid down. But connecting neurons
randomly in real physical space would require a lot of expensive connections and
a very large skull to hold together all the wiring. Furthermore, we know for a fact
that neurons in the visual cortex, for example, are not randomly connected to just
any other neurons locally, or to the auditory cortex, motor cortex, or the frontal
part of the brain. We also know that most connections among neurons are local in
most brain structures.

Structure Deﬁnes Function
37
16. Synaptic path length is the average number of synapses between randomly chosen neuron pairs
(i.e., the length of the most direct route between the most distant neurons). The term “network diame-
ter,” used mostly for describing connection access on the Web, is synonymous with synaptic path
length. Synaptic path length is different from assessment of path lengths by gross anatomical and
fMRI methods, which estimate values between two and three (e.g., Hilgetag et al., 2000; Sporns and
Zwi, 2004; Achard et al., 2006). The area-to-area path length is always shorter than neuron-to-neuron
path length.
17. One consequence of decreased interconnectedness in larger brains is increased segregation of
the neuronal pool. Ringo (1991) suggested that this segregation may be the force for more specializa-
tion in larger brains, for example functional differences between the hemispheres.
18. This pioneering paper (Watts and Strogatz, 1998) is an important reading for anatomists and
systems neuroscientists. For a thorough airing of the background and the discovery of small-world for-
malism, see Strogatz (2003). Another readable and personal account of the events leading to the for-
mulation of small-world networks is Watts (2003). Buchanan’s small paperback (2003) is yet another
easy read on the subject. Small-world networks are basically random graphs with local clustering.
Using mostly local connectivity we can build a graph different from random
graphs. In this new graph, local clustering can be very high. Now we face a dif-
ferent dilemma. In a graph with connections only between neighboring neuronal
clusters, it would take literally thousands of synapses to navigate from a neuron in
the visual part of the brain to a muscle-controlling neuron in the motor cortex. For
a brain using many serially connected neurons, sensing a fast-approaching object
and avoiding it by controlling the appropriate body muscles would be a hopeless
effort because the conduction velocity of pulses is very slow in the axon. Numer-
ous serial synaptic steps and the long time involved may also defeat the main
computational advantage of the cerebral cortex: sharing locally computed infor-
mation with all other neurons.
Thus, two organization principles—the degree of local clustering and the degree
of separation between the distant parts of the brain (let us call it synaptic path
length)16—compete with each other. Random connections can shrink the degrees of
separation, whereas the density of local connections increases the clustering effect.
It appears that we need both types of connectivity in the cerebral cortex so that efﬁ-
cient large-scale trafﬁc can be accomplished with a minimum amount of wiring.
Anatomists have known for quite some time that the majority of local connec-
tions are supplemented by long-range connections, although the rules that deter-
mine the “optimal” ratio of short- and long-range connections have yet to be
discovered. Is this ratio a constant in brains of various sizes, or, if different, can the
rule of “optimal” wiring in growing brains be determined? As the brain is scaled
up, it is expected that the percent connectedness (i.e., the fraction of all cells with
which any one cell communicates directly) should decrease. If the functional con-
nectedness is to be maintained in the face of increased neuron numbers, then the
average axon length connecting the neurons will be substantially increased. The
result is reduced computational speed due to axon conduction delays.17
A potential remedy to the brain wiring problem emerged outside the neuro-
science ﬁeld in the form of a three-page paper titled “Collective Dynamics of
‘Small-World’ Networks” published by Duncan Watts and his graduate advisor,
Steve Strogatz, at Cornell University.18 The crux of their mathematical insight is

38
RHYTHMS OF THE BRAIN
19. Degree of clustering or the density of local connectivity can be characterized by the clustering
coefﬁcient, deﬁned as the average fraction of neighbors directly connected to each other.
20. When testing their abstract theory, Watts and Strogatz examined three real-world networks:
power lines, the social web of Hollywood actors, and the neuronal net of the nematode Caenorhabdi-
tis elegans. These examples ﬁt the bill for small-world network architecture. But other real-world ex-
amples, including the mammalian brain, do not, as they realized later. In his book Six Degrees (2003),
Duncan Watts almost apologetically declared: “We made one big mistake. We did not check!” I, for
one, am glad they did not. Had they checked and looked elsewhere, they may have conceded defeat
and would not have submitted their paper. The scientiﬁc community would have been deprived of a
great discovery.
illustrated in ﬁgure 2.2. Suppose that each circle is a neuron, and the lines repre-
sent axonal connections. If we scale up the illustrated graph a bit so that each neu-
ron is connected to 10 of its nearest neighbors (rather than just four as shown), we
will have 5,000 synaptic connections and 0.67 degree of clustering, a measure
they introduced.19 Now, let us replace 50 local connections with 50 new randomly
placed links (1 percent of all); the degree of clustering decreases only negligibly
(0.65). Nevertheless, the new graph is entirely different in its other properties.
Without the 1 percent random but long-range connections, the average synaptic
path length (i.e., the degree of neuronal separation in the network) is about 50,
which is too long to achieve any useful function given the long axon conduction
and synaptic delays. With the few random links added, it drops to 7. The beauty of
the new arrangement is that it still preserves some advantageous features of the
old random graphs.20 The number of random links required to keep the synaptic
path length short increases much less than the size of the network. In other words,
the larger the network, the greater the impact of each random link on the effective
connectivity of the network. For 20 billion neurons in the human cerebral cortex,
organized mostly in local clusters, a much smaller fraction of long axonal links is
Figure 2.2. Small-word networks combine the advantages of regular local organization
and random wiring. Each network has 20 nodes (e.g., neurons), each of which is connected
to four other neurons. The synaptic path length (getting from any neuron to any other neu-
ron) is longest in local networks and shortest in random networks. With an intermediate
probability of random connections, the small-world network is highly clustered locally,
yet has small synaptic path length, similar to the random graph. With increasing numbers
of neurons, the proportion of long-range connections required to keep the synaptic path
length constant dramatically decreases. Reprinted, with permission, from Watts and
Strogatz (1996).

Structure Deﬁnes Function
39
Figure 2.3. The synergy of tension and integrity (tensegrity) provides robust stability to
structures. Buckminster Fuller’s tensegrity principle is used in many scalable structures,
such as the Epcot sphere in Orlando, Florida (left). Right: Major divisions of the left hemi-
sphere of the human brain. The cerebral cortex is also a scalable structure. The cortical and
cerebellar surface is increased by numerous grooves (gyri and ﬁssures). Systems deﬁned
here are characterized by more extensive long-range connections within members of the
system than across systems.
21. Barabási’s bestseller Linked (2002) is an entertaining and easy read on the subject of scale-free
systems.
needed to achieve the same short synaptic path length than in the much smaller
brain of a mouse (ﬁgure 2.3).
At about the time that Watts and Strogatz tried to ﬁgure out the math behind
their small-world universe, another physicist, Albert-László Barabási, at the Uni-
versity of Notre Dame struggled with a seemingly different problem. He studied
the rules of trafﬁc in the World Wide Web. By examining the accessibility of the
websites on the Internet, his team realized that trafﬁc is directed mostly toward a
handful of busy sites, for example, the search engine Google and the popular
e-store Amazon.com. These popular hubs are visited orders of magnitude more
frequently than, say, my website. Barabási argued that many real-world networks,
including the Web, evolve by some rules but they cannot be described by illustrat-
ing a typical, representative example. Instead, the connections in these “scale-
free” networks obey a statistical rule called the power law.21
Scale-Free Systems Are Governed by Power Laws
In explanations of complex problems, we often provide a persuasive “typical” ex-
ample that faithfully represents the whole distribution. For example, the brain of
an average adult human male weighs 3 pounds 2.2 ounces (1,350 g). Although this
number represents the brain size for most people, many have smaller or larger
brains than typical. Among famous people, Anatole France’s brain had the lowest
weight ever recorded for any nonretarded person: 1.11 kilograms. The upper end
of the scale is marked by the huge brain—2.01 kilograms—of another novelist,

40
RHYTHMS OF THE BRAIN
22. Phrenology (phrenos is Greek for mind) or cranioscopy assumes that a person’s character and
mental capacity can be detected by the external inspection of the skull. The Viennese physician Franz
Joseph Gall suggested that mental faculties could be deduced from the sizes and shapes of various
bumps and depressions on the skull because the tissue of the brain somehow shapes the hard bone.
Gall’s early maps on criminals and the insane led to his conjecture of “theft organs” and “murder or-
gans,” followed by numerous other terms, e.g., “benevolence,” “self-esteem,” “conjugal love,” “imag-
ination,” “religious experience,” “wit,” “cunningness,” and “honesty” (Damasio, 1995). Today, we are
witnessing the emergence of a new form of phrenology by searching for the physical locations in the
brain responsible for these and other invented terms based on our contemporary imaging methods,
e.g., fMRI and PET (see Cycle 4).
23. For brain weights of famous people and related stories, see Gould (1980).
24. The central limit theorem demonstrates that, in large enough samples, the distribution of a
sample mean approximates a normal, bell-shaped curve. Essentially, it means that a sufﬁcient number
of random samples of independent observations will have statistical properties similar to the popula-
tions they were chosen from. The approximation steadily improves as the number of observations in-
creases.
25. A function, f(x), is a power law if the dependent variable, x, has an exponent (i.e., x is raised to
some power, hence the name of the law). E.g., for x=1, y=1; x=2, y=4; x=3, y=9, etc., y=x2 ap-
plies. I.e., y is a power law in x with a power or index of 2. E.g., if 1,000 neurons have two synaptic
connections, then 500 have four, 250 have eight, only 125 will have 16, etc. . Here the index or power
is 2, but it can be any small number. Thus, a power law implies that small occurrences are extremely
common whereas large instances are rare. In scale-free systems, the rate of decay is much slower than
the decay rate for normal distribution, and there is no characteristic peak in the distribution that would
characterize mean behavior. Points distributed along a line in a log–log graph are the hallmark of the
power law. What makes the power laws so powerful is that they seem to be behind many seemingly un-
related complex systems, e.g., phase transitions of matter, chaos theory, fractals, airport trafﬁc, the
the great Russian writer Sergeyevich Turgenev. Ironically, Franz-Joseph Gall, the
founder of phrenology,22 had a very small brain (1.2 kilograms).23 These individ-
ual differences are, however, quite small, and brain weights of humans are pretty
much the same, with some minor variations on the left and right, thus creating a
bell-shaped curve (i.e., normal or Gaussian distribution). Nobody has a brain 10
times smaller or 10 times larger than that of the average person. This so-called
normal distribution is widespread in nature. Its general applicability is a conse-
quence of the central limit theorem,24 which suggests that if a large number of in-
dependent inﬂuences contribute to the outcome of some event, that outcome will
result in a bell-shaped distribution with a characteristic mean.
In scale-free systems, things are different. In systems governed by power law
statistics, there is no peak at an average value, and a select small group can have
the largest effect. For example, if we drop a vase on the ﬂoor, it will break into
fragments of varying size. There will be a lot of debris but also a number of rea-
sonably large fragments. If we collect all the pieces, from the microscopic ones to
the large, and plot their numbers as a function of size on a log–log scale, we will
get an oblique line: a power law for fractures. No one fragment can be considered
as the characteristic size. There is no “typical example” in a scale-free system. A
power law implies that there is no such thing as a normal or characteristic size
scale and that there is no qualitative difference between the larger and smaller
pieces or events.25

Structure Deﬁnes Function
41
size distribution of cities, the connection structure of the Internet, and trafﬁc at various websites
(Barabási and Albert, 1999). Viewing things from a broad perspective, small-world and scale-free ar-
chitectures are fundamentally similar. In a strict small-world network, long-range connections are ran-
domly placed. In scale-free systems, short-, intermediate- and long-range connections are distributed
according to a power law distribution. Coexistence of local and global interactions is also ubiquitous
in many other systems, living and nonliving (Csermely, 2005).
26. The brainstem is a collective name for structures directly above the spinal cord, including the
medulla, pons, and midbrain.
27. Joseph LeDoux of New York University, a pioneer in the study of emotions as biological phe-
nomena, has been studying the role of the amygdala in fear conditioning (LeDoux, 1996).
28. Modern architecture began in the twentieth century with the goal of turning engineering into
architectural-aesthetic structure. Rather than simply fusing architecture and engineering, the most
beautiful designs arise from the struggle between the two disciplines—Santiago Calatrava’s ﬂoating
roof of the Olympic Stadium in Athens is a beautiful example.
The abstract math behind the power law implies that, instead of the roll of the
dice, the events are not completely independent of each other, and a few large
events or connection “hubs” dictate the action. To provide an example from the
brain, a small collection of cells in the brainstem,26 called the locus ceruleus, lit-
erally meaning blue spot, is such an effective hub in the brain. Its neurons contain
and release a substance called norepinephrine, which, when oxidized, turns blue.
Each of the 10,000 or so locus ceruleus neurons receives input from only a few
hundred other neurons. But their output territory is enormous. They innervate
nearly the whole brain and spinal cord. If the ﬁring pattern of these neurons
changes, their inﬂuence is conveyed to virtually the whole brain. Other examples
of hubs in the brain include the cholinergic basal forebrain and dopamine-
producing cells of the substantia nigra (meaning black substance).
Because of their widespread inﬂuences, these brain hubs are susceptible to tar-
geted attacks of unknown etiology. Once a hub is damaged, the consequence is a
large-scale brain dysfunction, such as Parkinson’s disease. The amygdala, a hub
with numerous cortical projections, is needed for fear conditioning.27 Impaired
neuronal hubs, like their abstract and real-world cousins, can cause clinical prob-
lems in at least two different ways: ﬁrst, by failing to transfer information due to
the missing neurons, and second, by propagating potential errors, brought about
by the surviving hard-working minority, to a large number of brain sites. As de-
scribed in subsequent Cycles of this book, the brain has adopted a variety of ar-
chitectural solutions whose exact descriptions require novel anatomical approaches
and new mathematical solutions.
The Tensegrity Plan of the Cerebral Cortex
Before modern times, buildings were constructed from heavy materials according
to Egyptian, Greek, and Roman concepts of architecture.28 However, structures are
only as strong as their weakest link. With the traditional concepts and materials,

42
RHYTHMS OF THE BRAIN
29. The term “tensegrity” is used in this volume as a metaphor that reﬂects both structural and dy-
namic stability of the cortex. Tensegrity in an architectural system stabilizes a structure by balancing
the counteracting forces of discontinuous compression and continuous tension. The compression ele-
ments of the construct “ﬂoat” in continuous tension network, as ﬁrst recognized by the architect-
engineer Buckminster Fuller or by the sculptor Kenneth Snelson, depending on which argument you
prefer. According to Buckminster Fuller, tensegrity or, as he later preferred to call it, synergetics is a
new strategy of design science, which starts with the whole rather than parts, echoing the ideas of
Gestalt psychologists (Buckminster Fuller, 1975–1979). The fundamental unit in synergetics is the
equilateral triangle (60 degrees coordination) rather than the rectangle of traditional geometry (90 de-
grees). Buckminster Fuller was likely aware of the works of the evolutionary biologist D’arcy Thomp-
son (1917), who expressed similar ideas. Thompson believed that living structures obeyed engineering
principles. For Thompson, form is a mathematical problem, whereas growth is a physical problem.
Genetic information provides only a general plan, and the formative power of physical forces deter-
mines the ﬁnal form, depending on the “scale” of the organism. Among his most striking examples is
the geometrical transformation of baboon skulls into skulls of other primates or humans.
30. Tensegrity dynamics in brain networks is achieved by the balance between excitatory and in-
hibitory forces. Dynamic tensegrity provides a magic meaning for the New World shamans through
the teachings of Carlos Castaneda (1972). The Yagui shamans in Mexico perceive the world’s “ﬂoat-
ing pure energy” directly by a process they call “seeing.” The energy entering the shaman’s body con-
verges at the “assemblage point,” where pieces of the world come together. The assemblage point is
the very spot where perception of the world and “pure energy” are assembled. Although the assem-
blage point is generally ﬁxed in the body, it can be displaced during sleep and by “volitional dream-
ing,” assisted by a special concoction, containing the divine mushroom of the Psilocybe family (the
chemical structure of its active ingredient is similar to the neurotransmitter serotonin). During the
course of the “seeing” sessions, the shamans go through a series of rhythmic movements and postures,
called “magical passes,” that kindle volitional dreaming. According to the shamans’ belief, these
dreams foster the optimum balance between internal states and the “energy of the universe”: a tenseg-
rity state, a perfect harmony of opposing forces.
31. Harod Kroto and Richard Smalley, the experimental chemists who discovered C60, the carbon
cluster-cage molecule, named it buckminsterfullerene because they intuited that the atoms were arranged
in the shape of a truncated icosahedron—Buckminster Fuller’s geodesic dome (Kroto et al., 1985).
a triple-size replica of Stonehenge or St. Peter’s Basilica cannot be built. In other
words, these conventional architectural plans are not scalable. Yet, the Louisiana
Superdome in Atlanta has a 680-foot-diameter clear-span roof, a feat unimaginable
for architects before the introduction of the tensegrity (tension-integrity) concept
by Richard Buckminster Fuller in the 1940s.29 His solution was an astonishingly
simple but robust and scalable geodesic design, in fact, nothing more than a series
of contiguous triangles or hexagons on a spherical surface, building out from a
ring in its pole. The continuous pull (convergence) is balanced by the discontinu-
ous push (divergence), producing an integrity of tension–compression, a win-win
relationship.30 The tension-bearing members map out the shortest paths be-
tween adjacent members. Tensegrity structures are omnidirectionally stable and
independent of gravity. They do not have a “weakest point,” and faults do not
propagate, since tension-compression issues are dealt with locally and equally.
Theoretically, there is no internal limitation to the size of tensegrity structures.
Cities could be contained within them. Remarkably, the same principle provides
the stability of the atomic bonds in the geodesic-shaped C60, one of the most sta-
ble molecules, aptly named buckminsterfullerene31 by its discoverers. All these

Structure Deﬁnes Function
43
Fullerenes are closed-cage structures. Each carbon atom is bonded to three others, and the hexagonal
rings are closed into a cage by two pentagonal rings. The carefully chosen 20-letter term, buckmin-
sterfullerene, is not only an homage to a genius who designed whole systems unpredicted by their
parts but also matches the 20 facets of the icosahedron—a letter for each facet.
32. During the Cold War, Paul Baran (1964) worked out a communication network that would en-
dure a large number of breaks. His distributed design is essentially a tensegrity structure. In case of an
attack or router/cable failures, the network would reconstitute itself by rapidly relearning how to make
best use of the surviving links with the shortest path—a real neuron network-like behavior.
33. Most of our cerebral cortex is isocortex with a six-layer laminar structure. The allocortex (also
called heterotypical cortex) has variable numbers of layers. The two types of organization are also
spatially segregated. Projecting from the pyriform cortex (where olfaction is processed), a large
canyon or equator, called the rhinal (i.e., nose-related) ﬁssure, separates the neocortex from the allo-
cortex. The anatomical details described in this section apply mainly to the isocortex. When the struc-
tural and physiological mechanisms apply to both neo- and allocortex, the collective term “cortex” is
used.
34. This crude estimate is only for a single location of visual space in the primary visual cortex
(Hubel and Wiesel, 1974). However, it takes a much larger brain area to compute an image. The local
organization of the neocortex is remarkably similar everywhere, although important differences can
also be identiﬁed. The overall density of neurons in the neocortex is relatively constant, independent
of area (with the sole exception of the primary visual cortex). Each column with 1 square millimeter
of cortical surface area contains 50,000–100,000 neurons (Rockel et al., 1980).
35. In principle, a module should include all cell types of the neocortex, including the various
classes of interneurons, and the connectivity within the modules should be similar. The boundaries be-
tween the modules are difﬁcult to determine because there is a continuity of local, intermediate-range,
and long-range connections between the modules, often without any recognizable discontinuity.
astonishing features of scalability and robustness are due to a few elementary
rules.32
The cerebral cortex is a scalable and robust spherical structure.33 Its modular
plan is identical in all mammals, with ﬁve layers of principal cells and a thin su-
perﬁcial layer containing mostly distal apical dendrites and horizontal axons.
These layers are sandwiched together in the gray matter, spanning only 1–3 mil-
limeters in thickness in all mammals. The structural “algorithm” of the cerebral
cortex is a multiplication of fundamentally identical hypothetical modules, often
referred to as cortical mini- and macro-columns, barrels, stripes, or blobs, with
mostly vertically organized layers of principal cells and numerous interneuron
types (ﬁgure 2.4). It has been suggested that the smallest division of the monkey
cerebral cortex that can perform all of the functions of a cortical area is about 1
square millimeter. The number of these basic cortical modules multiplies by more
than 10,000-fold from the tiniest shrew to human.34 The boundaries of the hypo-
thetical modules, however, are often hard to deﬁne.35
In most body organs, deﬁning a unit of operations is quite useful. For example,
the kidney’s loop of Henle and the liver acinus are true modules. All modules
work in parallel and perform pretty much the same function. In the cerebral cor-
tex, however, modules do not simply operate in parallel but strongly interact.
They do not work in isolation but are embedded in a larger structure. Integrative
neocortical operations emerge through interactions between the modules rather
than within single isolated modules.Yet, the most efﬁcient way for nature to build

44
RHYTHMS OF THE BRAIN
Figure 2.4. The cortical “column.” The neocortex is assumed to consist of repetitive func-
tional modules. A functional module presumably contains all major neuron types and con-
nections, typical of all neocortex. The hypothetical modules can perform similar local
computation.Roman numerals (I to VI) refer the six cortical layers. Reprinted, with per-
mission, from Szentágothai (1983).
a robustly scalable network is through predominantly local wiring, according to
the principles of tensegrity.36
Like Buckminster Fuller’s tensegrity structures, neurons in most, but not all
(see Cycle 11), brain structures attempt to map out the shortest paths with their
36. The primarily neighborhood organization also has an impact on the macroscopic organization
of the neocortex. A clever solution for increasing the cortical surface yet keeping the neurons con-
nected with short wires is by folding it. The resulting grooves (or gyri) on the brain’s surface result in
much of the cortex being buried. In primates, more than half of the cerebral cortical surface is buried 

Structure Deﬁnes Function
45
and not visible directly from the surface. According to David Van Essen at Washington University–St.
Louis, the tug-of-war between hydrostatic pressure and the mechanical tension properties of the axons
is responsible for the formation of cortical folding patterns (gyri). His tension-based theory (Van Es-
sen, 1997) beautifully explains why strongly interconnected neighboring areas are consistently sepa-
rated by an outward fold, whereas weekly connected regions are separated by an inward fold. Like a
parachute, where the push is exerted to the middle of the canvas by air pressure whereas the ropes pull
the edges, the domelike shape of neocortical gyri and cerebellar folia is brought about simply by op-
posing mechanical forces: a tensegrity solution. It is quite refreshing to see explanatory engineering
ideas such as Van Essen’s in the molecular biology era of neuroscience.
37. Kalisman et al. (2005) suggest that axons promiscuously touch all neighboring dendrites with-
out any bias. There are many more potential contacts than the actual number of synapses. There are no
good methods to determine the exact density of local connections, and the estimates vary from 10 to
90 percent (Miles, 1986; Markram et al., 1997; Thomson and Bannister, 2003).
38. Granovetter (1973). This organization is apparent in the neocortex. When neurons in layer 2/3
are connected to each other, they more likely share common input from layer 4 and within layer 2/3
than are unconnected pairs (Yoshimura et al., 2005).
39. These maps are not simply formed according to some genetically determined blueprint but
have to be created by the movement of a body whose morphology constantly changes, especially dur-
ing early development (see Cycle 8 for discussion of the brain-in-the-body subject).
surrounding peers. They receive most information from their immediate neigh-
bors and act locally. Communicating with distant neurons requires costly con-
nections, and transporting electrical pulses over long distances is metabolically
expensive.37 The local order of neuronal connections has important consequences
for brain functions. One consequence is that any one neuron’s targets have a large
degree of overlap with its neighbors’ targets. This principle is not unlike our so-
cial connections. Friends of two friends are more likely to know each other than
are friends of two randomly chosen people.38 For motor organization, this princi-
ple has the consequence of considerably better coordination of adjacent than of
distal skeletal muscles, resulting in a neocortical map of the physical layout of the
individual muscles. Muscles of the thumb and ﬁngers will have more intercon-
nections in their representation than do, say, muscles of the thumb and toe. This
organization is, of course, advantageous since thumb muscles should be better co-
ordinated with physically adjacent muscles of the palm than with those of the foot
or tongue. Muscles are thus most economically represented in the neocortex by
their geometric relationships in the body. A map of the physical layout of the
body surface is also reﬂected in its neuronal representation. Neurons representing
the skin surface of the thumb in the somatosensory cortex are adjacent to those
representing the ﬁngers and distant from those representing the skin of the foot.
This organization makes sense. An insect crawling on one’s hand will stimulate
neighboring receptors in a short time epoch at orders of magnitude higher proba-
bility than in a ﬁnger–toe–nose–ﬁnger sequence.39 As discussed in Cycle 6,
neighboring frequencies in human speech are much more likely to follow each
other than are sounds with random frequency and power (air pressure) distribu-
tions. This likelihood rule is reﬂected by the tonotopic arrangement of neurons in
the auditory cortex. Neurons in the retina, visual thalamus, and cortex combine
information representing adjacent parts of the environment much more efﬁciently

46
RHYTHMS OF THE BRAIN
40. See Cowey (1979) and Allman (1999).
41. Most maps are “distorted,” however, such that certain peripheral parts, e.g., the mouth area in
somatosensation and the fovea in vision, are represented by much larger cortical areas than are others.
Allman (1999) is an excellent informative read on this subject.
42. For a quantitative treatment of wire optimization in the brain, see Cherniak (1995) and
Chklovskii and Koulakov (2004).
43. Julesz (1995) is a marvelous account of the early stages of visual processing, with numerous
illustrations of motion coherence of random dot patterns.
44. Read the original paper by Woolsey and Van der Loos (1970) or a recent review by Fox (2002)
on the modular (barrel) organization of the somatosensory cortex.
than nonadjacent parts.40 The retinotopic topographic representation is preserved
beyond the primary visual cortex, although the proportions change systemati-
cally.41 The interconnected maps of the visual system are arranged so that the dis-
tance traversed by axon paths, connecting neurons that represent adjacent part of
the visual environment, are minimized. This economic compromise of axon
wiring is used to explain why higher-order maps get split and folded, instead of
keeping an orderly two-dimensional layout.42
Imagine a computer screen with random dots appearing in all possible combi-
nations. Even for a low-resolution screen, the possible variations are staggeringly
high, yet only a very limited set of the theoretically possible combinations is in-
terpreted as “ﬁgures” by a human observer. The rest are simply judged as noise.
Of course, there is no a priori reason why some patterns are more meaningful
than others. The “meaning” of the pattern is created by the observer. According to
Béla Julesz, what makes a constellation of dots a meaningful ﬁgure is their local
relation to neighbors and their directional and temporal coherence when the dots
are moving.43 To wire an imagined superbrain that would recognize all possible
dot combinations as distinct with equal ease would require a galactic number of
connections and extensive computation. The real brain, however, is a “compro-
mise” between its evolutionary “goals” and wiring/metabolic costs—an adapta-
tion of brain circuits for making predictions and inferences about the physical
world. For example, in nocturnal bats, a large portion of neurons and cortical con-
nectivity is devoted to echolocation because echolocation is vital for their sur-
vival. Rodents with large sensory whiskers on their face developed a proportionally
detailed somatosensory cortex with a remarkably precise topography of the snout
whiskers.44 In the predominantly visual primate, almost half of the neocortical
neurons and wiring are allocated to the representation of the pictorial world. Fi-
nally, in the most complex brains, a large portion of the cortical mantle, called the
associational cortex, is devoted to generating and processing events that are not
directly related to sensory inputs or motor outputs. Remarkably, the cortical mod-
ules in the associational areas are not fundamentally different from the sensory or
motor cortical areas, an indication that local computation in cortical modules is
quite similar. Organizing most connections locally in cortical modules enables
the brain to map out the neighborhood relations of the environment efﬁciently, be-
cause local interactions are the main organizational principle of the physical

Structure Deﬁnes Function
47
45. The Rorschach inkblot test, developed by Hermann Rorschach, is a projective test of personal-
ity in which a subject’s interpretations of 10 standard abstract designs are analyzed to evaluate the
subject’s emotional and intellectual capacities. The brain cannot help but interpret any input, be it frac-
tals or random dots. Unfortunately, the inkblot test strongly depends on the subjective evaluation by
the experimenter and is not any more reliable than interpreting dreams.
46. Fractal structure in the second-order statistics is ubiquitous for natural scenes (Ruderman and
Bialek, 1994; Bell and Sejnowski, 1997). Neurons in the retina (Victor, 1999), lateral geniculate (Dan
et al., 1996), and primary visual cortex V1 (Olshausen and Field, 1996; Yu et al., 2005) respond
sparsely and most effectively in response to images with 1/f statistics (see Cycle 5 for explanation of
this term).
47. In the study by Fiser et al. (2004), neurons in the ferret visual cortex responded in a much more
coherent manner to a movie containing natural scenes than to a random-noise movie (see also Weliky
et al., 2003).
48. What we see with our brain is much more (or less) than what meets the eye. Illusion is a per-
ceived image that is deceptive or misleading. E.g., the moon seems larger in angular size when it is
near the horizon than when it is high in the sky.
world. We may conclude, therefore, that the statistically correlated features of the
environment are the principal reason for the primarily local tensegrity organiza-
tion of the neocortex.
In light of such anatomical–functional organization, it is surprising that in
most visual experiments simple moving bars and gratings are most frequently
used as stimuli. These shapes have high contrast and sharp edges, yet the surpris-
ing and consistent ﬁnding is that bars and gratings evoke neuronal patterns that
are quite different from those elicited by natural scenes. The more robust re-
sponses evoked by natural scenes are often used as an argument in favor of some
cognitive interpretation of the visual input. Of course, nothing prevents the ob-
server from interpreting even a random dot pattern as a meaningful ﬁgure. The
brain always interprets. This compulsive interpretation is the basis the Rorschach
inkblot test used by clinical psychologists.45 However, one may wonder why a
monkey raised in captivity or an anesthetized cat would attribute some special sig-
niﬁcance to the snow-covered peaks of the Rockies or a Lotus parked in front of
the Monte Carlo Casino. An alternative reason for the superior effectiveness of
these natural stimuli is that the spatial statistics of their feature “neighborhood-
ness” are matched best by the connection topography and local computations of
visual cortical neurons.46 In natural scenes, neighboring elements tend to have
high spatial and temporal correlations. Accordingly, the temporal response dy-
namics of the neurons in the visual cortex closely reﬂect the statistical properties
of the visual scenes.47 In general, the distributions of connections are “tuned” to
extract the most likely information from the environment. The small cost we pay
for such imperfection is illusions48 that inevitably arise when the brain is occa-
sionally confronted with an unusually low-probability geometry of stimuli.
The robust tensegrity plan prevents propagation of faults and allows no weak
points. On the other hand, any compromise in the accuracy of the general plan has
serious consequences. Allowing for just 10 percent imprecision could lead to the
collapse of the tensegrity structure of the Superdome. Brain function fares no bet-
ter. Suppose that we scramble the neurons a bit so that the new allocations will

48
RHYTHMS OF THE BRAIN
49. Multiple sclerosis (referring to microscopic scars) is the result of damage to myelin, the pro-
tective sheath surrounding nerve ﬁbers of the central nervous system. When myelin is damaged, it
slows down the speed of action potential propagation along the axons. See Keegan and Noseworth
(2002) for a review.
50. Several brain structures follow a true tensegrity organization with mostly local connections
(e.g., cerebellum and basal ganglia). These structures perform mainly parallel rather than global com-
putation (see Cycle 13). Global computation and small-world-like organization of the neocortex are
fundamental innovations of the mammalian evolution.
require a 10 percent increase in local connectivity. After rearrangement, we would
still have the exact same connections among the neurons and the same representa-
tion of the physical world by the same neurons. However, carrying electrical
pulses over longer distances would increase the metabolic costs and demand an
enlarged vascular infrastructure. Most important, the coordination of brain os-
cillators and information transfer in multiple synaptic pathways would be sub-
stantially affected because of the cumulative temporal delays. Even with such a
seemingly insigniﬁcant increase in wiring, we would lose all tennis games and
could not articulate properly or perceive normally, as is often the case in people
suffering from multiple sclerosis, a disease affecting the myelin insulation of ax-
ons.49 Local communication is therefore the most robust program in the neocor-
tex, allowing for the topographic representation of the internal and surrounding
environments.
However, with only adjacent connectivity, no matter how dense, the cerebral
cortex would not be a very useful device to guide the organism, because isolated
local decisions are not enough for most complex brain operations. Global, collec-
tive decisions are needed for most cortical functions. Collective decisions, how-
ever, require the cooperative actions of both neighboring and distant areas. Such
ﬂexible cooperation among local and distant cell assemblies is believed to under-
lie nearly all cognitive behaviors.
Are a Thousand Mouse Brains Worth the Brain 
of a Human?
The answer is a deﬁnite “no” when it applies to the cerebral cortex. The fundamen-
tal reason is that simply placing more modules next to each other will not cause a
novel performance to emerge. What makes the tensegrity plan so robust for a ge-
odesic dome is that local static errors and construction weaknesses do not propa-
gate. But locally conﬁned connectivity is a major disadvantage for numerous
computing tasks because with growth the newly added modules will be more and
more distant from each other, making global communication progressively more
difﬁcult, for reasons I address later.50 For now, it is enough to say that, with local
connectivity only, propagating information from one part of the cortex to another
may take too much time. To communicate with all cortical modules efﬁciently,
the synaptic network diameter of the brain, that is, the average synaptic path

Structure Deﬁnes Function
49
51. Braak and Braak (1976) and Braitenberg and Schütz (1998).
52. Braitenberg and Schütz (1998) and Abeles (1982) suggest random connections. Ikegaya et al.
(2004) emphasize extreme speciﬁcity. Wiring economists believe in mathematically deﬁned laws
(Chklovskii and Koulakov, 2004; Sporns et al., 2004).
53. Diameter and even volume of the brain are gross measures, however, because they do not faith-
fully reﬂect anatomical connectivity. E.g., the brain diameter of the giraffe is similar to that of the hu-
man brain, yet its long-range connections are much poorer.
length from one cortical neuron to any other, should remain constant so that ac-
tivity can jump from any place to some other place with more or less equal ease.
This point is where the information discussed above in connection with the
“small-world” and “scale-free” networks becomes useful. To keep the synaptic path
length constant, volume-demanding intermediate- and long-range connections are
needed. A prerequisite for growth with preserved global connectivity is that single
neurons should have longer axons as well as larger, more bushy dendritic trees with
increasing numbers of spines to accommodate more connections. The diameter of
the dendritic arbor of the large pyramidal neurons grew from approximately 0.2
millimeters in the mouse to 1 millimeter in the human cortex. The immediate con-
sequence of the enlarged dendritic tree in larger brains is an increase of the mutual
overlap of the nearby cells. A cylinder corresponding to the diameter of the den-
dritic tree of a single layer 5 pyramidal cell in the mouse and human contains ap-
proximately 3,000 and 100,000 neuronal cell bodies, respectively. Larger cells
occupy more volume and require longer axons to connect them. As a result, the den-
sity of axons and dendrites per volume, and therefore the number of synapses per
cubic millimeter, remains remarkably constant in different species.51 This con-
stancy explains why the submicroscopic structure of the cortex looks so similar in
small and large brains. Because of this dense overlap, an afferent ﬁber shooting to-
ward the surface in a straight line next to the cell body of a chosen neuron has, in
principle, the same probability of contacting spines of that neuron as of any other
neuron. This junglelike arborization of dendrites is the main reason why some in-
vestigators believe that afferents ﬁnd their targets randomly. Others believe in spe-
ciﬁc patterns of innervation or “motifs” that follow precise hardwiring plans, like
plumbing and electrical wiring in a building.52 Because connection matrices gov-
erned by power laws provide a much richer and more diversiﬁed network than ran-
dom choice or speciﬁc motifs, it is quite possible that the brain chooses to follow a
power law design or some other formula even at the microscopic level.
Are small and large brains equally well connected? Keeping the synaptic path
length constant while the brain grows is a necessary requirement for maintaining
global communication among neurons and modules. Adding more than the bare
minimum number of connections is, of course, advantageous for performance be-
cause additional connections allow more effective communication. A clear indi-
cation of a larger, more complex brain’s “need” for long-range connections is that
the volume of white matter increases at approximately at 4/3 power of the volume
of gray matter during the course of evolution. In other words, the cerebral cortex
of larger brains tends to have disproportionately more long-range connections
than do brains of small animals (ﬁgure 2.5).53 While in small insectivores the

50
RHYTHMS OF THE BRAIN
54. For speciﬁc numbers, consult Tomasch (1954), Bishop and Smith (1964), and Swadlow
(2000). The 4/3 power law was described by Allman (1999) and Zhang and Sejnowski (2000). At a
single-cell level, axon arbors of cortical neurons also show scale-free (fractal) statistics (Binzegger et
al., 2005), although dendrites may have more complex organizations (Cannon et al., 1999).
55. Ringo et al. (1994) speculate that this communication disadvantage has contributed to hemi-
spheric specialization in animals with large brains. Indeed, unihemispheric sleep has been described
in ﬁve species of cetaceans with very large brains (Lyamin et al., 2002).
white matter occupies only 6 percent of neocortical volume, it exceeds 40 percent
in humans.54 Furthermore, not all areas and connections expand proportionally.
For example, while the primary visual areas only double in size from macaques to
humans, the growth of the parietal and frontal cortical areas is 10–40 times larger
in humans. The growth patterns in primary sensory areas may follow the small-
world network recipe, since these areas deal with the statistical regularities of the
outside world, a task that is similar in all mammalian species. On the other hand,
in the proliferating “human-speciﬁc” associational areas, the needs and rules are
unknown. More connections, at the expense of brain volume enlargement and
maintenance costs, can provide more efﬁcient computation.
The connectivity problem concerns not only the numbers of ﬁbers but also
communication speed. Conduction velocity of myelinated axons is linearly re-
lated to axon diameter, whereas that of nonmyelinated axons is proportional to
the square root of the diameter. On the basis of increased anatomical segregation
due to the various conduction delay lines, one expects increased separation of
function, as well. Interhemispheric communication through thin callosal ﬁbers
less than 1 micrometer in diameter may lead to delays of more than 25 millisec-
onds.55 The neocortical white matter consists of axons that span a vast spectrum
of diameters, and the distribution of axon calibers may vary considerably in
Figure 2.5. The cerebral cortex of more complex brains deploys disproportionately more
axonal connections than does that of brains of small animals. Left: Cortical white and gray
matter volumes of various species are related by a power law that spans ﬁve to six orders
of magnitude. Connectedness is more important than size. Reprinted, with permission,
from Zhang and Sejnowski (2000). Right: Despite the large variation in brain size, the pe-
riods of various network oscillations in the cerebral cortex are remarkably well preserved
across mammalian species. Photos courtesy of Javier de Felipe.

Structure Deﬁnes Function
51
56. See Schütz and Braitenberg (2002). Axon collaterals of many neurons in the neocortex remain
local (e.g., the numerous spiny stellate cells of layer 4 and most inhibitory interneurons). Since the
many different types of neurons are not equal nodes in the mathematical sense, a coalition of local
neurons may be regarded as a functional unit. If calculated this way, the proportion of long-range
ﬁbers may increase more than the minimum requirement predicted from the strict small-world or
scale-free network rules.
57. Most intermediate- and long-range corticocortical projections originate from layer 2 and layer
3 pyramidal cells. It is not clear whether the large-caliber variation represents ﬁbers of these neurons
or, alternatively, if very large-caliber axons arise from hitherto unidentiﬁed neurons or inhibitory
interneurons.
different animal species. In the human brain, approximately 100–200 million
axon collaterals serve to interconnect symmetric and asymmetric neuronal groups
in the two hemispheres, forming the corpus callosum (or rigid body), and some-
what larger numbers of intermediate- and long-range ﬁbers connect areas within
the same hemispheres. This may sound like a lot of wires, but remember that
there may be 20 billion neurons in the neocortex. Long-range connections thus
may represent a minuscule fraction of neuronal connectivity.56 Because of their
scarcity, the “band width” of communication, that is, the amount of information
transmittable per unit time, is seriously limited in these long-range connections.
To compensate for the long distances they cover, the traveling velocity of action
potentials is accelerated by their strong myelination. Myelin insulation not only
speeds up spike transmission velocity but also protects axons from conduction
failure, reduces the cross-talk from neighboring axons, and allows for transmis-
sion of much higher frequency pulses per unit time than thinner, unmyelinated
ﬁbers.
Conduction velocities vary 100-fold in the long-range connections from as
slow as 0.3 meter per second in the very thin (0.1–0.5 micrometer) unmyelinated
majority to an exceptionally fast 50 meters per second in thick myelinated axons
that interconnect primary sensory areas. A small fraction of the myelinated ﬁbers
in the human brain can have as large as 5 micrometers of diameter.57 Wrapping
the axons with a thick insulation layer for rapid communication occurs, of course,
at the expense of valuable space. The fastest conducting, large-diameter ﬁbers
may occupy 10,000 times the volume of the ﬁnest unmyelinated ﬁbers of the
same length, and they are limited to connecting primary sensory and action areas
that require speed and short time-scale synchrony. Thus, unlike in the translation-
ally invariant abstract small-world models, the expensive long-range connections
in the brain must be used sparingly.
Corticocortical connectivity has changed with each turn of evolutionary dif-
ferentiation, from the pallium of birds to a localized dense connectivity com-
bined with precisely directed long-range connections in primates. Although
brain size and long-range connectivity often go hand in hand, there are some
notable exceptions. For example, the corpus callosum is a phylogenetically re-
cent structure, present only in placental mammals. We can hypothesize, there-
fore, that the brains of placental mammals may be more capable of global
communication than are those of marsupials and monotremes with similarly

52
RHYTHMS OF THE BRAIN
58. Marsupials and monotremes have a large anterior commissure, however. Not much work has
been done on the hemispheric specialization or the intrahemispheric long-range connections in these
creatures.
59. Salthe (1985) is an excellent introduction to hierarchy theory, levels of organization and prob-
lems of scaling.
sized brains, because of their more efﬁcient global connectivity.58 Long-range
connections within the same hemispheres also follow some wire-optimization
rule. Fibers connecting different cortical areas form macroscopic bundles that
are orderly arranged so that intermediate connections can depart easily from
the bundle, like cables in old telephone switch centers. David Van Essen and
his post-doctoral fellow Daniel Felleman at Washington University–St. Louis,
showed that the 30 or so cortical domains involved in processing visual infor-
mation are connected by at least 300 relatively distinct intermediate and longer
connections, implying a hierarchical organization (ﬁgure 2.6). Again, this
arrangement is not by chance. Hierarchical structure is an inevitable conse-
quence of complexity because complex systems represent multiple nested lev-
els of organization.59
Primary sensory cortical areas are relatively far from each other in the cerebral
cortex and have no direct connections between them, but they are linked indi-
rectly by the higher order cortical areas sandwiched between them. Connection
probability has long been used in attempts to deﬁne functionally meaningful
anatomical areas and systems, such as primary sensory areas, motor areas, higher
order associational areas, sensory and motor systems, the memory system, and
Figure 2.6. Hierarchical and looplike organization of brain systems. Left: Multiple pro-
cessing stages and numerous multiple-loop connections of the visual system from the eye
to higher order associational cortices. Reprinted, with permission, from Felleman and Van
Essen, (1991). Right: Spatial segregation of systems (e.g., visual, auditory, somatosensa-
tion, associational) on the basis of connectivity. Note high clusters of connections within
respective systems. Reprinted, with permission, from Young (1992).

Structure Deﬁnes Function
53
60. Axonal connections have long been used by neurologists to identify the localization of neuro-
logical symptoms, especially before the imaging era. Mesulam (1998) is a thorough review of the re-
lationship between traditionally deﬁned systems and alleged functions in primates.
61. Anatomical systems are deﬁned by the strength of their interconnections rather than by spatial
proximity. The monumental works of Felleman and Van Essen (1991) and Young (1992; Scannel et al.,
1995) were among the ﬁrst large-scale comparisons of systems connectivity. For the optimum place-
ment of frontal cortical areas, see Klyachko and Stevens (2003). Axon length economy may explain
the separation of dorsal (“where”) and ventral (“what”) visual pathways (Sporns et al., 2000a and b;
Ungerleider and Mishkin, 1982). Young and Scannell (1996) criticize the “if connected then adjacent”
wire economy rule (e.g., the retina and lateral geniculate are far from each other) and suggest that if
any component placement rule exists, then it is this: if adjacent, then connected. However, neighbor-
hood relations do not guarantee connectedness either (e.g., Alheid and Heimer, 1988; Léránth et al.,
1992).
62. The claim that the brain is most sensitive to those environmental perturbations that match the
statistics of its organization is related to Edelman’s (1987) “neural Darwinism,” which posits that evo-
lution of cortical connectivity reﬂects an adaptation to the statistical structure of sensory inputs
(Sporns et al., 2000a and b). Edelman and colleagues suggest that wiring economy is a “byproduct” of
functional adaptation. Adaptation serves to maximize complexity by connecting neuronal groups ac-
cording to the probability statistics of sensory inputs. Although identical anatomical connectivity of
neurons can be achieved by various groupings, it appears that evolving wired systems always choose
optimum component placements (Cherniak, 1995).
others.60 By examining many alternative arrangements of 11 distinct cortical ar-
eas in the macaque frontal lobe, Charles Stevens at the Salk Institute in La Jolla,
California, has found that the arrangement that is actually present in the brain
minimizes the volume of the axons required for interconnecting the areas. These
examples illustrate that the cerebral cortex is a highly ordered network at the
macroscopic scale.61 Topographic arrangement is an economic way to optimize
component placement to reduce excessive wiring and minimize axon conduction
delays. Efﬁcient computation depends on fast temporal solutions, and it is possi-
ble that such temporal advantages “drive” optimal brain wiring.
Complexity of Wiring in the Neocortex
The combination of the robust local tensegrity design and functionally relevant
long-range corticocortical pathways provides an economic solution for establish-
ing functionally effective paths across the vast domains of the neocortex. The
small-world-like organization of the neocortex, as opposed to strictly local, ran-
dom, or all-to-all connectivity, provides a higher order of wiring complexity.62
Moreover, areas of the neocortex in higher mammals are more strongly connected
than needed to form a graph structure. Areas preferentially connected are referred
to as cortical systems. If we regard the brain as a complex system, we rightfully
expect that its intricate connectivity has a lot to do with its complex operations.
But what is complexity?
Complexity is not just complicated stuff but a unique quality that emerges
from the relationship or interaction among elements. Think about a good wine.

54
RHYTHMS OF THE BRAIN
63. My recommended source on complexity is Herbert Simon’s landmark book on the empirical
study of organizations (Simon, 1969; see also Kauffman, 1995). Kelso (1995) is perhaps the most
user-friendly for psychologists and cognitive scientists. For a brief perspective on the subject, see
Koch and Laurent (1999).
64. According to Bak (1996), complexity occurs only at one very special point: not where there is
chaos or where there is trivial predictability but where there is a transition between these states with a
1/x distribution.
65. Brodmann’s systematic studies on the human cerebral cortex appeared between 1903 and 1908
as a series of communications in the Journal für Psychologie und Neurologie (which lives on as the
Journal für Hirnforschung; see Brodmann 1909/1994). Before Brodmann, confusion had reigned re-
garding the laminar structure of the cortex and the taxonomy of cortical areas. Small-brained animals
have fewer areas deﬁned by Nissl staining (e.g., the hedgehog has only 15), supporting the idea
When you describe its bouquet, you refer to a blend of scents, richness, ﬁnesse,
harmony, balance, and other fancy words that characterize a really good cabernet
sauvignon. Analogously, the territory of complexity is somewhere halfway between
chaos and order, stochastic and deterministic, random and predictable, labile and
stable, homogeneous and nonhomogeneous, segregated and integrated, autonomous
and dependent, unconstraint and ﬁxed, chance and necessity, aggregation and dif-
ferentiation, competition and cooperation, ﬁgure and background, context and con-
tent, anarchy and constraint, light and dark, matter and energy, good and evil,
similar and different (ﬁgure 2.7).63 Complex connectivity can be deﬁned quantita-
tively using the same halfway logic: neither random nor regular, neither local nor
fully connected, that is, a scale-free system that obeys a power law.64 Complexity
arises from the interaction of many parts, giving rise to difﬁculties in linear or re-
ductionist analysis due to the nonlinearities generated by the interactions. Such
nonlinear effects emerge from both positive (amplifying) and negative (damping)
feedbacks, the key ingredients of complex systems. Typically, the relationships be-
tween elements in a complex system are short range, but because of the feedback
loops, the imported information that passes through a local system is modiﬁed be-
fore being exported to other local or distant systems. So when it comes to organiza-
tion rules, one has to address the issue of whether the rules are the same or different
at the various levels, in our case, the whole cerebral cortex, cortical systems, and
their subdivisions, because not all levels are engaged for particular tasks.
How far information travels is typically hard to deﬁne because the boundaries
within and across complex systems are vague. Boundary decisions are usually
based on the experimenter’s methods and prejudices rather than on objectively
deﬁned properties. A case in point is the often-disputed borders between neocor-
tical areas. Korbinian Brodmann often lamented about Santiago Ramón y Cajal’s
“erroneous” views on cortical lamination. Using sections stained with the method
of Franz Nissl, Brodmann distinguished 47 areas in the human brain and compared
them with those in a number of other mammals, including primates, rodents, and
marsupials. Although his classiﬁcation scheme remains the gold standard, several
Brodmann areas have been further subdivided in recent years, due to the develop-
ment of more sophisticated morphological criteria.65 Among these new criteria,

Structure Deﬁnes Function
55
Figure 2.7. Complexity occupies the boundary between disorder (maximum entropy) and
order. It is neither fully predictable nor fully random. Complex systems are governed by
simple power laws. The dynamic range of the brain varies between complex and pre-
dictable.
that encephalization is associated with increased cellular differentiation. Contemporary imaging
methods use Jean Talairach’s atlas (Talairach and Tournoux P, 1988). Each page in the atlas describes
a slice of the human brain within a two-dimensional grid and refers to Brodmann numbers. The prob-
lem with anatomical classiﬁcations is not whether there are architecturally distinct areas but whether
and how they reﬂect differential functions.
66. Tononi et al. (1994, 1996) estimated complexity, using the theory of stochastic processes and
information theory. Entropy is a measure of the amount of disorder in a system. In information theory,
it refers to the amount of randomness in a signal. The mutual information between two variables I(x|y)
is deﬁned as the difference of entropy on x generated by the knowledge of y. The numerical value of
connectedness appears to be the most decisive. There is no doubt that there are
some variations in the ﬁne cortical organization among the areas, but what ap-
pears to be the primary determinant of function in the cortex is how each area is
related to other areas. Connectivity is of the essence.
Giulio Tononi, Olaf Sporns, and Gerald Edelman from the Neurosciences In-
stitute in La Jolla, California, searched for a structure-based metric that could
more objectively deﬁne “neuronal complexity” and capture the relationship be-
tween functional segregation and global integration of function in the brain. Us-
ing the concepts of statistical entropy and mutual information, they estimated the
relative statistical independence of model systems with various connectivity
structures. Not surprisingly, they found that statistical independence is low when
system constituents are either completely independent (segregated) or completely
dependent (integrated).66 However, using their formal deﬁnition of complexity,
they showed that statistical independence increased when segregated assemblies

56
RHYTHMS OF THE BRAIN
the amount of information we cannot account for is entropy. With this “information deﬁnition” of
complexity, the human mind enters the picture since information is not a physical thing. Similar ideas
on complexity measures have been advocated by Stuart Kauffman, who suggested that the best strat-
egy to identify complexity is to search at the phase transition between order and disorder, that is, at the
edge of chaos (Kauffman, 1995). To some extent, Kauffman’s system is based on Ilya Prigogine’s
nonequilibrium thermodynamics, which suggests that complex systems near equilibrium minimize
their rate of entropy production (independence). The original seed of all these ideas is likely from
Charles Darwin: order emerges from disorder without an outside agent, although many argue that the
term “natural selection” assumes an external selective “force.”
67. Granovetter (1973, 1995). The entropy-based deﬁnition of complexity is essentially the same
as the power-law–dependent scale-free distribution of connections.
coexisted with some integration between them. Complexity reached a maximum
when a large numbers of assemblies of varied sizes were combined. This feature,
as described above, is the hallmark of scale-free systems, governed by power
laws. In future Cycles, I refer to the small-world-like organization of the neo-
cortex to indicate the lack of characteristic scales of medium- and long-range
connectivity but with the implicit understanding that connections are much
stronger among many cortical areas than would be needed by the simplest scale-
free graph.
In a series of follow-up experiments mimicking Darwinian natural selection,
Tononi and colleagues analyzed large numbers of graphs and found that what
mattered most was not the mere number of connections present but the underly-
ing connection patterns. Graph architectures ideally suited for maximum en-
tropy (independence), integration (statistical dependence), and complexity were
fundamentally different. Dynamics with high complexity were supported by ar-
chitectures whose units (“neurons”) were organized into densely linked local
groups that were sparsely and reciprocally interconnected. These computa-
tional studies echo the economist Mark Granovetter’s dictum about the strengths
of weak ties.67
Unfortunately, one-dimensional abstract networks, used in these simulation
studies, consist of identical nodes (neurons) and links (synapses) and lack tem-
poral features such as conduction delays. In other words, they lack real-world
dynamics that add further kinks to the complexity issue. Nevertheless, quanti-
tative approaches such as those pioneered by Tononi, Sporns, and colleages, al-
low us to hypothesize about the information transfer in brains of various
connection complexities. For example, if local groups are more strongly con-
nected by long-range axons than expected from scale-free organization, this
knowledge suggests more efﬁcient global integration. Similarly, connectivity
among neuronal groups and group aggregates can be used to deﬁne the bound-
aries at multiple spatial scales and to indicate potential functional operations at
various spatial levels. In addition to connectivity, another approach for enhanc-
ing the complexity of a system is by introducing novel types of components. In
the cortex, such component diversity is achieved by using different neuron
types.

Structure Deﬁnes Function
57
68. Such a simple unit consists of a pyramidal cell and a feedback inhibitory interneuron or some
variation of such connectivity (Douglas and Martin, 1991, 2004).
69. Synﬁre chains of Abeles (1982) serve as a model of of cortical connectivity. The chains con-
sist of group of neurons linked together in a feedforward manner so that a wave of activity can propa-
gate from one end to the other, unidirectionally. More sophisticated synﬁre chains also include
inhibitory interneurons and these balanced models are used to study spike synchrony propagation, for
example from stimulus perception to initiating a behavioral output.
70. Hierarchy need not imply top-down relations of authority or an agent. The basic structure of mat-
ter is hierarchical, an inevitable consequence of self-organization. Before Simon (1969), hierarchy was
regarded as a static structure. Simon’s dynamic system was strongly inﬂuenced by “general systems the-
ory,” the topic introduced by the Hungarian writer and philosopher Arthur Koestler (1967) and devel-
oped further by Stanley (1985). According to these views, an organism is a self-regulated hierarchy. Due
to competition, activity patterns become progressively more complex, ﬂexible, and creative as we move
up the hierarchy. These thoughts are the roots of the single-cell doctrine in neuroscience (Barlow, 1972).
71. Because of their pattern completion ability, recurrent networks are also known as “autoassoci-
ators” (Kanerva, 1988).
Excitatory Cortical Networks: 
An Oversimpliﬁed Perspective
A fundamental problem in studying the brain derives from the fact that it is orga-
nized at multiple spatial and temporal scales. Examining a single neuron, small
circuit, or region in isolation is complicated by the difﬁculty that each of these
levels is a complex function of its lower level constituents and, at the same time,
is embedded in a large-scale organization. No wonder that it is still debated
whether functional organization emerges from a pluripotent network with identi-
cal constituents in which connectivity rules or from a system of components each
having a well-deﬁned function. According to the simplest reductionist approach,
one must understand the basic and common properties of all neurons, construct
and examine the properties of a “canonical” cortical circuit,68 and proceed from
there by analyzing how inputs from the external sensors, such as the eyes and
ears, affects function in such basic circuits. A popular framework, introduced by
Moshe Abeles of the Hebrew University in Jerusalem, is a feedforward network
or “synﬁre chain”69 matrix of pyramidal cells across many hypothetical layers of
identical neurons, where model layers may represent different anatomical layers
of a single cortical column or brain areas of the neocortex. Although there are
some speciﬁc examples of such unidirectional, feedforward connections in the
brain, they are neither robust nor efﬁcient for most functions performed by real
cortical networks. First, errors propagate and accumulate without corrections in
the multiple layers. Second, messages become too long while propagating across
the different layers due to synaptic and conduction delays. Because true feedfor-
ward networks are hierarchical decision makers, top-down inﬂuences or global
decisions that would emerge from the collective contribution of many con-
stituents are left unexploited.70 These shortcomings can be improved by recurrent
or feedback excitatory connections within and between layers. Such recurrent
networks can restore the original pattern from its fragmented versions.71

58
RHYTHMS OF THE BRAIN
72. Although they have a different name, the spiny stellate cells are essentially pyramidal cells
without an apical dendritic shaft. Numerous dendrites originate from the cell bodies in all directions.
This star-shaped appearance is the source of the distinguishing term “stellate.” Their axons are dense
locally and rarely leave the vicinity of the cortical module.
73. An excellent review in favor of the similarities of cortical modules is Zeki (1978).
74. The distinctly high density of layer 4 stellate cells in area 17 of the visual cortex of the primate
and the large Betz cells of motor area 4 are examples of dramatic architectonical differences. Analyz-
ing 834 connections between 72 cortical structures in the macaque cortex, Young and colleagues
(Young, 1992; Young and Scannel, 1996; 2000) have shown “hubs” with high connection densities,
corresponding roughly to visual, auditory, somatosensory, and frontolimbic areas, with ordered
Although the cerebral cortex is made up primarily of pyramidal neurons, their
intrinsic properties may show large enough variations to make a difference in
their integration and transfer properties. Pyramidal cells in layers 2, 3, 5, and 6
and the spiny stellate (star-shaped) cells of layer 4 differ not only in terms of their
connections but also by in their biophysical properties.72 Axons of stellate cells
remain local, whereas those of most pyramidal neurons project to distances larger
than the size of the postulated neocortical modules. Axon collaterals of large mo-
tor cortex neurons reach the most distant end of the spinal cord. The ﬁve
principal-cell categories in layers 2–6 release the same excitatory neurotransmit-
ter, glutamate, in their axon terminals, so at one level they are quite similar. On
the other hand, they are of different sizes and possess sufﬁciently different bio-
physical properties to postulate that they can give rise to at least ﬁve degrees of
freedom in neocortical computation, in addition to connectivity.
The next organizational level above the neuron is the hypothetical cortical
module. Most investigators emphasize how little the neocortex varies in its funda-
mental architectonic appearance from one cortical region to another, while ac-
knowledging that cell size and density can vary systematically. This basic
similarity implies that local computations at any cortical location are fundamen-
tally the same.73 Accordingly, the area differences in function in each area must
emerge from the unique patterns of input and output connections. The precise
connectivity among the various cell types is not fully known, although some gen-
eral connection plan exists. Based on the assumption that the basic ﬂow of infor-
mation in the neocortex is from the direction of the external world to higher areas,
ascending (feedforward) and descending (feedback) connections are distin-
guished. By and large, connections from one area to another are classiﬁed as as-
cending if they terminate mainly in layer 4, and descending if the terminals are
distributed in layers other than layer 4. The density of intermediate- and long-
range connections varies extensively among cortical areas, indicating that some
interactions are more important than others by virtue of their degree of connect-
edness. Quite often, these connection patterns correlate nicely with other anatom-
ical markers of regional cortical organization, but the many discrepancies remain
the source of constant debate regarding the precise delineation of boundaries be-
tween cortical areas.74
The reductionistic conclusion that one would like to draw from the above dis-
cussion is that the same physiological function, such as vision and somatosensation,

Structure Deﬁnes Function
59
degrees of connectivity between areas deﬁned by Brodmann. On the other hand, recent proposals on
the internal connectivity of the visual system bear little resemblance to the classical Brodmann maps
(Felleman and Van Essen, 1991). An extensive summary of the corticocortical connections in the rhe-
sus monkey is presented in Schahmann and Padya (2006). For a short but illuminating discussion
about local architecture and global connectivity, see Kaas (2000).
75. Nimchinsky et al. (1999). Similarly large neurons (Betz cells) in the primary motor cortex of
hominids have been known for some time. The potential signiﬁcance of these giant “spindle-shaped”
neurons is discussed in Allman (1999).
in mammalian brains of different sizes is supported by similar circuits, composed
of the same neuron types. Unique functions arise not (only) from the unique local
organization but from the unique embeddedness and connections of the local net-
works to other networks. Rapid growth of neocortical neuron numbers is possible
because disproportionately fewer long-range connections are needed in large
brains to assure the same degree of effective connectivity as in small brains. The
hope, then, is that the quantitatively different architectures in different brain areas
and species have some mathematically predictable relationship, a profoundly im-
portant message because it is an important justiﬁcation of research on the brains of
small animals in a quest to understand our own. If we come to understand the mys-
teries of basic cortical anatomical organization and the interactions of cortical ar-
eas in rodents, then the generated knowledge should be applicable to the human
cortex, as well. Some small surprises may emerge, however. Esther Nimchinsky
and Patrik Hof at Mount Sinai University in New York and John Allman at the Cal-
ifornia Institute of Technology have recently described a unique population of un-
usually large, spindle-shaped neurons in layer 5 of the insular and anterior
cingulate cortex of humans and great apes but not in other mammals.75 However, it
remains to be seen whether they are qualitatively different from other layer 5 neu-
rons, possessing some uniquely extensive connections or biophysical properties.
So far, I have discussed only the connectivity of the principal, excitatory cell
types of the neocortex. No matter how well connected these neurons are, in them-
selves they are not capable of carrying out anything useful. A major problem that we
face is that excitation spreads in all directions without any mechanisms to curb the
spread of activity. Without a proper control system, principal-cell types connected
by random, small-world, or any kind of network design would simply behave like
autonomous avalanches, building up very large excitation over an ever-expanding
territory and then shutting off from exhaustion. In order to generate the harmony of
tensegrity in cortical circuits, excitation must be balanced with an equally effective
inhibition. In the cortex, the solution is a stabilizing negative feedback control, pro-
vided by the inhibitory interneuron system, which I discuss in Cycle 3.
Brieﬂy . . .
The neocortex is built from a multitude of ﬁve principal-cell types and numerous
classes of interneurons. Early formulation of cortical structure emphasized the

60
RHYTHMS OF THE BRAIN
modularity of the neocortex, for example, juxtaposed cortical columns in large
numbers. Its robust local tensegrity organization has allowed continuous growth
from the small brain of a tree shrew to the giant brain of the whale. Medium-
and long-range connections that compose the white matter and interconnect non-
adjacent cortical neuronal circuits are relatively sparse but sufﬁcient to provide
the indispensable conduit for keeping the synaptic path lengths constant in
brains of different sizes. Such interconnectedness of cortical areas is a prerequi-
site for global operations in ﬁnite temporal windows. The precise connectivity
among the various principal-cell types is not fully known, although some general
connection plan exists. There is a consensus among neuroscientists that the
principal-cell types and their basic connectivity have been well preserved from
the smallest to the largest brains. The small-world-like, scale-free organization
of cortical architecture may provide some quantitative rules for the growths of
both cell numbers and associated axonal connections while minimizing the cost
of connectivity. However, the available anatomical data indicate that cortical ar-
eas processing similar kinds of information are more strongly connected than re-
quired by a simple random graph. These preferentially connected areas form the
motor, visual, auditory, somatosensory, gustatory, olfactory, and higher order
cortical systems. However, with excitatory connections only, no computation is
possible because any input would simply recruit all neurons of the cortex into
unstructured population bursts. Limiting excitatory spread and segregation of
computation are solved by balanced interactions between the excitatory principal
cells and inhibitory interneurons.

Cycle 33
Diversity of Cortical Functions Is Provided
by Inhibition
According to classical statistical thermodynamics, there is only one kind of inter-
action between the elements: excitation (collision). This can lead to changes in
only one direction. Brains are different. Brains use not only excitation and but
also inhibition in their normal operations. This additional component is responsi-
ble for the fundamental difference between disorder-destined physical systems
and the order-centered brain dynamics.
As described at the conclusion of Cycle 2, the excitatory networks of the cere-
bral cortex are inherently unstable. Tensegrity dynamics can be maintained only
if the excitatory effects are balanced by equally effective inhibitory forces, pro-
vided by specialized inhibitory neurons. If only excitatory cells were present in
the brain, neurons could not create form or order or secure some autonomy for
themselves. Principal cells can do only one thing: excite each other. In the ab-
sence of inhibition, any external input, weak or strong, would generate more or
less the same one-way pattern, an avalanche of excitation involving the whole
population.1
Nothing in biology makes sense except in the light of evolution.
—Theodosius Dobzhansky
61
1. Abstract neural network models are different from their real-world counterparts. E.g., Hopﬁeld
nets are built from a large number of simple equivalent components (“neurons”) and the computa-
tional properties emerge as collective properties. However, there is no real excitation in the Hopﬁeld
net, just 0 and 1 logical states (Hopﬁeld, 1982). In later models, components have graded responses
but no inhibition (Hopﬁeld and Tank, 1986).

62
RHYTHMS OF THE BRAIN
However, the brain is a system with diversiﬁed components, where different
types of neurons are related in a particular way to achieve unity of a particular
kind. In this Cycle, I ﬁrst provide a brief overview of the types of cortical in-
terneurons and their connections with each other and with the principal excitatory
cells and discuss how the excitatory and inhibitory forces balance each other
through oscillations.
Inhibitory Networks Generate Nonlinear Effects
Propagation of activity in excitatory networks is simple and predictable. Excita-
tion just generates further excitation, independent of time, wiring complexity,
strength of excitation, or, in fact, any other factor. Positive forces can move the
system only in a forward direction. An excitatory network always converges to-
ward the same irreversible end despite the different magnitudes or forms of start-
ing conditions. Inhibitory networks are fundamentally different. To illustrate this
difference, compare chains of excitatory and inhibitory neurons (ﬁgure 3.1). Inde-
pendent of the details, the evolution of activity in the purely excitatory network is
monotonic excitation. Excitatory neurons connected in series excite each other at
every step, resulting in a chain reaction of ever-increasing activity without global
stability. In contrast, when an inhibitory interneuron at the beginning of the chain
is activated, it will suppress the activity of its target neuron. As a result, the third
interneuron in the chain will be less suppressed by the second interneuron, so the
activity of the third neuron may increase. Neurophysiologists refer to this process
Figure 3.1. Inhibition introduces “hard-to-predict” nonlinearity in cortical circuits. Exci-
tatory chains (black) produce only monotonically increasing excitation. In contrast, in in-
hibitory (gray) and mixed circuits, the spread of activity can be strongly modiﬁed, and the
ultimate outcome depends on the ﬁne details of connections and synaptic strengths (arrow,
excitatory; circle, inhibitory). Vertical arrows indicate the magnitude of activity.

Diversity of Cortical Functions: Inhibition
63
2. Systems with multiple nested structures are called hierarchies. The cortex with its rich variety
of neuron types and multiple organization levels is a complex hierarchical system.
3. Shortly after the discovery of feedforward inhibition in the cortex (Buzsáki and Eidelberg,
1981, 1982; Alger and Nicoll, 1982), the fundamental neurophysiological differences between feed-
back and feedforward inhibition were emphasized (Buzsáki, 1984; see also Swadlow, 2002).
4. Pouille and Scanziani (2001).
as disinhibition. The disinhibited third neuron, in turn, will suppress its own
downstream target, and so on. Now consider a ring of excitatory neurons with one
or more inhibitory interneurons embedded in the circuit. Input activation brings
about both spreading excitation and inhibition. The ﬁring patterns of the individ-
ual neurons in the ring are hard to predict because their activity strongly depends
on the exact details of the connections. A minor change in some of the parameters
can result in dramatic changes in the ﬁring properties of all partners involved.
This property is known as nonlinearity.
Networks built from both excitatory and inhibitory elements can self-organize
and generate complex properties.2 However, even in the simplest partnership of a
principal cell and interneuron, the pattern of ﬁring depends on the details of
wiring (ﬁgure 3.2).3 In a recurrent inhibitory circuit, increased ﬁring of the prin-
cipal cell elevates the interneuron’s discharge frequency, and the interneuron, in
turn, may decrease the principal cell’s output, similar to the action of a thermo-
stat. Stabilization by negative feedback typically comes in the form of various os-
cillations (discussed in Cycle 6). In a feedforward inhibitory conﬁguration,
increased discharge of the interneuron, as the primary event, results in decreased
activity of the principal cell. Such simple pairing of excitation and inhibition can
increase the temporal precision of ﬁring substantially. This is because depolariza-
tion of the principal cell, initiated by the excitatory input, is reduced quickly by
the repolarizing effect of feedforward inhibition, narrowing the temporal window
of discharge probability. Fast coupling of the excitatory and inhibitory inﬂuences
can bring about submillisecond precision of spike timing.4
Any departure from the simple feedback or feedforward partnership inevitably
Figure 3.2. Negative (inhibitory) feedback provides stability. Feedforward inhibition
dampens (“ﬁlters”) the effect of afferent excitation. Lateral inhibition provides autonomy
(segregation) of neurons by suppressing the similarly activated neighboring neurons
(“winner take all”).

64
RHYTHMS OF THE BRAIN
5. Another important source of nonlinearity is derived from the numerous subcortical modulatory
neurotransmitters (Steriade and Buzsáki, 1990; McCormick et al., 1993). Part of the subcortical effect
is mediated by cortical interneurons (Freund, 2003).
6. An oft-used term for such maintained phase transition is “self-organized criticality” in physics.
Per Bak’s fascinating book on self-organized criticality (Bak, 1996) links self-organization to cascad-
ing failures. For criticism of his treatment of the topic, see Jensen (1998).
increases the complexity of the ﬁring patterns of the participating cells. For ex-
ample, when two interneurons are activated simultaneously, their combined effect
on the target principal cell depends primarily on the interaction between the in-
terneurons. Inhibition, as a “negative force,” introduces nonlinear, hard to predict
effects. An extension of feedback inhibition is lateral inhibition. This occurs when
activation of a principal cell recruits an interneuron, which in turn suppresses the
activity of the surrounding principal cells. Suppose that two principal cells are ex-
cited by the same input, but the input to principal cell A is slightly stronger than
the input to principal cell B. If neuron A and B share a common inhibitory in-
terneuron, the gain in neuron A results in a suppression of neuron B’s activity.
The same outcome occurs if the input strengths to neurons A and B are equal but
the synapse between neuron A and the interneuron is slightly stronger than that
between neuron B and the interneuron. The initial minor difference in the inputs
results in a very large difference in the output of the two neurons. The same asym-
metry can be produced if input to neuron A arrives slightly earlier than the input
to neuron B. This increased autonomy by competition is also known as “winner-
take-all” mechanism, a nonlinear selection or segregation mechanism.
Speaking more generally, cortical networks gain their nonlinearity and func-
tional complexity primarily from the inhibitory interneuron system.5 Such com-
plex interactions between the excitatory and inhibitory neuron pools have at least
two useful consequences. First, principal cells will neither be trapped in repeated
excitatory avalanches nor become completely suppressed, unable of responding
to inputs. Instead, in real networks the set point is somewhere in the middle, so
principal cells embedded in cortical networks are able to react robustly, when
needed, even to the weakest physiological input. In physics, such critical state is
referred to as phase transition, because external forces can shift the system in ei-
ther direction. A textbook example of a state transition is the shift between water
and ice. A slight change in temperature (an externally imposed inﬂuence) can
shift the state in either direction. If a system, for example, a neural network, can
self-organize in such a way as to maintain itself near the phase transition, it can
stay in this “sensitized” or metastable state until perturbed.6 Despite being maxi-
mally sensitized to external perturbations, neuronal networks with multiple levels
of excitatory and inhibitory constituents are resilient systems, capable of absorb-
ing large external effects without undergoing functional breakdown.
Another fundamental service of the inhibitory system is that it provides a
high degree of autonomy for individual principal cells or cell groups. Coopera-
tion of interneurons in the same “class” (see discussion on diverse classes be-
low) can secure the spatiotemporal segregation of principal cells to perform a

Diversity of Cortical Functions: Inhibition
65
given function. As discussed repeatedly in subsequent Cycles, the most basic
functions accomplished by neuronal networks are pattern completion and pat-
tern separation, functions related to the concepts of integration and differentia-
tion. Separation of inputs in a network with only excitatory connections is not
possible. However, with inhibitory connections, the competing cell assemblies
and even neighboring excitatory neurons can be functionally isolated, and exci-
tatory paths can be rerouted by the trafﬁc-controlling ability of coordinated in-
terneuron groups. The speciﬁc ﬁring patterns of principal cells in a network
thus depend on the temporal and spatial distribution of inhibition. As a result, in
response to the same input, the same network can produce different output pat-
terns at different times, depending on the state of inhibition (ﬁgure 3.3). The co-
ordinated inhibition ensures that excitatory activity recruits the right numbers
of neurons in the right temporal window and that excitation spreads in the right
direction. None of these important features can be achieved by principal cells
alone.
Interneurons Multiply the Computational Ability 
of Principal Cells
The term “cortical interneuron” dates back to times when inhibitory neurons were
thought to provide only somatic feedback inhibition onto local pyramidal cells.
Because their short-range connections were alleged to be the rule, an alternative
term “local circuit interneuron” was also in use for a while. Some interneurons,
however, do project as far as principal cells. Nevertheless, the term “cortical in-
terneuron” has been preserved with extended roles, much like the now divisible
atom in physics (Greek a-tom, cannot be cut further). Because all known cortical
Figure 3.3. Inhibition is essential for cell assembly selection. Slight differences in
synaptic strengths between the afferent input and neurons in assembly 1 and 2 can com-
pletely silence the competing assembly. In case of equal input strengths, the earlier input
selects the assembly and silences the competing assembly by feedforward and lateral
inhibition.

66
RHYTHMS OF THE BRAIN
7. See Csicsvari et al. (1998). Gulyás et al. (1993b) provides electron microscopic evidence that
excitatory postsynaptic potentials (EPSPs) in interneurons can be reliably evoked by single presynap-
tic spikes through just a single release site; see Barthó et al. (2004) and Silberberg et al. (2004) for re-
lated observations in the neocortex.
8. In addition to spike-related release of GABA, the inhibitory neurotransmitter is also released
“spontaneously” in the absence of presynaptic action potential. The exact functional role of these tiny
inhibitory currents (dubbed as “minis”) is not well understood, but they may contribute to the stability
of cortical networks (Nusser and Mody, 2002; Mody and Pearce, 2004).
interneurons, which make up less than one-ﬁfth of the cortical neuronal popula-
tion, release the inhibitory neurotransmitter gamma-aminobutyric acid (GABA),
the term “inhibitory interneuron” unambiguously deﬁnes the inhibitory cell pop-
ulation in the cerebral cortex.
How can such a minority group keep in check the excitatory effects brought
about by the majority principal cells in cortical networks? Interneurons deploy
numerous mechanisms to meet this challenge. In contrast to the typically weak
synaptic connections between principal cells, principal cell–interneuron connec-
tions are strong. In the return direction, a typical interneuron innervates a princi-
pal cell with 5–15 synaptic terminals (or boutons). Furthermore, almost half of
the inhibitory terminals are placed at strategically critical positions for controlling
action potential output. On the axon initial segment and cell body of principal
cells, there are only inhibitory synapses supplied by several chandelier and basket
interneurons. The threshold for action potential generation is much lower in in-
terneurons, and often a single action potential of a presynaptic principal cell is
sufﬁcient to discharge an interneuron, as Jozsef Csicsvari, a graduate student in
my laboratory, has shown.7 As a result, basket and chandelier interneurons work
harder, and their overall ﬁring rate is several times higher than that of the princi-
pal cells, such that the total number of inhibitory postsynaptic potentials (IPSPs)
per unit time, impinging upon a typical principal cell, approximately matches the
effects of the excitatory postsynaptic potentials (EPSPs).8
However, both the kinetics and the spatial distribution of IPSPs and EPSPs are
remarkably different. The rise time and decay time of IPSPs are much faster, and
their amplitude is larger than those of EPSPs. This faster kinetics is the main rea-
son why interneurons are so much more efﬁcient in timing the action potentials of
pyramidal neurons than are excitatory inputs from other pyramidal cells. Excita-
tory potentials dominate the dendrites of principal cells, whereas only IPSPs im-
pinge upon the cell body (soma) (ﬁgure 3.4). The result of this arrangement is
reﬂected by the larger power of high-frequency currents in the extracellular space
in the somatic layers (where the cell bodies concentrate), relative to the dendritic
layers (to where most excitatory inputs arrive).
It is through the opposing forces of excitation by principal cells and inhibition
by interneurons that the tensegrity harmony of cortical activity is established.
This balanced partnership ensures an overall homeostatic regulation of global ﬁr-
ing rates of neurons over extended territories of the cortex and at the same time
allows for dramatic increases of local excitability in short time windows, necessary
for sending messages and modifying network connections. Balance and feedback

Diversity of Cortical Functions: Inhibition
67
Figure 3.4. The perisomatic (output) region of pyramidal cells is fully controlled by
GABAergic inhibition. The proportion of GABAergic synapses decreases, whereas the
number of spines (associated mainly with excitatory synapses) increases as a function of
distance from the soma. Modiﬁed, with permission, from Papp et al. (2001).
9. Mainen and Sejnowski (1996). Morphological features, and likely the associated differences of
channel distributions, may be responsible for the differences between neuronal subtypes within the
same layers, e.g., layer 5 bursting and nonbursting pyramidal neurons (Connors and Regehr, 1996).
control are also essential principles for oscillations, and interneuron networks are
the backbone of many brain oscillators.
In Cycle 2, I mentioned that the ﬁve main principal-cell types have distinct
functional properties. This distinctness results from the unique combination of
ion channels in the membrane and from their morphological individuality.
Zachary Mainen and Terry Sejnowski at the Salk Institute have shown that the
biophysical behavior of their computer-model neurons could be changed dramat-
ically by altering their morphology.9 For example, a neuron with a large or small
dendritic arbor and neurons with similar geometry but different distribution of ion
channels will generate a different output in response to the same input. The exten-
sive computational capacity of a single principal cell is seldom utilized at once.
Dividing its full computational power into numerous subroutines that could be
ﬂexibly used according to momentary needs would be an enormous advantage.
This important service is provided with ease by the interneuron system. Interneu-
rons can functionally “eliminate” a dendritic segment or a whole dendrite, selec-
tively inactivate Ca2+ channels, and segregate dendrites from the soma or the
soma from the axon. In effect, such actions of interneurons are functionally
equivalent to replacing a principal cell with a morphologically different type,
thus functionally increasing component diversity of the principal-cell population

68
RHYTHMS OF THE BRAIN
Figure 3.5. Inhibition can alter the ﬁring patterns of neurons. Top: Burst ﬁring pattern of
a layer 5 model neuron. Bottom: Removal of the apical dendritic tree in the model neuron
converts the burst discharge into a regular ﬁring pattern. A similar effect in ﬁring pattern
can occur when the apical dendritic tree is isolated from the rest of the neuron by proximal
dendritic inhibition. Model ﬁring patterns are modiﬁed, with permission, from Mainen and
Sejnowski (1996).
10. Alvarez de Lorenzana and Ward (1987) distinguish between combinatorial expansion (linear)
and generative condensation (nonlinear) for describing general properties of evolving systems.
(ﬁgure 3.5). And the large family of interneuron species perform all these tricks in
a matter of milliseconds.
Diversity of Cortical Interneurons
Brain systems with “simple” computational demands evolved only a few neuron
types. For example, the thalamus, basal ganglia, and the cerebellum possess a low
degree of variability in their neuron types. In contrast, cortical structures have
evolved not only ﬁve principal-cell types but also numerous classes of GABAer-
gic inhibitory interneurons. Every surface domain of cortical principal cells is un-
der the speciﬁc control of a unique interneuron class. This is a clever way of
enormously multiplying the functional repertoire of principal cells using mostly
local interneuron wiring. Adding more interneurons of the same type linearly in-
creases the network’s combinatorial properties. However, adding novel interneu-
ron types to the old network, even in small numbers, offers a nonlinear expansion
of qualitatively different possibilities.10

Diversity of Cortical Functions: Inhibition
69
11. Interneuron classiﬁcation advanced ﬁrst in the hippocampus. See Halasy and Somogyi (1993),
Buhl et al. (1994), Gulyás et al. (1993a), Sík et al. (1994, 1995), and Freund and Buzsáki (1996). For
more recent progress, see the Interneuron Diversity series in Trends in Neuroscience (Mott and Din-
gledine, 2003; Freund, 2003; Maccaferri and Lacaille, 2003; Lawrence and McBain, 2003; Whitting-
ton and Traub, 2003; Jonas et al., 2004; Baraban and Tallent, 2004; Buzsáki et al., 2004; Monyer and
Markram, 2004; Cossart et al., 2005). The most comprehensive treatment of interneuron diversity is
the excellent book Diversity in the Neuronal Machine (Soltesz, 2006).
12. To date, the various classes, their connectivity, and functions are best characterized in the hip-
pocampus, a cortical structure with a single principal-cell layer, because the full extent of the dendritic
and axon arbors of in vivo labeled hippocampal interneurons has been quantiﬁed, and their physiolog-
ical features have been extensively characterized in both slice preparations and behaving animals (Fre-
und and Buzsáki, 1996; Klausberger et al., 2003, 2004). The wiring and functional principles derived
from hippocampal interneurons appear to be identical or very similar in the isocortex (Somogyi et al.,
1998; Markram et al., 2004; Somogyi and Klausberger, 2005).
13. This classiﬁcation is based on the concept that the “goal” of inhibition is to provide the
required spatiotemporal autonomy (segregation) for groups of pyramidal cells to execute a given
function.
14. This beautiful name was coined by János Szentágothai (1975; Szentágothai and Arbib, 1974).
He believed that the chandelier-like distribution of this neuron’s boutons corresponded to dendritic
synapses. It was Somogyi who, using his innovative combination of Golgi sections and electron mi-
croscopy, recognized that all boutons terminate on the axon initial segment of pyramidal cells (Somo-
gyi et al., 1983). He introduced a new term, axoaxonic cell, but the more poetic chandelier cell is still
widely used. A recent, unexpected ﬁnding is that chandelier cells may, in fact, depolarize the axon ini-
tial segment and thereby synchronize their target cells (Szabadics et al., 2006).
Our view on cortical interneurons has changed dramatically during the past
decade. What used to be thought of as a homogeneous collection of neurons pro-
viding negative feedback to the principal cells turned out to represent a large fam-
ily of intrinsically different cells with unexpectedly complex circuit wiring. To
date, there is not even a widely accepted taxonomy of interneurons, and novel
types are being discovered literally monthly. Splitters and lumpers like to divide
interneurons into, respectively, inﬁnite or small numbers of categories. Péter So-
mogyi at Oxford University, Tamás Freund at the Hungarian Academy of Sci-
ences, Budapest, and I suggested that the axonal targets of interneurons on the
principal cells should be the ﬁrst main division of interneuron classiﬁcation.11
The functional justiﬁcation of this classiﬁcation is that the main goal of the in-
terneuron system is to enhance and optimize the computational abilities of the
principal cells.12 In their relation to the principal cells, three major interneuron
families are recognized (ﬁgure 3.6).13 The ﬁrst and largest family of interneurons
controls the output of principal cells by providing perisomatic inhibition. Output
control is achieved at either the soma by basket cells or the axon initial segment
by chandelier cells.14 Interneurons of the second family target speciﬁc dendritic
domains of principal cells. Every known excitatory pathway in the cortex has a
matching family of interneurons. Several additional subclasses seek out two or
more overlapping or nonoverlapping dendritic regions, and yet other subclasses
innervate the somata and nearby dendrites with similar probability. Because the
different domains of principal cells have different functional dynamics, interneu-
rons innervating those speciﬁc domains adapted their kinetic properties to match

70
RHYTHMS OF THE BRAIN
Figure 3.6. The basic cortical circuit, including one type of pyramidal cell (P) and repre-
sentative interneuron classes. Perisomatic control of pyramidal cell is secured by basket
and axoaxonic (chandelier) neurons. Both pyramidal cells and interneurons are innervated
by extracircuit excitatory and inhibitory inputs as well as by subcortical neurotransmitters:
acetylcholine (ACh), dopamine (DA), norepinephrine (NA), and serotonin (5-HT, 5-
hydroxytryptamine). Modiﬁed, with permission, from Somogyi et al. (1998).
15. Before the landmark paper of Watts and Strogatz (1998) appeared, we reported on the “most pe-
culiar anatomical features,” as a reviewer of the manuscript put it, of a newly discovered interneuron
type in the hippocampus (Sík et al., 1994). The ﬂow of information in the hippocampus is mostly uni-
directional, or so-called feedforward. The axons of our new neuron, in contrast, went in all directions,
contacting neurons in all subregions of the hippocampus. We suggested that a few long-range neurons
are sufﬁcient to synchronize large territories of local networks. Long-range neurons have also been de-
scribed in layers 2 and 6 of the neocortex. Their extensive axon trees cross cortical regions and connect
similar regions of the two hemispheres (Peters et al., 1990; McDonald and Burkhalter, 1993). Similar to
hippocampal long-range interneurons, most of them contain somatostatin immunoreactivity, neuropep-
tide Y, and/or neuronal nitric oxide synthase (Tomioka et al., 2005). Axon collaterals of some of the
Martinotti cells (Martinotti, 1889) in the neocortex have been observed to enter the white matter.
their targets. Not surprisingly, members of the dendrite-targeting interneuron
family display the largest variability.
In addition to affecting the activity of principal cells, interneurons also in-
nervate each other by an elaborate scheme and affect each other’s biophysical
properties. An important subgroup with at least some overlap with the
dendrite-targeting family represents a special set of interneurons whose axon
trees span two or more anatomical regions, and some axon collaterals cross the
hemispheric midline and/or innervate subcortical structures, hence the term
“long-range” interneuron.15 Their distant clouds of terminal boutons are sepa-
rated by myelinated axon collaterals that provide fast conduction speed for
temporal synchrony of all terminals (ﬁgure 3.7). Such widely projecting, long-
range neurons are rare, but in light of the functional importance of small-world

Diversity of Cortical Functions: Inhibition
71
Figure 3.7. Axon collaterals of GABAergic interneurons can span different anatomical
regions. The interneuron shown here projects back from the hippocampal cornu ammonis
1 (CA1) region to the dentate gyrus (DG) and the CA3 regions. Similar long-range in-
terneurons project to subcortical sites, the contralateral hippocampus, or the entorhinal
cortex. Reprinted, with permission, from Sík et al. (1994).
16. Gulyás et al. (1996) and Freund and Gulyás (1997).
17. This taxonomy is based mostly on interneuron classes of the hippocampus, but it also holds in
the neocortex (Somogyi et al., 1998; Markram et al., 2004).
graphs, their role must be absolutely critical. They provide the necessary con-
duit for synchronizing distantly operating oscillators and allow for coherent
timing of a large number of neurons that are not connected directly with each
other.
The third distinct family of interneurons, discovered by Freund’s group, has
the distinguishing characteristics that their axons avoid principal cells and contact
exclusively other interneurons.16 The existence of these interneuron-speciﬁc in-
terneurons provides mounting support for a unique organization of the inhibitory
system. No principal cells are known that contact only other principal cells and
avoid inhibitory interneurons. The interneuron-speciﬁc family also overlaps with
the long-range subclass, again emphasizing the importance of interregional syn-
chronization of inhibition, and consequent coherent oscillatory entrainment of
their target principal-cell populations.17
The cell bodies and dendrites of interneuron families in the ﬁrst divisions of
our taxonomy can be found in different layers, and their differential inputs can

72
RHYTHMS OF THE BRAIN
18. For a recent review, see Somogyi and Klausberger (2005).
19. Gap junctions tend to occur within the same types of interneurons (Katsumaru et al., 1988;
Connors and Long, 2004; Hestrin and Galarreta, 2005).
20. Given the high diversity of interneuron types, it is unlikely that all types innervate each and
every pyramidal cell in the cortex (Markram et al., 2004). Thus, in addition to diversify the functions
of single cells, interneurons can diversify microcircuits, as well, by introducing inhomogeneities at
dynamically changing time scales.
21. Thomson (2000a,b), Gupta et al. (2000), and Pouille and Scanziani (2004).
compose the basis of the second division. With perhaps 20 or more distinguished
interneuron types in the rodent cortex, the complexity of their wiring must be
enormous, although the critical details are not yet known.18 Furthermore, in-
terneurons within the same family can communicate with each other via electrical
synapses. These are pores between adjacent membranes of two neurons, called
gap junctions, that allow bidirectional ﬂow of ions and small molecules.19 In ad-
dition to releasing GABA, interneurons also manufacture various calcium-
binding proteins, such as parvalbumin, calbindin, and calretinin, as well as a
variety of different peptides. Many of these peptides, such as cholecystokinin, so-
matostatin, and vasointestinal peptide, are hormones and polypeptides with
known endocrine and blood-ﬂow–regulating roles in the body. They thus not only
are convenient markers for anatomists but also could play hitherto poorly under-
stood roles in communicating the state of interneurons to the principal cells, glial
cells, and brain vessels.20
The advantage of varying the surface domain innervation of the principal cells
by the different interneuron classes becomes especially clear when temporal dy-
namics are also included. The biophysical properties of interneurons vary substan-
tially across the groups, and as a result, they can be recruited differentially at
different ﬁring frequencies of the principal cells. For example, basket cells respond
with decreasing efﬁcacy when stimulated by high-frequency inputs because of
their “depressing” input synapses, which function as a low-pass frequency ﬁlter. In
contrast, several types of dendrite-targeting interneurons fail to generate spike out-
put when driven at low frequency and require several pulses before they begin to
discharge because their input synapses are of the facilitatory type. These interneu-
rons therefore can be conceived as a high-pass frequency ﬁlter. The consequence
of such dynamics is easy to visualize.21 When a pyramidal neuron discharges at a
low rate, it activates almost exclusively its perisomatic interneurons. On the other
hand, at a higher discharge rate, the somatic inhibition decreases, and inhibition is
shifted to the dendritic domain (ﬁgure 3.8). Time is thus transformed into subcel-
lular space, due to the frequency-ﬁltering behavior of synapses.
The Interneuron System as a Distributed Clock
Despite its multifarious wiring, the principal-cell system alone cannot carry out
any useful computation. It is the inhibitory neuronal network, when coupled to

Diversity of Cortical Functions: Inhibition
73
Figure 3.8. Input frequency determines spatial dominance of inhibition. Left: At a slow
input frequency, feedforward dendritic inhibition is weak. Action potentials in the pyrami-
dal cell body back-propagate into the dendrite. Right: At fast input frequency, the dendrite-
targeting neuron (i1) is potentiated, whereas the drive of the soma-targeting interneuron
(i2) is depressed. The result is decreased inhibition of the soma and increased inhibition of
the dendrite. Back-propagation of the action potential to the pyramidal cell dendrite is at-
tenuated by the enhanced dendritic inhibition. Pouille and Scanziani (2004) have demon-
strated that fast input activation shifts inhibition from the soma to the dendrites. Dendritic
inhibition, in turn, suppressed somadendritic propagation of the action potential and den-
dritic Ca2+ inﬂux (Tsubokawa and Ross, 1996; Buzsáki et al., 1996).
the principal cells, that provides the ﬂexibility needed for the complex operations
of the brain. An important goal of single neurons and neuronal networks is to re-
spond efﬁciently but selectively to incoming inputs. In a single cell, the former
goal can be achieved by keeping the so-called “resting membrane potential” of
principal cells just below spike threshold. This task is difﬁcult to achieve due to
the nature of thresholds. The threshold concept is identical to that of the phase
transition between ice and water. In both cases, a minimal external force is needed
to bring about a state change. A difﬁcult problem, implicit in the concept of
threshold, is the neuron’s sensitivity to noise. If the membrane potential was just
below threshold all the time, any minor increase in excitation would discharge the
cell. Furthermore, this would be energetically a very expensive mechanism be-
cause complicated machinery would be required to “clamp” the membrane to a
narrow voltage range against a background of ﬂuctuating temperature, pH, and
other factors in the brain environment. If the membrane is protected from noise
by a more negative resting membrane potential, the production of an action po-
tential output would require stronger depolarization, which is also energetically
costly. An alternative solution is to move membrane potential up and down in a
coordinated manner across neurons. The only disadvantage of this solution is that
the same external input applied repeatedly will have different consequences in

74
RHYTHMS OF THE BRAIN
22. Such temporal sampling solutions are also used at the behavioral level. To get odor samples in
proper doses, vertebrates rhythmically sniff and arthropods ﬂick their olfactory appendages with char-
acteristic frequency and duration after detecting an odor. Such active ﬂuctuation of the input greatly
enhances odor detection (Laurent, 1999).
23. The external force, of course, is vital. Networks consisting of inhibitory neurons only cannot
sustain any activity. Sustained activity requires regenerative positive feedback, typically supplied by
recurrent excitation. Networks without recurrent excitatory loops (e.g., the cerebellum) do not possess
spontaneous or self-organized network activity (see Cycle 13).
each case, depending on the centrally coordinated mechanism of threshold adjust-
ment. There will be short windows of opportunity when the membrane potential
is elevated to just below threshold, alternating with times when the input remains
subthreshold because of the transient hyperpolarized state of the neurons. This
inconvenience, however, is amply balanced by the lower energy cost. Fluctuating
the membrane potential is energetically much less costly than keeping it at a con-
stant depolarized level.22 The important job of swinging the membrane potential
of principal cells is subcontracted to the interneuron system, and the mechanism
is oscillation.
Balance of opposing forces, such as excitation and inhibition, often gives
rise to rhythmic behavior. Oscillators consisting of only excitatory pyramidal
cells also exist, as is the case when GABAergic receptors are blocked pharma-
cologically. In such cases, the frequency of hypersynchonous, epileptic oscilla-
tions is determined primarily by the intrinsic biophysical properties of the
participating pyramidal cells and the time course of neurotransmitter replenish-
ment after depletion. Under physiological conditions, oscillations critically de-
pend on inhibitory interneurons. In fact, providing rhythm-based timing to the
principal cells at multiple time scales is one of the most important roles of in-
terneurons.
Let us ﬁrst consider the simplest possible oscillating network that consists
of similar types of interneurons, for example, synaptically connected basket
cells. Interneuronal networks without an external excitation would not do much,
of course, except remain silent. A transient excitation would generate only a
transient oscillatory response, which would die away quickly. In order to
maintain an oscillation, some external force is needed to generate spiking ac-
tivity. Since the only requirement of such an external force is to maintain some
ﬁring, this role can be played by a subcortical neurotransmitter or ambient glu-
tamate excitation, each of which can maintain a sufﬁcient level of tonic depo-
larization. Activity of interneurons, in turn, can give rise to some order. The
simplest case is when all or some interneurons themselves display an oscilla-
tory response, and inhibitory coupling can link them into an oscillating net-
work.23
However, even if none of the interneurons oscillates in isolation, the synapti-
cally connected homogeneous interneuron network can still give rise to sus-
tained oscillations. The intuitive interpretation of collective rhythm in interneuron

Diversity of Cortical Functions: Inhibition
75
24. Because GABAA-receptor–mediated inhibition is mediated by Cl–, whose equilibrium poten-
tial is close the resting membrane potential, inhibition is not necessarily hyperpolarizing but “shunt-
ing” (i.e., increased membrane conductance). For a contribution of shunting inhibition in oscillations,
see Vida et al. (2006).
25. Inhibition-based oscillators have been known for a long time in simple networks, consisting of
a few neurons only. In such circuits, neurons reciprocally suppress each other’s activity and therefore
spike out of phase (Marder and Calabrese, 1996). In-phase synchrony, brought about by inhibition, has
been demonstrated both in brain slices maintained in vitro and in computer models. For computational
models leading to the above ideas, see Wang and Rinzel (1993), Lytton and Sejnowski (1991), Ermen-
trout and Kopell (1998), White et al. (1998a and b), Whittington et al. (1995), Traub et al. (1996,
1999), and Wang and Buzsáki (1996). Inhibitory neurons, in turn, can effectively synchronize target
principal cells (Lytton and Sejnowski, 1991; Buzsáki and Chrobak, 1995; Cobb et al., 1995).
networks is the following. In the initial state, interneurons discharge randomly.
Due to chance, some of them may discharge together in a short time window.
This group of neurons will impose stronger inhibition on their targets than other
randomly discharging neurons. As a result of this stronger inhibitory seed, more
neurons will be silenced simultaneously, after which their probability of dis-
charging together upon recovery increases.24 Now, we have a larger group of
synchronously discharging cells which, in turn, will silence an even larger por-
tion of the population, increasing their probability to ﬁre together once inhibition
fades away. With appropriate connectivity and conduction delays, eventually
most or all neurons in the inhibitory network will be inhibited at the same time
and ﬁre synchronously after inhibition wears off. Discharge and silence will al-
ternate in all parts of the network synchronously. Not all interneurons need to
discharge at every cycle, and the oscillation can be maintained as long as a sufﬁ-
cient portion of interneurons ﬁre at each cycle. The mean time difference be-
tween the discharges of any two pairs of cells is zero; that is, interneurons
discharge synchronously at approximately the same time, independent whether
the cell pairs are connected bidirectionally, one way only, or not at all, as long as
they are part of the same network. The frequency of the oscillation depends only
on the average duration of inhibition, which is the critical time constant in the dis-
tributed interneuron clockwork. If inhibition is mediated by fast-acting GABAA
receptors, the oscillation frequency will correspond to the gamma frequency band
(40–100 hertz). Changing the time constant of the GABAA-receptor–mediated
GABA response will affect the beat frequency of the interneuron network
oscillator.25
Because interneurons connected by GABAA receptors are ubiquitous through-
out the brain, it is not surprising that gamma-frequency oscillation can arise in al-
most every structure. In such “gamma clocks,” no single neuron is responsible for
initiating or maintaining the oscillation, yet all of them contribute to the rhythm
whenever they ﬁre. The responsibilities are distributed, and the result depends on
cooperation. Once a collective pattern arises, it constrains the timing of the action
potentials of the individual cells because of the collectively generated inhibition
(ﬁgure 3.9). Thus, there are multiple causes/requirements at various levels. Firing

76
RHYTHMS OF THE BRAIN
and connectivity are essential, but the exact wiring is not critical as long as enough
convergence and divergence are present. On the other hand, the oscillation as a
group-level behavior decreases the timing freedom of all neurons. Once the
network is engaged in an oscillation, the convergent inhibition from multiple part-
ners conﬁnes the windows of opportunity for the neurons to discharge. This top-
down constraint is as important as the bottom-up contribution of the individual
members. Therefore, oscillation in the GABAergic interneuron network is a truly
emergent event, governed by both elementary (i.e., bottom-up) and statistical
(top-down) causes.
Let us now add pyramidal neurons to the interneuron network. Intuitively,
what we expect to see is the following. Because of the synchronous discharge of
interneurons, now both interneurons and pyramidal cells are inhibited rhythmi-
cally and at the same time. So if the pyramidal cells are also activated by some
random external force, they discharge with the lowest probability when all neu-
rons are inhibited and with a higher probability at times when least inhibited,
that is, at the same time as the interneurons. Thus, on average, all neurons will
ﬁre at a zero time lag and will be silenced at the same time. This scenario is best
observed during epileptic discharges and autonomous conditions when outside
inﬂuences exert very little effects on the internal pacing of the population. How-
ever, under physiological conditions, oscillator networks made from homoge-
neous inhibitory neurons are easy to disrupt because small perturbations in
timing can have a large deteriorating effect on subsequent synchronous dis-
charge of the neurons. This may explain why gamma-frequency oscillations are
typically short-lasting, transient events. Introducing some heterogeneities, for
Figure 3.9. In networks with only local inhibitory connections, no oscillations emerge
(left: top, spike raster of individual neurons; middle, voltage trace of a single representa-
tive cell; bottom, population synchrony). Adding a small subset of long-range interneurons
to the locally connected population, with 20 percent of the contacts distributed according
to a power-law distribution, robust oscillation emerges (right). Reprinted, with permission,
from Buzsáki et al. (2004).

Diversity of Cortical Functions: Inhibition
77
26. I discuss oscillators based on pyramidal cell–interneuron interactions in Cycle 9.
example, strong pyramidal cell–interneuron coupling, can interfere with the
rules because now locally active pyramidal cells can also affect timing of the in-
terneurons.26
How can a “distributed clock” of neurons with ﬁnite axon conduction and
synaptic delays grow in larger brains? Simultaneous inhibition of all neurons is
possible only if inhibition arrives to all neurons more or less at the same time. In-
serting just 1 millisecond of delay between each pair of neurons in a chain or a
two-dimensional lattice of neurons may prevent the coherence of the activity at
high frequencies. Some mechanisms are needed to compensate for the ever-
growing delays. The various solutions that are used to compensate for the delays
in different parts of the brain are discussed in subsequent Cycles. For now, let us
consider how the wiring relationship among the various classes of interneurons
can be maintained in growing brains.
Scaling Interneuron Connections in Growing Brains
The primary role of the interneuron networks is to coordinate timing of the action
potentials. This task becomes more and more complex as the brain grows because
neurons are placed farther apart from each other. Owing to the limited axon con-
duction velocities, the growth in volume should somehow be compensated for if
the goal is to keep the timing of principal cells constant even if those cells reside
in distant cortical modules. How this is done is not exactly clear. Below, I con-
sider a few possibilities.
If we know little about the types of interneurons, we know even less about the
relative frequency of cells in each interneuron class. As discussed above, the
numbers of neurons in each primary and secondary division vary considerably.
The most numerous interneuron types belong to the perisomatic control group,
followed by the dendrite-controlling groups, which innervate single or multiple
dendritic domains; the least numerous cells belong to the long-range interneuron
family. Independent of whether we subscribe to the “repeating module” concept
of the cortex or emphasize its small-world-like connectivity features, the relative
incidence of interneurons in the major divisions and the numerous subdivisions
are expected to have some mathematically deﬁnable relationship. It is highly un-
likely that proportions of interneurons in the different divisions (classes) with dif-
ferent extents of axonal projections would scale proportionally in growing brains
for the same reasons discussed for the principal cells (Cycle 2). If a deﬁned con-
nectivity is necessary for oscillatory timing of principal cells in a small rodent
brain, then how should the network be wired in the human brain so that the same
timing function is preserved?

78
RHYTHMS OF THE BRAIN
27. Changizi (2003) is an excellent source of the various scaling laws in the brain. It describes
physicomathematical models for numerous allometric (i.e., differential growth) relationships.
28. According to Lorente de Nó (1949), the morphology of cortical neurons becomes less uniform
and the number of nonpyramidal neurons increases as one ascends the phylogenetic scale. Yet, very
few comparative data are available to support or dispute this challenging claim.
The textbook recommendation for interneuron wiring is local connections, in-
cluding critical gap junctions among dendritically overlapping interneuron popu-
lations. However, this creates a different but related problem: physically distant
neurons are not connected to each other, and this “disconnectedness” increases
monotonically with network size. Synaptic path length and, consequently, synap-
tic and conduction delays become excessively long for synchronization in larger
networks. We need a mechanism that can compensate for the delay. The solution
for interneuron networks is the same as for principal cells: shortcuts. Such short-
cuts are accomplished by the long-range interneurons, which connect local in-
terneurons residing in different cortical regions. Now we can expect from the
small-world rules discussed in Cycle 2 that the fraction of long-range interneu-
rons in large brains will decrease substantially.27
The general conclusion that we can draw from the above discussion is that the
same physiological function in different-sized brains is supported by circuits with
different compositions of neuronal proportions and connectivity, which have to
be explored in the brains of each species to identify the particular wiring
schemes. Nevertheless, these quantitatively different architectures should have
some mathematically predictable relationships. This reasoning, of course, as-
sumes that all mammalian brains are built from essentially the same interneuron
types with similar connectivity principles. An alternative or complementary solu-
tion would be to increase the diversity of interneuron types with the evolution of
the mammalian cortex. To date, there are no data available for such hypothetical
enrichment.28
In the last century, we went as far as we could to uncover and describe the mi-
croscopic and macroscopic components of the brain. Progress over the past de-
cade brought us closer than ever to understanding the true nature of brain
topology. Now, it is time to see the functional consequences of this intricate
wiring. To achieve that, in the remaining Cycles I focus on the dynamics that take
place in the brain web.
Brieﬂy . . .
In addition to principal cells, the cerebral cortex contains diverse classes of in-
terneurons that selectively and discriminately innervate various parts of principal
cells and each other. The hypothesized “goal” of the daunting connectionist
schemes of interneurons is to provide maximum functional complexity. Without
inhibition and dedicated interneurons, excitatory circuits cannot accomplish any-
thing useful. Interneurons provide autonomy and independence to neighboring

Diversity of Cortical Functions: Inhibition
79
principal cells but at the same time also offer useful temporal coordination. The
functional diversity of principal cells is enhanced by the domain-speciﬁc actions
of GABAergic interneurons, which can dynamically alter the qualities of the
principal cells. The balance between excitation and inhibition is often accom-
plished by oscillations. Connections among interneurons, including electrical
gap junctions, are especially suitable for maintaining clocking actions. Thus, the
cerebral cortex is not only a complex system with complicated interactions
among identical constituents but also has developed a diverse system of compo-
nents.

Cycle 44
Windows on the Brain
We shall not fail or falter; we shall not weaken or tire. . . . Give us the tools
and we will ﬁnish the job.
—Winston Churchill
80
The quote from Churchill sounds like an honest promise, but one might suspect
that it is just empty political rhetoric. Of course, if someone gives us the right
tools, we can succeed in anything. The usual problem is, however, that ﬁrst one
has to invent those tools to succeed. To monitor the ever-changing patterns of
brain activity, neuroscientists need methods with sufﬁcient spatial and temporal
resolution. The deﬁnition of “sufﬁcient” in this context is a complex issue be-
cause it varies with the level of analysis and expectation.
There are only a handful of tools at the neuroscientist’s disposal to monitor
brain activity without seriously interfering with it. Can we ﬁnish the job with
these tools alone? Maybe not, but for now, we have to live with them and believe
that we will not fail or falter. Each of the existing methods is a compromise be-
tween spatial and temporal resolution. The desired temporal resolution is the op-
eration speed of neurons, that is, the millisecond scale. The desired spatial
resolution depends on the goal of the investigation and expands from the global
scale of the brain down to the spines of individual neurons. No current method is
capable of continuously zooming from the decimeter to the micrometer scale,
which is why several methods are being used, often in combination. Finding the
optimal level of resolution always depends on the question asked. This Cycle
summarizes the methods used for the exploration of brain activity, emphasizing
mostly those techniques that are most frequently used for monitoring oscillatory

Windows on the Brain     
81
behavior of neuronal networks. If you have taken an introductory level class in
neurophysiological methods, feel free to skip it and come back if you need further
clariﬁcation.
EEG and Local Field Potential Recording Methods
Hans Berger’s noninvasive recording technique is still the most widespread
method used in clinical and psychological laboratories. The galvanometers are
now in museums; the voltage changes are now detected by highly sensitive ampli-
ﬁers and the traces are stored on fast computers. Recording EEG traces from a
few sites is sufﬁcient to determine whether the brain is alive or dead or whether it
is sleeping or awake. However, deciphering the precise spatiotemporal changes in
the brain and how they are associated with the experience of, say, enjoying a Jack-
son Pollock canvas or of remembering your ﬁrst date is an entirely different chal-
lenge. Increasing the number of recording sites is very useful only up to a limit,
because scalp electrodes placed too close together will sense pretty much the
same electrical ﬁelds without further enhancing spatial resolution (ﬁgure 4.1).
(Please note that the term “ﬁeld” is often used differently by neurophysiologists
and physicists. For a neurophysiologist, the ﬁeld or local ﬁeld means extracellular
potential or EEG. For a physicist, ﬁeld refers to a force deﬁned at every point of
space generated by electric charge. The gradient of the ﬁeld is the extracellular
potential.) In contrast to the excellent temporal resolution, scalp recording EEG
methods have serious spatial resolution problems that cannot be easily overcome,
for the reasons explained below.
With several recording sites on the scalp, a map of the brain’s electrical
changes can be constructed. The mapping technique was not invented by neuro-
scientists or neurologists. Seismologists have used an identical method in their
effort to predict the time and place of destructive earthquakes. Our planet is cov-
ered by thousands of seismograph stations. These stations transmit their data for
centralized real-time processing. The online processed data are disseminated to
concerned national and international agencies, which maintain an extensive,
global seismic database on earthquake parameters. Despite the eight-digit dol-
lars spent annually, the spatiotemporal resolution of earthquake predictions, as
we know, is far from adequate. The seismologists’ task is literally identical to
that of a neurologist who attempts to localize the source of an epileptic seizure
from scalp recordings. The source localization problem or, as engineers call it,
the “inverse problem” is the task of recovering the elements and location of the
neural ﬁeld generators based on the spatially averaged activity detected by the
scalp electrodes. However, surface recordings provide only limited information
about the structures and neuron groups from which the hypersynchronous
epileptic activity emanates, and the inverse problem does not have a unique so-
lution. Localization of physiological, less synchronous patterns that generate

82
RHYTHMS OF THE BRAIN
Figure 4.1. Electrical activity of the cerebral cortex can be monitored by multiple elec-
trodes placed on the scalp (“geodesic” helmet, left). Better spatial resolution can be
achieved by subdural “grid” electrodes: intraoperative placement of the subdural grid after
craniotomy (top right) and the estimated electrode positions of the recording sites based on
the patient’s structural MRI (magnetic resonance imaging) scan acquired after the elec-
trodes were implanted (bottom right). Infant photo is courtesy of A. Benasich, Infancy
Studies Laboratory, Rutgers University; photo of grid electrodes is courtesy of R.T. Knight
and R. Canolty, University of California–Berkeley.
1. Nuñez (1998; 2000).
much smaller amplitude extracellular currents and ﬁelds is even more difﬁcult.
Furthermore, numerous brain source conﬁgurations can produce identical elec-
tromagnetic ﬁelds on the scalp, especially when measured at only a ﬁnite num-
ber of electrode positions. The difﬁculty of source localization has to do with the
low resistivity of neuronal tissue to electrical current ﬂow, the capacitive currents
produced by the lipid cell membranes, and the distorting and attenuating effects
of glia, blood vessels, pia, dura, skull, scalp muscles, and skin. As a result, the
EEG, recorded by a single electrode, is a spatially smoothed version of the local
ﬁeld potentials under a scalp surface on the order of 10 cm2 and, under most con-
ditions, has little discernible relationship with the speciﬁc patterns of activity of
the neurons that generate it.1 The spatiotemporal integration problem of neuronal
activity is similar to statistical mechanics of physics in the sense that the speciﬁc
details of the neuronal interactions are replaced by the typical average behavior.
The EEG recorded from the scalp samples mostly the synaptic activity that

Windows on the Brain     
83
2. Current density on the scalp (a measure of the volume conduction of current through the skull
and into the scalp, generated by the neurons) is sensitive mainly to superﬁcial sources, with sensitivity
falling off at approximately r4 (r=distance from a current source or sink to the scalp surface; Pernier
et al., 1988) and insensitive to deep current sources in the brain. Scalp current density is the spatial de-
rivative of current ﬂowing into and through the scalp.
3. Local ﬁeld potentials are usually recorded by small-sized electrodes, e.g., a wire tip placed in
the depth of the brain, and reﬂect transmembrane activity of neurons in a more conﬁned space than
does the scalp electroencephalogram (EEG). By deﬁnition, local ﬁeld potential and EEG are synony-
mous terms, but for historical reasons, EEG usually refers to scalp-recording ﬁeld potentials. Activity
recorded by electrodes placed directly on the brain surface is called an electrocorticogram (ECoG).
Deep electrodes are most often used in patients with intractable epilepsies (Spencer, 1981; Engel,
2002).
occurs in the superﬁcial layers of the cortex. The contribution of deeper layers is
scaled down substantially, whereas the contribution of neuronal activity from be-
low the cortex is, in most cases, virtually negligible. This “ﬁsh-eye lens” scaling
feature of the scalp EEG is the major theoretical limitation for improving its spa-
tial resolution.2
Depth Electrode and Subdural Grid Recordings
Precise localization of the anatomical structures that give rise to the physiological
abnormality is imperative in some clinical situations when the tissue has to be re-
moved surgically. In these difﬁcult cases, several wire electrodes are implanted
into the suspected region, through which the locally generated extracellular ﬁeld
potentials can be monitored, a method routinely used in animal experiments, as
well.3 A less invasive approach that yields localization effectiveness somewhere
between scalp recording and electrodes placed inside the brain is the subdural
grid electrode (ﬁgure 4.1). The grid, a ﬂexible strip with 20–64 rectangularly
arranged electrodes, is introduced subdurally. Although inserting the grid by re-
moving a bone ﬂap in the skull and placing it directly on the cortical (pial) surface
still requires surgery, both its implantation and removal are less invasive and less
risky than those of deep wire electrodes. The amplitude of the electrocorticogram
recorded by the grid electrodes is an order of magnitude larger than that of the
scalp EEG. The signals provide better spatial localization because the electrodes
integrate activity from a smaller brain area and are essentially free of muscle, eye-
movement, and other artifacts ubiquitously present in the scalp EEG of waking,
moving patients. Although these are superior features, the invasive grid electrode
recording technique cannot be used for research in healthy humans because of
ethical considerations. Fortunately, there is another method that can noninva-
sively increase spatial resolution, while keeping the advantage of the outstanding
temporal resolution of the EEG. This technique monitors the magnetic rather than
the electric ﬁelds of the brain.

84
RHYTHMS OF THE BRAIN
4. Maxwell’s equations are a set of partial differential equations that describe and predict the be-
havior of electromagnetic waves in free space, in dielectrics, and at conductor–dielectric boundaries.
Magnetic waves, generated by neurons, therefore can be sensed outside the brain and head. Unlike the
electric potential ﬁeld, which is a scalar quantity, the magnetic ﬁeld is a vector.
5. Brian D. Josephson was a graduate student at Cambridge University when he calculated in 1962
that electrical current would ﬂow between two superconducting materials, even when separated by a
nonsuperconductor or insulator, known today as the Josephson junction. The discovery of the tunnel-
ing phenomenon, or the “Josephson effect,” led to the design of SQUIDs. David Cohen (1968) de-
tected the ﬁrst magnetic waves of the brain (occipital alpha oscillation).
6. Hämäläinen et al. (1993) provide detailed theoretical background for the MEG and SQUIDs and
compares EEG and MEG signal detection problems.
Magnetoencephalography
Luckily, Berger was a physician, not a physicist. Had he understood Maxwell’s
equations, he would not have started recording electricity from his son’s scalp in
his search for the carrier mechanisms of telepathy.4 Electricity needs a conductor
to propagate, and air is a poor conductor; thus brain currents do not go beyond the
scalp. However, voltage changes are accompanied by magnetic ﬁeld changes. Be-
cause the brain generates electromagnetic currents, they can be detected outside
the skull. The technical challenge one has to face, however, is dealing with the
very small magnitude of magnetic ﬁelds generated by neuronal activity. The mag-
netic ﬁelds that emanate from the brain are only one hundred millionth to one bil-
lionth of the strength of Earth’s magnetic ﬁeld (or<0.5 picotesla)! The sensor
that can detect such weak signals is known as a SQUID (superconducting quan-
tum interference device), a truly cool machine: it operates at–270°C. In essence,
it consists of a superconductive loop and two Josephson junctions.5 Liquid helium
in the SQUID chills the coils to superconducting temperatures. Like with EEG,
we need many sensors around the head to increase spatial resolution. The detector
coils are placed as close to each other as possible, forming a spherical
honeycomb-like pattern concentric with the head (ﬁgure 4.2).
A practical advantage of magnetoencephalography (MEG) is that no elec-
trodes need to be attached to the scalp because the magnetic ﬁeld emerges from
the brain through the skull and the scalp without any distortion. The subject’s
head is simply ﬁxed close to the surrounding coils. In contrast to the EEG, the
MEG signal reﬂects mostly intracellular currents. Partly for this reason, MEG and
EEG “see” different types of activity. For example, the radial sources that form
the best dipoles for scalp EEG are not well detected by MEG. Only currents that
have a component tangential to the surface of a spherically symmetric conductor
produce a magnetic ﬁeld outside the scalp. This fact favors detection of activity
mainly from the ﬁssures of the cortex. The spatial resolution of MEG is better
than that of the EEG (ideally less than a centimeter), mostly because, in contrast
to the EEG, the magnetic ﬁelds are not scattered and distorted by inhomo-
geneities of the skull and scalp.6 Nevertheless, in practice, MEG source localiza-
tion is still not accurate because the model assumptions are overly simpliﬁed and

Windows on the Brain     
85
Figure 4.2. Magnetoencephalography (MEG) can detect brain responses outside the skull.
The neuromagnetometer can record from numerous sites over the cerebral cortex (top pan-
els). The example shown at the bottom is a spontaneous oscillation in the superior temporal
lobe (lower right, arrow) at approximately 10 hertz (the auditory tau rhythm, part of the alpha
family; see Cycle 7). Auditory stimulation suppresses the rhythm. The MEG source of the tau
rhythm is described in Lehtela et al. (1997) and discussed in Cycle 7. Figure courtesy of R.
Hari and M. Seppä, Brain Research Unit, Helsinki University of Technology.
are not adequate to represent the complexity of the physics and physiology involved
in the human brain. Even under ideal conditions, the improved spatial resolution of
MEG is insufﬁcient to obtain information about local circuits and layer-differential
effects in the cortex or about neuronal spikes, the necessary requirements for re-
vealing not only the locations but also the mechanisms of neuronal operations.
Origin of Local Field Potentials
The signals measured by EEG and MEG reﬂect the cooperative actions of neu-
rons. Not only neurons but also glia and even blood vessels can contribute to the

86
RHYTHMS OF THE BRAIN
mean ﬁeld measured by EEG and MEG, but in order to keep things simple, let us
ignore the latter for the moment. The “mean ﬁeld” measured outside the neurons
in the extracellular space simply reﬂects the “average” behavior of large numbers
of interacting neurons. The large degree of freedom—the essence of brain
activity—is thus replaced by the “typical” average behavior. The exact nature of
such cooperation is, of course, the million dollar question. Before attempting to
address this complex question, let us begin with a single neuron.
Neurons Communicate with Spikes
Neurons share the same characteristics and have the same parts as other cells in the
body, but they can pass messages to each other over long distances through their ax-
onal processes. Like virtually any cell in the body, neurons have a high concentra-
tion of ions of potassium (K+) and chloride (Cl–) inside and keep the sodium (Na+)
and calcium (Ca2+) ions outside. This arrangement produces a small battery that
maintains a voltage difference of –60 millivolts relative to the world outside of the
cell membrane. This ion separation is perhaps attributable to our single-cell ances-
tors and where they came from: the sea. Given the high concentration of Na+ in sea-
water, keeping Na+ outside the cell was a smart choice. However, when more
developed organisms migrated to land, they had to carry the sea with them to main-
tain the same extracellular environment. For this purpose, the circulation of lymph
and blood developed. All our cells are constantly bathed in water, more precisely,
salt water. Each cell’s membrane is perforated by myriads of small pores, appropri-
ately called channels, through which ions can move in and out. Neurons can open
and close these ion channels very quickly, thereby altering the ﬂux of ions and, as a
consequence, the voltage difference across the membrane. For example, the Na+
channel opening initially occurs linearly with time, with a consequent linear de-
crease of the voltage difference between the inside and outside of the membrane:
the neuron depolarizes. However, after some critical amount of Na+ crosses the
membrane, something entirely novel occurs. At this critical threshold, Na+ inﬂux
will facilitate the opening of additional Na+ channels, leading to an avalanche of
Na+ inﬂux. This fast, strongly nonlinear event will depolarize the membrane so that
the inside becomes positive by about 20 millivolts, as if the battery was reversed
temporally. This fast depolarizing event is portrayed by the rising phase of the ac-
tion potential (ﬁgure 4.3). At this voltage level, the process stops mostly due to an-
other feature of the membrane, the voltage-dependent inactivation of Na+ channels.
Pumping all the excess Na+ out of the neuron is a lengthy process. To regain the
resting voltage across the membrane more rapidly, neurons opted for another strat-
egy: voltage dependence of K+ channel activity. As the action potential reaches its
peak, the voltage-dependent K+ channels are activated and quickly repolarize the
cell. This fast repolarization is the falling phase of the action potential (ﬁgure 4.3).
Thus, the positive charge created by the inﬂux of Na+ is compensated for by the
quick efﬂux of equal charges carried by K+. This push-pull process, active during
the action potential, takes about a millisecond (absolute refractoriness) and limits
the maximum ﬁring rate of the neuron. Because the action potential appeared as a

Windows on the Brain     
87
100 m
20 mV
dendrite
K outflux
Na
influx
soma
axon
1 ms
Figure 4.3. Fast action potentials propagate forward to the axon collaterals and backward
to the dendrites: action potential waveforms (left) recorded with patch pipettes (described
further below; see note 24) from the axon, soma, and dendrite in a layer 5 pyramidal neuron
(right). Note delays and the different kinetics of Na+ inﬂux (rising phase of spike) and K+
outﬂux (falling phase) and the associated different waveforms of the voltage traces.
Reprinted, with permission, from Häusser et al. (2000).
7. Although failures may occasionally occur at junctions or in the terminals at higher frequencies,
the current view is that the low-frequency action potential travels to all presynaptic boutons.
short, large-amplitude event on the early chart recorders, investigators called the
action potential a “spike.” So when we refer to a spiking or ﬁring neuron, what we
really mean is that the neuron gives rise to action potentials.
In contrast to the megahertz speed of computers, the speed of spike transmis-
sion by neurons is limited to a maximum of a few hundred events per second.
Nevertheless, once an action potential is initiated, it can propagate through the en-
tire axon tree of the neuron and signal this event to all its downstream targets.7

88
RHYTHMS OF THE BRAIN
8. The quantitative description of the events associated with the action potential, by Alan Lloyd
Hodgkin and Andrew Fielding Huxley, remains among the most signiﬁcant conceptual breakthroughs
in neuroscience. Their success story is also a reminder of the power of long-term collaboration be-
tween people with different but overlapping expertise. For a quantitative description of the action po-
tential, see Johnston and Wu (1994).
Again, compared to the traveling velocity of electricity in computer circuits,
propagation of action potentials is quite sluggish at 0.5–50 meters per second, de-
pending on the caliber and insulation type of the axon cable.8 This slow transfer
of neuronal information by the traveling action potentials is the most important
limiting factor in the speed performance of neuronal networks.
Synaptic Potentials
Neurons are also good listeners, very much interested in what their upstream
peers have to say. At the contact point of each axon terminal or “bouton,” there is
a thin physical gap between the membrane of the axon terminal and the mem-
brane of the sensing neuron. This membrane–gap–membrane triad is called the
synapse (ﬁgure 4.4). The presynaptic terminal is specialized to release a chemical
substance, appropriately called a neurotransmitter, which then binds onto special-
ized receptors on the postsynaptic side. All cortical pyramidal cells release gluta-
mate, which depolarizes and discharges the target neurons; therefore, glutamate is
referred to as an excitatory neurotransmitter. In contrast, GABA typically hyper-
polarizes the postsynaptic resting membrane, which is why GABA’s effect is
called inhibitory. Neurotransmitters exert their effect by binding to receptors that
Figure 4.4. Neurons communicate mainly with chemical synapses. Left: Neural tissue
with somata, dendrites, spines, and axons. Middle: An axon terminal (presynaptic, pre) in
synaptic contact with a target (postsynaptic, post) neuron. Neurotransmitter is packaged
into vesicles in the axon terminal. Upon arrival of an action potential and associated Ca2+
inﬂux into the terminal, the vesicle empties its contents into the synaptic cleft, and the neu-
rotransmitter binds onto its receptors in the postsynaptic membrane. Right: Electron mi-
croscopic picture of the synapse. Courtesy of T.F. Freund.

Windows on the Brain     
89
9. Besides the major neurotransmitters glutamate and GABA, several other subcortical neuro-
transmitters are known (see Johnston and Wu, 1994; see also Cycle 7).
10. A low-pass ﬁlter offers easy passage to low-frequency signals and difﬁcult passage to high-
frequency signals because the capacitor’s impedance decreases with increasing frequency.
11. This is not necessarily the case under epileptic conditions, when neurons can synchronize
within the duration of action potentials. The synchronously discharging neurons create local ﬁelds,
known as compound or “population” spikes.
reside in the membrane of the postsynaptic neuron. When activated, the receptors
facilitate or suppress the kinetic activity of the Na+, K+, Cl–, and Ca2+ channels so
that the membrane potential will deviate from the resting voltage (see ﬁgure 
6.3).9 To deﬁne these respective events more clearly, we distinguish excitatory
postsynaptic potentials (EPSPs; or currents, EPSCs) from inhibitory postsynaptic
potentials (IPSPs; or currents, IPSCs). Compared to the fast action potentials,
membrane potential changes associated with EPSPs and IPSPs are several-fold
smaller in amplitude. However, they last for tens of milliseconds. This latter prop-
erty is critical for understanding the generation of EEG activity.
Extracellular Currents
For the transmembrane potential to change in a given neuron, there must be a
transmembrane current, that is, a ﬂow of ions across the membrane. Opening of
membrane channels (or, more precisely, an increase in their open state probabil-
ity) allows transmembrane ion movement and is the source of ion ﬂow in the ex-
tracellular space. The local ﬁeld potential (i.e., local mean ﬁeld), recorded at any
given site in or outside the brain, reﬂects the linear sum of numerous overlapping
ﬁelds generated by current sources (current from the intracellular space to the ex-
tracellular space) and sinks (current from the extracellular space to the intracellular
space) distributed along multiple cells (ﬁgure 4.5). The low resistance or “shunt-
ing” effect of the extracellular ﬂuid, the membranes of neurons, glia, and blood
vessels, and the slow movement of ions attenuate current propagation in the ex-
traneuronal space. Because the passive neuron acts as a capacitive low-pass ﬁlter,
this attenuation is quite discriminative: it affects fast-rising events, such as the ex-
tracellular spikes, much more effectively than slowly undulating voltages.10 As a
result, the effects of postsynaptic potentials can propagate much farther in the ex-
tracellular space than can spikes. Furthermore, because of their longer duration,
EPSPs and IPSPs have a much higher chance to occur in a temporally overlapping
manner than do the very brief action potentials. Finally, EPSPs and IPSPs are dis-
played by many more neurons than are spikes because only a very small minority
of neurons reach the spike threshold at any instant in time. For these reasons, the
contribution of action potentials to the local ﬁeld and especially to the scalp EEG
is negligible.11
Excitatory currents, involving Na+ or Ca2+ ions, ﬂow inwardly at an excitatory
synapse (i.e., from the activated postsynaptic site to the other parts of the cell) and
outwardly away from it. The passive outward current far away from the synapse is
referred to as a return current from the intracellular milieu to the extracellular

90
RHYTHMS OF THE BRAIN
Figure 4.5. Generation of extracellular ﬁeld potentials. Left: Spontaneously occurring
ﬁeld potential (sharp wave) recorded simultaneously in various layers of the hippocampus
(CA1–dentate gyrus axis). The traces represent averages of 40 events. Middle: Current-
source density map, constructed from the ﬁeld potentials. Interpretation of the current
sinks (s) and sources (so) is on the basis of anatomical connectivity, representing different
domains of parallel-organized pyramidal cells and granule cells. Active currents are indi-
cated on the right, and passive return (re) currents on the left, of the pyramidal neuron. The
sinks in the dendritic layers are caused primarily by excitation from the upstream CA3 py-
ramidal cells, whereas the source around the soma reﬂects mainly inhibition, mediated by
basket interneurons. Iso, isoelectric (neutral) state.
12. This “classical” description of the origin of extracellular ﬁelds must be supplemented by the
recent ﬁndings about the active properties of neurons (see Cycle 8; Llinás, 1988). Subthreshold oscil-
lations, afterpotentials, Ca2+ spikes, and other intrinsic events also produce relatively long-lasting
transmembrane events. The contribution of these nonsynaptic events to the local ﬁeld potential can of-
ten be more important than the contribution of synaptic events (Buzsáki et al., 2003b).
space. Inhibitory loop currents, involving Cl– or K+ ions, ﬂow in the opposite di-
rection. Viewed from the perspective of the extracellular space, membrane areas
where current ﬂows into or out of the cells are termed sinks or sources, respec-
tively. The current ﬂowing across the external resistance of the extraneuronal
space sums with the loop currents of neighboring neurons to constitute the local
mean ﬁeld or local ﬁeld potential (ﬁgure 4.5). In short, extracellular ﬁelds arise
because the slow EPSPs and IPSPs allow for the temporal summation of currents
of relatively synchronously activated neurons.12
Depending on the size and placement of the extracellular electrode, the vol-
ume of neurons that contributes to the measured signal varies substantially. With
very ﬁne electrodes, the local ﬁeld potentials reﬂect the synaptic activity of tens
to perhaps thousands of nearby neurons only. Local ﬁeld potentials are thus the
electric ﬁelds that reﬂect a weighted average of input signals on the dendrites and
cell bodies of neurons in the vicinity of the electrode. If the electrode is small

Windows on the Brain     
91
13. Current density is is the current entering a volume of extracellular space, divided by the vol-
ume. The current ﬂow between two sites (e.g., between recording electrodes 1 and 2 and between elec-
trodes 2 and 3 in the example) can be calculated from the voltage difference and resistance using
Ohm’s law. The difference between these currents (i.e., the spatial derivative) is the current density.
More precisely, the current density is a vector, reﬂecting the rate of current ﬂow in a given direction
through the unit surface or volume (measured in amperes per square meter for a surface and amperes
per cubic meter for a volume). Current density depends on both the electric ﬁeld strength and the con-
ductivity (σ) of the brain. The conductance is a factor of both conductivity and the shape of volume.
Conductivity is inversely proportional to resistivity. The average resistivity of white matter is ∼700 Ω.
cm, and that of gray matter is ∼300 Ω.cm. The proportion of ﬁbers therefore signiﬁcantly affects tis-
sue resistivity. For a thorough theoretical discussion of the current density method, I recommend
Mitzdorf (1985) and Nicholson and Freeman (1975).
enough and placed close to the cell bodies of neurons, extracellular spikes can
also be recorded. Therefore, in such a small volume of neuronal tissue, one often
ﬁnds a statistical relationship between local ﬁeld potentials, reﬂecting mostly in-
put signals (EPSPs and IPSPs), and the spike outputs of neurons. The reliability
of such relationship, however, progressively decreases with increasing the elec-
trode size, by lumping together electric ﬁelds from increasingly larger numbers
of neurons. This is why the scalp EEG, a spatially smoothed version of the local
ﬁeld potential at numerous contiguous sites, has a relatively poor relationship
with spiking activity of individual neurons.
In architecturally regular regions of the brain, such as the neocortex, the loca-
tions of the extracellular currents reﬂect the geometry of the inputs. Using several
microelectrodes with regular distance from each other, one can calculate the den-
sity of the local currents from the simultaneously measured voltages, provided
that information is available about the conductance of the tissue. Consider a dis-
tant current source relative to three equally spaced recording sites. Each electrode
will measure some contribution of the ﬁeld (due to the passive return currents that
pass through the extracellular space) from the distant source. The voltage differ-
ence between two adjacent electrodes can determine the voltage gradient, that is,
how fast the ﬁeld attenuates with distance from the current source. Because the
source is outside the area covered by the electrodes, the voltage gradient will be
the same between electrodes 1 and 2 and between electrodes 2 and 3. Taking the
difference between the voltage gradients, we get a value of zero, an indication that
the measured ﬁeld did not arise from local activity but was volume-conducted
from elsewhere. In contrast, if the three electrodes span across a synchronously
active afferent pathway, the voltage gradients will be unequal and their difference
will be large, indicating the local origin of the current. By placing more micro-
electrodes closer to each other, we can more precisely determine the maximum
current density and therefore the exact location of the maximum current ﬂow.13
Unfortunately, from measuring the local current density alone, we have no
way of telling whether, for example, an outward current close to the cell body
layer is due to active inhibitory synaptic currents or if it reﬂects the passive return
loop current of active excitatory currents produced in the dendrites. Without addi-
tional information that can clarify the nature of the current ﬂow, the anatomical

92
RHYTHMS OF THE BRAIN
14. Spike occurrences of in the vicinity of the cell body of the neurons reliably reﬂect their output
messages. Unfortunately, no reliable methods exist to monitor all individual inputs to a single neuron
simultaneously. Inputs can be estimated only by recording the local ﬁeld potentials that reﬂect the spa-
tially averaged activity of many neurons and inferring indirectly the mean input. Another, equally dif-
ﬁcult approach is to monitor the spike output of the afferent neurons to the chosen recipient neuron
and infer the input conﬁgurations from their spiking.
source remains ambiguous. The missing information may be obtained by simulta-
neous intracellular recording from representative neurons that are part of the pop-
ulation responsible for the generation of the local current. Alternatively, one can
record extracellularly from identiﬁed pyramidal cells and interneurons and use
the indirect spike-ﬁeld correlations to determine whether, for example, a local
current is an active, hyperpolarizing current or a passive, return current from a
more distant depolarizing event. Taking these extra steps is worthwhile. The re-
ward one obtains by pinning down the currents is crucial information about the
anatomical source of the input to those same neurons whose output (i.e., spiking)
activity is simultaneously monitored. Once information about both the input and
output of a small collection of neurons working together becomes available, one
may begin to understand the transformation rules governing their cooperative ac-
tion. This approach is the next best thing to the ideal condition when all inputs
(synapses) and the output of each cell could be monitored simultaneously and
continuously.14
Functional Magnetic Resonance Imaging
Currently, the best-known noninvasive procedure for the functional investigation
of the human brain is magnetic resonance imaging (MRI). The method is based
on the detection and analysis of magnetic resonance energy from speciﬁc points
in a volume of tissue. The MRI technique provides far better images than those
the traditional X-ray and other scanning technologies. Hydrogen atoms of water
represent tiny magnetic dipoles, which can align in an orderly way when placed
inside of a very strong magnetic ﬁeld. In practice, a short pulse of RF energy per-
turbs these tiny magnets from their preferred alignment. As they subsequently re-
turn to their original position, they give off small amounts of energy that can be
detected and ampliﬁed with a “receiver coil” placed directly around the head. The
injection of electromagnetic energy into a single plane is used to produce a slice
through the brain volume. To produce consecutive brain slices, the head is ad-
vanced in small increments. Because gray matter and white matter contain differ-
ent amounts of water, this difference generates a contrast between the surface of
the neocortex and the underlying white matter and other areas of the brain that
can be used to provide a detailed image of the brain. However, while the MRI
method offers exquisite details about the structure of the brain, it does not tell us
anything about neuronal activity.
As previously mentioned, active neurons consume a lot of energy, and in areas

Windows on the Brain     
93
15. During the late 1980s, Seiji Ogawa, then at Bell Labs in Murray Hill, New Jersey, noted that
cortical blood vessels became more visible as blood oxygen was lowered. From these initial observa-
tions, he concluded that the local magnetic ﬁeld inhomogeneities can be used to assess neuronal ac-
tivity, and termed his invention the blood-oxygenation-level–dependent (BOLD) method (Ogawa et
al., 1990). For a brief discussion on the complex origin of BOLD, I suggest Logothetis (2003), Logo-
thetis et al. (2001), and Raichle (2003).
with high neuronal activity this results in a large difference between the concen-
tration of the oxygenated hemoglobin in the arterial blood and the deoxygenated
hemoglobin in the venous outﬂow. These local magnetic-ﬁeld inhomogeneities
can be assessed by the BOLD (blood-oxygenation-level–dependent) method.
Functional MRI (fMRI), which uses the BOLD method, can measure neuronal
activity indirectly.15 Because of the unprecedented details of localized changes in
the brain in response to various challenges and perturbations, the fMRI method
has become the leading tool in cognitive science research. Nevertheless, as with
any technique, fMRI has its limitations. The ﬁrst limitation has to do with the
general statement that “fMRI measures neuronal activity.” Neuronal activity has
numerous components, including intrinsic oscillations, EPSPs, IPSPs both in
principal cells and in inhibitory interneurons, action potential generation and
propagation along the axon, and release, binding, reuptake, and reprocessing of
the released neurotransmitter. Which of these processes, alone or in combination,
are responsible for the changes in BOLD has yet to be worked out. Without such
crucial information, it is not possible to conclude whether an increase in BOLD
results from increased ﬁring of principal cells or interneurons or increased release
of neurotransmitter from afferents whose cell bodies are outside the area with in-
creased BOLD signal.
The second problem arises from the neurophysiological observations that nu-
merous brain operations are brought about by changing the ﬁring patterns of neu-
rons without any change in the rate of postsynaptic potentials or alteration of
neuronal ﬁring rates (I provide some examples in Cycles 8, 9, and 12). For exam-
ple, recognition or recall of the correct and incorrect information may use differ-
ent sets of neurons but engages those neurons with the same magnitude of
activity. Thus, fundamentally different cognitive operations in the same structures
can be generated with the same amount of energy, with no expected change in
BOLD. This reverse engineering problem is, of course, identical to that of the
EEG and MEG. Thus, with the exception of signiﬁcantly improved spatial resolu-
tion, one cannot expect more from fMRI than from EEG measurements.
The third technical drawback of fMRI is its slow temporal resolution. Not only
is the blood-ﬂow response delayed about half a second after neuronal activation,
but also the second-scale temporal resolution of the BOLD imaging method is ex-
cessively long for assessing spatiotemporal evolution of neuronal activity across
brain domains. As discussed in Cycle 2, activity can get from any structure to just
about any other structure in the brain by crossing just ﬁve to six synapses within a
second. Even if only a few areas show increased BOLD activity, we have no
knowledge about the temporal sequence of their activation, a critical issue for

94
RHYTHMS OF THE BRAIN
understanding how the information is processed. Understanding the neuronal
mechanisms that give rise to overt and cognitive actions requires method(s) at the
temporal resolution of behavior.
Positron Emission Tomography
Another important research tool for visualizing brain function is positron emis-
sion tomography (PET). A major advantage of PET is that it provides information
about the use and binding of speciﬁc chemicals, drugs, and neurotransmitters in
the brain. To obtain a PET scan, the subject either inhales or receives an injection
of a very small amount of a radiolabeled compound, which then accumulates in
the brain. As the radioactive atoms in the compound decay, they release positively
charged positrons. When a positron collides with a negatively charged electron,
they are both annihilated, and two photons are emitted. The photons move in op-
posite directions and are detected by the sensor ring of the PET scanner. Recon-
struction of the three-dimensional paths of the particles provides information
about the maximum accumulation or metabolism of the radiolabeled isotope.
Both the spatial and temporal resolutions of PET are inferior to fMRI.
Let me pause here to add a few important details regarding all of these ad-
vanced imaging methods. A single MEG, PET, or fMRI device weighs several
tons. Because the subject’s head must be immobilized for brain scanning, these
methods are not practical for the examination of behavior-generated brain
changes in the most frequently used small laboratory animals, such as rats and
mice. More important, even the combined, simultaneous application of these
methods falls short of the goal of explaining how neurons and neuronal assem-
blies make sense of the world, generate ideas and goals, and create appropriate re-
sponses in a changing environment. In the brain, speciﬁc behaviors emerge from
the interaction of neurons and neuronal pools. Although EEG, MEG, fMRI, PET,
and related methods have opened new windows on brain function, in the end all
these indirect observations need to be reconverted into a common currency—the
format of neuronal spike trains—to understand the brain’s control of behavior.
Increasing Spatial and Temporal Resolution: 
Optic Methods
To date, the best spatial resolution of neuronal activity is provided by optical
methods. By viewing through a microscope, light intensity or color changes can
be monitored at the micrometer scale, and at the same time, large two-
dimensional areas can be observed, just like watching a movie screen. The trick is
to extract functional information from the optically detected signals. The most
prominent pioneer in this ﬁeld has been Amiram Grinvald of the Weizmann Insti-
tute of Science in Rehovot, Israel. Working ﬁrst with invertebrates and later in the

Windows on the Brain     
95
16. Hemoglobin is a protein that binds oxygen. Cytochromes are energy-producing enzymes in the
inner mitochondrial membrane that catalyze the reaction between ferrocytochrome c and oxygen to
yield ferricytochrome c and water. It is associated with the pumping of protons and the resultant phos-
phorylation of ADP to ATP, a molecule in great demand for energy. The high metabolic rate of neu-
rons explains their strong cytochrome activity. Fast-ﬁring interneurons have a particularly high
density of cytochromes (Gulyás et al., 2006); therefore, they may bias the optical images.
17. For an overview of the fast imaging methods with voltage-sensitive dyes, see Grinvald and
Hildesheim (2004). In principle, optical ﬁbers can be lowered into the depth of the brain. However, the
spatial coverage of this invasive modiﬁcation is limited.
18. Winfried Denk, then a graduate student at Cornell University in New York, James Strickler,
and their adviser, Watt W. Webb, constructed the ﬁrst 2-PLSM in 1990 (Denk et al., 1990).
monkey visual cortex, Grinvald noticed that neuronal activity affects the optical
properties of brain tissue, which can be conveniently monitored by photon-
detecting arrays or sensitive cameras. His method is known as intrinsic optical
imaging, because it is based on the light-reﬂecting/absorbing properties of the in-
tact brain tissue. All that is needed is a very sensitive, fast camera to be able to
watch the brain in action. Unfortunately, interpretation of the obtained images in
terms of neuronal function is even more difﬁcult than in the case of fMRI. The
potential sources for these activity-dependent intrinsic signals are numerous and
include changes in the physical properties of the tissue itself, which affect light
scattering, or changes in the absorption, ﬂuorescence, or other optical properties
of various molecules having signiﬁcant absorption or ﬂuorescence, for example,
hemoglobin or cytochromes.16
The temporal resolution of the intrinsic imaging method can be signiﬁcantly
improved by using compounds whose optical properties can be altered by some
brain mechanisms. For example, voltage-sensitive dyes bind to the external sur-
face of the neuronal membrane and act as molecular transducers to transform
changes in membrane potential into optical signals. Optical imaging with voltage-
sensitive dyes and fast photodetecting devices permit the visualization of neu-
ronal activity with improved temporal resolution and a spatial resolution of
approximately 100 micrometers. This method combines the advantageous fea-
tures of surface local ﬁeld potential recordings with high spatial resolution. There
are a few methodological caveats, however. The dye has to be applied physically
to the surface of the brain, making prolonged and repeated observations difﬁcult.
Single cells cannot be identiﬁed, and more critically, input and output actions of
the neurons cannot be separated; thus, their contribution to the transfer of infor-
mation can be inferred by indirect means only or from a combination with other
methods. Finally, because the optical method works much like our video cameras,
it allows for the observation of surface events only, and it is hard to ﬁgure out
what happens inside the neocortex or in deeper brain structures.17
Penetration into deeper layers of the neocortex is possible with another inno-
vation, known as two-photon or multiphoton laser scanning microscopy (2-PLSM
or m-PLSM).18 Only three things are needed for this powerful method to work:
extremely powerful laser pulses in the 700–900 nanometer range (deep red to in-
frared), molecules that change their ﬂuorescence relevant to some physiological

96
RHYTHMS OF THE BRAIN
19. After moving to the Bell Laboratories, Denk and his colleagues David Tank, Karel Svoboda,
and Rafael Yuste provided images of neurons from the living brain with details that rivaled those visu-
alized in ﬁxed tissue and coupled these detailed images to brain function (Denk et al., 1996). Recog-
nizing that the most meaningful test of any hypothesized brain mechanism is behavior, they
constructed a miniaturized prototype of the 2-PLSM that can potentially be carried by a small animal
(Helmchen et al., 2001).
activity, and the ability of the microscope to collect the emitted ﬂuorescence
photons for producing a three-dimensional image. Very high energies are needed
for two- or multiphoton interactions with the ﬂuorescing target. When this
occurs, the individual energies of the photons combine, and the cumulative
effect is the equivalent of delivering one photon with twice the energy (in the
case of two-photon excitation) or three times the energy (in three-photon excita-
tion). High-wattage lasers can easily fry the brain instantaneously. To avoid such
an undesirable effect, the laser beams are pulsed so that only very short, 100 fem-
tosecond long pulses penetrate the brain. The scanning beam is a moving point,
like the cathode ray in the TV screen tube; therefore, the brain targets are affected
only at the time the beam moves across them. The 2-PLSM produces high-
resolution, three-dimensional pictures of tissues with minimal damage to living
cells.19
Most current functional measurements with 2-PLSM investigate intracellular
calcium changes, simply because effective ﬂuorescent sensors are available for
this ion. Methods for the direct detection of action potentials and other functional
indices are being developed. The optical imaging methods will fully reach their
potential when combined with the rapidly evolving tools of molecular biology for
the creation of function-sensing ﬂuorescent markers. Some further practical
problems, such as the trade-off between temporal and spatial resolution, can be
addressed and perhaps resolved. However, obtaining images in deep layers of the
neocortex or structures below the cortex remains a challenge even in small ani-
mals. In the meantime, alternative methods are needed to monitor the cooperative
action of individual neurons.
Recordings from Single Neurons In Vitro
Neurons are complex devices. Understanding the biophysical properties of indi-
vidual neurons would greatly enhance understanding their collective behavior in
networks. Characterization of individual neurons is especially critical in brain re-
gions built from a variety of different neuron types. Most of our knowledge about
the biophysical properties of neurons is derived from experiments carried out in
brain slice preparations in vitro. Although the brain slice method compromises
brain circuits, it provides unprecedented spatial resolution, precision, and phar-
macological speciﬁcity for the examination of the biophysical and molecular prop-
erties of the cell membrane. Brain slices allow recording from local neural circuits,

Windows on the Brain     
97
20. Brain slices are used for a wide variety of studies, including synaptic plasticity and develop-
ment, network oscillations, and intrinsic and synaptic properties of anatomically deﬁned neurons. The
in vitro slice preparation was introduced by Yamamoto and McIlwain (1966). Soon after it was
adopted for the physiological examination of the hippocampus in Per Andersen’s laboratory in the In-
stitute of Physiology, Oslo, Norway in the 1970s, it became the method of choice for biophysical and
pharmacological investigation of single neurons (see Skede and Westgaard 1971).
21. Khalilov et al. (1997). In addition to studying single neurons, brain slices have been used ex-
tensively to study the emergence of network oscillation. A variety of oscillatory patterns, reminiscent
of those in the intact brain, have been replicated in brain slices despite the fact that in these reduced
preparations only a small fraction of the in vivo network is present. Do these in vitro models faithfully
represent the rhythms they intend to mimic? If so, the model is of great value, because the reduced
preparations exclude a large number of variables that are uncontrollable in the intact brain and allow
for systematic changes of various parameters that are critical for the emergence, maintenance, and ter-
mination of the oscillation. Reduction of the parameter space, in turn, allows for the construction of
computer models for the identiﬁcation of the necessary and sufﬁcient conditions underlying various
aspects of the oscillations (Traub et al., 1999; Destexhe and Sejnowski, 2001, 2003). The ﬁnal and
most important step in this “reverse engineering” strategy is the comparison of the in vitro and in sil-
ico (i.e., computational modeling) engineered rhythms with those of the intact brain. It is this stage
that should address the important question of whether the evoking conditions in the reduced system
are in fact present in the intact brain and to identify the similar and dissimilar aspects of the observed
and created oscillations. This process should also identify features of the oscillation that cannot be re-
produced in the model and should thus point to the need for larger circuits and more complex interac-
tions than are offered by the model. Unfortunately, in vivo and in vitro experiments and computational
modeling are rarely done in the same laboratory. As a result, models too often claim too much. On the
other hand, critical details are often not accessible through the in vivo approach. It is fair to say that, to
date, oscillations that have been reproduced and studied with excruciating details in vitro and in mod-
els are best understood.
with the advantages of mechanical stability, direct visualization of neurons, and
the experimenter’s control over the extracellular environment.20 Depending on
the age of the animal, the thinly cut sections of the brain, placed in a humidiﬁed,
temperature-controlled dish and perfused with oxygenated cerebrospinal ﬂuid,
can be kept alive for several hours. Using a microscope and an infrared camera,
the outlines of individual neurons can be visualized. In case of very young ani-
mals, whole pieces of brain structures, for example, the hippocampus, can be kept
alive in vitro. Various drugs and electrolytes can be perfused or applied locally
under visual control.21
The popularity of the brain slice method was catalyzed by another ground-
breaking innovation, the patch-clamp technique, introduced by Erwin Neher and
Bert Sakmann of the Max Planck Institute for Biophysical Chemistry in Göttin-
gen, Germany. The key invention in patch-clamp recording is the use of a pipette
with a ﬁnely polished end. The pipette can be attached gently to the cell mem-
brane, and by applying negative pressure through the pipette, a piece of the cell
membrane, the patch, is “sucked” into the pipette. The result is that the membrane
attached to the pipette becomes mechanically and electrically isolated (“sealed”)
from the surrounding extracellular ﬂuid. By applying a short pulse of low pres-
sure through the pipette, the patch can be broken and a direct junction between the

98
RHYTHMS OF THE BRAIN
22. The membrane can be penetrated by sharp glass electrodes, as well. This sharp electrode ap-
proach has been used successfully for intracellular recordings of neurons for many years. However,
because its tiny tip cannot be easily visualized under the microscope, the sharp electrode methods be-
came less popular in in vitro experiments.
23. The patch-clamp method in fact refers to four different methods. (1) The most popular version
is the whole-cell method, typically patching the cell body. A major advantage of the whole-cell
method is the very low access resistance between the electrode content and the cytosol. This allows
“clamping” the membrane voltage to any arbitrary value, e.g., reversal potential of chloride or
sodium, and measuring the current ﬂowing through the membrane. (2) The “cell-attached” method is
basically an extracellular method. A difference from other extracellular methods is that the tip of an
electrode is attached tightly to the membrane and the inside of the pipette is isolated from the extra-
cellular environment electrically (a “gigaohm seal” is established). This feature prevents signals from
other neurons from interfering with the activity of the recorded neuron. The polished pipette method
is also useful to investigate ion channels in excised patches of the membrane without the inﬂuence
from the rest of the neuron. (3) In the inside-out conﬁguration, the outer membrane surface is facing
the pipette’s oriﬁce whereas (4) in the outside-out conﬁguration it is the inner membrane surface. Prior
to the patch-clamp method, neurons had been impaled with a sharp glass electrode successfully for
many years. The disadvantages of glass pipettes are their small size and the high resistance of their
tips, which makes delivering chemicals and large currents more difﬁcult.
24. The tungsten extracellular electrode method was introduced by Hubel (1957) for the explo-
ration of single neuronal responses in the visual cortex. The single-cell recording method has gener-
ated a wealth of information about a wide range of issues, including sensory representation,
short-term memory, and motor organization.
inside of the neuron and the electrolyte solution in the pipette is established.22
Any current waveform can be applied, and relatively large molecules can be
“washed” into the neuron through the pipette. Alternatively, a piece of a mem-
brane, sealed to the pipette tip, can be torn away, and the channels inside the
membrane piece can be studied electrically and pharmacologically. Patch-clamp
experiments performed in the in vitro slice preparation have provided unprece-
dented details about the active properties of neurons and important insights into
the mechanisms of network oscillations.23
Extracellular Recordings from Single Neurons
Because action potentials produce large transmembrane potentials in the vicinity
of the cell body, the occurrence of the spike can be sensed by a conductive micro-
electrode positioned near the cell body of the neuron by means of a precision me-
chanical drive. The voltage-sensing microelectrode, in essence, is a very sharp
insect pin, insulated except for the last few micrometers of the tip. The closer the
recording tip is to the neuron, the louder one can hear the action potentials, pro-
vided that the ampliﬁed voltage is connected to a loudspeaker. With some maneu-
vering by a mechanical micromanipulator device, the signal can be maximized so
that one neuron’s “voice” stands out from the others, a procedure called cell “iso-
lation.”24 If other active (spiking) neurons are in the vicinity of the tip, the elec-
trode records from all of them. Because neurons of the same class generate
virtually identical action potentials, the only way to identify a given neuron from

Windows on the Brain     
99
25. Willem Einthoven, whose string galvanometer was used to detect EEG signals by Berger,
worked out the ﬁrst diagnostic rules of heart signals on the basis of triangulation. The Einthoven tri-
angle is an imaginary equilateral triangle with the heart at its center, its equal sides representing the
three standard limb leads of the electrocardiogram (see ﬁgure 4.6, top right). In the electrocardiogram,
at any given instant the potential of any wave between two limbs is equal to the sum of the potentials
in leads obtained from the other limbs.
26. McNaughton et al. (1983a) and Gray et al. (1995). The tetrode catapulted into its present fame
after Wilson and McNaughton (1993) recorded from more than 100 neurons in a freely moving rat, us-
ing 12 movable tetrodes.
extracellularly recorded spikes is to move the electrode tip closer to its body (< 20
micrometers in cortex) than to any other neuron. The much larger spike from the
closest cell, relative to the spikes of more distant neurons, is often sufﬁcient to re-
liably monitor the output of a single cell. However, being very close to a neuronal
membrane with a sharp tip can be dangerous. Very small movements of the brain,
due to pulsation of the vessels, breathing-related shifts, or head position changes
can affect the relationship between the electrode tip and the neuron. The neuron is
easily injured, and perturbation of its immediate environment can affect its ﬁring
pattern. To record from another neuron with certainty, yet another electrode is
needed.
Triangulation of Neurons by Tetrodes
Triangulation of biological voltage sources began with the studies of the heart,
and the triangulation method has remained a routine method in the evaluation of
the electrocardiogram (EKG). The heart is massively connected torus of muscle
cells and produces a huge electrical signal (in the millivolt range) compared to the
brain. Created by placing just four electrodes on the left foot, right and left arms,
and chest, the heart “tetrode” is a pretty efﬁcient routine clinical tool for the lo-
calization of the anatomical sources of the components of the EKG (ﬁgure 4.6).
For more precise localization, many more electrodes are used.25 The triangulation
method, of course, should work for the localization of any stationary dipole, in-
cluding action potentials generated by neurons. The idea of triangulation for neu-
ron separation was ﬁrst introduced by John O’Keefe and Bruce McNaughton, at
University College, London. Their ﬁrst sensor consisted of two 25-micrometer-
long insulated wires twisted together, ﬁttingly called the “stereotrode,” followed
by the four-wire version called a “tetrode” (ﬁgure 4.6, bottom).26 A typical tetrode
consists of four thin wires (12–15 micrometers in diameter each) glued together
in a bundle. With only one electrode tip, signals from many neurons that are lo-
cated at the same distance from the tip in a sphere provide similar amplitude
spikes, making single-cell isolation difﬁcult. Thus, we may hear and see many
neurons, but we cannot tell them apart. With two closely spaced electrodes, the
ambiguity can be decreased to neurons in a plane, and with three electrodes to
neurons sitting in a line. If a fourth electrode is placed in different plane from the

Figure 4.6. Source localization by triangulation. For determining the heart’s electrical
axis, voltage measurements are made between the right and left arms, right arm and left
leg, and left arm and left leg (top right). Photograph (top left) illustrates Willem
Einthoven’s “electrodes”: the subject places an arm and a leg in salt water connected to a
galvanometer. From the voltage deﬂections in each measurement, the voltage vector can be
calculated. Bottom: Triangulation of the three-dimensional position of neurons by
“tetrode” measurements. The voltage differences between the wires of the tetrodes of the
recorded spikes from individual neurons allow the calculation of the unique position of
each neuron. Modiﬁed, with permission, from Buzsáki (2004).
100

Windows on the Brain     
101
27. Henze et al. (2000a) determined the relationship between the distance of the extracellular elec-
trode from the spiking neuron and the amplitude of the recorded spikes by monitoring the same neu-
rons both intracellularly and extracellularly in the intact hippocampus. For modeling extracellular
spike waveforms, see Gold et al. (2005). A concise overview of the extracellular recording methods is
Nádasdy et al. (1998).
other three, the spatial position of each neuron in the line, in principle, can be sep-
arated by triangulation.
Wire tetrodes have numerous advantages over sharp-tip single electrodes.
First, they provide recording stability. The thin wires are ﬂexible and can move
together with the brain to some extent. This is why recordings of neurons in
deeper structures are more stable than those of neurons in, for example, the su-
perﬁcial layers of the cortex. Because the recording tip need not be placed in the
immediate vicinity of the neuron, small movements of the tetrode are not as detri-
mental as would be the case of a sharp tip touching the neuron. Tetrodes are espe-
cially useful in areas with a high packing density of neurons, where isolation of
individual neurons from nearby peers is difﬁcult with single wires. Under ideal
conditions, a tetrode can record up to 20 well-isolated neurons.
Cortical pyramidal cells generate extracellular ﬁelds that ﬂow mostly parallel
to their somadendritic axis. For this reason, the action potentials can be detected
several hundred micrometers from the soma, in the proximity of thick apical den-
drites. The lateral spread of current is more restricted. Nevertheless, tetrodes can
“hear” pyramidal cells as far away as 140 micrometers lateral to the cell body, al-
though the extracellular spike amplitude decreases rapidly as a function of dis-
tance from the neuron. A cylinder with a radius of 140 micrometers contains
approximately 1,000 neurons in the rat cortex, which is therefore the upper limit
of the theoretically recordable cells by a single electrode. Yet, in practice, only a
small fraction of these neurons can be reliably separated (up to 20 neurons under
ideal conditions).27 The remaining neurons may be damaged by the blunt end of
the closely spaced wires or remain undetected with currently available spike-
sorting algorithms. Thus, there is a large gap between the number of routinely
recorded and theoretically recordable neurons. To monitor another dozen or so
neurons, another tetrode is needed. Because inserting wires in the brain is an in-
vasive procedure, recording from large numbers of neurons is possible only at the
expense of extensive cell damage.
High-Density Recordings with Silicon Probes
An ideal recording electrode has a very small volume, so that tissue injury is min-
imized. On the other hand, recording from many neurons with wire electrodes re-
quires large numbers of wires with consequent tissue damage. Obviously, these
competing requirements are difﬁcult to meet. A wire electrode has only one use-
ful site, the conductive tip; the rest is just conduit and inconvenient bulk. To in-
crease the number of useful recording sites without increasing the volume of the

102
RHYTHMS OF THE BRAIN
Figure 4.7. Functional connectivity within local microcircuits of the somatosensory cor-
tex of the rat. Synaptic connections between participating pyramidal cells (triangles) and
putative interneurons (circles) can be determined by their temporal relationship. For exam-
ple, decreased discharge of a partner neuron immediately after the spike of the reference
cell (time zero in the upper white histogram) reveals the inhibitory nature of the reference
neuron. Conversely, a consistent, short-latency discharge of the partner neuron after the
reference spike (lower histogram) indicates the excitatory nature of the reference cell.
Modiﬁed, with permission, from Barthó et al. (2004).
28. Wise and Najaﬁ(1991). A major advantage of silicon probes is that with integrated chip tech-
nology virtually any two- and even three-dimensional arrays can be fabricated, which is a highly de-
sirable feature for the exploration of local networks. In addition to recording from multiple sites,
silicon electrodes can use on-chip ampliﬁcation, ﬁltering, and time-division multiplexing as well as
programmed microstimulation through the recording sites and, potentially, real-time signal processing
(Olsson et al., 2005). Such a brain–chip interface may allow for reciprocal interactions with the brain,
paving the way for fully implantable neural prosthetic devices.
electrode, Kensall Wise at the University of Michigan devised multisite recording
probes, using silicon “chip” technology. These microelectromechanical system
(MEMS)–based recording devices can reduce the technical limitations inherent in
wire electrodes because with the same amount of tissue displacement, the number
of monitoring sites can be substantially increased. These silicon devices share the
advantages of tetrode recording principles, yet they are substantially smaller in
size. At the current level of development, multishank silicon probes can record
from as many as 100 well-separated neurons. Importantly, the geometrically pre-
cise distribution of the recording sites also allows for determination of the spatial
relationship and the functional connectedness of the isolated single neurons (ﬁg-
ure 4.7). This feature is a prerequisite for studying the spatiotemporal representa-
tion and transformation of inputs by neuronal ensembles.28

Windows on the Brain     
103
29. The spike amplitude variation is most substantial during complex spike-burst production,
when the amplitude of the extracellular spikes may decrease as much as 80 percent, associated with
changes in other waveform parameters.
30. The amplitude and waveform variability of the extracellularly recorded spike is the major
cause of unit isolation errors. Triangulation methods visually analyze two-dimensionally projected
datasets one at a time. With multisite-recorded data, successive comparisons of the various possible
projections generate cumulative errors of human judgment. Cumulative human errors can be reduced
Isolation and Identiﬁcation of Neurons by 
Extracellular Signatures
An indispensable step in spike-train analysis is the isolation of single neurons on
the basis of extracellular features. Spike-sorting methods fall into two broad
classes. The ﬁrst class attempts to separate spikes on the basis of amplitude and
waveform variation, on the assumption that neighboring neurons generate distinct
spike features. This assumption is difﬁcult to justify in most cases because similar
neurons at similar distances from the recording electrode tip generate nearly iden-
tical waveforms. As a result, these neurons may be inadvertently combined as if
the spikes were generated from a single neuron. The converse problem also oc-
curs: the same neuron can generate different waveforms, depending on ﬁring
rates, the magnitude of somadendritic propagation of spikes, and activation of
various channels in different states. The consequence of these wave shape varia-
tions is that spikes generated by the same neuron under different conditions will
be classiﬁed by the wave shape discrimination method as if the spikes with differ-
ent forms emanated from different cells.
The second general approach, the triangulation method discussed above, is
based on the tacit assumption that the extracellularly recorded spikes emanate
from point sources rather than the complex geometry of neurons. This is obvi-
ously a simplistic notion, because every part of the neuronal membrane is capable
of generating action potentials. The extent of the somadendritic back-propagation
of the action potential varies as a function of the excitatory and inhibitory inputs
impinging on the neuron. Because the extracellular spike is a summation of the
integrated signals from both soma and large proximal dendrites, the extracellu-
larly recorded spike parameters depend on the extent of spike back-propagation
and on other state- and behavior-dependent changes of the membrane potential.
These changes can affect the estimation of the neuron’s virtual “point source” lo-
cation and may place the same neuron at different locations, resulting in errors of
spike assignment to neurons.29 Another problem with the point-source assump-
tion for action potentials is that the somatic origin is not always resolvable with
distant recording sites. For example, in the neocortex, extracellular spikes can be
recorded from the large apical shaft of layer 5 pyramidal neurons as far as 500
micrometers from the cell body. As a consequence, a single electrode tip, placed,
for example, in layer 4, can record equally well from layer 4 cell bodies or apical
dendrites of deeper neurons. These sources of unit sorting errors can be reduced
by recording at multiple sites, using silicon probes, placed parallel to the axoden-
dritic axis of the neurons.30

104
RHYTHMS OF THE BRAIN
by semiautomatic clustering methods of high-dimensional data. A further difﬁculty is that no indepen-
dent criteria are available for the assessment of omission and commission errors of unit isolation. As
a result, improvement of spike-sorting algorithms is not guided by objective measures. In the absence
of quantitative criteria for unit isolation quality, interlaboratory comparison is difﬁcult and is often a
source for the controversy in data interpretation. This area of research can strongly beneﬁt from future
technical improvements (Henze et al., 2000a; Barthó et al., 2004; Buzsáki, 2004).
31. The combination of the various technical approaches proved successful for the classiﬁcation of
some interneuron classes in the hippocampus (Csicsvari et al., 1999; Klausberger et al., 2003, 2004).
Separation of Neuronal Classes
Because brain networks consist of several neuronal classes, each with a speciﬁc
computation task, their separation on the basis of extracellular features is highly
desirable. Several features of the extracellular spikes may assist with this process,
including spike duration, ﬁring rate and pattern, spike waveform, and the relation-
ship to network patterns. In the cortex, the most important step is the separation
of pyramidal cells and inhibitory interneurons. This step, in itself, is difﬁcult, and
progress depends on the successful combination of extracellular and intracellular
or other anatomical labeling methods that allow veriﬁcation of the recorded neu-
ron types. Separation of the different principal and inhibitory neuronal subclasses
is a further challenge but a necessary requirement for the understanding and in-
terpretation of assembly cooperation.31
Analyses of Brain Signals
Because neuronal signals have two fundamental appearances, the continuous
membrane potential and ﬁeld potentials (or analog signals) and the discrete (or
digital) action potentials, their analyses require a combination of methods appli-
cable for both continuous and point processes. Irrespective of the nature of the
observed signal, brain activity has multiple frequencies and evolves over time.
Therefore, the most appropriate method for analyzing brain signals would be a
“time–frequency analysis” algorithm that would provide a perfect description of
changes in all frequencies as a function of time. However, frequency and time
cannot be mixed; mathematically speaking, they are orthogonal. The implication
is that there is no concept of time in the frequency domain, and conversely, there
is no concept of frequency in the time domain. This counterintuitive relationship
explains why the two major classes of analytical tools that are used for the analy-
ses of brain signals are called “frequency domain” and “time domain” methods.
Suppose that we would like to “analyze” speech without knowing what infor-
mation we are exactly looking for. One approach can characterize the distribution
of frequencies in spoken speech. Because consonants and vowels are composed of
characteristic constellations of frequencies, and because the probability distribu-
tion of the individual consonants and vowels in language is quite different, some
frequencies will dominate the speech frequency landscape. To make sure that all

Windows on the Brain     
105
32. Jean Baptiste Joseph Fourier was as impatient as any self-respecting young scientist. In a letter
that he sent together with a paper on algebra to C. Bonard, he complained: “Yesterday was my 21st
birthday; at that age Newton and Pascal had already acquired many claims to immortality.” Fourier’s
immortal fame is mainly due to the method he introduced, the Fourier transform, which expresses a
waveform as a weighted sum of sines and cosines. In essence, it decomposes or separates a waveform
or function into sinusoids of different frequencies that sum to the original waveform. It identiﬁes or dis-
tinguishes the different frequency sinusoids and their respective amplitudes. The Fourier transform of
the autocorrelation function is the power spectrum and is illustrated by a plot of P( f) as a function of f.
33. The temporal resolution of the serial Fourier transform display assumes that the selected seg-
ments are stationary. E.g., when low frequencies are also of interest (e.g., 1 hertz), then the temporal
window of analysis must be slow enough (> 2×1 second). For a short overview of spectral methods of
EEG signals, see Muthuswamy and Thakor (1998).
sounds are sampled representatively, long epochs are needed for the analysis.
Alternatively, we can pick a characteristic frequency distribution pattern, deter-
mined in a short time epoch, and examine its distribution over time. Obviously,
neither method alone can reveal the information-encoding scheme of speech. A
frequency domain graph shows only how much of the signal lies within each given
frequency band over a range of frequencies, whereas a time domain display shows
only how a piece of the signal changes over time. EEG, MEG, and even spike-train
signals have both time- and frequency-domain representations that are not funda-
mentally different from the example of speech. Understanding the coding ability
of time-evolving neuronal signals, therefore, also requires appropriate methods.
Because brain signals contain multiple frequency components, their relation-
ship can be quantiﬁed using frequency domain methods. The complex EEG or
MEG waveform can be reproduced by an appropriate combination of sine waves.
This method is similar to the trick used by electronic synthesizers that can make
convincing acoustical forgeries of everything from trombones to harps. It is done
by a mathematical process called Fourier synthesis, named after the French math-
ematician Joseph Fourier.32 The reverse process, called Fourier analysis, takes the
complex EEG or MEG signal and decomposes it into the sine waves that make it
up. After the signal is decomposed into sine waves, a compressed representation
of the relative dominance of the various frequencies can be constructed. This fre-
quency versus incidence illustration is known as the power spectrum. The Fourier
method transforms the signal, deﬁned in the time domain, into one deﬁned in the
frequency domain. Although this representation ignores the temporal variation of
the EEG signal, it provides a quantitative answer regarding the power relationship
between the frequencies.
Determining the frequency from any continuous pattern requires making mea-
surements of time intervals before doing any calculation. However, in complex
waveforms such as the EEG, where multiple frequencies are simultaneously pres-
ent, it is often unclear where the intervals to be measured begin and end, that is,
where the analyzed epochs should be. The theory of Fourier transform assumes
that the signal is analyzed over all time—an inﬁnite duration. This restriction sug-
gests that the standard Fourier analysis is not well suited to describing time-
transient changes in “frequency content” because the frequency components
deﬁned by the Fourier transform require inﬁnite time support.33

106
RHYTHMS OF THE BRAIN
A practical “solution” to the time versus frequency orthogonality issue is the
short-time Fourier transform, which attempts to quantify the frequency content
changes over time. In this modiﬁed analysis, the brain signal is divided into mul-
tiple short epochs, and the Fourier transform is calculated for each epoch. The
successive spectra can display the evolution of frequency content with time.
The short-time Fourier transform can be viewed as a compromise of joint
time–frequency analysis. The use of a wide temporal window will give good fre-
quency resolution but poor time resolution, whereas the use of a narrow window
will give good time resolution but poor frequency resolution. Accepting this com-
promise, these modiﬁed methods can analyze sequential short epochs, and the
frequency structure can be displayed as a function of time (ﬁgure 4.8).
Another popular way of analyzing short-time segments of selected EEG pat-
terns is called “wavelet” analysis. The wave refers to the fact that this function is
Figure 4.8. Frequency spectral dynamics of an EEG. Top: Gray-scale–coded power of
neocortical local ﬁeld potential in the rat during REM (rapid eye movement) sleep, slow
wave sleep, and waking exploration. Arrows indicate volume-conducted theta frequency
(7–9 hertz) oscillation from the underlying hippocampus. Bottom: Fourier spectra of
lumped epochs. The asterisk indicates the power peak in the sleep spindle band (12–18
hertz). Note the distinct theta and gamma (40–90 hertz) frequency power increase during
REM sleep and waking. The spectra have been “whitened” by removing the 1/f correlated
power (see Cycle 5 for explanation of this term). LFP, local ﬁeld potential. Figure courtesy
of Anton Sirota.

Windows on the Brain     
107
34. Wavelet transforms are broadly classiﬁed into the discrete wavelet transform and the continu-
ous wavelet transform. The discrete transform uses a speciﬁc subset of all scale and translation values,
whereas the continuous transform operates over every possible scale and translation.
35. “The wavelet transform replaces one single, poorly behaved time series with a collection of
much better behaved sequences amenable to standard statistical tools” (Percival and Warden, 2000).
Although both wavelet and Hilbert transformation methods have become widely used recently, these
methods are formally (i.e., mathematically) identical with the Fourier transform (Bruns, 2004).
oscillatory; the diminutive form refers to the fact that this (window) function is of
ﬁnite length or a fast-decaying, oscillating waveform. The wavelet transform
refers to the representation of a signal in terms of a ﬁnite length. Rather than ana-
lyzing the distribution of all frequencies, the wavelet transform ﬁrst selects a “fre-
quency of interest.”34 Any arbitrary waveform can serve as a “prototype” whose
consistent appearance can be quantiﬁed. Therefore, all wavelet transforms may be
considered to be forms of time–frequency representation.35
Analysis in the time domain is usually performed by temporal correlation
functions. Correlating a signal with itself is called autocorrelation, which can re-
veal repetitive components in the signal. Because different sorts of signals have
distinctly different autocorrelation functions, these functions can be used to tell
signals apart. For example, random noise is deﬁned as uncorrelated because it is
similar only to itself, and any small amount of temporal shift results in no corre-
lation with the unshifted signal at all. In contrast, oscillating signals go in and out
of phase when shifted in time. The autocorrelation function of a periodic signal is
itself a periodic signal, with a period identical to the original signal. Therefore,
autocorrelation is an effective method for revealing periodic function in a signal.
Correlation methods are also often used to assess the similarity between two sig-
nals. When two signals are similar in shape and are in phase (i.e., “unshifted”
with respect to each other), their correlation is positive and maximum. The same
signals out of phase will provide a negative maximum correlation. As one signal
is shifted with respect to the other and the signals go out of phase, the correlation
decreases. Correlating a signal with another, that is, computing their cross-
correlation, is a powerful method for detecting a known reference signal in noise
or the directional connectedness of neuron pairs (ﬁgure 4.7).
Forms of Oscillatory Synchrony
There are numerous ways to affect oscillators, and the mechanisms that modify
them do not even have a standardized taxonomy. Some of the terms have agreed
mechanisms within one discipline but are used differently in another. Here are
deﬁnitions of a few terms as they are used in neuroscience and in the neurocom-
putation literature. Mutual entrainment refers to a measure of stability of two or
more oscillators that they would not have on their own. Mutual feedback is the
key to entrainment of oscillators of various frequencies and stabilities. For exam-
ple, when multiple single-cell oscillators with different intrinsic frequencies are

108
RHYTHMS OF THE BRAIN
Figure 4.9. Collective synchronization of multiple oscillators. The state of each oscillator
is represented as a dot in the complex plane. The amplitude and phase of the oscillation
correspond to the radius and angle of the dot in polar coordinates. Gray scale codes the os-
cillators’ natural frequencies. In the absence of coupling, each oscillator would settle onto
its limit cycle (circle) and rotate at its natural frequency. Starting from a random initial
condition, the oscillators self-organize by adjusting their amplitudes and are pulled toward
the mean ﬁeld (asterisk) that they generate collectively; then, they sort their phases so that
the fastest oscillators are in the lead. Ultimately, they all rotate as a synchronized pack,
with locked amplitudes and phases. Reprinted, with permission, from Strogatz (2001).
36. Coherence is a measure of phase covariance, which is quantiﬁed as the cross-spectrum of two
signals divided by the product of the two autospectra. Because it measures spectral covariance, it can-
not reliably separate amplitude and phase contributions. Phase-locking statistics can quantify phase
coherence between two signals independent of the amplitudes of the respective signals (Lachaux et al.,
1999).
37. For statistical methods of phase-locking, see Hurtado et al. (2004).
connected together, they may produce a common intermediate global frequency.
This is not a simply linear sum of the frequencies because in the functionally
connected scheme each neuron ﬁres phase-locked to the global rhythm. If one
generator temporally exceeds the common tempo, the others absorb the excess,
forcing it to slow down. Conversely, if it falls below the population rhythm, the
other oscillators “pull” it back so that it catches up. The emergent population
rhythm enslaves or supervenes the behavior of individual units (ﬁgure 4.9).
Coherence is the measure of the state in which two signals maintain a ﬁxed
phase relationship with each other or with a third signal that serves as a reference
for each.36 The phase differences are often used to infer the direction of the force,
although in most cases such inference is not possible.
Phase-locking refers to the mutual interaction among oscillators by which the
phase difference between any two oscillators is ﬁxed. This measure is indepen-
dent of the amplitude changes.37 Phase-locking or phase-coupling can occur be-
tween oscillatory and nonoscillatory events as well, such as phase-locked

Windows on the Brain     
109
38. In addition, physics describes a variety of dynamical synchronization phenomena that may
have relevance to neuronal networks, including splay-phase states, collective chaotic behavior, attrac-
tor crowding, clustering, frequency locking, dephasing, and bursting (Tass, 1999).
discharge of irregularly spiking neuron and an oscillator. Often, the term entrain-
ment is used for such cases.
Cross-frequency phase synchrony can occur between two or more oscillators
of different integer frequencies, when the oscillators are phase-locked at multiple
cycles. If two oscillators differ in frequency and cannot ﬁx their phases, they nev-
ertheless can produce a transient and systematic interaction, called phase preces-
sion or phase retardation.
Phase reset of one or many coupled or independent oscillators can occur if a
punctuate input forces to restart the oscillator(s) at the same phase. A related phe-
nomenon but one involving different mechanisms, is phase synchronization, a
stimulus-induced oscillation in two or more structures with transient coherent phase.
Phase modulation of power occurs between a slower and faster rhythm, where the
power of the faster oscillator varies as a function of phase of the slower oscillator.
Induced rhythms at two or multiple locations can be brought about with or
without phase synchrony by a slowly changing input. Even if the oscillators are
not coherent with each other, their power can be comodulated. This is sometimes
referred to as amplitude envelope correlation, since the integrated envelopes of
the signals are compared. It conveniently allows comparison of the amplitudes of
any frequency band. Large-frequency mismatch or strong coupling can lead to os-
cillation death or quenching. This short list of terms is far from exhaustive but
sufﬁcient for the understanding of most of the oscillatory phenomena discussed in
this volume.38
Naive wisdom would demand that one should use all methods described in this
Cycle, in all possible combinations and in every experiment to get the best result.
However, no serious mentor would provide such foolish advice to a student. The
reason is that each of these techniques is very complex, and a thorough understand-
ing of each requires several years of hard work and study. Furthermore, simultane-
ous application of multiple methods is often detrimental for various technical
reasons. So when it comes to the important question of choosing the best method
for understanding the brain, I pass along the advice I learned from my professor of
pathology György Romhányi: “The best method for investigating any issue is your
method.” Choose one or two or three methods and learn all their pitfalls and virtues
so you can interpret your data better than anyone else. There is no “best” method.
Brieﬂy . . .
Because the brain is organized at multiple temporal and spatial levels, monitoring
brain activity requires methods with appropriate resolutions. To date, only a hand-
ful of recording methods are available, and none of them has the ability to “see”

110
RHYTHMS OF THE BRAIN
simultaneously small and large areas at the temporal resolution of neuronal activ-
ity. 
Field potential analysis (EEG and MEG), imaging of energy production in
brain structures (fMRI), optical recording methods, and single-cell recording
techniques are the principal techniques in contemporary cognitive-behavioral
neuroscience for the study of the intact brain. Unfortunately, even their com-
bined, simultaneous application in behaving subjects falls short of the goal of
explaining how a coalition of neuronal groups generates representations of the
environments and creates appropriate responses in a changing environment. In
the brain, speciﬁc behaviors emerge from the interaction of its constituents, neu-
rons and neuronal pools. Studying these self-organized processes requires the si-
multaneously monitoring of the activity of large numbers of individual neurons
in multiple brain areas. Development of large-scale recording from multiple sin-
gle neurons with tetrodes or silicon probes is an attempt in this direction. How-
ever, these methods are invasive and cannot be used for the investigation of the
healthy human brain. Many other methods, such as pharmacological manipula-
tions, macroscopic and microscopic imaging, and molecular biological tools, can
provide insights into the operations of the brain, but in the end all these indirect
observations should be reconverted into the format of neuronal spike trains to
understand the brain’s control of behavior.

Cycle 55
A System of Rhythms: From Simple to
Complex Dynamics
Ts’ui Pen . . . did not think of time as absolute and uniform. He believed in an
inﬁnite series of times, in a dizzily growing, ever spreading network of di-
verging, converging and parallel times. This web of time—the strands of
which approach one another, bifurcate, intersect, or ignore each other . . .—
embraces every possibility.
—Jorge Luis Borges, “The Garden of Forking Paths”
111
Neurons and connections of the brain support and limit its self-generated, sponta-
neous order even in the absence of sensory inputs or motor outputs. As described
in Cycles 2 and 3, its structural organization supports a high complexity of wiring
architecture. However, not all neurons and connections are used all the time.
Quite the contrary, only a small fraction of the rich possibilities are chosen at any
one moment. The dynamically changing functional or effective connectivity gives
rise to short-lived oscillations that are perpetually created and destroyed by the
brain’s internal dynamics. The central tenet of this Cycle, which is echoed
throughout the book, is that brain dynamics constantly shift from the complex to
the predictable.1 Neuronal ensemble activities shuttle back and forth between the
interference-prone complexity and robust predictable oscillatory synchrony. As I
explain in this Cycle, this switching behavior is the most efﬁcient way for the
brain to detect changes in the body and the surrounding physical world, while
preserving its autonomous internal organization.
1. Karl Friston emphasized the importance of short-lived transients in his “labile brain” series (Fris-
ton, 2000). According to Friston, brain dynamics move from a stable incoherence through dynamic insta-
bility to complete entrainment. A similar idea is echoed by the chaotic organization of Walter Freeman’s
“wave packets” (Freeman and Rogers, 2002; Freeman et al., 2003) and the “neural moment” of transient
synchrony of Hopﬁeld and Brody (2001). It is not clear, though, how stable incoherence (high entropy)
can be maintained in an interconnected system, e.g., the brain. As Sporns et al. (2000a, b, 2002) have
pointed out, high-complexity and high-entropy conditions require very different architectures.

112
RHYTHMS OF THE BRAIN
2. The ﬁrst comprehensive review on the subject is Katz and Cracco (1971).
3. See International Federation of Societies for Electroencephalography and Clinical Neurophysi-
ology (1974) and Steriade et al. (1990a).
4. Komisaruk (1970) has already suggested that the different brain and body oscillators are cou-
pled by some mechanisms, but he assumed an integer phase-locked relationship between them.
How Many Brain Oscillators?
Since the seminal discoveries of Hans Berger (Cycle 1), oscillations have been
documented in the brains of numerous mammalian species, ranging from very
slow oscillations with periods of minutes to very fast oscillations with frequencies
reaching 600 hertz.2 Somewhat surprisingly, a functionally meaningful taxonomy
of brain rhythms has not emerged until recently. The ﬁrst classiﬁcation, intro-
duced by the experts of the International Federation of Societies for Electroen-
cephalography and Clinical Neurophysiology in 1974, was driven by pragmatic
clinical considerations.3 Following Berger’s tradition, the subsequently discov-
ered frequency bands were labeled with Greek letters, and the borders between
the different bands were evenly and arbitrarily drawn (delta, 0.5–4 hertz; theta,
4–8 hertz; alpha, 8–12 hertz; beta, 12–30 hertz; gamma,>30 hertz), like the
straight-line country borders between the African nations drawn by the colonial-
ists. The frequency border classiﬁcation was done out of necessity, since the
mechanisms and independence of the various oscillatory patterns were largely
unknown at that time. The frequency coverage of the classiﬁed bands was con-
ﬁned by the EEG recording technology. The widely used mechanical pen
recorders limited the upper border of frequencies, whereas electrode polarization
and movement artifacts prevented routine observations at low frequencies. Thus,
frequency bands below 0.5 hertz were not included or given names. Although the
international classiﬁcation of brain frequency bands continues to be of practical
importance, its major disadvantage is its self-limitation. Rhythms generated by
the same physiological machinery at different ages or in different species often
fall into different bands with different names. For example, the hippocampal theta
oscillation was discovered in the anesthetized rabbit, and because of its frequency
coverage (2–6 hertz), the name “theta” was given. However, in the drug-free ro-
dent, hippocampal theta should be designated theta-alpha, according to the com-
mittee’s recommendation, since it varies between 5 and 10 hertz.
A useful taxonomy of brain oscillations would require that the individual oscilla-
tory classes represent physiological entities that are generated by distinct mecha-
nisms. The same mechanism giving rise to different frequency bands in different
species or the same frequency bands in different states (e.g., sleep/awake, anesthe-
sia) of the same species ought to be referred to by the same name, even though the
dynamics underlying the rhythms may be different. Unfortunately, the exact mecha-
nisms of most brain oscillations are not known. As an alternative approach, Markku
Penttonen, a postdoctoral fellow in my lab, and I speculated that there might
be some deﬁnable relationship among the various brain oscillators.4 Penttonen

A System of Rhythms
113
5. Our strategy of taxonomic classiﬁcation of brain rhythms followed the tactic used by Dmitri
Mendeleev for his construction of the periodic chart of elements. In 1860, Mendeleev attended the
First International Chemical Congress in Karlsruhe, Germany, where the leading chemists of the day
gathered to sort out contradictory lists of atomic and molecular weights. They left for home with un-
ﬁnished business. However, the 34-year-old Mendeleev left the meeting with a grand research project
in his mind: ﬁnd a meaningful system among the known elements. Playing a jigsaw puzzle with the el-
ements for nine years did not yield results. Yet, one night in sleep, “I saw in a dream a table where all
the elements fell into place as required,” remembered Mendeleev (Strathern, 2000). His taxonomy
provided organization to inorganic chemistry.
6. Buzsáki et al. (1992), Penttonen and Buzsáki (2003), and Buzsáki and Draguhn (2004).
7. The described system of oscillators is characteristic of the cerebral cortex only. Most other
brain areas can support only limited types of oscillations.
reasoned that, if we found a quantiﬁable relationship among the well-documented
few, perhaps we could make some predictions about the less-known ones.5
We began by looking at the relationship among three hippocampal rhythms
observed in the rat: theta (4–10 hertz) and gamma (30–80 hertz) rhythms and a
fast oscillation (140–200 hertz).6 These rhythms are independently generated, be-
cause we have already observed that gamma oscillations persist without theta and
compete with the fast oscillation. Beginning with these three rhythms, we tried to
interpolate and extrapolate other classes and relate them to each other. We found
the best ﬁt based on a natural logarithmic scale. Using the mean frequencies of
our initially identiﬁed rhythms, the mean frequencies of other oscillation classes
were estimated. The predicted frequencies corresponded to the traditional beta
and delta bands as well as to less-known slow oscillations that we designated slow
1, slow 2, slow 3, and slow 4. By plotting the frequency bands in increasing order
of frequency, a general principle emerged: discrete oscillation bands formed a
geometric progression on a linear frequency scale and a linear progression on a
natural logarithmic scale (ﬁgure 5.1, bottom).7 This simple graph allowed us to
make some fundamental statements about brain oscillators. First, all frequencies
from 0.02 hertz to 600 hertz are continuously present, covering more than four
orders of magnitude of temporal scale. Second, at least 10 postulated distinct
mechanisms are required to cover the large frequency range. Third, because a sin-
gle structure does not normally generate all oscillatory classes, structures must
cooperate to cover all frequencies. Different mechanisms in different brain struc-
tures can give rise to the same oscillatory band, but there should be at least one
distinct mechanism for each oscillation class. Fourth, and perhaps most impor-
tant, there is a deﬁnable relationship among all brain oscillators: a geometrical
progression of mean frequencies from band to band with a roughly constant ratio
of e, 2.17—the base for the natural (Napierian) logarithm. Since e is an irrational
number, the phase of coupled oscillators of the various bands will vary on each
cycle forever, resulting in a nonrepeating, quasi-periodic or weakly chaotic pat-
tern: this is the main characteristic of the EEG.
All of this raises important questions: why are there so many oscillators? Why
can the brain not use a single, ﬁxed-frequency clock for all of its functions? There
are multiple answers to these questions. Behavior occurs in time, and precise tim-

114
RHYTHMS OF THE BRAIN
ing from fractions of a second to several seconds is necessary for successful pre-
diction of changes in the physical environment and for the coordination of muscles
and sensory detectors in anticipation of environmental events. In principle, multi-
ple tasks can be managed by a precise, single, fast clock and time division, as is
seen in digital computers. Perhaps a de novo design of the mammalian brain would
choose this solution. However, for sponges and other simple animals at early
stages of evolution, fast responding was not a requisite for survival. All that is
needed in these simple creatures is slow rhythmic movements for providing food
frequency (Hz)
Classes
Power
0.05
4 3 2 1
0
0
0.5
0
0.5
1.5
1
1
2
200-600 Hz, ultra fast
80-200 Hz, fast
3
4
5
6 lnHz
1
2
3
In frequency (Hz)
4
5
6
0.37
2.72
20.09
148.41
30-80 Hz, gamma
10-30 Hz, beta
4-10 Hz, theta
1.5-4 Hz, delta
0.7-2 s, slow 1
2-5 s, slow 2
5-15 s, slow 3
15-40 s, slow 4
Figure 5.1. Multiple oscillators form a hierarchical system in the cerebral cortex. Top:
Power spectrum of hippocampal EEG in the mouse recorded during sleep and waking peri-
ods. Note that the four peaks, corresponding to the traditional delta, theta, gamma, and fast
(“ripple”) bands, are multiples of natural log integer values. Bottom: Oscillatory classes in
the cerebral cortex show a linear progression of the frequency classes on the log scale. In
each class, the frequency ranges (“bandwidth”) overlap with those of the neighboring
classes so that frequency coverage is more than four orders of magnitude. The power spec-
trum was “whitened” by removing the log slope dominating the typical EEG spectrum (e.g.,
ﬁgure 5.2). Modiﬁed, with permission, from Penttonen and Buzsáki (2003).

A System of Rhythms
115
8. A nice example is category learning (McClelland et al., 1995).
9. It was perhaps William James (1890) who ﬁrst pointed to the segmentation of experience:
The unit of composition of our perception of time is a duration, with a bow and a stern, as it
were—a rearward- and a forward-looking end. It is only as parts of this duration-block that the
relation of succession of one end to the other is perceived. We do not ﬁrst feel one end and then
feel the other after it, and from the perception of the succession infer an interval of time be-
tween, but we seem to feel the interval of time as a whole, with its two ends embedded in it.
(p. 609)
James’s observer is at an instant but embedded in the stretched time of the mind.
intake. Once a slow oscillator was invented, faster ones could be added as needed
in subsequent evolutionary stages. New inventions of evolution are always built on
the back of previously useful functions. Another argument for not using a single
fast clock has to do with the wiring of the brain and the way neurons communi-
cate with each other. Although action potentials, the digital means for communi-
cation between neurons, propagate in nerves innervating muscles relatively
quickly (tens of meters per second), most axon collaterals in the brain are fairly
slowly conducting (from centimeters up to a few meters per second). This slug-
gishness likely reﬂects an economical compromise of evolution between size and
speed. Thicker axons conduct faster but occupy more space. But saving space
comes with a price. For instance, informing multiple postsynaptic targets, located
between 0.5 millimeter and 5 millimeters, of a single neuron may take 1 and 10
milliseconds, respectively; an order of magnitude time difference between the
most proximal and most distant target! This problem becomes progressively
larger when more complex events are represented in increasingly large neuronal
ensembles. Oftentimes, the cooperative activities of hundreds of neurons are
needed to discharge their postsynaptic target. The arrival times of action poten-
tials from such a large number of sources must be coordinated in time to exert an
impact. Recognizing somebody’s face and recalling her ﬁrst and last names, her
profession, our last meeting, and our common friends are events that do not occur
simultaneously but are protracted in time, since larger and larger neuronal loops
must become engaged in the process. A number of psychological phenomena ar-
gue in favor of the idea that these cognitive events require hierarchical pro-
cessing.8 Separate processing requires the engagement of neuronal networks at
multiple spatial scales.
Each oscillatory cycle is a temporal processing window, signaling the begin-
ning and termination of the encoded or transferred messages, analogous to the be-
ginning and end signals of the genetic code. In other words, the brain does not
operate continuously but discontiguously, using temporal packages or quanta.9
Designers of general-purpose programmable computers recognized a long time
ago that networks with cycles have orders of larger capabilities than networks
without cycles (e.g., a feed-forward net; see Cycle 9). The wave length of the os-
cillatory category determines the temporal windows of processing (ﬁgure 5.1)
and, indirectly, the size of the neuronal pool involved. It follows from this specu-
lation that different frequencies favor different types of connections and different
levels of computation. In general, slow oscillators can involve many neurons in

116
RHYTHMS OF THE BRAIN
10. The ﬁltering property of the brain tissue is the standard explanation for the observation that the
noise at a given frequency f is spatially correlated over a distance L( f) that increases as f decreases
(Voss and Clark, 1976). The physicist Paul Nuñez pioneered rigorous applications of physical wave
propagation theories to brain waves (Nuñez, 1998). Physics provides a vast toolbox for treating wave
phenomena mathematically. These techniques have provided some understanding of global brain phe-
nomena in terms of the physical properties of its carrier medium. How far can we go with this physi-
cist’s view of the brain? While medium ﬁltering is an important factor, it cannot explain the larger
spatial extent of neuronal recruitment at lower frequencies or the behavior-dependent highly coherent
gamma oscillations in distant brain areas (König et al., 1995; Varela et al., 2001; Buzsáki et al., 2004).
11. Benjamin Libet’s brain stimulation experiments support this point. Libet’s principal ﬁnding
was that short trains of pulses evoked only unconscious functions, and the somatosensory cortex had
to be stimulated for 200–500 milliseconds for evoking a conscious sensation of touch. To become
aware of a sensory experience requires engagement of the appropriate brain networks for hundreds of
milliseconds. The delay between Libet’s “mind time” relative to physical time is a favorite argument
of philosophers to question the unity of the mind and brain (Libet, 2004).
12. Von Stein et al. (1999) and Sarnthein et al. (1998).
large brain areas, whereas the short time windows of fast oscillators facilitate lo-
cal integration, largely because of the limitations of the axon conduction delays.10
Computation in the brain always means that information is moved from one
place to another. Obviously, the path length of network connectivity is very criti-
cal in this process. Because the synaptic path length (recall the degree of neuron
separation, as deﬁned in Cycle 2) and effective connectivity determine the possi-
ble routes for shuttling information from structure to structure, the cycle lengths
(i.e., periods) of the oscillation limit how far information gets transferred in one
step. Fast oscillations, therefore, favor local decisions, whereas the involvement
of distant neuronal groups in distinct structures in obtaining a global consensus
requires more time.11 This principle is nicely illustrated by a series of experi-
ments by Astrid von Stein and Johannes Sarnthein at the University of Zurich. In
their ﬁrst experiment, they had human subjects view parallel grating stimuli with
different numbers of bars per degree of visual ﬁeld. Their main ﬁnding was that
the power of the lower gamma-frequency band (24–32 hertz) increased with the
number of bars per degree. Importantly, these changes were conﬁned to the pri-
mary visual cortex. In the second experiment, everyday objects, familiar to all
sensory modalities, were shown instead. Each object was presented as spoken
word, written word, and picture. The modality-independent processing of inputs
resulted in increased coherent activity between the adjacent temporal and parietal
cortices. The main synchronization took place in the beta frequency range (13–18
hertz). A third set of experiments tested verbal and visuospatial working memory.
This time synchrony was observed between the prefrontal and posterior associa-
tional cortices in the theta range (4–7 hertz). Although the extent of active neu-
ronal assemblies could not be determined by this approach, the ﬁndings
nevertheless support the idea that the size of the activated neuronal pool is in-
versely related to the frequency of synchronization.12 The forthcoming Cycles
discuss and attempt to justify these ideas in detail. For now, let us tentatively ac-
cept that the several oscillatory classes have distinct mechanisms, each serves a

A System of Rhythms
117
13. From Latin circa (about) and di (day), meaning “about a day.” Diurnal and nocturnal refer to
patterns during the day and night, respectively, whereas ultradian rhythms are shorter periodic
changes, also locked to the 24-hour cycle. The discipline of chronobiology is fully devoted to the
study of body time, the impact of cyclic variations on health and disease (“chronotherapy”).
14. Liu and Reppert (2000) have shown that synchronization of suprachiasmatic neurons is medi-
ated mostly by GABA acting on GABAA receptors.
different function, and each involves various magnitudes of neuronal pools. Be-
cause many of these oscillators are active simultaneously, we can conclude that
the brain operates at multiple time scales.
Ultradian and Circadian Rhythms
The oscillators discussed so far are brain and neuron speciﬁc and emerge prima-
rily through mechanisms that are unique to neurons. However, several other
rhythms affect brain activity at a much slower pace, the most famous of which is
the circadian rhythm with a 24-hour period.13 As is the case with most oscilla-
tors, circadian periodicity can be maintained without an outside inﬂuence. The
hypothalamic suprachiasmatic nucleus is usually referred to as the circadian
“pacemaker” in mammals because it controls the daily ﬂuctuations in body
temperature, hormone secretion, heart rate, blood pressure, cell division, cell re-
generation, and the sleep/wake periods. Unlike members of most network oscil-
lators, each of the 20,000 neurons in the human suprachiasmatic nucleus is a
circadian oscillator. This alone is not a unique feature of these neurons, since the
molecular mechanisms that sustain the 24-hour rhythm are present in every cell
of the body, although each cell in isolation would run a bit faster or slower than
the 24-hour circadian cycle. The free-running periods of the individually iso-
lated suprachiasmatic neurons in tissue culture vary from 20 to 28 hours, with
ﬁring patterns of some cells or groups with 6- to 12-hour phase shifts. In the in-
tact brain, individual cells are entrained into coherent oscillation likely through
their connectivity. As is the case in many other neuronal oscillators, the in-
hibitory neurotransmitter GABA and gap junction communication among the
inhibitory neurons appear essential for the synchronization of individual
neurons.14
What make the circadian clock so “slow” are the molecular mechanisms in-
volved in its generation. It takes about 4–6 hours to make a protein from the gene.
Internal timing is achieved through a complex feedback loop in which at least four
freshly produced proteins participate. Two proteins, active in the morning, begin
to produce a second set of molecules that accumulate during the day. In the eve-
ning, this second set of proteins inactivates the daylight-active proteins. The inac-
tivation process involves genes in the nucleus. For example, in the fruit ﬂy
(Drosophila), a messenger RNA is transcribed from the period (per) gene, which
in turn initiates the production of PER protein. The accumulating protein in the

118
RHYTHMS OF THE BRAIN
15. The positive elements of this loop in the mouse are the transcription factors CLOCK and
BMAL1, which drive three period genes (mPer1–mPer3) and one cryptochrome gene (mCry1). The
mPER and mCRY proteins form heterodimers and negatively regulate their own transcription (Kume
et al., 1999). Other key reports in this ﬁeld include Konopka and Benzer (1971), Menaker et al.
(1978), Pickard and Turek (1983), and Allada et al. (2001). The book by Foster and Kreitzman (2004)
is an entertaining introduction to the daily cycles of life.
16. The quote is from a book (Los Autonautas de la Cosmopista) by the Argentine writer Julio
Cortazar written together with his wife, Carol Dunlop, on a 33-day trip from Paris to Marseilles, as
cited in Golombek and Yannielli (1996).
17. A useful collection on subcircadian rhythms in the body is in the volume edited by Hildebrandt
(1957).
cytoplasm enters the nucleus and suppresses further messenger RNA production.
The result is a reduction of PER with reduced suppression of the messenger RNA
production, and the cycle can start again. The real picture is a lot more complex
and involves interactions among the proteins themselves and multiple autoregula-
tory transcriptional/protein translational feedback loops.15
On the input side, timing of the circadian clock can be delayed or advanced by
light, which in mammals is detected by the retina in the eye. In the retina, a small
group of scattered ganglion cells contain the photoreceptor melanopsin and ambi-
ent light directly makes these neurons ﬁre. The exclusive brain target of this spe-
cial group of light-detecting neurons is the suprachiasmatic nucleus. Phase-locking
of this “master” circadian clock leads to the production of hitherto unidentiﬁed
molecules that work as output signals and synchronize the cycling of all individ-
ual cells in the body. In contrast to “simple” relaxation oscillators, several daily
pulses may be required to bring the multiple partners of the circadian clock—
including the sleep/wake cycle, body temperature, hormone secretion, and physi-
cal and mental functions—to a full reset and phase synchrony. All travelers are
aware of this synchronization problem. “When you go [from America] to Europe,
the soul takes about three days longer to get there,” noted the writer-traveler Julio
Cortazar.16
Embedded within the circadian cycle are at least two well-documented ultra-
dian rhythms. The faster one recurs at approximately 90–100 minutes, whereas
the mean duration of the slower one is 3–8 hours, with the shorter component
superimposed upon the longer one.17 Studies of the circadian and subcircadian
rhythms form a new and fast-growing discipline that is gaining increased atten-
tion in medicine, psychiatry, and sleep research. What interests us most in the
context of this Cycle is the relationship between these molecular oscillators and
the faster neuronal rhythms. The observation that isolated single neurons of the
suprachiasmatic nucleus vary their ﬁring rates, emitting about twice as many
spikes during the light phase as in the dark phase, proves the existence of a
mechanism that translates molecular changes to spiking output. These output
spikes can affect other neuronal oscillators in other parts of the brain. On the
feedback side, suprachiasmatic neurons are affected not only by light but also
by the global activity of the brain. For example, following sleep deprivation

A System of Rhythms
119
18. Deboer et al. (2003) found that changes in vigilance states are paralleled by strong changes in
the spiking activity of suprachiasmatic neurons and concluded that the circadian clock can be sub-
stantially modiﬁed by afferent information from the brain.
there is a rebound of prolonged sleep. In turn, such rebound sleep activity has a
profound effect on the activity of suprachiasmatic neurons.18 It is also signiﬁ-
cant that extension of the natural logarithmic relationship among neuronal
oscillators extrapolates faithfully to the periods of ultradian and circadian
rhythms.
In the past, brain oscillators were studied in isolation. Recently, we have begun
to see them as part of a system of oscillators with an intricate relationship be-
tween the various rhythmic components. Considering the short path lengths of
anatomical connectedness in the cerebral cortex, this complexity may not be sur-
prising. Nevertheless, future systematic work is needed to decipher the general
rules and mechanisms of coupling among the neuronal rhythms occupying multi-
ple spatial and temporal scales.
The 1/f Statistical Behavior of EEG
One grand question about the brain is how the microscopic laws of cell discharges
and synaptic activity can lead to a complex system organized at multiple time
scales. The inverse relationship between oscillation classes and the magnitude of
neuronal recruitment provides some interesting clues about the brain’s long-time
and large-scale behavior. When a goal is scored in a football stadium, the coordi-
nated roar of fans can be heard for miles, in contrast to uncoordinated local con-
versations, which are lost in the background noise. Similarly, slow rhythms
involve very large numbers of cells and can be “heard” over a long distance,
whereas localized fast oscillations involving only a small fraction of neurons may
be conveyed only to a few partners. The “loudness” feature of the various network
oscillations can be quantiﬁed easily by Fourier analysis (Cycle 4). Once the signal
is decomposed into sine waves, one can construct a power spectrum of the fre-
quencies, a compressed representation of the relative dominance of the various
frequencies. Although power spectrum ignores the temporal variation of the sig-
nal, it provides a quantitative assessment of the power relationship between the
frequencies. In ﬁgure 5.2, the logarithm of the density is plotted against the loga-
rithm of the EEG frequency. In this so-called log–log plot, we see a straight line,
the hallmark of scale-free systems (i.e., systems that obey power laws; Cycle 2).
By and large, the amplitude (square root of power), A, increases as the frequency,
f, decreases, as expressed by the inverse relationship, A ∼1/fα, where α is an ex-
ponent. The physicist’s reaction to such a relationship is that the EEG reﬂects
nothing special except the internal “noise” of the brain, generated by its active
and passive components. At ﬁrst glance, this conclusion seems diametrically

120
RHYTHMS OF THE BRAIN
opposite to our suggestion above that the brain generates a large family of oscilla-
tions that allows for processing and predicting events at multiple time scales. Ran-
dom noise does not allow any prediction. However, the noise with the “one over
f” power spectrum is a special noise (also called “pink” noise).
A critical aspect of brain oscillators is that the mean frequencies of the neigh-
boring oscillatory families are not integers of each other. Thus, adjacent bands
cannot simply lock-step because a prerequisite for stable temporal locking is
phase synchronization. Instead, the 2.17 ratio between adjacent oscillators can
give rise only to transient or metastable dynamics, a state of perpetual ﬂuctuation
between unstable and transient phase synchrony, as long as the individual oscilla-
tors can maintain their independence and do not succumb to the duty cycle inﬂu-
ence of a strong oscillator.19 In the parlance of nonlinear dynamics, the oscillators
are not locked together by a ﬁxed point or attractor (phase), but they attract and
repel each other according to a chaotic program and never settle to a stable attrac-
tor. A main reason for this recklessness is the presence of multiple oscillators that
perpetually engage and disengage each other. Locally emerging stable oscillators
in the cerebral cortex are constantly being pushed and pulled by the global dy-
namics. Nevertheless, despite the chaotic dynamics of the transient coupling of
log frequency (Hz)
log power
0
0.5
1
1.5
2
Figure 5.2. Power spectrum of EEG from the right temporal lobe region in a sleeping hu-
man subject (subdural recording). Note the near-linear decrease of log power with increas-
ing log frequency from 0.5 to 100 hertz, the characteristic feature of “pink” or “complex”
noise. The arrow indicates the peak at alpha (∼11 hertz). Reprinted, with permission, from
Freeman et al. (2000).
19. For a didactic explanation of chaotic coupling of oscillator pairs and their ability to generate
metastable saddle dynamics, see Bressler and Kelso (2001).

A System of Rhythms
121
20. The exponent of the 1/fα relationship varies somewhat across frequencies (Leopold et al.,
2003; Stam and de Bruin, 2004) and behavioral conditions (eyes open vs. eyes closed) but is highly in-
variant across subjects (Linkenkaer-Hansen et al., 2001).
21. 1/f noise is ubiquitous in nature. In white noise, the power density is constant over a ﬁnite fre-
quency range [P(f)=constant power]. If we mix visible light with different frequencies at random, the
resulting light is white, hence the name “white noise.” It is also known as Johnson noise. If the differ-
ent frequencies are mixed according to 1/f distribution, the resulting light is pinkish. In pink noise, the
power density decreases 3 decibels per octave with increasing frequency (density proportional to 1/f)
over a ﬁnite frequency range that does not include direct current. Engineers use the terms “ﬂicker” or 
the oscillators at multiple spatial scales, a uniﬁed system with multiple time scales
emerges. Indeed, the inverse relationship between frequency and its power is an
indication that there is a temporal relationship between frequencies: perturbations
of slow frequencies cause a cascade of energy dissipation at all frequency scales.
One may speculate that these interference dynamics are the essence of the global
temporal organization of the cortex.
In most illustrations, the log–log linear relationship breaks off below 2 hertz
(ﬁgure 5.2). Does this mean that frequencies below 2 hertz follow a different rule?
This departure from the 1/f line is partially due to the high-pass ﬁltering feature
of the routinely used ampliﬁers. However, if slow frequencies are also part of the
scale freedom, they should have an impact on higher frequencies. Indeed, long-
term scalp recordings conﬁrm power-law scaling behavior for all frequencies
tested and expand the temporal scale of the 1/f line beyond a minute.20 This rela-
tionship indicates that amplitude ﬂuctuation of, for example, an alpha wave at this
instant in your occipital cortex can inﬂuence the amplitude of another alpha wave
a thousand cycles later and all waves in between.
The scale-invariant feature of the EEG is the mathematical telltale sign of self-
organization. The speed at which the power decreases from low to high frequen-
cies measures the length of the correlations or, using another phrase, the
“temporal memory effects” in the signal. This time memory effect is the main
reason why the 1/f relationship is so intriguing. If there were no relationship
among the frequency bands, the power density would be constant over a ﬁnite fre-
quency range and the spectrum would be ﬂat, 1/f0. Physicists call this pattern
“white” noise. So there must be other colors of noise.
The third type of noise is “brown” noise. This time the term refers to the biol-
ogist Robert Brown, the discoverer of the cell nucleus, who also observed pollen
particles performing a random dance in a water droplet: Brownian motion. In the
case of brown noise, the power density decreases much faster with frequency
(1/f2) than is the case for pink noise. Brown noise is random at longer intervals,
but it is easily predictable and strongly correlated at short intervals. For example,
while touring a city without a guide or plan, we make turns at random at the inter-
sections but our walk in straight streets is predictable (“random walk” pattern).
Now, the interesting conclusion we can draw from this crash course on noise is
that the 1/f behavior of EEG and magnetoencephalographogram (MEG) is the
golden means between the disorder with high information content (white noise)
and the predictability with low information content (brown noise).21 The cerebral

122
RHYTHMS OF THE BRAIN
“excess noise.” In brown noise, the power density decreases 6 decibels per octave with increasing fre-
quency (density proportional to 1/f 2) over a frequency range that does not include direct current. In
brown noise, each point is displaced by a Gaussian (distributed) random amount from the previous
point. This is also known as “random walk” noise (Mandelbrot, 1983). For an accessible introduction
to the 1/fα and its more general form, the 1/xα behavior of various living and physical systems, see
Gardnera (1978). For psychologists and behavioral scientists, I recommend the review by Gilden
(2001).
22. Such a rare form of traveling wave is the so-called K-complex of light sleep (Massimini et al.,
2004). For spiral waves and vortices, see Ermentrout and Kleinfeld (2001).
23. Studies using multiple extracellular and intracellular studies over a large portion of the cat
neocortex by Steriade and colleagues provide ample evidence for the synchronous nature of slow
(delta and slow 1) oscillations (Steriade et al., 1993b, d, e; see Steriade, 2001a, 2003).
24. For a detailed treatment of the physics of EEG, see Nuñez (1998).
cortex with its most complex architecture generates the most complex noise
known to physics. But why would the brain generate complex noise?
The brain-speciﬁc problem to be explained is why the power increases towards
lower frequencies. The physicist-engineer explanation is that brain tissue acts as a
capacitive ﬁlter so that the faster waves are attenuated more than are slow waves.
This cannot be the whole story, however, because another main feature of the
spectrum, namely, that perturbations of slow frequencies result in energy dissipa-
tion at all frequency scales, cannot be easily explained by discrete oscillators and
passive ﬁltering. Brain oscillators are not independent, however. In fact, the same
elements, neurons, and neuronal pools are responsible for all rhythms. However,
when the rhythm is fast, only small groups can follow the beat perfectly because
of the limitations of axon conductance and synaptic delays. Slower oscillations,
spanning numerous axon conduction delay periods, on the other hand, allow the
recruitment of very large numbers of neurons. Thus, the slower the oscillation,
the more neurons can participate; hence, the integrated mean ﬁeld is larger. With
local connections only, an emerging rhythm at one place would progressively in-
vade neighboring territories, resulting in traveling waves.22 At other times, the
rhythm would emerge simultaneously at several locations and might be synchro-
nized via the intermediate and long-range connections.23 In short, the inevitable
delays and the time-limited recruitment of neuronal pools can account for a good
part of the 1/f magic.24
All of these EEG frequency relations would, of course, be of minimal interest
even to oscillator aﬁcionados if they were not intimately connected to behavior. If
noise generation is simply a byproduct of brain operations, an inevitable inconve-
nience that has to be overcome, then we might sit back and simply marvel at the
brain’s extraordinary ability to compete with its self-generated noise. Alterna-
tively, correlated noise production could be a deliberate “design” that must have
important advantages and perceptual, behavioral consequences. From the latter
viewpoint, the brain not only gives rise to large-scale, long-term patterns, but
these self-organized collective patterns also govern the behavior of its constituent

A System of Rhythms
123
25. The effects of the emergent, higher level properties on the lower level ones are often called
“downward causation” or an emergent process (Thompson and Varela, 2001). Haken (1984) and Kelso
(1995) refer to these features of dynamic systems by the term “circular causality.” There is no identiﬁ-
able agent responsible for the emergent organization; nevertheless, the pattern dynamics of the system
can be mathematically described by the “order parameter,” emergent property or “relational holism.”
26. Voss and Clark (1975).
27. Interestingly, the complex predictability of sounds applies to monkeys, dogs, and other ani-
mals, as well, in which the pleasantness–annoyance dimension can be behaviorally measured. The
psychologist Anthony Wright claims that rhesus monkeys hear music and other sounds in much the
same way as humans do. His monkeys reliably identiﬁed the melodies of two songs, “Happy Birthday
to You” and “Yankee Doodle Dandy,” even when they were separated by as many as two octaves
(Wright et al., 2000). For a review on “music perception” in animals, see Houser and McDermott
(2003). Of course, the dynamics of cortical patterns in all mammals exhibit 1/f spectra.
neurons.25 In other words, the ﬁring patterns of single cells depend not only on
their instantaneous external inputs but also on the history of their ﬁring patterns
and the state of the network into which they are embedded. Complex systems
with 1/f behavior can be perturbed in predictable ways by various inputs. This
susceptibility should apply to the brain, as well. Thus, it should not come as a sur-
prise that power (loudness) ﬂuctuations of brain-generated and perceived sounds,
like music and speech, and numerous other time-related behaviors exhibit 1/f
power spectra. Perhaps what makes music fundamentally different from (white)
noise for the observer is that music has temporal patterns that are tuned to the
brain’s ability to detect them because it is another brain that generates these pat-
terns. The long-time and large-scale note structure of Bach’s First Brandenburg
Concerto is quite similar to the latest hit played by a rock station or to Scott
Joplin’s Piano Rags.26 On the other hand, both high temporal predictability, such
as the sound of dripping water, and total lack of predictability, such as John
Cage’s stochastic “music” (essentially white noise) are quite annoying to most
of us.27
If self-generated brain dynamics have a link to the spectral composition of
speech and music, one might expect that the same dynamics would inﬂuence a
plethora of other behaviors. Indeed, in addition to speech and music, the power
law function is the best ﬁt to the large data sets available on forgetting in humans
and on other time-related behavioral patterns in a range of species, including ha-
bituation, rate sensitivity, and the many properties of time-based reinforcement
effects and even synchronization errors of human coordination. Let us focus on
some of them in more detail.
Weber’s Psychophysical Law and Large-Scale 
Brain Dynamics
The anatomical-functional organization of the cerebral cortex should have
consequences and limitations on cognitive behaviors as well. A well-known

124
RHYTHMS OF THE BRAIN
28. Ernst Heinrich Weber noted that the increase of stimulus necessary to produce an increase of
sensation in the various modalities is not a ﬁxed quantity but depends on the proportion that the in-
crease bears to the immediately preceding stimulus. The generalization of the relationship between
physical stimuli and cognitive events has come to be known as psychophysics. Gustav Theodor Fech-
ner, working at the same university (Leipzig) but unaware of Weber’s work, described the same law
but stated it in an equivalent mathematical form. When he learned that Weber had already discovered
the relationship, he generously referred to his own observations as a consequence of Weber’s law. Of-
ten, psychologists honor both by calling the relationship the Weber-Fechner law. Long before the
Weber-Fechner law, the Pythagoreans recognized that human perceptions of differences in musical
pitch correspond to ratios of vibrating string or air column lengths. It is believed that Pythagoras him-
self discovered that pleasing chords are achieved if length ratios correspond to successive elements of
an arithmetic progression, 1/2, 2/3, and 3/4, which deﬁne, respectively, the octave, ﬁfth, and fourth
(see Curtis, 1978; Schwartz et al., 2003). Contemporary psychophysical research has reﬁned and re-
placed Weber’s law by a more precise Stevens’s power law. Sensations (S) are related to the physical
stimulus (P) as S=Pn, where n could be less than 1 but occasionally greater than 1 (Stevens, 1975).
29. In its broad “deﬁnition,” quale is the qualitative content of experience, e.g., pleasure, pain, sor-
row, and the feelings that emanate from perception of color, sound, etc. (Llinás, 2001; Tononi, 2004).
According to the philosopher’s deﬁnition, it is an attribute of something that we observe in our minds
(e.g., Searle, 1992; Dennett, 1987).
30. Excellent books and papers deal with behavioral assessment of time in animals (Church and
Gibbon, 1982; Killeen and Weiss, 1987; Staddon and Higa, 1999) and humans (Vierordt, 1868; Allan,
1979; Gibbon et al., 1984; Levin and Zakay, 1989; Tallal, 2004; Näätänen and Syssoeva, 2004).
psychophysical law that comes to mind in connection with the 1/f nature of corti-
cal EEG is that of Weber and Fechner: the magnitude of a subjective sensation (a
cognitive unit) increases proportionally to the logarithm of the stimulus intensity
(a physical unit). For example, if a just-noticeable change in a visual sensation is
produced by the addition of one candle to an original illumination of 100 candles,
10 candles will be required to detect a change in sensation when the original illu-
mination is 1,000 candles.28 According to Rodolfo Llinás at New York University,
Weber’s law also underlies the octave tonal structure of music perception and pro-
duction. He goes even further by suggesting that quale,29 the feeling character of
sensation, may “derive from electrical architectures embedded in neuronal cir-
cuits capable of such logarithmic order.” If so, then the 1/f dynamics may be the
functional architecture underlying qualia and without the ability of a proper ar-
chitecture to generate such temporal dynamics, no “feelings” can be generated
(see Cycle 13 for a more extended discussion of this topic).
In the behavioral literature, interval or duration timing is often explained by a
discrete pacemaker-accumulator mechanism that, similar to a stop watch, yields a
linear scale for encoded time.30 However, researchers have been aware of prob-
lems related to the intuitively simple ticking clock. The fundamental problem is
that timing with a single clock implies similar accuracy at all time intervals; that
is, the coefﬁcient of variation (standard deviation divided by the mean) should not
increase. Behavioral observations, however, show that the error of the hypothe-
sized internal clock is proportional to the clock time; that is, they follow Weber’s
law or Stevens’s power law, much like large-scale brain dynamics as measured by
the EEG signal. Because the exponent of the power rule for interval magnitude
and interval production errors is close to 1 (i.e., it is pink noise), some authors

A System of Rhythms
125
31. However, several investigators argue in favor of a characteristic “tempo” in both music (beat)
and speech. Syllables are generated every 200–400 milliseconds during continuous speech in all lan-
guages.
32. Nieder and Miller (2003), examining the variability of single-unit activity from the monkey
prefrontal cortex, concluded that encoding of numerical information follows Weber’s law. They
trained monkeys to discriminate between different numbers of dots. Control behavioral experiments
showed that the monkeys indeed counted from 1 to 5. When plotted on a logarithmic scale, the tuning
curves of “number neurons” could be ﬁtted by a Gaussian with a ﬁxed variance across the range of
numbers tested. For “number neurons” in the parietal cortex, see Sawamura et al. (2002). The increas-
ing magnitude of neuronal pool necessary for identifying higher numerosity can explain the scaling.
33. The earliest large scalp-recorded response is a negative potential (N1, 60–80 milliseconds af-
ter stimulus onset) followed by positive deﬂection (P1) at about 100 milliseconds. These “sensory” po-
tentials are localized to the primary sensory cortical areas of the appropriate modality. The N2–P2
complex (around 200 milliseconds) is also known as mismatch negativity (Näätänen et al., 1987) be-
cause its amplitude is sensitive to the frequency mismatch of regular signals. Localization of the com-
ponents is more difﬁcult with scalp recordings, and they are collectively referred to as “cognitive”
components. The most studied “cognitive” potential, so-called P300 (Sutton et al., 1965), is enhanced
after an unexpected “oddball” event is embedded in a series of familiar events. A later, N450 (450 mil-
liseconds) component is believed to reﬂect semantic encoding (Kutas and Hillyard, 1980). It is impor-
tant to note that these evoked components reﬂect averaged waveforms of hundreds of repetitions. The
single events can often be equally or better described as combinations of various oscillators. See Uusi-
talo et al. (1996) and Cycle 10.
argue that psychological time corresponds to real time, at least at the milliseconds
to seconds scale. The psychophysical observations also indicate that there is not a
certain point in this time continuum where timing is most accurate. In other
words, time perception does not have a characteristic time scale; it is scale-free.31
This may be because the brain, in contrast to computers and other single clock-
dependent machines, uses a complex system of multiple oscillators for its opera-
tions with a power (1/f) relationship among them.
The progressively longer time required for recalling items from short-term
memory after the initial fast recall of the ﬁrst items may also reﬂect properties of
systems with pink noise. An intuitive explanation of the storage-limiting effect in
the brain is the time–space propagation of activity. Longer times allow propaga-
tion of activity to an ever-increasing population of neurons. However, information
passing through spatially divergent neuronal networks is progressively more vul-
nerable to interference from other network effects (technically referred to as noise
or “leakage”), therefore information deteriorates over time.32 Evoked-potential
experiments, recorded from the human scalp, nicely illustrate this conjecture.
Sensory stimuli, such as ﬂashes of light, evoke progressively longer latency,
longer duration, lower amplitude, and more variable responses at successive
stages of sensory pathways. Repeated presentation of such stimuli leads to modi-
ﬁcation (e.g., habituation) of the evoked responses. The most vulnerable compo-
nents are the long-latency responses recorded from higher level associational
areas, whereas the short-latency components, reﬂecting activity of early pro-
cessing, are quite resistant to habituation.33 The observations in humans echo
earlier experiments in cats. When the source and intensity of the auditory con-
ditioning signal were changed, the latency and amplitude of the early evoked

126
RHYTHMS OF THE BRAIN
34. Grastyán et al. (1978).
35. Several recent experiments provide evidence for the scale-free and spatial fractal nature of
scalp EEG recorded over extended durations (Freeman and Rogers, 2002; Freeman et al., 2003; Gong
et al., 2003; Hwa and Ferree, 2002; Leopold et al., 2003; Le van Quyen, 2003; Linkenkaer-Hansen et
al., 2001; Watters, 1998; Stam and de Bruin, 2004).
36. Even the power spectrum of synaptically isolated neurons, generating intrinsic (channel)
noise, has a 1/f form (DeFelice, 1981; White et al., 2000).
37. The scale invariance of fractals implies that the knowledge of the properties of a model system
at short time or length scales can be used to predict the behavior of the real system at large time and
length scales. In our context, the EEG pattern recorded from a single site for a “representative” period
of time can predict the EEG periods for very long times and at any other recording sites. Although nei-
ther of these statements holds true across all time and spatial scales, understanding the rules of space
and time invariance of EEG is important.
responses faithfully reﬂected the parameters of the physical stimulus. However,
the amplitude and shape of longer latency responses were essentially independent
of the location and intensity of the signal source and were, instead, invariant con-
comitants of the signiﬁcance of the signal, as veriﬁed by the overt behavior of the
cats.34 Overall, these observations suggest that successive stages of information
processing have distinct and characteristic memory decays.35
The Fractal Nature of EEG
So far, we have tacitly assumed that the distribution of EEG and MEG power at
different frequencies obeys the same rule, irrespective of the recording position in
the brain or whether activity was monitored in a relatively small or very large
neuronal pool. Indeed, this assumption appears to be the case, at least to a certain
minimum spatial scale. Power spectra of long epochs of electrical ﬁelds, repre-
senting membrane voltage ﬂuctuations of perhaps a few hundred neurons in the
depth of the cortex when recorded by a microelectrode (micrometer range) or
millions of neurons recorded by scalp electrodes (∼10 centimeters), are essen-
tially identical. Furthermore, the spectral content and frequency bands of the hu-
man EEG and the electrocorticogram of mice, rats, guinea pigs, rabbits, cats,
dogs, and monkeys are remarkably similar. In other words, the long-term tempo-
ral structure of the macroscopic neuronal signal, reﬂecting the collective behavior
of neurons that give rise to it, is macroscopically by and large similar in virtually
all cortical structures and in brains of various mammalian species. This is a re-
markable observation. In essence, the claim is that a collective pattern recorded
from a small portion of the cortex looks like the pattern recorded from the
whole.36 This “scale invariance” or “self-similarity” is a decisive characteristic of
fractals.37 Fractal structures—such as river beds, snow ﬂakes, fern leaves, tree ar-
bors, and arteries—and fractal dynamic processes—such as pink noise, cloud for-
mation, earthquakes, snow and sand avalanches, heart rhythms, and stock market
price ﬂuctuations—are self-similar in that any piece of the fractal design contains
a miniature of the entire design. Regarding the collective behavior of neuronal

A System of Rhythms
127
38. Claims about the fractal nature of the brain are in fact quite old. The importance of localized
vs. global or holistic brain operations is a long-standing controversy in philosophy, psychology, and
neuroscience (Lashley, 1931). The presence of 1/f behavior indicates that the network dynamics are
both local and global.
39. Kelso’s book on the dynamical system properties of the brain (Kelso, 1995) is an important
step in this direction.
signals as fractals with self-similar ﬂuctuations on multiple time and geometry
scales has potentially profound theoretical and practical implications for under-
standing brain physiology. It implies that the macroscopic EEG and MEG pat-
terns describe the large-scale function of neuronal networks as a uniﬁed whole,38
independent of the details of the dynamic processes governing the subunits that
make up the whole.
The concept that physical systems, made up of a large number of interacting
subunits, obey universal laws that are independent of the microscopic details is a
relatively recent breakthrough in statistical physics. Neuroscience is in serious
need of a similar systematic approach that can derive mesoscale laws at the level
of neuronal systems.39 The scale freedom of spatial and temporal dynamics in the
cortex has emerged as a useful direction of research. Does this mean that some
universal laws using a tiny bit of mathematics can help to bring the neuronal al-
gorithms out into the light?
Pausing with this thought for a second, the math is not as simple as it looks.
The seductively simple 1/fα function is, in fact, a very complex one. Every new
computation forward takes into consideration the entire past history of the sys-
tem. The response of a neuron depends on the immediate discharge history of the
neuron and the long-term history of the connectivity of the network into which it
is embedded. Assuming 100 independent neurons with spiking and nonspiking
binary states, more than 1030 different spike combinations are possible. However,
only a very small fraction of these combinations can be realized in the brain be-
cause neurons are interconnected; thus, they are not independent constituents. As
a result, even a weak transient local perturbation can invade large parts of the net-
work and have a long-lasting effect, whereas myriads of other inputs remain ig-
nored. Although neuronal networks of the brain are in perpetual ﬂux, due to their
time-dependent state changes, the ﬁring patterns of neurons are constrained by
the past history of the network. Complex networks have memory.
Scale-Free Dynamics of Noise and Rhythms: 
From Complexity to Prediction
The novel spectral analysis methods and the mathematics of fractals and power
laws have not only helped reveal the large-scale behavior of the brain signals but
have also led to some ﬁerce debate about the relationship between brain oscilla-
tions and noise. At the heart of the debate is the question of whether brain dy-
namics are characterized best by the various oscillators or “simply” pink noise.

128
RHYTHMS OF THE BRAIN
40. This issue has been debated for quite some time, and there are prominent people on both sides
of the debate (e.g., Wright and Liley, 1996; Nuñez, 2000; Shadlen and Newsome, 1994, 1995). Ac-
cording to Erb and Aertsen (1992), “the question might not be how much the brain functions by virtue
of oscillations, as most researchers working on cortical oscillations seem to assume, but rather how it
manages in spite of them. (p. 202).”
41. The now classic mathematical thesis by Bak et al. (1987) combined two fashionable
concepts—self-organization and critical behavior—to explain the even more difﬁcult notion of com-
plexity. This short paper’s seductive claim is that, if a system has 1/f temporal scale and spatially frac-
tal features, its behavior does not require any external “tuning” to undergo phase transitions (in
contrast to e.g., water-ice phase transition that does require the external inﬂuence of temperature). In-
stead, complex systems spontaneously evolve to a state, where they lose their characteristic temporal
and spatial scales, the result of which is that correlations run through the system at all scales. Self-
organized criticality provides a deﬁnition of complexity: a system that exhibits 1/f and spatially frac-
tal statistics. Complex systems with self-organized criticality include snow avalanches, earthquakes,
forest ﬁres, size of cities, airport trafﬁc, Internet communication, blackouts in electric networks, size
of companies, and biological mass extinctions. The attractive feature of the self-organized criticality
hypothesis is that the statistical properties of these complex systems can be described by simple power
laws. Several recent studies have suggested that EEG dynamics are characterized by self-organized
criticality. See, e.g., Linkenkaer-Hansen et al. (2001), Freeman et al. (2003), Le van Quyen (2003),
and Stam and de Bruin (2004).
The prominent alpha rhythms in human scalp recording notwithstanding, power
spectra of long EEG segments, recorded over various behaviors, give rise to spec-
tra without clear peaks. Rhythms come and go at various frequencies and various
times, and their effect may average out in the long term. The feeling of perma-
nence is only an illusion, and brain rhythms are no exception. Does this all mean
that the recorded brain rhythms are simply extreme states of the neuronal noise
generated by the busy brain works?40 If EEG synchronization between different
brain regions does not have a characteristic time scale, it is hard to understand
how the effective connectivity of those regions can be modiﬁed according to rap-
idly changing behavioral needs.
The scale-free nature of global synchronization dynamics implies some spe-
ciﬁc predictions. One such explicit implication of the 1/f law is that, most times,
brain dynamics are in a state of “self-organized criticality.” This mathematically
deﬁned complex state is at the border between predictable periodic behavior and
unpredictable chaos. In the context of brain dynamics, the implication of the con-
cept of self-organized criticality is that the cerebral cortex displays perpetual state
transitions, dynamics that favor reacting to inputs quickly and ﬂexibly. This
metastability is a clear advantage for the cerebral cortex since it can respond and
reorganize its dynamics in response to the smallest and weakest perturbations.
However, noise can be deﬁned only in a ﬁnite temporal window, and the 1/f dy-
namics of brain activity are deduced from long temporal integration windows.
Yet, at every instant, the state of the network is different; thus, the ability of corti-
cal networks to respond to perturbation also changes from moment to moment.
A direct prediction of the self-organized criticality theory is that rare but ex-
tremely large events are inevitable, because at one point 1/f dynamics become su-
persensitive to either external perturbations or its internal processes, responding
with very large synchronized events.41 One may rightly mistrust this latter claim.

A System of Rhythms
129
42. Jensen (1998) is an excellent and entertaining short summary of the highlights and downsides
of the self-organized criticality theory.
In the lifetime of a normal brain, such unusually large events never occur, even
though the ability of neuronal networks to generate such avalanches is illustrated
by the supersynchronous activity of epileptic patients. The tensegrity dynamics of
excitation and inhibition guard against such unexpected events. We have to recall
that the EEG reﬂects the “average” behavior of neurons, with many interacting
degrees of freedom. In the complex system of the brain, many degrees of freedom
interact at many levels, such as neurons, mini- and macromodules, areas, and sys-
tems. Seemingly insigniﬁcant changes of the interactive constituents at any level
can dramatically affect the course of events, as real-world tests of the self-organized
criticality theory illustrate. For example, experiments with sand piles, rice piles,
and other systems indicate that some minor changes of boundary conditions and
space constants can often switch their critical dynamics to oscillatory behavior.
For example, rice piles of certain types of rice grains display a broad distribution
of avalanche sizes, thus supporting the theory. Sand piles, on the other hand, most
often evolve into a temporal periodic state, presumably because gravity (a con-
stant) can overcome the friction between sand grains.42
Another prediction of the postulated scale-invariant and spatial fractal feature
of EEG is that knowledge of short-time information can be used to calculate long-
range temporal correlations; similarly, knowledge about small-space scale infor-
mation can estimate the global state. Neither prediction works perfectly well, as is
demonstrated by numerous experiments in later Cycles. The rhythm versus the
1/f noise controversy should remind us of the somewhat banal, but nevertheless
important, fact that general concepts such as power laws may be able to capture
some aspect of a phenomenon without necessarily being able to explain all of its
critical details. The 1/f feature of the EEG is obvious only when the events are in-
tegrated over a sufﬁciently long time and at a large enough spatial scale.
Why do some see convincing 1/f behavior, and others see mostly rhythms in
EEG and MEG traces? Can the power spectrum be decomposed into individual
rhythms generated by distinct neurophysiological mechanisms, or should we look
for mechanisms that can generate pink noise without oscillations? Luckily, one
can address the rhythm versus 1/f statistics controversy by removing the noise
from the measured brain signal obtained during a particular behavior. This pro-
cess is usually referred to as “whitening” or precoloring of the power spectrum by
removing the correlated “pink” noise. The illustration shown in ﬁgure 5.1 (top) is
an already whitened spectrum, which is why we can see clearly separable peaks at
delta, theta, gamma, and fast (“ripple”) frequencies. If there were no discrete, al-
beit interdependent, oscillations, the trace would be ﬂat. Recall now that our log-
arithmic rendering of brain oscillators (ﬁgure 5.1, bottom) shows that in the
frequency range where the 1/f relationship is continuous (2–200 hertz), ﬁve dis-
tinct oscillatory bands exist, each of which has a wide range of frequencies that
ﬂuctuate over time. The frequency, amplitude, and recurrence variability of the
oscillators may account for the smoothness of the broad frequency range of the

130
RHYTHMS OF THE BRAIN
43. A somewhat similar idea is expressed by Szentágothai and Érdi (1989).
44. For the relationship between Fourier analysis and wavelet methods, see Cycle 4.
45. Stam and de Bruin (2004) also point out that investigators who do not report characteristic
time scales in the EEG typically analyze long recording epochs with large variability. In contrast,
studies that consistently report on distinct oscillations tend to sample short epochs of EEG signals.
power spectrum constructed from long recordings without a need for generating
extra noise.43 Put bluntly, the brain does not generate complex noise directly. In-
stead, it generates a large family of oscillations whose spatial-temporal integra-
tion gives rise to the 1/f statistics. This is, in fact, the simplest way of producing
complex noise. The bonus is that switching from complexity to the predictive os-
cillatory mode can be fast; such a transition is a major requirement for efﬁciently
selecting a response from a background of uncertainty.
In the debate between pink noise and rhythms, we also have to remember how
we generate the power spectrum and what we are trying to answer with it. Recall
that the Fourier analysis works in the frequency domain and ignores temporal
variations altogether. The power spectrum of Bach’s First Brandenburg Concerto
is the same, regardless of whether it is played forward, backward, or chopped into
short segments and mixed so that even the best Bach scholars fail to recognize the
masterpiece. Fast but critical transitions across patterns cannot be recognized in
long-time power spectra. This, of course, applies to brain signals as well. All im-
portant serial effects, reﬂecting sequences of overt and covert behavior, are ig-
nored by the summed power spectrum of the EEG and MEG. To compensate for
such serious shortcomings, improved methods, such as the short-time Fourier
transform or wavelet analysis, have been introduced. With these improved meth-
ods, sequential short epochs can be analyzed and the frequency structure dis-
played as a function of time.44 This procedure is equivalent to calculating the
power spectrum of the score in the First Brandenburg Concerto at every few hun-
dred milliseconds. Obviously, there is still a lot of arbitrariness in the procedure,
but it is a signiﬁcant improvement over integrating the whole concert together
over time. The most important advantage of such reﬁned time series analysis is
that now spectral characterization of EEG or MEG can be done in time windows
that more faithfully correlate with behavioral changes. Using such reﬁned
brain–behavior analysis, spectra that correspond to identical behaviors can be
combined and their frequency–power distributions can be contrasted across dif-
ferent behaviors. When the analysis is carried out in such a way, the presence of
rhythms and their association with overt and cognitive behaviors often become
obvious.45 The simple reason is that transient behavioral changes and responses
are often associated with characteristic but transient oscillations.
A similar contrast applies to the coherence of EEG activity as a function of
distance. Long-term observations consistently show that coherence of neuronal
activity rapidly decreases as a function of distance at high frequency but de-
ceases less for low frequencies. On the other hand, short-lived but highly coher-
ent oscillations in the gamma frequency band are often reported between distant
sites processing different but related aspects of inputs (discussed in Cycle 10).

A System of Rhythms
131
46. Sensory, motor, and cognitive event-related “desynchronization” of the scalp EEG is just such
a clear example of the perturbation of the postulated critical state of the brain. See discussion in Cy-
cles 6 and 7.
47. For further arguments in favor of the importance of state variability in cognition and stimulus-
induced effects, see Arieli et al. (1996), Friston (2000), Gilden (2001), and Buzsáki (2004).
These observations are important, because if the occurrence of a behavioral act
is consistently associated with an induced rhythm in some structures, it likely
bears physiological importance. In the critical state, the spatiotemporal correla-
tions of neuronal interactions make the brain highly susceptible to perturba-
tions, allowing for an instantaneous reorganization of effective connectivity.46
Perturbations, such as sensory stimuli or motor output, could reduce the critical
state and provide transient stability by oscillations. These transient stabilities of
brain dynamics are useful to hold information for some time, as is the case while
recognizing a face or dialing a seven-digit telephone number. Shifting the brain
state from complex pink-noise dynamics to a state with a characteristic tempo-
ral scale is therefore an important mechanism that provides a transient auton-
omy to various levels of neuronal organization. I suggest that the ability to
rapidly shift from the state of metastable pink noise to a highly predictable os-
cillatory state is the most important feature of cortical brain dynamics. In the
high-complexity (1/f ) regime of metastability, the brain is in a critical state ca-
pable of responding to weak and unpredictable environmental perturbations. By
shifting its dynamics to an oscillatory regime, it instantaneously creates a state
with linear variables, which is a fundamental physiological requirement for psy-
chological constructs described by the terms “anticipation,” “expectation,” and
“prediction.”
Because most overt and covert behaviors are transient, their brain oscillation
correlates are also expected to be short-lived. Thus, it would appear that averag-
ing short-time power spectra is the perfect way to analyze brain–behavior rela-
tions. Indeed, stimulus-evoked averaging of brain potentials or metabolic changes
in brain imaging experiments has been a standard procedure in cognitive and ex-
perimental psychology. The variability of the responses across trials is generally
downplayed as unexplained variance or “noise” that needs to be averaged out to
reveal the brain’s true representation of invariant input. In functional magnetic
resonance imaging (fMRI), the responses are often pooled and averaged across
subjects to further reduce the variance. The real problem with the averaging pro-
cedure, of course, is that the state of the brain is constantly changing. State
changes are hard to predict from behavior on a moment-to-moment basis. State
variability is, to a large extent, internally coordinated. This “correlated brain
noise,” as it is often referred to, might be critically important because it is a po-
tential source of mental operations.47 The recorded signal, in fact, may contain
more information about the observer’s brain state than about the input, because
the process is an “interpretation” or “construction” rather than a reﬂection, to use
terms borrowed from psychology. In order to predict the present state of a brain,
one needs to have access to its recent history.

132
RHYTHMS OF THE BRAIN
48. For 1/f noise in human behavior, see Gilden et al. (1995), Chen et al. (2001), Ding et al.
(2002), Aks and Sprott (2003), for EEG measures, Linkenkaer-Hansen et al. (2001), Freeman et al.
(2003), Leopold et al. (2003), Stam and de Bruin (2004).
49. Izhikevich et al. (2004).
The embodiment of recent history is the temporal correlation represented by
the 1/f memory of scale-free systems. The term 1/f “memory” is a statistical
statement and does not necessarily imply a direct connection with human recall or
reminiscence. Nevertheless, because brain networks generate both behavior and
electrical patterns, it is not unreasonable to suspect a link. Consider a simple syn-
copation or continuation experiment, in which subjects continue to reproduce a
given temporal interval 1,000 times from memory after they are given 1-minute
metronome training with the sample intervals. David Gilden at the University of
Texas–Austin found that sequences of the errors can be best characterized with a
1/f power law. The translation of this statistical relation to behavior is that a given
tapping error can affect the precision of the 100th future tap and on all taps in be-
tween. A remarkably similar temporal structure can be revealed by examining the
long-term behavior of various brain oscillators. For example, alpha and gamma
episodes come and go, but their occurrence is far from random. In fact, they have
signiﬁcant temporal correlations for at least a couple of hundred seconds and dis-
play a 1/f power spectrum with a striking resemblance to the behaviorally ob-
served effects in both monkeys and humans.48 The 1/f statistical signature is a
potential link between brain dynamics and behavior. Ironically, this is the exact
measure that we throw out with the current practice of averaging short-term data.
This practice prevents us from addressing the important problem of response
variability.
Noise and Spontaneous Brain Activity
The largest computer network of the neocortex yet built was constructed by Eu-
gene Izhikevich and Gerald Edelman. Their three-dimensional model consisted
of 100,000 neurons exhibiting some known cortical ﬁring patterns. Each excita-
tory neuron was randomly connected to 75 local and 25 distant targets. Twenty
percent of the neurons were GABAergic and wired locally, mimicking the pro-
portions in the mammalian cortex. Despite such dense anatomical wiring, involv-
ing more than 7 million excitatory connections, neurons in the model remained
dead silent unless external noise was provided to each neuron. At low levels of in-
put noise, the system sustained oscillatory patterns with spatially uniform activity.
High levels of input noise gave rise to asynchronous Poisson patterns of spiking
activity that led to organized, sustained patterns.49 Other computer networks do
not fare better. In contrast to the brain, most current models of the brain or pieces
of the brain do not give rise to true spontaneous patterns without some externally
supplied noise. They either are dead silent or generate avalanches of activity in-

A System of Rhythms
133
50. Some form of noise is included in all models to mimic the highly variable spontaneous spiking
activity present in the intact brain (e.g., Usher et al., 1994). Some networks with sparse connectivity
can generate irregular spike trains (van Vreeswijk and Sompolinsky, 1996; Amit and Brunel, 1997).
However, these models are less sensitive to input perturbations and are quite unstable. Models of sin-
gle oscillators, on the other hand, are too stable, and without some external noise, the spike patterns
are very regular.
51. Voltage ﬂuctuations in real neurons are limited by conductance increases (see Cycle 6) that ac-
company synaptic activity. Therefore, it seems unlikely that synaptic activity can generate large-
enough white noise-like variability to sustain activity in model networks.
52. See e.g., Bullock and Horridge (1965) or Marder and Calabrese (1996) for spontaneous pat-
terns in small neuronal networks.
53. For cortical transplants, see Bragin and Vinogradova (1983) and Buzsáki et al. (1989). The
burst/pause patterns of cortical slabs resemble slow 1 oscillation (Timofeev et al., 2002) or epileptic
discharges (Buzsáki et al., 1989). Traub and Wong (1982) provide a quantitative explanation for the
avalanches in model networks. For the importance of subcortical neurotransmitters in preventing pop-
ulation bursts, see Steriade and Buzsáki (1990) and McCormick et al. (1993).
volving nearly the whole population.50 The usual explanation is that the network
is not large and complex enough and therefore cannot generate enough noise.
However, computer networks, including the supersized systems, fail to generate
enough internal noise necessary for observing some desired patterns.
How large should a system be to generate continuous spontaneous patterns?
My answer is that size is not the (only) issue.51 Even a very small real brain or
neuronal networks with just a few dozen neurons can solve complex problems
that would make man-made computer-controlled robots jealous.52 All real brains,
small and large, possess spontaneous activity because they are complex enough.
However, complexity does not simply emerge from increasing the number of con-
stituents. Neuronal systems that consist of glutamatergic excitatory and GABAer-
gic inhibitory neurons do not do much else than generate large epileptiform
population discharges interrupted by silence. Indeed, this is exactly what an iso-
lated piece of the mammalian cortex does. Fetal cortical tissue transplanted into
the anterior chamber of the eye or into a blood-supplying cavity in the cortex gen-
erates synchronous discharges of various sizes followed by pauses of various
lengths, a behavior not much different from that of sand piles. Isolated cortical
slabs and cortical neurons grown as two-dimensional tissue culture generate sim-
ilar burst/pause patterns. When isolated from their subcortical inputs, the nearly
two million neurons in the rat hippocampus just sit and wait to be part of a giant
collective scream.53 These intermittent patterns are a far cry from the 1/f dynam-
ics of the intact mammalian cortex.
Applying external noise to a network is convenient, but it has some inconve-
nient consequences. In Izhikevich’s large model, noise intensity had to be in-
creased ﬁvefold to shift the system from avalanches to irregular patterns. At this
high level of noise, synchrony occurred only in response to strong external inputs,
and the average ﬁring rate of neurons doubled. Most important, 10 percent of all
action potentials occurred in response to the externally applied noise rather than
to internally generated synaptic activity. This seems like an inefﬁcient system

134
RHYTHMS OF THE BRAIN
54. Laughlin and Sejnowski (2004).
because such a large percentage of spikes are devoted to noise production. In
models, this may not be such a big problem. However, energy calculations indi-
cate that the brain cannot afford to waste so many spikes. Doubling the ﬁring rate
of neocortical neurons would exhaust their energy resources within minutes.54
Furthermore, spikes generated by noise will propagate activity and interfere with
signal-related computation. So, is noise just a waste or is there something good
about it? Find out in Cycle 6.
Brieﬂy . . .
The collective behavior of neurons, summed up crudely as the mean ﬁeld (EEG
and MEG) is a blend of rhythms. Neuronal networks in the mammalian cortex
generate several distinct oscillatory bands, covering frequencies from<0.05
hertz to > 500 hertz. These neuronal oscillators are linked to the much slower
metabolic oscillators. The mean frequencies of the experimentally observed os-
cillator categories form a linear progression on a natural logarithmic scale with a
constant ratio between neighboring frequencies, leading to the separation of fre-
quency bands. Because the ratios of the mean frequencies of the neighboring
cortical oscillators are not integers, adjacent bands cannot linearly phase-lock
with each other. Instead, oscillators of different bands couple with shifting
phases and give rise to a state of perpetual ﬂuctuation between unstable and tran-
sient stable phase synchrony. This metastability is due to the presence of multi-
ple coupled oscillators that perpetually engage and disengage each other. The
resulting interference dynamics are a fundamental feature of the global temporal
organization of the cerebral cortex. The power density of the EEG or local ﬁeld
potential is inversely proportional to frequency (f ) in the mammalian cortex.
This 1/fα power relationship implies that perturbations occurring at slow fre-
quencies can cause a cascade of energy dissipation at higher frequencies, with
the consequence that widespread slow oscillations modulate faster local events.
The scale freedom, represented by the 1/fα statistics, is a signature of dynamic
complexity, and its temporal correlations constrain the brain’s perceptual and
cognitive abilities. The 1/fα (pink) neuronal “noise” is a result of oscillatory in-
teractions at several temporal and spatial scales. These properties of neuronal os-
cillators are the result of the physical architecture of neuronal networks and the
limited speed of neuronal communication due to axon conduction and synaptic
delays.
Brain evolution opted for a complex wiring pattern in the mammalian cortex.
The resulting 1/fα temporal statistics of mean ﬁeld are the hallmark of the most
complex dynamics and imply an inherently labile, self-organized state. Although
brain states are highly labile, neuronal avalanches are prevented by oscillatory
dynamics. Most oscillations are transient but last long enough to provide stability

A System of Rhythms
135
for holding and comparing information at linear time scales. Scale-free dynam-
ics generate complexity, whereas oscillations allow for temporal predictions. Or-
der in the brain does not emerge from disorder. Instead, transient order emerges
from halfway between order and disorder from the territory of complexity. The
dynamics in the cerebral cortex constantly alternate between the most complex
metastable state and the highly predictable oscillatory state: the dynamic state
transitions of the brain are of the complexity-order types. When needed, neu-
ronal networks can shift quickly from a highly complex state to act as predictive
coherent units due to the deterministic nature of oscillatory order.

Cycle 66
Synchronization by Oscillation
If the past is over, and the future has not yet come, all that exists is now; so
how long does now last?
—St. Augustine
136
What is and what is not an oscillator in the real world are not always easy to de-
termine. To start the discussion, here is a rule of thumb for a true oscillator: if it is
broken into pieces, it no longer oscillates. For example, a watch is a true oscilla-
tor system, a machine with a functional unity, in which cooperation of all its parts
is necessary to keep track of time. Each part is designed for a particular function
to assist other parts. Although several parts and functions contribute to the main-
tenance of clocking, only two of these are truly critical: mechanism for ticking
time (time constant) and energy to maintain ticking. In a more general sense,
rhythms arise whenever positive and negative forces balance each other. The pos-
itive force drives the system away from one state, while the negative force pushes
it back. Unfortunately, my high school physics rule of thumb often fails when it
comes to brain oscillators.
Indeed, identiﬁcation of the minimum conditions necessary for the mainte-
nance of neuronal oscillation can be a daunting task for various reasons. First,
oscillating systems can be built in various ways. Systems assembled from the ex-
act same building blocks can generate different dynamics and functions, depend-
ing on their precise internal and intersystem connections. Some architectural
designs promote synchronization while others resist it. Second, the take-it-apart,
put-it-back-together recipe does not work well in complex neuronal systems.
Third, the behavior of most brain oscillators cannot be easily identiﬁed with the
known types in physics. But we have to begin somewhere. Perhaps the best way

Synchronization by Oscillation
137
1. A weakly chaotic system is a system that is sensitive to the initial conditions (i.e., it is chaotic).
For a thorough discussion of various oscillators, see Pikovsky et al. (2001). Strogatz’s bestseller Sync
(Strogatz, 2003) is an easy read. For biological oscillators, I recommend Winfree’s classical book
(Winfree, 1980) or Glass and Mackey (1988) The reviews by Kaplan and Glass (1995) and Glass
(2001) are brief but comprehensive.
2. A harmonic oscillator is any physical system that varies above and below its mean value with a
characteristic frequency, f. The playground swing is essentially a pendulum, a harmonic oscillator.
You push when your velocity becomes zero at the top of swing to compensate for the lost energy, due
to friction. The duration [T, (the reciprocal of frequency, T=1/f), equal to 2π (l/g)1/2, where l=length
and g=gravity], does not depend on the amplitude of the swing or your weight, only on the length of
the swing.
to start is to examine some well-known oscillators in the physical world and
compare their behavior to neurons and neuronal groups. After reviewing some
prototype oscillators of physics, I turn to oscillating single neurons and net-
works. I also discuss the importance of neuronal synchronization and its role in
the formation of functional cell assemblies and conclude that synchronization
by oscillation is the simplest and most economic mechanism to bring together
discharging neurons in time so that they can exert a maximal impact on their
targets.
What Is an Oscillator?
Biological oscillators belong to the broad class of limit cycle or weakly chaotic
oscillators.1 To picture the abstract mathematical construct of the limit cycle,
think of a racing car on a circular track. If the speed of the car is relatively con-
stant, it will pass in front of you periodically. The reciprocal value of the time pe-
riod is the frequency of the car’s circular motion. The exact path of the car will
vary somewhat in each round, bypassing other cars at different parts of the track,
but this path variability is limited by the physical barriers of the track. The car can
occupy any part of the track but should avoid the barriers. Thus, the track surface
can be conceived of as the attractor of the car’s orbit. To generalize, the limit cy-
cle is an attractor to which the trajectories of the oscillation are drawn after per-
turbations, provided the system has run for “enough” time. It is this feature that
gives limit cycle oscillators their name. The most familiar form of oscillation is
the harmonic motion of the pendulum. The electrical current supplied to your
home by your local utility company is also a harmonic oscillator, with a periodic
sinusoidal oscillation of its amplitude at 60 hertz (or 50 hertz, depending on
where you live). Harmonic oscillators, like the pendulum clock, are reasonable
beat keepers and good predictors.2
Of course, racing cars do not keep a constant speed. In fact, if we watch the
race from a point that allows only a limited view, we cannot tell whether the peri-
odic and regular return of our favorite car is achieved by a constant or variable
speed. In theory, the car can idle for nearly the entire cycle period and ﬁnish the
circle at a very high speed. Or it can just run slowly at the beginning of the circle

138
RHYTHMS OF THE BRAIN
3. Most biological oscillators are relaxation or pulsatile types, including heartbeats, respiration,
walking, and hormone secretion. There are minimal requirements for an oscillator. The opposing
forces of push and pull, positive and negative, excitation and inhibition combined with proper feed-
back are all that is needed (Wang, 2003). A relaxation oscillator is typiﬁed by a slow accrual and fast
release of energy. Relaxation oscillators have only two free variables (voltage and voltage recovery).
The standard form of a relaxation oscillator is X=y–f(x), Y=–ex, where e is a parameter that modu-
lates the rate of coupling between the slow and fast cycles of the oscillator. When e is close to 0, the
oscillator spends most of its time in the slow accrual time scale, as is the case in a rhythmically dis-
charging neuron at a low frequency with highly nonlinear behavior. Coupled relaxation oscillators in
this slow mode synchronize with great stability. When e is close to 1, the variable y accrues very
quickly, and the time spent in the fast release time scale becomes similar to the slow accrual time
scale. In this case, the frequency of the relaxation oscillator is high, and the waveform is relatively si-
nusoidal (e.g., > 500 spikes/second for a neuron) and acts like a harmonic phase-pulling oscillator.
Thus, it is possible to make a relaxation oscillator act like a sinusoidal phase-pulling oscillator by sim-
ply making it oscillate faster.
and speed up for the remaining part. If the speed is not constant within a cycle, the
oscillator is called nonharmonic. The output of nonharmonic oscillators can be
virtually any shape. Because the output is generally characterized by a sudden
change followed by a slow accumulation of energy, or relaxation, nonharmonic
oscillators are often referred to as relaxation oscillators.3 Biologists like to call
them pulsatile oscillators. A household example of a relaxation oscillator is a
dripping faucet. If the faucet is not turned off completely, it behaves like a
metronome, generating water spheres and annoying sounds at regular intervals.
The energy source that maintains the oscillation is the water pressure, whereas the
balance between gravity and local viscosity determines the drop size. If the pres-
sure is reduced, the interval between the drops increases; thus, the oscillator slows
down, but the drop size remains the same. The frequency of the relaxation oscil-
lator is calculated from the intervals between the pulses (water drops).
If the kitchen example seems too trivial, one can construct a similar mecha-
nism from electronic components. Such an oscillator was ﬁrst designed by
Balthasar van der Pol in 1920 to model the perpetual contractions of the heart.
The components of this simple electronic oscillator (ﬁgure 6.1) illustrate the prin-
ciples and requirements that are sufﬁcient to sustain oscillation. First, the oscilla-
tor has an energy source, in this case, a battery. Once the circuit is closed, the
charges at the capacitor begin to accumulate. The speed of charge depends on the
capacitance and resistance. The growth of voltage is analogous to the increase in
the size of the water drop. When the voltage difference across the capacitance
reaches a critical level, the gas in the neon tube becomes conductive and the tube
glows for a short period of time. This energy-consuming process discharges the
capacitance, and the neon tube becomes nonconductive again. This process is
analogous to the drop of the water sphere. The interplay between two forces—the
charge of the capacitance and discharge of the neon tube—can sustain the oscil-
lation. Because of the slow charging and fast discharging features of the van der
Pol relaxation generator, it is also called an “integrate-and-ﬁre” oscillator. Mod-
ern versions of van der Pol oscillators are important circuits in radios, televisions,

Synchronization by Oscillation
139
4. van der Pol (1889–1959) was among the ﬁrst to recognize the importance of oscillations in bio-
logical systems. His pioneering work on hardware and mathematical modeling of heart contractions
by coupled oscillators remains a masterpiece of biological physics (van der Pol and van der Mark,
1928). The slow accrual of energy needed to trigger an action potential (fast release of energy) in
integrate-and-ﬁre model neurons can be brought about by various time dynamics, providing rhythmic
or stochastic ﬁring or any pattern in between, depending on the properties of the network and the dis-
tribution of channels in the model neuron.
and computers and are often used in modeling single neurons.4 Harmonic and re-
laxation oscillators are the best understood types in physics. If we know the com-
ponents of an oscillator, we can predict its dynamics. This bottom-up approach is
often not very helpful in the brain because the components and their relationships
are often too hard to decipher. Another approach is to determine the behavior of
the oscillator and infer the underlying mechanism from the top down. This can be
done because the general behavior of an oscillator and its response to perturba-
tion depends on the type of the oscillator.
There are important differences between the behaviors of harmonic and relax-
ation oscillators (ﬁgure 6.2). In our racing car analogy, the frequency of the oscil-
lation can be judged by measuring the speed (or phase angle) of the car at any
short distance around the track, as long as the speed remains constant. In other
words, the short-term and long-term behaviors of the harmonic oscillator are the
same. Perturbing the oscillator is difﬁcult, but it does not matter when (i.e., at
what phase) the perturbation is exerted. If the car is moving at a constant speed
and at a constant phase angle, an outside force (e.g., slight collision with another
car) will have the same transient impact independent of the car’s orbit on the
track. The car twists and turns a few times and gets back to its limit cycle again.
Similarly, if a pendulum clock is slightly perturbed, it exhibits a damped train of
vibrations for a while before returning to its regular clocking rhythm. Harmonic
Figure 6.1. Principles of the relaxation (van der Pol) oscillator. The energy source (V)
slowly charges the capacitance (C) through the resistor (R). When the voltage difference
across the capacitance reaches a critical level, the gas in the neon tube becomes conduc-
tive (the tube glows) and discharges the capacitance. The interplay between two forces—
the charge of the capacitance and discharge of the neon tube—can sustain perpetual
oscillation.

140
RHYTHMS OF THE BRAIN
oscillators, especially the variable frequency versions, are difﬁcult to build and
require a complicated multivariable coupling mechanism to keep the phase and
frequency constant.
Relaxation oscillators display variable phase angles (velocity) in their orbits.
Because of this nonlinear behavior, the estimation of the state of the oscillator
(i.e., time or phase) between beats is not straightforward. There is no simple way
to extrapolate the long-term frequency of water drops from observation periods
shorter than the limit cycle.
Relaxation oscillators have three distinct states. The ﬁrst is the excitable state
Figure 6.2. The alpha waves of Hans Berger share features with the harmonic (sinusoid)
oscillator (top). Single-cell spiking oscillators are of the relaxation type, characterized by
a slow accrual charge phase, threshold, and fast discharge (action potential) phase (mid-
dle). Increasing the frequency of oscillation can lead to equal charge (duty cycle; gray) and
discharge periods, essentially a conversion of a relaxation oscillator into a harmonic oscil-
lator (bottom).

Synchronization by Oscillation
141
5. Sleep patterns are discussed in Cycle 7.
(energy accumulation phase; “ready to participate”), during which the oscillator
can be perturbed. If one gently hits the faucet between the drops, the external force
might produce a smaller sized drop, after which the process is reset to its full
readiness state. The time between the perturbation and the next full-size drop is
identical to the usual interdrop periods. Thus, in contrast to harmonic clocks, the
relaxation oscillator wastes no time getting back to business as usual. The second
state is called active (or duty cycle phase) and corresponds to the drop of water.
Immediately after a drop, however, tapping at the faucet is no use, since water ac-
cumulation requires time. This early part of the accrual phase is usually referred
to as the refractory period (third state). Since nearly all single neuron oscillators
are of the relaxation type, these features should have a strong impact on the man-
ner in which information is transmitted in neuronal networks.
The accrual and discharge phases can be referred to as receiving and transmit-
ting modes, corresponding to the interspike and the spiking states of the neuron.
For these reasons, a synchronously oscillating neuronal group can be perturbed
by inputs only during the participating or ready state; they are immune to pertur-
bations during the active state and the refractory period. Relaxation oscillators
thus divide the labor between information transfer periods (duty or sending cycle)
and readiness (or receiving) periods. Receiving and transmission of information
are separated in time, and the magnitude of temporal separation is determined by
the frequency and other details of the oscillating mechanisms. Mostly because of
their phase reset properties, relaxation oscillators can couple together in large
numbers. This capacity gives networks of relaxation oscillators the important
ability to learn and store patterns. In summary, relaxation oscillations provide
predictable windows of opportunities for neuronal assemblies to cooperate or, al-
ternatively, ignore each other. This “gating” feature of oscillations has far-
reaching consequences for the operations of neuronal networks.
Most often, periodic phenomena come in various disguises; it is not always
easy to distinguish between harmonic and relaxation types or between true and
spurious oscillators. This challenge is especially true for oscillating neuronal net-
works. Good time keepers, such as our circadian clock, work forever. During
rapid eye movement (REM) sleep,5 theta oscillation in the hippocampus is sus-
tained for nearly the entire period of this sleep stage. These rhythms are therefore
called sustained or autonomous oscillations that make use of a constant source of
energy to counteract energy losses and are able to continue to oscillate virtually
forever.
There are two extreme conditions under which oscillations can be generated.
The simplest one is a phase-controlled energy source and a normally dampened
system. A familiar example is the trick of getting yourself going on a swing by
leaning back and forth with arms and legs timed (i.e., phase-locked) to the natural
frequency of oscillation of the swing. The oscillation continues because you are
periodically adding energy to keep the rhythm going. However, if the push is sup-
plied by a friend and her pacing varies at her leisure, the swing becomes a forced

142
RHYTHMS OF THE BRAIN
oscillator. In the second condition, the interaction occurs between the swing’s fea-
tures and a “noisy,” or random, energy source without a clear event or source that
is responsible for the oscillation period. Many intermediate forms between these
extreme conditions exist, but the main principles are the same in all oscillators: a
tension between opposing forces combined with a regenerative or positive feed-
back. In many cases, the temporal ﬂuctuation of the energy and the degree of
damping of the oscillatory system are not obvious, giving the impression of spon-
taneity even though the rhythm is supplied from an unrecognized outside source.
Thus far, we have considered oscillators in their steady state without getting
into the thorny issue of how oscillations are brought about or die away. Most brain
oscillators are not sustained for extensive time periods but rather come and go, for
which reason they are called transient. Identiﬁcation and quantitative description
of transient oscillators can be very difﬁcult. After all, what is an oscillator? If
events occur at regular intervals millions of times, we have no problem. But what
if they repeat merely 10 times, ﬁve times, or only once? Identiﬁcation of the
deﬁning limit cycle is elusive with so few cycles. A pendulum without energy loss
compensation is a damped or transient oscillator with a response that fades away
over time. The waxing/waning oscillatory patterns that occur during the early
stages of a night sleep, appropriately called sleep spindles, are prime examples of
a transient neuronal oscillator. Because spindle events repeat many times during
sleep, they can be lumped together for quantiﬁcation. So, when it comes to a brief
spindle of only two or three cycles, we generalize from the long-term observa-
tions and on the basis of waveforms and other features and accept or reject a pat-
tern as a spindle.
Characterization of an oscillator is problematic not only when classiﬁed by a
top-down approach but also when one attempts to deﬁne it with reverse engineer-
ing. An oscillator has numerous qualities, including rhythmicity, period, ampli-
tude, duration of the duty cycle, entrainability, and robustness. Each of these
features may be determined or inﬂuenced by several components of the oscillat-
ing system. One component may be responsible for the rhythm, another may ad-
just cycle duration, and yet another is critical for its amplitude. Without a full
picture of all components and their interactions, it is often difﬁcult to identify the
necessary and sufﬁcient elements of the oscillator and to delineate their speciﬁc
contribution. The master–slave (i.e., pacemaker–follower) scheme is often difﬁ-
cult to justify, yet this relationship is frequently taken for granted in the neuro-
physiological literature. Occasionally, it is virtually impossible to draw a line
between a true but transient oscillator and systems with properties prone to oscil-
late: resonators.
Resonance
If you happen to be standing near a piano with its top open and drop an object on
the ﬂoor, you will see some of the piano strings begin to vibrate. This seemingly
trivial phenomenon is called resonance, a condition in which energy is fed into a

Synchronization by Oscillation
143
6. Buildup of energy in the object forces it to resonate. If the energy dissipates, the resonance
dampens. In the simplest case, a sudden energy pulse will start the oscillation, and its amplitude
dampens quickly over time and stops. When an external force is supplied periodically at a frequency
that matches the natural frequency of the object, it will begin to resonate. Adding the same forcing
function at just the right phase during the oscillation makes the oscillation’s amplitude grow larger and
larger, unless energy loss or a negative force buffers it. Because driving forces at frequencies larger or
smaller than the resonant frequency become less effective, resonators are also frequency ﬁlters. For
the same reason, two or more oscillators at similar frequencies can resonate.
7. The Arup Group Ltd.’s website at http://www.arup.com/MillenniumBridge/index.html offers a
detailed discussion about the challenges involved in building and securing this striking design. An-
other famous “bridge problem” was the collapse of the Tacoma Narrows Bridge in Washington State
in 1940. In the numerous news articles that covered the event and in undergraduate textbooks, the col-
lapse was presented as a real-world example of elementary forced resonance, but the real reasons are
still debated (Billah and Scanlan, 1991).
8. The terms “upstream” and “downstream” imply that impulses travel in only one direction, as the
ﬂow of water. Given the multiple loops and high-dimensional organization of neuronal connections,
these terms are often misleading. This is particular true in oscillating networks.
system at the natural frequency of the system. In our example, the energy is
sound, the system is the piano, and the resonant frequency corresponds the natu-
ral frequency of the responding strings.6 A good piano has good resonance be-
cause it ampliﬁes the sound. Oftentimes, resonance is unwelcome because it
ampliﬁes events we want to avoid. Engineers of bridges and skyscrapers con-
stantly struggle with unwanted resonance. You might think that, with the advent
of powerful computers, all possible conditions and potential dangers to such
structures could be simulated and catastrophes prevented. Not quite. As recently
as the summer of 2000, the Millennium Bridge, designed for pedestrian trafﬁc be-
tween St. Paul’s Cathedral and the Tate Modern Gallery in London, was closed
only 3 days after its grand opening ceremony. Prior computer simulations and
wind tunnel tests of the design had guaranteed that the bridge could withstand a 1
in 10,000-year return period for lateral wind forces. What was not tested or
thought of in advance was how people walking across the bridge could introduce
horizontal vibrations into the structure. Authorities closed the bridge immediately
with the tentative diagnosis of resonance. It took more than a year and an addi-
tional £5 million to investigate and ﬁx the problems. My real point is, however,
that bridge failures happen not because of negligence but because oscillatory be-
havior in complex systems is not well understood.7 If bridges are not complex
enough, consider a neuron.
Oscillation and Resonance in Single Neurons
Before the 1980s, the main functions of a neuron were thought to be collecting
information about its inputs (integrate), deciding how much information was
enough (threshold), and sending this information, in the form of an action poten-
tial (ﬁre), to its downstream peers.8 Neurons and networks were believed to be
silent unless excited by some outside sensory input. Intrinsic or spontaneous

144
RHYTHMS OF THE BRAIN
9. Channels are the structural units within the membrane that allow ion movement between extra-
cellular and intracellular environments. The mechanism that regulates the probability and duration of
the open state of the channel is referred to as “gating.” Gating of ion channels operates through four
different mechanisms: voltage gating, ligand gating, ion-dependent gating, and second-messenger gat-
ing. These four processes can cooperate dynamically. Membrane channels are more or less ion selec-
tive, i.e., preferably permeable to certain ionic species (K+, Na+, Cl–, Ca2+). When the permeability to
a given ion increases, the membrane potential shifts to the equilibrium potential of this ion, where the
tendency for net diffusion along the concentration gradient is exactly equal and opposite to the force
exerted by the electrical gradient (the membrane potential). Hence, at the equilibrium potential, no net
movements of that particular ion take place. However, most ion channels are not perfectly selective.
Distinct channel types are characterized by their reversal potential, where none of the individual ion
species is at equilibrium, but the total current carried by them sums up to zero. Conductance (the in-
verse of resistance) is a measure of how easily ions move across the membrane, and it depends on both
the probability channel openings (i.e., permeability) and the concentration of permeable ions. The
electrical driving force is the difference between the reversal potential and the prevailing membrane
potential. Hence, the total ionic current (I) that ﬂows across a population of channels at any given in-
stant is obtained from a modiﬁcation of Ohm’s law, where I=conductance ×driving force. Important
books on ion channels are Johnston and Wu (1994), Kaila and Ransom (1998), Koch (1999), and Hille
(2001). For shorter reviews, see Kaila (1994) and Segev and Rall (1998).
activity was described as a regular feature only in “primitive” neurons of inver-
tebrates and in some “special” central pattern generators responsible for respira-
tion, walking, and other rhythmic motor events. From this comfortable
perspective, it appeared that studying the collective behavior of a large enough
number of appropriately connected integrate-and-ﬁre nodes (“neurons”) would
provide sufﬁcient insight into the large-scale operations of the brain. In line with
the program outlined by Turing (see Cycle 1), complexity was believed to be hid-
ing in the special connectivity of uniform threshold detectors. That happy hon-
eymoon of connectionist modeling came under ﬁre in a milestone review in
1988, written by Rodolfo Llinás. The simple yet revolutionary message of his
single-neuron manifesto was that neurons do a lot more than just passively inte-
grate. The process that led to our current neuron concept was made possible by
two critical innovations: the in vitro brain slice and the patch-clamp recording
method, which allowed for a detailed and systematic examination of the bio-
physical features of neurons (see Cycle 4 for brief descriptions of these tech-
niques).
The active neuron concept brought about a fundamental change in our think-
ing regarding the abilities of single neurons. The old view of the neuron as a
bistable, well-behaving integrate-and-ﬁre device was rapidly transformed. To-
day, we consider the neuron to be a dynamic piece of machinery with enormous
computational power. The conceptual change can be attributed largely to the dis-
covery of dozens of channels in the cell membrane, which allow differential
movement of ions between the inside and outside of the cell. The open or closed
state of these membrane channels is under the control of the membrane voltage,
neurotransmitters and modulators, and other factors.9 Voltage-gated channels
are open only in a particular voltage range. In other words, the transmembrane

Synchronization by Oscillation
145
10. The power spectrum of “intrinsic” (i.e., non-synaptic) noise often takes the form of 1/f (Diba
et al., 2004; for a review, see DeFelice, 1981). The computational analysis by Abbott and LeMasson
(1993) nicely illustrates the consequences of dynamic regulation of conductances. The persistent Na+
current (White et al., 1998b, 2000) and slow K+ currents (Liebovitch and Tóth, 1991; Manwani and
Koch, 1999) have been suggested to be the major sources of intrinsic noise. Importantly, these same
channels are thought to be key players in subthreshold oscillations (Alonso and Llinás, 1989; Llinás,
1988).
11. For important physiological effects of Ia, see Hoffman et al. (1997). Ih channels have been
studied extensively by Magee and colleagues (Magee, 2003; Magee et al., 1998). HCN1 channels, the
molecular name for one type of Ih, increase fourfold from the soma to the distal dendrites (Lõrincz et
al., 2002). For reviews on other channels, see Brown (1988), Storm (1990), and Vergara et al. (1998).
Single-neuron models with detailed channel kinetics are described in Traub et al. (1994), Traub and
Miles (1991), and Borg-Graham (1998).
voltage “gates” the channels’ open/closed states. More precisely, the probability
of their being open depends on the membrane potential, because channel open-
ing and closing are probabilistic events.10 The magnitude of ionic current that
ﬂows through a single channel is called conductance. If many Na+ channels are
open at the same time, the ionic driving force across the membrane is large;
therefore, the depolarizing current is strong. We have already discussed two
voltage-gated channels. These are the Na+ inﬂux and K+ outﬂux-associated con-
ductances responsible for the main part of the action potential (Cycle 4). The
new knowledge supplied by the many biophysicists using the in vitro slice
preparation is that there are many different voltage-gated channels, which are
selective for a particular ion species and activated at various potential ranges
with different kinetics. Other channels were shown to increase their open prob-
ability not by voltage but by various ligands, for example, neurotransmitters and
drugs. Activation of yet another family of conductances depends on a critical
concentration of other ions. For example, a particular class of K+ channels is ac-
tive only after a sufﬁcient level of Ca2+ enters through the membrane. Impor-
tantly, these channels are distributed nonuniformly in the membrane. Some of
them are present only in the soma, others in the dendrites with some regularity
as a function of the distance from the soma. Prime examples include the tran-
sient K+ channel (Ia) and the hyperpolarization-activated mixed cation current
(Ih) (ﬁgure 6.3).11
So why are there so many channels? For one thing, different channel species
have different temporal activation kinetics. Therefore, their complex dynamics,
rather than a simple threshold, determine how eagerly and precisely the neuron
responds to a given input. The newly found variety of voltage-, ligand-, ion-, and
second-messenger-gated conductances endow neurons with intrinsic properties
capable of generating a rich repertoire of activities, including oscillation and res-
onance at multiple frequencies. Single neurons respond with transient oscillations
to a strong input. The natural frequency, or “eigenfrequency,” of the damped os-
cillation is a result of two opposing effects. The passive leak conductance and ca-
pacitance of the neuronal membrane are mainly responsible for the low-pass

146
RHYTHMS OF THE BRAIN
open
close
K
Figure 6.3. Pores or ion channels in the lipid membrane allow for the rapid and selective
ﬂow of inorganic ions (e.g., K+ and Na+) across cell membrane and are responsible for the
generation of electrical signals inside and outside the neuron. Binding of neurotransmitters
or the cell’s membrane voltage controls the gating (opening and closing) properties of
channels.
12. Pike et al. (2000) demonstrate this general principle by comparing pyramidal cells and in-
terneurons in the hippocampus. Pyramidal cells show a subthreshold resonance to inputs at theta fre-
quencies (2–7 hertz) in vitro, whereas fast-spiking interneurons resonate at beta–gamma frequencies
(10–50 hertz).
ﬁltering property of neurons. As a result, responses of a passive neuron become
progressively less reliable at higher frequencies. On the other hand, several
voltage-gated currents, whose activation range is close to the resting membrane
potential, act as high-pass ﬁlters, making the neuron more responsive and precise
to faster trains of spikes. Neurons in which such conductances dominate are more
efﬁcient in transmitting fast inputs than slow inputs.12
The appropriate combination of high-pass (voltage-dependent) and low-pass
(time-dependent) ﬁltering properties of neurons can be exploited for the con-
struction of biological resonators (band-pass ﬁlters), “notch” or band-stop ﬁlters,
and subthreshold oscillators (ﬁgure 6.4). These resonant-oscillatory features al-
low neurons to select inputs based on their frequency characteristics. When em-
bedded in an oscillatory or otherwise time-varying network, the time course and
magnitude of the input predictably and continuously bias the open time probabil-
ity of a multitude of ionic channels. If afferent activity is tuned to the preferred
constellation of the neuron or part of it, the input will be ampliﬁed. If not appro-
priately tweaked, the neuron may elect to ignore the input altogether or respond
with a considerable delay. The initiation and spread of the action potential are the
result of a complex negotiation between afferent activation and the intrinsic fea-
tures of the neuron. A neuron is a complicated resonator like a Stradivari violin,
not necessarily tuned to a particular fundamental frequency, but endowed with a

Synchronization by Oscillation
147
13. In contrast to the neuron, the violin is a linear system, with the same Fourier components or
“partials” appearing at the output of the violin as are generated by the sawtooth force of the bowed
string. The amplitude of each partial in the radiated sound is determined largely by the mechanical
resonances of the bridge and by the body of the instrument. Neurons, on the other hand, can dynami-
cally change their resonant properties, as if the musician changed instruments between notes.
rich response repertory over a wide range of frequencies.13 Moreover, its re-
sponse can be tuned by the large numbers of conductances that are differentially
distributed in the somatodendritic membrane. Potassium channels are especially
important in this process, because they counteract the input-induced depolariza-
tion and set limits on the overall excitability by controlling the interspike inter-
vals. Potassium channels have the greatest diversity, with gating kinetics that
spans several orders of magnitude. Importantly, they can be regulated by a variety
of neuromodulators and cellular signals separately or in combination. For example,
Input current
Output voltage
Impedence
FFT output
FFT input
log (frequency)
Magnitude

Circuit
(a)
(b)
(c)
(d)
Figure 6.4. Resonant properties of neurons constrain them to respond most effectively to
inputs at biologically important frequencies such as those associated with brain oscilla-
tions. Resonance is a property of the impedance (deﬁned as frequency-dependent resis-
tance). The frequency-dependent change of impedance can be determined by probing the
circuit with an input current of varying frequency but constant amplitude (left column) and
by observing the voltage response (third column). Passive neurons (with resistivity and ca-
pacitive features) act as low-pass ﬁlters. In contrast, active properties (e.g., voltage- and
frequency-dependent synaptic currents) can act as high-pass ﬁlters. Most neurons, there-
fore, respond preferentially to inputs at a particular frequency. Reprinted, with permission,
from Hutcheon and Yarom (2000).

148
RHYTHMS OF THE BRAIN
14. D’Angelo et al.’s (2001) modeling experiments indicate that slow K+ currents (IKS) can affect
the resonant properties of neurons and increase the reliability of spike timing at the preferred rhythmic
input. The persistent sodium current (INaP) had the opposite effect. See also Hunter et al. (1998). In ac-
cordance with the computational modeling predictions, activation of slow K+ conductances in vivo in-
creased the temporal precision of spikes in the gamma frequency range (Penttonen et al., 1998). For
an early example of neuronal resonance, see Knight (1972).
15. The reviews of Hutcheon and Yarom (2000) and Izhikevich et al. (2003) are excellent sources
on neuronal resonance and ﬁltering. For frequency differences in ﬁltering ability by cortical pyrami-
dal cells and different classes of inhibitory interneurons, see Markram et al. (2004), Gupta et al.
(2000), Thomson (2000a,b), Pike et al. (2000), and Fellous et al. (2001). For theoretical background,
see Abbott et al. (1997).
16. For an expanded argument for the same point, see Mainen and Sejnowski (1996) and Steriade
(2004).
the amounts of neuromodulators released in the waking brain are much higher
than in the sleeping brain, and activation of K+ channels can increase spike tim-
ing reliability of cortical neurons at higher frequencies.14 The ion composition of
the various channels shows a large diversity among the various neuron types. As
a result, cortical neuron classes have a wide range of preferred frequencies and
spike timing properties, and their diverse frequency-tuning properties are im-
portant for setting network dynamics. For example, GABAergic interneurons
respond with highest temporal precision to frequencies in the gamma band,
whereas pyramidal cells respond more reliably to lower frequency rhythmic
inputs.15
The astonishing conclusion from contemporary biophysics is that every part of
the neuron can function as a resonator-oscillator. All the neuron needs is channel
activity with opposing actions and feedback to sustain the ying-yang game. Thus,
a single neuron consists of myriads of potential resonators whose properties dif-
fer due to the different channel properties and densities of the membrane along
the somatodendritic and axonal surface. When a cell discharges at low and mod-
erate frequencies, the distributed conductances are well coordinated, as expected
from the large numbers of coupled relaxation oscillators. However, at high fre-
quencies, the temporal choreography across the neuron becomes less perfect due
to the inequalities of channel distribution in the different surface domains of the
neuron. These simple biophysical considerations explain why the upper limit of
the output of cortical pyramidal cells is a few hundred spikes per second, and why
only much lower frequency spiking can be maintained in the distal dendritic ar-
bors. Single-neuron behavior, therefore, is a direct consequence of the proper co-
ordination of membrane channels along the somatodendritic domains of the
neuron. The selective control of these channels by the network, in which neurons
are embedded, is the reason behind my earlier claim that single neurons can per-
form in multiple ways.16
One can make the reasonable argument that oscillatory spiking in isolated
leaky neurons has little to do with their routine behavior in the intact brain. In-
deed, oscillatory spiking is easy to predict and therefore carries very little infor-
mation. Furthermore, statistical characterization of spikes of individual cortical

Synchronization by Oscillation
149
17. Numerous factors may be responsible for the apparent stochastic nature of single-unit dis-
charge. The debate is reminiscent of the controversy between 1/f and the rhythmic nature of an EEG
(Cycle 5). Investigators examining long-term ﬁring patterns always ﬁnd Poisson statistics in neuronal
discharge activity (Bair et al., 1994; Koch, 1999; Shadlen and Newsome, 1994, 1995, 1998; Shadlen
et al., 1996; Shadlen and Movshon, 1999), whereas researchers using short-term segments, induced
by a certain behavior, often report on oscillations (König et al., 1995; Singer and Gray, 1995; Singer,
1999; Engel et al., 2001) or nonrhythmic but phase-locked discharge to ﬁeld oscillations (Garcia-
Sanchez, 1978; Csicsvari et al., 1999).
18. Cohen and Miles (2000).
19. Harris et al. (2003b). These experiments, however, tell us only that pyramidal cells can os-
cillate in isolation under the right circumstances. Under different conditions, they may ﬁre only a
few action potentials with decreasing frequency and stop discharging altogether. This accommoda-
tion of discharge frequency is due to several voltage- and ligand-dependent conductances that are
activated by the spike-induced depolarization and Na+ inﬂux. However, once channels mediating
these conductances are blocked, the neuron’s spiking can become clocklike again (Penttonen et al.,
1998).
pyramidal cells in the intact brain does not give the impression of autorhythmic-
ity. The apparent lack of rhythm at the single-cell level has been the source of
some heated discussions about the role of oscillations and the nature of the neu-
ronal code.17 The issue can be formulated this way: is the default activity pattern
of cortical pyramidal cells irregular discharge, or is the observed irregularity due
to the property of the network they are embedded in? If the irregular ﬁring pattern
of neurons is due to their input control, then neurons in isolation should reveal
their true nature. Richard Miles at the Pasteur Institute in Paris pharmacologically
blocked the receptors responsible for excitation and inhibition in the hippocam-
pus. Removal of excitation led to decreased excitability, whereas removal of inhi-
bition enhanced activity, as expected. The surprise came when both types of
receptors were blocked. Now neurons ﬁred at a much higher rate and relatively
rhythmically compared to the baseline in vitro conditions. Miles concluded that
the default pattern of their recorded neurons was discharge, not silence.18 The rea-
son most neurons are silent (nondischarging) when they are part of the network is
that physiological conditions provide a strong enough inhibition to change the de-
fault spiking activity of single cells into relative silence. The advantage of this
arrangement is easy to see. If neurons were discharging at high rates all the time,
the network would become noisy and neuronal impulse trafﬁcking in large net-
works would be overwhelming and not particularly useful.
Ken Harris and Peter Barthó in my laboratory carried out a different but
equally revealing experiment in the intact somatosensory cortex of the anes-
thetized rat. Our original goal was to separate the recorded cells into some ra-
tional groups on the basis of their ﬁring patterns. There were two large groups,
rhythmic and nonrhythmic. The striking observation was that the oscillation in in-
dividual neurons in the rhythmic group, pulsing at 7–13 hertz, went on indepen-
dent of each other and of the local ﬁeld, as if in an orchestra the players were not
paying attention to either the other players or the conductor. We concluded that
the anesthetic freed the neurons from their network obligations, and therefore, we
could see their true individual behavior: oscillation.19

150
RHYTHMS OF THE BRAIN
20. An experiment by Moutoussis and Zeki (1997) illuminates this point. If a stimulus is moving
at 2 hertz, and the phase of movement and change of color occur simultaneously, it is very hard to tell
when the color change occurs. A potential explanation of this observation is that processing of differ-
ent features (motion and color) requires different brain circuits and different processing times. The
subjects misbind the color and the direction of motion because color and motion are perceived sepa-
rately and at different times, color being perceived ﬁrst. In other words, the brain regards visual attrib-
utes as synchronous that are perceived together, rather than ones that occur together in real time.
Collective Neuronal Behavior Can Be Established
through Synchrony
If you have seen Luis Bravo’s Broadway extravaganza Forever Tango, you can
picture the qualitative essence of neuronal synchrony: coupling through time by
some invisible links. The essence of this sensuous dance that has enthralled both
dancers and audiences for more than a century is the constant battle for control by
either partner. However, there is no forcible action involved whatsoever. Instead,
subtle facial expressions, harmonic body movement, light touch, and other invisi-
ble magic link the partners’ swing in perfect unison.
Now we have a soft description of synchrony. However, providing a quantitative
deﬁnition that satisﬁes physicists, engineers, and neuroscientists alike is a different
matter altogether. In its broad deﬁnition, synchrony refers to the concurrence of
events in time, a relation that exists when things occur simultaneously, such as two
or many neurons ﬁring within a short time interval. Events that occur at different
times are asynchronous. Although this deﬁnition of synchrony is found in most
textbooks, it is not particularly useful. For two observers to have expectations of
something occurring “at the same time” is meaningful only if they see the same
clock. Furthermore, a “discrete time window” should be deﬁned for the judgment
of simultaneity. Otherwise, it is impossible to name the time at which something
occurs. If the same tune is played at the same time on the radio in both London and
New York City, and the London broadcast is transmitted through the Internet, the
tunes played by a radio and a computer in New York will not be judged as being si-
multaneous by a human listener. The same is true for an observer neuron that re-
ceives inputs from other neurons with different physical distances. If the difference
in travel time of the action potentials from the presynaptic neurons is too long, the
target neuron may treat them as asynchronous (separate) events.20 In plain English,
time alone cannot deﬁne the functional meaning of synchrony.
The judgment of simultaneity or synchrony of events is made by the observer,
for example, a single neuron. Therefore, to be a useful concept in the brain, syn-
chrony requires a discrete temporal window determined by a neuron or a neuronal
pool. This period can be deﬁned by the time within which some trace of an earlier
event by one input is retained, which then alters the response to a subsequent
event to other inputs. For a neuron, events that can be integrated over time (e.g.,
postsynaptic potentials) by some intrinsic mechanisms are therefore synchronous.
The relevant temporal window for integration is the time within which a unitary

Synchronization by Oscillation
151
21. Time constant is the time at which the change in potential ∆V decays to 1/e (∼37 percent) of
its peak value. The time constant varies as a function of input resistance (increases with increasing
membrane resistance because the electrical charge dissipates slower when the membrane is less leaky)
and membrane capacitance (increases with increasing membrane capacitance because the electrical
charge dissipates slower if the membrane has a higher charge storage capacity). The time constant for
a passive cortical neuron is 10–50 milliseconds (Hille, 2001; Johnston and Wu, 1994; Koch, 1999).
However, this ﬁgure refers to an inactive neuron with very high input resistance. Neurons in the intact
brain are under constant bombardment from other neurons. These inputs activate channels, make the
neuron leaky, and can reduce the neuron’s input resistance several-fold (Kamondi et al., 1998; Borg-
Graham et al., 1998; Paré et al., 1998; Destexhe et al., 2003). Importantly, in the waking animal, input
resistance can be strongly affected by subcortical neurotransmitters, affecting mainly K+ channels
(Steriade and Timofeev, 2003). Synchrony from the neuron’s point of view, therefore, ﬂuctuates as a
function of network activity.
postsynaptic potential, brought about by one input, decays back to baseline.
Events that occur beyond this window are deemed nonsynchronous, because the
earlier event does not have any impact on the later response. The term that most
often refers to this decay is the membrane time constant of the neuron, which cor-
responds to tens of milliseconds in passive cortical pyramidal neurons.21 So if
synaptic inputs arrive no more than a few tens of milliseconds apart, they are syn-
chronous from the neuron’s point of view.
For real neurons, however, the integration time window is much harder to de-
termine and depends on a variety of factors, such as replenishment of the neuro-
transmitter in the presynaptic terminal, the actual resistance of the membrane,
receptor types, the immediate spiking history of the neuron, and the state of the
various conductances in general. When the neuron is very active, it becomes
leaky and can integrate over a much shorter window than at times of low activity.
Other intrinsic mechanisms can expand the temporal span of integration. In other
words, the time window of synchrony from the neuron’s point of view varies over
a wide temporal range and can be much shorter or longer than the membrane time
constant of a passive neuron. As a result, a “single neuron moment” within which
the neuron can integrate afferent activity is only tens to hundreds of milliseconds,
not long enough to be useful for holding even a telephone number.
The effective integration window for synchrony can be much longer than the
membrane time constant when it applies to a group of interactive neurons. For a
group of neurons, the window size is typically determined by the readiness period
of the ongoing population oscillation. The duration of the readiness state of the net-
work oscillator, now at the neuron group level, determines the window of synchro-
nization, which can be much wider than the properties of its constituent neurons
would predict. The slower the rhythm, the wider is the window of opportunity for
synchronization. In a wider time window, more neurons can be recruited from
larger brain areas because synaptic and axonal conductance delays are less limiting;
thus, the spatial extent of synchrony is much larger in the case of a slow rhythm.
The time window of synchronizing effects depends on the nature and details of
the oscillator. For a harmonic oscillator, synchronizing forces should arrive in less
then half the cycle period of the oscillator; otherwise, different subsets will ﬁre
out of phase and the network oscillation dies. For example, in the gamma

152
RHYTHMS OF THE BRAIN
22. Karl Friston (2000) suggests that synchrony is just one possibility of neuronal communication.
On theoretical grounds, he speculates that asynchronous coding provides rich, context-sensitive inter-
actions. Indeed, if you know the transformation code between “ti-ti-ti, ta-ta-ta, ti-ti-ti” and S.O.S. and
what the abbreviation stands for (Save Our Souls, the cry sent repeatedly by the radio operator of the
Titanic), there is no need for synchrony. Although similar sequential activation of neuronal groups is
surely a routine operation in the brain, it is not clear how a single neuron can be efﬁciently discharged
by asynchronous activity of its upstream peers.
frequency range (e.g., 50 hertz), excitatory inputs to all members should arrive
within 10 milliseconds (half the period) to enhance the oscillation. Interestingly,
this time window may be wider for coupling of relaxation oscillations. Because
relaxation oscillations have unequal integration and output phases, the critical
time windows vary depending on the nature of forces. For example, if in our
gamma oscillator example the ratio between the accrual and duty-cycle phases is
4 to 1, inhibitory effects that tend to prevent early discharge have a time window
of 16 milliseconds, whereas excitatory effects leading to neuronal discharges
should arrive within only 4 milliseconds to maintain steady oscillation. The wider
effective window for inhibition explains why inhibitory interneurons are so criti-
cal in clocking functions of the brain (Cycle 3). In summary, synchrony in neu-
ronal networks can vary from milliseconds to seconds or even longer, depending
on the period and exact architecture of network oscillations. The slower the oscil-
lation, the less it depends on fast conducting long-range connections.
Synchronization is one of nature’s most persuasive drives, extending from
atoms to neurons, from the stock market to hurricanes. Synchrony occurs when
some forces bring the events together in a given temporal window, determined by
some systematic time constant built into the system. The real “cause” of syn-
chrony is not always obvious. Some events, such as excitation, actively facilitate
temporal cohesion. Alternatively, some events, such as refractoriness or inhibi-
tion, actively prevent the occurrence of an output and thereby regulate the proba-
bility of occurrence of the duty cycle. Excitatory feedback in recurrent neuronal
networks is an especially effective method of recruiting large numbers of neurons
within a short time period. A main physiological advantage of synchrony is that it
brings about a rapid and large rise of population ﬁring rate. 22
Although stimulus-induced synchronization is often associated with increased
ﬁring rates of the responding neurons, ensemble synchrony can occur also in the
absence of ﬁring rate changes in individual neurons. In the latter case, increased
synchrony is not possible to identify with standard single-unit methods because
spikes of a single neuron do not inform us about cooperative performance. For ex-
ample, during rest and slow-wave sleep, the ﬁring patterns of individual hip-
pocampal pyramidal neurons are characterized more or less by Poisson statistics.
However, looking at a larger population can reveal an alternative perspective. Ob-
serving the neuron population as a whole, irregularly occurring, strongly syn-
chronized ensemble patterns become obvious. From time to time, in 80- to
150-millisecond time windows, up to 18 percent of the pyramidal cells discharge
a spike or a complex-spike burst, representing the most synchronous physiological

Synchronization by Oscillation
153
23. The emergence of this self-generated synchrony in the hippocampus takes the form of a fast
(140–200 hertz; “ripple”) transient oscillation in the pyramidal cell layer of the CA1 region (Buzsáki
et al., 1983, 1992; Buzsáki, 1989; O’Keefe 1976; Ylinen et al., 1995a; Csicsvari et al., 1998, 1999,
2000; for ripples in humans, see Bragin et al., 1999). Subsequently, we identiﬁed an analogous but
even faster transient ripple synchronization in the somatosensory cortex of the rat (Kandel and
Buzsáki, 1997; see also Jones and Barth, 1999; Grenier et al., 2001). Such fast patterns have been also
reported from scalp recordings in humans (Curio et al., 1994), but their physiological or artifactual na-
ture could not be established until they were observed in animal experiments. Fast (600 per second)
oscillations have also been documented by magnetoencephalography in the piglet’s somatosensory
cortex in response to stimulation of the snout (Ikeda et al., 2002). The authors suggest that at least part
of the oscillation is due to synchronous spiking in the thalamocortical terminals.
24. Vaadia et al. (1995).
25. An important practical implication of the information transfer by synchrony is that such im-
portant changes may remain undetected by fMRI.
discharge pattern of the mammalian cortex. Obviously, such powerful population
synchrony should have a profound inﬂuence on the downstream targets of the co-
operating neurons, and without synchrony, no such effect is expected because in-
dividual neurons do not change their pattern or rate noticeably.23
Several fundamental points can be deduced from these observations. First, a
population of neurons can have an explicit temporal dimension not present in the
dynamics of single cells. Second, population synchrony, and hence enhanced out-
put, can emerge even without modulation of the ﬁring rates of individual neurons.
Third, mean ﬁeld activity, representing the spatial-temporal statistical properties
of the nearby neuronal population, can serve as a useful reference to which activ-
ity of single neurons can be related. Some of these same points were discussed by
Eilon Vaadia and colleagues at the Hebrew University in Jerusalem.24 They
recorded from pairs of neurons in the monkey neocortex in response to a mean-
ingful stimulus and observed that the degree of the neurons’ coherent ﬁring
changed in response to behaviorally relevant events, even though the ﬁring rates
of the neurons did not necessarily alter. Unfortunately, no local ﬁeld potential was
recorded in these experiments, so it remains to be revealed whether coherent
changes at the population level were reﬂected by the mean ﬁeld statistics. The
most important message of these empirical observations in various cortical struc-
tures and species is that the information about the input can be embedded in the
dynamic change of temporal synchrony even without an alteration of discharge
frequency. And if no extra spikes are required to transfer information, no extra
energy is needed.25
External and Internal Sources of Synchrony
A synchronizing inﬂuence can be an outside force or can emerge from within a
self-organized system. Most often, these distinct inﬂuences cooperate, and it is
difﬁcult to distinguish their true origin. A useful example is the conductor’s con-
trol over the members of an orchestra. If the cellists, ﬁrst violinists, and other

154
RHYTHMS OF THE BRAIN
26. In experimental practice, disentangling stimulus-induced synchronization from network-
induced synchronization is not simple because the percentage of coincident spikes increases as the
square of the combined ﬁring rate of neurons, even if they ﬁre completely randomly. Induced rhythms
usually do not have a time-locked relationship to the input (see Cycle 9).
27. Information-theoretic analysis revealed that the responses encoded only approximately 1 bit
per second about constant-velocity stimuli but up to 29 bits per second about the time-varying stimuli
(Buracas et al., 1998). Similarly, Ruyter van Steveninck et al. (1997) showed that the motion-sensitive
neurons in the ﬂy’s visual system responded with irregular ﬁring patterns to constant-velocity motion.
However, more natural, moving signals yielded more reproducible spiking, in terms both of timing
and of counting precision. They also found that temporal information about the spikes carried twice
the amount of information as an equivalent (Poisson) rate code. These in vivo ﬁndings are reminiscent
of the precisely repeating ﬁring patterns of cortical pyramidal cells in response to intrasomatic injec-
tion of noisy depolarization (Mainen and Sejnowski, 1995). An explanation for these highly reliable
repeating patterns is that the threshold of the action potential depends on the trajectory of the preced-
ing postsynaptic potential and the immediate spiking history of the neuron (Azouz and Gray, 1999;
Henze and Buzsáki, 2001). For behaviorally relevant examples of temporal patterning in central struc-
tures, see also deCharms and Merzenich (1996).
28. Analyses of spike trains in response to the same physical signal show that the coefﬁcient of
variation is usually close to 1, a telltale sign of an underlying Poisson process (Softky and Koch, 1993;
Bair et al., 1994; Shadlen and Newsome, 1998; Stevens and Zador, 1998; but see Fenton and Muller,
1998; Csicsvari et al., 1999).
players are randomly placed in the concert hall, and if the musicians’ ability to
listen to others is attenuated by placing wax in their ears, the conductor-mediated
orchestration would still be apparent. Conversely, the piece can also be played
without the conductor, based exclusively on intraensemble interactions. Similarly,
the precise timing of central neurons depends not only on the physical inputs but
also on the exchange of signals among central neuronal ensembles. These two
sources of synchronization, externally driven and self-generated, should be dis-
tinguished because their tuning roles are often very different.26
External inﬂuence can be readily detected in early sensory pathways but can
also be recognized even at higher order cortical centers. A particularly nice ex-
ample of temporal patterning in the mid-temporal cortex of the monkey was pro-
vided by Tom Albright and his colleagues at the Salk Institute. They compared the
effects of either constant-velocity or time-varying visual stimuli on neuronal re-
sponses. The responses to both stimulus conﬁgurations were characterized as
rate-modulated Poisson spikes. Surprisingly, the speed at which the time-varying
stimuli moved was reﬂected by the temporal precision of neuronal spikes within 3
milliseconds, on average. In this and other examples,27 temporal coordination of
ensemble synchrony is brought about by inputs from the physical world, much
like the conductor’s inﬂuence on the members of a symphony. Stimulus-related
temporal coordination can be revealed by repeating the same physical signal and
observing common features of the response. Since the early days of sensory neu-
rophysiology, it has been known that neuronal responses vary considerably from
trial to trial. This variability has been traditionally thought of as “noise” that
should be averaged out to reveal the brain’s true attitude toward the input.28 How-
ever, the source of noise has never been identiﬁed and has been assumed to result
from the brain’s imperfections.

Synchronization by Oscillation
155
There are only two sources that control the ﬁring patterns of a neuron at any
time: an input from outside the brain and self-organized activity. These two
sources of synchronization forces often compete with each other (Cycle 9). If
cognition derives from the brain, this self-organized activity is its most likely
source. Ensemble synchrony of neurons should therefore reﬂect the combination
of some selected physical features of the world and the brain’s interpretation of
those features. Even if the stimulus is invariant, brain state is not. From this per-
spective, the most interesting thing we can learn about the brain is how its self-
generated internal states, the potential source of cognition, are brought about.
Extracting the variant, that is, brain-generated features, including the temporal re-
lations among neuronal assemblies and assembly members, from the invariant
features evoked by the physical world might provide clues about the brain’s per-
spective on its environment. Yet, this is the information we routinely throw away
with stimulus-locked averaging.
Stochastic Resonance
The optimal performance of man-made devices can be notoriously deteriorated
by the presence of noise. But noise is not necessarily bad. An oft-quoted beneﬁ-
cial aspect of noise in bistable systems, for example, neurons, is its ability to am-
plify hidden periodic signals under certain conditions. Consider a rhythmic input
to a neuron that produces depolarization at regular intervals but always below
threshold. Because the neuron does not spike, its oscillatory state is not informed
to downstream neurons. However, if a neuron also receives a Gaussian (white)
noisy input, which alone would not discharge it, the noise and the periodic signal
add up, resulting in an occasional action potential, timed by the depolarizing
phase of the input. This signal combination is known as stochastic (probabilistic)
resonance (ﬁgure 6.5). It is a phenomenon where a weak signal is detected or
transmitted optimally in the presence of noise. Because it is unpredictable when
the combination of the random noise and the periodic signal supersedes the
threshold, the output spikes will occur seemingly randomly. In effect, the noise re-
moves the apparent predictability of the oscillation. However, analyzing large-
enough intervals between spikes, the statistical distribution of spike intervals can
identify an underlying periodicity at the same frequency as the input. In this sim-
ple example, noise can help convey the signal through the neuron by facilitating
its spiking. This is the main reason why noise can maintain spontaneous activity
in computer models of neural networks. Signals become detectable due to reso-
nance between the weak deterministic signal and stochastic noise. Stochastic res-
onance thus appears as a mechanism for extracting information from weak
periodic signals. Although rhythmic stimuli are ubiquitous in all sensory modali-
ties, nonrhythmic, time-varying inputs can be detected by the same principle.
Stochastic resonance epitomizes noise-controlled onset of order in a complex
system in many ﬁelds of natural science. In the brain, stochastic resonance can be
useful for not only single cells but also for communication between cell assemblies

156
RHYTHMS OF THE BRAIN
Figure 6.5. Input feature extraction by stochastic resonance. Left: Combination of slow
and fasts oscillations can discharge a single neuron, when neither the fast nor the slow os-
cillatory inputs alone can. The output spike patterns contain information about the frequen-
cies of both inputs even if it occurs irregularly. Right: Stochastic resonance at the systems
level. Probability of occurrence of high-voltage spindles (y-axis) in the neocortex of the rat
is highest at a preferred magnitude of delta power in the preceding 2 seconds. The para-
bolic relationship between the event probability and delta power magnitude is the hallmark
of stochastic resonance. Modiﬁed, with permission, from Jandó et al., 1995.
29. The simplest stochastic resonant model is represented by a symmetric bistable process x(t)
driven by the combination of an external sinusoidal modulation and an additive random noise. The
amplitude of the periodic component of the process, x, grows sharply with the noise intensity, and af-
ter its maximum it decreases according to a power law (Benzi et al., 1981; Bulsara and Gammaitoni,
1996). The parabolic relationship of noise magnitude (inverted U-shaped curve) on signal detection is
the hallmark of stochastic resonance (Wiesenfeld and Moss, 1995). For examples of the beneﬁcial ef-
fect of external noise in models and perception, see Ward (2001).
or large systems within the brain. As discussed in the following Cycles, oscilla-
tory behavior in cell groups, modules, structures, and systems is state and context
dependent. Information from one place to another is transferred in small temporal
packages on a certain phase of the oscillatory cycle. A mechanism selectively
tuned to extract such messages and deduce the metric of the intrinsic dynamics of
the sending assembly is of great importance. This is where stochastic resonance
may be beneﬁcial for neuronal systems.
As one might expect, the amount of noise is critical for the proper ampliﬁca-
tion of the signal: too little noise and the signal does not get through, whereas for
larger noise amplitudes the signal increasingly gets corrupted. This noise-based
optimization is the essence of stochastic resonance. Noise can be added to the sig-
nal externally or internally by the brain.29 Although the term “stochastic reso-
nance” is the invention of physicists, the concept is quite familiar in psychology
and is known as the Yerkes-Dodson law, which describes an inverted U-shaped
function between arousal and performance. A corollary is that there are optimal

Synchronization by Oscillation
157
30. Yerkes and Dodson (1908).
31. In his challenge of the classical stimulus–response theories, Grossberg (1980) exploited the
advantages of stochastic resonance in his “adaptive resonance” theory. In his model, the bottom-up
and top-down pathways actively compare information and modify each other. A mismatch between
centrally generated expectation and the input signal leads to attenuation of the afferent signal, whereas
a match ampliﬁes its propagation.
32. Single neurons can respond in a highly reliable manner both in vivo and in vitro (Mainen and
Sejnowski, 1995; Kara et al., 2000; Buracas et al., 1998; Wehr and Zador, 2003; Fellous et al., 2004;
Ikegaya et al., 2004). When spiking history (Henze and Buzsáki, 2001) and peer neuron ﬁring effects
(Harris et al., 2003) are taken into quantitative consideration, precise spike timing is revealed even
when neurons are embedded in complex interconnected networks (Riehle et al., 1997). For the com-
putational advantage of sparse coding, see Levy and Baxter (1996).
33. Noise in the brain has yet to be shown to be controllable in ways useful for its operations
(Kelso, 1995). For an effect of stochastic noise on single-cell models, consult Ho and Destexhe
(2000); on small networks, see Gluckman et al. (1996).
34. Distinction between deterministic chaos and noisy quasi-periodic systems is not straightfor-
ward because in many cases their macroscopic behavior is equivalent (Rapp et al., 1993; Kelso, 1995;
Glass, 2001).
levels of arousal for each task to be learned.30 Viewed from the present context, an
important mechanism at work in arousal is stochastic resonance, an ampliﬁcation
of incoming signals by added neuronal noise.
Although signal ampliﬁcation through noise appears advantageous for the
brain, it has its own problems. A critical issue is the source of noise. Classical the-
ories, in which the brain is viewed as a stimulus-driven device, assumed that spike
response variability in response to an invariant input derives from unreliable indi-
vidual neurons.31 According to such view, a neuronal population can represent
consistent and coherent decisions, but single cells within the population can cast
different votes. These individually incongruent opinions are usually regarded as
wasted action potentials from the representational point of view and are consid-
ered the source of synaptic noise. From the “population code” perspective, sto-
chastic resonance is a clever mechanism because it can “recycle” the wasted
action potentials. However, in contrast to the population code model, numerous
recent works emphasize that action potentials are used sparingly in the brain, and
spiking of neurons is much more reliable than previously thought.32 If spikes are
used efﬁciently in the brain, then what is the source of noise that seems so critical
for the maintenance of spontaneous brain activity? Furthermore, if the brain has
to regulate its own noise level to enhance input sensitivity, noise utilization is not
so attractive anymore.33
The issue of noise generation invokes a broader theoretical problem. Finite
fractional dimension and the resultant scale-free behavior are typically regarded
as an indication of chaotic behavior.34 The 1/f dynamics of EEG may be inter-
preted that there are dedicated brain mechanisms for the generation of pink noise.
I suggest an alternative mechanism of noise production in the brain but with sim-
ilar beneﬁts: mixing of various oscillators. As discussed above, information
stored in a given phase of the oscillatory output of one structure could be effec-
tively read out by the target structure, provided that the faster oscillation in the

158
RHYTHMS OF THE BRAIN
35. The animal experiments were done by Jandó et al. (1995). There are many physiological ex-
planations available for explaining the “optimum” noise that results in an inverted U-shape level of ac-
tivity, including voltage-gated channels and competition between receptors with opposing actions for
the same neurotransmitter. For experiments in humans, see Collins et al. (1996) and Klinkenkaer-
Hansen et al. (2004).
36. A concise summary on the baseline problem of performance is Drive and Frith (2000). For a
discussion of the baseline problem in the imaging (PET, fMRI) ﬁelds, see Gusnard et al. (2001).
target is phase-locked to the input and the combination of the two oscillators suf-
ﬁciently depolarizes the neurons. Recall that the only function of noise in sto-
chastic resonance is to increase the magnitude of input variability so that the
subthreshold periodic input occasionally becomes effective in discharging some
of the target neurons. If so, this critical role can be played by a transient faster os-
cillation, instead of white noise. Ample empirical evidence is available for tran-
sient coupling between an oscillation in one structure and a faster oscillation in
another, a topic I discuss in more detail in Cycle 12. With such oscillatory cou-
pling, extraction of phase-coded information can be efﬁciently exploited by tak-
ing advantage of the mechanism of stochastic resonance without getting into the
trouble of generating metabolically costly noise. Viewed from this perspective,
dynamic coupling of neuronal oscillations as a source of noise should be regarded
as a beneﬁcial brain operation even for the most ardent opponents of brain
rhythms.
Experiments in animals and humans support the idea that the brain exploits
stochastic resonance. Examination of the relationship between background
EEG activity and the probability of occurrence of epileptic patterns in rats re-
vealed a parabolic relationship. Maximum probability of the abnormal pattern
is associated with a narrow range of delta power in the 2 seconds prior to the
events, whereas the probability decreased when delta power either increased or
decreased (ﬁgure 6.5, right). The parabolic relationship between the signal de-
tection and noise magnitude is the hallmark of stochastic resonance. The ongo-
ing EEG also has a deﬁnite relationship with psychophysical performance.
When subjects were requested to detect near-threshold tactile stimuli on the tip
of their index ﬁnger, the best performance was observed when the power of the
prestimulus alpha oscillation assumed intermediate values in the somatosen-
sory cortical area.35 The “optimum” level of noise in the jargon of stochastic
resonance may be the brain’s solution to the so-called “baseline shift” problem
of perception36 and motor activity precision and supports the long-held wis-
dom that “proper” level of brain activity is needed for optimizing behavioral
performance.
Emergence of Cell Assemblies through Synchrony
Donald O. Hebb was among the ﬁrst thinkers who explicitly stated that the brain’s
ability to generate a coherent thought derives from the spatiotemporal orchestration

Synchronization by Oscillation
159
37. Hebb (1949). Hebb’s concept has been advanced and reﬁned by Braitenberg (1978) and Abeles
(1982). Similar ideas emerged independently in the Soviet movement control group. Nikolai Bern-
stein’s school broke away from the hard-wired view of muscle control and, instead, suggested the
emergence of ﬂexible neuronal groups that are temporarily assembled to solve speciﬁc control tasks.
Bernstein hypothesized that movements result from the virtually inﬁnite variety of possible combina-
tions, or degrees of freedom, of neuromuscular and skeletal elements. Each movement pattern is con-
sidered to be a self-organized event assembled from the ﬂexible partnership of the controlling
neurons. Sequential activation of the various muscle groups of a limb is coordinated by different sets
of neurons active on different phases of a central oscillator. This idea is quite similar to Hebb’s notion
of ensemble sequences. Bernstein’s most inﬂuential book, On the Construction of Movements (O
Postroyeniis Dvizheniy, Medgiz, Moscow, 1947), was translated to English 20 years later (Bernstein,
1967). See also Gelfand et al. (1971) and Whiting (1984).
38. Hebb (1949, p. 62; italics original). This critical temporal relationship, considered one of
Hebb’s most important intuitions, has been known since the days of Ivan Petrovich Pavlov. The
essence of Pavlovian conditioning is that the conditional signal must consistently and repeatedly pre-
cede the unconditioned signal to bond an association so that the conditional signal can repeatedly and
consistently take part in evoking the unconditioned response (Pavlov, 1927).
39. In physical systems, hysteresis (Greek for deﬁciency) refers to history dependence.
of its neurons, which we refer to as the “cell assembly” hypothesis.37 Hebb’s cell
assembly is a transient coalition of neurons, much like the dynamic interactions
among jazz musicians. Members of the cell assembly are brought together by
Hebb’s synaptic plasticity rule, on the basis of temporal relations among them:
“When an axon of cell A is near enough to excite a cell B and repeatedly or per-
sistently takes part in ﬁring it, some growth process or metabolic change takes
place in one or both cells such that A’s efﬁciency, as one of the cells ﬁring B, is in-
creased.”38 As a result of this plasticity rule, information reverberates within the
formed assembly and the direction of ﬂow is determined by the synaptic strengths
among the members. Three hypothetical features are inherent in the cell assembly
hypothesis. First, activity within a cell assembly is synchronized more than pre-
dicted by the sensory input because neurons are interconnected and inﬂuence
each other. For the cell assembly hypothesis, the trial-to-trial variability of spike
trains is not a surprise, since the activity of a single cell is supervised by the group
of which the neuron is a part. Second, Hebb believed that activity reverberates in
loops of synaptically connected chains of neurons. This reverberation explains
why activity can outlast the physical presence of an input signal. In the language
of engineers, this refers to hysteresis, a reﬂection of nonlinearity in the system.39
Third, assembly membership is ﬂexible, so that a given neuron may be part of
several assemblies (ﬁgure 6.6). Of course, not every conceivable coincidental ﬁr-
ing of neurons meets the criterion of an assembly formation. Membership must
be reﬂected by a statistically reliable synchrony beyond chance.
Although much of contemporary cognitive neuroscience is based on Hebb’s
loosely deﬁned broad postulates, experimental veriﬁcation of his ideas had to
wait until the recording of large populations of neurons became possible in be-
having animals. Indirect support, however, has been available since the 1970s. E.
Roy John at New York University trained cats in a signal discrimination situation.
For example, the cats learned to respond to a 4 hertz but not an 8 hertz visual or

160
RHYTHMS OF THE BRAIN
Figure 6.6. Schematic of Hebb’s reverberating cell assemblies. Arrows represent not sin-
gle neurons but an “assembly” of neural pathways or open multiple chains ﬁring according
to the numbers on each. The same assemblies can participate more than once (e.g., path-
way 1,4 indicates that this subassembly of neurons ﬁres ﬁrst and fourth). The direction of
ﬂow is hypothesized to be determined by the synaptic strengths within and across assem-
blies. However, without inhibition or other means to restrain excitatory activity, progres-
sively larger groups of neurons and assemblies would be engaged, rather than reactivating
the same chain of 15 subassemblies repeatedly. Reprinted, with permission, from Hebb,
(1949).
40. John (1968) and John and Morgades (1969).
auditory stimulus. John and his colleagues observed that the evoked ﬁeld re-
sponses in many brain areas contained a component that was speciﬁc to the be-
havioral consequences rather than the physical features of the stimulus. They
called this component “readout from memory,” referring to the idea that this
modality-independent and widely distributed signal represented the “decision”
made by the animal on the basis of previous experience. A key aspect of their
work was the relationship between the “readout” component and behavior at
times when ambiguous stimuli (e.g., 6 hertz) were presented or when the animal
made an error. As predicted by the assembly hypothesis, the statistical features of
the readout component reﬂected whether the cat responded rather than the physi-
cal features of the signal, indicating that distinct patterns can be released from
memory.40
With the ability to record simultaneously from representatively large numbers of
cells from the hippocampus, we set out to test the cell assembly predictions directly.
Jozsef Csicsvari, Hajime Hirase, and George Dragoi working in my lab have al-
ready collected a large database in behaving rats. The receptive ﬁelds of hippocam-
pal neurons are characterized by the animal’s position in the environment (see

Synchronization by Oscillation
161
41. Hippocampal patterns and place cells are discussed in Cycle 11.
42. Harris et al. (2003a), Harris (2005) and Dragoi et al. (2003). Experiments by Wolf Singer and
colleagues in the primary visual cortex have already provided indirect evidence that neurons can be
part of one or more assemblies, depending on the conditions (e.g., Engel et al., 1991).
Cycle 11). Monitoring only the motor behavior of the animal, the best prediction
one can make about the precise temporal occurrence of spikes in single cells can be
made only from the momentary position of the rat.41 However, on some seemingly
identical trials, a place cell can ﬁre vigorously, whereas on others it remains silent.
Ken Harris and I reasoned that, if hippocampal cells are organized into cell assem-
blies, then members of the assembly can provide information not only about
whether a chosen recorded neuron ﬁres but also when, with a temporal precision that
is better than can be inferred from the animal’s overt behavior (ﬁgure 6.7).
The key aspect of the experiment was a novel statistical test that Harris devel-
oped and dubbed the “peer prediction method.” For each recorded neuron, the
timing of its spikes can be predicted by the behavior of the animal with some pre-
cision. If spike occurrence and timing are determined solely by variables external
to hippocampus, information about the other simultaneously recorded neurons
would not make any difference. On the other hand, if other assembly members are
present in the recorded population, information about their activity should im-
prove prediction, commensurate with the proportion of assembly members
recorded. Harris’s clever analysis showed that adding information about the tem-
poral structure of the population to the behavioral data can drastically improve the
prediction of an apparently stochastic spiking pattern. Importantly, this improve-
ment derived not only from neurons with correlated spiking but also from neurons
that were speciﬁcally silent at times when the selected target neuron emitted a
spike. Thus, the explicit absence of spikes (anticorrelation) is as important as the
spiking activity of assembly members. In a separate set of experiments, Dragoi
demonstrated that membership in cell assemblies is indeed modiﬁable by altering
synaptic connectivity among the neuronal population. Together, these ﬁndings
provided quantitative evidence for Hebb’s intuition about neuronal assembly or-
ganization 50 years ago.42
The greatest strength of Hebb’s cell assembly hypothesis—simplicity—is also
its weakness. A cell assembly is deﬁned as group of cells with excitatory connec-
tions whose synapses have been strengthened by coactivation and whose excita-
tory connections are stronger among themselves than with other nonmember
neurons. There are many postulated cell assemblies, and activity can hop from
one assembly to the next. The boundaries of assemblies are implicitly determined
by the hypothetical groups of anatomically connected neurons that ﬁre together.
However, with excitatory neurons only no segregation of assemblies is possible.
As discussed in Cycle 3, without inhibitory interneurons, excitation produces
only further excitation. Without inhibition, activity can spread from one assembly
to the next, and the whole brain would be synchronized by an external stimulus
every time the stimulus is applied. So how does the activity stop? Hebb’s assem-
bly hypothesis has no answer, because it contains no mechanism for ﬂexibly

Figure 6.7. Cell assemblies are organized by oscillatory timing. In the hippocampus, py-
ramidal neurons without synaptic connections can come together repeatedly at the trough
of theta oscillation, with the precision of nesting gamma cycles. Through temporal organi-
zation, cell assemblies can exert a maximal impact on their downstream, common target
neurons. Modiﬁed, with permission, from Harris et al. (2003).
162

Synchronization by Oscillation
163
43. Later versions of Hebb’s cell assembly hypothesis (Braitenberg, 1978; Abeles, 1982) also lack
deﬁned temporal scales. In these works, a cell assembly is generically deﬁned as group of intercon-
nected cells whose synapses have been strengthened by coactivation. Because a single neuron can be
part of several assemblies, the probability of ﬁnding routes between assemblies through joint mem-
bers is likely very high. Thus, the size of a cell assembly, deﬁned by preferred connectivity between
neurons, is large and, in principle, involves the whole cerebral cortex. In a feedforward or synﬁre
chain (Abeles, 1982), activity patterns can spread across the entire network. The larger the network is,
the larger the cell assembly. However, engaging the entire network of growing synﬁre chains requires
progressively longer time, a serious limitation of very large networks. Importantly, in more realistic,
three-dimensional synﬁre networks (i.e., no longer a chain), the activity can reverberate forever.
44. Braitenberg (1978), Abeles (1982), Palm (1982), and Miller (1996a,b).
45. Duration of excitatory postsynaptic potentials in pyramidal cells in vivo is also in the 10–30
millisecond range. Furthermore, this temporal window is most critical for spike-timing–dependent
plasticity of synapses (Magee and Johnston, 1997; Markram et al., 1997; Bi and Poo, 1998). Layer 4
cortical neurons show a resonance and subthreshold oscillations in this time period (Pedroarena and
Llinás, 1997), and their resonant properties make them especially sensitive to inputs at this frequency.
Note that in our formulation of assembly function, the population ﬁring rate in a given time window
(i.e., assembly synchrony) is the important variable, independent of whether it is achieved by a strict
rate or temporal “coding” mechanism (Harris et al., 2003a; Harris 2005).
engaging and disengaging cell assemblies for entering and transferring informa-
tion: it does not have a temporal metric.43 The beginning of assembly activity is
signiﬁed by an external stimulus, but there is no postulated mechanism that would
terminate sequential activation of all possible assembly combinations or time a
motor event by synchronous neuronal discharge. Without properly timed inhibi-
tion, cell assemblies can produce only avalanches (Cycle 3). Furthermore, ac-
cording to Hebb’s deﬁnition and that of several subsequent investigators, a
prerequisite for cell assembly organization is the existence of excitatory connec-
tions among assembly members.44 This deﬁnition excludes a very large popula-
tion of neurons of the cortex and, in fact, many other parts of the brain where
neurons are not connected directly by excitatory synapses. Yet, because neurons
can be brought together ﬂexibly in time by inhibition or by common inputs, these
dynamically created groups can exert the same selective effect on their distributed
and speciﬁc joint targets as Hebb’s postulated assemblies, which are held together
by excitation.
Armed with the peer prediction method, we were able to ask perhaps the most
intriguing question about cell assemblies: what is their temporal scale? By vary-
ing the time window within which spike times of the chosen target neuron were
predicted from the recorded population, the most effective time window could be
calculated. For our hippocampal population, this optimal window turned out to be
between 10 and 30 milliseconds. The time scale of the cell assembly may be of
particular functional signiﬁcance because many physiological variables share this
time window.45 Of these, the time constant of the pyramidal cells is perhaps the
most important, because this is the window that determines a cell’s integration
ability. Importantly, the assembly window also matches the time period of
gamma-frequency oscillations (Cycle 9). We can therefore conclude that cell as-
semblies are synchronized within the time window of gamma oscillation periods

164
RHYTHMS OF THE BRAIN
46. Kanerva (1988) is an excellent introduction to autoassociative networks.
47. In synﬁre chain models, autoassociative circuits, superimposed on the feedforward architec-
ture, can serve to provide error corrections (Abeles, 1982). Salinas and Sejnowski (2001) and Vogels
et al. (2006) also discuss the importance of the balance between excitatory and inhibitory forces for
stable propagation of information.
because this allows an assembly to exert the largest possible impact (i.e., depolar-
ization and discharge) on their downstream targets.
Our temporal deﬁnition of cell assemblies is therefore different from the strict
connectivity-based deﬁnition of Hebb. If neurons are brought together within a
critical temporal window, it is immaterial for a target observer neuron whether the
presynaptic neurons are connected. Just as synchrony is deﬁned by the observer,
cell assembly formation is also an observer-centric process. Nevertheless, if the
presynaptic neurons are also connected, their synchronous discharge may
strengthen their synaptic communication, as predicted by Hebb’s plasticity rule.
Because of the interdependence of the neurons, self-organized assembly patterns
enhance cohesion among its members by restricting their degrees of freedom.
This higher order organization provides their identity. Neurons discharging at dif-
ferent times can be part of many assemblies. The uniquely changing assemblies
in each oscillatory cycle can target anatomically unique sets of neurons. Through
assembly organization, time is translated to neuronal network space.
Integration, Segregation, and Synchrony: 
Is There a Balance?
Complexity and synchrony compete with each other. Therefore, in networks with
ﬁnite size, synchrony increases at the expense of complexity. Cortical networks
have both feedback and feedforward components, and they complement each oth-
ers’ function. Feedback excitatory connections can maintain activity in a re-
stricted place and even restore fragmented information, for which reason they are
also called autoassociative networks.46 In contrast, feedforward connections are
effective in propelling the information progressively in one direction. At ﬁrst ap-
proximation, sensory-related information is processed in feedforward networks,
whereas brain-added information arises in recurrent networks.
Because separation of signal sources in the intact cortex is so difﬁcult, com-
puter models have been designed to study their operations in isolation. Abeles’s
“synﬁre chains” have been speciﬁcally designed to examine how the input is pro-
gressively processed as activity travels forward in different layers and assemblies.
A major weakness of feedforward only systems is that, once an error enters at any
level, it is propagated and ampliﬁed in downstream layers, just like the useful sig-
nal. The nature of the mechanism that provides the safest information transfer in
multiple layers is not known.47 One proposal is that the key variable is the ﬁring
rate of neurons, because rate determines the overall depolarization, and conse-
quently the discharge, of the target neurons. An alternative view is that synchrony

Synchronization by Oscillation
165
48. For a debate on rate vs. temporal coding of information, consult Barlow (1972), Gray (1994),
Buzsáki et al. (1994a), Konig et al. (1996), Shadlen and Movshon (1999), Shadlen and Newsome
(1999), and Engel et al. (2001). For the critical role of the biophysical features of single neurons in os-
cillatory network synchrony, see Golomb and Hansel (2000).
is of primary importance in the transmission of temporally precise signals. These
competing ideas are sensitive to both network architecture and the biophysical
properties of its constituent neurons, so it does matter how neurons are modeled
in the networks.
Because of convergence and divergence of the projecting neurons to a subse-
quent layer, the target neurons will inevitably share some of the same synaptic in-
puts. The denser the connections are, the larger the probability for joint inputs.
These common inputs tend to discharge their downstream targets within a narrow
time window. The synchronous output from the target neuron can synchronize
even more neurons in subsequent layers, unless synchrony is speciﬁcally pre-
vented. Although speciﬁc features of neurons often become critical in the syn-
chronization process,48 in the ﬁrst pass, one can avoid the many assumptions of
single-neuron models. Alex Reyes from New York University just did that by de-
signing a feedforward hybrid of computer network and real, in vitro recorded neu-
rons. Feeding white noise into a single layer 5 neuron, say, 1,000 times, he
obtained 1,000 different outputs. He treated these outputs as if they were emitted
by 1,000 different neurons in his ﬁrst layer and used them to generate another
1,000 outputs in the second layer, and so on. Even though he used only a single
neuron repeatedly or, occasionally, two or three neurons, he created a multiple-
layer feedforward network, consisting of many identical but real neurons. His
consistent ﬁnding was that, even though the network was fed with a Poisson (ran-
dom) input, synchronous oscillations developed in subsequent layers under a
wide range of conditions and network conﬁgurations. Because his networks resis-
ted manipulations that were designed to destroy synchrony, Reyes concluded that
synchrony is the default state of feedforward cortical networks.
Can real cortical networks avoid such default synchrony? One obvious criti-
cism of the Reyes’s approach is that, in real networks, neurons are not identical.
This cannot be the single answer because synchrony did not change much when he
used different neurons, which presumably were sufﬁciently different from each
other. Another argument is that, in the model, the neurons were discharged by cur-
rent injection into their cell bodies, instead of physiological dendritic excitation. A
third criticism is the limited number of convergence relative to the in vivo situa-
tions. Although these factors are likely important to some degree, they are proba-
bly not critical. As discussed in Cycle 5, the default state of cortical networks,
operating with glutamatergic excitatory and GABAergic inhibitory synapses
alone, is synchrony, independent of its size. Only in the presence of subcortical
neurotransmitters can cortical networks operate in the “critical state” to generate
the highest degree of complexity. Otherwise, they just synchronize and pause.
Synchrony in response to shared inputs might be an important factor behind
the now classical observation of David Hubel and Torsten Wiesel. Their key

166
RHYTHMS OF THE BRAIN
49. Hubel and Wiesel (1963). For columnar organization of the cortex, see Szentágothai (1978)
and Mountcastle (1997).
50. The relatively independent operation of principal cells is a prerequisite of representing ﬂexible
associations in the outside world. As discussed in Cycle 3, this freedom is mainly provided by the in-
hibitory interneuron system.
51. Gawne and Richmond (1993) and Gawne et al. (1996). DeAngelis et al. (1999) also found that,
when receptive ﬁeld properties of neighboring neurons in the primary visual cortex (V1) were mea-
sured with high precision, the overlap was more of an exception than a rule. While intracolumnar pro-
cessing of information is generally considered to be the most fundamental operation of the cortex, it
is ironic that cortical columns are deﬁned by their uniform response properties. This paradox could be
due to biased and unsorted neuronal recordings in the cortex. Neurons and their properties in different
cortical layers are rarely distinguished (Krupa et al., 2004). Likewise, the information embedded in
the ﬁne temporal order of neurons is only rarely considered (Reich et al., 2001).
ﬁnding was that, if a neuron responded to a particular shape and movement of
the visual stimulus, other neurons in the same vertical penetration tended to be-
have similarly. These observations provided strong ammunition for the colum-
nar organization idea of the neocortex.49 Nevertheless, a major caveat of these
observations is that they were all done under anesthesia, with the effects of sub-
cortical inputs severely attenuated, and using relatively simple stimulus conﬁg-
urations.
As just discussed, isolated cortical networks are especially susceptible to neu-
ronal synchronization, but this susceptibility is not always advantageous or phys-
iological. An inevitable consequence of connection divergence of inputs and the
primarily local organization of neocortical networks is that neighboring neurons
share similar information because they share similar inputs. This redundancy at
ﬁrst appears to be a useful security mechanism. If a few neurons fail to respond to
the inputs, their peers may still transfer the information. However, given the high
metabolic demands of neuronal operations, such redundancy may be very costly.
Moreover, feedforward and feedback excitatory pathways tend to recruit very
large populations of neurons, such that a single message can engage a consider-
able part of the network. Obviously, such redundancy seriously compromises the
amount of information that can be processed by a given size network. Indeed, re-
cent experiments indicate that such redundancy, in most part, is due to anesthesia
and the testing conditions.50
Barry Richmond and colleagues at the National Institute of Mental Health
tested behaving monkeys with stimuli of varying complexity. When simple bars
and edges were used as stimuli, as much as 40 percent of the signal variance of
one neuron was related to that of an adjacent cell, a high level of redundancy.
However, when responses to more complex two-dimensional patterns were ana-
lyzed, the shared variance dropped to 20 percent. Although no true natural stimuli
were tested, the ﬁndings suggest that functional segregation among local principal
cells increases with input complexity. Importantly, these investigators also found
that the degree of independence between adjacent neurons increases with input
complexity in both primary visual cortex and inferior temporal cortex, the ﬁrst
and last stages of visual processing.51 These novel observations argue in favor of

Synchronization by Oscillation
167
52. Marshall et al. (2002).
53. Monier et al. (2003). In the somatosensory cortex, timing of inhibition plays a critical role in
the tuning of stimulus direction selectivity of layer 4 stellate cells (Wilent and Contreras, 2005). In the
hippocampus, the ratio of excitation and inhibition varies as a function of the theta cycle in pyramidal
cells. During sharp wave/ripple events, excitation transiently exceeds inhibition by as much as three-
fold, providing short temporal windows for facilitating somatodendritic spike propagation and synap-
tic plasticity (Csicsvari et al., 1999; King et al., 1999).
a general organization principle for independent information processing by mem-
bers of local neuronal groups throughout the cortex.
Although the exact mechanisms of such redundancy-reducing effects are not
known, a potential mechanism of functional segregation of principal cells is
activity-dependent inhibition (Cycle 3). The segregation and grouping services of
interneurons are not simply due to inhibition but to a nonlinear interaction between
the excitatory and inhibitory population. Furthermore, as discussed above, the
resonant-oscillatory features of interneurons allow them to select inputs based on
their frequency characteristics. Due to such intrinsic biophysical features, the ef-
fectiveness of the spike-transmission probability varies as a function of the ﬁring
frequency of the presynaptic pyramidal cell. For example, in the hippocampus,
spike transmission from pyramidal cell to interneuron is low at both low and high
frequencies and highest at 15–40 hertz, which is the typical discharge frequency of
an activated pyramidal neuron. In other words, a single but strongly “activated” py-
ramidal cell can exert an equal or larger effect in discharging its basket neurons
than several dozen other presynaptic neurons discharging the same number of
spikes because they target different, rather than the same, synapses. In essence, the
high-frequency discharge of a pyramidal cell in its receptive ﬁeld “enslaves” its
basket cells through resonance tuning. In turn, the output of the basket cells sup-
presses the activity of the surrounding pyramidal neurons.52 Such “winner-take-
all” or “rich-gets-richer” mechanisms are abundant in complex systems, from
automatons to Bill Gates’s empire, and analogous mechanisms may be responsible
for the segregation of neurons in networks strongly interconnected by excitatory
collaterals.
Experiments in the visual cortex by Yves Fregnac and colleagues at the Centre
National de la Recherche Scientiﬁque, Gif-sur-Yvette, France, further support
the role of inhibitory circuits in enhancing neuron segregation in local circuits. In-
hibition and excitation are generally thought to be perfectly balanced. While in-
hibitory/excitatory balance maintains stability in neuronal networks at longer
time scales, large discrepancies often occur transiently. For example, perfect bal-
ance in the visual system would imply that excitation and inhibition are strongest
at the cell’s preferred orientation and weakest at the nonpreferred orientation, but
balanced in both cases. In contrast, when Fregnac and colleagues systematically
assessed the relative contribution of excitatory and inhibitory inputs, they found
diversity for stimuli moving in different directions. In some neurons, inhibition
appeared strongest at directions orthogonal or opposite to maximum excitation.53
A possible explanation of these ﬁndings is that principal cells with different ori-
entation sensitivities compete for their common interneurons. In turn, interneuron

168
RHYTHMS OF THE BRAIN
54. Neda et al. (2000). Most of the observations were taken in the small underground Kamra
(Chamber) Theater in Budapest.
networks can bias the effective local connectivity and segregate adjacent principal
neurons. In doing so, they reduce the redundancy between principal cells and
maximize the amount of information transmitted by the principal-cell population.
Inhibitory interneurons are therefore the key players in the integration and segre-
gation process by allowing or preventing synchrony and bringing together or sep-
arating principal cells in time.
Oscillatory Synchrony Is Energetically Cheap
The paramount advantage of synchronization by oscillation is its cost-
effectiveness. No other known mechanism in the physical world can bring about
synchrony with so little investment. What do I mean by declaring that synchrony
by oscillation is cheap? Let me illustrate the cost issue ﬁrst with a few familiar ex-
amples from our everyday life. You have probably watched leisurely strolling ro-
mantic couples on a ﬁne evening in a park or on the beach. Couples holding hands
walk in perfect unison, whereas couples without such physical links walk out of
step. You can do this experiment yourself. Just touching your partner’s ﬁnger will
result in your walking in sync in a couple of cycles. Unless your partner is twice
as tall or short as you, it costs pretty much the same effort to walk in sync as out
of sync. Once you establish synchronous walking, it survives for quite some time
even if physical contact is discontinued. If both of you are about the same height
and have a similar step size, you will stay in sync for a long distance. In other
words, synchronization by oscillation requires only an occasional update, de-
pending on the frequency differences and precision of the oscillators. Two syn-
chronized Patek Philippe vintage timepieces can tick together for many weeks,
and quartz watches fare even better.
A much larger scale example of synchrony through oscillation is rhythmic
clapping of hands, an expression of appreciation for superior theater and opera
performances in some countries. Clapping always starts as a tumultuous cacoph-
ony but transforms into synchronized clapping after half a minute or so. Clapping
synchrony builds up gradually and dies away after a few tens of seconds. Asyn-
chronous and synchronous group clapping periods can alternate relatively regu-
larly. An important observation, made by Zoltán Néda at the Babes-Bolyai
University, Romania, and his colleagues, is that synchronized clapping increases
the transient noise during the duty cycle, but it actually diminishes the overall
noise (ﬁgure 6.8).54 The explanation for the noise decrease during the synchro-
nized clapping phase is the simple fact that everyone is clapping approximately
half as fast during the synchronous compared with the nonsynchronous phase.
Oscillatory entrainment nevertheless provides sharp surges of sound energy at the
cost of less overall muscular effort. The waxing and waning nature of rhythmic

Synchronization by Oscillation
169
55. The BOLD signal (see Cycle 4) decreases over large cortical areas during both alpha domi-
nance (Laufs et al., 2003) and thalamocortical spike-and-wave epilepsy (Salek-Haddadi et al., 2002),
demonstrating that the metabolic cost of neuronal activity associated with increased neuronal syn-
chrony may, in fact, be less than during nonrhythmic states.
56. For the English translation of Huygens’s original letter about the “sympathy” of clocks, see
Pikovsky et al. (2001).
hand clapping is reminiscent of numerous transient oscillatory events in the brain,
especially in the thalamocortical system. Similar to hand clapping, the total num-
ber of spikes emitted by the participating neurons and the excitatory events lead-
ing to spiking may be fewer during these brain rhythms than during comparable
nonrhythmic periods. A direct test of this hypothesis would require simultaneous
recordings from large numbers of individual neurons. Indirect observations, using
brain imaging methods, however, support the idea.55
Perhaps the most spectacular example of low-energy coupling, known to all
physics and engineering majors, is the synchronization of Christiaan Huygens’s
pendulum clocks. Huygens’s striking observation was that when two identical
clocks were hung next to each other on the wall, their pendula became time-
locked after some period. Synchrony did not happen when the clocks were placed
on different walls in the room. Huygens’s clocks entrained because the extremely
small vibrations of the wall that held both clocks were large enough that each rhythm
affected the other. The physical reason for synchrony between two oscillators is
relatively simple, and solid math exists to explain the phenomenon.56 However,
Figure 6.8. Emergence of synchronization in population hand clapping. Global and local
noise was measured by microphones above the audience and placed next to a spectator, re-
spectively. Rhythmic group clapping emerges between 12 and 25 seconds. Average global
noise intensity, integrated over 3-second time windows, indicates decreased energy spend-
ing by the audience during the rhythm despite large surges of noise. Reprinted, with per-
mission, from Neda et al. (2000).

170
RHYTHMS OF THE BRAIN
57. In reality, the issue we addressed was quite different from the clocks on the wall because none
of the 4,000 interneurons was an oscillator. Instead, their interactions formed one single clock
(Buzsáki et al., 2004). Couplings of numerous oscillators have been analyzed mathematically, but
these mathematical models lack the physical constraints of axon conduction delays; therefore, they
cannot be directly applied to coupling of brain oscillators (Kuramoto, 1984; Mirollo and Strogatz,
1990). For the coupling of two identical oscillators with realistic axon conduction delays, see Traub et
al. (1996) and Bibbig et al. (2002).
extrapolation from two oscillators to the coupling behavior of large numbers of
oscillators is not at all straightforward. Imagine that, in a cylinder-shaped room,
10 clocks are placed on the wall equidistant from one another, each started at a
different time. In a second, much larger room, there are 100 clocks. Finally, in a
giant arena, we hang 10,000 identical clocks on the wall. As with Huygens’s two
clocks, each clock in the rooms has neighbors on each side, and these clocks in-
ﬂuence the middle clock. Furthermore, in the new experiment, there are many
distant neighbors with progressively less inﬂuence. However, the aggregate ef-
fects of more distant clocks must be signiﬁcant, especially if they become syn-
chronous. Do we expect that synchronous ticking of all clocks will develop in
each room? Various things can happen, including traveling waves of synchrony or
local buildup of small or large synchronous groups transiently. Only one thing
cannot occur: global synchrony.
I know the answer because we did an analogous experiment with Xiao-Jing
Wang and his student Caroline Geisler. We built a network of 4,000 inhibitory
interneurons.57 When connectivity in the network mimicked local interneuron
connections in the hippocampus, all we could see were some transient oscilla-
tions involving a small set of neurons (see ﬁgure 3.9). On the other hand, when
the connections were random, a situation difﬁcult to create in physical systems, a
robust population oscillation emerged. So perfect harmony prevailed in a net-
work with no resemblance to the brain but not with what appeared to be a copy
of a local interneuronal network. The problem was the same as with the clocks
on the wall: neurons could affect each other primarily locally. To reduce the
synaptic path length of the network, we replaced a small subset of neurons with
neurons with medium- and long-range connections. Such interneurons with
medium- and long-range connections do indeed exist (see Cycle 3). The new,
scale-free network ticked perfectly. Its structure shared reasonable similarities
with the anatomical wiring of the hippocampus and displayed synchronized os-
cillations, involving each member equally, irrespective of their physical distance.
The reason why our small-world-like artiﬁcial network synchronized is because
it exploited two key features: few but critical long-range connections that re-
duced the average synaptic path length of the network and oscillatory coupling,
which required very little energy. Analogously, cortical networks may achieve
their efﬁcacy by exploiting small-world-like organization at the anatomical level
(Cycle 2) and oscillatory synchrony at the functional level. There is synchrony
for (almost) free.

Synchronization by Oscillation
171
58. The review of these issues by the mathematician Nancy Kopell is an excellent summary of the
analytical approaches to neuronal oscillators (Kopell, 2000). Another introductory review is Wang
(2003). Single-neuron models are covered in Marder and Calabrese (1996). For a more comprehen-
sive coverage of neuronal network oscillations, especially in their relation to epilepsy, I suggest Traub
et al. (1999).
Rules for Oscillatory Networks?
Can we use the knowledge learned from physics and engineering and apply it di-
rectly to neuronal oscillators? From the discussion above, one suspects that this
may not always work effectively. The behavior of an isolated single neuron, being
a relaxation oscillator, is strongly asymmetric with very short discharge (action
potential) and long charge periods. However, when very large numbers of neu-
rons come together with some time jitter, their integrated output, in principle, can
be so smooth that the population may appear to behave like a sinusoid oscillator.
In fact, this principle is routinely exploited by electric engineers to construct reli-
able sinusoid (i.e., harmonic) generators without the inconvenience of the inertia
inherent in real sinusoid generators. The important implication is that some EEG
rhythms with quasi-sinusoid appearance, such as the alpha waves of Hans Berger or
hippocampal theta oscillations, can emanate from the relaxation oscillation features
of single neurons. The critical issue to understand in the context of information
transfer is whether the population behavior of these collective oscillators follows the
rules of harmonic oscillators (as they appear macroscopically) or obeys the laws of
relaxation oscillators, their elementary building blocks. In mathematics, one can
conveniently classify oscillators into types, such as harmonic or relaxation or other
names with properly deﬁned equations.58 Since each of the math-deﬁned oscillators
has distinct features and consequences from perturbations and synchronization, the
experimentalist tries to explore the deﬁning features of in situ oscillators and relate
them to the off-the-shelf oscillators of mathematics and physics.
Unfortunately, network oscillations in the brain can be rarely equated with
these models. The reasons for this are multifold. Despite the macroscopic appear-
ance of almost sinusoid shape mean ﬁeld for some rhythms, all brain oscillators
known have differentiable duty and readiness phases, a key feature of relaxation
oscillators. Neuronal spikes associated with ﬁeld oscillators are typically grouped
around the trough of the extracellularly recorded ﬁeld, recorded near the somata
of the principal cells that give rise to the rhythm. This correlation rule, indepen-
dent of the oscillation frequency, arises from the facts that intracellular depolar-
ization of the perisomatic region is reﬂected as an inward (negative polarity)
current in the extracellular space and intracellular depolarization is associated
with increased probability of spike generation (see Cycle 4). Based on this statis-
tical relationship between the trough of the ﬁeld and the spiking of pyramidal
cells, one might conclude that inputs timed to the trough of the oscillation (i.e.,
during the duty cycle) might be less effective than inputs applied at the time of the

172
RHYTHMS OF THE BRAIN
peak. This is indeed the case when nearly all neurons ﬁre in sync, such as epilep-
tic discharges. However, in the physiological range of network operations, only a
very small percentage of all neurons ﬁre. Part of the remaining neuron population
may also be depolarized but remain subthreshold, and yet another fraction may be
hyperpolarized due to interneuron-mediated lateral inhibition from the discharg-
ing minority. Thus, an input synchronized to the trough of the ﬁeld is less effec-
tive for two sets of neurons for two different reasons (i.e., spike refractoriness and
hyperpolarization) but can be effective for the remaining subthreshold population.
The magnitude of the response of an afferent input therefore depends on the por-
tion of neurons being in the subthreshold readiness state, a feature that may vary
from structure to structure and oscillation type. Similarly, an input timed after the
duty cycle (e.g., the peak of the extracellular local ﬁeld) may reset the phase of
the population oscillation or remain ineffective because of interneuron-mediated
feedback inhibition or because of intrinsic hyperpolarization in the discharging
minority. These examples illustrate the disappointing “rule” of brain oscillators:
coupling behavior depends on the details.
True relaxation oscillators are eager to synchronize during their readiness pe-
riods, but they need to be discharged in order to advance their phases. On the
other hand, harmonic oscillators require very weak forces and can advance their
phase incrementally. These deﬁning features can be used to probe the nature of
network oscillators. A simple test that can assess the property of an oscillator is
its response to a transient perturbation, such as a single electrical shock (ﬁgure
6.9). The dynamics of the resumption of the original rhythm and the phase
Figure 6.9. Single-pulse electrical stimulation of intrahippocampal afferents resets theta
oscillation (ﬁeld) and silences all spiking activity (spike counts) transiently. After reorgani-
zation, the ﬁeld oscillation and concurrent neuron activity start at the same phase. Multiple
superimposed traces show random phase distribution before but regularity after the stimu-
lus. Note that the mean amplitude of the ﬁeld and mean spike counts remains the same as
prior to stimulation. This behavior is a telltale sign of a single global oscillator. Reprinted,
with permission, from Zugaro et al. (2005).

Synchronization by Oscillation
173
59. The phase reset behavior of hippocampal theta is a particularly good example of a brain
rhythm that behaves like a single oscillator, even though it is built from several oscillator types (Zu-
garo et al., 2005).
60. Many different computer architectures can be built to mimic the same neurophysiological fea-
tures. Here is a prime example: Prinz et al. (2004) simulated more than 20 million versions of a three-
cell model of the pyloric network of the lobster stomatogastric ganglion using different combinations
of synapse strengths and neuron properties. They found that virtually indistinguishable network activ-
ity can arise from widely disparate sets of underlying mechanisms, suggesting that many different
combinations of synaptic strengths and intrinsic membrane properties can be consistent with appro-
priate network performance. However, only one or few of these are biologically relevant. As Paul
Erdös also emphasized, of the many possible solutions, only the most elegant one(s) is in the “Book”
(see Cycle 1).
dependence of the perturbation may provide information about the underlying
mechanisms responsible for the network oscillation. An oscillator with relaxation
properties should reset instantaneously. Because the population is constructed
from heterogeneous individual oscillators with phase jitter, resetting the compo-
nents into a common phase is expected to increase the size of the mean ﬁeld.
Experiments on hippocampal theta rhythms showed that these oscillators do
not obey the simple rules predicted by the known oscillators. Reset properties fol-
low rules of the relaxation oscillator, yet phase reset does not affect the ﬁeld am-
plitude. Theta network oscillators appear to behave as a single, “monolithic”
oscillator even though they are made up of a very large and heterogeneous group
of individual neurons.59 The quasi-sinusoid ﬁeld monolith of theta rhythm keeps
time (phase) more precisely than the relaxation oscillations from which it is built.
So here is another vague rule: the same macroscopic ﬁeld can be brought about by
numerous intrinsic cellular and network mechanisms, and accordingly, the reso-
nant, transmission, and perturbation properties of the respective oscillators may
be quite different. Seemingly identical architectures can either promote synchro-
nization or resist it. Although I provide several examples of similarly behaving
oscillators in later Cycles, to date, general rules are exceptional for brain oscilla-
tions. The coupling properties of the rhythmic networks should be determined ex-
perimentally in each and every case, aided by computer modeling.60
Brieﬂy . . .
There are two requirements for an oscillator: opposing forces and positive feed-
back. Systems with opposing forces but without feedback can maintain only a
transient oscillation with decreasing amplitude, a phenomenon called resonance.
Neurons and networks with these properties preferentially treat inputs whose
frequency matches their own resonance. Neuronal oscillators belong to the fam-
ily of limit cycle or weakly chaotic oscillators. Two well-deﬁned oscillators, har-
monic and relaxation types, have numerous examples in the brain. Harmonic
oscillators are good long-term predictors because their phase is constant. Relax-
ation oscillators can synchronize quickly and efﬁciently. Brain oscillators tend to

174
RHYTHMS OF THE BRAIN
exploit and combine these properties. Single neurons oscillate mainly because
voltage-gated ion channels with opposite properties depolarize and hyperpolar-
ize the membrane. Due to the differential distribution of the ion channels in the
soma-dendritic domains, neurons can have multiple oscillatory and resonance
properties. These properties can be tuned dynamically by either changing the
neuron’s input resistance or affecting open channel probabilities. Interneurons
are especially prone to resonate and they are the primary building blocks for net-
work oscillators.
Collective behavior of neurons is established through synchrony. Synchrony
is a relative term, deﬁned by the time within which some trace of an earlier event
by an input is retained, which then alters the response to a subsequent event to
other inputs. Events that can be integrated over time by the target neurons are
synchronous. Although this temporal window is in the tens of milliseconds range
for single neurons, oscillatory coalitions of neurons can expand the effective
window of synchronization from hundreds of milliseconds to many seconds.
Population synchrony enhances the effective output of the population and it can
emerge also without the alternation of ﬁring rates of individual neurons. Thus,
synchrony by oscillation is a metabolically cheap mechanism to achieve a large
impact. Neuron assemblies are formed as transient coalitions of discharging neu-
rons with mutual interaction. Assemblies in the waking brain typically synchro-
nize in the gamma frequency range. Assembly behavior is a consequence of
self-organized interactions among neurons and this self-organization may be the
source of cognitive function.
Stochastic resonance may be a mechanism for selectively extracting messages
and deducing the metric of intrinsic dynamics of the sending assemblies. Instead
of costly white (stochastic) noise generation, brain networks opted for transient
coupling between oscillatory events of different frequencies with same beneﬁts
as stochastic noise.

Cycle 77
The Brain’s Default State: Self-Organized
Oscillations in Rest and Sleep
Sleep that knits up the ravell’d sleeve of care,
The death of each day’s life, sore labour’s bath,
Balm of hurt minds, great nature’s second course,
Chief nourisher in life’s feast.
—William Shakespeare, Macbeth
175
1. Information theory quantiﬁes the concept of information, in our case how an input signal can be
reconstructed from spikes (digital output of neurons). MacKay’s comprehensive book on information
theory (MacKay, 2003) is available online. For the reconstruction of sensory information from spikes
and a thorough quantitative treatment of the topic, see De Ruyter et al. (1997).
Descriptions of brain functions and operations typically begin with the brain’s re-
sponses to environmental inputs. Such an approach, often within the framework of in-
formation theory,1 attempts to infer the mechanisms of neuronal processing from the
brain’s responses to invariant physical stimuli. However, the information theory strat-
egy cannot account for important functions of the brain that do not require immediate
environmental inputs, including various the hard-to-deﬁne types of mental processing
and sleep. I take a different approach in this book, beginning with the examination of
the unperturbed, resting-sleeping brain and examining its evolving state changes. The
brain’s responses to environmental perturbations are addressed in later Cycles.
Rest and sleep are the best examples of self-organized operations within neu-
ronal circuits and systems. Brain tissue can and does support spontaneous col-
lective patterns even in the absence of any external “energizer” agent or
instructions. Neurons in the thalamocortical systems can support several states,
and these states follow each other according to a predictable choreography. Brain
“state” is a macroscopic variable, reﬂected by the mean ﬁeld behavior of the sys-
tem, typically a characteristic oscillatory mode or a transition between different

176
RHYTHMS OF THE BRAIN
2. Oscillations in sleep provide a striking example for “reciprocal causality.” The emergent ﬁeld
oscillation may be considered an order parameter (collective neuronal oscillation) that constraints the
timing and even the probability of neuronal action potentials.
3. The circadian and temperature rhythms are the most important “causes” of sleep. Sleep-
inducing humoral factors have been suggested by several investigators. According to Borbely (1982,
1998), activity in the waking brain builds up a sleep (S) factor that is responsible for inducing sleep
and delta activity. In support of his theory, sleep deprivation is followed by a homeostatic compensa-
tion (delta rebound). Rainnie et al. (1994) postulate that adenosine, acting on adenosine-1 receptors,
may be such an S factor. To account for the speciﬁc and differential effects in sleep, these hypothetical
factors should exert an effect locally. General, circulating factors can be largely excluded because
Siamese twins with a common circulatory system sleep independently (Webb, 1978; Sackett G, Kor-
ner, 1993 ) and unihemispheric sleep has been documented in dolphins and other see mammals
(Lyamin et al., 2002; Siegel, 2005).
oscillatory modes. The state is generated by the participating neurons and de-
ﬁned by a set of parameters such as activation of voltage-gated channels, avail-
ability of neurotransmitters and neuromodulators, and distribution of synaptic
weights. In turn, the created state variable, such as a network oscillation, con-
strains the ﬁring patterns of single neurons.2 The states change during the course
of sleep, but the passage of states over time is predictable from the history of
previous states.
Sleep is an excellent model of evolving brain states because it occurs without
an outside inﬂuence—it evolves from within. Complex systems with a predictable
“path” or trajectory in the state space are called deterministic. Sleep is such a de-
terministic evolving state. Unfortunately, very little is known about the mecha-
nisms that force brain networks to change and stabilize their trajectory of activity
during sleep. To date, most research on the physiology of sleep has been devoted
to understanding the biophysical and pharmacological bases of the various sleep
states—separately. These works have provided signiﬁcant advancements in our
understanding of the mechanisms involved in normal sleep and sleep alterations
psychiatric disorders. Virtually every psychiatric ailment is associated with some
kind of alteration of sleep duration and pattern. This change is usually interpreted
as a consequence of the primary problem apparent in the waking brain. However,
it is equally justiﬁed to consider causation in the opposite direction, namely, that
alteration of sleep structure is the cause of the altered responsiveness of the wak-
ing brain. Deciphering the self-organized dynamics of the neuronal circuits in-
volved in the various sleep stages and state progression may be the key to
understanding the brain’s responses to environmental perturbations.3 In this Cy-
cle, I examine sleep- and rest-associated oscillations and their mechanisms. In
Cycle 8, I discuss the possible functions these oscillations may serve.
Thalamus: A Partner for Neocortex
In large systems with complex connectivity, it is often difﬁcult to draw boundaries.
This is surely the case with the neocortical mantle, with its myriads of cortical

The Brain’s Default State     
177
4. Certain cytoarchitectural differences, e.g., the high density of layer 4 stellate neurons in the pri-
mary visual cortex or the giant Betz cells of the motor cortex in primates, do reveal boundaries, but
these anatomical differences are likely the consequence rather than the cause of modality-speciﬁc seg-
regation of function. Neocortical tissue during early development can be exchanged, and the respec-
tive tissue differentiates mainly according to its functional inputs.
5. Only a very small fraction of the excitatory neocortical synapses originates from the thalamus.
Even in layer 4 neurons, the main recipients of thalamic inputs, only 5–10 percent of synapses arrive
from the thalamus (Ahmed et al., 1994; Latawiec et al., 2000), and the majority of contacts originate
from other cortical neurons. The number of return paths from either layer 6 or layer 5 cortical neurons
to the sensory and higher order thalamic nuclei, respectively, outnumber the thalamocortical connec-
tions 5- to 10-fold (Jones, 1998, 2001)
modules and high-density local connectivity, supplied by neurons whose biophys-
ical features do not vary greatly across the cortex.4 Clustering of long-range con-
nections already provides some anatomical clues for subdivisions of the
neocortex and justiﬁes designations of cortical systems as visual, auditory, so-
matosensory, motor, language-related, spatial, or other. A further segregation of
neocortical function as well as integration of information across the distant re-
gions derives from its main afferent and efferent expansion: the thalamus. This
football-shaped structure is located in the origin of the two neocortical hemi-
spheres, like the atom of a large molecule. The purpose of this geometrical
arrangement—as implied in Cycle 2—could be that being equidistant from all
cortical areas demands the least length of reciprocal wiring and provides the
fastest axonal communication.
According to textbook wisdom, the thalamus is a large collection of relay nu-
clei, a kind of customs and border patrol agency. These nuclei are the only source
of information for the neocortex about the body and the surrounding physical
world. With the exception of olfaction, all sensory modalities are scrutinized by
the thalamus before they can proceed to the neocortex. How the incoming stimuli
are evaluated by the thalamus is quite a mystery, mostly because at ﬁrst glance
there is not too much coordination among the nuclei patrolling the different
modalities. Even neighboring neurons cannot chat with each other directly, since
they do not possess local axon collaterals, or only very sparse ones in some nu-
clei. Their axons rush up to the neocortex, terminating predominantly in layer 4
but also in layers 5 and 6; hence, they are called thalamocortical neurons.5 Per-
haps keeping sensory information segregated at this early stage is important so
that the information from different sensors does not get mixed in a structure with
limited capacity to extract modality-speciﬁc information. This segregation of
thalamic inputs is what provides behaviorally meaningful localization of function
in the neocortex.
Similar to the cortical principal cells, thalamocortical neurons release glutamate
and excite their target partners. However, there are many more anatomically deﬁned
nuclei in the thalamus than there are types of sensory information. In fact, a very
large part of the thalamocortical circuits do not have much to do with primary sen-
sory information. There are important inputs from the cerebellum and the basal
ganglia, but the bulk of the afferents are supplied by the neocortex. The bottom-up

178
RHYTHMS OF THE BRAIN
6. First-order nuclei receive driving afferents from the medial lemniscus (somatosensation), the
optic tract (vision), the inferior colliculus (hearing), the cerebellum (motor), and the limbic mammil-
lary bodies. Higher order nuclei include the large pulvinar, the lateral posterior, the mediodorsal, and
lateral dorsal nuclei. These novel ideas about the thalamocortical circuits are discussed at length in
Sherman and Guillery (2001) and several shorter but comprehensive reviews (Guillery and Sherman,
2002; Sherman and Guillery, 2002).
thalamocortical connections are reciprocated by layer 6 and also from layer 5 corti-
cothalamic connections, according to a cleverly organized plan (ﬁgure 7.1). The im-
portance of the cortical feedback is best illustrated by the fact that the thalamus is
the only corticofugal target of the layer 6 pyramidal cell population, and these neu-
rons innervate virtually all thalamic nuclei. In contrast, collaterals of layer 5 pyram-
idal cells, whose fast-conducting main axons are destined for the brainstem, target
those thalamic nuclei that do not receive primary sensory or motor information. Ray
Guillery at the University of Wisconsin, Madison and Murray Sherman at the State
University of New York–Stony Brook call these thalamic divisions “higher order”
nuclei, as opposed to the “ﬁrst-order” nuclei with speciﬁc sensory-motor informa-
tion. Most important, afferents from higher order nuclei send relatively widespread
projections to several cortical areas; thus, they disseminate their information con-
tent to several other cortical regions.6 The importance of this operation is reﬂected
in the more extensive axon arbor commitment and larger cortical coverage of the
neurons in higher order nuclei relative to their ﬁrst-order partners.
Figure 7.1. Differential neocortical and GABAergic (black lines) control of ﬁrst-order and
higher order thalamic nuclei. As an example, the somatosensory ﬁrst-order, ventral postero-
medial (VPM) nucleus, and the higher order posterior thalamic (Po) are shown. First-order
nuclei are innervated by layer 6 neocortical projections and the GABAergic reticular thala-
mic nucleus (nRT) and give rise spatially restricted cortical projections. Higher order nuclei
receive excitation from both layer 6 and layer 5. In addition to the nRT, higher order nuclei
are under the inhibitory control of the zona incerta (ZI) and the anterior pretectal nucleus
(APT) GABAergic system. Thalamocortical higher order neurons give rise to widespread
cortical projections. Figure courtesy of László Acsády and Didier Pinault.

The Brain’s Default State     
179
7. Llinás and Paré (1991) and Jones (2001).
8. Reticular thalamic neurons can communicate by three different means. In addition to traditional
synaptic innervation (Scheibel and Scheibel, 1966; McCormick and Bal, 1997), they are connected by
dendrodendritic synapses (Deschênes et al., 1985; Yen et al., 1985; Pineault et al., 1997; Steriade,
2001a,b, 2003) as well as gap junctions (Landisman et al., 2002). Local concentration of GABAergic
neurons is not unique to the reticular nucleus. A sheet of GABAergic neurons is present between cen-
tral and basolateral nuclei of the amygdala. These “intercalated” neurons are grouped together and
form an anatomical and physiological barrier between the projection nuclei of the amygdala (Royer
and Paré, 2003; Paré et al., 2003).
9. For a comprehensive discussion of the thalamic circuits, see Steriade et al. (1990b), Sherman
and Guillery (2001), and Jones (1985). Cox et al. (1996) examined the axon arbors of single reticular 
The pattern of thalamic connectivity coevolved with the neocortex. However,
cortical representations grew much more rapidly. For example, the number of
thalamocortical neurons in the mouse is only an order of magnitude less than the
number of target neurons in the cortex, whereas in the human brain the ratio is
less than one to a thousand. Even though thalamic growth did not keep up with
the fast development of the neocortex, higher order nuclei in primates are rela-
tively larger than the ﬁrst-order relays, indicating that allocation of divergent
cortical–thalamic–cortical connections is more important for the evolution of the
mammalian brain than enhancing the bandwidth capacity of primary sensory path-
ways. The connectivity pattern outlined above indicates that the thalamus alone is
not a very useful structure. It does not have the ability to add or subtract informa-
tion without the neocortex. However, in partnership with the neocortex, the recip-
rocal excitatory connections are prone to oscillation, and such a mechanism is
perfectly posed to mix thalamocortical information.7
The cytoarchitectural organization of the thalamus is unique. Unlike in the neo-
cortex, where inhibitory cells are nested within the excitatory networks and adja-
cent to their targets, most GABAergic interneurons in the thalamus reside in a thin
shell surrounding the thalamic chamber, called the reticular nucleus, and some
other subcortical nuclei. The evolutionary cause or advantage of the spatial segre-
gation of inhibitory and excitatory populations is not clear. A potential advantage
of placing GABAergic neurons together and far from their axonal targets is that
this arrangement allows for effective local communication through, for example,
electrical junctions and extensive dendrodendritic contacts. In turn, dendroden-
dritic junctions can release and sense locally secreted GABA, and these local
mechanisms may be critical for the global operation of the reticular nucleus.8
On their way to the neocortex, axons of thalamocortical cells pass through the
reticular nucleus, give off collaterals, and innervate the inhibitory GABAergic
neurons. Interneurons of the reticular nucleus are much fewer in numbers than
their thalamocortical partners; therefore, many thalamocortical cells and layer 6
cortical neurons converge onto a single reticular neuron. In turn, the reticular
cells contact large numbers of thalamocortical cells. Most of them address their
partners reciprocally with a high density of local axon collaterals; however, a mi-
nority have intermediate or large innervation territory capable of affecting neu-
rons in a larger thalamic space.9 In addition to the reticular nucleus, higher order

180
RHYTHMS OF THE BRAIN
cells, projecting to the ventrobasal nucleus in juvenile rats. Once within the nucleus, the axon ramiﬁed
into one of three branching patterns: cluster, intermediate, and diffuse. The size of a cluster arboriza-
tion closely approximated that of an individual barreloid with dense local branches. The intermediate
structure extended across an area that was approximately fourfold greater. Neurons with diffuse arbors
covered a large region of the nucleus and contained a relatively low density of axonal swellings. In
contrast to the Cox et al. (1996) study, in vivo juxtacellular labeling of reticular neurons in the adult rat
by Pineault and Deschênes (1998) revealed very few internuclear collaterals and no evidence of wide-
spread internuclear innervation. Age difference is a potential explanation for the contrasting results.
10. László Acsády and colleagues have discovered a widespread extrareticular inhibitory system
(Barthó et al., 2002; Bokor et al., 2005). These GABAergic nuclei compose a continuous system that
cooperatively affects ﬁrst-order and higher order nuclei of the thalamus. For the nigrothalamic and
pallidothalamic connections, see Kultas-Ilinsky et al. (1983).
11. Andersen et al. (1964).
thalamic nuclei receive further inhibitory innervation from a somewhat contigu-
ous set of structures: the zona incerta, the diencephalic anterior pretectal nucleus,
and the pars reticulata division of substantia nigra. Neurons in this extrareticular
inhibitory system do not receive direct thalamic information from thalamocortical
neurons but receive inputs from the axon collaterals of cortical layer 5 neurons.
These extrareticular inhibitory structures can be regarded as the functional
boundary expansion of the thalamus.10 Since the thalamus alone cannot generate
sustained or growing excitation, due to the lack of recurrent collaterals, one may
wonder why the thalamocortical neurons are under such massive inhibitory con-
trol. Information about anatomical connections alone does not provide an answer.
Single-Cell Contribution to Thalamocortical Oscillations
Per Andersen and John Eccles at the Department of Physiology, the Australian Na-
tional University, Canberra noted in the early 1960s that stimulation of the neocor-
tex or a foreleg nerve in the cat often induced initial inhibition rather than the
expected excitation in thalamocortical cells, followed by a series of fast action
potentials tens or hundreds of milliseconds later. They called their observation
“post-anodal exaltation,” referring to the requirement of an inhibition-induced hy-
perpolarization prior to the discharge.11 A decade later, Rodolfo Llinás at New York
University and his postdoctoral fellow Henrik Jahnsen identiﬁed the cellular mech-
anism of this puzzling phenomenon. At that time, most biophysicists “interrogated”
neurons by injecting square-wave currents of various magnitudes into the cell bod-
ies and evaluated the resulting membrane and spike dynamics. Llinás suspected that
this approach could not be the best strategy since neurons do not communicate with
square pulses. While he and Jahnsen were experimenting with various waveforms,
they observed that thalamocortical cells responded in a qualitatively different man-
ner when the same membrane potential was brought about by an arbitrary waveform
from either a depolarized or a more hyperpolarized level. When synaptically ex-
cited or depolarized by an intracellular current, thalamocortical neurons behaved
like “classical” neurons, emitting spike series. But the investigators were astonished

The Brain’s Default State     
181
12. Jahnsen and Llinás (1984a,b). For reviews, see Steriade and Deschênes (1984) and Huguenard
(1996).
to see that thalamocortical neurons also responded when released quickly from a
hyperpolarized state even without any extrinsic depolarizing force. In fact, the neu-
rons ﬁred a series of spikes at intervals of 3–5 milliseconds, or using the laboratory
jargon, they emitted a “burst” of spikes. This was a new revelation about neurons:
some neuron types, such as thalamocortical cells, can be discharged not only by ex-
citation but also by releasing the neuron from inhibition.
The mechanism of such “rebound” excitation is the deinactivation of a Ca2+
channel, the T-channel, as it became known later.12 Thus, thalamocortical cells
can ﬁre in two qualitatively different ways. Depolarization can induce rhythmic
single spikes, similar to those observed in neocortical pyramidal cells. When re-
leased from hyperpolarization, activation of the T-channel leads to a “slow spike,”
caused by the inﬂux of Ca2+ ions. Because the slow Ca2+ spike is depolarizing and
lasts for tens of milliseconds, typically a series of fast Na+ spikes ride on it. This
discovery, in itself, is important because it illustrates a fundamentally different
method of transferring information. In the “high-ﬁdelity,” Na+-spike-only mode,
sufﬁcient excitation will briskly discharge the neuron: the stronger the depolar-
ization, brought about by the converging excitatory inputs, the faster the thalamo-
cortical cell’s output. In the “low-ﬁdelity,” Ca2+-spike mode, the effect of the input
depends strongly on the state of the neuron. While the neuron discharges a burst
(reﬂecting its duty cycle), it remains refractory to afferent activation. Following
the burst, the cell gets hyperpolarized because the Ca2+ inﬂux activates a hyper-
polarizing K+ channel for tens of milliseconds, making the neuron still reluctant
to respond to afferent inputs. Another important consequence of this nonlinear
behavior is that, when coupled with an opposing force, it provides the necessary
conditions for oscillation, as the work from David McCormick ofYale University
has shown. Upon hyperpolarization, another voltage-gated channel (termed Ih:
also known as the pacemaker channel because it was ﬁrst described in the pace-
maker sinoatrial node of the heart) tends to repolarize the neuron. Adjusting the
membrane potential to an appropriate hyperpolarized range by an intracellular
electrode, thalamocortical neurons discharge a burst of spikes at 0.5–4 hertz, vir-
tually inﬁnitely (ﬁgure 7.2). Every thalamocortical neuron can therefore be con-
verted into a delta frequency clock when properly hyperpolarized. The opposing
forces required for the oscillator are the hyperpolarization-activated mixed
cation (Na+ and K+) current, Ih, and the low-threshold Ca2+ current, IT. These cur-
rents are activated at different membrane voltage levels. Hyperpolarizing the
neuron beyond–65 millivolts activates Ih. The activation of Ih depolarizes the
membrane slowly until a low-threshold Ca2+ spike is generated by activation of
IT at a more depolarized level. During the spike, Ih is deactivated, and the termi-
nation of the spike is followed by a hyperpolarizing “overshoot” that in turn be-
gins activating Ih, and the cycle repeats. In addition to voltage, activation of Ih is
also sensitive to the intracellular concentration of Ca2+. The variation of intracel-
lular Ca2+ can therefore adjust the “strength” of Ih, and it converts the clocklike

Figure 7.2. Single-cell oscillation in a thalamocortical neuron. Top: At membrane poten-
tial–65 millivolts, the neuron sustains stable oscillation at 1–2 hertz. Depolarization of the
membrane induces continuous fast (Na+) spikes. Two events are expanded in time (bot-
tom). The hyperpolarization-activated Ih (“pacemaker”) conductance repolarizes the mem-
brane into the activation range of IT (low-threshold Ca2+ channel). When IT activates, it
induces a wide Ca2+ spike upon which fast spikes ride. The Ca2+-spike–induced depolar-
ization deactivates Ih and inactivates IT. The ensuing hyperpolarization initiates a new iden-
tical cycle. Reprinted, with permission, from McCormick and Pape (1990).
182

The Brain’s Default State     
183
13. Thalamocortical neurons in the intact cat generate bursts at delta frequency (Curro Dossi et al.,
1992) and become clock-like after removal of the neocortex (Timofeev et al., 2000). Similar “pace-
maker oscillations” with rebound bursts at delta frequency are also present in the thalamic slice (Mc-
Cormick and Pape, 1990; Leresche et al., 1990; Soltész et al., 1991) and computer models of single
neurons (Toth and Crunelli, 1992; Destexhe et al., 1993; Wang, 1994; for a review, see Destexhe and
Sejnowski, 2001).
14. In fact, Steriade argues that Ca2+ bursts in thalamocortical neurons occur exclusively during
sleep. For a debate on the functional signiﬁcance of “bursts,” see Swadlow and Gusev (2001), Sher-
man (2001), and Steriade (2001c).
15. Rebound bursts in reticular neurons were ﬁrst demonstrated in vivo (Mulle et al., 1986) and
conﬁrmed by extensive in vitro studies (Llinás and Geijo-Barrientos, 1988; McCormick and Wang,
1991; Huguenard and Prince, 1992).
16. The IT-channel–mediated increase of intracellular Ca2+ also activates a nonspeciﬁc cation cur-
rent, called ICAN, which tends to depolarize the membrane. Combination of these currents in model
reticular neurons produced rebound bursting at 8–11 hertz but not in the higher spindle-frequency
range (Bal and McCormick, 1993; Destexhe and Sejnowski, 2001). For spindle generation, network
connectivity is needed.
delta oscillation into a waxing/waning pattern, a situation more similar to the in-
tact brain.13
These ﬁndings are interesting for several reasons. First, they illustrate that na-
ture went to a lot of trouble bringing together these channels at the right densities
and location just to serve one purpose: oscillation.14 Brain evolution adopted a
channel from the heart just to sustain oscillations during sleep. It is hard to imag-
ine that such a complex and energy-expensive design is simply a byproduct.
Even if bursts are also put to work for sensory transmission, their dominant oc-
currence during sleep is indisputable. Second, these and other oscillation-
promoting channels are present in a variety of cortical neurons, although their
density and spatial distribution vary substantially. Thus, in cortical neurons these
channels may serve similar functions. Third, when coordinated across multiple
thalamocortical neurons, the single-cell properties can provide a delta-frequency
pacing of their cortical targets. Finally, inhibition-induced rebound spikes are
not elicited by any speciﬁc sensory input. Because they are triggered by inhibi-
tion, in a sense, they are “useless” for the representation of upstream excitatory
inputs. Rebound spike bursts therefore are the prime examples of self-generated
spike patterns that communicate to downstream neurons primarily determined
by the state of the thalamic network.
Reticular neurons, similar to thalamocortical cells, also contain IT channels
and therefore can generate low-threshold Ca2+ spikes. Although IT channels have
a slower kinetics and are activated over a more depolarized range of membrane
potentials than in thalamocortical neurons,15 isolated reticular thalamic neurons
nevertheless can also sustain oscillations. Instead of Ih, however, the opposing
force of IT is a Ca2+-activated K+ current, IK[Ca]. Although a strong hyperpolarizing
pulse can also induce bursts of action potentials at delta frequency in isolated
reticular neurons, the evoked oscillations quickly dampen, suggesting that reticu-
lar neurons are not critical players in delta oscillations.16

184
RHYTHMS OF THE BRAIN
17. For a review of in vitro work, see Kaila (1994), Jonas et al. (2004) and Mody and Pearce
(2004). In the intact brain, inhibition is even shorter than in the slice (Barthó et al., 2004).
18. For the subcellular localization of GABAB receptors, consult Somogyi et al. (1998).
19. Besides the reticular nucleus, inhibition to the thalamus is supplied by the zona incerta and
pars reticulata of the substantia nigra. These GABAergic nuclei compose a continuous system that co-
operatively affects ﬁrst-order and higher order nuclei of the thalamus (Barthó et al., 2002; Bokor et al.,
2005).
From Single Neurons to Network Oscillations
With the discovery of the low-threshold calcium channel and other active conduc-
tances, thinking about thalamic function has changed forever, marking the begin-
ning of a new, very productive era of thalamic research. Research has progressed
simultaneously in the intact animal and in the in vitro slice preparation as well as in
silico, often with heated exchanges of ideas among the protagonists. Numerous
rhythms have been described in the resting-sleeping thalamocortical system, in-
cluding alpha waves (8–12 hertz), mu rhythm (8–12 hertz), sleep spindles (10–20
hertz) and associated ultrahigh-frequency oscillations (300–600 hertz), delta waves
(1–4 hertz), and the slow 1 to slow 4 rhythms (0.05–1 hertz). These patterns are col-
lectively called “thalamocortical” oscillations, indicating the involvement of both
the thalamus and the cortex. However, different investigators often emphasize the
primary dominance of one structure over the other for each of these patterns.
The study of thalamocortical oscillations has roughly two historical stages.
During the last century, we simply observed them. Recently, we began creating
them in some rudimentary but controllable and quantitative manner. Many books
and reviews have dealt with these fascinating yet complicated rhythms over the
years. The major debates revolve around the issue of the minimum substrate (i.e.,
thalamus vs. the neocortex) and mechanisms of these rhythms. A common func-
tion of all self-governed thalamocortical oscillations is that they bring about con-
straints regarding whether and when information about the outside world, detected
by the peripheral sensors, can pass through the thalamus and be distributed for fur-
ther processing in cortical networks or is ignored outright. Why are oscillations the
chosen solution for the isolation of sensory inputs from the downstream cortical
and other targets of the thalamus? In principle, such a “gating” function could be
accomplished by tonic GABAergic inhibition without any oscillatory component.
However, inhibition through the fast GABAA receptors can silence cells for only a
few tens of milliseconds.17 The inhibitory action of GABAB receptors is longer, but
a much larger amount of GABA should be released for their activation, so that the
transmitter molecules can passively diffuse to the receptor.18 This is still conceiv-
able. However, if the gating function is to be maintained at the seconds time scale,
as is the case during sleep, continuous release of GABA should be secured some-
how. Elevated release of GABA is possible only through the continuous excitation
of the reticular thalamic and extrareticular GABAergic neurons19 by their affer-
ents, including subcortical neurons, sensory (lemniscal) inputs, corticothalamic

The Brain’s Default State     
185
20. Foote et al. (1983) and Steriade and Buzsáki (1990).
21. Thalamus-mediated sensory inputs are believed to play a critical role in the ﬁne tuning of cor-
tical circuits (Katz and Shatz, 1996). According to such a postulated mechanism, random discharge of
thalamic neurons would randomize cortical connections.
22. A good example is the pulvinar, which is an “associative” visual thalamic nucleus. The pul-
vinar contains blurred maps of visual cortical areas V1–V5, in addition to other cortical projections. As
a result, the indirect cortical–pulvinar–cortical circuits tend to mimic direct corticocortical pathways
but with more extensive overlap. These widespread projections allow the pulvinar to coordinate corti-
cal information processing by facilitating and sustaining the formation of synchronized transarea as-
semblies and outlasting each other in activity (Shipp, 2003).
afferents, or thalamocortical cells. However, at sleep onset, subcortical neurons,
releasing acetylcholine, serotonin, norepinephrine, and histamine, decrease their
ﬁring rates.20 So do speciﬁc thalamic afferents and primary sensory cortical neu-
rons. Thus, the expected excitatory task is left to the thalamocortical neurons, that
is, to the population whose silencing is desired. Furthermore, if thalamocortical
cells would discharge randomly to maintain inhibition, their non-sense activity
would be heard by the neocortex, as well, potentially leading to random modiﬁca-
tion of neocortical connections.21 As this thought experiment illustrates, silencing
the principal-cell population in an interconnected system is not a simple task. Thal-
amocortical networks maintain activity all the time, and silence as a default is
rarely chosen. Tonic or random inhibition is thus not an effective mechanism for
preventing excitation unless an external control of inhibition is available. An alter-
native mechanism for ignoring inputs is through inhibition-based oscillations that
can provide prolonged periodic suppression of activity. In the thalamocortical sys-
tem, oscillations not only represent different states but also require different ionic
mechanisms.
The spatial extent of cortical involvement depends primarily on the frequency
of oscillations. As a rule, slower frequencies involve more extensive synchronous
activation of the neuronal pool. The distribution of neuronal information across
vast areas of the neocortical networks with limited interarea connections is as-
sisted by the special wiring relationship between the GABAergic reticular cells
and thalamocortical neurons, their unique biophysical properties, and the dissem-
ination of local cortical information by the widespread higher order thalamic nu-
clei. In contrast to the rigid interarea corticocortical connections, with
progressively increasing axon conduction delays, the transthalamic “shortcuts”
are nearly equidistant from all neocortical areas.22 With the thalamus as a match-
maker, the effective connectivity between local neocortical populations can be
changed according to current computational needs. The key ingredient in this
globalization process is the ability of the oscillatory mechanisms to recruit
anatomically distant cortical neurons into temporal coalitions. Thus, in addition
to the interarea long-range connections among the various cortical regions, the
thalamus provides additional radial “shortcuts” necessary for reducing the synap-
tic path lengths between the various cortical areas.23 The weak connections can be
ampliﬁed by phase modulation, due to the resonant properties of the thalamic and
cortical modules involved. As a result, modules with resonant relations between

186
RHYTHMS OF THE BRAIN
23. Speed limitations should be kept in mind, however. Layer 6 corticothalamic ﬁbers are very
thin, and it may take 20–40 milliseconds for an action potential to reach the thalamic terminals. Layer
5 projections to higher order thalamic nuclei have much faster conduction velocities, however (Swad-
low, 2000). Miller (1996a, b) suggested that the cortical–thalamic–cortical loops tie together cell as-
semblies whose neuron members are dispersed throughout the neocortex.
24. Hoppenstead and Izhikevich (1998) use the analogy of radio frequency modulation (FM): the
frequency of oscillation encodes the radio station, while the information is transmitted via phase mod-
ulations.
25. Bremer (1935). Prior to these early works, sleep was thought to be a passive process. Purkinje
(1846) speculated that sleep was caused by a functional interruption of connections between the brain-
stem and the forebrain. This view was ampliﬁed by Constantin von Economo’s famous observation that
the likely cause of the pronounced somnolence (lethargy) in patients with “encephalitis lethargica”
(sleeping sickness) was extensive damage to their brainstem (von Economo, 1928). Because this
sleeping sickness reached epidemic proportions during and after World War I, it was believed to be
mediated by a virus, although an etiological agent was never identiﬁed. Steriade (2001b) is an excel-
lent source of information on these early experiments, along with the discovery and impact of the
reticular activating system described in Moruzzi and Magoun (1949).
26. Batini (1959). During wake/sleep transition, not only are the sensory inputs decreased but also
many other mechanisms, including decreased release of subcortical neuromodulators, are in action
(Steriade, 2001a). The various neuromodulators of the brainstem affect mostly the slow K+ channels
in their target cells and effectively “scramble” their spike times (Steriade and Buzsáki, 1990).
their frequencies can exchange information more easily than modules with
nonoscillating properties or dissimilar frequencies.24
Viewed from this new anatomical-physiological perspective, the thalamus is no
longer a gigantic array of independent relays but a large communication hub that as-
sists in linking large cortical areas in a ﬂexible manner. The principal mechanism of
the cortical–thalamic–cortical ﬂow of activity is self-sustained oscillations.
Oscillatory Patterns of Sleep
Unlike most body parts, the brain is busy at night, as well. A main function of
sleep is to isolate the brain from the body and the environment, which is the rea-
son why we can call it a default state. When all subcortical inputs to the thalamus
are severed by a horizontal cut through the brainstem of a cat between the supe-
rior and inferior colliculi, the neocortex displays waxing and waning oscillatory
patterns at 10–20 per second alternating with relatively ﬂat, low-voltage EEG.
Because in this highly transected brain, or cerveau isolé, preparation, as Frederic
Bremer at L’école de Médecine de l’Université Libre de Bruxelles called it, the
pupils of the cat are constricted and because similar spindles are also observed in
superﬁcial stages of sleep (see below), Bremer concluded that this deafferented
brain is in constant sleep.25 On the other hand, if the cut is made in the midpon-
tine region, preserving the mesencephalon’s key structures (e.g., the noradrener-
gic locus ceruleus and the cholinergic pedunculopontine/laterodorsal tegmental
nuclei), the cat is awake most of the time with dilated pupils and is able to
track visual stimuli.26 In a different, so-called encéphale isolé, preparation, the

The Brain’s Default State     
187
27. The dampened oscillatory pattern of sleep varies during ontogeny and is perturbed in many
psychiatric illnesses.
28. Principal component analysis of subjective sleepiness and objective spectral analysis of day-
time EEG showed correlated features of ultradian rhythmicities, with periods of about 100 min and
3–8 hours, with highest sleepiness index early in mid-afternoon (Tsuji and Kobayashi, 1988).
transection is performed at the caudal end of the medulla, just above the spinal
cord. The encéphale isolé cat shows normal sleep/wake cycles. The major con-
clusion of these and many subsequent experiments is that it is the subcortical
neuromodulators that keep the thalamocortical system awake rather than sensory
stimuli from the body and the environment. Furthermore, the thalamocortical
system alone cannot show organized sequences of sleep stages but is trapped in a
single superﬁcial sleep stage.
Because sleep is not simply a suspension of waking activities, there must be a
good reason why complex brains have developed an elaborate choreography of
sleep. In humans, at least ﬁve stages with progressively higher wakening thresh-
old can be distinguished, with the deepest stage being the rapid eye movement
(REM) phase (ﬁgure 7.3). Separation of the ﬁrst four stages, known collectively
as “non-REM” sleep, is based mostly on the relative numbers of sleep spindles
and delta waves observed (discussed below). Stage 1 is the phase transition be-
tween wake and sleep. It consists of a relatively low-voltage EEG with mixed fre-
quencies, mainly slow alpha and theta activity. Stage 2 is heralded by the
emergence of sleep spindles and K-complexes. Stage 3 is a mixture of spindles
and delta waves (20–50 percent), whereas stage 4 is characterized by the domi-
nance of delta activity with only traces of spindles. Approximately half of sleep
consist of stages 2 and 3; stage 4 composes only 5–15 percent of total sleep time
and may be completely missing after 40 years of age. Stages 3 and 4 are often re-
ferred to as slow-wave or delta sleep. Although stage classiﬁcation of sleep is use-
ful for pragmatic and clinical purposes, the temporal boundaries of these stages
are not precise. The electrical patterns of the ﬁfth stage, REM sleep, are charac-
terized by waking-type scalp EEG, rapid eye movements, loss of muscle tone, and
dreaming. REM sleep composes usually 20–25 percent of total sleep time in hu-
man adults, and it is an indication of the end of a non-REM/REM sleep cycle.
Typically, four or ﬁve non-REM/REM cycles with a period of 70–90 minutes
each occur within a night. These ﬁve stages are organized into a periodic se-
quence, giving a dampened oscillator appearance to the macrostructure of sleep
(ﬁgure 7.3).27 The evolving patterns are characterized by various oscillations at
different frequencies with different degrees of involvement of the various cortical
and thalamic structures. Ultradian periodicity is not unique to sleep but is also re-
ﬂected by the oscillatory nature of vigilance levels and cognitive performance
throughout the day.28 In other words, in the absence of environmental inputs or an
explicit algorithm, the brain gives rise to self-organized activity that follows a
complex trajectory in time and neuronal space.
As discussed in Cycle 5, the 1/f nature of brain signals reﬂects their history de-
pendence, a result of lumping long epochs. However, this long-term picture of high

188
RHYTHMS OF THE BRAIN
dimensionality and high entropy is very different if shorter time slices are exam-
ined, because transient oscillatory couplings reduce dimensionality and increase or-
der. Each evolving sleep stage has it own characteristic oscillatory pattern. This is
not surprising, based on what we have learned about the requirements of oscillators.
Oscillation is the inherent global behavior of balanced systems, whose frequency is
determined by some time constants of its constituents, such as intrinsic properties
or synaptic and axon conduction delays of neurons in the case of the brain. In the
thalamocortical system, numerous time constants arise from the intrinsic properties
of neurons, axon conduction, and synaptic delays, providing multiple possibilities
for both oscillation frequency ranges and spatial extent of neuronal involvement.
Below, I brieﬂy overview the characteristic physiological patterns of sleep.
Sleep Spindles
Sleep spindles are the hallmark of natural non-REM sleep. After their sporadic
onset following the slow alpha dominance, the intensity of sleep spindles in-
creases progressively. With the increasing enslavement to oscillations, the respon-
siveness of neurons to other sensory and motor perturbations decreases further as
sleep deepens.
A key element for the generation of sleep spindles is the mutual interaction
between the GABAergic reticular neurons and the excitatory thalamocortical
cells. Let us assume that a small group of thalamocortical neurons, which jointly
Figure 7.3. Sleep is a dampened oscillation with approximately 90-minute periods. Top:
Hypnogram of a night’s sleep in a young adult human. Note periodic ascending and de-
scending phases. Bottom: Representative scalp-recorded EEG segments from each sleep
stage. EEG traces are courtesy of A.A. Borbely.

The Brain’s Default State     
189
29. Because lesions of the reticular nucleus, but not the neocortex (Morison and Basset, 1945),
abolish spindles (Steriade et al., 1995) and because barbiturate-induced oscillations survive in the iso-
lated reticular thalamic tissue (Steriade et al., 1990a,b), Steriade and colleagues suggested that the
reticular thalamus alone acts as a true pacemaker (Steriade et al., 1990b; 1993c). As discussed above,
reticular neurons can communicate with each other by synaptically released GABA, dendrodendritic
synapses, and gap junctions. In principle, such connectivity may be sufﬁcient for a pacemaker sub-
strate. Nevertheless, because blockade of N-methyl-d-asparate (NMDA) receptors in the thalamus,
that interfered with the slow excitatory transmission, abolished oscillations in the cortex of the rat, I
suggested that the minimum circuit for spindles involves both reticular and thalamocortical neurons
(Buzsáki,et al., 1990). This model is essentially an update of the thalamocortical–local interneuron
circuit of Andersen and Andersson (1968), but the local interneuron is replaced by the reticular cells
(Scheibel and Scheibel, 1966). In vitro work and computational models support the partnership model
(Steriade et al., 1993c; Destexhe et al. 1994; McCormick and Bal, 1997; Destexhe and Sejnowski,
2001). The most direct evidence for the model, using dual intracellular recordings, was obtained from
slices of the geniculate body of the ferret (Kim et al., 1997). It should be noted, however, that sleep
spindles are rare in the occipital cortical region; therefore, it is surprising to see a spindle-generating
mechanism in its thalamic input. Because the frequency of the oscillation in the geniculate slice is typ-
ically in the range of the alpha frequency band, it may well be that the oscillation described in the lat-
eral geniculate body is, in fact, more relevant to alpha oscillations than to sleep spindles.
innervate one or more reticular neurons, discharge together by chance, similar to
the emergence of hand clapping after a theater performance. All that is needed
for the emergence of oscillation is a seed of enough synchrony so that some
reticular neurons discharge, preferably a synchronous burst of spikes. The dis-
charging reticular cells now hyperpolarize the same and more thalamocortical
neurons because their axon collaterals diverge onto many thalamocortical neu-
rons. The next key event is that the inhibitory currents will bring the membrane
of the thalamocortical cells into the active range of Ih, and Ih, in turn, will depo-
larize the membrane, activate IT, and produce a burst of spikes both in those neu-
rons that initiated the events in the ﬁrst place and in other neurons. Because the
rebound spikes in the hyperpolarized thalamocortical neurons occur in syn-
chrony, they can initiate a new cycle and recruit more neurons in the next cycles
by the same mechanism as in the ﬁrst.29 In support of this hypothetical scenario,
McCormick and colleagues found that a burst of action potentials in a single
reticular neuron could generate an inhibitory postsynaptic potential in thalamo-
cortical cells that was large enough to result in the occurrence of a rebound low-
threshold Ca2+ spike and a burst of action potentials. Some of the bursting
thalamocortical cells, in turn, resulted in the generation of a “return” or “feed-
back” barrage of excitatory postsynaptic potentials in the originating single
reticular neuron. This simple, disynaptic loop is proposed to be the basis for the
generation of spindle waves.
Even if this simple model can account for the emergence of spindles on the ba-
sis of known connectivity and single neuron biophysics, it falls short in explain-
ing several other features of thalamocortical spindles. First, spontaneous “seeds”
of synchrony can occur at several thalamic spots relatively simultaneously. With
local thalamic connectivity only, it is hard to see how these seeds of spindles can
become synchronized. Indeed, both in vitro slice work and computation models

190
RHYTHMS OF THE BRAIN
30. Gibbs and Gibbs (1950) and Jankel and Niedermeyer (1985). The two types of spindle activity
show different maturational courses. The power of frontal spindles is greatest in young children (up to
about 5 years old) and rapidly decreases across the ﬁrst decade of life; by contrast, the spectral power
of centroparietal spindles varies little across age (Shinomiya et al., 1999). For a recent review on sleep
spindles, see De Gennaro and Ferrara (2003).
31. Not all thalamic neurons are innervated by the reticular group. Thalamocortical neurons in the
anteroventral and anteromedial nuclei do not discharge coherently with other thalamocortical neurons
during barbiturate-induced spindles or in the cerveau isolé cat preparation (Paré et al., 1987). These
nuclei, together with the neurons of the mediodorsal nucleus of the thalamus, connect limbic system
structures, e.g., the amygdala, with the prefrontal, cingulate, and temporal cortices. Instead of inner-
vation from the reticular nucleus, these limbic-system–associated thalamic neurons may receive their
GABAergic innervation and rhythm from the zona incerta or other inputs (Barthó et al., 2002; Bokor
et al., 2005). This difference in inhibitory control could explain the existence of two families of sleep
oscillations, a slower (8–12 hertz) frontal and a faster (12–20 hertz) more posterior rhythm (Ueda et
al., 2001). For traveling spindles in vitro, see Kim et al. (1997), and for computer models, consult Des-
texhe and Sejnowski (2001). The effects of decortication on the synchrony of thalamic spindles are
described in Contreras et al. (1996, 1997). Long-range horizontal connections are absent in the new-
born rat. As predicted from the lesion experiments in adult rats, cortical spindles remain localized or
travel slowly in the newborn (Khazipov et al., 2004). For a large-scale and detailed computational
modeling of sleep spindles and other thalamocortical rhythms, see Traub et al. (2002).
demonstrate that with local connections only, spindles emerge at almost any arbi-
trary location and travel at the speed of approximately 0.5 millimeter per second.
In contrast, spindles in the thalamus of the intact brain occur synchronously,
which explains why cortically recorded spindles are also coherent over a rela-
tively large area. The cortical mechanism of this global synchrony was demon-
strated in an elegant experiment by Mircea Steriade and his colleagues at Laval
University, Quebec, Canada. First, they showed synchronous barbiturate-induced
spindles in the thalamus of the intact cat over several millimeters. In the second
part of the experiment, they removed the entire cortical hemisphere. This proce-
dure did not prevent the continued occurrence of thalamic spindles. However, the
spindles were no longer synchronized but behaved like spindles in the isolated in
vitro thalamic slice preparation; that is, spindles from several site emerged inde-
pendently and asynchronously. If a traveling spindle wave emerging from one site
collided with another, the collision prevented further propagation.
The second problem with the two-neuron partnership model is that a single
pacemaker cannot account for the observation that, in both humans and other an-
imals, the frequency of frontally recorded spindles is slower (about 12 per sec-
ond) than that of spindles above the centroparietal cortex (about 14 per second).30
These differences in synchrony further support the notion that several seeds of
synchrony can emerge within the thalamus that are temporally coordinated by
their corresponding neocortical networks (ﬁgure 7.4).31
Slow 1 Oscillation
In the August 1993 issue of the Journal of Neuroscience, three papers appeared
back to back on the same topic. In them, Steriade and his collaborators described a
novel cortical oscillatory pattern. They broke away from the traditional Greek let-
tering tradition of frequency band labels and referred to the novel rhythm simply

The Brain’s Default State     
191
Figure 7.4. Cortical long-range connections synchronize thalamic activity. Top:
Barbiturate-induced spindles (8–9 hertz, lasting for 1–3 seconds) are synchronous at
multiple site in the thalamus (black dots in inset indicate recording sites Th1–Th8). Bot-
tom: Following decortication, spindling continued to occur at each electrode site, but
their temporal synchrony was disrupted. Reprinted, with permission, from Contreras
et al. (1996).
as “slow” oscillation because its frequency was less than 1 per second (referred to
as slow 1 in Cycle 5). Despite its modest name, the new pattern catapulted to fame
instantaneously. The slow 1 oscillation was soon found also in the human EEG
during sleep and was reproduced in cortical slice preparations in vitro.
Perhaps the most important feature of the slow 1 oscillation is its association

192
RHYTHMS OF THE BRAIN
32. The down state is caused by K+ channel activation and not by GABAergic inhibition (Kaila et
al, 1993). McCormick and colleagues have studied extensively the self-organizing properties of the up
and down states in cortical slices (Sanchez-Vives and McCormick, 2000; Shu et al., 2003b).
33. The latter possibility is indicated by the power-law scaling behavior of EEG and MEG in the
10–20 per second frequency band (Linkenkaer-Hansen et al., 2001) because sleep spindles are cou-
pled to the up state shift (Steriade et al., 1993b).
34. The fact that a completely silent cortical network can spontaneously revert back to activity is
further support for the notion that the default state of neurons is spiking rather than silence.
with a steplike change in the membrane potential of neocortical pyramidal neu-
rons from–70 to–80 millivolts to spike threshold. The hyperpolarized “down”
state is not simply due to synaptic inhibition. The neuron can be in the down state
for several seconds, much longer than expected by GABA-receptor–mediated in-
hibition or spike afterhyperpolarization. Indeed, the membrane voltage in the
down state is virtually ﬂat (ﬁgure 7.5), indicating the lack or extreme paucity of
synaptic activity. This ﬁnding is further supported by the increased input resis-
tance of the neuron in the down state and by the observation that nearby and dis-
tant neurons change their states synchronously. In large areas of the neocortex,
entorhinal cortex, subiculum, thalamus, and striatum, most neurons are either si-
multaneously hyperpolarized or stay in their “up” state, close to spike threshold.
The hyperpolarized down state, therefore, reﬂects mostly withdrawal of synaptic
barrages, since nearly all neurons are silent. The up state may emerge as a con-
sequence of excitation through reentrant loops of layer 5 pyramidal neurons and
is characterized by self-sustained depolarizing activity in both deep and more
superﬁcial cortical layers. The dynamics of the up and down state transitions
have not been studied in great detail yet.32 In several respects, the bistable be-
havior of the membrane is reminiscent of the open/closed states of membrane
channels but on a larger scale. Both events may be stochastic or governed by a
power law.33
Although it is the coherent changes of the polarization states of many neurons
that give rise to the slow rhythm in the extracellular space, the up and down shift
and the slow 1 oscillation can be dissociated. For example, under deep anesthesia,
several seconds of silence are followed by a few seconds of the up state. Small
cortical slabs, isolated by undercutting subcortical inputs and severing long-range
connections, also sustain up and down shifts. However, the short, 1- to 2-second
up states are separated by total silence lasting up to a minute. Up-down transitions
can also be replicated in cortical slices, indicating that the intracortical connectiv-
ity is the minimum and perhaps sufﬁcient condition for their occurrence. How-
ever, in the in vitro slice preparation, 1- to 3-second-long up state events are
interrupted by 5–10 seconds of silence.34
The fast transition from silence to population activity is reminiscent of self-
organized criticality, in which nonlinear interactions among the constituents evolve
into a critical state over time without an external agent. On the other hand, exter-
nal perturbations can also shift the complex system into a critical state. For exam-
ple, electrical stimulation in the down state can induce an up state shift, provided

The Brain’s Default State     
193
that the stimulus is applied after some minimum refractory period. The same ex-
act stimulus can terminate the up state. These in vitro stimulation studies provide
some insight into the mechanism of bistability in neocortical networks. Stimula-
tion during the silent period induces slightly stronger excitation than inhibition.
This perturbation brings about a balanced pattern of excitation and inhibition in
the recurrent cortical networks, which sustains activity for a while. Once the net-
work is active, the same stimulus evokes stronger inhibition and abruptly termi-
nates the up state, if applied around the time when the up state is about to
terminate spontaneously. This is interesting because the same cortical inputs can
produce a diametrically opposite change in the network state, depending on the
short-term history of the network.
The mechanisms responsible for bringing the active network back to silence
are not well understood. A combination of various factors, including decreasing
Figure 7.5. Cortical slow oscillation can trigger thalamocortical sleep spindles. Top left:
Intracellular and extracellular recordings of a cat under urethane anesthesia. Note sudden
and rhythmic changes of the membrane potentials between hyperpolarized (down) and de-
polarized (up) states and correlated EEG waves. The down-up shift can trigger spindle os-
cillations (spindle). Reprinted, with permission, from Steriade et al. (1993d). Bottom left:
In scalp recording of EEG in humans, the down-up shifts produce a sharp potential, known
as the K-complex in non-REM sleep. Reprinted, with permission, from Amzica and Steri-
ade (1997). Right: Large-scale recordings in the rat with multiple silicon probes from the
somatosensory cortex show virtually no spiking activity during the down state. Reprinted,
with permission, from Barthó et al. (2004).

194
RHYTHMS OF THE BRAIN
35. Steriade et al. (1993b,d,e), Timofeev et al. (2000) described slow oscillations in the isolated
cortical slab. For a review on slow oscillations, see Steriade (2001a, b; 2003). For possible mecha-
nisms of slow oscillations, see Sanchez-Vives and McCormick (2000), Compte et al. (2003), Shu et al.
(2003a,b), Petersen et al. (2003) and Petersen (2003). Achermann and Borbely (1997) identiﬁed slow
oscillations in the human sleep EEG.
36. Massimini et al. (2004) described the traveling wave nature of the slow oscillation and pro-
vided several other quantitative accounts of the propagation. The cellular events underlying the directed
nature of the traveling wave may be important for spike-timing–dependent plasticity (Ermentrout and
Kleinfeld, 2001).
input resistance of neurons, activity-dependent K+ currents, and gain of inhibition
over excitation, are considered opposing forces of excitation that collectively re-
vert the network into a silent state. Anesthetics that increase K+ conductance or
potentiate the action of GABA can prolong the down state. In contrast, cortical
neurons in the waking brain stay virtually constantly in the upstate. A major rea-
son for this is that a main action of subcortical neurotransmitters is to decrease K+
conductance of cortical neurons.
Recurrent and lateral excitation is the main mechanism through which excita-
tion can spread. This process takes time, given the low velocity of axon conduc-
tance. By stimulating the network and recording activity at various distances, one
can see how the latency of the up shift grows progressively longer with neurons
farther from the stimulation electrode. Spontaneous events also spread as a wave.
The seed of excitation in the cortical slice is not necessarily ﬁxed and can vary
from one event to the next.35 Studies on humans also document the traveling wave
nature of slow oscillation. Each wave originates at a deﬁnite location and sweeps
small or large parts of the cerebral cortex at a speed of 1–7 millimeters per mil-
lisecond. This is about 10 times faster than in the isolated cortical slab of the
anesthetized cat or in the cortical slice preparation of the rat and may be due to
the presence of intermediate- and long-range connections in the intact brain.36
The participation of neurons in successive up and down events is not random.
In the intact rat brain, the same set of neurons tends to initiate the up shift, and the
recruitment of subsequent neurons is also quite similar in subsequent events. It is
not clear what makes some neurons initiators and others followers, but it is likely
that synaptic connectivity plays an important role. Neurons that are more strongly
connected are more prone to be part of the initial event than neurons with weaker
synaptic links. One can only speculate that the synaptic weights that determine
the propagation direction of excitation were brought about by experience in the
waking state. This hypothesis would explain why anesthesia does not erase mem-
ories prior to the induction of anesthesia. If neurons ﬁred randomly under the in-
ﬂuence of anesthetics, such activity might equalize synaptic weights, potentially
leading to the erasure of previously learned skills and experiences.
The slow 1 oscillation does what it is expected to do: it biases the occurrence
of non-REM sleep–associated patterns, including gamma oscillation and sleep
spindles. In addition, the slow oscillation can explain two more clinically well-
known patterns of slow-wave sleep: delta waves and K-complexes.

The Brain’s Default State     
195
37. Steriade et al. (1993b,d,e) have already noted that down-up shifts of the slow oscillation trig-
gered sleep spindles. The association between sleep spindles and slow oscillation in humans was
demonstrated by Mölle et al. (2002). Buzsáki et al. (1988) showed that delta waves are not due to in-
hibitory postsynaptic potentials, and Metherate and Ashe (1993) found that delta waves were associ-
ated with a K+ conductance increase. Both studies implied that a main role of the cholinergic basal
forebrain is to block the K+ conductance (delta activity), which action is interpreted as “cortical
arousal.” For a review of the relationship between behavioral and electrophysiological arousal, see
Steriade and Buzsáki (1990), and for the cholinergic blockade of the down state, see Steriade et al.
(1993a).
38. All neuron types of the thalamocortical partnership participate in large-scale oscillations of al-
pha, spindle, delta, and even slow 1 oscillations, although different factors may dominate each of these
patterns. The involvement of voltage-gated channels can explain the competition between spindle os-
cillations and slower patterns, since the membrane can be only at one voltage level at a time. During
sleep spindles the membrane potentials of thalamocortical neurons are between –55 and –65 milli-
volts, whereas delta oscillations occur in the range –68 and –90 millivolts. The progressive hyperpo-
larization of thalamocortical neurons during the course of sleep may explain the prevalence of
spindles in early stages and delta dominance in stage 4 sleep (Nuñez et al., 1992). A portion of reticu-
lar neurons also displays up and down states (Fuentealba et al., 2005).
Origin of Delta Waves
As discussed above, the duration of both up and down states can be quite long un-
der anesthesia and especially in the isolated cortical slab, in which the duration of
neuronal silence can be maintained for tens of seconds. Such long silent (down)
episodes are never observed in the intact, drug-free brain. The longest silent peri-
ods last for 100–500 milliseconds during stage 3 and 4 sleep, associated with a
surface negative slow pattern, known as the delta wave. Similar to the down state
of the slow 1 oscillation, delta waves occur synchronously over the entire neocor-
tex. We can conclude, therefore, that delta waves of slow-wave sleep correspond
to the transient down state of the slow 1 oscillation. Although nearly all principal
neurons in all neocortical layers become silent relatively simultaneously, the large
cell bodies of layer 5 neurons generate most of the measurable extracellular cur-
rents. The hyperpolarizing shift in the cell bodies is reﬂected as a positive wave in
deep layers and draws current from the superﬁcial layers where delta waves have
a negative polarity. This novel interpretation of delta waves is in line with previ-
ous knowledge about delta sleep patterns. During delta oscillations, the deep pos-
itive waves are associated with an increase in K+ conductance and increased input
resistance of single neurons, which can be readily abolished by the activating
neurotransmitters acetylcholine or norepinephrine.37 As discussed above, in
deeper stages of sleep, thalamocortical neurons can sustain oscillations in the
delta frequency band (1–4 hertz). At the same time, the neocortex displays groups
of delta waves with a periodicity in the same range. One potential mechanism of
such a grouping is that the thalamic output toggles the neocortex back and forth
between up and down states. The initiator of this ﬂip-ﬂop event is not known and
probably involves several mechanisms. One source is neocortical, since down-up
shifts can occur in the absence of the thalamus, whereas the thalamocortical cells
without the cortex show nonsynchronous delta frequency oscillations.38

196
RHYTHMS OF THE BRAIN
39. Recently, a slow rhythmic modulation of delta power has been described in human sleep. This
ultraslow oscillation of power with a mean period of approximately 15 minutes appears to be an inte-
gral characteristic of the early non-REM sleep (Merica and Fortune, 2000).
40. Loomis et al. (1938), Roth et al. (1956), Halász et al. (1985), and Bastien and Campbell
(1992). For a recent review on K-complexes, see Halász et al. (2004). For the physiological correlates
of K-complexes, see Amzica and Steriade (1997, 1998).
The reciprocally connected toggle switches, the cortex and thalamic circuits,
can easily bias each other’s bistable states. A synchronous discharge of cortical
neurons during the upswing of the membrane can cause an up state shift in the
reticular neurons; in this state, they become more sensitive to other excitatory in-
puts, for example, to volleys from the thalamocortical cells. The synchronized
volleys of the thalamocortical neurons can also alter the state of cortical neurons,
depending on their membrane potential. From this perspective, the occasional
delta rhythm in stage 4 sleep is a special temporal case of the up-down shifts of
cortical activity, reﬂecting relatively symmetrical up and down states, correspon-
ding to the duration of delta waves. A critical part of this process is the sufﬁ-
ciently hyperpolarized state of thalamocortical neurons and the associated
transient silence of neuronal activity in large areas of the neocortex, reﬂected in
the EEG as a spatially coherent delta wave.39
Down-Up Shifts Trigger K-Complexes and Sleep Spindles
It has been known for many decades that spindles are often preceded by a large-
amplitude wave with a sharp component, reminiscent of the shape of the letter
K, for which reason they are called K-complexes. This distinctive EEG pattern
occurs most frequently during stages 2 and 3 of sleep, that is, when the occur-
rence of sleep spindles is also highest. The ﬁeld potential K-complex is associ-
ated with a population burst discharge of cortical neurons, including layer 5 and
6 pyramidal cells projecting to the thalamus. Such a strong and synchronous in-
put may discharge reticular cells directly or indirectly and thus could serve as
the initiator of sleep spindles. But how do K-complexes emerge? In more super-
ﬁcial sleep states, K-complexes can be elicited by all modalities of sensory
stimuli, including slight positional changes in bed. The multimodality of sen-
sory inputs can explain the spatial variability of the slow-wave/K-complex initi-
ation in different cortical sites. For these reasons, it has been debated whether
K-complexes reﬂect transient cortical arousal or sleep-protective events.40 It is
possible that the frequent association of spindles with K-complexes serves to
disengage the cortex from the sensory input by the self-organized spindle
mechanisms.
An endogenous trigger for sleep spindles is the down-up shifts of the slow 1 os-
cillation. These shifts are associated with a widespread and strongly synchronous
discharge of cortical principal cells. In the extracellular ﬁeld, the rapid down-up
transition in a large number of neurons results in a complex waveform, the “sponta-
neous” K-complex (ﬁgure 7.5). If the fast recruitment of cortical neurons during the
down-up shift occurs at times when thalamocortical neurons are in the activation

The Brain’s Default State     
197
41. The brain still is in charge of important vegetative functions, e.g., heart rate, blood pressure,
temperature, respiration, bowel movement, and blood sugar. Furthermore, communication between
the brain and body also includes hormonal signaling that continues to be active in all stages of sleep
(e.g., McEwen and Lasley, 2002).
42. Born et al. (1999). The “choice” between waking and REM sleep at the peak of the ascending
phase is perhaps the most intriguing point in the sleep cycle because it is the choice of simultaneously
enhancing or blocking the sensory inputs and motor outputs. REM sleep is the ultimate environment-
and body-deprived activity of the brain.
43. Day/night changes may be viewed as external inﬂuences, which are known to affect sleep,
perhaps through the circadian oscillator. Human volunteers isolated from such external phase-
resetting events can develop prolonged sleep cycles alternating with proportionally extended waking
periods (Strogatz et al., 1986). The orderly regulated sleep patterns in the normal brain are substan-
tially altered in numerous psychiatric diseases. It is tacitly assumed that sleep disturbance is a conse-
quence of the daily environmental interactions. One may wonder, however, whether the primary
perturbation is to be sought in the self-organizing ability of the brain, as reﬂected by sleep patterns,
and whether the disease is a consequence of the altered patterns of sleep. Sleep deprivation is known
to induce hallucinations, acute paranoia, and other symptoms (Babkoff et al., 1989), supporting such
a conjecture.
range of Ih and IT, a spindle is initiated. In humans, this relationship is reﬂected by
the strong correlation between slow 1 oscillation and the occurrence of sleep spin-
dles. If the up shift can bring about strong enough depolarization in cortical neu-
rons, transient gamma-frequency oscillation may be elicited instead of a spindle.
Such transient gamma rhythms during sleep may justify the clinically used term
“microarousal.”
Descending and Ascending Phases of Sleep Cycles
Over the past few decades, we have witnessed a spectacular progress in our under-
standing of the mechanisms of the various sleep oscillations. Yet, we have learned
very little about the interactions of these oscillations and the mechanisms that
bring about transition between the various sleep stages. Once the brain spends
enough time in stage 4 sleep with large delta oscillations, it descends from this
highly perturbation-resistant condition to more shallow states. In stage 2 of the as-
cending phase, the thalamocortical system arrives at an important bifurcation
point, a choice between awakening and REM sleep. The periods of the descending
and ascending phases of subsequent sleep cycles are quite similar but their depth
of modulation progressively diminishes during the night (ﬁgure 7.3). At the top of
every ascending phase, the brain faces the same bifurcation problem: to wake up
and be in control of the body or loose control of the skeletal musculature and fall
into REM sleep.41Yet, during the ﬁrst four cycles, the choice is typically REM; the
path of continuous waking is chosen only after the ﬁfth or sixth cycle.42 All these
transitions and stabilization of sleep stages evolve without a supervisor or exter-
nal inﬂuences.43
The forebrain EEG and many other physiological parameters of REM sleep
are quite similar to the waking state. However, the ability of sensory inputs to
perturb the brain reaches its minimum, and the nearly complete loss of muscle
tone paralyzes the body, preventing it from responding to the environment. The

198
RHYTHMS OF THE BRAIN
44. Jouvet (1999, 2004) popularized the term “paradoxical sleep” referring to the fact that the elec-
trographic patterns are quite similar to the waking brain yet arousing the subjects is more difﬁcult than
during slow-wave (non-REM) sleep. Grastyán and Karmos (1961) have independently discovered
similar electrophysiological features, including hippocampal theta oscillations, in the cat, and attrib-
uted them to dreaming.
45. If the environment remains stable, the prediction is that sleep patterns and spike content of
sleep-associated oscillations will remain similar. In support of this prediction, the ﬁring rates of si-
multaneously recorded hippocampal neurons remained distinctly similar for at least 12 hours, during
which time the rat experienced several wake/sleep cycles in its home environment (Hirase et al.,
2001).
46. The most comprehensive source of human rhythms is the EEG atlas of Niedermeyer and Lopes
da Silva (2005).
discrepancy between forebrain physiological parameters and the state of the
skeletal muscle system led the French sleep research pioneer Michel Jouvet to
call this state “paradoxical.”44
Given the deterministic nature of sleep, the initial conditions, that is, the state
of the brain network modiﬁed by the daytime experience, should predict the order
parameters and neuronal content of sleep.45 These fascinating issues are dis-
cussed in Cycle 8.
Partial Disengagement from the Environment: 
Family of Alpha Rhythms
Sleep is a drastic and global isolation of the cerebral cortex from environmental
inputs. What if we just eliminate one input at a time? This is as easy as shutting
your eyes. Once the eyelids are closed, the eyeball ceases its routine of slow and
ballistic movements for surveying the visual world. We have known since Hans
Berger’s work that, under these conditions, large-amplitude, rhythmic alpha
waves appear above the visual (occipital) cortex. Eye closure and cessation of
eye movements “release” rather than trigger the oscillation because there is not
a single “cause” for the occurrence of the activity. The occipital alpha rhythm is
regarded as the archetypal cerebral rhythm. Alpha oscillations are cortically
widespread and regionally attenuated by a diverse range of speciﬁc and nonspe-
ciﬁc stimuli and behaviors. The ongoing occipital alpha oscillation can be
promptly and consistently blocked by various manipulations, such as eye open-
ing, eye movement, visual imaginary, and even mental activity, such as arith-
metic calculations. Although alpha activity is most prominent above the visual
areas,46 oscillations in the alpha frequency band can be recorded over a large
part of the cortex, for example, over the frontal eye ﬁelds. These cortical areas
are in charge of controlling eye movements. The relative independence of the
occipital and frontal alpha oscillations is illustrated by their different frequen-
cies: alpha waves are faster at occipital and slower at more anterior recording
sites. The traditionally deﬁned frequency range of the alpha band is from 8 to

The Brain’s Default State     
199
47. Immobility can exert an effect on the activity of the somatosensory cortex in two different
ways. When a skeletal muscle contracts, the state of the muscle is reported to the somatosensory path-
ways by the so-called muscle spindle receptors and stretch sensors in the tendons. A motor command,
generated in the motor cortex, eventually contracts or relaxes the muscles, and these changes are reg-
istered by the somatosensory system. In a more direct way, motor neurons can affect neuronal activity
in the somatosensory cortex even when the peripheral outputs and inputs are severed. These intracor-
tical pathways are poorly understood, but since the works of von Holst and Mittelstaedt (1950) and
Sperry (1950), it has been believed that this reafferenz prinzip or corollary discharge is critical for dis-
criminating sensations due to our own movements from those that arise from the changing world
around us.
48. The Rolandic ﬁssure is the major sulcus that separates the frontal and parietal lobes. It sepa-
rates the primary sensory and the primary motor gyri.
49. The supplementary motor area (Brodmann area 8) is the area anterior to the primary motor
cortex that is important in temporal (sequence) organization and initiation of movements.
12 hertz. However, individual variations are quite large, and the mean fre-
quency of alpha varies as a function of age, gender, and even intelligence. It is
quite low in frequency in the infant human (< 7 hertz), reaches its maximum in
young adulthood, and declines with age.
A rhythm that is similar to occipital alpha in frequency and, perhaps, in
mechanisms can also be recorded above the sensory-motor cortical area. How-
ever, the conditions that give rise to this rhythm are quite different. It is indif-
ferent to the presence or absence of visual input but requires immobility of
skeletal muscles.47 Conversely, it can be blocked by simply clenching the ﬁst or
by just moving a ﬁnger or a toe. Its waveform is also different, and its slightly
spiky and arch-shaped morphology resembles a series of the Greek letter mu
(µ), hence its most frequently used name: mu rhythm. The pattern has been “re-
discovered” numerous times by various investigators, which explains the multi-
tude of terms that refer to the same motor-relaxation–associated rhythm (en
arceau, arcade, comb, wicket). The less poetic terms “Rolandic,” “central,” and
“somatosensory” alpha refer to the dominant cortical location of these oscilla-
tions on the banks of the Rolandic ﬁssure.48 Importantly, even in the case of a
very simple movement, such as moving a ﬁnger voluntarily, attenuation of the
mu rhythm begins approximately 2 seconds prior to the actual movement, indi-
cating time-intense computation of a voluntary act. Alpha oscillation has also
been observed in the supplementary motor area of the cortex.49 This rhythm is
usually coherent with the Rolandic mu rhythm, and both oscillations are re-
placed by low-amplitude gamma-frequency oscillation upon ﬁnger or wrist
movement. The intrinsic and independent nature of the alpha rhythm in the sup-
plementary motor area was ﬁrst demonstrated by the selective suppression of
local alpha upon “planning” of movement by Gert Pfurtscheller and colleagues
at the University of Graz in Austria. In the absence of overt movement but
“planning” to move, alpha and mu rhythms could be topographically dissoci-
ated. Furthermore, high-spatial-resolution studies have demonstrated that mu
synchrony can be selectively attenuated in a somatotopic manner. Isolated
movement of the ﬁnger, thumb, foot, or tongue blocks the oscillation in the 

200
RHYTHMS OF THE BRAIN
50. Pfurtscheller and Berghold (1989), Pfurtscheller (1992), Andrew and Pfurtscheller (1996), and
Manganotti et al. (1998). These ﬁndings with scalp recordings have been conﬁrmed by subdural elec-
trode grids in patients (Arroyo et al., 1993). However, Crone et al. (1998), also using subdural grid
recordings, did not ﬁnd spatial topography. In their study, movement resulted in widespread desynchro-
nization, including the ipsilateral somatosensory cortex. Pfurtscheller et al. (2000) suggested that topo-
graphical selectivity is visible only in the upper band (10–12 per second) of the mu rhythm, whereas
nonspeciﬁc, widespread attenuation is evoked by movement in the lower (8–10 per second) frequencies.
51. The ﬁndings of Lehtela et al. (1997) support the existence of a distinct, reactive auditory
rhythm in the human temporal cortex. Monaural bursts of white noise selectively blocked oscillatory
6.5–9.5 hertz MEG activity, with sources in the superior temporal lobes.
52. Using independent component analysis, Makeig et al. (2002, 2004) differentiated between pos-
terior and central alpha rhythms and left and right mu rhythms. Children show reduced anterior power
of alpha and reduced coherence between anterior and posterior electrodes in comparison to the adults
(Srinivasan, 1993).
53. There seems to be a reciprocal relationship between spindles and alpha oscillations. Alpha os-
cillations are conﬁned mainly to the ﬁrst-order thalamocortical systems, whereas spindles dominate 
corresponding somatosensory area, whereas the surrounding areas can show in-
creased power of mu oscillation.50
Using MEG, Riitta Hari and colleagues at the Helsinki University of Technol-
ogy discovered yet another rhythm in the alpha band above the auditory (midtem-
poral) cortical region. They called it the “tau” rhythm, referring to its temporal
cortical origin. The tau or third alpha rhythm is not affected by visual or so-
matosensory stimulation or by eye or hand movements but can be effectively
blocked by acoustic stimulation.51 Although the frequency and wave shape of the
different alpha rhythms vary somewhat, their critical common denominator is that
they emerge spontaneously in the speciﬁc sensory and motor areas of the cortex
and ﬁrst-order thalamic nuclei in the absence of relevant sensory inputs and mo-
tor outputs.52 They can occur in isolation and be selectively attenuated by appro-
priate stimulation, indicating that cortical regions associated with different
sensory modalities can sustain input-speciﬁc activity in relative isolation. In sum-
mary, alpha oscillation is a physiological reﬂection of the unperturbed state of
ﬁrst-order thalamic nuclei and their primary sensory and motor cortical partners.
The isolated blockade of alpha activity in the areas involved in sensation and ac-
tion convincingly illustrates the division of labor in the cerebral cortex. Collec-
tively, these observations suggest that the ﬁrst- and higher- order thalamocortical
systems differ not only in terms of their anatomical connectivity between thala-
mic nuclei and cortical areas and their selective GABAergic control by the reticu-
lar nucleus and the zona incerta system but also in terms of their large-scale
physiological behavior: the ability to generate alpha oscillations.53
Origin of Alpha Rhythms
In contrast to the well-studied and well-understood behavioral correlates of alpha
oscillations, no ﬁrm explanation exists regarding their genesis. Two major classes

The Brain’s Default State     
201
mainly the higher order systems. This physiological dichotomy may be related to the reciprocal fMRI
signals in the parietal-prefrontal “attentional” system and sensorimotor cortical areas (Greicius et al.,
2003; Fox et al., 2005).
54. The strict deﬁnition of pacemaker is that its clock function is entirely determined by internal
mechanisms without any external feedback. However, it may rely on some external “activation” or
energy, but such input should not directly contribute to the phasic output of the pacemaker. E.g., a
battery for a watch or an ambient neurotransmitter(s) for neuronal groups is not considered feed-
back. Brain networks, however, are complex feedforward and feedback systems, and too often it is
not easy to distinguish between the “energizer” and rhythmic feedback provider role of recurrent
pathways.
55. Norbert Wiener (1961) speculated that the human alpha rhythm is a result of coupled nonlin-
ear oscillators. Lopes da Silva et al. (1974, 1980, 1997) and Nuñez (1998, 2000) suggest that cortical
networks act as a band-pass ﬁlter at alpha frequency driven by a temporal brown noise. The random
walk feature of brown noise would be responsible for the aperiodic nature of alpha trains. These theo-
ries do not address the source of noise, however, even though noise is of the essence in these models.
The general model of Kelso and Fuchs (1995) assumes that brain activity displays trajectories, char-
acteristic of Shilnikov chaos. However, the high expectations generated by early reports of low-
dimensional chaos in the brain (e.g., Babloyantz et al., 1985; Freeman, 1992; McKenna et al., 1994)
have not been backed up by strong experimental support. Other experiments indicate that alpha
rhythm is often indistinguishable from linearly ﬁltered noise (Stam et al., 1999; Gebber et al., 1999).
See also other models by Jirsa and Haken (1996), Robinson et al. (1998), Stam et al. (1999), and Liley
et al. (2002), and for a recent review, see Nuñez (2000).
of hypotheses can be distinguished as attempts to explain their origin. “Pace-
maker” models, favored mostly by neurophysiologists,54 assume that alpha oscil-
lations arise from the endogenous rhythmicity of cortical or thalamic neuronal
populations, which entrain other thalamocortical partners. Models in the second
class of hypotheses assume that such oscillations emerge from the synaptic cou-
pling of distributed populations of neurons and that no single group is responsible
for the rhythm. The oscillation emerges in the context of a limit cycle or deter-
ministic chaos or is a consequence of linearly ﬁltered noise by some time con-
stants and nonlinear ampliﬁcation property of the system. All these computational
models have some experimental support, but in general, they are too vague to
pinpoint speciﬁc mechanisms and apply to a large set of oscillations not only al-
pha.55
The occipital alpha rhythm is prominent in animals with saccadic eye move-
ments, large visual cortex, and binocular frontal vision, but it is virtually absent in
the rat—the most extensively studied laboratory animal—and other nocturnal
species. This absence is perhaps the major reason why we know so little about the
mechanism of its generation. Most of the early work in this ﬁeld was done on
anesthetized cats in Andersen’s laboratory and in behaving dogs in Fernando
Lopes da Silva’s laboratory in the Institute of Medical Physics, Utrecht, the
Netherlands. Simultaneous recording from thalamic lateral geniculate nucleus
and occipital cortex showed highly coherent ﬁeld and unit activity between the
two structures, suggesting the involvement of thalamic mechanisms. Recent in
vitro work on the ferret and cat thalamus further supports the critical role of the

202
RHYTHMS OF THE BRAIN
56. The classical monograph of Andersen and Andersson (1968) described mostly experiments
done under anesthesia, and the mechanisms described therein may be more relevant to sleep spindles
than to alpha oscillations. For experiments in dogs, see Lopes da Silva et al. (1974, 1977l 1978, 1980;
Lopes da Silva and Storm van Leeuwen, 1978). Hughes et al. (2004) suggest that metabotropic
mGluR1a receptor activation of thalamocortical neurons and their gap junction coupling are parts of
the alpha-promoting mechanisms. Work from McCormick’s laboratory has been mostly dedicated to
sleep spindles, but they may also be relevant to occipital alpha oscillations (McCormick and Bal,
1997).
57. Tadeusz Marczynski also found a reliable positive correlation between the magnitude of
“postreinforcement synchronization” (i.e., mu rhythm) and the number of training sessions required
for learning to press a lever for milk reward (Rick and Marczynski, 1976). He also showed that light or
eye closure is not required for the occurrence of the rhythm. The alpha enhancement discovered by
Marczynski is evident in many recent reports (e.g., Fries et al., 2001b). For a review of mu rhythm in
the cat, see Rougeul-Buser and Buser (1997).
58. One of the most beautiful anatomical demonstrations of topographic representation in the cor-
tex is the “barrel” organization in rodents (Woolsey and Van der Loos, 1970). Each barrel in the pri-
mary somatosensory cortex and barreloid in the ventral posteromedial thalamus corresponds to an
identiﬁed whisker on the face, much like the orderly representation of ﬁngers and other body parts.
For a review, see Miller et al. (1991), Kossut (1992), Swadlow (2002), and Petersen (2003).
thalamus in occipital oscillations.56 Alpha-like activity has been also observed in
the sensorimotor cortex of the cat, in synchrony with neuronal discharges in the
ventralis posterior thalamic nucleus. Although the different investigators refer to
this rhythm as somatosensory rhythm or postreinforcement synchronization, the
frequency, waveform characteristics, and immobility dependence of the oscilla-
tion indicate strong homology with the human mu rhythm.57
In contrast to vision, rodents have an elaborate somatosensory representation.
The face whisker system has an orderly and large representation in both the thal-
amus and sensory cortex.58 Therefore, on the basis of evolutionary continuity,
one expects to see a rhythm analogous to the human mu rhythm in rats. And
there is one. In fact, the best-organized oscillation in the neocortex of the rodent
is a waking immobility-related rhythm of 6–10 per second, with its largest am-
plitude over the somatosensory cortex. Because of its particularly large ampli-
tude, I called it the high-voltage spindle (HVS). Its spike-and-wave form shares
more similarity with the human mu rhythm than with the more sinusoid occipital
alpha. Like in the cat, episode duration can vary from seconds to tens of seconds
during immobility, but the rhythm disappears promptly at the onset of sponta-
neous or evoked movement or by stimulation of the whiskers or other body parts.
As is the case for all alpha rhythms in humans, HVS also disappears during
sleep.
The long-term dynamics of HVS are quite complex, with trains of HVS recur-
ring rhythmically at 10–30 seconds and 15–30 minutes. Studies on HVS revealed
the elaborate and widespread mechanisms involved in the regulation of thalamo-
cortical rhythms. Units in the reticular thalamus as well as in the somatosensory
and motor thalamic nuclei are entrained to the spike component of HVS. Neurons
in the neocortex, striatum, pallidum, cerebellum, locus ceruleus, and other brain-
stem nuclei may also be recruited intermittently. Unilateral damage to the reticu-
lar nucleus can completely abolish the rhythm in one hemisphere, leaving the

The Brain’s Default State     
203
59. Semba and Komisaruk (1980) were the ﬁrst to use the term “mu” in the rat. For reviews, see
Buzsáki et al. (1990). For sensory perturbation of HVS, see Wiest and Nicolelis (2003). These authors
also emphasize the similarity between HVS and mu rhythm in humans. Buzsáki et al. (1991),
Nicolelis et al. (1995), Kandel and Buzsáki (1993), and Berke et al. (2004) illustrate phase-locked unit
activity in numerous brain structures.
60. Ultrahigh-frequency ripples (300–600 hertz) are present during both HVS and sleep spindles
(Kandel and Buzsáki, 1997) as well as epileptic discharges (Grenier et al., 2001). Ripples in the so-
matosensory cortex can also be evoked by somatosensory stimulation in both rats (Jones and Barth,
1999) and humans (Curio et al., 1994).
expression of HVS in the other hemisphere intact.59 Nevertheless, the reticular nu-
cleus cannot be regarded as a true pacemaker because its activity profoundly de-
pends on the excitatory inputs from thalamocortical and corticothalamic neurons.
The currents associated with HVS in the neocortex are quite complex, of
which only a very small portion reﬂects the synaptic activity of thalamocortical
neurons. Instead, the thalamic inputs are strongly ampliﬁed, and the current dis-
tribution reﬂects mostly the activity of intracortical neuronal activity. In the sim-
plest interpretation, it appears that the thalamus supplies the rhythm whereas the
currents arise mainly as a result of intracortically organized patterned interactions
among the various layers. Because the intracortical activity patterns are not
strictly coordinated in time and because both ﬁrst-order and higher order thalamic
nuclei are involved, the various combinations of the multiple ﬁeld dipoles give
rise to a substantial wave shape variability of HVS (ﬁgure 7.6). So what appears
as a relatively uniform mean ﬁeld on the brain surface is actually a combination
of numerous subpatterns that can be appreciated and analyzed only by simultane-
ously monitoring of all cortical layers.
The strong intracortical activation, associated with HVS, gives rise to a super-
synchronous rhythmic discharge of neurons in multiple cortical layers and a
short-lived ultrafast rhythm (300–600 per second).60 Assuming that similar mech-
anisms are at work for the occipital alpha and auditory cortical tau oscillations,
we can conclude that these rhythms arise as a result of a complex interaction be-
tween the GABAergic thalamic neurons and thalamocortical neurons combined
with neocortical ampliﬁcation of the thalamic signals. All these steps are neces-
sary parts of the oscillatory machinery. Given the dominance of alpha-type oscil-
lations in the circuits involving the ﬁrst-order thalamic nuclei, we can conclude
that the extent of alpha oscillations is an indication of the cortical disengagement
from inputs of the body and the environment.
Disconnection from some aspects of the environment is by no means an indica-
tion of decreased brain performance. We also have to emphasize that alpha oscilla-
tions are not sleep patterns. The alpha peak in the human scalp EEG power
spectrum is prominent under virtually all waking conditions, not only when eyes
are closed and muscles are relaxed, although these conditions robustly increase the
power in the alpha band. The “idling” hypothesis of alpha oscillations explains the
waking alpha peak in the EEG by assuming that not all sensory areas are active all
the time. Eyes or skeletal muscles are not moving constantly, and alpha may build
up in some intervening periods. When cortical columns are involved in processing

204
RHYTHMS OF THE BRAIN
Figure 7.6. Somatosensory “alpha” (mu rhythm) oscillations in the rat consist of multiple
time-shifted dipoles. Left: Location of the silicon probe and the recording sites in relation to
the different cortical layers. Middle: Three cycles of an HVS episode. Vertical lines indicate
the presence of at least three putative dipoles contributing to the fast component of the os-
cillation with different depths of phase reversal. Dipole 3 was occasionally observed as a
separate event (3′). Right: Vertical spread of multiple unit from layer 5 to superﬁcial and
deep layers during the fast component of dipole 3. Most cortical oscillators consist of mul-
tiple, time-shifted dipoles, as illustrated here. Because of its high amplitude and waking-
immobility correlate, the rhythm shown in the ﬁgure is called high-voltage spindle (HVS) to
distinguish it from sleep spindles. However, both depend on the integrity of the reticular nu-
cleus of the thalamus, and both consist of multiple dipoles (Steriade and Deschênes, 1984;
Buzsáki et al., 1988). Reprinted, with permission, from Kandel and Buzsáki (1997).
inputs from the legs, other columns can stay disengaged and produce alpha oscil-
lations. This “off-duty” hypothesis, therefore, suggests a very strict temporal rela-
tionship between sensory processing, motor activity, and the suppression of alpha
waves. However, it cannot explain why, in various cognitive tasks, alpha power in-
creases with task difﬁculty (see Cycle 12). An alternative hypothesis is that self-or-
ganized alpha oscillations are a reﬂection of internal, mental operations. Cycle 8
provides ample examples of such internal processes.
In summary, sleep- and rest-associated oscillations are the best examples of
self-organized operations in the brain. The trajectory of state changes in neuronal
space is predictable from the history of previous sleep states, indicating the deter-
ministic dynamics of sleep. Nevertheless, very little is known about the mecha-
nisms that force the brain to change and stabilize its trajectory of activity and even
fewer experimental data are available about the neuronal content of these state
changes. It is expected that the initial conditions (i.e., waking experience superim-
posed on the past history of brain circuits) can affect both the state variables that

The Brain’s Default State     
205
govern the evolution of sleep stages and the ensemble spike patterns that underlie
these states. What is the empirical evidence for such conjecture? Read on.
Brieﬂy . . .
The thalamus is a hub for the neocortex that provides functional shortcuts be-
tween the vast areas of the cerebral hemispheres and reduces the synaptic path
lengths between the various cortical areas. Both the excitatory thalamocortical
and the inhibitory neurons of the reticular nucleus are endowed with various in-
trinsic conductances, which promote oscillations at various temporal and spatial
scales. First-order and higher order nuclei of the thalamus have reciprocal rela-
tionships with sensory and associational cortices, respectively. Such a dichotomy
of thalamic organization is also reﬂected in the differential inhibitory control of
higher order nuclei by a large set of extrathalamic structures.
In the absence of environmental inputs, the brain gives rise to self-organized
activity that follows a complex trajectory in time and neuronal space during sleep.
The extent of thalamic and neocortical involvement varies in the different oscilla-
tions of sleep. The isolated neocortex or small pieces of the neocortex alone can
sustain self-organized patterns. Neurons in local or global regions of the cerebral
cortex rapidly swing between excitable and less excitable (up and down) states. In
the intact brain, properly timed exogenous inﬂuences (e.g., external sensory or
body-movement–associated signals during sleep) can trigger upswing changes,
provided that the cortical network has already spent a sufﬁcient amount of time in
the down state. The persistent activity in the up state is due to a balanced recur-
rent excitation and inhibition. The network-generated buildup of intracellular
Ca2+ and Na+ activates a K+ current, which together with increasing efﬁcacy of in-
hibition terminates recurrent activity and brings the network back to silence.
The average length of the down state increases as sleep deepens. The down
states are reﬂected as positive waves in deep layers and negative deﬂections in
scalp and superﬁcial cortical layer recordings. These silent epochs are the delta
waves of slow-wave sleep. The silent periods are associated with increased K+
conductance that can be blocked by various subcortical neurotransmitters. The
neuronal synchrony, associated with the down-up depolarization shift, is re-
ﬂected in the ﬁeld and scalp recordings as a K-complex. Parallel with the in-
creasing probability of cortical up-down state shifts, the membrane potential of
thalamocortical neurons progressively polarizes. Due to specialized voltage-
gated channels in thalamocortical and reticular neurons (IT, Ih, and ICAN), the up
state shift can either trigger sleep spindles or induce dominant delta activity.
The strong cholinergic activity during REM sleep and in the waking brain is
mainly responsible for the lack of down states in cortical neurons. The most
prominent oscillation of the waking brain is the family of alpha rhythms that oc-
cur selectively in every sensory and motor thalamocortical system in the absence
of sensory inputs. Nevertheless, alpha oscillations are not simply a result of sen-
sory disengagement but may reﬂect internal mental processing.

Cycle 88
Perturbation of the Default Patterns 
by Experience
With regard to sleep and waking, we must consider what they are: whether
they are peculiar to soul or to body, or common to both; and if common, to
what part of soul or body they appertain.
—Aristotle, On the Soul
206
Aristotle could not care less about the brain.1 Nevertheless, even if we substitute
or equate the soul with brain mechanisms, the question is as puzzling today as it
has been for the past 2,400 years: do our daytime experiences determine the exact
trajectory of sleep the following night, or does the self-organized process of sleep
determine how the waking brain reacts to environmental perturbations? It was
conjectured more than a century ago that learned material remains in a fragile
state after the experience but strengthens over time, and sleep is suspected to be
responsible for the consolidation process.2 Ever since the discovery of REM sleep
in 1953 and its association with its subjective content, dreaming, this peculiar
stage of the sleep cycle has been believed to be responsible for the consolidation
effect. Because dreams have been thought to incorporate events of daily life since
1. See Cycle 1 for the discussion of Aristotle’s view on the heart and brain.
2. Memory, in its widest deﬁnition, is neuronal representation of past experiences that persists over
time. Consolidation of memory is a hypothetical construct referring to the progressive stabilization of
the memory trace in long-term storage. A metaphor often used to illustrate this concept is the develop-
ment of a photograph. Taking a picture corresponds to the encoding process, and the chemical develop-
ment of the image is consolidation. The memory trace may be rekindled by rehearsal, recall,
associations, or dreaming (Squire, 1992; Squire and Zola, 1998; McGaugh, 2000; Nader et al., 2000;
Sara, 2000; Dudai and Eisenberg, 2004) and strengthened repeatedly. In general, actualization of the
same coherent spatiotemporal pattern of neuronal activity or recreation of a neural attractor responsible
for the speciﬁc assembly patterns provides the necessary conditions for the plastic changes required for

Perturbation of the Default Patterns by Experience
207
the stabilization or reparation of the trace. Retrieval of memory traces not only can strengthen them
but also can make them vulnerable each time they are recalled. The fragile nature of the trace and its
modiﬁability by the multiple stabilization processes are the fundamental neurophysiological reasons
for our “untrustworthy” memories (Loftus, 1997). For a very readable history of twentieth-century
memory research, see Milner et al. (1998).
3. The impact of Freud’s The Interpretation of Dreams (1900) is hard to dismiss even today. Aserinsky
(1996) and Gottesman (2001) are perhaps the best descriptions of the discovery and history of REM sleep.
For recent physiological works in favor of REM sleep’s role in memory consolidation, consult Winson
(1990, 1993), Pavlides and Winson (1989), Karni et al. (1994), Smith (1995), and Louie and Wilson (2001).
4. There are, of course, differences between REM and the waking brain. E.g., several subcortical
neuromodulators (serotonin, norepinephrine, histamine, hypocretin) reach their highest and lowest
levels of release during waking and REM, respectively. However, these and other known differences
do not explain why REM would be special for memory consolidation (Macquet and Franck 1996).
5. REM sleep deprivation by physical means refers to waking the subject every time some REM
sleep is detected. In small animals, the “inverted ﬂower plot” method is used most frequently: a small
platform is placed in a water tank, and every time the animal loses its muscle tone at the onset of
REM, it falls into water. Obviously, after waking, the subject does not immediately return to the same
stage of non-REM; thus, the procedure is not selective.
6. It has been also conjectured that sleep, and particularly REM sleep, serves to stimulate those
synapses that were not sufﬁciently used during wakefulness to maintain their synaptic connections
(Fowler et al., 1973; Krueger et al., 1995; Kavanau, 1997). Accordingly, neurons in REM sleep may
discharge randomly and erase synaptic modiﬁcations brought about by the waking brain (Crick and
Mitchison, 1983). For a criticism of REM sleep as a sole mechanism of memory consolidation, see
Buzsáki (1998), Vertes and Eastman (2000), and Siegel (2001).
7. I suggested that “idling” patterns and non-REM sleep that are contiguous with waking experience
are essential for memory consolidation, rather than REM sleep (see Cycle 12), on the basis of the elec-
trophysiological similarities of assembly patterns between non-REM sleep in the hippocampus and the
requirements of synaptic plasticity (Buzsáki, 1989). Numerous studies support this two-stage scenario
(Wilson and McNaughton, 1994; Stickgold et al., 2001; Destexhe and Sejnowski, 2001; Hobson and
Pace-Schott 2002; Steriade and Timofeev, 2003; Born and Wagner, 2004; Ribeiro et al., 2004). How-
ever, see criticism by Vertes and Eastman (2000), Siegel (2001, 2005) and Tononi and Cirelli (2006).
ancient times, it was logical to assume that rehearsal of learned information in
dreams could make repeated use of the brain hardware during REM sleep.3
Although initially large numbers of experiments, primarily involving a “selec-
tive” REM sleep deprivation design, seemed to support the critical role of REM
in memory consolidation, the technical and theoretical problems with those ex-
periments have begun to surface in the past two decades. First, the forebrain pat-
terns of activity of REM sleep are quite similar to those of the waking brain.4 So
one wonders what special processes are at work in REM that cannot happen in the
waking brain. Second, by physical means it is impossible to selectively deprive
the brain of REM sleep without affecting the whole sleep process because sleep is
a dynamic process. The techniques used to deprive the brain of REM sleep are
quite stressful, and therefore, stress could be the explanation for the performance
deﬁcit after perturbed sleep.5 Third, a large body of clinical literature shows that
millions of patients on antidepressants that decrease, and in some cases eliminate,
REM stage do not complain of striking memory problems.6 Finally, there is a the-
oretical problem: where does the memory trace reside between waking experi-
ence and the emergence of REM sleep?7 The experiments discussed in this Cycle

208
RHYTHMS OF THE BRAIN
8. Synaptic modiﬁcation during sleep cannot be the whole story, though, since it does not explain
the serious consequences of sleep deprivation. According to recent views, sleep corrects hypothetical
metabolic deﬁcits that build up during waking (Borbely, 1998; Borbely and Tobler, 1989; Greene and
Siegel, 2004). Vertes (2004) suggests that the role of REM sleep is to provide periodic stimulation to
the brain and promote recovery from sleep. If this were they case, then patients on antidepressants and
reduced REM sleep (Vertes and Eastman, 2000) would have problems waking up, which is not the
case. For metabolic changes of brain areas during sleep, see Macquet and Franck (1996) and Hoﬂe
et al. (1997).
9. For the consolidation hypothesis of memory trace in the thalamocortical system during sleep,
see Steriade and Timofeev (2003) and Destexhe and Sejnowski (2001).
10. For a concise summary of the multitude of molecular biological changes associated with
synaptic plasticity, see Kandel and Squire (2000) and Bliss and Collingridge (1993).
aim to illustrate that the deterministic patterns of sleep and rest can be perturbed
by waking experience. After each day’s experience, however, the brain falls back
to the default pattern to rerun and intertwine the immediate and past experiences
of the brain’s owner.
Behavioral Effects of the Self-Organized Oscillations 
of Rest and Sleep
We spend one-third of our life in sleep, a major part of which is non-REM sleep.
There must be a good reason why complex brains have developed an elaborate
choreography of periodically recurring sleep stages. Indirectly, the importance of
sleep is illustrated by the fact that the metabolic cost of maintaining brain activity
is only slightly reduced during sleep, and in many, nonsensory, parts of the brain,
the energy cost rivals with that of the waking brain.8 Even in hibernating animals,
brain metabolism remains relatively high.
Sleep is characterized by strong synchrony of neuronal activity, brought about
by the prominent oscillations of the various stages of the sleep cycle. Unfortu-
nately, very few empirical ﬁndings are available on the neuronal content of sleep
oscillations. Extrapolating from experiments on the hippocampus (Cycle 12), let
us assume that the neuronal content of thalamocortical oscillations of rest and
sleep is inﬂuenced by waking experience.9 If so, the repeated activation of the
same neurons and synapses after the initial experience could be useful because
the molecular processes, underlying strengthening and weakening of synaptic
connections between neurons, are quite protracted in time.10 Sleep could hold the
information for the time required for the slow molecular mechanisms by replay-
ing chunks or fragments of the information learned in the waking state.
However, even if convincing evidence is provided by future studies regarding
the similarity of neuronal ensembles in the waking and sleeping neocortex, these
observations alone cannot be considered as compelling evidence for the essential
role of sleep oscillations. Nevertheless, physics and computational modeling
might provide some clues why brain rhythms can be useful in this hypothetical
mechanism. Harmonic oscillators are excellent storage devices because the long-

Perturbation of the Default Patterns by Experience
209
11. Gerstner and Kistner (2002) provide numerous inspirations for future research on this topic.
Their simulations show how the initiating conditions can be recovered after many oscillatory cycles.
12. It is important to emphasize that “memory” is not a unitary term and has several forms that de-
pend on different brain mechanisms. Declarative memories include events of one’s past (episodic mem-
ory) and general (semantic) knowledge that can be “consciously” retrieved and declared. Declarative
memories are believed to depend on the hippocampal-entorhinal system. Other forms of memories 
term behavior of the oscillator can be reliably predicted/recalled by short-term ob-
servations. Let me draw support for this argument from the simplest case, a net-
work of randomly connected neurons in which oscillations can be turned on and
off. Once the oscillation is turned on, participation of neurons and their sequence
of activity depend only on the connectivity and the starting conditions. In a noise-
free system, the sequences of neuronal activity will repeat reliably and inﬁnitely.
Remember those annoying repetitions in your old gramophone record when the
needle kept slipping back to an outer groove? Unless the oscillation is perturbed
(the needle is moved manually into another groove), the pattern in an oscillating
network repeats itself inﬁnitely. This is an important observation because it im-
plies that the initial conditions can be reliably recreated from the repeating se-
quences of spike patterns even in the presence of occasional synaptic transmission
failures. Restarting the population activity with the same initial condition thus
leads to the very same sequence of spike patterns. A pertinent example is petit mal
epilepsy, characterized by a regular 3-hertz spike and wave discharge in the thala-
mocortical system, followed by an immediate recovery of neuronal activity. A sen-
tence interrupted by the onset of the spike and wave pattern that may last for
seconds or even long minutes, is often continued at the offset of the seizure (Her-
bert Jasper, personal communication). The possible explanation for this puzzling
phenomenon is that the initiating condition that gives rise to the rhythm is “frozen”
into the deterministic oscillation which can be regained at the offset.
The situation becomes a bit more complex if the ongoing oscillator is per-
turbed transiently. Now, the new sequence will reﬂect the combination of the ini-
tial conditions and the perturbation (see extended discussion in Cycle 12).11 With
some leap of faith, we can speculate that daily experiences that perturb the inter-
nal dynamics of the brain leave their marks. When the brain is left unperturbed
during sleep, the modiﬁcations in synaptic connections and channel distributions,
brought about by our daily waking routines, are “frozen” into the self-organized
oscillations of the various sleep stages. This is possible because sleep is a deter-
ministic process. Because various oscillatory patterns evolve through the various
stages of sleep, the dynamics of the neuronal replay are expected to vary over
time as well. To date, very little is known about the hypothetical scenario of
experience-induced neuronal patterns during sleep in the thalamocortical system.
The lack of hard physiological evidence for the experience-related content of
sleep did not prevent curious psychologists to test the real-life implications of the
two-stage model of memory consolidation. To date, Jan Born at the University of
Lübeck in Germany has provided the most compelling support for the critical role
of non-REM sleep in memory formation.12 Using both visual texture discrimination

210
RHYTHMS OF THE BRAIN
depend on other systems, e.g., the cerebellum, striatum, or amygdala, and cannot be retrieved “con-
sciously” and include procedural skills and habits (e.g., how to ride a bicycle or to pronounce words)
and emotions (Tulving, 1972, 2002; Squire, 1992; LeDoux, 1996; Eichenbaum, 2002).
13. Gais et al. (2000), Gais and Born (2004), Stickgold et al. (2001), and Mednick et al. (2002).
For a review of imaging studies on sleep and memory, see Maquet (2001).
task and paired word association task (e.g., bone/dog) in different experiments,
his team found substantial improvement in performance after sleep. Importantly,
they showed that improvement was due primarily to the ﬁrst 4 hours of night
sleep, rich in stage 3 and 4 events, and much less on late-night sleep, dominated
by superﬁcial stages and REM (ﬁgure 8.1). Similarly, Robert Stickgold and col-
leagues at Harvard Medical School found that the magnitude of memory en-
hancement after sleep was positively correlated with the amount of early-night
slow-wave sleep, although it as also correlated with late-night REM sleep. More-
over, behavioral performance also increased after a daytime nap, which is domi-
nated by slow-wave sleep.13
Perhaps the most spectacular result in this area of research is the demonstra-
tion of sleep facilitation of creative insight. Did you ever wake up with the right
answer to a problem that you could not solve the night before? To bring this folk
Early
sleep
†
*
Differences in threshold (ms)
Late
sleep
Early
wake
Late
wake
50
40
30
20
10
0
10
20
30
*
*
Figure 8.1. Slow-wave sleep facilitates memory. Subjects either slept for 3 hours during
the retention interval of a visual discrimination task or were kept awake throughout the
time interval. Only early-night sleep rich in slow-wave sleep improved performance. As-
terisks indicate signiﬁcant group differences. Dagger, signiﬁcant improvement relative to
chance performance. Reprinted, with permission, from Gais et al. (2000).

Perturbation of the Default Patterns by Experience
211
psychology belief into the lab, Born’s team asked their subjects to generate num-
ber sequences that included a hidden rule—the second sequence was identical to
the last in the series. Uncovering the hidden rule was possible only after several
trials. The subjects were given only two trials before going to bed, not knowing
about the hidden rule. A night’s sleep triggered insight of the rule the following
morning in most subjects, whereas the same amount of time spent in waking dur-
ing the day had little effect. These experiments provided the ﬁrst controlled labo-
ratory experiments for the widely known anecdotes of several famous scientists,
writers, and musicians that sleep catalyzes the creative process.14 The potential
physiological basis of such associations are discussed in Cycle 12.
Perturbation of Self-Organized Patterns 
by Waking Experience
While the experiments discussed above show that a learned skill or performance
of some memorized material improves after sleep, one might argue that it is sim-
ply the passage of time that causes the improvement. Although no such increase is
present after the same number of daytime hours, one may conjecture that the ex-
pected time-related improvement is canceled by the interfering effects of subse-
quent waking activity. To make the case for sleep stronger, one should demonstrate
some speciﬁc changes in sleep itself. We all know from experience that traumatic
daily events noticeably affect our sleep. But do “regular,” nontraumatic events
also leave their trace on the macroscopic appearance of the sleep cycle? At least a
handful of experiments suggest that this is indeed the case.
In an attempt to selectively stimulate a speciﬁc brain region, Alex Borbely and
colleagues at the University of Zurich exposed the dominant hand to a prolonged
vibration stimulus before sleep onset. After stimulation of the hand, the EEG
power in the contralateral hemisphere showed a signiﬁcant increase in the lower
frequency band (between 1 and 10 hertz). As expected, the largest increase was
observed at electrode sites overlying the sensory-motor cortex. An analogous re-
sult was obtained in the rat where unilateral whisker stimulation in the waking
state induced an interhemispheric shift of low frequency EEG power in non-REM
sleep toward the contralateral cortex (ﬁgure 8.2). A similar rationale was used in
a subsequent experiment by Giulio Tononi and his team at the University of Wis-
consin–Madison (ﬁgure 8.3). They asked their subjects to reach for visual targets
from a central starting point using a handheld cursor connected to a computer.
However, a trick was involved. An opaque shield prevented the subjects from
monitoring their hand and arm movements. Unbeknown to the subject, the cursor
position was rotated anticlockwise relative to the hand position by a ﬁxed angle
14. Wagner et al. (2004). See Prelude, footnote 2 in Prelude, for Otto Loewi’s dream about the va-
gus experiments; Strathern (2000) for Dmitri Mendeleev’s insight into the periodic system; and Ma-
quet and Ruby (2004) for sleep-induced insights reported by other famous people.

212
RHYTHMS OF THE BRAIN
15. Kattler et al. (1994), Vyazovskiy et al. (2000), and Huber et al. (2004).
while the subject executed the reaching task. Thus, this task was more than just re-
peating a well-trained movement. It required a complex eye–hand movement
adaptation, which has been shown earlier to activate the contralateral parietal cor-
tex. Immediately after the learning experience, scalp EEG was recorded by a 256-
channel high-resolution system. This technical wizardry was critical because, as it
turned out, the behaviorally induced changes occurred in a small cortical area.
During the ﬁrst cycle of sleep, the preceding practice induced a signiﬁcant in-
crease in the EEG power in a circumscribed part of the contralateral parietal cor-
tex, leaving the remaining regions of the brain unaffected by the experience.
Importantly, the investigators also showed that the local increase of low-
frequency power correlated with the magnitude of sleep-enhanced performance in
different subjects.15
Although these experiments indicate selective changes of EEG in spatially
localized brain regions, they do not speciﬁcally address the involvement of par-
ticular rhythms. In other experiments, a selective increase of the number and
power of sleep spindles was reported following spatial learning or intensive
verbal learning. Moreover, the spindle density in stage 2 of sleep positively
correlated with learning efﬁcacy. In a related series of experiments, no task
was given to the subjects, but differential distribution of sleep spindle density
above the frontal cortical region across subjects was related to their intelli-
gence quotient (IQ). A possible interpretation of the positive correlation be-
tween these measures is that the life-long experience that led to higher IQ was
reﬂected by the higher prevalence of speciﬁc sleep oscillations. The reduced
Figure 8.2. Waking experience modiﬁes subsequent neocortical activity during subse-
quent sleep. Whiskers of rats were trimmed on one side of the face 6 hours prior to testing
sleep patterns. EEG power density in slow-wave sleep increased in the hemisphere con-
tralateral to intact whiskers relative to the power of the ipsilateral (control) hemisphere.
NREMS, non-REM sleep. Reprinted, with permission, from Vyazovskiy et al. (2000).

Perturbation of the Default Patterns by Experience
213
number of sleep spindles in demented patients adds further support for the pos-
sible functional link between self-organized oscillations and waking brain per-
formance.16
Speciﬁc behavioral manipulations can produce selective changes in particular
brain areas. Raising kittens and mice for 3–4 months in complete darkness seri-
ously affects not only their visual abilities but also their sleep oscillations. Al-
though the total time spent in sleep did not differ between dark-reared and control
animals in these experiments, there was a selective decrease in delta power in the
dark-reared group. Importantly, the reduction in delta power was conﬁned largely
to the visual cortical areas, and no such change was observed above the so-
matosensory cortex, pointing to the selective effect of visual experience on delta
oscillation in the relevant cortical area. Interestingly, the effects were reversible
because delta power returned to control levels 2 months after exposing the dark-
reared animals to normal light. A more direct link between cortical plasticity and
sleep has been provided by Michael Stryker at the University of California–San
Figure 8.3. Learning produces speciﬁc and localized effects on sleep. Volunteers learned
to reach for visual targets using a handheld cursor while unconsciously adapting to sys-
tematic rotations imposed on the perceived cursor trajectory before going to sleep (left). In
a control session, subjects performed the same task without any imposed rotation. Right:
Topographic distribution of the percentage change in delta power during non-REM sleep
between the training and the control condition. White dots indicate the cluster of six elec-
trodes over the right parietal areas showing signiﬁcant increase of power. Modiﬁed, with
permission, from Huber et al. (2004).
16. Meyer-Koll et al. (1999), Gais et al. (2002), Mölle et al. (2002), Clemens et al. (2005), and
Bodizs et al. (2005). Physiological changes during sleep in dementia and other diseases may, of
course, be also explained by a common “third-party” mechanism that is independently responsible for
both the disease and altered sleep patterns. Nevertheless, the correlations are indicative of possible
links between sleep patterns and cognitive performance (Shinomiya et al., 1999).

214
RHYTHMS OF THE BRAIN
17. Frank et al. (2001).
18. Draganski et al. (2004). These ﬁndings suggest the possibility that new axon collaterals are
formed also in the adult. Imaging of white matter in professional piano players, however, indicates that
practice in childhood is most critical for the establishment of intermediate- and long-range connec-
tions (Bengtsson et al., 2005). This may also apply to other long-range connections supporting high-
level abilities.
Francisco. In normal cats, the amount of inputs from both eyes to the visual cor-
tex is roughly equal. Closing one eye during early development dramatically
shifts the balance of ocular dominance so that input from the covered eye is much
less effective in driving visual cortical neurons than from the control eye. The ef-
fect is so robust that the shift in ocular dominance can be reliably demonstrated
after only a few hours of eye closure. Stryker and colleagues closed one eye in
1-month-old kittens and let some of them actively explore in the light for 6 hours.
A subgroup of kittens was examined for ocular dominance right after the experi-
ence. The kittens in the critical experimental group were allowed to sleep in the
darkness for an additional 6 hours. Two more groups were involved to control for
darkness and extended waking for 12 hours. The enhancement of plasticity, as
measured by the magnitude of ocular dominance, was twice as large in the sleep
group and in the 12-hour light-exposed group, compared to the control kittens
with only 6 hours of monocular experience, even when followed by an additional
6 hours waking activity in the dark. In other words, the ocular asymmetry effect
continued to grow during sleep to the same extent as prolonged light and pattern
exposure. Importantly for our discussion, the magnitude of ocular dominance
shift robustly correlated with the amount of non-REM sleep but not with REM
episodes.17
Together, these experiments in laboratory animals and human subjects indicate
that sleep and its rhythms provide a clear, regional indicator of sensory experi-
ence. These long-lasting changes may be brought about by reorganization of
synaptic connections and strengths and/or by alterations of intrinsic conductances
in neurons. Support for such structural changes of connectivity is also provided
by MRI experiments. In the cerebral cortex of volunteers engaged in regular jug-
gling exercises daily for 3 months, a signiﬁcant enlargement of sensory-motor ar-
eas was observed, presumably due to more axonal connections. These ﬁndings
therefore support to idea that waking experience not only affects the macroscopic
aspects of sleep but also brings about structural changes.18 If short-term experi-
ence has a measurable effect on sleep patterns and oscillations, long-term practice
is expected to exert an even larger impact.
Long-Term Training of Brain Rhythms
Meditation-Induced Alpha Activity
Meditation is a widely practiced behavioral technique of tuning into your “inner
self ” but still remaining aware of the surroundings. The methods of meditation

Perturbation of the Default Patterns by Experience
215
19. For brain activity during Yoga meditation, see Wenger and Bagchi (1961), Anand et al. (1961),
or Shapiro (1980); in Zen, see Kasamatsu and Hirai (1966), Kugler (1982), or Murata et al. (2004).
The ﬁrst time I saw a presentation on the scalp EEG of yogis at the World Congress of EEG in Am-
sterdam in 1977, I thought the recordings were from patients with generalized spike-and-wave epilepsy
because of the large-amplitude, generalized pattern in some yogis. A recent study (Lutz et al., 2004)
emphasizes the enhanced gamma power during meditation, perhaps reﬂecting the increased neuronal
computation associated with the process of meditation.
20. Surwillo (1961) and Anokhin and Vogel (1996). For an informative review on the cognitive
role and correlations of alpha oscillation, see Klimesch (1999).
depend on the philosophies they serve. With some simpliﬁcation, Yoga empha-
sizes the “real” or superior reality within and devalues external reality, consistent
with the beliefs ofYogic philosophy, in which the world around us is held to be a
mere illusion, or Maya, in Sanskrit. Yoga meditation is typically practiced with
the eyes closed so that the mind can fully concentrate on inner events. The ulti-
mate goal of Yogic absorption into inner experience is to ignore stimuli from the
world of the senses. In contrast, Zen philosophy does not deny the reality of the
external world and seeks to build a harmony between the inner and outer worlds.
Zen is practiced with the eyes half open, focused softly on some blurred object. It
takes several years or decades to advance mind states from the beginner’s mind,
through kensho, culminating in satori. Brains of yogis and Zen practitioners,
therefore, provide unexploited opportunities to examine the effects of long-term
behavioral training on brain rhythms. Unfortunately, it is difﬁcult to obtain con-
sent of highly trained contemplative yogis and students of Zen to participate in
laboratory experiments. Not surprisingly, quantitative studies are rare. Neverthe-
less, the available evidence is telling. When absorbed in the Samadhi of Yoga
meditation, when the self-versus-environment distinction disappears, external
stimulation is largely ineffective in blocking alpha oscillations, whereas contin-
ued blocking without habituation is observed in Zen meditators. Both types of
practice increase both the power and the spatial extent of alpha oscillations, and
the magnitude of changes correlates with the extent of training. Beginners show
increases of alpha power activity over the occipital area, whereas in intermediate
meditators the extent of oscillating cortical area is increased and the frequency of
alpha oscillations is decreased. After decades of training, large-amplitude theta-
frequency rhythm may dominate over a large extent of the scalp.19 Yoga and Zen
training, therefore, reﬂects a competition between internal forces of synchrony
and external perturbation (ﬁgure 8.4).
Enhancement of Alpha Power by Sensory Feedback
Is spiritual experience a critical ingredient of the altered brain dynamics? Con-
versely, is alteration of oscillatory dynamics associated with behavioral perfor-
mance? Believers of the “alpha movement” believe so. The reasoning is this:
when our brains are dominated by alpha oscillations, we feel a sense of calm;
therefore, increasing alpha activity will calm our agitated brain. The repeatedly
observed correlation between various laboratory measures of spontaneous al-
pha oscillations and cognitive and memory performance20 is a further rationale

216
RHYTHMS OF THE BRAIN
Figure 8.4. Extensive practice can change brain patterns. The goal ofYoga (left) and Zen
(right) training is to fully engage the brain without sensory stimulation. Both training tech-
niques reﬂect a competition between internal forces of oscillatory synchrony and external
perturbation.
21. See, e.g., Hardt and Kamiya (1978), Chernigovskii et al. (1982), and Moore (2000). Enhance-
ment of alpha power to the stimuli is an illustration of network resonance at work. Resonance of thal-
amocortical network has been known for many decades. Electrical stimulation of the thalamus or its
inputs at about 10 hertz results in potentiation of the evoked responses, whose dynamics differ with
the site of stimulation. Repetitive stimulation of intralaminar thalamic nuclei induces the “recruiting”
response (Demsey and Morison, 1942; Morison and Demsey, 1942; Jasper and Drooglever-Fortuyn,
1947; Clare and Bishop, 1956; Ralston and Ajmone-Marsan, 1956), whereas simulation of sensory-
motor thalamic nuclei results in an “augmenting” response (Spencer and Brookhart, 1961; Morin and
Steriade, 1981; Steriade, 2001b).
for changing spontaneous brain activity. The method suggested to achieve such
goals is a hybrid of autogenic training and neurofeedback. The detected EEG
patterns from the scalp are transformed into audio tones so that the subjects can
recognize and monitor the occurrence of alpha waves online after minimum
training. Alternatively, alpha power can be integrated over several minutes by
an appropriate computer algorithm and fed back to the trainee. After several
days of practice, practitioners can more readily drive their brains toward the al-
pha state. Yet another way of increasing occipital alpha oscillation is by en-
training the waves by low-frequency light ﬂashes. Entrainment works as long as
the frequency of the second or third harmonic of the ﬂashes does not deviate by
more than 1–2 hertz from the “free-running” (i.e., spontaneous) alpha rhythm.21
After about a week’s training, signiﬁcant increases of alpha power are observed
even at more frontal sites, whose activity was not used for training. Occasion-
ally, slowing of alpha frequency is also reported. Whereas it takes several years

Perturbation of the Default Patterns by Experience
217
22. A good progress report on the subject is Allman (1992).
of Zen meditation to reach the stage of slowing the frequency of alpha and the
spreading of alpha oscillations forward to more frontal areas, approximately
the same results can be accomplished by a week’s training with alpha feed-
back.22
Does an accelerated enhancement of alpha oscillations mean that there is a
cheap way of getting relaxed and curing anxiety, for example? There is no simple
answer. Unfortunately, most studies with both alpha training and meditation have
been carried out on a small number of subjects, and placebo effects were seldom
considered. More troublesome is the fact that the “alpha relaxation” training be-
came commercialized before large-scale studies objectively examined its effects
on brain and behavior. The commercialized alpha biofeedback therapy promised
too much and delivered too little, and the alpha feedback “movement” went un-
derground by the late 1970s. There is also a conceptual misunderstanding be-
tween the goals of relaxation therapy and mediation. Meditation is not about
stress relief; it is an intense mental process with the goal of enhancing attention
skills and visual imagination. Some yogis can to hold complex images in their
minds for hours yet shift attention rapidly. A paradox is that enhanced alpha ac-
tivity is taken as evidence for the brain’s idling and relaxation in the brains of
Westerners and a physiological correlate of enhanced “internal attention” in the
brains of Buddhist monks. Obviously, this controversy is worth investigating. I
attempt to address the relaxation versus attention correlation of alpha rhythm in
Cycle 12.
Exploiting Brain Oscillations
Alpha or brain wave control has reemerged recently, this time for a different ap-
plication. If the power of brain activity can be controlled by the subject’s will,
such modiﬁable signals may be used to turn on a TV set or move a computer
mouse or wheelchair. Despite the poor spatial resolution of the scalp EEG, se-
lective control of different frequencies, such the mu rhythm and its harmonics,
can be exploited for differentially controlling horizontal and vertical move-
ments of a computer screen cursor or robot arm in a two-dimensional plane
(ﬁgure 8.5). In such a prototypical experiment, the subjects were asked to use
whatever imagined image they could to move a cursor from the center of the
screen to one of the eight possible targets at the periphery. The cursor was
moved by the output of an algorithm that measured the EEG power in the 12
and 24 hertz narrow bands derived from just two electrodes over the right and
left sensory-motor cortex. After a few weeks of practice, the best subjects hit
the targets with high accuracy within 2–5 seconds. Besides the potential med-
ical implications of such research for quadriplegic patients, the most striking
aspect of this experiment is the selective enhancement or reduction of arbitrary
brain oscillations by visual feedback. Recall that EEG is the mean ﬁeld of a

218
RHYTHMS OF THE BRAIN
large neuronal aggregate, so it was a large collection of neurons whose coordi-
nation was enhanced by the training.23
Reduced Sensory Input and Oscillations
If it was simply the absence of afferent inputs that invariably give rise to the os-
cillations in the respective primary sensory thalamocortical areas, one might ex-
pect that occipital alpha oscillations should be particularly prominent in blind
Figure 8.5. Robot control by oscillatory brain signals. The x- and y-coordinates of the
computer cursor were controlled by the ﬁrst and second harmonic component of the mu
rhythm recorded from the subject’s scalp. The subject’s task was to move the cursor to one
of the eight possible targets on the screen (the only feedback available). EEG traces of sin-
gle trials are shown below the computer screen. Right: Average amplitude of the signal
components associated with successful trials. The ability to differentially control the ﬁrst
and second harmonics of the ﬁeld signal provides evidence that multiple generators con-
tribute to the mu rhythm. Numbers indicate targets (as in the monitor). The 4 curves show
averaged power for trials in the 4 main directions of move. Modiﬁed, with permission,
from Wolpaw and McFarland (2004).
23. The cited experiments were done by Wolpaw and McFarland (2004). Several other “brain–
computer interfaces” have been used to control computers or simple robotic arms. To date, the most
fascinating and creative work on the subject remains Delgado (1969). Reviews by Donoghue (2002),
Nicolelis (2003), and Chapin (2004) summarize recent progress. Most current studies use surgically
implanted multiple electrodes, and coordinated activity of neuronal spikes are used for instrument
control, inviting serious challenges for chronic interfaces. If the goal is to control electronic devices or
robots, I do not quite understand the need for such complications. A tiny magnet implanted in the
tongue can generate a magnetic ﬁeld large enough to be detected by multiple coils placed on the cheek
or implanted in the maxilla. The virtually unlimited ﬂexibility of tongue movement in three-
dimensional space, detected by such a simple device, can do much more, much faster, and much more
accurately than we can hope for from the most sophisticated brain–computer interfaces for a long time
to come.

Perturbation of the Default Patterns by Experience
219
24. Birbaumer (1970) and Noebels et al. (1978).
25. Bach-y-Rita (1972) did perhaps the most original experiments in this ﬁeld by transducing op-
tical images of a camera to an array of skin vibrators. Optical images this way produced a two-
dimensional localized pattern of tactile sensations on the arm or thigh as a substitute of retinal
representation. Congenitally blind people began to experience depth of objects and their position in
three-dimensional space after a sufﬁcient amount of training.
26. For the superior auditory ability of the blind, see Roder et al. (1999) and Gougoux et al.
(2004). For tactile modality and verbal memory, see Sadato et al. (1996), Buchel (1998), and Amedi et
al. (2003).
27. It would be important to know, though, whether tactile or acoustic stimuli can modify occipital
EEG in the congenitally blind. If these functions indeed expand into the striate cortex, behavior de-
pendence of alpha oscillations could be a way to monitor such progress. Several studies indicate visual
to auditory cross-modal plasticity. E.g., spatial localization of auditory signals can activate occipital
association areas that in normal persons serve dorsal-stream visual processing. For a helpful review on
brain plasticity in animals and the congenitally blind, see Rauschecker (1995).
persons. This is not the case, and the underlying reason may be quite telling re-
garding the organization of the brain in the blind. In congenitally blind people,
occipital alpha power is substantially reduced, and at the same time, alpha oscil-
lations at more anterior normal brain sites may become more enhanced, suggest-
ing that site-speciﬁc development of thalamocortical rhythms is under the control
of appropriate sensory inputs.24 As discussed further below, thalamocortical pat-
terns may be critical not only for the ﬁne-tuning of local cortical circuits but also
for the establishment of long-range ﬁbers. Both clinical experience and labora-
tory studies indicate that blind people are superior to sighted people in tactile pro-
cessing and verbal memory.25 Furthermore, not only do they orient themselves by
sound and discriminate the changes of pitch more effectively than do healthy peo-
ple, but also they may show better than average musical talent. The younger a per-
son is when eyesight is lost, the greater these effects. “I was born with music
inside me,” remarks Ray Charles in his autobiography, who had lost his sight at an
early age. Stevie Wonder was born blind. How does early blindness explain their
exceptional musical talent?26 The tacit implication behind this question is that if a
nonallied cortical area, such as the visual cortex in the blind, is not engaged by its
physiological input, it may be utilized for processing another input, provided that
the long-range connections of visual areas are effectively connected to other sys-
tems. If the occipital cortex of the blind acquires newly specialized, nonvisual
characteristics, it is perhaps not surprising that eye movements in blind individu-
als do not have a big impact on occipital alpha EEG.27
But what if a blind adult person regains vision? The best-known recent case is
Mike May, a successful California businessman who lost his eyesight at the age of
3 and “regained” it after four decades, when a successful surgery provided him
with a pristine new lens of his right eye. Despite his newly acquired vision and
sensation at the level of the retina, he still travels with his dog and taps the side-
walk with a cane after 5 years of extensive visual training, although he is able to
detect color and light intensity differences and can combine his extensive previ-
ous experience with his newly acquired modality. For example, from seeing a
moving orange thing in the basketball court, he concludes it must be a spherical

220
RHYTHMS OF THE BRAIN
28. Fine et al. (2003). It is hard to adapt to a new sense:
A Man, being born blind, and having a Globe and a Cube, nigh of the same bignes, Committed into
his Hands, and being taught or Told, which is Called the Globe, and which the Cube, so as easily to
distinguish them by his Touch or Feeling: Then both being taken from Him, and Laid on a Table,
Let us suppose his Sight Restored to Him; Whether he Could, by his Sight, and before he touch
them, know which is the Globe and which the Cube? Or Whether he Could know by his Sight, be-
fore he stretchd out his Hand, whether he Could not Reach them, tho they were Removed 20 or 1000
feet from him?
Thus wrote William Molyneux, whose wife was blind, to the philosopher John Locke more than
300 years ago (for a fascinating treatment of this topic, see Sacks, 1995). Of the dozen or so adults
who learned to understand the world through their hands and ears and gained vision in adulthood, a
third voluntarily reverted to the world of the blind.
29. Such disconnection of the brain from the body occurs in REM sleep. However, the brain in
REM sleep has the cumulative effect of previous sensory and motor experience. Hallucinations also
frequently occur during sleep paralysis, a rare condition in which a person is not able to move skeletal
muscles voluntarily while awakening.
object. A brain that has been wired and trained to navigate the world through
sound, touch, and smell does not easily adopt a novel sense. In fMRI experi-
ments, presentation of faces and three-dimensional objects failed to activate his
inferotemporal cortex, suggesting that such complex constellations of visual pat-
terns have no meaning to a brain not trained to recognize such differences. On the
other hand, when objects in motion were shown, high level of activity was de-
tected in the motion-detection part of his brain.28 Motion-detection brain areas, of
course, could have been routinely activated in blind people because motion is not
unique to vision. To date, no EEG studies have been performed on sight-recovery
patients, so we do not know whether occipital alpha waves could eventually re-
sume the same function as in sighted people. Nevertheless, these and related stud-
ies make it clear that anatomical wiring in early life is a critical factor in
determining what kind of functions our brains can perform for the rest of our lives.
Brain in the Body: Emergence and Perturbation of the
First Cortical Rhythm
Imagine that the brain and the body would mature separately in a laboratory, and
only several years later we would connect them. This newly united brain–body
child would not be able to walk, talk, or even scratch her nose. Local stimulation
of her hand or foot would trigger generalized startle reactions, as is the case in
premature babies, rather than a spatially localized motor response that character-
izes a full-term baby. The reason is that the motor or sensory relations generated
by the brain grown in isolation would not match.29 In case of such mismatch, the
concepts of sensation and perception will acquire no meaning. I believe that the
outcome of this Frankensteinian Gedankenexperiment would not be much differ-
ent if the eyes, ears, nose, and all sensory inputs were left connected to the brain
but all effector systems were severed. The teleological argument here is that there

Perturbation of the Default Patterns by Experience
221
30. Katz and Shatz (1996), and Feldman et al. (1999).
31. Khazipov et al. (2004).
is no use in feeling or perceiving without being able to respond to the perceived
stimulus one way or another.
A unique problem of somatosensation is to relate the sensory information to
the real world. How do you know where your nose is without a reference coordi-
nate system? Without an explicit reference system, it is impossible for the brain to
construct reliable metric relationships among the various body parts. The brain,
even if all sensors are kept intact, cannot deduce whether sensory stimuli derive
from a sphere or snakelike body or any other geometry. We may suggest, then,
that the basis of all spatial metrics in the brain derives from muscular action.
Without the supervisor motor system, one cannot verify distance, depth, or any
spatial relationship. This calibration problem is especially magniﬁed during early
development when not only the absolute body size but also relative proportions of
different body parts change dramatically day by day.
How do sensory inputs affect the organization of neuronal representation of
the world outside the brain, such as the body and the environment? Carla Shatz at
Harvard University and Larry Katz at Duke University have demonstrated that
every part of the visual system, from the retina to the visual cortical areas, does
support spontaneous network patterns even if the animals are reared in complete
darkness, that is, without the relevant sensory input. They hypothesized that in the
presence of patterned visual inputs, the intrinsically generated connections can be
modiﬁed to represent coherent patterns. Their extensive research program is sum-
marized by the following dictum: neurons that ﬁre together in response to exter-
nal visual patterns will wire together to form functional assemblies.30 In the
thought experiment above, visual input without the ability to move can lead to
modiﬁcation of brain circuits, but I suspect that such altered connections have no
“meaning” to the brain’s owner. “Experience modiﬁes connectivity in the devel-
oping brain” is general wisdom. But what is experience? For the discussion be-
low, I deﬁne experience as accumulation of knowledge or skill that result from
direct action. Implicit in this deﬁnition is that no skill or conscious (explicit) ex-
perience emerges without the brain’s output. The brain can generate self-organized
activity and modify its wiring according to its activity. However, without the out-
put interacting with the body and environment, no amount of sensory stimulation
can generate a useful brain.
Inspired partly by Shatz and Katz’s pioneering experiments, Rustem
Khazipov, Anton Sirota, Xavier Leinekugel, and I decided to search for the ﬁrst
self-organized pattern in the neocortex during development and examine how it is
modiﬁed by the motor output generated by the spinal cord.31 It was already known
from the extensive work of our collaborator Yehezkel Ben-Ari at the Mediter-
ranean Institute of Neurobiology, Marseille, France, that neurons in the isolated
cortex of the newborn rat display “giant depolarizing potentials” due to sponta-
neous network excitation. Furthermore, previous work had already demonstrated
unique developmental changes during the ﬁrst week of life in rats, including the

222
RHYTHMS OF THE BRAIN
32. Ben-Ari (2005). Analogous spontaneous population patterns have been described in the neo-
cortex by Yuste et al. (1992) and Garaschuk et al. (2000).
33. These ideas have received further support from in vitro work (Dupont et al., 2006; R. Cossart
and Y. Ben-Ari, personal communication). Khazipov and colleagues have observed spindles in the vi-
sual area of the developing cortex, triggered by retinal waves (personal communication).
establishment of somatotopic cortical maps, dendritic development of superﬁcial
cortical neurons, the emergence of long-range corticocortical connections, and
enhanced experience-dependent plasticity.32 How these various processes cooper-
ate to establish the adult form of brain connectivity and behavior control, how-
ever, was not known.
Our ﬁrst observation was that, in contrast to the perpetual activity of the adult
neocortex, the neonatal pattern in the newborn rat pup was characterized by inter-
mittent network bursts of neuronal activity, separated by several seconds of silent
periods. The population bursts of neuronal activity were expressed in the form of
a sharp potential, often followed by waxing/waning spindle-shaped ﬁeld oscilla-
tions at about 10 hertz. Our intracellular recordings in anesthetized pups quickly
established that the activity was a result of coordinated release of excitatory and
inhibitory neurotransmitters by the already-existing local and thalamocortical in-
puts. Not knowing where such patterns were recorded from, most physiologists
would classify these cortical ﬁeld patterns as spontaneous sleep spindles or per-
haps mu oscillation. Thus, we could register that the ﬁrst organized pattern in the
intact neocortex is a rhythm. However, in contrast to sleep spindles of the adult,
the spindles in the pup were conﬁned to a very small cortical volume. Spindles
that emerged at a given spot have remained local or spread to neighboring sites at
a slow speed. The explanation for such conﬁnement of activity might be looked
for at the hardware differences between the maturing and adult brains. During the
ﬁrst days of rat life, the cortical connectivity is exclusively local. Layer 2 and 3
neurons have very simple dendrites, and their emerging axons have yet to travel
long distances. In contrast, the thalamocortical and layer 5 local wiring is already
in place. The neocortex at this stage is truly locally organized, like a mosaic or a
honeycomb with limited intermediate or global communication.33 Thus, our ob-
servations in the rat pup support our previously stated claim that, without long-
range cortical connections, global functional organization cannot emerge. But
why does the developing thalamocortical system need a rhythm?
Rats, like most rodents, are altricial; that is, they are born with eyes and ear
canals closed, rudimentary face whiskers, and poor sensory-motor coordination.
Developmental biologists tell us many parallels between the ﬁrst week of life in
the rat and the third trimester of pregnancy in humans. Indeed, the spindles we
observed in the pup are reminiscent of the brain patterns recorded from the scalp
of preterm human babies, although perinatal neurologists have not yet concluded
whether such patterns were signs of immaturity or part of normal development.
What could be the behavioral relevance of such well-organized intermittent
rhythms?
There does not seem to be much need for the body to move in the womb. Nev-

Perturbation of the Default Patterns by Experience
223
34. Until recently, the womb has been viewed as the romantic dwelling for the passively develop-
ing fetus, fully protected from the environment. In contrast to the subjective reports by mothers about
occasional kicks, ultrasound examinations and other studies have revealed frequent motor activity of
the fetus that includes twitches, random limb jerks, and rolling movements. Until the 1960s, these
movements were viewed as reﬂex responses to some undetermined stimuli. Only after Viktor Ham-
burger’s systematic experiments on chick embryos did it become clear that most of the early move-
ments are self-generated spontaneous patterns (Hamburger et al., 1966). However, Hamburger’s
program concentrated mostly on examining and explaining how sensation can modify motor organiza-
tion. For an early work on movement development, see Carlmichael (1934). For recent updates on the
subjects, see reviews by Hall and Oppenheim (1987) and Robinson and Kleven (2005).
ertheless, the fetus behaves; it cannot help it. Every expectant mother becomes
aware of “baby kicks” in the late stages of pregnancy. The vital importance of fe-
tal movements is illustrated by the correlation between movement density and
various postnatal ﬁtness indices, including Apgar scores, motor and speech devel-
opment, and even IQ, but the effect of these irregular, noncoordinated movements
on brain development has not been addressed.34 Analogous to human fetal move-
ments, newborn rat pups also display muscle twitches, limb jerks, and whole-
body startles, stochastic motor patterns generated by the spinal cord even in the
absence of the brain. It is quite entertaining to watch the “popcorn” movements of
a rat or mouse litter. After perfecting our recording system so that we could mon-
itor brain activity in the freely behaving pup, we began to study the behavioral
correlates of the earliest neocortical activity. To our astonishment, virtually all
cortical spindles were associated with isolated muscle twitches, limb jerks, startle
reactions, crawling, or sucking, that is, some movement. Isolated movements,
such as forelimb or hindlimb jerks, triggered localized spindles in separate parts
of the somatosensory cortex (ﬁgure 8.6).
Mechanical stimulation of the skin of the forelimb and hindlimb evoked the
same isolated cortical responses. Our systematic comparison between the muscle
activity-triggered cortical “maps” and the skin stimulation-evoked responses re-
vealed a perfect match. Of course, neuronal activity evoked by sensory stimula-
tion in the somatosensory cortex was not surprising and was expected from the
genetically controlled primary wiring of the cortex. What was surprising was
the long-lasting nature of the response in the form of spindle activity, outlasting
the input by several hundred milliseconds. Let me remind the reader here that
sleep spindles and the mu rhythm in the adult occur spontaneously in the absence
of movement. To examine whether spindles in the newborn require an external
drive or can also emerge spontaneously, we severed the lower part of the spinal
cord under anesthesia and thereby prevented all sensory feedback from the
hindlimbs. Despite this deafferentation procedure, spindles continued to emerge
in the hindlimb area of the cortex, although at a low incidence. This latter obser-
vation provided a deﬁnite evidence for the self-generative nature of the spindle.
However, in the intact developing brain, the high incidence of movement-initiated
sensory feedback consistently precedes the brain-timed occurrence of spindles
and acts as perturbations on the centrally generated mechanism. Again, this is in
line with the laws of oscillations discussed in Cycle 5: irregular perturbations can

224
RHYTHMS OF THE BRAIN
Figure 8.6. The ﬁrst organized neocortical pattern is an oscillation. Upper traces:
Movement-triggered spindle bursts (ﬁeld and units) in a 2-day-old rat pup. Between the
spindle events, no spiking activity is present. Bottom traces: Spontaneous movements of
the forelimb or hindlimb trigger topographically conﬁned spindles in the somatosensory
cortex. Modiﬁed, with permission, from Khazipov et al. (2004).
trigger a premature duty cycle, provided that some sufﬁcient time has elapsed
since the preceding cycle, and reset the oscillator so that it can start charging up
again. In the absence of such externally triggered synchrony, the brain provides
synchrony by inducing oscillations. But what is so special about movement-
triggered baby spindles?
Muscles and their tendons have sensors, which report the contractile state of
the muscle to the spinal cord and eventually to the somatosensory cortex. In addi-
tion, a jerk of the extremities and muscle twitches of the tongue and face increase
the chance that the skin over the muscle will touch another pup in the litter or nest
material. The uncoordinated, spinal-cord–initiated muscle activity consistently
activates local skin afferents with a probability proportional to the frequency of
twitches in the individual muscles. Given the several hundred skeletal muscles
that move the mammalian body, the number of movement combinations, in prin-
ciple, may appear very high. In reality, only a limited fraction of this large com-
binatorial space is ever realized in motor coordination, due to the physical
constraints of the bones and joints. These restrictions by the rigid body architec-
ture and tissue elasticity reduce the extraordinarily large number of degrees of
freedom that would result from the unrestrained temporal combination of sensory

Perturbation of the Default Patterns by Experience
225
35. There are various ways of changing effective connectivity, including changing synaptic
weights, generation and elimination of synapses, and altering ion channels. For a recent review on this
topic in the developing brain, I suggest Chklovskii et al. (2004).
36. I refer here to the intracortical substrate of the hypothesized reafferenz prinzip or corollary dis-
charge (von Holst and Mittelstaedt, 1950; Sperry, 1950).
37. Although not emphasized by the authors, spindlelike oscillatory patterns are also present in the
visual cortex of the developing ferrets, and they can be triggered by visual stimuli (Chiu and Weliky,
2001).
inputs. Importantly, all these real-world movement combinations are meaningful
inputs to the somatosensory thalamus and cortex because they will be used later
in life. Using the three-dimensional physical layout of the skeletal muscles as a
reference, the coordination of movement–afferent feedback–cortical spindle se-
quences serves to convert the initially abstract body representation in the sensory
cortex to a concrete metric space. In essence, the somatosensory representation
gets anchored to the real-world metric relationships of the skeletal muscles. This
cannot be achieved by a general, “one-size-ﬁts-all” blueprint since the metric re-
lations should be customized for each body and updated as the body shape
changes. In this training process, the distances between body parts are translated
into a spatial-temporal organization in the somatosensory system by creating new
connections and eliminating old ones by strengthening and weakening existing
synaptic connections.35
It is important to recognize that a crude topographic map-like representation
of the body surface in the somatosensory cortex does not automatically mean a
functional representation. It is the synaptic connections among the neurons that
provide a physiologically relevant representation. Movement-induced temporal
coactivation of sensory inputs may provide the temporal tuning for synaptic con-
nections. Because of poor axon myelination in the newborn pup, action potentials
travel slowly between neurons within the brain and between the brain and spinal
cord. As a result, short-lived local activity may not be sufﬁcient to compensate for
the time delays between various afferent volleys. Because spindles can sustain ac-
tivity for several hundred milliseconds in somatosensory thalamocortical mod-
ules, they can serve as a temporal bridge necessary for strengthening the
connections between neurons, representing different body parts. Such bridging of
temporal gaps is especially critical while the motor patterns become under corti-
cal control with the establishment of corticospinal connections and long-range
corticocortical connections. These latter pathways are essential for building inter-
nal forward models that provide predictions about the sensory consequences of
action.36 Emergence of sensory-motor coordination is therefore a selection pro-
cess, supervised by random muscle contractions, a competition and cooperation
between movement-generated reafferentation and the self-organized dynamics of
the thalamocortical system.
An important prediction of these observations is that in the absence of motor
activity, somatosensory information cannot incorporate the spatial relationship
among various stimuli. This likely applies to spatial relations and localization of
visual and sound modalities, as well.37 Only through movement can distances be

226
RHYTHMS OF THE BRAIN
38. Wall (1987). The lemniscus medialis is a ﬁber tract originating from the gracile and cuneate
nuclei and decussating in the lower medulla before terminating in the ventral posterior nucleus of the
thalamus. It conveys somatic-sensory information involved in tactile discrimination, position sense,
and vibration sense in a somatotopic manner.
39. Nicolelis et al. (1996), Westerga and Gramsbergen (1993), and Allman (1999). The research
program of Potter et al. (2006) tests these ideas by connecting output patterns of neuron cultures to ro-
bots and using the outputs of the robots’ sensors to modify neuronal connections.
measured and incorporated into our sensory scheme. For an immobile observer,
direction, distance, and location of sensory information are incomprehensible and
meaningless concepts. The real test of this hypothesis would require paralyzing
the skeletal muscle system during the early maturational stage of the brain, before
the appearance of sensory-evoked spindles. Although no such experiment has
been performed, the available data are in support of such a scenario. Cutting the
facial nerve selectively abolishes whisker movements without directly affecting
sensory innervation of the facial vibrissae, the tactile organs used by rats to dis-
criminate object shape and texture. If selective paralysis of whisker muscles by
severing the facial nerve is carried out during the second week of life, whisker
representation in the thalamus is severely reduced and disorganized, even though
whiskers can still be actively used by the head and body turns. Touching the whis-
kers will still evoke responses in thalamic neurons, but their directional organiza-
tion is missing in these animals, supporting the idea that movement-induced
sensation is the basis of representation in the physical world. A related experi-
ment examined the consequences of early limb immobilization on subsequent de-
velopment of walking. In the rat, the adult pattern around locomotion emerges
about the 15th postnatal day. Immobilization of one hindlimb in an extended po-
sition by a cast around the leg for the ﬁrst 3 weeks of life resulted in long-lasting
abnormalities in the timing of the electromyographic activation patterns of the
immobilized muscles, although the rats eventually acquired adult walking pat-
terns. This procedure, of course, did not prevent muscles from twitching and as-
sociated sensory reafferentation from the hindlimbs even in the presence of the
cast. The importance of action on perception is also obvious in the adult. When all
spinal tracts are cut except for the lemniscal system, which carries the topograph-
ical representation of the body surface from the spinal cord to the thalamus, one
may expect that sensation below the cut should remain intact because the major
sensory conduit from the body to brain is still intact. Nevertheless, experimental
rats tend to ignore stimulation below the cut.38
Ultrasonic images of human fetuses often document them sucking on their
thumb. According to our observations in the rat pup, such motor patterns trigger
temporally coordinated spindles in the mouth and tongue representation of the
cortex. John Allman at the California Institute of Technology, Pasadena specu-
lates that if the fetus consistently sucked on the thumb of one hand as opposed to
the other, the increased stimulation might favor the development of its cortical
representation, which in turn might lead to hand preference and asymmetry of ce-
rebral representation.39

Perturbation of the Default Patterns by Experience
227
40. The zebra ﬁnch work is cited from Goldstein et al. (2003). Ontogeny of phonetic gestures is
discussed in Vihmam (1991) and Kelso (1995). Sporns and Edelman (1993) suggest that movement
coordination is also an issue of selection from large battery of primary movement repertoire.
41. The “situatedness” or “embeddedness” of the brain in the body and environment is discussed
in detail in Varela et al. (1991). Several other excellent works have dealt with the “reciprocal causal-
ity” issues of the brain–body–environment continuum (Changeux, 1985; Chiel and Beer, 1997;
Panksepp, 1998; Damasio, 1999; O’Regan and Noe, 2001; Thompson and Varela, 2001). For compu-
tational aspects of similar issues, see also Salinas and Abbott (1995).
42. Young kids and teenagers often have difﬁculty sitting quietly and feel a strong urge to move their
legs. In 2–3% of the population, that feeling may be impossible to resist, and this minority is diagnosed
with periodic limb movement disorder (PLMD) or restless legs syndrome (RLS), distinct but related dis-
orders (Wetter and Pollmacher, 1997; Glasauer, 2001; Odin et al., 2002; Hening, 2004). Although other
extremities may also be affected, movement of the legs is more typical and occurs mainly during rest or
light sleep, causing insomnia. Muscle jerks typically occur for 0.5–10 seconds, at intervals separated by
The primacy of movement-induced sensory feedback may also underlie more
complex processes such as development of social communication and speech.
Songbirds, such as the extensively studied zebra ﬁnches, learn their songs from
their fathers. This process is more serendipitous, though, than a well-thought-out
learning algorithm. The young birds do not start with the ﬁrst syllables of the fa-
ther’s song and acquire the rest piece by piece. Instead, each bird “babbles” some
sounds, and it is these self-generated “syllables” from which the birds expand to
learn a species-speciﬁc adult song. Each bird starts out with a unique seed sylla-
ble. Analogously, babbling in human babies also reﬂects a self-organized intrinsic
dynamics. When the uttered sounds resemble a particular word in a given lan-
guage, parents exploit the internal dynamics of the brain by reinforcing the spon-
taneous utterances. As I have stressed all along, perturbation of the default
self-organized patterns of the brain is a more effective mechanism of pattern for-
mation than the de novo, tabula rasa approach because the former can exploit the
existing dynamics of the maturing brain networks.40 The brain, body, and the en-
vironment are highly intertwined systems at multiple levels, and the “upward cau-
sation” of somatic, humoral, autonomic, and environmental processes and their
dynamical interactions is as important as the “downward” causation of the brain
on their effectors (recall ﬁgure 2.1).41
Following axon myelination, the connection speed between assemblies and re-
gions becomes faster and spindle-mediated prolongation of sensory feedback activ-
ity is no longer needed. Parallel with the establishment of sensory-motor
coordination, the thalamocortical circuit becomes under the control of subcortical
modulatory systems, which prevents the occurrence of spindles in the adult waking
brain. Early development is thus a “wakening” process of the forebrain from its
dominantly sleeplike state. Nevertheless, spindles continue to emerge during early
stages of sleep throughout life. As discussed in Cycle 7, sleep is generally viewed as
the brain’s separation from the environment and, to a large extent, from the body.
Nevertheless, at least a portion of spindles are triggered by movement-initiated
afferent activity, similar to the developing brain. Occasionally, we all experience
spontaneous muscle twitches or even large startle motor patterns that seize our
whole body at the transition to sleep.42 Such movement-initiated afferent excitation

228
RHYTHMS OF THE BRAIN
5 to 30–90 seconds. These disorders may reﬂect a developmental problem of the brain and spinal cord,
a persistence or reemergence of the physiological fetal movement patterns. Notably, periodic limb
movements often trigger K-complexes (Mello et al., 1997).
43. See Leopold and Logothetis (1996, 1999) and Sheliga et al. (1994). The critical role of eye
movements in visual perception is also emphasized by Mriganka Sur and colleagues (Sharma et al.,
2003). The observation that “neglect,” a difﬁculty in acknowledging the affected part of the visual
ﬁeld even if it represents part of one’s own body (Kinsbourne, 1987), arises from damage to parietal
cortical areas serving motor activity further underlies the primacy of motor activity in sensation (Riz-
zolatti et al., 1983). For philosophical implications of the effect of movement on perception, see
O’Regan and Noe (2001).
44. Although Held and Hein (1963) emphasized the role of active exploration, they attributed the
observed effects to extensive visual experience, rather than to the primacy of motion in providing the
necessary real-world metric for depth perception.
can trigger K-complexes followed by sleep spindles. One can only speculate that the
function of sleep spindles in the adult is therefore not fundamentally different from
that of the early cortical spindles. The shape and size of the body change not only
during early development but also throughout the life span. If sleep spindles or mu
oscillations are indeed analogous to the baby spindles, these rhythms engaging the
somatosensory system may assist in the preservation of body representation.
The action strategy used by the developing brain is retained in adulthood, as
demonstrated by the extensive work of Nikos Logothetis and colleagues at the
Max Planck Institute in Tübingen, Germany. These investigators study the neu-
ronal mechanisms involved in binocular rivalry, when the visual system is con-
fronted by an ambiguous ﬁgure (ﬁgure 8.7). Their consistent ﬁnding is that the
activity of neurons in visual cortical areas alone cannot determine the perceptual
changes underlying the brain’s verdict. A critical element in this process, they be-
lieve, is the object’s continual surveillance by eye movements. Seeing is an active
exploration of the environment.43
The primacy of movement in the visual domain is also well illustrated by the
classic experiments in kitten pairs performed by Richard Held and Alan Hein at
Brandeis University in Waltham, Massachusetts. One of the pair was wearing a
harness and could move around freely in a circular track, while the experimental
kitten was strapped in a suspended gondola, which was pulled by the free cat.
Outside the experiments, the kittens were kept in darkness. After several weeks of
training, the cats were tested for sensory-motor coordination. As expected, the
free cat behaved just like any other ordinary cat. Its yoked partner, on the other
hand, did not stretch out its paws when lowered to the ground, often bumped into
objects, and could not coordinate its movements properly with visual objects be-
cause motor behavior was not in register with visual input. Held and Hein con-
cluded that perception is learned through the action of the motor system.44
Perception is not simply a feedforward process of sensory inputs but rather is an
interaction between exploratory/motor-output–dependent activity and the sensory
stream. It is something we do. To conclude this Cycle, I paraphrase Theodosius
Dobzhansky (Cycle 3 epigraph) by stating that nothing in the brain makes sense
except in the light of behavior.

Perturbation of the Default Patterns by Experience
229
Figure 8.7. Metastability of ambiguous ﬁgures. Ambiguous ﬁgures, such as the Necker
cube, are perceived as one of several possible stable conﬁgurations (e.g., the box here is
either seen from the top or the bottom). These perceptual shifts are initiated by eye move-
ments.
Brieﬂy . . .
Sleep is the default state of the brain—default in the sense that it develops as a
self-organized or spontaneous state without an external supervisor. Sleep shares
numerous features with autonomous early brain development. Both are not ho-
mogeneous states but evolutions of “stages” in which oscillations temporarily
stabilize brain dynamics. The neurons’ spiking content of these stages should be
predictable from the initiating conditions owing to the deterministic nature of os-
cillations. Perturbation of the spiking patterns by events that occur during a wak-
ing experience may change the initiating conditions and, therefore, the content
of spiking patterns during sleep and early development. It has been conjectured
for more than a century that sleep may serve to cement or consolidate memories
by replaying parts and details of the waking experience. Initially, this service of
sleep was contributed exclusively to REM sleep and its dream content. Recent
experiments stress the primary importance of slow-wave sleep and other “off-
line” states in the consolidation process because their population dynamics share
several similarities with conditions that favor synaptic plasticity. Human studies
consistently show that sleep leads to a gain in memory and skill performance
when compared to the same amount of waking time passed. Extensive or life-
long stereotypic experience, such as meditation, athletic, and other skills can
lead to quantitatively measurable alternation of oscillatory patterns in the rele-
vant cortical representations.
Without supervised training, the brain does not develop a sense of real-world
relationships. There is no a priori reason why representation of the environment

230
RHYTHMS OF THE BRAIN
in the brain should be three-dimensional and linear, instead of n-dimensional
and logarithmic or exponential. The brain’s sensory representations acquire real-
world metrics early in development. A key mechanism in this supervised train-
ing is the muscle-activity–generated sensations, which begin during late
intrauterine life. It is the three-dimensional layout of the skeletal muscle system
that provides the real-world metric to the sensorium by triggering oscillations in
the thalamocortical system at critical times of brain development that coincide
with the emergence of long-range corticocortical and corticospinal connections.
Without the supervision of the muscular system, the brain has no sense about the
shape of the body. Similarly, brain-controlled action is likely necessary for other
perceptual skills, such as vision and spatial orientation.
Until recently, exploring the complex mechanisms of rhythms in the resting-
sleeping brain was not a high priority because it was not clear whether they serve
some important functions or are merely epiphenomena. The reasons outlined in
this Cycle, however, justify the need for extensive explorations. The signiﬁcance
of these oscillations does not really begin to become apparent until their content
is uncovered and related to waking behavior. This endeavor will require large-
scale recording of neuronal spikes in behaving animals.

Cycle 99
The Gamma Buzz: Gluing by Oscillations
in the Waking Brain
Systems neuroscience was at its deep point in the 1980s, and several factors con-
tributed to its depression. Among the reasons were the radical innovations in
single-cell-level biophysics with the introduction of the in vitro slice preparation
and the rapid spread of molecular biological methods, followed by the invention
of functional imaging of the intact human brain in the early 1990s. While these
novel innovative methods provided new windows into the brain, systems neuro-
physiology stagnated with its classic theories and methods of single-cell record-
ing. Systems neuroscience transiently lost its ground and many of its followers.
This situation was instantaneously and radically changed by a historical event, the
symposium on visual perception at the Society for Neuroscience meeting in
Washington, DC, in the fall of 1993. I have never seen so many neuroscientists at-
tending any lecture on any topic of neuroscience than at that milestone event. The
giant auditorium was unbelievably packed, and many could not get in. Obviously,
the interested audience came from all walks of life and represented neuroscien-
tists from the molecular to cognitive levels, with only a small fraction of the at-
tendants working directly on the problem of vision perception. The unprecedented
attendance was an overt declaration that complex structure–function issues of the
brain fascinate all neuroscientists.
After a long vacuum in systems research, a radically different and comprehen-
sive theory was on the horizon. The protagonist of the symposium was Wolf Singer
from the Max-Planck Institute in Frankfurt-am-Main, Germany. The respondents
This . . . obliged us to abandon, on the plane of atomic magnitudes, a causal
description of nature in the ordinary space-time system, and in its place to set
up invisible ﬁelds of probability in multidimensional spaces.
—Carl Jung, On the Nature of the Psyche
231

232
RHYTHMS OF THE BRAIN
1. The journal Neuron has dedicated an issue to the binding problem, with excellent reviews pre-
senting both the advantages and shortcomings of the theory (Roskies, 1999). See also Phillips and
Singer (1997).
2. Of course, binding is not a problem for the brain. The problem is to understand the mechanisms
by which the brain achieves it. For discussions of the “binding problem” and feature extraction, see
Zeki and Shipp (1988), Damasio (1989), Singer (2001), Varela et al. (2001), Engel et al. (2001), Engel
and Singer (2001), and Mesulam (1998). The speed of visual processing in humans has been measured
by Thorpe et al. (1996) in a simple go/no-go categorization task (whether the picture contains an animal
or not). However, no ﬁrst-time viewer can extract a Dalmatian dog from a background of black and
white patches or ﬁnd Carmen San Diego in the busy scene of Fishermen’s Wharf in such a short time.
were equally experienced and equally wise experts. The essence of Singer’s mes-
sage was this: representation of the various attributes of the visual world by distrib-
uted neuronal assemblies can be bound together harmoniously in the time domain
through oscillatory synchrony. The “binding by synchrony” proposal, the shorthand
term of the theory, was a paradigm shift in the structure–function relationship of the
nervous system because, according to the theory, it is no longer the connectivity per
se but the coherent temporal organization of activity through oscillatory synchrony
that matters. Although many objections and alternative mechanisms have been
raised at that meeting and afterward, the temporal binding hypothesis of object per-
ception has remained the most debated framework to date.1 What really clashed at
that symposium and what makes the continued dispute all the more interesting is the
relationship between space and time management in the brain.
Binding by Bottom-Up Connectivity
What is the ﬁgure and what is the background in a Vasarely painting? Is the spot-
ted salamander part of the leafy ground or separate? How does the visual system
make a distinct decision in each case? According to Béla Julesz, what makes an
object an object and a ﬁgure a ﬁgure is the temporal and/or spatial coherence of
the parts. The camouﬂage effect of the salamander’s skin is effective only as long
as it remains motionless. Movement of parts or the whole of its body makes it
clearly detached from the background of otherwise statistically identical features.
Features that move together tend to belong together: they have a common fate, as
Gestalt psychology has stated long decades ago. However, not all attributes of an
object are always present all the time, and recognition of an object depends on
successful completion of the pattern on the basis of past experience. Dogs have
characteristic size, shape, color, odor, fur texture, and walking and barking pat-
terns that distinguish them from other animals. Proper combination of these fea-
tures should be bound together into a single image in the brain to recognize a dog
or an individual dog even if the size, viewing position, and lighting conditions
change. Because these features are processed in separate parts of the cortex by
different sets of neurons, one should explain how they are bound into a complex
representation in a matter of 200 milliseconds or so. This is called the binding
problem.2 A related problem is to avoid “superimposition” of coexisting patterns,

The Gamma Buzz
233
3. The sensory input–decision–response model is not unique to the visual system and has been the
dominant framework in all systems. It is a direct descendant of the sensory input–response models of
psychology (often referred to as the Hull-Spence theory; Pavlov, 1927; Hull, 1952; Spence, 1956), and
its origin can be traced back to the British empiricists.
4. Retinotopy is the maplike correspondence between receptor cells in the retina and the surface of
the visual cortex of the brain. The map is highly nonlinear in a sense that the fovea is disproportion-
ately represented in V1 but the representations of foveal and extrafoveal areas tend to equalize in
higher order visual areas.
5. Felleman and Van Essen (1991). The dorsal and ventral streams of visual structures have been sug-
gested to segregate spatial localization (“where”) and recognition (“what”) of objects (Ungerleider and
Mishkin, 1982). Goodale and Milner (1992) argue that “vision-for-action” and “vision-for-perception” 
such as the motionless spotty salamander and the leafy background, and separate
them into distinct entities. The problem of binding and superimposition invokes
the already familiar problem of the delicate relationship between integration and
segregation and the logical constructs of similar and different. The neurophysio-
logical essence of the problem is how neurons activated by the shape, color, mo-
tion, and other attributes of the salamander and the leafy background give rise to
one or two representations.
The ﬁrst neurophysiological explanation to the binding problem was provided
by David Hubel and Torsten Wiesel then at Harvard Medical School, Boston. In
their recordings in anesthetized cats and monkeys, they found that most neurons
in the primary visual cortex (V1) discharge only in a restricted part of the visual
ﬁeld with a phase-dependent fashion to a moving bar. They called these cells
“simple” cells. Another class of neurons, called “complex cells,” had bigger re-
ceptive ﬁelds and showed no phase dependence. They suggested that multiple
simple cells converge onto complex cells, and the integration of smaller receptive
ﬁelds by the complex cells makes the latter cell type respond to stimuli in a larger
area of the visual ﬁeld. Some neurons in visual areas downstream to V1 re-
sponded to higher order features of the stimulus (e.g., edges), which are called
“hypercomplex” cells. The straightforward and admittedly simpliﬁed conclusion
of these observations was that the visual system is a feedforward, hierarchical
processing system representing at each step more and more complex features of
the input, in line with the prevalent “input–decision–output” serial processing the-
ories of brain function.3
Numerous ﬁndings from various disciplines of neuroscience provide support
to this feedforward model. The visual cortex in primates is organized into a col-
lection of anatomically distinct areas with a gradual decrease of the foveal dom-
inance of retinotopic speciﬁcity.4 At each stage of visual processing, neurons
respond to somewhat distinct attributes of the visual input, indicating physio-
logical specialization of subsequent stages. Neurons in subsequent stages com-
bine features of inputs from earlier stages, losing ﬁrst-order features and
gaining more complex, higher order features. Importantly, separate streams of
structures in the primate parietal and inferotemporal cortical areas appear to
funnel fundamentally different aspects of visuals scenes.5 The ever-increasing
combinatorial complexity, a result from the ascending hierarchy of neuronal

234
RHYTHMS OF THE BRAIN
distinction is more appropriate. E.g., the middle temporal visual area (MT) and V4 belong to the ven-
tral and dorsal streams, respectively, and show selectivity for direction of motion (MT) and selectivity
for color (V4) (Van Essen and Zeki, 1978; see also Felleman and Van Essen, 1987). Nevertheless, the
dorsal and ventral streams have many anatomical links, and there is considerable intermixing of the
signals and representations (Ghose and Maunsell, 1999). Importantly, it is not clear how perception
can exist without action.
6. Face, hand, and banana-speciﬁc neurons were described by Gross et al. (1969; see also Desi-
mone et al., 1984; reviewed in Gross, 1992; 2002). Unfortunately, in vivo neocortical physiology
rarely identiﬁes the recorded neurons. Therefore, the anatomical identity of higher order, gnostic neu-
rons (see note 7) to date has remained unknown.
7. Konorski (1967) is an excellent summary of instrumental conditioning from a unique Eastern
European perspective. Konorski was a student of Ivan Petrovich Pavlov but was strongly inﬂuenced by
American behaviorism. His “gnostic neurons” were essentially decision makers between the input and
action.
8. Barlow referred to such highly complex cells as “cardinal” cells (Barlow, 1972), implying that
various aspects of an object (e.g., your grandmother) and constellations of the lower level features
converge to represent increasing orders of features in a feedforward hierarchy. It is not clear, though,
how Barlow estimated the necessary number of neuron for perception. Abbott et al. (1996) estimate
that 25 temporal lobe neurons can identify as many as 3,000 faces as familiar or unfamiliar. Similarly,
Shadlen et al. (1996) suggest that approximately 100 neurons are sufﬁcient to signal the direction of
moving clouds of dots. These estimations assume that neurons “code” as independent units, an as-
sumption that may not be granted in interconnected networks.
9. The statistical argument in favor of the single-cell doctrine is this: large numbers of sequential
responses of a single neuron converge to a histogram of the same shape as does the response of a large
ensemble of identical cells to a single stimulus, as predicted by the central limit theorem. This state-
ment, however, is true only if the brain state remains stationary during the entire time between stimu-
lus presentations and if the previous signals do not affect subsequent ones. However, such stationarity
conditions are hardly ever satisﬁed in the brain (Martin, 1994).
computation, culminates in unique neuronal patterns of the inferotemporal cor-
tex. Several neurons in this region were found to ﬁre selectively to hands, faces,
and other discerning features. The key property of these cells is their context,
scale, and translational invariance, that is, the persistent selective ﬁring in re-
sponse to the same object even when the background, size, or position of the
object varies in the visual ﬁeld. They explicitly represent the common features
of the object.6
Neurons with complex synthetic properties have been long hypothesized to ex-
its. The Polish behavioral scientist Jerzy Konorski was the ﬁrst to suggest that per-
formance depends on highly specialized “gnostic units.”7 Subsequently, the
British neurophysiologist Horace Barlow estimated that a small population, per-
haps a few hundred to a thousand, gnostic or “cardinal” neurons was needed to
give rise to a percept.8 These considerations also provided a long-standing strat-
egy for neurophysiological research, Barlow’s “single-cell doctrine,” which
claims that by recording neurons one by one in subsequent stages of processing,
one can infer all computations of the brain about an object as long as physical fea-
tures of the object remain unchanged during the recording.9 According to this sig-
nal processor model, lower level features of an object are represented in early
stages of a feedforward system, and the features become progressively more com-
plex as lower level information is combined. Barlow writes:

The Gamma Buzz
235
10. Barlow (1972, p. 372).
11. Experiments with paperclips were done by Logothetis and Pauls (1995; see also Logothetis,
1998). For a summary of the ﬁring patterns of inferotemporal neurons, see Tanaka (1996). In the neu-
ronal network literature, high-order representation of information is referred to as “sparse” coding (an
idea equivalent to “gnostic” or cardinal cells but without subjective connotations). Perhaps the great-
est appeal of sparse coding is its energy efﬁciency (Levy and Baxter, 1996; Laughlin and Sejnowski,
2004). Highly sparse coding has been characterized in several systems, including the hippocampus
(O’Keefe and Dostrovsky, 1971), the Kenyon cells of the olfactory system in insects (Laurent, 2002),
and in the song-generating system of zebra ﬁnches (Hahnloser et al., 2002).
12. An informative review on the match between unit ﬁring patterns and behavioral performance is
Parker and Newsome (1998). For an early overview, see Perrett et al. (1984). Note, though, that a
match between performance and unit ﬁring does not mean that the recorded units are responsible or
critical for the behavior. Stimuli can evoke similar patterns under anesthesia or sleep in the absence of
a behavioral output. Just because behavior or stimulus occurrence can be deduced from the spike pat-
terns by the experimenter does not mean that the same format is used by the downstream neurons for
“reconstructing” the stimulus or executing an output pattern.
13. Axon terminals from the thalamic lateral geniculate account for no more than 5 percent of the
total synapses in V1. Consequently, 95 percent of the excitatory synapses, even in V1, are supplied by
local neurons and neurons of other cortical areas and other thalamic nuclei. Similarly, the feedforward
projection from V1 to MT provides fewer than 5 percent of the excitatory synapses from V1. In fact, a
large portion of inputs come from nonvisual areas. Local computation will hence be markedly affected
Our perceptions are caused by the activity of a rather small number of neurons se-
lected from a very large population of predominantly silent cells. The activity of each
single cell is thus an important perceptual event and it is thought to be related quite
simply to our subjective experience. The subtlety and sensitivity of perception result
from the mechanisms determining when a single cell becomes active, rather than
from complex combinatorial rules of usage of nerve cells.10
In his view, activity of a special group of small cells is responsible for even the
most complex brain activity.
The unidirectional feedforward system eventually should converge on the top
where gnostic units will bind all critical features and therefore explicitly represent
the object. In further support of the convergence theory, virtually any arbitrary
complex feature of an object, such as a particular orientation of a bent paperclip,
can be extracted from the ﬁring patterns of inferotemporal neurons in a monkey.
However, such ability does not come free and subtle discriminations in any
modality require months and years of training.11 The ﬁnal, and perhaps strongest,
backing of the theory is the relationship between the gnostic units and behavioral
performance. Experimenters have repeatedly reported on neurons in visual and
other cortical areas where ﬁring patterns of single neurons reliably predict the be-
havioral outcome of the animal, even when its decisions are based on ambiguous
stimuli.12 Binding solved.
Yet, a purely feedforward model with its feudalistic hierarchy just cannot be
the whole story. First, and most important, it does not assign a role to the equally
extensive feedback connections in the cortex.13 A physiological theory that leaves
out half of the anatomical connections cannot be complete. A second frequently

236
RHYTHMS OF THE BRAIN
by information arriving from a very wide variety of sources. The architecture is thus rather inconsis-
tent with a strict feedforward analysis and implies that vision is more an inference than a hierarchical
analysis (Young and Scannell, 2000). Douglas et al. (1995) discusses the numerous advantages of re-
current neocortical circuits.
14. Von der Malsburg (1985).
15. Goldstone (1998) discusses the literature on the ability of trained observers to recognize orders
of magnitude more features than untrained subjects. The ability to match or detect differences between
colors, including shades of color and brightness, varies considerably among the normal population.
One out of 20 humans does not have normal color vision (Goldstein, 2002).
16. For the neuronal loss pattern in Alzheimer’s disease, see Terry et al. (1991). Multi-infarct de-
mentia is another condition where multiple “random” damage occurs but mostly in the white matter.
used reasoning against the hierarchical model of visual recognition is the “combi-
natorial explosion” problem.14 The argument goes like this: if at least one gnostic
cell is required to represent each possible combination of 100 hundred shapes,
100 positions, and 100 colors, then 1,000,000 neurons would be needed to repre-
sent all possible combinations. Of course, if one keeps adding other features, the
numbers rise quickly. Because the number of neurons needed grows exponen-
tially with the number of unique objects represented by their numerous features,
the brain, so the story goes, quickly runs out of neurons. The situation is much
worse, of course, if instead of single cells, populations of cells are taken to repre-
sent individual features. However, this purely mathematical argument may not
hold in the brain. It is hard to estimate the number of unique objects the human
brain can recognize, but it is surely not a galactic number. Most of us, non-
Eskimos, cannot discriminate hundreds of shades of white, and an average person
can name no more than a dozen geometric shapes. On the brain side of the equa-
tion, neurons are not independent coding units but are parts of a strongly inter-
connected system. This interconnectedness puts a clear limit on our ability to
discriminate among unfamiliar objects. What I judge as similar may be judged as
dramatically different by someone else with a different perspective.15 Neverthe-
less, I do not see how the combinatorial explosion argument can be justiﬁed with-
out a proper estimation of the number of objects a brain can recognize.
The third objection concerns the exact location and spatial relationship of the
gnostic neurons. Are they clustered in a small volume, such as a cortical column,
or are they distributed over a large area? Clustering of gnostic units does not ap-
pear to be the case. Clustering invites vulnerability to attacking agents. Devastat-
ing ailments, such as Alzheimer’s disease, are characterized by myriads of
localized attacks on cortical columns.16 However, the random damage of cortical
columns never results in the inability to recognize a particular book, a ﬁnger, or a
speciﬁc family member. Instead, the patients lose the combinatorial mechanisms
needed for recognition. On the other hand, if the postulated gnostic units are dis-
tributed, we face a fundamental problem: how do the gnostic units communicate,
and where do they send their messages? This would require special wiring, which
would make gnostic units special not only because of their conjunction-speciﬁc
response properties but also because of their highly specialized wiring. The com-
plex features represented by gnostic neurons may derive not from their special

The Gamma Buzz
237
17. I discuss how explicit representation may emerge from functional connectivity in Cycle 11.
18. This claim, to date, has no experimental support but follows from the dynamic organization of
cortical networks. My claim is, of course, very different from the condition known as prosopagnosia,
which is an impairment of face recognition that arises from a damage or developmental problem of a
circuit. For a patient-described lucid introduction to this condition, visit Cecilia Burman’s website at
http://www.prosopagnosia.com.
morphology or intrinsic biophysical features but from their functional connectiv-
ity and the dynamics of the network in which they are embedded.17 If all currently
active neurons to a particular face were selectively and instantaneously elimi-
nated in the inferotemporal cortex in my brain, I would not suffer from face
recognition problems because neighboring neurons would instantaneously take
over the response properties of the eliminated cells.18 Another objection that can
be added to the list of criticisms is that purely feedforward circuits with closed
ends do not really exist in the brain. There is no top in the brain hierarchy and the
bottom-up paths are always coupled to top-down connections. So the gnostic neu-
rons would inevitably end up sending their impulses back to earlier processing
stages.
But what is the point of sending impulses back to neurons representing the el-
ements of an object after the whole has been already identiﬁed by the gnostic
units? Because there are no stop signals in the bottom-up model, it is not clear
what mechanisms would prevent the reverberation of activity in an interconnected
system after an object is recognized. The hierarchical feedforward model lacks a
temporal scale that would ensure the discrete and timely transfer of information
from one stage to the next. In the absence of such a timing mechanism, it is not
clear how the input can be effectively linked to the output and become useful in
the real world. Oscillations, as discussed in Cycle 5, are perfectly suited for such
temporal segmentation. The existence of rhythms in the visual system, such as the
prominent alpha waves, is the physiological telltale sign of excitatory feedback
loops in action. Last but not least, the feedforward model is essentially a sequen-
tial integrator and has limited options to compare a newly created representation
with all the semantic knowledge stored about related images.
The purely hierarchic mode of operation is equally problematic in the effector
systems of the brain. Even if we identify a mechanism for ﬂexibly connecting the
postulated gnostic units at the perceptual end, it remains to be explained how the
action system of the brain can be mobilized effectively by a handful of decision-
making neurons at the top of an inverted hierarchy and how it can break down the
tasks efﬁciently into subroutines for motor and other outputs. The bottleneck
problem of highly convergent sensory inputs and extensive divergent outputs as-
sumes a central command that, when damaged, should result in simultaneous im-
pairment of perception and voluntary motor execution. Clinical observations and
experimental lesion studies do not support such a scheme.
As a ﬁnal point, there is an important philosophical objection. The very notion
of the hierarchical model assumes that what we see is already present in the two-
dimensional image of the retina and that the physiological process of seeing is a

238
RHYTHMS OF THE BRAIN
19. Milner (1974) and von der Malsburg (1985, 1999).
sequential extraction of information, which is already present at the level of the
input. The strictly feedforward model of sensory processing does not allow com-
bination the currently sensed inputs with past experience. Because of unidirec-
tional ﬂow of information, feedforward architectures cannot learn with network
growth. Bootstrapping into higher order requires networks with emergent proper-
ties. Systems with emergent features require feedback. Since feedback loops are
available, they are likely to be very important in processing sensory information
or combining the sensory inputs with past experience.
Binding by Time in a Decentralized Egalitarian Brain
An alternative to the hierarchical connectionist model of object recognition is a
more egalitarian solution: binding by temporal coherence. The key idea of this
model, usually attributed to Peter Milner, a colleague of Donald Hebb at McGill
University in Montreal, and to the German theoretical physicist Christoph von der
Malsburg at the University of Heildelberg, Germany, is that spatially distributed
cell groups should synchronize their responses when activated by a single
object.19 In this new scheme, connectivity is no longer the main variable; rather, it
is the temporal synchrony of neurons, representing the various attributes of the
object, that matters. The different stimulus features, embedded in the activity of
distributed cell assemblies, can be combined by mutual horizontal links.
Perhaps the most fundamental difference between the feedforward hierarchical
and temporal synchrony models is that a causal (i.e., temporal; see Cycle 1) se-
quence of events is required for the hierarchical model, whereas events occur si-
multaneously without causal features between the different attributes and higher
order features in the synchrony model. The roots of the ideas behind the temporal
binding model can be traced back to the notion of “synchronicity,” coined by Carl
Gustav Jung and Wolfgang Pauli. After his mother’s suicide in 1927, a failed brief
marriage to a cabaret dancer, and being routinely thrown out from every café in
town for drunken behavior, Wolfgang Pauli fell into a deep, personal crisis and
consulted the already famous psychoanalyst Carl Jung. Their relationship began
as a 2-year phase of doctor–patient connection, but their dialogue continued for
many years at a higher intellectual level. As a physicist, Pauli searched for a uni-
ﬁed ﬁeld theory, whereas Carl Jung was looking for a unifying principle behind
meaningful coincidence, individual consciousness, and the totality of space and
time. The concept of “synchronicity” was born from reviewing more than 400 of
Pauli’s dreams. After several years of discussion, they deﬁned synchronicity as
“the coincidence in time of two or more causally unrelated events which have the
same or similar meaning.” Synchronicity describes some striking and apparently
inexplicable “meaningful coincidences” or “signiﬁcantly related patterns of
chance” when, for example, the contents of a dream are paralleled in a pattern of

The Gamma Buzz
239
20. Pauli was never formally Jung’s patient, and the doctor–patient relationship was mainly con-
ﬁned to analysis of Pauli’s dreams. Their joint book (Jung and Pauli, 1954) is a result of many years of
discussion. However, the real ﬂavor of the debate between these two intellectual giants, arguing from
different sides to ﬁnd mutual enlightenment, is better documented by their long exchange of letters
from 1932 to 1958, published ﬁrst in German in 1992 and translated recently into English (Meier,
2001). The phrase “acausal connecting principle” reﬂects Jung’s struggle with the Aristotelian logic
and deduction. Emergence and circular causation as explanations arrived many years after Jung and
Pauli thought about these issues.
21. Pauli described his uncertainty in an essay, “The Piano Lesson” (Die Klavierstunde), written to
the psychologist Marie-Louise von Franz. In it, he described how an exotic Chinese woman appeared
to him in his dream as a piano teacher before he had to give a lecture about the union of matter and
psyche. The “real” content of this letter is Pauli’s hesitation about issues of synchronicity versus coin-
cidence as scientiﬁcally veriﬁable entities (see Bennet, 1985). Pauli’s suggestion was to detach the
psyche of an observer from any observed phenomenon. In contrast, Jung insisted that the observer’s
psyche is implicitly part of the experimental setup, results, and interpretation. David Peat’s book on
synchronicity (Peat, 1987) discusses further the liaison between psychology and physics and attempts
to ﬁnd a connection between quantum theory and synchronicity and, in a broader context, between
matter and mind.
22. As discussed in Cycle 2, it does not have to, because the world is highly constrained, and asso-
ciations are not entirely unlimited in scope but determined by the statistical features of the environ-
ment.
23. For rapid self-organization of population events, see Buzsáki et al. (1992).
seemingly unconnected external events. In their use of the term, synchronicity
corresponds to an “an acausal connecting principle,” as apposed to causality (see
Cycle 1), which is “the modern prejudice of the West.”20 Perhaps realizing the dif-
ﬁculty in separating synchronicity from chance coincidence, Pauli later preferred
to speak of meaningful correspondences (Sinnkorrespondenzen) or holistic order
(ganzheitliche Anordnung).21
The most attractive feature of the egalitarian binding by synchrony hypothesis
is that, in principle, it offers a virtually endless coding capacity for feature combi-
nations. In addition, cross-modality representations can be mapped directly onto
each other, using the same format. There is only one catch. Flexible representa-
tions of any feature that might coexist with any other feature would require inex-
haustible lateral connections, including long-range wiring between modalities
and sensory-motor domains. Laying down cables for extensive distant connec-
tions requires more space and is much more expensive to maintain than is multi-
plying neurons with local connections. The small-world-like architecture of the
neocortex with its limited density of long-range connections does not quite meet
this requirement.22 This is where oscillation as a linking mechanism comes handy,
since synchronization by oscillation is effective even through a few and weak links
(Cycle 6). During the oscillation, alternating cell assemblies can synchronize in
subsequent cycles, providing a time-multiplexing mechanism for the disambigua-
tion of superimposed images or ﬁgure versus background separation. A particular
assembly can be deﬁned by a short or single barrage of synchronous spikes,
whereby each individual neuron needs to contribute only a single or few spikes.
Such self-organized, synchronous coalitions can be established very rapidly.23

240
RHYTHMS OF THE BRAIN
24. Gray and Singer (1989) and Gray et al. (1989) dubbed bouts of gamma oscillations as “visual
sniffs,” referring to the sniff-induced large-amplitude gamma oscillation in the olfactory bulb, de-
scribed earlier by Walter Freeman, Gray’s mentor (see Freeman, 1975). Although Singer consistently
gives credit to von der Malsburg (1985) for the theoretical implication of synchrony in binding, Jung’s
cultural inﬂuence is hard to dismiss. This is reﬂected by Singer’s consistent use of the term “syn-
chronicity” (e.g., Fries et al., 1997; Singer, 1999; Engel et al., 2001). Eckhorn et al. (1988) also con-
cluded that gamma oscillations may be a potential solution to the binding problem, using a similar
experimental setup and reasoning. Synchrony and synchronicity refer to the same mechanism. I avoid
using the term “synchronicity” because of its Jungean overtones.
25. For a historical survey of observations of gamma-frequency oscillations in humans, primates,
and other animals, see Gray (1994).
How does all this theoretical reasoning translate into neuronal mechanisms?
The ﬁrst round of experimental support for the temporal synchrony conjecture
was provided by Singer and Charles Gray, then a postdoctoral fellow in the
Singer laboratory.24 Departing from the tradition of single-unit recording and
analysis in sensory systems, they recorded not only multiple-unit activity but
also local ﬁeld potentials from single electrodes placed in the striate cortex
(V1) of anesthetized and paralyzed cats. Using simple correlational analyses of
unit ﬁring and Fourier spectral methods, they discovered that a signiﬁcant frac-
tion of the recorded signals displayed oscillation in the 30–60 cycles per second
(i.e., gamma-frequency) band in response to moving bars. These gamma
“bursts” of ﬁeld and multiple-unit oscillations, lasting from tens to thousands of
milliseconds, were rarely observed spontaneously but were reliably induced by
visual stimuli. Optimal stimuli that induced the most robust unit discharge pro-
duced the largest amplitude ﬁeld response, whereas suboptimal stimuli evoked
less unit discharges and less regular ﬁeld oscillations. Unit activity was phase-
locked to the trough of the ﬁeld oscillation, but neither the units nor the ﬁeld
showed any evidence of being time-locked to the onset or other aspects of the
visual stimuli (ﬁgure 9.1). These ﬁndings provided conclusive evidence that the
oscillatory ensemble events emerged locally. The oscillatory dynamics were not
directly related to the stimulus but were added on by the brain. Gamma oscilla-
tion in the activated neocortex ﬁnally found a putative function 50 years after its
discovery.25
These initial observations have given rise to a barrage of experiments in vari-
ous systems and species. Perhaps the most important observation is that syn-
chrony between various locations occurs only when neurons at those locations
respond to related visual features of the object. Neurons with overlapping recep-
tive ﬁelds and similar response properties synchronize robustly with zero time
lag, whereas neurons that do not share the same receptive ﬁelds do not synchro-
nize. Importantly, it is the response features of the neurons, rather than their spa-
tial separation, that determine the vigor of synchrony. Neurons several
millimeters apart in the same or different stages of the visual system and even
across the two cerebral hemispheres have been shown to come together in time tran-
siently by gamma-frequency synchronization. The interarea and interhemispheric

The Gamma Buzz
241
Figure 9.1. Stimulus-induced gamma oscillation: ﬁeld potential and ﬁltered multiple-unit
responses recorded from the primary visual cortex of the cat. Movement of the visual stim-
ulus in the preferred direction of the largest amplitude units evoked rhythmic ﬁring and
ﬁeld oscillation at gamma frequency (40 hertz). Note the correlation of the ﬁeld and unit
ﬁring (visible at the lower, faster traces). Reprinted, with permission, from Gray and
Singer (1989).
synchronization of neuronal pairs or groups occurred primarily during the
stimulus-induced transient oscillations.
Support for the internally organized nature of oscillation, as opposed to
stimulus-driven synchrony, comes from experiments in which multiple neurons
from two recording sites in the motion-sensitive middle temporal area of the wak-
ing monkey were activated by a single moving bar or two bars. When the neurons
at the two sites were activated by two bars moving together over the receptive
ﬁelds and in the preferred directions of the neurons, oscillatory coupling was
rarely observed, even though neurons at both sites were activated. In contrast,
when a single, longer contour activated both neuronal groups, they robustly
synchronized. The “oneness” of the objects was therefore reﬂected by the

242
RHYTHMS OF THE BRAIN
26. Several exhaustive reviews summarize progress in the ﬁeld of temporal binding (Singer, 1993,
1999; Gray, 1994, 1999; Singer and Gray, 1995; Engel and Singer, 2001; Usrey and Reid, 1999), so I
refrain from citing the numerous original reports. See also reviews considering alternative views
(Shadlen and Newsome, 1994, 1995, 1998; Shadlen and Movshon, 1999; Ghose and Maunsell, 1999;
Reynolds and Desimone, 1999).
27. Strabismus or “squint-eye” condition is a developmental impairment, in most cases due to
problems in eye muscle control. As a result, incongruent spatial information is projected from the two
retinas to the brain. During development, one of the eyes becomes dominant, and information from the
nondominant eye is “suppressed” (Attebo et al., 1998).
28. In the binocular rivalry experiments (Roelfsema et al., 1994; Fries et al., 1997), the eye medi-
ating the detection of stimulus was veriﬁed by the direction of optokinetic nystagmus in the anes-
thetized cat. In a related human MEG study, gamma power was larger during rivalry from the eye that
dominated perception than was gamma activity evoked by the nondominant eye (Tononi et al., 1998).
29. The binding-by-synchronization model is often discussed in the context of top-down opera-
tions. However, those features do not directly follow from the original theory.
gamma-frequency coherence of unit activity and not by the similarly increased
discharge rates.26
A more direct relationship between neuronal synchronization and behavior has
been obtained in interocular rivalry tasks in cats with strabismic amblyopia.27
Light responses induced similar changes in ﬁring rates of V1 neurons from both
eyes. However, synchronization among neurons was reduced when ﬁne gratings
of slowly moving stimuli were projected to the amblyopic eye. Previous behav-
ioral experiments showed that these gratings were difﬁcult to resolve by the am-
blyopic but not by the dominant eye. In a related experiment, rivalry between the
two eyes was tested by using two mirrors through which different patterns were
presented to the two eyes. Because perception in strabismic animals alternate be-
tween the eyes, this perceptual alternation can be used to examine how neuronal
responses to stimuli change when they are perceived or excluded from percep-
tion. During binocular stimulation, each eye viewed grating stimuli of the same
orientation but drifting in opposite directions. Neurons in visual areas V1 and V2
showed strong synchrony when the dominant eye was stimulated with the proper
orientation, and synchrony was even enhanced after introduction of the rivaling
stimulus to the contralateral eye. The reverse was the case for the losing eye.28
These animal experiments indicate that timing by synchrony is an alternative
mechanism to the binding problem with numerous advantages over the connection-
ist model. Nevertheless, both approaches are based on the assumption that an object
in the brain is built from its distinct physical elements. Each critical element is rep-
resented and identiﬁed by neuronal activity. The fundamental difference between the
two models resides in the neuronal mechanism of the synthesis. In the hierarchical
connectionist model, it occurs by the convergence of simple to ever more complex
features. In the egalitarian binding-by-synchrony model, on the other hand, the sim-
ple representations are lumped together in one step by oscillations without the ne-
cessity of generating intermediate complexities. The neuronal knowledge generated
this way is not the work of a handful of “smart” gnostic neurons, but rather reﬂects
the aggregated wisdom of large numbers of individual cells. Nevertheless, in their
basic conﬁgurations, both models assume a feedforward, bottom-up ﬂow.29

The Gamma Buzz
243
Separation of ﬁgure and background is often mentioned as a major triumph
of the oscillatory binding model. However, most of those experiments have
been performed by using ambiguous ﬁgures. In most real situations, however,
the ﬁgure and background are strongly related, and the context (background)
determines the brain’s interpretation of the ﬁgure. In these situations, it is
the interrelationship of the two sets of stimuli rather than their segregation
that has to be expressed by some neuronal mechanism. It is not clear how the
feedforward or the binding-by-synchrony model can accomplish this re-
quirement. Strictly speaking, only physiological synchronization can be estab-
lished in anesthetized animals, but no perceptual binding. In the waking
animal, on the other hand, the synchronization process may be under top-down
control.
The issue of ﬁgure-background segmentation brings us back to the funda-
mental problem of the stimulus-brain response approach (Cycle 1). The tacit as-
sumption in perceptual research is that the experimenter actually knows the
attributes of the stimulus. The essence of this philosophy is that elements or fea-
tures of an object activate different neuronal groups, and the applied program
that should keep neuroscientists busy is to ﬁgure out how the binding of the ele-
mentary attributes is solved by the brain. The problem is that the attributes of the
object are not in the object. Instead, the attributes of the object are generated by
the observer’s brain. As Gestalt psychologists have known for long, the whole is
often faster recognized than its parts, indicating that object recognition is not
simply representation of elementary features but the result of bottom-up and top-
down interactions, in harmony with the architectural organization of the cerebral
cortex. Before I address the importance and mechanisms of these top-down
events (Cycle 12), let us consider some other important features of gamma oscil-
lations.
Gamma Oscillations in the Human Cortex
The binding-by-gamma-oscillation hypothesis has a clear prediction for the hu-
man brain, as well. Although historically the binding problem was formulated
for addressing the problems involved in visual object recognition, the idea that
various attributes of a whole make up the whole is quite general and should ap-
ply to all modalities. Accordingly, every part of the cortex should be able to
support gamma oscillations under the right condition. This generalization led
to the hypothesis that consciousness, a state that requires linking global fea-
tures of the brain–body–environment interface, can be linked to a deﬁned elec-
trophysiological process. Coherence measurement of MEG signals over the
whole extent of the cerebral hemispheres indicates that signiﬁcant coupling in
the gamma frequency band is present in the waking brain as well as during
REM sleep. However, sensory perturbation can easily reset the gamma rhythm
in the waking state, whereas the same stimulus is largely ineffective during

244
RHYTHMS OF THE BRAIN
30. Ribary et al. (1991), Llinás and Ribary (1993), and Llinás et al. (2005). A technical issue is
that the variability of the gamma cycle duration is much larger during REM than in the waking state.
This variability could also explain why stimulus-induced resetting appears less robust. Note also that
consciousness is assumed to be a qualitatively different state from unconscious state (Crick and Koch,
2003; Koch, 2004), whereas power of gamma frequency (and, in fact, all frequencies) and coherent
coupling of oscillations differ only quantitatively in the sleep/wake cycle.
31. Detection of transient oscillation poses technical challenges (Pfurtscheller and Aranibar
1997). Because the emergent self-organized gamma oscillations are short-lived and not time-locked to
stimulus features, time-domain averaging cannot detect them. One approach uses the time-varying
spectra of the EEG tapered by a moving window of ﬁxed duration (Makeig, 1993). Another alternative
is to estimate the time–frequency power of the signal by means of a complex Morlet’s wavelet trans-
form (Percival and Warden 2000), applied to single trials, followed by averaging the powers across tri-
als (e.g., Sinkkonen et al., 1995). The two methods are ultimately mathematically equivalent (see
Cycle 4).
32. Julesz patterns are pairs of slightly-different random dot patterns, which, when viewed binoc-
ularly create the illusion of depth (Julesz, 1995).
33. This latency, of course, corresponds to the well-studied P300 component in time-averaged
evoked responses (Näätänen 1975; Näätänen et al., 1987).
REM sleep.30 Irrespective of the interpretation, this is an important observation
because all previous investigations of the human EEG assumed that the “de-
synchronized” scalp patterns of REM sleep and waking states are indistin-
guishable. However, further reﬁnement of the localization and behavioral
methods revealed that gamma is not ubiquitous but localized temporarily to ar-
eas engaged in a particular operation.31
As in animal experiments, enhancement of gamma-frequency power has
been described in motor areas during, but more typically prior to, voluntary
movement and in sensory-motor tasks. In another set of experiments, increased
gamma activity over the frontal lobe was present intermittently during multi-
stable mental rotation task in accordance with perceptual switching. Stereo-
scopic fusion of random-dot Julesz patterns32 into a three-dimensional percept
enhanced the power of gamma-frequency oscillation in the occipital cortex.
Presentation of hidden ﬁgures, such as a Dalmatian dog in a patchy background
or “moony faces” shown upright or inverted, elicited much larger gamma activ-
ity when the ﬁgure was perceived compared to no perception. Learned associa-
tion between a visual and a tactile stimulus evoked a marked gamma oscillation
after the presentation of the visual stimulus and elevated coherence between
signals over the visual and sensory cortices. Signiﬁcant difference in gamma
power was reported between induced patterns by words versus pseudowords in
both visual and auditory tasks. A common feature of all these experiments is
that the induced gamma activity emerges at a variable latency between 150 and
300 milliseconds after stimulus onset, approximately at the time when stimuli
acquire meaning.33 Because the statistical features of the experimental and con-
trol stimuli were similar in many of these experiments, the waveforms of the
early components of the evoked responses (i.e., < 150 milliseconds) were quite
similar. Altogether, the late occurrence of context-dependent increase of
gamma activity over multiple cortical areas is usually interpreted in favor of the

The Gamma Buzz
245
34. Jagadeesh et al. (1992), Pfurtscheller et al. (1994), Salenius et al. (1996), Sanes and Donoghue
(1993), Donoghue et al. (1998), Murthy and Fetz (1996), Bas¸ar-Eroglu et al. (1996), Pulvermuller et
al. (1996), Tallon-Baudry et al. (1997, 2005), Miltner et al. (1999), and Rodriguez et al. (1999). There
are many more experiments available in the literature than the handful listed above. Excellent reviews
have summarized progress in this fast-growing ﬁeld of cognitive neuroscience (Singer and Gray,
1995; Pantev 1995, König et al. (1996), Tallon-Baudry and Bertrand, 1999; Engel and Singer, 2001,
Engel et al., 2001; Varela et al., 2001; Whittington and Traub 2003; Traub et al., 2004).
35. Tallon-Baudry et al. (2005) recorded with linear arrays of electrodes in the lateral occipital
sulcus, the fusiform gyrus, and the posterior calcarine region. The subdural study of Sederberg et al.
(2003) involved hundreds of subdural recording sites.
36. The idea that gamma oscillations could be used to hold sequentially encoded items in working
memory comes from Lisman and Idiart (1995).
hypothesis that the self-organized gamma oscillation reﬂects a top-down cogni-
tive process.34
The above observations also indicate that a coherent perception of an object
involves synchronization of large cortical areas. This conclusion is in contrast to the
experimental ﬁnding in animals, where mainly the cortical modules with the active
units show increased and coupled gamma oscillations, whereas the main part of the
surrounding cortex does not show such changes. However, the human observations
may be simply due to the low spatial resolution of scalp recordings. If gamma os-
cillations in the human cortex play roles similar to those predicted by animal work,
gamma oscillations should be conﬁned to discrete active locations rather than being
diffusely present over a wide cortical region. Intracranial and subdural recordings in
patients, equipped with recording electrodes for diagnostic purposes, conﬁrm this to
be the case. Recording sites as close as 3–4 millimeters from each other in the vi-
sual cortex yielded quite different amplitudes of gamma oscillations. Importantly,
sustained oscillations differentially occurred at different times of the task (ﬁgure
9.2), in a striking contrast to the short-lived oscillations over large areas observed in
scalp recordings. The discrepancy between intracranial and scalp recordings indi-
cates that the short bouts of oscillations detected by scalp electrodes actually corre-
spond to localized events that are integrated over time and space.35
A particular striking correlation between working memory and gamma oscilla-
tion was observed by subdural grid recordings. Working memory is a hypothetical
mechanism that enables us keep stimuli “in mind” after they are no longer avail-
able. The amount of information to be held at any given time is referred to as
memory load, for example, the number of “nonsense” syllables to be stored when
trying to repeat a toast salutation in a foreign language. The longer the string of
the syllables, the larger the memory load. Experiments in epileptic patients,
equipped with large numbers of subdural electrodes for diagnostic purposes,
showed that gamma power increased linearly with memory load at multiple, dis-
tributed sites, especially above the prefrontal cortex. The power remained at the
elevated level during the retention period but fell back quickly to baseline level
after the working memory information was no longer needed. Overall, these ob-
servations support the more general idea that gamma oscillations are used in the
brain for temporally segmenting representations of different items.36

246
RHYTHMS OF THE BRAIN
Figure 9.2. Gamma oscillations recorded from the human visual extrastriate cortex. Left:
Depth multicontact electrodes were inserted perpendicularly to the sagittal plane in this pa-
tient with medically intractable epilepsy for presurgical seizure focus localization. Middle:
Gamma-frequency oscillation evoked by a visually evoked stimulus that the subject at-
tended. Right: Power distribution as a function of frequency and time. Light shade indi-
cates a strong stimulus-induced power at 60 hertz, from 100 to 500 milliseconds after
stimulus onset. Reprinted, with permission, from Tallon-Baudry et al. (2005).
37. Synchrony of presynaptic terminals determines the total charge transfer. For discharging the
postsynaptic neuron, time integration over 15–30 milliseconds appears optimal (Harris et al., 2003). For
other needs, e.g., activation of postsynaptic NMDA channels, the temporal window of effective syn-
chrony might be wider. Von Malsburg (1985) and Singer (Konig et al., 1996; Singer, 1999) postulated
that “coincidence detection” in the 1- or 2-millisecond temporal window is needed for temporal coding,
but to date, there is little evidence for the occurrence of such tight synchrony in the waking neocortex.
Riehle et al. (1997) reported on behavior-dependent occurrence of spikes within 3 milliseconds in the
monkey motor cortex, which they interpreted as evidence for coincidence detection. However, because
the identity of the recorded neurons could not be revealed, the possibility could not be excluded that the
pairs represented monosynaptic discharge of an interneuron by its presynaptic pyramidal neuron part-
ner(s). In support of the latter explanation, the discharge probability between monosynaptically con-
nected pyramidal–interneuron pairs is modulated by ongoing behavior (Csicsvari et al., 1998).
Why Is Gamma Oscillation the Right Kind of Buzz?
The goal of synchrony for neuronal populations is the same as the goal of action
potentials for single cells: forwarding messages to downstream neurons in the
most effective manner. As discussed in Cycle 5, neuronal assemblies in the wak-
ing brain self-organize themselves into temporal packages of 15–30 milliseconds.
They do so because presynaptic discharge within this time window appears to be
most effective in discharging their downstream targets due to the temporal inte-
gration abilities of individual pyramidal cells.37
There is another, perhaps even more compelling reason for creating temporal
windows repeatedly. So far, we have not considered the brain’s perhaps most
unique mechanism: the ability to change the connections among neurons adap-
tively. Neuronal connections are not created equal but are subject to use-dependent
modiﬁcation. There are at least two fundamental ways of how membership in neu-
ronal coalitions can be altered. The ﬁrst one is by forming physical connections be-
tween neurons or eliminating them. Although this method is the primary
mechanism in the developing brain, it may continue in the adult brain, as well, al-
beit at a much reduced level. Another method is changing the synaptic strengths of

The Gamma Buzz
247
38. Until recently, it was assumed that connections among neurons are created during early devel-
opment and that those connections stay forever. However, recent in vivo imaging experiments tell a
different story by demonstrating a slower paced, nevertheless continued, motility of dendritic spines in
the adults, a method of wiring-based plasticity (Chklovskii et al., 2004). Synaptic plasticity was ﬁrst
demonstrated by Bliss and Lømo (1973), launching perhaps the most intense research in neuroscience
(Bliss and Collingridge, 1993; Kandel and Squire, 2000; Johnston et al., 1996; Magee et al., 1998).
Historical events leading to the discovery of LTP are discussed by Craver (2003). A third mechanism
of brain plasticity is by replacing neurons and creating new ones. Neurogenesis is ﬁrmly established in
the olfactory epithelium and in the dentate gyrus of the hippocampus (Gage, 2002).
39. The role of temporal order in synaptic plasticity was ﬁrst discovered by Levy and Steward
(1983) and was predicted by the rules of Pavlovian conditioning (Pavlov, 1927). See also Sejnowski
(1977) and Stanton and Sejnowski (1989) for a theoretical treatment for the importance of spike tim-
ing. Spike-timing–dependent plasticity at the single-cell level is shown in Magee and Johnston (1997),
Markram et al. (1997), and Bi and Poo (1998) and is reviewed in Kepecs et al. (2002) and Dan and Poo
(2004). The relationship between gamma synchrony and plasticity has been modeled by Bibbig et al.
(2001). This study hinges on the experimental demonstration that the time course of dendritic decay
of Ca2+ approximately matches the gamma period.
existing connections. There are two fundamental requirements for affecting
synaptic strength: sufﬁciently strong depolarization of the postsynaptic neuron
and appropriate timing between presynaptic activity and the discharge of the post-
synaptic neuron.38 Because both mechanisms are affected by the gamma-
oscillation–mediated synchronization, adjustment of synaptic strength is a
perpetual process in the cortex (ﬁgure 9.3). In recent years, it has been possible to
measure the critical time window between the activity of the presynaptic (sending)
and postsynaptic (receiving) neuron, which showed that every single time a post-
synaptic neuron ﬁres in a manner that the discharge leads to an increase of free
Ca2+ in the dendrites, the previously or subsequently active presynaptic connec-
tions are modiﬁed.
The important information for us in the present context is that the critical tem-
poral window of plasticity corresponds to the length of the gamma cycle. For my
money, spike-timing–dependent plasticity, as the phenomenon is now widely
known, is among the most important discoveries in cortical neurophysiology be-
cause it highlights the essential role of spike timing in modifying network con-
nectivity, an undisputedly fundamental brain mechanism.39 Thus, even if gamma
oscillation proves to be irrelevant for the binding problem, the oscillation remains
a central timing mechanism essential for synaptic plasticity. On the other hand,
gamma oscillations may link the problem of binding to plasticity. This is because
synchronization by gamma oscillations results in not only perceptual binding but,
inevitably, modiﬁcation of connections among the neurons involved. Synaptic
modiﬁcations can stabilize assemblies representing currently experienced con-
junctions. In turn, these use-dependent changes increase the probability that the
same assemblies will be activated upon future presentations of the same stimulus
even if the stimulus is somewhat modiﬁed in the meantime. The assembly bound
together by gamma-oscillation–induced synchrony can reconstruct patterns on
the basis of partial cues because of the temporally fortiﬁed connections among
neuron assembly members.

248
RHYTHMS OF THE BRAIN
Figure 9.3. Gamma oscillation reﬂects the temporal window of synaptic plasticity. Left: If
the onset of a presynaptic input (pre, which evokes only a subthreshold depolarization;
weak) is followed by burst discharge in the postsynaptic neuron (post) within 40 millisec-
onds, the synapse gets stronger (“Hebbian teaching”; Reprinted, with permission, from Bi
and Poo, 1998). Right: Once the weak input becomes strong enough to evoke a spike on its
own (i.e., suprathreshold), teaching will be suspended. The reason is that a single spike can
prevent the occurrence of burst discharge. The time course of the veto effect of a single
spike (lower left panel) is similar to the time course of spike-timing–dependent plasticity
(upper left panel). Reprinted, with permission, from Harris et al. (2001).
Gamma Oscillations Depend on Fast Inhibition
Gamma oscillations are intrinsic to the neocortex and can emerge in a small piece
of tissue as localized activity. Importantly, the simultaneous, emerging “islands”
sustaining gamma oscillations can occasionally get synchronized in widespread
cortical areas.40 As discussed in Cycle 3, inhibitory neuronal networks are essen-
tial in most oscillations. This is especially true for gamma-frequency rhythms,
and a key player in the process is the GABAA receptor.41
40. In contrast to the highly localized transient gamma oscillation, induced by natural inputs, in
vivo stimulation of the brainstem cholinergic nuclei induces widespread cortical gamma oscillation
after 50–150 milliseconds even in anesthetized cats (Steriade and Amzica, 1996). For widespread
gamma activity in humans, measured by MEG, see Ribary et al. (1991).
41. The idea that interneuron-mediated fast inhibition is critical in gamma oscillations came from
the in vivo observations that several interneurons ﬁre trains at gamma frequency, phase-locked to the 

The Gamma Buzz
249
ﬁeld (Buzsáki et al., 1983; Bragin et al., 1995a). For recent reviews, consult Miller (2000), Buzsáki
and Chrobak (1995), and Engel et al. (2001). In vitro rhythms are discussed in Traub et al. (1999,
2004). Nancy Kopell’s review (Kopell, 2000) is an excellent introduction to the mathematical prob-
lems of gamma oscillations and oscillatory coupling.
42. Whittington et al. (1995).
43. Enhancing or blocking GABAA receptors slows or accelerates the rhythm, respectively, provid-
ing strong support for a critical role of this receptor in gamma-frequency regulation (Whittington et al.,
1995; Traub et al., 1996, 1999; Wang and Buzsáki, 1996). Bartos et al. (2002) showed biexponential de-
cay of the GABAA-receptor–mediated inhibition between basket cells with a fast constant (2–3 mil-
liseconds) followed by a longer decay. The critical aspect of the inhibition depends on the model. It can
be the time constant of the decay or rise time of the postsynaptic potential, shunting effect of inhibition,
or their combination in the various models (Kopell et al., 2000; Vida et al., 2006). In a noise-dominated
interneuronal network, the oscillation frequency depends more on the shortest synaptic time constants
(delay and rise time) than on the longer synaptic decay time (Brunel and Wang, 2003).
There are numerous ways to induce oscillations in the gamma band. The pro-
totypic and simplest kind is when an isolated interneuron network is driven by a
tonic depolarizing force (Cycle 3). Phasic excitation of interneurons by pyramidal
cells can be readily prevented in slice preparations by blocking the ionotropic glu-
tamate receptors by appropriate drugs or not including pyramidal cells at all in
computer model networks. These approaches have attempted to address two main
questions: how does the rhythm emerge and vanish, and what determines the os-
cillation frequency?
Oscillation in interneuron nets can be induced by a strong depolarizing input,
such as a fast train of stimuli delivered locally in vitro, as ﬁrst demonstrated by
Miles Whittington, Roger Traub, and John Jefferys at University of Birmingham
in England.42 Direct recordings from interneurons and observing their patterns in
computer models have shown that the frequency of network oscillation has little
to do with the ﬁring properties of individual neurons because none of them be-
haves like single-cell pacemakers. The average frequency of individual neurons
can vary from 0 to 300 hertz, and the mean ﬁring of the population does not cor-
respond to the network frequency oscillations, either. Thus, frequency regulation
should be sought in factors other than the ﬁring frequency of the neurons. Both
modeling and mathematics showed that the coherent oscillation of the whole net-
work and the frequency of the rhythm are determined by the time course of the
rise and decay of the inhibition, that is, the duration of time the population is pre-
vented from ﬁring. This critical variable was identiﬁed with the time constant of
decay of the GABAergic current. The consequence of a silence or suppressed ac-
tivity can be predicted from what we have already learned about oscillators: the
introduction of a time constant, coordinated across a large part of a system, in-
evitably biases the system toward periodicity. Because the time constant of the de-
cay of the inhibitory postsynaptic potentials, mediated by fast-acting GABAA
receptors, varies from 10 to 25 milliseconds, the oscillation frequency can vary
between 40 and 100 cycles per second. Pharmacological prolongation or shorten-
ing of the time decay of fast inhibition can decrease or increase the frequency of
gamma oscillations.43 The ubiquitous presence of GABAA receptors throughout

250
RHYTHMS OF THE BRAIN
44. Gap junctions are present mainly among the same types of interneurons (Katsumaru et al.,
1988; Fukuda and Kosaka, 2003; Gibson et al., 1999; Tamás et al., 2000). Dendrites and somata of in-
terneurons can be coupled by one or as many as 16 connexin-36 type gap junctions (Bennett and
Zukin, 2004), with estimated coupling values of 0.5–1.5 nanosiemens (Galarreta and Hestrin, 2001).
Gap junctions may help to reduce the heterogeneity problem inherent in interneuron networks (Traub
et al., 2001). The role of gap junctions in gamma-frequency oscillation is illustrated by the reduced
gamma power in connexin-36 gene knockout mice (Hormuzdi et al., 2001; Traub et al., 2003; Buhl et
al., 2003; Connors and Long, 2004).
45. Both in vivo and in vitro ﬁndings show that the major part of the intracellular and extracellular
gamma power is brought about by the fast-ﬁring basket and chandelier neurons (Bragin et al., 1995a;
Fisahn et al., 1998; Penttonen et al., 1998; Csicsvari et al., 2003; Mann et al., 2005).
46. Miles (1990) observed high reliability of excitatory postsynaptic potentials between pyramidal
cells and unidentiﬁed interneurons. Gulyás et al. (1993b) showed that such highly reliable excitatory
postsynaptic potentials are mediated by a single release site. Pyramidal cells often form clusters of
multiple synapses on interneuron dendrites and can form contacts on cell bodies, as well (Buhl
et al., 1997; Ahmed et al., 1997). Csicsvari et al. (1998) demonstrated high reliability of spike trans-
mission between pyramidal cells and interneurons in the behaving rat. For neocortical pyramidal
cell–interneuron connections, see Swadlow (2003).
the brain explains why gamma-frequency oscillation can be found virtually
everywhere. Another mechanism that facilitates synchrony among local interneu-
rons is direct electrical communication in the form of gap junctions. These are
low-resistant junctions that provide strong coupling between neighboring in-
terneurons and facilitate the synchronous occurrence of spikes bidirectionally.44
Although gamma oscillation in interneuron networks helped our understand-
ing the basic principles, isolated interneuron networks do not exist in the work-
ing brain. In the intact cortex, interneurons are embedded in large-scale
excitatory networks, and both principal cells and interneurons are phase-biased
by the oscillations, as shown by the intracellularly recorded excitatory and in-
hibitory postsynaptic potentials and the phase-locking of their action potentials.
Although the decay time of the GABAA receptor remains the main cause in de-
termining the oscillation frequency, other factors such as shunting inhibition, the
magnitude and decay of the excitatory postsynaptic potentials and spike afterpo-
tentials are additional time constants that can affect the oscillation. Nevertheless,
the contribution of inhibitory postsynaptic potentials remains more critical for
the extracellularly recorded power in the gamma frequency band than is the
contribution of excitatory potentials. At the population level, this is amply re-
ﬂected by the largest power of gamma currents near the somatic layers, where
most inhibitory terminals are concentrated.45 In the presence of principal cells
and interneurons, a new competition emerges between inhibition-timed and
principal-cell–timed occurrences of action potentials in inhibitory neurons. The
synchronously discharging interneurons inhibit both each other and the pyrami-
dal cells with a similar time course, allowing them to discharge most easily after
the decay of inhibition. On the other hand, if a few pyramidal neurons happen to
discharge in response to some input, the situation changes dramatically. The rea-
son is the high efﬁcacy of the excitatory synapse between principal cells and in-
terneurons.46 Discharge of a single pyramidal cell can initiate spikes in its target

The Gamma Buzz
251
47. Without external perturbations, gamma oscillation may be sustained, provided that the depo-
larizing and hyperpolarizing forces are balanced and coordinated. Such persistent gamma can be in-
duced in small cortical slices in vitro by drugs that tonically depolarize both pyramidal cells and
interneurons, e.g., carbachol, kainate, or metabotropic receptor agonists (Fisahn et al., 1998, 2002;
Gillies et al., 2002; Mann et al., 2005). These in vitro studies also demonstrate that NMDA and
GABAB receptors are not necessary for gamma oscillations.
48. The earliest model of gamma-frequency oscillations in the olfactory bulb assumed that the pe-
riod of the oscillation is determined by the axon and synaptic delays in a reverberatory principal
cell–interneuron local circuit (Ahn and Freeman, 1974; for a related model in the hippocampus, see
Leung, 1992, 1998). The reverberation idea was based mainly on the observation that interneurons
ﬁred at an approximately one-quarter cycle phase delay after the pyramidal cells. The same reverber-
ation model was used by Andersen and Eccles (1962) to explain the much slower theta rhythm. The
presence of gamma in the purely interneuron network demonstrates that axon conduction delay is not
the key variable for determining the oscillatory frequency.
49. Another potential source of synchronization in the gamma band is the postulated gap junctions
between the axons of pyramidal neurons. Traub and colleagues have presented numerous arguments,
computational models, and experimental data in favor of axonal gap junctions (Schmitz et al., 2001;
Traub et al., 2002, 2003, 2004).
50. Gray and McCormick (1996) describe a special type of presumably excitatory cell in the visual
cortex, which ﬁres rhythmic bursts of spikes at gamma frequency upon tonic depolarization. They
suggest that these “chattering cells” possess pacemaker properties and are critical for the emergence
of network gamma oscillations. It is not clear, though, how a small group of excitatory cells can im-
pose a rhythm on the principal cells, given the low reliability of single excitatory synapses in the neo-
cortex. It is also not clear how excitatory postsynaptic potentials of chattering cells, exciting dendrites
of the principal cells, can time the occurrence of action potentials, given the low-pass ﬁltering effect
of the dendrites. Interneuron-induced inhibitory potentials with fast kinetics and impinging on the so-
mata of pyramidal cells are more efﬁcient in regulating spike timing. Furthermore, Steriade (2004)
has questioned whether chattering cells compose a special group, given that many pyramidal cells can
burst at gamma frequency, provided the right depolarizing conditions. The resonant properties of py-
ramidal neurons, on the other hand, might further enhance the propensity of cortical circuits to oscil-
late at gamma frequency (Steriade et al., 1991; Llinás et al., 1991; Penttonen et al., 1998).
interneurons, and the evoked interneuron spikes can dictate the time course of
inhibition. The spiking pyramidal cells therefore introduce a novel phasic com-
ponent, which can enhance or interfere with the oscillation. This unpredictable
interaction is perhaps the main reason for the fragility and transient nature of
gamma oscillations in the intact brain.47 Although a very small fraction of prin-
cipal cells are active at one time, their convergence on interneurons explains why
the discharging pyramidal cells lead the interneuron action potentials by a few
milliseconds.48
The phase-leading of principal cells in gamma oscillations raises an important
issue.49 Are subsets of spikes in principal cells dedicated for the initiation and
maintenance of a rhythm? If so, the oscillation-related spikes may not be used for
information transmission.50 This does not appear to be an energetically efﬁcient
arrangement. The alternative solution is that spikes generated for the transmission
of information and the initiation of the rhythm are the same, as has been sug-
gested by the binding-by-gamma hypothesis in the visual cortex. Although py-
ramidal neurons in the visual cortex occasionally ﬁre at gamma frequency in
response to a relevant stimulus, ﬁring patterns of single principal neurons are

252
RHYTHMS OF THE BRAIN
51. Firing patterns of cortical neurons can often be described by Poisson statistics (Bair et al.,
1994; Shadlen and Newsome, 1994).
52. A third proposed scenario is that the thalamus acts as a pacemaker and is responsible for gamma
coherence throughout the neocortex (Llinás et al., 2005). However, given the lack of interhemispheric
wiring in the thalamus, it is unlikely that the thalamus can provide mean zero time-lag synchrony for
cortical sites in the opposite hemispheres (Engel et al., 1991). In the absence of long-range cortical con-
nections, even spindles remain segregated (Contreras et al., 1996; Khazipov et al., 2004).
often characterized as irregular.51 For the maintenance of a distributed gamma os-
cillatory network, it is not necessary that principal cells discharge at the network
frequency. However, when a discharge occurs, its timing is constrained by the on-
going cycling inhibition. In turn, spikes of pyramidal cells will contribute to the
timing of the action potentials in the surrounding interneurons.
Viewed from the latter perspective, the physiological cause for the occurrence
of gamma-frequency oscillation is the elevated discharge of pyramidal cells cou-
pled with the pacing of GABAA-receptor–mediated local inhibition. Therefore,
gamma activity is expected to arise in cortical areas with elevated ﬁring of princi-
pal cells. Nevertheless, no single neuron in the oscillating network can be pointed
to as the leader of the rhythm. Instead, principal cells and interneurons contribute
equally to form a single oscillator. The implication is that small and large net-
works produce the same kind of rhythm and that the portions of the oscillator do
the same as the whole. Can such distributed network oscillators with fractal fea-
tures grow in size ad inﬁnitum?
Coupling Distant Gamma Oscillators
The frequency of gamma oscillations is similar in mice, rats, cats, monkeys, and
humans. The perpetuation of the rhythm across species also indicates that the size
of the network is of secondary importance and that mechanisms exist to preserve
timing across longer distances in larger brains. As discussed above, coherent
gamma oscillations have been observed between structures set apart by large dis-
tances, including the primary visual cortices in the two hemispheres, in both hu-
mans and animals with smaller brains. Do such coherent oscillations occur
because the participating neurons are part of a single oscillator growing in size, or
should they be considered separate local oscillators that are coupled by some efﬁ-
cient mechanism? In both cases, the problem to be addressed has to do with the
axon conduction delays.52
Let us ﬁrst consider a single oscillator that grows in size. In the small-world-
like structural organization of the neocortex, the synaptic path lengths remain the
same independent of the size. Thus, as far as synaptic neuronal distances are con-
cerned, there is no problem with size. The necessary shortcuts can be established
by the long-range corticocortical connections, which have excitatory and (pre-
sumably) inhibitory components. In order to keep synchrony in phase, neurons at
local and distant sites should discharge within the active cycle of the rhythm,

The Gamma Buzz
253
53. The advantage of long-range inhibitory connections, as opposed to excitatory ones, is that the
effective time window of inhibition-mediated synchronizing effect is longer than that of excitation in
relaxation oscillators. Excitation, to be effective, should arrive within the narrow duty phase of the
cycle.
54. Traub et al. (1996) and Bibbig et al. (2002). Gloveli et al. (2005) suggest that gamma synchro-
nization in the hippocampus is best in the CA3–CA1 axis, in contrast to theta synchronization, which
is highest along the long axis of the hippocampus (Bullock et al., 1990).
55. A caveat is that the induced gamma-frequency patterns in vitro are supersynchronous, involv-
ing the discharge of virtually all pyramidal cells, as evidenced by the large-amplitude population
spikes at gamma intervals (Traub et al., 1996). Therefore, the two-site synchrony studies under these
conditions may be more relevant to epileptic synchronization than to physiological gamma coupling
(Traub et al., 2005). Besides conduction delays, there are other explanations of the gamma to beta fre-
quency shift, as pointed out by Kopell et al. (2000) and Bibbig et al. (2002).
which is limited to 5–10 milliseconds in the case of gamma oscillations. Some
long-range axons with fast conduction speeds that meet these criteria do exist, but
they are very few and limited mostly to interconnecting primary sensory areas
(see Cycle 3).53
Another way of conceptualizing gamma synchrony between spatially distant
sites is that two networks, such as the primary visual cortices in the two hemi-
spheres, form two separate oscillators that are coupled by some links. Traub, now
at Downstate Medical Center in Brooklyn, New York, and associates were the ﬁrst
to study the coupling of neuronal oscillators experimentally and in computational
models.54 They studied the synchronization of induced oscillations at two sites in
the hippocampal slice preparation. In both the experiment and the associated
model, the key requirement for synchrony was extra spiking of at least some in-
terneurons in one network in response to excitatory inputs from the distant oscillat-
ing network. Because basket cells and other interneurons typically discharged a
single spike per gamma cycle, and spike doublets occurred mostly when gamma be-
came synchronized at both sites, the spike doublets in interneurons were taken as
the necessary requirement for long-range synchrony. Modeling studies showed that
the ﬁrst spike of the interneuron was initiated by the local pyramidal cells, whereas
after a short delay, another spike was triggered by inputs from the oscillating distant
site. Provided that the later interneuron spike occurred in the same phase of the cy-
cle as the ﬁrst spike, the two sites maintained zero time lag synchrony.
It is important to recognize that once synchrony is established on a single
gamma cycle, the two sites can remain synchronous for several cycles even with-
out further synchronizing events. This is the major advantage of oscillatory syn-
chrony and the main reason why synchrony can be established by relatively weak
connections and few spikes. If the input from the distant sites arrives too late, due
to long travel times, the extra interneurons spikes can prolong the inhibition and
interfere with the ongoing oscillation, resulting in desynchronized activity. Fur-
ther delays may lead to synchrony again, but this time the pyramidal cells are in-
hibited at every other cycle, ﬁring effectively at half the frequency of the
interneuronal gamma oscillation. Such gamma to beta oscillation shifts thus can
emerge when conduction delays between the two sites are large.55

254
RHYTHMS OF THE BRAIN
56. Although, to date, there is no experimental basis of such conjecture, ironically it is as good as
any available hypothesis attempting to explain the superior performance of the human brain. Long
conduction delays in whales can also be the reason for hemispheric independence and the observed
unihemispheric sleep in these large-brain animals. For a counterpoint on brain size/complexity and in-
telligence, see Emery and Clayton (2004).
57. Internal or central synchronization is deﬁned by a statistically signiﬁcant covariation in ﬁr-
ing probability of two neurons or a group that cannot be accounted for by their stimulus-locked
covariations.
Although the exact mechanisms of long-distance and large-scale gamma os-
cillations have yet to be clariﬁed, the available ﬁndings clearly demonstrate that
the major limitation of gamma coherence is the availability of fast-conducting
ﬁbers. Therefore, anatomical knowledge about the axonal diameter and myelin-
ization of long-range connections, and the incidence of such fast-conducting
ﬁbers can predict the effective temporal coupling between cortical sites. Be-
cause primary sensory cortices but not frontal cortical areas are interconnected
by large-diameter callosal ﬁbers (see Cycle 2), high interhemispheric gamma
synchrony is expected between sensory areas but not between frontal cortical
areas.
As discussed in previous Cycles, long-range connections occupy an exces-
sively large portion of brain volume, and therefore, large-diameter ﬁbers are
used sparingly. In large brains, such as those of elephants and cetaceans, the
cortical networks are placed physically “too far” from each other, and even
large-diameter ﬁbers may prove too slow for synchronizing networks at distant
cortical sites. Given the hypothesized importance of gamma-frequency syn-
chronization in cognitive operations, we can conjecture that brains larger than
that of Homo sapiens are less optimal for global performance because of sub-
optimal functional connectivity and, consequently, less effective temporal syn-
chrony.56
Synchrony Can Be Brought About by External or
Centrally Generated Oscillations
There is no a priori reason why information should be transmitted in a rhythmic
fashion. In principle, a computer or any household electronic appliance could per-
form pretty much the same manner if information was moved according to a ran-
dom temporal schedule, instead of a precise clock, as long as the steps at different
levels were coordinated by some mechanism. In short, the key mechanism is syn-
chrony for the sake of effectiveness; rhythm just happens to be a convenient phys-
ical and biological solution for synchrony.
Neurons can be brought together into short temporal windows by two general
mechanisms. One is synchronization by a strong punctuate stimulus, and the other
mechanism is emergent, self-generated synchrony.57 Synchronously discharging
neurons would exert the same effect on their targets, independent of the mechanisms

The Gamma Buzz
255
58. Bair and Koch (1996), Bair et al. (1994), and Buracas et al. (1998).
59. Kruse and Eckhorn (1996); Eckhorn (2000). The frequent occurrence of saccadic eye move-
ments in the waking animal may be another explanation why visually induced gamma oscillations are
often larger in the anesthetized preparation where the eye position is ﬁxed. For the precision of signal
timing across the visual system, see Schmolensky et al. (1998). Ahissar and Arieli (2001) emphasize
the active role of microsaccades in perception.
that brought about the synchrony. Most studies investigating the role of gamma-
frequency oscillations in binding used stimuli that are either stationary or moving
at a constant slow speed. The emerging oscillations are induced by the input in the
sense that the onset of the rhythm and the oscillatory cycles do not have a precise
temporal relation to the timing of the external event. However, the effect of tem-
porally dynamic stimuli is quite different. For example, single neurons in the me-
dial temporal area of the macaque monkey—several synapses downstream from
the retinal input—can encode the moment-to-moment changes of a moving signal
with a temporal precision of a few milliseconds between stimulus repetitions.58 If
changes of the external stimuli occur faster than the internally generated gamma
frequency, intrinsic gamma will not emerge. This behavior is predicted by the na-
ture of relaxation oscillators (Cycle 6). External stimuli can be conceived as per-
turbations that, when appropriately timed after the duty cycle, can advance the
phase of the next cycle. If the input is irregular, the output of the forced “oscilla-
tor” (now without a rhythmic output) will also be irregular but time-locked to the
input. We have described such pattern-following mechanism in rat pups, where
the timing of cortical spindles reﬂected the trigger signals from muscular activity
(Cycle 8).
If neurons are already engaged in internal synchronization, the external stimu-
lus will compete with the central oscillator, and the outcome depends on the rela-
tive timing and strength of the external input and the propensity of the internal
oscillator. The stimulus may be ignored, or it may enhance or quench the internal
oscillation. In an experimental test of these ideas, Reinhard Eckhorn and col-
leagues from the Philipps University of Marburg, Germany, examined the pertur-
bation of
centrally generated gamma oscillations by stimulus-locked
synchronized signals in V1 and V2 cortex of anesthetized cats. With increasing
amplitude of fast transient movements, the internally induced power of the oscil-
lation was gradually reduced, whereas the power of stimulus-locked events in-
creased (ﬁgure 9.4). These experiments point to the paramount importance of the
oscillation: synchrony. If synchrony is achieved by other means, such as strong
inputs, oscillation is not needed. On the other hand, if the input is not sufﬁcient to
provide synchrony, the brain generates it by means of oscillations. Similar exper-
iments were done also in the waking monkey. Rapid changes of the retinal image
due to sudden movement of the object or transient changes in its contrast reduced
the power of induced central oscillations. Position change of the object’s image
on the retina, due to fast vibration of the eyes at approximately 60 per second,
called microsaccades, produced similar effects.59
A fast-moving stimulus, unless tracked by eye movements, does not allow for

256
RHYTHMS OF THE BRAIN
in-depth examination of stimulus features. The competition between detection of
position and identiﬁcation of the moving object also raises the important ques-
tion of the necessary lifetime of cell assemblies in binding. One hypothesized
advantage of the binding-by-gamma hypothesis is its multiplexing ability, which
allows for the fast alternation of assemblies perhaps in successive gamma cycles.
The important question is whether the same or different assemblies can be acti-
vated in successive gamma cycles. In principle, the alternation feature could be
useful for the segregation of ﬁgure and background. However, neuronal activity
in just one gamma cycle may not be sufﬁcient for obtaining a consensus of dis-
tributed neurons and to induce the expected percept. This drawback is indicated
by both our limited ability to perceive details of fast-moving objects and stimu-
lation experiments of the human cortex. Brief electrical stimulation of the so-
matosensory cortex in waking patients can be detected but never described as
“feelings.” Only when trains, lasting from 200 to 500 milliseconds, are applied
Figure 9.4. Internally induced and stimulus-triggered synchronous activities compete
with each other. Top: Single-trial multiple-unit responses in the visual cortex, induced by a
smoothly moving stimulus (left) or by sudden “jerky” changes of the visual scene (right).
Note highly rhythmic activity at gamma frequency (30–60 hertz) in response to the contin-
uously moving signal. In contrast, randomly moving stimuli evoked responses that were
dominated by stimulus movement with no rhythmic component. Bottom: Adding increas-
ing levels of random movement progressively decreased the stimulus-induced gamma-
frequency power. Reprinted, with permission, from Kruse and Eckhorn (1996).

The Gamma Buzz
257
60. Libet (2004). Similarly, transcranial magnetic stimulation of the occipital area induces
phosphenes (tiny moving dots of light or stars) but no pattern sensation (Amassian et al., 1998). A
general problem with direct brain stimulation methods is that the electrical pulses not only evoke su-
persynchronous discharge in neurons as a function of distance from the electrode but also inevitably
recruit strong inhibition, which silences spiking activity for much longer time than the physiological
suppression of activity brought about by gamma oscillations. The minimum time of perceptual
switching when observing ambiguous ﬁgures may be related to the lifetime of induced gamma oscil-
lations.
do subjects report a sensation of touch.60 The temporal window requirement
places the induced gamma oscillations into a different perspective. It is possible
that the function of the self-generated oscillations is to engage the same or sys-
tematically growing cell assemblies for sufﬁcient duration necessary for subjec-
tive perception. In support of this idea, shortening the lifetime of the assemblies
by stimulating the somatosensory cortex shortly after touching the skin can pre-
vent sensation. A full assessment of the assembly lifetime window hypothesis
will require large-scale recording of neuronal activity, a method that has the suf-
ﬁcient time and single-neuron resolution to examine the buildup and decay of
neuronal assemblies and the impact of external perturbations on self-organized
interactions.
The Content of Gamma Oscillations: 
Insights from Insects
Model systems are always a trade-off, giving up some direct relevance for sim-
plicity. Consider olfactory perception in insects as a model for visual perception
in higher mammals. Yet, these entirely different sensory systems have at least one
thing in common: stimulus-induced gamma oscillations. The technical advan-
tages of using insects over mammals are enormous. The principal enemies of the
physiologist are movement-induced artifacts caused by breathing and vessel pul-
sations in mammals. The head of an insect with the brain can be ﬁxed without the
use of anesthetics that profoundly change the dynamics of the brain. For extra
mechanical stability, the head can be separated from the body without major con-
sequences. Biologically relevant stimuli can be delivered to the head sensors with
high precision. Despite the small size of neurons, very complex physiology can
be performed under convenient visual control in drug-free, sensing, and essen-
tially intact preparations.
Gilles Laurent and colleagues at the California Institute of Technology have
been working on the problem of coding of olfactory information. Their favorite
animal is the locust because of its well-described anatomy of the olfactory sys-
tem. Odorants exert their effects slowly, providing ample time for the experi-
menters to study the temporally evolving patterns. One such pattern is a transient
oscillatory ﬁeld response at gamma frequency that evolves over repeated presen-
tations in the antennal lobe, mushroom bodies, and the beta lobe, three sequentially

258
RHYTHMS OF THE BRAIN
61. Because GABAergic neurons in the locust antennal lobe do not emit action potentials, these
observations add further support of the GABAA receptor time constant as the major source of gamma-
frequency regulation. Gamma frequency in insects is lower (20–30 cycles per second) than in mam-
mals (Laurent, 2002).
connected stages of olfactory processing in insects. Both projection neurons and
GABAergic interneurons of the antennal lobe display membrane oscillations, co-
herent with the extracellular ﬁeld potential, much like in the mammalian cortex.
Spiking of the projection neurons shows unique ﬁring patterns that evolve over
1–3 seconds, a really sluggish response. Different odorants activate different sets
of cells, indicative of some spatial representation of odors. However, many neu-
rons respond to several odorants, and the temporal patterns of spike responses are
characteristic to different odorants and concentrations. Laurent observed that at a
certain time after the odorant presentation, the individual spikes become phase-
locked to the induced gamma cycles as well as to other simultaneously recorded
neurons.
Are oscillations and the ﬁne temporal patterning of spikes essential for odor
recognition, or are they simply a byproduct of the circuit, a sort of correlated
noise? By blocking GABAA receptors pharmacologically, synchronization of pro-
jection neurons in response to odorants is impaired, pointing to the importance of
inhibitory receptors in the generation of gamma oscillations.61 Importantly,
whereas blocking the fast GABAA receptors in the antennal lobe abolished
gamma waves and the oscillation-guided timing of the projection neurons, it
spared the spike patterning of individual neurons on the longer temporal scale. In
an elegant series of experiments, Laurent’s group asked whether such “desyn-
chronization” in the antennal lobe has any consequences to the behavioral re-
sponse of the animal and how such ﬁne temporal structures could be exploited for
extracting information about the odors by downstream networks.
For the behavioral experiments, they switched to honeybees and showed that
the basic physiological patterns are similar to those observed in the locust. They
trained the bees to discriminate between odorants of different chemical composi-
tion (“easy task”) or between molecularly similar odorants (“difﬁcult task”). The
blockade of gamma oscillations in the antennal lobe impaired the bees in the dif-
ﬁcult task, but they could still distinguish the dissimilar odorants. The experi-
menters reasoned that gamma oscillation of neuronal assemblies in the antennal
lobe is functionally relevant and that the ﬁne temporal structure of neuronal spik-
ing is essential for the segmentation of stimulus representation. To test this hy-
pothesis, they went one important step further and recorded from neurons in the
beta lobe, two synapses downstream from the antennal lobe. Similar to the pro-
jection cells of the antennal lobe, beta-lobe neurons display odor-speciﬁc ﬁring
patterns. Because the “observer” neurons are upstream from the antennal lobe
cells, they examined whether the ﬁne temporal relationship among the input neu-
rons is relevant to the response patterns of the observers. After screening for
odorant-speciﬁc patterns in the beta-lobe neurons, GABAA receptors were
blocked pharmacologically in the antennal lobe, resulting in the loss of gamma

The Gamma Buzz
259
62. A long list of reports describe the experiments summarized here (MacLeod and Laurent, 1996;
Wehr and Laurent, 1996; Stopfer et al., 1997; McLeod et al., 1998; Stopfer and Laurent, 1999). For re-
views, see Laurent (1999, 2002). A potential caveat is that insects can make a decision about the iden-
tity of odorants within 300–500 milliseconds, whereas the differences in ﬁring patterns evolve over
several seconds. Another criticism is that newborn rats are able to make olfactory discrimination yet
only snifﬁng-related theta oscillations without the fast gamma are present at this young age (Fletcher
et al., 2005). However, Laurent’s group has also pointed out that discrimination between chemically
distinct odorants in honeybees are still possible after pharmacological blockade of gamma oscilla-
tions, but the bees are severely impaired when chemically similar odorants are to be distinguished.
oscillation but not of the general response patterns of its neurons. Two observa-
tions were made. First, the discrimination of odors by the evolving ﬁring patterns
of the beta-lobe neurons was impaired. Whereas simple inspection of spike distri-
butions during and following odor presentation could inform the experimenter
whether cherry or citral odorant was delivered, following the loss of gamma os-
cillation in the antennal lobe, the neuronal responses in the downstream beta lobe
became less distinct. The second observation was the emergence of new re-
sponses to odorants to which the beta-lobe neurons never responded with the os-
cillation intact.62
No matter how convincing these experiments in insects are, they do not, by
analogy, prove that identical mechanisms are in action in the visual system of
mammals. After all, there is no guarantee that the mechanism of stimulus coding
in an insect has a lot in common with vision and other operations in a mammal.
Similar proof should be provided in the more complex brains. Nevertheless, the
experiments in insects do suggest that the ﬁne temporal organization by oscilla-
tory synchrony is a fundamental mechanism that may be valuable in many struc-
tures. If a constructive mechanism is invented by nature in simple organisms,
more complex animals tend to exploit it. The ﬁndings also show that the informa-
tion can be contained not only in the ﬁring rate changes of individual neurons but
also in the temporal relation of spikes in neuron pairs and assemblies. At this
point, it is worth reiterating that gamma oscillations, and neuronal oscillations in
general, are not “independent” events that impose timing on neuronal spikes but
rather are a reﬂection of self-organized interactions of those same neurons that
detect, transfer, and store information. Full exploration of this claim requires
recording from large numbers of identiﬁed neurons and appropriate analysis
methods.
Brieﬂy . . .
The most characteristic ﬁeld pattern of the waking, activated neocortex is
gamma oscillation. Because of its low amplitude, the oscillatory nature of this
EEG pattern was difﬁcult to reveal by the early mechanical pen recorders, for
which reason the waking scalp EEG pattern was generally referred to as “desyn-
chronized.” Gamma oscillations are ubiquitous throughout the brain. The main

260
RHYTHMS OF THE BRAIN
reason for this is that its generation depends primarily on the time decay of
GABAA-receptor–mediated inhibition and/or shunting. These receptors are uni-
formly distributed in the cerebral cortex and other brain regions. Because in-
hibitory postsynaptic potentials mediated by these neurons are quite reliable,
they provide a more efﬁcient means for timing than the notoriously unreliable
excitatory postsynaptic potentials. Furthermore, the membrane of basket and
chandelier neurons, the major suppliers of fast inhibition to the perisomatic re-
gion of principal cells, possess resonant properties selectively in the gamma fre-
quency band, and these interneurons often ﬁre in this frequency range. In
addition to mutual inhibitory innervation, interneurons are also coupled by gap
junctions. Due to the localized axon arbors of basket and chandelier cells and the
local gap junctions, gamma oscillations in the cortex are often conﬁned to a
small piece of tissue. Coupling of distant gamma oscillators require fast-
conducting conduits, which requirement may be fulﬁlled by the widespread axon
collaterals of long-range interneurons and possibly by the long axons of some
pyramidal cells. Phase coupling of induced gamma oscillations allows for the
temporally synchronous discharge of activated groups in disparate parts of the
cortex. The physiological importance of the gamma rhythm is supported by the
observation that neuronal assemblies in the waking brain self-organize them-
selves into temporal packages of 15–30 milliseconds. This time window is most
advantageous for neurons downstream from the assemblies because pyramidal
cells integrate excitatory inputs most efﬁciently in this time range. Perhaps an
even more compelling argument for the functional importance of gamma oscilla-
tions is that strengthening and weakening of synaptic links are best established
within the time period of gamma waves by the mechanism of spike-timing–
dependent plasticity.
Gamma oscillations have been hypothesized to offer a solution to the century-
old “binding problem” of perception. Because different features of an object,
such as color, texture, distance, spatial position, and smell, are processed in sep-
arate parts of the cortex by different sets of neurons, one should explain how
they are bound into a complex representation in a matter of 200 milliseconds or
so to “reconstruct” the physical object. An earlier solution of the binding prob-
lem is a hierarchical feature extraction in feedforward networks, the product of
which is a set of “gnostic” neurons at the top. At each processing stage, features
represented by the preceding stages are combined to gain ever more complex
features. The gnostic neurons at the end of the hierarchy are believed to explic-
itly represent unique objects and concepts.
Although hierarchical organization and feature extraction in the brain cannot
be denied, there are several problems with representations by gnostic units only.
An alternative to the sequential feature extraction scheme is the temporal bind-
ing mechanism by gamma-oscillation–assisted temporal synchrony, a novel hy-
pothesis of object perception that unleashed a new dialogue about the role of
timing in the brain. In the “binding by synchrony” model, convergence of con-
nectivity is no longer the main variable of feature extraction; rather, it is the tem-
poral synchrony of neurons, representing the various attributes of objects, that

The Gamma Buzz
261
matters. The different stimulus features, embedded in the activity of distributed
cell assemblies, can be brought together transiently by the temporal coherence
of the activated neurons, which oscillate at gamma frequency. An attractive fea-
ture of the temporal binding hypothesis is that it offers a versatile coding capac-
ity for feature combinations. In addition, cross-modality representations can be
mapped directly onto each other, using essentially the same coding format.
Can a mechanism as simple as an oscillation solve such a complicated prob-
lem as binding? Perhaps not, but it may be an essential ingredient of the solu-
tion. It must be emphasized that temporal synchrony by oscillation and
hierarchical feature extraction are not mutually exclusive mechanisms. Impor-
tantly, synchronization by gamma-frequency oscillation can be detached from
the problem of binding. Even if gamma oscillation does not solve the issue of
binding, oscillations in the gamma-frequency range remain a compelling tim-
ing/selection mechanism for neuronal communication.

Cycle 10
Perceptions and Actions Are 
Brain-State Dependent
Complex systems do not forget their initial conditions: they carry their his-
tory on their backs.
—Ilya Prigogine
262
The loss of our ability to communicate with the environment and control our
skeletal muscles at will—in short, the loss of awareness—at the onset of sleep
justiﬁes the use of two discrete words for the separation of two distinct brain
states: sleep and wakefulness. Being aware and not being aware of our surround-
ings are considered to be qualitatively different states. However, at any given mo-
ment, not all systems or subsystems are necessarily equally asleep or awake. Like
in the damped oscillatory stages of sleep, our various physiological and subjective
operations, emotions, and level of alertness also change systematically and peri-
odically while awake. The optimal time of day for maximum athletic achievement
or best cognitive performance varies and depends on the nature of the task. Even
some trivial motor outputs, such as hand grip strength, and simple cognitive per-
formance, such as multiplication, vary considerably. The variation of our motor
and cognitive abilities is evident over periods of minutes, seconds, and even ﬁner
time scales.
Psychophysical measurements have already provided ample evidence that
brain states characterized by various terms, such as arousal, vigilance, attention,
selective or focused attention, expectation, anticipation, mental set, mental
search, evaluation, surprise, emotions, motivation, drive, novelty, and familiarity,
exert a strong inﬂuence on the brain’s interpretation of sensory inputs prediction.
Other hypothetical constructs, such as planning, preparation, decision, and volition,

Perceptions and Actions Are Brain-State Dependent
263
also affect motor execution and the reaction time between sensory inputs and mo-
tor outputs. It is not clear, though, how these terms and especially their alleged
neurophysiological mechanisms differ or represent the same or overlapping
mechanisms. For example, the term “selective” or “focused attention” presup-
poses that some higher brain centers already “know” which aspects of the inputs
are worth attending. Without some prior knowledge, the details of an object are
available only after an object is identiﬁed. Gestalt psychologists have already
demonstrated that the whole can amplify or suppress its constituents, implying
some top-down brain mechanisms that bias sensation and perception. Clearly,
there is more to perception than just feedforward hierarchical processing and tem-
poral binding.
A “state” usually refers to a static condition, such as the solid, liquid, and gas
states of water, with fast phase transitions between them. Cognitive states, how-
ever, are notoriously difﬁcult to deﬁne. A brain state can be regarded as a transient
equilibrium condition, which contains all aspects of past history that are useful
for future use. This deﬁnition is related but not identical to the equally difﬁcult
concept of “context,” which refers to a set of facts or circumstances that surround
an event, situation, or object. Similar to “state,” the term “context” implies some
historical precedence; therefore, it invokes some feeling of dynamics. But how
can such idealized variables, such as state and context, be created in the brain and
deﬁned objectively without the need of an “executive network” or homunculus
and inevitable inﬁnite regress? A promising approach is to explore the sources of
response variability. Such an approach attempts to understand the neurophysio-
logical mechanisms that give rise to the perpetual changes of brain dynamics, in-
stead of dismissing the sources of variability as “noise” that emanates from the
brain’s imperfection.
Cycle 5 discussed the 1/f statistic of global brain activity as an idealized crit-
ical state, a perpetual phase transition that endows the brain with the ability to
respond to external perturbations most effectively. However, the 1/f statistic is a
historical product. It is a result of both intracortical connectivity and the inte-
gration of the various oscillations that evolve over time. At any given instant,
different oscillators dominate the brain’s landscape, determined by the memory
of its long-term dynamics. This Cycle discusses how to evaluate the effective-
ness of environmental perturbations against this time-evolving background.
Because this background is not a constant equilibrium state, responses of brain
networks are not expected to be constant, either. Evoked activity may reveal
more about the state of the brain than about the physical attributes of the
stimulus.
Averaging Brain Activity
Tracking the mean ﬁeld changes of neuronal activity is, in principle, a reliable
method for monitoring the spread of activity between anatomically connected

264
RHYTHMS OF THE BRAIN
1. See Hillyard and Kutas (1983) for evoked response exploration of cognitive processes. E. Roy
John’s book Neurometrics (John, 1977; see also John et al., 1998) is perhaps the most comprehensive
source of clinical applications of scalp-evoked responses.
2. Stimulus-locked reordering of phase is common in biological oscillators. See, e.g., Winfree
(1987) and Glass and Mackey (1988).
3. For a good introduction to evoked potentials, see Lopes da Silva (1993) and Vaughan and
Arezzo (1988).
structures. This strategy is based on the well-established method of stimulus-
evoked time averaging of brain potentials or metabolic changes in brain imaging
experiments. The averaging approach has been the foundation of an active and
successful experimental program in cognitive and experimental psychology.1
The tacit assumption behind the averaging procedure is that an external stimulus
produces something from nothing, where “nothing” is equated to a baseline of
no neuronal activity or stochastic ﬁring of neurons. Averaging is essentially a
subtraction method, in which the invariant and variant response components are
separated. The variability of the responses across trials is generally relegated as
unexplained variance or “noise” that needs to be averaged out to reveal the
brain’s true representation of an invariant input. Because the physical features of
the stimulus remain unchanged, the tacit assumption is that the brain’s response
should also remain constant. The trial-to-trial variability is attributed to unco-
rrelated noise in the background neuronal activity. In functional magnetic reso-
nance imaging (fMRI), the responses are often pooled and averaged across
subjects to further reduce the variance, irrespective of the subjects’ personal
histories.
A disturbing aspect of the additive “noise plus signal” concept has been the
observation that the magnitude of spontaneous activity is often as big as the
stimulus-evoked response, and the spectral components of the background and
evoked activity are often quite similar. Viewing it from the time domain, the aver-
aged waveform not only varies as a function of the background or spontaneous
activity but also often incorporates features of the background. For example, no
matter how many times a stimulus is presented in two different states, the average
responses, collected for example during sleep and alert wakefulness, will remain
characteristically different. This should not be so if the background was simply
random noise. However, previous Cycles have already presented ample evidence
that spontaneous activity that characterizes “brain state” is neither stationary nor
random.
Changes of brain state are hard to predict from overt behavior on a
moment–to-moment basis. On the other hand, momentary changes of the ongoing
EEG can be precisely monitored and related to each other in time. Such quantita-
tive comparisons point to an alternative source of evoked responses: phase reset-
ting of ongoing oscillations.2 The two competing models of evoked responses
have different predictions that can be tested experimentally.3 If the evoked re-
sponse is the sum of independent noise and an added signal, then the power of the
signal should increase after the stimulus in the frequency bands corresponding to
the components of the average response. On the other hand, if the stimulus simply

Perceptions and Actions Are Brain-State Dependent
265
resets an ongoing oscillator, no power increase is expected. Furthermore, the av-
erage stimulus-evoked response should contain damping oscillatory components
whose frequency is identical to the background oscillation.
A particular striking example of oscillatory phase reset has been shown by
Scott Makeig, Terry Sejnowski, and colleagues at the University of Califor-
nia–San Diego. They asked their subjects to press a button each time a target
stimulus was presented on the video monitor in a small green square and to ig-
nore the same stimulus presented at other, nontarget locations. They analyzed
the responses to the ignored stimuli (ﬁgure 10.1). The ﬁrst striking observation
was that in the absence of alpha power prior to the stimulus, virtually no re-
sponses were elicited. On the other hand, when the background alpha power was
high, the evoked response amplitude was also high, and the average “evoked re-
sponse” was essentially a ringing oscillation, whose frequency was identical to
the background alpha oscillation. When the individual responses were sorted as
a function of the phase of the ongoing oscillation, the evoked response peaks did
not have a ﬁxed latency with varying amplitude, as would be expected by the
noise-plus-stimulus model. Instead, the latencies varied systematically as a func-
tion of the phase of the ongoing alpha oscillation without much amplitude vari-
ance. In agreement with previous observations, ﬁne-grain analysis of individual
responses clearly showed that the ignored stimuli simply reset the phase of the
Figure 10.1. Phase resetting of ongoing oscillations. Left: Single-trial “evoked re-
sponses” from a posterior central scalp recording site, sorted according to the phase of on-
going alpha oscillation (top). Each horizontal line represents a single trial. The sigmoidal
shape of the phase-sorted poststimulus alpha waves indicates the dependence on the phase
of the prestimulus alpha oscillation. The bottom trace is an average “evoked response,” that
is, the mean of the phase-reset events. Modiﬁed, with permission, from Makeig et al.
(2002). Right: Stimulus-induced phase reset of theta oscillations from ﬁltered, single trials
of subdurally recorded ﬁeld potentials over the neocortex of a patient. Vertical line indi-
cates the onset of visual probe items. The bottom trace is an average of several hundred tri-
als. Note that neither the frequency nor the amplitude of the oscillation was affected by the
stimulus. Modiﬁed, with permission, from Rizzuto et al. (2003).

266
RHYTHMS OF THE BRAIN
ongoing alpha oscillations.4 Several spontaneous oscillators contributed to the
evoked responses, including the visual cortex alpha, mu rhythm, and even
frontal midline theta rhythms, illustrating the complex nature of scalp-recorded
potentials.
The functional importance of the background cortical activity comes from an-
other study, which examined the effect of just perceivable somatosensory stimuli.
The electrical stimulation of the left or right index ﬁnger was adjusted so that only
approximately 50 percent of the events were perceived and reported by the sub-
ject. The physically identical stimuli were detected only when they were preceded
and followed by a sufﬁcient power of alpha and theta activity not only in the so-
matosensory but also in the parietal and frontal cortical areas and when their
presentation coincided with a certain phase of the ongoing oscillation. The
stimulus-induced phase-locking or its absence, reﬂecting perceived and unper-
ceived stimuli, respectively, diverged as early as 30 milliseconds after the electri-
cal stimulation of the skin, suggesting that the perceptual “fate” of the input was
destined by the state of the large-scale cortical network.5 Near-threshold percep-
tion thus requires a special constellation of cortical oscillatory network activity,
and the ongoing spontaneous activity is critical for the enhanced detection of the
signal.
An important practical implication of the phase-reset model is that the compo-
nents of the average evoked response are not representative of single responses.
The individual responses are not simply a noisier version of the average response
with ﬁxed latencies. In fact, the component amplitudes of the average response
reﬂect a combination of the amplitude and latency variability of the single re-
sponses. Therefore, no matter how tempting it is to speculate about the contribu-
tion of excitatory and inhibitory sources of the negative and positive components
of the average, as is evident in numerous publications, no such top-down or
reverse-engineering inferences can be made. The theoretical implication is that
stimulus-correlated events reﬂect more the perturbation of spontaneous oscilla-
tions than de novo events. The external stimulus cannot be considered as the sole
initial condition for the ensuing brain activity.
The behavioral relevance of phase resetting is further supported by the con-
sistent observation that movement initiation and reaction times vary systemati-
cally as a function of phase of the scalp-recorded alpha rhythm.6 Similar
observations were made in relation to the robust hippocampal theta oscillations
4. Makeig et al. (2002, 2004). Such striking “alpha” ringing was ﬁrst reported in the occipital cor-
tex of rats (Klingberg and Pickenhain, 1967). Studying auditory responses, Sayers et al. (1974) raised
the possibility that the average evoked response components reﬂected phase reorganization of sponta-
neous oscillations. Bas¸ar (1980) has repeatedly stressed the importance of oscillatory phase reset in
evoked or induced responses.
5. JM Palva et al. (2005b) observed weaker but signiﬁcant phase reset of faster frequencies, as
well, indicating that the faster oscillations nest on the slower events.
6. In perhaps the earliest experiment on the topic, Bates (1951) used superimposition of scalp EEG
of subjects instructed to make a succession of abrupt grips at a rate of about 10 a minute. In some sub-
jects, the instant of motor performance tended to be related to a particular phase of the EEG alpha

Perceptions and Actions Are Brain-State Dependent
267
rhythm. In a related experiment, Lansing et al. (1959) found that the shortest and longest visuomotor
reaction times in some human subjects tended to fall at points in opposite phases of the alpha cycle.
Recently, the phase of alpha oscillation on the P300 component of evoked potentials (a positive de-
ﬂection that occurs approximately 300 milliseconds after the stimulus) in an auditory oddball was
studied. The alpha phase at stimulus onset in single trials with a large P300 was signiﬁcantly different
from that in single trials with a small or no P300 (Haig and Gordon, 1998). The exact timing of motor
execution, e.g., bar pressing in rats, varies as a function of the hippocampal theta cycle (Buño and Vel-
luti, 1977; Semba and Komisaruk, 1978).
7. Huerta and Lisman (1993, 1995) did the in vitro experiments, which were conﬁrmed in vivo by
Holscher et al. (1997).
8. Buzsáki et al. (1979) described theta reset by click stimuli. These observations were recently
replicated and extended (McCartney et al., 2004). However, in our recent (unpublished) experiments,
a tonal go signal failed to reset theta activity while the rat was running in a wheel. Click stimuli may
activate the vestibular system, as well, which may be critical for theta reset. See also Sinnamon (2005)
for lack of phase reset of hippocampal theta. Phase reset of theta oscillations in humans was analyzed
by Tesche, and Karhu (2000) and that of faster frequencies (7–16 per second) in a working memory
task, by Rizzuto et al. (2003).
in rats. Behaviorally relevant conditioning stimuli, predicting a reward, can ef-
fectively reset hippocampal theta oscillations and produce an average evoked re-
sponse resembling a ringing oscillator. Conversely, when short electrical trains
were delivered at the peak of stimulus-reset theta, long-term potentiation of the
affected intrahippocampal pathways was elicited. The same electrical pulses de-
livered at the time of the trough did not produce potentiation. Because similar
phase dependence of potentiation is also present during spontaneous theta waves
in the intact animal, as well, these ﬁndings add further support to the similar na-
ture of the spontaneous and evoked or phase-reset responses.7 The observations
in rodents are supported by neuromagnetic (MEG) studies in normal human sub-
jects and by subdural EEG recordings in epileptic patients in a working memory
task. MEG responses were recorded during presentation of a set of digits and a
subsequent probe of the retained items. The stimuli reset the theta oscillation,
and the duration of stimulus-related theta increased with memory load, with a
limiting value of approximately 600 milliseconds for ﬁve to seven retained
items.8 Phase resetting of oscillators, in general, is expected by the intrinsic
properties of oscillations, as discussed in Cycle 6. The ﬁring patterns of neurons
in both cortex and hippocampus are grouped to the trough of the local alpha and
theta waves (Cycles 8 and 11); thus, they behave like relaxation oscillators de-
spite the harmonic appearance of the macroscopic ﬁeld potentials. The relax-
ation oscillation nature of the ongoing alpha and theta rhythms can explain their
easy phase resetability.
The relaxation features of cortical oscillators also provide an explanation
for the behavioral advantage of phase reset. Resetting an oscillator can create
an optimal temporal relationship between cell assembly discharges and the in-
formation carried by the stimulus-related activity. If the input randomly arrives
on opposite phases of the cycle without the ability to affect timing of the neu-
ronal assemblies, the stimulus-induced effect may be enhanced or ignored. On

268
RHYTHMS OF THE BRAIN
9. Arieli et al. (1996), Tsodyks et al. (1999), and Kenet et al. (2003). For the relationship between
single neurons and population ﬁeld activity in the neocortex, see Steriade (2001a,b); in the hippocam-
pus, see Buzsáki et al. (1983).
the other hand, if the input can bias the ﬁring patterns of the neurons involved
in the oscillations, the probability of ignorance can be decreased. Phase reset-
ting, therefore, can selectively amplify the impact of afferent signals. This same
reasoning may explain why under most circumstances the average evoked re-
sponse reﬂects a combination of phase resetting of ongoing oscillations and en-
hanced power of activity. A very strong or salient stimulus can affect many more
neurons than do the self-generated spontaneous oscillators. For example, highly
arousing and salient stimuli not only can exploit ongoing brain dynamics but also
can alter the brain state, as well, so that the newly created dynamics are very dif-
ferent from the prestimulus condition. Event-related “desynchronization,” that is,
a prompt shift from alpha and mu synchrony to dominantly gamma activity, is the
typical example of such state change in brain network activity (Cycle 7). A
medium-intensity stimulus may only slightly modify the ongoing oscillators such
that the response is a combination of both enhanced neuronal activity and phase
modiﬁcation of the background oscillator(s). Finally, a weak stimulus may be
able to reset the oscillator without otherwise modifying it. In the last case, the on-
going oscillator may enhance the impact of the weak input through stochastic res-
onance (Cycle 8) and can extract information of weak but well-timed signals
coinciding with the duty cycle of oscillator.
The above discussion on the average evoked ﬁeld responses also holds for in-
duced rhythms, for example, the binding-associated gamma oscillation. Because
most overt and covert behaviors are transient, their brain oscillation correlates are
also short-lived. Although averaging short-time power spectra appears to be the
perfect way to analyze brain–behavior relations (Cycle 9), the trial-to-trial vari-
ability of induced gamma oscillations should also depend on the time-evolved
background context, an important issue addressed in Cycle 12.
Neurons Fire Best in Their Preferred Cortical State
The implication of the hypothesis of the concerted interaction between back-
ground and stimulus-induced activity is that there are speciﬁc network states in
which neurons discharge optimally. In a series of high-proﬁle reports, Amos
Arieli, Amiram Grinvald, and Misha Tsodyks at the Weizmann Institute in Re-
hovot, Israel have systematically explored the relationship between spontaneous
and evoked activity in the visual cortex of anesthetized cats.9 First, they found
that the probability of spike occurrence in single neurons was strongly related
to the activity of the recorded ﬁeld both in the vicinity of the unit and also sev-
eral millimeters apart. This relationship of course is not surprising since it is the
activity of the individual neurons that generates the extracellular ﬁeld. Spiking

Perceptions and Actions Are Brain-State Dependent
269
10. The term “functional map” was coined by Hubel and Wiesel (1963). The tangential layout of
the orientation columns exhibits a unique feature: iso-orientation domains are arranged in a pinwheel-
like fashion around singularities, known as “pinwheel centers” (Braitenberg and Braitenberg, 1979;
Swindale, 1982; Bonhoeffer and Grinvald, 1991). Around a pinwheel center, the preferred orientations
change continuously by ± 180°, corresponding to clockwise and counterclockwise pinwheel centers.
For a reader-friendly review on visual cortical maps, see Grinvald and Hildesheim (2004).
in a single neuron is under the control of an assembly, and assemblies are under
the inﬂuence of local control, and local networks are embedded in larger net-
works. However, their observations went beyond this general knowledge, made
possible by a new tool for imaging membrane potential changes in large neuronal
aggregates with a high spatial resolution. The method is optical imaging of local
ﬁeld potentials by applying a voltage-sensor dye that can measure the membrane
potential changes of neurons and glial cells on the surface of the cortex. It is es-
sentially the same method as electrode measurements of the ﬁeld, except that the
spatial resolution of the optical measurement is substantially better.
Using the surface imaging method, they have already demonstrated that different
stimulus features, for example, the orientation, direction of motion, and spatial fre-
quency of the visual stimuli, evoke unique spatial distributions of cortical surface
activity. These patterns occur because in the visual cortex, neurons with similar re-
sponse properties are clustered together, and visual features change gradually in the
tangential direction along the cortical surface. Such a systematic representation of
visual features is called a “functional map.” Among the various features, orientation
preference is the most prominent in the primary visual cortex.10 Because each func-
tional map results from the aggregate activity of a large neuronal assembly, one can
probe the relationship between the map and an arbitrarily chosen neuron by identi-
fying the constellation of stimuli that best drive the neuron. For example, if a verti-
cal grating is most favored stimulus of the neuron, stimulation can be repeated
numerous times, consistently discharging the cell and, at the same time, providing
an average functional map. The evoked map is a graphic reﬂection of the aggregate
activity of the nonrecorded peers with similar input preference and is called the neu-
ron’s “preferred cortical state.” The interesting part of the experiment, however, was
when the experimenters examined the relationship between spontaneous spike ac-
tivity of the single cell and the spatial distribution of the ﬁeld in the absence of vi-
sual input. Now, the trigger for averaging the ﬁeld was the spontaneous occurrence
of action potentials of the neuron. Remarkably, they found that the map generated
this way was quite similar to the evoked functional map (ﬁgure 10.2).
The similarity of the single-spike–associated and visually evoked map can be
explained by assuming that in the absence of visual stimuli spiking in the single
cell occurred when the trajectory of activity in the network was most similar to the
stimulus-driven case. In other words, the activity of visual cortical neurons in the
absence of visual input is not noise but controlled predictably by the dynamically
changing cortical states. In the absence of external inputs, a local cortical network
wanders through various attractor states, each corresponding to the cooperative ac-
tivity of a unique cell assembly. Examining long epochs of spontaneous cortical
activity revealed that such patterns are far from random. On the contrary, most

270
RHYTHMS OF THE BRAIN
Figure 10.2. Firing patterns of single neurons are constrained by the cortical networks in
which they are embedded. Simultaneous recording of the optical signal on the cortical sur-
face and single-cell recording can be used to compare the relationship between the activity
of single neurons and their network correlates (left). Movement of the visual stimulus in
the preferred direction of a single unit evoked a characteristic spatial pattern on the corti-
cal surface (middle). In the absence of visual stimulation, spontaneous activity time aver-
aged by the occurrence of spikes in the single neuron (right) is similar to the evoked
pattern. Reprinted, with permission, from Tsodyks et al. (1999).
11. The higher incidence of spontaneous states in the vertical and horizontal attractors can also
imply that the functional connectivity, underlying cortical assembly patterns, might be experienced
derived, since horizontal and vertical stimuli are more frequent in our surroundings than are other ori-
entations. The issue of experience versus intrinsic mechanisms is quite complex, as indicated by early
ﬁndings of Blakemore and Van Sluyters (1975) that suggest the visual experience is not necessary for
the emergence of orientation maps.
dynamically switching attractor states corresponded closely to orientation maps
evoked by visual stimuli. Surprisingly, most states corresponded to maps evoked
by either horizontal or vertical gratings.11 This latter ﬁnding might explain why
cats, humans, and other mammals recognize horizontal or vertical stimuli better
than other orientations. Accordingly to this view, stimuli do not simply induce ar-
bitrary ensemble patterns but rather can bring about any of the ﬁnite number of de-
fault attractor states. A match between a spontaneous cortical state and features of
the input should enhance perception, whereas attractor states far from the preferred
state of the input conﬁguration may ignore the input, unless the input can “push”
the network into the preferred state of the stimulus. This latter effect is similar to
the stimulus-induced phase resetting of an oscillator, described above.
In a conceptually related experiment, David Leopold and Nikos Logothetis at
the Max-Planck Institute in Tübingen, Germany, examined the relationship be-
tween the spontaneous power ﬂuctuation of the EEG and the fMRI signal in the
monkey. The EEG power was evaluated separately in the various frequency
bands, and the integrated power variations at the second and tens of seconds
scales were used for comparison. As discussed in Cycle 5, such low-frequency
ﬂuctuations of the EEG include several interacting rhythms (slow 1 to slow 4) and
generate a 1/f power-law function extending to the minute scale. The interesting
novel ﬁnding was that the power variation of the EEG signal often strongly corre-

Perceptions and Actions Are Brain-State Dependent
271
12. Although most physiological measurements were examined in the waking monkey, the EEG
power vs. fMRI comparisons were carried out under anesthesia (Leopold et al., 2003). The sponta-
neous ﬂuctuation of activity and associated fMRI and PET signals prompted Raichle et al. (2001) to
question the validity of the widespread “baseline subtraction” method of imaging. Ideally, the baseline
should be related to a physiologically well-deﬁned state, rather than just an arbitrary epoch before task
manipulations.
13. For a review on the unit discharge variations in slow oscillations in various brain regions, see
Penttonen and Buzsáki (2003).
14. Several reviews discuss the highly complex, parallel, and recurrent processing of visual infor-
mation (Bullier and Nowak, 1995; Schroeder et al., 1998; Lamme and Roelfsema, 2000).
15. Penﬁeld and Jasper (1954).
lated with the oxygen extraction fraction, measured by fMRI. As was the case in
the voltage-sensitive dye mapping experiments in the cat, the locally measured
electrical signal covaried with the fMRI signal from large areas of the cortex, in
some cases with nearly the entire brain.12
A major caveat of the mapping experiments is that the animals were under
deep anesthesia, a state that may have limited relevance to the activity of the drug-
free brain. Furthermore, no unit recordings were made in the fMRI experiments.
Nevertheless, previous studies in both anesthetized and behaving animals have
provided ample evidence for the large-scale changes in neuronal excitability in
multiple brain areas associated with the slow EEG power ﬂuctuations.13 Further-
more, the principle suggested by the experiments under anesthesia should remain
the same in the waking brain: the internally generated attractor states in the cortex
can bias the brain’s ability to extract information from the environment. This
principle also follows from the simultaneous feedforward and feedback opera-
tions of the cortex, implying that the ﬂow of activity even in primary visual and
other sensory areas is inherently multidirectional.14 If so, spontaneous back-
ground activity should exert a major impact on cognitive and motor behavior.
Behavioral Performance Is Affected by Brain State
The attractor dynamics explanation of brain-state–dependent processing can ex-
plain the Canadian neurosurgeon Wilder Penﬁeld’s celebrated observations in the
mid-1950s. He stimulated various sites of the surface of the neocortex of epileptic
patients and asked them to narrate their experience. The stimulations evoked dream-
like sensations, combining the actual situation and assumed recalled memories.
Repeated stimulation of the same cortical site typically produced different experi-
ences, while stimulation of some other sites could evoke the same experience.15 A
possible explanation of the stimulation results is that the stimulation effects were
combined with the ongoing trajectories of neuronal activity. This, of course,
remains a conjecture since no recordings were available in the human experiments;
therefore, the brain-state history dependence hypothesis cannot be veriﬁed. A
straightforward way to examine the effect of brain state on performance is to exam-
ine neuronal activity prior to the occurrence of some cognitive or motor act.

272
RHYTHMS OF THE BRAIN
16. Liang et al. (2002).
17. Fernandez et al. (1999) and Fell et al. (2001). These observations support previous scalp-
recording studies, which showed larger positive components of evoked potentials during verbal en-
coding of subsequently remembered words than of subsequently forgotten ones (Halgren and Smith,
1987; Paller et al., 1987).
I have already discussed how the oscillatory phase of population activity can
affect motor execution and reaction times in humans. Similar observations are
also available in monkeys, where the task sequence was initiated by the monkey
rather than the experimenter. By pressing the bar, a diamond or a line appeared on
the screen, and correct identiﬁcation of the shape was rewarded. The power in the
5–25 hertz band in the prefrontal area and the phase coherence in the same fre-
quency band highly correlated with both the amplitude and latency of the evoked
potentials recorded in the occipital cortex, as well as with motor response time.
These ﬁndings support the idea that the state of the prefrontal cortex can prepare
sensory areas for more efﬁcient processing.16
Similar state-dependent effects have been shown repeatedly for encoding
episodic and semantic memories. Memory encoding refers to the hypothetical pro-
cess that mediate between experience and the formation of a memory trace in the
brain of that event. What we remember and what we forget is not a simple decision
that we can command ourselves. Various electrophysiological parameters, measured
at the time of encoding, have been shown to distinguish between items that are re-
called later versus those that are not recalled. The waveforms of item-evoked poten-
tials in the rhinal cortex and hippocampus in human epileptic subjects at the time of
encoding reliably predicted whether the item was subsequently recalled or not. In-
creased transient gamma synchrony between these areas also predicted successful
recall.17 Similar predictive correlations were observed between scalp-recorded theta
power at the time of encoding and later recall. Recently, large-scale subdural record-
ings in humans have provided extensive support for the hypothesis that variation of
the ongoing brain states is a key factor in determining successful encoding (ﬁgure
10.3). In a series of experiments involving 800 recording sites in a group of patients,
a signiﬁcant number of electrodes showed increases in oscillatory power at the time
of encoding of the subsequently recovered items. Sites associated with increased
theta oscillations (4–8 hertz) were clustered predominantly in the right parietal-
occipital cortices, whereas sites exhibiting increased gamma oscillation power were
quite scattered, indicating that power ﬂuctuation of the rhythm in widespread corti-
cal areas can inﬂuence processing of external inputs (see also Cycle 12).
These ﬁndings in humans echo early observations in rabbits. Rabbits, like
lizards, birds, and some other mammals, have a third eyelid, called a nictitating
membrane. Any stimulus to the eyeball (e.g., a puff of air) will result in an uncon-
ditioned reﬂex contraction of the translucent nictitating membrane. When the puff
of air is consistently preceded by an otherwise neutral signal (e.g., a sound), the an-
imal learns to close the nictitating membrane prior to the occurrence of the uncon-
ditioned air puff after a several dozen pairings. A number of external factors, such
as the temporal gap between the conditional (sound) and unconditional signals and

Perceptions and Actions Are Brain-State Dependent
273
Figure 10.3. Power of gamma frequency oscillation is increased during successful mem-
ory encoding. Gray areas in the time–frequency spectrogram (2–96 hertz) illustrate signif-
icant increases in oscillatory activity during successful versus unsuccessful encoding. Note
increase in gamma-frequency power, centered around 40–80 hertz, for subsequently re-
called words ﬁrst between 500 and 1,000 milliseconds after the word presentation onset (0
milliseconds) and again around 1,500 milliseconds into the encoding epoch. Data were ob-
tained from 91 left-hippocampal electrodes of 15 epileptic patients undergoing invasive
monitoring for seizure localization. A similar pattern of increases in gamma power during
successful encoding is also visible at a number of cortical regions, including left inferior
prefrontal cortex and left temporal lobe. Figure is courtesy of M. Kahana, summarizing the
ﬁndings of Sederberg et al. (2003).
18. Berry and Thompson (1978).
their strength, affect the speed of learning. However, the state of the rabbit’s brain
at the time of the arrival of the sound is also a critical variable. The power of hip-
pocampal theta oscillation positively and robustly correlates with the pace of con-
ditioning. Rabbits with no detectable theta in the recording situation require ﬁve
times more trials to learn the task than do rabbits with the highest power of theta.18
Another set of experiments illustrates further that the animal’s response to the
same physical stimuli depends on the internal brain state. In that experiment, cats
were trained to discriminate between two distinct stimuli, so that stimulus A and
stimulus B required two different behavioral outcomes (e.g., approach right and
left feeder, respectively). After mastering the task, the evoked responses evoked
by the two physically different stimuli were quite distinct. When the cat mistakenly

274
RHYTHMS OF THE BRAIN
19. See Sutton et al. (1965) and Grastyán et al. (1978).
20. Raghavachari et al. (2001) and Sederberg et al. (2003). Increased gamma power is often inter-
preted as a physiological correlate of attention (Tiitinen et al., 1993; Engel et al., 2001; Fries et al.
(2001a, b). An implicit implication of these ﬁndings is that drugs that increase theta and gamma power
should improve encoding of memories.
21. For the role of locus ceruleus neurons in affecting cognitive performance, see Usher et al. (1999).
Neurons in several subcortical nuclei have been described as showing very large ﬁring rate ﬂuctuations
at a slow 1 to slow 4 frequencies (see Penttonen and Buzsáki, 2003). Moruzzi and Magoun (1949) for-
mulated the reticular activating system framework, implicating that bottom-up, nonspeciﬁc mechanisms
are necessary for maintaining forebrain activity in the waking state. Of course, the investigators at that
time were not aware of the numerous neuromodulators that are part of the ascending systems.
22. The exponent of the 1/fα relationship is somewhat different for gamma and theta power ﬂuctua-
tion (Linkenkaer-Hansen et al., 2001; Stam and de Bruin, 2004). In agreement with these ﬁndings, Bas¸ar
(1990) was among the ﬁrst to suggest that EEG activity is best described as quasi-deterministic activity.
went to the left feeder in response to stimulus A, the evoked-potential responses
corresponded to the usual correct responses to stimulus B, congruent with the
cat’s “belief ” about the correctness of the response. Obviously, the “readout from
memory” components of the evoked responses reﬂected the brain’s “interpreta-
tion” of the signals rather than the physical features of the stimuli.19
The above observations in humans and other animals are generally interpreted
within the psychological framework of selective attention, reﬂecting a top-down
executive mechanisms associated with gamma and theta oscillations.20 A logical
consequence of this hypothesis is that, for successful encoding, all we have to do is
to keep our brains in the optimal state and generate sufﬁcient amounts of theta and
gamma oscillations. However, the brain simply does not work this way, at least not
for sustained periods. Somehow the hypothetical executor fails to maintain long-
term control. One way of “instructing” the key parts of the brain to perform better
is to send signals from the body and the environment. We all have experienced the
feeling of irresistible fatigue during a long drive. The most efﬁcient way to prevent
our brain from falling asleep is by stretching the arms, moving the head, blinking
the eyes, deep breaths, fresh air, turning on the radio—in other words, by feeding
the brain with peripheral signals. Left without external stimulation, the brain suc-
cumbs to its internally programmed oscillations, resulting in ﬂuctuating levels of
neural performance. For the same reason, there is no simple way for willfully sus-
taining attention, perception, memory, or motor output for arbitrarily long periods.
An alternative explanation for the ﬂuctuation of our ability to perceive, learn,
and act is that the power of gamma and theta oscillations is not controlled by hy-
pothetical intentionality or an executor but is modulated in time by ongoing
slower rhythms. For example, changes of spontaneous ﬁring rates in the nora-
drenergic locus ceruleus neurons of monkeys are closely correlated with ﬂuctua-
tions in cognitive performance.21 The released neurotransmitter norepinephrine
is known to enhance both theta and gamma oscillations. Another indication of an
internal mechanism responsible for the ﬂuctuation of perceptual and motor readi-
ness state is that, in humans, the power variation of scalp-recorded gamma and
theta activity shows a 1/f power-law scaling behavior.22 In summary, these obser-

Perceptions and Actions Are Brain-State Dependent
275
23. It has long been thought that perceptual switching is a result of some internal brain computa-
tion (Attneave, 1971). However, this view was challenged because of the assumed stochastic proper-
ties of switching (Fox and Herrmann, 1967). Leopold et al. (2002) found that spontaneous alternation
of the percept during continuous exposure to a rotating random-dot sphere showed a characteristic
frequency at 0.3 hertz. Aks and Sprott (2003) found scale-free distribution of perceptual switching
with the Necker cube.
24. An especially elegant demonstration of such context dependence was demonstrated in a free-
recall task using fMRI. Subjects had to memorize a list of items consisting of three distinct categories
(faces, locations, objects). In each scan, a large number of brain structures were scanned and their 
vations lend support to the idea that brain-state ﬂuctuations are neither random
nor simply controlled by “will-guided” top-down mechanisms.
A sensitive method for examining the inﬂuence of self-organized brain patterns
on cognitive performance is to present ambiguous ﬁgures to subjects. In this case,
perceptual shifts are expected to be driven by the variation of brain dynamics in the
absence of any changes of environmental inputs. One such well-studied illusionary
ﬁgure is the Necker tube (see ﬁgure 8.7). When confronted with a reversible ﬁgure
such as this, viewers experience a spontaneously changing percept, alternatively see-
ing either the bottom or the top of the cube. Since the input remains constant, it is our
brain that does the switching by some rules. Switching occurrences can be tracked
by asking the subject to press a key each time they perceive a change in the orienta-
tion of the cube. The switching intervals often do not reﬂect a characteristic time
scale, which led several investigators to believe that the pattern of alternation was
stochastic. However, quantitative analysis of the time series of orientation reversals
revealed a 1/f function, suggesting a memory effect. These ﬁndings echo the scale-
free distribution of errors of the syncopation experiments discussed in Cycle 6.
The role of brain-state changes in perceptual switching is further supported by
the observation that spontaneous alternations occur only during continuous expo-
sure of ambiguous ﬁgures. The perceptual alternation can be slowed or even pre-
vented by periodically removing the ﬁgure from view, for example, by frequent
blinking. The brief exposures prevent switching during the stimulus presentation
and set the context for subsequent perceptions. Manipulations of binocular dis-
parity also affect perceptual stability. High-depth conditions yield less frequent
perceptual reversals than do low-depth conditions, supporting the view that the
more ambiguous the ﬁgure is, the stronger the role of spontaneous brain activity.23
Overall, the observations on ambiguous or puzzle ﬁgures illustrate that the
brain is compelled to interpret and that the interpretation is a combined effect of
the physical nature of the input and the temporally evolving spontaneous brain
state. Because of the additive contribution of the brain, the behavior of a neuron
or local network does not faithfully reﬂect the physical features of the input. If we
want to determine the ﬁring pattern of a cortical neuron, we would need to know
the discharge patterns of all connected cells in the immediate vicinity, and prefer-
ably at more distant sites, as well. To improve the prediction, we would need to
know not only the current state but also the activity that occurred in the prior 100
milliseconds or seconds ago. In short, information about the recent history of all
inputs is needed to improve prediction.24 This historical dependence is what

276
RHYTHMS OF THE BRAIN
BOLD constellations during the study phase were classiﬁed according to the categories (see Cycle 4
for a description of the technique). During free recall in the absence of cues, the three category states
shifted regularly with a 5- to 10-second periodicity, determining the categories of items to be recalled,
and the magnitude of the match predicted what kinds of information the subjects retrieved (Polyn et
al., 2006).
25. Although the temporal aspect of state implies context, I provide a more precise neurophysio-
logical deﬁnition of context in Cycle 12.
makes the brain a dynamic system. The structural basis of dynamic behavior may
be the multiple parallel loops, which provide feedback at extended temporal
scales due to the progressively longer conduction and synaptic delays in longer
loops. These feedback loops acting at multiple temporal and spatial scales em-
body the context dependence of input perturbations.25 In this framework, context
is deﬁned as a set of conditions in which an input is uniquely coupled to an out-
put. It is a sorting mechanism that directs the neuronal representation of the input
to the most appropriate circuits on the basis of the input’s historical association
with the brain’s previous responses.
To fully appreciate the consequences of such multilevel interactions, we must
monitor changes in multiple related systems (Cycle 12). However, before we can
address the complex issues of systems interactions, ﬁrst we need to explore how
long-term memories are formed, because it is the experience of each individual
that fundamentally determines how the brain reacts in various situations.
Brieﬂy . . .
The variation of our motor and cognitive abilities is present at multiple time
scales, expanding from periods of tens of milliseconds to hours. The brain-state
variability to a large extent is internally coordinated even in the waking brain.
This internal coordination is not simply “correlated noise” that the brain should
overcome and the experimenter must eliminate to reveal the true attitude of the
brain to an environmental input. Instead, the time-evolving brain states are an
important source of mental operations. The recorded signals may contain more
information about the observer’s brain than about the signal because the mecha-
nism of perception is an “interpretation” by the neuronal circuits rather than a
summation or “binding” of invariant physical features. Precisely what makes the
brain a dynamic system is that its current state is, in part, dependent on a prior
one. In order to predict the state of a neuronal network, one needs to have access
to its recent history. The 1/f brain dynamic, as revealed by various global physi-
ological measurements, is often reﬂected by a similar 1/f scale freedom of overt
behaviors, such as various mental operations and motor outputs. From this per-
spective, the neuronal “signal” in response to a given environmental perturbation
of the brain state is not an initial condition but, rather, a modiﬁcation of a perpet-
ually evolving network pattern in the brain’s landscape.

I’ve never tried to block out the memories of the past, even though some are
painful. . . . Everything you live through helps to make you the person you
are now.
—Sophia Loren
277
Cycle 11
Oscillations in the “Other Cortex”:
Navigation in Real and Memory Space
Despite its beauty and complex order, the relatively uniformly organized modular
neocortex has its limitations. The functions that its mostly locally organized
structure supports are tuned mainly to detect orderly relationships in the environ-
ment. The perceptions of natural scenes, speech, music, and body image as well
as our occasional illusions can be attributed largely to the unique organization of
the isocortex. Brains with these features of organization are useful as long as they
are embedded in an unchanging environment. However, we live in an ever-
changing world, and numerous events relevant to our survival and happiness oc-
cur independent of us and often in an idiosyncratic manner. It is impossible to
create or even imagine a machine that would be able to detect and store all of the
random events and relationships around us. Most of these random events are ir-
relevant and do not have any personal signiﬁcance. But some do. Our names, the
birthdates of loved ones, and other important family events are our unique expe-
riences, which do not simply unfold by some external rules. Forming and storing
of individual experiences create a knowledge base, a unique brain-based context
that modiﬁes the way the neocortex processes future sensory experiences and
contingencies and affects our actions. The accumulation and persistence of past
experiences of the individual, collectively called memory, are responsible for cre-
ating individual identity.
The emergence of individuality and personal identity are therefore strongly

278
RHYTHMS OF THE BRAIN
1. This is not to deny the importance of species-speciﬁc biases even in lately developed
species, e.g., the inborn fear of snakes in primates. Nevertheless, in animals with larger and more
complex brains, perception and action become progressively modiﬁed by individually acquired as-
sociations.
2. See Cycle 8, footnote 12, for the major memory categories. Many excellent and easily readable
works are available on the taxonomy of memory and about the relationship between the different
memory categories and brain structures. Here is my short-list: Tulving (1972, 2002), Squire (1992),
Eichenbaum (2002), and Nadel and Moscovitch (1997). For a very readable history of twentieth-
century memory research, see Milner et al. (1998).
linked to mechanisms that enable an animal to recollect the past and modify its
future behavior on the basis of these recollections. There is nothing in the physi-
cal world that would tell us whether a face is pleasant or repellent to us. The same
face may be judged as beautiful or ugly on the basis of the cumulative past expe-
riences of different observers.1 What are these experiences, and where are they
stored?
Experiences stored in the brain are usually divided into two major categories:
implicit and explicit. For a psychologist, the term “explicit” or “declarative”
means that such experiences have “conscious” recollections and can be declared
verbally. They include lifetime episodes unique to an individual, such as your ﬁrst
accepted paper or getting your ﬁrst grant, or learning arbitrary facts related to the
world we live in, such as the distinction between relaxation and harmonic oscilla-
tors. These latter factual or semantic memories lack a unique personal link. In
contrast, the implicit experience of learning how to walk comfortably in high-
heeled shoes or ignoring the annoying sound of the air conditioner in your ofﬁce
does not require that we be aware of the process.2
Forming and storing arbitrary episodes require a suitable large storage space
with randomly organized connections. By now, we have learned that the six-layer
neocortex with its regular modular architectonics and that mostly local wiring is
far from ideal for such a task. A large part of the modularly organized neocortex
is tuned to extract statistical regularities in the world conveyed by our sensors. But
there is another piece of cortex that we have hardly mentioned so far: the “other
cortex,” or, in our Hellenistic scientiﬁc jargon, the allocortex (also called het-
erotypical cortex), with its variable numbers of layers, unique cell types, and a
special wiring plan (ﬁgure 11.1). This piece of cortex, as I describe below, con-
tains a large connection space that is ideally built for the construction of episodes
and event sequences from arbitrary relations by providing a spatiotemporal con-
text for the information to be deposited.
The speculation about memory space is supported by clinical ﬁndings in hu-
mans: damage to the hippocampus–entorhinal cortex system results in pro-
found memory problems. In contrast, single-cell research in animals has
provided a different perspective, namely, that the hippocampus and associated
structures serve spatial navigation. Both of these research lines have coexisted
with the extensive work on hippocampal oscillations, but the three research di-
rections have converged only recently. A major goal of this Cycle is to discuss
and illustrate how oscillations can link these disparate directions and provide a

Figure 11.1. Excitatory circuits of the hippocampal formation. Top: Santiago Ramón y Ca-
jal’s drawing of the major cell types and their axonal projections in the rodent brain. (Re-
produced, with permission from Ramón y Cajal S (1901). The original is ﬁgure 41 in
Ramón y Cajal (1901) and ﬁgure 167 in DeFelipe and Jones (1988). Perforant path ﬁbers
from layers 2 and 3 of the entorhinal cortex (not shown) project to the dendrites of dentate
granule cells/CA3 pyramidal cells and CA1 pyramidal cells, respectively. The arrow shows
one ﬁber. The parallel running ﬁbers cross the dendrites of granule cells and pyramidal
cells. Granule cells project to CA3 pyramidal cells, whose major axon collaterals, also
called Schaffer collaterals, innervate CA1 pyramidal cells. Ramón y Cajal believed that the
output axons of CA1 pyramidal cells left the hippocampus in the ﬁmbria and traveled to
subcortical destinations (see small directional arrows). In reality, the majority of CA1 axons
target neurons in the subiculum (sub) and the deep-layer cells of the entorhinal cortex (large
arrow). Bottom: Section of the human hippocampus. In contrast to the rodent hippocampus,
which extends above the thalamus, the hippocampus in primates assumes a ventral location
in the temporal lobe. This is why the position of the layers is reversed compared with the top
drawing. o, stratum oriens; p, stratum pyramidale; r, stratum radiatum; lm, stratum
lacunosum-moleculare; m, dentate stratum moleculare; gc, granule cell layer. DG, dentate
gyrus; SUB, subiculum. Courtesy of Tamás Freund and Zsóﬁa Maglóczky.

280
RHYTHMS OF THE BRAIN
3. Focusing on a single topic (i.e., episodic memory) comes at the expense of ignoring numerous
other important functions of the allocortex, e.g., emotions, olfaction, and movement control.
4. McLean has published numerous papers on the triune brain since the 1950s, summarized in a
comprehensive volume (MacLean, 1990). MacLean did not speak about parallel loops. Instead, he en-
visioned the three layers as strict hierarchies.
5. Besides the limbic system, the allocortex also contains the olfactory cortex, a sensory area with-
out thalamic connections. The striatum, medial nuclei of the amygdala, and nucleus accumbens are
sometimes also labeled as allocortical structures, although they are not considered parts of the limbic
system (Graybiel et al., 1994). The olfactory cortex, lateral amygdala, and hippocampal system are
collectively referred to as the medial temporal lobe. De Curtis and Paré (2004) provide a concise sum-
mary of the structure and functions of rhinal cortices.
6. This tacit assumption may not hold. Starting with Rose (1937), several evolutionary biologists
have argued that the mesocortex and especially its key structure, the hippocampus, made its ﬁrst 
coherent picture for the functions of the hippocampal–entorhinal system.3 To
achieve this goal, we need to cover several lines of seemingly independent
investigations before we can combine them into a comprehensive, oscillation-
based framework.
The Allocortex Is Sandwiched between the Oldest and
the Most Recent Brain Parts
The safest way to start speculating about the functions of a structure is to inspect
its anatomical organization carefully. The dictum “structure deﬁnes function”
never fails, although the architecture in itself is hardly ever sufﬁcient to provide all
the necessary clues. Nevertheless, knowledge about the nature of neuronal connec-
tions provides important constraints and reduces the large degree of freedom of
speculation to manageable levels. As discussed in Cycle 2, the brain is essentially
a multitude of superimposed and ever-growing loops between the input from the
environment and the brain’s outputs, the most important of which is movement.
The number of superimposed loops in the complex mammalian brain is impossible
determine, so perhaps it is useful to reduce the numbers by some rational group-
ing. Paul McLean at the National Institutes of Health suggested that three gross
levels of brain organization are about right.4 His bottom tier is an interconnected
series of structures that are easily recognizable also in premammals; therefore, he
uses the term “reptilian brain” or, to sound more scientiﬁc, the archipallium (Latin
for ancient brain), as a collective name for structures that include the olfactory
bulb, brainstem, mesencephalon, cerebellum, and the basal ganglia. On the top of
the organization lies the latest and superior mammalian invention, the neopallium,
which is more or less equivalent to the thalamoneocortical system. Sandwiched be-
tween the “primitive” reptilian brain and the rational new brain lies an intermedi-
ate tier, the mesocortex or paleopallium, comprising the structures of the limbic
system.5 According to McLean, these three tiers emerged chronologically during
the course of the evolution of animal species from lizards up to Homo sapiens, and
the sequential order is also recapitulated during ontogenenesis.6

Navigation in Real and Memory Space
281
appearance in mammals, virtually simultaneously with the emergence of the isocortex. On the other
hand, birds also have a structure analogous to the hippocampus, with potentially similar functions as
in mammals but no granule cells (e.g., Doupe, 1994).
7. In Latin, limbus means a surrounding ring. The French neurologist Paul Broca introduced the
term la grand lobe limbique in 1878. Papez (1937) went further by postulating that emotions rever-
berate in the ring, often referred to as the Papez circle.
8. The pivotal role of some amygdaloid nuclei in emotions led to the still oft-used term “emotional
brain.” The best-written works on this subject are Damasio (1995) and LeDoux (1996). Endre
Grastyán attributed ludic (playful) behaviors, a mammalian specialty, to the hippocampo-amygdaloid
system and explained their regression during ontogenetic development by the increasing dominance
of the rational neocortex (personal communication).
9. Ramón y Cajal (1909, 1911).
The main border between the allocortex (paleopallium) and the overlying neo-
cortex is the rhinal (i.e., nose-related) ﬁssure, a large canyon easily recognizable
in most mammalian brains. A common feature of allocortical structures is the vi-
olation of the strict six-layer modular arrangement of the isocortex. As is the case
for the neocortex, sensory information cannot directly penetrate the structures of
the allocortex. Olfactory information arrives most directly by way of a thalamus-
like relay station, the olfactory bulb, whereas all other sensory information
reaches the allocortex through tortuous paths by way of the neocortex.
Because of the relatively direct access of olfactory information to some allo-
cortical structures, early investigators used the term “rhinencephalon,” implying
that the dominant function of most allocortical structures was processing olfac-
tory information. The later-introduced term “limbic” system derives from the
ringlike arrangement of allocortical structures, including the amygdala, hip-
pocampus, entorhinal cortex, and hypothalamus, that provide a relatively distinct
border separating the brainstem from the new cortex.7 Because many psycholog-
ical constructs, such as emotions and feelings, boredom and passion, love and
hate, attraction and disgust, joy and sadness, are thought to be mammalian in-
ventions, and neither the reptilian brain nor the rational neocortex seemed suit-
able sites for such functions, these functions were delegated to the limbic
system.8
These assumptions made perfect sense in light of the known anatomy of the
limbic system 40 or so years ago. According to the anatomical knowledge at that
time, the main input to the limbic system is the neocortex. Virtually all neocorti-
cal regions project to the perirhinal and entorhinal cortices, and the neocortical
information is funneled to the hippocampus by these structures. Thus, according
to the brain hierarchy formula, the hippocampus is the ultimate association struc-
ture, receiving the highest order neuronal information (see ﬁgure 2.6). So the key
question is: what happens to the information funneled to the hippocampus? Ac-
cording to the main anatomical authority of the times, Santiago Ramón y Cajal,
the hippocampus-processed information is sent down to the reptilian brain (ﬁgure
11.1).9 In support of this neopallium–paleopallium–archipallium funneling traf-
ﬁc, anatomical and lesion studies also indicated that the hippocampus and amyg-
dala are critical in the control of hypothalamic endocrine and autonomic function.

282
RHYTHMS OF THE BRAIN
10. See the pioneering studies by Gorski (1974) and for recent reviews: Sapolsky (1998) and
McEwen and Lasley (2002).
11. Scoville and Milner (1957). For the debate about memory and other functions of the limbic
system, see Isaacson (1994) and Vanderwolf (2003). Swanson and Cowan (1977) were the ﬁrst
anatomists to emphasize that the main hippocampofugal path is projected to back to the entorhinal
cortex.
Putting all of the available pieces of the puzzle together, the following picture
emerged: the results of the rational neocortical computation are transferred to the
allocortex; after proper evaluation of the emotional content by limbic structures,
the hippocampal and amygdalar outputs instruct the skeletal and autonomic effec-
tors to ﬁght or ﬂight, increase or decrease heart rate and blood pressure, and to
mobilize stress and other hormones.10
But even giants can make (small) mistakes. A few decades after Ramón y Cajal
outlined the direction of the main hippocampal output, it was discovered that the
subcortical projection of the hippocampus is not the most signiﬁcant output pro-
jection. Instead, the principal hippocampal efferents return to the subicular com-
plex and to the deep layers of the entorhinal cortex, from where the information is
routed back to the neocortex. Thus, the principal direction of neocortex–paleocortex
trafﬁc is not downward to the archipallium but upward to the neocortex. The orga-
nization is not a simple feedforward hierarchy but a recurrent loop. Of course,
ﬁnding a massive return path from the hippocampus to the entorhinal cortex does
not invalidate the importance of the hippocampal and subicular output to down-
stream projections (fornix) and the associated physiological functions associated
with this output.
Ignoring the anatomical knowledge of the times, the psychologist Brenda Mil-
ner and the neurosurgeon William Scoville concluded in the late 1950s that the
hippocampus was related to memory functions. Studying the now famous patient
H.M. and several related cases with bilateral surgical removal of the hippocampus
and some surrounding structures, they consistently observed that acquisition of
new episodic-declarative knowledge was no longer possible in these people. Nev-
ertheless, these patients retained and effectively used most of their experiences
prior to the surgery.11
Memories are useful only if they can be retrieved. Obviously, if the sole out-
puts of the hippocampus were the few efferent ﬁbers projecting downstream into
the fornix bundle, it is hard to see how the neocortex could get quickly informed
about previous experiences, that is, retrieve memories. The new anatomical pic-
ture that has emerged provided a different insight. The main outputs of the hip-
pocampal formation and the amygdala are the same as their inputs: the
neocortex. These structures can therefore be viewed as “appendages” of the
large neocortical mantle with bidirectional trafﬁc. From this gross anatomical
vantage point, we can ask a critical question: what functions can a structure per-
form whose main outputs are the same as its inputs? Not many. The only thing it
can do reasonably well is modify the inputs. In light of the clinical observations
of Milner and Scoville, this is good news, however. The paleocortical output may

Navigation in Real and Memory Space
283
12. The rest of the discussion focuses on the hippocampal system. Another key limbic structure,
the amygdala, is neglected, mainly because excellent books have been written on the amygdala and its
role in emotions (Damasio, 1995; LeDoux, 1996). For a review of the role of oscillations in amygdala
function, see Paré et al. (2002). Since I have very little to add to their views, I do not repeat the dis-
cussion here. For the anatomical classiﬁcation and connections of the various nuclei of the amyg-
daloid complex, read the comprehensive reviews by Pitkanen et al. (2000) and Swanson (2000). For a
detailed discussion of the entorhinal–perirhinal structures, see Suzuki and Amaral (2004), and for a
general overview of the paleocortex, I suggest Pigache (1970).
13. My anatomical discussion here is strongly biased toward the hippocampus, because this is the
structure that, to date, provides the best understanding of the functional roles of oscillations.
14. The term “layer” is often used differently by anatomists and computational modelers. For the
latter, the layer refers to a group of parallel computational units. In anatomy, the Latin stratum refers
to vertically separable organization, e.g., dendritic and somatic layers, or distinct inputs from various
sources.
15. My hunch about the critical role of granule cells was based on the hypothesis that the major
role of granule cells is to alter the synaptic weights in the CA3 recurrent matrix during learning
(Buzsáki, 1989). Granule cells are special in other contexts as well. They co-release both glutamate
and GABA (Sloviter et al., 1996). Most granule cells in rats and humans appear after birth and con-
tinue to divide throughout life (Gage, 2002; Gage et al., 1998), and they cannot survive in the absence
of circulating steroids (Sloviter et al., 1989).
assist in modifying the neocortical circuits. The combination of the knowledge
gleaned from the human surgical cases and the new anatomical information ob-
tained in animals initiated an entirely different direction for limbic system re-
search: memory.12
The Hippocampus Is a Giant Cortical Module
Allocortical structures have a different anatomical organization than does the iso-
cortex. In most allocortical areas, layer 4 is absent, reﬂecting the lack of a major
thalamic input. In other cases, such as the lateral amygdala, the regular cytoarchi-
tectonics is missing. But what makes the paleocortex qualitatively so different
from the neocortex is the hippocampal formation.13 Like the isocortex, most pale-
ocortical structures are constructed from pyramidal cells and GABAergic in-
terneurons, although their layer and wiring organizations vary substantially from
the regular isocortical modules.14 The hippocampal dentate gyrus has a radically
different cell type, called granule cells, with fundamentally different features
from pyramidal neurons. Because of their qualitatively different nature, there is
reason to believe that the unusual properties of granule cells hold the key to a
comprehensive understanding of hippocampal function.15 Paradoxically, it is the
dentate gyrus component of the hippocampus whose functions we understand the
least.
The hippocampus is a one-layer cortex, according to anatomical textbooks, but
that depends on how one looks at it. Indeed, if one unfolds the tooth-shaped den-
tate gyrus and the C-shaped hippocampus proper, also called cornu ammonis (CA
or Ammon’s horn), a large sheet with a single layer of granule cells and pyramidal

284
RHYTHMS OF THE BRAIN
Figure 11.2 The entire hippocampus can be conceived as a single giant cortical column.
The bottom-layer granule cells (gc) disperse (“orthogonalize”) input information for the
second-layer CA3b/c neuron, which project mainly to CA1 but also to the largely recurrent
CA3a/b population. Mossy cells in the hilus (not shown), which provide excitatory feed-
back to large numbers of granule cells, can also be conceived as a separate layer.
16. The term “hippocampus,” or seahorse, was introduced by the Italian anatomist Giulio Cesare
Aranzi because of the macroscopic similarity in appearance of the human hippocampus and this sea
creature, with the uncus as the head and the thin curved posterior part as its tail.
17. The thick main conduit axons, curving from the CA3 to CA1 stratum radiatum, are called
Schaffer collaterals after the Hungarian anatomist-neurologist Károly (Karl) Schaffer (1892).
18. This CA3–granule cell back-projection is very sparse in the dorsal hippocampus but quite sig-
niﬁcant in the ventral third in the rat (Li et al., 1994), a hippocampal part analogous to the uncus in pri-
mates. Although the CA3 neurons have extensive axonal arbors in all parts of the structure, there are
several important anatomical, physiological, and pathological differences between the dorsal and ven-
tral (uncal) parts of the hippocampus. Some of the striking functional differences between the dorsal
and ventral (tail body vs. uncus in primates) parts of the hippocampus may derive from their inputs,
rather than from differences in internal connectivity. Despite these differences, the concept of large
synaptic space in the hippocampus prevails.
cells is obtained.16 But if one looks at connectivity and disregards size, the resem-
blance of the hippocampus to a neocortical module is hard to miss (ﬁgure 11.2).
One important entry point to the hippocampus is the granule cells of the dentate
gyrus. The axon terminals of granule cells excite about half of the hippocampal
pyramidal cells; these reside in the CA3 region. The CA3 region is actually two
layers with a continuous transition. Pyramidal cells in the so-called hilar or portal
area engulfed by the granule cells send their main collaterals to the CA1 pyrami-
dal cells.17 The remaining CA3 and CA2 neurons compose a strongly recursive
network. Instead of transferring the information quickly to the output CA1 neu-
rons, they have very extensive recurrent collaterals, contacting their peers locally
and distantly, including those in the hilar region, in addition to contacting CA1
pyramidal cells and even reaching back to the granule cells.18 Viewed from this
perspective, this organization is somewhat analogous to the ﬂow of information in
the neocortical layer 4 (think granule cells), layer 3 (hilar CA3), layer 2 (CA1),
and layer 5 (recursive CA3 neurons) excitatory feedforward structure. The major
difference between the neocortical and hippocampal organizations lies mainly in
the manner in which the two systems grew during the course of the mammalian

Navigation in Real and Memory Space
285
evolution. The small-world-like organization allows neocortical growth virtually
inﬁnitely, constrained only by the axon conduction velocities and the long-range
“shortcuts” necessary to keep the synaptic path lengths in the neocortex short.
Evolution of the hippocampal formation follows a different rule. The hippocam-
pus grows as a single large multilayer space.19 The evolutionary advantage of
such an architectural solution is the creation of a giant random connection space,
a requisite for combining arbitrary information.20 The main limitation on the
structural growth of the hippocampus is the slow conduction velocities of axons.
Indeed, the numbers of neurons in the hippocampus increased only 10- to 20-fold
from rat to human, whereas the neocortex expanded by several orders of magni-
tude during the mammalian evolution. Apart from size and cell numbers, the
gross appearance and the microscopic connectivity of the hippocampus in various
species are strikingly similar.
What is discussed in Cycle 2 about the brain’s loops in general is especially
true at the level of the hippocampus. Getting from one neuron to anywhere else is
possible by multiple paths, through just one synapse or using as many as 10 steps
(ﬁgure 11.3). Integration of the return path from the short and long loops depends
on the available time windows. Such divergent and convergent reverberating cir-
cuits can serve various functions, including error correction, pattern completion,
ampliﬁcation, and temporary storage.
The Hippocampus Is the Neocortex’s Librarian
How big is the available “random space” in the hippocampus? We set out to study
this important question by labeling single neurons in the intact rat brain and recon-
structing the entirety of their axon collaterals and synaptic contacts in three-
dimensional space. Here are some useful numbers from the rat. The axon length of
a single CA3 pyramidal cell varies from 150 to 400 millimeters, establishing be-
tween 25,000 and 50,000 synapses within the same hippocampus and about half as
many in the contralateral hippocampus. Because there are approximately 200,000
CA3 pyramidal neurons in each hemisphere, this translates to a total of 40 kilome-
ters of axon collaterals and an estimated 5–10 billion synaptic contacts in each
hemisphere (ﬁgure 11.4).21 This incredible wiring matrix is squeezed into the rat
hippocampal volume, which is approximately the size of a small bean. Importantly,
19. Because the hippocampus is among the best-characterized networks in terms of anatomy and
physiology, understanding its operations has considerable heuristic signiﬁcance in understanding sys-
tems operation in general. It has to be kept in mind, though, that studying the hippocampus in isolation
is equivalent to studying an isolated neocortical module.
20. Random access memory (RAM) in the digital computers is a useful metaphor to conceptualize
the recursive system of CA3 neurons (e.g., Marr, 1971; McNaughton and Morris, 1987; Kanerva,
1988), but there several differences, as pointed out below.
21. Tamamaki et al. (1988) and Li et al. (1994). See also Ishizuka et al. (1990), Amaral (1993), and
Amaral and Witter (1989).

286
RHYTHMS OF THE BRAIN
Figure 11.3. Multiple excitatory glutamatergic loops in the hippocampal formation and
associated structures. The long loop connecting the layer 2 entorhinal cortex (EC), granule
cells (gc), CA3, CA1, and subiculum (S) back to the layer 5 entorhinal cortex is supple-
mented by multiple shortcuts and superimposed loops. The shortest loop between the en-
torhinal cortex and hippocampus is the path from the layer 3 entorhinal cortex to CA1 and
back to the layer 5 entorhinal cortex. Excitatory trafﬁc in the multiple loops is controlled
by a large family of interneurons (see Cycle 2), whose connections are not looplike. mc,
mossy cells of the hilus; A, amygdala; RE, nucleus reuniens of thalamus; pFC prefrontal,
anterior cingulate cortex.
22. Connection probability has never been measured quantitatively but is inferred mostly from si-
multaneous recording from neuron pairs. Approximately 1 in 20–50 pairs shows physiologically
demonstrated monosynaptic connections (Miles and Wong, 1986).
the distribution is spatially widespread, such that the axon arbor of a single cell
covers as much as two-thirds of the longitudinal axis of the hippocampus. Unlike
neocortical neurons, hippocampal pyramidal cells do not necessarily prefer their
neighbors, and a given CA3 neuron may contact its neighbors with approximately
the same probability as some distant peers. The distribution of the contacts in the
recursive CA3–CA3 and the feedforward CA3–CA1 projections is reminiscent of
a random graph, with 2–5 percent synaptic connection probability.22 No compara-
ble data are available from other species, but based on the size and numbers of
neurons and the volume of the human hippocampus, it is expected that the connec-
tion probability of hippocampal cells in our brain is similar to that in the rat. Be-
cause extrahippocampal afferents, including the most prominent excitatory
entorhinal cortical input, represent less than 10 percent of all synapses, the

Figure 11.4. The recurrent and CA1-bound collaterals of the CA3 pyramidal cells provide
a large three-dimensional random synaptic space in the hippocampus. Top: Collaterals of a
single CA3b pyramidal neuron ﬁlled in vivo. Arrow points to the cell body. Bottom: Higher
resolution of the axon collateral distribution. Nearby and distant neurons may be contacted
with a similar degree of probability by the collaterals. This single cell had more than
60,000 estimated synaptic boutons. L. Wittner and G. Buzsáki (unpublished observations).
287

288
RHYTHMS OF THE BRAIN
23. When I ﬁrst read Luria’s “little book” (1987; published in Russian in 1968), I thought it was a
ﬁction. In reality, it is about Solomon Shereshevskii’s boundless memory capacity, a mnemonist who
could remember chains of numbers up to 70 digits forward or backward and could not forget them. For
most of us, storing and retrieving numbers of arbitrary compilation accurately is difﬁcult because there
is nothing unique about sequences of numbers. However, Shereshevskii had synesthetic memory, which
can be conceived of as a multidimensional hologram. Instead of remembering meaningless digits, he
chunked them and created episodes by blending all of his senses so that the number sequences acquired
sound, pictorial, smell, and even taste features. The multimodality episodes became unique personal ex-
periences that could be recreated from small fragments. This came not without costs, though, to the
owner of this exceptional quality. Although Shereshevskii was a shy person, he was aware of his excep-
tional ability and hoped to discover something extraordinary. It did not happen. He had difﬁculty in rec-
ognizing people and reading their emotions from their facial expressions, a skill most of us perform
automatically. His difﬁculty in forming explicit semantic memories may perhaps explain his extraordi-
nary episodic memory. Unfortunately, no histological information is available about his brain.
24. The origin of these views can be traced back to Hirsh (1974) and Teyler and DiScenna (1985),
who considered the hippocampus to be a context-indexing device. Episodic memory in its widest def-
inition reﬂects a unique spatiotemporal trajectory of events. An everyday example of episodic memory
is a free recall of particular events. A list of items presented together in a particular temporal context
(e.g., a list of arbitrary words or objects) is another example. Damage to the medial temporal cortex,
involving the hippocampal–entorhinal area, severely compromises recollection of episodes (Vargha-
Khadem et al., 1997; Squire and Zola, 1998; Tulving, 2002).
hippocampus can be viewed as a single, supersized cortical module with largely
random connections.
Ten billion synapses is not an astronomical ﬁgure, especially if one compares it to
the number of connections in the human neocortex. However, the hippocampus, be-
ing a single giant cortical module, is a vast searchable multidimensional space. To
understand the signiﬁcance of this organization, think of the neocortex as a huge li-
brary and the hippocampus as its librarian. An ideal library not only contains most
books ever written but also allows speedy and accurate access to any volume. Unfor-
tunately, there is no ideal library, man-made or biological. The more books are accu-
mulated in the library, the higher the overlap among authors’ names, titles, and
content. Searching for an item in such a colossal library can become a nightmare.
Finding the book Sparse Distributed Memory by Pentti Kanerva is straightforward
because of the explicit key words one can supply. But try, for example, to ﬁnd the
book that you can only remember begins with an episode about some Eastern Euro-
pean journalist who never took any notes at the editorial meetings because he re-
membered all facts including complex projection numbers. With this little
fragmentary information, your search might be hopeless in a real library. Even after
typing in multiple combinations of numerous key words that you may remember, the
Internet search engine Google may give you a million choices, out of which perhaps
only one is relevant. However, if you ask your educated librarian, chances are that
she would tell you right away that the book you are desperately looking for is Alek-
sandr Romanovich Luria’s little book about a vast memory.23 The reason for such a
huge difference in search efﬁciency is that your librarian has a hippocampus,
whereas Google does not. Thanks to the hippocampus, humans are very efﬁcient at
storing and remembering episodes and recovering them from fragments.24 How do
we do that?

Navigation in Real and Memory Space
289
25. In autoassociative attractor networks, the maximum number of stored memories is limited by
the decimal order of the number of converging synapses on a single cell from other cells. If memories
are stored by static anatomical connections only, the upper limit of the number of memories that can
be stored in the rat hippocampus would be tens of thousands, and the storage capacity may not in-
crease much more as we go from rat to human (Amit, 1989; Rolls and Treves, 1997; for a synopsis, see
Rolls, 1996). These ideas have their roots in early modeling attempts (Marr, 1971; Kohonen, 1984;
Kaverna, 1988; Maas and Bishop, 1999). For a comprehensive description of autoassociative net-
works, see McLeod et al. (1998) and Kanerva (1988).
26. Strictly speaking, this is not quite true. The axon tree of a single CA3 pyramidal cell covers up
to two-thirds of the hippocampal volume. Nevertheless, each neuron has some spatial target preference,
and there are differences between axon arbors of pyramidal cells in the dorsal and ventral hippocampus
(Li et al., 1994). Despite this anisotropy, the random graph analogy of the CA3 system is valid. Adja-
cent neurons have the same probability of representing overlapping parts of the environment as do spa-
tially distant cells (O’Keefe and Nadel, 1978; Redish et al., 2001; but see Hampson et al., 1999).
Search Strategy in an Autoassociator
Let’s begin with some theoretical speculation. The computational properties of
recursive organization, such as the extensive CA3 recurrent system, meet the re-
quirements of an “autoassociator.” By its computational deﬁnition, an autoassoci-
ator is a self-correcting network that can recreate a previously stored pattern that
most closely resembles the current input pattern, even if it is only a fragment of
the stored version. Give the autoassociative network part of the content, and it re-
turns the whole. The performance of an associative network is characterized by
its memory capacity and content addressability. As the library analogy above im-
plies, these two requirements compete with each other, because storage space is
ﬁnite and speed is limited. Memory capacity is easy to deﬁne: the maximum num-
ber of patterns that can be stored and correctly retrieved. Content addressability is
a technical term that refers to an ability to recall a whole episode from a retrieval
cue consisting of only a small part of the original information.25
Finding a book in a library may require an exhaustive search, meaning that
every book should be checked, unless the library is organized, in which case some
key words can drastically simplify the search. The most efﬁcient method of search
depends on the organization of the system. The extensive axon arbors of the CA3
pyramidal cells indicate that the probability of connecting to nearby or distant CA3
neurons is approximately the same.26 As discussed in Cycle 2, systems with similar
“peer-to-peer” contact probabilities can be treated as random graphs. The concept
of a random graph implies that one can walk from any neuron to any other neuron
along the calculated shortest possible synaptic path, much like one can walk in an
unobstructed ﬁeld from any one place to any other place. Construction of a full
random graph from 200,000 CA3 pyramidal cells would require only 15–20 diver-
gent connections from each cell. However, going from any neuron to any other
neuron may require an excessively large number of steps (i.e., long synaptic path
length, as referred to in Cycle 2). The theoretical minimum of 10–15 connections
is in stark contrast to the 10,000–20,000 synapses that an average CA3 pyramidal
cell establishes with its peers. With this large divergence, in principle, activity can
jump from any neuron to any other through just two synapses. Furthermore, the

290
RHYTHMS OF THE BRAIN
27. Encoding is thought of as a neuronal process involved in transforming external events and in-
ternal thoughts into both temporary and long-lasting neural representations. This process can take
place irrespective of retrieving or reusing that representation.
28. (Muller et al., 1996b). See the extended discussion on the autoassociative graph below.
29. Of course, activity can spread in multiple directions if postsynaptic targets respond with spikes
and converge occasionally, generating a manifold trajectory. The number of possible trajectories and,
consequently, the number of episodes, represented by sequential activation of cell assemblies, are
practically unlimited.
30. The best illustration of sparsely distributed representation is the “place” cells in the hippocam-
pus (O’Keefe and Dostrovsky, 1971). The size of the place ﬁelds increases systematically, however, in
the septotemporal axis (Jung et al., 1994), and cell assemblies are formed from spatially randomly dis-
tributed neurons (Harris et al., 2003).
31. In the brain, members of the spatially distributed cell assembly might be brought together by
Hebbian plasticity, discussed further below.
large divergence implies that the number of possible routes between any randomly
chosen start and goal cell is a truly galactic ﬁgure. Nevertheless, no matter how im-
pressive this ﬁgure is, we do not get far with such anatomical reasoning alone, be-
cause synapses between pyramidal cells are weak, and the discharge of a single
starter cell will not be able to ﬁre any of its target peers. Yet, only discharging neu-
rons can be used for encoding and retrieving memories.27 Furthermore, the
strength of the synapses among neurons is highly variable. In other words, not all
routes are equal. Finally, the CA3 recurrent graph is directed because connections
between cell pairs are rarely reciprocal. Without speculating further, we can regis-
ter that the CA3 autoassociator and the CA3–CA1 synaptic matrix represent a
strongly connected, directed, and weighted graph.28 This arrangement simpliﬁes
how activity can spread in the recursive network. Instead of spreading excitation in
any direction randomly, the trajectory of sequentially spiking neurons in the hip-
pocampal space is determined by two factors only: the synaptic weights among
neurons and the state of local inhibition. When activity arrives at a bifurcation
choice, it will progress along the path with the stronger synapses and least inhibi-
tion, i.e., toward to path of the least resistance (ﬁgure 11.5).29
Precise anatomical data and computational modeling have provided useful
guidelines for the assessment of the storage capacity and content addressability of
real networks. Several caveats remain, however. The ﬁrst issue is a safe coding
format of the trace. The recommended computational solution is a sparse and dis-
tributed memory. “Sparse” representation means that only a fraction of the trace
is represented at one physical storage location. Each synapse can store only one
fact about the environment or the history of the brain’s owner. At the same time,
the memory is distributed over a large space. It is a bit like ﬁxing a dozen locks on
the same door and hiding the respective keys at different locations, with each lo-
cation providing a clue about the next location. The anatomy of the hippocampus
meets the requirements of sparse representation. Unlike in primary sensory cor-
tices, cell assemblies in the hippocampus, representing the same information,
consist of neurons that are distributed virtually randomly over the entire
CA3–CA1 regions.30 Spreading memory traces in a large coding space reduces
overlaps among the stored patterns.31

Navigation in Real and Memory Space
291
Figure 11.5. Activity spreads along the path of least resistance. Left: A ﬂoating object in
the delta of the Lena River will follow the path of fastest water ﬂow at each junction. Right:
Spread of neuronal activity in a multidimensional grid space, such as the CA3–CA1 net-
work, is determined by two factors: the synaptic strengths between neurons and momen-
tary inhibition. Inhibition at any junction can instantaneously divert the trajectory (path) of
activity. The numbers of possible trajectories are high.
32. Tamamaki and Nojyo (1993) ﬁlled a single layer 2 neuron in vivo. Its enormous axon cloud in
the molecular layer of the dentate gyrus and CA3 stratum lacunosum-moleculare illustrated the large
fan-out of the entorhinal input. Even if the numbers of neurons that project to the dentate gyrus in-
crease as the brain grows, the divergence still remains respectable.
Distribution of the input in the large space of the autoassociator requires a
special mechanism, and this is where granule cells become critical. Each super-
ﬁcial entorhinal neuron receives inputs from large neocortical areas. In turn, an
estimated 50,000 layer 2 stellate cells send inputs to 1,000,000 granule cells,
each of which is a recipient of inputs from approximately 10,000 converging en-
torhinal neurons. Viewed differently, a single entorhinal stellate cell disperses its
information to 20 times more granule cells.32 The goal of this arithmetic exercise
is to contrast the large fan-out in the neocortex–entorhinal cortex–granule cell
axis with the exceptionally low divergence and convergence of the granule cell
projections to the CA3 recurrent system. An average granule cell contacts only
20 CA3 pyramidal cells, a mere 0.1 percent of the possible targets. Because of
this low divergence, fewer than 50 granule cells converge on a single pyramidal
cell.
As expected from these anatomical ﬁgures, many inputs must converge on a
granule cell to discharge it, but a fundamentally different mechanism is needed
for the granule cell to make itself heard. The unique solution is a giant, so-called
“mossy” synapse, placed strategically close to the cell body (ﬁgure 11.6). This gi-
ant synapse contains multiple transmitter release sites, and under the right condi-
tions a single granule cell is sufﬁcient to discharge its target neurons, as Darrell

292
RHYTHMS OF THE BRAIN
33. The mossy terminal is the largest cortical bouton and one of the most complex axon terminals
in the mammalian brain (Chicurel and Harris, 1992). A comparably effective synapse is the calyx of
Held in the auditory brainstem (Habets and Borst, 2005). Granule cells target a disproportionally
larger percentage of interneurons than they do pyramidal cells, perhaps to compensate for the strong
effect of the mossy terminal (Acsády et al., 1998). The postsynaptic membrane of the mossy terminal
does not contain NMDA receptors, and long-term potentiation of the synapse is brought about largely
by presynaptic mechanisms (see Henze et al., 2000b). The synapse is extremely sensitive to frequency
potentiation, which is the main reason why fast trains of spikes in a single granule cell can discharge
its targets (Henze et al., 2002). The frequency potentiation produces activity-dependent delays in CA3
discharges, and these “delay lines” can be exploited for temporal deconvolution of decorrelated neo-
cortical inputs (Lõrincz and Buzsáki, 2000).
34. In computation jargon, the dispersion process is called “orthogonalization,” a process that re-
duces the similarity input patterns, thereby facilitating their unique storage and selective retrieval
(Treves and Rolls, 1994; O’Reilly and McClelland, 1994; Lõrincz and Buzsáki, 2000).
35. Tulving (1972, 2002). According to Suddendorf and Corballis (1997), the ability to travel men-
tally in time constitutes a discontinuity between humans and other animals.
Henze has shown it in my laboratory.33 With the help of the granule cells, the in-
put to be memorized can be dispersed into the large space of the CA3 recursive
system,34 at least in the proposed models.
How to Study the Mechanisms of Explicit 
Memory in Animals?
A major conceptual difﬁculty of studying the mechanism of memory storage in-
volves the exclusive nature of memory deﬁnition. Episodic memory is claimed to
be uniquely human, a mental travel back in time that endows the individual with
the capacity to reference personal experiences in the context of both time and
space. It is these life-long experiences, representing unique events through space-
time, that give rise to the feeling of the self and are the sources of individuality.35
The singular episodes can reemerge through the process of free recall. Semantic
knowledge, on the other hand, is largely a context-free form of information. It is
the “meaning” of things. Against this background, how are we expected to work
out physiological mechanisms of declarative memories in animals simpler than
humans?
Luckily, experimental psychology provides some clues about the internal orga-
nization of memories. These include the principles of contiguity and temporal
asymmetry, studied extensively by Michael Kahana at Brandeis University in
Waltham, Massachusetts. The principle of contiguity refers to the observation that
subsequent recall of an item is facilitated by the presentation or recall of another
item that was presented close in time to the item just recalled. The related princi-
ple, temporal asymmetry, is based on another well-known fact: forward associa-
tions are stronger than backward associations. If “desk, ﬂower, can, bird, and
lamp” were items in the middle of a list to be memorized, and if one recalled
“can,” the next most likely item to be recalled is “bird.” In other words, the item

Navigation in Real and Memory Space
293
Figure 11.6. Granule cells communicate with their limited number of principal-cell tar-
gets via giant boutons (also called mossy terminals, mt) and a larger number of interneu-
rons via ﬁlopodial extensions (arrowheads).Arrows, mossy ﬁber axons of granule cells.
Inset: Electron microscopic appearance of the mossy terminal at approximately the same
magniﬁcation as shown in the cartoon. The large size of the mossy terminal can be appre-
ciated by comparing it with a “regular-sized” excitatory terminal of a CA3 pyramidal cell
(small inset, lower left corner). Reprinted, with permission, from Acsády et al. (1998).
to be recalled from the middle of an episode tends to come from nearby serial po-
sitions. Furthermore, from the choice of nearby neighbors, the item in the forward
direction is twice as likely to be recalled as the item in the backward direction. In
essence, recall of a fragment of the episode recreates the temporal context of the
episode, and the temporal context facilitates sequential free recall.36
Now we have some principles that can guide neurophysiological research in
animals. Whatever shape or form a neurophysiological model of episodic mem-
ory takes, it must be compatible with these general guidelines and constrained by
the unique structural organization of the hippocampal system. As brieﬂy men-
tioned above, a model cannot be based on anatomical data only. The potential of
36. The principles of temporal contiguity and asymmetry are described in Kahana (1996). The
“temporal context model” of episodic memory (Howard and Kahana, 2002; Howard et al., 2005) is es-
sentially a recurrent autoassociator in which the previous state of the network contributes to the next.
See also Raaijmakers and Shiffrin (1981).

294
RHYTHMS OF THE BRAIN
37. The original logs were lost, but the Italian translation by Fernando Colon (1571/1959) sur-
vived. For a recent evaluation of Columbus’s navigation method, see Pickering (1996). Navigating
with the help of a global positioning system (GPS) is essentially instructed dead reckoning, but the
routes to the goal are determined by a precise map.
a large searchable space does not tell us how the search is done. For example,
once the entire system is searched, what prevents the propagation of activity into
an inﬁnite loop? In abstract models, relaxation to an attractor is the usual solution.
I suggest that, in the hippocampus, periodic inhibition in the form of theta-
frequency oscillation is the solution. However, before we can discuss how
episodic memory is carried by the ensemble actions of neurons, we must navigate
through 50 years of research on single cells and hippocampal rhythms. These lat-
ter two lines of inquiry have progressed relatively independently and often in con-
ﬂict with research on memory.
Navigation in Two-Dimensional Space
There are various methods of getting from place to place. Christopher Columbus
used a method called “dead” (originally called “deduced”) reckoning in his voy-
ages in the Mediterranean Sea and to America (ﬁgure 11.7). We know this be-
cause the dead-reckoning method depends upon continuous measurements of
course and distance sailed from some known port, and this method is exactly what
Columbus’s detailed logs reﬂect.37 Course was measured by a magnetic compass.
For the calculation of distance, the navigator multiplied the speed of the vessel by
the time traveled. Speed calibration was simple. The pilot threw a piece of ﬂotsam
over the side of the ship and started a rhythmic chant when the ﬂotsam passed a
mark on the side of the ship and stopped chanting when it passed another mark at
a known distance from the ﬁrst. Remembering the last syllable reached in the
chant, the speed was calculated. The total time elapsed leaving land was deter-
mined by the number of turns of the hourglass or by subsequently developed,
more sophisticated clocks. The direction of navigation was assisted by a magnetic
compass, a key navigation instrument in continuous use in Europe since the
twelfth century. At the end of the day, the estimated course and total distance were
transferred to a navigation chart and compared to the predicted position of the
goal (if known). Estimation of distance by dead reckoning works poorly on long
journeys. With an inaccurate chronometer and imprecise instruments to update or
recalibrate the boat’s position, the errors accumulate over time. On the positive
side, the dead-reckoning method does not require visible landmarks and, in prin-
ciple, works just the same in complete darkness. It was good enough for Colum-
bus to discover the New World.
Reliance of landmarks or celestial bodies is not critical in the Mediterranean
Sea, where the latitude is roughly the same wherever you are. However, when Por-
tuguese sailors began their long voyages along the north-south coast of Africa,
they soon learned that dead reckoning, without recalibration of the ship’s position,

Navigation in Real and Memory Space
295
was not particularly reliable in the vast waters of the Atlantic Ocean. A new
method, celestial navigation, was adopted. Celestial navigation determines one’s
geographic position by means of astronomical observations (distal cues). For ex-
ample, one can use the sun during the day and Polaris (the North Star), a star near
the North Celestial Pole known to every sailor, by night. It is fairly easy to
roughly estimate latitude by looking at the sun or Polaris. Each star has a celestial
latitude, or declination. Even if a star is not directly overhead, by calculating the
angle between the star and the overhead point (called the zenith), the latitude can
be deduced.38
In its simplest form, celestial or landmark navigation is a triangulation prob-
lem. Triangulation involves afﬁxing an object’s location via triangles. One can es-
timate position and travel distance by keeping track of the angles between the
navigator and a distant landmark. If at least two ﬁxed landmarks are available, po-
sitioning becomes a simple trigonometric problem, in which process time is irrel-
evant. But one has to be able to see or otherwise sense the landmarks. On land, a
Figure 11.7. Dead-reckoning navigation (path integration). Keeping track of distances
and directions at each segment of the travel, one can calculate the shortest return path to
home base.
38. Because heavenly bodies are not stationary, the measurement must be made at the time of night
when the star in question is highest in the sky. Columbus learned about celestial navigation from the
Portuguese sailors and attempted to use it. However, his logs reveal how poorly he calculated geo-
graphical position, even by the standards of his day (Pickering, 1996).

296
RHYTHMS OF THE BRAIN
39. Tessellation (from Latin tessera for square tablet) of a plane using identical shapes is possible
with either equilateral triangles or quadrilaterals. An important idea that can be illustrated through tes-
sellations is symmetry. Plane symmetry involves moving all points around the plane so that their posi-
tions relative to each other remain the same.
40. Rommell and McCleave (1972), Walcott and Green (1974), Baker (1980), Mittelstaedt and
Mittelstaedt (1980), and Redish (1999).
41. O’Keefe and Dostrovsky (1971). It is not clear how many of the eight cells in this original
landmark study were true place cells because they ﬁred when the “rat was facing in a particular direc-
tion,” a criterion for head-direction cells rather than omnidirectional place cells.
42. Several studies prior to O’Keefe’s seminal discovery examined the behavioral correlates of
hippocampal unit activity. Ranck (1973) listed more than 20 behavioral correlates of unit activity. The
detailed map can be created through tessellation, which exploits the principle
from ﬂoor tiling that every part of a surface can be covered by polygons of the
same size and shape without any gaps or overlaps.39 These polygons can then pro-
vide ﬁxed reference points.
Celestial or landmark navigation is a superior form of navigation, but it needs
a map, which ﬁrst must be created by prior dead-reckoning navigation. In the ab-
sence of visible landmarks or astronomical anchor points, the navigator can only
rely on dead reckoning. In addition to humans, all mammals and even lower forms
of animals seem to ﬂexibly use both dead-reckoning and triangulation methods of
navigation.40 Humans invented principles for navigation that have been in use by
other animals for millions of years. But what do navigation methods have to do
with brain oscillations and memory? You will soon see the relevance of my story
about nautical explorers.
Place Cells and Maps in the Hippocampus and
Entorhinal Cortex
Finding behavioral correlates of single neurons in central structures such as the
hippocampus is a daunting task because this central structure is so far removed
from the peripheral inputs. Nevertheless, when a hippocampal pyramidal cell
ﬁres while the rat is freely navigating in its home cage or the testing apparatus, it
is enough to watch the animal and listen to the loudspeaker broadcasting the cell’s
spikes to recognize that the neuron’s activity is distinctly related to the rat’s visits
to a circumscribed small location. It is a memorable experience for anyone listen-
ing to a well-tuned “place cell,” a term referring to the receptive or decoding fea-
tures of pyramidal and granule cells. This striking relationship in only eight of the
several dozens of the recorded neurons was enough for John O’Keefe at Univer-
sity College London to declare in 1971 that hippocampal neurons code for the
Cartesian position of the rat, irrespective of its behavior and regardless of the di-
rection from which it came to its position.41 This observation was a major break-
through because it showed a clear relationship between an overt behavior and
single units in a high-level associative structure.42 In his follow-up studies, O’Keefe

Navigation in Real and Memory Space
297
lasting contribution of his monograph is the recognition of two types of hippocampal CA1 neurons:
complex spikes cells and theta cells, which later were identiﬁed as pyramidal cells and a subset of fast-
ﬁring interneurons phase-locked to the theta waves. Other early single-unit studies include Noda et al.
(1969), Thompson (1976), and works from James Olds’s laboratory (e.g., Segal et al., 1972) and Vino-
gradova’s laboratory (summarized in Vinogradova (2001).
43. O’Keefe and Nadel (1978). The manuscript was circulated among their peers for almost 5
years before it was submitted for publication. Neither author had more than a handful of published pa-
pers prior to their book. In the absence of MedLine and the Internet, the book also became a refer-
enced encyclopedia of hippocampus research. There are numerous tables in the book that list the
observations and interpretations of other investigators, citing virtually every relevant experiment per-
formed on the topic in the Western hemisphere.
44. These features should remind us that re-creation or completion of the whole from fragmentary
inputs is the hallmark of autoassociative networks (Wills et al., 2005).
45. In humans, this explicitness is illustrated by the observations that some hippocampal units re-
spond invariantly to the different views of the same person or object independent of size or back-
ground or whether it is a photograph, a cartoon, or a written name (Heit et al., 1998; Quiroga et al.,
2005). Explicit (semantic) representation implies high logical depth and invariance to nonspeciﬁc
demonstrated that every hippocampal pyramidal neuron has a place correlate, and
by inference, every part of space is represented by the discharge of some hip-
pocampal neurons. O’Keefe teamed up with another protégé of Donald Hebb,
Lynn Nadel, and they expanded their observations into a large-scale theory. The
book that contains these ideas has remained the opus magnum of all prior works
written about the hippocampus.43 In essence, the authors argued that the hip-
pocampus computes the allocentric (“other–than–self-centered”) space, similar to
landmark or celestial navigation of Portuguese mariners. Information from all
modalities enters the hippocampal networks by way of the entorhinal cortex and a
map comes out; it is a conceived or holistic cognitive map, which allows the ani-
mal to navigate much the same way as we do when in possession of a map. We
can make shortcuts, solve detour problems, and plan a trip economically to sev-
eral cities on a single trip.
Over the past 30 years, O’Keefe and other investigators have discovered numer-
ous important features of place cells. In a two-dimensional environment, which is
the normal ecological space for most rat strains in the wild, the place ﬁelds are cone
shaped, with the center determined by the highest ﬁring rate of the neuron (ﬁgure
11.8); that is, the ﬁring rate increases identically, independent of the direction from
which the rat arrives. This omnidirectional property indicates that place neurons are
not coding for simple sensory stimuli but instead are computing an explicit location
of the environment. Removal of a variety of cues in the environment does not affect
the ﬁring pattern as long as a few cues remain available. On the other hand, when the
distant room cues are rotated together or the animal’s testing box is moved to an-
other room, place cells will rotate with the cues or “remap,” supporting the idea that
it is the distant landmarks that guide map construction.44 As long as the landmarks
stay put, place cells are stable in the same environment for months. Only a small
fraction of all pyramidal cells ﬁre in any given environment, and those that do re-
main pretty much silent outside their ﬁeld. This sparsity feature, together with their
hypothesized explicit spatial computation, qualiﬁes place cells as gnostic units.45

298
RHYTHMS OF THE BRAIN
information (Von Neuman, 1956). Logical depth refers to the number of computational steps required
to reach a conclusion (Koch 2004). Semantic items typically require only one step, whereas items in
an episode require several steps of computation.
46. Grid size of neurons increases from the dorsal to the ventral part of the medial entorhinal cor-
tex, a pattern that is also reﬂected by the increasing size of place ﬁelds in the septotemporal axis of the
hippocampus (Jung et al., 1994). Thus, the spatial distances are represented by multiple scales in both
the entorhinal cortex and hippocampus.
Recent studies by Edvard and May-Britt Moser and colleagues at the Center
for the Biology of Memory in Trondheim, Norway, identiﬁed the immediate ori-
gin of the allocentric map in the layer 2 cell population of the dorsomedial en-
torhinal cortex. These neurons are the major recipients of the information from
the visual and parietal cortices and give rise to the major input to the hippocampal
granule cells and CA3 pyramidal neurons. However, unlike hippocampal place
cells, which have an explicit, single receptive ﬁeld, the entorhinal neurons are ac-
tivated whenever the animal’s position coincides with any vertex of a grid of
equilateral triangles spanning the entire surface of the environment. Hence their
name: “grid cells” (ﬁgure 11.9). The grid size is approximately 30 centimeters,
echoing the size of a typical hippocampal place ﬁeld, and neighboring entorhinal
neurons display the rotated or displaced versions of the same tessellating struc-
ture.46 The periodically organized entorhinal map is a rigid map because coactive
Figure 11.8. Explicit representation by a CA1 place cell of the animal’s position in a two-
dimensional environment. Distances are in centimeters on the x- and z-axes. The y-axis
(vertical) is the ﬁring rate of the neuron. Note the cone shape (omnidirectionality) of the
place ﬁeld with a 40- to 50-centimenter base. The shape of the place ﬁeld does not depend
on velocity, acceleration, or past or future trajectory of motion of the rat, but the height of
the ﬁeld (i.e., frequency of discharge) does. Reprinted, with permission, from Sam-
sonovich and McNaughton (1997).

Navigation in Real and Memory Space
299
47. Although the grid structure remains unaltered in two different environments, the grids may
shift in a particular direction (E. Moser, personal communication).
48. In contrast to the plane symmetry features of entorhinal cells (Hafting et al., 2005), the
context-dependent remapping of hippocampal neurons is the telltale sign of symmetry braking. Lever
et al. (2002) observed that when rats are repeatedly exposed to two differently shaped environments,
hippocampal place-cell ﬁelds in the respective environments diverged over several days. Their ﬁnd-
ings indicate that place cells may be a neural substrate for long-term incidental learning. This ﬂexibil-
ity of context is in contrast to the original formulation of hippocampal place cells (O’Keefe and Nadel,
1978), which stated, following Kant, that representation of the environment is innate.
49. For a quantitative analysis of the relationship between spatial locations and physical locations
of place cells in the hippocampus, see Redish et al. (2001).
grid cells remain in register when the rat is moved to another apparatus with a dif-
ferent size or shape or is tested in the same apparatus but in a different room.47 In
contrast, hippocampal maps are ﬂexible, and unique cell assemblies are called
upon in different environments. Importantly, grid cells become active instanta-
neously in any novel environment, whereas establishment of stable place cells in
the hippocampus may take from minutes to days of learning.48 Thus, there are
similarities as well as important differences between hippocampal and entorhinal
cortical representation of the environment.
A map is the embodiment of the spatial relations among landmarks. It allows
for the computation of position, distance, and direction and assists effective navi-
gation. How can one identify maps of the environment in the brain? In contrast to
the orderly and constant relationship of objects in the environment, a consistent
ﬁnding is that physically nearby neurons in the hippocampus do not code for
neighboring places (ﬁgure 11.10).49 The random graph architecture of the hip-
pocampus does not reveal a simple physiological topology. The brain structure
that gives rise to explicit maps does not have a strict topographic organization. It
Figure 11.9. Gridlike representation of the environment by entorhinal place cells. Left:
Tessellation of a city map by squares provides information about position, distance, and di-
rection, allowing speciﬁc places to be easily located. Middle: As a rat explores an experi-
mental enclosure (1 m2), the discharge rate of a neuron in the dorsocaudal medial
entorhinal cortex increases at regular intervals corresponding to the vertices of a triangular
grid (Figure courtesy of Edvard Moser). Each of the 12 place ﬁelds of the single neuron is
similar to the cone shape shown in ﬁgure 11.8. Right: Integration of information from sev-
eral grid components (i.e., from the outputs of several neurons) can increase the spatial res-
olution of the environment. Reprinted, with permission, from Buzsáki (2005a).

300
RHYTHMS OF THE BRAIN
Figure 11.10. Absence of topographical representation of the environment in the hip-
pocampus: ﬁve recording electrodes placed in the CA1 pyramidal layer (top) and corre-
sponding unit discharges over a short period (left). Right: Place ﬁelds of neurons from two
electrodes (separated by the horizontal line). Note the random representation of place seg-
ments in the apparatus with a square-shape ﬂoor, viewed from above, by neighboring neu-
rons. Light areas represent neuronal discharges of individual hippocampal neurons.
does not have to. Orderly maps can be constructed by random connections, as
well, although reading the routes may ﬁrst appear complicated. Suppose that we
would like to drive from New York to San Francisco. By consulting the road map
of the United States, we can calculate the shortest path by measuring the distances
of the roads connecting the different cities along the way. If we make a paper ball

Navigation in Real and Memory Space
301
50. Another, more persuasive explanation for the lack of a physical resemblance between the envi-
ronment and the functional connections is that the hippocampus stores many maps, one for each envi-
ronment (Muller et al., 1996b; Samsonovich and McNaughton 1997).
51. (Muller et al., 1996b). Maps can be constructed by various neuronal architectures, because
maplike representation are present in most animals from insects to mammals with different types of
brains (Gallistel, 1990). However, the CA3 autoassociator can allow for the ﬂexible use of multiple in-
dependent maps, unlike the rigid single map representation of grid cells in the dorsomedial entorhinal
cortex (Hafting et al., 2005). Furthermore, the synaptic-weight–guided connections are exactly the
sort of architecture needed for attractor dynamics. Samsonovich and McNaughton (1997), building on
the graph representation of the environment, demonstrated how multiple graphs or charts can coexist
in a hippocampal model to ﬂexibly represent multiple environs.
52. The synaptic graph model, in its originally conceived version, is not feasible physiologically,
however. Synapses between pyramidal cells are weak, and the activity cannot spread from one neuron
to another. Nevertheless, the conceptual simpliﬁcation of Muller et al. (1996b) has far-reaching con-
sequences for understanding the utility of a high-dimensional autoassociator for coding and retrieving
information. Once single cells are substituted with cell assemblies, the effectiveness of assembly
communication can be assessed by large-scale recordings of neurons even without measuring the
synaptic weights directly between neuron pairs.
out of the map, the route information remains preserved, but ﬁnding the shortest
path now gets a bit trickier.50
In the hippocampus, the two major elements of the route-ﬁnding optimization
procedure are the omnidirectional, explicit place cells and the synaptic strengths
between them. An appropriate algorithm can easily calculate the shortest, that is,
the most effective, route between any two neurons (ﬁgure 11.5). Thus, searching
for a path in neuronal space is analogous to reading a map. The essential isomor-
phism between the strongly recurrent CA3 network and two-dimensional Carte-
sian space was ﬁrst conceived by Robert Muller at the Downstate Medical Center
in Brooklyn and the graph theorist János Pach at the Courant Institute in New
York. They hypothesized that every path in Cartesian space can be described as a
path in neuronal space (neuron–synapse–neuron route).51 The key intuition here is
that the distance between positions represented by two place cells is coded by
synaptic strength between the neurons. Neurons representing nearby locations are
connected by stronger synapses than are neurons representing more distant loca-
tions. In a randomly connected neuronal graph, maps can therefore be stored even
if the physical locations of place cells in the hippocampus and entorhinal cortex
have no resemblance to the layout of the environment they represent. Although
not much experimental support was available to back up their hypothesis, the
modeling results of Muller and Pach showed that the best paths in two-
dimensional space associated with best paths in neuronal space approached
straight line segments (i.e., shortest possible path lengths) as the divergence of
single neurons in the model system increased. In essence, the neuron graph model
demonstrated the conceptually similar nature of ﬁnding the shortest routes in real
and neuronal space. Graph-searching algorithms in the neuronal-synaptic space
effectively calculated shortcuts when road blocks were removed or the shortest
route when faced with a detour problem.52
The omnidirectional features of place cells and the equipotential tessellation
features of entorhinal cortical cells illustrate the important concept of plane

302
RHYTHMS OF THE BRAIN
53. Ego/allo, self/other distinctions have resurfaced several times in the history of neuroscience.
Hughling Jackson used the term “subject consciousness” for our ﬁrst, personalized awareness of our
subjective self and distinguished it from “object consciousness,” which refers to the other things “out
there” in the environment.
54. Whishaw and Brooks (1999) trained rats to forage on an open table for a large food pellet,
which the rats could carry back to a refuge. In the test phase of the experiment, the location of the
refuge from which the rats emerged was changed. In these trials, all rats ﬁrst explored the table with
symmetry. Plane symmetry involves moving all points around the plane so that
their positions relative to each other remain the same. Symmetries preserve dis-
tances, angles, sizes, and shapes. The plane symmetry representation by explicit
place cells in the entorhinal grid cells is in stark contrast to the asymmetric recall
features of episodic memory. Episodic recall moves forward in time, whereas
maps do not require time dimension. Yet, I suggested above that the strongly con-
nected, directed, and weighted graph of the CA3 autoassociator and the
CA3–CA1 synaptic matrix is an ideal architecture for storing and recalling
episodic information. The conﬂict is even more apparent at the conceptual level,
because map-based navigation is an allocentric concept, whereas the essence of
episodic memories is egocentric, self-referenced, ﬁrst-person representation.53 To
solve the conﬂict between spatial mapping and episodic memory, we need to add
two more ingredients to hippocampal neuronal patterns: symmetry braking of
routes and temporal context. A useful step in this direction is to examine how
maps are constructed and calibrated in the ﬁrst place.
Dead Reckoning by the Hippocampus: Maps Are Made
through Motor Actions
Imagine that you are transported to a dark room while asleep, and you wake up in
that totally unknown environment. Walking in random directions, you may come
to a wall. Remembering the number of steps it took you to reach the wall and the
direction of motion, you can easily return to the start position. Continued walking
in the opposite direction will take you to the opposite wall. From the total number
of steps, you have a sense of the distance between the two walls. Using the same
dead-reckoning strategy, the distances between all walls and all possible objects
identiﬁed in the room can be estimated. After sufﬁcient amount of exploration,
that is, dead-reckoning navigation, you can form an internal image, often referred
to as a mental or cognitive map, of the room that allows you to make shortcut and
detours. The method of map formation is fundamentally the same in the light. Al-
though you can often estimate distances on the basis of visual cues, as well, mak-
ing map formation faster than in the dark, such visual distance estimation by eye
movements is based on previous locomotor practice. We are not born with these
metrics in our heads. They are developed through active locomotion. Map-based
navigation requires a calibrated representation of the environment. The dictum
“no action—no perception” (Cycle 8) also applies to the navigation system.54

Navigation in Real and Memory Space
303
the same vigor under both light and dark conditions before navigating home in a straight line with the
food, even though the available landmarks, in principle, provided the appropriate direction and dis-
tance to ﬁnd the reward and return to the refuge.
55. The random-walk analogy is not true for the whole extent of behavior. Rodents adopt speciﬁc lo-
cations in their home environment, and even featureless environments, as home bases from which they
organize exploratory trips. The excursions from the home bases are circuitous and consist of a number of
progressions punctuated by stops. Typically, excursions are terminated by fast, direct returns to the home
base. These behavioral patterns are altered after hippocampal damage (Whishaw et al., 2001).
However, movement itself is not sufﬁcient to develop a map. If in our dark
room example you walk in a spiral without crossing paths and reexperiencing the
same objects (landmarks) from different directions, a map does not develop. The
same is true for any one-dimensional travel, for example, moving back and forth
on a straight line or running on a treadmill. However, dead-reckoning exploration
is essentially a random-walk type of navigation during which the paths of naviga-
tion often cross (ﬁgure 11.11).55 As a result, the intersections will be tied to mul-
tiple routes. The landmark junctions are critical for correcting the positional
Figure 11.11. Generation of a map requires exploration with path crossings ( junctions).
Dead-reckoning navigation on a linear track, complex maze, or spiral maze without path
crossings and distant landmarks cannot establish anchor points and maps. Travel is based
exclusively on self-referenced cues. Exploration in an open environment, on the other
hand, such as a large cylinder, is random walk navigation, during which paths are recrossed
multiple times. Such multiple path junctions are hypothesized to generate omnidirectional
hippocampal place cells. Reprinted, with permission, from Buzsáki (2005b).

304
RHYTHMS OF THE BRAIN
errors and for the construction of a map. Once in possession of a map, landmark
navigation is a superior form of navigation and is likely chosen by all animals that
can generate such representation. In the absence of landmarks, on the other hand,
animals can always rely on dead reckoning. It follows that dead-reckoning and
map-based navigations are interchangeable only after a map has been established
as a result of dead-reckoning exploration, because two-dimensional maps evolve
from junction crossings of one-dimensional routes.
An important justiﬁcation for distinguishing between one- and two-dimensional
travels is that such a distinction appears important to the brain. When a rat runs back
and forth in a straight alley, different sets of hippocampal neurons are active on the
opposite journeys.56 The direction-dependent or unidirectional ﬁring of neurons in
a one-dimensional task is in sharp contrast to the plane-symmetric, omnidirectional
discharge of place cells in two-dimensional environments. This observation also in-
dicates that the ﬁring rate of single cells alone is not a foolproof correlate of the an-
imal’s momentary position. Although environmental cues may exert effective
control on the ﬁring rate of hippocampal cells, other types of inputs are also impor-
tant. One such strong inﬂuence is the speed at which the animal moves through the
place ﬁeld. Speed information may come from multiple sources, including the
vestibular system, optical ﬂow, and reafferent signals from the muscles and muscle
tendons. András Czurkó and Hajime Hirase, working in my laboratory, have identi-
ﬁed reafferentation as a critical source of speed information. Recording from place
cells while the rat was running in a wheel, we found a linear relationship between
ﬁring discharge of the neurons and running velocity (ﬁgure 11.12). Optical ﬂow and
vestibular input appeared to be of secondary importance because the head was quite
stationary in the wheel and the velocity-ﬁring rate relationship remained the same
in complete darkness. Importantly, scalar speed did not modulate the ﬁring rate of
just any cell but increased the rate only when the rat’s head was within the bound-
aries of its place ﬁeld. In fact, increasing speed may decrease the rate when the rat
runs in a direction opposite to the favored direction of the cell.57
These ﬁndings in the wheel experiment not only demonstrate direction-speciﬁc
ﬁring in another one-dimensional task but also show that the ﬁring rate of single
cells is a combination of both location and the velocity of the animal.58 The engi-
neering notion of such combinatorial property is “gain.”59 Velocity is a gain factor
56. McNaughton et al. (1983a) found that in an eight-arm radial maze, place cells often ﬁre only in
one direction of motion, some during the outbound, and others during the inbound journeys but not
both directions. This was also the ﬁrst report to note the effect of locomotor velocity on the discharge
rate of hippocampal place cells.
57. The direction-speciﬁc ﬁring of hippocampal neurons in the wheel with the rat’s head kept rel-
atively stationary is reminiscent of “view cells” in head-ﬁxed monkeys (Rolls 1999).
58. Neurons in the wheel have unidirectional place ﬁelds (Czurkó et al., 1999; Hirase et al., 1999).
For the conditional signal enhancement of place-cell activity, see Moita et al. (2003).
59. The different inputs are not simply summated, and the idea of “gain” is different from “conjunc-
tive” neurons, which refer to a new quality that arises from a combination of singular features (e.g.,
Deadwyler and Hampson, 1997; Eichenbaum, 2002). E.g., the environmental context can select the neu-
ronal assembly, whereas gain control (provided by local cues, locomotion speed, emotional state, and
other factors) can differentially adjust the ﬁring rate of the assembly members (Leutgeb et al., 2005).

Navigation in Real and Memory Space
305
Figure 11.12. Gain modulation of neuronal activity. Top: Firing rate of a pyramidal cell as
a function of running speed. The rat was running in a wheel so that the spatial and body-
reference signals were kept constant. Negative and positive speed values indicate running
directions to the left and right, respectively. Note suppression of discharge rate in the non-
preferred direction. Bottom: Interneurons show only a moderate speed dependence, and in-
dependent of the direction of running. Reprinted, with permission, from Czurkó et al.
(1999).
60. Similar “gain control” has been described in other systems, as well. In the posterior parietal
cortex, a neuron’s ﬁring response is expressed as the product of the visual response relative to the
retina (the cell’s conventionally deﬁned receptive ﬁeld) and the position of the eye within its orbit
that enhances the sensitivity of hippocampal place cells to provide a greater
output.60 Because of gain control, the discharge rate of single cells is always am-
biguous for deﬁning location. For now, however, the important thing to remember is
that speed information is available in the hippocampal system. To derive velocity

306
RHYTHMS OF THE BRAIN
(Andersen et al., 1997; Zipser and Andersen, 1988). In visual area V4, saccadic eye movements en-
hance the ﬁring rates of only those neurons that are driven by their preferred inputs (Sharma et al.,
2003; Bichot et al., 2005).
61. Ranck (1985).
62. For comprehensive reviews on the head-direction system, see Taube and Bassett (2003) and
Muller et al. (1996a). Firing of thalamic head-direction cells is also correlated with the speed of head
turning (Blair and Sharp, 1995). Some neurons in the subicular complex show both spatial and direc-
tional properties (Sharp and Green, 1994; Cacucci et al., 2004). Head-direction cells allow the re-
orientation in a familiar environment as rapidly as 80 milliseconds after changes in the visual scene
(Zugaro et al., 2003), i.e., about one theta cycle.
63. The main arguments in favor of the hippocampus-based dead-reckoning navigation are sum-
marized in a landmark paper (McNaughton et al., 1996). A formal model of path integration is pre-
sented in Samsonovich and McNaughton (1997). At about the same time, Touretzky and Redish
(1996) also developed a computational model of dead reckoning (see also Redish, 1999).
(i.e., a vector) from speed, direction is needed, as well. The source of this critical in-
formation was revealed by James Ranck from State University of New York–Brook-
lyn at a small meeting of hippocampus aﬁcionados in 1984. “Head-direction”
neurons in the postsubiculum, part of the subicular complex between the hippocam-
pus and entorhinal cortex, ﬁre only when the head points in a certain direction in the
environment, regardless of the neck angle or the animal’s location.61 A set of head-
direction cells can function as a compass, a handy instrument in dead-reckoning
navigation. However, the target of head-direction cells is not Earth’s magnetic ﬁeld
but some arbitrary reference direction, which may shift when cues in the laboratory
are rotated in a coherent manner. There are many sets of head-direction cells tuned
to different arbitrary directions. Ranck’s student Jeffrey Taube, now at Dartmouth
College, and Alain Berthoz’s group at College de France in Paris have searched for
head-direction cells outside the postsubiculum and identiﬁed a whole system of
head-direction cells in the brain. Varying fractions of neurons in the anterior thala-
mic nuclei, lateral dorsal thalamus, posterior parietal and retrosplenial cortices, dor-
sal striatum, lateral septum, dorsal tegmental nucleus, lateral mammillary nucleus,
and entorhinal cortex show head-direction properties. Importantly, the direction sys-
tem can function independent of the hippocampal place cells, because damage or in-
activation of the hippocampus does not abolish directional tuning of head-direction
cells.62 In addition to direction, many cells in the lateral mammillary body also re-
spond to the angular velocity of the head. So there is a common thread here with
position-reporting place cells: both navigational systems are gain-modulated by
speed signals. The properties described above endow the system of head-direction
neurons with the ability to signal the rat’s sense of direction during navigation.
These and related ﬁndings appeared sufﬁciently strong exceptions to the omnidi-
rectional place-cell–based landmark navigation to Bruce McNaughton at University
of Arizona–Tucson that he challenged the map theory of the hippocampus.63 In a
conceptually similar set of experiments, McNaughton and O’Keefe examined the
critical determinants of place cells. In the London experiment, the rats were tested in
rectangular boxes of various sizes and shapes. Place ﬁelds recorded in a small
square box became elongated or even split into two place ﬁelds when the rat was put

Navigation in Real and Memory Space
307
64. O’Keefe and Burgess (1996) and Gothard et al. (1996). The term “path integration” was
adopted from Mittelstaedt and Mittelstaedt (1980), who showed a gerbil mother, after searching for a
missing pup in the dark by an apparent random walk, returned to the nest in a straight line after the pup
was found. Path integration and dead reckoning are synonymous terms.
65. Foster et al. (1989) showed the silencing effect of immobilization on place cells, and Knierim
et al. (1995), on head-direction neurons. The active and “toy car driving” experiments are reported in
Terrazas et al. (2005).
66. The location of the integrator in the Samsonovich and McNaughton (1997) model was tenta-
tively identiﬁed with the subicular complex. Another option for integration is the entorhinal cortex.
Egorov et al. (2002) reported that transient depolarization of layer 5 neurons causes a persistent ﬁring,
with discharge rates commensurate with the magnitude of depolarization. Conversely, transient hy-
perpolarization reduces ﬁring rate in a steplike manner. The tessellation feature of entorhinal cortical
neurons is also consistent with the notion that integration of position, direction, and distance may take
place in the entorhinal cortex (Hafting et al., 2005). Indeed, head-direction cells are also present in the
dorsomedial entorhinal cortex. Layer 5 neurons are explicit head-direction cells, whereas layer 3 neu-
rons show both grid tessellation and head-direction properties (K. Mizuseki and G. Buzsáki, unpub-
lished observations; E. Moser, personal communication). Thus, place and direction information are
present in single entorhinal cortical modules.
in a double-size rectangular test box. Often, the newly created split place ﬁelds be-
came directional, with the preferred directions of each half oriented toward each
other. The rats in the Tucson experiment had to shufﬂe back and forth between two
food sites on a linear track. In some trials, the distance between the two sites was re-
duced. As a result, the size of the place ﬁelds became compressed and occasionally
disappeared altogether. O’Keefe and his long-term collaborator Neil Burgess pro-
vided a geometrical explanation, suggesting that the rat calculated the box sizes by
triangulation on the basis of vertical heights of the walls and other visual cues. Mc-
Naughton offered an alternative explanation: dead reckoning or path integration.64
One of his key arguments is that seeing or otherwise sensing distant landmarks is
not sufﬁcient to activate place cells. Instead, distance is calculated on the basis of
self-motion cues. During locomotion, the rat remembers each physical contact with
the wall and monitors the amount and direction of movement from the contacted
landmark for the computation of vectorial distance. In an enviably simple experi-
ment, his group has already shown that it is sufﬁcient to wrap the rat tightly in a
towel: under such conditions of movement restraint, both place cells and thalamic
head-direction cells become virtually silent, even when the animal is moved through
the place ﬁelds by the experimenter. In another experiment, the rat either actively
ran around a circular track or “drove” a toy car, or the curtain surrounding the track
was rotated while the rat was sitting. The ﬁring rate of the place cells was propor-
tional to the movement generated by the rat and to the power of theta oscillation.65
The main ingredients of McNaughton’s dead-reckoning model are the multi-
modal sensory inputs, direction of self-motion, hippocampal place cells, and a
hypothetical integrator. Direction is calculated by the head-direction system re-
siding outside the hippocampus. This information feeds the hippocampal place-
cell system, which functions as a two-dimensional attractor that calculates the
shortest distances between landmarks with the help of the integrator. The integra-
tor receives inputs from all other components of the path integrator machinery
and calculates all possible combinations of head orientation and location.66

308
RHYTHMS OF THE BRAIN
67. The discovery of neurons predicting the future choice of the animal in a T-maze task also pro-
vides support for the hypothesized link between dead reckoning and episodic memory (Frank et al.,
2000; Wood et al., 2000; Ferbinteanu and Shapiro, 2003).
68. More than 1,600 reports have been published on theta oscillations over the past six decades. I
can only brieﬂy highlight the major milestones here. I refer the reader to the several comprehensive re-
views on the topic (Grastyán et al., 1959; Buzsáki et al., 1983, 1994a; O’Keefe and Nadel, 1978;
Bland, 1986; Vanderwolf, 1988, 2003; Lopes da Silva et al., 1990; Stewart and Fox, 1990; Vino-
gradova, 1995, 2001; Vertes and Kocsis, 1997; Buzsáki, 2002, 2005b). For theta oscillation’s role in
plasticity, see Larson and Lynch G (1986) and Huerta and Lisman (1993; 1995).
69. Theta oscillation is also the hallmark of REM sleep (Jouvet, 1999, 2004; Grastyán and Kar-
mos,1961)).
The idea that the hippocampus contributes to dead reckoning indirectly brought
time back into the picture, the fundamental dimension for episodic memory. Thus,
this is the point at which, without the discussion of a timing mechanism, I cannot
develop the discussion further. Furthermore, we still have to understand how dis-
tances are converted into synaptic weights in the autoassociative attractor networks
of the hippocampus and in the grid map of the entorhinal cortex. Because both
dead reckoning and episodic memory depend on time, and because both processes
are self-centered, there may be a link between them. Furthermore, the relationship
with allocentric maps and semantic (allocentric explicit) memory, also attributed
to the activity of the hippocampal–entorhinal system, remains to be elucidated, as
well.67 Before we can move on with these difﬁcult issues, I provide an overview of
the theta rhythm, the major temporal organizer of the hippocampal–entorhinal cor-
tex. My main claim is that it is the theta oscillation through which one can under-
stand the relationship between one-dimensional and two-dimensional navigation
and between episodic and semantic memory.
Theta: The Rhythm of Navigation in Physical and
Neuronal Space
Hippocampal theta oscillations (6–10 hertz in the rat and somewhat slower in
higher species) are different from all cortical rhythms discussed so far. Theta os-
cillation is a sustained rhythm in the sense that as long as the animal is engaged in
the same behavior, theta waves occur continuously.68 As alluded to in Cycle 1, the
exact behavioral categories associated with theta have never been agreed upon. I
have used the term “exploration” in my writings to avoid the connotation of “vol-
untary” or “attentional” behavior, but it is arguable whether walking the same al-
ley for the hundredth time is still considered exploration. Navigation is perhaps
the best descriptive term, implying both self-motion and mnemonic navigation in
neuronal space.69
Generation of Theta Rhythms
Neurons in many structures, including all those illustrated in ﬁgure 11.3, can ﬁre
phase-locked to hippocampal theta oscillations, although the extent of the phase

Navigation in Real and Memory Space
309
70. Petsche et al. (1962).
71. Bland et al. (1988) introduced the slice preparation for the study of in vitro rhythms. For re-
views of thetalike and gammalike oscillations in vitro, see Traub et al. (1999, 2004).
72. The interneuron identity of “theta cells” (Ranck, 1973) was a controversial issue for a long
time. Brian Bland and his post-doctoral advisor Per Andersen, the authority on both in vivo and in
vitro cellular physiology, concluded that the granule cells in the anesthetized rabbit are the most rhyth-
mic and best locked to the phase of theta oscillation in the hippocampus, followed by pyramidal cells, 
entrainment depends on structure, cell type, and task. In such a strongly intercon-
nected system with multiple loops, identifying the key ingredients responsible for
the emergence of the rhythm is not trivial. The simplest and oldest idea is that a
“pacemaker” is responsible for it all. Helmut Petsche at the Brain Research Insti-
tute in Vienna pointed to the cholinergic medial septum as the theta pacemaker
more than four decades ago. Recently, the supramammillary nucleus, a structure
in the hypothalamus with bidirectional connections with the septum, emerged as
a supplementary pacemaker candidate.70 Petsche and many subsequent investiga-
tors have shown that complete destruction of the medial septum abolished theta in
the hippocampus and, by implication, in all related structures. This could be be-
cause the septum, as postulated, is an independent pacemaker or rhythm genera-
tor. Alternatively, its connections may lie at a critical crossroad of the loop(s) of
structures that collectively give rise to the rhythm.
In support of the pacemaker idea, septal and other basal forebrain cells that re-
lease the neurotransmitter acetylcholine or GABA can sustain bursts of action po-
tentials at theta frequency. In other words, they are endowed with the proper time
constant and necessary intrinsic mechanisms to sustain subthreshold and
suprathreshold oscillations. What has never been shown, however, is whether the
circuitry that entrains these individual neurons into a synchronous action resides in
the septum itself, assisted, for example, by its own GABAergic neurons, or requires
feedback from other structures, such as the hippocampus. The role of the neuro-
transmitter acetylcholine is rather complex. For example, pharmacological block-
ade of the action of acetylcholine does not signiﬁcantly affect locomotion-related
theta, although the drug effect can be revealed by the reduction or abolishment of
theta waves induced by meaningful sensory inputs in the absence of movement. On
the other hand, selective and complete damage to the cholinergic cells in the septal
area decreases the amplitude of hippocampal theta oscillations several-fold, al-
though it does not completely eliminate it. In contrast, application of cholinergic
drugs can induce transient thetalike oscillations in hippocampal slices, that is, with-
out the septum.71 This “in vitro theta” depends on the excitatory recurrent collater-
als of the CA3 autoassociator as well as on hitherto not well-understood
interactions with interneurons. With Anatol Bragin in my lab and Bernard Kocsis at
Harvard University, we have shown that the CA3 theta generator functions rela-
tively independently of other theta generators in the intact brain. Thus, at least one
theta oscillator that is supported by the hippocampal networks requires a permis-
sive action of the medial septal cholinergic input but no external timing.
GABAergic hippocampal interneurons have also been implied in theta oscilla-
tions ever since Ranck’s ﬁnding of rhythmic “theta” cells in the navigating rat.72

310
RHYTHMS OF THE BRAIN
whereas GABAergic interneurons hardly ever ﬁre rhythmically or phase-locked to theta (Bland et al.,
1980). Our in vivo intracellular labeling studies provided the conclusive evidence that “theta cells” are
inhibitory interneurons (Ylinen et al., 1995b; Sík et al., 1995).
73. O-LM interneuron-supported thetalike oscillation in vitro does not require AMPA receptor-
mediated excitatory postsynaptic potentials or acetylcholine and it is most pronounced in the CA1 re-
gion (Gillies et al., 2002). Computer modeling suggests that mutual connections between the O-LM
and putative basket neurons are sufﬁcient to sustain the oscillation. The key element in the model os-
cillation is the hyperpolarization-induced rebound discharge of O-LM neurons (Rotstein et al., 2005).
A potential caveat is that, in the HCN1 knockout mouse in which Ih is virtually absent in hippocampal
neurons, including O-LM cells, the amplitude of theta is larger than in the control littermate (Nolan et
al., 2004). Distal dendrites of pyramidal cells contain the highest density of HCN 1 channels (Magee
2000; Lõrincz et al., 2002). Nevertheless, in the presence of Ih, O-LM cells can support theta oscilla-
tions.
74. The voltage activation range of Ih and Im channels is close to the resting membrane potential;
therefore, they are expected to enhance inhibitory and excitatory inputs at a frequency determined by
the channel inactivation time constant. The opposing force of these channels is likely the persistent
Na+ current INaP (Pike et al., 2000; Hu et al., 2002).
Tamàs Freund’s group at the Institute of Experimental Mecicine, Budapest, Hun-
gary has been at the forefront of working out the relevant microcircuitry in the
septohippocampal GABAergic system. Their most remarkable discovery is the
selective nature of connections within the GABAergic population. GABAergic
cells in the medial septum project to all types of hippocampal interneurons but do
not contact pyramidal cells or granule cells at all. In turn, long-range interneurons
are the only hippocampal cells that project back to the medial septum, innervating
the cells of origin, and may be responsible for synchronizing the neuron popula-
tions in the medial septal nucleus. A case similar to the postulated medial septal
pacemaker can be made also for a special group of interneurons, the oriens–la-
cunosum-moleculare (O-LM) cells. The dendrites of O-LM neurons are conﬁned
to the oriens layer and are innervated mainly by CA1 pyramidal cells; their axons
innervate mostly the distal apical dendrites of the pyramidal cells. Like the
cholinergic septal cells, O-LM interneurons are endowed with the necessary in-
trinsic properties to oscillate at theta frequency individually. Their propensity to
oscillate is made possible mainly by the especially high density of channels re-
sponsible for the pacemaker current Ih. However, for a coordinated group action,
the O-LM neurons have to be synchronized, a job that can be accomplished by ei-
ther the faster ﬁring basket cells or the long-range neurons (ﬁgure 11.13).73
There are other critical ingredients to add. Although hippocampal pyramidal
cells do not typically oscillate in isolation, they have resonant properties at theta
frequency, due mainly to the time constants of currents ﬂowing through ion chan-
nels known as Ih and Im .74 Layer 2 entorhinal cortical neurons (the grid cells), on
the other hand, are endowed with subthreshold oscillations at theta frequency. The
oscillation is a result of the dynamic interplay between two opposing forces, a
depolarization-activated persistent inward current (so-called INaP) and the
hyperpolarization-activated pacemaker current (Ih).
My goal with this short survey was to demonstrate that evolution has dedicated
a consortium of mechanisms to secure a precise timing mechanism at the theta

??????????
0.2
0.4
0.6
Axo-axonic Cells
0.0
??????????
0.10
0.20
0.30
PV Basket Cells
0.00
??????????
0.08
0.04
0.12
0.16
O-LM Cells
0.00
0
360
theta phase
720
1
1
0
normalized time
??????????
0.1
Bistratified Cells
0.4
0.0
??????????
0.02
0.04
Pyramidal Cells
0.00
0.05
0.10
0
360
720
0.00
0.4
0.2
1.0
0.0
0.10
0.15
0.05
0.10
0.00
0.3
0.6
0.95
0.00
0.04
0.02
0.06
0.08
0.10
0.00
Figure 11.13. Timing of principal-cell action potentials is secured by a coordinated action
of interneuron classes. Mean ﬁring probabilities of pyramidal cells and different interneu-
ron types during theta (left) and sharp wave-related fast “ripple” oscillations (right). Differ-
ent constellations of interneuron classes contribute speciﬁcally and differentially to theta
and ripple oscillations. Reprinted, with permission, from Klausberger et al. (2003, 2004).

312
RHYTHMS OF THE BRAIN
75. For a review on theta current generation summarizing progress and outstanding issues, includ-
ing the most critical references on the topic, see Buzsáki (2002). A comprehensive experimental report
on theta currents, including direct current (DC) measurements, is Brankack et al. (1993).
76. Upon strong dendritic depolarization, the voltage-dependent intrinsic oscillation can be faster
than the ongoing network theta rhythm (Kamondi et al., 1998).
time period. Single-cell properties perfectly match circuit features in both princi-
pal cells and interneurons. As a result, the multiple theta oscillation mechanisms
can contribute to the computational properties of hippocampal–entorhinal neu-
rons in complex ways. Of course, the exact details of this last statement are what
we are most interested in, because these details determine how cell populations
are assembled to represent episodes and maps. But ﬁrst, let us examine how theta
currents emerge.
Generation of Theta Oscillation Currents
Theta currents arise primarily from the laminarly arranged pyramidal cells and
granule cells, simply because of majority rule. Theta currents have been most ex-
tensively studied in the CA1 region.75 The ﬁrst important observation was that the
phase of the extracellularly recorded theta waves reverses gradually from the cell
body layer to the distal apical dendrites without a prominent null zone. This be-
havior is a telltale sign of multiple, phase-shifted dipoles in action. The presence
of multiple dipoles is not so surprising because every pathway with phase-locked
activity to the global rhythm contributes to the extracellular mean ﬁeld by its
synaptic action on hippocampal neurons, and there are many paths to choose from.
The largest amplitude theta is observed at the distal apical dendrites of the CA1
pyramidal cells, the layer where the afferents from layer 3 entorhinal cortical cells
and the thalamic reunions nucleus terminate. The entorhinal cortex/reuniens–me-
diated theta, to a large extent, is NMDA-receptor dependent. Layer 2 grid cells
provide rhythmic dipoles to the granule cells and the distal apical dendrites of CA3
pyramidal neurons. However, removal of the entorhinal inputs does not eliminate
all theta. A rhythmic current sink remains in the mid-apical dendritic zone of CA1
pyramidal cells, a reﬂection of the CA3 theta output, and another dipole remains in
the stratum lacunosum-moleculare, perhaps reﬂecting the inhibitory actions of the
O-LM interneurons. Intrinsic conductances can further enhance the synaptic cur-
rents. Anita Kamondi, in my laboratory, recorded from thin dendrites of CA1 py-
ramidal neurons in the intact animal and found large-amplitude, high-threshold
Ca2+ spikes phase-locked to the theta rhythm. These nonsynaptic transmembrane
currents in active neurons should also contribute to extracellular theta.76
A further complication is that each set of excitatory terminals is matched by a
family of interneurons (Cycle 2). The partner interneuron group of the entorhi-
nal–reuniens input to the distal dendrites of pyramidal cells is the O-LM cells. By
a feedback action, an active CA1 place cell can potentiate its O-LM interneu-
ron(s), which in turn can prevent both synaptic excitation and Ca2+-spike–mediated
depolarization of the distal dendrites of neighboring pyramidal cells: a “winner-
take-all” scenario. The CA3 excitatory input is matched by the bistratiﬁed in-

Navigation in Real and Memory Space
313
77. Csicsvari et al. (1999) and Klausberger et al. (2003, 2004).
terneuron family. Both the dendrites and the extensive axon collaterals of these
cells are conﬁned to the oriens and radiatum layers, the target zones of the CA3
pyramidal cells. The basket family of interneurons also appears critical because
they ﬁre rhythmic bursts of spikes at theta frequency, thereby inducing inhibitory
currents in the perisomatic region. Although these and nearly all other interneu-
ron types are entrained to the rhythm, their maximum activity referenced to the
phase of the theta cycle differs systematically, as our collaborative work with
Thomas Klausberger and Peter Somogyi has shown.77 It is hard to imagine how
such an elaborate phase scheme would arise from a centralized septal pacemaker
alone. The multiplicity of the theta current generators may also explain why pre-
vious “lumped” models, using a single “representative” neuron, have failed to ac-
count for the many facets of theta oscillations. Network models, which include
intracellular properties of the constituents, have yet to emerge because they re-
quire information about the instantaneous ﬁring patterns of the neurons contribut-
ing to the extracellular ﬁeld.
Place-Cell Firing Is Phase-Guided by Theta Oscillations
If theta activity is the macroscopic correlate of behavioral navigation, and if hip-
pocampal pyramidal cells generate internal maps for the animal, one might sus-
pect that there is a link. Although several laboratories found a quantitative and
reliable relationship between cell ﬁring and theta phase using long recording
epochs, these studies did not explicitly deal with place cells. On occasions, when
I have consulted O’Keefe on the matter, he assured me that there is no relation-
ship between theta waves and place-cell activity, or at least he cannot see one. In
fact, the faster a place cell ﬁres, the more likely that one can see spikes on every
possible phase. The vague explanation was that strongly activated place cells
could perhaps somehow escape from the enslavement to the common rhythm. Or
perhaps the two phenomena, place-cell ﬁring and theta oscillations, may signal
different meanings. After all, landmark navigation by triangulation does not need
a time metric. There was no immediate solution, and theta ﬁeld and place-cell
studies continued to be investigated independently in different laboratories.
At the same meeting where Ranck unveiled his newly discovered head-
direction cells, a discussion was dedicated to the different types of theta oscilla-
tions. There were two candidates: cholinergic theta, which we equate today with the
intrinsic CA3 theta generator, and the noncholinergic theta, corresponding to the
entorhinal cortex–mediated large-amplitude oscillation. In the course of the dis-
cussion, O’Keefe suggested that perhaps we should
speculate about the possibility that in fact there are various phase relationships that
can occur between these two EEG patterns, and may be part of the function of the

314
RHYTHMS OF THE BRAIN
78. Buzsáki and Vanderwolf (1985), p. 386.
79. See general discussion in Buzsáki and Vanderwolf (1985). The discovery of phase precession
is described in O’Keefe and Recce (1993). Unknown to these authors, an analogous phenomenon, er-
ror precession, had been described previously. Dunlap (1910) reported that when subjects had to syn-
copate in synchrony with a metronome, the timing errors tended to occur in advance of the next beat.
The errors grew systematically until a correction occurred. Dunlop attributed the error precession to a
frequency mismatch between stimulus and response, not unlike the two-oscillator interference model
of O’Keefe and Recce. More recent experiments by Chen et al. (1997; 2001) demonstrate that timing
errors are characterized by a 1/fα type of power law. The authors suggest that the 1/fα type of long-
range correlated timing errors reﬂect distributed neural processes acting on multiple time scales. An-
other phase precession example is the relationship between temperature and the sleep/wake cycle.
Analysis of sleep durations of volunteers isolated in caves or windowless rooms showed that free-
running sleep/wake patterns obey a simple rule: the phase of the circadian temperature rhythm at bed-
time correlates with the lengths of both prior wake and subsequent sleep phases (Strogatz et al., 1986).
Since the two oscillations are slightly different in frequency, sleep times shift systematically along the
temperature phase.
80. Below, I discuss how, although spikes can occur at any phase, spike density is highest at the
trough of the theta cycle, signaling the middle of the place ﬁeld. If theta is conceived as an order pa-
rameter of assembly activity, the trough serves as an attractor.
EEG is to create interference patterns as a function of the different phases of these
two theta waves. This might be a beginning to examine the function of these theta
waves.78
Nine years later, he cracked the puzzle. O’Keefe’s insight was that the interfer-
ence of two oscillators beating at slightly different frequencies but acting on the
same neurons can systematically affect spike timing. He and his student Michael
Recce provided experimental support for the hypothesis by showing that the
spikes of a place cell shift systematically relative to the phase of the ongoing theta
oscillation. They called the phenomenon “phase precession.”79
O’Keefe was right all along. Spikes of single place cells can occur at virtually
any phase of theta.80 However, such a wide phase distribution is not due to ran-
dom noise, because there is a unique and systematic relationship between spikes
and theta phase. As the rat enters the ﬁeld, the spikes occur near the peak of theta
waves, recorded at the CA1 pyramidal layer, and the spikes may retard a full cy-
cle as the animal passes through the entire receptive ﬁeld of the cell. As a result,
the phase of spikes and the animal’s position on the track are correlated. The ﬁr-
ing rate behaves differently. The rate of single place cells is not an explicit marker
of position, because it is confounded by the gain of locomotion velocity. Further-
more, rate increases and decreases as the animal moves in and out of the ﬁeld. In
contrast, the phase of the place-cell spikes shifts monotonically as a function of
the rat’s position on a linear track. The relationship between position and spike
phase, also called “slope of phase precession,” is independent of ﬁring rate or the
speed of the animal and depends only on the size of the place ﬁeld. Ideally, the
slope is a line between the beginning and end of the place ﬁeld, spanning 360° of
phases. The asymmetric nature of phase precession is therefore qualitatively dif-
ferent from the plane-symmetric ﬁring rate distribution.

Navigation in Real and Memory Space
315
81. Phase is a relative variable, an abstract relational quantity that can be realized by many differ-
ent effector systems. Relative phase may be used for the cooperation/integration of similar and segre-
gation of dissimilar assemblies. Of course, in the physical world, it is time, not the abstract phase, that
matters. For an exhaustive list of phase precession models, see Zugaro et al. (2005). Perhaps the ﬁrst
investigator to exploit phase as a coding mechanisms was Bernstein (1967), who emphasized that per-
formance of any kind of complex movement can result from an inﬁnite variety of possible combina-
tions of the several hundred neuromuscular and skeletal elements. E.g., we can utter comprehensible
sentences with our mouth full or one side of the face anesthetized after leaving the dentist ofﬁce, us-
ing entirely different combinations of muscles than we normally do. His engineering solution to the
problem of inﬁnite complexity was self-organization of the neuronal pools aided by oscillatory pat-
terning of motor units. The oscillation can serve as a temporal coordinator for the sequential activation
of different muscle groups that are active during different phases of the cycle.
82. In light of what we know about the mechanisms of theta ﬁeld generation by cell assemblies, it
is hard to envision how rate and phase could be independently manipulated (Hirase et al., 1999; Har-
ris et al., 2002; Mehta et al., 2002). If rate changed completely independently of the phase, it is difﬁ-
cult to explain the relationship between membrane polarization, spiking, and the generation of the
extracellular mean ﬁeld (see Buzsáki, 2002).
83. The evolution of this view (Huxter et al., 2003) is interesting because, in the original treat-
ment of the subject (O’Keefe and Nadel, 1978), the authors considered the possibility that the addi-
tion of time to the spatial map in humans can provide the basis for an episodic memory system (see
also Nadel and Eichenbaum, 1999), but this was rejected subsequently. “I reiterate the basic tenet of
the cognitive map theory that the processing and storage of spatial information is the primary and
perhaps exclusive role of the hippocampus in the rat, and that the data that appear to contradict this
have been misinterpreted” (O’Keefe, 1999, p. 353). A convenient but disputable way to settle the is-
sue would be the declaration of species differences of hippocampal computation, as is implicit in the
quote. I view these things differently. Perhaps the most interesting and challenging question in this
ﬁeld is how a given physiological mechanism that evolved in a small-brain animal (e.g., navigation in
physical space) can be exploited for more complex tasks in humans (e.g., memory storage and re-
trieval).
The phase-precession demonstration was the ﬁrst convincing example of the
long-suspected temporal “code,” and it has remained the most compelling evi-
dence in support of the critical role of oscillations in brain function. The possibil-
ity of a causal relationship between the timing of spikes and overt behavior
spawned dozens of computer models exploring possible mechanisms.81
With the discovery of phase precession, timing directly entered the ﬁeld of
place-cell research, offering the opportunity to combine space and time in the
service of episodic memory. Surprisingly (at least to me), O’Keefe has regarded
the phase precession phenomenon as yet another piece of evidence in support
of the allocentric, map-based theory of the hippocampus, even though omnidi-
rectional place cells are not observed in the one-dimensional linear track, the
apparatus in which the phenomenon of phase precession was discovered. He
suggests that ﬁring rate is not critical for place coding, making the liberated rate
dimension available for coding something else, such as episodic memory.82
Paradoxically, in the proposed dual coding scheme, time (phase) is assigned to
map-based navigation, which does not need it, whereas timing is taken away
from episodic memories, which do.83 Below, we try to address this paradox and
ﬁnd some common grounds for navigation in rats and episodic memory in
humans.

316
RHYTHMS OF THE BRAIN
84. Bidirectional neurons are present occasionally in one-directional environments, e.g., at the
corners of a rectangular track (Dragoi et al., 2003) or if objects are placed on part of the track
(Battaglia et al., 2004). Corners and objects may elicit lateral turns and therefore multiple viewings of
the same position, which can give rise to junctional (omnidirectional) neurons.
85. There is another procedural difference. In a free-recall task, human subjects sequentially in-
spect items in a single trial and are asked to repeat them in a later session. In contrast, rats on a linear
track are tested repeatedly.
Sequence Coding by Theta Phase Ordering 
of Neuronal Assemblies
The simplest form of dead-reckoning navigation is moving along a straight line,
for example, sailing from Genoa to Valencia and back or running back and forth
on a linear track for a food reward. Since there are no junctions, there is no need
for maps or omnidirectionally (explicitly) discharging place cells. Indeed, be-
cause omnidirectionality of place cells is the hallmark of landmark navigation,
the unidirectional nature of hippocampal neurons on linear tracks and the run-
ning wheel can be taken as evidence for the lack of map formation in one-
dimensional tasks.84 On the other hand, coding for ordered locations and
distances is analogous to learning an episode of sequentially presented or visited
items. Both location sequences on a linear track and episodic sequences of arbi-
trary items are unidimensional; therefore, position relations correlate with tem-
poral relations. The ordered locations and their distances can be computed from
the theta period and the velocity-dependent ﬁring rates of hippocampal neurons.
In human subjects, episodic memory performance is tested by subsequent
free recall.85 In the absence of access to free recall in animals, one can investi-
gate the parallel between episodic learning and behavior in animals only by
comparing the deﬁning features of free recall and the neuronal correlates of
dead reckoning on a linear track. As discussed above, free-recall tests indicate
that stronger associations are formed between stimuli that occur near each other
in time than between those that are separated by a greater interval; this relation-
ship also holds for higher order distances. Furthermore, forward associations
are stronger than backward associations. If these features are revealed in the re-
lationship of hippocampal cell assemblies, they may be used to support the
view that the neuronal mechanisms of episodic memory and dead reckoning are
analogous.
In support of the above hypothesis, there is an important phenomenon em-
bedded in the systematic phase relationship of place-cell spiking to the theta cy-
cle. Place cells have long and heavy tails, the consequence of which is that
spikes of many neurons often overlap in time. During successive theta cycles,
multiple neurons, representing overlapping place ﬁelds, shift together in time
and sustain a temporal order relationship with each other so that the cell that ﬁres
on the earliest phase represents a place ﬁeld whose center the rat will reach ﬁrst
(ﬁgure 11.14). At a constant running velocity, the spatial position of the animal is

Navigation in Real and Memory Space
317
correlated with both the ﬁring rate of a given place cell and the phase of spikes
within the theta cycle. Therefore, the spike phase in a given cell provides an esti-
mate of the distance traveled from the beginning of the place ﬁeld. However, this
distance information varies from cell to cell, since the slope of the phase preces-
sion depends on the size of the place ﬁeld of the neuron. Thus, the distances be-
tween sequentially visited places cannot simply be calculated from the phase
precession slope of individual place cells. Some other mechanism is needed for
distance computation.
Taking two or more place cells into consideration, the distances between ad-
jacent place ﬁeld peaks can be estimated from the temporal relationship of the
Figure 11.14. Representation of spatial distances by temporal correlation between spikes
of hippocampal neurons. Top: Mean ﬁring rate changes of ﬁve place neurons (a–e) as the
rat traverses sequential locations on an elevated track. Middle: Spikes of each neuron dur-
ing the same travels as a function of location (x-axis) and the phase of the theta cycle
(y-axis). Note that for all place cells the highest ﬁring rates occur on the trough of the theta
cycle (180°). Lower left: Temporal correlation between neurons d and e. Note that the max-
imum rate of discharge of neuron e occurs approximately 60 milliseconds after the refer-
ence spikes of neuron d. Lower middle: relationship between distances between place ﬁeld
peaks (e.g., d and e in top panel) and temporal delays (e.g., d and e in lower left panel).
Note that distances between place ﬁelds correlate with the temporal delays between spikes
of the respective place cells. Lower right: Within theta cycles, the temporal order relation-
ship of neurons represents place ﬁeld differences. This temporal “compression” mecha-
nism allows for the strengthening of synapses not only between neurons representing
adjacent places but also nonadjacent (higher order) relationships. Reprinted, with permis-
sion, from Dragoi and Buzsáki (2006).

318
RHYTHMS OF THE BRAIN
corresponding neuronal spikes at two different time scales. The ﬁrst scale is triv-
ial and corresponds to the time it takes the rat to traverse the distances between
place ﬁeld peaks, deﬁned by the maximum ﬁring rate of each place cell in its
ﬁeld center. However, there is also a shorter or “theta period scale,” at which the
same distances are represented by the temporal relations of spikes at the tens of
millisecond time scale. In essence, the place ﬁeld sequences on the one-
dimensional track are “compressed” into time/phase sequences of the theta os-
cillation.86
The discovery of the temporal coordination of neuronal spikes by theta oscil-
lations offered new insights into the assembly functions of hippocampal neurons.
William Skaggs and Mayank Mehta, working in the laboratory of McNaughton
and Carol Barnes, suggested that the spike timing relationship of neurons, repre-
senting successive positions in the linear track, was just perfect for the short time
window needed for spike-timing–dependent plasticity.87 According to the spike-
timing–dependent plasticity rule, a strong suprathreshold synaptic input always
increases the synaptic strengths of subthreshold inputs that have occurred a few
tens of milliseconds earlier. The plasticity rule, together with the sequential acti-
vation of neurons within the theta cycle, may be the key for tying together se-
quential places and items into meaningful episodes. How this may happen is
discussed next.
Mechanisms of Theta Phase Precession
Transient phase coupling of two or more oscillators with different frequencies is
an effective method for producing a continuously moving phase vector. As I have
shown above, the discovery of phase precession in hippocampal place cells also
sprang out from the idea of two interfering oscillators, tentatively identiﬁed with
the entorhinal input (noncholinergic) and the intrahippocampal CA3 (cholinergic)
theta oscillators. However, interference of two harmonic oscillators can explain
phase precession only of single spikes. For the increased neuronal ﬁring as a
function of position within the place ﬁeld, an additional mechanism is needed.
Furthermore, the simple interference mechanism would also suggest that the
properties of the global oscillators similarly affect the phase-locking of all place
cells, with the consequence that all place cells have the same phase precession
slope. This is not the case. The slope, the correlated place ﬁeld size and the ﬁring
rate vary considerably among neurons.
A reﬁned version of the dual-oscillator model operates at a single-cell level,
where a transient dendritic depolarization from spatial inputs produces a
86. Skaggs et al. (1996) pointed ﬁrst to this time-compression mechanism. The original version of
this paper was rejected by the Journal of Neuroscience, due to an unfavorable review by one of the ref-
erees. Ironically, the original manuscript by O’Keefe and Recce (1993) was also rejected. It did not
matter. Both papers, eventually published in Hippocampus, became highly cited pieces.
87. Although this notion is also presented in Skaggs et al. (1996), Mehta et al. (1997) provided
speciﬁc experiments, and Blum and Abbott (1996) modeled how spike timing can be exploited for se-
quence coding.

Navigation in Real and Memory Space
319
88. Our intradendritic recordings from CA1 pyramidal cells in vivo provided the experimental ba-
sis for this hypothesis. Strong intradendritic depolarization by a voltage ramp of about 1 second, mim-
icking the dendritic depolarization of the place cells as the rat approaches the center of the ﬁeld,
produced voltage-dependent oscillations in the dendrite slightly faster than the ongoing ﬁeld theta
rhythm (Kamondi et al., 1998). However, models based on interference of oscillations predict that if
one or both oscillators are reset, it should lead to an interruption of phase precession. This is not the
case in the hippocampus. Single-pulse electrical stimulation of the CA3 collaterals resets the phase of
the theta cycle and silences all hippocampal neurons for about 200 milliseconds. If such pulses are de-
livered while the rat is passing through a place ﬁeld of an assembly, the recovered spikes occur on the
phase of the theta cycle as in control runs (Zugaro et al., 2005). This could occur because the nondis-
turbed grid cells in the entorhinal cortex, coding for the previous position of the rat, can initiate the
readout sequence determined by the dynamics of the CA3 recursive network (described further be-
low). Moser et al. (2005) conducted a similar theta perturbation experiment, although phase recovery
of place cells was not explicitly examined.
89. Kamondi et al. (1998), Harris et al. (2002), and Mehta et al. (2002). The relationship between
rate, theta phase precession, and ﬁeld size would suggest that, on average, ﬁring rates in the ventral
hippocampus have lower ﬁring rates and less steep phase precession slope than place cells in the dor-
sal hippocampus. However, the observation that neurons with small and larger place ﬁelds can occa-
sionally be found next to each other indicates that mechanisms other than a simple extrinsic excitation
must be at work.
90. This is explicitly stated in Skaggs et al. (1996) and implicit in most other models.
voltage-dependent oscillation at a frequency slightly faster than the general so-
matic pacemaker theta input.88 The predictions of the hypothesized “single-cell
pacemaker” model is that neurons with stronger spatial inputs oscillate faster and
therefore have steeper phase precession slopes and smaller place ﬁelds. A corol-
lary prediction is that neurons with stronger dendritic excitation should discharge
at a higher rate, resulting in a correlation between ﬁring rate and the magnitude of
spike phase advancement.89 In the hypothetical single-cell oscillator model, the
slope of phase precession of place cells depends only on the magnitude of the ex-
ternal spatial inputs. If place cells are sequentially activated on the track, a direct
consequence of the single-cell model of spike phase precession is the theta–time-
scale temporal correlation between neuron pairs with overlapping place ﬁelds.90
Because no interactions among neurons are needed in this simple model, the
“ideal” phase precession slope for a given place cell in any given trial would be
that of the average slope across all trials. Deviation from this average in a partic-
ular trial can be attributed to some unaccounted “noise.”
A different way of thinking about the theta–time-scale correlation among neu-
rons is that sequential positions on the track are represented by unique sets of cell
assemblies, and phase precession of spikes is a result of temporally coordinated
activity within and between anatomically distributed groups of sequentially acti-
vated cell assemblies. At the very least, the synaptic interactions among neurons
should account for the trial-to-trial variability of phase precession. An analogy
may be helpful here to illustrate the differences between the pacemaker and cell
assembly models. Imagine musicians of an orchestra playing their parts in isola-
tion, supervised by a metronome timer only. Once all the musicians have played
their parts separately, the recorded pieces are combined into a single set. I do not

320
RHYTHMS OF THE BRAIN
91. In the synaptically connected assembly model, both external inputs and internal synaptic con-
nections are important. Suppose that eight sequential environmental positions will produce similar de-
polarizing–repolarizing ramps, lasting for about 1 second, in groups of cells. The group with the same
input is deﬁned as an assembly. Upon depolarization, the groups oscillate slightly higher than theta
frequency. As the rat passes the ﬁrst position and approaches the next, the ﬁrst oscillating assembly ex-
erts a force (i.e., excitation) on the trailing assembly oscillator and advances its phase, etc. The synap-
tic strength between the assemblies determines the magnitude of the advancement (i.e., the time/phase
difference within the theta cycle between members of successive assemblies). A conceptually similar
spinal cord network explained the forward swim of the lamprey (Ermentrout and Kopell, 1994).
92. In the autoassociator model, distances in physical space are stored in the synaptic strengths among
CA3–CA3 pyramidal neurons. Our analyses suggest that distance–time relations and, by extension,
distance–synaptic strength relations are also present in CA3–CA1 synapses (Dragoi and Buzsáki 2006).
have to convince the reader that the quality of the metronome-paced cut-and-paste
piece would never match the quality of a real, concert hall performance, where in-
teractions among musicians are available at a much ﬁner time scale than supplied
by the metronome-supplied beat (ﬁgure 11.15). Hippocampal neurons, like the
members of the orchestra, are embedded in an interactive synaptic environment,
and the timing of their action potentials is biased not only by theta oscillation pac-
ing but also by all their synaptically connected and spiking peers.91 A more radi-
cal view is that the interactions among the recurrently connected CA3 place cells
give rise to rhythmic assembly discharges at theta frequency and that these as-
semblies coordinate neurons in the septum by way of the septally projecting long-
range interneurons.
Functional interactions among place-cell peers offer the following hypothesis
of the phase precession effect. The key idea is that sequentially activated cell as-
semblies in the hippocampus are connected by synaptic links, and the strengths of
these synapses are reﬂected by the temporal relations between them.92 George
Dragoi, a graduate student in my laboratory, designed and conducted experiments
to test the coordinated place-cell assembly hypothesis by recording from ensem-
bles of hippocampal neurons simultaneously while the rat was walking clockwise
or counterclockwise on a rectangular track. Distances between place ﬁeld peaks
of place-cell pairs on the track were correlated with their theta–time-scale corre-
Figure 11.15. Temporal correlations can occur due to an external pacemaker or emerge
from interactions among neurons. In the interactive (“orchestra without a conductor”) case,
temporal coordination among spikes can be more precise and better coordinated at a ﬁner
temporal scale.

Navigation in Real and Memory Space
321
93. Compression of items into theta cycles is reminiscent of the mnemonic technique called
“chunking.” Chunking is best known in the task of memorizing a string of numbers in short-term
memory. Typically seven (± two) “items” are chunked together (Miller, 1956). Adding tune and tempo
to arbitrary sets of items is known to enhance memorization and has been exploited by school teach-
ers for generations. Memorizing long strings of random letters, e.g., “SPWFMRITHETAAPEEG-
PETSFN” is easier if they are chunked into “SPW, fMRI, THETA, AP, EEG, PET, SFN.”
94. Dragoi and Buzsáki (2006). The oscillatory dynamics-based temporal coordination among
neurons is reminiscent of attractor-based dynamical models (Tsodyks et al., 1996; Wallenstein and
Hasselmo, 1997; Samsonovich and McNaughton, 1997; Jensen and Lisman, 1998, 2005).
95. Because individual place ﬁelds vary in size, introducing noise to the superimposed ﬁelds, it is
expected that the clouds would be much better segregated if all neurons in the hippocampus could be
recorded simultaneously and displayed similarly during a single trial.
lation, a measure we called “sequence compression.”93 We exploited the observa-
tion that the trial-to-trial variability of phase precession of single neurons be-
comes larger after the rat leaves the center of the ﬁeld compared to approaching
it. Adding enough time jitter to the spikes emitted during the approach to the ﬁeld
center, we equalized the phase precession variability of individual neurons. This
procedure therefore neutralized the contribution of the hypothetical intracellular
oscillator in single place cells. Despite the added spike time jitter and the similar
phase precession slopes, we found that the sequence compression (i.e., spike tim-
ing coordination among neurons) was still more reliable in the approach part than
in the exit part of the place ﬁelds, supporting the idea that the “excess correlation”
in spike times derives from either direct or interneuron-mediated synaptic inter-
actions among members of the active assembly.94
Let me illustrate the same idea differently. Imagine that one could monitor the
spiking activity of every neuron in the hippocampus, while the rat moves across
the receptive ﬁeld of a single place cell and its assembly members. Such a dis-
play would allow the observer to follow the evolution of multiple assemblies
over time and identify all neurons that contribute to the representation of a single
position or an episode item. The dot display of ﬁgure 11.16 approximates this
imaginary population pattern. In the real experiment, instead of recording from
all cells simultaneously, ensembles of neurons were recorded from several ani-
mals over multiple sessions, and all place ﬁelds were superimposed to represent
an “average” receptive ﬁeld.95 The large X at zero time lag and zero distance cor-
responds to the occurrence of spikes of the reference neurons at the peak of their
place ﬁelds (i.e., zero distance) averaged over multiple trials. The small dots cor-
respond to the averaged time-spatial position occurrence of spikes of the partner
neurons. The most important aspect of the illustration is that a given position is
not simply deﬁned by the time-discrete discharge of a cell group. Instead, the
representation evolves and dissolves over time. Seven to nine “clouds” can be
recognized, with centers separated by 110–120 millisecond intervals, related to
the duration of theta oscillation. Spatial distances are repeatedly represented by
the discharges of the partner neurons, beginning approximately 500 millisec-
onds before the animal reaches the center of the place and lasting for another 500
milliseconds until the rat exits the ﬁeld. The accuracy of predicting the ﬁeld

322
RHYTHMS OF THE BRAIN
center gradually increases in subsequent theta cycles as the animal approaches
the center, corresponding to the densest central cloud. The spatial extent of the
central cloud is 30 to 40 centimeters, which reﬂects the mean size of a place ﬁeld
in the dorsal hippocampus and the grid size of the neurons in the dorsomedial
entorhinal cortex.
Because the average walking velocity of the rat on the track is 30 centimeters
per second, corresponding to approximately 5 centimeters of travel per theta cy-
cle, shifting parts of the same ﬁeld are repeatedly and intermittently represented
by the same groups of cells in six to nine subsequent theta cycles. The neuronal
sequences are direction speciﬁc because plotting the same reference spikes with
100
100
cm
0
Distance between fields
Spike time shifts (msec)
sec
0.5
0
0.5
X
Figure 11.16. Temporal coding of metric distances by cell assemblies: discharge timing
of partner neurons (dots) relative to the spikes of a chosen place cell in the middle of its
ﬁeld (X) as a function of the rat’s travel. Time zero is the spike occurrence in the middle of
the ﬁeld. Note multiple clouds of dots, reﬂecting precise temporal representation of place
ﬁeld distances nested within the repeating theta cycles. Reprinted, with permission, from
Dragoi and Buzsáki (2006).

Navigation in Real and Memory Space
323
the same partner neurons on the opposite journey on the track does not show com-
parable clouds.
Due to the long and heavy tails of the place ﬁelds, several place cells are ac-
tive in each theta cycle, but the assembly composition varies from cycle to cycle.
The whole extent of the ﬁeld is represented only once in the central cycle, sur-
rounded by place cells of past and future positions. This complex representation
of positions and distances by the evolving and dissolving cell assemblies can be
elucidated by the following example. When looking out of the window of a mov-
ing train and ﬁxating on distant objects as they move past, one makes successive
rapid eye movements parallel with the direction of the motion of the train. Be-
tween the fast eye moments, shifting but overlapping sceneries will be repeatedly
surveyed. In each scanning eye movement, a new segment of the scenery is in-
cluded, overlapping with the previous segment. Similarly, assemblies in the hip-
pocampus take overlapping snapshots of approximately 30–40 centimeters of
space in each theta cycle. The neurons that contribute to the deﬁnition of the cur-
rent position are also parts of assemblies representing past and future positions.
The temporal relationship of cell assemblies over multiple theta cycles is an ad-
vantageous mechanism for strengthening the synaptic connections between the
evolving assemblies.
A remarkable outcome of the assembly organization is that the relationship be-
tween successive positions on the track and the theta phase-related discharge of
place cells (i.e., the slope of phase precession) remains the same independent of
the locomotor velocity of the rat. The constant relationship is made possible by
the velocity-dependent gain of place-cell discharge frequency (ﬁgure 11.17). To
illustrate this, let us assume that on two successive trials the rat traverses the place
ﬁeld of the recorded neuron in 1 second and in 0.5 second. In the ﬁrst, slow run,
the place cell will be active in eight theta cycles, but only in four cycles in the sec-
ond faster run.96 However, during the faster run, the place cell is more strongly
depolarized and the number of spikes per theta cycle may double because the
velocity-dependent gain. As a result, the phase shift of spikes from cycle to cycle
is twice as large as during the slow run. In short, the velocity-gain compensates
for the shorter time spent in the place ﬁeld, leaving the relationship between
phase and spatial position unaltered.
Complementary Roles for CA1 and CA3 Cell Assemblies
The representation of distances by theta–time-scale correlations is similar for
CA1–CA1, CA3–CA3, and CA3–CA1 neuron pairs. Nevertheless, CA1 and CA3
assemblies show important differences. The most fundamental difference is that
the discharge probabilities of the CA1 and CA3 populations alternate. CA1 cell
assemblies are attracted to the trough of the local theta waves, whereas CA3 cell
assemblies are most active on the opposite phase of the theta cycle. Because the
96. Although speed has some minor effect on theta frequency, this change is very small, so that
doubling running velocity may increase frequency by only a few percent.

324
RHYTHMS OF THE BRAIN
most numerous excitatory inputs to CA1 pyramidal cells are supplied by the CA3
collaterals, the antiphase discharge correlation of the two populations needs an
explanation.
A reasonable approach is to examine the functional connections within the
feedforward CA3–CA1 system and the distinct population dynamics of each re-
gion. The CA3 excitatory recurrent system is able to maintain self-organized ac-
tivity, as illustrated by the emergence of thetalike oscillation in the isolated slice
preparation. As recurrent excitation builds up, more and more inhibitory neurons
are recruited, which limits and terminates the spread of excitation in the recurrent
system. In other words, excitation and inhibition build up and die in a relatively
parallel manner during the theta cycle in the CA3 region. The buildup of excita-
tion and inhibition also gives rise to a transient gamma oscillation, associated
with the increased gamma-cycle–locked oscillation of basket and chandelier
cells, as Ole Paulsen and his colleagues at Oxford University, working in vitro,
and Jozsef Csicsvari working in the intact hippocampus in my laboratory have
Figure 11.17. Velocity gain of place-cell discharge keeps the spiking phase versus posi-
tion relation constant. Top: On fast and slow runs of the rat through the maze, the number
of spikes emitted in the place ﬁeld of the neuron is approximately constant, whereas the
number of theta waves within the ﬁeld is twice less during fast run than during slow run. As
a result, the number of spikes per theta waves as well as the phase shift of spikes from one
theta cycle to the next is larger during fast runs. Bottom: The rat’s trajectory during the two
representative runs. Dots correspond to the rat’s instantaneous position within the place
ﬁeld. Courtesy of C. Geisler and G. Buzsáki (unpublished observations).

Navigation in Real and Memory Space
325
shown.97 Of course, the axon collaterals of the same CA3 cell assemblies that
give rise to theta and gamma oscillations also excite CA1 pyramidal cells.98 The
result is a temporally coherent increase of gamma power in both regions on the
descending phase of the CA1 pyramidal cell layer theta, which is precisely the
phase when the CA3 recurrent excitation reaches its maximum.
The observation of the antiphase discharge of the CA3 and CA1 cell popula-
tion suggests that the simultaneously built-up CA3 feedforward inhibition pre-
vents most CA1 place cells from discharging. As a result, CA1 neurons can
discharge maximally when their perisomatic inhibition is weakest.99 This may be
the neurophysiological explanation for the abstract term “attractor” at the trough
of the theta cycle. So what causes CA1 pyramidal cells to discharge, and what is
the contribution of the CA3 input besides feedforward inhibition? At present, we
do not have a full explanation, but several clues point to a possible answer. First,
feedforward inhibition in the CA1 region is spatially much more widespread than
the convergence of excitation from a given CA3 assembly. This is a useful mech-
anism for preventing the discharge of those CA1 pyramidal cells that do not re-
ceive convergent excitation from ﬁring CA3 cells. Second, the major
extrahippocampal input to CA1 neurons is the direct layer 3 entorhinal projection.
This pathway has been implicated in determining the place-related activity of
CA1 pyramidal neurons.100 The third clue has been provided by Douglas Coulter
and colleagues at University of Pennsylvania–Philadelphia. Using intracellular
recording and optical imaging in the hippocampal slice preparation, they con-
ﬁrmed the well-known observation that electrical stimulation of the entorhinal in-
put typically evokes hyperpolarization in CA1 pyramidal cells. However, when
the entorhinal input was activated after stimulating the CA3 input, the hyperpo-
larization was converted into depolarization and discharge of the cell.101 The op-
timal interval between the CA3 and entorhinal inputs for discharging CA1
pyramidal cells was 40–60 milliseconds, that is, precisely one half of the theta cy-
cle. The implication is that an active CA3 assembly predicts the future location of
the animal half a theta cycle earlier. If the layer 3 entorhinal input “conﬁrms” the
97. Fisahn et al. (1998), Csicsvari et al. (2003), and Mann et al. (2005).
98. Chandelier cells may be activated in a similar manner (Klausberger et al., 2003). However,
most apical dendrites of chandelier cells are conﬁned to the stratum lacunosum-moleculare, so they
may get less excitation from CA3 pyramidal cells than from basket neurons (Li et al., 1993).
99. The maximum discharge of CA1 pyramidal cells at the trough of local theta is also associated
with the maximum activity of the O-LM interneurons, which are driven mainly by the CA1 place cells
(Klausberger et al., 2003). The discharging O-LM cells and the inhibitory postsynaptic potentials their
terminals produce in stratum lacunosum-moleculare may explain the presence of a current source at
the time when place cells are active. This arrangement can contribute to the isolated activity of place
cells. The winner place cell may prevent a neighboring neuron from discharging by activating the
O-LM neurons in a feedback manner. The winner cell may continue to discharge because its periso-
matic inhibition may be depressed by the release of endocannabinoids, which suppress GABA release
from the inhibitory terminals (Klausberger et al., 2005).
100. Brun et al. (2002).
101. The conversion of inhibition to excitation in response to the entorhinal input is explained
mainly by the transient activation of NMDA receptors by the CA3 collaterals (Ang et al., 2005).

326
RHYTHMS OF THE BRAIN
prediction, the CA1 pyramidal cells will respond. If the prediction is not con-
ﬁrmed, the layer 3 input remains largely ineffective.102 Overall, the combination
of these observations suggests that the CA3 and CA1 systems operate as a func-
tional unit during theta oscillation.
Physiological Deﬁnition of Spatiotemporal Context
Let us now synthesize the ﬁndings discussed so far into a coherent picture (ﬁg-
ure 11.18). Distance information between positions on the linear track is stored
by synaptic weights among neurons of the CA3–CA1 collateral system. Dur-
ing each theta cycle, this large synaptic space is searched, recalling several,
temporally linked cell assemblies. The trajectory in the neuronal space repre-
sents the position sequences that the rat just passed and will traverse during the
next half second or so. The internal sequence readout in the CA3 region is trig-
gered by the previous locations by way of the active grid cells of the entorhinal
cortex. The readout is forward in time, reﬂecting the sequence order during
learning. In each theta cycle, the most active CA3 assembly occurs at the peak
of the theta cycle referenced to the CA1 pyramidal layer and corresponds to
the predicted current location of the rat’s head.103 As the CA3 assemblies dis-
solve, the CA1 assemblies get stronger, partially because of the decreasing
perisomatic inhibition and because of the strengthening of the layer 3 entorhi-
nal input, signaling the current location. The predicted and perceived locations
are therefore replayed in tandem by the most active CA3 and CA1 assemblies,
respectively.
As the animal moves forward, a new cell assembly dominates each theta cycle.
However, the assembly members that deﬁne the current location also contribute
spikes to the representation of the past and future positions in multiple theta cy-
cles. Conversely, the most active CA1 assembly, anchored to the trough of the lo-
cal theta, is ﬂanked by spikes on the descending and ascending phases,
contributed by assembly members of passed and upcoming locations, respec-
tively, corresponding to the rat’s locomotion trajectory on the track. Stated differ-
ently, information about places and distances is not determined simply by single
102. In support of this cooperative effect, Wilson and McNaughton (1993) described that, in a
novel environment, CA1 pyramidal cells remain largely silent for several minutes. Furthermore,
Nakazawa et al. (2002) showed impairment of place-cell activity when only a fraction of the original
cues were presented to mice in which the NMDA receptor gene was genetically ablated speciﬁcally in
CA3 pyramidal cells. In the experiments of Brun et al. (2002), place-cell activity in CA1 was observed
after cutting most CA3–CA1 connections and removing both convergent excitation and feedforward
inhibition. However, Brun et al. also emphasize that many features of the place cells (e.g., ﬁeld size,
dispersion) were quite different from the sharp place ﬁelds found in the intact animal. Recall of spatial
information was also impaired in the CA3–CA1-disconnected rats.
103. Muller and Kubie (1987) also suggested that place-cell ﬁring predicts future locations a few
centimeters in front of the head of the rat.

Navigation in Real and Memory Space
327
assemblies bound to the troughs of theta oscillation but also by the precise tem-
poral sequences within cycles. The sequences within theta cycles precisely reﬂect
the past, present, and future place ﬁeld centers of the sequentially active cell as-
semblies on the track.
In light of the above summary, we can conclude that the current position of
the animal is embedded in the representation of the past and the expected future
in terms of both location and time. In short, the currently coded item is placed
into spatiotemporal context by the theta oscillation mechanism. This context
dependence can explain why a hippocampal place cell, active on a journey in
one direction, may not be active at the same location during the opposite jour-
ney.104
Navigation in Real and Memory Space
After navigating through decades of research on hippocampal single cells and
theta oscillations, and deﬁning context by a physiological mechanism, we now re-
turn to the problem of memory. As discussed above, work in humans suggests that
the hippocampal–entorhinal system is involved in both episodic and semantic
memories. Both types of memory can be verbally declared because they are parts
of the “conscious brain systems.” Research on animals, on the other hand, has
Figure 11.18. Deﬁnition of “context” by oscillatory timing of cell assemblies. The width
of the bars indicates ﬁring rates of the assemblies, and the temporal differences between
assemblies reﬂect distances of their spatial representations. The predicted (CA3) and the
environment-updated (CA1) representations (places P1–P5) are phase shifted. The current
position of the rat’s head is represented by the most active CA1 cell assembly at the trough
of CA1 theta oscillation. This assembly is surrounded by the representation of past and fu-
ture places within the same theta cycle, deﬁning the spatiotemporal context for the most ac-
tive assembly. Reprinted, with permission, from Dragoi and Buzsáki (2006).
104. A prediction of the hypothesis that context is deﬁned by the spatiotemporal sequences of neu-
ronal assemblies is that changing the synaptic strength among neurons should change their sequences
on the track. In support of this prediction, artiﬁcial alteration of synaptic weights by long-term poten-
tiation affected both place ﬁelds and distance representation by neuron pairs (Dragoi et al., 2003).

328
RHYTHMS OF THE BRAIN
105. As discussed above, a map can be generated without vision, as well, in which case each place
must be physically visited. With vision, it may be sufﬁcient that the eye “visits,” i.e., explores, every
place.
106. An alternative view of the episodic memory vs. mapping-based navigation dilemma is that
the hippocampus is a more general system, concerned not only with spatial maps but also with many
other types of nonspatial relations. Howard Eichenbaum at Boston University makes the point that
the spatial map is simply a byproduct of a relational memory system. Relations can be either temporal
or spatial. Eichenbaum designed behavioral experiments in which the relations between spatial or
nonspatial stimuli had to be memorized, and he demonstrated that animals with hippocampal damage
were consistently inferior in solving such tasks (Bunsey and Eichenbaum, 1996). According to the re-
lational hypothesis, individual hippocampal neurons code for sensory cues of any type, other subsets
for their combinations, and yet other groups of cells for relations, including temporal (Wallenstein et
al., 1998; Hampson et al., 1999; Eichenbaum, 2002). However, learning general relations requires
repetition, and the temporal context is optional. In contrast, the essence of episodes is their spatiotem-
poral context, and they can be acquired by a single exposure.
107. Because omnidirectionality of place-cell ﬁring is the hallmark of landmark navigation
(O’Keefe and Nadel, 1978), the unidirectional nature of hippocampal neurons on the linear track can
be taken as evidence of the lack of map formation in one-dimensional tasks.
implicated the hippocampal–entorhinal system in either dead-reckoning or map-
based navigation. The challenging issue is to understand how a useful neuronal
mechanism that evolved in a small-brain animal (e.g., navigation in physical
space) can be exploited for another purpose (e.g., memory storage and retrieval)
at later stages of brain evolution.
Relationship between Episodic Memory 
and One-Dimensional Travel
Let me recapitulate brieﬂy the discussion on dead-reckoning and landmark navi-
gation. In dead reckoning, the distances passed are calculated on the basis of self-
generated cues rather than environmental inputs. This process does not require
repetition. In contrast, map-based navigation requires external cues or at least
their internal representation and is learned by repeated visits to the same posi-
tions. These different strategies can be studied best in one-dimensional and two-
dimensional environments. The prerequisite for forming a map is junction
crossings, that is, visits to the same positions from different directions, which is
ideal in two-dimensional environments.105 It follows that dead-reckoning explo-
ration must precede the establishment of a map. At the neuronal level, the distinc-
tion between the two forms of navigation is illustrated by the unidirectional and
omnidirectional place cells in one-dimensional and two-dimensional environ-
ments, respectively.106 Omnidirectional place cells explicitly deﬁne particular po-
sitions and do not require temporal context or self-reference.107 How do these
forms of navigation relate to memory?
In one-dimensional tasks, representation of the ordered locations and their
relationships is achieved by encoding metric information about distances in
space and direction of movement. This process is analogous to learning an
episode of sequentially presented or visited items. The difference lies in the

Navigation in Real and Memory Space
329
108. Fortin et al. (2004) used such an approach in recognition memory and found a striking simi-
larity between behavioral choice patterns in rats and humans.
109. This external “updating” mechanism is best demonstrated by the recurrence of spikes reﬂect-
ing the correct position of the animal after transiently silencing hippocampal networks (Zugaro et al.,
2005).
110. Such spontaneous phase shifting of spikes is rarely observed during running but is a common
in REM sleep (Harris et al., 2002). Most neurons in the wheel-running task sustain steady discharge
rate, although some show phase-precession (Czurkó et al., 1999; Hirase et al., 1999).
nature of the inputs rather than the nature of hippocampal computation. An
ideal structure for episode coding and recall is an autoassociator, since free re-
call is essentially a pattern-completion problem. The asymmetric nature of the
recursive CA3–CA3 and CA3–CA1 connections, combined with temporal or-
dering of cell assemblies and spike-timing–dependent plasticity, favor tempo-
rally forward associations. Similar to the physical distances on the linear track,
positional “distances” among items of an episodic list can be coded by the
synaptic strengths between the cell assemblies, which represent the items. Be-
cause distance representations are brought together into the cycle time of theta,
not only temporally adjacent but also noncontiguous items can be linked to-
gether by synaptic plasticity. These higher order links can be established be-
cause the probability of anatomical connections among any cell pairs is similar
in the hippocampus. Therefore, it is the timing rule of synaptic plasticity that
functionally connects assembly A more strongly to assembly B than to assem-
bly C in the sequence (see ﬁgure 11.14). However, if for some reason assembly
B cannot be recalled, the excitation spreads toward the next best-connected as-
sembly, which is C.
In humans, performance is tested by later free recall, in the absence of external
explicit cues. This recall can occur if the most active cell assembly in a given
theta cycle, encoding the remembered item “calls up” the next best-connected as-
sembly, which also reﬂects the order of the learned sequence. Due to the lack of
access to free recall in animals, this critical feature can be examined only indi-
rectly by comparing the fundamental features of free recall and neuronal corre-
lates of behavior.108 However, on a linear track, environmental cues constantly
supervise and affect the direction of activity sequences by updating the content of
each theta cycle, similar to cue-guided story-telling of episodes.109 In contrast,
spontaneous or free recall requires that the cell assembly sequences of subsequent
theta cycles be advanced by the content of the previous cycle rather than by exter-
nal cues. Supporting this possibility, we observed spontaneous changes in ﬁring
rate and associated phase precession of place neurons while the rat was running in
a wheel with its head staying stationary.110 Because environmental and self-
motion cues were kept constant, such “spontaneous” phase precession could have
been brought about by shifting cell assemblies in successive theta cycles. These
internally generated sequences can be potentially regarded as neuronal correlates
of episodic recall.

330
RHYTHMS OF THE BRAIN
Relationship between Semantic Memory and Spatial Maps
With the link between navigation in one-dimensional task and episodic memory
established, let us turn to the relationship between spatial maps in two-dimensional
tasks and semantic memory. As discussed above, place cells in one-dimensional
travel have unidirectional place ﬁelds, determined primarily by the position se-
quences passed. This situation changes dramatically if paths of the navigation
cross, as happens routinely during exploration. Now the activated neurons at the
crossroads will be tied to different routes or episodes.111 The establishment of such
junctions and the emergence of omnidirectional place cells mark the emergence of
a map. The omnidirectionality of place cells can therefore be taken as evidence
that the rat approached a position or landmark from multiple directions. Omnidi-
rectionality is thus an indication that the place cell has become part of multiple
neuronal trajectories, and its activation no longer depends on a unique temporal se-
quence of particular cell assemblies. Once established, omnidirectional place cells
no longer require a temporal context. They become explicit gnostic units.112
Applying the same idea to humans, multiple episodes with common junction
items can free the common item from its context. If the same junction points of
the episodes are traversed repeatedly by other episodes, they no longer require
the temporal context of item sequences. For example, discovery of a new neuron
type or a novel oscillation is an episode, reﬂecting a series of exciting and memo-
rable events through space and time for those involved. However, after the obser-
vations are conﬁrmed in multiple laboratories, the pioneers and the conditions of
the initial discoveries become irrelevant and the convergent or joint elements of the
research lose their spatiotemporal context and become scientiﬁc facts. Multiple
overlapping observations with common junctions are therefore the source of se-
mantic knowledge. Seeing a dog for the ﬁrst time in life is an episode. However, af-
ter seeing many different dogs and pictures of dogs, the universal features assume
a semantic meaning: a common name.113 Neuron members of an omnidirectional
or explicit assembly collectively deﬁne or symbolize the “meaning” of an item. Such
explicit, higher order representation is invariant to the conditions that created it.
Although dead-reckoning navigation and episodic memory are requisites of
landmark-guided maps and semantic information, storage of consolidated se-
mantic knowledge may no longer require the large combinatorial associational
network provided by the hippocampus.114 Once maps and semantic information
111. A similar explanation for the multidirectionality of place cells was offered to by Eichenbaum
(2002) and Brunel and Trullier (1998).
112. Such explicit representation by hippocampal neurons has been documented in humans, as
well (Heit et al., 1998; Quiroga et al., 2005).
113. Computer models of categorization that learn via changes of connections work in essentially
the same manner (McClelland et al., 1995). The categories generate a context that facilitates the re-
trieval of memories. E.g., if a list of items involving faces, locations, and objects is presented, during
the recall process items in the same categories tend to cluster. There is no consensus yet on the mech-
anisms of semantic memories, and their episodic origin is debated.
114. For a more exhaustive discussion of this topic, see Buzsáki (2005b).

Navigation in Real and Memory Space
331
are solidiﬁed, they can be transferred to neocortical destinations. However,
transfer of information needs another type of oscillation, which is discussed in
Cycle 12.
Brieﬂy . . .
The hippocampus is the ultimate search engine for the retrieval of archived in-
formation. In this Cycle, we examined how hippocampal theta oscillations are
related to episodic and semantic memory, “dead reckoning” (or path integration),
and “map-based” (or landmark) navigation. These concepts have been associated
with the hippocampal–entorhinal system, primarily on the basis of lesion cases
in humans and unit and ﬁeld recording studies in smaller animals.
The hippocampus and associated structures are organized in multiple loops
and are part of the allocortex, with reciprocal connections to the neocortex. The
most prominent collective pattern of hippocampal neurons is theta oscillation, a
sustained rhythm associated with explorative navigation. A consortium of circuit
and single-cell properties supports theta oscillations, which provides timing for
individual hippocampal pyramidal and granule cells and the principal cells of the
limbic system. The major theta current generator in the hippocampus is the en-
torhinal input to the distal apical dendrites of CA1 pyramidal cells. Theta cur-
rents in this layer arise from at least three mechanisms. First, currents (sinks)
generated by excitatory postsynaptic potentials are mediated mainly through
NMDA receptors. Another sink is due to rhythmic, voltage-dependent Ca2+
spikes in the distal dendrites that occur in strongly excited neurons. Third, the
discharging CA1 pyramidal neurons activate O-LM interneurons whose main
axon arbors terminate in the stratum lacunosum-moleculare. These synapses set
up inhibitory currents (sources) and compete with the effects of the excitatory
entorhinal input on less activated pyramidal cells (“winner take all”).
The medial septum is a key rhythm generator of theta cycles, but the recurrent
CA3 system can also generate theta oscillations. Interactions between CA3 py-
ramidal cells and basket interneurons also give rise to gamma frequency oscilla-
tions, phase-locked to the slower theta rhythm. Inhibition and gamma power are
built up simultaneously in the CA3 and CA1 regions, the consequence of which
is that pyramidal cells in these sectors, on average, discharge on the opposite
phases of the theta cycle. These various theta oscillation mechanisms are respon-
sible for the temporal organization of pyramidal neurons.
The discharge pattern of single neurons depends mainly on the testing condi-
tions. In one-dimensional tasks, such as a straight track, only dead-reckoning
navigation is possible. Individual pyramidal cells on the track ﬁre maximally at
particular positions, signifying the place ﬁeld center. In CA1 pyramidal cells, the
spikes ﬁrst occur on the peak of theta waves as the rat enters the ﬁeld, ﬁre maxi-
mally at the trough of the theta in the middle of the place ﬁeld and continue the
phase shift up to a full cycle after the rat leaves the receptive ﬁeld of the cell. As

332
RHYTHMS OF THE BRAIN
a result, the phase of spikes and the animal’s position on the track are correlated.
As the rat moves forward, a new cell assembly dominates each theta cycle. How-
ever, the assembly members that deﬁne the current location also contribute
spikes to the representation of the past and future positions in multiple theta cy-
cles. Conversely, the most active CA1 assembly, anchored to the trough of the
local theta, is ﬂanked by spikes on the descending and ascending phases, con-
tributed by assembly member neurons of passed and upcoming locations, re-
spectively, corresponding to the rat’s locomotion trajectory on the track. Because
of the long and heavy tails of the place ﬁelds, multiple cell assemblies are coac-
tive in any given theta cycle. Distances between place ﬁeld peaks of place-cell
pairs on the track are correlated with their theta–time-scale correlation, so that
information about successive metric distances is reﬂected in the precise temporal
sequences within cycles. Because representation of the current position is em-
bedded in the representation of the past and the expected future, the temporal
compression mechanism of the theta oscillation objectively deﬁnes spatiotempo-
ral context, a key ingredient of episodic memory.
Coding for ordered locations and distances is analogous to learning an
episode of sequentially presented or visited items. Similar to the theta cycle
representation of physical distances in one-dimensional tasks, positional “dis-
tances” among items of an episodic list can be coded by the synaptic strengths
between the cell assemblies, representing the items of the episode. Because dis-
tance representations are compressed into the cycle time of theta, not only tem-
porally adjacent but also noncontiguous items can be linked together by synaptic
plasticity. These higher order links can be established because the probability of
anatomical connections among cell pairs is similar in the hippocampus. The cre-
ated links among cell assemblies may account for the contiguity and temporal
asymmetry principles of episodic memory. An ideal structure for episode coding
and recall is an autoassociator with a large random synaptic space, since free re-
call is essentially a pattern-completion problem. The extensive axon arbors of
CA3 pyramidal cells and their recursive CA3–CA3 and CA3–CA1 connections
are ideal for storing large numbers of episodic memories and for retrieving them
efﬁciently.
In two-dimensional environments, exploration leads to crossing the same po-
sitions from different directions. These junctions serve to establish a map and
subsequent landmark (map-based) navigation. The hallmark of the cognitive
map is the presence of omnidirectional place cells in the hippocampus and tes-
sellating “grid cells” in the entorhinal cortex. The omnidirectional discharge pat-
tern in a neuron is an indication that the place cell has become part of multiple
neuronal trajectories and that its activation no longer depends on a unique tem-
poral sequence of particular cell assemblies. Once established, omnidirectional
place cells no longer require a temporal context or self-reference. They explic-
itly deﬁne position.
Analogous to the dead reckoning–to–map transition in the rat, exempliﬁed
by the conversion of unidirectional to omnidirectional neurons, multiple

Navigation in Real and Memory Space
333
episodes with a common item can free the common item from its spatiotempo-
ral context. Neuron members of an omnidirectional or explicit assembly collec-
tively deﬁne or symbolize the semantic “meaning” of an item. Explicit
representation is invariant to the conditions that created it. The short punch line
of this Cycle is that episodic and semantic memory representations may have
evolved from mechanisms serving dead-reckoning and map-based navigation,
respectively.

Cycle 12
Coupling of Systems by Oscillations
Hierarchical operations in the brain indicate not only that representations in
“higher” centers are more complex and abstract than are lower areas, but also
that such sequential, feedforward processing inevitably requires temporal de-
lays. However, bottom-up and top-down distinctions are merely abstractions, a
convenient way to conceptualize activity in brain circuits. In reality, a purely
feedforward scheme is an exception in cortical systems; the typical connectiv-
ity is reciprocal and recurrent innervation. There is no real structural “top” in
neuronal hierarchy since the higher order information in a brain area can be
immediately forwarded back “down” to other areas. The top or end of compu-
tation is generally heralded by time, marked by inhibition of activity, rather
than by some deﬁned anatomical boundary. Neuronal information is pro-
pelled in parallel in multiple juxtaposed and superimposed loops, making the
distinction between the top and bottom processing very difﬁcult. For example,
the psychological construct “attention” is often thought of as a top-down pro-
cess, an intentional act, initiated in some hypothetical “executive” top-level
areas. However, a candidate physiological mechanism of attention is gain con-
trol, which is a quantitative rather than qualitative change, reﬂecting an en-
hanced sensitivity of the processing circuits to inputs. Such enhanced gain in
neuronal networks can be achieved mainly by subcortical neurotransmitters,
such as acetylcholine and norepinephrine, which enhance cortical gamma
It is necessary to study not only parts and processes in isolation, but also to
solve the decisive problems found in organization and order unifying them,
resulting from dynamic interaction of parts, and making the behavior of the
parts different when studied in isolation or within the whole. . . .
—Ludwig von Bertalanffy, Allgemeine Systemtheorie
334

Coupling of Systems by Oscillations
335
1. For the roles of neuromodulators in attention and information processing, see Foote et al.
(1983), Metherate and Ashe (1995), and McCormick (1992). The role of the basal forebrain in en-
hancement of cortical gamma oscillations, see Jones (2005).
2. The concept of “situatedness” expresses this context-dependent synthesis (Varela et al., 1991;
Thompson and Varela, 2001).
3. For thorough and comprehensive reviews of top-down operations, see Engel et al. (2001) and
Miyashita (2004).
oscillations.1 If these neurotransmitters are essential for the attention-
associated gain of neuronal responses, the process is not simply a top-down in-
struction but a loop pattern.
As I have also shown, all cerebral cortical circuits of the mammalian brain can
maintain an autonomous, self-organized activity, independent of the inputs. Thus,
cortical activity is in perpetual motion, and every motor and cognitive act is a syn-
thesis of self-generated, circuit-maintained activity and environmental perturba-
tion, as discussed within the “brain in the body and environment” framework in
Cycle 8.2 Whereas the brain can detach itself from the body and environment to a
large extent (e.g., during sleep), the converse—that is, invariant responses of the
brain irrespective of its state—is true only for elementary reﬂexes involving short
loops. In most situations, the brain’s reaction to environmental changes is not in-
variant but depends on the outcome of previous reactions in similar situations and
on the brain’s current state, determined by the multiple interactions among the var-
ious oscillators. These recent views of brain function emphasize the constructive
nature of adaptive neuronal operations.3 If different brain areas and systems con-
stantly generate their autonomous self-organized patterns, how can they initiate a
conversation and listen to each other? I suggest that the fundamental basis of such
communication and exchange of information is oscillatory phase-locking. In recip-
rocally interconnected systems, temporal ordering of neuronal activity by way of
phase-locking can direct the ﬂow of excitation. Neurons that discharge earlier can
drive the neurons of the trailing oscillator (Cycle 4). By simply reversing the phase
offset, the direction of drive can also be reversed. The main goal of this Cycle is to
illustrate how network and system interactions can be assisted by oscillations.
Coupling of Hippocampal–Neocortical Circuits 
by Theta Oscillations
Because it is largely past experience that determines the brain’s response to envi-
ronmental inputs, it is expected that the dialogue between the hippocampus and
the relevant parts of the neocortex is virtually continuous. Viewed from this context,
it is not surprising that hippocampal theta oscillations are among the rare sustained
rhythms in the brain (Cycle 11; ﬁgure 12.1). This continuous dialogue, in principle,
can be accomplished in several different ways. The simplest and less likely scenario
is that the phasic hippocampal output forces the neocortical assemblies to ﬁre in
phase with theta frequency. The second option is that hippocampal output drives

336
RHYTHMS OF THE BRAIN
Figure 12.1. Theta oscillation in the human hippocampus–entorhinal cortex. Top: A short
trace of unﬁltered EEG, recorded directly from the hippocampus of a patient, during awak-
ening shows dominance of theta frequency oscillations. During REM sleep, the same elec-
trode exhibited short episodes of theta oscillations (Middle, boxed area). Reprinted, with
permission, from Cantero et al. (2003). Bottom: Theta oscillation in the entorhinal cortex, in-
duced by word presentation in a different patient. Trace courtesy of E. Halgren and I. Ulbert.
4. Robert Miller was among the ﬁrst to suggest that hippocampal theta oscillations may drive neo-
cortical circuits through what he called reverberation resonance (Miller, 1989, 1991). He envisioned
that the hippocampal “baseline theta oscillator” would strengthen just those cortical connections
whose combined synaptic-conduction delays are the same as the theta period. Theta then can serve as
the contextual retrieval signal and function as an “index” that can point to the relevant chapters of a
book (Hirsh, 1974; Teyler and DiScenna, 1985).
multisynaptic “reverberating” paths of neocortical–hippocampal loops, and the
combined synaptic-conduction delays in these loops approximate the theta pe-
riod. This would be an example of time-delayed, in-phase synchronization of
limit-cycle oscillators. Because of the consistent and unidirectional phase offsets,
unique resonant loops can be established. Under the resonant loop mechanism,
the macroscopic ﬁeld oscillations may not be prominent or even observable in
neocortical areas. Nevertheless, the sequentially activated assemblies at each site
could be identiﬁed by progressively longer phase delays to the reference hip-
pocampal theta. The neocortical route sequences would not be active on their own
and require the orchestration of the hippocampal rhythm and some external in-
put.4 The third possibility is that various neocortical regions are capable of gener-
ating their own local theta oscillations under the right conditions, such that
hippocampal and neocortical theta oscillators entrain each other. An extension of
this possibility is the stochastic resonant properties of neocortical local circuits,

Coupling of Systems by Oscillations
337
5. Adey was among the ﬁrst neuroscientists who beneﬁted from NASA’s space science program
and, as a result, was able to use computers for the ﬁrst time to process brain signals. His reports were
the ﬁrst to quantitatively assess cooperative mechanisms across different brain regions (Adey et al.,
1960a,b). Unfortunately, the histological locations of the recording electrodes were not revealed in
those reports, and there were large differences across cats. Thus, the observed phases in different cats
could have arisen from implantation of the electrodes in different layers in the hippocampus and en-
torhinal cortex. The training-related phase leads and lags were also confounded by the parallel fre-
quency changes.
which can extract the theta-coded message. The advantages of the second and
third hypothetical mechanisms of hippocampal theta engagement of neocortical
circuits are that coupling can be established by very weak links, and many corti-
cal assemblies can be entrained with short time lags after just one cycle such that
their joint outputs would be synchronized with minimal delays. As a result, distant
cortical networks with nonexistent or weak anatomical connections can orches-
trate their activity in such a way that their temporally locked outputs can select
common downstream assemblies. Overall, these mechanisms in isolation or com-
bination would allow top-down hippocampal–neocortical communication at a
pace determined by the hippocampal theta oscillator.
Before we begin to consider speciﬁc examples, it should be clearly stated
(again) that such a global treatment of oscillators is a questionable oversimpliﬁ-
cation. Descriptions of oscillators at the macroscopic level assume a single, giant
harmonic oscillator and neglect the dynamics of the individual components,
whose properties often crucially determine the nature of coupling or quenching.
Because each network oscillator is composed of large numbers of components,
the macroscopic or lumped models assume that perturbations affect each compo-
nent equally and at the same time.
An early set of experiments that examined the role of theta oscillatory cou-
pling involved the hippocampus and entorhinal cortex, the main hub between the
hippocampal system and the neocortex. Ross Adey and colleagues at the Univer-
sity of California–Los Angeles studied the relationship between hippocampal and
entorhinal theta rhythms in cats that learned a visual discrimination task in a
T-maze. Early in training, hippocampal theta had a phase lead over that in the en-
torhinal cortex, but by the end of training the phase relationship reversed, with en-
torhinal theta oscillations leading the hippocampal signal. Interestingly, such
phase reversals between the two structures also occurred between correct and the
occasional incorrect trials in well-trained animals. On error trials, the hippocam-
pus was leading the oscillations as in the early stages of learning. The learning-
related phase shift was associated with a frequency decrease of the oscillation
from 6 to 5 per second. Also, the frequency of theta oscillation was slower on er-
ror trials than on correct trials.5 One can speculate from these early experiments
that the relative phase-delayed activity of neurons in the hippocampus or entorhi-
nal cortex determined the direction of neuronal communication between the two
structures, and that the direction of impulse ﬂow changed as a result of experi-
ence. This tentative conclusion is further supported by related studies in epilep-
tic human patients with depth electrodes. The subjects in these experiments

338
RHYTHMS OF THE BRAIN
6. Coherence increases in the theta range were correlated with the memory-related changes in rhi-
nal–hippocampal gamma phase synchronization in these same patients (Fell et al., 2001, 2003).
7. Naya et al. (2001).
8. Seidenbecher et al. (2003). For an excellent overview of the role of oscillations in amygdala
function, see Paré et al. (2002).
performed a word list-learning paradigm with a free recall memory test following
a distraction task. Successful as opposed to unsuccessful memory formation was
associated with a general rhinal–hippocampal coherence enhancement of theta
oscillations during encoding, without noticeable alterations in spectral power.6
Studies in monkeys, carried out in Yasushi Miyashita’s laboratory at the University
of Tokyo, provide further support for the training-reversed direction of informa-
tion. In these experiments, the time courses of perceptual and memory-retrieval
signals were monitored, using single-unit recordings in the temporal and perirhi-
nal cortex while monkeys performed a visual pair-association task. The percep-
tual signal reached the temporal cortex before the perirhinal cortex, conﬁrming its
forward propagation. In contrast, memory-retrieval signals appeared earlier in the
perirhinal cortex, and neurons in the temporal cortex were gradually recruited to
represent the sought target.7 Coupling by theta oscillations has also been reported
in the amygdalohippocampal circuit. As a result of fear conditioning, theta oscil-
lations emerged in the amygdala of mice, with the waves in synchrony with hip-
pocampal theta oscillations. Such temporal coordination may allow fear signals
conveyed by the amygdala to be associated with the environmental context pro-
vided by spatial inputs to the hippocampus.8
Scalp recording of EEG in humans has provided indirect support for the role
of theta oscillations in memory functions. Wolfgang Klimesch and colleagues at
the University of Salzburg in Austria have been studying the role of alpha and
theta oscillations in cognitive performance. They distinguish between overlap-
ping bands of theta (6–10 cycles per second), low-frequency (6–10 cycles per sec-
ond), and high-frequency (9–14 cycles per second) alpha oscillations on the basis
of scalp topography and behavioral correlation. Importantly, the borders of the
behaviorally deﬁned bands vary considerably among individuals. Therefore,
lumping frequency bands across subjects without determining the frequency bor-
ders in each individual can wash out important effects because these individual-
ized bands vary independently and often in the opposite direction in different
tasks. After separating the individualized alpha band, Klimesch’s assessment is
that sensory stimuli and semantic memory performance are best correlated with a
decrease of the high alpha power (“desynchronization”), whereas increased theta
power above the occipital region is associated with encoding of new information.
In a typical memory task, discrete visual or auditory items appear one at a time
for a few seconds each. In the recall phase, subjects are presented with some of
the old items (target, e.g., robin) mixed with novel items (distractor, e.g., sparrow)
and are asked to identify items that were part of the original list. The magnitude
of item-induced theta power is generally larger during the retrieval than in the
encoding phase. Critically, the subsequently correctly recalled items in the study

Coupling of Systems by Oscillations
339
9. The many studies of Klimesch and colleagues are reviewed in Klimesch (1999, 2000). See also
Bastiaansen and Hagoort (2003).
10. Working memory, also called “short-term,” “immediate,” “conscious,” “scratch pad,” or “at-
tentional” memory is a mental workspace with limited capacity. It is very sensitive to interference.
One has to continuously rehearse or “keep in mind” the items to prevent forgetting.
11. Gevins et al. (1997) and Sarnthein et al. (1998). The presence of theta rhythm in the anterior
cingulate cortex in humans is directly supported by current-source density analysis of ﬁeld potentials
and multiple-unit activity measurements (Wang et al., 2005).
12. Tesche and Karhu (2000).
phase are associated with a signiﬁcantly larger theta power increase than incor-
rectly identiﬁed items, emphasizing the need for increased theta activity for suc-
cessful speciﬁc encoding.9 It is not simply a general brain state but the speciﬁc
oscillatory constellation that creates favorable conditions for encoding novel in-
formation.
Although it is the theta power that covaries best with cognitive performance,
alpha oscillations may also play an important role, perhaps in an indirect way, as
shown by the observation that in good memory performers the baseline (prestim-
ulus) alpha frequency is about one cycle per second higher than that of bad per-
formers. Due to the poor spatial resolution of the scalp signal, however, the source
of the recorded alpha and theta power has remained unknown. With standard
recording electrodes, it is impossible to conclude whether the power increase re-
ﬂects increased amplitude of theta oscillation at a single site or coherent oscilla-
tions within smaller subregions integrated by the scalp electrode.
Power increase is usually interpreted as increased synchrony, implying phase
coherence of multiple sites, but this claim is hard to justify. Using high-density
scalp recording and a visual working memory task,10 Alan Gevins at the EEG
Systems Laboratory in San Francisco, California, localized the enhanced theta
signal to the region of the anterior cingulate cortex. Theta power increased with
both enhancement of task difﬁculty and practice. In other working memory stud-
ies, using either verbal or visuospatial stimuli, an increase in theta coherence was
observed between the prefrontal cortex and posterior association areas.11 Al-
though these studies connect theta oscillations to declarative and/or working
memory, the relationship between neocortical and hippocampal oscillations re-
mains unknown. Indirect support for such a connection is the observation that, in
a working memory task, both encoding and retrieval items reset the MEG theta
signal, whose dipole source was attributed to the anterior (uncal) hippocampus.12
As is the case with gamma oscillations (Cycle 10), the results obtained from
scalp-recorded EEG and subdural electrode grids often mismatch. In a large clin-
ical study, the oscillatory responses were examined at several hundred cortical
and hippocampal sites in patients equipped with subdural grid and depth elec-
trodes. The patients were presented with a short list of consonants; shortly there-
after, they were asked to report whether or not a “probe” consonant matched
letters on the list. Theta activity selectively increased and was sustained through-
out the trial at hippocampal sites and a portion of neocortical sites. Importantly,
the increase in theta power was speciﬁc for items successfully recalled in a free

340
RHYTHMS OF THE BRAIN
13. Kahana (2006) Kahana et al. (2001), Raghavachari et al. (2001, 2006), Rizzuto et al. (2003),
and Sederberg et al. (2003).
14. Lee et al. (2005).
15. Occipital activity in the theta band may also reﬂect “lambda” waves, thought to be of retinal
origin (Billings, 1989).
recall task. Some neocortical sites showed item-triggered phase resetting without
power changes. The majority of sites with signiﬁcant task-related effects were lo-
cated in the occipitoparietal region, and a minority were located in the temporal
region. Unexpectedly, exceptionally few sites were affected by the task in the pre-
frontal cortex. Although the task-related modulation of power occurred simulta-
neously at hippocampal and neocortical sites, the induced oscillations were rarely
phase coherent. Coherence was also rare among the cortical sites, and it de-
creased as a power law function of distance.13
The simultaneous appearance of oscillations in the theta frequency without
phase coherence across structures poses challenging questions regarding their
functional role and origin. The least attractive explanation is that they emerge ex-
clusively in local circuits, without any ﬁne time-scale coordination with each
other. An alternative hypothesis for the lack of sustained synchrony throughout
the encoding period is that each item presented in the learning and retrieval
phases produces a short-lived, unique set of coherent oscillations in a subset of
the recording sites, similar to the orientation-speciﬁc gamma synchronization in
varying subsets of cortical columns (Cycle 10). Under this scenario, each item ac-
tivates a unique hippocampal cell assembly, which in turn produces transient cou-
pling between the hippocampal assembly and the partnering, spatially distinct
neocortical assembly. Subsequent items engage different hippocampal assem-
blies, each transiently coupled to speciﬁc neocortical assemblies at different sites.
Experiments in rhesus monkeys support this idea. As in humans, theta oscillation
in the monkey extrastriate cortex is maintained throughout the encoding period in
a working memory task, and its power increases with task difﬁculty. However, the
locally recorded single neurons respond selectively to individual visual items.
The task-related enhanced ﬁring of the neurons occurs near a speciﬁc preferred
phase of each theta cycle, reminiscent of the position–phase relationship of hip-
pocampal place cells.14 Assuming that the successively presented items are repre-
sented by different assembly sets in the hippocampus, their outputs may engage
spatially varying cortical assemblies.
Although these disparate observations in humans and monkeys are compatible
with the idea that theta oscillations in the neocortex are related to those in the hip-
pocampus, they do not provide proof. An alternative explanation is that neocorti-
cal oscillations during working memory tasks emanate from the thalamocortical
networks. “Theta” in this case would reﬂect a slower version of thalamocortical
alpha rhythms.15 Under this hypothesis, alpha would reﬂect task-irrelevant activ-
ity over sites not participating in the computation process, which could explain
why the majority of “activated” sites are conﬁned to the posterior part of the
neocortex. As reviewed in Cycle 8, alpha oscillations do not necessarily reﬂect

Coupling of Systems by Oscillations
341
16. As opposed to the traditional idling role of alpha rhythms, Luria (1966) conjectured that they
reﬂect visual imagery, internal attention, free associations, and planning.
17. Leung and Borst (1987), Collins et al. (1999), and Siapas et al. (2005).
18. Sirota et al. (2003).
19. Kahana (2006) and Sederberg et al. (2003).
idling of cortical networks but rather indicate an active disengagement from envi-
ronmental inputs with an emphasis on internal mental operations.16 Unfortu-
nately, without a thorough understanding of the physiological mechanisms
underlying the macroscopic ﬁeld patterns, one can only speculate what happens at
the neuronal level.
Simultaneous recordings of hippocampal and neocortical cell assemblies in
rats lend support to the idea that at least some forms of the dialogue between hip-
pocampus and neocortex occur in the packages of theta oscillatory waves. Theta
ﬁeld oscillation and phase-locked discharge of multiple neurons in various corti-
cal layers of the perirhinal and posterior cingulate cortices often occur during
navigation and REM sleep. Both unit discharges and the ﬁeld, when present, are
phase-locked to theta oscillations in the hippocampus, although no theta dipoles
have yet been reliably localized to the cortical layers. The posterior cingulate cor-
tex has monosynaptic connections with parahippocampal and visual structures, as
well as with the anterior cingulate cortex. The latter area is part of the prefrontal
cortex. Areas of the prefrontal cortex are direct targets of the ventral hippocampal
efferents, and a signiﬁcant portion of neurons in the medial prefrontal cortex dis-
charge coherently with the hippocampal theta rhythm. The phase-locked action
potentials of the medial prefrontal neurons are delayed by approximately 50 mil-
liseconds, indicating hippocampoprefrontal directionality.17
Theta phase-locked discharge of neurons in anatomically direct targets of the
hippocampal system is perhaps not so surprising. But can neurons in other areas
of the neocortex, several synapses away from the hippocampus, display theta
phase-locking, if even transiently? Anton Sirota, a graduate student in my labora-
tory, addressed this question by examining the effect of hippocampal theta oscil-
lations on the discharges of neurons in the primary somatosensory cortex. This
structure was selected because it occupies a large area of the rat neocortex and be-
cause the synaptic path length is longest between the hippocampus and primary
sensory areas. His ﬁrst observation was that, during both navigation and REM
sleep, the ﬁring patterns of a portion of the somatosensory neurons became tran-
siently but reliably coherent with theta oscillations while the animal was per-
forming a navigation task or in REM sleep. Importantly, the majority of the
phase-locked units were inhibitory interneurons, some of which ﬁred rhythmic
bursts at theta frequency (ﬁgure 12.2).18 These ﬁndings at the cellular level can
also explain why induced ﬁelds at various cortical sites in episodic memory tasks
are not necessarily coherent with hippocampal theta oscillations.19
What could be the advantage of such long-range, multisynaptic entrainment?
Sirota and I hypothesized that oscillatory entrainments are advantageous mainly
for the entrainer, in our case, the hippocampus or, more precisely, the evolving

342
RHYTHMS OF THE BRAIN
Figure 12.2. Phase-locked discharge of cortical neurons by hippocampal theta oscilla-
tions: simultaneous recording of ﬁeld theta oscillation (bottom) and from a putative cor-
tical interneuron from layer 5 of the somatosensory cortex (top histogram). Note
phase-locked modulation of spike activity by the hippocampal theta cycle. Courtesy of A.
Sirota and G. Buzsáki (unpublished observations).
hippocampal cell assemblies. Since the hippocampus operates in a discontiguous
manner during theta oscillation, information arriving at the “wrong” phase may be
ignored. However, if the hippocampal output manages to temporally bias the ﬁring
patterns of distant cortical sites by polysynaptically entraining some of their in-
terneurons, well-timed messages from those same cortical areas will be treated
preferentially over others by the hippocampus. Speaking generally, centrally orga-
nized rhythms can enhance the efﬁcacy of their inputs by biasing them to send
messages at times convenient for the oscillating receiving structure. An analogy of
such directed dialogue is the boss-determined appointments with subordinates for
reporting work in progress. Such a temporally speciﬁed “call-up” mechanism can
be an effective solution for top-down selection of bottom-up inputs.
Hippocampal-Neocortical Dialogue 
during Nontheta States
The means by which large collections of neurons, within and across the vast re-
gions of the brain, interact is not well understood. Nevertheless, it is striking that
these interactions persist in all brain states but the temporal dynamics underlying

Coupling of Systems by Oscillations
343
20. The classical reference on behavioral correlates of hippocampal patterns in the rat is Vander-
wolf (1969). For an extended review, see Vanderwolf (1988).
the information exchange vary from state to state. Understanding the nature of
these state-dependent dialogues is of great importance because they can provide
us clues about the direction and temporal windows of information transfer. These
transfer processes are not continuous but packaged into compressed population
events separated by renewal processes. Stating this in the framework of networks
and systems, the macroscopic order parameters guide the single-cell processes at
different spatial and temporal scales.
Hippocampal Oscillatory Patterns Reﬂect Neocortical States
Cycles 10 and 11 discussed how gamma oscillations tie together the hippocampal
CA3 and CA1 regions, how the CA3 autoassociator generates an intrinsic theta
rhythm, and how both theta and gamma oscillations are affected by the oscillatory
patterns of the dentate gyrus. The antagonism between the activities of the dentate
gyrus, the main recipient of neocortical information, and the CA3 and CA1 re-
gions is even more prominent in the absence of theta oscillations. Behaviorally,
these nontheta states involve consummatory behaviors, such as eating, drinking,
and grooming and immobility, non-REM sleep, and deep stages of anesthesia.20
The activity of the neocortex under various anesthetics alternates between neu-
ronal silence with nearly all neocortical principal cells sitting at a hyperpolarized
level (down state) and the up state, with many neurons spiking (Cycle 7). The
global shifts of activity are partially due to the toggle switching of the membrane
potential in principal cells throughout the neocortex. Is this the case in the allo-
cortex and hippocampus as well? Yoshikazu Isomura, a postdoctoral fellow in my
laboratory, compared the impact of the global neocortical shifts on the activity of
prefrontal, entorhinal, subicular, and hippocampal neurons. Similar to prefrontal
and other neocortical neurons, both entorhinal and subicular neurons showed bi-
modal distribution of the membrane potential, toggling in parallel with the up-
down shifts of the global neocortical activity. In contrast, hippocampal granule
cells and CA3 and CA1 pyramidal neurons did not show such bimodality, adding
further support to the distinct functional organization of the hippocampus. How-
ever, the hippocampus was not left unaffected by the neocortical inputs. In the
dentate gyrus, gamma power increased in parallel with the up state, often with si-
multaneous increase of gamma power in CA3–CA1. However, when the neocor-
tex, entorhinal cortex, and subiculum became silent, gamma power in the dentate
gyrus decreased, most likely because the necessary drive from the entorhinal cor-
tex was absent. Nevertheless, the down state in the neocortical networks was asso-
ciated with gamma oscillation bursts in the CA3–CA1 system. The straightforward
interpretation of these observations is that the CA3 recurrent system can generate
self-sustained gamma oscillation on its own, supporting the previous contention.
Furthermore, the combination of the anatomical connections and the dynamic pat-
terns in the dentate gyrus exerts a general suppressing inﬂuence on the recurrent
circuits of the CA3 system, yet at other times, the dentate can have a facilitative

344
RHYTHMS OF THE BRAIN
21. Isomura et al. (2005). Previous ﬁndings in behaving and anesthetized animals support the com-
petition of activity between the dentate gyrus and CA3–CA1 (Bragin et al., 1995a, 1995b; Penttonen
et al., 1997). Annihilation of a trailing oscillator is described in Winfree (1980).
22. Because of their spikelike appearance, these patterns were called “dentate spikes” (Bragin
et al., 1995b). The cellular-synaptic mechanisms of these spikes are identical to the gamma oscilla-
tions, and only their isolated appearance and large amplitude distinguish them from the more regular,
multiwave gamma rhythm.
23. Leinekugel et al. (2002) and Buzsáki et al. (1987).
effect on the same target network. The mechanism of the suppression of
CA1–CA3 gamma activity by the dentate gyrus remains to be investigated. A can-
didate mechanism is annihilation of the target oscillator by the critical intensity
and phase of the dentate gamma oscillation.21
Oscillatory Patterns of the Hippocampus in “Ofﬂine” States
Although experiments carried out under anesthesia should be viewed with cau-
tion, the general observations discussed above are also valid in the drug-free
brain. In the nonexploring rat, three basic types of patterns alternate with each
other in the hippocampus: intermittent gamma oscillations, silent periods, and
a unique, hippocampus-speciﬁc pattern called the sharp-wave–ripple complex.
In the dentate region, gamma activity is the most conspicuous pattern. How-
ever, in contrast to the relatively uniform theta–phase-modulated gamma oscil-
lation in the exploring animal and REM sleep, gamma oscillations are much
more irregular in the absence of theta rhythm. Relatively silent periods with no
cellular discharge activity alternate irregularly with short gamma oscillatory
epochs, which vary substantially in both frequency and amplitude. Occasion-
ally, just one to three waves with the period of the gamma cycle emanate from
a ﬂat baseline, with the middle wave displaying a large-amplitude, spikelike
appearance. This irregular dentate gamma pattern exerts a dampening effect
on the excitability of the CA3–CA1 neurons, although this process is quite
complex.22
The third major pattern includes a “sharp wave,” which is observed irregu-
larly in the apical dendritic layer of the CA1 region as a result of a strong depo-
larization by the CA3 collaterals, due to the synchronous bursting of CA3
pyramidal cells. Sharp waves are the ultimate self-organized endogenous hip-
pocampal events because they occur when the animal has no or minimal interac-
tion with the environment. They are the ﬁrst and only population pattern in the
developing hippocampus. In fact, sharp waves and associated neuronal burst dis-
charges persist when the hippocampus is completely isolated from its environ-
ment, for example, after being transplanted into a brain cavity or the anterior
chamber of the eye.23 In the intact brain, the endogenous hippocampal sharp
wave emerges in the excitatory recurrent circuits of the CA3 region. The syn-
chronously discharging CA3 pyramidal cells activate not only CA1 pyramidal
cells but also interneurons and the interaction between pyramidal cells, and the
various classes of inhibitory interneurons gives rise to a short-lived, fast ﬁeld

Coupling of Systems by Oscillations
345
24. O’Keefe and Nadel (1978), Buzsáki et al. (1983, 1992), and Csicsvari et al. (2000). For the po-
tential role of axonal gap junctions between axons of pyramidal cells in the ripple event, see computa-
tional models in Traub and Bibbig (2000) and Traub et al. (2004). Sharp-wave–ripple events are
present in all mammals investigated, including humans (Bragin et al., 1999). For the differential role
of interneurons, see Csicsvari et al. (1999) and Klausberger et al. (2003).
25. Buzsáki et al. (1983, 2003) and Buzsáki (1986; 1989, 1996, 1998).
oscillation (140–200 per second) or “ripple” conﬁned to the CA1 pyramidal cell
layer.24
The hippocampal sharp-wave–ripple complex has numerous remarkable fea-
tures that make it a candidate pattern for consolidation of synaptic plasticity and
transfer of neuronal patterns.25 One of its major features is its widespread effect.
In the approximately 100-millisecond time window of a hippocampal sharp wave,
50,000–100,000 neurons discharge together in the CA3–CA1–subicular com-
plex–entorhinal axis of the rat, qualifying it as the most synchronous network pat-
tern in the brain, as James Chrobak, a postdoctoral fellow in my laboratory, has
described it. This number represents 5–15 percent of the local population, an or-
der of magnitude larger than during theta oscillations (ﬁgure 12.3). This feature
alone makes the sharp waves eligible for affecting neocortical targets. Its recruitment
dynamics are delicately controlled by the various classes of interneurons. Both
Figure 12.3. Self-organized hippocampal activity can invade large cortical areas. A syn-
chronous population burst that emerges in the recurrent excitatory system of the hip-
pocampal CA3 region depolarizes CA1 neurons, as reﬂected by a sharp wave in the apical
dendritic layer, and brings about a short-lived fast oscillation (“ripple” in the cell body
layer). The strong, ripple-related hippocampal activity can bring about similar population
bursts in the subiculum (Sub), parasubiculum (Para), and entorhinal cortex (EC), from
where it can reach widespread regions of the neocortex. The temporally “compressed,”
experience-dependent sequences of neurons during the sharp wave–ripple may be critical
for transferring information from the hippocampus to cortex. Reprinted, with permission,
from Buzsáki and Chrobak (2005).

346
RHYTHMS OF THE BRAIN
26. The increased spike output is due to adjusting the timing of pyramidal cell discharges rather
than increasing discharge rates of single cells (Chrobak and Buzsáki, 1994, 1996; Csicsvari et al.,
1999, 2000).
27. Crick and Mitchison (1983) attributed such “scrambling” role to REM sleep. Recently, Colgin
et al. (2004) applied this “memory erasure” role speciﬁcally to hippocampal sharp waves.
pyramidal and selected interneuron populations increase their spike outputs dur-
ing the sharp wave, but inhibition cannot keep of with the increased excitation, re-
sulting in a three- to ﬁvefold gain in network excitability.26
The transient but substantial gain in population excitation creates favorable
conditions for synaptic plasticity. However, in order for the sharp-wave–ripple
events to be useful for their desired purpose, they should have an interpretable
content, and the content should be modiﬁable. Understanding the content, of
course, is a general requirement for understanding any macroscopic ﬁeld pattern
and requires large-scale recording of neurons. Since this strategy proved valuable
for revealing the relationship between single-level behavior and theta oscillations
(Cycle 12), I follow a similar line of reasoning here for sharp waves.
Modiﬁcation of Self-Organized Hippocampal Patterns 
by Experience
In principle, neuronal activity during sharp waves can be useful in two funda-
mentally different ways. First, the participating neurons can discharge indepen-
dently and randomly, thereby erasing or equalizing synaptic modiﬁcations
brought about by speciﬁc activity in the waking brain. The expected result is a
fresh tabula rasa of the hippocampal autoassociator, every morning ready to be
ﬁlled with the excitements of the new day. This hypothetical erasure mechanism,
of course, should also apply to immobility, drinking, and eating following ex-
ploratory learning, because sharp waves are present during such consummatory
behaviors, as well.27 As a result, the “noisy” or random activity during sharp
waves would interfere with the synaptic modiﬁcations brought about by the pre-
ceding experience. Alternatively, the neuronal pathways used and modiﬁed in the
waking brain can be repeatedly replayed during nontheta behaviors but now with
the temporal dynamics of the sharp waves. This mechanism could be useful in at
least three different ways. First, neuronal representations of a single episode
could be replayed multiple times, assisting with the consolidation process. Sec-
ond, the molecular mechanisms underlying synaptic plasticity occur in multiple
stages, involving transient local synaptic modiﬁcation, signaling to the nucleus,
gene transcription, and eventually incorporation of a newly synthesized protein
into the synapse that brought about the cascade in the ﬁrst place. This complex
process lasts for hours, by which time the rat undergoes at least one ultradian
sleep cycle, and it is not clear how the multiple-stage molecular processes involv-
ing the cell’s nucleus ﬁnd their way back selectively to those speciﬁc synapses
that were affected by the learning process. The selective and repeated activation
of the same neurons and synapses by the sharp-wave events could be indispensable
in this protracted course because the molecular trafﬁc would still be guided by

Coupling of Systems by Oscillations
347
28. Frey and Morris (1997) advanced a “synaptic tag” hypothesis for guiding this process. The ac-
tivated synapse would trigger local protein synthesis and create a short-lived synaptic tag, which in
turn would attract the products of gene expression, shipped globally throughout the cell. The sharp-
wave replay mechanism could replace the tagging mechanism or the two processes could work in par-
allel to ensure input speciﬁcity of synaptic modiﬁcation.
29. This combinatorial feature of hippocampal sharp wave may be responsible for the sleep-
induced creativity, discussed in Cycle 8.
30. For the modiﬁcation of macroscopic sleep patterns by experience and the performance
enhancing effect of sleep, see discussion in Cycle 9.
31. Wilson and McNaughton (1994) and Skaggs and McNaughton (1996). Pavlides and Winson
(1989) were the ﬁrst to observe ﬁring rate correlations in the waking and sleeping rat in a well-learned
task. Louie and Wilson (2001) extended the waking/sleeping ﬁring pattern observations to REM sleep,
as well.
synapse-speciﬁc electrical processes.28 The third potential service of sharp-wave
bursts is the combination of various representations, that is, a nonconscious asso-
ciative process. Because many more neurons are active during the sharp-wave
event than in a single theta cycle or at any other comparable time window, repre-
sentations that occurred at intervals longer than hundreds of milliseconds in the
waking brain can be brought together into the temporal scale of synaptic plastic-
ity. Furthermore, recently acquired information can be combined with retrieved
previous knowledge, again in the critical temporal window of plasticity.29 Finally,
packaging hippocampal activity into short and synchronous bursts appears to be
an especially effective way of exerting an impact on the neocortex. From this per-
spective, sharp waves may be the means of internally organized hippocamponeo-
cortical transfer of neuronal information. Beneath all that turbulence, sharp waves
retain and replay the information embedded in the synaptic network that gives
rise to the event.
Several experiments support the above hypothetical scenario.30 Most critically,
participation of single neurons in successive sharp-wave–ripple events is not ran-
dom. A small fraction of pyramidal cells participate in as many as 40 percent of
successive events, whereas the majority remain silent or contribute only occa-
sionally. Since this unequal distribution of active neurons is largely similar to the
differential ﬁring patterns of hippocampal pyramidal cells in the waking animal,
an important issue is whether the ﬁring patterns in theta and sharp waves correlate
with each other. Using large-scale recordings of multiple single neurons,
Matthew Wilson and Bruce McNaughton at the University of Arizona in Tucson
were the ﬁrst to demonstrate such a relationship. Using a well-learned behavioral
task in rats, they reported that pyramidal cells with overlapping place ﬁelds pre-
served their pairwise temporal correlations during subsequent sleep, whereas
place cells, which did not overlap spatially or temporally, rarely showed corre-
lated ﬁring during sleep. Several other experiments in various laboratories have
conﬁrmed the now well-accepted observation that, in an unchanging environ-
ment, the ﬁring rates and temporal correlations of neurons are preserved in multi-
ple sleep/wake/sleep cycles and that most of the correlated discharge occurs
during sharp waves.31 However, because in these experiments no new learning

348
RHYTHMS OF THE BRAIN
32. Nádasdy et al. (1999) and Hirase et al. (2001). Lee and Wilson (2002) also showed that the
neuron sequences during sharp waves were related to the sequences in the waking state. Kudrimoti et
al. (1999) used an “explained variance” method and found enhanced correlation in sleep after the new
experience compared to the baseline “presleep” session.
took place, one could argue that the correlation of ﬁring rates and pairwise coac-
tivation patterns simply reﬂects the stability of a hard-wired system and the in-
trinsically differential discharge properties of hippocampal neurons, and that
sleep played no special role in the conservation of ﬁring patterns.
One possible way to attribute a causal link to the sleep/wake correlations is to
perturb the synaptic connectivity by novel experience and to detect the ensuing
changes in subsequently occurring sharp waves. Zoltán Nádasdy and Hajime Hi-
rase in my laboratory set out to pursuit this hypothesis. As expected, exposure of
the animal to a novel situation, such as addition of a running wheel or novel ob-
jects to a routinely explored environment, altered the structure of cell assembly
ﬁring in both the novel situation and during the subsequent sleep cycle. The cor-
relation between the ﬁring rates of individual neurons in the novel environment
and the subsequent sleep episode was stronger than the correlation between ﬁring
rates in the novel environment and the preceding sleep episode. The novel envi-
ronment had a similar effect on coactivation of neuron pairs, as well. Neuron pairs
with high wake state correlation continued to display high correlation in the sub-
sequent sleep episode. However, some residual correlation was still present be-
tween exploration and the preceding sleep session, indicating that novelty does
not entirely erase previously established relationship between neurons.
Even more direct support for the replay of learned neuronal patterns came from
an analysis in which complex neuronal sequences were compared, instead of pair-
wise correlations. In rats, exposed to a wheel-running task for the ﬁrst time, pre-
cisely timed spike sequences of multiple neurons were detected. The same neurons
repeatedly ﬁred in the same temporal order during sharp waves of sleep immedi-
ately following, but not preceding, the wheel-running experience. As expected from
the dynamics of the sharp-wave events, neuronal spikes occurred at 5- to 6-
millisecond intervals at the troughs of the ripple. The sharp-wave–associated se-
quence replay was therefore twice as fast as the cell assembly sequences compressed
into a single theta period (Cycle 11), an indication of a faster search of the
hippocampal autoassociator during sharp waves compared to theta oscillation.32An-
other experiment, comparing spike sequences on an elevated maze and sharp-
wave–ripple complexes, found similar repetition of sequences (ﬁgure 12.4).
The simplest interpretation of these experiments is that learning in the novel en-
vironment repeatedly engaged speciﬁc sets of cell assemblies. The new temporal
coalitions within members of the assemblies and across the assemblies altered the
synaptic weights within the CA3 recurrent system. In turn, the newly created synap-
tic weights determined the spread of activity in the large synaptic space of the hip-
pocampus. As discussed in Cycle 11, a simple rule of neuronal recruitment is that
activity spreads along the path of the strongest synaptic weights. Therefore, assem-
blies that are activated most during the experience are held together by the strongest

Coupling of Systems by Oscillations
349
Figure 12.4. Temporally compressed replay of learned neuronal sequences. Top: Spa-
tiotemporal ﬁring rate changes of 10 CA1 place units on an elevated track. Bottom: Repre-
sentative examples of ﬁring patterns of the same units during two ripple events of
non-REM sleep. Note the similarity between ripple-related spike sequences and the order
of place-cell activation on the track. Reprinted, with permission, from Lee and Wilson
(2002).
33. King et al. (1999) used Hebbian pairing of sharp-wave bursts and single-cell discharges to in-
crease sharp-wave participation of neurons.
synaptic connectivity and become the “burst initiators” of the self-organized sharp-
wave events, followed by the progressively less activated neurons of the learning
episode. The temporal proximity of neuronal discharges during sharp waves can
therefore be taken as an indication of the strengths of their synaptic connectedness.
A separate experiment also showed that, by artiﬁcially changing synaptic inputs to
selected neurons, their participation in subsequent sharp-wave events was altered.33
Transient Coupling between Neocortex and Hippocampus
May Support Information Transfer
Although experiments discussed above support a “two-stage” model of memory
consolidation, they do not provide direct clues about whether and how sharp-wave
packaging of hippocampal assemblies can contribute to the alteration of synaptic
circuits in the neocortex and, by extrapolation, to the transfer of hippocampal
memories to more permanent neocortical sites. A fundamental question not ad-
dressed so far is how hippocampal sharp-wave events “know” which neurons in the
neocortex were active in the waking experience, that is, which assemblies to mod-
ify ofﬂine. Given that sharp-wave–associated CA1, subicular, and entorhinal deep-
layer cell assemblies can target large numbers of distributed neocortical neurons,
some selection process must take place. A hypothetical solution is “tagging” those
neocortical neurons that provide inputs to the hippocampus during the novel expe-
rience. In turn, the hippocampal–entorhinal output must somehow readdress the
tagged neurons during sharp waves. Because during slow-wave sleep the neocor-
tex has its own self-organized patterns (Cycle 7), the hippocampal output may
often ﬁnd neocortical neurons in a refractory state, unless some coordination

350
RHYTHMS OF THE BRAIN
34. Sirota et al. (2003). Co-occurrences of ripples and sleep spindles were modulated by a 10-
second slow 2 oscillation. See also Vanhatalo et al. (2004) for slow 2 oscillator modulation of ex-
citability in the human cortex. Siapas and Wilson (1988) were the ﬁrst to assume a link between sharp
waves and spindles.
process is in place. Furthermore, sharp-wave events do not always begin with the
activity of the same assembly. As in episodic memory, a cues can initiate recall
at any segment of the episode. During sleep, such cues can arrive to the hip-
pocampus from the neocortex and can select which assemblies are activated in a
given sharp-wave event. Experimental ﬁndings support this hypothesis.
In general, emergence of sharp-wave–ripple complexes does not require ex-
trahippocampal inputs. Nevertheless, when such inputs are available, the inputs
may affect the time of occurrence of the ripple event and the composition of the
participating neurons. As discussed in Cycle 7, the neocortical activity during
down-up transitions is often ampliﬁed by the triggered thalamocortical spindles.
Simultaneous monitoring of neocortical and hippocampal activity revealed that
the excitability ﬂuctuations, associated with the thalamocortical spindles, reliably
affected the timing of hippocampal ripples and cell discharges, as expected from
the appropriate neocortical–hippocampal synaptic delays.34 The ﬁne temporal
structure that emerges during the co-occurrence of the relatively longer neocorti-
cal spindle and the “punctuate” hippocampal sharp wave is another example of a
potentially useful “call-up” mechanism that may provide a framework for coordi-
nated information transfer between the two structures according to the following
scenario (ﬁgure 12.5). Individual sleep spindles emerge from the activity of
Figure 12.5. Oscillatory coupling between hippocampus and neocortex. Top: Short seg-
ment of somatosensory local ﬁeld activity (layer 5) and ﬁltered hippocampal ripples (one
ripple event is shown at a fast scale below). Bottom: Averaged, hippocampal ripple-
triggered neocortical spectrogram in a mouse. Note the increased correlation of power in
the delta and sleep spindle (10–18 Hz) bands with hippocampal ripples. The asterisk indi-
cates slow oscillatory (0.1 Hz) comodulation of neocortical spindle and delta waves and
hippocampal ripple activity. Reprinted, with permission, from Sirota et al. (2003).

Coupling of Systems by Oscillations
351
characteristically different thalamocortical neuronal assemblies, as evidenced by
the variable spatial distribution of spindle power in successive spindle episodes. The
output of the speciﬁc neocortical cell assemblies can select burst initiators of the
hippocampal sharp-wave events. In turn, the biased sharp-wave–related discharge
of a unique assembly of neurons in the CA3–CA1–subicular complex–entorhinal
cortex axis provides a synchronous output to all their neocortical targets. Never-
theless, it will modify the synaptic inputs of only those neocortical cell assem-
blies that continue to spike in the spindle event. Thus, the hippocampal output
message is temporally sandwiched between the cyclic discharges of spindle-
activated neocortical neurons. The temporal directedness within the spindle–sharp
wave–spindle sequence facilitates conditions in which unique neocortical inputs
to the hippocampus and hippocampal outputs to the neocortex may be selectively
modiﬁed by spike-timing–dependent plastic mechanisms. A direct proof of this
hypothetical mechanism will require assembly recordings from both hippocampal
and neocortical areas to demonstrate that speciﬁc assemblies in the two brain re-
gions are brought about by a learning process and that their temporally coordi-
nated occurrence has future behavioral consequences.
Multiplexing Representations by Multiplexed
Oscillations
When multiple, transient, or sustained oscillations emerge from the same or differ-
ent neuronal substrates simultaneously, how do they inﬂuence each other? Given
the ubiquitous and simultaneous presence of multiple oscillators in various parts
of the brain, this is a critical question. Yet, relatively little research has been devoted
to the problem of cross-frequency coupling. The most frequent case is co-occurrence
or comodulation of different rhythms. A trivial but robust example is the temporal
correlation between cortical “up” states and gamma oscillations. A requisite of
gamma oscillations is sufﬁcient activity of cortical interneurons (Cycle 9), which is
only available during the up state, while absent in the down state when all neuron
types are silent. In the drug-free brain, gamma oscillations can occur in both waking
and sleep states, although variance and power of the waves vary extensively across
states. A particularly striking relationship is the coupling between hippocampal
gamma and theta rhythms. Although gamma oscillations can be present in all states,
the power of gamma activity is higher and more regular during theta-associated be-
haviors. Beyond the parallel covariation of theta and gamma oscillations, Anatol
Bragin in my laboratory observed that the power of gamma activity varies dynami-
cally as a function of the theta cycle. In subsequent experiments, we revealed a sim-
ilar relationship in the entorhinal cortex and the neocortex, as well (ﬁgure 12.6).35
35. Buzsáki et al. (1983), Bragin et al. (1995), Chrobak and Buzsáki (1998), and Sirota et al. (2005).
Slow rhythms often phase-modulate the power of faster oscillations. The effect can be powerful enough
to trigger epileptic afterdischarges in animals predisposed to seizures (Penttonen et al., 1999).

352
RHYTHMS OF THE BRAIN
Figure 12.6. Mutiplexing by oscillatory phase modulation. Left: Simultaneous recordings
from the entorhinal cortex of the rat. The slower theta and faster gamma waves were sepa-
rated by ﬁltering. Note the strong theta phase modulation of the amplitude of gamma os-
cillation. Reprinted, with permission, from Chrobak and Buzsáki (1998). Right: The nested
gamma oscillations can be used for grouping cell assemblies. For example, repeating the
assembly sequences from A to G in subsequent theta cycles can be used to hold informa-
tion in working memory. Alternatively, shifting the sequences in subsequent theta cycles
can serve to represent episodic memories. Reprinted, with permission, from Lisman and
Idiart (1995).
36. Lisman and Idiart (1995) suggest that sequence information is not necessarily resident in the
synaptic connections but provided by discrete oscillatory gamma cycles on a particular phase of the
theta cycle. See also Jensen and Lisman (1998).
37. Packaging of items by mnemonic techniques is known as “chunking” (Miller, 1956; Sternberg,
1966).
Phase modulation of gamma activity by slower oscillators is potentially very
important because, as discussed in Cycles 6 and 11, cell assemblies are nested
within gamma waves; therefore, the slow carrier waves can serve to combine and
segregate cell assemblies in successive slow cycles. Each theta wave can host be-
tween seven and nine gamma cycles. Our ﬁnding in the rat prompted John Lisman
at Brandeis University in Waltham, Massachusetts, to suggest that nested gamma
waves can be used to simultaneously maintain several items in working memory
in humans. The theta period would deﬁne the span of memory with seven to nine
items multiplexed on successive gamma cycles. Firing of neurons in each gamma
cycle is assumed to be maintained by a membrane process intrinsic to each cell
and established promptly at the onset of working memory. Although direct sup-
port for these assumed mechanisms is not yet available, the major innovation of
Lisman’s time-multiplexing model of the short-term memory buffer is that it does
not require reverberating circuits.36 Indirect support comes from experiments in
human subjects demonstrating that the duration of memory scanning increases
with the set size and corresponds to approximately 25 milliseconds per item “to
be remembered.” Thus, the number of items that can be stored by the multiplexed
gamma–theta model is identical with the “magical number 7 (±2),” the psy-
chophysically measured limit of working memory.37 As discussed in Cycle 11,

Coupling of Systems by Oscillations
353
such a multiplexing mechanism may also be responsible for providing a spa-
tiotemporal context for episodic memories. Similarly, nested gamma activity on
theta waves in the prefrontal cortex can serve as a buffer for short-term memories.
Through the theta phase modulation of gamma oscillations in the prefrontal cor-
tex, the multiplexing mechanism could provide a physiological link between
short-term memory and episodic memory.
In addition to up states of sleep and hippocampal theta oscillations in the ex-
ploring rat, neocortical alpha waves in humans also modulate gamma power, and
coupling of these oscillators may serve perceptual functions.38 However, in the
case of the faster alpha oscillator, the span is shorter, with a capacity limit of four
or ﬁve nested cell assemblies in a single alpha wave. It is interesting to note that
this value is equivalent to the psychophysical estimate of the number of objects
that can be perceived at a glance, although a causal relationship between the phys-
iological and behavioral processes has yet to be established. Further support for
this postulated relationship is the classic observation that reaction time his-
tograms show periodicities at both 25 and 100 milliseconds, corresponding to the
periods of gamma and alpha oscillations, respectively. In fact, the gamma period
may be a physiological measure of the upper limit of temporal resolution in the
visual and somatosensory system. Stimulation of the hand and foot at the same
clock time is judged perceptually as simultaneous, even though there is a tempo-
ral difference of approximately 10 to 20 milliseconds in somatosensory evoked
responses, due to the longer axonal conduction delay from the foot. Because the
delay is shorter than the period of the gamma cycle, the two events are perceived
as simultaneous.39
Two or more oscillators at different frequencies can relate to each other not
only through power modulation of the faster signal but also by phase-coupling of
the different oscillators. Such cross-frequency phase synchrony has been ob-
served between alpha and gamma oscillations during mental arithmetic tasks. The
potential behavioral relevance of the phase-coupling mechanism is supported by
experiments in humans that show a positive correlation between task load and the
magnitude of phase synchrony.40
Further Opportunities for Oscillatory Coupling
As described in Cycle 6, there are numerous mechanisms by which oscillators of
the same or different frequencies can synchronize. Whether or not a duty cycle
produces synchrony (or phase-locking) of a trailing physiological event depends
mainly on the strength of the functional connections and the phase dynamics of
38. Freeman et al. (2003) showed phase resetting of gamma waves at alpha rates.
39. VanRullen and Koch (2003) is an excellent review of both old psychophysical experiments and
the relevant brain rhythms that may underlie the periodicities of reaction times and subjective judg-
ment.
40. JM Palva et al. (2005); S Palva et al. (2005).

354
RHYTHMS OF THE BRAIN
the trailing oscillator. Randomly occurring inputs cannot synchronize oscillating
targets. On the other hand, inputs with various phase dynamics can have pre-
dictable effects on a target oscillator. Two oscillators with nearly equal frequen-
cies can communicate with each other in the sense that the phase (timing) of one
of them becomes sensitive to the phase of the other. We have discussed simple
cases, such as one-to-one coupling between mutually connected gamma oscilla-
tors. We also illustrated the consequences of minimal frequency differences,
which can give rise to systematic phase precession or phase retardation. Because
each perturbation exerts a lasting effect on the oscillator, subsequent effects are
typically cumulative, producing a systematic forcing effect. Another simple case
is one-to-two locking, or frequency doubling. In fact, frequency locking can oc-
cur between any two or more oscillators with an integer period relationship. In
principle, virtually inﬁnite numbers of combinations are possible but the limited
number of classes of oscillators that can be simultaneously present in the same
neuronal substrate puts severe constraints on the possible numbers of combina-
tions.41 Some arrangements enhance, whereas others annihilate each other.42 To
date, very few rhythm combinations in the brain have been studied or understood.
Among them, “desynchronization” is a well-studied but little-understood phe-
nomenon. The term typically refers to the quantitative reduction of alpha activity
in the scalp-recorded signal upon presentation of a stimulus. However, the stimu-
lus often induces or enhances gamma frequency oscillations, which may be the
cause of the reduced alpha power. The best, albeit artiﬁcial, demonstration of an-
nihilation of a slow rhythm by a high-frequency oscillation is the reduction of
Parkinson tremor by constant high-frequency stimulation of the subthalamic
nucleus.43
Coupling of oscillators having similar frequency but arising from different ar-
chitectures, such as the hippocampus and neocortex, provides special challenges
because even identical perturbations of similar macroscopic oscillators, which
emanate from different physical substrates, can result in different outcomes. Cou-
pling oscillators of two or more frequencies can generate complex envelopes of
population activity and synchrony. Because such compound envelope oscillators
can generate high-dimensional patterns, they can be very useful for encoding in-
formation.44
41. Combinations of oscillatory coupling are also limited in music. It has been claimed repeatedly
that music is a matter of numbers. J.S. Bach used formal mathematical patterns in his organ fugues,
e.g., the Fibonacci succession (1, 1, 2, 3, 5, 8, . . . , in which each number in the succession is the sum
of the two previous ones). Béla Bartók also believed that there is a numerical logic that is pleasing to
the ear (Lendvai, 1971).
42. Tass (1999) is a mathematically detailed treatment of phase-locking of oscillators.
43. For a review of possible mechanisms of deep brain stimulation, see Garcia et al. (2005). Bet-
ter understanding of oscillators will lead to more rational stimulating regimes and more effective
therapies.
44. Friston (2000) calls interregional coupling between different frequencies “asynchronous.” His
main argument for its importance is the nonlinear nature of coupling between different bands, as op-
posed to “simple,” linear pairing within the same frequency band. See also Bressler and Kelso (2001).

Coupling of Systems by Oscillations
355
A major motivation for studying the mechanisms of oscillatory coupling is to
use such understanding for describing the direction and strength of functional
connectivity between brain areas of interest. Unfortunately, there is no general
mathematical or computational theory of oscillatory networks of multiple inter-
acting oscillators. In the absence of such a theory, prediction of functional or ef-
fective connectivity on the basis of ﬁeld measurements alone remains a conjecture.
All known models are likely special and perhaps simplest cases of all possibili-
ties. Nevertheless, regardless of the mechanisms, oscillators tend to synchronize
transiently or for extended periods and thereby inﬂuence neuronal activities. It is
therefore perhaps not outrageous to state that a requisite for understanding net-
work and system interactions in the brain is an understanding the nature of oscil-
latory coupling.
Brieﬂy . . .
Top-down and bottom-up processing of signals is a mere abstraction. In brain
networks, there is no “top,” since activity at any level can be transmitted to other
levels, ascending or descending. The termination of a particular computation is
heralded by time, marked typically by inhibition of activity, rather than by some
deﬁned anatomical boundary. Oscillatory packaging of information can deﬁne
the length of the messages, and this same mechanism allows for efﬁcient ex-
change of information across anatomical domains. Messages between areas can
be exchanged by forced oscillations, resonant loops, or transient oscillatory cou-
pling. Human scalp, depth, and subdural recording studies consistently describe
increased power of theta oscillations in memory tasks. Increased power in the
theta band during the practice (“encoding”) phase is speciﬁc to items retrieved
successfully. However, instances of increased theta power observed at several
cortical sites are rarely coherent with each other or with the simultaneous in-
crease of theta power in the hippocampus. A possible interpretation for the lack
of sustained synchrony between the hippocampus and neocortical sites is that
each item presented in the learning and retrieval phases engages varying subsets
of typographically distinct, short-lived oscillations in unique neocortical sites. In
support of this hypothesis, neocortical neurons various allo- and neocortical re-
gions are phase-locked transiently to hippocampal oscillations in rodents. The
advantage of such a long-range, transient entrainment of cortical assemblies to
hippocampal theta is that assembly messages can reach the hippocampus at
times (phases) when its receiving state (i.e., sensitivity for perturbation) is most
optimal. This temporally speciﬁed “call-up” mechanism is a particularly effec-
tive solution for input selection.
Exchange of information between the hippocampus and neocortex continues
during times when the brain is disengaged from the environment (“ofﬂine”
states), although at a different temporal scale. The hippocampus, even in the ab-
sence of neocortical inputs, can give rise to self-organized patterns. The most

synchronous population activity arises from the CA3 recurrent collateral 
system that brings about short-lived fast oscillations in the target CA1–subicu-
lum–parasubiculum–entorhinal cortex output circuits, known as the sharp-
wave–ripple complex. Part of the content of these oscillations reﬂects activity of
neurons activated in the preceding waking periods. Through the temporal com-
pression mechanisms of sharp waves, recently acquired information can be com-
bined with retrieved previous knowledge in the critical temporal window of
plasticity. The neuronal content of individual hippocampal sharp waves may be bi-
ased by thalamocortical spindles. Because individual sleep spindles may emerge
from the activity of unique thalamocortical neuronal assemblies, the synchronous
hippocampal output can selectively target the actively discharging neocortical neu-
rons because the compressed hippocampal message is temporally sandwiched be-
tween the cyclic discharges of spindle-activated neocortical neurons.
The ubiquitous and simultaneous presence of multiple oscillators in various
parts of the brain often leads to transient cross-frequency coupling or phase-
modulation of the power of a faster event by a slower oscillator. Two such well-
studied coupling mechanisms are the gamma power modulation by theta or alpha
oscillations. The transiently and consistently emerging nested gamma cycles
may serve as multiplexing mechanisms for sustaining working memory content
or perceptual functions. Although transient coupling of various oscillators is lit-
tle studied, these compound envelope oscillators may be particularly useful for
encoding neuronal messages because they can generate high-dimensional pat-
terns. Unfortunately, the story stops here for now, just as it begins to get really
interesting, because the mechanisms of coupling of multiple oscillations are
poorly understood.
356
RHYTHMS OF THE BRAIN

Cycle 13
Tough Problems
Knowledge is not a series of self-consistent theories that converges toward an
ideal view; it is rather an ever increasing ocean of mutually incompatible (and
perhaps even incommensurable) alternatives, each single theory, each fairy
tale, each myth that is part of the collection forcing the others into greater
articulation and all of them contributing, via this process of competition, to
the development of our consciousness.
—Paul Feyerabend
357
The sleek, 59-story Citicorp Center, one of the most daring engineering designs
in New York City’s history, is set on four massive columns, positioned at the cen-
ter of each side, rather than at the corners. This design allowed the northwest cor-
ner of the building to cantilever over St. Peter’s Lutheran Church. But slenderness
and beauty of buildings always come with a cost. Skyscrapers tend to sway in
high winds and in the seismic waves generated by earthquakes, causing them to
oscillate in various ways depending on the direction of wind force or ground mo-
tion. Such oscillations can be destructive to the buildings or simply unpleasant for
the people working in them. Since it is virtually impossible to construct buildings
without resonant features, it is easier to build light structures capable of oscilla-
tions and to provide adequate damping. To compensate for the unwanted effects,
William LeMessurier, the chief structural engineer of the Citicorp Center, de-
signed a device known as the “tuned mass damper” to moderate the tower’s sway.
It consists of a 400-ton concrete block that can slide in a steel pan ﬁlled with oil,
placed on the top of the building. The counterbalanced movement of the damper
effectively annihilates the unwanted oscillations of the building.1
1. Taipei 101 in the capital of Taiwan, currently the tallest building in the world, has a 730-ton
tuned mass damper suspended between the 88th and 92nd ﬂoors, stabilizing the tower against earth-
quakes, typhoons, and wind. The damper reduces up to 40 percent of the tower’s movements. See
http://www.popularmechanics.com/science/technology_watch/1612252.html.

358
RHYTHMS OF THE BRAIN
Tall buildings, bridges, and many other artifacts possess oscillatory and reso-
nant properties that rarely serve a purpose, and most often these properties are
outright detrimental to function. These everyday examples automatically pose a
thorny question: are oscillations an essential ingredient of the brain “design,” or
are they simply an inevitable byproduct of the opposing forces that are so ubiq-
uitous in neurons and neuronal networks? Throughout this volume, I have tried
to convince the reader that oscillations in the brain serve useful functions and
that, without understanding these rhythms, the brain cannot be fully understood.
However, I postponed addressing the difﬁculty involved in providing a deﬁnite
answer to this difﬁcult question. I also claimed that evolution took advantage of
the ease with which synchrony can be brought about by oscillations at multiple
temporal and spatial scales. However, I have not addressed the tough question of
whether oscillations are critical for the emergence of the most complex brain op-
erations, as well. Because oscillations and complex systems have been exten-
sively discussed in the consciousness debate, it would be unfair to ﬁnish a book
on brain rhythms without bringing up this much-debated issue.2 Below are my
thoughts, without pretending that I have the right solutions to these difﬁcult
problems.
Brain without Oscillations?
Most experiments discussed in the preceding Cycles dealt with correlations be-
tween some overt or covert behavior and oscillations. Providing only correlations,
as supportive evidence for a function, is usually viewed with skepticism. In gen-
eral, there are two types of objections presented against the case for brain oscilla-
tions. First, “I do not see them in my experiments; therefore, they do not exist or
are not essential.” Second, “My intervention eliminated the oscillations but did
not affect behavior.” These objections are relatively easy to dismiss on logical
grounds. For example, the absence of evidence (not seeing it) is not sufﬁcient ev-
idence against the existence of a rhythm. One should look harder and use higher
resolution methods. Furthermore, elimination of the rhythm may not have been
complete, or the behavior under investigation may not have depended on the net-
work examined. Arguments in favor of rhythms are similar and equally vulnera-
ble. First, “In my experiments, a speciﬁc behavior is always accompanied by a
2. Crick and Koch (1990) suggested gamma oscillation as a carrier of conscious experience, al-
though they subsequently rejected it in favor of a special type or group of neurons with hitherto undis-
closed features (Crick and Koch, 2003; Koch, 2004). More recently, they pointed to the claustrum as
the critical structure in consciousness because of its widespread cortical and subcortical connections
(Crick and Koch, 2005). Rodolfo Llinás conjectured that consciousness is the product of a resonance
between the speciﬁc and nonspeciﬁc thalamocortical systems in the gamma frequency range (Llinás
et al., 1994). Freeman (1999) describes consciousness as a two-step process, led by the intentional
causation self and followed by the awareness of the self and its actions. The two steps are realized
through hierarchically stratiﬁed kinds of neural activity, but the functions and nature of neuronal
activity of these processes are not detailed.

Tough Problems     
359
particular oscillation.” Second, “Whenever my intervention affects oscillations,
behavior is always impaired.” These arguments can also be easily dismissed.
First, correlation is not causation. Second, the intervention may not have been se-
lective enough, and the behavioral impairment may not have been caused by the
absence of oscillations but by some unwanted and unobserved side effect of the
perturbation.3
The acid test for providing a deﬁnite proof for the essential role of brain
rhythms in computation and brain function would be to selectively eliminate them
and examine what is left after the complete lack of oscillatory timing. Unfortu-
nately, this test in its pure form cannot be performed for reasons I discussed in
previous Cycles. I brieﬂy reiterate those arguments here. Most oscillations in the
brain are not driven by an independent pacemaker but emerge from nonoscilla-
tory constituents. Even when a pacemaker is identiﬁed, it is typically embedded
in large networks with a complex feedback to the rhythm-generating neurons. As
a result, oscillations are not a product of some independent function or structure
that can be physically removed or selectively manipulated, leaving the rest of the
brain patterns invariant. In fact, there is a logical absurdity in the quest of ex-
punging oscillations selectively. Oscillation is an emergent property; that is, it re-
ﬂects an order parameter that, in turn, affects the parts that gave rise to it. Thus,
there is nothing “extra” to eliminate without fundamentally interfering with the
elementary properties of the parts. Oscillations and other emerging collective pat-
terns do not have “receptors” that can be affected by drugs or other means; only
individual neurons do. It is not possible to selectively eliminate a rhythm without
altering membrane channels, synapses, ﬁring patterns of individual neurons, or
their temporal interactions.4 The problem in the quest for selective elimination of
an order parameter lies in the reciprocal causal relationship between parts and the
whole of an emergent quality, such as an oscillation.
Given the difﬁculty in providing an acid test, the bafﬂing question naturally
arises of whether a brain without oscillations can function properly. In principle,
the answer is yes, as long as synchrony of neuronal assemblies can be brought
about by some other mechanism(s) at the right time scales. In other words, what
may not be essential is the rhythmic aspect of synchrony. As discussed in Cycle 5,
3. A scientiﬁc hypothesis or theory, of course, cannot be proven. A proof can be provided only
when the rules are known, as is the case in mathematics. But in science, the rules are not known. Hy-
potheses and theories are constructed to guess what those rules might be. Good theories are not proven
but rather are not (yet) replaced by more universal theories.
4. Nearly all interventions that affect oscillations are associated with gross changes of ﬁring rates
and/or alteration of the balance between excitation and inhibition. Our laboratory found a notable ex-
ception to this general rule. Activation of cannabinoid receptors, the brain targets of marijuana, pre-
served the ﬁring rates of both pyramidal cells and interneurons in the hippocampus. Nevertheless, it
reduced or eliminated theta, gamma, and ripple oscillations. The effect is due to a balanced reduction
of presynaptic release of both GABA and glutamate and the ensuing reduction of population syn-
chrony. While individual neurons keep emitting the same numbers of action potentials under the
drug’s inﬂuence, the spikes are no longer associated with assembly behavior (Robbe et al., 2005). The
impairment of oscillation and synchrony may explain the detrimental memory effects of marijuana.

360
RHYTHMS OF THE BRAIN
computers, TV sets, and other devices can also run, in principle, without oscilla-
tory clocks, provided that some other mechanisms do the necessary temporal co-
ordination across all levels of computation. If proper timing can somehow be
provided by a nonrhythmic solution, the same brain hardware could perform all
functions. However, this imaginary brain has to deal with further problems. First,
it has to eliminate or randomize all time constants of its constituent neurons and
their connections, because such constants are natural sources of oscillations. Sec-
ond, it should eliminate the balance between opposing forces, such as excitation
and inhibition or ion inﬂux and outﬂux, because these opposing forces are also
natural forces of oscillations. Alternatively, special mechanisms should be intro-
duced for the annihilation of the emergent oscillations. Elimination of oscillations
would also require introducing other mechanisms to keep track of time. In other
words, avoiding oscillations and their consequences on the population behavior
of neurons is much more complicated than exploiting the synchronization conse-
quences of naturally emerging oscillations. Oscillations are ubiquitous in all
brains, small and large; therefore, it is expected that such inherent features would
be exploited by evolution. Rhythms naturally arise from the opposing forces that
are so fundamental for brain operations, and oscillations are a “free” source of
synchronization and timing. Understanding the utility of brain rhythms is possi-
ble only from this evolutionary perspective. On the other hand, the evolutionary
argument also implies that oscillations play a role at all levels of brain function,
from the simplest to the most complex, including the subjective character of brain
computation.
Consciousness: A Function without Deﬁnition
What is the difference between a blink and a wink? The straightforward answer is
that you must be conscious to execute a wink whereas blinking is a simple reﬂex.
And what is the difference between declarative and nondeclarative memories?
The answer is that we are aware of declarative memories; therefore, we can con-
sciously declare them, which is not the case for nondeclarative memories. The ex-
planatory power of these answers, of course, depends on the understanding of the
hypernym “consciousness,” which supposedly makes the distinction between the
declarative and nondeclarative or voluntary and automatic clear. Consciousness is
the crutch of cognitive neuroscience, perhaps the most widely used covert ex-
planatory tool for the classiﬁcation of mental phenomena. Yet, this frequently
used hypernym does not even have a deﬁnition. Is it a product, a process, or a
thing? There is not even good agreement what the theory about consciousness
would be like.5
5. Stating that a wink is voluntary whereas the blink is involuntary faces the same linguistic prob-
lem since the hypernym “volition” remains undeﬁned. Juarrero (2000) is a good guide for the philo-
sophical debate about the voluntary vs. involuntary distinction. The compilation of essays on the self

Tough Problems     
361
Although deﬁnitions of consciousness vary, from those proposed by philoso-
phers to those put forth by practicing anesthesiologists and neuroscientists, it may
be helpful to list some of the suggested deﬁnitions. The reductionist’s view is am-
ply exempliﬁed by Carl Sagan’s famous statement: “My fundamental premise
about the brain is that its workings—what we sometimes call the ‘mind’—are a
consequence of its anatomy and physiology and nothing more.”6 In essence, this
and similar statements claim that conscious behavior is the direct product of brain
activity. However, they fall short of explaining the “hard” question of why we are
aware of some brain operations but not of others, or, in other words, why some
neural representations are translated into mental representations whereas others
are not.7 Sagan’s reductionistic deﬁnition also misses the fact that the brain is em-
bedded in a body and an environment, and it is questionable whether a single
brain in isolation would be conscious.8 The neuroscientist E. Roy John deﬁnes
consciousness as
a process in which information about multiple individual modalities of sensation and
perception is combined into a uniﬁed multidimensional representation of the state of
the system and its environment, and integrated with information about memories and
the needs of the organism, generating emotional reactions and programs of behavior
to adjust the organism to its environment.9
This contextual deﬁnition has the advantage of not being exclusive, and it can in-
corporate issues such as whether some animals have a conscious experience sim-
ilar to that of humans. Giulio Tononi at the University of Wisconsin in Madison
deﬁnes the problem within the context of information theory: the brain’s capac-
ity to integrate and differentiate information corresponds to the quantity of
consciousness.10 In contrast to these nominal deﬁnitions stands the Cartesian
dualistic view that consciousness is a thing, independent of the brain or other
matter.
and soul by Hofstadter and Dennett (1981) is a nice summary of ideas about consciousness and the
mind. Christof Koch’s success book (Koch, 2004) discusses the numerous issues involved in deﬁning
the problem.
6. Sagan (1977), p. 26.
7. The “hard” problem of consciousness is how feelings arise. All other issues are considered
“easy” or manageable because they can be understood by neural mechanisms (Chalmers, 1996).
8. In common parlance, consciousness denotes being awake and responsive to one’s surroundings.
The word “consciousness” comes from the Latin con (with) and scio (to know), meaning “that with
which we know.” However, in many languages it means “shared knowledge,” referring to a “calibra-
tion” of a brain’s output in light of responses by others to those outputs (Szirmai and Kamondi, 2006).
Plum and Posner (1980) deﬁne consciousness as “the state of awareness of self and the environment.”
(p. 242). This medical deﬁnition only shifts the problem to another unexplained hypernym, “aware-
ness.” Faced with the difﬁculty of an objective deﬁnition, the usual attitude is to take the meaning of
consciousness for granted (“Man, if you gotta ask what jazz is, you will never know”—Louis Arm-
strong) or ignore it (“If you can’t explain it, deny it”).
9. John (2005), p. 145.
10. Tononi’s information theory model of consciousness (Tononi, 2004) implies that subjective ex-
perience is one and the same thing as a system’s capacity to integrate and differentiate information.

362
RHYTHMS OF THE BRAIN
Faced with the difﬁculty of providing an objective deﬁnition, an alternative ap-
proach is to ask what brain systems are involved in those behaviors that are usu-
ally characterized as signifying consciousness and what distinguishes them from
systems that do not support consciousness. For example, instead of distinguishing
between declarative and nondeclarative memories, we can classify experience as
whether or not it depends critically on operations of particular brain structures
(e.g., hippocampus-dependent memory). Below, I follow this approach and sug-
gest that brain systems that give rise to the subjective conscious experience re-
quire special anatomical connectivity and a special constellation of oscillations
that characterize the mammalian cerebral cortex. My goal is not to take sides in
the consciousness debate but to contrast architectures of different evolutionary
lineages and their performance constraints and convince the reader of the viabil-
ity of this approach.
Networks That Do Not Feel
I have discussed two distinct anatomical “design” principles so far, each of which
serves different functional roles. The relatively random connectivity of the hip-
pocampus is ideally suited for storing and recalling arbitrary events embedded in
a spatiotemporal context. The scalable, small-world-like architecture of the neo-
cortex, on the other hand, can effectively deal with the statistical regularities of
the environment, can combine or bind the various features, and can make calcu-
lated decisions on the basis of complex features, such as previous experience and
the current state of the network upon which the environmental inputs impinge.
There is general agreement that the neocortex is essential for awareness and that
the hippocampus-supported episodic memories give rise to the “feeling of indi-
viduality.” The essence of cortical operation is that, whatever computation takes
place locally, other parts of the cortex get informed about it, due to the
intermediate- and long-range connections and oscillatory coupling mechanisms.
Conversely, self-organized (spontaneous) activity in large cortical areas perpetu-
ally inﬂuences the nature of local processing of external inputs. In other words,
computation in the cerebral cortex is global.
The implication of his theory is that any physical system that is capable of integrating information, ir-
respective of what it is made of, must have subjective experience. Subjective experience, as integra-
tion, is graded, not all or none. The brain’s capacity to integrate information grows with increasing
brain size; therefore, larger brains, in general, are “more conscious.” The medical deﬁnition of brain
death indirectly supports this “information integration” model of consciousness: the total and irre-
versible loss of the brain’s capacity to integrate and coordinate the functions of the body—physical
and mental—into a functional unit. A tacit assumption of the information integration model is that in-
formation is a physical reality, independent of the observer, and the observer’s brain only manipulates
or transforms the objective reality. However, as discussed in Cycles 9 and 12, representation of the out-
side world is a combination of some ego-ﬁltered input and past experience. Thus, the paradox is that
consciousness of the brain is explained with a measure that is the product of the brain itself.

Tough Problems     
363
Because a major claim of this book is that the complex wiring of the neocortex
supports its complex (1/f) self-organized network patterns, it is instructive to
look at other structures that followed different evolutionary paths and that do not
support 1/f type self-organization. Two such prime examples are the cerebellum
and the basal ganglia.11 Another reason for comparing these structures with the
organization of the neocortex is that even complete damage of the cerebellum or
basal ganglia does not abolish consciousness.
Circuit Plan of the Cerebellum
The cerebellum, or “little brain,” has approximately the same number of cells as
the rest of the brain combined, yet it occupies less than 10 percent of the human
skull volume. The reason for such an efﬁcient space savings is that the cerebellum
is a truly locally organized structure. It receives its main inputs from the cerebral
cortex, the basal ganglia, the reticular system, and spinal pathways containing
sensory inputs from muscles spindles, tendons, and joints. Through these inputs,
the cerebellum continually monitors the activity of skeletal muscles and informs
brain areas that regulate these muscles. The result is the execution of rapid,
skilled movements at speeds that are much faster than can be controlled by the
“conscious” sensory systems.12 These computations are carried out in the anterior
and posterior lobes, whereas the more ancient ﬂocculonodular lobe is concerned
primarily with vestibular functions, such as posture and eye movements. The sur-
face of the cerebellar cortex is increased by shallow ﬁssures, which create multi-
ple folia. However, there is no corpus callosum or intermediate- or long-range
associational paths, nor there are other space-expensive connections. Further-
more, there are no substantial regional variations that would justify cytoarchitec-
tural classiﬁcation, similar to the Brodmann areas of the neocortex. Unlike the
cerebral cortex, the cerebellum is not a mammalian invention. All vertebrate ani-
mals have a cerebellum with highly preserved phylogenetic homology, and it con-
tinues to serve identical functions.13
Computation in the cerebellar cortex is carried out cooperatively by four types
of GABAergic inhibitory cells—the Purkinje cells, basket cells, stellate cells, and
Golgi cells—and excitatory granule cells (ﬁgure 13.1). Purkinje cells are the prin-
cipal computational neurons of the cerebellum and exhibit many differences from
the pyramidal cells of the cerebrum. There are 15 million Purkinje cells in the
11. Paul MacLean’s reptilian archipallium (olfactory bulb, brainstem, mesencephalon, cerebellum,
and the basal ganglia; MacLean, 1990) is characterized by lack of intelligence and subjectivity and no
sense of time and space.
12. A point in case is Glenn Gould’s legendary speed of ﬁnger movements in his 1955 recording
of Bach’s Goldberg Variations. It almost seems impossible that ﬁngers could move that fast with such
perfectly calculated temporal precision! Motor practice can likely “chunk” long passages of move-
ment sequences into a “ballistic-type” action without a need for detailed sensory feedback.
13. A short review of the evolution of the cerebellum is Bell (2002). For a thorough exposure to the
cerebellum, consult the classic reference Eccles et al. (1967). Although neocerebellar circuits receiv-
ing and targeting nonmotor neocerebellar areas may support nonmotor functions, as well, the nature
of computation in these circuits likely remains the same.

364
RHYTHMS OF THE BRAIN
human cerebellum. The extensive dendritic arborization of the Purkinje cell is the
most elaborate in the brain. However, in contrast to the cortical pyramidal cells
that have cylindrical dendritic arbors and extensive mutual overlap with thou-
sands of other nearby pyramidal cells, Purkinje cells are ﬂat, and their dendrites
hardly touch each other. This organization provides maximum autonomy for each
Purkinje cell.
The principal source of glutamatergic excitation in the cerebellar cortex comes
from the small but numerous granule cells, densely packed below the cell bodies
of Purkinje cells. There are more granule cells (∼1011) than all neurons combined
in the neocortex. However, they have very small dendrites and receive inputs from
only three to ﬁve so-called mossy ﬁbers, which originate mainly in the brainstem.
The remaining three sets of neurons are present in smaller numbers. Basket cells
innervate the somata of Purkinje cells, whereas stellate cells inhibit the dendrites.
The ﬁfth cell type, the Golgi cell, inhibits granule cells.
The basic cerebellar circuit can be conceived as three sets of loops attached to
the rest of the brain (ﬁgure 13.1, right). The short loop involves the mossy ﬁbers
from the brainstem area, which innervate the deep cerebellar nuclei.14 The outputs
14. Three nuclei compose the deep cerebellar complex: the dentate nucleus, the interposed nuclei
(which is composed of the emboliform and globose nuclei), and the fastigial nucleus. They act as “re-
lays” for information in and out of the cerebellum and receive topographically arranged inputs from
regions of the cerebellar cortex. The fastigial nucleus controls trunk movements and receives inputs
from the midline, also called the vermis for its wormlike appearance. The interposed nuclei are inner-
vated by the intermediate zones or paravermis and control ipsilateral limb movements. The main input
to the dentate nucleus is from the larger lateral hemispheres. This complex is thought to be involved in
motor “planning,” i.e., prediction and coordination.
Figure 13.1. The cerebellum is organized as multiple parallel loops without interloop
communication. Left: Histological section through a cerebellar folium. Middle: Position of
cerebellar cell types. Purkinje cells are juxtaposed to each other with little overlap of their
large dendritic trees. Right: Inhibitory loops complement the mossy ﬁber–deep cerebellar
excitatory loop. The short loop involves the climbing ﬁber–Purkinje cell–deep nucleus
feedforward path, whereas the long loop includes the mossy ﬁber–granule cell–Purkinje
cell–deep nucleus path.

Tough Problems     
365
from these nuclei affect structures primarily involved in motor control. The two
longer loops involve the cerebellar cortex and are more elaborate. In addition to
the deep cerebellar nuclei, collaterals of the mossy ﬁbers address thousands of
granule cells. The granule cells then project axons into the outer molecular layer
of the cerebellar cortex, containing the dendrites of Purkinje cells. Here, the ax-
ons bifurcate and form ﬁber bundles, which run parallel to the cortical surface and
perpendicular to the ﬂat dendritic trees of the Purkinje cells. The very thin, un-
myelinated parallel ﬁbers each pass through 500 Purkinje cells, and each Purkinje
cell receives information from an estimated 200,000 parallel ﬁbers. The goal of
this arrangement is to disperse or sparsify the inputs into a large synaptic space
for reﬁned computation. In turn, the synchronous discharge of a very large num-
ber of convergent granule cells is needed to bring their target Purkinje cell to
threshold, whose output spiking activity inhibits neurons in the deep cerebellar
nuclei. This mossy ﬁber–granule cell–Purkinje cell loop is therefore a feedfor-
ward inhibitory path superimposed on the short loop.
The other feedforward inhibitory loop is a “shortcut” that originates in the in-
ferior olive of the brainstem, bypasses the granule cells, and terminates directly
on the Purkinje cells.15 Each of these so-called climbing ﬁbers innervates a sin-
gle Purkinje cell but with multiple contacts, so that their spiking activity can in-
duce burst ﬁring in the Purkinje cell. In short, the canonical circuit of the
cerebellar cortex is two parallel feedforward inhibitory loops that exert differen-
tial and elaborate control over the output deep cerebellar neurons.16 This anatom-
ical arrangement suggests that cerebellar “modules,” which roughly correspond
to the extent of parallel ﬁbers, process the incoming inputs locally, but they do
not need to consult or inform the rest of the cerebellum about the locally derived
computation.
Circuit Plan of the Basal Ganglia
Another major loop attached to the brainstem–thalamocortical system involves
the basal ganglia. Similar to the cerebellar loop, the cortex–basal ganglia–thala-
mocortical pathways have major inhibitory steps in the loop (ﬁgure 13.2). The
projections from one step to the next are largely topographic, providing two
15. The inferior olive or inferior olivary nucleus is a homogeneous collection of gap junction-
connected neurons in the medulla oblongata lateral to the pyramidal tract. Its axons form the climbing
ﬁbers that terminate on cerebellar Purkinje cells. The nucleus is often thought of as a pacemaker be-
cause its neurons individually and collectively oscillate at 4 to 10 hertz (Llinás and Yarom, 1981; Bal
and McCormick, 1997).
16. For functions and dysfunctions of the cerebellum, the best summary remains Eccles et al.
(1967). Motor learning is typically studied by classical conditioning. The conditioned stimulus is car-
ried by the thin, slow-conducting mossy ﬁbers, whereas unconditioned stimulus is represented by the
climbing ﬁber input. By proper timing of these inputs, the efﬁcacy of parallel ﬁbers on their target
Purkinje cells can be effectively modiﬁed (Ito, 1989; McCormick and Thompson, 1984; Thompson
2005). In vivo recordings from single granule cells show that mossy ﬁber excitation is essential for
their spiking activity (Chadderton et al., 2004).

366
RHYTHMS OF THE BRAIN
possible scenarios for computation. The ﬁrst possibility is a reentrant loop. For
example, the supplementary motor area 1 and the frontal eye-ﬁeld representa-
tion in the primate motor cortex send inputs to the basal ganglia and thalamus,
and the pathways remain segregated all the way before returning to the cortical
cell groups where they originated. The second possibility is that the activity “spi-
rals” in the loop so that the return message will address areas different from its
origin. In both cases, there is little integration between the participants of the
separate loops, another case for parallel processing. Parallel processing does not
require recurrent excitatory or long-range circuits but comes with the caveat that
no global computation can take place because information is shared only by ad-
jacent local circuits.
The collective term “basal ganglia” refers to the serially connected striatum,
globus pallidus external segment, and globus pallidus internal segment (entope-
duncular nucleus in rodents)/substantia nigra pars reticulata. What makes these
large gray masses so special is that nearly all of their neurons use GABA as a neu-
rotransmitter. Besides the cortex, a major glutamatergic excitatory input with re-
ciprocal connections to pallidum and substantia nigra is the subthalamic nucleus,
a hub with numerous other connections. In addition, the midline and intralaminar
thalamic nuclei provide further excitation. Finally, the ventral thalamic nuclei
provide the cerebellum a link to the basal ganglia.
Figure 13.2. Inhibitory loops of the basal ganglia. Left: Location of the major structures
of the basal ganglia in a horizontal section of the human brain, including the striatum (cau-
date nucleus, CA, and putamen and pallidum). Right: Major connections of the basal gan-
glia. The multiple inhibitory loops are funneled onto the relatively small ventralis anterior
and ventralis lateralis (VA/VL) nuclei of the thalamus, affecting cortical–thalamic–cortical
communication. The multiple loops include neocortex–striatum–pallidum; neocortex–stria-
tum–substantia nigra pars reticulata (SNr), neocortex–subthalamic nucleus (STN)–pal-
lidum; and neocortex–STN–SNr.

Tough Problems     
367
The striatum receives its major excitatory inputs from the neocortex and allo-
cortex. More than 95 percent of its neurons are of the same kind, called medium
spiny neurons, which receive cortical inputs on the spines and thalamic inputs
onto their dendrites and spines. The axons of these principal neurons arborize lo-
cally, covering a disk with a diameter of a several hundred micrometers before
giving rise to the projection axon, which reaches target cells in the external pal-
lidum or substantia nigra. These projection cells are complemented by two groups
of cells, another inhibitory basket cell-like interneuron and a large cholinergic
neuron, which are reciprocally connected to the principal cell type. These three
major cell types compose the computational circuit of the striatum. Interactions
are limited by the extent of the local collaterals, and there are no options for
long-distance talk without the assistance of other structures. Given the similar-
ity of cytoarchitecture and computation throughout the striatum, the differential
behavioral effects in the different parts must come from the speciﬁcity of their
inputs.
The cell organization in the target external pallidum is similar, except that the
principal cell type here has sparsely branching but very long, smooth dendrites.
The neurons, like Purkinje cells, are ﬂat. There is an order of magnitude fewer
pallidal cells than medial spiny neurons in the striatum, the consequence of which
is a large striatopallidal convergence. The output side of the pallidum is the inter-
nal pallidum and the dopaminergic compact part (pars compacta) and GABAergic
reticular part (pars reticulata) of the substantia nigra. The major target of the
output GABAergic neurons in these structures is the subthalamic nucleus. In ad-
dition, the inhibitory terminals innervate the ventral and other nuclei of the thala-
mus.17
The similarity between the cerebellar and basal ganglia architectural organiza-
tions is striking. Very large numbers of parallel inhibitory loops are funneled back
onto a relatively small, excitatory hub with widespread projections (i.e., deep
cerebellar nuclei and the ventral thalamic nuclei, respectively). The best guess for
the computation role of this arrangement is that the neurons in the loops provide
the necessary calculation for precise spike timing for the numerically much
smaller target neurons in these hubs. The strictly local organization of the loops
can provide highly accurate temporal coordination for adjacent targets only (e.g.,
for high-precision coordination of neighboring muscles). Integration between
17. An excellent overview of the anatomical organization of the basal ganglia is Heimer et al.
(1995). For the discussion of parallel computation in functionally segregated loops, see Alexander et
al. (1986), Graybiel et al. (1994), and Haber (2003). Intrinsic connectivity is discussed in Koós and
Tepper (1999) and Chang et al. (1981). The loops involving orbitofrontal, anterior cingulate, and dor-
solateral prefrontal cortices may contribute to nonmotor functions (Bolam et al., 2000). It should be
noted that the above description ignores the complex mosaic organization of neurochemical systems
that are related to these neuroanatomical connections. For a thorough discussion of the segregation of
the functional compartments, see Gerfen (1992). The dorsolateral vs. ventromedial functional distinc-
tions are based mainly on the input-output connections. This applies to the core vs. shell divisions of
the nucleus accumbens, as well (Záborszky et al., 1985).

368
RHYTHMS OF THE BRAIN
nonadjacent calculations, when necessary, must occur downstream to the outputs.
Alternatively, the calculations can proceed in parallel, and the precision of timing
is due to the similar initiating conditions by the inputs.
Sustained Activity Requires Regenerative Feedback
A fundamental difference between the inhibition-dominated cerebellum and
basal ganglia circuits, on the one hand, and cortical networks, on the other, is the
inability of the former structures to support large-scale, self-organized sponta-
neous patterns.18 This is best illustrated by the very low-amplitude local mean
ﬁeld potentials observed from the surface or the depth of the cerebellar cortex.19
From the anatomical point of view, the low-amplitude activity is surprising,
given the regular architectonics of the cerebellum and the parallel excitatory in-
puts it receives. On the basis of cytoarchitecture alone, one might expect to see
local ﬁeld responses as large as those seen in the hippocampus. This is indeed
the case with electrical stimulation, when large numbers of neurons are syn-
chronized by an external input.20 However, in the absence of external synchro-
nization, cerebellar or basal ganglia circuits cannot support spatially widespread
synchrony. Supersynchronous, epileptic discharges never arise from the
GABAergic-neurotransmission–dominated cerebellar or basal ganglia networks.
In fact, it appears that the computation in the locally organized networks of these
structures represents an antithesis of cortical performance, characterized by per-
petual spontaneous activity and temporally coordinated patterns over wide spa-
tial domains.21
Cell-attached and whole-cell recordings in anesthetized rats have shown that
cerebellar granule cells are usually not spontaneously active in vivo and require
excitatory mossy ﬁber synaptic inputs to ﬁre. Inputs from the mossy ﬁbers exhibit
periods of rhythmicity in the 5–13 hertz range.22 The inferior olive also provides
18. Cortical inputs and the subthalamic nucleus do provide excitation to striatal neurons, but this is
not recurrent or reconstructive. Both sources of excitation generate feedforward inhibition.
19. Niedermeyer (2004) concludes that the cerebellar EEG is characterized predominantly by ul-
trafast, low-amplitude patterns, but the “electrocerebellogram is still insufﬁciently understood.”
20. During synchronized inputs from either the brainstem or inferior olive, e.g., during general-
ized petit mal thalamocortical seizures, large-amplitude ﬁelds can be recorded from throughout the
cerebellum, demonstrating that cerebellar circuits can generate extracellular currents, provided that
synchrony is provided from outside (Kandel and Buzsáki, 1993).
21. Of course, the locally conﬁned computation is the essence of these circuits. Balance and mus-
cle coordination require instant and updated short responses. Sustained activity may be detrimental,
since it would interfere with the precise tuning of muscles. Each cerebellar and basal ganglia module
can provide computation with temporally high resolution without interference from distant modules.
This high autonomy is more reminiscent of computer architectures than of the shared computation of
the cerebral cortex.
22. Häusser and Clark (1997) and Häusser et al. (2004). Unfortunately, there are very few studies
on the cerebellar and basal ganglia circuits during sleep, and it cannot be inferred to what extent ac-
tivity is due to the synchronized inputs or to the internal circuitry (e.g., Andre and Arrighi, 2001).

Tough Problems     
369
a rhythmic input to the Purkinje cells in the same frequency range by way of the
climbing ﬁbers. In the absence of chemical neurotransmission, Purkinje cells do
display continuous spiking, but these spikes are not coordinated across neurons.
Even the isolated brainstem–cerebellar preparation, sustained in vitro, has no
spontaneous population activity. However, this preparation responds with oscilla-
tions to the pharmacological challenge by the psychoactive plant alkaloid harma-
line the same way it responds in vivo. The oscillation arises in the olivary network
(10–12 hertz), which drives Purkinje cells. In turn, Purkinje cells generate rhyth-
mic inhibitory potentials in the neurons of the deep cerebellar nuclei.23 Individual
neurons in the cerebellar nuclei ﬁre remarkably rhythmically between 20 and 150
hertz during both waking and sleep states, but they seldom show population syn-
chrony.24
Similarly, coordinated network activity in the basal ganglia neurons is pro-
vided by the cortical inputs, but oscillatory patterns remain highly localized. In
the oculomotor region of the striatum in macaque monkeys, focal oscillations at
15–30 hertz pop in and out of synchrony as the monkey makes saccadic eye
movements.25 Similar local ﬁeld oscillatory patterns have been described in the
rat striatum, as well. However, individual neurons only exceptionally showed
phase-locked spiking with the ﬁeld, suggesting a noncoherent multifocal origin of
the fast waves.26
Only Structures That Display Persistent Neuronal Activity
and Involve Large Neuron Pools Support Consciousness
Although explaining the sufﬁcient conditions for conscious behavior is not within
our reach, we can at least begin to list the necessary requirements by examining
the distinguishing features of the neuronal organizations that support it. The ﬁnd-
ings discussed above illustrate the important point that different anatomical archi-
tectures support different physiological functions. Although oscillations can arise
from many types of networks, only special architectures, such as the cerebral cor-
tex, can support spatially widespread oscillations at multiple temporal scales and
23. Llinás and Muhlethaler (1988).
24. The activity of Purkinje neurons is generated through an intrinsic mechanism, mainly through
persistent Na+ channels (Llinás and Sugimori , 1980; Nitz and Tononi; 2002). Individual Purkinje cells
display strong metastability, switching between sustained ﬁring and hyperpolarized states (Loewen-
stein et al., 2005). However, these state changes are not coordinated across distant Purkinje cells.
25. Courtemanche et al. (2003). For a summary of striatal rhythms, see Brown (2003) and Boraud
et al. (2005).
26. Berke et al. (2004). Most neurons showed synchronous discharge with high-voltage spindles
(Buzsáki et al., 1990), but these rhythms arise in the thalamocortical system, and striatal neurons sim-
ply respond to the cortical inputs. Importantly, the rhythm-generating substrate of Parkinsonian
tremor, a cardinal symptom associated with a deﬁcit of the basal ganglia, is the reticular nucleus–
ventrobasal thalamus circuit.

370
RHYTHMS OF THE BRAIN
27. For my money, understanding the self-organizing ability of the brain is the most interesting
challenge in science. Without such knowledge, it is hard to imagine how we will ever resolve the deep-
est mysteries of the intact and deranged brains.
28. E.g., Srinivasan et al. (1999). Unfortunately, EEG or MEG studies do not have the necessary
spatial resolution to address these issues analytically. Massimini et al. (2005) studied the spread of
evoked activity in response to transcranially induced magnetic stimuli in humans. The stimuli reset al-
pha oscillations and invaded large cortical areas during rest with eyes closed, as expected from the
widespread nature of alpha oscillations (Makeig et al., 2002; Cycle 7). In contrast, the same stimuli
evoked larger local ﬁeld potentials during slow-wave sleep, but the size of the stimulus-affected neo-
cortical territory was smaller compared to the resting state. This latter observation is in line with the
well-known resistance of sleep-related oscillations to external perturbations.
with the consequent 1/f-type, self-organized criticality features. Global, collec-
tive decisions are needed for most cortical functions. Collective decisions, how-
ever, require cooperative actions of both neighboring and distant areas. Flexible
cooperation among local and distant cell assemblies is believed to underlie the ef-
ﬁcacy of cortical performance and is an essential ingredient for cognition, as well.
One may therefore speculate that the ability of a network to generate sustained or
persistent activity is the key for the emergence of conscious experience. If no
long-range connectivity exists and/or if the activity cannot persist for a sufﬁcient
amount of time, locally generated activity cannot engage distant neurons; there-
fore, integration of information over a large neuronal space cannot take place. Re-
generative activity requires positive, excitatory feedback, a critical ingredient
conspicuously absent in cerebellar and basal ganglia circuits. Regenerative feed-
back can incorporate the past into the system’s present state, and it threads the
system through both time and space, thereby allowing input-induced perturba-
tions to be compared with the effects of previous similar encounters. It is the re-
constructive feedback and the sustained neuronal activity it supports that can
place the inputs into context.
The most striking, yet perhaps the least appreciated, behavior of cortical net-
works is their regenerative, spontaneous activity. This self-generated neuronal ac-
tivity is what is constantly added to the sensory inputs. Every spike, sensory
evoked or spontaneous, in cortical principal cells can reach distant neurons. It is
critical to recognize that there is not much else that one can investigate at the neu-
ronal level in the brain besides stimulus-evoked and spontaneous brain activity. If
spontaneous cortical activity is perturbed by a stimulus for a sufﬁciently long
time in large enough neuronal space, it will be noticed; that is, we become aware
of it. This spontaneous, self-organizing ability of cortical networks is what gives
rise to originality and freedom in the brain.27
In contrast to the abstract and arcane problem of consciousness, the issues in-
volved in the interaction between self-organized and evoked activity can be inves-
tigated empirically and systematically by comparing the lifetime and expansion
of an input in neuronal space.28 As discussed in previous Cycles, the same physi-
cal inputs engage neuronal populations of different sizes whether or not they are
perceived, and their efﬁcacy depends on the state of the brain.
Spontaneous activity alone does not give rise to consciousness, however. A

Tough Problems     
371
29. Autonomous oscillations of non-REM sleep and anesthetic states are an antithesis of conscious
awareness. These oscillations are deterministic and resistant to environmental or body inputs. Similar
arguments can be made for the oscillations in the cerebral cortex that characterize sleep (Cycle 7). In
contrast, the scale-free (1/f type) neocortical EEG of waking and REM-sleep reﬂects perpetual phase
transitions brought about by the interference of multiple oscillators and characterized by high sensi-
tivity to perturbation (Cycle 5). The 1/f complex nature of cerebral cortical activity may be the neuro-
biological expression of the integration consciousness index, Φ, of Tononi (2004).
30. Quale (e.g, feeling of a color) and feeling of the self are often distinguished as different quali-
ties. In my view they are related “hard” problems because the difﬁcult issue is the source of “feeling”
rather than the difﬁculty in explaining the difference between color and self. Testing self-
consciousness or self-awareness in nonhuman animals is quite difﬁcult. Nevertheless, there is some
agreement that visual self-recognition or self-identity is present in great apes. E.g., chimps can come
to recognize dabs of paint on their foreheads in a mirror, placed there by the experimenter while the
animals slept (Gallup, 1970). The existence of phenomenal consciousness, i.e., the phenomenological
aspects of conscious experience (related to qualia), is more controversial (e.g., Nagel, 1974). One
identiﬁable quale in most mammals is the feeling of pain. Although “feeling” can be only inferred
from overt behavior, centrally acting pain-relieving drugs not only reduce the subjective feeling of
pain in humans but also can eliminate the motor correlates of inferred pain in other mammals. Interest
in animal consciousness not only is a philosophical issue but also has considerable moral signiﬁcance.
brain grown in vitro with sensors attached but without an ability to move those
sensors by the brain’s output, as discussed in Cycle 8, cannot become conscious,
in the sense that the neuronal responses evoked by the sensory inputs would not
acquire or reﬂect meaning. Similar to the somatosensory system, which requires
metric calibration through movement, and the dead-reckoning navigation system
of the hippocampus, which has to be calibrated by explorative locomotion, con-
sciousness also needs a calibration process. It is the brain’s interactions with the
body and the physical–social environment that provide stability and meaning to a
subset of all possible spontaneous states of the brain. The brain gradually ac-
quires its self-awareness by learning to predict the neuronal performance of other
brains. In other words, acquisition of self-consciousness requires feedback from
other brains. This process may be likened to being one of the protestors in a large
demonstration. A special feeling arises from the realization that multitudes of oth-
ers feel (resonate) the same way (with similar past histories, desires, etc). Self-
consciousness has to be learned.
An explicit prediction of the above speculation is that large numbers of neu-
rons with small-world-like connectivity can give rise to regenerative, spontaneous
activity of the 1/f type, and that this self-organized activity is a potential source of
consciousness.29 An implicit prediction is that such a quality is not all-or-none but
is graded and depends on the size of the network. The lack of long-range connec-
tions and intermittent local neuronal bursts in premature babies implies the ab-
sence of consciousness. Perinatal maturation of cortical anatomy and the
emergence of 1/f cortical dynamics offer the proper substrate for the gradual
emergence of self-awareness. Furthermore, these same properties grant con-
sciousness to not only humans but also to other mammals, although to a lesser de-
gree.30 Consciousness is in the organization, although size also matters. As
Sigmund Freud phrased it, anatomy, in this regard, is destiny. Cerebellum-type

372
RHYTHMS OF THE BRAIN
31. A new story should begin here. It likely did not escape the reader’s attention that rhythms, as
reﬂections of global cortical computations, can be altered by a wide variety of agents and that these
perturbations must seriously alter brain performance. Rhythms are a robust phenotype that can be
monitored and quantiﬁed objectively for the diagnosis and progression of psychiatric and neurological
ailments. Although “rhythmopathies,” “oscillopathies,” and “dysrhythmias” have been discussed re-
peatedly over the years (John, 1977; Rensing et al., 1987; Llinás et al., 2005; Schnitzler and Gross,
2005), recent progress in the understanding of the mechanisms and neuronal content of brain rhythms
infuses a new life into these old terms. Rhythms are affected by most psychotropic drugs, and testing
their effects on neuronal oscillations will likely become a widespread tool in drug discovery.
organization can never give rise to conscious experience, no matter the size. On
the other hand, the cerebral cortex, with its self-organized, persistent oscillations
and global computational principles, can create qualities fundamentally different
from those provided by input-dependent local processing. It may turn out that the
rhythms of the brain are also the rhythms of the mind.31

References
Abbott LF, LeMasson G (1993) Analysis of neuron models with dynamically regulated
conductances. Neural Comput 5:823–842.
Abbott LF, Rolls ET, Tovee MJ (1996) Representational capacity of face coding in mon-
keys. Cereb Cortex 6:498–505.
Abbott LF, Varela JA, Sen K, Nelson SB (1997) Synaptic depression and cortical gain con-
trol. Science 275:220–224.
Abeles M (1982) Local cortical circuits: Studies in brain function. Springer, Berlin.
Achard S, Salvador R, Whitcher B, Suckling J, Bullmore E (2006) A resilient, low fre-
quency, small-world human brain functional network with highly connected association
cortical hubs. J Neurosci 26:63–72.
Acsády L, Kamondi A, Sík A, Freund T, Buzsáki G (1998) GABAergic cells are the ma-
jor postsynaptic targets of mossy ﬁbers in the rat hippocampus. J Neurosci 18:
3386–3403.
Adey WR, Dunlop CW, Hendrix CE (1960a) Hippocampal slow waves: Distribution and
phase relationships in the course of approach learning. Arch Neurol 3:74–90.
Adey WR, Walter DO, Hendrix CE (1960b) Computer techniques in correlation and spectral
analyses of cerebral slow waves during discriminative behavior. Exp Neurol 3:501–524.
Adrian EB, Mathews B (1934) The Berger rhythm. Brain 57:355–385.
Ahissar E, Arieli A (2001) Figuring space by time. Neuron 32:185–201.
Ahmed B, Anderson JC, Douglas RJ, Martin KA, Nelson JC (1994) Polyneuronal innerva-
tion of spiny stellate neurons in cat visual cortex. J Comp Neurol 34:39–49.
373

374
References
Ahmed B, Anderson JC, Martin KA, Nelson JC (1997) Map of the synapses onto layer 4
basket cells of the primary visual cortex of the cat. J Comp Neurol 380:230–242.
Ahn SM, Freeman WJ (1974) Steady-state and limit cycle activity of mass of neurons
forming simple feedback loops (II): Distributed parameter model. Kybernetik 16:
127–132.
Aks DJ, Sprott JC (2003) The role of depth and 1/f dynamics in perceiving reversible ﬁg-
ures. Nonlin Dynam Psychol Life Sci 7:161–180.
Alexander GE, DeLong MR, Strick PL (1986) Parallel organization of functionally segre-
gated circuits linking basal ganglia and cortex. Annu Rev Neurosci 9:357–381.
Alger BE, Nicoll RA (1982) Feed-forward dendritic inhibition in rat hippocampal pyrami-
dal cells studied in vitro. J Physiol (Lond) 328:105–123.
Alheid GF, Heimer L (1988) New perspectives in basal forebrain organization of special
relevance for neuropsychiatric disorders: The striatopallidal, amygdaloid, and corti-
copetal components of substantia innominata. Neuroscience 27:1–39.
Allada R, Emery P, Takahashi JS, Rosbash M (2001) Stopping time: The genetics of ﬂy
and mouse circadian clocks. Annu Rev Neurosci 24:1091–1119.
Allan LG (1979) The perception of time. Percept Psychophys 26:340–354.
Allman JM (1999) Evolving brains. W.H. Freeman and Company, New York.
Allman WF (1992) The mental edge. US News World Rep 113:50–56.
Alonso A, Llinás RR (1989) Subthreshold Na+-dependent theta-like rhythmicity in stellate
cells of entorhinal cortex layer II. Nature 342:175–177.
Alvarez de Lorenzana JM, Ward LM (1987) On evolutionary systems. Behav Sci 32:19–33.
Amaral DG (1993) Emerging principles of intrinsic hippocampal organization. Curr Opin
Neurobiol 3:225–229.
Amaral DG, Witter MP (1989) The three-dimensional organization of the hippocampal
formation: A review of anatomical data. Neuroscience 31:159–177.
Amari S (1982) A mathematical theory of self-organizing nerve systems. In: Biomathe-
matics: Current status and future perspectives (Ricciardi LM, Scott A, eds). North-
Holland, New York, 59–177.
Amassian VE, Cracco RQ, Maccabee PJ, Cracco JB, Rudell AP, Eberle L (1998) Transcra-
nial magnetic stimulation in study of the visual pathway. J Clin Neurophysiol
15:288–304.
Amedi A, Raz N, Pianka P, Malach R, Zohary E (2003) Early “visual” cortex activation
correlates with superior verbal memory performance in the blind. Nat Neurosci
6:758–766.
Amit DJ (1989) Modeling brain function: The world of attractor neural networks. Cam-
bridge University Press, New York.
Amit DJ, Brunel N (1997) Model of global spontaneous activity and local structured activ-
ity during delay periods in the cerebral cortex. Cereb Cortex 7:237–252.
Amzica F, Steriade M (1997) The K-complex: Its low (<1 Hz) rhythmicity and relation to
delta waves. Neurology 49:952–959.
Amzica F, Steriade M (1998) Cellular substrates and laminar proﬁle of sleep K-complex.
Neuroscience 82:671–686.
Anand BK, Chhina GS, Singh B (1961) Some aspects of electroencephalographic studies
in yogis. Electroencephalogr Clin Neurophysiol 13:452.

References
375
Andersen P, Andersson SA (1968) Physiological basis of the alpha rhythm. Appleton-
Century-Crofts, New York.
Andersen P, Brooks C, Eccles JC, Sears TA (1964) The ventrobasal nucleus of the thala-
mus: Potential ﬁelds, synaptic transmission and excitability of both presynaptic and
post-synaptic components. J Physiol (Lond) 174:348–369.
Andersen P, Eccles JC (1962) Inhibitiory phasing of neuronal discharge. Nature
196:645–647.
Andersen RA, Snyder LH, Bradley DC, Xing J (1997) Multimodal representation of space
in the posterior parietal cortex and its use in planning movement. Annu Rev Neurosci
20:303–330.
Andre P, Arrighi P (2001) Modulation of Purkinje cell response to glutamate during the
sleep-waking cycle. Neuroscience 105:731–746.
Andrew C, Pfurtscheller G (1996) Event-related coherence as a tool for studying dynamic
interaction of brain regions. Electroencephalogr Clin Neurophysiol 98:144–148.
Ang CW, Carlson GC, Coulter DA (2005) Hippocampal CA1 circuitry dynamically gates
direct cortical inputs preferentially at theta frequencies. J Neurosci 25:9567–9580.
Anokhin A, Vogel F (1996) EEG alpha rhythm frequency and intellingence in normal
adults. Intelligence 23:1–14.
Arieli A, Sterkin A, Grinvald A, Aertsen A (1996) Dynamics of ongoing activity: Explana-
tion of the large variability in evoked cortical responses. Science 273:1868–1871.
Arroyo S, Lesser RP, Gordon B, Uematso S, Jackson D, Webber R (1993) Functional sig-
niﬁcance of the mu rhythm of human cortex: An electrophysiological study with sub-
dural electrodes. Electroencephalogr Clin Neurophysiol 87:76–87.
Aserinsky E (1996) The discovery of REM sleep. J Hist Neurosci 5:213–227.
Ashby WR (1947) Principles of the self-organizing dynamic system. J Gen Psychol
37:125–128.
Atick JJ, Redlich AN (1992) What does the retina know about natural scenes? Neural
Comp 4:196–210.
Attebo K, Mitchell P, Cumming R, Smith W, Jolly N, Sparkes R (1998) Prevalence and
causes of amblyopia in an adult population. Ophthalmology 105:154–159.
Attneave F (1971) Multistability in perception. Sci Am (Dec) 225:142–151.
Azouz R, Gray CM (1999) Cellular mechanisms contributing to response variability of
cortical neurons in vivo. J Neurosci 19:2209–2223.
Babkoff H, Sing HC, Thorne DR, Genser SG, Hegge FW (1989) Perceptual distortions and
hallucinations reported during the course of sleep deprivation. Percept Mot Skills
68:787–798.
Babloyantz A, Nicolis C, Salazar JM (1985) Evidence of chaotic dynamics of brain activ-
ity during the sleep cycle. Phys Lett 111A:152–156.
Bach-y-Rita P (1972) Brain mechanisms in sensory substitution. Academic Press, New York.
Bair W, Koch C (1996) Temporal precision of spike trains in extrastriate cortex of the be-
having macaque monkey. Neural Comput 8:1185–1202.
Bair W, Koch C, Newsome W, Britten K (1994) Power spectrum analysis of bursting cells
in area MT in the behaving monkey. J Neurosci 14:2870–2892.
Bak P (1996) How nature works. The science of self-organized criticality. Springer-Verlag,
New York.

376
References
Bak P, Tang C, Wiesenfeld K (1987) Self-organized criticality: An explanation of 1/f noise.
Phys Rev Lett 59:381–384.
Baker, RR (1980) Goal orientation in blindfolded humans after long distance displace-
ment: Possible involvement of a magnetic sense. Science 210:555–557.
Bal T, McCormick DA (1993) Mechanisms of oscillatory activity in guinea-pig nucleus
reticularis thalami in vitro: A mammalian pacemaker. J Physiol 468:669–691.
Bal T, McCormick DA (1997) Synchronized oscillations in the inferior olive are con-
trolled by the hyperpolarization-activated cation current I(h). J Neurophysiol 77:
3145–3156.
Baraban SC, Tallent MK (2004) Interneuron diversity series: Interneuronal neuropeptides—
endogenous regulators of neuronal excitability. Trends Neurosci 27:135–142.
Barabási AL (2002) Linked: The new science of networks. Perseus Press, Cambridge, MA.
Barabási AL, Albert R (1999) Emergence of scaling in random networks Science
286:509–512.
Barabási AL, Stanley HE (1995) Fractal concepts in surface growth. Cambridge University
Press, Cambridge.
Baran P (1964) On distributed communications. RAND Books and Publications online.
http://www.rand.org/publications/RM/baran.list.html
Barlow HB (1972) Single units and sensation: A neuron doctrine for perceptual psychol-
ogy. Perception 1:371–394.
Barthó P, Freund TF, Acsády L (2002) Selective GABAergic innervation of thalamic nuclei
from zona incerta. Eur J Neurosci 16:999–1014.
Barthó P, Hirase H, Monconduit L, Zugaro M, Harris KD, Buzsáki G (2004) Characteriza-
tion of neocortical principal cells and interneurons by network interactions and extracel-
lular features. J Neurophysiol 92:600–608.
Bartos M, Vida I, Frotscher M, Meyer A, Monyer H, Geiger JR, Jonas P (2002) Fast synap-
tic inhibition promotes synchronized gamma oscillations in hippocampal interneuron
networks. Proc Natl Acad Sci USA 99:13222–13227.
Bas¸ar E (1980) EEG-brain dynamics: Relation between EEG and brain evoked potentials.
Elsevier, Amsterdam.
Bas¸ar E (ed) (1990) Chaos in brain function. Springer Series in Brain Dynamics, vol 3.
Springer, New York.
Bas¸ar-Eroglu C, Struber D, Schurmann M, Stadler M, Bas¸ar E (1996) Gamma-band re-
sponses in the brain: A short review of psychophysiological correlates and functional
signiﬁcance. Int J Psychophysiol 24:101–112.
Bastiaansen M, Hagoort P (2003) Event-induced theta responses as a window on the dy-
namics of memory. Cortex 39:967–992.
Bastien C, Campbell K (1992) The evoked K-complex: All-or-none phenomenon? Sleep
15:236–245.
Bates JA (1951) Electrical activity of the cortex accompanying movement. J Physiol
(Lond) 113:240–257.
Batini C, Moruzzi G, Palestini M, Rossi GF, Zanchetti A (1959) Effects of complete pon-
tine transections on the sleep-wakefulness rhythm: the midpontine pretrigeminal prepa-
ration. Arch Ital Biol 97:1–12.
Battaglia FP, Sutherland GR, McNaughton BL (2004) Local sensory cues and place cell

References
377
directionality: Additional evidence of prospective coding in the hippocampus. J Neu-
rosci 24:4541–4550.
Bayes T (1958) Studies in the history of probability and statistics. Vol 9. Thomas Bayes’s
essay towards solving a problem in the doctrine of chances. Biometrika 45:296–315
(originally published 1763).
Bell AJ, Sejnowski TJ (1997) The “independent components” of natural scenes are edge
ﬁlters. Vision Res 37:3327–3338.
Bell CC (2002) Evolution of cerebellum-like structures. Brain Behav Evol 59:235–239.
Ben-Ari Y (2005) The multiple facets of GABA. Trends Neurosci 28:277–282.
Bengtsson SL, Nagy Z, Skare S, Forsman L, Forssberg H, Ullen F (2005) Extensive piano
practicing has regionally speciﬁc effects on white matter development. Nat Neurosci
8:1148–1150.
Bennet EA (1985) Meetings with Jung: Conversations recorded during the years,
1946–1961. 2nd ed. Daimon Verlag, Zurich.
Bennett MV, Zukin RS (2004) Electrical coupling and neuronal synchronization in the
Mammalian brain. Neuron 41:495–511.
Benzi R, Sutera A, Vulpiani A (1981) The mechanism of stochastic resonance. J Phys A
14:L453–L457.
Berger H (1929) Ueber das Elektroenkephalogramm des Menschen. Arch Psychiatr Ner-
venkrankh 87:527–570.
Berke JD, Okatan M, Skurski J, Eichenbaum HB (2004) Oscillatory entrainment of striatal
neurons in freely moving rats. Neuron 43:883–896.
Bernardo JM, Smith AFM (1994) Bayesian theory. Wiley, New York.
Bernstein NA (1967) The coordination and regulation of movements. Pergamon Press,
London.
Berry SD, Thompson RF (1978) Prediction of learning rate from the hippocampal elec-
troencephalogram. Science 200:1298–1300.
Bi GQ, Poo MM (1998) Synaptic modiﬁcations in cultured hippocampal neurons: Depen-
dence on spike timing, synaptic strength, and postsynaptic cell type. J Neurosci 18:
10464–10472.
Bibbig A, Faulkner HJ, Whittington MA, Traub RD (2001) Self-organized synaptic plas-
ticity contributes to the shaping of γ, β oscillations in vitro. J Neurosci 21:9053–9067.
Bibbig A, Traub RD, Whittington MA (2002) Long-range synchronization of gamma and
beta oscillations and the plasticity of excitatory and inhibitory synapses: A network
model. J Neurophysiol 8:1634–1654.
Billah KY, Scanlan RH (1991) Resonance, Tacoma Narrows bridge failure, and under-
graduate physics textbooks. Am J Physics 59:118–121.
Billings RJ (1989) The origin of occipital lambda waves in man. Electroencephalogr Clin
Neurophysiol 72:95–113.
Binzegger T, Douglas RJ, Martin KA (2005) Axons in cat visual cortex are topologically
self-similar. Cereb Cortex 15:152–165.
Bichot NP, Rossi AF, Desimone R (2005) Parallel and serial neural mechanisms for visual
search in macaque area V4. Science 308:529–534.
Birbaumer N (1970) The EEG of congenitally blind adults. Electroencephalogr Clin
Neurophysiol 29:318.

378
References
Bishop GH, Smith JM (1964) The sizes of nerve ﬁbers supplying cerebral cortex. Exp
Neurol 9:483–501.
Blair HT, Sharp PE (1995) Anticipatory head direction signals in anterior thalamus: Evi-
dence for thalamic circuits that integrate angular head motion to compute head direc-
tion. J Neurosci 16:2112–2126.
Blakemore C, Van Sluyters RC (1975) Innate and environmental factors in the develop-
ment of the kitten’s visual cortex. J Physiol (Lond) 248:663–716.
Bland BH (1986) Physiology and pharmacology of hippocampal formation theta rhythms.
Prog Neurobiol 26:1–54.
Bland BH, Andersen P, Ganes T, Sveen O (1980) Automated analysis of rhythmicity of
physiologically identiﬁed hippocampal formation neurons. Exp Brain Res 38:205–219.
Bland BH, Colom LV, Konopacki J, Roth SH (1988) Intracellular records of carbachol-
induced theta rhythm in hippocampal slices. Brain Res 447:364–368.
Blinkov SM, Glezer II (1968) The human brain in ﬁgures and tables: A quantitative hand-
book. Plenum, New York.
Bliss TV, Collingridge GL (1993) A synaptic model of memory: Long-term potentiation in
the hippocampus. Nature 361:31–39.
Bliss TV, Lømo T (1973) Long-lasting potentiation of synaptic transmission in the dentate
area of the anaesthetized rabbit following stimulation of the perforant path. J Physiol
(Lond) 232:331–356.
Blum KI, Abbott LF (1996) A model of spatial map formation in the hippocampus of the
rat. Neural Comput 8:85–93.
Bodizs R, Kis T, Lazar AS, Havran L, Rigo P, Clemens Z, Halasz P (2005) Prediction of
general mental ability based on neural oscillation measures of sleep. J Sleep Res
14:285–292.
Bokor H, Frere SG, Eyre MD, Slezia A, Ulbert I, Luthi A, Acsady L (2005) Selective
GABAergic control of higher-order thalamic relays. Neuron 45:929–940.
Bolam JP, Hanley JJ, Booth PA, Bevan MD (2000) Synaptic organisation of the basal gan-
glia. J Anat 196:527–542.
Bollobás B (1985) Random graphs. Academic Press, New York.
Bonhoeffer T, Grinvald A (1991) Iso-orientation domains in cat visual cortex are arranged
in pinwheel-like patterns. Nature 353:429–431.
Boraud T, Brown P, Goldberg JA, Graybiel AM, Magill PJ (2005) Oscillations in the basal
ganglia: The good, the bad, and the unexpected. In: The basal ganglia (Bolam JP, Ing-
ham CA, Magill PJ, eds), vol 7. Springer, New York, 3–24.
Borbely AA (1982) A two-process model of sleep regulation. Hum Neurobiol 1:195–204.
Borbely AA (1998) Processes underlying sleep regulation. Horm Res 49:114–117.
Borbely AA, Tobler I (1989) Endogenous sleep-promoting substances and sleep regula-
tion. Physiol Rev 69:605–670.
Borck C (2005) Hirnströme. eine Kulturgeschichte der Elektroenzephalographie. Wallstein
Verlag, Göttingen.
Borg-Graham LJ (1998) Interpretation of data and mechanisms for hippocampal pyrami-
dal cell models. Cereb Cortex 13:19–138.
Borg-Graham LJ, Monier C, Fregnac Y (1998) Visual input evokes transient and strong
shunting inhibition in visual cortical neurons. Nature 393:369–373.

References
379
Born J, Hansen K, Marshall L, Molle M, Fehm HL (1999) Timing the end of nocturnal
sleep. Nature 397:29–30.
Born J, Wagner U (2004) Memory consolidation during sleep: Role of cortisol feedback.
Ann NY Acad Sci 1032:198–201.
Bower MR, Euston DR, McNaughton BL (2005) Sequential-context-dependent hippocam-
pal activity is not necessary to learn sequences with repeated elements. J Neurosci
25:1313–1323.
Braak H, Braak E (1976) The pyramidal cells of Betz within the cingulate and precentral
gigantopyramidal ﬁeld in the human brain. A Golgi and pigmentarchitectonic study. Cell
Tissue Res 172:103–119.
Bragin A, Engel J Jr, Wilson CL, Fried I, Buzsáki G (1999) High-frequency oscillations in
human brain. Hippocampus 9:137–142.
Bragin A, Jandó G, Nádasdy Z, Hetke J, Wise K, Buzsáki G (1995a) Gamma (40–100 Hz)
oscillation in the hippocampus of the behaving rat. J Neurosci 15:47–60.
Bragin A, Jandó G, Nádasdy Z, van Landeghem M, Buzsáki G (1995b) Dentate EEG
spikes and associated interneuronal population bursts in the hippocampal hilar region of
the rat. J Neurophysiol 73:1691–1705.
Bragin AG, Vinogradova OS (1983) Comparison of neuronal activity in septal and hip-
pocampal grafts developing in the anterior eye chamber of the rat. Brain Res 312:279–286.
Braitenberg V (1978) Cell assemblies in the cerebral cortex. In: Lecture notes on biomath-
ematics (Heim R, Palm G, eds), vol 21. Springer, Berlin, 171–188.
Braitenberg V, Atwood RP (1958) Morphological observations on the cerebellar cortex.
J Comp Neurol 109:1–33.
Braitenberg V, Braitenberg C (1979) Geometry of orientation columns in the visual cortex.
Biol Cybern 33:179–186.
Braitenberg V, Schütz A (1998) Cortex: Statistics and geometry of neural connectivity.
Springer, Berlin.
Brankack J, Stewart M, Fox SE (1993) Current source density analysis of the hippocampal
theta rhythm: Associated sustained potentials and candidate synaptic generators. Brain
Res 615:310–327.
Brazier MAB (1959) The historical development of neurophysiology. In: Handbook of
physiology Vol 1 (J. Field, HW Magoun, VE Hall, Eds)., American Physiological Soci-
ety, Washington, DC, 1–58.
Bremer F (1935) Cerveau isole et physiologie du sommeil. CR Soc Biol Paris
118:1235–1241.
Bressler SL, Kelso JAS (2001) Cortical coordination dynamics and cognition. Trends
Cogn Neurosci 5:26–36.
Broca P (1878) Anatomie comparée des circonvolutions cérébrales. Le grand lobe lim-
bique et la scissure limbique dans le série des mammifères. Rev Anthropol 1:385–408.
Brodmann K (1909) Vergleichende Lokalisationslehre der Grosshirnrinde in ihren Prinzip-
ien dargestellt auf Grund des Zellenbaues. J.A. Barth, Leipzig. Reprint: Localisation in
the cerebral cortex (Garey L, trans). Smith-Gordon, London, 1994.
Brown DA (1998) M-currents: An update. Trends Neurosci 11:294–299.
Brown P (2003) Oscillatory nature of human basal ganglia activity: Relationship to the
pathophysiology of Parkinson’s disease. Mov Disord 18(4):357–363.

380
References
Brun VH, Otnass MK, Molden S, Steffenach HA, Witter MP, Moser MB, Moser EI (2002)
Place cells and place recognition maintained by direct entorhinal-hippocampal circuitry.
Science 296:2243–2246.
Brunel N, Wang XJ (2003) What determines the frequency of fast network oscillations
with irregular neural discharges? I. Synaptic dynamics and excitation-inhibition bal-
ance. J Neurophysiol 90:415–430.
Brunel N, Trullier O (1998) Plasticity of directional place ﬁelds in a model of rodent CA3.
Hippocampus 8:651–665.
Bruns A (2004) Fourier-, Hilbert- and wavelet-based signal analysis: Are they really dif-
ferent approaches? J Neurosci Methods 137:321–332.
Buchanan M (2003) Nexus: Small worlds and the groundbreaking science of networks.
W.W. Norton and Company, New York.
Buchel C (1998) Functional neuroimaging studies of Braille reading: Cross-modal reorga-
nization and its implications. Brain 121:1193–1194.
Buckminster Fuller R (1975–1979) Synergetics—Explorations in the geometry of think-
ing. Vols 1 and 2. Macmillan Publishing Company, New York.
Buhl DL, Harris KD, Hormuzdi SG, Monyer H, Buzsáki G (2003) Selective impairment of
hippocampal gamma oscillations in connexin-36 knock-out mouse in vivo. J Neurosci
23:1013–1018.
Buhl EH, Halasy K, Somogyi P (1994) Diverse sources of hippocampal unitary inhibitory
postsynaptic potentials and the number of synaptic release sites. Nature 368:823–838.
Buhl EH, Tamás G, Szilágyi T, Stricker C, Paulsen O, Somogyi P (1997) Effect, number
and location of synapses made by single pyramidal cells onto aspiny interneurones of
cat visual cortex. J Physiol (Lond) 500:689–713.
Bullier J, Nowak LG (1995) Parallel versus serial processing: New vistas on the distributed
organization of the visual system. Curr Opin Neurobiol 5:497–503.
Bullock TH, Buzsáki G, McClune MC (1990) Coherence of compound ﬁeld potentials re-
veals discontinuities in the CA1-subiculum of the hippocampus in freely-moving rats.
Neuroscience 38:609–619.
Bullock TH, Horridge GA (1965) Structure and function in the nervous system of inverte-
brates. W.H. Freeman, San Francisco.
Bulsara AR, Gammaitoni L (1996) Tuning in to noise. Phys Today 49:39–45.
Buño W Jr, Velluti JC (1977) Relationships of hippocampal theta cycles with bar pressing
during self-stimulation. Physiol Behav 19:615–621.
Bunsey M, Eichenbaum H (1996) Conservation of hippocampal memory function in rats
and humans. Nature 379:255–257.
Buracas GT, Zador AM, DeWeese MR, Albright TD (1998) Efﬁcient discrimination of
temporal patterns by motion-sensitive neurons in primate visual cortex. Neuron
20:959–969.
Burke RE (2001) The central pattern generator for locomotion in mammals. Adv Neurol
87:11–24.
Buzsáki G (1984) Feed-forward inhibition in the hippocampal formation. Prog Neurobiol
22:131–153.
Buzsáki G (1986) Hippocampal sharp waves: Their origin and signiﬁcance. Brain Res
398:242–252.

References
381
Buzsáki G (1989) Two-stage model of memory trace formation: A role for “noisy” brain
states. Neuroscience 31:551–570.
Buzsáki G (1996) The hippocampo-neocortical dialogue. Cerebral Cortex 6:81–92.
Buzsáki G (1998) Memory consolidation during sleep: A neurophysiological perspective.
J Sleep Res 7(suppl):17–23.
Buzsáki G (2002) Theta oscillations in the hippocampus. Neuron 33:325–340.
Buzsáki G (2004) Large-scale recording of neuronal ensembles. Nat Neurosci 7:446–451.
Buzsáki G (2005a) Neurons and navigation. Nature 436:781–782.
Buzsáki G (2005b) Theta rhythm of navigation: Link between path integration and land-
mark navigation, episodic and semantic memory. Hippocampus 15:827–840.
Buzsáki G, Bayardo F, Miles R, Wong RK, Gage FH (1989) The grafted hippocampus: An
epileptic focus. Exp Neurol 105:10–22.
Buzsáki G, Bickford RG, Ponomareff G, Thal LJ, Mandel R, Gage FH (1988) Nucleus
basalis and thalamic control of neocortical activity in the freely moving rat. J Neurosci
8:4007–4026.
Buzsáki G, Bragin A, Chrobak JJ, Nádasdy Z, Sík A, Ylinen A (1994a) Oscillatory and in-
termittent synchrony in the hippocampus: Relevance for memory trace formation. In:
Temporal coding in the brain (Buzsàki G, Llinás RR, Singer W, Berthoz A, Christen Y,
eds). Springer-Verlag, Berlin, 145–172.
Buzsáki G, Buhl DL, Harris KD, Csicsvari J, Czeh B, Morozov A (2003a) Hippocampal
network patterns of activity in the mouse. Neuroscience 116:201–211.
Buzsáki G, Chrobak JJ (1995) Temporal structure in spatially organized neuronal ensem-
bles: A role for interneuronal networks. Curr Opin Neurobiol 5:504–510.
Buzsáki G, Chrobak JJ (2005) Synaptic plasticity and self-organization in the hippocam-
pus. Nat Neurosci 8:1418–1420.
Buzsáki G, Czopf J, Kondakor I, Bjorklund A, Gage FH (1987) Cellular activity of intrace-
rebrally transplanted fetal hippocampus during behavior. Neuroscience 22:871–883.
Buzsáki G, Draguhn A (2004) Neuronal oscillations in cortical networks. Science 304:
1926–1929.
Buzsáki G, Eidelberg E (1981) Commissural projection to the dentate gyrus of the rat: Ev-
idence for feed-forward inhibition. Brain Res 230:346–350.
Buzsáki G, Eidelberg E (1982) Direct afferent excitation and long-term potentiation of
hippocampal interneurons. J Neurophysiol 48:597–607.
Buzsáki G, Geisler C, Henze DA, Wang XJ (2004) Interneuron diversity series: Circuit
complexity and axon wiring economy of cortical interneurons. Trends Neurosci
27:186–193.
Buzsáki G, Grastyán E, Tveritskaya IN, Czopf J (1979) Hippocampal evoked potentials
and EEG changes during classical conditioning in the rat. Electroencephalogr Clin
Neurophysiol 47:64–74.
Buzsáki G, Horváth Z, Urioste R, Hetke J, Wise K (1992) High-frequency network oscilla-
tion in the hippocampus. Science 256:1025–1027.
Buzsáki G, Hsu M, Slamka C, Gage FH, Horváth Z (1991) Emergence and propagation of
interictal spikes in the subcortically denervated hippocampus. Hippocampus 1:163–180.
Buzsáki G, Leung LW, Vanderwolf CH (1983) Cellular bases of hippocampal EEG in the
behaving rat. Brain Res 287:139–171.

382
References
Buzsáki G, Llinás RR, Singer W, Berthoz A, Christen Y (1994b) Temporal coding in the
brain. Springer-Verlag, Berlin.
Buzsáki G, Penttonen M, Nádasdy Z, Bragin A (1996) Pattern and inhibition-dependent in-
vasion of pyramidal cell dendrites by fast spikes in the hippocampus in vivo. Proc Natl
Acad Sci USA 93:9921–9925.
Buzsáki G, Smith A, Berger S, Fisher LJ, Gage FH (1990) Petit mal epilepsy and parkin-
sonian tremor: Hypothesis of a common pacemaker. Neuroscience 36:1–14.
Buzsáki G, Traub RD, Pedley T (2003b) The cellular synaptic generation of EEG. In: Cur-
rent practice of clinical encephalography (Ebersole JS, Pedley TA, eds), 3rd ed.
Lippincott-Williams and Wilkins, Philadelphia, 1–11.
Buzsáki G, Vanderwolf CH (1985) Electrical activity of the archicortex. Akademiai Kiado,
Budapest.
Cacucci F, Lever C, Wills TJ, Burgess N, O’Keefe J (2004) Theta-modulated place-by-
direction cells in the hippocampal formation in the rat. J Neurosci 24:8265–8277.
Cannon RC, Wheal HV, Turner DA (1999) Dendrites of classes of hippocampal neurons
differ in structural complexity and branching patterns. J Comp Neurol 413:619–633.
Cantero JL, Atienza M, Stickgold R, Kahana MJ, Madsen JR, Kocsis B (2003) Sleep-
dependent theta oscillations in the human hippocampus and neocortex. J Neurosci 23:
10897–10903.
Carlmichael L (1934) An experimental study in the prenatal guinea-pig of the origin and
development of reﬂexes and patterns of behavior in relation to the stimulation of speciﬁc
receptor areas during period of active fetal life. Genet Psychol Monogr 16:337–491.
Castaneda C (1972) Journey to Ixtlan: The lessons of Don Juan. Simon and Schuster, New
York.
Caton R (1875) The electric currents of the brain. Br Med J 2:278.
Chadderton P, Margrie TW, Häusser M (2004) Integration of quanta in cerebellar granule
cells during sensory processing. Nature 428:856–860.
Chalmers DJ (1996) The conscious mind. Oxford University Press, New York.
Chang HT, Wilson CJ, Kitai ST (1981) Single neostriatal efferent axons in the globus pal-
lidus: A light and electron microscopic study. Science 213:915–918.
Changeux J-P (1985) Neuronal man: The biology of mind. Random House, New York.
Changizi MA (2003) The brain from 25,000 feet: High level explorations of brain com-
plexity, perception, induction and vagueness. Kluwer Academic, Dordrecht.
Chapin JK (2004) Using multi-neuron population recordings for neural prosthetics. Nat
Neurosci 7:452–455.
Chen Y, Ding M, Kelso JAS (2001) Origins of timing errors in human sensorimotor coor-
dination. J Mot Behav 33:3–8.
Chen Y, Mingzhou D, Kelso JAS (1997) Long memory processes (1/fa type) in human co-
ordination. Phys Rev Lett 79:4501–4504.
Cherniak C (1995) Neural component placement. Trends Neurosci 18:522–527.
Chernigovskii VN, Markman VG, Avsarkisyan AN (1982) Voluntary control of alpha- and
theta-rhythms of the human EEG. Hum Physiol 8:366–370.
Chicurel ME, Harris KM (1992) Three-dimensional analysis of the structure and composi-
tion of CA3 branched dendritic spines and their synaptic relationships with mossy ﬁber
boutons in the rat hippocampus. J Comp Neurol 325:169–182.

References
383
Chiel HJ, Beer RD (1997) The brain has a body: Adaptive behavior emerges from interac-
tions of nervous system, body and environment. Trend Neurosci 20:553–557.
Chiu C, Weliky M (2001) Spontaneous activity in developing ferret visual cortex in vivo. J
Neurosci 21:8906–8914.
Chklovskii DB, Koulakov AA (2004) Maps in the brain: What can we learn from them?
Annu Rev Neurosci 27:369–392.
Chklovskii DB, Mel BW, Svoboda K (2004) Cortical rewiring and information storage.
Nature 431:782–788.
Chklovskii DB, Schikorski T, Stevens CF (2002) Wiring optimization in cortical circuits.
Neuron 34:341–347.
Chrobak JJ, Buzsáki G (1994) Selective activation of deep layer (V-VI) retrohippocampal
cortical neurons during hippocampal sharp waves in the behaving rat. J Neurosci 14:
6160–6170.
Chrobak JJ, Buzsáki G (1996) High-frequency oscillations in the output networks of the
hippocampal-entorhinal axis of the freely behaving rat. J Neurosci 16:3056–3066.
Chrobak JJ, Buzsáki G (1998) Gamma oscillations in the entorhinal cortex of the freely
behaving rat. J Neurosci 8:388–338.
Church RM, Gibbon J (1982) Temporal generalization. J Exp Psychol Anim Behav Process
8:165–186.
Clare HM, Bishop GH (1956) Potential wave mechanism in cat cortex. Electroencephalogr
Clin Neurophysiol 8:583–602.
Clemens Z, Fabo D, Halász P (2005) Overnight verbal memory retention correlates with
the number of sleep spindles. Neuroscience 132:529–535.
Cobb SR, Buhl EH, Halasy K, Paulsen O, Somogyi P (1995) Synchronization of neu-
ronal activity in hippocampus by individual GABAergic interneurons. Nature 378:
75–78.
Cohen D (1968) Magnetoencephalography, evidence of magnetic ﬁelds produced by
alpha-rhythm currents. Science 161:784–786.
Cohen I, Miles R (2000) Contributions of intrinsic and synaptic activities to the generation
of neuronal discharges in in vitro hippocampus. J Physiol (Lond) 524:485–502.
Colgin LL, Kubota D, Jia Y, Rex CS, Lynch G (2004) Long-term potentiation is impaired
in rat hippocampal slices that produce spontaneous sharp waves. J Physiol (Lond) 558:
953–961.
Collins DR, Lang EJ, Paré D (1999) Spontaneous activity of the perirhinal cortex in be-
having cats. Neuroscience 89:1025–1039.
Collins JJ, Imhoff TT, Grigg P (1996) Noise-enhanced information transmission in rat
SA1 cutaneous mechanoreceptors via aperiodic stochastic resonance. J Neurophysiol
76:642–645.
Colon F (1959) The life of admiral Christopher Columbus (Keen B, trans). Rutgers Uni-
versity Press, New Brunswick, NJ (originally published 1571).
Compte A, Sanchez-Vives MV, McCormick DA, Wang XJ (2003) Cellular and network
mechanisms of slow oscillatory activity (<1Hz) and wave propagations in a cortical net-
work model. J Neurophysiol 89:2707–2725.
Connors BW, Long MA (2004) Electrical synapses in the mammalian brain. Annu Rev
Neurosci 27:393–418.

384
References
Connors BW, Regehr WG (1996) Neuronal ﬁring: Does function follow form? Curr Biol
6:1560–1562.
Contreras D, Destexhe A, Sejnowski TJ, Steriade M (1996) Control of spatiotemporal co-
herence of a thalamic oscillation by corticothalamic feedback. Science 274:771–774.
Contreras D, Destexhe A, Steriade M (1997) Spindle oscillations during cortical spreading
depression in naturally sleeping cats. Neuroscience 77:933–936.
Cossart R, Bernard C, Ben-Ari Y (2005) Multiple facets of GABAergic neurons and
synapses: Multiple fates of GABA signalling in epilepsies. Trends Neurosci 28:108–115.
Courtemanche R, Fujii N, Graybiel AM (2003) Synchronous, focally modulated beta-band
oscillations characterize local ﬁeld potential activity in the striatum of awake behaving
monkeys. J Neurosci 23:11741–11752.
Cowey A (1979) Cortical maps and visual perception: The Grindley Memorial Lecture. Q
J Exp Psychol 31:1–17.
Cox CL, Huguenard JR, Prince DA (1996) Heterogeneous axonal arborizations of rat thal-
amic reticular neurons in the ventrobasal nucleus. J Comp Neurol 366:416–430.
Craver CF (2003) The making of a memory mechanism. J Hist Biol 36:153–195.
Crick F, Koch C (1990) Toward a neurobiological theory of consciousness. Semin Neu-
rosci 2:263–275.
Crick F, Koch C (2003) A framework for consciousness. Nat Neurosci 6:119–126.
Crick FC, Koch C (2005) What is the function of the claustrum? Philos Trans R Soc Lond
B Biol Sci 360:1271–1279.
Crick F, Mitchison G (1983) The function of dream sleep. Nature 304:111–114.
Crone NA, Miglioretti DL, Gordon B, Sieracki JM, Wilson MT, Uematsu S, Lesser RP
(1998) Funcional mapping of human sensorimotor cortex with electrocorticographic
spectral analysis. I. Alpha and beta event-related desynchronization. Brain 121:
2271–2299.
Cruse DA (1986) Lexical semantics. Cambridge: Cambridge University Press.
Csermely P (2005) Weak links: A universal key of network diversity and stability.
http://www.weaklink.sote.hu/weakbook.html
Csicsvari J, Hirase H, Czurkó A, Buzsáki G (1998) Reliability and state dependence of py-
ramidal cell-interneuron synapses in the hippocampus: An ensemble approach in the be-
having rat. Neuron 21:179–189.
Csicsvari J, Hirase H, Czurkó A, Mamiya A, Buzsáki G (1999) Oscillatory coupling of hip-
pocampal pyramidal cells and interneurons in the behaving rat. J Neurosci 19:274–287.
Csicsvari J, Hirase H, Mamiya A, Buzsáki G (2000) Ensemble patterns of hippocampal
CA3-CA1 neurons during sharp wave-associated population events. Neuron 28:585–594.
Csicsvari J, Jamieson B, Wise KD, Buzsáki G (2003) Mechanisms of gamma oscillations
in the hippocampus of the behaving rat. Neuron 37:311–322.
Curio G, Mackert BM, Burghoff M, Koetitz R, Abraham-Fuchs K, Harer W (1994) Local-
ization of evoked neuromagnetic 600 Hz activity in the cerebral somatosensory system.
Electroencephalogr Clin Neurophysiol 91:483–487.
Curro Dossi R, Pare D, Steriade M (1992) Various types of inhibitory postsynaptic poten-
tials in anterior thalamic cells are differentially altered by stimulation of laterodorsal
tegmental cholinergic nucleus. Neuroscience 47:279–289.
Curtis LJ (1978) Concept of the exponential law prior to 1900. Am J Phys 46: 896–906.

References
385
Czurkó A, Hirase H, Csicsvari J, Buzsáki G (1999) Sustained activation of hippocampal
pyramidal cells by “space clamping” in a running wheel. Eur J Neurosci 11:344–352.
Damasio AR (1989) Time-locked multiregional retroactivation: A systems-level proposal
for the neural substrates of recall and recognition. Cognition 33:25–62.
Damasio AR (1995) Descartes’ error: Emotion, reason, and the human brain. Avon Books,
New York.
Dan Y, Atick, JJ, Reid RC (1996) Efﬁcient coding of natural scenes in the lateral geniculate
nucleus: Experimental test of a computational theory. J Neurosci 16:3351–3362.
Dan Y, Poo MM (2004) Spike timing-dependent plasticity of neural circuits. Neuron
44:23–30.
D’Angelo E, Nieus T, Maffei A, Armano S, Rossi P, Taglietti V, Fontana A, Naldi G (2001)
Theta-frequency bursting and resonance in cerebellar granule cells: Experimental evi-
dence and modeling of a slow K+-dependent mechanism. J Neurosci 21:759–770.
Deadwyler SA, Hampson RE (1997) The signiﬁcance of neural ensemble codes during be-
havior and cognition. Annu Rev Neurosci 20:217–244.
DeAngelis GC, Ghose GM, Ohzawa I, Freeman RD (1999) Functional micro-organization
of primary visual cortex: Receptive ﬁeld analysis of nearby neurons. J Neurosci
19:4046–4064.
Deboer T, Vansteensel MJ, Detari L, Meijer JH (2003) Sleep states alter activity of supra-
chiasmatic nucleus neurons. Nat Neurosci 6:1086–1090.
deCharms RC, Merzenich MM (1996) Primary cortical representation of sounds by the co-
ordination of action-potential timing. Nature 381:610–613.
de Curtis M, Paré D (2004) The rhinal cortices: A wall of inhibition between the neocortex
and the hippocampus. Prog Neurobiol 74:101–110.
DeFelice LJ (1981) Introduction to membrane noise. Plenum, New York.
DeFelipe J, Jones EG (1988) Cajal on the cerebral cortex. Oxford University Press, New
York.
De Gennaro L, Ferrara M (2003) Sleep spindles: An overview. Sleep Med Rev 7:423–440.
Dehaene S, Sergent C, Changeux JP (2003) A neuronal network model linking subjective
reports and objective physiological data during conscious perception. Proc Natl Acad
Sci USA 100:8520–8525.
Delgado JMR (1969) Physical control of the mind. Toward a psychocivilized society.
Harper and Row, New York.
Demsey EW, Morison RS (1942) The mechanism of thalamo-cortical augmentation and
repetition. Am J Physiol 138:297–308.
Denk W, Strickler JH, Webb WW (1990) Two-photon laser scanning ﬂuorescence mi-
croscopy. Science 248:73–76.
Denk W, Yuste R, Svoboda K, Tank DW (1996) Imaging calcium dynamics in dendritic
spines. Curr Opin Neurobiol 6:372–378.
Dennett DC (1987) The intentional stance. MIT Press, Cambridge, MA.
De Ruyter van Steveninck RR, Lewen GD, Strong SP, Koberle R, Bialek W (1997) Repro-
ducibility and variability in neural spike trains. Science 275:1805–1808.
Deschênes M, Madariaga-Domich A, Steriade M (1985) Dendrodendritic synapses in the
cat reticular thalamic nucleus: A structrural basis for thalamic spindle synchronization.
Brain Res 334:165–168.

386
References
Desimone R, Albright TD, Gross CG, Bruce C (1984) Stimulus-selective properties of
inferior temporal neurons in the macaque. J Neurosci 4:2051–2062.
Destexhe A, Babloyantz A, Sejnowski TJ (1993) Ionic mechanisms for intrinsic slow oscil-
lations in thalamic relay neurons. Biophys J 65:1538–1552.
Destexhe A, Contreras D, Sejnowski TJ, Steriade M (1994) A model of spindle rhythmic-
ity in the isolated thalamic reticular nucleus. J Neurophysiol 72:803–818.
Destexhe A, Rudolph M, Paré D (2003) The high-conductance state of neocortical neurons
in vivo. Nat Rev Neurosci 4:739–751.
Destexhe A, Sejnowski T (2001) Thalamocortical assemblies: How ion channels, single neu-
rons and large-scale networks organize sleep oscillations. Oxford University Press, Oxford.
Destexhe A, Sejnowski T (2003) Interactions between membrane conductances underlying
thalamocortical slow-wave oscillations. Physiol Rev 83:1401–1453.
Diba K, Lester HA, Koch C (2004) Instrinsic noise in cultured hippocampal neurons: Ex-
periment and modeling. J Neurosci 24:9723–9733.
Ding M, Chen Y, Kelso JA (2002) Statistical analysis of timing errors. Brain Cogn
48:98–106.
Donoghue J (2002) Connecting cortex to machines: Recent advances in brain interfaces.
Nat Neurosci 5(suppl):1085–1088.
Donoghue JP, Sanes JN, Hatsopoulos NG, Gaal G (1998) Neural discharge and local ﬁeld
potential oscillations in primate motor cortex during voluntary movements. J Neuro-
physiol 79:159–173.
Douglas RJ, Koch C, Mahowald M, Martin KA, Suarez HH (1995) Recurrent excitation in
neocortical circuits. Science 269:981–985.
Douglas R, Martin KAC (1991) A functional microcircuit for cat visual cortex. J Physiol
(Lond) 440:735–769.
Douglas R, Martin KAC (2004) Neuronal circuits of the neocortex. Annu Rev Neurosci
27:419–451.
Doupe AJ (1994) Seeds of instruction: Hippocampus and memory in food-storing birds.
Proc Natl Acad Sci USA 91:7381–7384.
Draganski B, Gaser C, Busch V, Schuierer G, Bogdahn U, May A (2004) Neuroplasticity:
Changes in grey matter induced by training. Nature 427:311–312.
Dragoi G, Buzsáki G (2006) Temporal encoding of place sequences by hippocampal cell
assemblies. Neuron 50:145–157.
Dragoi G, Harris KD, Buzsáki G (2003) Place representation within hippocampal net-
works is modiﬁed by long-term potentiation. Neuron 39:843–853.
Drive J, Frith C (2000) Shifting baselines in attention research. Nat Rev Neurosci
1:147–148.
Dunlap K (1910) Reactions on rhythmic stimuli, with attempt to synchronize. Psychol Rev
17:399–416.
Dudai Y, Eisenberg M (2004) Rites of passage of the engram: Reconsolidation and the
lingering consolidation hypothesis. Neuron 44:93–100.
Dupont E, Hanganu IL, Kilb W, Hirsch S, Luhmann HJ (2006) Rapid developmental
switch in the mechanisms driving early cortical columnar networks. Nature 439:79–83.
Eagleman DM, Sejnowski TJ (2000) Motion integration and postdiction in visual aware-
ness. Science 287:2036–2038.

References
387
Eccles JC, Ito M, Szentágothai J (1967) The cerebellum as a neuronal machine. Springer-
Verlag, Berlin.
Eckhorn R (2000) Cortical processing by fast synchronization: High frequency rhythmic
and non-rhythmic signals in the visual cortex point to general principles of spatiotem-
poral coding. In: Time and the brain (Miller R, ed). Harwood Academic Publishers,
Australia, 169–201.
Eckhorn R, Bauer R, Jordan W, Brosch M, Kruse W, Munk M, Reitboeck HJ (1988) Co-
herent oscillations: A mechanism of feature linking in the visual cortex? Multiple elec-
trode and correlation analyses in the cat. Biol Cybern 60:121–130.
Edelman G (1987) Neural Darwinism. The theory of neuronal group selection. Basic
Books, New York.
Egorov AV, Hamam BN, Fransen E, Hasselmo ME, Alonso AA (2002) Graded persistent
activity in entorhinal cortical neurons. Nature 420:173–178.
Eichenbaum H (2002) Cognitive neuroscience of memory. Oxford University Press, New
York.
Einstein A (1920/1988) Relativity: The special and general theory. Methuen & Co. Ltd.,
London.
Emery NJ, Clayton N (2004) The mentality of crows: Convergent evolution of intelligence
in corvids and apes. Science 306:1903–1907.
Engel AK, Fries P, Singer W (2001) Dynamic predictions: Oscillations and synchrony in
top-down processing. Nat Rev Neurosci 2:704–716.
Engel AK, Konig P, Singer W (1991) Direct physiological evidence for scene segmentation
by temporal coding. Proc Natl Acad Sci USA 88:9136–9140.
Engel AK, Singer W (2001) Temporal binding and the neural correlates of sensory aware-
ness. Trends Cogn Sci 5:16–25.
Engel J Jr (2002) Early versus late surgery for intractable seizures. Adv Exp Med Biol
497:99–105.
Erb M, Aertsen A (1992) Dynamics of activity in biology-oriented neural network
models: Stability analysis at low ﬁring rates. In: Information processing in the cor-
tex: Experiments and theory (Aertsen A, Braitenberg V, eds). Springer, Berlin,
201–223.
Erdös P, Rényi A (1960) On the Evolution of Random Graphs. Publ Math Inst Hung Acad
Sci 5:17–61.
Ermentrout GB, Kleinfeld D (2001) Traveling electrical waves in cortex: Insight from
phase dynamics and speculation on a computational role. Neuron 29:33–44.
Ermentrout GB, Kopell N (1994) Learning of phase-lags in coupled neural oscillators.
Neural Comput 6:225–241.
Ermentrout GB, Kopell N (1998) Fine structure of neural spiking and synchronization in
the presence of conduction delays. Proc Natl Acad Sci USA 95:1259–1264.
Feldman DE, Nicoll RA, Malenka RC (1999) Synaptic plasticity at thalamocortical
synapses in developing rat somatosensory cortex: LTP, LTD, and silent synapses. J Neu-
robiol 41:92–101.
Fell J, Klaver P, Elfadil H, Schaller C, Elger CE, Fernandez G (2003) Rhinal-hippocampal
coherence during declarative memory formation: Interaction with synchronization? Eur
J Neurosci 17:1082–1088.

388
References
Fell J, Klaver P, Lehnertz K, Grunwald T, Schaller C, Elger CE, Fernandez G (2001) Hu-
man memory formation is accompanied by rhinal-hippocampal coupling and decou-
pling. Nat Neurosci 4:1259–1264.
Felleman DJ, Van Essen DC (1987) Receptive ﬁeld properties of neurons in area V3 of
macaque monkey extrastriatal cortex. J Neurophysiol 57:889–920.
Felleman DJ, Van Essen DC (1991) Distributed hierarchical processing in the primate ce-
rebral cortex. Cereb Cortex 1:1–47.
Fellous JM, Houweling AR, Modi RH, Rao RP, Tiesinga PH, Sejnowski FJ (2001) Fre-
quency dependence of spiking timing reliability in cortical pyramidal cells and in-
terneurons. J Neurophysiol 85:1782–1787.
Fellous JM, Tiesinga PH, Thomas PJ, Sejnowski TJ (2004) Discovering spike patterns in
neuronal responses. J Neurosci 24:2989–3001.
Fenton AA, Muller RU (1998) Place cell discharge is extremely variable during individual
passes of the rat through the ﬁring ﬁeld. Proc Natl Acad Sci USA 95:3182–3187.
Ferbinteanu J, Shapiro ML (2003) Prospective and retrospective memory coding in the
hippocampus. Neuron 40:1227–1239.
Fernandez G, Effern A, Grunwald T, Pezer N, Lehnertz K, Dumpelmann M, Van Roost D,
Elger CE (1999) Real-time tracking of memory formation in the human rhinal cortex
and hippocampus. Science 285:1582–1585.
Fine I, Wade AR, Brewer AA, May MG, Goodman DF, Boynton GM, Wandell BA,
MacLeod DI (2003) Long-term deprivation affects visual perception and cortex. Nat
Neurosci 6:915–916.
Fisahn A, Pike FG, Buhl EH, Paulsen O (1998) Cholinergic induction of network oscilla-
tions at 40Hz in the hippocampus in vitro. Nature 394:186–189.
Fisahn A, Yamada M, Duttaroy A, Gan JW, Deng CX, McBain CJ, Wess J (2002) Mus-
carinic induction of hippocampal gamma oscillations requires coupling of the M1 re-
ceptor to two mixed cation currents. Neuron 33:615–624.
Fiser J, Chiu C, Weliky M (2004) Small modulation of ongoing cortical dynamics by sen-
sory input during natural vision. Nature 431:573–578.
Fletcher ML, Smith AM, Best AR, Wilson DA (2005) High-frequency oscillations are
not necessary for simple olfactory discriminations in young rats. J Neurosci 25:
792–798.
Fodor J (2000) The mind doesn’t work that way: The scope and limits of computational
psychology. MIT Press/Bradford Books, Boston.
Foote SL, Bloom FE, Aston-Jones G (1983) Nucleus locus ceruleus: New evidence of
anatomical and physiological speciﬁcity. Physiol Rev 63:844–914.
Fortin NJ, Wright SP, Eichenbaum H (2004) Recollection-like memory retrieval in rats is
dependent on the hippocampus. Nature 431:188–191.
Foster RG, Kreitzman L (2004) Rhythms of life. The biological clocks that control the
daily lives of every living thing. Yale University Press, New Haven, CT.
Foster TC, Castro CA, McNaughton BL (1989) Spatial selectivity of hippocampal neu-
rons: Dependence on preparedness for movement. Science 244:1580–1582.
Fowler MJ, Sullivan MJ, Ekstrand BR (1973) Sleep and memory. Science 179:302–304.
Fox K (2002) Anatomical pathways and molecular mechanisms for plasticity in the barrel
cortex. Neuroscience 111:799–814.

References
389
Fox MD, Snyder AZ, Vincent JL, Corbetta M, Van Essen DC, Raichle ME (2005) The hu-
man brain is intrinsically organized into dynamic, anticorrelated functional networks.
Proc Natl Acad Sci USA 102:9673–9678.
Fox R, Herrmann J (1967) Stochastic properties of binocular rivalry alterations. Percep-
tand Psychophys 2:432–436.
Frank LM, Brown EN, Wilson M (2000) Trajectory encoding in the hippocampus and en-
torhinal cortex. Neuron 27:169–178.
Frank MG, Issa NP, Stryker MP (2001) Sleep enhances plasticity in the developing visual
cortex. Neuron 30:275–287.
Freeman WJ (1975) Mass action in the nervous system. Academic Press, New York.
Freeman WJ (1991) The physiology of perception. Sci Am, March 264:78–85.
Freeman WJ (1992) Tutorial on neurobiology: From single neurons to brain chaos. Int
J Bifurc Chaos 2:451–482.
Freeman WJ (1999) Consciousness, intentionality, and causality. J Consc Stud 6:143–172.
Freeman WJ (2000) Perception of time and causation through the kinesthesia of inten-
tional action. Cogn Proc 1:18–34.
Freeman WJ, Burke BC, Holmes MD (2003) Aperiodic phase-resetting in scalp EEG of
beta-gamma-oscillations by state transitions at alpha-theta-rates. Hum Brain Map
19:248–272.
Freeman WJ, Rogers LJ (2002) Fine temporal resolution of analytic phase reveals episodic
synchronization by state transitions in EEGs. J Neurophysiol 87:937–945.
Freeman WJ, Rogers LJ, Holmes MD, Silbergeld DL (2000) Spatial spectral analysis of
human electrocorticograms including the alpha and gamma bands. J Neurosci Methods
95:111–112.
Freud S (1900) The interpretation of dreams. Vol 4, std ed. Hogarth Press, London.
Freund TF (2003) Interneuron diversity series: Rhythm and mood in perisomatic inhibi-
tion. Trends Neurosci 26:489–495.
Freund TF, Buzsáki G (1996) Interneurons of the hippocampus. Hippocampus 6:347–470.
Freund TF, Gulyás AI (1997) Inhibitory control of GABAergic interneurons in the hip-
pocampus. Can J Physiol Pharmacol 75:479–487.
Frey U, Morris RG (1997) Synaptic tagging and long-term potentiation. Nature 85:
533–53.
Fries P, Neuenschwander S, Engel AK, Goebel R, Singer W (2001a) Rapid feature selec-
tive neuronal synchronization through correlated latency shifting. Nat Neurosci
4:194–200.
Fries P, Reynolds JH, Rorie AE, Desimone R (2001b) Modulation of oscillatory neuronal
synchronization by selective visual attention. Science 291:1560–1563.
Fries P, Roelfsema PR, Engel AK, Konig P, Singer W (1997) Synchronization of oscilla-
tory responses in visual cortex correlates with perception in interocular rivalry. Proc
Natl Acad Sci USA 94:12699–12704.
Friston KJ (2000) The labile brain. I. Neuronal transients and nonlinear coupling. Philos
Trans R Soc Lond B 355:215–236.
Fuentealba P, Timofeev I, Bazhenov M, Sejnowski TJ, Steriade M (2005) Membrane
bistability in thalamic reticular neurons during spindle oscillations. J Neurophysiol
93:294–304.

390
References
Fukuda T, Kosaka T (2003) Ultrastructural study of gap junctions between dendrites of
parvalbumin-containing GABAergic neurons in various neocortical areas of the adult
rat. Neuroscience 120:5–20.
Gage FH (2002) Neurogenesis in the adult brain. J Neurosci 22:612–613.
Gage FH, Kempermann G, Palmer TD, Peterson DA, Ray J (1998) Multipotent progenitor
cells in the adult dentate gyrus. J Neurobiol 36:249–266.
Gais S, Born J (2004) Low acetylcholine during slow-wave sleep is critical for declarative
memory consolidation. Proc Natl Acad Sci USA 101:2140–2144.
Gais S, Molle M, Helms K, Born J (2002) Learning-dependent increases in sleep spindle
density. J Neurosci 22:6830–6834.
Gais S, Plihal W, Wagner U, Born J (2000) Early sleep triggers memory for early visual
discrimination skills. Nat Neurosci 3:1335–1339.
Galarreta M, Hestrin S (2001) Spike transmission and synchrony detection in networks of
GABAergic interneurons. Science 292:2295–2299.
Gallistel CR (1980) The organization of action: A new synthesis. Lawrence Erlbaum Asso-
ciates, Hillsdale, NJ.
Gallistel CR (1990) The organization of learning. Bradford Books/MIT Press, Cambridge,
MA.
Gallup GG Jr (1970) Chimpanzees: Self-recognition. Science 167:86–87.
Garaschuk O, Linn J, Eilers J, Konnerth A (2000) Large-scale oscillatory calcium waves in
the immature cortex. Nat Neurosci 3:452–459.
Garcia L, D’Alessandro G, Bioulac B, Hammond C (2005) High-frequency stimulation in
Parkinson’s disease: More or less? Trends Neurosci 28:209–216.
Garcia-Sanchez JL, Buño W Jr, Fuentes J, Garcia-Austt E (1978) Non-rhythmical hip-
pocampal units, theta rhythm and afferent stimulation. Brain Res Bull 3:213–219.
Gardner M (1978) Mathemantical games—white and brown music, fractal curves and one-
over-f ﬂuctuations. Sci Am 238:16–32.
Gawne TJ, Kjaer TW, Hertz JA, Richmond BJ (1996) Adjacent visual cortical complex
cells share about 20% of their stimulus-related information. Cereb Cortex 6:
482–489.
Gawne TJ, Richmond BJ (1993) How independent are the messages carried by adjacent in-
ferior temporal cortical neurons? J Neurosci 13:2758–2771.
Gebber G L, Zhong S, Lewis C, Barman SM (1999) Human brain alpha rhythm: Non-
linear oscillations or ﬁltered noise. Brain Res 818:56–60.
Gelfand IM, Gurﬁnkel VS, Fomin SV, Tsetlin ML (eds) (1971) Models of the structural-
functional organization of certain biological systems. MIT Press, Cambridge, MA.
Gerfen CR (1992) The neostriatal mosaic: Multiple levels of compartmental organization.
Trends Neurosci 15(4):133–139.
Gerstner W, Kistler WM (2002) Spiking neuron models. Cambridge University Press,
Cambridge.
Gevins A, Smith ME, McEvoy L, Yu D (1997) High-resolution EEG mapping of cortical
activation related to working memory: Effects of task difﬁculty, type of processing, and
practice. Cereb Cortex 7:374–485.
Ghose GM, Maunsell J (1999) Specialized representations in visual cortex: A role for
binding? Neuron 24:79–85.

References
391
Gibbon J, Church RM, Meck WH (1984) Scalar timing in memory. Ann NY Acad Sci
423:52–77.
Gibbs FA, Gibbs EL (1950) Atlas of Electroencephalography. Normal Controls. Vol 1.
Addison-Wesley, Cambridge.
Gibson JR, Beierlein M, Connors BW (1999) Two networks of electrically coupled in-
hibitory neurons in neocortex. Nature 402:75–79.
Gilden DL (2001) Cognitive emissions of 1/f noise. Psychol Rev 108:33–56.
Gilden DL, Thornton T, Mallon MW (1995) 1/f noise in human cognition. Science
267:1837–1839.
Gillies MJ, Traub RD, LeBeau FE, Davies CH, Gloveli T, Buhl EH, Whittington MA
(2002) A model of atropine-resistant theta oscillations in rat hippocampal area CA1. J
Physiol 543:779–793.
Glasauer FE (2001) Restless legs syndrome. Spinal Cord 39:125–133.
Glass L (2001) Synchronization and rhythmic processes in physiology. Nature
410:277–284.
Glass L, Mackey MC (1988) From clocks to chaos: The rhythms of life. Princeton Univer-
sity Press, Princeton, NJ.
Gleick J (1987) Chaos: Making a new science. Viking Penguin, New York.
Gloveli T, Dugladze T, Rotstein HG, Traub RD, Monyer H, Heinemann U, Whittington
MA, Kopell NJ (2005) Orthogonal arrangement of rhythm-generating microcircuits in
the hippocampus. Proc Natl Acad Sci USA 102:13295–13300.
Gluckman BJ, Netoff TI, Neel EJ, Ditto WL, Spano ML, Schiff SJ (1996) Stochastic reso-
nance in a neuronal network from mammalian brain. Phys Rev Lett 77:4098–4101.
Gold C, Henze DA, Koch C, Buzsáki G (2006) The origin of the extracellular action po-
tential waveform: A modeling study. J Neurophysiol (in press).
Goldstein EB (2002) Sensation and perception. Wadsworth, Paciﬁc Grove, CA.
Goldstein MH, King AP, West MJ (2003) Social interaction shapes babbling: Testing par-
allels between birdsong and speech. Proc Natl Acad Sci USA 100:8030–8035.
Goldstone RL (1998) Perceptual learning. Annu Rev Psychol 49:585–612.
Golomb D, Hansel D (2000) The number of synaptic inputs and the synchrony of large,
sparse neuronal networks. Neural Comput 12:1095–1139.
Golombek DA, Yannielli PC (1996) Chronoliterature: Biological rhythms in Argentine ﬁc-
tion. Chronobiol Int 13:487–488.
Gong P, Nikolaev AR, van Leeuwen C (2003) Scale-invariant ﬂuctuations of the dynami-
cal synchronization in human brain electrical activity. Neurosci Lett 336:33–36.
Goodale MA, Milner AD (1992) Separate visual pathways for perception and action.
Trends Neurosci 15:20–25.
Goodale MA, Pelisson D, Prablanc C (1986) Large adjustments in visually guided reach-
ing do not depend on vision of the hand or perception of target displacement. Nature
320:748–750.
Gorski RA (1974) The neuroendocrine regulation of sexual behavior. Adv Psychobiol
2:1–58.
Gothard KM, Skaggs WE, McNaughton BL (1996) Dynamics of mismatch correction in
the hippocampal ensemble code for space: Interaction between path integration and en-
vironmental cues. J Neurosci 16:8027–8040.

392
References
Gottesman C (2001) The golden age of rapid eye movement sleep discoveries. 1.
Lucretius—1964. Prog Neurobiol 65:211–287.
Gougoux F, Lepore F, Lassonde M, Voss P, Zatorre RJ, Belin P (2004) Neuropsychology:
Pitch discrimination in the early blind. Nature 430:309–311.
Gould SJ (1980) The panda’s thumb. More reﬂections in natural history. W.W. Norton,
New York.
Granovetter M (1973) The strength of weak ties. Am J Sociol 78:1360–1380.
Granovetter M (1995) Getting a job: A study of contacts and careers. 2nd ed. University of
Chicago Press, Chicago.
Grastyán E, John ER, Bartlett F (1978) Evoked-response correlate of symbol and signiﬁ-
cance. Science 201:168–171.
Grastyán E, Karmos G (1961) A study of a possible “dreaming” mechanism in the cat.
Acta Physiol Acad Sci Hung 20:41–50.
Grastyán E, Lissák, Madarász I, Donhoffer H (1959) Hippocampal electrical activity dur-
ing the development of conditioned reﬂexes. Electroencephalogr Clin Neurophysiol
11(suppl):409–430.
Gray CM (1994) Synchronous oscillations in neuronal systems: Mechanisms and func-
tions. J Comput Neurosci 1:11–38.
Gray CM (1999) The temporal correlation hypothesis of visual feature integration: Still
alive and well. Neuron 24:31–47.
Gray CM, Konig P, Engel AK, Singer W (1989) Oscillatory responses in cat visual cortex
exhibit inter-columnar synchronization which reﬂects global stimulus properties. Nature
338:334–337.
Gray CM, Maldonado PE, Wilson M, McNaughton B (1995) Tetrodes markedly improve
the reliability and yield of multiple single-unit isolation from multi-unit recordings in
cat striate cortex. J Neurosci Methods 63:43–54.
Gray CM, McCormick DA (1996) Chattering cells: Superﬁcial pyramidal neurons con-
tributing to the generation of synchronous oscillations in the visual cortex. Science
274:109–113.
Gray CM, Singer W (1989) Stimulus-speciﬁc neuronal oscillations in orientation columns
of cat visual cortex. Proc Natl Acad Sci USA 86:1698–1702.
Graybiel AM, Aosaki T, Flaherty AW, Kimura M (1994) The basal ganglia and adaptive
motor control. Science 265:1826–1831.
Greene R, Siegel J (2004) Sleep: A functional enigma. Neuromolecular Med 5:59–68.
Greicius MD, Krasnow B, Reiss AL, Menon V (2003) Functional connectivity in the rest-
ing brain: A network analysis of the default mode hypothesis. Proc Natl Acad Sci USA
100:253–258.
Grenier F, Timofeev I, Steriade M (2001) Focal synchronization of ripples (80–200 Hz) in
neocortex and their neuronal correlates. J Neurophysiol 86:1884–1898.
Grillner S (1985) Neurobiological bases of rhythmic motor acts in vertebrates. Science
228:143–149.
Grinvald A, Hildesheim R (2004) VSDI: A new era in functional imaging of cortical dy-
namics. Nat Rev Neurosci 5:874–885.
Gross CG (1992) Representation of visual stimuli in inferior temporal cortex. Philos Trans
R Soc Lond B Biol Sci 335:3–10.

References
393
Gross CG (2002) Genealogy of the “grandmother cell.” Neuroscientist 8:512–518.
Gross CG, Bender DB, Rocha-Miranda CE (1969) Visual receptive ﬁelds of neurons in in-
ferotemporal cortex of the monkey. Science 166:1303–1306.
Grossberg S (1980) How does the brain build a cognitive code. Psychol Rev 87:1–51.
Guillery RW, Sherman SM (2002) The thalamus as a monitor of motor outputs. Philos
Trans R Soc Lond B Biol Sci 357:1809–1821.
Gulyás A, Freund TF, Buzsáki, G, Hirase (2006) Populations of hippocampal inhibitory
neurons express different levels of cytochrome C. Eur J Neurosci (in press).
Gulyás AI, Hájos N, Freund TF (1996) Interneurons containing calretinin are specialized
to control other interneurons in the rat hippocampus. J Neurosci 16:3397–3411.
Gulyás AI, Miles R, Hájos N, Freund TF (1993a) Precision and variability in postsynaptic
target selection of inhibitory cells in the hippocampal CA3 region. Eur J Neurosci
5:1729–1751.
Gulyás AI, Miles R, Sík A, Tóth K, Tamamaki N, Freund TF (1993b) Hippocampal py-
ramidal cells excite inhibitory neurons through a single release site. Nature 366:
683–687.
Gupta A, Wang Y, Markram H (2000) Organizing principles for a diversity of GABAergic
interneurons and synapses in the neocortex. Science 287:273–278.
Gusnard DA, Raichle ME, Raichle ME (2001) Searching for a baseline: Functional imag-
ing and the resting human brain. Nat Rev Neurosci 2:685–694.
Haber SN (2003) The primate basal ganglia: Parallel and integrative networks. J Chem
Neuroanat 26:317–330.
Habets RL, Borst GJ (2005) Post-tetanic potentiation in the rat calyx of Held synapse.
J Physiol (Lond) 564:173–187.
Hafting T, Fyhn M, Molden S, Moser MB, Moser EI (2005) Microstructure of a spatial
map in the entorhinal cortex. Nature 309:619–623.
Hahnloser RH, Kozhevnikov AA, Fee MS (2002) An ultra-sparse code underlies the gen-
eration of neural sequences in a songbird. Nature 419:65–70.
Haig AR, Gordon E (1998) EEG alpha phase at stimulus onset signiﬁcantly affects the am-
plitude of the P3 ERP component. Int J Neurosci 93:101–115.
Haken H (1984) The science of structure: Synergetics. Van Nostrand Reinhold, New York.
Halasy K, Somogyi P (1993) Subdivisions in the multiple GABAergic innervation of gran-
ule cells in the dentate gyrus of the rat hippocampus. Eur J Neurosci 5:411–429.
Halász P, Pál I, Rajna P (1985) K-complex formation of the EEG in sleep: A survey and
new examinations. Acta Physiol Acad Sci Hung 65:3–35.
Halász P, Terzano, Parrino L, Bodizs R (2004) The nature of arousal in sleep. J Sleep Res
13:1–13.
Halgren E, Smith ME (1987) Cognitive evoked potentials as modulatory processes in hu-
man memory formation and retrieval. Hum Neurobiol 6:129–139.
Hall ET (1983) The dance of life. Doubleday, New York.
Hall WG, Oppenheim RW (1987) Developmental psychology: Prenatal, perinatal, and
postnatal aspects of behavioral development. Annu Rev Psychol 38:91–128.
Hämäläinen M, Hari R, Ilmoniemi RJ, Knuutila J, Lounasmaa OV (1993) Magnetoenceph-
alography—theory, instrumentation, and applications to noninvasive studies of the
working human brain. Rev Mod Phys 65:413–497.

394
References
Hamburger V, Wenger E, Opperheim RW (1966) Motility in the chick embryo in the ab-
sence of sensory input. J Exp Zool 162:133–160.
Hampson RE, Simeral JD, Deadwyler SA (1999) Distribution of spatial and nonspatial in-
formation in dorsal hippocampus. Nature 402:610–614.
Hardt JV, Kamiya J (1978) Anxiety change through electroencephalographic alpha feed-
back seen only in high anxiety subjects. Science 201:79–81.
Harris KD (2005) Neural signatures of cell assembly organization. Nat Rev Neurosci
6:399–407.
Harris KD, Barthó P, Zugaro MB, Monconduit L, Marguet S, Buzsaki G (2003b) Neocor-
tical population patterns during EEG activation: Waking, REM, and anesthetised states.
Society for Neuroscience Meeting, Washington DC (abstract #719.5).
Harris KD, Csicsvari J, Hirase H, Dragoi G, Buzsáki G (2003a) Organization of cell as-
semblies in the hippocampus. Nature 424:552–556.
Harris KD, Henze DA, Hirase H, Leinekugel X, Dragoi G, Czurkó A, Buzsáki G (2002)
Spike train dynamics predicts theta-related phase precession in hippocampal pyramidal
cells. Nature 417:738–741.
Harris KD, Hirase H, Leinekugel X, Henze DA, Buzsáki G (2001) Temporal interaction
between single spikes and complex spike bursts in hippocampal pyramidal cells. Neuron
32:141–149.
Häusser M, Clark BA (1997) Tonic synaptic inhibition modulates neuronal output pattern
and spatiotemporal synaptic integration. Neuron 19:665–678.
Häusser M, Raman IM, Otis T, Smith SL, Nelson A, du Lac S, Loewenstein Y, Mahon S,
Pennartz C, Cohen I, Yarom Y (2004) The beat goes on: Spontaneous ﬁring in mam-
malian neuronal microcircuits. J Neurosci 24:9215–9219.
Häusser M, Spruston N, Stuart GJ (2000) Diversity and dynamics of dendritic signaling.
Science 290:739–744.
Hawking SW (1992) Brief history of time. Bantam, New York.
Hayes B (2000a) Graph-theory in practice, part I. Am Sci (Jan.–Feb.) 88:19–13.
Hayes B (2000b) Graph-theory in practice, part II. Am Sci (Jan.–Feb.) 88:104–109.
Hebb D (1949) Organization of behavior. Wiley, New York.
Heimer L, Zahm DS, Alheid GF (1995) Basal ganglia. In: The rat nervous system (Paxinos
G, ed), 2nd ed. Academic Press, New York, 579–628.
Heit G, Smith ME, Halgren E (1998) Neural encoding of individual words and faces by the
human hippocampus and amygdala. Nature 333:773–775.
Held R, Hein A (1963) Movement-produced stimulation in the development of visually-
guided behavior. J Comp Physiol Psychol 56:872–576.
Helmchen F, Fee MS, Tank DW, Denk W (2001) A miniature head-mounted two-photon
microscope. High-resolution brain imaging in freely moving animals. Neuron 31:903–
912.
Hening W (2004) The clinical neurophysiology of the restless legs syndrome and periodic
limb movements. Part I: Diagnosis, assessment, and characterization. Clin Neurophys-
iol 115:1965–1974.
Henze DA, Borhegyi Z, Csicsvari J, Mamiya A, Harris KD, Buzsáki G (2000a) Intracellu-
lar features predicted by extracellular recordings in the hippocampus in vivo. J Neuro-
physiol 84:390–400.

References
395
Henze DA, Buzsáki G (2001) Action potential threshold of hippocampal pyramidal cells in
vivo is increased by recent spiking activity. Neuroscience 105:121–130.
Henze DA, Urban NN, Barrionuevo G (2000b) The multifarious hippocampal mossy ﬁber
pathway: A review. Neurosci 98:407–427.
Henze DA, Wittner L, Buzsáki G (2002) Single granule cells reliably discharge targets in
the hippocampal CA3 network in vivo. Nat Neurosci 5:790–795.
Hestrin S, Galarreta M (2005) Electrical synapses deﬁne networks of neocortical
GABAergic neurons. Trends Neurosci 28:304–309.
Hildebrandt G, Moog R, Raschke F (eds) (1957) Chronobiology and chronomedicine. Ba-
sic research and applications. Peter Lang, Frankfurt.
Hilgetag CC, Burns GA, O’Neill MA, Scannell JW, Young MP (2000) Anatomical connec-
tivity deﬁnes the organization of clusters of cortical areas in the macaque monkey and
the cat. Philos Trans R Soc Lond B Biol Sci 355:91–110.
Hille B (2001) Ion channels of excitable membranes. 3rd ed. Sinauer Associates, Sunder-
land, MA.
Hillyard SA, Kutas M (1983) Electrophysiology of cognitive processing. Annu Rev Psy-
chol 34:33–61.
Hirase H, Czurkó A, Csicsvari J, Buzsáki G (1999) Firing rate and theta-phase coding
by hippocampal pyramidal neurons during “space clamping.” Eur J Neurosci 11:
4373–4380.
Hirase H, Leinekugel X, Czurkó A, Csicsvari J, Buzsáki G (2001) Firing rates of hip-
pocampal neurons are preserved during subsequent sleep episodes and modiﬁed by
novel awake experience. Proc Natl Acad Sci USA 98:9386–9390.
Hirsh R (1974) The hippocampus and contextual retrieval of information from memory: A
theory. Behav Biol 12:421–444.
Ho N, Destexhe A (2000). Synaptic background activity enhances the responsiveness of
neocortical pyramidal neurons. J Neurophysiol 84:1488–1496.
Hobson JA (1995) Sleep. W.H. Freeman and Company, New York.
Hobson JA, Pace-Schott EF (2002) The cognitive neuroscience of sleep: Neuronal sys-
tems, consciousness and learning. Nat Rev Neurosci 3:679–693. .
Hoffman DA, Magee JC, Colbert CM, Johnston D (1997) K+ channel regulation of sig-
nal propagation in dendrites of hippocampal pyramidal neurons. Nature 387:
869–875.
Hoﬂe N, Paus T, Reutens D, Fiset P, Gotman J, Evans A, Jones B (1997) Regional cerebral
blood ﬂow changes as a function of delta and spindle activity during slow wave sleep in
humans. J Neurosci 17:4800–4808.
Hofstadter DR, Dennett DC (1981) The mind’s I. Fantasies and reﬂections on self and
soul. Bantam Books, New York.
Holscher C, Anwyl R, Rowan MJ (1997) Stimulation on the positive phase of hippocampal
theta rhythm induces long-term potentiation that can be depotentiated by stimulation on
the negative phase in area CA1 in vivo. J Neurosci 17:6470–6477.
Hopﬁeld JJ (1982) Neural networks and physical systems with emergent collective compu-
tational abilities. Proc Natl Acad Sci USA 79:2554–2558.
Hopﬁeld JJ, Brody CD (2001) What is a moment? Transient synchrony as a collective
mechanism for spatiotemporal integration. Proc Natl Acad Sci USA 98:1282–1287.

396
References
Hopﬁeld JJ, Tank DW (1986) Computing with neural circuits: A model. Science 233:
625–633.
Hoppensteadt FC, Izhikevich EM (1998) Thalamo-cortical interactions modeled by
weakly connected oscillators: Could the brain use FM radio principles? Biosystems
48:85–94.
Hormuzdi SG, Pais I, LeBeau FE, Towers SK, Rozov A, Buhl EH, Whittington MA,
Monyer H (2001) Impaired electrical signaling disrupts gamma frequency oscillations in
connexin 36-deﬁcient mice. Neuron 31:487–495.
Houser MD, McDermott J (2003) The evolution of the music faculty: A comparative per-
spective. Nat Neurosci 6:663–668.
Howard MW, Fotedar MS, Datey AV, Hasselmo ME (2005) The temporal context model in
spatial navigation and relational learning: Toward a common explanation of medial tem-
poral lobe function across domains. Psychol Rev 112:75–116.
Howard MW, Kahana MJ (2002) A distributed representation of temporal context. J Math
Psychol 46:269–299.
Hu H, Vervaeke K, Storm JF (2002) Two forms of electrical resonance at theta frequencies,
generated by M-current, h-current and persistent Na+ current in rat hippocampal pyram-
idal cells. J Physiol (Lond) 545:783–805.
Hubel DH (1957) Tungsten microelectrodes for recording single units. Science
125:549–550.
Hubel DH, Wiesel TN (1963) Shape and arrangement of columns in cat’s striate cortex. J
Physiol (Lond) 165:559–568.
Hubel DH, Wiesel TN (1974) Uniformity of monkey striate cortex: A parallel relationship
between ﬁeld size, scatter, and magniﬁcation factor. J Comp Neurol 158:295–305.
Huber R, Ghilardi MF, Massimini M, Tononi, G (2004) Local sleep and learning. Nature
430:78–81.
Huerta PT, Lisman JE (1993) Heightened synaptic plasticity of hippocampal CA1 neurons
during a cholinergically induced rhythmic state. Nature 364:723–725.
Huerta PT, Lisman JE (1995) Bidirectional synaptic plasticity induced by a single burst
during cholinergic theta oscillation in CA1 in vitro. Neuron 15:1053–1063.
Hughes SW, Cope DW, Blethyn KL, Crunelli V (2002) Cellular mechanisms of the slow
(<1Hz) oscillation in thalamocortical neurons in vitro. Neuron 33:947–958.
Huguenard JR (1996) Low-threshold calcium currents in central nervous system neurons.
Annu Rev Physiol 58:329–348.
Huguenard JR, Prince DA (1992) A novel T-type current underlies prolonged Ca(2+)-
dependent burst ﬁring in GABAergic neurons of rat thalamic reticular nucleus. J Neu-
rosci 12:3804–3817.
Huizinga J (1955) Homo Ludens. Beacon Press, Boston.
Hull C (1952) A behavior system. Yale University Press, New Haven, CT.
Hunter JD, Milton JG, Thomas PJ, Cowan JD (1998) Resonance effect for neural spike
time reliability. J Neurophysiol 80:1427–1438.
Hurtado JM, Rubchinsky LL, Sigvardt KA (2004) Statistical method for detection of
phase-locking episodes in neural oscillations. J Neurophysiol 91:1883–1898.
Hutcheon B, Yarom Y (2000) Resonance, oscillation and the intrinsic frequency prefer-
ences of neurons. Trends Neurosci 23:216–222.

References
397
Huxter J, Burgess N, O’Keefe J (2003) Independent rate and temporal coding in hip-
pocampal pyramidal cells. Nature 425:828–832.
Hwa R, Ferree TC (2002) Scaling properties of ﬂuctuations in the human electroen-
cephalogram. Phys Rev E 66:021901.
Ikeda H, Leyba L, Bartolo A, Wang Y, Okada YC (2002) Synchronized spikes of thalamo-
cortical axonal terminals and cortical neurons are detectable outside the pig brain with
MEG. J Neurophysiol 87:626–630.
Ikegaya Y, Aaron G, Cossart R, Aronov D, Lampl I, Ferster D, Yuste R (2004) Synﬁre
chains and cortical songs: Temporal modules of cortical activity. Science 304:559–564.
International Federation of Societies for Electroencephalography and Clinical Neurophys-
iology (1974) Electroencephalogr Clin Neurophysiol 37:521.
Isaacson RL (1994) The limbic system. Plenum, New York.
Ishizuka N, Weber J, Amaral DG (1990) Organization of intrahippocampal projections
originating from CA3 pyramidal cells in the rat. J Comp Neurol 295:580–623.
Isomura Y, Sirota A, Ozen S, Buzsaki A (2005) Entorhino-hippocampal interactions during
slow and theta network oscillations. Society for Neuroscience Abstracts 275:11.
Ito M (1989) Long-term depression. Annu Rev Neurosci 12:85–102.
Izhikevich EM, Desai NS, Walcott EC, Hoppensteadt FC (2003) Bursts as a unit of neural
information: Selective communication via resonance. Trends Neurosci 26:161–167.
Izhikevich EM, Gally JA, Edelman GM (2004) Spike-timing dynamics of neuronal groups.
Cereb Cortex 14:933–944.
Jacob F (1994) The possible and the actual. University of Washington Press, Seattle.
Jagadeesh B, Gray CM, Ferster D (1992) Visually-evoked oscillations of membrane poten-
tial in neurons of cat striate cortex studied with in vivo show cell patch recording. Sci-
ence 257:552–554.
Jahnsen H, Llinás R (1984a) Electrophysiological properties of guinea-pig thalamic neu-
rones: An in vitro study. J Physiol (Lond) 349:205–226.
Jahnsen H, Llinás R (1984b) Ionic basis for the electro-responsiveness and oscillatory
properties of guinea-pig thalamic neurones in vitro. J Physiol (Lond) 349:227–247.
James W (1890/1991) The principles of psychology. Harvard University Press, Cam-
bridge, MA.
Jandó G, Carpi D, Kandel A, Urioste R, Horváth Z, Pierre E, Vadi D, Vadász C, Buzsáki G
(1995) Spike-and-wave epilepsy in rats: Sex differences and inheritance of physiologi-
cal traits. Neuroscience 64:301–317.
Jankel WR, Niedermeyer (1985) E. Sleep spindles. J Clin Neurophysiol 2:1–35.
Jasper HH, Drooglever-Fortuyn J (1947) Experimental studies on the functional anatomy
of petit mal epilepsy. Res Publ Assoc Res Nerv Ment Dis 26:272–298.
Jensen HJ (1998) Self-organized criticality: Emergent complex behavior in physical and
biological systems. Cambridge University Press, Cambridge.
Jensen O, Lisman JE (1998) An oscillatory short-term memory buffer model can account
for data on the Sternberg task. J Neurosci 18:10688–10699.
Jensen O, Lisman JE (2005) Hippocampal sequence-encoding driven by a cortical multi-
item working memory buffer. Trends Neurosci 28:67–72.
Jerison HJ (1985) Animal intelligence as encephalization. Philos Trans R Soc Lond B
308:21–35.

398
References
Jirsa V, Haken H (1996) Field theory of electromagnetic brain activity. Phys Rev Lett
77:960–963.
John E, Prichep LS, Fridman J, Easton P (1998) Neurometrics: Computer-assisted differ-
ential diagnosis of brain dysfunctions. Science 239:162–169.
John ER (1968) Mechanisms of memory. Vols 1 and 2; 2nd printing. Academic Press, New
York.
John ER (1977) Functional neuroscience. Vol 2. Neurometrics: Quantitative electrophysio-
logical analyses (John ER, Thatcher RW, eds). Lawrence Erlbaum, Hillsdale, NJ.
John ER (2003) A theory of consciousness. Current directions in psychological science 12:
244–249.
John ER, Morgades PP (1969) Patterns and anatomical distribution of evoked potentials and
multiple unit activity by conditioned stimuli in trained cats. Commun Behav Biol 3:181–207.
Johnson S (2001) Emergence: The connected lives of ants, brains, cities, and software.
Touchstone, New York.
Johnston D, Magee JC, Colbert CM, Cristie BR (1996) Active properties of neuronal den-
drites. Annu Rev Neurosci 19:165–186.
Johnston D, Wu SMS (1994) Foundations of cellular neurophysiology. MIT Press, Cam-
bridge, MA.
Jonas P, Bischofberger J, Fricker D, Miles R (2004) Interneuron diversity series: Fast in,
fast out—temporal and spatial signal processing in hippocampal interneurons. Trends
Neurosci 27:30–40.
Jones BE (2005) From waking to sleeping: Neuronal and chemical substrates. Trends
Pharmacol Sci 26:578–586.
Jones EG (1985) The thalamus. Kluwer Academic/Plenum, New York.
Jones EG (1998) A new view of speciﬁc and nonspeciﬁc thalamocortical connections. Adv
Neurol 77:49–71.
Jones EG (2001) The thalamic matrix and thalamocortical synchrony. Trends Neurosci
24:595–601.
Jones MS, Barth DS (1999) Spatiotemporal organization of fast (>200 Hz) electrical oscil-
lations in rat vibrissa/barrel cortex. J Neurophysiol 82:1599–1609.
Jones W H S (1923) Hippocrates, Volume II. Harvard University Press (Loeb Classical Li-
brary), London, Cambridge.
Jouvet M (1999) The paradox of sleep: The story of dreaming (Garey L, trans). Bradford
Books/MIT Press, Cambridge, MA.
Jouvet M (2004) How sleep was dissociated into two states: Telencephalic and rhomben-
cephalic sleep? Arch Ital Biol 142:317–326.
Juarrero A (2000) Dynamics in action: Intentional behavior as a complex system. Emer-
gence 2:24–57.
Julesz B (1995) Dialogues on perception. MIT Press, Cambridge, MA.
Jung CG, Pauli W (1954) The interpretation of nature and the psyche. Bollingen Series 51.
Pantheon, New York.
Jung MW, Wiener SI, McNaughton BL (1994) Comparison of spatial ﬁring characteristics
of units in dorsal and ventral hippocampus of the rat. J Neurosci 14:7347–7356.
Kaas JH (2000) Why is brain size so important: Design problems and solutions as neocor-
tex gets bigger or smaller? Brain Mind 1:7–23.

References
399
Kahana MJ (1996) Associative retrieval processes in free recall. Mem Cogn 24:103–109.
Kahana MJ (2006) The cognitive correlates of human brain oscillations. J Neurosci
26:1669–1672.
Kahana MJ, Seelig D, Madsen JR (2001) Theta returns. Curr Opin Neurobiol 11:739–744.
Kaila K (1994) Ionic basis of GABAA receptor channel function in the nervous system.
Prog Neurobiol 42:489–537.
Kaila K, Ransom B (eds) (1998) pH, brain function. Wiley-Liss, New York.
Kaila K, Voipio J, Pasternack M, Paalasmaa P, Deisz R (1993) The role of bicarbonate in
GABAA receptor-mediated IPSPs of rat neocortical neurons. J Physiol (Lond)
464:273–289.
Kalisman N, Silberberg G, Markram H (2005) The neocortical microcircuit as a tabula
rasa. Proc Natl Acad Sci USA 102:880–885.
Kamondi A, Acsády L, Wang XJ, Buzsáki G (1998) Theta oscillations in somata and den-
drites of hippocampal pyramidal cells in vivo: Activity-dependent phase-precession of
action potentials. Hippocampus 8:244–261.
Kampis G (1991) Self-modifying systems: A new framework for dynamics, information,
and complexity. Pergamon, Oxford.
Kandel A, Buzsáki G (1993) Cerebellar neuronal activity correlates with spike and wave
EEG patterns in the rat. Epilepsy Res 16:1–9.
Kandel A, Buzsáki G (1997) Cellular-synaptic generation of sleep spindles, spike-and-
wave discharges, and evoked thalamocortical responses in the neocortex of the rat. J
Neurosci 17:6783–6797.
Kandel ER, Squire LR (2000) Neuroscience: Breaking down scientiﬁc barriers to the study
of brain and mind. Science 290:1113–1120.
Kanerva P (1988) Sparse distributed memory. Bradford/MIT Press, Cambridge, MA.
Kaplan D, Glass L (1995) Understanding nonlinear dynamics. Springer-Verlag, New York.
Kara P, Reinagel P, Reid RC (2000) Low response variability in simultaneously recorded
retinal, thalamic, and cortical neurons. Neuron 27:635–646.
Karni A, Tanne D, Rubenstein BS, Askenasy JJ, Sagi D (1994) Dependence on REM sleep
of overnight improvement of a perceptual skill. Science 265:679–682.
Kasamatsu A, Hirai T (1966) An electroencephalographic study on the Zen meditation
(Zazen). Fol Psychiatr Neurol Jpn 20:315–336.
Katsumaru H, Kosaka T, Heizmann CW, Hama K (1988) Gap junctions on GABAergic
neurons containing the calcium-binding protein parvalbumin in the rat hippocampus
(CA1 region). Exp Brain Res 72:363–370.
Kattler H, Dijk DJ, Borbely AA (1994) Effect of unilateral somatosensory stimulation
prior to sleep on the sleep EEG in humans. J Sleep Res 3:159–164.
Katz L, Cracco RQ (1971) A review of the cerebral rhythms in the waking EEG. Am J
EEG Technol 11:77–100.
Katz LC, Shatz CJ (1996) Synaptic activity and the construction of cortical circuits. Sci-
ence 274:1133–1138.
Kauffman S (1995) At home in the universe: The search for laws of self-organization and
complexity. Oxford University Press, Oxford.
Kavanau JL (1997) Memory, sleep and the evolution of mechanisms of synaptic efﬁcacy
maintenance. Neuroscience 79:7–44.

400
References
Keegan MB, Noseworth JH (2002) Multiple sclerosis. Annu Rev Med 53:285–302.
Kelso JA, Fuchs A (1995) Self-organizing dynamics of the human brain: Critical instabili-
ties and Sil’nikov chaos. Chaos 5:64–69.
Kelso JAS (1995) Dynamic patterns: The self-organization of brain and behavior. MIT
Press, Cambridge, MA.
Kenet T, Bibitchkov D, Tsodyks M, Grinvald A, Arieli A (2003) Spontaneously emerging
cortical representations of visual attributes. Nature 425:954–956.
Kepecs A, van Rossum MC, Song S, Tegner J (2002) Spike-timing-dependent plasticity:
Common themes and divergent vistas. Biol Cybern 87:446–458.
Khalilov I, Esclapez M, Medina I, Aggoun D, Lamsa K, Leinekugel X, Khazipov R, Ben-
Ari Y (1997) A novel in vitro preparation: The intact hippocampal formation. Neuron
19:743–749.
Khazipov R, Sirota A, Leinekugel X, Holmes GL, Ben-Ari Y, Buzsáki G (2004) Early mo-
tor activity drives spindle bursts in the developing somatosensory cortex. Nature
432:758–7561.
Killeen PR, Weiss NA (1987) Optimal timing and the Weber function. Psychol Rev
94:455–468.
Kim U, Sanchez-Vives MV, McCormick DA (1997) Functional dynamics of GABAergic
inhibition in the thalamus. Science 278:130–134.
King C, Henze DA, Leinekugel X, Buzsáki G (1999) Hebbian modiﬁcation of a hip-
pocampal population pattern in the rat. J Physiol (Lond) 521:159–167.
Kinsbourne M (1987) Mechanisms of unilateral neglect. In: Neurophysiological and neu-
ropsychological aspects of spatial neglect (Jeannerod M, ed). Elsevier Science Publish-
ers, Amsterdam, 69–86.
Klausberger T, Magill PJ, Marton LF, Roberts JD, Cobden PM, Buzsáki G, Somogyi P
(2003) Brain-state- and cell-type-speciﬁc ﬁring of hippocampal interneurons in vivo.
Nature 421:844–888.
Klausberger T, Marton LF, Baude A, Roberts JD, Magill PJ, Somogyi P (2004) Spike tim-
ing of dendrite-targeting bistratiﬁed cells during hippocampal network oscillations in
vivo. Nat Neurosci 7:41–47.
Klausberger T, Marton LF, O’Neill J, Huck JH, Dalezios Y, Fuentealba P, Suen WY, Papp
E, Kaneko T, Watanabe M, Csicsvari J, Somogyi P (2005) Complementary roles of
cholecystokinin- and parvalbumin-expressing GABAergic neurons in hippocampal net-
work oscillations. J Neurosci 25:9782–9793.
Klimesch W (1999) EEG alpha and theta oscillations reﬂect cognitive and memory perfor-
mance: A review and analysis. Brain Res Rev 29:169–195.
Klimesch W (2000) Theta frequency, synchronization and episodic memory performance.
In: Time and the brain (Miller R, ed). Harwood Academic Publishers, Singapore,
225–240.
Klingberg F, Pickenhain L (1967) The effect of the light stimulus parameter on the occur-
rence of photic secondary discharges (in German). Acta Biol Med Ger 18:57–69.
Klinkenkaer-Hansen K, Nikulin VV, Palva S, Ilmoniemi RJ, Palva JM (2004) Prestimulus os-
cillations enhance psychophysical performance in humans. J Neurosci 24:10186–10190.
Klyachko VA, Stevens CF (2003) Connectivity optimization and the positioning of cortical
areas. Proc Natl Acad Sci USA 100:7937–7941.

References
401
Knierim JJ, Kudrimoti HS, McNaughton BL (1995) Place cells, head direction cells, and
the learning of landmark stability. J Neurosci 15:1648–1659.
Knight BW (1972) The relationship between the ﬁring rate of a single neuron and the level
of activity in a population of neurons. Experimental evidence for resonant enhancement
in the population response. J Gen Physiol 59:767–778.
Koch C (1999) Biophysics of computation: Information processing in single neurons. Ox-
ford University Press, New York.
Koch C (2004) The quest for consciousness: A neurobiological approach. Roberts and
Company, Englewood, CO.
Koch C, Laurent G (1999) Complexity and the nervous system. Science 284:96–98.
Komisaruk BR. 1970. Synchrony between limbic system theta activity and rhythmical be-
havior in rats. J Comp Physiol Psychol 70:482–492.
König P, Engel AK, Singer W (1996) Integrator or coincidence detector? The role of the
cortical neuron revisited. Trends Neurosci 19:130–137.
Konopka RJ, Benzer S (1971) Clock mutants of Drosophila melanogaster. Proc Natl Acad
Sci USA 68:2112–2116.
Koestler A (1967) The ghost in the machine. Arkana, London.
Kohonen T (1984) Self-organization and associative memory. Springer-Verlag, Berlin.
König P, Engel AK, Singer W (1995) The relation between oscillatory activity and long-
range synchronization in cat visual cortex. Proc Natl Acad Sci USA 92:290–294.
König P, Engel AK, Singer W (1996) Integrator or coincidence detector? The role of the
cortical neuron revisited. Trends Neurosci 19:130–137.
Konorski J (1967) Integrative activity of the brain. University of Chicago Press, Chicago.
Koós T, Tepper JM (1999) Inhibitory control of neostriatal projection neurons by
GABAergic interneurons. Nat Neurosci 2:467–472.
Kopell N (2000) We got rhythm: Dynamical systems of the nervous system. N Am Math
Soc 47:6–16.
Kopell N, Ermentrout GB, Whittington MA, Traub RD (2000) Gamma rhythms and beta
rhythms have different synchronization properties. Proc Natl Acad Sci USA 97:
1867–1872.
Kossut M (1992) Plasticity of the barrel cortex neurons. Prog Neurobiol 39:389–422.
Kroto HW, Heath JR, O’Brien SC, Curl RF, Smalley RE (1985) C60: Buckminster-
fullerene. Nature 318:162–163.
Krueger JM, Obal F, Kapas L, Fang J (1995) Brain organization and sleep function. Behav
Brain Res 69:177–185.
Krupa DJ, Wiest MC, Shuler MG, Laubach M, Nicolelis MA (2004) Layer-speciﬁc so-
matosensory cortical activation during active tactile discrimination. Science 304:1989–
1892.
Kruse W, Eckhorn R (1996) Inhibition of sustained gamma oscillations (35–80 Hz) by
transient responses in cat visual cortex. Proc Natl Acad Sci USA 93:6112–6117.
Kudrimoti HS, Barnes CA, McNaughton BL (1999) Reactivation of hippocampal cell as-
semblies: Effects of behavioral state, experience, and EEG dynamics. J Neurosci
19:4090–4101.
Kugler JE (1982) Mediation and the electroencephalogram. Electroencephalogr Clin Neu-
rophysiol 35(suppl):391–398.

402
References
Kultas-Ilinsky K, Ilinsky I, Warton S, Smith KR (1983) Fine structure of nigral and palli-
dal afferents in the thalamus: An EM autoradiography study in the cat. J Comp Neurol
216:390–405.
Kume K, Zylka MJ, Sriram S, Shearman LP, Weaver DR, Jin X, Maywood ES, Hastings
MH, Reppert SM (1999) mCRY1 and mCRY2 are essential components of the negative
limb of the circadian clock feedback loop. Cell 98:193–205.
Kuramoto Y (1984) Chemical oscillation, waves, and turbulence. Springer-Verlag,
Tokyo.
Kurzweil R (1999) The age of spiritual machines, when computers exceed human intelli-
gence. MIT Press/Viking, Boston.
Kutas M, Hillyard SA (1980) Reading senseless sentences: Brain potentials reﬂect seman-
tic incongruity. Science 207:203–205.
Lachaux JP, Rodriguez E, Martinerie J, Varela FJ (1999) Measuring phase synchrony in
brain signals. Hum Brain Map 8:194–208.
Lamme VA, Roelfsema PR (2000) The distinct modes of vision offered by feedforward and
recurrent processing. Trends Neurosci 23:571–579.
Landisman CE, Long MA, Beierlein M, Deans MR, Paul DL, Connors BW (2002) Electri-
cal synapses in the thalamic reticular nucleus. J Neurosci 22:1002–1009.
Lange W (1975) Cell number and cell density in the cerebellar cortex of man and other
mammals. Cell Tissue Res 157:115–124.
Lansing RW, Schwartz E, Lindsley DB (1959) Reaction time and EEG activation under
alerted and nonalerted conditions. J Exp Psychol 58:1–7.
Larson J, Lynch G (1986) Induction of synaptic potentiation in hippocampus by patterned
stimulation involves two events. Science 232:985–988.
Laufs H, Kleinschmidt A, Beyerle A, Eger E, Salek-Haddadi A, Preibisch C, Krakow K
(2003) EEG-correlated fMRI of human alpha activity. Neuroimage 19:1463–1476.
Laughlin SB, Sejnowski TJ (2003) Communication in neuronal networks. Science
301:1870–1874.
Laurent G (1999) A system perspective on early olfactory learning. Science 286:723–728.
Laurent G (2002) Olfactory network dynamics and the coding of multidimensional signals.
Nat Rev Neurosci 3:884–895.
Lashley KS (1931) Mass action in cerebral function. Science 73:245–254.
Latawiec D, Martin KA, Meskenaite V (2000) Termination of the geniculocortical projec-
tion in the striate cortex of macaque monkey: A quantitative immunoelectron micro-
scopic study. J Comp Neurol 419:306–319.
Lawrence JJ, McBain CJ (2003) Interneuron diversity series: Containing the detonation—
feedforward inhibition in the CA3 hippocampus. Trends Neurosci 26:631–640.
LeDoux JE (1996) The emotional brain. Simon and Schuster, New York.
Lee AK, Wilson MA (2002) Memory of sequential experience in the hippocampus during
slow wave sleep. Neuron 36:1183–1194.
Lee H, Simpson GV, Logothetis NK, Rainer G (2005) Phase locking of single neuron ac-
tivity to theta oscillations during working memory in monkey extrastriate visual cortex.
Neuron 45:147–156.
Lehtela L, Salmelin R, Hari R (1997) Evidence for reactive magnetic 10-Hz rhythm in the
human auditory cortex. Neurosci Lett 222:111–114.

References
403
Leinekugel X, Khazipov R, Cannon R, Hirase H, Ben-Ari Y, Buzsáki G (2002) Correlated
bursts of activity in the neonatal hippocampus in vivo. Science 296:2049–2052.
Lendvai E (1971) Béla Bartók, an analysis of his music. Kahn and Averill, London.
Leopold DA, Logothetis NK (1996) Activity changes in early visual cortex reﬂect mon-
keys’ percepts during binocular rivalry. Nature 379:549–553.
Leopold DA, Logothetis NK (1999) Multistable phenomena: Changing views in percep-
tion. Trends Cogn Sci 3:254–264.
Leopold DA, Murayama Y, Logothetis NK (2003) Very slow activity ﬂuctuations in mon-
key visuual cortex: Implications for functional brain imaging. Cereb Cortex 13:422–
433.
Leopold DA, Wilke M, Maier A, Logothetis NK (2002) Stable perception of visually am-
biguous patterns. Nat Neurosci 5:605–609.
Léránth C, Deller T, Buzsáki G (1992) Intraseptal connections redeﬁned: Lack of a lateral
septum to medial septum path. Brain Res 583:1–11.
Leresche N, Jassik-Gerschenfeld D, Haby M, Soltesz I, Crunelli V (1990) Pacemaker-like
and other types of spontaneous membrane potential oscillations of thalamocortical cells.
Neurosci Lett 113:72–77.
Leung LS (1992) Fast (beta) rhythms in the hippocampus: A review. Hippocampus
2:93–98.
Leung LS (1998) Generation of theta and gamma rhythms in the hippocampus. Neurosci
Biobehav Rev 22:275–290.
Leung LW, Borst JG (1987) Electrical activity of the cingulate cortex. I. Generating mech-
anisms and relations to behavior. Brain Res 407:68–80.
Leutgeb S, Leutgeb JK, Barnes CA, Moser EI, McNaughton BL, Moser MB (2005) Inde-
pendent codes for spatial and episodic memory in hippocampal neuronal ensembles.
Science 309:619–623.
Le van Quyen M (2003) Disentangling the dynamic core: A research program for a neuro-
dynamics at the large-scale. Biol Res 36:67–88.
Lever C, Wills T, Cacucci F, Burgess N, O’Keefe J (2002) Long-term plasticity in hip-
pocampal place-cell representation of environmental geometry. Nature 416:90–94.
Levin I, Zakay D (1989) Time and human cognition: A life span perspective. North-
Holland, Amsterdam.
Levy WB, Baxter RA (1996) Energy efﬁcient neural codes. Neural Comput 8:531–543.
Levy WB, Steward O (1983) Temporal contiguity requirements for long-term associative
potentiation/depression in the hippocampus. Neuroscience 8:791–797.
Leyton M (1999) Symmetry, causality, mind. MIT Press, Cambridge, MA.
Li XG, Somogyi P, Tepper JM, Buzsáki G (1993) Axonal and dendritic arborization of an
intracellularly labeled chandelier cell in the CA1 region of rat hippocampus. Exp Brain
Res 90:519–525.
Li XG, Somogyi P, Ylinen A, Buzsáki G (1994) The hippocampal CA3 network: An in vivo
intracellular labeling study. J Comp Neurol 339:181–208.
Liang H, Bressler SL, Ding M, Truccolo WA, Nakamura R (2002) Synchronized activity in
prefrontal cortex during anticipation of visuomotor processing. Neuroreport 13:
2011–2015.
Libet B (1973) Electrical stimulation of cortex in human subjects, and conscious sensory

404
References
aspects. In: Handbook of sensory physiology. Vol 2. Somatosensory system (Iggo A,
ed). Springer-Verlag, Berlin, 743–790.
Libet B (2004) Mind time: The temporal factor in consciousness. Harvard University
Press, Cambridge.
Liebovitch LS, Tibor L, Tóth I (1991) A model of ion channel kinetics using deterministic
chaotic rather than stochastic processes. J Theoret. Biol 148:243–267.
Liley DT, Cadusch PJ, Daﬁlis MP (2002) A spatially continuous mean ﬁeld theory of elec-
trocortical activity. Network 13:67–113.
Linkenkaer-Hansen K, Nikouline VV, Palva JM, Ilmoniemi RJ (2001) Long-range temporal
correlations and scaling behavior in human brain oscillations. J Neurosci 21:1370–1377.
Liu C, Reppert SM (2000) GABA synchronizes clock cells within the suprachiasmatic cir-
cadian clock. Neuron 25:123–128.
Lisman JE, Idiart MAP (1995) Storage of 7 ± 2 short-term memories in oscillatory subcy-
cles. Science 267:1512–1515.
Llinás R (1988) The intrinsic properties of mammalian neurons: Insights into central ner-
vous system function. Science 242:1654–1664.
Llinás R (2001) I of the vortex: From neurons to self. MIT Press, Cambridge, MA.
Llinás R and Geijo-Barrientos E (1988) In vitro studies of mammalian thalamic and retic-
ularis thalami neurons. In: Cellular thalamic mechanisms (M. Bentivoglio and R.
Spreaﬁco, eds). Elsevier/Holland, Amsterdam, 23–33.
Llinás RR, Grace AA, Yarom Y (1991) In vitro neurons in mammalian cortical layer 4 ex-
hibit intrinsic oscillatory activity in the 10- to 50-Hz frequency range. Proc Natl Acad
Sci USA 88:897–901.
Llinás R, Muhlethaler M (1988) An electrophysiological study of the in vitro, perfused
brain stem-cerebellum of adult guinea-pig. J Physiol (Lond) 404:215–240.
Llinás RR, Paré D (1991) Of dreaming and wakefulness. Neuroscience 44:521–535.
Llinás R, Ribary U (1993) Coherent 40-Hz oscillation characterizes dream state in hu-
mans. Proc Natl Acad Sci USA 90:2078–2081.
Llinás RR, Ribary U, Joliot M, Wang X-J (1994) Content and context in temporal thalam-
ocortical binding. In: Temporal coding in the brain (Buzsáki G, Llinás R, Singer W,
Berthoz A, Christen Y, eds). Springer-Verlag, Berlin, 251–272.
Llinás R, Sugimori M (1980) Electrophysiological properties of in vitro Purkinje cell so-
mata in mammalian cerebellar slices. J Physiol (Lond) 305:171–195.
Llinás R, Urbano FJ, Leznik E, Ramirez RR, van Marle HJ (2005) Rhythmic and dys-
rhythmic thalamocortical dynamics: GABA systems and the edge effect. Trends Neu-
rosci 28:325–333.
Llinás RR, Yarom Y (1981) Electrophysiology of mammalian inferior olivary neurones in
vitro. Different types of voltage-dependent ionic conductances. J Physiol 315:549–567.
Loewenstein Y, Mahon S, Chadderton P, Kitamura K, Sompolinsky H, Yarom Y, Häusser
M (2005) Bistability of cerebellar Purkinje cells modulated by sensory stimulation. Nat
Neurosci 8:202–211.
Loewi O (1960) An autobiographic sketch. University of Chicago Press, Chicago.
Loftus EF (1997) Creating false memories. Sci Am (Sept.) 277:70–75.
Logothetis N (2003) The underpinnings of the BOLD functional magnetic resonance im-
aging signal. J Neurosci 23:3963–3971.

References
405
Logothetis NK (1998) Single units and conscious vision. Philos Trans R Soc Lond B
353:1801–1818.
Logothetis NK, Pauls J (1995) Psychophysical and physiological evidence for viewer-
centered object representation in the primate. Cereb Cortex 5:270–288.
Logothetis NK, Pauls J, Augath M, Trinath T, Oeltermann A (2001) Neurophysiological in-
vestigation of the basis of the fMRI signal. Nature 412:150–157.
Loomis AL, Harvey N, Hobart GA (1938) Distribution of disturbance patterns in human
electroencephalogram, with special reference to sleep. J Neurophysiol 1:413–430.
Lopes da Silva F (1993) Event-related potentials: Methodology and quantiﬁcation. In:
Electroencephalography: Basic principle, clinical applications, and related ﬁelds (Nie-
dermeyer Z, Lopes da Silva F, eds). Williams and Wilkins, Baltimore, MD, 877–886.
Lopes da Silva FH, Hoeks A, Smits H, Zetterberg LH (1974) Model of brain rhythmic
activity: The alpha rhythm of the thalamus. Kybernetik 15:27–37.
Lopes da Silva FH, Pijn JP, Velis D, Nijssen PCG (1997) Alpha rhythms: Noise, dynamics
and models. Int J Psychophysiol 26:237–249.
Lopes da Silva FH, Storm van Leeuwen W (1978) The cortical alpha rhythm of the dog:
The depth and proﬁle of phase. In: Architectonics of the cerebral cortex (Brazier MAB,
Petsche H, eds). Raven, New York150–187.
Lopes da Silva FH, Vos JE, Van Rotterdam A (1980) Relative contributions of intracortical
and thalamo-cortical processes in the generation of alpha rhythms, revealed by partial
coherence analysis. Electroencephalogr Clin Neurophysiol 50:449–456.
Lopes da Silva FH, Witter MP, Boeijinga PH, Lohman AH (1990) Anatomic organization
and physiology of the limbic cortex. Physiol Rev 70:453–511.
Lorente de Nó R (1949) Cerebral cortex: Architecture, intracranial connections, motor
projections. In: Physiology of the nervous system (Fulton JF, ed). Oxford University
Press, London, 288–313.
Lõrincz A, Buzsáki G (2000) Two-phase computational model training long-term memo-
ries in the entorhinal-hippocampal region. Ann NY Acad Sci 911:83–111.
Lõrincz A, Notomi T, Tamas G, Shigemoto R, Nusser Z (2002) Polarized and
compartment-dependent distribution of HCN1 in pyramidal cell dendrites. Nat Neurosci
5:1185–1193.
Louie K, Wilson MA (2001) Temporally structured replay of awake hippocampal ensem-
ble activity during rapid eye movement sleep. Neuron 29:145–156.
Luria AR (1966) Higher cortical functions in man. Basic Books, New York.
Luria AR (1987) The mind of a mnemonist: A little book about a vast memory. Harvard
University Press, Cambridge, MA (originally published in Russian in 1968).
Lutz A, Greischar LL, Rawlings NB, Ricard M, Davidson RJ (2004) Long-term meditators
self-induce high-amplitude gamma synchrony during mental practice. Proc Natl Acad
Sci USA 101(46):16369–16373.
Lyamin OI, Mukhametov LM, Siegel JM, Nazarenko EA, Polyakova IG, Shpak OV (2002)
Unihemispheric slow wave sleep and the state of the eyes in a white whale. Behav Brain
Res 129:125–129.
Lytton WW, Sejnowski TJ (1991) Simulations of cortical pyramidal neurons synchronized
by inhibitory interneurons. J Neurophysiol 66:1059–1079.
Maas W, Bishop CM (eds) (1999) Pulsed neural networks. MIT Press, Cambridge, MA.

406
References
Maccaferri G, Lacaille JC (2003) Interneuron Diversity series: Hippocampal interneuron
classiﬁcations—making things as simple as possible, not simpler. Trends Neurosci
26:564–571.
MacDonald S (1998) Aquinas’s libertarian account of free will. Rev Int Philos 2:309–328.
MacKay DJC (2003) information theory, inference and learning algorithms. Cambridge
University Press, Cambridge. http://www.inference.phy.cam.ac.uk/mackay/itila/
MacLean PD (1990) The triune brain in evolution: Role in paleocerebral functions.
Plenum Press, New York.
MacLeod K, Bäcker A, Laurent G (1998) Who reads temporal information contained
across synchronized and oscillatory spike trains? Nature 395: 693–698.
MacLeod K, Laurent G (1996) Distinct mechanisms for synchronization and temporal pat-
terning of odor-encoding neural assemblies Science, 274: 976–979.
Macquet P, Franck G (1996) Functional neuroanatomy of human rapid eye movement
sleep and dreaming. Nature 383:163–166.
Magee J, Hoffman D, Colbert C, Johnston D (1998) Electrical and calcium signaling in
dendrites of hippocampal pyramidal neurons. Annu Rev Physiol 60:327–346.
Magee JA (2003) A prominent role for intrinsic neuronal properties in temporal coding.
Trends Neurosci 26:14–16.
Magee JA (2000) Dendritic integration of excitatory synaptic input. Nat Rev Neurosci
1:181–190.
Magee JC, Johnston D (1997) A synaptically controlled, associative signal for Hebbian
plasticity in hippocampal neurons. Science 275:209–213.
Mainen ZF, Sejnowski TJ (1995) Reliability of spike timing in neocortical neurons. Sci-
ence 268:1503–1506.
Mainen ZF, Sejnowski TJ (1996) Inﬂuence of dendritic structure on ﬁring pattern in model
neocortical neurons. Nature 382:363–366.
Makeig S (1993) Auditory event-related dynamics of the EEG spectrum and effects of ex-
posure to tones. Electroencephalogr Clin Neurophysiol 86:283–293.
Makeig S, Delorme A, Westerﬁeld M, Jung TP, Townsend J, Courchesne E, Sejnowski TJ
(2004) Electroencephalographic brain dynamics following manually responded visual
targets. PLoS Biol 202:747–762.
Makeig S, Westerﬁeld M, Jung TP, Enghoff S, Townsend J, Courchesne E, Sejnowski TJ
(2002) Dynamic brain sources of visual evoked responses. Science 295:690–694.
Mandelbrot B (1999) Multifractals and 1/f noise: Wild self-afﬁnity in physics. Springer,
New York.
Mandelbrot BB (1983) The fractal geometry of nature. W.H. Freeman, San Francisco.
Manganotti P, Gerloff C, Toro C, Katsuta H, Sadato N, Zhuang P, Leocani L, Hallet M
(1998) Task-related coherence and task-related spectral power changes during sequen-
tial ﬁnger movements. Electroencephalogr Clin Neurophysiol 109:50–62.
Mann EO, Suckling JM, Hajos N, Greenﬁeld SA, Paulsen O (2005) Perisomatic feedback
inhibition underlies cholinergically induced fast network oscillations in the rat hip-
pocampus in vitro. Neuron 45:105–117.
Manwani A, Koch C (1999) Detecting and estimating signals in noisy cable structure,
I: Neuronal noise sources. Neural Comput 11:1797–1829.
Maquet P (2001) The role of sleep in learning and memory. Science 294:1048–1052.

References
407
Maquet P, Ruby P (2004) Psychology: Insight and the sleep committee. Nature 427:
352–355.
Marder E, Calabrese RL (1996) Principles of rhythmic motor pattern generation. Physiol
Rev 76:687–717.
Markram H, Lubke J, Frotscher M, Sakmann B (1997) Regulation of synaptic efﬁcacy by
coincidence of postsynaptic APs and EPSPs. Science 275:213–215.
Markram H, Toledo-Rodriguez M, Wang Y, Gupta A, Silberberg G, Wu C (2004) Interneu-
rons of the neocortical inhibitory system. Nat Rev Neurosci 5:793–807.
Marr D (1971) Simple memory: A theory for archicortex. Philos Trans R Soc Lond
262:23–81.
Marr D (1982) Vision: A computational investigation into the human representation and
processing of visual information. W.H. Freeman Publishers, San Francisco.
Marshall L, Henze DA, Hirase H, Leinekugel X, Dragoi G, Buzsáki G (2002) Hippocam-
pal pyramidal cell-interneuron spike transmission is frequency dependent and responsi-
ble for place modulation of interneuron discharge. J Neurosci 22:RC197.
Martin KA (1994) A brief history of the “feature detector.” Cereb Cortex 4:1–7.
Martin RD, Harvey PH (1985) Brain size allometry. Ontogeny and phylogeny. In: Size and
scaling in primate biology (Jungers WL, ed). Plenum, New York, 147–173.
Martinotti C (1889) Contributo allo studio della corteccia cerebrale, ed all’origine centrale
dei nervi. Ann Freniatr Sci Afﬁni 1:14–381.
Massimini M, Ferrarelli F, Huber R, Esser SK, Singh H, Tononi G (2005) Breakdown of
cortical effective connectivity during sleep. Science 309:2228–2232.
Massimini M, Huber R, Ferrarelli F, Hill S, Tononi G (2004) The sleep slow oscillation as
a traveling wave. J Neurosci 24:6862–6870.
Maturana HR, Varela FJ (1980) Autopoiesis and cognition: The realization of the living.
Boston Studies in the Philosophy of Science (Cohen RS, Wartofsky MW, eds), vol 42.
D. Reidel Publishing Company, Dordecht.
McCartney H, Johnson AD, Weil ZM, Givens B (2004) Theta reset produces optimal con-
ditions for long-term potentiation. Hippocampus 14:684–647.
McClelland JL, McNaughton BL, O’Reilly RC (1995) Why there are complementary
learning systems in the hippocampus and neocortex: Insights from the successes and
failures of connectionist models of learning and memory? Psychol Rev 102:419–457.
McCormick DA (1992) Neurotransmitter actions in the thalamus and cerebral cortex and
their role in neuromodulation of thalamocortical activity. Progr Neurobiol 39:337–388.
McCormick DA, Bal T (1997) Sleep and arousal: Thalamocortical mechanisms. Annu Rev
Neurosci 20:185–215.
McCormick DA, Pape HC (1990) Properties of a hyperpolarization-activated cation cur-
rent and its role in rhythmic oscillation in thalamic relay neurones. J Physiol (Lond)
431:291–318.
McCormick DA, Thompson RF (1984) Cerebellum: Essential involvement in the classi-
cally conditioned eyelid response. Science 223:296–299.
McCormick DA, Wang Z (1991) Serotonin and noradrenaline excite GABAergic neurones
of the guinea-pig and cat nucleus reticularis thalami. J Physiol (Lond) 442:235–255.
McCormick DA, Wang Z, Huguenard J (1993) Neurotransmitter control of neocortical
neuronal activity and excitability. Cereb Cortex 3:387–398.

408
References
McDonald CT, Burkhalter A (1993) Organization of long-range inhibitory connections
with rat visual cortex. J Neurosci 13:768–781.
McEwen BS, Lasley EN (2002) The end of stress as we know it. Joseph Henry Press,
Washington DC.
McGaugh JL (2000) Memory—A century of consolidation. Science 287:248–251.
McKenna TM, McMullen TA, Shlesinger MF (1994) The brain as a dynamic physical sys-
tem. Neuroscience 60:587–605.
McLeod P, Plunkett K, Rolls ET (1998) Introduction to connectionist modelling of cogni-
tive processes. Oxford University Press, Oxford.
McNaughton BL, Barnes CA, Gerrard JL, Gothard K, Jung MW, Knierim JJ, Kudrimoti H,
Qin Y, Skaggs WE, Suster M, Weaver KL (1996) Deciphering the hippocampal polyglot:
The hippocampus as a path integration system. J Exp Biol 199:173–185.
McNaughton BL, Barnes CA, O’Keefe J (1983a) The contribution of position, direction,
and velocity to single unit activity in the hippocampus of freely moving rats. Exp Brain
Res 52:41–49.
McNaughton BL, Morris RGM (1987) Hippocampal synaptic enhancement and informa-
tion storage within a distributed memory system. Trends Neurosci 10:408–415.
McNaughton BL, O’Keefe J, Barnes CA (1983b) The stereotrode: A new technique for si-
multaneous isolation of several single units in the central nervous system from multiple
unit records. J Neurosci Methods 8:391–397.
Mednick SC, Nakayama K, Cantero JL, Atienza M, Levin AA, Pathak N, Stickgold R (2002)
The restorative effect of naps on perceptual deterioration. Nat Neurosci 5:677–681.
Mehta MR, Barnes CA, McNaughton BL (1997) Experience-dependent, asymmetric ex-
pansion of hippocampal place ﬁelds. Proc Natl Acad Sci USA 94:8918–8921.
Mehta MR, Lee AK, Wilson MA (2002) Role of experience and oscillations in transform-
ing a rate code into a temporal code. Nature 417:741–746.
Meier CA (ed) (2001) Atom and archetype: The Pauli/Jung letters, 1932–1958 (Roscoe D,
trans). Princeton University Press, Princeton, NJ.
Mello MT, Silva AC, Rueda AD, Poyares D, Tuﬁk S (1997) Correlation between K com-
plex, periodic leg movements (PLM), and myoclonus during sleep in paraplegic adults
before and after an acute physical activity. Spinal Cord 35:248–252.
Menaker M, Takahashi JS, Eskin A (1978) The physiology of circadian pacemakers. Annu
Rev Physiol 40:501–526.
Merica H, Fortune RD (2000) Brainstem origin for a new very slow (1 mHz) oscillation in
the human non-REM sleep episode. Sleep Res Online 3:53–59.
Mesulam MM (1998) From sensation to cognition. Brain 121:1013–1052.
Metherate R, Ashe JH (1993) Ionic ﬂux contributions to neocortical slow waves and
nucleus basalis-mediated activation: Whole-cell recordings in vivo. J Neurosci 13:
5312–5323.
Metherate R, Ashe JH (1995) Synaptic interactions involving acetylcholine, glutamate,
and GABA in rat auditory cortex. Exp Brain Res 107:59–72.
Meyer MP, Morrison P (1960) Tissue respiration and hibernation in the thirteen–lined
ground–squirrel, Spermophilus tridecemlineatus. Bull Mus Comp Zool 124:405–421.
Meyer-Koll A, Bussmann B, Schmidt C, Neuschwander D (1999) Walking through a maze
alters the architecture of sleep. Percept Mot Skills 88:1141–1159.

References
409
Miles R (1990) Synaptic excitation of inhibitory cells by single CA3 hippocampal pyram-
idal cells of the guinea-pig in vitro. J Physiol (Lond) 428:61–77.
Miles R, Wong RK (1986) Excitatory synaptic interactions between CA3 neurones in the
guinea-pig hippocampus. J Physiol (Lond) 373:397–418.
Miller GA (1956) The magical number seven, plus or minus two: Some limits on our ca-
pacity for processing information. Psychol Rev 63:81–97.
Miller KD, Pinto DJ, Simons DJ (2001) Processing in layer 4 of the neocortical circuit:
New insights from visual and somatosensory cortex. Curr Opin Neurobiol 11:
488–497.
Miller R (1989) Cortico-hippocampal interplay: Self-organizing phase-locked loops for
indexing memories. Psychobiology 17:115–128.
Miller R (1991) Cortico-hippocampal interplay and the representation of context in the
brain. Springer-Verlag, Berlin.
Miller R (1996a) Cortico-thalamic interplay and the security of operation of neural assem-
blies and temporal chains in the cerebral cortex. Biol Cybern 75:263–275.
Miller R (1996b) Neural assemblies and laminar interactions in the cerebral cortex. Biol
Cybern 75:253–261.
Miller R (2000) (ed) Time and the brain. Harwood Academic Publishers, Singapore.
Milner B, Squire LR, Kandel ER (1998) Cognitive neuroscience and the study of memory.
Neuron 20:445–468.
Milner PM (1974) A model for visual shape recognition. Psychol Rev 81:521–535.
Miltner WHR, Braun C, Arnold M, Witte H, Taub E (1999) Coherence of gamma-band
EEG activity as a basis for associate learning. Nature 397:434–437.
Mirollo RE, Strogatz SH (1990) Synchronization of pulse-coupled biological oscillators.
SIAM J Appl Math 50:1645–1662.
Mittelstaedt ML, Mittelstaedt H (1980) Homing by path integration in a mammal. Natur-
wissenschaften 67:566–567.
Mitzdorf U (1985) Current source-density method and application in cat cerebral cortex:
Investigation of evoked potentials and EEG phenomena. Physiol Rev 65:37–100.
Miyashita Y (2004) Cognitive memory: Cellular and network machineries and their top-
down control. Science 306:435–440.
Mody I, Pearce RA (2004) Diversity of inhibitory neurotransmission through GABA(A)
receptors. Trends Neurosci 27:569–575.
Moita MAP, Rosis S, Zhou Y, LeDoux JE, Blair HT (2003) Hippocampal place cells ac-
quire location-speciﬁc responses to the conditioned stimulus during auditory fear condi-
tioning. Neuron 37:485–497.
Mölle M, Marshall L, Gais S, Born J (2002) Grouping of spindle activity during slow os-
cillations in human non-rapid eye movement sleep. J Neurosci 22:10941–10947.
Monier C, Chavane F, Baudot P, Graham LJ, Fregnac Y (2003) Orientation and direction
selectivity of synaptic inputs in visual cortical neurons: A diversity of combinations pro-
duces spike tuning. Neuron 34:663–680.
Monyer H, Markram H (2004) Interneuron diversity series: Molecular and genetic tools to
study GABAergic interneuron diversity and function. Trends Neurosci 27:90–97.
Moore NC (2000) A review of EEG biofeedback treatment of anxiety disorders. Clin Elec-
troencephalogr 31:1–6.

410
References
Morin D, Steriade M (1981) Development from primary to augmenting responses in the
somatosensory system. Brain Res 205:49–56.
Morison, RS, Basset, DL (1945). Electrical activity of the thalamus and basal ganglia in
decorticate cats. Journal of Neurophysiology 8:309–314.
Morison RS, Demsey EW (1942) A study of thalamo-cortical relations. Am J Physiol
135:281–292.
Moruzzi G, Magoun HW (1949) Brain stem reticular formation and activation of the EEG.
Electroencephalogr Clin Neurophysiol 1:455–473.
Moser EI, Moser MB, Lipa P, Newton M, Houston FP, Barnes CA, McNaughton BL
(2005) A test of the reverberatory activity hypothesis for hippocampal “place” cells.
Neuroscience 130:519–526.
Moss F, Wiesenfeld K (1995) The beneﬁts of background noise. Sci Am 273:66–69.
Mott DD, Dingledine R (2003) Interneuron diversity series: Interneuron research—
challenges and strategies. Trends Neurosci 26:484–488.
Mountcastle VB (1997) The columnar organization of the neocortex. Brain 120:701–722.
Moutoussis K, Zeki S (1997) A direct demonstration of perceptual asynchrony in vision.
Proc Biol Sci 264:393–269.
Mulle C, Madariaga A, Deschenes M (1986) Morphology and electrophysiological prop-
erties of reticularis thalami neurons in cat: in vivo study of a thalamic pacemaker. J Neu-
rosci 6:2134–2145.
Muller RU, Kubie JL (1987) The effects of changes in the environment on the spatial ﬁring
of hippocampal complex-spike cells. J Neurosci 7:1951–1968.
Muller RU, Ranck JB Jr, Taube JS (1996a) Head direction cells: Properties and functional
signiﬁcance. Curr Opin Neurobiol 6:196–206.
Muller RU, Stead M, Pach J (1996b) The hippocampus as a cognitive graph. J Gen Physiol
107:663–694.
Murata T, Takahashi T, Hamada T, Omori M, Kosaka H, Yoshida H, Wada Y (2004) Indi-
vidual trait anxiety levels characterizing the properties of zen meditation. Neuropsy-
chobiology 50:189–194.
Murthy VN, Fetz EE (1996) Oscillatory activity in sensorimotor cortex of awake monkeys:
Synchronization of local ﬁeld potentials and relation to behavior. J Neurophysiol
76:3949–3967.
Muthuswamy J, Thakor NV (1998) Spectral analysis methods for neurological signals.
J Neurosci Methods 83:1–14.
Näätänen R, Paavilainen P, Alho K, Reinikainen K, Sams M (1987) The mismatch nega-
tivity to intensity changes in an auditory stimulus sequence. Electroencephalogr Clin
Neurophysiol 40(suppl):125–131.
Näätänen R (1975) Selective attention and evoked potentials in humans—A critical review.
Biol Psychol 2:237–307.
Näätänen R, Syssoeva O, Takegata R (2004) Automatic time perception in the human brain
for intervals ranging from milliseconds to seconds. Psychophysiology 41:660–663.
Nádasdy Z, Csicsvari J, Penttonen M, Buzsáki G (1998) Extracellular recording and analy-
sis of electrical activity: From single cells to ensembles. In: Neuronal ensembles: Strate-
gies for recording and decoding (Eichenbaum H, Davis JL, eds). Wiley-Liss, New York,
17–55.

References
411
Nádasdy Z, Hirase H, Czurkó A, Csicsvari J, Buzsáki G (1999) Replay and time compres-
sion of recurring spike sequences in the hippocampus. J Neurosci 19:9497–9507.
Nadel L, Moscovitch M (1997) Memory consolidation, retrograde amnesia and the hip-
pocampal complex. Curr Opin Neurobiol 7:217–227.
Nadel L, Eichenbaum H (1999) Introduction to the special issue on place cells. Hippocam-
pus 9:341–345.
Nader K, Schafe GE, LeDoux JE (2000) The labile nature of consolidation theory. Nat Rev
Neurosci 1:216–219.
Nagel T (1974) What is it like to be a bat? Philos Rev 83:435–450.
Nakazawa K, Quirk MC, Chitwood RA, Watanabe M, Yeckel MF, Sun LD, Kato A, Carr
CA, Johnston D, Wilson MA, Tonegawa S (2002) Requirement for hippocampal CA3
NMDA receptors in associative memory recall. Science 297:211–218.
Nauta WJ, Feirtag M (1979) The organization of the brain. Sci Am (July) 241:88–111.
Naya Y, Yoshida M, Miyashita Y (2001) Backward spreading of memory-retrieval signal in
the primate temporal cortex. Science 291:661–664.
Neda Z, Ravasz E, Brechet Y, Vicsek T, Barabási AL (2000) The sound of many hands
clapping. Nature 403:849–850.
Nicholson C, Freeman JA (1975) Theory of current source-density analysis and determi-
nation of conductivity tensor for anuran cerebellum. J Neurophysiol 38:356–368.
Nicolelis MA (2003) Brain-machine interfaces to restore motor function and probe neural
circuits. Nat Rev Neurosci 4:417–422.
Nicolelis MA, Baccala LA, Lin RC, Chapin JK (1995) Sensorimotor encoding by syn-
chronous neural ensemble activity at multiple levels of the somatosensory system. Sci-
ence 268:1353–1358.
Nicolelis MA, De Oliveira LM, Lin RC, Chapin JK (1996) Active tactile exploration inﬂu-
ences the functional maturation of the somatosensory system. J Neurophysiol 75:
2192–2196.
Nieder A, Miller EK (2003) Coding of cognitive magnitude: Compressed scaling of nu-
merical information in the primate prefrontal cortex. Neurons 37:149–157.
Niedermeyer E (2004) The electrocerebellogram. Clin EEG Neurosci 35:112–115.
Niedermeyer Z, Lopes da Silva F (eds) (2005) Electroencephalography: Basic principle,
clinical applications, and related ﬁelds. 5th ed. Williams and Wilkins, Baltimore.
Nimchinsky EA, Gilissen E, Allman JM, Perl DP, Erwin JM, Hof PR (1999) A neuronal
morphologic type unique to humans and great apes. Proc Natl Acad Sci USA 96:5268–
5273.
Nitz D, Tononi G (2002) Tonic rhythmic activity of rat cerebellar neurons. Exp Brain Res
146:265–270.
Noda H, Manohar S, Adey WR (1969) Spontaneous activity of cat hippocampal neurons in
sleep and wakefulness. Exp Neuron 24:217–231.
Noebels JL, Roth WT, Kopell BS (1978) Cortical slow potentials and the occipital EEG in
congenital blindness. J Neurol Sci 37:51–58.
Nolan MF, Malleret G, Dudman JT, Buhl DL, Santoro B, Gibbs E, Vronskaya S, Buzsáki
G, Siegelbaum SA, Kandel ER, Morozov A (2004) A behavioral role for dendritic inte-
gration: HCN1 channels constrain spatial memory and plasticity at inputs to distal den-
drites of CA1 pyramidal neurons. Cell 119:719–732.

412
References
Nuñez A, Curro Dossi R, Contreras D, Steriade M (1992) Intracellular evidence for in-
compatibility between spindle and delta oscillations in thalamocortical neurons of cat.
Neuroscience 48:75–85.
Nuñez PL (1998) Electric ﬁelds of the brain: The neurophysics of EEG. Oxford University
Press, New York.
Nuñez PL (2000) Toward a quantitative description of large-scale neocortical dynamic
function and EEG. Behav Brain Sci 23:371–398.
Nussbaum MC (1978) Aristotle’s De Motu Animalium. Princeton University Press,
Princeton, NJ.
Nusser Z, Mody I (2002) Selective modulation of tonic and phasic inhibitions in dentate
gyrus granule cells. J Neurophysiol 87:2624–2628.
Odin P, Mrowka M, Shing M (2002) Restless legs syndrome. Eur J Neurol 9 Suppl 3:59–67.
Ogawa S, Lee TM, Kay AR, Tank DW (1990) Brain magnetic resonance imaging with con-
trast dependent on blood oxygenation. Proc Natl Acad Sci USA 87:9868–9872.
O’Keefe J (1976) Place units in the hippocampus of the freely moving rat. Exp Neurol
51:78–109.
O’Keefe J (1999) Do hippocampal pyramidal cells signal non-spatial as well as spatial in-
formation? Hippocampus 9:352–964.
O’Keefe J, Burgess N (1996) Geometric determinants of the place ﬁelds of hippocampal
neurons. Nature 381:425–428.
O’Keefe J, Dostrovsky J (1971) The hippocampus as a spatial map. Preliminary evidence
from unit activity in the freely-moving rat. Brain Res 34:171–175.
O’Keefe J, Nadel L (1978) The hippocampus as a cognitive map. Clarendon Press, Oxford.
O’Keefe J, Recce ML (1993) Phase relationship between hippocampal place units and the
EEG theta rhythm. Hippocampus 3:317–330.
Olhausen BA, Field DJ (1996) Emergence of simple-cell receptive ﬁeld properties by
learning a sparse code for natural images. Nature 381:607–609.
Olsson RH 3rd, Buhl DL, Sirota AM, Buzsáki G, Wise KD (2005) Band-tunable and mul-
tiplexed integrated circuits for simultaneous recording and stimulation with microelec-
trode arrays. IEEE Trans Biomed Eng 52:1303–1311.
O’Regan JK, Noe A (2001) A sensorimotor account of vision and visual consciousness.
Behav Brain Sci 24:939–973.
O’Reilly RC, McClelland JL (1994) Hippocampal conjunctive encoding, storage, and re-
call: Avoiding a trade-off. Hippocampus 4:661–682.
Pakkenberg B, Gundersen HJG (1997) Neocortical neuron number in humans: Effect of
sex and age. J Comp Neurol 384:312–320.
Paller KA, Kutas M, Mayes AR (1987) Neural correlates of encoding in an incidental
learning paradigm. Electroencephalogr Clin Neurophysiol 67:360–371.
Palm G (1982) Neural assemblies. Springer, Berlin.
Palva S, Linkenkaer-Hansen K, Naatanen R, Palva JM (2005) Early neural correlates of
conscious somatosensory perception. J Neurosci 25:5248–5258.
Palva JM, Palva S, Kaila K (2005) Phase synchrony among neuronal oscillations in the hu-
man cortex. J Neurosci 25:3962–3972.
Panksepp J (1998) Affective neuroscience: The foundations of human and animal emo-
tions. Oxford University Press, New York.

References
413
Pantev C (1995) Evoked and induced gamma-band activity of the human cortex. Brain
Topography 7:321–330.
Papez JW (1937) A proposed mechanism of emotion. Arch Neurol Psychiatr 38:725–743.
Papp E, Leinekugel X, Henze DA, Lee J, Buzsáki G (2001) The apical shaft of CA1 py-
ramidal cells is under GABAergic interneuronal control. Neuroscience 102:715—721.
Paré D, Collins DR, Pelletier JG (2002) Amygdala oscillations and the consolidation of
emotional memories. Trends Cogn Sci 6:306–314.
Paré D, Royer S, Smith Y, Lang EJ (2003) Contextual inhibitory gating of impulse trafﬁc
in the intra-amygdaloid network. Ann NY Acad Sci 985:78–91.
Paré D, Shink E, Gaudreau H, Destexhe A, Lang EJ (1998) Impact of spontaneous synap-
tic activity on the resting properties of cat neocortical pyramidal neurons in vivo. J Neu-
rophysiol 79:1450–1460.
Paré D, Steriade M, Deschênes M, Oakson G (1987) Physiological characteristics of ante-
rior thalamic nuclei, a group devoid of inputs from reticular thalamic nucleus. J Neuro-
physiol 57:1669–1685.
Parker AJ, Newsome WT (1998) Sense and single neurons: Probing the physiology of per-
ception. Annu Rev Neurosci 21:227–277.
Pavlides C, Winson J (1989) Inﬂuences of hippocampal place cell ﬁring in the awake state
on the activity of these cells during subsequent sleep episodes. J Neurosci 9:2907–2918.
Pavlov IP (1927) Conditioned reﬂexes. Routledge and Kegan Paul, Baltimore.
Peat FD (1987) Synchronicity: The bridge between matter and mind. Bantam, New York.
Pedroarena C, Llinás R (1997) Dendritic calcium conductances generate high-frequency
oscillation in thalamocortical neurons. Proc Natl Acad Sci USA 94:724–728.
Penﬁeld W, Jasper H (1954) Epilepsy and the functional anatomy of the human brain. Lit-
tle, Brown, Boston.
Penttonen M, Buzsáki G (2003) Natural logarithmic relationship between brain oscillators.
Thalamus Relat Syst 48:1–8.
Penttonen M, Kamondi A, Acsády L, Buzsáki G (1998) Gamma frequency oscillation in
the hippocampus of the rat: Intracellular analysis in vivo. Eur J Neurosci 10:
718–728.
Penttonen M, Kamondi A, Sík A, Acsády L, Buzsáki G (1997) Feed-forward and feed-back
activation of the dentate gyrus in vivo during dentate spikes and sharp wave bursts. Hip-
pocampus 7:437–750.
Penttonen M, Nurminen N, Miettinen R, Sirvio J, Henze DA, Csicsvari J, Buzsáki G
(1999) Ultra-slow oscillation (0.025 Hz) triggers hippocampal afterdischarges in Wistar
rats. Neuroscience 94:735–743.
Percival DB, Warden AT (2000) Wavelet methods for time series analysis. Cambridge Uni-
versity Press, Cambridge.
Pernier J, Perrin F, Bertrand O (1988) Scalp current density ﬁelds: Concepts and proper-
ties. Electroencephalogr Clin Neurophysiol 69:385–389.
Perrett DI, Hietanen JK, Oram MW, Benson PJ (1984) Organization and functions of cells
responsive to faces in the temporal cortex. Philos Trans R Soc Lond B 335:23–30.
Petsche H, Stumpf C, Gogolak G (1962) The signiﬁcance of the rabbit’s septum as a relay
station between the midbrain and the hippocampus. I. The control of hippocampus
arousal activity by the septum cells. Electroencephalogr Clin Neurophysiol. 14:202–211.

414
References
Peters A, Palay SL, Webster HF (1991) The ﬁne structure of the nervous system: The cells
and their processes. Oxford University Press, New York.
Peters A, Payne BR, Josephson K (1990) Transcallosal non-pyramidal cell projections
from visual cortex in the cat. J Comp Neurol 302:124–142.
Petersen CC (2003) The barrel cortex—integrating molecular, cellular and systems physi-
ology. Pﬂuegers Arch 447:126–134.
Petersen CC, Hahn TT, Mehta M, Grinvald A, Sakmann B (2003) Interaction of sensory
responses with spontaneous depolarization in layer 2/3 barrel cortex. Proc Natl Acad Sci
USA 100:13638–13643.
Pfurtscheller G (1992) Event related synchronization (ERS): An electrophysiological cor-
relate of cortical areas at rest. Electroencephalogr Clin Neurophysiol 82:62–69.
Pfurtscheller G, Aranibar A (1997) Event-related cortical desynchronization detected by
power measurements of scalp EEG. Electroencephalogr Clin Neurophysiol 42:817–826.
Pfurtscheller G, Berghold A (1989) Patterns of cortical activation during planning of vol-
untary movement. Electroencephalogr Clin Neurophysiol 72:250–258.
Pfurtscheller G, Neuper C, Krausz G (2000) Functional dissociation of lower and upper
frequency mu rhythms in relation to voluntary limb movement. Clin Neurophysiol
111:1873–1879.
Pfurtscheller G, Neuper C, Mohl W (1994) Event-related desynchronization (ERD) during
visual processing. Int J Psychophysiol 16:147–153.
Phillips WA, Singer W (1997) In search of common foundations for cortical computation.
Behav Brain Sci 20:657–683.
Pickard GE, Turek FW (1983) The suprachiasmatic nuclei: Two circadian clocks? Brain
Res 268:201–210.
Pickering KA (1996) Columbus’s method of determining longitude: An analytical view. J
Navig 49:99–113.
Pigache RM (1970) The anatomy of “paleocortex.” A critical review. Ergeb Anat Entwick-
lungsgesch 43:3–62.
Pike FG, Goddard RS, Suckling JM, Ganter P, Kasthuri N, Paulsen O (2000) Distinct fre-
quency preferences of different types of rat hippocampal neurones in response to oscil-
latory input currents. J Physiol (Lond) 529:205–513.
Pikovsky A, Rosenblum M, Kurths J (2001) Concept in nonlinear sciences. Cambridge
University Press, Cambridge.
Pinault D, Deschênes M (1998) Projection and innervation patterns of individual thalamic
reticular axons in the thalamus of the adult rat: A three-dimensional, graphic, and mor-
phometric analysis. J Comp Neurol 391:180–203.
Pinault D, Smith Y, Deschênes M (1997) Dendrodendritic and axosomatic synapses in the
thalamic reticular nucleus of the adult rat. J Neurosci 17:3215–3233.
Pitkanen A, Pikkarainen M, Nurminen N, Ylinen A (2000) Reciprocal connections be-
tween the amygdala and the hippocampal formation, perirhinal cortex, and postrhinal
cortex in rat. Ann NY Acad Sci 911:369–391.
Plum F, Posner JB (1980) The diagnosis of stupor and coma. 3rd ed. F.A. Davis Company,
Philadelphia.
Polyn SM, Vaihedi SN, Cohen JD, Norman KA (2006) Category-speciﬁc cortical activity
precedes retrieval during memory search. Science 310:1963–1966.

References
415
Porkka-Heiskanen T, Strecker RE, Thakkar M, Bjorkum AA, Greene RW, McCarley RW
(1997) Adenosine: A mediator of the sleep-inducing effects of prolonged wakefulness.
Science 276:1265–1268.
Potter SM, Wagenaar DA, DeMarse TB (2006) Closing the loop: stimulation feedback sys-
tems for embodied MEA cultures. In: Advances in network electrophysiology using
multielectrode arrays (M Taketani and M Baudry, eds), Springer, New York (in press).
Pouille F, Scanziani M (2001) Enforcement of temporal ﬁdelity in pyramidal cells by so-
matic feed-forward inhibition. Science 293:1159–1163.
Pouille F, Scanziani M (2004) Routing of spike series by dynamic circuits in the hip-
pocampus. Nature 429:717–723.
Pravdich-Neminskii VV (Prawdicz-Neminski WW) (1913) Ein Vesuch der Registrierung
der elektrischen Gehirnerscheinungen. Zentralbl Physiol 27:951–960.
Prigogine I, Stengers I (1984) Order out of chaos. Bantam, New York.
Prinz AA, Bucher D, Marder E (2004) Similar network activity from disparate circuit pa-
rameters. Nat Neurosci 7:1345–1352.
Pulvermuller F, Eulitz C, Pantev C, Mohr B, Feige B, Lutzenberger W, Elbert T, Bir-
baumer N (1996) High-frequency cortical responses reﬂect lexical processing: An MEG
study. Electroencephalogr Clin Neurophysiol 98:76–85.
Purkinje JE (1846) Wachen, Schlaf, Traum und verwandte Zustande. In: Handwortenbuch
der Physiologie mit Rucksicht auf physiologische Pathologie (R Wagner, ed), vol 2.
Vieweg und Sohn, Brounschweig, Germany, 412–480.
Quiroga RQ, Reddy L, Kreiman G, Koch C, Fried I (2005) Invariant visual representation
by single neurons in the human brain. Nature 435:1102–1107.
Raaijmakers JGW, Shiffrin RM (1981) Search of associative memory. Psychol Rev
88:93–134.
Raghavachari S, Kahana MJ, Rizzuto DS, Caplan JB, Kirschen MP, Bourgeois B, Madsen
JR, Lisman JE (2001) Gating of human theta oscillations by a working memory task. J
Neurosci 21:3175–3183.
Raghavachari S, Lisman JE, Tully M, Madsen JR, Bromﬁeld EB, Kahana MJ (2006) Theta
oscillations in human cortex during a working-memory task: Evidence for local genera-
tors. J Neurophysiol 95:1630–168.
Raichle ME (2003) Functional brain imaging and human brain function. J Neurosci
23:3959–3962.
Raichle ME, MacLeod AM, Snyder AZ, Powers WJ, Gusnard DA, Shulman GL (2001) A
default mode of brain function. Proc Natl Acad Sci USA 98:676–682.
Rainnie DG, Grunze HC, McCarley RW, Greene RW (1994) Adenosine inhibition of
mesopontine cholinergic neurons: Implications for EEG arousal. Science 263:
689–692.
Ralston B, Ajmone-Marsan C (1956) Thalamic control of certain normal and abnormal
cortical rhythms. Electroencephalogr Clin Neurophysiol 8:559–583.
Ramón y Cajal S (1901) Estudios sobre la corteza cerebral IV. Estructura de la corteza cere-
bral olfativa del hombre y mamíferos. Trab. Lab. Invest. Biol. Univ. Madrid 1:1–140.
Ranck JB Jr (1973) Studies on single neurons in dorsal hippocampal formation and septum
in unrestrained rats. I. Behavioral correlates and ﬁring repertoires. Exp Neurol 41:
461–531.

416
References
Ranck JB Jr (1985) Head direction cells in the deep cell layer of dorsal postsubiculum in
freely moving rats. In: Electrical activity of the archicortex (Buzsáki G, Vanderwolf CH,
eds). Akademiai Kiado, Budapest, 217–220.
Rapp PE, Albano AM, Schmah TI, Farwell LA (1993) Filtered noise can mimic low-
dimensional chaotic attractors. Physical Rev E 47:2289–2297.
Rauschecker JP (1995) Compensatory plasticity and sensory substitution in the cerebral
cortex. Trends Neurosci 18:36–43.
Redish AD (1999) Beyond the cognitive map: From place cells to episodic memory. MIT
Press, Cambridge, MA.
Redish AD, Battaglia FP, Chawla MK, Ekstrom AD, Gerrard JL, Lipa P, Rosenzweig 
ES, Worley PF, Guzowski JF, McNaughton BL, Barnes CA (2001) Independence of ﬁr-
ing correlates of anatomically proximate hippocampal pyramidal cells. J Neurosci
21:RC134.
Reich DS, Mechler F, Victor JD (2001) Independent and redundant information in nearby
cortical neurons. Science 294:2566–2568.
Rensing L, van der Heiden U, Mackey MC (eds) (1987) Temporal disorder in human os-
cillatory system. Springer Series in Synergetics, vol 36. Springer, New York.
Reynolds JH, Desimone R (1999) The role of neural mechanisms of attention in solving
the binding problem. Neuron 24:19–29.
Ribary U, Ioannides AA, Singh KD, Hasson R, Bolton JP, Lado F, Mogilner A, Llinás R
(1991) Magnetic ﬁeld tomography of coherent thalamocortical 40-Hz oscillations in hu-
mans. Proc Natl Acad Sci USA 88:11037–11041.
Ribeiro S, Gervasoni D, Soares ES, Zhou Y, Lin SC, Pantoja J, Lavine M, Nicolelis MA
(2004) Long-lasting novelty-induced neuronal reverberation during slow-wave sleep in
multiple forebrain areas. PLoS Biol 2:E24.
Rick JH, Marczynski TJ (1976) Dependence of reward contingent positive variation
(RCPV) and cortical synchronization on visual input in the cat. Electroencephalogr Clin
Neurophysiol 41:301–309.
Riehle A, Grun S, Diesmann M, Aertsen A (1997) Spike synchronization and rate modula-
tion differentially involved in motor cortical function. Science 278:1950–1953.
Ringo JL (1991) Neuronal interconnection as a function of brain size. Brain Behav Evol
38:1–6.
Ringo JL, Doty RW, Demeter S, Simard PY (1994) Time is of the essence: A conjecture
that hemispheric specialization arises from interhemispheric conduction delay. Cereb
Cortex 4:331–343.
Rizzolatti G, Matelli M, Parvasi G (1983) Deﬁcit in attention and movement following the re-
moval of postarcuate (area 6) and prearcuate (area 8) cortex in monkey. Brain 106:655–673.
Rizzuto DS, Madsen JR, Bromﬁeld EB, Schulze-Bonhage A, Seelig D, Aschenbrenner-
Scheibe R, Kahana MJ (2003) Reset of human neocortical oscillations during a working
memory task. Proc Natl Acad Sci USA 100:7931–7936.
Robbe D, Montgomery SM, Buzsaki G (2005) Cannabinoids destroy cell assembly coordi-
nation in the hippocampus. Society for Neuroscience Meeting (Washington DC) Ab-
stract #. 275.13.
Robinson PA, Rennie CJ, Wright JJ, Bourke PD (1998) Steady states and global dynamics
of electrical activity in the cerebral cortex. Phys Rev E 58:3557–3571.

References
417
Robinson SR, Kleven GA (2005) Learning to move before birth. In: Prenatal development
of postnatal function (Hopkins B, Johnson SP, eds). Praeger, New York, 131–175.
Rockel AJ, Hiorns RW, Powell TPS (1980) The basic uniformity in structure of the neo-
cortex. Brain 103:221–244.
Roder B, Teder-Salejarvi W, Sterr A, Rosler F, Hillyard SA, Neville HJ (1999) Improved
auditory spatial tuning in blind humans. Nature 400:162–166.
Rodriguez E, George N, Lachaux JP, Martinerie J, Renault B, Varela FJ (1999) Percep-
tion’s shadow: Long-distance synchronization of human brain activity. Nature 397:
430–433.
Roelfsema PR, Konig P, Engel AK, Sireteanu R, Singer W (1994) Reduced synchroniza-
tion in the visual cortex of cats with strabismic amblyopia. Eur J Neurosci 6:1645–1655.
Rolls ET (1996) A theory of hippocampal function in memory. Hippocampus 6:601–620.
Rolls ET (1999) Spatial view cells and the representation of place in the primate hip-
pocampus. Hippocampus 9:467–480.
Rolls ET, Treves A (1997) Neural networks and brain function. Oxford University Press,
New York.
Rommell SA, McCleave JD (1972) Oceanic electric ﬁelds: Perception by American eels.
Science 176:1233.
Rose M (1937) Gyrus limbicus anterior and Regio retrosplenialis (Cortex holoprotopty-
chos quin-questratiﬁcatus). Vergleichende Architektonik bei Tier und Mensch. J Psychol
Neurol 35:65–173.
Roskies A (1999) The binding problem. Neuron 24:7–9.
Roth M, Shaw J, Green J (1956) The form, voltage distribution and physiological signiﬁ-
cance of the K-complex. Electroencephalogr Clin Neurophysiol 8:385–402.
Rougeul-Buser A, Buser P (1997) Rhythms in the alpha band in cats and their behavioural
correlates. Int J Psychophysiol 26:191–203.
Rotstein HG, Pervouchine DD, Acker CD, Gillies MJ, White JA, Buhl EH, Whittington
MA, Kopell N (2005) Slow and fast inhibition and an H-current interact to create a theta
rhythm in a model of CA1 interneuron network. J Neurophysiol 94:1509–1518.
Royer S, Paré D (2003) Conservation of total synaptic weight through balanced synaptic
depression and potentiation. Nature 422:518–522.
Ruderman DL, Bialek W (1994) Statistics of natural images: Scaling in the woods. Phys
Rev Lett 73:814–817.
Sacks O (1995) An anthropologist on Mars: Seven paradoxical tales. Alfred A. Knopf,
New York.
Sadato N, Pascual-Leone A, Grafman J, Ibanez V, Deiber MP, Dold G, Hallett M (1996)
Activation of the primary visual cortex by Braille reading in blind subjects. Nature
380:526–528.Sackett G, Korner A (1993) Organization of sleep-waking states in con-
joined twin neonates. Sleep 16:414–427.
Sagan C (1977) The dragons of Eden: Speculations on the evolution of human intelligence.
Random House, New York.
Salek-Haddadi A, Merschhemke M, Lemieux L, Fish DR (2002) Simultaneous EEG-
correlated ictal fMRI. Neuroimage 16:32–40.
Salenius S, Salmelin R, Neuper C, Pfurtscheller G, Hari R (1996) Human cortical 40 Hz
rhythm is closely related to EMG rhythmicity. Neurosci Lett 213:75–78.

418
References
Salinas E, Abbott LF (1995) Transfer of coded information from sensory to motor net-
works. J Neurosci 15:6461–6474.
Salinas E, Sejnowski TJ (2001) Correlated neuronal activity and the ﬂow of neural infor-
mation. Nat Rev Neurosci 2:539–550.
Salthe S (1985) Evolving hierarchical systems: Their structure and representation. Colum-
bia University Press, New York.
Samsonovich A, McNaughton BL (1997) Path integration and cognitive mapping in a con-
tinuous attractor neural network model. J Neurosci 17:5900–5920.
Sanchez-Vives MV, McCormick DA (2000) Cellular and network mechanisms of rhythmic
recurrent activity in neocortex. Nat Neurosci 3:1027–1034.
Sanes JN, Donoghue JP (1993) Oscillations in local ﬁeld potentials of the primate motor
cortex during voluntary movement. Proc Natl Acad Sci USA 90:4470–4474.
Sapolsky R (1998) Why zebras don’t get ulcers: An updated guide to stress, stress-related
disease and coping. W.H. Freeman and Company, New York.
Sara SJ (2000) Retrieval and reconsolidation: Toward a neurobiology of remembering.
Learn Mem. 7:73–84.
Sarnthein J, Petsche H, Rappelsberger P, Shaw GL, von Stein A (1998) Synchronization
between prefrontal and posterior association cortex during human working memory.
Proc Natl Acad Sci USA 95:7092–7096.
Sawamura H, Shima K, Tanji J (2002) Numerical representation of the quantity of visual
items in the primate parietal cortex of the monkey. Nature 415:918–922.
Sayers BM, Beagley HA, Henshall WR (1974) The mechanism of auditory evoked EEG
responses. Nature 247:481–483.
Scannell JW, Blakemore C, Young MP (1995) Analysis of connectivity in the cat cerebral
cortex. J Neurosci 15:1463–1483.
Schaffer K (1892) Beitrag zure Histologie der Ammonshornformation. Arch Mikrosk Anat
39:611–632.
Schahmann JD, Pandya DN (2006) Fiber pathways of the brain. Oxford University Press,
Oxford.
Scheibel ME, Scheibel AB (1966) The organization of the nucleus reticularis thalami, a
Golgi study. Brain Res 1:43–62.
Schmitz D, Schuchmann S, Fisahn A, Draguhn A, Buhl EH, Petrasch-Parwez RE, Dermi-
etzel R, Heinemann U, Traub RD (2001) Axo-axonal coupling: A novel mechanism for
ultrafast neuronal communication. Neuron 31:831–840.
Schmolensky MT, Wand Y, Hanes DP, Thomson KG, Leutgeb S, Schall JD, Leventhal
AG (1998) Signal timing across the macaque visual system. J Neurophysiol 79:
3272–3278.
Schnitzler A, Gross J (2005) Normal and pathological oscillatory communication in the
brain. Nat Rev Neurosci 6:285–296.
Schroeder CE, Mehta AD, Givre SJ (1998) A spatiotemporal proﬁle of visual system acti-
vation revealed by current source density analysis in the awake macaque. Cereb Cortex
8:575–792.
Schütz A, Braitenberg V (2002) The human cortical white matter: Quantitative aspects of
cortico-cortical long-range connectivity. In: Cortical areas: Unity and diversity (Schütz
A, Miller R, eds). Taylor and Francis, London.

References
419
Schwartz DA, Howe CQ, Purves D (2003) The statistical structure of human speech
sounds predicts musical universals. J Neurosci 23:7160–7168.
Scoville WB, Milner B (1957) Loss of recent memory after bilateral hippocampal lesions.
J Neuron Neurosurg Psychiatry 20:11–21.
Searle J (1992) The rediscovery of the mind. MIT Press, Cambridge.
Sederberg PB, Kahana MJ, Howard MW, Donner EJ, Madsen JR (2003) Theta and gamma
oscillations during encoding predict subsequent recall. J Neurosci 23:10809–10814.
Segal M, Disterhoft JF, Olds J (1972) Hippocampal unit activity during classical aversive
and appetitive conditioning. Science 175:792–794.
Segev I, Rall W (1998) Excitable dendrites and spines: Earlier theoretical insights eluci-
date recent direct observations. Trends Neurosci 21:453–460.
Seidenbecher T, Laxmi TR, Stork O, Pape HC (2003) Amygdalar and hippocampal theta
rhythm synchronization during fear memory retrieval. Science 301:846–850.
Sejnowski TJ (1977) Statistical constraints on synaptic plasticity. J Theor Biol 69:385–389.
Semba K, Komisaruk BR (1978) Phase of the theta wave in relation to different limb
movements in awake rats. Electroencephalogr Clin Neurophysiol 44:61–71.
Semba K, Komisaruk BR (1980) Synchrony among rhythmical facial tremor, neocortical
“alpha” waves, and thalamic non-sensory neuronal bursts in intact awake rats. Brain Res
195:281–298.
Shadlen MN, Britten KH, Newsome WT, Movshon JA (1996) A computational analysis of
the relationship between neuronal and behavioral responses to visual motion. J Neurosci
16:1486–1510.
Shadlen MN, Newsome WT (1994) Noise, neural codes and cortical organization. Curr
Opin Neurobiol 4:569–579.
Shadlen MN, Newsome WT (1995) Is there a signal in the noise? Curr Opin Neurobiol
5:248–250.
Shadlen MN, Newsome WT (1998) The variable discharge of cortical neurons: Implica-
tions for connectivity, computation, and information coding. J Neurosci 18:3870–3896.
Shadlen MN, Movshon AJ (1999) Synchrony unbound: A critical evaluation of the tempo-
ral binding hypothesis. Neuron 24:67–77.
Shallice T (1964) The detection of change and the perceptual moment hypothesis. Br J Stat
Psychol 17:113–135.
Salthe S (1985) Evolving hierarchical systems: Their structure and representation. Colum-
bia University Press, New York.
Shannon CE (1948) A mathematical theory of communication. Bell Syst Tech J 27:
379–423, 623–656.
Shapiro DH (1980) Mediation: Self-regulation strategy and altered state of consciousness.
Aldine, New York.
Shariff GA (1953) Cell counts in the primate cerebral cortex. J Comp Neurol 98:381–400.
Sharma J, Dragoi V, Tenenbaum JB, Miller EK, Sur M (2003) V1 neurons signal acquisi-
tion of an internal representation of stimulus location. Science 300:1758–1763.
Sharp PE, Green C (1994) Spatial correlates of ﬁring patterns of single cells in the subicu-
lum of freely moving rat. J Neurosci 14:2339–2356.
Sheliga BM, Riggio L, Rizzolatti G (1994) Orienting of attention and eye movements. Exp
Brain Res 98:507–522.

420
References
Sherman SM (2001) Tonic and burst ﬁring: Dual modes of thalamocortical relay. Trends
Neurosci 24:122–126.
Sherman SM, Guillery RW (2001) Exploring the thalamus. Academic Press, San Diego.
Sherman SM, Guillery RW (2002) The role of the thalamus in the ﬂow of information to
the cortex. Philos Trans R Soc Lond B Biol Sci 357:1695–1708.
Shinomiya S, Nagata K, Takahashi K, Masumura T (1999) Development of sleep spindles
in young children and adolescents. Clin Electroencephalogr 30:39–43.
Shipp S (2003) The functional logic of cortico-pulvinar connections. Philos Trans R Soc
Lond B Biol Sci 358:1605–1624.
Shu Y, Hasenstaub A, Badoual M, Bal T, McCormick DA (2003a) Barrages of synaptic ac-
tivity control the gain and sensitivity of cortical neurons. J Neurosci 23:10388–10401.
Shu Y, Hasenstaub A, McCormick D (2003b) Turning on, off recurrent balanced cortical
activity. Nature 423:288–293.
Siapas AG, Lubenov EV, Wilson MA (2005) Prefrontal phase locking to hippocampal theta
oscillations. Neuron 46:141–151.
Siapas AG, Wilson MA (1988) Coordinated interactions between hippocampal ripples and
cortical spindles during slow-wave sleep. Neuron 21:1123–1128.
Siegel JM (2001) The REM sleep-memory consolidation hypothesis. Science 294
(5544):1058–1063.
Siegel JM (2005) Clues to the functions of mammalian sleep. Nature 437:1264–1271.
Sík A, Penttonen M, Ylinen A, Buzsáki G (1995) Hippocampal CA1 interneurons: An in
vivo intracellular labeling study. J Neurosci 15:6651–6665.
Sík A, Ylinen A, Penttonen M, Buzsáki G (1994) Inhibitory CA1-CA3-hilar region feed-
back in the hippocampus. Science 265:1722–1724.
Silberberg G, Wu C, Markram H (2004) Synaptic dynamics control the timing of neuronal
excitation in the activated neocortical microcircuit. J Physiol (Lond) 556:19–27.
Simon HA (1969) The sciences of the artiﬁcial. MIT Press, Cambridge, MA (2nd edition,
1981).
Singer W (1993) Synchronization of cortical activity and its putative role in information
processing and learning. Annu Rev Physiol 55:349–374.
Singer W (1999) Neuronal synchrony: A versatile code for the deﬁnitions of relations?
Neuron 24:49–65.
Singer W (2001) Consciousness and the binding problem. Ann NY Acad Sci 929:123–146.
Singer W, Gray CM (1995) Visual feature integration and the temporal correlation hypoth-
esis. Annu Rev Neurosci 8:555–586.
Sinkkonen J, Tiitinen H, Naatanen R (1995) Gabor ﬁlters: An informative way for
analysing event-related brain activity. J Neurosci Methods 56:99–104.
Sinnamon HM (2005) Hippocampal theta activity and behavioral sequences in a reward-
directed approach locomotor task. Hippocampus 15:518–534.
Sirota A, Csicsvari J, Buhl D, Buzsáki G (2003) Communication between neocortex and
hippocampus during sleep in rodents. Proc Natl Acad Sci USA 100:2065–2069.
Sirota AM, Montgomery SM, Zugaro MB, Monconduit L, Buhl DL, Buzsaki G (2005)
Neocortical-hippocampal interactions through oscillations. Society for Neuroscience
Abstract (Washington, DC) No. 275.7.

References
421
Skaggs WE, McNaughton BL (1996) Replay of neuronal ﬁring sequences in rat hip-
pocampus during sleep following spatial experience. Science 271:1870–1873.
Skaggs WE, McNaughton BL, Wilson MA, Barnes CA (1996) Theta phase precession in
hippocampal neuronal populations and the compression of temporal sequences. Hip-
pocampus 6:149–172.
Skede KKR, Westgaard RH (1971) The transverse hippocampal slice: A well-deﬁned cor-
tical structure maintained in vitro. Brain Res 35:589–593.
Sloviter RS, Dichter MA, Rachinsky TL, Dean E, Goodman JH, Sollas AL, Martin DL
(1996) Basal expression and induction of glutamate decarboxylase and GABA in excita-
tory granule cells of the rat and monkey hippocampal dentate gyrus. J Comp Neurol
37:593–618.
Sloviter RS, Valiquette G, Abrams GM, Ronk EC, Sollas AL, Paul LA, Neubort S (1989)
Selective loss of hippocampal granule cells in the mature rat brain after adrenalectomy.
Science 243:535–538.
Smith C (1995) Sleep states and memory processes. Behav Brain Res 69:137–145.
Softky WR, Koch C (1993) The highly irregular ﬁring of cortical cells is inconsistent with
temporal integration of random EPSPs. J Neurosci 13:334–350.
Soltesz I (2006) Diversity in the neuronal machine. Oxford University Press, New York.
Soltesz I, Lightowler S, Leresche N, Jassik-Gerschenfeld D, Pollard CE, Crunelli V (1991)
Two inward currents and the transformation of low-frequency oscillations of rat and cat
thalamocortical cells. J Physiol (Lond) 441:175–179.
Somogyi P, Klausberger T (2005) Deﬁned types of cortical interneurone structure space
and spike timing in the hippocampus. J Physiol (Lond) 562:9–26.
Somogyi P, Nunzi MG, Gorio A, Smith AD (1983) A new type of speciﬁc interneuron in
the monkey hippocampus forming synapses exclusively with the axon initial segments
of pyramidal cells. Brain Res 259:137–142.
Somogyi P, Tamas G, Lujan R, Buhl EH (1998) Salient features of synaptic organisation in
the cerebral cortex. Brain Res Rev 26:113–135.
Spence KW (1956) Behavior theory and conditioning. Yale University Press, New Haven, CT.
Spencer SS (1981) Depth electroencephalography in selection of refractory epilepsy for
surgery. Ann Neurol 9:207–214.
Spencer WA, Brookhart JM (1961) Electrical patterns of augmenting and recruiting waves
in depth of sensorimotor cortex of cat. J Neurophysiol 24:26–49.
Sperry RW (1950) Neural basis of the spontaneous optokinetic response produced by vi-
sual inversion. J Comp Physiol Psychol 43:482–489.
Sporns O, Chialvo DR, Kaiser M, Hilgetag CC (2004) Organization, development and
function of complex brain networks. Trends Cogn Sci 8:418–425.
Sporns O, Edelman GM (1993) Solving Bernstein’s problem: A proposal for the develop-
ment of coordinated movement by selection. Child Dev 64:960–981.
Sporns O, Tononi G, Edelman GM (2000a) Connectivity and complexity: The relationship
between neuroanatomy and brain dynamics. Neural Networks 13:909–922.
Sporns O, Tononi G, Edelman GM (2000b) Theoretical neuroanatomy: Relating anatomi-
cal and functional connectivity in graphs and cortical connection matrices. Cereb Cor-
tex 10:127–141.

422
References
Sporns O, Tononi G, Edelman GM (2002) Theoretical neuroanatomy and the connectivity
of the cerebral cortex. Behav Brain Res 135:69–74.
Sporns O, Zwi JD (2004) The small world of the cerebral cortex. Neuroinformatics
2:145–162.
Squire LR (1992) Memory and the hippocampus: A synthesis from ﬁndings with rats,
monkeys, and humans. Psychol Rev 99:195–231.
Squire LR, Zola SM (1998) Episodic memory, semantic memory and amnesia. Hippocam-
pus 8:205–211.
Srinivasan R (1999) Spatial structure of the human alpha rhythm: Global correlation in
adults and local correlation in children. Clin Neurophysiol 110:1351–1362.
Srinivasan R, Russell DP, Edelman GM, Tononi G (1999) Increased synchronization of
neuromagnetic responses during conscious perception. J Neurosci 19:5435–5448.
Staddon JER, Higa JJ (1999) Time and memory: Towards a pacemaker-free theory of in-
terval timing. J Exp Anal Behav 71:215–251.
Stam CJ, de Bruin EA (2004) Scale-free dynamics of global functional connectivity in the
human brain. Hum Brain Map 22:97–109.
Stam CJ, Pijn JPM, Suffczynski P, Lopes da Silva FH (1999) Dynamics of the human
rhythm: Evidence for non-linearity? Clin Neurophysiol 110:1801–1813.
Stanley S (1985) Evolving hierarchical systems. Columbia University Press, New York.
Stanton PK, Sejnowski TJ (1989) Associative long-term depression in the hippocampus in-
duced by hebbian covariance. Nature 339:215–218.
Stein PSG, Grillner S, Selverston AI, Stuart DG (eds) (1997) Neurons, networks, and mo-
tor behavior. MIT Press, Cambridge, MA.
Steriade M (2001a) Impact of network activities on neuronal properties in corticothala-
mamic system. J Neurophysiol 86:1–39.
Steriade M (2001b) The intact and sliced brain. MIT Press, Cambridge, MA.
Steriade M (2001c) To burst, or rather, not to burst. Nat Neurosci 4:671.
Steriade M (2003) Neuronal substrates of sleep and epilepsy. Cambridge University Press,
Cambridge.
Steriade M (2004) Neocortical cell classes are ﬂexible entities. Nat Rev Neurosci 5:
121–134.
Steriade M, Amzica F (1996) Inracortical and corticothalamic coherency of fast sponta-
neous oscillations. Proc Natl Acad Sci USA 93:2533–2538.
Steriade M, Amzica F, Nuñez A (1993a) Cholinergic and noradrenergic modulation of slow
(approximately 0.3Hz) oscillation in neocortical cells. J Neurophysiol 70:1385–1400.
Steriade M, Buzsáki G (1990) Parallel activation of thalamic and cortical neurons by
brainstem and basal forebrain cholinergic systems. In: Brain cholinergic systems (Steri-
ade M, Biesold D, eds). Oxford University Press, Oxford, 3–64.
Steriade M, Contreras D, Curro Dossi R, Nuñez A (1993b) The slow (< 1 Hz) oscillation in
reticular thalamic and thalamocortical neurons: Scenario of sleep rhythm generation in
interacting thalamic and neocortical networks. J Neurosci 13:3266–3283.
Steriade M, Curró Dossi R, Paré D, Oakson G (1991). Fast oscillations (20–40 Hz) in thal-
amocortical systems and their potentiation by mesopontine cholinergic nuclei in the cat.
Proc Natl Acad Sci USA 88:4396–4400.

References
423
Steriade M, Deschenes M (1984) The thalamus as a neuronal oscillator. Brain Res Rev
8:1–63.
Steriade M, Deschenes M, Domich L, Mulle C (1985) Abolition of spindle oscillations in
thalamic neurons disconnected from nucleus reticularis thalami. J Neurophysiol
54:1473–1497.
Steriade M, Gloor P, Llinás R, Lopes da Silva FH, Mesulam MM (1990a) Basic mecha-
nisms of cerebral rhythmic activity. Electroencephalogr Clin Neurophysiol 76:481–508.
Steriade M, Jones EG, Llinás R (1990b) Thalamic oscillations and signaling. Wiley, New
York.
Steriade M, Llinás R (1988) The functional states of the thalamus and the associated neu-
ronal interplay. J Physiol (Lond) Rev 68:649–742.
Steriade M, McCormick DA, Sejnowski TJ (1993c) Thalamocortical oscillations in the
sleeping and aroused brain. Science 262:679–685.
Steriade M, Nuñez A, Amzica F (1993d) Intracellular analysis of relations between the
slow (< 1Hz) neocortical oscillation and other sleep rhythms in the electroencephalo-
gram. J Neurosci 13:3266–3283.
Steriade M, Nuñez A, Amzica F (1993e) A novel slow (< 1 Hz) oscillation of neocortical
neurons in vivo: Depolarizing and hyperpolarizing components. J Neurosci 13:
3252–3265.
Steriade M, Timofeev I (2003) Neuronal plasticity in thalamocortical networks during
sleep and waking oscillations. Neuron 37:563–476.
Sternberg S (1966) High speed scanning in human memory. Science 153:652–654.
Stevens CF, Zador AM (1998) Input synchrony and the irregular ﬁring of cortical neurons.
Nat Neurosci 1:210–217.
Stevens SS (1975) Psychophysics: Introduction to its perceptual, neural, and social
prospects. Wiley, New York.
Stewart M, Fox SE (1990) Do septal neurons pace the hippocampal theta rhythm? Trends
Neurosci 13:163–168.
Stickgold R, Hobson JA, Fosse R, Fosse M (2001) Sleep, learning, and dreams: Off-line
memory reprocessing. Science 294:1052–1057.
Stopfer M, Bhagavan S, Smith B and Laurent G (1997) Impaired odor discrimination on
desynchronization of odor-encoding neural assemblies. Nature 390:70–74.
Stopfer M and Laurent (1999) G Short-term memory in olfactory network dynamics. Na-
ture 402:664–668.
Storm JF (1990) Potassium currents in hippocampal pyramidal cells. Prog Brain Res
83:161–187.
Strathern P (2000) Mendeleyev’s dream. The quest for the elements. Hamish-Hamilton,
London.
Strogatz SH (2003) Sync: The emerging science of spontaneous order. Hyperion Press,
New York.
Strogatz SH, Kronauer RE, Czeisler CA (1986) Circadian regulation dominates homeosta-
tic control of sleep length and prior wake length in humans. Sleep 9:353–364.
Suddendorf T, Corballis MC (1997) Mental time travel and the evolution of the human
mind. Genet Soc Gen Psychol Monogr 123:133–167.

424
References
Surwillo W (1961) The relationship of the alpha rhythm, reaction time and age. Nature
191:823–824.
Sutton S, Braren M, John ER, Zubin J (1965) Evoked potential correlates of stimulus un-
certainty. Science 150:1187–1188.
Suzuki WA, Amaral DG (2004) Functional neuroanatomy of the medial temporal lobe
memory system. Cortex 40:220–222.
Swadlow HA (2000) Information ﬂow along neocortical axons. In: Time and the brain
(Miller R, ed). Harwood Academic Publishers, Singapore, 131–155.
Swadlow HA (2002) Thalamocortical control of feed-forward inhibition in awake so-
matosensory “barrel” cortex. Philos Trans R Soc Lond B Biol Sci 357:1717–1727.
Swadlow HA (2003) Fast-spike interneurons and feedforward inhibition in awake sensory
neocortex. Cereb Cortex 13:25–32.
Swadlow HA, Gusev AG (2001) The impact of “bursting” thalamic impulses at a neocorti-
cal synapse. Nat Neurosci 4:402–408.
Swanson LW (2000) Cerebral hemisphere regulation of motivated behavior. Brain Res
886:113–164.
Swanson LW, Cowan WM (1977) An autoradiographic study of the organization of the
efferent connections of the hippocampal formation in the rat. J Comp Neurol 172:49–
84.
Swerdlow NR, Braff DL, Geyer MA (1999) Cross-species studies of sensorimotor gating
of the startle reﬂex. Ann NY Acad Sci 877:202–216.
Swindale NV (1982) A model for the formation of orientation columns. Proc R Soc Lond
B 215:211–230.
Szabadics J, Varga C, Molnár G, Oláh S, Barzó P, Tamás G (2006) Excitatory effect of
GABAergic axo-axonic cells in cortical microcircuits. Science 311:233–235.
Szentágothai J (1975) The “module-concept” in cerebral cortex architecture. Brain Res
95:475–496.
Szentágothai J (1978) The neuron networkof the cerebral cortex: A functional interpreta-
tion. Proc R Soc Lond B 201:219–248.
Szentágothai J (1983) The modular architectonic principle of neural centers. Rev Physiol
Biochem Pharmacol 98:11–61.
Szentágothai J, Arbib MA (1974) Conceptual models of neural organization. Neurosci Res
Prog Bull 12:305–510.
Szentágothai J, Érdi P (1989) Self-organization in the nervous system. J Soc Biol Struct
12:367–384.
Szent-Györgyi A (1951) Chemistry of muscular contraction. Academic Press, New York.
Szilárd L (1929) Über die Entropieverminderung in einem thermodynamischen System bei
Eingriffen intelligenter Wieser (On the decrease of entropy in a thermodynamic system
by the intervention of intelligent beings). Z Physík 53:840–856. Reprint and trans:
Maxwell’s demon. Entropy, information, computing (Leff HS, Rex AF, eds). Adam
Hilger, Bristol, 1990.
Szirmai I, Kamondi A (2006) Consciousness and altered consciousness. Clin Neurosci
59:17–28.
Talairach J, Tournoux P (1998) Co-planar stereotactic atlas of the human brain. Thieme,
Stuttgart.

References
425
Tallal P (2004) Improving language and literacy is a matter of time. Nat Rev Neurosci
5:721–728.
Tallon-Baudry C, Bertrand O (1999) Oscillatory gamma activity in humans and its role in
object representation. Trend Cogn Sci 3:151–162.
Tallon-Baudry C, Bertrand O, Henaff MA, Isnard J, Fischer C (2005) Attention modulates
gamma-band oscillations in the human lateral occipital cortex and fusiform gyrus.
Cereb Cortex 15:654–662.
Tallon-Baudry C, Bertrand O, Wienbruch C, Ross B, Pantev C (1997) Combined EEG and
MEG recordings of visual 40 Hz responses to illusory triangles in human. Neuroreport
8:1103–1107.
Tamamaki N, Abe K, Nojyo Y (1998) Three-dimensional analysis of the whole axonal ar-
bors originating from single CA2 pyramidal neurons in the rat hippocampus with the aid
of a computer graphic technique. Brain Res 452:255–272.
Tamamaki N, Nojyo Y (1993) Projection of the entorhinal layer II neurons in the rat as
revealed by intracellular pressure-injection of neurobiotin. Hippocampus 3:471–480.
Tamas G, Buhl EH, Lõrincz A, Somogyi P (2000) Proximally targeted GABAergic
synapses and gap junctions synchronize cortical interneurons. Nat Neurosci 3:366–371.
Tanaka K (1996) Inferotemporal cortex and object vision. Annu Rev Neurosci 19:
109–139.
Tass PA (1999) Phase resetting in medicine and biology. Springer, Berlin.
Taube JS, Bassett JP (2003) Persistent neural activity in head direction cells. Cereb Cortex
13:1162–1172.
Terrazas A, Krause M, Lipa P, Gothard KM, Barnes CA, McNaughton BL (2005) Self-
motion and the hippocampal spatial metric. J Neurosci 25:8085–8096.
Terry RD, Masliah E, Salmon DP, Butters N, DeTeresa R, Hill R, Hansen LA, Katzman R
(1991) Physical basis of cognitive alterations in Alzheimer’s disease: Synapse loss is the
major correlate of cognitive impairment. Ann Neurol 30:572–580.
Tesche CD, Karhu J (2000) Theta oscillations index human hippocampal activation during
a working memory task. Proc Natl Acad Sci USA 97:919–924.
Teyler TJ, DiScenna P (1985) The role of hippocampus in memory: A hypothesis. Neu-
rosci Biobehav Rev 9:377–389.
Thompson D (1917) On growth and form. Cambridge University Press, Cambridge.
Thompson E, Varela FJ (2001) Radical embodiment: Neural dynamics and consciousness.
Trends Cogn Sci 5:418–425.
Thompson RF (1976) The search for the engram. Am Psychol 31:209–227.
Thompson RF (2005) In search of memory traces. Annu Rev Psychol 56:1–23.
Thomson AM (2000a) Facilitation, augmentation and potentiation at central synapses.
Trends Neurosci 23:305–312.
Thomson AM (2000b) Molecular frequency ﬁlters at central synapses. Prog Neurobiol
62:159–196.
Thomson AM, Bannister AP (2003) Interlaminar connections in the neocortex. Cereb Cor-
tex 13:5–14.
Thorpe S, Fize D, Marlot C (1996) Speed of processing in the human visual system. Na-
ture 381:520–522.
Tiitinen H, Sinkkonen J, Reinikainen K, Alho K, Lavikainen J, Naatanen R (1993) Selec-

426
References
tive attention enhances the auditory 40-Hz transient response in humans. Nature
364:59–60.
Timofeev I, Grenier F, Bazhenov M, Sejnowski TJ, Steriade M (2000) Origin of slow cor-
tical oscillations in deafferented cortical slabs. Cereb Cortex 10:1185–1199.
Timofeev I, Grenier F, Bazhenov M, Houweling AR, Sejnowski TJ, Steriade M (2002)
Short- and medium-term plasticity associated with augmenting responses in cortical
slabs and spindles in intact cortex of cats in vivo. J Physiol (Lond) 542:583–598.
Tomasch J (1954) Size, distribution, and number of ﬁbers in the human corpus callosum.
Anat Record 119:119–135.
Tomioka R, Okamoto K, Furuta T, Fujiyama F, Iwasato T, Yanagawa Y, Obata K, Kaneko
T, Tamamaki N (2005) Demonstration of long-range GABAergic connections distrib-
uted throughout the mouse neocortex. Eur J Neurosci 21:1587–1600.
Tononi G (2004) An information integration theory of consciousness. BMC Neurosci
5:42–58.
Tononi G, Cirelli C (2006) Sleep function and synaptic homeostasis. Sleep Med Rev
10:49–62.
Tononi G, Sporns O, Edelman GM (1994) A measure for brain complexity: Relating func-
tional segregation and integration in the nervous system. Proc Natl Acad Sci USA
91:5033–5037.
Tononi G, Sporns O, Edelman GM (1996) A complexity measure for selective matching of
signals by the brain. Proc Natl Acad Sci USA 93:3422–3427.
Tononi G, Srinivasan R, Russell DP, Edelman GM (1998) Investigating neuronal correlates
of conscious perception by frequency-tagged neuromagnetic responses. Proc Natl Acad
Sci USA 95:3198–3203.
Toth T, Crunelli V (1992) Computer simulation of the pacemaker oscillations of thalamo-
cortical cells. Neuroreport 3:65–68.
Touretzky DS, Redish AD (1996) Theory of rodent navigation based on interacting repre-
sentations of space. Hippocampus 6:247–270.
Traub RD, Bibbig A (2000) A model of high-frequency ripples in the hippocampus based
on synaptic coupling plus axon-axon gap junctions between pyramidal neurons. J Neu-
rosci 20:2086–2093.
Traub RD, Bibbig A, LeBeau FE, Buhl EH, Whittington MA (2004) Cellular mechanisms
of neuronal population oscillations in the hippocampus in vitro. Annu Rev Neurosci
27:247–278.
Traub RD, Contreras D, Cunningham MO, Murray H, LeBeau FE, Roopun A, Bibbig A,
Wilent WB, Higley MJ, Whittington MA (2005) Single-column thalamocortical net-
work model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts.
J Neurophysiol 93:2194–2232.
Traub RD, Draguhn A, Whittington MA, Baldeweg T, Bibbig A, Buhl EH, Schmitz D
(2002) Axonal gap junctions between principal neurons: A novel source of network os-
cillations, and perhaps epileptogenesis. Rev Neurosci 13:1–30.
Traub RD, Jefferys JG, Miles R, Whittington MA, Tóth K (1994) A branching dendritic
model of a rodent CA3 pyramidal neurone. J Physiol (Lond) 481:79–95.
Traub RD, Jefferys JGR, Whittington MA (1999) Fast oscillations in cortical circuits. MIT
Press, Cambridge, MA.

References
427
Traub RD, Kopell N, Bibbig A, Buhl EH, LeBeau FEN, Whittington MA (2001) Gap junc-
tions between interneuron dendrites can enhance long-range synchrony of gamma oscil-
lations. J Neurosci 21:9478–9486.
Traub RD, Miles R (1991) Neuronal networks of the hippocampus. Cambridge University
Press, New York.
Traub RD, Pais I, Bibbig A, LeBeau FEN, Buhl EH, Hormuzdi SG, Monyer H, Whitting-
ton MA (2003) Contrasting roles of axonal (pyramidal cell) and dendritic (interneuron)
electrical coupling in the generation of gamma oscillations in the hippocampus in vitro.
Proc Natl Acad Sci USA 100:1370–1374.
Traub RD, Whittington MA, Stanford IM, Jefferys JG (1996) A mechanism for generation
of long-range synchronous fast oscillations in the cortex. Nature 383:621–624.
Traub RD, Wong RK (1982) Cellular mechanism of neuronal synchronization in epilepsy.
Science 216:745–747.
Treves A, Rolls ET (1994) Computational analysis of the role of the hippocampus in mem-
ory. Hippocampus 4:374–391.
Tsodyks M, Kenet T, Grinvald A, Arieli A (1999) Linking spontaneous activity of single
cortical neurons and the underlying functional architecture. Science 286:1943–1946.
Tsodyks MV, Skaggs WE, Sejnowski TJ, McNaughton BL (1996) Population dynamics
and theta rhythm phase precession of hippocampal place cell ﬁring: A spiking neuron
model. Hippocampus 6:271–280.
Tsubokawa H, Ross WN (1996) IPSPs modulate spike backpropagation and associated
[Ca2+]i changes in the dendrites of hippocampal CA1 pyramidal neurons. J Neurophys-
iol 76:2896–2906.
Tsuji Y, Kobayashi T (1988) Short and long ultradian EEG components in daytime arousal.
Electroencephalogr Clin Neurophysiol 70:110–117.
Tulving E (1972) Episodic and semantic memory. In Organisation of memory (Tulving E,
Donaldson W, eds). Academic Press, New York, 381–403.
Tulving E (2002) Episodic memory: From mind to brain. Annu Rev Psychol 53:1–25.
Turing A (1936) On computable numbers, with an application to the Entscheidungsprob-
lem. Proc Lond Math Soc Ser 2 42:230–265.
Ueda K, Nittono H, Hayashi M, Hori T (2001) Spatiotemporal changes of slow wave ac-
tivities before and after 14 Hz/12 Hz sleep spindles during stage 2 sleep. Psychiatry Clin
Neurosci 55:183–184.
Ungerleider LG, Mishkin M (1982) Two cortical visual systems. In: Analysis of visual
behavior (Ingle DJ, Goodale MA, Mansﬁeld RJW, eds). MIT Press, Cambridge,
549–586.
Usher M, Cohen JD, Servan-Schreiber D, Rajkowski J, Aston-Jones G (1999) The role of
locus coeruleus in the regulation of cognitive performance. Science 283:549–554.
Usher M, Stemmler M, Koch C (1994) Network ampliﬁcation of local ﬂuctuation causes
high spike rate variability, fractal patterns and oscillatory ﬁeld potentials. Neural Com-
put 6:795–836.
Usrey WM, Reid RC (1999) Synchronous activity in the visual system. Annu Rev Physiol
61:435–656.
Uusitalo MA, Williamson SJ, Seppa MT (1996) Dynamical organisation of the human
visual system revealed by lifetimes of activation traces. Neurosci Lett 213:149–152.

428
References
Vaadia E, Haalman I, Abeles M, Bergman H, Prut Y, Slovin H, Aertsen A (1995) Dynam-
ics of neuronal interactions in monkey cortex in relation to behavioural events. Nature
373:515–518.
van der Pol B, van der Mark J (1928) The heartbeat considered as a relaxation oscillation,
and an electrical model of the heart. Balth Phil Mag Suppl. 6:763–775.
Vanderwolf CH (1969) Hippocampal electrical activity and voluntary movement in the rat.
Electroencephalogr Clin Neurophysiol 26:407–418.
Vanderwolf CH (1988) Cerebral activity and behavior: Control by central cholinergic and
serotonergic systems. Int Rev Neurobiol 30:225–340.
Vanderwolf CH (2003) An odyssey through the brain, behavior and the mind. Kluwer Aca-
demic Publishers, Boston.
Van Essen D (1997) A tension-based theory of morphogenesis and compact wiring in the
central nervous system. Nature 385:313–318.
Van Essen DC, Zeki SM (1978) The topographic organization of rhesus monkey prestriate
cortex. J Physiol (Lond) 277:193–226.
Vanhatalo S, Palva JM, Holmes MD, Miller JW, Voipio J, Kaila K (2004) Infraslow oscil-
lations modulate excitability and interictal epileptic activity in the human cortex during
sleep. Proc Natl Acad Sci USA 101:5053–5057.
VanRullen R, Koch C (2003) Is perception discrete or continuous? Trends Cogn Sci
7:207–213.
van Vreeswijk C, Sompolinsky H (1996) Chaos in neuronal networks with balanced exci-
tatory and inhibitory activity. Science 274:1724–1726.
Varela F, Lachaux J-P, Rodriguez E, Martinerie J (2001) The brainweb: Phase synchro-
nization and large-scale integration. Nat Rev Neurosci 2:229–239.
Varela FJ, Thompson E, Rosch E (1991) The embodied mind. MIT Press, Cambridge,
MA.
Vargha-Khadem F, Gadian DG, Watkins KE, Connelly A, Van Paeschen W, Mishkin M
(1997) Differential effects of early hippocampal pathology on episodic and semantic
memories. Science 277:376–380.
Vaughan HG Jr, Arezzo JC (1988) The neural basis of event-related potentials. In: Human
event-related potentials (Picton TW, ed), vol 3. Elsevier Science Publishers, New York,
45–94.
Vergara C, Latorre R, Marrion NV, Adelman JP (1998) Calcium-activated potassium chan-
nels. Curr Opin Neurobiol 8:321–319.
Vertes RP (2004) Memory consolidation in sleep; Dream or reality? Neuron 44:
135–148.
Vertes RP, Eastman KE (2000) The case against memory consolidation in REM sleep. Be-
hav Brain Sci 23:867–876.
Vertes RP, Kocsis B (1997) Brainstem-diencephalo-septohippocampal systems controlling
the theta rhythm of the hippocampus. Neuroscience 81:893–926.
Vicsek T (1992) Fractal growth phenomena. 2nd ed. World Scientiﬁc, Singapore.
Victor JD (1999) Temporal aspects of neuronal coding in the retina and lateral geniculate.
Network Comput Neural Syst 10:1–66.
Vida I, Bartos M, Jonas P (2006) Shunting inhibition improves robustness of gamma oscil-
lations in hippocampal interneuron networks by homogenizing ﬁring rates. Neuron
49:107–117.

References
429
Vierordt K (1868) Der Zeitsinn nach Vershucher. Laupp, Tübingen.
Vihmam MM (1991) Ontogeny of phonetic gestures: Speech production. In: Modularity
and the motor theory of speech production (Mattingly IG, Studdert-Kennedy M, eds).
Erlbaum, Hillsdale, NJ, 69–104.
Vinogradova OS (1995) Expression, control, and probable functional signiﬁcance of the
neuronal theta-rhythm. Prog Neurobiol 45:523–583.
Vinogradova OS (2001) Hippocampus as comparator: Role of the two input and two output
systems of the hippocampus in selection and registration of information. Hippocampus
11:578–598.
Vogels TP, Rajan K, Abbott LF (2006) Neural network dynamics. Annu Rev Neurosci
28:357–376.
Von Bertalanffy L (1968) General systems theory. Braziller, New York.
von der Malsburg C (1985) Nervous structures with dynamical links. Ber Bunsenges Phys
Chem 89:703–710.
von der Malsburg C (1999) The what and why of binding: The modeler’s perspective. Neu-
ron 24:95–104.
Von Economo C (1929) Schlaftheorie. Ergeb Physiol 28:312–339.
von Holst E, Mittelstaedt H (1950) Das reafferenzprinzip: Wechselwirkungen zwischen
zentralnervensystem und peripherie. Naturwissenschaften 37:464–476.
Von Neuman J (1956) Proabilistic logic and the synthesis of reliable organisms from unre-
liable components. In: Automata studies (Shannon C, McCarthy J, eds). Princeton Uni-
versity Press, Princeton, NJ.
von Stein A, Rappelsberger P, Sarnthein J, Petsche H (1999) Synchronization between
temporal and parietal cortex during multimodal object processing in man. Cereb Cortex
9:137–150.
Voss RF, Clark J (1975) “1/f noise” in music and speech. Nature 258:317–318.
Voss RF, Clark J (1976) Flicker (1/f ) noise: Equilibrium temperature and resistance ﬂuc-
tuations. Phys Rev B 13:556.
Vyazovskiy V, Borbely AA, Tobler I (2000) Unilateral vibrissae stimulation during waking
induces interhemispheric EEG asymmetry during subsequent sleep in the rat. J Sleep
Res 9:367–371.
Wagner U, Gais S, Haider H, Verleger R, Born J (2004) Sleep inspires insight. Nature
427:352–355.
Walcott C, Green RP (1974) Orientation of homing pigeons altered by a change in the di-
rection of an applied magnetic ﬁeld. Science 184:180.
Wall PD (1987) The control of neural connections by three physiological mechanisms.
Prog Brain Res 71:239–247.
Wallenstein GV, Eichenbaum H, Hasselmo ME (1998) The hippocampus as an associator
of discontiguous events. Trends Neurosci 21:317–323.
Wallenstein GV, Hasselmo ME (1997) GABAergic modulation of hippocampal population
activity: Sequence learning, place ﬁeld development, and the phase precession effect.
J Neurophysiol 78:393–408.
Walter WG (1952) Form and function in the E.E.G. Arch Int Stud Neurol 1:409–417.
Wang C, Ulbert I, Schomer DL, Marinkovic K, Halgren E (2005) Responses of human an-
terior cingulated cortex microdomains to error detection, conﬂict monitoring, stimulus-
response mapping, familiarity and orienting. J Neurosci 25:604–613.

430
References
Wang X-J (1994) Multiple dynamical modes of thalamic relay neurons: rhythmic bursting
and intermittent phase-locking. Neuroscience 59:21–31.
Wang X-J (2003) Neural oscillators. In: Encyclopedia of cognitive science (Nadel L, ed).
McMillan, London, 272–280.
Wang XJ, Buzsáki G (1996) Gamma oscillation by synaptic inhibition in a hippocampal
interneuronal network model. J Neurosci 16:6402–6413.
Wang XJ, Rinzel J (1993) Spindle rhythmicity in the reticularis thalami nucleus: Synchro-
nization among mutually inhibitory neurons. Neuroscience 53:899–904.
Ward LM (2001) Dynamical cognitive science. MIT Press, Boston.
Watters PA (1998) Fractal structure in the electroencephalogram. Complex Int 5.
http://www.complexity.org.au/ci/v0105/watters/watters.html
Watts DJ (2003) Six degrees: The science of a connected age. W.W. Norton and Company,
New York.
Watts DJ, Strogatz SH (1998) Collective dynamics of “small-world” networks. Nature
393:440–442.
Webb WB (1978) The sleep of conjoined twins. Sleep 1:205–211.
Wehr M and Laurent G (1996) Odour encoding by temporal sequences of ﬁring in oscillat-
ing neural assemblies Nature 384: 162–166.
Wehr M, Zador AM (2003) Balanced inhibition underlies tuning and sharpens spike timing
in auditory cortex. Nature 426:442–446.
Weliky M, Fiser J, Hunt RH, Wagner DN (2003) Coding of natural scenes in primary vi-
sual cortex. Neuron 37:703–718.
Wenger MA, Bagchi BK (1961) Studies of autonomic functions in practitioners of yoga in
India. Behav Sci 6:312–323.
Westerga J, Gramsbergen A (1993) Development of locomotion in the rat: The signiﬁcance
of early movements. Early Hum Dev 34:89–100.
Wetter TC, Pollmacher T (1997) Restless legs and periodic leg movements in sleep syn-
dromes. J Neurol 244(suppl 1):S37–S45.
Whishaw IQ, Brooks BL (1999) Calibrating space: Exploration is important for allothetic
and idiothetic navigation. Hippocampus 9:659–667.
Whishaw IQ, Hines DJ, Wallace DG (2001) Dead reckoning (path integration) requires the
hippocampal formation: Evidence from spontaneous exploration and spatial learning
tasks in light (allothetic) and dark (idiothetic) tests. Behav Brain Res 127:49–69.
White JA, Chow CC, Ritt J, Soto-Treviño C, Kopell N (1998a) Synchronization and oscilla-
tory dynamics in heterogeneous, mutually inhibited neurons. J Comput Neurosci 5:5–16.
White JA, Klink R, Alonso A, Kay AR (1998b) Noise from voltage-gated ion channels
may inﬂuence neuronal dynamics in the entorhinal cortex. J Neurophysiol 80:262–269.
White JA, Rubinstein JT, Kay AR (2000) Channel noise in neurons. Trends Neurosci
23:131–137.
Whiting HTA (ed) (1984) Human motor actions: Bernstein reassessed. North-Holland,
Amsterdam.
Whittington MA, Traub RD (2003) Interneuron diversity series: Inhibitory interneurons
and network oscillations in vitro. Trends Neurosci 26:676–682.
Whittington MA, Traub RD, Jefferys JG (1995) Synchronized oscillations in interneuron
networks driven by metabotropic glutamate receptor activation. Nature 373:612–615.

References
431
Wiener N (1961) Cybernetics: Or, control and communication in the animal and the ma-
chine. MIT Press, Cambridge, MA.
Wiest MC, Nicolelis MA (2003) Behavioral detection of tactile stimuli during 7–12 Hz
cortical oscillations in awake rats. Nat Neurosci 6:913–914.
Wilent WB, Contreras D (2005) Dynamics of excitation and inhibition underlying stimu-
lus selectivity in rat somatosensory cortex. Nat Neurosci 10:1364–1370.
Williams RW, Herrup K (1988) The control of neuron number. Annu Rev Neurosci
11:423–453.
Wills TJ, Lever C, Cacucci F, Burgess N, O’Keefe J (2005) Attractor dynamics in the hip-
pocampal representation of the local environment. Science 308:873–876.
Wilson MA, McNaughton BL (1993) Dynamics of the hippocampal ensemble code for
space. Science 261:1055–1058.
Wilson MA, McNaughton BL (1994) Reactivation of hippocampal ensemble memories
during sleep. Science 265:676–682.
Winfree AT (1980) The geometry of biological time. Springer-Verlag, New York.
Winfree AT (1987) When time breaks down. The three-dimensional dynamics of electro-
chemical waves and cardiac arrhythmias. Princeton University Press, Princeton, NJ.
Winson J (1990) The meaning of dreams. Sci Am (July) 263:86–96.
Winson J (1993) The biology and function of rapid eye movement sleep. Curr Opin Neu-
robiol 3:243–248.
Wise KD, NajaﬁK (1991) Microfabrication techniques for integrated sensors and mi-
crosystems. Science 254:1335–1342.
Wolpaw JR, McFarland DJ (2004) Control of a two-dimensional movement signal by a non-
invasive brain-computer interface in humans. Proc Natl Acad Sci USA 101:17849–17854.
Wolpert DM, Ghahramani Z (2000) Computational principles of movement neuroscience.
Nat Neurosci 3(suppl):1212–1217.
Wood ER, Dudchenko PA, Robitsek RJ, Eichenbaum H (2000) Hippocampal neurons en-
code information about different types of memory episodes occurring in the same loca-
tion. Neuron 27:623–633.
Woolsey TA, Van der Loos H (1970) The structural organization of layer IV in the so-
matosensory region (SI) of mouse cerebral cortex. The description of a cortical ﬁeld
composed of discrete cytoarchitectonic units. Brain Res 17:205–242.
Wright AA, Rivera JJ, Hulse, SH, Shyan M, Neiworth JJ (2000) Music perception and oc-
tave generalization in rhesus monkeys. J Exp Psychol Gen 129:291–307.
Wright JJ, Liley DTJ (1996) Dynamics of the brain at global and microscopic scales.
Neural networks and the EEG. Behav Brain Sci 19:285–320.
Yamamoto C, McIlwain H (1966) Electrical activities in thin sections from the mam-
malian brain maintained in chemically-deﬁned medi in vitro. J Neurochem 13:1333–
1343.
Yen CT, Conley M, Hendry SH, Jones EG (1985) The morphology of physiologically iden-
tiﬁed GABAergic neurons in the somatic sensory part of the thalamic reticular nucleus
of the cat. J Neurosci 5:2245–2268.
Yerkes RM, Dodson JD (1908) The relation of strength of stimulus to rapidity of habit-
formation. J Comp Neurol Psychol 18:459–482.
Ylinen A, Bragin A, Nádasdy Z, Jandó G, Szabo I, Sík A, Buzsáki G (1995a) Sharp wave-

432
References
associated high-frequency oscillation (200 Hz) in the intact hippocampus: Network and
intracellular mechanisms. J Neurosci 15:30–46.
Ylinen A, Soltész I, Bragin A, Penttonen M, Sík A, Buzsáki G (1995b) Intracellular corre-
lates of hippocampal theta rhythm in identiﬁed pyramidal cells, granule cells, and basket
cells. Hippocampus 5:78–90.
Yoshimura Y, Dantzker JL, Callaway EM (2005) Excitatory cortical neurons form ﬁne-
scale functional networks. Nature 433:868–873.
Young MP (1992) Objective analysis of the topological organization of the primate corti-
cal visual system. Nature 358:152–155.
Young MP, Scannell JW (1996) Component-placement optimization in the brain. Trends
Neurosci 19:413–415.
Young MP, Scannell JW (2000) Brain structure-function relationships: Advances from
neuroinformatics. Philos Trans R Soc Biol Sci 355:3–6.
Yu Y, Romero R, Lee TS (2005) Preference of sensory neural coding for 1/f signals. Phys
Rev Lett 94:103–108.
Yuste R, Peinado A, Katz LC (1992) Neuronal domains in developing neocortex. Science
257:665–669.
Záborszky L, Alheid GF, Beinfeld MC, Eiden LE, Heimer L, Palkovits M (1985) Chole-
cystokinin innervation of the ventral striatum: A morphological and radioimmunologi-
cal study. Neuroscience 14:427–453.
Zeki SM (1978) Uniformity and diversity of structure and function in rhesus monkey pre-
striate cortex. J Physiol (Lond) 277:272–290.
Zeki S, Shipp S (1988) The functional logic of cortical connections. Nature 335:311–317.
Zhang K, Sejnowski TJ (2000) A universal scaling law between gray matter and white mat-
ter of cerebral cortex. Proc Natl Acad Sci USA 97:5621–5626.
Zipser D, Andersen RA (1988) A back-propagation programmed network that simulates
response properties of a subset of posterior parietal neurons. Nature 331:679–684.
Zugaro MB, Arleo A, Berthoz A, Wiener SI (2003) Rapid spatial reorientation and head
direction cells. J Neurosci 23:3478–3482.
Zugaro MB, Monconduit L, Buzsáki G (2005) Spike phase precession persists after tran-
sient intrahippocampal perturbation. Nat Neurosci 8:67–71.

Index
433
Abeles, M., 57
Acetylcholine,185, 309
Acsády, L., 178, 180
Action potential, 87
backpropagation, 87, 103
generation, 66, 87, 221
Adaptation, adaptive, 15
Adaptive resonance, 157
Adey, R., 337
Albright, T., 154
Allman, J., 59
Allocentric navigation, 297, 315
allocentric, explicit map, 308
Allocortex, 278, 280
Alpha oscillations, rhythm, 4, 112, 132,
189, 198, 199, 200, 214, 216, 237,
265, 266, 338, 370
Alpha power, 265
Alpha relaxation, 217
Alpha ringing, 226
Alzheimer’s disease, 236
Amazon.com, 38
Ambiguous ﬁgures, 229, 275
Ammon’s horn, 283
Ampliﬁcation, 157
Amplitude envelop correlation, 109
Amygdala, 41, 179, 282, 338, 210
Amygdalohippocampal complex, 338
Anderson, P., 97, 108, 309
Anesthesia, anesthetics, 194, 274, 343
Antennal lobe, 257
Anterior cingular cortex, 59, 339, 341
Anticipation, 131, 262
Anticorrelation of phase, 161
Antiphase discharge, 325
Anxiety, 217
Apgar score, 223
Aquinas, T., 12
Archipallium, 280
Architectural organization, 367
Arieli, A., 268
Aristotle, 11, 16, 206
Aristotelian logic, 21
Artiﬁcial intelligence, 23
Ascending phase of sleep cycle, 197
Ashby, R. W., 12

Associative, association, 20, 185, 206
ATP, 95
Attention, 19, 217
Attractor, 14, 120, 307, 207
Attractor dynamics, 301
Attractor-based dynamical models, 
321
Autoassociator, autoassociative network,
57, 164, 297, 289
Autoassociative graph, 290
Autoassociator model, 320
Autocorrelation, 107
Autogenic training, 216
Autonomic function, 281
Autonomous oscillations, 54, 141, 371
Avalanches, 64
Averaged evoked response, 263, 264
Awareness, 361
Axon, 67, 88
Axonal communication, 177
Axon initial segment, 66
Axon myellination, 227
Axon terminal, 88
Babbling, 227
Baby kicks, 223
Bach, J. S., 123
Background activity, 243
Backward association, 316
Bak, P., 64
Balanced partnership, 66
Bandwidth, 51
Barabasi, A. L., 38, 23
Barlow, H., 234
Barnes, C., 318
Barrel cortex, 46
Barthó, P., 149
Bartók, B., 354
Basal forebrain, 309
Basal ganglia, 31, 68, 280, 365, 366
Baseline shift, 158
Baseline subtraction, 271
Basic circuit of cortex 30
Basket cells, 69, 167, 253, 310, 313
Bayes, T., 9
Bellshaped curve, 39
BenAri, Y., 221
Benasich, A., 82
Berger, H., 3, 81, 84, 112, 171, 198
Bernstein school, 159
Berthoz, A., 306
Beta oscillation, 112
Betz cells, 58, 117
Bible, 17
Bifurcation problem, 197
Bimodality, 343
Binding problem, 232
Binding by gamma, 256
Binding by synchrony, 232, 242, 
243
Binding by temporal coherence, 238
Binding by time, 238
Binocular disparity, 275
Binocular frontal vision, 201
Binocular rivalry, 242, 228
Binocular stimulation, 242
Biophysicist, 145, 180
Bistable, 156
Bland, B., 309
Blindness, 218
Bloodﬂow response, 93
Blood-oxygenation-level-dependent
(BOLD), 93
Body architecture, 224
Body surface 225
Borbely, A., 211
Borges, J. L., 111
Born, J., 209
Bottomup approach, 24, 334
Bottomup connectivity, 232
Bragin, A., 309, 351
Brain, 17
Brain in the body, 220, 335
Brain computation, 360
Brain dynamics, 132
Brain oscillators, rhythms, 214, 217
Brain signals, 104
Brain slices, 92, 96
Brain states, 271, 275
Brain weights, 39
Brain-machine interface, 102
British empiricists, 233
Brodmann, K., 54
Brown noise, 121, 201
Buckminsterfullerene, 42
Burgess, N., 307
Bursts, 183
Burst initiators, 349
434
Index

C60, 42
CA1 region of hippocampus, 153, 284
CA3 autoassociator, 290, 301
CA3 recurrent excitation, 325
CA3 recurrent system, 290, 343
Cage, J., 123
Calbindin, 72
Calcium (Ca2+), 86
Ca2+ channels, 67
Ca2+ spike, 181
Calibration, 11, 31, 33, 221, 371
Callup mechanism, 342, 350
Calretinin, 72
Cannabinoid receptors, 359
Canolty, R., 82
Canonical circuit, 57, 365
Cartesian, dualistic view, 361
Cartesian space, 301
Castaneda, C., 42
Categorization, 330
Category learning, 115
Cats, 20, 126
Causality, 9, 239
Causation, 9, 16
Cause–effect, 10
Reciprocal casuality, 1, 21, 176, 227,
239
Celestial navigation, 295
Cell assembly, 65, 158, 161, 162, 319, 326,
340, 348
Competition of cell assemblies, 54, 65
Central limit theorem, 39
Cerebellum, 31, 68, 74, 210, 280, 363
Cerveau isole preparation, 186, 190
Cetaceans, 254
Chandelier cell, 69, 325
Channel(s), 89,126, 144, 145
Channel kinetics, 145
Chloride (Cl–), 86
Ih, 182, 197, 310
It, 182, 197
K+, channel, 86
K+, conductance 195
K+, currents 194
Chaos, 13, 30, 54, 128
Chaotic behavior, 113; see also
nonlinear dynamics
Chattering cells, 251
Chimpanzee, 20
Choice behavior, 12; see also volition
Cholecystokinin (interneuron type), 72
Cholinergic, 318; see also theta
Chrobak, J., 345
Chunking, 10, 321, 352
Churchill, W., 80
Circadian clock, rhythm, 117
Circle of life, 7
Circular causality, 123; see also Causality
Citicorp Center, 357
Clamping of membrane potential, 98
Clapping of hands, 168
Claustrum, 358
Climbing ﬁbers, cerebellum, 365
Clock time, 8
Clustering of units, 104
Coactivation of neuron pairs, 348
Coefﬁcient of variation, 124
Cognitive abilities, 262
Cognitive map, 302
Cognitive performance, 262
Cognitive potential (evoked), 125
Cognitive science/neuroscience, 93
Coherence, 108, 243, 340
Collective behavior, 174
Collective neuronal patterns, 150
Collective synchronization 108; see also
synchrony
Collision, 61
Columbus, C., 294
Combinatorial complexity, 233
Combinatorial expansion, 68, 236
Commission error, 104
Common junction 330; see also place cells
Comodulation of power, 109
Complex cells, 233
Complexity, 11, 13, 53, 55, 64, 120, 127,
164, 166, 277
Complex systems, 115, 119
Complex noise, 130
Compound envelope oscillators, 354
Compressed replay, 318, 349
Computation, 116
Computational modeling, 190, 290, 310
Computer networks, 132
Concepts, 18
Concepts of architecture, 41
Conductance, 91, 144, 149
Conduction delays, 115, 116
Index
435

Conduction velocities, 51
Conductivity, 91
Congenital blindness, 219
Conjunctive neurons, 304
Connected neuronal graph, 301
Connectivity pattern, 179
Connors, B., 72
Consciousness, 19, 278, 360, 369, 371
Consolidation of memory, 346, 206
Constellation of oscillations, 362
Construction of perception, 131
Content addressability, 289
Content of gamma oscillation, 257
Context, 263
Contextual retrieval, 336
Convergence of patterns, 42, 165
Coordinated place-cell assembly
hypothesis, 320, see also place cells
Corollary discharge, 33, 199; see also
Reafferenz Prinzip
Corpus callosum, 363
Correlated Brain Noise, 131
Cortazar, J., 118
Cortex, 164
Cortical circuit, 57
Cortical “column,” 44
Cortical “maps,” 223
Cortical spindles, 223
Coulter, D., 325
Coupled relaxation oscillators, 138
Coupling of oscillators, 170, 252
Coupling of systems, 334
Covariation of oscillations, 351
Crawling, 223
Creative process, 211
Crick, F., 22
Cross-frequency phase synchrony, 109, 353
Csicsvari, J., 66, 160, 324
Cultural evolution, 16
Current density, 83, 91
Current ﬂow in extracellular space, 89
Current-source density, 90, 339
Cycle length, 116
Cytoarchitecture, 368
Cytochrome oxydase, 95
Czurkó, A., 304
Damped oscillator, 54, 142, 187, 188
Darwinian evolution, 56
Dead (deduced) reckoning, 249, 302, 306,
307, 316, 328
Dead-reckoning navigation 294, 306, 371
Decision making, 19, 262
Declarative memory, 278; see also
memory
Deduction, deductive arguments, 16, 17
Deep Blue, 23
Deep brain stimulation, 354
Default patterns of the brain, 5, 26, 206
Default state, 175, 186, 192
Degree of separation, 37, see also synaptic
path length
Delay, synaptic, 78
Delay lines, 292
Delta oscillation, 112, 183, 195
Delta power, 156
Dendrites, 49, 66, 71
Dendritic segment, 67
Dendritic spines, 247
Dendrodendritic junctions, 179
Denk, W., 95
Dentate gyrus, 283
Dentate spikes, 344
Depressing synapses, 72
Depth electrodes, 83
Descartes, 20
Descending phase of theta, 197; see also
theta oscillations
“Design” principles, 362
Desynchronization, 12, 131, 258, 268, 338,
354
Deterministic oscillation, 209
Deterministic systems, 30, 176,198
Detour problem, 297, 301
Dictionary deﬁnition, 21
Differentiation, 65
Directional tuning, 306
Direction in navigation, 294
Direction of neuronal communication, 337
Discharge phase of oscillation, 171
Disconnectedness, 78
Disengagement of activity, 198, 341
Dissipation, 143; see also complex systems
Distance representation, 226, 294, 326, 329
Distributed clock, 72, 77
Distributed memory, 288
Distributed network oscillators, 252
Distributed networks, 252
436
Index

Divergence of connections, 42, 165
Dobzhansky, T., 61, 228
Dogs, 20
Dolphins, 17
Down state, 192; see also slow oscillations
Down-up shift, 196
Downward causation, 14, 123, 227; see
also causality
Dragoi, G., 160, 320
Dreams, dreaming, 113, 206, 207
Driving force, 144
Drosophila, 117
Dura mater, 82
Duty cycle of oscillations, 141, 268
Dynamical systems, 16
Dynamical theory, dynamics, 13
Dysrhythmias, 372
Earthquake(s), 81, 357
Eccles, J., 180
Eckhorn, R., 255
Edelman, G., 22, 53, 132
EEG, 81, 82, 89, 110,120, 197
Egalitarian brain, 238
Egocentric representation, 302; see also
allocentric, dead reckoning
Egyptian architecture, 41
Eigenfrequency, 145
Einstein, A., 6
Einthoven, W., 99
Einthoven triangle, 99
Electrocardiogram (EKG), 99
Electrocerebellogram, 368
Electrocorticogram (ECcG), 83
Electroencephalogram (EEG), 4
Elephants, 254
Embeddness, 11, 227
Emergence, 153, 169, 220
Emergent property, 11, 254, 359
Emergent population, 108
Emotion(s), 17, 19, 262, 283,
Encephale isolé, 186, 187
Endocannabiniods, 325
Endocrine function, 72, 281
Endogenous activity, 11; see also self-
organized activity
Energy dissipation, 134
Engineering, 171
Enslavement principle, 14, 167
Entorhinal cortex, 192, 296, 306, 345
Entorhinal projection, 325
Entorhinal-perirhinal connections, 283
Entropy, 12, 55, 111
Epileptic discharge, 76, 368
Epileptic subjects, 272
Epileptiform, 133
Episodic memory, 272, 280, 292, 308, 341,
350, 353
Episodic recall, 302
EPSP, EPSC, 89, 90
Equilateral triangle, 99
Equilibrium potential, 144
Equilibrium state, 13
Erdös, P., 18, 36
Error trials, 337
Evoked potentials, 254
Evolution, 61
Excess correlation, 321
Excitation, 62
Excitatory connections, 132, 167
Excitatory feedforward structure, 284
Excitatory glutamatergic loops, 286
Excitatory neurotransmitter, 88
Excitatory postsynaptic potential
(EPSPs), 66, 163
Excitatory recurrent circuits, 344
Executor networks, 263, 274; see also
volition
Exhaustive search, 289
Expectation, 131, 262
Experience, 11, 206, 221, 278; see also
learning
Experience dependent plasticity, 222
Explained variance, 348
Explicit representation, 16, 234, 278; see
also gnostic neurons
Explicit location coding, 297
Explicit memory, 292
Explicit place cells, 301
Explicit reference system, 221
Externally controlled oscillation, 254
External pacemaker, 320
External perturbation, 215
Extracellular events, recording, 98, 250
Extracellular current, 89
Extracellular ﬁeld potentials, 90
Extracellular spikes, 91, 101
Extrastriate cortex, 340
Index
437

Facial nerve, 226
Facial vibrissae, 226; see also whiskers
Familiarity, 262
Fast inhibition, 248
Fast oscillations, 113, 116; see also ripples
Fear conditioning, 338
Feedback, 58, 63, 164, 276
Feedforward effects, 57, 58, 63, 163, 164,
242, 282
Feedforward inhibition, 63, 73, 325
Feedforward inhibitory loop, 365
Feedforward model, 235, 237
Feedforward net, 115
Feedforward processing, 334
Feedforward systems, 234, 235
Feeling(s), 371, 256; see also quale
Feeling of individuality, 362
Feeling of time, 8
Fetus, 222, 226
Figure-background segmentation, 243
Filter, 72
Filtering property, 116
Band-pass ﬁlter, 146
Band-stop ﬁlter, 146
Low-pass ﬁlter, 72, 89
Notch ﬁlter, 146
Five stages of sleep, 187
fMRI, 39, 110, 131, 264
Fodor, J., 23
Forced oscillator, 255
Fornix, 282
Forward association, 316
Fourier analysis, 105, 119
Fourier spectral methods, 240
Fourier synthesis, 105
Fourier transforms, 130
Fractal(s), 30, 126, 127, 129
Fractal geometry, 30
Fractal of loops, 30
Fractal nature of EEG, 126
Fractal structure, 47
France, A., 38
Freedom of the self, 12
Free recall, 292, 316, 329
Free-running oscillator, 216
Free will, 12; see also volition
Fregnac, Y., 167
Frequency content, 105
Frequency domain analysis, 104, 105
Frequency doubling, 105
Frequency potentation, 292
Freud, S., 371
Freund, T. F., 88, 69, 310
Freyeraband, P., 357
Friston, K., 111, 152
Fuller, R. Buckminster, 38, 42
Functional assemblies, 221
Functional Magnetic Resonance Imaging
(fMRI), 92
Functional map, 269
GABA (Gamma-aminobutyric acid), 66,
72, 117, 309
GABA inhibition, 165, 184
GABA receptors, 132, 178, 248, 249,
258, 283
GABA system, 310
Gain control, 304
Gamma frequency oscillation, 75, 76, 106,
112, 113, 116, 130, 132, 194, 240,
241, 245, 248, 250, 252, 258, 273,
339, 343, 351
Gamma cycle-locked oscillation, 324
Gamma power, 250
Gamma synchrony, 253, 272
Ganglion cell, 118
Gap junction, 72, 117, 179, 250, 251, 365
Gating function, 141, 144, 145
Gaussain distribution, 39
Geisler, C., 170
General systems theory, 17
Gene transcript, 346
Geodesic dome, 42
Gestalt psychology, 15, 243
Gevins, A., 339
Giant depolarizing potential, 221
Gigaohm seal, 98
Gilden, D., 132
Glial cells, 35, 72, 269
Global brain activity, 263
Global synchrony, 170
Globus pallidus, 366
Glutamatergic excitation, 364
Gnostic neurons, units, 234, 242, 330
Banana-speciﬁc neurons, 234
Cardinal neurons, 234
Goal directedness, 12, 15; see also volition
Golgi cells, 363
438
Index

Google, 38, 288
Granovetter, M., 56
Granule cells 90, 283, 291, 343
Grastyán, E., 19, 21
Gray, C., 240
Gray matter, 91
Great apes, 59
Greek architecture, 41
Grid cells, 298, 312, 319
Grinvald, A., 94, 268
Guillery, R., 178
Guinea pigs, 20
Gulyás, A., 71
Gyrus, gyri, 44
Habits, 210
Habituation, 125
Haken, H., 14
Halgren, E., 336
Hallucinations, 220
Hamburger, V., 223
Hard problem, 361
Harmonic oscillator, 137, 151, 171, 208, 337
Harri, R., 85, 200
Harris, K., 149, 161
Head-direction cells, 306, 313
Head-direction system, 306, 307
Hebb, D. O., 158, 238
Hein, A., 228
Held, R., 228
Hemoglobin, 95
Hexagons, 42
Hibernation, 35
Hierarchical theory, 52
Hierarchy, 30, 57, 63, 235, 237, 282
High-dimensional patterns, 354
High-dimensional space, 104
High-pass ﬁlter, 72, 146
High-voltage spindle (HVS), 202, 203,
204
Hilbert transformation, 107
Hippocampus, 173, 283, 319
Hippocampal-enthorhinal output, 209,
278, 349
Hippocampal formation, 279
Hippocampal maps, 299
Hippocampal neocortical dialogue, 342
Hippocampal-neocortical
communication, 337, 347
Hippocampo-prefrontal directionality,
341
Hippocampus and amygdala, 281
Hippocrates, 17
Hirase, H., 160, 304, 348
Histamine, 185, 207
History-dependence of system activity, 127
Hof, P., 59
Homeostatic regulation, 66
Homunculus, 263
Hopﬁeld, J., 61
Hormones, 72
HTML-based communication, 23
Hubel, D., 26, 165, 233
Human speech, 45
Hume, D., 20
Huygens, C., 169
Huygens’s pendulum clock, 169
Hypercomplex cells, 233
Hyperpolarization, 172
Hypocretin, 207
Hyponym, 21
Identiﬁcation of neurons, 103; see also
extracellular spikes
Idling patterns, 12, 207, 217
Idling hypothesis of alpha, 203
Illusion(s), 47, 128
Immediate spiking history, 151
Individuality, 277
Induced rhythms, 109
Inductive process, 9
Inferior olive, 365, 368
Inﬁnite loop, 294
Information, 11, 254, 347
Information integration, 362
Information theory, 12, 175
Information transfer, 349
Infrared camera, 97
Inhibition, 62, 90, 167, 185
Inhibitory interneurons, 51, 61; see also
interneurons
Inhibitory loops, 366
Inhibitory postsynaptic potential
(IPSPs), 66, 89, 90
Input complexity, 166
Input–decision–output, 233
Input resistance, 194
Integer period relationship, 354
Index
439

Integrate-and-ﬁre units, neurons, 138, 144
Integration, integrated systems, 54, 55, 65,
164
Hypothetical integrator, 307
Integration time window, 151
Intelligence, 15
Intelligence and alpha oscillations, 199
Intentionality, 20
Intercalated neurons, 179
Interconnected systems, 185
Interhemispheric shift, 211
Interloop communication, 364
Internal attention, 217
Internal synchronization, 255
Internet, 16
Internet’s mind, 23
Interneurons, 65, 250, 253, 258, 359
Interneuron classes, 77, 104, 311
Interpretation process, 131
Intracellular recording, 250
Intradendritic recording of theta
oscillation, 319
Intrinsic mechanisms, 151; see also
channels
Intrinsic oscillation, 312
Introspection, 18
Inverse problem, 81
Inverted ﬂower plot, 207; see also REM
sleep
In Vitro slice preparation, 96, 98, 145, 184,
192, 231, 309
Isomorphism, 301
Isomura, Y., 343
Izhikevich, E., 132
Jackson, J. H., 19
Jacob, F., 8
Jahnsen, H., 180
James, W., 20, 115
Jefferys, J., 249
Jerks, 223
John, E. R., 159, 361
Joplin, S., 123
Josephson junction, 84
Julesz, B., 46
Julesz pattern, 244
Junction, crossing, 328, 330
Jung, C., 231, 238
Juxtacellular recording, labeling, 180
Kahana, M., 292
Kamondi, A., 312
Kanerva, P., 57, 288
Kant, I., 6
Katz, L., 221
K-complex, 122, 194, 196, 228
Kelso, S., 17
Kenyon cells, 235
Khazipov, R., 221
Kittens, 213
Klausberger, T., 69, 313
Klimesch, W., 338
Knight, R. T., 86
Koch, C., 361, 22
Kocsis, B., 309
Konorski, J., 234
Kopell, N., 171
Kurzweil, R., 23
Labile brain, 111
Landmark-guided maps, 330; see also
place cells
Landmark navigation, 303, 313
Largescale excitatory network, 250
Largescale organization, 33, 127
Largescale oscillation, 195
Lateral inhibition, 63
Laterodorsal tegmental nuclei, 186
Laurent, G., 257
Layers in anatomy and computer models,
283
Leakage current, 125
Learning, 213
LeDoux, J., 41
Leinekugel, X., 221
Libet, B., 10
Libet’s mind time, 116
Limbic system, 281
Limb immobilization, 226
Limit cycle, 108, 137
Linear causation, 9, 16; see also
causality
Linear track, 316, 326
Lisman, J., 352
Llinás, R., 11, 124, 144, 180, 358
Local circuit interneuron, 65; see also
interneurons
Local clustering, 37
Local connections, 78, 168
440
Index

Local ﬁeld potential, 83, 89, 106, 153, 269
Recording of local ﬁeld potentials, 81
Local inhibition, 290
Local mean ﬁeld, 89
Local-to-global causation, 14
Location of sensory stimuli, 226
Locke, J., 20
Locus ceruleus, 274
Logical depth, 297
Logical illusion, 10
Log-log plot, 119, 121
Logothetis, N., 93, 228
Long and heavy tail, 323
Long-range connection, 37, 41, 51, 78,
170, 177, 191, 252
Long-range interneuron(s), 70, 310
Loop-like organization, 30, 52, 280
Lopes da Silva, F., 201
Lousiana Superdome, 42
Lower level feature, 234
Low-threshold Ca2+ spike, 183
Luria, A. R., 288
Lyapunov exponent, 13
Lymph circulation, 86
Macroscopic variable, 175
Magnetic ﬁeld, 175
Magnetic resonance imaging (MRI), 92
Magnetoencephalography,
magnetoencephalogram (MEG), 84,
121, 153
Mainen, Z., 67, 68
Makeig, S., 265
Mammalian brain, 59
Mandelbrot, B. B., 30
Map, 45
Map-based navigation, 45, 46, 225, 296,
315, 328
Mapping technique, 81
Marczynski, T., 202
Marijuana, 359
Markram, H., 69, 71
Marr, D., 23
Marsupials, 52
Martinotti cells, 70; see also interneurons
Master-slave relationship, 142
Mathematics, 171
Maxwell’s equations, 84
McBain, C., 69
McCornick, D., 181
McLean, P., 280
McNaughton, B., 99, 306, 347
Mean ﬁeld, 86, 89
Meaningful coincidences, 238; see also
synchronicity
Mechanical pen recorders, 112
Medial septum, 309
Meditation, 214, 217
Medium spiny neurons, 367
Mehta, M., 318
Melanospin, 118
Memory, 20, 132, 206, 210
Memory capacity, 289
Memory consolidation, 207, 209
Memory encoding, 272
Memory erasure, 346
Memory performance, 215
Memory space, 327
Mendeleev, D., 113
Mesoscale, 127
Metaphors, 21
Metastability, 128
Mice, 20, 213
Microarousal, 197
Microelectromechanical system (MEMS),
102
Micromanipulator, 98
Microsaccades, 255
Mies van der Rohe, L., 29
Milennium bridge, 143
Miles, R., 149, 336
Milner, B., 282
Milner, P., 238
Mind, 361
Mind time, 10, 116, 125; see also Libet
Minsky, M., 17
Mismatch negativity, 125
Miyashita, Y., 338
Modular organization, 43, 58, 77, 365
Monkey, 255
Monolithic oscillator, 173
Monosynaptic connections, 246
Monotremes, 52
Moony faces, 244
Moser, E., 298
Moser, M. B., 298
Mossy ﬁbers, 364
Mossy synapse, terminal, 291, 293
Index
441

Motifs, 49
Motivation, 262
Mountcastle, V., 26
Muller, R., 301
Multidimensional space, 288, 291
Multiinfarct dementia, 236
Multilayered space, 285
Multiple parallel loops, 276, 364
Multiple sclerosis, 48
Multiple spatial scales, 121
Multiplexed oscillations, 351
Multiplexing mechanism, 256, 353
Multishank silicon probes, 102
Multisite recording, 103
Mu rhythm, 200, 202, 222, 223, 266; see
also alpha rhythm
Muscle twitches, 223
Mushroom bodies, 257
Mutual entrainment, 107
Myosin, 34
N1 component of evoked potential, 125
N2P2 components of evoked potential,
125
Nádasdy, Z., 348
Nadel, L., 297
Na spike, 181
Natural (Napierian) logarithm, 113
Navigation, 294, 327
Necker cube, 275, 229
Neda, Z., 168
Negative damping feedback, 54
Negative force, 64
Neglect, 228
Neher, E., 97
Neocortical-hippocampal loops, 336
Neocortical networks, 166, 179
Neon tube, 138
Nested gamma activity, 353
Network excitability, 346
Network oscillations, 184
Neural Darwinism, 53
Neural moment, 111
Neurofeedback, 216
Neuronal classes, 104; see also
interneurons
Neuronal correlates of consciousness, 22
Neuronal trajectories, 330
Neurotransmitter, 88
New World shamans, 42
Nictitating membrane, 272
Nigrothalamic pathway, 180
Nimchinsky, E., 59
Nissl, F., 54
NMDA receptor, 189, 246, 312, 325
Noise, 12, 126, 128, 132, 154, 156, 168,
263, 264, 319
Noncholinergic component of theta
oscillation, 313, 318
Nondeclarative memories, 362
Nonlinear behavior, 181
Nonlinearity, 13, 62, 64
Non-REM sleep, 187
Nonsynaptic effects, 90
Norepinephrine, 185, 207
Normal or Gaussian distribution, 40
Number neurons, numerosity, 125
Nuñez, P., 116
1/f noise, 106, 119, 120, 202; see also
power law
Occipital alpha oscillation, 84; see also
alpha oscillations
Occipital cortex, 198
Oddball task, 125
Odor detection, 74, 258
Ogawa, S., 93
Ohm’s law, 91, 144
O’Keefe, J., 99, 296, 306
Olfactory bulb, 251
Olfactory information, 257, 281
Olfactory perception, 257
OLM interneuron, 310, 325; see also
interneurons
Omission errors, 104
Omnidirectional cells, 42, 297, 301, 328,
330; see also place cells
One-dimensional track, navigation, 315,
316, 328
Opposing forces, 142, 360
Optical ﬂow, 304
Optical imaging, 94, 269
Optimal brain wiring, 37, 53
Optimum level of noise, 158; see also
stochastic resonance
Orbit, 140; see also limit cycle
Order parameter, 14
Orienting response, 19
442
Index

Orthogonalization of memory, 292
Oscillations, 6, 19, 74, 112, 129, 136, 137,
143, 173
Oscillatory coupling, 350, 354
Oscillation death or quenching, 109
Oscillatory dynamics–based temporal
coordination, 321
Oscillatory networks, 171
Oscillatory synchrony, 107, 168, 232
Oscillatory timing, 359
Phase modulation, 352
Oscillopathies, 372
Oxygen extraction function, 271
P1 component of evoked response, 125
P300 component of evoked response, 267
Pacemaker, 117, 189, 190, 201, 203, 252,
359, 309
Pacemaker-follower, 142
Packing density, 101
Paleopallium, 280
Pallidothalamic, 180
Pallidum, 366
Pantha rei, 7, 8
Papp, E., 67
Parabolic relationship, 158
Paradoxical sleep, 198; see also REM
sleep
Parahippocampal area, 341
Parallel loops, 30, 367
Parallel processing, 366
Parietal cortex, 125
Parkinson tremor, 354
Partials of Fourier transform, 147
Parvalbumin, 72; see also interneurons
Passive return currents, 91
Patch-clamp method, 97, 98
Inside-out patch, 26
Outside-in patch, 26
Path crossing, 303; see also junctions
Path integration, 307; see also dead
reckoning
Pattern separation, 65
Pauli, W., 238
Paulsen, O., 324
Pedunculopontine nucleus, 186
Peer prediction method, 161
Peer-to-peer contact probabilities, 289
Penﬁel, W., 271
Penttonen, M., 112
Peptides, 72
Perception, 20, 158, 228, 235
Perceptual stability, 275
Perinatal maturation, 371
Period (Per) gene, 117
Periodic chart of elements, 113
Periodic inhibition, 294
Periodicity, 5, 116
Periodic limb movement disorder, 227
Perirhinal cortex, 341
Perisomatic inhibition, 67, 69, 325
Permeability, 144
Persistent neuronal activity, 369
Persistent oscillation, 372
Personal identity, 277
Perturbation of activity, oscillations,
53,128, 131, 149, 211, 220, 227, 251,
255, 276,
PET, 39, 94, 110
Peters, A., 70
Petsche, H., 309
Phase angle, 140
Phase coherence, 272
Phase covariance, 108
Phase delay, 336
Phase dynamics, 354
Phase modulation, 109, 352
Phase offset, 336
Phase precession, 109, 314, 319, 354
Phase reset, 109, 266, 267, 268
Phase-coded information, 158
Phase-locked discharge, 108, 158, 341,
342
Phase-locking of oscillators, 354
Phase-shifted dipoles, 312
Philosophy, 22
Photoreceptor, 118
Phrenology, 39
Physicist, 81
Physics, 171
Physiological topology, 229
Pia mater, 82
Pinault, D., 178
Pink noise, 120, 121, 129, 131
Pinwheel centers, 269
Pipette, 98
Place cells, 161, 296, 290, 313; see also
gnostic neurons
Index
443

Place coding, 315
Plane symmetry, 299, 302, 304
Planning, 262
Plasticity, 347
Plasticity rule, 318
Point source of action potential, 103
Poisson distribution, 132, 152, 154
Polypeptides, 72
Population activity, 272
Population code, 157
Population oscillation, 170
Population spike, 89
Positive feedback, 142
Positron emission tomography (PET), 94
Posterior association areas, 339
Posterior cingular cortex, 341
Postsubiculum, 306
Postsynaptic side, 88
Power-law, 38, 54, 5650, 121, 274
Power spectrum, 105, 119, 120, 130, 145
Predictable, 54, 111
Prediction, 127, 131
Preferred cortical state, 268, 269
Prefrontal area, 272
Prefrontal cortex, 339
Pregnancy, 222
Premature babies, 222
Prigogine, I., 13, 262
Principal cells, 61, 65, 71, 251
Principle of contiguity, 292
Principle of movement control, 227
Procedural, skill memory, 210
Processing window, 115
Projection neurons, 258
Prosopagnosia, 237
Pueblo Indians, 17
Pulsatile oscillator, 138; see also relaxation
oscillator
Pulvinar, 185
Purkinje cells, 363
Psychiatric diseases, 27
Psychological time, 125
Psychology, 22
Pyramidal cell, 34, 58, 167
Pythagoreans, 124
Quale, qualia, 124, 371
Quasi-periodic, 113
Quasi-sinusoid, 171, 173
Rabbit(s), 20, 126, 272
Ramón y Cajal, S., 41, 54, 279, 281
Ranck, J., Jr., 306
Random graph architecture, 285, 299
Random graph theory, 35
Random patterns, 54, 142
Random walk, 121, 201, 303
Rate coding, 165
Readout from memory, 160, 274, 326
Reafferenz Prinzip, 33, 199, 255; see also
corollary discharge
Rebound spikes, 181, 183
Recall of memory, 206, 271, 338
Recce, M., 314
Receptive ﬁeld, 160
Recurrent loop, 282, 284, 287
Redundancy, 166, 167
Reentrant loop, 366
Refractory period, 141
Regained vision, 219
Regenerative feedback, 368
Relational memory, 328
Relaxation oscillators, 118, 138, 148, 152,
171, 172
Accrual (accumulation) and discharge
phase, 20, 141
Remapping, 297
REM sleep, 187, 197, 207
Rényi, A., 35
Representation, 11
Reptilian brain, 280
Reset the theta oscillation, 267
Resistivity, 91
Resonance, 142, 143, 147, 163
Resonant loop, 336
Resonant properties of neurons, 163, 254,
358
Rest-associated oscillation, 204
Resting activity, 175, 208
Restless leg syndrome, 227
Reticular cells, 189
Reticular nucleus of the thalamus, 179,
183, 203
Retina, 45, 118
Retinotopic topographic, 46, 233
Retrieving memories, 290
Retrosplenial cortex, 306
Reverberating, 160
Reverberating circuits, 160, 336, 352
444
Index

Reversal potential, 144
Reverse engineering, 97
Reyes, A., 165
Rhinal ﬁssure, 281
Rhinal-hippocampal coherence, 338
Rhinencephalon, 281
Rhythmic hand clapping, 338
Rhythmic movements, 114
Rhythmopathies, 372
Rich-get-richer principle, 167
Richmond, B., 166
Ripple oscillation, 129, 311, 345
Robot control, 217
Romhányi, G., 109
Rorschach test, 47
Saccadic eye movement, 201
Sagan, C., 361
St. Augustine, 19, 136
Sakmann, B., 97
Samadhi ofYoga, 215
Sarnthein, J., 116
Scalable structures, 43
Scale-free systems, 35, 39, 54, 56, 119,
121, 127
Scale invariance, 121, 126
Scaling laws, 34, 77, 78
Scalp EEG, 82, 91, 153, 338
Scanziani, M., 37
Schaffer collaterals, 284
Scientiﬁc vocabulary, 18
Scoville, W., 282
Search strategy, 289
Seed of excitation, 194
Seeds of synchrony, 189
Segregation of ﬁgure and background, 256
Segregation of patterns, activity, 54, 55,
164, 167
Seismic waves, 357
Seismology, 81
Sejnowski, T., 67, 265
Self-awareness, 22, 371
Self-cause, 11
Self-consciousness, 371
Self-emergence, 16; see also emergence,
spontaneous
Self-generated neuronal activity, 370
Self-generated patterns, activity, 11, 111,
122, 153, 257, 268, 370
Self-generated synchrony, 254
Self-motion, 307
Self-organization, 10, 11, 17, 74, 155, 175,
204, 208, 211, 275, 315, 349, 335
Self-organized hippocampal activity,
345
Self-organized interactions, 259
Self-organized oscillation, 213
Self-organized spontaneous patterns,
368
Self-organized criticality, 64, 128, 370
Self-reference, 328
Self-similarity, 126; see also fractals
Self-sustained depolarization, 192
Semantic knowledge, 292, 297
Semantic memory, 272, 308, 330
Sensory feedback, 215
Septal pacemaker, 313
Sequence coding, 316
Sequence compression, 321
Serial processing, 233
Serotonin, 185, 207
Sharp electrode, 98
Sharp wave-ripple complex, 90, 344, 348
Shatz, C., 221
Sherman, M., 178
Shortcuts, 285
Short-time Fourier transform, 106
Shunting inhibition, 75, 89
Sik, A., 70, 71
Silicon probes, 101, 102, 103
Sine wave, 105
Singer, W., 161, 221, 240
Single-cell doctrine, 234
Single neuron isolation, 96, 98
Single neuron moment, 151
Sink-source, 89; see also current-source
density
Sinusoid oscillator, 171; see also harmonic
oscillator
Sirota, A., 221, 341
Situatedness, 227; see also embeddedness
Six Degrees of Separation 36
Skaggs, W., 318
Skeletal muscles, 199, 224
Skull, 82
Sleep, 175, 176, 186, 187, 208, 209, 262
Sleep cycle, 197, 211, 348
Sleep onset, 185
Index
445

Sleep (continued)
Sleep spindles, 188, 195, 196, 228
Sleep-associated oscillations, 204
Slice, in vitro, 251
Silence (down state), 195
Silent periods, 344; see also slow
oscillation
Slope-reset, 172, 314; see also phase
precession
Slow oscillators, 113, 115, 190, 191
Slow-wave sleep, 152, 210, 349
Small-world-like architecture, 239, 362
Small-world network, 37, 49, 170, 239,
252, 285,
Smartness of neurons, 13, 15
Social communication, 227
Soltész, I., 69
Somatosensation, 199, 221
Somatosensory cortex, 45, 225, 341
Somogyi, P., 69, 70, 313
Songbirds, 227
Source localization, 100
Sparse representation, 290; see also
memory
Sparsity feature, 297
Spatial distance, 321
Spatial memory, 330
Spatial scale, 126
Spatial symmetry, 6
Spatio-temporal context, 6, 326
Spectrogram, 106
Speech, 227
Speed gain modulation, 294
Spike-ﬁeld correlation, 92
Spike-sorting methods, 103, 104
Spike time jitter, 321
Spike timing, 63
Spike timing–dependent plasticity, 163,
248, 318, 329
Spiking neurons, 98
Spindles, 189, 190, 194, 223; see also
sleep spindles
Spindle-shaped neurons, 59, 222
Spiritual experience, 215
Sponges, 114
Spontaneous activity, 11, 12, 15, 17, 111,
132, 216; see also self-organized
activity
Sporns, O., 55
Spreading excitation, 290
SQUID, 84
Startle reﬂex, 32
State-dependence, 32, 175, 176, 263
State transition, 64
Stereotrode, 99
Steriade, M., 190
Stevens, C., 53
Steven’s power law, 124
Stickgold, R., 210
Stochastic resonance, 54, 149, 155, 157,
336
Strabismic amblyopia, 242
Stress relief, 217
Striatal rhythm, 369
Striatum, 192, 210, 366
Strogatz, S., 37
Stryker, M., 213
Subdural electrode grids, 83
Subicular complex, 192, 306, 339, 343
Substantia nigra, 367
Subthalamic nucleus, 366
Subthreshold oscillations, 90, 163
Superimposed activity, 232, 280
Supervisor, executor, 14
Supplementary motor area, 199
Suprachiasmatic nucleus, 117
Surface imaging method, 269
Surface local ﬁeld potential, 95
Sustained activity, 141
Svoboda, K., 96
Swing, pendulum, 142
Symmetry braking, 299
Synapse, 33, 92, 285
Presynaptic terminal, bouton, 66
Synaptic graph model, 301
Synaptic path length, 37, 49, 170
Synaptic plasticity, 247, 329
Synaptic potential, 88
Synaptic strength, weight, 247
Synaptic tag hypothesis, 347
Synchronization, 152, 155, 166, 254, 360
Synchronicity, 238, 240
Synchrony, 75, 150, 151, 152, 153, 158,
164, 168, 208, 215, 246, 254
Synergy, 14
Synﬁre chain, 57, 163, 164
Synthesizers, frequency, 105
Systems, 15
446
Index

Systems, neuroscience, 231
Szentágothai, J., 69
Szentgyörgyi, A., 24
Tabula rasa, 227, 346
Tacoma Narrows bridge, 143
Talairach, J., 55
Talmud, 17
Tank, D., 61, 96, 98
Taube, J., 306
Tau rhythm 85, 200
Taxonomy, 71, 112
Taxonomy of memory, 278
T-channel 181
Teleology, 15
Telepathy, 3, 84
Tempo, 125
Temporal asymmetry, 292
Temporal coding, 163, 165, 259, 293, 315
Temporal gaps, 225
Temporal memory effect, 121
Temporal resolution, 93, 94
Temporal scale, 113
Temporal summation, 90
Temporal window, 257
Tendons, 224
Tensegrity, 41, 47, 61, 129
Tension compression, 42
Tessellation, 175
Tetrodes, 99
Thalamocortical oscillations, 180
Thalamocortical spindles, 350
Thalamocortical system, 175, 179, 183,
184
First-order nuclei, 178, 200, 203
Higher-order nuclei, 178, 200
Thalamus, 31, 45, 176, 177, 179, 192, 252
Ventral thalamic nuclei, 366
Ventrobasal nucleus, 180
Thermodynamics, 61
Theta cell, 309
Theta oscillation, rhythm, 19, 112, 113,
173, 187, 266, 308, 313, 336, 341
Cholinergic theta, 313
Theta coherence, 339
Theta current, 312
In vitro theta, 309
Theta phase ordering, 316
Third trimester, 222
Thomson, A., 72
Three-dimensional arrays, 102
Threshold, 66
Time constant, 151
Time domain analysis, 104
Time-frequency analysis, 104
Time-frequency representation, 107
Time metric, 313
Time-multiplexing model, 352
Timing mechanism, 308, 310
Tissue culture, 117
Toggle switch, 196
Tonic depolarization, 74
Tononi, G., 55, 361, 211
Top-down approach, 22, 23, 334
Trajectory, 13, 176, 201, 291
Transient oscillator, 76, 142, 196
Translational invariance, 234
Transmembrane activity, 83
Traub, R., 185, 253
Traveling spindles, 190
Triangulation, 42, 99, 100, 103, 207, 295,
313
Tsodyks, M., 268
Tsubokawa, H., 73
Tuned mass damper, 357
Tungsten extracellular electrode, 98
Turing, A., 23, 144
Turing program, 23
Two-dimensional arrays, 102
Two-dimensional space, 294
Two-photon, multiphoton laser scanning
microsopy (2PLSM), 95
Two-stage model of memory, 349
Ulbert, I., 336
Ultradian rhythm, 117
Ultrafast rhythm, 203
Unidirectional travel, 304, 316
Unihemispheric sleep, 176
Upstate of slow oscillation, 192, 351
Vadia, E., 153
Van der Pol, B., 138
Vanderwolf, C. H., 21
Van Essen, D., 45, 52
Varela, F., 11
Vasointestinal polipeptide, 72; see also
interneurons
Index
447

Vector, 91
Vectorial distance, 307
Velocity, 304
Velocity-dependent gain, 323
Vestibular function, 363
Video camera, 95
View cells, 304
Vision-for-action, 233
Vision-for-perception, 233
Visual cortical areas, 221
Visual discrimination, 337
Visual imagination, 217
Visual working memory, 339
Volition, will, 262
Voltage-gated channel, 181; see also channels
Voltage-sensitive dye mapping, 95, 271
Voluntary movement, 19, 360
von Bertalanffy, L., 14
von der Malsburg, C., 238
von Stein, A., 116
Waking state, 213
Walter, G., 17
Wavelet analysis, 106, 107, 130
Wavelet transform, 106, 107
Wave packets, 111
Wave shape, 103
Weakly chaotic, 137
Webb, W. W., 95
Weber’s psychophysical law, 123
Weighted graph, 290
Well-isolated neurons, 101
Wheel-running task ,348
Whiskers, 202, 211; see also barrel cortex
White matter, 91
Whitening of spectrogram, 106, 129
Whittington, M., 69, 249
Whole-cell recordings, 368; see also patch-
clamp
Wiener, N., 201
Wiesel, T., 26, 165, 233
Will-guided action, 20, 275
Wilson, M., 347
Wing, X. J., 170
Winner-take-all, 63, 64, 167, 312
Wire optimization, complexity, 29, 46, 62
Wire tetrodes, 101
Wise, K., 102
Working experience, 211
Working Memory, 245, 339
World Wide Web, 38
X-ray, 92
Yerkes–Dodson law, 156
Yoga, 215
Young, M.P., 52
Yuste, R., 96
Zebra ﬁnch, 227
Zen, 215
Zero-time-lag synchrony, 252
448
Index

