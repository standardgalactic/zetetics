Trace and Pace: Controllable Pedestrian Animation
via Guided Trajectory Diffusion
Davis Rempe∗,1,2
Zhengyi Luo∗,1,3
Xue Bin Peng1,4
Ye Yuan1
Kris Kitani3
Karsten Kreis1
Sanja Fidler1,5,6
Or Litany1
1NVIDIA
2Stanford University
3Carnegie Mellon University
4Simon Fraser University
5University of Toronto
6Vector Institute
Figure 1. (Left) We propose TRACE, a trajectory diffusion model that enables user control through test-time guidance. (Right) Generated
trajectories are passed to a novel physics-based humanoid controller (PACER), forming a closed-loop pedestrian animation system.
Abstract
We introduce a method for generating realistic pedes-
trian trajectories and full-body animations that can be con-
trolled to meet user-defined goals. We draw on recent ad-
vances in guided diffusion modeling to achieve test-time
controllability of trajectories, which is normally only asso-
ciated with rule-based systems. Our guided diffusion model
allows users to constrain trajectories through target way-
points, speed, and specified social groups while accounting
for the surrounding environment context. This trajectory
diffusion model is integrated with a novel physics-based hu-
manoid controller to form a closed-loop, full-body pedes-
trian animation system capable of placing large crowds in
a simulated environment with varying terrains.
We fur-
ther propose utilizing the value function learned during RL
training of the animation controller to guide diffusion to
produce trajectories better suited for particular scenarios
such as collision avoidance and traversing uneven terrain.
Video results are available on the project page.
1. Introduction
Synthesizing high-level human behavior, in the form
of 2D positional trajectories, is at the core of modeling
pedestrians for applications like autonomous vehicles, ur-
ban planning, and architectural design. An important fea-
ture of such synthesis is controllability – generating tra-
∗Equal contribution
jectories that meet user-defined objectives, edits, or con-
straints. For example, a user may place specific waypoints
for characters to follow, specify social groups for pedestri-
ans to travel in, or define a social distance to maintain.
Attaining controllability is straightforward for algorith-
mic or rule-based models of human behavior, since they
have built-in objectives. In the simplest case, human tra-
jectories can be determined by the shortest paths between
control points [11], but more sophisticated heuristics have
also been developed for pedestrians [2,14], crowds [22,46],
and traffic [29, 53]. Unfortunately, algorithmically gener-
ated trajectories often appear unnatural. Learning-based ap-
proaches, on the other hand, can improve naturalness by
mimicking real-world data. These methods often focus on
short-term trajectory prediction using a single forward pass
of a neural network [1, 10, 49, 61]. However, the ability to
control these models is limited to sampling from an out-
put trajectory distribution [34,58] or using an expensive la-
tent space traversal [45]. As a result, learning-based meth-
ods can predict implausible motions such as collisions with
obstacles or between pedestrians. This motivates another
notion of controllability – maintaining realistic trajectories
during agent-agent and agent-environment interactions.
In this work, we are particularly interested in using con-
trollable pedestrian trajectory models for character anima-
tion. We envision a simple interface where a user provides
high-level objectives, such as waypoints and social groups,
and a system converts them to physics-based full-body hu-
man motion. Compared to existing kinematic motion mod-

els [19, 27, 42], physics-based methods have the potential
to produce high-quality motion with realistic subtle behav-
iors during transitions, obstacle avoidance, traversing un-
even terrains, etc. Although there exist physics-based ani-
mation models [12, 27, 39–41, 57], controlling their behav-
ior requires using task-specific planners that need to be re-
trained for new tasks, terrains, and character body shapes.
We develop a generative model of trajectories that is data
driven, controllable, and tightly integrated with a physics-
based animation system for full-body pedestrian simulation
(Fig. 1). Our method enables generating pedestrian trajec-
tories that are realistic and amenable to user-defined objec-
tives at test time. We use this trajectory generator as a plan-
ner for a physics-based pedestrian controller, resulting in a
closed-loop controllable pedestrian animation system.
For trajectory generation, we introduce a TRAjectory
Diffusion Model for Controllable PEdestrians (TRACE).
Inspired by recent successes in generating trajectories
through denoising [9, 20, 64], TRACE generates the future
trajectory for each pedestrian in a scene and accounts for
the surrounding context through a spatial grid of learned
map features that is queried locally during denoising. We
leverage classifier-free sampling [17] to allow training on
mixed annotations (e.g., with and without a semantic map),
which improves controllability at test time by trading off
sample diversity with compliance to conditioning. User-
controlled sampling from TRACE is achieved through test-
time guidance [7,17,18], which perturbs the output at each
step of denoising towards the desired objective. We extend
prior work [20] by introducing several analytical loss func-
tions for pedestrians and re-formulating trajectory guidance
to operate on clean trajectory outputs from the model [18],
improving sample quality and adherence to user objectives.
For character animation, we develop a general-purpose
Pedestrian Animation ControllER (PACER) capable of
driving physics-simulated humanoids with diverse body
types to follow trajectories from a high-level planner. We
focus on (1) motion quality: PACER learns from a small
motion database to create natural and realistic locomotion
through adversarial motion learning [40,41]; (2) terrain and
social awareness: trained in diverse terrains with other hu-
manoids, PACER learns to move through stairs, slopes, un-
even surfaces, and to avoid obstacles and other pedestrians;
(3) diverse body shapes: by training on different body types,
PACER draws on years of simulation experience to control
a wide range of characters; (4) compatibility with high-level
planners: PACER accepts 2D waypoints and can be a plug-
in model for any 2D trajectory planner.
We demonstrate a controllable pedestrian animation sys-
tem using TRACE as a high-level planner for PACER, the
low-level animator. The planner and controller operate in
a closed loop through frequent re-planning according to
simulation results. We deepen their connection by guiding
TRACE with the value function learned during RL training
of PACER to improve animation quality in varying tasks.
We evaluate TRACE on synthetic [2] and real-world pedes-
trian data [3, 26, 38], demonstrating its flexibility to user-
specified and plausibility objectives while synthesizing re-
alistic motion. Furthermore, we show that our animation
system is capable and robust with a variety of tasks, terrains,
and characters. In summary, we contribute (1) a diffusion
model for pedestrian trajectories that is readily controlled at
test time through guidance, (2) a general-purpose pedestrian
animation controller for diverse body types and terrains, and
(3) a pedestrian animation system that integrates the two to
drive simulated characters in a controllable way.
2. Related Work
Pedestrian Trajectory Prediction.
Modeling high-level
pedestrian behavior has been extensively studied in the
context of motion prediction (forecasting).
Approaches
range from physics and planning-based [13, 14, 55] to re-
cent learned methods [1,5,24,49,61]. We refer the reader to
the thorough survey by Rudenko et al. [47] for an overview,
and focus this discussion on controllability. Most forecast-
ing work is motivated by planning for autonomous vehi-
cles (AVs) or social robots [10] rather than controllability
or longer-term synthesis. Rule-based models for pedestri-
ans [2, 22, 46] and vehicle traffic [29, 53] can easily incor-
porate user constraints [25] making them amenable to con-
trol. However, the trajectories of these approaches are not
always human-like; methods have even been developed to
choose the best simulation method and tune parameters to
make crowd scenarios more realistic [21].
Data-driven methods produce human-like motions, but
neural network-based approaches are difficult to explicitly
control. Some works decompose forecasting into goal pre-
diction followed by trajectory prediction based on goals [6,
34]. These models offer limited control by selecting goal lo-
cations near a target or that minimizes an objective (e.g. col-
lisions) [58]. Synthesized pedestrian behavior can also be
controlled by strategically choosing a starting location [43].
STRIVE [45] showed that a VAE trajectory model can be
controlled through test-time optimization in the learned la-
tent space. Reinforcement learning (RL) agents can be con-
trolled in crowd simulations by incorporating tasks into re-
ward functions for training [23]. By varying the weights
of different rewards, the characters can be controlled to ex-
hibit one of several behaviors at test time [37]. Our method,
TRACE, trains to mimic trajectories from data and is agnos-
tic to any task: all controls are defined at test time, allowing
flexibility to new controls after training. Instead of lengthy
test-time optimization, we use guidance for control.
Controllable Character Animation. Full-body pedestrian
animation typically involves a high-level task (e.g. trajec-
tory following, obstacle avoidance) and low-level body con-

trol. Some methods solve both with a single network that
implicitly uses high-level planning and low-level animation.
GAMMA [63] trains a kinematic model to go to waypoints,
while PFNN [19] follows gamepad inputs. Physics-based
humanoid controllers such as AMP [41] train different mod-
els for each task, limiting their general applicability.
Two-stage methods split the task into separate high-level
planning and low-level character control, where task infor-
mation is only used by the planner. Planning can be done
with traditional A* [11], using learned trajectory predic-
tion [4], searching in a pre-trained latent space [27, 40, 44,
57], or using hierarchical RL [12,39,40,42,57]. DeepLoco
[39], Haworth et al. [12], and ASE [40] utilize hierarchical
RL to achieve impressive dynamic control for various tasks.
They require lengthy training for both low-level and high-
level controllers and often jointly train as a final step. They
must also train different planners for different tasks.
Our approach follows the two-stage paradigm, with the
distinction that both our high-level (TRACE) and low-
level (PACER) models consume task information for pedes-
trian navigation:
through test-time guidance and map-
conditioned path following, respectively.
TRACE and
PACER are unaware of each other at training time, yet can
be tightly integrated in a closed loop: trace-pace-retrace.
Diffusion Models and Guidance.
Diffusion models
have shown success in generating images [16, 36, 54],
videos [15], and point clouds [62].
Guidance has been
used for test-time control in several ways: classifier [7] and
classifier-free [17] guidance reinforce input conditioning,
while reconstruction guidance [18] has been used for co-
herent video generation. Gu et al. [9] adapt the diffusion
framework for short-term pedestrian trajectory forecasting
conditioned on past trajectories. Diffuser [20] generates tra-
jectories for planning and control in robotics applications
with test-time guidance. Closest to ours is the concurrent
work of CTG [64], which builds on Diffuser to develop
a controllable vehicle traffic model, focusing on following
formalized traffic rules like speed limits. Our method con-
tains several key differences: we encode map conditioning
into an expressive feature grid queried in denoising, we use
classifier-free sampling to enable multi-dataset training and
test-time flexibility, we re-formulate guidance to operate on
clean model outputs, and we link with a low-level animation
model using value function guidance.
3. Method
To model high-level pedestrian behavior, we first intro-
duce the controllable trajectory diffusion model (TRACE).
In Sec. 3.2, we detail our low-level physics-based pedes-
trian controller, PACER, and in Sec. 3.3 how they can be
combined into an end-to-end animation system.
3.1. Controllable Trajectory Diffusion
Problem Setting. Our goal is to learn high-level pedestrian
behavior in a way that can be controlled at test time. For
pedestrian animation, we focus on two types of control: (1)
user specification, e.g., goal waypoints, social distance, and
social groups, and (2) physical plausibility, e.g., avoiding
collisions with obstacles or between pedestrians.
We formulate synthesizing pedestrian behavior as an
agent-centric trajectory forecasting problem. At each time
step, the model outputs a future trajectory plan for a tar-
get ego agent conditioned on that agent’s past, the past tra-
jectories of all neighboring agents, and the semantic map
context. Formally, at timestep t we want the future state tra-
jectory τ s = [st+1
st+2
. . .
st+Tf ] over the next Tf
steps where the state s = [x
y
θ
v]T includes the 2D
position (x, y), heading angle θ, and speed v. We assume
this state trajectory is actually the result of a sequence of
actions [64] defined as τ a = [at+1
at+2
. . .
at+Tf ]
where each action a = [˙v
˙θ]T contains the acceleration ˙v
and yaw rate ˙θ. The state trajectory can be recovered from
the initial state and action trajectory as τ s = f(st, τ a) us-
ing a given dynamics model f. The full state-action tra-
jectory is then denoted as τ = [τ s; τ a]. To predict the
future trajectory, the model receives as input the past state
trajectory of the ego pedestrian xego = [st−Tp
. . .
st]
along with the past trajectories of N neighboring pedestri-
ans Xneigh = {xi}N
i=1. It also gets a crop of the rasterized
semantic map M ∈RH×W ×C in the local frame of the
ego pedestrian at time t. These inputs are summarized as
the conditioning context C = {xego, Xneigh, M}.
Our key idea is to train a diffusion model to condition-
ally generate trajectories, which can be guided at test time
to enable controllability. For simplicity, the following for-
mulation uses the full trajectory notation τ, but in prac-
tice, the state trajectory is always a result of actions, i.e.,
diffusion/denoising are on τ a which determines the states
through f. Next, we summarize our diffusion framework,
leaving the details to the supplementary material.
3.1.1
Trajectory Diffusion Model
We build on Diffuser [20] and generate trajectories through
iterative denoising, which is learned as the reverse of a pre-
defined diffusion process [16,51]. Starting from a clean fu-
ture trajectory τ 0 ∼q(τ 0) sampled from the data distri-
bution, the forward noising process produces a sequence of
progressively noisier trajectories (τ 1, . . . , τ k, . . . , τ K) by
adding Gaussian noise at each process step k:
q(τ 1:K | τ 0) :=
K
Y
k=1
q(τ k | τ k−1)
q(τ k | τ k−1) := N(τ k;
p
1 −βkτ k−1, βkI)
(1)
where βk is the variance at each step of a fixed schedule,
and with a large enough K we get q(τ K) ≈N(τ K; 0, I).

Figure 2. Trajectory diffusion model (TRACE). Future trajectory denoising is conditioned on past and neighbor motion by adding processed
features to intermediate U-Net features. Map conditioning is provided through a feature grid queried along the noisy input trajectory.
TRACE learns the reverse of this process so that the sam-
pled noise can be denoised into plausible trajectories. Each
step of this reverse process is conditioned on C:
pϕ(τ k−1 | τ k, C) := N(τ k−1; µϕ(τ k, k, C), Σk)
(2)
where ϕ are model parameters and Σk is from a fixed sched-
ule. TRACE learns to parameterize the mean of the Gaus-
sian distribution at each step of the denoising process.
Training and Classifier-Free Sampling. Importantly for
guidance, the network does not directly output µ. Instead,
at every step it learns to predict the final clean trajectory τ 0,
which is then used to compute µ [36]. Training supervises
this network output ˆτ 0 with ground truth future trajectories
(i.e. denoising score matching [16,52,56]):
L = Eϵ,k,τ 0,C

||τ 0 −ˆτ 0||2
(3)
where τ 0 and C are sampled from the training dataset, k ∼
U{1, 2, . . . , K} is the step index, and ϵ ∼N(0, I) is used
to corrupt τ 0 to give the noisy input trajectory τ k.
Our training procedure allows the use of classifier-free
sampling1 at test time, which has been shown to improve
compliance to conditioning in diffusion models [17]. We
simultaneously train both a conditional model µϕ(τ k, k, C)
and unconditional model µϕ(τ k, k) by randomly dropping
out conditioning during training. At test time, predictions
from both models are combined with weight w as:
˜ϵϕ = ϵϕ(τ k, k, C) + w
 ϵϕ(τ k, k, C) −ϵϕ(τ k, k)

(4)
where ϵϕ is the model’s prediction of how much noise was
added to the clean trajectory to produce the input τ k; it is
straightforward to compute from µϕ [36].
Note that w>0 and w<0 increase and decrease the effect
of conditioning, respectively, while w=0 and w=−1 result
in the purely conditional or unconditional model, respec-
tively. This flexibility allows a user to trade off respecting
1we refer to it as “sampling” instead of the common term “guid-
ance” [17] to avoid confusion with the guidance introduced in Sec. 3.1.2
conditioning with trajectory diversity, which benefits con-
trollability (see Sec. 4.2). This approach also enables train-
ing on multiple distinct datasets with varying annotations:
conditioning is already being dropped out randomly, so it is
easy to use mixed data with subsets of the full conditioning.
Since there are pedestrian datasets with diverse motions but
no semantic maps [26,38], and others with limited motions
but detailed maps [3], we find mixed training is beneficial
to boost diversity and controllability (see Sec. 4.2).
Architecture. As shown in Fig. 2, TRACE uses a U-Net
similar to [20] that has proven effective for trajectories. The
input trajectory τ k at step k is processed by a sequence of
1D temporal convolutional blocks that progressively down
and upsample the sequence in time, leveraging skip con-
nections. A key challenge is how to condition the U-Net
on C to predict trajectories that comply with the map and
other pedestrians. To incorporate step k, ego past xego, and
neighbor past Xneigh, we use a common approach [18, 20]
that extracts a single conditioning feature and adds it to the
intermediate trajectory features within each convolutional
block. For the map M, we encode with a 2D convolu-
tional network into a feature grid, where each pixel contains
a high-dimensional feature. At step k of denoising, each 2D
position (x, y) ∈τ k is queried by interpolating into the grid
to give a feature trajectory, which is concatenated to τ k and
becomes the U-Net input. Intuitively, this allows learning a
localized representation that can benefit subtle map interac-
tions such as obstacle avoidance.
3.1.2
Controllability through Clean Guidance
After training TRACE to generate realistic trajectories, con-
trollability is implemented through test-time guidance. In-
tuitively, guidance nudges the sampled trajectory at each
step of denoising towards a desired outcome. Let J (τ) be
a guidance loss function measuring how much a trajectory
τ violates a user objective. This may be learned [20] or an
analytical differentiable function [64]. Guidance uses the
gradient of J to perturb the predicted mean from the model
at each denoising step such that the right side of Eq. (2)

Figure 3. Pipeline: Pedestrian Animation Controller (PACER).
becomes N(τ k−1; ˜µϕ(τ k, k, C), Σk) where ˜µ is the per-
turbed (guided) mean. Prior work [20,64] directly perturbs
the noisy network-predicted mean with
˜µ = µ −αΣk∇µJ (µ)
(5)
where α determines the guidance strength. Note that Eq. (5)
evaluates J at the noisy mean, so learned loss functions
must be trained at varying noise levels and analytic loss
functions may suffer from numerical issues.
To avoid this, we build upon “reconstruction guidance”,
which operates on the clean model prediction ˆτ 0 [18]. We
extend the guidance formulation introduced in [18] for tem-
poral video upsampling to work with arbitrary loss func-
tions. At each denoising step with input τ k, we first perturb
the clean trajectory predicted from the network ˆτ 0 with
˜τ 0 = ˆτ 0 −αΣk∇τ kJ (ˆτ 0),
(6)
then compute ˜µ in the same way as we would in Eq. (2), i.e.,
as if ˜τ 0 were the output of the network. Note that the gra-
dient is evaluated wrt the noisy input trajectory τ k rather
than the clean ˆτ 0, requiring backpropagation through the
denoising model. We formulate several analytical guidance
objectives like waypoint reaching, obstacle avoidance, col-
lision avoidance, and social groups (see Sec. 4.1, 4.2). A
learned RL value function can also be used (Sec. 4.3).
3.2. Physics-Based Pedestrian Animation
To enable full-body pedestrian simulation, we design the
Pedestrian Animation ControllER (PACER) to execute the
2D trajectories generated by TRACE in a physics simulator.
Background:
Goal-Conditioned RL. Our framework
(Fig. 3) follows the general goal-conditioned reinforce-
ment learning framework, where a goal-conditioned policy
πPACER is trained to follow 2D target trajectories specified
by τ s. The task is formulated as a Markov Decision Pro-
cess (MDP) defined by a tuple M = ⟨S, A, T , R, γ⟩of
states, actions, transition dynamics, reward function, and
discount factor. The state S, transition dynamics T , and re-
ward R are calculated by the environment based on the cur-
rent simulation and goal, while the action A is computed
by the policy πPACER. The policy’s objective is to maximize
the discounted return E
hPT
t=1 γt−1rt
i
where rt is the re-
ward per timestep. We utilize Proximal Policy Optimization
(PPO) [50] to find the optimal control policy πPACER.
Terrain, Social, and Body Awareness. To create a con-
troller that can simulate crowds in realistic 3D scenes
(e.g. scans, neural reconstructions, or artist-created meshes
(Fig. 1)), our humanoid must be terrain aware, socially
aware of other agents, and support diverse body types. We
use a humanoid model that conforms to the kinematic struc-
ture of SMPL [28], and is automatically generated using
a procedure similar to [30, 31, 60].
Our control policy
πPACER(at|ht, ot, β, τ s) is conditioned on the state of the
simulated character ht, environmental features ot, body
type β, and goal trajectory τ s. The environment input is
a rasterized local height and velocity map of size ot ∈
R64×64×3, which gives agents crucial information about
their surroundings. To allow for social awareness, nearby
humanoids are represented as a cuboid and rendered on the
global height map. In this way, each humanoid views other
people as dynamic obstacles to avoid. Obstacle and inter-
personal avoidance are learned by using obstacle collision
as a termination condition. By conditioning and training
with different body parameters β our policy learns to adapt
to characters with diverse morphologies.
Realistic Motion through Adversarial Learning. To learn
the optimal control policy πPACER that (1) follows a 2D tra-
jectory closely and (2) creates realistic pedestrian motions,
we follow Adversarial Motion Prior (AMP) [41]. AMP uses
a motion discriminator to encourage the policy to generate
motions that are similar to the movement patterns contained
in a dataset of motion clips recorded by human actors. The
discriminator D(ht−10:t, at) is then used to specify a mo-
tion style reward ramp
t
for training the policy.
The style
reward is combined with a trajectory following reward rτ
t
and an energy penalty renergy
t
[8] to produce the total reward
rt = ramp
t
+ rτ
t + renergy
t
. To mitigate artifacts arising from
asymmetric gaits, such as limping, we utilize the motion-
symmetry loss proposed by [59]:
Lsym(θ) =∥πPACER(ht, ot, β, τ s)−
Φa(πPACER(Φs(ht, ot, β, τ s)))∥2,
(7)
where Φs and Φa mirror the state and action along the char-
acter’s sagittal plane. This loss encourages the policy to
produce more symmetric motions, leading to natural gaits.
During training, random terrains are generated following
the procedure used in [48]. We create stairs, slopes, un-
even terrains, and obstacles consisting of random polygons.
Character morphology is also randomized by sampling a
gender and body type from the AMASS dataset [32]. The
policy and discriminator are then conditioned on the SMPL
gender and body shape β parameters.
More details are
available in the supplementary material.

Figure 4.
Guidance results on ORCA-Maps.
For VAE and
TRACE, 20 samples are visualized for each pedestrian (the boxes)
along with the final trajectory chosen via filtering which is bolded.
3.3. Controllable Pedestrian Animation System
The high-level trajectory planning from TRACE is com-
bined with the low-level character control from PACER to
create an end-to-end pedestrian animation system. The two
components are trained independently, but at runtime they
operate in a closed feedback loop: PACER follows planned
trajectories for 2s before TRACE re-planning, taking past
character motion from PACER as input. By combining ter-
rain and social awareness of PACER with collision avoid-
ance guidance, both high and low-level systems are task-
aware and work in tandem to prevent collisions and falls.
Value Function as Guidance. To enable tighter two-way
coupling between TRACE and PACER, in Sec. 4.3 we ex-
plore using the value function learned during RL training
of PACER to guide trajectory diffusion. The value function
predicts expected future rewards and is aware of body pose
and surrounding terrain and agents. Using the value func-
tion to guide denoising encourages TRACE to produce tra-
jectories that are easier to follow and better suited to the cur-
rent terrain (which TRACE is unaware of otherwise). Un-
like Diffuser [20], which requires training a reward function
with samples from the diffusion model at varying noise lev-
els, our guidance (Eq. (6)) operates on clean trajectories so
we can use the value function directly from RL training.
4. Experiments
We first demonstrate the controllability of TRACE when
trained on synthetic (Sec. 4.1) and real-world (Sec. 4.2)
pedestrian data. Sec. 4.3 evaluates our full animation sys-
tem on several tasks and terrains. Video results are pro-
vided in the supplementary material.
Implementation Details. TRACE is trained to predict 5s
of future motion from 3s of past motion (both at 10Hz),
and uses K=100 diffusion steps. During training, map and
neighbor conditioning inputs are independently dropped
with 10% probability. At test time, we sample (and guide)
multiple future trajectories for each pedestrian in a scene
and choose one with the lowest guidance loss, which we re-
fer to as filtering. PACER operates at 30Hz; we randomly
sample terrain, body type, and procedural 2D trajectories
during training and use a dataset of locomotion sequences
from AMASS [32]. All physics simulations are performed
using NVIDIA’s Isaac Gym simulator [33].
Datasets.
The ORCA dataset (Sec. 4.1) contains syn-
thetic trajectory data from 10s scenes generated using the
ORCA crowd simulator [2]. Up to 20 agents are placed
in a 15m×15m environment with ≤20 static primitive ob-
stacles.
Agent placement and goal velocity, along with
obstacle placement and scale, are randomized per scene.
The dataset contains two distinct subsets: ORCA-Maps has
many obstacles but few agents, while ORCA-Interact has no
obstacles (i.e. no map annotations) but many agents.
For real-world data (Sec. 4.2), we use ETH/UCY and
nuScenes. ETH/UCY [26,38] is a common trajectory fore-
casting benchmark that contains scenes with dense crowds
and interesting pedestrian dynamics but does not have se-
mantic maps.
nuScenes [3] contains 20s driving scenes
in common street settings.
We convert the pedestrian
bounding-box annotations to 2D trajectories and use them
for training and evaluation. Detailed semantic maps are also
annotated with layers for roads, crosswalks, and sidewalks.
Metrics. We care about trajectory plausibility and meeting
user controls. Controllability is evaluated with a Guidance
Error that depends on the task: e.g., for avoidance objec-
tives this is collision rate, while the waypoint error measures
the minimum distance from the trajectory. Obstacle and
Agent Collision Rates measure the frequency of collisions.
Realism is measured at the dataset or trajectory level by
(1) computing the Earth Mover’s Distance (EMD) between
the generated and ground truth test-set histograms of tra-
jectory statistics (e.g. velocity, longitudinal/lateral accelera-
tion) [58], or (2) measuring the mean accelerations of each
trajectory, assuming pedestrians generally move smoothly.
4.1. Augmenting Crowd Simulation
We first evaluate TRACE trained on ORCA-Maps and
ORCA-Interact. These provide a clean test bed for compar-
isons since there is a clear definition of correct pedestrian
behavior – no obstacle or agent collisions are present in the
data. All methods operate in an open loop by predicting a
single 5s future for each pedestrian. This way, compound-
ing errors inherent to closed-loop operation are not a factor.
Results for single and multi-objective guidance on the
ORCA-Maps test set are shown in Tab. 1. TRACE is com-
pared to a VAE baseline [45] adapted to our setup, which
achieves controllability through test-time latent optimiza-
tion. This is a strong baseline that generally works well,
but requires expensive optimization at test time. We also

Guidance
Collision Rate
Realism (EMD)
Guide
Method
Error
Obstacle
Agent
Vel
Lon Acc
Lat Acc
None
VAE [45]
–
0.076
0.118
0.038
0.039
0.040
TRACE
–
0.050
0.132
0.029
0.008
0.009
Obstacle
VAE [45]
0.018
0.018
0.116
0.040
0.036
0.039
Avoid
TRACE-Filter
0.018
0.018
0.123
0.019
0.011
0.015
TRACE-Noisy
0.015
0.015
0.125
0.021
0.012
0.017
TRACE
0.014
0.014
0.124
0.020
0.011
0.017
Agent
VAE [45]
0.010
0.075
0.010
0.041
0.038
0.039
Avoid
TRACE-Filter
0.049
0.050
0.049
0.031
0.012
0.013
TRACE-Noisy
0.000
0.056
0.000
0.035
0.013
0.012
TRACE
0.000
0.058
0.000
0.025
0.010
0.012
Waypoint
VAE [45]
0.078
0.051
0.092
0.070
0.031
0.033
TRACE-Filter
0.333
0.046
0.112
0.044
0.013
0.013
TRACE-Noisy
0.129
0.052
0.110
0.067
0.038
0.033
TRACE
0.105
0.048
0.093
0.057
0.013
0.014
Waypoint
VAE [45]
0.207
0.021
0.015
0.053
0.032
0.032
& Obs Avoid
TRACE-Filter
0.527
0.023
0.096
0.025
0.014
0.016
& Agt Avoid
TRACE-Noisy
0.236
0.022
0.017
0.057
0.025
0.022
TRACE
0.211
0.021
0.009
0.036
0.007
0.009
Table 1. Guidance evaluation on ORCA-Maps dataset. TRACE
using full diffusion guidance improves upon VAE latent optimiza-
tion and selective sampling (TRACE-Filter) in terms of meeting
objectives, while maintaining strong realism.
Guidance
Realism (Mean)
Guide
Method
Train Data
w
Error
Lon Acc
Lat Acc
Waypoint
VAE [45]
Mixed
–
0.340
0.193
0.172
TRACE
nuScenes
-0.5
0.421
0.177
0.168
Mixed
0.0
0.551
0.159
0.145
Mixed
-0.5
0.366
0.140
0.132
Waypoint
VAE [45]
Mixed
–
0.962
0.443
0.441
perturbed
TRACE
nuScenes
-0.5
0.977
0.239
0.238
Mixed
0.0
1.129
0.233
0.218
Mixed
-0.5
0.802
0.212
0.204
Social
VAE [45]
Mixed
–
0.297
0.109
0.104
groups
TRACE
nuScenes
-0.5
0.287
0.155
0.158
Mixed
0.0
0.244
0.110
0.101
Mixed
-0.5
0.245
0.094
0.087
Table 2. Guidance evaluation on nuScenes. Training on mixed
data and using w<0 for classifier-free sampling are important to
achieve controllability for out-of-distribution objectives.
compare to two ablations: TRACE-Filter samples from the
diffusion model without guidance and chooses the best sam-
ple according to the guidance loss (similar to [58]), while
TRACE-Noisy uses the guidance formulated in Eq. (5) from
prior works [20, 64]. Models are trained on the combined
dataset of ORCA-Maps (with map annotations) and ORCA-
Interact (no map annotations). The guidance losses are:
None samples randomly with no guidance; Obstacle avoid
discourages collisions between map obstacles and pedes-
trian bounding boxes; Agent avoid discourages collisions
between pedestrians by denoising all their futures in a scene
jointly; Waypoint encourages a trajectory to pass through
a goal location at any point in the planning horizon. For
this experiment, the waypoint is set as the position of each
pedestrian at 4s into the future in the ground truth data.
These are in-distribution objectives, since they reinforce be-
havior already observed in the ground truth data.
In Tab. 1, TRACE successfully achieves all objectives
through the proposed guidance. It is competitive or bet-
ter than the VAE optimization in terms of guidance, while
maintaining velocity and acceleration distributions closer to
Figure 5. nuScenes results demonstrating flexibility of TRACE.
(a) Using mixed training and w=−0.5 is best for noisy waypoints.
(b) Social group guidance encourages sets of pedestrians to stay
close. (c) Mixed training (ETH/UCY+nuScenes) learns a more
diverse distribution as demonstrated by unconditional sampling.
ground truth as indicated by Realism. Fig. 4 shows that
random samples from the VAE contain collisions, and us-
ing latent optimization for controllability gives similar lo-
cal minima across samples thereby limiting diversity com-
pared to TRACE. Finally, using our proposed clean guid-
ance (Eq. (6)) instead of the noisy version produces consis-
tently better results in guidance and realism.
4.2. Real-world Data Evaluation
We next evaluate controllability when trained on real-
world data, and focus on out-of-distribution (OOD) guid-
ance objectives to emphasize the flexibility of our approach.
In this experiment, methods operate in a closed loop: pedes-
trians are rolled out for 10s and re-plan at 1Hz. Results on
a held out nuScenes split are shown in Tab. 2. We com-
pare TRACE trained on mixed data (ETH/UCY+nuScenes),
after training on nuScenes only, and using two differ-
ent classifier-free sampling weights w.
Along with in-
distribution Waypoint (now at 9s into the future), two addi-
tional objectives are evaluated: Waypoint perturbed uses
a noisily perturbed ground truth future position (at 9s), re-
quiring pedestrians to go off sidewalks or into streets to
reach the goal; Social groups specifies groups of agents to
stay close and travel together. Groups are set heuristically
based on spatial proximity and velocity at initialization.
In Tab. 2, we observe that OOD flexibility requires (1)
training on mixed data, and (2) classifier-free sampling.
Since nuScenes data is less diverse (people tend to follow
the sidewalk), TRACE trained on just nuScenes struggles

Figure 6. Our animation system enables avoiding obstacles, meeting goals, traversing variable terrains, and large crowds.
Fail
Traj Follow
Discrim
Terrain
Guide
Rate
Error
Reward
Random
Procedural
0.133
0.680
1.950
None
0.093
0.104
1.887
Waypoint
0.107
0.111
2.113
Obstacles
Procedural
0.307
0.948
2.278
None
0.125
0.093
2.512
Obs Avoid
0.063
0.089
2.521
Flat
Procedural
0.127
0.371
2.320
(Crowd)
None
0.087
0.082
2.374
Agt Avoid
0.013
0.071
2.402
Table 3. Closed-loop animation results. Our system successfully
follows waypoints and avoids collisions in a variety of terrains,
and additional guidance improves performance.
to hit perturbed waypoints. Though the VAE is trained on
mixed data, it struggles to produce diverse dynamics on the
nuScenes maps to achieve OOD objectives, even though it
uses 200 optimization steps (2× more than the diffusion
steps K=100 in TRACE). TRACE reaches OOD objec-
tives using classifier-free sampling with w=−0.5 to down-
weight the conditioning of the semantic map and leverage
diverse trajectories learned from ETH/UCY. The flexibility
of TRACE is further highlighted in Fig. 5.
4.3. Controllable Pedestrian Animation
Finally, we demonstrate our full controllable pedestrian
animation system. TRACE is trained on ORCA and used
as a planner for the pre-trained PACER without any fine-
tuning. We evaluate the animations by: Fail Rate measures
the fraction of agents that fall down or collide with an ob-
stacle or other agent, Trajectory Following Error measures
the average deviation of the character from TRACE’s plan,
and Discriminator Reward is the mean reward returned by
the adversarial motion prior used to train PACER, which
measures how human-like a generated motion appears.
Tab. 3 evaluates the animations from our system using
TRACE with and without guidance in various settings: Ran-
dom is an assortment of smooth and rough slopes and stairs
with varying difficulties, Obstacles is a flat terrain with
large obstacles, and Flat is a flat terrain with pedestrians
spawned in a crowd of 30. For each setting, 600 rollouts of
10s are simulated across 30 characters with random bodies
from AMASS [32]. To put the difficulty of environments
and discriminator rewards in context, we also include met-
rics when using the (terrain and obstacle unaware) Proce-
Guide
Waypoint
Fail
Traj Follow
Discrim
Terrain
Waypoint
Value
Error
Rate
Error
Reward
Random
√
0.541
0.107
0.111
2.113
√
√
0.481
0.100
0.112
2.162
Obstacles
√
1.065
0.220
0.138
2.552
√
√
0.929
0.178
0.113
2.609
Flat
√
0.248
0.063
0.084
2.555
(Crowd)
√
√
0.175
0.053
0.084
2.607
Table 4. Using the value function learned in RL training as guid-
ance improves quality of trajectory following and robustness to
varying terrains, obstacles, and other agents.
dural trajectory generation method used to train PACER.
Our combined system performs well in the physically-
simulated environment with TRACE providing easy-to-
follow trajectories resulting in high-quality animations from
PACER, as evaluated by the discriminator. Diffusion guid-
ance can further improve failure rates, especially for avoid-
ing agent collisions in dense crowds. Fig. 6 shows some
qualitative applications of our animation system and we
highly encourage viewing the supplementary video results
to qualitatively evaluate the motion quality. Tab. 4 shows
the effect of using the learned value function from train-
ing PACER as a guidance loss for TRACE. In each set-
ting, adding value guidance in addition to waypoint guid-
ance makes trajectories easier to follow, reduces failures,
and improves the discriminator reward. As a result, way-
point guidance error also improves.
5. Discussion
We have introduced a controllable trajectory diffusion
model, a robust physics-based humanoid controller, and an
end-to-end animation system that combines the two. This
represents an exciting step in being able to control the high-
level behavior of learned pedestrian models, and opens sev-
eral directions for future work. First is improving the ef-
ficiency of sampling from trajectory diffusion models to
make them real-time: TRACE currently takes 1-3s to sam-
ple for a single character, depending on the guidance used
(see the supplement for full analysis). Recent work in dif-
fusion model distillation [35] offers a potential solution. In
addition to high-level motion controllability, exploring how
diffusion models can be extended to low-level full-body
character control is an interesting next step.
Acknowledgments. Davis Rempe was supported by an NVIDIA
Graduate Fellowship. The authors thank Ziyuan Zhong and the AV
Research Group for helpful discussions on trajectory diffusion.

References
[1] Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan,
Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese. So-
cial lstm: Human trajectory prediction in crowded spaces. In
Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 961–971, 2016. 1, 2
[2] Jur van den Berg, Stephen J Guy, Ming Lin, and Di-
nesh Manocha.
Reciprocal n-body collision avoidance.
In Robotics Research: The 14th International Symposium
(ISRR), pages 3–19. Springer, 2011. 1, 2, 6
[3] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora,
Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi-
ancarlo Baldan, and Oscar Beijbom.
nuscenes: A multi-
modal dataset for autonomous driving. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition, pages 11621–11631, 2020. 2, 4, 6
[4] Zhe Cao, Hang Gao, Karttikeya Mangalam, Qi-Zhi Cai,
Minh Vo, and Jitendra Malik.
Long-term human motion
prediction with scene context. In European Conference on
Computer Vision, pages 387–404. Springer, 2020. 3
[5] Yuning Chai, Benjamin Sapp, Mayank Bansal, and Dragomir
Anguelov. Multipath: Multiple probabilistic anchor trajec-
tory hypotheses for behavior prediction. In Conference on
Robot Learning (CoRL), pages 86–99. PMLR, 2020. 2
[6] Patrick Dendorfer, Aljosa Osep, and Laura Leal-Taix´e. Goal-
gan: Multimodal trajectory prediction based on goal position
estimation. In Proceedings of the Asian Conference on Com-
puter Vision, 2020. 2
[7] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. Advances in Neural Informa-
tion Processing Systems, 34:8780–8794, 2021. 2, 3
[8] Zipeng Fu, Xuxin Cheng, and Deepak Pathak. Deep whole-
body control: Learning a unified policy for manipulation and
locomotion. ArXiv, abs/2210.10044, 2022. 5
[9] Tianpei Gu, Guangyi Chen, Junlong Li, Chunze Lin, Yong-
ming Rao, Jie Zhou, and Jiwen Lu.
Stochastic trajectory
prediction via motion indeterminacy diffusion. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 17113–17122, 2022. 2, 3
[10] Agrim Gupta, Justin Johnson, Li Fei-Fei, Silvio Savarese,
and Alexandre Alahi. Social gan: Socially acceptable tra-
jectories with generative adversarial networks. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, pages 2255–2264, 2018. 1, 2
[11] Mohamed Hassan, Duygu Ceylan, Ruben Villegas, Jun
Saito, Jimei Yang, Yi Zhou, and Michael J Black. Stochas-
tic scene-aware motion prediction.
In Proceedings of the
IEEE/CVF International Conference on Computer Vision,
pages 11374–11384, 2021. 1, 3
[12] M. Brandon Haworth, Glen Berseth, Seonghyeon Moon, Pet-
ros Faloutsos, and Mubbasir Kapadia. Deep integration of
physical humanoid control and crowd navigation. Proceed-
ings of the 13th ACM SIGGRAPH Conference on Motion,
Interaction and Games, 2020. 2, 3
[13] Dirk Helbing, Ill´es Farkas, and Tamas Vicsek. Simulating
dynamical features of escape panic. Nature, 407(6803):487–
490, 2000. 2
[14] Dirk Helbing and Peter Molnar.
Social force model for
pedestrian dynamics. Physical review E, 51(5):4282, 1995.
1, 2
[15] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang,
Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben
Poole, Mohammad Norouzi, David J Fleet, et al. Imagen
video: High definition video generation with diffusion mod-
els. arXiv preprint arXiv:2210.02303, 2022. 3
[16] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu-
sion probabilistic models. Advances in Neural Information
Processing Systems, 33:6840–6851, 2020. 3, 4
[17] Jonathan Ho and Tim Salimans.
Classifier-free diffusion
guidance. arXiv preprint arXiv:2207.12598, 2022. 2, 3, 4
[18] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William
Chan, Mohammad Norouzi, and David J Fleet. Video dif-
fusion models. arXiv preprint arXiv:2204.03458, 2022. 2, 3,
4, 5
[19] Daniel Holden, Taku Komura, and Jun Saito.
Phase-
functioned neural networks for character control.
ACM
Transactions on Graphics (TOG), 36(4):1–13, 2017. 2, 3
[20] Michael Janner, Yilun Du, Joshua B Tenenbaum, and Sergey
Levine. Planning with diffusion for flexible behavior synthe-
sis. International Conference on Machine Learning (ICML),
2022. 2, 3, 4, 5, 6, 7
[21] Ioannis Karamouzas, Nick Sohre, Ran Hu, and Stephen J
Guy. Crowd space: a predictive crowd analysis technique.
ACM Transactions on Graphics (TOG), 37(6):1–14, 2018. 2
[22] Jongmin Kim, Yeongho Seol, Taesoo Kwon, and Jehee
Lee. Interactive manipulation of large-scale crowd anima-
tion.
ACM Transactions on Graphics (TOG), 33(4):1–10,
2014. 1, 2
[23] Jaedong Lee, Jungdam Won, and Jehee Lee. Crowd simula-
tion by deep reinforcement learning. In Proceedings of the
11th Annual International Conference on Motion, Interac-
tion, and Games, pages 1–7, 2018. 2
[24] Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B
Choy, Philip HS Torr, and Manmohan Chandraker. Desire:
Distant future prediction in dynamic scenes with interacting
agents. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 336–345, 2017. 2
[25] Marilena Lemonari, Rafael Blanco, Panayiotis Charalam-
bous, Nuria Pelechano, Marios Avraamides, Julien Pettr´e,
and Yiorgos Chrysanthou. Authoring virtual crowds: A sur-
vey. In Computer Graphics Forum, volume 41, pages 677–
701. Wiley Online Library, 2022. 2
[26] Alon Lerner, Yiorgos Chrysanthou, and Dani Lischinski.
Crowds by example.
In Computer graphics forum, vol-
ume 26, pages 655–664. Wiley Online Library, 2007. 2, 4,
6
[27] Hung Yu Ling, Fabio Zinno, George Cheng, and Michiel Van
De Panne. Character controllers using motion vaes. ACM
Transactions on Graphics (TOG), 39(4):40–1, 2020. 2, 3
[28] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard
Pons-Moll, and Michael J. Black. Smpl: a skinned multi-
person linear model. ACM Trans. Graph., 34:248:1–248:16,
2015. 5

[29] Pablo Alvarez Lopez, Michael Behrisch, Laura Bieker-Walz,
Jakob Erdmann, Yun-Pang Fl¨otter¨od, Robert Hilbrich, Leon-
hard L¨ucken, Johannes Rummel, Peter Wagner, and Eva-
marie Wießner. Microscopic traffic simulation using sumo.
In 2018 21st international conference on intelligent trans-
portation systems (ITSC), pages 2575–2582. IEEE, 2018. 1,
2
[30] Zhengyi Luo, Ryo Hachiuma, Ye Yuan, and Kris Kitani.
Dynamics-regulated kinematic policy for egocentric pose es-
timation. In Advances in Neural Information Processing Sys-
tems, 2021. 5
[31] Zhengyi Luo, Shun Iwase, Ye Yuan, and Kris Kitani. Em-
bodied scene-aware human pose estimation. In Advances in
Neural Information Processing Systems, 2022. 5
[32] Naureen Mahmood, N. Ghorbani, N. Troje, Gerard Pons-
Moll, and Michael J. Black.
Amass: Archive of motion
capture as surface shapes.
2019 IEEE/CVF International
Conference on Computer Vision (ICCV), pages 5441–5450,
2019. 5, 6, 8
[33] Viktor Makoviychuk, Lukasz Wawrzyniak, Yunrong Guo,
Michelle Lu, Kier Storey, Miles Macklin, David Hoeller,
Nikita Rudin, Arthur Allshire, Ankur Handa, and Gavriel
State. Isaac gym: High performance gpu-based physics sim-
ulation for robot learning, 2021. 6
[34] Karttikeya Mangalam, Yang An, Harshayu Girase, and Jiten-
dra Malik. From goals, waypoints & paths to long term hu-
man trajectory forecasting. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pages 15233–
15242, 2021. 1, 2
[35] Chenlin Meng, Ruiqi Gao, Diederik P Kingma, Stefano Er-
mon, Jonathan Ho, and Tim Salimans.
On distillation of
guided diffusion models. arXiv preprint arXiv:2210.03142,
2022. 8
[36] Alexander Quinn Nichol and Prafulla Dhariwal. Improved
denoising diffusion probabilistic models.
In International
Conference on Machine Learning, pages 8162–8171. PMLR,
2021. 3, 4
[37] Andreas
Panayiotou,
Theodoros
Kyriakou,
Marilena
Lemonari, Yiorgos Chrysanthou, and Panayiotis Char-
alambous.
Ccp: Configurable crowd profiles.
In ACM
SIGGRAPH 2022 Conference Proceedings, pages 1–10,
2022. 2
[38] Stefano Pellegrini, Andreas Ess, Konrad Schindler, and Luc
Van Gool. You’ll never walk alone: Modeling social behav-
ior for multi-target tracking. In 2009 IEEE 12th international
conference on computer vision, pages 261–268. IEEE, 2009.
2, 4, 6
[39] Xue Bin Peng, Glen Berseth, KangKang Yin, and Michiel
van de Panne. Deeploco: Dynamic locomotion skills using
hierarchical deep reinforcement learning. ACM Transactions
on Graphics (Proc. SIGGRAPH 2017), 36(4), 2017. 2, 3
[40] Xue Bin Peng, Yunrong Guo, Lina Halper, Sergey Levine,
and Sanja Fidler. Ase: Large-scale reusable adversarial skill
embeddings for physically simulated characters. ACM Trans.
Graph., 41(4), July 2022. 2, 3
[41] Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, and
Angjoo Kanazawa. Amp: Adversarial motion priors for styl-
ized physics-based character control. ACM Trans. Graph.,
40(4), July 2021. 2, 3, 5
[42] Maria Priisalu, Ciprian Paduraru, Aleksis Pirinen, and Cris-
tian Sminchisescu. Semantic synthesis of pedestrian locomo-
tion. In Proceedings of the Asian Conference on Computer
Vision, 2020. 2, 3
[43] Maria Priisalu, Aleksis Pirinen, Ciprian Paduraru, and Cris-
tian Sminchisescu. Generating scenarios with diverse pedes-
trian behaviors for autonomous vehicle testing. In Confer-
ence on Robot Learning, pages 1247–1258. PMLR, 2022. 2
[44] Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang,
Srinath Sridhar, and Leonidas J. Guibas. Humor: 3d human
motion model for robust pose estimation. In International
Conference on Computer Vision (ICCV), 2021. 3
[45] Davis Rempe, Jonah Philion, Leonidas J. Guibas, Sanja Fi-
dler, and Or Litany. Generating useful accident-prone driving
scenarios via a learned traffic prior. In Conference on Com-
puter Vision and Pattern Recognition (CVPR), 2022. 1, 2, 6,
7
[46] Zhiguo Ren, Panayiotis Charalambous, Julien Bruneau,
Qunsheng Peng, and Julien Pettr´e. Group modeling: A uni-
fied velocity-based approach. In Computer Graphics Forum,
volume 36, pages 45–56. Wiley Online Library, 2017. 1, 2
[47] Andrey Rudenko, Luigi Palmieri, Michael Herman, Kris M
Kitani, Dariu M Gavrila, and Kai O Arras. Human motion
trajectory prediction: A survey. The International Journal of
Robotics Research, 39(8):895–935, 2020. 2
[48] Nikita Rudin, David Hoeller, Philipp Reist, and Marco Hut-
ter. Learning to walk in minutes using massively parallel
deep reinforcement learning, 2021. 5
[49] Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and
Marco Pavone. Trajectron++: Dynamically-feasible trajec-
tory forecasting with heterogeneous data. In European Con-
ference on Computer Vision, pages 683–700. Springer, 2020.
1, 2
[50] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Rad-
ford, and Oleg Klimov. Proximal policy optimization algo-
rithms. ArXiv, abs/1707.06347, 2017. 5
[51] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,
and Surya Ganguli.
Deep unsupervised learning using
nonequilibrium thermodynamics. In International Confer-
ence on Machine Learning, pages 2256–2265. PMLR, 2015.
3
[52] Yang Song and Stefano Ermon. Generative modeling by esti-
mating gradients of the data distribution. Advances in Neural
Information Processing Systems, 32, 2019. 4
[53] Martin Treiber, Ansgar Hennecke, and Dirk Helbing. Con-
gested traffic states in empirical observations and micro-
scopic simulations. Physical review E, 62(2):1805, 2000. 1,
2
[54] Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based
generative modeling in latent space. Advances in Neural In-
formation Processing Systems, 34:11287–11302, 2021. 3
[55] Jur Van den Berg, Ming Lin, and Dinesh Manocha. Recip-
rocal velocity obstacles for real-time multi-agent navigation.
In 2008 IEEE international conference on robotics and au-
tomation, pages 1928–1935. Ieee, 2008. 2

[56] Pascal Vincent. A connection between score matching and
denoising autoencoders. Neural computation, 23(7):1661–
1674, 2011. 4
[57] Jungdam Won, Deepak Gopinath, and Jessica Hodgins.
Physics-based character controllers using conditional vaes.
ACM Transactions on Graphics (TOG), 41(4):1–12, 2022.
2, 3
[58] Danfei Xu, Yuxiao Chen, Boris Ivanovic, and Marco Pavone.
Bits: Bi-level imitation for traffic simulation. arXiv preprint
arXiv:2208.12403, 2022. 1, 2, 6, 7
[59] Wenhao Yu, Greg Turk, and C. Karen Liu. Learning sym-
metric and low-energy locomotion. ACM Transactions on
Graphics (TOG), 37:1 – 12, 2018. 5
[60] Ye Yuan, Shih-En Wei, Tomas Simon, Kris Kitani, and Jason
Saragih. Simpoe: Simulated character control for 3d human
pose estimation. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
2021. 5
[61] Ye Yuan, Xinshuo Weng, Yanglan Ou, and Kris M Kitani.
Agentformer: Agent-aware transformers for socio-temporal
multi-agent forecasting. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pages 9813–
9823, 2021. 1, 2
[62] Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic,
Or Litany, Sanja Fidler, and Karsten Kreis.
Lion: Latent
point diffusion models for 3d shape generation. In Advances
in Neural Information Processing Systems (NeurIPS), 2022.
3
[63] Yan Zhang and Siyu Tang.
The wanderings of odysseus
in 3d scenes. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 20481–
20491, 2022. 3
[64] Ziyuan Zhong, Davis Rempe, Danfei Xu, Yuxiao Chen,
Sushant Veer, Tong Che, Baishakhi Ray, and Marco Pavone.
Guided conditional diffusion for controllable traffic simula-
tion. International Conference on Robotics and Automation
(ICRA), 2023. 2, 3, 4, 5, 7

