
Texts and Monographs in Computer Science 
Editor 
David Gries 
Advisory Board 
F. L. Bauer 
K. S. Fu 
J. J. Horning 
R. Reddy 
D. C. Tsichritzis 
W. M. Waite 

The AKM Series in 
Theoretical Computer Science 
A Subseries of Texts and Monographs in Computer Science 
A Basis for Theoretical Computer Science 
by M. A. Arbib, A. J. Kfoury, and R. N. Moll 
An Introduction to Computability Theory 
by A. J. Kfoury, R. N. Moll, and M. A. Arbib 
An Introduction to Formal Language Theory 
by R. N. Moll, M. A. Arbib, and A. J. Kfoury 

A Basis 
for Theoretical 
Computer Science 
Michael A. Arbib 
A. J. Kfoury 
Robert N. Moll 
With 49 Figures 
Springer-Verlag 
New York Heidelberg Berlin 

Michael A. Arbib 
Department of Computer and 
Information Science 
University of Massachusetts 
Amherst, MA 01003 
USA 
Robert N. Moll 
Department of Computer and 
Infotmation Science 
University of Massachusetts 
Amherst, MA 01003 
USA 
A. J. Kfoury 
Department of Mathematics 
Boston University 
Boston, MA 02215 
USA 
Series Editor 
David Gries 
Department of Computer Science 
Cornell University 
Upson Hall 
Ithaca, NY 14859 
USA 
AMS Subject Classification (1980): 68COl 68005 68F05 
(CR.) Computer Classification: 5.20 
With 49 Figures 
Library of Congress Cataloging in Publication Data 
Arbib, Michael A. 
A basis for theoretical computer science. 
(Texts and monographs in computer science) 
Bibliography: p. 
Includes index. 
1. Machine theory. 
11. Moll, Robert N. 
2. Formal languages. 
I. Kfoury, A. J. 
Ill. Title. 
IV. Series. 
QA267.A715 
001.64 
81-5688 
AACR2 
All rights reserved. 
No part of this book may be translated or reproduced in any 
form without permission from Springer-Verlag, 175 Fifth Avenue, 
New York, New York 10010, U.S.A. 
Â© 1981 by Springer-Verlag New York Inc. 
Softcover reprint of the hardcover 1 st edition 1981 
9 8 7 6 5 4 3 2 1 
ISBN-13: 978-1-4613-9457-0 
DOl: 10.1007/978-1-4613-9455-6 
e-ISBN-13: 978-1-4613-9455-6 

Preface 
Computer science seeks to provide a scientific basis for the study of inform a-
tion processing, the solution of problems by algorithms, and the design 
and programming of computers. The last forty years have seen increasing 
sophistication in the science, in the microelectronics which has made 
machines of staggering complexity economically feasible, in the advances 
in programming methodology which allow immense programs to be 
designed with increasing speed and reduced error, and in the development 
of mathematical techniques to allow the rigorous specification of program, 
process, and machine. The present volume is one of a series, The AKM 
Series in Theoretical Computer Science, designed to make key mathe-
matical developments in computer science readily accessible to under-
graduate and beginning graduate students. Specifically, this volume takes 
readers with little or no mathematical background beyond high school 
algebra, and gives them a taste of a number of topics in theoretical computer 
science while laying the mathematical foundation for the later, more detailed, 
study of such topics as formal language theory, computability theory, 
programming language semantics, and the study of program verification 
and correctness. 
Chapter 1 introduces the basic concepts of set theory, with special 
emphasis on functions and relations, using a simple algorithm to provide 
motivation. Chapter 2 presents the notion of inductive proof and gives the 
reader a good grasp on one of the most important notions of computer 
science: the recursive definition of functions and data structures. Chapter 2 
also introduces the reader to formal language theory, and to list processing. 
Chapter 3 examines trees, structures which recur again and again in com-
puter science, and shows how techniques for counting trees enable us to 
v 

VI 
Preface 
solve a whole range of interesting problems. We also give an example of 
"analysis of algorithms" -showing how counting the number of execution 
steps of an algorithm allows us to compare the efficiency of different ap-
proaches to a given problem. 
Chapter 4 looks at the role of the two element set in the analysis of 
switching circuits and in the proving of theorems. Chapter 5 gives us a more 
detailed study ofthe relations of Chapter 1, with special emphasis on equiva-
lence relations and partial order. We introduce lattices and Boolean algebras 
as classes of partially ordered sets of special interest to computer scientists. 
Finally we introduce Cantor's diagonal argument which not only shows that 
infinities come in different sizes, but also plays a vital role in computability 
theory. The last Chapter is an introduction to graph theory, motivated by a 
study of Euler's 1735 study of "The Seven Bridges of Konigsberg." We use 
matrices over semi rings to study the connectivity of graphs and the reacha-
bility problem for automata, and close by proving Kleene's theorem on the 
equivalence of finite-state languages and regular languages. More detailed 
outlines may be found at the start of each section. 
The book grew out of our teaching to classes over several years at the 
University of Massachusetts at Amherst. Our colleague, Edwina Rissland, 
taught from an earlier draft of the book and provided us with many con-
structive suggestions embodied in the published text. We thank our students 
for all that they taught us about what we had to teach them, and we thank 
Gwyn Mitchell, Martha Young and Stan Kulikowski for their efforts in 
typing the manuscript. 
July 1980 
M.A.A., A.J.K., R.N.M. 

Contents 
CHAPTER 1 
Sets, Maps, and Relations 
1.1 Sets 
1.2 Exponents and Series 
1.3 Maps and Relations 
CHAPTER 2 
Induction, Strings, and Languages 
2.1 Induction on the Natural Numbers 
2.2 The Strings Over an Arbitrary Set 
2.3 Languages and Automata: A First Look 
2.4 Context-Free Grammars 
2.5 Processing Lists 
CHAPTER 3 
Counting, Recurrences, and Trees 
3.1 Some Counting Principles 
3.2 Trees and Recurrences 
3.3 An Example of Algorithm Analysis 
CHAPTER 4 
Switching Circuits, Proofs, and Logic 
4.1 Truth Tables and Switching Circuits 
4.2 Proving Theorems 
1 
12 
15 
31 
32 
41 
47 
53 
60 
73 
73 
87 
102 
111 
111 
131 
vii 

viii 
CHAPTER 5 
Binary Relations, Lattices, and Infinity 
5.1 Equivalence Relations and Partial Orders 
5.2 Lattices and Boolean AIgebras 
5.3 An Introduction to Infinity 
5.4 Another Look at Trees 
CHAPTER 6 
Graphs, Matrices, and Machines 
6.1 An Invitation to Graph Theory 
6.2 Graphs and Matrices 
6.3 Finite-State Acceptors and Their Graphs 
Author Index 
Notation Index 
Subject Index 
Contents 
145 
145 
155 
160 
167 
175 
175 
186 
199 
209 
211 
213 

CHAPTER 1 
Sets, Maps, and Relations 
1.1 Sets 
1.2 Exponents and Series 
1.3 Maps and Relations 
There are two main languages in which theoretical computer science is 
expressed -
the language of sets and the language of numbers. The principal 
aim of this chapter is to set forth the basic concepts of set theory. Section 1.1 
introduces sets and subsets, and shows how to build up new sets from old 
ones by such operations as the Cartesian product, union, intersection, and 
set differences. Section 1.2 briefly summarizes fundamental facts about 
exponents, logarithms, and finite series. Section 1.3 introduces the basic 
notions of maps or functions, partial functions, and relations. The way in 
which computer programs transform input data provides examples of partial 
functions. Finding relations between items stored in a data base is an im-
portant task for computer science. 
1.1 Sets 
To motivate our introduction of set theory, we shall study a flow diagram 
(Figure 1) for dividing one number into another. The flow diagram accepts 
as input two integers, x and y (with x 2 0 and y > 0), and finally haIts 
after printing out two numbers rand q (r stands for "remainder"; q for 
"quotient.") The notation := can be read as "becomes." Thus r:= r - y 
does not mean that r equals r - y (this would be true only if y = 0, which 
cannot be true if y > 0). Instead, r := r - y means that we change the value 
of r so that it becomes equal to the old value of r less the old value of y. So 
if we start with r equal to 6, and y equal to 4, the instruction r:= r - y 
changes r to 2 (but leaves the value of y as 4). 
1 

2 
INPUT 
x ~ 0, y > 0 
q:=O 
r:=x 
r:= r - y 
q:= q + I 
1 Sets. Maps. and Relations 
false 
PRINT 
r, q 
Figure I A simple flow diagram for computing x mod y and x div y. 
After reading in its input, the program initializes r to equal x, and q to 
equal O. Each loop execution decreases r by y and increases q by 1. So, 
after n times round the loop q = n and r = x - n * y (using * to denote 
multiplication). The loop is traversed until r is less than y, so that on exit 
we have 
x = q * y + rand 0 ~ r < y 
(can you see why 0 ~ r?), which we may rewrite as 
q = x div y, the integer part of x divided by y; and 
r = x mod y, the remainder after x is divided by y. 
SETS AND SUBSETS 
We now explore some of the sets, functions, and relations that play a role in 
the program given in Figure 1. A set is simply a collection of objects. Sets are 
usually described by some specification that indicates whether or not a 
particular object belongs to (is a member of) the collection. The first set we 
meet in our example is the set of integers, which we shall write as Z. The 
program's two inputs, x and y, must be members of this set. However, by 
restricting x and y, we have constrained the program to deal exclusively 

1.1 Sets 
3 
with the set N of all non-negative integers -
these are called the "natural 
numbers." We can indicate the set N in two ways (at least!): 
N = {O, 1, 2, 3, ... } 
N = {XIXEZ and 
x ~ O}. 
In the first case, we display an explicit list of members of the set N. In 
the second case, we describe conditions which must be met in order for an 
element to belong to the set - "N is the set of all x such that x is an integer 
and x ~ 0." Here we use the general notation x E A for "x is a member of 
the set A," which we may also read as "x is in A" or "x belongs to A." The 
notation x ~ A indicates that x does not belong to A. Thus 3 E N but - 2 ~ N. 
More generally, if P(x) indicates some test which may be applied to suitable 
x's to yield an answer of true or false, then {x I P(x)} is the set of all x for 
which P(x) is true. For example 
{x I x E Z and x mod 2 = O} = the set of even integers; 
{x Ix E Z and x mod 2 = 1} = the set of odd integers; 
{xix E Z and 2 ~ x < 7} = {2, 3, 4, 5, 6}. 
Another set implicit in Figure 1 is the set 
fJI = {T, F} 
of truth values (where Tis short for true, F for false). This set is also denoted 
Boolean, and is often called the set of Boolean values in honor of the British 
mathematician and logician George Boole (1818-1864) whose book, An 
Investigation of the Laws of Thought, published in London in 1854, showed 
how the truth of propositions could be manipulated in an algebraic fashion. 
The resultant subject of propositional logic and its applications in computer 
science will occupy us in Chapter 4. The test r ~ y? takes on a value that is a 
member of the set Boolean. 
One important set (not explicitly mentioned in Figure 1) is the empty set 
0= { } 
which contains no elements. Just as 0 is a very useful number, so 0 is a 
very useful set: 
o = the set of American unicorns 
0= {XIXEN and x < O} 
and many other bizarre examples best left to the imagination of the reader. 
We saya set A is a subset of the set B, and write A c B(though some authors 
prefer the notation A Â£; B), if every element of A is also an element of B: 
x E A implies x E B. We say A is a proper subset of B if A c B but A =F B. 

4 
1 Sets, Maps, and Relations 
We note the following basic facts: 
1. For any set A, both 0 c A and AeA. 
2. For any two sets A and B, we have that both A c Band B c A are true 
iff (short for: "if and only if") A = B, i.e. iff every element of A is an 
element of B and vice versa. 
Notice that N c Z, and that the set of values that y can take on in our 
sample program -
yE {W I W > O} -
is a proper subset of x's possible values 
-xE{zlz~O}. 
We stress that the membership rule for a finite set given by an explicit 
list like {2, 3, 4, 5, 6} is simply" x E A iff x is on the list." Thus the set does 
not change if we alter the order of elements on the list or repeat elements: 
{2, 3, 4, 5, 6} = {2, 3, 6, 5, 4} = {6, 2, 6, 3, 5,4,2, 6} 
but the set will change if we add or remove elements: 
{2, 3,4, 5} i= {2, 3,4, 5, 6} 
{a, 2, 3, b, 4,5, 6} i= {2, 3,4,5, 6}. 
Thus a set is different from a sequence. A sequence is a list of elements 
which are placed in a specific order. We use the general notation 
for the sequence with Xl before Xz before X3 .... We say that two sequences 
are equal if they contain the same elements in the same order. Thus 
if m = n (the sequences have the same length, namely m) and Xl = YI' 
X Z = Yz,Â·Â·Â· ,and Xm = YnÂ· 
We use the term n-tuple for a sequence oflength n. Thus, an ordered pair 
is a 2-tuple. 
A sequence can be finite or it might never end, in which case we say it is 
infinite. For example, the sequence of all prime numbers (see Exercise 1) in 
increasing order is 
(2,3,5, 7, 11, 13, ... ) 
and the sequence never ends. But how do we know it never ends? The answer 
was given by Euclid, the "father of geometry," who lived in ancient Greece 
around 300 BC. His proof is an example of proof by contradiction or reductio 
ad absurdum (Latin for "reduction to an absurdity"). To prove some result P, 
by this method, we look at what happens if we start by assuming that P is not 
true. If this assumption leads to a contradiction, it was wrong to assume P 
was not true -
and we conclude that P must be true after all. 

1.1 Sets 
5 
EUCLID'S PROOF THAT THERE ARE INFINITELY MANY PRIMES. If there are only 
finitely many primes, we could write them down in increasing order as a 
finite sequence 
where PI = 2, P2 = 3, ... , and Pn is the largest prime. Now consider the 
number obtained by mUltiplying all these primes together and then adding 
one to the result: 
M = (PI * P2 * P3 * ... * Pn) + 1. 
For any prime number Pb we have M mod Pk = 1, so none of the primes on 
our list divides M evenly. Thus either M itself is a prime number not on our 
list, or it is a product of primes not on the list. This contradicts the assumption 
that there are finitely many primes. Thus the list of primes is infinite. 
0 
(The symbol 0 is used either to mark the end of a proof, or to indicate 
that any further details of the proof are left to the reader.) 
Given two sets A and B, we are often interested in the set, denoted A x B, 
of all ordered pairs (a, b) whose first element a is in A and whose second 
element b is in B: 
A x B = {(a,b)laEA,bEB}. 
This set is called the Cartesian product of A and B, in honor of the French 
mathematician and philosopher Rellt~ Descartes (1596-1650) who founded 
analytic geometry with the observation that the plane could (as we see in 
Figure 2) be represented as 
R x R = {(X,y)IXER,YER}, 
where R is the "real number line," that is, the set of all real numbers. The 
idea extends naturally to three-fold and indeed n-fold Cartesian products: 
A x B xC = {(a,b,c)laEA,bEB,CEC} 
y-axis -
a copy of the" real number line" R 
Y 1---........ (x, y) -
a typical point of R x R 
'-----'---_________ â¢ x-axis -
a copy of the 
x 
"real number line" R 
Figure 2 

6 
1 Sets, Maps, and Relations 
and 
Al X A2 X â¢â¢â¢ X An = {(al,a2, ... ,an)lalEA, ... ,anEAn}' 
It is often useful to view a Cartesian product as a set of samples. Each 
sample is obtained by selecting one element from each of the sets that make 
up the product. Thus if a E A, bE B, and eEC, then (a, b, c) is a "sample" 
from A x B x C, and b's position in this 3-tuple tells us that b came out of 
the second factor in the product, B. 
The Cartesian prpduct is an extremely valuable construction in mathe-
matics and computer science. It gives us an elegant and general notation for 
describing a great many familiar mathematical concepts and operations. 
For example, note that in Figure 1, the assignment r .= r - y operates on 
the ordered pair of integers (r, y) -
the variables on the right hand side of 
the assignment symbol -
to return the new value of r, so that we can think 
of this statement as "acting" on N x N. We return to this in Section 1.3. 
Let us consider another example, the set B of birthdates of people born 
in the 20th century. Since a birthdate is a triple of the form 
(month, day, year) 
we can think of B as a subset of the Cartesian product M x D x Y where 
the set M of months is {January, February, ... , December}, the set D of 
days is {I, 2, ... ,30, 31} and the set Y of years is {O, 1,2,3, ... , 99}. B is a 
proper subset of M x D x Y because, for example, (February, 29, 89) does 
not belong to B. 
Given a set A, we use fJJ A or 2A to denote the powerset of A, which is 
defined to be the set of all subsets of A. 
fJJA = 2A = {XIX c: A}. 
If A is a finite set (that is, we can count how many elements there are in A), 
we use I A I - read" the cardinality of A" - to denote the number of elements 
of A. For example 
I {2, 3, 2} I = 2. 
101 =0, 
I{{a, b}}1 = 1. 
(Make sure you understand the point of the first and third example.) It 
should be easy to see that if A and B are finite sets, then I A x B I = I A I * I B I. 
The O-element set 0 has one subset: 
fJJ0 = {0}, so that IfJJ01 = 2101, since 1 = 2Â°. 
The I-element set {a} has two subsets: 
fJJ{a} = {0, {a}}, so that IfJJ{a} 1= 2/(all, since 2 = 21. 

1.1 Sets 
7 
Figure 3 A "binary decision tree" for the 8 = 23 subsets of {ab a2, a3}. 
This suggests the general hypothesis that an n-element set has 2n elements. 
Before we give the general proof, look at Figure 3 to see how to systemat-
ically arrange the 8 subsets of the 3-element set {ai' a2, a3}' 
1 Fact. If A is afinite set with m elements, then A has 2m subsets. In symbols, 
we have 
12AI=21AI 
which explains the choice of the notation 2A for the powerset of A. 
PROOF. Suppose A = {ai' a2' ... , am}. Then we can divide 2A into 2 = 21 
collections: subsets of A which contain ai' and those which do not. Con-
sidering the next element a2 , we get 4 = 22 collections depending on which 
of a l and a2 are included in the subset. Continuing in this way, we finally 
see that there are 2m subsets of A, each determined by the choice of whether 
or not each aj will be included, as j runs from 1 to m. 
D 
We have already seen how to combine two sets to form their Cartesian 
product. We close this subsection by showing several other basic ways of 
combining sets. The shaded area in each of the diagrams below indicates 
the set determined by the definition. Such diagrams are called Venn diagrams 
for the British logician John Venn (1834-1923). 
The union of two sets A and B is the set of elements which belongs to at 
least one of them: 
AuB 
A u B = {xlxeA or xeB or both}. 

8 
1 Sets, Maps, and Relations 
More generally, given any collection A l, ... , An of sets, we define their 
union by the equation 
U Ai = {x!xEAifor at least one iwith 1 ~ i ~ n}. 
l:5i:5n 
The intersection of two sets A and B is the set of elements which belong 
to both of them: 
AnB 
A nB = {x!xEA andxEB}. 
We say that two sets are disjoint if they have no common elements, A n B 
=0Â· 
The set difference, A -
B, of two sets A and B (in that order) is the set 
of those elements of A that are not in B: 
A-B 
A - B = {x!xEA butxif=B}. 
Consider A = {l, 2, 3} and B = {3,4, 5}. Then A u B = {l, 2,3,4, 5} -
there is no trace of the fact that 3 was contributed by both A and B. Some-
times it is convenient to "tag" the elements of A and B so that the" history" 
of each element is preserved in the union. Let, then, t A and t B be distinct 
symbols, and replace A and B by the "tagged," and thus disjoint, copies 
A x {tA} = {Cl, tA), (2, tA), (3, tA)} 
B x {tB} = {(3, tB), (4, tB), (5, tBn. 
Then (A x {tA}) u (B x {tB}) = {Cl, tA), (2, tA), (3, tA), (3, lB), (4, tB), (5, tB)} 
does indeed maintain A and B as separate. 
More generally, given arbitrary sets A 1> â¢â¢â¢ , An we define their disjoint 
union LAi to be 
U Ai x {i} = {(x, i)!xEAi and 1 ~ i ~ n}. 
l~i~n 
We may also denote the union of A l, ... , An by Al U ... U An and their 
disjoint union by A 1 + ... + AnÂ· 

1.1 Sets 
9 
The disjoint union of A and B is the union of copies 
"tagged" to make them disjoint. 
â¢â¢ 
A+B 
Consider, for example, R, the "real line" or set â¬If real numbers. Then 
R u R = {xlxER or x ER} = R, a single line; R + R = {(x, l)lxER} u 
{(x, 2)lx ER}, which is a pair oflines 
typical point (x, 2) 
--------.. e--------R x {2} 
------__ e--------- R x {I} 
typical point (x, 1) 
(without disjoint unions there would be no railroads!); while R x R is the 
Cartesian plane of Figure 2. 
The reader should check the following simple numerical relationships. 
Take care to recognize when a symbol (such as + ) denotes a set operation. 
2 Fact. Let A and B be two finite sets, with I A I and I B I elements, respectively. 
Then: 
lA x BI = IAI * IBI 
IAuBI:::; IAI + IBI 
lA (") BI :::; the minimum aliA I and IBI 
lA -BI:::; IAI 
lA + BI = IAI + IBIÂ· 
o 
If we are specifically interested in subsets of a fixed set S (indicated by the 
rectangle of the Venn diagram), we write A as an abbreviation for S - A: 
A = {xlx~A} 
it being understood that the only x's we consider belong to S. 

10 
1 Sets, Maps, and Relations 
3 Fact. For all sets A and B (as subsets of a fixed" universe" S) we have 
AnB=BnA 
AuB=BuA 
B - (A - B) = B 
A=A 
AnA=0 
AuA = S. 
Other facts can be verified as exercises. 
EXERCISES FOR SECTION 1.1 
D 
1. An integer p > 1 is a prime if the only factorization of p as a product m * n has 
{m, n} = {p, I}. Thus 2, 3, and 5 are prime, but 4 = 2 * 2 and 6 = 2 * 3 are not. 
We say a number is composite ifit is not prime. 
(a) Write down {xix is prime and 1 < x < 50} 
(b) Write down {xix is composite and 1 < x ::;; 26} 
2. Let A = {xix E N and x < 50}. Write down the list of elements for: 
(a) A Il {xix mod 3 = I} 
(b) A Il {xix div 7 = 2} 
(c) A Il {xix div 7 = 8}. 
3.,(i) Let A = {{a, b, c}}. (a) WhatislAI? (b) Whatisl&'AI? 
(ii) LetB= {a,b,c}. (a) WhatislBI? (b) Whatisl&'BI? 
4. Write down all 8 elements of {a, b} x {a, b, c, d}. 
5. Let Ne be the set of all even natural numbers and No the set of all odd natural 
numbers. Describe the sets 
(a) No Il Ne; 
(b) Ne V No; 
(c) N V Ne; 
(d) N - Ne; 
(e) Nil Ne. 
6. It is true that A vB = B v A, and that All B = B Il A. We say that union (v) 
and intersection (Il) are commutative. Is it true that the set difference (-) is com-
mutative? Justify your answer with a careful argument. 
7. Verify from the definitions that 
(a) (A v B) v C = A v (B v C); 
(b) (A Il B) Il C = A Il (B Il C). 
These are associative laws. 
8. Use Venn diagrams to verify the so-called distributive laws: 
(a) A Il (B v C) = (A Il B) v (A Il C) -
we say that Il distributes over v. 
(b) A v (B Il C) = (A v B) Il (A v C) -
we say that v distributes over Il. 

1.1 Sets 
11 
(c) Point of comparison: For integers, we have a * (b + c) = a * b + a * c, that 
is, multiplication distributes over addition. Give a numerical example to show that 
it is not generally true that a + (b * c) = (a + b) * (a + c). 
9. Use Venn diagrams to verify (a) A u B = An E. Next, without using Venn dia-
grams, use (a) and the fact that A = A for any set A to deduce that (b) A n B = 
A u E. The two identities (a) and (b) are called De Morgan's laws after the British 
mathematician, logician, and author of A Budget of ParaiWxes, Augustus De 
Morgan (1806-1871). 
10. Find a set A with the property that A is disjoint from itself. 
11. We say that a number m divides a number n if m divides n without a remainder, 
i.e., if n mod m = O. What is the usual mathematical term for the following set 
A = {nIID(n)1 = 2} 
where 
D(n) ={mlmEN and m divides n} 
is the set of divisors of n? 
12. Let A I' ... , An be sets with I Ai I = mi for 1 ::;;; i ::;;; n. What is the cardinality of their 
disjoint union? 
13. Prove that for any two sets A and B 
IAnBI::;;; IAuBI. 
When will it be true that two finite sets A and B satisfy I A n B I = I A uBI? Write 
down a general condition. 
14. Let I A I be the number of elements in the set A. 
(a) Prove by reference to a Venn diagram that for any pair of finite sets A and B, 
we have 
IAuBI = IAI + IBI-IAnBIÂ· 
(b) If A and B are subsets of the set S, verify that 
lA n El = ISI -
IAI -
IBI + lA n BI 
is true as a direct consequence of (a). (Hint: Use De Morgan's law.) 
(c) Complete the equation 
IAuBuCl = IAI + IBI + ICI-'" + .... 
15. Give one element belonging to each of the sets given below. 
(a) N x Z x R 
(b) &,(N x N) 
(c) &'0 x N 
(d) (N x N) - (N -
{O, 1}) x N) 
(e) &'&'&'0 

12 
1 Sets, Maps, and Relations 
1.2 Exponents and Series 
EXPONENTS 
If we multiply n copies (with n ~ 1 in N) of the number m together, we call 
the result mn, which we read as m to the power n. We call n the exponent in 
this expression. We can extend this to any n in Z by the following rules 
mO = 1 
(1)-n 
mn =;;:; 
for n < 0 
for any non-zero number. What makes these definitions work is that they 
satisfy 
mn, +n2 = mn, * mn2 
for any m =I- 0, and any integers n1 and n2' To see this, consider 
(i) 
n1 and n2 both greater than 0: 
mn, +n2 = m * ... * m = m * ... * m * m * ... * m = mn, * mn2 
n1 times 
n2 times 
(ii) n2 = 0: 
mn'+"2 = m"'+o = m"' = m"' * 1 = m"' * mO = m"' * m"2 
(iii) n1 > -n2 > 0: 
(1)<-"2) 
m"' *;;:; 
= m"' * m"2. 
We leave the other cases to be checked by the reader. 
We can graph the powers of m for any non-zero number m, for both 
positive and negative values of the exponent which in this case we write as x. 
The graph of Figure 4 shows the situation for an m which is greater than 1. 
We have" exponential growth" as we go positive from 0, and "exponential 
decay" as we go negative from O. 
As a result of mathematical analysis, we can fit a special smooth curve 
through all the points (x, mX) for integers x, and so define mX for all real 
numbers x. Note that the curve shows mX increasing as x increases, with mX 
> 0 for all values of x. Thus to each y > 0 we can associate a unique x 
which satisfies y = mX. We call this number the logarithm of y to the base m 
and denote it by logm y. 
x = logm y if and only if y = mX. 

1.2 Exponents and Series 
13 
-3 
-2 
-1 
o 
2 
3 
X 
Figure 4 The curve of mX. 
The basic property of logarithms then corresponds to our fundamental law 
of exponents, mn, +n2 = mn, * mn2, namely 
logm(yl * Yz) = logm Yl + logm YzÂ· 
This says: to multiply two numbers we may add their logarithms, then see 
what number the result is the logarithm of. 
SUMMING SERIES 
We often encounter series of numbers built up in some regular way, and want 
a formula to express their sum. We show how to obtain formulas for two 
kinds of series -
arithmetic and geometric progressions. 
We say a series of numbers is an arithmetic progression if each term is 
obtained from the preceding term by adding the same number or increment. 
For example, the first 100 positive integers 
1, 2, 3, 4, ... , 99, 100 
form an arithmetic progression because each term is obtained from the 
previous term by adding 1. In general, an arithmetic progression takes the 
form 
1 
al , az, ... , an, 
with aj = a + U - l)h for 1 ~ j ~ n, 
where a is the first term, h is the increment, and n is the number of terms. 

14 
1 Sets, Maps, and Relations 
Let us write S for the sum of the series in 1. Then the sum of the terms in 
reverse order is also S and we have 
S = 
a 
+ 
(a + h) 
+ 
(a + 2h) 
+ ... + (a + (n -
2)h) + (a + (n -
l)h) 
S = (a + (n -
l)h) + (a + (n -
2)h) + (a + (n -
3)h) + ... + 
(a + h) 
+ 
a 
2S = (2a + (n -
l)h) + (2a + (n -
l)h) + (2a + (n -
l)h) + ... + (2a + (n -
l)h) + (2a + (n -
l)h) 
Thus 2S, double the sum, is equal to the sum of n terms, each of which is 
2a + (n - l)h, which equals a l + an' Hence 
2 
2S = n * [al + anJ 
S = [al + anJ * n. 
2 
To sum an arithmetic progression, add the first and last terms, 
multiply by the number of terms, and divide by 2. 
We can indeed see that 
1 + 2 = [1 + 2J * 2 = 3 
2 
1 + 2 + 3 = [1 + 3J * 3 = 6 
2 
[1 + 4J * 4 
1 + 2 + 3 + 4 = 
2 
= 10 
but it is good to have the general formula to tell us that 
1 + 2 + 3 + ... + 99 + 100 = [1 + 10~J * 100 = 5050. 
We say a series of numbers is a geometric progression if each term is 
obtained from the preceding term by multiplying by the same number or 
factor. For example, the series 
6, 12, 24,48, ... , 1536 
forms a geometric progression because each term is obtained from the 
previous term by doubling. In general, a geometric progression takes the 
form 
3 
where g is the first term, m is the factor, and n is the number of terms. 
Let us write S for the sum of the series in 3, and look at m times S: 
S = g + g . m + g . m2 + ... 
SÂ·m= 

1.3 Maps and Relations 
Thus S . m differs from S by adding 9 . mn and deleting g: 
so 
4 
SÂ·m=S+gÂ·mn-g 
S(m -
1) = Srn - S = g(mn -
1). 
S = g(mn - 1), 
(m -
1) 
the sum of a geometric series with first term g, factor m, and n terms. 
15 
Consider strings of bits, i.e., strings of O's and 1's. There are 2 strings of 
length 1: 
0, 1. 
There are 4 strings of length 2: 
00,01, 10, 11. 
There are 8 strings of length 3: 
000, 001, 010, 011, 100, 101, 110, 111. 
The number of strings of length s 3 is 
2 + 4 + 8 = 14 
which agrees with formula 4 for 9 = 2, m = 2 and n = 3: 
2 (23 -
1) = 2 x 7 = 14 
2 -
1 
. 
In general the number of strings of bits whose length is between 1 and n, 
inclusive, is 2(2n -
1)/(2 -
1) = 2Â· (2n -
1). 
EXERCISES FOR SECTION 1.2 
1. Given the digits 0, 1,2, how many sequences (called ternary sequences) are there of 
length ~n? 
2. Show that nn = mnl08mn. 
3. For n > 2 which is larger, n2n or (2n)n? 
1.3 Maps and Relations 
In a phone book, each person's name is assigned a phone number 
person H phone number of person. 
On a football team, each player is assigned a number 
player H number on uniform. 

16 
1 Sets. Maps. and Relations 
At a dance at which each person comes with a date of the opposite sex, 
we have an assignment of a man to each woman 
woman 1-+ man who is her date. 
In each case we have two sets A and B and a rule, which we denote f, 
that assigns to each element a of A a corresponding element f(a) of B. 
Returning to the flow diagram of Figure 1, we see that there are four 
assignments: 
(1) q:=O 
(2) 
r:=x 
(3) 
r:= r - y 
(4) q:= q + 1. 
In (1), we need no values of any program variables to determine the new 
value of q; in (2) and (4), we need the value of one variable; while in (3), we 
need the values of both rand y. Given the necessary data (zero, one, or two 
natural numbers), we perform an appropriate mathematical operation to 
find a new integer and use the result as the new value ofthe indicated variable. 
The notion of map (which we will also call function) introduced in the next 
definition generalizes the above concepts of both mathematical operation 
and "real-life" assignment. 
1 Definition. Given two sets A and B, a map or function f from A to B, 
denoted f: A --+ B, is an assignment to each element a in A of a single element 
in B. We may use the notation a 1-+ f(a) (note the different arrow) to indicate 
that f(a) in B is the value assigned to a; we call f(a) the image of a. A is 
called the domain off, and B is the codomain of f. The range of f, denoted by: 
f(A) = {blbEBandb = f(a) for some a in A} 
is the subset of B comprising the f-images of elements of A. This is the part of 
B that f actually "ranges over." 
We can picture a map f: A --+ B as in Figure S. Here we draw an arrow for 
each element a to its image f(a) in B. Note that exactly one arrow leaves each 
element in A, but that zero, one, or more than one arrow may terminate on a 
given element of B. 
The function is represented by a set of arrows from the domain to the 
co domain. Note that if A = 0, then there is exactly one map 0 --+ B, because 
the empty set of arrows is the only map possible (Figure Sb). On the other 
hand, if A =I- 0, there are no maps of the form A --+ 0 since every element 
of A must go somewhere, but with B = 0 there is no place for an arrow to 
go (Figure Sc). 
Let us use N 2 , the set of natural numbers two-at-a-time, as shorthand for 
N x N = {(m, n) I mEN and nE N}. Let NÂ°, the set of natural numbers 
none-at-a-time, denote a one-element set, whose single element is denoted A. 
(We shall justify this convention later; for now just notice that when we look 

1.3 Maps and Relations 
(a) 
(c) There are no maps A -+ 0 
for A :F 0. 
17 
uO 
(b) This unique map 0 -+ B 
has no arrows. 
(d) Choosing an element of B 
specifies a map {A} -+ B. 
Figure 5 Maps/: A -> B. 
at the powers of natural numbers, we take nO = 1 so that na+ b = na * nb is 
true if a = 0.) Note that an element, b, of a set B corresponds to a map from 
the one-element set to B; namely, the map f: {A} -+ B with f(A) = b. 
(Figure 5d). 
The mathematical operations involved in the assignments (1)-(4) can 
be presented in our map notation as follows: 
1'. q:= 0 can be written q := f(A), where f: NÂ° -+ N, A 1--+ 0 
2'. r:= X can be written r:= g(x), where g: N -+ N, n 1--+ n 
3'. r:= r -
y can be written r := her, y), where h: N 2 -+ N, (m, n) -+ m - n 
4'. q:= q + 1 can be written q := k(q), where k: N 1--+ N, n 1--+ n + 1. 
The observant reader will have noticed a "bug" in the map h of (~/). 
The difference m - n only lies in N if m ~ n, and the codomain of h should 
be Z, the set of all integers. This caused no problem in Figure 1, since the 
program tests that r ~ y before making the assignment r:= r - y. This 
example suggests the importance of extending the notion of a function to 
yield that of a partial function which is not necessarily defined for all elements 
of the domain. We will come back to the notion of partial function later. 
2 Definition. We say a functionf:A -+ B is onto if f(A) = B, i.e., every b 
in B is the image of some a in A. 
onto 

18 
1 Sets, Maps, and Relations 
We say a function f: A -
B is one-to-one if a =1= a' implies f(a) =1= f(a'), 
i.e., distinct points in A have distinct images. 
one-to-one 
We say a function f: A -
B is a bijection if it is both one-to-one and onto. 
bijection 
Clearly, if there is a bijection f: A -
B for the finite sets A and B, then 
IAI = IBI, for if al' a2' ... ' an is a listing of the n distinct elements which 
comprise the set A, then f(a l), f(a2), ... ,f(an) is a listing of all (since f is 
onto) the distinct (since f is one-to-one) elements in B, so that B too has n 
elements. Conversely, if both A and B have n elements we can write them out 
in any order 
A I al I a2 I ... I an 
B 
bl 
b2 
â¢â¢. 
bn 
to define a bijection f: A -
B by f(aj) = bj for 1 ~ j ~ n. We have thus 
proved: 
3 Theorem. Given two finite sets A and B, I A I = I B I if and only if there exists 
a bijection A -
B. 
D 
Returning to our examples, we have: 
f:NÂ° -N, 
g:N-N, 
h:N2 _ Z, 
k:N-N, 
nl-+n 
(m, n) 1-+ m -
n 
is one-to-one but not onto; 
is a l:iijection; 
is onto, since for r E Z, r ~ 0, r is the 
image of (r, 0); while for r E Z, r < 0, r is 
the image of (0, r). 
But m -
n = (m + 1) -
(n + 1), and so 
the map is not one-to-one; 
is one-to-one but is not onto -
in fact, 
the range of the map is the set N -
{O} 
of all positive integers. 

1.3 Maps and Relations 
19 
We use the notation A ~ B to indicate that A and B are in bijective cor-
respondence, i.e., that there exists a bijection from A to B. 
lt is often important to consider the set of all maps from a set A to a 
set B. We use the notation [A --. B] to denote this set. For example, if 
A = B = {O, I}, there are four members of [A --. B], as shown in the next 
table: 
f(O) 
f(1) 
o 
o 
1 
1 
o 
1 
o 
1 
At this stage, we return to the sequence NÂ°, NI, N 2 to discuss the general 
notion of Cartesian powers. Recall that N 3 = {(x, y, z) 1 x, y, zEN}. Thus 
each element ofN3 may be viewed as a map sending each of the three positions 
of the triple to N. For example, (13, 15, 19) can be thought of as a function 
f: {I, 2, 3} --. N, with 1 H 13, 2 H 15, and 3 H 19. Let us examine this point 
of view more closely. 
Let A be any set. Consider the set n = {I, 2, ... , n} consisting of the 
first n positive integers. For example, I = {I}, and 2 = {l,2}. We shall 
extend the notation to put 0 = 0 - fitting in with the general scheme that 
n -
1 = n - {n}. 
Consider the set [n --. A] of all maps from n to A. There is only one map 
in [0 --. A]. We denote it by A: 0 --. A, and so we see that [0 --. A] is a one-
element set AO = {A}. 
There are 1 A 1 maps in [I --. A]. We get a distinct map fa: I --. A for each 
choice fa(l) = a. We see that we can define a bijection from A = A I to 
[I --. A] by the rule a H fa. 
There are 1 A 12 maps in [2 --. A]. We get a distinct map fal. a2: 2 --. A 
for each choice fal,a2(1) = aI' fa"a2(2) = a2' We see that [2 --. A] is in 
bijective correspondence (aI' a2)H fa,I,a2 with A2 = A x A. 
More generally, then, for any n ~ 0, we may view a function f: n --. A 
as the sequence of n values (f(1), f(2), ... ,f(n)), so that [n --. A] is in 
bijective correspondence with the set of all such sequences, which set we 
denote by An. We refer to both [n --. A] and An as the nth Cartesian power 
of A. 
Just as the powers of any number k satisfy km+n = km * kn for any rn, n 
in N, so also do we have the following. 
4 Fact. For any rn, n in N and set A, there is a bijection 

20 
1 Sets, Maps, and Relations 
initial 
data ~ 
evaluate 
f(a) 
evaluate 
with 
-" 
with 
f 
intermediate result 
g 
Figure 6 Sequential application of/followed by g. 
g(f(aÂ» 
final 
value 
which sends Â«al,a2, .. "am), 
(a'l,a~, ... ,a~Â» to (al,a2, ... ,am, a'l,a~, 
... , a~). Note, in particular, that if we identify A with the empty sequence ( ) 
then we have 
Am X AO ~ Am, Â«a l , â¢.. , am), ( Â» ~ (a l , .â¢â¢ , am) 
AO X An ~ An, Â« ), (ai, ... , anÂ» ~ (a l , ..â¢ , an). 
D 
We have seen that for finite sets A and B, A ~ B iff IAI = IBI. This 
implies that there is a bijection f: A ~ B iff there is a bijection g: B ~ A 
(Why?). We now look at this latter result in a new perspective based on 
function composition. 
5 Definition. Given two functions f: A ~ Band g: B ~ C (where the co-
domain of f equals the domain of g) we define their composite g. f: A ~ C 
(also denoted by A L B .!!.. C) by the equality 
g . f(a) = g(f(aÂ» 
for each a in A 
as shown in Figure 6. 
It is useful to note another characterization of bijections. For any set A, 
the function idA: A ~ A, a f->a, is called the identity map on A. 
6, Definition. We say a map f: A ~ B is an isomorphism if it has an inverse, i.e., 
a map g: B ~ A such that 
gÂ·f=idA and fÂ·g=idB. 
Note that g too is an isomorphism, with inverse f. 
Recall, for example, the pairing of men and women at the dance. If the 
pairing is exact, then the assignment f: Men ~ Women which maps a man 
to his date has as inverse the assignment g: Women ~ Men which maps 
a woman to her date. (Here M en is the set of men at the party; and similarly 
Women.) 
7 Fact. A map f: A ~ B is an isomorphism if! it is a bijection. 
PROOF. Suppose that f is an isomorphism. We must show that f is onto and 
one-to-one. Given any b in B, b = idB(b) = (f. g)(b) = f(g(bÂ» in A, so 
that f is onto. Now suppose that f(a) = f(a'). Then 
a = idA(a) = g. f(a) = g(f(aÂ» = g(f(a'Â» = g. f(a') = a' 
so that f is one-to-one. 

1.3 Maps and Relations 
21 
The other half of the proof, that each bijection is an ismorphism is left 
to the reader (Exercise 17). 
Given the fixed "universe" S, we may associate with any subset A its 
characteristic function XA: S -+ PA = {T, F} where 
{ T 
if sEA, 
XA(S) = 
F 
if s ~ A. 
Inversely, given any map X: S -+ PA we may associate with it the subset 
{si X(s) = T}, and it is clear that each subset of S corresponds to one and only 
one such X, and vice versa. In other words. we have an isomorphism between 
f!JJS, the powerset of S, and [S -+ PA], the set of all maps from S to the 
Boolean set PA. 
8 Example. Let S be the two-element set {a, b}. Then 
f!JJS = {~, {a}, {b}, {a,b}} 
is a set with four elements, each of which is a subset of S. We can then tabulate 
the characteristic functions of these four subsets as follows: 
a 
b 
F 
F 
T 
F 
X(b} 
F 
T 
X(a,b} 
T 
T 
and we see that the subsets are thus placed in a bijective correspondence 
with all possible functions X: S -+ {T, F}. 
9 Fact. Let the finite sets A and B have I A I and I B I elements, respectively. 
Then there are IB IIAI distinct functions from A to B. (Note the reversal -
there 
are "IBI to the IAI" mapsfrom A to B.) 
PROOF. Consider the table where m = I A I, n = I B I 
For each of the m elements aj of A, we may, in defining a particular f: A 4 B, 
fix f(a) to be anyone of the n elements of B. We thus have a total of 
(n for al) * (n for a2) * ... * (n for am) = nm = I B IIAI choices in defining the 
different maps from A to B. 
0 
This gives us a new proof of a result from the last section: 
10 Corollary. The finite set S has 21s1 subsets. 
PROOF. The number of subsets of S equals the number of characteristic 
functions on S, namely IPA Ilsl = 21sl. 
D 

22 
1 Sets, Maps, and Relations 
Note that we used a "change of viewpoint," viewing a subset as a suitable 
function. 
PARTIAL FUNCTIONS 
As mentioned earlier, partial functions are not necessarily defined for all 
elements of the domain. The importance of such functions in computer 
science may be seen by considering Figure 1 again. We have already con-
vinced ourselves that if the input is a pair (x, y) of integers with x ~ 0 and 
y > 0, then the output will be a pair (r, q) with r = x mod y and q = x div y. 
We summarize this by saying that Figure 1 provides a rule for computing 
the function 
f: N x (N - {On ~ N x N, 
(x, y) 1---+ (x mod y, x div y). 
But suppose we started with y = 0 instead of y > O. After q := 0, r := x, 
we have r ~ y, and so we enter the loop. But each time round the loop, 
r := r - y doesn't change r, sInce y = O. The program execution repeats 
the loop endlessly. We say, then, that the program of Figure 1 computes the 
partial function 
1':NxN~NxN 
where 
1'(x, y) = {(X mod y, x div y), 
~f y > 0; 
undefined, 
If y = o. 
l' is called a partial function since on some values in the domain (namely, 
pairs (x, y) for which y = 0) there is no associated codomain value . 
.The concept of partial function is more appropriate for computer science 
than the traditional notion of a function. Functional relationships in 
computer science are usually derived from programs, and in programs 
infinite looping is a necessary if undesirable possibility. By allowing for 
undefined values, partial functions can adequately reflect the full range of 
functional relationships expressible by program execution. 
11 Definition. Given two sets A and E, a partial function f from A to E, 
also denoted f: A ~ B, is an assignment to each element a in a subset dom(f) 
of A, called the domain of definition of f, of a single element in B, a 1---+ f(a), 
called the image of a. 
The domain of definition of f, dom(f), is a subset of the domain, A, of f. 
The range of f,f(A), is a subset of the codomain, B, of f. Since A is a subset of 
itself, a map or function f: A ~ B as defined earlier is a partial function 
which is total in the sense that dom(f) = A. (The idea of a "total partial 
function" may seem contradictory at first, but it makes good sense. Given 

1.3 Maps and Relations 
23 
a program P, we want to call the function <pp that it executes a partial function 
if we cannot yet guarantee that it halts for all inputs, yet later investigation 
may allow us to guarantee termination and so conclude that <pp is total.) 
We now give a few more examples of partial functions and (total) 
functions. 
The monus function 
{ m -
n 
(m, n)H 0 
if m ~ n 
if m < n 
is a function (i.e., it is total), as is the function 
(m, n)Hm -
n. 
Note, then, how important it is to specify the domain and codomain of a 
function. Thus N 2 --+ B, (m, n}H m - n, is total if the codomain B is Z, 
but partial if B = N. 
If Q is the set of rational numbers (i.e., ratios m/n of integers m and n 
subject to the condition n '1= 0) we may define the partial function of division 
(!!!.,!!.) H mq 
n q 
np 
-+-: Q x Q --+ Q, 
which is not total since division by zero is undefined. 
A change of viewpoint lets us identify a partial function with a suitable 
(total) function with a new codomain. Given the set B, let us form a new set 
B u {..L} by adding a new element read "bottom;' which is the Tof "TOP" 
upside down!) which does not belong to B. Then we may view a partial 
function f: A --+ B as a total function f.L: A --+ B u {..L} defined by the rule 
f.L(a) = {f(a) if a is i~ dom(f) 
..L 
otherwIse. 
Conversely, any function A --+ B u {..L} yields a partial function. 
12 Example. Let A = {a, a'}, B = {b}. Then we may tabulate the partial 
functions from A to B as 
b 
b 
where -
indicates that no value is defined. By changing -
to ..L we change 
eachfto the correspondingf.L and we see that we have a bijection from the 
set Pfn[A, B] whose elements are the partial functions A --+ B to the set 
[A --+ B u {..L}] whose elements are the total functions A --+ B u {..L}. The 
assignment f H f.L is a bijection but we do not claim that any particular jj is 
an isomorphism. 

24 
1 Sets, Maps, and Relations 
13 Corollary. Given finite sets A and B, there are 
(IBI + l)IAI = (IB u {-L}I)IAI 
partial functions from A to B. 
o 
We see here a powerful role of theory: to enable us to use a change of 
representation to convert a problem into a simpler one, or into a problem 
that we already know how to solve. 
GRAPHS AND RELATIONS 
In analytic geometry we often represent a function of the form f: R ~ R 
by its graph as shown in Figure 7. 
We see that a typical point of the graph has coordinates (x,f(xÂ», and we 
may regard the graph (the curve itself, not the whole drawing which includes 
the axes, etc.) as a subset of R x R. This suggests the following general 
definition: 
14 Definition. Given any function f: A ~ B, the graph of f is the subset 
graph(f) = {(a, b)la E A, bE B, b = f(a)} 
ofAx B. It is clear that a subset G of A x B is the graph of some function 
A ~ B just in case for each a in A there is one and only one b in B for which 
(a, b) E G. Moreover, given such a G, the g for which G = graph(g) is defined 
by letting g(a), for each a in A, equal the unique b in B with (a, b) in G. 
For a partial function f: A ~ B, only those a in the domain of definition 
of f, the subset dom(f) of A, have assigned values in B. Thus for such a 
partialf, 
graph (f) = {(a, b)la E dom(f), bE B, b = f(a)}. 
Then a subset G ofAx B is the graph of some partial function A ~ B iff 
for each a E A there exists at most one b in B with (a, b) E G. Such a G is 
R 
R 
Figure 7 

1.3 Maps and Relations 
25 
graph(g) for the partial function g: A ~ B for which g(a) is the unique b 
with (a, b) in G, if such b exists, and for which g(a) is undefined if no (a, b) 
is in G. 
15 Example. For the partial function h: N x N ~ N which sends (m, n) to 
m - n if m ~ n but otherwise undefined, 
graph(h) = {(m,n,k)lm ~ nandm = n + k} c N x N x N. 
We have said that a (partial) function A ~ B can be thought of as a 
suitably restricted subset ofAx B. We next set: how we may think of an 
arbitrary subset of A x B as a relation. A familiar example of a mathematical 
relation is inequality. For m and n in N, 
m < n if there is an integer k > 0 such that m + k = n. 
We can think of this relation as a generalized function. For instead of 
pairing each m with a single value f(m) in the way a map f: N ~ N does, it 
pairs each number m with a whole set of numbers, namely {nlm < n}. 
Suppose, for another example, that A and B both equal the set of human 
beings, and that we write aRb as shorthand for" a is an aunt of b." Then we 
may consider the subset {(a, b)laRb} ofAx B, which we also denote by R. 
If a is a man, then {blaRb} is empty. If a is a woman with one niece and no 
nephews, then {b I aRb} has just one element. And if the woman, a, has 17 
nieces and nephews then the relationship aRb, a is the aunt of b, holds for 17 
distinct elements of the set B. This motivates the general definition: 
16 Definition. A relation R: A.....,. B from A to B (note the use of the "half-
arrow" to distinguish relations from functions) is a subset R ofAx B. 
We use aRb as an alternative notation for (a, b) E R. 
A relation may be (the graph of) a function -
consider the relation 
aRb = "b is the father of a." A relation may be (the graph of) a partial 
function -
consider the relation aRb = "b is the first-born child of a," 
which is partial because a person may have no children. 
Just as we could pass back and forth between functions and their graphs, 
so may we represent relations by functions: Given a relation ReA x B, 
we may associate with it a function 
R:A~~B. 
(Remember, ~B is the powerset of B, so that for each a in A, R(a) is a (pos-
sibly empty) subset of B). R sends each a in A to its set of R-relatives in B. 
Formally, 
R(a) = {bib E Band aRb}. 
Consider, for example, the relation :::;; on the natural numbers. We may 
represent it by the subset 
R = {(m, n)lm :::;; n} 

26 
1 Sets, Maps, and Relations 
of N X N, or as the function N --4 &'N with 
R(m) = {nlm ~ n}. 
In either case, we learn whether indeed m ~ n for a given pair of integers -
either by checking to see if (m, n) E R or by checking to see if nE R(m). 
Note that both representations correspond to the following graph 
where the shaded region includes the solid line {nlm ~ n}. 
N 
R(m) = {nlm ~ n} 
~-----------r------------~~N 
m 
The entire shaded region represents R, while the portion of it lying above 
m represents R(m), just as in the graph of a function f: A --4 B, the point 
(a, b) "lying above" a allows us to read off f(a) = b. More generally, an 
n-ary relation is a subset R of A t X â¢.â¢ x An for some integer n ~ 1. (Thus a 
unary relation (n = 1) is just a subset of some At; while a binary relation 
(n = 2) is an R: At -,.. A2 in the sense of our earlier definition.) 
Given a relation R c At x ... x An, we may form its characteristic 
function 
XR: At x ... x An -+ {T, F}. 
In fact, any function of the form p: AJ x ... x An -+ {T, F} is called an 
n-ary predicate, and we see that there is a bijective correspondence between 
predicates and relations. 
Returning to our motivating flow diagram (Figure 1 of Section 1.1), we 
see that a test corresponds to a relation. 
false 

1.3 Maps and Relations 
27 
In this case, the relation is {(r, y) I r 2!: y} c N x N and our branching 
convention explicitly makes use of the predicate p: N x N -+ {T, F} where 
p(r, y) = T if r 2!: y, and p(r, y) = F if not. 
Finally, we look at composition of relations: If aRb means" a is the mother 
of b" and bSc means" b is the father of c," we may deduce that" a is the 
paternal grandmother of c," and call "paternal grandmother" the composite 
of Rand S. In general, then 
17 Definition. Given relations R: A ~ Band S: B ~ C their composite 
S . R: A -"7' C is defined to be the relation 
SÂ· R = {(a, c) I there is a b in B with aRb and bSc} c A x C. 
18 If a relation R has the same domain and codomain, R: A ~ A, we can 
define the powers of R as follows: 
RO = idA = {(a, a)laEA} 
RI = R 
R2 = R.R 
R3 = R2. R 
Rn+l = Rn. R. 
Given relations with the same domain and codomain, Si: A ~ 
B, we define 
their union Ui Si as follows: a pair (a, b) belongs to Ui Si iff (a, b) E Si 
for at least one i. 
19 We then write 
R+ for U Rn 
n>O 
and 
R* for URn. 
n2:0 
For example, if R is the relation "parent of" for human beings, then R + 
is the relation" ancestor of." 
If R: N ~ N is the relation with mRn just in case m = n + 1, then R + 
is the relation> (greater than), while R* is the relation 2!: (greater than or 
equal to). 
20 R + is called the transitive closure of R; while R* is called the transitive 
reflexive closure of R. We shall see what these words mean when we study 
partial orders in Section 5.1. 

28 
1 Sets, Maps, and Relations 
EXERCISES FOR SECTION 1.3 
1. Consider the relations 
Rs = {(m, n)lm ~ n} eN x N 
R~ = {(m,n)lm ~ n} eN x N. 
Show that the intersection of Rs and R~ is the graph of a function. Identify the 
function. 
2. (a) Show that the following flow diagram computes Z as x * y, the product of 
natural numbers x and y. 
(b) Spell out explicitly all the functions and relations used here. 
INPUT 
x~O,y~O 
false 
Z:=Z + X 
y:= y - 1 
true 
PRINT z 
3. (a) For each of the maps below, indicate whether it is one-to-one, onto, a bijection, 
or none of these. 
N~N, 
Z~N, 
N~N, 
Z~Z, 
n f-+ n2 
n f-+ n2 
nf-+n+l 
nf-+n+l 
Z ~ Ze, 
n f-+ 2n where Ze is the set of even integers 
Z~{O,l, ... ,m-l}, 
nf-+n mod m. 
(b) For each map which is a bijection,give the explicit definition of its inverse. 
4. We say that map g: B ~ A is a left inverse (respectively, right inverse) of map 
f: A ~ B if g. f = idA (respectively, fÂ· g = idB)Â· 
(a) Show that whenever f: A ~ B is one-to-one, then f has a left inverse. 
(b) Show that whenever f: A ~ B is onto, then f has a right inverse. 

1.3 Maps and Relations 
29 
5. (i) Prove that if the relations Rand S of Definition 17 are functions, then Definition 
17 yields the same notion of function composition as Definition 5. 
(ii) Specialize Definition 17 to give a direct definition of the composite g . f of two 
partial functions f: A --+ Band g: B --+ C. 
6. Prove that if functions f: A --+ Band g: B --+ C are both one-to-one, then so is their 
composite. 
7. Write down an explicit definition 
R* = {(m, n)IÂ·Â·Â·} 
for the binary relation R: N --+ N where mRn just in case I m - n I = 2. Here I I 
stands for absolute value, 
{
X 
ifx;;::O 
Ixl = 
-x if x ~ o. 
The next three examples are arranged in increasing order of difficulty. 
8. Let I A I = m and I B I = n. How many isomorphisms are there from A to B? (Hint: 
First compare m and n. Use the factorial function in your answer.) 
9. Let IAI = m and IBI = n. How many one-to-one maps are there from A to B? 
(Hint: First compare m and n. Use the factorial function in your answer.) 
10. Let I A I = m and I B I = n. How many onto maps are there from A to B? (Hint: 
First compare m and n. Then start thinking about dividing B into m disjoint non-
empty subsets.) 
11. If A = {I, 2, ... , n}, show that a function from A to A which is one-to-one must 
be onto -
and conversely. 
12. Give an example of a function which is one-to-one but not onto from N to N. 
13. Show that there is an onto but not one-to-one function from N to N. 
14. Prove that the functions 
f: N x N --+ N, 
g: N x N --+ N, 
are both onto but not one-to-one. 
(m, n)f--+m + n 
(m,n)f--+m*n 
15. In the definitions to follow, f and g are binary functions on a set A, f: A x A --+ A 
and g: A x A --+ A 
f is said to be commutative if for all aI' az E A 
f is said to be associative if for all aI' az, .Q3 E A 
f is said to be distributive over g if for all aI' az, a3 E A 

30 
1 Sets, Maps, and Relations 
(i) Indicate which of the following functions N x N .... N is commutative, or 
associative, or both, or neither: 
(m, n) f-+ m + n 
(m,n)f-+m*n 
(m, n) f-+ m" 
(m, n) f-+ m + (n mod 5) 
(m, n) f-+ lcm(m, n) 
(m, n) f-+ gcd(m, n). 
(ii) Consider f: N x N .... N, (m, n) f-+ m * n, and g: N x N .... N, (m, n) f-+ m + n. 
Is f distributive over g? Is g distributive over f? Justify your answers. 
16. Let tjJ be the partial function mapping N to N defined by 
tjJ( ) = {n 
if n is even, 
n 
undefined, if n is odd. 
Write a computer program in some higher level language such as Pascal that 
computes this function. 
17. Complete the proof of Fact 7. 
18. Let C equal the set of cities in the world, and for a, bEe, define aRb to hold just in 
case there is a nonstop regularly scheduled airplane flight from a to b. What is 
RO? RI? R2? R+? R*? 

CHAPTER 2 
Induction, Strings, and Languages 
2.1 Induction on the Natural Numbers 
2.2 The Strings over an Arbitrary Set 
2.3 Languages and Automata: A First Look 
2.4 Context-Free Grammars 
2.5 Processing Lists 
One of the most powerful ways of proving properties of numbers, data 
structures, or programs is proof by induction. And one of the most powerful 
ways of defining programs or data structures is by an inductive definition, 
also referred to as a recursive definition. Section 2.1 provides a firm basis 
for these principles by introducing proof by induction for the set N of 
natural numbers and then looking at the recursive definition of numerical 
functions. Words are strings ofletters and numbers are strings of digits, and 
in Section 2.2 we look at the set of strings over an arbitrary set, stressing how 
induction over the length of strings may be used for both proofs and defini-
tions. We also introduce the algebraic notion of "semiring" which plays an 
important role in our study of graphs in Section 6.2. 
We then turn to formal languages, subsets of the set of strings on some 
particular alphabet. For example, the programs of a programming language 
are a formal language over some fixed character set. In Section 2.3 we intro-
duce a restricted set of formal languages, the finite-state languages, which can 
be associated with a class of machines called finite-state acceptors. Se~ion 
2.4 then introduces context-free grammars, a more powerful method of 
language definition that has proved very popular in the formal specification 
of the well-formed programs of such languages as Algol and Pascal. Finally, 
Section 2.5 looks at list processing, with special emphasis on the re~ursive 
definition and processing of s-expressions, the data structures of the pro-
gramming language Lisp. 
31 

32 
2 Induction, Strings, and Languages 
2.1 Induction on the Natural Numbers 
In the course of this book a variety of proof techniques will be used to 
establish theorems and propositions. In this chapter we introduce one 
particular proof technique, proof by induction. Induction is especially im-
portant for computer scientists because it can serve as a principle of computa-
tion as well as a method of proof. Programmes defined using recursion are 
really doing induction "backwards" during execution. 
Proof by induction is a powerful method of proving that a property holds 
for all natural numbers. First, we check that the property holds for O. This is 
called the basis step. Then we prove that whenever any n in N satisfies the 
property, it must follow that n + 1 satisfies the property. This is called the 
induction step. 
o 
basis 
step 
1 
2 
n 
n + 1 
~ 
... 
t" 
induction 
step 
The basis step tells us that the property holds for n = O. Then the induction 
step for n = 0 guarantees that the property holds for n = 1. Then the in-
duction step for n = 1 guarantees that the property holds for n = 2. And 
so, counting up one step at a time, we see that the property must hold for all 
n in N. 
Proofs by induction may start at 1 as well as 0; and, indeed, proofs of this 
kind may start at any positive integer. A proof by induction with basis step 
n = 1 works this way: first the basis step establishes that a property holds for 
n = 1; then induction uses the n = 1 case to guarantee that the property holds 
for n = 2; then the induction uses the truth of the property for n = 2 to 
guarantee truth for n = 3, and so forth. In this case, counting up one step at 
a time guarantees that the property holds for all nE N with n ~ 1. 
We give two examples of proof by induction. 
In Figure 8, we see how successively larger squares are formed by adding 
borders. For example, the shaded border around the 2 x 2 square in Figure 
8 contains 1 + 2 * 2 = 5 squares. We observe that 
12 = 1 
22 = 1 + 3 
32 = 1 + 3 + 5. 
Figure 8 

2.1 Induction on the Natural Numbers 
33 
This suggests the hypothesis that, for every n ~ 1, we have that n2 equals the 
sum of the first n odd numbers. 
n2 = 1 + 3 + ... + (2n - 1). 
We prove this by induction. 
Basis Step: (Since we only want to prove our result for n ~ 1, we take 
n = 1 as our basis step.) For n = 1, 12 = 1, and the property holds. 
Induction Step: Suppose the hypothesis holds for n, so that 
n2 = 1 + 3 + ... + (2n -
1). 
(1) 
Then the sum of the first n + 1 odd numbers equals 
1 + 3 + ... + (2n -
1) + (2n + 1) = n2 + (2n + 1) = (n + 1)2 by (1) 
and so our hypothesis holds for n + 1. 
D 
Many students on first reading a proof by induction are stymied by the 
assumption: "Suppose the hypothesis holds for n." "What," they ask, 
"ifit doesn't hold for n?" Perhaps it helps to expand the statement as follows: 
We use n as an algebraic variable which can be made to take any value in 
the set N = {O, 1,2,3, ... } of natural numbers. At any time we assume that 
n has a single fixed value in N. Returning to our hypothesis, we do not yet 
know whether or not it holds for all n. That is what we are trying to prove. 
But suppose that we now assign to n a value for which the hypothesis does 
hold. We now know that if we add one to this particular value -
we denote 
the result by n + 1 -
then the hypothesis also holds for this value. 
Let us, then, use P(n) as our shorthand for "the hypothesis holds for n." 
If we want to prove that P(n) for all n ~ 0, the basis step requires us to prove 
P(O). The induction step requires us to prove that P(n) implies P(n + 1), i.e., 
for every value of n in N for which P(n) is true we must have that P(n + 1) 
is true. Note that the induction step tells us nothing about P(n + 1) if P(n) 
is not true. 
If we can verify both the basis step and the induction step, we can infer the 
truth of P(n) for all n. For example, we can see that P(3) holds because 
P(O) is true by the basis step. 
P(O) implies P(1) by the induction step with n = O. 
Thus P(1) is true. 
P(1) implies P(2) by the induction step with n = 1. 
Thus P(2) is true. 
P(2) implies P(3) by the induction step with n = 2. 
Thus P(3) is true. 
Now it was rather boring to write this explicit proof out for n = 3. Imagine 
how tedious it would be to write the proof out for n = 1,000,000 -
it would 
have 2,000,001 lines ! And that's the whole point of proof by induction. We 
don't have to write out a separate proof for every natural number we are 

34 
2 Induction, Strings, and Languages 
interested in. Just a proof of the basis (P(O) is true) and the induction step 
(for every natural number n, it is the case that the truth of P(n) guarantees 
the truth of P(n + 1)) will do. 
1 Example. Consider the claim" n > 7." The induction step is clearly correct, 
since if n > 7 then certainly n + 1 > 7. But in this case the basis step fails, 
because it is not true that 0 > 7. So we cannot prove by induction that for 
every natural number n, it is true that n > 7. (We can, however, prove by 
induction that "n > 7" is true for every n ~ 8 if we choose n = 8 as our 
basis step.) 
2 Example. Consider the claim "n < 7." Here the basis step works, 0 < 7, 
but the induction step fails -
we cannot prove" n < 7 implies n + 1 < 7" 
because it fails for the particular value n = 6. 
We now give a new proof of Fact 1 in Section 1.1: 
3 Theorem. Each n element set has 2n subsets. 
PROOF BY INDUCTION 
Basis Step: For n = 0, the only n element set is the empty set 0 which has 
only one subset, namely 0. But 2Â° = 1, establishing the basis. 
Induction Step: Suppose that every n element set has 2n subsets. We 
must show that this guarantees that 1 A 1 = n + 1 implies 1 fY A 1 = 2n + 1. Let 
then A = B u {a}, where B has n elements, and a is an element not in B. 
Each subset of A either does or does not contain a. 
fY A = {S 1 SeA, a E S} u {S 1 SeA, a ~ S} 
= {Tu {a}ITc B} u {TI Tc B}. 
Thus IfY AI = IfYBI + IfYB 1 = 2n + 2n, by hypothesis on n, = 2n+ 1. 
0 
Before we go further, it will be useful to distinguish a number from the 
notation which represents it. We may write 
N = {O, 1, 2, 3, 4, 5, ... } 
or N = {zero, one, two, three, four, five, ... } 
or N = {O, I, II, Ill, IV, V, ... } 
or N = {O, 1, 10, 11, 100, 101, ... } 
and we realize that these are notational variants of each other. In each case, 
we first write down an element (0 or zero, say) which represents the number 
we use to count an empty pile of stones; and when we have written a repre-
sentation of the number n we use to count the stones in a given pile, we may 
then write down the representation of the number a(n) -
the successor of 
n - that counts the stones in the pile obtained by adding a single stone to the 
previous pile. The Italian mathematician Giuseppe Peano (1858-1932) 
summarized our intuit ions about the non-negative integers in the following: 

2.1 Induction on the Natural Numbers 
35 
4 Peano's Axioms. The set N contains an element 0, and is equipped with 
a function which assigns a number O'(n) to each number n in such a way that 
the following properties hold: 
P1. For no n in N does O'(n) = O. 
(0 is the first member of N and so is the 
successor of no other number.) 
P2. If m ::F n the nO'(m) ::F O'(n). 
(Distinct numbers have different 
successors.) 
P3. Ifa subset S ofN contains 0 and contains O'(n) for each n in S, then in fact 
S is precisely N. 
Note that P3 states the validity of proof by induction. For let pen) be a 
statement that is either true or false for each natural number n, and let S 
be the set of n for which pen) is true. (In other words, P = Xs: N --+ {T, F}, 
the characteristic function of S as a subset of N.) Then P3 says precisely: 
If P(O) is true (basis step), and if pen) is true implies P(O'(nÂ» is true (induction 
step), then pen) is true for every n in N. 
RECURSION 
So far, we have talked about verifying the properties of natural numbers by 
induction. But we can also use induction to define new constructs. A mathe-
matician will call this type of definition an inductive definition, but a computer 
scientist will call it a recursive definition. We shall discuss why after looking 
at the "standard example." 
The factorialfunction N --+ N, n H n!, assigns to 0 the value 1, and assigns 
to each n > 0 the value n! = n * (n - 1) * ... * 2 * 1, i.e., the product of the 
first n positive integers: 
O! = 1 
1! = 1 = 1 * O! 
2! = 2 * 1 = 2 = 2 * 1! 
3!=3*2*1=6=3*2! 
4! = 4 * 3 * 2 * 1 = 24 = 4 * 3! 
Thus, for each natural number neither n = 0 and n! = 1, or n > 0 and 
n! = n * (n - 1)!. Going further, this permits us to define n! by the following 
scheme: 
5 Recursive Definition of the Factorial Function 
Basis Step: If n = 0, then n! = 1. 
Recursion Step: If n! is already defined, then we can define (n + 1)! 
to be (n + 1) * n!. 

36 
2 Induction, Strings, and Languages 
We rename the induction step of our definition "the recursion step" 
to indicate that the function we are defining recurs in the actual definition 
(i.e., on the right-hand side of the equation -
the definition -
not just on 
the left-hand side, which simply tells us the notation for what is being defined). 
This recursive definition of a function f: N --+ N, then, acts just like an 
inductive proof. The basis step tells us how to define f(O) explicitly. The 
recursion step tells us that if we already know how to define f(n) (for some 
particular value n in N) then we can define f(n + 1) for the successor of 
that value of n. 
Such a definition starts with 0 and works up one step at a time to define 
f(n) for larger and larger natural numbers. But if we want to compute f(n) 
we work the other way around. Consider 
4!=4*3! 
=4*3*2! 
=4*3*2*1! 
=4*3*2*1*0! 
= 4 * 3 * 2 * 1 * 1 
= 24. 
(2) 
The idea is this. To compute f(n) we check to see ifn = 0, in which case we 
apply the basis step of the definition. Otherwise we subtract 1 from n to re-
duce the problem to that for a smaller integer. And so it goes through n 
reduction steps (running the recursion step backwards, as it were) until we 
return to the basis and complete the computation. 
Many programming languages allow us to use a recursive definition as 
part of a program: 
n! := if n = 0 then I else n * (n -
1)! 
(3) 
tells the computer 
test to see if n = 0; 
if the answer is YES, then the value of n! is 1; 
if the answer is NO, then the value of n! is n * (n -
I)! 
and the computer must call the instruction (3) again (but with n replaced by 
(n -
1Â» to compute (n - 1)!' And so on, just as in (2) for n = 4. 
The interesting thing about the program (3) is that it cannot be rep-
resented as a flow diagram. However, we can draw a flow diagram as in 
Figure 9 for a different way of computing n!. Here we have a loop with a 
variable m to count how many times around the loop remain (we count 
down from n to 0) and a variable w which, after j times around the loop, will 

2.1 Induction on the Natural Numbers 
INPUT 
n ~ Â° 
m:=n 
w:= 1 
w:=w*m 
m:=m -
1 
37 
PRINTw 
Figure 9 
hold the value n * (n -
1) * ... * (n - j + 1) -
which for n = j is just n!, 
the desired result. 
Note that this program is not recursive. Nowhere in this program for 
factorial does factorial itself get mentioned, as it did in the recursive program 
(3). Instead the solution is by iteration: we build a loop and iterate (repeat) 
it again and again until we have satisfied the test that allows the computa-
tion to exit from the loop. 
NUMBERS AS STRINGS OF DIGITS 
We know what natural numbers are, and we know what the decimal repre-
sentations of these numbers are -
they are strings of digits such as Â° or 3 
or 13 or 99 or 659432. We also "know" how to add 1 to any number in 
decimal notation -
in the above cases we get 1, 4, 14, 100, and 659433, 
respectively. But in what sense do we know? Most students find it very hard 
to write down a precise algebraic definition for this "decimal successor" 
function. (Try it for five minutes before you read on.) Our aim is to show how 
a recursive definition can be used to solve the problem. 
Consider again Peano's axioms, introduced in this section. These axioms 
say we can construct all of N via a basis step, which gives us 0, and repeated 
application of the induction step, which gives us o"(n) once we have n. Recall 

38 
2 Induction, Strings, and Languages 
that O'(n) = n + 1, the successor of n. More generally, an inductive or re-
cursive definition of a set (generalizing from N) is one which defines certain 
basic elements, and then defines a process which can be applied repeatedly 
to give more and more elements. 
6 Inductive Definition of N D' the Set of Decimal Representations of the 
Natural Numbers. Let D = {O, 1,2,3,4,5,6, 7, 8, 9} be the set of decimal 
digits. 
(i) Basis Step: Each d in D belongs to ND. 
(ii) Induction Step: If w is in ND and d is in D, then wd (the set of digits 
obtained by following w by the digit d) is also in ND. 
(iii) Nothing belongs to ND save by (i) and (ii). 
For example, to see that 1357 is in ND, we note that 1 is in ND by (i), so 
that 13 is in ND by (ii), so that 135 is in ND by (ii), and so 1357 is in ND by 
(ii). (But note Example 11.) 
Before going further, we need the table that tells us in which order the 
digits occur. We define m: D -+ D by the display 
d I 0 1 2 3 4 5 6 7 8 9 
m(d) 
1 2 3 4 5 6 7 8 9 0 
This is an exhaustive, explicit definition. All possible cases are in the table. 
By contrast, when we deal with large or infinite sets, we need a rule rather 
than an explicit table to tell us the definition of a function. 
Now we have to define 0': ND -+ ND so that for any string w of digits, 
O'(w) represents the successor of the number given by w. Clearly, for each 
digit, O'(d) = m(d), except when d = 9, and then 0'(9) = 10. 
Now what about a multidigit number? If it does not end in a 9, we simply 
replace the last digit d by m(d). If d is 9, we must replace it by 0, and" carry 1." 
7 Definition. The successor function 0': ND -+ ND for natural numbers in 
decimal notation is defined recursively: 
Basis Step: If v = d in D, then 
(a) If d i= 9, O'(v) = m(d) 
(b) If d = 9,0'(v) = 10. 
Recursion Step: If v = wd with w in ND, d in D, then 
(a) If d i= 9, O'(v) = wm(d) 
(b) If d = 9,0'(v) = O'(w)O. 
8 Example 
0'(999) = 0'(99)0 = 0'(9)00 = 1000 
0'(1399) = 0'(139)0 = 0'(13)00 = 1400 
0'(236) = 23m(6) = 237. 

2.1 Induction on the Natural Numbers 
39 
. In the last section, we studied induction on N. {O} was the basis, and the 
passage from n to n + 1 was the induction step. Here we consider ND with 
the set D of digits as the basis. The passage from any string w to each of the 
strings wd, one for each digit in D, is the induction step. 
For another look at the inductive treatment of numbers in decimal 
notation, we present addition in terms of a recursive definition of N x N 
-+ N, (m, n) ~ m + n based on the intuition" m + n is the number of stones 
in a pile of stones obtained by merging a pile of m stones with a pile of n 
stones." 
9 Recursive Definition of Addition. Having already defined the successor 
function, we may define m + n by induction on n as follows: 
Basis Step: m + 0 = m. 
Induction Step: Given that m + n is already defined, we set 
m + <T(n) = <T(m + n). 
10 Example 
4 + 3 = 4 + <T(2) 
since 3 = <T(2) 
= <T(4 + 2) 
by induction step 
= <T(4 + <T(1Â» 
since 2 = <T(1) 
= <T(<T(4 + 1Â» 
by induction step 
= <T(<T(4 + <T(OÂ») 
since 1 = <T(O) 
= <T(<T(<T(4 + 0Â») 
by induction step 
= <T(<T(<T(4Â») 
by basis step 
= <T(<T(5Â» 
since <T(4) = 5 
= <T(6) 
since <T( 5) = 6. 
=7 
since <T(6) = 7. 
Of course, this is a tedious way to add numbers, and neither humans nor 
computers usually add numbers this way. Moral: The first program you find 
to do a job may not be the best one. 
EXERCISES FOR SECTION 2.1 
1. Prove by induction that 
(a) 
12 
22 
32 
2 
n(n + 1)(2n + 1) 
+ 
+ 
+Â·Â·Â·+n =---6---
1 
1 
1 
n 
(b) 
-+-+ ... + 
=--
1Â·2 
2Â·3 
n(n + 1) 
n + 1 
(c) 
1 
2 
3 
n 
n+2 
- + - + - + ... + -
= 2 - --. 
2 
22 
23 
2" 
2" 

40 
2 Induction, Strings, and Languages 
2. Prove the following inequalities by induction: 
(a) (1 + !)" ~ 1 + !n. 
(b) For x > -1, 
(1 + nx)n ~ 1 + nx. 
3. Let pen) be the assertion "In any group of n people, all the people have the same 
color hair." What is wrong with the following proof that pen) is true for all n ~ I? 
Basis Step: P(l) is certainly true. 
Induction Step: Suppose pen) is true. Given a group of n + 1 people, arrange 
them in order: 
First n 
~-----------
â¢ 
â¢ 
â¢ 
â¢ 
2 
n n + 1 
Last n 
Since pen) is true, the first n have the same color hair, and the last n all have the 
same color hair. But the nth person belongs to both groups, and so all n + 1 people 
must have the same color hair. Thus pen + 1) is true. 
4. The recursive definition of addition also works for numbers in binary notation. 
To check this, compute: 
(i) 1101 + 101 
(ii) 1010 + 11. 
5. Assuming that the function +: N x N ..... N of addition is already available, we 
can give a recursive definition of multiplication as follows: 
Basis Step: m * 0 = 0 
Recursion Step: m * a(n) = m * n + m. 
(i) Use this definition to compute 6 * 4. (Just add all necessary pairs of numbers 
directly - don't use the recursive definition 9.) 
(ii) Write a flow chart for an iterative program which multiplies two numbers, 
using addition as a primitive operation. 
6. Write a recursive definition of the exponential, exp: N x N ..... N, (m, n) H mn, 
making use of multiplication as a primitive operation. 
7. Write a recursive definition of the monus operation, 
{m-n ifm>n 
m .,;.. n = 
0 
otherwise 
using only the successor function as a primitive operation. (Hint: First define by 
recursion a predecessor function, pen) = n .,;.. 1.) 
8. Prove by induction that 2n < n!, for all n ~ 4. 
9. Prove by induction that n3 + 2n is divisible by 3, for all nonnegative integers n. 
10. Give an inductive definition of the set {1O, 15,20, ... }, i.e., all multiples of 5 starting 
with 10, using only addition (of two numbers) in the induction step. 

2.2 The Strings over an Arbitrary Set 
41 
11. Modify definition 6 to avoid generating strings like 0116, without losing O. 
12. Give an inductive definition of the set {n I n is a non-negative multiple of 3 and 5}, 
using only addition in the induction step. 
2.2 The Strings over an Arbitrary Set 
The notion of a string of symbols is familiar to every computer scientist. In 
this section we consider the mathematical properties of this concept. To do 
this we will fix an abstract alphabet or set of characters X, and we will consider 
the set of all finite strings of symbols from X. This set of strings is called X*. 
One particular string, the empty string (it has length 0 and is denoted by A), 
plays a special role in the study of X*, in much the same way that 0 plays a 
special role for N. We now formally define X*. 
1 Definition. For any set X, X* is the set of all finite strings (or sequences) 
over the alphabet X. We write a typical element of X* as w = (Xl' ... , xn) 
or Xl ... Xn , where Xi E X for every 1 :::; i :::; n, and say that its length t(w) 
is n. We also include in X* the empty string A = ( 
), with t(w) = O. 
The set X+ is the set X* -
{A} obtained from X* by deleting the empty 
string. 
Given any two strings w = (Xl' ... , xm) and w' = (X'l, ... , x~) we may 
concatenate them to obtain 
ww' = (Xl' ... , X m , X'l, ... , x~). 
We note that 
(a) 
t(ww') = t(w) + t(w') -
the length is like a logarithm! 
(b) 
w(w'w") = (ww')w" and so we may write either as ww'w". 
(c) 
wA = Aw = w. 
2 Example. The set ND of decimal representations of numbers (2.1.6) 
equals D+. 
3 Example. If X = 0, the empty set, X* has only one element, namely 
A: 0* = {A}. But for every nonempty set X, we see that X* is an infinite 
set. For example, {1}* = {A, 1, 11, 111, ... , 1n, â¢â¢â¢ } where a typical element 
is a string 
11 ... 1 
'--.--' 
n times 
of n l's which we denote 1n. Thus we have a bijection N ~ {1}*, nH 1n. 
Caution: 1n is string notation (n l's in a row) not number notation (n 1'8 
multiplied together). 

42 
2 Induction, Strings, and Languages 
Remember that, in a sequence, the length of the sequence and the position 
of each element all matter, so that m =F n implies 1 m =F 1 n in string notation. 
On the other hand, a set is defined by its elements, irrespective of their order; 
e.g., {l, 1, 1} = {1} and the set .9'{1} is finite: .9'{1} = {0, {l}} = {{1}, 0}. 
In Section 1.1 we introduced the notion of disjoint union of sets while in 
Section 1.3 we introduced Cartesian powers. We may combine these notions 
to give an alternative definition of (a set in bijective correspondence with) 
X*: 
X* = I xn = X O + Xl + x 2 + ... + xn + ... 
n:2:0 
= {A} + X + X x X + ... + X x ... x X + .... 
'-.-' 
n times 
This expression says that X* is the union of the length 0 strings, the length 1 
strings, the length 2 strings, etc. A typical element of xn is (x l' X 2 , â¢â¢â¢ , xn) 
for that same n. Remember that the different terms are tagged to make them 
disjoint in a disjoint union: 
I xn = U xn X {n}. 
n:2:0 
n:2:0 
Thus, to inject (X l,X2, ... ,xn) into the disjoint union XO+Xl+X2 
+ ... + xn + ... we tag it with the index n. Thus in this presentation of X*, 
the typical element is written 
Â«Xl' X2'Â·Â·Â·' x n), n) 
which explicitly records the length n along the sequence itself. Concatenation 
is 
then 
Â«Xl' ... , Xm), m)Â· Â«X'l' .... ,X~), n) = Â«Xl' ... , Xm , X'l, ... ' X~), 
m + n). There is an obvious bijective map from X* to the disjoint union, 
sending (Xl' ... , xn) to Â«Xl' ... , xn), n). 
As an exercise in inductive definition, we turn to a third definition of X*, 
giving yet a third way of denoting a list of n elements of X. We formalize, 
for any set X, the formation of longer strings by adding elements X of X 
at the left-hand end. (This is very similar to Definition 2.1.6, but there we 
formed longer and longer elements of ND by adding new digits to the right-
hand end of a decimal string.) 
4 Definition. For any set S, we simultaneously define X* and the length 
function t: X* ~ N inductively by 
Basis Step: X* contains a distinguished element, written A, which we call 
the empty string. We set t(A) = O. 
Induction Step: If w is an element of X* and X is an element of X, then 
(x, w) is an element of X*. We may abbreviate (x, w) as xw. We set t(xw) 
= t(w) + 1. 
(We sometimes use (w, x) in the induction step to define X*.) 

2.2 The Strings over an Arbitrary Set 
43 
We then define a map conc: X* x X* ~ X*, (w, w') H ww', called 
concatenation, by induction on the length of w as follows: 
Basis Step: conc(A, w') = w' 
Induction Step: conc(xv, w') = (x, conc(v, w'Â» where v E X*. 
As an exercise, the reader should verify that properties (a), (b), and (c), 
mentioned after 1 follow from the inductive definition of 4 above. 
Note that our inductive definition offers the notation (Xl' (X2' (X3Â») 
for what we normally write as (Xl' X2' X3) or X I X 2X3' The reader familiar 
with Lisp will recognize A as being another notation for what Lispers call 
NIL. Lisp is a list-processing language especially important in Artificial 
Intelligence (AI). (AI is a field of computer science which studies computa-
tional processes involved in problem-solving, natural language under-
standing, etc. A very readable introduction to AI for the nonspecialist is 
Margaret Boden's "Artificial Intelligence and Natural Man," Basic Books, 
1977.) In Section 2.5, we will build on our knowledge of X* to define the basic 
data stucture of Lisp. 
X*, the set of finite strings over some finite alphabet X, is the fundamental 
object of formal language theory. We define a language over X to be any 
subset of X*. Thus, the set of words of English is a language over the alphabet 
X = {a, b, ... , y, z}. Likewise L = {a"b"ln ~ 1}, consisting ofa string of a's 
followed by a string of b's of equal length, is a language over X = {a, b}. 
Three basic operations are important in language theory. 
S Definition. Let X be a fixed finite alphabet, and let A and B be languages 
over X. Then 
1. The union of A and B, A u B = {wlw E A or wEB}. A u B is sometimes 
written as A + B in language theory, where + does not denote the disjoint 
union. 
2. The concatenation AÂ· B = {w I w 21 w I E A and w 2 E B} consists of all 
strings from X* that are made up of a string from A followed by a string 
from B. 
3. The iterate (or Kleene star) A* = {WI ... w"ln ~ 0, each Wi E A} is made 
up of all strings from X* that can be obtained by concatenating any 
finite number of strings from A. (Notice that, as with X*, A E A *, cor-
responding to the case where n = 0). 
6 Examples. Suppose we take X = {a, b}, and set A = {a}*, B = {b}*. 
Then A contains all finite strings of a's, B contains all finite strings of b's, 
and C = A u B contains any finite strings of a's as well as any finite string 
of b's. Strings of A . B are made up of a finite string of a's followed by any 
finite string of b's. A . B includes aabbb, aaa (there may be no b's at all), and 
bbbb (there may be no a's at all). The strings ba and abba are not in A . B, 
since no b may precede any a. 

44 
2 Induction, Strings, and Languages 
If A is any language, it is often useful to view A* as the infinite (disjoint) 
union of successively longer concatenations of A with itself: 
A* = AO + A + AÂ· A + AÂ· AÂ· A + ... + AÂ· ... Â· A ... 
'-.t---' 
n times 
Here AO represents {A}, and a typical element of this sum, 
AÂ· ... Â·A 
'-.t---' 
n times 
is made up of all possible concatenations of any n strings from A. 
7 Example. The language ({a} u {bb})* = {A} u ({a} u {bb}) u ({a} u {bb}) 
. ({a} u {bb})Â·Â·Â· = {A} u {a} u {bb} u {aa} u {abb} u {bba} u {bbbb}Â·Â·Â· = 
all strings of a's and b's in which b's occur consecutively as doubletons. 
8 Example. The language ({a 4 } u {a6})* = {A} + {a4 } + {a6 } + {as} + 
{aIO} + ... + {a 2n } + ... = {a 2k lk ~ 2}. 
MONOIDS, GROUPS, AND SEMIRINGS 
In the remainder of this section, we show how the above operations on X* 
can be placed in an algebraic perspective. The material here will not be used 
until Section 6.2 and so may be omitted at a first reading. We write the triple 
(X*, conc, A) to mean that we are to consider as an object of study the set X* 
together with the operator conc: X* x X* --+ X* and the distinguished 
element A E X*. Our (X*, conc, A) triple has two properties that are of 
general interest in computer science and mathematics. First of all conc is 
associative: (W I W2)W3 = WI (W2W3) 
-
that is, conc(conc(wl' w2 ), W3) = 
conc(wl' conc(w2' W3Â». And secondly the empty string is an identity for cone: 
conc(A, w) = conc(w, A) = w. 
Whenever a triple of this kind has these two properties, then it is an 
example of structure called a monoid. 
9 Definition. A monoid is a triple (M, m, e) where M is a set, m: M x M --+ M 
is a binary operation on M, and e is an element of M, subject to the conditions: 
1. m is associative: For all elements x, y, z of M we have 
m(m(x, y), z) = m(x, m(y, zÂ». 
2. e is an identity for m: For all elements x of M we have 
m(x, e) = m(e, x) = x. 

2.2 The Strings over an Arbitrary Set 
10 Example. (N, +, 0) is a monoid: 
(N, *, 1) is a monoid: 
(m + n) + p = m + (n + p) 
m+O=O+m=m. 
(m * n) * p = m * (n * p) 
m*l=l*m=m. 
45 
We say that 0 is the additive identity for N, and that 1 is the multiplicative 
identity of N. 
Why do mathematicians introduce abstract concepts like "monoid"? 
Because it is often possible to prove a property once and for all in the general 
setting, and then use it in any special case without any further work. Here 
is a simple example: 
11 Fact. A mono id has only one identity. 
PROOF. Suppose that e and e' are both identities for m. Then 
m(e, e') = e because e' is an identity; 
m(e, e') = e' because e is an identity; 
and hence e = e'. 
D 
This saves us an individual investigation in each case to verify the unique-
ness of A and 0 as the identities of (X*, conc, A) and (N, +, 0), respectively. 
There is an important difference between the set of all integers and the 
set of all natural numbers. Each integer n in Z has an additive inverse - n, 
that is 
n + (-n) = 0 = (-n) + n. 
By contrast, the only n in N with an additive inverse is 0, 
0+ 0 = 0, 
since the minus of any positive integer is negative. We have another general 
definition: 
12 Definition. Let (M, " e) be a monoid. Then we say that element x is an 
inverse for the element y if 
xÂ· y = e = yÂ·x. 
A mono id is called a group if every element of M has an inverse. 

46 
2 Induction, Strings, and Languages 
We now look at Example 10 in more detail. 
1. (N, +,0) is a commutative monoid, i.e., not only is it a monoid, but, more-
over, m + n = n + m for all m, n in N. 
2. (N, *, 1) is a monoid. (It is commutative, too, but we shall not use this fact 
here.) 
3. Multiplication distributes over addition, i.e., 
m * (n + p) = m * n + m * p 
for all m, n, and p in N. This calls for yet another general definition: 
13 Definition. A quintuple (S, +, ,,0, 1) is called a semiring with additive 
identity 0 and multiplicative identity 1 if 
1. (S, +, 0) is a commutative monoid; 
2. (S,Â·, 1) is a monoid; 
3. . distributes over + : 
aÂ· (b + c) = a . b + a . c for all a, b, cin S. 
One reason for the interest of this concept to computer scientists is given by 
the following example. Another is given in Exercise 6. We shall return to 
semirings when we study connection matrices for graphs in Section 6.2. 
14 Observation. Let Lx = &> X* be the set of all languages over the alphabet 
X. Then union, U, has an identity 0, the empry subset: 
A U 0 = A = 0 U A for all A c X*. 
Moreover, (Lx, u, 0) is a commutative monoid. 
Concatenation, " has an identity {A}, the language whose sole element is the 
empty string {A}: 
A . {A} = A = {A} . A for all A c X*. 
Moreover, (Lx," {A}) is a non commutative monoid: in general, AÂ· B Â¥= 
BÂ·A. 
Finally, concatenation distributes over union 
A . (B U C) = A . B U A . C 
for all languages A, B, Cover X. Thus, (Lx, U,', <p, {A}) is a semiring. 
0 
EXERCISES FOR SECTION 2.2 
1. Use 3, the inductive definition of X*, to prove by induction that 
(a) I (ww') = t(w) + t(w') 
(b) conc(conc(w, w'), w") = conc(w, conc(w', w")) 
(c) conc(w, A) = conc(A, w) = w. 

2.3 Languages and Automata Theory: A First Look 
47 
2. Give an inductive definition of the" string reversal function" 
p: X* -+ X* which sends X 1X2 ... Xn to Xn ..â¢ X 2 X 1. 
3. Prove that the triple (Z, +, 0) is a monoid. 
4. A semigroup is a pair (S, m) where S is a set and m: M x M -+ M is associative. (i) 
Prove that the set of even integers is a semigroup under addition. (ii) Is the set of odd 
integers a semigroup under addition? Justify your result. 
5. Prove that every element of a group has a unique inverse. 
6. The set {a, I} can be equipped with two operations called disjunction and con-
junction. We shall study these operations in more detail later. Disjunction is denoted 
by v, and defined by Â° v Â° 
= 0, Â° v 1 = 1 v Â° 
= 1 v 1 = 1. 
Conjunction is denoted by A, and defined by 
Â° 
A Â° 
= 0 A 1 = 1 A Â° 
= 0, 1 A 1 = 1. 
Prove that ({O, I}, v, A, 0, 1) is a semiring. It is called the Boolean semiring. 
7. Let Zm denote the set {a, 1,2, ... , (m -
I)}. 
(a) Show that (Zm, +m' 0) and (Zm, *m' l)are monoids, where +m and *m are addition 
and multiplication modulo m, respectively. 
(b) Show that if m is a prime number, then (Zm -
{O}, *m' 1) is a group. 
8. Given two monoids (M I, ml , el) and (M 2, m2, e2) a map f: M 1 -+ M 2 is called a 
homomorphism from (MI' ml , el) to (M2' m2, e2) if 
(i) f(el)=e2; 
. 
(ii) for all x, yE M l,f(ml(x, yÂ» = m2(f(x),f(yÂ». 
If such a map f exists, we also say that (M 2' m2, e2) is a homomorphic image of 
(M I' ml , el), although it may be the case that f(M 1 ) c M 2' 
(a) Show that (Zm' +m' 0), in Exercise 7, is a homomorphic image of (N, +,0), 
in Example 5. 
(b) Show that the map f: R -+ R, x f-+ 2X is a homomorphism from the monoid 
(R, +, 0) to the mono id (R, x, 1). 
9. Describe informally the following languages: 
(a) {a, b}* . {a}* 
(b) {a, b}* . {aa}* 
(c) {a, b}* . {b, a}* 
(d) {a, b}*Â· {a}*Â· {b}* 
2.3 Languages and Automata Theory: A First Look 
It is,often important in computer science to give two equivalent characteriza-
tions of a particular language -
one essentially algebraic, the other machine-
like. Thus, while a computer language like Pascal has a formal definition, 
made up of rules for generating all and only legal Pascal programs, at the 
same time program legality is also characterized by a theoretical machine: a 

48 
2 Induction, Strings, and Languages 
Pascal compiler. In this section we want to introduce another, similar sort of 
dichotomy. 
We saw in Section 2.2 how union, dot, and star operations may be com-
bined algebraically to form a wide variety of languages over the same finite 
alphabet. These languages have machine-like characterizations too, and 
here, as we shall see, the class of machines in question can be described 
simply and elegantly. We begin with a simple example. 
1 Example. The language {a*} . {b*} of Example 2.2.6 is recognized by the 
following machine: 
a 
b 
a 
b 
b 
The machine operates as follows on string aab. Starting at position qo 
(indicated by the left-most arrowhead), the machine reads aab from 
left to right. The first symbol is an "a," and since the arc labeled "a" leading 
ftom qo returns to position qo, the machine stays at qo as it proceeds to the 
second symbol. This symbol is also an "a," so the device again returns to qo 
to read the third symbol, a " b." The" b " arrow leads to position q 1. This is the 
terminal state of the device since the symbol string has been completely 
scanned. Position ql has a double circle around it, indicating that it is an 
"accepting" state and so the string aab is accepted by this device. Notice 
that this machine decides "yes" or "no" on every string in {a, b}*. The 
string aaba, for example brings the machine to q2' a rejecting state since it is 
only circled once. It should be clear that this machine accepts exactly the 
language {a}*Â· {b}*; the state q2 can be reached only if an "a" follows a "b" 
in the input stream of symbols. 
The "positions" of our device -
qo, ql' etc. -
are called states, and 
a subset of them, in this case qo and ql' are termed accepting states. The 
state qo is called the start state. We summarize the structure of these devices 
with the following definition. 
2 Definition. Ajinite-state acceptor (FSA) M with input alphabet X is speci-
fied by a quadruple (Q, b, qo, F) where 
Q is a finite set of states 
(): Q x X ~ Q is the transition function 
qo E Q is the initial state 
F c Q is the set of accepting states. 

2.3 Languages and Automata Theory: A First Look 
49 
3 Example. The FSA of Example 1 is represented by the quadruple 
where the function () may be described by means of the following chart: 
a 
b 
4 Example. Let us consider the language {a, b} * - ({a} * {b} *). This language 
is the complement of the language in Example 1. Notice that it can be accepted 
by the same FSA with accepting and nonaccepting states interchanged: 
F = {q2} instead of {qo, qt} in this case. Pictorially we have 
The general idea is that we use the finite-state acceptor M to classify 
elements of X* (strings of symbols from the input alphabet X) as follows: 
M starts in state qo, and scans the left-most symbol in some string w in 
X*. Based on its current state -
in this case qo -
and the symbol scanned, 
M shifts to some new state. This transition is governed by the transition 
function () given above, which maps a state/symbol pair to a new state. The 
second symbol is then scanned, with M in the new state, and again a ()-
transition occurs. This process continues until the entire input string is read. 
If the final state is a member of F, then the string x is accepted by M. Given an 
FSA M, we shall denote by T(M) the set of strings accepted by M -
the 
set of WE X* which send M from qo to some state in F. Our goal is to charac-
terize the set of strings which can be T(M)'s for some M. 
We now consider T(M) more formally by defining a function ()*: Q x X* 
~ Q such that ()*(q, w) is the state which M will go to with an input string 
W if started in state qo. We do this by induction: 
Basis Step: ()*(q, A) = q for each state q in Q. If M is started in state q, 
then when it has received the empty input string it must still be in that same 
state q. 

50 
2 Induction, Strings, and Languages 
Induction Step: c5*(q, wx) = c5(c5*(q, w), x) for each state q in Q, each input 
string w in X* and each input symbol x in X. 
L. 
q 
:--:s:X) 
c5*(q, w) 
x 
c5(c5*(q, w), x) 
The string w sends M from state q to state c5*(q, w), which input x then 
changes to state c5(c5*(q, w), x) -
but this is just the state c5*(q, wx) to which 
the string wx sends M from state q. 
5 Definition. The set T(M) of strings accepted by the FSA M = (Q, c5, qo, F) 
with input alphabet X is the subset of X* 
T(M) = {wlc5*(qo, w)EF} 
comprising all those strings which send M from its initial state qo to an 
accepting state, i.e., a state in F. 
We say a subset L of X* is a finite state language (FSL) if it equals 
T(M) for some FSA M. 
EXAMPLES OF FINITE-STATE LANGUAGES 
(i) The empty set 0 is an FSL since it is T(M) for any M for which the set 
F of accepting states is empty. Here is the simplest such M (where we take 
X = {O, I}): 
Here Q = {qo}, c5(qo, 0) = c5(qo, 1) = qo, and F = 0Â· 
(ii) The following state graph is that of a parity checker. 
o 
o 
It accepts just those strings with an odd number of I's: 
0*( 
) = {qO, 
ifw contains an even number of I's; 
qo, w 
ql' 
ifw contains an odd number of l's. 

2.3 Languages and Automata Theory: A First Look 
51 
(Hi) The set {A} whose only element is the empty string is an FSL, since 
it is accepted by the machine. 
0,1 
0,1 
Here F = {qo} and we see that (j*(qo, w) = qo if w = A, while (j*(qo, w) 
= ql ifw ;/= A. Then T(M) = {wl(j*(qo, w) = qo} = {A}. 
(iv) The string 1011 (i.e., the one-element subset {1Oll} of X*) is accepted 
by the machine 
The state q5 (like the state ql of the previous example) is a trap -
it is a 
nonaccepting state wth the property that once M enters it, M never leaves 
it: (j(q5' x) = q5 for each x in X. We may simplify state diagrams by omitting 
all trap states and the edges which lead to them. Thus the above state graph 
can be abbreviated to 
it being understood that each missing transition leads to a single trap state. 
With this convention, we see that any string XIX2 â¢â¢â¢ Xn (n ~ 0) is accepted 
by an (n + 2)-state machine 
I--_X..:.2---l~Er ... ~ 
(Why does this diagram only show n + 1 states? Does this work for n = O?) 

52 
2 Induction, Strings, and Languages 
(v) We can extend this construction to accept any finite subset of X*. 
First, we show the construction for L = {O, 11, 101}: 
o 
e 
Note that qA' not qo, is the initial state in this diagram. 
Here is the general construction. For any string w = x I â¢â¢. Xn (n ~ 0) 
of X*, we say a string w' is a prefix of w just in case w' = Xl .â¢â¢ Xm for some 
m with 0 :s; m :s; n. (Thus A is the only prefix of A; each w is a prefix of itself; 
and A is a prefix of any w.) Let, then, L be any finite subset of X* and let K 
be the set of all prefixes of L. (For example, if L = {O, 11, 101}, then K = 
{A,O, 1, 10, 11, 101}.) Then an FSA ML which satisfies L = T(ML ) may be 
defined as follows: 
The set QL of states has one distinct state qw for each string w in the set K 
of prefixes of L, together with a trap state qt. The initial state is qA' For 
each w in K and X in X 
(jL(qw, x) = 
wx' 
{ q 
ifwx is in K, 
q" 
if not, 
while (jL(q" x) = qt for each x in X. 
Finally, FL = {qwlw is in L}. 
This reduces to the construction in (v) above for L = {O, 11, 101}, as 
well as (except for renaming of the states) that of (iv) for L = {lOll}, that of 
(iii) for L = {A}, and that of (i) for L = 0. (Check the construction for 
each of these cases to make sure you agree.) 
6 Proposition. Each finite subset of X* is a finite-state language. 
0 
EXERCISES FOR SECTION 2.3 
1. Give FSAs which accept each of the following languages. 
(i) 
L = {001, 100, 11} 
(ii) L = {lklk is divisible by 3} 
(iii) L = {I k(}i I k is divisible by 3, and j is odd}. 

2.4 Context-Free Grammars 
53 
2. What languages do the following FSLs accept? 
(i) 
o 
o 
(ii) 
o 
2.4 Context-Free Grammars 
We learn to parse sentences of English with trees like the one shown in 
Figure 10. The structure of these rules may be summarized in the form: 
S -. N P V P 
a sentence (S) can take the form of a noun phrase (N P) 
followed by a verb phrase (VP). 
N P -. Det Adj N a noun phrase (N P) can take the form of a determiner 
(Det), possibly followed by an adjective (Adj), followed 
by a noun (N). 
VP -. V NP 
a verb phrase (VP) can take the form of a verb (V) 
followed by a noun phrase (NP). 
Finally, Det -. the, Adj -. ugly, N -. elephant, N -. petunias, V -. trampled 
tell us the parts of speech to which various words of English belong. 
Of course, a full grammar of English contains many more replacement 
rules (e.g., to handle prepositions, negations, conjunctions, relative clauses, 
etc.) and also contains consistency mechanisms to make sure, for example, 
that a plural verb takes a plural subject ("they give," not "he give," etc.). 
Nonetheless, context1ree grammars -
grammars whose grammatical rules 
are all of the simple replacement kind shown in Figure 10 -
have played a 

54 
2 Induction, Strings, and Languages 
~s~ 
~p~ 
VP .............. 
~ I~ 
~ 
............ NP 
Det 
Adj 
N 
I 
D~t~N 
I 
I 
I 
I 
I 
The 
ugly 
elephant 
trampled 
the 
petunias. 
Figure 10 
useful role in mathematical linguistics. Grammatical systems of this kind are 
also extremely important in computer science. This is so because context-free 
grammars are adequate for expressing much of the syntax of programming 
languages -
the rules that determine which strings of symbols constitute 
well-formed programs. 
Consider, for example, describing what strings of symbols constitute a 
number in decimal notation. Typical such numbers are 
179 -
a string of digits 
.394 -
a decimal point followed by a string of digits 
IS.64 -
two strings of digits separated by a decimal point. 
We first describe nonempty strings of decimal digits by the grammar 
M-+DIMD 
D -+ 0 111213141S16171819 
The first line says that M may be replaced by D or by M followed by D; 
the second line says that a D may be replaced by anyone of the ten digits. 
Let us use w => w' to indicate that w' is obtained from w by replacing a single 
letter with one of its acceptable substituents. Then, for example, 
M => MD => M9 => MD9 => DD9 => ID9 => 179 
Now, we saw that a number could be of the form w, .w', or w.w' where 
wand w' are nonempty strings of digits. We can describe this by 
N -+ MI.MIM.M 
A derivation of IS.64 from N is then given by 
N => M.M => MD.M => MD.MD => DD.MD => DD.DD 
=> ID.DD => IS.DD => IS.6D => IS.64 
which corresponds to the derivation tree shown in Figure 11. 
The above example is a special case of the following: 
1 Definition. A context-free grammar G = (V, T, S, P) is specified by a 
finite set V of symbols called the non terminals (or variables), a finite set T 

2.4 Context-Free Grammars 
55 
N 
/I~ 
M 
â¢ 
M 
/\ /\ 
M 
D 
M 
D 
I 
I 
I 
I 
D 
5 
D 
4 
I 
I 
1 
6 
Figure 11 
Derivation tree for 15.64. 
of symbols, disjoint from V, called terminals, an element S of V called the 
start symbol, and a finite subset P of V x (V u T)* called the set of produc-
tions. 
In the above example, we have a grammar G1 with 
V= {N,M,D} 
T = {.,O, 1,2,3,4,5,6, 7, 8, 9} 
S = N 
P = {(N, M), (N, .M), (N, M.M), (M, D), (M, MD), (D, 0), ... , (D, 9)} 
(Note then that we write v -+ w11 w2 1 ... I Wn if (v, w1), (v, w2 ), ..â¢ , (v, wn) 
are all the productions in P with v in Vas first element.) Then the decimal 
numbers are precisely those strings which can be derived from N (the start 
symbol of this grammar) and which only contain terminal symbols, i.e., the 
decimal point and the digits. This generalizes as follows. 
2 Definition. Let G = (V, T, S, P) be a context-free grammar. We define 
the binary relation => on (V u T)* -
W => w' is read as W directly derives w' 
- by specifying that 
W => W' just in case w' is obtained from W by replacing a single variable 
in a fashion specified by a production in P, i.e., just in case there 
exist W1, W2 in (Vu T)*, v in V and (v, Hi) in P such that W = 
W 1VW 2 ' W' = W1WW2. 
Note that => is then a binary relation on (Vu T)*. Section 1.3 showed 
how to associate with any relation R: A -,. A its reflexive transitive closure 
R*: A....". A. In the same way, we define the binary relation b on (Vu T)* 
as the reflexive transitive closure of =>. w~w', read as w derives w', just in 
case w = w' or there exists a sequence w1, w2 , â¢â¢â¢ , Wn (n ~ 2) of strings in 
(V u T)* such that 
. 
w = w1 ; 
Wj => Wj+ 1 
for 1 ::; j < n; 
Wn = w'. 

56 
2 Induction, Strings, and Languages 
3. The language L(G) generated by G is the set of terminal strings which can 
be derived from S: 
L(G) = {wlw E T*, S b w}. 
We say that a set A c T* is a context1ree language just in case it is an 
L(G) for some context-free grammar G. 
Here is a second example ofa context-free grammar, G2 = (V, T, S, P): 
V = {S} 
T = {a, b} 
S --+ aSb I ab. 
We see that the only possible derivations are 
S=ab 
S = aSb = aabb 
S = aSb = aaSbb = aaabbb, 
etc. Thus, if we use the notation an to abbreviate a string of n occurrences of 
the letter a, 
L(G) = {anbnln ;;:: I}. 
Let us consider a third example. A palindrome is a string of characters, 
like "pop," "madam," or "otto," which is the same forwards and backwards. 
Odd length palindromes such as "madam" pivot about a unique middle 
character; even length palindromes -
"otto" -
simply divide in half. 
There are a number offamous palindromes in English (blanks ignored), such 
as "A man a plan a canal Panama" and "Able was I ere I saw Elba." One 
of the longest English palindromes (ignoring spaces and periods!) is "Doc 
note I dissent. A fast never prevents a fatness. I diet on cod." If we restrict our 
attention to a two letter terminal alphabet, say T = {a, b}, then we can 
easily write a context-free grammar generating all and only palindromes 
over this character set: 
4. 
S --+ aSalbSblalblA. 
[Here, and in what follows, we just specify the productions when the rest of 
the grammar can be understood.] 
The derivation of abababa proceeds as follows: 
S = aSa = abSba = abaSaba = abababa. 
How do we know for sure that this grammar (i) derives only palindromes; 
and (ii) derives every palindrome over {a, b} ? The assertion that the grammar 
above meets its specification is a claim that requires formal proof. We 
now consider how such proofs may be obtained, and in particular we look at 
the close connection between context-free grammars and proofs by induction. 

2.4 Context-Free Grammars 
INDUCTION REVISITED 
Let us reconsider the grammar with productions 
S -+ aSalbSblalblA. 
57 
A proof that this grammar generates all and only palindromes is easily 
accomplished using induction. In fact, the very form of the productions in 
the grammar supplies us with exactly the facts we need to make the proof 
work. 
In order to prove this result, however, it will be useful to appeal to a slightly 
extended principle of induction, which can be shown to be equivalent to the 
induction principle developed in Section 2.1. 
5 The Principle ofInduction Extended. In order to prove a property P(n) for 
all n E N, it is sufficient to prove 
(i) a Basis Step: P(O) is true; and 
(ii) an Induction Step: If P(k) holds for all k :$; n, then P(n + 1) is true. 
It goes without saying that this principle can be used to prove results by 
induction with basis case m > 0 as well. 
Notice how this principle, which is sometimes called complete induction, 
differs from our earlier notion of inductive proof. Here the induction step 
allows the assumption of P(k) for all k < n in addition to the assumption 
P(n). 
Using this extended principle of induction, we can now prove that our 
palindrome grammar does indeed meet its specification. 
6 Lemma. L( G) for the grammar G whose productions are given in 4 is just 
the set of palindromes over {a, b}. 
PROOF (i) We first show that our grammar generates only palindromes. 
Basis Step: Suppose a string x E L, and t(x) = 0 or t(x) = 1. Strings of 
length 1 or 0 may only be derived by the productions 
S -+ a, 
S -+ b, S -+ A. 
Hence, for strings of these lengths, our (basis) claim that only palindromes 
are produced is indeed correct. 
Induction Step: Next, suppose that for all strings x E L(G) such that 
t(x):$; n, where n ~ 1, x is a palindrome. We must show that if y E L(G), 
t(y) = n + 1, then y is a palindrome. We argue as follows: ifS b y, t(y) ~ n, 
then the derivation of y must begin with either 
S -+ aSa or S -+ bSb. 

58 
2 Induction, Strings, and Languages 
For definiteness, let us assume the first case holds (the argument for the 
second case is exactly the same). Thus 
S => aSa b y 
and hence y begins and ends with an a. But then the S occurring between the 
a's in the center expression must derive a string y' of length n -
1, where 
y = ay' a. By our inductive hypothesis, y' is a palindrome, and therefore so 
is y, since pasting an "a" at the front and back of a palindrome preserves the 
symmetry of string reversal. Thus our grammar generates only palindromes. 
(ii) A similar argument establishes that our grammar generates every 
palindrome. As our basis step, we consider all length 0 and length 1 palin-
dromes over {a, b}. There are only three palindromes of these lengths, A, 
a, b, and G trivially generates all of these. Now suppose G generates all 
palindromes of length 5, n, for n ~ 1. Let x be a length n + 1 palindrome. 
We must use the inductive hypothesis and the actual productions of the 
grammar to show how x may be generated. The first and last characters of x 
must be the same, and without loss of generality, let us assume this character 
is "a." That is, x = ax'a, where x' is a string oflength n -
1. Since x' falls in 
the" center" of x, x' must itself be a palindrome. Hence, by the inductive 
hypothesis (t(x') 5, n) S b x'. But then x is derivable by the sequence 
S => aSa b ax' a = x. 
0 
Consider, again, the context-free grammar which generates all the decimal 
numbers: N -> MI.MIM.M with M --+ DIMD. If D stands for any of the 
ten digits, the L(G 1) of this grammar is the set of strings accepted by the 
machine [Exercise: Restructure the machine to avoid the two D-transitions 
from qo.J: 
qo is the only initial state; q 1 is the only accepting state; and the set of accepted 
strings is just L(G 1). 
This raises the question: Is every context-free language a regular set? 
The answer is no, as the following observation shows. 
7 Observation. The language {anbn I n ~ I} is not accepted by any finite 
state acceptor M. 
PROOF. Suppose that every string of the form anb" were accepted by M. 
We shall show that M must accept a string not of the form a"b". Let M have 
k states, and consider the sequence 
(<5*(qo, a"): 0 5, n 5, k) 

2.4 Context-Free Grammars 
59 
where we use c5*(qo, an) to denote the state of M reachable from the initial 
state qo by applying a string n a's. There are k + 1 states in this sequence, 
and so at least two of them must be .the same, say 
c5*(qo, a') = c5*(qo, as) for some 0 ~ r < s ~ k. 
But then as we see from the diagram 
we must have that 
c5*(qo, arbs) = c5*(c5*(qo, ar), bS) 
= c5*(c5*(qo, as), bS ) = c5*(qo, aSbS) 
which belongs to F, since M accepts every string in {anbn: n ~ 1}. Thus M 
accepts a'bs. But r -# s, and so M cannot accept the exact set {anbnln ~ 1}. 
D 
The detailed study of context-free languages must be left to another 
volume. We close our present discussion with an example of an alternative 
notation for context-free grammars which is popular for specifying the 
syntax of programming languages. We present the syntax of decimal numbers 
in the form: 
<decimal number) ::= <unsigned integer) IÂ· <unsigned integer) 1 
<unsigned integer) . <unsigned integer) 
< unsigned integer) ::= < unsigned integer) < digit) 1 < digit) 
(digit)::= 0111213141516171819 
Each nonterminal is represented by a name in angle brackets ( ); we use 
::= instead of the replacement arrow; and we use 1 to separate the alternative 
replacements for the nonterminal occurring to the left of the ::= in the display. 
This way of representing the productions of a context-free grammar was 
introduced by Backus and Naur in specifying the syntax of the programming 
language Algol, and is referred to as BNF for Backus-Naur Form. 
8 Example. The inductive definition of X* can be recast in the BNF as 
follows: 
(string)::= AI <element) (string) 
Here elements of X* correspond to "string" and elements of X correspond 
to "element." 

60 
2 Induction. Strings. and Languages 
EXERCISES FOR SECTION 2.4 
1. Write context-free grammars for the following languages: 
(a) Lt = {a"bma" In, m:2: I} (A typical string: aaabbaaa) 
(b) L2 = {a"bmcbma" In, m :2: I} (A typical string: a2b3cb 3a2) 
(c) L3 = {x E {a, b}* Ix contains an equal number of a's and b's} 
(A typical string: baaababb). 
2. Suppose L, and L2 are context-free languages over the alphabet V = {a, b}. Prove 
that L, u L2 is also a context-free language. 
3. Suppose L is a context-free language over {a, b}. Define L R to be the set of strings 
obtained by reversing all the strings in L. Show that L R is also context-free. (Hint: 
What change in the productions of a grammar for L might bring this about?) 
4. Assign parts of speech to the words of the sentence, "John walked the salty dog," 
and then provide a parse tree for it using the grammar presented at the beginning 
of this section. 
5. (a) What language does the grammar 
generate? Prove your result. 
(b) Is this language an FSL? 
S -+ aaA 
A -+ aa I aaA I B 
B -+ blbB 
6. Use the technique of Observation 7 to show that the. following languages cannot be 
accepted by any finite state acceptor. 
(a) {a"bmln:2: m} 
(b) {a"bmln :::; m} 
(c) {ak I k is a power of 2}. 
2.5 Processing Lists 
We may regard the typical element of X* as being a list, (Xl' X 2 , .â¢â¢ , x n), 
whose typical entry Xj is an element of X. In this section we look at a typical 
data-retrieval problem -
finding someone's number in a telephone direc-
tory -
as an exercise in list-processing. We look at it in three passes: first, 
informally and set-theoretically (and with some comments on Pascal, an 
increasingly popular programming language); second, using the inductive 
definition of X*; and, third, in the context of an introduction to the List 
Processing language, Lisp. The algorithms in this section will involve sequen-
tial search -
looking at one entry after another till we find the one we want. 
In Section 3.3 we shall look at a different method, called binary search, 
which yields a far more efficient algorithm. 

2.5 Processing Lists 
A telephone directory can be viewed as a finite list 
(entrYl' entrY2,Â·Â·Â·, entrYbÂ·Â·Â·, entrYn) 
of entries. Each entry is in turn a list of three elements 
entrYk = (namek, addressb numberk)Â· 
61 
These three items are themselves lists of characters. For the present purpose, 
we need not analyze the character set, but it is worth noting that it must 
include a blank character, which we denote" (quotes with a single space 
between then). The blank is not the empty string (hitting the space bar on a 
typewriter is not the same as hitting no key at all): t(") = 1, teA) = 0, and 
BOGGS"E"Q = BOGGS E Q =I- BOGGSEQ = BOGGSAEAQ 
In any case, we define the format for a telephone directory using a character 
set called character (we use mnemonic names in italics to denote sets here, 
rather than the single letters that prove convenient in more general algebraic 
settings). We set up three subsets of character*: 
name = set of character strings which serve as names, 
address = set of character strings which serve as addresses, 
number = set of character strings which serve as phone numbers. 
For example, a typical element of name might consist of a family name fol-
lowed by a blank followed by a string of initials separated by blanks; while 
a typical element of number might have the form 555-1212, three digits 
followed by a hyphen and four more digits, so that number = D3 x {-} 
X D4. 
We then define entry, the set of possible entries, as a Cartesian product 
entry = name x address x number. 
The set of possible directories is then the set of sequences of entries, 
directory = entry*. 
A directory W is an element of directory, i.e., a finite (possibly empty) list 
of entries, each of which is an element of entry. (In the present discussibn we 
have not required that the directory be arranged in alphabetical order by 
name, or that an entry occur only once. We shall look at a program which 
searches the directory item-by-item until the desired entry is found. In a 
course on data structures you will learn about sorted lists. Search time for 
sorted lists can be cut by making intelligent use of the knowledge of whether 
the desired item occurs before or after the one under current scrutiny. See 
Section 3.3 for an example of this.) 
Here, then, is an informal program to determine the phone number of 
BOGGS E Q in a directory by a sequential search (going through the list 

62 
2 Induction, Strings, and Languages 
one entry at a time). The program will give NIL as output if there is no 
entry under this name. 
1. Let the first entry be the current entry. 
2. Is BOGGS E Q the name in the current entry? 
if YES: 
Print out the number of that entry, and HALT. 
if NO: 
Is there another entry left in the directory? 
if YES: 
Make it the current entry and return to 2. 
if NO: 
Print out NIL and HALT. 
ARRA YS AND PASCAL 
We now show how this can be written in a Pascal-like language. We start 
by specifying the number N of entries in a directory, so that we require 
that each directory belong to the N -fold Cartesian power 
directory = entryN 
(1) 
rather than having the arbitrary length allowed members of entry*. 
Each entry is still a list of three elements, so we have the Cartesian product 
entry = name x address x number. 
(2) 
Before giving the Pascal program, we must show how Pascal represents the 
definitions (1) and (2). In a programming language, a data type is a set 
together with certain basic operations that a program may perform upon it. 
Let us assume that we have already been given the data types name, address, 
and number and that we have operations available which let us test two 
strings of the same data type to see if they are equal. In carrying out the 
definitions (1) and (2), we not only want to build up the right set of elements, 
but wish to have operations for reading out specified elements of the list. 
For example, in (1) we need N maps, directory -
entry, w 1---+ w[j] which let 
us read out the jth entry of the directory w, 1 :::; j :::; N. And in (2) we need 
three selector maps 
entry -
name, 
x 1---+ x.sname 
entry -
address, 
x 1---+ x.saddress 
entry -
number, 
x 1---+ x.snumber 
where x.sname, x.saddress, and x.snumber are, respectively, the first, second, 
and third component of x. If, for example, x = (BOGGS E Q, 99 WILLOW 
RD, 555-1212), then x.snumber = 555-1212. 
Pascal uses the notation (known as a data type declaration) 
type entry = record name: a; 
address: b; 
end; 
number: c 

2.5 Processing Lists 
63 
to indicate that the new data type entry is the Cartesian product of three 
already-defined data types a, b, and c, and that the respective entries in an 
item of this Cartesian product can be accessed by using the selectors sname, 
saddress, and snumber respectively. 
Pascal uses the notation (data type declaration) 
type directory = array [1. .N] of entry; 
to indicate that the new data type directory is the N-fold Cartesian power of 
the already defined data type entry, and that the jth entry (1 ::; j ::; N) in an 
item of this Cartesian power can be accessed by using the maps w 1-+ wU]' 
A Pascal program to scan our directory would then look something like 
this (where we use the braces { } to enclose comments that are not part of 
the program): 
type entry = record name: a; 
address: b; 
number: c 
end; 
type directory = array [1 .. N] of entry; 
var: w: directory; 
x: entry; 
nm: a; 
nr: c; 
i: l..N; 
{So far, we have just repeated the definition of entry in terms of a, b, and c, 
and of directory in terms of entry. We have then introduced five variables, 
and have specified what data types each will take its values from for the 
program. For example, nr will take its value from c, i.e., each value will be a 
phone number. The last line tells us that i can take any value in the range 1 
through N.} 
load(w), load(nm) 
{This is not formal Pascal notation, but indicates that the program must 
assign to w as value the actual directory that is to be searched; and must 
assign to nm the name for which we wish to find the c('lTesponding phone 
number.} 
begi~ for i := I to N do 
{This line tells the computer to repeat the operations below, starting first 
with i = 1, and then repeating the procedure, increasing i by 1 each time 
until either the goto I sends the computation to the line of the program 
labelled 1; or until the program has completed the entire procedure N times. 
In the latter case, control is then transferred to the next line of the program.} 
begin x := w[i]; {get the ith entry of the directory w} 
if x.sname = nm then begin nr := x.snumber; goto I end 
end; 
nr := "NIL"; 

64 
2 Induction, Strings, and Languages 
{Set nr to the number item x.snumber of the first entry x = w[iJ whose 
name item x.sname equals the given name nm. If no such entry is found, 
set nr to "NIL." (The quotes indicate that it is the actual string NIL ofthree 
characters that is required.)} 
1 Print ("THE PHONE NUMBER FOR" nm "IS" nr) 
end 
In a flow diagram, leaving aside the declarations: 
ENTRY 
EXIT 
We have just seen how to represent a directory as an array of fixed length, 
and then use a counter to keep track as we work our way through the directory, 
one entry at a time. This, then, is the iterative solution to the phone number 
problem. We now return to the inductive definition of X* and see how this 
allows us to define the phone-number-retrieval function by induction. 
Our goal, then, is to define the function PHONENR: directory x name 
-> number so that PHONENR(w, nm) is the phone number occurring in 

2.5 Processing Lists 
65 
the first entry of w whose name item is nm; and is NIL if no such item occurs 
in w. This immediately yields the 
Basis Step: PHONENR(A, nm) = NIL 
for if there are no entries in the directory (w = A), there are certainly no 
entries which start with nm. For our induction step, note that a nonempty 
directory w has the form (x, w') with x in entry and w' in directory. Then 
either x starts with nm, and we are done, or we simply forget about x, and 
move on to search w'. We thus have the 
Induction Step: Ifw = (x, w') with x in entry and w' in directory, then 
(a) If x.sname = nm, 
then PHONENRÂ«x, w'), nm) = x.snumber 
(b) If x.sname '# nm, 
then PHONENRÂ«x, w'), nm) 
= PHONENR(w', nm). 
S-EXPRESSIONS AND LISP 
We now introduce a few basic features of the programming language Lisp, 
and show that they permit us to translate the inductive definition of a 
function such as PHONENR directly into a Lisp program, without the use 
of counters. 
We first introduce the basic Lisp data structure, the s-expression, (short 
for symbolic-expression). In defining strings in X*, our inductive step was 
to form (x, w) where x was in X and w was a previously formed element of 
X*. By contrast, the inductive step in the formation of s-expressions in 
Lisp combines a pair of s-expressions. 
1 Definition. Let A be a set. Then the set S(A) of s-expressions over A is 
defined inductively by: 
Basis Step: Each a in A belongs to S(A). 
Induction Step: If W1 and W2 are s-expressions, then the dotted pair 
(Wl . w2) is also an s-expression. 
We say that an element of S(A) is an atom just in case it belongs to A. 
Lisp further requires that A contain two distinguished elements, T and 
NIL. These two elements are used to denote the truth values true and false, 
respectively, so that a predicate is represented in Lisp by a function 
S(A) -. {T, NIL}. NIL also plays a second role, namely the role that the 
symbol A played in the inductive definition of X*. (Warning: Different 
computer centers have different versions of Lisp. In what follows, we present 
basic concepts of Lisp, but we do not expect that the programs will run as 
printed. However, with the understanding that this section provides, you 
should find it fairly easy to use a manual to get programs running if your 
neighborhood system has a Lisp interpreter.) 

66 
2 Induction, Strings, and Languages 
2 The basic predicate of Lisp is ISATOM: SeA) ~ {T, NIL}, which tells 
whether or not an s-expression is an atom 
{ T 
ifw is in A; 
ISATOM(w) = ~IL, ifnot. 
An s-expression can also be represented by a Lisp or L-tree. For example, 
the s-expression Â«aÂ· b)Â· c) is represented by the L-tree 
root------------~ 
nOde~ 
leaf ----l.~ a 
b 
We see that an L-tree is a collection of straight lines. The lines are called 
branches while the ends of the lines are called nodes or vertices. We see that 
there is one node at the top called the root, and that every other node is at the 
lower end of a single branch. Each node is either at the top of two branches 
(one to the left and one to the right), or it is at the top of no branches at all. 
In the latter case we call the node a leaf, and label it with an atom. We say 
that a leaf is a terminal node, and that other nodes are nonterminal. 
The rule for representing an s-expression by a tree is easily given induc-
tively: 
Basis Step: If a is an atom, then the tree T (a) representing a comprises a 
single node labelled by a. 
Induction Step: If Wl and W2 are s-expressions represented by the trees 
T(w1) and T (w 2) respectively, then (Wl . w2) is represented by 
1\ 
T(Wl) 
T(W2) 
For example, TÂ«aÂ· b)Â· (aÂ· (bÂ· c))) equals 
b 
c 

2.5 Processing Lists 
67 
To see how s-expressions may be represented in the computer, we may 
redraw the tree by replacing each non-terminal node by a box 
and each terminallabeled a by a box 
We can then rearrange the position of the nodes without losing track of what 
comes first. In this box-notation, Â«aÂ· b) . (a . (b . cÂ») becomes 
o 
(1) 
One strategy for storing s-expressions in a computer has each box 
correspond to a word in computer memory. Words in one portion of memory 
-
say, words in a particular range of memory addresses -
are treated as 
atoms. Words outside this range correspond to nonatomic s-expressions, 
and are divided in two. Each half of a" nonatomic" word contains the address 
of the word toward which it points. Notice that with this scheme, ISATOM 
(recall 2) is particularly easy to compute -
the address of ISATOM's 
argument determines if the argument is an atom. 
Given a dotted pair (Wl . W2), it is important to be able to extract W1 
and W 2 â¢ Conversely, given W1 and W2 we want to be able to form them into 
(Wl . w2 ). We thus need three functions: 
1. HEAD: SeA) -+ SeA) is a partial function defined inductively by 
{HEAD(a) = 1- (i.e., is undefined) if argument a is an atom, 
HEADÂ«wl . w2Â» = W1 
otherwise. 
2. TAIL: SeA) -+ SeA) is a partial function defined inductively by 
{TAIL(a) = 1-
if argument a is an atom, 
TAILÂ«wl . W2Â» = W2 
otherwise. 

68 
2 Induction, Strings, and Languages 
3 CONS: S(A) x S(A) ~ S(A) is the construction function defined explicitly 
by 
CONS(w 1, w2 ) = (Wl . w2 )Â· 
In Lisp, HEAD is called CAR, and TAIL is called CDR. It may help to 
notice that A comes before D, so CAR comes before CDR. But to understand 
the notation, we must return to the box notation (1) for W = Â«aÂ·b)Â·(aÂ·(bÂ·cÂ»). 
If the interpreter has the address a for the root node of w, it obtains the 
address of the root node of CAR( w) = (a . b) simply by reading the first half 
of the contents of the word at address a. Now, in the IBM 7090, the machine 
on which Lisp programs were first written, the first half of a word of computer 
memory was called the Address Register -
and so CAR was short for 
Contents of the Address Register. The second half of a word in memory was 
called the Decrement Register -
and thus CDR. 
We can of course compose the above functions. For example, it is always 
true that 
and 
CDR(CONS(w 1, w2Â» = w2 â¢ 
Turning to a specific example 
CAR(CDR(CDRÂ«a' (b . (d . cÂ»Â»Â» = CAR(CDRÂ«bÂ· (d . cÂ»Â» 
= CARÂ«d . cÂ» 
= d. 
Since this use of chains of CARs and CDRs is very common in Lisp, there 
is a standard abbreviation - write C, then the middle letter of each CAR and 
CDR in order, then close with R. So, for example, CADDR is short for 
CARÂ· CDRÂ· CDR, and we have 
CADDRÂ«a . (b . (d . cÂ»Â» = d 
while 
CADRÂ«aÂ· (bÂ· (d . cÂ»Â» = b 
and 
CDARÂ«aÂ· (b . (d . cÂ»Â» = 1-. 
Lisp has a special function EQ which can compare two atoms and tell if 
they are equal: 
E 
(Wb W2 
-
. 
Q 
) _ {T 
ifwl and W2 are both atoms and W1 = w2 , 
NIL otherwIse. 

2.5 Processing Lists 
69 
Let us use this to define a Lisp program to check whether two arbitrary 
s-expressions are equal. (Repeated warning: Your local Lisp interpreter may 
require a different format from that used here. But the ideas are the same.) 
We have to define EQUAL: SeA) x SeA) --+ {T, NIL} so that 
{ T 
ifw = w' 
EQUAL(w, w') = NIL if w # w'. 
This is easy if w is an atom, since then 
EQUAL(w, w') = EQ(w, w'). 
If w is not an atom but w' is an atom, we have 
EQUAL(w, w') = NIL. 
But if neither w nor w' is an atom, then we have 
w = (Wt' wz) where W t = CAR(w) and Wz = CDR(w) 
w' = (w't . w~) where w~ = CAR(w') and w~ = CDR(w') 
and it is clear that 
A = A if and only if both wt = W't and Wz = w~. 
w t 
Wz W't 
w~ 
The Lisp conditional generalizes the if ... then ... else construct that we have 
already used. Its general form is 
(COND(P t 
F 1) 
(Pz F z) 
and it is executed as follows: If the predicate Pt is true, then evaluate Ft to 
obtain the result; otherwise, if P z is true, evaluate F z to obtain the result; 
... ; if Pn is true, evaluate Fn to obtain the result; if none of Pt through Pn is 
true, then the result is undefined. 
If Pn is just T, then should none of Pt through Pn - t evaluate to T, then 
Fn will automatically be evaluated to obtain the result. We use AND to 
combine two truth values. 
AND(T, T) = T, while 
AND(T, NIL) = AND(NIL, T) = AND(NIL, NIL) = NIL. 

70 
2 Induction, Strings, and Languages 
Thus we have the following recursive Lisp program for EQUAL: 
EQUAL(w, w') = (CONDÂ«ISATOM(wÂ» (EQ(w, w'Â») 
Â«(ISATOM(w'Â» NIL) 
(T Â«EQUAL(CAR(w), CAR(w'Â»)AND 
(EQUAL(CDR(w), CDR(w'Â»Â»Â». 
Look at how EQUAL compares the L-trees 
a 
b 
Since the first two tests (ISATOM(w) and ISATOM(w'Â» both return NIL, 
we have to test EQUAL(CAR(w), CAR(w'Â» 
and EQUAL(CDR(w), 
CDR(w'Â». The first chore reduces to testing both 
EQUAL(a, a) and EQUAL(b, b) 
which both return T, so that EQUAL(CAR(w), CAR(w'Â» = T. However, 
CDR(w) = c is an atom, and so 
EQUAL(CDR(w), CDR(w'Â» = EQ(c, CDR(w'Â» 
= NIL, since CDR(w') is not an atom. 
Thus 
EQUAL(w, w') = EQUAL(CAR(w), CAR(w'Â»AND EQUAL(CDR(w), 
CDR(w'Â» 
= TANDNIL 
= NIL 
and so our program confirms (correctly )that w i= w' in this case. 
So far in our discussion of Lisp we have considered as objects of study 
only s-expressions -
trees built up from atoms using the operator CONS. 
But clearly a much more reasonable representation for many objects in 
computer science is a list: (W 1W2 â¢â¢â¢ wn). Now lists are such a common and 
important data structure that Lisp systems permit list notation, with the 
understanding that a list -
say (A B C) -
is an abbreviation for the s-
expression (A . (BÂ· (C . NIL))), i.e., 
A~ 
C 
NIL 

2.5 Processing Lists 
71 
Notice that (CAR(A B C) = A, CDR(A B C) = (B C), and CONS(A (B CÂ» 
= (A BC). 
Now let us return to our telephone directory. Using list notation, we can 
represent our directory as 
(W1WZ â¢.â¢ wn-1wn) 
and a typical entry of the telephone book is of the form 
e = Â«(X[Jy) 
where (X is a name, [J is an address, and y is a number. 
Now at the end of the previous subsection we defined 
PHONENR: directory x name -> number 
recursively by 
Basis Step: PHONENR(A, nm) = NIL 
Induction Step: Let W = (x, w'). If nm = x.sname then 
PHONENR(x, nm) = x.snumber, else PHONENR(w, nm) 
= PHONENR(w', nm). 
(2) 
(3) 
We can immediately transform this into a Lisp program which will take 
any directory w that is legally defined as a list of the form (2) whose entries are 
legally defined (name, address, number) triples of the form (3), and any name 
nm and will return the third component of the first entry for which nm is the 
first component; and will return NIL if no such entry exists in w. Here is our 
phone number program in Lisp. Notice that if CAR(w) is the first entry in 
the directory, then CAAR(w) is the name field of the first entry, and 
CADDR(w) is the number field of the first entry. 
PHONENR(w, nm) = (COND(EQUAL(NIL, w) NIL) 
EXERCISES FOR SECTION 2.5 
(EQUAL(nm, CAAR(wÂ» CADDAR(wÂ» 
(T PHONENR(CDR(w), nmÂ». 
1. Suppose a university keeps a record of each student which contains in order, the 
student's name, address, year of graduation, and -
for up to 50 courses - the course 
number, title, semester of study, and final grade. Provide an explicit description ofa 
Cartesian product of sets to which each record belongs. Provide a data type declara-
tion for this record structure. (Hint: To make all records the same length, include 
in the set of course numbers a "dummy number," call it NOTYET, to fill in for courses 
not yet taken.) 
2. Write down an iterative program to compute the grade-point average for a student 
from the record of Exercise 1. (Let each course grade be a number between 0 and 4. 
Sum up the course grades, then divide by the number of courses already taken.) 

72 
2 Induction, Strings, and Languages 
3. Define a recursive structure which is a list of course results, each of which comprises 
a course number and final grade for a course. Provide a recursive program which 
can compute the grade-point average (see Exercise 2) from such a list. 
4. Write the following s-expressions and lists in box notation. 
(i) (aÂ·(bÂ·(cÂ·cÂ») 
(ii) (A B C D) 
(iii) (A B C(D EÂ») 
5. What is CADARÂ«A B) CD E)? 
6. Describe in words what the following Lisp program does. 
FIRST(S) = (COND(ATOM(S) S) 
(T FIRST(CAR(S)). 
7. Let A be an atom, and B be an s-expresslOn. Provide a recursive definition of a 
function IS.MEMBER such that IS.MEMBER(A, B) equals T if A occurs in the 
s-expression B, but equals NIL otherwise. 

CHAPTER 3 
Counting, Recurrences, and Trees 
3.1 Some Counting Principles 
3.2 Trees and Recurrences 
3.3 An Example of Algorithm Analysis 
Section 3.1 introduces a number of principles useful in counting complicated 
sets of objects. These principles include the rule of sum, the rule of product, 
and the pigeonhole principle. The section also introduces permutations and 
combinations, and the binomial theorem. Section 3.2 extends the formal 
study of trees, which were briefly encountered in Chapter 2, and explores 
ways of counting and computing based on recurrence relations. The final 
section has a different flavor but is still devoted to counting -
this time to 
counting the number of steps taken by an algorithm to process data. It 
thus introduces the reader to the important topic of "analysis of algorithms" 
which enables us to compare the efficiency of different approaches to solve 
a given problem. 
3.1 Some Counting Principles 
Counting related objects in large collections is a matter of finding a syste-
matic way for listing the members of the collection. Some of these ways occur 
frequently enough in practice so that we may formulate them as "counting 
rules" or "counting principles." 
1 The Rule of Sum. Let X and Y be mutually exclusive events (that is, X and 
Y cannot both occur at the same time). If X can happen in m different ways, and 
Y can happen in n different ways, then the event (X or Y) can happen in (m + n) 
different ways. 
73 

74 
3 Counting, Recurrences, and Trees 
2 Example. Suppose that statement labels in a programming language are 
either single alphabetic symbols or single decimal digits. If we call X the 
event that a statement label is an alphabetic symbol, then X can happen in 
any of 26 different ways, i.e., X can take any value from the set {A, B, C, 
... , Z}. If we call Y the event that a statement label is a decimal digit, then Y 
can happen in any of 10 different ways, corresponding to the distinct choices 
of values, from the set {O, 1,2, ... , 9}. Hence a statement label, whether 
alphabetic symbol or decimal digit, denoted by the event (X or Y) can happen 
in (26 + 10) = 36 possible different ways. 
3 The Rule of Product. Let X and Y be mutually exclusive events. If X can 
happen in m different ways and Y can happen in n different ways, then the 
event (X and Y) can happen in m x n different ways. 
4 Example. If we can go from Amherst to Boston in 3 different ways, say 
{a, b, c} and from Boston to New York in 5 different ways, say {I, 2, 3,4, 5}, 
then we can go from Amherst to Boston and then from Boston to New York 
in 3 * 5 = 15 different ways. This situation can be described by the tree of 
Figure 12. 
Thus the different ways of going from Amherst to New York via Boston 
may be specified by the set {aI, a2, a3, ... , c4, c5} -
altogether 15 different 
routes. 
The reader may recognize these rules as being new versions of facts 
about the number of elements in a set given in Fact 1.1.2. If A is the set of 
different ways in which X can occur, and B is the set of different ways in 
which Y can occur, then the rule of sum asserts that 
From 
Amherst 
to 
New York 
From 
Amherst 
to 
Boston 
From 
Boston 
to 
New York 
lA uBI = IAI + IBI 
a 
b 
c 
AA~ 
1234512345 
1 2 3 4 5 
Figure 12 A tree illustrating the Rule of Product. 

3.1 Some Counting Principles 
whenever A and B are disjoint; while the rule of product asserts that 
lA x BI = IAI * IBIÂ· 
75 
5 The Rules of Sum and Product (Generalized). If an event X 1 can happen in 
ml different ways, X 2 in m2 different ways, ... , X k in mk different ways, then if 
each pair of distinct Xi are mutually exclusive, 
(a) the event (X 1 or X 2 or ... or Xk) can happen in (ml + m2 + ... + mk) 
different ways; 
(b) the event (X land X 2 andÂ·Â·Â· and Xk) can happen in (ml * m2 * ... * mk) 
different ways. 
6 Example. Consider the collection of all non-negative integers less than 
10,000 that contain the digit 1. We wish to determine the percentage of all 
non-negative integers less than 10,000 this collection represents. 
We can solve this problem by first counting all integers between Â° and 
10,000 (inclusive) that do not contain the digit 1. We proceed by counting 
all strings of 4 symbols from the set {a, 2, 3, 4, 5, 6, 7, 8, 9}. There are 9 
choices for the first digit, 9 choices for the second digit, 9 choices for the 
third digit, and 9 choices for the fourth digit. (Of course, we don't usually 
include leading O's when we write a number. For this example, however, we 
identify 0042 as the four digit string for the number 42.) This situation can be 
described by the tree shown in Figure 13. 
By the Rule of Product, there are 94 = 6561 such numbers. This is also 
the number of distinct paths from the" root," the left-most node, in the tree of 
Figure 13 to one of the right-most nodes or "leaves." Hence, the number of 
(decimal) integers between Â° and 10,000 that mentions the digit 1 is 10,000 
- 6541 = 3439. That is, slightly more than! of all integers between Â° 
and 
10,000 contain the digit 1. 
We can take this result one step further, and draw from it a conclusion 
about "the probability of the digit 1 occurring in decimal numbers." Suppose, 
for example, that we fill a (rather large) bag with 10,000 numbered marbles. 
If we draw a marble at random and record its number, then toss it back and 
shake up the bag, and if we repeat this process as often as we wish, then on 
the average, about! ofthe recorded decimal numbers should contain a 1. 
The Rule of Product provides us with an alternative way of looking 
at the following result (already proved in Corollary 1.3.10). 
7 Theorem. Any set ofn elements has 2n different subsets. 
PROOF. Let the elements of the set S be ai' a2, ... , an' Any particular subset 
of this set either contains the element a 1 or it does not. This means that the 
event al E S can happen in two ways. Similarly, each of the events a2 E S, 
... , an E S, can happen in two ways. The number of ways in which all these 

76 
3 Counting, Recurrences, and Trees 
choices 
for the 
second 
third 
fourth NUMBER 
first digit 
digit 
digit 
digit 
FORMED 
o\~ 
0000 
0 
0002 
2 
. 
0 
2 
. 
. 
9 
0009 
2 
9 
9 
3 
0 
0 
2 
2 
9~~ 
3290 
3292 
9 
9 
3299 
9 
0 
2 
9 
Figure 13 The tree whose paths represent 4-digit numbers not including the digit 1. 
events can happen simultaneously is, by the Rule of Product, (2 * 2 * ... * 2) 
n times = 2n -
and this is precisely the number of distinct subsets of the set 
{ab a2,"" an}, as in Figure 14. 
0 
8 Example. Determine the number of ways in which a nonempty string of 
symbols from the set {A, B, C, D} can be selected such that the string 
mentions each symbol at most once. 
Four different kinds of selections are possible: The string in question 
may be of length 1, or of length 2, or of length 3, or of length 4. Let us denote 
these four subevents by X 1> X 2, X 3, and X 4, and the numbers of ways in 
which each can occur by m1, m2, m3, and m4' respectively. By the Rule of 

3.1 Some Counting Principles 
77 
Element al 
~ 
out 
In 
Element a2 
A 
A 
Ol;1t 
In 
out 
t.n 
Element an 
~. 
out 
In 
I 
I 
Set Formed o 
{an} 
Figure 14 A tree whose paths represent the subsets of {aI' ... , an}. 
Sum (X 1 or X 2 or X 3 or X 4) can happen in m 1 + m2 + m3 + m4 different 
ways. 
A string of length 1, i.e., XI' can happen in four different ways, hence 
ml = 4. For X 2, we have to count the number of ways in which two different 
symbols from {A, B, C, D} can be written: X 2 consists of a first symbol 
(which can happen in four different ways), and a second symbol (which can 
happen in three different ways, the letter placed in first position not being a 
possibility for the second position). Hence, by the Rule of Product, 
m2 = 4 * 3 = 12. 
Using the Rule of Product again, and by a similar reasoning, we have 
m3 = 4 * 3 * 2 = 24 and m4 = 4 * 3 * 2 * 1 = 24. Hence, strings of length 
~4 with nonrepeating symbols from the set A, B, C, D can be chosen in 
4 + 12 + 24 + 24 = 64 different ways. 
Let us now examine another counting technique which, although not 
adding anything new to the Rule of Sum and Rule of Product (Exercise 14), 
should be identified separately given its importance. This is the so-called 
"pigeonhole principle," which we first state in its simplest form. 
9 The Pigeonhole Principle (simplified). If (n + 1) pigeons occupy n pigeon-
holes, then at least one hole will house at least two pigeons. 
10 Example. In a group of 367 people, at least 2 will have the same birthdate. 
Although it is deceptively simple to state, the Pigeonhole Principle, in the 
form given above, is a powerful tool. We illustrate its power with the following 
result from Number Theory. 
11 Theorem.Ifn + 1 numbers are selected from the set {I, 2, 3, 4, ... , 2n -
1, 
2n} then one of the selected numbers will divide some other evenly. 
PROOF We can write each of the n + 1 selected numbers as a power of 2 
times an odd part. For instance, 1 = 2Â° Â·1, 14 = 21 Â·7,40 = 23 .5, etc. 

78 
3 Counting, Recurrences, and Trees 
Now there are exactly n odd and n even numbers between 1 and 2n, and 
we shall use the n odd numbers as our pigeonholes. This is done by associating 
each chosen number with the odd part of its even-odd factorization (e.g., 
40 goes with 5). Since n + 1 numbers are selected, and each is associated 
with one of at most n odd numbers, some odd number gets two associates. 
If the odd number is k then its associated pair, 2'Â· k and 2i . k, has the desired 
property. 
D 
A few comments are in order concerning the preceding theorem. First of 
all, we classify it as a best possible result, in the sense that if we weaken 
the hypothesis in the most minimal way the theorem is no longer true. 
Indeed, if we select only n (instead ofn + 1) numbers from 1 to 2n, we do not 
necessarily have a pair among them that divide evenly. For example, none 
of the n numbers 
{n + 1,n + 2,n + 3, ... ,2n} 
can divide evenly any of the others in the set. 
Further, the preceding theorem is called an existence theorem, because its 
statement is of the following form: 
"For every configuration with properties ... , there exists an element 
(exist elements) in this configuration satisfying conditions ... ". And the 
proof of the theorem is called (naturally enough!) an existence proof. 
Existence proofs may be constructive or non-constructive. A constructive 
existence proof demonstrates the existence of elements satisfying the con-
clusion of the theorem by actually "constructing" them; e.g., by describing 
a step-wise method of calculating these elements. A non-constructive exis-
tence proof, on the other hand, does not exhibit such elements. 
We may then call the preceding application of the pigeonhole principle a 
"non-constructive existence proof," since it proves the existence of a certain 
pair of numbers without actually calculating them. But is it really non-
constructive? While this is apparently the case, the proof may nevertheless 
be converted into an algorithm to extract the numbers in question. For 
example, we can list the (n + 1) selected numbers from the set {1, 2, 3, ... , 
2n}, factor each into a power of 2 times an odd part, and finally search 
exhaustively for two among them that have the same odd part. 
We discuss other proof techniques in Section 4.2. 
Just as we generalized the Rule of Sum and Rule of Product, we can also 
generalize the Pigeonhole Principle. Thus, if 2n + 1 pigeons fit into n holes, 
then at least one hole will house at least 3 pigeons. And if there are (3n + 1) 
pigeons, then at least one hole will house at least 4 pigeons. For the general 
statement of the Pigeonhole Principle, given in the next theorem, we need to 
introduce new notation. 
Given a non-negative number x, the floor of x, denoted Lxj, is the unique 
integer n such that (x - 1) < n :::;; x. In other words, Lxj is obtained from x 
by throwing away its fractional part. The ceiling of x, denoted by Lxj, is the 

3.1 Some Counting Principles 
79 
unique integer n such that x :s;; n < (x + 1). Thus r x 1 is the smallest integer 
~x. For instance, given n = 3.14 ... , Lnj = 3 and rnl = 4. 
12 Theorem (The Pigeonhole Principle). /fm pigeons occupy n holes then one 
hole contains at least L(m -
l)/nj + 1 pigeons. 
PROOF. The largest number k such that k * n is less than m is precisely 
L(m -
1)/nj. If we had exactly n * L(m -
1)/nJ pigeons, we could put 
L(m - 1)/nj in each hole. But since there are m pigeons, and n * L(m - 1)/nJ 
is strictly less than m, one hole must contain more than L(m - 1)/nJ pigeons. o 
Using the general Pigeonhole Principle, we c~n say, for example, that in a 
group of 50 people, at least L(50 - 1)/12J + 1 = 4 + 1 = 5 of them will 
be born in the same month. A more interesting illustration follows. 
13 Example. We want to prove that in a group of six people, there are either 
three mutual friends (i.e., each pair already know each other), or else three 
mutual strangers (i.e., no pair has previously met). 
Call the six people One, Two, ... , Six. If we consider One, the remaining 
five persons can be divided into two sets: 
F = {the friends of One}, and 
S = {the strangers to One}. 
Since we are placing five people into two groups, the Pigeonhole Principle 
tells us that one of the two groups has at least L(5 - 1)/2J + 1 = 3 members. 
Now if F has three members, then either they are three mutual strangers 
or at least two of them are friends. If F contains a pair offriends, then grouping 
them with One gives us a set of three mutual friends. 
On the other hand, if it is S that has three members, then either they are 
mutual friends (in which case we are done), or else at least two of them are 
mutual strangers. And if S contains a pair of mutual strangers then grouping 
them with One gives us a set of three mutual strangers. 
In all cases we have either three mutual friends or else three mutual 
strangers. 
The situation of the preceding example can be nicely described by a 
diagram. We represent the six people by dots, one dot for each person, and 
between any two of these dots there is either a solid line (if the corresponding 
two people are friends) or a dotted line (if the corresponding two people are 
strangers). A possible situation is thus described in Figure 15. 
What we have proved is that in any such diagram we find either a solid-line 
triangle or else a dashed line triangle. For instance, in Figure 15, {Three, 
Four, Six} is a solid line triangle, and {Two, Three, Five} is a dashed-line 
triangle. 

80 
3 Counting, Recurrences, and Trees 
One 
Four 
Figure 15 Solid lines link friends; dotted lines link strangers. This group does include 
a subgroup of three mutual friends and a subgroup of mutual strangers. 
This is again a case of a "best possible" result, in the sense that six is the 
smallest number guaranteeing that among them we shall always find a 
matching threesome of mutual friends or of mutual strangers. Indeed, with 
five people only, we can draw Figure 16, which contains neither a solid-line 
triangle nor a dashed-line triangle. 
The preceding discussion is a special case of a more general situation 
extensively studied in Combinatorial Theory, where an important and deep 
generalization of the Pigeonhole Principle (called Ramsey's Theorem) is 
studied. 
PERMUTATIONS AND COMBINATIONS 
Given a collection of n distinct objects, in how many different ways can we 
arrange them in a row? Each one of these arrangements is called a permuta-
tion of the n objects. For example, given objects a, b, and c, the following 6 
permutations are possible: 
abc, acb, bac, bca, cab, cba. 
14 Theorem. The number of permutations of n distinct objects is n! = 
n(n - 1)Â· ... Â·2Â· 1. 
One 
Figure 16 This group of five contains no subgroup of either three mutual friends or 
three mutual strangers. 

3.1 Some Counting Principles 
81 
PROOF. The number of ways in which we can select the first element is n. 
Having selected one element out of n, we are left with (n -
1) elements 
from which to choose our second element, so that, by the Rule of Product, 
there are n(n - 1) ways to select the first element, and the second element. 
By a similar reasoning, there are (n - 2) ways in which we can select the 
third element, and n(n - 1)(n - 2) ways to select the first, and the second, 
and the third elements. And so on, until we reach the nth element, which we 
can select in exactly one way. By the Rule of Product again, the number of 
ways in which we can select the first to the nth element is exactly nÂ· (n - 1) 
. (n - 2)Â· ... Â·2Â·1 = nL 
0 
15 Example. Consider a collection of 3 objects {a, b, cl. We ask, "In how 
many different ways can we arrange them -
not in a row - but in a circle?" 
This is not exactly the number of the permutations of three objects, because 
two distinct permutations may become identical when arranged in a circle. 
For instance, the three permutations abc, bca, and cab, when put in a circle, 
give the same circular pattern (save for the nonessential rotation). Similarly, 
the three other permutations of {a, b, cl, acb, bac, and cba, give the same 
circular pattern. In fact, there are exactly 2 distinct ways of arranging three 
objects around a circle. This is a special case of the following result. 
16 Theorem. The number of arrangements of n distinct objects around a 
circle is (n -
1) L 
PROOF. We prove that there is a one-to-one correspondence, that is, a 
bijection between the arrangement of {al' a2' ... , an} in a circle and the 
permutations (i.e., arrangements in a row) of {a2' a3' ... ' an} -
the original 
set of n elements from which we have deleted al. Since there are (n - 1)! 
permutations of the set {a2, .. " an}, this will prove the result. 
Given an arrangement of {al' ... , an} in a circle, let us agree to "cut" the 
circle at a 1. After cutting, we "straighten" the circle, putting the next clock-
wise element at the left end, as in the figure 
Now this mapping is clearly one-to-one: Distinct circular arrangements -
arrangements that cannot be made to coincide -
must lead to distinct linear 

82 
3 Counting, Recurrences, and Trees 
arrangements after cutting at at and "straightening." The map is also onto. 
Any linear arrangement of a2,"" an is the image under "cutting and 
straightening" of the circle formed by putting a t at the right end of the string, 
and then "bending" the string into a circle. 
Thus our "circle to line" mapping is one-to-one and onto, establishing 
the desired bijection. 
D 
Sometimes we do not want to count all the permutations of n objects, but 
only the permutations of r ~ n objects out of these n objects. For example, 
all the permutations of2 objects out of the 3 objects {a, b, c} are: 
ab, ac, ba, bc, ca, cb. 
17 Notation. The number of permutations of r objects chosen from a set of n 
objects is denoted by pen, r). This may be read as 'n permute r', and is 
sometimes written npr. 
We have already shown that P(n, n) = n! for any positive integer n. We 
now want to establish the value of P(n, r) for arbitrary positive integer n 
and non-negative integer r ~ n. 
18 Theorem. The number of ways of arranging in a row r objects out of a 
collection of n objects is given by 
n! 
P(n, r) = n . (n -
1) ... (n -
r + 1) = ---
(n -
r)! 
PROOF. This result can be proven by an argument similar to those of the two 
preceding theorems. We choose an alternative method here. 
Note first that, for all k, P(k, k) = k!. This is simply a restatement of the 
previous theorem. 
Imagine we have n marked positions which we divide into two groups, the 
first r positions and the remaining (n - r) positions, listed in order from 
left to right. By the Rule of Product, the number of ways of placing n objects 
in these n positions is equal to the number of ways of placing r of the n 
objects in the first r positions multiplied by the number of ways of placing the 
remaining (n -
r) objects in the remaining (n -
r) positions. This means 
that we have 
P(n, n) = P(n, r) . P(n -
r, n -
r) 
Hence, P(n, r) = P(n, n)/P(n - r, n -
r) = n!j(n -
r)!. 
D 
19 Example. How many different 2 or 3 letter sequences are possible from the 
alphabet a, ... , z? 
Given the 26 letters of the alphabet, we must compute P(26, 2) (for the 
two letter sequences) and P(26, 3) (for the three letter sequences). By the 
Rule of Sum, the desired result is P(26, 2) + P(26, 3). 

3.1 Some Counting Principles 
83 
Now, 
P(26,2) = 26 !/(26 - 2)! = 26 X 25 = 650 
and 
P(26, 3) = 
261/(26 - 3)! = 26 x 25 x 24 = 15,600 -
for a total of 15,600 + 650 
= 16,250 letter sequences. 
There is one more combinatorial notion we want to introduce, and this is 
the notion of combination. When we select r objects out of n, and we are not 
interested in arranging the selected objects in any particular way, we say 
that we have a combination ofr objects out ofn. For instance, all the combina-
tions of two items out of the set {a, b, c}, are: 
{a, b}, {a, c}, {b, c}. 
Since the order of the selected objects is not taken into account here, we also 
call a combination of r objects an r-subset (of a given set of n objects). 
20 Notation. The number of r-subsets, or combinations of r objects, chosen 
from a set ofn objects is denoted by (~). This may be read as 'n choose r', and 
is sometimes written ner â¢ 
21 Theorem. The number of r-subsets of a set of n objects, 
( n) 
Pen, r) 
n! 
r 
= -r-! -
= (n - r)!r!' 
PROOF. Let X be an r-subset of ab a2, ... , an, a collection of n objects. By 
Theorem 14, the number of ways of permuting the members of X is rL 
Hence, by the Rule of Product, the number of ways of selecting and arranging 
r objects out ofn is (~) * rL By the last theorem, this number is also equal to 
pen, r). We therefore have r! * G) = pen, r), proving the result. 
0 
22 The Binomial Theorem. The symbol (~) for counting combinations occurs 
in the expansion of a binomial (a + b) to a positive integral power n according 
to the formula 
(a + bt = (~)an + (~)an-lb + (;)an- 2b2 + ... 
+ (n ~ 2)a2bn- 2 + (n ~ 1)abn- 1 + (:)bn, 
where the coefficient of the term an-rbr is e). The e) are thus also called 
binomial coefficients. 
0 
To see why the binomial coefficients show up in the binomial theorem, 
consider the expression 
(a + b)n = (a + b) . (a + b) ... (a + b) , 
, 
n factors 

84 
3 Counting, Recurrences, and Trees 
and imagine how this expression might be multiplied out. Terms of the form 
an-rbr are formed by choosing the b summand from exactly r of the n factors 
in the expression. The a summand is chosen from the (n - r) other factors. 
Now choosing b from exactly r of the n factors can happen in exactly (~) 
ways, and so (~) counts the number of ways the term an-rbr can be formed. 
We conclude this section with an example that is particularly relevant to 
Computer Science. 
23 Example. A convenient and efficient representation for the subsets of a 
set of elements indexed with integers from 1 to n, say the set 
A = {ai, a2' ... , an} 
is by means of a string of n bits, i.e., a string of nO's and 1 'so In this string of 
bits, if the ith bit, 1 ~ i ~ n, is 0 then we agree that ai is not a member of the 
subset, and if it is 1 then ai is a member. For instance, if n = 16 and A = 
{ab a2"'" a16} then the string 
1 101 
00000 0 0 0 0 0 
represents the subset {ai, a2' a4' as, aI6}' In fact we have here a bijective 
correspondence between the collection of all bit-patterns of length n and the 
collection of all subsets of A = {ai, a2' ... ,an}. We immediately conclude 
that there are exactly 2n bit-patterns of length n (since there are 21AI subsets 
of A), and there are exactly e) bit-patterns with r one's and (n -
r) zero's 
(this is the number of r-subsets of A). (The reader should recall the discussion 
of characteristic functions following Fact 1.3.7.) 
EXERCISES FOR SECTION 3.1 
1. In how many ways can a deck of 52 cards be shuffled? 
2. A committee has 8 members. In how many ways can two (disjoint) subcommittees, 
each of size three, be chosen? 
3. Suppose 5 points are chosen from inside a square with edge length 2. Show that 
some pair of points must be within )2 of each other. 
4. In how many ways can 6 different colored beads be strung on a necklace? 
5. For n > m > k which is larger, 
6. Show that n . (n; 1) = (r + 1) . er ~ 1)' Can you prove your result without using the 
explicit formula for G)? 
7. A bit-string ofO's and I's is said to have even parity if 1 occurs in the string an even 
number of times; otherwise it is of odd parity. Given all bit strings of length n, for 

3.1 Some Counting Principles 
85 
some positive integer n, how many of them are of even parity? And how many are 
of odd parity? 
8. A coin is flipped n times, for some positive integer n. (a) Count the number of ways of 
getting exactly one head. (b) Count the number of ways of getting exactly r heads, 
for 0 S r S n. 
9. Use the binomial theorem to prove the identity 
(~) + G) + ... + C) = 2n. 
10. Prove that the total number of even subsets (i.e., subsets with an even number of 
elements) of a set of n elements is equal to the total number of its odd subsets by 
first using the Binomial Theorem to prove the identity 
(~) - (;) + G) -... Â± C) = 0 
where the minus and plus signs alternate and the last sign may be either + or -
depending on whether n is even or odd. 
11. Prove that the number of ways of selecting r objects from a set of n distinct objects, 
where order does not count and repetitions are allowed is ("+~-l). (Hint. A typical 
selection of r out of n elements al, a2, ... , an with repetitions allowed can be repre-
sented by a string of symbols of the form 
alalal lla31 a4 111 a7 a7a7a711a9a9 
where there is a I between the a;'s selected and the ai+ I'S selected. Two consecutive 
I's means that some ai has not been selected. Three I's in a row means that two 
a;'s have been omitted as with as and a6. The total number of such selections of r 
objects is the number of strings of the above form, where there are exactly ra's 
and (n -
1) "vertical bars.") 
12. (a) In how many ways can three numbers be selected from the set {I, 2, ... , 50} 
such that their sum is even? 
(b) Repeat (a) when the sum is required to be odd. 
(Hint. The sum of three integers is odd if and only if either one or three of them are 
odd.) 
13. (a) In how many ways can three numbers be selected from the set {I, 2, ... , 99} 
such that their sum is a multiple of 3? 
(b) Generalize (a) to selections of three numbers from the set {I, 2, ... , 3n}. 
14. Argue that the rule of sum (generalized) can be restated in the following form: If 
a finite set X of objects is divided into mutually disjoint subsets Xl' X 2, ... , X k, 
then the number of objects in X can be determined by finding the number of objects 
in each of the sets Xl' X 2, ... , X k, and adding. Using this form of the rule of sum, 
deduce the pigeonhole principle. 
15. A square array of dimension n x n, with all the entries consisting of the integers 
1,2,3, ... , n2 , is called a magic square if the sum S of the integers in each row, in 
each column, and in each of the two diagonals is the same. The number S is called 

86 
3 Counting, Recurrences, and Trees 
the magic sum of the magic square. For example, the following square arrays are 
magic squares of order 3 and 4, respectively: 
6 
8 
13 
2 
3 16 
7 
5 
3 
12 
7 
6 
9 
2 
9 
4 
8 
11 
10 
5 
14 
15 
4 
The magic sum of the first is 15, that ofthe second is 34. Magic squares were studied 
in antiquity in China and were introduced in medieval times in Europe, where they 
were supposed to protect against evils. 
(a) Show that there cannot exist a magic square of order 2 (i.e., dimension 2 x 2). 
(b) Prove that all magic squares of the same order n must have the same magic 
sum S. (E.g., all magic squares of order 3 have the sum 15.) Find an expression 
for S as a function of n. 
16. A square array of dimension n x n is called a latin square of order n if each row 
and column is a permutation of the numbers 1,2, ... , n. An example of a latin square 
of order 4 is 
2 
3 
4 
4 
2 
3 
3 
4 
2 
2 
3 
4 
1. 
Whereas "magic squares" in the previous exercise seem to be a mathematical 
curiosity with little practical value, latin sqhares have played an important role 
in the development of combinatorial theory, and have proved to be useful in certain 
areas of applied mathematics such as statistics. 
(a) Find an upper bound on the number of latin squares of order n. Justify your 
answer. (It is considerably more difficult to find the exact number of latin 
squares of order n -
if you can find this exact number, you probably need 
not take this course ... ) 
Two latin square A and B of the same order are said to be orthogonal if by juxta-
posing A and B we get n2 distinct pairs of entries. For example, if A and Bare 
3 
2 
2 
3 
2 
3 
2 
3 
3 
2 
3 
2 
then their justaposition results in the following array 
(3,2) (2,3) (1, 1) 
(2,1) (1,2) (3,3) 
(1, 3) 
(3, 1) (2,2). 
Since all entry pairs in the resulting array are distinct, A and Bare orthogonal. 

3.2 Trees and Recurrences 
87 
(b) Show that if A and Bare orthogonallatin squares, then in each of A and B 
there are n positions which lie in n different rows and n different columns such 
that the entries in these positions are the integers 1, 2, 3, ... , n in some order. 
3.2 Trees and Recurrences 
BASIC DEFINITIONS AND PROPERTIES OF TREES 
We have already encountered "trees" in Chapter 2, and in our discussion of 
counting principles in the previous section. A typical tree is displayed in 
Figure 17. The node A is called the root; nodes F, G, H, J, K, L, and M are 
called leaves. With complete disregard for the botanical facts, computer 
scientists represent trees pictorially with the root above the leaves. 
We can see that every node is either a leaf, or has edges below it which 
lead to other nodes. Each node in a tree can be regarded as the root for the 
subtree consisting of the tree structure below it. This observation is the 
basis for our next definition. 
1 Definition. A (rooted) tree T is a non empty set of labeled nodes with one 
distinguished node, called the root of the tree; the remaining nodes are 
partitioned into m ~ 0 disjoint subtrees T1, T2, ... , Tm. Nodes having no 
subtrees are called leaves; the remaining nodes are called internal nodes. 
Set theoretically, we can say that the tree of Fig. 17 is: 
T = {A, B, C, D, E, F, G, H, J, J, K, L, M} 
Root of T: A 
Subtrees of T: Tl = {B, E, K, L}, T2 = {C, F, G}, T3 = {D, H, J, J, M} 
Root of T1 : B 
Subtrees of T1 : T4 = {E, K, L} 
Root of T2 : C 
Subtrees of T2: Ts = {F}, T6 = {G} 
Root of T3: D 
Subtrees of T3: T7 = {H}, T8 = {J, M}, T9 = {J} 
Root of T4 : E 
Subtrees of T4 : T10 = {K}, Tll = {L} 
Root of T8: J 
Subtrees of T8: T12 = {M} 
Subtrees Ts, T6, T7, T9, T10 ' Tll , T12 are all leaves. 
It should be clear that the graphic representation of the tree is not only 
easier to grasp, but also more compact than the set-theoretic representation. 

88 
3 Counting, Recurrences, and Trees 
A 
~ 
BeD 
I 
A 
ffi 
E 
F 
G H I 
J 
A 
I 
K 
L 
M 
Figure 17 A tree. 
We shall now very briefly examine some of the issues related to trees. 
Because the notation of a tree captures the idea of a hierarchy or a structured 
organization, it is one of the most useful notions in computer science. 
Let us introduce some additional terminology that is helpful when we 
talk about trees. The terms used here are of mixed genealogical-botanical 
origins. Thus the root A in the tree of Figure 17 has three branches, each 
connecting it to a different subtree. Furthermore, all the nodes in a tree of a 
subtree are said to be descendants of its root; conversely, the root is an 
ancestor of all its descendants. We also refer to the root in a tree (or a subtree) 
as the parent of the roots of its subtrees; these nodes are in turn the children or 
immediate successors of the root. 
A path is a succession of consecutive branches connecting the root to a 
leaf. In Figure 17, for example, A D I M is a path. In a tree there are clearly 
as many distinct finite paths as there are leaves. Note that we did not restrict 
a tree to be finite. A tree may have infinitely many nodes either because it has 
an infinite path or because some node has infinitely many branches. This fact, 
which is known as K6nig's lemma, requires proof -
see Exercise 14. When 
all the paths in a tree are finite, we can talk meaningfully about the height of 
the tree, which is the number of branches in a longest path. 
1 
2~n. 
(a) 
1 
/"'-.. 
2 
3 
/"'-.. 
4 
~ 
n A 
n+l 
n+2 
A 
n + 3 
(b) 
Figure 18 Two examples of infinite trees. (a) Node 1 has infinitely many branches. 
(b) Node I is the root of an infinitely descending path. 

3.2 Trees and Recurrences 
89 
2 Example. Consider the tree in Figure 19 whose root is labeled with the 
finite set {a, b, c}, and its remaining nodes with subsets of {a, b, c}, such 
that the immediate successors of a node X are labeled with the subsets of the 
set associated with X obtained by deleting one element. 
{a, b, c} 
~ 
{a,b} 
{a,c} 
{b,c} 
A 
A 
A 
{a} 
{b} 
{a} 
{c} 
{b} 
{c} 
I I I I I I 
o 
0 
0 
0 
0 
0 
Figure 19 A tree of subsets. 
This tree has six paths from the root to its leaves, all are of length 3, and 
therefore the tree height is also 3. 
In all trees considered so far, the order in which the siblings of a node are 
drawn (from left to right) was not relevant. Thus 
A 
A 
A 
and A 
Bee 
B 
were identical trees. Often we need to talk about ordered trees, where the 
relative order of subtrees is important. 
3 Example. Consider the algebraic expression Â«a - 6) * b)/(c - 3) rep-
resented by the tree of Figure 20a. 
This is an ordered tree of height 3 (the length of the longest path). We 
choose to have it "ordered" because once the symbols are given their usual 
(a) 
(b) 
Figure 20 Two trees representing arithmetic expressions. (a) Â«a - 6) * b)j(c - 3). 
(b) (c -
3)j(b * (6 -
a)). Note that order of nodes plays a crucial role on this inter-
pretation. 

90 
3 Counting, Recurrences, and Trees 
meanings, permuting subtrees changes the meaning of the tree representation. 
Thus, the tree in Figure 20b has the "meaning": (c - 3)/(b * (6 - aÂ» which 
is obviously different from the original expression in its meaning. 
Just as we earlier defined trees in general in terms of sets, we can also 
define ordered trees in terms of ordered sets. For the present we shall not 
burden our presentation with such formal definition. Instead, we use the 
(more intuitive) drawn diagrams both for trees and ordered trees. 
An important variant of the ordered trees is the class of "binary trees." 
Their chief characteristic is that any node can be parent of at most two 
children. 
4 Definition. A binary tree T is a finite set of nodes which is either empty or 
consists of a root and two binary subtrees TL and TR in that order, called the 
left and right subtrees of T. 
It is important to note that binary trees are not a subclass of ordered trees. 
Indeed, a tree or an ordered tree cannot be empty, while a binary tree can. 
Furthermore, the way we draw the subtrees of a root in binary trees is 
important; for instance, 
A 
A 
/ 
and 
\ 
B 
B 
are different as binary trees because the left tree has an empty right subtree, 
while the right tree has an empty left subtree. As trees and ordered trees, on 
the other hand, both are identical to 
A 
I 
B 
While a node in an ordered tree may be thought of as a root with 0 or more 
subtrees (ordered from left to right), nodes in binary trees always have 
exactly two subtrees (one or both of which being possibly empty). 
A forest of trees (or ordered trees, or binary trees) is a collection of the 
given type. If we list the members of a forest in some prescribed order, then 
we have an ordered forest. 
5 Example. The tree in Figure 20a was given as an ordered tree. We can 
also look at it as a binary tree. If we remove its root node, /, we get a forest 
made up of the two subtrees of the original binary tree -
namely, 

3.2 Trees and Recurrences 
91 
A 
-
b 
A 
and c 
3 
A 
a 
6 
In fact, if we give the node labels their usual meanings, we should view the 
forest as an ordered forest, because if we connect them back by taking them 
again as subtrees of a binary tree it will make a difference which of the trees 
is on the left. 
We now state and prove an important counting property of binary trees. 
This property was implicit in several parts of the preceding section, where we 
talked about counting principles, permutations, and combinations. To 
establish this result, we need the notion of "level" in a tree, which we define 
recursively. First, the level of the root node is 0. Second, if a node is at level n, 
then its children are at level (n + 1). This means that the height of a tree, 
which we defined earlier, is also the maximum level of any node in the tree. 
6 Proposition. The number of nodes at level i in a binary tree is ~ 2i. 
PROOF. By induction on i, if i = 0, the binary tree has exactly one node at 
this level: the root node; and the total number of nodes is indeed 2Â° = 1. 
Assume that the result is true for an arbitrary integer i. We want to prove 
it for (i + 1). Consider a binary tree T which has k nodes at its ith level. By 
the induction hypothesis, k ~ 2i. Each of these k nodes can have at most 
two children, so that the number of nodes at level i + 1 is at most 2 . k ~ 
2Â·2i = 2i+ 1, as desired. 
0 
7 Corollary. The number of nodes in a binary tree of height n is ~(2n+ 1 -
1). 
PROOF. By the preceding result the maximum number of nodes at level i 
is 2i. If every level has as many nodes as possible, and the tree height is n, 
then the total number of nodes is bounded by 
L 2i = 2Â° + 21 + ... + 2n. 
Osisn 
By induction on n, we shall prove that this sum is equal to (2n+ 1 -
1). 
Basis Step. For n = Â° 
we clearly have that 2Â° = 2Â° + 1 - 1 = 1. 
Induction Step. For n ~ 1, suppose that 2Â° + 21 + '" + 2n- 1 = 2n -
1, 
and suppose we double both sides: 2(2Â° + 21 + ... + 2n- 1) = 2(2n - 1). 
Then 21 + 22 + ... + 2n = (2n + 1 _ 2), and so 20 + 21 + 22 + ... + 2n 
= 2n+ 1 -
1. 
0 

92 
3 Counting, Recurrences, and Trees 
level 0 
level 1 
level 2 
level 3 
Figure 21 
A full binary tree of height 3. 
8 Definition. A full binary tree of height n is a binary tree such that each of 
its nodes has two children, except that those at level n are all leaves. 
A full binary tree of height 3 is shown in Figure 21. 
In a full binary tree of height n, every level i, 0 ~ i ~ n, contains exactly t 
nodes, and the total number of nodes is (2n+ 1 -
1). Thus the bounds obtained 
in Corollary 7 above are in fact attained by full binary trees. 
9 Definition. We say a binary tree of height n is complete if at every level i, 
o ~ i ~ (n -
1), it has exactly 2i nodes, and if all nodes at level (n - 1) 
with two children are to the left of those nodes with no children, and there 
are no nodes with only one child, as in Figure 22. 
10 Corollary. The height of a binary tree with n nodes,for n ~ 1, is at least 
LIOg2 nJ, 
PROOF. To minimize the height of a tree built from n nodes, fill all levels up to 
say level h, and then distribute the remaining nodes at level h. Then levels 0 up 
to (h - 1) contain exactly (2h - 1) nodes, while level h contains at least one 
node and no more than 2h nodes. Hence, the minimum number of nodes in a 
complete binary tree of height h is 
(2h -
1) + 1 = 2\ 
and the maximum number of nodes in such a tree is 
(2h _ 1) + 2h = 2h+ 1 -
1. 
Hence 2h ~ n ~ 2h+ 1 -
1. If n = 2h we have h = log2 n, and if n = 2h+ 1 -
1 
we have h + 1 = log2(n + 1). It is left as an exercise to show that in the 
latter case h = LIog2 nJ. Thus, in both cases we have h = Llog2 nJ. 
0 
Counting the nodes present in various kinds of trees, and especially in 
binary trees, is a fundamental aspect of a topic in Computer Science called 
"Algorithm Analysis." We shall give an important example of algorithm 
analysis in Section 3.3. 

3.2 Trees and Recurrences 
level 0 
level! 
level 2 
level 3 
level 4 
Figure 22 
A complete binary tree of height 4. 
TRAVERSALS OF BINARY TREES 
93 
In many applications, we need to "traverse" all the nodes in a tree or a 
forest; that is, we wish to visit all the nodes in a tree or forest in some syste-
matic manner. We briefly discuss here some of these traversal procedures for 
binary trees. We consider the so-called "preorder," "inorder," and "post-
order" procedures, which we define recursively. 
11 Definition. Given a binary tree T, and its two subtrees TL and TR , we can 
traverse the nodes of Tin: 
Preorder: 
1. Visit the root of T; 
2. Traverse the left subtree TL in preorder; 
3. Traverse the right subtree TR in preorder. 
Inorder: 
1. Traverse the left subtree TL in inorder; 
2. Visit the root of T; 
3. Traverse the right subtree TR in inorder. 
Postorder: 
1. Traverse the left subtree TL in postorder; 
2. Traverse the right subtree TR in postorder; 
3. Visit the root of T. 
The origins of the terms "preorder," "inorder," and "postorder," will 
become clear as some examples are worked out. 
12 Example. Consider the binary tree of Figure 20a, representing the 
expression Â«a - 6) * b)/(c - 3). Figure 23 gives integer labels that indicate 
the order in which nodes are visited according to each of the traversal 
procedures. 
If we list the original nodes' labels in Figure 20a according to each of the 
traversals, we get: 
Preorder: 
/ * - a 6 b - c 3 
Inorder: 
a - 6 * b / c - 3 
Post order : a 6 - b * c 3 - / 

94 
1 
~ 
2 
7 
~~ 
368 
9 
~ 
4 
5 
(a) 
(c) 
3 Counting, Recurrences, and Trees 
6 
~8 
4 
~ 
~57 
9 
~ 
1 
3 
Cb) 
Figure 23 
Illustrating three ordering of nodes of a tree: (a) Preorder. (b) Inorder. 
(c) Postorder. 
Note that the original algebraic expression Â«a - 6) * b)/(c - 3) is identical 
to the inorder listing modulo the insertion of parentheses. Here the paren-
theses are necessary in order to distinguish between two different expressions 
with the same sequence of symbols (save for the parentheses). For instance, 
the expression (a - (6 * bÂ»/(c - 3) has a binary tree representation of 
Figure 24. While this tree clearly represents an algebraic expression different 
from the preceding binary tree, its inorder listing is, nevertheless, the same: 
Inorder: 
a - 6 * b / c - 3. 
We therefore conclude that it is not always possible to reconstruct a binary 
tree uniquely from an inorder presentation of its nodes. In this sense, inorder 
listings are ambiguous. 
The beauty of preorder and postorder expressions is that they can be 
used to reconstruct uniquely corresponding binary trees. We leave it to the 
reader to check that the preorder and postorder listings above uniquely 
describe the binary tree from which we have derived them. We thus say that 
preorder and postorder expressions are unambiguous. As a result, we do not 
Figure 24 Binary tree representing (a -
(6 * bÂ»j(c -
3). 

3.2 Trees and Recurrences 
95 
need to insert parentheses in preorder and postorder expressions to remove 
their ambiguity. 
We shall look at preorder from another perspective in Section 5.3. 
RECURRENCE RELATIONS 
We have now seen that counting methods, and in particular counting methods 
on trees, are intimately related to inductive proofs and recursive definitions. 
There is still another important notion which is closely related to counting 
principles considered so far: this is the notion of recurrence or recurrence 
relations. 
In a way we have already encountered this notion. A recursive definition 
always establishes a recurrence relation, and conversely, every recurrence 
relation can be construed as a recursive definition. However, the use of a 
recurrence relation (or difference equation) in mathematics usually calls for 
an explicit closed-form solution, while the use of a recursive definition in 
computer science does not. 
13 Example. Consider, the following system of equations involving the 
function f: N ~ N 
(1) 
f(O) = 1; 
(2) f(n) = n * f(n - 1), for n ~ 1. 
This is clearly the" recursive definition" of the factorial function. But if we 
want to find a closed-form expression for a function satisfying the above 
equations, we can just as well view (2) as a "recurrence relation" with (1) as 
its "initial condition." Admittedly the distinction between "recurrence 
relation" and "recursive definition" in this case seems contrived -
and 
it is. 
14 The Fibonacci Sequence. A situation that perhaps deserves more the 
name" recurrence relation" is the following one. Let {ao, aI' a2' ... } be an 
infinite sequence of integers satisfying the following conditions: 
(1) 
ao = 1, 
(2) 
al = 1, 
(3) 
an = an- 1 + an-2' for n ~ 2. 
The third equation relates an arbitrary number an in the sequence, for n ~ 2, 
to the two numbers immediately preceding it, an _ 1 and an _ 2' And the values 
specified by (1) and (2) are "initial conditions" which are required before we 

96 
3 Counting, Recurrences, and Trees 
can start assigning values to a2' a3' a4' ... , in succession using relation (3). 
It is clear how we can generate the numbers in the above sequence: 
2 
3 
5 
8 
13 
21 
34 
55 
This sequence of numbers is called the Fibonacci sequence. It was first 
studied by Leonardo of Pisa, alias Fibonacci, around the year 1200 in 
his work Liber Abaci. In it, he poses the so-called "rabbit problem" according 
to which rabbits reproduce in the following manner: every pair of rabbits 
(at least one month old) will produce one pair of rabbits as offspring every 
month. To simplify the analysis, it is assumed that rabbits never die and 
never stop reproducing. How many rabbits are there after n months? 
In the Fibonacci sequence {ao, ab a2, a3'" .}, an is the number ofrabbit 
pairs in the population after n months. If we denote by bn the number of pairs 
born during the nth month, and by Cn the number of at least one month old 
pairs at the end of the nth month, we have an = bn + Cn. According to the 
breeding law mentioned above: 
Cn + 1 = bn + Cn = an, 
i.e., the old population at time n + 1 is the entire 
population at time n; and 
bn + 1 = Cn 
i.e., every old pair at month n produces a newborn 
pair during month n + 1. 
In month n + 2 the same events are repeated: 
Cn+2 = bn+1 + Cn+l = an+l, 
bn+2 = Cn+l' 
Combining these equations we obtain: 
that is, 
which is identical to recursive relation (3) stated earlier. 
It should be added that while the Fibonacci sequence is of little use to 
breeders, it is of great importance in mathematics and computer science (in 
particular, algorithm analysis). 
We can reformulate the Fibonacci problem in terms of a function 

3.2 Trees and Recurrences 
97 
f: N -+ N. Recurrence relation (3) and its initial conditions (1) and (2) then 
take the form 
(1') f(O) = 1, 
(2') f(1) = 1, 
(3') f(n) = f(n -
1) + f(n - 2), for n ~ 2. 
We can call this function f the Fibonacci function. The correspondence 
between the Fibonacci sequence and the Fibonacci function is obvious: 
for all nE N, an is the same as f(n). 
Now, finding a closed-form expression for the Fibonacci function demands 
more effort than was required in the factorial example. There are well-
studied techniques to find solutions of recurrence relations, which we shall 
not cover here. Let us at least mention the solution that can be found using 
some of these techniques for the Fibonacci function: 
__ 1 (1 + J5)n+l __ 1 (1 - J5)n+l 
f(n) - J5 
2 
J5 
2 
. 
This is not an expression that can be guessed by looking long enough at the 
above recurrence relation. Of course, once the formula is found, it can be 
verified by induction (Exercise 6). 
Our next example of a recurrence is one of the most important in mathe-
matics. 
15 Example. Earlier in this chapter, in 3.1.22, we introduced the binomial 
coefficients, which we denoted (~). Binomial coefficients can be given one of 
two meanings (at least), which we shall call "combinatorial" and "factorial": 
(1) 
combinatorial -
we define (~) to be the number of ways in which we 
can select r ~ n objects from a set of n objects; 
(2) 
factorial -
we define (~) to be n !/(n -
r)! r!. 
Either one of the two meanings, (1) and (2), can be chosen as the basic 
definition of (~), and we can then derive the other meaning. 
Here we want to show that (~) satisfies a certain recurrence relation; 
namely: 
1, 
if r = 0; 
ifr = n; 
if 0 < r < n. 
We argue, using the combinatorial meaning of (~), that binomial coefficients 
indeed satisfy the above relation. 

98 
3 Counting, Recurrences, and Trees 
Concerning the "initial conditions" m and C:), it is evident that there is 
exactly one way of selecting 0 things and n things, respectively from a set of 
n things. Hence (~) = C:) = 1. 
Consider now the case when 0 < r < n. If we select a subset of r objects 
from the set, say {aI' a2"'" an}, then we can do it in one of two ways: 
case A -
one of the r objects is al; 
case B -
none of the r objects is al' 
In case A we then choose the rest of the subset (r - 1 objects) from the 
remaining n - 1 objects {a2' a3,"" an}. Thus A can happen in (~=D ways. 
In case B we have to select all r objects from the remaining n - 1 objects 
{a2' a3' ... , an}. Hence B can happen in (n; 1) ways. By the Rule of Sum, we 
can select r things out of the n objects {ab a2' a3"'" an} in 
ways. We have thus proved the desired recurrence relation. 
We could have also started from the factorial meaning, i.e., from the fact 
that 
(~) = n!/(n - r)!r!, and again showed that binomial coefficients 
satisfy the above recurrence relation. In either case we start from an already 
given definition -
here either the combinatorial or factorial definition of 
(~) -
and then prove that it satisfied a certain recurrence relation (which is 
not readily inferred from this definition). 
One final point. Given the sequence of values generated by a recurrence 
relation, there is a natural way of calculating these values using trees. 
Suppose for instance that we want to compute the 6th number in the 
Fibonacci sequence, f(5). Starting with f(5), two values f(4) and f(3) are 
required before we can compute it; and to compute f(4) and f(3), we first 
need to know the values of f(3) and f(2), and of f(2) and f(1), respectively. 
f(5) 
f(1) = 1 
f(3)<:: 
f(O) = 1 
f(2)~f(1) = 1 
_____ f(O) = 1 
______ f(2)----f(1) = 1 
fW~ 
ftij=1 
f(3)~f(2)~-==========f(0) = 1 
f(1) = 1 
Figure 25 A parsing tree for the Fibonacci number, f(5), corresponding to f(n) = 
f(n -
1) + f(n -
2) ;f(O) = f(l) = 1 

3.2 Trees and Recurrences 
99 
C(2,0) = 1 
C(3, 1) < 
C(1,0) = 1 
C(2,1) ~ 
C(1, 1) = 1 
C(4,2) 
C(1,0) = 1 
<
c(2'1)~ 
C(3, 2) 
C(1, 1) = 1 
C(2,2) = 1 
Figure 26 A parsing tree for the binomial coefficient C( 4,2) corresponding to C(n, r) = 
C(n -
1, r -
1) + C(n -
1, r); C(n, 0) = C(n, n) = 1. 
We can proceed in this fashion "backward" until we reach f(O) and f(1), 
whose values are given directly by the initial conditions. This inductive 
process is best described by the tree of Figure 25. To find the value of f(5) 
we have to climb up to the root f(5) from the leaves, using the fact that the 
value of a parent node is the sum of the values of its two children. 
A similar evaluation of the binomial coefficient (t) is given by the tree 
of Figure 26. 
EXERCISES FOR SECTION 3.2: 
1. Given the ordered tree T below: 
A 
~ 
B 
C 
I1\G~ 
I I I I 
I 
a bed 
e 
(i) 
What is the root of the tree? 
(ii) What nodes are the ancestors of d? 
(iii) How many leaves are there? 
(iv) How many internal nodes are there? 
2. What expression tree corresponds to the postfix expression 
3. List all the expression trees according to the infix expression 
2 + 3 *4 + 5. 
4. Show that if h + 1 = fiOg2 (n + 1)1, where hand n are positive integers, then 
h = Llog2 nJ (cf. Corollary 10). 

100 
3 Counting, Recurrences, and Trees 
5. Let ao, ai' a2, ... be the Fibonacci sequence. Prove the following identities in two 
different ways: first, inductively (easy) and, second, by appropriate grouping of 
terms (more difficult). 
(a) ao + al + a2 + ... + an-I = an+ I -
1 
(b) ao + a2 + a4 + ... + a2n = a2n+ 1 
(c) a5 + ai + a~ + ... + a; = anan+1 
6. Verify the formula fen) = (1/)5)[((1 + )5)/2)n+ I - Â«1 - j5)/2)n+ I] 
for the Fibonacci function, using induction on n. 
7. We define inductively a function f: {binary trees} --+ N. Recall that we denote by 
TL and TR the left and right subtrees of a binary tree T. 
Such a function f is called a Strahler numbering of binary trees. 
(a) What is the Strahler number of a full binary tree of height n? And the Strahler 
number of a complete binary tree of height n? Give a general relationship 
between the height of a binary tree and its Strahler number. 
(b) Devise an inductive procedure based on the postorder traversal to compute 
the Strahler number of a binary tree. 
8. Prove that if a tree has n nodes, then it has exactly (n -
1) edges. 
9. Prove that the number of internal nodes in a binary tree of height h > 0 is less than 
2h -1. 
10. Let T be a binary tree where every node has either no children or exactly two 
children, i.e., we preclude the possibility that a node may have one child. Let T 
have n leaves, for some integer n ;::: 1, and t \> t 2, â¢.. , tn be the respective levels of 
these n leaves. Let C(i) = the number of leaves at level i. 
(a) Show that LI Si9 CO)Â· (1/2i) = 1. (Hint: It is helpful to first think in terms of 
full binary trees, then in terms of complete binary trees, and finally in terms of 
binary trees in general -
all satisfying the condition that a node cannot have 
exactly one child node.) 
(b) Prove that max(t I, t 2, ... , tn) ;::: log n. 
11. In the present exercise all trees are ordered binary trees where all internal nodes 
have exactly two children. If such an ordered binary tree has exactly n leaves, 
we say that its order is n. We shall label the leaves of a tree of order n with the letters 
XI' X 2 , .â¢â¢ , X., from left to right; further, if two nodes with labels UI and U2 are 
the left and right children of the same node, we label the latter with (U 1U2) -
parentheses included. For example, a tree of order 6 with the labelingjust described 
looks as shown in Figure 27. 
(a) Argue that there is a bijective correspondence between the collection of all 
such trees of order n and the different ways we can parenthesize the product 
X I X2 ... X n â¢ (To parenthesize a product means to insert enough parentheses so 
that every subproduct has exactly two factors -
with the convention that if 
n = 1 we have one factor X 1 and do not need to parenthesize, and if n = 2 we have 
two factors X I X 2 and only one possible parenthesization (X 1X 2).) 

3.2 Trees and Recurrences 
101 
Figure 27 A tree with nodes labeled by parenthesized products. 
(b) Prove that the total number of left-going (or, right-going) edges in such a tree 
of order n is (n - 1). Conclude that the number of parentheses required to 
parenthesize n factors is (n -
1) left parentheses and (n -
1) right parentheses. 
(c) If f: {I, 2, ... } -> {I, 2, ... } is the function that counts the number of different 
ways a product of n 2 1 factors can be parenthesized, show that f satisfies the 
following recurrence relation and initial condition: 
(1) f(l) = 1; 
(2) 
fen) = f(l)f(n -
1) + f(2)f(n - 2) + ... + fen - l)f(l) 
= LI $i$n-I f(i)f(n -
i), for n 2 2. 
(The solution of this recurrence relation, by techniques not examined in this 
book, is fen) = (l!n)en"--12 ).) 
12. Give preorder and postorder representations of the tree given in Figure 24. 
13. Show that for fixed nand 0 ::5: k ::5: 2n, the expression en is largest when k = n. 
14. Prove Konig's lemma: "If a finitely branching tree has infinitely many nodes, 
then it has an infinite branch." (Hint: use the following extension of the pigeonhole 
principle: "If infinitely many pigeons are placed in finitely many holes, then some 
hole holds infinitely many pigeons." To use this principle in the proof of Konig's 
lemma, consider the finitely many immediate descendants of the root node. Col-
lectively, they cover the infinitely many nodes (pigeons) present in the tree with the 
root omitted. So one of these descendants must cover infinitely many nodes. Put 
that node (along with the root) in the to-be-constructed infinite branch. The 
chosen node is itself the root of a finitely branching subtree with infinitely many 
nodes, so the same argument may be repeated.) 
15. What function f solves the recurrence 
f(O) = 1 
fen) = 2 * fen - I)? 
16. Let the function hen), for every integer n 2 0, be 
hen) = 13 + 23 + ... + (n -
1)3 + n3 â¢ 

102 
3 Counting, Recurrences, and Trees 
Verify a recurrence relation with an appropriate initial condition for which hen) 
is the solution. 
(Answer: 
h(O) = 0 
hen) = hen -
1) + n3.) 
17. Consider a 1 x n chessboard. Suppose we color each square of the chessboard 
black or white. For nE {1, 2, 3, ... }, define the function hen) to be the number of 
colorings in which no two adjacent squares are colored black -
although two 
adjacent squares may be colored white. Find a recurrence relation satisfied by 
hen), then find a closed-form formula for hen). 
18. Find a closed-form expression for the function hen), which satisfies the following 
recurrence relation: 
(1) 
hen) = 4 * hen - 2), for n = 2,3,4, '" 
(2) 
h(O) = 0 
(3) 
h(l) = 1 
3.3 An Example of Algorithm Analysis 
The "analysis of algorithms" is an important subject for both practical and 
theoretical computer science. In this section we illustrate the nature of this 
topic by means of a single example: the problem of searching an array (or a 
file) for an item x. Our illustration of analysis techniques will be based on the 
theory laid down earlier in the chapter. 
Admittedly we have not yet explained what the" analysis of algorithms" 
actually involves -
and we shall not try to discuss this concept in general 
terms. Instead we shall show how to analyze algorithms for array searching, 
and use this to give the reader a taste for the" style" of the subject. The 
general question is this -
given different algorithms to handle a given task, 
how can we compare their "efficiency" or "complexity"? 
SEQUENTIAL VERSUS BINARY SEARCH 
Consider the problem of searching for a particular record in some list. For 
our purposes we can simplify the problem in the following way. Every record 
in question is associated with a search key, a natural number which identifies 
it uniquely, and all such search keys are stored sequentially in a one-
dimensional array A. If we have n ~ 0 records, then we have n search keys 

3.3 An Example of Algorithm Analysis 
103 
stored in array cells A[l], A[2], ... , A[n]. The problem of accessing a 
particular record with search key x is therefore the problem of finding an 
index value i, 1 S; i S; n, such that A[i] = x. 
The simplest procedure to solve this problem is to sequentially search 
the entries of the array A, in the order in which they are stored from 1 to n, 
until one is found to equal x. This algorithm is described by the flow-chart of 
Figure 28. 
Let us agree to measure the cost of a search by counting the number of 
entries that have to be examined in the array A. Clearly, the smallest possible 
number oflook-ups is 1, which occurs when A[l] happens to store the value 
x; and the largest such number is n, which occurs when x is either found in 
A[n] or not found at all. The latter case gives us the worst-case complexity 
of the sequential search procedure. This tells us first that no matter what the 
values in the input data are, we are guaranteed never to need more than n 
look-ups, and second that this upper bound is in fact attained for certain 
possible input values. 
In actual practice, the cost of sequentially searching for x in the array A 
wi11likely be a number of look-ups that falls somewhere between the two 
extremes of 1 and n. If we assume that x is equally likely to be stored in any 
of the n locations A[1], A[2], ... , A[n], and that in addition, x is always 
INPUT 
number x 
array A[l], ... , A[n] 
>-___ 
t_ru_e ___ 
--J~ record 
not found 
true 
record 
~--~~--~~ round 
Figure 28 
Flow diagram for sequential search of an array. 

104 
3 Counting, Recurrences, and Trees 
found somewhere in the array A, then on the average x will be (l/n)th of the 
time in each of the n locations. With these assumptions the average number 
of look-ups will be 
- (1 + 2 + ... + n) = -
L i = -. 
= --. 
1 
1 ( 
) 
1 n(n + 1) 
n + 1 
n 
n lSiSn 
n 
2 
2 
This gives us the average complexity of the sequential search procedure. It 
tells us that, under the stated assumptions, every search of the array A will 
on the average look up about half the entries. 
The preceding solution can be improved considerably if the array is 
sorted, i.e., if A[i] < AU] for all i < j. In this case search for an entry, 
"dictionary" style: (1) Open the dictionary to the center; if the search key x 
is there, stop; (2) if x precedes the entries in the center page, then only the 
first half of the dictionary need be searched, and open to the center of that 
remaining half (i.e., go to (1)); (3) if x follows the entries in the center page, 
then only the second half of the dictionary need be searched, and open to the 
center of that remaining half. In this process, called binary search because 
it successively splits the dictionary in two -
either the key x is located by a 
particular "probe," or else the remaining interval of entries to be searched 
is halved. 
The binary search of (sorted) array A for an entry equal to x may be 
programmed as in Figure 29. In this algorithm we have used the operation 
div (integer division) introduced in Section 1.1. The effect of the instruction 
k := (i + j) div 2 is to assign to k the value L(i + j)/2J, the midpoint of the 
interval running from i to j. 
How do we know that the above algorithm works correctly? In the case 
of sequential search the flow chart was somewhat simpler, and we left it 
to the reader to verify that it worked as claimed. Perhaps a close examination 
of the flow chart for binary search, given above, will also convince the reader 
of its correctness. But if we ask for a more formal argument that the program 
behaves as intended, then we are asking for a proof of correctness - a rigorous 
demonstration that the algorithm outputs the correct value for all possible 
inputs. The study of correctness proofs is a major topic in theoretical com-
puter science, which will not however occupy us here. (A textbook account 
of the subject is given by S. Alagic and M. A. Arbib in their book, The 
Design of Well-Structured and Correct Programs, Springer-Verlag, 1978.) 
Nevertheless, all of the algorithms mentioned in this section can be rigorously 
proved to be correct. 
Let us analyze the complexity of binary search. Specifically, we want to 
count the number of entries that must be examined in array A before an out-
put is given. It will be useful to describe the sequence of comparisons that 
binary search goes through in the form of a binary tree. We use the notation 
"x: A[k]" to indicate a comparison between x and the contents of the kth 
array cell. 

3.3 An Example of Algorithm Analysis 
INPUT 
number x 
sorted array A[l], ... , A[n] 
i:= 1 
j:=n 
true 
record not 
found 
true 
record 
found at k 
Figure 29 Flow diagram for binary search of a sorted array. 
105 
The first comparison is x: A[L(n + 1)/2J], which we place at the root of 
the tree 
x: A[L(n + 1)/2J] 
< 
The left and right subtrees are the tree structures of the succeeding compari-
sons when x < A[L(n + l)/2J] and x > A[l(n + 1)/2J] respectively. For 
example the tree corresponding to a binary search for x in a sorted array A 
containing ten entries is given in Figure 30. 
Note that whenever there are no further comparisons that can be made in 
a subtree, we indicate this by a leaf marked with a square node. The resulting 

106 
3 Counting, Recurrences, and Trees 
Figure 30 Decision tree for binary search where a number x is sought in a sorted array 
containing 10 elements. 
binary tree is such that all internal nodes are ovals, and each has two 
children, and all leaves are square nodes. 
The tree just defined is called a binary decision tree. Each path through 
this tree, from the root to one of the leaves, represents a sequence of compari-
sons in the binary search method. If x is present. then the algorithm will stop 
at one of the circular nodes. If x is not present, the algorithm will terminate 
at one of the square nodes. 
Having placed square nodes in the fashion described above, a binary 
decision tree is always of height 1 or more. Moreover, if N is the number 
of internal nodes in such a tree, and if N Land N R are the number of nodes in 
the left and right subtrees, then N L = N R or N L = N R -
1. This is so 
because the internal nodes in the subtrees cover the search interval less the 
center point, which is chosen as Ln + 1J/2 for a length n interval, thus 
dividing the two subtrees as evenly as possible. 
1 Lemma. 
1. The left and right sub trees, TL and TR , of any node in a binary decision 
tree are such that height(TL) = height(TR) or 
height(TL) = height(TR) -
1. 
2. The total number n of internal (i.e., oval) nodes in a binary decision 
tree of height h ~ 1 is such that 2h-l ~ n < 2h. 
3. In a binary decision tree of height h ~ 1, all square nodes are either at 
level (h - 1) or level h, and all oval nodes are at levels 0, 1,2, ... ,(h -
1). 
PROOF. By induction on the height h, we prove simultaneously parts (1), 
(2), and (3). That is, we shall first prove the basis step for each part of the 

3.3 An Example of Algorithm Analysis 
107 
lemma. Then we shall assume simultaneously as inductive hypotheses each 
of the lemma's parts for trees of height h - 1, and these hypotheses combined 
will be adequate to establish the h case for each part. 
For h = 1, a binary decision tree has the following form: 
< 
> 
which clearly satisfies all the claimed results. Although the case h = 2 is 
not required in the basis step, and will follow from the induction step below, 
it is instructive to consider the two possible binary decision trees of height 2: 
< 
> 
Here, again, (I), (2), and (3) are easily verified. 
For the induction step, consider an arbitrary binary decision tree of 
height h ~ 1. 
By the induction hypothesis both TL and TR satisfy the inequality of (2) 
which rewrites as hL - 1 ::;; log2 nL < hL' and hR - 1 ::;; log2 nR < hR" A 
moment's thought shows that this implies hL = llog2 nd + 1 and hR 
= Llog2 nRJ + 1, where the subscripts Land R are used to identify quantities 
belonging to TL and TR respectively. 

108 
3 Counting, Recurrences, and Trees 
In a binary search algorithm either nL = nR or nL = nR -
1. Using the 
fact that hL = Llog2 nLJ + 1 and hR = LIOg2 nRJ + 1, this means that either 
hL = hR or hL = hR -
1, completing the proof for part (1). 
For part (2), note that h = max(hL , hR) + 1, so that here h = hR + 1, 
Whether nL = nR = n12, or nL = Lnl2J = nR -
1, it is easily checked that 
2h- 1 ~ n < 2h. Finally, it is readily verified that part (3) is also true, in both 
cases, nL = nR and nL = nR -
1. 
0 
2 Proposition. If the sorted array A has n entires, then the binary search 
method requires at most LIOg2 nJ + 1 comparisons for a successful search, 
and either Llog2 nJ or LIOg2 nJ + 1 comparisons for an unsuccessful search. 
PROOF. It should be clear that the binary decision tree describing the action 
of binary search on A has exactly n oval nodes. If h is the height of this 
tree, the number of comparisons needed to terminate at an oval node is 
~ h, while the number of comparisons needed to terminate at a square node 
is either (h -
1) or h, by part (3) of the lemma. (Recall that a square node 
does not correspond to a comparison, but only indicates unsuccessful 
termination. ). 
By part (2) of the lemma, 2h- 1 ~ n < 2h so that h = LIOg2 nJ + 1. The 
desired result follows immediately. 
0 
We have just demonstrated that the worst-case complexity of binary 
search on a sorted array of size n is about log2 n. For large n, the saving on the 
number of look-ups (or element comparisons) becomes considerable when 
compared to the worst-case complexity of sequential search. 
The average complexity of binary search, which we shall not examine here, 
can be shown to be about log2 n too. Because of this complexity estimate, 
binary search is sometimes called logarithmic search. 
EXERCISES FOR SECTION 3.3 
1. Consider the following algorithm to evaluate the polynomial 
p(x) = anxn + an_1xn - 1 + ... + alx + ao. 
begin 
p := a[D] ; 
XPOWER:= 1; 
for i := 1 to n do 
end 
begin XPOWER := X * XPOWER; 
p := p + a[i] * XPOWER end 
(a) How many multiplications are carried out (as a function of n) in the worst case? 
(b) How many multiplications are carried out on the average? 

3.3 An Example of Algorithm Analysis 
2. Consider now the following amended version of the preceding algorithm: 
begin 
p := a[O]; 
XPOWER:= 1; 
for i := 1 to n do 
begin XPOWER := X * XPOWER; 
if a[l] oF 0 then p := p + a[l] * XPOWER end 
end 
(a) How many multiplications are carried out in the worst case? 
109 
(b) How many multiplications are carried out on the average? Assume that the 
probability that a coefficient Qi is zero is -to. 
3. The Tournament Method to select the largest element in a list of n elements derives 
its name from the fact that it performs comparisons in the same way that tournaments 
are played. Elements are paired off and compared in the first round; the winners 
from the first round are then paired off and compared in the second round; and, in 
general, the winners from the preliminary round are paired off and compared in the 
next round. If at any round there is an odd number of entries, one is arbitrarily 
designated as a winner and not compared to another that round. 
A tournament between, say, eight players can be described by a binary tree as 
follows 
player 
6 
(the winner) 
player 
2 
~ 
player 
player 
2 
3 
A 
A 
player 
player 
player 
player 
1 
2 
3 
4 
player 
6 
~ 
player 
playel 
6 
7 
A 
A 
player 
player 
player 
player 
5 
6 
7 
8 
(a) What is the number of pairwise comparisons (as a function of n) required by the 
Tournament Method to select the largest element in a list of n entries? 
(b) Using the fact that the second largest element in the list must be paired off with 
the largest element at some point in the course of the tournament (why?), show 
that a total of (n + flog n 1 - 2) pairwise comparisons are sufficient to select the 
largest and the second largest elements in the list. 
4. (a) Verify that (in 3.1 part (2Â» if 2h- 1 ::; n < 2h then h = LiOg2 nJ + 1, where h 
and n are positive integers. 
(b) Verify that flog2 (n + 1)1 = LiOg2 nJ + 1. 
5. (a) We have shown that the worst-case complexity of the sequential search method 
is ::;n (i.e., searching a key in an array of n records never exceeds n look-ups). 
Show that this is in fact an optimal worst-case complexity, in that there are array 

110 
3 Counting, Recurrences, and Trees 
configurations that force the sequential search method to go through as many 
as n look-ups. 
(b) Show that if you are certain that the record to be found is in the array, then 
sequential search can be modified so that its worst-case complexity is :s; (n -
1) 
-
in fact = (n -
1), so that the bound (n -
1) is optimal. 
(c) How can you modify the binary search to eliminate unnecessary work if you 
are certain that the record to be found is in the array? Give the decision tree for 
the modified binary search method, and carry out the corresponding worst-case 
complexity analysis. 
6. Multiplication of two natural numbers x and y 
Program PI 
Program P2 
begin z:= 0; u:= x; 
end 
repeat z ,= z + y; u ,= u -
until u = 0 
beginz ,=0; u :=x; v:= y; 
while u =1= 0 do 
end 
begin if u is odd then z ,= z + v; 
u :=udiv 2; l' :=2 * v; 
end 
Let A be the cost of an assignment; 
B that of an addition or subtraction; 
C that of a division by 2 or multiplication by 2; 
D that of any test. 
(a) Determine the worst-case costs of PI and P2, as functions of A, B, C, D, x, and y. 
(b) What are the values of x and/or y for which the worst-case costs of PI and P2 
are reached? 
(c) If A = B = C = D, compare the worst-case costs of PI and P2. 

CHAPTER 4 
Switching Circuits, Proofs, and Logic 
4.1 Truth Tables and Switching Circuits 
4.2 Proving Theorems 
The two-element set plays a vital role in computer science, both as the bits 
o and 1 of binary arithmetic (corresponding to the two stable states of the 
basic subcomponents of computer circuitry), and as the two truth values, 
T (true) and F (false), of the logical analysis of circuitry, and the tests of pro-
grams. Section 4.1 introduces the basic operations of negation, conjunction, 
and disjunction on truth values, and shows how these operations can be 
used to express Boolean functions in normal form. We briefly discuss the 
use of components corresponding to these basic operations in building up 
computer circuits for addition. Section 4.2 looks at proof techniques from 
two perspectives. The first makes explicit the various "everyday" techniques 
we use in proving theorems in this book. The second gives a formal discussion 
of the notion of proof in propositionallogic, and closes with a brief intro-
duction to the quantifiers of predicate logic. 
4.1 Truth Tables and Switching Circuits 
A proposition is a statement that is either true or false. "My aunt lives in 
Boston" is a proposition; "The capital of Massachusetts" is not. If a pro-
position is true, we say its truth value is T (short for true); while if the state-
ment is false, we say its truth value is F (short for false). The set [JI = {T, F}, 
which we met in Section 1.1, is then the set of truth values. 
Given a statement we can form its negation, or denial. "All men are mortal" 
has truth value T; its negation is "Not every man is mortal," the English 
111 

112 
4 Switching Circuits, Proofs, and Logic 
form of "NOT (all men are mortal)" and has truth value F. We may thus 
represent negation by a map {T, F} -+ {T, F} which assigns to the truth 
value of a proposition (denoted by some letter, p), the truth value of the 
negation of that proposition (denoted p or -,p or NOT(P)). Clearly, p is 
defined by the truth table 
W;
p 
T 
F 
F 
T 
which pairs each truth value of p with the corresponding truth value of p. 
Another way of combining statements is conjunction. An example is the 
proposition "Harry is young AND Mary is old," which is true just in case 
both" Harry is young" and" Mary is old" are true. We are thus led to define 
a map 
,,: {T, F}2 -+ {T, F}, 
(p, q) 1--+ P " q 
whose values are defined by the truth table 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
pAq 
T 
F 
F 
F 
Yet another way of combining two statements is to use the word "or." 
But there are two different ways of defining "or" by means of truth tables. 
The first case is the exclusive or; in this case (A or B) is true if either A or 
B is true, but not if both are. An example of the use of the exclusive "or" 
is the proposition "He took the train or he took the plane." The cor-
responding function EEl: {T, F}2 -+ {T, F} is given by the truth table 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
p$q 
F 
T 
T 
F 
The second case is the inclusive or - (A OR B) - which is true if either of A 
or B is true, or if both are true. An example is the proposition "The weather 
will be fine on Tuesday or Wednesday," considered as an abbreviation for 
"The weather will be fine on Tuesday OR the weather will be fine on Wed-
nesday," which includes the possibility that the weather may be fine on both 

4.1 Truth Tables and Switching Circuits 
113 
Tuesday and Wednesday. The corresponding {T, F}2 -+ {T, F}, (p, q) 1-+ 
P V q is given by 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
pvq 
T 
T 
T 
F 
The choice of" v " comes from the fact that vel is the Latin word for the 
inclusive or; then the " /\" is the" v " upside down. This "upside down" 
relationship between the symbols for AND and OR is reflected logically by 
the equation 
P /\ q = 15 v q. 
The truth tables below show that this equivalence does indeed hold. 
p 
q 
P /\ q 
P 
q 
pVij 
T 
T 
F 
T 
T 
F 
T 
F 
T 
T 
F 
T 
F 
T 
T 
F 
T 
T 
F 
F 
T 
F 
F 
T 
Another simple truth table manipulation shows us that 
15= p. 
Let us use these two facts to evaluate p v q: 
pvq=15vq 
=15/\q 
=15/\q 
by two applications of (2) 
on applying (1) to 15 and q 
by applying (2) again. 
(1) 
(2) 
We thus have De Morgan's Laws: For all pairs of truth values p and q, 
P/\q=15vq 
p V q = 15 /\ q. 
Thus /\ can be replaced by a composite of v and - ; and v can be replaced 
by a combination of /\ and - . However, - cannot be replaced by a combina-
tion of /\ and v. This is because if we think of T as representing 1 and F as 
representing 0, then 1 /\ 1 = 1 and 1 v 1 = 1, but -
converts 1 to 0, 
something no combination of /\ 's and v 's can do. (This is not a rigorous 
proof. See Exercise 4 for a sketch of how to proceed more formally.) 

114 
4 Switching Circuits, Proofs, and Logic 
THE SWITCHING CIRCUIT VIEWPOINT 
We now examine how each propositional function introduced above may 
be thought of as a switching function of the kind used in building computer 
circuitry. We replace T by 1 and F by 0, respectively, to get the "bits" of a 
computer's binary arithmetic. In what follows we may, for example, think 
of 0 as representing a low voltage on a line in the circuit, and of 1 as rep-
resenting a high voltage. 
A NOT-gate is an inverter: m
p 
--------~o~------
o 
1 
1 
0 
An AND-gate emits a 1 only if both input lines carry a 1 : 
-01----
01\0=001\1=0 
11\0=011\1=1. 
An OR-gate emits a 1 if at least one of the input lines carries a 1 : 
-D~ 
OvO=O Ovl=1 
IvO=11vl=1. 
If we think of inverters as "beads" which we can "slide" along a line until 
they rest against an AND-gate or OR-gate, we can represent De Morgan's 
laws by: 
pl\q=pvq --------101---
pvq=Pl\q -D>---
We shall explore this switching function interpretation in more detail 
later in this section. For the present let us consider propositionallogic more 
closely from the numerical point of view. We start with the following simple 
relationships. 
p = (1 - p) 
p v q = max(p, q) 
p 1\ q = min(p, q) 
since 1 - 0 = 1, 1 - 1 = O. 
the larger of p and q. 
the smaller of p and q. 

4.1 Truth Tables and Switching Circuits 
Let us also look at p EEl q and see what it means numerically. 
p 
q 
pÂ® q 
000 
o 
1 
1 
101 
110 
115 
p EEl q is precisely the sum of p and q modulo 2 -
i.e., add p and q as ordinary 
numbers, and take the remainder after division by 2. Recall from Section 1.1 
the notation n mod m for the "remainder when n is divided by m," also 
referred to as "n modulo m," which is the number r (the remainder) such that 
there exists some number q (the dividend) satisfying 
n = q * m + r 
with 0 ~ r ~ m -
1. 
When the modulus m is 2, we have 
(0 + 0) mod 2 = 0 mod 2 = 0 = 0 EEl 0 
(0 + 1) mod 2 = 1 mod 2 = 1 = 0 EEl 1 
(1 + 0) mod 2 = 1 mod 2 = 1 = 1 EEl 0 
(1 + 1) mod 2 = 2 mod 2 = 0 = 1 EEl 1. 
In general, given any natural number m > 1, we can define Zm to be 
the set {O, 1, 2, ... , m -
1} which we refer to as the set of integers modulo m. 
We have the map 
nHnmodm 
which sends each integer n in Z to its (positive) remainder modulo m. This 
map can be visualized by thinking of Z as being wound into a helix, with m 
integers in every revolution, and then projecting the whole helix down onto 
the bottom ring -
the single turn {O, 1, ... , m -
1}, as shown in Figure 31 
for the case m = 4. 
We can define a successor function a: Zm ~ Zm by a(n) = (n + 1) mod m, 
that is, 
{o 
ifn=m-1 
a(n) = 
. 
n+1 
IfO~n<m-1 
and we can define addition modulo m, EElm: Z;, ~ Zm by 
n EElm n' = (n + n') mod m 
where + is the usual addition defined on the integers. Note, then, that we 
use EEl as an abbreviation for EEl 2' 

116 
4 Switching Circuits, Proofs, and Logic 
11 
9 
7 
5 
3 
1 
z 
-1 
Figure 31 
Mapping Z onto Z4. 
~ 
__ I----r - 3 
-5 
~-!--~T -7 
-9 
3 
1 
2 
Returning to logic gates, let us see how to build EEl using AND, OR, 
and NOT gates. Recall first that p EEl q is true just in case p v q is. true save 
with one exception, namely when p /\ q is true. That is p EEl q is true if p v q 
is true and p /\ q is false: 
p EEl q = (p v q) /\ (p /\ q). 
(3) 
Let us check this by formal substitution in truth tables: 
p 
o 
o 
q 
o 
1 
o 
p v q 
o 
P /\ q 
1 
o 
(p v q) /\ (p/\ q) 
o 
I 
1 
o 
We compute the third and fourth columns directly, and then use the /\ -rules 
to find the fifth column, which is indeed the same as the column for EEl, 
thus verifying (3). In other words, we have the following EEl-circuit: 
p---< 
q---I----< 
I---p$q 

4.1 Truth Tables and Switching Circuits 
117 
NORMAL FORMS 
A common technique in mathematics is to reduce complicated expressions 
to some normal form. 
Perhaps the most familiar example of a normal form is the expression of a 
fraction in its lowest terms 
1 . 
1 2 3 
117 
2 IS the normal form for 2' 4' 6' ... , 334' etc. 
7. hit' 
t' 
7 14 21 
136332 
9 IS t e norma lorm lor 9' 18' 27' ... , 175284' etc. 
Another normal form 
so-called scientific notation -
allows us to 
express any nonzero decimal number in the form a x lOb where a has only 
one digit to the left of the decimal point, and b is an integer, so that 
1.375 x 106 is the normal form for 1375000 
7.215 x 10- 4 is the normal form for .0007215. 
We now examine normal forms for formulas built up using 1\, v, 
and propositionalletters. Consider the formula 
(pvq)l\(rvq). 
(4) 
This expression has the following truth table 
p 
q 
o 
o 
o 
1 
o 
1 
o 
0 
o 
0 
r 
1 
0 
1 
0 
1 
0 
1 
0 
(p v q) /\ (r v q) 
0 
0 
0 
1 
0 
0 
0 
The disjunctive normalform for this formula is 
(p 1\ q 1\ r) v (p 1\ q 1\ r). 
(5) 
That is, formula (4) and formula (5) are equivalent formulas since they have 
the same truth tables, and (5) is in disjunctive normal form: it is a disjunction 
of conjuncts of variables and negations of variables, and each disjunct 
mentions every variable exactly once. 
Expression (5) was obtained in the following way. Examining the truth 
table above, we see that exactly two of its rows yield a true value for the 
original formula. The first row occurs when p is true and q and r are false - a 
set of conditions we can represent by the expression (p 1\ q 1\ r). This 

118 
4 Switching Circuits, Proofs, and Logic 
expression is false whenever these conditions are not exactly met. Similarly, 
(p 1\ q 1\ r) represents the second true row of the truth table. Since either 
pattern of values to the variables is sufficient to yield a true row, the dis-
junction of these two conditions, formula (5) above, is the desired expression. 
Our result shows that any formula built up from 1\, v, and - has an 
equivalent disjunctive normal form. But in fact a more general result, 
yielding a disjunctive normal form for any "truth-table" or "Boolean func-
tion" is also true. 
1 Definition. A Boo lean function of n arguments is a map 
f: {a, l}n --+ {a, l} 
which assigns a value f(Pl, ... , Pn) of Â° or 1 to each n-tuple (Pl, ... , Pn) 
of O's and l's. 
There are 2n elements in {a, l}n. We can therefore write a truth table for f 
with 2n lines, one for each n-tuple in {a, l}n, the n-tuple (Pl, ... , Pn) being 
followed by the value f(Pl' ... , Pn) that f assigns to that particular n-tuple. 
Hence, there are 22" different n-ary truth tables. (Alternatively, recall from 
1. 3.9 that there are I B IIAI distinct maps from A to B. Here A = {a, l}n 
with IAI = 2n and B = {a, l} with IBI = 2.) In the course of showing that 
every Boolean function of n arguments has a disjunctive normal form, we 
shall also show that such a function can be built up just using 1\, v, -, and 
propositionalletters Pl, ... , Pn' 
Consider first the operation of conjunction. It is clear that it is associative; 
that is, 
P 1\ (q 1\ r) = (P 1\ q) 1\ r 
since both sides take the value 1 iff all of p, q, and r take the value 1. We can 
thus remove the parentheses and write expressions like 
q 1 1\ q 2 1\ â¢ â¢â¢ 1\ qn 
(6) 
as short for any of the equivalent repeated conjunctions such as 
Â« ... (ql 1\ q2) 1\ ... ) 1\ qn). 
We also abbreviate (6) to !\l:S.i:S.n qi or !\iel qi for 1= {l, 2, ... , n}. In 
the latter case I is called the index set for the conjunction. Similarly, given 
an index set I with one proposition qi for each i E I, we may use the notation 
ieI 
for the repeated disjunction which takes the value 1 iff at least one of the 
q;'s is 1. Now, consider the notation 
pO as short for p 
pl as short for p. 

4.1 Truth Tables and Switching Circuits 
119 
Then note that 0Â° = 1 and 01 = 0, while 1Â° = 0 and 11 = 1. We thus see 
that pX = 1 iff p = x, for p, x E {O, I}. Let us fix, then, an n-tuple of Boolean 
values, (Xl"'" Xn) E {O, l}n and use it to define a Boolean function: 
We see that this function takes the value 1 just in case pi' = 1 for every 
1 ::;; i::;; n; Le., just in case Pi = Xi for every 1 ::;; i::;; n. The truth table of the 
Boolean function just defined has all the entries of its right-hand side column 
equal to 0, except for a single entry in the row corresponding to the fixed 
n-tuple (Xl' ... , Xn). 
We can see this directly by inspecting the truth tables for n = 2, one for 
every function of the form (p, q) f-+ pX /\ qY: 
p 
q 
P /\ i:i 
p 
q 
P /\ q 
0 
0 
1 
0 
0 
0 
0 
1 
0 
0 
1 
1 
0 
0 
1 
0 
0 
1 
0 
1 
0 
(x, y) = (0, 0) 
(x, y) = (0, 1) 
P 
q 
P /\ i:i 
P 
q 
P /\ q 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
1 
0 
0 
1 
0 
0 
1 
0 
1 
1 
(x, y) = (1, 0) 
(x, y) = (1, 1). 
Any other Boolean function of two arguments which has in the right-hand 
side column of its truth table more than one entry equal to 1 can now be 
obtained as a combination of the four defined above. Consider for instance 
the truth table for p Ee q: it has a 1 in the (0, 1) and (1, 0) lines; Le., it has value 
1 just in case pO /\ ql = P /\ q is true or pI /\ qO = P /\ q is true, and so 
we have 
p Ee q = (p /\ q) V (p /\ q) 
as an alternative way of expressing Ee in terms of /\, v and -. 
2 Example. Let f: {O, l}3 --+ {O, I} be such that f(P, q, r) = 0 unless (p, q, r) 
has one of the values (1, 0, 1) or (0, 0, 1) or (0, 1, 0). 
Then 

120 
4 Switching Circuits, Proofs, and Logic 
f(P, q, r) = (P t\ q t\ r) v (p t\ q t\ r) v (p t\ q t\ r), which yields the 
switching function: 
p 
q 
r 
In the same way we can build up any Boolean function: 
3 Theorem. Given any Boolean function f: {a, I}" ~ {a, 1}, we may express 
f(Pl' ... , Pn) as the disjunction of those conjuncts p~' t\ ... t\ p~n for which 
f(Xl, ... , xn) equals 1: 
f(Pb ... , Pn) = 
V 
p~' t\ ... t\ p~n 
{(Xl, ..â¢â¢ xn)lf(XI â¢...â¢ Xn)= i) 
V 
f(Xb ... , Xn) t\ p~' t\ ... t\ p~n. 
{(Xl â¢.. " Xn) I (Xl â¢â¢..â¢ Xn) e to, l}n} 
PROOF. This is a generalization of the preceding discussion. When we choose 
specific values for (Pi' ... , Pn), the only term of the disjunction which is non-
zero satisfies Pi = Xi for all 1 :$; i :$; n, and so the value of the disjunction 
is 1 if and only if f(Pl, ... , Pn) = 1. 
D 
The disjunctive normal form theorem, Theorem 3 above, shows that any 
Boolean function can be built up using only the operations t\, v, and -. 
Note that each disjunct in the disjunctive normal form for a Boolean 
function of n arguments mentions everyone ofthe variables (i.e., propositional 

4.1 Truth Tables and Switching Circuits 
121 
letters) in the set {PI, ... , Pn}. Such a disjunct is called a minterm. The 
characteristic property of a minterm is that it assumes the value 1 for exactly 
one assignment of values to the n variables. We can easily see that a minterm 
is unique (up to a reordering of the n variables), in that no other minterm 
assumes the value 1 for the same combination of the n arguments. This 
immediately leads to the following fact. 
4 Corollary. The disjunctive normal form of a Boolean function f(Pl' .. , Pn) 
is unique, up to a reordering of the n variables in each conjunct and up to a 
reordering of the conjunct in the disjunctive normal form. 
PROOF. We already pointed out that the value of a conjunct is not affected 
by the order in which its variables are mentioned, since the operation /\ is 
commutative, i.e., P /\ q = q /\ p. Likewise, the value of a disjunctive normal 
form is not affected by the order of its disjuncts, since the operation v is 
commutative. 
0 
Another normal form for a Boolean function f: {O, l}n ~ {O, 1} is the 
so-called conjunctive normal form, which uniquely expresses f(Pl, ... ,Pn) 
as a conjunction of disjuncts. The existence and uniqueness of the conjunctive 
normal form can be easily established in a manner similar to our discussion 
of the disjunctive normal form above (see Exercise 2). However, once we 
have found the disjunctive normal form for f, we may also use De Morgan's 
laws to determine the conjunctive normal form of f, as shown in the next 
example. 
5 Example. This example continues Example 2. The negation of f is the 
function l(p, q, r) which has value 1 at the following values of its arguments: 
(0,0,0), (0, 1, 1), (1,0,0), (1, 1,0), and (1, 1, 1). Hence, the disjunctive normal 
form of lis: 
Rp, q, r) = (fi /\ q /\ r) v (fi /\ q /\ r) v (p /\ q /\ r) v (p /\ q /\ r) 
v (P /\ q /\ r) 
which includes all the minterms not included in the disjunctive normal form 
of f. Negating 1 and applying De Morgan's laws, we now get 
f(P, q, r) = l(p, q, r) 
=(fi/\q/\n/\(fi/\q/\~/\(p/\q/\n/\(p/\q/\n 
/\ (p-/\-q-/\ ~r) 
=(Pvqv~/\(pvqvn/\(fivqv~/\(fivqv~ 
/\(pvqvr) 

122 
4 Switching Circuits. Proofs. and Logic 
which is the conjunctive normal form for f. Each of the disjuncts in the 
conjunctive normal form off is called a maxterm, because it mentions each of 
the variables p, q, and r, and assumes the value 1 for all but one of the as-
signments of values to the three variables. 
Generally, then, if the disjunctive normal form of the function f: {O, I}" ..... 
{O, I} is known, then the disjunctive normal form of the negation of f, 
f {O, I}" ..... {O, I}, will consist of the disjunction of the remaining minterm~ 
which do not appear in the disjunctive normal form of f. Now, since f = j, 
we can obtain the conjunctive normal form of f by repeated applications of 
De Morgan's laws to the disjunctive normal form of J 
FUNcnONALL Y COMPLETE OPERA nONS 
A set of operations is said to be functionally complete if every Boolean 
function can be expressed entirely by means of operations from this set. 
Theorems 3 and 4 above show that the set { 1\, v, -} is functionally com-
plete. 
We have seen that De Morgan's laws let us either build 1\ from v and 
, or build v from 1\ and -. Hence, again using Theorem 3 or 4, we have 
6 Fact. The sets { v, -} and { 1\, -} are functionally complete. 
o 
In fact, there is a Boolean function from which all other Boolean functions 
can be composed. It is the Sheffer stroke p j q: 
p 
q 
o 
0 
o 
1 
1 
o 
plq 
1 
o 
We see that pjq = p 1\ q, and so the Sheffer stroke is often called NAND, 
short for NOT-AND. It can be realized by a NAND-gate 
-Df---

4.1 Truth Tables and Switching Circuits 
123 
Given the Sheffer stroke, we recapture -, /\ and v as follows: 
jj = P /\ P = pip 
P /\ q = P /\ q = [Jlq" = (plq)l(plq) 
P v q = jj /\ q = (PIp) /\ (qlq) = (Plp)l(qlq). 
We thus have the following 
7 Fact. The Sheffer stroke isfunctionally complete. 
o 
There is still another operation, a NOR operation, (P l q) = (p v q), 
the "dagger" l in terms of which all other Boolean functions can be defined, 
which we shall leave to the reader's consideration (Exercise 1). 
ADDING BITS 
As an example of the logical design of a circuit which can be used as part 
of a computer, consider a half-adder (we shall meet the full-adder below), 
which takes two bits, a and b, as input and returns a carry bit c and sum 
bit s as output. The pair cs in that order is the binary sum of a and b. 
a 
b 
c 
s 
o 
0 
0 
0 
010 
1 
001 
o 
We recognize that c = a /\ b while, using the disjunctive normal form, 
s = a EEl b = (a /\ b) v (a /\ 5). Thus we can build our half-adder using a 
total of four AND- and OR-gates as follows: 
a ----+------1 
b---+--- --+---a 
")----+---s 
r---~--------~--c 
a/\b 

124 
4 Switching Circuits, Proofs, and Logic 
However, if we recall the formula a Efl b = (a v b) /\ (a /\ b), we can build 
the half-adder with one less gate. 
a--h;-----\ 
b--+--""----t 
}---+---s 
~-~~------+----c 
a/\b 
(7) 
These two circuits exemplify the general observation that while disjunctive 
normal form tells us how to build any switching functions using AND-, OR-, 
and NOT-gates, it does not in general give us the minimal circuit, i.e., the one 
with the smallest number of gates. The problem of finding minimal circuits 
was an active area of research in the 50's and 60's. But computer circuitry 
is no longer built by wiring individual components together. Instead, 
integrated circuits containing the equivalent of tens of thousands of gates 
can be mass produced by a process akin to printing photographs. (See, for 
example, the article on "Microcomputers" by A. G. Vacroux in the May 
1975 Scientific American, which gives a useful account of how the entire 
circuitry of a computer can be made from just a few specially designed 
"chips.") As a result, minimization problems have been replaced by layout 
problems -
how do we layout components to reduce the length of con-
nections of the number of crossovers? -
and these are usually handled by 
computer-assisted design techniques outside the scope of this book. 
Returning now to the binary addition problem: We want to design a 
full-adder which can take the bits a and b together with a carry bit c' to 
return the sum bit s and carry bit c. 
a 
b 
c 
c' 
(8) 
s 
The desired sum bit s is clearly (a Efl b) Efl c'. But what of the carry bit c as a 
function of a, b, and the "input carry" c'? We want c to be 1 just in case 
at least two of a, b, and c' are 1. But (a Efl b) /\ c' is 1 if only a and c' are 1 
or only band c' are 1; while a /\ b is true if only a and bare 1, or if all a, b, 
and c' are 1. Thus 
c = [(a Efl b) /\ c'] v (a /\ b). 

4.1 Truth Tables and Switching Circuits 
125 
Thus we can realize the full-adder of (8) (changing the position of input and 
output lines) by combining two half-adders with an OR-gate as follows: 
C'-------f 
(a Efl b) Efl c' 
5 
a Efl b) 1\ C' 
c 
(9) 
a------I 
aEflb 
b-----; lA 
al\b 
Given a collection offull-adders, we can add binary numbers of any length, 
as in the circuit below for adding 4-bit numbers (b4b3b2b1) and (a4a3a2a1) 
to yield a 5-bit number (C4S453S2S1): 
A 
(10) 
A problem of great interest to computer scientists is to determine the 
complexity of switching functions -
to find lower bounds on the speed with 
which a function can be computed, and to seek circuits which can compute the 
function in close to minimal time. As an example of this, consider the time 
required to add two binary numbers with circuit (10). Take as our time unit 
the time required for an AND-gate or OR-gate (with or without inverters) to 
achieve a stable output level after the input values have been changed. Then 
circuit (7) for a half-adder will take 2 time units to stabilize its output after 
a change in input values; and the full-adder of (8) will take 5 time units to 
stabilize. Consider, then, an n-bit adder such as that in (10) for n = 4. 
Circuit (10) is inherently serial, in that the U + l)th full-adder cannot begin 
to compute the correct outputs until it receives a stable carry bit Cj from the 
preceding full-adder. Thus the total time to achieve a stable output from such 
an n-bit adder is 
2 + 5(n -
1) ~ 5n 
where the notation ~ indicates that the two sides are almost equal, and 
that the difference becomes less and less important as n gets larger. It may 
appear to the reader that no n-bit adder could be designed without requiring 
a time proportional to the number n of bits, for the propagation of carry bits 

126 
4 Switching Circuits, Proofs, and Logic 
seems to be the limiting factor. However, there is an ingenious design called 
the carry look-ahead adder which uses parallelism based on "guessing 
carry bits and patching up later" which has a time requirement proportional 
to the logarithm of n. For 64 bits, the look-ahead adder is about 9 times 
faster, yet only requires about 50 % more gates than the conventional adder 
like (10). (For actual circuit details, see Sections 11.4 to 11.6 of F. J. Hill and 
G. R. Peterson: "Digital Systems: Hardware Organization and Design," 
WHey, 1973.) 
THRESHOLD LOGIC UNITS 
In 1943, Warren McCulloch and Waiter Pitts offered a formal model of 
the neuron (the basic cellular component of the brain) as a switching function 
{O, l}n -> {O, 1} defined in the following way: 
.p 
(11) 
There is a real number e called the threshold, and for each input line there is a 
weight W -
we say the input is excitatory if W > 0 and inhibitory if W < O. 
Given a binary input vector (Pl' ... , Pn) we form the real number sum 
Ii'= 1 WiPi, and decree that the output is 1 just in case this sum reaches 
threshold: 
{ 
n 
1 if I WiPi 2 e 
i= 1 
p= 
o if itl WiPi < e. 
(12) 
Such a component is referred to as a McCulloch-Pitts Neuron or a Threshold 
Logic Unit. (Such units have been of great interest in the field of pattern 
recognition where researchers study how the weights Wi might be adjusted to 
cause a threshold logic unit to respond only to those inputs belonging to 
some "pattern." For a review of this field, see N. J. Nilsson: "Learning 
Machines," McGraw-Hill, 1965.) 
We now see how to choose weights and threshold to build a NOT-gate, 
and an AND-gate. Against each line of the truth table, we place the inequality 
which the weights and threshold must satisfy according to (12). 
Hi
p 
P~P 
0 
1 
1 
0 
yields 0 ~ () 
yields w < () 

4.1 Truth Tables and Switching Circuits 
127 
and we can satisfy these inequalities with (J = 0, W = - 1. 
p 
q 
P /\ q 
Pfr 
(J 
pl\q 
0 
0 
0 
yields 0 < e 
0 
1 
0 
yields W2 < e 
q 
W2 
1 
0 
0 
yields W1 < e 
1 
1 
yields W1 + W2 ~ e 
and we can satisfy these inequalities with (J = 2, Wl = W2 = 1. 
However, we shall see that no single threshold logic unit can compute 
p Efl q. For suppose we have 
p 
q 
pEfJq 
0 
0 
0 
yielding o<e 
0 
1 
1 
yielding W2 ~ e 
1 
0 
1 
yielding W 1 ~ e 
1 
1 
0 
yielding W 1 + W2 < e. 
We could then deduce that 
W1 + W2 ~ (J + (J > (J 
since (J > 0 
but this would contradict Wl + W2 < (J. Hence no such choice ofwl, W2 and 
(J is possible. 
This is an example of the very important notion of an impossibility proof 
-
the proof that a problem cannot be solved using a particular methodology. 
EXERCISES FOR SECTION 4.1 
1. Let (p ! q) denote the Boolean function realized by the NOR-gate 
~ ---V>---- (p !q) 
(a) Write the truth table for (p ! q) 
(b) Show how to express /\, v and 
by repeated application of !. 
2. Given any Boolean functionf: {O, l}n -+ {O, I}, prove directly (i.e., without applying 
De Morgan's laws to the disjunctive normal form of 1) that f can be written in the 
following conjunctive normal form 
f(P 
P ) 
1\ 
PXJ' V pX22 V â¢â¢â¢ V pXnn. 
I"", n = 
{(x, â¢... â¢ xn)I!(x, , ... ,xn)=O) 

128 
4 Switching Circuits, Proofs, and Logic 
3. Use AND, OR, and NOT-gates to build a circuit which realizes the function 
f: {O, 1}3 ..... {O, 1}2 defined by the table: 
p 
q 
r 
fl(P, q, r) 
f2(P, q, r) 
o 
o 
o 
o 
I 
I 
I 
I 
o 
o 
I 
I 
o 
o 
I 
o 
I 
o 
I 
o 
I 
o 
I 
o 
1 
o 
1 
o 
1 
1 
o 
1 
o 
1 
1 
o 
o 
o 
1 
4. Prove by induction on the number of gates that no circuit built entirely from 
AND-gates and OR-gates can realize p, where the circuit has one input line carrying 
p, and the output line of one gate in the circuit should (but you will prove it cannot) 
bear the value p. 
p------~~----~ 
>--+---p 
5. Choose weights W1 and W2 and threshold () for a threshold logic unit to realize 
each of the following 
(a) (P Lq) 
(b) p v q 
(c) p = q defined by 
p 
o 
o 
1 
1 
or prove that no such realization exists. 
q 
o 
1 
o 
1 
1 
o 
o 
1 
6. Let if p then q else r be the Boolean function which returns the truth value of q if p 
is true, but returns the truth value of r if p is false. Verify that 
(a) if p then p else p equals false 
(b) if p then q else true equals p :=> q which is defined by the truth table 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
p:=>q 
T 
F 
T 
T 

4.1 Truth Tables and Switching Circuits 
(c) if p then q else false equals p 1\ q. 
(d) if p then false else true equals p. 
What expression of this kind (called a 3-conditional) yields p v q? 
(e) Show that the ternary connective if-then-else is complete. 
(f) Give a Sheffer stroke representation of if p then q else r. 
7. A more general form of conditional than that of Exercise 6 is given by 
129 
which is evaluated as follows: Find the first j such that Pi is true and return the 
value of e j; if no such j exists, the result is undefined (a partial Boolean function !). 
(a) Verify that if p then q else r = (COND(P q)(T rÂ» 
(b) Write down the disjunctive normal form for 
(r) (COND(p 1\ q q)(p p)(q qÂ» 
(ii) (COND(p v q v r q 1\ r)(T rÂ». 
8. Notice that 
if (if p then q else r) then. seise n 
is equivalent to 
if p then (if q then seise n) else (if r then seise n). 
Use this fact to devise an algorithm that transforms any if-then-else expression into 
an equivalentif-then-elseexpression in which the "if" expression is a simple variable. 
9. By writing out truth tables show 
(i) (p v q) v s = p v (q v s) 
(ii) (p 1\ q) 1\ S = P 1\ (q 1\ s) 
(iii) (p EEl q) EEl s = P EEl (q EEls) 
(iv) [(P 1\ q) V p] 1\ [p V q] = P 1\ q. 
10. How many Boolean functions {O, I}" --+ {O, I} are there for n = 1, 2, and 3? 
Display all the Boolean functions for n = 2 in a table as shown below. Label the 
functions encountered in the text with the appropriate symbol. 
p 
o 
o 
1 
1 
q 
o 
1 
o 
1 
fo 
o 
o 
o 
o 
11. Give an example of a formula which is a disjunct of conjuncts and which is distinct 
from its disjunctive normal form. 

130 
4 Switching Circuits, Proofs, and Logic 
12. Determine the function f(PI' P2' P3, P4) realized by the following network 
P2 
P3 
-1 
P4 
3 
f(PI, P2, P3' P4) 
PI 
P2 
2 
P3 
-2 
13. Determine which of the following Boolean functions are realized by threshold 
logic units 
(a) f(P, q, r) = p ij r v p ij r v p q r 
(b) f(P, q, r) = pq v qf 
(c) f(P, q, r) = p ij r v p q r v P q v P q r 
(d) f(P, q, r) = p q v P q r. 
14. Consider the following threshold network 
P 
q 
r 
2 
3 
B 
P b 
2 
2 
-2 
-2 
q 
7 
r 
(a) What is the truth table ofthe function f(P, q, r)? 
(b) Realize f(P, q, r) with a single threshold logic unit. 
â¢ 
f(P, q, r) 
15. A formula is in biconditional form if no connective other than -
is present. P -
q; 
P -
(P -
q), and q are in biconditional form. Given an example of a formula 
that is not equivalent to any formula in biconditional form. The truth table for 
-
is given below 
P 
T 
T 
F 
F 
q 
T 
F 
T 
F 
T 
F 
F 
T 

4.2 Proving Theorems 
131 
4.2 Proving Theorems 
In this section, we take a self-conscious look at the way in which we establish 
those "true statements" called theorems. In the first subsection we look at 
the proof techniques of everyday mathematics. We then take a quick look 
at quantifiers, which we use to formalize" for some" and" for all" statements. 
We close the section with a brief study of the formal notion of proof in logic. 
PROOF TECHNIQUES IN "EVERYDAY MATHEMATICS" 
Now that the reader has seen a number of proofs in the preceding sections, 
it is time for a more explicit look at some of the most useful proof techniques. 
(Note, too, the discussion of existence and constructive proofs on page 78.) 
Proof by Induction. In Section 2.1 we presented the concept of proof by 
induction. Recall that to prove a property P(n) of the natural numbers, we 
proceed in two steps: 
1. The Basis Step: We demonstrate that P(n) is true for n = O. (If we wish 
to prove that P(n) holds for all n ~ m, we begin with n = m.) 
2. The Induction Step: We assume that P(n) is true for n = k, and under 
this assumption demonstrate that P(n) must be true for n = k + 1. 
We also saw more general proofs by induction for properties of sets of 
strings and for sets oflists, and such proofs are also available for other sets of 
structured objects. 
Proofby Exhaustion of Cases. A proof may be performed by demonstrating 
the validity of a statement for all possible cases. For example, in proving a 
property for all integers we might, as exemplified in the proof of Theorem 2 
below, give three proofs showing that the property holds for all integers of the 
form 3m, the form 3m + 1, and the form 3m + 2. Since all integers are of one 
of these three forms, this exhausts all possible cases. 
Proof by Contradiction. The next proof technique we will consider is that 
of proof by contradiction. It is also called reductio ad absurdum: reduction to 
an absurdity. In this method, we use the property that a given statement is 
either true or false, but not both. We assume that the given statement is 
false, and then use definitions and facts (whether obvious or previously proven) 
to develop some statement which contradicts that which we know to be 
factual. Since the contradiction was developed by assuming that the given 
statement was false, and since we have used only known truths, our original 
assumption must have been incorrect. This then proves that the original 
statement is true. 
At first sight, proof by contradiction may not appear to be significant, 
but is often the easiest and best proof technique. We gave a classical reductio 

132 
4 Switching Circuits, Proofs, and Logic 
ad absurdum in Section 1.1 when we presented Euclid's proof that there are 
infinitely many primes in N. 
NECESSARY CONDITIONS 
When a statement A implies a statement B, we say that B is a necessary 
condition for A. This is simply because it is "necessary" for B to be true when 
A is true. There is more than one way to say -this: 
1. A is true implies B is true. 
2. If A is true, then B is true. 
3. A can be true only if B is true. 
4. A necessary condition for A to be true is that B is true. 
5. It is necessary that B be true in order for A to beÂ· true. 
The above five statements are equivalent, and can all be symbolized mathe-
matically by A => B. To prove necessity, we simply start with A (the hypo-
thesis), and present -a series of supported statements until we conclude B 
(possibly by employing methods of contradiction). 
Note that if A => B, it is not necessarily true that B => A (which is the 
converse of A => B.) For example, suppose we take Z to be the set 
{ ... , - 3, - 2, -1,0,1,2,3, ... } of all integers, be they negative, zero, or 
positive; and then consider the two statements: 
An which is true if n E Z and 0 ~ n ~ 2; and 
Bn which is true if n E Z and n2 ~ 4. 
Then An => Bn, but not Bn => An. Taking n = - 1, we see a case in which 
Bn holds but An does not hold, thus showing that An cannot be a necessary 
condition for Bn. 
If we denote the negation of A by A (so that A is false means A is true; 
and A is true means A is false), then it is useful to note that: proving A => B 
is equivalent to proving the contrapositive B => it. To say that whenever 
A is true, then B must be true, is just to deny that B can be false when A is' 
true; in other words, it is easy to say that whenever B is false then A is false; 
i.e., that B => it. For example, the statement "If I live in Montreal, then I 
live in Canada" has as its contrapositive "If I don't live in Canada, I don't 
live in Montreal." We shall apply this technique in the second half of our 
proof of Theorem 1 below. 
SUFFICIENT CONDITIONS 
We previously mentioned that for the case A=> B, we refer to B as a necessary 
condition for A. In a similar vein, we say that A is a sufficient condition for B. 
This is due to the fact that the truth of A is "sufficient" for us to conclude 

4.2 Proving Theorems 
133 
the truth of B. Since the statement of a necessary condition can take many 
forms, it's quite clear that the same is true for the statement of a sufficient 
condition. In fact, the three forms (1) to (3) given above constitute valid ways 
of saying that A is a sufficient condition for B. To be explicit, we would re-
write statements (4) and (5) to the equivalent forms: 
4'. A sufficient condition for B to be true is that A is true. 
5'. For B to be true, it is sufficient that A is true. 
NECESSARY AND SUFFICIENT CONDITIONS 
We now discuss the most interesting case: That for which not only A ~ B, 
but in which we also have the converse, B ~ A (B implies A) or A <= B (A is 
implied by B). We symbolize this situation by A ~ 
B. In words, we may say: 
1. A is true if and only if B is true. 
2. A necessary and sufficient condition that A be true is that B be true (or 
vice versa). 
If one statement is both a necessary and sufficient condition for another, 
then the statements are equivalent even though they may be worded in 
completely different ways. Often it is more convenient to work with a neces-
sary and sufficient condition of some property rather than directly with the 
original definition. Under this circumstance, we may wish to think of the 
condition as an alternative definition. Even in many definitions themselves, 
authors (including ourselves) will sometimes use the term "if and only if," 
although technically it is somewhat redundant. 
Throughout the book we will either spell out" if and only if," shorten it to 
"iff," or use the symbol ~ when dealing with necessary and sufficient 
conditions. 
Finally, to prove A ~ B (i.e., a necessary and sufficient condition), we 
must actually complete two proofs (the order is irrelevant): We must prove 
both A ~ B and its converse B ~ A. 
For some proofs, once it is demonstrated that A ~ B it is just a matter of 
working backwards to show that B ~ A. Unfortunately, for a substantial 
number of proofs, it is impossible to proceed in this manner, and a .com-
pletely different approach is required. 
We close this section by proving a simple" if and only if" theorem, whose 
proof demonstrates most of the points we have made above. 
1 Theorem. A natural number is a multiple of 3 if! the sum of the digits in its 
decimal representation is a multiple of 3. 
It turns out that the proof of this theorem will be easier if we first prove a 
lemma. A lemma is a result we prove not for its own interest but because it 

134 
4 Switching Circuits, Proofs, and Logic 
helps us prove some theorems. (The German word for lemma is HilJsatz -
HilJ = help and Satz = theorem.) 
2 Lemma. Let <n) denote the decimal representation of the number nE N, 
and let r(n) equal the sum of the digits in <n). Then r(n + 3) differs from r(n) 
by a multiple of3. 
PROOF. We prove the result by exhausting two cases: 
(I) The last digit d of <n) is 0, 1, 2, 3, 4, 5 or 6. In this case we form 
<n + 3) by changing d to d + 3. Thus, r(n + 3) = r(n) + 3, satisfying the 
claim of the lemma. 
(11) 
The last digit d of <n) is 7, 8, or 9. In that case we form <n + 3) 
from the string <n) = dmdm- 1 ... d1d (m ~ 0) of digits by the following rule, 
which exhausts three possible subcases: 
(1) If d1 =I 9, set <n + 3) = dmdm- 1 ... (d1 + l)(d - 7). (If m = 0, this 
rule changes <n) to l(d - 7).) Then r(n + 3) = 1 + r(n) - 7 = r.(n) - 6, 
satisfying the claim of the lemma. 
(2) If <n)=dmdm-l ... dk+2dk+19 ... 9d with dk+l =19 (where 1 ~ 
k ~ m), set <n + 3) = dmdm- 1 ... dk+zCdk+1 + 1)0 ... O(d -7). Then 
r(n + 3) = r(n) - 9k - 6, satisfying the claim of the lemma. 
(3) If <n) = 9 ... 9d, set <n + 3) = 10 ... O(d - 7). Then r(n + 3) = 
r(n) - 9m - 6, satisfying the claim of the lemma. 
Having verified the lemma for all subcases, we have proved it to be true. 0 
With this lemma we have an immediate corollary -
a result which follows 
so easily that it is almost part of the original result: 
3 Corollary. 
[fn = 3m, then r(n) is a multiple of3. 
[fn = 3m + 1, then r(n) is of the form 3k + 1. 
[fn = 3m + 2, then r(n) is of the form 3k + 2. 
PROOF. The proof is by induction on m for each of the three cases. However, 
it is so obvious from the lemma that we do not bother to write it out. 
0 
Finally, we come to the proof of Theorem 1, which uses the corollary just 
given. 
PROOF OF THEOREM 1. 
1. n is a multiple of 3 => r(n) is a multiple of 3. This is immediate from the first 
clause of the corollary to the lemma. 
2. r(n) is a multiple of 3 => n is a multiple of 3. 
We prove this by proving the contrapositive: n is not a multiple of 3 
=> r(n) is not a multiple of 3. But there are only two subcases, n = 3m + 1 

4.2 Proving Theorems 
135 
and n = 3m + 2, and the truth of these two cases is provided by the second 
and third clauses of the corollary to the lemma. 
0 
IMPLICA nON AND WELL-FORMED FORMULAS 
In our discussion of proof techniques in "everyday mathematics," we 
introduced two symbols, => and~: 
A => B says that whenever A is true then B must also be true. 
A ~ B says that A is true if and only if B is true. 
It is clear then that ~, which we call (logical) equivalence is represented 
by the truth table 
p 
q 
p=q 
T 
T 
T 
T 
F 
F 
p if and only if q 
F 
T 
F 
F 
F 
T 
for to say that p ~ 
q is true is to say that p and q have the same truth values. 
(Thus p ~ q = -, (p Et:> q).) The truth table for =>, which we call implication 
or the conditional, is 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
T 
F 
T 
T 
if p then q 
The first two lines are clear: p => q is true for p true only if we also have that 
q is true. The last two lines are a bit more subtle. For p => q to be true, we 
have that "if p is true, then q is true." If p is false, then it does not matter 
whether q is true or false - neither gives us evidence against the claim that the 
truth of p guarantees the truth of q. And _ so we say (F => T) = T and 
(F => F) = T. Note that (writing p as -, p) 
p => q = -, p v q. 
The reason the truth table for (p => q) strikes us as "strange" is that in 
ordinary English we expect some sort of causal connection between the 
antecedent (P) and the consequent (q). For example the following statement 
looks like a "reasonable'" implication 
"If you heat the metal to 200Â°C then the metal will melt" 

136 
4 Switching Circuits. Proofs. and Logic 
whether or not it is true. On the other hand, 
"If Rome is the capital of Italy then the metal will melt" 
feels "strange." But => does not address these subtle interrelations, and 
only offers a truth value for (p => q) when given the truth values of p and q. 
Thus we have the following truth values: 
Proposition 
If 1 + 1 = 2 then Paris is the capital of France 
If 1 + 1 = 2 then Rome is the capital of France 
If 1 + 1 #- 2 then Paris is the capital of France 
If 1 + 1 #- 2 then Rome is the capital of France 
Truth Value 
(T~ T) = T 
(T~F) = F 
(F~ T) = T 
(F~F) = T 
One advantage of the truth table definition of => is that it yields the 
validity of (If A A B is true, then B is true) in all cases: 
A 
B 
A/\B 
(A /\ B) ~ B 
T 
T 
T 
T 
T 
F 
F 
T 
F 
T 
F 
T 
F 
F 
F 
T 
In fact, we might say that this logical requirement forces the truth table 
definition of =>. 
With the truth table definition of p => q, we can recapture <=>, A, and v 
by the formulas (see Exercise 2) 
P A q = -,(p => -,q) 
p v q = -,(-,p A -,q) = -,p => q 
p<=>q = (p => q) A (q => p) = -,Â«P => q) => -,(q => pÂ». 
We also have the identity 
p => q = -, q => -, p. 
This corresponds to our observation that to prove A => B is equivalent to 
proving its contrapositive B => A. 
Note that, since we already know that any Boolean function can be built 
up from A, v and -', the above formulas show that any Boolean function 
can be built up using just => and -,. As an exercise in the inductive definitions 
of Section 2.1, we give (in 4 and 5 below) an explicit inductive definition of 
well-formed formulas built up using => and -', and of how they are interpreted 
to yield truth values. The syntax gives the "grammar" which tells us what 
strings of symbols are we1l1ormed; the semantics tells us what a formula 

4.2 Proving Theorems 
137 
means. For example, the syntax must tell us that (p => ....., q) is well-formed 
but that (p ....., q) is not well-formed; while the semantics tells us that if p is 
interpreted as T and q as F, then (p => ....., q) is interpreted as T. 
4 Syntax of Well-Formed Formulas of Propositional Logic. We fix a set 
f![ = {p, q, r, ... } whose elements are called the propositional letters or 
variables. Then we define the set of well-formed formulas of propositional 
logic with respect to f![ to be the set Prop (f![) defined inductively as follows: 
Each x in f![ belongs to Prop(f![). 
If x and y belong to Prop(f![), then so do .....,x and (x => y). 
Alternatively, we may define the set <Prop wff) of propositional wffs 
(well-formed formulas) by the context-free or BNF grammar: 
<Prop_wff) ::= <Prop_ var) I....., <Prop _ wff) 1 
Â«Prop _ wff) => <Prop _ wffÂ» 
< Prop_ var)::= plqlr ... 
where <Prop-var) denotes the set of propositional variables. Thus we can 
build up (....., x=>....., y) by forming""" x and....., y from x and y, and then 
combining them with =>. But the above rules cannot build up x....., y, for 
example. 
5 Semantics of Well-Formed Formulas ofPropositional Logic. An interpreta-
tion J: f![ --+ {T, F} assigns a truth value J(x) to each propositional variable 
x in f1Â£. We extend J to a map j' :Prop(f1Â£) --+ {T, F} inductively as follows: 
(i) f(x) = J(x) for each x in f![. 
(ii) If j' is already defined for x and y in Prop(f![), then we define j'(....., x) 
and j'Â«x => yÂ» by the truth tables 
.i(x) 
.i(--,x) 
.i(x) 
.i(y) 
.J((x => yÂ» 
T 
F 
T 
T 
T 
F 
T 
T 
F 
F 
F 
T 
T 
F 
F 
T 
Thus, for example, the interpretation of (....., x=>....., y) follows its inductive 
construction, e.g., if j'(x) = T and f(y) = F, then f(.....,x) = F and j'(.....,y) 
= T, and so, finally, j'Â«.....,x => .....,yÂ» = T. 
Two classes of propositional formulas are particularly important because 
of their semantic properties. These classes are the tautologies and the contra-
dictions. A formula is a tautology if it is true under every interpretation. If 
it is false under every interpretation, it is a contradiction. The formula 
(p /\ q => P v q) is a tautology; (p /\ p) is an example of a contradiction. 

138 
4 Switching Circuits, Proofs, and Logic 
As another example of the relationship between syntax and semantics 
let us consider arithmetic expressions. Here we start with a set f!Â£ = {p, 
q, r, ... } of numerical variables. We define the set Exp(f!Â£) of arithmetic 
expressions over f!Â£ inductively by 
(i) Each x in f!Â£ belongs to Exp(f!Â£). 
(ii) If x and y belong to Exp(f!Â£), 
then so do -x, (x + y) and (x * y). 
An interpretation then offers a map f from f!Â£ to some suitable set A, 
and a set of maps (j_: A -+ A, (j+: A x A -+ A and (j*: A x A -+ A. Familiar 
examples take A to be Z (integer), Q (rational numbers), or R (real numbers). 
In these cases, (j_, (j+, (j* are the appropriate numerical minus, addition, 
and multiplication, respectively. 
FORMAL PROOFS IN PROPOSITIONAL LOGIC 
Readers who have studied Euclidean geometry will remember the basic 
idea of a formal proof. We start with axioms and then combine them to 
deduce new statements using rules of inference. 
An axiomatization of propositional logic will provide us with a rigorous 
and formal definition of the concepts of theorem and proof in terms of the 
concepts of axiom and rule of inference. There are different possible axiom 
systems for propositionallogic, each of which suits our purpose here equally 
well. We choose a particularly simple one. 
6 An Axiom System for Propositional Logic 
Axioms: All the axioms are well-formed formulas of one of the three follow-
ing forms: 
1. 
A => (B => A) 
2. 
(A => (B => CÂ» => Â«A => B) => (A => CÂ» 
3. ('(IA) => A) 
where A, B, and C each stands for an arbitrary well-formed formula (wfJ). 
The reader should note that the three axiom schemas are all tautologies, 
i.e., whatever particular wffs may be substituted for A, B, and C, and no 
matter what truth values these wffs may have as interpretation, the overall 
formula has truth value T (see Exercise 1). 
Next, the notion of a rule of inference is that if the premises are tautologies 
(the wffschemas above the line in the rules below), then the wffbelow the line 
must be tautology as well. We have two rules of inference. 

4.2 Proving Theorems 
Rule of Inference 1 : 
Modus Ponens 
A,A~B 
B 
139 
i.e., if wff A and wff A ~ B have already been proved, deduce wff B. 
This is certainly a valid rule of inference, since we know from the truth 
table definition of ~ that when A evaluates to T and A ~ B evaluates to T, 
then B must evaluate to T at the same time, since (T ~ F) = F. 
For the next rule of inference, we need the notion of substitution. A! is the 
wff obtained by replacing every occurrence of the propositional variable p 
in A by the wff B. This substitution can be defined inductively as follows: 
Basis Step: 
p! = B; and q! = q if q is a propositional variable distinct 
from p. 
Induction Step: (lA)! = ,(A!) 
Rule of Inference 2: 
(A ~ C)! = (A! ~ C!). 
Substitution 
A 
AB 
p 
This is clearly valid, since if the wff A is true no matter what truth 
value is assigned to p, then the wff A! obtained by replacing every 
occurrence of the propositional variable p in A by the wff B will 
be true no matter what truth value B might have. 
The notions of proof and theorem may now be defined for axiomatic 
theories in general. A list of wff's A 1> A 2 , â¢â¢â¢ , An is a proof of An if for every 
i ~ neither 
1. Ai is an axiom, or 
2. Ai may be derived from wffs occurring earlier in the list by applying one of 
the rules of inference. 
The well-formed formula An is said to be a theorem if there is a proof of An. 
An axiomatization of propositional logic is sound if it hCÂ¥l the properties 
demonstrated above: Each axiom is a tautology; and the rules of inference 
will produce a tautology as conclusion when given tautologies as premises. 
It is clear, then, that in a sound axiomatization of propositional logic, the 
theorems it produces are verifiable by truth tables. That is, every formally 
derived theorem in the axiom system is a truth table tautology. We have 
shown that axiom system 6 for propositional logic is sound. In fact, 6 is 

140 
4 Switching Circuits, Proofs, and Logic 
also complete, in that every truth table tautology can be formally derived as a 
theorem in it. For a proof of completeness, the reader is referred to a standard 
text on logic. 
As an example of a proof using axiom system 6., we have the following 
proof of the theorem A => A, where A is an arbitrary wff: 
1. (A => (B => CÂ» => Â«A => B) => (A => CÂ» 
by Axiom 2, 
2. (A => (B => AÂ» => Â«A => B) => (A => AÂ» 
by substituting A for C in 0), 
3. A => (B => A) by Axiom 1, 
4. (A => B) => (A => A) by Modus Ponens from (3) and (2), 
5. (A => (B => AÂ» => (A => A) by substituting (B => A) for B in (4). 
6. A => A by Modus Ponens from (3) and (5). 
QUANTIFIERS AND PREDICATE LOGIC 
Mathematical logic starts with the basic formalizations of such propositional 
connectives as AND (/\), OR (v), and NOT (-,) -
which is the subject 
matter of propositionallogic we have just discussed -
but then goes on to 
study predicates. Predicates, as we saw in Section 1.2, are "relations in 
truth value form." Let us recall what this means. An n-ary relation R on a set 
S is a subset of sn, the Cartesian product of n copies of S. For example, we can 
define a ternary (= 3-ary) relation on the natural numbers by saying 
(m, n, r)ER~m = n + r. 
(1) 
The predicate P corresponding to a relation R c sn is just the characteristic 
function of R 
P( 
) = {T if (Sl' ... , sn) E R, 
Sl' ... , Sn 
â¢ 
F 
If(Sl"'" snHR. 
For example, if P corresponds to the R of (*) we have 
P(3, 4, 7) = F, 
P(5, 3, 2) = T, 
P(117, 100, 17) = T, 
etc. 
Notice that P(m, n, r) does not have a truth value by itself, for we have 
not specified numerical values for m, n, and r, but once we choose actual 
numbers for these variables, we get a definite truth value. There exist other 
ways, besides substitution of values, to get a truth value from a predicate. 
Consider, for example, that m + 0 = m for every m in N. We can rephrase 
this using the R of (1), by saying that 
There exists an n in N (namely 0) with the property that for 
every m in N we have P(m, m, n). 
(2) 
Time and again in mathematics we fix some set S as the "universe" in 
which all relations hold and then express the fact that some property holds 

4.2 Proving Theorems 
141 
for every x in S, or that there is at least one x in S for which the property 
holds. We thus have special notations: 
(Vx)P denotes "for all x in the 'universe' under discussion, the predicate 
P is true." 
The symbol V is the A of "All" upside down. (Vx) is called the universal 
quantifier since we assert the truth of P for all x in the universe. 
(3x)P denotes "there exists an x in the 'universe' under discussion for 
which the predicate P is true." 
The symbol 3 is the E of" Exists" back to front. (3x) is called the existential 
quantifier since we assert there exists at least one x for which P is true. 
Using this notation, we see that (2) may be re-expressed in the form 
(3n)(Vm)(m = m + n) 
and we see that this has the truth value T. On the other hand, the statement 
(Vm)(m = m + m) 
has the truth value F over the universe N since 1 =F 1 + 1; while 
(3m)(m = m + m) 
has the truth value T since 0 = 0 + O. 
Note, too, that the order of quantifiers can determine whether a statement 
is true or false. Continuing with universe N, we have: 
(Vm)(3n)(m + n ~ m + m) has truth value T (having chosen m, just 
take n = m), while 
(3n)(Vm)(m + n ~ m + m) has truth value F (having chosen n, note that 
m = n + 1 fails). 
We have seen how to use = and --, to build up the wffs (well-formed 
formulas) in propositional logic. In predicate logic we may use variables 
(such as m and n), function symbols (such as + ) and predicate symbols (such 
as ~), together with the propositional connectives and the quantifiers to 
build up our well-formed formulas. But the treatment of the formal syntax 
and semantics of the predicate calculus, as well as the axiom system, is be-
yond the scope of this book. However, we will give some informal examples 
of the use of predicate calculus. First, here is a rule of inference: 
7 Rule of Inference for Predicate Calculus (V-elimination): 
(Vx)P(x) 
P(a) 
for any individual constant a i.e., if we have as a theorem of our logic that 
"P(x) is true for any value of x" then we should be able to infer that P(a) is a 
theorem, no matter what the particular "element of the universe" a refers to. 

142 
4 Switching Circuits, Proofs, and Logic 
To see this rule in action, let us return to the classical argument: 
8 Example. 
All men are mortal 
Socrates is a man 
... Socrates is mortal 
First, we introduce two predicates: "Man(x)" is to be interpreted as 
"x is a man" while" Mortal(x)" is to be interpreted as "x is mortal." 
(a) 
(b) 
The two premises in 8 can be expressed as 
(\ix)(Man(x) => Mortal(xÂ» 
Man(Socrates ). 
Applying \i-elimination to (a), we infer 
(c) 
Man(Socrates) => Mortal(Socrates). 
Then, applying Modus Ponens to (b) and (c) we obtain the desired con-
clusion: 
(d) 
Mortal(Socrates). 
Here is another example: 
Example. 
Any friend of Martin is a friend of John 
Peter is not John's friend 
... Peter is not Martin's friend 
Here we introduce" F(x, y)" to be interpreted as "x is a friend of y." 
The two premises in 9 can then be formalized as: 
(a) 
(b) 
(\ix)(F(x, Martin) => F(x, JohnÂ» 
IF(Peter, John). 
Applying \i-elimination to (a), we infer 
(c) 
F(Peter, Martin) => F(Peter, John). 
To proceed further, we would invoke (d), which is in fact a theorem of 
propositionallogic: 
(d) 
(A => B) => (,B => lA). 

4.2 Proving Theorems 
143 
After making the appropriate substitutions of F(Peter, Martin) for A 
and F(Peter, John) for B, we may apply Modus Ponens to infer 
(e) 
-,F(Peter, John) => -,F(Peter, Martin). 
We then apply Modus Ponens to (b) and (e) to obtain the conclusion of 
our argument 
(f) 
-,F(Peter, Martin). 
EXERCISES FOR SECTION 4.2 
1. For each of the following wffs, evaluate the truth table to confirm that it is a tautology. 
(i) 
p ~ (q ~ p) 
(ii) (p ~ (q ~ rÂ» ~ ((P ~ q) ~ (p ~ rÂ» 
(iii) (-,(-,p) ~ p). 
2. Use the truth tables to check the equalities 
(i) 
p /\ q = -,(p~ -,q) 
(ii) p v q = -, p ~ q 
(iii) p ~ q = -, q ~ -, P 
(iv) p<=>q = (p~q) /\ (q~p). 
3. Apply the interpretation .J of 5 to evaluate (, (-, p) ~ p) 
(i) when..1(p) = T; and 
(ii) when ..1(p) = F. 
4. Translate into wffs of predicate calculus 
(i) 
Not all birds fly. 
Use B(x) for" x is a bird," F(x) for" x can fly." 
(ii) Anyone who is persistent can learn logic. 
Use P(x) for" x is persistent," L(x) for" x can learn logic." 
(iii) Everyone loves somebody and no one loves everybody. 
Use L(x, y) for "x loves y." 
5. In the following formulas, we consider variables to range over the natural numbers 
N, and give +, *, and ~ their usual interpretations. State the truth value of the 
proposition, or specify what values of the variables wiII make the truth value equal T. 
(i) 
(Vx)(3Y)(X2 + y2 ~ lOO) 
(ii) (3y)(3x)(X2 + y2 ~ 100) 
(iii) (Vx)(x + y = x) 
(iv) (Vx)(3y)(x + y = x) 
(v) (Vy)(Vz)(x * y = x * z). 
6. A propositional calculus formula A is satisfiable if it is true for some interpretation. 
Thus the formula p v q is satisfiable, since, for example, p v q is true when p is true 
and q is false. On the other hand, p /\ P is unsatisfiable. Consider those formulas 
using implication as the only logical connective. Show that every such formula is 
satisfiable. (Hint: prove your result by induction on the number of implication 
symbols in the formula.) 

144 
4 Switching Circuits, Proofs, and Logic 
7. Let < be the binary order relation on the set of all integers, * be multiplication 
between two integers, and + addition between two integers. Determine the truth 
value of each of the following assertions over the universe Z of all integers. 
(i) 
VxVy [x * y == y * x] 
(ii) 
Vx3y [x < y] 
(iii) 
3xVy [x < y] 
(iv) 
VxVy [x < y] 
(v) 
VxVy [(x < y) v (x = y) v (y < x)] 
(vi) 
Vx3y [x * x = y] 
(vii) Vx3y [x = y * y] 
(viii) VxVyVz [x * (y + z) = (x * y) + (x * z)] 
(ix) 
VxVy [(x * x < y * y) => (x < y)] 
(x) 
VxVyVz [(x + z < y + z) => (x < y)] 
8. Give an example of one-place predicates P(x) and Q(Y), where x, YEN, such that 
3xP(x) " 3yQ(y) is true, 
but 
3x[P(x) " Q(x)] is false. 

CHAPTER 5 
Binary Relations, Lattices, and Infinity 
5.1 Equivalence Relations and Partial Orders 
5.2 Lattices and Boolean Algebras 
5.3 An Introduction to Infinity 
5.4 Another Look at Trees 
Section 5.1 introduces the two most popular ftavors of binary relations on a 
set, namely equivalence relations and partial orders. Modular arithmetic 
is seen as a special case of forming equivalence classes, and we see that a 
variety of objects of interest to computer scientists can be related to a partial 
order. Particularly important are those partial orders for which we can 
speak of maxima and minima. We discuss these objects - called lattices - in 
Section 5.2. There we pay particular attention to the Boolean algebras, an 
important class of lattices which include the truth values equipped with the 
operations of disjunction and conjunction, and the set of subsets of a set 
equipped with union and intersection. Then, in Section 5.3, we show that 
some infinities are bigger than others! This may seem irrelevant to computer 
science, but in fact quite the opposite is true -
the technique used in this 
proof, Cantor's diagonal argument, is one of the most important techniques 
in the theory of computability, and can be used to demonstrate that certain 
problems cannot be solved by any computer program. Finally, we conclude 
this chapter with a general, abstract look at trees. Tree structures have shown 
up in a number of important contexts so far in this book, and the treatment 
they are given in Section 5.4 highlights some of the algebraic features these 
structures have in common. 
5.1 Equivalence Relations and Partial Orders 
We saw in Section 1.3 that a relation R: A......,.. B from a set A to a set B could 
be thought of as a subset R of A x B, so that we could then use 
aRb and (a, b) E R 
145 

146 
5 Binary Relations, Lattices, and Infinity 
as two different notations for saying that" a is R-related to b." When a 
relation R holds between elements of the same set, R: A --,.. A, we say that 
such an R is a relation on A. In this section we consider two special kinds of 
relations of this type. 
EQUIVALENCE RELA nONS 
Perhaps the most familiar relationship is equality. If we write ~A for the 
equality relation on A, we have 
1 
~A = {(a, b)la = b} c A x A. 
We draw the graph for ~N in Figure 32 -
we see it is the diagonal. (The 
symbol ~ does not stand for a triangle here. It is the capital letter "delta" -
the Greek D. Thus -
D for diagonal.) 
Incidentally, we recognize from the definition 1 and from Figure 32 
that ~A is the graph (in the sense of Section 1.3) of the identity function on A, 
idA : A ~ A, a 1---+ a. 
Here is another example of a relation on pairs from the same set. We 
say that two integers nand n' are equivalent modulo m if their difference is 
divisible by m, where m is some fixed integer greater than O. 
2 
n"'m n' <=>(n - n') mod m = 0 
i.e., the remainder on dividing n - n' by m is zero. We also write n == n' mod m 
to indicate that (n - n') mod m = 0, so that we may define the relation", m as 
a subset of Z x Z by rewriting 2 in the form 
"'m = {(n, n')ln == n' mod m} c Z x Z. 
We now observe three properties of '" m and ask the reader to note that 
equality enjoys the same three properties. 
1. Each element is related to itself (we say the relation is reflexive): n - n = 0 
so certainly n '" m n for each n in N. 
2. If two elements are related, the order does not matter (we say the relation 
is symmetric): 
If (n - n') is divisible by m, then certainly (n' - n) is divisible by m as well. 
Thus n '" m n' implies n' '" m n. 
3. If n is related to n', and n' is related to nil, then n is related to nil (we say 
the relation is transitive because it can make the transition from n to nil 
across the common relative n'): 
n '" m n' means n = n' + km for some integer k. 
n' '" m nil means n' = nil + k'm for some integer k'. 

5.1 Equivalence Relations and Partial Orders 
147 
N 
(0,0) 
N 
Figure 32 The dots on the diagonal show 6 points of the equality relation ~N' 
But then 
n = n' + km = (nil + k'm) + km = nil + (k' + k)m 
and so n ~ 
m nil as was to be shown. 
This leads us to the following general definition, of which LlA and ~ 
m are 
examples: 
3 Definition. We say that a relation == on the set A is an equivalence relation 
if it satisfies the three conditions: 
R (Reflexivity): For every a in A, a == a. 
S (Symmetry): For every a, b in A, a == b implies b == a. 
T(Transitivity): For every a, b, c in A, if a == band b == c then a == c. 
Recall now, Figure 31 of Section 4.1, which we reproduce here as Figure 
33. This shows the map 
nl--+ n mod m 
where Zm = {O, 1, ... , m -
1}. We stress that two integers in Z map to the 
same entry in Zm just in case they are equivalent, and that Z breaks neatly 
into nonoverlapping subsets, one for each equivalence class, i.e., collection 
of elements equivalent under ~ m' The next definition and proposition show 
us that this "partitioning" will be achieved by any equivalence relation. 
4 Definition. Let == be an equivalence relation on the set A. Then for each 
a in A, the equivalence class of a with respect to == 
[a]", = {bJa == b} 
is the set of all elements of A equivalent to a. 

148 
5 Binary Relations, Lattices, and Infinity 
11 
~--II--~T9 
7 
3 
~--II----T 5 
~--I1----r1 
Z 
-1 
~--II--~T - 3 
-5 
-7 
-9 
3 
1 
2 
Figure 33 
The mapping from Z to Zm for the case m = 4. The modulo values appear 
on the bottom ring. Integers are in the same equivalence class just in case they lie on the 
same vertical line. 
5 When the context makes clear which equivalence relation we are consider-
ing we shall use the simple notation [a], rather than [a];:, to denote the 
equivalence class of a with respect to ==. 
5 Proposition. Let == be an equivalence relation on the set A. Then for any 
two elements a and b of A, either [a] and Cb] are disjoint, or they are equal. 
PROOF. Given [a] and [b], eithe. they have no elements in common and so are 
disjoint; or they have at least one element in common. We must show that the 
latter case implies that [a] = Cb]. 
Consider, then, the case in which c belongs to [a] n Cb]. We shall prove 
that we have [a] c Cb]. In other words we must prove that d E [a] = dE Cb]. 
Now cE[a] means a == c; cE[b] means b == c; and dE[a] means a == d. 
But then C == a by symmetry; and then (b == C and C == a) implies b == a by 
transitivity; and then (b == a and a == d) implies b == d by transitivity. 
Thus any d in [a] also belongs to [b], so that [a] c [b]. 
It is now immediate by symmetry that Cb] c [a]. But [a] c Cb] and 
Cb] c [a] together imply that [a] == Cb], and so our proof is complete. 
0 
Let us return to '" 2 on Z and write [n] 2 for [n] _ 2' Two integers nand n' 
belong to the same equivalence class just in case they differ by a multiple of 2. 

5.1 Equivalence Relations and Partial Orders 
149 
Thus 
[0]2 = [-2]2 = [2]2 = ... = [17364]2 
= ... = the set Ze of all even integers, 
[1]2 = [ -1]2 = [3]2 = ... = [2957]2 
= ... = the set Zo of all odd integers. 
Thus there are only two equivalence classes, Ze and Zo, but each of them has 
infinitely many names. We may pick Â° 
and 1 as the typical representatives, 
so that we have 
where we use the notation Z/- 2 to denote the set of equivalence classes of 
Z under - 2' We recognize Z/- 2 as just being a relabele<;l version of Z2 = 
{O, I}. In this light, we may view Figure 33. as showing the map Z ~ Z4 
which sends each integer n to its equivalence class, [n]4, -
simply by replacing 
the labels 0, 1,2 and 3 by [0]4, [1]4, [2]4 and [3]4, respectively, on the Z4 
circle. 
This all leads to the following general definition: 
6 Definition. Given an equivalence relation = on the set A, we define" A 
modulo =" to be the set 
AI= = {[a]", la E A} 
of all equivalence classes of A. (Note that AI= has one element for each 
distinct equivalence class; not one element for each a in A.) The map 
1]",: A ~ AI=, 
a 1---+ [a]", 
which sends each element to its equivalence class is clearly onto, and is 
called the canonical surjection. 
7 Example. Let Z + be the set {n In> Â° and n E Z} of positive integers. 
Define the relation - on Z x Z+ by 
(p, q) - (r, s) ~ ps = rq. 
Then - is an equivalence relation because we have: 
Reflexivity: 
Symmetry: 
Transitivity: 
(p, q) - (p, q) since pq = pq. 
(p, q) - (r, s) => (r, s) - (p, q) since ps = rq => rq = ps. 
(p, q) -
(r, s) and (r, s) - (t, u) => (p, q) -
(t, u) since if ps = 
rq and ru = ts then (pu)s = (ps)u = (rq)u = (ru)q = (ts)q 
= (tq)s. But SE Z+ and so we may cancel it to deduce that 
pu = tq, i.e., (p, q) - (t, u). 

150 
5 Binary Relations, Lattices, and Infinity 
We can thus define the set Z x Z+/ '" of equivalence classes modulo "', 
and discover that it' is just (a relabeled version of) the set Q of rational 
numbers (i.e., fractions). To see this, use the notation 
p -
for [(P, q)] _ . 
q 
Then the definition of '" says that [(p, q)] _ = [(r, s)] _ if and only if 
(p, q) '" (r, s), i.e., if and only if ps = rq. But this just says 
p. = ~ if and only if ps = rq 
q 
s 
which is indeed the familiar definition of equality of rational numbers. 
PARTIAL ORDERS 
We now consider a different kind of relation on a set A, namely a partial 
order. To motivate this, consider the relation ~ of" less than or equal to" 
on the set Z of integers. It has the reflexive property -
certainly n ~ n for 
each integer n. It is also transitive: m ~ nand n ~ p certainly implies m ~ p 
for any three integers m, n, and p. But it is not symmetric: for if m ~ n we 
cannot have n ~ m unless m = n. These three properties taken together 
define a partial order, which we summarize formally below. 
8 Definition. We say that a relation ~ on the set A is a partial order if it 
satisfies the three conditions: 
R (Reflexivity): 
For every a in A, a ~ a. 
A (Antisymmetry): For every a, a' in A, if both a ~ a' and a' ~ a hold, 
then a = a'. 
T (Transitivity): 
For every a, a', a" in A, if both a ~ a' and a' ~ a" 
then a ~ a". 
If ~ is a partial order on A, we call the pair (A, ~) a poset (short for partially 
ordered set). 
In fact, "less than or equal to" is a total order on A, i.e., a partial order 
with the extra property that every pair of elements a, a' of A are related -
either a ~ a' or a' ~ a. However, the next example shows that a partial 
order need not be total (which is why we call it partial !). If ~ is not a total 
order on A, we say two elements a, a' are incomparable (with respect to ~) if 
neither a ~ a' nor a' ~ a. 
9 Example. Given any set S, let 2s be the set of all subsets of S, and let c 
be the usual inclusion relation 
A c B~(SEA implies sEB). 

5.1 Equivalence Relations and Partial Orders 
151 
s 
A 
B 
Figure 34 
A and B are incomparable in (2S , c). 
Then (2S, c) is a poset: it is clearly reflexive, antisymmetric (A c Band 
B c A implies A = B), and transitive (A c Band B c C implies A cC). 
But c is not a total order, since the A and B of the Venn diagram of Figure 
34 are clearly incomparable. 
10 Example. We saw in Section 1.3 that a partial function I: A -+ B is a rule 
which assigns to each a in some subset dom(f) of A, a unique element 
I(a) in B. We thus saw that the graph of such an I is a subset ofAx B with 
the property that if (a, b) and (a, b') belong to that set for the same a, we 
must have b = b'. We can thus define a partial order on the set Pfn(A, B) of 
all partial functions from A to B by 
I::; 9 <:;> graph(f) c graph(g) as subsets ofAx B. 
This says that I ::; 9 iff "whenever I(a) is defined for a particular a in A, 
then g(a) must also be defined with g(a) = I(a)," as shown in Figure 35. 
We say that two partial functions /1 and 12 are disjoint if at most one of 
them is defined at any a in A: dom(f1) n dom(f2) = 0. If /1 and 12 are 
disjoint, we may define their diSjoint sum /1 + 12 by 
graph(f1 + 12) = graph(f1) u graph(f2), the union in 2A x B. 
Figure 35 f ~ g: The entire curve is the graph of g, while the darkened portion is the 
graph off 

152 
5 Binary Relations, Lattices, and Infinity 
Thus 
Note that 
if aEdom(fd 
if a E dom(f2) 
otherwise. 
11 On Pfn(A, B), f ~ g if! there exists a partial function h disjoint from f 
such that g = f + h. 
PROOF. Suppose g = f + h, and f and h are disjoint. Then f ~ g since 
f ~ f + h. For the converse, let f ~ g, so that we must have dom(f) c 
dom(g). Let then h be defined by dom(h) = dom(g) - dom(f) = {alg(a) is 
defined but f(a) is not defined}, and then set 
h(a) = g(a) 
for each a in dom(h). 
Then f and h are disjoint, and g = f + h, as was to be shown. 
o 
The relation ~ and the partial-addition + on Pfn(A, B) play an impor-
tant role in theoretical computer science in providing the formal setting for 
programming language semantics, the mathematical study of computer 
programs. 
Other important examples of ordering are related to the set X* of finite 
strings over the alphabet X. 
12 Definition. We say that w is a prefix of w', and write w ~p w' for w, w' 
in X*, just in case there is a third string w" such that ww" = w'. 
It is clear that ~ p is a partial order that is not total -
for example, 
1011 ~ p 1011010, but the strings 1011 and 1001 are incomparable. 
We can also place a total order on X*, the lexicographic order, which is 
the same as the ordering used in making dictionaries (" lexicon" is another 
word for "dictionary"). First we place a total ordering on X -
just as we 
have to fix the order of the letters in the alphabet before we can order words 
in the dictionary. Now consider how we tell that APPLE precedes APPRE-
CIATE in the dictionary. We remove the longest common prefix and look 
at the first letter of the remaining suffix -
the word comes first whose 
initial letter comes first. But what of APPLE and APPLESAUCE? We 
must conclude that A precedes SAUCE to make the order work. All of this 
seems to be captured in the following definition. 
13 We define the lexicographic ordering ~t on X*, given a total ordering 
~ e on X, as follows, where x, x' EX: 
1. A ~ t w for all w in X* ; 
2. x ~ t x' as strings in X* if x ~ e x' as elements of X. 
3. If w ~ t w' then uwv ~ t uw' Vi for all u, v, and Vi in X*. 

5.1 Equivalence Relations and Partial Orders 
EXERCISES FOR SECTION 5.1 
1. Let L be the collection of all lines in the plane. 
(a) Show that the relation 
tl - t 2 -
t I is parallel to t 2 
is an equivalence relation. 
(b) Is the relation 
t I - t 2 - t 1 is perpendicular to t 2 
an equivalence relation? 
153 
2. Let S be the set of infinite subsets of N, the natural numbers. For A, B in S, say that 
A - B _ A n B is infinite. 
Is this an equivalence relation? 
3. A relation on the set A is a subset of A x A. We may thus write RI C R2 to indicate 
that the subset RI is contained in the subset R2, i.e., that aRla'~aR2a'. Recall the 
definition of composition of relations from Section 1.3, namely that aR2 . Rla'-
there exists a" such that aRia" and a"R2a'. We define the inverse of the relation R 
to be R - I = {(a, a') I a' Ra}. Prove that the relation R on the set A is an equivalence 
relation if and only if it satisfies the three conditions: 
(i) 
AA C R 
(ii) R = R- I 
(iii) RÂ· R c R. 
4. We say a collection of disjoint nonempty subsets of A is a partition of A if the 
union of the sets is A. We know from Proposition 5 that the equivalence classes of 
an equivalence relation on A provide a partition of A. Conversely, let us be given 
any partition of A, i.e., a collection (Ai liE J) of subsets of A such that Ai n Aj = 0 
for i i= j, while U(Ai liE I) = A. Define a relation -
A on A by a - Ab -
a and b 
are in the same Ai' 
(i) Prove that -
A is an equivalence relation. 
(ii) Prove that the equivalence classes of -
A are just the "blocks" Ai of the partition 
(A;li E I). 
5. Suppose x, y, z are strings over some nonempty alphabet X. What familiar binary 
relation P(x, y) does the following expression of predicate logic represent? (Here, 
concat is the concatenation function of Section 2.2) 
P(x, y) _ (3z) (concat(x, z) = y). 
6. Describe informally the meaning of the predicate 
Q(x, y) -
(3z)(concat(z, x) = y) 
where x, y, z are strings. 
7. Let (A, ::;;) be any poset. Define the relation ~ on A by a ~ a' -
a' ::;; a. Prove 
that (A, ~) is also a poset. 

154 
5 Binary Relations, Lattices, and Infinity 
8. Let X* be the set of finite sequences of elements of the set X, including the empty 
sequence A. Show whether or not (X*, :$;) is a poset with respect to the relations 
defined by 
(i) W:$; w' iff l(w) :$; t(w'), where t(w) = length(w). 
(ii) w :$; w' iff there exist strings Wl> W2 in X* such that WI W'W2 = w. 
9. Let F equal the set of all (total) functions from N to N. For f, g E F, say that f - g 
if f and g are equal almost everywhere, i.e., if f(n) = g(n) for all but possibly finitely 
many nE N. Show that - is an equivalence relation. 
10. Recall the definition of R*, for any relation R: A ~ A, from Section 1.3. Prove that 
R* is reflexive and transitive. Moreover, prove that if R c: S: A ~ A, and S is 
transitive and symmetric, then R* c: S. This is why R* is called the reflexive transi-
tive closure of R. 
11. This exercise uses the equivalence relation developed in Exercise 9. We denote the 
equiValence class of f by [f]. Say that [f] :$; [g] if f(n) :$; g(n) for all but finitely 
many n. (This is numerical, not subset, ordering.) 
(a) Show that:$; is a partial order on these equivalent classes. 
(b) Denote by [k] the equivalence class of f(n) = k for all n. Show that there are in-
finitely many distinct elements [fl], [f2], ... , [f,J, ... , such that 
12. Let T be a binary tree and define a binary relation, Left, on pairs of nodes of T as 
follows: 
Left(x, y) -= x and y have a common ancestor z such that 
x is on the left subtree dominated by z and 
y is on the right subtree dominated by z. 
Show: Left(x, y) and Left (y, w) => Left(x, w). 
13. Let (at> a2, ... , an) be a sequence of all n elements in a finite set A. Suppose R is a 
partial order on A. We say that (aI' a2, ... , an) is a topological sorting of A relative 
to Riff for all ai' aj E A, (ai' a) E R implies i < j. 
(a) Show that if R is a partial order on a finite set A, then there are elements x, 
YEA such that for no z E A is it the case that (z, x) E R and (y, z) E R. (Such 
elements x and y are respectively called minimol and maximal.) 
(b) Show that if R is a partial order on a finite set A, then A can be topologically 
sorted relative to R. (Hint: set al equal to some minimal element, throw that 
element out of the partial order, and apply the algorithm again.) 

5.2 Lattices and Boolean Algebras 
155 
5.2 Lattices and Boolean Algebras 
We now look at po sets (A, ~) which have extra properties of interest in 
theoretical computer science. 
First consider (2s, c), the poset of subsets of S ordered under inclusion. 
Given any family (Ai lie I) of sets -
whether I is finite or infinite -
we may 
define the union and intersection 
Au = U (Adi e I) = {ala e Ai for at least one i e I} 
A("\ = n(AdieI) = {alaeAiforeveryieI}. 
We clearly have Ai c Au for every i in I -
so we say that Au is an upper 
bound for (Ai lie 1). Now suppose that the subset B of S is also an upper bound 
-
Ai c B for each i. Then 
a e Ai for at least one i => a e B 
and thus Au c B. In other words, in the inclusion ordering Au is less than or 
equal to any other upper bound of (Ai lie I). We say Au is the least upper 
bound. 
1 Definition. Let (A, ~) be a poset. Let (ai lie I) be a family of elements of A. 
We say that b is an upper bound for this family if ai ~ b for every i e I. We 
say that b is the least upper bound (lub) for the family if b ~ b' for every 
upper bound b' for (ai lie I); we denote the least upper bound V (ai lie I). If 
I has only two elements, we write al v a2 (read: al join a2) for V (al' a2)' 
We can speak of the least upper bound because it is indeed unique. For 
if band b' are both least upper bounds we must have 
b ~ b' because b is least; and 
b' ~ b because b' is a least upper bound of the family, 
and so b = b' by the antisymmetry of ~. 
Note immediately that the property of (2S , c) that every family has a 
least upper bound V (Ai lie I) = U (Ai lie I) is very special. 
2 Example. Consider (N, ~), the natural numbers ordered by the predicate 
~. Clearly any finite sequence of numbers (nl' n2"'" nk) has a least upper 
bound,namelytheirmaximum: V (nl' n2"'" nk) = max(nl' n2"'" nk)' For 
example V (3, 4) = 4, and V (2, 1, 3, 1, 16, 4) = 16. 
However, an infinite family of numbers will not have an upper bound 
(unless there are only finitely many different numbers, but with some repeated 
infinitely often). For example consider the sequence 
(0,2,4,6, ... , 2n, ... ) 

156 
5 Binary Relations, Lattices, and Infinity 
of all even numbers. Clearly there is no single number m such that 2n ~ m 
for every n. 
3 Example. We may represent many examples of posets (A, ~) by Hesse 
diagrams such as the two examples shown below. In each case, the nodes 
represent the elements of A, while the relation is defined by saying that 
a ~ a' just in case a = a' or there is a path from a to a' which goes entirely in 
the upward direction. This relation is clearly reflexive, antisymmetric (if two 
upward paths in sequence return us to the starting point, they must both 
have zero length) and transitive. 
(tl) 
e 
(13) 
n 
d 
k 
m 
b 
c 
g 
h 
a 
f 
The reader can quickly see that every set of elements in the left-hand poset 
has a least upper bound -
for example, V (b, c) = d and V (c, d) = d 
and V (a, b, e) = e. However, this property fails for the right-hand poset. 
Just consider the family (g, h) of two elements. Clearly k and m are both 
upper bounds of g and h which are "as small as possible" but it is not true 
either that k ~ m or that m ~ k, and so there is no least upper bound of 
(g, h) in the sense of Definition 1. 
Now, returning to (2"", c), we see that just as U (Ai liE 1) is the least 
upper bound for the family (Ai liE J), so is n (Ai liE J) for greatest lower 
bound in the sense of the next definition. 
4 Definition. Let (A, ~) be a poset. Let (ai liE J) be a family of elements of 
A. We say that b is a lower bound for this family if b ~ ai for every i E 1. We 
say that b is the greatest lower bound (gib) for the family if b' ~ b for every 
lower bound b' for (ad i ~ J). We denote the greatest lower bound by 
/\ (ad i E J). If J has only two elements, we write al /\ a2 (read: al meet a2) 
for /\ (aI' a2)' 
Thus /\ (Ai liE J) = n (Ad i E J) in (2S, c). 
For (N, ~) we have 
/\(n l , n2,"" nk) = min(n l , n2, ... , nk), 

5.2 Lattices and Boolean Algebras 
157 
the smallest integer in the collection. What about infinite collections in N? 
They also have greatest lower bounds! This is because N is bounded below 
by 0, and so even infinite collections in N must have a smallest number :2: O. 
(What about (Z, ~)?) 
In the Hesse diagrams of Example 3 we see that /\ is well-defined for the 
poset (a), but k /\ m is not well-defined in poset (fJ). 
The possession of greatest lower bounds and least upper bounds is so 
important that posets which possess them are given a special name: 
5 Definition. A lattice is a poset with the property that every pair of elements 
of A has both a greatest lower bound and a least upper bound. A complete 
lattice is a poset with the property that every set of elements of A has both a 
greatest lower bound and a least upper bound. 
Thus (25, c) is a complete lattice for every set S; (N, ~) and (a) are lattices, 
while (fJ) is not an example of a lattice. 
The reader may note that the definition of a lattice only specified the 
behavior of pairs of elements. In fact, these properties give us the desired 
properties for any finite set of elements. 
6 Proposition. Let (A, ~) be a lattice. Then every finite non empty set 
(ab a2'.Â·Â·, an) of elements of A has both a least upper bound and greatest 
lower bound given, respectively, for n :2: 2 by 
V (ab a2' ... , an) = Â« ... Â«a1 V a2) V a3) ... an-I) van) 
1\ (ab a2' ... , an) = Â« ... Â«a1 /\ a2) /\ a3) ... an-I) /\ an)Â· 
PROOF. Note that if n = 1, V (a 1) = a1 and 1\ (a1) = a1 so that every poset 
trivially has lub's and gib's for one-element subsets. We now turn to the 
V-formula for n > 2. The I\-formula proof is just the same. 
Basis Step: For n = 2, V (aI, a2) = a1 V a2 by definition. 
Induction Step: 
Forn > 2,supposethatV(ab ... ,an) = Â« ... Â«a1 V a2) 
V a3) ... an-I) van). We must prove that V (aI' ... , an, an+ 1) does exist, 
and is defined by (V(a1' ... , anÂ» V an+ 1, and we are done. 
Let us then set c = (V(a1' ... , anÂ» V an+ 1. Clearly, by definition, 
V(a1' ... , an) ~ c -
and thus each ai ~ c for 1 ~ i ~ n -
and an+ 1 ~ c, 
and so c is an upper bound for (aI, ... , an+ 1). Now suppose that d is also an 
upper bound for (a1, ... , an+ 1). Then ai ~ d for 1 ~ i ~ n, and so 
V(a1' ... , an) ~ d. But also an+ 1 ~ d, and so 
c = (V(a 1, ... , an) V an+1) ~ d 
and c is the least upper bound for (aI, ... , an+ 1). 
D 
We often use the notation (A, v, /\) for a lattice which emphasizes the 
lattice operations join, v, and meet, /\. This is okay since we can in fact 

158 
5 Binary Relations, Lattices, and Infinity 
regain the partial order =:; from either lattice operation. The proof is easy, 
and is left to the reader. 
7 Lemma. Let (A, =:;) be a lattice. Then 
1. a =:; b if! a = a /\ b. 
2. a =:; b if!b = a v b. 
o 
We thus write (2s, u, n) and (N, max, min) for our two main examples of 
a lattice. Here is another interesting example. 
8 Example. Let Boolean be the set {F, T} of truth values, with the ordering 
=:; given by T =:; T, F =:; F, F =:; T. Then (Boolean, =:;) is indeed a lattice. 
Using Lemma 7, we see that the join and meet are given by the tables 
p 
T 
T 
F 
F 
q 
T 
F 
T 
F 
p v q 
P /\ q 
T 
T 
T 
F 
T 
F 
F 
F 
and we recognize that the join p v q is indeed the inclusive-or, p OR q, and 
that the meet p /\ q is indeed the conjunction, p AND q. 
Actually, (Boolean, v, /\) is the same example as (2s, u, n) for the one-
element set S = {I}. To see this, consider the bijection f: Boolean --+ 2{t) 
withf(T) = {1},j(F) = 0. Then it is easy to see that v in Boolean is the 
same as u in 2{l), e.g., 
f(T v F) = f(T) u f(F) 
since 
f(T v F) = f(T) = {I} 
and f(T) u f(F) = {I} u 0 = {I}. 
Again, /\ in Boolean is the same as n in 2{l), e.g., 
f(T /\ F) = f(T) n f(F) 
since 
f(T /\ F) = f(F) = 0 
and f(T) nf(F) = {I} n 0 = 0. 
9 Definition. We say the element T of a poset (A, =:;) is maximal if a =:; T 
for every a in A, i.e., if T = V (a I a E A); and that element -L is minimal if 
-L =:; a for every a in A, i.e., if -L = 1\ (a I a EA). 
Thus T (read: "top") and -L (which is T upside down; read: bottom) 
are unique if they exist. In (2S, c) we have T = S, and -L = 0. In (N, =:;) 
we have no T, but -L = O. In (Boolean, =:;), we have -L = F, and T = T 
(corresponding to -L = 0, and T = {I} in (2{l), c)). 

5.2 Lattices and Boolean Algebras 
159 
We have shown that the 1\ and V of propositionallogic may be modeled 
by the U and n of set theory. To model negation, we next recall the notion of 
set complement. For subsets of S we have 
A = S - A = {alaeS and 
a~A}. 
In the case of the one-element set S = {I}, this becomes 0 = {I} and 
{I} = 0, which corresponds exactly to negation pH pin Boolean: F = T 
and T= F. 
We have the obvious properties 
A n A = 0 
and A u A = S 
in 2s, which reduce to 
p " p = F and p v p = T 
in Boolean on equating Fwith 0 and T with {I}. This leads to the definition: 
10 Definition. We say that a lattice (A, v, ,,) is complemented if it has a 
minimal element .1, a maximal element T, and a map A -+ A, a H ii (we 
call a the complement of a) such that a " ii = .1 and a v a = T for every a 
inA. 
We close by recalling another property of u and n that was spelled out 
in the Exercises for Section 1.1, the so-called distributive laws 
A n (B u C) = (A n B) u (A n C) 
A u (B n C) = (A u B) n (A u C). 
These reduce to the logical equalities 
p " (q v r) = (p " q) v (p " r) 
p v (q " r) = (p v q) " (p v r). 
11 Definition. We say that a lattice (A, v, ,,) is distributive if it satisfies the 
distributive laws 
a " (b v c) = (a " b) v (a " c) 
a v (b " c) = (a v b) " (a v c). 
We may summarize all these observations by saying that each (2s, u, n), 
and so in particular (Boolean, v, ,,), is a Boolean algebra, where: 
12 Definition. A Boolean alg.ebra is a complemented distributive lattice, i.e., 
a lattice (A, v, ,,) with the properties: 
1. There is a minimal element .1 and a maximal element T with respect to 
which every element a in A has a complement a, i.e., ii has the property 
that a " ii = .1 and a v ii = T. 

160 
5 Binary Relations, Lattices, and Infinity 
2 The distributive laws hold: 
a /\ (b v c) = (a /\ b) v (a /\ c) 
a v (b /\ c) = (a v b) /\ (a v c). 
It is an amazing fact (due to the American mathematician, Marshall 
Stone) that every finite Boolean algebra is isomorphic to (2S, U, n) for some 
finite set S. By this, we mean that if (A, v, /\) is a Boolean algebra for which 
A is a finite set, then there is a bijection f: A -+ 2s for some set S which satisfies 
the property that 
f(a v b) = f(a) U f(b) and f(a /\ b) = f(a) n f(b), 
just as we saw that the map T f-+ {I}, F f-+ 0 does for that most fundamental 
of all Boolean algebras, namely (Boolean, /\, v). Since the proof of the 
general result takes about five pages, we do not give it here. 
EXERCISES FOR SECTION 5.2 
1. Show that Definition 5.1.13 makes lexicographic ordering a total order on X*. 
2. Prove that (X*, :::; p) has greatest lower bounds for any pair of elements. Does it 
have least upper bounds? 
3. Write out the A-formula proof for Proposition 6. 
4. Prove Lemma 7. 
5. Verify that under the bijection f(T) = {I}, f(F) = 0 of Example 8 we do indeed 
have 
f(a v b) = f(a) u f(b) 
f(a /\ b) = f(a) n f(b) 
for all choices of truth values for a and b. 
6. Let (A, ~) be obtained from (A, :::;) as in Exercise 5.1.7. Prove that b is a (greatest) 
lower bound for (ad i E 1) in (A, :::;) just in case b is a (least) upper bound for 
(ad i E /) in (A, ~). 
7. Let a ...... a, a ...... a be two complement operations with respect to which (A, v, /\) 
is a Boolean algebra. Prove that a = a for every a in A. 
5.3 An Introduction to Infinity 
Let fi' be the collection of all finite sets. Let us write A ;;; B to denote that 
two finite sets A and B are isomorphic, i.e., there exists a map f: A -+ B with 
inverse g: B -+ A, so that g. f = idA and fÂ· g = idB â¢ We saw in Section 1.3 
that A ;;; B iff A and B have the same number of elements, 1 AI = 1 B I. Thus 

5.3 An Introduction to Infinity 
161 
isomorphism of finite sets is an equivalence relation, simply by making use 
of the fact that equality is an equivalence relation on the natural numbers: 
Reflexivity: I A I = I A I for every finite set A. 
Symmetry: If I A I = I B I then certainly I B I = I A IÂ· 
Transitivity: IflAI = IBI and IBI = ICI then IAI = ICI. 
Now in this section, we want to talk about infinite sets. Here, we do not 
yet know how to talk about the number of elements in an infinite set, except 
to say that it is "infinite." But is there one infinite number, or two, or as many 
infinite numbers as there are different infinite sets? Our answer to the question 
was given by Georg Cantor (1845-1918), who was born in St. Petersburg, 
Russia, but from 1856 on lived in Germany. Two finite sets are isomorphic 
if and only if they have the same number of elements. Thus, given two sets 
A and B, at least one of which is infinite, Cantor defines them to have the same 
number of elements iff they are isomorphic. Let us start following Cantor's 
approach to infinity by showing that isomorphism is an equivalence relation 
even for infinite sets. In what follows, we fix some collection o/J of sets (the 
"Universe"), which includes all the finite and infinite sets we need to talk 
about. 
1 Lemma. Isomorphism, A ;;:; B, is an equivalence relation on 0/1. 
PROOF. 
(i) Reflexivity: id A: A -+ A is an isomorphism, so each set A is isomorphic 
to itself. 
(ii) 
Symmetry: If f: A -+ B is an isomorphism with inverse g: B -+ A, 
then g: B -+ A is an isomorphism with inverse f: A -+ B. Thus A ;;:; B implies 
B;;:;A. 
(iii) Transitivity: Suppose f: A -+ B has inverse g: B -+ A, and h: B -+ C 
has inverse k: C -+ B. Ab: B J!:Â± C. Then hÂ· f: A -+ C has inverse g . k: C -+ A 
9 
k 
since 
(hÂ· f) . (g . k) = hÂ· idB Â· k = h . k = idc 
and 
(g. k) . (hÂ· f) = g . idB â¢ f = g . f = idA 
Thus if A ;;:; Band B ;;:; C, then A ;;:; C. 
o 
We can thus follow Cantor in making the definition: 
2 Definition. We say that two sets A and B in o/J have the same cardinality 
if A ;;:; B. If we write I A I for the equivalence class of A under isomorphism, 
we may write I A I = I B I to show that A and B have the same cardinality. We 
call each;;:; -equivalence class a cardinal number, and call the cardinal number 
I A I the cardinality of A. 

162 
5 Binary Relations, Lattices, and Infinity 
It will cause no trouble to use this notation for finite sets, so that we can 
think of I A I as being either the integer n, when we wish to count the elements 
of A, or as the equivalence class of A under isomorphism.1 
3 Notation. We use the notation t{o (read: aleph-null- aleph is the letter A 
of the Hebrew alphabet) for the cardinality of the natural numbers: 
t{o = 1NlÂ· 
Our next three examples provide surprises -
namely that there are sets 
much smaller and larger than N which still have cardinality t{o. These 
examples may tempt us to believe that every infinite set has cardinality t{o, 
but we shall see that this is not true. 
4 Example. Since every positive integer can be paired with a negative integer, 
we can write down an equation like 
s 
I Z I + 1 = 2 x t{o 
(we have to add 1 to I Z I because" doubling" N makes us add a new element, 
- 0 to Z). This might make us expect that I Z I, being" almost twice as big" as 
t{o, cannot equal t{o. But, in fact, I Z I = t{o because the map 
N-Z, 
{ 2nl-+ n 
2n + 11-+ -(n + 1) 
is clearly an isomorphism with inverse 
Z-N, 
{ n>OI-+2n 
n < OI-+2(-n) -
1. 
(The reader interested in the" infinite arithmetic" of S should work through 
Exercises 2 and 4 to prove that t{o + 1 = t{o = 2 x t{o. It is this type of 
strange property that makes infinite numbers so very different from finite 
numbers.) 
6 Example. The set of all prime numbers seems much smaller than N. Yet 
the isomorphism n f-+ the nth prime number shows that it has cardinality 
t{o, taking 2 as the Oth prime. 
1 Indeed some logicians define the natural number n to be the equivalence class of all sets 
isomorphic to {O, 1, ... , n - I} - getting the inductive definition going by definingOto be 101, 
the equivalence class of the empty set. But the reader who finds this confusing -
and even good 
mathematicians have problems the first time they see this! -
should "forget about it," because 
we can just use 1 AI" either way" for finite sets to achieve the task of this section, which is to shed 
light on "counting" infinite sets. 

5.3 An Introduction to Infinity 
163 
7 Example. The set of all pairs of natural numbers N x N satisfies the 
equation 
I N x NI = ~o x ~o = ~&. 
But we shall see that ~& = ~o, again contradicting our intuition from finite 
numbers, where n2 :1= n unless n equals Â° or 1. To provide the necessary 
isomorphism N ~ N x N, we arrange the elements of N x N in a table with 
(i,j) in row i and columnj. 
diagonal Â° diagonal 1 diagonal 2 diagonal 3 diagonal 4 
row Â° (0, O)~o, I)~O, 2)~0, 3)~0, 4)/ .. . 
rOW1~0)~1)~2)~3)~4) 
.. . 
rOW2~O)~1)~2)~3) 
(2,4) 
rOW3~0)~1)~2) 
(3,3) 
(3,4) 
row4<0)~1) 
(4,2) 
(4,3) 
(4,4) 
~ 
: 
column 0 column 1 column 2 column 3 column 4 
We see that we can count the elements of N x N in the order 
(0,0), (0, 1), (1,0), (0,2), (1, 1), (2,0), (0,3), (1,2), ... 
by moving down the diagonals in turn. Let us use (i, j) to denote the position 
that (i,j) takes in this sequence. Thus 
N x N --+ N, 
(i,j) H (i,j) 
is a bijection, and we have (0,0) = 0, (0, I) = 1, (1,0) = 2, etc. Let us 
see how to write down an explicit formula for (i,j). We first note that (i,j) 
occurs in diagonal i + j, and is in fact in position i (row i) in that diagonal. 
For example, (1, 3) is the I-position (row I) in diagonal 4. Thus 
(i, j) = (the sum of the lengths of diagonals preceding the (i + j)th) + i 
= [1 + 2 + ... + (i + j)] + i 
(i + j)(i + j + 1) 
. 
= 
2 
+ l. 
8 Definition. We say a set A is denumerable if IAI = ~o. An enumeration 
of A is an isomorphismf: N --+ A. If we write an for f(n), an enumeration is a 
sequence 

164 
5 Binary Relations, Lattices, and Infinity 
which lists A without repetitions, and with one element an for each natural 
number n. 
The method used in constructing the enumeration of N x N can be 
formalized in the following lemma, which can be a useful tool for organizing 
the demonstration that a given infinite set is denumerable. 
9 Lemma. Let A be such that there is an infinite sequence of disjoint nonempty 
sets (An In;::: 0) whose union is A. If each An is finite, then A is denumerable. 
PROOF. Since An is finite it has some finite number mn, say, of elements and 
so its elements can be written in order as anl, an2, ... , anmn. But then 
is an enumeration of A. 
o 
In the case of N x N, the corresponding An is the nth diagonal n, 
{(i, j) I i + j = n}, and we enumerate the elements of An as 
(0, n), (1, n -
1), (2, n - 2), ... , (n, 0). 
We now show that there is a nondenumerable infinite set, namely the set 
R of all real numbers. The proof technique is called Cantor's Diagonal 
Argument, and it turns out to be more important than the theorem! Many 
important results in mathematics -
including theoretical computer science 
-
are proved using variations of this technique, so it is important that you 
read and re-read the proof to make sure that you understand it fully. [Do 
exercises 5 and 6.J 
10 Theorem. The set R of real numbers is nondenumerable. 
PROOF. We must show that there is no isomorphism N -+ R. Since every 
isomorphism is onto, we can show this by using Cantor's Diagonal Argument 
to prove that there does not exist an onto map f: N -+ R. To see this, let 
f be any map N -+ R, which we display by the table 
f(O) = aoÂ· 
boo 
bOl 
b02 
bon 
f(1) = al' 
blo 
bll 
b12 
bln 
f(2) = a2' 
b20 
b2l 
b22 
b2n 
fen) = an' 
bno 
bnl 
bn2 
bnn 
where each an is an integer while bnm is the (m + 1)st digit after the decimal 
point in the decimal expansion of fen). 

5.3 An Introduction to Infinity 
165 
Cantor's argument is as follows. Consider the diagonal elements as 
shown, and let us systematically change each 0 to 1, and each non-zero digit 
to 0, to form the real number 
- - -
-
-
{O 
if b .. # 0 
b = O. boo bll bn ... bnn â¢ â¢ â¢ 
where b;j = 1 if b:~ = 0: 
Thus b certainly belongs to R but is not in the range f(N) -
because b 
cannot equal f(n) for any n, since the (n + l)st digit of b is bnn which does 
not equal bnn , the (n + l)st digit of f(n). Hence f is not onto. 
But f was any map from N to R, so there is no map 'of N onto R. 
0 
Note that we could add this new element b to the above listing to obtain 
the listing g: N ~ R with 
g(O) = b 
g(l) = f(O) 
g(n) = f(n + 1) 
But this addition of b does not suffice to make 9 onto, for we can apply 
Cantor's argument to the diagonal of 9 to find a real number not in the 
range of 9 -
and so on, again and again ad irifinitum. 
EXERCISES FOR SECTION 5.3 
1. Let nand n' be two cardinal numbers. Define S; by saying that n S; n' just in case 
n = I A I and n' = I A' I implies that there exists a one-to-one map f: A --+ A'. 
(i) Prove that S; is well-defined by checking that if I A I = I B I and I A' I = I B' I 
and f: A --+ A' is one-to-one, then there also exists a one-to-one map g: B --+ B'. 
(ii) Prove that S; is a partial order on the set r1Ii/;:E. of cardinal numbers. 
2. Define addition of cardinal numbers by 
IAI + IA'I = lA + A'I 
where A + A' is the disjoint union of A and A'. Define multiplication of cardinal 
numbers by 
IAI * IA'I = lA x A'I 
where A x A' is the Cartesian product of A and A'. Define exponentiation of cardinal 
numbers by 
IAIIA'I = IAA'I 
where AA' is the mapping set of all functions from A' to A. Prove that each operation 
is well-defined, Le., that if A ;:E. B and A' ;:E. B' then 
(i) 
A + A' ;:E. B + B' 
(ii) A * A x ;:E. B * B' 
(iii) AA' ;:E. BB'. 

166 
5 Binary Relations, Lattices, and Infinity 
3. Show that the definition of subtraction 
IAI- IA'I = lA - A'I 
where A - A' is the set difference {alaEA,a~A'} is not well-defined by con-
structing a counterexample using the sets Z and N. 
4. Let n be any natural number. Prove that 
(i) n * ~o = ~O, and 
(ii) n + ~o = ~o. 
5. Let n be any natural number ~ 2. Prove that 
(i) 
~on = ~o, and 
(ii) nNO #- ~o. 
6. Let G be the set of all nondecreasing functions f: N --> N, i.e., each fin G satisfies 
f(O) $ f(l) $ ... $ fen) $ fen + 1) $ ... 
Prove that G is nondenumerable. [Hint: Modify Cantor's diagonal argument to 
ensure that the function constructed from the diagonal itself belongs to G.] 
7. (i) Let Fn be the set of all maps f: N --> N with the properties that (a) f(k) = 0 
for all k > n; and (b) f(k) $ n for all 0 $ k $ n. How many functions belong 
to Fn? How many belong to Fn - Fn- 1 (for n ~ i)? 
(ii) Let F be the set of all functions f: N --> N with the property that {n If(n) #- O} 
is finite. Prove that F is denumerable. 
8. We have proved in example 7 that IN x NI = ~o.ThesetQofallrationalnumbers 
is isomorphic to {(m, n)lmEZ, ZEN -
{O}}/-
where -
is described in 
Section 4.1. 
(i) 
Prove that IQI $ IN x NIÂ· 
(ii) Prove that 1Nl $ IQI. 
(iii) Deduce that I Q I = ~oÂ· 
10. Determine whether the cardinalities of A and B are equal, in each of the following 
cases: 
(a) A = {n I n is an integer multiple of 5} 
B = {nln is an integer multiple of 1O} 
(b) A = {2n I n is a non-negative integer} 
B = {22"ln is a non-negative integer}. 
11. Show that the cardinality of the set of all polynomials in one variable with integer 
coefficients equals ~o. What if the coefficients may be drawn from Q, the set of all 
rational numbers? 
12. Show that the set of lines in R x R that go through the point (0,0) has the same 
cardinality as R. 
13. Let X be a finite set. What is the cardinality of X*? 

5.4 Another Look at Trees 
167 
5.4 Another Look at Trees 
We introduced the concept of an ordered tree in Section 3.2, having already 
sampled the computer scientist's use of such trees in Section 2.4. We saw, 
for example, that the s-expression (aÂ· b)Â· (aÂ· (bÂ· cÂ» could be represented 
by the tree 
b 
c 
We can also use trees to represent arithmetic expressions 
+ 
2 
6 
represents (3 x 4) + (-(2 x 6Â» 
or expressions (such as those in Section 4.2) in propositionallogic 
v 
p 
q 
represents (p /\ r) v (-,(P /\ qÂ». 
In this section we give a different formalization of what counts as a tree 
structure (from now on all trees will be ordered) and study some of the ways 
in which trees may be labeled and manipulated. 
Perhaps the easiest way to describe a tree is by observing that there is a 
unique node which acts as the root, and then that each other node can be 
reached by a path starting at the root. Consider, for example, the node v 

168 
5 Binary Relations, Lattices, and Infinity 
root 
Figure 36 
of Figure 36. We can specify it by the sequence (1, 2, 1,3) -
take branch 1 
at the root to get v', then take branch 2 at v' to get to v", then take branch 1 (the 
only choice) at v" to get to VIII, and finally take branch 3 from VIII to get to v. 
Clearly, then, we can describe each node in the tree by its address,. namely 
the string of elements of the set P of positive integers describing the branches 
taken en route from the root. In particular, the root corresponds to the 
empty string A. The question now is: When does a subset of P* correspond 
to the addresses of the nodes of a tree? 
Think for a moment of Figure 36 as a family tree showing the women 
descended from the matriarch represented by the root of the tree. A successor 
of a node corresponds to a daughter of the woman represented by that node: 
if a node has address w in P*, its successors are the nodes of the tree with 
addresses wn for some n in P. The relation of v corresponding to the younger 
sister of the women represented at v' translates to v and v' being successors 
of the same node, but with v to the left of v': There is a string w of p* and 
integers m and n with m < n such that the address of v is wm while the address 
of v'is wn. 
Now for Figure 36 to be an acceptable family tree, the following two 
conditions must be met, where we use T for the set of addresses of nodes of 
the tree: 
1. If a woman is in the family tree, she is either the matriarch, or her mother 
must also be included in the tree: 
For each w in T, either w = A or w = w'n with w' in T. 
2. If a woman is in the family tree, then either she is the matriarch, or all 
her younger sisters must also be included in the tree: 
For each w in T, either w = A, or w = w'n with w'm also in T for 
1 ~ m ~ n. 
This motivates the following definition: 
1 Definition. A subset T of p* is called a tree domain if: 
1. AeT. 
2. If wn e T, with w in P* and n in P then wand each wm for 1 ~ m ~ n also 
belong to T. 

5.4 Another Look at Trees 
v", 
~v 
Â· A 
Figure 37 
169 
We will often find~ convenient to use their addresses as the names of the 
vertices of a tree. Using this convention, we say: 
A node is a successor of node w just in case it is wn for some n in P. 
A node w has outdegree n in T -
we write od(w) = n - just in case it has 
n successors, that is wm is in T if and only if 1 ~ m ~ n. 
A node w is terminal, or is a leaf, if od(w) = 0, i.e., if no wm belongs to T 
for any m in P. 
For example, the root of the tree of Figure 36 has 2 successors, while 
od(v") = 1 and od(v"') = 3. There are 7 leaves. 
Now consider the node ve. We may take it as the root of a new tree -
the 
subtree of the original tree which is shown in Figure 37. We call the set of 
addresses of nodes in this subtree the scope of v"'. Note that the address of v in 
Figure 36 is 1213, which is 121 (the address of v'" in Figure 36) followed by 3 
(the address of v in Figure 37). This motivates Definition 2. 
2 Definition. Let T be a tree domain, and v a node in T. We say that the 
scope of v in T is the 
ScopeT(v) = {WIVWE T} 
which is also a tree domain. We say that a tree domain S is a sub tree of T 
just in case it is the scope of some node of S. 
OPERATOR DOMAINS 
With Figure 38, we recall the examples which introduced the section: 
In (a) we may label each node of outdegree 2 with the .; each leaf with an 
atom; and there can be no other nodes or labelings. 
In (b), we may label each node of outdegree 2 with a + or *; each node of 
outdegree 1 with a -; each leaf with an integer; and there can be no other 
nodes or labelings. 
In (c), we may label each node of outdegree 2 with v or /\ ; each node of 
outdegree 1 with a -,; each leaf with a p, q or r, or other propositional 
variable; and there can be no other nodes or labelings. 
What is common in each case, then, is that we have a set of labels, and for 
each label (call it w) we prescribe a natural number (call it v(w) and pro-
nounce it "nu of omega" and call it the" arity" of w) which tells us the out-
degree of the nodes it ma.v label. We call such a collection of labels, each w 

170 
5 Binary Relations, Lattices, and Infinity 
+ 
V 
b 
(aÂ· b)Â· (aÂ· (bÂ· c)) 
(a) 
c 
2 
6 
(3.4) + (-(2.6)) 
(b) 
Figure 38 
p 
q 
(p 1\ r) v (--.(p 1\ q)) 
(c) 
having its own arity v(w), an operator domain. In (b), for example, we con-
sider the set of labels Q = {., +, -} with v(.) = v( + ) = 2 and v( - ) = 1; 
we then refer to the tree in (b) as an Q-tree over Z because it is properly 
labeled with elements of Q, but leaves may also be labeled by elements of Z. 
3 Definition. An operator domain is a pair (Q, v) where Q is a set, and 
v: Q -. N is a map which assigns to each operator label w in Q a natural 
number v(w) called its arity. We refer to Qn = {wlweQ with v(w) = n} as 
the set of n-ary labels. 
Let Q be an arbitrary set (which will typically be N or Z). An Q-tree 
over Q is a pair (T, h) where T is a tree domain and h: T -. Q u Q is a labeling 
function which satisfies the conditions: 
v in Twith od(v) = n > 0 ~ h(v)eQn 
v in Twith od(v) = 0 
~ h(v) e Q o or h(v) e Q. 
We can represent tree structures in a linear notation by writing 
W[t1, ... , tnJ rather than 
w 
A 
Then an Q-tree over Q may be equivalently defined by induction: 
Basis Step: 
Each w in Qo and each q in Q is an Q-tree over Q. 
Induction Step: If t 1, â¢â¢â¢ , tn are Q-trees over q, and v(w) = n, then 
wet 1, ... , tnJ is an Q-tree over Q. 
We use Tg(Q) to denote the set ofQ-trees over Q. 
We shall now see how this inductive definition allows us to evaluate 
trees. The present theory generalizes the notion of interpretation of pro-
positional formulas and arithmetic formulas presented in Section 4.2. The 

5.4 Another Look at Trees 
171 
+(0) 
- (-12) 
2 
6 
Figure 39 
reader may wish to review 4.2.5, 4.2.6 and the ensuing discussion before 
proceeding further. 
We start with the tree of Figure 38b. Since we know how to manipulate 
integers, we can evaluate this tree by starting at the leaves and moving 
rootwards, combining integers with the operators indicated at each node, 
until we achieve the final value at the root. Figure 39 shows the value attained 
as we reach each node during this process. The key point is that we have 
an underlying set Z in which all values lie, and each n-ary operator symbol 
can be interpreted as an n-ary function zn --+ Z 
+ : Z x Z --+ Z, 
(m,n) H m + n 
*: Z x Z --+ Z, 
(m, n) H m * n 
-: Z --+ Z, 
mH-m. 
The notion of n-algebra -
with carrier Q replacing the Z of this particular 
example -
provides the general setting in which we can evaluate n-trees. 
4 Definition. Given an operator domain (n, v), an n-algebra is a pair (Q, <5) 
where Q is a set called the carrier and <5 assigns to each w in nn a map 
<5",: Qn --+ Q. 
We have already seen that (Z, +, *, -) provides an interpretation of 
the n = {+, *, -} with v( +) = v(*) = 2, v( -) = 1. But another interpre-
tation, that is, another n-algebra is available among the structures we have 
studied: (81, <5) where 81 = {T, F}, <5( +) = 1\, <5(*) = v, and <5( -) = I. It 
doesn't matter that conjunction is not really addition -
all that matters is 
that the arities match up correctly. Thus the 81-tree 
+ 
Xl-
evaluates as (T v F) A h T) ~ F. 
T 
F 
T 

172 
5 Binary Relations, Lattices, and Infinity 
5 Definition (Inductive Evaluation of O-trees over Q). Given an operator 
domain (0, v) and an O-algebra (Q, (5), the evaluation by <5 of O-trees over 
Q is the map <5*: T,lQ) ~ Q given as follows: 
Basis Step: The evaluation of q in Q is q; the evaluation of w with 
v(w) = 0 is <5", in Q. (An element of Q corresponds to a map QO ~ Q.) 
Induction Step: If tl, ... , tn have been evaluated as <5*(tI)"'" <5*(tn), 
respectively, and v(w) = n, then the evaluation of W[tl, ... , tnJ is 
<5*(W[tI' ... , tnJ) = <5",[<5*(tI), ... , <5*(tn)]. 
The reader should check to see how this compares with Definition 4.2.5. 
The assignment of a truth value )lex) to each propositional variable x in f!( 
generalizes to the assignment of a value <5", in Q to each w with v(w) = O. 
The truth tables for -, and => may be viewed as maps <5,: !!J ~ !!J, and 
<5~: !!J2 ~ !!J. 
POLISH NOTATION AND LEXICOGRAPHIC ORDER 
Polish notation is named in honor of the Polish logician Lukasiewics 
(" Wukashevitch") who introduced it. Using K for conjunction, A for dis-
junction and N for negation, he coded propositionallogic expressions in the 
fashion shown below. 
1\ 
p 
q 
r 
KApqNr 
p 
v 
p 
AKNpqArKpq 
q 
The rule is as follows: To code a tree W[tl' ... , tnJ first write down the 
code for w, then write down the code for t 1> the code for t 2, etc., and finally 
write the code for tn â¢ For example: 
Codefor (~,) 
~ K (CodefO' p~)(codefO' [') 
p 
q 
r 
= KA (code for p)(code for q)N(code for r) 
= KApqNr 
where each leaf label is coded as itself. 

5.4 Another Look at Trees 
173 
This suggests the following (if we use each label to code itself): 
6 Definition. The Polish (prefix) notation of Q-trees over Q is the map 
P: Tn(Q) ~ (Q u Q)* defined inductively as follows: 
Basis Step: 
For each q in Q, P(q) = q. 
Induction Step: If w is in Qn, and each t 1, â¢â¢â¢ , tn is in Tn(Q), then 
P(w[tt> ... , tnJ) = WP(tl) ... P(tn). 
For example, the Polish notation for 
+ 
3 
2 
2 
is + x + 3 2 2 x 1 - + 1 2. We now tabulate the addresses of the nodes 
in the order in which their labels occur in this expression. 
7 
+ 
2 
A 
2212 
Think of 1 and 2 as letters of an alphabet, with 1 coming before 2. Then 
note that the order of words above is lexicographic order -
words starting 
with 1 occur before words starting with 2; and if v is a prefix of w = vu, the 
v comes before w. (Recall definition 5.1.13.) We close this section by showing 
that Polish notation always corresponds to lexicographic order. The follow-
ing rather formal statement corresponds to the situation of table 7 above. 
8 Observation. Let T be a tree domain whose nodes are (v 1 = A, V2' â¢â¢â¢ , Vk) 
when arranged in lexicographic order. Let t be the Q-tree over Q given by 
the labeling h: T ~ Q u Q of T. Then the Polish notation for t is given by 
the labels of the nodes arranged in lexicographic order. 
PROOF. Basis Step: 1ft = qinQ,then T= {A}andP(t) = q = h(A).Similarly, 
if t = w with v( w) = O. 

174 
5 Binary Relations, Lattices, and Infinity 
Induction Step: Let t = w[t1, ... , tnJ with w in On, n > 0, and each tj in 
Tn(Q). Let tj have tree domain ~ with node addresses (tj1, tj2' ... , tjn) in 
lexicographic order, and assume by way of the inductive hypothesis that 
P(tj) = hitjl)hitj2) ... hitjr). 
Then we see from the picture 
A 
if address is t li within t l' 
then address is 1 t li in t. 
that the tree domain Tfor t = w[t1, ... , tnJ is just 
T = (A, 1t11 , â¢â¢. , 1t1r1, ... , ntn1, ... , ntnrJ 
and that these nodes are in lexicographic order. Moreover, h(A) = w while 
hUt) = hit) for each t in ~. Thus 
pet) = WP(tl)'" P(tn) 
= wh 1(t 11 ) .â¢. h1(tlr) '" hn(tnl)'" hnCtnrJ 
= h(A)h(lt 11 ) â¢.â¢ h(lt1r) '" h(ntnl) .,. h(ntnrn) 
which is precisely the labeling of the nodes of t in lexicographic order. 
D 
EXERCISES FOR SECTION 5.4 
1. We showed that Polish notation for an Q-tree t over Q corresponds to the lexicographic 
ordering of the node addresses of t. Show that Polish notation also corresponds to 
reading the node labels of t when traversed in preorder. (Recall the definition of 
preorder traversal in Section 3.2.) 
2. Establish the proper connections between reverse Polish notation and postorder 
traversal. 

CHAPTER 6 
Graphs, Matrices, and Machines 
6.1 An Invitation to Graph Theory 
6.2 Graphs and Matrices 
6.3 Finite-State Acceptors and Their Graphs 
Graph theory started in 1735 with Euler's proof that no path could lead a 
person over all seven bridges of the Prussian town of K6nigsberg without 
at least one bridge being crossed twice. Our study of Euler's theorem in 
Section 6.1 allows us to introduce such concepts as paths, Euler paths and 
connectedness for graphs. Section 6.2 uses matrices over semi rings to 
characterize the connectivity of graphs. Finally, Section 6.3 applies these 
connectivity matrices to analyze the reachability problem for automata, 
and then returns to a theme initiated in Section 2.3, showing that a language 
is accepted by a finite-state acceptor iff it can be built up from finite sets by a 
finite number of applications of the operations of union, dot, and star. 
6.1 An Invitation to Graph Theory 
ORDERED AND UNORDERED GRAPHS 
The word "graph" is used in two senses in theoretical computer science. 
The first sense - familiar to many readers from analytic geometry or calculus 
-
is that of the graph of a function. As we spelled out in Section 1.3, the 
graph of a function f: A ~ B is the subset 
graph(f) = {(a, b)laEA, b = f(a)} 
ofAx B comprising all pairs related by f. In this section, however, we 
introduce another sense of graph which is even more widely used in 
175 

176 
6 Graphs. Matrices. and Machines 
N 
Figure 40 
theoretical computer science. Before giving the general definition, we discuss 
several examples. 
Consider a town map such as that shown in Figure 40, where arrows 
indicate one-way streets. 
We do not need to keep a detailed record of the shape and geographical 
orientation of each street since we can replace the map by the structure 
shown in Figure 41a. This object is a graph in our new sense. It has one node 
or vertex for each intersection and "town exit" in the original map; and an 
edge joining two nodes for each road joining the corresponding points of 
the original map. Note that the graph only shows the path relations between 
points, not their relative geographical positions. In Figure 41b we show 
(a) 
(b) 
Figure 41 

6.1 An Invitation to Graph Theory 
177 
another graph representing the map of Figure 40 -
but this times the edges 
are directed, and so we have a single edge for each one-way street, and two 
oppositely directed edges for each two-way street. 
The map of the underground/metro/subway in a major city is more like 
the graphs of Figure 41 than the map of Figure 41 -
but on a subway map 
each edge is color coded for a different line, so that the number of edges 
joining two nodes corresponds to the number of different lines which directly 
link corresponding stations one stop apart. 
We may now give the formal definition of a graph in the sense just 
exemplified. 
1 Definition. A directed graph G = (V, E, 00, a,) is specified by providing 
two sets, the set V of vertices (or nodes) and the set E of edges, and two 
functions, the start function 00: E -+ V and the end function a,: E -+ V. 
If oo(e) = Vo and a, (e) = v, we say that edge e joins Vo to v, or runs from 
Vo to v,. 
2 Definition. An undirected graph G = (V, E, a) is specified by providing 
two sets, the set V of vertices (or nodes) and the set E of edges, together 
with a function a which associates an unordered pair of elements (which 
need not be distinct) within each edge. If o(e) = {vo, vd = {v" vo} we 
say that edge e joins Vo to v, (and v, to vo). 
3 Examples 
V={1,2,3} 
E = {el' e2, e3' e4} 
e,~ 
e 
oo(e) 
Â°l(e) 
e,~e, 
el 
1 
e2 
1 
2 
e3 
3 
2 
e4 
2 
3 
e, 
e 
o(e) 
e2 
el 
{I, I} 
e2 
{1,2} 
e3 
{2,3} 
e4 
{2,3} 
Note that e, in the undirected graph is really associated with a one-element 
set {1} = {1, 1}, but we readily interpret this as coding the fact that e, joins 
the vertex 1 to itself (it is a loop). 

178 
6 Graphs, Matrices, and Machines 
THE SEVEN BRIDGES OF KONIGSBERG 
The first interesting result in graph theory (though the subject did not yet 
have that name) was presented by the Swiss mathematician Leonhard 
Euler (1707-1783) to the Russian Academy at St. Petersburg (the modern 
Leningrad) in 1735.2 Consider the map shown in Figure 42, which represents 
an island (A) in the middle of the town of Konigsberg in Prussia (Germany) 
around which flow two branches of the river Pregel. Can a person plan a 
walk in such a way that he will cross each of the seven bridges once and once 
only (and not swim the river)? You should try to find such a path before 
reading on. 
Euler was told that while some denied that such a walk was possible 
and others were unsure, no one believed that such a path did exist. But 
to list all possible sequences of bridge crossings and check that none can 
include all bridges without repetition takes a lot of work. As a mathematician, 
Euler asked if there was some simple criterion which would replace the 
tedious listing of alternatives to answer the following general problem: 
"Given any configuration of a river and the branches into which it may 
divide, as well as any number of bridges, determine whether or not it is possible 
to cross each bridge exactly once." Before giving Euler's answer, and the 
surprisingly simple proof that it is correct, let us rephrase the problem in 
the terminology of modern graph theory. First note that the map of Figure 
42 can be replaced by the undirected graph of Figure 43 which has a node 
for each region of land and an edge for each bridge. 
We can go from A to D directly via edge (bridge) e, or indirectly via C 
along the path cg (c followed by g) or dg (d followed by g). An example of a 
path which crosses all bridges (i.e., involves all the edges) can be written 
cgf bdgea -
but, like all such paths across the bridges of Konigsberg, it 
involves a repetition. 
4 Definition. A path in an unordered graph G = (V, E, 0) is given by a 
sequenceal,a2,Â·'" an of edges to which corresponds a sequence Wo, Wl,Â·Â·., Wn 
of vertices such that each edge ak (1 ~ k ~ n) runs from Wk-l to Wk' We 
say that the path runs from (or connects) Wo to W n â¢ A path is a cycle if Wo 
= W n â¢ We say that a cycle is strict if no vertex (other than wo) occurs twice 
in the sequence. 
In Euler's. honor, we say that a path al, a2, ... , an is an Euler path if it 
includes each edge of G once and only once. (Some authors use the term 
"walk" where we use "path," and then reserve the term path for a walk in 
2 An English translation of this presentation appears in Volume 1 (pp. 573-580) of "The World 
of Mathematics" edited by lames R. Newman (Simon and Schuster, 1956). The paper is quick 
easy reading. Incidentally, "The World of Mathematics" is a delightful collection of essays, 
excerpts, and even humor which is recommended for browsing and dipping into by anyone 
who reads this footnote. 

6.1 An Invitation to Graph Theory 
179 
c 
c 
t;::::: 
B 
b 
Figure 42 The Seven Bridges of Konigsberg 
which no edge occurs more than once, but we do not find this distinction 
useful.) 
Before turning to Euler's argument, we use our knowledge of relations to 
introduce the notion of connectedness of a graph. 
5 Definition. Let the relation R be defined on the set V of vertices of the 
graph G by: 
vRv' iff there exists an edge of G which connects v to v'. 
Then the reflexive transitive closure C = R* of R (see 1.3.20) satisfies the 
condition 
vCv' iff v = v' or there exists a path from v to v'. 
6 Observation. The connectedness relation C for an undirected graph G is an 
equivalence relation. 
PROOF. Exercise 5. 
C 
c 
d 
g 
A 
e 
D 
a 
f 
b 
B 
Figure 43 
Graph of the Seven Bridges of Konigsberg. 

180 
6 Graphs, Matrices, and Machines 
Now recall from 5.1.4 the notion of the equivalence class of an element 
with respect to an equivalence relation. 
7 Definition. The component of a vertex v of an undirected graph G is the 
equivalence class of v with respect to the connectedness relation C. We say 
G is connected if [v] = V for any (and then for each, by 5.1.5) vertex v. 
We say a vertex v is isolated if [v] = {v}, and that a graph is proper if no 
edge is isolated. 
(a) 
(b) 
Figure 44 
The distinct equivalence classes of C are called the components of the graph 
G. Thus a graph is connected iff it has one component. 
The graph of Figure 44 (b) is disconnected, and is obtained from the con-
nected graph of (a) by removing one edge. It has two components. 
Clearly, a proper graph must be connected if it is to have an Euler path. 
But this condition is not enough, since the graph of Figure 43 is connected 
but has no Euler path. 
We now use the terminology of Definition 4 to provide the setting for 
Euler's original argument. Suppose that a graph G has M vertices and N 
edges. Then an Euler path is a sequence aI' a2"'" aN of the N edges in some 
appropriate order without repetition, and thus involves Wo, W I , W2, .â¢â¢ , w" 
a corresponding arrangement of the M vertices (with whatever repetitions 
are necessary). Consider any pair of vertices, say A and B. If the graph G has k 
edges from A to B, then the pair AB (or BA) must occur as some WjWj+1 in 
the sequence exactly k times. Moreover, suppose we can write the vertices 
of G (with repetitions) as a sequence Wo, W I , W2' â¢â¢â¢ , Wn where Wj and Wj+ I 
are adjacent for 0 :s; j < n. Suppose also that in this sequence each pair of 
vertices occurs together just as many times as there are edges joining them. 
Then we can associate distinct edges with each such pair to get an Euler 
path. Figure 45 (which is also taken from Euler's 1735 article) gives an 
example of this construction. 

6.1 An Invitation to Graph Theory 
181 
8 Euler's Theorem. Let G be a proper connected undirected graph. Then G 
has an Euler path if.[ every node is connected by an even number of edges, 
or exactly two nodes are connected by an odd number of edges. 
Before we prove the theorem, note that the condition is not satisfied 
by the seven bridges of Konigsberg (aU4 vertices of Figure 43 are connected 
by an odd number of edges), but is satisfied by the graph of Figure 45 (only 
D and E are connected by an odd number of edges). 
PROOF. Only if: Consider a sequence wo, Wl , .â¢. , Wn of vertices that form a 
path through G. The occurrence of a vertex v as Wo or Wn requires one edge 
(a) 
Cb) 
EaFbBcF dAeF f CgAhCiDkAmEnApBoEID. 
Cc) 
Figure 45 
(a) Euler's map. (b) The corresponding graph. (c) An example of an Euler 
path, with edge labels inserted between the names of the vertices they join. 

182 
6 Graphs. Matrices. and Machines 
connected to v, namely, one with a(e) = {wo, wd or a(e) = {Wn-l, wn} 
respectively. The occurrence of v as Wj for 0 < j < n requires two edges 
connected to v,namely e and e' with a(e) = {Wj-l, wj}anda(e') = {Wj' wj+d. 
Thus for an Euler path, either Wo = Wn and every node is connected by an 
even number of edges, or Wo =1= Wn and there are exactly two vertices con-
nected by an odd number of edges. 
Interestingly, Euler only proved the" only if" half of his theorem. In fact, 
the "if" part is harder to prove, and lets us exercise quite a bit of our termin-
ology of graph theory. 
If: Let G be a proper connected undirected graph for which all nodes are 
connected to an even number of edges (the remaining case is considered in 
Exercise 6.) 
The proof proceeds by constructing a sequence of cycles in G which, when 
taken together, form the desired Euler path. The first cycle, with vertices 
Wo, W1, â¢â¢â¢ , Wn and edge sequence al"'" an is constructed by the following 
inductive argument. 
Basis Step: 
Pick any vertex v, and set Wo = v. 
Induction Step: 
For 0 ~ j < n, assume that Wo, w1, â¢â¢â¢ , Wj' and ab 
... , aj have already been chosen, and that all of al through aj are distinct. 
Let Ej be the set of edges not contained in the set {aI' ... , a). 
If Wj =1= Wo, then only an odd number of edges connected to Wj have 
already occurred in the {a 1, â¢â¢â¢ , aj}, so at least one edge remains in Ej 
which is connected to wj. Let aj+ 1 be such an edge, so that wj+ 1 is the node 
for which aj+ 1 runs from Wj to Wj+ l' Finally, set Ej+ 1 = Ej -
{aj+ d. 
If Wj = Wo, either no edges connected to Wj remain, and the cycle is 
complete, or at least one such edge remains, and the cycle may be further 
extended as above. (End of Construction.) 
Either such a cycle exhausts all edges of the graph and is thus an Euler 
path, or a number of edges remain. For example, in Figure 46 we might 
start at node A, and form the cycle 
AaDcBbA 
and find no edges to proceed further from A. Note, however, that there are 
nodes in the above cycle which still have "spare edges." Pick one such node, 
say B. We then get another cycle: 
BdDhEiCeDgC f B. 
Now use this cycle to replace B in the original cycle, and we get 
AaDcBdDhEiCeDgCfBbA 
which is indeed an Euler path. In the general case we proceed as follows: 
If a cycle is not an Euler path, it must contain at least one vertex connected 
to edges which do not occur in the cycle. This is obvious if all vertices occur 
at least once along the cycle. But if any vertex v does not occur on the cycle, 

6.1 An Invitation to Graph Theory 
183 
a 
b 
Figure 46 
there must be a path from v to any vertex on the cycle (because G is con-
nected), and the desired edge will then be the first edge of that path connected 
to a vertex on the cycle. 
Given a cycle without repeated edges, then, we may extend it by replacing 
a vertex w by a cycle from v back to itself to get a new longer cycle without 
repeated edges. Clearly, we can repeat this process only a finite number of 
times until we have used all the edges of G. The resultant cycle is an Euler 
~h~~ 
D 
MAPS AND FLOWCHARTS 
Figure 47 shows how we may associate an undirected graph with a map 
showing different countries of a region. The undirected graph in Figure 
47b is obtained from the map of Figure 47a by providing a node for every 
different country. An edge joins two nodes just in case there is a stretch of 
border (not just a point) where corresponding countries meet. 
A famous problem in mathematics is the Four-Color Problem. If we look 
at any map and try to color it in such a way that we never give the same 
color to countries with a common border, we sometimes need four colors 
(the reader should check that Figure 47a is an example of a map needing 
four colors) -
but no one had ever found an example of a map needing five 
colors or more. Could there be a map with a zillion countries that did need 
five colors? For more than a century, mathematicians tried to prove that no 
matter how complicated a map might be, four colors would be enough. They 
simplified the problem by noting that the shape of the countries in the map 
did not matter, only which pairs of countries had a common border. They 
could thus simplify the problem to that of placing colors on a graph in such 
a way that no two nodes with a joining edge have the same color. The key to 
restriction was that the graph should be planar -
i.e., that the graph can be 
drawn on a piece of paper in such a way that no edges cross each other. At 
first glance, the graph of Figure 47 looks as if it were not planar -
but we 
see that we can rearrange the nodes as shown in Figure 47c to reveal that the 

184 
6 Graphs, Matrices; and Machines 
(a) 
(b) 
(c) 
Figure 47 
graph really is planar. In fact, the graph of any map must be planar - just 
position the nodes at the center of each country. Incidentally, this example 
shows that a graph is given by node-edge relationships, and not by the layout 
of a picture on a piece of paper -
Figures 47b and 47c are two pictures of the 
same graph. Figure 48 shows a nonplanar graph -
note that it requires 
five colors to color it. Eventually, in 1976, two American mathematicians 
Figure 48 

6.1 An Invitation to Graph Theory 
INPUT 
x ~ 0, y ~ 0 
q:=O 
r:=x 
r:= r - y 
q:=q + 1 
>-,fi,--a_ls_e ~I PRINT I 
r, q 
(a) 
Figure 49 
185 
(b) 
were able to prove, with the help of a computer, that in fact any planar graph 
could be colored using no more than four colors. 
Our final example of a graph is the flowgraph of Figure 1 which we used 
to motivate our discussion of sets and functions. We reproduce it in Figure 
49 with one small change -
the return arrow of the loop goes to the test box 
rather than to the line feeding into it. We see that this flow diagram is itself 
a directed graph with one node for each test or operation box, and with a 
directed edge showing the transfer of control. Every node is labeled, but 
only the edges leaving a test node bear labels. Figure 49b shows an alternative 
way of associating a directed graph with a flow diagram. Here we have an 
edge for each operation, and two edges for each test. All edges are labeled, 
but none of the nodes are. 
EXERCISES FOR SECTION 6.1 
1. The degree of a vertex i in a graph G is the number of edges incident to the vertex, 
and we use di to note this degree. 
(a) If G has n vertices, prove that Ll ,;i,;n di is an even nonnegative integer. 
(b) Show that every graph has an even number of vertices of odd degree. 

186 
6 Graphs, Matrices, and Machines 
2. If G contains at most one edge between any two nodes, what is the length of a shortest 
cycle? What is the maximum possible length of a strict cycle in G if G has n vertices? 
What is the maximum possible number of strict cycles in G? 
3. A graph is called bipartite if its vertices can be partitioned into two sets VI and V2 
such that no two vertices in VI or in V2 are joined by an edge; that is, all edges extend 
"between VI and V2 ," and no edg~ is within VI or within V2 â¢ Show that G is bipartite 
iff each of its cycles is of even length. 
4. Does the following graph have an Euler path? 
5. Show that the connectedness relation C for an undirected graph G is an equivalence 
relation. 
6. Prove the final case of Euler's theorem: if G is a proper connected undirected graph 
for which exactly two nodes are connected to an odd number of edges, then G has an 
Euler path. 
6.2 Graphs and Matrices 
Most readers will be familiar with matrices from their study oflinear algebra. 
In this section, we shall show how to associate a number of different matrices 
with a graph, and then use these matrices to deduce various graph properties. 
But first we recall the basic notions of matrices as used in linear algebra. 
MATRICES 
We saw in Section 1.1 how the plane could be represented as R2 = 
{(X,y)IXER,YER}. More generally, we shall be interested in Rn= 
{(Xl' X2"'" Xn)IXi E R, 1 S is n}, the Cartesian product ofn copies ofR-
these n-tuples may be thought of as the result of n measurements. 

6.2 Graphs and Matrices 
187 
Given positive integers m and n, an m x n matrix A is a collection of 
m * n real numbers aij (1 ::;; i ::;; m, 1 ::;; j ::;; n) arranged in m rows and n 
columns, with the number aij (also written (A)ij or Ai) occurring in row i 
and column j. 
[
all 
a12 
.. , aln 1 
a21 
a22 
... a2n 
A= 
ami 
am2 ... amn 
We may associate with A a map Rn ~ Rm which sends 
where the ith component Yi (1 ::;; i ::;; m) ofAx is defined as the sum 
n 
Yi = I aijXj = ailxl + ai2 x2 + ... + ainxn' 
j= 1 
Given two vectors x and x' in Rn we define their sum x + x' in Rn by 
setting (x + X')i = Xi + x;: 
[
X11 
[X:11 
[Xl + X:11 
X2 
X2 
X2 + X2 
Â· + 
. = 
. 
Â· 
. 
. 
Â· 
. 
. 
Xn 
X~ 
Xn + X~ 
Given a vector x in Rn and a real number r, the scalar multiple rx in Rn 
is defined by setting (rx)i = rXi: 
[X11 
[rX11 
X2 
rX 2 
r 
. 
= 
. 
. 
. 
. 
. 
Xn 
rXn 
1 Definition. A map f: Rn ~ Rm is linear if for every pair x and x' of vectors 
in Rn and pair of real numbers r, r' we have 
f(rx 1- r'x') = rf(x) + r'f(x). 
2 Observation. A map f: Rn ~ Rm is linear if! it is the map of some m x n 
matrix A. 
PROOF. (i) Given an m x n matrix A, we have 
A(rx + r'x') = Lt aij(rx + r'x')j: 1 ::;; i ::;; mJ 

188 
But 
Thus 
6 Graphs. Matrices. and Machines 
n 
n 
L ai/rX + r' x') j = L ai/rX j + r' xi) 
j= 1 
j= 1 
n 
= L (raijXj + r'aijx}) 
j= 1 
n 
n 
= L raijXj + L r'aijXi 
j= 1 
j= 1 
n 
n 
= r L aijXj + r' L aijxi 
j= 1 
j= 1 
= rÂ· (AX)i + r'Â· (AX')i' 
A(rx + r'x') = rÂ· Ax + r'Â· Ax' 
and so the map Rn -+ Rm induced by A is linear. 
(ii) Let 
be the n unit vectors in Rn. 
Then any 
can be written as xlel + X2e2 + ... + Xnen and it is an easy exercise in 
linearity to check that if f: Rn -+ Rm is linear, then 
3 
f(x) = f(Xlel + X2 e2 + ... + Xnen) = xd(el) + x2f(e2) + ... + xnf(en). 
Now each f(e) is a vector in Rm, so there are m real numbers alj' a2j' 
... , amj such that 

6.2 Graphs and Matrices 
189 
But then equation 3 becomes: 
[all] 
[a12] 
laIn] 
a21 
a22 
a2n 
f(x) = Xl 
: 
+ X2 
: 
+ ... + Xn 
: 
amI 
am2 
amn 
[
allXl + a12 x2 + ... + alnxnj 
= a21xl + a22X2: + ... + a2n Xn 
amlXl + am2X2 + ... + amnXn 
which just says that f is the map corresponding to the matrix 
[
all . .. aln ] 
A =. afl 
.. :. afn 
= [f(el) I f(e2) ! ... If(en)]. 
amI 
amn 
o 
Given two m x n matrices A and A' we define their sum to be the m x n 
matrix A + A' with ij component aij + aij. Note that the map of A + A' is 
the sum of the maps of A and A': 
(A + A')x = Ltl(aij + ai)Xj] = Ltl(aijXj + aijX)] 
= Ltl aijxj + jtlaijXj] = Ax + A'X. 
Suppose now that the linear map f: Rn --+ Rm is given by the m x n 
matrix A, and that the linear map g: Rm --+ RP is given by the p x n matrix B. 
Consider the composite map g . f: Rn --+ RP, X f--+ g(f(x)). 
g . f(x) = Bf(x) = [tl bkJ(X)i 11 ::;; k ::;; p] 
= [.f bki (.f aijXj) 11 ::;; k ::;; p] 
.=1 
}=l 
since f(x) = Ax 
reversing the order of 
summation 

190 
6 Graphs, Matrices, and Machines 
Thus B(Ax) = ex where the p x n matrix e is defined by 
m 
Ckj = L bkiaij' 
i= 1 
We write e = BA, and call e the product of B and A (in that order). 
MA TRICES OVER A SEMI RING 
In Section 2.2, we introduced the abstract algebraic notation of a semiring. 
Recall that a semiring is a triple (S, +",0, 1) where 
a. + is a commutative associative operation on S with identity 0: 
a+b=b+a 
for every a, b, c in S. 
(a + b) + c = a + (b + c) 
a+O=a=O+a 
b. . is an associative operation on S with identity 1: 
for every a, b, c in S. 
c. . is distributive over +: 
for every a, b, and c in S. 
(aÂ·b)Â·c = aÂ·(bÂ·c) 
aÂ·1=a=1Â·a 
aÂ·(b + c) = aÂ·b + aÂ·c 
To use matrices in studying graphs, we shall consider matrices whose 
entries come from one of these semirings: 
4 (N, +, Â·,0,1) is the semiring of natural numbers, with + (numerical addi-
tion with identity 0), andÂ· (numerical multiplication with identity 1). 
numbers, Boolean matrices whose entries are 0 or 1, and X*-matrices 
5 {O, 1}, v, 1\,0,1) is the Boolean semiring with v (disjunction with identity 
0), and 1\ (conjunction with identity 1). 
6 (2x', u,', cP, {A}) is the set of strings semiring with u (union with identity 0), 
andÂ· (concatenation with identity {A}). 
In what follows, then, we consider N-matrices whose entries are natural 
numbers, Boolean matrices whose entries are 0 or 1, and X*-matrices 
whose entries are sets of strings on the alphabet X. In each case we use the 

6.2 Graphs and Matrices 
191 
semiring operations to define the matrix operations. In the first case, we use 
the usual addition and multiplication of integers in adding and multiplying 
matrices: 
7 For A and A' being m x n matrices of non-negative integers 
(A + A')ij = (aij + a;). 
For A an m x n, and Bap x m, matrix of non-negative integers 
m 
(BA)kj = L bkiaij. 
i= 1 
For Boolean matrices, we use disjunction (v) for addition, and conjunc-
tion ( /\ ) for multiplication. 
8 A and A' being m x n matrices ofO's and 1's 
(A + A')ij = (aij v a;). 
For A an m x n, and Bap x m, matrix of O's and 1's, 
m 
(BA)kj = V (bki /\ ai) 
i= 1 
the disjunction of m terms, each of which is a conjunction of two terms. 
For X*-matrices, we use union (u) for addition, and concatenation (-) 
for multiplication. 
9 For A and A' being m x n matrices of subsets of X* 
(A + A')ij = (aij u a;) = {WIWEX*, wEaij or wEa;). 
For A an m x n, and Bap x m, matrix of subsets of X*, 
m 
(BA)kj= U (bkiÂ·aij) = {wlw= W1W2EX*withw1Ebki and w2 Eaij 
i= 1 
for the same i, 1 :::; i :::; m}: 
Returning to maps Rn --+ Rm: Recall that the identity map on any set S 
is the map ids: S --+ S which sends each s in S to itself, ids(s) = s. In particular, 
the identity map on Rn is given by the n x n identity matrix 
whose ij entry is 1 if i = j but is otherwise O. 

192 
6 Graphs, Matrices, and Machines 
The identity matrix In has the property that for every n x m matrix A 
and every m x n matrix B 
In fact it is the only matrix with these properties -
if J were another n x n 
identity matrix, we would have IJ = J because I is the identity, and IJ = I 
because J is an identity, implying that I = IJ = J. (See Exercise 1.) 
We now write down the identity matrices for our three new families of 
matrices. (The proof that they are all identity matrices is left to the reader as 
Exercise 1 (ii). Since the readers need only prove one result to get all three 
here, they may get some feel for the advantages of using the general notion of 
a semiring.) 
10 The n x n N-matrix identity is 
whose ij entry is 1 if i = j, but is otherwise O. 
11 The n x n Boolean matrix identity is the In given by 
whose ij entry is 1 if i = j, but is otherwise O. 
12 The n x n X*-matrix identity is the In given by 
whose ij entry is {A}, the set whose only element is the empty string A in 
X*, if i = j; but otherwise it is the empty set 0. To see why this is the identity 
matrix, recall that 0Â· A = 0 and {A}Â· A = A for any A c X*. 

6.2 Graphs and Matrices 
193 
13 Given any n x n matrix A, we define its powers Am for m ~ 0 inductively 
by the formulas: 
A 0 = In, 
the appropriate n x n identity matrix. 
Am+l = Am. A, for each m ~ O. 
Thus Al = In' A = A, A 2 = AI. A = A . A; A 3 = A 2 â¢ A = A . A . A, and 
Am for m > 0 is the product of m copies of A as desired. 
CONNECTION MATRICES OF GRAPHS 
Let G = (V, E, 00 , ( 1) be a directed graph with m vertices, and let us write 
V = {VI' V2"'" vm} for ease of reference. Then we associate three connection 
matrices with G as follows: 
14 The Boolean connection matrix C of G is the m x m array of O's and l's 
such that 
_ {l ifthere is an edge e with oo(e) = Vi' 01(e) = Vj 
cij -
0 if no edge joins Vi to Vj' 
15 The N-connection matrix D of G is the m x m array of natural numbers 
such that 
dij = the number of different edges e in E with oo(e) = Vi and 01(e) = Vj' 
16 The E*-connection matrix K of G is the m x m array of subsets of E* 
such that 
kij = {ele E E with oo(e) = Vi and 01(e) = Vj}' 
17 Example. For the directed graph of Example 6.1.3 
e2 
e,~e, 
el 
we have 
C ~ [~ 
1 n 
D ~ [~ 
1 n 
[le,} 
{e2} 
{~}l 
0 
0 
K= 
0 
0 
1 
1 
0 
{e3} 

194 
6 Graphs. Matrices. and Machines 
The definitions for an undirected graph G = (V, E, 0) are essentially 
the same, except that the phrase "edge e with oo(e) = Vi and 01(e) = v/' 
simply becomes "edge e with o(v) = {Vi' v)" which views the vertices Vi and 
Vj as forming an unordered pair. 
18 Example. For the undirected graph of Example 6.1.3 
we have 
1 0] 
01, 
1 0 
[ 1 1 0] 
D= 1 0 2 , 
020 
Note that for an undirected graph, all these matrices are symmetric -
the ij 
element equals theji element for each pair (i,j). 
In what follows, we shall just develop the theory for directed graphs -
with Example 18 before them, readers should have no trouble extending the 
theory to handle the case of undirected graphs. 
We begin by defining the notion of a path for directed graphs, which 
parallels the notion of path for an undirected graph given in definition 6.1.4. 
19 Definition. A path of length n in the directed graph G = (V, E, 00' (1) 
from vertex Vi to vertex Vj is a string of length n from E* 
with the property that 00(ei) = Vi; (J1(eiJ = OO(eik+) for 1 ~ k ~ n; and 
0l(ei) = Vj. For each vertex v, we regard the empty string A in E* as being a 
path from V to itself. 
We now examine the powers en, Dn, Kn of the connection matrices of our 
directed graph in Example 17. By 13, the 0 powers are the identity matrices: 
[1 0 0] 
eO=OlO, 
001 
[1 0 0] 
DO = 
0 1 0 , 
001 

6.2 Graphs and Matrices 
195 
We quickly see that these matrices describe the length 0 paths - K3 is 
just {A} ifi = j and is otherwise empty, reflecting that we cannot get from 
one node in G to another without traversing at least one edge. D3 is just 
the number of elements in K3; and C3 is 1 if K3 is nonempty while it is 0 
otherwise. 
Now compute the squares of the matrices; C, D, and K: 
To compute C2, remember that we use 1\ for multiplication and v for 
addition: 
[ 1 1 0] [1 1 0] 
[ 1 1 1] 
C2 = 0 0 1 
0 0 1 = 
0 1 o. 
010010 
001 
The reader should check that Cl is 1 if and only if there is a path of length 2 
from Vi to Vj in our graph. 
To compute D2, we use normal numerical multiplication and addition: 
[ 1 1 0] [1 
1 0] 
[1 1 1] 
D2 = 0 0 1 
0 0 1 = 0 1 0 
010010 
001 
and Di] is the number of paths of length 2 from Vi to Vj. 
Finally, we compute K2 and K3 -
where now we use union of subsets of 
E* for addition, and concatenation of these sets for multiplication. 
[ le,) 
{e2} o ne') le,} 0] [{e,e') 
{e1e2} 
{e~4}] 
K2 = 
0 
0 
{e4} 
0 
o 
{e4} = 
0 
{e4e3} 
0 
{e3} o 
0 
{e3} 
0 
0 
0 
{e3e4} 
while 
[{e,e,} {e,e,} {e,e4}] [le') 
{ez} 
{~}] 
K3 = K2 . K = 
0 
{e4e3} 
0 
0 
0 
o 
0 
{e3e4} 
0 
{e3} 
{e1e1e2, e2e4e3} 
o 
{e3e4e3} 
We see that Kl is just the set of length 2 paths from i to j in G; while Kfjis 
just the set of length 3 paths from i to j in G. 
This calls for a general theorem: 
20 Theorem. Let G = (V, E, 00, (1) be a directed graph with E*-connection 
matrix K. Then the ij entry of the nth power of K, for any n ~ 0, is the set of 
all length n paths from Vi to Vi in G. 

196 
6 Graphs, Matrices, and Machines 
PROOF. We proceed by induction on the power n: 
Basis Step: 
K~ = {{A} ifi =j 
IJ 
0 
if i =1= j 
and so is certainly the set of all length 0 paths from Vi to Vj in G. 
Induction Step: 
We verify that truth of the assertion for any n guarantees 
its truth for n + 1: 
Suppose then that n is such that K ke equals the set of all length n paths 
from Vk to Ve , no matter which vertices Vk and Ve of G we consider. Now 
consider a path of length n + 1 from i to j: 
~r-----n-------.~l~ 
It can be split into a length n path followed by a length 1 path. Thus the set 
of length n + 1 paths from Vi to V j 
= UVkEV {those paths from Vi to Vj consisting of a length n path from Vi to 
Vk followed by a length 1 path from Vk to Vj} 
= UVk EV {length n paths from Vi to Vk} . {length 1 path from Vk to Vj} 
= UVk EV K7k' K kj by the induction hypothesis and by the definition of K, 
respectively 
= K7/ 1 by the definition of multiplication of E*-matrices. 
Thus we have completed the induction step, and the theorem follows. 
0 
We can repeat the same proof with minor modifications to deduce that 
21 Theorem. Let G be a directed graph with Boolean connection matrix C and 
N-connection matrix D. Then C7j equals 1 if and only if there is a length n 
path from Vj to V j in G; while D7j equals the number of length n paths from Vj to 
~~a 
0 
We close by making a simple observation about the path structure of 
1 
graphs, and then relate it to computations based on the simplest of the 
connection matrices, namely the Boolean matrix C. 
22 Observation. Let G be a directed graph with m vertices. Then there is a path 
from Vj to Vj if and only if there is such a path of length m - 1 or less. 

6.2 Graphs and Matrices 
197 
PROOF. Obviously~ all we have to prove is that if there is a path from Vi to Vj 
of length greater than or equal to m, there must also be a path of length at 
most m - 1. Now consider a path oflength n ~ m: 
It must visit n + 1 nodes -
Vi and the end, 0l(er), of each edge er for 1 ~ r ~ n 
where el' ... , er> ... , en are the edges that make up the path from Vi to Vj' 
But there are only m different nodes in G so at least one, call it V, must be 
visited twice. 
Thus for some k, 1 ~ k< n, 0l(ek) = 0o(et) = V for k < t. But then 
is also a path from Vi to Vj' Either it is of length < m, or we can repeat the 
loop-removal process. Eventually, then, we reach a path oflength < m which 
runs from Vi to Vj' 
0 
We can capture this in a formula as follows: 
23 Corollary. Let G be a directed graph with m vertices, and let C be its 
Boolean connection matrix. Form the sum of m Boolean matrices 
M = I + C + C2 + ... + cm-I. 
Then there is a path from Vi to Vj in G if and only if Mij = 1. 
PROOF. By Theorem 21, there is a path from Vi to V j of length n just in case 
C7j = 1. Thus 
and so equals 1 if and only if there is a path from Vi to Vj of length n for some 
n with Â° 
~ n :5 m -
1. But this means, by Observation 22, that Mij = 1 if 
and only if there is a path from Vi to Vj of any length. 
0 
24 Example. For the directed graph of Example 17, m = 3 and so 
[1 Â° 0] [1 1 0] [1 1 1] 
[1 
M 
= I + C 
+ C
2 = 0 1 0 + 0 0 1 + Â° 1 0 = 0 
001 
010 
001 
0 
1 1] 
1 1 
1 1 
and Mij does indeed equal 1 if and only if there 'is a path from vertex i to 
vertexj. 

198 
6 Graphs, Matrices, and Machines 
EXERCISES FOR SECTION 6.2 
1. Let (S, +, .) be any semiring. Let S" X" be the set of all n x n matrices with entries 
from S. Denote a typical element of S" X" by (a;). Define addition on S"X" by 
(A + B)ij = Aij + Bij 
and define multiplication on S" X" by 
(A . B)ij = I A;k . Bkj 
k=l 
where the additions and multiplications on the right-hand side use the + and ., 
respectively, of(S, +, .). Show that: 
(i) 
The n x n matrix 0 with Oij = 0 for 1 ::;; i,j ::;; n is an identity for + on S" X". 
(ii) The n x n matrix I with Iij == (ifi = j then 1 else 0) for 1 ::;; i,j ::;; n is an identity 
forÂ· on S"X". 
(iii) (S" X", +,0) is a commutative semigroup. 
(iv) (S"X",., 1) is a semigroup. 
(v) (S"X", +,.) is a semiring. 
2. Given the following directed graph 
1 ~ 
~3 
(a) Compute the C, D, and K matrices for this graph. 
(b) Calculate the M matrix of Corollary 23 for this graph. 
3. Recall the notion of a relation R: A ~ 
A. We may represent it by a Boolean matrix 
M R with rows and columns indexed by A, setting 
{ I 
if aRa' 
(MR)aa' = 
0 ifnot. 
Prove by induction that the nth power of M R is the matrix of the relation R". Deduce 
that 
4. The matrix 
c_(: ~ D 
is the Boolean connection matrix for what graph? Calculate Cl and draw its cor-
responding graph. 

6.3 Finite-State Acceptors and Their Graphs 
199 
6.3 Finite-State Acceptors and Their Graphs 
In Section 2.3 we introduced the notion of a finite-state acceptor, a device 
for accepting sets of strings of symbols from a finite alphabet. Since FSAs 
have an underlying graph structure, our introduction to the formal machinery 
of graph theory earlier in this chapter will provide us with considerable 
insight into the behavior of these primitive machines. In this section, we 
first relate the reachability problem for such automata to the connectivity 
matrices of the last section. We then prove the equality between finite-state 
languages and the so-called regular languages, i.e., those which can be built 
up from finite subsets of X* by a finite number of applications of the union, 
dot, and star operations of Section 2.2. 
GRAPHS AND REACHABILITY 
The dynamics (or state-transition function) of a finite-state acceptor is a map 
15: Q x X -+ Q 
where Q = {qo, ql' ... ' qn} is the set of states and X is the set of inputs. 
An FSA's state graph has Q for its set of nodes, and has one distinct edge 
from qj to qj for each'x in X for which J(qj, x) = qj. 
1 The connection matrix for this state-transition function is then the matrix 
A with 
Aij = {xEXIJ(qj,x) = qj} 
Now recall from Section 2.3 the definition of the reachability function 
15*: Q x X* -+ Q by 
J*(q, A) = q 
J*(q, wx) = J(J*(q, w), x) for each w in X* and x in X. 
2 Definition. We say that qj is reachable from qj with respect to the dynamics 
15 just in case qj = J*(qj, w) for at least one string w in X*. 
3 Example. Consider the state graph 
a 
b 
& 
~ ,\b 

200 
6 Graphs, Matrices, and Machines 
It has the connection matrix (with row and columns indexed 0, 1,2) 
[(b) 
(a) 
{:b)j 
A= 0 
0 
o 
{a} 
{b} 
We then compute 
[ (bb) 
(ba) 
(aa, ab) 1 
A2 = 
o 
{aa,ba} 
{ab, bb} 
. 
o 
{ba} 
{aa, ab, bb} 
We see that the ij entry of A 2 is just the set of paths w of length 2 for which 
b*(q;, w) = qj. 
We then have that 
AO + A + A2 = 
{a, b, ab, bb} 
. 
[
{A'~b' bb} 
{a, ba} 
{A, aa, ba} 
{a,ba} 
{aa, ab} 1 
{A, b, aa, ab, bb} 
Note that qj is reachable from q; just in case the ij entry of A Â° + A + A 2 is 
nonempty. 
In fact, we may apply Theorem 6.2.20 and Corollary 6.2.21 to deduce the 
following result: 
4 Theorem. Let b: Q x X -. Q have connection matrix A. Then the (i, j) 
entry of the nth power of A, for any n ;;:: 0, is the set of all length n paths from 
q; to qj in the state graph of b. 
Moreover, if A has m states, and we form the sum 
B = I + A + A2 + ... + A m- 1 
of X*-matrices, then qj is reachable from q; just in case Bij is nonemptv. 
D 
REGULAR LANGUAGES 
In Section 2.3, we introduced the notion of a finite-state language as being 
the set 
T(M) = {wEX*lb*(qo, w)EF} 
of all strings accepted by some finite-state acceptor M. We suggested that 
such languages were closely related to those that could be built up using 
the union, dot, and star of Section 2.2. 
5 Example. (In what follows, recall that all "missing transitions" lead to a 
single nonaccepting trap state.) 

6.3 Finite-State Acceptors and Their Graphs 
201 
(i) Let M be given by 
1 
-~E 
o 
T(M) = {wl<5*(qo, w) = qd, and we see that the only way to get from 
qo to ql is by applying a 1 to get to ql the first time, and then applying 01 any 
finite number n ~ 0 of times to traverse the loop to qo and back to ql again. 
Thus 
which we simplify to 1(01)*. 
(ii) 
T(M) = {1}Â· {01}* 
Here T(M) = {O, 1}* = ({O} u {1})*, which we may also denote by 
(0 + 1)*. 
(iii) 
T(M) = 00(10)* + 1(0 + 1)*. 
We devote the rest of this section to showing that any finite-state language 
can be represented in this fashion. 
. 
(j Definition. A subset of X* is regular if it can be built up from finite subsets 
of X* by a finite number of applications of u, " and *. We may also define 
the collection 9l(X) of regular sets on the alphabet X inductively as follows: 
Basis Step: 
Each finite subset of X* is in 9l(X). 
Induction Step: If A and B are in 9l(X), then so too are A u B, AÂ· B, 
and A*. 

202 
6 Graphs. Matrices. and Machines 
7 Theorem. Every finite-state language is a regular set. 
PROOF. Given a finite-state acceptor M = (Q, 0, qo, F) with input alphabet 
X, let 
Aqqâ¢ = {wlo*(q, w) = q'} 
be the set of strings which send M from state q to state q'. Then 
T(M) = U AM 
qeF 
so that we have proved our theorem if we can show that each Aqqâ¢ is a regular 
set. To do this, we order the states Q of M as {qo, ql"'" qn-d and then set 
A~q' = those strings which send M from q to q' with only 
{qo, q1>"" qs- d as intervening states. 
Thus the string w = X1X2 ... Xm belongs to A~q' just in case 
o*(q, X1X2 ... x) E {qo, ql' ... , qs- d for 1 ~ j < m 
while o*(q, X1X2 â¢.. xm) = q'. 
We now prove by induction on s, 0 ~ s ~ n, that each A:qâ¢ is a regular 
set - so that Aqq. = A~q' must also be regular for each pair of states q and q'. 
Basis Step: 
For s = 0, the set of "intervening states" must be empty, 
and so 
A~q' = {WIWEX u {A} with o*(q, w) = q'} 
is a finite (possibly empty) set -
and so is certainly regular. 
Induction Step: 
Suppose that we already know that A~jqk is regular for 
some fixed value of s (0 ~ s < n) and for any pair of states qj and qk' We 
now prove that this implies that A~; 1 is also regular. To see this, note 
that a path from q to q' which only goes through intermediate states in 
{qo, ... , qs} either goes only through {qo, ... , qs- d 
~. 
q 
q' 
in which case the corresponding input sequence w is in A~q'; or else the path 
goes through qs at least once 
~. 
qs 
q' 
so that the corresponding w belongs to A~qs . (A~sqJ* . A~sq' . 
Hence if each A~jqk is regular, then so too must be 
A~; 1 = A~q' + A:q â¢ . (A~.qs)* . A~.q" 

6,3 Finite-State Acceptors and Their Graphs 
203 
We have thus proved by induction that each Aqq, = A~q' is regular, and 
hence T(M) = UqeF Aqoq is also regular, 
0 
We have just proved that every finite-state language is a regular set. 
Our goal in the rest of the section is to prove the converse -
that every 
regular set is a finite-state language, Now we already know (2.3.6) that every 
finite set is a finite-state language, So we only have to prove that if A and B 
are both finite-state languages, then so too are A u B, A ' B, and A *, 
8 Example. The language ({a4 } u {a6 })* can be recognized by the FSA 
a 
a 
a 
a 
a 
a 
~GJBJq~ 
a 
But there is a problem! There are two different arcs labeled "a" emanating 
from qo, one leading to the a4 100p, the other leading to the a6 100p, According 
to the definition of c5: Q x X ~ X, such a device is illegal. To permit transi-
tions of the type indicated, c5 would have to be redefined as a map 
c5: Q x X ~ 2Q 
sending a state/symbol pair to a set of states, 
9 Definition. A nondeterministic finite-state acceptor (NDA) M with input 
alphabet X is specified by a quadruple (Q, c5, Qo, F) where 
Q is a finite set of states 
c5: Q x X ~ 2Q assigns to each state/input pair (q, x) a set c5(q, x) c Q of 
possible next states, 
Qo c Q is the set of initial states 
F c Q is the set of accepting states, 
We shall see that an NDA is just like an FSA except that there is a set of 
initial states and a set of possible next states. We can motivate this non-
determinism - the fact that at any stage of process sing there is a set of possible 
states -
by briefly considering the problem of parsing a sentence of English, 
that is, assigning to the sentence its grammatical structure. Consider a 
machine which reads in one word at a time of a sentence, and considers all 
possible analyses consistent with what it has seen before. After reading in 
"The red wood" 

204 
6 Graphs, Matrices, and Machines 
it could be in either of two states 
"determiner adjective adjective"; or 
"determiner adjective noun." 
The first would work if the completion of the sentence were "The red wood 
box is heavy," while the second would work with the sentence "The red wood 
is beautiful" -
but there is no way that either can be completed in a way that 
will let the parsing machine construe "The red wood gracefully" as a gram-
matical English sentence. 
This motivates considering all possible states to which an input string w 
can lead an NDA M from its initial states, and saying w is accepted if there 
is at least one way of getting to an accepting state. 
10 We extend 15: Q x X --+ 2Q to 15*: 2Q x X* --+ 2Q by: 
Basic Step: 
b*(p, A) = {p} for each pc Q. 
Induction Step: 
b*(p, wx) = U {b(q, x)lq E b*(p, w)} for each w in X*, 
x in X,p c Q. 
} O(q, x) 
b*(p, w) 
b*(p, wx) 
We then set 
T(M) = {wlw in X* and b*(Qo, w) n F #- 0}. 
The reader should have little trouble completing the proof of the following: 
11 Proposition. A subset of X* is a finite-state language if and only if it is a 
T(M) for some NDA M. 
PROOF OUTLINE. (I) If L c X* is a finite-state language, it is T(M1) for some 
FSA M1 = (Q1, 151, q1' F1)' We define an NDA M2 = (Q1, 152 , {qd, F1) in 
terms of M1 by setting 15 2 : Q1 x X --+ 2Q ,: (q, X)H {b 1(q, x)}. Then (check 
the details) T(M 1) = T(M 2)' 

6.3 Finite-State Acceptors and Their Graphs 
205 
(ii) If L c X* is T(M) for the NDA M = (Q, {), Qo, F) we may define an 
FSA M' = (Q', {)', q', F') in terms of M by 
Q' = 2Q 
{)'(P, x) = U{{)(q, x)lq E p} for each p in Q' and x in X 
q' = QoEQ' 
F' = {plpnF -=f. 0} c Q'. 
Then (check the details) T(M) = T(M'). 
12 Example. Consider the NDA 
1 
o 
o 
which accepts the language 0*Â·1Â· (0 + 1)* + 0* . 1 . 1 *0Â· (0 + 1)*. The 
two factors in this expression correspond to the two paths from qo to q2. 
The FSA corresponding to this device has 8 states: 
Its start state is {qo}, and its final states are F = {{q2}, {ql, Q2}, {Qo, Q2}, 
{qo, ql' q2}}. Finally, its transition function {) is given by the following chart. 
STATE 
INPUT 
0 
{qo} 
{qo} 
{ql, q2} 
{qd 
{q2} 
{ql} 
{q2} 
{q2} 
{q2} 
{qo, qd 
{qo, q2} 
{ql, q2} 
{qo, q2} 
{qo, ql} 
{ql, q2} 
{ql, q2} 
{q2} 
{ql, q2} 
{qo, ql, q2} 
{qO\ q2} 
{ql, q2} 
To complete our proof that every regular set is a finite-state language, 
we need only prove the following: 

206 
6 Graphs, Matrices, and Machines 
13 Theorem. Let MA and MB be NDAs which accept the sets A = T(MA) and 
B = T(MB) respectively. Then we can define NDAs MAuB, M A.B, and MA. 
which accept A u B, AÂ· Band A*, respectively. 
PROOF. Let 
MA = (QA, bA, QOA, FA) 
MB = (QB, bB, QOB, FB)' 
(i) We set (using + for disjoint union) 
MAuB = (QA + QB, bAuB, QOA + QOB, FA + FB), 
where 
Then 
{ bA(q, x) if q E QA, 
b Auiq, x) = 'B(q, x) 
'f 
Q 
u 
1 q E 
B' 
T(MAuB) = {wlb~uiq, w) n (FA + F B) -=f 0 for q E QOA + QOB} 
= {wlb~(q,w)nFA -=f 0forqEQoA} 
u {Wlb~(q, w) n F B -=f 0 for q E QOB} 
=AuB. 
(ii) AÂ·B: 
x_-__ 1 
â¢ q" E QOB 
x 
The idea of the construction is that M A should continually monitor a string 
w -
but now instead of simply entering an accepting state in F A when an 
initial segment belongs to A, it must also have MB enter its initial states 
QOB (in addition to whatever states it may already be in -
remember that 
MB is nondeterministic), so that it may also check if the remainder of the 
string belongs to B: 

6.3 Finite-State Acceptors and Their Graphs 
where 
(iii) A* 
ifqeA and 0A(q,x)nFA = 0, 
ifqeAandoA(q,x)nFA "# 0, 
ifqeB. 
q" e QOA 
, 
e~ /eq eFA 
xyx 
q 
207 
The same idea applies for A *: MA must be modified so that whenever it has 
checked that the string so far belongs to A *, it must not only continue 
checking but must also reactivate its initial states. 
MA' = (Q', OA" QOA, FA) 
where Q' = QA, QOA = QOA' and FA = FA if FA n QOA"# 0 but Q' = QA U {q} 
QOA = QOA u {q'} and FA = FA U {4} for a new state 4, otherwise. This 
makes sure that the empty string A will be accepted in A *. 
Â° 
A,(q, x) is only defined for q e QA and satisfies 
s: 
( 
) _ {O A(q, x) 
if Â° 
A(q, x) n FA = 0, 
uA,q,x -
. 
0A(q, x) u QAO 
If 0A(q, x) n FA 1= 0. 
o 
14 Example. A = 01 * is accepted by the NDA 
Now A* = (01 *)*, which equals {A} + oÂ· (0 + 1)*. Let us check that this is 
indeed accepted by M A' which, according to the above construction, equals 
i.e., we make 4 an initial as well as accepting state, and we add a transition to 
qo in MA' for each transition to an accepting state (Le., ql) in MA' 

208 
6 Graphs, Matrices, and Machines 
Since 4 is both a start and final state of MAO, we see that A E T(MAO). Since 
<>AO(qO' 1) = 0, we see that no string starting with 1 can belong to T(MAO). 
Now 
<>A.(qO, 0) = {qo, qdÂ· 
<>A.({qO' qd, 0) = <> AO(qO, 0) u <> AO(ql, 0) = {qo, ql} u 0 = {qo, qdÂ· 
<>AO({qO, qd, 1) = <>AO(qO' 1) u <>AO(ql' 1) = 0 u {qo, ql} = {qo, ql}Â· 
Thus <>A.(qO' w) = {qo, ql} for every w in oÂ· (0 + 1)*. Thus T(MA.) = {A} 
u oÂ· (0 + 1)* = A*, as was to be shown. 
EXERCISES FOR SECTION 6.3 
1. Use the construction described in the text to provide the state diagram of the FSA 
M L which accepts the sets: 
(a) L = {O, 1, 001,1110, 1111} 
(b) L = {A,O, 1,00, 11111}. 
2. Show that (0+ 1)* f; 0*1 *. 
3. Construct NDAs which accept the languages A = (0 + 1)* Â·01 and B = 01 * + 
1(1 + 00)*. Then use the constructions given in the text to provide NDAs which 
accept A u B, AÂ· Band A*, respectively. 
4. Supply the formal details of the proof that a subset of X* is a finite-state language if 
and only if it is accepted by some NDA. 
5. Let X be a finite alphabet with Le X*. Define 
Prefix(L) = {w E P I for some Z E P, wz EL}. 
Prove that if L is a finite-state language, then so too is Prefix (L). (Hint: Relate the 
prefix relationship on strings to the reachability condition on the state graph of an 
FSA.) 
6. Describe an NDA that accepts the language over the alphabet:E = {O, 1} generated 
by the following productions: S -+ OA, S -+ 1, A -+ OA, A -+ 1, A -+ lS. (Hint: Use 
the nonterminalletters S and A as names for states.) 

Author Index 
Alagic, S. 
104 
Arbib, M. A. 
104 
Boden, Margaret 43 
Boole, George 3 
Cantor, Georg 
161 
Descartes, Rene 5 
Euclid 4 
Euler, Leonhard 
178 
Fibonacci 96 
Hill, F. J. 
126 
Leonardo of Pisa 96 
-Eukasiewics 
172 
McCuIloch, Warren 
126 
De Morgan, Augustus 
11 
Newman, James R. 
178 
Nilsson, N. J. 
126 
Peano, Giuseppe 34 
Peterson, G. R. 
126 
Pitts, WaIter 126 
Stone, MarshaIl 
160 
Vacroux, A. G. 
124 
Venn, John 7 

Notation Index 
.-
1 
An 
19 
xdiv y 2 
A~B 19, 160 
xmody 2 
gÂ·f 20 
Z 2 
A 20,41 
N 3 
/\ 
47,112 
XEA 3 
1\ 156 
x$A 3 
XA 
21 
PA 
3, 111 
Q 23 
cp 
3 
.1 
23, 158 
AcB 3 
Pfn[A, B] 23 
D 5 
..:... 23 
AxB 5 
~ 25 
R 5 
R 25 
2A 6 
Ixl 29 
IAI 6, 160, 161 
n! 
35 
&l'A 6 
(J 38,48,177 
AuB 7,43,201 
X* 
41 
AnB 8 
In 41 
A-B 8 
AÂ·B 43,201 
Al + ... + An 8 
A* 43,44,201 
U Ai 8 
V 
47,113 
V 155 
l'5.is.n 
15 
48 
A 9 
qo 
48 
rnn 
12 
15* 
49,204 
f(A) 
16 
T(M) 50 
f:A -+ B 16 
v-+wl lw2 1Â·Â·Â·IWn 55 
a Hf(a) 16 
â¢ 
55 
= 
n 19 
= 55 

212 
.. -
59 
X* 
60 
e 
60 
{} 63 
T 
65 
ISATOM 66 
HEAD 67 
TAIL 67 
CONS 68 
CAR 68 
CDR 68 
EQ 68 
EQUAL 68 
COND 68 
LxJ 
78 
P(n, r) 82 
nPr 
82 
nCr 83 
(~) 83 
T 
111 
F 
111 
NOT 112 
AND 112 
OR 
112 
$ 
112 
15 
112 
-,p 112 
NOT-gate 
114 
AND-gate 114 
OR-gate 
114 
max 
114 
min 
114 
Zm 
115 
n mod m 
115 
O'(n) 
115 
$m 115 
plq 122 
NAND 
122 
NAND-gate 122 
NOR 123 
L 123 
(P L q) 
123 
NOR-gate 
127 
COND 
129 
A=> B 
132 
= 
133 
p => q 
135 
(Vx) 
141 
(3x) 
141 
R:A~A 146 
~A 146 
n : n' mod m 146 
idA 
146 
[a] 
147 
A modulo: 
149 
AI: 149 
:=:; 
150 
Pfo 
151 
(A, v, A) 
157 
T 
158 
~o 162 
ScopeT(v) 
169 
v(w) 
169 
nn 
170 
c5w 
171 
0'0 
177 
0'1 
177 
T(M) 200 
Notation Index 

Subject Index 
A 
absolute value 29 
accepting states 48 
additive identity 45 
additive inverse 45 
addition of cardinal numbers 
165 
address of a node in a tree 
168 
aleph null 
162 
Algorithm Analysis 92, 102 
almost everywhere 
154 
alphabet 41 
ambiguous tree presentation 94 
analytic geometry 5 
ancestor 88 
antecedent 
135 
antisymmetry 
150 
arithmetic progression 
13 
Artificial Intelligence (AI) 43 
arity 
169, 170 
arrays 62, 64 
associative 29 
operation 44 
laws 
10 
atom 65 
average complexity 
104 
axiomatization 
138 
complete 
140 
sound 139 
Axiom System for Propositional Logic 
138 
B 
Backus-Naur Form (BNF) 59 
base 
12 
basis step 32, 131 
best possible result 78 
biconditional form 
130 
bijection 
18, 20 
bijective correspondence 
19 
binary 
decision tree 7, 106 
search 60, 104 
tree 90 
tree, complete 92 
Binomial Theorem 83 
bipartite graph 
186 
bits 
15 
Boolean 3, 158 
algebra 
159 

214 
Boolean (cont.) 
connection matrix 193 
function 
118 
semiring 47, 190 
bottom 23, 158 
box notation for s-expressions 67 
branches 88 
c 
canonical surjection 
149 
Cantor's Diagonal Argument 
165 
cardinal number 
161 
cardinali ty 6, 161 
carrier 
171 
carry bit 
123 
carry look-ahead adder 
126 
Cartesian power 19,42,62 
Cartesian product 5, 62, 63 
ceiling of x 78 
characteristic function 21,26 
codomain 
16,22 
combination 
83 
comments 63 
commutative 
10, 29 
commutative mono id 46 
compiler 48 
complemented lattice 
159 
complete axiomatization 
140 
complete binary tree 92 
complete lattice 
157 
complexity 
average 
104 
of switching functions 
125 
optimal worst-case 
109 
worst-case 
103 
component of a graph 180 
composite 
10 
of maps 20 
of relations 27,153 
computer circuitry 114 
conc function 43 
concatenate 
41 
concatenation 43 
condition 
sufficient 
132 
conditional 
135 
conjunct 
121, 129 
conjunction 
112,47 
Subject Index 
conjunctive normal form 
121, 127 
connected graph 
180 
connectedness relation 
179 
connection matrices of graphs 
193 
connection matrix of an FSA 
199 
construction function 
68 
constructive proof 78 
consequent 
135 
Context-Free Grammars 53, 54 
context-free language 
56 
contradic tion 
137 
contrapositive 132, 136 
converse 
132 
corollary 
134 
cost of a search 
103 
counter 64 
counting principles 73 
cycle 
178 
D 
data type 62 
daughter 
168 
decimal notation 54 
definition 
domain of 22 
formal 47 
inductive 64 
recursive 
35 
Recursive Definition of Addition 
39 
degree of a vertex 
185 
De Morgan's Laws 
11, 113 
denumerable set 
163 
descendants 88 
derivation tree 
55 
derives 
55 
diagonal 
146 
dictionary order 152 
difference equation 
95 
directed graph 
177 
directly derives 
55 
disjoint 
partial functions 
151 
sets 8 
sum of partial functions 
151 
union 8,42 
disjunction 
47 
disjunctive normal form 
117 
disjunctive normal form theorem 
120 

Subject Index 
distributive 
29 
distributive lattice 
159 
distributive laws 
10 
dividend liS 
divides 
II 
domain 
16 
interpretation of an operator 
domain 
171 
of definition 
22 
operator 
169, 170 
tree 
168 
dotted pair 65 
dynamics 
199 
E 
E*-connection matrix 193 
edges 
177 
element 
maximal 154 
minimal 154 
empty 
set 3 
sequence 20 
string 41 
end function 
177 
enumeration 
163 
equivalence class 
147 
equivalence (logical) 
135 
equivalence relation 
146, 147 
Euler path 
178 
EuIer's Theorem 
181 
exclusive or 
112 
existential quantifier 
141 
existence proof 78 
existence theorem 
78 
exponents 
12 
exponentiation of cardinal numbers 
165 
exponential 
F 
decay 
12 
growth 
12 
factorial function 
35 
false 
111 
Fibonacci function 
97 
Fibonacci Sequence 95 
finite state acceptor (FSA) 48 
finite state language (FSL) 
50, 200 
floor of x 78 
flowcharts 
183 
flow diagram 
1, 185 
forest of trees 90 
forest, ordered 90 
formal definition 47 
formal language theory 43 
Four-Color Problem 
183 
full-adder 
124 
full binary tree 92 
function 
16 
Boolean 
118 
characteristic 21,26 
construction 68 
disjoint partial 
151 
disjoint sum of partial 
151 
end 177 
factorial 35 
Fibonacci 97 
graph of a function 24 
graph of a partial function 24 
identity 
146 
length 42 
monus 23 
partial 17, 22 
start 
177 
state transition 
199 
switching 
125 
total 22 
transition 48 
215 
functionally complete operations 122 
G 
grammar of English 
53 
graph 
175 
bipartite 
186 
component of 180 
connected 180 
connection matrix 
193 
directed 177 
of a function 24 
of a partial function 
24 
ordered 
175 
theory 
175 

216 
graph (cont.) 
undirected 177 
unordered 
175 
greatest lower bound (gIb) 
156 
group 45 
geometric progression 
14 
H 
half-adder 
123 
height of a tree 88 
Hesse diagrams 
156 
homomorphic image 47 
homomorphism 47 
I 
id 20 
identity 44 
additive 45 
for an operation 44 
function 
146 
map 20 
matrix 
191 
multiplicative 45 
if and only if 133 
if ... then . .. else 69, 128 
image 
16,22 
immediate successor 88 
implication 
135 
impossibility proof 127 
inclusion relation 150 
inclusive or 
112 
incomparable elements 
150 
induction 57 
induction step 32, 131 
inductive definition 
64 
inequality 25 
infinite 4 
sets 
161 
infinity 160 
initial state 48 
inorder 93 
input 
excitatory 
126 
inhibitory 
126 
internal node 87 
Subject Index 
interpretation 
137 
interpretation of an operator domain 
71 
intersection 8 
inverse 20, 45, 47 
additive 45 
left 28 
of a relation 
153 
right 28 
inverter 
114 
isolated vertex 
180 
isomorphic sets 
160 
isomorphism 
20 
iterate 43 
iteration 37 
iterative solution 64 
J 
join 
157 
K 
Konig's lemma 88, 101 
Kleene star 43 
L 
languCfge over X 43 
latin square 86 
orthogonal 86 
lattice 
157 
complemented 159 
complete 
157 
distributive 
159 
law 
associative 10 
De Morgan's 
11, 113 
distributive 
10 
leaf 66,169 
least upper bound (lub) 
155 
leaves 87 
left inverse 28 
left subtree 90 
lemma 
133 
length 4,41 
function 
42 

Subject Index 
level in a tree 91 
lexicographic order 
152, 160, 173 
linear algebra 
186 
linear map 
187 
Lisp 43, 60, 65 
list 60 
logarithm 
12 
logarithmic search 
108 
logic 
Axiom System for Propositional 
Logic 
138 
predicate 
140 
propositional 140 
loop 
177 
lower bound 156 
L-tree 66 
M 
machine, state-graph of 48 
magic square 85 
magic sum 
86 
map 
16, 183 
composite of 20 
identity 20 
linear 
187 
selector 62 
subway 
177 
matrix 
187 
Boolean connection 
193 
connection matrices of graphs 
193 
connection matrix of an FSA 
199 
E*-connection 
193 
identity 
191 
N-connection 
193 
product of matrices 
190 
sum of 187, 189 
symmetric 
194 
maximal 158 
element 
154 
maxterm 
122 
McCulloch-Pitts Neuron 
126 
meet 
157 
microcomputers 
124 
minimal 158 
circuit 
124 
element 
154 
minterm 
121 
modulo sum 
115 
Modus Ponens 
139 
mono id 44 
monus 23 
217 
multiplication of cardinal numbers 
165 
multiplicative identity 45 
mUltiplication modulo m 47 
mutually exclusive events 73 
N 
n-ary predicate 26 
n-ary relation 
26 
natural numbers 2, 32 
semiring of 190 
n choose r 
83 
N-connection matrix 193 
NDA 203 
necessary and sufficient conditions 
133 
necessary conditions 
132 
negation 
111 
neuron 
126 
NIL 43,65 
nodes 66,87, 169, 177 
non-constructive proof 78 
nondenumerable 
166 
set 
164 
nondeterminism 203 
nondeterministic finite state acceptor 
(NDA) 203 
non-negative integers 3 
nonterminals 54 
normal form 
11 7 
conjunctive 
121, 127 
disjunctive 
117 
disjunctive normal form theorem 
120 
n permute r 82 
numbers as string of digits 
37 
o 
il-algebra 
171 
il-trees 
172 
onto 
17 
one-to-one 
18 
operator domain 
170 
operator label 
170 
optimal worst-case complexity 
109 
ordered forest 
90 

218 
ordered graph 
175 
orthogonallatin square 86 
outdegree 
169 
p 
palindrome 56 
parallelism 
126 
parent 88 
parity 84 
parity checker 51 
parse 53, 203 
partial function 
17, 22 
disjoint 
151 
graph of 24 
partially ordered set 150 
partial order 150, 158 
partition 
153 
Pascal 47,62 
path 88 
of a directed graph 
194 
Euler 
178 
length 
194 
pattern recognition 
126 
Peano's Axioms 35 
permutations 80, 82 
Pigeonhole Principle 77, 79 
planar graph 
183 
poset 
150 
postorder 93, 174 
Polish (prefix) notation 
173 
powerset 6 
predicate logic 
140 
predicates 
140 
prefix 
152 
preorder 93, 174 
prime 
IQ 
primes, infinitely many 5 
principle 
Pigeonhole Principle 77, 79 
Principle of Induction 57 
Principle of Induction Extended 57 
product of matrices 190 
production 
55 
programming language semantics 
152 
progression 
arithmetic 
13 
geometric 
14 
Subject Index 
proof 138, 139 
by contradiction 4, 131 
by exhaustion of cases 
131 
by induction 32, 131 
of correctness 
104 
techniques 
131 
propagation of carry bits 
125 
proper graph 
180 
proper subset 3 
proposition 
III 
propositional connectives 
140 
propositionallogic 3, 137 
propositional variable 
137 
proving theorems 
131 
Q 
quantifiers 
140 
existential 
141 
universal 
141 
quotient 1 
R 
Rabbit breeding 96 
Ramsey's Theorem 80 
range 
16,22 
rational numbers 23 
reachable state 
199 
Recurrence Relations 95 
recursion 
32 
in programming languages 36 
recursion step 36 
recursive definition 
35 
Recursive Definition of Addition 39 
reductio ad absurdum 4, 131 
reduction step 36 
reflexive 
146 
regular languages 20 
regular set 58 
relation 25, 146 
composite of 27, 135 
connectedness 179 
equivalence 146, 147 
inclusion 
150 
inverse 
153 
n-ary 26 

Subject Index 
Recurrence 95 
transitive closure 27 
transitive reflexive closure 27 
union of 27 
remainder 
1, 115 
right inverse 28 
right subtree 90 
root 66, 87, 168 
rooted tree 
87 
Rule of Inference 
139 
Rule of Product 74 
Rule of Sum 73 
Rules of Sum and Product Generalized 
75 
s 
sample 6 
satisfiable formula 
143 
scalar multiple 
187 
scope 
169 
search key 
102 
s-expressions 65 
selector maps 62 
semantics 
136 
of well-formed formulas 
137 
semigroup 47 
semiring 46, 190 
Boolean 
190 
of natural numbers 
190 
string 
190 
sequence 4 
empty 20 
Fibonacci 95 
sequential search 60,61, 103 
series 
13 
sum of 13 
set 2 
complements 9 
denumerable 
163 
difference 8, 166 
disjoint 8 
empty 3 
infinite 
161 
isomorphic 
160 
nondenumerable 
164 
of characters 41 
regular 58 
set theory 1 
Seven Bridges of K6nigsberg 
178 
Sheffer stroke 
122 
Socrates 
142 
sorted array 105 
sound axiomatization 149 
Strahler numbering 100 
start state 48 
start function 
177 
state 48 
accepting 48 
initial 48 
finite state acceptor (FSA) 48 
machine, state-graph of 48 
nondeterministic finite state 
acceptor (NDA) 203 
reachable 
199 
start 48 
transition function 
199 
string 
empty 41 
notation 41 
numbers as strings of digits 37 
of symbols 41 
reversal 47 
semi ring 
190 
Strings over an Arbitrary Set 41 
subset 3 
substitution rule 
139 
subtree 
169 
subway map 177 
successor 35 
ofa node 168,169 
sufficient conditions 
132 
sum of matrices 
187, 189 
switching circuit 114 
functions 
125 
symbolic-expression 65 
symmetric 
146 
matrix 
194 
syntax 54, 136 
T 
of decimal numbers 59 
of programming languages 59 
of well-formed formulas 
137 
tautologies 
137 
telephone directory 61 
219 

220 
terminal 55 
node 
169 
ternary 
15 
theorem 
138, 139 
threshold 
126 
Logic Unit 
126 
top 
158 
topological sorting 
154 
total function 22 
total order 
150 
Tournament Method 
109 
transition function 48 
transitive 
146 
transitive closure of a relation 27 
transitive reflexive closure of a 
relation 27 
traversals of binary trees 
93 
trap state 
51 
tree 53,87, 167 
ambiguous presentation 94 
binary 90 
binary decision 
7, 106 
complete binary 92 
derivation 55 
domain 
168 
forest 
90 
full binary 92 
height 88 
level in 
91 
L-tree 66 
rooted 87 
true III 
truth table 
112 
u 
undirected graph 
177 
union 7,43 
union of relations 27 
unit vector 
188 
universal quantifier 
141 
unordered graph 175 
unordered pair 194 
upper bound 155 
v 
variables 54 
vel 113 
Venn diagrams 7 
vertex 66 
w 
Subject Index 
well-formed formula 
135, 138 
well-formed programs 54 
wff 138 
weight 
126 
worst-case complexity 103 

