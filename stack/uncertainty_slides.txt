What Uncertainties Do We Need 
in Bayesian Deep Learning for 
Computer Vision 
Patryk Chrabąszcz

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Importance of modeling uncertainty 

Importance of modeling uncertainty 
●Autonomous Car Accident

Importance of modeling uncertainty 
●Autonomous Car Accident
●Google app racial discrimination

Importance of modeling uncertainty 
●Autonomous Car Accident
●Google app racial discrimination
●Safety Critical Systems

Importance of modeling uncertainty 
●Autonomous Car Accident
●Google app racial discrimination
●Safety Critical Systems
●Medical Applications
I have never seen those 
symptoms before. I’m 
completely uncertain what 
it could be. Better see a 
doctor!

Example: Active Learning

Example: Active Learning
●Model decides which data should be labeled

Example: Active Learning
●Model decides which data should be labeled
Source: “Cost-Effective Active Learning for Deep Image Classification” 

Example: Active Learning
●Model decides which data should be labeled
●Collect the best data at low cost
Source: “Cost-Effective Active Learning for Deep Image Classification” 

Example: Reinforcement Learning

Example: Reinforcement Learning
●No knowledge at the start

Example: Reinforcement Learning
●No knowledge at the start
●Make decision at each step
○Explore ?
○Exploit ?

Example: Reinforcement Learning
●No knowledge at the start
●Make decision each step
○Explore ?
○Exploit ?
●Intelligent exploration

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary



Aleatoric uncertainty
●Natural randomness 
Modeling the result of dice throw.
In latin āleae: a die

Aleatoric uncertainty
●Natural randomness
●Sensor quality

Aleatoric uncertainty
●Natural randomness
●Sensor quality
●Can’t be reduced

Aleatoric uncertainty
●Natural randomness
●Sensor quality
●Can’t be reduced
●But can be learned


Homoscedastic uncertainty
●Stays constant for different
input values
Source:Gal, Y. Uncertainty in Deep Learning. PhD thesis, 
University of Cambridge, 2016.

Homoscedastic uncertainty
●Stays constant for different
input values
●Limited, captures ‘average’ 
uncertainty
Source:Gal, Y. Uncertainty in Deep Learning. PhD thesis, 
University of Cambridge, 2016.


Heteroscedastic uncertainty
●Depends on the input
Source:Gal, Y. Uncertainty in Deep Learning. PhD thesis, 
University of Cambridge, 2016.

Heteroscedastic uncertainty
●Depends on the input
●Important for CV tasks
Source:Gal, Y. Uncertainty in Deep Learning. PhD thesis, 
University of Cambridge, 2016.

Heteroscedastic uncertainty
●Depends on the input
●Important for CV tasks
●Learned from the data
Source:Gal, Y. Uncertainty in Deep Learning. PhD thesis, 
University of Cambridge, 2016.


Epistemic uncertainty
●Lack of knowledge about the process
Epistēmē Greek meaning: knowledge.

Epistemic uncertainty
●Lack of knowledge about the process
●Detects samples far from the training distribution

Epistemic uncertainty
●Lack of knowledge about the process
●Detects samples far from training distribution
●Disappears given enough data.

Epistemic uncertainty
●Lack of knowledge about the process
●Detects samples far from training distribution
●Disappears given enough data.
●Train many models, detect where models disagree

Epistemic uncertainty
●Lack of knowledge about the process
●Detects samples far from training distribution
●Disappears given enough data.
●Train many models, detect where models disagree
●Use distribution over model weights

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Bayesian Neural Networks
●Neural Network

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)
○One best model

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)
○One best model
●Bayesian Neural Network

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)
○One best model
●Bayesian Neural Network
○Distribution over weights

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)
○One best model
●Bayesian Neural Network
○Distribution over weights
○Output is a distribution 

Bayesian Neural Networks
●Neural Network
○Finds a function y = f(x)
○One best model
●Bayesian Neural Network
○Distribution over weights
○Output is a distribution 
○Many models within a network

Bayesian Neural Networks

Bayesian Neural Networks
●Ideas from 30 years ago
Source:Gal, Y. 
http://mlg.eng.cam.ac.uk/yarin/index.html

Bayesian Neural Networks
●Ideas from 30 years ago
●BNN with ∞ many weights ￫ Gaussian Process
Source:Gal, Y. 
http://mlg.eng.cam.ac.uk/yarin/index.html

Bayesian Neural Networks
●Ideas from 30 years ago
●BNN with ∞ many weights ￫ Gaussian Process
●Difficult to make inference on:
○Multimodal correlated distribution
○Nonlinearities
Source:Gal, Y. 
http://mlg.eng.cam.ac.uk/yarin/index.html

Bayesian Neural Networks
●Ideas from 30 years ago
●BNN with ∞ many weights ￫ Gaussian Process
●Difficult to make inference on:
○Multimodal correlated distribution
○Nonlinearities
●Different approximation techniques
Source:Gal, Y. 
http://mlg.eng.cam.ac.uk/yarin/index.html

Bayesian Neural Networks
●Find 

Bayesian Neural Networks
●Find
○Find models that are likely to generate our training data

Bayesian Neural Networks
●Find
○Find models that are likely to generate our training data

Bayesian Neural Networks
●Likelihood (Gaussian, Laplace)
○Measures how likely model with weights W generated Y

Bayesian Neural Networks
●Likelihood (Gaussian, Laplace)
○Measures how likely model with weights W generated Y

●Prior
○Usually a  Gaussian distribution with mean at 0 
Bayesian Neural Networks

●Prior
○Usually a  Gaussian distribution with mean at 0 
○Acts as a regularizer
Bayesian Neural Networks

Bayesian Neural Networks
●Marginal Probability
○Normalizes probability  

Bayesian Neural Networks
●Marginal Probability
○Normalizes probability 
○Can not be evaluated 

Bayesian Neural Networks
●In general                           can be a complex distribution 

Bayesian Neural Networks
●In general                           can be a complex distribution 
●We need an approximation

Bayesian Neural Networks
●In general                           can be a complex distribution 
●We need an approximation
●Replace complex                          
with                 from a tractable family 
(Gaussian, Bernoulli) 

Bayesian Neural Networks
●In general                           can be a complex distribution 
●We need an approximation
●Approximate complex                          
with                 from a tractable family 
(Gaussian, Bernoulli) 
●Minimize the distance between 
them (KL Divergence)

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Dropout Variational Inference
●Randomly drop network units
Source: “Dropout:  A Simple Way to Prevent 
Neural Networks from Overfitting” 
Srivastava et. al.

Dropout Variational Inference
●Randomly drop network units
●Bernoulli approximation
Source: “Dropout:  A Simple Way to Prevent 
Neural Networks from Overfitting” 
Srivastava et. al.

Dropout Variational Inference
●Randomly drop network units
●Bernoulli approximation
●One of the simplest possible 
Source: “Dropout:  A Simple Way to Prevent 
Neural Networks from Overfitting” 
Srivastava et. al.

Dropout Variational Inference
●Randomly drop network units
●Bernoulli approximation
●One of the simplest possible 
●We learn  θ for each weight
Source: “Dropout:  A Simple Way to Prevent 
Neural Networks from Overfitting” 
Srivastava et. al.

Training with dropout
●Neural network trained with dropout is already a BNN

Training with dropout
●Neural network trained with dropout is already a BNN
○Because we have a distribution over its weights

●Neural network trained with dropout is already a BNN
Training with dropout

●Neural network trained with dropout is already a BNN
For each training point 
draw a new dropout mask
Training with dropout

●Neural network trained with dropout is already a BNN
Minimize negative log likelihood
Training with dropout

●Neural network trained with dropout is already a BNN
Regularization term (prior)
Training with dropout

Training with dropout
●Neural network trained with dropout is already a BNN
●In this work dropout probability p is set to 0.2

Training with dropout
●Neural network trained with dropout is already a BNN
●In this work dropout probability p is set to 0.2
●Minimizing this loss we also minimize KL divergence 
between                           and 

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Modeling uncertainties

Homoscedastic uncertainty 
●Regression Problem

●Regression Problem
Homoscedastic uncertainty 

●Regression Problem
●If Laplace Likelihood:
Homoscedastic uncertainty 

●Regression Problem
●If Laplace Likelihood:
○Minimize the distance between model predictions and the 
training data
Homoscedastic uncertainty 

●Regression Problem
●If Laplace Likelihood
●Use sigma and dropout samples to estimate uncertainty
Homoscedastic uncertainty 

●Sum of aleatoric and epistemic variance
Estimated variance

●Sum of aleatoric and epistemic variance
○Epistemic variance: variance over multiple dropout draws  
Estimated variance

Heteroscedastic uncertainty 

●Start as before
Heteroscedastic uncertainty 

●Start as before
●Uncertainty as a 
function of the input
Heteroscedastic uncertainty 

●Start as before
●Uncertainty as a 
function of the input
○If it is hard to predict correct output, 
increase uncertainty to reduce loss
○Uncertainty acts as a loss attenuation
○Robust to outliers 
Heteroscedastic uncertainty 

●Start as before
●Uncertainty as a 
function of the input
Heteroscedastic uncertainty 

Classification with Uncertainty 
●Modeling uncertainty for classification

Classification with Uncertainty 
●Modeling uncertainty for classification
○Add noise to the output of the network (logits)

Classification with Uncertainty 
●Modeling uncertainty for classification
○Add noise to the output of the network (logits)
○Variance of this noise depends on the input

Classification with Uncertainty 
●Modeling uncertainty for classification
○Add noise to the output of the network (logits)
○Variance of this noise depends on the input

Classification with Uncertainty 
●Modeling uncertainty for classification
○Add noise to the output of the network (logits)
○Variance of this noise depends on the input
●If model is wrong, bigger uncertainty results in a lower 
loss

Classification with Uncertainty 
●Example

Classification with Uncertainty 
Network outputs:
 
First class: 1
Second class: 2

Classification with Uncertainty 
After softmax:
 
First class: 27%
Second class: 73%

Classification with Uncertainty 
Sample 50 times logits with 
noise (variance = 0.5)
27%
73%

Classification with Uncertainty 
27%
73%
30%
70%

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

CamVid
●Road scene understanding dataset
●367 train, 233 test 
●Day and dusk scenes
●11 classes
●Resized to 360×480

NYUv2 40-Class
●Indoor segmentation dataset 
●40 different semantic classes
●464 different indoor scenes.
●1449 images
●640×480

NYUv2 Depth
●Indoor dataset 
●464 different indoor scenes.
●1449 images
●640×480

Make 3D
●400 training, 134 test
●3-D laser scanner. 
●Resized to 345×460

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Semantic Segmentation
Aleatoric 
Epistemic

Semantic Segmentation
Aleatoric 
Epistemic

Pixel-wise Depth Regression
Aleatoric 
Epistemic

Pixel-wise Depth Regression
Aleatoric 
Epistemic

●Uncertainty 
correlates with 
accuracy
Quality of Uncertainty Metric

Quality of Uncertainty Metric
●Uncertainty 
correlates with 
accuracy
●Precision
decreases as we 
increase uncertainty

Calibration
●If prediction 
has a probability 
of “p”, we would 
like this prediction 
to be correct with 
frequency “p”

Calibration
●If prediction 
has a probability 
of “p”, we would 
like this prediction 
to be correct with 
frequency “p”

●Modeling epistemic variance should be more 
beneficial when our training data is small
Dataset size

●Modeling epistemic variance should be more 
beneficial when our training data is small
●Epistemic variance captures data from 
different distribution
Dataset size

Improvement over Baseline
Source: http://alexgkendall.com/talks/

Outline:
●Motivation
●Types of Uncertainty 
●Bayesian Neural Networks
●Dropout Variational Inference
●Modeling uncertainties
●Experiments
●Results Analysis
●Summary

Summary:
●Aleatoric uncertainty:
○Can be used for real time applications
○Can be used alone for large datasets 
●Epistemic uncertainty:
○Can detect samples out of the training data
○Useful for small datasets 
○Expensive to evaluate (MC Sampling)

Thank you

