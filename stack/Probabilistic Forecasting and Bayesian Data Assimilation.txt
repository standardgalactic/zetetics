
Probabilistic Forecasting and Bayesian Data Assimilation
In this book the authors describe the principles and methods behind probabilistic fore-
casting and Bayesian data assimilation. Instead of focusing on particular application
areas, the authors adopt a general dynamical systems approach, with a selection of
low-dimensional, discrete time numerical examples designed to build intuition about
the subject.
Part I explains the mathematical framework of ensemble-based probabilistic forecast-
ing and uncertainty quantiﬁcation. Part II is devoted to Bayesian ﬁltering algorithms,
from classical data assimilation algorithms such as the Kalman ﬁlter, variational tech-
niques, and sequential Monte Carlo methods, through to more recent developments such
as the ensemble Kalman ﬁlter and ensemble transform ﬁlters. The McKean approach
to sequential ﬁltering in combination with coupling of measures serves as a unifying
mathematical framework throughout Part II.
The prerequisites are few. Some basic familiarity with probability is assumed, but
concepts are explained when needed, making this an ideal introduction for graduate
students in applied mathematics, computer science, engineering, geoscience and other
emerging application areas of Bayesian data assimilation.


Probabilistic Forecasting and
Bayesian Data Assimilation
SEBASTIAN REICH
University of Potsdam and University of Reading
COLIN COTTER
Imperial College London

University Printing House, Cambridge CB2 8BS, United Kingdom
Cambridge University Press is part of the University of Cambridge.
It furthers the University’s mission by disseminating knowledge in the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781107069398
© Sebastian Reich and Colin Cotter 2015
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2015
Printed in the United Kingdom by Bell and Bain Ltd
A catalogue record for this publication is available from the British Library
ISBN 978-1-107-06939-8 Hardback
ISBN 978-1-107-66391-6 Paperback
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication,
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.

Contents
Preface
page vii
1
Prologue: how to produce forecasts
1
1.1
Physical processes and observations
1
1.2
Data driven forecasting
6
1.3
Model driven forecasting and data assimilation
15
1.4
Guide to literature
28
1.5
Appendix: Numerical implementation of tent map iteration
28
Part I
Quantifying Uncertainty
31
2
Introduction to probability
33
2.1
Random variables
35
2.2
Coupling of measures and optimal transportation
46
2.3
Guide to literature
62
2.4
Appendix: Conditional expectation and best approximation
62
2.5
Appendix: Dual formulation of optimal linear transportation
63
3
Computational statistics
65
3.1
Deterministic quadrature
66
3.2
Monte Carlo quadrature
74
3.3
Sampling algorithms
81
3.4
Guide to literature
93
3.5
Appendix: Random probability measures
93
3.6
Appendix: Polynomial chaos expansion
95
4
Stochastic processes
96
4.1
Dynamical systems and discrete-time Markov processes
96
4.2
Stochastic diﬀerence and diﬀerential equations
111
4.3
Probabilistic forecasting and ensemble prediction
117
4.4
Scoring rules for probabilistic forecasting
121
4.5
Guide to literature
130

vi
Contents
5
Bayesian inference
131
5.1
Inverse problems from a probabilistic perspective
132
5.2
Sampling the posterior
142
5.3
Optimal coupling approach to Bayesian inference
148
5.4
Guide to literature
158
5.5
Appendix: BLUE estimator
159
5.6
Appendix: A geometric view on Brownian dynamics
160
5.7
Appendix: Discrete Fokker–Planck equation
165
5.8
Appendix: Linear transport algorithm in one dimension
168
Part II
Bayesian Data Assimilation
169
6
Basic data assimilation algorithms
171
6.1
Kalman ﬁlter for linear model systems
175
6.2
Variational data assimilation
179
6.3
Particle ﬁlters
187
6.4
Guide to literature
196
6.5
Appendix: Posterior consistency
196
6.6
Appendix: Weak constraint 4DVar
198
7
McKean approach to data assimilation
200
7.1
Ensemble Kalman ﬁlters
206
7.2
Ensemble transform particle ﬁlter
213
7.3
Guide to literature
223
7.4
Appendix: Linear transport algorithm
224
7.5
Appendix: Gaussian mixture transform ﬁlter
226
8
Data assimilation for spatio-temporal processes
229
8.1
Spatio-temporal model systems
232
8.2
Ensemble inﬂation
242
8.3
Localisation
248
8.4
Guide to literature
257
9
Dealing with imperfect models
259
9.1
Model selection
260
9.2
Parameter estimation
266
9.3
Molliﬁed data assimilation
270
9.4
Guide to literature
283
9.5
Appendix: Continuous-time ﬁltering
283
A postscript
288
References
289
Index
295

Preface
Classical mechanics is built upon the concept of determinism. Determinism
means that knowledge of the current state of a mechanical system completely
determines its future (as well as its past). During the nineteenth century, deter-
minism became a guiding principle for advancing our understanding of natural
phenomena, from empirical evidence to ﬁrst principles and natural laws. In order
to formalise the concept of determinism, the French mathematician Pierre Simon
Laplace postulated an intellect now referred to as Laplace’s demon:
We may regard the present state of the universe as the eﬀect of its past and the cause
of its future. An intellect which at a certain moment would know all forces that set
nature in motion, and all positions of all its items of which nature is composed, if this
intellect were also vast enough to submit these data to analysis, it would embrace in a
single formula the movements of the greatest bodies of the universe and those of the
tiniest atoms; for such an intellect nothing would be uncertain and the future just like
the past would be present before its eyes.1
Laplace’s demon has three properties: (i) exact knowledge of the laws of nature;
(ii) complete knowledge of the state of the universe at a particular point in time
(of course, Laplace was writing in the days before knowledge of quantum me-
chanics and relativity); and (iii) the ability to solve any form of mathematical
equation exactly. Except for extremely rare cases, none of these three condi-
tions is met in practice. First, mathematical models generally provide a much
simpliﬁed representation of nature. In the words of the statistician George Box:
“All models are wrong, some are useful”. Second, reality can only be assessed
through measurements which are prone to measurement errors and which can
only provide a very limited representation of the current state of nature. Third,
most mathematical models cannot be solved analytically; we need to approxi-
mate them and then implement their solution on a computer, leading to further
errors. At the end of the day, we might end up with a perfectly deterministic
piece of computer code with relatively little correspondence to the evolution of
the natural phenomena of interest to us.
1 We have found this quote in the Very Short Introduction to Chaos by Smith (2007b),
which has also stimulated a number of philosophical discussions on imperfect model
forecasts, chaos, and data assimilation throughout this book. The original publication is
Essai philosophique sur les probabilit´es (1814) by Pierre Simon Laplace.

viii
Preface
Despite all these limitations, computational models have proved extremely
useful, in producing ever more skilful weather predictions, for example. This has
been made possible by an iterated process combining forecasting, using highly
sophisticated computational models, with analysis of model outputs using obser-
vational data. In other words, we can think of a computational weather predic-
tion code as an extremely complicated and sophisticated device for extrapolating
our (limited) knowledge of the present state of the atmosphere into the future.
This extrapolation procedure is guided by a constant comparison of computer
generated forecasts with actual weather conditions as they arrive, leading to
subsequent adjustments of the model state in the weather forecasting system.
Since both the extrapolation process and the data driven model adjustments
are prone to errors which can often be treated as random, one is forced to ad-
dress the implied inherent forecast uncertainties. The two main computational
tools developed within the meteorology community in order to deal with these
uncertainties are ensemble prediction and data assimilation.
In ensemble prediction, forecast uncertainties are treated mathematically as
random variables; instead of just producing a single forecast, ensemble prediction
produces large sets of forecasts which are viewed as realisations of these random
variables. This has become a major tool for quantifying uncertainty in fore-
casts, and is a major theme in this book. Meanwhile, the term data assimilation
was coined in the computational geoscience community to describe methodolo-
gies for improving forecasting skill by combining measured data with computer
generated forecasts. More speciﬁcally, data assimilation algorithms meld compu-
tational models with sets of observations in order to, for example, reduce uncer-
tainties in the model forecasts or to adjust model parameters. Since all models
are approximate and all data sets are partial snapshots of nature and are limited
by measurement errors, the purpose of data assimilation is to provide estimates
that are better than those obtained by using either computational models or
observational data alone. While meteorology has served as a stimulus for many
current data assimilation algorithms, the subject of uncertainty quantiﬁcation
and data assimilation has found widespread applications ranging from cognitive
science to engineering.
This book focuses on the Bayesian approach to data assimilation and gives
an overview of the subject by ﬂeshing out key ideas and concepts, as well as
explaining how to implement speciﬁc data assimilation algorithms. Instead of
focusing on particular application areas, we adopt a general dynamical systems
approach. More to the point, the book brings together two major strands of data
assimilation: on the one hand, algorithms based on Kalman’s formulas for Gaus-
sian distributions together with their extension to nonlinear systems; and on the
other, sequential Monte Carlo methods (also called particle ﬁlters). The common
feature of all of these algorithms is that they use ensemble prediction to repre-
sent forecast uncertainties. Our discussion of ensemble-based data assimilation
algorithms relies heavily on the McKean approach to ﬁltering and the concept of
coupling of measures, a well-established subject in probability which has not yet

Preface
ix
found widespread applications to Bayesian inference and data assimilation. Fur-
thermore, while data assimilation can formally be treated as a special instance of
the mathematical subject of ﬁltering and smoothing, applications from the geo-
sciences have highlighted that data assimilation algorithms are needed for very
high-dimensional and highly nonlinear scientiﬁc models where the classical large
sample size limits of statistics cannot be obtained in practice. Finally, in contrast
with the assumptions of the perfect model scenario (which are central to most of
mathematical ﬁltering theory), applications from geoscience and other areas re-
quire data assimilation algorithms which can cope with systematic model errors.
Hence robustness of data assimilation algorithms under ﬁnite ensemble/sample
sizes and systematic model errors becomes of crucial importance. These aspects
will also be discussed in this book.
It should have become clear by now that understanding data assimilation algo-
rithms and quantiﬁcation of uncertainty requires a broad array of mathematical
tools. Therefore, the material in this book has to build upon a multidisciplinary
approach synthesising topics from analysis, statistics, probability, and scientiﬁc
computing. To cope with this demand we have divided the book into two parts.
While most of the necessary mathematical background material on uncertainty
quantiﬁcation and probabilistic forecasting is summarised in Part I, Part II is
entirely devoted to data assimilation algorithms. As well as classical data assimi-
lation algorithms such as the Kalman ﬁlter, variational techniques, and sequential
Monte Carlo methods, the book also covers newer developments such as the en-
semble Kalman ﬁlter and ensemble transform ﬁlters. The McKean approach to
sequential ﬁltering in combination with coupling of measures serves as a unifying
mathematical framework throughout Part II.
The book is written at an introductory level suitable for graduate students in
applied mathematics, computer science, engineering, geoscience and other emerg-
ing application areas of Bayesian data assimilation. Although some familiarity
with random variables and dynamical systems is helpful, necessary mathematical
concepts are introduced when they are required. A large number of numerical ex-
periments are provided to help to illustrate theoretical ﬁndings; these are mostly
presented in a semi-rigorous manner. Matlab code for many of these is avail-
able via the book’s webpage. Since we focus on ideas and concepts, we avoid
proofs of technical mathematical aspects such as existence, convergence etc.; in
particular, this is achieved by concentrating on ﬁnite-dimensional discrete time
processes where results can be sketched out using ﬁnite diﬀerence techniques,
avoiding discussion of Itˆo integrals, for example. Some more technical aspects
are collected in appendices at the end of each chapter, together with descrip-
tions of alternative algorithms that are useful but not key to the main story. At
the end of each chapter we also provide exercises, together with a brief guide to
related literature.
With probabilistic forecasting and data assimilation representing such rich and
diverse ﬁelds, it is unavoidable that the authors had to make choices about the
material to include in the book. In particular, it was necessary to omit many in-

x
Preface
teresting recent developments in uncertainty quantiﬁcation which are covered by
Smith (2014). A very approachable introduction to data assimilation is provided
by Tarantola (2005). In order to gain a broader mathematical perspective, the
reader is referred to the monograph by Jazwinski (1970), which still provides an
excellent introduction to the mathematical foundation of ﬁltering and smoothing.
A recent, in-depth mathematical account of ﬁltering is given by Bain & Crisan
(2009). The monograph by del Moral (2004) provides a very general mathemat-
ical framework for the ﬁltering problem within the setting of Feynman–Kac for-
mulas and their McKean models. Theoretical and practical aspects of sequential
Monte Carlo methods and particle ﬁlters can, for example, be found in Doucet,
de Freitas & Gordon (2001). The popular family of ensemble Kalman ﬁlters is
covered by Evensen (2006). The monograph by Majda & Harlim (2012) devel-
ops further extensions of the classic Kalman ﬁlter to imperfect models in the
context of turbulent ﬂows. We also mention the excellent monograph on optimal
transportation and coupling of measures by Villani (2003).
We would like to thank: our colleagues Uri Ascher, Gilles Blanchard, Jochen
Br¨ocker, Dan Crisan, Georg Gottwald, Greg Pavliotis, Andrew Stuart and Pe-
ter Jan van Leeuwen for the many stimulating discussions centred around var-
ious subjects covered in this book; our students Yuan Cheng, Nawinda Chut-
sagulprom, Maurilio Gutzeit, Tobias Machewitz, Matthias Theves, James Tull,
Richard Willis and Alexandra Wolﬀfor their careful reading of earlier drafts of
this book; Jason Frank, who provided us with detailed and very valuable feed-
back; Dan and Kate Daniels who provided childcare whilst much of Colin’s work
on the book was taking place; and David Tranah from Cambridge University
Press who provided guidance throughout the whole process of writing this book.
Finally, we would like to thank our families: Winnie, Kasimir, Nepomuk, Re-
becca, Matilda and Evan, for their patience and encouragement.

1
Prologue: how to produce forecasts
This chapter sets out a simpliﬁed mathematical framework that allows us to
discuss the concept of forecasting and, more generally, prediction. Two key in-
gredients of prediction are: (i) we have a computational model which we use to
simulate the future evolution of the physical process of interest given its current
state;1 and (ii) we have some measurement procedure providing partially ob-
served data on the current and past states of the system. These two ingredients
include three diﬀerent types of error which we need to take into account when
making predictions: (i) precision errors in our knowledge of the current state of
the physical system; (ii) diﬀerences between the evolution of the computational
model and the physical system, known as model errors; and (iii) measurement
errors in the data that must occur since all measurement procedures are imper-
fect. Precision and model errors will both lead to a growing divergence between
the predicted state and the system state over time, which we attempt to cor-
rect with data which have been polluted with measurement errors. This leads
to the key question of data assimilation: how can we best combine the data with
the model to minimise the impact of these errors, and obtain predictions (and
quantify errors in our predictions) of the past, present and future state of the
system?
1.1
Physical processes and observations
In this book we shall introduce data assimilation algorithms, and we shall want
to discuss and evaluate their accuracy and performance. We shall illustrate this
by choosing examples where the physical dynamical system can be represented
mathematically. This places us in a somewhat artiﬁcial situation where we must
generate data from some mathematical model and then pretend that we have only
observed part of it. However, this will allow us to assess the performance of data
assimilation algorithms by comparing our forecasts with the “true evolution” of
the system. Once we have demonstrated the performance of such algorithms in
this setting, we are ready to apply them to actual data assimilation problems
1 It is often the case, in ocean modelling for example, that only partial observations are
available and it is already challenging to predict the current state of the system
(nowcasting). It is also often useful to reconstruct past events when more data become
available (hindcasting).

2
Prologue: how to produce forecasts
where the true system state is unknown. This methodology is standard in the
data assimilation community.
We shall use the term surrogate physical process to describe the model that we
use to generate the true physical dynamical system trajectory for the purpose of
these investigations. Since we are building the surrogate physical process purely
to test out data assimilation algorithms, we are completely free to choose a
model for this. To challenge these algorithms, the surrogate physical process
should exhibit some complex dynamical phenomena. On the other hand, it should
allow for numerically reproducible results so that we can make comparisons and
compute errors. For example, we could consider a surrogate physical process
described in terms of a ﬁnite-dimensional state variable z ∈RNz of dimension
Nz ≥1, that has time dependence governed by an ordinary diﬀerential equation
(ODE) of the form
dz
dt = f(z) + g(t),
z(0) = z0,
(1.1)
with a chosen vector ﬁeld f : RNz →RNz and a time-dependent function g(t) ∈
RNz for t ≥0 such that solutions of (1.1) exist for all t ≥0 and are unique. While
such an ODE model can certainly lead to complex dynamic phenomena, such as
chaos, the results are not easily reproducible since closed form analytic solutions
rarely exist. Instead, we choose to replace (1.1) by a numerical approximation
such as the forward Euler scheme
zn+1 = zn + δt (f(zn) + g(tn)) ,
tn = n δt,
(1.2)
with iteration index n ≥0, step-size δt > 0, and initial value z0 = z0.2 Usually,
(1.2) is used to approximate (1.1). However, here we will choose (1.2) to be
our actual surrogate physical process with some speciﬁed value of δt (chosen
suﬃciently small for stability). This is then completely reproducible (assuming
exact arithmetic, or a particular choice of rounding mode) since there is an
explicit formula to obtain the sequence z0, z1, z2, etc.
We shall often want to discuss time-continuous systems, and therefore we
choose to use linear interpolation in between discrete time points tn and tn+1,
z(t) = zn + (t −tn)zn+1 −zn
δt
,
t ∈[tn, tn+1],
(1.3)
to obtain a completely reproducible time-continuous representation of a surro-
gate physical process. In other words, once the vector ﬁeld f, together with the
step-size δt, the initial condition z0, and the forcing {g(tn)}n≥0, have been spec-
iﬁed in (1.2), a unique function z(t) can be obtained for t ≥0, which we will
denote by zref(t) for the rest of this chapter. It should be emphasised at this
point that we need to pretend that zref(t) is not directly accessible to us dur-
ing the data assimilation process. Our goal is to estimate zref(t) from partial
2 Throughout this book we use superscript indices to denote a temporal iteration index, for
example zn in (1.2). Such an index should not be confused with the nth power of z. The
interpretation of zn should hopefully be clear from the circumstances of its use.

1.1 Physical processes and observations
3
measurements of zref(t), using imperfect mathematical models of the dynamical
system. We will return to these issues later in the chapter.
To clarify the setting, we next discuss a speciﬁc example for producing surro-
gate physical processes in the form of a reference solution zref(t).
Example 1.1
The Lorenz-63 model (Lorenz 1963) has a three-dimensional
state variable
z := (x, y, z)T ∈RNz, for scalar variables x, y, z, with Nz = 3.
The variable z satisﬁes an equation that can be written in the form (1.2) with
vector ﬁeld f given by
f(z) :=
⎛
⎝
σ(y −x)
x(ρ −z) −y
xy −βz
⎞
⎠,
(1.4)
and parameter values σ = 10, ρ = 28, and β = 8/3. We will use this vector ﬁeld
in the discrete system (1.2) to build a surrogate physical process with step-size
δt = 0.001 and initial conditions
x0 = −0.587,
y0 = −0.563,
z0 = 16.870.
(1.5)
As we develop this example throughout this chapter, we will discuss model errors,
deﬁned as diﬀerences between the surrogate physical process and the imperfect
model that we will use to make predictions. For that reason we include a non-
autonomous forcing term g in (1.2), which will have diﬀerent deﬁnitions in the
two models. We shall deﬁne the forcing g(tn) = gn = (gn
1 , gn
2 , gn
3 )T ∈R3 for
the surrogate physical process as follows: set a = 1/
√
δt and, for n ≥0, deﬁne
recursively
gn+1
i
=
 2gn
i + a/2
if gn
i ∈[−a/2, 0),
−2gn
i + a/2
otherwise,
(1.6)
for i = 1, 2, 3 with initial values
g0
1 = a(2−1/2 −1/2),
g0
2 = a(3−1/2 −1/2),
g0
3 = a(5−1/2 −1/2).
It should be noted that gn
i ∈[−a/2, a/2] for all n ≥0. In order to avoid an
undesired accumulation of round-oﬀerrors in ﬂoating point arithmetic, we need
to slightly modify the iteration deﬁned by (1.6). A precise description of the
necessary modiﬁcation can be found in the appendix at the end of this chapter.
A reader familiar with examples from the dynamical systems literature might
have noticed that the iteration (1.6) reduces to the tent map iteration with
a = 1 and the interval [−1/2, 1/2] shifted to [0, 1]. The factor a > 0 controls the
amplitude of the forcing and the interval has been shifted such that the forcing is
centred about zero. We choose this for the surrogate physical process since it is
completely reproducible in exact arithmetic, but has very complicated dynamics
that can appear random.
The numerical solutions obtained from an application of (1.2) for n = 0, . . . ,
N −1 with N = 2 × 105 lead to a time-continuous reference solution zref(t)

4
Prologue: how to produce forecasts
20
10
0
10
20
40
20
0
20
40
0
10
20
30
40
50
x component
Lorenz attractor
y component
z−component
Figure 1.1 Trajectory of the modiﬁed Lorenz-63 model as described in Example 1.1.
This trajectory provides us with the desired surrogate physical process. The cloud of
solution points is part of what is called the model attractor.
according to the interpolation formula (1.3) for time t ∈[0, 200], which is used
for all experiments conducted in this chapter. See Figure 1.1 for a phase portrait
of the time series. Solutions asymptotically ﬁll a subset of phase space R3 called
the model attractor.
Next, we turn our attention to the second ingredient in the prediction problem,
namely the measurement procedure. In this setting, neither zref(t) nor (1.2) will
be explicitly available to us. Instead, we will receive “observations” or “measure-
ments” of zref(t) at various times, in the form of measured data containing partial
information about the underlying physical process, combined with measurement
errors. Hence we need to introduce a mathematical framework for describing
such partial observations of physical processes through measurements.
We ﬁrst consider the case of an error-free measurement at a time t, which we
describe by a forward map (or operator) h : RNz →RNy
yobs(t) = h(zref(t)),
(1.7)
where we typically have Ny < Nz (corresponding to a partial observation of the
system state zref). For simplicity, we shall only consider Ny = 1 in this chapter.
Since h is non-invertible, we cannot deduce zref(t) from simple inversion, even if
the measurements are free from errors.
More realistically, a measurement device will lead to measurement errors,
which may arise as the linear superposition of many individual errors ηi ∈R,
i = 1, . . . , I. Based on this assumption, we arrive at a mathematical model of

1.1 Physical processes and observations
5
-
t0
t1
t2 · · ·
t1 = tNout
t2 = t2Nout
t3
t4
Figure 1.2 Diagram illustrating model timesteps t0, t1, etc. and observation times
t1 = tNout, t2, etc. Here, Nout = 5.
type
yobs(t) = h(zref(t)) +
I

i=1
ηi(t).
(1.8)
The quality of a measurement is now determined by the magnitude of the in-
dividual error terms ηi and the number I of contributing error sources. Mea-
surements will only be taken at discrete points in time, separated by intervals of
length Δtout > 0. To distinguish the discrete model time tn = n δt from instances
at which measurements are taken, we use Gothic script to denote measurement
points, i.e.,
tk = k Δtout,
k ≥1,
and Δtout = δtNout for given integer Nout ≥1. This is illustrated in Figure 1.2.
We again consider a speciﬁc example to illustrate our “measurement proce-
dure” (1.8).
Example 1.2
We consider the time series generated in Example 1.1 and assume
that we can observe the x-component of
zref(t) = (xref(t), yref(t), zref(t))T ∈R3.
This leads to a linear forward operator of the form
h(zref(t)) = xref(t).
In this example, we shall use a modiﬁed tent map of type (1.6) to model
measurement errors. More speciﬁcally, we use the iteration
ξk+1 =
 2ξk + a/2
if ξk ∈[−a/2, 0),
−2ξk + a/2
otherwise,
(1.9)
with a = 4 and starting value ξ0 = a(2−1/2 −1/2) for k ≥0. From this sequence
we store every tenth iterate in an array {Ξi}i≥1, i.e.,
Ξi = ξk=10i,
i = 1, 2, . . . .
(1.10)
An observation xobs at time t1 = Δtout = 0.05 is now obtained as follows:
xobs(t1) := xref(t1) + 1
20
20

i=1
Ξi.
This procedure ﬁts into the framework of (1.8) with I = 20 and ηi(t1) = Ξi/20,
i = 1, . . . , 20.

6
Prologue: how to produce forecasts
0
2
4
6
8
10
20
10
0
10
20
time
x−coordinate
observed values
0
2
4
6
8
10
1
0.5
0
0.5
1
time
x−coordinate
measurement error
Figure 1.3 Observed values for the x-component and their measurement errors over the
time interval [0, 10] with observations taken every Δtout = 0.05 time units.
For the next observation at t2 = 2Δtout = 0.1 we use
xobs(t2) = xref(t2) + 1
20
40

i=21
Ξi,
and this process is repeated for all available data points from the reference tra-
jectory generated in Example 1.1. Numerical results are displayed for the ﬁrst
200 data points in Figure 1.3. Our procedure of deﬁning the measurement errors
might appear unduly complicated, but we will ﬁnd later in Chapter 2 that it
mimics important aspects of typical measurement errors. In particular, the mea-
surement errors can be treated as random even though a perfectly deterministic
procedure has deﬁned them.
1.2
Data driven forecasting
We now assume that Nobs scalar observations yobs(tk) ∈R at tk = k Δtout,
k = 1, 2, . . ., Nobs, have been made at time intervals of Δtout. To deﬁne what we
understand by a forecast or a prediction, we select a point in time tk∗that we
denote the present. Relative to tk∗, we can deﬁne the past t < tk∗and the future
t > tk∗. A possible forecasting (or prediction) problem would be to produce an
estimate for
yref(t) := h(zref(t))

1.2 Data driven forecasting
7
with t > tk∗and only observations from the past and present available. Such
statements can be veriﬁed as soon as a future moment becomes the present and
a new measurement becomes available. More generally, we would, of course, like
to make predictions about the complete surrogate process zref(t) for t > tk∗and
not only about the quantity we can actually observe. We will come back to this
more challenging task later in this chapter.
Returning to the problem of predicting future observations, we ﬁrst utilise the
concept of polynomial interpolation. Recall that there is a unique polynomial
q(t) = b0 + b1t + b2t2 + · · · + bptp
(1.11)
of order p with coeﬃcients bl through any p + 1 data points. We would like
to ﬁnd a polynomial that interpolates observations at p + 1 present and past
observation times {tk∗, tk∗−1, . . . , tk∗−p} with the aim of using it to predict future
observations. This leads to the interpolation conditions
q(tk) = yobs(tk),
tk ∈{tk∗, tk∗−1, . . . , tk∗−p},
which determine the p + 1 coeﬃcients bl in (1.11) uniquely. A predicted observa-
tion at t > tk∗is then simply provided by q(t). Since t is outside the interval of
the observed data points, the prediction is an extrapolation from the data. For
the linear case p = 1 we obtain
q(t) = yobs(tk∗) + (t −tk∗)yobs(tk∗) −yobs(tk∗−1)
tk∗−tk∗−1
= yobs(tk∗) + (t −tk∗)yobs(tk∗) −yobs(tk∗−Δtout)
Δtout
.
Upon setting t = tk∗+1 we obtain the extrapolation formula
ypredict(tk∗+1) := q(tk∗+1) = 2yobs(tk∗) −yobs(tk∗−1).
(1.12)
As soon as yobs(tk∗+1) becomes available, we can compare this prediction with
the observed value. Furthermore, we can use this new observation point (and
discard the oldest one from tk∗−1) and a correspondingly updated linear extrap-
olation formula to obtain ypredict(tk∗+2). This can be iterated over several time
intervals, repeatedly using data to predict the new observation. To assess the
accuracy of this procedure we introduce the following measure.
Definition 1.3 (Root mean square error)
For a set of predictions and obser-
vations at times {t1, t2, . . . , tN} the root mean square error (RMSE) is given
by
time averaged RMSE =

	
	

 1
N
N

k=1
|yobs(tk) −ypredict(tk)|2.
(1.13)
In the case of linear interpolation, if there are Nobs observations then N =
Nobs −2 since we cannot make predictions using linear interpolation for the ﬁrst
two observations.

8
Prologue: how to produce forecasts
We illustrate the linear interpolation prediction strategy by our next example.
Example 1.4
We utilise the observations generated in Example 1.2 for the ﬁrst
solution component of the Lorenz-63 system, i.e., yobs(tk) = xobs(tk). Recall that
the observation interval is Δtout = 0.05. We set the ﬁrst tk∗equal to tk∗= 100,
and make a total of 2000 veriﬁable predictions until we reach t = 200. The linear
extrapolation formula (1.12) is used for making predictions of observations, and
the quality of these predictions is assessed using the time averaged RMSE (1.13)
with N = 2000. A snapshot of the computational results over a short time-
window can be found in Figure 1.4. The time averaged RMSE over the whole
interval is approximately 1.2951.
It is usually desirable to “extend the prediction window” by making predictions
further into the future. In view of this, we modify the procedure so that at each
time tk∗, we attempt to predict the observation at time tk∗+2 instead of tk∗+1.
The associated linear extrapolation formula becomes
ypredict(tk∗+2) := q(tk∗+2) = 3yobs(tk∗) −2yobs(tk∗−1).
The results can also be found in Figure 1.4; the quality of the predictions is
clearly worse over this larger window. This is conﬁrmed by the time averaged
RMSE which increases to approximately 3.3654.
The results of Example 1.4 show that linear interpolation does not provide
good predictions over longer times. This suggests the accuracy of forecasts can
be improved by extending the extrapolation formula (1.12) to use a linear com-
bination of the present data point plus several previous data points of the form
ypredict(tk∗+1) =
p

l=0
al yobs(tk∗−l).
(1.14)
We have already seen that linear extrapolation ﬁts into this framework with
p = 1 and coeﬃcients a0 = 2, a1 = −1. We recall that the linear extrapolation
formula (1.12) was based on ﬁrst deriving the linear interpolation formula. Hence,
as a ﬁrst attempt at deriving coeﬃcients al for (1.14) with p > 1, we shall use
higher-order interpolation formulas. Interpolation formulas of order p can be
conveniently based on the Lagrange polynomials (S¨uli & Mayers 2006) of order p
lj(t) =

i̸=j(t −ti)

i̸=j(tj −ti),
where the indices i and j run over the integers
{k∗, k∗−1, . . . , k∗−p}.
These polynomials have the useful property that
lj(ti) =
 1
if j = i,
0
otherwise,

1.2 Data driven forecasting
9
100
101
102
103
104
105
30
20
10
0
10
20
30
time
x−coordinate
observed and predicted values
prediction
observed
100
101
102
103
104
105
30
20
10
0
10
20
30
time
x−coordinate
observed and predicted values
prediction
observed
Figure 1.4 Observed values for the x-component and its predicted values using linear
extrapolation. The ﬁgure at the top shows the results from linear extrapolation over a
single observation interval Δtout = 0.05, while the ﬁgure beneath shows results when
doubling the prediction interval to 0.1 time units.
which leads to the interpolation formula
q(t) = lk∗(t) yobs(tk∗) + lk∗−1(t) yobs(tk∗−1) + · · · + lk∗−p(t) yobs(tk∗−p). (1.15)
The coeﬃcients al in (1.14) are obtained by setting t = tk∗+1 in (1.15), i.e.
al = lk∗−l(tk∗+1),
l = 0, 1, . . ., p.

10
Prologue: how to produce forecasts
0.2
0.15
0.1
0.05
0
0.05
10
8
6
4
2
0
2
4
6
8
10
time
Lagrange polynomials for p = 4
Figure 1.5 Lagrange polynomials lj(t) of order four corresponding to observations at
ti = 0, −0.05, −0.1, −0.15, −0.2. The coeﬃcients al in (1.14) are equal to the values of
the Lagrangian polynomials at t = 0.05. Crosses mark the points where each polynomial
takes the value one. Note that the other polynomials are zero at those interpolation
points, and note the steep increase in magnitude outside the interpolation interval
t ∈[−0.2, 0].
Example 1.5
We consider extrapolation based on polynomial interpolation of
order p = 4. The associated extrapolation coeﬃcients in (1.14) are
a0 = 5, a1 = −10, a2 = 10, a3 = −5, a4 = 1,
and the associated Lagrange polynomials are shown in Figure 1.5, taking tk∗= 0
for simplicity. The values of the extrapolation coeﬃcients can be obtained by
inspecting the intersection of the Lagrange polynomials with the vertical line at
t = 0.05.
The results of applying the fourth-order extrapolation formula to the data
set from Example 1.2 are shown in Figure 1.6; the time averaged RMSE was
4.2707. This error is much larger than that observed for linear extrapolation
(compare Example 1.4). The reason for this discrepancy can be found in the
strong separation of the Lagrange polynomials outside the interpolation interval
(compare Figure 1.5), which results in relatively large coeﬃcients al in (1.14).
Hence even relatively small measurement errors can be severely ampliﬁed and do
not necessarily cancel out. This eﬀect becomes even more pronounced when the
prediction interval is doubled to 2Δtout. The associated extrapolation coeﬃcients
are now given by
a0 = 15, a1 = −40, a2 = 45, a3 = −24, a4 = 5.

1.2 Data driven forecasting
11
100
101
102
103
104
105
30
20
10
0
10
20
30
time
x−coordinate
observed and predicted values
prediction
observed
100
101
102
103
104
105
30
20
10
0
10
20
30
time
x−coordinate
observed and predicted values
prediction
observed
Figure 1.6 Observed values for the x-component and its predicted values using
fourth-order extrapolation. The ﬁgure at the top shows the results from extrapolation over
a single observation interval Δtout = 0.05 while the ﬁgure beneath shows results for
doubling the prediction interval to 0.1 time units. Compare these results to those
displayed in Figure 1.4 for linear extrapolation.
See Figure 1.6 for numerical results.
We now discuss an entirely diﬀerent approach for determining the coeﬃcients
al in (1.14). Instead of using polynomial interpolation, we shall seek the coeﬃ-
cients that optimise the prediction errors for a chosen subset of the observations,

12
Prologue: how to produce forecasts
which we call the training set. These extrapolation coeﬃcients are then ﬁxed,
and can be used to predict future observations. We shall assess the performance
of our extrapolation coeﬃcients on the remaining observation points, which we
shall call the test set. For simplicity, let us assume that the training set con-
sists of the ﬁrst NT < Nobs observations {yobs(t1), . . . , yobs(tNT)}, and use the
remaining data points as the test set.
Given a chosen set of coeﬃcients al ∈R, l = 0, . . . , p, we can obtain a predic-
tion of yobs(tj+p+1) for 0 < j ≤NT −p −1 by using (1.14). The quality of the
predictions is measured by the residuals
rj = yobs(tj+p+1) −ypredict(tj+p+1)
= yobs(tj+p+1) −
p

l=0
alyobs(tj+p−l)
(1.16)
for j = 1, 2, . . ., J with J = NT −p −1. We now seek the coeﬃcients al in (1.14)
such that the resulting time averaged RMSE is minimised over the training set.
This is equivalent to minimising the functional
L({al}) = 1
2
J

j=1
r2
j ;
we have recovered the method of least squares.
The minimum of L({al}) is
attained when the partial derivatives of L with respect to the coeﬃcients al
vanish, i.e.,
∂L
∂al
= −
J

j=1
yobs(tj+p−l) rj = 0
(1.17)
for l = 0, . . . , p. These conditions lead to p + 1 linear equations which may be
solved for the p + 1 unknown coeﬃcients al.
Once an optimal set of coeﬃcients al has been found, these coeﬃcients can be
used in (1.14) to make predictions over the test set. The underlying assumption
is that the training and test sets display a similar behaviour. Mathematically
speaking, this relies on the assumption of stationarity of the time series of ob-
servations. See Chorin & Hald (2009) for more details.
We mention in passing that (1.14) with coeﬃcients al determined by the
method of least squares may be considered as a particular instance of an au-
toregressive model of order p + 1. The class of autoregressive models provides an
example of purely data driven models.
Example 1.6
We return again to the setting from Example 1.4. We replace the
linear extrapolation procedure by predictions using (1.14) with the coeﬃcients al
determined by the method of least squares. We ﬁnd that setting p = 4 in (1.14)
and a training set with NT = Nobs/2 = 2000 leads to a time averaged RMSE of

1.2 Data driven forecasting
13
0.9718 with coeﬃcients
a0 = 2.0503, a1 = −1.2248, a2 = −0.2165, a3 = 0.4952, a4 = −0.1397.
Note that these values ﬂuctuate much less about the observed values than those
obtained from fourth-order interpolation (compare Example 1.5) and that the
values for a0 and a1 are relatively close to those obtained from linear extrapo-
lation (compare (1.12)). Hence we may argue that the method of least squares
leads to a modiﬁed linear extrapolation procedure with a slight reduction in the
time averaged RMSE.
We also apply the same methodology to predict y at tk∗+2 (prediction over
2Δtout = 0.01) and ﬁnd that the averaged RMSE increases to 2.3039. See Figure
1.7 for some numerical results.
The mathematical structure of the least squares approach becomes more trans-
parent when put into matrix notation. We ﬁrst collect the unknown coeﬃcients
al into a vector
x =
⎛
⎜
⎜
⎜
⎝
a0
a1
...
ap
⎞
⎟
⎟
⎟
⎠∈Rp+1
and the residuals rj into a vector
r =
⎛
⎜
⎜
⎜
⎝
r1
r2
...
rJ
⎞
⎟
⎟
⎟
⎠∈RJ.
Next we write (1.14) as
r = b −Ax,
where b ∈RJ is deﬁned by
b =
⎛
⎜
⎜
⎜
⎝
yobs(tp+2)
yobs(tp+3)
...
yobs(tp+J+1)
⎞
⎟
⎟
⎟
⎠∈RJ
and the matrix A ∈RJ×(p+1) by
A =
⎛
⎜
⎜
⎜
⎝
yobs(tp+1)
yobs(tp)
· · ·
yobs(t1)
yobs(tp+2)
yobs(tp+1)
· · ·
yobs(t2)
...
...
...
yobs(tp+J)
yobs(tp+J−1)
· · ·
yobs(tJ)
⎞
⎟
⎟
⎟
⎠.

14
Prologue: how to produce forecasts
100
101
102
103
104
105
30
25
20
15
10
5
0
5
10
15
20
time
x−coordinate
observed and predicted values
prediction
observed
100
101
102
103
104
105
30
25
20
15
10
5
0
5
10
15
20
time
x−coordinate
observed and predicted values
prediction
observed
Figure 1.7 Observed values of the x-component and corresponding predicted values
using the method of least squares with p = 4 in (1.14). The ﬁgure on the top shows the
results from predictions over a single observation interval Δtout = 0.05, and the ﬁgure
beneath shows results when doubling the prediction interval to 0.1 time units. The results
should be compared to those in Figures 1.4 and 1.6 obtained from extrapolation.
For square matrices A (i.e., J = p + 1) with det(A) ̸= 0 we recall that x can be
determined such that r = 0 and
x = A−1b.
However, in practice we are usually dealing with the case of overdetermined
systems of equations for which J ≫p + 1 and for which there is in general no x

1.3 Model driven forecasting and data assimilation
15
such that r = 0. The method of least squares determines x∗∈Rp+1 such that
the norm of the vector r is minimised, i.e.,
x∗= arg min ∥r∥2 = arg min ∥Ax −b∥2.
We ﬁnd that the gradient of the functional L(x) = ∥Ax −b∥2 with respect to x
is given by
∇xL(x) = 2AT(Ax −b) ∈Rp+1.
Here AT ∈R(p+1)×J denotes the transpose of A. Furthermore, the Hessian (ma-
trix of second derivatives) of L(x) is
H = 2ATA ∈R(p+1)×(p+1),
which is positive deﬁnite when A has maximum column rank p + 1. If this is the
case, then setting ∇L(x∗) = 0 leads to the following equation for x∗,
ATAx∗= ATb.
We can conﬁrm that we have a minimiser of L(x) since
L(x∗+ δx) = L(x∗) + ∇xL(x∗)Tδx + δxTATAδx
= L(x∗) + δxTATAδx
> L(x∗),
for all vectors δx ̸= 0.
1.3
Model driven forecasting and data assimilation
So far in this chapter, we have used observations and elementary mathematical
tools to design linear models for predicting future outcomes in the observable
variable y = h(z). More precisely, we have considered mathematical tools that
rely on the observed quantities alone, without any reference to our surrogate
physical process from which they were generated. The predictions were con-
strained by the assumption of a polynomial form in time, or by optimising the
coeﬃcients over a training set. These models are often described as empirical
or bottom-up. We now introduce our third ingredient, the use of mechanistic or
top-down models of the physical process that are derived from ﬁrst principles, a
process well established in the context of classical mechanics (Arnold 1989), for
example. In practice such ﬁrst principles might be provided by conservation of
mass and/or energy or by Newton’s laws of motion, or other analogues in e.g.
biology, sociology or economics. Given an estimate of the system state z(t0) at
time t0, a model allows us to obtain estimates of the system state z(t) for t > t0.
In almost all cases the model is imperfect, and model errors lead to increased
errors in the state estimate over time, unless it is corrected by introducing more
data at later times.

16
Prologue: how to produce forecasts
In the somewhat artiﬁcial setting of this chapter, we imagine that understand-
ing of the surrogate physical process has allowed us to derive a model from ﬁrst
principles, in the form of the diﬀerence equation
zn+1 = zn + δtf(zn),
tn+1 = tn + δt.
(1.18)
In this case, we have chosen a scenario where the diﬀerence between the surrogate
physical process, as provided by (1.2), and our mechanistic model, as given by
(1.18), is simply in the inclusion or omission of the time-dependent driving term
g(t). This allows us to easily quantify the impact of the error. In practice, when
data are obtained from an observed physical process, quantifying this error is a
much more diﬃcult problem. In our case, provided that we have exact knowledge
of the state zn
ref of our surrogate physical process at time tn and provided we use
this information in order to set zn
model = zn
ref in our mechanistic model, the one
step ahead prediction error en+1 = zn+1
model −zn+1
ref
is given by
en+1 = −δt g(tn),
tn = n δt.
(1.19)
We will also call en the model error since en reﬂects the diﬀerence between
(1.2), our surrogate physical process, and (1.18), our mechanistic model for this
process. One speciﬁc type of model errors are discretisation errors that arise
when mechanistic models are approximated numerically. We will return to the
issue of discretisation errors in Chapter 4.
At this point two major challenges arise. First, we wish to predict over time
intervals much larger than δt. Second, we can only partially observe the present
states of the underlying physical process in intervals of Δtout; we do not have
access to the full state vector zref(t) at any moment in time. The ﬁrst diﬃculty
requires us to assess the propagation and accumulation of model errors over
several timesteps, under the hypothetical assumption that both the physical
process and the mechanistic model start from the same initial state z0 at t0 = 0.
We explore this in the next example.
Example 1.7
We return to Example 1.1 and simulate (1.18) with the vector
ﬁeld f(z) given by (1.4). We then compare the surrogate physical process as
simulated in Example 1.1.
The numerical solution obtained from an application of (1.18) is stored over a
time interval t0 = 0 to tend = 200 in intervals of Δtout = 0.05. These 3×4001 data
points provide us with the model output zmodel(tk) at tk = k Δtout, which can
be compared to the reference trajectory zref(tk) from Example 1.1. We plot the
phase portrait of the time series from our mechanistic model in Figure 1.8. The
result looks rather similar to the phase portrait displayed in Figure 1.1, which
indicates that our mechanistic model is able to capture qualitative aspects of the
surrogate physical process.
We next check whether this property carries over to speciﬁc predictions. In
order to assess this aspect of our mechanistic model, both the mechanistic model
and physical process are started from the same initial condition (1.5) at time t0 =

1.3 Model driven forecasting and data assimilation
17
20
10
0
10
20
40
20
0
20
40
0
10
20
30
40
50
x component
Lorenz attractor
y component
z−component
Figure 1.8 Long trajectory from our mechanistic model which traces the Lorenz
attractor of our model. The shape of the attractor is nearly identical to that displayed in
Figure 1.1.
0. We display the results in all three state variables over a time interval [0, 10] in
Figure 1.9. A diﬀerence in the solutions becomes noticeable at about t = 2; this is
much longer than the prediction intervals obtained for linear interpolation and/or
an autoregressive model obtained from the method of least squares. However, this
comparison is unrealistic as we require the precise knowledge of the initial state
in order to make predictions based on our mechanistic model. Indeed, the exact
initial or present state is unavailable in most practical applications.
The previous example has demonstrated that the use of mechanistic models
can lead to skilful predictions over relatively long time intervals, provided the
model state from which we start our prediction is suﬃciently close to the state
of the physical process under consideration at the initial time. It should also be
obvious that the quality of model-based predictions will depend on the relative
magnitude of the modelling errors en and the subsequent systematic contribu-
tions from δtf(zn) in (1.18).
From these ﬁndings we conclude that (i) we need methods for estimating
appropriate initial conditions for our mechanistic model from the available ob-
servations; and that (ii) we should strive to improve our mechanistic models by
making the unaccounted contributions from g(t) as small as possible. Both tasks
can be addressed by clever combinations of mechanistic models with observa-
tional data. Associated computational techniques are often referred to as data
assimilation in the geosciences and ﬁltering/smoothing in the engineering com-
munity. Throughout this book we will primarily use the term data assimilation,

18
Prologue: how to produce forecasts
0
1
2
3
4
5
6
20
0
20
time
x−variable
solutions
reference
model
0
1
2
3
4
5
6
50
0
50
time
y−variable
0
1
2
3
4
5
6
0
50
time
z−variable
0
0.5
1
1.5
2
2
0
2
x−variable
error
time
0
0.5
1
1.5
2
5
0
5
y−variable
time
0
0.5
1
1.5
2
5
0
5
time
z−variable
Figure 1.9 We compare the behaviour of our mechanistic model to the reference
trajectory under the assumption that both start from the same initial condition at time
t = 0. The diﬀerences between the model and nature are caused by the non-autonomous
driving terms gn = g(tn) in (1.2) and their accumulative eﬀect. These diﬀerences become
signiﬁcant at about t = 2 as can be seen from the bottom panel, which displays the
diﬀerences in all three solution components as a function of time.
which, broadly speaking, covers the task of combining mechanistic models with
partial observations in order to produce skilful forecasts.
To give a ﬂavour of what is to come in Part II of this book, we present an
application of the method of least squares to the state estimation of a mechanistic
model (1.18). Let us assume that observations yobs(tk) are available at time

1.3 Model driven forecasting and data assimilation
19
instances
tk = k Δtout,
k = 1, . . . , NA,
where Δtout = Noutδt for given integer Nout ≥1. Starting from the initial
condition z0 at t = 0, kNout applications of (1.18) produces a model solution
zmodel(tk) and a simulated observation ymodel(tk) = h(zmodel(tk)), which can be
compared to the observed value yobs(tk). The diﬀerences between simulated and
true observations is measured in a residual
rk = ymodel(tk) −yobs(tk) = h(zmodel(tk)) −yobs(tk),
k = 1, . . . , NA.
The residual implicitly depends on the model initial condition z0, since this
changes the entire model trajectory and therefore the simulated observations
ymodel(tk). To simplify the discussion, we will assume that the forward operator
h is linear and is represented by a row vector H ∈R1×Nz, i.e.,
h(z) = Hz.
Adopting the method of least squares, we seek the initial condition z0 that
minimises the residual sum
L(z0) = 1
2
NA

k=1
r2
k.
(1.20)
We denote a minimiser by z0
∗, and recall from elementary calculus that z0
∗has
to be a critical point of L to be a candidate for a minimum, i.e., the gradient
∇z0L(z0) ∈RNz has to vanish at z0 = z0
∗. In contrast with the linear least
squares method considered previously, we now must solve systems of nonlinear
equations to ﬁnd critical points of L. These critical points may correspond to
local minima or even maxima. The main complication arises from the nonlinear
dependence of zmodel(tk) on z0. In order to make this dependence explicit, we
introduce the map ψ as a shorthand for the Nout-fold application of (1.18), i.e.
if we deﬁne
zmodel(tk+1) = ψ(zmodel(tk)),
k ≥0,
then
zmodel(tk) = ψk(z0) :=
ψ(ψ(· · · ψ(z0)))



k-fold application of ψ
.
(1.21)
Computing the gradient of L(z0) requires the Jacobian matrix of ﬁrst derivatives
of zmodel(tk) ∈RNz with respect to the initial condition z0 ∈RNz, given by
Dzmodel(tk) := Dψk(z0) ∈RNz×Nz.
The Jacobian can be computed from (1.21) directly or using the following recur-
sive approach. First we note that a single application of (1.18) leads to
Dz1 := D(z0 + δtf(z0)) = I + δtDf(z0),

20
Prologue: how to produce forecasts
since Dz0 = I and Df(z) ∈RNz×Nz denotes the Jacobian matrix of partial
derivatives of f(z). The calculation of Dz2 can now be decomposed into
Dz2 := D(z1 + δtf(z1)) = (I + δtDf(z1)) Dz1,
using the chain rule of diﬀerentiation. More generally, one ﬁnds the recursion
Dzn+1 = (I + δtDf(zn)) Dzn
(1.22)
for n ≥0 with Dz0 equal to the identity matrix. Upon setting n = kNout, we
obtain the desired expression for the Jacobian Dψk(z0) and the gradient of L is
given by
∇z0L(z0) =
NA

k=1
(Dψk(z0))THTrk.
(1.23)
The minimiser z0
∗must satisfy
∇z0L(z0
∗) = 0.
Later in this book we will show that an explicit calculation of the Jacobian
Dzmodel(tk) via the recursion (1.22) is not necessary for determining (1.23). We
emphasise again that, in contrast with the linear method of least squares, the
existence and uniqueness of a critical point of L is often not guaranteed a priori.
In addition, critical points may correspond to local maxima or saddle points
instead of minima.
A (local) minimum of L can be searched for by the gradient or steepest decent
method, which is an iteration of the form
z(l+1) = z(l) −α∇z0L(z(l))
(1.24)
for l ≥0 and an appropriate initial guess z(0). The coeﬃcient α > 0 needs to be
chosen suﬃciently small in order to guarantee
L(z(l+1)) ≤L(z(l))
throughout the iteration process. More reﬁned gradient methods would choose
the coeﬃcient α adaptively (see Nocedal & Wright (2006), for example).
Let us assume that we have obtained a reasonable estimate for the initial
state z0 of our mechanistic model and that a series of NA observations within
the assimilation window become available at t1, . . . , tNA. Then we can iterate
(1.24) with starting value z(0) = z0 until
∥∇z0L(z(l∗))∥≤ε,
(1.25)
where ε > 0 is a desired tolerance. The resulting z0
∗= z(l∗) is often called the
analysis at t = 0 and we have completed what is often called a variational data
assimilation cycle.
Once the analysis z0
∗has been obtained, we can use the mechanistic model
(1.18) with adjusted initial condition z0 = z0
∗to obtain forecasts zmodel(t) for t >
tNA. In due course, a new sequence of observations yobs(tNA+k), k = 1, . . . , NA,

1.3 Model driven forecasting and data assimilation
21
-
t0
t1
t2 · · ·
tNA
t2NA
t3NA
t4NA
assimilation interval 1
assimilation interval 2
assimilation interval 3
assimilation interval 4
Figure 1.10 Diagram illustrating model time-steps, observation times, and assimilation
intervals. At the end of each assimilation window, a new trajectory is computed that uses
the observations made during that window.
becomes available. At this point a new data assimilation cycle can be initiated.
More speciﬁcally, we can repeat the above nonlinear least squares method by
minimising the cost functional L(z0) with residuals rk, k = 1, . . . , NA, now given
by
rk = Hψk(z0) −yobs(tNA+k)
and starting value z(0) = zmodel(tNA) in (1.24).3 The information from the pre-
vious sequence of observations feeds in via the choice of initial condition for the
steepest descent calculation, which may select a particular local minimum; this
may also speed up the calculation by starting closer to the minimum. It is often
also desirable to make better use of this information by including a penalty term
in the functional that becomes large if z0 gets too far from this initial guess, en-
coding our belief that the previous data assimilation cycle gave us a good guess
for the current system state. This presents a diﬃculty: we must then decide how
much weight in the functional to give the previous forecast relative to the new
observational data. We leave this problem for now, but it is a central topic for
the rest of the book.
In contrast with the forecasted values zmodel(t), t > tNA, which do not make
use of the observations yobs(tNA+k), k ≥1, the minimiser z0
∗of L now provides
an improved approximation zmodel(t), called the analysis, using the mechanistic
model (1.18) with adjusted initial condition zmodel(tNA) = z0
∗. In order to distin-
guish the forecast from the analysis we introduce the notation zf
model(tk) for the
forecast at time tk, k = NA + 1, . . . , 2NA, and za
model(tk) for the analysis arising
from the adjusted initial condition at tNA.
Once time t is increased beyond t = t2NA the analysis za
model(t) becomes
a forecast and, as soon as all necessary observations have become available,
za
model(t2NA) is taken as the starting value z(0) for the next assimilation cycle
covering the interval [t2NA, t3NA]. The process of producing forecasts with the
mechanistic model and correcting them by assimilating available observations
over ﬁnite time intervals can now be repeated as often as desired, as illustrated
in Figure 1.10.
Each data assimilation cycle eﬀectively leads to a nudging of the model output
towards observations. In other words, the sequence of data assimilation cycles
3 The simpliﬁcation of always minimising with respect to z0 and only changing the
observations in the deﬁnition of the residuals rk is possible since our mechanistic model
(1.18) is assumed to be time independent.

22
Prologue: how to produce forecasts
0
2
4
6
8
10
20
15
10
5
0
5
10
15
20
time
x solution component
analysis
reference
0
2
4
6
8
10
5
10
15
20
25
30
35
40
45
time
z solution component
analysis
reference
Figure 1.11 We display the results from 40 data assimilation cycles each over a window
of length 5 Δtout = 0.25. Only the x-variable is observed in intervals of Δtout = 0.05. The
synchronising eﬀect of the nonlinear least squares approach can be clearly seen both in
the x variable and the unobserved z variable, while the model output without adjustments
from the data assimilation cycles loses track of the underlying physical process at about
t = 2. Compare Figure 1.9.
should ideally synchronise the model (1.18) with the physical process via partial
observations and corresponding adjustments in model forecasts zf
model(tmNA),

1.3 Model driven forecasting and data assimilation
23
1.5
1.6
1.7
1.8
1.9
2
2.1
2.2
0
2
4
6
8
10
12
14
16
time
x solution component
forecast (x) and analysis (o)
Figure 1.12 We display the forecast (which does not take the observations into
account) and the analysis (which has assimilated the observations) for three data
assimilation cycles. The forecast is in blue and marked with crosses, and the analysis is in
red and marked with circles. At the beginning of each assimilation window, the previous
forecast terminates, the most recent analysis turns into a forecast and eventually provides
the starting value for the next assimilation cycle. This can be best seen at t = 1.75, where
the upper cross marks the last step of the forecast starting at t = 1.5. The circles between
t = 1.5 and t = 1.75 represent the subsequent analysis using the data available from that
interval. The next forecast (crosses) starts from the last analysis (circle) at t = 1.75. This
forecast window ranges from t = 1.75 to t = 2.0. The process then repeats, and this new
forecast is modiﬁed by the data available from the interval [1.75, 2.0]. This data
assimilation step provides the second, lower circle at t = 2.0 as well as the starting value
of a new forecast over the interval [2.0, 2.25].
m ≥1. The most recently adjusted model state is then used as an initial condition
for model-based forecasts further into the future.
We now demonstrate this synchronising eﬀect with our “mechanistic” Lorenz-
63 model from Example 1.7.
Example 1.8
We implement the nonlinear least squares method for the Lorenz-
63 model already investigated in Example 1.7. Recall that the model output
deviates from the surrogate physical process after a relatively short time interval
even if both the mechanistic model (1.18) and the reference model (1.2) are
started from identical initial conditions at t0 = 0. We now consider sequences of
NA = 5 observations with observation interval Δtout = 0.05 in order to adjust
the model’s initial states over each data assimilation window [tmNA, t(m+1)NA]
with m = 0, 1, 2, . . ., 39. See Figure 1.11 for a comparison between the reference
trajectory zref(t) and the analysis za
model(t) over all 40 assimilation cycles, and

24
Prologue: how to produce forecasts
4
3
2
1
0
1
2
3
4
0
0 1
0 2
0 3
0 4
0 5
0 6
0 7
0 8
error in x component
Relative frequencies of binned differences
4
3
2
1
0
1
2
3
4
0
0 1
0 2
0 3
0 4
0 5
0 6
0 7
0 8
error in z component
Relative frequencies of binned differences
Figure 1.13 Relative frequencies of binned diﬀerences between the reference solution
and the analysis, in both x and z. It is tempting to view these relative frequencies as
arising from ﬁnite samples of an underlying random variable with unknown speciﬁcations.
We could then discuss the probability of an analysis falling within a certain range of the
(generally unavailable explicitly) true system state. It is a task of uncertainty
quantiﬁcation to characterise such probabilities.
Figure 1.12 for a zoomed region displaying the diﬀerence between model forecasts
zf
model(t) and their analysis za
model(t). The nonlinear method of least squares
is implemented with step-length α = 0.025 in the gradient method (1.24) and
ε = 0.01 in (1.25). This small value of α is necessary in order to avoid a divergence
of (1.24). More eﬃcient minimisation methods could be implemented but are
outside the scope of this book.
In practical applications, such as weather forecasting, it is desirable to obtain a
priori estimates of the likelihood of an analysis being within a certain range of the
(generally not explicitly available) true system state. This gives an indication of
how seriously to take the forecast; this is crucial when using forecasts in decision-
making and planning. We display a histogram of the resulting diﬀerences between
the reference solution zref(t) and the analysis za
model(t) in Figure 1.13. Note, for
example, that the errors in the z-component have a much broader distribution
than those in the x-component. More abstractly, we will view histograms, such as
the ones displayed in Figure 1.13, as resulting from ﬁnite samples of underlying
random variables with generally unknown distribution. It is a task of uncertainty
quantiﬁcation to provide as much information about these random variables as
possible.
We have already mentioned that the analysis can be used to generate forecasts
over time intervals where observations have not yet been obtained. In order to
illustrate this aspect of data assimilation we use the analysis za
model(t) at time
t = 10 as the initial condition for our model (1.18) at t = 10. We then run this

1.3 Model driven forecasting and data assimilation
25
10
11
12
13
14
15
20
15
10
5
0
5
10
15
20
time
x solution component
model from analysis at t = 10
reference
Figure 1.14 Forecast started from the analysis at time t = 10 and reference solution
from the surrogate physical process. It can be seen that the forecast stays close to the
reference solution for about two time units after which its starts diverging due to errors in
the analysis and model errors.
model over the time interval [10,15] in order to produce a forecast which can
be compared to the reference solution zref(t) of our surrogate physical process
over the same time interval. The result is displayed in Figure 1.14, where it
can be seen that the forecast stays close to the reference solution up to time
t ≈12. It is a task of uncertainty quantiﬁcation to quantify the actual forecast
uncertainties without explicit knowledge of the reference solution. In addition
to analysis errors, forecast errors will be also treated as random variables. We
will learn about computational methods for estimating their distributions later
in this book.
We conclude this example by emphasising that the nonlinear least squares
method is sensitive to the length of the assimilation window. If the window is
chosen too large, then the data assimilation procedure leads to a divergence of
the gradient method (1.24) due to the increasingly nonlinear behaviour of the
functional L. We also found that a shorter window of 2Δtout (i.e. two observations
per assimilation cycle) leads to results similar to those displayed in Figure 1.11 for
ﬁve observations per assimilation cycle. This is surprising, since with NA = 2 we
cannot expect that L has a unique (local) minimum. In particular, the computed
minimiser z0
∗will depend on the initial guess for the steepest decent method. As
we will see in later chapters, such a dependence is not necessarily a disadvantage.

26
Prologue: how to produce forecasts
The previous example has demonstrated the eﬀectiveness of using observa-
tions to estimate the state of a mechanistic model, then using the model with
adjusted initial conditions to generate forecasts. The nonlinear method of least
squares provides us with the ﬁrst example of a data assimilation algorithm, which
also goes under the name of variational data assimilation or maximum likelihood
estimation. While the results are encouraging, we will learn about even more so-
phisticated data assimilation methods later in this book. These methods rely on a
probabilistic interpretation of model forecasts as well as measurement errors. The
necessary mathematical tools will be provided in subsequent chapters. In partic-
ular, we will need to introduce the concept of a random variable, together with
methods for performing computer experiments with random variables (Monte
Carlo methods). We will then apply these tools to mechanistic models of type
(1.18) to describe stochastic processes and forecast uncertainties. We also need
to introduce Bayesian inference as a probabilistic framework for inferring in-
formation on random variables from (partial) observations and available prior
knowledge about the random variable under consideration. Once these mathe-
matical foundations have been established, the second part of this book on data
assimilation algorithms can be entered.
We end this introductory chapter with some general comments on the pro-
cess of building mathematical models for making predictions and the role of
data assimilation within this process. We can use well-established theories, such
as Newton’s laws of motion, to build mathematical models in the form of evo-
lution equations/dynamical systems as encountered in this chapter in Equation
(1.18). These models can be discretised and programmed on a computer, allowing
mathematical experiments to be performed. The analysis of such computational
models falls, broadly speaking, into the world of applied computational mathe-
matics. When making predictions, this is one side of the coin; the other side is
the world of measured data and their mathematical structure. This area is tra-
ditionally investigated from a mathematical perspective by statisticians. While
the two sides of the same coin have largely been developed independently over
the years, there is an increasing awareness that they belong together and that
maximal beneﬁt can be gained by combining them within the framework of data
assimilation. Data assimilation can be used for state estimation, for adapting
models through parameter estimation, and for intercomparison of models. The
Bayesian formalism has emerged as a particularly fruitful approach to data as-
similation and is primarily the approach that we will follow in this book. See
Figure 1.15 for a graphical illustration of this discussion.
Problems
1.1
Implement the numerical model from Example 1.1 and store the resulting
reference trajectory in time intervals of Δtout = 0.05 in a ﬁle for later use in
other examples. Do not store the system state from every single time-step as this
becomes very ineﬃcient, even for low-dimensional problems; it is much better to
overwrite the state vector on each time-step, and take a copy of the vector when

1.3 Model driven forecasting and data assimilation
27

	




























Figure 1.15 A schematic presentation of the complex process of building and using
mathematical models. An essential building block is data assimilation which is a
mathematical technique for combining mechanistic models with statistical models based
on data. Here a statistical model refers to a set of probability distributions describing
observed data, while a mechanistic model consists of evolution equations which give rise
to deterministic and/or stochastic processes. Mechanistic models depend on parameters
(including the state of the model), which we treat as random variables. Finally, a
computational model is typically an algorithm that allows us to produce process
realisations of the mechanistic model. Among the possible outcomes of data assimilation
are improved predictions through parameter and state estimation as well as model
selection.
you need to store it. The resulting data set should be stored in a matrix of size
3 × 4001. Do not forget to replace (1.6) by (1.27) and check that your numerical
results reproduce the model attractor from Figure 1.1.
1.2
Implement the numerical observation process as deﬁned in Example 1.2
using the reference trajectory generated in Problem 1.1. Store the numerically
generated observation values yobs(tk) for k = 1, . . . , Nobs = 4000, in a ﬁle for
later use. Investigate the diﬀerence between using the two recursions (1.28) and
(1.9) for generating measurement errors. Hint: You might obtain a trajectory
diﬀerent from the one displayed in Figure 1.3. Diﬀerences can arise even for
mathematically identical implementations due to round-oﬀerrors.
1.3
Follow Example 1.4 and use linear extrapolation in order to produce fore-
casts from the observations produced in Problem 1.2. Compute the time averaged
RMSE and compare to the values produced in Problem 1.4.
1.4
Implement the method of least squares in the setting laid out in Example
1.6. Compare your coeﬃcients al, l = 1, . . . , 4, to the one stated in Example 1.6.
Also, compare the resulting time averaged RMSEs.
1.5
Implement the mechanistic model for our surrogate physical process as de-

28
Prologue: how to produce forecasts
scribed in Example 1.7. Use (1.5) as initial conditions at t0 = 0. Your results
should reproduce the phase portrait displayed in Figure 1.8. Now compare the
model trajectory to the reference trajectory zref(t) computed in Exercise 1.1.
Next, vary the initial conditions (x0, y0, z0) for the mechanistic model by adding
arbitrary perturbations (δx, δy, δy) ∈[−1, 1]3 and study the impact of these per-
turbations on the forecast quality with respect to the reference trajectory zref(t).
1.4
Guide to literature
A thought-provoking introduction to many of the topics raised in this chapter can
be found in Smith (2007b). Another book from the same series by Hand (2008)
discusses some of the data related issues in more detail. The Lorenz-63 model was
introduced by Lorenz (1963) and provides a widely studied chaotic dynamical
system. Polynomial interpolation and the method of least squares are covered in
S¨uli & Mayers (2006). A broad overview of minimisation techniques including
the nonlinear method of least squares is given in Nocedal & Wright (2006). The
importance of uncertainty quantiﬁcation and data assimilation for numerical
weather forecasting is demonstrated in Kalnay (2002). In fact, numerical weather
forecasting provides an ideal motivation as well as an application area for most
of the material covered in this book.
1.5
Appendix: Numerical implementation of tent map iteration
In this appendix, we discuss the implementation on a computer of the tent map
iteration
gn+1 =
 2gn
if gn ∈[0, 1/2),
2(gn −1)
otherwise,
(1.26)
for given initial g0 ∈[0, 1] and n ≥0. We consider the case where this iteration is
approximated by a binary ﬂoating point representation of the non-negative real
numbers gn in the form of
gn = m × 2l,
where
m = 0.m1m2m3 · · · ,
is called the mantissa and mi ∈{0, 1} are the mantissa bits. The integer l is
called the exponent of the representation. For eﬃcient storage, the exponent l is
chosen such that m1 = 1 unless m = 0. If the mantissa has only ﬁnitely many
non-zero bits, then i∗denotes the largest i such that mi = 1. We call i∗the
mantissa length. As an example, consider
gn = 0.1101 × 22,

1.5 Appendix: Numerical implementation of tent map iteration
29
with mantissa length i∗= 4, which corresponds to
gn = 1 × 21 + 1 × 20 + 0 × 2−1 + 1 × 2−2 = 3.25
in our standard decimal representation. We also ﬁnd that gn = 1 corresponds to
0.1×21 in our binary representation. Furthermore, gn ∈[0, 1/2) implies that the
associated exponent l satisﬁes l ≤−1. Similarly, we ﬁnd that gn ∈[0, 1] implies
l ≤1.
Now consider the tent map iteration written in this representation. Straight-
forwardly, 2gn leaves the mantissa of gn unaltered while its exponent is increased
by one. Understanding the impact of 2 −2gn on gn ∈[1/2, 1) is more delicate.
We obtain
0.1 × 22 −0.1m2m3 · · · × 21 = (0.1 −0.01m2m3 · · · ) × 22
= 0.00m2m3 · · · × 22
= 0.m2m3 · · · × 20,
where mi = mi +1 modulo 2 for all i = 1, . . . , i∗−1. If i∗is ﬁnite, then we obtain
mi∗= mi∗= 1. In this case, the mantissa length of gn+1 is reduced by at least
one (it is exactly one in the case in which m2 = 1). Consequently, if the initial
g0 is chosen such that its mantissa m has ﬁnite length, then the tent map will
ultimately lead to gn = 0 after suﬃciently many iterations of the tent map. Of
course, a number with inﬁnite mantissa length will lead to zero for any number
of tent map iterations.
Since digital computers rely on a binary representation of real numbers with
a mantissa of necessarily ﬁnite length, any computer implementation of the tent
map iteration will ultimately result in gn = 0, after suﬃciently many iterations.
This is in stark contrast to the “true” tent map, which generically produces inﬁ-
nite, non-repetitive sequences {gn}∞
n=0. This example should serve as a warning
not to identify a mathematical model with a computer implementation of it.
The following modiﬁcation mimics the desired asymptotic behaviour of the
tent map iteration when implemented in ﬁnite ﬂoating point arithmetic:
gn+1 =
 1.99999gn
if gn ∈[0, 1/2),
1.99999(gn −1)
otherwise.
Similarly, the following modiﬁcations were applied to the iterations (1.6) and
(1.9), respectively:
gn+1
i
=
 1.99999gn
i + a/2
if gn
i ∈[−a/2, 0),
−1.99999gn
i + a/2
otherwise,
(1.27)
ξk+1 =
 1.99999ξk + a/2
if ξk ∈[−a/2, 0),
−1.99999ξk + a/2
otherwise.
(1.28)


Part I
Quantifying Uncertainty


2
Introduction to probability
In the previous chapter we discussed how models can be used to interpolate data
from observations, and to make predictions about future states of physical sys-
tems. Since predictions are often used to make decisions, it is crucial to be able to
estimate their uncertainty. The main theme of this book is prediction algorithms
that provide uncertainty quantiﬁcation for forecasts, expressed in the language
of probability. Hence, in this chapter we recall some basic material from proba-
bility theory. In particular, we will introduce the concept of a random variable
as a useful mathematical abstraction for the description of computational (and,
more generally, scientiﬁc) experiments such as the ones conducted in Chapter 1.
A familiar example is that of a coin ﬂip, in which case the measureable out-
put consists of two elements: heads or tails. The associated random variable is
formally written as X : Ω →{heads, tails}, where the sample space Ω mathe-
matically represents the set of all possible physical processes that go into ﬂipping
a coin. An actual coin ﬂip amounts to selecting a speciﬁc realisation ω ∈Ω of
such a physical process which assigns the outcome (heads or tails) to X(ω). For
an idealised coin, the probability of heads or of tails should both be equal to
one half. Putting oneself in the position of Laplace’s demon, there is, of course,
nothing random about ﬂipping a coin: the outcome of a coin ﬂip is determined
by all of the forces acting on the coin in motion, together with the starting con-
ﬁguration of the coin. This knowledge is inaccessible in practice and the dynamic
processes involved are so complex that ﬂipping a coin constitutes an experiment
with unpredictable (or random) outcome.
In a similar vein, we will ﬁnd later in this chapter that the non-autonomous
forcing {Ξi}∞
i=1 generated by the simple recursion (1.10) can also be considered as
the outcome of random experiments, even though these numbers are produced
by an entirely deterministic procedure. This observation will also allow us to
treat measurement errors such as (1.8) as realisations of an appropriate random
variable.
While probability theory deals with the formal mathematical rules of how to
manipulate and process probabilities, there remains the separate issue of how
to actually assign probabilities to events or outcomes of experiments in the ﬁrst
place. There are several diﬀerent methodologies for achieving this including:
(i) Conducting a large number of identical experiments and recording the rel-

34
Introduction to probability
ative frequency of an event A to occur. The probability of an event is then
the large sample limit of this relative frequency.
(ii) Identifying equally likely alternatives and assigning equal probabilities to
each of these alternatives.
(iii) Estimating probabilities based on perceived knowledge and previous expe-
rience of similar systems (this is necessarily subjective, and requires us to
revise these estimates when new information is received).
Returning to the coin ﬂipping experiment, we ﬁnd that probabilities of possible
outcomes (heads or tails) can be assigned by either method (i) or (ii). When as-
signing probabilities to outcomes of computer experiments, method (i) is suitable.
On the other hand, method (iii) is often necessary in more complex situations
when repeated experimentation is infeasible, and/or when possible events cannot
a priori be categorised as equally likely.
This chapter puts this discussion aside, and focuses on the mathematical rules
of how to manipulate and process probabilities. We start with a formal deﬁnition
of a random variable. This formal language places our intuitive understanding of
probability in a mathematical framework required for rigorous work; we include
it for completeness. Given a sample space Ω, an event is a subset E ⊂Ω. We
assume that the set F of all events forms a σ-algebra (i.e., F is non-empty, and
closed over complementation and countable unions).
Example 2.1
If Ω = {1, 2, 3}, then an associated σ-algebra of possible events
is deﬁned by
F = {Ω, ∅, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}}.
Example 2.2
If Ω = [0, 1] ⊂R, then the associated set F of all events can be
taken as the smallest σ-algebra containing all open intervals (a, b) ⊂Ω; this F
is also known as a σ-algebra of Borel sets, or just Borel σ-algebra. We mention
that the concept of a σ-algebra of Borel sets can be generalised from the unit
interval to the whole real line.
Having deﬁned a sample space Ω with associated σ-algebra F of all possible
events, each event A ∈F is assigned a probability P(A) ∈[0, 1]. If P(A) = 0, this
means that the event will (almost) never occur, while probability one implies
that the event will (almost) always occur. A probability of one half implies that
chances of the event occurring are the same as the chances of the event not
occurring etc. Probabilities of events should satisfy certain properties in order
to be mathematically self-consistent.
Definition 2.3 (Probability measure)
A probability measure is a function P :
F →[0, 1] with the following properties:

2.1 Random variables
35
(i) total probability equals one, P(Ω) = 1, and
(ii) probability is additive for disjoint events, so if A1, A2, . . . , An, . . . is a ﬁnite
or countable collection of events Ai ∈F and Ai ∩Aj = ∅for i ̸= j, then
P

i Ai

=

i
P(Ai).
The triple (Ω, F, P) is called a probability space.
Example 2.4
We return to the σ-algebra from Example 2.1 and postulate that
P({i}) = 1/3,
for i = 1, 2, 3. Following the properties of a probability measure, we may also
quickly conclude that, for example,
P({1, 3}) = 1/3 + 1/3 = 2/3.
Hence we can extend the probability measure P to the complete σ-algebra F.
Example 2.5
In the case of Ω = [0, 1], a probability measure can be introduced
by ﬁrst saying that each interval (a, b) ⊂[0, 1] is assigned the probability
P((a, b)) = b −a.
This deﬁnition is then extended to the associated Borel σ-algebra F using the
probability measure properties (i) and (ii), and we obtain the uniform probability
measure on the unit interval [0, 1].
2.1
Random variables
Formally, when we consider random processes in this book there will be an under-
lying abstract probability space (Ω, F, P) representing all sources of uncertainty
(as already discussed in the context of coin ﬂipping). However, in practice we
are usually only interested in the impact of these uncertainties on observables
(such as heads or tails in the case of coin ﬂipping). This means that most of
the time we can focus on the concept of a random variable, which relates the
underlying probability space (Ω, F, P) to induced uncertainties/probabilities in
an observable (or measureable) quantity of interest.
Let us simplify things for the moment by assuming that any such quantity will
take values in the space of real numbers. This leads us to the following formal
deﬁnition of a univariate random variable.

36
Introduction to probability
Definition 2.6 (Univariate random variable)
A function X : Ω →R is called a
(univariate) random variable if the sets Ax, deﬁned by
Ax = {ω ∈Ω : X(ω) ≤x},
are elements of the set of all events F, i.e., Ax ∈F for all x ∈R. The (cumulative)
probability distribution function of X is given by
FX(x) = P(Ax).
If X only takes ﬁnitely many values in R, then we call X a discrete random
variable, otherwise it is called a continuous random variable.
For a given random variable X on R, we deﬁne an induced probability measure
μX on R (not Ω) via
μX(B) = P({ω ∈Ω : X(ω) ∈B})
for all intervals B in R (more precisely for all sets B in the Borel σ-algebra on
R).
Often, when working with a random variable X, the underlying probability
space (Ω, F, P) is not emphasised. Typically, only the target space X (currently
R) and the probability distribution or measure μX on X are speciﬁed. We then
say that μX is the law of X and write X ∼μX or law(X) = μX. However,
the underlying probability space is important when discussing several random
variables and their mutual relations. We will come back to this issue later in this
chapter.
What makes random variables X(ω) diﬀerent from regular functions f(t) is
that they are mappings from a probability space. Usually, we choose the input t
for a function f, and observe the output f(t). For random variables, the input ω
is determined at random according to the laws of the probability space, and we
just observe the output X(ω), which we refer to as a “realisation” of the random
variable X.
Example 2.7
We return to the coin ﬂipping experiment with the associated
random variable deﬁned by X : Ω →{heads, tails}. Generally speaking, we do
not know anything about Ω and the associated probability space. We only wish
to predict whether we will obtain heads or tails, and so our interest is focused on
the induced probability measure μX(heads) = μX(tails) = 1/2. This situation
will arise repeatedly throughout this book and the emphasis will therefore be on
probability measures induced by random variables rather than on the underlying
probability space (Ω, F, P) itself.
The following deﬁnition of expectation provides an important tool for obtain-
ing descriptive numbers, which we call statistics, about probability measures.

2.1 Random variables
37
Definition 2.8 (Expectation)
A probability measure μX on X induces an as-
sociated (Lebesgue) integral over X and
E[f(X)] =

X
f(x)μX(dx)
is called the expectation of a function f : X →R. Two important choices for f
are f(x) = x, which leads to the mean x = E[X] of X, and f(x) = (x −x)2,
which leads to the variance σ2 = E[(X −x)2] of X.
The integral is formally deﬁned by ﬁrst considering functions f which only
take ﬁnitely many distinct values fi in which case
E[f(X)] =

i
fi μX({x ∈X : f(x) = fi}).
Such simple functions are then used to approximate general functions f and their
expectation values. More details can be found in standard textbooks on measure
theory.
Definition 2.9 (Absolute continuity)
A probability measure μX on X = R is
called absolutely continuous (with respect to the standard Lebesgue integral dx
on R) if there exists a probability density function (PDF) πX : X →R with
πX(x) ≥0, and

R
f(x)μX(dx) =

R
f(x)πX(x)dx.
The shorthand μX(dx) = πX(x)dx is often adopted.
An immediate consequence is that

X πX(x)dx = 1, which follows from the
particular choice f(x) = 1. We also obtain
FX(x) =
 x
−∞
πX(x′)dx′.
If a probability measure μX is absolutely continuous then for all practical pur-
poses we can work within the classical Riemann integral framework without need-
ing Lebesgue integration. Furthermore, any function πX(x) such that πX(x) ≥0
and

R
πX(x)dx = 1,
can serve as the PDF of a random variable.
Univariate random variables naturally extend to the multivariate case, for
example, X = RNx, Nx > 1. Consider, for example, a bivariate random variable
X : Ω →R2 with components X1 : Ω →R and X2 : Ω →R. Deﬁnition 2.6 is
generalised as follows. The sets
Ax = {ω ∈Ω : X1(ω) ≤x1, X2(ω) ≤x2},

38
Introduction to probability
x = (x1, x2) ∈R2, are assumed to be elements of the set of all events F. The
(cumulative) probability distribution function of X = (X1, X2) is deﬁned by
FX(x) = P(Ax),
and the induced probability measure on R2 is denoted by μX. In particular, the
deﬁnition μX(Bx) := FX(x) for Bx = (−∞, x1]×(−∞, x2] can be extended to all
sets B in the Borel σ-algebra on R2. If μX is absolutely continuous with respect
to the Lebesgue measure on R2, then it has a PDF πX(x), which satisﬁes
FX(x1, x2) =
 x1
−∞
 x2
−∞
πX(x′
1, x′
2)dx′
1dx′
2.
We shall now discuss a few examples of random variables with well-known
probability distributions.
Example 2.10
We use the notation X ∼N(x, σ2) to denote a univariate Gaus-
sian random variable with mean x and variance σ2. Its PDF is given by
πX(x) =
1
√
2πσ e−
1
2σ2 (x−x)2,
x ∈R, which is often referred to as a normal distribution. In the multivariate
case, we use the notation X ∼N(x, P) to denote a Gaussian random variable
with PDF given by
πX(x) =
1
(2π)Nx/2|P|1/2 exp

−1
2(x −x)TP −1(x −x)

,
for x ∈RNx. Here x ∈RNx denotes the mean, deﬁned by
x = E[X] =

RNx
xπX(x)dx,
and P ∈RNx×Nx denotes the covariance matrix, deﬁned by
P = E[(X −x)(X −x)T] =

RNx
(x −x)(x −x)TπX(x)dx,
and where we adopt the shorthand notation |P| = | det P| is the absolute value
of the determinant of P. The PDF πX(x) of a Gaussian random variable X ∼
N(x, P) is denoted by n(x; x, P).
Example 2.11
The univariate Laplace distribution has PDF
πX(x) = λ
2 e−λ|x|,
(2.1)
x ∈R. This may be rewritten as
πX(x) =
 ∞
0
1
√
2πσ e−x2/(2σ2) λ2
2 e−λ2σ/2dσ.

2.1 Random variables
39
Here, the integrand is the product of a Gaussian PDF with mean zero and vari-
ance σ2 and a σ-dependent weight factor. Replacing the integral by a Riemann
sum over a sequence of quadrature points {σj}J
j=1, we obtain
πX(x) ≈
J

j=1
αj
1
√
2πσj
e−x2/(2σ2
j ),
αj ∝λ2
2 e−λ2σj/2(σj −σj−1),
and the constant of proportionality is chosen such that the weights αj sum to
one. This ﬁnite sum approximation provides an example of a Gaussian mix-
ture distribution, i.e. a weighted sum of Gaussians. In this particular example,
the Gaussians are all centred about zero. The most general form of a Gaussian
mixture is
πX(x) =
J

j=1
αj
1
√
2πσj
e−(x−mj)2/(2σ2
j ),
with weights αj > 0 subject to J
j=1 αj = 1, and locations −∞< mj < ∞.
Univariate Gaussian mixtures generalise to mixtures of multivariate Gaussians.
Example 2.12
As a third example, we consider the point measure μx0 deﬁned
by

X
f(x)μx0(dx) = f(x0).
The associated random variable X has the outcome X(ω) = x0 with probability
1. We call such a random variable deterministic, writing X = x0 for short.
Note that the point measure is not absolutely continuous with respect to the
Lebesgue measure, i.e., there is no corresponding PDF. Using the Dirac delta
notation δ(·), we shall nevertheless often formally write μx0(dx) = δ(x−x0)dx or
πX(x) = δ(x−x0). Following the formal deﬁnition of a random variable, we ﬁnd
Fx0(x) = P({ω ∈Ω : X(ω) ≤x})
=
 x
−∞
μx0(dx)
=
 1
if x ≥x0,
0
otherwise,
(2.2)
for the cumulative distribution function of the point measure μx0.
Throughout this book we will repeatedly encounter transformations of random
variables. Therefore, it is of utmost importance to understand how probability
distributions of random variables transform under diﬀeomorphisms.
Lemma 2.13 (Invertible transformations of random variables)
Let X : Ω →RNx
be a random variable with PDF πX, and let Y : Ω →RNx be a random variable

40
Introduction to probability
deﬁned by Y = Φ(X) for smooth and invertible Φ : RNx →RNx (i.e., Φ is a
diﬀeomorphism). Then, Y has PDF πY given by
πY (y) = πX(Φ−1(y))|J(y)|,
where Φ−1 denotes the inverse of Φ,
J(y) = DΦ−1(y) ∈RNx×Nx
the Jacobian matrix of partial derivatives, and |J| the absolute value of the
determinant of J, i.e., |J| = | det J|.
Proof
By conservation of probability,
μY (A) = P({ω ∈Ω : Y (ω) ∈A})
= P({ω ∈Ω : Φ(X(ω)) ∈A})
= P({ω ∈Ω : X(ω) ∈Φ−1(A)})
= μX(Φ−1(A)),
for any Borel set A ⊂RNx, where Φ−1(A) denotes the preimage of A under Φ.
Hence

A
πY (y) dy =

Φ
1(A)
πX(x)dx,
and a change of variables x = Φ−1(y) gives

A
πY (y) dy =

A
πX(Φ−1(y))|J(y)| dy.
Since this is true for all Borel sets A ∈RNx, we obtain the desired result.
We now discuss several mathematical concepts relating to pairs of random
variables X1 : Ω →X and X2 : Ω →X. We may treat X1 and X2 as components
of a single multivariate random variable Z = (X1, X2) over Z = X × X, which
then has some joint distribution μZ(z) = μX1X2(x1, x2).
Definition 2.14 (Marginals, independence, conditional probability distributions)
Let X1 and X2 denote two random variables on X with joint PDF πX1X2(x1, x2).
The two PDFs,
πX1(x1) =

X
πX1X2(x1, x2)dx2
and
πX2(x2) =

X
πX1X2(x1, x2)dx1,
are called the marginal PDFs, i.e. X1 ∼πX1 and X2 ∼πX2. The two random
variables are called independent if
πX1X2(x1, x2) = πX1(x1) πX2(x2).

2.1 Random variables
41
We also introduce the conditional PDFs
πX1(x1|x2) = πX1X2(x1, x2)
πX2(x2)
and
πX2(x2|x1) = πX1X2(x1, x2)
πX1(x1)
.
The conditional PDF πX1(x1|x2) is the PDF for X1 under the assumption
that X2(ω) takes the value x2. For independent random variables we obviously
have πX1(x1|x2) = πX1(x1). These formulas lead to the following important
deﬁnition which we shall use for iteratively constructing joint distributions from
conditional probabilities.
Definition 2.15 (Disintegration)
The two equivalent representations
πX1X2(x1, x2) = πX1(x1|x2)πX2(x2) = πX2(x2|x1)πX1(x1)
(2.3)
are called disintegrations of the joint PDF πX1X2. In the case of several random
variables X1, X2, . . . , Xn, this becomes, for example,
πX1···Xn(x1, . . . , xn) = πX1(x1|x2, . . . , xn)πX2(x2|x3, . . . , xn) · · · πXn(xn). (2.4)
We can also use these formulas to deduce the following formula for the marginal
distributions.
Lemma 2.16 (Marginals as expectation of conditional PDFs)
Let X1 and X2 be
two random variables with joint PDF πX1X2 as above. Then
πX1(x1) = E [πX1(x1|X2)] ,
(2.5)
where the expectation is taken with respect to the random variable X2.
Proof
πX1(x1) =

X
πX1X2(x1, x2)dx2
=

πX1(x1|x2)πX2(x2)dx2
= E [πX1(x1|X2)] ,
as required.
If we have a pair of random variables, we would like to quantify how they are
related. Correlation is a useful tool for measuring the dependence between two
variables.
Definition 2.17 (Correlation)
The correlation between two univariate random
variables X and Y is given by
corr(X, Y ) =
E[(X −x)(Y −y)]

E[(X −x)2]E[(Y −y)2]
,
with x = E[X] and y = E[Y ].

42
Introduction to probability
The normalisation factor is chosen so that | corr(X, Y )| ≤1 and | corr(X, Y )| ≈
1 indicates a high degree of correlation.1
Example 2.18
A joint Gaussian distribution πX1X2(x1, x2), x1, x2 ∈R, with
mean (x1, x2), covariance matrix
P =
 σ2
11
σ2
12
σ2
21
σ2
22

,
(2.6)
and σ12 = σ21 leads to a Gaussian conditional distribution
πX1(x1|x2) =
1
√
2πσc
e−(x1−xc)2/(2σ2
c),
(2.7)
with conditional mean
xc = x1 + σ2
12σ−2
22 (x2 −x2)
and conditional variance
σ2
c = σ2
11 −σ2
12σ−2
22 σ2
21.
Note that
P −1 =
1
σ2
11σ2
22 −σ2
12σ2
21

σ2
22
−σ2
12
−σ2
12
σ2
11

=
⎡
⎣
σ−2
c
σ−2
c
σ2
12
σ2
22
σ−2
c
σ2
12
σ2
22
σ−2
c
σ2
11
σ2
22
⎤
⎦
and
πX1X2(x1, x2) =
1
√
2πσc
exp

−1
2σ2c
(x1 −xc)2

×
1
√
2πσ22
exp

−
1
2σ2
22
(x2 −x2)2

,
which can be veriﬁed by direct calculations. See Problem 2.5. The correlation be-
tween X1 and X2 is given by corr(X1, X2) = σ2
12/(σ11σ22). Since | corr(X1, X2)| ≤
1, we ﬁnd that |σ2
12| ≤σ11σ22.
The PDF πXi(x) of a Gaussian random variable Xi ∼N(xi, σ2
ii) is denoted
by n(x; xi, σ2
ii). For given x2, we deﬁne X1|x2 as the random variable with con-
ditional probability distribution πX1(x1|x2). From the previous calculations we
then obtain X1|x2 ∼N(xc, σ2
c) and
πX1X2(x1, x2) = n(x1; xc, σ2
c) n(x2; x2, σ2
22).
(2.8)
The concept of independence can be extended to sequences of random vari-
ables, as follows.
1 However, it is important to note that high correlation between two variables does not
indicate that there is a causal link. For example, the price of wheat in Angola may be
highly correlated with the sales of laptops in Dakar, but this does not mean that more
people in Dakar are buying laptops because the price of wheat in Angola has increased.

2.1 Random variables
43
Definition 2.19 (Independent and identically distributed)
Let X be a random
variable with distribution πX. A sequence of random variables {Xi}M
i=1 with
joint PDF πX1,...,XM is called independent and identically distributed (i.i.d.) with
distribution πX if
(i) the variables are mutually independent, i.e.,
πX1,...,XM (x1, . . . , xM) = πX1(x1)πX2(x2) · · · πXM (xM),
where πXi is the marginal distribution for Xi, i = 1, . . . , M, and
(ii) the marginal distributions are all the same, i.e., πXi(x) = πX(x).
A particular realisation of an i.i.d. sequence of random variables of size M with
distribution πX, i.e.,
(x1, . . . , xM) = (X1(ω), . . . , XM(ω)),
is referred to as “M independent samples from the random variable X”.
The values of a sequence of M samples represent outcomes of an experiment
where X is repeatedly measured. There are many numerical algorithms for sim-
ulating random variables on a computer, and in this book we shall often discuss
algorithms where we “draw” or “generate” M samples of a random variable X.
Simple random variables are often used to model complex deterministic be-
haviour, since they are cheap to simulate on a computer, and facilitate mathemat-
ical analysis. In the following example, we return to the sequence {Ξi} deﬁned by
(1.10) in Example 1.2 of Chapter 1, and consider how the entries of this sequence
might be approximated as independent samples of a random variable.
Example 2.20
We investigate the properties of the sequence {Ξi}I
i=1 deﬁned
by (1.10) and (1.9) with I = 104 and I = 107, respectively. Figure 2.1 displays
relative frequencies of the Ξi values in ten bins from the interval [−a/2, a/2] =
[−2, 2]. The relative frequencies become essentially equal for I = 107. This shows
that the Ξi values are uniformly distributed over the interval [−2, 2]. Although
the sequences {Ξi} are generated in an entirely deterministic manner, these rela-
tive frequencies suggest that they behave like an identically distributed sequence
of random variables with uniform distribution in [−2, 2]. We observe that they
appear to have mean ξi = 0, for example.
An important aspect of the coin ﬂipping experiment is that outcomes of suc-
cessive ﬂips are independent of each other. This clearly cannot be the case for
the tent map process since successive Ξi values are, by deﬁnition, dependent.
Since the dependence of a sequence of samples is diﬃcult to assess numerically
we instead compute the empirical (normalised) autocorrelations
C(τ) =
I−τ
i=1 ΞiΞi+τ
I−τ
i=1 ΞiΞi
,
τ ≥0.

44
Introduction to probability
2
1 5
1
0 5
0
0 5
1
1 5
2
0
0 02
0 04
0 06
0 08
0 1
0 12
Ξ
relat ve frequencies from 104 iterates
2
1 5
1
0 5
0
0 5
1
1 5
2
0
0 02
0 04
0 06
0 08
0 1
0 12
Ξ
relative frequency from 107 iterates
Figure 2.1 Relative frequencies of the samples Ξi in ten bins from the interval [−2, 2]
for sample sizes I = 104 (left) and I = 107 (right), respectively. It can be concluded that
the distribution of samples converges to a uniform distribution over the interval [−2, 2] for
sample sizes suﬃciently large.
The variables Ξi and Ξi+τ are uncorrelated if C(τ) = 0 for τ > 0 and I →∞.
For sample size I = 107, we ﬁnd C(0) = 1 by deﬁnition and
C(1) = 0.1228 × 10−3,
C(2) = −0.1172 × 10−3,
C(3) = −0.1705 × 10−3.
Hence we may conclude that, for all practical purposes, the samples Ξi are un-
correlated.2 We have already brieﬂy mentioned in Chapter 1 that (1.9) is a scaled
and shifted version of the tent map iteration (1.26), which is known to display
chaotic solution behaviour and which has the uniform distribution on [0, 1] as
the stationary distribution (recall that it is necessary to replace the factor 2.0 by
1.99999 in order to avoid an undesirable accumulation of round-oﬀerrors in com-
puter implementations). This suggests that we might approximate the Ξi values
by independent samples from a uniform random variable U : Ω →[−a/2, a/2].
Next we consider the accumulated measurement error
δ =
20

i=1
ηi = 1
20
20

i=1
Ξi.
(2.9)
We can generate a total of 5 × 105 samples of δ by using appropriate patches
from the sequence of Ξi values. We denote these samples by δj and display their
relative frequencies in Figure 2.2. For comparison we also display the relative
frequencies of an equal number of samples from a Gaussian distribution with
mean zero and variance σ2 = 1/15.
The results from Figure 2.2 suggest that we may safely approximate the mea-
2 Recall that although independence implies zero correlation, the reverse is not generally
true.

2.1 Random variables
45
1 5
1
0 5
0
0 5
1
1 5
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
measurement error
relative frequency from 5x105 error samples
1 5
1
0 5
0
0 5
1
1 5
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
measurement error
relat ve frequency from 5x105 Gaussian samples
Figure 2.2 The relative frequencies on the left represent the spatial distribution of the
measurement error samples δj. For comparison we also generated the same number of
samples from a Gaussian distribution with mean zero and variance σ2 = 1/15 and display
the resulting relative frequencies over bins of the same size.
surement errors δj by realisations from a Gaussian random variable with mean
zero and variance σ2 = 1/15. This leads to a simpliﬁed observation model which
we will discuss in more detail later in Chapter 5.
We now reconsider another example from Chapter 1 and put it into the context
of random variables.
Example 2.21
We considered the method of least squares in Chapter 1 in
order to estimate the coeﬃcients al in the autoregressive model 1.14 of order
ﬁve. We now use the data from Example 1.6 and analyse the resulting residuals
rj, deﬁned by (1.16). The relative frequencies in Figure 2.3 display a bell-shaped
distribution similar to the data presented in Figure 2.2.
Figure 2.3 suggests that the residuals follow a Gaussian distribution and that
we may treat the residuals as realisations of a Gaussian random variable R.
We verify this hypothesis by computing the empirical estimates for the mean
r = E[R], the variance σ2 = E[(R −r)2],
skewness = E[(R −r)3]
σ3
and
kurtosis = E[(R −r)4]
σ4
−3.
The skewness and kurtosis are zero for Gaussian random variables. Empirical
estimators for the mean and the variance from samples {rj}J
j=1 of size J are

46
Introduction to probability
6
4
2
0
2
4
6
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
residuals
relative frequencies for binned residuals from least square method
Figure 2.3 Relative frequencies of
the binned residuals (1.16) obtained
from the method of least squares
applied to the data used in Example
1.6 from Chapter 1. The relative
frequencies again resemble those of a
Gaussian random sample.
provided by
rJ := 1
J
J

j=1
rj,
σ2
J :=
1
J −1
J

j=1
(rj −rJ)2
and by
skewnessJ =
1
Jσ3
J
J

j=1
(rj −rJ)3,
kurtosisJ =
1
Jσ4
J
J

j=1
(rj −rJ)4 −3
for the skewness and kurtosis, respectively. With J = 2000 data points we obtain
the values rJ ≈0.0060, σ2
J ≈1.0184, skewnessJ ≈0.0031, kurtosisJ ≈0.3177.
While the data are therefore not perfectly Gaussian, a Gaussian approximation
with mean zero and variance one seems nevertheless justiﬁable.
2.2
Coupling of measures and optimal transportation
We now consider the reverse situation, in which two marginal distributions are
given and we wish to ﬁnd an appropriate joint distribution with associated ran-
dom variables. This leads us to the concept of coupling.
Definition 2.22 (Coupling)
Let μX1 and μX2 denote two probability measures
on a space X. A coupling of μX1 and μX2 consists of a pair Z = (X1, X2) of
random variables such that X1 ∼μX1, X2 ∼μX2, and Z ∼μZ. The joint
measure μZ on the product space Z = X × X, is called the transference plan for
this coupling. The set of all transference plans is denoted by Π(μX1, μX2).
Since the involved measures will generally be assumed to be absolutely contin-
uous throughout this book, the discussion of couplings will be mostly restricted
to the less abstract case of X = RNx and μX1(dx) = πX1(x)dx, μX2(dx) =
πX2(x)dx. In other words, we generally assume that the marginal measures are

2.2 Coupling of measures and optimal transportation
47
10
5
0
5
10
10
5
0
5
10
0
0.05
0.1
0.15
0.2
random variable X1
marginals and joint distribution (coupling with correlation of ρ=0.95)
random variable X2
10
5
0
5
10
10
5
0
5
10
0
0.05
0.1
0.15
0.2
random variable X1
marginals and joint distribution (coupling with correlation of ρ=0.1)
random variable X2
Figure 2.4 The ﬁgure shows possible couplings (joint distributions) between two
univariate Gaussian random variables X1 and X2. The top panel is for a correlation of
ρ = 0.95 while the bottom panel is for ρ = 0.1. The marginal distributions are also shown
in both cases. The marginal distribution for X2 has smaller variance, and thus is more
“concentrated” around the mean.
absolutely continuous. We will ﬁnd, however, that couplings are often not abso-
lutely continuous on Z = X × X = RNx × RNx. Clearly, couplings always exist
since we can use the trivial product coupling
πZ(x1, x2) = πX1(x1)πX2(x2),
in which case the associated random variables X1 and X2 are independent.

48
Introduction to probability
Example 2.23
We set Nx = 1 and consider a pair of univariate Gaussian PDFs
πXi(xi) = n(xi; xi, σ2
ii), i = 1, 2. We seek a coupling in z = (x1, x2) of the form
πZ(z) = n(z; z, P). We quickly ﬁnd from the given marginals that z = (x1, x2)T
and the covariance matrix P must be of the form
P =

σ2
11
ρ σ11σ22
ρ σ11σ22
σ2
22

.
Since P has to be positive deﬁnite, the correlation
ρ =
σ2
12
|σ11||σ22| =
σ2
21
|σ11||σ22|
between X1 and X2 has to satisfy
ρ2 ≤1.
(2.10)
We now investigate the conditional PDF πX2(x2|x1) further. Making use of the
formulas in Example 2.18, we obtain
πX2(x2|x1) = n(x2; xc, σ2
c)
with
xc = x2 −σ2
21
σ2
11
(x1 −x1) = x2 −ρσ22
σ11
(x1 −x1)
and
σ2
c = σ2
22 −σ4
12σ−2
11 = (1 −ρ2)σ2
22.
We ﬁnd that the limit ρ →1 leads to σc →0, which implies that the conditional
probability density becomes a Dirac delta distribution centred about
xc = x2 −σ22
σ11
(x1 −x1).
Hence optimising the correlation between X1 and X2 has led us to a deterministic
coupling
X2 = x2 + σ22
σ11
(X1 −x1).
(2.11)
Such a coupling is commonly used in order to transform random numbers from
a N(0, 1) random number generator into Gaussian random numbers with mean
x and variance σ2. This particular case leads to x1 = 0, x2 = x, σ11 = 1 and
σ22 = σ in (2.11). We will ﬁnd later that this coupling is optimal in the sense
that it maximises the correlation between X1 and X2. Joint distributions in z
are shown in Figure 2.4 for a small correlation ρ = 0.1 and a nearly optimal
correlation ρ = 0.95.
Motivated by the previous example, we now discuss deterministic couplings in
a more general setting. The reader might also want to recall Lemma 2.13.

2.2 Coupling of measures and optimal transportation
49
Definition 2.24 (Deterministic coupling)
Assume that we have a random vari-
able X1 with law μX1 and a probability measure μX2. A diﬀeomorphism T :
X →X is called a transport map if the induced random variable X2 = T (X1)
satisﬁes
E[f(X2)] =

X
f(x2)μX2(dx2) =

X
f(T (x1))μX1(dx1) = E[f(T (X1))]
(2.12)
for all suitable functions f : X →R. The associated coupling
μZ(dx1, dx2) = δ(x2 −T (x1))μX1(dx1)dx2,
(2.13)
where δ(·) is the standard Dirac distribution, is called a deterministic coupling.
Note that μZ is not absolutely continuous, even if both μX1 and μX2 are.
Using

X
f(x2)δ(x2 −T (x1))dx2 = f(T (x1)),
it indeed follows from the above deﬁnition of μZ that

X
f(x2)μX2(dx2) =

Z
f(x2)μZ(dx1, dx2) =

X
f(T (x1))μX1(dx1)
and X2 has marginal distribution μX2.
We now discuss a simple example.
Example 2.25
Let πX1(x) and πX2(x) denote two PDFs on X = R. The
associated cumulative distribution functions are deﬁned by
FX1(x) =
 x
−∞
πX1(x′)dx′,
FX2(x) =
 x
−∞
πX2(x′)dx′.
The right inverse of FX2 is given by
F −1
X2 (p) = inf{x ∈R : FX2(x) ≥p}
for p ∈[0, 1]. The inverse may be used to deﬁne a transport map that transforms
X1 into X2 as follows,
X2 = T (X1) = F −1
X2 (FX1(X1)).
For example, consider the case where X1 is a random variable with uniform dis-
tribution U[0, 1], and X2 ∼N(0, 1) is a standard Gaussian random variable. Then
the transport map between X1 and X2 is simply the inverse of the cumulative
distribution function
FX2(x) =
1
√
2π
 x
−∞
e−(x′)2/2dx′.
This provides a standard tool for converting uniformly distributed random vari-
ables into Gaussian random variables. The construction generalises to univari-
ate measures μX2 which are not absolutely continuous. Consider, for example,

50
Introduction to probability
the point measure μx0 with cumulative distribution function (2.2). Its right-
continuous inverse is deﬁned by
F −1
x0 (p) = inf{x ∈R : Fx0(x) ≥p} = x0
for all p ∈[0, 1].
We can extend the transform method of Example 2.25 to random variables
in RNx with Nx ≥2 by applying the disintegration formula (2.4) to the Nx
components of x, and obtaining subsequent recursive one-dimensional couplings
along each dimension. The resulting deterministic coupling is called the Knothe–
Rosenblatt rearrangement (Villani 2009), also well-known to statisticians as the
conditional quantile transform. While the Knothe–Rosenblatt rearrangement can
be used in quite general situations, it has the undesirable property that the map
depends on the order in which the Nx dimensions of X are processed.
We now generalise the deterministic couplings for univariate Gaussians from
Example 2.23 to the multivariate case.
Example 2.26
Consider two Gaussian distributions N(x1, P1) and N(x2, P2)
in RNx with means x1 and x2 and covariance matrices P1 and P2, respectively.
We ﬁrst deﬁne the square root P 1/2 of a symmetric positive deﬁnite matrix P
as the unique symmetric matrix which satisﬁes P 1/2P 1/2 = P. Then the aﬃne
transformation
x2 = T (x1) = x2 + P 1/2
2
P −1/2
1
(x1 −x1)
(2.14)
provides a deterministic coupling. Indeed, we ﬁnd that
(x2 −x2)TP −1
2
(x2 −x2) = (x1 −x1)TP −1
1
(x1 −x1)
under the suggested coupling. In contrast with the univariate case, deterministic
couplings are not uniquely deﬁned since
x2 = T (x1) = x2 + P 1/2
2
QP −1/2
1
(x1 −x1),
where Q is any orthogonal matrix, also provides a coupling.
Deterministic couplings can be viewed as a special case of an integral transform
deﬁned by
πX2(x2) =

X1
πX2(x2|x1)πX1(x1)dx1,
where πX2(x2|x1) denotes the conditional PDF for the random variable X2 given
X1 = x1 induced by the coupling πX1X2(x1, x2) via
πX2(x2|x1) = πX1X2(x1, x2)
πX1(x1)
.
Furthermore, we formally have
πX2(x2|x1) = δ(x2 −T (x1))

2.2 Coupling of measures and optimal transportation
51
for deterministic couplings. The trivial coupling πZ(x1, x2) = πX1(x1)πX2(x2)
leads to πX2(x2|x1) = πX2(x2) and we conclude that X2 is independent of X1.
A transport map x2 = T (x1) leads instead to dependent random variables and
a covariance matrix
cov(X1, X2) := E[X1XT
2 ] −E[X1](E[X2])T = E[X1T (X1)T] −x1xT
2 ,
which is non-zero in general. One way to select a particular coupling is to choose
the one that maximises the covariance. In fact, in many applications (including
the ones we will consider later in this book) it is desirable to maximise the
covariance or correlation between X1 and X2 subject to the desired marginal
distributions. In addition, maximising the covariance for given marginals also
has an important geometric interpretation. For simplicity, consider univariate
random variables X1 and X2. Then we have
E[(X2 −X1)2] = E[X2
1] + E[X2
2] −2E[X1X2]
= E[X2
1] + E[X2
2] −2E[(X1 −x1)(X2 −x2)] −2x1x2
= E[X2
1] + E[X2
2] −2x1x2 −2cov(X1, X2).
Hence, ﬁnding a joint measure μZ that minimises the expectation of (X1 −X2)2
simultaneously maximises the covariance between univariate random variables
X1 and X2. This geometric interpretation extends to multivariate random vari-
ables and leads to the celebrated Monge–Kantorovitch problem.
Definition 2.27 (Monge–Kantorovitch problem)
A transference plan μ∗
Z ∈
Π(μX1, μX2) is called the solution to the Monge–Kantorovitch problem with cost
function c(x1, x2) = ∥x1 −x2∥2 if
μ∗
Z = arg
inf
μZ∈Π(μX1 ,μX2 ) E[∥X1 −X2∥2],
law(Z = (X1, X2)) = μZ,
(2.15)
where Π(μX1, μX2) denotes the set of all possible couplings between μX1 and
μX2. The associated functional
W(μX1, μX2) =

inf E[∥X1 −X2∥2]
(2.16)
is called the L2-Wasserstein distance between μX1 and μX2.
Example 2.28
In this example we consider couplings between two discrete
random variables X1, X2 with domain given by the discrete set
X = {a1, a2, . . . , aM},
ai ∈R,
(2.17)
and probability distributions
P(X1 = ai) = 1/M,
P(X2 = ai) = wi,
respectively, with wi ≥0, i = 1, . . . , M, and 
i wi = 1. Any coupling between

52
Introduction to probability
these two probability distributions is characterised by a matrix T ∈RM×M such
that its entries tij = (T )ij satisfy tij ≥0 and
M

i=1
tij = 1/M,
M

j=1
tij = wi.
(2.18)
These matrices characterise the set of all couplings Π in the deﬁnition of the
Monge–Kantorovitch problem. The joint measures of X1 and X2 are of the form
μX1X2(dx1, dx2) =
M

i,j=1
tijδ(x1 −aj)δ(x2 −ai)dx1dx2.
(2.19)
Given a coupling T and the mean values
x1 = 1
M
M

i=1
ai,
x2 =
M

i=1
wiai,
the covariance between the associated discrete random variables X1 and X2 is
deﬁned by
cov(X1, X2) =
M

i,j=1
(ai −x2)tij(aj −x1).
(2.20)
The particular coupling deﬁned by tij = wi/M leads to zero correlation between
X1 and X2. On the other hand, maximising the correlation leads to a linear
transport problem in the M 2 unknowns {tij}. More precisely, the unknowns tij
have to satisfy the inequality constraints tij ≥0, the equality constraints (2.18),
and should minimise
J({tij}) =
M

i,j=1
tij(ai −aj)2
which, following our previous discussion, is equivalent to maximising (2.20). An
algorithm for solving the minimisation problem, which relies on the coeﬃcients
ai being real numbers, is given in Appendix 5.8. The basic idea of this algorithm
is demonstrated in the following example. The more general coupling problem,
also called a linear transport problem, for ai ∈RNx, Nx > 1, is much harder to
solve. See Appendix 7.4 and the textbook by Strang (1986).
Example 2.29
In this example we demonstrate how to obtain the optimal
coupling for the (sorted) discrete target set X given by
ai =
1
2M + i −1
M
∈[0, 1]
with M = 10. The weights wi are determined by
wi =
e−(ai−0.1)2/0.2
M
j=1 e−(aj−0.1)2/0.2 .

2.2 Coupling of measures and optimal transportation
53
The optimal coupling matrix is
T ∗≈
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0.1
0.1
0.0002
0
0
0
0
0
0
0
0
0
0.0998
0.1
0.0003
0
0
0
0
0
0
0
0
0
0.0997
0.081
0
0
0
0
0
0
0
0
0
0.019
0.1
0.03
0
0
0
0
0
0
0
0
0
0.07
0.04
0
0
0
0
0
0
0
0
0
0.06
0.013
0
0
0
0
0
0
0
0
0
0.045
0
0
0
0
0
0
0
0
0
0.025
0
0
0
0
0
0
0
0
0
0.012
0
0
0
0
0
0
0
0
0
0.005
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
This matrix can be obtained through the following considerations. We start with
the smallest a1 = 1/2M = 0.05 and its probability weight w1 ≈0.200157. Since
a diagonal entry in T does not contribute to the transport cost J(T ), we set
t∗
11 to its maximal possible value which is t∗
11 = 1/M = 0.1. The next cheapest
transport cost is achieved through the t∗
12 entry which couples a1 = 0.05 with
a2 = 0.15. Hence we again set t∗
12 to its maximal possible value t∗
12 = 0.1. This
leaves us with t∗
13 ≈0.000157 ≈0.0002 and t∗
1j = 0 for all j ≥4. We now
continue to distribute the probability weight w2 = 0.200157 across the second
row of T ∗. Since the columns must sum to 1/M, we are required to set t∗
2,1 and
t∗
2,2 equal to zero and t∗
23 ≈0.1 −0.000157 ≈0.0998. The remaining probability
weight is distributed then according to t∗
24 = 0.1 and t∗
25 ≈0.000314 ≈0.0003.
Again all entries t∗
2j, j ≥6, are set equal to zero. The remaining rows are now
ﬁlled in exactly the same manner and we obtain the complete coupling matrix
T ∗. The algorithm in Appendix 5.8 is a formalisation of this construction. Note
that the fact that the set X has been sorted is crucial.
Another special case of a linear transport problem occurs when two probability
distributions with discrete sets X1 = {a1, . . . , aM} and X2 = {b1, . . . , bM} and
uniform probabilities P(ai) = P(bi) = 1/M are to be coupled. This is called an
assignment problem.
We now return to continuous random variables and state the following remark-
able result.
Theorem 2.30 (Optimal transference plan)
If the measures μX1, μX2 on X =
RNx are absolutely continuous and have bounded second-order moments, then
the optimal transference plan that solves the Monge–Kantorovitch problem cor-
responds to a deterministic coupling with transfer map
X2 = T (X1) = ∇xψ(X1),
for some convex potential ψ : RNx →R.
Proof
We assume that the inﬁmum in (2.15) is attained by deterministic cou-

54
Introduction to probability
plings. This assumption will be justiﬁed later in this section. Here we only demon-
strate that the optimal transfer map is generated by a potential ψ.3
We denote the associated PDFs by πXi, i = 1, 2. To obtain the optimal transfer
map, we seek extrema of the following functional,
K[T, Ψ] = 1
2

RNx
∥T −1(x) −x∥2πX2(x)dx
+

RNx
Ψ(x) [πX2(T (x))|DT (x)| −πX1(x)] dx,
where DT (x) denotes the Jacobian matrix of T at x, |DT (x)| = | det DT (x)|,
and Ψ : RNx →R is a Lagrange multiplier enforcing the coupling of the two
marginal PDFs under the desired transport map.
To simplify the calculation, we introduce the inverse transfer map X1 =
S(X2) = T −1(X2), and obtain the functional
L[S, Ψ] = 1
2

RNx
∥S(x) −x∥2πX2(x)dx
+

RNx
[Ψ(S(x))πX2(x) −Ψ(x)πX1(x)] dx,
having made use of the change of variables formula.
To ﬁnd the extrema of the functional, we compute the variational derivatives
with respect to S and Ψ. These are deﬁned (in the weak sense) as

RNx
Φ(x)T δL
δS (x)dx = lim
ϵ→0
1
ϵ (L[S + ϵΦ, Ψ] −L[S, Ψ]) ,

RNx
φ(x) δL
δΨ(x)dx = lim
ϵ→0
1
ϵ (L[S, Ψ + ϵφ] −L[S, Ψ]) ,
for all smooth test functions φ and maps Φ for which the limit is ﬁnite. At
the extrema, the variational derivatives are zero, and after some calculation, we
obtain the equations
δL
δS (x) = πX2(x) [(S(x) −x) + ∇xΨ(S(x))] = 0
and
δL
δΨ(x) = −πX1(x) + πX2(T (x))|DT (x)| = 0.
(2.21)
These equations characterise the critical points of the functional L. The ﬁrst
equality implies
x2 = T (x1) = x1 + ∇xΨ(x1) = ∇x
1
2xT
1 x1 + Ψ(x1)

=: ∇xψ(x1)
and the second implies that T transforms πX1 into πX2 as required.
3 See Villani (2003) for a completely general proof and also for more general results in terms
of subgradients of convex functions and weaker conditions on the two marginal measures.

2.2 Coupling of measures and optimal transportation
55
Example 2.31
Consider two univariate PDFs πX1 and πX2 with cumulative
distribution functions FX1 and FX2, respectively. Then, as already discussed, a
coupling is achieved by
x2 = T (x1) = F −1
X2 (FX1(x1)),
which is also optimal under the (·)2 distance. Furthermore, the L2-Wasserstein
distance (2.16) between πX1 and πX2 is given by
W(πX1, πX2)2 =

R

R
(x1 −x2)2δ

x2 −F −1
X2 (FX1(x1))

πX1(x1)dx1dx2
=
 1
0

R
(F −1
X1 (p) −x2)2δ

x2 −F −1
X2 (p)

dx2dp
=
 1
0
(F −1
X1 (p) −F −1
X2 (p))2dp,
(2.22)
with p = FX1(x1) and dp = πX1(x1)dx1.
Example 2.32
Consider two Gaussian distributions N(x1, P1) and N(x2, P2)
in RNx, with means x1 and x2 and covariance matrices P1 and P2, respectively.
We previously discussed the deterministic coupling (2.14). However, the induced
aﬃne transformation x2 = T (x1) cannot be generated from a potential ψ since
the matrix P 1/2
2
P −1/2
1
is not symmetric. Indeed, the optimal coupling in the sense
of Monge–Kantorovitch with cost function c(x1, x2) = ∥x1 −x2∥2 is provided by
x2 = T (x1) := x2 + P 1/2
2
!
P 1/2
2
P1P 1/2
2
"−1/2
P 1/2
2
(x1 −x1) .
(2.23)
See Olkin & Pukelsheim (1982) for a derivation. The associated Wasserstein
distance (2.16) between the two Gaussian distributions is
W(μX1, μX2)2 = ∥x1 −x2∥2 + trace

P1 + P2 −2
!
P 1/2
2
P1P 1/2
2
"1/2
.
We now make a generalisation that will be used later in the book. Assuming
that a matrix A ∈RNx×M is given such that P2 = AAT, clearly we can choose
A = P 1/2
2
in which case M = Nx and A is symmetric. However, we allow for A
to be non-symmetric, and M can be smaller than Nx in the case where P2 is not
of full rank. An important observation is that we can replace P 1/2
2
in (2.23) by
A and AT, respectively, i.e.,
T (x1) = x2 + A
#
ATP1A
$−1/2 AT (x1 −x1) .
(2.24)
In order to describe the geometric structure of optimal couplings (whether de-
terministic or not) we need to introduce the two concepts of cyclical monotonicity

56
Introduction to probability
and subdiﬀerentials of convex functions. Cyclical monotonicity is a property of
the support of a transference plan.
Definition 2.33 (Support of a measure and cyclical monotonicity)
The support
of a coupling μZ on Z = X × X is the smallest closed set on which μZ is
concentrated, i.e.
supp (μZ) :=
%
{S ⊂Z : S closed and μZ(Z \ S) = 0}.
The support of μZ is called cyclically monotone if for every set of points (xi
1, xi
2) ∈
supp (μZ) ⊂X × X, i = 1, . . . , I, and any permutation σ of {1, . . . , I}, we have
I

i=1
∥xi
1 −xi
2∥2 ≤
I

i=1
∥xi
1 −xσ(i)
2
∥2.
(2.25)
Note that (2.25) is equivalent to
I

i=1
(xi
1)T(xσ(i)
2
−xi
2) ≤0.
We will ﬁnd later that cyclical monotonicity implies that the support of a trans-
ference plan is contained in the subdiﬀerential of an appropriate convex func-
tional ψ(x). If that convex function can be shown to be suﬃciently regular then
the transference plan is deterministic. This chain of arguments can be made
rigorous, providing a proof of Theorem 2.30 (Villani 2009).
We next discuss an example for which the support of the coupling is ﬁnite.
Example 2.34
We return to the linear transport problem associated with the
optimal coupling μ∗
X1X2 of the two discrete random variables X1 and X2 as
discussed in Examples 2.28 and 2.29. From (2.19), we see that the support of the
optimal coupling is deﬁned by
(x1 = aj, x2 = ai) ∈supp (μ∗
X1X2)
if and only if
t∗
ij > 0.
(2.26)
Since the coeﬃcients ai have been sorted, cyclical monotonicity is evident from
the staircase-like structure of the non-zero entries in T ∗.
Furthermore, let T denote any coupling matrix, i.e., a matrix with non-negative
entries and
M

i=1
tij = 1/M,
M

j=1
tij = wi,
and take any two pairs (aj1, ai1) ∈R2 and (aj2, ai2) ∈R2 such that ti1j1 > 0 and
ti2j2 > 0. If this pair does not satisfy cyclical monotonicity, i.e.,
(ai1 −aj1)2 + (ai2 −aj2)2 > (ai1 −aj2)2 + (ai2 −aj1)2,

2.2 Coupling of measures and optimal transportation
57
then there is a T ′ with lower cost. Speciﬁcally, set
c = (ai1 −aj1)2 + (ai2 −aj2)2 −(ai1 −aj2)2 −(ai2 −aj1)2
= 2(ai2 −ai1)(aj1 −aj2) > 0
and deﬁne the associated entries in T ′ by
t′
i1j1 = ti1j1 −ε, t′
i2j2 = ti2j2 −ε, t′
i2j1 = ti2j1 + ε, t′
i1j2 = ti1j2 + ε
with ε > 0 chosen such that the new entries are all non-negative. Since the
associated contribution to the cost for T is given by
J = ti1j1(ai1 −aj1)2 + ti2j2(ai2 −aj2)2 + ti2j1(ai2 −aj1)2 + ti1j2(ai1 −aj2)2
we ﬁnd that
J′ = t′
i1j1(ai1 −aj1)2 + t′
i2j2(ai2 −aj2)2 + t′
i2j1(ai2 −aj1)2 + t′
i1j2(ai1 −aj2)2
= (ti1j1 −ε)(ai1 −aj1)2 + (ti2j2 −ε)(ai2 −aj2)2
+ (ti2j1 + ε)(ai2 −aj1)2 + (ti1j2 + ε)(ai1 −aj2)2
= J −εc < J
for T ′. The reduction in cost is maximised by choosing ε such that either t′
i1j1
or t′
i2j2 becomes zero. More generally, unless a coupling matrix T is cyclically
monotone, we can ﬁnd a better coupling.
We now generalise this last observation.
Theorem 2.35 (Cyclical monotonicity)
If μ∗
Z is a solution to the Monge–Kantor-
ovitch problem (2.15), then μ∗
Z has cyclically monotone support.
Proof
We prove the theorem by contradiction, i.e., we assume that there exists a
set of points (xi
1, xi
2) ∈supp (μ∗
Z), i = 1, . . . , I, and a permutation σ of {1, . . ., I}
such that
I

i=1
∥xi
1 −xi
2∥2 >
I

i=1
∥xi
1 −xσ(i)
2
∥2
for optimal μ∗
Z. Let c > 0 be deﬁned by
c =
I

i=1
∥xi
1 −xi
2∥2 −
I

i=1
∥xi
1 −xσ(i)
2
∥2.
By continuity there exist neighbourhoods U(xi
1) and U(xi
2) for all i such that
∥xi
1 −xi
2∥2 −c
2I < ∥x1 −x2∥2
for all
(x1, x2) ∈U(xi
1) × U(xi
2)
and
∥xi
1 −xσ(i)
2
∥2 + c
2I > ∥x1 −x2∥2
for all
(x1, x2) ∈U(xi
1) × U(xσ(i)
2
).
We also choose the neighbourhoods such that the sets Wi = U(xi
1)×U(xi
2) are

58
Introduction to probability
subsets of the support of μ∗
Z for i = 1, . . . , I. Next we introduce non-vanishing
probability measures μi
Z on each of the sets Wi with marginals denoted by μi
X1
and μi
X2, respectively, and measures ˜μi
Z on ˜Wi = U(xi
1) × U(xσ(i)
2
) by
˜μi
Z(dx1, dx2) = μi
X1(dx1) μσ(i)
X2 (dx2)
for i = 1, . . . , I.
A new coupling ˜μZ ∈Π(μX1, μX2) is now constructed via
˜μZ = μZ −γ
I

i=1
μi
Z + γ
I

i=1
˜μi
Z
with γ > 0 chosen small enough that ˜μZ remains non-negative. It is obvious by
construction that the marginals of ˜μZ are indeed μX1 and μX2, respectively.
Finally, we demonstrate that
Δ :=

Z
∥x1 −x2∥2μ∗
Z(dx1, dx2) −

Z
∥x1 −x2∥2˜μZ(dx1, dx2) > 0,
which provides the desired contradiction. Indeed
Δ = γ
I

i=1
∥x1 −x2∥2μi
Z(dx1, dx2) −γ
I

i=1
∥x1 −x2∥2˜μi
Z(dx1, dx2)
> γ
I

i=1
&
∥xi
1 −xi
2∥2 −c
2I
'
−γ
I

i=1
&
∥xi
1 −xσ(i)
2
∥2 + c
2I
'
= γ(c −c) = 0,
which completes the proof.
A fundamental theorem of convex analysis, Rockafellar’s theorem (Villani
2003), states that cyclically monotone sets S ⊂RNx × RNx are contained in
the subdiﬀerential of a convex function ψ : RNx →R.
Definition 2.36 (Subdiﬀerential)
The subdiﬀerential ∂ψ of a convex function
ψ at a point x ∈RNx is deﬁned as the non-empty and convex set of all m ∈RNx
such that
ψ(x′) ≥ψ(x) + mT(x′ −x)
for all x′ ∈RNx. We write m ∈∂ψ(x).
Example 2.37
Consider the convex function ψ(x) = |x|, which is diﬀerentiable
away from x = 0 with ψ′(x) = 1 for x > 0 and ψ′(x) = −1 for x < 0. At x = 0
we need to ﬁnd the set of all m such that
|x′| ≥mx′

2.2 Coupling of measures and optimal transportation
59

 
 
 
 

 	

 	
 
 	
 
 	
 
 
  
Figure 2.5 Convex potential
function ψ for the coupling
computed in Example 2.29. The
function is piecewise linear and its
subdiﬀerential ∂ψ(x1) is deﬁned as
the derivative of ψ whenever
x1 ̸= ai, i = 1, . . . , M, and as the
interval spanned by the left and right
derivatives of ψ whenever x1 = ai.
These intervals include all possible
cases x2 = ai which are coupled to
x1 = aj by a non-zero entry in t∗
ij.
and we ﬁnd that m ∈[−1, 1]. This is the interval spanned by the left and right
derivatives of ψ at x = 0. In summary, we obtain the set-valued subdiﬀerential
∂ψ(x) =
⎧
⎨
⎩
−1
for x < 0,
[−1, 1]
for x = 0,
1
for x > 0.
Given a cyclically monotone set S ∈RNx × RNx, a suitable potential ψ can be
deﬁned as follows. Pick a particular pair (x0
1, x0
2) ∈S. Then deﬁne
ψ(x) := sup{xI
2(x −xI
1) + xI−1
2
(xI
1 −xI−1
1
) + · · · + x0
2(x1
1 −x0
1)}.
(2.27)
Here the supremum is taken over all possible families of pairs {(xi
1, xi
2) ∈S}I
i=1
with integer I ≥1. Cyclical monotonicity of S implies that ψ(x0
1) ≤0 and the
particular choice I = 1 with x1
1 = x0
1 and x1
2 = x0
2 leads to ψ(x0
1) = 0.
Example 2.38
If S is ﬁnite, then (2.27) is constructive. Consider, for exam-
ple, the coupling between X1 and X2 deﬁned in Example 2.29 and set S =
supp (μ∗
X1,X2). Because of (2.26), the set S is deﬁned by
(x1 = aj, x2 = ai) ∈S if and only if t∗
ij > 0.
Using (x0
1, x0
2) = (a1, a1) in (2.27) leads to the convex potential ψ(x1) displayed
in Figure 2.5.
A compact statement of Rockafellar’s theorem is that S ⊂∂ψ for a suitable
convex potential ψ. An optimal transport map T is obtained whenever ψ is
suﬃciently regular in which case the subdiﬀerential ∂ψ(x) reduced to the classic
gradient ∇xψ and x2 = T (x1) = ∇xψ(x1). This happens, for example, when the
involved (marginal) measures are absolutely continuous with bounded second-
order moments. See Villani (2003) for more details.

60
Introduction to probability
While optimal couplings between continuous random variables are of broad
theoretical and practical interest, their computational implementation is non-
trivial. The case of discrete random variables with target space (2.17) can be
dealt with by linear transport algorithms. We will come back to this issue in
Chapter 5.
Problems
2.1
Show the following.
(i)
If X and Y are independent, then corr(X, Y ) = 0.
(ii)
If X = dY + b, then corr(X, Y ) = sgn(d).
(iii)
| corr(X, Y )| ≤1 for any random variables X, Y with bounded mean and
variance. (Hint: Use the Cauchy–Schwarz inequality.)
2.2
Consider two independent univariate Gaussian random variables X and Ξ
and deﬁne a third random variable Y for given coeﬃcient h as follows:
Y = hX + Ξ.
Provided that h ̸= 0, then X = (Y −Ξ)/h. Instead of this simple rearrangement,
we now attempt to approximate X in terms of Y alone and make the linear
ansatz
ˆX = aY + b.
Determine the unknown coeﬃcients a and b through minimisation of the expected
distance between X and ˆX, i.e. E[(X −ˆX)2]. Assume that X ∼N(x, σ2) and
Ξ ∼N(0, r2) are independent.4 Hint: Find the derivatives of
E
&
X −ˆX
'2
= E
!
(X −aY −b)2"
with respect to a and b.
2.3
Consider the joint PDF
πXY (x, y) = δ(y −h(x))πX(x)
for given function h : RNx →RNy, Nx > Ny = 1, and marginal PDF πX in X.
We assume that the sets
Ay := {x ∈RNx : h(x) = y}
(2.28)
deﬁne smooth hypersurfaces in RNx for all y ∈R. Show that the marginal PDF
πY is given by
πY (y) =

Ay
πX(x)dx.
Hint: Replace the Dirac delta function by
δε(s) =
 0
for |s| ≥ε/2,
1/ε
otherwise,
4 We will discuss such inverse problems in much more detail in Chapter 5. See also
Appendix 2.4 at the end of this chapter.

2.2 Coupling of measures and optimal transportation
61
and take the limit ε →0.
2.4
Implement the iteration (1.28) for k = 1, . . . , K with K = 109. Plot a
histogram for the resulting I = 108 iterates Ξi, deﬁned by (1.10). Relative fre-
quencies are obtained by normalising the histogram by the total sample size.
In addition, compute the autocorrelation coeﬃcients C(τ) for τ = 1, 2, 3. The
increase of the number of samples from I = 107 to I = 108 further improves
the statistical signiﬁcance of our results. However, it also increases the necessary
computer time. Repeat the experiment with the coeﬃcient 1.99999 in (1.28)
replaced by 2.0 and 1.9, respectively. What do you observe in the histograms?
Next generate samples {δj}J
j=1 with J = 5 × 106 of the accumulated mea-
surement error (2.9) from the sequence {Ξi} and plot their histogram or relative
frequencies. Use the standard estimators
δJ = 1
J
J

j=1
δj
for the mean and
σ2
J =
1
J −1
J

j=1
(δj −δJ)2
for the variance, respectively, in order to generate J = 5 × 106 samples from
the associated Gaussian N(δJ, σ2
J). Use the Matlab function randn (or similar)
to generate those samples, which we denote by Δj. Compare the histogram for
both samples sets {δj} and {Δj}. See Example 2.21 for further details on how
to verify whether a set of available samples (here the δj values), can be replaced
by samples from an appropriate Gaussian random variable.
2.5
Consider the two-dimensional Gaussian PDF n(z; z, P), z = (x1, x2) from
Example 2.18 with mean z = (x1, x2) and covariance matrix (2.6). Verify that
n(z; z, P) =
1
2π|P|1/2 exp

−1
2(z −z)TP −1(z −z)

=
1
√
2πσc
exp

−1
2σ2c
(x1 −xc)2

1
√
2πσ22
exp

−
1
2σ2
22
(x2 −x2)2

.
What are the corresponding formulas for the conditional PDF πX2(x2|x1) and
the marginal πX1(x1)?
2.6
Construct examples to show that a deterministic transport map to a mea-
sure μX2 cannot, in general, be deﬁned in the case where the measure μX1 consists
of ﬁnitely many point measures; for example,
μX1(dx) = 1
M
M

i=1
μxi(dx) = 1
M
M

i=1
δ(x −xi)dx
for given xi ∈R.
2.7
Consider the two sets
X1 = {a1 = 1, a2 = 2, a3 = 3}
and
X2 = {b1 = 1.5, b2 = 2, b3 = −1}

62
Introduction to probability
with uniform probability vectors P(ai) = P(bi) = 1/3. A coupling is deﬁned by
a matrix T ∈R3×3 with tij ≥0 and
3

i=1
tij =
3

j=1
tij = 1/3.
Find the coupling that minimises
J(T ) =
3

i,j=1
tij|bi −aj|2.
What do you notice about the sparsity structure of the optimal coupling matrix
T ∗?
2.8
Prove that (2.24) is indeed equivalent to (2.23). You may assume that
M = Nx and P2 has full rank.
2.9
The construction (2.27) can be applied to the coupling computed in Exam-
ple 2.29. Find an explicit expression for the resulting potential ψ and reproduce
Figure 2.5 from Example 2.38. Hint: The potential ψ is piecewise linear and all
ai with t∗
ij ̸= 0 for given j satisfy
ai ∈∂ψ(x = aj).
2.3
Guide to literature
An elementary introduction to basic concepts from probability theory can be
found in Chorin & Hald (2009) and Tijms (2012). A deeper mathematical treat-
ment of random variables can, for example, be found in Jazwinski (1970) and
Bre´zniak & Zastawniak (1999). The two monographs Villani (2003) and Villani
(2009) provide an in-depth introduction to optimal transportation.
2.4
Appendix: Conditional expectation and best approximation
We have previously considered pairs of random variables X and Y which are
related by smooth invertible maps ψ : RNx →RNx. In this appendix, we consider
the situation where
Y = h(X)
and h : RNx →R cannot be invertible if Nx > 1. We then assume that the sets
Ay := {x ∈RNx : h(x) = y}
deﬁne smooth hypersurfaces in RNx for all y ∈R, i.e., the sets Ay foliate RNx.
Let us introduce the conditional expectation of X given y = Y (ω):
E[X|y] :=

Ay xπX(x)dx

Ay πX(x)dx .

2.5 Appendix: Dual formulation of optimal linear transportation
63
This deﬁnition can be written more generally as
E[X|y] =

RNx
xπX(x|y)dx
with the conditional PDF here formally given by
πX(x|y) = πXY (x, y)
πY (y)
= δ(y −h(x))πX(x)

Ay πX(x)dx
.
Compare (2.28) from Problem 2.3.
The conditional expectation is a function of y = Y (ω), which we denote by
φ∗(y), i.e., E[X|y] = φ∗(y). The conditional expectation can be understood as
a best approximation of X in terms of functions φ : R →RNx of Y . Indeed the
functional
L[φ] :=

R

RNx
∥x −φ(y)∥2πX(x|y)πY (y)dxdy
= E[XTX] −2

R

Ay
2xTφ(y)πX(x)dxdy + E[φ(Y )Tφ(Y )]
=

R

φ(y)Tφ(y) −2φ∗(y)Tφ(y)

πY (y)dy + E[XTX]
is minimised for φ(y) = φ∗(y).5 In other words, in situations were we have access
to realisations y = Y (ω) of Y but not of X, ˆX(ω) := φ∗(Y (ω)) provides an
estimate for the unavailable X(ω) in the form of a best approximation. This is
an example of inference which we will discuss in much more detail in Chapter 5.
See also Chorin & Hald (2009) and Evans (2013) for a more detailed discussion
of conditional expectation.
2.5
Appendix: Dual formulation of optimal linear transportation
In this appendix, we sketch the reformulation of a linear transport problem
{t∗
ij} = arg min
{tij≥0}
M

i,j=1
tijdij,
dij = ∥ai −aj∥2
subject to the constraint
{tij} ∈S :=
⎧
⎨
⎩{tij ≥0} :
M

i=1
tij = 1/M,
M

j=1
tij = wi
⎫
⎬
⎭
5 The concept of variational derivative is needed in order to demonstrate that φ∗is a critical
point of L. Variational derivatives are discussed in Appendix 5.6.

64
Introduction to probability
as a min–max problem. First we introduce additional variables ui ∈R and
vj ∈R, i, j = 1, . . . , M. Next we deﬁne an augmented Lagrangian
L =
M

i,j=1
tijdij +
M

i=1
ui
⎛
⎝wi −
M

j=1
tij
⎞
⎠+
M

j=1
vj
.
1/M −
M

i=1
tij
/
and note that
max
{ui},{vj} L =
0 M
i,j=1 tijdij
if {tij} ∈S,
+∞
if {tij} /∈S.
Hence we can formulate the optimal transport problem as the following min–max
problem:
{t∗
ij} = arg min
{tij≥0}
max
{ui},{vj} L.
Alternatively, consider ﬁrst minimising and then maximising. In general
min
{tij≥0}
max
{ui},{vj} L ≥
max
{ui},{vj} min
{tij≥0} L
and equality holds if the dual problem
({u∗
i }, {v∗
j }) = arg max
⎧
⎨
⎩
M

i=1
uiwi + 1
M
M

j=1
vj
⎫
⎬
⎭
subject to the inequalities
dij ≥ui + vj,
(2.29)
i, j = 1, . . . , M, also has a solution. The essential observation is that L can be
rewritten as
L =
M

i=1
wiui + 1
M
M

j=1
vj +
M

i,j=1
tij (dij −vj −ui) ,
with min{tij≥0} L = −∞if (2.29) is not satisﬁed, and
min
{tij≥0} L =
M

i=1
uiwi + 1
M
M

j=1
vj
if (2.29) holds.

3
Computational statistics
In Chapter 1 we introduced the idea of using models and data to estimate, or
predict, the state of a system in the past, present or future. We highlighted that
it is important to quantify uncertainty when making predictions. In Chapter 2
we introduced the concept of a random variable X : Ω →X, whose outcome is
characterised by a probability measure μX on X. When we make a probabilistic
prediction, instead of providing a single value x0 ∈X, we provide a random vari-
able X. The random variable describes the relative likelihood of diﬀerent values
and thus quantiﬁes our uncertainty in the prediction. For real applications, the
dimension of X is often very large, which means that X itself is often very un-
wieldy. It is then convenient to communicate the uncertainty characterised by
X in terms of summary statistics, many of which take the form of approxima-
tions (also called estimates if such approximations involve realisations of random
variables) to expectation values of scalar functions f : X →R,
E[f(X)] =

X
f(x)μX(dx).
These are integrals which might be tackled by numerical quadrature, which we
shall discuss ﬁrst. However, when the dimension of X is even moderately large,
numerical quadrature becomes very computationally intensive, which motivates
the use of Monte Carlo methods for numerical integration. These methods then
lead to ensemble prediction and ﬁltering methods in later chapters.
In most cases discussed throughout this chapter X = RNx and μX is absolute
continuous with respect to the Lebesgue measure on RNx. Then Deﬁnition 2.9
tells us that there exists a PDF πX such that
μX(dx) = πX(x)dx,
i.e.,
E[f(X)] =

X
f(x)πX(x)dx,
provided the integral exists for the f under consideration.

66
Computational statistics
3.1
Deterministic quadrature
We ﬁrst consider the simpler case of univariate random variables. We will often
write f instead of E[f(X)] for simplicity. Under appropriate assumptions on f,
expectation integrals can be approximated by numerical quadrature rules.
Definition 3.1 (Numerical quadrature rules)
For a particular PDF πX, a nu-
merical quadrature rule for an integral
f =

R
f(x)πX(x)dx,
with any choice of function f, is given by
f M :=
M

i=1
bif(ci).
(3.1)
Here ci ∈R, i = 1, . . . , M, denote the quadrature points and bi > 0 denote their
weights. Let Πk(R) denote the (k+1)-dimensional linear space of all polynomials
of order k or less, i.e. of the form
f(x) = a0 + a1x + · · · + akxk.
A quadrature rule is of order p if f = f M for all integrands f(x) ∈Πp−1(R).
Diﬀerent quadrature rules are required for diﬀerent PDFs πX. We illustrate the
application of quadrature rules to expectation integrals in the following example
in which the PDF is the uniform distribution.
Example 3.2
Consider the case of a uniform distribution on the unit interval
[0, 1] and recall the notation X ∼U[0, 1] for a random variable X with PDF
πX(x) =
 1
if x ∈[0, 1],
0
otherwise.
Expectation values are then simply given by
f =
 1
0
f(x)dx.
(3.2)
The midpoint rule,
f ≈f1 = f(1/2) ,
is the lowest-order Gauss–Legendre quadrature formula with M = 1, b1 = 1, c1 =
1/2. It can be veriﬁed by explicit calculation that it integrates any linear function
f(x) = a1x + a0 exactly. The midpoint rule is therefore second-order accurate.
With M = 2, Gauss–Legendre quadrature achieves fourth-order accuracy and
the quadrature points and weights are given by
c1 = 1 −1/
√
3
2
,
c2 = 1 + 1/
√
3
2
,
b1 = b2 = 1
2.

3.1 Deterministic quadrature
67
More generally, Gauss–Legendre quadrature rules achieve order p = 2M for M
quadrature points, for the uniform distribution.
In addition to (or as an alternative to) increasing the number of quadrature
points M, the integral (3.2) may be split into a sum of integrals over ﬁnitely
many non-overlapping subintervals of [0, 1]. Consider, for example, the formal
decomposition
f =
NI

i=1
 iΔx
(i−1)Δx
f(x)dx,
(3.3)
where each subinterval is of length Δx = 1/NI with NI > 1. A Gauss–Legendre
quadrature rule can now be applied to each of the integrals in (3.3). Let us
denote the numerical result by f M,NI. If the function f is p times continuously
diﬀerentiable, then
|f M,NI −f| = O(Δxmin(p,q)),
(3.4)
for a quadrature rule of order q. Hence high-order quadrature rules are only
useful if f is suﬃciently smooth. We will come back to this issue in Example 3.4.
Another well-known family of quadrature rules are the Gauss–Hermite quadra-
ture rules for univariate Gaussian random variables, discussed in the following
example.
Example 3.3
If X′ is a univariate Gaussian random variable with mean zero
and variance one, then expectation values take the form
E[f(X′)] =
1
√
2π

R
f(x′)e−(x′)2/2dx′.
With M = 2 in (3.1), the quadrature points and weights for the Gauss–Hermite
quadrature rule of order four are given by
c1 = −1,
c2 = 1,
b1 = b2 = 1/2.
(3.5)
Assume that we want to use the same quadrature rule for approximating ex-
pectation values of another Gaussian random variable X with mean x ̸= 0 and
variance σ2 ̸= 1. We may rewrite E[f(X)] as an expectation over X′ as follows,
E[f(X)] =

R
f(x)πX(x)dx
=

R
f(x) πX(x)
πX′(x)πX′(x)dx
= E

f(X′) πX(X′)
πX′(X′)

.

68
Computational statistics
This suggests the following quadrature formula for f = E[f(X)] given by
fM =
M

i=1
bif(ci) πX(ci)
πX′(ci) =
M

i=1
ˆbif(ci),
with new weights
ˆbi = bi
πX(ci)
πX′(ci).
For constant f = f0, we expect to obtain f M = f0, but in general 
i ˆbi ̸= 1:
the order of the quadrature rule has dropped from p = 2M to p = 0! In order to
recover p = 1, we could use the normalised weights
˜bi =
ˆbi
M
j=1 ˆbj
=
bi
πX(ci)
πX′(ci)
M
j=1 bj
πX(cj)
πX′ (cj)
.
(3.6)
A much better remedy is to realise that X is also Gaussian distributed and
that the quadrature rule could be adjusted by using a change-of-variables for-
mula to change the quadrature points ci instead of the weights. Applying the
transformation x′ = (x −x)/σ and dx = σdx′, we get
E[f(X)] =
1
√
2πσ
 ∞
−∞
f(x)e−(x−x)2/2σ2dx
=
1
√
2π
 ∞
−∞
f(σx′ + x)e−(x′)2/2dx′ = E[f ′(X′)],
where f ′(x) = f(σx + x). We conclude that Gauss–Hermite quadrature points
for a Gaussian random variable with mean x and variance σ2 are given by
ˆci = σci + x.
Note that a linear transformation does not change the order of a polynomial
f ′ ∈Πk(R) and, hence, the order of a quadrature rule is preserved.
In Example 3.3 we observed that when transforming between two Gaussian
random variables with diﬀerent means and variances, changing the quadrature
points preserves the order of the quadrature rule, whereas changing the quadra-
ture weights does not. The choice between changing the weights of a quadrature
rule or changing the location of its quadrature points (or both) will be a recurring
theme of this book.
The following example demonstrates the reduction in convergence rate that
occurs for non-smooth functions.
Example 3.4
Let φ : [0, 1] →[0, 1] denote the tent map deﬁned by
φ(x) =
 2x
if x ≤1/2,
2 −2x
otherwise.

3.1 Deterministic quadrature
69
We compute expectation values with respect to X ∼U[0, 1/2] with PDF
πX(x) =
 2
if x ∈[0, 1/2],
0
otherwise,
and f given by application of φ n times, i.e.,
f(x) = φ(φ(· · · (φ(x)) · · · ))



n times
= φn(x),
n ≥1.
(3.7)
Since
E[φn(X)] = 2
 1/2
0
φn(x)dx = 2
 1/2
0
φn−1(φ(x))dx
= 2
 1/2
0
φn−1(2x)dx =
 1
0
φn−1(x)dx
= 2
 1/2
0
φn−1(x)dx = E[φn−1(X)],
n > 1,
and
E[φ(X)] = 2
 1/2
0
φ(x)dx = 2
 1/2
0
2xdx = 1/2,
the analytic value for f = E[φn(X)] is equal to 1/2 for all n ≥1. The midpoint
rule for the interval [0, 1/2] can be obtained by transforming the quadrature point
c1 = 1/2 to ˆc1 = 1/4 while keeping the weight b1 = 1 (compare the previous
Example 3.3). The midpoint rule yields the exact result for n = 1. However,
since
φn(ˆc1) =
⎧
⎨
⎩
1/2
for n = 1,
1
for n = 2,
0
otherwise,
the approximation errors for the implicit midpoint method increase to 0.5 in
absolute value for n > 1.
Even more revealing is the behaviour of the implicit midpoint rule applied to
the formulation (3.3) with f = φn. To examine this, we now ﬁx n = 50 and
increase the number of subintervals NI ≫1. Following the result (3.4), if f were
twice continuously diﬀerentiable, we could expect second-order convergence. This
is not conﬁrmed by the numerical results displayed in Figure 3.1. The reason is
that f = φ50 is a highly irregular function. The numerical results indicate that
the eﬀective order of convergence drops to p = 1 in this case.
A quadrature rule with quadrature points ci and weights bi yields exact ex-
pectation value with respect to the empirical measure of the form
μM(dx) :=
M

i=1
wiμxi(dx) =
M

i=1
wi δ(x −xi)dx,
(3.8)

70
Computational statistics
10
6
10
5
10
4
10
3
10
2
10
1
10
12
10
10
10
8
10
6
10
4
10
2
10
0
Δ x = 1/(2NI)
approximation error
numerical order of convergence for implicit midpoint
error from implicit midpoint
p=1/2 convergence
p=1 convergence
p=2 convergence
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
function f = φn for n=4
x variable
Figure 3.1 Top: approximation errors from the midpoint rule applied to (3.3) with
f = φn, n = 50. The approximation error is displayed as a function of the interval length
Δx = 1/(2NI) of subintervals. The classic order of the implicit midpoint order is p = 2
but only p = 1 is observed in this example, where f is a highly irregular function. Bottom:
plot of the function φn(x) for n = 4.
with weights wi = bi and samples xi = ci. Recall that μxi denotes the point
measure centred at xi and that δ(·) is the Dirac delta function. The empirical
measure μM is a probability measure if M
i=1 wi = 1 since therefore

RNx
μM(dx) = 1.

3.1 Deterministic quadrature
71
Proceeding, insertion of the empirical measure into the expectation formula gives
f =

X
f(x)μM(dx) =
M

i=1
wif(xi) =
M

i=1
bif(ci),
(3.9)
as required. Hence, an interpretation of quadrature rules for expectation integrals
is that we ﬁrst approximate the measure μX by the empirical measure (3.8), and
then evaluate all expectations exactly with respect to that measure. We shall
see later in this chapter that if we take a sequence of quadrature rules with
increasing number of quadrature points for which the expectations converge,
then the corresponding sequence of empirical measures converges in a certain
(weak) sense to μX.
Gauss-type quadrature rules are extremely powerful whenever they are appli-
cable. However, the data assimilation problems considered in this book lead to
random variables in very high-dimensional spaces. Under those circumstances,
standard quadrature rules, such as Gauss–Hermite or Gauss–Legendre, are no
longer useful. For example, a straightforward approximation of an integral
f =
 1
0
· · ·
 1
0
f(x1, . . . , xNx)dx1 · · · dxNx =

[0,1]Nx
f(x)dx
(3.10)
in RNx by a product of Nx one-dimensional quadrature rules, each with M
quadrature points, leads to a regular array of M Nx quadrature points in RNx.
This number quickly becomes very large as the dimension of the problem in-
creases and the associated computational eﬀort cannot be justiﬁed, especially in
combination with a possible reduction of order as encountered in the previous
example. This is often referred to as the “curse of dimensionality”.
A popular method for reducing the computational eﬀort of high-dimensional
integrals of type (3.10) is the analysis of variance (ANOVA) representation of
an integrand f. In order to demonstrate the basic idea, we set Nx = 3 and
x = (x1, x2, x3)T in (3.10). We seek a decomposition of f of the form
f(x1, x2, x3) = f0 + f1(x1) + f2(x2) + f3(x3) + f12(x1, x2)
+ f13(x1, x3) + f23(x2, x3) + f123(x1, x2, x3).
(3.11)
Once such a decomposition is available, the ﬁrst three non-trivial terms can
be integrated by standard univariate quadrature rules. The next three terms
require more work but still reduce to two-dimensional quadrature rules, while
only the last term requires a full three-dimensional quadrature approach. The
key idea of ANOVA is now to choose the decomposition such that the signiﬁcant
contributions to the integral come from the lower-order terms in (3.11). This can
be achieved as follows. We deﬁne
f0 = E[f(X)] =

[0,1]3 f(x1, x2, x3) dx1dx2dx3,

72
Computational statistics
and set
fl(xl) =

[0,1]2 f(x)
1
j̸=l
dxj −f0,
l = 1, 2, 3.
We then continue at the next level with
flk(xl, xk) =

[0,1]
f(x)dxj −fl(xl) −fk(xk) −f0,
j ̸= k, j ̸= l, k < l ≤3.
We ﬁnally obtain
f123(x) = f(x) −f12(x1, x2) −f13(x1, x3) −f23(x2, x3)
−f1(x1) −f2(x2) −f3(x3) −f0.
(3.12)
The decomposition (3.12) has the desirable property that all terms in (3.11) are
mutually orthogonal under the inner product
⟨g, f⟩=

[0,1]3 g(x)f(x)dx,
for two functions f, g : [0, 1]3 →R. Hence the variance of the integrand, i.e.,
σ2 =

[0,1]3 (f(x) −E[f(X)])2 dx,
is equivalent to
σ2 = σ2
1 + σ2
2 + σ2
3 + σ2
12 + σ2
23 + σ2
13 + σ2
123,
(3.13)
with, for example,
σ2
1 =
 1
0
(f1(x1) −E[f1(X1)])2 dx1,
and the other variances deﬁned accordingly.
ANOVA decompositions can easily be derived analytically for integrands which
are sums or products of univariate functions. However, ANOVA decompositions
cannot be used directly for designing high-dimensional quadrature rules since
the constant f0 term already requires the computation of a high-dimensional
integral. This limitation of the classic ANOVA decomposition has led to the
anchored ANOVA (Holtz 2011) decomposition. ANOVA approximations to an
integral (3.10) are based on the observation that the individual variances in
(3.13) decrease for suﬃciently regular integrands f(x) as the dimensionality of
the involved functions in (3.11) increases. The number of quadrature points in
each of the associated integrals may then be adjusted accordingly. Ultimately,
ANOVA-type approximations lead to sparse grid quadrature rules (Holtz 2011).
Sparse grid approximation can be very eﬃcient provided the integrands in (3.10)
are suﬃciently regular.
Laplace’s method is another eﬃcient approximation method for expectation

3.1 Deterministic quadrature
73
values in high dimensions. There are two key assumptions behind Laplace’s
method. First, there is a function g such that
f(x)πX(x) = e−g(x),
and second, g has a unique global minimum denoted by x0. In that case we may
expand g about x0 to obtain
g(x) = g(x0) + g′(x0)
  
=0
(x −x0) + 1
2g′′(x0)(x −x0)2 + · · ·
= g(x0) + 1
2g′′(x0)(x −x0)2 + · · · ,
where we have assumed x ∈R for notational simplicity, and where primes de-
note diﬀerentiation with respect to x. Since x0 is the unique minimum, we have
g′′(x0) > 0. Substituting this expansion into f gives
f ≈e−g(x0)

R
e−g′′(x0)(x−x0)2/2dx.
Then, making use of the fact that

R
e−g′′(x0)(x−x0)2/2dx =
2
2π
g′′(x0),
we ﬁnally obtain the approximation
f ≈e−g(x0)
2
2π
g′′(x0).
This approximation becomes very useful in higher dimensions, since it always
leads to a global integral of a multivariate Gaussian function which can be eval-
uated analytically. It is valid provided g quickly increases away from x0. In this
case we may assume that signiﬁcant contributions to the expectation value f are
from regions near x0, where the Taylor expansion of g can be applied. On a more
formal level the following asymptotic result holds.
Lemma 3.5 (Laplace’s method)
Assume that ˜g : [a, b] →R is twice diﬀeren-
tiable and has a unique global minimum at x0 ∈[a, b]. Then
lim
ε→0
 b
a e−˜g(x)/εdx
e−˜g(x0)/ε3
2πε
˜g′′(x0)
= 1.
We formally have g(x) = ˜g(x)/ε in our description of Laplace’s method.
Example 3.6
We consider the approximation of
E[cos(X)] =
1
√
2πε

R
cos(x)e−x2/(2ε)dx

74
Computational statistics
by Laplace’s method, where X is a Gaussian with mean zero and variance ε > 0.
We ﬁrst rewrite the integral as
E[cos(X)] =
1
√
2πε

R
(cos(x) + 1)e−x2/(2ε)dx −
1
√
2πε

R
e−x2/(2ε)dx
=
1
√
2πε

R
(cos(x) + 1)e−x2/(2ε)dx −1,
and apply Laplace’s method to the remaining integral,
I =
1
√
2πε

R
(cos(x) + 1)e−x2/(2ε)dx
=
1
√
2πε

R
e−x2/(2ε)+ln(cos(x)+1)dx.
Hence, using the notation of Lemma 3.5,
˜g(x) = x2
2 −ε ln(cos(x) + 1),
with a unique global minimum x0 = 0 for all ε > 0 suﬃciently small, since
˜g′(x) = x + ε
sin(x)
1 + cos(x).
Hence ˜g(x0) = −ε ln(2), and the second derivative satisﬁes
˜g′′(x0) = 1 + ε
2.
Finally we obtain the Laplace approximation
E[cos(X)] ≈
eln(2)

1 + ε/2
−1 =
2

1 + ε/2
−1,
for ε suﬃciently small. We compare this approximation to the exact value of the
integral, which is e−ε/2, and to numerical approximations using the fourth-order
Gauss–Hermite quadrature rule with quadrature points and weights given by
(3.5). The results are displayed in Figure 3.2 for ﬁnite ε. These two approximation
methods lead to virtually indistinguishable results.
3.2
Monte Carlo quadrature
We now introduce an extremely ﬂexible and powerful family of methods for ap-
proximating integrals: Monte Carlo methods. Monte Carlo methods have been
developed as random and mesh-free alternatives to grid-based quadrature rules.
Monte Carlo methods can be used to approximate statistics, for example ex-
pectation values E[f(X)] of a random variable X. We begin by discussing the
special case f(x) = x, i.e. the mean.

3.2 Monte Carlo quadrature
75
10
6
10
4
10
2
10
0
10
14
10
12
10
10
10
8
10
6
10
4
10
2
10
0
ε
approximation error
Gauss−Hermite quadrature
Laplace approximation
Figure 3.2 Approximation errors for
Laplace’s method and the
fourth-order Gauss–Hermite
quadrature rule. Both methods
display second-order accuracy in ε.
However, while Laplace’s method
extends easily to higher dimensions,
the same does not hold true for
Gauss–Hermite quadrature rules.
Definition 3.7 (Empirical mean)
Given a sequence Xi, i = 1, . . . , M, of inde-
pendent random variables1 with identical PDF πX (so that they have a joint
measure equal to the product PDF M
i=1 πX(xi)), the empirical mean is
xM = 1
M
M

i=1
xi,
for independent samples (x1, x2, . . . , xM) = (X1(ω), X2(ω), . . . , XM(ω)).
The empirical mean xM constitutes a Monte Carlo approximation to the inte-
gral

R xμX(dx). Before we discuss the application of Monte Carlo approxima-
tions to more general integrals (in particular, expectation values), we need to
understand the sense in which xM provides an approximation to the mean x as
M →∞. We note that xM itself is the realisation of a random variable
XM = 1
M
M

i=1
Xi.
(3.14)
We quantify the error in the empirical mean by using the mean squared error
(MSE), given by
MSE(XM) = E[(XM −x)2]
= (E[XM] −x)2 + E
#
(XM −E[XM])2$
,
(3.15)
as a measure for the approximation error. Here we have decomposed the MSE
into two components: squared bias and variance. Such a decomposition is possible
for any estimator and is known as the bias-variance decomposition. The bias
measures the systematic deviation of the estimator from the true expectation
value, whilst the variance measures the ﬂuctuations in the estimator due to the
use of random samples. The particular estimator XM is called unbiased since
1 Recall Deﬁnition 2.19.

76
Computational statistics
E[XM] = x for any M ≥1. Furthermore, the variance of the estimator satisﬁes
E
#
(XM −E[XM])2$
= σ2
M
provided that σ2 = E[(X−x)2] < ∞. This result holds since the random variables
Xi in (3.14) are independent and identically distributed.
Estimators for other quantities may contain biases, as described in the follow-
ing example.
Example 3.8
Consider the task of estimating the covariance matrix P of a
random variable X with PDF πX. We again assume that Xi, i = 1, . . . , M,
are independent and identically distributed random variables with PDF πX. In
analogy with the estimator (3.14) for the mean, we ﬁrst consider the estimator
ˆPM = 1
M
M

i=1
(Xi −xM)(Xi −xM)T.
However, while the estimator for the mean is unbiased, the same does not hold
for ˆPM. We demonstrate this for M = 2 and E[X] = 0, in which case we obtain
E[ ˆPM] = 1
2E
4 2

i=1
(Xi −1
2(X1 + X2))(Xi −1
2(X1 + X2))T
5
= 1
2
1
2E[X1XT
1 ] + 1
2E[X2XT
2 ]

= 1
2P,
and the estimator is biased. An unbiased estimator is given by the modiﬁcation
ˆPM =
1
M −1
M

i=1
(Xi −xM)(Xi −xM)T .
Since (M −1)/M →1 as M →∞, both estimators agree in the limit M →∞.
Realisations ˆPM(ω) of the estimator ˆPM, i.e. actual estimates based on samples
xi, will be denoted by PM throughout this book.
We now discuss the convergence of a sequence of random variables such as
(3.14) for M →∞with independent and identically distributed samples {Xi}.
We may ﬁrst ask in what sense such a sequence of random variables may converge.
Definition 3.9 (Convergence of sequences of random variables)
Let XM, M ≥1,
denote a sequence of (univariate) random variables. Such a sequence converges
with probability one to a random variable X if
P( lim
M→∞XM = X) = 1.

3.2 Monte Carlo quadrature
77
The sequence is said to converge in probability to X if for every ε > 0 it holds
that
lim
M→∞P(|XM −X| > ε) = 0.
Finally, the sequence converges weakly (or in distribution) to X if
lim
M→∞E[g(XM)] = E[g(X)],
for any bounded and continuous function g.
We also recall the central limit theorem and Chebychev’s inequality, which are
essential tools for studying the asymptotic behavior of estimators.
Theorem 3.10 (Central limit theorem)
Given a sequence Xi, i = 1, . . . , M, of
independent univariate random variables with identical PDF πX, mean x, and
ﬁnite variance σ2, then the random variable XM, deﬁned as
XM =
6
M
σ2
4
1
M
M

i=1
Xi −x
5
=
6
M
σ2 (XM −x),
(3.16)
converges weakly to a Gaussian random variable with mean zero and variance
one as M →∞.
For quadrature rules, we are able to quantify convergence of expectations as
the number of quadrature points goes to inﬁnity, if the function and PDF are
suﬃciently smooth. For the empirical mean, this is replaced by the concept of a
conﬁdence interval and its scaling as M →∞. Under repeated sampling of the
empirical mean xM, a conﬁdence interval is constructed such that the true mean
value x is contained within the conﬁdence interval with some chosen probability
(typically 95% is used).
Example 3.11
Suppose Xi, i = 1, . . . , M, are independent and identically dis-
tributed random variables with mean x and variance σ2. Consider the estimator
(3.14) with M ≫1 such that the distribution of XM can be well approximated
by a Gaussian with mean x and variance
σ2
M = σ2
M ,
according to the central limit theorem. The constant c in the 95% conﬁdence
interval I = [xM −c, xM + c] for a given estimate xM = XM(ω) is deﬁned by
the condition
P

−c ≤XM −x ≤c

≈
 x+c
x−c
n(x; x, σ2
M)dx = 0.95.
It follows that
c ≈1.96σM = 1.96
σ
M 1/2,
for a Gaussian distribution N(x, σ2
M). Hence, averaged over many estimates xM,

78
Computational statistics
the true mean x will fall within the conﬁdence interval I ≈[xM −1.96σM, xM +
1.96σM] in 95% of the cases.
Hence we may conclude that the empirical mean xM converges with a rate
of M −1/2 to the mean x. The same convergence rate can be derived without a
Gaussian approximation using Chebychev’s inequality, which we introduce next.
Theorem 3.12 (Chebychev’s inequality)
Let the random variable XM be deﬁned
by (3.14). Then Chebychev’s inequality states that
P

|XM −x| ≥kσM

≤1
k2 ,
k > 0
with σ2
M = σ2/M.
For example, set k = 1/
√
0.05 ≈4.47. Then the 95% conﬁdence interval I
of XM satisﬁes I ⊂[xM −kσM, xM + kσM] independently of whether XM is
Gaussian or not, and goes to zero as M →∞with rate p = 1/2.
Proof
We introduce the indicator function of a set I ⊂R:
χI(x) =
 1
if x ∈I,
0
otherwise.
Choose I = {x ∈R : |x| ≥kσM}, and introduce YM = XM −x. Then
P

|XM −x| ≥kσM

= E[χI(YM)]
≤E
4 YM
kσM
25
=
1
k2σ2
M
E[(XM −x)2] = 1
k2 .
Here we have used the properties y2/(kσM)2 ≥χI(y) for all y ∈R, and E[(XM −
x)2] = σ2
M.
We also mention that the strong law of large numbers states that
P( lim
M→∞XM = x) = 1,
provided E[|X|] < ∞. In other words, the sequence XM converges with probabil-
ity one to the mean x of the underlying (univariate) random variables Xi ∼πX.
The weak law of large numbers is a statement of convergence in probability, i.e.,
lim
M→∞P(|XM −x| > ε) = 0
for all ε > 0. Both laws imply that Monte Carlo approximations xM converge to
the mean x as M →∞. However, in contrast to the central limit theorem and
Chebychev’s inequality, they do not provide a rate of convergence.
Of course, Monte Carlo methods can be used to approximate the expectation

3.2 Monte Carlo quadrature
79
value of functions more general than f(x) = x. In fact, in contrast with grid-
based methods, for which certain smoothness assumptions have to be made on
f in order to achieve higher-order convergence, Monte Carlo methods can be
applied to any f as along as, for example, the second moment E[Y 2] of Y = f(X)
is bounded.
Definition 3.13 (Monte Carlo approximation)
For a given PDF πX and a mea-
surable function f, let Xi, i = 1, . . . , M, be independent random variables with
identical PDF πX. Then the Monte Carlo approximation to E[f(X)] is given by
fM =
M

i=1
wif(xi),
(3.17)
where (x1, x2, . . . , xM) = (X1(ω), X2(ω), . . . , XM(ω)) are the i.i.d. samples and
wi = 1/M denote uniform weights.
Example 3.14
We return to Example 3.4 and approximate the integral
f =
 1/2
0
2f(x)dx,
with f deﬁned by (3.7) and n = 50. In order to implement a Monte Carlo approxi-
mation, we need to simulate samples xi from U[0, 1/2]. Most scientiﬁc computing
software packages contain a pseudo random number generator which will simu-
late samples ˆxi from the U[0, 1] distribution. A simple change of variables can
be used to deﬁne the Monte Carlo approximation
fM = 1
M
M

i=1
f(ˆxi/2).
The resulting errors for diﬀerent M for particular realisations of the random vari-
ables are displayed in Figure 3.3; a convergence rate of 1/
√
M on average can be
observed. Note that the number of samples, M, of a Monte Carlo approximation
corresponds to the number of subintervals NI in (3.3).
We shall see that Deﬁnition 3.13 is part of a more general framework in which
an alternative joint distribution is used to generate the sample sequence {Xi}.
This distribution can produce accurate estimates of statistics, provided that we
also modify the weights.
Definition 3.15 (Generalised Monte Carlo approximation)
A generalised Monte
Carlo approximation to E[f(X)] uses Equation (3.17) but with a diﬀerent (and
possibly non-independent) joint distribution with PDF ˜πM(x1, . . . , xM) for the
sequence of random variables {Xi}, and non-uniform weights {wi} subject to
the conditions wi > 0, i = 1, . . . , M, and M
i=1 wi = 1.

80
Computational statistics
10
6
10
5
10
4
10
3
10
2
10
1
10
12
10
10
10
8
10
6
10
4
10
2
10
0
1/M
approximation error
numerical order of convergence for Monte Carlo method
error from Monte Carlo method
p=1/2 convergence
p=1 convergence
p=2 convergence
Figure 3.3 Expectation value for f deﬁned by (3.7) with n = 50 resulting from a Monte
Carlo approximation using M independent samples from X ∼U[0, 1/2]. We observe an
order 1/
√
M convergence on average. Note that any speciﬁc error depends on the drawn
samples and is therefore the outcome of a random experiment.
Appropriate choices for the weights wi of a generalised Monte Carlo method
will be discussed shortly.
Approximation of expectations by standard quadrature rules can be incorpo-
rated into the (generalised) Monte Carlo framework by formally selecting the
joint PDF ˜πM as a product of Dirac delta functions, i.e.,
˜πM(x1, . . . , xM) =
M
1
i=1
δ(xi −ci),
or, properly written as a measure,
˜μM(dx1, . . . , dxM) =
M
1
i=1
μci(dxi),
and weights wi = bi. There is, however, a major diﬀerence: for a given quadrature
rule, the realisations (x1, . . . , xM) = (c1, . . . , cM) are always the same, but for
a Monte Carlo scheme the samples – and hence the induced empirical measure
(3.8) – will be diﬀerent each time we draw realisations from the sequence of ran-
dom variables (X1, X2, . . . , XM) with joint PDF ˜πM. This renders the analysis
of convergence of the induced empirical measure as M →∞somewhat more
complicated in the Monte Carlo case.

3.3 Sampling algorithms
81
3.3
Sampling algorithms
We now discuss some practical aspects of how to implement Monte Carlo meth-
ods. Monte Carlo methods are easy to implement provided that it is possible to
simulate the random variables {Xi}. Most scientiﬁc computing software packages
provide (pseudo) random number generators for the uniform and the standard
Gaussian distribution. The following techniques will allow us to move beyond
those distributions.
The transform method is the ﬁrst method we discuss for generating Monte
Carlo samples from a PDF πX of a univariate random variable X. It is based on
the idea of coupling which was introduced in Chapter 2.
Lemma 3.16 (Transform method for sampling)
Let X and Y be random vari-
ables, and let T be a transport map that deﬁnes a coupling between them. Let
{xi} be a sequence of independent and identically distributed samples from X.
Then {T (xi)} is a sequence of independent and identically distributed samples
from Y .
Proof
First, it is clear that {T (Xi)} are independent, identically distributed,
since {Xi} are. Further, Y and T (X) have the same law (weakly) if E[f(Y )] =
E[f(T (X))] for all suitable test functions f (i.e., functions for which the expec-
tations are ﬁnite). This is guaranteed by the deﬁnition of the transport map
(2.12).
In Example 2.25, we deﬁned a transport map for univariate random variables,
via the cumulative distribution function. This map can be used to transform
the uniform distribution (which is easy to simulate on a computer) into other
distributions, as described in the following example.
Example 3.17
Given a univariate random variable X with PDF πX and cu-
mulative distribution function
FX(x) =
 x
−∞
πX(x′)dx′,
we ﬁrst draw M samples ui from independent random variables Ui with uniform
distribution U[0, 1] and then solve the implicit equation
FX(xi) = ui,
(3.18)
for xi ∈R, i = 1, . . . , M. The samples xi provide realisations from M indepen-
dent and identically distributed random variables with PDF πX.
In order to generate univariate Gaussian random numbers using the transform
method, we must evaluate the error function
erf (t) =
2
√π
 t
0
e−s2ds,

82
Computational statistics
and its inverse. Neither can be expressed in terms of elementary functions. This
problem can be circumvented by generating a pair of independent Gaussian
random variables from a pair of independent uniform random variables.
Example 3.18
We deﬁne a transport map between a pair of independent Gaus-
sian random variables X1, X2 ∼N(0, 1) and a pair of independent uniform ran-
dom variables U1, U2 ∼U[0, 1], as follows,
X1 =

−2 ln U1 sin(2πU2),
X2 =

−2 ln U1 cos(2πU2).
This is a transport map since
dx1dx2 = det
.
−
sin(2πu2)
u1
√−2 ln u1
2π√−2 ln u1 cos(2πu2)
−
cos(2πu2)
u1
√−2 ln u1
−2π√−2 lnu1 sin(2πu2)
/
du1du2
=

2π cos(2πu2)2
u1
+ 2π sin(2πu2)2
u1

du1du2
= 2π
u1
du1du2.
We also ﬁnd that
u1 = e−(x2
1+x2
2)/2,
and therefore
du1du2 =
1
√
2π
e−x2
1/2dx1
1
√
2π
e−x2
2/2dx2,
which implies
E[f(X1, X2)] =
 1
0
 1
0
f(x1, x2)du1du2 = E[ ˜f(U1, U2)],
with ˜f(u1, u2) = f(x1(u1, u2), x2(u1, u2)). The resulting sampling method is
called the Box–Muller algorithm.
Example 3.19
In this example, we discuss a multidimensional case of the trans-
form approach. Mathematical software packages typically provide pseudo random
number generators for multivariate Gaussian random variables with mean zero
and covariance matrix P = I. As an example, consider two multivariate Gaussian
distributions N(x1, P1) and N(x2, P2) in RNx with means x1 = 0 and x2 ̸= 0,
and covariance matrices P1 = I and P2 ̸= I, respectively. The coupling (2.14)
leads to the well-known transformation
X2 = x2 + P 1/2
2
X1,
which, in this particular case, coincides with the optimal coupling given by (2.23).

3.3 Sampling algorithms
83
This transformation can be used to generate samples from a Gaussian distribu-
tion N(x, P) based on available random number generators.
As we have already discussed in Chapter 2 in the context of optimal trans-
portation, there exist mappings T which transform a random variable X with
PDF πX into another random variable Y with PDF πY under quite general
assumptions. Furthermore, those maps can be generated by convex potentials
ψ, i.e., Y = T (X) = ∇xψ(X). This result allows us to extend the transform
method to more general multivariate random variables, at least theoretically.
We will return to this issue in Chapter 5 when we discuss Bayesian inference;
we will introduce an approximation scheme for transforming random variables
based on linear transportation.
In many cases, obtaining an exact solution to (3.18) is intractable or expen-
sive. In Example 3.3, whilst discussing Gauss–Hermite quadrature, we explored
reformulating integrals with respect to a PDF πX as
E[f(X)] =

RNx
f(x) πX(x)
πX′(x)πX′(x)dx.
This formula is also useful for generalised Monte Carlo approximation, in the
case where πX′(x) denotes the PDF of a random variable X′ which we can easily
draw samples from. We then use (3.17) with weights
wi =
πX(xi)/πX′(xi)
M
j=1 πX(xj)/πX′(xj)
,
where {xi} are samples from M independent and identically distributed random
variables X′
i with PDF πX′. This is referred to as importance sampling, our
second type of Monte Carlo method.
Definition 3.20 (Importance sampling)
Let X be a random variable with PDF
πX and X′ be a second random variable with PDF πX′ such that
πX(x) = 0
if
πX′(x) = 0,
i.e., the measure μX(dx) = πX(x)dx is absolutely continuous with respect to
μX′(dx) = πX′(x)dx. Assume that we wish to obtain expectation formulas for
X, but that it is much easier or eﬃcient to sample from X′. Then, the importance
sampling estimate of E[f(X)] is given by
E[f(X)] ≈
M

i=1
wif(x′
i),
where {x′
i} are M independent samples from the random variable X′. The
weights {wi} are given by
wi ∝πX(x′
i)
πX′(x′
i),

84
Computational statistics
where the constant of proportionality is chosen such that 
i wi = 1.2
The choice of the random variable X′ might be determined by the availabil-
ity of suitable random number generators and/or by accuracy considerations
(minimising the variance of the resulting estimator).
In the following example, we illustrate importance sampling as a method for
reducing the variance of a Monte Carlo estimator.
Example 3.21
We consider the approximation of the expectation value
E[e−10X cos(X)] =
 1
0
e−10x cos(x)dx,
(3.19)
with respect to X ∼U[0, 1]. Its analytic value is given by
E[e−10X cos(X)] = 10
101 −10 cos(1) −sin(1)
101e10
.
We can approximate this value by drawing M independent samples ui from the
uniform distribution U[0, 1], i.e.,
xM = 1
M
M

i=1
cos(ui)e−10ui.
Since e−10x decays very rapidly away from zero, it seems reasonable to replace
the uniform samples ui by samples xi ∈[0, 1], which are concentrated around
zero. For example, we may take X′ to have PDF
πX′(x) =
0
10e
10x
1−e
10
if x ∈[0, 1],
0
otherwise.
Samples xi from this distribution can be generated using the transform method
with cumulative distribution function
FX′(x) =
⎧
⎪
⎨
⎪
⎩
1
if x ≥1,
1−e
10x
1−e
10
if x ∈[0, 1),
0
otherwise.
We obtain the explicit formula
xi = −0.1 ln(1 −ui + uie−10)
for independent samples ui from the uniform distribution U[0, 1]. The expecta-
tion value (3.19) is now approximated by
xM = 1
M
M

i=1
cos(xi)1 −e−10
10
.
2 Using unnormalised weights wi = πX(x′
i)/πX′(x′
i) leads to an unbiased estimator of
E[f(X)]. This is beneﬁcial in certain situations but stops the associated measure (3.8) from
being a probability measure. Unnormalised weights are implicitly applied in Example 3.21.

3.3 Sampling algorithms
85
As illustrated in Figure 3.4, we observe in numerical experiments that the vari-
ance of this estimator,
σ2
M = E[(XM −E[XM])2],
is reduced by a factor of about ten thousand in comparison to a standard Monte
Carlo implementation meaning that the accuracy (width of the conﬁdence inter-
vals) is improved by a factor of one hundred.
It should be noted that the performance of importance sampling is rather
sensitive to the integrand. For example, if we replace (3.19) by
E[e−10X sin(X)] =
 1
0
e−10x sin(x)dx,
(3.20)
then the same importance sampling approach does not give any reduction in
variance and there is no improvement in the associated estimator.
A third type of Monte Carlo methods is rejection sampling. Rejection sampling
is based on two ingredients: a proposal PDF πP (x), and a constant m > 1 such
that πX(x) < m πP (x) for all x ∈RNx. Rejection sampling is summarised in the
following algorithm.
Algorithm 3.22 (Rejection sampling)
For i = 1, . . . , M do the following.
(i) Use a random number generator to generate a sample x ∈RNx from a ran-
dom variable X′ with PDF πP and draw a u from the uniform distribution
U[0, 1].
(ii) If
u < πX(x)
mπP (x),
then set xi = x, increase i by one, and go back to (i). Otherwise reject the
proposal, x, and return to (i).
Lemma 3.23 (Consistency of rejection sampling)
Rejection sampling generates
samples xi, i = 1, . . . , M, from M independent and identically distributed ran-
dom variables Xi with PDF πX.
Proof
The independence of the accepted samples follows from their deﬁnition.
The correct distribution follows from rearrangement of Equation (2.3) into the
standard conditional probability identity3
π(x|accept) = P(accept|x) π(x)
P(accept)
,
where π(x|accept) denotes the conditional PDF that a proposed x is accepted,
3 Much more shall be said about this formula in Chapter 5.

86
Computational statistics
10
8
10
6
10
4
10
2
10
0
10
6
10
5
10
4
10
3
10
2
10
1
10
0
1/M
approximation error
Comparison between standard Monte Carlo and importance sampling
standard Monte Carlo
importance sampling
reference 1/M1/2
10
8
10
6
10
4
10
2
10
0
10
4
10
3
10
2
10
1
10
0
1/M
approximation error
Comparison between standard Monte Carlo and importance sampling
standard Monte Carlo
importance sampling
reference 1/M1/2
Figure 3.4 Comparison between a standard Monte Carlo approximation to the
expectation value (3.19) and an importance sampling Monte Carlo approximation. The
top ﬁgure shows that an error reduction by a factor of about one hundred is achieved in
this case. However, the same importance sampling approach applied to (3.20) does not
lead to an improvement. See bottom ﬁgure. This result indicates that importance
sampling for reducing the variance of estimators needs to be handled with great care.
and P(accept|x) is the conditional probability to reach acceptance for a given x.
Note that P(reject|x) = 1 −P(accept|x). Rejection sampling leads to
P(accept|x) = πX(x)
mπP (x),

3.3 Sampling algorithms
87
and
π(x) = πP (x).
Hence
P(accept) =

RNx
P(accept|x)π(x)dx =

RNx
πX(x)
mπP (x)πP (x)dx = 1
m,
and
π(x|accept) =
πX(x)
mπP (x)πP (x)
1/m
= πX(x),
as required.
There is a practical diﬃculty with rejection sampling: what is a good choice for
the constant m? If m is chosen too large, we will only rarely accept a proposed
sample x from the proposal density. We will learn about more eﬃcient methods
for sampling from a given PDF in Chapter 5.
Example 3.24
Rejection sampling can be given the following geometric inter-
pretation. Step (i) of Algorithm 3.22 generates pairs (x, u). We introduce the
variable y = umπP (x) and plot the associated (x, y) pairs in the plane. These
pairs ﬁll the area underneath f(x) := mπP (x) uniformly. In step (ii), we only
retain those samples x for which the associated y is also underneath the graph
of g(x) := πX(x). Hence the ratio of generated to accepted samples converges to
the ratio of the two deﬁnite integrals associated with f and g. Of course, since g
is obtained from a PDF πX, we know that g integrates to one. However, we may
apply rejection sampling to any pair of functions f(x) > g(x) ≥0. If the area
enclosed by f is known, then rejection sampling can be used to approximate the
area deﬁned by g. We consider the following speciﬁc example. Deﬁne f by
f(x) =
 1
if x ∈[−1, 1],
0
otherwise,
and g by
g(x) =
 √
1 −x2
if x ∈[−1, 1],
0
otherwise.
Then,
 1
−1
f(x)dx = 2
and
 1
−1
g(x)dx = π
2 ,
and rejection sampling can be used to approximate π. Numerical results are
displayed in Figure 3.5.
We now return to the interpretation of Monte Carlo methods or quadrature
rules as introducing empirical measures of type (3.8) with associated expectation
values (3.9). Furthermore, we are interested in the cases for which the weights

88
Computational statistics
10
8
10
6
10
4
10
2
10
0
10
5
10
4
10
3
10
2
10
1
10
0
1/M
approximation error
rejection sampling for approximating π
1
0.5
0
0.5
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x axis
y axis
rejection sampling for approximating π
Figure 3.5 Approximation of π using rejection sampling. The bottom ﬁgure shows the
accepted samples from a uniform distribution in [−1, 1] × [0, 1]. The top ﬁgure shows the
approximation error as a function of sample size M.
wi are non-uniform, i.e., wi ̸= 1/M. As we have already discussed, such cases
arise for importance sampling or Gauss–Legendre quadrature rules. In the case of
importance sampling in particular, it is often the case that very small weights can
be obtained for some of the samples. For random variables that are expensive
to simulate (such as those that are coupled to mechanistic models, which are
encountered in data assimilation), these samples are not contributing much to the

3.3 Sampling algorithms
89
expectation value. This is ineﬃcient. Hence, it is useful to replace the empirical
measure μM with another measure ˜μM with equal weights (but possibly duplicate
samples). This is referred to as resampling. The aim is that μM and ˜μM should
both approximate the same distribution; this approximation is quantiﬁed in the
weak sense by comparing expectation values for suitable test functions f. See
Appendix 3.5 at the end of this chapter for more details.
A simple resampling method is called independent resampling with replace-
ment, deﬁned as follows.
Definition 3.25 (Resampling)
Let μM be an empirical measure of the form
(3.8). Resampling replaces μM by another empirical measure ˜μM of the form
˜μM(dx) = 1
L
M

i=1
ξiδ(x −xi)dx,
(3.21)
with corresponding expectation estimators
fξ = 1
L
M

i=1
ξif(xi),
(3.22)
where L > 0 is a positive integer, and the weights {ξi} are realisations of uni-
variate discrete random variables Ξi : Ω →S with integer-valued realisations in
S = {0, 1, . . ., L} subject to
M

i=1
ξi = L.
In this setting, fξ is a random estimator that depends on the outcome of {ξi}.
Lemma 3.26 (Unbiased resampling)
Take the sequence Ξ = {Ξi} of discrete
random variables such that
E[Ξi] = Lwi.
Then,
E[f Ξ] =
M

i=1
wif(xi).
This means that, upon averaging over all possible realisations of {ξi}, the
resampled empirical measure produces the same statistics as μM. Any errors are
due to the variance in the estimator.
Proof
For any suitable test function f we obtain
E[f Ξ] = 1
L
M

i=1
(E[Ξi]) f(xi) =
M

i=1
wif(xi)
as required.

90
Computational statistics
The interpretation of unbiased resampling is that we have replaced an em-
pirical measure (3.8) with non-uniform weights wi by a new empirical measure
(3.22) with uniform weights ˜wj = 1/L and each sample xi being replaced by ξi
identical oﬀspring. The total number of oﬀspring is equal to L. In other words,
the oﬀspring {ξi}M
i=1 follow a multinomial distribution deﬁned by
P(ξi = ni, i = 1, . . . , M) =
M!
M
i=1 ni!
M
1
i=1
(wi)ni,
(3.23)
with ni ≥0 such that M
i=1 ni = L.
We introduce the notation Mult(L; w1, . . . , wM) to denote the multinomial
distribution of L independent trials, where the outcome of each trial is distributed
among M possible outcomes according to probabilities {wi}M
i=1. The following
algorithm draws random samples from Mult(L; w1, . . . , wM).
Algorithm 3.27 (Multinomial samples)
The integer-valued variable ξi, i =
1, . . . , M, is set equal to zero initially.
For l = 1, . . . , L do the following.
(i) Draw a number u ∈[0, 1] from the uniform distribution U[0, 1].
(ii) Determine the integer i∗∈{1, . . . , M} which satisﬁes
i∗= arg min
i≥1
i

j=1
wj ≥u.
(iii) Increment ξi∗by one.
The ﬁnal integers {ξi} are distributed according to Mult(L; w1, . . . , wM).
Independent resampling with replacement will become important when we
discuss sequential Monte Carlo methods in Chapter 6 (typically, L = M). In-
dependent resampling leads to quite high variance errors, and is often replaced
by residual or systematic resampling. We next summarise residual resampling,
while we refer the reader to Arulampalam, Maskell, Gordon & Clapp (2002) for
an algorithmic description of systematic resampling.
Definition 3.28 (Residual resampling)
Given an empirical measure (3.8) resid-
ual resampling generates a total of M oﬀspring with
ξi = ⌊Mwi⌋+ ξi,
oﬀspring for each sample xi, i = 1, . . . , M. Here ⌊x⌋denotes the integer part of
x and the values {ξi} follow the multinomial distribution (3.23) with
L = M −
M

i=1
⌊Mwi⌋

3.3 Sampling algorithms
91
4
3
2
1
0
1
2
3
4
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
relative frequencies from 2000 multinomial draws
sample positions
Figure 3.6 Relative frequency of
two thousand repeated draws from a
multinomial distribution with
probability vector
w = (1/8, 3/8, 1/8, 3/8).
and new weights
wi =
Mwi −⌊Mwi⌋
M
j=1(Mwj −⌊Mwj⌋)
.
Example 3.29
Consider four samples x1 = −3, x2 = −1, x3 = 1, and x4 = 3
with associated weights w1 = 1/16, w2 = 3/16, w3 = 5/16, and w4 = 7/16,
respectively. Residual resampling leads to ⌊Mwi⌋equal to zero for i = 1, 2 and
⌊Mwi⌋= 1 for i = 3, 4. The new weights wi are then given by w1,3 = 1/8,
w2,4 = 3/8, and L = 2. Drawing a total of two thousand samples from the
associated multinomial distribution, we ﬁnd that the relative frequency of the
outcomes indeed reproduces the probabilities given by the probability vector
w = (1/8, 3/8, 1/8, 3/8). See Figure 3.6.
We ﬁnally mention that linear transportation, as discussed in Chapter 2 in
the context of coupling discrete random variables, can also be used for replacing
an empirical measure with non-uniform weights by an empirical measure with
equal weights. We will discuss this approach in more detail in Chapter 5.
Problems
3.1
The formal estimate in (3.4) can be made precise for the implicit midpoint
rule applied to an integral (3.2). The order of the implicit midpoint method is
p = 2 and
|f 1,NI −f| ≤maxξ∈[0,1] |f ′′(ξ)|
24
Δx2
with Δx = 1/NI and NI the number of subintervals.

92
Computational statistics
(i)
Generalise this estimate to integrals of the form
f =
 a
−a
f(x)dx,
a > 0,
and corresponding approximations by the implicit midpoint rule over
NI subintervals of length Δx = 2a/NI.
(ii)
Apply this result to
f =
 3
−3
e−x2dx
(3.24)
and derive a lower bound N ∗
I that guarantees that |f −f1,NI| ≤0.01
for all NI ≥N ∗
I .
(iii)
Implement the implicit midpoint rule for (3.24) and compute the
actual approximation error arising for NI = N ∗
I .
3.2
Repeat the experiments from Example 3.4 with the random variable X ∼
U[0, 1/2] replaced by X ∼U[0, 1]. Compare your results to those obtained in
Example 3.4.
3.3
Determine the ANOVA decomposition for
f(x1, x2) = 12x1 + 6x2 −6x1x2
and compute the associated variances σ2
1, σ2
2, and σ2
12. Which terms in the
ANOVA decomposition contribute most signiﬁcantly to the total variance σ2?
3.4
Consider a sequence {Xi}i≥1 of independent and identically distributed
univariate Gaussian random variables with mean zero and variance σ2 = 1.
Apply the central limit theorem to the induced sequence of random variables
YM = M −1/2
M

i=1
X2
i ,
in order to determine the PDF πYM for YM as M →∞.
3.5
Repeat the numerical experiment from Example 3.14 with n = 1, 10, and
50 in the deﬁnition (3.7) for the integrand f. Compare the resulting errors from
the associated Monte Carlo approximations. Explain your ﬁndings in terms of
the variance of Y = φn(X) with X ∼U[0, 1/2].
3.6
Consider a univariate random variable X with smooth cumulative distribu-
tion function FX(x). A coupling between X and a random variable U ∼U[0, 1]
is provided by X = F −1
X (U). Such couplings form the basis of the transform
method. Compute the associated Wasserstein distance
W(πX, πU) :=
3
E[(F −1
X (U) −U)2]
in the case where X is Gaussian with mean zero and variance one.
3.7
Use rejection sampling in the setting of Example 3.24 to approximate π.
Denote the number of generated (x, u) pairs by M. Display the approximation
error as a function of 1/M and compare your ﬁndings with those displayed in
Figure 3.5.

3.4 Guide to literature
93
3.8
Implement Algorithm 3.27. The input parameters are the integers M, L,
and a set of weights wi ≥0, i = 1, . . . , M, with M
i=1 wi = 1. The output of
the algorithm are M integers ξi ≥0 which satisfy M
i=1 ξi = L. Verify your
algorithm by checking that ξi/L ≈wi for L ≫M.
3.4
Guide to literature
Basic concepts of numerical quadrature rules are covered in most textbooks on
numerical analysis such as S¨uli & Mayers (2006). Sparse grid quadrature rules
for high-dimensional integrals and their relation to ANOVA-type approximations
are discussed in Holtz (2011); see also the survey paper by Bungartz & Griebel
(2004). An introduction to Monte Carlo methods can be found, for example, in
Liu (2001) and Robert & Casella (2004). Theoretical aspects of Monte Carlo
and Quasi-Monte Carlo methods are covered by Caﬂisch (1998). Quasi-Monte
Carlo methods increase the convergence rate of Monte Carlo methods by using
low discrepancy (or quasi-random) samples xi.
3.5
Appendix: Random probability measures
In this appendix, we give a brief introduction to random probability measures.
We restrict the discussion to discrete measures and consider monomial resam-
pling as a concrete example. Assume we are given M ﬁxed points xi ∈RNx. Any
set of weights wi ≥0, i = 1, . . . , M, subject to M
i=1 wi = 1 leads to an empirical
measure
μM(dx) =
M

i=1
wiδ(xi −x)dx.
(3.25)
We may now “randomise” this measure by considering the weights {wi} as the
outcome of random variables Wi : Ω →[0, 1], which satisfy M
i=1 Wi = 1,
i.e., wi = Wi(ω). We introduce the notation μΩ
M to emphasise that (3.25) is
now viewed as the outcome of a random experiment. Next we introduce the
distance of two such random measures μΩ
M and νΩ
M as follows:
d(μΩ
M, νΩ
M) = sup
|f|≤1

	
	
	

E
⎡
⎣
. M

i=1
(Wi −Vi)f(xi)
/2⎤
⎦.
(3.26)
Here the expectation is taken over all realisations of the two sets of random
variables {Wi} and {Vi} associated with μΩ
M and νΩ
M, respectively. We recall
that
M

i=1
(wi −vi)f(xi) =
M

i=1
wif(xi) −
M

i=1
vif(xi) =: EμΩ
M [f] −EνΩ
M [f],

94
Computational statistics
where wi = E[Wi] and vi = E[Vi].
In the case of monomial resampling, the measure μΩ
M has ﬁxed importance
weights {wi}, i.e., wi = Wi(ω) for almost all ω ∈Ω, and an expectation value
EμΩ
M [f], abbreviated by f M. The weights vi of the “random” resampling measure
νω
M are given by vi(ω) = ξi(ω)/L, where ξi(ω) counts how many times xi has
been drawn under the resampling step and M
i=1 ξi(ω) = L. Furthermore, it
holds that vi = wi, or, equivalently,
E[Ξi] = wiL.
An alternative representation of realisations νω
M of the random measure νΩ
M is
νω
M(dx) = 1
L
L

l=1
δ(x −Xl(ω))dx,
with L independent and identically distributed discrete random variables
Xl : Ω →{x1, . . . , xM},
such that P[Xl = xi] = wi.
We now bound the distance d(μΩ
M, νΩ
M) as a function of the resampling size L.
First note that
EνΩ
M [f] −EμΩ
M [f] = 1
L
L

l=1
(E[f(Xl)] −f M) = 0,
and that
E
#
(f(Xl) −f M)(f(Xk) −f M)
$
= 0
for k ̸= l. These equalities hold since the the random variables {Xl} are inde-
pendent and identically distributed and satisfy E[f(Xl)] = fM. Hence
d(μΩ
M, νΩ
M) = sup
|f|≤1

	
	
	

E
⎡
⎣
.
1
L
L

l=1
f(Xl) −f M
/2⎤
⎦
=
1
L1/2 sup
|f|≤1

	
	

E
4
1
L
L

l=1
(f(Xl) −fM)2
5
≤
4
L1/2 ,
since |f(xl) −f M| ≤2 under the assumption that |f(x)| ≤1 for all x ∈RNx.
The discussion of this appendix can be extended to continuous random mea-
sures and can be used to prove the convergence of empirical measures generated
from Monte Carlo importance sampling-resampling steps to the posterior PDF
of Bayesian inference as the sample size L = M →∞. See Chapter 5.

3.6 Appendix: Polynomial chaos expansion
95
3.6
Appendix: Polynomial chaos expansion
As an alternative to the numerical methods discussed in this chapter, here we
consider approximating a random variable X : Ω →RNx by another random
variable ˜X : Ω →RNx. Let us assume, for simplicity, that Nx = 1 and that there
is a transformation X = T (Y ) with Y a Gaussian random variable with mean
zero and variance equal to one. Then ˜X can be deﬁned by a ﬁnite truncation of
the polynomial chaos expansion (PCE) of X,
X = T (Y ) =

k≥0
αkHk(Y ),
where {αk} are constant expansion coeﬃcients, and Hk(y) denotes the Hermite
polynomial of order k ≥0. Hermite polynomials satisfy the orthogonality relation
E[Hk(Y )Hl(Y )] = 0 for k ̸= l if Y is N(0, 1).
Multiplying both sides of the expression by Hk(Y ), taking expectation and
using the orthogonality relation, we obtain
αk = E[T (Y )Hk(Y )]
E[Hk(Y )Hk(Y )].
The ﬁrst four Hermite polynomials are given by H0(y) = 1, H1(y) = y, H2(y) =
y2 −1, and H3(y) = y3 −3y.4 Polynomial chaos expansions, also called spec-
tral expansions, have become popular in the context of stochastic ﬁnite element
methods for partial diﬀerential equations. See Smith (2014) for more details.
4 The roots of these polynomials are also used to deﬁne the quadrature points ci of
Gauss–Hermite quadrature rules. See Example 3.3. For example, the Gauss–Hermite
quadrature rule of order four satisﬁes H2(ci) = 0, i = 1, 2.

4
Stochastic processes
In the previous two chapters, we discussed how probability measures can be
used to express our uncertainty in estimating quantities. We also introduced
some useful tools for calculating with probability measures. A key aspect of many
physical systems of interest is that they evolve in time according to physical laws,
such as (1.2). Having obtained a probability measure expressing our uncertainty
in the system state at a particular snapshot in time, we would like to know how
our uncertainty evolves in time. This motivates a probabilistic view of dynamical
systems. It is also often the case that the models that we use are themselves
random, often because they approximately represent some complex dynamical
process by a simple random process. We can use the language of stochastic
processes to describe such models and incorporate them into the probabilistic
dynamical systems framework. In this book we do not discuss speciﬁc models,
instead we are interested in qualitative properties that can be described in this
framework.
In this chapter we will develop this framework in the context of forecasting.
Dynamical systems and stochastic processes are among the most fundamental
mathematical modelling tools; they ﬁnd widespread use in science and engi-
neering. This is a vast topic, and this chapter can only highlight those aspects
which are of particular relevance to forecasting and data assimilation. We will
primarily restrict the discussion to discrete-time systems and processes in order
to keep mathematical details relatively elementary. For a more in-depth study
we recommend the textbooks listed at the end of this chapter.
4.1
Dynamical systems and discrete-time Markov processes
We start with the concept of a dynamical system.
Definition 4.1 (Dynamical system)
Given a phase space B ⊂RNz embedded
into an Nz-dimensional Euclidian space, an autonomous dynamical system is a
map ψ : B →B. Given an initial condition z0 ∈B, a dynamical system deﬁnes
a solution sequence or trajectory {zn}n≥0 via the iteration
zn+1 = ψ(zn).
(4.1)

4.1 Dynamical systems and discrete-time Markov processes
97
If the map ψ also depends on the iteration index n, then we call it a non-
autonomous dynamical system.
Using this terminology, we ﬁnd that (1.18) induces an autonomous dynamical
system
ψ(z) = z + δtf(z),
(4.2)
while (1.2) deﬁnes a non-autonomous dynamical system
ψn(z) = z + δt (f(z) + g(tn)) ,
tn = nδt,
for given g(tn).
From a forecasting perspective, if we do not know the precise value of the
system state z, but instead only know that it lies in some subset A of phase space,
we would like to know the minimum subset deﬁnitely containing the system state
at later times. More generally, this is the setting for many questions of interest
about the properties of dynamical systems. The theory of dynamical systems is
less concerned about the behaviour of individual trajectories and instead focuses
on the collective or typical behaviour of many trajectories. For example, we
might ask whether trajectories remain bounded or whether they enter a compact
subset of phase space after ﬁnitely many iterations. This perspective leads us to
the consideration of sequences of sets
An+1 = ψ(An),
A0 = A,
where zn+1 ∈An+1 if and only if there exists a zn ∈An such that zn+1 = ψ(zn).
A subset A of phase space is now called forward invariant if
ψ(A) ⊆A.
In other words, if zn∗∈A for some n∗, then zn ∈A for all n ≥n∗.
Let us explore this aspect further by means of Example 1.7.
Example 4.2
We recall the Lorenz-63 system (Lorenz 1963) and its discreti-
sation in time by the forward Euler method, which gives rise to an autonomous
dynamical system of type (4.2) with B = R3, z = (x, y, z)T, and the vector ﬁeld
f given by
f(z) =
⎛
⎝
σ(y −x)
x(ρ −z) −y
xy −βz
⎞
⎠,
(4.3)
with parameters σ = 10, ρ = 28, and β = 8/3.
A ﬁrst observation is that f(0) = 0 and hence zn = 0 for all n > 0 provided
z0 = 0. Therefore, A = {0} is forward invariant. However this is not an “interest-
ing” forward invariant set since any initial condition z0 ̸= 0 with ∥z0∥arbitrarily
small will be repelled from the origin and will ultimately approach a much more
interesting forward invariant set, which is called the Lorenz attractor. The set
A deﬁning the Lorenz attractor has a complicated geometric structure which is

98
Stochastic processes
−20
0
20
−40
−20
0
20
40
−10
0
10
20
30
40
50
initial conditions
−20
0
20
−40
−20
0
20
40
−10
0
10
20
30
40
50
solutions at t  10
−20
0
20
−40
−20
0
20
40
−10
0
10
20
30
40
50
solutions at t  100
Figure 4.1 Snapshots of M = 1000 solutions starting near the origin at time zero (left
panel) at time t = 10 (middle panel) and at t = 100. The solutions start approaching a
set closely resembling the set displayed in Figure 1.8.
beyond this introductory textbook, but it can be easily explored numerically.
In fact, the qualitative structure of the Lorenz attractor is well represented by
Figure 1.8.
A numerical demonstration of “attraction” is provided in Figure 4.1 where one
thousand solutions with initial conditions close to zero are displayed at t = 10
and t = 100. The solutions approach the Lorenz attractor as time progresses.
Before giving a formal deﬁnition of an attractor, we ﬁrst deﬁne the distance
from a point to a set.
Definition 4.3 (Distance from a point to a set)
For z ∈B, the distance from z
to a subset A ⊂B is
d(z, A) := inf
z′∈A ∥z −z′∥.
Definition 4.4 (Attractor)
A compact set A ⊂B is called an attractor of a
dynamical system ψ if
(i) A is forward invariant;
(ii) A attracts a neighbourhood of itself, i.e., there exists δ > 0 such that if
d(z0, A) < δ, then d(zn, A) →0, as n →∞; and
(iii) A is minimal, i.e., there is no A′ ⊂A such that both A and A′ are forward
invariant and attracting.
Example 4.5
The identiﬁcation of an attractor is often highly non-trivial. Let
us consider, for example, the dynamical system deﬁned by B = [0, 1] ⊂R and

4.1 Dynamical systems and discrete-time Markov processes
99
the tent map
ψ(z) :=
 2z
if z ∈[0, 1/2],
2 −2z
otherwise.
If we deﬁne A0 = [0, 1/2], for example, then we ﬁnd that A1 = B = [0, 1] after
a single iteration. Clearly B is forward invariant. The choice A0 = {0, 1} leads,
on the other hand, after a single iteration to A1 = {0} which itself is forward
invariant. We ﬁnd that A = {0} is attracting for certain initial conditions, since
any z0 = 1/2k, k = 0, 1, 2, . . ., will result in trajectories reaching {0} after ﬁnitely
many steps (in fact k+1 iterations). At the same time, there is no neighbourhood
U of {0} in [0, 1] such that all z0 ∈U approach {0} and, hence, {0} is not an
attractor as deﬁned above. Furthermore, there are also periodic trajectories of
period n∗> 1 by which we mean that
zn = zn+n∗
for all n ≥0. For example, z0 = 2/5 leads to z1 = 4/5 and then back to
z3 = 2/5 = z0. Hence n∗= 2 in this case and A = {2/5, 4/5} is forward
invariant. Again these sets do not deﬁne attractors in the above sense. In fact,
the tent map has only the whole set B as its attractor.
From the perspective of forecasting, rather than simply specifying a set that we
think contains z, it is more useful to quantify our uncertainty1 about where z is
by assigning probabilities to subsets A ⊂B. We can then compare subsets based
on where z is most likely to be found. We will denote Pn(A) the probability of z
being in set A at time n. Once we have assigned probabilities P0(A) to subsets
at n = 0, their evolution is entirely determined by the dynamical system since
Pn+1(A) = Pn(A′),
n ≥0,
with A′ = ψ−1(A) for all appropriate sets A ⊂B. We have already encountered
this transformation rule (or conservation law) for probabilities in Lemma 2.13 of
Chapter 2.
Using the language of probability theory, as summarised in Chapter 2, we
deﬁne a PDF πZ0 and a random variable Z0 : Ω →B on phase space B ⊂RNz
such that
P0(A) =

A
πZ0(z0)dz0.
After a single application of the dynamical system, we then obtain a random
variable Z1 = ψ(Z0), with marginal PDF πZ1 deﬁned by
P1(A) =

A
πZ1(z1)dz1 =

ψ
1(A)
πZ0(z0)dz0,
1 Here we consider uncertainty to be a subjective quantity that will depend on prior
knowledge and assumptions about z.

100
Stochastic processes
for all subsets A ⊆B.
Example 4.6
We consider the scalar, linear iteration
zn+1 = dzn + b,
with phase space B = R and ﬁxed parameters d and b. Assume that z0 is obtained
from a Gaussian random variable Z0 with mean z0 and variance σ2
0. The PDF
for Z0 is
πZ0(z) = n(z; z0, σ2
0) =
1

2πσ2
0
e
−1
2

z
z0
σ0
2
.
The random variable Z1 is now deﬁned by
Z1 = dZ0 + b,
which is again Gaussian with mean
z1 = E[dZ0 + b] = dz0 + b,
and variance
σ2
1 = E[(dZ0 + b −z1)2] = d2E[(Z0 −z0)2] = d2σ2
0.
By induction, Zn is Gaussian for n ≥0, and the mean and variance are obtained
from the recursions
zn+1 = dzn + b,
σ2
n+1 = d2σ2
n.
We denote the marginal distribution of Zn by πZn(z) = n(z; zn, σ2
n). Note that
Zn and Zn+1 are fully correlated since
E[(Zn −zn)(Zn+1 −zn+1)] = E[d(Zn −zn)(Zn −zn)] = dσ2
n,
and the correlation becomes
corr(Zn, Zn+1) =
E[(Zn −zn)(Zn+1 −zn+1)]
E[(Zn −zn)2]1/2 E[(Zn+1 −zn+1)2]1/2 =
 1
if d > 0,
−1
if d < 0.
This is, of course, not surprising since Zn and Zn+1 are connected by a deter-
ministic linear map.
If the parameter d is chosen such that |d| < 1, then σn →0 as n →∞and
zn tends to z∞= b/(1 −d) as n →∞. Hence πn converges to the Dirac delta
function δ(z −z∞) as n →∞. On the other hand, if |d| > 1, the variances
increase without bound and the mean tends to ±∞unless z0 = b = 0. The
particular case d = 1 and b = 0 leads to zn+1 = zn and σn+1 = σn. In this case,
the distribution πn is stationary, i.e., πn = π0 for all n ≥1.
These considerations can be generalised to multivariate iterations
zn+1 = Dzn + b,
(4.4)

4.1 Dynamical systems and discrete-time Markov processes
101
zn ∈RNz, in which case the mean of the associated random variables Zn is
recursively given by
zn+1 = Dzn + b,
and the covariance matrices P n follow the recursion
P n+1 = E[(Zn+1 −zn+1)(Zn+1 −zn+1)T]
= DE[(Zn −zn)(Zn −zn)T]DT
= DP nDT .
Furthermore, since (i) the degree of a polynomial q(z) remains invariant under
linear transformations of type (4.4) and (ii) any quadratic polynomial can be
written as
q(z) = 1
2(z −m)TP −1(z −m) + c,
with m, c ∈RNz, P ∈RNz×Nz appropriately chosen, we may conclude that Gaus-
sian PDFs remain Gaussian under any linear transformation and the marginal
distribution of Zn is given by the PDF
πZn(z) = n(z; zn, P n) =
1
(2π)Nz/2|P n|1/2 exp

−1
2(z −zn)T(P n)−1(z −zn)

.
The probabilistic interpretation of dynamical systems is essential for quanti-
fying forecast uncertainties arising from uncertainties in the initial conditions.
At the same time we have seen in Chapter 1 that such uncertainties can be
reduced by estimating initial conditions from available observations. Therefore
we brieﬂy discuss the relation between observations and initial conditions within
an idealised dynamical systems perspective. We assume that we are given a dy-
namical system (4.1) with a unique attractor A. We also assume that we have
a scalar-valued forward or observation operator h : RNz →R and a sequence
of observations yk ∈R for k = 1, . . . , NA. These observations are related to an
initial state z0 of the dynamical system through
yk = h(ψk(z0)).
(4.5)
In other words these observations do not contain measurement errors and they
are generated by our model. The goal is to reconstruct z0 from the NA obser-
vations. This is possible through the following fundamental result in dynamical
systems theory.
Theorem 4.7 (Takens’ theorem)
Let ψ be a smooth and invertible dynamical
system with a unique attractor A, let h be a smooth forward operator, and let
{yk}NA
k=1 be a sequence of noise-free observations given by (4.5) with z0 ∈A.
Then it is a generic property that z0 ∈A can be determined uniquely from the
discrete set of observations {yk}NA
k=1, provided that NA ≥2Nz + 1.

102
Stochastic processes
Proof
See Takens (1981) and Collet & Eckmann (2006).
If we replace the sequence {yk}NA
k=1 by noisy observations {yk
obs}NA
k=1, such as
those constructed in Chapter 1, the overdetermined system of equations
yk
obs = h(ψk(z0)),
k = 1, . . . , NA ≥2Nz + 1,
does not have a solution z0 ∈RNz, in general. This situation can be compared
to that of an overdetermined linear system of equations
Az = b
(4.6)
with b ∈RNA, z ∈RNz and Nz < NA. If (i) A has rank Nz, and (ii) b lies in
the image of A, then there is a unique solution z to this system of equations.
However, if we perturb b to become ˆb such that ˆb is no longer in the image of
A, then there is no solution. It becomes necessary to replace (4.6) by the least
squares formulation
z∗= arg min
z∈RNz ∥Az −ˆb∥2,
which we have already encountered in Chapter 1. This discussion suggests that
we should replace (4.5) by the minimisation of
L(z0) = 1
2
NA

k=1

yk
obs −h(ψk(z0))
2 ,
(4.7)
over initial conditions z0, which is the same nonlinear least squares data assimila-
tion formulation (1.20) from Chapter 1. Provided that (i) the diﬀerences between
yk and yk
obs are suﬃciently small and that (ii) we have enough observations, i.e.,
NA ≥2Nz + 1, we can generically expect that the minimisation problem (4.7)
has a unique global minimiser.
We mention in passing that the bound NA ≥2Nz + 1 on the necessary num-
ber of observations can be improved to NA ≥2NA + 1, where NA denotes the
box-counting dimension of the attractor A. We refer the reader to the dynami-
cal systems literature for a mathematical deﬁnition of attractor dimension, but
remark that the Lorenz-63 system possesses an attractor of box-counting dimen-
sion NA ≈2.06. Recall that we used NA = 5 for the numerical experiments in
Example 1.8, which is close to the theoretical bound of NA ≥5.12.
Our discussion has given a heuristic justiﬁcation to the method of least squares
as a tool for estimating model states from suﬃciently long and accurate sequences
of observations. In practice, state estimation problems typically have Nz ≫NA
or NA ≫NA, respectively. Then the method of least squares is bound to fail; the
inverse problem of estimating the state z0 ∈RNz from observations {yk
obs}NA
k=1
becomes ill posed. This means that either estimates are not uniquely deﬁned or
they do not depend continuously on the observations. We will learn more about
ill-posed inverse problems in Chapter 5, and about associated data assimilation
techniques in the second part of this book.
Let us return to the discussion of dynamical systems without reference to

4.1 Dynamical systems and discrete-time Markov processes
103
10
0
10
20
30
10
0
10
20
30
10
5
0
5
10
x component
random motion generated by modified tent map
y component
z−component
Figure 4.2 Trajectory from a simulation with non-autonomous forcing in R3. Although
the forcing is generated by a deterministic tent map, the trajectory resembles a “random
walk”.
observational data. So far we have exclusively discussed autonomous dynamical
systems. We now turn our attention to non-autonomous systems. Recall that we
introduced a non-autonomous forcing term in Example 1.1. We will investigate
its impact in the following example with the drift term f(z) set equal to zero for
simplicity.
Example 4.8
We consider the iteration
xn+1 = xn + δtgn
1 ,
(4.8)
yn+1 = yn + δtgn
2 ,
(4.9)
zn+1 = zn + δtgn
3 ,
(4.10)
in R3 with step-size δt = 0.001, initial condition
x0 = y0 = z0 = 0,
and with the non-autonomous forcing g(tn) = gn = (gn
1 , gn
2 , gn
3 )T ∈R3 generated
as follows. Set a = 1/
√
δt and, for n ≥0, deﬁne recursively
gn+1
i
=
 1.99999gn
i + a/2
if gn
i ∈[−a/2, 0),
−1.99999gn
i + a/2
otherwise,
(4.11)
with initial values g0
1 = a(2−1/2 −1/2), g0
2 = a(3−1/2 −1/2), and g0
3 = a(5−1/2 −
1/2). Recall that gn
i ∈[−a/2, a/2].
The resulting trajectory is stored over a time interval t0 = 0 to tend = 200 in
intervals of Δtout = 0.05. For later reference these trajectory values are denoted

104
Stochastic processes
0 2
0 1
0
0 1
0 2
0 3
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
x position
relative frequency of binned increments
Figure 4.3 Relative frequency of
binned solution increments
Δxk := x(tk) −x(tk−1) produced by
the modiﬁed tent map iteration (4.8)
with increments taken over time
intervals Δtout = 0.05.
by x(tk), y(tk), and z(tk), respectively, with tk = kΔtout for k ≥0. See Figure
4.2 for the numerical results.
The trajectory clearly displays “random walk” behaviour in R3. In order to
analyse this phenomenon in more detail we deﬁne solution increments
Δxk = x(tk) −x(tk−1),
for k ≥1 with corresponding expressions for Δyk and Δzk. Relative frequencies
of the Δxk values are displayed in Figure 4.3. We approximate this distribution
by a Gaussian with mean zero and variance σ2
x ≈0.0838Δtout.
We also compute the (normalised) autocorrelation coeﬃcients (see Deﬁnition
4.19 later in this chapter)
C(τ) =

k≥1 ΔxkΔxk+τ

k≥1 ΔxkΔxk ,
for τ = 0, 1, . . ., 10. By deﬁnition, C(0) = 1 and all other coeﬃcients are found to
be smaller than 10−2 in absolute value. In other words, increments can be treated
as mutually uncorrelated. These ﬁndings suggest that we could approximate the
iteration
xn+1 = xn + δtgn
1 ,
(4.12)
and the resulting output sequence {x(tk)}k≥0 with a stochastic diﬀerence equa-
tion
x(tk+1) = x(tk) + ξk,
(4.13)
where the increments {ξk} are realisations of independent and Gaussian dis-
tributed random variables {Ξk} with mean zero and variance σ2
x ≈0.0838Δtout.
The same stochastic diﬀerence equations can be derived for the other two com-
ponents of the state vector. We display a simulation result using these stochastic
diﬀerence equations in Figure 4.4. The stochastic model (4.13) provides us with

4.1 Dynamical systems and discrete-time Markov processes
105
10
0
10
20
30
20
10
0
10
20
25
20
15
10
5
0
5
x component
random motion generated by stochastic model
y component
z−component
Figure 4.4 Trajectory from the stochastic diﬀerence equation (4.13) in x(kΔtout) and
from related equations in y(kΔtout) and z(kΔtout). This trajectory should be compared
qualitatively to the one displayed in Figure 4.2. Note, however, that we only see a
particular realisation of our stochastic model. Hence the trajectories in both ﬁgures should
not be compared on a point-wise level.
a simpliﬁed, imperfect model for the reference system (4.12). We will come back
to this point later in this chapter.
We would like to incorporate random processes such as the stochastic recursion
(4.13) into our probabilistic view of dynamical systems. We start the discussion
with the following example.
Example 4.9
We consider a sequence of univariate random variables {Zn}n≥0
deﬁned by the recursion
Zn+1 = Zn + Ξn,
n = 0, 1, 2, . . .
.
(4.14)
Here Ξn ∼N(0, 1) are assumed to be independent with respect to each other
and to {Zk}n
k=0 (but not Zk for k > n, of course). We will discuss this recursion
probabilistically, which means that we want to understand how the probability
measures for the sequence of random variables {Zn} are related. The recursion
requires an initial condition, i.e. a speciﬁcation of the probability distribution
of Z0. For simplicity we choose the Dirac measure centred at z = 0, i.e., the
random variable Z0 takes the value Z0(ω) = 0 with probability one. Hence we
may simply conclude that Z1 is distributed according to N(0, 1) since we know
that Ξ0 ∼N(0, 1) and Z0 = 0 almost surely.
Computing the distribution of Z2 is more involved. First we assume the value

106
Stochastic processes
of Z1 is known to be z1. Then the conditional distribution of Z2, given that
Z1 = z1, is
Z2|z1 = z1 + Ξ1 ∼N(z1, 1).
Consequently, the joint probability density for (Z1, Z2) is given by
πZ1Z2(z1, z2) = 1
2πe−1
2 (z2−z1)2e−1
2 (z1)2.
The marginal distribution for Z2, i.e. the distribution for Z2 only, is obtained
by integrating over z = z1,
πZ2(z′) = 1
2π

R
e−1
2 (z′−z)2e−1
2 z2dz
= 1
2π

R
e−1
4 (z′)2e−(z−z′/2)2dz
=
1
2√π e−1
4 (z′)2.
Hence Z2 ∼N(0, 2) and we ﬁnd that
πZn+1(z′) =

R
1
√
2πe−1
2 (z′−z)2πZn(z)dz,
n ≥0,
by induction. We see that the conditional PDF
πZn+1(z′|z) =
1
√
2π e−1
2 (z′−z)2
plays the role of a transition probability density. Since this PDF does not depend
on time, we will drop the subscript and use the simpler notation π(z′|z).
These Gaussian recursions are examples of (discrete-time) stochastic processes,
which we now discuss in more generality.
Definition 4.10 (Stochastic process)
Let T be a set of indices. A stochastic
process is a family {Zt}t∈T of random variables Zt : Ω →Z with joint probability
space (Ω, F, P).
The variable t typically corresponds to time; we distinguish between continu-
ous time t ∈[0, tend] ⊂R and discrete time tn = nδt, n ∈{0, 1, 2, . . .} = T , with
time increment δt > 0. In the discrete-time setting we generally prefer Zn to Ztn.
We will also use the notation Z(t) or Z(tn), respectively, whenever superscript
indices would be more confusing.
A stochastic process can be seen as a function of two arguments: t and ω. For
ﬁxed ω ∈Ω, Zt(ω) becomes a function of t ∈T , which we call a realisation or
trajectory of the stochastic process. In the case of continuous processes, we will
only consider processes for which Zt(ω) is continuous in t. Alternatively, we can
ﬁx a time t ∈T and consider the random variable Zt(·) and its distribution (as we
did when we obtained the marginal distribution for Z2 above). More generally,

4.1 Dynamical systems and discrete-time Markov processes
107
we can consider l-tuples (t1, t2, . . . , tl) and associated l-tuples of random variables
(Zt1(·), Zt2(·), . . . , Ztl(·)) with their joint distributions. This leads to concepts
such as autocorrelation, which we shall discuss later in this chapter.
In Example 4.9, we introduced the idea of a transition probability density
which allowed us to compute the distribution for Zn+1 from that for Zn. This
generalises to the concept of Markov processes for discrete-time processes.
Definition 4.11 (Discrete-time Markov processes)
The discrete-time stochas-
tic process {Zn}n∈T with Z = RNz and T = {0, 1, 2, . . .) is called a (time-
independent) Markov process if its joint PDFs can be written as
πZ0···Zn(z0, z1, . . . , zn) = π(zn|zn−1)π(zn−1|zn−2) · · · π(z1|z0)πZ0(z0)
(4.15)
for all n ∈{1, 2, . . .} = T . The associated marginal distributions
πZn(zn) =

Z
· · ·

Z
πZ0···Zn(z0, z1, . . . , zn)dz0 · · · dzn−1,
i.e., the probability density functions for Zn, n = 1, 2, . . ., satisfy the Chapman–
Kolmogorov equation
πZn+1(z′) =

Z
π(z′|z)πZn(z)dz,
(4.16)
from which the marginal distributions can be computed recursively for given
initial πZ0 in order to yield the family {πZn}n∈T . A Markov process is called
time dependent if the conditional PDF π(z′|z) depends on the time level n.
The Chapman–Kolmogorov equation (4.16) can be written in more abstract
form as a linear iteration
πZn+1 = PπZn,
(4.17)
where the operator P is called the transition operator.2
Equation (4.15) for a Markov process should be compared with the disinte-
gration formula in Equation (2.4) which is valid for arbitrary stochastic pro-
cesses. Hence the above deﬁnition is equivalent to the more traditional deﬁ-
nition which states that a process is Markov if the conditional distributions
πZn(zn|z0, z1, . . . , zn−1), n ≥1, satisfy
πZn(zn|z0, z1, . . . , zn−1) = π(zn|zn−1).
We also ﬁnd that the Chapman–Kolmogorov equation (4.16) is obtained from
the joint PDF
πZnZn+1(zn, zn+1) = π(zn+1|zn)πZn(zn),
followed by marginalisation,
πZn+1(zn+1) =

Z
πZnZn+1(z, zn+1)dz,
2 Transition operators will be discussed in more detail in Chapter 5.

108
Stochastic processes
to obtain πZn+1(zn+1).
In the context of forecasting, if the mechanistic model used for predictions
is a discrete Markov process, and π0 represents our uncertainty in the system
state at time level n = 0, then repeated iteration of the Chapman–Kolmogorov
equation provides our uncertainty in the system state, based on the model, at
later times. This allows for a practical implementation since having calculated
zn+1 from zn, zn can be discarded as it is not required to compute zn+2. The
Chapman–Kolmogorov equation is a crucial tool in propagating our uncertainty
forwards in time using the mechanistic model.
Example 4.12
We consider a diﬀeomorphism ψ : B →B with B ⊂RNz and
the associated dynamical system (4.1). If we view the initial condition as the
realisation of a random variable Z0 ∼π0, then the dynamical system gives rise
to a Markov process with (formal) transition probability density
π(z′|z) = δ(z′ −ψ(z)).
More precisely, it holds that μ(dz′|z) = μψ(z)(dz′) in terms of probability mea-
sures. We have already encountered such transition probabilities in the context
of transport maps in Chapter 2 and recall that
πZn+1(z′) = πZn(ψ−1(z′))|Dψ−1(z′)|
is the transformation formula for the associated marginal PDFs if ψ is a diﬀeo-
morphism. Indeed,
πZn+1(z′) =

B
π(z′|z) πZn(z)dz
=

B
δ(z′ −ψ(z)) πZn(z)dz
=

ψ
1(B)
δ(z′ −ˆz)πZn(ψ−1(ˆz))|Dψ−1(ˆz)|dˆz
= πZn(ψ−1(z′))|Dψ−1(z′)|.
We return to our mechanistic model (1.18) and combine it with our ﬁndings
from Example 4.8 in order to ﬁnd a better mechanistic model for our surrogate
physical process, in terms of a stochastic Markov process.
Example 4.13
In our example data assimilation problem in Chapter 1, the
surrogate physical process (1.2) and the mechanistic model (1.18) diﬀer only by
the missing non-autonomous driving term g(t). In addition we have just found
in Example 4.8 that the non-autonomous driving terms (gn
1 , g2
2, gn
3 )T give rise
to a random walk like behaviour, which can be modelled by a stochastic diﬀer-
ence equation. This suggests that we could replace the mechanistic model from

4.1 Dynamical systems and discrete-time Markov processes
109
0
1
2
3
4
5
6
20
0
20
time
x−variable
solutions
reference
stochastic
0
1
2
3
4
5
6
50
0
50
time
y−variable
0
1
2
3
4
5
6
0
50
time
z−variable
0
1
2
3
4
5
6
20
0
20
time
x−variable
solutions
deterministic
stochastic
0
1
2
3
4
5
6
50
0
50
time
y−variable
0
1
2
3
4
5
6
0
50
time
z−variable
Figure 4.5 Comparison between the behaviour of our modiﬁed stochastic model and the
reference trajectory zref(t), under the assumption that both start from the same initial
condition at time t = 0. Note that the results (top panel) are similar to those displayed in
Figure 1.9 for the deterministic model. We also compare the results from the deterministic
and the stochastic models (bottom panel). The growth of uncertainty in the forecast is
relatively well captured even though it appears slightly delayed when compared to the
results in the top panel.
Example 1.7 by the following stochastic diﬀerence equations
xn+1 = xn + δtσ(yn −xn) +
√
δtξn
1 ,
(4.18)
yn+1 = yn + δt (xn(ρ −zn) −yn) +
√
δtξn
2 ,
(4.19)
zn+1 = zn + δt (xnyn −βzn) +
√
δtξn
3 ,
(4.20)

110
Stochastic processes
where {ξn
i } are now realisations of independent Gaussian random variables with
mean zero and variance 0.0838. We will discuss the mathematical properties of
such stochastic diﬀerence equations in more detail in the next section.
In a general modelling context, the precise nature of the non-autonomous
driving terms gn
i in (1.2) would be unknown to us and the additional random
terms in (4.18)–(4.20) would be called a parametrisation3 of those driving terms.
Since our stochastic parametrisation can only provide an approximation, (4.18)–
(4.20) is still an imperfect model! In fact, when we replace the deterministic
model from Example 1.7 by our new stochastic model, we ﬁnd that the quality
of the predictions does not improve. The shape of the attractor also does not
change signiﬁcantly. Compare Figures 4.5 and 4.6. These ﬁndings warrant an
explanation. Our parametrisation was based on an interpretation of the non-
autonomous forcing terms gn
i in (1.2) as realisations of a stochastic process. We
do not have direct access to these realisations and replace them therefore by
some realisations ξn
i . However, the probability that
√
δtξn
i = δtgn
i
is zero. Whilst we do not expect the stochastic parametrisation to help to repro-
duce particular trajectories, they may help to improve probabilistic forecasts.
We will readdress this issue later in this book when we discuss probabilistic
forecasting and data assimilation algorithms.
We complete this section by a discussion of the linear transition operator (4.17)
in the context of ﬁnite state space models.
Definition 4.14 (Discrete state space random processes)
A ﬁnite state space
random process {Zn}n∈T is one in which Zn can only take a ﬁnite set of values
for each n, taken from the same ﬁnite state space B ⊂RNz. We write B =
{a1, a2, . . . , aM}. The probability distribution for the random variable Zn : Ω →
B is then entirely characterised by an M-tuple of non-negative numbers pn(ai) =
P(Zn = ai), i = 1, . . . , M, which satisfy 
i pn(ai) = 1. A discrete-time Markov
process is then deﬁned through transition probabilities pij = P(Zn+1 = ai|Zn =
aj), which we collect in an M × M transition matrix P. This transition matrix
replaces the transition operator in (4.17) for stochastic processes with ﬁnite state
space. We obtain the linear recursion
pn+1(ai) =
M

j=1
pij pn(aj).
A matrix P with entries pij = (P)ij such that (i) pij ≥0 and (ii) 
i pij = 1 is
called a stochastic matrix. By deﬁnition, a transition matrix is always a stochastic
matrix.
3 This is a standard term in weather prediction, ocean and climate modelling to indicate a
model term that is an inprecise representation of physical processes that are otherwise
unrealisable within the model.

4.2 Stochastic diﬀerence and diﬀerential equations
111
20
10
0
10
20
40
20
0
20
40
0
10
20
30
40
50
x component
Lorenz attractor
y component
z−component
Figure 4.6 Long trajectory from our improved mechanistic model which traces the
model attractor. The shape of the attractor is nearly identical to the one displayed in
Figure 1.8 for the model without stochastic driving terms.
Discrete state space random processes have many useful applications; in this
book we shall discuss them as numerical discretisations of continuous state space
processes. See Appendix 5.7.
4.2
Stochastic diﬀerence and diﬀerential equations
We will now examine the continuous time limit of stochastic diﬀerence models
such as the one in Example 4.13. We start from the stochastic diﬀerence equation
Zn+1 = Zn + δtf(Zn) +
√
2δtΞn,
tn+1 = tn + δt,
(4.21)
where δt > 0 is a small parameter (the step-size), f is a given (Lipschitz con-
tinuous) function, and Ξn ∼N(0, Q) are independent and identically distributed
random variables with covariance matrix Q. Here we have written the stochastic
diﬀerence equations directly in terms of the involved random variables {Zn}n≥0.
Equation (4.21) is a discrete-time Markov process, and so the time evolution of
the associated marginal densities πZn is governed by the Chapman–Kolmogorov
equation (4.16) with conditional PDF
π(z′|z) =
1
(4πδt)Nz/2|Q|1/2
× exp

−1
4δt(z′ −z −δtf(z))TQ−1(z′ −z −δtf(z))

.
(4.22)
We wish to investigate the limit δt →0 for ﬁxed ﬁnal time T > 0. This

112
Stochastic processes
can be achieved by deﬁning δt = T/N with N →∞and iteration indices n ∈
{0, 1, . . ., N} in (4.21). Let us ﬁrst consider the special case Nz = 1, f(z) = 0,
and Q = 1 (univariate Gaussian random variable). We also drop the factor
√
2
in (4.21) and consider linear interpolation in between time-steps, i.e.,
Z(t) = Zn +
√
δt
t −tn
tn+1 −tn
Ξn,
t ∈(tn, tn+1],
(4.23)
setting Z0(ω) = 0 with probability one. For each family of realisations {ξn =
Ξn(ω)}n≥0 we obtain a piecewise linear and continuous function Z(t, ω). Further-
more, the limit δt →0 is well deﬁned and the stochastic process Z(t), t ≥0, can
be shown to converge weakly to a stochastic process called Brownian motion.4
Definition 4.15 (Brownian motion)
Standard univariate Brownian motion is
a stochastic process W(t), t ≥0, with the following properties:
(i) W(0) = 0,
(ii) realisations W(t, ω) are continuous in t,
(iii) W(t2) −W(t1) ∼N(0, t2 −t1) for t2 > t1 ≥0, and
(iv) increments W(t4) −W(t3) and W(t2) −W(t1) are mutually independent
for t4 > t3 ≥t2 > t1 ≥0.
It follows from our construction (4.23) that with probability one the Brownian
motion is not diﬀerentiable, since
Zn+1 −Zn
δt
= δt−1/2Ξn ∼N(0, δt−1)
and so the limit δt →0 is not well deﬁned. Using the concept of Brownian
motion, we can rewrite the stochastic diﬀerence equations (4.21) in the form
Zn+1 = Zn + δtf(Zn) +
√
2Q1/2(W(tn+1) −W(tn)).
(4.24)
We now take the formal limit δt →0, which leads to a stochastic diﬀerential
equation (SDE). While we will always use (4.24) and related approximations
when doing computations, the underlying theory often manifests itself much
more clearly in a SDE formulation. Below we summarise a few results particularly
relevant in the context of this book. The reader is referred to Evans (2013) for
more details. In particular, we must be careful with regard to the underlying
stochastic calculus (Itˆo or Stratonovitch); this is not an issue for the simple
SDEs considered in this chapter.
Proposition 4.16 (Stochastic diﬀerential equation and Fokker–Planck equation)
After taking the limit δt →0 in (4.24), we obtain the SDE
dZ = f(Z)dt +
√
2Q1/2dW,
(4.25)
4 A more rigorous discussion of Brownian motion can be found in Evans (2013).

4.2 Stochastic diﬀerence and diﬀerential equations
113
where W(t) denotes standard Nz-dimensional Brownian motion. The Fokker–
Planck equation,
∂πZ
∂t
= −∇z · (πZf) + ∇z · (Q∇zπZ),
(4.26)
describes the time evolution of the marginal densities πZ(z, t). If Q = 0 (no
noise), Equation (4.26) becomes
∂πZ
∂t
= LπZ,
(4.27)
in which case it is called the Liouville, transport or continuity equation, with
operator L deﬁned by
Lπ := −∇z · (πf).
(4.28)
The Fokker–Planck equation for stochastic diﬀerential equations is the limit
of the Chapman–Kolmogorov equation for stochastic diﬀerence equations. It has
the same interpretation in the context of forecasting: if our mechanistic model
is a stochastic diﬀerential equation of the form (4.25), then the Fokker–Planck
equation (4.26) allows us to propagate our uncertainty in the system state for-
ward in time.
We now proceed with an outline of a proof.
Proof
See Evans (2013) on the existence and uniqueness theory for SDEs. The
diﬀerence equation (4.21) is called the Euler–Maruyama method for approxi-
mating the SDE (4.25). See Higham (2001) and Kloeden & Platen (1992) for a
discussion on the convergence of (4.21) to (4.25) as δt →0. Here we shall provide
a heuristic derivation of the Fokker–Planck equation (4.26). We formally use
Zn+1 −Zn →dZ(tn),
δtf(Zn) →f(Z(tn))dt,
W(tn+1) −W(tn) →dW(tn).
The right hand side of (4.26) is the linear combination of a drift and a diﬀusion
term. To simplify the discussion we derive both terms separately from (4.21) by
ﬁrst considering f = 0, Q ̸= 0 and then Q = 0, f ̸= 0. In order to simplify the
derivation of the diﬀusion term even further, we also assume z ∈R and Q = 1.
In other words, we shall ﬁrst show that if the discrete process {Zn} satisﬁes the
stochastic diﬀerence equation
Zn+1 = Zn +
√
2(W(tn+1) −W(tn)),
then the Chapman–Kolmogorov equation for the sequence of marginal PDFs
{πZn} converges to the diﬀusion equation
∂πZ
∂t
= ∂2πZ
∂z2 .
In the case f(z) = 0, Q = 1, Nz = 1, the conditional PDF (4.22) reduces to
π(z′|z) = (4πδt)−1/2 exp

−(z′ −z)2
4δt

.

114
Stochastic processes
Under the variable substitution Δz = z−z′, the discrete-time Chapman–Kolmog-
orov equation (4.16) becomes
πn+1(z′) =

R
1
√
4πδt
e−Δz2/(4δt)πn(z′ + Δz)dΔz,
(4.29)
where we have introduced the abbreviation πn(z) for the marginal distributions
πZn(z). We now expand πn(z′ + Δz) in Δz about Δz = 0, i.e.,
πn(z′ + Δz) = πn(z′) + Δz ∂πn
∂z (z′) + Δz2
2
∂2πn
∂z2 (z′) + · · · ,
and substitute the expansion into (4.29):
πn+1(z′) =

R
1
√
4πδt
e−Δz2/(4δt)dΔz

πn(z′)
+

R
1
√
4πδt
e−Δz2/(4δt)ΔzdΔz
 ∂πn
∂z (z′)
+ 1
2

R
1
√
4πδt
e−Δz2/(4δt)Δz2dΔz
 ∂2πn
∂z2 (z′) + · · · .
The three integrals correspond to the zeroth, ﬁrst and second-order moments of
the Gaussian distribution with mean zero and variance 2δt. Hence their value is
known, and we obtain
πn+1(z′) = πn(z′) + δt∂2πn
∂z2 (z′) + · · · .
It can be shown that the neglected higher-order terms have magnitude O(δt2).
Therefore
πn+1(z′) −πn(z′)
δt
= ∂2πn
∂z2 (z′) + O(δt),
and the diﬀusion equation is obtained upon taking the limit δt →0.
We now show that if the discrete process {Zn} satisﬁes the diﬀerence equation
Zn+1 = ψ(Zn) := Zn + δtf(Zn),
then the Chapman–Kolmogorov equation for the sequence of marginal PDFs
{πn} convergences to Liouville’s equation (4.27). For δt suﬃciently small, ψ is
a diﬀeomorphism, and we may use the transformation rule for PDFs under a
diﬀeomorphism ψ (compare Example 4.12) in the form
πn+1(ψ(z))|Dψ(z)| = πn(z).
(4.30)
For f and πn+1 suﬃciently smooth,5 we may expand |Dψ(z)| and πn+1(ψ(z))
as power series in δt, to obtain
πn+1(ψ(z)) = πn+1(z) + δt∇zπn+1(z) · f(z) + O(δt2),
(4.31)
|Dψ(z)| = 1 + δt∇z · f(z) + O(δt2),
(4.32)
5 A more rigorous proof requires careful examination of when, and in what sense, these
formulas are valid.

4.2 Stochastic diﬀerence and diﬀerential equations
115
and (4.30) then implies
πn = πn+1 + δtπn+1∇z · f + δt(∇zπn+1) · f + O(δt2),
and
πn+1 −πn
δt
= −∇x · (πn+1f) + O(δt).
Taking the limit δt →0, we obtain (4.27).
In data assimilation, practical computations will rely on a chosen, ﬁxed step-
size δt > 0 for the dynamical model, which may be diﬀerent from observation
intervals Δtout = Noutδt. In this context it is helpful to generalise the Chapman–
Kolmogorov equation (4.16) to its Nout-fold recursive application which propa-
gates a PDF πZn to πZn+Nout according to
πZn+Nout (z) =

RNz
· · ·

RNz
π(z|z′) π(z′|z′′) · · ·
π(z(Nout−1)|z(Nout)) πZn(z(Nout)) dz′ · · · dz(Nout)
=

RNz
πNout(z|˜z) πZn(˜z) d˜z,
(4.33)
where the one-step transition probability π(z|z′) is given by (4.22) and the imp-
lied Nout-step transition probability is denoted by πNout(z|z′). Let Pδt denote the
transition operator (recall Deﬁnition 4.17) deﬁned by (4.16) and (4.22). Similarly,
let PΔtout be the transition operator associated with (4.33). Then
PΔtout = Pδt · · · Pδt



Nout times
= (Pδt)Nout.
The operator PΔtout transforms our uncertainty in the system state from one
observation time to another.
We now discuss an important subclass of Markov processes,6 known as ergodic
processes, where it is possible make quantitative statements about averages over
long time intervals. We start from the deﬁnition of the invariant measure.
Definition 4.17 (Invariant measure)
Let π∗
Z be a steady state solution to (4.17)
(or (4.26) in the case of time-continuous processes). Then μ∗
Z(dz) = π∗
Zdz is
called an invariant measure for the underlying Markov process.
If the random variable Z0 has probability distribution with an invariant mea-
sure as its marginal PDF, i.e., πZ0 = π∗
Z, then all subsequent random variables
Zn with n > 0 will have the same marginal PDF. This means that expectation
values E[f(Zn)] are independent of n, with value
E[f(Zn)] =

Z
f(z)π∗
Z(z)dz.
Such processes are called stationary.
6 Discussed here in the context of discrete-time processes.

116
Stochastic processes
More generally, let us assume that the iteration (4.17) has a unique invariant
measure π∗
Z and that any initial PDF πZ0 converges to π∗
Z in a weak sense, i.e.,
E[g(Zn)] →

Z
g(z)π∗
Z(z)dz
for all bounded and continuous functions g as n →∞. This process of con-
vergence is called equilibration, with Zn said to be “close to equilibrium” if
πZn ≈π∗
Z(z). In other words, such a stochastic process becomes essentially
stationary for n suﬃciently large, which motivates the following deﬁnition of
ergodicity.
Definition 4.18 (Ergodicity)
Let {Zn} be a discrete Markov process with
unique invariant measure μ∗
Z and associated PDF π∗
Z. The process is said to
be ergodic if time averages along speciﬁc process realisations {Zn(ω)} converge
almost surely to expectations with respect to π∗
Z, i.e.,
lim
N→∞
1
N
N

n=1
f(Zn(ω)) =

Z
f(z)π∗
Z(z)dz,
for all functions f with
8888

Z
f(z)π∗
Z(z)dz
8888 < ∞.
Stochastic processes are often assumed to be ergodic, although it is only pos-
sible to prove ergodicity in special cases. Approximately speaking, a stochastic
process is ergodic if the iterates of (4.17) converge to π∗
Z suﬃciently quickly for
any initial PDF πZ0, and if the iterates decorrelate suﬃciently rapidly. We will
discuss a speciﬁc example in the context of Brownian dynamics in Chapter 5.
For ergodic processes, we can quantify the degree of independence between Zn
and Zm for n < m, i.e. the amount of “memory” in the stochastic process, by
using autocorrelation (the reader is reminded of Deﬁnition 2.17).
Definition 4.19 (Autocorrelation)
Let {Zn} be a stochastic process in equi-
librium, i.e., the process has invariant PDF π∗
Z, and Z0 has PDF π∗
Z. Then the
autocorrelation of the stochastic process is
C(τ) = E [(Zn+τ −z) (Zn −z)]
E
!
(Zn −z)2"
,
z =

Z
zπ∗
Z(z)dz,
for τ ≥0. If the stochastic process is ergodic, then this can be calculated from
time averages along speciﬁc process realisations {Zn(ω)},
C(τ) = limN→∞1
N
N
n=1 (Zn+τ(ω) −z) (Zn(ω) −z)
limN→∞1
N
N
n=1 (Zn(ω) −z)2
.
(4.34)
Equation (4.34) can be approximated by truncating after ﬁnite N, to provide
an empirical estimate of independence of Zn and Zn+τ for τ > 0. This was used
in Example 2.20 in Chapter 2, and Example 4.8 to test for near-independence of
(deterministic) Markov processes.

4.3 Probabilistic forecasting and ensemble prediction
117
4.3
Probabilistic forecasting and ensemble prediction
In probabilistic forecasting, our goal is to calculate marginal PDFs πZ(z, t) for a
Markov process, given the initial PDF πZ(z, 0). This is useful since we can use
expectations to provide a forecast by computing the mean, together with vari-
ances and higher-order statistics that quantify the uncertainty. It may even be
the case that the distribution becomes multimodal, suggesting very diﬀerent out-
comes are possible (for example, diﬀerent possible tracks of a tropical storm). For
high-dimensional models, the PDF πZ(z, t) is very unwieldy, and so we concen-
trate on computing expectations. This motivates a Monte Carlo approximation
of the marginal PDFs πZ(z, t), t ≥0, evolving under the SDE model (4.25).
Definition 4.20 (Ensemble prediction)
A Monte Carlo approximation to the
marginal PDFs πZ(z, t) which solve the Fokker–Planck equation (4.26) can be
obtained from solving the SDEs
dzi = f(zi)dt +
√
2Q1/2dξi(t),
i = 1, . . . , M,
(4.35)
where the processes {ξi(t)}M
i=1 denote independent realisations of a standard Nz-
dimensional Brownian motion W(t) : Ω →RNz and the initial conditions zi(0)
are sampled independently from the initial PDF πZ(z, 0). Approximations of
expectations at later times t > 0 are obtained from
gM(t) = 1
M
M

i=1
g(zi(t)).
This approximation is an example of a particle or ensemble prediction method
for the marginal PDFs; an analogous deﬁnition applies to stochastic diﬀerence
equations (4.21).
We now discuss two examples.
Example 4.21
We return to the Lorenz-63 model with and without stochas-
tic perturbations. We perform an ensemble prediction with the initial ensem-
ble drawn from Gaussian distributions centred about the initial condition z0 =
(x0, y0, z0) given in Chapter 1 by (1.5) and variance 0.01 in each of the three com-
ponents of the state vector. We then compute the empirical expectation value of
the absolute value |x(t)| of the x solution component, i.e.,
|x|M(t) = 1
M
M

i=1
|xi(t)|,
at initial time t = 0 and ﬁnal time t = 5. We also estimate the variance
varM(t) = 1
M
M

i=1
(|xi(t)| −|x|M(t))2.
Under the simplifying assumption of a Gaussian distribution, the 95% conﬁdence

118
Stochastic processes
10
1
10
2
10
3
10
4
10
5
0 5
0 6
0 7
ensemble mean of |x| at initial time
estimated mean
lower confidence interval
upper confidence interval
10
1
10
2
10
3
10
4
10
5
8
9
10
11
12
13
sample size M
ensemble mean of |x| at final time
estimated mean
lower confidence interval
upper confidence interval
10
1
10
2
10
3
10
4
10
5
0 5
0 6
0 7
ensemble mean of |x| at initial time
10
1
10
2
10
3
10
4
10
5
8
9
10
11
12
13
sample size M
ensemble mean of |x| at final time
estimated mean
lower confidence interval
upper confidence interval
estimated mean
lower confidence interval
upper confidence interval
Figure 4.7 Ensemble estimates for |x| and their conﬁdence intervals for the
deterministic Lorenz-63 model (see Example 4.2) in the top panel and the stochastically
perturbed variant (see Example 4.13) for increasing ensemble size M in the bottom panel.
Both models display a similar behaviour. However the asymptotic values for |x| diﬀer by
about 10% at ﬁnal time t = 5.
interval for the estimated expectation values is itself estimated by
4
|x|M(t) −1.96
6
varM(t)
M
, |x|M(t) + 1.96
6
varM(t)
M
5
.
The computed expectation values and the boundaries for their conﬁdence inter-
vals can be found in Figure 4.7 for the deterministic model (Example 4.2) as well
as for the stochastically perturbed model (Example 4.13). The expectation val-

4.3 Probabilistic forecasting and ensemble prediction
119
ues |x|M converge to approximately 11.16 for the stochastically perturbed model
and 10.26 for the deterministic model, as the ensemble size M is increased. There
is also a systematic diﬀerence in the computed variance varM(t). The determin-
istic model leads to a value of about 9.8 while the stochastically perturbed model
leads to 12.5.
Example 4.22
We consider the SDE
dZ = γ(−Z3 + Z)dt +
√
0.2dW(t),
(4.36)
on Z = R for γ > 0. We note that
z3 −z = d
dz
z4
4 −z2
2

,
i.e., the deterministic part of (4.36) is generated by the negative derivative of
the potential
U(z) = γ z4
4 −γ z2
2 .
Stationary points of the deterministic part are characterised by U ′(z) = 0, i.e.,
0 = z(z2 −1) and we obtain three stationary points z0 = 0, and zm = ±1,
respectively. Upon investigating the second derivative U ′′(z) = 3z2 −1, we ﬁnd
that z0 = 0 is unstable (since U is locally concave) while zm = ±1 are stable
(since U is locally convex).
The shape of the potential U is shown in Figure 4.8 for 1 ≤γ ≤4. We
also show a typical trajectory for γ = 1 and γ = 2 which demonstrates that it
becomes increasingly diﬃcult for solutions to overcome the barrier between the
two potential wells at zm = ±1 in the limit of large γ. The occasions when z(t)
crosses this barrier becomes a rare event.7
We now use ensemble prediction to estimate the fraction of trajectories starting
at z0 = 1 that take a value z(t) < 0 at time t = 1000. The ensembles are gen-
erated numerically using the Euler–Maruyama method with step-size δt = 0.01.
Table 4.1 shows the results as a function of the ensemble size and the parameter
γ. A fraction of 0.5 implies that trajectories have statistically equilibrated while
a small fraction implies that most trajectories have not been able to cross the
barrier.
We mention that ensemble prediction leads to associated empirical measures
μM(dz, t) = 1
M
M

i=1
μzi(t)(dz) = 1
M
M

i=1
δ(z −zi(t))dz,
(4.37)
7 The statistics of rare events is investigated under extreme value theory (EVT). In contrast
with the laws of large numbers, as considered in Chapter 3, EVT deals with laws for small
numbers. An introduction to EVT can be found in Coles (2001).

120
Stochastic processes
2
1.5
1
0.5
0
0.5
1
1.5
2
1
0
1
2
3
4
5
6
7
8
state variable z
potential U(z)
γ = 1
γ = 2
γ = 4
0
200
400
600
800
1000
2
1
0
1
2
trajectory for γ = 1
0
200
400
600
800
1000
2
1
0
1
2
time
trajectory for γ = 2
Figure 4.8 We display the potential U for diﬀerent values of γ in the top panel. The
barrier between the two potential wells at zm = ±1 increases as γ increases. The eﬀect on
trajectories starting from z0 = 1 can be seen in the bottom panel.
which provide a numerical approximation to uncertainties induced by uncertain
initial conditions and stochastic forcing terms in an SDE model. These empirical
measures were used in Example 4.22 to estimate the probability of a trajectory
to be found in either the left or right potential well. These probabilities represent
our uncertainty when forecasting whether a particular realisation z(t) will satisfy

4.4 Scoring rules for probabilistic forecasting
121
γ/M
1
2
3
4
5
10
0.5
0.3
0.2
0
0
100
0.54
0.52
0.26
0.03
0.02
1000
0.512
0.515
0.26
0.043
0.002
10000
0.5009
0.4907
0.2539
0.0361
0.0044
Table 4.1 Fraction of
trajectories starting from
z0 = 1 at t = 0 that take a
value z(t) < 0 at t = 1000
in an ensemble of
M ∈{10, 100, 1000, 10000}
members and for parameter
value γ ∈{1, 2, 3, 4, 5}.
z(t) > 0 or z(t) < 0. However, it should be kept in mind that these uncertain-
ties may not reﬂect forecast uncertainties with respect to the reference solution
zref(t), as introduced in Chapter 1 (or future partial observations of zref(t)), in
the case of systematic model errors. We provide a brief discussion on this issue
in the following section.
4.4
Scoring rules for probabilistic forecasting
We have seen that stochastic dynamical models, in the form of either a diﬀerence
equation (4.21) or an SDE (4.25), allow us to forecast the PDFs πZ(z, t), t ≥0,
starting from some known initial PDF πZ(z, 0). Numerically, these PDFs can be
approximated by ensemble prediction as discussed in the previous section; we
obtain a good prediction of model statistics in the limit of large ensemble sizes.
However, there will still be errors in the probabilistic forecast due to the use
of an imperfect model (these could be numerical discretisation errors, or model
errors such as incorrect values of parameters or simplifying assumptions in the
model). In probabilistic forecasting, we need to assess the impact of these errors
on statistics, which are the main “product” that we are interested in.
One diﬃculty in analysing the impact of model errors on statistics is that
the model is of some physical system where we cannot measure the complete
system state or construct exact solutions. One approach is to collect a time
series of observations from the physical system, and to compare it with simulated
observations from the model; this will determine how well calibrated the model
is to the physical system.
We will assume that partial observations y = h(z) of a physical process are
available at equally spaced time instances tk = kΔtout, k = 1, . . . , Nobs, with
Δtout > 0. We denote the observed values by yobs(tk), and will ignore measure-
ment errors throughout this section. For simplicity, we will also assume that the
observed quantity is a scalar. Then, given a model predicted PDF πZ(z, tk), we
can deduce predicted probability measures μY (dy, tk) in the observable via
μY (A, tk) =

h
1(A)
πZ(z, tk) dz
for all Borel sets A ⊂R. We will assume that there is a PDF πY (y, tk) such that

122
Stochastic processes
μY (dy, tk) = πY (y, tk)dy, i.e., the measures μY (dy, tk) are absolutely continuous
with respect to the Lebesgue measure on R.
We now introduce the probability integral transform as a tool for assessing the
calibration of the predicted PDFs πY (y, tk) with respect to the data yobs(tk) ∈R.
Definition 4.23 (Probability integral transform)
Given a scalar random variable
Y with cumulative probability density function FY (recalling Deﬁnition 2.6), the
probability integral transform (PIT) deﬁnes a new random variable P with
P = FY (Y ).
(4.38)
Lemma 4.24 (Uniform distribution for the PIT)
Let P be deﬁned as the PIT of
Y , as above, and assume that FY is strictly monotonic increasing on the range
of Y . Then P ∼U[0, 1].
Proof
Since FY is strictly monotonic increasing on the range of Y , its inverse
exists and is deﬁned by
P(Y < F −1
Y (p)) = p.
Then, for 0 ≤p ≤1,
P(P < p) = P(FY (Y ) < p) = P(Y < F −1
Y (p)) = p,
(4.39)
hence the result.
This means that it is possible to check whether two random variables Y1 and
Y2 have the same distribution by taking samples from Y2, computing the PIT
using FY1, and comparing visually with the uniform distribution by plotting a
histogram.
We can apply this to the calibration of dynamic models, if we assume that
the observations {yobs(tk)} are ergodic with respect to some stationary invariant
measure. We also assume that the forecast PDFs πY (y, tk) become stationary as
tk →∞. Under these assumptions, we can combine the sequence of forecast PDFs
πY (y, tk) together with observations yobs(tk) for tk = kΔtout, k = 1, . . . , Nobs
with Nobs suﬃciently large, to obtain PIT values
ptk = FY (yobs(tk), tk).
Here FY denotes the induced cumulative distribution function given by
FY (y, tk) =
 y
−∞
πY (y′, tk) dy′.
(4.40)
Since the forecast PDFs will not be available in general, in practice this has
to be implemented using Monte Carlo ensemble forecasts yi(tk) = h(zi(tk)),
i = 1, . . . , M, instead of πY (y, tk). Let us denote by
Fy(y) :=
 y
−∞
μy(dy′) =
 0
for y < y ,
1
for y ≥y ,
(4.41)
the cumulative distribution function of the point measure μy(dy) = δ(y −y)dy.

4.4 Scoring rules for probabilistic forecasting
123
Then the empirical measure (4.37), associated with a forecast ensemble {yi(tk)},
gives rise to an empirical cumulative distribution function
F ˆYM (y, tk) = 1
M
M

i=1
Fyi(tk)(y),
(4.42)
and associated PIT values ˆptk = F ˆYM (yobs(tk), tk), k ≥1, which we then in-
spect to see whether they are uniformly distributed over their discrete range
{0, 1/M, . . ., (M −1)/M, 1}. The following algorithm provides a slightly simpli-
ﬁed assessment of PIT values in terms of rank histograms.
Algorithm 4.25 (Rank histogram)
Set M +1 counters ξi equal to zero initially.
For k = 1, . . . , Nobs do the following.
(i) Sort the (scalar) predicted observations yi = h(zi(tk)), i = 1, . . . , M, such
that y1 ≤y2 ≤· · · ≤yM.
(ii) Deﬁne the M + 1 intervals I1 = (−∞, y1], Ii+1 = (yi, yi+1] for i = 1, . . .,
M −1, and IM+1 = (yM, +∞).
(iii) Find the interval Ii∗containing the actual observation yobs(tk), and increase
the associated counter ξi∗by one.
Definition 4.26 (Calibrated ensemble forecast)
A Monte Carlo ensemble fore-
cast {yi(tk)}, k = 1, . . . , Nobs, is called calibrated if the histogram of ranks is
ﬂat, i.e.,
ξi ≈Nobs
M + 1
for Nobs suﬃciently large.
If the ensemble consists of a single forecast z(tk), i.e., M = 1, then we simply
need to count the cases for which h(z(tk)) > yobs(tk) and h(z(tk)) ≤yobs(tk),
respectively. The forecast is calibrated if both events have equal probability.
In addition to calibration we might also want to compare diﬀerent models by
using forecast scores.
Definition 4.27 (Forecast score)
Let FY be the cumulative distribution func-
tion which is being forecast, and let Yobs be a random variable which is be-
ing forecast by FY . Yobs has PDF πYobs. A scoring rule is a random variable
S(FY , Yobs) that assigns a scalar score to FY based on the actually observed
value of yobs = Yobs(ω). The expected value of the scoring rule is
E [S(FY , Yobs)] =

Y
S(FY , yobs)πYobs(yobs)dyobs.
A scoring rule is:
(i) proper if
E [S(FY , Yobs)] ≥E [S(FYobs, Yobs)] ,

124
Stochastic processes
for all cumulative distribution functions FY , where FYobs is the cumulative
distribution function for Yobs, and
(ii) strictly proper if
E [S(FY , Yobs)] = E [S(FYobs, Yobs)] =⇒FY = FYobs.
If S(FY , Yobs) is strictly proper then d(FY , FYobs), deﬁned by
d(FY , FYobs) = E [S(FY , Yobs)] −E [S(FYobs, Yobs)] ,
satisﬁes the properties of a divergence, i.e., d(F1, F2) ≥0 for all F1, F2, and
d(F1, F2) = 0 implies that F1 = F2.8
Given a proper scoring rule S(FY , Yobs), we say that a prediction F1 is more
skilful than another prediction F2 if
E [S(F1, Yobs)] < E [S(F2, Yobs)] .
Of course, in our context, we do not have access to the probability distribution for
the observations {yobs(tk)}. Instead we must again assume that the statistics of
the observations are ergodic and stationary and that the distributions FY (·, tk)
become stationary as k →∞. We can then calculate the empirical averaged
scoring rule
S({FY (·, tk)}, {yobs(tk)}) =
1
Nobs
Nobs

k=1
S(FY (·, tk), yobs(tk)).
In addition, we do not have access to FY (·, tk) either, and must use the empirical
CDF given by (4.42) to approximate the scoring rule.
We now discuss a few examples of scoring rules.
Definition 4.28 (Continuous ranked probability score)
Given a cumulative dis-
tribution function FY (y) and an observed value yobs without observation errors,
the continuous ranked probability score is deﬁned by
Scrps(FY , yobs) =
 ∞
−∞
(FY (y) −Fyobs(y))2 dy,
(4.43)
where Fyobs is the empirical cumulative probability distribution function given
by (4.41), with y = yobs.
Lemma 4.29
The continuous ranked probability score is strictly proper.
8 A divergence has all the properties of a distance as deﬁned in topology except the triangle
inequality property.

4.4 Scoring rules for probabilistic forecasting
125
Proof
It can be shown that (see Problem 4.6)
E [Scrps(FY , Yobs)] =
 ∞
−∞
Scrps(FY , yobs) πYobs(yobs)dyobs
=
 ∞
−∞
(FY (y) −FYobs(y))2dy
+
 ∞
−∞
FYobs(y)(1 −FYobs(y))dy,
(4.44)
and hence
dcrps(FY , FYobs) = E [Scrps(FY , Yobs)] −E [Scrps(FYobs, Yobs)]
=
 ∞
−∞
(FY (y) −FYobs(y))2dy ≥0,
which is only equal to zero if FY = FYobs, hence the result.
The logarithmic scoring rule is another popular scoring rule.
Definition 4.30 (Logarithmic scoring rule)
The logarithmic scoring rule is de-
ﬁned by
Slog(FY , yobs) = −ln πY (yobs),
where πY (y) = F ′
Y (y).
Lemma 4.31
The logarithmic scoring rule is strictly proper.
Proof
The implied expected score is
E[Slog(FY , Yobs)] =
 ∞
−∞
Slog(FY , yobs) πYobs(yobs)dyobs
= −
 ∞
−∞
ln πY (yobs) πYobs(yobs)dyobs,
which gives rise to the Kullback–Leibler divergence
dKL(FY , FYobs) = E[Slog(FY , Yobs)] −E[Slog(FYobs, Yobs)]
=
 ∞
−∞
ln πYobs(yobs)
πY (yobs) πYobs(yobs)dyobs.
(4.45)
See Gneiting, Balabdaoui & Raftery (2007) for a more detailed discussion of
scoring rules, and also Br¨ocker (2012) for computational aspects of the continuous
ranked probability score.
Finally, we give an example of a proper but not strictly proper scoring rule.
Definition 4.32 (Root mean square error)
The root mean square error scoring
rule is
S(FY , yobs) = (y −yobs)2,

126
Stochastic processes
where y = E[Y ] denotes the mean with respect to the cumulative distribution
function FY .
Application of the scoring rule in our framework gives rise to the root mean
square error (RMSE)
RMSE(FY ) =

	
	

1
Nobs
Nobs

k=1
(yM(tk) −yobs(tk))2,
yM(tk) = 1
M
M

i=1
yi(tk),
which is widely used as a simple metric to assess the quality of a family of
ensemble forecasts {yi(tk)}, k = 1, . . . , Nobs.
Lemma 4.33
The root mean square error scoring rule is proper but not strictly
proper.
Proof
The expected score is
 ∞
−∞
S(FY , yobs) πYobs(yobs)dyobs = (y −yobs)2 + E[(Yobs −yobs)2]
and we ﬁnd that
d(FY , FYobs) = (y −yobs)2 ≥0.
This expression does not deﬁne a divergence since there exist many distribution
functions FY and FYobs with FY ̸= FYobs and y = yobs.
While it is straightforward to compute the RMSE for an ensemble yi(tk) =
h(zi(tk)) of M model forecasts with respect to an observed yobs(tk), computing
the continuous ranked probability score is slightly more technical. Using the
empirical cumulative distribution function (4.42) instead of FY in the deﬁnition
of the continuous ranked probability score, Scrps(F ˆYM , yobs) can be explicitly
evaluated and we obtain
Scrps(F ˆYM , yobs) = 2
M
M

i=1
i −1/2
M
(yobs −yi)+
+ 2
M
M

i=1

1 −i −1/2
M

(yi −yobs)+.
(4.46)
Here (y)+ = 0 if y ≤0 and (y)+ = y for y > 0. For a single member forecast
y(tk) = h(z(tk)), i.e., M = 1, this formula reduces to
Scrps(F ˆYM (·, tk), yobs(tk)) = |y(tk) −yobs(tk)|.
Example 4.34
We apply the rank histogram and the empirical averaged con-
tinuous ranked probability score (ACRPS),
Scrps({F ˆYM (·, tk)}, {yobs(tk)}) =
1
Nobs
Nobs

k=1
Scrps(F ˆYM (·, tk), yobs(tk)),

4.4 Scoring rules for probabilistic forecasting
127
100
200
300
400
500
600
700
800
900
1000
0
2
4
x 10
3
relative frequency
rank histogram for deterministic model
100
200
300
400
500
600
700
800
900
1000
0
2
4
x 10
3
rank of observation in ensemble
relative frequency
rank histogram for stochastic model
Figure 4.9 Rank histograms for the deterministic and the stochastically perturbed
Lorenz-63 models. Both models are found to be calibrated with respect to the
observations according to their essentially ﬂat rank histograms.
to our deterministic and stochastically perturbed Lorenz-63 models. The unper-
turbed observations are provided by the reference model described in Example
1.1 from Chapter 1. We use a total of 4000 data points collected in intervals of
Δtout = 0.05. The x-component of the state vector is observed and formula (4.46)
is used for evaluating the ACRPS. The computations are based on M = 1000 en-
semble forecasts from each model. Initial conditions are generated by perturbing
the values of the reference solution at time zero by random numbers with mean
zero and variance σ2 = 0.01. The resulting score for the deterministic model is
9.0049 while the stochastically perturbed model leads to 8.9786. We also run
the reference model from Example 1.1 with the same random initial conditions
and obtain a score of 8.9572. Hence we may conclude that the stochastically
perturbed model performs nearly as well as the reference model for the given
initial conditions closely followed by the deterministic model. Furthermore, the
rank histograms for the deterministic and the stochastically perturbed model are
displayed in Figure 4.9 and reveal that both imperfect models can be considered
as calibrated.
We now investigate the impact of numerical time-stepping errors. We have
already mentioned this additional source of forecast errors in Chapter 1. In order
to investigate the impact of numerical errors on calibration and scoring we replace
the deterministic model, which we write abstractly as
zn+1 = zn + δtf(zn),
tn+1 = tn + δt,
by either the explicit Euler approximation
zn+1 = zn + Δtf(zn),
tn+1 = tn + Δt,

128
Stochastic processes
100
200
300
400
500
600
700
800
900
1000
0
2
4
x 10
3
relative frequency
rank histogram for explicit Euler with Δ t  0 01
100
200
300
400
500
600
700
800
900
1000
0
2
4
x 10
3
rank of observation in ensemble
relative frequency
rank histogram for implicit midpoint with Δ t  0 01
Figure 4.10 Eﬀect of diﬀerent time-stepping methods on calibration. While the Euler
method with step-size Δt = 0.01 = 10δt leads to non-calibrated forecasts, the implicit
midpoint is still calibrated even though the step-size has increased by a factor of ten.
with Δt = 10δt = 0.01, or the implicit midpoint rule
zn+1 = zn + Δtf

(zn+1 + zn)/2

.
In both cases we only investigate the deterministic model and still retain Δtout =
0.05. The computed ACRPS for the explicit Euler approximation is 9.2786 while
the implicit midpoint leads to 8.9823. We note an increase in the score for the ex-
plicit Euler approximation. This increase is also conﬁrmed by the rank histogram
for the Euler method, which is no longer ﬂat. See Figure 4.10. This is in contrast
to the implicit midpoint method, which despite the much longer time-step, still
leads to a ﬂat rank histogram and, therefore, to calibrated forecasts.
Problems
4.1
Generate an ensemble of initial conditions z0
i ∼N(0, δI) for i = 1, . . . , M,
with M = 1000, δ = 0.1, I the 3 × 3 identity matrix. Propagate these initial
conditions under the dynamical system deﬁned by (4.2) with step-size δt = 0.001
and the right hand side given by the Lorenz-63 model. Plot the resulting solution
ensembles at tn = 10, 100, and 1000. Increase the ensemble size to M = 10000
and, if computationally feasible, to M = 100000. The resulting ensemble at
t = 1000 should rather closely resemble the Lorenz attractor from Chapter 1.
Repeat the experiments, starting the initial ensemble from a diﬀerent point z in
phase space, i.e., z0
i ∼N(z, δI). What is the impact on the resulting ensemble
at later times?
4.2
Implement the iteration (4.9) with gn
2 generated by the modiﬁed tent map
iteration (4.11), δt = 0.001, and initial conditions y0 = 0, g0
2 = a(3−1/2 −1/2).
Output the resulting trajectory yn, n ≥0 every 50 iterations and generate a

4.4 Scoring rules for probabilistic forecasting
129
total of 1000000 outputs. By computing the sample mean, variance, skewness,
and kurtosis (see Chapter 2), discuss whether or not the increments
Δyk = y50k −y50(k−1),
k ≥1,
can be approximately viewed as samples from a Gaussian random variable.
4.3
Consider a transition matrix P ∈RM×M which we assume to be also
symmetric, i.e., PT = P. Eigenvectors v ∈RM with eigenvalue λ = 1 are called
stationary under the transition matrix P.
(i)
Show that all eigenvalues λ of P are real and satisfy λ ∈[−1, 1].
(ii)
A transition matrix P is called geometrically ergodic if it possesses a
unique stationary eigenvector and all other eigenvalues λ satisfy |λ| <
1.9 Show that the entries v∗
i of a stationary eigenvector v∗of a geomet-
rically ergodic transition matrix satisfy v∗
i ≥0 and can be normalised
to M
i=1 v∗
i = 1. (Of course, if v∗is an eigenvector so is −v∗.) Show
that other eigenvectors v satisfy M
i=1 vi = 0.
4.4
The time evolution of the marginal PDFs πZ(z, t) under an SDE (4.25) is
given by the Fokker–Planck equation (4.26). For scalar-valued SDEs the invari-
ance condition for a PDF reduces to
∂
∂z

f(z)π∗
Z(z) −∂π∗
Z(z)
∂z

= 0.
Determine all functions π∗
Z which satisfy this diﬀerential equation. Under which
conditions on f are those functions normalisable, i.e.,

R
π∗
Z(z)dz < ∞?
Hint: Consider ﬁrst the special case f(z) = az for a < 0 and a > 0.
4.5
Consider the linear SDE
dZ = −Zdt +
√
2dW(t),
with initial PDF πZ(z, 0) = n(z; −1, 0.01). Since the SDE is linear, the time-
evolved PDFs πZ(z, t) will remain Gaussian. Find analytic expressions for the
mean z(t) and the variance σ2(t). Next apply the Euler–Maruyama method to the
SDE with step-size δt = 0.01 over a time interval [0, 100]. Generate an ensemble
of M solutions {zn
i }n≥0 with initial conditions drawn from πZ(z, 0). Verify that
the estimated means zM and σ2
M converge to their analytic counterparts as
M →∞. Study the impact of the step-size on the estimates by increasing its
value to δt = 0.1 and δt = 1.0.
4.6
Show that the two parts of (4.44) are indeed equivalent using the deﬁnition
of the continuous ranked probability score (4.43). Hint: Show ﬁrst that
 ∞
−∞
FY (y)Fyobs(y)πYobs(yobs)dyobs = FY (y)FYobs(y).
9 We will reencounter transition matrices in Chapter 5 when we discuss Brownian dynamics
and spatio-temporal discretisation of its associated Fokker–Planck equation.

130
Stochastic processes
4.7
Verify that the Kullback–Leibler divergence (4.45) of two univariate Gaus-
sians Xi ∼N(xi, σ2
i ), i = 1, 2, is given by
dKL(FX1, FX2) =

R
ln πX1(x)
πX2(x)πX1(x)dx
= 1
2

σ−2
2 σ2
1 + σ−2
2 (x2 −x1)2 −1 −2 ln σ1
σ2

.
According to Example 2.32 the Wasserstein distance between πX1 and πX2 is
given by
W(πX1, πX2)2 = (x1 −x2)2 + (σ1 −σ2)2.
4.8
Replace the implicit midpoint method in Example 4.34 by the implicit
Euler method
zn+1 = zn + Δtf(zn+1)
(4.47)
and compute the resulting rank histograms for M = 100 ensemble members and
for step-sizes Δt = 0.001 and Δt = 0.01. Either ﬁxed point iteration or Newton’s
method (S¨uli & Mayers 2006) can be used to solve the resulting nonlinear equa-
tion (4.47) for zn+1. All other computational details can be found in Example
4.34.
4.5
Guide to literature
Gardiner (2004), Jazwinski (1970), Chorin & Hald (2009), and Pavliotis (2014)
provide an introduction to various aspects of stochastic processes. A more foun-
dational axiomatic treatment is provided in Bre´zniak & Zastawniak (1999),
Øksendal (2000), Lasota & Mackey (1994), and Meyn & Tweedie (1993). An el-
ementary introduction to stochastic diﬀerential equations can be found in Evans
(2013) and numerical issues are discussed in Higham (2001) and Kloeden &
Platen (1992). Verhulst (2000) and Collet & Eckmann (2006) provide an intro-
duction to diﬀerential equations and dynamical systems while an in depth treat-
ment of dynamical systems can be found in Katok & Hasselblatt (1995). The
reader is referred to Gneiting et al. (2007) and Br¨ocker (2012) for a discussion
of scoring rules and calibration.

5
Bayesian inference
In this chapter, we deﬁne Bayesian inference, explain what it is used for and
introduce some mathematical tools for applying it.
We are required to make inferences whenever we need to make a decision in
light of incomplete information. Sometimes the information is incomplete be-
cause of partial measurements. For example, it can be diﬃcult determine from
a photograph whether the ball crossed the goal line in a football match because
the information is incomplete: three-dimensional reality has been projected into
a two-dimensional image, and in addition, the picture is only a snapshot in time
and we cannot determine the speed and direction in which the ball is moving.
The information is partial because we only see the situation from one angle, and
at one moment in time. Also, sometimes the information is incomplete because of
inaccurate measurements. In our example, this would occur if the photographic
image was fuzzy, so we could not even determine exactly where the ball and the
goal line are in the photograph. Incomplete information results in uncertainties
which make decision-making diﬃcult. However, often we have to make a decision
anyway, despite the presence of uncertainty. In this situation, we have to combine
the incomplete information with preconceived assumptions. We do this all the
time in our daily lives, without even thinking about it; it is called “intuition”.
Intuition can be surprisingly successful in some situations, for example we are
somehow able to control cars at high speeds on motorways with relatively few
accidents. However, in some other situations, intuition can fail miserably. To in-
crease skill in decision making, in predicting the spread of tuberculosis in cattle
for example, it is necessary to adopt a more rigorous approach.
When making an inference we have to decide how much to trust the incom-
plete information and how much to trust prior assumptions (assumptions based
on previous experience before taking the measurement). If we take an uncertain
measurement that does not match our previous experience, do we assume that
the situation is changing and take notice of the measurement, or do we neglect
the measurement, assuming that an error was made? If a mathematical approach
is to be useful, it needs to be able to guide us in these situations. In Bayesian
inference, this question is resolved by quantifying our uncertainty in the mea-
surements as probabilities. In addition, the uncertainty in our prior assumptions
(prior uncertainty), and our uncertainty about the situation after taking the
measurements (posterior uncertainty), are also quantiﬁed as probabilities. The
step of treating uncertainties in our prior knowledge (or belief) as probabilities
constitutes a bold mathematical abstraction. However, this abstraction leads to

132
Bayesian inference
the relationship between measurement uncertainty, prior uncertainty, and poste-
rior uncertainty being completely described by Bayes’ theorem, the central tool
of Bayesian inference. Later in this book we will explain that prior knowledge
can be acquired from mathematical models and, depending on the modeller and
the model, ensemble forecasts will be given a probabilistic interpretation. The
main task of Bayesian inference is then to evaluate the posterior uncertainty
accurately and in a computationally eﬃcient way.
5.1
Inverse problems from a probabilistic perspective
In this chapter we introduce the framework of Bayesian inference, illustrated
with some simple examples. Mathematical theories of inference are concerned
with determining the value of some variable x of interest, which could be a sin-
gle number (for example the price of cotton), an array of numbers organised into
a vector (for example the position of a space probe travelling towards Jupiter), or
a function (for example the distribution of temperature in the world’s oceans).
From a more mathematical perspective, the variable of interest could, for ex-
ample, be the state z of a dynamical system or, more generally, of a stochastic
process as considered in Chapter 4. We refer to x ∈X as the parameters with
parameter space X. In Bayesian statistics, we use probability to quantify our
uncertainty about x; this requires us to regard x as a realisation of a random
variable X : Ω →X. A typical inference model is then the following.
Definition 5.1 (Inference model1)
Consider a random parameter vector X :
Ω →X = RNx, and an observation noise variable Ξ : Ω →Y = RNy, both over
a probability space (Ω, F, P). Assume that X and Ξ are independent random
variables. Then the observed variable Y : Ω →Y ∈RNy is a random variable
deﬁned by
Y = h(X) + Ξ,
(5.1)
where h : X →Y is a continuous map, called the forward map.
The goal of Bayesian inference is to estimate our uncertainty in the state vari-
able X after we have observed one or more realisations of the random variable Y .
We now describe a simple inference problem that leads to a low-dimensional
linear inference model, closely related to the discussions from Chapter 1.
Example 5.2
Assume that a scalar variable z ∈R varies in time according to
the following linear model
z(t) = b1t + b0,
(5.2)
where b0 and b1 are unknown parameters. In contrast with the modelling scenario
described in Chapter 1, here we assume that (5.2) is also used for generating the
reference trajectory zref(t), but now with unknown parameter values b0 and b1.
1 This model can of course be generalised in many ways, Y may be a nonlinear function of
Ξ, and X and Ξ may not be independent variables. Also, here X and Y are taken from
vector spaces but they could be taken from any chosen mathematical sets.

5.1 Inverse problems from a probabilistic perspective
133
This modelling scenario is often referred to as a perfect model scenario. Our goal
is to estimate the parameters b0 and b1 from observations of yobs(tk) taken at
a set of discrete times tk, k = 1, . . . , Nobs. We assume that the observations are
made with a measurement device that introduces an error which is normally
distributed with mean zero and variance σ2 > 0, and that the observation errors
at diﬀerent times are statistically independent. Then the measurement process
can be described mathematically as follows:
yobs(tk) = b1tk + b0 + ξk,
k = 1, . . . , Nobs.
The measurement errors ξk are viewed as independent realisations of N(0, σ2).
This can be rewritten in the form of (5.1) with
Y = (Y (t1), Y (t2), . . . , Y (tNobs))T ∈RNobs,
x = (b0, b1)T ∈R2,
h(x) =
⎛
⎜
⎜
⎜
⎝
b0 + b1t1
b0 + b1t2
...
b0 + b1tNobs
⎞
⎟
⎟
⎟
⎠,
and ξ = (ξ1, . . . , ξNobs)T is a realisation of Ξ ∼N(0, σ2I).
In order to infer information about the state variable X from realisations of Y ,
we need to know how the probability distribution for Y relates to the probability
distribution for X. Lemma 2.13 from Chapter 2 can be used to prove the following
formula for πY .
Theorem 5.3 (Distribution of observation variable Y )
Assume that X and Ξ
are absolutely continuous with PDFs πX and πΞ respectively, and Y is related
to X and Ξ via (5.1). Then Y is also absolutely continuous with PDF
πY (y) =

RNx
πΞ(y −h(x))πX(x)dx.
(5.3)
If X is a deterministic variable, i.e., X(ω) = x0 almost surely for an appropriate
x0 ∈X, then the PDF simpliﬁes to
πY (y) = πΞ(y −h(x0)).
Proof
First we compute the conditional PDF πY in the case of a ﬁxed parameter
value X = x0. If X is deterministic then the only source of uncertainty is Ξ. We
use Lemma 2.13 with transformation Φ(ξ) = h(x0) + ξ, its inverse Φ−1(y) =
y −h(x0), and Jacobian DΦ−1(y) = I to obtain
πY (y) = πΞ(y −h(x0)).
In the case of a deterministic parameter X = x0, the proof is complete. If X is a
random variable, then the same reasoning gives the conditional PDF for X = x0
πY (y|x0) = πΞ(y −h(x0)),

134
Bayesian inference
and the joint distribution πXY of (X, Y ) satisﬁes
πXY (x, y) = πY (y|x)πX(x).
Finally we marginalise, i.e.,
πY (y) =

RNx
πXY (x, y)dx =

RNx
πY (y|x)πX(x)dx,
and obtain Equation (5.3).
Example 5.4
In this example we will calculate πY for the case in which X
and Ξ are multivariate normal random variables with means x and zero, and
covariance matrices P and R, respectively. The forward operator h : RNx →RNy
is a linear map deﬁned by
h(x) = Hx,
where H is an (Nx × Ny)-dimensional matrix. Equation (5.3) then becomes
πY (y) ∝

RNx
exp

−1
2(y −Hx)TR−1(y −Hx)

× exp

−1
2(x −x)TP −1(x −x)

dx,
where we have left out the constant of proportionality since we can always nor-
malise the PDF at the end of the calculation. Next we use the completing-the-
square formula
xTCx −2dTx = (x −C−1d)TC(x −C−1d) −dTC−1d,
to reformulate the exponent in the integrand
I = −1
2
9
(Hx −y)TR−1(Hx −y) + (x −x)TP −1(x −x)
:
,
as
I = −1
2
9
(x −C−1d)TC(x −C−1d) −dTC−1d + yTR−1y + xTP −1x
:
,
where
C = P −1 + HTR−1H,
d = HTR−1y + P −1x.
Since the x dependence in I reduces to a normalisation constant under marginal-
isation, we obtain
πY (y) ∝exp

−1
2(yTR−1y −dTC−1d)

.

5.1 Inverse problems from a probabilistic perspective
135
Figure 5.1 Schematic representation of
the loop created by the forward map H,
which links the desired variable x to an
observable quantity y, an actual
observation yobs, and its inference back
onto the variable of interest x. Bayesian
inference treats x and y as random
variables and we use the notations X and
Y instead.
If we quantify the uncertainty in the measurement device using the random
variable Ξ, and quantify our uncertainty in the parameters using the random
variable X, then Theorem 5.3 shows us how to quantify our uncertainty in the
measured values using the random variable Y . This is often referred to as the
forward problem which, as we have seen, can be solved using a simple transfor-
mation of variables. However, this simple transformation can already be very
challenging to compute for large Nx, since it involves integration over a large
number of dimensions. Hence we either have to restrict ourselves to (or approx-
imate by) cases for which the integrals are simple to evaluate (such as the case
of linear transformations of Gaussian variables given in Example 5.4), or adopt
Monte Carlo methods as discussed in Chapter 3.
Having said that, we are actually more interested in the inverse inference
problem in which we have obtained an observation which is modelled as a ran-
dom observation variable y ∈Y, and we wish to infer the uncertainty in the
parameters x ∈X. See Figure 5.1 for a schematic representation of the connec-
tion between the forward problem, an observation, and the inference problem.
An example of such an inference problem is in oil recovery. Oil engineers try
to learn about the structure of oil reservoirs deep under the ground by various
techniques such as taking seismic readings at the surface, and by drilling holes
so that pressure and electrostatic measurements can be taken at depth. In that
case, the parameters x ∈X would contain all the variables required to describe
the state of the oil reservoir and the surrounding geology, for example, the oil
concentration ﬁeld and the rock porosity ﬁeld. The observation variable y ∈Y
would contain all of the observational data obtained. The forward operator h
would be a numerical model that simulates the oil reservoir (perhaps containing
ﬂuid and solid mechanics and solving the electrostatic equations) and the re-
sulting observations. The oil engineers wish to quantify their uncertainty about
the structure of the oil reservoir, having observed a value yobs of the observation
variable. This uncertainty can then be used to assess the chance of drilling for

136
Bayesian inference
oil being proﬁtable, which ultimately informs a decision by oil companies about
whether to invest.
Bayesian inference provides a mathematical framework to solve such inference
problems. The main tool is Bayes’ theorem which yields a conditional PDF for
the parameters x given an observation yobs.
Theorem 5.5 (Bayes’ theorem)
Given a particular observation value yobs ∈
RNy, the conditional PDF πX(x|yobs) is given by Bayes’ formula,
πX(x|yobs) = πY (yobs|x)πX(x)
πY (yobs)
.
(5.4)
Proof
The proof is obtained by exchanging the variables X and Y in the deﬁ-
nition of marginalisation and conditional PDFs to obtain
πXY (x, y) = πY (y|x)πX(x) = πX(x|y)πY (y),
and, hence,
πX(x|y) = πY (y|x)πX(x)
πY (y)
.
Here πX quantiﬁes our uncertainty about the parameters X before observ-
ing yobs (and hence we call it the prior PDF), whilst πX(x|yobs) quantiﬁes our
uncertainty after observing yobs (and hence we call it the posterior PDF). The
conditional PDF πY (y|x) quantiﬁes the likelihood of observing y given a par-
ticular value of x, and hence it is often called the likelihood function. The real
power of this formula comes from the fact that πY (yobs) is simply a normalisa-
tion factor; we know that πX(x|yobs) must integrate to 1, so we can compute any
normalisation factor as a post-processing step. This means that Equation (5.4)
can be written as
πX(x|yobs) ∝πY (yobs|x)πX(x) = πΞ(yobs −h(x))πX(x).
We note, however, that the normalisation factor πY (yobs) can become im-
portant when comparing diﬀerent models. Under such circumstances the factor
πY (yobs) is also referred to as the evidence. We will return to this topic in Chapter
9.
We use the formulas developed in Example 5.4 to evaluate the posterior dis-
tribution for Gaussian distributions with linear observation operator in the fol-
lowing example.
Example 5.6
Return to the notation of Example 5.4, and assume that we
have observed a particular value yobs of the observation variable Y . From the
calculations in that example we obtain
πX(x|y) ∝exp

−1
2

(y −Hx)TR−1(y −Hx) + (x −x)TP −1(x −x)

∝exp

−1
2(x −C−1d)TC(x −C−1d)

,

5.1 Inverse problems from a probabilistic perspective
137
with C and d deﬁned as before. This means that πX(x|yobs) = n(x; xa, P a) with
covariance matrix P a = C−1 = (P −1 + HTR−1H)−1 and mean
xa = C−1d
= x −P aHTR−1(Hx −yobs).
We now make a connection to Examples 1.2 and 1.8 from Chapter 1 and
Example 2.20 from Chapter 2. The state variable z takes the role of the parameter
x in all of these examples.
Example 5.7
We introduced the (scalar) measurement model (1.8) in Chapter
1. In addition we considered a particular case in Example 1.2, analysing it further
in Example 2.20. The key conclusion was that (1.8) can be replaced by the
stochastic measurement model
Y = h(zref(t)) + Ξ(t),
where Ξ(t) is a Gaussian random variable with mean zero and variance R. Follow-
ing our previous discussion, with the state variable z now replacing the parameter
variable x, this model gives rise to the conditional PDF (likelihood)
πY (y|z) =
1
√
2πR
e−(y
h(z))2
2R
.
A more complex case was considered in Example 1.8, where Nobs observations
yobs(tk) in observation intervals Δtout were considered simultaneously. Using the
notation of Chapter 1, we obtain
yobs(t1) = Hψ(z0) + ξ1,
yobs(t2) = Hψ2(z0) + ξ2,
...
yobs(tNA) = HψNA(z0) + ξNA,
where the variables {ξk} are realisations of independent and identically dis-
tributed Gaussian random variables with mean zero and variance R. Note that
we have replaced zref(tk) by ψk(z0); this is justiﬁed if the model errors en, as
deﬁned by (1.19), are suﬃciently small and their accumulative eﬀect can be ig-
nored over the interval [0, tNA]. Under this assumption, we obtain the likelihood
function
πYt1 NA (yobs
t1 NA|z) =
1
(2πR)NA/2 ΠNA
k=1 exp

−(yobs(tk) −Hψk(z))2
2R

,
(5.5)
where yobs
t1 NA ∈RNA represents the values of all measurements yobs(tk) ∈R from
t1 to tNA. The nonlinear method of least squares, as introduced in Example 1.8,
can now be viewed as maximising the likelihood, i.e., ﬁnding the minimiser of

138
Bayesian inference
(1.20) is equivalent to ﬁnding the maximiser z0
∗of (5.5) for given yobs
t1 NA. Indeed,
we ﬁnd that
ln πYt1 NA (yobs
t1 NA|z) = −R−1L(z) −NA
2 ln(2πR),
with L deﬁned by (1.20) and, consequently,
∇zπYt1 NA (yobs
t1 NA |z) = 0
if and only if
∇zL(z) = 0,
which justiﬁes the statement. In other words, we have used maximum likelihood
estimates (MLEs) in order to perform data assimilation in Example 1.8. We
will now introduce Bayesian estimates which will replace MLEs as a tool for
performing data assimilation in Chapter 6.
Having obtained a posterior PDF πX(x|yobs), it is often necessary to provide an
appropriate point estimate of x. Bayesian estimates for x are deﬁned as follows.
Definition 5.8 (Bayesian estimate)
Given a posterior PDF πX(x|yobs) we deﬁne
a Bayesian estimate ˆx ∈X by
ˆx = arg min
x′∈X

X
ℓ(x′, x)πX(x|yobs)dx,
where ℓ(x′, x) is an appropriate loss function. Popular choices include the max-
imum a posteriori (MAP) estimate with ˆx corresponding to the modal value
(global maximum) of πX(x|yobs). The MAP estimate formally corresponds to
the loss function
ℓε(x′, x) =
 1
if ∥x′ −x∥> ε,
0
otherwise,
in the limit ε →0. The posterior median estimate corresponds to ℓ(x′, x) =
∥x′ −x∥while the posterior mean estimate,
ˆx =

X
xπX(x|yobs)dx,
results from ℓ(x′, x) = ∥x′ −x∥2.2
The MLE is formally obtained as a special case of the MAP estimate with the
prior PDF (formally) set equal to a constant. This step is justiﬁed provided that

RNx
πY (y|x)dx < ∞.
(5.6)
This situation is referred to as a non-informative prior. Condition (5.6) does
not hold for most practical data assimilation problems since the dimension of
2 These estimates ˆx are themselves realisations of random variables ˆ
X, called estimators,
which depend on yobs = Y (ω). Compare Appendix 2.4 for the special case of the posterior
mean estimator under vanishing measurement errors Ξ ≡0 and Appendix 5.5 for the best
linear unbiased (BLUE) estimator.

5.1 Inverse problems from a probabilistic perspective
139
parameter space RNx is larger than the dimension of observation space RNy and
a proper/informative prior is essential for obtaining Bayesian estimates.
Note that the MAP estimate, the posterior mean and the posterior median
coincide for Gaussian random variables. This does not hold generally, as we
demonstrate in the following example.
Example 5.9
We consider a nonlinear forward map given by
y = h(x) = 7
12x3 −7
2x2 + 8x.
The observed value is yobs = 2 and the measurement error is normal with mean
zero and variance equal to one. The likelihood function is therefore
πY (yobs|x) =
1
√
2π e−(h(x)
2)2
2
.
The prior is assumed to be normal with mean x = −2 and variance σ2 = 1/2.
Hence the posterior is
πX(x|2) ∝
1
√
2π e−(x+2)2−1
2 (h(x)−2)2.
(5.7)
In order to compute the posterior PDF we introduce a computational grid
xj = jΔx with grid spacing Δx = 0.0001 suﬃciently small in order to com-
pute the posterior mean, median and MAP value from the grid values πX(xj|2)
to an accuracy of four leading digits. We obtain x ≈0.2095, a median of ap-
proximately 0.2006 and a MAP value of approximately 0.1837. A coarser grid is
used to display the prior, likelihood, and posterior in Figure 5.2. Note that the
uncertainty in the prior is signiﬁcantly larger than the measurement error in the
forward model and that the observed yobs = 2 is in the tail of the prior Gaussian
distribution.
We now discuss an important example where the posterior can be computed
analytically.
Example 5.10
Consider the case of a scalar observation with Ξ ∼N(0, R).
Then
πY (y|x) = πΞ(y −h(x)) =
1
√
2πR
e−1
2R (h(x)−y)2.
We also assume that X ∼N(x, P) and that h(x) = Hx. Then, the posterior
distribution of X given an observed y = yobs is also Gaussian with mean
xa = x −P aHTR−1(Hx −yobs)
= x −PHT(HPHT + R)−1(Hx −yobs),
(5.8)

140
Bayesian inference
4
3
2
1
0
1
0
0.5
1
1.5
2
2.5
3
probability density functions
prior
likelihood
posterior
Figure 5.2 Prior, likelihood and
posterior distributions for a univariate
example with nonlinear forward
operator. The prior is chosen to be
rather uninformative and also has a
mean quite far away from the observed
value. As a result, we ﬁnd that the
posterior is relatively close to the
likelihood.
and covariance matrix
P a = (P −1 + HTR−1H)−1
= P −PHT(HPHT + R)−1HP.
(5.9)
These are the famous Kalman update formulas. Both formulas can be veriﬁed by
direct calculations using the results from Example 5.6.
We note that xa solves the minimisation problem
xa = arg min
x∈RNx
1
2(x −x)TP −1(x −x) + 1
2R(Hx −yobs)2
;
,
(5.10)
which can be viewed as a Tikhonov regularisation of the ill-posed inverse problem
yobs = Hx,
x ∈RNx,
for Nx > 1. A standard Tikhonov regularisation would use x = 0 and P −1 = δI
with the regularisation parameter δ > 0 appropriately chosen. In the Bayesian
approach to inverse problems, the regularisation term is instead determined by
the prior PDF πX.
Example 5.11
We extend the previous example to a Gaussian mixture prior
on X:
πX(x) =
J

j=1
αj
(2π)Nx/2|Pj|1/2 exp

−1
2(x −xj)TP −1
j
(x −xj)

=
J

j=1
αj n(x; xj, Pj),
(5.11)

5.1 Inverse problems from a probabilistic perspective
141
where αj > 0, j = 1, . . . , J, denote the mixture weights which sum to one. The
posterior distribution is again a Gaussian mixture
πX(x|yobs) =
J

j=1
αa
j n(x; xa
j, P a
j ),
with new means
xa
j = xj −PjHT(HPjHT + R)−1(Hxj −yobs),
new covariance matrices
P a
j = Pj −PjHT(HPjHT + R)−1HPj,
and new weights
αa
j ∝
αj

2π(HPjHT + R)
exp

−(Hxj −yobs)2
2(HPjHT + R)

,
where the constant of proportionality is chosen such that the weights αa
j sum to
one.
We mention that Bayes’ formula must be replaced by the Radon–Nikodym
derivative in cases where the prior distribution is not absolutely continuous with
respect to the Lebesgue measure (or in the case that the space X does not admit
a Lebesgue measure). Consider as an example the case of an empirical measure
μX centred about the M samples xi ∈X, i = 1, . . . , M, i.e.,
μX(dx) = 1
M
M

i=1
μxi(dx) = 1
M
M

i=1
δ(x −xi)dx.
Then the resulting posterior measure μX(·|yobs) is absolutely continuous with
respect to μX and the associated Radon–Nikodym derivative is given by
dμX(x|yobs)
dμX(x)
∝πΞ(yobs −h(x)).
Furthermore, since

X
g(x)μX(dx|yobs) =

X
g(x)dμX(x|yobs)
dμX(x)
μX(dx)
for any suﬃciently regular function g, the posterior measure is given by
μX(dx|yobs) =
M

i=1
wi μxi(dx) =
M

i=1
wiδ(x −xi)dx,
with weights wi ≥0 deﬁned by
wi ∝πΞ(yobs −h(xi)),
and the constant of proportionality is determined by the condition M
i=1 wi = 1.

142
Bayesian inference
5.2
Sampling the posterior
We usually want to summarise our uncertainty, formally represented by the pos-
terior PDF πX(x|yobs), in terms of expectation values
g =

X
g(x)πX(x|yobs)dx,
where g could, for example, stand for the variance or correlation. Apart from a
few special examples, these integrals are intractable, and it becomes necessary to
use Monte Carlo methods to approximate them. Recall that a standard Monte
Carlo method would be based on samples xi, i = 1, . . . , M, from the posterior
distribution. In some cases such samples are easy to generate by the methods
discussed in Chapter 3; in other cases these methods can become computationally
demanding. In this section, we therefore introduce an alternative method for
generating samples from a desired distribution πX. This method is based on
Brownian dynamics and invariant measures.
A Brownian dynamics model is an SDE of type (4.25) with the vector ﬁeld
f being generated by a potential U : RNx →R. We also set Q = I in (4.25).
Note that we are shifting focus from an SDE as a model of a physical process
towards its use as a tool for generating samples xi from a PDF πX(x). In order
to emphasise this shift in focus we will denote the independent variable by τ
instead of t as used previously.
Definition 5.12 (Brownian dynamics and canonical distribution)
We consider
Brownian dynamics
dX = −∇xU(X)dτ +
√
2dW,
(5.12)
where U : RNx →R is an appropriate potential, the independent variable is
denoted by τ, and W(τ) denotes standard Brownian motion. We introduce the
canonical PDF
π∗
X(x) = C−1 exp(−U(x)),
C =

RNx
exp(−U(x))dx,
(5.13)
provided C < ∞. Following (4.28), we also deﬁne the linear operator
Lπ := ∇x · (π∇xU) + ∇x · ∇xπ,
(5.14)
and write the Fokker–Planck equation for Brownian dynamics in the abstract
operator form
∂πX
∂τ
= LπX.
(5.15)
Proposition 5.13 (Stationary distribution)
The canonical distribution (5.13)
satisﬁes Lπ∗
X = 0 which implies that the canonical PDF is stationary under the
associated Fokker–Planck equation.

5.2 Sampling the posterior
143
Proof
The proposition follows from ∇xπ∗
X = −π∗
X∇xU and
∇x · (π∗
X∇xU) + ∇x · ∇xπ∗
X = ∇x · (π∗
X∇xU + ∇xπ∗
X) = 0.
Note that the Fokker–Planck equation can also be reformulated as a gradient
ﬂow towards the stationary solution π∗
X:
∂πX
∂τ
= ∇x · (πX∇xU(x) + ∇xπX)
= ∇x ·

π∗
X∇x
πX
π∗
X

.
(5.16)
Equation (5.16) has the structure of a weighted diﬀusion equation with standard
diﬀusion formally obtained for π∗
X ≡1. See Appendix 5.6 for more details.
We now illustrate how Brownian dynamics in conjunction with Proposition
5.13 can be used to sample from a posterior PDF πX(x|yobs). A key observa-
tion is that the posterior PDF becomes the stationary distribution of Brownian
dynamics, provided that the potential U is chosen according to
U(x) = −ln πX(x|yobs)
= −ln πX(x) −ln πY (yobs|x) + ln πY (yobs).
Since the dynamics does not depend on a constant added or subtracted from
U(x), we may actually use
U(x) = −ln πX(x) −ln πY (yobs|x),
(5.17)
which provides a huge simpliﬁcation in practice since it avoids the computation
of the evidence πY (yobs).
If the Brownian dynamics is ergodic, then expectations from the posterior can
be computed by using time integrals according to
E[g(X)] =

RNx
g(x)π∗
X(x)dx
= lim
T →∞
1
T
 T
0
g(x(τ))dτ ≈lim
N→∞
1
N
N

n=1
g(x(τn)).
Here x(τ) denotes a particular realisation of Brownian dynamics and τn = n Δτ
with step-size Δτ > 0. This is an example of a generalised Monte Carlo method,
as deﬁned in Deﬁnition 3.15, with equal weights wi = 1/N. It is generalised since
the sample points x(τn) are not independent.
Example 5.14
We continue with Example 5.9 and recall the posterior (5.7)
which, according to (5.17), corresponds to the potential
U(x) = (x + 2)2 + 1
2(h(x) −2)2,

144
Bayesian inference
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
10
−6
10
−4
10
−2
10
0
1/M
relative error
Monte Carlo sampling
mean
variance
1/M1/2 reference slope
Figure 5.3 Relative errors in the posterior mean and the variance along trajectories of
(5.18) of length M. The typical Monte Carlo M −1/2 convergence rate can be observed
even though the samples xi are correlated.
with gradient
∇xU(x) = U ′(x) = 2(x + 2) +
 7
12x3 −7
2x2 + 8x −2
 7
4x2 −7x + 8

.
We now conduct a long simulation with the Euler–Maruyama method (compare
(4.21) from Chapter 4):
xn+1 = xn −ΔτU ′(xn) +
√
2Δτξn,
(5.18)
where the variables {ξn} are realisations of independent Gaussian random vari-
ables with mean zero and variance one. The step-size is set equal to Δτ = 0.001
(it is small for stability reasons) and we start from x0 = −2 (the centre of the
prior PDF). Time has no physical meaning here: we are not modelling a physical
process but merely exploiting the sampling property of the Brownian dynamics.
We disregard the ﬁrst one thousand time-steps and then store every iterate from
(5.18) until we have a total of Mmax = 130000 samples, which we denote by
{xi}Mmax
i=1
. To illustrate the behaviour of (5.18) as a sampling device we consider

5.2 Sampling the posterior
145
6
5
4
3
2
1
0
1
2
0
0.5
1
1.5
2
2.5
3
state variable z
probability densities computed from binned prior and posterior samples
Figure 5.4 Approximative probability
densities from binned samples drawn
from the posterior using Brownian
dynamics with a Gaussian prior using a
standard random number generator. The
result agrees well with the distributions
displayed in Figure 5.2.
the convergence of the empirical mean,
xM = 1
M
M

i=1
xi,
to the posterior mean x ≈0.2095 (as computed in Example 5.9) as a func-
tion of sample size (length of the trajectory) M ≤Mmax. We also consider the
approximation to the posterior variance,
σ2
M = 1
M
M

i=1
(xi −xM)2,
and monitor convergence to its asymptotic value σ2 ≈0.0211. We display the
relative errors |xM −x|/|x| and |σ2
M −σ2|/σ2, respectively, in Figure 5.3. The
typical Monte Carlo M −1/2 convergence rate is observed numerically.
Finally M = 130000 samples ˆxi are generated from the prior PDF using a
standard normal random number generator. The probability densities resulting
from the binned samples {xi} and {ˆxi} are displayed in Figure 5.4; note the
similarity with the PDFs displayed in Figure 5.2. These approximative densities
are obtained from the relative frequencies of the binned samples scaled by the
inverses of the bin widths.
While Brownian dynamics samples asymptotically from its stationary distri-
bution π∗
X, subsequent samples are not independent. This is diﬀerent from the
Monte Carlo methods we considered in Chapter 3. It is the case, however, that
the two random variables X(τn) and X(τm) become almost independent for
τn −τm ≫1. This is called decorrelation. Our tool for understanding decorrela-

146
Bayesian inference
tion is the linear Fokker–Planck equation (5.15).3 If all solutions of the Fokker–
Planck equation converge to the stationary PDF π∗
X in the limit τ →∞, then
for any random variable X(τn), we have πX(x, τn) ≈π∗
X(x) for large τn, inde-
pendently of the distribution of X(τm). This means that X(τn) and X(τm) are
becoming independent in the limit τn −τm →∞. To determine whether solu-
tions of the Fokker–Planck equation do indeed converge to the stationary PDF,
we need to study the spectral properties of L.
To analyse the eigenvalues of L, we introduce the weighted inner product
⟨π1, π2⟩∗=

RNx
π∗
X(x)−1 π1(x) π2(x) dx
in the space of all integrable functions such that ∥π∥∗= ⟨π, π⟩1/2
∗
< ∞. Since
⟨Lπ1, π2⟩∗=

RNx
(π∗
X)−1π2∇x · (π1∇xU + ∇xπ1)dx
= −

RNx
∇x((π∗
X)−1π2) · (π1∇xU + ∇xπ1)dx
= −

RNx
(π∗
X)−1(∇xπ2 + π2∇xU) · (π1∇xU + ∇xπ1)dx
= −

RNx
∇x((π∗
X)−1π1) · (π2∇xU + ∇xπ2)dx
=

RNx
(π∗
X)−1π1∇x · (π2∇xU + ∇xπ2)dx = ⟨π1, Lπ2⟩∗,
we may conclude that L is self-adjoint with respect to the inner product ⟨·, ·⟩∗.
Hence the spectrum σ(L) of L is on the real axis. Furthermore, since
⟨Lπ, π⟩∗=

RNx
(π∗
X)−1π∇x · (π∇xU + ∇xπ)dx
= −

RNx
(π∗
X)−1 (∇xπ + π∇xU) · (π∇xU + ∇xπ) dx
= −∥π∇xU + ∇xπ∥2
∗
≤0,
all eigenvalues of L have to be non-positive. We express this by writing σ(L) ⊂
{λ ∈R : λ ≤0}.
To determine whether solutions converge to the stationary PDF, ﬁrst we must
ask whether (5.13) is the only eigenfunction (up to scaling by a constant) with
eigenvalue zero. Second, in the case that (5.13) is indeed the only stationary
PDF for (5.15), we must ask whether the remaining spectrum of L is bounded
away from zero. If it is, then the non-zero eigenvalue with smallest magnitude
determines the rate at which solutions converge to the stationary PDF, since all
the non-stationary eigenfunctions will decay by at least that rate.
3 Although we are discussing a discrete time process, we know that it converges to a
continuous time process where the decorrelation process is somewhat easier to explain.
Similar arguments can be made for the discrete time process.

5.2 Sampling the posterior
147
Indeed, if (i) U is smooth, (ii)

X exp(−U(x))dx < ∞, and (iii) there is a
constant c > 0 such that the Hessian matrix, D2U(x), of second-order derivatives
satisﬁes
vTD2U(x)v ≥c∥v∥2,
for all v ∈RNx and all x ∈RNx, then the canonical PDF (5.13) is the unique
invariant density and
sup[σ(L) \ {0}] ≤−c.
(5.19)
See Pavliotis (2014) for a derivation of this result. Furthermore, solutions to the
Fokker–Planck equation (5.15) can be written in semi-group form
πX(·, τ) = eτLπX(·, 0).
(5.20)
This means that the non-stationary contributions in πX(x, 0) decay at least as
quickly as e−cτ as τ →∞. A numerical approximation to the operator eτL is
discussed in Appendix 5.7. There we also perform numerical experiments to verify
the bound (5.19) for Brownian dynamics with a particular choice of potential
U(x).
If Brownian dynamics fulﬁlls a spectral gap condition of type (5.19), then
XM = 1
M
M

n=1
Xn
(5.21)
satisﬁes a central limit theorem and a strong law of large numbers (compare
Chapter 3) even though the random variables Xn = X(τn) are correlated. Here
X(τ), τ ≥0, denotes the stochastic process induced by Brownian dynamics.
If Brownian dynamics is discretised by the Euler–Maruyama method (4.21),
time-stepping errors lead to sampling errors which imply that the associated es-
timator (5.21) is inconsistent as M →∞, where Xn now refers to the numerical
approximation at τn = nΔτ. However, the inconsistency vanishes as Δτ →0.
The inconsistency can also be eliminated for ﬁnite step-sizes by combining (4.21)
with a Metropolis accept-reject criterion. (See Deﬁnition 5.15 below.) The result-
ing Metropolis adjusted time-stepping method gives rise to a particular instance
of a Markov chain Monte Carlo (MCMC) method, called the Metropolis adjusted
Langevin algorithm (MALA) or hybrid Monte Carlo (HMC) method (Liu 2001).
We remark that the Euler–Maruyama method (4.21) without a Metropolis cri-
terion often leads to satisfactory results provided Δτ is chosen appropriately.
MCMC methods provide a ﬂexible tool for generating samples from a desired
PDF π∗
X. The basic idea is to combine a Markov process with symmetric tran-
sition PDF π(z′|z) = π(z|z′) in combination with a Metropolis accept/reject
criterion in order to generate a modiﬁed Markov process with π∗
X as an invariant
PDF. This is a very broad topic; here we summarise the key ideas in the case of
a ﬁnite state space X = {a1, a2, . . . , aM}. We assume that we have a symmetric
Markov chain on X with stochastic transition matrix P ∈RM×M, i.e., pij = pji.

148
Bayesian inference
Definition 5.15 (Discrete state space Markov chain Monte Carlo (MCMC) method)
Given a desired probability distribution p∗∈RM and a symmetric stochastic
transition matrix P ∈RM×M over a discrete state-space X = {a1, a2, . . . , aM},
the modiﬁed Markov chain with stochastic transition matrix ˜P with entries
˜pij = (1 −αij)δij + αijpij,
αij = 1 ∧(p∗
i /p∗
j) ,
(5.22)
gives rise to a MCMC method. The coeﬃcients αij ∈[0, 1] deﬁne the Metropolis
accept/rejection criterion. Here δij denotes the Kronecker symbol with values
δii = 1 and δij = 0 for i ̸= j and
a ∧b = min{a, b}.
The invariance of p∗under (5.22) follows from the detailed balance condition
˜pijp∗
j = ˜pjip∗
i
(5.23)
for all pairs i, j = 1, . . . , M since (5.23) implies

j
˜pijp∗
j =

j
˜pjip∗
i = p∗
i .
Detailed balance is satisﬁed by (5.22) since pij = pji. In terms of practical
implementation of (5.22) we proceed as follows. If the chain is in state aj, draw
a proposal state ai from X with probability pij. Next draw a uniform random
number ξ and accept the proposal if αij > ξ otherwise remain in the current
state aj. If p∗is the only invariant probability vector and all other eigenvalues
λl of the induced Markov chain
pn+1 = ˜Ppn
satisfy |λl| < 1 −c for a c > 0, then again a central limit theorem and a strong
law of large numbers hold for samples generated by the MCMC method.
5.3
Optimal coupling approach to Bayesian inference
In this section, we summarise the application of optimal transportation, as out-
lined in Chapter 2, to Bayesian inference. In the Bayesian context, it is often the
case that we have samples from the prior distribution, but we wish to compute
statistics from the posterior distribution. Recall that we introduced importance
sampling in Chapter 3 as a form of Monte Carlo method which is used when
we have samples from one distribution but we wish to compute statistics from
another distribution. In this section, we will combine importance sampling with
a transformation step which is based on the idea of optimal coupling and optimal
transportation. This transformation step allows us to transform prior samples
into posterior ones in a completely deterministic manner. Such transformations
will become important when we discuss recursive applications of Bayes’ theorem
in Part II of this book.

5.3 Optimal coupling approach to Bayesian inference
149
To prepare for the transition to a recursive application of Bayes’ theorem in
the context of data assimilation, we introduce the terms forecast and analysis
random variables (these are names which are used in the geosciences context
and have diﬀerent names in other ﬁelds). The forecast random variable gives rise
to the prior distribution and a Bayesian assimilation of data then leads to the
analysis random variable with its marginal distribution equal to the posterior
PDF.
More speciﬁcally, given a prior or forecast random variable Xf : Ω →RNx,
we denote its PDF by πXf(x), x ∈RNx, and consider the assimilation of an
observed yobs ∈RNy with likelihood function πY (y|x). The posterior or analysis
PDF is given by
πXa(x|yobs) =
πY (yobs|x)πXf(x)

RNx πY (yobs|x)πXf(x)dx,
(5.24)
according to Bayes’ theorem.4 It is important to emphasise that Bayes’ theorem
does not determine the random variable Xa as a transformation from Xf. In-
stead Bayes’ theorem only determines the marginal PDF πXa(x|yobs); for given
marginal PDF there are many possible couplings in general. Computing optimal
couplings between Xf and Xa is the subject of this section.
Typically, the forecast random variable Xf and its PDF are not available ex-
plicitly. Instead we assume that an ensemble of forecasts xf
i ∈RNx, i = 1, . . . , M,
is given, which are considered as realisations Xf
i(ω), ω ∈Ω, of M independent
(or dependent) random variables Xf
i : Ω →RNx with law πXf. Applying the im-
portance sampling technique (see Chapter 3), we obtain the following estimator
for E[g(Xa)] with respect to the posterior PDF πXa(x|yobs) using the forecast
ensemble:
ga
M =
M

i=1
wig(xf
i),
with weights
wi =
πY (yobs|xf
i)
M
j=1 πY (yobs|xf
j)
.
(5.25)
This estimator is consistent (recall from Chapter 3 that an estimator is called
consistent if the root mean square error between the estimator ga
M and the exact
expectation value ga = E[g(Xa)] vanishes as M →∞).
Example 5.16
We return to the Bayesian inference problem of Example 5.9.
Instead of the Brownian dynamics sampling approach considered in Example
5.14 we now consider importance sampling by drawing M samples xi from the
4 Note that we will switch to the notation Zf and Za, respectively, in Part II of this book
when the random variables under consideration come from a dynamical system or a more
general Markov process.

150
Bayesian inference
10
6
10
5
10
4
10
3
10
2
10
1
10
3
10
2
10
1
10
0
10
1
1/M
relative error
importance sampling estimate
mean
variance
1/M1/2 reference slope
Figure 5.5 Relative errors
in the posterior mean and
variance obtained from
importance sampling with
the samples drawn from the
Gaussian prior. The relative
errors are deﬁned as in
Example 5.14. The error
behaviour is qualitatively
similar to that displayed in
Figure 5.3.
Gaussian prior N(−2, 1/2) with posterior weights
wi ∝e−1
2 (h(xi)−2)2.
The relative errors (as deﬁned in Example 5.14) in the posterior mean and vari-
ance,
xM =
M

i=1
wixi,
σ2
M =
M

i=1
wi(xi −xM)2,
are displayed in Figure 5.5 for a range of values of the ensemble size M. We ob-
serve an M −1/2 convergence behaviour on average; the overall errors are compa-
rable to those obtained from (5.18) in Example 5.14. We remark that examples
could be easily constructed where importance sampling is more eﬃcient than
Monte Carlo sampling using Brownian dynamics and vice versa. Importance
sampling is eﬃcient if the posterior does not diﬀer much from the prior and the
prior is easy to sample from.
Instead of using weighted forecast samples, an alternative is to attempt to
transform the samples xf
i = Xf
i(ω) with Xf
i ∼πXf into samples xa
i from the
posterior distribution πXa(x|yobs). Then we can use the estimator
ga
M = 1
M
M

i=1
g(xa
i ),
with equal weights. In other words, we are looking for a coupling between the
prior and posterior PDFs as discussed in Chapter 2.
Recall from Chapter 2 that for univariate random variables X1 = Xf and X2 =
Xa with PDFs πXf and πXa respectively, the transformation is characterised by
FXa(xa
i ) = FXf(xf
i),
(5.26)

5.3 Optimal coupling approach to Bayesian inference
151
2
1
0
1
2
3
4
realisations x
 
 
prior
posterior
Figure 5.6 Prior xf
i and posterior xa
i
realisations from the transform
method for M = 20.
where FXf and FXa denote the cumulative distribution functions of Xf and Xa,
respectively. Equation (5.26) requires knowledge of the associated PDFs; the
extension to multivariate random variables is non-trivial. Instead, we propose an
alternative approach that does not require explicit knowledge of the underlying
PDFs and that easily generalises to multivariate random variables. This approach
combines importance sampling with the idea of optimal transportation.
We have already discussed monomial resampling in Chapter 3, which can be
used to generate posterior samples {xa
i } from weighted prior samples {xf
i, wi}.
Monomial resampling eﬀectively deﬁnes a coupling between the two discrete
random variables Xf
M : Ω →XM and Xa
M : Ω →XM with realisations in
XM = {xf
1, . . . , xf
M} and probability vector pf = (1/M, . . . , 1/M)T for Xf
M and
pa = (w1, . . . , wM)T for Xa
M, respectively. Here a coupling between pf and pa is
an M × M matrix T with non-negative entries tij = (T )ij ≥0 such that
M

i=1
tij = 1
M ,
M

j=1
tij = wi;
(5.27)
compare Chapter 2.
Instead of deﬁning a coupling T through monomial resampling,5 we seek the
coupling T ∗that minimises the expected Euclidean distance
E[∥Xf
M −Xa
M∥2] =
M

i,j=1
tij∥xf
i −xf
j∥2.
(5.28)
As already discussed in Examples 2.28 and 2.34, the desired coupling T ∗is
obtained by solving a linear transport problem. Since (5.27) leads to 2M −1
independent constraints, the matrix T ∗contains at most 2M −1 non-zero entries.
Having computed T ∗, the stochastic transition matrix P = M T ∗∈RM×M on
XM then has the property that the probability vectors pf and pa satisfy pa = Ppf.
5 More precisely, monomial resampling can be interpreted as leading to a matrix T with
entries tij = wi/M, which treats Xf
M and Xa
M as independent random variables.

152
Bayesian inference
−2
−1
0
1
2
3
4
−2
−1 5
−1
−0 5
0
0 5
1
1 5
2
2 5
forecast particle locations
analysed particle locations
analytic transformat on
Linear programming transformation
Figure 5.7 Exact and numerical
ensemble transform map for
M = 20. The Gaussian case leads to
the exact transformation being
linear. The numerical approximation
deviates from linearity mostly in the
tails.
Given a set of M realisations xf
j, j = 1, . . . , M, from the prior PDF and
importance weights wi ∝πY (yobs|xf
i), a Monte Carlo resampling step proceeds
now as follows.
(i) Compute the coupling matrix T ∗which is optimal under the cost function
(5.28) and deﬁne discrete random variables ˆXa
j , j = 1, . . . , M, with law
ˆXa
j ∼
⎛
⎜
⎝
p1j
...
pMj
⎞
⎟
⎠.
(5.29)
Here pij denotes the (i, j)th entry of P = MT ∗and each column vector
in P deﬁnes a probability vector, i.e., M
i=1 pij = 1.
(ii) An analysis ensemble {xa
j} of size M is obtained by collecting a sin-
gle realisation from each random variable ˆXa
j , i.e., xa
j :=
ˆXa
j (ω) for
j = 1, . . . , M. This ensemble of equally weighted samples allows for
the approximation of expectation values with respect to the posterior
distribution πXa(x|yobs).
The outlined procedure leads to a particular instance of resampling with re-
placement. The main diﬀerence with the resampling techniques discussed in
Chapter 3 is that the resampling is chosen such that the expected distance (5.28)
between the prior and posterior samples is minimised (which is equivalent to
maximising the correlation between the prior and posterior samples).
We now introduce a further modiﬁcation which replaces the random resam-
pling step by a linear transformation. The modiﬁcation is based on the observa-
tion that the expectation values of the random variables (5.29) are given by
xa
j = E[ ˆXa
j ] =
M

i=1
xf
ipij.
(5.30)

5.3 Optimal coupling approach to Bayesian inference
153
0
5
10
15
20
0
2
4
6
8
10
12
14
16
18
20
analysed part cle index
forecast particle index
M 20 particles
Figure 5.8 Non-zero entries in the
matrix P for M = 20, which indicate
the support of the coupling. There are a
total of 2M −1 = 39 non-zero entries.
The banded structure reveals the spatial
locality and the cyclical monotonicity of
the resampling step.
We use this result to propose the deterministic transformation
xa
j := xa
j =
M

i=1
xf
ipij,
(5.31)
j = 1, . . . , M, hoping that
ga
M = 1
M
M

j=1
g(xa
j)
still provides a consistent estimator for E[g(Xa)] as M →∞. Indeed, consistency
for the posterior mean, i.e., g(x) = x, follows from
xa
M = 1
M
M

j=1
xa
j = 1
M
M

j=1
M

i=1
pijxf
i =

i,j
t∗
ijxf
i =
M

i=1
wixf
i.
Consistency for a general g is less obvious. Before investigating the theoretical
properties of the proposed transformation (5.31) we discuss an example, which
indicates that (5.31) leads to a consistent approximation to (5.26) in the limit
M →∞.
Example 5.17
We take the univariate Gaussian with mean x = 1 and variance
σ2 = 2 as the PDF for the prior random variable Xf. Realisations of Xf are
generated using
xf
i = 1 + 2 erf−1(2ui −1),
ui =
1
2M + i −1
M
for i = 1, . . . , M. The likelihood function is
πY (yobs|x) =
1
√
4π exp
−(yobs −x)2
4

with assumed observed value yobs = 0.1. Bayes’ formula yields a posterior dis-
tribution which is Gaussian with mean x = 0.55 and variance σ2 = 1. Since

154
Bayesian inference
Table 5.1 Estimated posterior ﬁrst- to fourth-order moments from the ensemble
transform method applied to a Gaussian scalar Bayesian inference problem.
x
σ2
E[(X −x)3]
E[(X −x)4]
M = 10
0.5361
1.0898
–0.0137
2.3205
M = 40
0.5473
1.0241
0.0058
2.7954
M = 100
0.5493
1.0098
–0.0037
2.9167
we are dealing with univariate random variables in this example, the matrix T ∗
of the associated optimal transport problem can be computed eﬃciently by the
algorithm described in Appendix 5.8 at the end of this chapter. The prior and
posterior realisations from the transform method are shown for M = 20 in Fig-
ure 5.6. We also display the analytic transform, which is a straight line in the
case of Gaussian distributions,6 and the approximative transform using optimal
transport in Figure 5.7. The locations of the non-zero entries of the stochastic
transition matrix P are displayed in Figure 5.8, which shows a banded structure
of local interactions. The staircase-like arrangement is due to cyclical mono-
tonicity of the support of T ∗. More generally, we obtain the posterior estimates
for the ﬁrst four moments displayed in Table 5.1, which indicate convergences as
M →∞. In fact, since non-random samples {xf
i} are being used, the convergence
rate is ﬁrst-order in 1/M.
We now proceed with a theoretical investigation of the transformation (5.31).
Our convergence result is based on the following lemma and general results from
McCann (1995).
Lemma 5.18
The set T consisting of all pairs (xf
j, xa
j), j = 1, . . . , M, with xa
j
deﬁned by (5.30), is cyclically monotone.
Proof
Let Ij denote the set of indices i where pij = Mt∗
ij > 0. From Theorem
2.35, the optimal coupling T ∗satisﬁes cyclical monotonicity. Hence let S denote
the support of μ∗
Xf
MXa
M , i.e., the set of all (xf
j, xf
i) ∈XM × XM such that t∗
ij > 0.
(Compare Example 2.34.) Then
⟨ξa
1, ξf
2 −ξf
1⟩+ ⟨ξa
2, ξf
3 −ξf
2⟩+ · · · + ⟨ξa
l , ξf
l+1 −ξf
l⟩+ · · · + ⟨ξa
L, ξf
1 −ξf
L⟩≤0 (5.32)
for any set of pairs (ξf
l, ξa
l ) ∈S, l = 1, . . . , L. In particular, (5.32) holds for
sequences containing a term of type
⟨ξa
l , ξf
l+1 −ξf
l⟩= ⟨xf
i, ξf
l+1 −xf
j⟩
with ξf
l = xf
j and ξa
l = xf
i for an appropriate index j and i ∈Ij. By linearity
6 Gaussian random variables are transformed into each other by shifting their centres and
scaling the anomalies. As already discussed in Chapter 2, this is equivalent to a linear
transformation.

5.3 Optimal coupling approach to Bayesian inference
155
of ⟨xf
i, ξf
l+1 −xf
j⟩in each of its two arguments, (5.32) then also applies to linear
combinations giving rise to
M

i=1
pij
9
⟨ξa
1, ξf
2 −ξf
1⟩+ ⟨ξa
2, ξf
3 −ξf
2⟩+ · · · + ⟨xf
i, ξf
l+1 −xf
j⟩+ · · · + ⟨ξa
L, ξf
1 −ξf
L⟩
:
= ⟨ξa
1, ξf
2 −ξf
1⟩+ ⟨ξa
2, ξf
3 −ξf
2⟩+ · · · + ⟨xa
j, ξf
l+1 −xf
j⟩+ · · · + ⟨ξa
L, ξf
1 −ξf
L⟩≤0
since M
i=1 pij = 1 and pij > 0 if and only if i ∈Ij. We ﬁnally use ξf
l = xf
j and
ξ
a
l = xa
j and apply the same procedure to all indices l′ ∈{1, . . ., L}\{l} resulting
in
⟨ξ
a
1, ξf
2 −ξf
1⟩+ ⟨ξ
a
2, ξf
3 −ξf
2⟩+ · · · + ⟨ξ
a
l , ξf
l+1 −ξf
l⟩+ · · · + ⟨ξ
a
L, ξf
1 −ξf
L⟩≤0.
Hence the set T is cyclically monotone.
Theorem 5.19
Assume that the ensemble X f
M = {xf
i}M
i=1 consists of reali-
sations from M independent and identically distributed random variables Xf
i :
Ω →RNx with PDF πXf. Deﬁne the set X a
M = {xa
j}M
j=1 with the means {xa
j}
given by (5.30). Then the associated maps ΨM : X f
M →X a
M deﬁned for ﬁxed M
by
xa
j = ΨM(xf
j),
j = 1, . . . , M,
converge weakly to a map Ψ : RNx →RNx for M →∞. Furthermore, the random
variable deﬁned by Xa = Ψ(Xf) has distribution (5.24) and the expected distance
between Xa and Xf is minimised among all such mappings.
The essence of this theorem can be found in McCann (1995). The only signiﬁ-
cant diﬀerence here is that McCann (1995) considers optimal couplings between
M independent samples {xf
i} from the prior πXf and M independent samples
{xa
i } from the posterior πXa. The optimal coupling ˆΨM : X f
M →ˆ
X a
M between the
uniform distribution on X f
M = {xf
i} and the uniform distribution on ˆ
X a
M = {xa
i }
is obtained by solving the associated assignment problem. Hence we only need
to demonstrate that we may replace ˆ
X a
M and ˆΨM in the proof of McCann (1995)
by the associated quantities deﬁned in Theorem 5.19.
Proof
The maps ΨM, M ≥1, deﬁne a sequence of couplings between discrete
random variables on X f
M and X a
M, which satisfy cyclical monotonicity according
to Lemma 5.18. We may now follow the proof of Theorem 6 in McCann (1995)
and conclude that these couplings converge weakly to a continuous coupling,
i.e., a probability measure μ ˜
Xf ˜
Xa on RNx × RNx with marginals π ˜
Xf and π ˜
Xa,
respectively. By construction it is clear that π ˜
Xf = πXf. We still need to show
that π ˜
Xa(x) = πXa(x|yobs) and that the support of μ ˜
Xf ˜
Xa is the graph of a map
Ψ. The latter property follows from the fact that μ ˜
Xf ˜
Xa is cyclically monotone
and that the probability measure for Xf is absolutely continuous with respect
to the Lebesgue measure on RNx. Hence the Main Theorem of McCann (1995)
can be applied to guarantee the existence and uniqueness of the map Ψ, which

156
Bayesian inference
itself is the gradient of a convex potential ψ. The potential ψ can be taken as
the limit of a family of convex potentials ψM on RNx such that
SM ⊂∂ψM,
i.e., the support SM of the coupling μ∗
Xf
M ,Xa
M induced by T ∗for ﬁxed M is
included in the subdiﬀerential of ψM (see Theorem 2.27 in Villani (2003)), as
well as
TM := {(xf
1, xa
1), . . . , (xf
M, xa
M)} ⊂∂ψM.
This proves that SM approaches TM as M →∞and π ˜
Xa(x) = πXa(x|yobs)
since the weights {wi} are deﬁned by importance sampling, which provides a
consistent approximation to the posterior PDF. The coupling μ ˜
Xf ˜
Xa solves the
Monge–Kantorovitch problem with cost c(x, y) = ∥x −y∥2 (Villani 2003, Villani
2009).
In particular, this theorem implies that the variance of the random vectors
ˆXa
j , as deﬁned by (5.29), vanishes as M →∞, and so the error replacing ˆXa
j by
its mean vanishes in that limit.
Example 5.20
We return to the problem set out in Example 5.9 and im-
plement importance sampling from the Gaussian prior as described in Example
5.16. Instead of estimating posterior expectation values from the samples xf
i with
weights wi, we now apply the linear transform method in order to generate pos-
terior samples xa
i with uniform weights wi = 1/M. The resulting estimates for
the posterior mean and variance are displayed in Figure 5.9. We note that the
results are almost identical to those displayed in Figure 5.5. This observation
should be expected since the transform method starts by deﬁning importance
weights. Hence, the results from the transform method should not be more accu-
rate than those obtained from importance sampling alone. At the same time we
note that the transform method is not degrading the results either. In Chapters
7 and 8, we will ﬁnd that samples with uniform weights are preferable when
considering the recursive application of Bayes’ theorem in the context of data
assimilation.
Problems
5.1
Consider a two-dimensional state variable z ∈R2, a linear map ψ(z) =
Az, and a linear forward operator H = (1, 0)T. Formulate the associated MLE
estimator for given NA ≥1 and given observations yobs(tk) = Hψk(z) + ξk,
ξk ∼N(0, R), k = 1, . . . , NA. Discuss necessary and suﬃcient conditions on NA
and A for the existence of a unique minimiser.
5.2
Show that the posterior median estimate ˆx, given by
 ˆx
−∞
πX(x|yobs) = 1/2,

5.3 Optimal coupling approach to Bayesian inference
157
10
6
10
5
10
4
10
3
10
2
10
1
10
3
10
2
10
1
10
0
10
1
1/M
relative error
transform sampling estimate
mean
variance
1/M1/2 reference slope
Figure 5.9 Relative errors for the
posterior mean and variance for
importance sampling combined with the
transform method. We note that the
results are essentially identical to those
displayed in Figure 5.5. The results
indicate that the transform method does
not degrade the estimates (at the same
time it cannot improve them since the
transform method is entirely based on
the prior samples xf
i and their
importance weights wi). The transform
method will turn out to be
advantageous when considering recursive
applications of Bayesian inference. See
Part II.
is indeed the minimiser with respect to the loss function ℓ(x, x′) = ∥x −x′∥.
5.3
Compute the MAP estimate for the problem described in Example 5.9 by
minimising the cost functional
L(x) = 1
2

2 −7
12x3 + 7
2x2 −8x
2
+ (x + 2)2.
Compare the steepest decent method
x(l+1) = x(l) −L′(x(l))
to Newton’s method
x(l+1) = x(l) −L′(x(l))
L′′(x(l)).
In both cases the iteration is started with x(0) = −2.
5.4
Verify that (5.8)–(5.9) are mathematically equivalent to the formulas al-
ready derived for xa and P a in Example 5.6.
5.5
Consider the linear Brownian dynamics model,
xn+1 = xn −Δτxn +
√
2Δτξn,
(5.33)
with Δτ = 0.01 and initial value x0 = 0. This model has the Gaussian distri-
bution N(0, 1) as the invariant distribution in the limit Δτ →0. Use the model
in order to generate a total of Mmax = 13000 samples xi from the Gaussian
distribution by storing every tenth iterate of (5.33). Compute empirical means
and variances and compare those with the estimates obtained from M inde-
pendent samples using a standard random number generator. Plot the resulting
approximation errors as a function of 1/M.
5.6
Implement the transform method for univariate random variables as a sub-
routine using the algorithm from Appendix 5.8. Use M, {xf
i}, and wi as inputs

158
Bayesian inference
and provide the transformed ensemble {xa
i } as output. Apply your algorithm to
Example 5.20. Prove that the algorithm does indeed solve the associated linear
transport problem.
5.7
Consider a discrete Markov chain with three possible states X = {1, 2, 3}
and transition matrix
P =
⎛
⎝
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
1/3
⎞
⎠.
What is the invariant discrete probability distribution for this Markov chain? Fol-
lowing Deﬁnition 5.15, use this discrete Markov chain to construct an MCMC
sampler ˜P for the discrete probability distribution p∗= (4/12, 3/12, 5/12). Im-
plement the MCMC sampler and verify its correctness by computing relative
frequencies of occurrence of each state ai = i, i = 1, 2, 3.
5.8
The time evolution of the marginal PDF πX(x, t) under Brownian dynamics
is characterised by the Fokker–Planck equation (5.16). A numerical discretisation
of this partial diﬀerential equation is discussed in Appendix 5.7 and leads to an
approximation of the operator eτL in (5.20) by a Markov chain.
(i)
Using Equation (5.44), show that πn
j = π∗
j for all j ∈Z is an invariant
probability vector for the Markov chain.
(ii)
Implement the discretisation (5.44) for the problem described in Example
5.25 from Appendix 5.7 but with a coarser mesh-size of Δx = 0.2 and
a total of Ngrid = 41 grid points. The time-step is Δτ = Δx2/4 = 0.1.
Compute all eigenvalues μl ∈[−1, 1] and eigenvectors vl ∈RNgrid of the
associated Markov chain PNgrid. Determine the coeﬃcients βl = (π0)Tvl,
where π0 ∈RNgrid denotes the vector representation of the prior PDF with
entries π0
k = n(xk; −1, 1/2), k = 1, . . . , Ngrid and grid points
xk =

−Ngrid −1
2
+ k −1

Δx ∈[−4, 4].
The time evolution of the initial vector π0 is then explicitly given by
πn =
Ngrid

l=1
βlvl(μl)n.
What can you conclude about the convergence to the stationary distribu-
tion?
5.4
Guide to literature
Bayesian inference and a Bayesian perspective on inverse problems are discussed,
in Kaipio & Somersalo (2005), Neal (1996), Lewis, Lakshmivarahan & Dhall
(2006), and Robert (2001), for example. A discussion of inﬁnite-dimensional
Bayesian inference problems can be found in Stuart (2010) and Tarantola (2005),

5.5 Appendix: BLUE estimator
159
for example. We point to Hastie, Tibshirani & Friedman (2009) for a discussion
of estimation and regression methods from a bias-variance perspective. Markov
chain Monte Carlo methods are covered in Liu (2001) and Robert & Casella
(2004). The two monographs Villani (2003) and Villani (2009) provide an in-
depth introduction to optimal transportation and coupling of random variables.
The link between Bayesian inference and optimal transportation is discussed
by Moselhy & Marzouk (2012), Reich (2011), and Reich & Cotter (2013). The
linear transformation method was introduced by Reich (2013b). Linear pro-
gramming/transport and algorithmic implementations are covered in Nocedal
& Wright (2006). A discussion of Brownian dynamics and its ergodic properties
can, for example, be found in Pavliotis (2014).
5.5
Appendix: BLUE estimator
We have encountered several Bayesian estimators such as the posterior mean, and
the maximum a posteriori estimator (MAP), in Deﬁnition 5.8. In this appendix,
we brieﬂy discuss another estimator which replaces the generally nonlinear con-
ditional expectation (posterior mean) ˆX = φ∗(Y ) with φ∗: RNx →RNy deﬁned
by
φ∗(y) =

RNx
xπX(x|y)dx.
We start from our familiar forward model
Y = h(X) + Ξ.
Here Ξ is assumed to be centred, i.e., E[Ξ] = 0 and independent of X.7 No
further assumptions about X and Ξ are being made. Instead we postulate a
linear estimator of the form
ˆX = AY + b,
where A ∈RNx×Ny and b ∈RNx are determined by minimising the expected
distance E[∥X −ˆX∥2]. More speciﬁcally,
E[∥X −ˆX∥2] = E[XTX] −2E[XT(AY + b)] + E[(AY + b)T(AY + b)],
and minimisation leads to
∇AE[∥X −ˆX∥2] = 2AE[Y Y T] −2E[XY T] + 2bE[Y T] = 0,
as well as
∇bE[∥X −ˆX∥2] = −2E[X] + 2b + 2AE[Y ] = 0.
The last equality implies
b = x −Ay
7 Conditional expectation for the special case Ξ ≡0 was discussed in Appendix 2.4.

160
Bayesian inference
with y = E[h(X)]. Upon substitution into the ﬁrst equation, we obtain
0 = A(E[Y Y T] −y yT) −(E[XY T] −x yT)
= APyy −Pxy,
which ﬁnally yields the estimator
ˆX = x + PxyP −1
yy (Y −y).
(5.34)
This estimator is called the best linear unbiased estimator (BLUE).
Furthermore, let Phh denote the covariance matrix of h(X) and R the covari-
ance matrix of Ξ, respectively. Since X and Ξ are assumed to be uncorrelated it
holds that
Pyy = Phh + R.
If, in addition, the forward operator is linear and h(X) = HX, then Pxy =
PxxHT, Phh = HPxxHT, and the BLUE estimator reduces to the Kalman esti-
mate (5.8) for the mean, i.e.,
ˆX = x + PxxHT(HPxxHT + R)−1(Y −Hx),
once Y is replaced by the observed value yobs = Y (ω).
Since
X −ˆX = X −x −PxyP −1
yy (Y −Hx),
the covariance matrix E[(X −ˆX)(X −ˆX)T] satisﬁes
E[(X −ˆX)(X −ˆX)T] = Pxx −2PxyP −1
yy P T
xy + PxyP −1
yy PyyP −1
yy P T
xy
= Pxx −PxxHT(HPxxHT + R)−1HPxx,
which is the Kalman update formula (5.9) for the covariance matrix in x under
a linear forward operator H.
5.6
Appendix: A geometric view on Brownian dynamics
Following Otto (2001) and Villani (2003), in this appendix we demonstrate that
certain evolution equations for PDFs, such as the diﬀusion equation and the
Fokker–Planck equation for Brownian dynamics, possess a gradient ﬂow struc-
ture. This helps to characterise their evolution towards an equilibrium state.
We ﬁrst introduce some notation.
Definition 5.21 (Diﬀerential geometric structure on manifold of probability den-
sities)
We formally introduce the manifold of all PDFs on Z = RNz
M =
<
π : RNz →R : π(z) ≥0,

RNz
π(z)dz = 1
=
,

5.6 Appendix: A geometric view on Brownian dynamics
161
with tangent space
TπM =
<
φ : RNz →R :

RNz
φ(z)dz = 0
=
.
It is a manifold rather than a vector space due to the constraint that the PDF
must be positive, and integrate to 1; neither of these properties is invariant under
linear transformations.
The variational derivative of a functional F : M →R is deﬁned as

RNz
δF
δπ φ dz = lim
ϵ→0
F(π + ϵφ) −F(π)
ϵ
,
where φ is a function such that

RNz φdz = 0, i.e., φ ∈TπM.
Consider the potential V : M →R given by
V (πZ) =

RNz
πZ ln πZdz,
(5.35)
which has variational derivative
δV
δπZ
= ln πZ,
since
V (πZ + ϵφ) = V (πZ) + ϵ

RNz
(φ ln πZ + φ)dz + O(ϵ2)
= V (πZ) + ϵ

RNz
ln πZφ dz + O(ϵ2),
having made use of the fact that φ integrates to zero. Hence we ﬁnd that the
diﬀusion part of the Fokker–Planck equation is equivalent to
∂πZ
∂t
= ∇z · (Q∇zπZ) = ∇z ·

πZQ∇z
δV
δπZ
;
.
(5.36)
Proposition 5.22 (Gradient on the manifold of probability densities)
Let gπ be
a metric tensor deﬁned on TπM as
gπ(φ1, φ2) =

RNz
(∇zψ1) · (M∇zψ2) πdz
with potentials ψi, i = 1, 2, determined by the elliptic partial diﬀerential equation
(PDE)
−∇z · (πM∇zψi) = φi,
where M ∈RNz×Nz is a symmetric, positive-deﬁnite matrix.
Then, the gradient of potential F(π) under gπ satisﬁes
gradπF(π) = −∇x ·

πM∇z
δF
δπ

.
(5.37)

162
Bayesian inference
Proof
Given the metric tensor gπ, the gradient of a functional F(π) is deﬁned
by
gπ(gradπF(π), φ) =

RNz
δF
δπ φ dz,
(5.38)
which has to hold for all φ ∈TπM. Since
φ = −∇z · (πM∇zψ1),
and
gradπF(π) = −∇z · (πM∇zψ2),
for suitable potentials ψ1 and ψ2, respectively, we need to demonstrate that
ψ2 = δF
δπ is consistent with (5.38). Indeed, we ﬁnd that

RNz
δF
δπ φ dz = −

RNz
δF
δπ ∇z · (πM∇zψ1) dz
=

RNz
π∇z
δF
δπ · (M∇xψ1) dz
=

RNz
(∇zψ2) · (M∇zψ1)π dz
= gπ(φ2, φ1) ,
with φ1 = φ and φ2 = gradπF(π).
It follows that the diﬀusion part of the Fokker–Planck equation can be viewed
as a gradient ﬂow on the manifold M. More precisely, set F(π) = V (πZ) and
M = Q to reformulate (5.36) as a gradient ﬂow
∂πZ
∂t
= −gradπZV (πZ),
with potential (5.35). We note that
dV
dt =

RNz
δV
δπZ
∂πZ
∂t dz
= −

RNz

∇z
δV
δπZ

·

Q∇z
δV
δπZ

πZ dz ≤0.
While we have considered the diﬀusion equation so far, it turns out that the
entire Fokker–Planck equation (4.26) can be viewed as a gradient system on the
manifold M of all PDFs πZ in the case of Brownian dynamics.
Proposition 5.23 (Geometric structure of Brownian dynamics)
The Fokker–
Planck equation (4.26) with f(z) = −∇zU(z) and Q = I (Brownian dynamics)
can be formulated as a gradient system
∂πZ
∂t
= −gradπZVBD(πZ),
(5.39)

5.6 Appendix: A geometric view on Brownian dynamics
163
with potential
VBD(πZ) =

RNz
πZ ln πZ dz −

RNz
πZ ln π∗
Z dz.
The canonical PDF (5.13) satisﬁes VBD(π∗
Z) = 0. Note that VBD(πZ) is equal to
the Kullback–Leibler divergence,
dKL(πZ|π∗
Z) =

RNz
πZ ln πZ
π∗
Z
dz ,
between πZ and π∗
Z.
Proof
This follows from the deﬁnition of the gradient on the manifold M of
PDFs.
There is an interesting generalisation of the implicit Euler method to gradient
ﬂows on M which we now state.
Proposition 5.24 (Implicit Euler method for geometric formulation of Brownian
dynamics)
The following abstract formulation of an implicit Euler method ap-
plied to (5.39) can be given on the manifold M of PDFs:
πZ(tn+1) = arg inf
πZ

W(πZ(tn), πZ)2 + δtVBD(πZ)

,
where W(πZ(tn), πZ) denotes the L2-Wasserstein distance between the two PDFs
πZ(z) and πZ(z, tn) and δt > 0 is the step-size.
Proof
We assume for simplicity that the solution πZ(tn+1) is obtained from
πZ(tn) through an appropriate transport map z2 = T (z1). Furthermore the
transport map shall be of the form z2 = z1+δt∇zψ(z1), where ψ is an appropriate
potential. Hence the cost functional induced by the implicit Euler approximation
can be replaced by
L[∇zψ] = W(πZ(tn), πZ)2 + δtVBD(πZ)
= δt2
2

Z
∥∇zψ∥2πZ(tn)dz + δtVBD(πZ),
with πZ given by
πZ = πZ(tn) −δt∇z · (πZ(tn)∇zψ) + O(δt2),
in terms of the potential ψ. Next we take variations with respect to ∇zψ. After
some algebra using variational derivatives, we obtain
δL
δ∇zψ = δt2πZ(tn)∇zψ + δt2πZ(tn)∇z
δVBD
δπZ
+ O(δt3).
Setting the variational derivative to zero yields
∇zψ = −∇z
δVBD
δπZ
+ O(δt),

164
Bayesian inference
and, therefore,
z2 −z1
δt
= −∇z
δVBD
δπZ
(z1) + O(δt),
(5.40)
and the desired result follows from taking the limit δt →0.
At this point, we mention another interesting link between the geometric struc-
ture on the manifold M of PDFs on Z = RNz and optimal transportation as
discussed in Chapter 2. In particular, it has been shown by Benamou & Bre-
nier (2000) that the L2-Wasserstein distance between two PDFs πZ1 ∈M and
πZ2 ∈M can be equivalently deﬁned as follows.
(i) We minimise
L[v] = 1
2
 1
0

RNz
π(z, s)∥v(z, s)∥2dzds,
(5.41)
over all velocity ﬁelds v(z, s) ∈RNz such that the associated time-
evolved PDFs π(z, s) satisfy the continuity equation
∂π
∂s = −∇z · (πv),
subject to the boundary conditions π(z, 0) = πZ1(z) and π(z, 1) =
πZ2(z).
(ii) We then set W2(πZ1, πZ2)2 = L[v∗], where v∗denotes the minimiser.
(iii) Furthermore, the optimal transport map is given as the time-one ﬂow
map of
dz
ds = v∗(z, s),
and v∗is deﬁned as the gradient of a potential.
We ﬁnally discuss an application of the formulation (5.40) in the context of en-
semble prediction methods for the underlying SDE (4.25) with f(z) = −∇zU(z).
More speciﬁcally, we introduce the alternative ensemble equations
dzi
dt = −∇z
δVBD
δπZ
(zi)
= −∇zU(zi) −
1
πZ(zi, t)∇zπZ(zi, t),
(5.42)
i = 1, . . . , M. In contrast with the SDEs (4.35), this formulation requires the
PDF πZ(z, t), which is not explicitly available in general. However, a Gaussian
approximation can be obtained from the available ensemble zi(t), i = 1, . . . , M,
using
πZ(z, t) ≈
1
(2π)Nz/2|PM|1/2 exp

−1
2(z −zM(t))TPM(t)−1(z −zM(t))

,
with empirical mean zM and empirical covariance matrix PM. Substituting this
Gaussian approximation into (5.42) as well as replacing the gradient of U by a

5.7 Appendix: Discrete Fokker–Planck equation
165
general vector ﬁeld f and the noise covariance matrix I by Q yields the ensemble
evolution equations
dzi
dt = f(zi) + QP −1
M (zi −zM),
(5.43)
which converges to the analytic solution for M →∞in the case when the vector
ﬁeld f is linear, i.e., f(z) = Az + u, and the initial PDF is Gaussian.
Note the plus sign in front of the second term in (5.43), which leads to increased
spread in the ensemble members in agreement with what diﬀusion is meant to
achieve. Switching the sign to a minus would instead drive the ensemble members
closer together.
5.7
Appendix: Discrete Fokker–Planck equation
In this appendix, we explore the convergence to equilibrium of Brownian dy-
namics, through numerical experiments and in the one-dimensional case. We
will do this by studying the convergence to equilibrium of the corresponding
Fokker–Planck equation, directly approximating the densities using ﬁnite diﬀer-
ences in phase space. In the language of Chapter 3, this is equivalent to using
a deterministic quadrature rule in phase space, rather than using Monte Carlo
approximation.
We formulate an appropriate ﬁnite-dimensional approximation to the operator
eτL in (5.20) for given step-size τ = Δτ (which will also allow us to estimate
the constant c in the spectral estimate (5.19)). In particular, we start from the
Fokker–Planck formulation (5.16) and introduce a space-time grid (xj, τn) =
(jΔx, nΔτ) for n ≥0 and j ∈Z. The associated grid values π∗
X(xj) are denoted
by π∗
j and the numerical approximations to πX(xj, τn) by πn
j . A straightforward
generalisation of the standard central diﬀerence approximation for the diﬀusion
equation results in
πn+1
j
−πn
j
Δτ
=
π∗
j+1/2
& πn
j+1
π∗
j+1 −
πn
j
π∗
j
'
−π∗
j−1/2
& πn
j
π∗
j −
πn
j
1
π∗
j
1
'
Δx2
,
(5.44)
with π∗
j±1/2 = π∗
X(xj±1/2). We next write this scheme in discrete Markov chain
form (recall Deﬁnition 4.14 from Chapter 4 and formally set πn
i = pn(i)), and
use the recurrence
πn+1
j
= pj,j+1πn
j+1 + pj,jπn
j + pj,j−1πn
j−1,
with transition probabilities
pj,j = 1 −Δτ
Δx2
π∗
j+1/2 + π∗
j−1/2
π∗
j
,
pj,j±1 = Δτ
Δx2
π∗
j±1/2
π∗
j±1
.
These probabilities sum to one, i.e. 
i∈Z pi,j = 1, as required, and are all non-

166
Bayesian inference
negative provided
Δτ ≤
Δx2π∗
j
π∗
j+1/2 + π∗
j−1/2
.
Upon formally deﬁning inﬁnite-dimensional probability vectors πn = {πn
j }j∈Z,
n ≥0, we rewrite this approximation in the discrete Markov chain formulation
πn+1 = Pπn,
where P denotes the transition operator with entries pi,j and i, j ∈Z.
So far we have considered a discrete grid with an inﬁnite number of grid
points. To compute the eigenvectors and eigenvalues on a computer, we need
to further approximate the problem by restricting the grid to a ﬁnite domain
|j| ≤(Ngrid−1)/2 for odd Ngrid > 0. Furthermore, to guarantee accurate results,
Ngrid must be chosen suﬃciently large that the solution to the inﬁnite domain
problem has almost no probability outside the ﬁnite domain. In order to obtain
a ﬁnite-dimensional transition matrix PNgrid ∈RNgrid×Ngrid we introduce indices
l, k ∈{1, . . . , Ngrid} via
l = j + 1
2(Ngrid + 1),
|j| ≤1
2(Ngrid −1),
and
k = i + 1
2(Ngrid + 1),
|i| ≤1
2(Ngrid −1),
respectively. The entries of PNgrid are denoted by pk,l and are related to the
entries of P by pk,l = pi,j. Since we also wish the resulting ﬁnite-dimensional
matrix PNgrid to deﬁne a Markov chain we need to enforce that
Ngrid

l=1
pl,k = 1,
for all k = 1, . . . , Ngrid. This is achieved by redeﬁning the ﬁrst and last diagonal
entries in PNgrid by
p1,1 = 1 −p2,1,
pNgrid,Ngrid = 1 −pNgrid−1,Ngrid.
The matrix PNgrid provides an approximation to the propagator eΔτL. All eigen-
values of PNgrid are contained in the unit disc {λ ∈C : |λ| ≤1} of the complex
plane and invariant distributions have eigenvalue one.
These ideas are made more concrete in the following example.
Example 5.25
Consider the Gaussian prior πX(x) = n(x; −1, 1/2), the likeli-
hood
πY (y|x) = n(y; x, 1),
and an observed yobs = 1. The resulting posterior PDF is then πX(x|yobs) =

5.7 Appendix: Discrete Fokker–Planck equation
167
3
2
1
0
1
2
0
0.5
1
space
evolved prior PDF at time τ = 0.05
3
2
1
0
1
2
0
0.5
1
space
evolved prior PDF at time τ = 0.5
evolved prior
posterior
evolved prior
posterior
Figure 5.10 Time evolution of the PDF under a Fokker–Planck equation with initial
condition equal to the prior PDF and the posterior PDF as the stationary PDF. The
time-evolved PDF is close to the stationary PDF at τ = 0.5.
n(x; −1/3, 1/3). The associated Brownian dynamics model is therefore
dX = −1
3

x + 1
3

dt +
√
2dW
and c = 3 in (5.19). Instead of simulating Brownian dynamics, we implement the
ﬁnite diﬀerence approximation (5.44) with π∗
X given by the posterior distribution
πX(x|yobs). The mesh-size is Δx = 0.05, the number of grid points is Ngrid = 161,
and the step-size is Δτ = 6.25 ×10−4. The eigenvalues of the associated Fokker–
Planck operator L can be approximated by computing the eigenvalues of PNgrid,
taking their logarithm and ﬁnally dividing by Δτ. We ﬁnd that PNgrid has a
single eigenvalue equal to one, and that applying this procedure to the next
largest eigenvalue μ gives λ := Δτ −1 ln μ ≈−3.00. This eigenvalue determines
the time-scale on which an initial PDF will approach the stationary posterior
PDF; it agrees with the theoretical bound provided by (5.19). We demonstrate
the approach to the stationary posterior distribution by starting from the prior
distribution at τ = 0 and display the evolved PDFs at time τ = 0.05 and τ = 0.5
in Figure 5.10. Note that e0.05λ ≈0.8607 and e0.5λ ≈0.2231. The time-scale of
1/λ determines the decorrelation time of a Monte Carlo sampling method based
on the associated Brownian dynamics formulation (5.18).

168
Bayesian inference
5.8
Appendix: Linear transport algorithm in one dimension
The linear transport problem of ﬁnding the optimal transport matrix T ∗in the
case of samples {xf
i} from a univariate random variable can be solved eﬃciently
by the following algorithm. The key observation is that scalar samples xf
i can be
sorted such that xf
1 ≤xf
2 ≤· · · ≤xf
M.
The algorithm is described in the following pseudocode.
SORT SCALAR SAMPLES xf IN ASCENDING ORDER
COMPUTE ARRAY OF IMPORTANCE WEIGHTS w
FOR i = 1 : M
w0(i) = 1 / M
END
i = M
j = M
WHILE i * j >= 1
IF w(i) < w0(j)
t(i,j) = w(i)
w0(j) = w0(j) - w(i)
i = i - 1
ELSE
t(i,j) = w0(j)
w(i) = w(i) - w0(j)
j = j - 1
END
END

Part II
Bayesian Data Assimilation


6
Basic data assimilation algorithms
In this chapter, we return to the state estimation problem for dynamical sys-
tems as initially raised in Chapter 1. However, in contrast to Chapter 1, data
assimilation algorithms will be based on a probabilistic interpretation of model-
based forecasts in addition to measurement processes. Hence state estimation
from partial and noisy observations can be put into the framework of Bayesian
inference with model-based forecast uncertainties taking the role of prior distri-
butions. Most of the mathematical ingredients have already been provided in the
previous chapters. The goal of this chapter is to provide a concise mathematical
formulation of the state estimation problem and to derive the Kalman ﬁlter for
linear dynamical systems and Gaussian random variables on the one hand, and
particle ﬁlters (also called sequential Monte Carlo methods) for general nonlin-
ear dynamical systems and non-Gaussian distributions on the other. We will also
touch upon variational data assimilation techniques as a natural link between
the method of least squares, as considered in Chapter 1, and the assimilation
techniques to be discussed in the remainder of this book. Applications of state
estimation include, for example, weather forecasting, robotics, tracking using the
global positioning system (GPS), and econometrics. In each of these cases partial
and noisy observations are used in conjunction with a dynamical model in order
to forecast future events. It is also often necessary to quantify forecast uncer-
tainties; this is essential for taking decisions and/or for controlling the system
under consideration.
In order to provide the necessary mathematical framework, we assume a model
in the form of a stochastic diﬀerence equation
Zn+1 = Zn + δtf(Zn) +
√
2δt Ξn,
tn+1 = tn + δt,
(6.1)
where Ξn : Ω →RNz are independent and identically distributed Gaussian
random variables with mean zero and covariance matrix Q, δt > 0 is a given
step-size, and f : RNz →RNz is a given vector ﬁeld. We also assume that
the marginal distribution πZ(z, 0) for Z0 is given. This marginal distribution
characterises our uncertainty about the initial state of our model at time t = 0.
Recall that the time evolution of the marginal PDFs πZ(z, tn) (n ≥1) under
(6.1) is given recursively by the Chapman–Kolmogorov equation,
πZ(z′, tn+1) =

RNz
π(z′|z)πZ(z, tn)dz,

172
Basic data assimilation algorithms
with transition kernel (conditional PDF)
π(z′|z) =
1
(4πδt)Nz/2|Q|1/2
× exp

−1
4δt(z′ −z −δtf(z))TQ−1(z′ −z −δtf(z))

.
In addition to the stochastic dynamical model (6.1) and its initial PDF, we
assume that noisy partial observations
yobs(tk) ∈RNy,
tk = kΔtout,
k = 1, 2, . . .,
become available in regular time intervals of width Δtout > 0. We also assume
that these observations are related to the unknown reference trajectory zref(t)
of the dynamical model (6.1) by
Y k = h(zref(tk), tk) + Σk,
(6.2)
i.e., yobs(tk) = h(zref(tk), tk) + Σk(ω), where Σk denotes a Gaussian random
variable with mean zero and covariance matrix R and h(·, tk) : RNz →RNy is
the forward operator at observation time tk. The conditional PDF for Yk given
a state z is therefore given by
πY (y|z, tk) =
1
(2π)Ny/2|R|1/2 exp

−1
2(y −h(z, tk))TR−1(y −h(z, tk))

. (6.3)
We ﬁnally assume that the measurement errors, as represented by Σk, are mutu-
ally independent. The desired zref(tn) is obtained from (6.1) with generally un-
known initial condition zref(0) at t = 0 and unknown realisations ξn = Ξn(ωref).
In other words, we view the unknown zref(tn) as a particular realisation Zn(ωref),
n ≥0, of the stochastic dynamical model (6.1). We call this scenario the per-
fect model scenario since the surrogate physical process and our mathematical
forecasts use the same mathematical model. Data assimilation is used to infer
information about zref(tn) from the inﬁnitely many possible realisations of a
stochastic dynamical system (6.1), constrained only by the initial PDF πZ(z, t0)
and partial observations yobs(tk), to produce an estimate ˆz(tn) such that ˆz(tn) is
close to zref(tn) under an appropriate norm. It is also often necessary to quantify
the uncertainty in the estimated states explicitly.
We distinguish three possible scenarios for obtaining such an estimate and its
uncertainty in terms of probability densities.
Definition 6.1 (Prediction, ﬁltering and smoothing)
In the case where there are
no observations available, our knowledge about a process zref(t) is encoded in
the marginal PDFs πZ(z, tn) for Zn. When we are given observations yobs(tk),
k = 1, . . . , Nobs, collected in an Ny × Nobs matrix
yobs
t1 Nobs = (yobs(t1), yobs(t2), . . . , yobs(tNobs)) ∈RNy×Nobs,
our knowledge is encoded in the conditional, marginal PDFs πZ(z, tn|yobs
t1 Nobs ) for

Basic data assimilation algorithms
173
Zn|yobs
t1 Nobs. The task of calculating these PDFs takes one of the following three
names:
(i) prediction if tn > tNobs,
(ii) ﬁltering if tn = tNobs, and
(iii) smoothing if tn < tNobs.
In each of the three cases, an estimate ˆz(tn) can be obtained by using an appro-
priate Bayesian estimate as introduced in (5.8).1
The Kalman and particle ﬁlters are, as their names indicate, primarily re-
lated to the ﬁltering problem, while variational data assimilation is equivalent
to solving a smoothing problem with tn = 0.
We continue with a closer inspection of the ﬁltering problem and derive re-
cursive representations of the conditional, marginal PDFs πZ(z, tk|yobs
t1 k) for k =
1, . . . , Nobs. Let us assume, for simplicity, that
Δtout = Noutδt,
in which case the Nout-fold application of the Chapman–Kolmogorov equation
leads from the initial PDF πZ(z, 0) at t = 0 to
πZ(z′, t1) =

RNz
πNout(z′|z)πZ(z, 0)dz,
with the transition kernel πNout(z′|z) appropriately deﬁned (see Equation (4.33)).
Suppose an observation yobs(t1) is available at t1; then the ﬁltering problem with
Nobs = 1 is solved via Bayes’ theorem by
πZ(z, t1|yobs
t1 1) =
πY (yobs(t1)|z, t1) πZ(z, t1)

RNz πY (yobs(t1)|z, t1) πZ(z, t1) dz ,
with
πY (y|z, t1) =
1
(2π)Ny/2|R|1/2 exp

−1
2(y −h(z, t1))TR−1(y −h(z, t1))

.
Furthermore, the prediction problem with tn > t1, conditioned on having ob-
served yobs(t1), can again be solved by applying the Chapman–Kolmogorov equa-
tion. We obtain, in particular,
πZ(z′, t2|yobs
t1 1) =

RNz
πNout(z′|z)πZ(z, t1|yobs
t1 1)dz,
for n = 2Nout, i.e., tn = t2. If we now set Nobs = 2 in Deﬁnition 6.1, then
the associated ﬁltering problem is solved by yet another application of Bayes’
formula:
πZ(z, t2|yobs
t1 2) =
πY (yobs(t2)|z, t2) πZ(z, t2|yobs
t1 1)

RNz πY (yobs(t2)|z, t2) πZ(z, t2|yobs
t1 1) dz .
1 These estimates are themselves realisations of random variables ˆZ(tn) which are
conditioned on the sequence of random observations yobs
t1 Nobs = Yt1 Nobs (ω) with
Yt1 Nobs := (Y (t1), . . . , Y (tNobs)). See Chapter 9 for more details.

174
Basic data assimilation algorithms
These steps can be repeated recursively to solve the ﬁltering problem from
Deﬁnition 6.1 for any Nobs ≥1. More precisely, given the conditional PDF
πZ(z, tk−1|yobs
t1 k
1) for the ﬁltering problem at t = tk−1, the Chapman–Kolmog-
orov equation
πZ(z, tk|yobs
t1 k
1) =

RNz
πNout(z|z′)πZ(z′, tk−1|yobs
t1 k
1)dz′,
(6.4)
yields the marginal PDF for the prediction problem at t = tk conditioned on hav-
ing observed yobs
t1 k
1. This marginal PDF is then used as a prior for assimilating
an observation yobs(tk) via Bayes’ theorem
πZ(z, tk|yobs
t1 k) =
πY (yobs(tk)|z, tk) πZ(z, tk|yobs
t1 k
1)

RNz πY (yobs(tk)|z, tk) πZ(z, tk|yobs
t1 k
1) dz ,
(6.5)
which solves the ﬁltering problem for t = tk.
We summarise the recursive approach to sequential data assimilation in the
following deﬁnition.
Definition 6.2 (Sequential data assimilation)
Given a stochastic dynamical
system (6.1) with initial PDF π(z, 0) and observations yobs(t) for t = t1, . . . , tNobs
in observation intervals of Δtout = Noutδt, Nout ≥1, and forward model (6.2),
the marginal ﬁltering distributions πZ(z, tk|yobs
t1 k), k = 1, . . . , Nobs, are recursively
deﬁned by ﬁrst solving the prediction problem (6.4) followed by the Bayesian
assimilation step (6.5).
An important remark has to be made at this point. Sequential data assim-
ilation, as stated above, provides us with a sequence of marginal ﬁltering dis-
tributions πZ(z, tk|yobs
t1 k) for conditioned random variables ˜Z(tk) := Z(tk)|yobs
t1 k,
k = 1, . . . , Nobs. However, it does not specify joint distributions π ˜Zt0 k (˜zt0 k|yobs
t1 k)
for the family of conditioned random variables
˜Zt0 k = ( ˜Z(t0), ˜Z(t1), . . . , ˜Z(tk)).
In particular, nothing is being said about mutual dependencies amongst ˜Z(tk1)
and ˜Z(tk2) for k1 ̸= k2. In order to deﬁne such families of random variables and
their joint distributions we need to employ the concept of coupling as introduced
in Chapter 2. This will be the subject of Chapter 7, allowing us to give the families
˜Zt0 k an interpretation in terms of Markov processes, which is at the heart of
the McKean approach to data assimilation. In this chapter, we continue with
a traditional discussion of the ﬁltering problem purely at the level of marginal
PDFs.
In order to simplify the subsequent discussions, we assume from now on that
the forward operator h in (6.2) does not explicitly depend on time and the
associated conditional PDF (6.3) simpliﬁes to
πY (y|z) =
1
(2π)Ny/2|R|1/2 exp

−1
2(y −h(z))TR−1(y −h(z))

.

6.1 Kalman ﬁlter for linear model systems
175
6.1
Kalman ﬁlter for linear model systems
There is a particular case for which the sequential ﬁltering formulation from
the previous section can be implemented algorithmically in closed form; namely
when the initial PDF is Gaussian, the evolution model is linear,
Zn+1 = Zn + δt(DZn + b) +
√
2δtΞn,
(6.6)
and the forward model is also linear,
Y k = Hzref(tk) + Σk.
Here H ∈RNy×Nz, D ∈RNz×Nz and b ∈RNz denote constant matrices and a
constant vector, respectively. The random variables Ξn and Σk are independent
and Gaussian with mean zero and covariance matrices Q and R, respectively.
As we have already discussed in Example 4.6, a Gaussian random variable re-
mains Gaussian under linear transformations, and a linear transformation can be
found to link any two Gaussian random variables provided that their variances
have the same rank. We also know that if both the prior and the likelihood are
Gaussian, then so is the posterior, as discussed in Chapter 5. Hence we only
need to keep track of the mean z and the covariance matrix P of the associated
Gaussian distributions N(z, P). Following standard notation from meteorology,
we denote variables arising from a prediction step by superscript “f” (forecast)
and those arising from the assimilation of data via Bayes’ theorem by superscript
“a” (analysis). In order to simplify notation we also introduce the shorthand
zf
k = zf(tk),
za
k = za(tk),
P f
k = P f(tk),
P a
k = P a(tk).
Hence we are dealing with sequences of Gaussian distributions
π(z, tk|yobs
t1 k
1) = n(z; zf
k, P f
k),
π(z, tk|yobs
t1 k) = n(z; za
k, P a
k ),
in terms of given mean vectors and covariance matrices.
We now derive explicit recursive formulas for these mean vectors and covari-
ance matrices. Upon recalling Example 4.6, we ﬁnd that a single propagation
step under the linear model leads to the update
zn+1 = [I + δtD]zn + δtb,
(6.7)
for the mean, and the update
P n+1 = [I + δtD]P n[I + δtD]T + 2δtQ,
(6.8)
for the covariance matrix, where Q is the covariance matrix of the stochastic
forcing terms Ξn. Here we have also made use of the facts that E[Ξn] = 0, and
Ξn and Zn are uncorrelated.
The update step is repeated Nout times to propagate the mean and the co-
variance matrix over a time interval Δtout = δtNout. This results in an explicit

176
Basic data assimilation algorithms
transformation of the analysis pair (za(tk−1), P a(tk−1)) into the forecast pair
(zf(tk), P f(tk)), given by
zf(tk) = [I + δtD]Noutza(tk−1) + δt
Nout

i=1
[I + δtD]i−1b,
and
P f(tk) = [I + δtD]NoutP a(tk−1)([I + δtD]Nout)T
+ 2δt
Nout

i=1
[I + δtD]i−1Q([I + δtD]i−1)T.
We now analyse the Bayesian assimilation step in more detail. Recall the
general formulas from Example 5.6 in Chapter 5. Applied to our situation with
an appropriate identiﬁcation of symbols (i.e., b := 0, A := H, P := P f
k, x := zf
k,
P a := P a
k , xa := za
k, and yobs := yobs(tk)), we obtain
(P a
k )−1 = (P f
k)−1 + HTR−1H,
and
za
k = zf
k −P a
k HTR−1(Hzf
k −yobs(tk)).
We now employ the Sherman–Morrison–Woodbury matrix inversion formula (see
Golub & Loan (1996)),
(M + U TNU)−1 = M −1 −M −1U T(N −1 + UM −1U T)−1UM −1,
(6.9)
with M = (P f
k)−1, U = H and N = R−1 to reformulate the covariance matrix
update as
P a
k = P f
k −P f
kHT(R + HP f
kHT)−1HP f
k
= P f
k −KHP f
k,
with Kalman gain matrix
K = P f
kHT(R + HP f
kHT)−1.
Using the Kalman gain matrix, the update for the mean can also be reformulated
as
za
k = zf
k −K(Hzf
k −yobs(tk)),
since
(P f
k −KHP f
k)HTR−1 = P f
kHT[I −(HP f
kHT + R)−1HP f
kHT]R−1
= P f
kHT(R + HP f
kHT)−1.
See also formulas (5.8) and (5.9) from Example 5.10 in Chapter 5.
After collecting all of these formulas, we have derived the celebrated Kalman
ﬁlter.

6.1 Kalman ﬁlter for linear model systems
177
Algorithm 6.3 (Kalman Filter)
Given a mean za
0 and a covariance matrix P a
0 at
time t = 0 and a sequence of observations yobs(tk) with error covariance matrix
R, tk = kΔtout and observation interval Δtout = δtNout, the following sequence
of steps is performed for k ≥1.
(i) Set z0 := za
k−1, P 0 := P a
k−1 and iteratively determine zn+1 and P n+1 for
n = 0, . . . , Nout −1 via
zn+1 = [I + δtD]zn + δtb,
(6.10)
P n+1 = [I + δtD]P n[I + δtD]T + 2δtQ.
(6.11)
Set zf
k := zNout and P f
k := P Nout.
(ii) Compute the Kalman gain matrix
K = P f
kHT(R + HP f
kHT)−1,
and update the mean and covariance matrix according to
za
k := zf
k −K(Hzf
k −yobs(tk)),
(6.12)
P a
k := P f
k −KHP f
k.
(6.13)
The performance of the Kalman ﬁlter is now demonstrated for a one-dimen-
sional example.
Example 6.4
Consider the scalar stochastic diﬀerence equation
Zn+1 = Zn + δtdZn + δtb +
√
2δtΞn
(6.14)
with d = −0.1, b = 1, Ξn ∼N(0, 1), and δt = 0.01. The initial condition has
probability distribution Z0 ∼N(10, 2). Observations are given in intervals of
Δtout = 0.05 (i.e., Nout = 5), the forward operator is H = 1, and the measure-
ment error has distribution N(0, 1). The reference trajectory zref(t) is generated
from the same model (6.14) with initial condition zref(0) = 10. This setting cor-
responds to the perfect model scenario. A simple inspection of the Kalman ﬁlter
equations for the variances reveals that they are independent of the actual ob-
servations and, indeed, we ﬁnd that the analysis and forecast variances quickly
converge to stationary values P a
∗≈0.2666 and P f
∗≈0.3636, respectively (see the
right panel in Figure 6.1, where we also display the analysis means za
k and the
observed values yobs(tk)). As an immediate consequence the Kalman gain matrix
also becomes stationary with K ≈0.2666.
We now investigate an imperfect model scenario, which is more relevant for
practical applications. Here we make the model “imperfect” by choosing that the
trajectory zref(t) is still obtained from (6.14) with d = −0.1 while the Kalman
ﬁlter implementation is based on d = −0.5. All other parameters are as speciﬁed
before (but could have been modiﬁed as well). The imperfect model scenario can
be recognised from the fact that about 73% of the observed values yobs(tk) are
larger than the analysis za
k, conﬁrming that the model (6.14) is no longer cali-
brated. The diﬀerence between the perfect and the imperfect model scenario can

178
Basic data assimilation algorithms
0
2
4
6
8
10
0
2
4
6
8
10
12
14
16
18
20
time
state variable z
Kalman filter (perfect model)
analysis mean
observation
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
time
variance
Kalman filter (perfect model)
Figure 6.1 Top panel: analysis za
k and observed values yobs(tk) for the Kalman ﬁlter
under the perfect model scenario. Here “perfect” refers to the fact that the reference
solution is generated from the same model that is used for ﬁltering. Bottom panel: time
evolution of the analysis variances. A rapid convergence to a stationary value can be
observed.
be assessed in terms of time averaged root mean square error (RMSE), and the
averaged continuously ranked probability score (ACRPS), as deﬁned in Chapter
4. A long simulation over Nobs = 108 observations reveals that the perfect model
scenario leads to slightly better scores (imperfect model, time averaged RMSE =
0.7692; perfect model, time averaged RMSE = 0.5162; imperfect model, ACRPS

6.2 Variational data assimilation
179
= 0.6345; perfect model, ACRPS = 0.4118). The asymptotic value for the anal-
ysis variances is slightly reduced for the imperfect model scenario (imperfect
model, P a
∗= 0.2530; perfect model P a
∗= 0.2666). See Figure 6.2. It should be
noted that the perfect/imperfect model experiments are based on one and the
same set of observations yobs(tk). In summary, we ﬁnd that the performance of
the Kalman ﬁlter is quite robust with respect to the change in d in (6.14).
6.2
Variational data assimilation
In Chapter 1, a nonlinear method of least squares was used to estimate model
states from observations. This was a particular instance of a variational data as-
similation technique; such techniques are based on minimising appropriate cost
functionals subject to model constraints. In this section, a connection will be
established between the Kalman ﬁlter and a variational data assimilation tech-
nique called four-dimensional variational data assimilation (4DVar). The name
4DVar arose in meteorology since the models are partial diﬀerential equations in
three spatial dimensions and one temporal dimension: this is mostly not the case
in this book since we concentrate on ﬁnite-dimensional examples. Nonetheless,
we will use the term 4DVar to emphasise the time dimension.
It is assumed throughout this section that the stochastic model perturbations
Ξn vanish, i.e., the model error covariance matrix is Q = 0. We also set b = 0 for
notational convenience. The Nout-fold application of the model dynamics (6.1)
can therefore be reduced to
z(tk) = Ψz(tk−1),
Ψ := (I + δtD)Nout ∈RNz×Nz,
and the Kalman ﬁlter equations are reformulated as follows. For k = 1, . . . , Nobs
deﬁne
zf
k = Ψza
k−1,
(6.15)
P f
k = ΨP a
k−1ΨT,
(6.16)
(P a
k )−1 = (P f
k)−1 + HTR−1H,
(6.17)
za
k = zf
k −P a
k HTR−1(Hzf
k −yobs(tk)),
(6.18)
recursively from given initial mean za
0, initial covariance matrix P a
0 , and a se-
quence of observations yobs(tk), k = 1, . . . , Nobs.
In this section, we demonstrate that variational data assimilation is closely
related to the smoothing problem: determine the marginal distribution at t0 = 0
from observations at tk, k = 1, . . . , Nobs. These marginal distributions are again
Gaussian under the assumptions stated (linear model and initial Gaussian) and
we introduce the notation
πZ(z, t0|yobs
t1 k) = n(z; zs
0:k, P s
0:k)
(6.19)

180
Basic data assimilation algorithms
0
2
4
6
8
10
0
2
4
6
8
10
12
14
16
18
20
time
state variable z
Kalman filter (imperfect model)
analysis mean
observation
0
0.5
1
1.5
2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
time
variance
Kalman filter (imperfect model)
Figure 6.2 We repeat the experiment from Figure 6.1 but with the Kalman ﬁlter being
implemented for a modiﬁed model with d = −0.5 instead of d = −0.1. The Kalman ﬁlter
is still able to track the reference solution and only a careful analysis of the time series
reveals a diﬀerence between the imperfect and the perfect model scenarios. For example,
we notice that more observations are located above the analysis in the plot on the top,
showing that the model is no longer calibrated.
in terms of the involved mean vectors zs
0:k and covariance matrices P s
0:k.
In order to introduce 4DVar, we ﬁrst demonstrate that za
1, as determined by

6.2 Variational data assimilation
181
(6.18) with k = 1, is also the minimiser of the functional
˜L(z′) = 1
2(z′ −zf
1)T(P f
1)−1(z′ −zf
1)
+ 1
2(Hz′ −yobs(t1))TR−1(Hz′ −yobs(t1)).
(6.20)
Indeed, we ﬁnd that
∇z ˜L(z′) = (P f
1)−1(z′ −zf
1) + HTR−1(Hz′ −yobs(t1)),
and the condition ∇z ˜L(za
1) = 0 leads to
9
(P f
1)−1 + HTR−1H
:
za
1 = (P f
1)−1zf
1 + HTR−1yobs(t1).
Since
P a
k (P f
k)−1 =
9
(P f
k)−1 + HTR−1H
:−1 (P f
k)−1
= I −
9
(P f
k)−1 + HTR−1H
:−1 HTR−1H
= I −P a
k HTR−1H,
the desired (6.18) follows for k = 1. It also follows that the marginal ﬁltering
distribution at t1 is given by
π(z′, t1|yobs
t1 1) ∝e−˜L(z′).
Upon introducing z = Ψ−1z′, we can rewrite (6.20) as
L(z) := 1
2(Ψz −zf
1)T(P f
1)−1(Ψz −zf
1)
+ 1
2(HΨz −yobs(t1))TR−1(HΨz −yobs(t1))
= 1
2(z −za
0)T(P a
0 )−1(z −za
0) + 1
2(HΨz −yobs(t1))TR−1(HΨz −yobs(t1)).
The associated PDF
π(z, t0|yobs
t1 1) ∝e−L(z),
(6.21)
solves the smoothing problem at time t0 = 0 with data given up to t1. If we
denote the minimiser of L by zs
0:1, then we have zs
0:1 = Ψ−1za
1, by deﬁnition.
Hence it follows from our discussion that we can ﬁrst solve the ﬁltering problem
up to t1, and then apply the inverse operator Ψ−1 to obtain the mean zs
0:1 of the
smoothing problem. Furthermore, the Hessian matrix H of second derivatives of
L(z) with respect to z is
H = (P a
0 )−1 + ΨTHTR−1HΨ = ΨT((P f
1)−1 + HTR−1H)Ψ = ΨT(P a
1 )−1Ψ.
The Hessian is equivalent to the inverse of the smoother covariance matrix at t0,
i.e.,
P s
0:1 := H−1 = Ψ−1P a
1 Ψ−T.

182
Basic data assimilation algorithms
Hence L(z) can equivalently be written as
L(z) = 1
2(z −zs
0:1)T(P s
0:1)−1(z −zs
0:1) ,
in agreement with (6.21) and (6.19).
This statement can actually be generalised to k > 1 and leads to the cost
functional
L(z) = 1
2(z −za
0)T(P a
0 )−1(z −za
0)
+ 1
2
Nobs

k=1
(HΨkz −yobs(tk))TR−1(HΨkz −yobs(tk)),
(6.22)
for the smoothing problem at t0 = 0 with data up to tNobs. The corresponding
mean, xs
0:Nobs, is determined by
∇zL(zs
0:Nobs) = 0.
This is, in fact, the linear variant of 4DVar. In this linear setting without stochas-
tic model contributions, our discussion suggests that 4DVar is equivalent to ﬁrst
running a Kalman ﬁlter up to tNobs resulting in za
Nobs, then applying the inverse
dynamic operator Ψ−1 Nobs-times to obtain
zs
0:Nobs = Ψ−Nobsza
Nobs.
Similarly, we obtain the smoothing covariance matrix
P s
0:Nobs = Ψ−NobsP a
Nobs(Ψ−Nobs)T.
Proposition 6.5 (Variational formulation of the optimal state estimation)
Let the
analysis random variable Za
0 have mean za
0 and covariance matrix P a
0 at time t0 =
0. Assume that a sequence of observations yobs(tk), with k = 1, . . . , Nobs is given.
We also assume deterministic model dynamics and deﬁne Ψ := (I + δtD)Nout ∈
RNz×Nz . Finding the analysis mean za
Nobs from the associated Kalman ﬁltering
problem is then equivalent to minimising (6.22) with respect to z, denoting the
minimiser by zs
0:Nobs, and setting
za
Nobs = ΨNobszs
0:Nobs.
The associated analysis covariance matrix is determined by
P a
Nobs = ΨNobsH−1(ΨNobs)T,
where H ∈RNz×Nz is the Hessian matrix of second partial derivatives of L with
respect to z given by
H = (P a
0 )−1 +
Nobs

k=1
(Ψk)THTR−1HΨk.

6.2 Variational data assimilation
183
Proof
We have already shown the validity of the result for Nobs = 1. The case
Nobs = 2 follows from
L(z) = 1
2(z −za
0)T(P a
0 )−1(z −za
0)
+ 1
2
2

k=1
(HΨkz −yobs(tk))TR−1(HΨkz −yobs(tk))
= 1
2(z −zs
0:1)T(P s
0:1)−1(z −zs
0:1)
+ 1
2(HΨ2z −yobs(t2))TR−1(HΨ2z −yobs(t2)),
with zs
0:1 = Ψ−1za
1 and P s
0:1 = Ψ−1P a
1 Ψ−T. We next introduce z′ = Ψ2z and
note that L(z) becomes equivalent to
˜L(z′) = 1
2(Ψ−2z′ −zs
0:1)T(P s
0:1)−1(Ψ−2z′ −zs
0:1)
+ 1
2(Hz′ −yobs(t2))TR−1(Hz′ −yobs(t2))
= 1
2(z′ −zf
2)T(P f
2)−1(z′ −zf
2) + 1
2(Hz′ −yobs(t2))TR−1(Hz′ −yobs(t2))
= 1
2(z′ −za
2)T(P a
2 )−1(z′ −za
2)
following arguments previously made for the case Nobs = 1. The desired result
for Nobs = 2 follows from
L(z) = 1
2(z −Ψ−2za
2)T(Ψ2)T(P a
2 )−1Ψ2(z −Ψ−2za
2)
= 1
2(z −zs
0:2)T(P s
0:2)−1(z −zs
0:2).
This argument can recursively be generalised to any Nobs > 2.
Hence we may view the marginal smoothing PDF,
πZ(z, t0|yobs
t1 Nobs ) ∝e−L(z),
as the posterior distribution at t0 = 0 corresponding to the Gaussian prior
N(za
0, P a
0 ) and the compound likelihood function
πYt1 Nobs (yt1 Nobs |z) ∝
Nobs
1
k=1
e−1
2 (HΨkz−y(tk))TR
1(HΨkz−y(tk)).
Therefore zs
0:Nobs is the mean of the posterior PDF πZ(z, t0|yobs
t1 Nobs), or equiva-
lently, the associated MAP estimator (see Deﬁnition 5.8)
This reformulation of the smoothing problem allows for a generalisation to
nonlinear dynamical systems of type
zn+1 = zn + δtf(zn),
(6.23)
as considered in Chapters 1 and 4. If Δtout = δtNout (as assumed before), then

184
Basic data assimilation algorithms
we deﬁne the map ψ as the result of an Nout-fold application of (6.23) and
formally introduce the iteration
zk+1 = ψ(zk),
(6.24)
in order to describe the model dynamics in between observations. Again, we have
assumed that stochastic contributions to the model dynamics can be ignored,
e.g., ψ could correspond to any deterministic dynamical system considered in
Chapter 4.
Definition 6.6 (Four-dimensional variational data assimilation (4DVar))
Let a
mean za
0 and a covariance matrix P a
0 at time t = 0 be given as well as a sequence
of observations yobs(tk) with k = 1, . . . , Nobs. The model dynamics in between
observations is described by (6.24). Then the smoothing distribution at t0 = 0
is given by
πZ(z, t0|yobs
t1 Nobs) ∝e−1
2 (z−za
0)T(P a
0 )
1(z−za
0) πYt1 Nobs (yobs
t1 Nobs|z),
up to a normalisation constant independent of z. The associated MAP estimator,
denoted by ˆzs
0:Nobs, is the minimiser of the functional L(z) deﬁned by
L(z) = 1
2(z −za
0)T(P a
0 )−1(z −za
0)
+ 1
2
Nobs

k=1
(Hψk(z) −yobs(tk))TR−1(Hψk(z) −yobs(tk)).
(6.25)
The associated ˆza
Nobs = ψNobs(ˆzs
0:Nobs) provides the MAP estimator at the end
of the observation interval tNobs. The process of obtaining the MAP estimator is
called 4DVar. Recall that the MAP estimator is equivalent to the posterior mean
zs
0:Nobs if the smoothing distribution is Gaussian. However, the MAP estimator
and the posterior mean take diﬀerent values in general.
Instead of applying 4DVar to a complete set of observations, we can also apply
4DVar recursively to patches of observations from intervals
[0, tNA],
[tNA, t2NA],
. . .
with the integer NA chosen appropriately (compare with Example 1.8). In this re-
cursive setting, we often assume a ﬁxed background covariance matrix B instead
of an observation adjusted (P a
0 ), (P a
NA), etc. Furthermore, the MAP estimator at
the end of the last patch is used as the background mean in the cost functional
for the next patch. Consider, for example, the second patch over the interval
[tNA, t2NA]. The associated 4DVar functional becomes
L(z) = 1
2(z −ˆza
NA)TB−1(z −ˆza
NA)
+ 1
2
NA

k=1
(Hψk(z) −yobs(tk+NA))TR−1(Hψk(z) −yobs(tk+NA)), (6.26)

6.2 Variational data assimilation
185
10
1
10
0
10
1
10
2
10
3
10
4
0
0 1
0 2
0 3
0 4
background covariance
averaged RMS error
x solution component
10
1
10
0
10
1
10
2
10
3
10
4
0
0 5
1
background covariance
averaged RMS error
z solution component
Figure 6.3 Time averaged RMSEs over
40 data assimilation cycles each
consisting of NA = 5 observations.
Results are displayed for various
strengths δ > 0 of the background
covariance matrix B = δI3.
Observations are ignored in the limit
δ →0, while δ →∞recovers the
assimilation experiment conducted in
Experiment 1.8 of Chapter 1. The
results demonstrate that an optimal
choice of the background covariance can
lead to a substantial reduction of the
RMSE.
with the analysis ˆza
NA obtained from the assimilation of the ﬁrst patch of ob-
servations. The minimiser of this functional, denoted by ˆzs
NA:2NA, provides the
background state via ˆza
2NA := ψNA(ˆzs
NA:2NA) for the next assimilation cycle.
We return now to Example 1.8 from Chapter 1 and ﬁnd that there we used a
data assimilation technique rather close in spirit to 4DVar. The only diﬀerence
being that, instead of (6.26), in Example 1.8 we minimised
L(z) = 1
2
NA

k=1
(Hψk(z) −yobs(tk))TR−1(Hψk(z) −yobs(tk)),
(6.27)
i.e., the prior distribution was ignored. In the following example, we repeat the
numerical experiment from Example 1.8 with a proper 4DVar implementation
and the background covariance matrix B appropriately chosen.
Example 6.7
We repeat the data assimilation experiment from Example 1.8.
Recall that we assimilated data over assimilation windows consisting of patches
of 5 observations, i.e., NA = 5, with each observation separated by Δtout =
0.05 = 50δt time units. A total of 40 assimilation cycles were performed. Fol-
lowing the discussion from Example 2.20, we model the measurement error as a
Gaussian random variable with mean zero and variance R = 1/15. This parame-
ter is used in the cost functional (6.25). We also use a constant prior (also called
background) covariance matrix B = δI for all assimilation windows. The param-
eter δ > 0 was varied over a range of values to determine an optimal value. The
resulting time averaged RMSEs in the observed x and the unobserved z variable
can be found in Figure 6.3. Note that δ →∞leads back to the assimilation
experiment conducted in Experiment 1.8 while δ →0 implies that observations
are ignored and the smoothed values are identiﬁed with their forecasted values.

186
Basic data assimilation algorithms
In addition to improved behaviour of (6.25) compared with (6.27) for an op-
timised choice of P a
0 = B, it should also be kept in mind that minimising (6.27)
becomes ill posed whenever the available set of observations is not suﬃcient to
guarantee a well-deﬁned minimiser. The same situation can, in principle, also
arise for (6.25). However, the background term in (6.25) can always be chosen
such that the associated L possesses a unique minimiser. In contrast, in Ap-
pendix 6.5 we discuss the relation between (6.25) and (6.27) as Nobs →∞by
means of a simple example. This example demonstrates that both (6.25) and
(6.27) lead asymptotically to the same estimator/minimiser.
We conclude this discussion by emphasising that 4DVar provides a mathe-
matically elegant approach to state estimation in the context of smoothing. In
combination with Monte Carlo sampling, variational data assimilation can also
be used to compute expectation values with respect to πZ(z, t0|yobs
t1 Nobs). The im-
pact of stochastic model contributions on state estimation within a variational
framework is discussed in Appendix 6.6.
We now provide some implementation details of the 4DVar method for the
interested reader, which could be skipped during a ﬁrst reading. The gradient
descent method
z(l+1) = z(l) −α∇zL(z(l)),
l = 0, 1, . . . ,
is often used for ﬁnding local minima of the 4DVar cost functional (6.26). The
parameter α > 0 is chosen such that L(z(l+1)) ≤L(z(l)). We used α = 0.01
in Example 6.7. More sophisticated methods for adaptively determining an ap-
propriate step-length α are available (Nocedal & Wright 2006). In any case, an
eﬃcient method for computing the gradient ∇zL(z) is crucial for the implemen-
tation of the gradient method. In order to avoid the construction of large dense
matrices, the adjoint method should be used for calculating the gradient at a
z = z(l). For simplicity we describe the procedure for NA = 2 in (6.26). The
ﬁrst step of the adjoint method is a forward trajectory calculation resulting in
z1 = ψ(z0) and z2 = ψ(z1) with z0 = z(l) in our particular case. Simultaneously,
we compute the two residuals
r1 := Hz1 −yobs(tNA+1),
r2 := Hz2 −yobs(tNA+2).
The second step is a backward sweep starting at the last observation index
NA + 2. Hence, we start in our case with
a2 = HTR−1r2
and then set
a1 = HTR−1r1 + (Dψ(z1))Ta2.
Here Dψ(z) denotes the Jacobian matrix of partial derivatives of ψ at z. Finally
∇zL(z(l)) = B−1(z(l) −ˆza
NA) + (Dψ(z(l)))Ta1.
Note that the entire calculation involves only matrix–vector multiplications. We

6.3 Particle ﬁlters
187
ﬁnd that the convergence rate of the gradient method with B = δI increases
as δ > 0 becomes smaller. This can be explained by the fact that the scaled
functional δ L(z) converges to an isotropic quadratic functional as δ →0. To
completely specify a single step of the gradient method, we still need to provide
an eﬃcient method for computing Dψ(z0)Ta1 and Dψ(z1)Ta2. Here we make
use of the fact that ψ is deﬁned as the Nout-fold application of the model (6.23).
We explain the basic idea for Nout = 2 and for Dψ(z1)Ta2. Again we start with
a forward sweep resulting in
z1,1 := z1 + δtf(z1),
z1,2 := z1,1 + δtf(z1,1).
Note that z1,2 = z2 by deﬁnition. These calculations are followed by a backward
sweep deﬁning two vectors a2,1 and a2,0 by
a2,1 = (I + δtDf(z1,1))T a2,
and
a2,0 = (I + δtDf(z1))T a2,1,
respectively. Then
Dψ(z1)Ta2 = a2,0
as can be veriﬁed by applying the chain rule of diﬀerentiation. Note that the
calculation of, for example, a2,1 can be interpreted as a single explicit Euler step
applied to the adjoint diﬀerential equation
da
dt = −Df(z(t))Ta,
backward in time along z(t) = z1,1, i.e., with step-size −δt < 0, and for given
end value a2.
Beyond simple gradient descent minimisation, we could consider more ad-
vanced minimisation techniques such as Gauss–Newton and the nonlinear con-
jugate gradient method. We refer the reader to textbooks such as Nocedal &
Wright (2006).
6.3
Particle ﬁlters
While 4DVar is a powerful data assimilation method, it is not consistent with
a Bayesian perspective unless the prior distribution at t0 is indeed Gaussian.
This assumption is typically violated when 4DVar is applied recursively over
patches of observations. Computing the mode of a posterior distribution can
also be misleading in cases where the smoothing distribution is multimodal.
We therefore discuss a proper Bayesian generalisation of the Kalman ﬁlter to
nonlinear dynamical models and non-Gaussian distributions in the remainder
of this chapter. This generalisation, a sequential Monte Carlo method called
the particle ﬁlter, relies on ensemble prediction for nonlinear dynamical systems

188
Basic data assimilation algorithms
as introduced in Chapter 4, combined with an importance sampling approach,
introduced in Chapter 3 and further elaborated on in the context of Bayesian
inference in Chapter 5.
We ﬁrst recall the ensemble prediction approach to the approximation of
marginal PDFs πZ(z, t) of an SDE model,
dZ = f(Z)dt +
√
2Q1/2dW(t) ,
as outlined in Deﬁnition 4.20 from Chapter 4. In fact, as before, we replace the
continuous ensemble formulation (4.35) by an ensemble of time-discrete approx-
imations
zn+1
i
= zn
i + δtf(zn
i ) +
√
2δtQ1/2ξn
i ,
i = 1, . . . , M,
(6.28)
n ≥0, with the values {ξn
i } denoting realisations of independent and identically
distributed Gaussian random variables with mean zero and covariance matrix
equal to the identity matrix. The initial conditions z0
i at t = 0 are realisations
of a random variable with PDF πZ(z, 0). Recall that the ensemble prediction
method is just a Monte Carlo implementation of the prediction step (6.4).
The idea of particle ﬁlters is to combine ensemble prediction with importance
sampling. Each ensemble member is assigned a weight w0
i = 1/M at t = 0. These
weights are kept constant during each ensemble prediction step (6.28) provided
that there is no observation to be assimilated. We now assume that after Nout
steps under (6.28), an observation yobs(t1) becomes available at t1 = Δtout :=
δtNout with likelihood function πY (yobs(t1)|z). Then, an application of Bayes’
formula to the forecast ensemble zf
i(t1) = zNout
i
leads to rescaling the weights
according to
w1
i =
w0
i πY (yobs(t1)|zf
i(t1))
M
j=1 w0
jπY (yobs(t1)|zf
j(t1))
=
πY (yobs(t1)|zf
i(t1))
M
j=1 πY (yobs(t1)|zf
j(t1))
,
i = 1, . . . , M, since w0
i = 1/M. Compare Equation (5.25) from Chapter 5.
The new weights w1
i are again kept constant whilst the states are incremented
according to (6.28), until a second set of observations yobs(t2) becomes available
at t2 = 2Δtout and a new forecast ensemble is deﬁned by
zf
i(t2) = z2Nout
i
.
At that point the weights are changed to
w2
i =
w1
i πY (yobs(t2)|zf
i(t2))
M
j=1 w1
j πY (yobs(t2)|zf
j(t2))
,
i = 1, . . . , M.
More generally, we obtain the update formula
wk
i =
wk−1
i
πY (yobs(tk)|zf
i(tk))
M
j=1 wk−1
j
πY (yobs(tk)|zf
j(tk))
,
zf
i(tk) = zkNout
i
,
(6.29)
with the variables {zn
i }, n ≥0, obtained by simple propagation of the initial
ensemble {z0
i } under the discrete model dynamics (6.28) throughout the whole

6.3 Particle ﬁlters
189
assimilation process. This update means that more weight is given to ensemble
members which produce simulated observations that are more “likely” in terms
of the actual observations and the observation noise model, i.e. the likelihood.
Posterior expectation values of functions g : RNz →R at tk are approximated
by
ga
M(tk) =
M

i=1
wk
i g(zf
i(tk)),
while approximations to prior expectation values are based on
gf
M(tk) =
M

i=1
wk−1
i
g(zf
i(tk)).
We now demonstrate that the posterior estimator is consistent with the assump-
tion of a prior empirical distribution, formally given by
μf
Z(dz, tk|yobs
t1 k
1) =
M

i=1
wk−1
i
δ(z −zf
i(tk))dz,
and an application of Bayes’ formula. Indeed, upon deﬁning the posterior mea-
sure according to Bayes’ formula,
μZ(dz, tk|yobs
t1 k) =
πY (yobs(tk)|z) M
i=1 wk−1
i
δ(z −zf
i(tk))dz

RNz πY (yobs(tk)|z) M
j=1 wk−1
j
δ(z −zf
j(tk))dz
=
M
i=1 wk−1
i
πY (yobs(tk)|z) δ(z −zf
i(tk))dz
M
j=1 wk−1
j
πY (yobs(tk)|zf
j(tk))
=
M

i=1
wk
i δ(z −zf
i(tk))dz,
we obtain
ga
M(tk) =

RNz
g(z)μZ(dz, tk|yobs
t1 k)
=
M

i=1
wk
i g(zf
i(tk)),
as desired. The resulting particle ﬁlter is often referred to as sequential impor-
tance sampling (SIS) ﬁlter.
It is to be expected that the weights will become non-uniform after a few
assimilation steps. In order to quantify the non-uniformity in the weights we
introduce the eﬀective sample size.
Definition 6.8 (Eﬀective sample size)
Given a set of weights wi ≥0, i =
1, . . . , M, the eﬀective sample size is deﬁned by
Meﬀective =
1
M
i=1 w2
i
.
(6.30)

190
Basic data assimilation algorithms
0
0 5
1
1 5
2
10
0
10
1
10
2
10
3
10
4
10
5
time
effective sample size
10
1
10
2
10
3
10
4
10
5
0
0 1
0 2
0 3
0 4
0 5
0 6
sample size M
time averaged RMSEs
x−coordinate
z−coordinate
Figure 6.4 Assimilation results from the Lorenz-63 model over a time period [0, 2] and
for various ensemble sizes M. Filtering is performed with a sequential importance sampling
(SIS) ﬁlter. The left panel displays the evolution of the eﬀective sample sizes while the
right panel shows the time averaged RMSEs as a function of the ensemble size M. In
these experiments we found that the ﬁlter fails to converge over an extended time window
[0, 3] due to a collapse of the eﬀective sample size, even with ensembles of size M ≤105.
The eﬀective sample size is equal to M in the case of uniform weights wi = 1/M.
In the extreme non-uniform case wi = 1 for one single ensemble member i and
wj = 0 for all j ̸= i, we obtain Meﬀective = 1.
The eﬀective sample size is used to quantify the weight non-uniformity for the
following example.
Example 6.9
We return to the modiﬁed Lorenz-63 model introduced in Chap-
ter 1. Recall that the process of generating the underlying physical process zref(t)
was described in Example 1.1. The generation of partial observations in the x-
variable was laid out in Example 1.2. We now use these observations together
with the stochastic Lorenz-63 model (4.18)–(4.20) from Example 4.13 to imple-
ment an SIS ﬁlter. The required likelihood function is given by
πY (xobs(tk)|zf
i(tk)) =
1
√
2πR
e−1
2R (xobs(tk)−xf
i(tk))2,
with error variance R = 1/15. See Example 2.20 from Chapter 2. As for Examples
1.8 and 6.7, observations are collected every Δtout = 0.05 time units. The initial
PDF is Gaussian with mean z = (−0.587, −0.563, 16.87) and diagonal covariance
matrix P = σ2I with σ = 0.1.
Numerical results for the resulting eﬀective sample sizes as a function of time
and the time averaged RMSEs as a function of the ensemble size M can be
found in Figure 6.4. Notice that the eﬀective sample size decays rather quickly,
and that the RMSEs converge as M is increased for ﬁxed assimilation intervals

6.3 Particle ﬁlters
191
(here [0, 2]). However, the SIS ﬁlter is found to fail to converge on the extended
assimilation interval [0, 3] for ensembles of size M ≤105. Here the RMSEs are
deﬁned as in Example 6.7 with the analysis mean now deﬁned by
za
k =
M

i=1
wk
i zf
i(tk).
We may conclude that an SIS particle ﬁlter is not competitive with an op-
timally implemented 4DVar algorithm for this particular example. Indeed the
RMSEs from Example 6.7 are comparable to those displayed in Figure 6.4 but
the achievable 4DVar assimilation windows are much longer.
The previous example clearly illuminates the need to modify the particle ﬁl-
ter to avoid the collapse of the eﬀective sample size. The resampling strategies
discussed towards the end of Chapter 3 are natural candidates for this. Such
modiﬁed particle ﬁlters are collectively called sequential importance resampling
(SIR) ﬁlters. Other names often found in the literature are bootstrap ﬁlter and
condensation algorithm (del Moral 2004).
Algorithm 6.10 (Sequential Importance resampling (SIR) ﬁlter)
Given an ini-
tial distribution πZ(z, 0), we draw M independent realisations zi(t0) from this
distribution with equal weights w0
i = 1/M.
The following steps are performed recursively for k = 1, . . . , Nobs.
(i) In between observations, the ensemble is propagated under an evolution
model, such as (6.28), with constant weights wk−1
i
producing a forecast
ensemble {zf
i(tk)}M
i=1.
(ii) An observation yobs(tk) at tk = kΔtout = δtkNout results in a change of
weights from wk−1
i
to wk
i , i = 1, . . . , M, according to (6.29).
(iii) After each change of weights, the eﬀective sample size is evaluated according
to (6.30).
(a) If Meﬀective drops below M/2, a new set of M equally weighted en-
semble members za
i (tk) is generated from the forecast ensemble zf
i(tk)
by the method of residual resampling. See Algorithm 3.27 from Chap-
ter 3. Finally we return to (i) with the resampled ensemble, i.e., with
ensemble members given by
zi(tk) := za
i (tk),
weights given by wk
i := 1/M, and k incremented by one.
(b) Otherwise we continue in (i) with zi(tk) = zf
i(tk), weights wk
i as com-
puted under (ii), and increment k by one.
The threshold for resampling can, of course, be chosen to be diﬀerent from
M/2. In fact, we could simply resample after each assimilation step. We now
apply the SIR ﬁlter to the data assimilation experiment from Example 6.9.

192
Basic data assimilation algorithms
0
2
4
6
8
10
0
50
100
150
200
250
300
time
effective sample size
50
100
150
200
250
300
0
0 1
0 2
0 3
0 4
0 5
0 6
0 7
0 8
sample size M
time averaged RMSEs
x−coordinate
z−coordinate
Figure 6.5 Assimilation results from the Lorenz-63 model over a time period [0, 10] and
varying ensemble sizes M ∈[30, 300]. Filtering is performed with an SIR ﬁlter. The left
panel displays the evolution of the eﬀective sample sizes for M = 30, 100 and 300 while
the right panel shows the time averaged RMSEs as a function of the ensemble size M.
We notice that resampling helps to keep the eﬀective sample size stabilised and the ﬁlter
is able to follow the surrogate physical process as represented by zref(t). When averaged
over [0, 10], the RMSEs quickly converge as M increases and the size of the errors are
comparable to those obtained from an optimised 4DVar implementation for M ≥100. See
Figure 6.3.
Example 6.11
We repeat the experiment from Example 6.9 with the SIS ﬁlter
being replaced by the SIR ﬁlter described in the previous algorithm. The SIR
ﬁlter is able to successfully track the reference solution as given by zref(t). The
RMSEs averaged over a time period [0, 10] are similar to those from an optimised
4DVar technique. See Figures 6.5 and 6.3. However the SIR ﬁlter is easier to
implement since no iterative minimisation of a cost functional is required.
It can be shown (see Bain & Crisan (2009) and del Moral (2004), for example)
that the SIR ﬁlter provides a consistent Monte Carlo implementation of the
abstract Bayesian ﬁltering problem, as outlined at the beginning of this chapter,
within a perfect model setting. However, in Example 6.11 an imperfect model
setting was used, i.e., the reference trajectory and the forecasts were generated
by diﬀerent models. There are very few rigorous results about the convergence
of particle ﬁlters under imperfect model scenarios, but the previous example
demonstrates that skilful forecasts are nevertheless possible.
We ﬁnally demonstrate, using numerical experiments, that an SIR ﬁlter is able
to reproduce the results from a Kalman ﬁlter in the case of a linear dynamical
model and a Gaussian distribution on the initial conditions.

6.3 Particle ﬁlters
193
0
0.5
1
1.5
2
0
0.5
1
1.5
2
time
variance
Kalman filter
0
0.5
1
1.5
2
0
0.5
1
1.5
2
time
variance
particle filter
M = 10
M = 100
M = 1000
M = 10000
10
1
10
2
10
3
10
4
0.5
0.51
0.52
0.53
0.54
0.55
0.56
0.57
0.58
sample size M
time averaged RMSEs
particle filter
Kalman filter
Figure 6.6 Comparison of the SIR ﬁlter to the Kalman ﬁlter for a scalar linear model
and a Gaussian initial distribution. While the top panel displays the behaviour in terms of
posterior variances, the bottom one gives the resulting time averaged RMSEs for both
ﬁlters. The convergence of the SIR ﬁlter to the (optimal) Kalman solution as M increases
is clearly visible.
Example 6.12
We repeat the perfect model experiment from Example 6.4
and replace the Kalman ﬁlter by the SIR ﬁlter with increasing sample sizes M.

194
Basic data assimilation algorithms
Again we ﬁnd that the SIR ﬁlter converges as M is increased and, furthermore,
a comparison with the Kalman ﬁlter reveals that the SIR ﬁlter converges to the
same asymptotic value of the posterior variance. See Figure 6.6. We also compare
the time averaged RMSEs from the Kalman and the SIR ﬁlter and again ﬁnd
asymptotic convergence as M →∞.
An SIR resampling step generally produces an equally weighted analysis en-
semble with some of its members being identical. If the model dynamic is de-
terministic, then these ensemble members will remain identical for all times;
eventually the eﬀective ensemble size may collapse as for an SIS particle ﬁl-
ter. Particle rejuvenation is often used to generated mutually distinct analysis
ensemble members.
Definition 6.13 (Particle rejuvenation)
Let {za
i } denote an equally weighted
analysis ensemble with some ensemble members being identical, i.e., there exist
indices i1 and i2 such that za
i1 = za
i2. Let B ∈RNz×Nz denote a given covariance
matrix and τ > 0 a given bandwidth parameter. Then particle rejuvenation re-
places each analysis ensemble member za
i , i = 1, . . . , M, by a single draw from
the Gaussian distribution N(za
i , τB). Note that the analysis ensemble remains
unaltered for τ = 0 and that B can be chosen to be the empirical covariance
matrix of the forecast ensemble.
Particle rejuvenation was not applied in the previous examples since the un-
derlying dynamical models are stochastic. However, in Chapters 7 and 8, we will
ﬁnd that the introduction of particle rejuvenation is essential for good perfor-
mance of particle ﬁlters in many contexts.
Problems
6.1
Derive the update formulas (6.7) and (6.8) from the dynamical model equa-
tions (6.6).
6.2
Repeat the imperfect model experiment from Example 6.4 with the pa-
rameter d in (6.14) set to d = 0.5. The reference trajectory is still generated
with d = −0.1. Compute the asymptotic value P a
∗, the analysis means {za
k}, and
the time averaged RMSE. Compare your results to those from the perfect and
imperfect model settings from Example 6.4.
6.3
The derivation of linear 4DVar was based on the simpliﬁed assumption that
the dynamical system satisﬁes zn+1 = (I + δtD)zn. How do the results change
if we were to consider the more general linear system with aﬃne term
zn+1 = (I + δD)zn + δtb?
6.4
Consider the trivial dynamical model zn+1 = zn for zn ∈RNz and n ≥0.
The initial conditions z0 are Gaussian distributed with mean zero and covariance
matrix P 0 = I. For simplicity, the reference trajectory is given by zn
ref = 0 for all
n ≥0. We will consider a time-dependent observation operator where a diﬀerent

6.3 Particle ﬁlters
195
component of the state vector z is observed at each time-step. At time index
n, we observe the nth entry of the state vector z, which we denote by z(n).
In other words, the forward operator H ∈R1×Nz is time dependent and given
by H(tn) = eT
n and Nout = 1. The measurement errors are independent and
Gaussian distributed with mean zero and variance R = 0.16. Hence, we obtain
the time-dependent conditional PDF
πY (yn
obs|z, tn) ∝e−
(yn
obs
eT
n zn)2
2R
,
with yn
obs = ξn and ξn ∼N(0, R). Apply the Kalman formulas to this problem
to derive the sequence of analyis means za
n and covariance matrices P a
n for n =
1, . . . , Nz. Be careful to note that the forward operator H is time dependent.
Finally discuss the dependence of the ﬁnal za
Nz and P a
Nz on the dimension of
state space Nz.
6.5
Implement the SIS particle ﬁlter for the data assimilation scenario in Prob-
lem 6.4. How does the particle ﬁlter behave for ﬁxed ensemble size M = 10 and
increasing values of the dimension of state space Nz ∈{1, 10, 20, . . ., 100, 200}?
Repeat each experiment one thousand times and average over the resulting nor-
malised RMSEs at the ﬁnal iteration n = Nz, i.e.,
RMSE =
1
N 1/2
z
>>>>>
M

i=1
wNz
i
zNz
i
>>>>> ,
noting that for this model, zNz
i
= z0
i . Also monitor the eﬀective sample size
(6.30) as a function of the iteration index n = 0, . . . , Nz.
6.6
The behaviour of the SIS particle ﬁlter observed in Problem 6.5 is an exam-
ple of the curse of dimensionality for dynamical systems with high-dimensional
state spaces. We will discuss ﬁlter algorithms for high-dimensional systems in
Chapter 8. Here we illustrate one of their basic ideas for the data assimilation
problem from Problem 6.4. Note that the Kalman ﬁlter updates each entry of
the state vector individually while the particle ﬁlter of Problem 6.5 couples all
entries through a change in the particle weights wn
i ≥0. A more appropriate
approach would be to localise the impact of an observation yn
obs onto the cor-
responding entry of the ensemble vectors zn
i ∈RNz, i = 1, . . . , M. This leads
to vectors of weights wn
i ∈RNz with their kth entry denoted by wn
i (k). Those
entries individually satisfy

k
wn
i (k) = 1;
surprisingly only the nth entry is updated at the nth assimilation step using
wn
i (n) ∝wn−1
i
(n)e−
(yn
obs
eT
n zn
i )2
2R
,
i = 1, . . . , M,
with wn−1
i
(n) = 1/M. Implement the associated localised SIS ﬁlter and compare

196
Basic data assimilation algorithms
your results with those from Problem 6.5 in terms of the RMSE deﬁned by
RMSE =
1
N 1/2
z

	
	

M

i=1
Nz

n=1
&
wNz
i
(n)zNz
i
(n)
'2
.
6.7
Implement the SIR ﬁlter for the stochastically perturbed Lorenz-63 model
(4.18)–(4.20) from Example 4.13. Use the same model to generate a reference
trajectory {zn
ref}n≥0 from the initial condition
z0
ref = (−0.587, −0.563, 16.87).
Use this reference trajectory to generate a total of Nobs = 100000 observations of
the x-components in time intervals of Δtout = 0.01 and with measurement error
variance R. Compute time averaged RMSEs for ensemble sizes varying between
M = 50 and M = 1000 and for measurement error variances R = 0.1 and
R = 1.0. The initial PDF is Gaussian with mean z = z0
ref and diagonal covariance
matrix P = σ2I with σ = 0.1. In addition to varying values of the measurement
error variance R, it is also interesting to explore diﬀerent observation intervals
Δtout and/or diﬀerent variances σ in the initial PDF N(z0
ref, σ2I).
6.4
Guide to literature
Tarantola (2005) is a very readable introduction to data assimilation, whilst
Jazwinski (1970) is still an excellent monograph on the classic theory of ﬁltering
and Bayesian data assimilation. The linear ﬁlter theory (Kalman ﬁlter) can, for
example, be found in Simon (2006). A broad range of assimilation techniques,
including variational ones, is discussed in Lewis et al. (2006). Also, see S¨arkk¨a
(2013) for a stronger emphasis on the Bayesian approach to smoothing and
ﬁltering. Practical aspects of particle ﬁlters/sequential Monte Carlo methods can
be found in Doucet et al. (2001), Robert (2001), and Arulampalam et al. (2002),
while del Moral (2004), Bain & Crisan (2009) and K¨unsch (2005) provide a more
theoretical perspective. Bengtsson, Bickel & Li (2008) discuss the applicability
of particle ﬁlters to high-dimensional systems.
A discussion of data assimilation in a meteorological and geophysical context
is provided by Daley (1993) and Kalnay (2002).
An introduction to minimisation algorithms can be found in Nocedal & Wright
(2006).
6.5
Appendix: Posterior consistency
Bayes’ formula tells us how to adjust our probability distribution having received
noisy observations. If a series of measurements is taken, then we expect to re-
duce our uncertainty in the system state as each measurement is made, even if

6.5 Appendix: Posterior consistency
197
the measurements are noisy. It seems reasonable to expect that the probability
measure converges to the Dirac measure centred on the true value, in the limit
of many observations with observation noise of ﬁxed variance. This is called
posterior consistency. Posterior consistency is often used as a way of verifying
Bayesian data assimilation algorithms, or even debugging algorithm code.
The conditions under which posterior consistency is expected under a given
data assimilation scheme are very technical, and a subject of current research.
Here, we consider a very simple case, namely the trivial iteration
zn+1 = zn,
tn+1 = tn + 1,
where we wish to estimate the initial state z0 from observations yobs(tn) at
tn = n, n = 1, 2, . . ., Nobs. The reference solution is simply given by zn
ref = z0
under a perfect model assumption. We further assume for simplicity the forward
model
yobs(tn) = z0 + ξn,
where the variables {ξn} are independent realisations of a Gaussian random
variable with mean zero and covariance matrix R.
This very much simpliﬁed data assimilation problem allows us to compare
maximum likelihood based estimators, such as (6.27), with Bayesian ones, such
as (6.25). Without further restriction of generality we also assume that z and y
are univariate.
Since the measurement errors are assumed to be mutually independent, the
likelihood function of Nobs observations is simply given by
l(z, yobs
t1 Nobs) :=
Nobs
1
n=1
πY (yobs(tn)|z),
with
πY (y|z) =
1
√
2πR
e−1
2R (y−z)2.
The maximum likelihood estimate of z0, denoted by ˆz0, is now deﬁned as the
minimiser of the negative log likelihood function
LMLE(z) = −ln l(z, yobs
t1 Nobs) =
Nobs

n=1
1
2R(yobs(tn) −z)2 + Nobs
2
ln(2πR),
and we recognise the method of least squares applied to the residuals
rn := z −yobs(tn),
up to an insigniﬁcant additive constant. Since ˆz0 has to satisfy
L′
MLE(ˆz0) = 1
R
Nobs

n=1
(ˆz0 −yobs(tn)) = 0,

198
Basic data assimilation algorithms
the maximum likelihood estimate is given by
ˆz0 =
1
Nobs
Nobs

n=1
yobs(tn),
which determines ˆz0 as the mean over the available observations.
Since the observations yobs(tn) are realisations of random variables Y (tn), the
estimator ˆz0 is also the realisation of an appropriately deﬁned random variable
ˆZ0. Within our simple model setting, the distribution of ˆZ0 is Gaussian for any
Nobs ≥1 with mean ˆz0 and variance σ2 = R/Nobs.
How does this picture change for the associated Bayesian MAP estimate ˜z0,
which is based on minimising
LMAP(z) =
1
2B (z0 −z)2 + LMLE(z),
in the case of a Gaussian prior N(z0, B)? Straightforward calculations lead to
the equation
L′
MAP(˜z0) = 1
B (˜z0 −z0) + 1
R
Nobs

n=1
(˜z0 −yobs(tn)) = 0.
Hence
˜z0 +
R
BNobs
(˜z0 −z0) =
1
Nobs
Nobs

n=1
yobs(tn)
and ˜z0 →ˆz0 as Nobs →∞. In other words, the maximum likelihood estimator
ˆz0 is recovered asymptotically as the number of observations is increased.
6.6
Appendix: Weak constraint 4DVar
Our discussion of variational data assimilation techniques has been based on
deterministic models leading to a relation
zf
k+1 = ψ(za
k)
(6.31)
between the analysis at time tk and the forecast at tk+1. In this appendix, we
brieﬂy describe an extension of the 4DVar functional (6.25) to models contain-
ing stochastic contributions. This extension, known as weak constraint 4DVar,
formally replaces the perfect model (6.31) by
zf
k+1 = ψ(za
k) + wk+1,
with the new variables wk, k = 1, . . . , Nobs, representing stochastic model con-
tributions. These contributions are assumed to be Gaussian with mean zero and

6.6 Appendix: Weak constraint 4DVar
199
covariance matrix ˆQ ∈RNz×Nz. Furthermore, the functional (6.25) is replaced
by
L = 1
2(z0 −za
0)T(P a
0 )−1(z0 −za
0) + 1
2
Nobs

k=1
wT
k ˆQ−1wk
+ 1
2
Nobs

k=1
(Hzk −yobs(tk))TR−1(Hzk −yobs(tk)),
(6.32)
subject to
wk := zk −ψ(zk−1).
(6.33)
These modiﬁcations to 4DVar have the important consequence that the func-
tional (6.32) now depends on a whole sequence z0, z1, . . . , zNobs of states. Critical
points are given by the Nz × (Nobs + 1) nonlinear equations
∇z0L = (P a
0 )−1(z0 −za
0) −Dψ(z0)T ˆQ−1w1 = 0,
∇zkL = −Dψ(zk)T ˆQ−1wk+1 + ˆQ−1wk + HTR−1rk = 0,
for k = 1, . . . , Nobs −1, and
∇zNobsL = ˆQ−1wNobs + HTR−1rNobs = 0
with model contributions (6.33) and residuals
rk := Hzk −yobs(tk).
Weak constraint 4DVar can be shown to reduce to the associated Kalman
smoother equations in the case of linear models and Gaussian uncertainties in
the initial conditions and model errors (Jazwinski 1970).
Standard 4DVar is recovered in the formal limit ˆQ →0.

7
McKean approach to data
assimilation
The previous chapter introduced some well-established data assimilation algo-
rithms. On the one hand, the Kalman ﬁlter provides a way to convert from a
forecast PDF to an analysis PDF, under the assumption of a linear model, a
Gaussian forecast PDF and Gaussian observation error. On the other hand, the
particle ﬁlter transforms an empirical PDF from forecast to analysis by altering
the weights, and can be used in completely general situations. In this chapter
we will develop a framework that uniﬁes these two approaches, by taking a cou-
pling and optimal transportation perspective. We will use this framework in this
(and the following) chapter to explore a number of data assimilation algorithms
which attempt to deal with the major drawback of the particle ﬁlter, namely the
requirement of relative large ensemble sizes for good state estimates.
We start by recalling that a Markov process gives rise to families of random
variables
Zt0 N := (Z0, Z1, . . . , ZN) : Ω →RNz×N+1,
with joint PDFs given by
πZt0 N (zt0 N) = πZ(z0, t0)π(z1|z0) · · · π(zN|zN−1),
where π(z′|z) denotes the transition kernel of the Markov process and πZ(z, t0)
is the initial PDF. The marginal PDFs πZ(z, tn) for the random variables Zn,
n = 1, . . . , N, are recursively determined by the Chapman–Kolmogorov equation
πZ(z′, tn) =

RNz
π(z′|z)πZ(z, tn−1)dz.
Ensemble prediction methods produce realisations (or samples) of Zt0 N, based
on the recursive structure of the underlying Markov process. More precisely,
given a set of M ensemble members zn−1
i
at tn−1, this ensemble is subsequently
transformed into an ensemble at tn according to a (stochastic) model which we
write as
zn
i = Zn
i (ωi),
Zn
i ∼π(·|zn−1
i
),
for i = 1, . . . , M, i.e., zn
i is taken as the realisation of a random variable with PDF
π(·|zn−1
i
). We have discussed several methods for generating realisations from a
PDF πZ(z) := π(z|zn−1
i
) in Chapter 3. After having completed this process for

McKean approach to data assimilation
201
n = 1, . . . , N we may formally write
Zt0 N(ωi) := (z0
i , z1
i , . . . , zN
i ),
for i = 1, . . . , M.
Furthermore, since the ensemble values {zn
i } at time tn are samples from
π(z, tn), the ensemble induced PDF
πM(z′, tn+1) = 1
M
M

i=1
π(z′|zn
i ),
converges weakly to πZ(z′, tn+1) and the new ensemble {zn+1
i
} at tn+1 can be
used to approximate the expectation value
E[g(Zn+1)] ≈1
M
M

i=1
g(zn+1
i
),
of any continuous and bounded function g.
Bayesian data assimilation algorithms combine ensemble prediction for Markov
processes with a recursive application of Bayes’ formula
πZa(z|yobs) = πY (yobs|z)πZf(z)
πY (yobs)
,
(7.1)
which transforms a forecast PDF πZf(z) into an analysis PDF πZa(z|yobs) un-
der the likelihood πY (yobs|z) of an observation yobs. One of the challenges of
merging ensemble prediction methods and Bayesian data assimilation algorithms
lies in the fact that Bayes’ formula does not come in the form of a Chapman–
Kolmogorov equation. The SIR particle ﬁlter works around that problem by im-
plementing Bayes’ formula as an importance resampling step in order to obtain
an analysis ensemble with uniform weights.
The McKean approach1 to data assimilation pushes importance resampling a
step further by putting Bayes’ formula directly into the framework of Markov
chains. The Markov chain deﬁnes the transition from a forecast ensemble into an
analysis ensemble at an observation time tk, with all ensemble members keeping
equal weights. The desired Markov chain will only be applied once and has to
produce an analysis which is consistent with Bayes’ formula (7.1). We summarise
this in a formal deﬁnition. A broader perspective on the McKean approach and,
more generally, interacting particle systems can be found in del Moral (2004).
1 McKean (1966) pioneered the study of stochastic processes that are generated by
stochastic diﬀerential equations for which the diﬀusion term depends on the time-evolving
marginal distributions πZ(z, t). Such stochastic diﬀerential equations are fundamentally
diﬀerent from the ones considered in Chapter 4, and lead to interacting particle/ensemble
approximations. More precisely, Monte Carlo sampling paths {zi(t)}t∈[0,T ], i = 1, . . . , M,
are no longer independent if samples {zi(t)} at time t are used to approximate the
marginal PDF πZ(z, t) by, e.g., the ensemble induced empirical measure. Here we utilise a
generalisation of this idea which allows for Markov transition kernels π(z′, tn|z) that
depend on the marginal distribution πZ(z, tn).

202
McKean approach to data assimilation
Definition 7.1 (McKean approach)
Let b(z′|z) be a transition kernel such that
Bayes’ formula (7.1) becomes equivalent to a Chapman–Kolmogorov equation,
πZa(za|yobs) =

RNz
b(za|zf)πZf(zf)dzf.
Given an ensemble zf
i which follows the forecast PDF, an analysis ensemble can
be obtained from
za
i = Za
i (ω),
Za
i ∼b(·|zf
i),
i = 1, . . . , M, i.e., the analysis samples za
i are realisations of random variables
Za
i with PDFs b(z|zf
i). This Monte Carlo approach to Bayesian inference is called
the McKean approach.
The transition kernel b(z′|z) will, in general, depend on both the observed
value yobs as well as the forecast PDF πZf. In this sense, the induced Markov
process will be non-autonomous; this is contrary to most of the Markov processes
considered in Chapter 4.
Example 7.2
The following transition kernel can be found in del Moral (2004):
b(za|zf) = επY (yobs|zf)δ(za −zf) + (1 −επY (yobs|zf))πZa(za|yobs).
Here ε ≥0 is chosen such that
1 −επY (yobs|z) ≥0,
for all z ∈RNz. Indeed we ﬁnd that

RNz
b(za|zf)πZf(zf)dzf = επY (yobs|za)πZf(za) + πZa(za|yobs)
−επZa(za|yobs)

RNz
πY (yobs|zf)πZf(zf)dzf
= πZa(za|yobs)
+ ε {πY (yobs|za)πZf(za) −πZa(za|yobs)πY (yobs)}
= πZa(za|yobs).
This choice of a transition kernel implies that the state remains at zf with prob-
ability p = επy(yobs|zf), otherwise we draw a new sample from the analysis PDF
πZa(za|yobs). The particular choice ε = 0 implies zero correlation between the
forecast and analysis ensembles.
In order to apply the McKean approach to data assimilation, we need to ﬁnd
an appropriate transition kernel b(za|zf). There are many possibilities for doing
so. The kernels considered in this chapter are based on the concept of coupling
two probability measures. Recalling the deﬁnition in Chapter 2, a Bayes’ formula

McKean approach to data assimilation
203
coupling between the forecast and the analysis PDFs is a joint measure μZfZa
such that the marginals satisfy
πZf(zf)dzf =

za∈RNz
μZfZa(dzf, dza),
and
πZa(za|yobs)dza =

zf∈RNz
μZfZa(dzf, dza),
respectively. Once such a coupling is available we obtain the desired transition
PDF b(za|zf) from the disintegration formula
b(za|zf) πZf(zf) dzfdza = μZfZa(dzf, dza).
We recall from Chapter 2 that couplings can often be made deterministic and
are then given in the form of a transport map, i.e., there exists a transformation
za = T (zf) such that
μZfZa(dzf, dza) = δ(za −T (zf)) πZf(zf) dzfdza,
in which case we have
b(za|zf) = δ(za −T (zf)),
formally. In this case, a Monte Carlo implementation of the McKean approach
to Bayesian inference reduces to the simple mathematical formula
za
i = T (zf
i),
i = 1, . . . , M.
(7.2)
In addition to ﬁnding appropriate couplings there is another major challenge for
implementing the McKean approach in practice. This challenge is related to the
fact that the forecast PDF is often not available explicitly. Indeed, an ensemble
prediction method will only provide us with a forecast ensemble zf
i, i = 1, . . . , M,
from which we will have to estimate a statistical model in the form of a forecast
PDF (or measure) πZf. See Figure 7.1 for a graphical presentation of the complete
ensemble-based implementation of a McKean approach for Bayesian inference.
A statistical model for the forecast PDF πZf can be either parametric or non-
parametric. A simple parametric model is the Gaussian N(zf
M, P f
M) with its mean
zf
M and covariance matrix P f
M estimated from the prior or forecast ensemble zf
i,
i = 1, . . . , M, i.e.,
zf
M = 1
M
M

i=1
zf
i
(7.3)
and
P f
M =
1
M −1
M

i=1
(zf
i −zf
M)(zf
i −zf
M)T ∈RNz×Nz.
(7.4)
If the likelihood function πY (yobs|z) is also Gaussian, then the posterior is Gauss-
ian as well with its mean and covariance matrix given by Kalman’s formulas from

204
McKean approach to data assimilation


	
Figure 7.1 A graphical presentation of the McKean approach to Bayesian inference in
the context of Monte Carlo methods. We assume that M ensemble members zf
i are
available which are realisations from a generally unknown forecast/prior PDF. The ﬁrst
task is to estimate a statistical model in the form of a PDF πZf from the available
ensemble members. Bayes’ formula then leads to an analysis/posterior PDF πZa. Next we
need to ﬁnd a coupling πZfZa between the forecast and analysis PDFs. Once such a
coupling is available, an analysis ensemble {za
i }M
i=1 can be generated following standard
Monte Carlo methodologies.
Chapter 6. However, unlike the classical Kalman ﬁlter, we need to establish a
coupling between the prior and posterior Gaussians in order to derive an approp-
riate map (7.2) for ensemble-based data assimilation algorithms. Later in this
chapter we will see that the associated data assimilation algorithms give rise
to the popular family of ensemble Kalman ﬁlters. Note that we have already
discussed in Chapter 2 how to couple two Gaussian random variables. Hence we
only need to put this material into the McKean data assimilation framework.
On the other hand, a non-parametric model for the forecast measure is pro-
vided by the empirical measure
μf
M(dz) = 1
M
M

i=1
δ(z −zf
i)dz.
(7.5)
The associated analysis measure is then
μa
M(dz) =
M

i=1
wiδ(z −zf
i)dz
(7.6)
with weights wi ∝πY (yobs|zf
i). The problem of ﬁnding couplings for such mea-
sures has already been discussed in Chapters 2 and 5 in the context of linear
transportation and a single Bayesian inference step.

McKean approach to data assimilation
205
The Gaussian parametric and empirical non-parametric approaches can be
combined to obtain Gaussian mixture models
πM(z) = 1
M
M

i=1
n(z; zf
i, τP f
M),
where τ > 0 is the bandwidth parameter and P f
M denotes the empirical covariance
matrix (7.4) of the ensemble. In other words, the prior PDF is approximated as
the sum of M Gaussians with means zf
i and identical covariance matrices equal
to τP f
M. The empirical measure can be recovered by letting τ →0.
One of the key ﬁndings of this chapter will be that Monte Carlo implemen-
tations of the McKean approach lead to linear ensemble transformations of the
form
za
j =
M

i=1
zf
idij,
(7.7)
regardless of the chosen prior approximation. Data assimilation algorithms from
this chapter will therefore only diﬀer through their coeﬃcients dij in (7.7), which
have some (possibly random) functional dependence on the forecast ensemble.
These coeﬃcients can be collected in an M × M matrix D.
Definition 7.3 (Linear ensemble transform ﬁlters)
A particle or ensemble ﬁlter
with the Bayesian inference step implemented in the form of a linear ensemble
transformation (7.7) is called a linear ensemble transform ﬁlter (LETF).
Example 7.4
An SIR particle ﬁlter with resampling performed after each
analysis step also ﬁts into the framework of LETFs. In this case, the coef-
ﬁcients in (7.7) are given as realisations of a matrix-valued random variable
D : Ω →RM×M whose entries satisfy
(i) dij := Dij(ω) ∈{0, 1},
(ii) M
i=1 dij = 1, and
(iii)
1
M E
!M
j=1 Dij
"
= wi.
So far we have discussed a single Bayesian inference step in terms of an in-
duced Markov transition kernel b(za|zf). We now combine such a kernel at each
observation instance tk with the Markovian model dynamics in between obser-
vations. Let us denote these kernels by b(za, tk|zf) and πNout(zf|za), respectively.
A complete transition kernel from an analysis at tk−1 to the induced analysis at
tk is then characterised by the marginalised transition kernel
π(za(tk), tk|za(tk−1)) =

RNz
b(za(tk), tk|zf) πNout(zf|za(tk−1)) dzf.

206
McKean approach to data assimilation
Hence, as for the Markovian model dynamics, the McKean approach to Bayesian
data assimilation leads to families of analysis random variables
Za
t0 Nobs = (Za(t0), Za(t1), . . . , Za(tNobs)) ,
with joint PDFs formally given by
πZa
t0 Nobs (za
t0 Nobs ) = πZ(za(t0), t0) π(za(t1), t1|za(t0)) · · ·
π(za(tNobs), tNobs|za(tNobs−1)).
Ensemble prediction methods for Markov processes can now be extended to
sequential data assimilation problems. Two such approaches will be discussed in
detail in the remainder of this chapter. More speciﬁcally, the following section
discusses the McKean approach for Gaussian approximations to the forecast
distribution πZf in the Bayesian inference step, which gives rise to the popular
class of ensemble Kalman ﬁlters. Subsequently we discuss particle ﬁlters from an
optimal transportation perspective, which gives rise to another family of LETFs.
7.1
Ensemble Kalman ﬁlters
The classic Kalman ﬁlter formulas provide a transition from the forecast mean
zf and covariance matrix P f to the analysis mean za and covariance matrix P a.
An ensemble Kalman ﬁlter (EnKF) pulls this transition back onto the level of
forecast ensembles zf
i, i = 1, . . . , M, and analysis ensembles za
i , i = 1, . . . , M,
respectively. Therefore it provides an implicit coupling between the underlying
forecast and analysis random variables. The basic algorithmic steps of an EnKF
can be summarised as follows.
(i) The forecast ensemble is used to deﬁne the empirical mean (7.3) and co-
variance matrix (7.4).
(ii) The Kalman update formulas from Chapter 6 result in the analysis mean
za = zf
M −K(Hzf
M −yobs),
(7.8)
and the analysis covariance matrix
P a = P f
M −KHP f
M.
(7.9)
Here the Kalman gain matrix is given by
K = P f
MHT(HP f
MHT + R)−1,
(7.10)
H is the (linear) forward operator, and R is the measurement error covari-
ance matrix of an observation yobs.
(iii) Finally the analysis ensemble {za
i } is deﬁned by a linear transformation
(7.7) with the transformation matrix D chosen such that
1
M
M

i=1
za
i = za,
(7.11)

7.1 Ensemble Kalman ﬁlters
207
and
1
M −1
M

i=1
(za
i −za)(za
i −za)T = P a.
(7.12)
If the transformation D is a random matrix, we require that (7.11) and (7.12)
hold in expectation.
The transformation matrix D of an EnKF is not uniquely determined by the
constraints (7.11) and (7.12); this allows for diﬀerent implementations of an
EnKF. We start with the oldest EnKF formulation, which is based on a non-
deterministic coupling between the forecast and analysis ensemble.
Definition 7.5 (EnKF with perturbed observations)
Given a prior ensemble
zf
i, i = 1, . . . , M, with associated empirical mean (7.3) and covariance matrix
(7.4), we ﬁrst compute the Kalman gain matrix (7.10). The EnKF with perturbed
observations is then based on the non-deterministic coupling
Za = Zf −K(HZf + Ξ −yobs),
(7.13)
where Ξ denotes a Gaussian random variable with mean zero and covariance
matrix R. The posterior ensemble {za
i } is obtained accordingly via
za
i = zf
i −K(Hzf
i + ξi −yobs),
i = 1, . . . , M,
where the variables {ξi} are realisations of M i.i.d. Gaussian random variables
with PDF N(0, R). In other words, the McKean transition kernel b(za|zf) of an
EnKF with perturbed observations is given by
b(za|zf) = n(za; zf −K(Hzf −yobs), KRKT).
In order to ensure that
M

i=1
ξi = 0,
(7.14)
it is often useful to shift a given set of samples {ξ′
i} from N(0, R) by its empirical
mean,
ξ
′
M = 1
M
M

i=1
ξ′
i ∈RNy,
so that ξi := ξ′
i −ξ
′
M and (7.14) holds.
We demonstrate that (7.13) is consistent with the Kalman update formulas
provided Zf has mean zf and covariance matrix P f
M. We ﬁrst verify that
za = E[Za] = zf
M −K(Hzf
M −yobs),

208
McKean approach to data assimilation
since Ξ is centred. Next, we ﬁnd that
P a = E[(Za −za)(Za −za)T]
= E[(Zf −K(HZf + Ξ −yobs) −za)(Zf −K(HZf + Ξ −yobs) −za)T]
= E[KΞΞTKT]
+ E[(Zf −zf
M −KH(Zf −zf
M))(Zf −zf
M −KH(Zf −zf
M))T]
= KRKT + P f
M −P f
MHTKT −KHP f
M + KHP f
MHTKT
= P f
M −KHP f
M .
Here we have used the property that Ξ and Zf are independent, and the identity
KRKT + KHP f
MHTKT = P f
MHT(HP f
MHT + R)−1HP f
M = P f
MHTKT.
The EnKF with perturbed observations ﬁts into the framework of LETFs
(7.7) and the associated matrix-valued random variable D : Ω →RM×M has
realisations with entries
dij = δij −
1
M −1(zf
i −zf
M)THT(HP f
MHT + R)−1(Hzf
j + ξj −yobs),
(7.15)
where δij denotes the Kronecker delta, i.e., δii = 1, δij = 0 for i ̸= j. This claim
can be veriﬁed by direct calculations making use of
P f
M =
1
M −1
M

i=1
zf
i(zf
i −zf
M)T.
We discuss the coupling perspective on an EnKF with perturbed observations
in some more detail for the univariate case.
Example 7.6
The EnKF with perturbed observations for a scalar state variable
and forward operator H = 1 becomes
Za = Zf −K(Zf −yobs + Ξ),
(7.16)
with Kalman gain factor
K =
(σf)2
(σf)2 + R,
where we have replaced the prior covariance matrix P f
M by (σf)2 for notational
convenience. Let us interpret this update in terms of an induced coupling between
Zf and Za, with Zf being Gaussian with mean zf and variance (σf)2, and Za
being Gaussian with mean
za = zf −
(σf)2
(σf)2 + R(zf −yobs),
and variance
(σa)2 =

1 −
(σf)2
(σf)2 + R

(σf)2 =
R
(σf)2 + R(σf)2,

7.1 Ensemble Kalman ﬁlters
209
respectively. Any Gaussian coupling must have mean
(zf, za) ∈R2,
and covariance matrix
Σ =
 (σf)2
ρσfσa
ρσfσa
(σa)2

,
with the correlation ρ taking values between minus one and one. We have already
seen in Chapter 2 that |ρ| = 1 leads to a deterministic coupling. In the case of
the EnKF with perturbed observations, the induced coupling is not deterministic
and the correlation between Zf and Za is instead given by
E[(Zf −zf)(Za −za)] = E[(Zf −zf)(Zf −zf −K(Zf −zf + Ξ))]
= (σf)2 −K(σf)2 = (σa)2,
and, therefore,
Σ =
 (σf)2
(σa)2
(σa)2
(σa)2

.
Hence
ρ = σa
σf =
2
R
(σf)2 + R < 1.
We now put the EnKF analysis step into the context of state estimation for
an evolution model such as (6.28), using the notation introduced in Chapter 6.
Algorithm 7.7 (EnKF with perturbed observations)
We draw M independent
realisations z0
i = zi(0) from a given initial distribution πZ(z, 0). Observations
are given in intervals of Δtout = δtNout.
The following steps are performed recursively for k = 1, . . . , Nobs.
(i) In between observations, the initial ensemble {zi(tk−1)} at tk−1 = (k −
1)Δtout is propagated under the given evolution model, such as (6.28), in
order to produce a forecast ensemble {zf
i} at the next observation time
tk = kΔtout.
(ii) The forecast ensemble is transformed into an analysis ensemble {za
i }M
i=1
according to (7.7). The coeﬃcients dij are deﬁned by (7.15) with observed
yobs = yobs(tk) and M independent realisations ξi of a Gaussian random
variable with distribution N(0, R) satisfying (7.14). Finally, we return to
(i) with new initial conditions
zi(tk) := za
i ,
i = 1, . . . , M,
and the index k increased by one.

210
McKean approach to data assimilation
We mention in passing that the EnKF with perturbed observations can be
viewed as a Monte Carlo implementation of a BLUE estimator as introduced in
Appendix 5.5, with the variable X being replaced by the forecast state variable
Zf. The key observation is that yobs := Y (ω), x := zf, and za := ˆX(ω) in (5.34).
This interpretation of the EnKF with perturbed observations is appealing since
it does not rely on the assumption of the prior PDF being Gaussian.
Given the theoretical results on couplings from Chapter 2, it is rather natural
to look for deterministic couplings between the forecast and the analysis. Indeed,
following Example 2.26 from Chapter 2, a suitable analysis ensemble could, for
example, be deﬁned by the linear transformation
za
i = za + (P a)1/2(P f
M)−1/2(zf
i −zf
M),
i = 1, . . . , M,
(7.17)
with za given by (7.8) and P a by (7.9), respectively. This formulation requires
the computation of the square root of two Nz × Nz matrices, which can be
computationally demanding if Nz is large.
In order to derive an alternative update formula, we write the empirical fore-
cast covariance matrix (7.4) as
P f
M =
1
M −1Af(Af)T,
(7.18)
with the Nz ×M matrix of forecast ensemble perturbations (also called ensemble
anomalies)
Af :=
#
(zf
1 −zf
M)
(zf
2 −zf
M)
· · ·
(zf
M −zf
M)
$
.
(7.19)
We next seek a matrix S ∈RM×M such that
1
M −1AfSST(Af)T = P a = P f
M −KHP f
M.
(7.20)
A set of analysis ensemble anomalies is then provided by
Aa := AfS ∈RNz×M.
(7.21)
More speciﬁcally, Equation (7.20) together with (7.18) imply
P a =
1
M −1Af

I −
1
M −1(HAf)T #
HP f
MHT + R
$−1 HAf
;
(Af)T,
and hence
S :=

I −
1
M −1(HAf)T #
HP f
MHT + R
$−1 HAf
;1/2
.
Recall that the square root of a positive semi-deﬁnite matrix U is the unique
symmetric matrix U 1/2 such that U 1/2U 1/2 = U.
An application of the Sherman–Morrison–Woodbury formula (6.9) leads to the
equivalent formulation
S =

I +
1
M −1(HAf)TR−1HAf
;−1/2
.
(7.22)

7.1 Ensemble Kalman ﬁlters
211
Formulation (7.22) is preferable computationally whenever the ensemble size M
is smaller than the number of observations Ny, and R is diagonal. Furthermore,
the equivalent Kalman update formula
za = zf
M −P aHTR−1(Hzf
M −yobs)
= zf
M −
1
M −1AfS2(Af)THTR−1(Hzf
M −yobs),
can be used to bring (7.8) into the form
za =
M

i=1
zf
iwi,
(7.23)
with the weights wi deﬁned as the ith entry of the column vector
w = 1
M 1 −
1
M −1S2(Af)THTR−1 
Hzf
M −yobs

.
(7.24)
Here 1 := (1, 1, . . . , 1)T ∈RM. Since S1 = 1 and Af1 = 0 it follows that
Aa1 = AfS1 = 0,
(7.25)
and the weights wi satisfy
M

i=1
wi = 1.
The weights can therefore be interpreted as “importance” weights similar to the
weights in an SIS or SIR particle ﬁlter. See Chapter 6 and the discussion later
in the chapter.
A complete ensemble update is given by
za
j =
M

i=1
wizf
i +
M

i=1
(zf
i −zf
M)sij =
M

i=1
zf
i

wi + sij −1
M
;
,
(7.26)
where sij = (S)ij denotes the (i, j)th entry of the transform matrix S which
satisiﬁes M
i=1 sij = 1. This formula forms the basis of the popular ensemble
square root ﬁlter (ESRF). We can bring (7.26) into the form (7.7) with coeﬃcients
dij = wi −1
M + sij.
We have already discussed in Example 2.32 of Chapter 2 that the transforma-
tion (7.17) is not optimal in the sense of the Monge–Kantorovitch transportation
problem as formulated in Deﬁnition 2.27. The same applies to the ESRF update
(7.26). An optimal update in the sense of Monge–Kantorovitch is
za
i = za +
1
√M −1Aa #
(Aa)TP f
MAa$−1/2 (Aa)T(zf
i −zf
M),
(7.27)
where Aa is deﬁned by (7.21). Compare Equation (2.24) from Example 2.32.
Note that (7.27) requires an additional computation of an M ×M matrix square
root.

212
McKean approach to data assimilation
5
10
15
20
25
30
35
40
0
0 1
0 2
0 3
0 4
0 5
sample size M
time averaged RMSEs
EnKF with perturbed observations
x−coordinate
z−coordinate
5
10
15
20
25
30
35
40
0
0 1
0 2
0 3
0 4
0 5
sample s ze M
time averaged RMSEs
ESRF
x−coordinate
z−coordinate
Figure 7.2 Data assimilation results for the Lorenz-63 model over a time period [0, 10]
and varying ensemble sizes M. Filtering is performed with the EnKF with perturbed
observations and the ESRF. The left (right) panel displays the time-averaged RMSEs
from the EnKF (ESRF) as a function of the ensemble size M. When averaged over the
time period, the RMSEs quickly converge as M is increased; the size of the errors is
comparable to those obtained from the SIR ﬁlter implementation for much larger
ensemble sizes, as depicted in Figure 6.5. Also note that the ESRF is stable even for
M = 2 while the EnKF with perturbed observations requires at least M = 4.
The ESRF update formulas give rise to the following algorithm for performing
sequential data assimilation.
Algorithm 7.8 (ESRF)
Given an initial distribution πZ(z, 0), we draw M in-
dependent realisations z0
i = zi(0) from this distribution. Observations are given
in intervals of Δtout = δtNout.
The following steps are performed recursively for k = 1, . . . , Nobs.
(i) In between observations, the initial ensemble {zi(tk−1)} at tk−1 = (k −
1)Δtout is propagated under the given evolution model, such as (6.28), in
order to produce a forecast ensemble {zf
i} at the next observation time
tk = kΔtout.
(ii) A Gaussian N(xf
M, P f
M) is ﬁt to the forecast ensemble zf
i, i = 1, . . . , M.
The observation yobs = yobs(tk) leads to a posterior Gaussian N(za, P a).
Using either (7.26) or (7.27) together with either (7.8) or (7.23), we deﬁne
a posterior ensemble za
i , i = 1, . . . , M. Finally, we return to (i) with new
initial conditions
zi(tk) := za
i ,
i = 1, . . . , M,
and the index k increased by one.
Example 7.9
We return to the stochastically perturbed Lorenz-63 model from

7.2 Ensemble transform particle ﬁlter
213
Chapter 4. The EnKF with perturbed observations and the ESRF are imple-
mented for the data assimilation setting of Example 6.9 from Chapter 6. Nu-
merical results for the time-averaged RMSEs as a function of the ensemble size
M can be found for both ensemble Kalman ﬁlter implementations in Figure 7.2.
The results should be compared to those obtained for the SIR ﬁlter in Example
6.11. Remarkably, the ensemble Kalman ﬁlter implementations lead to smaller
time-averaged RMSEs than the SIR ﬁlter for small ensemble sizes, and to com-
parable errors for larger ensemble sizes. These results indicate that the forecast
PDFs are nearly Gaussian under this experimental setting (frequent observations
and small measurement errors).
7.2
Ensemble transform particle ﬁlter
The ensemble Kalman ﬁlter relies on a Gaussian approximation to the fore-
cast PDF and an interpretation of the classical Kalman formulas in terms of
an ensemble transform or coupling step. While this relatively simple parametric
approach is rather robust, it becomes inconsistent whenever the forecast uncer-
tainties are not well represented by a Gaussian distribution. We now discuss a
class of LETFs that are developed using non-parametric statistical models for
the forecast PDFs instead.
The forecast empirical measure (7.5) and the analysis empirical measure (7.6)
provide the starting point for the derivation of the ensemble transform particle
ﬁlter (ETPF). This step is identical to that of a classical SIS or SIR particle
ﬁlter. Instead of resampling, the ETPF then follows the coupling methodology
developed in Chapter 5, using the solution of the associated linear transport
problem
T ∗= arg min
M

i,j=1
tij∥zf
i −zf
j∥2,
(7.28)
for non-negative tij subject to
M

i=1
tij = 1/M,
M

j=1
tij = wi.
The analysis ensemble members za
j are deﬁned by
za
j =
M

i=1
zf
ipij,
pij := Mt∗
ij,
(7.29)
for j = 1, . . . , M.
The ETPF formulation (7.29) can lead to the creation of identical or near-
identical analysis ensemble members, which is problematic if the dynamic model

214
McKean approach to data assimilation
is deterministic. Just as for the SIR particle ﬁlter, particle rejuvenation can be
applied, which replaces (7.29) by
za
j =
M

i=1
zf
ipij + ξj.
(7.30)
for j = 1, . . . , M, where the variables {ξj} are independent realisations from
Gaussian distributions N(0, P a
j ) with some chosen covariance matrix P a
j . A sim-
ple choice is P a
j = τP f
M for all j = 1, . . . , M with bandwidth parameter τ ≥0.
Note that τ = 0 leads back to the linear update (7.29). We now summarise the
complete ETPF as follows.
Algorithm 7.10 (ETPF)
Given an initial distribution πZ(z, 0), we draw M
independent realisations z0
i = zi(0) from this distribution. Observations are given
in intervals of Δtout = δtNout.
The following steps are performed recursively for k = 1, . . . , Nobs for given
bandwidth parameter τ ≥0.
(i) In between observations, the initial ensemble {zi(tk−1)} at tk−1 = (k −
1)Δtout is propagated under the given evolution model, such as (6.28), in
order to produce a forecast ensemble {zf
i} at the next observation time
tk = kΔtout.
(ii) The empirical measure (7.5) is ﬁt to the forecast ensemble zf
i, i = 1, . . . , M.
The observation yobs = yobs(tk) leads to the analysis empirical measure
(7.6) with weights deﬁned by
wi ∝exp

−1
2(Hzf
i −yobs)TR−1(Hzf
i −yobs)

with the constant of proportionality chosen such that 
i wi = 1. We solve
the associated linear transport problem (7.28) and obtain the analysis en-
semble {za
i } according to (7.30) with the variables {ξj} being independent
realisations from the Gaussian N(0, τP f
M) distribution.
(iii) Finally, we return to (i) with initial conditions
zi(tk) := za
i ,
i = 1, . . . , M,
and the index k increased by one.
The essential steps of an algorithm for solving the linear transport problem
(7.28) are outlined in Appendix 7.4. A fast implementation, called FastEMD,
is discussed by Pele & Werman (2009). FastEMD is also available as a Matlab
subroutine.
The ETPF update is substantially more computationally expensive than an
EnKF update because of the need to solve a linear transport problem in each
assimilation step. This shortcoming will be addressed partially in Chapter 8
when the concept of localisation is introduced. More speciﬁcally, the problem of
solving one linear transport problem in RNz will be replaced by solving Nz linear

7.2 Ensemble transform particle ﬁlter
215
30
40
50
60
70
80
90
100
0
0 1
0 2
0 3
0 4
0 5
0 6
sample size M
time averaged RMSEs
Ensemble transform particle f lter
x−coord nate
z−coord nate
Figure 7.3 Time-averaged RMSEs
for the ETPF in the data
assimilation setting of Example 7.9.
The ETPF requires larger ensemble
sizes than the EnKF but leads to
otherwise similar time-averaged
RMSEs.
transport problems in one dimension. These linear transport problems can be
solved simultaneously by the eﬃcient algorithm given in Appendix 5.8.
Example 7.11
The data assimilation setting of Example 7.9 is now also used for
testing the performance of the ETPF in its formulation (7.29). The time-averaged
RMSEs can be found in Figure 7.3. The ETPF does not improve the time-
averaged RMSEs obtained for the EnKF implementations and also requires larger
ensemble sizes M. This ﬁnding indicates again that the forecast and analysis
PDFs are close to Gaussian for this data assimilation setting.
We discuss two more examples in order to explore the behaviour of the various
proposed ﬁlter algorithms in a more non-Gaussian context.
Example 7.12
Let us consider the one-dimensional stochastic dynamical sys-
tem (7.36) from Problem 7.4 with φ(z) = z3. Solutions of the associated dynam-
ical system approach ±∞in ﬁnite time with probability one. We shall use this
as our model, but simulate “observations” at every iteration according to
yn
obs = ξn,
n ≥1,
with the variables {ξn} being realisations of independent and identically dis-
tributed N(0, 4) Gaussian random variables. This is an example of assimilating
data with an unstable reference solution and strongly nonlinear model dynamics,
providing a simple way to obtain very non-Gaussian PDFs. We will assume that
the initial ensemble z0
i , i = 1, . . . , M, follows a Gaussian distribution N(0, 2).
Experiments were conducted with ensemble sizes varying from M = 100 to
M = 10000, using RMSEs averaged over Nobs = 10000 assimilation cycles to
compare the perturbed observations EnKF to the ETPF, implemented using
(7.29). The results from the EnKF can be found in Figure 7.4 while those from
the ETPF can be found in Figure 7.5. The RMSEs from the EnKF are approxi-
mately equal to the standard deviation of the observations, which indicates that

216
McKean approach to data assimilation






 	

 	

 	
  
	
  ! "#"
 # 
10
5
0
5
10
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
state variable
relative frequenc es of binned EnKF ensemble at final time
Figure 7.4 The EnKF with perturbed observations is applied to the stochastic
dynamical system from Example 7.12. The time-averaged RMSEs for ensemble sizes
varying between M = 100 and M = 10000 are displayed in the left panel. Note that the
standard deviation of the measurement errors is R1/2 = 2. Hence on average, the EnKF
does not provide any additional information beyond what is already contained in the
observations yn
obs. The right panel shows the histogram produced from the analysis
ensemble at ﬁnal time and M = 10000.
the EnKF is not providing any additional information: we could have simply
replaced the output of the dynamical system by the observed quantity. In other
words, the EnKF only manages to stabilise the unstable dynamics towards the
observed values. The ETPF, on the other hand, leads to signiﬁcantly smaller
time-averaged RMSEs. We mention that the SIR ﬁlter from Chapter 6 leads to
results similar to those obtained from the ETPF ﬁlter and that the ETPF is
implemented using the algorithm from Appendix 5.8.
Example 7.13
In this example, we formulate a more nonlinear data assim-
ilation setting by returning to the Lorenz-63 model. First, we set the time-
dependent function g(t) in (1.1) equal to zero. We also replace the forward Euler
time-stepping by the implicit midpoint approximation
zn+1 = zn + δtf(zn+1/2),
zn+1/2 = 1
2(zn+1 + zn),
(7.31)
with step-size δt = 0.01. The state variable is z = (x, y, z)T ∈R3 and right hand
side of the iteration is provided by
f(z) =
⎛
⎝
10(y −x)
x(28 −z) −y
xy −8/3z
⎞
⎠.

7.2 Ensemble transform particle ﬁlter
217
10
2
10
3
10
4
0 5
1
1 5
2
2 5
ensemble size M
ETPF
time averaged RMSEs
10
5
0
5
10
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
0 45
0 5
state variable
relative frequencies of binned ETPF ensemble at final time
Figure 7.5 The ETPF is applied to the stochastic dynamical system from Example 7.12.
We display the same quantities as shown in Figure 7.4 for the EnKF with perturbed
observations. The time-averaged RMSEs from the ETPF are signiﬁcantly smaller than
those displayed in Figure 7.4. The analysis ensemble at ﬁnal time is also distributed rather
diﬀerently.
Instead of observations of the x-variable being taken every Δtout = 5δt = 0.05
time units, we increase the observation interval to Δtout = 12δt = 0.12 and
observe all three solution components. The measurement error variance is also
increased from R = 1/15 to R = 9 and measurement errors in the three solution
components are mutually independent. The reference trajectory zn
ref, n ≥0, is
obtained from (7.31) with initial condition
x0 = −0.587276,
y0 = −0.563678,
z0 = 16.8708.
Note that the model for generating the reference solution is identical to the
model used for generating forecasts in this setting, and is autonomous and de-
terministic. This is, in fact, a standard setting found in the literature for testing
data assimilation algorithms, referred to as an identical twin experiment. While
identical twin experiments are clearly a strong idealisation, they allow for an
easier assessment of data assimilation algorithms. Here we compare the ESRF,
SIR ﬁlter, and the ETPF, using a total of 50000 of data assimilation steps in
identical twin experiments.
The distribution for the initial ensemble is Gaussian with mean z0=(x0, y0, z0),
covariance matrix σ2I, and σ = 0.1. All ﬁlter algorithms are implemented with a
rejuvenation step (as outlined in Deﬁnition 6.13), by adding Gaussian N(0, τP f
M)
perturbations to the analysis. The bandwidth parameter τ is chosen from the
interval [0, 0.5]. The SIR ﬁlter resamples the particles after each assimilation step
using residual resampling as outlined in Chapter 3. The smallest time-averaged
RMSEs for ﬁxed ensemble sizes ranging from M = 10 to M = 80 are given for
each method in Figure 7.6. We ﬁnd that the ESRF settles at a time-averaged

218
McKean approach to data assimilation
10
20
30
40
50
60
70
80
0 8
1
1 2
1 4
1 6
1 8
2
2 2
ensemble size
time averaged RMSEs
ESRF
SIR
ETPF
Figure 7.6 Time-averaged RMSEs
obtained by the ESRF, the SIR
particle ﬁlter, and the ETPF for the
modiﬁed Lorenz-63 model of
Example 7.13. The ESRF settles at
an RMSE of about 1.2 for all
ensemble sizes. This value is
signiﬁcantly smaller than the
measurement error standard
deviation R1/2 = 3. Both the SIR
ﬁlter and the ETPF lead to more
skilful results as M increases.
Furthermore, the ETPF outperforms
the SIR ﬁlter for all values of M.
Displayed are the smallest RMSEs
for rejuvenation parameters
τ ∈[0, 0.5].
RMSE of about 1.2, independent from the ensemble size, while both the SIR
and the ETPF keep improving their RMSEs as M increases. The ETPF also
performs consistently better than the SIR ﬁlter implementation.
We now compare the ESRF and the ETPF within the context of linear en-
semble transform ﬁlters (7.7) in further detail. The ETPF without particle re-
juvenation leads directly to a representation in the form of (7.7) with dij = pij.
We now demonstrate that the ETPF update formula (7.29) can be decomposed
into an update of the mean and the ensemble deviations, just as for the ESRF.
First we note that
za = 1
M
M

i,j=1
pijzf
i =
M

i=1
wizf
i,
which provides a consistent estimator for the analysis mean under importance
sampling from the forecast distribution. We next formulate an ETPF update
formula for the ensemble deviations, i.e.,
za
j −za =
M

i=1
zf
ipij −za
=
M

i=1
(zf
i −zf
M)pij −
M

i=1

wi −1
M

zf
i
=
M

i=1
(zf
i −zf
M)

pij + 1
M −wi
;
.
(7.32)
Here we have used that M
i=1 pij = 1. Hence we can compare the transform

7.2 Ensemble transform particle ﬁlter
219
10
0
10
1
10
2
10
3
10
2
10
1
10
0
ensemble size M
error in computed mean
ETPF
ESRF
10
0
10
1
10
2
10
3
10
3
10
2
10
1
10
0
ensemble size M
error in computed variance
ETPF
ESRF
Figure 7.7 Averaged errors in the posterior means (left panel) and the variance (right
panel) from a single ESRF and ETPF assimilation step as a function of the ensemble size
M. A convergence of both approximations as M is increased can clearly be seen. The
convergence rate is approximately M −1/2. The ESRF gives slightly more accurate
estimates for the mean and variance, which is not surprising given the fact that the prior
ensemble is Gaussian.
matrix (7.22) of an ESRF to the transform matrix ˜S, with entries given by
˜sij = pij −wi + 1
M ,
of the ETPF. It should be noted that the coeﬃcients dij = pij and wi of an
ETPF are all non-negative while this is not the case for an ESRF. This fact is
important when entries of the state vector should only take non-negative values,
for example, when z represents concentrations or densities. In this case, an ESRF
analysis step can potentially lead to an analysis ensemble {za
i } for which some
of its members take negative entries. See Janji´c, McLaughlin, Cohn & Verlaan
(2014) for more details.
Example 7.14
We compare the ESRF transformation with the ETPF transfor-
mation for a single Bayesian assimilation step for a univariate Gaussian random
variable with prior mean zero and variance one. The observed value is yobs = 1,
with measurement error variance R = 1. The posterior is then also Gaussian with
mean za = 1/2 and variance 1/2. Given M ∈{5, 10, . . ., 1000} realisations from
the prior distribution, we compare the resulting empirical posterior means and
variances under both LETFs as well as the diﬀerence between the importance
weights
wETPF
i
∝e−(zf
i−1)2/2

220
McKean approach to data assimilation
10
0
10
1
10
2
10
3
10
1 9
10
1 7
10
1 5
10
1 3
10
1 1
ensemble size M
distance of importance weights
Figure 7.8 Diﬀerence between the
importance weights from an
importance sampling step with the
weights (7.24) generated by an
ESRF. The diﬀerence vanishes as M
increases, which indicates that the
ESRF asymptotically approximates
the importance weights from a
Gaussian likelihood provided the
prior is Gaussian.
and the weights (7.24) from the ESRF (denoted here by wESRF
i
), given by
∥wETPF −wESRF∥2 =
. M

i=1
|wETPF
i
−wESRF
i
|2
/1/2
.
The results averaged over 200 experiments for each ﬁxed ensemble size can be
found in Figures 7.7 and 7.8, for ETPF and ESRF respectively. A convergence
of all quantities as M increases can clearly be seen.
This discussion leads us to consider LETFs (7.7) in their representation
za
j =
M

i=1
zf
i

wi −1
M + sij
;
(7.33)
with the transformation matrix S ∈RM×M and the weight vector w ∈RM
suitably deﬁned. The matrix S should satisfy M
j=1 sij = 1 in order to preserve
the mean given by za = 
i wizf
i. For example, we could combine parts of an
ESRF with parts of the ETPF ﬁlter.
Another class of transform ﬁlters, which ﬁts into the framework (7.33), has
been proposed by Anderson (2010). We explain the key idea for a univariate
observable y ∈R with forward operator H ∈R1×Nz. The ﬁrst step is to deﬁne a
forecast ensemble yf
i := Hzf
i, i = 1, . . . , M, in observation space. The second step
consists of deﬁning an analysis ensemble ya
i , i = 1, . . . , M, in observation space
by an appropriate ﬁlter algorithm. This amounts to implementing a Bayesian
inference step
πY (y|yobs) ∝πY (yobs|y)πY (y),
in observation space with likelihood
πY (yobs|y) =
1
√
2πR
e−(y−yobs)2/2R,

7.2 Ensemble transform particle ﬁlter
221
and the prior PDF πY representing the ensemble {yf
i}M
i=1. The analysis ensem-
ble is then deﬁned through an appropriate coupling of the univariate prior and
posterior PDFs. The particular choice
πY (y)dy = 1
M
M

i=1
δ(y −yf
i)dy,
(7.34)
for the prior PDF leads to an implementation of the ETPF in observation space.
See Anderson (2010) for another choice for πY , which leads to the rank histogram
ﬁlter.
Once the analysis ensemble {ya
i } has been computed, the update in state space
is deﬁned by linear regression
za
i = zf
i + P f
MHT(HP f
MHT)−1(ya
i −yf
i)
= zf
i +
1
M −1Af(Af)THT(HP f
MHT)−1(ya
i −yf
i)
(7.35)
onto the state space Z = RNz. Hence we obtain
za = zf
M + P f
MHT(HP f
MHT)−1(ya −yf
M),
which satisﬁes Hza = ya. More generally, we have ya
i = Hza
i and, therefore,
Aa = Af +
1
M −1Af(Af)THT(HP f
MHT)−1H(Aa −Af)
= Af

I +
1
M −1(Af)THT(HP f
MHT)−1H(Aa −Af)

= AfS
with the second line implicitly deﬁning a transform matrix S for the ensemble
deviations.
This algorithm can be extended to multivariate observables yobs either by solv-
ing the ﬁltering problem directly in the associated observation space Y = RNy or,
in the case where the measurement error covariance matrix R is diagonal, by se-
quentially processing each entry in the observed vector yobs ∈RNy (since the like-
lihood function πY (y|z) factors into a product of univariate likelihood functions).
Problems
7.1
Consider a forecast ensemble of four members zf
1 = −3, zf
2 = −1, zf
3 = 1
and zf
4 = 3 with equal weights 1/4. Suppose that a particle ﬁlter importance
sampling step leads to non-uniform weights
(w1, w2, w3, w4) = (1/16, 3/16, 5/16, 7/16),
and that subsequently a residual resampling step is performed (compare Exam-
ple 3.29). Interpret the resulting SIR analysis step in terms of a random matrix

222
McKean approach to data assimilation
D : Ω →R4×4 as outlined in Example 7.4 above. Write down all possible reali-
sations of D and their associated probabilities.
7.2
Write the EnKF update step (7.16) for scalar state variable z ∈R in
the form of an LETF (7.7). Assume that the forecast ensemble {zf
i} consists of
independent samples from a random variable Zf with PDF πZf, H = 1, and that
a set of realisations ξi ∈R, i = 1, . . . , M of Ξ is given.
(i)
Show that
M

i=1
dij = 1.
(ii)
What can be said about wi = M
j=1 dij in the limit M →∞?
(iii)
Construct an example that demonstrates that Zf ≥0, i.e., zf
i ≥0,
does not necessarily imply za
i ≥0.
(iv)
Consider an implementation of the EnKF with perturbed observa-
tions where we replace the empirical covariance matrix P f
M by an a
priori given covariance matrix B in the Kalman gain matrix. Deter-
mine the resulting analysis mean za and covariance matrix P a and
discuss their dependence on B. We mention that such an a priori
choice is often found in nudging techniques.
7.3
Show that the weights deﬁned by (7.24) minimise the cost function
J(w) = 1
2(za −zf
M)T(P f
M)−1(za −zf
M) + 1
2(Hza −yobs)R−1(Hza −yobs),
with za given by (7.23). Here we have assumed for simplicity that the empirical
covariance matrix,
P f
M =
1
M −1Af(Af)T,
is invertible. Hint: First demonstrate that za −zf
M = Afδw with the vector
δw ∈RM having entries δwi = wi −1/M and M
i=1 δwi = 0.
7.4
Consider a scalar dynamical system
zn+1 = φ(zn) + ηn,
n ≥0,
(7.36)
where the variables {ηn} are realisations of independent and identically dis-
tributed Gaussian random variables N(0, 1). We also assume that φ(0) = 0 and
the desired reference solution is simply given by zn
ref = 0 and observations are
generated at every iteration according to
yn
obs = ξn,
n ≥1 ,
with the ξn being independent realisations of independent and identically dis-
tributed Gaussians N(0, 4). The initial distribution for the ﬁltering problem is
Gaussian N(0, 2).
Implement the EnKF with perturbed observations and an ESRF for the special
choices φ(z) = −z, φ(z) = z and φ(z) = z3 and ensemble sizes varying from M =

7.3 Guide to literature
223
10 to M = 1000. Compute time-averaged RMSEs over a total of Nobs = 10000
assimilation cycles. How does the RMSE vary for the diﬀerent choices of φ?
7.5
With linear observation operator h(z) = Hz and scalar observations, ﬁnd
the functional J(za
i ) whose minimiser produces the analysis
za
i = zf
i −P f
MHT(HP f
MHT + R)−1(Hzf
i + ξi −yobs)
for the ith ensemble member in an EnKF with perturbed observations (recall
(5.10)). You may assume that P f
M is invertible.
We now consider general nonlinear observation operators h(z). By replacing
Hz with h(z) in the functional J(za
i ) and ﬁnding the equations for the minimiser,
obtain EnKF update formulas when h is nonlinear.
7.6
Implement the EnKF with perturbed observations for the problem de-
scribed in Example 5.9. How does the mean value compare with the MAP esti-
mator value computed in Chapter 5?
7.7
We return to Problem 6.4 and replace the particle ﬁlter implementations
from Problem 6.5 by the ESRF. Study the behaviour of the ﬁlter for M = 10
and increasing dimension Nz ∈{1, 10, 20, . . ., 100, 200} of state space. Compare
your results to those from Problem 6.5. A localised particle ﬁlter was suggested
in Problem 6.6. Can you suggest an extension of the concept of localisation to
the ESRF? Implement your ideas and compare results to those from Problem
6.6.
7.8
Return to Example 7.1 and ﬁnd the associated optimal coupling matrix
T ∗∈R4×4. Which values do the analysis ensemble members za
i ∈R, i = 1, . . . , 4,
take?
7.9
Implement the ETPF for the data assimilation problems described in Prob-
lem 7.4 and compare the resulting time-averaged RMSEs to those obtained for
the two EnKF implementations. Use the algorithm from Appendix 5.8 in order
to implement the ETPF.
7.3
Guide to literature
The McKean approach is discussed in the context of general Feynman–Kac mod-
els in del Moral (2004). In particular, this approach leads to an interpretation of
recursive Bayesian inference as an interacting particle system; this also forms the
basis for the discussion of ensemble-based data assimilation algorithms in this
chapter. A discussion of ensemble Kalman ﬁlters from a linear transformation
perspective can, for example, be found in Tippett, Anderson, Bishop, Hamill
& Whitaker (2003), Wang, Bishop & Julier (2004), Livings, Dance & Nichols
(2008), Ott, Hunt, Szunyogh, Zimin, Kostelich, Corazza, Kalnay, Patil & Yorke
(2004), Hunt, Kostelich & Szunyogh (2007), and Nerger, Pfander, Schr¨oter &
Hiller (2012). A more detailed introduction to ensemble Kalman ﬁlters is given
by Evensen (2006).
There are a number of algorithms which are closely related to the family of

224
McKean approach to data assimilation
ensemble Kalman ﬁlters. The analysis step of the ensemble Kalman ﬁlter with
perturbed observations is, for example, equivalent to a method proposed by
Oliver (1996), which has been generalised to what is now called the randomised
maximum likelihood method (Kitanidis 1995, Oliver, He & Reynolds 1996). The
ensemble square root ﬁlter is, on the other hand, similar to the unscented Kalman
ﬁlter and the reader is referred to Julier & Uhlmann (1997) and S¨arkk¨a (2013)
for more details.
Extensions of the ensemble Kalman ﬁlter to non-Gaussian forecast PDFs and
nonlinear forward operators include the rank histogram ﬁlter (RHF) by Anderson
(2010), the moment matching ﬁlter by Lei & Bickel (2011), and the randomised
maximum likelihood method as already mentioned.
Another broad class of methods is based on Gaussian mixture approximations
to the forecast PDF. The analysis PDF is then also a Gaussian mixture pro-
vided the forward operator h is linear. Compare Example 5.11 from Chapter
5. Several procedures have been proposed to adjust the forecast ensemble such
that the analysis ensemble approximately follows the analysis Gaussian mixture
PDF. See, for example, Smith (2007a), Frei & K¨unsch (2013), Stordal, Karlsen,
Nævdal, Skaug & Vall´es (2011), and Reich (2012).
The idea of using couplings to describe ensemble-based Bayesian inference
and ﬁltering can be found in the survey paper by Reich & Cotter (2013) and
in Moselhy & Marzouk (2012). The ETPF was introduced in Reich (2013b) and
was developed further in Cheng & Reich (2013). A gentle introduction to linear
programming and transport problems can be found in Strang (1986). FastEMD
has been used in our numerical implementations of the ETPF (Pele & Werman
2009).
7.4
Appendix: Linear transport algorithm
The ETPF requires the solution of linear transport problems of type (7.28).
An algorithm for ﬁnding T ∗for one-dimensional ensembles has been stated in
Appendix 5.8. Here we outline an extension of this algorithm to ensembles zf
i ∈
RNz, i = 1, . . . , M, with Nz > 1.
For notational convenience, we introduce
dij := ∥zf
i −zf
j∥2.
The proposed algorithm generates sequences of admissible M × M matrices T ,
where admissible means that
tij ≥0,
M

i=1
tij = 1/M,
and
M

j=1
tij = wi,
for a given set of importance weights wi. We note that the algorithm from Ap-
pendix 5.8 can be used to obtain admissible matrices regardless of whether en-
semble members can be sorted or not. Iterative improvements are based on the

7.4 Appendix: Linear transport algorithm
225
dual formulation in terms of variables ui, i = 1, . . . , M, and vi, i = 1, . . . , M,
which satisfy the inequality constraints
ui + vj ≤dij,
for i, j = 1, . . . , M, and maximise the cost function
V =
M

i=1
(uiwi + vi/M).
The optimal solution satisﬁes
u∗
i + v∗
j = dij,
for all pairs (i, j) for which t∗
ij ̸= 0. We denote the set of such indices as the
supp (T ). See Appendix 2.5 and Strang (1986) for more details on the primal
and dual formulations of linear transport problems.
Algorithm 7.15 (Linear transport problem)
Given an ensemble {zf
i}M
i=1, im-
portance weights wi, and distances dij, an initial admissible T (0) is found by
applying the algorithm from Appendix 5.8. The cost of T (0) is given by
C(0) =
M

i,j=1
t(0)
ij dij.
A sequence of admissible matrices {T (l)} with associated costs
C(l) =
M

i,j=1
t(l)
ij dij,
l ≥0,
is now generated by the following procedure.
(i) Choose values {ui} and {vj} such that ui + vj = dij for pairs (i, j) ∈
supp (T (l)). Start with u1 = 0.
(ii) If ui + vj ≤dij for all pairs (i, j) then the algorithm terminates and T ∗=
T (l). Otherwise ﬁnd the pair (i∗, j∗) for which ui + vj −dij is maximised.
(iii) Set
t(l+1)
i∗j∗
= ε,
where ε > 0 is yet to be determined. Adjust t(l)
ij > 0 to
t(l+1)
ij
= t(l)
ij ± ε,
for an appropriate subset S of indices (i, j) ∈supp (T (l)) in order to keep
the new T (l+1) admissible. Pick ε > 0 such that at least one t(l+1)
ij
= t(l)
ij −ε
drops to zero.

226
McKean approach to data assimilation
The set S ⊂{1, . . ., M}×{1, . . ., M} in step (iii) needs to be chosen such that
the entries of T (l+1) −T (l) sum to zero across all rows and columns.
We remark that the algorithm needs to be modiﬁed if fewer than 2M −1
entries in a T (l) are non-zero. In this case the sets of values {ui} and {vj} in
Step (ii) are not uniquely determined. There are also more eﬃcient algorithms
available for solving linear transport problems. Their computational complexity
is O(M 3 ln M) with respect to the ensemble size M. For the computational
experiments in this book we have used the FastEMD algorithm developed by
Pele & Werman (2009). FastEMD is available as a Matlab subroutine.
Example 7.16
Consider the following linear transport problem for which the
entries of the optimal T ∗∈RN×M take integer values and T is no longer a
square matrix, i.e., N ̸= M. We set N = 3 and M = 5. Admissible transport
plans T ∈R3×5 are now deﬁned by the conditions tij ≥0,
5

j=1
tij = Si,
3

i=1
tij = Dj,
with S1 = 15, S2 = 20, S3 = 15, D1 = 11, D2 = 12, D3 = 9, D4 = 10, and
D5 = 8. Note that we still have 
i Si = 
j Dj while no longer being equal to
one. The transport costs dij are given by the following table:
dij
1
2
3
4
5
1
51
62
35
45
56
2
59
68
50
39
46
3
49
56
53
51
37
The optimal transport plan T ∗is provided by
t∗
ij
1
2
3
4
5
1
6
0
9
0
0
2
2
0
0
10
8
3
3
12
0
0
0
You might want to derive this optimal transport plan through an appropriate
adaptation of Algorithm 7.15.
7.5
Appendix: Gaussian mixture transform ﬁlter
In this appendix we discuss an alternative ETPF implementation which replaces
the ensemble generated empirical measure by Gaussian mixtures of the form
πZf(z) = 1
M
M

i=1
n(z; zf
i, B).
(7.37)

7.5 Appendix: Gaussian mixture transform ﬁlter
227
Recall that n(z; z, B) denotes the PDF of a Gaussian with mean z and covariance
matrix B. The forecast ensemble members zf
i are the centres of the Gaussian
mixture components while the covariance matrix can either be set to B = τI
with τ > 0 a bandwidth parameter or to
B = τP f
M.
(7.38)
Provided that an observation comes from a linear forward model
yobs(tk) = Hzref(tk) + ξk,
with ξk being a realisation of a Gaussian with mean zero and covariance matrix
R, the analysis PDF can be explicitly computed and is given by
πZ(z|yobs) =
M

i=1
αin(z; zc
i , Bc),
as already discussed in Example 5.10. Here the parameters entering the analysis
PDF are deﬁned as follows:
αi ∝exp

−1
2(Hzf
i −yobs(tk))T(HBHT + R)−1(Hzf
i −yobs(tk))

,
with the constant of proportionality chosen such that  αi = 1,
zc
i = zf
i −K(Hzf
i −yobs(tk)),
(7.39)
and
Bc = B −KHB,
(7.40)
with Kalman gain matrix K = BHT(HBHT + R)−1.
We now construct a (non-optimal) coupling between the prior and posterior
Gaussian mixtures. The ﬁrst step consists in solving the linear transport problem
T ∗= arg min
M

i,j=1
tij∥zc
i −zc
j∥2,
(7.41)
for non-negative tij subject to
M

i=1
tij = 1/M,
M

j=1
tij = αi.
We then deﬁne new Gaussian centres by
zc
j =
M

i=1
zc
i pij,
pij := Mt∗
ij,
for j = 1, . . . , M, and ﬁnally obtain an analysis ensemble za
j , j = 1, . . . , M, by
drawing a single realisation from each of the Gaussian distributions N(zc
j, Bc),
i.e.,
za
i = Za
i (ω),
Za
i ∼N(zc
i, Bc).
(7.42)

228
McKean approach to data assimilation
We call this ﬁlter the Gaussian mixture transform ﬁlter. The Gaussian mixture
transform ﬁlter converges to the ETPF as the bandwidth τ in (7.38) approaches
zero.
In practice a bandwidth τ needs to be determined. Assume that a ﬁnite set
of observed or computed state estimates ˆzref(tk), k = 1, . . . , Nobs, is available.
These estimates can be used as a training set in order to determine an appropriate
τ > 0. For example, one possibility is to choose the parameter τ in the covariance
matrix B = τI or B = τP f
M such that the value of the time-averaged logarithmic
scoring rule, i.e.,
Slog(τ) := −1
Nobs
Nobs

k=1
ln
0
1
M
M

i=1
n(ˆzref(tk); zi(tk), B)
?
,
is minimised along an ensemble {zi(tk)} of model predictions.

8
Data assimilation for
spatio-temporal processes
So far we have investigated the behaviour of data assimilation algorithms for
models with state space dimension Nz ≤3. Furthermore, we have investigated
the behaviour of ensemble-based data assimilation algorithms for ensemble sizes
M ≫Nz. Classical theoretical results about particle ﬁlters discuss convergence
to the optimal estimates for M →∞within the perfect model scenario and
with ﬁxed dimension of state space Nz. While we do not cover these theoretical
results in this book, in the previous two chapters we found that the particle
ﬁlters did indeed converge numerically in terms of their time-averaged RMSEs
as the ensemble size M was increased. In fact, the same observation also applies
to the ensemble Kalman ﬁlters. However, an ensemble Kalman ﬁlter does not
generally converge to the optimal estimates because of a systematic bias due
to the Gaussian assumption in the Bayesian inference step. Nevertheless, the
ensemble Kalman ﬁlter remains a very popular method in the geosciences since
it has much better control over the variance error for small ensemble sizes.
In this chapter, we will apply ensemble-based data assimilation algorithms to
models which arise from spatio-temporal processes. More speciﬁcally, the mod-
els from this chapter can be viewed as spatial and temporal discretisations of
partial diﬀerential equations (PDEs). For simplicity, we will only consider evolu-
tionary PDEs in one spatial dimension (denoted by x). The dimension of state
space of the arising models is inversely proportional to the spatial discretisa-
tion parameter Δx and the limit Δx →0 leads to Nz →∞. While a rigorous
analysis of data assimilation algorithms for M ﬁxed and Nz →∞is beyond
the scope of this book, we will demonstrate some of the practical problems that
arise from such a scenario, which is often referred to as the curse of dimensional-
ity.1 We will also introduce ensemble inﬂation and localisation2 as two practical
techniques for making ensemble-based data assimilation techniques applicable to
spatio-temporal processes.
We start this chapter with a simple example that demonstrates how ﬁnite
ensemble sizes M can have a systematic impact on the behaviour of an ensemble
1 The diﬃculty with high-dimensional problems can already be appreciated from the
following well-known fact: the probability of a sample drawn uniformly from a hypercube
in RNz hitting the embedded hypersphere goes to zero as Nz →∞.
2 We have already discussed the implementation of particle ﬁlters and EnKFs for a trivially
high-dimensional problem in Problems 6 4 to 6.6 and Problem 7.7. The localisation idea,
proposed in Problem 6.6 will be extended to spatio-temporal processes in this chapter.

230
Data assimilation for spatio-temporal processes
Kalman ﬁlter. Recall that an ensemble Kalman ﬁlter is built upon the empirical
forecast covariance matrix P f
M and the resulting Kalman gain matrix, K =
P f
MHT(HP f
MH + R)−1, which is needed for updating the ensemble mean and
for transforming P f
M into an analysis covariance P a.
Example 8.1
We consider the empirical estimator for the covariance matrix
P f
M =
1
M −1
M

i=1
(zf
i −zf
M)(zf
i −zf
M)T,
zf
M = 1
M
M

i=1
zf
i,
(8.1)
for M samples zf
i ∈RNz from a Gaussian random variable Zf ∼N(0, I). It is
known that the estimator is unbiased, i.e.
E[P f
M] = I.
However, any ﬁnite M leads to a non-vanishing variance in the estimator. In
this example, we will assess this variance numerically, taking Nz = 10 and using
ensembles of size M > 10. We will inspect two aspects of P f
M which will be of
particular relevance in this chapter. First, we consider spurious cross-correlations
pkl := (P f
M)kl, k ̸= l, in P f
M, which we quantify by averaging the quantity
c =
1
Nz(Nz −1)
Nz

l,k=1,l̸=k
|pkl|
(8.2)
over one thousand ensembles {zf
i} of size M. We know that |pkl| →0, k ̸= l,
as M →0. Second, we consider |P f
M|1/Nz as a measure of how much the overall
variance in the samples is underestimated or overestimated. Again we know a
priori that |P f
M|1/Nz →1 as M →∞and |P f
M| = 0 for M ≤Nz.
The average over ensembles {zf
i}M
i=1 with M ranging between 11 and 2000
can be found in Figure 8.1. Not unexpectedly, on average the empirical P f
M
underestimates the true value of the determinant of the covariance matrix and
signiﬁcant spurious correlations arise even for moderate values of M. In other
words, the ensemble spread is likely to be too small, implying that the true
forecast uncertainties are underestimated. Furthermore, spurious correlations are
introduced, which are not present in the underlying statistical reference model.
Both these phenomena can have catastrophic eﬀects on the performance of an
ensemble data assimilation algorithm.
Note that an EnKF can be interpreted as ﬁrst computing an analysis ensemble
{ya
i } in observation space which is then mapped back onto state space by the
linear regression formula
za
i = zf
i + P f
MHT(HP f
MHT)−1(ya
i −yf
i)
with yf
i := Hzf
i. Hence spurious correlations in P f
M, as found in Example 8.1, im-
ply spurious correlations in P f
MHT. These spurious correlations in turn lead to

Data assimilation for spatio-temporal processes
231
0
500
1000
1500
2000
0 4
0 5
0 6
0 7
0 8
0 9
1
ensemble size M
determinant of empirical covariance matrix
0
500
1000
1500
2000
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
ensemble size M
spurious correlations
Figure 8.1 We display values of |P f
M|1/Nz (left panel) and the quantity c in Equation
(8.2) (right panel), for Nz = 10, having averaged over one thousand ensembles of size M,
displayed as a function of the ensemble size M. The realisations are drawn from a
Gaussian distribution with mean zero and covariance matrix P f = I. Hence the analytic
value for |P f|1/Nz is one and the analytic values of the oﬀ-diagonal terms of P f are all
zero. These values are indeed approached by P f
M as M →∞, but modest ensemble sizes
lead to a signiﬁcant underestimation of |P f|1/Nz together with spurious non-zero cross
correlations.
an erroneous transformation of the increments Δyi = ya
i −yf
i back to state space.
The problem of spurious correlations between observation and state space vari-
ables becomes particularly relevant for data assimilation problems which involve
spatio-temporal evolution models. In such cases the ensemble sizes are often rela-
tively small, since each run of the spatio-temporal model can be computationally
demanding. Furthermore, spurious correlations between an observation and spa-
tial locations far from the actual measurement can clearly impact negatively on
the performance of a data assimilation algorithm.
In the ensemble Kalman ﬁlter literature, ensemble inﬂation and localisation
are two techniques for dealing with small ensemble sizes which have become pop-
ular in the context of spatio-temporal systems. Localisation reduces the impact
of spurious correlations between observation and state space, whilst ensemble
inﬂation increases the ensemble spread in order to avoid an underestimation of
the reduced Kalman gain matrix
HK = HP f
MHT(HP f
MHT + R)−1,
in the update of the ensemble mean
ya = yf
M −HK(yf
M −yobs),
in observation space. This correction is important, since an underestimation of
HK can lead to ﬁlter divergence, i.e., the ﬁlter is no longer able to track the
reference solution.

232
Data assimilation for spatio-temporal processes
Definition 8.2 (Filter divergence)
Given reference values yref(tk), associated
observations yobs(tk), and ensemble values yi(tk), k = 1, . . . , Nobs, from a ﬁlter
algorithm, we speak of ﬁlter divergence if
Nobs

k=1
(yref(tk) −yM(tk))2 ≫
Nobs

k=1
(yref(tk) −yobs(tk))2,
i.e., the ensemble means, as produced by a ﬁlter algorithm, yield a prediction for
the underlying reference values which is much worse than using the observations
alone.
Example 8.3
Filter divergence can arise when the ensemble spread becomes
much smaller than the distance of the ensemble mean to an observation, i.e.,
max
i=1,...,M |yi(tk) −yM(tk)| ≪|yobs(tk) −yM(tk)|.
In an extreme case y1(tk) = y2(tk) = · · · = yM(tk) in which case the induced
Kalman gain matrix becomes K = 0 and any observed yobs(tk) gets completely
ignored by the ﬁlter.
In this chapter, we will also demonstrate how localisation and inﬂation can
be applied to particle ﬁlters and how these techniques improve the performance
of particle ﬁlters for spatio-temporal dynamical systems. However, before we
describe ensemble inﬂation and localisation in more detail, we introduce the
spatio-temporal model systems which will be used throughout this chapter.
8.1
Spatio-temporal model systems
For simplicity, we restrict our discussion to PDEs with a single spatial variable,
which we denote by x and which will be restricted to a periodic domain x ∈[0, L]
of length L > 0. Hence, our state space variables z ∈RNz are replaced by
functions u(x) which are periodic in x, i.e., u(x) = u(x + L).3 Below we discuss
a few speciﬁc PDEs which naturally arise in the context of geophysical ﬂuid
dynamics, together with their numerical treatment, which immediately leads
back to a ﬁnite-dimensional state space with Nz ≫1. All of these models are
popular in the data assimilation literature as toy models for testing assimilation
algorithms, since they provide an intermediate step between low-dimensional
ODEs and more realistic, but complex, geophysical models.
We start with the linear advection equation
∂u
∂t = −a∂u
∂x,
(8.3)
3 The spatial domain should be viewed as a circle with circumference L and serves us as a
simple one-dimensional “approximation” to the two-dimensional spherical shape of the
Earth.

8.1 Spatio-temporal model systems
233
which implicitly characterises the time evolution of the function u in time, i.e.,
the desired u is a function of space and time with its partial derivatives related
by (8.3) for all (x, t), x ∈[0, L], t ≥0. The advection velocity a ∈R is assumed to
be constant. We are, in addition, given u(x, t) at time t = 0, i.e., u(x, 0) = u0(x)
for given u0. The function u0 is called the initial condition.
The task is to ﬁnd the function u(x, t) that simultaneously satisﬁes (8.3) and
the initial condition. First, note that any function u of the special form u(x, t) =
ρ(x −at) has partial derivatives
∂u
∂t (x, t) = −aρ′(x −at),
∂u
∂x(x, t) = ρ′(x −at),
and therefore satisﬁes (8.3). Here ρ : R →R is a diﬀerentiable function and
ρ′ denotes its derivative. Second, note that u(x, 0) = ρ(x) and the given initial
condition implies that ρ(x) = u0(x) for x ∈[0, L] and ρ(x) = u0(x mod L) for
all x ∈R by periodic extension.4 Hence we have deduced that
u(x, t) = u0(x −at mod L)
provides a solution to (8.3) given the initial condition u(x, 0) = u0(x) (existence
of a solution to the initial value problem). It could be possible that more than
one solution exists (non-uniqueness of the initial value problem) but this turns
out not to be the case for the linear advection equation. A closer inspection
reveals that u(x, t) is constant along straight lines in the (x, t) plane deﬁned by
x = x0 + at for given x0 ∈[0, L]. These straight lines are called characteristics
and satisfy the diﬀerential equation
dx
dt = a
with initial condition x(0) = x0. This equation also explains why a is called
the advection velocity. For periodic boundary conditions we must replace x(t) =
x0 + at by x0 + at mod L.
We can generalise the linear advection equation by replacing the constant a
by a function which depends on x (and possibly also on time t). Hence we obtain
the diﬀerential equation
dx
dt = a(x)
(8.4)
for the characteristics, which we need to solve for all initial conditions x(0) =
x0 ∈[0, L]. We denote the solutions with initial condition x0 by x(t; x0). As for
the linear advection equation with constant velocity, we say that the time evo-
lution of a function u(x, t) with initial condition u(x, 0) = u0(x) is characterised
by
u(x(t; x0), t) = u0(x0),
t ≥0.
However, the last equation says that u(x(t; x0), t) is constant in time. This implies
4 Here a mod b stands for a modulo b, which is the remainder of the division of a by b.

234
Data assimilation for spatio-temporal processes
that its total derivative with respect to time has to vanish, i.e.,
du
dt = ∂u
∂x
dx
dt + ∂u
∂t
= ∂u
∂xa(x) + ∂u
∂t = 0.
(8.5)
Upon rearranging (8.5) we obtain the generalised linear advection equation
∂u
∂t = −a(x)∂u
∂x.
(8.6)
We have shown that solving a rather complicated looking evolutionary PDE can
be reduced to solving the ODE (8.4).
We now describe a numerical discretisation method based upon this structure.
We discretise the interval [0, L] into Nd equal intervals of length Δx = L/Nd
and introduce equally spaced initial positions x0
k := kΔx for k = 1, . . . , Nd. We
next take the solutions of the ODE (8.4) with those initial values, i.e., x(0) = x0
k,
k = 1, . . . , Nd, and abbreviate these solutions x(t; x0
k) by xk(t). Then
u(xk(t), t) = u0(xk(0)).
Furthermore, if xk(t) falls outside the domain [0, L] for some t > 0, then we make
use of
u(xk(t) ± L, t) = u(xk(t), t)
to map xk(t) back onto the domain [0, L]. Hence we always end up with Nd points
xk(t) ∈[0, L] with constant function values uk = u0(xk(0)). The pairs (xk(t), uk)
can be linearly interpolated in order to get a continuous function ˜u(x, t) which
serves as a numerical approximation to the analytic u(x, t). This is called the
method of characteristics. Note that ˜u(xk(t), t) = u(xk(t), t) along all computed
characteristics and we anticipate convergence of ˜u(x, t) to u(x, t) for ﬁxed t > 0
and all x ∈[0, L] as Δx →0 (Nd →∞).
Example 8.4
Consider advection under the spatially- and temporally-periodic
velocity ﬁeld
a(x, t) = sin(2πx) cos(πt)
(8.7)
with periodic boundary conditions over the domain x ∈[0, 1], i.e., L = 1. The
initial ﬁeld is u0(x) = sin(2πx). We implement the method of characteristics by
subdividing the interval [0, 1] into Nd = 100 subintervals of length Δx = 0.01.
The initial positions of the characteristics are x0
k = kΔx, k = 1, . . . , 100, with
constant solution values uk = sin(2πkΔx). The positions evolve in time under
the forward Euler discretisation
xn+1
k
= xn
k + Δt sin(2πxn
k) cos(πtn),
tn = nΔt,
with step-size Δt = 0.001. Periodic boundary conditions are used to map xn+1
k
back onto [0, 1] if necessary. The numerical results are displayed in Figure 8.2.

8.1 Spatio-temporal model systems
235
0
1
2
3
4
0
0 2
0 4
0 6
0 8
1
1
0 5
0
0 5
1
space
time
Figure 8.2 Numerical results from the
method of characteristics applied to the
linear advection equation with advecting
velocity ﬁeld given by (8.7).
The method of characteristics works very well in one spatial dimension but it
becomes more complicated in more than one spatial dimension. An alternative
discretisation method is based on the idea of ﬁnite diﬀerences, which can be
directly applied to the PDE (8.6) and more easily generalises to higher spatial
dimensions. In addition to the temporal grid tn = nΔt we now introduce a
ﬁxed spatial grid xk = kΔx. An approximation of u at the ﬁxed spatio-temporal
location (xk, tn) is denoted by un
k and we replace partial derivatives by ﬁnite
diﬀerence approximations such as
∂u
∂t (xk, tn) ≈u(xk, tn + Δt) −u(xk, tn)
Δt
≈un+1
k
−un
k
Δt
for the ﬁrst-order temporal derivative and
∂u
∂x(xk, tn) ≈u(xk, tn) −u(xk −Δx, tn)
Δx
≈un
k −un
k−1
Δx
,
or
∂u
∂x(xk, tn) ≈u(xk + Δx, tn) −u(xk, tn)
Δx
≈un
k+1 −un
k
Δx
.
for the ﬁrst-order spatial derivative. Plugging these ﬁnite diﬀerence approxima-
tions into (8.6) and rearranging terms into an explicit iteration in the temporal
iteration index n, we obtain two examples of possible discretisations,
un+1
k
= un
k −a(xk)Δt
Δx
(un
k+1 −un
k)
(right diﬀerencing),
(8.8)
and
un+1
k
= un
k −a(xk)Δt
Δx
(un
k −un
k−1)
(left diﬀerencing),
(8.9)
respectively. Without going into technical details, we state that for stable results,
the spatial mesh-size Δx and the time-step-size Δt needs to be chosen such that
|a(xk)| Δt
Δx ≤1,

236
Data assimilation for spatio-temporal processes
and that the right diﬀerencing scheme (8.8) is used whenever a(xk) ≤0 and the
left diﬀerencing scheme is used if a(xk) > 0 (this is called the upwind method,
since the spatial diﬀerence is evaluating in the upwind direction). The numerical
approximation scheme is now completed by setting u0
k = u0(xk) and by cycling
through all xk, k = 1, . . . , Nd, for each n ≥0. Once again we make use of
periodicity in the spatial domain, i.e., un
k = un
k±Nd, in order to deﬁne spatial
ﬁnite diﬀerence approximations near the boundaries at x = 0 and x = L.
Example 8.5
We apply the upwind method to the advection equations with
advecting velocity ﬁeld (8.7). We compare numerical results for a spatial mesh of
Δx = 0.01 and time-step Δt = 0.01 to those for Δx = 0.001 and Δt = 0.001 in
Figure 8.3. We observe that the coarser resolution leads to a signiﬁcant numer-
ical damping of the advected solution while Δx = 0.001 leads to results closer
to those obtained from the method of characteristics in Example 8.6. Compare
Figure 8.3. This numerical example demonstrates that discretisations of partial
diﬀerential equations can lead to signiﬁcant systematic errors unless the discreti-
sation parameters are chosen suﬃciently small. Further problems can arise from
unstable discretisations (such as interchanging left diﬀerencing with right dif-
ferencing and vice versa). We will not discuss these numerical issues further in
this book, but they must be taken into account when applying data assimilation
algorithms to real world problems. This renders the perfect model scenario often
used in theoretical studies rather unrealistic from a practical perspective.
Let us now complicate matters further by replacing the predeﬁned advection
velocity a(x, t) by the unknown function u(x, t) itself. This leads us to the non-
linear advection equation
∂u
∂t = −u∂u
∂x = −1
2
∂(u)2
∂x .
The solution theory for this PDE is rather more complicated than the equations
considered so far. To avoid the technical discussion of shocks and rarefactions,
we immediately move on to Burgers’ equation
∂u
∂t = −1
2
∂(u)2
∂x
+ μ∂2u
∂x2
(8.10)
with viscosity coeﬃcient μ > 0 and initial velocity ﬁeld u0(x). A ﬁnite diﬀerence
approximation is provided by
un+1
k
−un
k
Δt
= −(un
k+1)2 −(un
k−1)2
4Δx
+ μun
k+1 −2un
k + un
k−1
Δx2
(8.11)
with the step-size chosen such that
Δt < min{Δx2/μ, umaxΔx/2},
umax := max
x∈[0,L]|u0(x)|.
It turns out that the time evolution of u(x, t) under Burgers’ equation leads

8.1 Spatio-temporal model systems
237
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1
1
0.5
0
0.5
1
space
time
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1
1
0.5
0
0.5
1
space
time
Figure 8.3 Numerical results from the upwind method applied to the advection equation
with advecting velocity ﬁeld (8.7). The top panel has been obtained for spatial mesh-size
Δx = 0.01 while the bottom panel is for Δx = 0.001. These results should be compared
to those from the method of characteristics (Figure 8.2). It is obvious that Δx = 0.01
leads to a severe artiﬁcial damping of the advected sine wave.
to a constant function as t →∞, regardless of the initial velocity ﬁeld u0(x);
this is due to the non-vanishing viscosity. This makes prediction of the solution
at long times insuﬃciently challenging, and hence we need to make alterations
in order to obtain a good model for assessing data assimilation algorithms. We

238
Data assimilation for spatio-temporal processes
do this by adding random additive forcing to obtain
∂u
∂t = −1
2
∂(u)2
∂x
+ μ∂2u
∂x2 +
Nf

l=1
ζl(t) sin
2πl
L x

,
(8.12)
where the time-dependent coeﬃcients ζl satisfy the following SDEs,
dζl = −l2ζldt + dWl,
l = 1, . . . , Nf,
(8.13)
and the variables {Wl(t)} denote mutually independent standard Brownian mo-
tions. The model description is completed by setting the length of the domain
to L = 1, the viscosity coeﬃcient to μ = 0.0005, and the number of stochastic
modes to Nf = 20.
Example 8.6 We describe a computational implementation of the model (8.12)–
(8.13). In a ﬁrst step only the spatial domain [0, 1] is subdivided into 100 intervals
of length Δx = 0.01. Numerical approximations at the grid points xk = kΔx are
denoted by uk(t). Using basic ﬁnite-diﬀerence approximations for the spatial par-
tial derivatives in (8.12) we obtain the spatially discretised system of stochastic
diﬀerential equations
duk
dt = −(uk+1)2 −(uk−1)2
4Δx
+ μuk+1 −2uk + uk−1
Δx2
+
20

l=1
ζl(t) sin (2πlxk) ,
(8.14)
where the evolution of the variables {ζl} is determined by (8.13).
We next apply the forward Euler method to discretise (8.13) and (8.14) in
time with step-size Δt resulting in
un+1
k
= un
k −Δt(un
k+1)2 −(un
k−1)2
4Δx
+ μΔtun
k+1 −2un
k + un
k−1
Δx2
+ Δt
20

l=1
ζn
l sin (2πlxk) ,
(8.15)
ζn+1
l
= ζn
l −l2Δtζn
l + Δt1/2ξn
l ,
(8.16)
with the variables {ξn
l } denoting mutually independent realisations of standard
Gaussian random variables with mean zero and variance one. The step-size is
set equal to Δt = 0.001. We collect the complete set of state variables {un
k} and
{ζn
l } into the state vector zn ∈RNd+Nf with Nd + Nf = 120.
Simulations are started from the trivial initial conditions u0(x) = 0, ζl(0) = 0,
and ensemble prediction is performed by applying diﬀerent realisations of the
noise terms {ξn
l } to each ensemble member. The ensemble sizes range from M = 5
to M = 1000 and ensemble members at tn = nΔt are denoted by zn
i .

8.1 Spatio-temporal model systems
239
We monitor the time evolution of the empirical covariance matrices
P n
M =
1
M −1
M

i=1
Qu(zn
i −zn
M)(zn
i −zn
M)TQT
u,
where Qu : RNd+Nf →RNd projects zn onto its {un
k} components. Example 8.1
provided a demonstration that ﬁnite ensemble sizes lead to an underestimation
of |P n
M|. Instead, in this example we monitor the time evolution of the leading
singular value of P n
M and its dependence on the ensemble size M. The result is
shown in Figure 8.4. Small ensemble sizes of M = 5, 10 lead to large ﬂuctuations
in the leading singular value of the system, but the results with M = 100 agree
extremely well with the results for M = 1000 and so it appears that the nu-
merical results have converged. We also conclude that the leading singular value
approaches an asymptotic value close to 10 for this system. A typical spatio-
temporal structure of the u(x, t) solution ﬁelds is also displayed in Figure 8.4.
In addition to the stochastically forced PDE model we will use the dynamical
system
duk
dt = −uk−1uk+1 −uk−2uk−1
3Δx
−uk + F,
k = 1, . . . , 40,
(8.17)
known as the Lorenz-96 model, as a model for testing data assimilation algo-
rithms. This system can be seen as a coarse spatial approximation to the forced-
dissipative PDE
∂u
∂t = −1
2
∂(u)2
∂x
−u + F,
with a particular spatial discretisation of the nonlinear advection term, mesh-
size Δx = 1/3, Nd = 40 grid points and domain length L = 40/3. Here F > 0
is a constant forcing term and periodic boundary conditions are assumed, i.e.,
uk±40(t) = uk(t). Furthermore, the viscosity term μuxx in Burgers’ equation has
been replaced by the Newtonian damping term −u.
Example 8.7
We now repeat the numerical experiments conducted in Example
8.6 with the model (8.12)–(8.13) being replaced by the Lorenz-96 model (8.17).
The diﬀerential equations (8.17) are discretised in time by the forward Euler
method with step-size Δt = 0.001. The initial conditions are drawn from the
Gaussian N(0, I) distribution. We compare results obtained with two diﬀerent
values F = 2 and F = 8 for the forcing term. We again display typical spatio-
temporal solution ﬁelds and the time-evolved leading singular value of ensemble
generated covariance matrices in Figures 8.5 and 8.6, respectively. Note that
the randomly generated initial ensembles already lead to an increased leading
singular value for small ensemble sizes. Furthermore, F = 8 leads to a dramatic
increase in the the leading singular value of the Lorenz-96 model and the spatial
structure of the solution ﬁelds is highly irregular in both cases. It can be expected

240
Data assimilation for spatio-temporal processes
0
2
4
6
8
10
0
5
10
15
20
25
time
leading singular value of P
 
 
M=5
M = 10
M=100
M=1000
10
11
12
13
14
15
0
0 5
1
1 5
1
0 5
0
0 5
1
1 5
time
space
Figure 8.4 Ensemble prediction for the model system (8.12)–(8.13). The numerical
implementation is described in Example 8.6. We display a typical u(x, t) ﬁeld in the
bottom panel while the top panel shows the time evolution of the leading singular value of
the ensemble generated empirical covariance matrices for four diﬀerent ensemble sizes.
Small ensemble sizes lead to large ﬂuctuations in the leading singular value of the system
while M = 100 and M = 1000 lead to essentially identical results.
that (8.17) with F = 8 will provide a tough test case for any data assimilation
scheme.

8.1 Spatio-temporal model systems
241
0
1
2
3
4
5
6
7
8
0
5
10
15
20
25
30
35
40
45
time
leading singular value of P
 
 
M 5
M  10
M 100
M 1000
8
10
12
14
16
0
10
20
30
40
−1
0
1
2
3
time
space
Figure 8.5 Ensemble prediction for the Lorenz-96 model (8.17) with F = 2. We display
a typical u(x, t) ﬁeld in the right panel while the left panel shows the time evolution of
the leading singular value of the ensemble generated empirical covariance matrices for
four diﬀerent ensemble sizes. Small ensemble sizes lead to an overestimation of the
leading singular value of the system while M = 100 and M = 1000 lead to essentially
identical results. We conclude that the leading singular value approaches an asymptotic
value close to 10 for this system.
0
1
2
3
4
5
6
7
8
0
100
200
300
400
500
600
time
leading singular value of P
 
 
M 5
M  10
M 100
M 1000
8
10
12
14
16
0
10
20
30
40
−10
−5
0
5
10
15
time
space
Figure 8.6 Lorenz-96 model (8.17) with F = 8. The spatio-temporal ﬁelds (right panel)
become much more irregular (compare Figure 8.5) and the asymptotic value of the
leading singular value increases to about 40.
We ﬁnally specify the process of generating observations for the purpose of
testing assimilation algorithms. Throughout this chapter we will concentrate
on the simpliﬁed identical twin experiment/perfect model setting in which the
reference solution and model forecasts are generated from the same numerical
model. Systematic biases between forecast models and reference solutions and

242
Data assimilation for spatio-temporal processes
their impact on data assimilation will be explored in Chapter 9. The reference
solution will be denoted by uref(x, t), which has been extended from computed
grid values un
k,ref by bilinear interpolation to arbitrary values of (x, t) ∈[0, L] ×
[0, tend]. We observe grid point values of uref(x, t) subject to measurement errors,
i.e.,
yn
obs(xk) = uref(xk, tn) + ξn
k ,
with observations taken in spatial intervals of Δxout and in temporal intervals
of Δtout, i.e.,
xk = kΔxout,
tn = nΔtout.
The measurement errors ξn
k are mutually independent and Gaussian distributed
with mean zero and variance R. In general, the observation grid {(xk, tn)} will
be coarser than the computational grid {(xk, tn)}.
Therefore, in the context of Laplace’s demon, we are considering the situation
where our model is a perfect replica of “reality”. In the case of the Lorenz-96
model (8.17), it is also directly computable (up to round-oﬀerrors due to ﬁnite
machine precision). Hence forecast/analysis uncertainties only arise from uncer-
tain initial conditions as well as partial and noisy observations of the current
model states. The situation is slightly more complex for the stochastic model
(8.15)–(8.16), where the unknown stochastic forcing terms represent an addi-
tional source of uncertainty.
In the remainder of this chapter we discuss the application of the ensemble
transform ﬁlters of Chapter 7 to the Lorenz-96 model (8.17) and the model
(8.13)–(8.14). Two additional techniques need to be introduced in order to obtain
acceptable results when applying these ﬁlters to spatio-temporal processes. These
are ensemble inﬂation and localisation. We start with the concept of ensemble
inﬂation.
We continue using the notation z ∈RNz with Nz = Nd + Nf and Nz = Nd,
respectively, for the state variables of our spatially discretised spatio-temporal
models (8.13)–(8.14) and (8.17), respectively, unless stated otherwise. We will
also use the notation z(xk) in order to denote the value of z at the spatial
location xk, for example z(xk) = uk, and to emphasise the spatial dependence
of the entries in the state vector z.
8.2
Ensemble inﬂation
The simple idea behind ensemble inﬂation is to increase the spread of a forecast
ensemble {zf
i} about its mean zf
M. In other words, we artiﬁcially increase the
forecast uncertainty in order to make an ensemble Kalman ﬁlter implementation
more robust against the ﬁnite ensemble size eﬀects, as discussed at the beginning
of this chapter, and deviations from the assumed Gaussian behaviour of the
forecast ensemble.

8.2 Ensemble inﬂation
243
Definition 8.8 (Ensemble inﬂation)
Given a forecast ensemble zf
i ∈RNz, i =
1, . . . , M, we ﬁrst compute its empirical mean zf
M and the ensemble anomalies
Δzi := zf
i −zf
M. An inﬂated ensemble is deﬁned by
zf
i := zf
M + α Δzf
i
(8.18)
with inﬂation factor α > 1.
The approach (8.18) is called multiplicative ensemble inﬂation. Alternatively,
we could apply particle rejuvenation, following Deﬁnition 6.13, in order to re-
place the forecast ensemble by zf
i + ξi, where the variables {ξi} are independent
realisations of some chosen random variable Ξ with zero mean. Such an addi-
tive ensemble inﬂation strategy is often associated with stochastic model errors,
but multiplicative inﬂation has been found to be more eﬀective in the context
of ensemble Kalman ﬁlter implementations. Note that multiplicative ensemble
inﬂation is typically applied prior to an assimilation step.
We apply the ensemble Kalman ﬁlter with inﬂation to the model system (8.12)–
(8.13) as described in Example 8.6 and to the Lorenz-96 model (8.17) as described
in Example 8.7. We have already found that (8.12)–(8.13) leads to solutions which
are much more spatially regular than those of (8.17). Furthermore, (8.17) is de-
terministic with a large leading singular value of the ensemble covariance matrix
while (8.12)–(8.13) are stochastically driven with a smaller leading singular value
of the associated time-evolved ensemble covariance matrices.
Example 8.9
Consider (8.12)–(8.13) over a spatially-periodic domain of length
L = 1 as outlined in Example 8.6. The computational grid has grid-spacing
Δx = 0.01, and the u variable is observed every fourth grid-point (implying that
Δxout = 0.04). Measurement errors are mutually uncorrelated with variance
R = 0.01, and the forward model at an observation time tn is
yn
obs(xk) = uref(xk, tn) + ξn
k ,
xk = kΔxout, tn = nΔtout.
The step-size is Δt = 0.001 and observations are taken every 125 time-steps,
i.e., Δtout = 0.125. A total of 5100 data assimilation cycles are performed, with
the ﬁrst 100 cycles being used for equilibration of the algorithm.
We compare the performance of the EnKF with perturbed observations (i)
without inﬂation and (ii) with multiplicative inﬂation using an inﬂation factor α
from the range {1.05, 1.1, . . ., 1.2}. The comparison is made using the spatially-
and temporally-averaged RMSE:
RMSE =

	
	

1
NobsNd
Nd

k=1
Nobs

n=1
|uref(xk, tn) −ua
M(xk, tn)|2.
Here ua
M(xk, tn) := Quza
M(xk, tn) and za
M(xk, tn) denotes the ensemble mean of
the analysis ensemble at grid point xk = kΔx and observation time
tn = nΔtout = 125 n Δt = 0.125 n.

244
Data assimilation for spatio-temporal processes
Table 8.1 Spatially- and temporally-averaged RMSEs for the EnKF with perturbed
observations, applied to the model system (8.12)–(8.13), as a function of the ensemble
size M ∈{5, 10, 20, 40, 100}. The table also states the inﬂation factors which lead to the
smallest time-averaged RMSEs. If the stated inﬂation factor is 1.0 then using no inﬂation
is optimal. It can be concluded that the eﬀect of ensemble inﬂation is signiﬁcant only at
the smallest ensemble size of M = 5.
RMSE/inﬂation factor
No inﬂation
Optimal inﬂation
M = 5
0.1064
0.0680/1.15
M = 10
0.0483
0.0457/1.15
M = 20
0.0429
0.0390/1.10
M = 40
0.0388
0.0382/1.05
M = 100
0.0374
0.0374/1.00
Ensemble inﬂation is applied prior to an analysis step. As shown in Table 8.1,
we ﬁnd that an ensemble size of M = 10 is required in order to obtain skilful
results, i.e. to RMSEs which are smaller than R1/2 = 0.1, without inﬂation, and
that the time-averaged RMSE can be improved by applying ensemble inﬂation
for small ensemble sizes.
Example 8.10
In this example, multiplicative ensemble inﬂation is tested on
the Lorenz-96 model (8.17) with F = 8. Every grid point is observed every
Δtout = 0.1 time units. The measurement covariance matrix R is diagonal with
variances equal to 1. The numerical implementation of the Lorenz-96 model is as
described in Example 8.7, with the initial ensemble now drawn from the Gaussian
N(z0, R) distribution with z0 ∈R40 given by
z0 = ( −1.76, −0.66, −2.11, 2.02, −2.26, 4.57, −0.38, 4.35, 1.58, 2.31,
1.89, 0.13, 0.55, 2.61, 0.22, 7.25, 0.74, 1.89, 4.29, −2.47,
4.61, 0.57, 1.90, 0.28, −0.12, 5.25, −0.81, 3.70, 2.62, 0.36,
−0.84, 2.25, 0.74, 7.27, 3.15, −0.14, 4.91, 0.58, 0.89, 1.15).
The reference trajectory has initial value z0, and is generated by the same
numerical implementation of the Lorenz-96 model. We compare the spatially-
and temporally-averaged RMSEs for the EnKF with perturbed observations for
ensemble sizes M = 20, 22, 24, 26 and inﬂation factors from the range α ∈
{1.05, 1.10, . . ., 1.35, 1.40}. A total of 20000 assimilation cycles is performed.
Again inﬂation is applied prior to each analysis step. The smallest spatially-
and temporally-averaged RMSEs and the corresponding optimal inﬂation fac-
tors can be found in Figure 8.7. Contrary to Example 8.9, ensemble inﬂation is
now essential to the success of the EnKF, i.e., in order to avoid ﬁlter divergence.
It should be kept in mind that we conducted identical twin experiments al-

8.2 Ensemble inﬂation
245
20
21
22
23
24
25
26
0 3
0 32
0 34
0 36
0 38
0 4
0 42
ensemble size M
spatially and temporally averaged RMSEs
20
21
22
23
24
25
26
1 15
1 2
1 25
1 3
1 35
1 4
ensemble size M
inflation factor
Figure 8.7 Optimal ensemble inﬂation for the EnKF with perturbed observations
applied to the Lorenz-96 model. The left panel shows the spatially- and
temporally-averaged RMSEs while the right panel shows the corresponding optimised
inﬂation factors from the range α ∈{1.05, 1.10, . . . , 1.35, 1.40}.
lowing us to directly assess RMSEs. The computation of an optimal choice of
inﬂation factors is impossible in most practical applications since the true refer-
ence solution is not available. Methods for the practical estimation of inﬂation
factors are discussed in the references at the end of this chapter.
Recall that the particle rejuvenation step was introduced in Deﬁnition 6.13 to
avoid the creation of identical analysis ensemble members za
i under a particle
resampling/transformation step, whether in the form of the SIR ﬁlter or the
ETPF. We now discuss the eﬀect of particle rejuvenation on the ETPF in the
context of additive ensemble inﬂation. We ﬁrst note that the ETPF update
formula (7.30) with P a
j = τP f
M can be viewed as producing balanced samples
(i.e., an equal number of samples are drawn from each mixture component) from
the Gaussian mixture PDF
πZa(z) = 1
M
M

j=1
n(z; za
j, τP f
M),
za
j =
M

i=1
zf
ipij
(8.19)
and the ETPF update without particle rejuvenation corresponds to a balanced
sample from the empirical measure
μZa(dz) = 1
M
M

j=1
δ(z −za
j)dz.
(8.20)

246
Data assimilation for spatio-temporal processes
Although the same mean value
za = 1
M
M

j=1
za
j,
is obtained for both PDFs (8.19) and (8.20), the covariance matrices satisfy
P a =
1
M −1
M

j=1
(za
j −za)(za
j −za)T + τP f
M
and
P a =
1
M −1
M

j=1
(za
j −za)(za
j −za)T,
(8.21)
respectively. Hence we may conclude that particle rejuvenation has a similar
eﬀect as ensemble inﬂation: it increases the ensemble spread while preserving
the ensemble mean.
We now discuss why particle rejuvenation is necessary for the ETPF when used
with small ensemble sizes. In Chapter 5 we have already seen that the analysis
ensemble {za
i } exactly reproduces the posterior mean za = 
i wizf
i. We have also
shown that empirical expectation of a function g(z) converges to the analytical
expectation as M →∞. However, we also ﬁnd that, for ﬁnite ensemble sizes, the
empirical covariance matrix (8.21) of the analysis ensemble underestimates the
posterior covariance matrix
ˆP a =
M
M −1
M

i=1
(zf
i −za)wi(zf
i −za)T
deﬁned through the importance weights {wi}.
Example 8.11
Consider a univariate forecast ensemble {zf
i} with importance
weights {wi}. The posterior variance is given by
(ˆσa)2 =
M
M −1
M

i=1
wi(zf
i −za)2,
while the variance of the analysis ensemble
za
j =
M

i=1
zf
ipij
is equal to
(σa)2 =
1
M −1
M

i=1
(za
i −za)2.

8.2 Ensemble inﬂation
247
Table 8.2 Spatially- and temporally-averaged RMSEs obtained by the SIR ﬁlter and the
ETPF applied to the model system (8.12)–(8.13) as a function of the ensemble size
M ∈{5, 10, 20, 40, 100}. We also state the bandwidths τ for the rejuvenation step.
Overall the RMSEs are substantially larger than those displayed in Table 8.1 for the EnKF
with perturbed observations. This gap in performance closes as the ensemble size
increases.
RMSE/bandwidth
SIR
ETPF
M = 5
0.1363/0.15
0.1358/0.15
M = 10
0.0844/0.20
0.0914/0.20
M = 20
0.0630/0.20
0.0687/0.20
M = 40
0.0520/0.15
0.0527/0.20
M = 100
0.0438/0.15
0.0481/0.15
We ﬁnd that σa and ˆσa satisfy
(ˆσa)2 = (σa)2 +
1
M −1
M

j=1
M

i=1
pij(zf
i −za
j )2.
(8.22)
Although the convergence result from Chapter 5 implies that σa →ˆσa as M →
∞, we have σa < ˆσa for all ensemble sizes M (unless the optimal coupling T ∗
happens to be a permutation matrix) and particle rejuvenation can be used to
compensate for the implied reduction in ensemble spread. Related expressions
hold for multivariate state variables.
Example 8.12
We apply the SIR particle ﬁlter and the ETPF from Chapter
7 to the model (8.12)–(8.13) in the data assimilation setting of Example 8.9.
Both ﬁlters are implemented with particle rejuvenation, i.e., analysis ensembles
are drawn as balanced samples from (8.19). Spatially- and temporally-averaged
RMSEs as a function of ensemble size for an optimised bandwidth in the range
τ ∈{0.05, 0.1, 0.15, 0.2} are collected in Table 8.2; these should be compared to
those from the EnKF displayed in Table 8.1.
Example 8.13
We turn to the Lorenz-96 model (8.17) with F = 8 in the
data assimilation setting of Example 8.10. We ﬁnd that neither particle ﬁlter
implementation is able to track the reference solution, i.e., both ﬁlters result in
ﬁlter divergence, unless the ensemble size is increased to M = 100. The SIR
ﬁlter with M = 100 and bandwidth τ = 0.8 yields a spatially- and temporally-
averaged RMSE of 0.3673 while the ETPF results in an RMSE of 0.3381 for the
same setting.

248
Data assimilation for spatio-temporal processes
The performance gap between the ensemble Kalman ﬁlters and particle ﬁlters
for the Lorenz-96 model in terms of achievable ensemble sizes is striking. It is
exactly this robustness of the ensemble Kalman ﬁlters which has made them so
popular for large-scale geophysical applications. The next section will introduce
a technique which further improves the behaviour of ensemble data assimilation
algorithms in the setting of relatively small ensemble sizes.
8.3
Localisation
While ensemble inﬂation does not take the spatial structure of solutions into
account directly, we will now discuss a method, called localisation, which exploits
the spatial decay of correlations in the solutions u(x, t) of a PDE. Let us therefore
consider an ensemble {zn
i } of numerical solutions to a PDE at a time tn. If the
PDE under consideration is a scalar evolution equation with periodic boundary
conditions discretised by Nd grid points, then zn
i ∈RNz with Nz = Nd and the
kth entry of zn
i is an approximation to the solution u(x, t) at (xk, tn). We use
the abbreviation zn
i (xk) for these approximations, i.e.
zn
i = (zn
i (x1), zn
i (x2), . . . , zn
i (xNd))T.
(8.23)
Similarly we can deﬁne forecast values zf
i(xk) and analysis values za
i (xk), which
are collected in state vectors zf
i and za
i respectively. Formally, we also introduce
periodic extensions of, for example, zn
i (xk±Nd) = zn
i (xk) for given zn
i (xk), k =
1, . . . , Nd. Also recall that observations are taken in spatial intervals of Δxout
and that the corresponding grid values are denoted by xk = kΔxout.
Definition 8.14 (Spatial correlation coeﬃcients)
Given numerically generated
approximations zn
i (xk) for a time index n ≥0, spatial indices k = 1, . . . , Nd, and
ensemble indices i = 1, . . . , M, we deﬁne spatial correlation coeﬃcients Cn(lΔx)
at tn by
Cn(lΔx) =
1
Cn
0
M

i=1
Nd

k=1
(zn
i (xk) −zn
M(xk))(zn
i (xk+l) −zn
M(xk+l)),
(8.24)
for 0 ≤l ≤Nd/2 with spatial mesh-size Δx = L/Nd, normalisation constant
Cn
0 =
M

i=1
Nd

k=1
(zn
i (xk) −zn
M(xk))2,
and grid-point empirical means
zn
M(xk) = 1
M
M

i=1
zn
i (xk).
By deﬁnition, we have Cn(0) = 1.
Example 8.15
We compute (8.24) for the Lorenz-96 model (8.17) and the
model (8.12)–(8.13) for n = 1, . . . , 5000 and ensemble size M = 10 . In the case

8.3 Localisation
249
0
5
10
15
20
−0 4
−0 2
0
0 2
0 4
0 6
0 8
1
shift index
spatial correlation
0
0 1
0 2
0 3
0 4
0 5
−0 8
−0 6
−0 4
−0 2
0
0 2
0 4
0 6
0 8
1
spatial shift
spatial correlation
Figure 8.8 Time-averaged spatial correlation coeﬃcients, as deﬁned by (8.25), for the
Lorenz-96 model (left panel) and the model (8.12)–(8.13) (right panel). The spatial shift
lΔx (shift index l) is restricted to half of the domain [0, L] (0 ≤l ≤Nd/2) because of
the assumed periodic boundary conditions, which also implies a periodic behaviour of the
spatial correlation coeﬃcients. While the time-averaged spatial correlations for the
Lorenz-96 model decay quickly in l, the model (8.12)–(8.13) leads to a signiﬁcant
correlation across the whole domain.
of (8.12)–(8.13) we only compute spatial correlation coeﬃcients for the u ﬁeld.
The spatial correlation coeﬃcients are then averaged in time, i.e.,
C(lΔx) =
1
5000
5000

n=1
Cn(lΔx).
(8.25)
The numerical results can be found in Figure 8.8. While the Lorenz-96 model
leads to a rapid decay of spatial correlation, the stochastic Burgers’ model (8.12)–
(8.13) leads to correlations which are signiﬁcant across the whole domain x ∈
[0, 1]. This diﬀerent behaviour of the spatial correlation factors is a manifestation
of the diﬀerent spatial regularity of individual solutions as displayed in Figures
8.4 and 8.5, respectively.
Spatial correlation structures have important ramiﬁcations for data assimi-
lation algorithms since the forecast ensemble {zf
i} must reproduce those spa-
tial correlations in order to correctly distribute increments in observation space
across the computational domain. We discuss this aspect in more detail for a
single observation yobs at a grid point xk for simplicity. If the state vector is of
the form (8.23), then the associated forward model is simply
Y = zref(xk) + Ξ,
where Ξ ∼N(0, R). An ensemble Kalman ﬁlter implementation can be decom-
posed into the following three steps. First, deﬁne forecasts yf
i = zf
i(xk) and

250
Data assimilation for spatio-temporal processes
their empirical mean yf
M = zf
M(xk) in observation space. Second, an analysis
ensemble ya
i ∈R is produced, together with the associated ensemble increments
Δyi := ya
i −yf
i in observation space. Third, these increments are mapped back
onto state space via
za
i = zf
i +
M
j=1(zf
j −zf
M)(zf
j(xk) −zf
M(xk))
M
j=1(zf
j(xk) −zf
M(xk))2
Δyi.
(8.26)
Let us now assume that the spatial correlation coeﬃcients Cn(lΔx), as deﬁned
by (8.24), are close to zero for l ≥l∗for the model under consideration. The
associated correlation coeﬃcients in (8.26) should then also be close to zero, i.e.,
M
j=1(zf
j(xk + lΔx) −zf
M(xk + lΔx))(zf
j(xk) −zf
M(xk))
M
j=1(zf
j(xk) −zf
M(xk))2
≈0
(8.27)
for all |l| ≥l∗. One way to enforce this statistical constraint is to bring these
correlations to zero, regardless of whether a forecast ensemble {zf
i} is correctly
reproducing (8.27) or not. This is called localisation.
In order to reformulate (8.26) with localisation we introduce rk,k′ = |xk −xk′|
as the spatial distance between grid points xk and xk′ and deﬁne weight factors
ρ(rk,k′/rloc) for some appropriate ﬁlter function ρ as well as a chosen localisation
radius rloc ≥0. Note that periodicity needs to be taken into account in deﬁning
rk,k′ in the case of a spatially-periodic domain, i.e.,
rk,k′ = |xk −xk′|L := min{|xk −xk′ −L|, |xk −xk′|, |xk −xk′ + L|}.
We introduce the abbreviation
s := rk,k′
rloc
≥0
and state two possible ﬁlter functions. The ﬁlter function could be as simple as
ρ(s) =
 1 −1
2s
for s ≤2,
0
otherwise .
(8.28)
Alternatively, a higher-order piecewise polynomial such as
ρ(s) =
⎧
⎨
⎩
1 −5
3s2 + 5
8s3 + 1
2s4 −1
4s5
for s ≤1,
−2
3s−1 + 4 −5s + 5
3s2 + 5
8s3 −1
2s4 + 1
12s5
for 1 ≤s ≤2,
0
otherwise ,
(8.29)
could be used. Given an observation at grid point xk = kΔxout, we deﬁne the
vector ck ∈RNd with entries
(ck)l = ρkl := ρ
|xl −xk|L
rloc

for l = 1, . . . , Nd. We also introduce the Schur product A ◦B of two matrices (or
vectors) A and B of equal size, deﬁned in terms of their matrix entries by
(A ◦B)kl = (A)kl(B)kl.

8.3 Localisation
251
The localised version of the update (8.26) is now given by
za
i = zf
i + (ck ◦(P f
MHT))(HP f
MHT)−1Δyi,
(8.30)
where the index k refers to the index of the grid point xk at which the observation
yobs has been taken and H ∈R1×Nz is the forward operator deﬁned by
Hz = z(xk).
(8.31)
The localised update (8.30) can be reformulated more abstractly by introduc-
ing the localisation matrix C ∈RNd×Nd with entries
(C)kl = ρ
|xk −xl|L
rloc

.
(8.32)
The matrix C becomes circulant on a one-dimensional periodic domain.
Example 8.16
We give a simple example of a localisation matrix for a spatially-
periodic domain of length L = 1 discretised into Nd = 10 grid points with
grid spacing Δx = 0.1. We use the ﬁlter function ρ deﬁned in (8.28) with the
localisation radius set to rloc = Δx. The resulting localisation matrix C ∈R10×10
is given by
C =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
1/2
0
0
0
0
0
0
0
1/2
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
0
0
0
0
0
0
0
0
1/2
1
1/2
1/2
0
0
0
0
0
0
0
1/2
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
With the localisation matrix C deﬁned as above, note that (C)kk = 1, i.e., the
diagonal entries of C are equal to one and therefore
H(C ◦P f
M)HT = HP f
MHT
for the forward operator H deﬁned in (8.31). It is then easy to verify that (8.30)
becomes equivalent to
za
i = zf
i + (C ◦P f
M)HT
Δyi
H(C ◦P f
M)HT .
(8.33)
We now extend the concept of localisation to multivariate observations. If the
measurement errors of all observations are mutually independent, i.e., the error
covariance matrix R is diagonal, then observations can be processed sequentially

252
Data assimilation for spatio-temporal processes
one after another, following the procedure we have just discussed for the sin-
gle observation case. However, more eﬃcient approaches can be followed. We
will focus here on two alternatives which allow the simultaneous assimilation
of multivariate observations yobs. We start with the concept of B-localisation.
We continue considering evolution equations with a single spatial dimension and
periodic boundary conditions. Hence Nz = Nd.
For simplicity of exposition we assume that observations are taken at grid
points and hence the forward operator H has exactly one entry equal to one in
each row with all other entries being identically zero.
Definition 8.17 (B-localisation for EnKF with perturbed observations)
Given
a ﬁlter function ρ such as (8.28) or (8.29), a localisation radius rloc, and an
associated localisation matrix C ∈RNd×Nd with entries deﬁned by (8.32), B-
localisation for the EnKF with perturbed observations is deﬁned by
za
i = zf
i −Kloc(Hzf
i −yobs + ξi)
with localised Kalman gain matrix
Kloc = (C ◦P f
M)HT(H(C ◦P f
M)HT + R)−1.
(8.34)
All other quantities are deﬁned as before for the EnKF with perturbed observa-
tions. Here the forward operator H ∈RNy×Nd collects now all observations of
the state vector z at the Ny grid points xk = kΔxout.
Note that because of the assumed structure of the forward operator H we can
also deﬁne a localisation operator
ˆC = HCHT ∈RNy×Ny
in observation space. It holds that
(ˆC)kl = ρ
|xk −xl|L
rloc

and
H(C ◦P f
M)HT = ˆC ◦(HP f
MHT).
Similar considerations apply to (C◦P f
M)HT and help to reduce the computational
expenses of a localised EnKF implementation.
Localisation is slightly more diﬃcult to implement for the family of ESRFs.
Here we discuss the use of R-localisation, a popular localisation technique in
ensemble Kalman ﬁltering that has given rise to the local ensemble transform
Kalman ﬁlter (LETKF) (Ott et al. 2004, Hunt et al. 2007). First recall that an
ESRF can be written as a LETF which in our context amounts to
za
j (xk) =
M

i=1
zf
i(xk)dij,
k = 1, . . . , Nd.

8.3 Localisation
253
R-localisation replaces this global spatial update by separate updates for each
grid point xk, k = 1, . . . , Nd, in the form
za
i (xk) =
M

i=1
zf
i(xk)dij(xk).
The associated transformation matrices D = {dij(xk)} now depend on the grid
point xk.
Next, for each grid point xk we introduce the diagonal matrix ˜Ck ∈RNy×Ny
in observation space with diagonal entries
(˜Ck)ll = ρ
|xk −xl|L
rloc

,
(8.35)
for l = 1, . . . , Ny and xl = lΔxout. Also recall the deﬁnition of the matrix
Af =

zf
1 −zf
M, zf
2 −zf
M, . . . , zf
M −zf
M

∈RNd×M
of ensemble anomalies. In order to implement R-localisation for the ensemble
anomalies Af, we need to introduce the ensemble anomalies
Af(xk) :=
#
(zf
1(xk) −zf
M(xk)), . . . , (zf
M(xk) −zf
M(xk))
$
∈R1×M
at each grid point xk with their updates being individually deﬁned by a linear
transform approach of type (7.21).
Definition 8.18 (R-localisation for ESRF/LETKF)
The matrix Af of forecast
ensemble anomalies is updated at grid point xk by
Aa(xk) = Af(xk)S(xk) ∈R1×M
with the transformation matrix S(xk) ∈RM×M given by5
S(xk) =

I +
1
M −1(HAf)T(˜CkR−1)HAf
−1/2
.
The complete set of analysis ensemble anomalies is collected in
Aa =
⎡
⎢⎢⎢⎣
Aa(x1)
Aa(x2)
...
Aa(xNd)
⎤
⎥⎥⎥⎦∈RNd×M.
The localised update for the forecast ensemble mean zf
M ∈RNd can be written
as
za(xk) =
M

i=1
zf
i(xk)wi(xk),
k = 1, . . . , Nd,
(8.36)
5 This formula is the localised version of the update formula (7.22) derived previously in
Chapter 7. The only diﬀerence is that the inverse error covariance matrix R−1 is replaced
by ˜CkR−1.

254
Data assimilation for spatio-temporal processes
10
20
30
40
50
60
70
80
1 4
1 5
1 6
1 7
1 8
1 9
2
2 1
2 2
localised EnKF and ETPF
Ensemble size
RMSE
EnKF
ETPF
Figure 8.9 Spatially- and
temporally-averaged RMSEs for the
localised EnKF with perturbed
observations and the localised ETPF
for ensemble sizes
M ∈{10, 20, . . . , 80}. We only
display the smallest RMSEs over a
range of localisation radii and
inﬂation/rejuvenation factors.
with the vectors w(xk) ∈RM given by
w(xk) = 1
M 1 −
1
M −1S(xk)2(Af)THT(˜CkR−1)

Hzf
M −yobs

.
(Compare (7.23) and (7.24) from Chapter 7.)
We note that it is possible to replace the update (8.36) for the ensemble mean
by
za = zf
M −Kloc(Hzf
M −yobs).
However, the formulation (8.36) is to be preferred if M ≪Ny, since the compu-
tation of Kloc requires the inversion of a non-diagonal Ny × Ny matrix.
Example 8.19
We return to the Lorenz-96 model (8.17) in the setting of Exam-
ple 8.10 and investigate the impact of localisation on the behaviour of ensemble-
based ﬁltering algorithms. To make the problem even more challenging, we ob-
serve only every second grid point in time intervals of Δtout = 0.11 with the vari-
ance of the independent measurement errors increased to 8.0. A total of 10000
assimilation steps are performed. We implement B-localisation for the EnKF with
perturbed observations with multiplicative inﬂation α ∈{1.0, 1.02, . . ., 1.12} and
for localisation radii rloc ∈{1/3, 2/3, . . ., 10/3} and localisation function (8.29).
Recall that Δx = 1/3 for the Lorenz-96 model. The results can be found in
Figure 8.9 where the smallest averaged RMSE is displayed.
We now extend the idea of R-localisation to the ETPF from Chapter 7. Since
the ensemble Kalman ﬁlters and the ETPF both rely on a linear transformation of
type (7.7), an application of R-localisation to a ETPF is rather straightforward.
The ETPF Algorithm 7.10 uses a transformation
za
j =
M

i′=1
zf
ipij

8.3 Localisation
255
of the forecast into the analysis ensemble with the transform matrix P = MT ∗
being determined by importance sampling and an associated linear transport
problem. To implement R-localisation for the ETPF we proceed essentially as
for the LETKF, i.e., we deﬁne separate transformation matrices P(xk) for each
grid point xk, k = 1, . . . , Nd. We summarise the resulting ﬁlter algorithm in the
following deﬁnition.
Definition 8.20 (R-localisation for ETPF)
We deﬁne a localised/weighted dis-
tance between two ensemble members zf
i1, zf
i2 ∈RNd at a grid point xk as follows:
∥zf
i1 −zf
i2∥2
k =
Nd

l=1
ρ
|xk −xl|L
rloc

(zf
i1(xl) −zf
i2(xl))2.
(8.37)
This distance represents a weighted averaged diﬀerence between the two ensemble
members over neighbouring gridpoints.
We also localise the impact of observations by modifying the likelihood of zf
i
with respect to a set of observations to
wi(xk) ∝exp

−1
2(yobs −Hzf
i)T(˜CkR−1)(yobs −Hzf
i)

,
(8.38)
for i = 1, . . . , M with the diagonal matrix ˜Ck deﬁned by (8.35). Again we have
assumed that only grid values of u(x, t) are being observed and that the mea-
surement error covariance matrix R is diagonal. The optimal coupling matrix
T ∗(xk) ∈RM×M at grid point xk is obtained as the solution to the linear trans-
port problem coupling the two probability vectors w(xk) and 1/M under the
distance ∥· ∥k. Finally the analysis ensemble at grid point xk is given by
za
j (xk) =
M

i=1
zf
i(xk)pij(xk),
j = 1, . . . , M,
where pij(xk) = Mt∗
ij(xk).
We note that diﬀerent localisation radii can be used in (8.37) and (8.38).
Computationally it is most eﬃcient to set rloc = 0 in (8.37) since it reduces the
associated distance to
∥zf
i1 −zf
i2∥2
k = (zf
i1(xk) −zf
i2(xk))2
(8.39)
and the linear transport problem to an univariate transport problem which can
be solved very eﬃciently using the algorithm from Appendix 5.8.
Alternatively, we could process observations sequentially which would lead to
a separate linear transport problem for each observation with “localised” cost
function deﬁned by the distance ∥zf
i1 −zf
i2∥2
k, where the index k now refers to
the location xk of the kth observation. Furthermore, the impact of the resulting
coupling matrix T ∗(xk) on the forecast ensemble would be limited to grid points
in the vicinity of xk as done in B-localisation.
We have seen in Example 8.16 that particle ﬁlters are unable to track reference

256
Data assimilation for spatio-temporal processes
solutions of the Lorenz-96 model unless the ensemble size is increased to the order
of 102. We now demonstrate that this situation can be rectiﬁed with the localised
ETPF.
Example 8.21
We repeat the experiment set out in Example 8.19 with the
localised EnKF being replaced by the localised ETPF implementation of Algo-
rithm 7.10. The spatially- and temporally-averaged RMSEs for ensemble sizes
M ∈{10, 20 . . ., 80} can be found in Figure 8.9. The localised ETPF outperforms
the localised EnKF for ensemble sizes M ≥50. The computational costs of a
localised ETPF update are, however, signiﬁcantly higher than those for ensemble
Kalman ﬁlter implementations. See Cheng & Reich (2013) for more details.
Problems
8.1
Consider a Gaussian random variable X in Nx ≫1 dimensions with mean
zero and covariance matrix P = σ2I. We set σ2 = N −1
x
and consider the associ-
ated univariate random variable
Y := ∥X∥=

	
	

Nx

i=1
X2
i
with PDF
πY (y) ∝rNx−1e−r2
2 ,
r := N 1/2
x
y ≥0.
Plot πY as a function of y ∈[0, 2] for Nx = 1, Nx = 10, Nx = 100, and Nx = 200.
Discuss the implications of your results on the behaviour of the multivariate
random variable X as Nx increases.
8.2
Repeat the numerical experiment from Example 8.4 with the advecting ve-
locity ﬁeld (8.7) replaced by the time-independent ﬁeld a(x) = sin(2πx). Com-
pare the resulting approximation at t = 1 for Nd = 100 grid points with those
for Nd = 20. Find the analytic solution to the diﬀerential equation
dx
dt = sin(2πx)
for initial conditions x(0) ∈[0, 1]. Compare the exact solution for initial x(0) =
1/4 at t = 1 with the approximations from Euler’s method for step-sizes Δt =
0.001, Δt = 0.01, and Δt = 0.1. Which rate of convergence to the true solution
is observed as Δt is decreased?
8.3
Repeat the numerical experiment from Example 8.5 after replacing the
advecting velocity ﬁeld (8.7) with the time-independent ﬁeld a(x) = sin(2πx).
Compare the results to those obtained in Problem 8.2 for Nd = 100 and Nd = 20.
8.4
Implement the Lorenz-96 model with F = 8 in the setting of Example
8.15 and integrate the equations using the forward Euler method with step-size
Δt = 0.001 over a time interval [0, 8]. The initial ensemble is drawn from a
Gaussian distribution with mean u0 = 0 and covariance matrix P = I. Compare

8.4 Guide to literature
257
the time evolution of the leading eigenvalue of the empirical covariance matrix
for ensemble sizes M = 10, 20, 40, 80 and M = 100 with those displayed in Figure
8.6. Repeat the experiment for diﬀerent realisations of the initial ensemble drawn
from the Gaussian N(0, I) distribution.
8.5
Implement the EnKF with perturbed observations with ﬁxed ensemble in-
ﬂation parameter α = 1.15 for the Lorenz-96 model. Follow the implementation
details from Example 8.10. Note that ensemble inﬂation is applied prior to the
EnKF analysis step. Compute spatially- and temporally-averaged RMSEs for
ensembles of size M = 20 and M = 26. Compare your results to those from
Figure 8.7.
8.6
Verify formula (8.22).
8.7
Recompute the localisation matrix C from Example 8.16, with the ﬁlter
function (8.28) replaced by (8.29).
8.8
Verify that H(C ◦P f
M)HT = ˆC ◦(HP f
MHT), given that the entries hij
of the linear forward operator H satisfy hij ∈{0, 1} and Nd
j=1 hij = 1 for all
i = 1, . . . , Ny.
8.9
Implement B-localisation for the EnKF with perturbed observations and
apply your implementation to the Lorenz-96 model as outlined in Example 8.19.
Use ensemble sizes of M ∈{10, 20, . . ., 80} with associated localisation radii
given by6
M
10
20
30
40
50
60
70
80
rloc
2/3
4/3
6/3
6/3
7/3
7/3
8/3
8/3
and inﬂation parameters α ∈{1.0, 1.02, . . ., 1.12}.
8.4
Guide to literature
An excellent textbook on PDEs is Evans (1998). A deeper dynamical systems
perspective on PDEs is given in Robinson (2001). A solid introduction to the
numerics of evolution equations such as those considered in this chapter can be
found in Ascher (2008).
Standard ensemble inﬂation and localisation techniques for ensemble Kalman
ﬁlters are covered in Evensen (2006).
The estimation of optimal inﬂation factor α has been investigated in a number
of publications. Anderson (2007) suggested treating the unknown α as part of the
state estimation problem, then applying data assimilation to the combined state-
parameter estimation problem. Alternatively, a hierarchical Bayesian approach
to the estimation of the prior distribution for the Bayesian assimilation step was
suggested by Bocquet & Sakov (2012), putting a Jeﬀreys prior on the covariance
matrix to be estimated. A third option is provided by a Gaussian approach to
covariance inﬂation proposed by Miyoshi (2011).
6 Recall that Δx = 1/3 for the Lorenz-96 model. Hence rloc = 2/3 = 2Δx, for example.

258
Data assimilation for spatio-temporal processes
A recent comparison between R- and B-localisation can be found in Nerger
et al. (2012) and references cited therein. An adaptive localisation algorithm
was proposed by Anderson (2012). See also Majda & Harlim (2012) for further
discussions on the application of ensemble-based ﬁlter techniques to spatially
extended systems. Majda & Harlim (2012) introduce, in particular, the idea of
localisation for linear PDEs in spectral space.
The failure of standard particle ﬁlters in high dimensions is studied and ex-
plained in Bengtsson et al. (2008). Extending particle ﬁlters to spatio-temporal
Markov processes is a very active area of research. Several authors have intro-
duced alternative proposal steps into the particle ﬁlter which lead to forecast
ensemble members zf
i with high and nearly uniform likelihoods πY (zf
i|yobs). For
example, a combined particle and Kalman ﬁlter is proposed in van Leeuwen
(2010) and van Leeuwen & Ades (2013) (see also the discussion in Bocquet, Pires
& Wu (2010)), while in Chorin, Morzfeld & Tu (2010), Morzfeld, Tu, Atkins &
Chorin (2012), and Morzfeld & Chorin (2012), forecast ensemble members zf
i are
deﬁned by means of implicit equations. See also Reich (2013a).
More details on the localised ETPF, including numerical results for the Lorenz-
96 model, can be found in Cheng & Reich (2013). The idea of localised particle
ﬁlters also appears in Rebeschini & van Handel (2013).

9
Dealing with imperfect models
Recall from our discussion in the Preface that Laplace’s demon possessed (i) a
perfect mathematical model of the physical process under consideration, (ii) a
snapshot of the state of that process at an arbitrary point in the past or the
present, and (iii) inﬁnite computational resources to unravel explicit solutions
of the mathematical model. In Chapter 1 we discussed these aspects in a very
simpliﬁed mathematical setting where physical processes were reduced to one
set of mathematical equations (the surrogate physical process) and the math-
ematical model was represented by a system of diﬀerence equations. We also
discussed partial and noisy observations of state space as presentations of our
knowledge about the surrogate physical process, and brieﬂy touched upon the is-
sue of numerical approximation errors, which arise from putting a mathematical
model into algorithmic form amenable to computer implementations. However,
contrary to these general considerations made in Chapter 1, we have mostly
limited the discussion of data assimilation algorithms in Chapters 6 to 8 to an
even more simpliﬁed setting where the mathematical model is assumed to be a
perfect replica of the surrogate physical process. In other words, the same model
has been used both for generating the surrogate physical process and for making
predictions about this process. We also generally assumed that the mathematical
models come in algorithmic form and discretisation errors were discarded. This
setting is called an ideal twin experiment. Within a perfect model setting, uncer-
tainty only arises from incomplete knowledge of the model’s initial state. A slight
generalisation of this perfect model scenario arises when the surrogate physical
process is a particular realisation of the stochastic diﬀerence equation which is
used for producing forecasts. In that case, forecast uncertainties are caused by
the unknown distribution of initial conditions and the unknown realisations of
the stochastic contributions to the evolution equation.
In this chapter, we will discuss how to deal with imperfect models and pa-
rameter dependent families of imperfect models from a Bayesian perspective.
Again our situation will be simpliﬁed by the assumption that the underlying
reference solution is generated by a known computational model. However, dif-
ferent computational models will be used for making forecasts and for producing
observations.
A key problem with an imperfect model setting is that computed forecast
ensemble distributions might not be fully representative of actual forecast un-

260
Dealing with imperfect models
certainties. This is particularly worrisome if the forecast ensemble spread is too
small relative to an ensemble spread from a perfect model setting. One solution
is to use ensemble inﬂation, as introduced in Chapter 8, in order to artiﬁcially
increase ensemble spreads. At the same time we are often faced with the problem
of having to evaluate the performance of several imperfect models. This leads
us to the topic of model comparison. In this chapter, we start with comparing
models based on their evidence with respect to the available observations. This
discussion will then be extended to adapting model parameters using observa-
tions. Here we will focus on ensemble-based parameter estimation techniques
instead of the more classical maximum likelihood estimators. Ensemble-based
methods have the advantage that they not only provide a “best” ﬁt estimate of
the parameter, but also a characterisation of the uncertainty in this value.
In the second part of this chapter we will discuss molliﬁed formulations of
sequential data assimilation algorithms. These formulations allow us to view data
assimilation algorithms as nudging terms added to a model in order to “steer”
model states towards closer agreement with the unknown reference solution.
Nudging is often used in the presence of strong model errors and unreliable
quantiﬁcation of forecast uncertanties. We will also discuss the treatment of
nonlinear forward operators in the context of ensemble Kalman ﬁlters.
9.1
Model selection
Recall the importance sampling approach to Bayesian inference: given an en-
semble zf
i of M realisations with weights wf
i ≥0 from a forecast PDF πZf, the
analysis ensemble is characterised by new weights
wa
i ∝wf
i πY (yobs|zf
i),
where the constant of proportionality is chosen such that
M

i=1
wa
i = 1.
The constant of proportionality is explicitly given by
E(yobs) :=
M

i=1
wf
i πY (yobs|zf
i)
and provides a Monte Carlo approximation to the marginal PDF
πY (y) =

RN πY (y|z)πZf(z)dz
evaluated at y = yobs. The normalisation factor πY (yobs), and its numerical
approximation by E(yobs), play a key role in this section.
More speciﬁcally, we compare diﬀerent models based on their ﬁt to given
observations. Here a model, denoted by M, consists of an initial PDF πZ(z, t0)

9.1 Model selection
261
and evolution equations for evolving ensemble members zi(tn), i = 1, . . . , M,
with initial conditions drawn from πZ(0, t0). Let us assume that we are given L
such models, which we denote by Ml. These models may diﬀer by their initial
PDFs, the evolution equations or both. Identical sets of observations are then
applied to each of the models in order to perform sequential data assimilation
using any of the assimilation methods from Chapter 7. The novel aspect is that,
in addition to performing the assimilation steps, we also compute the ensemble-
based evidence or likelihood for each model.
Definition 9.1 (Model evidence/likelihood)
Let
Yt1 Nobs = (Y (t1), . . . , Y (tNobs)) : Ω →RNy×Nobs,
be the random variable describing observations at times t1 < t2 < · · · < tNobs.
Given a model M that provides a joint distribution for a discrete stochastic
process {Z(tk)}Nobs
k=0 , which for notational convenience is now abbreviated as
Zt0 Nobs = (Z(t0), Z(t1), . . . , Z(tNobs)) : Ω →RNz×(Nobs+1),
we write the marginal distribution (recall Lemma 2.16) for Yt1 Nobs as
πYt1 Nobs (yt1 Nobs|M) = E
!
πYt1 Nobs
&
yt1 Nobs |Zt0 Nobs
'"
,
(9.1)
for all
yt1 Nobs = (y(t1), . . . , y(tNobs)) ∈RNy×Nobs.
Here the expectation is taken over all possible trajectories zt0 Nobs = Zt0 Nobs(ω)
of the model M.
Given a sequence of actual observations
yobs
t1 Nobs = (yobs(t1), . . . , yobs(tNobs)) ∈RNy×Nobs,
the evidence or likelihood of the data yobs
t1 Nobs under the model M, is then deﬁned
as πYt1 Nobs (yobs
t1 Nobs|M).
A higher value evidence suggests that a model ﬁts better with the available
data. Of course, it is feasible that a certain model might provide a better ﬁt
to certain data sets, while another model might be better for others. We could
alternatively use any of the scoring rules from Chapter 4, which can be used to
assess sequences of analysis ensembles as well as the forecast ensembles as they
were introduced in that chapter. However, we will concentrate on the calcula-
tion of evidence in this chapter since it makes a link to posterior probability
distributions via Bayes’ theorem.
We now make the usual assumption that given a realisation of the model M,
the observations are mutually independent, and yobs(tk) has a PDF that only
has conditional dependence on z(tk), for 1 ≤k ≤Nobs. This means that we may

262
Dealing with imperfect models
write
πYt1 Nobs (yobs
t1 Nobs |M) = E
4Nobs
1
k=1
πY (yobs(tk)|Z(tk))
5
.
(9.2)
A Monte Carlo approximation to the formulation in Equation (9.2) would involve
obtaining an ensemble of M realisations of the model M,
(zi(t0), zi(t1), zi(t2), . . . , zi(tNobs)) ,
i = 1, . . . , M,
and then computing the ensemble average
E(yobs
t1 Nobs ) = 1
M
M

i=1
Nobs
1
k=1
πY (yobs(tk)|zi(tk)),
(9.3)
where πY (y|z) denotes the standard likelihood function for a state z given an ob-
servation y. This Monte Carlo approximation will suﬀer from the same problems
as the particle ﬁlter without resampling, i.e., the distribution of weights
wi =
Nobs
1
k=1
πY (yobs(tk)|zi(tk))
(9.4)
will be highly non-uniform. This is because it is very unlikely that any of the
realisations Zt0 Nobs(ω) will be close to the data: a huge number of trajectories
are required to obtain an accurate approximation of the evidence. We would
prefer to use an adaptive resampling approach that only computes weights for
trajectories suﬃciently close to the data.
To facilitate a resampling approach, we rewrite Equation (9.2) using the dis-
integration formula (see Deﬁnition 2.15) applied to a conditional probability to
obtain
πYt1 Nobs (yt1 Nobs|M) = E
!
πYt1 Nobs (yt1 Nobs|Zt0 Nobs )
"
= E
4Nobs
1
k=1
πY

y(tk)|yt1 k
1, Zt0 k

5
= E
4Nobs
1
k=1
πY (y(tk)|Zf
tk)
5
=
Nobs
1
k=1

Z
πY (y(tk)|z)πZ(z, tk|yt1 k
1) dz

,
(9.5)
where (as in previous chapters) πZ(z, tk|yt1 k
1) denotes the PDF for the forecast
Zf at tk which is conditional on all observations up to and including tk−1. Ap-
proximations of (9.5) can be based on an SIR or ETPF ﬁlter, recursively generat-
ing equally weighted forecast ensembles from the forecast PDFs πZ(z, tk|yt1 k
1).
The evidence can thus be computed by calculating with stochastic processes
that stay suﬃciently close to the data. This leads to the following algorithmic
implementation of (9.5).

9.1 Model selection
263
Algorithm 9.2 (Computing model evidence)
Given a set of observations yobs(tk),
k = 1 . . . , Nobs, at observation times tk = kΔtout, a dynamic model M, and an
initial ensemble {za
i (t0)}, the model evidence (9.5) can be recursively approxi-
mated using
Ek = Ek−1
0
1
M
M

i=1
πY (yobs(tk)|zf
i (tk))
?
(9.6)
with initial value E0 = 1. Then
E(yobs
t1 Nobs|M) := ENobs
provides a Monte Carlo approximation to πYt1 Nobs (yobs
t1 Nobs|M). Here {zf
i (tk)}
denotes the model generated forecast ensemble at observation time tk which is
based on an equally weighted analysis ensemble {za
i (tk−1)} at time tk−1. The
desired ensembles can be computed using either the SIR particle ﬁlter or the
ETPF from Chapter 7, with resampling after each assimilation step.
Example 9.3
We return to the imperfect model setting from Chapter 1. Recall
that a reference solution zref(t) = (xref(t), yref(t), zref(t))T ∈R3 is generated in
Example 1.1 from a perturbed Lorenz-63 model. Given this reference solution,
observations xobs(tk) for tk = kΔtout of the x-component are then generated
in intervals of Δtout = 0.05, using the computational procedure described in
Example 1.2. Furthermore, we have deﬁned a forward model for this observation
process in Example 2.20 of the form
xobs(tk) = xref(tk) + ξk,
where {ξk} are independent realisations of Gaussian random variables with mean
zero and variance R = 1/15. Finally we have also constructed a stochastic model
(4.18)–(4.20) in Chapter 4 with the stochastic forcing terms being Gaussian
with mean zero and variance σ2 = 0.0838 in each solution component. We now
assess the ﬁt of this stochastic model by computing its evidence with respect
to the available observational data. We do this to compare the variance value
σ2 = 0.0838 to other values from the range {0.02, 0.05, 0.1, 0.2}. Hence we have
L = 5 models Ml, which we can compare against each other in terms of their
evidence. The computations are performed for ensembles of size M = 1000 with
the initial ensemble drawn from a Gaussian with mean equal to the value of the
reference solution at t = 0 and covariance matrix P 0 = 1/15I. The computed
evidence along 200 observations is then averaged over 100 independent draws of
the initial ensemble from N(zref(0), P 0). The results from an SIR particle ﬁlter
implementation without particle rejuvenation can be found in Figure 9.1. The
numerical results conﬁrm that σ2 = 0.0838 is a good choice for the stochastic
forcing term. We also found that slightly larger or smaller values of σ2 lead to
similar values for the averaged evidence.

264
Dealing with imperfect models
0
0 05
0 1
0 15
0 2
10
17
10
16
10
15
10
14
10
13
variance
evidence
Evidences under SIR particle filter
Figure 9.1 Evidence of the stochastic
Lorenz-63 model along observations
xobs(tk), k = 1, . . . , 200, for diﬀerent
values of the variance σ2 of the
stochastic forcing terms. Results from
an SIR particle ﬁlter are averaged over
100 initial ensembles drawn from
N(zref(0), P 0). In each case the
ensemble size is M = 1000. The
evidence for the SIR ﬁlter is largest for
σ2 ∈{0.05, 0.0838, 0.1}. Outside this
range the evidence quickly falls oﬀ,
indicating a poorer match between the
resulting stochastic model and the
underlying reference model from which
the observations are generated.
Example 9.4
Let us discuss Equation (9.2) for deterministic model dynamics
in some more detail. Since
Z(tk) = ψk(Z(t0))
for an appropriate map ψ, we obtain
πYt1 Nobs (yt1 Nobs|z(t0), M) =
Nobs
1
k=1
πY (y(tk)|ψk(z(t0)))
(9.7)
and
πYt1 Nobs (yt1 Nobs|M) = E
4Nobs
1
k=1
πY (y(tk)|ψk(Z(t0)))
5
=

Z
Nobs
1
k=1
πY (y(tk)|ψk(z)) πZ(z, t0)dz.
If a large number of accurate observations {yobs(tk)} are available then it makes
sense to approximate the evidence πYt1 Nobs (yobs
t1 Nobs |M) using Laplace’s method
from Chapter 3. More precisely, deﬁne
g(z) := −ln
0Nobs
1
k=1
πY (yobs(tk)|ψk(z)) πZ(z, t0)
?
and let ˆz denote the MAP estimate,
ˆz = arg min g(z).
Here we have suppressed an explicit dependence of g on the model M and the

9.1 Model selection
265
data yobs
t1 Nobs. An application of Laplace’s method is now based on the quadratic
approximation
g(z) ≈g(ˆz) + 1
2(z −ˆz)TD2g(ˆz)(z −ˆz),
(9.8)
i.e.,
πYt1 Nobs (yt1 Nobs |M) ≈e−g(ˆz)

Z
e−1
2 (z−ˆz)TD2g(ˆz)(z−ˆz)dz
= e−g(ˆz)(2π)Nz/2|D2g(ˆz)|−1/2 .
See Chapter 3 for further details. Here D2g(ˆz) ∈RNz×Nz denotes the Hessian
matrix of second-order partial derivatives of g.
We mention in passing that further approximations to the quadratic contribu-
tion in (9.8) lead to the Bayesian information criterion (BIC) for model com-
parison (Hastie et al. 2009).
In the Bayesian setting, it may be the case that we have also developed some
prior experience of which of the models is more appropriate. Each model Ml
would then be given a prior probability P(Ml), in order to make a Bayesian
model comparison. For simplicity, consider the case of two models M1 and M2
with evidence πYt1 Nobs
&
yobs
t1 Nobs |M1
'
and πYt1 Nobs
&
yobs
t1 Nobs|M2
'
, respectively.
The posterior model probabilities are then simply deﬁned by
P(M1|yobs
t1 Nobs ) =
πYt1 Nobs (yobs
t1 Nobs |M1)P(M1)
πYt1 Nobs (yobs
t1 Nobs|M1)P(M1) + πYt1 Nobs (yobs
t1 Nobs|M2)P(M2)
and
P(M2|yobs
t1 Nobs) =
πYt1 Nobs (yobs
t1 Nobs|M2)P(M2)
πYt1 Nobs (yobs
t1 Nobs |M1)P(M1) + πYt1 Nobs (yobs
t1 Nobs |M2)P(M2),
respectively. If there is no initial preference for one or the other model then we
would choose
P(M2) = P(M1) = 1/2
as the prior probabilities. However, past experience with the models might sug-
gest diﬀerent relative probabilities; the Bayesian model comparison framework
allows us to take this into account.
The extent to which observations support M1 over M2, characterised by the
ratio
P(M1|yobs
t1 Nobs )
P(M2|yobs
t1 Nobs ) =
πYt1 Nobs (yobs
t1 Nobs |M1)
πYt1 Nobs (yobs
t1 Nobs |M2) × P(M1)
P(M2),
is called the posterior odds for M1 against M2.

266
Dealing with imperfect models
9.2
Parameter estimation
If the forecast model involves free parameters (such as the parameters σ, ρ and
β in the Lorenz model (1.4)) then it is clearly useful to compare the outcome
of diﬀerent parameter choices, as discussed in the previous section. However, it
is much more useful to go beyond that, and adaptively select parameters to in-
crease the ﬁt between model forecasts and measurements. This task falls into the
broad ﬁeld of parameter estimation; here we will consider two parameter estima-
tion approaches which ﬁt particularly well with the data assimilation algorithms
developed in this book.
To outline the basic ideas let us assume that the forecast model comes in the
form of a recursion
zn+1 = zn + δtf(zn, λ),
(9.9)
where the right hand term f now also depends on the parameters λ ∈RNλ and
δt > 0 is the step-size such that tn = nδt, n ≥0. For simplicity, we restrict
the discussion to univariate parameters, i.e., Nλ = 1. Following the Bayesian
perspective taken throughout this book, we treat λ as a random variable with
a speciﬁed prior distribution πΛ. One way to deal with this is to incorporate λ
into the state. We rewrite (9.9) in the augmented state-space form
zn+1 = zn + δtf(zn, λn),
(9.10)
λn+1 = λn,
(9.11)
placing the parameter λ on equal footing with the state variable z ∈RNz, despite
its trivial dynamics. Given an extended ensemble {zi, λi}, i = 1, . . . , M, from
the product PDF πZ(z, t0)πΛ(λ) for the initial conditions, we can now apply any
ensemble-based data assimilation algorithm to recursively update both the state
and the parameter upon receiving incoming observations.
Definition 9.5 (Sequential state parameter estimation with stochastic perturba-
tions)
Given initial (or prior) distributions for the model state z at time t0
and the parameter λ and an associated initial ensemble (z0
i , λ0
i ), i = 1, . . . , M,
combined sequential state parameter estimation is performed by applying an
ensemble-based assimilation algorithm to the augmented model
zn+1
i
= zn
i + δtf(zn
i , λn
i ),
(9.12)
λn+1
i
= λn
i +
√
δtϵn
i
(9.13)
for given observations yobs(tk) at times tk = kΔtout and k = 1, . . . , Nobs. Here
{ϵn
i } are independent realisations of a univariate Gaussian random variable with
mean zero and variance σ2.
The role of the noise term in the evolution equation for λ is to spread out
the marginal PDF for λ as time progresses, i.e., to increase the spread of the
ensemble in λ. The choice of σ is crucial for a good performance of a sequential

9.2 Parameter estimation
267
state parameter estimation algorithm: smaller values for σ make the outcome
more dependent on the initial distribution πΛ, while larger values of σ can lead
to excessive spreading of ensembles. As an alternative to the stochastic perturba-
tions in (9.13) we could also apply ensemble inﬂation, as introduced for ensemble
Kalman ﬁlter algorithms. In this case, the strength of the ensemble inﬂation has
a similar impact on the quality of the parameter estimation as the size of σ.
Example 9.6
We consider the Lorenz-63 equations in the setting of Example
7.13 from Chapter 7. Recall that the Lorenz-63 model comes in the form of an
ordinary diﬀerential equation with right hand side given by
f(z) =
⎛
⎝
10(y −x)
x(28 −z) −y
xy −8/3z
⎞
⎠.
(9.14)
The state variable is z = (x, y, z)T ∈R3 and the forward Euler method (9.10)
with step-size δt = 0.001 is used to numerically approximate the reference tra-
jectory zref(t). The initial condition for the reference solution is
z0 = (−0.587276, −0563678, 16.8708)T.
Let us now assume that the ﬁrst component in f is replaced by
fx(z) = λ(y −x) ,
(9.15)
where λ is treated as an unknown parameter with uniform prior distribution
U[7, 11] and the initial conditions are distributed according to N(z0, I). We imple-
ment the ESRF with M = 20 ensemble members and inﬂation factor α = 1.005,
over the extended phase space (zT, λ)T ∈R4 in order to estimate the parameter
λ. Ensemble members are propagated under the forward Euler method (9.12)
and observations of zref(t) ∈R3 are assimilated in intervals of Δtout = 0.10. All
three components of the state vector z are observed with a measurement error
variance of R = 8. Since ensemble inﬂation is used, the random perturbations ϵn
i
in (9.13) are set to zero. The time evolution of the ensemble mean
λM = 1
M
M

i=1
λi
can be found in Figure 9.2. For comparison we also present results for an in-
creased inﬂation factor of α = 1.02.
The sequential parameter adaptation approach is designed to improve the
estimate of the parameter λ sequentially, as data are received. A more robust
alternative is to try to sample directly from the marginalised posterior distri-
bution for λ, using either importance or rejection sampling. Standard Markov

268
Dealing with imperfect models
0
500
1000
1500
2000
8
8 5
9
9 5
10
10 5
11
11 5
12
time
λ
Estimated parameter value with inflation α  1 005
0
500
1000
1500
2000
4
6
8
10
12
14
16
18
time
λ
Estimated parameter value with inflation α  1 02
Figure 9.2 Parameter estimation for the Lorenz-63 model. The ESRF is applied in
extended phase space (z, λ) in order to estimate the λ parameter from noisy observations
of the state vector z. An ensemble inﬂation factor of α = 1.005 and α = 1.02,
respectively, is applied and the ensemble size is M = 20. The time evolution of the
ensemble mean λM is displayed over a time interval [0, 2000]. Ensemble inﬂation leads to
a ﬂuctuation of the estimated parameter value about its correct value λ = 10. The
strength of these ﬂuctuations depends on the inﬂation factor α.
chain Monte Carlo methods would produce samples from the joint posterior dis-
tribution,
πZt0 Nobs Λ(zt0 Nobs , λ|yobs
t1 Nobs),
but we wish to sample from the marginalised posterior distribution
πΛ(λ|yobs
t1 Nobs ) =

ZNobs+1 πZt0 Nobs Λ(zt0 Nobs , λ|yobs
t1 Nobs)dzt0 Nobs .
Hence, in order to compute the importance weight (or to determine whether to
accept or reject the sample in the case of rejection sampling) we need to eval-
uate this marginalised posterior distribution for particular values of parameters
λ and observations yobs
t1 Nobs. In other words, we deﬁne a particular model Mλ
for each proposed λ value and compute the evidence for the model Mλ. The
corresponding evidence formula (9.2) can be approximated by an SIS particle
ﬁlter.
More speciﬁcally, the following Markov chain Monte Carlo algorithm samples
from the posterior distribution in the model parameter λ given an initial PDF
πZ(·, t0) for the state variable z ∈RNz, a prior PDF πΛ for the parameter λ ∈R,
and a ﬁxed set of observations yobs(tk), k = 1, . . . , Nobs, with conditional PDF
πY (y|z).
Algorithm 9.7 (Pseudo-marginal Markov chain Monte Carlo method)
A sequence
of parameters λl, l = 1, . . . , L, from its posterior PDF is obtained by the following
Markov chain Monte Carlo method.

9.2 Parameter estimation
269
Draw a realisation λ1 from the distribution πΛ and formally set E1 = 0. For
l = 1, . . . , L perform the following steps.
(i) Using the previous accepted parameter λl with evidence El, draw an initial
ensemble {z0
i }M
i=1 from πZ(·, t0) and a new proposal
λ∗= λl + ξ,
(9.16)
where ξ is a realisation of a random variable with PDF πΞ. This proposal
distribution needs to satisfy πΞ(ξ) = πΞ(−ξ).
(ii) Compute an ensemble of M trajectories {zi(tk)} of the model with param-
eter value λ = λ∗and initial values zi(t0) = z0
i . Determine the associated
evidence according to
E(yobs
t1 Nobs |Mλ∗) := 1
M
M

i=1
Nobs
1
k=1
πy(yobs(tk)|zi(tk)).
(9.17)
(iii) Accept the proposed λ∗with probability
p = min

1, E∗πΛ(λ∗)
El πΛ(λl)
;
,
where the abbreviation E∗= E(yobs
t1 Nobs |Mλ∗) has been used. If accepted,
set λl+1 = λ∗and El+1 = E∗, otherwise continue with λl+1 = λl and
El+1 = El. Increase the index l by one and return to (i) unless l = L + 1.
The sequence {λl}L
l=1, L ≫1, provides (correlated) samples from the posterior
distribution
πΛ(λ|yobs
t1 Nobs ) ∝πYt1 Nobs (yobs
t1 Nobs |λ) πΛ(λ).
Note that this conditional PDF also depends on the choice of πZ(·, t0). For no-
tational convenience we have suppressed this dependence. The above algorithm
is a special instance of the grouped independence Metropolis–Hastings (GIMH)
Monte Carlo method proposed by Beaumont (2003). The GIMH method does
not ﬁt the standard Markov chain Monte Carlo setting since it does not directly
evaluate the required marginal PDF, but instead approximates the marginal-
isation as an ensemble average. However, it can be shown that the algorithm
asymptotically samples the posterior PDF as L →∞since the computed ev-
idences El provides an unbiased approximation to πYt1 Nobs (yobs
t1 Nobs |λ) for any
ﬁnite ensemble size M (Andrieu & Roberts 2009). The GIMH method is also
referred to as the pseudo-marginal Monte Carlo method which is the term that
we use in this book.
The proposal step (9.16) can be replaced by alternative proposals such as
directly sampling from the prior distribution πΛ in which case the acceptance
probability simpliﬁes to
p = min

1, E∗
El
;
.

270
Dealing with imperfect models
Furthermore, in order to avoid a degeneracy of weights (9.4), we could replace
(9.17) by the alternative approximation provided by Algorithm 9.2.
Example 9.8
We return to the imperfect model setting from Example 9.3,
in order to evaluate the evidence for diﬀerent strength of the stochastic forcing
terms in the model (4.18)–(4.20) from Chapter 4. In this example we ﬁx the true
variance of the stochastic forcing term to 0.08383 and treat the parameter λ in
(9.15) as random with uniform prior distribution U[7, 11]. Recall that the value
used in the reference model from Example 1.1 is λ = 10.
We apply Algorithm 9.7 to this problem with proposals λ∗directly drawn
from U[7, 11]. The distribution of the initial ensemble z0
i , i = 1, . . . , M, M = 20,
is Gaussian with mean z0 = (−0.587, −0.563, 16.870)T and diagonal covariance
matrix with diagonal entries 1/15. The estimated evidence E(yobs
t1 Nobs |Mλ∗) for
each proposed λ∗is computed using Algorithm 9.2. The observations of the x
component of the state variable as generated in Example 1.2 are used and the
likelihood πY (y|z) is assumed to be Gaussian with variance R = 1/15. However
we limit the number of assimilated data points to Nobs = 20 and Nobs = 100,
respectively, and investigate its impact on the posterior distribution of the pa-
rameter. A total of L = 10, 000 samples is generated and the resulting histograms
for the parameter λ are displayed in Figure 9.3.
It should be noted that while Algorithm 9.7 allows for mathematically rigorous
sampling from the posterior parameter distribution, the sequential approach of
Algorithm 9.5 is much easier to implement, in particular when combined with
an ensemble Kalman ﬁlter. Therefore the later approach is often preferable when
considering large systems and parameter distributions that can be assumed to
be close to Gaussian.
9.3
Molliﬁed data assimilation
In the previous section we described how model errors can be compared and
minimised during the data assimilation process. In this section, we describe how
model errors can lead to unrealistic dynamics when combined with Bayesian data
assimilation. We then introduce techniques that attempt to apply the Bayesian
update in a less impulsive manner, with the aim of reducing this eﬀect.
We start with a discussion of model errors in terms of dynamical systems and
their attractors. Assume that the underlying surrogate physical process {zn
ref}n≥0
satisﬁes a dynamical system
zn+1
ref
= ψref(zn
ref),
for some appropriate map ψref : RNz →RNz. On the other hand, assume that

9.3 Molliﬁed data assimilation
271
8 5
9
9 5
10
10 5
11
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
parameter value
relative frequency of MCMC samples for Nobs = 100
8 5
9
9 5
10
10 5
11
0
0 05
0 1
0 15
0 2
0 25
0 3
0 35
0 4
parameter value
relative frequency of MCMC samples for Nobs = 20
Figure 9.3 Parameter estimation using the pseudo-marginal Markov chain Monte Carlo
method. Samples λl from the posterior distribution of the λ parameter in (9.15) are
generated using a total of Nobs = 100 (left panel) and Nobs = 20 (right panel),
respectively, observations. Each histogram is based on 10,000 samples. The proposal step
of the pseudo-marginal Markov chain Monte Carlo method uses the SIR particle ﬁlter
implementation of the underlying data assimilation problem. It can be seen that the larger
Nobs value leads to a more focused posterior distribution and the imprint of the prior
parameter distribution U[7, 11] is reduced.
our forecast model is given by the dynamical system
zn+1 = ψ(zn).
We assume that both dynamical systems possess unique global attractors Aref
and A, respectively. We also assume that zn ∈A and zn
ref ∈Aref for n suﬃciently
large.
Partial observations of zn
ref, n ≥0, are generated according to
yn
obs = h(zn
ref) + ξn,
where the variables {ξn} are independent realisations of a Gaussian N(0, R)
random variable. Even if zn
ref ∈Aref, measurement errors lead to observations
that are not consistent with data on the attractor, i.e.,
yn
obs /∈h(Aref).
To quantify this discrepency, we introduce the distance
d(y, B) = inf
y′∈B ∥y −y′∥
between a point y ∈RNy and a set B ⊂RNy in observation space. We see
that relatively small measurement errors and large model errors can lead to a
situation where
d(h(zn), h(Aref)) ≫d(yn
obs, h(Aref)).

272
Dealing with imperfect models
If this situation occurs, and zn is then used as the forecast value zf in a data
assimilation cycle, we can expect that the analysis za will be pulled oﬀthe
attractor A towards Aref, i.e.
d(h(za), h(A)) ≫0,
even though zf ∈A. As a consequence, data assimilation can create analy-
sis states that will trigger the forecast model to readjust rapidly towards its
attractor A. These rapid data driven model adjustments are untypical of real
trajectories, and we will introduce molliﬁcation and nudging as techniques to
reduce them. Furthermore, model generated ensembles might lead to a severe
misrepresentation of forecast errors, which puts the Bayesian perspective of data
assimilation into question.
Most dynamical systems considered throughout this book have been derived
as forward Euler discretisations of an underlying ODE. However, in the current
context it is easier to discuss algorithms based on the underlying continuous time
ODE formulation. In particular, we reformulate sequential data assimilation for
an ensemble prediction model
dzi
dt = f(zi),
i = 1, . . . , M,
in terms of an additional driving or nudging term to the model, i.e.,
dzi
dt = f(zi) +
Nobs

k=1
δ(t −tk)gi({zj}M
j=1, yobs(tk)),
(9.18)
where the functions gi, i = 1, . . . , M, depend on the whole ensemble and the
observations yobs(tk). Here, as before, δ(s) denotes the Dirac delta function.
In other words, assimilation of data eﬀectively leads to an interacting particle
system. We see that each ensemble member propagates independently of the
rest of the ensemble, except at observation times t = tk, when it undergoes an
impulsive “kick” from the nudging term, designed to keep the overall ensemble
close to the observations.
In order to understand the implied mathematical structure, the Dirac delta
function should be replaced by a family of approximations δε(s) ≥0, ε > 0, with
the properties that

R
δε(s)ds = 1,
and
lim
ε→0

R
h(s)δε(s)ds = h(0),
for all smooth functions h. Consider, for example, the step-function approxima-
tion
δε(s) =
 0
for |s| ≥ε/2,
1/ε
otherwise.
(9.19)

9.3 Molliﬁed data assimilation
273
Upon replacing the Dirac delta function in (9.18) by δε(s) and taking the limit
ε →0 we ﬁnd that (9.18) is equivalent to:
(i) integrating the model equations up to time tk, denoting the resulting
ensemble by {zf
i}, then
(ii) solving the system
dzi
ds = gi({zj}M
j=1, yobs(tk))
(9.20)
over a unit time interval in the ﬁctitious time s ∈[0, 1] with initial
conditions zi(0) = zf
i, and ﬁnally
(iii) using the solutions at s = 1 of Equation (9.20) to provide the analysed
ensemble {za
i }, which is used as input to the model equations at tk to
advance the ensemble beyond tk up to the next observation point tk+1.
Hence (9.18) is indeed equivalent to sequential ensemble data assimilation, as
discussed throughout this book, provided the ﬁctitious dynamics (9.20) can be
chosen such that they induce a (possibly only approximate) transformation from
the prior to the posterior distribution.
We put the ensemble-based framework aside for a moment, and consider a
simple deterministic nudging approach given by
dz
dt = f(z) −

k≥1
δ(t −tk)BHTR−1(Hz −yobs(tk)),
(9.21)
where B ∈RNz×Nz is a positive-deﬁnite matrix.1 This equation is for a single
trajectory z(t) that follows the model dynamics until an observation is taken, in
which case it is nudged towards the observation. As we have already discussed,
this leads to unphysical dynamics for z if it is pulled away from the model
attractor A, so we would like to nudge the system in a more “gentle” manner.
This can be done by replacing the Dirac delta function with a regularised Dirac
delta function,
dz
dt = f(z) −

k≥1
δε(t −tk)BHTR−1(Hz −yobs(tk)),
(9.22)
with the parameter ε > 0 chosen appropriately. In particular, the regularised
Dirac delta function δε needs to be chosen such that solutions z(t) are pulled
smoothly towards zref(t) ∈Aref. Hence we replace (9.19) by the continuous
function
δε(s) =
 0
for |s| ≥ε,
ε−2(ε −|s|)
otherwise.
The system (9.22) can be integrated in time by a standard time-stepping method
such as the explicit Euler method or the implicit midpoint rule. The regularised
1 In the case where B is constant in time, this type of system is closely related to a data
assimilation technique called 3DVar, where the matrix B is called the background
covariance matrix. See Kalnay (2002) and Evensen (2006) for more details.

274
Dealing with imperfect models
function δε is referred to as a molliﬁed Dirac delta function, and so we call this
system molliﬁed nudging.
We would like to generalise this molliﬁed approach to arbitrary data assimila-
tion algorithms in the McKean setting. This is done by ﬁrst writing the trans-
formation from prior to posterior distributions in the form of Equation (9.20).
This then deﬁnes the form of the functions {gi} in Equation (9.18). Finally, the
Dirac delta function in that equation can be replaced by a molliﬁed Dirac delta
function δϵ.
Having established this approach, we will spend the rest of this section de-
scribing how to write our various prior-to-posterior transformations in the form
of Equation (9.20). We start with the case in which all of the PDFs are Gaussian
and the observation operator is linear, i.e. the Kalman update step.
Proposition 9.9 (Kalman–Bucy equations)
The standard Kalman update step
for the mean and covariance matrix can be formulated as a diﬀerential equation
in artiﬁcial time s ∈[0, 1]. The Kalman–Bucy equations are
dz
ds = −PHTR−1(Hz −yobs)
(9.23)
and
dP
ds = −PHTR−1HP.
(9.24)
The initial conditions are z(0) = zf and P(0) = P f and the Kalman update is
obtained from the ﬁnal conditions za = z(1) and P a = P(1).
Proof
We present the proof for Nz = 1 (one-dimensional state space), Ny = 1 (a
single observation), and H = 1. Under these assumptions, the standard Kalman
analysis step gives rise to
P a =
P fR
P f + R,
za = zfR + yobsP f
P f + R
,
for a given observation value yobs.
We now demonstrate that one single Kalman analysis step is equivalent to
the succesive application of two Kalman analysis steps with R replaced by 2R.
Speciﬁcally, we obtain
ˆP a =
2PmR
Pm + 2R,
Pm =
2P fR
P f + 2R,
for the variance ˆP a with intermediate value Pm. The analysis mean ˆza is provided
by
ˆza = 2zmR + yobsPm
Pm + 2R
,
zm = 2zfR + yobsP f
P f + 2R
.
We need to demonstrate that P a = ˆP a and za = ˆza. We start with the variance

9.3 Molliﬁed data assimilation
275
and obtain
ˆP a =
4P fR
P f+2RR
2P fR
P f+2R + 2R
=
4P fR2
4P fR + 4R2 =
P fR
P f + R = P a.
A similar calculation for ˆza yields
ˆza =
2 2zfR+yobsP f
P f+2R
R + yobs 2P fR
P f+2R
2R +
2P fR
P f+2R
= 4zfR2 + 4yobsP fR
4R2 + 4RP f
= za.
Hence, by induction, we can replace the standard Kalman analysis step by D > 2
iterative applications of a Kalman analysis with R replaced by DR. We set
P0 = P f, z0 = zf, and iteratively compute Pj+1 and zj+1 from
Pj+1 =
DPjR
Pj + DR,
zj+1 = DRzj + Pjyobs
Pj + DR
for j = 0, . . . , D −1. We ﬁnally set P a = PD and za = zD. Next we introduce a
step-size δs = 1/D and assume D ≫1. Then
zj+1 = Rzj + δsPjyobs
R + δsPj
= zj −δsPjR−1 (zj −yobs) + O(δs2)
as well as
Pj+1 =
PjR
R + δsPj
= Pj −δsPjR−1Pj + O(δs2).
Taking the limit δs →0, we obtain the two diﬀerential equations
dP
ds = −PR−1P,
dz
ds = −PR−1 (z −yobs)
for the variance and mean, respectively. The equation for P can be rewritten in
terms of its square root P 1/2 as
dP 1/2
ds
= −1
2PR−1P 1/2.
(9.25)
Next we recall the deﬁnition (7.19) of the ensemble anomalies matrix A from
Chapter 7, which satisﬁes P = 1/(M −1)AAT. It is easy to verify that the square
root P 1/2 can be replaced by the matrix of ensemble anomalies A in (9.25) and
we obtain the ensemble transform Kalman–Bucy ﬁlter equations of Bergemann
& Reich (2010), Bergemann & Reich (2012) and Amezcua, Kalnay, Ide & Reich
(2014).
Definition 9.10 (Ensemble transform Kalman–Bucy ﬁlter equations)
The ensem-
ble transform Kalman–Bucy ﬁlter equations for the assimilation of an observation
yobs = yobs(tk) at tk are given by
dzi
ds = −1
2PMHTR−1(Hzi + HzM −2yobs)

276
Dealing with imperfect models
in terms of the ensemble members zi, i = 1, . . . , M, and are solved over a unit
time interval in artiﬁcial time s ∈[0, 1] with initial conditions zi(0) = zf
i. Here
PM(s) =
1
M −1
M

i=1
(zi(s) −zM(s))(zi(s) −zM(s))T
denotes the empirical covariance matrix, zM(s) the empirical mean of the en-
semble, and the analysis ensemble is given at s = 1 by za
i = zi(1). The nudging
formulation of an ESRF is therefore given by the coupled system of ODEs
dzi
dt = f(zi) −1
2

k≥1
δε(t −tk)PMHTR−1(Hzi + HzM −2yobs(tk)),
(9.26)
i = 1, . . . , M, and replaces (9.22).
Note that (9.26) leads to the evolution equation
dzM
dt
= 1
M
M

i=1
f(zi) −

k≥1
δε(t −tk)PMHTR−1(HzM −yobs(tk))
for the ensemble mean. After making the approximation
1
M
M

i=1
f(zi) →f(zM)
we obtain
dzM
dt
= f(zM) −

k≥1
δε(t −tk)PMHTR−1(HzM −yobs(tk)),
which can be compared to (9.21). In fact we can consider hybrid data assimilation
techniques in which the ensemble generated covariance matrix PM is replaced
by a linear combination αPM + (1 −α)B in (9.26) with α ∈(0, 1).
The ensemble transform Kalman–Bucy equations are an approximation to the
diﬀerential equation
dZ
ds = −1
2PHTR−1(HZ + Hz −2yobs)
(9.27)
in the random variable Z with mean
z = E[Z] =

RNz
zπZdz
and covariance matrix
P = E[(Z −z)(Z −z)T].
The associated evolution of the PDF πZ(z, s) (here assumed to be absolutely
continuous) is given by Liouville’s equation
∂πZ
∂s = −∇z · (πZv)
(9.28)

9.3 Molliﬁed data assimilation
277
with velocity ﬁeld
v(z) = −1
2PHTR−1(Hz + Hz −2yobs).
(9.29)
Recalling the earlier discussion of the Fokker–Planck equation in Chapter 5,
we note that (9.28) with velocity ﬁeld (9.29) also has an interesting geometric
structure.
Proposition 9.11 (Ensemble transform Kalman–Bucy equations as a gradient ﬂow)
The velocity ﬁeld (9.29) is equivalent to
v(z) = −P∇z
δF
δπZ
with potential
F(πZ) = 1
4

RNz
(Hz −yobs)TR−1(Hz −yobs)πZdz
+ 1
4(Hz −yobs)TR−1(Hz −yobs).
(9.30)
Liouville’s equation can be stated as
∂πZ
∂s = −∇z · (πZv) = −gradπZF(πZ).
Proof
The result can be veriﬁed by direct calculation using the deﬁnitions from
Appendix 5.6 with M = P.
Nonlinear forward operators can be treated in this framework by replacing the
potential (9.30) by, for example,
F(πZ) = 1
4

RNz
(h(z) −yobs)TR−1(h(z) −yobs)πZdz
+ 1
4(h(z) −yobs)TR−1(h(z) −yobs).
Further, eﬃcient time-stepping methods for the ensemble transform Kalman–
Bucy ﬁlter equations are discussed in Amezcua et al. (2014); an application to
continuous data assimilation can be found in Bergemann & Reich (2012).
In the regime of strong model errors and relatively accurate measurements, it
might also be helpful to increase the ensemble spread artiﬁcially with ensemble
inﬂation and, at the same time, nudge the ensemble mean more closely towards
the observations. This can be achieved by modifying (9.29) to
v(z) = −1
2PHTR−1(αHz + βHz −(α + β)yobs)
with the two non-negative parameters α<1 and β>1 chosen such that α+β>2.
So far we have discussed a continuous formulation of the ESRF. The corre-
sponding equation for the EnKF with perturbed observations is given by
dZ = −PHTR−1(HZ −yobs)ds + PHTR−1/2dW,
(9.31)

278
Dealing with imperfect models
where W(s) denotes standard Brownian motion. Indeed an Euler–Maruyama
discretisation of (9.31) with step-size δs leads to
Zn+1 = Zn −δsP nHTR−1(HZn −yobs) +
√
δsP nHTR−1/2Ξn
with Ξn ∼N(0, I). We can immediately extract the associated evolution for the
mean z which is
zn+1 = zn −δsP nHTR−1(Hzn −yobs).
The update for the covariance matrix is a bit more involved. We introduce the
shorthand δZn = Zn −zn and use the independence of Ξn and Zn in order to
obtain
P n+1 = E
#
(Zn+1 −zn+1)(Zn+1 −zn+1)T$
= E
!
(δZn −δsP nHTR−1HδZn +
√
δsP nHTR−1/2Ξn)
(δZn −δsP nHTR−1HδZn +
√
δsP nHTR−1/2Ξn)T"
= P n −2δsP nHTR−1HP n
+ δs2P nHTR−1HP nHTR−1HP n + δsP nHTR−1HP n
= P n −δsP nHTR−1HP n + δs2P nHTR−1HP nHTR−1HP n.
Upon taking the limit δs →0 we conclude that (9.31) is consistent with the
continuous Kalman–Bucy equations (9.23)–(9.24).
The continuous EnKF formulation (9.31) also reveals another interesting op-
tion for extending the EnKF to nonlinear forward operators h(z). We simply
replace PHT in (9.31) by
Pzh = E[(Z −z)(h(Z) −h)T]
(9.32)
in order to obtain
dZ = −PzhR−1(h(Z) −yobs)ds + PzhR−1/2dW.
(9.33)
Equation (9.33) can be thought of as providing a stochastic linearisation by
directly utilising the correlation between state and observation space.
Example 9.12
We consider a single Bayesian analysis step with the EnKF
with perturbed observations applied to an ensemble of size M = 2000 from a
Gaussian prior with mean zf = −2 and variance σ2 = 1/2. The forward model
is given by
Y = 7
12z3 −7
2z2 + 8z + Ξ
with Ξ ∼N(0, 1). The observed value is yobs = 2.0. This example has already
been investigated in Example 5.9. The resulting posterior PDF and ensemble
histograms from the single-step standard EnKF with perturbed observations as
well as its continuous counterpart can be found in Figure 9.4. The continuous

9.3 Molliﬁed data assimilation
279
−4
−3
−2
−1
0
1
0
2
4
probability density functions
 
 
−4
−3
−2
−1
0
1
0
0.5
position
relative frequency, continuous EnKF
−4
−3
−2
−1
0
1
0
0.5
relative frequency, EnKF
prior
likelihood
posterior
Figure 9.4 Comparison between the standard EnKF with perturbed observations and its
continuous formulation for a Gaussian prior but strongly nonlinear forward operator.
Displayed are the analytic prior and posterior PDFs as well as relative frequencies from an
ensembles of size M = 2000 for each of the two methods. The continuous formulation
clearly leads to a closer agreement with the analytic posterior PDF.
EnKF formulation (9.33) obviously leads to a better agreement with the posterior
PDF than the standard EnKF with perturbed observations based on a single
evaluation of the covariance matrix Pzh over the prior ensemble. The continuous
formulation is discretised by the forward Euler–Maruyama method with step-size
δs = 1/2000.
We now summarise a continuous formulation of Bayes’ formula which gener-
alises the continuous EnKF formulation from above, addressing the question of
how to deﬁne gi in (9.18) for non-Gaussian prior distributions within a Bayesian
framework. However, it should be kept in mind that the Bayesian framework
might not be appropriate in the case of strong and systematic model errors
which might lead to an inappropriate ensemble distribution relative to the un-
derlying reference solution zref(t) from which the observations yobs(tk) are drawn.
In fact, the robustness of the ensemble Kalman ﬁlter techniques with respect to
unavoidable model errors has contributed much to the popularity of the method.
We ﬁrst note that a single application of Bayes’ formula can be replaced by a

280
Dealing with imperfect models
D-fold recursive application of the incremental likelihood BπY :
BπY (y|z) =
1
(2πD)Ny/2|R|1/2 exp

−1
2D (h(z) −y)T R−1 (h(z) −y)

,
(9.34)
i.e., we ﬁrst write Bayes’ formula as
πZ(z|yobs) ∝πZ(z)
D
1
j=1
BπY (yobs|z),
where the constant of proportionality depends only on yobs, and then consider
the implied iteration
πj+1(z) =
πj(z) BπY (yobs|z)

RNz BπY (yobs|z) πj(z) dz
(9.35)
with π0 = πZ and πZ(·|yobs) = πD. We write (9.35) more compactly as
πj+1(z) = πj(z) exp(−δsL)
E[exp(−δsL)],
(9.36)
where δs = 1/D and L denotes the negative log likelihood function
L(z; yobs) = 1
2 (h(z) −yobs)T R−1 (h(z) −yobs) .
(9.37)
We now expand the exponential functions in (9.36) in the small parameter δs,
and obtain
exp(−δsL)
E[exp(−δsL)] ≈1 −δsL
1 −δsL ≈1 −δs(L −L),
(9.38)
which implies
πj+1(z) −πj(z)
δs
≈−πj(z)(L(z) −L)
with L = E[L(Z; yobs)]. Finally, upon taking the limit δs →0, we derive the
evolution equation
∂πZ
∂s = −πZ

L −L

(9.39)
in the ﬁctitious time s ∈[0, 1]. We set πZ(z, 0) = πZ(z) at s = 0 and obtain
πZ(z|yobs) = π(z, 1) at s = 1.
It should be noted that the continuous embedding deﬁned by (9.39) is not
unique. Moser (1965), for example, used the linear interpolation
πZ(z, s) = (1 −s)πZ(z) + sπZ(z|yobs),
which results in
∂πZ
∂s = πZ(z|yobs) −πZ(z).
(9.40)
Equation (9.39) (or, alternatively, (9.40)) deﬁnes the change (or transport) of
the PDF πZ in ﬁctitious time s ∈[0, 1]. Alternatively, following Moser (1965)

9.3 Molliﬁed data assimilation
281
and Villani (2003), we can view this change as being induced by a continuity
(Liouville) equation
∂πZ
∂s = −∇z · (πZg)
(9.41)
for an appropriate vector ﬁeld g(z, s) ∈RNz.
At any time s ∈[0, 1] the vector ﬁeld g(·, s) is not uniquely determined by
(9.39) and (9.41), unless we also require that it is the minimiser of the kinetic
energy
T (v) = 1
2

RNz
πZvTM−1v dz
over all admissible vector ﬁelds v : RNz →RNz, where M ∈RNz×Nz is a symmet-
ric, positive deﬁnite matrix. Here admissible means that the vector ﬁeld satisﬁes
(9.41) for given πZ and ∂πZ/∂s. Under these assumptions, minimisation of the
functional
L[v, ψ] = 1
2

RNz
πZvTM−1v dz +

RNz
ψ
∂πZ
∂s + ∇z · (πZv)
;
dz
for given πZ and ∂πZ/∂s leads to the Euler–Lagrange equations
πZM−1g −πZ∇zψ = 0,
∂πZ
∂s + ∇z · (πZg) = 0
in the velocity ﬁeld g = v and the potential ψ. Hence, provided that πZ(z, s) > 0,
the desired vector ﬁeld is given by g = M∇zψ, and we have shown the following
result.
Proposition 9.13 (Transport map from gradient ﬂow)
If the potential ψ(z, s)
is the solution of the elliptic PDE
∇z · (πZM∇zψ) = πZ

L −L

,
(9.42)
then the desired transport map z′ = T (z) for the random variable Z with PDF
π(z, s) is deﬁned by the time-one-ﬂow map of the diﬀerential equation
dz
ds = −M∇zψ.
(9.43)
If the PDF πZ(z, s) is approximated by a Gaussian, then the elliptic PDE
(9.42) can be solved analytically, and the resulting diﬀerential equations are
equivalent to the ensemble transform Kalman–Bucy equations (9.27). Appro-
priate analytic expressions can also be found if πZ(z, s) is approximated by a
Gaussian mixture and the forward map h(z) is linear (see Reich (2012) for de-
tails).
Problems
9.1
Verify Equation (9.5) for Nobs = 2 and under the assumption that the
transition kernel π(z′|z) describes the Markovian model dynamics in between

282
Dealing with imperfect models
observations. Hint: note that
E
#
πYt1 2 (yt1 2|Zt0 2)
$
=

Z

Z

Z
πY (y(t2)|z2)π(z2|z1)πY (y(t1)|z1)π(z1|z0)πZ(z0, 0)dz0dz1dz2.
9.2
Use the experimental setting from Example 9.3 and ensemble prediction
in order to approximate the evidence (9.2) as a function of the variance σ2
in the stochastic driving terms of the modiﬁed Lorenz-63 model (4.18)–(4.20).
Instead of one hundred ensembles of size M = 1000, use a single ensemble of
size M = 10000 and assimilate only the ﬁrst 50 observations, i.e., set Nobs = 50.
Compare your ﬁndings with those displayed in Figure 9.1.
9.3
Repeat the numerical experiment from Example 9.6 with a prior distribu-
tion of U[6, 10] in λ. Compare your ﬁndings with those from Figure 9.2.
9.4
Derive explicit solution formulas for the diﬀerential equation
dz
dt = −az + δε(t −1)bz
over the time interval t ∈[0, 2] with initial condition z(0) = 1, a, b given param-
eters, and the molliﬁed Dirac delta function given by (9.19). Discuss the limit
ε →0.
9.5
Repeat Example 9.12 with yobs = 0 and δs = 1/200. What do you observe
for δs = 1/100? In order to explain your ﬁndings you may wish to consult the
paper by Amezcua et al. (2014).
9.6
Verify that the continuous Kalman–Bucy ﬁlter equations are a special case
of (9.43) with M = P and ψ = δF/δπZ with the functional F given by (9.30).
9.7
Consider the sequence of univariate random variables
δYj := hδs +
√
δsΞj,
j = 1, . . . , D,
where the random variables {Ξj} are Gaussian and identically distributed with
mean zero and variance one, h is a given constant, δs = t/D is the step-size and
D the number of steps. We are interested in the properties of the sum of squares
SD =
D

j=1
(δYj)2
in the limit D →∞.
(i)
Show that
lim
D→∞E[SD] = t.
(ii)
What do you obtain for var (SD) as D →∞? Remark: The results of
this problem can be used to justify (9.49) from Appendix 9.5.

9.4 Guide to literature
283
9.4
Guide to literature
A stimulating discussion of chaos, imperfect models and predictions is given by
Smith (2007b). Data assimilation for imperfect models and parameter estima-
tion are also discussed in Majda & Harlim (2012). Raftery (1995) provides an
introduction to Bayesian model selection. Classical variational techniques for
parameter estimation are, for example, covered in Tarantola (2005), and the
textbook by S¨arkk¨a (2013) discusses parameter estimation techniques based on
Monte Carlo methods.
A discussion of general Markov chain Monte Carlo methods can be found in
Liu (2001) and Robert & Casella (2004). The pseudo-marginal Markov chain
Monte Carlo method is described by Beaumont (2003) and Andrieu & Roberts
(2009).
The use of nudging to initialise forecast models goes back to Hoke & An-
thes (1976). Incremental or molliﬁed data analysis was ﬁrst proposed by Bloom,
Takacs, Silva & Ledvina (1996). Molliﬁed ensemble Kalman ﬁlter implementa-
tions are implemented in Bergemann & Reich (2010) in the context of a Lorenz-
96 model coupled to a linear wave equation, where the generation of spurious
unbalanced waves through intermittent assimilation of data is studied.
The idea of a continuous reformulation of the ensemble Kalman analysis step
is also closely related to iterative approaches to data assimilation for strongly
nonlinear forward operators as proposed, for example, by Sakov, Oliver & Bertino
(2012), Chen & Oliver (2013), and Emerik & Reynolds (2012). These iterative
algorithms can also be viewed as derivative-free implementations of a regularised
Levenberg–Marquardt algorithm for ill-posed inverse problems (Engl, Hanke &
Neubauer 2000).
See Daum & Huang (2011) and Reich & Cotter (2013) for further discussions
on the implementation of (9.42)–(9.43) in the context of nonlinear ﬁlters.
Theoretical results on the ability of ﬁltering algorithms of type (9.22) to track a
partially observed reference solution for hyperbolic systems, such as the Lorenz-
63 model, over inﬁnite time intervals can be found, for example, in Gonz´alez-
Tokman & Hunt (2013) and Law, Shukia & Stuart (2014).
9.5
Appendix: Continuous-time ﬁltering
Throughout this book we have considered measurements taken at discrete times
tk. However, it is also possible to consider continuous measurements with forward
model
dY = h(Z)dt + R1/2dW ,
(9.44)
where W(t) denotes Ny-dimensional Brownian motion. While discrete-time ob-
servations are more common from a practical point of view, the continuous data
model (9.44) can often be found in mathematical textbooks on ﬁltering because

284
Dealing with imperfect models
of its mathematical elegance. Without proof we state the associated ensemble
Kalman–Bucy ﬁlter formulation with perturbed observations
dZ = f(Z)dt −PzhR−1(h(Z)dt −dyobs(t) + R1/2dW)
(9.45)
and we see that the original dynamics, given by
dZ = f(Z)dt ,
(9.46)
is now constantly nudged towards the observed dyobs(t). Here the cross-correlation
covariance matrix Pzh is deﬁned by (9.32). The equation (9.45) can be discretised
in time by the Euler–Maruyama method. In fact, a derivation of (9.45) starts
from such a discrete-time formulation together with a discretised forward model
δY = h(Z)δt + (δtR)1/2Ξ,
Ξ ∼N(0, I), and subsequent limit δt →0.
Example 9.14
We consider the discretised Lorenz-63 system (9.9) from Ex-
ample 9.6 with right hand side given by (9.14). However, instead of intermittent
observations and misspeciﬁed parameter values, we now consider the forward
observation model
δyn
obs = eT
1 f(zn
ref)δt +
√
δtξn
with e1 = (1, 0, 0)T and ξn a realisation of N(0, 1), i.e., h(z) = eT
1 f(z) and we ob-
serve a noisy version of the increments in the x-component of the reference solu-
tion. The computational data assimilation model is given by an Euler–Maruyama
discretisation of the continuous EnKF formulation (9.45), i.e.,
zn+1
i
= zn
i + δtf(zn) −PzhR−1 &
eT
1 f(zn)δt −δyn
obs +
√
δtR1/2ζn'
,
(9.47)
where R = 1 in our setting, the variables {ζn} are independent realisations
of N(0, 1), and the empirical correlation matrix between state and observation
variables is given by
Pzh =
1
M −1
M

i=1
(zn
i −zn)
.
eT
1 f(zn
i ) −1
M
M

i=1
eT
1 f(zn
i )
/
.
In this example, the ensemble size is set to M = 20, the step-size is δt = 0.0025,
and the initial ensemble is generated as outlined in Example 9.6. The time-
averaged RMSE along the whole trajectory and averaged over all three solution
components is found to be 0.1890. See Figure 9.5 for numerical results.
We end this appendix with a brief discussion of the general continuous data
assimilation problem in terms of an evolution equation for the marginal PDF
πZ(z, t). In order to derive this evolution equation we consider continuous mea-
surements of type (9.44) and apply a discretisation with an outer step-size δt and

9.5 Appendix: Continuous-time ﬁltering
285
0
2
4
6
8
10
5
0
5
continuous EnKF
error in z−component
0
2
4
6
8
10
0
20
40
60
time
z−component
Figure 9.5 Continuous EnKF applied to
the Lorenz-63 model. Displayed are the
z-component of the ﬁltered solution and
its error with respect to the reference
solution.
an inner step-size δs = δt/D, D ≫1. The Euler–Maruyama method is applied
at the inner time-step resulting in
δyj = h(zref(t))δs +
√
δsR1/2ξj,
where {ξj} are independent realisations from the N(0, I) distribution. The outer
approximation is then given by
δyobs =
D

j=1
δyj .
(9.48)
We now proceed along the lines of (9.35) with conditional PDFs
π(δyj|z) ∝e−Lj
and negative log likelihood functions
Lj(z; δyj) = 1
2
&
h(z)δs1/2 −δs−1/2δyj
'T
R−1 &
h(z)δs1/2 −δs−1/2δyj
'
.
Following the previous discussion on the continuous Bayesian formalism, we con-
sider the iteration
πj+1(z) = πj(z) exp(−Lj)
E[exp(−Lj)].
Due to the presence of the δs−1/2 term in Lj, the exponential function needs to
be expanded more carefully in order to keep all terms of order O(δs). In order
to simplify the notation, we continue the discussion for a scalar observation, set
R = 1, and drop the argument in the forward map h. We also immediately drop
all terms that give rise to contributions of order O(δs3/2). This leads to the

286
Dealing with imperfect models
following approximations:
exp(−Lj)
E[exp(−Lj)] =
exp

−1
2h2δs + hδyj

E[exp

−1
2h2δs + hδyj

]
≈1 −1
2h2δs + hδyj + 1
2h2δy2
j
1 −1
2h2δs + hδyj + 1
2h2δy2
j
≈

1 −1
2h2δs + hδyj + 1
2h2δy2
j

×

1 + 1
2h2δs −hδyj −1
2h2δy2
j + h
2δy2
j

≈1 −1
2(h2 −h2)δs + 1
2(h2 −2hh + 2h
2 −h2)δy2
j + (h −h)δyj.
Since δt = Dδs and (9.48) the D-fold product can be approximated as
D
1
j=1
exp(−Lj)
E[exp(−Lj)] ≈1 −1
2
D

j=1
(h2 −h2)δs
+
D

j=1

(h −h)δyj + 1
2(h2 −2hh + 2h
2 −h2)δy2
j
;
≈1 −1
2(h2 −h2)δt + (h −h)δyobs
+
D

j=1
δy2
j
1
2(h2 −h2) −(h −h)h
;
.
Note that (compare Problem 9.7)
lim
D→∞
D

j=1
δy2
j ≈δt
(9.49)
and the evolution of the marginal PDF πZ(z, t) under a continuous observation
over a time increment δt can be approximated by
πZ(z, t + δt) ≈πZ(z, t) + πZ(z, t)
9
(h(z) −h)TR−1(δyobs −hδt)
:
.
We ﬁnally take the limit δt →0, return to the general observation model with
covariance matrix R, and obtain the evolution equation
dπZ = πZ (h −E[h(Z)])TR−1(dyobs −E[h(Z)]dt),
(9.50)
which provides the “nudging” part of the Kushner–Stratonovitch ﬁlter equation
dπZ = −∇z · (πZf)dt + πZ (h −E[h(Z)])TR−1(dyobs −E[h(Z)]dt),
(9.51)
under an observed process yobs(t). See Jazwinski (1970) for a related derivation
and more details.
The Kushner–Stratonovitch equation (9.51) generalises the Liouville (or more
generally Fokker–Planck) equation for the marginal PDFs under the dynamic

9.5 Appendix: Continuous-time ﬁltering
287
model to the continuous time observation case. The theory of continuous time
ﬁltering is covered, for example, in Jazwinski (1970) and Øksendal (2000).
As for the evolution equation (9.39) for the marginal PDF πZ under a discrete-
time observation, the contribution (9.50) can be given an interpretation as pro-
viding additional driving terms to the model equation (9.46). However, the
derivation of these driving terms and McKean-type continuous time ﬁltering
techniques are beyond the mathematical machinery developed in this book and
we refer the interested reader to Crisan & Xiong (2010) and Yang, Mehta & Meyn
(2013). We mention that the additional driving terms reduce to the Kalman–
Bucy terms considered earlier in this section in the case of a Gaussian πZ and
linear forward operator (Bergemann & Reich 2012).

A postscript
We have come to the end of our introduction to ensemble-based forecasting and
data assimilation algorithms. The ﬁeld is rapidly developing and key challenges
come from imperfect model scenarios and the high dimensionality of models.
While certain particle ﬁlters are asymptotically optimal within a perfect model
scenario, this picture is much less clear for “real world” data assimilation prob-
lems. Here the ensemble Kalman ﬁlter has been shown to be both robust and
suﬃciently accurate for many practical problems. However, it should be kept
in mind that most successful applications of the ensemble Kalman ﬁlter have
arisen against a background of relatively advanced mechanistic models and for
problems for which the forecast uncertainties can be approximated by Gaussian
distributions. Further challenges arise when, in the absence of accepted mech-
anistic design principles, only crude empirical models are available and model
parameters as well as model states need to be estimated. Ideally, in such cases
one might wish to convert empirical models into mechanistic design principles
by extracting causalities from data using data assimilation algorithms. These
topics are beyond our introductory textbook and we end by inviting the reader
to become an active participant in the exciting enterprise called probabilistic
forecasting and data assimilation.

References
Amezcua, J., Kalnay, E., Ide, K. & Reich, S. (2014), ‘Ensemble transform Kalman–Bucy
ﬁlters’, Q.J.R. Meteor. Soc. 140, 995–1004.
Anderson, J. (2007), ‘An adaptive covariance inﬂation error correction algorithm for
ensemble ﬁlters’, Tellus 59A, 210–224.
Anderson, J. (2010), ‘A non-Gaussian ensemble ﬁlter update for data assimilation’,
Mon. Wea. Rev. 138, 4186–4198.
Anderson, J. (2012), ‘Localization and sampling error correction in ensemble Kalman
ﬁlter data assimilation’, Mon. Wea. Rev. 140, 2359–2371.
Andrieu, C. & Roberts, G. (2009), ‘The pseudo-marginal approach for eﬃcient Monte-
Carlo computations’, Ann. Statist. 37, 697–725.
Arnold, V. (1989), Mathematical Methods of Classical Mechanics, 2nd edn, Springer-
Verlag, New York.
Arulampalam, M., Maskell, S., Gordon, N. & Clapp, T. (2002), ‘A tutorial on parti-
cle ﬁlters for online nonlinear/non-Gaussian Bayesian tracking’, IEEE Trans. Sign.
Process. 50, 174–188.
Ascher, U. (2008), Numerical Methods for Evolutionary Diﬀerential Equations, SIAM,
Philadelphia, PA.
Bain, A. & Crisan, D. (2009), Fundamentals of Stochastic Filtering, Vol. 60 of Stochastic
Modelling and Applied Probability, Springer-Verlag, New York.
Beaumont, M. (2003), ‘Estimation of population growth or decline in genetically mon-
itored populations’, Genetics 164, 1139–1160.
Benamou, J. & Brenier, Y. (2000), ‘A computational ﬂuid mechanics solution to the
Monge–Kantorovitch mass transfer problem’, Numer. Math. 84, 375–393.
Bengtsson, T., Bickel, P. & Li, B. (2008), ‘Curse of dimensionality revisited: Collapse
of the particle ﬁlter in very large scale systems’. In IMS Collections, Probability and
Statistics: Essays in Honor of David F. Freedman, 2, 316–334.
Bergemann, K. & Reich, S. (2010), ‘A molliﬁed ensemble Kalman ﬁlter’, Q.J.R. Mete-
orolog. Soc. 136, 1636–1643.
Bergemann, K. & Reich, S. (2012), ‘An ensemble Kalman–Bucy ﬁlter for continuous
data assimilation’, Meteorolog. Zeitschrift 21, 213–219.
Bloom, S., Takacs, L., Silva, A.D. & Ledvina, D. (1996), ‘Data assimilation using in-
cremental analysis updates’, Q.J.R. Meteorolog. Soc. 124, 1256–1271.
Bocquet, M. & Sakov, P. (2012), ‘Combining inﬂation-free and iterative ensemble
Kalman ﬁlters for strongly nonlinear systems’, Nonlin. Processes Geophys. 19, 383–
399.

290
References
Bocquet, M., Pires, C. & Wu, L. (2010), ‘Beyond Gaussian statistical modeling in
geophysical data assimilaition’, Mon. Wea. Rev. 138, 2997–3022.
Bre´zniak, Z. & Zastawniak, T. (1999), Basic Stochastic Processes, Springer-Verlag,
London.
Br¨ocker, J. (2012), ‘Evaluating raw ensembles with the continuous ranked probability
score’, Q.J.R. Meteorolog. Soc. 138, 1611–1617.
Bungartz, H.-J. & Griebel, M. (2004), ‘Sparse grids’, Acta Numerica 13, 147–269.
Caﬂisch, R. (1998), ‘Monte Carlo and Quasi-Monte Carlo methods’, Acta Numerica
7, 1–49.
Chen, Y. & Oliver, D. (2013), ‘Levenberg–Marquardt forms of the iterative ensemble
smoother for eﬃcient history matching and uncertainty quantiﬁcation’, Computa-
tional Geoscience 17, 689–703.
Cheng, Y. & Reich, S. (2013), ‘A McKean optimal transportation perspective on
Feynman–Kac formulae with application to data assimilation’., arXiv:1311.6300. To
appear in Frontiers in Applied Dynamical Systems, Vol. 1, Springer-Verlag, New
York.
Chorin, A. & Hald, O. (2009), Stochastic Tools in Mathematics and Science, 2nd edn,
Springer-Verlag, Berlin.
Chorin, A., Morzfeld, M. & Tu, X. (2010), ‘Implicit ﬁlters for data assimilation’,
Comm. Appl. Math. Comp. Sc. 5, 221–240.
Coles, S. (2001), An Introduction to Statistical Modeling of Extreme Values, Springer-
Verlag, New York.
Collet, P. & Eckmann, J.-P. (2006), Concepts and Results in Chaotic Dynamics,
Springer-Verlag, Berlin.
Crisan, D. & Xiong, J. (2010), ‘Approximate McKean–Vlasov representation for a class
of SPDEs’, Stochastics 82, 53–68.
Daley, R. (1993), Atmospheric Data Analysis, Cambridge University Press, Cambridge.
Daum, F. & Huang, J. (2011), ‘Particle ﬁlter for nonlinear ﬁlters’. In Acoustics, Speech
and Signal Processing (ICASSP), 2011 IEEE International Conference, IEEE, New
York, 5920–5923.
del Moral, P. (2004), Feynman–Kac Formulae: Genealogical and Interacting Particle
Systems with Applications, Springer-Verlag, New York.
Doucet, A., de Freitas, N. & Gordon, N., editors (2001), Sequential Monte Carlo Meth-
ods in Practice, Springer-Verlag, Berlin.
Emerik, A. & Reynolds, A. (2012), ‘Ensemble smoother with multiple data assimila-
tion’, Computers & Geosciences 55, 3–15.
Engl, H., Hanke, M. & Neubauer, A. (2000), Regularization of Inverse Problems, Kluwer
Academic Publishers, Dordrecht.
Evans, L. (1998), Partial Diﬀerential Equations, American Mathematical Society, Prov-
idence, RI.
Evans, L. (2013), An Introduction to Stochastic Diﬀerential Equations, American Math-
ematical Society, Providence, RI.
Evensen, G. (2006), Data Assimilation. The Ensemble Kalman Filter, Springer-Verlag,
New York.
Frei, M. & K¨unsch, H. (2013), ‘Mixture ensemble Kalman ﬁlters’, Computational Statis-
tics and Data Analysis 58, 127–138.
Gardiner, C. (2004), Handbook of Stochastic Methods, 3rd edn, Springer-Verlag.

References
291
Gneiting, T., Balabdaoui, F. & Raftery, A. (2007), ‘Probabilistic forecasts, calibration
and sharpness’, J. R. Statist. Soc. B 69, 243–268.
Golub, G. & Loan, C.V. (1996), Matrix Computations, 3rd edn, Johns Hopkins Uni-
versity Press, Baltimore, MD.
Gonz´alez-Tokman, C. & Hunt, B. (2013), ‘Ensemble data assimilation for hyperbolic
systems’, Physica D 243, 128–142.
Hand, D. (2008), Statistics: A Very Short Introduction, Oxford University Press, Ox-
ford.
Hastie, T., Tibshirani, R. & Friedman, J. (2009), The Elements of Statistical Learning,
2nd edn, Springer-Verlag, New York.
Higham, D. (2001), ‘An algorithmic introduction to numerical simulation of stochastic
diﬀerential equations’, SIAM Review 43, 525–546.
Hoke, J. & Anthes, R. (1976), ‘The initialization of numerical models by a dynamic
relaxation technique’, Mon. Wea. Rev. 104, 1551–1556.
Holtz, M. (2011), Sparse Grid Quadrature in High Dimensions with Applications in
Finance and Insurance, Springer-Verlag, Berlin.
Hunt, B., Kostelich, E. & Szunyogh, I. (2007), ‘Eﬃcient data assimilation for spatial-
temporal chaos: A local ensemble transform Kalman ﬁlter’, Physica D 230, 112–137.
Janji´c, T., McLaughlin, D., Cohn, S. & Verlaan, M. (2014), ‘Convervation of mass and
preservation of positivity with ensemble-type Kalman ﬁlter algorithms’, Mon. Wea.
Rev. 142, 755–773.
Jazwinski, A. (1970), Stochastic Processes and Filtering Theory, Academic Press, New
York.
Julier, S.J. & Uhlmann, J.K. (1997), ‘A new extension of the Kalman ﬁlter to non-
linear systems’. In Proc. AeroSense: 11th Int. Symp. Aerospace/Defense Sensing,
Simulation and Controls, pp. 182–193.
Kaipio, J. & Somersalo, E. (2005), Statistical and Computational Inverse Problems,
Springer-Verlag, New York.
Kalnay, E. (2002), Atmospheric Modeling, Data Assimilation and Predictability,
Cambridge University Press, Cambridge.
Katok, A. & Hasselblatt, B. (1995), Introduction to the Modern Theory of Dynamical
Systems, Cambridge University Press, Cambridge.
Kitanidis, P. (1995), ‘Quasi-linear geostatistical theory for inverting’, Water Resources
Research 31, 2411–2419.
Kloeden, P. & Platen, E. (1992), Numerical Solution of Stochastic Diﬀerential Equa-
tions, Springer-Verlag, Berlin.
K¨unsch, H. (2005), ‘Recursive Monte Carlo ﬁlter: Algorithms and theoretical analysis’,
Ann. Statist. 33, 1983–2021.
Lasota, A. & Mackey, M. (1994), Chaos, Fractals, and Noise, 2nd edn, Springer-Verlag,
New York.
Law, K., Shukia, A. & Stuart, A. (2014), ‘Analysis of the 3DVAR ﬁlter for the partially
observed Lorenz ’63 model’, Discrete and Continuous Dynamical Systems A 34,
1061–1078.
Lei, J. & Bickel, P. (2011), ‘A moment matching ensemble ﬁlter for nonlinear and
non-Gaussian data assimilation’, Mon. Wea. Rev. 139, 3964–3973.
Lewis, J., Lakshmivarahan, S. & Dhall, S. (2006), Dynamic Data Assimilation: A Least
Squares Approach, Cambridge University Press, Cambridge.

292
References
Liu, J. (2001), Monte Carlo Strategies in Scientiﬁc Computing, Springer-Verlag, New
York.
Livings, D., Dance, S. & Nichols, N. (2008), ‘Unbiased ensemble square root ﬁlters’,
Physica D 237, 1021–1028.
Lorenz, E. (1963), ‘Deterministic non-periodic ﬂows’, J. Atmos. Sci. 20, 130–141.
Majda, A. & Harlim, J. (2012), Filtering Complex Turbulent Systems, Cambridge Uni-
versity Press, Cambridge.
McCann, R. (1995), ‘Existence and uniqueness of monotone measure-preserving maps’,
Duke Math. J. 80, 309–323.
McKean, H. (1966), ‘A class of Markov processes associated with nonlinear parabolic
equations’, Proc. Natl. Acad. Sci. USA 56, 1907–1911.
Meyn, S. & Tweedie, R. (1993), Markov Chains and Stochastic Stability, Springer-
Verlag, London.
Miyoshi, T. (2011), ‘The Gaussian approach to adaptive covariance inﬂation and its
implementation with the local ensemble transform Kalman ﬁlter’, Mon. Wea. Rev.
139, 1519–1535.
Morzfeld, M. & Chorin, A. (2012), ‘Implicit particle ﬁltering for models with partial
noise and an application to geomagnetic data assimilation’, Nonlinear Processes in
Geophysics 19, 365–382.
Morzfeld, M., Tu, X., Atkins, E. & Chorin, A. (2012), ‘A random map implementation
of implicit ﬁlters’, J. Comput. Phys. 231, 2049–2066.
Moselhy, T.E. & Marzouk, Y. (2012), ‘Bayesian inference with optimal maps’, J. Com-
put. Phys. 231, 7815–7850.
Moser, J. (1965), ‘On the volume elements on a manifold’, Trans. Amer. Math. Soc.
120, 286–294.
Neal, R. (1996), Bayesian Learning for Neural Networks, Springer-Verlag, New York.
Nerger, L., Pfander, T.J., Schr¨oter, J. & Hiller, W. (2012), ‘A regulated localization
scheme for ensemble-based Kalman ﬁlters’, Q.J.R. Meteorolog. Soc. 138, 802–812.
Nocedal, J. & Wright, S. (2006), Numerical Optimization, 2nd edn, Springer-Verlag,
New York.
Øksendal, B. (2000), Stochastic Diﬀerential Equations, 5th edn, Springer-Verlag, Berlin.
Oliver, D. (1996), ‘On conditional simulation to inaccurate data’, Math. Geology
28, 811–817.
Oliver, D., He, N. & Reynolds, A. (1996), ‘Conditioning permeability ﬁelds on pressure
data. Technical Report: presented at the 5th European Conference on the Mathe-
matics of Oil Recovery, Leoben, Austria.
Olkin, I. & Pukelsheim, F. (1982), ‘The distance between two random vectors with
given dispersion matrices’, Lin. Alg. and its Applns. 48, 257–263.
Ott, E., Hunt, B., Szunyogh, I., Zimin, A., Kostelich, E., Corazza, M., Kalnay, E.,
Patil, D. & Yorke, J.A. (2004), ‘A local ensemble Kalman ﬁlter for atmospheric data
assimilation’, Tellus A 56, 415–428.
Otto, F. (2001), ‘The geometry of dissipative evolution equations: the porous medium
equation’, Comm. Part. Diﬀ. Eqs. 26, 101–174.
Pavliotis, G. (2014), Stochastic Processes and Applications, Springer-Verlag, New York.
Pele, O. & Werman, M. (2009), ‘Fast and robust earth mover’s distances’. In 12th IEEE
International Conference on Computer Vision, IEEE New York, pp. 460–467.

References
293
Raftery, A. (1995), ‘Bayesian model selection in social research’, Sociological Method-
ology 25, 111–163.
Rebeschini, P. & van Handel, R. (2013), ‘Can local particle ﬁlters beat the curse of
dimensionality?’, arXiv:1301.6585.
Reich, S. (2011), ‘A dynamical systems framework for intermittent data assimilation’,
BIT Numer Math 51, 235–249.
Reich, S. (2012), ‘A Gaussian mixture ensemble transform ﬁlter’, Q.J.R. Meteorolog.
Soc. 138, 222–233.
Reich, S. (2013a), ‘A guided sequential Monte Carlo method for the assimilation of
data into stochastic dynamical systems’. In Recent Trends in Dynamical Systems,
Proceedings in Mathematics and Statistics, 35, Springer-Verlag, Basel, pp. 205–220.
Reich, S. (2013b), ‘A nonparametric ensemble transform method for Bayesian inference’,
SIAM J. Sci. Comput. 35, A2013–A2024.
Reich, S. & Cotter, C. (2013), ‘Ensemble ﬁlter techniques for intermittent data assim-
ilation’. In Large Scale Inverse Problems. Computational Methods and Applications
in the Earth Sciences, M. Cullen, M.A. Freitag, S. Kindermann & R. Scheichl, eds,
Radon Ser. Comput. Appl. Math., 13, de Gruyter, Berlin, pp. 91–134.
Robert, C. (2001), The Bayesian Choice: From Decision-Theoretic Motivations to Com-
putational Implementations, 2nd edn, Springer-Verlag, New York.
Robert, C. & Casella, G. (2004), Monte Carlo Statistical Methods, 2nd edn, Springer-
Verlag, New York.
Robinson, J. (2001), Inﬁnite-Dimensional Dynamical Systems, Cambridge University
Press, Cambridge.
Sakov, P., Oliver, D. & Bertino, L. (2012), ‘An iterative EnKF for strongly nonlinear
systems’, Mon. Wea. Rev. 140, 1988–2004.
S¨arkk¨a, S. (2013), Bayesian Filtering and Smoothing, Cambridge University Press,
Cambridge.
Simon, D. (2006), Optimal State Estimation, Wiley, New York.
Smith, K. (2007a), ‘Cluster ensemble Kalman ﬁlter’, Tellus 59A, 749–757.
Smith, L. (2007b), Chaos: A Very Short Introduction, Oxford University Press, Oxford.
Smith, R. (2014), Uncertainty Quantiﬁcation, SIAM, Philadelphia, PA.
Stordal, A., Karlsen, H., Nævdal, G., Skaug, H. & Vall´es, B. (2011), ‘Bridging the
ensemble Kalman ﬁlter and particle ﬁlters: the adaptive Gaussian mixture ﬁlter’,
Comput. Geosci. 15, 293–305.
Strang, G. (1986), Introduction to Applied Mathematics, 2nd edn, Wellesley-Cambridge
Press, Wellesley, MA.
Stuart, A. (2010), ‘Inverse problems: a Bayesian perspective’, Acta Numerica 17, 451–
559.
S¨uli, E. & Mayers, D. (2006), An Introduction to Numerical Analysis, Cambridge Uni-
versity Press, Cambridge.
Takens, F. (1981), ‘Detecting strange attractors in turbulence’. In Dynamical Sys-
tems and Turbulence. Lecture Notes in Mathematics, 898, Springer-Verlag, Berlin,
pp. 366–381.
Tarantola, A. (2005), Inverse Problem Theory and Methods for Model Parameter Esti-
mation, SIAM, Philadelphia, PA.
Tijms, H. (2012), Understanding Probability, 3rd edn, Cambridge University Press,
Cambridge.

294
References
Tippett, M., Anderson, J., Bishop, G., Hamill, T. & Whitaker, J. (2003), ‘Ensemble
square root ﬁlters’, Mon. Wea. Rev. 131, 1485–1490.
van Leeuwen, P. (2010), ‘Nonlinear data assimilation in the geosciences: an extremely
eﬃcient particle ﬁlter’, Q.J.R. Meteorolog. Soc. 136, 1991–1996.
van Leeuwen, P. & Ades, M. (2013), ‘Eﬃcient fully nonlinear data assimilation for
geophysical ﬂuid dynamics’, Computers & Geosciences 55, 16–27.
Verhulst, F. (2000), Nonlinear Diﬀerential Equations and Dynamical Systems, 2nd edn,
Springer-Verlag, Berlin.
Villani, C. (2003), Topics in Optimal Transportation, American Mathematical Society,
Providence, RI.
Villani, C. (2009), Optimal Transportation: Old and New, Springer-Verlag, Berlin.
Wang, X., Bishop, C. & Julier, S. (2004), ‘Which is better, an ensemble of positive-
negative pairs or a centered spherical simplex ensemble?’, Mon. Wea. Rev. 132, 1590–
1505.
Yang, T., Mehta, P. & Meyn, S. (2013), ‘Feedback particle ﬁlter’, IEEE Trans. Auto-
matic Control 58, 2465–2480.

Index
analysis of variance (ANOVA), 71
assignment problem, 53
autocorrelation function, 43
Bayes’ theorem, 136
continuous embedding, 280
Bayesian estimate
loss function, 138
maximum a posteriori (MAP), 138, 196
posterior mean, 138
posterior median, 138
Bayesian inference
Bayes’ formula, 136
estimate, 138, 173
evidence, 136, 260
importance sampling, 148
likelihood, 136
linear programming, 151
Monte Carlo, 142
posterior, 136
prior, 136
Radon–Nykodym derivative, 141
transform method, 151, 155
Bayesian information criterion (BIC), 265
Bayesian model comparison, 265
best approximation, 63
Box–Muller algorithm, 82
Brownian dynamics, 142
asymptotic behaviour, 147
canonical distribution, 142
discrete Markov chain approximation, 166
geometric structure, 162
Brownian motion, 112
central limit theorem, 77
Chapman–Kolmogorov equation, 107, 113,
115, 171
Chebychev’s inequality, 78
conditional distribution, 106
conditional expectation, 62
continuous ranked probability score, 124
cumulative probability distribution function,
36
curse of dimensionality, 71, 195, 229
cyclical monotonicity, 56, 154
data assimilation, 18
hyperbolic dynamical systems, 283
sequential, 174
variational, 179
diﬀusion equation, 114
discretisation errors, 16
dynamical system, 96
attractor, 98
autonomous, 96
autoregression model, 12
initial condition, 96
Lorenz-63 model, 3
method of least squares, 102
non-autonomous, 96
phase space, 96
probabilistic interpretation, 101
tent map, 3, 28
empirical measure, 69
ensemble inﬂation, 229, 242
additive, 243
multiplicative, 243
ensemble Kalman ﬁlter (EnKF), 206
ensemble square root ﬁlter (ESRF), 211,
212
local ensemble transform Kalman ﬁlter
(LETKF), 252
perturbed observations, 207, 209
ensemble Kalman–Bucy ﬁlter, 275
gradient ﬂow structure, 277
nonlinear forward operator, 277, 278
with perturbed observations, 277
ensemble prediction, 117
calibration, 122
forecast scores, 123
rank histogram, 123
ensemble transform particle ﬁlter (ETPF),
214
estimate
Bayesian, 138
estimator
BLUE, 159
extrapolation, 7
higher-order, 8

296
Index
linear, 7
extreme value theory (EVT)
rare events, 119
ﬁlter divergence, 231
ﬁltering, 18, 173
continuous time, 283
Fokker–Planck equation, 113
forecasting, 1
forward Euler scheme, 2
forward map, 4, 132
Gaussian mixture transform ﬁlter, 228
geometric ergodicity, 129
i.i.d., 42
identical twin experiment, 241, 259
independent, identically distributed, 42
inference model, 132
forward map, 132
forward problem, 133
inverse problem, 136
interacting particle systems, 272
interpolation
linear, 2
joint probability distribution, 106
Kalman ﬁlter, 171
linear systems, 177
update formula, 140
Kalman–Bucy equations, 274
ensemble transform, 275
Knothe–Rosenblatt rearrangement, 50
Kullback–Leibler divergence, 125, 163
Laplace’s demon, vii, 242, 259
Laplace’s method, 73, 265
linear ensemble transform ﬁlter (LETF), 205
EnKF with perturbed observations, 208
ESRF, 211
ETPF, 214
linear programming
algorithm, 168
linear transport, 52
algorithm, 168, 225
dual formulation, 225
localisation, 229, 248
B-localisation, 252
ﬁlter function, 250
localisation radius, 250
R-localisation, 252
R-localisation for ETPF, 255
logarithmic scoring rule, 125
Lorenz-63 model, 16
Lorenz attractor, 16
non-autonomous, 3
stochastically perturbed, 108
Lorenz-96 model, 239
marginal distribution, 106
Markov chain Monte Carlo (MCMC), 148
detailed balance, 148
Metropolis criterion, 148
Markov process, 107
Chapman–Kolmogorov equation, 107
discrete-time, 107
transition operator, 110
matrix square root, 50
maximum likelihood estimation (MLE), 26,
138, 196
McKean approach, 174, 202
mean squared error (MSE), 75
bias-variance decomposition, 76
measurement
forward map, 4, 132
measurement error, 5
method of least squares, 12
linear, 12
nonlinear, 18
steepest decent, 20
model comparison, 260
evidence, 261
likelihood, 261
posterior odds, 265
model setting
imperfect, ix, 177, 192
perfect, ix, 192, 241, 259
molliﬁcation, 272
molliﬁed delta function, 274
Monge–Kantorovitch problem, 51
linear transport, 51
Monte Carlo method, 74, 79
Brownian dynamics, 142
conﬁdence interval, 77
empirical covariance matrix, 230
empirical mean, 75
ensemble prediction, 117
grouped independence
Metropolis–Hastings, 269
importance sampling, 83
independent resampling with replacement,
89
MCMC, 148
parameter estimation, 268
rejection sampling, 85
residual resampling, 90
normal distribution, 38
nudging, 272
molliﬁed, 274
numerical quadrature rule, 66
Gauss–Hermite, 67
Gauss–Legendre, 66
order reduction, 68
sparse grid, 72
ordinary diﬀerential equation, 2
parameter estimation, 260
partial diﬀerential equation (PDE), 229

Index
297
Burgers’ equation, 236
ﬁnite diﬀerences, 235
Fokker–Planck equation, 112, 161
gradient ﬂow, 162
Kushner–Stratonovitch equation, 286
linear advection equation, 232
Liouville equation, 113
method of characteristics, 234
nonlinear advection equations, 236
upwind method, 236
particle ﬁlter, 171, 188
eﬀective sample size, 189
sequential importance resampling (SIR),
191
sequential importance sampling (SIS), 189
particle rejuvenation, 194
polynomial chaos expansion, 95
polynomial interpolation, 7
Lagrange polynomial, 8
linear, 7
posterior consistency, 196
prediction, 173
three ingredients of, 1
probability density function (PDF), 37
conditional probability, 40
disintegration, 41
independence, 40
marginal, 40
probability integral transform, 122
probability measure, 34, 36
coupling, 46
Dirac delta, 39
manifold structure, 160
point measure, 39
probability space, 35
Radon–Nykodym derivative, 141
random variable, 24, 36
as quantiﬁcation of uncertainty in
prediction, 65
expectation value, 37
Gaussian, 38
Gaussian mixture, 39
Laplace distribution, 38
multinomial distribution, 90
transformation of, 39
rank histogram ﬁlter, 221
resampling, 89
Rockafellar’s theorem, 58
root mean square error (RMSE), 7, 125
Schur product, 250
scoring rule
divergence, 124
strictly proper, 124
sequences of random variables
convergence in probability, 76
convergence with probability one, 76
weak convergence, 76
Sherman–Morrison–Woodbury matrix
inversion formula, 176
smoothing, 18, 173
spatial correlation, 248
stochastic diﬀerence equation, 111
stochastic diﬀerential equation (SDE), 111
Euler–Maruyama method, 113
Fokker–Planck equation, 112, 161
stochastic matrix, 110
stochastic process, 106
continuous time, 107
discrete-time, 107
Fokker–Planck equation, 112
strong law of large numbers, 78
subdiﬀerential, 58
surrogate physical process, 2
Tikhonov regularisation, 140
time-stepping method
Euler–Maruyama method, 113
explicit Euler method, 127
implicit Euler method, 130
implicit midpoint method, 128
transference plan, 46
optimal, 53
transform method, 81
linear programming, 151
transition matrix, 110
transition operator, 107, 166
transition probability density, 106
transport map, 49
variational data assimilation, 20, 26, 179
3DVar, 273
4DVar, 179, 184
adjoint method, 186
MAP estimator, 184
maximum likelihood, 26, 185
variational derivative, 54, 161
Wasserstein distance, 51
weak law of large numbers, 78

