Biomolecular 
Simulations
Massimiliano Bonomi 
Carlo Camilloni Editors
Methods and Protocols
Methods in 
Molecular Biology   2022

M E T H O D S I N M O L E C U L A R B I O L O G Y
Series Editor
John M. Walker
School of Life and Medical Sciences
University of Hertfordshire
Hatfield, Hertfordshire, UK
For further volumes:
http://www.springer.com/series/7651

For over 35 years, biological scientists have come to rely on the research protocols and
methodologies in the critically acclaimed Methods in Molecular Biology series. The series was
the ﬁrst to introduce the step-by-step protocols approach that has become the standard in all
biomedical protocol publishing. Each protocol is provided in readily-reproducible step-by-
step fashion, opening with an introductory overview, a list of the materials and reagents
needed to complete the experiment, and followed by a detailed procedure that is supported
with a helpful notes section offering tips and tricks of the trade as well as troubleshooting
advice. These hallmark features were introduced by series editor Dr. John Walker and
constitute the key ingredient in each and every volume of the Methods in Molecular Biology
series. Tested and trusted, comprehensive and reliable, all protocols from the series are
indexed in PubMed.

Biomolecular Simulations
Methods and Protocols
Edited by
Massimiliano Bonomi
Structural Bioinformatics Unit, Institut Pasteur, CNRS UMR 3528, Paris, France
Carlo Camilloni
Dipartimento di Bioscienze, Università degli Studi di Milano, Milano, Italy

Editors
Massimiliano Bonomi
Structural Bioinformatics Unit
Institut Pasteur, CNRS UMR 3528
Paris, France
Carlo Camilloni
Dipartimento di Bioscienze
Universita` degli Studi di Milano
Milano, Italy
ISSN 1064-3745
ISSN 1940-6029
(electronic)
Methods in Molecular Biology
ISBN 978-1-4939-9607-0
ISBN 978-1-4939-9608-7
(eBook)
https://doi.org/10.1007/978-1-4939-9608-7
© Springer Science+Business Media, LLC, part of Springer Nature 2019
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction
on microﬁlms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation,
computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations
and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to
be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty,
express or implied, with respect to the material contained herein or for any errors or omissions that may have been made.
The publisher remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations.
This Humana imprint is published by the registered company Springer Science+Business Media, LLC, part of Springer
Nature.
The registered company address is: 233 Spring Street, New York, NY 10013, U.S.A.

Foreword
Stating that the future of biomolecular simulations is not what it used to be is an almost trite
observation. But this is exactly what this wonderful book illustrates: the future of biomolec-
ular simulations is more exciting and more goal oriented than had seemed possible in the
early 1970s when biomolecular simulations were pioneered. And, importantly, much of the
current progress is not primarily due to increased (and still increasing) computing power—
although Moore’s law has certainly played an important role.
It is probably useful if I state what I view as the long-term aim of biomolecular
simulations: it is to develop a set of computational tools that enable us to model a living
organism from its constituent molecules upward, and that enable us predict how this
organism will respond to “interventions”—be they pathogenic, remedial, or related to the
age or environment of the organism.
That is a tall order and we are not nearly there. To sketch the magnitude of the problem,
let us express computing power in a strange unit: atom-second/day (ASD). One ASD would
correspond to performing a simulation of 100,000 atoms over 10 μs in 1 day of real time
(this unit only makes sense if we assume that the time of a simulation scales approximately
linearly with the system size—an optimistic, but not unreasonable assumption). The fastest
computers for classical biomolecular simulations now run at around 10 ASD. To simulate
the life cycle of a simple bacterium in 1 day, we would require about a trillion ASD. And that
is assuming that we can limit ourselves to classical simulations, which we cannot. Yet,
treating a whole organism quantum mechanically is so far beyond anything that we can
hope to achieve that I will not even try to express it in ASDs—the more so, as for quantum-
chemistry-style ab initio methods, linear scaling is deﬁnitely not justiﬁed.
But even if we limit ourselves to classical simulations the challenge is huge: if we were to
rely on Moore’s law arrive at whole-organism simulations (and relying on Moore’s law may
be a dangerous bet), we would have to wait more than a typical scientiﬁc lifetime to get
anywhere near. Not surprisingly, most scientists are not that patient. This book, by Bonomi
and Camilloni, reﬂects that impatience. Note, however, that the book has no chapter on
quantum computing. The immediate reason is simple: even if we would have robust
quantum computers, we do not seem to have suitable quantum algorithms for problems
of this type. It is not even obvious that quantum computing would be particularly suited to
address this class of problems, but obviously I would love to be proven wrong.
So what has to be done? First of all, we must construct the classical models (force ﬁelds)
that are as faithful as possible to the underlying quantum reality, without becoming prohi-
bitively expensive—in some cases, these models must even contain quantum parts. For
instance, chemical reactions where electrons are transferred or bonds are made or broken
are intrinsically quantum mechanical. This book contains a number of key contributions that
describe the state of the art in constructing classical force-ﬁelds, or integrating quantum bits
into classical simulations. But there are other ways in which biomolecular simulations can be
made faster. Many of these simulation techniques address the problem that many biomolec-
ular rate processes contain one or more steps that are infrequent, but fast. Efﬁcient sampling
of such rare events and exploration of the pathways that biomolecular systems follow during
reactions or conformational changes are therefore a crucial ingredient of modern biomolec-
ular simulations.
v

Another key development is that, increasingly, modeling is closely integrated with, or
more precisely “driven by,” experimental data. Modern experiments yield a wealth of data
and it is important to ensure that our necessarily approximate simulations account for these
data, which are typically heterogeneous, i.e. from different types of experiments. The
question that we are implicitly asking in this context is the old Bayesian question: “what
model is best compatible with the available (experimental) evidence?” It should be stressed
that coarse-grained models are not necessarily derived from more ﬁne-grained models. It is
perfectly legitimate to start at a particular level of coarse graining and then select the model
parameters that account best for the available data. Again, this philosophy is well represented
in the book.
Finally, we are still confronted with one other problem: suppose that we have a “perfect”
(or, more likely, “good enough”) simulation; what do the resulting data tell us? Clearly, the
trajectory of a system in the high-dimensional conﬁguration space that the simulations
explore contains all the information that we could extract. However, we are unable to
visualize or comprehend information in this form. Rather, we need tools that allow us to
construct a cartoon of what is happening: what are the characteristic molecular conforma-
tions that a biomolecule visits while carrying out its function? What are the key structural
features of a transition state during a biomolecular transformation? Sometimes we have an
idea what questions to ask, but often not even that: e.g. the correct reaction for an allosteric
transition coordinate may be very different from what we would have thought. Hence, we
need unbiased tools that reveal the patterns that help us form a hypothesis about the way in
which biomolecules do or don’t do (in the case of disease) what they are supposed to do.
Of course, simulations are used to model and predict the properties of many other,
nonbiological systems. In particular, there is an explosive growth in the ﬁeld of computa-
tional materials science, where high-throughput computational screening has become an
essential tool in materials discovery. It should be stressed that many of the tools and
techniques described in this book carry over to other ﬁelds of simulations—and practitioners
of such simulations will ﬁnd much of interest in this book.
Brieﬂy, (bio)molecular simulations have moved far beyond the simple F ¼ ma of
standard molecular dynamics. Using a broad array of tools, many of which were not even
imagined when the ﬁrst protein simulations were carried out, we are increasingly able to
model life processes that do not just involve one or two biomolecules but hundreds or
thousands. This is not a question of establishing records: the point is that systems with many
agents (biomolecules) show emergent behavior that will not be observed in a system with
only a few such molecules. Life is the ultimate emergent phenomenon (I show my bias here
and hopefully demonstrate that I am not a “bot”). To understand life, we need to be able to
model cooperative nonequilibrium effects involving a large number of distinct biomole-
cules. It will be very difﬁcult and we have a long way to go, but it is a wonderful objective—
and this book points the way.
Department of Chemistry
University of Cambridge
Cambridge, UK
Daan Frenkel
vi
Foreword

Preface
The aim of Biomolecular Simulations: Methods and Protocols is to provide a comprehensive
overview of recent advances in biomolecular simulations of proteins, small molecules, and
nucleic acids. The main focus is on classical molecular dynamics (MD) simulations at
atomistic and coarse-grained levels, with a few excursions at the quantum/ab initio level.
The book is organized into four parts, each one covering the latest developments in a
speciﬁc area.
The ﬁrst part of the book introduces the readers to the recent progresses in the
development of accurate physico-chemical models of proteins, small molecules, nucleic
acids, and lipids: the so-called force ﬁelds. This is a central topic in MD simulations, as
their reliability strongly depends on the accuracy of the underlying force ﬁeld. Thankfully,
force ﬁelds have shown signiﬁcant improvement over the past few years, especially in the case
of disordered systems and nucleic acids.
The second part of the book is meant to give an overview of some of the most popular
methods to accelerate MD and access time scales that would be prohibitive in conventional
simulations. These methods are often referred to as enhanced sampling techniques. Special
attention has been reserved to free-energy calculations and to the study of the interactions
between small molecules and proteins, which are topics of extreme relevance in both
academia and industry.
The third part of the book is focused on an area of research that has literally ﬂourished in
the last decade, that of integrative or hybrid methods. Methods belonging to this class aim at
improving the description of a system provided by the force ﬁeld by introducing additional
sources of information, such as experimental, statistical, and bioinformatics data. Different
approaches to determine more accurate structural models and conformational ensembles by
integrating multiple sources of information into biomolecular simulations will be presented,
including methods based on the maximum entropy principle and on Bayesian inference.
The fourth part of the book is dedicated to the analysis of the outcome of biomolecular
simulations. This is a fervent area of research, since simulations typically produce an
immense amount of data and extracting the most useful information from them is not
always straightforward. These methods not only try to make sense of the large volume of
data generated by MD, but they also enable effective comparisons between the outcomes of
different simulations, thus facilitating reproducibility.
All the recent advances in the ﬁeld of biomolecular simulations presented in this book
would be of limited use if researches could not readily access to the pieces of software that
implement these methods. While this book does not extensively focus on this area (with a
few exceptions), we strongly believe that the development and dissemination of (open
source) software should be a fundamental part in the life of every computational researcher,
and yet this effort is too often underappreciated.
Biomolecular Simulations: Methods and Protocols is intended as a practical guide for
researchers in both academia and industry, ranging from novice to expert level. In the
tradition of the Springer series Methods in Molecular Biology, each chapter ends with a
“Notes” section. This part contains all those details, tips, and tricks of the trade as well as
troubleshooting advice that usually do not ﬁnd place in standard research articles. We believe
vii

that readers that are unfamiliar with biomolecular simulations will ﬁnd this section particu-
larly useful to avoid those mistakes that are inevitably made when approaching a new ﬁeld of
research. We also hope that more advanced users will enjoy the overview of the recent
progresses in different areas of biomolecular simulations and possibly discover new tools that
will prove useful for their current and future research projects.
We would like to conclude this Preface by thanking all the authors who devoted part of
their time to contributing a chapter to the book and John Walker, Series Editor of Methods
in Molecular Biology, who assisted us in reviewing chapters and assembling the book. Finally,
a special thank goes to Daan Frankel, who honored us with a Foreword to this book and
whose “Understanding Molecular Simulations” has been a precious guide for many of us
who decided to adventure into the ﬁeld of biomolecular simulations.
Paris, France
Massimiliano Bonomi
Milano, Italy
Carlo Camilloni
viii
Preface

Contents
Foreword. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
v
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
vii
Contributors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
xi
PART I
ATOMISTIC AND COARSE-GRAINED FORCE FIELDS
FOR PROTEINS, SMALL MOLECULES, AND NUCLEIC ACIDS
1
Atomistic Force Fields for Proteins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Robert B. Best
2
Force Fields for Small Molecules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
Fang-Yu Lin and Alexander D. MacKerell Jr
3
Improvement of RNA Simulations with Torsional Revisions
of the AMBER Force Field. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
Ilyas Yildirim
4
Quantum Chemical and QM/MM Models in Biochemistry. . . . . . . . . . . . . . . . . .
75
Patricia Saura, Michael Ro¨pke, Ana P. Gamiz-Hernandez,
and Ville R. I. Kaila
5
A Practical View of the Martini Force Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
Bart M. H. Bruininks, Paulo C. T. Souza, and Siewert J. Marrink
6
Using SMOG 2 to Simulate Complex Biomolecular Assemblies . . . . . . . . . . . . . .
129
Mariana Levi, Prasad Bandarkar, Huan Yang, Ailun Wang,
Udayan Mohanty, Jeffrey K. Noel, and Paul C. Whitford
PART II
ENHANCED SAMPLING AND FREE-ENERGY CALCULATIONS
7
Replica-Exchange Methods for Biomolecular Simulations. . . . . . . . . . . . . . . . . . . .
155
Yuji Sugita, Motoshi Kamiya, Hiraku Oshima, and Suyong Re
8
Metadynamics to Enhance Sampling in Biomolecular Simulations. . . . . . . . . . . . .
179
Jim Pfaendtner
9
Protein–Ligand Binding Free Energy Calculations with FEP+ . . . . . . . . . . . . . . . .
201
Lingle Wang, Jennifer Chambers, and Robert Abel
10
Ligand-Binding Calculations with Metadynamics . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
Davide Provasi
11
The Adaptive Path Collective Variable: A Versatile Biasing Approach
to Compute the Average Transition Path and Free Energy
of Molecular Transitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
255
Alberto Pe´rez de Alba Ortı´z, Jocelyne Vreede, and Bernd Ensing
12
Google-Accelerated Biomolecular Simulations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
291
Kai J. Kohlhoff
ix

PART III
INTEGRATIVE APPROACHES FOR BIOMOLECULAR SIMULATIONS
13
A Practical Guide to the Simultaneous Determination of Protein
Structure and Dynamics Using Metainference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
313
Thomas Lo¨hr, Carlo Camilloni, Massimiliano Bonomi,
and Michele Vendruscolo
14
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
Using Bayesian, Maximum Entropy, and Minimal-Ensemble
Reﬁnement Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
341
Ju¨rgen Ko¨ﬁnger, Bartosz Roz˙ycki, and Gerhard Hummer
15
Modeling Biological Complexes Using Integrative Modeling Platform . . . . . . . .
353
Daniel Saltzberg, Charles H. Greenberg, Shruthi Viswanath,
Ilan Chemmama, Ben Webb, Riccardo Pellarin, Ignacia Echeverria,
and Andrej Sali
16
Coevolutionary Analysis of Protein Sequences for Molecular Modeling. . . . . . . .
379
Duccio Malinverni and Alessandro Barducci
17
Coarse Graining of a Giant Molecular System: The Chromatin Fiber. . . . . . . . . .
399
Guido Tiana and Luca Giorgetti
PART IV
ANALYZING, VISUALIZING, AND COMPARING BIOMOLECULAR
SIMULATIONS
18
Analyzing Biomolecular Ensembles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
415
Matteo Lambrughi, Matteo Tiberti, Maria Francesca Allega,
Valentina Sora, Mads Nygaard, Agota Toth, Juan Salamanca Viloria,
Emmanuelle Bignon, and Elena Papaleo
19
Using Data-Reduction Techniques to Analyze Biomolecular Trajectories . . . . . .
453
Gareth A. Tribello and Piero Gasparotto
20
Analysis Libraries for Molecular Trajectories: A Cross-Language Synopsis. . . . . .
503
Toni Giorgino
21
Analyzing and Biasing Simulations with PLUMED . . . . . . . . . . . . . . . . . . . . . . . . .
529
Giovanni Bussi and Gareth A. Tribello
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
579
x
Contents

Contributors
ROBERT ABEL
 Schro¨dinger, Inc., New York, NY, USA
MARIA FRANCESCA ALLEGA
 Computational Biology Laboratory, Danish Cancer Society
Research Center, Copenhagen, Denmark
PRASAD BANDARKAR
 Department of Physics, Northeastern University, Boston, MA, USA
ALESSANDRO BARDUCCI
 Centre de Biochimie Structurale (CBS), INSERM, CNRS,
Universite´ de Montpellier, Montpellier, France
ROBERT B. BEST
 Laboratory of Chemical Physics, National Institute of Diabetes and
Digestive and Kidney Diseases, National Institutes of Health, Bethesda, MD, USA
EMMANUELLE BIGNON
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
MASSIMILIANO BONOMI
 Structural Bioinformatics Unit, Institut Pasteur, CNRS UMR
3528, Paris, France
BART M. H. BRUININKS
 Groningen Biomolecular Sciences and Biotechnology Institute &
Zernike Institute for Advanced Materials, University of Groningen, Groningen, The
Netherlands
GIOVANNI BUSSI
 Scuola Internazionale Superiore di Studi Avanzati, Trieste, Italy
CARLO CAMILLONI
 Dipartimento di Bioscienze, Universita` degli Studi di Milano, Milano,
Italy
JENNIFER CHAMBERS
 Schro¨dinger, Inc., New York, NY, USA
ILAN CHEMMAMA
 California Institute for Quantitative Biosciences, University of
California, San Francisco, CA, USA
IGNACIA ECHEVERRIA
 California Institute for Quantitative Biosciences, University of
California, San Francisco, CA, USA
BERND ENSING
 Amsterdam Center for Multiscale Modeling and Van ’t Hoff Institute for
Molecular Sciences, Universiteit van Amsterdam, Amsterdam, The Netherlands
ANA P. GAMIZ-HERNANDEZ
 Department Chemie, Technische Universit€at Mu¨nchen,
Garching, Germany
PIERO GASPAROTTO
 Laboratory of Computational Science and Modelling and National
Centre for Computational Design and Discovery of Novel Materials MARVEL, IMX, E´ cole
Polytechnique Fe´de´rale de Lausanne, Lausanne, Switzerland
LUCA GIORGETTI
 Friedrich Miescher Institute for Biomedical Research, Basel, Switzerland
TONI GIORGINO
 Biophysics Institute (IBF-CNR), National Research Council of Italy, c/o
Department of Biosciences, University of Milan, Milan, Italy
CHARLES H. GREENBERG
 California Institute for Quantitative Biosciences, University of
California, San Francisco, CA, USA
GERHARD HUMMER
 Max Planck Institute of Biophysics, Frankfurt am Main, Germany;
Department of Physics, Goethe University Frankfurt, Frankfurt am Main, Germany
VILLE R. I. KAILA
 Department Chemie, Technische Universit€at Mu¨nchen, Garching,
Germany
MOTOSHI KAMIYA
 Computational Biophysics Research Team, RIKEN Center for
Computational Science, Kobe, Japan
JU¨ RGEN KO¨ FINGER
 Max Planck Institute of Biophysics, Frankfurt am Main, Germany
KAI J. KOHLHOFF
 Research, Google, Mountain View, CA, USA
xi

MATTEO LAMBRUGHI
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
MARIANA LEVI
 Department of Physics, Northeastern University, Boston, MA, USA
FANG-YU LIN
 Department of Pharmaceutical Sciences, Computer-Aided Drug Design
Center, School of Pharmacy, University of Maryland, Baltimore, MD, USA
THOMAS LO¨ HR
 Department of Chemistry, University of Cambridge, Cambridge, UK
ALEXANDER D. MACKERELL JR
 Department of Pharmaceutical Sciences, Computer-Aided
Drug Design Center, School of Pharmacy, University of Maryland, Baltimore, MD, USA
DUCCIO MALINVERNI
 Laboratory of Statistical Biophysics, Institute of Physics, E´ cole
Polytechnique Fe´de´rale de Lausanne, Lausanne, Switzerland
SIEWERT J. MARRINK
 Groningen Biomolecular Sciences and Biotechnology Institute &
Zernike Institute for Advanced Materials, University of Groningen, Groningen, The
Netherlands
UDAYAN MOHANTY
 Department of Chemistry, Boston College, Chestnut Hill, MA, USA
JEFFREY K. NOEL
 Max Delbrueck Center for Molecular Medicine, Kristallographie, Berlin,
Germany
MADS NYGAARD
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
HIRAKU OSHIMA
 Laboratory for Biomolecular Function Simulation, RIKEN Center for
Biosystems Dynamics Research, Kobe, Japan
ELENA PAPALEO
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
RICCARDO PELLARIN
 Structural Bioinformatics Unit, Institut Pasteur, CNRS UMR 3528,
Paris, France
ALBERTO PE´ REZ DE ALBA ORTI´Z
 Amsterdam Center for Multiscale Modeling and Van ’t
Hoff Institute for Molecular Sciences, Universiteit van Amsterdam, Amsterdam, The
Netherlands
JIM PFAENDTNER
 Department of Chemical Engineering, University of Washington, Seattle,
WA, USA; Paciﬁc Northwest National Laboratory, Richland, WA, USA
DAVIDE PROVASI
 Department of Pharmacological Sciences, Icahn School of Medicine at
Mount Sinai, New York, NY, USA
SUYONG RE
 Laboratory for Biomolecular Function Simulation, RIKEN Center for
Biosystems Dynamics Research, Kobe, Japan
MICHAEL RO¨ PKE
 Department Chemie, Technische Universit€at Mu¨nchen, Garching,
Germany
BARTOSZ RO´ Z˙ YCKI
 Institute of Physics, Polish Academy of Sciences, Warsaw, Poland
JUAN SALAMANCA VILORIA
 Computational Biology Laboratory, Danish Cancer Society
Research Center, Copenhagen, Denmark
ANDREJ SALI
 California Institute for Quantitative Biosciences, University of California,
San Francisco, CA, USA
DANIEL SALTZBERG
 California Institute for Quantitative Biosciences, University of
California, San Francisco, CA, USA
PATRICIA SAURA
 Department Chemie, Technische Universit€at Mu¨nchen, Garching,
Germany
VALENTINA SORA
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
xii
Contributors

PAULO C. T. SOUZA
 Groningen Biomolecular Sciences and Biotechnology Institute &
Zernike Institute for Advanced Materials, University of Groningen, Groningen, The
Netherlands
YUJI SUGITA
 Theoretical Molecular Science Laboratory, RIKEN Cluster for Pioneering
Research, Saitama, Japan; Computational Biophysics Research Team, RIKEN Center for
Computational Science, Kobe, Japan; Laboratory for Biomolecular Function Simulation,
RIKEN Center for Biosystems Dynamics Research, Kobe, Japan
GUIDO TIANA
 Department of Physics and Center for Complexity and Biosystems, Universita`
Degli Studi di Milano and INFN, Milan, Italy
MATTEO TIBERTI
 Computational Biology Laboratory, Danish Cancer Society Research
Center, Copenhagen, Denmark
AGOTA TOTH
 Computational Biology Laboratory, Danish Cancer Society Research Center,
Copenhagen, Denmark
GARETH A. TRIBELLO
 Atomistic Simulation Centre, School of Mathematics and Physics,
Queen’s University Belfast, Belfast, UK
MICHELE VENDRUSCOLO
 Department of Chemistry, University of Cambridge, Cambridge,
UK
SHRUTHI VISWANATH
 California Institute for Quantitative Biosciences, University of
California, San Francisco, CA, USA
JOCELYNE VREEDE
 Amsterdam Center for Multiscale Modeling and Van ’t Hoff Institute for
Molecular Sciences, Universiteit van Amsterdam, Amsterdam, The Netherlands
AILUN WANG
 Department of Chemistry, Boston College, Chestnut Hill, MA, USA
LINGLE WANG
 Schro¨dinger, Inc., New York, NY, USA
BEN WEBB
 California Institute for Quantitative Biosciences, University of California, San
Francisco, CA, USA
PAUL C. WHITFORD
 Department of Physics, Northeastern University, Boston, MA, USA
HUAN YANG
 Department of Physics, Northeastern University, Boston, MA, USA
ILYAS YILDIRIM
 Department of Chemistry and Biochemistry, Florida Atlantic University,
Jupiter, FL, USA
Contributors
xiii

Part I
Atomistic and Coarse-Grained Force Fields for Proteins,
Small Molecules, and Nucleic Acids

Chapter 1
Atomistic Force Fields for Proteins
Robert B. Best
Abstract
All-atom, classical force ﬁelds for protein molecular dynamics (MD) simulations currently occupy a sweet
spot in the universe of computational models, sufﬁciently detailed to be of predictive value in many cases,
yet also simple enough that some biologically relevant time scales (microseconds or more) can now be
sampled via specialized hardware or enhanced sampling methods. However, due to their long evolutionary
history, there is now a myriad of force ﬁeld branches in current use, which can make it hard for those
entering the simulation ﬁeld to know which would be the best set of parameters for a given application. In
this chapter, I try to give an overview of the historical motivation for the different force ﬁelds available,
suggestions for how to determine the most appropriate model and what to do if the results are in conﬂict
with experimental evidence.
Key words Transferable model, CHARMM, AMBER, GROMOS, OPLS, Protein folding, Unfolded
state, Conformational change, Membrane proteins
1
Introduction
Classical simulations of biomolecules have provided many insights
into structure, function and dynamics. A spectrum of models rang-
ing from extremely coarse-grained (one bead per residue or per
molecule) to very detailed quantum mechanical methods has
emerged for describing their dynamics and function, with a trade-
off to be made between accuracy and computational cost. Highly
coarse-grained models, whilst computationally cheap, are usually
only valid under speciﬁc conditions and may need to be reopti-
mized or parameterized for each problem they are applied to; they
usually also result in unrealistically fast dynamics due to their
smoother energy surface. At the other extreme, quantum mechani-
cal models, while they can be very accurate, quickly become too
slow to perform any sampling of time scales relevant to biology.
All-atom simulations with explicit solvent, in which every atom,
including hydrogen, is represented by an explicit particle, currently
represent a reasonable trade-off between these two difﬁculties [1].
They are often referred to as “transferable”, meaning that their
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_1, © Springer Science+Business Media, LLC, part of Springer Nature 2019
3

parameters are reasonably independent of the molecule(s) in ques-
tion; for example, they can be speciﬁed entirely from the sequence
in the case of proteins. This gives them more predictive value than
more coarse-grained models, and their reproduction of protein
dynamical properties measured in experiment is frequently of useful
accuracy. At the same time, partly thanks to Moore’s law [2], partly
to the development of specialized hardware such as GPUs [3] and
the ANTON supercomputer [4] and partly to advances in simula-
tion algorithms and enhanced sampling methods [5, 6], it is now
possible to run simulations with such models routinely reaching a
microsecond (and sometimes millisecond) time scale. These time
scales allow many biologically relevant processes to be accessed,
from the folding of small proteins [7] to the functioning of ion
channels [8].
In this chapter, I focus on classical non-polarizable (“additive”)
force ﬁelds for running simulations of proteins (more detailed
models are discussed in Chapter 4, and a less detailed, coarse-
grained model in Chapter 5 of this book). I am only concerned
with simulations in which the solvent molecules are explicitly
included in the simulation, that is, implicit solvent models are not
discussed. Since molecular simulations of proteins have the longest
history amongst biomacromolecules, methods and force ﬁelds for
proteins are perhaps the most developed. Most current empirical
force ﬁelds share a very similar overall functional form due to their
common heritage from the early days of molecular dynamics
[9, 10]. As a result, users can very often choose independently the
simulation code and force ﬁeld for a given application. The simula-
tion package can easily be chosen according to performance, accu-
racy and desired features (e.g. enhanced sampling schemes)—
however, some care is needed (see Note 1).
The question of which force ﬁeld to use is more difﬁcult to
answer. It is also probably the only question about force ﬁelds that
most users would care to know about. Unfortunately, there is no
simple answer, as all additive force ﬁelds available today have
strengths and weaknesses. This is partly due to the limitations of
the functional form which includes many effects only implicitly,
such that any set of parameters is a coarse-graining and cannot be
generally applicable; it is possible that more sophisticated models,
including polarization or charge penetration effects, may ultimately
be more accurate. However, due to the complexity of optimizing
the large number of available parameters, there is surely still con-
siderable room for improving parameters for current functional
forms, and this challenge will be even more severe for more com-
plex functional forms. Thus, we can anticipate that imperfect force
ﬁelds will be with us for the foreseeable future. Users therefore
cannot afford to treat force ﬁelds as a black box, but need to
account for force ﬁeld limitations when designing a simulation
study. This includes being aware of potential shortcomings,
4
Robert B. Best

running small tests relevant to the problem under consideration,
comparison with experiment and possible reﬁnement of the results
using experimental data. All of these are interconnected issues, and
this chapter will attempt to provide some guidance on how to deal
with them in real world applications.
2
Theory
2.1
Functional Form
and Parameters
Classical atomistic force ﬁelds start by assigning each atom a speciﬁc
chemical atom “type”, for example, aliphatic carbon or amide
nitrogen. The potential energy of the system is then given by a
form similar to that in Eq. 1:
V ¼ V bonded þ V non‐bonded
ð1Þ
where the bonded part of the energy function usually takes the
form:
V bonded ¼
X
bonds
i
1
2kb,i ri  r0
i

2 þ
X
angles
i
1
2kθ,i θi  θ0
i

2
þ
X
torsions
i
X
nkϕ,i,n cos nϕi  ϕ0
i


ð2Þ
In this expression, the ﬁrst sum runs over pairs of bonded
atoms with separation ri and equilibrium bond length r0
i , the
second sum runs over triples of bonded atoms with an angle
between bonds of θi and an equilibrium bond angle of θ0
i and the
last sum runs over sets of four consecutively bonded atoms with
torsion angle ϕi. The bond and angle terms are harmonic and the
torsion angle term is given by the ﬁrst few terms of a Fourier series.
The parameters ki, r0
i and so on are deﬁned only in terms of the
atom types rather than being atom speciﬁc; this constraint is what
makes the scheme “transferable”, as well as reducing the number of
parameters required. An “improper” torsion angle term with simi-
lar form to the torsion angles is often used to maintain tetrahedral
or planar geometry. Some force ﬁelds use slight variations on this
form, and additional terms.
The non-bonded part of the energy has the form:
V non‐bonded ¼
X
i,j4εij
σij
rij

12

σij
rij

6
"
#
þ
X
i,j
qiq j
4πϵ0rij
ð3Þ
In which, the sums run over all atom pairs i, j (usually atoms
separated by fewer than a 2–3 bonds are excluded from these terms)
separated by a distance of rij and having respective charges qi and qj.
This type of non-polarizable energy function is often known as
Atomistic Protein Force Fields
5

“additive”, since it can be evaluated as a single sum, without the
need to iterate a polarizable term to self-consistency. Force ﬁelds of
this form originated with the “consistent force ﬁeld” developed by
Lifson [9], together with Levitt and Warshel.
Clearly, the large number of parameters to be deﬁned requires
careful optimization to give accurate results, such that determining
these parameters is generally the province of specialists. Nonethe-
less, it is useful for users to understand the origin of the different
terms and their interdependence. The bonds, angles and improper
torsions are the stiffest terms in the force ﬁeld (i.e. the energy varies
most for a given displacement from ideal geometry) and as such are
relatively independent of the other terms. They can usually be
determined based on small-molecule crystal structures, as well as
geometry optimization and normal mode analysis using an accurate
quantum chemistry method. Therefore, it is usually possible to
deﬁne them at a relatively early stage of parameterization. The
remaining bonded term “the torsion angles”, however, needs to
be determined in the context of the rest of the force ﬁeld, as it tends
to compensate for imperfections in the other terms and effects not
capture by the rest of the force ﬁeld. It can also be determined by
ﬁtting to quantum chemistry data; however, care is required for
torsion angle parameters that are common to many residues in the
protein, such as the backbone ϕ, ψ angles, as will be discussed later.
The Lennard-Jones parameters are usually determined by ﬁt-
ting to experimental data on the physical and thermodynamic
properties of simple liquids, an approach originally taken by the
Optimized Potentials for Liquid Simulations (OPLS) developers
[11]. The partial charges qi are perhaps one of the trickiest para-
meters to deﬁne. The most common method for doing so is to ﬁt
them to reproduce the electrostatic potential obtained from a
quantum mechanical calculation, a method pioneered by the
Assisted Model Building with Energy Reﬁnement (AMBER) family
of force ﬁelds [12]. However, the solutions are highly underdeter-
mined in such a ﬁt so that strong regularization is required to deﬁne
a unique solution (e.g. the solution in which all charges are as close
to zero as possible), and the result depends on the speciﬁc regulari-
zation chosen. The result is also highly dependent on the molecular
conformation chosen for the ﬁt and of course also on the level of
quantum theory used. This uncertainty is reﬂected in the diversity
of partial charges across different force ﬁelds. As will be seen later,
this can be a critical factor in obtaining accurate protein-protein
interactions.
2.2
Some Notes
on Force Field
Phylogeny
and Parameterization
Philosophy
The main all-atom force ﬁeld families are Chemistry at Harvard
Molecular Mechanics (CHARMM), AMBER, Groningen Molecu-
lar Simulation (GROMOS) and OPLS/AA (the all-atom version of
OPLS), most of which take their names from the simulation pack-
age with which they were originally associated, although most
simulation codes now support more than one force ﬁeld family.
6
Robert B. Best

There is signiﬁcant overlap of methodology used for parameteriza-
tion of these energy functions, so I will only describe the distin-
guishing features of each. I have also restricted discussion in this
section to the main trunk of each force ﬁeld lineage, with a selection
of branches and variations described in later application-speciﬁc
contexts.
2.2.1
CHARMM
The ﬁrst all-atom CHARMM protein force ﬁeld was CHARMM
22 [13], and this has been the basis for all subsequent atomistic,
additive CHARMM protein force ﬁelds. One distinct feature of its
parameterization was the use of QM energies for interaction of
biomolecular fragments with water molecules in order to parame-
terize the partial charges qi. This was one of the ﬁrst parameteriza-
tion
procedures
to
attempt
to
mimic
a
condensed
phase
environment. The ﬁrst major update to the CHARMM 22 force
ﬁeld was the addition of the “CMAP” potential in CHARMM
22/CMAP. This was a 2-dimensional (2D) cubic spline potential
for the backbone ϕ, ψ torsion angles, which was better able to
capture the features of the 2D distribution of ϕ, ψ angles observed
in structures deposited in the protein data bank [14, 15]. The most
recent update to CHARMM is version 36, in which the backbone
CMAP was reﬁtted, and also the side-chain dihedral parameters
were reoptimized against high-level QM data [16]. A further
reﬁnement, CHARMM 36m, is described in more detail in a later
section [17]. CHARMM 36 and 36m represent the state of the art
for additive CHARMM force ﬁelds.
2.2.2
AMBER
The ﬁrst all-atom AMBER force ﬁeld intended for explicit solvent
simulations was AMBER ff94 [18], and this has served as the parent
of most atomistic AMBER force ﬁelds till the present day. The
novel feature introduced in the parameterization of this force ﬁeld
was the ﬁtting of atomic partial charges to reproduce the electro-
static potential obtained from QM calculations using Hartree-Fock
in the gas phase, known as restrained electrostatic potential (RESP)
ﬁtting [12, 18]. Restraints, or regularization, are needed in order to
remove the degeneracy from the solution space. This procedure is
easily automated and provides a well-deﬁned, algorithmic proce-
dure for deriving charges for new molecules. The use of Hartree-
Fock for determining the electrostatic potential leads to a slight
“overpolarization” which was justiﬁed as approximately mimicking
a condensed phase environment would also tend to increase polari-
zation. This set of partial charges has been used without modiﬁca-
tion in almost all AMBER force ﬁelds to date. The main exception
was the AMBER ff03 force ﬁeld which also used a RESP procedure
to obtain charges, but the QM electrostatic potential was computed
with an implicit solvent environment, in conjunction with a higher
level of QM theory. Although less extensively used, this force ﬁeld
has some advantages, as will be described later. More recently, the
Atomistic Protein Force Fields
7

ff14ipq force ﬁeld used a sophisticated self-consistent reﬁnement of
parameters in which the electrostatic environment in the QM cal-
culation was represented by surrounding water molecules whose
conﬁgurations were obtained by simulation with the previous
parameter iteration [19]. The trunk of AMBER force ﬁeld devel-
opment has nonetheless consisted of revisions of ff94, including
ff96 [20], ff99 [21] and ff99SB [22], all of which primarily reﬁned
torsion angle parameters. The ff99SB force ﬁeld was the standard
for many years, until the recent publication of the ff14SB force ﬁeld
which further reﬁned backbone and side-chain torsion parameters
against high-level QM calculations and experimental data for pep-
tides [23] and is considered the state of the art amongst the
“standard” AMBER force ﬁelds. In addition to the force ﬁelds
mentioned earlier, there are a myriad variants of each of these
ofﬁcial versions, which would be impossible to comprehensively
summarize in the space available. Nonetheless, some of these rep-
resent signiﬁcant improvements for certain applications and are
described in further detail in other sections later.
2.2.3
GROMOS
Strictly speaking, the GROMOS force ﬁelds are not all-atom, since
the non-polar hydrogens are not explicitly represented, instead
being accounted for by the Lennard-Jones parameters of the car-
bon center to which they are bonded (i.e. “united-atom” model).
There are also some signiﬁcant differences in the functional form
for both bond and angle terms, which will not be described here as
they are mainly intended for computational efﬁciency. Non-bonded
parameters (both Lennard-Jones and partial charges) are ﬁtted to
reproduce thermodynamic properties of pure liquids, as well as
solvation thermodynamics of amino acid analogs. The most recent
versions of the force ﬁeld are GROMOS 53A5 and 53A6 [24];
versions 54A7 and 54B7 build on these primarily by reﬁning tor-
sion angle parameters [25].
2.2.4
OPLS/AA
As mentioned earlier, OPLS was the ﬁrst force ﬁeld family to ﬁt
non-bonded parameters based on liquid state simulations. The
original all-atom OPLS-AA force ﬁeld [26] borrowed torsional
parameters from AMBER, which were subsequently reﬁtted against
QM energies for dipeptides in OPLS-AA/L [27]. OPLS-AA/L is
perhaps the most widely used all-atom version of OPLS; however, it
has been subsequently updated, the most recent version being
OPLS3 [28]. A particular focus of OPLS parameter development
has been small molecule binding, with a view towards applications
in drug design.
This summary of force ﬁeld families is of necessity restricted to
the most essential information on recent generations of the most
widely used force ﬁelds. Those desiring a more comprehensive
historical overview are referred to a recent review [29].
8
Robert B. Best

2.3
Force Fields
for Water and Ions
Although this chapter is about protein force ﬁelds, it is also impor-
tant to specify what the model is for environment, which in most
cases is water and inorganic ions. Each of the abovementioned force
ﬁelds were developed with a speciﬁc three-site water model in mind,
that being TIP3P [30] for the AMBER and OPLS families, a
modiﬁed TIP3P model for CHARMM [13] and the SPC [31]
model for the GROMOS family. The modiﬁcation for CHARMM
consists of adding a small Lennard-Jones term to the hydrogens
(which have no Lennard-Jones potential in standard TIP3P). For
the most part, this modiﬁcation makes relatively little difference,
although it can slightly alter folding equilibrium [32].
One unifying feature of the standard water models for use with
protein force ﬁelds is that they are known to be quite poor models
for water itself, particularly considering recent progress that has
been made towards developing better models [33–37]. In most
force ﬁelds, the water model is included in the parameterization,
making it harder to justify a simple substitution. However, since the
AMBER non-bonded parameters did not explicitly consider a water
model in their derivation, it is easier to motivate testing with
alternative models. Using either the TIP4P-Ew [35] or TIP4P-
2005 [34] models (two relatively accurate four-site models) did
yield improvements in the properties of small peptides [38, 39].
However, as we discuss further in the later sections, a simple
substitution of the water model was insufﬁcient to reproduce prop-
erties of disordered proteins: it turns out that the major deﬁciency
of these models is not their reproduction of pure water properties
but that the protein-water dispersion interactions are too weak.
A quick word on ions: if using a low salt concentration (less
than ~100 mM), default force ﬁeld parameters for ions are usually
adequate. However, if high salt conditions are of interest, more care
is needed, since older parameter sets can lead to rapid and sponta-
neous formation of ion pairs and even small salt crystals well below
the experimental solubility limit. Several efforts in recent years have
addressed this problem [40, 41]. Note that the improved ion
parameter sets are not necessarily included as the default in all
distributions!
3
Methods
3.1
Choosing a Force
Field for a Given
Application
As alluded to in the introduction, there is no panacea for choosing a
good force ﬁeld for a particular problem. Given that almost all force
ﬁeld parameter sets have some known limitations, an initial litera-
ture search for applications close to the problem of interest will be
useful to eliminate force ﬁelds with known deﬁciencies relevant to
that application. Such an application-speciﬁc choice of force ﬁeld
may seem to go against the spirit of general-purpose transferable
force ﬁelds that should be applicable to a broad range of problems.
Atomistic Protein Force Fields
9

However, given that force ﬁelds are not quite at this point yet, it
really is important to choose a force ﬁeld which is expected to be
most accurate for the domain of interest—if it is not accurate
enough, it may not be practical to use experimental data to correct
the obtained ensembles. Although there is no substitute for famil-
iarity with the literature, I have summarized here some of the
important issues with recent force ﬁelds, how they have been at
least partially resolved and how they affect different classes of
problems. This is roughly ordered from problems which are least
sensitive to force ﬁeld choice, to those that are most sensitive.
3.1.1
Conformational
Changes in Folded Proteins
Native state ﬂuctuations and dynamics and conversions between
different conformational states of folded proteins are amongst the
oldest applications of biomolecular force ﬁelds. Most force ﬁelds
have been extensively tested for such problems, and major short-
comings have been addressed. Therefore, most recent force ﬁelds
should do a reasonable job in reproducing the properties of folded
proteins. Recent force ﬁeld modiﬁcations that affect folded proteins
have focused mainly only improvements to torsion angle potentials.
Examples include the CHARMM CMAP potential to more accu-
rately describe the protein backbone in CHARMM 22/CMAP
[14, 15] and both backbone CMAP and side-chain torsions in
CHARMM 36 [16]. In the AMBER family, the ILDN modiﬁcation
improved the description of side-chain torsion angles of Isoleucine,
Leucine, Aspartate and Asparagine residues [42] for the AMBER
ff99SB force ﬁeld [22]; more recently, the AMBER ff14SB force
ﬁeld has integrated backbone and side-chain improvements into the
main trunk of AMBER force ﬁelds. Simulations of folded states are
relatively tolerant to many force ﬁeld errors, since the ability of the
protein to sample incorrect states is rather limited whilst it remains
folded, and unfolding usually only occurs on relatively long-time
scales. Nonetheless, users are encouraged to read recent articles
which compare the performance of different force ﬁelds in repro-
ducing experimental data (especially that from nuclear magnetic
resonance (NMR) spectroscopy) for the folded state [43] in order
to guide their choice.
3.1.2
Protein Folding
Protein folding, starting from a disordered chain, clearly samples a
much greater region of conformational space and as such is more
sensitive to force ﬁeld errors. Early simulations of the folding of
small mini-proteins, particularly by Pande and co-workers, chalked
up some important successes by obtaining folding events in unbi-
ased simulations, but also revealed that certain force ﬁelds at the
time were more appropriate for certain kinds of proteins—that is,
according to whether the protein consisted primarily of alpha-
helical or beta-sheet structure [44–46]. This deﬁciency was also
evident in all-atom simulations of the all-β WW-domain by Schul-
ten and co-workers, which populated only α-helical structures
10
Robert B. Best

[47, 48]. The key to resolving this problem was reﬁnement of
backbone dihedral angles, since even small biases, less than kBT, in
favour of helical or extended structure could add up to a large
cumulative effect over the whole sequence. This issue was resolved
by reﬁning force ﬁelds against NMR data for peptides in solution,
particularly using NMR data for the helix-forming peptide Ac-(AA-
QAA)3-NH2 [49], leading to the force ﬁelds AMBER ff03∗and
AMBER ff99SB∗[50], which could fold into both alpha and beta
structures [51, 52]. Similar reﬁnements of backbone torsion angles
were made in the CHARMM 22∗force ﬁeld by the DE Shaw
group in their landmark study folding ten different proteins by
unbiased MD simulations [7, 53]. Recent force ﬁelds such as
CHARMM 36 [16] and AMBER ff14SB [23] have included similar
corrections to the backbone potential. A more detailed approach to
reﬁning the backbone potential is to use a residue-speciﬁc torsion
potential (versus the common backbone potentials described ear-
lier). This idea has been implemented in the recent residue-speciﬁc
force ﬁelds RSFF1 [54] and RSFF2 [55], in which the backbone
torsion terms are speciﬁcally ﬁtted for each residue to data from coil
regions in structures deposited in the protein databank. With the
types of torsion angle corrections summarized earlier, most current
force ﬁelds should be much more capable than earlier generations
of folding proteins to their native states. The accuracy of different
force ﬁelds for studying protein folding has recently been assessed
[56]. Indeed, detailed analysis of folding mechanisms obtained in
the folding simulations by the DE Shaw group showed that the
folding pathways obtained were in excellent agreement with rele-
vant experimental observables [57]. Despite this success, many
force ﬁelds which are capable of folding proteins still contain
important deﬁciencies in the properties of unfolded states, as will
be discussed later.
3.1.3
Unfolded Proteins,
Intrinsically Disordered
Proteins and Protein-
Protein Interactions
The torsion angle corrections described earlier would certainly be
expected to improve the properties of denatured states in force
ﬁelds, through reducing formation of incorrect secondary struc-
tures. While this is indeed the case, it was also observed that a major
residual shortcoming in the representation of unfolded states was
that they were much too compact [58]. Switching to more accurate
water models, although an improvement, did not fully resolve the
situation [39]. This compaction, essentially attributable to the
water in simulations being an insufﬁciently good solvent, is related
to a second force ﬁeld deﬁciency, namely that the association of
folded proteins is much too tight. Even proteins which are known
to only weakly associate would associate non-speciﬁcally with very
high afﬁnity in simulations [59], presumably attributable to the
protein force ﬁeld being overall too hydrophobic. A number of
solutions have been proposed to this problem, falling either into
Atomistic Protein Force Fields
11

the category of speciﬁcally modifying protein-water interactions
[60, 61] or of modifying the water model itself [62]. Both have
the effect of strengthening the dispersion interactions from the
Lennard-Jones potential between the protein and water, thus
making water a better solvent for unfolded proteins and yielding
much better properties for unfolded proteins.
An obvious question when strengthening protein-water inter-
actions is whether this would destabilize folded states, since the
solvent accessible surface area is larger for unfolded states. This
problem would be even more acute for larger proteins, since
unfolded state surface area scales with the number of residues, N,
while the folded state surface area grows as N2/3. A slight destabili-
zation was indeed observed for all approaches which corrected the
over-collapse problem [60–62]. It appears that adding back a term
representing stronger backbone hydrogen bonding, ﬁrst proposed
by Nerenberg et al. [60] and more extensively developed by Robus-
telli et al. [63], helps to correct this shortcoming and may be
sufﬁcient to create a force ﬁeld that is truly equally applicable to
folded and unfolded proteins.
An issue which has received less attention in the literature than
the overall degree of collapse in unfolded proteins is the strength of
salt bridges in simulations. This has been observed to be relevant in
some long-time scale simulations of protein folding and seems to be
mainly related to the choice of side-chain partial charges on the
charged side-chains, particularly those of arginine, aspartate and
glutamate [53, 64]. In general, it seems that such salt bridges may
be too strong in many force ﬁelds. A manual adjustment of charges
using experimental data for association of small-molecule analogues
of these side chains was found to improve the strength of
(i.e. weaken) salt bridges in the CHARMM 22∗force ﬁeld [53],
as was the charge set in AMBER ff15ipq [64, 65]. A recent study of
the association of side-chain analogues from multiple force ﬁelds
suggested that the overlying tight binding of oppositely charged
residues may be common to most force ﬁelds, with the best
performing model in that study being AMBER ff03 [66]. In
many applications where charged groups are rare, overly strong
salt bridges may not be a serious issue, but for highly charged
(e.g. DNA-binding proteins and their binding partners and some
intrinsically disordered proteins), it would clearly be preferable to
choose one of the force ﬁelds that has a lower propensity to over-
stabilize salt bridges.
3.1.4
Membrane Protein
Folding and Association
Both experiments and simulations of membrane proteins are less
developed than for soluble proteins owing to the difﬁculty of
working with membranes in both contexts. In the simulation con-
text, a chief difﬁculty is the very high viscosity of the membrane
itself. Very accurate models of membranes have been developed
through years of careful reﬁnement, in particular the CHARMM
12
Robert B. Best

36 membrane force ﬁeld [67]. Together with the high-quality
CHARMM 36 protein force ﬁeld [16], this is expected to be a
good combination for simulations of membrane proteins. How-
ever,
an
initial
calculation
of
the
dissociation
constant
of
glycophorin A, a prototypical transmembrane helix dimer, using
the CHARMM 36 protein and lipid force ﬁelds showed that it was
unstable, versus the strong experimental evidence that it was stable
[68] (a similar result was obtained with the AMBER Slipids
[69, 70] and AMBER ff03w protein force ﬁeld [39]). A simple
adjustment of protein-lipid interactions was sufﬁcient to remedy
this issue [68], although its generality remains to be tested. For
larger transmembrane proteins, their greater intrinsic stability and
the slow dynamics in the membrane likely mean that this issue will
not be relevant to currently accessible simulation time scales.
3.2
Running Pilot
Force Field Tests
for a New Application
Although the earlier discussion covers many commonly encoun-
tered applications, it is impossible to be comprehensive. Since it is
now straightforward in many MD codes to set up the same system
with different force ﬁelds, it can be very useful to devise simple tests
that can be informative of force ﬁeld quality before embarking on a
large-scale simulation project. Often the main project will consume
a large fraction of a computing allocation on a supercomputer
facility, and there may not be a chance to repeat it with different
force ﬁelds. But if the results turn out to be of too low quality due to
a poorly chosen force ﬁeld, that time was essentially wasted. The
ideal test should be as relevant as possible to the ﬁnal problem. To
take an example from my own work, if one is interested in the
properties of unfolded proteins in chemical denaturants, a quantita-
tive comparison to data for association of chemical denaturants with
model peptides will provide initial feedback on which force ﬁelds are
most accurate [71, 72]. Such well-designed test cases can also be
used to tweak force ﬁeld parameters in case no available force ﬁeld is
of sufﬁcient quality [36], as discussed later. Choosing a sufﬁciently
good force ﬁeld at the outset is important, even if experimental data
are being used in conjunction (see Subheading 3.4 below and Part
III of this book). This is ﬁrstly because in a simulation with an
experimental bias any properties not determined by the experiment
will come from the force ﬁeld (although in reality most properties
would be determined by a combination of the two). Secondly, if
reweighting is done after the fact in order to better match experi-
ment, this will require the simulation ensemble to be sufﬁciently
similar to the true ensemble in order to be practically useful.
3.3
Testing
Simulation Results
Against
Experimental Data
Clearly, the goal of using molecular simulations is not just to
reproduce experimental observables but to obtain atomistic
insights that would be much harder, if not impossible, to glean
from experiment, as discussed in Part III of this book. Nonetheless,
as with any model, it is important to assess its accuracy by
Atomistic Protein Force Fields
13

comparing the results with the available experimental data (and
thus, if there is an option, one should choose to study a system
for which experimental data are available, or are expected to
become available). Note that before comparing with experimental
data, it is essential to demonstrate (as best possible) that the sam-
pling is adequate to compute reliable equilibrium average (see Note
2 below). If the simulation is not sampling from an equilibrium
distribution, then any disagreement from experiment could contain
contributions both from the force ﬁeld and from the insufﬁcient/
inaccurate sampling, which will be impossible to separate.
For simple equilibrium properties, a commonly used measure
of agreement of observables computed from simulation xi,sim with
experimental counterparts xi,expt is the reduced χ2 parameter,
χ2 ¼ 1
N
XN
i¼1
xi,sim  xi,expt

2
σ2
sim xi
ð
Þ þ σ2
expt xi
ð
Þ
where the σ2
sim xi
ð
Þ and σ2
expt xi
ð
Þ are respectively the variances of the
N simulated and experimental observables. The choice of χ2 is due
to its close relation to the likelihood function for Gaussian-
distributed errors and because it weights deviations from experi-
ment according to the associated errors. The intuitive interpreta-
tion is that for good agreement with experiment, χ2  1. It is
important to choose experimental data related to the properties
of interest of the protein. For example, comparing with NMR scalar
couplings, which give local information on dihedral angles, it is not
likely to be very informative about the overall degree of collapse of a
protein; on the other hand, the translational diffusion coefﬁcient or
small-angle X-ray scattering data would be more relevant to the
degree of collapse.
With a well-chosen force ﬁeld, it is now often possible to get
quantitative agreement with experimental properties, at least in the
vicinity of 300 K. Thus, ideally, computing this deviation should
only help to conﬁrm that the results are consistent with experiment.
3.4
Dealing
with Deviations from
Experiment
In the unfortunate situation that there remain signiﬁcant deviations
from the experimental properties of interest, this complicates any
inferences of structure or mechanism from the simulation, since
clearly even the equilibrium ensemble differs from experiment.
There are two routes to recover from this situation. The simplest
is to reweight the simulation snapshots in order to match the
available data (of course with appropriate restraints on the weights
to prevent overﬁtting), an approach which is presented in the
chapters in Part III. However, this approach can only work if the
overlap of the simulation with the true ensemble is sufﬁciently
good. If there is bad overlap, the only way to ﬁt the experimental
data will be to choose very non-uniform weights in the reweight-
ing, that is, only a few snapshots would receive non-negligible
14
Robert B. Best

weights, casting doubt on the reliability of any conclusions drawn
[73, 74]. In that situation, the only option is to carry out a new
simulation.
The most straightforward way of performing such a new simu-
lation that will better match experiment is to incorporate the exper-
imental data, or some subset of the experimental data, as restraints
in ensemble-restrained simulations, as also described in Part III.
Leaving out a fraction of the data can help to test for overﬁtting in
the restrained simulations. A more ambitious approach than doing
restrained simulations would be to systematically modify the force
ﬁeld itself, which has the potential advantage of improving both the
present as well as future simulation studies [36, 50, 75]. However,
this will be more demanding both in terms of computational costs
and potential technical pitfalls.
4
Notes
1. It should be noted that even for the same force ﬁeld, small
differences will generally be obtained in results using different
codes,
mainly
due
to
differences
in
the
treatment
of
non-bonded cut-offs and long-range dispersion corrections;
considerable care is needed in replicating these details for
quantitative comparisons, since different codes use different
approaches or parameters by default, and exactly replicating
cut-offs and switching functions in different codes is challeng-
ing. In the long run, the introduction of lattice sum methods
for Lennard-Jones terms should help to further reduce differ-
ences between force ﬁeld implementations in different codes, as
well as including the important long-range contribution to the
dispersion forces [76].
2. Importance of appropriate sampling. Before drawing any con-
clusions regarding force ﬁeld quality, it needs to be shown that
the sampling is sufﬁcient that the results approximate an equi-
librium distribution—commonly referred to as “convergence”.
Most experimental data reﬂect equilibrium properties, and it is
not possible to compare them with a simulation that is not
also sampling an equilibrium distribution. Following trends in
collective properties (e.g. radius of gyration or a suitable reac-
tion coordinate) versus time can give some indication of
whether a simulation has converged. However, this can still
be misleading if there is a large energy barrier which the system
has not crossed during the simulation (this is true even when
enhanced sampling schemes are used). A much more stringent
test of convergence, appropriate for either unbiased runs or
enhanced sampling simulations, is to start two or more runs
from very different initial conditions, ideally on either side of
Atomistic Protein Force Fields
15

the putative major free energy barrier (e.g. folded, unfolded for
protein folding or bound, unbound for binding). Convergence
is obtained when the results from these runs are consistent, that
is, the same within statistical error (since all averages obtained
from simulation have some associated error). Estimation of the
errors from molecular simulations must also be done with care,
in order to avoid underestimating the error due to data which
are correlated in time. A standard technique for overcoming this
issue is block error analysis [77]. If the sampling has not been
shown to be sufﬁcient to achieve convergence, it is pointless to
even begin a discussion about force ﬁeld quality. Part II of this
book has information about different enhanced sampling meth-
ods which may be able to speed up the rate of sampling.
Acknowledgment
RB is supported by the Intramural Research Program of the
National Institute of Diabetes and Digestive and Kidney Diseases
of the National Institutes of Health.
References
1. Karplus M, McCammon JA (2002) Molecular
dynamics simulations of biomolecules. Nat
Struct Biol 9(9):646–652
2. Moore GE (1965) Cramming more compo-
nents into integrated circuits. Electronics 38
(8):114–117
3. Friedrichs MS, Eastman P, Vaiyanathan V,
Houston M, Legrand S, Beberg AL, Ensign
DL, Bruns CM, Pande VS (2009) Accelerating
molecular dynamics simulations on graphics
processing
units.
J
Comput
Chem
30
(6):864–872
4. Shaw DE, Deneroff MM, Dror RO, Kuskin JS,
Larson RH, Salmon JK, Young C, Batson B,
Bowers
KJ,
Chao
JC,
Eastwood
MP,
Gagliardo J, Grossman JP, Ho CR, Ierardi
DJ, Kolossvary I, Klepeis JL, Layman T,
McLeavey C, Moraes MA, Mueller R, Priest
EC, Shan
YB, Spengler
J, Theobald
M,
Towles B, Wang SC (2007) Anton, a special-
purpose machine for molecular dynamics sim-
ulation. In: Isca’07: 34th Annual International
Symposium on Computer Architecture, Con-
ference Proceedings. Conference Proceedings -
Annual International Symposium on Com-
puter Architecture. Assoc Computing Machin-
ery, New York, NY, pp 1–12
5. Zuckerman DM (2011) Equilibrium sampling
in biomolecular simulations. Annu Rev Bio-
phys 40:41–62
6. Valsson O, Tiwary P, Parrinello M (2016)
Enhancing important ﬂuctuations: rare events
and metadynamics from a conceptual view-
point. Annu Rev Phys Chem 67:159–184
7. Lindorff-Larsen K, Piana S, Dror RO, Shaw
DE (2011) How fast-folding proteins fold.
Science 334:517–520
8. Noskov SY, Berneche S, Roux B (2004) Con-
trol of ion selectivity in potassium channels by
electrostatic and dynamic properties of car-
bonyl ligands. Nature 431:830–834
9. Lifson S (1968) Consistent force ﬁeld for cal-
culations of conformations, vibrational spectra
and enthalpies of cycloalkane and n-alkane
molecules. J Chem Phys 49(11):5116
10. Gelin BR, Karplus M (1975) Sidechain tor-
sional potentials and motion of amino acids in
proteins: bovine pancreatic trypsin inhibitor.
Proc Natl Acad Sci U S A 72:2002
11. Tirado-Rives J, Jorgensen WL (1988) The
OPLS [Optimized Potentials for Liquid Simu-
lations] potential functions for proteins, energy
minimizations for crystals of cyclic peptides and
crambin. J Am Chem Soc 110(6):1657–1666
12. Bayly CI, Cieplak P, Cornell W, Kollman PA
(1993) A well-behaved electrostatic potential
based method using charge restraints for deriv-
ing atomic charges: the RESP model. J Phys
Chem 97:10269–10280
16
Robert B. Best

13. MacKerell AD Jr, Bashford D, Bellot M, Dun-
brack JRL, Evanseck JD, Field MJ, Fischer S,
Gao J, Guo H, Ha S, Joseph-McCarthy D,
Kuchnir L, Kuczera K, Lau FTK, Mattos C,
Michnick S, Ngo T, Nguyen DT, Prodhom B,
Reiher WE, III RB, Schlenkrich M, Smith JC,
Stote R, Straub J, Watanabe M, Kuczera J,
Yin D, Karplus M (2000) All-atom empirical
potential for molecular modeling and dynamics
studies of proteins. J Phys Chem B 102
(18):3586–3616
14. MacKerell AD Jr, Feig M, Brooks CL (2004)
Improved treatment of the protein backbone in
empirical
force
ﬁelds.
J
Am
Chem
Soc
126:698–699
15. MacKerell AD Jr, Feig M, Brooks CL (2004)
Extending the treatment of backbone energet-
ics
in
protein
force
ﬁelds:
limitations
of
gas-phase quantum mechanics in reproducing
protein conformational distributions in molec-
ular dynamics simulations. J Comput Chem
25:1400–1415
16. Best RB, Zhu X, Shim J, Lopes P, Mittal J,
Feig M, MacKerell AD Jr (2012) Optimization
of the additive CHARMM all-atom protein
force ﬁeld targeting improved sampling of the
backbone φ, ψ and side-chain χ1 and χ2 dihe-
dral
angles.
J
Chem
Theor
Comput
8:3257–3273
17. Huang J, Rauscher S, Nawrocki G, Rang T,
Feig M, De Groot BL, Grubmu¨ller H, Mack-
erell AD (2016) CHARMM36m: an improved
force ﬁeld for folded and intrinsically disor-
dered proteins. Nat Methods 14:71–73
18. Cornell WD, Cieplak P, Bayly CI, Kollman PA
(1993) Application of RESP charges to calcu-
late conformational energies, hydrogen bond
energies, and free energies of solvation. J Am
Chem Soc 115:9620–9631
19. Cerutti DS, Swope WC, Rice JE, Case DA
(2014) ff14ipq: a self-consistent force ﬁeld for
condensed-phase simulations of proteins. J
Chem Theor Comput 10:4515–4534
20. Kollman PA (1996) Advances and continuing
challenges in achieving realistic and predictive
simulations of the properties of organic and
biological
molecules.
Acc
Chem
Res
29
(10):461–469
21. Wang J, Cieplak P, Kollman PA (2000) How
well does a restrained electrostatic potential
(RESP) model perform in calculating confor-
mational energies of organic and biological
molecules?
J
Comput
Chem
21
(12):1049–1074
22. Hornak V, Abel R, Okur A, Strockbine B,
Roitberg A, Simmerling C (2006) Comparison
of
multiple
AMBER
force-ﬁelds
and
development of improved protein backbone
parameters. Proteins 65:712–725
23. Maier
JA,
Martinez
C,
Kasavajhala
K,
Wickstrom L, Hauser KE, Simmerling C
(2015) ff14SB: improving the accuracy of pro-
tein side chain and backbone parameters from
ff99SB.
J
Chem
Theor
Comput
11:3696–3713
24. Oostenbrink C, Villa A, Mark AE, van Gunste-
ren WF (2004) A biomolecular force ﬁeld
based on the free enthalpy of hydration and
solvation: the GROMOS force-ﬁeld parameter
sets 53A5 and 53A6. J Comput Chem 25:1656
25. Schmid N, Eichenberger AP, Choutko A,
Riniker S, Winger M, Mark AE, Van Gunsteren
WF (2011) Deﬁnition and testing of the GRO-
MOS force-ﬁeld versions 54A7 and 54B7. Eur
Biophys J 40:843–856
26. Jorgensen WL, Maxwell DS, Tirado-Rives J
(1996) Development and testing of the OPLS
all-atom force ﬁeld on conformational energet-
ics and properties of organic liquids. J Am
Chem Soc 118:11225–11236
27. Kaminski GA, Friesner RA, Tirado-Rives J, Jor-
gensen WL (2001) Evaluation and reparame-
terization of the OPLS-AA force ﬁeld for
proteins via comparison with accurate quantum
chemical calculations on peptides. J Phys Chem
B 105(28):6474–6487
28. Harder
E,
Damm
W,
Maple
J,
Wu
C,
Reboul M, Xiang JY, Wang L, Lupyan D,
Dahlgren MK, Knight JL, Kaus JW, Cerutti
DS, Krilov G, Jorgensen WL, Abel R, Friesner
RA (2015) OPLS3: a force ﬁeld providing
broad coverage of drug-like small molecules
and
proteins.
J
Chem
Theor
Comput
12:281–296
29. Riniker S (2018) Fixed-charge atomistic force
ﬁelds for molecular dynamics simulations in the
condensed phase: an overview. J Chem Inf
Model 58:565–578
30. Jorgensen WL, Chandrasekhar J, Madura JD
(1983) Comparison of simple potential func-
tions for simulating liquid water. J Chem Phys
79(2):926–935
31. Hermans J, Berendsen HJC, Van Gunsteren
WF, Postma JPM (1984) A consistent empiri-
cal potential for water-protein interactions.
Biopolymers 23:1513–1518
32. Boonstra S, Onck PR, Van der Giessen E
(2016) CHARMM TIP3P water model sup-
presses
peptide
folding
by
solvating
the
unfolded
state.
J
Phys
Chem
B
120:3692–3698
33. Vega C, Abascal JLF, Conde MM, Aragones JL
(2008) What ice can teach us about water inter-
actions:
a
critical
comparison
of
the
Atomistic Protein Force Fields
17

performance of different water models. Fara-
day Discuss 141:251–276
34. Abascal JLF, Vega C (2005) A general purpose
model for the condensed phases of water:
TIP4P/2005. J Chem Phys 123:234505
35. Horn HW, Swope WC, Pitera JW, Madura JD,
Dick TJ, Hura GL, Head-Gordon T (2004)
Development of an improved four-site water
model for biomolecular simulations: TIP4P-
Ew. J Chem Phys 120:9665
36. Wang L-P, Martinez TJ, Pande VS (2014)
Building force ﬁelds: an automatic, systematic
and reproducible approach. J Chem Theor
Comput 5:1885–1891
37. Izadi S, Anandakrishnan R, Onufriev AV
(2014) Building water models: a different
approach. J Phys Chem Lett 5:3863–3871
38. Nerenberg PS, Head-Gordon T (2011) Opti-
mizing protein-solvent force ﬁelds to repro-
duce intrinsic conformational preferences of
model
peptides.
J
Chem
Theory
Comp
7:1220–1230
39. Best RB, Mittal J (2010) Protein simulations
with an optimized water model: cooperative
helix
formation
and
temperature-induced
unfolded
state collapse.
J Phys
Chem B
114:14916–14923
40. Luo Y, Roux B (2009) Simulations of osmotic
pressure in concentrated aqueous salt solu-
tions. J Phys Chem Lett 1:183–189
41. Joung IS, Cheatham TE (2008) Determina-
tion of alkali and halide monovalent ion para-
meters
for
use
in
explicitly
solvated
biomolecular simulations. J Phys Chem B
112:9020–9041
42. Lindorff-Larsen
K,
Piana
S,
Palmo
K,
Maragakis P, Klepeis JL, Dror RO, Shaw DE
(2010) Improved side-chain torsion potentials
for the Amber ff99SB protein force ﬁeld. Pro-
teins 78:1950–1958
43. Lindorff-Larsen K, Maragakis P, Piana S, East-
wood MP, Dror RO, Shaw DE (2012) System-
atic validation of protein force ﬁelds against
experimental data. PLoS One 7(2):e32131
44. Snow CD, Nguyen H, Pande VS, Gruebele M
(2002) Absolute comparison of simulated and
experimental protein-folding dynamics. Nature
420:102–106
45. Snow CD, Zagrovic B, Pande VS (2002) The
trp cage: folding kinetics and unfolded state
topology via molecular dynamics simulations.
J Am Chem Soc 124:14548
46. Zagrovic B, Snow CD, Shirts MR, Pande VS
(2002) Simulation of folding of a small alpha-
helical
protein
in
atomistic
detail
using
worldwide-distributed computing. J Mol Biol
323:927
47. Freddolino PL, Park S, Roux B, Schulten K
(2009) Force ﬁeld bias in protein folding simu-
lations. Biophys J 96:3772–3780
48. Freddolino PL, Harrison CB, Liu Y, Schulten
K (2010) Challenges in protein folding simula-
tions. Nat Phys 6:751–758
49. Shalongo W, Dugad L, Stellwagen E (1994)
Distribution of helicity within the model pep-
tide Acetyl(AAQAA)3amide. J Am Chem Soc
116:8288–8293
50. Best
RB,
Hummer
G
(2009)
Optimized
molecular dynamics force ﬁelds applied to the
helix-coil transition of polypeptides. J Phys
Chem B 113:9004–9015
51. Mittal J, Best RB (2010) Tackling force-ﬁeld
bias in protein folding simulations: folding of
villin HP35 and pin WW domains in explicit
water. Biophys J 99:L26–L28
52. Best RB, Mittal J (2010) Balance between α
and β structures in ab initio protein folding. J
Phys Chem B 114:8790–8798
53. Piana S, Lindorff-Larsen K, Shaw DE (2011)
How robust are protein folding simulations
with respect to force ﬁeld parameterization.
Biophys J 100:L47–L49
54. Jiang F, Zhou C-Y, Wu Y-D (2014) Residue-
speciﬁc force ﬁeld based on the protein coil
library. RSFF1: modiﬁcation of OPLS-AA/L.
J Phys Chem B 118:6983–6998
55. Zhou C-Y, Jiang F, Wu Y-D (2015) Residue-
speciﬁc force ﬁeld based on protein coil library.
RSFF2: modiﬁcation of AMBER ff99SB. J
Phys Chem B 119:1035–1047
56. Piana S, Klepeis JL, Shaw DE (2014) Assessing
the accuracy of physical models used in protein-
folding simulations: quantitative evidence from
long molecular dynamics simulations. Curr
Opin Struct Biol 24:98–105
57. Best RB, Hummer G (2016) Microscopic
interpretation of folding phi-values using the
transition-path ensemble. Proc Natl Acad Sci U
S A 113(12):3263–3268
58. Nettels
D,
Mu¨ller-Sp€ath
S,
Ku¨ster
F,
Hofmann
H,
Haenni
D,
Ru¨egger
S,
Reymond
L,
Hoffmann
A,
Kubelka
J,
Heinz B, Gast K, Best RB, Schuler B (2009)
Single
molecule
spectroscopy
of
the
temperature-induced collapse of unfolded pro-
teins.
Proc
Natl
Acad
Sci
U
S
A
106:20740–20745
59. Petrov D, Zagrovic B (2014) Are current
atomistic forceﬁelds accurate enough to study
proteins
in
crowded
environments?
PLoS
Comput Biol 10(5):e1003638
60. Nerenberg PS, Jo B, Tripathy A, Head-Gordon
T (2012) Optimizing solute-water van der
18
Robert B. Best

Waals interactions to reproduce solvation free
energies. J Phys Chem B 116:4524–4534
61. Best RB, Zheng W, Mittal J (2014) Balanced
protein-water interactions improve properties
of disordered proteins and non-speciﬁc protein
association.
J
Chem
Theor
Comput
10:5113–5124
62. Piana S, Donchev AG, Robustelli P, Shaw DE
(2015) Water dispersion interactions strongly
inﬂuence simulated structural properties of dis-
ordered
protein
states.
J
Phys
Chem
B
119:5113–5123
63. Robustelli P, Piana S, Shaw DE (2018) Devel-
oping a molecular dynamics force ﬁeld for both
folded and disordered protein states. Proc Natl
Acad Sci U S A 115(21):E4758–E4766
64. Ahmed MC, Papaleo E, Lindorff-Larsen K
(2018) How well do force ﬁelds capture the
strength of salt bridges in proteins? PeerJ 6:
e4967
65. Debiec KT, Cerutti DS, Baker LR, Gronen-
born AM, Case DA, Chong LT (2016) Further
along the road less travelled: AMBER ff15ipq,
an original protein force ﬁeld built on a self-
consistent physical model. J Chem Theor
Comput 12:3926–3947
66. Debiec KT (2014) Evaluating the strength of
salt bridges: a comparison of current biomolec-
ular
force
ﬁelds.
J
Phys
Chem
B
118:6561–6569
67. Klauda JB, Venable RM, Freites JA, O’Connor
JW,
Tobias
DJ,
Mondragon-Ramirez
C,
Vorobyov I, Mackerell AD, Pastor RW (2010)
Update of the CHARMM all-atom additive
force ﬁeld for lipids: validation on six lipid
types. J Phys Chem B 114:7830–7843
68. Domanski J, Sansom MSP, Stansfeld P, Best RB
(2018) Balancing force ﬁeld protein-lipid inter-
actions to capture transmembrane helix-helix
association.
J
Chem
Theor
Comput
14:1706–1715
69. Jambeck JPM, Lyubartsev AP (2012) Deriva-
tion and systematic validation of a reﬁned
all-atom force ﬁeld for phosphatidylcholine
lipids. J Phys Chem B 116:3164–3179
70. Jambeck JPM, Lyubartsev AP (2012) An
extension
and
further
validation
of
an
all-atomistic force ﬁeld for biological mem-
branes. J Chem Theor Comput 8:2938–2948
71. Horinek D, Netz RR (2011) Can simulations
quantitatively predict peptide transfer
free
energies to urea solutions? Thermodynamic
concepts and force ﬁeld limitations. J Phys
Chem A 115:6125–6136
72. Zheng W, Borgia A, Borgia MB, Schuler B,
Best RB (2015) Empirical optimization of
interactions between proteins and chemical
denaturants in molecular simulations. J Chem
Theor Comput 11:5543–5553
73. Hummer
G,
Ko¨ﬁnger
J
(2015)
Bayesian
ensemble reﬁnement by replica simulations
and reweighting. J Chem Phys 143:243150
74. Rangan R, Bonomi M, Heller GT, Cesari A,
Bussi G, Vendruscolo M (2018) Determina-
tion
of
structural
ensembles
of
proteins:
restraining vs reweighting. J Chem Theor
Comput 14:6632
75. Di Pierro M, Elber R (2013) Automated opti-
mization of potential parameters. J Chem
Theor Comput 9:3311–3320
76. Wennberg CL, Murtola T, Pall S, Abraham MJ,
Hess B, Lindahl E (2015) Direct-space correc-
tions
enable
fast
and
accurate
Lor-
entzBerthelot combination rule Lennard-
Jones lattice summation. J Chem Theor Com-
put 11:5737–5746
77. Flyvbjerg H, Petersen HG (1989) Error esti-
mates on averages of correlated data. J Chem
Phys 91:461–466
Atomistic Protein Force Fields
19

Chapter 2
Force Fields for Small Molecules
Fang-Yu Lin and Alexander D. MacKerell Jr
Abstract
Molecular dynamics (MD) simulations have been widely applied to computer-aided drug design (CADD).
While MD has been used in a variety of applications such as free energy perturbation and long-time
simulations, the accuracy of the results from those methods depends strongly on the force ﬁeld used.
Force ﬁelds for small molecules are crucial, as they not only serve as building blocks for developing force
ﬁelds for larger biomolecules but also act as model compounds that will be transferred to ligands used in
CADD. Currently, a wide range of small molecule force ﬁelds based on additive or nonpolarizable models
have been developed. While these nonpolarizable force ﬁelds can produce reasonable estimations of physical
properties and have shown success in a variety of systems, there is still room for improvements due to
inherent limitations in these models including the lack of an electronic polarization response. For this
reason, incorporating polarization effects into the energy function underlying a force ﬁeld is believed to be
an important step forward, giving rise to the development of polarizable force ﬁelds. Recent simulations of
biological systems have indicated that polarizable force ﬁelds are able to provide a better physical represen-
tation of intermolecular interactions and, in many cases, better agreement with experimental properties
than nonpolarizable, additive force ﬁelds. Therefore, this chapter focuses on the development of small
molecule force ﬁelds with emphasis on polarizable models. It begins with a brief introduction on the
importance of small molecule force ﬁelds and their evolution from additive to polarizable force ﬁelds.
Emphasis is placed on the additive CHARMM General Force Field and the polarizable force ﬁeld based on
the classical Drude oscillator. The theory for the Drude polarizable force ﬁeld and results for small
molecules are presented showing their improvements over the additive model. The potential importance
of polarization for their application in a wide range of biological systems including CADD is then discussed.
Key words Molecular dynamics simulations, Additive force ﬁeld, Polarizable force ﬁeld, Drude
oscillator model, Computer-aided drug design, CHARMM
1
Introduction
Computer-aided drug design (CADD) is assuming an important
role in drug development, speeding up the identiﬁcation of lead
compounds as well as facilitating their optimization into new ther-
apeutic agents. Molecular dynamics (MD) simulations based on
molecular mechanics have been widely used in CADD to predict
binding orientations and provide thermodynamic information,
including the prediction of the binding afﬁnity of ligands
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_2, © Springer Science+Business Media, LLC, part of Springer Nature 2019
21

[1]. MD simulations are based on solving Newton’s equations of
motion in which the required forces are obtained from a molecular
mechanics or empirical force ﬁeld. Hence, force ﬁelds for small
organic, drug-like molecules are required and crucial to ensure
the accuracy of MD simulations of ligands in drug discovery. MD
simulations of ligands alone may be of utility in the context of
ligand-based drug design [2–6] or be performed in the presence
of the macromolecule, typically a protein, and remaining environ-
ment in the context of target-based or structure-based drug design
[7–10].
Generating a force ﬁeld for drug-like ligands represents a sig-
niﬁcant challenge. Unlike proteins, where the chemical space has
relatively limited boundaries (e.g., amino acid side chains and pep-
tide backbone), drug-like molecules have an almost inﬁnite number
of possible atom combinations. Although drug-like molecules can
be broken down into different pieces, the properties of each chemi-
cal group could vary because of the neighboring chemical moieties,
especially in conjugated systems. For example, the property of
benzene is different from the property of benzene with a hydroxyl
group attached to it. On the other hand, chemical groups such as
phenol or imidazole that are linked by extended aliphatic-
containing moieties do largely maintain their chemical characteris-
tics, allowing for a drug-like molecule force ﬁeld to be treated as a
collection of individual chemical group parts. Thus, the develop-
ment of accurate organic molecule force ﬁelds is challenging and
requires large numbers of small model compounds that will act as
the parts to be combined to create drug-like molecules.
With the increased interest of modeling and simulation in drug
discovery, efforts have been ongoing in the development of drug-
like molecule force ﬁelds since the early 1980s. Nowadays, the
widely used force ﬁelds for small molecules are OPLS-All-Atom
(OPLS-AA) [11], OPLS3 [12], the CHARMM General force ﬁeld
(CGenFF) force ﬁeld [13–16], the General AMBER Force Field
(GAFF) [17, 18], Merck Molecular Force Field (MMFF) [19–23],
and GROMOS [24–28]. These force ﬁelds have been actively
maintained and regularly improved to include new parameters for
a wider range of chemical entities. As manual assignment of para-
meters for a new molecule requires much experience and is error-
prone, algorithms for automatically identifying atom types and
generating parameters for molecules have been developed. For
example, AnteChamber [18] was designed to generate GAFF and
AMBER topologies, and the CGenFF program, accessible through
the ParamChem [14, 15] website, was designed to generate
CHARMM topologies and parameters based on CGenFF. Other
parameter assignment programs include ATB [29] and PRODRG
[30, 31] for GROMOS, as well as MATCH [32] and SwissParam
[33] for CHARMM.
22
Fang-Yu Lin and Alexander D. MacKerell Jr

The majority of force ﬁelds for small molecules currently in use
are referred to as additive or nonpolarizable force ﬁelds. These force
ﬁelds share certain basic characteristics: a potential energy function
and the parameters used in the energy function. The term “addi-
tive” is based on the use of Coulomb’s law to treat electrostatic
interactions with the partial atomic charges, q, being static or ﬁxed,
such that the electrostatic energy of the system is simply the sum of
all individual atom-atom Coulombic interactions. An example of
the typical potential energy function is shown in Eq. 1.
U rð Þ ¼
X
bonds
kb b  b0
ð
Þ2
þ
X
angles
kθ θ  θ0
ð
Þ2 þ
X
dihedrals
kχ 1 þ cos nχ  δ
ð
Þ
ð
Þ
þ
X
vdW, i6¼j
εij
Rmin,ij
rij

12
 2 Rmin,ij
rij

6
"
#
þ
X
elec, i6¼j
qiq j
4πε0rij
ð1Þ
Equation 1 includes a simple functional form to describe
bonded (or internal) energies and nonbonded energies. Bonded
energies come from interactions between covalently bound atoms
within three covalent bonds, which include bond and valence angle
terms computed based on harmonic stretching and bending poten-
tials and dihedral angle term expressed as a cosine series expansion.
The symbols in Eq. 1 are as follows: b0 and θ0 are equilibrium values
for the bond length and valence angle between atoms, respectively;
n is the dihedral multiplicity; δ is the dihedral angle phase; and kb,
kθ, and kχ are force constants for bonds, angles, and dihedral terms.
b, θ, and χ are bond length, valence angle, and dihedral angle for a
given atomic conﬁguration, respectively. Nonbonded energies are
described by van der Waals (vdW) and electrostatic interactions.
Calculation of these interactions is normally excluded for atoms
connected by one or two covalent bonds (so-called 1–2 and 1–3
pairs, respectively). Energies from vdW interactions are often cal-
culated based on the Lennard-Jones (LJ) 6–12 potential that mod-
els electronic repulsion and dispersive interactions. As stated above,
the electrostatic energies are calculated based on Coulomb’s for-
mula, where each atom is assigned a ﬁxed point charge, also known
as partial atomic charges. In Eq. 1, rij is the distance between two
atoms i and j, Rmin,ij is the radius (the distance at which the LJ
energy is minimum), and εij is the well depth. Once a functional
form has been selected, all of the parameters in that functional form
for the different types of chemical entities in the force ﬁeld must be
optimized, a process called parametrization.
Although the additive force ﬁelds have been used for many
years and are remarkably successful in biomolecular MD simula-
tions and CADD, there are still inherent limitations in these addi-
tive models. One limitation is the lack of explicit treatment of
Force Fields for Small Molecules
23

electronic polarizability to model molecules. This limitation is pres-
ent because the partial atomic charges are ﬁxed, treating the
induced polarization in a mean-ﬁeld average way; however, in
reality, the electron density of an atom is not static and should be
able to adjust in response to the local electric ﬁeld, such that the
electronic polarizability of molecular systems is typically underesti-
mated in condensed phases in most of the additive force ﬁelds
[34]. To implicitly treat polarization response and give a better
representation of the electrostatic properties in condensed phases,
a common strategy in additive force ﬁelds is to overestimate the
gas-phase dipole moment of the molecule, typically on the order of
20% or more in the dipole moment [35]. This is based on the fact
that molecular dipole moments in condensed phases are generally
larger than those in the gas phase. For example, the dipole moment
of water in the gas phase is 1.9 D [36], whereas that in small clusters
is 2.1 D [37], and in the liquid phase is 2.9 D [38]. Accordingly, a
ﬁxed charge model is unable to obtain accurate properties in differ-
ent environments, although implicitly including polarizability
through overestimation of the dipole moment has been shown to
better model biomolecular systems. While the additive models have
shown good agreement with condensed phase properties, such as
experimental molecular volumes and enthalpies of vaporizations,
this approach is unable to accurately represent the polarization
response when molecules are experiencing changes between polar
and nonpolar environments. For example, in biological systems,
when a ligand binds to a protein, or a small molecule passes through
a membrane, the charge distribution of the molecule will change in
response to the local electric ﬁelds. However, using ﬁxed charges in
simulations will not model such variation of electrostatic properties;
therefore, the accuracy of the simulation using the additive force
ﬁeld is limited.
To solve this problem, a promising approach is to introduce the
explicit treatment of electric polarizability into the potential energy
function. Recent advances in polarizable force ﬁelds have demon-
strated the beneﬁts of explicitly treating the polarization effects and
have yielded improvements and better representations over the
additive force ﬁelds in a range of system [39–44]. For example,
the polarizable models are able to more accurately treat molecular
systems in environments with different polar characters, such as the
ion distribution near the water–air interface [45–48], ion perme-
ation through ion channel proteins [49–51], water–lipid bilayer
interactions [52, 53], protein folding [54], and protein–ligand
binding [55–60]. In the remainder of this chapter, we ﬁrst present
a short overview of the widely used CGenFF [13, 16] and GAFF
[17] additive force ﬁelds, with the remainder of the chapter focus-
ing on the development of polarizable force ﬁelds of small mole-
cules and their improvements in several aspects.
24
Fang-Yu Lin and Alexander D. MacKerell Jr

2
Additive CHARMM General Force Field and General AMBER Force Field
2.1
Additive
CHARMM General
Force Field
CHARMM General Force Field (CGenFF) [13, 16] is a force ﬁeld
developed
for
drug-like
molecules
and
is
compatible
with
CHARMM36 additive biomolecular force ﬁeld [61–76]. It is asso-
ciated with a wide range of model compounds, which were highly
optimized based on a standard CGenFF parametrization protocol
[13]. The protocol involves parametrizing partial atomic charges
targeting QM dipole moments and water interaction energies, LJ
parameters targeting experimental condensed phase properties and
bonded parameters targeting QM calculated geometries, vibra-
tional spectra, and dihedral potential energy scans. More impor-
tantly, the parametrization philosophy in CGenFF focuses on the
transferability among the model compounds rather than over-
ﬁtting of the parameters, such that the developed parameters for
the small molecules will be appropriate building blocks for larger
drug-like molecules.
The
CGenFF
program
[14,
15]
automatically
provides
CGenFF parameters for a molecule. This process includes atom
typing, followed by parameters and charges being assigned in an
automated fashion by analogy to those in the highly optimized
small model compounds existing in CGenFF. The ﬁrst step of
assigning parameters is to assign atom types for atoms of a given
molecule. This is performed by the “atom typer” module in the
CGenFF program. In practice, the atom typer will ﬁrst retrieve the
information of atoms in the molecule, the connectivity pattern of
these atoms, and the bond types between these atoms, which are
typically obtained through mol2 format ﬁle. Then, the assignment
of the atom types is determined through a decision tree based on a
rule ﬁle that has many subcategories for different chemical proper-
ties, such that according to the decision tree, the atom typer will
proceed from the main category to the next subcategory until the
condition for each atom is satisﬁed leading to assignment of the
atom type. Next, the CGenFF program will assign bonded para-
meters and charges to the given molecule based on those atom
types. However, as existing bonded parameters are often not pres-
ent in CGenFF for a given connectivity of atoms, the missing
bonded parameters are identiﬁed by analogy based on the similarity
between the atom types that deﬁne the parameters. Charges are
assigned through a bond-charge increment scheme, similar to that
implemented in MMFF94 [19–23]. Notably, in addition to single
charge increment for each bond, there are two charge increments
for each angle and three charge increments for each dihedral angle
in the CGenFF program. While such an approach requires the
optimization of the charge increments, it has the advantage of
capturing the inductive and resonance effects as well as improve
transferability between the dihedral parameters and the 1–4
Force Fields for Small Molecules
25

electrostatic interactions. Finally, a “penalty score” is returned for
bonded and charge parameters that are assigned based on analogy,
allowing users to estimate the quality of the force ﬁeld for the given
molecule, such that parameters with small penalties are assumed to
be of better accuracy versus those with high penalties. However, it
should be emphasized that the penalties are based on analogy rather
than on the reproduction of speciﬁc target data, such that para-
meters with higher penalties may be of suitable accuracy, while
parameters with low or zero penalties may be of limited accuracy
because they are in a chemical connectivity not included in the
original parametrization. Accordingly, it is suggested that when
the parameters for a given molecule are critical, such as with a
lead compound that will undergo extensive optimization, the user
should perform QM calculations to determine if the geometry and
conformational energies are satisfactory. This effort could include
comparison of the empirical and QM dipole moments as well as
interactions with water. Information of our webpage (http://
mackerell.umaryland.edu/) and tools such as the Force Field
Toolkit (ffTK) [77] or General Automatic Atomic Model Parame-
trization (GAAMP) utility [78] can be accessed to facilitate such a
process.
2.2
Additive General
AMBER Force Field
General AMBER Force Field (GAFF) [17] is designed for a wider
range of organic molecules that are compatible with existing
AMBER force ﬁelds that were developed primarily for proteins
and nucleic acids [79, 80], with subsequent extensions to carbohy-
drates [81–83] and lipids [84]. In the original version of GAFF
[17], there were 33 basic atom types and 22 special atom types to
cover most of the chemical space having the elements H, C, N,
O, S, P, F, Cl, Br, and I. The atom types in GAFF are determined on
the basis of the element, hybridization, aromaticity, and chemical
environment. In practice, for each atom, the match is performed
through each deﬁnition string; so, when a successful match is
achieved, the atom type is assigned. The bonded parameters are
derived based on empirical functions associated with reference data
including QM results, empirical rules, and crystal structures. The
charges in GAFF are computed from QM ab initio (i.e., HF/6-
31G* RESP charge) [80, 85, 86] or AM1-BCC semi-empirical
model [87]. Thus, the charges in GAFF are explicitly determined
for each molecule based on the QM method applied. Accordingly,
the charge determination requires a signiﬁcant amount of compu-
tational time, which possibly becomes a bottleneck in high-
throughput applications requiring a large number of molecules.
This is in contrast to CGenFF where the charge assignment is
instantaneous. In addition, GAFF does not supply any metric of
the quality of the assigned parameters.
26
Fang-Yu Lin and Alexander D. MacKerell Jr

3
Polarizable Force Fields
With increasing focus on the polarization response in simulations,
several polarizable force ﬁelds have been developed. Currently,
polarizable functional forms used in polarizable force ﬁelds can be
classiﬁed into three categories: the ﬂuctuating charge model, the
induced dipole model, and the classical Drude oscillator model.
These models are brieﬂy introduced below. In all three models, the
remainder of the functional form of the potential energy function is
largely the same as that in additive force ﬁelds, although variations
are seen.
3.1
Fluctuating
Charge Model
In the ﬂuctuating charge model, the calculation of electrostatic
energies involves the partial atomic charges on the molecule redis-
tributing in response to the electric ﬁeld from the environment
such that the molecular dipole changes. The redistribution of the
charges between atoms is based on the relative electronegativity and
hardness of each atom (see Note 1), while the overall charge on the
molecule is maintained. This model has been used in the universal
force ﬁeld (UFF) developed by Rappe et al. [88], force ﬁelds
developed by Berne, Friesner, and coworkers [89–91], and in the
CHARMM ﬂuctuating charge (FQ) force ﬁeld [92, 93]. However,
one limitation of this model is its inability to describe the out-of-
plane polarization directly for planar systems, such as water or
conjugated molecules, which is due to electrons only being able
to redistribute between atoms in the plane of the molecule. A
strategy to solve this problem is to add out-of-plane virtual sites
so that the redistribution of the charge is possible in the orthogonal
direction to yield the out-of-plane polarization. Another limitation
is the application in monatomic ions, as the redistribution of the
charge is not possible for a single charge site. Thus, in early studies
of ion solvation with the ﬂuctuating charge model for water, a
modiﬁed Drude oscillator (described below) was used for the
monatomic ions to model the electronic polarization [94].
3.2
Induced Dipole
Model
In this representation, inducible dipoles are added to atomic sites.
As shown in Eq. 2, the dipole moment (μi) induced on the atom (i)
is proportional to its atomic polarizability (αi) and the total electric
ﬁeld at that site. The total electric ﬁeld includes electrostatic ﬁelds
E0
i and E p
i , where E0
i is created on the atom (i) by the permanent
charges, and E p
i is created by the other induced dipoles from the
rest of the atoms in the system (see Note 2).
μi ¼ αi E0
i þ E p
i


ð2Þ
Thus, the contribution of the polarization energy, Upol, to the
total nonbonded energy is described as
Force Fields for Small Molecules
27

U pol ¼ 1
2
X
i
μiEi
ð3Þ
The induced point dipole model has been used in several
polarizable force ﬁelds, including OPLS/PFF [95], AMBER
[96–100], and PIPF [101], as well as force ﬁelds developed by
Berne, Friesner, and coworkers [95, 102], in the water, ion, and
small molecule force ﬁeld of Dang and coworkers [103–105] and
others [106–109]. Ren and Ponder combined the induced dipole
model with atomic multipoles through the quadrupole moments in
the treatment of the electrostatic interactions in the context of the
AMOEBA force ﬁeld [110–112]. However, the induced dipoles are
typically determined by a self-consistent ﬁeld (SCF) iterative proce-
dure followed by the calculation of the electrostatic energy of the
system from the charge–charge, charge–dipole, and dipole–dipole
interactions, representing a bottleneck associated with the demand-
ing computational time. To reduce computation, Wang et al. pro-
posed the iAMEOBA [113] approach with induced dipoles initially
set to zero such that the response of induced dipoles to the perma-
nent electrostatics has no mutual induction, thereby avoiding the
iterative SCF step. Recently, Albaugh et al. developed a new
approach (iEL/0-SCF) [114], based on iEL/SCF Lagrangian
scheme [115], from which the auxiliary induced dipoles serve as
initial guesses for the real induced dipoles and stay close to the
Born–Oppenheimer surface to achieve a SCF-less calculation. An
interesting alternative has been introduced by Brooks and cow-
orkers in which the induced dipoles are treated using the perturba-
tion theory [116] and the multipoles are treated using spherical
harmonics [117]. This model, termed MPID, was recently shown
to be equivalent to the Drude model in a study in which the Drude
parameters were mapped onto the MPID formalism [118].
3.3
Classical Drude
Oscillator Model
The classical Drude oscillator model is also referred to as the Shell
or charge-on-spring model. In the Drude oscillator model, explicit
polarization is introduced by attaching a charged auxiliary particle
(the Drude oscillator or particle) with a harmonic spring to the core
(i.e., nuclei) of each polarizable atom, which allows the atomic
dipoles to adjust in response to the surrounding electronic ﬁeld
by simply minimizing the position of the Drude particles with the
atomic core ﬁxed (Fig. 1). This is analogous to the SCF calculation
in the context of the Born–Oppenheimer approximation. The elec-
trostatic energy is then obtained from the Coulombic interactions
between the atomic and Drude charges (Eq. 4). Accordingly, the
Drude oscillator model retains many of the pair-wise features of the
functional forms as those in the additive models (Eq. 1), but the
potential energy function is modiﬁed to further include the energy
results from the Drude particles thereby explicitly treating polariz-
ability. In Eq. 4, qi and qj are the charges on atoms i and j; qD,i and
28
Fang-Yu Lin and Alexander D. MacKerell Jr

qD,j are charges on the respective Drude particles; ri, rj, rD,i, and rD,
j are their locations.
Eelec,Coulombic ¼
1
4πD
X
i6¼j
qiq j
ri  r j

 þ
X
i6¼j
qD,iq j
rD,i  r j


 
þ
X
i6¼j
qD,iqD,j
rD,i  rD,j


!
ð4Þ
In the Drude model, the isotropic atomic polarizability, α, is
deﬁned based on the magnitude of the charge on the Drude
particle, qD, and the force constant, KD, on the spring attaching
the Drude particle to the atomic core as shown in Eq. 5.
α ¼ qD
2
K D
ð5Þ
Thus, the value of α will determine the charge assigned to the
Drude particle (qD), and the total partial atomic charge on the atom
(qA) will be qA ¼ q  qD, where q is the charge assigned to the
atomic core. From this description, polarization is determined by a
pair of point charges (qA and qD) separated by a variable displace-
ment, d, between the Drude particle and the atomic core, which is
able to adjust in response to the electric ﬁeld, E, according to the
Eq. 6:
Fig. 1 Schematic of the Drude oscillator model. The addition of Drude particles to carbon (C) and oxygen
(O) atoms via harmonic springs with a force constant, KD, and the subsequent distribution of charge between
the atoms (qC and qO) and their respective Drude oscillators (qDC and qDO) are presented. Virtual particles to
mimic the lone-pairs on the oxygen atom are labeled “LPA” and “LPB” with the charge, qLPA and qLPB. The
anisotropic polarization tensor components on the oxygen are labeled as K D
11 and K D
22. The other tensor
component is orthogonal to K D
11 and K D
22 and is not shown
Force Fields for Small Molecules
29

d ¼ qDE
K D
ð6Þ
The induced atomic dipole, μ, will be calculated as
μ ¼ qD
2E
K D
ð7Þ
The electrostatic component of the potential energy function
therefore includes Coulombic electrostatic interactions between
atom-Drude and Drude-Drude pairs as shown in Eq. 4 above and
a harmonic self-polarization term, Uself, calculated as
U self ¼ K Dd2
ð8Þ
The resulting total potential energy function, U, in the polar-
izable force ﬁeld will become an extension of the additive energy
functional form with U calculated as
U r; d
ð
Þ ¼ U bond r
ð Þ þ U LJ r
ð Þ þ U elec r; d
ð
Þ þ U self d
ð Þ
ð9Þ
where Ubond indicates the bonded internal energy terms (e.g.,
bonds, angles, and dihedrals), ULJ is the LJ energy term, Uelec
represents all the Coulombic electrostatic interactions (e.g., inter-
actions between atom–atom, atom–Drude, and Drude–Drude
pairs), and the self-polarization Uself. The Drude particles in the
CHARMM Drude polarizable force ﬁeld are only associated with
nonhydrogen atoms, which has been shown to be sufﬁcient to
reproduce molecular polarizabilities and to minimize computa-
tional cost in the calculation of electrostatic interactions [119].
The representation of Uself in Eq. 8 treats polarization isotro-
pically, where KD is the scalar value of harmonic force constant. To
improve nonbond interaction as a function of orientation, the
polarization on the Drude particle can be treated anisotropically.
This is achieved by expanding the scalar KD to a tensor KD, as
shown in Eq. 10 such that the anisotropic form of Uself becomes
U self ¼ 1
2 K D
11d1
2 þ K D
22d2
2 þ K D
33d3
2


ð10Þ
where d1, d2, and d3 are the projections of the Drude particle-atom
displacement vectors on the orthogonal axes deﬁned based on the
local molecular frame, and KD is a tensor with off-diagonal ele-
ments set to zero. Additionally, lone pairs can be added to further
improve the description of electronic distribution around hydrogen
bond acceptor atoms (Fig. 1) [120]. The combination of aniso-
tropic polarization and lone pairs results in an improved description
of functional groups acting as hydrogen bond acceptors [120].
Another difference from the additive model is that the Drude
model includes explicit treatment of induced dipole–dipole inter-
actions for 1–2 and 1–3 atom pairs. This allows for better treatment
of molecular polarizabilities as ﬁrst introduced by Thole. However,
30
Fang-Yu Lin and Alexander D. MacKerell Jr

as the induced dipoles are treated as point charges that are in close
proximity (Fig. 2) and, therefore, not well modeled using Cou-
lomb’s law, those electrostatic interactions are screened by a Thole-
like screening function Sij [121]:
Sij rij


¼ 1 
1 þ ti þ t j


rij
2 αiα j

1=6
0
@
1
A
2
4
3
5exp  ti þ t j


rij
αiα j

1=6
2
4
3
5
ð11Þ
where rij is the distance between atoms i and j, αi and αj are
respective atomic polarizabilities, ti and tj are the respective atomis-
tic Thole screening factors that dictate the degree of scaling. The
use of atom-speciﬁc Thole screening factors along with the 1–2 and
1–3 interactions is particularly useful with respect to the reproduc-
tion of molecular polarizability tensors, as shown schematically in
Fig. 2.
Fig. 2 Schematic illustration of the directional response in the Drude oscillators model under an external
electric ﬁeld, E, due to the 1–2 dipole–dipole interactions caused by atom-Drude pairs with charges of
qA1-qDA1 and qA2-qDA2, respectively. (a) When E is perpendicular to the bond, the 1–2 dipoles damp each
other, decreasing the molecular polarizability response perpendicular to the bond. (b) When E is parallel to the
bond, the 1–2 dipoles enhance each other thereby increasing the molecular polarizability along the bond
Force Fields for Small Molecules
31

While the Drude model has performed well, accurately repro-
ducing QM and experimental target data in a variety of systems, it
has been observed that the hydration free energies were shown to
be overestimated compared to the experimental values. One expla-
nation for this is that the Lorentz-Berthelot combining rules [122]
(Eqs. 12 and 13) are inadequate to describe the LJ contributions to
the solvation energies.
Rmin,ij ¼ Rmin
2
, i þ Rmin
2
, j
ð12Þ
εij ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
εi  ε j
p
ð13Þ
To allow for a more accurate reproduction of hydration free
energies, the strategy of using “atom pair-speciﬁc LJ parameters”
[123] between the water oxygen and selecting solute nonhydrogen
atoms was developed to override the standard LJ combining rules.
Thus, Rmin,ij and εij of an atom pair are not assigned through the
combining rules (Eqs. 12 and 13), but they are speciﬁed directly
according to the atom pair-speciﬁc LJ parameters (NBFIX in
CHARMM nomenclature). By utilizing the atom pair-speciﬁc LJ
parameters, the hydration free energies of the molecules could be
improved without affecting pure solvent properties and other
molecular interactions.
One limitation of the Drude model, as well as other polarizable
models, is the possibility of over-polarization. With the Drude
model, this occurs when the Drude particle is displaced far from
its parent atomic core, resulting in unphysically large interaction
energies, leading to the so-called polarization catastrophe. To pre-
vent this from happening, a “hard-wall constraint” [124] is intro-
duced to prevent Drude particles from moving further from a
speciﬁc displacement, typically is 0.2 A˚ , from the atomic core.
The Drude model also includes an additional anharmonic term
representing a restoring force to prevent excessively large excur-
sions of the Drude particle away from the atom [47, 125], thereby
reducing the polarizability of atoms at high electric ﬁeld. This latter
term is not commonly used in the current version of the Drude
force ﬁeld.
As in other polarizable models, the calculation based on the
SCF scheme would be time-consuming in simulations. To perform
simulations more efﬁciently, Lamoureux and Roux developed an
extended Lagrangian approach for the Drude model [126], in
which each Drude particle is given a small mass (0.4 amu) that is
subtracted from the parent atom (i.e., total mass of the Drude–a-
tom pair is still equal to the atomic mass). As the Drude particles are
now included in the equations of motion, typically a 1 fs time step is
used in simulations to prevent large forces associated with the
Drude particles, which would be an inherent limiting factor with
respect to the computational time. Drude polarizable simulations
32
Fang-Yu Lin and Alexander D. MacKerell Jr

using the extended Lagrangian are approximately a factor of
2 slower due to the additional nonbond calculations versus an
additive model, with an additional factor of 2 present if integration
time steps of 1 fs versus 2 fs are used for the Drude and additive
models, respectively.
3.4
Scope
of the Most Widely
Used Polarizable Force
Fields
The current scope of the most widely used polarizable force ﬁelds is
summarized in Table 1. The AMBER polarizable force ﬁeld has
been developed for the study of ions [96, 98], neat liquid proper-
ties of water methanol, and N-methylacetamide [97]. A more
extended force ﬁeld, AMBER ff02, was released including para-
meters for acetamide, dipeptides, and nucleic acid bases, and it is
available for simulations on proteins/peptides and nucleic acids
[99, 100]. CHARMM ﬂuctuating charge (FQ) force ﬁeld has
been developed for several biomolecules including proteins
[92, 93], lipids [132], and selected carbohydrates [133]. In addi-
tion, this force ﬁeld has been applied to the study of ligand binding
to lysozyme [158], ion solvation [134], and lipid bilayer perme-
ability [159]. Parameters for drug-like small molecules have not
been reported with the AMBER or CHARMM FQ models.
AMOEBA
has
been
developed
for
water
[110],
ions
[130, 131], and a fully functional model for protein [112].
Recently, nucleic acid parameters for the AMOEBA force ﬁeld
have been published [127] and are available with the rest of the
Table 1
The scope of available polarizable force fields
Force ﬁelds
Polarizable models
Scope of biomolecules
AMBER ff02
Induced dipole
Proteins [99, 100]
Nucleic acids [99]
Atomic ions [96, 98]
AMOEBA
Induced dipole
Proteins [112, 127]
Nucleic acidsa
Small molecules [128, 129]
Atomic ions [130, 131]
CHARMM-FQ
Fluctuating charge
Proteins [92, 93]
Lipids [132]
Carbohydrates [133]
Atomic ions [134]
CHARMM Drude
Classical Drude Oscillator
Proteins [135]
Nucleic acids [136–139]
Lipids [124, 140]
Carbohydrates [141–144]
Small molecules [119, 145–157]
Atomic ions [47]
aParameters have not been reported in the literature, but they are available through the website http://dasher.wustl.edu
Force Fields for Small Molecules
33

AMOEBA force ﬁeld in the Tinker package [160] via the website
http://dasher.wustl.edu. Currently, AMOEBA polarizable para-
meters of several small organic compounds containing biologically
important functional groups have been presented, including
alkanes, alcohols, amines, sulﬁdes, aldehydes, carboxylic acids,
amides, aromatics [128], and chloromethanes [129]. While para-
meters have not been reported for simulations on carbohydrates or
lipids, AMOEBA has already demonstrated its success in various
molecular systems where polarization is critical, including the study
of liquid water [110, 161], ion solvation properties [130, 131,
162], computational X-ray crystallography [163], ligand-binding
[164], N-methyl-acetamide dimers, alanine dipeptide conforma-
tional study [165], and binding free energy calculations for small
ligands [55, 56, 166].
MacKerell, Roux, and coworkers have developed the Drude
polarizable force ﬁeld for a range of molecular systems and atomic
ions. Parameters have been published for water models [167, 168],
ions [47], and a range of small molecules representative of
biological macromolecules [119, 145–156] and, more recently, of
halogenated species [157]. Force ﬁeld parameters have also been
published for biomolecules including carbohydrates [141–144],
proteins
[135],
DNA
[136–139],
and
selected
lipids
[124, 140]. These biomolecular parameters have been used in a
number of application studies, showing the role of explicit treat-
ment of electronic polarization in the cooperativity of both peptide
folding and peptide unfolding [169] as well as base ﬂipping in DNA
[170]. Other interesting results include the sensitivity of the solu-
tion structure of DNA to different types of monovalent ions
[171]. Current efforts on the Drude biomolecular force ﬁeld
involve additional reﬁnements, which are anticipated to yield
improved models of increased accuracy that will yield an optimized
picture of the physical properties of macromolecules and their
relationship to their structure, dynamics, and function. A more
detailed description of the small molecules treated by the Drude
force ﬁeld is given below.
4
Current Status of Drude Polarizable Force Field for Small Organic Molecules
In the following sections, a detailed description of the various
classes of small molecules in the Drude force ﬁeld that have been
developed to date will be presented. These molecules were primar-
ily selected as the basis for extension of the force ﬁeld to larger
entities, such as protein [135], nucleic acid [44, 136, 137, 139],
lipid [124, 140], and carbohydrate [143]. More recent develop-
ments of Drude parameters for halogens combined with the small
molecules represent the initial molecular building blocks that will
lay the foundation for a Drude General Force Field (DGenFF) for
molecules of medicinal chemistry interest.
34
Fang-Yu Lin and Alexander D. MacKerell Jr

4.1
Alkanes
Parametrization of alkanes are essential, as they serve as model
compounds for the aliphatic groups, which are major components
of biological macromolecules, including lipid tails, amino acid side
chains, and the majority of carbohydrates. While additive models
have been developed in a wide range of force ﬁelds and have shown
great utility in studying a variety of systems, the additive models
yield a systematic underestimation of alkane dielectric constants,
which is due to their inability to account for the high-frequency
electronic oscillating ﬁeld that contributes to the optical dielectric
constant, leading to dielectric constants for pure alkanes of approx-
imately 1 (see Note 3). Accurate treatment of the dielectric con-
stants, which should be approximately 2, is critical in simulating
biomolecular systems given that the free energy of solvation scales
with (1  1/ε), where ε is the dielectric constant of the environ-
ment. Thus, even a small underestimation of alkane dielectric con-
stants would cause a signiﬁcant impact on the treatment of
solvation in nonpolar environments, particularly for compounds
that need to pass through the hydrophobic region of lipid bilayers
when they are crossing the membrane. Accordingly, an accurate
force ﬁeld for alkanes that is able to properly treat the dielectric
constant is required. The Drude polarizable model for alkanes
including ethane, propane, butane, isobutene, and pentane meets
this need, as the dielectric constants of those pure liquids are in
good agreement with the experimental values [145].
When developing the Drude alkane electrostatic parameters,
the ability to readily transfer those parameters to more complex
molecules was considered. Transferability was insured by imposing
a restraint on the charges of carbons (qC) and hydrogens (qH) based
on qC ¼ xqH, where x is the number of hydrogen atoms, such that
the charges on CHx groups would be neutral. A polarizability
scaling factor of 1, which is different from the polarizable scaling
factors (0.70–0.85) for other small molecules [119, 146–155], was
in good agreement with experimental values. The model was able
to reproduce experimental enthalpies of vaporizations (ΔHvap),
molecular volumes (Vm), hydration free energies (ΔGhydr), NMR
relaxation times, and particularly the static dielectric constants. The
accurate reproduction of the static dielectric constants was an
important outcome. For example, the Drude polarizable alkane
model produced signiﬁcantly better agreements with experimental
dielectric constants that were ranging from 1.71 to 2.13 for alkane
series, whereas the additive model produced nearly uniform values
of 1.0 regardless of different alkyl chain length.
The Drude alkane force ﬁeld was originally parametrized by
including long-range LJ interactions using an isotropic correction
for pure solvents and in aqueous solution [124]. However, isotro-
pic treatment of long-range LJ interactions is inappropriate for
modeling anisotropic systems such as alkane/air interfaces [172],
which becomes a signiﬁcant problem in modeling the structural
Force Fields for Small Molecules
35

and thermodynamic properties of lipids. To overcome this limita-
tion, Leonard et al. [173]. have applied the Lennard-Jones particle-
mesh Ewald (LJ-PME) method [174] (see Note 4) to better model
the LJ contribution in anisotropic systems. Their results showed
the Drude polarizable model with LJ-PME to have improved
agreement across various experimental quantities such as density,
isothermal compressibility, surface tension, viscosity, translational
diffusion, and 13C T1 relaxation times of long-chain pure alkanes.
Moreover, the Drude results are systematically closer to the experi-
ment results than the CHARMM36 additive counterpart. Accord-
ingly, the updated polarizable model for these alkanes is expected to
improve the accuracy of modeling the hydrophobic environments,
such as lipid bilayers.
4.2
Ethers
Ether moieties are substructures of important functional groups in
biological molecules, such as furanoses, including ribose and
deoxyribose, and pyranoses. Accordingly, the accuracy of the
ether parameters lays the foundation for extending the polarizable
force ﬁeld to carbohydrates and nucleic acids. Ethers are generally
considered as relatively nonpolar due to the nonpolar aliphatic
groups, while the polar oxygen atoms are capable of participating
in hydrogen bonds and ion coordination. Therefore, the develop-
ment of the force ﬁeld for ethers requires attaining the right balance
between dispersion, electrostatic, and repulsive forces. Vorobyov
et al. developed the initial Drude polarizable model for linear and
cyclic ethers [150]. The developed ethers includes tetrahydrofuran,
tetrahydropyran, dimethyl ether, methyl ethyl ether, diethyl ether,
and 1,2-dimethoxyethane. To ensure transferability, the parameters
for cyclic ethers were developed ﬁrst, and subsequently transferred
to a series of linear molecules. One of the signiﬁcant outcomes of
the ether polarizable model was the ability to more accurately treat
the polar character in different environments. In the additive
model, the dipole distributions are nearly identical from the gas
to aqueous phase for THF and DEE (~2 D and 1.8 D, respectively).
In contrast, the differences of dipole distributions in the different
environments in the polarizable model are more signiﬁcant, with an
obvious increase from the gas to aqueous phase. These observations
indicated that the polarizable models are more responsive to the
polarity of the environment. Another key outcome in the polar-
izable model for ethers is their agreement in relative energies of
various conformations and their corresponding dipole moments
[147], which reﬂects the ability of the polarizable model to accu-
rately model the electronic properties in various conformations.
However, the dielectric constants of the neat liquid cycloalkanes
and ethers were still not optimal and systematically underestimated,
with an average percentage difference of 13% compared to the
experimental values. As a result, Baker et al. reparametrized the
model including the use of atom-type-dependent Thole screening
36
Fang-Yu Lin and Alexander D. MacKerell Jr

factors (t, in Eq. 11) [119] and applied a scaling factor of 0.85 for
the gas molecular polarizabilities. The new model signiﬁcantly
improved the reproduction of the dielectric constants, while main-
taining good agreement of properties from the previous model as
well as other experimental and QM data, reinforcing the sensitivity
of the atomic polarizability parameters.
4.3
Alcohols
Alcohol moieties are functional groups that are ubiquitous in
biological molecules, such as amino acids (e.g., serine, threonine,
and tyrosine), nucleic acids (e.g., 20- and 30-hydroxyl groups),
carbohydrates, and lipids. As alcohols consist of both polar and
nonpolar components, the hydration of alcohols involves hydro-
phobic and hydrophilic interactions. Therefore, proper treatment
of electronic polarization is required to ensure the accurate descrip-
tion of the balance of the hydroxyl–water and aliphatic–water inter-
actions. While a number of nonpolarizable models for alcohol-
containing molecules are available, the gas-phase dipole moment
of alcohols were overestimated by approximately 40% to implicitly
treat the condensed phase polarization effects [149]. A polarizable
alcohol force ﬁeld using the Drude oscillator model was initially
presented by Noskov et al. [146] to elucidate the hydrophobic
hydration in water–ethanol mixtures. Subsequently, a more
generalized parameter set for alcohols was developed by Anisimov
et al., including a larger series of primary and secondary alcohols
(e.g., methanol, ethanol, 1-propanol, 1-butanol, secondary alco-
hols, 2-propanol, and 2-butanol.) [149]. The updated model
added lone pairs on the hydroxyl oxygen atom and introduced
atom pair-speciﬁc LJ parameters for alcohol oxygen atoms with
water oxygen atoms. The polarizable model developed based on
the training set molecules was found to present a signiﬁcant
improvement over the additive model in all cases for ΔHvap and
ΔGhydr and dielectric constants. Notably, the Drude polarizable
model has shown the ability to capture the response of the molecu-
lar dipole moments in response to different environments. The
dipole moments of ethanol and 2-propanol shifted from low dipole
moments in the gas phase to much higher values when solvated in
aqueous solution, in agreement with previous theoretical calcula-
tions [175], whereas the dipole moments obtained from the addi-
tive model were largely unchanged in the simulations in gas phase,
pure solvent, and aqueous systems. Moreover, small variations of
the dipole moment of water molecules hydrating alcohols were
observed as a function of distance, showing that the intermolecular
interactions between water and alcohols would be dictated by their
mutual polarization. These results clearly indicate that the polar-
izable model is more applicable in modeling the dynamics of mole-
cules containing hydroxyl group in different environments than
additive force ﬁelds.
Force Fields for Small Molecules
37

4.4
Amides
As amide moieties comprise protein backbones and the side chain
of asparagine and glutamine, as well as being components of car-
bohydrates, an accurate model for amide group is critical for the
development of a polarizable protein force ﬁeld, motivating efforts
to
parametrize
amide-containing
model
compounds
[119, 154]. The initial Drude polarizable model for amides repro-
duced a wide range of gas-phase QM and condensed-phase experi-
mental data. Particularly, the amide polarizable model was able to
reproduce the high dielectric of neat N-methylacetamide (NMA,
100 at 373 K), whereas the additive model yielded a 70% under-
estimation of the dielectric constant, indicating that the mean-ﬁeld
approximation in the additive model is limited to account for the
induced electronic polarization [176]. Two factors could account
for this large dielectric constant in the polarizable model. One is the
increased average NMA dipole moment in the neat liquid than in
the gas phase. The other is the intermolecular hydrogen bonding
(Fig. 3) that enhances the orientational alignment of the molecular
dipoles. This is consistent with the calculated Kirkwood GK factor
[177] (see Note 5) that GK was considerably larger in the polar-
izable model (GK ¼ 4.6) than in the additive model (GK ¼ 3.0).
This result indicates that the inclusion of explicit electrostatic
polarization is expected to lead to a greater accuracy in modeling
of hydrogen bonding interactions. However, the early model for
amide-containing compounds primarily focused on neat liquid
simulation properties. An updated model for NMA and acetamide
[154] was presented to further assess the properties of the amide
series in aqueous solution in greater detail. While the value of the
dielectric constant was signiﬁcantly smaller than the previously
reported value, there was a better balance of the solute–solute,
Fig. 3 Representative hydrogen bonding conﬁgurations from neat liquid
simulations of NMA and acetamide. Reprinted with permission from ref.
[119]. Copyright (2017) American Chemical Society
38
Fang-Yu Lin and Alexander D. MacKerell Jr

solvent–solute, and solvent–solvent interactions in the updated
models. Such a balance is a crucial factor for applying the model
in the Drude polarizable protein force ﬁeld, as the relative stability
of helical versus sheet versus random coil conformations and pro-
tein conformational dynamics [178] are related to the balance of
protein intramolecular and protein–solvent interactions.
4.5
Aromatic
and Heteroaromatic
Systems
Aromatic rings are commonly used in drug design, as they make
hydrophobic contributions to binding, allowing them to partici-
pate in hydrogen bonding and are able to participate in π interac-
tions [179]. Therefore, the development of an aromatic polarizable
force ﬁeld would be useful in drug-like molecules [180] as well as
serve as building blocks for parametrizing phenylalanine and tyro-
sine in the development of protein force ﬁeld and the nucleic acid
bases. Benzene and toluene parameters were initially developed
[151] followed by parameters for heteroaromatics [151] and sub-
sequently nucleic acid bases [136–139]. While many of the
dynamic features of the benzene and toluene liquids are similar
between the polarizable and additive models, the polarizable
model is more accurate in reproducing the experimental dielectric
constants. The additive force ﬁeld dielectric for benzene was close
to 1.0, considerably lower than the experimental value of 2.3 for
benzene and 2.4 for toluene, whereas dielectric constants obtained
from the Drude model yielded better agreement. In parametrizing
aromatic molecules, one important feature to be reproduced is the
interactions between the π electron system on the aromatic rings
and water (see Note 6) [181, 182]. From the radial and spatial
distribution functions of aqueous solutions of benzene and tolu-
ene, subtle differences of hydration shells were observed between
the two models. The Drude polarizable model produced a more
deﬁned population of water molecules at 3.5 A˚ above the ring than
the additive model, which indicates that the Drude polarizable
model is more capable of capturing the out of plane π-stacking
interaction between the aromatic ring and water, providing a
more physical description of hydration of aromatic moieties. Fur-
ther improvements in the polarizable benzene model were made by
Esam et al. with respect to cation–π interactions [183]. In their
study, QM interaction orientations and energies were better repro-
duced by introducing a virtual particle in the center of the benzene
ring with the use of atom pair-speciﬁc LJ parameters.
A series of heterocyclic aromatic compounds (e.g., pyrrole,
imidazole, pyridine, pyrimidine, indole, and purine) based on
Drude polarizable model were developed [151]. The inclusion of
virtual sites that represent in-plane lone pairs on nitrogen atoms
along with anisotropic polarizabilities yielded improved agreement
with the QM polarization response as a function orientation as
determined using a perturbing ion. The resulting parameters
achieved good agreement for pyridine and pyrrole dielectric
Force Fields for Small Molecules
39

constants and were validated against additional experimental data
such as diffusion constants, heat capacities, and isothermal com-
pressibilities, indicating the ability of the model to be used for the
studies of a variety of heterocycles. Extension of the model to
nucleic acid bases was subsequently undertaken, although addi-
tional optimization of the base parameters was carried out as part
of the development of the Drude DNA force ﬁeld [136–139].
4.6
Sulfur-
Containing
Compounds
Sulfur-containing scaffolds exist in a broad range of pharmaceuti-
cals and natural products [184–186] as well as in many biological
systems such as proteins (e.g., methionine and cysteine). As sulfur
atoms are highly polarizable, additive models are signiﬁcantly lim-
ited to simultaneously describe the electronic response of sulfur-
containing molecules in both polar and nonpolar environments.
The polarizable force ﬁeld for sulfur-containing compounds was
derived [153], providing a more accurate representation of chemi-
cal groups containing sulfurs, including methanethiol, ethanethiol,
propanethiol, ethyl methyl sulﬁde, and dimethyl disulﬁde. In para-
metrizing this model, anisotropic polarizabilities were applied to
the sulfur atoms, yielding good agreement with QM water and ion
interaction energies as a function of angle or distance. Different
polarizability scaling factors were used among the sulfur-containing
compounds, indicating that the electronic properties of sulfur are
sensitive to its chemical environment. A scaling factor of 0.7 was
used for thiols to yield good agreement with experimental dielectric
constants, while 0.85 was applied to dimethyl disulﬁde. For ethyl
methyl sulﬁde, which models the parameters used in methionine, a
scaling factor of 0.6 was needed to reproduce condensed-phase
properties including the dielectric constant and the gas-phase
dipole moment. Atom pair-speciﬁc LJ parameters [123] between
sulfur and water oxygen atoms were required to improve the aque-
ous solvation free energies. The resulting Drude polarizable model
demonstrates that the explicit treatment of electronic polarization
improves the accuracy of the force ﬁeld in reproducing experimen-
tal properties such as ΔHvap, Vm, molecular interactions with water,
ΔGhydr, and dielectric constants, leading to a considerable improve-
ment over the additive model for the same sulfur-containing
compounds.
4.7
Ketones
and Aldehydes
While ketones and aldehydes are rarely present in drug molecules
[187], they are functional groups that occur in acyclic carbohy-
drates in biological systems. The Drude polarizable force ﬁeld for
aliphatic ketones and aldehydes (e.g., acetaldehyde, propionalde-
hyde, butaryaldehyde, isobutaryaldehyde, acetone, and butanone)
has been developed [155]. The model was then transferred to
larger acyclic sugars such as D-allose and D-psicose. The developed
parameters for ketones and aldehydes reproduced properties in
good agreement with QM and experimental target data. Notably,
40
Fang-Yu Lin and Alexander D. MacKerell Jr

the Drude–water interaction energies and distances were in better
agreement with the QM data than the additive model, which could
be attributed to the lone pairs added on the carbonyl oxygen. The
resulting polarizable force ﬁeld yielded different dipole moments in
different environments, with an increase of the dipole moments
upon going from the gas phase to pure solvent to aqueous phase,
consistent with the hydrogen bonding between the monomers in
the pure solvent and with water in aqueous solution. Accordingly, it
is clear that the treatment of polarization response is important for
more accurately simulating systems where molecular species would
encounter environments of hydrogen bond interactions or varying
polarities.
4.8
Halogenated
Ethanes and Benzenes
Halogenated molecules have been widely used in drug develop-
ment [188, 189], as they have been shown to increase selectivity
and binding afﬁnity of inhibitors [190, 191]. Notably, halogens
serve as both hydrogen bond acceptors (HBA) [192–196] and
halogen bond (XB) donors [190–192], both of which have been
reported to contribute to ligand–protein interactions experimen-
tally [189, 197–201]. The dual roles of halogens result from their
anisotropic electron distribution when the halogen (X) is covalently
bonded to a carbon atom (C), resulting in the shift of the pz-orbital
on halogens to participate in the formation of the C-X covalent
bond. This leads to an electron diminished region on the outer side
of the halogen linear to the C-X bond, yielding a slightly positive
potential known as a σ-hole [192, 202, 203], which is able to
favorably
interact
with
hydrogen
bond
acceptors
(HBA)
[190–192, 204]. Simultaneously, the valence electrons on the per-
pendicular px and py atomic orbitals of halogens remain occupied
yielding an electronegative potential, allowing halogens to interact
with hydrogen bond donors (HBD) [192]. Such X-HBD interac-
tions have been reported to be more favorable than halogen bonds
and of similar strength as canonical hydrogen bonds [205]. Nota-
bly, the vdW surface of the halogen becomes asymmetric due to the
shifted electron distribution, resulting in a shorter vdW surface on
the halogen linear to the C-X covalent bond [206]. Thus, accurate
reproduction of XB and X-HBD interactions was emphasized in
parametrization to better modeling such important feature in
halogens.
The Drude force ﬁeld was able to reproduce QM molecular
dipole moments and polarizabilities, as well as experimental ΔHvap,
Vm, ΔGhyd, and dielectric constants for the halogen model com-
pounds [157]. As expected, the halogen polarizable model has the
ability to treat the polar character in different environments as
shown in Fig. 4. The dipole distributions of chlorobenzene
(CHLB) and bromobenzene (BROB) from the Drude model
Force Fields for Small Molecules
41

both obviously increase from the gas to aqueous phase, whereas the
dipole distributions from the additive CGenFF model are nearly the
same in the different phases, indicating the lack of polarization
response. Similar to other small molecules, the polarizable model
was able to reproduce dielectric constants. The halogen polarizable
model yielded a signiﬁcant improvement over the additive model
with an average percent difference of only 1% of the experiment
results compared to the average percent difference of 33%
obtained from the additive halogen model. This improvement of
the dielectric constants from the polarizable model is attributed to
the explicit treatment of polarizability as previously discussed
[44, 145, 207].
One important outcome of the developed halogen model is
better treatment of the anisotropic charge distribution and shape of
the halogens, which were modeled by inclusion of a virtual particle
along the C-X covalent bond, atom pair-speciﬁc LJ parameters
(NBFIX parameters) on the halogen Drude particle-water hydro-
gen pairs and on halogen-water oxygen pairs [157]. Notably, the
use of the atom pair-speciﬁc LJ parameters signiﬁcantly improved
the agreement of the Drude model with the QM interaction energy
surfaces for both XB and X-HBD interactions, further indicating its
ability to more accurately model the asymmetry of the halogen
atoms. Such strategy also resulted in better reproduction of experi-
mental ΔGhydr than the additive halogen model in CGenFF
[208]. Accordingly, the resulting polarizable force ﬁeld is expected
to be applicable in CADD involving halogenated derivatives as well
as simulation studies of halogens in a range of chemical systems.
Fig. 4 Dipole moment distributions of chlorobenzene (CHLB) and bromobenzene (BROB) in the gas phase
(Gas), in pure solvents (Pure), and in aqueous solution (Aqueous), respectively for both the CGenFF (dotted
lines) and Drude (solid lines) polarizable force ﬁelds
42
Fang-Yu Lin and Alexander D. MacKerell Jr

5
Conclusion
Force ﬁelds for small molecules based on additive models have been
available for a number of years and shown success in drug design as
well as other biochemical and biophysical studies. However, limita-
tion of additive models occurs due to the lack of explicit polariza-
tion, particularly in cases where polarizable charged groups or
atoms, such as ions, are involved, which would strongly polarize
their coordinating ligands. In addition, the impact of polarization
on more accurate treatment of nonpolar moieties such as those in
the interior of membranes has been noted. Toward overcoming this
limitation, parameters for organic small molecules based on polar-
izable force ﬁelds have started to be developed, dominated by the
AMOEBA and Drude models as well as the work of Dang and
coworkers [103–105, 209–214]. This chapter focused on the
small-molecule polarizable force ﬁelds based on the classical
Drude oscillator model, which utilizes Drude oscillators on non-
hydrogen atoms to generate the induced dipole in the context of an
intuitive physical picture to model the electronic distribution. In
practical aspects, the Drude model has advantages over other polar-
izable models, as the functional forms is similar to those in the
additive model, facilitating its implementation in multiple simula-
tion
packages,
including
CHARMM
[215–217],
NAMD
[218, 219], ChemSell QM/MM [220], OpenMM [221], and
GROMACS [222]. Currently, the CHARMM Drude polarizable
force ﬁeld for small molecules is still expanding. For example, the
development of parameters for halogen-containing molecules
greatly expand the range of chemical space covered by the Drude
force ﬁeld relevant to medicinal compounds [157]. Similarly to the
CGenFF force ﬁeld [13] that is a part of the CHARMM all-atom
additive biological force ﬁeld, efforts are ongoing toward the devel-
opment of a Drude General Force Field (DGenFF) that will cover a
wide range of chemical groups in drug-like molecules. In the end,
the polarizable force ﬁeld for these molecules will be applicable in
chemical and biophysical studies as well as be able to be useful for
ligands in the study of computer-aided drug design.
6
Notes
1. Electronegativity is the attraction of an atom for electrons.
Hardness is the work needed to transfer charge between atoms.
2. The total electric ﬁeld in induce dipole model is determined
self-consistently via an iterative procedure that minimizes the
polarization energy via optimization of the atomic dipoles with
the atomic nuclei ﬁxed or via the extended Lagrangian method
in the context of MD simulations [115, 223, 224].
Force Fields for Small Molecules
43

3. The static dielectric constant ε is calculated from the dipole
moment ﬂuctuations of the entire simulation system according to
ε ¼ ε1 þ
4π
3 V
h
iK BT
M 2

	
 M 2

	


where M is the total dipole moment of the cubic simulation
system, hVi is the average volume of the cubic unit cell, and ε1
is the high-frequency optical dielectric constant, which was
estimated from the Clausius-Mossotti equation [225].
4. Lennard-Jones particle-mesh Ewald (LJ-PME) method [174]
extends the particle-mesh Ewald (PME) method [226, 227] to
long-range LJ interactions. LJ-PME is suitable for use with
anisotropic systems such as lipid bilayers and monolayers.
5. The Kirkwood factor (GK) [177] is a measure of the orienta-
tional correlation with molecular dipoles. Conﬁgurations that
have parallel dipole alignment lead to GK > 1, and for uncorre-
lated dipoles, GK ¼ 1. Therefore, that larger GK indicates a
greater degree of cooperative dipole alignment.
6. The π electron system on the aromatic rings results in a negative
partial charge in the center of the ring, such that the faces of the
benzene ring are able to act as hydrogen bond acceptors
[181, 182].
Acknowledgments
This work was supported by National Institutes of Health grants
GM131710. The University of Maryland Computer-Aided Drug
Design Center and XSEDE are acknowledged for their generous
allocations of computer time.
Conﬂict of Interest: ADM is co-founder and CSO of SilcsBio LLC.
References
1. Durrant JD, McCammon JA (2011) Molecu-
lar dynamics simulations and drug discovery.
BMC Biol 9:71
2. Bernard D, Coop A, MacKerell AD Jr (2003)
2D
conformationally
sampled
pharmaco-
phore: a ligand-based pharmacophore to dif-
ferentiate δ opioid agonists from antagonists.
J Am Chem Soc 125:3101–3107
3. Bernard D, Coop A, MacKerell AD Jr (2005)
Conformationally
sampled
pharmacophore
for peptidic δ opioid ligands. J Med Chem
48:7773–7780
4. Bernard D, Coop A, MacKerell AD Jr (2007)
Quantitative
conformationally
sampled
pharmacophore for δ opioid ligands: reevalu-
ation of hydrophobic moieties essential for
biological
activity.
J
Med
Chem
50:1799–1809
5. Shim J, MacKerell AD Jr (2011) Computa-
tional ligand-based rational design: role of
conformational sampling and force ﬁelds in
model development. Med Chem Commun
2:356–370
6. Shim J, Coop A, MacKerell AD Jr (2011)
Consensus 3D model of μ-opioid receptor
ligand efﬁcacy based on a quantitative confor-
mationally sampled pharmacophore. J Phys
Chem B 115:7487–7496
44
Fang-Yu Lin and Alexander D. MacKerell Jr

7. Kuntz ID (1992) Structure-based strategies
for
drug
design
and
discovery.
Science
257:1078–1082
8. Anderson
AC
(2003)
The
process
of
structure-based
drug
design.
Chem
Biol
10:787–797
9. Sliwoski G, Kothiwale S, Meiler J, Lowe EW
(2014) Computational methods in drug dis-
covery. Pharmacol Rev 66:334–395
10. De Vivo M, Masetti M, Bottegoni G, Cavalli
A (2016) Role of molecular dynamics and
related methods in drug discovery. J Med
Chem 59:4035–4061
11. Jorgensen WL, Maxwell DS, Tirado-Rives J
(1996) Development and testing of the OPLS
all-atom force ﬁeld on conformational ener-
getics and properties of organic liquids. J Am
Chem Soc 118:11225–11236
12. Harder E, Damm W, Maple J et al (2016)
OPLS3: a force ﬁeld providing broad cover-
age of drug-like small molecules and proteins.
J Chem Theory Comput 12:281–296
13. Vanommeslaeghe K, Hatcher E, Acharya C
et al (2010) CHARMM general force ﬁeld
(CGenFF): a force ﬁeld for drug-like mole-
cules
compatible
with
the
CHARMM
all-atom additive biological force ﬁelds. J
Comput Chem 31:671–690
14. Vanommeslaeghe K, MacKerell AD Jr (2012)
Automation of the CHARMM general force
ﬁeld (CGenFF) I: bond perception and atom
typing. J Chem Inf Model 52:3144–3154
15. Vanommeslaeghe K, Raman EP, MacKerell
AD Jr (2012) Automation of the CHARMM
general force ﬁeld (CGenFF) II: assignment
of bonded parameters and partial atomic
charges. J Chem Inf Model 52:3155–3168
16. Yu W, He X, Vanommeslaeghe K, MacKerell
AD Jr (2012) Extension of the CHARMM
General Force Field to sulfonyl-containing
compounds and its utility in biomolecular
simulations. J Comput Chem 33:2451–2468
17. Wang J, Wolf RM, Caldwell JW, Kollman PA,
Case DA (2004) Development and testing of
a general amber force ﬁeld. J Comput Chem
25:1157–1174
18. Wang J, Wang W, Kollman PA, Case DA
(2006) Automatic atom type and bond type
perception in molecular mechanical calcula-
tions. J Mol Graph Model 25:247–260
19. Halgren TA (1996) Merck molecular force
ﬁeld. I. Basis, form, scope, parameterization,
and performance of MMFF94. J Comput
Chem 17:490–519
20. Halgren TA (1996) Merck molecular force
ﬁeld.
II.
MMFF94
van
der
Waals
and
electrostatic parameters for intermolecular
interactions. J Comput Chem 17:520–552
21. Halgren TA (1996) Merck molecular force
ﬁeld. III. Molecular geometries and vibra-
tional frequencies for MMFF94. J Comput
Chem 17:553–586
22. Halgren TA, Nachbar RB (1996) Merck
molecular force ﬁeld. IV. conformational
energies and geometries for MMFF94. J
Comput Chem 17:587–615
23. Halgren TA (1996) Merck molecular force
ﬁeld. V. Extension of MMFF94 using experi-
mental data, additional computational data,
and
empirical
rules.
J
Comput
Chem
17:616–641
24. Daura X, Mark AE, Van Gunsteren WF
(1998) Parametrization of aliphatic CHn
united atoms of GROMOS96 force ﬁeld. J
Comput Chem 19:535–547
25. Schuler LD, Daura X, van Gunsteren WF
(2001) An improved GROMOS96 force
ﬁeld
for
aliphatic
hydrocarbons
in
the
condensed
phase.
J
Comput
Chem
22:1205–1218
26. Oostenbrink C, Villa A, Mark AE, Van Gun-
steren WF (2004) A biomolecular force ﬁeld
based on the free enthalpy of hydration and
solvation: the GROMOS force-ﬁeld parame-
ter sets 53A5 and 53A6. J Comput Chem
25:1656–1676
27. Horta BAC, Fuchs PFJ, van Gunsteren WF,
Hu¨nenberger PH (2011) New interaction
parameters for oxygen compounds in the
GROMOS force ﬁeld: improved pure-liquid
and solvation properties for alcohols, ethers,
aldehydes,
ketones,
carboxylic
acids,
and
esters. J Chem Theory Comput 7:1016–1031
28. Horta BAC, Merz PT, Fuchs PFJ, Dolenc J,
Riniker
S,
Hu¨nenberger
PH
(2016)
A
GROMOS-compatible force ﬁeld for small
organic molecules in the condensed phase:
the 2016H66 parameter set. J Chem Theory
Comput 12:3825–3850
29. Malde AK, Zuo L, Breeze M, Stroet M,
Poger D, Nair PC, Oostenbrink C, Mark AE
(2011) An automated force ﬁeld topology
builder (ATB) and repository: version 1.0. J
Chem Theory Comput 7:4026–4037
30. van Aalten DMF, Bywater R, Findlay JBC,
Hendlich M, Hooft RWW, Vriend G (1996)
PRODRG, a program for generating molecu-
lar topologies and unique molecular descrip-
tors from coordinates of small molecules. J
Comput Aided Mol Des 10:255–262
31. Schu¨ttelkopf AW, van Aalten DMF (2004)
PRODRG:
a
tool
for
high-throughput
Force Fields for Small Molecules
45

crystallography of protein-ligand complexes.
Acta
Crystallogr
D
Biol
Crystallogr
60:1355–1363
32. Yesselman JD, Price DJ, Knight JL, Brooks
CL (2012) MATCH: an atom-typing toolset
for molecular mechanics force ﬁelds. J Com-
put Chem 33:189–202
33. Zoete V, Cuendet MA, Grosdidier A, Michie-
lin O (2011) SwissParam: a fast force ﬁeld
generation tool for small organic molecules.
J Comput Chem 32:2359–2368
34. Vanommeslaeghe K, MacKerell AD Jr (2015)
CHARMM additive and polarizable force
ﬁelds
for
biophysics
and
computer-aided
drug design. Biochim Biophys Acta Gen
Subj 1850:861–871
35. MacKerell AD Jr (2004) Empirical force ﬁelds
for biological macromolecules: overview and
issues. J Comput Chem 25:1584–1604
36. Lide DR (2008) CRC handbook of chemistry
and physics. CRC Press, Taylor & Francis,
Boca Raton, FL, p 2009
37. Gregory JK, Clary DC, Liu K, Brown MG,
Saykally RJ (1997) The water dipole moment
in water clusters. Science 275:814–817
38. Badyal YS, Saboungi M-L, Price DL, Shastri
SD, Haeffner DR, Soper AK (2000) Electron
distribution
in
water.
J
Chem
Phys
112:9206–9208
39. Huang J, Lopes PEM, Roux B, MacKerell AD
Jr (2014) Recent advances in polarizable force
ﬁelds for macromolecules: microsecond simu-
lations of proteins using the classical Drude
oscillator
model.
J
Phys
Chem
Lett
5:3144–3150
40. Lopes PEM, Guvench O, MacKerell AD Jr
(2015) Current status of protein force ﬁelds
for molecular dynamics. Methods Mol Biol
(Clifton, NJ) 1215:47–71
41. Shi Y, Ren P, Schnieders M, Piquemal J-P
(2015) Polarizable force ﬁelds for biomolecu-
lar modeling. In: Parrill AL, Lipkowitz KB
(eds) Reviews in computational chemistry,
vol 28. John Wiley & Sons, Inc, New York,
NY, pp 51–86
42. Xu P, Wang J, Xu Y et al (2015) Advancement
of polarizable force ﬁeld and its use for molec-
ular modeling and design. In: Advance in
structural
bioinformatics.
Springer,
Dor-
drecht, pp 19–32
43. Baker CM (2015) Polarizable force ﬁelds for
molecular dynamics simulations of biomole-
cules. Wiley Interdiscip Rev Comput Mol Sci
5:241–254
44. Lemkul JA, Huang J, Roux B, MacKerell AD
Jr (2016) An empirical polarizable force ﬁeld
based on the classical Drude oscillator model:
development history and recent applications.
Chem Rev 116:4983–5013
45. Archontis G, Leontidis E, Andreou G (2005)
Attraction of iodide ions by the free water
surface, revealed by simulations with a polar-
izable force ﬁeld based on Drude oscillators. J
Phys Chem B 109:17957–17966
46. Jungwirth P, Tobias DJ (2006) Speciﬁc ion
effects at the air/water interface. Chem Rev
106:1259–1281
47. Yu
H,
Whitﬁeld
TW,
Harder
E,
Lamoureux G, Vorobyov I, Anisimov VM,
MacKerell AD Jr, Roux B (2010) Simulating
monovalent and divalent ions in aqueous
solution using a drude polarizable force ﬁeld.
J Chem Theory Comput 6:774–786
48. Bauer BA, Ou S, Patel S (2012) Solvation
structure and energetics of single ions at the
aqueous liquid-vapor interface. Chem Phys
Lett 527:22–26
49. Allen TW, Andersen OS, Roux B (2004)
Energetics of ion conduction through the
gramicidin channel. Proc Natl Acad Sci U S
A 101:117–122
50. Allen TW, Andersen OS, Roux B (2006)
Molecular dynamics — potential of mean
force calculations as a tool for understanding
ion permeation and selectivity in narrow chan-
nels. Biophys Chem 124:251–267
51. Patel S, Davis JE, Bauer BA (2009) Exploring
ion permeation energetics in gramicidin a
using polarizable charge equilibration force
ﬁelds. J Am Chem Soc 131:13890
52. Harder E, MacKerell AD Jr, Roux B (2009)
Many-body polarization effects and the mem-
brane dipole potential. J Am Chem Soc
131:2760–2761
53. Bauer BA, Lucas TR, Meninger DJ, Patel S
(2011) Water permeation through DMPC
lipid bilayers using polarizable charge equili-
bration
force
ﬁelds.
Chem
Phys
Lett
508:289–294
54. Soto P, Mark AE (2002) The effect of the
neglect of electronic polarization in peptide
folding
simulations.
J
Phys
Chem
B
106:12830–12833
55. Jiao D, Golubkov PA, Darden TA, Ren P
(2008) Calculation of protein–ligand binding
free energy by using a polarizable potential.
Proc Natl Acad Sci 105:6290–6295
56. Jiao D, Zhang J, Duke RE, Li G, Schnieders
MJ, Ren P (2009) Trypsin-ligand binding free
energies from explicit and implicit solvent
simulations with polarizable potential. J Com-
put Chem 30:1701–1711
57. Shi Y, Zhu CZ, Martin SF, Ren P (2012)
Probing
the
effect
of
conformational
46
Fang-Yu Lin and Alexander D. MacKerell Jr

constraint on phosphorylated ligand binding
to an SH2 domain using polarizable force
ﬁeld
simulations.
J
Phys
Chem
B
116:1716–1727
58. Zhang J, Shi Y, Ren P (2012) Polarizable
force ﬁelds for scoring protein–ligand interac-
tions. In: Gohlke H (ed) Protein-ligand inter-
act. Wiley-VCH Verlag GmbH & Co. KGaA,
Weinheim, pp 99–120
59. de Courcy B, Piquemal J-P, Garbay C, Gresh
N (2010) Polarizable water molecules in
ligand-macromolecule
recognition.
Impact
on the relative afﬁnities of competing pyrro-
lopyrimidine inhibitors for FAK kinase. J Am
Chem Soc 132:3312–3320
60. Gresh N, de Courcy B, Piquemal J-P, Foret J,
Courtiol-Legourd S, Salmon L (2011) Polar-
izable
water
networks
in
ligand-
metalloprotein recognition. Impact on the
relative
complexation
energies
of
Zn-dependent phosphomannose isomerase
with D-mannose 6-phosphate surrogates. J
Phys Chem B 115:8304–8316
61. Best RB, Zhu X, Shim J, Lopes PEM, Mittal J,
Feig M, MacKerell AD Jr (2012) Optimiza-
tion of the additive CHARMM all-atom pro-
tein force ﬁeld targeting improved sampling
of the backbone φ, ψ and side-chain χ1 and
χ2 dihedral angles. J Chem Theory Comput
8:3257–3273
62. MacKerell
AD
Jr,
Banavali
NK
(2000)
All-atom empirical force ﬁeld for nucleic
acids: II. Application to molecular dynamics
simulations of DNA and RNA in solution. J
Comput Chem 21:105–120
63. Foloppe N, MacKerell AD Jr (2000) All-atom
empirical
force
ﬁeld
for
nucleic
acids:
I. Parameter optimization based on small
molecule and condensed phase macromolec-
ular target data. J Comput Chem 21:86–104
64. Denning EJ, Priyakumar UD, Nilsson L,
MacKerell
AD
Jr
(2011)
Impact
of
2-
’-hydroxyl sampling on the conformational
properties of RNA: update of the CHARMM
all-atom additive force ﬁeld for RNA. J Com-
put Chem 32:1929–1943
65. Hart K, Foloppe N, Baker CM, Denning EJ,
Nilsson L, MacKerell AD Jr (2012) Optimi-
zation of the CHARMM additive force ﬁeld
for DNA: improved treatment of the BI/BII
conformational equilibrium. J Chem Theory
Comput 8:348–362
66. Feller SE, Gawrisch K, MacKerell AD Jr
(2002) Polyunsaturated fatty acids in lipid
bilayers: intrinsic and environmental contri-
butions to their unique physical properties. J
Am Chem Soc 124:318–326
67. Klauda JB, Venable RM, Freites JA, O’Con-
nor JW, Tobias DJ, Mondragon-Ramirez C,
Vorobyov I, MacKerell AD Jr, Pastor RW
(2010) Update of the CHARMM all-atom
additive force ﬁeld for lipids: validation on
six
lipid
types.
J
Phys
Chem
B
114:7830–7843
68. Guvench O, Hatcher E, Venable RM, Pastor
RW, MacKerell AD Jr (2009) CHARMM
additive all-atom force ﬁeld for glycosidic lin-
kages between hexopyranoses. J Chem The-
ory Comput 5:2353–2370
69. Guvench O, Mallajosyula SS, Raman EP,
Hatcher E, Vanommeslaeghe K, Foster TJ,
Jamison
FW,
MacKerell
AD
Jr
(2011)
CHARMM additive all-atom force ﬁeld for
carbohydrate derivatives and its utility in poly-
saccharide and carbohydrate-protein model-
ing. J Chem Theory Comput 7:3162–3180
70. Klauda JB, Monje V, Kim T, Im W (2012)
Improving the CHARMM force ﬁeld for
polyunsaturated fatty acid chains. J Phys
Chem B 116:9424–9431
71. Guvench O, Greene SN, Kamath G, Brady
JW, Venable RM, Pastor RW, MacKerell AD
Jr (2008) Additive empirical force ﬁeld for
hexopyranose monosaccharides. J Comput
Chem 29:2543–2564
72. Hatcher E, Guvench O, MacKerell AD Jr
(2009) CHARMM additive all-atom force
ﬁeld for acyclic polyalcohols, acyclic carbohy-
drates and inositol. J Chem Theory Comput
5:1315–1327
73. Hatcher E, Guvench O, MacKerell AD Jr
(2009) CHARMM additive all-atom force
ﬁeld
for
aldopentofuranoses,
methyl-
aldopentofuranosides, and fructofuranose. J
Phys Chem B 113:12466–12476
74. Raman EP, Guvench O, MacKerell AD Jr
(2010) CHARMM additive all-atom force
ﬁeld for glycosidic linkages in carbohydrates
involving
furanoses.
J
Phys
Chem
B
114:12981–12994
75. Mallajosyula SS, MacKerell AD Jr (2011)
Inﬂuence
of
solvent
and
intramolecular
hydrogen bonding on the conformational
properties of O-linked glycopeptides. J Phys
Chem B 115:11215–11229
76. Mallajosyula SS, Guvench O, Hatcher E,
MacKerell AD Jr (2012) CHARMM additive
all-atom force ﬁeld for phosphate and sulfate
linked to carbohydrates. J Chem Theory
Comput 8:759–776
77. Mayne
CG,
Saam
J,
Schulten
K,
Tajkhorshid E, Gumbart JC (2013) Rapid
parameterization of small molecules using
Force Fields for Small Molecules
47

the force ﬁeld toolkit. J Comput Chem
34:2757–2770
78. Huang L, Roux B (2013) Automated force
ﬁeld parameterization for nonpolarizable and
polarizable atomic models based on ab initio
target
data.
J
Chem
Theory
Comput
9:3543–3556
79. Ross WS, Hardin CC (1994) Ion-induced
stabilization of the G-DNA quadruplex: free
energy perturbation studies. J Am Chem Soc
116:6070–6080
80. Cornell WD, Cieplak P, Bayly CI, Gould IR,
Merz KM, Ferguson DM, Spellmeyer DC,
Fox T, Caldwell JW, Kollman PA (1996) A
second generation force ﬁeld for the simula-
tion of proteins, nucleic acids, and organic
molecules.
J
Am
Chem
Soc
1995,
117:5179–5197. J Am Chem Soc 118:2309
81. Ha SN, Giammona A, Field M, Brady JW
(1988) A revised potential-energy surface for
molecular
mechanics
studies
of
carbohy-
drates. Carbohydr Res 180:207–221
82. Homans SW (1990) A molecular mechanical
force ﬁeld for the conformational analysis of
oligosaccharides: comparison of theoretical
and crystal structures of Man alpha 1-3Man
beta
1-4GlcNAc.
Biochemistry
(Mosc)
29:9110–9118
83. Kirschner KN, Yongye AB, Tschampel SM,
Gonza´lez-Outeirin˜o J, Daniels CR, Foley
BL, Woods RJ (2008) GLYCAM06: a gener-
alizable biomolecular force ﬁeld. Carbohy-
drates. J Comput Chem 29:622–655
84. Dickson CJ, Madej BD, Skjevik A˚ A, Betz RM,
Teigen K, Gould IR, Walker RC (2014)
Lipid14: the amber lipid force ﬁeld. J Chem
Theory Comput 10:865–879
85. Bayly CI, Cieplak P, Cornell W, Kollman PA
(1993) A well-behaved electrostatic potential
based method using charge restraints for
deriving atomic charges: the RESP model. J
Phys Chem 97:10269–10280
86. Cieplak P, Cornell WD, Bayly C, Kollman PA
(1995) Application of the multimolecule and
multiconformational RESP methodology to
biopolymers: charge derivation for DNA,
RNA,
and
proteins.
J
Comput
Chem
16:1357–1377
87. Jakalian A, Jack DB, Bayly CI (2002) Fast,
efﬁcient generation of high-quality atomic
charges. AM1-BCC model: II. Parameteriza-
tion
and
validation.
J
Comput
Chem
23:1623–1641
88. Rappe AK, Casewit CJ, Colwell KS, Goddard
WA, Skiff WM (1992) UFF, a full periodic
table force ﬁeld for molecular mechanics and
molecular dynamics simulations. J Am Chem
Soc 114:10024–10035
89. Rick SW, Stuart SJ, Berne BJ (1994) Dynami-
cal ﬂuctuating charge force ﬁelds: application
to liquid water. J Chem Phys 101:6141–6156
90. Rick SW, Berne BJ (1996) Dynamical ﬂuctu-
ating charge force ﬁelds: the aqueous solva-
tion of amides. J Am Chem Soc 118:672–679
91. Stern HA, Rittner F, Berne BJ, Friesner RA
(2001) Combined ﬂuctuating charge and
polarizable dipole models: application to a
ﬁve-site water potential function. J Chem
Phys 115:2237–2251
92. Patel S, Brooks CL III (2004) CHARMM
ﬂuctuating charge force ﬁeld for proteins: I
parameterization and application to bulk
organic liquid simulations. J Comput Chem
25:1–16
93. Patel S, MacKerell AD Jr, Brooks CL (2004)
CHARMM ﬂuctuating charge force ﬁeld for
proteins: II Protein/solvent properties from
molecular dynamics simulations using a non-
additive electrostatic model. J Comput Chem
25:1504–1514
94. Stuart SJ, Berne BJ (1996) Effects of polariz-
ability on the hydration of the chloride ion. J
Phys Chem 100:11934–11943
95. Kaminski GA, Stern HA, Berne BJ, Friesner
RA, Cao YX, Murphy RB, Zhou R, Halgren
TA (2002) Development of a polarizable
force ﬁeld for proteins via ab initio quantum
chemistry: ﬁrst generation model and gas
phase tests. J Comput Chem 23:1515–1531
96. Dang LX, Rice JE, Caldwell J, Kollman PA
(1991) Ion solvation in polarizable water:
molecular dynamics simulations. J Am Chem
Soc 113:2481–2486
97. Caldwell JW, Kollman PA (1995) Structure
and properties of neat liquids using nonaddi-
tive molecular dynamics: water, methanol,
and
N-methylacetamide.
J
Phys
Chem
99:6208–6219
98. Caldwell JW, Kollman PA (1995) Cation-.pi.
interactions: nonadditive effects are critical in
their accurate representation. J Am Chem Soc
117:4177–4178
99. Cieplak P, Caldwell J, Kollman P (2001)
Molecular mechanical models for organic
and biological systems going beyond the
atom centered two body additive approxima-
tion: aqueous solution free energies of meth-
anol and N-methyl acetamide, nucleic acid
base, and amide hydrogen bonding and chlo-
roform/water partition coefﬁcients of the
nucleic
acid
bases.
J
Comput
Chem
22:1048–1057
48
Fang-Yu Lin and Alexander D. MacKerell Jr

100. Wang Z-X, Zhang W, Wu C, Lei H, Cieplak P,
Duan Y (2006) Strike a balance: optimization
of backbone torsion parameters of AMBER
polarizable force ﬁeld for simulations of pro-
teins
and
peptides.
J
Comput
Chem
27:781–790
101. Xie W, Pu J, MacKerell AD Jr, Gao J (2007)
Development of a polarizable intermolecular
potential function (PIPF) for liquid amides
and
alkanes.
J
Chem
Theory
Comput
3:1878–1889
102. Liu Y-P, Kim K, Berne BJ, Friesner RA, Rick
SW (1998) Constructing ab initio force ﬁelds
for molecular dynamics simulations. J Chem
Phys 108:4739–4755
103. Dang LX, Chang T-M (1997) Molecular
dynamics study of water clusters, liquid, and
liquid–vapor interface of water with many-
body
potentials.
J
Chem
Phys
106:8149–8159
104. Sun X, Wick CD, Dang LX (2011) Computa-
tional study of ion distributions at the air/-
liquid methanol interface. J Phys Chem A
115:5767–5773
105. Chang T-M, Dang LX (2014) Computational
studies of [bmim][PF6]/n-alcohol interfaces
with many-body potentials. J Phys Chem A
118:7186–7193
106. Wang J, Cieplak P, Li J, Hou T, Luo R, Duan
Y (2011) Development of polarizable models
for
molecular
mechanical
calculations
I:
parameterization of atomic polarizability. J
Phys Chem B 115:3091–3099
107. Wang J, Cieplak P, Li J, Wang J, Cai Q,
Hsieh M, Lei H, Luo R, Duan Y (2011)
Development
of
polarizable
models
for
molecular mechanical calculations II: induced
dipole models signiﬁcantly improve accuracy
of intermolecular interaction energies. J Phys
Chem B 115:3100–3111
108. Wang J, Cieplak P, Cai Q, Hsieh M-J, Wang J,
Duan Y, Luo R (2012) Development of
polarizable models for molecular mechanical
calculations. 3. Polarizable water models con-
forming
to
thole
polarization
screening
schemes. J Phys Chem B 116:7999–8008
109. Wang J, Cieplak P, Li J, Cai Q, Hsieh M-J,
Luo R, Duan Y (2012) Development of
polarizable models for molecular mechanical
calculations. 4. van der Waals parametriza-
tion. J Phys Chem B 116:7088–7101
110. Ren P, Ponder JW (2003) Polarizable atomic
multipole water model for molecular mechan-
ics simulation. J Phys Chem B 107:5933–5947
111. Ponder JW, Wu C, Ren P et al (2010) Current
status of the AMOEBA polarizable force ﬁeld.
J Phys Chem B 114:2549–2564
112. Shi Y, Xia Z, Zhang J, Best R, Wu C, Ponder
JW,
Ren
P
(2013)
Polarizable
atomic
multipole-based AMOEBA force ﬁeld for
proteins.
J
Chem
Theory
Comput
9:4046–4063
113. Wang L-P, Head-Gordon T, Ponder JW,
Ren P, Chodera JD, Eastman PK, Martinez
TJ, Pande VS (2013) Systematic improve-
ment of a classical molecular model of water.
J Phys Chem B 117:9956–9972
114. Albaugh A, Niklasson AMN, Head-Gordon T
(2017) Accurate classical polarization solu-
tion with no self-consistent ﬁeld iterations. J
Phys Chem Lett 8:1714–1723
115. Albaugh A, Demerdash O, Head-Gordon T
(2015)
An
efﬁcient
and
stable
hybrid
extended
Lagrangian/self-consistent
ﬁeld
scheme for solving classical mutual induction.
J Chem Phys 143:174104
116. Simmonett AC, Pickard FC, Ponder JW,
Brooks BR (2016) An empirical extrapolation
scheme for efﬁcient treatment of induced
dipoles. J Chem Phys 145:164101. https://
doi.org/10.1063/1.4964866
117. Simmonett AC, Pickard FC, Schaefer HF,
Brooks BR (2014) An efﬁcient algorithm for
multipole energies and derivatives based on
spherical harmonics and extensions to particle
mesh Ewald. J Chem Phys 140:184101
118. Huang J, Simmonett AC, Pickard FC, MacK-
erell AD Jr, Brooks BR (2017) Mapping the
Drude polarizable force ﬁeld onto a multipole
and induced dipole model. J Chem Phys
147:161702
119. Harder E, Anisimov VM, Whitﬁeld T, MacK-
erell AD Jr, Roux B (2008) Understanding
the dielectric properties of liquid amides from
a polarizable force ﬁeld. J Phys Chem B
112:3509–3521
120. Harder E, Anisimov VM, Vorobyov IV, Lopes
PEM, Noskov SY, MacKerell AD Jr, Roux B
(2006) Atomic level anisotropy in the electro-
static modeling of lone pairs for a polarizable
force ﬁeld based on the classical Drude oscil-
lator. J Chem Theory Comput 2:1587–1597
121. Thole BT (1981) Molecular polarizabilities
calculated with a modiﬁed dipole interaction.
Chem Phys 59:341–350
122. Allen MP, Tildesley DJ (2017) Computer
simulation of liquids, 2nd edn. Oxford Uni-
versity Press, Oxford; New York, NY. New to
this Edition
123. Baker CM, Lopes PEM, Zhu X, Roux B,
MacKerell AD Jr (2010) Accurate calculation
of hydration free energies using pair-speciﬁc
lennard-jones parameters in the CHARMM
Force Fields for Small Molecules
49

drude polarizable force ﬁeld. J Chem Theory
Comput 6:1181–1198
124. Chowdhary
J,
Harder
E,
Lopes
PEM,
Huang L, MacKerell AD Jr, Roux B (2013)
A polarizable force ﬁeld of dipalmitoylpho-
sphatidylcholine based on the classical Drude
model for molecular dynamics simulations of
lipids. J Phys Chem B 117:9142–9160
125. Kunz A-PE, van Gunsteren WF (2009) Devel-
opment of a nonlinear classical polarization
model for liquid water and aqueous solutions:
COS/D. J Phys Chem A 113:11570–11579
126. Lamoureux G, Roux B (2003) Modeling
induced polarization with classical Drude
oscillators: theory and molecular dynamics
simulation
algorithm.
J
Chem
Phys
119:3025–3039
127. Zhang C, Lu C, Jing Z, Wu C, Piquemal JP,
Ponder
JW,
Ren
P
(2018)
AMOEBA
polarizable atomic multipole force ﬁeld for
nucleic acids. J Chem Theory Comput 14
(4):2084–2108.
https://doi.org/10.1021/
acs.jctc.7b01169
128. Ren P, Wu C, Ponder JW (2011) Polarizable
atomic multipole-based molecular mechanics
for organic molecules. J Chem Theory Com-
put 7:3143–3161
129. Mu X, Wang Q, Wang L-P, Fried SD, Pique-
mal J-P, Dalby KN, Ren P (2014) Modeling
organochlorine compounds and the σ-hole
effect using a polarizable multipole force
ﬁeld. J Phys Chem B 118:6456–6465
130. Grossﬁeld A, Ren P, Ponder JW (2003) Ion
solvation thermodynamics from simulation
with a polarizable force ﬁeld. J Am Chem
Soc 125:15671–15682
131. Wu
JC,
Piquemal
J-P,
Chaudret
R,
Reinhardt P, Ren P (2010) Polarizable molec-
ular dynamics simulation of Zn(II) in water
using the AMOEBA force ﬁeld. J Chem The-
ory Comput 6:2059–2070
132. Lucas TR, Bauer BA, Patel S (2012) Charge
equilibration
force
ﬁelds
for
molecular
dynamics simulations of lipids, bilayers, and
integral membrane protein systems. Biochim
Biophys Acta Biomembr 1818:318–329
133. Zhong Y, Bauer BA, Patel S (2011) Solvation
properties of N-acetyl-β-glucosamine: molec-
ular dynamics study incorporating electro-
static
polarization.
J
Comput
Chem
32:3339–3353
134. Ou S, Patel S (2013) Temperature depen-
dence and energetics of single ions at the
aqueous liquid-vapor interface. J Phys Chem
B 117:6512–6523
135. Lopes PEM, Huang J, Shim J, Luo Y, Li H,
Roux B, MacKerell AD Jr (2013) Force ﬁeld
for peptides and proteins based on the classi-
cal Drude oscillator. J Chem Theory Comput
9:5430–5449
136. Savelyev A, MacKerell AD Jr (2014) All-atom
polarizable force ﬁeld for DNA based on the
classical Drude oscillator model. J Comput
Chem 35:1219–1239
137. Savelyev A, MacKerell AD Jr (2014) Balanc-
ing the interactions of ions, water, and DNA
in the drude polarizable force ﬁeld. J Phys
Chem B 118:6742–6757
138. Lemkul JA, MacKerell AD Jr (2017) Polar-
izable force ﬁeld for DNA based on the classi-
cal Drude oscillator: I. Reﬁnement using
quantum mechanical base stacking and con-
formational energetics. J Chem Theory Com-
put 13:2053–2071
139. Lemkul JA, MacKerell AD Jr (2017) Polar-
izable force ﬁeld for DNA based on the classi-
cal
Drude
oscillator:
II.
Microsecond
molecular dynamics simulations of duplex
DNA.
J
Chem
Theory
Comput
13:2072–2085
140. Li H, Chowdhary J, Huang L, He X, MacK-
erell AD Jr, Roux B (2017) Drude polarizable
force ﬁeld for molecular dynamics simulations
of saturated and unsaturated zwitterionic
lipids.
J
Chem
Theory
Comput
13:4535–4552
141. He X, Lopes PEM, MacKerell AD Jr (2013)
Polarizable empirical force ﬁeld for acyclic
polyalcohols based on the classical Drude
oscillator. Biopolymers 99:724–738
142. Patel DS, He X, MacKerell AD Jr (2015)
Polarizable empirical force ﬁeld for hexopyr-
anose monosaccharides based on the classical
Drude
oscillator.
J
Phys
Chem
B
119:637–652
143. Jana M, MacKerell AD Jr (2015) CHARMM
drude polarizable force ﬁeld for aldopentofur-
anoses and methyl-aldopentofuranosides. J
Phys Chem B 119:7846–7859
144. Yang M, Aytenﬁsu AH, MacKerell AD (2018)
Proper balance of solvent-solute and solute-
solute interactions in the treatment of the
diffusion of glucose using the Drude polar-
izable force ﬁeld. Carbohydr Res 457:41–50
145. Vorobyov IV, Anisimov VM, MacKerell AD Jr
(2005) Polarizable empirical force ﬁeld for
alkanes based on the classical Drude oscillator
model. J Phys Chem B 109:18988–18999
146. Noskov SY, Lamoureux G, Roux B (2005)
Molecular dynamics study of hydration in
ethanol–water mixtures using a polarizable
force ﬁeld. J Phys Chem B 109:6705–6713
147. Anisimov VM, Lamoureux G, Vorobyov IV,
Huang N, Roux B, MacKerell AD Jr (2005)
50
Fang-Yu Lin and Alexander D. MacKerell Jr

Determination of electrostatic parameters for
a polarizable force ﬁeld based on the classical
Drude oscillator. J Chem Theory Comput
1:153–168
148. Lopes PEM, Lamoureux G, Roux B, MacK-
erell AD Jr (2007) Polarizable empirical force
ﬁeld for aromatic compounds based on the
classical Drude oscillator. J Phys Chem B
111:2873–2885
149. Anisimov VM, Vorobyov IV, Roux B, MacK-
erell AD Jr (2007) Polarizable empirical force
ﬁeld for the primary and secondary alcohol
series based on the classical Drude model. J
Chem Theory Comput 3:1927
150. Vorobyov I, Anisimov VM, Greene S, Venable
RM, Moser A, Pastor RW, MacKerell AD Jr
(2007) Additive and classical drude polar-
izable force ﬁelds for linear and cyclic ethers.
J Chem Theory Comput 3:1120–1133
151. Lopes PEM, Lamoureux G, MacKerell AD Jr
(2009) Polarizable empirical force ﬁeld for
nitrogen-containing
heteroaromatic
com-
pounds based on the classical Drude oscilla-
tor. J Comput Chem 30:1821–1838
152. Baker CM, MacKerell AD Jr (2010) Polariz-
ability rescaling and atom-based Thole scaling
in the CHARMM Drude polarizable force
ﬁeld for ethers. J Mol Model 16:567–576
153. Zhu X, MacKerell AD Jr (2010) Polarizable
empirical force ﬁeld for sulfur-containing
compounds based on the classical Drude
oscillator
model.
J
Comput
Chem
31:2330–2341
154. Lin B, Lopes PEM, Roux B, MacKerell AD Jr
(2013) Kirkwood-Buff analysis of aqueous
N-methylacetamide and acetamide solutions
modeled by the CHARMM additive and
Drude polarizable force ﬁelds. J Chem Phys
139:084509
155. Small MC, Aytenﬁsu AH, Lin F-Y, He X,
MacKerell AD Jr (2017) Drude polarizable
force ﬁeld for aliphatic ketones and aldehydes,
and their associated acyclic carbohydrates. J
Comput Aided Mol Des 31:349–363
156. Lin F-Y, Lopes PEM, Harder E, Roux B,
MacKerell AD (2018) Polarizable force ﬁeld
for molecular ions based on the classical
Drude
oscillator.
J
Chem
Inf
Model
58:993–1004
157. Lin F-Y, MacKerell AD (2018) Polarizable
empirical force ﬁeld for halogen-containing
compounds based on the classical Drude
oscillator.
J
Chem
Theory
Comput
14:1083–1098
158. Zhong Y, Patel S (2013) Binding structures
of tri-N-acetyl-β-glucosamine in hen egg
white lysozyme using molecular dynamics
with a polarizable force ﬁeld. J Comput
Chem 34:163–174
159. Hu Y, Ou S, Patel S (2013) Free energetics of
arginine permeation into model DMPC lipid
bilayers: coupling of effective counterion con-
centration and lateral bilayer dimensions. J
Phys Chem B 117:11641–11653
160. Ponder JW, Richards FM (1987) An efﬁcient
newton-like method for molecular mechanics
energy minimization of large molecules. J
Comput Chem 8:1016–1024
161. Ren P, Ponder JW (2004) Temperature
and pressure dependence of the AMOEBA
water
model.
J
Phys
Chem
B
108:13427–13437
162. Piquemal J-P, Perera L, Cisneros GA, Ren P,
Pedersen LG, Darden TA (2006) Towards
accurate
solvation
dynamics
of
divalent
cations in water using the polarizable amoeba
force ﬁeld: from energetics to structure. J
Chem Phys 125:054511
163. Schnieders MJ, Fenn TD, Pande VS, Brunger
AT
(2009)
Polarizable
atomic
multipole
X-ray reﬁnement: application to peptide crys-
tals. Acta Crystallogr D Biol Crystallogr
65:952–965
164. Zhang J, Yang W, Piquemal J-P, Ren P (2012)
Modeling structural coordination and ligand
binding in zinc proteins with a polarizable
potential.
J
Chem
Theory
Comput
8:1314–1324
165. Ren P, Ponder JW (2002) Consistent treat-
ment of inter- and intramolecular polarization
in molecular mechanics calculations. J Com-
put Chem 23:1497–1506
166. Shi Y, Jiao D, Schnieders MJ, Ren P (2009)
Trypsin-ligand binding free energy calcula-
tion with AMOEBA. IEEE Eng Med Biol
Soc Annu Conf 2009:2328–2331
167. Lamoureux G, Harder E, Vorobyov IV,
Roux B, MacKerell AD Jr (2006) A polar-
izable model of water for molecular dynamics
simulations of biomolecules. Chem Phys Lett
418:245–249
168. Yu W, Lopes PEM, Roux B, MacKerell AD Jr
(2013) Six-site polarizable model of water
based on the classical Drude oscillator. J
Chem Phys 138:034508. https://doi.org/
10.1063/1.4774577
169. Huang J, MacKerell AD Jr (2014) Induction
of peptide bond dipoles drives cooperative
helix formation in the (AAQAA)3 peptide.
Biophys J 107:991–997
170. Lemkul JA, Savelyev A, MacKerell AD Jr
(2014) Induced polarization inﬂuences the
fundamental forces in DNA base ﬂipping. J
Phys Chem Lett 5:2077–2083
Force Fields for Small Molecules
51

171. Savelyev A, MacKerell AD Jr (2015) Compe-
tition among Li+, Na+, K+, and Rb+ mono-
valent ions for DNA in molecular dynamics
simulations using the additive CHARMM36
and drude polarizable force ﬁelds. J Phys
Chem B 119:4428–4440
172. Klauda JB, Wu X, Pastor RW, Brooks BR
(2007) Long-range Lennard-Jones and elec-
trostatic interactions in interfaces: application
of the isotropic periodic sum method. J Phys
Chem B 111:4393–4400
173. Leonard AN, Simmonett AC, Pickard FC,
Huang J, Venable RM, Klauda JB, Brooks
BR, Pastor RW (2018) Comparison of addi-
tive and polarizable models with explicit treat-
ment
of
long-range
Lennard-Jones
interactions
using
alkane
simulations.
J
Chem Theory Comput 14:948–958
174. Wennberg CL, Murtola T, Pa´ll S, Abraham
MJ, Hess B, Lindahl E (2015) Direct-space
corrections enable fast and accurate Lorentz–-
Berthelot combination rule Lennard-Jones
lattice summation. J Chem Theory Comput
11:5737–5746
175. van Erp TS, Meijer EJ (2003) Ab initio
molecular dynamics study of aqueous solva-
tion of ethanol and ethylene. J Chem Phys
118:8831–8840
176. Whitﬁeld TW, Martyna GJ, Allison S, Bates
SP, Vass H, Crain J (2006) Structure and
hydrogen
bonding
in
neat
N-methylacetamide:
classical
molecular
dynamics and raman spectroscopy studies of
a liquid of peptidic fragments. J Phys Chem B
110:3624–3637
177. Kirkwood JG (1939) The dielectric polariza-
tion of polar liquids. J Chem Phys 7:911–919
178. Tran HT, Mao A, Pappu RV (2008) Role of
backbone–solvent interactions in determining
conformational equilibria of intrinsically dis-
ordered
proteins.
J
Am
Chem
Soc
130:7380–7392
179. Salonen LM, Ellermann M, Diederich F
(2011)
Aromatic
rings
in
chemical
and
biological recognition: energetics and struc-
tures. Angew Chem Int Ed 50:4808–4842
180. Asif M (2017) A mini review: biological sig-
niﬁcances of nitrogen hetero atom containing
heterocyclic compounds. Int J Bioorganic
Chem 2:146
181. Levitt M, Perutz MF (1988) Aromatic rings
act as hydrogen bond acceptors. J Mol Biol
201:751–754
182. Suzuki
S,
Green
PG,
Bumgarner
RE,
Dasgupta S, Goddard WA, Blake GA (1992)
Benzene forms hydrogen bonds with water.
Science 257:942–945
183. Orabi EA, Lamoureux G (2012) Cation–π
and π–π interactions in aqueous solution stud-
ied using polarizable potential models. J
Chem Theory Comput 8:182–193
184. Sperry JB, Wright DL (2005) Furans, thio-
phenes and related heterocycles in drug dis-
covery.
Curr
Opin
Drug
Discov
Devel
8:723–740
185. Schnitzer
TJ,
Truitt
K,
Fleischmann
R,
Dalgin P, Block J, Zeng Q, Bolognese J,
Seidenberg B, Ehrich EW (1999) The safety
proﬁle, tolerability, and effective dose range of
rofecoxib in the treatment of rheumatoid
arthritis. Clin Ther 21:1688–1702
186. Feng M, Tang B, Liang SH, Jiang X (2016)
Sulfur containing scaffolds in drugs: synthesis
and application in medicinal chemistry. Curr
Top Med Chem 16:1200–1216
187. Harrold MW, Zavod RM (2014) Basic con-
cepts in medicinal chemistry. Drug Dev Ind
Pharm 40:988–988
188. Hernandes M, Cavalcanti SM, Moreira DR,
de Azevedo Junior W, Leite AC (2010) Halo-
gen atoms in the modern medicinal chemis-
try: hints for the drug design. Curr Drug
Targets 11:303–314
189. Xu Z, Yang Z, Liu Y, Lu Y, Chen K, Zhu W
(2014) Halogen bond: its role beyond drug–-
target binding afﬁnity for drug discovery and
development. J Chem Inf Model 54:69–78
190. Aufﬁnger P, Hays FA, Westhof E, Ho PS
(2004) Halogen bonds in biological mole-
cules.
Proc
Natl
Acad
Sci
U
S
A
101:16789–16794
191. Scholﬁeld MR, Zanden CMV, Carter M, Ho
PS (2013) Halogen bonding (X-bonding): a
biological
perspective.
Protein
Sci
22:139–152
192. Cavallo G, Metrangolo P, Milani R, Pilati T,
Priimagi A, Resnati G, Terraneo G (2016)
The
halogen
bond.
Chem
Rev
116:2478–2601
193. Zhou P-P, Qiu W-Y, Liu S, Jin N-Z (2011)
Halogen
as
halogen-bonding
donor
and
hydrogen-bonding acceptor simultaneously
in ring-shaped H3N·X(Y)·HF (X ¼ Cl, Br
and Y ¼ F, Cl, Br) Complexes. Phys Chem
Chem Phys 13:7408–7418
194. Politzer P, Murray JS, Clark T (2013) Halo-
gen bonding and other σ-hole interactions: a
perspective.
Phys
Chem
Chem
Phys
15:11178–11189
195. Lu Y, Wang Y, Xu Z, Yan X, Luo X, Jiang H,
Zhu W (2009) C–X···H contacts in biomolec-
ular systems: how they contribute to pro-
tein–ligand binding afﬁnity. J Phys Chem B
113:12615–12621
52
Fang-Yu Lin and Alexander D. MacKerell Jr

196. Lu Y, Wang Y, Zhu W (2010) Nonbonding
interactions of organic halogens in biological
systems: implications for drug discovery and
biomolecular design. Phys Chem Chem Phys
12:4543–4551
197. Singh SK, Yamashita A, Gouaux E (2007)
Antidepressant binding site in a bacterial
homologue of neurotransmitter transporters.
Nature 448:952–956
198. Tomar D, Khan T, Singh RR, Mishra S,
Gupta S, Surolia A, Salunke DM (2012) Crys-
tallographic
study
of
novel
transthyretin
ligands
exhibiting
negative-cooperativity
between two thyroxine binding sites. PLoS
One 7:e43522
199. Verschueren KHG, Selje´e F, Rozeboom HJ,
Kalk KH, Dijkstra BW (1993) Crystallo-
graphic analysis of the catalytic mechanism of
haloalkane
dehalogenase.
Nature
363:693–698
200. Tipparaju SK, Mulhearn DC, Klein GM et al
(2008) Design and synthesis of aryl ether inhi-
bitors of the bacillus anthracis enoyl-ACP
reductase. ChemMedChem 3:1250–1268
201. Carbone V, Chung R, Endo S, Hara A,
El-Kabbani O (2008) Structure of aldehyde
reductase in ternary complex with coenzyme
and the potent 20α-hydroxysteroid dehydro-
genase inhibitor 3,5-dichlorosalicylic acid:
implications for inhibitor binding and selec-
tivity. Arch Biochem Biophys 479:82–87
202. Clark T, Hennemann M, Murray JS, Politzer
P (2006) Halogen bonding: the σ-hole. J Mol
Model 13:291–296
203. Politzer P, Murray JS, Clark T (2010) Halo-
gen
bonding:
an
electrostatically-driven
highly directional noncovalent interaction.
Phys Chem Chem Phys 12:7748–7757
204. Nunes R, Costa PJ (2017) Ion-pair halogen
bonds in 2-halo-functionalized imidazolium
chloride receptors: substituent and solvent
effects. Chem Asian J 12:586–594
205. Lin F-Y, MacKerell AD Jr (2017) Do halo-
gen–hydrogen bond donor interactions dom-
inate the favorable contribution of halogens
to ligand–protein binding? J Phys Chem B
121:6813–6821
206. Carter M, Rappe´ AK, Ho PS (2012) Scalable
anisotropic shape and electrostatic models for
biological bromine halogen bonds. J Chem
Theory Comput 8:2461–2473
207. Lamoureux G, MacKerell AD Jr, Roux B
(2003) A simple polarizable model of water
based on classical Drude oscillators. J Chem
Phys 119:5185–5197
208. Soteras
Gutie´rrez
I,
Lin
F-Y,
Vanommeslaeghe K, Lemkul JA, Armacost
KA, Brooks CL III, MacKerell AD Jr (2016)
Parametrization of halogen bonds in the
CHARMM general force ﬁeld: improved
treatment
of
ligand–protein
interactions.
Bioorg Med Chem 24:4812–4825
209. Dang LX (1992) Development of nonaddi-
tive intermolecular potentials using molecular
dynamics: solvation of Li+ and F ions in
polarizable
water.
J
Chem
Phys
96:6970–6977
210. Chang T-M, Dang LX (1997) Ion solvation
in
polarizable
chloroform:
a
molecular
dynamics
study.
J
Phys
Chem
B
101:10518–10526
211. Dang LX (2000) Molecular dynamics study of
benzene–benzene
and
benzene–potassium
ion interactions using polarizable potential
models. J Chem Phys 113:266–273
212. Sun X, Chang T, Cao Y, Niwayama S, Hase
WL, Dang LX (2009) Solvation of dimethyl
succinate in a sodium hydroxide aqueous
solution. A computational study. J Phys
Chem B 113:6473–6477
213. Baer M, Mundy CJ, Chang T-M, Tao F-M,
Dang LX (2010) Interpreting vibrational
sum-frequency spectra of sulfur dioxide at
the air/water interface: a comprehensive
molecular dynamics study. J Phys Chem B
114:7245–7249
214. Dang LX, Truong TB, Ginovska-Pangovska B
(2012) Note: interionic potentials of mean
force for Ca2+-Cl in polarizable water. J
Chem Phys 136:126101
215. Brooks BR, Brooks CL, MacKerell AD et al
(2009) CHARMM: the biomolecular simula-
tion
program.
J
Comput
Chem
30:1545–1614
216. Brooks BR, Bruccoleri RE, Olafson DJ, States
DJ,
Swaminathan
S,
Karplus
M
(1983)
CHARMM: a program for macromolecular
energy, minimization, and dynamics calcula-
tions. J Comput Chem 4:187–217
217. MacKerell AD Jr, Brooks CL III, Nilsson L,
Roux B, Won Y, Karplus M (1998) In: PvR S,
Allinger N, Clark T, Gasteiger J, Kollman PA,
Schaefer
HF
III,
Schreiner
PR
(eds)
CHARMM: the energy function and its
parameterization with an overview of the pro-
gram. John Wiley & Sons, Chichester, pp
271–277
218. Phillips JC (2005) Scalable molecular dynam-
ics
with
NAMD.
J
Comput
Chem
26:1781–1802
219. Jiang W, Hardy DJ, Phillips JC, MacKerell
AD Jr, Schulten K, Roux B (2011) High-
performance
scalable
molecular
dynamics
simulations of a polarizable force ﬁeld based
Force Fields for Small Molecules
53

on classical Drude oscillators in NAMD. J
Phys Chem Lett 2:87–92
220. Sherwood P, de Vries AH, Guest MF et al
(2003) QUASI: a general purpose implemen-
tation of the QM/MM approach and its
application to problems in catalysis. J Mol
Struct Theochem 632:1–28
221. Huang J, Lemkul JA, Eastman PK, MacKerell
AD (2018) Molecular dynamics simulations
using the Drude polarizable force ﬁeld on
GPUs with OpenMM: implementation, valida-
tion,
and
benchmarks.
J
Comput
Chem
39:1682.https://doi.org/10.1002/jcc.25339
222. Abraham MJ, Murtola T, Schulz R, Pa´ll S,
Smith JC, Hess B, Lindahl E (2015) GRO-
MACS: high performance molecular simula-
tions through multi-level parallelism from
laptops
to
supercomputers.
SoftwareX
1–2:19–25
223. Belle DV, Froeyen M, Lippens G, Wodak SJ
(1992) Molecular dynamics simulation of
polarizable water by an extended Lagrangian
method. Mol Phys 77:239–255
224. Albaugh A, Head-Gordon T (2017) A new
method for treating drude polarization in
classical molecular simulation. J Chem The-
ory Comput 13:5207–5216
225. Rysselberghe PV (1931) Remarks concerning
the Clausius-Mossotti law. J Phys Chem
36:1152–1155
226. Darden T, York D, Pedersen L (1993) Parti-
cle mesh Ewald: an Nlog(N) method for
Ewald sums in large systems. J Chem Phys
98:10089–10092
227. Essmann
U,
Perera
L,
Berkowitz
ML,
Darden T, Lee H, Pedersen LG (1995) A
smooth
particle
mesh
Ewald
method.
J
Chem Phys 103:8577–8593
54
Fang-Yu Lin and Alexander D. MacKerell Jr

Chapter 3
Improvement of RNA Simulations with Torsional Revisions
of the AMBER Force Field
Ilyas Yildirim
Abstract
Our current knowledge on the unique roles of RNA in cells makes it vital to investigate the properties of
RNA systems using computational methods because of the potential pharmaceutical applications. With the
continuous advancement of computer technology, it is now possible to study RNA folding. Molecular
mechanics calculations are useful in discovering the structural and thermodynamic properties of RNA
systems. Yet, the predictions depend on the quality of the RNA force ﬁeld, which is a set of parameters
describing the potential energy of the system. Torsional parameters are one of the terms in a force ﬁeld that
can be revised using physics-based approaches. This chapter focuses on improvements provided by revisions
of torsional parameters of the AMBER (Assisted Model Building with Energy Reﬁnement) RNA force ﬁeld.
The theory behind torsional revisions and re-parameterization of several RNA torsions is brieﬂy described.
Applications of the revised torsional parameters to study RNA nucleosides, single-stranded RNA tetramers,
and RNA repeat expansions are described in detail. It is concluded that RNA force ﬁelds require constant
revisions and should be benchmarked against diverse RNA systems such as single strands and internal loops
in order to test their qualities.
Key words RNA, AMBER force ﬁeld, Torsional revision, RNA mononucleoside, Single-stranded
RNA tetramer, RNA repeat expansion, Molecular dynamics, Umbrella sampling, Discrete path sam-
pling, Free energy, Potential of mean force
1
Introduction
In cellular biology, RNA molecules have important roles in cells
[1]. While DNA stores all the genetic information, the information
is ﬁrst passed to messenger RNAs (mRNA), which then are trans-
lated into proteins through the utilization of transfer RNA (tRNA)
and ribosomal RNA (rRNA). This workﬂow, however, does not
capture all the other crucial roles of RNA: (1) Viruses such as HIV,
human T-cell leukemia (HTLV), and Zika have RNA genomes
[2, 3]. (2) Riboswitches in mRNA are activated by small molecules
to regulate protein levels in cells [4, 5]. (3) Retrotransposons are
RNA elements amplifying speciﬁc genes [6]. (4) Guide RNAs
(gRNA)
can
insert
or
delete
uridine
residues
in
mRNA
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_3, © Springer Science+Business Media, LLC, part of Springer Nature 2019
55

[7]. (5) Small interfering RNAs (siRNA) and microRNAs (miRNA)
can inhibit gene expression or translation [8, 9]. (6) Ribonucleic
acid enzymes (ribozymes) are RNA molecules behaving like
enzymes catalyzing biochemical reactions [10–12]. (7) RNA apta-
mers bind speciﬁc targets [13, 14]. (8) The CRISPR/Cas9-gRNA
is a new technology, which can perform gene editing [15]. (9) Per-
turbation of RNA metabolism, such as expansion of RNA repeats,
can cause neurodegenerative and neurological diseases such as
Alzheimer’s, parkinsonism, Huntington’s disease (HD), myotonic
dystrophy, and fragile X syndrome [16–21]. Discovery of unique
properties of RNA will make it possible to design next-generation
drugs and/or technologies for effectively treating diseases that do
not presently have known cures.
Predicting 3D structures of RNA from sequence is one of the
ambitions of researchers working in the ﬁeld of computational
chemistry. Yet, RNA folding is a challenging problem, which
requires a proper understanding of physicochemical properties of
RNA. Direct application of quantum mechanics (QM) would be
the best approach to study these molecules, but this is not yet
possible due to the size of even the simplest RNA systems. This
necessitates use of approximate models such as atom-centered force
ﬁelds (Assisted Model Building with Energy Reﬁnement —
AMBER [22], Chemistry at HARvard Macromolecular Mechan-
ics — CHARMM [23], and GROningen MOlecular Simulation —
GROMOS [24]), which use Newtonian mechanics. The use of
molecular mechanics force ﬁelds to study challenging biomolecular
systems is popular because they are computationally economical.
With the advancement of computer technology such as the use of
graphics processing units (GPU), one can run over microsecond
molecular dynamics (MD) simulations in a desktop machine in a
short period of time. Furthermore, supercomputers such as Anton
developed by D. E. Shaw Research allow one to run MD simula-
tions close to biological timescales [25]. Yet, the quality of compu-
tational methods and models is crucial for these technologies to
make accurate predictions.
Different computational methods are utilized to study struc-
tural and thermodynamic properties of RNA systems. Free energy
calculation methods are particularly intriguing because the results
can be used to characterize reaction pathways and free energy land-
scapes of a system. For example, umbrella sampling (US) [26–29]
MD calculations are useful to study base opening and ﬂipping
[30–34] in nucleic acids. Furthermore, the thermodynamic inte-
gration (TI) approach can describe chemical processes. Moreover,
the discrete path sampling (DPS) method developed in the Wales
group [35] can be applied to biomolecular systems to predict
complex energy landscapes without a biasing reaction coordinate.
Other computational methods include steered MD simulations
[36], metadynamics [37], and targeted MD [38], which are
56
Ilyas Yildirim

variations of US calculations. Molecular Mechanics Poisson-
Boltzmann/Generalized Born Surface Area (MMPBSA/GBSA)
approaches [39] allow calculations of binding free energies. Fur-
thermore, several methods, such as replica exchange MD (REMD)
[40] and accelerated MD (aMD) [41], have been developed to
solve sampling issues seen in MD calculations.
Since the 1960s, there has been extensive research done on
improving molecular mechanics force ﬁelds. Initial force ﬁelds were
designed to study small molecules, which then were extended to
study protein and DNA structures. RNA force ﬁelds are relatively
new. The ﬁrst AMBER RNA force ﬁeld was built by utilizing the
force ﬁeld parameters describing DNA [22]. Since 2010, there have
been a handful of revisions to AMBER RNA force ﬁelds. As
described earlier, the quality of the RNA force ﬁeld will direct the
computational predictions. The goals of RNA force ﬁelds are to
mimic nature.
In this chapter, I concentrate on revisions of torsional para-
meters for the AMBER RNA force ﬁeld and highlight improve-
ments in computational predictions due to the revisions. The
chapter is organized as follows: In Subheading 2, basic theory is
illustrated for (1) application of linear-least-squares ﬁtting in tor-
sional revisions of RNA (Subheading 2.1), (2) revision of χ, β, ε/ζ
torsional parameters (Subheading 2.2), (3) revision of α/γ para-
meters (Subheading 2.3), and (4) other revisions (Subheading 2.4).
In Subheading 3, effects of improvements are demonstrated by
applying the revised AMBER RNA force ﬁelds on nucleosides
(Subheading 3.1), single-stranded RNA tetramers (Subheading
3.2), and RNA repeat expansions (Subheading 3.3). Subheading
4 contains notes to highlight several important details presented in
this chapter.
2
Theory
2.1
Revision
of Torsions
Like other molecular mechanics (MM) force ﬁelds, the functional
form of the AMBER force ﬁeld representing the potential energy of
biomolecules is written as
V r
ð Þ ¼
X
bonds
K r r  req

2 þ
X
angles
K θ θ  θeq

2
þ
X
torsions
V n
2 1 þ cos nϕ  γ
ð
Þ
½
 þ
X
i<j
Aij
r12
ij
 Bij
r6
ij
 
!
þ
X
i<j
qiq j
εrij


ð1Þ
Here, the ﬁrst three terms represent bonded interactions (bond
stretching, bond angle bending, and torsional rotation), and
RNA Revisions of the AMBER Force Field
57

the last two terms represent nonbonded interactions (Lennard-
Jones and Coulomb interactions). In multibody systems like bio-
molecules, computational predictions can be improved by revising
speciﬁc terms in Eq. 1. Nevertheless, this is challenging because one
of the problems is determination of the regions requiring revisions.
In general, when a regular RNA duplex is simulated, the predictions
are reasonable, which does not provide any hints on the regions
requiring revisions. When challenging RNA systems are studied,
however, such as single-stranded RNA tetramers, RNA quadru-
plexes, RNA hairpins, and RNA loops, the current RNA force ﬁelds
will have problems predicting experimental observables. Usage of
such exotic RNA systems as benchmarks facilitates determination of
force ﬁeld parameters requiring revision.
In nucleic acid structures, there are six torsions representing the
backbone (α, β, γ, δ, ε, and ζ) and one for the base orientation with
respect to sugar (χ) (Fig. 1). These torsions are represented by the
third term in Eq. 1, and their parameters can be revised using QM
methods. By scanning the potential energy surface (PES) of a
speciﬁc torsion, the QM energy proﬁles of the torsions can be
created, and then linear-least-squares ﬁtting can be used to
optimize the MM parameters to reproduce the QM proﬁle (see
Note 1). The potential energy of a torsional angle, E TOR
MM θ
ð Þ, can
be written as
E TOR
MM θ
ð Þ ¼
X
n
V n  1 þ cos n  θ  Pn
ð
Þ
½

ð2Þ
where n is the periodicity, Vn and Pn are the potential energy
barriers and phase angles, respectively, of periodicity n. Linear-
least-squares ﬁtting can be used to revise the torsional parameters
of Vn, and Pn, for the torsion described by θ, to optimize Eq. 3.
Fig. 1 Torsions in RNA
58
Ilyas Yildirim

E TOR
MM θ
ð Þ  ΔE θ
ð Þ ¼ EQM θ
ð Þ  EnoTOR
MM
θ
ð Þ
ð3Þ
Here, EQM is the QM energy, and EnoTOR
MM
is the MM energy,
which does not include the torsional energy coming from θ. For
illustration purposes, assume that there are 36 data points (θi, i ¼ 1,
2, . . ., 36) equally separated and representing the PES around θ,
where both the EQM and the EnoTOR
MM
for each data point are
calculated. Also, assume that the periodicity n is chosen to be
4. Using trigonometric identities, Eq. 2 can be rewritten as
E TOR
MM
θ
ð Þ
¼
X
4
n¼1
V n  1 þ cos n  θ  Pn
ð
Þ
½

¼ V 1 cos P1
ð
Þ cos θ þ V 1 sin P1
ð
Þ  sin θ
ð
Þ
þ V 2 cos P2
ð
Þ cos 2θ þ V 2 cos P2
ð
Þ  sin 2θ
ð
Þ
þ V 3 cos P3
ð
Þ cos 3θ þ V 3 sin P3
ð
Þ  sin 3θ
ð
Þ
þ V 4 cos P4
ð
Þ cos 4θ þ V 4 sin P4
ð
Þ  sin 4θ
ð
Þ
þ V 1 þ V 2 þ V 3 þ V 4
ð
Þ
ð4Þ
Here, E TOR
MM θ
ð Þ is the energy that needs to resemble the energy
proﬁle, ΔE(θ), described in Eq. 3, which can be written in matrix
form as
Xβ ¼ y
ð5Þ
where
X ¼
cos θ1
 sin θ1
cos 2θ1
 sin 2θ1
  
cos 4θ1
 sin 4θ1
1
cos θ2
 sin θ2
cos 2θ1
 sin 2θ2
  
cos 4θ2
 sin 4θ2
1
⋮
⋮
⋮
⋮
⋱
⋮
⋮
⋮
cos θ36
 sin θ36
cos 2θ1
 sin 2θ36
  
cos 4θ36
 sin 4θ36
1
2
664
3
775
369
β ¼
V 1 cos P1
V 1 sin P1
V 2 cos P2
V 2 sin P2
⋮
V 4 sin P4
V 4 cos P4
Eopt
2
66666666664
3
77777777775
91
,
y ¼
ΔE1
ΔE2
ΔE3
ΔE4
⋮
ΔE35
ΔE36
2
6666664
3
7777775
361
The unknowns in β can be solved by utilizing linear-least-
squares ﬁtting, where the pseudo-inverse of X, X1, is applied to
both sides in Eq. 5.
X1Xβ
¼ X1y
β
¼ X1y
ð6Þ
Results of Eq. 5 will yield Vn and Pn (n ¼ 1, 2, 3, 4) (see Note 2).
2.2
Revision of χ, β,
ε, and ζ
Early amber99 MD simulations of single-stranded RNA tetramers
generated random coil structures. This initial observation looked
RNA Revisions of the AMBER Force Field
59

reasonable but could not explain experimental free energies of
duplex formation for several RNA tetramers, where the thermody-
namic integration (TI) approach was utilized to make predictions
[42]. However, if single-stranded RNA structures were forced to
sample around A-form conformations, the native structure of RNA,
then computational predictions using TI approach were in line with
experiments. These preliminary results indicated issues with the
torsional parameters of RNA in the amber99 force ﬁeld. Speciﬁ-
cally, the parameters describing the RNA χ torsions required revi-
sions in order to observe single-stranded RNA tetramers sampling
A-form-like conformations [43, 44]. Others observed related
results in RNA hairpin structures, where revision of χ torsional
parameters eliminated formation of ladder-like structures in MD
simulations [45]. These simulations used revisions of χ torsional
parameters using modiﬁed versions of ribonucleosides as model
systems and addition of continuum solvent models in the QM
calculations [46]. It is also noteworthy that Ode and coworkers
did a separate revision of χ torsional parameters in 2008 for all
nucleic acid residues, but their model systems did not include the
full sugars (see Note 3) [47].
There are several reasons why amber99 RNA force ﬁeld failed in
predicting experimental results. (1) The χ torsional parameters of
purines and pyrimidines were calculated using model systems of
adenosine
and
thymidine
(Fig.
2a),
respectively,
and
then
generalized for all DNA and RNA residues. (2) When calculating
the χ torsional parameters, the model systems were created to
imitate deoxyribose C20-endo sugar puckering, while RNA residues
prefer C30-endo sugar puckering. (3) At the time the amber99 force
ﬁeld was created, computer power limited the QM calculations
used to calculate the torsional parameters. (4) The original χ tor-
sional parameters were changed without doing any ﬁtting to
Fig. 2 One of the model systems used by amber99 (a) and amber99 + χ (b) to
revise the χ torsional parameters of RNA. In (a), the sugar pucker was modeled
to imitate C20-endo, while in (b), structures representing C20-endo and C30-endo
sugar puckering were utilized. Furthermore, parameters calculated using the
model in (a) were generalized for all purines
60
Ilyas Yildirim

improve C20-endo sugar puckering in DNA. Evidently, it is impor-
tant to choose a model that closely represents the molecule of
interest and to calculate the QM energy landscape well (see Note 4).
Modern computational resources allowed using the full nucle-
oside structures of adenosine, cytidine, guanosine, and uridine to
create separate sets of χ torsional parameters for each RNA residue
(Fig. 2b) [44]. For each RNA nucleoside, four different conforma-
tions representing the C20-endo and C30-endo sugar pucker were
created. For each conformation, a potential energy surface (PES)
scan was performed around χ with increments of 5, yielding
4  72 ¼ 288 conformations for each RNA nucleoside. For each
of these conformations, structures were ﬁrst optimized with HF/6-
31G* level of theory, followed by single-point energy calculations
performed with MP2/6-31G* level of theory. All the calculations
were performed by Gaussian03 [48]. During the optimization
process, most torsions were frozen in order to create a smooth
energy landscape for χ. The 288 data points were then used in the
parameter ﬁtting process described earlier.
After observing improved predictions due to χ torsion revision,
a similar approach was followed for revising β, ε, and ζ torsional
parameters of RNA using the model systems shown in Fig. 3.
For revision of β, a 1D PES scan was performed. For ε/ζ torsions,
six 2D PES scans were performed to calculate the energy land-
scapes
using
QM.
The
QM
results
were
then
used
for
re-parameterization [42].
Fig. 3 Model systems used to revise the β (a), and ε/ζ (b) torsions of RNA.
Adapted with permission from ref. [42] (https://pubs.acs.org/doi/abs/10.1021%
2Fct200557r). Further permissions related to the material excerpted should be
directed to the ACS
RNA Revisions of the AMBER Force Field
61

2.3
Revision of α/γ
Computational predictions were improved particularly by revision
of χ torsional parameters for RNA, but some structures observed in
simulations of single-stranded RNA tetramers were not consistent
with nuclear magnetic resonance (NMR) spectra (Fig. 4a). Revision
of α/γ torsional parameters using the model system displayed in
Fig. 4b largely eliminated the unphysical states observed in MD
simulations [49]. Previously, the α/γ torsional parameters devel-
oped for DNA residues, called parmbsc0 [50], were transferred to
represent RNA residues. There are two reasons why parmbsc0
would not be optimal for RNA: (1) The model system used for
creating the parmbsc0 force ﬁeld only had one sugar attached to a
phosphate group and (2) the parameters were speciﬁcally developed
for DNA residues, as they used a deoxyribose sugar in the model
system (see Note 5). To account for the different electronic envi-
ronment of ribose compared to deoxyribose, the model shown in
Fig. 4b was utilized to reﬁne the α/γ torsional parameters for RNA.
The 2D QM energy landscapes of α/γ torsions were calculated for
two sugar conformations in the model system (Fig. 4b): (1) Both
sugars were in C30-endo conformations, and (2) ﬁrst sugar was in
C20-endo, while the second one was in C30-endo conformation.
For each conformation, α and γ were rotated with an increment of
10, yielding 2  36  36 ¼ 2592 data points for the reﬁnement.
Also, the γ torsional parameters for the 50-terminus were revised
separately. Similar to the χ revision, the QM approach included
optimization and single-point energy calculations using HF/6-
31G* and MP2/6-31G* levels of theory, respectively. Parameters
were then ﬁt using linear-least-squares ﬁtting described earlier.
Fig. 4 (a) An unphysical state observed in single-stranded RNA GACC
simulations. (b) Model system for revising the α/γ torsional parameters for
RNA [49]. Reprinted with permission from ref. [49] (https://pubs.acs.org/doi/
pdf/10.1021/acs.jpcb.7b00819). Further permissions related to the material
excerpted should be directed to the ACS
62
Ilyas Yildirim

2.4
Other Revisions
There have been other studies to revise the AMBER force ﬁeld. In
2013, Chen and Garcia revised the Lennard-Jones (L-J) and χ
torsional parameters of the AMBER RNA force ﬁeld to hinder
formation of over-stabilized RNA tetraloops [51]. In 2015, Chea-
tham and coworkers revised the van der Waals (vdW) parameters of
phosphate oxygens to improve predictions for single-stranded
RNA tetramers [52]. In another approach, empirical corrections
were made by Bussi and coworkers to improve the predictions of
RNA tetramers [53]. In 2016, Lahiri’s group revised both the χ
torsional and the L-J parameters of the O30 atom in a study of
modiﬁed uridine residues. They showed that modiﬁcation of L-J σ
parameter of O30 has a direct consequence on the C20/C30-endo
preference of ribose [54]. In 2017, Mathews and coworkers revised
ﬁve of the backbone and the χ torsional parameters using dinucleo-
tide structures extracted from the Protein Data Bank and showed
that predictions for single-stranded RNA tetramers and other
benchmarks were improved [55]. Recently, Shaw and coworkers
re-parameterized the AMBER RNA force ﬁeld by ﬁrst revising the
nonbonded parameters of nucleobases to improve the description
of base pairing and stacking and then deriving revised terms for the
γ, ζ, and χ torsions [56].
3
Applications
3.1
Nucleosides
Nucleosides are the simplest molecules for benchmarking RNA
force ﬁelds. In solution, nucleosides have two important regions,
which describe their structure: (1) Orientation of base with respect
to sugar and (2) conformation of sugar pucker. While DNA resi-
dues are known to have C20-endo sugar puckering, RNA residues
prefer C30-endo conformations. Transient 1D Nuclear Overhauser
Effect (NOE) experiments and measurements of 3J1020 and 3J3040
spin-spin couplings showed that cytidine and uridine nucleosides
prefer anti-orientation ~90%, and C30-endo conformation ~60%
(see Note 6) [44]. These NMR results are the simplest benchmarks
for testing the quality of an RNA force ﬁeld. The older amber99
RNA force ﬁeld predicted the syn/C20-endo conformations to be
the global minimum for cytidine and uridine (Fig. 5a). Further-
more, the older amber99 RNA force ﬁeld displayed a shift toward
high anti-orientations in adenosine and guanosine residues. As
described earlier, the parameters of amber99 force ﬁeld were opti-
mized for DNA residues, which is probably the reason that it did
not predict the NMR results of RNA nucleosides. The revised χ
torsional parameters for RNA, however, make predictions that
agree with the NMR results [44]. The revised χ torsional para-
meters predict the anti/C30-endo conformation to be the global
minimum for cytidine and uridine (Fig. 5b) and suppressed the
emergence of high anti-orientations in adenosine and guanosine.
RNA Revisions of the AMBER Force Field
63

These results yield several important conclusions, such as (1) RNA
molecules require separate parameterization and (2) if a force ﬁeld
cannot predict the experimental results of simpler systems such as
RNA nucleosides, it will have serious issues in making predictions
on complex RNA structures. Thus, revision of χ torsional para-
meters is an important step to balance the forces governing RNA
molecules.
3.2
Single-Stranded
RNA Tetramers
Altona and coworkers used qualitative NOEs to identify base-base
stacking in single-stranded RNA, AACC [57]. Similarly, Chatto-
padhyaya’s group identiﬁed A-A stacking in single-stranded DNA
and RNA GAAAC sequences [58]. NMR spectra of oligonucleo-
tides, CAAU, CMAMAMUM, and CLAMALUM, where M and L
stand for 20O-methyl and locked nucleic acid (LNA) sugars, also
revealed helical organization [59]. More detailed quantitative 2D
NMR studies of single-stranded RNA tetramers—GACC, CCCC,
CAAU, and AAAA—showed preference for A-form-like conforma-
tions [60, 61]. These types of single-stranded systems provide
another set of benchmarks for testing the quality of RNA force
ﬁelds.
The structural properties of single-stranded RNA—GACC—
were studied by 2D NMR spectroscopy, which discovered a major
and a minor conformation (Fig. 6). The major structure (Fig. 6a) is
A-form, while the minor structure (Fig. 6b) is A-form with a ﬂipped
upside-down C4 residue. However, the NMR results could not be
Fig. 5 Population distributions of (P, χ) observed in cytidine using amber99 (a) and amber99 + χ (b) force
ﬁelds. P stands for pseudorotation angle, which represents the sugar pucker. χ around 60 and 200
represent syn and anti-conformations, respectively, while P around 18 and 162 represent C30-endo and
C20-endo conformations, respectively. Note that the global minimum structures for cytidine are predicted to be
syn/C20-endo and anti/C30-endo conformations by amber99 and amber99 + χ force ﬁelds, respectively
64
Ilyas Yildirim

reproduced with the amber99 force ﬁeld simulations, which pro-
duced random-coil conformations. When revised χ torsional para-
meters were incorporated in the amber99 force ﬁeld, both the
major and minor structures were generated in MD simulations
(Fig. 6). Extension of an MD simulation to cover ~2 μs, however,
displayed a stable yet an unphysical state (Fig. 4a). This state has
unusual characteristics such as G1 being intercalated between C3
and C4 predicting unique NOEs, which could not be observed in
the NMR data (Fig. 4a). This intercalated state or other unphysical
states were also observed in the MD simulations of the single-
stranded RNA AAAA, CAAU, CCCC, and UUUU (see Note 7)
[60, 62].
Generation of transitions between several stable unphysical
states in the MD simulations with χ torsional revision revealed
that the torsional parameters of AMBER force ﬁeld for RNA
required more corrections. Because the revised AMBER force
ﬁeld stabilized the major and minor NMR structures of single-
stranded GACC RNA, simulations were compared to additional
benchmarks. For example, modiﬁed thermodynamic integration
(TI) approach was used to study formation free energies of RNA
duplexes formed by either GC or iGiC base pairs, where iG and iC
stand for isoguanosine and isocytidine, respectively [42]. The
Fig. 6 Overlap of the NMR modeled (black) and computationally predicted (red)
structures of the major (a) and minor (b) species for single-stranded GACC RNA
[43]. Computational predictions used the revised χ torsional parameters with
amber99 force ﬁeld. Note that in the minor species, C4 is ﬂipped upside down.
Reprinted with permission from ref. [43] (https://pubs.acs.org/doi/abs/10.1021/
jp2016006). Further permissions related to the material excerpted should be
directed to the ACS
RNA Revisions of the AMBER Force Field
65

experimental results could only be approximately reproduced when
the revised χ torsional parameters were incorporated in the
amber99 force ﬁeld. This is because one part of the thermodynamic
cycles required alchemical transformations of single-stranded RNA
tetramers (Fig. 7). The improvements of the calculations came from
the better description of the single-stranded RNA tetramers, which
preferred A-form-like conformations with the χ revision rather than
random coils.
As described in Subheading 2.3, α and γ torsional parameters of
RNA have also been re-parameterized [49]. When the revised α/γ
and χ torsional parameters were incorporated in the amber99 force
ﬁeld, dramatic improvements were observed in simulations of
single-stranded tetramers. In 10 μs MD simulations of single-
stranded RNA GACC, the major and minor conformations
(Fig. 6) were sampled even though the initial structure was the
unphysical intercalated state (Fig. 4a). Similar improvements were
observed in the MD simulations of single-stranded AAAA, CAAU,
CCCC, and UUUU due to the better description of the energy
landscapes (Fig. 8) [49]. Single-stranded RNA strands are more
complex than the RNA duplexes due to their ﬂexible nature. Thus,
correct description of RNA single strands with the revised AMBER
RNA force ﬁeld makes it possible to study exotic and complex RNA
systems.
3.3
RNA Repeat
Expansions
One of the main goals of RNA force ﬁelds is to make physically
meaningful predictions using different computational methods to
study biologically signiﬁcant RNA systems so that (1) theoretical
interpretations to biological and chemical processes are provided,
(2) an in-depth understanding of structure and dynamics is
achieved, and (3) new solutions in therapeutics and biotechnology
Fig. 7 One of the thermodynamic cycles treated with the revised χ torsional
parameters for the amber99 force ﬁeld [42]. ΔG1 and ΔG4 represent the
experimental duplex formation free energies of GGCC ! (GGCC)2, and
iGiGiCiC ! (iGiGiCiC)2, respectively, where iG and iC stand for isoguanosine
and isocytidine, which have amino and carbonyl groups transposed compared to
G and C. Similar to G and C, iG and iC form Watson-Crick-like iGiC base pairs
with three hydrogen bonds. The thermodynamic cycle must satisfy the equation
of ΔG1  ΔG4 ¼ ΔG3  ΔG2. By calculating ΔG3 and ΔG2 using TI approach,
one can benchmark RNA force ﬁelds
66
Ilyas Yildirim

are developed. Thus, each improvement in RNA force ﬁelds is
crucial to make predictions more reliable. There are many diseases
caused by anomalies in RNA transcripts [16]. For example, expan-
sions of r(CUG) and r(CCUG) repeats, which have periodic 1  1
UU and 2  2 CU/CU internal loop motifs, respectively, separated
by GC/GC base-pairs, are found in the noncoding regions of
mRNA and cause myotonic dystrophy type 1 (DM1) and type
2 (DM2), respectively [17]. These are neuromuscular diseases
characterized by muscle weakness and slow relaxation of muscles
after contraction. Because these expansions are in noncoding
regions, the diseases are caused by RNA gain-of-function mecha-
nism where proteins such as muscleblind-like 1 protein (MBNL1)
sequesters around the expanded RNA repeats. Another such dis-
ease, Huntington’s disease (HD), is caused by expansion of r(CAG)
repeats in the coding regions of mRNA, which are translated into
toxic polyglutamine (polyQ) proteins. These systems were studied
with the revised amber99 force ﬁelds to discover unique properties
of RNA repeat expansions, which can be utilized in drug design
[44, 49].
Fig. 8 Free energy disconnectivity graphs [63, 64] of single-stranded GACC RNA at 300 K using the revised α/γ
and χ torsional parameters [49] (a), and amber10 force ﬁeld, which includes the parameters of amber99 force
ﬁeld [22] with parmbsc0 [50] and chiOL3 [46] corrections (b). INT and AF stand for intercalated and A-form
states, respectively. Discrete path sampling (DPS) calculations [35] were performed to build these energy
landscapes. Note that amber10 over-stabilizes the unphysical intercalated states, while incorporation of α/γ
and χ torsional parameters in amber99 stabilizes the physical A-form over intercalated state. Adapted with
permission from ref. [49] (https://pubs.acs.org/doi/pdf/10.1021/acs.jpcb.7b00819). Further permissions
related to the material excerpted should be directed to the ACS
RNA Revisions of the AMBER Force Field
67

Initially, RNA CAG repeat expansions were investigated
[34]. It was discovered that the 1  1 AA internal loop motifs can
have both syn-anti and anti-anti orientations even though anti-anti
is known to be the global minimum for these loops. The reason for
observation of the syn-anti AA state in the X-ray structure is that
the ﬂanking uridine bases used to crystalize a model RNA duplex
with three CAG repeats interact with the terminal 1  1 AA loops.
Umbrella sampling calculations predicted that the syn-anti state in
1  1 AA internal loops is a local minimum with a free energy
0.9 kcal mol1 less stable than the anti-anti state (Fig. 9a). The
results are particularly intriguing because they indicate that the
1  1 AA loops in RNA CAG repeat expansions are dynamic and
can transform to local minima states shown in Fig. 9a when they
interact with small molecules and ligands. A similar result was
observed when 1  1 UU internal loops were studied in RNA
CUG repeat expansions (Fig. 9b). Even though the 2D free energy
landscape of 1  1 UU loops displays the same minima states
observed in 1  1 AA loops, the free energy values and energy
barriers are different (Fig. 9a). This is due to the different structural
preferences of purines and pyrimidines, where pyrimidines have a
higher preference for anti. All these results and studies are particu-
larly important because the thermodynamics of RNA repeat expan-
sions such as the 2D free energy landscapes (Fig. 9) could only be
generated using computational methods. Nevertheless, it is worth
reiterating that the reliability of the predictions depends on the
quality of the RNA force ﬁeld used, which is why constant revisions
in RNA force ﬁelds are required.
Designing bioactive molecules, which will target speciﬁc RNA
molecules, is one way to ameliorate RNA-based disease. In RNA
repeat expansion, the 1  1 and 2  2 internal loops are targets for
modulating the RNA function. For example, sequestration of
MBNL1 in RNA CUG and CCUG repeats can be inhibited with
small molecules or ligands, which speciﬁcally target the periodic
internal loops in these repeats. Disney and coworkers performed
quantitative high-throughput screening for several RNA repeat
expansions such as RNA CUG repeats to identify compounds
inhibiting r(CUG)-MBNL1 interaction by binding to either RNA
or protein [67]. Furthermore, the binding modes of several small
molecules targeting RNA CUG and CCUG repeat expansions were
predicted with a dynamic binding methodology [68, 69]. Interest-
ingly, studies of the binding modes of a substituted naphthyridine
that targets RNA CUG repeat expansions revealed that the global
minimum “g” in Fig. 9a, which is in anti-anti orientation, trans-
formed into the local minimum state, “e” (Fig. 9a) [69]. Results
suggest that the local minima states can be exploited if a small
molecule or ligand would stabilize that state (Fig. 9a). The pre-
dicted bound states are useful because they can suggest ways to
improve binding afﬁnities of small molecules.
68
Ilyas Yildirim

Fig. 9 (a) 2D (θ1,χ) PMF surfaces predicted for 1  1 AA and 1  1 UU base pairs for model systems
representing CAG and CUG repeat expansions using umbrella sampling (US) calculations. Reaction coordinates
of χ and θ1 are displayed in (b) and (c), respectively. χ represents rotation around the glycosidic bond, while θ
is a pseudotorsion deﬁned by the center-of-mass of the atom groups shown in (c) to mimic base ﬂipping/
opening. The predicted free energy landscapes in A for both 1  1 AA and 1  1 UU display 11 identical
minima where “g” is the global minimum representing the anti-anti state. Minima with χ ~ 50, and χ ~ 200
represent syn, and anti-states, respectively. There are three pathways for syn $ anti-transformation as
shown with black arrows in (a). Note that even though US calculations predicted 11 identical minima for both
systems, the free energy values of each state compared to “g” and the energy barriers in 1  1 AA and 1  1
UU are very different. This is due to the difference observed between purines and pyrimidines, where
pyrimidines prefer anti more than purines do [65]. Adapted with permission from ref. [66] (https://pubs.acs.
org/doi/abs/10.1021%2Facs.jctc.5b00728). Further permissions related to the material excerpted should be
directed to the ACS

4
Notes
1. When revising the parameters of torsion, it is crucial to create
smooth QM energy proﬁles, which require additional torsional
restraints. Otherwise, the results will include artifacts coming
from other force ﬁeld parameters.
2. The vector β has a term, Eopt, which is a constant requiring
optimization due to the energy difference observed between
QM and MM calculations. The whole idea behind the torsional
revision process described in Subheading 2.1 is not to mimic
the QM energies but the energy landscapes. As a result, the
term (V1 + V2 + V3 + V4), which is a constant, is implicitly
included in Eopt, too.
3. The original amber99 force ﬁeld [22] carried out the ab initio
calculations at MP2/6-3 1G*//HF/6-3 1G* level. Other
QM methods have been used by others to revise torsional
parameters, too [46, 47, 55].
4. While revising the torsional parameters of a force ﬁeld, it is
crucial that the model system closely represents the real struc-
ture. Otherwise, the energy landscapes will not be correct, and
the conformational transformation pathways will not be cap-
tured properly.
5. As highlighted in Note 4 earlier, the proper description of the
energy landscapes requires reasonably correct model systems.
There has been a trend to transfer DNA parameters to RNA to
describe the missing force ﬁeld parameters. The α/γ parameters
developed for DNA is one such parameter set, which worked
well to describe regular RNA duplexes. Nevertheless, the limi-
tation of parmbsc0 in RNA showed up in more challenging
RNA systems such as single-stranded RNA tetramer simula-
tions described in Subheading 3.2. The revision of α/γ para-
meters for RNA described in Subheading 2.3 corrected the
issues seen in single-stranded RNA simulations. Results indi-
cate that separate revisions are required when studying mod-
iﬁed nucleic acid residues.
6. While studying adenosine and guanosine mononucleosides
using NMR spectroscopy, aggregates were observed in the
NMR samples that indicated stacking and/or base interactions.
As a result, the predictions of purines could not be compared to
experiments. Previous work done by others indicated that pur-
ines favor anti-orientations [65]. Nonetheless, it is not clear if
these results eliminated the purine-purine interactions arising
in solution.
7. The NMR data of single-stranded RNA UUUU are particu-
larly interesting because the dispersion of chemical shifts in
70
Ilyas Yildirim

UUUU is much less than that in AAAA and CAAU, an indica-
tion that UUUU is dynamic [60]. The results imply that
UUUU tetramer samples non-A-form conformations more
than AAAA and CAAU.
Acknowledgments
I would like to thank the Department of Chemistry and Biochem-
istry, Florida Atlantic University, for ﬁnancial support, and Prof.
Douglas H. Turner for valuable suggestions while writing this book
chapter.
References
1. Batey RT, Rambo RP, Doudna JA (1999) Ter-
tiary motifs in RNA structure and folding.
Angew Chem Int Ed 38(16):2327–2343
2. Bishop JM (1983) Cellular oncogenes and ret-
roviruses. Annu Rev Biochem 52:301–354.
https://doi.org/10.1146/annurev.bi.52.
070183.001505
3. Gifford R, Tristem M (2003) The evolution,
distribution and diversity of endogenous retro-
viruses. Virus Genes 26(3):291–316. https://
doi.org/10.1023/a:1024455415443
4. Haller A, Souliere MF, Micura R (2011) The
dynamic nature of RNA as Key to understand-
ing riboswitch mechanisms. Acc Chem Res 44
(12):1339–1348.
https://doi.org/10.1021/
ar200035g
5. Smith AM, Fuchs RT, Grundy FJ, Henkin TM
(2010) Riboswitch RNAs Regulation of gene
expression by direct monitoring of a physiolog-
ical signal. RNA Biol 7(1):104–110
6. Sabot F, Schulman AH (2006) Parasitism and
the retrotransposon life cycle in plants: a hitch-
hiker’s guide to the genome. Heredity 97
(6):381–388.
https://doi.org/10.1038/sj.
hdy.6800903
7. Kable ML, Seiwert SD, Heidmann S, Stuart K
(1996) RNA editing: a mechanism for gRNA-
speciﬁed uridylate insertion into precursor
mRNA.
Science
273(5279):1189–1195.
https://doi.org/10.1126/science.273.5279.
1189
8. Hannon GJ (2002) RNA interference. Nature
418(6894):244–251
9. Kole R, Krainer AR, Altman S (2012) RNA
therapeutics: beyond RNA interference and
antisense oligonucleotides. Nat Rev Drug Dis-
cov
11(2):125–140.
https://doi.org/10.
1038/nrd3625
10. Birikh KR, Heaton PA, Eckstein F (1997) The
structure, function and application of the ham-
merhead
ribozyme.
Eur
J
Biochem
245
(1):1–16.
https://doi.org/10.1111/j.1432-
1033.1997.t01-3-00001.x
11. Frank DN, Pace NR (1998) Ribonuclease P:
unity and diversity in a tRNA processing ribo-
zyme.
Annu
Rev
Biochem
67:153–180.
https://doi.org/10.1146/annurev.biochem.
67.1.153
12. Cate JH, Gooding AR, Podell E, Zhou KH,
Golden BL, Kundrot CE, Cech TR, Doudna
JA (1996) Crystal structure of a group I ribo-
zyme domain: principles of RNA packing. Sci-
ence 273(5282):1678–1685
13. Patel DJ, Suri AK, Jiang F, Jiang LC, Fan P,
Kumar RA, Nonin S (1997) Structure, recog-
nition and adaptive binding in RNA aptamer
complexes.
J
Mol
Biol
272(5):645–664.
https://doi.org/10.1006/jmbi.1997.1281
14. Daniels DA, Chen H, Hicke BJ, Swiderek KM,
Gold L (2003) A tenascin-C aptamer identiﬁed
by tumor cell SELEX: systematic evolution of
ligands by exponential enrichment. Proc Natl
Acad
Sci
U
S
A
100(26):15416–15421.
https://doi.org/10.1073/pnas.2136683100
15. Cong L, Ran FA, Cox D, Lin SL, Barretto R,
Habib N, Hsu PD, Wu XB, Jiang WY, Marraf-
ﬁni LA, Zhang F (2013) Multiplex genome
engineering using CRISPR/Cas systems. Sci-
ence 339(6121):819–823. https://doi.org/
10.1126/science.1231143
16. Ashley CT, Warren ST (1995) Trinucleotide
repeat expansion and human disease. Annu
Rev Genet 29:703–728
17. Emery AEH (2002) The muscular dystrophies.
Lancet 359(9307):687–695
RNA Revisions of the AMBER Force Field
71

18. Greco
CM,
Berman
RF,
Martin
RM,
Tassone F, Schwartz PH, Chang A, Trapp
BD, Iwahashi C, Brunberg J, Grigsby J,
Hessl D, Becker EJ, Papazian J, Leehey MA,
Hagerman RJ, Hagerman PJ (2006) Neuropa-
thology of fragile X-associated tremor/ataxia
syndrome
(FXTAS).
Brain
129:243–255.
https://doi.org/10.1093/brain/awh683
19. Jin P, Duan RH, Qurashi A, Qin YL, Tian DH,
Rosser TC, Liu HJ, Feng Y, Warren ST (2007)
Pur alpha binds to rCGG repeats and modu-
lates repeat-mediated neurodegeneration in a
Drosophila model of fragile X tremor/ataxia
syndrome. Neuron 55(4):556–564. https://
doi.org/10.1016/j.neuron.2007.07.020
20. Verheij
C,
Bakker
CE,
Degraaff
E,
Keulemans
J,
Willemsen
R,
Verkerk
A,
Galjaard H, Reuser AJJ, Hoogeveen AT, Oos-
tra BA (1993) Characterization and localiza-
tion of the FMR-1 gene product associated
with
fragile
X
syndrome.
Nature
363
(6431):722–724
21. Verkerk A, Pieretti M, Sutcliffe JS, Fu YH,
Kuhl DPA, Pizzuti A, Reiner O, Richards S,
Victoria MF, Zhang FP, Eussen BE, Vanom-
men GJB, Blonden LAJ, Riggins GJ, Chastain
JL, Kunst CB, Galjaard H, Caskey CT, Nelson
DL, Oostra BA, Warren ST (1991) Identiﬁca-
tion of a gene (FMR-1) containing a CGG
repeat coincident with a breakpoint cluster
region exhibiting length variation in fragile X
syndrome. Cell 65(5):905–914
22. Cornell WD, Cieplak P, Bayly CI, Gould IR,
Merz KM, Ferguson DM, Spellmeyer DC,
Fox T, Caldwell JW, Kollman PA (1995) A
second generation force ﬁeld for the simulation
of proteins, nucleic acids, and organic mole-
cules. J Am Chem Soc 117(19):5179–5197
23. Jr MKAD, Brooks B, Brooks CL III, Nilsson L,
Roux
B,
Won
Y,
Karplus
M
(1998)
CHARMM: the energy function and its param-
etrization with an overview of the program. In:
Schleyer PR, Allinger NL, Clark T et al (eds)
The encyclopedia of computational chemistry,
vol 1. John Wiley & Sons, Chichester, pp
271–277
24. Scott WRP, Hunenberger PH, Tironi IG, Mark
AE, Billeter SR, Fennen J, Torda AE, Huber T,
Kruger P, van Gunsteren WF (1999) The
GROMOS biomolecular simulation program
package. J Phys Chem A 103(19):3596–3607
25. Shaw DE, Deneroff MM, Dror RO, Kuskin JS,
Larson RH, Salmon JK, Young C, Batson B,
Bowers
KJ,
Chao
JC,
Eastwood
MP,
Gagliardo J, Grossman JP, Ho CR, Ierardi DJ,
Kolossvary
I,
Klepeis
JL,
Layman
T,
McLeavey C, Moraes MA, Mueller R, Priest
EC,
Shan
YB,
Spengler
J,
Theobald
M,
Towles B, Wang SC (2008) Anton, a special-
purpose machine for molecular dynamics sim-
ulation. Commun ACM 51(7):91–97. https://
doi.org/10.1145/1364782.1364802
26. Bartels C, Karplus M (1997) Multidimensional
adaptive umbrella sampling: applications to
main chain and side chain peptide conforma-
tions. J Comput Chem 18(12):1450–1462.
https://doi.org/10.1002/(sici)1096-987x(
199709)18:12<1450::aid-jcc3>3.0.co;2-i
27. Virnau P, Muller M (2004) Calculation of free
energy through successive umbrella sampling. J
Chem Phys 120(23):10925–10930. https://
doi.org/10.1063/1.1739216
28. Babin V, Roland C, Darden TA, Sagui C
(2006) The free energy landscape of small pep-
tides as obtained from metadynamics with
umbrella sampling corrections. J Chem Phys
125(20):204909.
https://doi.org/10.1063/
1.2393236
29. Kastner J (2011) Umbrella sampling. Wiley
Interdiscipl
Rev
Comput
Mol
Sci
1
(6):932–942.
https://doi.org/10.1002/
wcms.66
30. Banavali NK, MacKerell AD (2002) Free
energy and structural pathways of base ﬂipping
in a DNA GCGC containing sequence. J Mol
Biol
319(1):141–160.
https://doi.org/10.
1016/s0022-2836(02)00194-8
31. Song K, Campbell AJ, Bergonzo C, de los
Santos C, Grollman AP, Simmerling C (2009)
An improved reaction coordinate for nucleic
acid base ﬂipping studies. J Chem Theory
Comput 5(11):3105–3113. https://doi.org/
10.1021/ct9001575
32. Hart K, Nystrom B, Ohman M, Nilsson L
(2005) Molecular dynamics simulations and
free energy calculations of base ﬂipping in
dsRNA. RNA 11(5):609–618. https://doi.
org/10.1261/rna.7147805
33. Giudice E, Varnai P, Lavery R (2003) Base pair
opening within B-DNA: free energy pathways
for GC and AT pairs from umbrella sampling
simulations.
Nucleic
Acids
Res
31
(5):1434–1443.
https://doi.org/10.1093/
nar/gkg239
34. Yildirim I, Park H, Disney MD, Schatz GC
(2013)
A
dynamic
structural
model
of
expanded RNA CAG repeats: a reﬁned X-ray
structure
and
computational
investigations
using Molecular Dynamics and Umbrella Sam-
pling
simulations.
J Am
Chem
Soc
135
(9):3528–3538.
https://doi.org/10.1021/
ja3108627
35. Wales DJ (2002) Discrete path sampling. Mol
Phys 100(20):3285–3305. https://doi.org/
10.1080/00268970210162691
72
Ilyas Yildirim

36. Isralewitz B, Gao M, Schulten K (2001)
Steered molecular dynamics and mechanical
functions of proteins. Curr Opin Struct Biol
11(2):224–230.
https://doi.org/10.1016/
s0959-440x(00)00194-9
37. Laio A, Gervasio FL (2008) Metadynamics: a
method to simulate rare events and reconstruct
the free energy in biophysics, chemistry and
material
science.
Rep
Prog
Phys
71
(12):126601.
https://doi.org/10.1088/
0034-4885/71/12/126601
38. Schlitter J, Engels M, Kruger P, Jacoby E,
Wollmer
A
(1993)
Targeted
molecular-
dynamics simulation of conformational change
- application to the t -- r transition in insulin.
Mol Simulat 10(2-6):291. https://doi.org/
10.1080/08927029308022170
39. Case DA, Betz RM, Cerutti DS, Cheatham TE,
Darden TA, Duke RE, Giese TJ, Gohlke H,
Goetz AW, Homeyer N, Izadi S, Janowski P,
Kaus J, Kovalenko A, Lee TS, LeGrand S, Li P,
Lin
C,
Luchko
T,
Luo
R,
Madej
B,
Mermelstein
D,
Merz
KM,
Monard
G,
Nguyen
H,
Nguyen
HT,
Omelyan
I,
Onufriev A, Roe DR, Roitberg A, Sagui C,
Simmerling CL, Botello-Smith WM, Swails J,
Walker RC, Wang J, Wolf RM, Wu X, Xiao L,
Kollman PA (2016) AMBER 16. University of
California, San Francisco, CA
40. Nymeyer H, Gnanakaran S, Garcia AE (2004)
Atomic simulations of protein folding, using
the
replica
exchange
algorithm.
Methods
Enzymol 383:119
41. Hamelberg D, Mongan J, McCammon JA
(2004) Accelerated molecular dynamics: a
promising and efﬁcient simulation method for
biomolecules.
J
Chem
Phys
120
(24):11919–11929.
https://doi.org/10.
1063/1.1755656
42. Yildirim I, Kennedy SD, Stern HA, Hart JM,
Kierzek R, Turner DH (2012) Revision of
AMBER
torsional
parameters
for
RNA
improves free energy predictions for tetramer
duplexes with GC and iGiC base pairs. J Chem
Theory Comput 8(1):172–181
43. Yildirim I, Stern HA, Tubbs JD, Kennedy SD,
Turner DH (2011) Benchmarking AMBER
force ﬁelds for RNA: comparisons to NMR
spectra
for
single-stranded
r(GACC)
are
improved by revised χ torsions. J Phys Chem
B 115(29):9261–9270
44. Yildirim I, Stern HA, Kennedy SD, Tubbs JD,
Turner DH (2010) Reparameterization of
RNA χ torsion parameters for the AMBER
force ﬁeld and comparison to NMR spectra
for cytidine and uridine. J Chem Theory Com-
put
6(5):1520–1531.
https://doi.org/10.
1021/ct900604a
45. Banas P, Hollas D, Zgarbova M, Jurecka P,
Orozco M, Cheatham TE, Sponer J, Otyepka
M (2010) Performance of molecular mechan-
ics force ﬁelds for RNA simulations: stability of
UUCG and GNRA hairpins. J Chem Theory
Comput 6(12):3836–3849. https://doi.org/
10.1021/ct100481h
46. Zgarbova M, Otyepka M, Sponer J, Mladek A,
Banas P, Cheatham TE, Jurecka P (2011)
Reﬁnement of the Cornell et al. nucleic acids
force ﬁeld based on reference quantum chemi-
cal calculations of glycosidic torsion proﬁles. J
Chem
Theory
Comput
7(9):2886–2902.
https://doi.org/10.1021/ct200162x
47. Ode H, Matsuo Y, Neya S, Hoshino T (2008)
Force ﬁeld parameters for rotation around chi
torsion axis in nucleic acids. J Comput Chem
29(15):2531–2542.
https://doi.org/10.
1002/jcc.21006
48. Frisch MJ, Trucks GW, Schlegel HB, Scuseria
GE, Robb MA, Cheeseman JR, Montgomery
JA Jr, Vreven T, Kudin KN, Burant JC, Millam
JM,
Iyengar
SS,
Tomasi
J,
Barone
V,
Mennucci B, Cossi M, Scalmani G, Rega N,
Petersson
GA,
Nakatsuji
H,
Hada
M,
Ehara M, Toyota K, Fukuda R, Hasegawa J,
Ishida M, Nakajima T, Honda Y, Kitao O,
Nakai H, Klene M, Li X, Knox JE, Hratchian
HP, Cross JB, Bakken V, Adamo C, Jaramillo J,
Gomperts R, Stratmann RE, Yazyev O, Austin
AJ, Cammi R, Pomelli C, Ochterski JW, Ayala
PY, Morokuma K, Voth GA, Salvador P, Dan-
nenberg JJ, Zakrzewski VG, Dapprich S,
Daniels AD, Strain MC, Farkas O, Malick
DK, Rabuck AD, Raghavachari K, Foresman
JB, Ortiz JV, Cui Q, Baboul AG, Clifford S,
Cioslowski J, Stefanov BB, Liu G, Liashenko A,
Piskorz P, Komaromi I, Martin RL, Fox DJ,
Keith
T,
Al-Laham
MA,
Peng
CY,
Nanayakkara A, Challacombe M, PMW G,
Johnson B, Chen W, Wong MW, Gonzalez C,
Pople JA (2004) Gaussian 03. revision C.02
edn. Gaussian, Inc., Wallingford, CT
49. Wales DJ, Yildirim I (2017) Improving compu-
tational predictions of single-stranded RNA
tetramers with revised α/γ torsional parameters
for the amber force ﬁeld. J Phys Chem B 121
(14):2989–2999
50. Perez A, Marchan I, Svozil D, Sponer J, Chea-
tham TE, Laughton CA, Orozco M (2007)
Reﬁnement of the AMBER force ﬁeld for
nucleic acids: improving the description of
alpha/gamma
conformers.
Biophys
J
92
(11):3817–3829
51. Chen AA, Garcia AE (2013) High-resolution
reversible folding of hyperstable RNA tetra-
loops using molecular dynamics simulations.
Proc
Natl
Acad
Sci
U
S
A
110
RNA Revisions of the AMBER Force Field
73

(42):16820–16825.
https://doi.org/10.
1073/pnas.1309392110
52. Bergonzo C, Cheatham TE (2015) Improved
force ﬁeld parameters lead to a better descrip-
tion of RNA structure. J Chem Theory Com-
put
11(9):3969–3972.
https://doi.org/10.
1021/acs.jctc.5b00444
53. Gil-Ley A, Bottaro S, Bussi G (2016) Empirical
corrections to the amber RNA force ﬁeld with
target metadynamics. J Chem Theory Comput
12(6):2790–2798. https://doi.org/10.1021/
acs.jctc.6b00299
54. Deb I, Pal R, Sarzynska J, Lahiri A (2016)
Reparameterizations of the chi torsion and
Lennard-Jones sigma parameters improve the
conformational characteristics of modiﬁed uri-
dines. J Comput Chem 37(17):1576–1588.
https://doi.org/10.1002/jcc.24374
55. Aytenﬁsu AH, Spasic A, Grossﬁeld A, Stern
HA, Mathews DH (2017) Revised RNA dihe-
dral parameters for the amber force ﬁeld
improve RNA molecular dynamics. J Chem
Theory Comput 13(2):900–915
56. Tan D, Piana S, Dirks RM, Shaw DE (2018)
RNA force ﬁeld with accuracy comparable to
state-of-the-art protein force ﬁelds. Proc Natl
Acad
Sci
U
S
A
115(7):E1346–E1355.
https://doi.org/10.1073/pnas.1713027115
57. Doornbos J, Wreesmann CTJ, Boom JH,
Altona C (1983) Conformational analysis of
the single-stranded ribonucleic acid AACC. A
one-dimensional and two-dimensional proton
NMR study at 500 MHz. Eur J Biochem 131
(3):571–579.
https://doi.org/10.1111/j.
1432-1033.1983.tb07301.x
58. Isaksson J, Acharya S, Barman J, Cheruku P,
Chattopadhyaya J (2004) Single-stranded ade-
nine-rich DNA and RNA retain structural char-
acteristics of their respective double-stranded
conformations and show directional differ-
ences in stacking pattern. Biochemistry 43
(51):15996–16010
59. Kierzek
E,
Pasternak
A,
Pasternak
K,
Gdaniec Z, Yildirim I, Turner DH, Kierzek R
(2009) Contributions of stacking, preorgani-
zation, and hydrogen bonding to the thermo-
dynamic stability of duplexes between RNA
and 20-O-methyl RNA with locked nucleic
acids.
Biochemistry
48(20):4377–4387.
https://doi.org/10.1021/bi9002056
60. Condon
DE,
Kennedy
SD,
Mort
BC,
Kierzek R, Yildirim I, Turner DH (2015)
Stacking in RNA: NMR of four tetramers
benchmark molecular dynamics. J Chem The-
ory Comput 11(6):2729–2742. https://doi.
org/10.1021/ct501025q
61. Tubbs
JD,
Condon
DE,
Kennedy
SD,
Hauser M, Bevilacqua PC, Turner DH (2013)
NMR of CCCC RNA reveals a right-handed
helix and revised parameters for AMBER force
ﬁeld torsions improve structural predictions
from molecular dynamics (vol 52, 996, 2013).
Biochemistry 52(19):3390–3392. https://doi.
org/10.1021/bi400401j
62. Tubbs
JD,
Condon
DE,
Kennedy
SD,
Hauser M, Bevilacqua PC, Turner DH (2013)
The nuclear magnetic resonance of CCCC
RNA reveals a right-handed helix, and revised
parameters for AMBER force ﬁeld torsions
improve structural predictions from molecular
dynamics.
Biochemistry
52(6):996–1010.
https://doi.org/10.1021/bi3010347
63. Wales DJ, Miller MA, Walsh TR (1998) Arche-
typal
energy
landscapes.
Nature
394
(6695):758–760.
https://doi.org/10.1038/
29487
64. Becker OM, Karplus M (1997) The topology
of multidimensional potential energy surfaces:
theory and application to peptide structure and
kinetics. J Chem Phys 106(4):1495–1517.
https://doi.org/10.1063/1.473299
65. Davies DB (1978) Conformations of nucleo-
sides and nucleotides. Prog Nucl Magn Reson
Spectrosc 12:135–225
66. Yildirim I, Chakraborty D, Disney MD, Wales
DJ, Schatz GC (2015) Computational investi-
gation of RNA CUG repeats responsible for
myotonic dystrophy 1. J Chem Theory Com-
put 11(10):4943–4958. https://doi.org/10.
1021/acs.jctc.5b00728
67. Disney MD, Yildirim I, Childs-Disney JL
(2014) Methods to enable the design of bioac-
tive small molecules targeting RNA. Org Bio-
mol
Chem
12(7):1029–1039.
https://doi.
org/10.1039/c3ob42023j
68. Childs-Disney JL, Yildirim I, Park H, Lohman
JR, Guan L, Tran T, Sarkar P, Schatz GC, Dis-
ney MD (2014) Structure of the myotonic
dystrophy type 2 RNA and designed small
molecules that reduce toxicity. ACS Chem
Biol
9(2):538–550.
https://doi.org/10.
1021/cb4007387
69. Childs-Disney
JL,
Stepniak-Konieczna
E,
Tuan T, Yildirim I, Park H, Chen CZ,
Hoskins J, Southall N, Marugan JJ, Patnaik S,
Zheng W, Austin CP, Schatz GC, Sobczak K,
Thornton CA, Disney MD (2013) Induction
and
reversal
of
myotonic
dystrophy
type
1 pre-mRNA splicing defects by small mole-
cules. Nat Commun 4:2044. https://doi.org/
10.1038/ncomms3044
74
Ilyas Yildirim

Chapter 4
Quantum Chemical and QM/MM Models in Biochemistry
Patricia Saura, Michael Ro¨pke, Ana P. Gamiz-Hernandez,
and Ville R. I. Kaila
Abstract
Quantum chemical (QC) calculations provide a basis for deriving a microscopic understanding of enzymes
and photobiological systems. Here we describe how QC models can be used to explore the electronic
structure, dynamics, and energetics of biomolecules. We introduce the hybrid quantum mechanics/classical
mechanics (QM/MM) approach, where a quantum mechanically described system of interest is embedded
in a classically described force ﬁeld representation of the biochemical surroundings. We also discuss the QM
cluster model approach, as well as embedding theories, that provide complementary methodologies to
model quantum mechanical effects in biomolecules. The chapter also provides some practical guides for
building quantum biochemical models using the quinone reduction catalysis in respiratory complex I and a
model reaction in solution as examples.
Key words Quantum biochemistry, QM cluster models, DFT, Enzyme catalysis, Photobiology,
Proton transfer, Oxidoreductase, Bioenergetics
1
Introduction
Several biological processes are based on quantum mechanical
effects. Enzymes catalyze biochemical reactions by lowering the
free energy barrier for bond-formation and bond-breaking pro-
cesses. Photobiological systems capture light quanta of a certain
energy that electronically excite their chromophores, and oxidor-
eductases transfer electrons across large distances by quantum
mechanical tunneling effects. Although some aspects of these pro-
cesses can be studied by classical atomistic simulation techniques
(see Chapter 1), a rigorous quantitative description requires quan-
tum mechanical (QM) models that are based on solving approx-
imations of the Schro¨dinger equation for the biomolecular system
of interest.
The exact Schro¨dinger equation cannot be solved for large
molecular systems, but several computationally efﬁcient approxi-
mations have been developed in the last decades, providing the
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_4, © Springer Science+Business Media, LLC, part of Springer Nature 2019
75

basis for quantum biochemical modeling. Since the development
of quantum mechanics in the 1920s, there has been a profound
interest to apply QM calculations to derive a detailed understand-
ing of biochemical systems. In his famous book from 1944, Schro¨-
dinger discussed the quantum and statistical mechanical basis of
biology [1], whereas the Pullmans [2] introduced the concept of
“quantum biochemistry” in the early 1960s. Moreover, Lo¨wdin,
one of the founding fathers of quantum chemistry, proposed in
1963 that proton tunneling between nucleobases could contribute
as a possible mechanism for mutations in DNA [3]. Quantum
mechanical calculations have also been applied to study several
photobiological systems, for example, the retinal visual pigment
of rhodopsin, since the early 1970s [4, 5], and continue to be an
active research area till today [6, 7].
In modern QM calculations, the accurate approximations
within density functional theory (DFT), which we will review in
Subheading 2 of this chapter, have revolutionized the ﬁeld allowing
chemical accuracy at a feasible computational cost. Nowadays, it is
possible to model 100–1000 atoms at the DFT level that allows to
study the central parts of biochemical interesting systems, for
example, an enzyme active site or a light-capturing chromophore
and its nearest chemical surroundings at a QM level [7, 9, 10]. In
addition to “ﬁrst principles” methods, introducing further approx-
imations through parametrization of certain contributions to the
electronic energy in the so-called semi-empirical quantum chemical
methods can be used to further lower the computational cost. It is
possible to increase both the size of the QM system (>1000 atoms)
and the simulation timescales (100–1000 ps) with semi-empirical
methods. For example, tight-binding DFT-based methods [8] have
thus remained important in the QM treatment of biochemical
systems (see Subheading 2). In recent years, computationally effec-
tive approximations have also been introduced within correlated ab
initio quantum chemical methods, which, together with ever-
increasing high-performance computing capacity, are making such
calculations feasible also for biochemical modeling. Particularly in
the ﬁeld of photobiology, coupled cluster-based methods [9, 10]
and multi-reference calculations [11] are employed in combination
with both QM and QM/MM models. Moreover, new develop-
ments in near-linear scaling coupled-cluster theory (DLPNO-
CCSD(T)) [12] have already found promising application in bio-
chemistry [13, 14].
Similar to atomistic classical molecular simulations, quantum
chemical calculations are employed in computational biochemistry
to predict the structure and relative energies between different
states of interest; to study the dynamics of equilibrium or nonequi-
librium states; to obtain potential energy or free energy proﬁles of
bond-breaking/formation process; and to compute molecular
properties, for example, optical or magnetic properties, which can
76
Patricia Saura et al.

be related UV–VIS or NMR/EPR spectra, based on molecular
dynamics trajectories or optimized structures. It is also important
to emphasize that QM methods allow modeling nonclassical
effects, such as electron spin, which is central for the function of
many metalloenzymes.
Three hierarchies of QM models are normally considered
(Fig. 1): in the quantum chemical cluster model approach, the
chemically relevant part of the system is explicitly treated with
QM methods, whereas the surrounding is modeled as an implicit
polarizable medium. In contrast, QM/MM approaches embed and
polarize the explicitly modeled central QM part by a force ﬁeld
(MM) representation of the surroundings. In addition to the clus-
ter- and QM/MM models, a QM region of interest can also be
embedded in a frozen electron density representation of the sur-
roundings, a methodology known as frozen density embedding
theory (FDET).
1.1
Quantum
Chemical Cluster
Models
In the QM cluster model approach, both the chemically relevant
active system of interest and the ﬁrst- and second-solvation sphere
are explicitly included in the model. For protein systems, the amino
acid side chains are usually included in the model by cutting the
amino acid at the Cα-Cβ bond and saturating the terminated bond
by a hydrogen-capping atom (Fig. 1b). Terminal parts of the model
are ﬁxed to mimic the strain arising from the protein framework,
and the surroundings are modeled using a polarizable dielectric
medium with a low dielectric constant, for example, ε ¼ 4, when
Fig. 1 Three quantum chemical models of an enzyme active site (NADH:ubiquinone oxidoreductase, complex I).
(a) QM/MM model with the QM atoms shown in CPK representation and the MM surroundings shown as a
cartoon representation. Link atoms are shown as pink spheres. (b) QM cluster model with the surroundings
represented by a polarizable medium with ε ¼ 4. Atoms that are kept ﬁxed during structure optimization are
marked with an asterisk. (c) Frozen density embedding model constructed based on (b). The quinone and
nearest residues are represented in the active site. The surroundings are represented by a frozen electron
density shown in surface representation
QM/MM Models in Biochemistry
77

modeling buried parts of a protein. It has been shown that struc-
tures, molecular properties, and energetics usually converge with
increasing cluster size [15–17], which we will illustrate by a practi-
cal example below (see Subheading 5). Moreover, for converged
cluster models, the choice of the dielectric constant does not sig-
niﬁcantly affect computed barriers and energetics, as the chemical
surroundings are modeled explicitly [18]. Convergence of the
cluster models suggests that chemical properties of many biochem-
ical systems are determined by local interactions. There are, how-
ever, also interesting systems where residues far away from the
active site have large effects on catalytic properties (cf. [19, 20]).
The structural ﬂexibility of proteins adds another challenge to
the construction of QM cluster models, since experimentally
resolved structures usually provide one snapshot of the active
phase space accessible to the protein. It can thus be important to
combine QC studies with classical atomistic simulations and rare-
sampling techniques to probe chemically relevant states and struc-
tures (see below).
A beneﬁt of the QM cluster approach is that a computational
model with a few hundred atoms can be geometry optimized with
standard optimization algorithms, and one can thus compare total
electronic energies between different states of interest. Moreover,
computation of the molecular Hessian is usually possible, which can
be used to determine transition state structures and estimate entro-
pic effects. The bottom-up philosophy of the QM cluster models
thus provides a systematic approach to increase the model size until
the properties of interest converge. When a QM model reproduces
the target properties, it thus also provides a simple analysis of the
underlying chemistry of the system. However, certain effects such
as long-range electrostatics can be challenging to capture in small
models, and uneven charge distribution within the QM system can
lead to highly charged cluster models, where the electrons are
loosely bound. Constructing a QM cluster model that captures all
relevant chemical effects can therefore require experience and
chemical intuition. To this end, usually, the nearest residue neigh-
bors and groups directly interacting with the site of interest should
be included. In particular, charged residues up to 10 A˚ away can
have a signiﬁcant inﬂuence on the computed energetics, especially if
the site of interest is in a typical protein interior. At such distances, a
Coulombic interaction is ca. 8 kcal mol1 (Eel  332 kcal mol1 A˚ /
ε r[A˚ ]). In addition to residue proximity, it can also be important to
consider residue conservation based on bioinformatics analysis, as
well as data from site-directed mutagenesis experiments to guide
the model building.
1.2
Hybrid QM/MM
Methods
In the QM/MM approach, the central QM region is embedded and
polarized by a classical description of the surrounding system.
Similar as in QM cluster models, the surrounding protein
78
Patricia Saura et al.

framework must be separated and cut from the QM system
(Fig. 1a). To this end, the amino acids are normally terminated
between the Cα-Cβ bond and saturated by a hydrogen-capping
atom, similar as in the QM cluster models, to avoid electrons
from leaking to the unsaturated bond. The link atoms are only
explicitly considered in the QM calculations and are made “invisi-
ble” from the MM region, and charges next to the boundary region
are normally redistributed to reduce errors in electrostatics at the
boundary (see Fig. 1a, inset). Apart from link atoms, frozen loca-
lized orbitals can also be employed to prevent electrons from leak-
ing
to
the
unsaturated
bond,
which
is
implemented
by
modiﬁcations in the electronic structure code. Benchmarking cal-
culations, however, suggest that the accuracy of the link atom and
frozen localized orbitals approaches is comparable [21], and when
constructing the QM/MM models, it is important to consider that
the boundary region between the QM and MM subsystems always
introduces an error in the calculation. The boundary region should
therefore be placed as far as computationally feasible from the active
center of interest. Moreover, similar as in QM cluster models, the
intrinsic properties and energetics of the QM/MM models con-
verge with increasing system size, although somewhat faster, as the
surroundings are modeled explicitly (see Subheading 5).
QC calculations rely on structure optimization techniques,
which are technically simpler for systems comprising a few hundred
atoms than for large protein-water-ion models with 104–106
atoms, for which it is in practice impossible to ﬁnd a global mini-
mum. In addition, the ﬂat energy landscape of complex biological
systems can prevent a large QM/MM model from reaching con-
vergence. To overcome this challenge, it is common to optimize a
smaller boundary region in the QM/MM calculations, whereas
atoms beyond a certain distance threshold from the active QM
region are kept frozen. To help converging QM/MM structure
optimizations, micro-iterative optimization schemes have also been
developed [22], in which the structure optimization is performed
by consecutively allowing the QM and MM regions (within a
certain distance threshold) to relax, while the other system is kept
frozen. The different variants of the QM/MM approach are pre-
sented in the theory Subheading 2. In contrast to QM cluster
models, all boundary region atoms are normally allowed to move
in QM/MM simulations, as the surrounding system is represented
explicitly. However, due to challenges to converge QM/MM struc-
tures, QM/MM molecular dynamics simulations and QM/MM
free energy calculations provide powerful alternatives to explore
the free energy surface.
1.3
Frozen Density
Embedding Approach
In the frozen density embedding (FDE) method, the classical force
ﬁeld representation of the surroundings is replaced by a ﬁxed
electron density distribution, which is not optimized during the
QM/MM Models in Biochemistry
79

electronic structure calculations (Fig. 1c). In contrast to QM/MM
approaches, the surrounding system polarizes the active region in
addition to electrostatic interactions between the two electron
density distributions, also by accounting for the Pauli-exchange
interactions and a kinetic energy contribution between the two
subsystems (see Subheading 2). In practice, the embedding calcula-
tions are often performed using a cluster model approach, since it is
challenging to split covalent bonds in the embedding calculations.
Moreover, until recently, gradients have not been available, which
prevented geometry optimizations of density-embedded struc-
tures. FDE-calculations and other fragment based-embedding
modes have been particularly important in studies of light-
capturing and charge-separation processes in biology [23–25].
1.4
General
Considerations
As mentioned above, it is challenging in QM modeling of biochem-
ical systems to capture rare but functionally important conﬁgura-
tions, since the sampling timescales available with these methods
are several orders of magnitude shorter than for classical molecular
dynamics simulations (i.e., picoseconds instead of microseconds).
It is possible to employ, for example, QM/MM free energy simula-
tion approaches or resort to lower but computationally more
efﬁcient QM-theory levels. To this end, semi-empirical QM calcu-
lations or even classical empirical reference potentials [26] can be
employed, followed by perturbation theory computations to map
the higher level free energy surface, an approach that has been
developed and employed to large extent by Warshel and coworkers.
However, for such an approach to be feasible, it is important that
the lower theory level predicts at least qualitatively a similar reaction
mechanism as the higher theory level, which is not always the case
(see, e.g., [27]). To sample chemically relevant structures, it is also
possible to combine QM/MM or QM calculations with large-scale
classical molecular dynamics simulations. For example, QC models
can be constructed based on equilibrium or nonequilibrium states
from microsecond MD simulations (see Fig. 3 and below).
Historically, both QC cluster and QM/MM calculations have
been performed in biomolecular systems since the 1970s. The ﬁrst
QM/MM calculation was performed in 1976 by Warshel and
Levitt [28], studying the stability of the carbonium cation in lyso-
zyme, and how it is employed in the splitting of glycosidic bonds.
The QM region comprised the carbonium cation and was treated at
semi-empirical level (QCFF/PI—Quantum mechanical extension
of the Consistent Force Field method to PI electron molecules and
the MNDO2 method). Warshel and Levitt further coupled the QM
region to the MM part, used to treat the rest of the enzyme, by
using an additive QM/MM scheme. The QM/MM methodology
was further developed by several groups [22, 29–31] to include
both subtractive and additive schemes with mechanical, electro-
static, and polarizable embedding approaches that are introduced
80
Patricia Saura et al.

in Subheading 2, in combination with several different QM theory
levels.
Many research groups [15, 32–35] have also been actively
involved in developing quantum chemical cluster models for
enzymes, with important contributions from, for example, Blom-
berg and Siegbahn [36], and Himo and coworkers [37]. The
frozen-density embedding approach was originally developed by
Wesolowski and Warshel [38] in the early 1990s with important
contributions from several groups [23, 25, 39]. FDET calculations
have been employed in particular to study light- and charge-
transport effects in biology [6, 40]. The important recognition
for the ﬁeld came from the 2013 Nobel Prize in chemistry, which
was awarded to Arieh Warshel, Michael Levitt, and Martin Karplus,
for their contribution to the development of QM/MM and other
multi-scale models for the treatment of chemical and biochemical
systems.
This chapter is organized as follows: after reviewing the theory
of QM models in biochemistry, we present an introduction to both
hybrid QM/MM and QM models by illustrating practical aspects
of such calculations. To this end, we consider the catalytic proper-
ties of the quinone reduction site in respiratory complex I (NADH:
ubiquinone oxidoreducase), an enzyme that functions as an initial
electron acceptor in aerobic respiratory chains of bacteria and
eukaryotes. Complex I reduces ubiquinone (Q) to ubiquinol
(QH2) by electrons that originate from NADH. The quinone
reduction further couples to the proton pumping in the membrane
domain. The reader can ﬁnd mechanistic suggestions derived from
multi-scale simulations on these systems in our recent works
[41–43]. In addition to our example on complex I, we also illus-
trate QM/MM free energy calculations and their relation to con-
tinuum QC cluster models for a simple organic model reaction in
solution.
2
Theory
2.1
Brief
Introduction to Density
Functional Theory
Density functional theory (DFT) provides an important computa-
tional framework for modern quantum biochemical modeling.
DFT is based on the fundamental theorems by Hohenberg and
Kohn, showing that the electron density, ρ, is a unique representa-
tion of the molecular system, similar to the wavefunction in the
Schro¨dinger equation. However, in contrast to the 3N-dimensions
of the wavefunction, the electron density depends on only three
spatial coordinates (and one spin coordinate). Later, Kohn and
Sham introduced molecular orbitals and an electron density that
can be written in terms of a noninteracting system, with exactly the
same electron density as in the interacting one into the framework
QM/MM Models in Biochemistry
81

of DFT. This allows the total energy to be written as a functional of
the density ρ,
E ρ½  ¼ T s ρ½  þ J ρ½  þ Ene ρ½  þ Exc ρ½ ,
ð1Þ
where Ts[ρ] is the kinetic energy functional of the noninteracting
system, J[ρ] is the classical Coulombic interaction between elec-
trons, Ene[ρ] is the interaction between nuclei and electrons, and
Exc[ρ] is the so-called exchange-correlation term. The exact form of
the Exc[ρ] term is unknown, but commonly employed approxima-
tions are discussed below. The exchange-correlation term is a mea-
sure of the difference in the kinetic energy between the interacting
(T[ρ]) and noninteracting (Ts[ρ]) systems, as well as the difference
in electron correlation and classical Coulombic interaction between
the two systems,
Exc ρ½  ¼ T ρ½   T s ρ½ 
ð
Þ þ V ee ρ½   J ρ½ 
ð
Þ,
ð2Þ
where Vee[ρ] is the quantum mechanical electron–electron interac-
tion term. For a one-electron system, for example, H2
+, J[ρ], and
Exc[ρ] of Eq. 1 should exactly cancel out, as they do in the mean-
ﬁeld Hartree-Fock theory. However, this is not satisﬁed for most
density functionals, a property known as electron self-interaction
error (SIE). Interestingly, functionals designed to minimize the SIE
tend to have larger errors in benchmarking tests. It has been
speculated that the SIE might emulate multi-reference effects
within DFT (see below for other challenges within DFT).
Modern density functionals provide approximations to the
exchange-correlation term, Exc[ρ], following the “Jacob’s ladder,”
a concept introduced by Perdew [44], where each rung introduces
more physics into the functional. The simplest local density approx-
imation (LDA) describes the exchange-correlation (xc) term based
only on the (local) electron density itself. This approximation is,
however, not very accurate for molecules, which are strongly polar-
ized in comparison to a uniform electron gas. LDA should thus not
be used for describing molecules but still has important applications
in solid state physics, and it also provides a central ingredient for
other functionals. At the next rung on Jacob’s ladder, the xc-term
depends in addition to the electron density, also on its gradient, ∇ρ,
an approximation known as the generalized gradient approxima-
tions (GGAs). GGAs, such as BLYP, BP86, and PBE, are com-
monly used in biomolecular modeling, as they perform well in
predicting molecular structures, with an error of ca. 0.05 A˚ in
bond distances, and energetics with 5–15 kcal mol1, based on
benchmarking calculations [45].
The next rung introduces a Laplacian-dependence of the elec-
tron density or the numerically simpler kinetic energy operator,
|∇ϕ|2, which includes some nonlocal effects into the exchange-
correlation functional, an approximation known as meta-GGA.
82
Patricia Saura et al.

The TPSS functional [46] and its hybrid variant, TPSSh, perform
well for transition metal complexes [47, 48] and have been used to
study the electronic structure of, for example, the highly challeng-
ing Mn4O5Ca center of photosystem II [49] and iron-sulfur cen-
ters in hydrogenases [50].
The fourth rung along the Jacob’s ladder introduces exact
exchange from Hartree-Fock theory that replaces some electron
gas exchange [51]. Becke’s three-parameter functional with Lee-
Yang-Parr correlation, B3LYP, is one of the most popular hybrid
density functionals employed in quantum biochemical chemical
calculations,
EB3LYP
xc
¼ 1  a
ð
ÞELSDA
x
þ aE HF
x
þ bΔEB88X
x
þ 1  c
ð
ÞELSDA
c
þ cE LYP
c
ð3Þ
where a ¼ 0.2, b ¼ 0.72, c ¼ 0.81. Ex and Ec are the exchange and
correlation terms, respectively, and LSDA refers to the local-spin
density approximation. Benchmarking calculations suggest that the
B3LYP functional has a mean error of <0.05 A˚ in bond distances
and energetics within 3–5 kcal mol1 accuracy [52].
The ﬁfth rung within DFT is the random phase approximation
(RPA), where the correlation energy is modeled by considering
excitations to virtual orbitals, which results in a formal N5 scaling
of the functional. RPA functionals have not yet been extensively
employed in biochemical modeling, but it has been shown that they
provide promising methods to treat transition metal complexes
[53]; thus, they are likely to become important for modeling, for
example, metalloenzymes.
To reduce the computational cost of two-electron four-center
integrals, it is possible to introduce a multipole resolution of iden-
tity approximation or Cholesky decomposition, which effectively
reduces the formal computational cost of the DFT calculations
from N4 to N3 for a system with N basis functions (see below).
Several linear-scaling approximations have also been introduced in
recent years. These methods also lower the computational cost by
speeding up the evaluation of four-center two-electron integrals
required for treating electron-electron interactions. This can be
achieved, for example, by introducing a distance-dependent
Schwarz-based
integral
screening
estimator
[54].
In
such
approaches, the Coulombic matrix is divided into near- and
far-ﬁeld contributions, solving the latter part using fast multipole
methods. Moreover, for evaluation of the time-consuming exact
exchange part, it is possible to utilize the PreLink-algorithm [55],
in which preselection allows for an asymptotic linear scaling, while
retaining accuracy. The linear-scaling behavior results from the
exponential decay of density matrix elements for systems with a
non-vanishing HOMO-LUMO gap, which can be difﬁcult to
achieve
for
very
large
QM
models
with
standard
density
QM/MM Models in Biochemistry
83

functionals. Similarly as for atomistic classical molecular simula-
tions, a computational speedup can also be obtained from massively
parallel architectures, such as GPUs, which are based on ﬁne-
grained data arrangements [56] and have thus promising applica-
tions for biochemical systems in the near future.
In addition to these approaches, semi-empirical approxima-
tions can also be introduced within DFT to reduce its computa-
tional cost. In the tight-binding DFT approximation (DFTB), the
Kohn-Sham energy expression for a reference density, ρ0, of a
neutral molecule is expanded as a Taylor series
E ρ½  ¼ E0 ρ0
½
 þ E1 ρ0; δρ
½
 þ E2 ρ0; δρ
ð
Þ2
h
i
þ E3 ρ0; δρ
ð
Þ3
h
i
þ   
ð4Þ
For example, in the self-consistent charge variant, SCC-DFTB
(also known as DFTB2), the energy is expanded to second order,
and Mulliken charges are employed to model the electron density.
The DFTB functionals are parameterized based on DFT calcula-
tions, for example, at the PBE/DZP level. SCC-DFTB and
SCC-DFTB/MM calculations have been employed to treat several
biochemical systems with promising benchmarking results, for
which the reader is encouraged to consult recent reviews [57].
2.2
Basis Sets
Electrons are described in electronic structure calculations by basis
sets formed by a linear combination of atomic orbitals to give
molecular orbitals (LCAO-MO),
ϕi ¼ Σiciχi,
ð5Þ
where the atomic orbital coefﬁcients, ci, of the atomic orbitals, χi,
are optimized in single-reference electronic structure calculations
to give molecular orbitals, ϕi. In multi-reference calculations, for
example, the complete active space self-consistent ﬁeld (CASSCF)
method, which has many important photobiological applications,
both the orbital coefﬁcients and the atomic orbitals themselves are
optimized. Today, it is possible to treat ca. 16 active electrons in
16 active orbitals, which enables correlation of, for example, all
retinal π-electrons, but new density matrix renormalization group
(DMRG) methods are pushing these limits further [58]. We will
here, however, only consider single reference methods, and the
reader should consult specialized reviews for further information
on multi-reference calculations [59].
Gaussian functions are usually employed to model the electrons
in the electronic structure calculations, since analytical expressions
for the two-electron four-center integrals can be employed. The
Gaussian-type orbitals (GTOs) are deﬁned as
χ r; θ; ϕ
ð
Þ ¼ NY lm θ; ϕ
ð
Þxiy jzkexp γr2


,
ð6Þ
84
Patricia Saura et al.

where i þ j þ k ¼ 0 for s-functions, 1 for p-functions etc., r is the
distance between the electrons, N is a normalization coefﬁcient,
and Ylm(θ,ϕ) are the spherical harmonics for angular and magnetic
quantum numbers l and m. Some electronic structure codes, such
as ADF, also employ Slater type orbitals (STOs) with exp
[γr]. Due to lack of analytic integral expressions for such func-
tions, the integrations are performed numerically in such cases. In
addition, functions of other types, such as plane-waves, are com-
monly used in material science to model electrons.
GTOs do not have the correct long-range decay or the correct
cusp-behavior at the nucleus, and it is therefore necessary to
employ more than one Gaussian function to represent the correct
electron density in each orbital. In double-zeta (DZ) basis sets,
each function is described by two Gaussians, whereas in triple-
zeta (TZ) basis sets, three Gaussians are employed. Moreover,
since chemical properties are usually deﬁned by valence electrons,
it is possible to add more functions only to the valence shell. These
are known as split-valence (SV) basis sets. To account for proper
chemical hybridization, functions of higher angular momenta are
often introduced, for example, p-functions to model hydrogen, and
d- and f-function to model carbon. Polarization functions are
usually indicated with a “P” or a “*”, for example, cc-pVDZ,
def2-SVP, or 6-31G*. Some molecules such as anions or molecules
with Rydberg states can have loosely bound electrons, which can be
modeled with small exponents. Such diffuse functions are often
designated with an “aug” or “þ”, for example, aug-cc-pVTZ or
6-31G+G(d). DFT calculations usually require triple-zeta quality
basis sets (def2-TZVP or 6-311G**) to reach convergence in
electronic energies and molecular properties, whereas structure
optimization and dynamics are usually performed at the double-
zeta level. If metals are included in the system, it is recommended to
describe such elements with a triple zeta-level basis also for optimi-
zations and molecular dynamics. As shown for the proton transfer
reaction in the active site of complex I, the def2-SVP basis produces
an error of few kcal mol1 relative to the def2-TZVP basis set.
2.3
Known Problems
Within DFT and Their
Relevance for
Computational
Biochemistry
DFT has some known problems, which are important to consider
when modeling biochemical systems. Many biochemical systems
interact by dispersive forces, which arise from electron correlation
effects between two nonoverlapping densities. The rigorous mod-
eling of such effects requires the consideration of electronic excita-
tions between occupied and virtual orbitals between the two
fragments, as in coupled cluster theory of second order (CCSD)
and beyond, or in second-order perturbation treatment (e.g.,
MP2). However, the standard local functionals do not consider
such double excitations and therefore do not capture these disper-
sion effects. London showed in the 1930s that the dispersion
energy decays as 1/r6 with the distance, a functional form that is
QM/MM Models in Biochemistry
85

employed to model weak interactions also in biomolecular force
ﬁelds. In dispersion-corrected DFT by Grimme [60], the disper-
sion energy is simply added to the DFT electronic energy by a
simple empirical term,
EDFT‐D ¼ EDFT þ Edisp,
ð7aÞ
Edisp ¼ s6Σi,jC6
ij=rij
6f damp rij


,
ð7bÞ
where rij is the distance between two atoms, fdamp (rij) ¼ 1/(1 + exp
[d(rij/Rr  1)]), where parameters d and Rr vary the switching
distance for the dispersion correction, and s6 and C6 are element-
speciﬁc coefﬁcients. fdamp(rij) smoothly switches the dispersion
off at short distances since DFT captures short-range correlation
well. In comparison to correlated quantum chemical methods,
dispersion-corrected DFT, for example, DFT-D3, captures disper-
sive effects relatively well [60] and is recommended also for bio-
chemical applications.
When modeling the energetics of spin states, it is important to
consider that the amount of exact exchange affects the relative
energetics between a high-spin (HS) state compared to the
low-spin (LS) state, since the repulsion (J) of electrons of equal
spin are diminished by the Pauli exchange (K), that is, by “J-K.” To
this end, Reiher and coworkers [61] showed that common hybrid
functionals such as B3LYP overestimate the HS-LS gap, but by
reducing the amount of exact exchange to ca. 15%, a functional
called B3LYP*, spin splitting consistent with experimental observa-
tions is obtained. When studying spin energetics, it is thus impor-
tant to probe the effect of different functionals and to study the
exact exchange (see e.g., [41]). Moreover, in order to prepare the
correct spin states for complex metal systems, for example, iron-
sulfur centers with multiple anti-ferromagnetically coupled spins,
it is recommended to employ the spin-ﬂip broken-symmetry
(BS) approach [62].
DFT has also a deﬁciency known as the charge transfer prob-
lem, in which the energy of a charge transfer state (D0/A0 ! D+/
A) is underestimated and does not decay exactly as 1/r with the
distance. This can lead to preference of delocalized electronic dis-
tributions over localized ones, since fractional occupations are pre-
ferred. The problem is closely linked to the problem known as
derivative discontinuity within DFT [63], which will lead to a
wrong energy dissociation limit of, for example, radicals, and to
underestimation of charge transfer excitation energies. To this end,
the long-range interaction can be treated by the Hartree-Fock
theory using an error function. Such functionals, for example, the
CAM-B3LYP [64] (with 19% short-range, 65% long-range HF-ex-
change) or ωB97-X, are recommended to study charge transfer
states.
86
Patricia Saura et al.

2.4
QM/MM Energy
Expression
The
total
additive
QM/MM
energy
can
be
written
as
[28, 29, 31],
E QM=MM
ð
Þ ¼ Esurr MM
ð
Þ þ Eactive QM
ð
Þ
þ Eactive‐surr QM=MM
ð
Þ,
ð8Þ
where Esurr(MM) is the classical force ﬁeld expression of the sur-
rounding system, Eactive(QM) is the QM energy computed in pres-
ence of polarizing point charges of the surroundings by using,
for example, the DFT methods discussed above, and Eactive-
surr(QM/MM) is the interaction energy term between the QM
and MM systems. The MM term is often modeled using biomolec-
ular force ﬁelds as,
Esurr MM
ð
Þ ¼
X
bonds
1=2kb r  r0
ð
Þ2 þ
X
angles
1=2kθ θ  θ0
ð
Þ2
þ
X
impropers
1=2kχ χ  χ0
ð
Þ2 þ
X
dihedralskϕ 1 þ cos nϕ  δ
ð
Þ
½

þ
X
i>j qiq j=4πε0rij


þ
X
i>jεij
σij=rij

12  2 σij=rij

6
h
i
ð9Þ
where terms 1–4 describe bonded, angle, improper, and dihedral
interactions and allow for ﬂuctuation around some equilibrium
reference values (r0, θ0, χ0, ϕ, δ). The nonbonded interactions
within and between molecules are modeled using the Coulombic
electrostatic potential (qi—point charges; ε0—vacuum permittivity)
and the Lennard-Jones 12-6 potential (εij—potential depth; σij—
combined van der Waals radii for atoms i and j) that describes
dispersive interactions.
The coupling between the QM and MM systems can be
considered by electrostatic and van der Waals interactions, and
link atoms contributions between the QM and MM parts of the
system [31],
Eactive‐surr QM=MM
ð
Þ ¼ E el
QM=MM þ E LJ
QM=MM þ Elink:
ð10Þ
The classical (MM) point charges, qi, interact with both the
electron density (ρ) and the nuclei of the QM regions (QA),
E el
QM=MM ¼ Σi,Iqi=4πε0 ri  RI
j
j
þ Σi,AqiZ A=4πε0 ri  RA
j
j,
ð11Þ
where I, i, and A refer to the electrons, point charges of the MM
system, and nuclei of the QM system. Evaluation of the terms in
Eq. 11 requires modiﬁcation of the electronic structure code to
allow for the polarization of electron density by the point charges.
For the ELJ
QM/MM term, classical Lennard-Jones parameters can be
assigned for the QM atoms, whereas the linking part, Eb, can be
deﬁned by link atoms that saturate the QM part by capping it with
QM/MM Models in Biochemistry
87

hydrogen atoms (Fig. 1a, inset). The link atoms are made “invisi-
ble” for the MM region.
The position of the link atoms can be deﬁned as [65],
Rlink ¼ 1  α
ð
ÞRQM þ αRMM:
ð12Þ
An sp3-hybridized C-C bond has a bond length of 1.54 A˚ and
a C-H bond length of 1.09 A˚ , and α is thus ca. 0.71.
In contrast to the additive QM/MM energy, the total energy in
the subtractive QM/MM models is written as,
E QM=MM
ð
Þ ¼ Esurrþactive MM
ð
Þ  Eactive MM
ð
Þ
þ Eactive QM
ð
Þ,
ð13Þ
in which the MM energy of the active part is replaced by the QM
energy of the active part. In the original ONIOM (Our-own N-
layer Integrated molecular Orbital and molecular Mechanics)
scheme by Morokuma and coworkers [66], the active part is
mechanically embedded in a surrounding system. Mechanical
embedding was later extended to electrostatic embedding, where
the QM system is electrostatically polarized by point charges
[67, 68]. It has been shown that with electrostatic embedding,
both
additive
and
subtractive
schemes
produce
similar
accuracies [69].
The localized point charges can sometimes introduce a too
strong polarization of the delocalized electron density. It is thus
possible to represent the MM charges by a Gaussian distribution,
smearing the point charges in accordance with [70],
χ r
ð Þ ¼ qiexp  r  ri=σ
ð
Þ2
h
i
= √πσ

3,
ð14Þ
where qi is the MM point charge, ri is the center, and σ is the width
of the Gaussian distribution. Values for σ are usually in the 1–2 A˚
range, which are typical bond lengths. Thus, this blurring function
mimics the actual charge distribution along the chemical bond in
the QM/MM boundary.
Polarizable force ﬁelds (see Chapter 2 of Part I) can also be used
to study polarization effects of the MM surroundings as a response
to the QM electron density. Benchmarking calculations [71] sug-
gest that polarization effects of the surroundings can be important,
for example, for charge transfer processes, protein–ligand binding,
and excitation processes in photobiological systems [72]. However,
it can also be important to increase the size of the QM system in the
QM/MM model in order to describe the polarization of the envi-
ronment quantum mechanically.
QM/MM calculations are usually performed with a single QM
system embedded in an MM environment, but it is also straightfor-
ward to extend the methodology to treat multiple active QM
centers. Multiple center systems are common in nature and
employed, for example, in the transfer electron and exciton transfer
88
Patricia Saura et al.

between different sites [73]. Multiple QM centers that interact
with other QM regions can be introduced by the interaction term
[73],
E QM=MM
ð
Þ ¼ Eall MM
ð
Þ  Eactive MM
ð
Þ þ Eactive QM
ð
Þ
þEactivesurr QM=MM
ð
Þ þ Eactiveactive QM=QM
ð
Þ,
ð15Þ
where “all” refers to the whole system, “active” to the regions
treated at the QM level, and “surr” to the MM region. The
QM/QM interactions are evaluated as the average of the classical
and QM interactions between the two systems
H el
QM=QM ¼ 1=2
X
r1
X
r26¼r1
X
i∈r1
X
β∈r2 qβ=riβ


h
þ
X
α∈r1
X
β∈r2 Z αqβ=rαβ

i
,
ð16Þ
where i refers to subsystem 1, β refers to of subsystem 2, and α to
the nuclei of subsystem 1. The different QM-MM, and QM-QM
interaction terms are shown in Fig. 2. Although multi-QM/MM
calculations allow in principle to replace force ﬁeld parameters with
QM interactions, it is important to note that the behavior of too
small QM systems might introduce errors, as saturation of chemical
properties requires a certain QM buffer region. Benchmarking
studies,
for
example,
suggest that
the
Lennard-Jones radii
employed in regular force ﬁelds are ca. 5–20% too small to account
Fig. 2 Left: Partitioning in QM/MM calculations with multiple subsystems. The active regions are marked as
QM1 and QM2, and the rest of the system is modeled at the MM level. The model shows a Glu-Arg ion pair
interaction in ubiquitin. Right: QM/MM MD showing the dynamics of the Glu-51 and Arg-54 headgroup
distance, calculated with MM, QM/MM, and QM/QM partitioning
QM/MM Models in Biochemistry
89

for the correct interactions between the QM and MM regions in
QM/MM calculations [74]. Such problems might arise in particu-
lar when the nearby surroundings are highly charged, and there is a
strong electrostatic attraction to the QM region. Future work is
thus needed to re-parametrize force ﬁelds also in context of
QM/MM simulations.
2.5
Modeling Protein
Dynamics in QM/MM
Proteins have rich dynamics that extends in many systems from the
picosecond to millisecond timescales. Methodologically, however,
it is not feasible to sample rare events or large-scale conformational
changes in proteins by quantum chemical methods due to their
high computational cost. Nevertheless, the biologically active state
of interest might not be captured in the experimental available
structure that is used as the starting model for the QC modeling.
To probe functionally relevant states in QM models that form
on timescales beyond those accessible for such simulations, it is
possible to sample the system using classical atomistic molecular
dynamics simulations, based on which the QM/MM simulations
are performed. We illustrate this approach in Fig. 3 with two recent
case studies [42, 75]. Figure 3a shows the hydration dynamics of an
antiporter-like membrane subunit of complex I. The hydration
dynamics takes place on microsecond timescales and leads to for-
mation of hydrogen-bonded water wires in the initially dry channel
between the bulk and titratable charged residues in the membrane
interior. These water wires are a prerequisite for Grotthuss-type
proton transfer reactions, in which the charge rather than the
proton itself hops between hydrogen-bonded water molecules
and titratable residues. Snapshots from the MD simulations in
Fig. 3a show that the water wires form on ca. 300–1000 ns time-
scale, whereas QM/MM MD treatment of these classically formed
wires and the surrounding protein residues support rapid proton
transfer from the bulk to the protein interior (Fig. 3a, inset).
However, if the QM/MM MD simulations are performed on the
dry membrane channel obtained from the X-ray structure, no
proton transfer reactions are observed [42]. The classical sampling
is thus a prerequisite to study the proton transfer process in this
system.
Another example where we found classical sampling central for
the QM/MM simulations is in the light-driven Na+ pump Kroki-
nobacter eikastus rhodopsin 2 (KR2). In this study [75], we per-
formed classical MD simulations on the experimental dark-state of
KR2, which was used as a starting point for preparing photocycle
intermediates of the protein by isomerizing the retinal and moving
the proton between the retinal and nearby conserved residues. In
order to characterize the modeled states, we computed optical
signatures of the retinal using QM/MM MD simulations at the
coupled-cluster/MM
level
(RVS-ADC(2)/def2-TZVP/
CHARMM27, see [75]). To this end, each intermediate was relaxed
90
Patricia Saura et al.

classically for 1–2 μs, which captured biologically important con-
formational changes in the protein structures. From snapshots of
these MD structures, we further initiated QM/MM MD simula-
tions on ca. 5 ps timescales, which were used for computation of the
optical properties. Molecular properties can be very sensitive to the
employed molecular geometry, which is why we recommend to
calculate such properties not directly from force ﬁeld-sampled
structures, but rather from QM- or QM/MM-derived structures.
The large conformational and hydration changes in the protein
result in optical shifts of the retinal shown in Fig. 3b. The classical
MD simulations thus enable probing the dynamics of protein con-
formational states that would otherwise not be accessible to the
QM/MM simulations. For some proteins, detailed time-resolved
Fig. 3 Large-scale classical MD simulations in combination with QM/MM dynamics. (a) Hydration of complex I
proton channels takes place at the 100–1000 ns timescale. After channel hydration that takes place on ca.
300–1000 ns timescales, QM/MM MD simulations can be employed to study the pT along the water chains.
For more details, see [42]. (b) Absorption spectra of Krokinobacter eikastus rhodopsin 2. Classical MD
simulations on the microsecond timescale were performed to derive structural intermediates along the
photocycle, KR2, K/L, M and O states, followed by 5 ps QM/MM MD to calculate the absorption spectra.
Data were taken from [75]
QM/MM Models in Biochemistry
91

X-ray structures of intermediate states are available [76, 77], which
can provide more accurate starting points for the QM/MM simu-
lations than structures derived from MD simulations.
2.6
QM/MM Free
Energies
The simplest approach to take protein dynamics into account in
QM/MM potential energy proﬁles is to perform QM/MM com-
putations based on different snapshots generated by classical MD
simulations [78] and to calculate average properties or energy
barriers, for example, using a Boltzmann weighted exponential
average,
E{

	
¼ RT ln 1=nΣi
nexp E{
i=RT




,
ð17Þ
where RT ¼ 0.616 kcal mol1 at T ¼ 310 K, E{
i is the barrier of
structure i, and n is the ensemble size. The convergence of the
conformational ensemble was addressed in several benchmarking
studies [79, 80]. These studies suggest that evaluation of QM/MM
properties as an ensemble average might have a slow convergence
and might thus not always be computationally feasible.
Instead of considering several individual structures, the mean-
ﬁeld QM/MM approach [81] uses a dynamically averaged distri-
bution of point charges that polarizes the QM region. After an
initial MD simulation, the average distribution of the MM point
charges is introduced in the QM Hamiltonian instead of evaluating
the energy for every individual MM point charge distribution,
reducing the computational cost signiﬁcantly. Initially developed
for chemical reactions in solution, this approach is not always
straightforward in protein simulations, especially if slow-relaxation
conformational changes are involved [82, 83]. Moreover, the aver-
age structures can lead to unphysical polarization of the QM
region, for example, for charged transition states in proteins [84].
Instead of computing properties based on structural snapshots,
the rigorous treatment of protein dynamics can be probed by
QM/MM free energy calculations, which are based on similar
approaches as in classical molecular simulations. For a general
introduction to enhanced sampling and free energy methods, the
reader is thus referred to Part II of this book. Common techniques
to obtain QM/MM free energies are, for example, umbrella sam-
pling, string simulations, free energy perturbation methods, and
metadynamics. The challenge in QM/MM free energies is the
reduced sampling timescale, which is limited to picosecond-time-
scale/sampling window for ﬁrst principles and 100–1000 ps for
semi-empirical QM/MM methods.
In addition to the brute-force sampling using restrained
QM/MM MD, it is thus also possible to independently sample
the dynamics of surroundings classically and employ a perturbation
theory treatment for computing the embedding free energy. In
such QM/MM free energy perturbation methods, interactions
92
Patricia Saura et al.

between the MM and QM regions are described classically during
sampling, and a perturbation theory treatment is employed to
compute the free energy at the QM/MM level,
exp ΔG MM!QM=MM
ð
Þ


¼ exp  EQM=MM  EMM


=kBT



	
MM,
ð18Þ
where EQM/MM–EMM is the energy gap between the QM/MM and
MM energies, kBT is the thermal energy, and h iMM is the ensemble
average sampled over the MM system. These approaches have been
developed by several research groups [85, 86] in context of
QM/MM simulations. Moreover, recent reweighting approaches
[87] also provide promising methods for computing converged
QM/MM free energy proﬁles.
A commonly employed perturbation technique is to sample the
system at a lower theory level, for example, using reactive force
ﬁelds [88, 89] such as empirical valence bond method and compute
the free energy correction to the higher theory level (ΔΔG) by
employing perturbation theory or linear-response theory [90],
ΔΔG ¼ kBT ln
exp  Ehigh  Elow


=RT



	
low


,
ð19aÞ
ΔΔG  1=2
Ehigh  Elow

	
low


þ
Elow  Ehigh

	


high,
ð19bÞ
Such approaches have been employed to large extent by War-
shel and coworkers [90, 91].
2.7
Frozen Density
Approximation
In the frozen density embedding (FDE) methodology, the electron
density of an active system, ρA, is embedded in the frozen electron
density of the surrounding electron density, ρB, which gives the
embedding potential [38],
vemb ρA; ρB; r
½
 ¼ dr0ρB
pos r0
½ = jr  r0j
ð
Þ þ drρB r0
½ = jr  r0j
ð
Þ
þδExcnad ρA; ρB
½
=δρA r0
ð Þ þ δT snad ρA; ρB
½
=δρA r0
ð Þ,
ð20Þ
where the ﬁrst and second terms are the electron density of nuclei
and electrons from the surrounding system, respectively, the third
term is the nonadditive exchange correlation component, and the
fourth term is the kinetic energy component to the embedding
potential. The FDE thus explicitly accounts for the quantum
mechanical interactions between the central system of interest and
its chemical surroundings. The FDE methodology has, in addition
to ground state, also been extended for excited states through the
linear-response time-dependent DFT (LR-TDDFT) method, and
recently, also to lower order excited states [92]. Although impor-
tant for photobiological applications [6, 25, 40], the FDE meth-
odology will not be discussed here further, but the reader is instead
referred to reviews [23].
QM/MM Models in Biochemistry
93

3
Materials
Classical MD simulations were carried out with NAMD2 [93]. All
QM calculations were performed with TURBOMOLE version 7.1,
which were coupled together with CHARMM [94] by a python
interface [95]. The WHAM equations were solved using the imple-
mentation in ref. [96]. Figures were prepared with VMD [97].
4
Methods
In this section, we illustrate practical aspects of QM and QM/MM
calculations applied to the quinone reduction in the active site of
the enzyme respiratory complex I (NADH:ubiquinone oxidore-
ductase) (see also [98]). We also discuss QM/MM free energy
calculations and their relation to QM calculations in implicit solva-
tion by considering the bimolecular nucleophilic substitution (SN2)
reaction between chloroethane (ClCH2CH3) and a bromide ion
(Br). A basic QM/MM tutorial for setup of QM/MM calcula-
tions can be found on the Kaila group web page: http://villekaila.
wordpress.com/.
4.1
Reactions
in Proteins
4.1.1
Preparation of QM
Cluster Models
DFT cluster models of the quinone-reduction site in complex I
were prepared based on the X-ray structure from Thermus thermo-
philus (PDB ID: 4HEA). As for many biochemical systems of
interest, the experimental structure of complex I has not been
resolved with a bound quinone in the catalytically active site. We
therefore inserted ubiquinone-10 (Q10), with ten isoprenoid units,
into the Q-binding pocket, identiﬁed with the protein cavity search
program HOLE. Next, the structure was relaxed for 100 ns at
T ¼ 310 K by classical MD simulations using the CHARMM27
force ﬁeld and our own in-house parametrization of the cofactors,
using a 1 fs integration timestep. We constructed three different
QM cluster models, with N ¼ 65, 95, and 221 atoms, comprising
the residues shown in Fig. 3. The structures were optimized at the
B3LYP-D3/def2-SVP
level,
with
the
protein
surrounding
described as a polarizable dielectric medium with ε ¼ 4 using the
conductor-like screening model (COSMO). The amino acids were
cut between the Cα and Cβ atoms, which were ﬁxed during the
structure optimizations. To help the convergence of the cluster
models, we also ﬁxed terminal side chain atoms of Phe and Arg
residues at the Cζ atoms. The optimizations were performed using
an m3 DFT integration grid, and the energies and gradients were
converged to 106 au and 103 au, respectively.
To compare the catalytic properties between the different mod-
els, we studied the potential energy surface (PES) for the proton
transfer between His-38 (Nε-H) and the carbonyl group of the
94
Patricia Saura et al.

quinone (C5-O5). Our recent studies [41] suggest that His-38
functions as a proton donor in the formation of quinol (QH2)
upon reduction of the quinone (Q) from the nearby iron-sulfur
(FeS) center N2. Reactant (QH/HisH+) and product (QH2/
His0) structures were optimized at the B3LYP-D3/def2-SVP
level, and the subsequent adiabatic PES was optimized by a
chain-of-state method related to the zero-temperature string
method, implemented in an in-house version of the woelﬂing
module of TURBOMOLE, which allows to ﬁx Cartesian coordi-
nates. Final energetics were evaluated by single-point energy calcu-
lations at the B3LYP-D3/def2-TZVP/ε ¼ 4 level of theory.
4.1.2
Preparation
of QM/MM Models
The classical setup of complex I comprises ca. 1,000,000 atoms,
which would lead to a signiﬁcant increase in the CPU time required
to compute the QM density-point charge interaction terms. To
speed up the QM/MM-computations, the classical system was
trimmed to include only nearest subunits. We therefore cut the
QM/MM system to include the Nqo4/7/8/9 subunits, that com-
prise the N6a, N6b, and N2 iron-sulfur centers, and we solvated
and neutralized the system into a water-ion box. The water-ion
surroundings were relaxed for 1 ns with a ﬁxed protein environ-
ment. QM/MM models contained N ¼ 95 QM atoms. Only the
QM atoms and MM hydrogen atoms within 5 A˚ from the QM
subsystem were allowed to relax during structure optimizations.
The initial QM/MM structures were relaxed by performing a
100 fs MD simulation at T ¼ 310 K with a 1 fs integration time
step, followed by minimization with the Adopted Basis Newton-
Raphson (ABNR) method until the energy did not ﬂuctuate
beyond 0.0006 kcal mol1. For computation of the QM/MM
PES, the reaction coordinate, R0 ¼ r1(Nε-HH38)  r2(H-O) + r3(N-
δ-HδD138)  r4(HδD138-Oδ1D138), was sampled from reactants,
R ¼ 1.9 A˚ , to products, R ¼ 1.9 A˚ , using a harmonic potential
restrain with a force constant of k ¼ 1000 kcal mol1 A˚ 2 by the
RESD module in CHARMM. A 5 ps QM/MM MD trajectory was
also performed to probe the dynamics of the system at T ¼ 310 K
and using a 1 fs integration timestep.
4.2
Reactions in
Aqueous Solution
As an example of a chemical reaction in aqueous solution, we
studied the SN2 reaction between ClCH2-CH3 and Br (see Fig. 5
below). The DFT models contained the organic molecule and
halogen ion. Reactants (ClCH2-CH3 + Br), products (BrCH2-
CH3 + Cl), and transitions state (Brδ--[CH2CH3]δ+--Clδ),
were optimized at the B3LYP-D3/def2-SVP/ε ¼ 80 level of the-
ory. The adiabatic PES was calculated by the chain-of-state method,
using the woelﬂing module in TURBOMOLE as described previ-
ously, between the reactant/product and the optimized transition
state. Final energetics were evaluated by B3LYP-D3/def2-TZVP/
ε ¼ 80 single point energy calculations, including the zero-point
QM/MM Models in Biochemistry
95

energy (ZPE) correction at the B3LYP-D3/def2-SVP/ε ¼ 80
level. QM/MM models comprised the solute atoms, included
within the QM region, and a 20 A˚ radius sphere of explicit TIP3P
water molecules centered on the solute, comprising in total ca.
3200 atoms. QM/MM free energy calculations were performed
using the umbrella sampling (US) method. In total, 14 windows
spanning the range of the reaction coordinate were selected. The
reaction coordinate was deﬁned as R ¼ r1(Cl-C)  r2(Br-C). For
each window, 10 ps of QM/MM MD sampling at T ¼ 298 K was
performed, giving a total of 140 ps for the entire reaction coordi-
nate range. The system was restrained to the corresponding value of
the reaction coordinate in each window by a harmonic potential,
using a force constant of 100 kcal mol1 A˚ 2 applied to R. The
resulting free energy proﬁle was computed using the weighted
histogram analysis method (WHAM), using a convergence thresh-
old of 0.0001 kcal mol1 in the WHAM equations.
5
Results
5.1
QM/MM and
Quantum Chemical
Models for Reactions
in Enzymes
DFT-optimized structures at the QM and QM/MM level of the
proton transfer (pT) reaction between the active site residue His-38
and the reduced quinone molecule are shown in Fig. 4. The
corresponding potential energy surface (PES) for the pT reaction
as a function of the size of the QM cluster model is shown in
Fig. 4a, a QM/MM potential energy surface in Fig. 4b, and a
5 ps QM/MM MD trajectory in Fig. 4c. The reaction energy for
the larger system with N ¼ 221 atoms computed at B3LYP-D3/
def2-TZVP/ε ¼ 4 level is ca. 4 kcal mol1. In the medium size
model, we obtain a reaction energy of ca. 5 kcal mol1, whereas
when using the small QM model with N ¼ 65 atoms, the reaction
energy is ca. 8 kcal mol1. The reaction barriers are similar, with
around 1–3 kcal mol1 for all three QM models. The energy
proﬁles thus suggest that the energetics converge when increasing
the system size. Moreover, if a small def2-SVP basis set is employed
in the otherwise converged QM cluster model, we obtain a few
kcal mol1 shift in the reaction energetics, suggesting that large
basis sets should be employed if computationally feasible. The
effect of the dielectric medium on the QM clusters is often dis-
cussed. Interestingly, when recomputing the energy proﬁles with a
higher dielectric constant of ε ¼ 80, we observe a ca. 2 kcal mol1
shift for the small systems, whereas the large model is nearly insen-
sitive to the choice of the dielectric constant. The explicit modeling
of the intermolecular interactions thus replaces the effect of the
polarizable medium in the larger QM model, which is in line with
results from previous studies [18, 37].
Figure 4b shows the QM/MM potential energy proﬁles for the
proton transfer between His-38 and Q. The QM/MM potential
96
Patricia Saura et al.

energy barrier is ca. 3 kcal mol1, and the reaction energy is ca.
2 kcal mol1, which are thus qualitatively similar to the ones
obtained by QM cluster calculations. The convergence of the
QM/MM potential energy surfaces is, however, outside the scope
of the present work, since reaction path optimizations at the
QM/MM level are computationally more expensive than at the
QM cluster level. In addition to the PES, QM/MM MD simula-
tions can be used to study the proton transfer dynamics, since no
positional restraints on the terminal atoms are required as in cluster
models. Figure 4b shows the distance of the proton between
His-38 and Q obtained from a 5 ps QM/MM MD simulations.
The simulations suggest that the proton ﬂickers between the resi-
dues, initially being bound to His-38, and then moves within 3 ps
to the reduced quinone, consistent with the low barrier obtained
Fig. 4 QM and QM/MM models of the quinone (Q) protonation reaction in the active center of complex I. (a)
Left: Quantum chemical cluster models of the active site with the small system (N ¼ 65 atoms) in CPK
representation, medium size model (N ¼ 95 atoms) in CPK and thick licorice representation, and the large
model (N ¼ 221 atoms) showing all atoms. Middle: Potential energy proﬁles computed at B3LYP-D3/def2-
TZVP and B3LYP-D3/def2-SVP levels for the proton transfer for the different-sized models. The proﬁles show
convergence with size/basis increase. Right: Reactant, transition state, and product state for the small and
large models computed with ε ¼ 4 and ε ¼ 80. (b). Left: QM/MM models with the QM system shown in CPK
and the protein modeled at the MM level in Cartoon representation. Middle: Potential energy proﬁles obtained
from QM/MM reaction path optimization. N2[ox] (oxidized iron-sulfur cluster) and N2[red] (reduced iron-sulfur
cluster) show the effect of reduction of a nearby N2 iron-sulfur center (not shown in ﬁgure). Right: A QM/MM
MD simulation showing spontaneous proton transfer. Inset: Qualitative free energy proﬁle computed from the
MD trajectory. QM/MM data were taken from [98]
QM/MM Models in Biochemistry
97

from the PES. Although this trajectory is too short to properly
compute a free energy proﬁle, G(x) ¼ RT ln(p(x)), the computed
probability distribution of the pT reaction coordinate p(x), never-
theless, qualitatively supports the PES.
5.2
QM/MM and
Quantum Chemical
Modeling of Reactions
in Solution
In order to illustrate the connection between QM models and
QM/MM free energy calculations, Fig. 5 shows an organic SN2
reaction in solution computed using the respective computational
models. We obtain a reaction free energy using an implicit solvent
model with ε ¼ 80, of ca. 10 kcal mol1, and a free energy barrier of
ca. 21 kcal mol1 (Fig. 5c, blue curve). The DFT proﬁle is obtained
by optimizing the transition state and computing the zero-point
energy and entropic corrections based on the molecular Hessian.
These terms contribute by 0.3 kcal mol1 and 0.2 kcal mol1 to
the barrier and reaction energetics, respectively. We also obtain a
similar free energy proﬁle using QM/MM umbrella sampling with
a reaction free energy of ca. 8 kcal mol1 but lower free energy
barrier of ca. 14 kcal mol1, suggesting that solvent dynamics
stabilize the transitions state by ca. 4 kcal mol1. The histogram
overlaps in the simulations are rather good and the statistical errors
small, less than 0.1 kcal mol1, suggesting that the QM/MM free
energy proﬁles are well converged. However, in contrast to reac-
tions in solutions, converging free energy proﬁles for enzymatic
processes can be more challenging, since the anisotropic protein
environment might relax on much longer time-scales than a
Fig. 5 QM/MM and QM free energy calculations of a chemical reaction in aqueous solution. (a) The QM/MM
model of the studied SN2 reaction between ClCH2-CH3 and Br, showing the QM region in CPK representation
and the surrounding MM water molecules in stick representation. (b) QM/MM MD trajectories for the
14 umbrella sampling (US) windows along the reaction coordinate, R ¼ r1  r2 (see panel a). The US included
in total 10 ps/window. (c) QM (in blue) and QM/MM free energy proﬁle computed by US (in red), and
histograms of the sampled windows (below). The micro-solvated QM models are shown in black (see main
text)
98
Patricia Saura et al.

homogeneous solvent. By analyzing the restrained QM/MM tra-
jectories, we ﬁnd that two water molecules stabilize the transition
state relative to the ground state. If the QM models are microsol-
vated with these water molecules, we indeed obtain a ca.
2 kcal mol1 stabilization of the transition state relative to the
reactant and product states, whereas calculations with larger def2-
TZVP basis sets further lower the transition state energy by ca.
2 kcal mol1. This shows that similar information can, at least in
principle, be obtained using both “conventional” QM models and
QM/MM simulations. However, even for this simple model reac-
tion, it might be difﬁcult to determine the dynamics of the sur-
rounding systems without explicit dynamic sampling. On the other
hand, analyzing electronic energies rather than free energies
obtained from probability distributions is far simpler and allows in
many cases to derive a chemical understanding of the system at least
on a qualitative level.
6
Notes
Below we have summarized some central points that should be
considered in quantum biochemical modeling:
1. Build both QM cluster and QM/MM models in parallel to
study convergence and to decompose the physical basis for
observed chemical effects.
2. In both QM and QM/MM modeling, consider sequence
homology, site-directed mutagenesis data (if available), and
chemical interactions that might inﬂuence the (bio)chemical
system of interest.
3. Consider if the employed QM theory level can capture the
biochemical effects that are studied. Probe the behavior of
your systems also at other theory levels rather than B3LYP/
6-31G*.
4. Increase the size of the QM model systematically in the QM
cluster models. Consider if similar size/convergence require-
ments are necessary in the QM/MM models.
5. In order to prevent loosely bound electrons, create QM sys-
tems close to charge neutrality. If this is not possible, probe the
quality of QM calculations by considering if total energies are
sensible, if the system is spin contaminated (in open shell
systems), and if obtained HOMO-LUMO gaps/energies are
sensible.
6. For QM/MM partitioning, terminate your system so that
integer charge is preserved within your MM system. For exam-
ple, in the CHARMM force ﬁeld, the backbone atoms “C-O-
QM/MM Models in Biochemistry
99

CA-HA-N-HN” form a charge neutral group, as does the side
chain.
7. Place the boundary region, that is, the link atom or the termi-
nal capping atom as far as computationally feasible from the
system of interest to avoid artiﬁcial boundary effects.
8. Do not terminate the QM system at chemically challenging
regions, such as peptide bonds, but rather at saturated bonds,
for example, the Cα-Cβ bond.
9. Perform structure and/or reaction path optimizations for both
QM clusters and QM/MM models and compare the consis-
tency
of
the
results
to
QM/MM
molecular
dynamics
simulations.
10. Study the dynamics of the system at the classical level to access
dynamics at ns–μs timescales. Construct independent quantum
chemical models using classically sampled systems.
11. To avoid being trapped in local minima in QM/MM optimiza-
tions, study the system with QM/MM MD dynamics simula-
tions and compare results with electronic energies of sampled
states from QM cluster calculations. Employ micro-iterative
optimization schemes to improve convergence.
12. If computationally feasible, perform QM/MM free energy
computations and compare with PES obtained from path opti-
mizations and QM/MM MD simulations.
Acknowledgments
We thank Dr. Mikael P. Johansson for helpful discussions. Compu-
tational resources were provided in part by HPC Europa3 grant
2000831 HPCE3 “Mechanism of long-range electron transfer in
respiratory complex I.”
References
1. Schro¨dinger E (1944) What is life? Cambridge
University Press, Cambridge
2. Pullman A, Pullman B (1967) Quantum Bio-
chemistry. Wiley-Interscience, New York, NY,
pp 1–60
3. Lo¨wdin P-O (1963) Proton tunneling in DNA
and its biological implications. Rev Mod Phys
35:724–732
4. Honig B, Karplus M (1971) Implications of
torsional potential of retinal isomers for visual
excitation. Nature 229:558–560
5. Warshel A, Karplus M (1972) Calculation of
ground and excited state potential surfaces of
conjugated molecules. I. Formulation and
parametrization.
J
Am
Chem
Soc
94:5612–5625
6. Zhou X, Sundholm D, Wesołowski TA, Kaila
VRI (2014) Spectral tuning of rhodopsin and
visual
cone
pigments.
J
Am
Chem
Soc
136:2723–2726
7. Suomivuori C-M, Lang L, Sundholm D,
Gamiz-Hernandez AP, Kaila VRI (2016) Tun-
ing the protein-induced absorption shifts of
retinal in engineered rhodopsin mimics. Chem-
istry 22:8254–8261
8. Cui Q, Elstner M (2014) Density functional
tight binding: values of semi-empirical meth-
ods in an ab initio era. Phys Chem Chem Phys
16:14368–14377
100
Patricia Saura et al.

9. Gamiz-Hernandez AP, Angelova IN, Send R,
Sundholm D, Kaila VRI (2015) Protein-
induced
color
shift
of
carotenoids
in
β-crustacyanin.
Angew
Chem
Int
Ed
54:11564–11566
10. Suomivuori C-M, Winter NOC, H€attig C,
Sundholm D, Kaila VRI (2016) Exploring the
light-capturing properties of photosynthetic
chlorophyll clusters using large-scale correlated
calculations.
J
Chem
Theory
Comput
12:2644–2651
11. Andruniow T, Ferre N, Olivucci M (2004)
Structure, initial excited-state relaxation, and
energy storage of rhodopsin resolved at the
multiconﬁgurational
perturbation
theory
level.
Proc
Natl
Acad
Sci
U
S
A
101:17908–17913
12. Riplinger C, Pinski P, Becker U, Valeev EF,
Neese F (2016) Sparse maps—a systematic
infrastructure for reduced-scaling electronic
structure methods. II. Linear scaling domain
based pair natural orbital coupled cluster the-
ory. J Chem Phys 144:024109
13. Bistoni G, Polyak I, Sparta M, Thiel W, Neese F
(2018) Toward Accurate QM/MM Reaction
Barriers
with
Large
QM
Regions
Using
Domain Based Pair Natural Orbital Coupled
Cluster Theory. J Chem Theory Comput
14:3524–3531
14. Supekar S, Papageorgiou AC, Gemmecker G,
Peltzer
R,
Johansson
MP,
Tripsianes
K,
Sattler M, Kaila VRI (2017) Conformational
selection of dimethylarginine recognition by
the survival motor neuron tudor domain.
Angew Chem Int Ed 52:486–490
15. Retegan M, Neese F, Pantazis DA (2013) Con-
vergence of QM/MM and cluster models for
the spectroscopic properties of the oxygen-
evolving complex in photosystem II. J Chem
Theory Comput 9:3832–3842
16. Flaig D, Beer M, Ochsenfeld C (2012) Con-
vergence of electronic structure with the size of
the QM region: example of QM/MM NMR
shieldings.
J
Chem
Theory
Comput
8:2260–2271
17. Siegbahn PEM, Himo F (2011) The quantum
chemical
cluster
approach
for
modeling
enzyme reactions. Wiley Interdiscip Rev Com-
put Mol Sci 1:323–336
18. Siegbahn PEM, Himo F (2009) Recent devel-
opments of the quantum chemical cluster
approach for modeling enzyme reactions. J
Biol Inorg Chem 14:643–651
19. A˚ qvist J, Isaksen GV, Brandsdal BO (2017)
Computation of enzyme cold adaptation. Nat
Rev Chem 1:0051
20. Isaksen GV, A˚ qvist J, Brandsdal BO (2016)
Enzyme surface rigidity tunes the temperature
dependence of catalytic rates. Proc Natl Acad
Sci U S A 113:7822–7827
21. Reuter N, Dejaegere A, Maigret B, Karplus M
(2000) Frontier bonds in QM/MM methods:
a comparison of different approaches. J Phys
Chem A 104:1720–1735
22. Maseras F, Morokuma K (1995) IMOMM: a
new integrated ab initio + molecular mechanics
geometry optimization scheme of equilibrium
structures and transition states. J Comput
Chem 16:1170–1179
23. Wesolowski TA, Shedge S, Zhou X (2015)
Frozen-density embedding strategy for multi-
level simulations of electronic structure. Chem
Rev 115:5891–5928
24. Kovyrshin A, Neugebauer J (2016) Analytical
gradients for excitation energies from frozen-
density embedding. Phys Chem Chem Phys
18:20955–20975
25. Ho¨fener S, Visscher L (2016) Wave function
frozen-density
embedding:
coupled
excita-
tions. J Chem Theory Comput 12:549–557
26. Duarte
F,
Amrein
BA,
Blaha-Nelson
D,
Kamerlin SCL (2015) Recent advances in
QM/MM free energy calculations using refer-
ence potentials. Biochim Biophys Acta Gen
Subj 1850:954–965
27. Mly´nsky´ V, Bana´sˇ P, Sˇponer J, van der Kamp
MW, Mulholland AJ, Otyepka M (2014) Com-
parison of ab initio, DFT, and semiempirical
QM/MM approaches for description of cata-
lytic mechanism of hairpin ribozyme. J Chem
Theory Comput 10:1608–1622
28. Warshel A, Levitt M (1976) Theoretical studies
of enzymic reactions: dielectric, electrostatic
and steric stabilization of the carbonium ion
in the reaction of lysozyme. J Mol Biol
103:227–249
29. Singh UC, Kollman PA (1986) A combinedab
initio
quantum
mechanical
and
molecular
mechanical method for carrying out simula-
tions on complex molecular systems: applica-
tions to the CH3Cl + Cl? exchange reaction
and gas phase protonation of polyethers. J
Comput Chem 7:718–730
30. Vreven T, Byun KS, Koma´romi I, Dapprich S,
Montgomery JA, Morokuma K, Frisch MJ
(2006) Combining quantum mechanics meth-
ods with molecular mechanics methods in
ONIOM. J Chem Theory Comput 2:815–826
31. Field MJ, Bash PA, Karplus M (1990) A com-
bined quantum mechanical and molecular
mechanical potential for molecular dynamics
simulations. J Comput Chem 11:700–733
QM/MM Models in Biochemistry
101

32. Noodleman L, Lovell T, Han WG, Li J, Himo
F (2004) Quantum chemical studies of inter-
mediates and reaction pathways in selected
enzymes
and
catalytic
synthetic
systems.
Chem Rev 104:459–508
33. Torres RA, Lovell T, Noodleman L, Case DA
(2003)
Density
functional
and
reduction
potential calculations of Fe4S4 clusters. J Am
Chem Soc 125:1923–1936
34. Liao RZ, Thiel W (2012) Comparison of
QM-only and QM/MM models for the mech-
anism of tungsten-dependent acetylene hydra-
tase. J Chem Theory Comput 8:3793–3803
35. Bakowies D, Thiel W (1996) Hybrid models
for combined quantum mechanical and molec-
ular mechanical approaches. J Phys Chem
100:10580–10594
36. Blomberg MRA, Siegbahn PEM (2006) Quan-
tum chemistry applied to the mechanisms of
transition metal containing enzymes—cyto-
chromec oxidase, a particularly challenging
case. J Comput Chem 27:1373–1384
37. Himo F (2017) Recent trends in quantum
chemical modeling of enzymatic reactions. J
Am Chem Soc 139:6780–6786
38. Wesolowski TA, Warshel A (1993) Frozen den-
sity functional approach for ab initio calcula-
tions of solvated molecules. J Phys Chem
97:8050–8053
39. Neugebauer J (2007) Couplings between elec-
tronic transitions in a subsystem formulation of
time-dependent density functional theory. J
Chem Phys 126:134116
40. Neugebauer J (2008) Photophysical properties
of natural light-harvesting complexes studied
by subsystem density functional theory. J Phys
Chem B 112:2207–2217
41. Gamiz-Hernandez AP, Jussupow A, Johansson
MP, Kaila VRI (2017) Terminal electron–pro-
ton transfer dynamics in the quinone reduction
of respiratory complex I. J Am Chem Soc
139:16282–16288
42. Di Luca A, Gamiz-Hernandez AP, Kaila VRI
(2017) Symmetry-related proton transfer path-
ways in respiratory complex I. Proc Natl Acad
Sci U S A 114:E6314–E6321
43. Kaila VRI (2018) Long-range proton-coupled
electron transfer in biological energy conver-
sion: towards mechanistic understanding of
respiratory complex I. J R Soc Interface
15:20170916
44. Perdew JP (2001) Jacob’s ladder of density
functional approximations for the exchange-
correlation energy. AIP Conf Proc 577:1–20
45. Curtiss LA, Redfern PC, Raghavachari K
(2005) Assessment of Gaussian-3 and density-
functional theories on the G3/05 test set of
experimental
energies.
J
Chem
Phys
123:124107
46. Tao J, Perdew JP, Staroverov VN, Scuseria GE
(2003) Climbing the density functional ladder:
nonempirical
meta–generalized
gradient
approximation designed for molecules and
solids. Phys Rev Lett 91:146401
47. Weymuth T, Couzijn EPA, Chen P, Reiher M
(2014) New benchmark set of transition-metal
coordination reactions for the assessment of
density functionals. J Chem Theory Comput
10:3092–3103
48. Jensen KP (2008) Bioinorganic chemistry
modeled with the TPSSh density functional.
Inorg Chem 47:10357–10365
49. Ugur I, Rutherford AW, Kaila VRI (2016)
Redox-coupled substrate water reorganization
in the active site of Photosystem II—the role of
calcium in substrate water delivery. Biochim
Biophys Acta Bioenerg 1857:740–748
50. Finkelmann AR, Senn HM, Reiher M (2014)
Hydrogen-activation
mechanism
of
[Fe] hydrogenase revealed by multi-scale mod-
eling. Chem Sci 5:4474–4482
51. Arbuznikov AV (2007) Hybrid exchange cor-
relation functionals and potentials: concept
elaboration. J Struct Chem 48:S1–S31
52. Siegbahn PEM (2006) The performance of
hybrid DFT for mechanisms involving transi-
tion metal complexes in enzymes. J Biol Inorg
Chem 11:695–701
53. Waitt C, Ferrara NM, Eshuis H (2016) Ther-
mochemistry and geometries for transition-
metal
chemistry
from
the
random
phase
approximation.
J
Chem
Theory
Comput
12:5350–5360
54. Kussmann J, Beer M, Ochsenfeld C (2013)
Linear-scaling self-consistent ﬁeld methods for
large molecules. Wiley Interdiscip Rev Comput
Mol Sci 3:614–636
55. Kussmann J, Ochsenfeld C (2015) Preselective
screening for linear-scaling exact exchange-
gradient calculations for graphics processing
units and general strong-scaling massively par-
allel calculations. J Chem Theory Comput
11:918–922
56. Uﬁmtsev IS, Martı´nez TJ (2008) Quantum
chemistry on graphical processing units. 1. Stra-
tegies for two-electron integral evaluation. J
Chem Theory Comput 4:222–231
57. Gaus M, Cui Q, Elstner M (2014) Density
functional tight binding: application to organic
and biological molecules. Wiley Interdiscip Rev
Comput Mol Sci 4:49–61
58. Sharma S, Sivalingam K, Neese F, Chan GK-L
(2014) Low-energy spectrum of iron–sulfur
102
Patricia Saura et al.

clusters directly from many-particle quantum
mechanics. Nat Chem 6:927–933
59. Szalay PG, Mu¨ller T, Gidofalvi G, Lischka H,
Shepard R (2012) Multiconﬁguration self-
consistent ﬁeld and multireference conﬁgura-
tion interaction methods and applications.
Chem Rev 112:108–181
60. Grimme S (2006) Semiempirical GGA-type
density functional constructed with a long-
range dispersion correction. J Comput Chem
27:1787–1799
61. Salomon O, Reiher M, Hess BA (2002) Asser-
tion and validation of the performance of the
B3LYP⋆functional for the ﬁrst transition
metal row and the G2 test set. J Chem Phys
117:4729–4737
62. Mouesca J-M, Noodleman L, Case DA (1995)
Density-functional calculations of spin cou-
pling in [Fe4S4]3+ clusters. Int J Quantum
Chem 56:95–102
63. Cohen AJ, Mori-Sanchez P, Yang W (2008)
Insights into current limitations of density
functional theory. Science 321:792–794
64. Yanai T, Tew DP, Handy NC (2004) A new
hybrid exchange-correlation functional using
the
Coulomb-attenuating
method
(CAM-B3LYP). Chem Phys Lett 393:51–57
65. Sauer J, Sierka M (2000) Combining quantum
mechanics and interatomic potential functions
in ab initio studies of extended systems. J Com-
put Chem 21:1470–1493
66. Svensson
M,
Humbel
S,
Froese
RDJ,
Matsubara T, Sieber S, Morokuma K (1996)
ONIOM: a multilayered integrated MO + MM
method for geometry optimizations and single
point energy predictions. A test for dielsalder
reactions and Pt(P(t -Bu) 3) 2 + H 2 oxidative
addition. J Phys Chem 100:19357–19363
67. Vreven T, Morokuma K (2003) Investigation
of the S0 S1 excitation in bacteriorhodopsin
with the ONIOM(MO:MM) hybrid method.
Theor Chem Acc 109:125–132
68. Ryde U (1996) The coordination of the cata-
lytic zinc ion in alcohol dehydrogenase studied
by combined quantum-chemical and molecular
mechanics calculations. J Comput Aided Mol
Des 10:153–164
69. Roßbach S, Ochsenfeld C (2017) Inﬂuence of
coupling and embedding schemes on QM size
convergence in QM/MM approaches for the
example of a proton transfer in DNA. J Chem
Theory Comput 13:1102–1107
70. Das D, Eurenius KP, Billings EM, Sherwood P,
Chatﬁeld
DC,
Hodosˇcˇek
M,
Brooks
BR
(2002) Optimization of quantum mechanical
molecular mechanical partitioning schemes:
Gaussian
delocalization
of
molecular
mechanical charges and the double link atom
method. J Chem Phys 117:10534–10547
71. Warshel A, Kato M, Pisliakov AV (2007) Polar-
izable force ﬁelds: history, test cases, and pro-
spects. J Chem Theory Comput 3:2034–2045
72. Schwabe T, Beerepoot MTP, Olsen JMH,
Kongsted J (2015) Analysis of computational
models for an accurate study of electronic exci-
tations
in
GFP.
Phys
Chem Chem Phys
17:2582–2588
73. Ro¨pke M, Po¨verlein M, B€arwinkel T, Kaila VRI
(2019) Particle exchange in a coupled multi-
subsystem
quantum
chemical
calculation
setting. In preparation
74. Freindorf M, Shao Y, Furlani TR, Kong J
(2005) Lennard-Jones parameters for the com-
bined QM/MM method using the B3LYP/6-
31G*/AMBER potential. J Comput Chem
26:1270–1278
75. Suomivuori
C-M,
Gamiz-Hernandez
AP,
Sundholm D, Kaila VRI (2017) Energetics
and dynamics of a light-driven sodium-pump-
ing rhodopsin. Proc Natl Acad Sci U S A
114:7043–7048
76. Kaila VRI, Schotte F, Cho HS, Hummer G,
Anﬁnrud PA (2014) Contradictions in X-ray
structures of intermediates in the photocycle
of photoactive yellow protein. Nat Chem
6:258–259
77. Gamiz-Hernandez AP, Kaila VRI (2016) Con-
version of light-energy into molecular strain in
the photocycle of the photoactive yellow pro-
tein. Phys Chem Chem Phys 18:2802–2809
78. Saura P, Suardı´az R, Masgrau L, Lluch JM,
Gonza´lez-Lafont A` (2014) Unraveling how
enzymes can use bulky residues to drive site-
selective c–h activation: the case of mammalian
lipoxygenases catalyzing arachidonic acid oxi-
dation. ACS Catal 4:4351–4363
79. Ryde U (2017) How many conformations
need to be sampled to obtain converged
QM/MM energies? The curse of exponential
averaging.
J
Chem
Theory
Comput
13:5745–5752
80. Li Y, Zhang R, Du L, Zhang Q, Wang W
(2016) How many conformations of enzymes
should be sampled for DFT/MM calculations?
A case study of ﬂuoroacetate dehalogenase. Int
J Mol Sci 17:E1372
81. Yamamoto T (2008) Variational and perturba-
tive formulations of quantum mechanical/
molecular mechanical free energy with mean-
ﬁeld embedding and its analytical gradients. J
Chem Phys 129:244104
82. Kosugi
T,
Hayashi
S
(2012)
QM/MM
reweighting free energy SCF for geometry
optimization on extensive free energy surface
QM/MM Models in Biochemistry
103

of enzymatic reaction. J Chem Theory Comput
8:322–334
83. Hayashi S, Uchida Y, Hasegawa T, Higashi M,
Kosugi T, Kamiya M (2017) QM/MM geom-
etry optimization on extensive free-energy sur-
faces for examination of enzymatic reactions
and design of novel functional properties of
proteins. Annu Rev Phys Chem 68:135–154
84. Rosta E, Haranczyk M, Chu ZT, Warshel A
(2008) Accelerating QM/MM free energy cal-
culations: representing the surroundings by an
updated mean charge distribution. J Phys
Chem B 112:5680–5692
85. Hu H, Yang W (2008) Free energies of chemi-
cal reactions in solution and in enzymes with ab
initio quantum mechanics/molecular mechan-
ics
methods.
Annu
Rev
Phys
Chem
59:573–601
86. Rod TH, Ryde U (2005) Accurate QM/MM
free energy calculations of enzyme reactions:
methylation by catechol O -methyltransferase.
J Chem Theory Comput 1:1240–1251
87. Ko¨nig G, Hudson PS, Boresch S, Woodcock
HL (2014) Multiscale free energy simulations:
an efﬁcient method for connecting classical
MD simulations to QM or QM/MM free ener-
gies using non-boltzmann bennett reweighting
schemes.
J
Chem
Theory
Comput
10:1406–1419
88. Hartke B, Grimme S (2015) Reactive force
ﬁelds made simple. Phys Chem Chem Phys
17:16715–16718
89. Senftle TP, Hong S, Islam MM et al (2016)
The ReaxFF reactive force-ﬁeld: development,
applications and future directions. NPJ Com-
put Mater 2:15011
90. Sham YY, Chu ZT, Tao H, Warshel A (2000)
Examining methods for calculations of binding
free energies: LRA, LIE, PDLD-LRA, and
PDLD/S-LRA calculations of ligands binding
to an HIV protease. Proteins Struct Funct
Genet 39:393–407
91. Singh N, Warshel A (2010) Absolute binding
free energy calculations: on the accuracy of
computational scoring of protein-ligand inter-
actions. Proteins Struct Funct Bioinformatics
78:1705–1723
92. Prager S, Zech A, Aquilante F, Dreuw A, Weso-
lowski TA (2016) First time combination of
frozen density embedding theory with the
algebraic diagrammatic construction scheme
for the polarization propagator of second
order. J Chem Phys 144:204103
93. Phillips JC, Braun R, Wang W, Gumbart J,
Tajkhorshid E, Villa E, Chipot C, Skeel RD,
Kale´ L, Schulten K (2005) Scalable molecular
dynamics with NAMD. J Comput Chem
26:1781–1802
94. Brooks BR, Brooks CL, Mackerell AD et al
(2009) CHARMM: the biomolecular simula-
tion program. J Comput Chem 30:1545–1614
95. Riahi S, Rowley CN (2014) The CHARMM-
TURBOMOLE
interface
for
efﬁcient and
accurate QM/MM molecular dynamics, free
energies, and excited state properties. J Com-
put Chem 35:2076–2086
96. Grossﬁeld A. WHAM: the weighted histogram
analysis
method.
http://membrane.urmc.
rochester.edu/wordpress/?page_id=126
97. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph 14:33–38
98. Sharma V, Belevich G, Gamiz-Hernandez AP,
Ro´g T, Vattulainen
I, Verkhovskaya ML,
Wikstro¨m M, Hummer G, Kaila VRI (2015)
Redox-induced activation of the proton pump
in the respiratory complex I. Proc Natl Acad Sci
U S A 112:11571–11576
104
Patricia Saura et al.

Chapter 5
A Practical View of the Martini Force Field
Bart M. H. Bruininks, Paulo C. T. Souza, and Siewert J. Marrink
Abstract
Martini is a coarse-grained (CG) force ﬁeld suitable for molecular dynamics (MD) simulations of (bio)
molecular systems. It is based on mapping of two to four heavy atoms to one CG particle. The effective
interactions between the CG particles are parametrized to reproduce partitioning free energies of small
chemical compounds between polar and apolar phases. In this chapter, a summary of the key elements of
this CG force ﬁeld is presented, followed by an example of practical application: a lipoplex-membrane fusion
experiment. Formulated as hands-on practice, this chapter contains guidelines to build CG models of
important biological systems, such as asymmetric bilayers and double-stranded DNA. Finally, a series of
notes containing useful information, limitations, and tips are described in the last section.
Key words Coarse-grained models, Martini force ﬁeld, Molecular dynamics simulations, Biomolecu-
lar systems
1
Introduction
The initial Martini coarse-grained (CG) force ﬁeld was developed in
2003 to study lipid membrane properties [1–3]. It allowed to
investigate the behavior of large lipid aggregates at spatial and
timescales unachievable to atomistic MD simulations, while retain-
ing enough resolution and chemical speciﬁcity to give a micro-
scopic and dynamic picture still unavailable in experiments. The
Martini force ﬁeld was shown to be capable to address a wide range
of lipid-based processes such as vesicle self-assembly, vesicle fusion,
lamellar to inverted hexagonal phase transition, and the formation
of the gel- and liquid-order phases [1–6]. Over the years, the
applicability of the force ﬁeld has expanded to most common
biomolecules such as proteins [7, 8], sugars [9, 10], nucleotides
[11, 12], and some important cofactors [13], as well as many
nonbiological molecules including synthetic polymers [14–20]
and nanoparticles [17–19, 21]. Examples of Martini CG models
are shown in Fig. 1a. A complete list can be found under “down-
loads” at cgmartini.nl. Noteworthy is the high compatibility of the
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_5, © Springer Science+Business Media, LLC, part of Springer Nature 2019
105

individual models with each other. This allows for the modeling of
complex biological environments such as the plasma membrane
[22] (shown in Fig. 1b) and photosystem II in a thylakoid
membrane [23].
This high compatibility is achieved by a clear modular mapping
and parameterization scheme based on building blocks, called
beads. Martini is a CG force ﬁeld, which, in general, maps four
nonhydrogen atoms to a single CG bead. During the mapping,
chemical groups such as carboxylates or esters are represented by a
single CG bead. This approach makes it easy to build new models
based on the already available ones. The CG beads come in four
chemical classes (or “ﬂavors”): charged (Q), polar (P), nonpolar
(N), and apolar (C). The Q and N classes each have four subtypes
that are linked to their capability of participating in hydrogen
Fig. 1 Martini force ﬁeld: (a) Some examples of Martini CG models used for lipids (DPPC and cholesterol),
peptide, water, benzene, and some amino acids (adapted from [27]); (b) Example for a complex application:
the idealized asymmetric plasma membrane comprises 63 different lipid types [22]; (c) Workﬂow for the
parametrization of a new Martini CG model
106
Bart M. H. Bruininks et al.

bonding: donor and acceptor (da), donor (d), acceptor (a), and
none (0). The main difference between these subtypes is their
interaction strength with each other, allowing for a qualitative
representation of hydrogen bonding. The P and C beads each
have ﬁve subtypes, which represent a gradient from weak to strong
polar or apolar properties, respectively. In total, this gives rise to
18 different bead chemical types. For computational efﬁciency, the
mass of all standard beads is set to 72 amu, which equals the mass of
four water molecules (represented by a P4 bead type in Martini).
Martini employs bonded and nonbonded potential forms com-
monly used in atomistic force ﬁelds, which make the model easy
to be implemented in modern molecular dynamic programs as
GROMACS [3, 5], GROMOS [24], and NAMD [25, 26].
Although this choice of potential forms is not the most accurate
one for coarse-grained models (see Notes 1 and 2) [27], it enables
Martini to take beneﬁt of all the advances in high-performance
parallel algorithms and enhanced sampling techniques developed
in the past years. For the nonbonded interactions, 12–6 Lennard-
Jones and Coulomb potentials are used (as shown in Eq. 1). In
practice, these potentials are shifted and truncated for computa-
tional speedup. In the current implementation [5, 28], these
potentials are both shifted such that the potentials reach 0 kJ/
mol for any distance greater than 1.1 nm, the cutoff distance. In
case of the LJ potential, ten levels of interaction are deﬁned, differ-
ing in the LJ well depth (epsilon ranging from 5.6 to 2.0 kJ/mol),
but with the same bead size (a sigma of 0.47 nm is used for the
standard beads, except for interaction level IX, which has an
increased sigma of 0.62 nm). For all possible pairs of CG bead
types, one of those ten interaction levels has been assigned. These
levels have been chosen based on the experimental water-oil parti-
tioning of small molecules that are represented by each of the
beads. Only the Q-beads bear an explicit charge and additionally
interact via the Coulomb potential with a relative dielectric con-
stant εrel ¼ 15 for explicit screening. Together with the use of a shift
function, this effectively results in a distance-dependent screening.
To allow for the mapping of aliphatic and aromatic ring struc-
tures (such as cyclohexane or benzene), a smaller bead (denoted
with preﬁx “S”) was introduced, mapping two or three nonhydro-
gen atoms to a single CG bead. The S beads have a reduced sigma of
Equation 1 The treatment of nonbonded interactions in the Martini force ﬁeld is based in shifted and truncated
12–6 Lennard-Jones (VLJ) and Coulomb potentials (VCoul)
A Practical View of the Martini Force Field
107

0.43 nm and a scaled interaction strength corresponding to 75% of
their standard bead counterpart. In the current model only S-S
interactions make use of the reduced interaction scheme, that is,
interaction with normal (N) particles are treated as N-N interac-
tions. For the full parametrization scheme and interaction table, we
would like to refer to the original paper of Marrink et al. [5] After
the release of Martini 2.0 in 2007, an extra bead size has been
added to the collection. The tiny (T) bead was introduced for the
mapping of nucleotides and follows three/two-to-one mapping.
Such a tiny bead is needed for correct stacking distance of the
nucleobases in the double-stranded helix. The interaction strength
of the T beads is not reduced, but their sigma is 0.32 nm. T beads
interact with S and N beads as S-S and N-N, respectively (see Note
3) [11]. Besides the extra bead size, many new beads were intro-
duced to satisfy the needs of speciﬁc models, as nucleic acids
[11, 12], polymers [14–16, 20], nanoparticles [21], and some
sugars [10, 29]. Polarizable water models [30, 31] have been
designed for modeling of systems where implicit screening of elec-
trostatic interactions caused by reorienting water dipoles is neces-
sary (as discussed in Note 4).
Where the nonbonded interactions follow a “top-down” mod-
eling approach (making use of experimental partitioning data), the
bonded interactions are usually extracted via a “bottom-up”
approach, based on reference atomistic data. This is achieved by
mapping the heavy atoms of an atomistic simulation to a pseudo
CG trajectory. The CG beads are usually placed at the centers of
mass of the atoms they represent. From these pseudo CG trajec-
tories, the bonded parameters can be extracted and compared to
the CG model under development. By changing the bonded para-
meters, one should try to maximize the overlap of the conforma-
tional distributions of the pseudo CG and real CG models. This is
an iterative process that should be repeated for achieving the best
results. However, the philosophy of the Martini force ﬁeld is to use
(mainly) simple bonded potentials (as shown in Eq. 2); therefore,
perfect overlap is not always achieved. Also, be aware that the
bonded parameters might inﬂuence the partitioning of your mole-
cule or even other macroscopic properties (e.g., area per lipid—
APL—for bilayers and radius of gyration for polymers). Therefore,
validation of your CG model against experimental data, after satis-
factory bonded parameters have been achieved, is considered good
practice. An in-depth tutorial of parametrizing a new molecule can
Equation 2 Examples of simple bonded potentials used in Martini: two-body harmonic potential (Vbond), three-
body angular potential (Vangle), and four-body dihedral angle potential (Vdihedral)
108
Bart M. H. Bruininks et al.

be found under “Tutorials” at the Martini web page (cgmartini.nl),
which is summarized in Fig. 1c. Automatic parametrization
approaches could be an easier but probably a less accurate option
to generate Martini models [32]. However, they could provide
prospects for high-throughput simulation methodologies [33].
Note that, to keep the secondary structure of proteins and nucleo-
tides close to the target state (e.g., crystal structure), Martini makes
uses of additional harmonic bonds that deﬁne an elastic network
(see Note 5).
In the next subsection of this chapter, we will describe a hands-
on tutorial, which uses one of our current projects (lipoplex-
membrane fusion) as a guide. This practice addresses useful exam-
ples of how to build Martini CG models of macromolecules
(double-stranded DNA), (solvated) liquid crystals, and complex
asymmetric membranes. At the ﬁnal part, all these CG models are
put together for particle-membrane fusion simulations.
2
Hands-On: Cationic Lipid-DNA Lipoplexes for Gene Transfer
This section will be a guide for setting up a CG simulation of a
lipoplex-membrane fusion experiment making use of the Martini
2.0 force ﬁeld with the DNA extension [11]. We will start with a
small introduction regarding lipoplexes and their biological rele-
vance. However, the main objective of this section is to show the
construction of such a complex system using the Martini approach,
from A to Z.
Lipoplexes are complexes of genetic material and lipids used for
transfection in gene therapy. Due to the high negative charge of
nucleotide polymers (DNA, RNA), they do not readily cross the
hydrophobic core of biological membranes via a passive mecha-
nism. Another downside of using naked DNA for therapeutic
purposes is its low half-life time in the bloodstream [34]. In lipo-
plexes, the packing architecture is such that, upon fusion with a
membrane or vesicle, its content is mainly released on the side of
the membrane opposing the leaﬂet of initial fusion [35]. This
allows the escape of the genetic material from the endosome in
which the lipoplex is trapped after being taken up by the cell via
endocytosis. Transfection of cells utilizing depathogenized viral
vectors currently has a much higher transfection efﬁcacy than the
lipid-based vectors or any other non-viral-based method [36].
However, depathogenized viral vectors still trigger the immune
system in humans, causing their application in medical gene therapy
to be limited [37]. Another drawback of viral vectors compared to
their nonviral counterparts is their high preparation cost [37].
Therefore, increasing the efﬁcacy of nonviral vectors for transfec-
tion is required for the development of gene therapy as a safe and
affordable medical treatment.
A Practical View of the Martini Force Field
109

In this hands-on section, we will build a lipoplex using one of
the earlier lipoplex compositions used [38], in which the DNA is
entrapped in an inverted hexagonal (HII) lipid phase. First, the
lipoplex itself will be built using 1,2-dioleoyl-sn-glycerol-phos-
phoethanolamine (DOPE) as the helper lipid and 1,2-dioleoyl-3-
trimethylammoniopropane (DOTAP) as the cationic lipid in a 4:1
ratio. In this example, we will use double-stranded (ds) DNA oli-
gomers, with a length of 24 base pairs (bp), as the gene carrier.
Replacing the DNA with RNA should not change the general
procedure described in this section, though this was not speciﬁcally
tested. Lastly, the constructed lipolex will be solvated and fused
with an asymmetric bilayer mimicking the endosomal membrane.
During this section, lines preceded with a “$” are to be exe-
cuted in the terminal. This hands-on was designed to be used in
combination with GROMACS 2016.3 [39]. Visual Molecular
Dynamics (VMD) version 1.9.3 [40] was used for visual inspection,
and Python 2.7 was the default python compiler used for all python
scripts, unless stated otherwise.
2.1
Building a Liquid
Lipoplex Crystal
For building the inverted hexagonal phase (HII), we will make use
of the procedures described in refs. [41, 42]. We start with prepar-
ing a Martini CG model for DNA, which is to be rested on top of a
bilayer. Then, we duplicate this DNA-membrane stack and perform
energy minimization, equilibration, and ﬁnally a production run to
form the crystal lattice.
2.1.1
Preparing the DNA
First, download the .pdb ﬁle from the martini website. This struc-
ture corresponds to a sequence of DNA with 24 bases in each
strand ([CGCGAATTCGCG]2).
$
wget
http://cgmartini.nl/images/parameters/dna/24bp_AA2CG_
stiff.tar.gz
$ tar -xvf 24bp_AA2CG_stiff.tar.gz
To transform an atomistic DNA structure into a CG structure,
we will use martinize-dna (cgmartini.nl, under Downloads, Force
ﬁeld parameters, DNA) [11, 12]. Before running martinize-dna,
we should remove the ion and water molecules from the .pdb. Be
aware that if you have used a DNA structure builder, to obtain a
different length or sequence of DNA (e.g., using scfbio-iitd.res.in),
the ﬁnal atom and residue names have to follow the default pdb
nomenclature.
The 24bp_cleaned.gro ﬁle is already made compatible with the
martinize-dna script and we can perform the all-atom (AA) to CG
transformation (Fig. 2a). The output includes a CG.pdb and the
CG.itp ﬁles. We will use a stiff elastic network to imply a strict
helical structure to our DNA (see Note 5). Later on, this could be
replaced by a softer elastic network if desired.
110
Bart M. H. Bruininks et al.

Fig. 2 Building a lipoplex with Martini: (a) The CG mapping of a 24 bp dsDNA; (b1, b2) shows two views of the
initial bilayer with a double-stranded DNA; (c) This system is replicated to form a lamellar conﬁguration; (d)
After running 45 ns of MD simulations, the lamellar phase is converted to an inverted HII phase (liquid lipoplex
crystal); (e) The liquid lipoplex crystal is solvated and coated with lipids; (f) An example of a lipoplex-
membrane fusion experiment
A Practical View of the Martini Force Field
111

$ python martinize-dna.py -dnatype ds-stiff -f 24bp_cleaned.
gro -x 24bp_CG.pdb
Always read the output and check, for example, if the number
of chains or base pairs speciﬁed matches that what you expect. In
our case, this should be two chains (A and B), each containing
24 nucleotides. We need to rotate the DNA such that it will lie
parallel to the membrane. We will use GROMACS to do so.
$
gmx
editconf -f
24bp_CG.pdb
-rotate 0
90
0
-o
24bp_CG_ro
tated.gro
2.1.2
Creating the DNA
Bilayer Stack
Now, we need to generate a simulation box containing our DNA
CG model and a symmetric bilayer with the desired lipid composi-
tion. We will aim at a 4:1 ratio of DOPE and DOTAP, respectively.
To do so, we will use insane [43]. Insane is a python program,
developed in-house, which generates an initial CG conﬁguration
using a grid-based approach. This procedure makes insane one of
the fastest initial state builders for membranes with or without
incorporated protein(s). The latest stable version of insane can be
downloaded from our web page (cgmartini.nl, under downloads/
tools). We will generate a small piece of membrane with DNA,
which will be used later on to generate the HII phase with
dsDNA inside its channels.
$ python insane.py -l DOPE:4 -l DOTAP:1 -alname DOTAP -alhead
’C’ -allink ’G G’ -altail "CDCC CDCC" -x 11 -y 6.5 -z 7 -f
24bp_CG_rotated.gro -dm 3.5 -o bilayer_1DNA.gro -sol W -salt
0.150 -sold 0.87
As DOTAP is not a default lipid, its topology needs to be
completely described in insane using the ﬂags “-alname” (name of
the new lipid), “-alhead” (groups in the lipid head, where “C”
deﬁnes the head as choline), “-allink” (groups in the lipid linkers,
with “G G” deﬁning two ester groups), and “-altail” (deﬁne the
lipid tails, where each “C” indicates four carbon atoms in a linear
saturated chain, while “D” indicates four linear carbon atoms con-
taining a single unsaturation). This should generate a box contain-
ing roughly 187 DOPE, 44 DOTAP, plus the DNA at physiological
salt concentration (as shown in Fig. 2b1, b2). The target ratio of
atomistic water with respect to the amount of lipids is around 8:1
[41, 42]. For Martini water, with one bead representing four water
molecules, the target ratio is thus 2:1. Do remember that the
charge of the DNA is not yet neutralized and this will be 46.
Therefore, overshooting your target amount of water by 46 is
recommended, for we will transform those waters into sodium
beads.
To
generate
a
bigger
complex,
we
will
copy
the
112
Bart M. H. Bruininks et al.

DNA-membrane conﬁguration along its axis perpendicular to the
channel normal (as shown in Fig. 2c).
$ gmx genconf -f bilayer_1DNA.gro -o 2bilayer_4DNA.gro -nbox
1 2 2
2.1.3
Preparing
the Topology Files
Next, we need to generate a top ﬁle which matches the
“2bilayer_4DNA.gro” composition and order and makes use of
the correct topology ﬁles. To achieve a charge neutral system, we
will reduce the number of waters in the topology by 46 and add
46 sodium ions right underneath (this will transform 46 water
molecules into sodium ions). The ﬁnal topology should resemble
the example topology below.
#include "martini-dna-150909/martini_v2.1-dna.itp"
#include "martini-dna-150909/martini_v2.0_ions.itp"
#include "martini_v2.0_DOTAP.itp"
#include "martini_v2.0_DOPE_02.itp"
#define RUBBER_BANDS
#include "Nucleic_A+Nucleic_B.itp"
[ system ]
; name
Martini system containing 4 dsDNA and 2 bilayers
[ molecules ]
; name
number
Nucleic_A+Nucleic_B
1
DOPE
89
DOTAP
22
DOPE
89
DOTAP
22
W
106
NA
49
CL
47
. . . another 3 times for the 2bilayer4_DNA.gro
2.1.4
Running EM/EQ
and Production
Now, we have all the components together, and we can start
running an energy minimization, equilibration, and production
run. We will not go into much details, but the default settings can
be found at cgmartini.nl (under Downloads, Force ﬁeld para-
meters, Input parameters). To perform energy minimization, we
need to set the integrator to “steep” and 1000 steps should sufﬁce.
$ gmx grompp -f em.mdp -c 2bilayer_4DNA.gro -p topol.top -o em.
tpr -maxwarn 1
$ gmx mdrun -deffnm em -v
A Practical View of the Martini Force Field
113

The “-maxwarn” ﬂag is to allow overwriting name mismatches
between the .gro and .top ﬁle, caused by the DOTAP and added
sodium ions. After running the minimization, we need to create an
index ﬁle (index.ndx) to use for our temperature coupling scheme.
We will create a group for all lipids, the DNA, and the water plus
ions. For the sake of this tutorial, those groups are called “Lipids,”
“DNA” and “W_IONS” respectively. The index groups can be
easily generated from the em.gro, using “gmx make_ndx.”
$ gmx make_ndx -f em.gro -o index.ndx
Before we run the equilibration, we need to ﬁx the DNA in the
x dimension. This will help with a smooth conversion from the
periodic crystal to the solvated naked lipoplex. To do so, we need to
add a few lines of code to the bottom of our “Nucleic_A
+Nucleic_B.itp.”
#ifdef CONSTRAINED_X
[ position_restraints ]
; ai funct fcx
fcy
fcz
1
1
500
0
0 ; restrains to a plane (y-z-plane)
305
1
500
0
0 ; restrains to a plane (y-z-plane)
#endif
For equilibration, 250,000 steps at a 2 fs time step should
sufﬁce. We will use anisotropic pressure coupling, and the berend-
sen barostat for improved stability. Do not forget to set the inte-
grator back to “md” and add “deﬁne ¼ -DCONSTRAINED_X”.
In the “mdrun” command we add an “rdd” of 2 to prevent
instabilities due to our long elastic bonds in the DNA.
$ gmx grompp -f eq.mdp -c em.gro -p topol.top -n index.ndx -o
eq.tpr
$ gmx mdrun -deffnm eq -v -rdd 2.0
For the production run, we will use roughly the same settings
as those for equilibration. Important is that the pressure coupling
will be changed from “berendsen” to “parrinello-rahman,” and the
time step for the integrator should be larger. For systems contain-
ing DNA, a time step of 10 fs is the maximum (see Note 6).
$ gmx grompp -f md.mdp -c eq.gro -p topol.top -n index.ndx -o
md.tpr
$ gmx mdrun -deffnm md -v -rdd 2.0 -nsteps -1
Keep running the simulation until inspection with VMD shows
full formation of the HII phase.
114
Bart M. H. Bruininks et al.

While writing this hands-on section, it took roughly 2,268,000
steps (~45 ns CG time, which should correspond to ~200 ns real
time, as explained in Note 7) to complete the formation of the
inverted HII phase (as shown in Fig. 2d). The ﬁnal frame can be
extracted using VMD, and for the sake of this tutorial, we assume it
was named md.gro. We are now ﬁnished with the construction of
the liquid lipoplex crystal. Do keep in mind that this crystal was
made to be solvated, and therefore, its PBC conditions were not
optimized for a perfect hexagonal unit cell.
2.2
Solvating
a Liquid Lipoplex
Crystal
For the second part of this tutorial, we will use the liquid lipoplex
crystal we generated in part 2.1. The goal is to extract the crystal in
such a manner that the channel geometry is not disturbed (naked
lipoplex). We will also have to add an extra layer of lipids around our
extracted lipoplex to act as a coat (coated lipoplex, as shown in
Fig. 2e). Once we have added the coating lipids, we can solvate the
whole system. From there on, we energy minimize, equilibrate,
and run a production run in a similar manner as that described in
part 2.1.
2.2.1
Extracting
the Periodic Crystal
The liquid lipoplex crystal generated before contains four channels
with four strands of dsDNA in total. This could be considered the
smallest possible crystal under cubic periodic boundary conditions.
To generate a larger crystal, we use “gmx genconf,” to copy this
box in the desired dimensions. Even though we will stick to the
2  2 geometry for the solvated lipoplex, we will duplicate the box
in its “y” and “z” dimensions. By doing so, we can make extraction
of a 2  2 lipoplex much easier. This might not seem logical as of
yet, but bear with us, and you will see that this is indeed the case. To
prevent weird indexes after copying the box, we will ﬁrst make the .
gro ﬁle “whole.”
$ gmx trjconv -f 2bilayer_4DNA.gro -pbc whole -o 2bilayer_4D
NA_whole.gro
$ gmx genconf -f 2bilayer_4DNA_whole.gro -o 4bilayer_16DNA.gro
-nbox 1 2 2
We will use VMD to select the inner four strands of DNA.
Then, we will make an area selection around these strands of DNA
to include all their lipids, water, and ions.
$ vmd 4bilayer_16DNA.gro
“same resid as within 20 of index
your_central_4_DNA_strands”
Export the selected structure and name it “naked_lipoplex.
gro.”
A Practical View of the Martini Force Field
115

2.2.2
Coating the Naked
Lipoplex
After extracting the naked lipoplex, we will have to add coating
lipids. This can be achieved in many ways. One of the options is to
increase the selection range in the VMD command used above in
combination with excluding any DNA beads. However, the lipids
you will have selected in doing so are in a structure that is rather
stable. This would make equilibration of the coat of the lipoplex,
potentially, a long and expensive process. Therefore, we will make
use of PACKMOL, another
tool for initial state building
[44]. PACKMOL differs from insane, for it uses a packing optimi-
zation in deﬁned regions of space. This makes PACKMOL much
slower than insane for building simple membranes, but it allows
for the addition of molecules to an already complex geometry.
PACKMOL can be downloaded free of charge at the web page of
the University of Campinas (www.ime.unicamp.br/~martinez/
packmol/).
We need to coat the lipoplex with a nice monolayer, and we will
make a rough initial approximation by regarding each face of the
naked lipoplex as an independent plane. Then we will use the
average area per lipid (APL) to calculate the amount of lipids we
would need to cover the total area of our lipoplex. To calculate the
APL of our mixture, we have to set up a symmetrical bilayer con-
taining our lipid concentrations. A bilayer of 10  10 nm2 will be
large enough to get an accurate APL for the lipids used in this
tutorial. This bilayer can be constructed following the same proto-
col as that described in part 2.1. To calculate the APL, we need to
simulate the solvated bilayer (under semi-isotropic pressure cou-
pling) up to the point that the box dimensions are stable for a while.
Then we can extract the box dimensions over time using “gmx
energy”.
$ gmx energy -f md.edr
Select either the x or y dimension as the preferred output
and calculate the average value over the period where it is stable
(e.g., the last 10%).
APLdope,dotap ¼
2x2
Number of lipids  0:65 nm2
To roughly calculate the area the outer monolayer (the coat)
has to cover, you can use VMD. Pressing “2” in the visualization
screen will allow you to select two particles and measure the dis-
tance between them. We will add 2 nm to each side to accommo-
date for the fact that the outer leaﬂet has an increased distance to
span with respect to the inner leaﬂet (which we are measuring).
Lipidsadded ¼ 2
x þ 2
ð
Þ y þ 2
ð
Þ
½
 þ
x þ 2
ð
Þ z þ 2
ð
Þ
½
 þ
y þ 2
ð
Þ z þ 2
ð
Þ
½

ð
Þ
APLdope,dotap
 1800 ) 1440 DOPE,360 DOTAP
116
Bart M. H. Bruininks et al.

After estimating the amount of lipids we need, we will use
PACKMOL to conﬁgure them around our lipoplex. Extensive
tutorials for using PACKMOL can be found at their web page
(m3g.iqm.unicamp.br/packmol/). As PACKMOL makes use of .
pdb ﬁles, we will have to convert our individual ﬁles to .pdb.
$ gmx editconf -f your_file.gro -o your_file.pdb
Use VMD to obtain a .pdb ﬁle for each of the lipids using the
export coordinates function, with a single lipid selected. After gen-
erating the correct PACKMOL input ﬁle we can run it.
$ packmol < coating_lipoplex.inp
Running PACKMOL can take up quite some time and some-
times no correct packing can be found, even upon running for
multiple hours. Try playing around with the excluded and included
volume which are deﬁned in the input ﬁle (outside and inside box),
until a satisfactory packing has been achieved. The output structure
is presumed to be named “coated_lipoplex.pdb.” Convert the .pdb
to a .gro in the same manner as was demonstrated in part 1.
2.2.3
Tidying Up the GRO
and Topology Files
To tidy things up, you need to sort the “coated_lipoplex.gro” and
make sure that the topology has the same order and number of
molecules as your sorted .gro. After sorting and updating our
topology, we will solvate the lipoplex using insane.
$ python insane.py -f coated_lipoplex.pdb -o
solvated_lipoplex.gro -sol W -salt 0.15 -pbc cubic
Add the amount of waters and ions insane added to your sorted
topology. During the PACKMOL step, we also added more
DOTAP, which causes our system to have a nonzero net charge.
Therefore, we will replace some of the added water in the insane
step with CL to obtain a net charge of zero. To prevent freezing of
water (see Note 1), we will also replace 10% of the waters in our last
entry with antifreeze water (WF).
2.2.4
Running EM/EQ
and Production
To ﬁnish, we need to energy minimize and equilibrate our system
before we can start the production run. To do so, we can use the
same
procedure
as
before,
but
we
will
now
use
the
“-DCONSTRAINED_XYZ” ﬂag (constructed in the same manner
as before, but now in XYZ) until large deformations are resolved,
and we will use isotropic pressure coupling. It will take roughly
10 μs for the solvated lipoplex to equilibrate its outer coat. You can
use “gmx gyrate” to inspect if the lipoplex’ shape has stabilized. If
the outer coat is too loose, or tight, try adding more or less coating
A Practical View of the Martini Force Field
117

lipids with PACKMOL, or change the included and excluded vol-
ume. We are now done with solvating a liquid lipoplex crystal.
2.3
Lipoplex Fusion
with an Asymmetric
Complex Membrane
For the lipoplex fusion with an asymmetric complex bilayer, we will
use the solvated and equilibrated lipoplex generated in part 2.2 of
this hands-on section, in combination with a generated asymmetric
bilayer.
2.3.1
Creating
an Asymmetric Bilayer
By now, we are able to generate complex bilayers; however, we
never attempted to generate an asymmetric one. Here, we want
to model an endosomal type membrane containing a 1:1 DPPC/
DOPC mixture in the upper leaﬂet and a 2:2:1 DPPC/DOPC/
DOPS mixture in the bottom one. To do so, we will use insane
again. However, ﬁrst we generate each leaﬂet of our asymmetric
bilayer as a symmetrical bilayer. Thus, for each asymmetric bilayer,
you need to run two symmetric simulations. From those simula-
tions, we can obtain the complex APL for each of the leaﬂets. To do
so, we can use the same protocol as described in part 2.1. After
obtaining the complex APL for each of the leaﬂets, we will use
insane to generate the complex bilayer using the obtained APL of
each leaﬂet. This will make sure that the ﬁnal tension in the two
leaﬂets is equal. An example is given below:
$ python insane.py -u DPPC:1 -u DOPC:1 -ua APLDPPC-DOPC -l DPPC:2
-l DOPC:2 -l DOPS:1 -a APLDPPC-DOPC-DOPS -x 10 -y 10 -z 10 -sol W
-salt 0.150 -o complex_asymmetrical_bilayer.gro
The topology ﬁles for a wide range of lipids can be found at our
web
page
(cgmartini.nl,
under
Downloads).
Make
the
corresponding topology using the output of insane and equilibrate
the membrane. This will take roughly 500 ns, though the amount
of time equilibration will take increases with the complexity of the
membrane. Equilibration of the membrane can be done as before in
parts 2.1 and 2.2; do make sure that you use semi-isotropic pressure
coupling and that your membrane lies in the xy plane.
2.3.2
Combining
the Asymmetric Bilayer
and the Lipoplex
After obtaining an equilibrated membrane, we will remove the
waters and ions. We now have an equilibrated membrane in vacuum
and a solvated lipoplex. To be able to combine the lipoplex and the
membrane, we will also extract the solvated lipoplex from its envi-
ronment. To do so, we will use VMD.
$ vmd solvated_lipoplex_equilibrated.gro
To extract the lipoplex from its environment, we will use the
following selection and export it, as described in part 2.1.
118
Bart M. H. Bruininks et al.

“pbwithin 15 of (resname DOPE DOTAP or name “SC.∗” “BB.
∗”)” We will save it as “extracted_lipoplex.gro”.
To combine our extracted lipoplex with the equilibrated asym-
metric complex membrane, we create a combined .gro ﬁle. To do
so, we copy the content of the membrane into the new .gro ﬁle
(“lipoplex-membrane.gro”). Remove the ﬁnal line (the box
description). Add the content of the “extracted_lipoplex.gro” but
remove the header line, atom count, and box description.
If the lipoplex and membrane overlap, you can use “gmx
editconf -translate x y z” to shift your lipoplex. Solvate the system
as before using insane. Generate a topology ﬁle that matches the .
gro one. Energy minimize and equilibrate (as before in part 1)
using semi-isotropic pressure coupling. The equilibrated system
should resemble Fig. 2f. To perform an unbiased fusion experi-
ment, you have to simulate for a long time to observe adhesion,
stalk formation, and transfection. However, such a simulation
would take up a large amount of computational time; therefore,
you could add biasing forces to drive membrane adhesion and
initiate stalk formation. From there on, you could remove all
biasing forces to observe the fusion process after initial stalk
formation [1].
2.3.3
Alternative
Methods and Tools
We suggest to the reader as possible follow-up steps for this hands-
on section, the building of even more complex CG systems. For
example, a lipoplex fusion experiment within a vesicle (a process
that could mimic the DNA transfection event in the early endo-
some). However, the current implementation of insane does not
allow us to build such lipid structures yet. A user-friendly option for
this problem could be the usage of a graphical user interface as
CHARMM-GUI Martini Maker [45, 46]. In the current imple-
mentation, this program can build Martini models of micelles,
nanodiscs, bilayers, and vesicles. We hope that the tools and tips
presented above will help you on your way with your own imple-
mentations of the Martini forceﬁeld. If you would like to learn
more about Martini, you can visit our web page for other tutorials
(cgmartini.nl). For any questions regarding the implementation of
the Martini force ﬁeld for your project(s), we would like to direct
you to the forum at our web page.
3
Outlook
Since its initial publications, the Martini force ﬁeld has been devel-
oped and tested in a broad range of applications, from simple lipid
bilayers to complex fusion processes as detailed here for the lipoplex
hands-on. Despite the huge success of the model, certain problems
have been reported as excessive protein and sugar aggregation (see
A Practical View of the Martini Force Field
119

Note 4), and water freezing (also described in Note 1). Along with
the modeling demand of new and challenging systems, these lim-
itations pushed the MD group of Groningen to improve the CG
beads—the fundamental building blocks of Martini—until now
largely untouched since version 2. One of the main features of the
forthcoming version, entitled Martini 3, is the re-parametrization
of small (S) and tiny (T) beads, designed to be fully balanced with
the normal (N) size beads. New chemical-type beads were also
tuned to model systems not included in the current version. For
instance, we will have more beads with hydrogen-bonding capabil-
ities (including all polar and nonpolar beads) and charged beads
dedicated for modeling divalent ions. Water has also its own special
bead, parametrized to improve its miscibility with other beads and
also avoid freezing problems. The interaction matrix was modiﬁed,
including more interaction levels and smoother transitions between
the beads. In this aspect, special attention was taken regarding
charged beads, with trends in solvent polarization and ion-pi inter-
actions implicitly included in the Lennard-Jones potential with
neutral beads. Together with other new features of the model,
preliminary tests indicate a signiﬁcant improvement of proteins,
sugars, and nucleic acids in Martini 3. Besides, exciting new systems
seem to nicely behave, including MD simulations of ionic liquids,
and coacervates, as well as protein-ligand binding. We conclude
that a promising new era of Martini CG simulations is coming.
4
Notes
This last section of the chapter contains a series of notes, which
include useful information, limitations, and tips for problems that
can arise using the Martini force ﬁeld.
1. Limited stability of ﬂuid phase and water freezing problem: This
is a known consequence of the use of the LJ 12–6 potential for
the nonbonded interactions. The thermodynamic behavior of
solid-ﬂuid and gas-ﬂuid interfaces should therefore be inter-
preted with care, at least at the quantitative level. In applica-
tions where such interfaces are formed (especially water-vapor),
these limitations have to be kept in mind. In biomolecular
simulations, a related problem is the potential freezing of the
Martini water model. The LJ parameters for water (5.0 kJ/mol
and 0.47 nm) put the model into the solid-state region of the
LJ phase diagram. However, the use of a shifted and truncated
potential reduces the long-range attractive part and the CG
water is more ﬂuid compared to the standard LJ particle. While
the freezing temperature is higher than it should be (around
290 K, [3, 5, 47]), in most applications, freezing is not
observed as long as no nucleation site is formed. At lower
120
Bart M. H. Bruininks et al.

temperatures, rapid freezing is a potential problem in systems
where a nucleation site is already present (such as an ordered
bilayer surface) or when periodicity enhances the long-range
ordering. In these cases, a simple pragmatic solution is the
addition of 10% antifreeze particles into the bulk water [5].
2. Entropy-enthalpy compensation: Martini parameterization is
based on partition free energies. The inherent entropy loss on
coarse graining is necessarily compensated for by a reduced
enthalpy term [24]. The enthalpy/entropy balance of many
processes may therefore be biased when modeled at the CG
level and affect its temperature dependence, although not nec-
essarily weakening it. For instance, the temperature-dependent
hydration free energy for linear alkanes was found to be more
pronounced in the CG representation compared to an AA
representation [24]. As is true for any force ﬁeld, applications
outside the temperature range used for parameterization
(270–330 K) have to be considered with care. Although abso-
lute entropies are clearly underestimated due to the loss of
atomistic degrees of freedom, entropy differences can still be
accurate [48].
3. “Sticky problem” in sugars and proteins: In the past years, the
Martini force ﬁeld has showed some speciﬁc limitations involv-
ing excessive interactions between certain classes of molecules.
For example, protein-protein interactions in water solution
seem to be overestimated [49]. To a lesser extent, this effect
was also demonstrated for some transmembrane proteins [50].
Recently, mono, oligo- and polysaccharides were found to
aggregate in simulations even at moderate concentrations,
below their solubility limit [51]. These similar problems (called
together here as “sticky problems”) could be attenuate for
pragmatic solutions, as down-scaling of the Lennard-Jones
parameters between the solutes [49–51]. Another option is to
increase the interactions with the solvent, which was success-
fully applied to study protein-crowded environments [52]. The
usage of S-beads for the modeling of carbohydrate rings seems
to reduce their aggregation propensity, as shown in the
re-parametrization of gangliosides [53]. All these possible pro-
cedures are not ideal solutions, as they are applied without a
deeper understanding of the reasons behind the sticky problem.
Besides, scaling factors are speciﬁc for classes of molecules and
could potentially change important properties of the systems, as
the correct binding mode of proteins dimers [50]. New rules for
the usage of S- and T-beads together with re-parametrization of
Martini (e.g., including speciﬁc cross-interactions between
standard and S/T bead sizes) showed to be crucial to reduce
the excessive interactions (results not published yet). In the near
future, all these features will be released as new version of the
Martini force ﬁeld (coined as version 3.0).
A Practical View of the Martini Force Field
121

4. Electrostatic interactions and implicit screening: Another difﬁ-
culty encountered in our CG model, and perhaps in most
coarse-graining approaches, is the correct modeling of the
partitioning of polar and charged compounds into a low dielec-
tric medium. Because of the implicit screening, the interaction
strength of polar substances is underestimated in nonpolariz-
able solvents. Applications involving the formation of polar/
charged complexes in a nonpolar environment are especially
prone to be affected. The inability to form a transmembrane
water pore upon dragging a lipid across the membrane is an
example [5, 54]. The development of a Martini water model
that includes orientational polarization by the means of a dipole
represented by two drude charges attached to each water bead
allows to correct for some of these effects [30]. Apart from the
implicit screening in the CG model, the neglect of long-range
electrostatic forces poses a further limitation. Pairwise interac-
tions beyond 1.1 nm (between 2 and 3 CG beads away) are not
taken into account. In principle, long-range electrostatic inter-
actions could be added to the CG model, in ways similar to
those used in atomistic simulations [31]. In particular, PME in
combination with the polarizable Martini water model is
often used.
5. Fixed structure for proteins and nucleic acids: In applications of
peptides, proteins, and nucleic acids, one has to be aware that
structure transformations are not modeled in the current
parameterization.
For
proteins,
the
secondary
structure
(SS) is essentially ﬁxed by the use of bond angle and dihedral
angle potential energy functions. The backbone bead type is
also a function of the SS, to take into account the fact that when
involved in interactions stabilizing a given element, the back-
bone is less prompted to engage in other interactions. The
backbone interaction strength is therefore decreased when
involved in a SS element. This approach allows discrimination
between various secondary structure elements but prevents
realistic transitions between them. Processes in which folding
and unfolding are playing a substantial role are therefore not
suitable for modeling with the current Martini force ﬁeld.
However, movements of SS elements with respect to each
other are possible and were shown to be quite realistic, for
instance, in modeling the gating of a membrane-embedded
mechanosensitive channel [55]. In cases where the speciﬁcity
of the local deformations of the protein backbone is important,
the use of other approaches are necessary, as combining Martini
with an elastic network [56, 57] or with structure-based CG
models [58]. In the case of peripheral membrane proteins,
further corrections in the side-chain dihedral angles could
also be necessary [59]. Martini DNA and RNA can be used
122
Bart M. H. Bruininks et al.

to model both single and double-stranded structures. For the
single-stranded settings, the structure is considered ﬂexible,
while double-stranded could be modeled with two different
elastic networks: a soft model which has a cutoff of 1.2 nm and
a force constant of 13 kJ/mol/nm2, and the stiff model which
has a cutoff of 1.0 nm and a 500 kJ/mol/nm2 force constant
[11, 12].
6. Time step: Martini has been parameterized using time steps in
the range of 10–40 fs. Whether you can use 40 fs or have to
settle for a somewhat smaller time step depends on your sys-
tem, and on your attitude toward coarse-grained modeling, as
explained below. First, the Martini force ﬁeld is not an atomis-
tically detailed force ﬁeld. Many assumptions underlie the
model, the major one being the neglect of some of the atomis-
tic degrees of freedom. As a result, the interactions between
particles are effective ones and the energy landscape is highly
simpliﬁed. This simpliﬁed energy landscape allows for a greatly
increased sampling speed at the cost of a loss of detail. This
makes CG models in general so powerful. The emphasis, there-
fore, should not be to sample the energy landscape as accurately
as possible, but rather, as effectively as possible. This is in
contrast to traditional all-atom models, for which the energy
landscape is more realistic and an accurate integration scheme is
more important. In practice, the inherent “fuzziness” of the
Martini model makes the presence of small energy sinks or
sources a less critical problem than in accurate atomistic simu-
lations. Second and most importantly, structural properties are
rather robust with respect to the time step; for a time step up to
40 fs, there are no noticeable effects on structural properties of
the systems investigated. Moreover, thermodynamic properties
such as the free energy of solvation also appear insensitive to the
size of the time step. Thus, if the goal is to generate represen-
tative ensembles quickly, large time steps seem acceptable.
Whereas
one
can
debate
the
ﬁrst
argument
(i.e.,
the
“idealist” vs. “pragmatic” view of the power of CG simula-
tions), the second argument (i.e., the insensitivity of both
structural and thermodynamic properties to the magnitude of
the time step) implies that a reduction of the time step to 10 fs
or below, as has been suggested [60], is a waste of computer
time [47]. Nevertheless, time steps of 40 fs and beyond may be
pushing the limits too far for certain systems. For some sys-
tems, as nucleic acids, time steps higher than 10 fs promote
simulation instability [11, 12]. We therefore recommend a time
step of 10–20 fs to be on the safe side. Of course, one should
always check whether or not results are biased by the choices
made. Given that the largest simpliﬁcations are made at the
level of the interaction potentials, this can best be done by
comparing to results obtained using more detailed models.
A Practical View of the Martini Force Field
123

7. Effective timescale: The CG dynamics are faster than the AA
dynamics, because the CG interactions are much smoother
compared to atomistic interactions. The effective friction
caused by the ﬁne-grained degrees of freedom is missing.
Based on comparison of diffusion constants for a range of
systems (including simple solvents and lipids) in the CG
model versus experimental data, the effective time sampled
using CG interactions is three- to eightfold larger. When inter-
preting the simulation results with the CG model, a standard
conversion factor of 4 has been used, which is the effective
speed-up factor in the diffusion dynamics of CG water com-
pared to real water. The same order of acceleration of the
overall dynamics is also observed for a number of other pro-
cesses, including the permeation rate of water across a mem-
brane [3], the sampling of the local conﬁgurational space of a
lipid [61], the aggregation rate of lipids into bilayers [3], and
the self-diffusion of lipids [3, 5], transmembrane peptides [62],
and proteins [63]. However, the speed-up factor can be quite
different in other systems or for other processes, and in general
no simple conversion of the time axis can be performed. Partic-
ularly for protein and nucleic acid systems, no extensive testing
of the actual speed-up due to the CG dynamics has been
performed, although protein translational and rotational diffu-
sion was found to be in good agreement with experimental data
in simulations of CG rhodopsin [63]. In general, the timescale
of the simulations has to be interpreted with care.
Acknowledgments
The authors would like to thank the many people who have directly
and indirectly contributed to the development of the Martini force
ﬁeld. In particular Alex de Vries, Helgi I. Ingolfsson, Manuel
N. Melo, Tsjerk Wassenaar, Xavier Periole and all the past and
present members of the MD group in Groningen, as well as the
many users abroad, are acknowledged for their dynamism and
enthusiasm in using, criticizing, and improving Martini.
References
1. Marrink SJ, Mark AE (2003) The mechanism
of vesicle fusion as revealed by molecular
dynamics
simulations.
J
Am
Chem
Soc
125:11144–11145
2. Marrink
SJ,
Mark
AE
(2003)
Molecular
dynamics simulation of the formation, struc-
ture, and dynamics of small phospholipid vesi-
cles. J Am Chem Soc 125:15233–15242
3. Marrink SJ, de Vries AH, Mark AE (2004)
Coarse grained model for semiquantitative
lipid simulations. J Phys Chem B 108:750–760
4. Marrink SJ, Risselada J, Mark AE (2005) Sim-
ulation of gel phase formation and melting in
lipid bilayers using a coarse grained model.
Chem Phys Lipids 135:223–244
5. Marrink SJ, Jelger Risselada H, Yeﬁmov S et al
(2007) The MARTINI force ﬁeld: coarse
124
Bart M. H. Bruininks et al.

grained model for biomolecular simulations. J
Phys Chem B 111:7812–7824
6. Risselada HJ, Marrink SJ (2008) The molecu-
lar face of lipid rafts in model membranes. Proc
Natl Acad Sci U S A 105:17367–17372
7. Monticelli L, Kandasamy SK, Periole X et al
(2008) The MARTINI coarse-grained force
ﬁeld: extension to proteins. J Chem Theory
Comput 4:819–834
8. de Jong DH, Singh G, Bennett WFD et al
(2013) Improved parameters for the Martini
coarse-grained protein force ﬁeld. J Chem The-
ory Comput 9:687–697
9. Lo´pez CA, Rzepiela AJ, de Vries AH et al
(2009) Martini coarse-grained
force ﬁeld:
extension to carbohydrates. J Chem Theory
Comput 5:3195–3210
10. Lo´pez CA, Bellesia G, Redondo A et al (2015)
MARTINI coarse-grained model for crystalline
cellulose
microﬁbers.
J
Phys
Chem
B
119:465–473
11. Uusitalo JJ, Ingo´lfsson HI, Akhshi P et al
(2015)
Martini
coarse-grained
force ﬁeld:
extension to DNA. J Chem Theory Comput
11:3932–3945
12. Uusitalo JJ, Ingo´lfsson HI, Marrink SJ et al
(2017)
Martini
coarse-grained
force ﬁeld:
extension to RNA. Biophys J 113:246–256
13. de Jong DH, Liguori N, van den Berg T et al
(2015) Atomistic and coarse grain topologies
for the cofactors associated with the photosys-
tem
II
core
complex.
J
Phys
Chem
B
119:7791–7803
14. Panizon E, Bochicchio D, Monticelli L et al
(2015) MARTINI coarse-grained models of
polyethylene and polypropylene. J Phys Chem
B 119:8209–8216
15. Rossi G, Fuchs PFJ, Barnoud J et al (2012) A
coarse-grained MARTINI model of polyethyl-
ene glycol and of polyoxyethylene alkyl ether
surfactants. J Phys Chem B 116:14353–14362
16. Rossi G, Monticelli L, Puisto SR et al (2011)
Coarse-graining polymers with the MARTINI
force-ﬁeld: polystyrene as a benchmark case.
Soft Matter 7:698–708
17. Alessandri R, Uusitalo JJ, de Vries AH et al
(2017)
Bulk
heterojunction
morphologies
with atomistic resolution from coarse-grain
solvent evaporation simulations. J Am Chem
Soc 139:3697–3705
18. Liu J, Qiu L, Alessandri R et al (2018) Enhanc-
ing molecular n-type doping of donor-acceptor
copolymers by tailoring side chains. Adv Mater
30(7):1704630
19. Qiu L, Liu J, Alessandri R et al (2017) Enhanc-
ing doping efﬁciency by improving host-
dopant miscibility for fullerene-based n-type
thermoelectrics.
J
Mater
Chem
A
Mater
Energy Sustain 5:21234–21241
20. Grunewald F, Rossi G, de Vries AH et al
(2018) Transferable MARTINI model of poly
(ethylene
oxide).
J
Phys
Chem
B
122:7436–7449
21. Monticelli L (2012) On atomistic and coarse-
grained models for C60 fullerene. J Chem The-
ory Comput 8:1370–1378
22. Ingolfsson HI, Tieleman P, Marrink S (2015)
Lipid organization of the plasma membrane.
Biophys J 108:358a
23. Van Eerden FJ, Melo MN, Frederix PWJM et al
(2017) Exchange pathways of plastoquinone
and plastoquinol in the photosystem II com-
plex. Nat Commun 8:15214
24. Baron R, Trzesniak D, de Vries AH et al (2007)
Comparison of thermodynamic properties of
coarse-grained
and
atomic-level
simulation
models. ChemPhysChem 8:452–461
25. Shih AY, Arkhipov A, Freddolino PL et al
(2006) Coarse grained proteinlipid model
with application to lipoprotein particles. J
Phys Chem B 110:3674–3684
26. Shih AY, Freddolino PL, Arkhipov A et al
(2007)
Assembly
of
lipoprotein
particles
revealed by coarse-grained molecular dynamics
simulations. J Struct Biol 157:579–592
27. Periole X, Marrink S-J (2013) The Martini
coarse-grained force ﬁeld. Methods Mol Biol
924:533–565
28. de Jong DH, Baoukina S, Ingo´lfsson HI et al
(2016) Martini straight: boosting performance
using a shorter cutoff and GPUs. Comput Phys
Commun 199:1–7
29. Lo´pez CA, de Vries AH, Marrink SJ (2013)
Computational
microscopy
of
cyclodextrin
mediated cholesterol extraction from lipid
model membranes. Sci Rep 3:2071
30. Yesylevskyy SO, Sch€afer LV, Sengupta D et al
(2010) Polarizable water model for the coarse-
grained MARTINI force ﬁeld. PLoS Comput
Biol 6:e1000810
31. Michalowsky J, Sch€afer LV, Holm C et al
(2017) A reﬁned polarizable water model for
the coarse-grained MARTINI force ﬁeld with
long-range electrostatic interactions. J Chem
Phys 146:054501
32. Bereau T, Kremer K (2015) Automated param-
etrization of the coarse-grained Martini force
ﬁeld for small organic molecules. J Chem The-
ory Comput 11:2783–2791
33. Menichetti R, Kanekal KH, Kremer K et al
(2017) In silico screening of drug-membrane
thermodynamics
reveals
linear
relations
between bulk partitioning and the potential of
mean force. J Chem Phys 147:125101
A Practical View of the Martini Force Field
125

34. Kawabata K, Takakura Y, Hashida M (1995)
The fate of plasmid DNA after intravenous
injection in mice: involvement of scavenger
receptors in its hepatic uptake. Pharm Res
12:825–830
35. Zhao Y, Huang L (2014) Lipid nanoparticles
for gene delivery. Adv Genet 88:13–36
36. Ramamoorth M (2015) Non viral vectors in
gene therapy - an overview. J Clin Diagn Res
9:Ge01–Ge06
37. Chira S, Jackson CS, Oprea I et al (2015)
Progresses towards safe and efﬁcient gene ther-
apy vectors. Oncotarget 6:30675–30703
38. Ciani L, Ristori S, Salvati A et al (2004)
DOTAP/DOPE and DC-Chol/DOPE lipo-
plexes for gene delivery: zeta potential mea-
surements
and
electron
spin
resonance
spectra. Biochim Biophys Acta 1664:70–79
39. Abraham MJ, Murtola T, Schulz R et al (2015)
GROMACS:
high
performance
molecular
simulations
through
multi-level
parallelism
from laptops to supercomputers. SoftwareX
1–2:19–25
40. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph 14:33–38, 27–28
41. Marrink S-J, Mark AE (2004) Molecular view
of hexagonal phase formation in phospholipid
membranes. Biophys J 87:3894–3900
42. Corsi J, Hawtin RW, Ces O et al (2010) DNA
lipoplexes: formation of the inverse hexagonal
phase observed by coarse-grained molecular
dynamics
simulation.
Langmuir
26:12119–12125
43. Wassenaar TA, Ingo´lfsson HI, Bo¨ckmann RA
et al (2015) Computational lipidomics with
insane: a versatile tool for generating custom
membranes for molecular simulations. J Chem
Theory Comput 11:2144–2155
44. Martı´nez L, Andrade R, Birgin EG et al (2009)
PACKMOL: a package for building initial con-
ﬁgurations for molecular dynamics simulations.
J Comput Chem 30:2157–2164
45. Qi Y, Cheng X, Im W (2015) CHARMM-GUI
Martini maker for coarse-grained simulations.
Biophys J 108:161a
46. Hsu P-C, Bruininks BMH, Jefferies D et al
(2017) CHARMM-GUI Martini Maker for
modeling and simulation of complex bacterial
membranes with lipopolysaccharides. J Com-
put Chem 38:2354–2363
47. Marrink SJ, Periole X, Peter Tieleman D et al
(2010) Comment on “On using a too large
integration time step in molecular dynamics
simulations of coarse-grained molecular mod-
els” by M. Winger, D. Trzesniak, R. Baron and
W. F. van Gunsteren, Phys. Chem. Chem.
Phys., 2009, 11, 1934. Phys Chem Chem
Phys 12:2254
48. Yano Y, Matsuzaki K (2006) Measurement of
thermodynamic parameters for hydrophobic
mismatch 1: self-association of a transmem-
brane helix. Biochemistry 45:3370–3378
49. Stark AC, Andrews CT, Elcock AH (2013)
Toward
optimized
potential
functions
for
protein-protein interactions in aqueous solu-
tions: osmotic second virial coefﬁcient calcula-
tions using the MARTINI coarse-grained force
ﬁeld. J Chem Theory Comput 9:4176–4185
50. Javanainen M, Martinez-Seara H, Vattulainen I
(2017) Excessive aggregation of membrane
proteins in the Martini model. PLoS One 12:
e0187936
51. Schmalhorst PS, Deluweit F, Scherrers R et al
(2017) Overcoming the limitations of the
MARTINI force ﬁeld in simulations of poly-
saccharides.
J
Chem
Theory
Comput
13:5039–5053
52. Liu B, A˚ berg C, van Eerden FJ et al (2017)
Design and properties of genetically encoded
probes for sensing macromolecular crowding.
Biophys J 112:1929–1939
53. Gu R-X, Ingo´lfsson HI, de Vries AH et al
(2017)
Ganglioside-lipid
and
ganglioside-
protein interactions revealed by coarse-grained
and atomistic molecular dynamics simulations.
J Phys Chem B 121:3262–3275
54. Bennett WFD, Peter Tieleman D (2011) Water
defect and pore formation in atomistic and
coarse-grained lipid membranes: pushing the
limits of coarse graining. J Chem Theory Com-
put 7:2981–2988
55. Melo MN, Arnarez C, Sikkema H et al (2017)
High-throughput
simulations
reveal
membrane-mediated effects of alcohols on
MscL gating. J Am Chem Soc 139:2664–2671
56. Periole X, Cavalli M, Marrink S-J et al (2009)
Combining an elastic network with a coarse-
grained
molecular
force
ﬁeld:
structure,
dynamics, and intermolecular recognition. J
Chem Theory Comput 5:2531–2543
57. Siuda I, Thøgersen L (2013) Conformational
ﬂexibility of the leucine binding protein exam-
ined by protein domain coarse-grained molec-
ular dynamics. J Mol Model 19:4931–4945
58. Poma AB, Cieplak M, Theodorakis PE (2017)
Combining the MARTINI and structure-based
coarse-grained approaches for the molecular
dynamics studies of conformational transitions
in
proteins.
J
Chem
Theory
Comput
13:1366–1374
59. Herzog FA, Braun L, Schoen I et al (2016)
Improved side chain dynamics in MARTINI
126
Bart M. H. Bruininks et al.

simulations of protein–lipid interfaces. J Chem
Theory Comput 12:2446–2458
60. Winger M, Trzesniak D, Baron R et al (2009)
On using a too large integration time step in
molecular dynamics simulations of coarse-
grained molecular models. Phys Chem Chem
Phys 11(12):1934–1941
61. Baron R, de Vries AH, Hu¨nenberger PH et al
(2006) Conﬁgurational entropies of lipids in
pure and mixed bilayers from atomic-level and
coarse-grained
molecular
dynamics
simula-
tions. J Phys Chem B 110:15602–15614
62. Ramadurai S, Holt A, Sch€afer LV et al (2010)
Inﬂuence of hydrophobic mismatch and amino
acid composition on the lateral diffusion of
transmembrane
peptides.
Biophys
J
99:1447–1454
63. Periole X, Huber T, Marrink S-J et al (2007) G
protein-coupled
receptors
self-assemble
in
dynamics simulations of model bilayers. J Am
Chem Soc 129:10126–10132
A Practical View of the Martini Force Field
127

Chapter 6
Using SMOG 2 to Simulate Complex Biomolecular
Assemblies
Mariana Levi, Prasad Bandarkar, Huan Yang, Ailun Wang,
Udayan Mohanty, Jeffrey K. Noel, and Paul C. Whitford
Abstract
Over the last 20 years, the application of structure-based (Go¯-like) models has ranged from protein folding
with coarse-grained models to all-atom representations of large-scale molecular assemblies. While there are
many variants that may be employed, the common feature of these models is that some (or all) of the
stabilizing energetic interactions are deﬁned based on the knowledge of a particular experimentally
obtained conformation. With the generality of this approach, there was a need for a versatile computational
platform for designing and implementing this class of models. To this end, the SMOG 2 software package
provides an easy-to-use interface, where the user has full control of the model parameters. This software
allows the user to edit XML-formatted ﬁles in order to provide deﬁnitions of new structure-based models.
SMOG 2 reads these “template” ﬁles and maps the interactions onto speciﬁc structures, which are provided
in PDB format. The force ﬁeld ﬁles produced by SMOG 2 may then be used to perform simulations with a
variety of popular molecular dynamics suites. In this chapter, we describe some of the key features of the
SMOG 2 package, while providing examples and strategies for applying these techniques to complex (often
large-scale) molecular assemblies, such as the ribosome.
Key words SMOG, Structure-based model, Go¯-model, Coarse-grained models, Protein folding
1
Introduction
When performing a molecular dynamics (MD) simulation, the
equations of motions are repeatedly integrated for a given Hamil-
tonian. In the context of molecular biophysics, there is a wide
variety of Hamiltonians available, where each is typically described
in terms of its potential energy function (i.e., the “model” or “force
ﬁeld”). Available models differ in terms of both spatial resolution
(e.g., all-atom or coarse-grained) and energetic detail. In the pres-
ent chapter, we will discuss one class of models, called “structure-
based models.” The hallmark feature of structure-based models is
that the user predeﬁnes the dominant potential energy minima,
prior to performing a simulation. Typically, the minima are deﬁned
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_6, © Springer Science+Business Media, LLC, part of Springer Nature 2019
129

such that they correspond to experimentally obtained (i.e.,
“native”) structures. Originally, this type of model was inspired by
the principle of minimal frustration [1], which states that the
interactions that dominate the energy landscape of protein folding
are those formed in the native conﬁguration. This led to the devel-
opment of early coarse-grained (i.e., “Go¯-like”) models [2, 3] of
proteins, which were subsequently extended to all-atom resolution
[4, 5].
While purely structure-based models have been widely used in
the study of protein folding and function [6, 7], these models can
also serve as a basis for exploring the role of non-speciﬁc energetic
interactions. For example, protein–DNA interactions have been
extensively studied through the use of structure-based models
that include electrostatic effects [8, 9], and RNA–RNA electrostat-
ics have been characterized in the context of the ribosome
[10]. Beyond the inclusion of electrostatic interactions, one can
envision a more general spectrum of models that range from purely
structure-based (i.e., only native interactions are stabilizing) to
completely non-speciﬁc (e.g., CHARMM [11], AMBER [12])
representations.
To provide a ﬂexible platform for the construction of structure-
based model variants, the SMOG 2 [13] software package was
developed. The principle that guided the development of this
software is that any user should be able to deﬁne/extend
structure-based models without modifying the source code. To
enable this, SMOG 2 reads user-provided “template” ﬁles that
deﬁne rules for constructing structure-based models. SMOG
2 maps the deﬁnitions in the template ﬁles onto a biomolecular
system, which allows the user to perform their simulations with a
number of popular MD engines (Gromacs [14], NAMD [15], or
openMM [16]). This allows the user to rapidly alter the resolution
of the model, introduce charges on speciﬁc atoms/residues, or
simulate new residues (e.g., modiﬁed residues). From the user’s
perspective, only simple modiﬁcations to XML-formatted template
ﬁles are required to construct a structure-based model that is suited
to address speciﬁc physical questions.
In this chapter, we provide step-by-step descriptions of how to
utilize the SMOG 2 software package. In particular, we provide
examples for how to effectively utilize this software to simulate
large biomolecular systems, such as the ribosome. Our intention
is that this guide will provide the technical steps necessary for a
typical computational researcher to develop their own structure-
based models and apply them to complex molecular assemblies. For
a thorough discussion of the general utility of these models, other
references are recommended [17, 18].
130
Mariana Levi et al.

2
Materials
This chapter describes the SMOG 2 software package [13]. The
commands and modules are speciﬁc to a recently released version of
SMOG 2 (v2.1). As mentioned above, the purpose of SMOG 2 is to
read a set of template ﬁles, which deﬁne the rules for constructing a
structure-based model, and then map these interactions onto a
speciﬁc structure of a biomolecular system (provided in PDB for-
mat). The output of SMOG 2 is a set of force ﬁeld and coordinate
ﬁles that are formatted for use with Gromacs [14] (v4, or v5). Here,
we provide instructions for how to utilize these models with Gro-
macs v5. However, other groups have ported these models to
NAMD and openMM, thereby allowing the SMOG 2 output ﬁles
to be used with a broader range of MD engines (see user’s manual
for details).
3
Methods
In this section, we ﬁrst provide an overview for how to generate a
structure-based model and perform a simulation. This is followed
by tutorials for using SMOG tools, as well as examples for how to
design new models (e.g., novel residues or introduction of
charges).
3.1
Basic Steps
When Using SMOG 2
To illustrate the basic utility of SMOG 2, we will brieﬂy describe the
steps necessary to simulate an arbitrary protein. For this example,
we will simulate chymotrypsin inhibitor 2 (CI2) [19]. For the steps
below, $SMOG_PATH will refer to the main directory of the locally
installed version of SMOG 2, and smog2 will refer to the SMOG
2 executable (located in $SMOG_PATH/bin). It is assumed that the
SMOG executables are in the user’s path (this is automatically
performed by the configure.smog2 script).
3.1.1
Preprocess the
Structure (PDB) File
Download and save the atomic coordinates of CI2 (PDB ID: 2CI2)
to a ﬁle named 2CI2.pdb. The PDB identiﬁers ATOM, HETATM,
BOND, TER, and END are recognized by SMOG 2. TER lines separate
covalently bonded chains and BOND lines indicate that SMOG
2 should include system-speciﬁc covalent bonds, e.g., a disulﬁde
bond. Since CI2 is a monomer with standard residue naming, only
the ATOM and END lines are relevant. One may extract these lines
with a simple one-line grep command:
> $ grep ’^ATOM ∖|^END’ 2CI2.pdb > CI2.atoms.pdb
Simulating Biomolecular Assemblies
131

Once you have removed all comments from the PDB ﬁle, it is
necessary to rename any terminal residues, such that they are con-
sistent with default SMOG 2 conventions. For example, a
C-terminal protein residue has an OXT atom. In order for the
template ﬁles to be properly mapped to the PDB structure, terminal
residues must be distinguished from non-terminal residues. To
facilitate this step, SMOG 2 includes the smog_adjustPDB tool.
When using the default SMOG models, smog_adjustPDB may be
used with the following ﬂags:
> $ smog_adjustPDB -i CI2.atoms.pdb -default
If an output ﬁle name is not speciﬁed, then the new PDB ﬁle will be
named adjusted.pdb. For tips on PDB formatting, see Note 1.
3.1.2
Use SMOG 2 to
Generate a Force Field
For this example, we will use the all-atom structure-based model
[5], which is deﬁned by the template ﬁles found in the directory
$SMOG_PATH/share/templates/SBM_AA. To generate the force
ﬁeld ﬁles, issue the command:
> $ smog2 -i adjusted.pdb -AA
An equivalent invocation would be
> $ smog2 -i adjusted.pdb -t $SMOG_PATH/share/templates/SBM_AA
Note that, if you want to use a non-standard (e.g., user-modiﬁed)
force ﬁeld, then the second invocation should be used, where the
location of the template ﬁles would be given after the -t ﬂag.
After SMOG 2 has successfully completed, four ﬁles will be
generated (default names below):
l
smog.gro: Atomic coordinates in Gromacs format.
l
smog.top: Topology ﬁle that deﬁnes the potential energy
function.
l
smog.contacts: List of atom pairs used to deﬁne stabilizing
“native” contacts in smog.top (listed in the [ pairs ] section).
l
smog.ndx: Gromacs index ﬁle listing the atoms of each chain as
a separate group.
In this example, the ﬁle 2CI2.pdb works smoothly with SMOG
2 since it contains coordinates for all non-Hydrogen atoms, uses
standard nomenclature for the 20 amino acids and their constituent
atoms, and it does not have non-standard amino acids. PDB ﬁles
often contain atoms, residues, or small molecules that differ from,
or are not deﬁned in, the SMOG 2 default templates. Such
instances will trigger errors during SMOG 2 processing.
132
Mariana Levi et al.

3.1.3
Perform the
Simulation in Gromacs
After using SMOG 2, one may perform a simulation with a number
of MD engines. For the steps below, we provide the commands
necessary to utilize Gromacs v5. When using Gromacs, one must
create a portable xdr ﬁle (in the example below, run.tpr) that
contains the coordinates, force ﬁeld, and simulation parameters.
The mdp ﬁle deﬁnes the simulation settings, such as the integrator/
thermostat (e.g., Berendsen, Langevin dynamics, Nose´ Hoover),
time step size, number of time steps, and simulated temperature.
For the commands below, it is assumed that the Gromacs 5 execut-
able (gmx) is in your path. To prepare your simulation, you should
ﬁrst center your molecule within a box using the editconf mod-
ule of Gromacs:
> $ gmx editconf -f smog.gro -c -d 2
-o centered.gro
In this example, -d 2 tells Gromacs to deﬁne a box such that the
solute is 2 nm from any edge (for tips on setting the box size, see
Note 2). Next, use the grompp module of Gromacs to prepare
your tpr ﬁle:
> $ gmx grompp -f min.mdp -p smog.top -maxwarn 1 -c centered.gro -o min
In this example, it is assumed that the mdp ﬁle named min.mdp is
being used to instruct Gromacs to perform steepest-descent energy
minimization (see user manual, or example ﬁles distributed with
SMOG 2, for recommended settings in the mdp ﬁle). Note: It is
typically necessary to use the ﬂag -maxwarn 1 when using SMOG
models. The reason is that, to improve performance, periodic
boundary conditions are almost always employed. However, since
most SMOG models do not include solvent, the potential energy is
translationally and rotationally invariant. Accordingly, it is necessary
to remove center of mass rotation, even though periodic bound-
aries are used. If the molecule does not traverse any boundaries
(which can be ensured by using a very large box), one may ignore
the warning regarding the removal of center of mass rotational
freedom in a periodic system.
After you have created the tpr ﬁle with grompp, perform
energy minimization with mdrun:
> $ gmx mdrun -v -deffnm min -noddcheck [-nt numberOfThreads]
By using the ﬂag -deffnm min all output ﬁles will be named “min”
with the appropriate sufﬁx appended. After minimization, repeat
the grompp and mdrun steps using a different mdp (for this exam-
ple, run.mdp) ﬁle in which integrator ¼ steep is replaced with
Simulating Biomolecular Assemblies
133

integrator ¼ sd. This will indicate to Gromacs that stochastic
dynamics should be used.
> $ gmx grompp -f run.mdp -p smog.top -maxwarn 1 -c min.gro -o run.tpr
> $ gmx mdrun -v -deffnm run -noddcheck [-nt numberOfThreads]
3.2
Simulating a
Portion of a Larger
Assembly
It is a common practice in the MD community to only simulate a
portion of a larger complex. For example, recent studies on the
ribosome have involved free-energy calculations where only the
atoms
near
bimolecular
interfaces
are
represented
[20, 21]. Large-scale conformational changes of tRNA inside the
ribosome have also performed where only a portion of the ribo-
some is explicitly represented [10, 22]. In all of these examples, the
rationale for simulating a subset of atoms is that the bimolecular
interactions of interest are not always associated with global con-
formational rearrangements. Accordingly, to reduce computational
demand (see Note 3), a minimal number of atoms is included in
each simulation.
smog_extract, included as a part of the SMOG 2 package,
can be used to prepare a structure-based model for a fraction of a
larger assembly. Speciﬁcally, smog_extract will read a set of
Gromacs-formatted force ﬁeld ﬁles and generate new ﬁles that
describe a subset of the original atoms. In doing so, it ensures
that the truncated system provides an identical energetic represen-
tation of the preserved atoms. Using smog_extract is also sim-
pler, in terms of user intervention, than removing atoms from the
PDB ﬁle and then using SMOG 2 to generate a new model. For
example, if one were to use the latter approach, the prepared PDB
ﬁle would still need to conform to the deﬁned templates (e.g., every
atom deﬁned in each residue would need to be present). In addi-
tion, the force ﬁeld could be perturbed by the use of a truncated
PDB (e.g., scaling of energetics is system dependent [13] and the
generated contact map could be impacted by the absence of atoms).
smog_extract processes input structure (gro) and topology
(top) ﬁles describing the molecular system, and then produces the
corresponding ﬁles for a truncated system. The list of atoms to be
included in the truncated system is supplied as a Gromacs-
formatted index ﬁle (ndx). This list of selected atoms can be
prepared using your choice of molecular visualization programs,
such as VMD (see Note 4). A sample invocation of smog_extract
would be
> $ smog_extract -f fullsystem.top -g fullsystem.gro -n truncated.ndx
A general concern when simulating a subsystem is that the removal
of atoms may lead to artiﬁcial changes in molecular ﬂexibility at the
boundary of the truncated system. To address this, one may option-
ally instruct smog_extract to introduce a harmonic position
134
Mariana Levi et al.

restraint on every atom that has an interaction (bond, bond angle,
dihedral, contact) removed during the truncation step. For this, the
user simply needs to supply the ﬂag -restraint <val>, where
<val> is the energetic weight of the restraints. The restraint
strength is in units of energy/nm2, where energy is in reduced
units (see Note 5). As a side note, since reduced units are employed,
it is important that one properly interprets the reported simulated
time scale. For a discussion on time scale estimates, see Note 6.
3.3
Avoiding
Artiﬁcial Boundary
Effects in Truncated
Systems
One of the strengths of structure-based models is that they are able
to provide descriptions of the overall ﬂexibility of biomolecules that
are consistent with experimental observations and more highly
detailed models. For example, the root mean squared ﬂuctuations
(rmsf) of each residue in the ribosome have been shown to be
similar between SMOG models, explicit-solvent simulations, and
crystallographic B-factors [23]. Similarly, the structural ﬂuctuations
of single molecules are also often consistent between SMOG and
explicit-solvent models [5, 24]. Since the scale of these ﬂuctuations
can directly inﬂuence the kinetics of other conformational processes
and free-energy barriers [10, 22], an accurate representation of
ﬂexibility is important when studying any molecular assembly.
By truncating a molecular system using smog_extract (see
Subheading 3.2), the mobility of the atoms at the system boundary
is likely to be perturbed. To avoid introducing these artiﬁcial
effects, it is necessary that one tunes the strength of the atomic
restraints imposed on the boundary atoms. Below, we describe a
ﬂuctuation-matching protocol that has been applied to study the
ribosome [10]. In this approach, heterogeneous isotropic spatial
restraints are reﬁned, such that the dynamics in the truncated
systems are consistent with the full assembly.
To apply ﬂuctuation-matching techniques, the user must estab-
lish reference values for the mobility of each atom and then introduce
atomic restraints in the truncated system. To deﬁne the reference
ﬂuctuations, the following steps may be applied: First, generate a
SMOG model and perform a simulation of the complete molecular
system at a desired reference temperature. For tips on selecting a
simulation temperature, see Note 7. Next, use smog_extract
to generate a new set of top/gro ﬁles for the user-deﬁned subset
of atoms. It is necessary to use the -restraint option, in order
to automatically introduce restraints on the boundary atoms.
This will result in the position_restraints directive being
added to the output top ﬁle (see Listing 1).
Simulating Biomolecular Assemblies
135

Listing 1
Example top ﬁle in which homogeneous isotropic position
restraints are added by smog_extract
[ position_restraints ]
1 1 100.00 100.00 100.00
2 1 100.00 100.00 100.00
. . .
Finally, for the boundary atoms identiﬁed by smog_extract,
calculate the rmsf values in the simulation of the full system. The
Gromacs module rmsf may be used for this step.
> $ gmx rmsf -f traj.xtc -s run.tpr -n boundary_full.ndx -o rmsf.xvg
This will provide the rmsf value of each boundary atom, from which
you can calculate the msf of each atom (msfref
i ) and the average msf
value of the boundary atoms hmsfiref. These will serve as the refer-
ence values during reﬁnement.
After establishing a set of reference msf values for the boundary
atoms, one needs to iteratively perform simulations of the
truncated system and update the position_restraints section
of the truncated top ﬁle. The speciﬁc steps are
1. Perform a simulation of the truncated system using the
truncated top ﬁle. Note: Since the potential energy is not
translationally invariant when position restraints are included,
it is important that the center of mass velocity is not removed
during the simulation. That is, include comm_mode¼none in
the mdp ﬁle.
2. Calculate the rmsf values of the boundary atoms.
> $ gmx rmsf -f traj.xtc -s run.tpr -n boundary_truncated.ndx -nofit
From this, calculate the mean msf value for the truncated
system hmsfitrunc.
3. Rescale the weight of every position restraint (listed in the top
ﬁle) by the factor hmsfitrunc/hmsfiref.
4. Return to step 1.
The above steps should be repeated until hmsfitrunc/hmsfiref
 1, at which point the average msf values in the truncated system
are consistent with the full system. However, this global rescaling
does not ensure that the mobility of each atom is consistent. To
further improve agreement between the truncated and full systems,
136
Mariana Levi et al.

the above steps may be continued, though in the subsequent itera-
tions each atomic restraint should be rescaled individually by
msf trunc
i
=msf ref
i . After multiple iterations, one will obtain a topol-
ogy ﬁle in which heterogeneous restraints are present (Listing 2).
Listing 2
Example top ﬁle specifying isotropic position restraints.
[ position_restraints ]
1 1 154.338 154.338 154.338
2 1 122.95 122.95 122.95
. . .
It should be noted that more sophisticated reﬁnement algo-
rithms are available. For example, the method of Savelyev and
Papoian follows a similar sequence of steps, though the updated
values of the parameters (restraints) account for the possibility of
coupling between restrained atoms [25]. In addition, the described
approach may be extended to include anisotropic restraints
[22]. For an example of the effectiveness of the approach, see Fig. 1.
Fig. 1 Comparison of rmsf values obtained for simulations of the ribosome and a truncated subset of ribosomal
atoms. (Left) Atomic rmsf values obtained in a simulation of a complete ribosome, compared to the values
obtained in a truncated system in which homogeneous isotropic position restraints are applied. As expected,
there is relatively poor agreement when a homogeneous value of the restraint is used for all atoms. (Right)
Comparison of rmsf values obtained after reﬁnement of isotropic [10] and then anisotropic position restraints
[22]. After reﬁnement, the rmsf values have a correlation coefﬁcient of 0.99 and a mean squared deviation of
0.03 A˚ 2
Simulating Biomolecular Assemblies
137

3.4
Extending
Structure-Based
Models to Include Non-
standard Residues
The default SMOG 2 templates provide deﬁnitions of common
amino acid and nucleic acid residues. However, there are many
assemblies that are inﬂuenced by post-transcriptional and post-
translational modiﬁcations, and large-scale conformational changes
are often associated with ligand binding/release. To include these
molecular features in SMOG models, one needs to deﬁne addi-
tional residue types. Here, we use phosphothreonine (TPO) as an
example for how to add an amino acid deﬁnition to the SMOG
2 template ﬁles. For this example, we will demonstrate how to
modify the standard all-atom structure-based model [5] that is
distributed with SMOG 2. Since we are simply adding another
amino acid (as opposed to adding inorganic molecules or prosthetic
groups), one only needs to introduce the following modiﬁcations
to the biomolecular structure ﬁle (SBM_AA/AA-whitford09.
bif):
1. Place a residue tag within the residues element (Listing 3).
The residue tag requires at least two attributes: name (TPO)
and type (amino). The residue name must be identical to the
name appearing in the PDB ﬁle.
Listing 3
Amino acid residue section of bif ﬁle
2. Deﬁne each atom in the residue by providing atom child ele-
ments within the atoms element. Similar to the residue name,
the atom names must match the convention used in the input
PDB ﬁle. Since we are extending the standard SMOG model,
where all energetic parameters are homogeneous (e.g., all
138
Mariana Levi et al.

bonds have the same spring constant), the bType, nbType,
and pairType are given the same common values of B_1,
NB_1, and P_1 (Listing 4). For instructions on how to include
heterogeneous
energetic
parameters,
consult
the
user’s
manual.
Listing 4
Adding the atoms section to the residue structure
Simulating Biomolecular Assemblies
139

3. Insert deﬁnitions for the chemical bonds within the bonds
element.
Listing 5
Adding the bonds to the residue deﬁnition
140
Mariana Levi et al.

Each bond element deﬁnes a single bond between two
atoms. A required attribute of each bond is the energyGroup
attribute, which indicates how to deﬁne dihedral interactions
about the bond. In the default all-atom model, bb_a (sc_a)
indicates that the bond is part of the protein backbone (side
chain) and that the associated dihedral should be given cosine
potentials.
4. Deﬁne any improper dihedral angles. An improper dihedral is
used to ensure chirality about an atom for which not all bonded
atoms are explicitly represented (e.g., due to the removal of
hydrogen atoms), or to ensure that trigonal planar covalent
geometry is maintained. Each improper dihedral associated
with a residue should be listed within an improper element.
For TPO, there are two such dihedrals: CB-CA-C-N and
CA-CB-OG1-CG2.
Listing 6
Adding the improper dihedral section to the residue
structure
384
<impropers>
385
<improper>
386
<atom>CB </atom>
387
<atom>CA </atom>
388
<atom>C </atom>
389
<atom>N </atom>
390
</improper>
391
<improper>
392
<atom>CA </atom>
393
<atom>CB </atom>
394
<atom>OG1 </atom>
395
<atom>CG2 </atom>
396
</improper>
397
</impropers>
3.5
Including
Electrostatics in
Structure-Based
Models
As discussed above, one of the key features of SMOG 2 is that it
allows the user to adjust force ﬁeld deﬁnitions without requiring
source-code modiﬁcations. One way in which these models are
often extended is to include an explicit representation of electro-
static interactions [8–10]. Here, we describe multiple ways in which
these models may be extended to include electrostatic interactions
and ionic effects.
3.5.1
Assigning Charges
There are two methods by which a user may deﬁne charges within
the SMOG 2 framework. First, it is possible to deﬁne atom types
that carry speciﬁc charges. The second method is to override atom
Simulating Biomolecular Assemblies
141

type deﬁnitions and provide charge deﬁnitions for speciﬁc atoms
within a deﬁned residue.
Adding Charges by Atom Type: It is common in classical mechan-
ics force ﬁelds for one to provide identical energetic parameters for
many chemically similar atoms. For example, one may assign the
same parameters (mass, charge, vdW) to every backbone P atom in
RNA. To implement this in SMOG 2, one needs to modify the nb
and bif template ﬁles. The ﬁrst step is to use the nonbond element
to deﬁne a new atom type. In the example below (Listing 7) the
nbType NB_P will be used to describe P atoms.
Listing 7
Modifying nb ﬁle to change the charge and mass
In this example, the NB_P type is deﬁned to be of mass 2.5,
charge of 1, and have only a repulsive non-speciﬁc vdW parame-
ter. The second step is to use the nbType type within an atom
element of a residue (e.g., Listing 4).
After modifying the template ﬁles to deﬁne a new atom type,
these templates may be used with SMOG 2. After running SMOG
2, if an atom of the newly deﬁned type is present in the molecular
system, then its deﬁnition will appear under the atom types
directive (Listing 8) in the generate top ﬁle.
Listing 8
Charge information shown in top ﬁle
[ atomtypes ]
; name
mass
charge
ptype c6
c12
NB_1
1.0000
0.000000
A
0.00000 e+00
5.96046 e 09
NB_P
2.5000
1.000000
A
0.00000 e +00
5.96046 e 09
Adding Charges to Residue Deﬁnitions: While it is possible to
always use nbType deﬁnitions to assign charges, it is sometimes
142
Mariana Levi et al.

more convenient to deﬁne charges for speciﬁc atoms within a
particular residue. For example, one may add a charge to the P
atom of each adenine residue by adding the charge attribute to the
atom element P for residue A. It should be noted that explicit
assignment of charge to speciﬁc atoms will supersede any charge
assignments based on the nbType. For example, if the P atom were
given nbType of NB_1, which is deﬁned to have charge 0, the
explicit attribute charge¼"-1" would override this value. This
type of assignment will result in charges appearing on speciﬁc
atoms under the atoms directive of the top ﬁle.
3.5.2
Modeling
Monovalent and Divalent
Ions
The dynamics of many biomolecular assemblies, especially those
containing RNA (e.g., the ribosome and spliceosome), are strongly
inﬂuenced by the presence of ions. Ions may bind to assemblies and
contribute to structural stability, or the local environment of diffuse
ions may lead to non-linear electrostatic screening effects. Depend-
ing on what aspects of ion dynamics you would like to study, there
are multiple strategies for deﬁning ions in structure-based models.
Here, we describe multiple SMOG tools that can facilitate the study
of ionic effects in biomolecular assemblies. Before discussing the
technical aspects of introducing ions, it is important to note that
the user is ultimately responsible for calibrating the most appropri-
ate scale and functional form of the electrostatic interactions. While
there are some general guidelines for calibrating energy scales, such
considerations must be applied on a per-model basis (see Note 8).
Implicit Treatment of Ions: To simulate a system in which mono-
valent ions are treated implicitly, one may introduce electrostatics
via a screened Debye-Hu¨ckel (DH) potential. To accomplish this,
one needs to generate a look-up table that deﬁnes the functional
form of the desired electrostatic potential. This table is then
provided as input to Gromacs. For this step, SMOG 2 provides
the tool smog_tablegen, which may be invoked with the follow-
ing ﬂags:
> $ smog_tablegen -M <M> -N <N> -ic <ion conc.>
-sd <elec. switch dist.> ∖∖
-sc < elec. truncate dist.> -tl <table length> -table <output name>
Here, <M> and <N> denote the exponents of the attractive and
repulsive non-bonded interactions, respectively. If M and N are not
provided, default values of 6 and 12 are used. <ion conc.> is
the desired effective monovalent ion concentration, which deter-
mines the Debye screening length, as implemented previously
[8]. Finally, in order to ensure continuous ﬁrst derivatives, a fourth-
order polynomial is added to the force over the distance range
<elec. switch dist.> to <elec. truncate dist.> (nm).
Employing the DH potential in a speciﬁc simulation requires
minor changes to both the grompp and mdrun steps. Before
Simulating Biomolecular Assemblies
143

running grompp, the mdp ﬁle must deﬁne coulombtype¼User
and vdwtype¼User. When running the simulation with mdrun,
the user has to indicate where the table ﬁle is located:
> $ gmx mdrun -s run.tpr -noddcheck -table table.xvg -tablep table.xvg
In this example, table.xvg is located in the current working
directory.
Explicit Treatment of Ions: In addition to implicitly accounting
for monovalent ions, SMOG 2 also supports explicit ion models.
Explicit ions may be treated as structural (bound) or diffuse/bulk.
For these two representations, different steps should be followed.
Bound/Structural Ions: One way in which to describe bound ions
is to treat them as part of the biomolecular structure. For example,
crystallographic models of the ribosome often include “structural”
Mg2+ ions. Since the residence time of these ions is much longer
than accessible simulation times, it is appropriate to describe these
ions as being permanently bound to the biomolecular complex. For
this representation, SMOG 2 can read a PDB ﬁle in which ions are
present and then include harmonic interactions between the ions
and molecular system. Consistent with the general approach to
deﬁning structure-based models, each harmonic potential will
have a minimum corresponding to the distance found in the
provided PDB structure. In the default all-atom model, this type
of interaction is deﬁned for atom and residue type BMG (“Bound
MG”). This treatment of ions is declared in the .nb and .bif
template ﬁles. First, the BMG residue is deﬁned in the .bif ﬁle
(Listing 9).
Listing 9
Deﬁning ions in the .bif ﬁle
In this deﬁnition, one should notice that there are several
additional attributes provided to the residue and atom elements.
Speciﬁcally, the connect¼no attribute instructs SMOG 2 to not
attempt to include bonds between ions that are listed sequentially
144
Mariana Levi et al.

in
the
input
PDB
ﬁle.
The
next
attribute
to
notice
is
atomCount¼0, which instructs SMOG 2 to not account for ions
when setting any energetic normalization conditions. Finally,
bonds¼0 indicates that the ion has no covalent bonds. If this
attribute is absent and a BMG atom appears in your PDB ﬁle,
SMOG 2 will exit with an error, since it expects every atom to
have at least one covalent bond. In addition to deﬁning the BMG
residue in the bif ﬁle, the template ﬁles indicate that harmonic
interactions should be included with BMG atoms (rather than the
typical 6–12 potential for contacts). This is declared in the nb ﬁle
(Listing 10).
Listing 10
Deﬁning the contact potential for bound BMG ions
Here, the function type is bond_type6, which is deﬁned as a
harmonic, non-chemical, potential (see Gromacs manual for
details). It should be noted that the user is at liberty to use any
pair-wise potential to describe ion–biomolecule interactions. In the
above discussion, we have used a harmonic representation as an
example.
Diffuse/Bulk Ions: In addition to structural ions, the precise local
concentration of freely diffusing ions can strongly inﬂuence the
kinetics of large-scale conformational processes. If one is aiming
to study the role of diffuse ions with structure-based models, then it
is necessary to add additional ions that are not present in the input
PDB structure. Within the SMOG framework, after generating a
force ﬁeld for the biomolecule using the executable smog2, addi-
tional ion deﬁnitions must be present in the top and gro ﬁles. The
tool smog_ions was written for the speciﬁc purpose of adding a
user-deﬁned number of ions to a structure-based model force ﬁeld.
In addition to providing the ion name and number of desired ions,
the user must also specify the charge, mass, and c12 parameter that
deﬁnes its excluded volume (an attractive c6 term is optional). Note
that each call of smog_ions can only add a single ion type. Thus, if
you would like to add multiple ion species (e.g., K+ and Cl), it
would be necessary to make repeated calls to smog_ions. After
running smog_ions, the user will have a top ﬁle describing the
composite biomolecule–ion system, as well as a new coordinate ﬁle
that will have randomly placed ions (e.g., Fig. 2).
Simulating Biomolecular Assemblies
145

4
Notes
1. Some common processing errors:
l
Missing atoms
– Structures with insufﬁcient resolution may be missing
atoms because the local electron density didn’t allow for
its determination. If these regions are in disordered
loops, a simple solution is simply to change these residues
names to ALA and remove any side chain atoms beyond
the CB. The reasoning would be that any native contacts
that may be excluded would likely have been an artifact of
the crystallization conditions. If the missing atoms are
not in loops, an appropriate strategy may be to use
homology modeling software to insert the missing
atoms, e.g., SWISS-MODEL [26].
l
Non-canonical residues, such as MSE
– X-ray crystallography is often aided by small perturba-
tions such as selenomethionine (MSE) instead of methi-
onine (MET). In the case of MSE, the solution is either
(a) to add MSE to the bif by duplicating MET and
changing S atom to SE, or (b) to edit the PDB by
renaming MSE to MET. If the bonded structure is not
exactly identical to one of the residues in the bif ﬁle,
another strategy would be to generate a homology
model to restore the native sequence. This model
would then be used as input to SMOG 2.
Fig. 2 K+ ions (pink beads) added to an RNA model using smog_ions
146
Mariana Levi et al.

l
Missing residues
– Often loop regions will be missing due to disorder in
crystal structures. One solution is to insert TER lines
between breaks in the protein sequence. However, one
issue with this approach is that it requires that the
simulated temperature be sufﬁciently low that the now
disconnected chains do not dissociate. Homology mod-
eling software can be used to insert the missing residues,
but this raises the question of whether to add native
contacts for the disordered region. To automatically
ignore contacts for these disordered regions via the
SMOG 2 templates: (a) duplicate all the residues in the
bif with names (e.g., ALA->ALAD), (b) change all the
pair types for atoms in these new residues to a new type
(e.g., P_1 -> P_D), (c) add a rule in the .nb for contacts
between
anything
(type
*)
and
P_D
with
func¼“contact_free()”.
2. When running protein folding simulations, take care to run the
simulation with a sufﬁciently large box. The xyz dimensions of
the box are denoted in the last line of the gro ﬁle. The protein
should never interact with itself through the periodic bound-
aries. Take note that Gromacs tabulated pair potentials (the
Lennard-Jones native contacts) are neglected for the remainder
of a simulation if the distance between a native pair exceeds the
length of the table. This length is initialized as the largest cutoff
distance, rvdw or rcoulomb. Since unfolded protein native
pairs are far apart, setting table-extension in the mdp to
half the box diagonal can ensure that no pairs are inadvertently
neglected.
3. Even though structure-based models are less computationally
demanding than explicit-solvent models, simulations of large
assemblies can require substantial resources. Fortunately, most
modern MD engines exhibit strong scaling, such that many
cores may be used for a single simulation. For a eukaryotic
ribosome (250,000 atoms), Gromacs v4.6.3 was shown to
scale to more than 1000 compute cores [13]. In a previous
study where only 1/6 of the ribosome was explicitly repre-
sented [27], a single trajectory required 128 cores for over
4 months. As a guide for expected performance, we have
obtained more than 50,000,000 time steps per day using
28 compute cores for a system of 28,000 atoms [22].
4. When using smog_extract, the TkConsole of VMD can be a
very helpful tool for generating the list of atoms to be included
in the truncated system. In the example below, one can select a
rectangular box of atoms and write the indices to the ﬁle
truncatedAtoms.ndx:
Simulating Biomolecular Assemblies
147

set
p0
[
atomselect
0
”(x>85)
and
(x<140)
and
(y>105)
and
(y<155) and (z>140) and (z<180)” ]
set
file [ open
”truncatedAtoms.ndx” w ]
puts
$file [ $p0 get serial ]
close $file
To fully adhere to ndx ﬁle format, the user simply needs to
add an atom group declaration (e.g., [ group1 ]) to the ﬁrst
line of the ndx ﬁle. Note that the above example uses the
keyword “serial” (starts at 1), rather than “index” (start at 0).
5. SMOG 2 topology ﬁles are written in reduced units. The
length unit is the same as Gromacs: nanometers. The mass of
each bead is 1. In the all-atom model this corresponds to a mass
unit of 12 amu. In the C-alpha model, each residue is a single
bead, which, given 8 heavy atoms per bead, corresponds to a
mass unit of 100 amu. In principle, the correct heteroge-
neous masses could be written to the topology, but this
would only have a small effect on the kinetics, and thermody-
namics is unaffected. A Gromacs mdp expects the temperature
to be provided in Kelvin, where a value of Boltzmann’s con-
stant kB of 0.00831451 kJ/mol/K is used internally. Thus, in a
Gromacs mdp ﬁle, a temperature of 120.3 K corresponds to a
reduced temperature of 1. When adding additional energetic
terms that have empirical units with the effective energetics in
structure-based models, it is often useful to express both
energy scales in terms of kBT.
6. Estimating time scales in simpliﬁed and/or coarse-grained
simulations can be a tricky business. In the structure-based
model, speed-up relative to all-atom explicit-solvent models
comes from three effects: (a) unfrustrated energetics, (b) low
viscosity, (c) coarse graining. In the ﬁeld of protein folding, the
ﬁrst two effects are known as internal and external friction,
respectively [28]. The external friction is formally absent
because of the lack of solvent, but is re-introduced to a small
degree through the use of Langevin dynamics protocols. The
lack of non-native interactions in the structure-based model
smooths the energy landscape and reduces the internal friction.
Coarse-graining smooths the internal friction as well, by both
simplifying and softening the interactions. Of course, coarse
graining also provides an obvious algorithmic speed-up by
requiring less. Taken together, for protein folding, the time
scale is estimated to be increased by a factor of 1000–10,000
[29]. Simple diffusion limited processes like molecular encoun-
ter in aggregation will be most dependent on the residual
viscosity controlled with the thermostat and, thus, care must
be taken when studying the kinetics of systems that involve
148
Mariana Levi et al.

multiple physical processes, e.g., coupled binding and folding
of a homodimer.
7. Since reduced units are used in SMOG models, it is important
to choose an appropriate simulated temperature. To determine
the proper value of the reduced temperature, one typically
compares atomic rmsf values between a SMOG model and
explicit-solvent simulations, or experimental B-factors. When
using the all-atom SMOG model, a reduced Gromacs temper-
ature of approximately 60–80 typically corresponds to a tem-
perature of around 300 K in explicit-solvent simulations
[24]. When studying biomolecular folding, an alternate strat-
egy for calibrating temperature is to describe the system in
terms of the folding temperature Tf. That is, by equating an
experimental observable Tf with a simulation Tf can give a
helpful point of reference. As a ﬁnal note, it is important to
recognize that linear extrapolation of temperature for any
molecular mechanics model is not likely to be reliable, since
the solvent introduces strong non-linear effects, e.g., cold
denaturation and boiling.
8. After calibrating the temperature in the model, additional
energetic terms can be included in the model and calibrated
by thermal energy matching. Two examples that have been
explored with SMOG models are pulling forces [30, 31] and
electrostatic forces [10]. A correspondence between an experi-
mental temperature Texp ¼ 300 K and simulation temperature
Tsim ¼ 0.9 allowed for thermal energy matching, where kBTexp
¼ 2.5 kJ/mol ¼ 4.2 pN  nm ¼ kBTsim ¼ 0.9E ¼ 0.9[F] 
nm. Thus, a reasonable initial estimate of the reduced force
unit [F] is 4.2/0.9 pN ¼ 4.7 pN. As a tip, for these types of
comparisons, the strength of the Coulomb force may be
adjusted by scaling the effective dielectric constant, which is
set by epsilon_r in the mdp ﬁle. Given the same temperature
calibration as above, one could rescale the dielectric constant by
a factor of 4.2/0.9 ¼ 4.7, where the dielectric for water
80 would be scaled to 80  4.7 ¼ 376 ! epsilon_r.
Acknowledgements
This work was supported in part by an NSF CAREER Award
(Grant MCB-1350312). JKN is a Humboldt Postdoctoral Fellow.
UM acknowledges support as a John Simon Guggenheim Memo-
rial Foundation fellowship. We acknowledge generous support
provided by Northeastern University Discovery Cluster.
Simulating Biomolecular Assemblies
149

References
1. Bryngelson JD, Wolynes PG (1989) Inter-
mediates and barrier crossing in a random
energy-model (with applications to protein
folding). J Phys Chem 93:6902–6915
2. Clementi C, Nymeyer H, Onuchic J (2000)
Topological and energetic factors: what deter-
mines the structural details of the transition
state ensemble and “en-route” intermediates
for protein folding? An investigation for small
globular proteins. J Mol Biol 298:937–953
3. Karanicolas J, Brooks CL (2003) Improved G-
o¯-like models demonstrate the robustness of
protein
folding
mechanisms
towards
non-native
interactions.
J
Mol
Biol
334:309–325
4. Clementi C, Garcia A, Onuchic J (2003) Inter-
play among tertiary contacts, secondary struc-
ture formation and side-chain packing in the
protein folding mechanism: all-atom represen-
tation
study
of
protein
L.
J
Mol
Biol
326:933–954
5. Whitford P, Noel J, Gosavi S, Schug A,
Sanbonmatsu
K,
Onuchic
J
(2009)
An
all-atom structure-based potential for proteins:
bridging minimal models with all-atom empir-
ical forceﬁelds. Proteins Struct Funct Bioinf
75:430–441
6. Oliveberg M, Wolynes PG (2005) The experi-
mental survey of protein-folding energy land-
scapes. Q Rev Biophys 38:245–288
7. Rao G, Hemanth VV, Gosavi S (2016) Using
the folding landscapes of proteins to under-
stand protein function. Curr Opin Struct Biol
36:67–74
8. Givaty O, Levy Y (2009) Protein sliding along
DNA: dynamics and structural characteriza-
tion. J Mol Biol 385:1087–1097
9. Vuzman D, Levy Y (2010) DNA search efﬁ-
ciency is modulated by charge composition and
distribution in the intrinsically disordered tail.
Proc Natl Acad Sci USA 107:21004
10. Noel JK, Whitford PC (2016) How EF-Tu can
contribute to efﬁcient proofreading of aa-tRNA
by the ribosome. Nat Commun 7:13314
11. Brooks B, Brooks C, Mackerell A, Nilsson L,
Petrella R, Roux B, Won Y, Archontis G,
Bartels C, Boresch S, Caﬂisch A, Caves L,
Cui Q, Dinner A, Feig M, Fischer S, Gao J,
Hodoscek M, Im W, Kuczera K, Lazaridis T,
Ma J, Ovchinnikov V, Paci E, Pastor R, Post C,
Pu J, Schaefer M, Tidor B, Venable R,
Woodcock H, Wu X, Yang W, York D, Karplus
M (2009) CHARMM: the biomolecular simu-
lation
program.
J
Comput
Chem
30:1545–1614
12. Wang J, Cieplak P, Kollman P (2000) How well
does a restrained electrostatic potential (RESP)
model perform in calculating conformational
energies of organic and biological molecules?.
J Comput Chem 21:1049–1074
13. Noel
JK,
Levi
M,
Raghunathan
M,
Lammert H, Hayes RL, Onuchic JN, Whitford
PC (2016) SMOG 2: a versatile software pack-
age for generating structure-based models.
PLoS Comput Biol 12:e1004794
14. Lindahl E, Hess B, van der Spoel D (2001)
Gromacs 3.0: a package for molecular simula-
tion and trajectory analysis. J Mol Model
7:306–317
15. Phillips JC, Braun R, Wang W, Gumbart J,
Tajkhorshid E, Villa E, Chipot C, Skeel RD,
Kale´ L, Schulten K (2005) Scalable molecular
dynamics with NAMD. J Comput Chem
26:1781–1802
16. Eastman P, Swails J, Chodera JD, McGibbon
RT, Zhao Y, Beauchamp KA, Wang L-P, Sim-
monett AC, Harrigan MP, Stern CD, Wiewiora
RP, Brooks BR, Pande VS (2017) Openmm 7:
rapid development of high performance algo-
rithms for molecular dynamics. PLoS Comput
Biol 13:1–17
17. Noel JK, Onuchic JN (2012) Computational
modeling
of
biological
systems.
Springer,
New York, pp 31–54
18. Whitford PC, Sanbonmatsu KY, Onuchic JN
(2012) Biomolecular dynamics: order-disorder
transitions and energy landscapes. Rep Prog
Phys 75:076601
19. McPhalen CA, James MNG (1987) Crystal and
molecular structure of the serine proteinase
inhibitor ci-2 from barley seeds. Biochemistry
26:261–269
20. Aqvist J, Lind C, Sund J, Wallin G (2012)
Bridging the gap between ribosome structure
and biochemistry by mechanistic computa-
tions. Curr Opin Struct Biol 22:815–823
21. Lind C, Oliveira A, Aqvist J (2017) Origin of
the omnipotence of eukaryotic release factor
1. Nat Commun 8:1425
22. Yang H, Noel JK, Whitford PC (2017) Aniso-
tropic ﬂuctuations in the ribosome determine
tRNA
kinetics.
J
Phys
Chem
B
121:10593–10601
23. Whitford PC, Geggier P, Altman RB, Blan-
chard SC, Onuchic JN, Sanbonmatsu KY
(2010) Accommodation of aminoacyl-tRNA
into the ribosome involves reversible excur-
sions
along
multiple
pathways.
RNA
16:1196–1204
150
Mariana Levi et al.

24. Jackson J, Nguyen K, Whitford PC (2015)
Exploring the balance between folding and
functional dynamics in proteins and RNA. Int
J Mol Sci 16:6868–6889
25. Savelyev A, Papoian GA (2009) Molecular
renormalization group coarse-graining of elec-
trolyte solutions: application to aqueous NaCl
and KCl. J Phys Chem B 113:7785–7793
26. Biasini M, Bienert S, Waterhouse A, Arnold K,
Studer
G,
Schmidt
T,
Kiefer
F,
Gallo
Cassarino T, Bertoni M, Bordoli L, Schwede
T (2014) SWISS-MODEL: modelling protein
tertiary and quaternary structure using evolu-
tionary information. Nucleic Acid Res 42:
W252–W258
27. Noel JK, Chahine J, Leite VBP, Whitford PC
(2014) Capturing transition paths and transi-
tion states for conformational rearrangements
in the ribosome. Biophys J 107:2872–2881
28. Soranno A, Holla A, Dingfelder F, Nettels D,
Makarov DE, Schuler B (2017) Integrated
view of internal friction in unfolded proteins
from single-molecule FRET, contact quench-
ing, theory, and simulations. Proc Natl Acad
Sci USA 114:E1833–E1839
29. Kouza M, Li M, O’Brien E, Hu C-K, Thiru-
malai D (2006) Effect of ﬁnite size on coop-
erativity and rates of protein folding. J Phys
Chem A 110:671–676
30. Sun L, Noel JK, Sulkowska JI, Levine H,
Onuchic JN (2014) Connecting thermal and
mechanical
protein (un)folding landscapes.
Biophys J 107:2941–2952
31. Sun L, Noel JK, Levine H, Onuchic JN (2017)
Molecular
simulations
suggest
a
force-
dependent mechanism of vinculin activation.
Biophys J 113:1697–1710
Simulating Biomolecular Assemblies
151

Part II
Enhanced Sampling and Free-Energy Calculations

Chapter 7
Replica-Exchange Methods for Biomolecular Simulations
Yuji Sugita, Motoshi Kamiya, Hiraku Oshima, and Suyong Re
Abstract
In this study, a replica-exchange method was developed to overcome conformational sampling difﬁculties in
computer simulations of spin glass or other systems with rugged free-energy landscapes. This method was
then applied to the protein-folding problem in combination with molecular dynamics (MD) simulation.
Owing to its simplicity and sampling efﬁciency, the replica-exchange method has been applied to many
other biological problems and has been continuously improved. The method has often been combined with
other sampling techniques, such as umbrella sampling, free-energy perturbation, metadynamics, and
Gaussian accelerated MD (GaMD). In this chapter, we ﬁrst summarize the original replica-exchange
molecular dynamics (REMD) method and discuss how new algorithms related to the original method are
implemented to add new features. Heterogeneous and ﬂexible structures of an N-glycan in a solution are
simulated as an example of applications by REMD, replica exchange with solute tempering, and GaMD.
The sampling efﬁciency of these methods on the N-glycan system and the convergence of the free-energy
changes are compared. REMD simulation protocols and trajectory analysis using the GENESIS software
are provided to facilitate the practical use of advanced simulation methods.
Key words Replica-exchange molecular dynamics method, Replica-exchange umbrella sampling,
Replica exchange with solute tempering, Detailed balance and global balance, Reweighting
approaches, Free-energy landscape, N-Glycans
1
Introduction
Proteins, nucleic acids, and other biomacromolecules have complex
free-energy landscapes with a large number of local minimum states
[1]. This nature results in heterogeneous and ﬂexible conforma-
tions of biomacromolecules in solution and cellular environments,
which are usually difﬁcult to be accessed by the standard molecular
dynamics (MD) and Monte Carlo (MC) simulations. So far, huge
amounts of efforts have been made by theoretical and computa-
tional scientists to enhance conformational sampling in computer
simulations and to obtain reliable free-energy landscapes of various
biological systems [2–5]. The replica-exchange method is one of
those methods and was originally developed in statistical physics or
solid-state physics [6, 7]. The method is also considered as one of
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_7, © Springer Science+Business Media, LLC, part of Springer Nature 2019
155

the generalized-ensemble algorithms [8]. The simulation methods
categorized as the generalized-ensemble algorithms have two key
features: one is a random walk of the trajectory in the potential
energy space or other essential coordinates to avoid trapping at one
of the local energy minima and another is the ability to compute
thermal averaged quantities at different conditions just from one
simulation run. Many global or local optimization algorithms do
not possess both features [9, 10].
In replica-exchange molecular dynamics (REMD) [11], copies
of the target molecular system, which we call replicas, are simulated
in parallel at different temperatures. The temperatures between a
pair of replicas are exchanged using the Metropolis criteria in MD
simulations, and random walks of replica trajectories in the temper-
ature space are realized. Each replica experiences both high and low
temperature conditions, searching large conformational changes at
high temperatures as well as stable conformations with low poten-
tial energies at low temperatures. REMD, thus, allows us to
enhance conformational samplings as well as to provide accurate
thermal averaged quantities or free-energy landscapes under vari-
ous conditions. The well-known drawback of the REMD, which is
often called temperature REMD (T-REMD), is that the number of
replicas increases rapidly as the target system size becomes large
[6]. REMD was therefore applied to relatively smaller peptide
systems in solution [12] or combined with implicit solvent/mem-
brane representations [5, 13].
Last 15 years, the replica-exchange method has progressed in
various ways. One of the important progresses is the multidimen-
sional version (multidimensional REM: MREM) [14], where not
only temperature but also other conditions or bias potentials are
exchanged between a pair of replicas. Replica-exchange umbrella
sampling (REUS) is one of the well-known examples in MREM and
is often called Hamiltonian REMD (H-REMD) [15], the bias-
exchange method [16], the window-exchange method [17, 18],
and so on. Another important progress is replica exchange with
solute tempering (REST) [19–22], where only temperatures of the
predeﬁned solute regions are exchanged between a pair of replicas.
In contrast, the solvent temperature is kept constant in all the
replicas. This method signiﬁcantly reduces the number of replicas
and allows us to extend the simulation system sizes for replica-
exchange methods. The other essential approach is the develop-
ment of combined methods with other enhanced sampling techni-
ques like umbrella sampling (REUS [14], REST/REUS [23]),
free-energy
perturbation
(FEP/REMD
[24],
FEP/REST
[25, 26]), Gaussian accelerated MD (GaMD/REMD) [27], meta-
dynamics (PT-MTD [28], bias-exchange MTD (BE-MTD) [29],
replica
state
exchange
metadynamics
method
(RSE-MTD)
[30, 31]), and so on. These progresses allow us to apply replica-
156
Yuji Sugita et al.

exchange methods to larger and more complicated biological sys-
tems using reasonable computational resources.
In this chapter, we ﬁrst summarize the basic theory of replica-
exchange methods. Not only T-REMD, but also MREM [14] is
discussed to extend REMD into the multidimensional version,
allowing exchange of various parameters between a pair of replicas.
REST [20–22] is generalized into gREST (generalized REST [19])
by introducing a more ﬂexible partition between the solute and
solvent regions. We also explain how to combine REMD (or REST)
with other enhanced sampling methods. To examine the confor-
mational sampling efﬁciency of various replica-exchange methods
and the convergence of free-energy changes, heterogeneous and
ﬂexible structures of an N-glycan with an explicit solvent [32, 33],
simulations are performed using the GENESIS software package
[34, 35]. GENESIS has been developed by us for simulating
cellular-scale biological systems [36] as well as for obtaining reliable
free-energy differences or landscapes via enhanced sampling meth-
ods like REMD [19, 30, 37]. Using the N-glycan simulations as
examples, we discuss the practical aspects of replica-exchange simu-
lations using the GENESIS software package.
2
Theory
2.1
Replica-
Exchange Molecular
Dynamics
In T-REMD, copies of the target molecular system (replicas) are
simulated in parallel with MD or MC simulations at different
temperatures [11]. Each simulation is carried out in an isothermal
(NVT) or isothermal–isobaric (NPT) ensemble. In the simulation,
the target temperatures are exchanged between a pair of replicas
when the Metropolis criteria is satisﬁed for the transition probabil-
ity, w(X ! X
0):
w X ! X 0
ð
Þ ¼
1,
for Δ  0
exp Δ
ð
Þ,
for Δ > 0

,
ð1Þ
where X and X
0 indicate the replica states before and after a replica
exchange (see Fig. 1a). Here, we assume an exchange between
replicas i and j, which are simulated at temperatures Tm and Tn,
respectively, before the exchange. Using the potential energy of the
target system, E(q), the Boltzmann constant, kB, and the
generalized positions and momenta, q and p, respectively, Δ in
Eq. 1 is written as
Δ 
1
kBT n

1
kBT m


E q i½ 


 E q j½ 




:
ð2Þ
REMD for BioSim
157

This transition probability of REMD (Eqs. 1 and 2) is exactly
the same as MC version of a replica-exchange method [6, 7], if
atomic momenta are rescaled using Tm and Tn after the exchange:
p i½ 0 
ﬃﬃﬃﬃﬃﬃﬃ
T n
T m
r
p i½ 
p j½ 0 
ﬃﬃﬃﬃﬃﬃﬃ
T m
T n
r
p j½ 
:
ð3Þ
If thermostat and barostat momenta are included in the equa-
tions of motion, these variables should be rescaled after replica
exchanges like Eq. 3 [38, 39].
In MREM [14], not only temperatures but also other para-
meters that specify the system conditions or structural parameters
Fig. 1 Schematic of (a) the replica-exchange molecular dynamics (REMD), (b) the replica-exchange with
solute tempering (REST), and (c) the generalized REST (gREST) simulations
158
Yuji Sugita et al.

used in the umbrella potentials are exchanged between a pair of
replicas. We assume the extended Hamiltonian of replica i at Tm,
where K(p[i]) and E0(q[i]) are the kinetic and potential energies of
replica
i,
respectively,
and
the
umbrella
potential,
Vm(q[i])  Em(q[i])  E0(q[i]), is applied:
H m q i½ ; p i½ 


¼ K
p i½ 


þ Em q i½ 


¼ K
p i½ 


þ E0 q i½ 


þ V m q i½ 


:
ð4Þ
We can consider replica exchanges in the two-dimensional
replica space spanning with temperatures and umbrella potentials.
Δ in Eq. 1 is modiﬁed to:
Δ ¼
1
kBT m
Em q j½ 


 Em q i½ 





1
kBT n
En q j½ 


 En q i½ 




:
ð5Þ
There are several possibilities of replica-exchange trials in the
two-dimensional space. One of the practical ways is to exchange
temperatures and umbrella potentials between a pair of replicas
separately in sequential manners [14]. Recently, different replica-
exchange schemes, such as the inﬁnite swapping [40, 41] or Suwa–-
Todo methods [42], have been proposed, relying on the global
balance conditions. Since these schemes allow us to exchange not
only two, but also more replicas simultaneously, the replica-
exchange rates can be improved [30, 31, 43]. There are several
proposals of multidimensional replica-exchange methods, which
include
PT-REMD
[44],
surface-tension
REMD
[37]
for
biological membrane systems, REUS method [14], which is often
referred to as H-REMD [15], the bias-exchange method [16], the
window-exchange method [17, 18], and so on. MREM is useful
particularly when the reaction coordinates that describe the free-
energy changes of target molecular systems are clear before the
simulation is conducted. A potential drawback of MREM is the
increase in the number of replicas to cover the multidimensional
space. For instance, M  N replicas in the two-dimensional REM
are required when M and N replicas are necessary for the ﬁrst and
second replica spaces, respectively.
2.2
Replica
Exchange with Solute
Tempering
REST was developed by Berne et al. [20] to reduce the number of
replicas required in T-REMD simulations. By introducing the mod-
iﬁed Hamiltonian of the target molecular system, solvent–solvent
interaction energy is excluded from the transition probability of
replica exchanges (Eqs. 1 and 2) [20]. In REST, a predeﬁned solute
region is simulated at a replica-dependent temperature Tm, whereas
the rest of the system, namely the solvent region, is simulated at
common temperature, T0, for all the replicas (Fig. 1b). In the most
REMD for BioSim
159

commonly used version, which is referred to as REST2 [21, 22],
the modiﬁed potential energy of replica i is written as:
EREST2, i½ 
m
¼ βm
β0
Euu q i½ 


þ
ﬃﬃﬃﬃﬃﬃ
βm
β0
s
Euv q i½ 


þ Evv q i½ 


,
ð6Þ
where Euu, Euv, and Evv are the solute–solute, solute–solvent, and
solvent–solvent interaction energies, respectively. β0 and βm are the
inverse temperatures of T0 and Tm, respectively. The modiﬁed
potential energy in REST2 results in Δ in Eq. 1 as follows:
Δ ¼ βn  βm
ð
Þ Euu q i½ 


 Euu q j½ 




þ
ﬃﬃﬃﬃﬃ
β0
p
ﬃﬃﬃﬃﬃ
βn
p

ﬃﬃﬃﬃﬃﬃ
βm
p


Euv q i½ 


 Euv q j½ 




:
ð7Þ
In Eq. 7, the solvent–solvent interaction energy disappears,
implying that the interaction energy space to be covered by all the
replicas is much restricted in REST.
Recently, we have introduced a more ﬂexible deﬁnition of
“solute” in the framework of REST2. In the new method, which
we call gREST [19], “solute” is deﬁned as a part of a solute
molecule or even selected potential energy terms, as shown in
Fig. 1c. For instance, only the dihedral-angle energy term of a
target solute molecule is deﬁned as the “solute” region in gREST.
We utilize similar expressions of the modiﬁed potential energy and
the transition probability compared to the REST2. In several
choices of the “solute” region, the modiﬁed potential energy
becomes a simpler form. If only the dihedral-angle energy term of
a solute molecule is selected as the “solute” region, the modiﬁed
Hamiltonian for replica i becomes
EgREST, i½ 
m
¼ βm
β0
Euu q i½ 


þ Evv q i½ 


:
ð8Þ
It is because there is no solute–solvent interaction in the mod-
iﬁed potential energy in this case. Note that if we select a whole
solute molecule as the solute region in gREST, the method is
identical to REST2 and that if all the molecules in the system are
selected as the solute region, the method is the same as T-REMD.
In this sense, gREST is considered as a generalization of the original
REST to utilize the additive property of the current force-ﬁeld
functions.
2.3
Combined with
Other Enhanced
Conformational
Sampling Methods
Due to the simplicity of the theory, replica-exchange methods can
be combined with other enhanced sampling methods for further
improvement of sampling efﬁciency in biological simulations.
In early studies, Sugita and Okamoto combined T-REMD with
multicanonical algorithm for reducing the number of replicas
(multicanonical replica-exchange method, MUCAREM) [45]. In
160
Yuji Sugita et al.

multicanonical algorithm, a ﬂat distribution in the potential energy
space is realized via the multicanonical weight factors [46, 47]. In
MUCAREM, replicas with the multicanonical weight factors at
different energy regions are prepared and the weight factors are
exchanged between a pair of replicas in simulations. A few ﬂat-
bottom distributions of replicas can cover the whole potential
energy space, reducing the total number of replicas compared to
T-REMD. This approach successfully applied to the folding simula-
tions of C-peptide [12], G-peptide [48], and villin headpiece sub-
domain in explicit solvent [49]. REMD and simulated tempering
were similarly combined into REST [50]. Kim et al. also developed
a generalized replica-exchange method particularly suited to ﬁrst-
order phase transitions [51].
MTD [52, 53], which constructs the bias potential in prede-
ﬁned collective variables (CV) iteratively, is also combined with
replica-exchange methods. In the PT-MTD [28], all the replicas
have the same collective variables and bias potentials. They are
simulated at different temperatures and temperature exchange is
conducted between a pair of replicas in PT-MTD. MTD is also
combined with the solute tempering (REST) to reduce the number
of necessary replicas [54]. In the BE-MTD [29], each replica has a
different CV space and a bias potential. The bias potentials are
exchange between a pair of replicas via the Metropolis–Hasting
algorithm. In other words, T-REMD and MTD are combined in
PT-MTD, whereas REUS and MTD are combined in BE-MTD.
We introduced the replica permutation algorithms, namely inﬁnite
swapping or the Suwa–Todo method, into BE-MTD and devel-
oped the RSE-MTD method [31]. The RSE-MTD method can
enhance transitions in a replica-state space and accelerate the con-
vergence of free-energy changes of alanine polypeptides in vacuum
and water [31] and an N-glycan in water [30].
REST is also combined with umbrella sampling (REST/
REUS) [23] or FEP/REST [25, 26]. Both REST/REUS and
FEP/REST signiﬁcantly reduce the number of replicas in the
two-dimensional replica-state space. These two methods are in
particular useful for the free-energy calculations in in silico drug
discovery. REST/REUS can be used to predict the most likely
ligand-binding pose at the predeﬁned binding pocket in a
protein [23]. In FEP/REST, a ligand molecule is treated as
“solute” in the framework of REST2. At the initial and ﬁnal
states of FEP calculations, solute is simulated at room temperature,
while the solute temperatures at the rest of replicas (intermediate
states) are higher than room temperature. This allows a wider
conformational sampling of ligand poses in the protein-binding
pocket and, therefore, reproduces the free-energy changes more
accurately.
REMD for BioSim
161

3
Materials
The conformational samplings of an N-glycan in solution have been
performed
by
using
REMD
simulation
modules
in
the
GENeralized-Ensemble SImulation System (GENESIS) software
package [34, 35, 55]. The trajectory analysis tools in GENESIS
have been used in the conformational analyses of the simulation
trajectories. UCSF Chimera [56], visual molecular dynamics
(VMD) [57], and Matplotlib [58] were used to prepare all ﬁgures.
Readers may refer to GENESIS website (https://www.r-ccs.riken.
jp/labs/cbrt/) to obtain GENESIS software as well as user manual
for practical usages. The website also provides tutorials for basic and
advanced uses of GENESIS.
4
Methods
In this section, we show the applications of REMD, REST, GaMD,
and standard MD to the conformational sampling of an N-glycan in
solution [30, 32, 33, 59]. N-glycans are essential for many
biological processes, but their structural ﬂexibility and complexity
make the experimental structure analysis very difﬁcult. MD simula-
tion of an N-glycan tends to trap at one of the local energy minima
due to high-energy barriers associated with the glycosidic linkages,
functional group rotations, and rearrangements of intra- and inter-
molecular hydrogen bond network. Enhanced sampling techniques
help overcome the difﬁculty and provide conformational ensembles
at atomic resolution, giving insight into the structure–function
relationship of N-glycans.
In the following, we ﬁrst introduce the GENESIS simulation
package in Subheading 4.1 and show examples of REMD and
related simulations in Subheadings 4.2–4.6. Finally, we compare
the sampling efﬁciency of REMD with those of the other methods
in Subheading 4.7.
4.1
GENESIS
Simulation Package
GENESIS is an open-sourced (GNU General Public License ver-
sion 2) software package for MD simulation and modeling of
biomolecular systems [34, 35, 55]. GENESIS has been primarily
designed for massively paralleled supercomputers, but runs on
typical Linux workstations and cluster machines as well. It also
supports PC-clusters with multiple general-purpose computing
on graphics processing units (GPGPUs) [55]. GENESIS contains
two MD simulators having different parallelization schemes,
ATDYN (atomic decomposition algorithm) and SPDYN (domain
decomposition algorithm). Speciﬁcally, SPDYN is highly scalable in
K computer or other supercomputers for the systems with hundred
million atoms or more. The other advantage of GNESIS is
162
Yuji Sugita et al.

availability of enhanced sampling simulations with multiple replicas,
including
various
REMD
simulations
and
string
methods
[60, 61]. Currently, GENESIS supports potential energy functions
used in AMBER, CHARMM, and GROMACS packages. The ver-
sion 1.2.1 has been released at the beginning of 2018.
4.2
System
Preparation
We focus on a biantennary complex-type N-glycan (referred to as
Bi9 hereafter). The structure of Bi9 is shown in Fig. 2. Bi9 contains
a branched trimannosyl core structure that is shared by all types of
N-glycans, serving a good model for general N-glycan structures.
The conformational ﬂexibility of Bi9 relies on the α1,6-linkage
connecting the trimannosyl core and α1,6-arm. The linkage is
characterized by three dihedral angles φ, ψ, and ω. The nuclear
magnetic resonance (NMR) experiments suggest that this linkage
mainly has gauche-gauche (gg, ω ¼ 60) and gauche-trans (gt,
ω ¼ 60) conformations in solution (Fig. 3). To check the initial
conﬁguration dependence, we built two models corresponding to
gg and gt conformations: 10,527 atoms (3447 H2Os) with a box
size of 51.7 A˚  49.3 A˚  55.0 A˚ for gg and 10,698 atoms (3504
H2Os) with a box size of 53.0 A˚  49.1 A˚  55.0 A˚ for gt.
Hereafter, the simulations from gg and gt conformers are referred
to as s(gg) and s(gt), respectively. One can easily build initial models
by using either GLYCAM-Web Carbohydrate Builder (http://
glycam.org) [62] or CHARMM-GUI (http://www.charmm-gui.
org) [63, 64] depending on the force ﬁeld in use. Here, we use
CHARMM36 additive force ﬁeld for carbohydrates [65–67] and
the TIP3P model [68] for water. Long-range electrostatic interac-
tions were evaluated using the particle-mesh Ewald summation
method, while Lennard-Jones (van der Waals (vdW)) interactions
were truncated at a cutoff distance of 10 A˚ with an atom-based
switching function effective at 8.0 A˚ . The pairlist for nonbonded
interactions was truncated at 11.5 A˚ . Each system was equilibrated
for 2 ns ﬁrst in NPT (300 K, 1 atom) followed by NVT (300 K)
Fig. 2 Structure of a biantennary complex-type N-glycan
REMD for BioSim
163

ensembles. The ﬁnal structure was used for subsequent REMD,
REST, and GaMD simulations.
4.3
T-REMD
The difﬁculty in conformational sampling of N-glycans mainly
arises from high-energy barriers separating rotamer states, such as
the gg and gt conformers of Bi9. Both the rotational motions along
the glycosidic linkages and the reorganization of intra- and inter-
molecular hydrogen bond network contribute to the high-energy
barriers. Figure 3 shows a time series of angle ω in our conventional
MD simulation of Bi9 at 300 K. This simulation starts with gg
conformation and transitions from gg to tg and tg to gt occur
around 600–700 ns. To get statistics, we performed three 1 μs
simulations each for s(gg) and s(gt). The average number of transi-
tions observed in 100 ns MD are 0.17 and 0.23 for s(gg) and s(gt),
respectively (Table 1).
Fig. 3 Transition of the angle ω in a conventional MD simulation for 1 μs. The deﬁnition of gauche-gauche (gg),
gauche-trans (gt), and trans-gauche (tg) conformations as well as the corresponding snapshots are also
shown
164
Yuji Sugita et al.

T-REMD simulation facilitates the transition between gg and gt
conformers by exchanging temperatures between a pair of replicas.
The performance of REMD depends on the choices of the tem-
peratures, number of replicas, and exchange periods. At ﬁrst, an
appropriate temperature range should be determined. We per-
formed a series of short MD simulations at different temperatures
and took the temperature at which the radius of gyration converges
as the highest temperature. Next, the number of replicas and tem-
peratures should be determined. This could be done such that a
desired exchange probability is obtained [69]. There is an online
tool to do this (temperature generator for REMD simulation
(http://folding.bmc.uu.se/remd/)). For our system, the tempera-
ture range of 300–500 K and the exchange probability of 0.3 give
64 replicas and their temperatures. Replica exchanges were
attempted every 2 ps on the Metropolis–Hasting algorithm with
alternating
even/odd
pairs
of
replicas.
We
performed
two
T-REMD simulations, s(gg) and s(gt), for 150 ns per replica.
First, we check the performance of replica exchanges. The
acceptance ratio tells us whether the desired exchanges occurred
or not. One could also plot time series of either the replica
exchanges at selected temperatures or the temperature exchanges
of selected replicas to check if random walks are realized. For Bi9,
we found the average acceptance ratios of ~50% and found random
walks in both replica and temperature spaces [30], suggesting that
the desired conformational sampling is achieved (see Note 1).
Then, we examine the transitions between gg and gt confor-
mers. In Fig. 4, the time series of the angle ω in arbitrary chosen
two replicas are shown for s(gg) and s(gt) simulations (see Note 2).
In both cases, the conformational transitions occur few times
within 100 ns. The average number of transitions are 6.92 and
6.31 for s(gg) and s(gt), which are more than 30 times larger than
those observed in the conventional MD simulations (Table 1).
Note that the conformations of the other linkages may not be
troublesome in sampling, as the α1,3-linkage largely ﬂuctuates
around the single minimum (χ ¼ 60) (Fig. 4).
The highest temperature and number of replicas employed here
might be sufﬁcient for crossing moderate-energy barriers, such as
Table 1
Average number of transitions in 100 ns trajectories obtained from different methods (REMD, REST,
GaMD, and conventional MD)
REMD
REST
gREST-dihed
GaMD
MD
s(gg)
6.92 (2.73)
5.66 (2.57)
3.75 (1.62)
2.60 (1.85)
0.17 (0.37)
s(gt)
6.31 (2.80)
5.19 (2.43)
3.59 (2.34)
2.13 (1.65)
0.23 (0.50)
The standard deviations are shown in parenthesis
REMD for BioSim
165

those associated with hydrogen bond rearrangements. However,
they might not be enough to overcome the high-energy barrier
along the ω angle. One could raise the highest temperature to
further enhance the sampling. However, the number of replicas
rapidly increases, and such high temperature might also cause
unwanted instability of biomolecules.
4.4
REST and gREST
We examine the performance of REST and gREST for Bi9 system.
We deﬁned the solute in two ways (see Notes 3 and 4). In the
ﬁrst case, all energy terms in Bi9 were deﬁned as the solute. The
number of solute atoms is 216 and that of each energy term is
120 (bond), 414 (angle), 168 (Urey Bradley), 898 (dihedrals), and
8 (improper), respectively. In addition to this, nonbonded interac-
tions between solute (Bi9) and solvent (water molecules) are also
scaled (Fig. 1b). Eight replicas were used to cover the temperature
range of 300–531 K. In the second case, only the dihedral energy
term in Bi9 is taken as the solute (the number of energy term is
Fig. 4 Transition of the angle ω and χ in two arbitrary chosen replicas (blue and red) from REMD simulations
for 100 ns
166
Yuji Sugita et al.

898 for dihedrals). Four replicas were used with the temperature
range of 300–915 K. The ﬁrst and second cases are referred to as
“REST” and “gREST-dihed” hereafter. For each of the two mod-
els, s(gg) and s(gt), we performed both REST (400 ns  8 replicas,
3.2 μs) and gREST-dihed (800 ns  4 replicas, 3.2 μs) simulations
(see Note 5).
Similar to the REMD simulations, we examine the transitions
between gg and gt conformers. Both REST and gREST-dihed
simulations show multiple gg/gt transitions within 100 ns. The
average number of transitions for REST is 5.66 and 5.19 for s(gg)
and s(gt), respectively, which are close to the REMD values. Less
numbers of transitions, 3.75 for s(gg) and 3.59 for s(gt), are
observed in the gREST-dihed simulations. The gg/gt transitions
may accompany with complex distortions of local structures.
4.5
For Further
Efﬁcient Sampling
GaMD [70] accelerates the conformational sampling of biomole-
cules by adding a non-negative boost potential to the system
potential energy. To examine the performance of GaMD, we
applied a dual boost GaMD to Bi9. The upper limits of standard
deviations of the boost potentials are set to 6 kcal/mol (see Note
6). The initial guesses of the parameters for boosting potentials
were calculated from 4 ns NVT simulation without boosting. The
boost potentials were updated every 100 ps in a subsequent 6 ns
NVT simulation to converge the GaMD parameters. Finally, three
1 μs productions of GaMD NVT simulation were performed. The
PyReweighting toolkit [71] was used to reweight the probability
distribution obtained by GaMD simulations to calculate the free-
energy landscape of Bi9. The cumulant expansion to the second
order was used in the reweighting (see Note 7).
We again examine the transitions between gg and gt confor-
mers. GaMD simulations show multiple gg/gt transitions within
100 ns as observed in gREST-dihed. The average numbers of
transitions for GaMD are 2.60 and 2.13 for s(gg) and s(gt), respec-
tively, which are approximately ten times larger than those of
conventional MD (Table 1). GaMD could enhance the sampling
to a similar extent to gREST-dihed that uses four replicas.
4.6
Conformational
Analysis Using
GENESIS
Free-energy landscapes and structural details could be analyzed by
using analysis tools in the GENESIS software package. For replica-
exchange trajectories, one needs to sort the trajectories by parame-
ter indexes before the analysis. In GENESIS, an analysis tool named
remd_converter sorts the trajectories which were originally prepared
for replica indexes (see Note 8). The analysis tool also provides
commonly used analysis tools for drawing free-energy landscape
(see Note 9), the weighted histogram analysis method (WHAM)
[72, 73] and multistate Bennett acceptance ratio (MBAR)
[74]. Readers may refer to the GENESIS website for details.
In Fig. 5, we show the free-energy maps of Bi9 system using a
spherical coordinate for REMD simulations. In short, the angle η
REMD for BioSim
167

Fig. 5 Free-energy maps of global conformations of Bi9 using a spherical coordinate drawn by using different
lengths of REMD trajectories (10, 25, 50, and 100 ns)
168
Yuji Sugita et al.

and θ represent swing motion of the α1,6 arm around z (polar) axis
and up down motion with respect to the xy-plane, respectively. The
positive and negative θ values correspond to the gg and gt confor-
mations, respectively. Two free-energy maps from s(gg) and s(gt)
are signiﬁcantly different in the ﬁrst 10 ns. The map of s(gg) shows a
large minimum in θ > 0, while that of s(gt) shows a minimum in
θ < 0. As the simulation time increases, the minima grow in θ < 0
and θ > 0 for s(gg) and s(gt), respectively. Two maps nearly
coincide with each other for 100 ns, indicating that the simulations
are converged.
Taking a close look at the converged free-energy maps, we ﬁnd
that there are multiple stable conformers in both gg (θ < 0) and gt
(θ > 0) regions. A clustering analysis of the trajectories leads to
precise characterization of Bi9 conformers in solution: two gg con-
formers (extended and α1,6 backfolded forms) and two gt confor-
mers (extended and α1,6 tightly backfolded forms), respectively
[30, 32].
4.7
Overall Look on
Performances
Finally, we summarize the performance of different methods.
Figure 6a shows the gg/gt populations obtained from two
REMD simulations, s(gg) and s(gt), with different simulation
lengths. REMD simulations nearly converge for 150 ns, giving
the gg/gt ratios of 57:43 for s(gg) and 50:50 for s(gt). In Fig. 6b,
the gg/gt populations from different methods (3 μs of sampling for
each method) are shown for comparison. The difference between
gg/gt ratios from s(gg) and s(gt) is very large for conventional MD
simulations. The difference becomes smaller for gREST-dihed and
negligible for REST. The latter shows similar convergence behavior
to REMD, giving the gg/gt ratios 55:44 and 57:43 from s(gg) and s
(gt), respectively.
The difference is also negligible for GaMD (gg/gt ratio of
43:57 for both s(gg) and s(gt)). The reweighted free-energy maps
along η and θ axes are almost the same as those of REMD as shown
in Fig. 5. These results imply that GaMD simulations successfully
converge to the equilibrium value without using many replicas. We
notice however that the gg/gt ratio from each single run of 1 μs
GaMD largely deviates from the average (Fig. 6c). This implies that
the methods with single run, like GaMD, require multiple simula-
tions and their averaging for convergence.
5
Notes
1. The acceptance ratio of the exchange between two replicas,
i and j, drops exponentially with increasing the difference
between two temperatures (βi  βj). Thus, the exchange is
commonly attempted between neighboring replicas to keep
the temperature gap small enough (typically a few Kelvin). It
REMD for BioSim
169

Fig. 6 (a) Relative population of gg and gt conformations obtained from REMD simulations with different
lengths (10, 25, 50, 100, and 150 ns). The populations are shown for two simulations with different initial
conﬁgurations: s(gg) and s(gt). (b) Relative gg/gt populations obtained using the other methods: REST
(400 ns  8 replicas, 3.2 μs), gREST-dihed (800 ns  4 replicas, 3.2 μs), GaMD (1 μs  3 runs, 3.0 μs),
and conventional MD (1 μs  3 runs, 3.0 μs). (c) Relative gg/gt populations obtained from three sets of GaMD
(Traj. 1, 2, and 3) and their averages
170
Yuji Sugita et al.

is important to check the acceptance ratio for each pair of
replicas. Ideally, all the acceptance ratios are uniform. Nonuni-
form values indicate that a free random walk is not realized in
replica and temperature spaces.
2. The trajectory ﬁles (DCD ﬁles) of temperature REMD simula-
tion are prepared for each replica index. Therefore, the temper-
ature in a trajectory of each replica changes in time. One might
look at a trajectory of each replica to see continuous changes in
structure as in Fig. 4, but should bear in mind that the trajec-
tory is not physical.
3. In REST and gREST, there is always one replica that is
simulated with unscaled potential at the temperature of inter-
est. Other replicas are affected by scaling of energy functions
for solute–solute and solute–solvent interactions. The choice of
solute greatly affects the sampling efﬁciency of REST. How-
ever, to ﬁnd a good solute region is not trivial, and may need
trials and errors.
4. The efﬁciency of replica exchange largely depends on the
choice of parameters. Contrary to T-REMD, there is no gen-
eral way to determine the parameters for REST or REUS.
GENESIS provides an automatic parameter tuning algorithm
that adjusts the parameters to achieve a target exchange proba-
bility (Ptgt). The algorithm calculates the deviation of the
exchange probability between replicas i and j from the target
value
ΔPi,j ¼ Pi,j  Ptgt  sgn Pi,j  Ptgt

	
 min Pi,j  Ptgt




; Pmgn

	
,
where sgn is the sign function and Pmgn is the margin for the
target exchange probability, Ptgt. The parameters, Xi and Xj,
will be updated according to the following equation:
ΔX i,j ¼ ΔPi,j  100  vg,
where ΔXi, j is the displacement for updating parameters (Xi
and Xj) and vg is the grid size in parameter space. By repeating
the update, we will get the exchange probabilities that are close
to the target value.
5. In using automatic parameter tuning in REST, the highest
temperature may become too high such as over 1000 K. Such
too high solute temperature might make a target biomolecule
unstable and generate undesired conﬁgurations. In the case of
Bi9, if high temperatures over 1000 K are included in REST
simulations, tg conformation frequently appears in trajectories
and its relative population to gg/gt becomes non-negligible,
which is inconsistent with the results of REMD and GaMD.
When too high solute temperatures are obtained by automatic
REMD for BioSim
171

tuning, one may consider reducing the number of replicas to
exclude such high-temperature replicas.
6. For optimal acceleration in GaMD simulations, one should
determine σ0 through short simulations. When σ0 is increased
in trial simulations, k0 and σΔV are also increased. If either k0
reaches 1.0 or σΔV reaches 10kBT (¼ 6 kcal/mol), the
corresponding value of σ0 is used for production runs. The
value of 10kBT is the upper limit of the ΔV distribution width
for accurate reweighting. The default value of σ0 is 10kBT in the
GaMD implementation in GENESIS.
7. In calculation of the free-energy landscape using GaMD, the
exponential average appears: ln exp βΔV
½

h
i0
ξ. The exponential
average is well known to cause large statistical noise because the
Boltzmann factor is often dominated by a few frames with high
boost potential. To reduce the energetic noise arising from the
averaging, Maclaurin series expansion or the cumulant expan-
sion was used to approximate the exponential averaging in
accelerated MD studies. When the distribution of the boost
potential in the bin can be approximated by a Gaussian distri-
bution, the cumulant expansion to the second order provides a
good approximation for the free-energy calculation. Note that
sufﬁcient number of samples in each bin is required for accurate
reweighting. If the sample number in a bin is small, the distri-
bution of the boost potential in the bin would deviate from the
Gaussian distribution, which causes the large statistical error. If
you have a small number of samples, you should make bin’s
width larger.
8. GENESIS provides tools for basis analyses. For REMD or
REST simulations, we ﬁrst sort the trajectory ﬁles along the
parameter index by using the tool named remd_converter. The
trajectory ﬁles that are prepared for replica indexes are sorted
based on the information written in remﬁles generated from the
simulation. The sorted trajectories are then used to calculate
several properties at the temperature of interest by using the
tools named as rmsd_analysis (RMSD and RMSF) as well as
trj_analysis (distance, angle, torsion, etc.).
9. Free-energy map and the gg/gt ratio are calculated from tra-
jectories at 300 K. However, sampling at 300 K alone may
become insufﬁcient when a system of interest becomes more
complex or the dimension of free-energy surface becomes
higher. The conformational spaces sampled at higher tempera-
tures could also be taken into account using MBAR to improve
the quality of free-energy map. For example, in REST, the
relative free energies of replicas are calculated by solving the
following equation iteratively:
172
Yuji Sugita et al.

^f i ¼  1
β0
ln
X
N rep
j¼1
X
N step
ns¼1
exp β0EREST
i
X j½ 
ns

	


N step
PN rep
k¼1 exp β0 ^f k  EREST
k
X j½ 
ns

	


h
i ,
where i, j, and k are the solute temperature indexes. β0 ¼ 1/
(kBT0) is the inverse of the simulation temperature T0, ^f i is the
free energy for i-th solute temperature, EREST
i
is the modiﬁed
potential energy used in REST, Nrep is the number of replicas,
Nstep is the number of snapshots in a trajectory, and X j½ 
ns is the
ns-th coordinate of j-th solute temperature index.EREST
i
X j½ 
ns

	
is
evaluated using the trajectories after the simulation. The
weight factors for the unperturbed state (i.e., at 300 K), W0,
are calculated using ^f k as
W 0 X j½ 
ns


¼ 1
c
exp β0E0 X j½ 
ns

	


N step
PN rep
k¼1 exp β0 ^f k  EREST
k
X j½ 
ns

	


h
i ,
where c is the normalization constant, and E0 is the potential
energy in the unperturbed state. Histogram counts of a physi-
cal quantity, A, at a certain value Aa in the unperturbed state,
~H 0 Aa
ð
Þ, is obtained using the following equation:
~H 0 Aa
ð
Þ ¼
X
N rep
j¼1
X
N step
ns¼1
W 0 X j½ 
ns


Q Aa; X j½ 
ns


Q Aa; X
ð
Þ ¼
1,
A X
ð Þ  Aa
j
j < ΔA=2
0,
otherwise

:
Q equals one only if the snapshot, X, has a value of A between
Aa  ΔA/2 and Aa + ΔA/2. ΔA is a bin width. The free-
energy map at 300 K can be calculated from this histogram
using REST simulation trajectories at all solute temperatures.
Acknowledgements
Y.S. thanks especially Yuko Okamoto for the collaboration and
guidance to develop T-REMD, MREM, REUS, and MUCAREM
at the Institute for Molecular Science. We are grateful to the young
scientists who have worked with us in RIKEN for the development
of replica-exchange methods and the applications (Naoyuki Miya-
shita, Takaharu Mori, Raimondas Galvelis, Daisuke Matsuoka, Ai
Niitsu, George Pantelopulos). Computer resources were provided
by HOKUSAI GreatWave in RIKEN Advanced Center for Com-
puting and Communication and K computer in RIKEN Center for
Computational Science through the HPCI System Research proj-
ect (Project IDs ra000009, hp140169, hp150108, hp150270,
hp160207, hp170254, and hp170115). This research has been
REMD for BioSim
173

funded by strategic programs for innovation research: “Computa-
tional life science and application in drug discovery and medical
development,” “Novel measurement techniques for visualizing live
protein molecules at work” (Grant No. 26119006), JST CREST on
“Structural Life Science and Advanced Core Technologies for
Innovative Life Science Research” (Grant No. JPMJCR13M3),
RIKEN pioneering research projects on “Dynamics Structural Biol-
ogy” and “Integrated Lipidology” (to Y.S.), and MEXT/JSPS
KAKENHI Grant Numbers 25330358 and 16K00415 (to S.R.).
References
1. Karplus M, McCammon JA (1983) Dynamics
of proteins: elements and function. Annu Rev
Biochem 52:263–300
2. Abrams C, Bussi G (2014) Enhanced sampling
in molecular dynamics using metadynamics,
replica-exchange,
and
temperature-
acceleration. Entropy 16:163–199
3. Bernardi RC, Melo MCR, Schulten K (2015)
Enhanced sampling techniques in molecular
dynamics simulations of biological systems.
Biochim Biophys Acta 1850:872–877
4. Miao Y, McCammon JA (2016) Uncon-
strained enhanced sampling for free energy cal-
culations of biomolecules: a review. Mol Simul
42:1046–1055
5. Mori T, Miyashita N, Im W, Feig M, Sugita Y
(2016) Molecular dynamics simulations of
biological membranes and membrane proteins
using enhanced conformational sampling algo-
rithms.
Biochim
Biophys
Acta
1858:1635–1651
6. Hukushima K, Nemoto K (1996) Exchange
Monte Carlo method and application to spin
glass
simulations.
J
Phys
Soc
Jpn
65:1604–1608
7. Swendsen RH, Wang JS (1986) Replica Monte
Carlo simulation of spin glasses. Phys Rev Lett
57:2607–2609
8. Okamoto
Y
(2004)
Generalized-ensemble
algorithms: enhanced sampling techniques for
Monte Carlo and molecular dynamics simula-
tions. J Mol Graph Model 22:425–439
9. Lee J, Scheraga HA, Rackovsky S (1997) New
optimization
method
for
conformational
energy calculations on polypeptides: conforma-
tional
space
annealing.
J
Comput
Chem
18:1222–1232
10. Okamoto Y, Fukugita M, Nakazawa T, Kawai
H (1991) Alpha-helix folding by Monte Carlo
simulated annealing in isolated C-peptide of
ribonuclease A. Protein Eng 4:639–647
11. Sugita Y, Okamoto Y (1999) Replica-exchange
molecular dynamics method for protein fold-
ing. Chem Phys Lett 314:141–151
12. Sugita Y, Okamoto Y (2005) Molecular mech-
anism for stabilizing a short helical peptide
studied by generalized-ensemble simulations
with explicit solvent. Biophys J 88:3180–3190
13. Im W, Feig M, Brooks CL III (2003) An
implicit membrane generalized born theory
for the study of structure, stability, and inter-
actions of membrane proteins. Biophys J
85:2900–2918
14. Sugita Y, Kitao A, Okamoto Y (2000) Multidi-
mensional replica-exchange method for free-
energy
calculations.
J
Chem
Phys
113:6042–6051
15. Fukunishi H, Watanabe O, Takada S (2002)
On the Hamiltonian replica exchange method
for efﬁcient sampling of biomolecular systems:
application to protein structure prediction. J
Chem Phys 116:9058–9067
16. Moradi M, Tajkhorshid E (2013) Mechanistic
picture for conformational transition of a mem-
brane transporter at atomic resolution. Proc
Natl Acad Sci U S A 110:18916–18921
17. Park S, Im W (2013) Two dimensional window
exchange umbrella sampling for transmem-
brane helix assembly. J Chem Theory Comput
9:13–17
18. Park S, Kim T, Im W (2012) Transmembrane
helix assembly by window exchange umbrella
sampling. Phys Rev Lett 108:108102
19. Kamiya M, Sugita Y (2018) Flexible selection
of the solute region in replica exchange with
solute
tempering:
application
to
protein-
folding
simulations.
J
Chem
Phys
149
(7):072304
20. Liu P, Kim B, Friesner RA, Berne BJ (2005)
Replica exchange with solute tempering: a
method for sampling biological systems in
explicit water. Proc Natl Acad Sci U S A
102:13749–13754
174
Yuji Sugita et al.

21. Terakawa T, Kameda T, Takada S (2011) On
easy implementation of a variant of the replica
exchange with solute tempering in GRO-
MACS. J Comput Chem 32:1228–1234
22. Wang L, Friesner RA, Berne BJ (2011) Replica
exchange with solute scaling: a more efﬁcient
version of replica exchange with solute temper-
ing (REST2). J Phys Chem B 115:9431–9438
23. Kokubo H, Tanaka T, Okamoto Y (2013)
Two-dimensional
replica-exchange
method
for predicting protein-ligand binding struc-
tures. J Comput Chem 34:2601–2614
24. Jiang W, Roux B (2010) Free energy perturba-
tion Hamiltonian replica-exchange molecular
dynamics (FEP/H-REMD) for absolute ligand
binding free energy calculations. J Chem The-
ory Comput 6:2559–2565
25. Wang L, Berne BJ, Friesner RA (2012) On
achieving high accuracy and reliability in the
calculation of relative protein-ligand binding
afﬁnities.
Proc
Natl
Acad
Sci
U
S
A
109:1937–1942
26. Wang L, Deng Y, Knight JL, Wu Y, Kim B,
Sherman W et al (2013) Modeling local struc-
tural rearrangements using FEP/REST: appli-
cation to relative binding afﬁnity predictions of
CDK2 inhibitors. J Chem Theory Comput
9:1282–1293
27. Huang YM, McCammon JA, Miao Y (2018)
Replica exchange Gaussian accelerated molec-
ular dynamics: improved enhanced sampling
and free energy calculation. J Chem Theory
Comput 14:1853–1864
28. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for beta hairpin
folding from combined parallel tempering and
metadynamics.
J
Am
Chem
Soc
128:13435–13441
29. Piana S, Laio A (2007) A bias-exchange
approach to protein folding. J Phys Chem B
111:4553–4559
30. Galvelis R, Re S, Sugita Y (2017) Enhanced
conformational sampling of N-glycans in solu-
tion with replica state exchange metadynamics.
J Chem Theory Comput 13:1934–1942
31. Galvelis R, Sugita Y (2015) Replica state
exchange metadynamics for improving the
convergence of free energy estimates. J Com-
put Chem 36:1446–1455
32. Nishima
W,
Miyashita
N,
Yamaguchi
Y,
Sugita Y, Re S (2012) Effect of bisecting
GlcNAc and core fucosylation on conforma-
tional properties of biantennary complex-type
N-glycans
in
solution.
J
Phys
Chem
B
116:8504–8512
33. Re S, Miyashita N, Yamaguchi Y, Sugita Y
(2011) Structural diversity and changes in
conformational
equilibria
of
biantennary
complex-type N-glycans in water revealed by
replica-exchange molecular dynamics simula-
tion. Biophys J 101:L44–L46
34. Jung J, Mori T, Kobayashi C, Matsunaga Y,
Yoda T, Feig M et al (2015) GENESIS: a
hybrid-parallel
and
multi-scale
molecular
dynamics simulator with enhanced sampling
algorithms for biomolecular and cellular simu-
lations. Wiley Interdiscip Rev Comput Mol Sci
5:310–323
35. Kobayashi C, Jung J, Matsunaga Y, Mori T,
Ando T, Tamura K et al (2017) GENESIS
1.1: a hybrid-parallel molecular dynamics sim-
ulator with enhanced sampling algorithms on
multiple computational platforms. J Comput
Chem 38:2193–2206
36. Yu I, Mori T, Ando T, Harada R, Jung J, Sugita
Y et al (2016) Biomolecular interactions mod-
ulate macromolecular structure and dynamics
in atomistic model of a bacterial cytoplasm.
elife 5:e19274
37. Mori T, Jung J, Sugita Y (2013) Surface-
tension replica-exchange molecular dynamics
method for enhanced sampling of biological
membrane systems. J Chem Theory Comput
9:5629–5640
38. Mori Y, Okamoto Y (2010) Generalized-
ensemble
algorithms
for
the
isobaric-
isothermal
ensemble.
J
Phys
Soc
Jpn
79:074003
39. Mori Y, Okamoto Y (2010) Replica-exchange
molecular dynamics simulations for various
constant temperature algorithms. J Phys Soc
Jpn 79:074001
40. Chodera
JD,
Shirts
MR
(2011)
Replica
exchange and expanded ensemble simulations
as Gibbs sampling: simple improvements for
enhanced mixing. J Chem Phys 135:194110
41. Plattner N, Doll JD, Dupuis P, Wang H, Liu Y,
Gubernatis JE (2011) An inﬁnite swapping
approach to the rare-event sampling problem.
J Chem Phys 135:134111
42. Suwa H, Todo S (2010) Markov chain Monte
Carlo method without detailed balance. Phys
Rev Lett 105:120603
43. Itoh
SG,
Okumura
H
(2013)
Replica-
permutation method with the Suwa-Todo
algorithm
beyond
the
replica-exchange
method. J Chem Theory Comput 9:570–581
44. Paschek D, Garcia AE (2004) Reversible tem-
perature and pressure denaturation of a protein
fragment: a replica exchange molecular dynam-
ics simulation study. Phys Rev Lett 93:238105
45. Sugita Y, Okamoto Y (2000) Replica-exchange
multicanonical algorithm and multicanonical
replica-exchange
method
for
simulating
REMD for BioSim
175

systems with rough energy landscape. Chem
Phys Lett 329:261–270
46. Berg BA, Neuhaus T (1992) Multicanonical
ensemble: a new approach to simulate ﬁrst-
order phase transitions. Phys Rev Lett 68:9–12
47. Hansmann UHE, Okamoto Y (1993) Predic-
tion of peptide conformation by multicanoni-
cal algorithm - new approach to the multiple-
minima
problem.
J
Comput
Chem
14:1333–1338
48. Yoda T, Sugita Y, Okamoto Y (2007) Cooper-
ative folding mechanism of a beta-hairpin pep-
tide
studied
by
a
multicanonical
replica-
exchange molecular dynamics simulation. Pro-
teins 66:846–859
49. Yoda T, Sugita Y, Okamoto Y (2010) Hydro-
phobic core formation and dehydration in pro-
tein folding studied by generalized-ensemble
simulations. Biophys J 99:1637–1644
50. Mitsutake A, Okamoto Y (2000) Replica-
exchange simulated tempering method for
simulations of frustrated systems. Chem Phys
Lett 332:131–138
51. Kim J, Keyes T, Straub JE (2010) Generalized
replica
exchange
method.
J
Chem
Phys
132:224107
52. Barducci A, Bussi G, Parrinello M (2008) Well-
tempered metadynamics: a smoothly converg-
ing and tunable free-energy method. Phys Rev
Lett 100:020603
53. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci U S A
99:12562–12566
54. Camilloni C, Provasi D, Tiana G, Broglia RA
(2008) Exploring the protein G helix free-
energy surface by solute tempering metady-
namics. Proteins 71:1647–1654
55. Jung J, Naurse A, Kobayashi C, Sugita Y
(2016) Graphics processing unit acceleration
and parallelization of GENESIS for large-scale
molecular dynamics simulations. J Chem The-
ory Comput 12:4947–4958
56. Pettersen
EF,
Goddard TD,
Huang
CC,
Couch GS, Greenblatt DM, Meng EC et al
(2004) UCSF Chimera—a visualization system
for exploratory research and analysis. J Comput
Chem 25:1605–1612
57. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph 14(33–8):27–28
58. Hunter JD (2007) Matplotlib: a 2D graphics
environment. Comput Sci Eng 9:90–95
59. Re S, Nishima W, Miyashita N, Sugita Y (2012)
Conformational ﬂexibility of N-glycans in solu-
tion studied by REMD simulations. Biophys
Rev 4:179–187
60. Matsunaga Y, Komuro Y, Kobayashi C, Jung J,
Mori T, Sugita Y (2016) Dimensionality of
collective variables for describing conforma-
tional changes of a multi-domain protein. J
Phys Chem Lett 7:1446–1451
61. Maragliano L, Fischer A, Vanden-Eijnden E,
Ciccotti G (2006) String method in collective
variables: minimum free energy paths and iso-
committor surfaces. J Chem Phys 125:24106
62. Woods G (2005–2018) GLYCAM Web. Com-
plex Carbohydrate Research Center, University
of Georgia, Athens, GA
63. Jo S, Song KC, Desaire H, MacKerell AD Jr,
Im W (2011) Glycan Reader: automated sugar
identiﬁcation and simulation preparation for
carbohydrates and glycoproteins. J Comput
Chem 32:3135–3141
64. Park SJ, Lee J, Patel DS, Ma H, Lee HS, Jo S
et al (2017) Glycan Reader is improved to rec-
ognize most sugar types and chemical modiﬁ-
cations
in
the
Protein
Data
Bank.
Bioinformatics 33:3051–3057
65. Guvench O, Greene SN, Kamath G, Brady JW,
Venable RM, Pastor RW et al (2008) Additive
empirical force ﬁeld for hexopyranose mono-
saccharides. J Comput Chem 29:2543–2564
66. Guvench O, Hatcher ER, Venable RM, Pastor
RW, Mackerell AD (2009) CHARMM additive
all-atom force ﬁeld for glycosidic linkages
between hexopyranoses. J Chem Theory Com-
put 5:2353–2370
67. Guvench O, Mallajosyula SS, Raman EP,
Hatcher E, Vanommeslaeghe K, Foster TJ
et al (2011) CHARMM additive all-atom
force ﬁeld for carbohydrate derivatives and its
utility in polysaccharide and carbohydrate-
protein modeling. J Chem Theory Comput
7:3162–3180
68. Jorgensen WL, Chandrasekhar J, Madura JD,
Impey RW, Klein ML (1983) Comparison of
simple potential functions for simulating liquid
water. J Chem Phys 79:926–935
69. Patriksson A, van der Spoel D (2008) A tem-
perature predictor for parallel tempering simu-
lations. Phys Chem Chem Phys 10:2073–2077
70. Miao Y, Feher VA, McCammon JA (2015)
Gaussian
accelerated
molecular
dynamics:
unconstrained enhanced sampling and free
energy calculation. J Chem Theory Comput
11:3584–3595
71. Miao Y, Sinko W, Pierce L, Bucher D, Walker
RC,
McCammon
JA
(2014)
Improved
reweighting of accelerated molecular dynamics
simulations for free energy calculation. J Chem
Theory Comput 10:2677–2689
72. Kumar S, Bouzida D, Swendsen RH, Kollman
PA, Rosenberg JM (1992) The weighted
176
Yuji Sugita et al.

histogram analysis method for free-energy cal-
culations on biomolecules. 1. The method. J
Comput Chem 13:1011–1021
73. Kumar S, Rosenberg JM, Bouzida D, Swend-
sen RH, Kollman PA (1995) Multidimensional
free-energy calculations using the weighted
histogram analysis method. J Comput Chem
16:1339–1350
74. Shirts MR, Chodera JD (2008) Statistically
optimal analysis of samples from multiple equi-
librium states. J Chem Phys 129:124105
REMD for BioSim
177

Chapter 8
Metadynamics to Enhance Sampling in Biomolecular
Simulations
Jim Pfaendtner
Abstract
Molecular dynamics is a powerful simulation method to provide detailed atomic-scale insight into a range of
biological processes including protein folding, biochemical reactions, ligand binding, and many others.
Over the last several decades, enhanced sampling methods have been developed to address the large
separation in time scales between a molecular dynamics simulation (usually microseconds or shorter) and
the time scales of biological processes (often orders of magnitude longer). This chapter speciﬁcally focuses
on the metadynamics family of methods, which achieves enhanced sampling through the introduction of a
history-dependent bias potential that is based on one or more slow degrees of freedom, called collective
variables. We introduce the method and its recent variants related to biomolecular studies and then discuss
frontier areas of the method. A large part of this chapter is devoted to helping new users of the method
understand how to choose metadynamics parameters properly and apply the method to their system of
interest.
Key words Metadynamics, Enhanced sampling, Proteins, Biomolecular simulations, Molecular
dynamics
1
Introduction
This chapter introduces the metadynamics (MetaD) method
through the lens of biomolecular simulations. In 2002 [1],
MetaD was introduced as a simple approach to explore slow
degrees of freedom in biased molecular simulations. In the
subsequent 17 years since its introduction, it has grown widely in
popularity owing to traits such as its ﬂexibility and adaptability to a
variety
of
problems,
straightforward
implementation
and
community-developed codes supporting the method, ease of inter-
pretation of the results, and (presumably) the lasting value of the
method as an essential tool for molecular modelers.
This chapter was written keeping new practitioners of the
method, probably graduate students and postdocs, in mind. We
assume that the reader is generally familiar with molecular
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_8, © Springer Science+Business Media, LLC, part of Springer Nature 2019
179

simulation of biomolecules. This chapter introduces a few concepts
that are essential for learning how the method works, followed by
an overview of MetaD theory and introduction of some variations
on MetaD relevant to biomolecular simulations. Next, a brief
review of frontier areas in development of MetaD theory is
provided, followed by a look at how researchers have been applying
MetaD to problems involving biomolecules over the last few years.
The chapter concludes with advice on how to approach learning
practical skills to use MetaD, and a section of notes and tips.
As a ﬁnal note, this chapter will not address the historic devel-
opment of the MetaD method or compare MetaD to other meth-
ods. The simple reason for this is that our emphasis here is
speciﬁcally on introducing MetaD and its variants as currently
applied to a host of problems in biomolecular simulations. Readers
interested in such comparisons and detailed development can ﬁnd
many engaging discussions in the many review articles that have
been published over the last 12 years from a general perspective
[2–7], that of biology [8–10], and that of chemical reactions
[11, 12].
2
The Collective Variables (CVs) and Biasing a Simulation Using CVs
The CV is perhaps the most generic term in use to describe, in
reduced dimension, some important properties of the 3N-6
degrees of freedom in a molecular simulation. A CV can be trivially
deﬁned as any quantity that is calculated using some or all of the
microscopic coordinates in a system (e.g., distances, angles, radii of
gyration, or coordination number). The usual deﬁnition of CVs
[5, 9] reserves the variable S and notes the dependence on the
microscopic coordinates (R) as:
S R
ð
Þ ¼ S1 R
ð Þ; . . . ; Sd R
ð
Þ
ð
Þ:
ð1Þ
Strictly speaking, the only requirement of a CV is that it is
instantaneously calculable from the microscopic coordinates only.
However, care should be taken in choosing a CV that provides
meaningful information about the system of interest. Some rules
of thumb about the selection of CVs for biomolecular simulations
are provided in the Subheading 7 of this chapter. For the purpose of
the introduction of the MetaD method and biasing CVs, it sufﬁces
to say that using a relatively small number of CVs, one should be
able to distinguish between relevant (stable or metastable) states in
a system related to phenomena of interest, and the CVs must be
differentiable with respect to the system coordinates.
The CV has two special subclasses that also bear mentioning:
the order parameter and the reaction coordinate. Given how often
these deﬁnitions are confused, it is essential for a modeler to
180
Jim Pfaendtner

understand the subtle differences. Order parameters are strictly
deﬁned with regard to the assessment of atomic or molecular
ordering in a system [13, 14]. Typical use cases of order parameters
involve differentiating between phases of a material or characteriz-
ing the atomic structure of a particular phase. Like order para-
meters, reaction coordinates are also CVs. The essential difference
is that reaction coordinates are capable of uniquely quantifying the
dynamics of a system as it transitions between two stable states
[13]. Discussion of the identiﬁcation and assessment of reaction
coordinates has been thoroughly accomplished elsewhere [14] and
is far beyond the scope of this article. However, every user of
metadynamics should understand that CVs should strictly be
referred to as “reaction coordinates” only when a certain set of
tests have been performed to verify the properties of the energy
landscape projected onto the CVs, F(S), obey a certain set of
stringent requirements [13, 14].
It can be shown [15] that integration of the partition function
over the phase space of the CVs yields the well-known relationship
between the CV’s probability distribution, P(S), and free-energy:
F sð Þ ¼ kBT  log P sð Þ
ð
Þ:
ð2Þ
However, the use of this relationship in the biomolecular con-
text is very often hindered by the lack of sufﬁcient statistics to
construct a reliable histogram in the estimation of P(s). Our limita-
tions on available simulation time are often insufﬁcient for sampling
enough transitions between relevant states in the system so that
thermodynamic or kinetic quantities can be calculated at an accept-
able level of uncertainty. When there is a decent guess about how
the relevant slow CVs hinder fast exploration of phase space, the use
of enhanced sampling methods that bias those CVs can be very
effective.
For the purpose of this chapter, the concept of “bias” means an
additional term added to the system’s potential energy function.
Because of the direct connection between the instantaneous coor-
dinates of the system and the CV, a bias can be trivially added, only
as a function of the CVs, as a mean to direct the simulation in a
number of different ways. As eluded to in the Introduction, there
are scores of different CV-based biasing methods and it is beyond
the scope of this chapter to introduce them in any substantive way.
However, the essential divergence of a “static bias” versus a “tran-
sient bias” is essential to understand.
Within the world of enhanced sampling with a static bias, the
method of umbrella sampling (US) [16] still remains the simplest
to understand and popular to use—over 40 years after its introduc-
tion. In the usual usage of US, a static biasing potential is added to
restrain the system to some point in CV space (S0). Very frequently,
this bias potential takes the form of a harmonic restraint:
Metadynamics in Biomolecular Simulations
181

V bias S
ð Þ ¼ ks S  S0
ð
Þ2:
ð3Þ
Proper selection of the spring constant (ks) allows for rapid
determination of the biased probability distribution (Pbias). It can
be trivially shown [5, 16] that the unbiased (often target) probabil-
ity distribution is obtained from the biased ensemble as:
Ptarget S
ð Þ / Pbias S
ð ÞeβV bias S
ð Þ,
ð4Þ
which allows for reconstruction of the free energy (projected onto
S). In practice, many US calculations are performed to expedite
sampling over the interesting range of S, and the entire free energy
is reconstructed by alignment of the individual and overlapping free
energies
using
a
method
like
weighted
histogram
analysis
(WHAM), which is very commonly used with the harmonic poten-
tials described in Eq. 3 [17].
While US and related static biasing methods are reliable and
straightforward to understand and implement, there are many cases
in which on-the-ﬂy adjustment of the bias can be advantageous
(e.g., avoiding oversampling of high-energy regions or extension to
many
dimensions).
A
transiently
biased
enhanced
sampling
method, in which the bias potential evolves during the simulation,
can overcome some of the limitations of US, and the MetaD
method is commonly used for this task.
3
Enhancing Important Fluctuations with Metadynamics
Since its introduction in 2002 [1], the MetaD family of methods
has enjoyed success and growth from a large group of users and
developers. Brieﬂy, MetaD is a method to enhance key ﬂuctuations
[5] in a system that is trapped in a stable or metastable state. This is
accomplished by the introduction of a time-dependent biasing
potential: V(s(R),t), which acts on selected slow degrees of freedom
(called CVs) (S(R)). The typical form of the MetaD bias potential at
a given time (t) uses a summation of Gaussians as in Eq. 5, where
W represents the Gaussian height (energy), τG is wait time between
Gaussian additions, and σ is the width of the Gaussian for the ith
CV:
V S; t
ð
Þ ¼
X
t0<
t0¼τG...
W 0  ∏N CV
i¼1 exp  Si  Si t0
ð Þ
ð
Þ2
2σ2
i
"
#
:
ð5Þ
In the commonly used well-tempered MetaD (WTM) variant
[18], the Gaussian height (Eq. 6) is controlled by the amount of
prior bias deposited as well as the parameter ΔT (also known as bias
factor or γ ¼ (ΔT + T)/T) to ensure smooth decay and convergence
of the bias, which is initially deposited at a height of W0 (n.b.,
standard MetaD is obtained as an instance of WTM in which the
182
Jim Pfaendtner

CV temperature, ΔT, is inﬁnite, i.e., the Gaussian hill heights are
ﬁxed in height)
W ¼ W 0  exp V s; t
ð
Þ
kBΔT


:
ð6Þ
Applying a bias potential to important slow CVs encourages
the system to visit new locations in the CV space, leading to wide
exploration of phase space. The free energy plus a usually neglected
constant, as projected onto the CVs (F(s)), can be readily estimated
in a time-dependent manner as shown in the original well-tempered
MetaD paper [9, 18] (Eq. 7). Recently, Tiwary and Parrinello
introduced a time-independent estimator [19] of the free energy
from a well-tempered MetaD simulation (Eq. 8), allowing for
improved estimates of convergence and easier reweighting (Eqs. 9
and 10):
F S
ð Þ ¼ 
T γ
ΔT


V S; t ! 1
ð
Þ þ C
ð7Þ
F S
ð Þ ¼ 
T γ
ΔT


V S; t
ð
Þ þ kBT log
ð
dseγV S;t
ð
Þ=kBΔT
ð8Þ
In addition to the free energy of the CVs, the converged bias
potential from a MetaD simulation can be used to obtain other
properties. In particular, the probability distributions of other
observables from the simulation can be reweighted in order to
obtain estimates of the unbiased probability, and thereby the free
energy. A histogram reconstruction method was originally pro-
posed by Bonomi et al. for reweighting [20]. Later, a useful ansatz
was proposed [21] that treated the ﬁnal bias potential as a static
quantity and reweights using the Torrie–Valleau relation (Eq. 4).
Recently, Tiwary and Parrinello have shown that the time-
independent MetaD free-energy estimator (Eq. 8) also provides a
useful means to reweight the simulation for ensemble averages or
free energies of other observables (Eqs. 9 and 10):
O R
ð
Þ
h
iunbiased ¼
O R
ð
Þeβ V S;t
ð
Þc tð Þ
ð
Þ
D
E
biased
ð9Þ
eβc tð Þ 
ð
ds eγV S;tþΔt
ð
Þ=kBΔT  eγV S;t
ð
Þ=kBΔT
h
i
:
ð10Þ
For systems with a few (usually 2, no more than 3) relevant slow
degrees of freedom, MetaD is robust and easy to use as evidenced
by the huge number of applications of the method. Such simula-
tions can provide quantitative estimates of underlying free energies,
which can be tested in a straightforward manner for their impor-
tance to the underlying mechanism [22] and/or reweighted to
provide free energies of other CVs that are known to be important.
However, moving beyond even 2 CVs presents a daunting
Metadynamics in Biomolecular Simulations
183

computational task due to the exploding dimensionality of the
metadynamics bias. Within the context of time-dependent biasing
methods, several advances on the original well-tempered MetaD
scheme can be used to speed convergence and/or potentially
explore more degrees of freedom, particularly for biomolecular
simulations. These methods and their scope are brieﬂy highlighted
in Table 1, without exhaustive derivation of their governing equa-
tions. As discussed in Subheading 6 and related chapters in this
book, the implementation of MetaD and analysis of the results has
been greatly facilitated through the development and free distribu-
tion of the PLUMED library [29, 30].
Table 1
Brief overview of key improvements to the original MetaD scheme often used in biomolecular
simulations
Method
Description
Number
of CVsa
Key limitations
Standard MetaD or
well-tempered
MetaD [1, 18]
As described above
1–3
Hidden degrees of freedom limit
convergence
MetaD + multiple
walkers [23]
Scheme to improve convergence
speed of a MetaD simulation by
having parallel replicas share a
bias potential
1–3
Hidden degrees of freedom limit
convergence
MetaD + parallel
tempering [24]
Combine MetaD with parallel
tempering [25] to use
temperature to explore
acceleration of hidden degrees
of freedom
1–3
Number of replicas grows steeply
with system size with explicit
solvation. Hidden degrees of
freedom must be energetic,
not entropic. Usually limited
to fewer than 3 CVs
Bias exchange MetaD
(BEMD) [26]
Combine MetaD with replica-
exchange scheme to increase
dimensionality of approach.
Each replica biases a different
CV, swap with Metropolis
conﬁguration
Usually
5 or
fewer
Serial bias of many CVs causes
challenges for collective
motions. Number of replicas
scales with numbers of CVs.
Not straightforward to
construct multidimensional
free energy surfaces
MetaD + parallel
tempering + WTE
[27, 28]
Use well-tempered-ensemble [28]
MetaD to overcome system size
challenges from MetaD + PT
1–3
Hidden degrees of freedom must
be energetic, not entropic.
Same CV limitations as other
MetaD simulations
aNumber of CVs here refers to simulations in which exhaustive convergence of the transient bias potential can usually be
demonstrated
184
Jim Pfaendtner

4
Recent Frontier Areas
This section details several areas of the MetaD methodology that
have been in development in recent years, which are speciﬁcally
related to effective simulation of biomolecular systems.
4.1
High-
Dimensional Sampling
Although the bias-exchange MetaD (BEMD) method has found
widespread use, the number of CVs are still often limited by the
explicit requirement to increase the number of parallel replicas of
the system for each CV added. Recently, Pfaendtner and Bonomi
have introduced an alternate approach based on sampling of an
arbitrary number of CVs with individual biases all contained in a
single replica—parallel bias Metadynamics (PBMetaD) [31]. The
key relationships in PBMetaD are described below.
The central concept in PBMetaD begins with considering mul-
tiple WTM bias potentials. It is known (from the derivation of
so-called concurrent MetaD [32]) that simultaneous addition of
Gaussians to both potentials (VG(S1) and VG(S2)) will lead the
system to converge to the wrong ﬁnal free energy [31]. This sys-
tematic error is due to the fact that CVs are usually not entirely
independent and there is some correlation between them. In
PBMetaD, we introduce a discrete auxiliary variable, η, which can
be used for on-the-ﬂy switching between Gaussian additions to
different biases. The extended probability distribution of this hypo-
thetical system is given by:
P R; η
ð
Þ / exp β  U R
ð
Þ þ η1V G S1; t
ð
Þ þ η2V G S2; t
ð
Þ
ð
Þ
ð
Þ: ð11Þ
In principle, one could sample the probability distributions
including η by a Gibbs sampling scheme, which pairs MD of the
atomistic coordinates (R) with a Monte Carlo sampling of η. How-
ever, it is of course not desirable to add another system variable.
Moreover, there is no reason to suspect the equilibrium statistics of
η will provide useful information about the system. We can margin-
alize [33] the probability distribution to remove η and obtain an
effective multidimensional bias potential as shown in Eqs. 12 and
13:
P R
ð
Þ ¼
ð
dηP R; η
ð
Þ ¼ P R; 1; 0
ð
Þ
ð
Þ þ P R; 0; 1
ð
Þ
ð
Þ
/ exp β  U R
ð
Þ þ V PB S1; S2; t
ð
Þ
ð
Þ
ð
Þ
ð12Þ
V PB S1; S2; t
ð
Þ ¼ 1
β log exp βV G S1; t
ð
Þ
ð
Þ þ exp βV G S2; t
ð
Þ
ð
Þ
ð
Þ:
ð13Þ
As shown in these equations, the probability distribution of (R)
evolves with a unique exponential sum of multiple Gaussian bias
potentials—this is the chief innovation of PBMetaD and explains why
Metadynamics in Biomolecular Simulations
185

many biases can be constructed in parallel (and therefore permit
scaling to arbitrary numbers of CVs). Finally, the functional form
of the Gaussian bias potential in Eq. 13 is fundamentally different
from that introduced in WTM in Eqs. 5 and 6. In PBMetaD, the
correct Gaussian heights are obtained through on-the-ﬂy determi-
nation of instantaneous weights (heights) of each Gaussian in
Eq. 14. These relationships are derived in detail in the original
PBMetaD paper [31] and summarized here for the ﬁrst CV as
ω1 tð Þ ¼ ω  exp V G S1; t
ð
Þ
kBΔT 1


 P η ¼ 1; 0
ð
ÞjR
ð
Þ
ð14Þ
P η ¼ 1; 0
ð
ÞjR
ð
Þ ¼
exp βV G S1; t
ð
Þ
ð
Þ
exp βV G S1; t
ð
Þ
ð
Þ þ exp βV G S2; t
ð
Þ
ð
Þ : ð15Þ
The proportional scaling of the Gaussian heights can be
extended to an arbitrary number of CVs. We also note that PBMe-
taD is designed to be used with low-dimensional bias potentials
(which converge very fast), so the typical penalty for adding more
CVs to the overall bias potential can be reduced compared to
ordinary MetaD simulations.
4.2
Learned CVs
As many practitioners of MetaD have discovered, the quest to ﬁnd
the correct set of CVs that discriminate between relevant states and
lead to effective biasing within MetaD is often arduous. In fact,
many researchers consider the identiﬁcation of “good CVs” tanta-
mount to solving the science problem at hand. A question naturally
arises as to whether there exist methods complementary to MetaD
that can assist in identiﬁcation of the correct CVs—either using
unbiased trajectories of the system in its stable basins or other
advanced methods. Perhaps one of the earliest examples of this is
the use of the principal component analysis (PCA) to determine the
CVs used in biasing conformational switching in alanine dipeptide
[34]. Several years later, the “Reconnaissance MetaD” method was
introduced as a self-learning method capable of discovering on-the-
ﬂy clusters corresponding to stable basins [35]. The Sketch-map
algorithm uses this method to provide reduced dimensional CVs
for biasing [36]. Recently, a new algorithm called spectral gap
optimization of order parameters (SGOOP) was introduced to
provide a convenient estimate of the best combination of a series
of candidate CVs, with the ultimate goal of maximizing the speed
of convergence of MetaD simulations by using the principal of
entropy maximization to learn optimal CVs [37]. The time-
structure-based independent component analysis (tICA) method
is another example of a method capable of learning optimal CVs for
use in MetaD simulations [38]. These methods are examples of
emerging algorithms that complement the MetaD framework to
assist users in identifying the best CVs for their problem.
186
Jim Pfaendtner

4.3
Kinetics from
MetaD
Up until this point in this chapter, we have focused on applications
of MetaD to the determination of equilibrium thermodynamics via
fast exploration of the conformational space of a few CVs. This
capability has transformed our ability to use molecular simulations
of biomolecules for determination of free energies and related
quantities. However, the relative weights of stable and metastable
states in a system tell only part of the story. The kinetics of transi-
tions between important states is also very important, and a worthy
goal for investigation with molecular simulations. As previously
stated, there are well-known challenges with interpretation of the
free-energy surfaces derived from MetaD simulations—and an
observed barrier height or estimated activation energy should gen-
erally not be claimed from a simulation without additional testing,
usually via committor analysis [14]. Even though a barrier height is
determined from MetaD, it must be interpreted through the lens of
an additional theory (e.g., transition state theory) to relate it to a
kinetic rate coefﬁcient. It has been shown that such a collection of
kinetic rate coefﬁcients derived from MetaD can be effectively used
in construction of a Markov state model (MSM) as a bridge to
macroscopic kinetics [39].
An alternate approach is to use the microscopic details of the
biased MD trajectories and reconstruct unbiased time scales of the
successful events that escape metastable basins. To this end, infre-
quent metadynamics [40] was introduced as a variant of the hyper-
dynamics
approach
[41].
Brieﬂy,
both
methods
work
by
reconstructing unbiased time scales according to a simple relation:
tunbiased ¼
X
N
i
ΔtMDeβV S;t
ð
Þ,
ð16Þ
where Δt is the time step in the MD simulation and V(s,t) is the
value of the bias potential at the ith time step. The key innovation in
infrequent MetaD is the demonstration that the transient MetaD
biasing potential can be used in place of the static bias potential that
is used in hyperdynamics calculations. A set of useful statistical
analyses [42] accompany the method and guide the user toward
understanding how many simulations must be performed to obtain
statistically reliable results. In the biomolecular space, the infre-
quent MetaD method has been used to study the kinetics of protein
unfolding [43] and protein/ligand binding [44–46] and confor-
mational switching in mini-peptides [47]. A recent addition to the
method by Wang et al. [48] provides a frequency-adaptive scheme
that can increase the efﬁciency of the rates calculation.
4.4
Integration of
MetaD and
Experimental Data
This section brieﬂy introduces efforts to reproduce or integrate
experimental data within metadynamics simulations. The reader is
also referred to Part III of this book, the entirety of which is
devoted to integration of experimental data into biomolecular
Metadynamics in Biomolecular Simulations
187

simulations. The advent of early methods to reweight MetaD
simulations by Bonomi and Parrinello [20] led to efforts to calcu-
late ensemble-averaged quantities that were interesting to the user,
but not useful CVs for biasing. Prominently, it was shown that
nuclear magnetic resonance (NMR) scalar couplings could be
recovered from biased simulations of peptides [20]. This was an
important development in the MetaD family of methods, demon-
strating the effectiveness of the approach in determining a huge
range of interesting equilibrium properties from biased simula-
tions. Following this development, Camilloni et al. introduced
replica-averaged
MetaD
[49],
introducing
the
concept
of
structural-averaged restraints within MetaD type approaches.
Later, White and Voth [50, 51] and separately Marinelli and Fer-
aldo-Go´mez [52] demonstrated effective ways to use MetaD to
bias simulations toward target distributions that proved to be better
representations of different types of experimental data. This
approach has been referred to as target metadynamics [53] and
applied in a variety of contexts. Recently, Bonomi et al. [54] have
paired the Bayesian metainference method of Bayesian inference
with MetaD in an effort to more broadly address issues arising from
many types of errors in data (and simulation force ﬁelds) and
account for a nuanced problem that often escapes modelers who
are attempting to reproduce experimental data—how to account
for sample heterogeneity.
4.5
What Types
of MetaD Calculations
Are People Using
to Study Biological
Problems?
Another useful way to understand how to select the appropriate
type of MetaD to apply to your system is to look at what has been
used in recent studies making use of MetaD. To this end, a litera-
ture review was performed that ultimately led to detailed analysis of
49 manuscripts published over the last 3 years that used MetaD for
the study of biological problems [55–103]. The methodology for
selecting these manuscripts is detailed at the end of the subsection
and summative results are shown below in Table 2.
The manuscripts were scrutinized to understand the type of
biomolecules under investigation, the type of MetaD used, which
CVs were employed in the study of a particular biological problem
and ﬁnally, which code or force ﬁeld was employed. This snapshot is
only meant to help new users understand what types of problems
are being investigated and with what tools. The frequency column
in Table 2 is a simple frequency count of papers that used that
particular item in the table. Note that there are several catch-all
categories. For example, “multireplica” includes a number of
MetaD variants including multiple walkers, bias exchange MetaD,
PTMetaD, replica-averaged MetaD, and parallel bias MetaD (all of
which have been already brieﬂy discussed in this study). The CVs
commonly employed largely use distances or dihedral angles, with a
separate call-out for CVs based on the common sigmoidal “coordi-
nation number” (see PLUMED manual for reference). The high
188
Jim Pfaendtner

frequency in the category of “other conformational sampling” is in
recognition of the huge range of interesting biological conforma-
tional changes that do not strictly involve folding of a peptide or
protein. Finally, it is stressed that reporting the relative proportion
of using a certain type of force ﬁeld or code is by no means an
endorsement of those potentials or software.
5
Some Essential Concepts for Biomolecular Simulations
This section reviews a few high-level concepts that are important to
understand before setting out to study a biomolecular problem
with MetaD.
5.1
Understanding
How to Choose
Your CVs
Arguably, one of the greatest challenges in a MetaD simulation is
the proper selection of the CVs so as to achieve reliable accelerated
sampling of phase space. Mastery of this task, and the subtle details
that underlie your choices will take years to develop. You will help
Table 2
Details of a collection of published MetaD investigations from the past 3 years
Category and details
Frequency in set
of papers (%)
System
Proteins or peptides
90
MetaD method
Well-tempered
63
Multireplica
45
Type of CVs used
Distance
65
Dihedral
20
Coord-type
16
Type of biological problem
Folding
22
Binding
27
Other conformational sampling
(including large-scale domain motion)
39
Code used and family
of force ﬁelds selected
GROMACS + PLUMED
71
AMBER force ﬁeld
45
CHARMM force ﬁeld
25
The literature review was conducted as follows. On January 15, 2018, Web of Science was used to search with the
following parameters: title includes “metadynamics” OR topic includes “metadynamics” over the period 2015–2018.
The results were reﬁned by including only articles from among any of the following categories from among the available
Web of Science scientiﬁc topics: cell biology, biochemistry, molecular biology, pharmacology, pharmacy, biology,
biophysics, biotechnology, applied microbiology, mathematical computational biology, or biochemical research methods.
From this set of around 85 articles, the list was further reﬁned by removing all articles that had no biomolecular
signiﬁcance, review articles, metastudies, conference abstracts, or methods papers that explicitly developed a new method
or MetaD variant. The ﬁnal list that was scrutinized to obtain this table contained the 49 original research articles cited
above. It is emphasized that these 49 articles are simply the result of the above search parameters and therefore assumed
to be a likely representative sample of how MetaD is being applied to biological problems over the last 3 years. The intent
was not to be entirely comprehensive of all published research that uses MetaD to study biological problems over this
time period, and we apologize in advance if your published research that ﬁts these criteria did not appear in the search as
we performed it
Metadynamics in Biomolecular Simulations
189

yourself the most by making a habit of visualizing the trajectories of
your biomolecules with a careful emphasis on the behavior of the
CVs. Unfortunately, MetaD is not a substitute for actual physical
understanding of your system, which can only be gained by the
painstaking work of studying and careful trial-and-error testing.
Additionally, careful consideration of seemingly innocent choices
(e.g., does it matter if you bias the RMSD of all backbone atoms or
just the alpha carbons?) will help you quickly develop deeper
insight. I have found it useful to sketch out the results of these
thought experiments with an emphasis on “following the forces”
(i.e., understanding how forces get applied and propagated due to
MetaD biasing). Get in the habit of asking how your CV deﬁnitions
translate to applied forces in your system.
5.2
Understanding
Hidden CVs
The “hidden CV” concept has been well known for over a decade.
As an illustrative example, consider a peptide with exposed charged
side chains, both positive and negative. Using MetaD to bias the
radius of gyration of the backbone will initially lead to unfolding or
change in conformation. However, it is possible that salt bridges,
not present in the native state of the peptide, form, which frustrates
the exploration of phase space. Using MetaD for biomolecular
simulations tends to be particularly prone to frustrations of hidden
CVs. This is presumably due to the rich chemical diversity of
proteins, the huge number of possible interactions, and the inher-
ent ﬂexibility of biomolecules. Fortunately, careful visualization of
trial MetaD calculations (see Subheading 7) will often reveal new
slow CVs that were unanticipated at the onset of your calculations.
These newly discovered interactions can be incorporated into your
bias potential as additional CVs or combined into other CVs.
5.3
Determining If
Your Simulation Is
Converged
The convergence of a MetaD simulation tends to be difﬁcult to
assess compared to other types of molecular simulations. This is due
to the transient nature of the bias potential as well as the possibility
for hidden variables to frustrate exploration of phase space related
to your chosen CVs. There is abundant guidance in free online
tutorials from the PLUMED developers (see www.plumed.org,
Chapter 21 of this book, and other published works that use
MetaD). Additionally, several of the tips and suggestion in Sub-
heading 7 of this chapter are devoted to helping you understand
best practices in ensuring your simulations are converged.
5.3.1
Ensuring
Reproducible MetaD
Simulations
Simply put: the journal you are publishing in has a supplemental or
supporting information section—use it. Even more than standard
MD simulations, enhanced sampling MetaD simulations can have a
signiﬁcant (ten or more) number of adjustable parameters that are
related to all aspects of how the bias potential is constructed.
Therefore, it is paramount among your duties as a responsible
researcher to ensure others can reproduce your simulations.
190
Jim Pfaendtner

Although the community of researchers using MetaD has gone
through great lengths to ensure that we understand the relationship
between the adjustable parameters in our simulation and the speed
of convergence (e.g., early work studying this relationship on
model potentials [104]), there remains a great need [105] for
researchers in our ﬁeld to be vigilant in taking steps to ensure
MetaD simulations can be reproduced.
6
Getting Started with Metadynamics and Biomolecular Simulations
This section will serve as a reference to new users of metadynamics
with biomolecular simulations. It is assumed that the aspiring user
will have at least an intermediate level of familiarity with performing
MD simulations of proteins or other biomolecules and a solid
understanding of the relevant states of the system or types of
processes the user wishes to explore with enhanced sampling. As
detailed extensively in Chapter 21 of this book, the PLUMED
library [29, 30] is an obvious choice for carrying out MetaD
simulations in a variety of free and open source codes. Details on
analyzing and biasing simulations with PLUMED, including the
structure and usage of the code are available in the aforementioned
chapter. Furthermore, there is a wealth of free tutorials and docu-
mentation available at the PLUMED page (www.plumed.org).
Development of proﬁciency with advanced enhanced sampling
methods can take years, and the information contained in this
chapter is simply meant to point the new user in the right direction.
There are two essential tasks a new MetaD user should set about to
do before diving headﬁrst into production simulations on a com-
plex and, potentially, computationally expensive campaign of pro-
duction
simulations:
reproduce
known
results
and
develop
intuition about the behavior of their own system. These are covered
in the remainder of this section.
Once the basic theory of MetaD is understood from reading
and studying available learning materials online, it is time to try
your ﬁrst MetaD calculation for a biomolecular system. I strongly
recommend the so-called “alanine dipeptide” (actually ACE-ALA-
NME, in practice), given that the existing results for a huge range
of force ﬁelds and variants of MetaD can be found through a
cursory literature search. For example, new MetaD users in our
research group are always instructed to exactly reproduce Fig. 1 of
the original well-tempered MetaD paper [18] using GROMACS.
The required CPU time for these calculations is of the order of
minutes on a modern laptop computer, so there is no barrier for any
aspiring user. This system is so well-studied, that it can seem trite.
However, there is no substitute for a computationally fast system
with multiple stable minima and an easy-to-understand energy
Metadynamics in Biomolecular Simulations
191

landscape. With conﬁdence that you can reproduce and visualize a
simulation of slow conformational change in a biomolecular sys-
tem, you may wish to seek other examples from the literature more
closely related to your problem of interest to reproduce. There are
abundant example problems reviewed in prior MetaD review arti-
cles and tutorials [9]. As previously noted, there is a great need to
support reproducible science, even more so in the context of
computational molecular science wherein there are comparatively
few sources of irreducible error that cannot be accounted for. If a
selected paper with a result for reproducing (i.e., learning MetaD)
does not contain sufﬁcient information to parameterize the calcu-
lation (e.g., some MetaD, MD or force ﬁeld terms are missing), you
are advised to move on to a paper with a more robust accounting of
key details so that you can, to the best of your ability, exactly
reproduce the input ﬁles for the calculation of interest.
In parallel to learning to use MetaD on a simpliﬁed system, you
should begin understanding the rare event or transformation you
wish to sample in your biomolecular system. A typical use case ﬁrst
involves preparing replicas of your system in the key metastable
states of interest and testing out a variety of CV choices. For
example, a folded or unfolded ensemble of a peptide, a large protein
with domains rotated or moved according to some biological func-
tion, an enzymatic reaction, or a ligand–protein binding event. As
detailed in Chapter 21 of this book, simpliﬁed functions for driving
the system to different parts of CV space (i.e., “steering”) are
readily available and can assist in quickly facilitating this task. You
should run classical MD simulations of the system in different
regions of phase space and observe the behavior of your trial CVs.
Failing any (bio)chemical insight about what regions of phase space
might separate minima of interest you can use some trial MetaD
simulations of the variety discussed in Subheading 7 to rapidly
explore the phase space of your CVs. Be warned that a few rounds
of trial and error in the selection of (1) appropriate CVs for your
problem and (2) which variant of MetaD will provide the fastest
convergence may be required. Therefore, you are especially
required to be vigilant in searching the literature for published
examples that can guide your initial guesswork.
7
Notes
This section is a collection of advice and tips for anyone setting out
to use MetaD to study biomolecular problems. While they are
mostly heuristic and based on our group’s experience, we hope
they will assist you in getting the most out of your CPU time!
192
Jim Pfaendtner

1. Do Ample Testing on Your Candidate CVs
It is absolutely essential to understand the properties of your
CVs in simple unbiased MD simulations. Whenever possible,
you should prepare your system (e.g., via steering) and run
classical MD trajectories with no MetaD bias to observe the
behavior of the system. You will learn a lot about the ways the
CVs diffuse through metastable basins and have the opportu-
nity to understand the effect on your CVs from your choice of
adjustable parameters (e.g., exponents in the sigmoidal switch-
ing functions commonly used in H-bonding and coordination
calculations). Only when you are convinced you have a set of
CVs that will faithfully discriminate between states you care
about, should you try biasing the system with MetaD. My
advice is to run trial MetaD simulations using the nontempered
variant. While well-tempered MetaD has proven to be very
effective at smoothly converging your bias potentials, it is
clear from years of experience that nontempered simulations
will often give you a faster initial transition between your stable
states. Simply put: if you cannot force your transition of interest
in a nontempered MetaD calculation, it is not going to work in
well-tempered MetaD.
2. Understand There Are Multiple Convergence Tests That You
Should Perform
The convergence of your simulation, at minimum, must be
assessed with two tests. First, at long simulation times, the
system must continue to diffuse among CV space and visit
regions of interest. If your system is “stuck” in one basin after
making several transitions, it is my judgement there is probably
an error in your selection of CVs. By all means, this could be an
interesting result to discuss in the supporting information of
your publication—we do not do a good enough job reporting
when things do not go as planned. However, I argue (force-
fully) that if you are failing to continue diffusing in CV space,
then it is almost certain the dynamics have been frustrated by
one or more “hidden” CVs. Take the time to visualize your
trajectories and carefully study why this might be occurring. I
cannot count the number of times we have learned something
interesting about the system by learning why a certain CV is not
working. Second, your bias potential should converge to an
acceptable level of accuracy. There are a number of tools avail-
able to assess convergence of the bias potential (analogously,
the free energy from MetaD). You can study the free-energy
difference between two states as a function of time, you can
look at the time evolution of 1D free-energy proﬁles, or you
can use block averaging methods (see recent PLUMED tutor-
ials for more information). Tiwary and Parrinello also demon-
strated how to use Eq. 8 in this paper to track the convergence
Metadynamics in Biomolecular Simulations
193

of a particular region of your free-energy landscape (e.g., to
determine if one basin more than another is slow to converge)
[19]. Convergence tests are essential to perform and should
always be published with your work in your supporting materi-
als. If you are a reviewer of a manuscript that uses MetaD,
please insist these details be added to the paper before
publication!
3. Understand the Proper Additional Tests Required for Multi-
replica Simulations
This chapter only introduced multiple replica simulations in a
cursory manner (Table 1). However, it is very important to
understand that your system can appear artiﬁcially converged
when you perform such simulations—so there are additional
criteria to consider. The simplest case is to consider the method
of multiple walkers MetaD. Here, independent replicas of your
simulation interact only via a shared MetaD bias potential. In
these cases, you must independently inspect the diffusivity of
CVs in each of your replicas. For example, it may appear that
you have a converged bias potential from a two-replica multi-
walker simulation, although each replica remains stuck in a
different basin. I have been asked many times for a rule of
thumb or heuristic for “how many transitions” between stable
states is enough, or if all of the replicas have to traverse all of
CV space in each simulation. My answer is always the same:
transparently publish all the details in the supporting informa-
tion of your paper. The truth is, we only know what is true at
the extremes: you cannot properly converge a MetaD FES if at
least one of your replicas does not traverse the different basins
in CV space and conversely, your convergence speed is max-
imized when your CVs promote rapid diffusion of all the
replicas throughout all of the important regions of CV space.
Share the key details of how your system approached equilib-
rium and nobody will fault you if it turns out later the work
could have been improved.
The more complicated case is when you are using parallel
tempering MetaD calculations. In this case, particularly in the
GROMACS code, you must understand exactly what is being
output. PT calculations typically follow the equilibrium ensem-
bles at each temperature, and therefore you do not intrinsically
have access to the time series of your CVs for your different
replicas. There are free tools available to reconstruct the indi-
vidual walker trajectories, and you are responsible for taking
the time to do the proper analysis to ensure at least some of
your replicas are diffusing through CV space. Otherwise, you
cannot credibly claim the bias potential has converged (follow-
ing the same logic as in the last paragraph).
194
Jim Pfaendtner

4. Errors Are Usually Evident Early in Your Simulation—If You
Carefully Visualize Your Trajectories
It has been my experience that all manner of errors in your
MetaD simulations, ranging from simple typos in your input
ﬁle to poorly selected CVs or hidden CVs can often be caught if
you take time during the early stages of your simulations to
watch movies of the simulation trajectories.
5. Make Use of Quantitative Reweighting of Your MetaD
Simulations
In my view, one of the biggest enablers of MetaD over the past
10 years has been the advent of methods to reweight your
simulations and estimate unbiased probability distributions of
your nonbiased CVs. This opens the door to calculation of all
types of quantities that would not be available either because
they are not instantaneously calculable (e.g., reweighting clus-
ters of structures as we have recently demonstrated [106]) or
they are not going to effectively lead to the conformational
exploration you want. It is important to note, however, that
additional convergence tests apply. The CVs you are reweight-
ing must also sufﬁciently diffuse so that their unbiased proba-
bility distributions converge within an acceptable level of error.
Acknowledgement
The author gratefully acknowledges the help of Kayla Sprenger and
Sarah Alamdari in providing detailed feedback on a draft of this
chapter.
References
1. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci U S A 99
(20):12562–12566
2. Laio A, Parrinello M (2006) Computing free
energies and accelerating rare events with
metadynamics.
Lect
Notes
Phys
703:303–335
3. Laio A, Gervasio FL (2008) Metadynamics: a
method to simulate rare events and recon-
struct the free energy in biophysics, chemistry
and material science. Rep Prog Phys 71
(12):126601
4. Barducci A, Bonomi M, Parrinello M (2011)
Metadynamics. WIREs Comput Mol Sci 1
(5):826–843.
https://doi.org/10.1002/
wcms.31
5. Valsson O, Tiwary P, Parrinello M (2016)
Enhancing important ﬂuctuations: rare events
and
metadynamics
from
a
conceptual
viewpoint.
Annu
Rev
Phys
Chem
67
(1):159–184.
https://doi.org/10.1146/
annurev-physchem-040215-112229
6. Sutto L, Marsili S, Gervasio FL (2012) New
advances in metadynamics. WIREs Comput
Mol Sci 2(5):771–779. https://doi.org/10.
1002/wcms.1103
7. Abrams C, Bussi G (2014) Enhanced sam-
pling in molecular dynamics using metady-
namics, replica-exchange, and temperature-
acceleration. Entropy 16(1):163
8. Leone V, Marinelli F, Carloni P, Parrinello M
(2010) Targeting biomolecular ﬂexibility with
metadynamics. Curr Opin Struct Biol 20
(2):148–154
9. Barducci A, Pfaendtner J, Bonomi M (2015)
Tackling sampling challenges in biomolecular
simulations. In: Kukol A (ed) Molecular mod-
eling of proteins. Springer, New York, NY, pp
Metadynamics in Biomolecular Simulations
195

151–171. https://doi.org/10.1007/978-1-
4939-1465-4_8
10. Furini S, Domene C (2016) Computational
studies of transport in ion channels using
metadynamics.
BBA-Biomembranes
1858
(7):1733–1740. https://doi.org/10.1016/j.
bbamem.2016.02.015
11. Ensing B, De Vivo M, Liu Z, Moore P, Klein
ML (2005) Metadynamics as a tool for
exploring free energy landscapes of chemical
reactions.
Acc
Chem
Res
39(2):73–81.
https://doi.org/10.1021/ar040198i
12. Zheng S, Pfaendtner J (2015) Enhanced sam-
pling of chemical and biochemical reactions
with
metadynamics.
Mol
Simulat
41
(1–3):55–72
13. Peters B (2017) Reaction rate theory and rare
events. Elsevier, Ann Arbor
14. Peters B (2016) Reaction coordinates and
mechanistic hypothesis tests. Annu Rev Phys
Chem 67(1):669–690. https://doi.org/10.
1146/annurev-physchem-040215-112215
15. Trzesniak D, Kunz APE, van Gunsteren WF
(2007) A comparison of methods to compute
the potential of mean force. ChemPhysChem
8:162–169. https://doi.org/10.1002/cphc.
200600527
16. Torrie GM, Valleau JP (1977) Non-physical
sampling distributions in Monte-Carlo free-
energy estimation - umbrella sampling. J
Comput Phys 23(2):187–199
17. Kumar S, Rosenberg JM, Bouzida D, Swend-
sen RH, Kollman PA (1995) Multidimen-
sional
free-energy
calculations
using
the
weighted histogram analysis method. J Com-
put Chem 16(11):1339–1350
18. Barducci A, Bussi G, Parrinello M (2008)
Well-tempered metadynamics: a smoothly
converging and tunable free-energy method.
Phys Rev Lett 100:020603
19. Tiwary P, Parrinello M (2015) A time-
independent free energy estimator for meta-
dynamics. J Phys Chem B 119(3):736–742.
https://doi.org/10.1021/jp504920s
20. Bonomi M, Barducci A, Parrinello M (2009)
Reconstructing the equilibrium Boltzmann
distribution
from
well-tempered
metady-
namics.
J
Comput
Chem
30
(11):1615–1621. https://doi.org/10.1002/
jcc.21305
21. Branduardi D, Bussi G, Parrinello M (2012)
Metadynamics with adaptive Gaussians. J
Chem
Theory
Comput
8(7):2247–2254.
https://doi.org/10.1021/ct3002464
22. Peters B (2010) Recent advances in transition
path sampling: accurate reaction coordinates,
likelihood maximization, and diffusive barrier
crossing
dynamics.
Mol
Simulat
36:1265–1281
23. Raiteri P, Laio A, Gervasio FL, Micheletti C,
Parrinello M (2006) Efﬁcient reconstruction
of complex free energy landscapes by multiple
walkers metadynamics. J Phys Chem B 110
(8):3533–3539.
https://doi.org/10.1021/
jp054359r
24. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for beta hairpin
folding from combined parallel tempering
and
metadynamics.
J
Am
Chem
Soc
128:13435–13441.
https://doi.org/10.
1021/ja062463w
25. Sugita
Y,
Okamoto
Y
(1999)
Replica-
exchange molecular dynamics method for
protein
folding.
Chem
Phys
Lett
314:141–151
26. Piana S, Laio A (2007) A bias-exchange
approach to protein folding. J Phys Chem B
111(17):4553–4559.
https://doi.org/10.
1021/jp0678731
27. Deighan M, Bonomi M, Pfaendtner J (2012)
Efﬁcient simulation of explicitly solvated pro-
teins in the well-tempered ensemble. J Chem
Theory Comput 8(7):2189–21982
28. Bonomi M, Parrinello M (2010) Enhanced
sampling in the well-tempered ensemble.
Phys Rev Lett 104(19):190601
29. Tribello GA, Bonomi M, Branduardi D,
Camilloni C, Bussi G (2014) PLUMED 2:
new feathers for an old bird. Comput Phys
Commun 185(2):604–613
30. Bonomi
M,
Branduardi
D,
Bussi
G,
Camilloni
C,
Provasi
D,
Raiteri
P,
Donadio D, Marinelli F, Pietrucci F, Broglia
RA, Parrinello M (2009) PLUMED: a porta-
ble plugin for free-energy calculations with
molecular dynamics. Comput Phys Commun
180(10):1961–1972.
https://doi.org/10.
1016/j.cpc.2009.05.011
31. Pfaendtner J, Bonomi M (2015) Efﬁcient
sampling
of
high-dimensional
free-energy
landscapes with parallel bias metadynamics. J
Chem Theory Comput 11(11):5062–5067.
https://doi.org/10.1021/acs.jctc.5b00846
32. Gil-Ley A, Bussi G (2015) Enhanced confor-
mational sampling using replica exchange
with collective-variable tempering. J Chem
Theory Comput 11(3):1077–1085. https://
doi.org/10.1021/ct5009087
33. Sivia J (2006) Data analysis: a Bayesian tuto-
rial. Oxford University Press, Oxford, UK
34. Spiwok V, Lipovova´ P, Kra´lova´ B (2007)
Metadynamics in essential coordinates: free
energy simulation of conformational changes.
196
Jim Pfaendtner

J Phys Chem B 111(12):3073–3076. https://
doi.org/10.1021/jp068587c
35. Tribello GA, Ceriotti M, Parrinello M (2010)
A self-learning algorithm for biased molecular
dynamics. Proc Natl Acad Sci U S A 107
(41):17509–17514.
https://doi.org/10.
1073/pnas.1011511107
36. Tribello GA, Ceriotti M, Parrinello M (2012)
Using sketch-map coordinates to analyze and
bias molecular dynamics simulations. Proc
Natl Acad Sci U S A 109(14):5196
37. Tiwary P, Berne BJ (2016) Spectral gap opti-
mization of order parameters for sampling
complex molecular systems. Proc Natl Acad
Sci U S A 113(11):2839–2844. https://doi.
org/10.1073/pnas.1600917113
38. Sultan
M,
Pande
VS
(2017)
tICA-
metadynamics: accelerating metadynamics by
using kinetically selected collective variables. J
Chem Theory Comput 13(6):2440–2447.
https://doi.org/10.1021/acs.jctc.7b00182
39. Marinelli F, Pietrucci F, Laio A, Piana S
(2009) A kinetic model of Trp-cage folding
from multiple biased molecular dynamics
simulations.
PLoS
Comput
Biol
5(8):
e1000452.
https://doi.org/10.1371/jour
nal.pcbi.1000452
40. Tiwary P, Parrinello M (2013) From metady-
namics to dynamics. Phys Rev Lett 111
(23):230602
41. Voter AF (1997) Hyperdynamics: accelerated
molecular dynamics of infrequent events.
Phys Rev Lett 78(20):3908–3911
42. Salvalaglio M, Tiwary P, Parrinello M (2014)
Assessing the reliability of the dynamics
reconstructed from metadynamics. J Chem
Theory Comput 10(4):1420–1425. https://
doi.org/10.1021/ct500040r
43. Tung H-J, Pfaendtner J (2016) Kinetics and
mechanism of ionic-liquid induced protein
unfolding: application to the model protein
HP35.
Mol
Syst
Des
Eng
1:382–390.
https://doi.org/10.1039/C6ME00047A
44. Tiwary P, Limongelli V, Salvalaglio M, Parri-
nello M (2015) Kinetics of protein–ligand
unbinding: predicting pathways, rates, and
rate-limiting steps. Proc Natl Acad Sci U S A
112(5):E386–E391.
https://doi.org/10.
1073/pnas.1424461112
45. Tiwary P, Mondal J, Morrone JA, Berne BJ
(2015) Role of water and steric constraints in
the kinetics of cavity–ligand unbinding. Proc
Natl Acad Sci U S A 112(39):12015–12019.
https://doi.org/10.1073/pnas.
1516652112
46. Wang Y, Martins JM, Lindorff-Larsen K
(2017) Biomolecular conformational changes
and ligand binding: from kinetics to thermo-
dynamics.
Chem
Sci
8(9):6466–6473.
https://doi.org/10.1039/C7SC01627A
47. Sprenger
KG,
Pfaendtner
J
(2016)
Chapter Sixteen - Using molecular simulation
to study biocatalysis in ionic liquids. In: Gre-
gory AV (ed) Methods in enzymology, vol
577. Academic, London, pp 419–441
48. Wang Y, Valsson O, Tiwary P, Parrinello M,
Lindorff-Larsen K (2018) Frequency adaptive
metadynamics for the calculation of rare-
event kinetics. J Chem Phys 149(7):072309.
https://doi.org/10.1063/1.5024679
49. Camilloni
C,
Cavalli
A, Vendruscolo
M
(2013)
Replica-averaged
metadynamics.
J
Chem Theory Comput 9(12):5610–5617.
https://doi.org/10.1021/ct4006272
50. White AD, Voth GA (2014) Efﬁcient and
minimal method to bias molecular simula-
tions with experimental data. J Chem Theory
Comput 10(8):3023–3030. https://doi.org/
10.1021/ct500320c
51. White AD, Dama JF, Voth GA (2015)
Designing free energy surfaces that match
experimental
data
with
metadynamics.
J
Chem Theory Comput 11(6):2451–2460.
https://doi.org/10.1021/acs.jctc.5b00178
52. Marinelli F, Faraldo-Go´mez Jose´ D (2015)
Ensemble-biased metadynamics: a molecular
simulation method to sample experimental
distributions.
Biophys
J
108
(12):2779–2782. https://doi.org/10.1016/
j.bpj.2015.05.024
53. Gil-Ley A, Bottaro S, Bussi G (2016) Empiri-
cal corrections to the amber RNA force ﬁeld
with target metadynamics. J Chem Theory
Comput
12(6):2790–2798.
https://doi.
org/10.1021/acs.jctc.6b00299
54. Bonomi M, Camilloni C, Vendruscolo M
(2016)
Metadynamic
metainference:
enhanced
sampling
of
the
metainference
ensemble
using
metadynamics.
Sci
Rep
6:31232.
https://doi.org/10.1038/
srep31232
55. Albesa-Jove D, Romero-Garcia J, Sancho-
Vaello E, Contreras FX, Rodrigo-Unzueta A,
Comino N, Carreras-Gonzalez A, Arrasate P,
Urresti S, Biarnes X, Planas A, Guerin ME
(2017) Structural snapshots and loop dynam-
ics along the catalytic cycle of glycosyltransfer-
ase GpgS. Structure 25(7):1034. https://doi.
org/10.1016/j.str.2017.05.009
56. Ardevol
A,
Iglesias-Fernandez
J,
Rojas-
Cervellera V, Rovira C (2016) The reaction
mechanism of retaining glycosyltransferases.
Biochem Soc Trans 44:51–60. https://doi.
org/10.1042/bst20150177
Metadynamics in Biomolecular Simulations
197

57. Binette V, Cote S, Mousseau N (2016) Free-
energy landscape of the amino-terminal frag-
ment of Huntingtin in aqueous solution. Bio-
phys J 110(5):1075–1088. https://doi.org/
10.1016/j.bpj.2016.01.015
58. Bonetti D, Camilloni C, Visconti L, Longhi S,
Brunori M, Vendruscolo M, Gianni S (2016)
Identiﬁcation and structural characterization
of an intermediate in the folding of the mea-
sles virus X domain. J Biol Chem 291
(20):10886.
https://doi.org/10.1074/jbc.
M116.721126
59. Brandt AML, Batista PR, Souza-Silva F, Alves
CR, Caffarena ER (2016) Exploring the
unbinding of Leishmania (L.) amazonensis
CPB derived-epitopes from H2 MHC class I
proteins. Proteins 84(4):473–487. https://
doi.org/10.1002/prot.24994
60. Camilloni C, Vendruscolo M (2015) Using
pseudocontact shifts and residual dipolar cou-
plings as exact NMR restraints for the deter-
mination of protein structural ensembles.
Biochemistry
54(51):7470–7476.
https://
doi.org/10.1021/acs.biochem.5b01138
61. Casillas-Ituarte NN, Cruz CHB, Lins RD,
DiBartola
AC,
Howard
J,
Liang
XW,
Hook M, Viana IFT, Sierra-Hernandez MR,
Lower SK (2017) Amino acid polymorphisms
in
the
ﬁbronectin-binding
repeats
of
ﬁbronectin-binding protein A affect bond
strength and ﬁbronectin conformation. J
Biol
Chem 292(21):8797–8810.
https://
doi.org/10.1074/jbc.M117.786012
62. Chow
ML,
Troussicot
L,
Martin
M,
Doumeche
B,
Guilliere
F,
Lancelin
JM
(2016) Predicting and understanding the
enzymatic inhibition of human peroxiredoxin
5 by 4-substituted pyrocatechols by combin-
ing funnel metadynamics, solution NMR, and
steady-state
kinetics.
Biochemistry
55
(24):3469–3480. https://doi.org/10.1021/
acs.biochem.6b00367
63. Comitani F, Melis C, Molteni C (2015) Elu-
cidating ligand binding and channel gating
mechanisms in pentameric ligand-gated ion
channels by atomistic simulations. Biochem
Soc Trans 43:151–156. https://doi.org/10.
1042/bst20140259
64. Cunha RA, Bussi G (2017) Unraveling Mg2
+-RNA binding with atomistic molecular
dynamics. RNA 23(5):628–638. https://doi.
org/10.1261/rna.060079.116
65. D’Agostino T, Salis S, Ceccarelli M (2016) A
kinetic model for molecular diffusion through
pores.
BBA-Biomembranes
1858
(7):1772–1777. https://doi.org/10.1016/j.
bbamem.2016.01.004
66. Darre L, Domene C (2015) Binding of capsa-
icin to the TRPV1 ion channel. Mol Pharm 12
(12):4454–4465. https://doi.org/10.1021/
acs.molpharmaceut.5b00641
67. della Longa S, Arcovito A (2016) A dynamic
picture of the early events in nociceptin bind-
ing to the NOP receptor by metadynamics.
Biophys J 111(6):1203–1213. https://doi.
org/10.1016/j.bpj.2016.07.004
68. Della-Longa S, Arcovito A (2015) Intermedi-
ate states in the binding process of folic acid to
folate receptor alpha: insights by molecular
dynamics
and
metadynamics.
J
Comput
Aided Mol Des 29(1):23–35. https://doi.
org/10.1007/s10822-014-9801-8
69. Deriu MA, Grasso G, Tuszynski JA, Gallo D,
Morbiducci U, Danani A (2016) Josephin
domain structural conformations explored by
metadynamics in essential coordinates. PLoS
Comput Biol 12(1):e1004699. https://doi.
org/10.1371/journal.pcbi.1004699
70. Dore AS, Bortolato A, Hollenstein K, Cheng
RKY, Read RJ, Marshall FH (2017) Decoding
corticotropin-releasing factor receptor type
1 crystal structures. Curr Mol Pharmacol 10
(4):334–344.
https://doi.org/10.2174/
1874467210666170110114727
71. Formoso E, Mujika JI, Grabowski SJ, Lopez
X (2015) Aluminum and its effect in the equi-
librium between folded/unfolded conforma-
tion
of
NADH.
J
Inorg
Biochem
152:139–146.
https://doi.org/10.1016/j.
jinorgbio.2015.08.017
72. Han MZ, Xu J, Ren Y, Li JH (2016) Simula-
tion of coupled folding and binding of an
intrinsically disordered protein in explicit sol-
vent with metadynamics. J Mol Graph Model
68:114–127.
https://doi.org/10.1016/j.
jmgm.2016.06.015
73. Han MZ, Xu J, Ren Y, Li JH (2016) Simula-
tions of ﬂow induced structural transition of
the beta-switch region of glycoprotein Ib
alpha. Biophys Chem 209:9–20. https://doi.
org/10.1016/j.bpc.2015.11.002
74. Heller
GT,
Aprilel
FA,
Bonomi
M,
Camilloni C, De Simone A, Vendruscolo M
(2017) Sequence speciﬁcity in the entropy-
driven binding of a small molecule and a dis-
ordered
peptide.
J
Mol
Biol
429
(18):2772–2779. https://doi.org/10.1016/
j.jmb.2017.07.016
75. Hultqvist G, Aberg E, Camilloni C, Sundell
GN,
Andersson
E,
Dogan
J,
Chi
CN,
Vendruscolo M, Jemth P (2017) Emergence
and evolution of an interaction between
intrinsically
disordered
proteins.
elife
6:
e16059.
https://doi.org/10.7554/eLife.
16059
198
Jim Pfaendtner

76. Iglesias-Fernandez J, Hancock SM, Lee SS,
Khan
M,
Kirkpatrick
J,
Oldham
NJ,
McAuley K, Fordham-Skelton A, Rovira C,
Davis BG (2017) A front-face ‘S(N)i synthase’
engineered from a retaining ‘double-S(N)2’
hydrolase.
Nat
Chem
Biol
13(8):874.
https://doi.org/10.1038/nchembio.2394
77. Isabella VM, Campbell AJ, Manchester J,
Sylvester
M,
Nayar
AS,
Ferguson
KE,
Tommasi R, Miller AA (2015) Toward the
rational design of carbapenem uptake in Pseu-
domonas
aeruginosa.
Chem
Biol
22
(4):535–547.
https://doi.org/10.1016/j.
chembiol.2015.03.018
78. Jana K, Bandyopadhyay T, Ganguly B (2017)
Designed inhibitors with hetero linkers for
gastric proton pump H+,K+-ATPase: steered
molecular dynamics and metadynamics stud-
ies. J Mol Graph Model 78:129–138. https://
doi.org/10.1016/j.jmgm.2017.10.006
79. Jorgensen C, Furini S, Domene C (2016)
Energetics of ion permeation in an open-
activated TRPV1 channel. Biophys J 111
(6):1214–1222. https://doi.org/10.1016/j.
bpj.2016.08.009
80. Kukic P, Leung HTA, Bemporad F, Aprile FA,
Kumita JR, De Simone A, Camilloni C, Ven-
druscolo M (2015) Structure and dynamics of
the integrin LFA-1 I-domain in the inactive
state underlie its inside-out/outside-in signal-
ing and allosteric mechanisms. Structure 23
(4):745–753. https://doi.org/10.1016/j.str.
2014.12.020
81. Kukic P, Lundstrom P, Camilloni C, Evenas J,
Akke M, Vendruscolo M (2016) Structural
insights into the calcium-mediated allosteric
transition in the C-terminal domain of cal-
modulin from nuclear magnetic resonance
measurements.
Biochemistry
55(1):19–28.
https://doi.org/10.1021/acs.biochem.
5b00961
82. Li DC, Liu MS, Ji BH (2015) Mapping the
dynamics landscape of conformational transi-
tions in enzyme: the adenylate kinase case.
Biophys J 109(3):647–660. https://doi.org/
10.1016/j.bpj.2015.06.059
83. Luciani P, de Mendoza AEH, Casalini T,
Lang S, Atrott K, Spalinger MR, Pratsinis A,
Sobek J, Frey-Wagner I, Schumacher J, Ler-
oux JC, Rogler G (2017) Gastroresistant oral
peptide for ﬂuorescence imaging of colonic
inﬂammation.
J
Control
Release
262:118–126.
https://doi.org/10.1016/j.
jconrel.2017.07.024
84. Meloni R, Tiana G (2017) Thermodynamic
and structural effect of urea and guanidine
chloride on the helical and on a hairpin frag-
ment of GB1 from molecular simulations.
Proteins
85(4):753–763.
https://doi.org/
10.1002/prot.25255
85. Mlynsky V, Bussi G (2017) Understanding
in-line probing experiments by modeling
cleavage of nonreactive RNA nucleotides.
RNA
23(5):712–720.
https://doi.org/10.
1261/rna.060442.116
86. Oparin
RD,
Moreau
M,
De
Walle
I,
Paolantoni M, Idrissi A, Kiselev MG (2015)
The interplay between the paracetamol poly-
morphism and its molecular structures dis-
solved in supercritical CO2 in contact with
the solid phase: in situ vibration spectroscopy
and molecular dynamics simulation analysis.
Eur J Pharm Sci 77:48–59. https://doi.org/
10.1016/j.ejps.2015.05.016
87. Panczyk K, Plazinski W (2018) Pyranose ring
puckering in aldopentoses, ketohexoses and
deoxyaldohexoses.
A
molecular
dynamics
study. Carbohydr Res 455:62–70. https://
doi.org/10.1016/j.carres.2017.11.011
88. Pietropaolo A, Pierri CL, Palmieri F, Klingen-
berg M (2016) The switching mechanism of
the mitochondrial ADP/ATP carrier explored
by free-energy landscapes. BBA-Bioenergetics
1857(6):772–781.
https://doi.org/10.
1016/j.bbabio.2016.02.006
89. Pietropaolo A, Satriano C, Strano G, La
Mendola D, Rizzarelli E (2015) Different
zinc(II) complex species and binding modes
at A beta N-terminus drive distinct long range
cross-talks in the A beta monomers. J Inorg
Biochem 153:367–376. https://doi.org/10.
1016/j.jinorgbio.2015.08.013
90. Plazinski W, Drach M (2015) The inﬂuence of
the hexopyranose ring geometry on the con-
formation of glycosidic linkages investigated
using molecular dynamics simulations. Car-
bohydr Res 415:17–27. https://doi.org/10.
1016/j.carres.2015.07.018
91. Rather MA, Basha SH, Bhat IA, Sharma N,
Nandanpawar P, Badhe M, Gireesh-Babu P,
Chaudhari A, Sundaray JK, Sharma R (2017)
Characterization, molecular docking, dynam-
ics simulation and metadynamics of kisspeptin
receptor with kisspeptin. Int J Biol Macromol
101:241–253.
https://doi.org/10.1016/j.
ijbiomac.2017.03.102
92. Roy S, Karmakar T, Rao VSP, Nagappa LK,
Balasubramanian S, Balaram H (2015) Slow
ligand-induced
conformational
switch
increases the catalytic rate in Plasmodium fal-
ciparum
hypoxanthine
guanine
xanthine
phosphoribosyltransferase. Mol BioSyst 11
(5):1410–1424.
https://doi.org/10.1039/
c5mb00136f
93. Saeedi M, Lyubartsev AP, Jalili S (2017)
Anesthetics mechanism on a DMPC lipid
Metadynamics in Biomolecular Simulations
199

membrane model: insights from molecular
dynamics
simulations.
Biophys
Chem
226:1–13.
https://doi.org/10.1016/j.bpc.
2017.03.006
94. Shang Y, Yeatman HR, Provasi D, Alt A,
Christopoulos
A,
Canals
M,
Filizola
M
(2016) Proposed mode of binding and action
of positive allosteric modulators at opioid
receptors.
ACS
Chem
Biol
11
(5):1220–1229.
https://doi.org/10.1021/
acschembio.5b00712
95. Sharma N, Sonavane U, Joshi R (2017) Dif-
ferentiating the pre-hydrolysis states of wild-
type and A59G mutant HRas: an insight
through
MD
simulations.
Comput
Biol
Chem
69:96–109.
https://doi.org/10.
1016/j.compbiolchem.2017.05.008
96. Shrestha P, Wereszczynski J (2016) Discern-
ing the catalytic mechanism of Staphylococcus
aureus sortase A with QM/MM free energy
calculations. J Mol Graph Model 67:33–43.
https://doi.org/10.1016/j.jmgm.2016.04.
006
97. Singh R, Bansal R, Rathore AS, Goel G
(2017) Equilibrium ensembles for insulin
folding from bias-exchange metadynamics.
Biophys J 112(8):1571–1585. https://doi.
org/10.1016/j.bpj.2017.03.015
98. Timmers L, Neto AMS, Montalvao RW,
Basso LA, Santos DS, de Souza ON (2017)
EPSP synthase ﬂexibility is determinant to its
function: computational molecular dynamics
and metadynamics studies. J Mol Model 23
(7):197. https://doi.org/10.1007/s00894-
017-3372-2
99. Wang J, Sun LF, Cui WW, Zhao WS, Ma XF,
Li B, Liu Y, Yang Y, Hu YM, Huang LD,
Cheng XY, Li LY, Lu XY, Tian Y, Yu Y
(2017) Intersubunit physical couplings fos-
tered by the left ﬂipper domain facilitate chan-
nel opening of P2X4 receptors. J Biol Chem
292(18):7619–7635.
https://doi.org/10.
1074/jbc.M116.771121
100. Wang Y, Papaleo E, Lindorff-Larsen K (2016)
Mapping transiently formed and sparsely
populated
conformations
on
a
complex
energy landscape. elife 5:e17505. https://
doi.org/10.7554/elife.17505
101. Yang C, Kulkarni M, Lim M, Pak Y (2017) In
silico direct folding of thrombin-binding
aptamer
G-quadruplex
at
all-atom
level.
Nucleic
Acids
Res
45(22):12648–12656.
https://doi.org/10.1093/nar/gkx1079
102. Zhang RT, Erler J, Langowski J (2017) His-
tone acetylation regulates chromatin accessi-
bility: role of H4K16 in inter-nucleosome
Interaction.
Biophys
J
112(3):450–459.
https://doi.org/10.1016/j.bpj.2016.11.
015
103. Zhao HC, Palencia A, Seiradake E, Ghaemi Z,
Cusack S, Luthey-Schulten Z, Martinis S
(2015) Analysis of the resistance mechanism
of a benzoxaborole inhibitor reveals insight
into
the
leucyl-tRNA
synthetase
editing
mechanism.
ACS
Chem
Biol
10
(10):2277–2285. https://doi.org/10.1021/
acschembio.5b00291
104. Laio A, Rodriguez-Fortea A, Gervasio FL,
Ceccarelli M, Parrinello M (2005) Assessing
the accuracy of metadynamics. J Phys Chem B
109(14):6714–6721.
https://doi.org/10.
1021/jp045424k
105. Baker M, Penny D (2016) Is there a repro-
ducibility crisis? Nature 533:452
106. Prakash A, Baer MD, Mundy CJ, Pfaendtner J
(2018) Peptoid backbone ﬂexibility dictates
its interaction with water and surfaces: a
molecular dynamics investigation. Biomacro-
molecules. https://doi.org/10.1021/acs.bio
mac.7b01813
200
Jim Pfaendtner

Chapter 9
Protein–Ligand Binding Free Energy Calculations with FEP+
Lingle Wang, Jennifer Chambers, and Robert Abel
Abstract
Accurate and reliable calculation of protein–ligand binding free energy is of central importance in compu-
tational biophysics and structure-based drug design. Among the various methods to calculate protein–li-
gand binding afﬁnities, alchemical free energy perturbation (FEP) calculations performed by way of
explicitly solvated molecular dynamics simulations (FEP/MD) provide a thermodynamically rigorous and
complete description of the binding event and should in turn yield highly accurate predictions. Although
the original theory of FEP was proposed more than 60 years ago, subsequent applications of FEP to
compute protein–ligand binding free energies in the context of drug discovery projects over much of that
time period was sporadic and generally unsuccessful. This was mainly due to the limited accuracy of the
available force ﬁelds, inadequate sampling of the protein–ligand conformational space, complexity of
simulation set up and analysis, and the large computational resources required to pursue such calculations.
Over the past few years, there have been advances in computing power, classical force ﬁeld accuracy,
enhanced sampling algorithms, and simulation setup. This has led to newer FEP implementations such as
the FEP+ technology developed by Schro¨dinger Inc., which has enabled accurate and reliable calculations
of protein–ligand binding free energies and positioned free energy calculations to play a guiding role in
small-molecule drug discovery. In this chapter, we outline the methodological advances in FEP+, including
the OPLS3 force ﬁelds, the REST2 (Replica Exchange with Solute Tempering) enhanced sampling, the
incorporation of REST2 sampling with conventional FEP (Free Energy Perturbation) through FEP/REST,
and the advanced simulation setup and data analysis. The validation of FEP+ method in retrospective
studies and the prospective applications in drug discovery projects are also discussed. We then present the
recent extension of FEP+ method to handle challenging perturbations, including core-hopping transfor-
mations, macrocycle modiﬁcations, and reversible covalent inhibitor optimization. The limitations and
pitfalls of the current FEP+ methodology and the best practices in real applications are also examined.
Key words Protein–ligand binding, Free energy perturbation, FEP+, OPLS3, REST2
1
Introduction
Many important biological processes depend on protein–ligand
binding events. For example, the GPCR (G protein-coupled recep-
tor) activation process is triggered by the binding of the endoge-
nous ligand to the GPCR and transduced following binding
between the GPCR and G protein [1]. The neural transmission
process depends on the binding between the neural transmitter and
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_9, © Springer Science+Business Media, LLC, part of Springer Nature 2019
201

neural transmitter receptor [2, 3]. The ligand-gated ion channel
relies on the binding of a chemical messenger molecule to open the
channel and allow ions to pass through the cell membrane [3].
Protein–ligand binding is also central to pharmaceutical activ-
ity. Small-molecule drugs achieve their therapeutic effects by bind-
ing to their target proteins. Some ligands simply block or inhibit
target protein function, while others induce protein conforma-
tional changes to modulate the downstream cellular signaling path-
ways. In both cases, the efﬁcacies of the drugs are dependent on the
magnitudes of the binding afﬁnities of ligands to their target recep-
tors. A primary objective of small-molecule drug discovery projects
has thus been to design tight-binding ligands while maintaining the
other ligand properties required for safety and biological efﬁcacy.
Therefore, accurate and reliable calculation of protein–ligand bind-
ing afﬁnities is of central importance in computational biophysics
and structure-based drug discovery [4–8].
Protein–ligand binding is a complex process with many factors
contributing to the binding free energy. These include the direct
interaction between the protein and the ligand, the desolvation of
the protein and the ligand, the protein and ligand strain energies
associated with adopting bioactive conformations, and the change
in the conﬁgurational entropies of the protein and the ligand upon
binding. Over the past few decades, a variety of methods have been
proposed and developed to calculate protein–ligand binding free
energies with different tradeoffs between speed and accuracy. There
are fast end-point methods, such as empirical scoring functions
primarily
used
for
virtual
screening,
molecular
mechanics/
generalized Born surface area (MM/GBSA) or Poisson-Boltzmann
(MM/PBSA) methods based on implicit solvent models, and more
rigorous free energy perturbation (FEP) and thermodynamic inte-
gration (TI) methods based on statistically mechanically rigorous
post
processing
of
explicitly
solvated
molecular
dynamics
(MD) simulations. The more intensive methods are expected to
provide a thermodynamically complete description of the binding
event [4–7, 9–15].
Although the original theory of FEP has been known by more
than 60 years, [16] subsequent applications of FEP for protein–li-
gand binding free energy calculations in drug discovery projects
had been generally limited and were not very successful for much of
that time period. Major reasons blocking effective deployment of
FEP in drug discovery applications in the past included the follow-
ing: (1) the poor accuracy of the free energy calculations due to the
inadequate sampling of the relevant protein–ligand conformational
space and the limited accuracy of available protein and small-
molecule force ﬁelds; (2) the complexity of the simulation setup
and data analysis; and (3) the large computational cost associated
with the calculations. Combined, these pose a great challenge to
202
Lingle Wang et al.

the delivery of reliable results within the timeline needed to posi-
tively impact discovery projects.
Over the past few years, multiple recent improvements in com-
puting power, classical force ﬁeld accuracy, enhanced sampling
methods, and simulation setup have enabled accurate and reliable
FEP calculations of protein–ligand binding free energies [17, 18],
and position free energy calculations to play a guiding role in small-
molecule drug discovery. In this chapter, we focus on a particular
FEP implementation, FEP+, which is beginning to see widespread
use in the pharmaceutical industry [19–27].
First, we will review the crucial technology advances enabling
the success of FEP+ in an industrial drug discovery setting, includ-
ing the OPLS3 force ﬁelds [28], the REST2 (Replica Exchange
with Solute Tempering) enhanced sampling methodology [29, 30],
the incorporation of REST2 sampling with conventional FEP (Free
Energy Perturbation) through FEP/REST [31], and advanced
simulation setup and data analysis [5, 17]. Next, we will review
the validation and use of FEP+ in drug discovery projects. Third,
we will discuss the recent extension of FEP+ method to handle
more challenging types of ligands, including core-hopping trans-
formations [32], macrocycle modiﬁcations [33], and reversible
covalent inhibitor optimization [26]. Lastly, we will extensively
discuss the limitations of the current methodology and best prac-
tices for FEP+.
1.1
Alchemical FEP
Methodology
for Rigorous
Protein–Ligand
Binding Free Energy
Calculation
The primary goal of computer-aided drug design (CADD) is to
accurately predict protein–ligand free energies of binding. How-
ever, calculating the absolute free energy of protein–ligand binding
is a profoundly challenging task requiring extensive sampling of
protein and ligand conformational space. Fortunately, in many
drug discovery projects, it is often sufﬁcient to estimate the differ-
ence of the binding free energy between two structurally related
ligands, rather than attempt to determine the absolute binding free
energies of the two ligands, to help determine which of the two
compounds to prioritize for synthesis. When considering the pro-
cesses involved in calculating the difference in the free energy of
two ligand-binding events, two paths can be envisioned as depicted
in Fig. 1. While calculating the difference in free energy between
the two ligands is often viewed as the difference between path 1 and
path 2, it can also be the difference between path A and path B. As
this is a thermodynamic process, the free energy difference between
the vertical and horizontal paths is equivalent. Additionally, while
the vertical paths are difﬁcult to converge, calculating the horizon-
tal paths is feasible by calculating the free energy difference to
mutate from the ﬁrst ligand to the second in different environments
(Fig. 1).
There are a number of different methods to calculate the free
energy difference between two closely related thermodynamic
Binding Free Energy Calculations
203

states, including the Zwanzig exponential average (also called free
energy perturbation, FEP) [16], thermodynamic integration
(TI) [9], λ dynamics [34], and nonequilibrium Jarzynski equations
[35]. These methods rely on an atomistic analysis of the energy
difference between two similar compounds, transitioning between
the compounds either by a chemical or by an alchemical route. The
relative binding free energy calculations between two ligands in
FEP+ employ an alchemical methodology, meaning that the bind-
ing process of the ligand is simulated by transforming the initial
ligand state into the ﬁnal state via nonphysical intermediate states.
Intermediate states with dummy atoms may not represent realistic
chemical states, but this allows the calculation to be achieved in a
fraction of the time that directly simulates the binding/unbinding
process of the ligands would require [36]. This transformation is
done over a series of steps, termed lambda windows, with the ﬁrst
lambda window corresponding the initial ligand, and the last
lambda window corresponding to the second ligand (Fig. 2).
The ﬁrst proposed method for rigorous relative free energy
calculation discussed herein is based on the Zwanzig equation,
which calculates the free energy difference between two systems
with the same number of particles and different potential energies
using the following formula [16]:
ΔF ¼ F 1  F 0 ¼ kT ln Q 1=Q 0


¼ kT < exp βΔU
ð
Þ>0
where β ¼ 1/kT, ΔU ¼ U1(x)  U0(x) is the difference in potential
and the average is over
the ensemble of the initial state
corresponding to system with potential energy U0(x). Q is the
partition function Qi ¼
Ð
dΓ exp (βUi). The above equation
can be easily derived as Q1 can be written as:
Fig. 1 The thermodynamic cycle used for relative protein–ligand binding free
energy calculations. The relative binding free energy between ligand 1 and
ligand 2 can be rigorously calculated from the free energy difference to
transform from ligand 1 to ligand 2 in the binding pocket versus that in bulk
solution. (Reproduced from ref. 5)
204
Lingle Wang et al.

Q 1 ¼
ð
dΓexp
 
 β½ðU 1  U 0Þ þ U 0
!
¼
ð
dΓexpðβΔU ÞexpðβU 0Þ
Similarly, the free energy difference can also be written in terms
of an average over the ensemble of the ﬁnal state:
ΔF ¼ F 1  F 0 ¼ kT ln Q 0=Q 1


¼ kT < exp βΔU
ð
Þ>1
When simulations are done for both the initial state U0(x) and
the ﬁnal state U1(x), the two formulas might give disagreeing
estimates of the free energy difference between the two systems.
The Bennett Acceptance Ratio (BAR) method [37] addresses this
outcome by combining data from both simulations to give a best
estimate of the free energy difference with minimized variance.
Using BAR, an imaginary intermediate state with potential energy
U∗(x) is created and the free energy difference between U0(x) and
U∗(x) is calculated using the data sampled from U0(x). Then, the
free energy difference between U1(x) and U∗(x), using the data
sampled from U1(x), is calculated and the sum of these values gives
the free energy difference between the two states. By minimizing
the variance of the calculated free energy, BAR determines the
optimal potential for the alchemical state and the free energy differ-
ence is obtained via the iterative solution to the following two
equations, where N0 and N1 are the number of uncorrelated data
points sampled from U0 and U1 [37, 38]:
Fig. 2 The free energy difference to transform from the ﬁrst ligand to the second
ligand in the binding pocket or bulk water. A number of intermediate states are
simulated together with the physical end states. The free energy difference
between neighboring states is calculated through the BAR method, and the sum
of free energy between neighboring states gives the free energy of transforma-
tion. (Adapted from ref. 5)
Binding Free Energy Calculations
205

ΔF BAR ¼ 1
β ln
X
N 1
i¼1
f xi
ð
Þ
X
N 0
i¼1
f xi
ð
Þ
þ C  1
β ln N 1
N 0
C ¼ ΔF BAR þ 1
β ln N 1
N 0
with the error associated with this value estimated by:
σ2 ΔF BAR


¼
1
N 0β
< f 2 x
ð Þ>0
< f x
ð Þ>20
 1


þ
1
N 1β
< f 2 x
ð
Þ>1
< f x
ð
Þ>21
 1


where f(x) is the Fermi function:
f x
ð Þ ¼
1
1 þ exp x
ð Þ
x ¼ β ΔU  C
ð
Þ
The above formula is derived in the NVT ensemble, and the
difference in free energy between two compounds using the BAR
method in NPT ensemble, ΔG, can be similarly calculated.
1.2
Challenges
in Achieving Highly
Accurate and Reliable
Protein–Ligand
Binding Free Energy
Calculations
Despite the original Zwanzig equation being published more than
60 years ago, [11, 16] FEP has only recently been able to be put to
large-scale use in drug design projects [4, 17, 25, 39–47]. Several
long-standing challenges had to be overcome to enable FEP calcu-
lations to efﬁciently and accurately calculate protein–ligand binding
free energies. First, accurate classical mechanics force ﬁelds for
proteins and drug-like small molecules needed to be developed, as
it is crucial to have a robust and comprehensive description of the
interactions, energies, and movements of the atoms for accurate
FEP calculations [28, 48–56]. Second, efﬁcient sampling of protein
and ligand conformational phase space during the alchemical trans-
formation process is also required for accurate FEP calculations.
The complexity of the potential energy surface of biological mole-
cules like proteins and drug-like ligands (which have many minima
separated by high-energy barriers) leads to brute force MC or MD
simulations not being able to sample the conformational space
adequately, which in turn will lead to pathological dependence of
the FEP calculation results on the starting geometries of the protein
and
ligands
used
to
initialize
the
calculations
[29,
30,
57–59]. Lastly, for FEP to enable researchers to triage and priori-
tize compounds in a drug discovery project, error estimates of the
calculated free energies must also be included [57, 60], calculation
setup and analysis must be straightforward and highly automated
[17, 61], and calculation throughput must greatly exceed wet-lab
chemistry. Excitingly, several key technology advances have largely
addressed these challenges, as described in the next section.
206
Lingle Wang et al.

2
FEP+ Approach to Address These Challenges
2.1
OPLS3 Force
Field
Originally based on the OPLS force ﬁeld developed by the Jorgen-
sen lab [48, 49, 62], the OPLS3 force ﬁeld [28] has achieved 95%
coverage of small-molecule torsion parameters for drug-like chem-
ical space, which is much broader than other commonly used force
ﬁelds, such as MMFF [63]. Additionally, the Force Field Builder
tool enables parameterization via QM calculations for molecular
motifs that are not described by OPLS3.
2.2
FEP/REST
Enhanced Sampling
It is difﬁcult to converge explicit solvent simulations to an accept-
able precision, while maintaining a tractable calculation time. FEP+
uses the FEP/REST enhanced sampling method to intensify the
sampling of protein or ligand local structural rearrangement
[29–31] enabling convergence to be achieved in a relatively short
5 ns simulation time. This method was based on REST2 [30], a
Hamiltonian replica exchange method where only the region sur-
rounding the protein binding pocket is “heated up,” while the rest
of the system stays “cold,” achieving a much more efﬁcient replica
exchange than the commonly used temperature replica exchange
method. During the alchemical transformation from the initial state
to the ﬁnal state, the effective temperature of the hot region is
gradually increased from T0 at the beginning of the transformation
to Th for the middle lambda window, and then gradually decreased
to T0 for the ﬁnal state [31]. The hot region’s effective temperature
is achieved by scaling the Hamiltonian and exchanging of conﬁg-
urations are attempted between neighboring lambda windows.
The hot region in FEP+ for protein–ligand-binding free energy
calculations includes the part of the ligands that are alchemically
transformed in the simulation and may also include protein residues
important to ligand binding [57]. The rest region is determined
using an automated algorithm, enabling quick and uniform selec-
tion. Using the REST2 enhanced sampling method, FEP/REST
achieves the efﬁcient sampling of ligand conformations and/or
protein residues in the proximity of the binding pocket.
2.3
GPU
Implementation
The advent of graphics processing units (GPUs) allows FEP calcu-
lations to run roughly two orders of magnitude faster than on a
traditional central processing unit (CPU) [17, 64, 65]. This trans-
lates into a >10 cost/performance improvement, allowing a
typical FEP calculation involving ~6000 atoms to complete four
perturbations in a day. On this scale, it is possible to evaluate many
thousands of compounds a year using computing resources that are
commonly available at both commercial and academic institutions,
where in contrast it would be unusual for more than 1000 com-
pounds per year to be synthesized in a wet-lab during the lead
optimization phase of a drug discovery project.
Binding Free Energy Calculations
207

2.4
Cycle Closure
Algorithm for Robust
Error Estimates
Error estimates for FEP calculations are important, particularly in a
prospective drug discovery project, to enable researchers to inter-
pret results and make decisions with conﬁdence. FEP+ uses the
cycle closure method [57, 66] to assess the convergence of the
simulations and to estimate the sampling error. In a simple exam-
ple, with a set of three ligands (A, B, and C), the relative binding
free energy of ligand A and B is F exp
AB ¼ F exp
A
 F exp
B
and, as free
energy is a thermodynamic property, F exp
AB þ F exp
BC þ F exp
CA ¼ 0, that
is, the free energy is a state function. Convergence errors associated
with calculated free energy values often mean that BAR free energy
differences and experimental free energy differences are not equal,
and sampling errors in the free energy estimates for the three edges
will result in hysteresis, that is, F BAR
AB
þ F BAR
BC þ F BAR
CA
6¼ 0. (The
deviation from 0 of the sum of the BAR free energy differences
along a closed thermodynamic cycle is called the hysteresis.) This
sampling error can stem from the free energy estimator or incom-
plete sampling of the phase space (i.e., the protein/ligand are
trapped in a local minimum). The cycle closure algorithm uses the
maximum likelihood statistical method to give the optimal free
energy estimates for the free energies of all the perturbations, and
the cycle closure corrected free energy between any pair of ligands
does not depend on the paths of how the ligand is traversed in the
perturbation graph. The errors for the free energy estimates are also
approximated by the hysteresis of all closed cycles. Further, the
cycle closure algorithm provides a much more reliable sampling
error estimates than the commonly used BAR error estimates.
2.5
FEP+ Setup
Finally, setup of FEP calculations via FEP+ has been designed to be
as automated and easy to use as possible. In a graphical user
interface (GUI), structures of interest are able to be imported
using several common formats and are immediately analyzed for
liabilities, such as improper ligand preparation or protein prepara-
tion [17]. These liabilities can be addressed from the GUI, and any
adjustments required to be made by the user will be saved. The
ligands are analyzed and perturbation pathways are automatically
generated using a variation of the LOMAP mapping algorithm
[61]. The similarity between two ligands is measured, taking into
account their maximum common substructure (MCS). Com-
pounds with high similarity are connected by edges where each
edge represents two FEP calculations, the ﬁrst calculation perturb-
ing between the two ligands when bound to the protein and the
second perturbing between the two ligands in bulk solution. FEP+
map generation is designed to generate maps with closed cycles and
have at least two paths with fewer than ﬁve edges between any pair
of compounds [17]. Maps are able to be easily manipulated, and
edges can be introduced and deleted interactively by the user.
Information about known binding afﬁnities of some ligands can
also be used to better construct the perturbation graph. The
208
Lingle Wang et al.

automated nature and GUI aspects of FEP+ remove much of the
error-prone manual setup of previous FEP implementations, allow-
ing FEP+ to be used by a broader set of researchers on many
different systems.
3
FEP+ Benchmark Results
3.1
Retrospective
Validation
The FEP+ method has been validated on many different ligands
from a diverse set of drug targets. For example, the results of FEP+
calculations on eight different data sets from diverse targets tested
retrospectively and reported in a recent large-scale benchmark
study are shown in Fig. 3 [17]. The protein structures were taken
from the PDB, prepared using default settings retaining crystallo-
graphic waters, and additional torsional parameters were generated
using the Force Field Builder. The 199 ligands in the dataset were
subjected to 330 FEP perturbations exhibiting a roughly Gaussian
distribution of error between the predicted binding afﬁnity and the
experimental
binding
afﬁnity
with
a
standard
deviation
of
~1.14 kcal/mol (Table 1).
A scatter plot of predicted versus experimental binding shows
that the convergence error for the systems are small and all predic-
tions fall roughly within ~1 kcal/mol from the experimental value
Fig.
3
Correlation
between
FEP-predicted
binding
free
energies
and
experimental data for a retrospective study of eight different systems.
FEP-predicted binding free energies for most of the ligands are within
1.0 kcal/mol of their experimental values, and only 9 of 199 studied ligands
deviate from their experimental free energies by more than 2 kcal/mol.
(Reproduced from ref. 17)
Binding Free Energy Calculations
209

(Fig. 3). In analyzing these data, it is important to note that, even
with the very accurately predicted binding free energies for throm-
bin ligands (RMSE ¼ 0.93 kcal/mol, and MUE ¼ 0.76 kcal/mol),
the R value (correlation coefﬁcient) between the prediction and
experiment obtained is modest, 0.71. This highlights a very impor-
tant point that the correlation coefﬁcient (R or R2) as a metric to
assess the performance of the prediction has its own limitation. R2
value is highly dependent on the dynamic range of the binding
afﬁnities. When the dynamic range of the binding afﬁnity is narrow,
the expected R2 value is very small even for very accurate predic-
tions [67]. By comparison, the RMSE and MUE values are more
instructive statistical metrics that do not depend on the dynamic
range of the data.
These data showed that FEP+ was able to sufﬁciently predict
binding free energy differences across a broad range of targets using
known ligands with experimentally veriﬁed data to warrant pro-
spective study. An additional exciting outcome of this study is that
it demonstrated that relatively large perturbations can be pursued
with FEP+. Previously, much of the FEP literature analyzed small
perturbations, often only a single atom, as it was assumed that a
small change in ligand structure would result in a small change in
the relevant ensemble of states. While this makes sampling less
of an obstacle, effective applications of free energy calculations in
drug discovery projects often require perturbations of a much
larger size. This retrospective study contained ligands that undergo
signiﬁcant chemical changes representing perturbation sizes that
are representative of drug design research, and FEP+ was further
found to be able to reliably compute perturbations of ~10 heavy
atoms [5, 17].
Table 1
Error distribution for all 330 perturbations on the eight drug targets published in Ref. 17
Abs. err. (kcal/mol)
Anticipated percentage (%)
Observed percentage (%)
<0.5
33.9
35.5
<1.0
62.0
63.3
<1.5
81.2
81.5
<2.0
92.1
92.4
<2.5
97.2
96.7
>2.5
2.8
3.3
The distribution is approximately Gaussian with some fattening of the tail of the distribution beyond 2.5 kcal/mol. The
observed percentage is the percentage of FEP perturbations found to be accurate within the speciﬁed absolute error. The
anticipated percentage is the percentage of FEP perturbations that would be expected given an underlying root-mean-
square error of 1.1 kcal/mol and an ideal Gaussian error distribution
210
Lingle Wang et al.

3.2
Applications
in Prospective Studies
The FEP+ method has also been used prospectively in several active
drug discovery projects, and a similar level of high accuracy in the
predicted binding free energies was obtained. We have recently
undertaken a large-scale review of FEP+ accuracy across projects
where FEP+ was used to score the binding free energies of com-
pounds in active drug discovery projects. These data come primarily
from industrial and academic collaborators. As of January 2017,
there were at least 92 distinct applications of FEP+ to score small-
molecule ligands series, both prospectively and retrospectively,
where the number of ligands was sufﬁciently large to make judg-
ments regarding the accuracy of the scoring of the series. This
accumulated data set includes the scoring of more than 3000
ligands where the resulting computed afﬁnity could be directly
compared to the experimental data either prior to or subsequent
to the FEP+ calculations. Key statistics of this large-scale analysis are
presented in Table 2 [5]. The quantitative agreement between the
predicted binding free energies and the experimental data in this
large dataset is in line with our retrospective testing, suggesting
such a high level of accuracy can be reliably obtained in future
projects. An important aspect of this work has been a more precise
clariﬁcation of the domain of applicability of the technology. In
particular, we ﬁnd ideal systems to meet the following criteria:
Table 2
Key statistics of a recent large-scale review of FEP+ scoring accuracy
Total number of projects
92
Total number of ligands
3021
Number of academic collaborations
4
Number of internal projects
26
Number of discovery collaboration
24
Number of industrial projects
38
Number of prospective projects
27
Average RMSE of all projects
1.087 kcal/mol
Median RMSE of all projects
1.000 kcal/mol
Average R2 value of all projects
0.571
Median R2 of all projects
0.62
Average RMSE of prospective projects
1.087 kcal/mol
Median RMSE of prospective projects
1.045 kcal/mol
Average R2 value of prospective projects
0.661
Median R2 value of prospective projects
0.565
FEP+ demonstrated a similarly high level of accuracy in prospective drug discovery projects. (Reproduced from ref. 5)
Binding Free Energy Calculations
211

1. Availability of at least one high-quality crystal structure with
cocrystallized series ligand.
2. A reasonable expectation of a conserved binding mode across
the series.
3. Minimal tautomeric, ionization state, and stereochemistry
uncertainties across the series.
4. High reliability experimental binding data from the same assay
for all compounds.
5. Assay data and crystal structures are for the same protein
construct.
If these criteria are met, we ﬁnd there is a high probability the
FEP calculations will be predictive.
4
Extension of Conventional FEP for More Complex Transformations
4.1
Core Hopping
FEP+
The FEP calculations described above all involve modiﬁcation of a
peripheral group of the ligand. In the simplest cases, a hydrogen
might be converted into a methyl group or a halogen. More com-
plex transformations including adding or deleting a peripheral ring
system can also be readily addressed. These capabilities allow a large
number of interesting candidate molecules to be computationally
evaluated.
However, there are important classes of chemical transforma-
tions that cannot be easily handled by standard FEP protocols
designed for modiﬁcation of peripheral groups. In particular, if
the bond topology of the core of the target molecule differs from
the original molecule such that chemical bonds have to be made or
broken in the core, the most commonly used algorithms for
alchemical transformation are subject to potentially severe system-
atic errors. This is due to the sudden change in the interaction
potential and interaction exclusion lists upon bond formation or
annihilation [32]. An example of this type of perturbation between
a pair of TPSB2 inhibitors is shown in Fig. 4. The initial molecule
has a six-member ring connecting two fragments binding in differ-
ent subpockets of TPSB2 receptor, and in the target molecule, the
six-member ring is transformed into a bridged ring with the intro-
duction of an additional covalent bond [32].
Previous work has shown that in practice, the systematic error
induced by these instabilities is considerable and precludes effective
use in prospective projects, especially so for the transformations of
the greatest interest to drug discovery such as changing the size of
aliphatic rings within the core of a molecule or transforming simple
rings to bridged- or spiro-systems [68]. Examples of such transfor-
mations include transformation from a linear structure to a ring
structure in the core of the molecule (ring opening/closing),
212
Lingle Wang et al.

extending a single ring into a fused ring or bridged ring (ring
extension), and changing the size of a ring in the core of the
molecule (ring size change).
We have recently developed a solution to the numerical insta-
bility problems discussed above, based on the construction of a
“soft bond” potential, which eliminates rapid changes in energetics
when bonds are made or broken [32, 69]. The method has been
tested on a dataset of six pharmaceutically interesting targets taken
from the literature and comprises a total of 18 core modiﬁcations of
various types. In a number of cases, these modiﬁcations resulted in
the synthesis of a clinical candidate starting from a lead compound.
The results of the FEP+ calculations for these systems are compared
with the experiment in Fig. 5, [32] and the RMSE accuracy and
correlation obtained for the core hopping transformations is com-
parable to the accuracy reported for simple R-group transforma-
tions reported in Tables 1 and 2.
Transformations in the core of the molecule can be crucially
important in drug discovery projects for a variety of reasons, includ-
ing direct interactions with the protein, modiﬁcation of ADME/
tox properties without loss of potency, and intellectual property
issues; however, the synthetic effort required for modiﬁcation in
the core can also be quite large, and it is often very difﬁcult to
reliably predict the effects of these modiﬁcations on potency using
simpliﬁed approaches. For these reasons, core hopping (or scaffold
hopping) is in many cases viewed as a high-risk/high-reward strat-
egy to be implemented when a project is experiencing difﬁculties
reaching the targeted endpoints and requires a signiﬁcant change in
direction. An inexpensive computational assay predicting the
effects of core modiﬁcation can potentially alter this situation,
enabling the chemical space of attractive, synthetically accessible
Fig. 4 An example core-hopping transformation between a pair of TPSB2 molecules. The initial molecule has a
six-member ring connecting two fragments binding in different subpockets of TPSB2 receptor. In the target
molecule, the six-member ring is transformed into a bridged ring connecting the same two fragments with the
introduction of an additional covalent bond. Conventional FEP methods cannot be used to accurately model
this type of chemical modiﬁcations. (Reproduced from ref. 32)
Binding Free Energy Calculations
213

cores to be routinely surveyed, with the results guiding the progress
of the project. Such a capability would be valuable in the early
phases of a project (e.g., hit to lead) to late-stage lead optimization.
4.2
Macrocycle FEP
The FEP methods described above are focused on typical small-
molecule drugs, that is, molecules satisfying Lipinski’s rule of
5 with a molecular weight of around or less than 500 Da without
large rings. Another important class of molecules occupying a
unique region in chemical space bridging the gap between typical
drug-like small molecules and large biomolecules is macrocycles.
Due to their unique ability to span a larger binding site surface area
while remaining conformationally restricted than their acyclic
counterparts with similar molecular weights, macrocycles are
emerging as a very important drug class, particularly for targets
that are difﬁcult to modulate by small molecules. In addition,
macrocyclization has been proven to be a very effective way to
modulate potency, selectivity, membrane permeability, and many
other relevant physicochemical properties of the ligands, making it
an attractive strategy in pharmaceutical drug discovery in general.
Macrocycles are generally much more difﬁcult to synthesize
than the corresponding acyclic molecules, and brute force macro-
cyclization rarely leads to improved binding potency. Therefore,
accurate modeling of the free energy change associated with
Fig. 5 Comparison between the Core Hopping FEP+ predicted relative binding
free energies and the experimental data for the six pharmaceutically interesting
drug targets. The Core Hopping FEP+ predicted relatively binding free energies
agree very well with the experimental data, with a root mean square error
(RMSE) of 0.50 kcal/mol and a R2 value of 0.81. (Reproduced from ref. 32)
214
Lingle Wang et al.

structure modiﬁcations on the macrocycles, including modiﬁca-
tions that change the size or chemical composition of the macro-
cycle,
or
transformations from
an
acyclic
molecule
into a
macrocycle, will provide great value in macrocycle drug discovery,
avoiding the synthetic effort wasted on molecules that are unlikely
to meet the targeted binding potency and enabling chemists to
pursue synthetic directions that would be considered as too risky
without computational validation [33].
In macrocycle drug design, the most crucial starting problem is
to determine if the initial linear molecule will maintain or improve
its binding afﬁnity if it is macrocyclized. If so, the next task is to
determine what are the optimal length and chemical composition
of the linker groups that should be used to macrocyclize the linear
molecule. Both the above two design goals require the calculation
of the free energy to form and/or to break a covalent bond along
the macrocycle backbone. In addition, due to macrocycles’ rela-
tively larger sizes as compared to typical small-molecule drugs and
the complexity of the structures resulting from the cyclization
restriction, the commonly employed FEP algorithm will not be
able to efﬁciently sample the accessible conformational space of
macrocycles, leading to severe problems in the calculation of their
binding afﬁnities to their target protein receptors. An example
macrocyclization perturbation between a pair of MTH1 inhibitors
is shown in Fig. 6. The macrocyclization strategy in this system was
successful, leading to a signiﬁcantly improved binding potency.
This is because macrocyclization limited the conformational space
of the macrocycle, resulting in the reduction of entropy loss experi-
enced in protein–ligand binding, which further led to improved
binding potency. Conventional FEP methods cannot be used to
accurately model this type of transformation [33].
We have recently developed a solution to this difﬁculty, which
enables accurate and rigorous free energy calculations for the
macrocycle transformations [33]. The macrocycle FEP method is
Fig. 6 An example of macrocyclization transformation between a pair of MTH1 inhibitors. In this case, the
macrocyclization signiﬁcantly reduces the amount of entropy loss experienced during protein–ligand binding,
leading to much improved binding potency. (Reproduced from ref. 33)
Binding Free Energy Calculations
215

an extension of core-hopping FEP methodology, [32] enabling the
calculation of the free energy change associated with the breaking
or formation of a chemical bond in a macrocycle, and simulta-
neously enhancing the sampling of the macrocycle conformational
space. This is achieved by adopting the same soft bond potential
mentioned above and changing the soft bond parameter so that a
wide range of distances of the soft bond can be sampled in the
intermediate lambda windows [33]. The partially broken soft bond
in intermediate lambda windows effectively removes the cyclization
restriction and greatly reduces the energy barriers between different
macrocycle conformations, leading to efﬁcient sampling of the
macrocycle conformations, which further leads to accurate free
energy calculations.
We have validated the above macrocycle FEP+ method on
seven pharmaceutically interesting data sets taken from recent
drug discovery projects including 33 macrocyclic ligands covering
a diverse chemical space. The results of the FEP+ calculations for
these systems are compared with the experiment in Fig. 7 [33]. The
macrocycle FEP+ calculated binding free energies are in good
agreement with experimental data, with an overall mean unsigned
error (MUE) and root mean square error (RMSE) of 0.68 kcal/
mol and 0.94 kcal/mol, respectively. The same method has been
applied by a pharmaceutical company on a wide range of target
–4
–6
–8
–10
–12
–14
–14
–12
–10
–8
–6
–4
Exp. dG(kcal/mol)
Pred. dG(kcal/mol)
CHK1(2E9P)
CK2(2PVN)
BACE-1(288V)
BACE-1(2015)
MTH1(5ANT)
Hsp90(3RKZ)
Hsp90(3VHA)
Fig. 7 The correlation plot between macrocycle FEP-predicted binding free
energies and experimental data for the 33 macrocycle ligands binding on
seven
pharmaceutically
interesting
drug
targets.
The
macrocycle
FEP-predicted binding free energies agree very well with the experimental
data, with an overall MUE and RMSE of 0.71 kcal/mol and 0.92 kcal/mol,
respectively. (Reproduced from ref. 33)
216
Lingle Wang et al.

classes with macrocycle ligands, and a similar high level of accuracy
is also achieved [24, 25].
4.3
Reversible
Covalent Inhibition FEP
Conventional FEP methods to calculate protein–ligand binding
free energies are focused on ligands that bind noncovalently, that
is, ligands binding to protein through nonbonded electrostatic
interactions and van de Waals dispersion interactions. However,
many important drug molecules form covalent bonds with one or
more residues of the protein upon binding, in addition to forming
other favorable electrostatic and van der Waals interactions. These
are commonly referred to as covalent inhibitors. The commonly
deployed FEP methods cannot be used to calculate the binding free
energies of the covalent inhibitors, since the ligands in the protein-
ligand complexes have different bond topologies than those in the
solvent due to the formation of the covalent linkage with the
protein. For example, a small-molecule inhibitor with a cyano
group as a warhead binding to human cathepsin L receptor can
form a covalent bond with the cysteine residue in the binding
pocket (Fig. 8).
Covalent inhibitors have unique advantages to achieve high
potency as compared to noncovalent ligands because covalent
interactions are usually much stronger than noncovalent interac-
tions. Furthermore, the residue that forms a covalent bond with
covalent ligands might not exist in the relevant off-target proteins,
potentially making the covalent ligands better poised to achieve
selectivity. Due to their unique advantages to achieve high potency
Fig. 8 A small-molecule inhibitor with a cyano warhead that binds to human
cathepsin L receptor and forms a covalent bond with the cysteine residue in the
binding pocket. The covalent bond between the sulfur atom in Cys 25 and the
nitrile carbon atom in the ligand is shown in magenta. (Reproduced from ref. 26)
Binding Free Energy Calculations
217

and selectivity, covalent ligands are often considered for targets that
are difﬁcult to drug by noncovalent small molecules.
There are two important classes of covalent ligands, reversible
covalent ligands and irreversible covalent ligands. For reversible
covalent ligands, the covalent bond formation and breaking
between the ligand warhead and protein residue is reversible on
the time scale of an experimental assay. For these ligands, their
binding afﬁnity is determined by thermodynamics, that is, the free
energy differences among the various states. For irreversible cova-
lent ligands, the covalent bond breaking between the ligand war-
head and the protein residue is sufﬁciently slow that the covalent
bond formation reaction is effectively irreversible on the time scale
of experimental assay. For these ligands, their binding afﬁnities are
time dependent, and the efﬁcacy is determined by kinetic observa-
bles, that is, the rate of the covalent bond formation and the Kon
and Koff to form the prereaction complex.
We have also developed a method in FEP+ to calculate the
binding free energy change for ligand modiﬁcation not expected
to modulate the reactivity of the warhead of reversible covalent
ligands. The thermodynamics of reversible covalent ligand binding
is shown in Fig. 9 [26]. Reversible covalent ligands bind to the
protein through a two-step process. In the ﬁrst step, the ligand
binds to the protein active site due to electrostatic and hydrophobic
interactions, forming a noncovalently bound protein–ligand pre-
reaction complex. During the second step, a chemical reaction
occurs between the warhead of the ligand and a protein residue in
the binding pocket, resulting in the formation of a covalent bond.
If the equilibrium concentration of the prereaction complex is
much lower than that of the covalent complex, which is usually
Fig. 9 The thermodynamic cycle of reversible covalent inhibitor binding. Reversible covalent ligands ﬁrst bind
to the protein forming a noncovalently bound protein–ligand prereaction complex and then forms a covalent
protein–ligand complex through the chemical bond between the warhead of the ligand and a protein residue in
the binding pocket. The binding afﬁnities are determined by the free energy differences among these states.
(Reproduced from ref. 26)
218
Lingle Wang et al.

the case for reversible covalent ligands, the binding afﬁnities of the
ligands are determined by the difference of the chemical potential
of the covalent complex versus the sum of the chemical potentials of
protein and ligand in solvent. Therefore, through the thermody-
namic cycle depicted in Fig. 9, we can calculate the free energy to
mutate from ligand 1 to ligand 2 in the covalent protein–ligand
complex and the free energy to mutate from ligand 1 to ligand 2 in
solvent. By taking the difference of these two free energies, the
relative binding free energy between the two ligands can be rigor-
ously calculated.
Note that, in the above method, we assume that the chemical
potential difference between covalent protein–ligand 1 complex
and covalent protein–ligand 2 complex can be estimated by classical
mechanics force ﬁeld. This is a valid approximation only when the
contribution of covalent bond formation to the chemical potential
is approximately the same for the two ligands, meaning the muta-
tion on the ligands does not affect the reactivity of the warhead
signiﬁcantly. In practical covalent ligand drug discovery projects,
during the stage to optimize the ligand properties by mutating the
chemical groups far away from the warhead, the aforementioned
covalent ligand FEP method can be used to estimate the effect of
these mutations on the ligand-binding afﬁnity.
Covalent ligand FEP+ has been validated in a prospective test-
ing versus other industry standard techniques [26]. In this testing,
the goal was to optimize the binding potency of a covalent lead
compound binding to human cathepsin L (hCal) receptor. The lead
compound had an initial binding potency of 200 nM, as well as a
cyano warhead that formed a covalent bond with the cysteine
residue in the hCal receptor. The test consists of prioritizing
novel substituents of the lead compound on the vector exiting the
S2 pocket with improved binding to the hCatL receptor. From a
library of 3325 fragments, the covalent ligand FEP method
together with three other methods, namely, medicinal chemist
section, manual modeling, and docking, followed by manual ﬁlter-
ing, was each used to select ten building blocks, aiming at improved
binding potency compared with the initial lead compound. The
compounds selected by all four groups were synthesized after the
submission of each selection. The structures of the selected com-
pounds along with their experimental binding afﬁnities are shown
in Table 3 [26]. While eight out of ten compounds selected by
covalent ligand FEP+ bind stronger than the reference lead com-
pound, all the other three methods picked only one out of ten
compounds that were found to bind more potently than the initial
lead compound. Among the total of 36 compounds synthesized
(3 compounds were selected by more than one methods), 9 of
them bound stronger than the lead compound, and 8 out of
these 9 tight binders were from FEP+ selection. From these studies,
it is clear that covalent ligand FEP+ outperformed all other
Binding Free Energy Calculations
219

Table 3
Structures of the selected compounds along with their experimental binding affinities (in nM units)
Medicinal chemist (MC)
Format: ID, 2D
structure (Ki in nM)
Manual modeling
(MM)
Format: ID, 2D
structure (Ki in nM)
Docking + manual
ﬁltering (DOMF)
Format: ID, 2D
structure (Ki in nM)
Docking + FEP+
(FEP) Format: ID, 2D
structure (Ki in nM)
3
(12)
13
(1010)
22
(77)
30
(123)
4
(3020)
3
(12)
13
(1010)
31
(27)
5
(>5100)
14
(217)
23
(671)
3
(12)
6
(1800)
15
(3860)
24
(5100)
32
(1750)
7
(952)
16
(505)
25
a
(>5100)
33
(30)
8
(3500 cis;
>5100 trans)
17
(2790)
20
(1020)
34
(91)
9
(515)
18
(>5100)
26
(411)
35
(77)
10
(>5100)
19
(>5100)
27
(>5100)
36
(1430)
11
(279)
20
(1020)
28
(358)
37
(25)
(continued)
220
Lingle Wang et al.

approaches in prioritizing compounds, demonstrating the poten-
tially large impact FEP+ can provide on covalent ligand lead opti-
mization (Table 3).
5
FEP+ Best Practices
5.1
Structure
Preparation
FEP+ is a physics-based free energy calculation method, and it is
imperative that the best practices are followed to set up and run the
calculations to generate the high-quality predictions. At the current
stage of FEP+ technology development, it is still very challenging
to model signiﬁcant conformational changes of the protein (e.g.,
loop motion) upon ligand transformation. Therefore, it is impor-
tant to identify all available crystal structures of a target and ascer-
tain if there is signiﬁcant conformational change to the binding site
upon ligand binding. This analysis can help with choosing targets
and structures better suited for FEP analysis. Once a structure is
selected, careful inspection and preparation of the receptor and
ligands are critical to the success of a FEP+ calculation. Typically,
raw crystallographic data of hydrogens, partial charges, side chains,
or even loop regions are missing. A complete structure is important
as chain breaks in or near the active site increase the likelihood of
missing or incorrect modeling of important protein–ligand inter-
actions and ﬁne details absent from crystal structures can have a
large impact on results. In order to make these structures suitable
Table 3
(continued)
Medicinal chemist (MC)
Format: ID, 2D
structure (Ki in nM)
Manual modeling
(MM)
Format: ID, 2D
structure (Ki in nM)
Docking + manual
ﬁltering (DOMF)
Format: ID, 2D
structure (Ki in nM)
Docking + FEP+
(FEP) Format: ID, 2D
structure (Ki in nM)
12
b (NA)
21
(>5100)
29
c
(304)
38
d
(167)
The compounds are selected by four different approaches, including covalent ligand FEP+, medicinal chemists’ selection
(MC), manual modeling (MM), and docking followed by manual ﬁltering (DOMF). While eight out of ten compounds
selected by covalent ligand FEP bind stronger than the reference lead compound, all the other three methods picked only
one compound that binds stronger than the lead compound. Afﬁnities for potent compounds are green colored.
(Adapted from ref. 26)
aA methyl on the nitrogen is missing in compound 25 compared to the intended molecule, still maintaining the positive
charge
bCompound 12 could not be synthesized
cCompound 29 is an unintended product but was approved in the DOMF approach before compounds were tested. It
shows high similarity with compound 28
dThe original submission for compound 38 had one more carbon atom in the linker
Binding Free Energy Calculations
221

for FEP+ calculations, missing atoms or loops need to be carefully
modeled into the structure. In addition to this, disulﬁde bridges
should be created, and termini residues capped where needed.
Additionally, protein structures for FEP+ calculations should
include all biologically important components (e.g., cofactor near
the binding site), and biologically irrelevant parts of the structure
should be removed. Water molecules also play an important role
during the course of the simulation; therefore, all crystallographic
water molecules should be included in the structure. For perturba-
tions that change interactions with water molecules in deeply
buried binding pockets, it is easier for buried waters to diffuse out
of the binding pocket than it is for the water to diffuse into the
binding pocket. Therefore, it is better to retain or model that water
into the protein structure than rely on it being introduced during
the course of the short simulation. Once the content of protein
structure is satisfactory, the hydrogen bonding network should be
optimized and a restrained minimization performed to relax the
structure after all the changes are made.
Similarly, ligand structures must also be prepared, particularly
when beginning as a 1D or 2D structure with unstandardized
chemistry. Ligand ﬁles should be converted to 3D structures appro-
priate for FEP+, with the stereochemistry and protonation properly
extrapolated. Modeling the correct protonation state of the ligands
is important and these should be conﬁrmed by more rigorous pKa
calculations if a protonation state is ambiguous. If ligands are
evaluated independently of the protein environment, it is important
to check whether the same protonation state is dominant in the
binding site. Visual inspection of ligands in the binding site is
recommended to check that protonation/tautomeric states are
consistent with the chemical environment.
5.2
Graph Generation
Given inﬁnite sampling, the results of the FEP+ job would not be
sensitive to the initial conformation of the ligands. However, to
achieve convergence and reliable results during the default 5 ns
simulation, two things are crucial. First, the initial conformation of
the ligands to be evaluated must be as close to the experimental
binding mode of the ligand as possible. Second, the common
atoms between two ligands being perturbed must be effectively
co-incident with one another in space. Ideally, the FEP+ project
will have a set of congeneric ligands with at least one high-quality
co-crystal structure. Alignment of the ligand set to the ligand with
the most conﬁdent binding mode information should be per-
formed, with visual inspection done to ensure that conformations
of R-groups off the common core are consistent with known data.
For small to medium perturbations, it may be sufﬁcient to perform
a ligand alignment with visual inspection of the poses to ensure
there are no steric clashes with the protein. Docking ligands with
core constraints may also sufﬁce. For larger changes, initial ligand
222
Lingle Wang et al.

core alignment as above followed by an MM-GBSA sampling of the
ligand R-groups can provide a good initial pose for FEP+. There are
some notable cases where additional evaluation of ligands must be
done, including asymmetrically substituted rings or when the ori-
entation of a substituent is ambiguous. Please see the section on
investigating outliers for more information. Once the protein and
ligand structures are prepared and loaded into the FEP+ program,
the program will also automatically evaluate the prepared structures
to ensure the quality of input structures.
The accurate FEP+ calculation relies on the accurate force ﬁelds
of the proteins and ligands. While OPLS3 has a broad coverage of
chemical space, constant search of novel chemistry in drug discov-
ery programs inevitably produces compounds with torsions not
accurately represented by the default parameters in OPLS3. There-
fore, it is essential to run Force Force Builder to obtain accurate
force ﬁeld parameters for all the ligands before the FEP+ simula-
tions. The Force Field Builder calculations can take several hours
and the torsional parameter ﬁle needs to be saved for use in
FEP+ jobs.
FEP+ simulations calculate the relative binding free energies
between pairs of ligands. In principle, with inﬁnite sampling and
converged simulations, the predicted binding free energies for a set
of ligands should not depend on the perturbation graph topology
(the set of perturbations between pairs of ligands connecting all
ligands together). While the current FEP+ technology can reliably
deal with perturbations with around ten heavy atoms, perturba-
tions between ligands with larger chemical change might not be
feasible to converge in the default 5-ns simulations. Therefore,
some set of perturbation graphs might converge faster than others
in practice. The default perturbation map generated by FEP+ uses
the maximum common substructure between the ligands, consid-
ering the 3D alignment and similarity of the ligands. Connections
are made between structures with high similarity, and the map can
be biased to particular ligands. Biasing to one or two ligands with
known binding afﬁnity is ideal, minimizing the number of steps
needed to traverse from compounds with known afﬁnity to other
idea compounds. Most often, the default graph is good enough to
proceed to the simulations. If the ligands are structurally too dis-
similar, some edges in the default graph might have very low
similarity scores and intermediate molecules might be needed to
speed up the convergence of the simulations. Therefore, after gen-
erating the map, inspect the similarity scores of the edges and add
or delete edges as needed. If a similarity score is below 0.3, consider
adding an intermediate compound, using an analysis of the com-
mon and different parts between the ligands to determine the
optimal structure of the intermediate compound.
Binding Free Energy Calculations
223

6
How to Analyze Results and Investigate Outliers
FEP+ calculations execute a complex workﬂow involving many
steps, and it is important to have a systematic way to assess the
reliability of the calculations. If the Bennett error for a perturbation
is above 0.3 kcal/mol, that perturbation is very likely not reliable,
and additional analysis or simulations might be needed to improve
the convergence of that perturbation. Inspection of the hysteresis
of the edges is also informative, as large hysteresis values in closed
cycles indicate convergence issues in the simulations. Cycles with
severe hysteresis should be analyzed further, and please refer to the
Section 8 on investigating outliers for more information. Once the
quality of the FEP+ results has been established, activity cliffs can be
useful in gaining SAR insight and driving lead optimization. Pre-
dicted relative free energy values can be used to rank-order com-
pounds and prioritize synthesis.
It is important to have a quantitative assessment of the perfor-
mance of FEP+ calculations particularly in prospective studies to
gauge whether the model used in the simulations accurately
describes the physics of the underlying system. We recommend to
use the root-mean-square error (RMSE) and mean-unsigned error
(MUE) values to assess the quality of the results for reasons dis-
cussed earlier (R2 value is highly dependent on the dynamic range
of the afﬁnity). These values are automatically calculated in FEP+
program when the output ﬁle from FEP+ simulations is imported
into the GUI.
7
Discussion and Conclusions
Accurate and reliable calculation of protein–ligand binding free
energies is of central importance in computational biophysics and
has been considered a “holy grail” in computer-aided drug design.
While free energy perturbation methods offer a theoretically rigor-
ous way of calculating protein–ligand binding free energies, previ-
ous deployments of FEP in the past few decades had limited
success. This was mostly driven by the lack of accurate protein
and small-molecule ligand force ﬁelds and the inadequate sampling
of protein–ligand conformational space.
With multiple recent advances in computing power, classical
force ﬁeld accuracy, and enhanced sampling methods, the accuracy
and reliability of protein–ligand binding free energy calculations
have improved signiﬁcantly. Within the FEP+ implementation, key
scientiﬁc advances are included. First, an accurate description of
protein–ligand interaction potentials and their conformational
energetics has been achieved with OPLS3. Second, sampling of
slow motions relevant to protein–ligand binding, including the
224
Lingle Wang et al.

protein residues close to the binding pocket and the ligands them-
selves, has been improved through the increased effective tempera-
ture of the local region in the ligand where an alchemical change is
being performed via FEP/REST. Third, reliable and robust char-
acterization of the errors associated with the free energy calcula-
tions through cycle closure analysis in an automated graphical user
interface has made analysis of FEP+ results straightforward.
Through these multiple improvements, the FEP+ method has
achieved a very high level of accuracy, ~1 kcal/mol, for calculating
protein–ligand binding free energies. This accuracy stemmed from
broad retrospective validations and prospective applications, cover-
ing a broad range of target classes and ligands. Such results have
positioned free energy calculations to play a guiding role in drug
discovery projects.
While the RMSE of the current FEP+ method of ~1 kcal/mol
is sufﬁcient to positively impact the drug discovery project, it still
deviates from the accuracy limit of 0.5 kcal/mol for common
experimental assays. Furthermore, occasionally, there are outliers
in the predictions where the predicted binding free energy differs
from the experimental value by more than 2 kcal/mol. Through
careful evaluation of these outlier cases, we have identiﬁed the
following factors that contribute to poor predictions. The OPLS3
force ﬁelds have high levels of accuracy for proteins and drug-like
small molecules; however, the interactions between transition
metals and proteins/ligands are generally not as robust. Therefore,
for perturbations that change the metal–ligand interactions, the
FEP+ results may not be as reliable. Error can also be introduced
into the FEP+ calculation from water molecules that are deeply
buried in the binding pocket. FEP/REST can efﬁciently sample the
protein side chain motions in the binding pocket, and the ligand
conformational change, orientation, and the translational move-
ments of water molecules are assumed to be fast enough to be
adequately sampled by regular MD simulations. However, the
water molecules in the deeply buried binding pocket may have a
long residence time as the pathway for water molecules to exit has
been blocked by the ligands. In these systems, if a ligand perturba-
tion should push water molecules that are kinetically trapped in the
interior of the protein pocket into bulk solution during the MD
simulations, the accuracy of the FEP+ results for these perturba-
tions will be affected.
Many drug-like compounds contain titratable sites with pKas
close to the pH of the experimental assay. For these compounds,
multiple protonation states coexist both in bulk solution and in the
protein-ligand complexes. Furthermore, the protein environment
may shift the relative population of these protonation states, and
the dominant protonation state of the ligand might be different in
the binding complex compared to that in the bulk solution. Simi-
larly, on the protein side, the protonation state of the protein
Binding Free Energy Calculations
225

residues close to the binding pocket may also change with ligand
modiﬁcations, particularly for residues with pKa values close to
7, such as histidine. Therefore, FEP+ results for these ligands may
have large errors if only one protonation state is modeled in the
simulations. Likewise, some ligands may have multiple tautomeric
states, and errors will occur if only one tautomeric state is modeled
in the simulations.
FEP+ works well for relative binding free energy calculations
between ligands maintaining similar binding mode with the target
receptor. Relatively small induced conformational changes of the
protein residues close to the binding pocket can be effectively
sampled by REST2 enhanced sampling method. Occasionally,
there are cases where a very small modiﬁcation on the ligand,
such as an atom change on a heterocycle, signiﬁcantly changes the
conformations of loops surrounding the binding pocket. In these
cases, the local effective heating through REST2 is not sufﬁcient to
adequately sample large loop conformational changes, leading to
errors in the FEP+ results.
We anticipate these challenges will be addressed with future
methodological improvements, including improvements in OPLS3
force ﬁeld to better represent interactions between transition metals
and proteins/ligands and enhanced sampling of water equilibration
through Grand Canonical Monte Carlo (GCMC). Additionally,
development of constant pH simulations will allow FEP+ to simul-
taneously model all the possible protonation states of the ligands
and proteins. Similarly, the alchemical free energy calculation
results on all possible tautomeric states of the ligands can be
reweighted, based on the relative populations of the tautomeric
states from quantum mechanics calculations. Finally, more efﬁcient
and convergent enhanced sampling method for protein loop
motions relevant to ligand binding and broader coverage on chem-
ical space by the force ﬁeld is underway. We expect the accuracy of
FEP+ calculations will be further improved with these methodo-
logical enhancements, making free energy calculations an integral
component for any structure-based drug discovery platform.
8
Notes
1. Identifying Unconverged Perturbations from a Large Perturba-
tion Graph
If a problematic edge or ligand is identiﬁed, there are a few
possible courses of action. Large hysteresis value could indicate
that an inconsistent binding mode was adopted for a ligand in
one of its edges relative to another, or perhaps that the protein
was unstable in one perturbation. The FEP+ panel can auto-
matically detect the most likely unconverged edges leading to
large
hysteresis.
This
method
to
identify
unconverged
226
Lingle Wang et al.

perturbations is based on an analysis of hysteresis of closed
cycles and the graph topology, and a deeper analysis of the
simulations corresponding to each edge is sometimes needed
to identify the physical basis for the convergence problem. The
unconverged perturbations leading to large hysteresis values
can be visualized in FEP+ panel, and all edges that contribute
to high hysteresis displayed. These unconverged edges could
be removed, if the resulting map still has closed cycles for each
ligand. After ligand/edge removal, check to see that the Pre-
dicted Error is reduced or fewer cycles have large hysteresis.
Another option is to extend the simulation time for the edge in
question, if poor convergence is leading to the large hysteresis
values.
2. Sampling of Protein and Ligand Motions
FEP+ utilizes molecular dynamics simulations to allow ligand
movement in a binding pocket, as the initial compound is
perturbed to the target compound. However, larger groups—
such as bulky ring moieties—will not likely have complete
sampling of rotational space during the timescale of the simu-
lation. As ligand preparation and alignment methods are inde-
pendent of the binding pocket, the orientation of asymmetrical
rings that are generated may not be reﬂective of the best pre-
dicted binding pose. Steric clashes and the relatively short time
scale of the simulation may not allow the ring to change its
orientation during the FEP+ calculation. If the ring conforma-
tion is not known, then it is best to ensure that any FEP+
calculations will completely annihilate the ring as the com-
pound is perturbed from one ligand to another. In this way,
the ring can easily rotate its orientation in the corresponding
dummy atom state, and complete sampling of the ring ﬂipping
can be achieved through efﬁcient replica exchange in FEP+.
This can be achieved by adding in additional intermediates that
do not contain the ring or by using Custom Cores. If FEP+
calculations have already been run, use the torsion angle distri-
bution plots of an FEP+ edge to estimate the extent of the
sampling around the ring of interest. The observed rotamer
states can guide decision-making about whether additional
intermediates or Custom Cores should be used in follow-up
simulations.
Additionally,
for
example,
both
psuedo-
stereoisomers of a triple-substituted ammonium should be
modeled in FEP+ calculations, as this center cannot invert
stereochemistry over the course of the FEP+ simulation.
3. Sampling of Water Molecules
Water molecules trapped in the binding pocket are sometimes
not sampled properly during the course of the FEP+ calcula-
tion. The slow movement of waters entering or exiting a deeply
buried portion of the binding pocket can be a rate-limited step
Binding Free Energy Calculations
227

for convergence. If water sampling in deeply buried binding
pocket causes convergence problems in FEP simulations,
WaterMap can be used to predict the structure of water mole-
cules for each protein–ligand complex. Following the analysis
of WaterMap results, the ligands can be grouped according to
the number of water molecules in the binding pocket and FEP+
applied separately for each group. In addition, grand canonical
Monte Carlo for water deletion/insertion in the binding
pocket that is currently under development may provide useful
placements of waters in deep binding pockets.
4. Tips to Address Unconverged Perturbations
Overall, problematic edges in FEP+ maps are usually caused by
slow degrees of freedom that are not sufﬁciently sampled in the
simulations. Analysis of the Simulation Interaction Diagram
reports or trajectories can help with addressing underlying
issues. For example, there may be slower degrees of freedom
for a ligand that was not sufﬁciently sampled during the default
5-ns simulation. Common situations that cause slower degrees
of freedom include (1) exchange of deeply buried water mole-
cules: (2) ﬂipping of nearby protein residues; (3) ﬂipping of
perturbed R-groups; (4) large-scale protein conformational
change.
Slow degrees of freedom can be alleviated by a few techni-
ques. The ﬁrst is to ensure that all crystallographic waters are
included with a structure to allow buried waters to be ade-
quately sampled. If this has already been done, the REST
region of the perturbation can be modiﬁed to run with addi-
tional protein ﬂexibility and thus improve protein and ligand
sampling efﬁciency. Other troubleshooting options include
performing larger perturbations to enable more room for the
waters to move around in the presence of the smaller ligand,
adding intermediates to force larger perturbations which
would facilitate R-group ﬂipping, or extending edges by run-
ning longer simulations. Finally, divide the series into sub-
groups with the same number of water molecules in the
pocket. This can mitigate the effect of a water molecule being
trapped.
5. Since the initial submission of the chapter, a number of
improvements have been made in FEP+, which include
enhancements to the OPLS3 force ﬁeld to improve torsion
parameter coverage for drug-like small molecules in the new
OPLS3e force ﬁeld. Additionally, GCMC water sampling is
now used by default in the latest release of FEP+, 2019–12.
Finally, charged perturbations—including pKa corrections for
multiple
protonation
and
tautomeric
states—are
now
supported.
228
Lingle Wang et al.

References
1. Kobilka BK (2007) G protein coupled receptor
structure and activation. Biochim Biophys Acta
1768(4):794–807. https://doi.org/10.1016/
j.bbamem.2006.10.021
2. Freund TF, Katona I, Piomelli D (2003) Role
of endogenous cannabinoids in synaptic signal-
ing. Physiol Rev 83(3):1017–1066. https://
doi.org/10.1152/physrev.00004.2003
3. Dale Purves GJA, Fitzpatrick D, Hall WC,
LaMantia A-S, McNamara JO, White LE
(2007) Neuroscience. Sinauer Associates, Sun-
derland, MA
4. Jorgensen WL (2009) Efﬁcient drug lead dis-
covery and optimization. Acc Chem Res 42
(6):724–733
5. Abel R, Wang L, Harder ED, Berne BJ, Fries-
ner RA (2017) Advancing drug discovery
through enhanced free energy calculations.
Acc Chem Res 50(7):1625–1632. https://
doi.org/10.1021/acs.accounts.7b00083
6. Gallicchio E, Levy RM (2011) Advances in all
atom sampling methods for modeling protein-
ligand binding afﬁnities. Curr Opin Struct Biol
21(2):161–166
7. Chodera JD, Mobley DL, Shirts MR, Dixon
RW, Branson K, Pande VS (2011) Alchemical
free energy methods for drug discovery: prog-
ress and challenges. Curr Opin Struct Biol 21
(2):150–160
8. Jorgensen WL (2004) The many roles of com-
putation
in
drug
discovery.
Science
303
(5665):1813–1818
9. Chipot C, Pohorille A (2007) Free energy cal-
culations: theory and applications in chemistry
and biology, vol 86. Springer, Berlin
10. Perez A, Morrone JA, Simmerling C, Dill KA
(2016) Advances in free-energy-based simula-
tions of protein folding and ligand binding.
Curr Opin Struct Biol 36:25–31. https://doi.
org/10.1016/j.sbi.2015.12.002
11. Kollman P (1993) Free energy calculations:
applications to chemical and biochemical phe-
nomena.
Chem
Rev
93(7):2395–2417.
https://doi.org/10.1021/cr00023a004
12. Durrant J, McCammon J (2011) Molecular
dynamics
simulations
and
drug
discovery.
BMC Biol 9(1):1–9
13. Deng Y, Roux B (2009) Computations of stan-
dard binding free energies with molecular
dynamics simulations. J Phys Chem B 113
(8):2234–2346
14. Riniker
S,
Christ
C,
Hansen
H,
Hu¨nenberger P, Oostenbrink C, Steiner D,
van Gunsteren W (2011) Calculation of rela-
tive free energies for ligand-protein binding,
solvation,
and
conformational
transitions
using the GROMOS software. J Phys Chem B
115(46):13570–13577.
https://doi.org/10.
1021/jp204303a
15. Hansen N, van Gunsteren WF (2014) Practical
aspects of free-energy calculations: a review. J
Chem
Theory
Comput
10(7):2632–2647.
https://doi.org/10.1021/ct500161f
16. Zwanzig RW (1954) High-temperature equa-
tion
of
state by
a perturbation
method.
I.
Nonpolar
gases.
J
Chem
Phys
22
(8):1420–1426. https://doi.org/10.1063/1.
1740409
17. Wang L, Wu Y, Deng Y, Kim B, Pierce L,
Krilov G, Lupyan D, Robinson S, Dahlgren
MK, Greenwood J, Romero DL, Masse C,
Knight
JL,
Steinbrecher
T,
Beuming
T,
Damm W, Harder E, Sherman W, Brewer M,
Wester R, Murcko M, Frye L, Farid R, Lin T,
Mobley DL, Jorgensen WL, Berne BJ, Friesner
RA, Abel R (2015) Accurate and reliable pre-
diction of relative ligand binding potency in
prospective drug discovery by way of a modern
free-energy calculation protocol and force ﬁeld.
J Am Chem Soc 137(7):2695–2703
18. Schrodinger Suite 2016 FEP+ (2016) Schro-
dinger Suite 2016 FEP+. Schrodinger L. L. C.,
New York, NY
19. Ford MC, Babaoglu K (2017) Examining the
feasibility of using free energy perturbation
(FEP+) in predicting protein stability. J Chem
Inf
Model
57(6):1276–1285.
https://doi.
org/10.1021/acs.jcim.7b00002
20. Rombouts FJR, Tresadern G, Buijnsters P,
Langlois
X,
Tovar
F,
Steinbrecher
TB,
Vanhoof G, Somers M, Andre´s J-I, Trabanco
AA
(2015)
Pyrido[4,3-e][1,2,4]triazolo
[4,3-a]pyrazines as selective, brain penetrant
phosphodiesterase 2 (PDE2) inhibitors. ACS
Med Chem Lett 6(3):282–286. https://doi.
org/10.1021/ml500463t
21. van Vlijmen H, Desjarlais RL, Mirzadegan T
(2017) Computational chemistry at Janssen. J
Comput
Aided
Mol
Des
31(3):267–273.
https://doi.org/10.1007/s10822-016-9998-
9
22. Ker€anen
H,
Pe´rez-Benito
L,
Ciordia
M,
Delgado F, Steinbrecher TB, Oehlrich D, van
Vlijmen HWT, Trabanco AA, Tresadern G
(2017) Acylguanidine beta secretase 1 inhibi-
tors: a combined experimental and free energy
perturbation study. J Chem Theory Comput
13(3):1439–1453. https://doi.org/10.1021/
acs.jctc.6b01141
Binding Free Energy Calculations
229

23. Ciordia M, Pe´rez-Benito L, Delgado F, Tra-
banco AA, Tresadern G (2016) Application of
free energy perturbation for the design of
BACE1 inhibitors. J Chem Inf Model 56
(9):1856–1871.
https://doi.org/10.1021/
acs.jcim.6b00220
24. Wagner V, Jantz L, Briem H, Sommer K,
Rarey M, Christ CD (2017) Computational
macrocyclization: from de novo macrocycle
generation
to
binding
afﬁnity
estimation.
ChemMedChem 12(22):1866–1872. https://
doi.org/10.1002/cmdc.201700478
25. Abel R, Mondal S, Masse C, Greenwood J,
Harriman G, Ashwell MA, Bhat S, Wester R,
Frye L, Kapeller R, Friesner RA (2017) Accel-
erating drug discovery through tight integra-
tion of expert molecular design and predictive
scoring. Curr Opin Struct Biol 43:38–44.
https://doi.org/10.1016/j.sbi.2016.10.007
26. Kuhn B, Tichy´ M, Wang L, Robinson S, Martin
RE,
Kuglstatter
A,
Benz
J,
Giroud
M,
Schirmeister T, Abel R, Diederich F, Hert J
(2017) Prospective evaluation of free energy
calculations for the prioritization of cathepsin
L inhibitors. J Med Chem 60(6):2485–2497.
https://doi.org/10.1021/acs.jmedchem.
6b01881
27. Hauser K, Negron C, Albanese SK, Ray S,
Steinbrecher T, Abel R, Chodera JD, Wang L
(2018) Predicting resistance of clinical Abl
mutations to targeted kinase inhibitors using
alchemical free-energy calculations. Commun
Biol
1(1):70.
https://doi.org/10.1038/
s42003-018-0075-x
28. Harder
E,
Damm
W,
Maple
J,
Wu
C,
Reboul M, Xiang JY, Wang L, Lupyan D,
Dahlgren MK, Knight JL, Kaus JW, Cerutti
DS, Krilov G, Jorgensen WL, Abel R, Friesner
RA (2016) OPLS3: a force ﬁeld providing
broad coverage of drug-like small molecules
and proteins. J Chem Theory Comput 12
(1):281–296
29. Liu P, Kim B, Friesner RA, Berne BJ (2005)
Replica exchange with solute tempering: a
method for sampling biological systems in
explicit water. Proc Natl Acad Sci U S A 102
(39):13749–13754
30. Wang L, Friesner RA, Berne BJ (2011) Replica
exchange with solute scaling: a more efﬁcient
version of replica exchange with solute temper-
ing
(REST2).
J
Phys
Chem
B
115
(30):9431–9438
31. Wang L, Berne BJ, Friesner RA (2012) On
achieving high accuracy and reliability in the
calculation of relative protein-ligand binding
afﬁnities. Proc Natl Acad Sci U S A 109
(6):1937–1942
32. Wang L, Deng Y, Wu Y, Kim B, LeBard DN,
Wandschneider D, Beachy M, Friesner RA,
Abel R (2017) Accurate modeling of scaffold
hopping transformations in drug discovery. J
Chem Theory Comput 13(1):42–54. https://
doi.org/10.1021/acs.jctc.6b00991
33. Yu HS, Deng Y, Wu Y, Sindhikara D, Rask AR,
Kimura T, Abel R, Wang L (2017) Accurate
and reliable prediction of the binding afﬁnities
of macrocycles to their protein targets. J Chem
Theory Comput 13(12):6290–6300. https://
doi.org/10.1021/acs.jctc.7b00885
34. Knight JL, Brooks CL (2009) λ-Dynamics free
energy simulation methods. J Comput Chem
30(11):1692–1700.
https://doi.org/10.
1002/jcc.21295
35. Jarzynski C (2007) Comparison of far-from-
equilibrium
work
relations.
C
R
Phys
8
(5):495–506.
https://doi.org/10.1016/j.
crhy.2007.04.010
36. Shobana S, Roux B, Andersen OS (2000) Free
energy simulations: thermodynamic reversibil-
ity and variability. J Phys Chem B 104
(21):5179–5190
37. Bennett CH (1976) Efﬁcient estimation of free
energy differences from Monte Carlo data. J
Comput Phys 22(2):245–268
38. Paliwal H, Shirts MR (2011) A benchmark test
set for alchemical free energy transformations
and its use to quantify error in common free
energy methods. J Chem Theory Comput 7
(12):4115–4134.
https://doi.org/10.1021/
ct2003995
39. Lovering
F,
Aevazelis
C,
Chang
J,
Dehnhardt C, Fitz L, Han S, Janz K, Lee J,
Kaila N, McDonald J, Moore W, Moretto A,
Papaioannou N, Richard D, Ryan MS, Wan
Z-K, Thorarensen A (2016) Imidazotriazines:
spleen tyrosine kinase (Syk) inhibitors identi-
ﬁed by free-energy perturbation (FEP). Chem-
MedChem 11(2):217–233. https://doi.org/
10.1002/cmdc.201500333
40. Christ CD, Fox T (2013) Accuracy assessment
and automation of free energy calculations for
drug
design.
J
Chem
Inf
Model
54
(1):108–120.
https://doi.org/10.1021/
ci4004199
41. Steinbrecher TB, Dahlgren M, Cappel D,
Lin T, Wang L, Krilov G, Abel R, Friesner R,
Sherman W (2015) Accurate binding free
energy predictions in fragment optimization. J
Chem Inf Model 55(11):2411–2420. https://
doi.org/10.1021/acs.jcim.5b00538
42. Lenselink EB, Louvel J, Forti AF, van Veldho-
ven JPD, de Vries H, Mulder-Krieger T,
McRobb FM, Negri A, Goose J, Abel R, van
Vlijmen HWT, Wang L, Harder E, Sherman W,
230
Lingle Wang et al.

Ijzerman AP, Beuming T (2016) Predicting
binding afﬁnities for GPCR ligands using free-
energy
perturbation.
ACS
Omega
1
(2):293–304.
https://doi.org/10.1021/
acsomega.6b00086
43. Goldfeld DA, Murphy R, Kim B, Wang L,
Beuming T, Abel R, Friesner RA (2015) Dock-
ing and free energy perturbation studies of
ligand binding in the kappa opioid receptor. J
Phys Chem B 119(3):824–835. https://doi.
org/10.1021/jp5053612
44. Kaus JW, Harder E, Lin T, Abel R, McCam-
mon JA, Wang L (2015) How to deal with
multiple binding poses in alchemical relative
protein–ligand binding free energy calcula-
tions.
J
Chem
Theory
Comput
11
(6):2670–2679.
https://doi.org/10.1021/
acs.jctc.5b00214
45. Mikulskis P, Genheden S, Ryde U (2014) A
large-scale test of free-energy simulation esti-
mates of protein–ligand binding afﬁnities. J
Chem Inf Model 54(10):2794–2806. https://
doi.org/10.1021/ci5004027
46. Clark AJ, Gindin T, Zhang B, Wang L, Abel R,
Murret CS, Xu F, Bao A, Lu NJ, Zhou T,
Kwong PD, Shapiro L, Honig B, Friesner RA
(2017) Free energy perturbation calculation of
relative binding free energy between broadly
neutralizing antibodies and the gp120 glyco-
protein of HIV-1. J Mol Biol 429(7):930–947.
https://doi.org/10.1016/j.jmb.2016.11.021
47. Steinbrecher T, Zhu C, Wang L, Abel R,
Negron C, Pearlman D, Feyfant E, Duan J,
Sherman W (2017) Predicting the effect of
amino acid single-point mutations on protein
stability—large-scale validation of MD-based
relative free energy calculations. J Mol Biol
429(7):948–963. https://doi.org/10.1016/j.
jmb.2016.12.007
48. Jorgensen WL, Tirado-Rives J (1988) The
OPLS [optimized potentials for liquid simula-
tions] potential functions for proteins, energy
minimizations for crystals of cyclic peptides and
crambin. J Am Chem Soc 110(6):1657–1666.
https://doi.org/10.1021/ja00214a001
49. Jorgensen WL, Maxwell DS, Tirado-Rives J
(1996) Development and testing of the OPLS
all-atom force ﬁeld on conformational energet-
ics and properties of organic liquids. J Am
Chem Soc 118(45):11225–11236. https://
doi.org/10.1021/ja9621760
50. Cornell WD, Cieplak P, Bayly CI, Gould IR,
Merz KM, Ferguson DM, Spellmeyer DC,
Fox T, Caldwell JW, Kollman PA (1995) A
second generation force ﬁeld for the simulation
of proteins, nucleic acids, and organic mole-
cules. J Am Chem Soc 117(19):5179–5197.
https://doi.org/10.1021/ja00124a002
51. Cerutti DS, Swope WC, Rice JE, Case DA
(2014) ff14ipq: a self-consistent force ﬁeld for
condensed-phase simulations of proteins. J
Chem Theory Comput 10(10):4515–4534.
https://doi.org/10.1021/ct500643c
52. Lindorff-Larsen
K,
Piana
S,
Palmo
K,
Maragakis P, Klepeis JL, Dror RO, Shaw DE
(2010) Improved side-chain torsion potentials
for the Amber ff99SB protein force ﬁeld. Pro-
teins 78(8):1950–1958. https://doi.org/10.
1002/prot.22711
53. Wang J, Wolf RM, Caldwell JW, Kollman PA,
Case DA (2004) Development and testing of a
general amber force ﬁeld. J Comput Chem 25
(9):1157–1174.
https://doi.org/10.1002/
jcc.20035
54. Best RB, Zhu X, Shim J, Lopes PEM, Mittal J,
Feig M, MacKerell AD (2012) Optimization of
the additive CHARMM all-atom protein force
ﬁeld targeting improved sampling of the back-
bone ϕ, ψ and side-chain χ1 and χ2 dihedral
angles.
J
Chem
Theory
Comput
8
(9):3257–3273.
https://doi.org/10.1021/
ct300400x
55. MacKerell AD, Bashford D, Bellott M, Dun-
brack RL, Evanseck JD, Field MJ, Fischer S,
Gao J, Guo H, Ha S, Joseph-McCarthy D,
Kuchnir L, Kuczera K, Lau FTK, Mattos C,
Michnick S, Ngo T, Nguyen DT, Prodhom B,
Reiher WE, Roux B, Schlenkrich M, Smith JC,
Stote R, Straub J, Watanabe M, Wio´rkiewicz-
Kuczera J, Yin D, Karplus M (1998) All-atom
empirical potential for molecular modeling and
dynamics studies of proteins. J Phys Chem B
102(18):3586–3616.
https://doi.org/10.
1021/jp973084f
56. Schuler LD, Daura X, van Gunsteren WF
(2001) An improved GROMOS96 force ﬁeld
for aliphatic hydrocarbons in the condensed
phase. J Comput Chem 22(11):1205–1218.
https://doi.org/10.1002/jcc.1078
57. Wang L, Deng Y, Knight JL, Wu Y, Kim B,
Sherman W, Shelley JC, Lin T, Abel R (2013)
Modeling
local
structural
rearrangements
using FEP/REST: application to relative bind-
ing afﬁnity predictions of CDK2 inhibitors. J
Chem Theory Comput 9(2):1282–1293
58. Lim NM, Wang L, Abel R, Mobley DL (2016)
Sensitivity in binding free energies due to pro-
tein reorganization. J Chem Theory Comput
12(9):4620–4631. https://doi.org/10.1021/
acs.jctc.6b00532
59. Wang L, Berne BJ (2018) Efﬁcient sampling of
puckering states of monosaccharides through
replica exchange with solute tempering and
bond softening. J Chem Phys 149(7):072306.
https://doi.org/10.1063/1.5024389
Binding Free Energy Calculations
231

60. Pohorille A, Jarzynski C, Chipot C (2010)
Good practices in free-energy calculations. J
Phys Chem B 114(32):10253
61. Liu S, Wu Y, Lin T, Abel R, Redmann JP,
Summa CM, Jaber VR, Lim NM, Mobley DL
(2013) Lead optimization mapper: automating
free energy calculations for lead optimization. J
Comput
Aided
Mol
Des
27(9):755–770.
https://doi.org/10.1007/s10822-013-9678-
y
62. Jorgensen WL, Schyman P (2012) Treatment
of halogen bonding in the OPLS-AA force
ﬁeld: application to potent anti-HIV agents. J
Chem
Theory
Comput
8(10):3895–3901.
https://doi.org/10.1021/ct300180w
63. Halgren
TA, Nachbar
RB
(1996)
Merck
molecular force ﬁeld. IV. Conformational ener-
gies and geometries for MMFF94. J Comput
Chem 17(5–6):587–615. https://doi.org/10.
1002/(SICI)1096-987X(199604)17:5/
6<587::AID-JCC4>3.0.CO;2-Q
64. Salomon-Ferrer R, Go¨tz AW, Poole D, Le
Grand S, Walker RC (2013) Routine microsec-
ond
molecular
dynamics
simulations
with
AMBER on GPUs. 2. Explicit solvent particle
Mesh Ewald. J Chem Theory Comput 9
(9):3878–3888.
https://doi.org/10.1021/
ct400314y
65. Michael Bergdorf SB, Rendleman CA, Shaw
DE (2015) Desmond/GPU performance as
of October 2015. D E Shaw Research Techni-
cal Report DESRES/TR--2015-01
66. Wang L, Lin T, Abel R (2014) Cycle closure
estimation of relative binding afﬁnities and
errors. Patents
67. Brown SP, Muchmore SW, Hajduk PJ (2009)
Healthy skepticism: assessing realistic model
performance.
Drug
Discov
Today
14
(7–8):420–427.
https://doi.org/10.1016/j.
drudis.2009.01.012
68. Liu S, Wang L, Mobley DL (2015) Is ring
breaking feasible in relative binding free energy
calculations?
J
Chem
Inf
Model
55
(4):727–735
69. Abel R, Wang L (2015) Methods and systems
for calculating free energy differences using a
modiﬁed bond stretch potential. United States
Patent
232
Lingle Wang et al.

Chapter 10
Ligand-Binding Calculations with Metadynamics
Davide Provasi
Abstract
All-atom molecular dynamics simulations can capture the dynamic degrees of freedom that characterize
molecular recognition, the knowledge of which constitutes the cornerstone of rational approaches to drug
design and optimization. In particular, enhanced sampling algorithms, such as metadynamics, are powerful
tools to dramatically reduce the computational cost required for a mechanistic description of the binding
process. Here, we describe the essential details characterizing these simulation strategies, focusing on the
critical step of identifying suitable reaction coordinates, as well as on the different analysis algorithms to
estimate binding afﬁnity and residence times. We conclude with a survey of published applications that
provides explicit examples of successful simulations for several targets.
Key words Metadynamics, Molecular dynamics, Collective variables, Free energy, Binding kinetics,
Drug discovery, Ligand binding
1
Introduction
Computational methods in drug discovery campaigns have tradi-
tionally been focused on the prediction of the most stable pose of a
ligand in a complex, along with a (semi-)quantitative estimation of
its stability [1, 2]. With the growth of computational power and the
advancement of simulation algorithms, though, other important
features of the binding process, such as kinetics, have been found to
be amenable to a computational description at the atomistic level
(e.g., [3]). Therefore, due to the renewed awareness that the early
phases of development ought to involve more than the optimiza-
tion of binding afﬁnity, molecular dynamics-based algorithms such
as metadynamics [4, 5], which afford an accurate dynamic descrip-
tion of binding, are attracting considerable interest [6].
Any method based on expensive simulations must acknowledge
that experimental techniques can routinely probe binding afﬁnities
and kinetic properties of ligands with signiﬁcant accuracy and high
throughput. Looking beyond computational cost, though, one
must remember that meaningful computational biophysics is not
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_10, © Springer Science+Business Media, LLC, part of Springer Nature 2019
233

only about getting binding afﬁnities within 1 kcal/mol accuracy, or
rate estimates within a few orders of magnitude from experimental
values, but the crucial task during the lead development process is
also to recapitulate quantitative structure-activity (QSAR) and
structure-kinetics relationships (SKR) and provide insight for opti-
mization. In this respect, the main advantage of physics-based
computational methods is their potential to disentangle the pro-
cesses contributing to the observed endpoints and therefore offer a
potential route for engineering improvements. More generally, the
ambition of computational methods must be to contribute to
enlarging the pool of druggable targets by elucidating recognition
mechanisms and by providing mechanistic insight into experimen-
tal results that don’t report directly about structural and dynamical
details at the atomic level.
In the vast majority of practical cases, several processes (Fig. 1)
contribute to the binding, and, to be meaningful, any mechanistic
insight aimed at rationalization and optimization needs to account
for them. The study of the binding of relatively rigid ligands to
stable, shallow pockets provides excellent testing grounds to com-
pare rigor, reliability, and reproducibility of computational strate-
gies. Unfortunately, though, the successes of computational
protocols on idealized examples are often difﬁcult to generalize to
cases more representative of targets of interest in modern drug
discovery, where multiple intermediate poses (Fig. 1a), deep pockets
with slow desolvation (Fig. 1b), protein ﬂexibility (Fig. 1c, d), and
heterogeneous environment (Fig. 1e) affect the binding process.
One of the great advantages to molecular-dynamics-based
approaches is their potential to seamlessly account for protein
ﬂexibility and for the compounded effects of induced ﬁt and con-
formational selection mechanisms, including the possible emer-
gence of cryptic binding pockets. Not only do these features play
a prominent role in important classes of targets, such as kinases and
G Protein-Coupled Receptors (GPCRs), but most of the main
experimental techniques used to probe structural features, such as
Fig. 1 Typical dynamical processes that may inﬂuence ligand binding. (a) Intermediate metastable ligand
poses, (b) ligand and pocket desolvation, (c) induced-ﬁt binding mechanism, whereby a high-afﬁnity state of
the receptor is reached upon binding, (d) conformational selection, where the ligand binds with different
afﬁnities to two states of the receptor, and (e) competition between membrane-associated, 2D binding, and
3D binding
234
Davide Provasi

X-ray or electron diffraction from crystals, and cryo-electron
microscopy, are unable to capture atomic-level dynamics, and simu-
lations can offer exclusive insights.
Additionally, for targets associated to the cell membrane, such
as channels, transporters, or GPCRs, the complex interplay
between diffusion of the ligands into the membrane and direct
access from the extracellular or intracellular solvent can modulate
the kinetics and the effective concentration [2, 7, 8] of ligands
locally available for binding.
This chapter focuses on approaches based on the metadynamics
algorithm [4, 5] and reviews the speciﬁc details of its application to
ligand binding. Notably, several other promising molecular-
dynamics-based strategies have been proposed and applied to this
important ﬁeld of computational chemistry (see, for instance, [6, 9]
and references therein), but reviewing them is beyond the scope of
this work. Similarly, we refrain from discussing the many general
technical details necessary for the proper use of metadynamics, and
we refer instead the interested reader to one of the several excellent
reviews available in the literature (see, e.g., [10, 11] and Chapter 8
of this book).
The rest of this chapter is organized as follows. Subheading
2 brieﬂy indicates software packages required to perform the simu-
lations and analysis described in the rest of this work. In Subhead-
ing 3.1 we introduce the options available when selecting the
collective variables employed in ligand-binding studies, arguably
the main determinant of a successful simulation. We then discuss
(Subheading 3.2) the main strategies developed to analyze the
simulations, including reweighing of the thermodynamic estimates
and of the kinetic properties of the binding process. Finally (Sub-
heading 3.3), we review a number of signiﬁcant applications and
provide some perspective about computational cost and accuracy of
the results for systems of pharmacological interest. We conclude
(Subheading 4) with a perspective on the current challenges and
future directions, while technical details useful in the practical
application of the techniques described are collected in the Notes
(Subheading 5) at the end of the chapter.
2
Materials
Metadynamics sampling is available in several of the simulation
platforms used in modern computational biophysics, either natively
or through PLUMED [12], a general plugin that implements most
of the methods discussed in this work and can be used, among
others, with GROMACS [13] and OpenMM [14]. Software libraries
developed for Markov models, for instance the popular pyEmma
[15] or MSMBuilder [16] packages, can be used to calculate
time-lagged independent component analysis (TICA, introduced
Ligand Binding with Metadynamics
235

below in Subheading 3.1.5). The same libraries also provide analysis
tools needed for some of the strategies combining metadynamics
with unbiased simulations described in Subheading 3.2.3, like the
estimation of transition matrices and reweighing of multi-ensemble
Markov models through transition-based reweighting analysis
method (TRAM) [17]. The code to implement TICA-metady-
namics [18] and dynamic histogram analysis method extended to
detailed balance (DHAMed) [19] are available from the msultan/
tica_metadynamics and bio-phys/PyDHAMed GitHub reposi-
tories, respectively.
3
Methods
3.1
Reaction
Coordinates for Ligand
Binding
One of the features characterizing standard applications of meta-
dynamics is the need to deﬁne before the simulation appropriate
reaction coordinates, or “collective variables” (CVs), that capture
the slow degrees of freedom of the system and are able to discrimi-
nate the states with biological relevance (see Chapter 8). Unfortu-
nately, we still have a limited understanding of the features of the
binding process, and the eccentricities of each particular ligand-
target pair make it impossible to outline a general recipe to express
the degrees of freedom that provide optimal efﬁciency. In the
following sections, we outline the main approaches used for accel-
erating the dynamics of binding and unbinding processes. While
different choices can obviously be combined based on prior infor-
mation on the ligand and the target, it should be kept in mind that,
unless replica exchange schemes are implemented (see Note 1),
even (semi-)quantitative convergence is very hard to achieve when
more than two to three dimension are used.
3.1.1
Geometric
Descriptors
Natural, albeit likely crude, initial choices for the biasing collective
variables are geometric descriptors (see Fig. 2a) of the relative
position of the ligand with respect to the protein (e.g., distances
between reference points on the ligand, such as the center of mass
of some of its moieties, and on the protein; angles, dihedrals), or
some function thereof (e.g., contact maps). When this approach is
used, one has to keep in mind that most metadynamics ﬂavors are
poorly suited to sample efﬁciently the diffusive region of the phase
space corresponding to the unbound ligand in bulk solvent. In this
case, it is advisable to restrain the region accessible to the ligand
with appropriate constraints, as pioneered ﬁrst in umbrella sam-
pling simulations [20, 21]. A popular implementation of this idea is
achieved using a funnel-shaped restraint [22] that allows the ligand
to sample a broader region close to the binding pocket and restricts
the sampling to a narrow cylinder of radius Rc in the unbound state.
Because of the restraint, the free-energy difference ΔG recon-
structed from the bias does not reﬂect the unbiased probability
difference between the unrestrained states in the binding pocket
236
Davide Provasi

and in the bulk solvent. The free-energy difference must be cor-
rected by a term accounting for the larger phase space available to
the ligand in the absence of the restraint
ΔG
 ¼ ΔG  kBT log πR2
cC



where C
 is the concentration of the standard reference state and
kBT is the thermal energy. It must be emphasized that in the case of
complex binding pathways, such as those in which the ligand has to
undergo obligate coordinated changes in orientation or conforma-
tion, and/or where the binding pocket is deep or cryptic, this
approach might fail to converge unless ad hoc additional collective
variables are accelerated.
3.1.2
Path Collective
Variables
An alternative approach is based on the description of the binding
pathway by path-collective variables [23] (see Fig. 2b). This
approach requires preliminary explorative simulations accelerated
either by coarse metadynamics bias or by non-equilibrium (e.g.,
ratchet-and-pawl [24]) bias potentials. CVs used in this ﬁrst step
need not assume that information about the bound state is known
and can include choices such as the potential energy [25] or surro-
gates for the entropy [26], as well as geometric variables. These
simulations are used to generate reference conformations {Rk}
connecting the initial and ﬁnal states along a one-dimensional
path. Production runs are then performed using the path-collective
variable
s R
ð
Þ ¼
P
kk ed R;Rk
ð
Þ=δ
P
k ed R;Rk
ð
Þ=δ
where d is a metric measuring the proximity in high dimensional
space between the reference conformations Rk and R. In practice,
some caution must be observed when choosing the references and
the length-scale δ (see Notes 2–4).
Fig. 2 Collective variables commonly used in ligand-binding metadynamics simulations. (a) Geometric
descriptors of the ligand-protein relative position and orientation and of protein conformation (b) solvation
of the ligand and/or the binding pocket (c) path-collective variable describing the binding/unbinding pathway
(d) high-dimensional description of the relative position (e.g., contact maps, set of ligand-protein distances)
followed by dimensional reduction using unsupervised machine-learning algorithms
Ligand Binding with Metadynamics
237

3.1.3
Pocket and Ligand
Dewetting
The solvation state of the ligand and of the binding pocket (see
Fig. 2c) is known to constitute one of the crucial steps along the
binding and unbinding pathway. In order to accelerate this rela-
tively slow dynamical relaxation, speciﬁc CVs can be added to the
simulation. A natural choice is represented by the overall coordina-
tion number between the solvent oxygen atoms W and the (polar)
moieties A of the binding pocket (or the ligand):
wA R
ð
Þ ¼
X
i∈A;j∈W
1  rij=r0

n
1  rij=r0

m
Typical values for the parameters of the switching function are
r0 ﬃ0.6 nm, with n ¼ 6 and m ¼ 10. Both protein-drug and
protein-protein interactions can depend on water-mediated con-
tacts, and metadynamics simulations [27] have shown that their
interplay can be crucial for ligand afﬁnity and kinetics in speciﬁc
cases. However, there is no clear understanding of the general
mechanisms through which desolvation and water dynamics inﬂu-
ence the binding and in which cases solvent degrees of freedom
have to be included explicitly in the acceleration.
3.1.4
Target Flexibility
Slow degrees of freedom in the dynamics of the target should be
explicitly included in the CV set. For short ﬂexible regions close to
the binding pocket including a distance between protein residues
can be effective [28, 29], but the speciﬁc nature of each system
makes it impossible to outline a single, generally viable, optimal
solution. More coordinated conformational changes, including in
principle large-scale rearrangements of the target, can be accounted
for by path-collective variables.
3.1.5
Unsupervised
Machine Learning
Approaches
More recently, some strategies based on learning relevant degrees
of freedom of the dynamics from preliminary trajectories have been
proposed [18, 30, 31]. These protocols build on the techniques for
optimal description of structural properties accumulated in the
study of Markov state models and provide strategies to identify
low-dimensional linear combinations of basis functions that repre-
sent the required slow degrees of freedom (see Fig. 2d). Speciﬁcally,
given a set {fi(R)} of predeﬁned functions, that is, “features,” of the
molecular conformation R, we look for the combination(s)
c j R
ð
Þ ¼
X
i
A jð Þ
i f i R
ð
Þ
that optimally describe the binding. The stochastic dynamics of the
system in the phase space identiﬁed by the {cj(R)} is described, via a
master equation, by a transition probability matrix Ω, whose eigen-
vectors and eigenvalues approximate [32] those of the propagator
of the continuous dynamics. Therefore, a low-dimensional descrip-
tion of the dynamics is optimal when a large gap separates the ﬁrst
238
Davide Provasi

s (nontrivial) eigenvalues of Ω from the rest of the spectrum,
corresponding to a clear separation of the slow degrees of freedom
from the faster ones. The ﬁrst approach proposed [31, 33] consists
of running a preliminary metadynamics simulation for an initial,
possibly suboptimal, choice of {Ai}, sampling both bound and
unbound states. While reweighing techniques, described in more
detail in the next section, allow estimating the Boltzmann distribu-
tion of the function cj(R), the kinetics on the sampled trajectories is
biased and cannot therefore be used to estimate the spectrum of Ω.
One practical solution [31] is to invoke the maximum caliber
principle. This amounts to considering the most likely kinetic
model Ω compatible with the steady state probabilities of micro-
states deﬁned by the {cj(R)} and imposing detailed balance, as well
as some additional dynamic constraints (see Note 5). Once the
optimal cj(R) have been determined, a production metadynamics
run is performed.
Two other recently proposed approaches [18, 30] are based on
the fundamental variational principle of conformation dynamics,
which results in the observation that deﬁning the dynamical corre-
lation function as
χii0 τð Þ ¼ f i R tð Þ
ð
Þf i0 R t þ τ
ð
Þ
ð
Þ


the optimal approximation of the propagator eigenfunctions is the
solution of the generalized eigenvalue equation
χii0 τð ÞA jð Þ
i0 ¼ λ jð Þχii0 0
ð ÞA jð Þ
i0
The components cj(R) deﬁned using these coefﬁcients are
called “time-lagged independent components” (TIC), and the
corresponding λ( j) provide a measure of the time scale of relaxation
of the dynamics along each component (see Note 6).
Strategies based on auto-encoders have also been proposed
[34]. Speciﬁcally, this strategy extracts relevant collective variables
as a nonlinear function of the set of features {fi(R)} from the latent
variable of a neural network with the auto-encoder architecture.
While these methods are promising, no application to realistic
binding cases has been published so far, and it is still unclear how
sampling efﬁciency and estimation accuracy will beneﬁt in practice
from such automatic identiﬁcation of the slow degrees of freedom.
3.2
Reweighting and
Estimation of Kinetic
Properties
3.2.1
Thermodynamics
and Equilibrium Averages
of Observables
To provide meaningful quantitative estimates that reﬂect the proper
equilibrium distribution, the results of any simulation strategy that
enhances the sampling by introducing external energy terms have
to be properly reweighted to correct for the bias. One of the
advantages of metadynamics is the availability of robust algorithms
to recover the Boltzmann distribution from the biased trajectories.
Among the several proposed algorithms [35–37], we outline here
the principles of Tiwary and Parrinello [38]. Speciﬁcally, after
Ligand Binding with Metadynamics
239

performing a metadynamics simulation with a well-tempered bias
acting on a set of CVs s(R), and accumulating a bias potential
u(s, t), which we assume measured in kBT units, the expectation
value of any function f(R) of the molecular coordinates R can be
expressed as a weighted average
f R
ð
Þ
h
i ¼ lim
T !1
ð T
0
dt w tð Þf Rt
ð
Þ
in which the weight w tð Þ / eu st;t
ð
Þc tð Þ is obtained from the bias
after correcting it by a factor c(t) that asymptotically represents the
reversible work performed on the system. In particular, this method
can be used to recover the free-energy of the system as a function of
coordinates that were not biased during the simulation. Notably,
the weight can be used to also deﬁne a rescaled time
d~t ¼ w tð Þdt
that measures the enhancement of the metadynamics sampling.
3.2.2
Estimation of Mean
Exit Time from Metastable
States
Building on previous applications of transition state theory
[39, 40], metadynamics simulations [41, 42] can be used to calcu-
late the unbiased transition rates between two metastable states
separated by a free-energy barrier. The ratio between the transition
time τ across a given transition state and its biased estimation τM,
that is, the so-called “acceleration factor,” is given by
τ
τM
¼ a tð Þ ¼
eu sð Þ
D
E
M
where the average h∙iM is performed on the biased trajectory in the
basin of the metastable state from which the system is escaping. The
expression for the acceleration factor is valid provided that the free-
energy in the transition state region is unaffected by the bias, a
condition that is more likely to be satisﬁed in a regime where the
deposition rate is sufﬁciently slow. For this reason, the method has
been called “infrequent” metadynamics. Speciﬁcally, deposition
times as long as 10 ps have been used in ligand-binding applications
[43, 44]. Escape times are expected to be distributed according to a
Poisson distribution [45], and therefore a single instance of τ is not
enough to estimate the mean exit time from the metastable state.
Once multiple escape trajectories are accumulated, the reliability of
the kinetic estimates should be assessed by checking that the transi-
tion time distribution is indeed Poissonian, in agreement with the
theoretical assumptions on which the method is based.
3.2.3
Kinetic Models
from Metadynamics
Another set of strategies potentially allows one to also access kinetic
information when the dynamics at the transition state is complex
and standard transition state theory estimates are not reliable.
Algorithms in this class employ simulations run with metadynamics
240
Davide Provasi

bias complemented with non-equilibrium unbiased trajectories. As
mentioned earlier, application of the maximum caliber principle can
be used to obtain information about the transition matrix describ-
ing the dynamics of the system across microstates that discretize the
phase space into disjoint sets. The approach employed in Marinelli
et al. and Donati et al. [46, 47], though based on an expression
derived by Hummer [48] without explicit reference to maximum
caliber, is in fact formally equivalent to what is described here. For a
given set of probability estimates πi for the microstates, obtained
from metadynamics free-energies, the maximum caliber estimate of
the rate matrix kij can be obtained by maximizing the path entropy,
which for a Markov process can be expressed as
S ¼
X
ij
πikijlogkij,
enforcing detailed balance, conservation of probability, and one or
more additional dynamical constraints
O. The functional to be
maximized is the “caliber”
C ¼ S þ
X
i
ai πi 
X
jπikij


þ
X
j
bi π j 
X
iπikij


þ μ
X
ij
πikijOij  O

where ai, bi, and μ are Lagrange multipliers. Minimally, the mean
number of transitions between microstates must be supplied as one
of the constraints. Adding this constraint is equivalent to estimating
a global diffusion constant, which can be done, for instance, by
short unbiased non-equilibrium simulations.
Another strategy to obtain kinetic estimates from combined
metadynamics and unbiased simulations was introduced in Juraszek
et al. [49]. After estimating the equilibrium free-energy using
metadynamics, partial path transition interface sampling (PPTIS)
[50] is used to calculate the transmission coefﬁcient of the transi-
tion state.
More recently, rigorous approaches have been proposed to
optimally estimate both the thermodynamics and the kinetics start-
ing from a pool of biased and unbiased non-equilibrium simula-
tions (for instance TRAM [17] and DHAMed [19]) and can, in
principle be used with metadynamics as well. These approaches are
particularly appealing for their ability to rigorously incorporate
experimental information in the model in an integrative approach
(e.g., [51, 52]), and their use with the maximum caliber principle
opens the possibility of screening the effects of mutants and/or
small modiﬁcations of the ligands without the need for new
simulations [53].
Finally, the possibility to apply Girsanov reweighing of the
correlation functions to obtain unbiased estimates of kinetics and
Ligand Binding with Metadynamics
241

transition matrices from metadynamics has been recently proposed
[54]. This approach rests on the observation that the transition
probability between two microstates is formally a path ensemble
average that can be corrected by calculating reweighting factors on
the ﬂy [55].
3.3
Practical
Strategies for Ligand
Binding
Metadynamics has been widely applied to study the binding of
small molecules to several targets, proving its value as a reliable
strategy to obtain insight into the intricacies of the recognition
process. Nonetheless, its use to obtain routinely quantitative esti-
mates of afﬁnities and rates still requires ad hoc intervention. No
automated workﬂows, such as the ones implemented for the esti-
mation of relative binding afﬁnities via alchemical transformations
[56], have been perfected and implemented so far.
3.3.1
Ranking of Poses
Strategies to reﬁne the ranking of docking poses, essentially based
on rough estimates of the transition barrier to unbinding, have
attracted attention for their compromise between throughput and
accuracy. A combination of docking and metadynamics that
explores the dynamics of the ligand in the binding pocket and up
to the transition state toward the unbound state [57–59] can
provide semi-quantitative estimates of the stability for typical simu-
lation times in the order of ~100 ns. Similar strategies combining
docking with metadynamics and non-equilibrium [24] bias poten-
tials [60] or docking and metadynamics with a supervised simula-
tion algorithm [61] have been shown to yield useful insight into the
stability of the docked poses and can identify properties of the
escape transition state.
3.3.2
Binding Afﬁnity
Estimates
Binding afﬁnity estimates have been obtained with surprisingly
good accuracy (see Fig. 3a) for a large variety of systems. Along
with targets chosen for their well-known properties and employed
as proof of concept for the various ﬂavors of metadynamics proto-
cols, several pharmacologically relevant systems, including GPCRs
and kinases, have been studied.
The ﬁrst application [62] of metadynamics to protein-ligand
complexes addressed simple binding to three globular proteins,
using the ligand-active site distance and the angle between the
line connecting the center of mass of the receptor and the ligand
and the principal axis of inertia of the ligand, as collective variables.
Simple geometrical descriptors (distance and dihedral angle) were
shown to properly capture the binding of small ligands to other
targets as well [63, 74], including the cyclooxygenase enzymes
[22, 64], for which alternative binding modes were found to eluci-
date the determinants of target selectivity. The same simple choice
of geometrical descriptors can also be effective for more complex
ligands. For instance, metadynamics simulations recapitulated
242
Davide Provasi

QSAR data at the EphA2 receptor [65, 75] and accurately repro-
duced differences between analogs and stereoisomers.
Kinases
The role of protein ﬂexibility for binding and selectivity at kinase
targets was studied using geometric descriptors of the ligand posi-
tion, along with CVs to enhance the in/out ﬂuctuations of the
activation loop to speed up convergence [28]. These CVs were
coupled to replica schemes (parallel tempering metadynamics, see
Note 1). A similar strategy was used in Morando et al. [66] to
address the interplay of conformational selection and induced-ﬁt
binding mechanisms and the effect of mutations in the receptor
[76, 77]. Path variables, either alone [78] or in combination with
funnel restraints [79], were also applied for the enhancement of
conformational sampling of kinase targets.
GPCRs and Other
Membrane Targets
Due to the relevance of GPCRs as pharmacological targets for
many conditions and their complex pharmacology that is difﬁcult
to recapitulate with less sophisticated techniques, several attempts
have been made to use metadynamics to elucidate binding at these
membrane receptors. In case no prior information is available about
the structure of the bound pose, these studies typically require
several μs of simulation time.
Early studies [29] used a path-collective variable to enhance the
sampling of states within the transmembrane bundle, coupled to
geometric descriptors and a simple reaction coordinate enhancing
loop ﬂuctuations in the extracellular region. The efﬁciency of this
strategy can be improved as in Saleh et al. [67] by breaking the
degeneracy of the path-collective variable using the distance from
10−3
10−2
10−1
100
101
102
103
10−2
10−1
100
101
102
103
exp
104
105
106
107
108
104
105
106
107
108
exp
−15
−10
−5
−15
−10
−5
exp
calc
Fig. 3 Comparison of computational estimates and experimental results. (a) Binding afﬁnity estimates (in kcal/
mol) from metadynamics versus experimental measures for selected studies. Globular proteins [22, 62–66],
membrane [29, 67–69] proteins, and DNA [70, 71] are indicated with blue, gold, and gray points, respectively.
The dashed lines indicate a free-energy difference corresponding to one log unit in afﬁnity. (b) Unbinding rates
(in s1) from metadynamics studies compared with experimental estimates [27, 43, 44, 47, 66, 72, 73]. (c)
Binding rates (in s1M1) from metadynamics compared with experimental estimates [27, 47, 72, 73]
Ligand Binding with Metadynamics
243

the reference path z(R) and applying the funnel directly on this
variable, allowing the ligand to efﬁciently explore alternative bind-
ing modes within the receptor, while facilitating convergence
outside it.
Multiple binding pockets in the vestibule and the intermediate
region above the orthosteric pocket, as well as multiple binding
modes in the orthosteric region, confuse the interpretation of the
results and the identiﬁcation of the bioactive poses. This phenome-
non has been observed for ligands binding in the orthosteric pocket
[80], as well as for allosteric modulators binding to distal regions
near the extracellular loops [81, 82] in different GPCRs. Another
important feature of GPCR-ligand recognition is the possibility
that interactions with the membrane affect the binding and kinet-
ics. Funnel metadynamics was used in Yuan et al. [68], in conjunc-
tion with other metadynamics simulations with a set of geometric
descriptors and the coordination to lipid molecules to characterize
the binding of BPTU to P2Y1R, obtaining excellent agreement
with experimental values and elucidating the role of several inter-
mediate states.
Finally, an extensive set of simulations for ligands with known
binding pockets have been performed using a simple distance CV
measuring the relative position of the ligand with respect to the
conserved residue W6.48 (where the residue numbering refers to
the Ballesteros-Weinstein convention for rhodopsin-like GPCRs),
with an adapted bell-shaped restraint instead of the more common
funnel-shaped one [69]. The sampling was further enhanced by
using multiple walkers (see Note 1) to alleviate the inefﬁciencies due
to slow diffusivity of the system in the phase space. This strategy
was shown to converge each afﬁnity estimate in 0.5–1 μs per ligand
and recovered high-accuracy binding estimates (with a mean
unsigned error of 0.8 kcal/mol) for ligands at several different
receptors.
In summary, while not completely automatic, protocols that
provide a thorough description of binding, including multiple
poses and the effects of ﬂexible regions of the receptor and an
accurate estimation of the binding afﬁnity within less than 1 kcal/
mol from experimental measures are available for several GPCRs.
As a relevant example of membrane proteins with more
exposed pockets, the binding of inhibitors to the M2 proton chan-
nel [83] was studied using the distance between the ligand and
binding pocket residues. Also, the binding of GABA to a penta-
meric ligand-gated ion channel [84] was investigated using a
funnel-shaped constraint with basic geometric CVs capturing posi-
tion along the funnel axis and the distance from it, allowing the
free-energy surface to converge in less than 1 μs.
244
Davide Provasi

DNA
Applications to binding of small-molecules to DNA were also
published using the ligand distance and number of contacts with
the target [70, 85] as reaction coordinates, as well as with Diffusion
Map CVs analysis [86] that allowed the description of the binding
and sliding proﬁle without the introduction of intuitive geometrical
order parameters. Similar protocols can be used to study binding to
RNA [71, 87] as well.
3.3.3
Kinetic Estimates
One of the ﬁrst studies to address kinetic properties through meta-
dynamics simulations [47] investigated the binding to HIV-1 pro-
tease and was based on an approximation of the transition matrix
between microstates deﬁned by binning seven different CVs on a
regular grid. The biased simulations were used to estimate the free-
energy of each microstate. A method formally equivalent to a
maximum caliber estimation of the transition matrix was used,
along with short unbiased simulations that determined the overall
diffusive time scale of the kinetic model.
The infrequent metadynamics protocol [41, 42] has been suc-
cessfully applied to a number of interesting systems to estimate
ligand-binding kinetics. The simulation time needed to obtain
reliable estimates is considerable and ranges between ~5 and
10 μs. These simulations require a signiﬁcant investment but are
still orders of magnitude less expensive than approaches based on
proper estimation of the transition matrix between microstates with
techniques like adaptive sampling based on Markov State Model
analysis of unbiased simulations (see, e.g., [88]).
Applications to benchmark systems, that is, the unbinding of
benzamidine from trypsin [72] and of benzene from T4-lyzozyme
[44, 73], have been used to investigate the efﬁciency of the
method—these studies showed that infrequent metadynamics can
provide relatively accurate dynamic information about the system.
Studies of the kinetics of binding to pharmacologically relevant
kinases were also executed using either path collective variables
[43] or combinations of geometric descriptors and solvation
[27]. Binding to the c-Src Kinase was also studied using a combi-
nation of biased and unbiased simulations with TS-PPTIS [66],
which highlighted the complex kinetic regime at the transition state
resulting in a small transmission probability.
Kinetic rates obtained from these studies are generally within
one to two orders of magnitude from available experimental values
(see Fig. 3c, d). It must be stressed that infrequent metadynamics is
best suited to estimation of the unbinding rate, that is, to capture
the escape transition out of a small-entropy-bound state. The bind-
ing rate can be calculated indirectly from the off rate once the
overall binding afﬁnity is estimated by converging the free-energy
(for instance using funnel metadynamics).
As shown in several of the published examples, this method can
also provide kinetic rates between multiple metastable macrostates
Ligand Binding with Metadynamics
245

and therefore gives access to a Markov model description of the
dynamics between bound poses.
The extent to which the information recovered from detailed
kinetic models of the binding process can be leveraged in drug
discovery is still unclear. Nonetheless, extracting kinetic informa-
tion from metadynamics constitutes a very promising strategy to
access features of the binding process that would require simula-
tions orders of magnitude longer using unbiased molecular
dynamics.
4
Conclusions
The computational estimation of ligand-binding properties using
enhanced sampling provides a much richer picture of the molecular
recognition process than alchemical free-energy estimates, which
have become common in practical drug discovery campaigns and
are routinely used prospectively for rational design. Information
such as binding pathways, intermediate binding poses, and the
characterization of kinetic bottlenecks can potentially unlock
design strategies that are nowadays unavailable to modelers that
rely only on relative binding afﬁnities. Despite the apparent advan-
tages, though, the application of metadynamics, and similar tech-
niques, to the study of binding is still mostly limited to proof-of-
concept studies.
The computational cost of these protocols is the most evident
hurdle to its routine use, but some other technical issues limit its
appeal to general users.
As the literature reviewed in Subheading 3 shows, each recep-
tor potentially requires different CV choices for optimal sampling,
and the detailed knowledge of the system is required in the prepa-
ration of the simulation setup. Promising steps are being made
toward the automated identiﬁcation of optimal reaction coordi-
nates for the biasing, but these methods are yet to be tested on
systems of practical relevance.
Retrospective validation studies on the accuracy of kinetic esti-
mates for a more signiﬁcant number of ligands, as well as a better
understanding of the cases in which the method fails, will beneﬁt
from high-quality datasets that are still of difﬁcult accessibility to
developers outside industrial laboratories.
Finally, as is the case for all molecular dynamics studies based on
semi-empirical models, the variability of the rates across different
force-ﬁeld families, and its relative magnitude with respect to the
sampling errors is still mostly unexplored.
246
Davide Provasi

5
Notes
1. Metadynamics can be fruitfully coupled to Hamiltonian-
exchange replica schemes to further enhance the sampling
efﬁciency and overcome intrinsic weaknesses of the algorithm.
For instance, applying a metadynamics bias to each replica in a
parallel tempering (or solute tempering) scheme has been
shown to partially alleviate hysteresis problems due to
“hidden”
slow
relaxations
orthogonal
to
the
explicitly
included CVs.
The beneﬁcial effect of thermally induced crossing of
hidden barriers facilitates the convergence and results in a
more forgiving simulation scheme, called Parallel tempering
Metadynamics [89]. Bias-exchange metadynamics [46] imple-
ments a replica scheme whereby different collective variables
are enhanced for each replica, considerably increasing the
potential number of degrees of freedom that can be accelerated
during the simulation. Another protocol that exploits parallel
simulation of multiple trajectories is multiple-walker metady-
namics, whereby several runs starting from different regions of
the phase space contribute to updating the same bias potential.
These techniques have been applied in binding simulations (see
Subheading 3.3.2).
2. For a large number of inﬁnitesimally close reference conforma-
tions, the length-scale δ could in principle be kept small, and
the variable s would describe the progression along the detailed
pathway. However, in order to have a smooth foliation of the
phase space and for the sake of computational efﬁciency, it is
advisable to limit the number of references. The average
nearest-neighbor distance will therefore be a ﬁnite value
hdi  hd(Ri, Ri+1)i. For small δ  hdi, the path variable will
essentially assume a constant value equal to the index of the
nearest reference, effectively neutralizing the enhancement of
the sampling. For this reason, it is crucial that the references are
uniformly spaced under the chosen metric d(Ri, Ri+1)  hdi, so
that choosing a value for δ  hdi/2.3 results in a smooth
variation between points, and a roughly constant gradient.
3. Effective use of path-collective variables also requires a careful
choice of the metric d(Ri, Rj), that ought to capture the differ-
ent degrees of freedom that uniquely characterize the path in
conformational space. While the RMSD of the ligand after
aligning the protein conformation is a natural choice, this
metric also includes several fast degrees of freedom that can
make the resulting path-collective variables less effective. One
way around this problem is to deﬁne contact matrices between
Ligand Binding with Metadynamics
247

carefully selected subsets of ligand moieties a∈A and protein
residues b∈B along the binding pathway [90], as
M ab R
ð
Þ ¼ 1  rab=r0
ð
Þn
1  rab=r0
ð
Þm
and use the distance induced by the Frobenius norm
d Ri; R j


¼
M Ri
ð
Þ  M R j




to deﬁne the path-collective variables. Ideal choices would
include physically meaningful contacts (i.e., salt-bridges,
h-bonds, polar contacts, π-stacking, hydrophobic contacts)
that play a role in stabilizing the conformations of the speciﬁc
ligand along its speciﬁc path, but this choice has the disadvan-
tage of not being generalizable.
4. The variable s(R) is very degenerate and foliates the NR-dimen-
sional space of the system coordinates into high-dimensional
(NR  1)-dimensional leaves. If conformations signiﬁcantly far
from the reference path need to be sampled efﬁciently, the
dynamics within each leaf must be accelerated by additional
CVs. One all-purpose choice to lift the degeneracy is the dis-
tance from the reference path, deﬁned as
z R
ð
Þ ¼ δ log
X
k ed R;Rk
ð
Þ=δ
In speciﬁc cases, variables with a more direct physical mean-
ing (e.g., geometric descriptors such as angles [72] and dis-
tances, or contacts) can also be used to discriminate different
conformations that project onto the same value of s.
5. In the original implementation [31, 33], only the mean num-
ber of transitions between microstates was used as a dynamical
constraint in the caliber. Indicating with ΔGn, the reweighed
free-energies of the microstates, and with μ, the Lagrange
multiplier corresponding to the constraint, we ﬁnd that the
number of transitions simply ﬁxes the overall timescale of the
dynamics [91]
Ω MaxCal
ð
Þ
nn0
¼ eμe
ΔGn0ΔGn
2
and does not inﬂuence the spectral gap, so that μ does not need
to be calculated. The accuracy of Ω(MaxCal) can be improved by
adding system speciﬁc constraints to the caliber.
6. The most straightforward approach [18] is to run a preliminary
set of unbiased simulations, calculate the required dynamical
correlation functions using averages over the unbiased trajec-
tories, and estimate the optimal values of A. The downside of
this naı¨ve approach is that unbiased simulations might be
unable to sufﬁciently sample the binding process to provide
reliable estimates of χ(τ). An alternative strategy [30], that
248
Davide Provasi

takes advantage of the properties of metadynamics, directly
estimates the time-lagged covariance matrix in the features
space from a biased simulation. Speciﬁcally, the dynamic aver-
age that deﬁnes χ(τ) is evaluated by reweighing the product
fi(t)fi0(t + τ), as described in Subheading 3.2.1. Crucially, lag
time τ has to be corrected as well to account for the acceleration
due to the applied bias.
Acknowledgements
The author wishes to thank Kristen Marino, Sebastian Schneider,
and Abhijeet Kapoor for the critical reading of the manuscript.
References
1. Guo D, Hillger JM, AP IJ, Heitman LH
(2014) Drug-target residence time—a case for
G protein-coupled receptors. Med Res Rev 34
(4):856–892. https://doi.org/10.1002/med.
21307
2. Vauquelin G (2016) Cell membranes ... and
how long drugs may exert beneﬁcial pharma-
cological activity in vivo. Br J Clin Pharmacol
82(3):673–682.
https://doi.org/10.1111/
bcp.12996
3. Kruse AC, Hu J, Pan AC, Arlow DH, Rosen-
baum DM, Rosemond E, Green HF, Liu T,
Chae PS, Dror RO, Shaw DE, Weis WI,
Wess J, Kobilka BK (2012) Structure and
dynamics of the M3 muscarinic acetylcholine
receptor.
Nature
482(7386):552–556.
https://doi.org/10.1038/nature10867
4. Barducci A, Bussi G, Parrinello M (2008) Well-
tempered metadynamics: a smoothly converg-
ing and tunable free-energy method. Phys Rev
Lett
100(2):020603.
https://doi.org/10.
1103/PhysRevLett.100.020603
5. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci U S A 99
(20):12562–12566.
https://doi.org/10.
1073/pnas.202427399
6. Bruce NJ, Ganotra GK, Kokh DB, Sadiq SK,
Wade RC (2018) New approaches for comput-
ing ligand-receptor binding kinetics. Curr
Opin Struct Biol 49:1–10. https://doi.org/
10.1016/j.sbi.2017.10.001
7. Sykes DA, Parry C, Reilly J, Wright P, Fairhurst
RA, Charlton SJ (2014) Observed drug-
receptor association rates are governed by
membrane afﬁnity: the importance of establish-
ing
“micro-pharmacokinetic/pharmacody-
namic
relationships”
at
the
beta2-
adrenoceptor.
Mol
Pharmacol
85
(4):608–617. https://doi.org/10.1124/mol.
113.090209
8. Vauquelin
G
(2015)
On
the
‘micro’--
pharmacodynamic
and
pharmacokinetic
mechanisms that contribute to long-lasting
drug action. Expert Opin Drug Discov 10
(10):1085–1098.
https://doi.org/10.1517/
17460441.2015.1067196
9. Saladino G, Estarellas C, Gervasio FL (2017)
Recent progress in free energy methods. In:
Chackalamannil S, Rotella D, Ward SE (eds)
Comprehensive medicinal chemistry III. Else-
vier, Oxford, pp 34–50. https://doi.org/10.
1016/B978-0-12-409547-2.12356-X
10. Barducci A, Bonomi M, Parrinello M (2011)
Metadynamics. Wiley Interdiscip Rev Comput
Mol Sci 1(5):826–843. https://doi.org/10.
1002/wcms.31
11. Bussi G, Branduardi D (2015) Free-energy cal-
culations with metadynamics: theory and prac-
tice. In: Parrill AL, Lipkowitz KB (eds) Reviews
in computational chemistry, vol 28. John Wiley
& Sons, Inc., Hoboken, NJ. https://doi.org/
10.1002/9781118889886.ch1
12. Tribello
GA,
Bonomi
M,
Branduardi
D,
Camilloni C, Bussi G (2014) PLUMED 2:
new feathers for an old bird. Comput Phys
Commun 185(2):604–613. https://doi.org/
10.1016/j.cpc.2013.09.018
13. Abraham MJ, Murtola T, Schulz R, Pa´ll S,
Smith JC, Hess B, Lindahl E (2015) GRO-
MACS: high performance molecular simula-
tions through multi-level parallelism from
laptops
to
supercomputers.
SoftwareX
1–2:19–25. https://doi.org/10.1016/j.softx.
2015.06.001
14. Eastman P, Swails J, Chodera JD, McGibbon
RT, Zhao Y, Beauchamp KA, Wang L-P,
Ligand Binding with Metadynamics
249

Simmonett AC, Harrigan MP, Stern CD, Wie-
wiora RP, Brooks BR, Pande VS (2017)
OpenMM 7: rapid development of high per-
formance algorithms for molecular dynamics.
PLoS Comput Biol 13(7):e1005659. https://
doi.org/10.1371/journal.pcbi.1005659
15. Scherer MK, Trendelkamp-Schroer B, Paul F,
Perez-Hernandez G, Hoffmann M, Plattner N,
Wehmeyer
C,
Prinz
JH,
Noe
F
(2015)
PyEMMA 2: a software package for estimation,
validation, and analysis of Markov models. J
Chem Theory Comput 11(11):5525–5542.
https://doi.org/10.1021/acs.jctc.5b00743
16. Beauchamp
KA,
Bowman
GR,
Lane
TJ,
Maibaum L, Haque IS, Pande VS (2011)
MSMBuilder2:
modeling
conformational
dynamics at the picosecond to millisecond
scale.
J
Chem
Theory
Comput
7
(10):3412–3419.
https://doi.org/10.1021/
ct200463m
17. Wu H, Paul F, Wehmeyer C, Noe F (2016)
Multiensemble Markov models of molecular
thermodynamics and kinetics. Proc Natl Acad
Sci U S A 113(23):E3221–E3230. https://doi.
org/10.1073/pnas.1525092113
18. Sultan
MM,
Pande
VS
(2017)
tICA-
metadynamics: accelerating metadynamics by
using kinetically selected collective variables. J
Chem
Theory
Comput
13(6):2440–2447.
https://doi.org/10.1021/acs.jctc.7b00182
19. Stelzl LS, Kells A, Rosta E, Hummer G (2017)
Dynamic histogram analysis to determine free
energies and rates from biased simulations. J
Chem Theory Comput 13(12):6328–6342.
https://doi.org/10.1021/acs.jctc.7b00373
20. Allen TW, Andersen OS, Roux B (2004) Ener-
getics of ion conduction through the gramici-
din channel. Proc Natl Acad Sci U S A 101
(1):117–122. https://doi.org/10.1073/pnas.
2635314100
21. Roux B, Andersen OS, Allen TW (2008) Com-
ment on “Free energy simulations of single and
double
ion
occupancy
in
gramicidin
A”
[J. Chem. Phys. 126, 105103 (2007)]. J
Chem
Phys
128(22):227101.
https://doi.
org/10.1063/1.2931568
22. Limongelli V, Bonomi M, Parrinello M (2013)
Funnel metadynamics as accurate binding free-
energy method. Proc Natl Acad Sci U S A 110
(16):6358–6363.
https://doi.org/10.1073/
pnas.1303186110
23. Branduardi D, Gervasio FL, Parrinello M
(2007) From A to B in free energy space. J
Chem Phys 126(5):054103. https://doi.org/
10.1063/1.2432340
24. Marchi M, Ballone P (1999) Adiabatic bias
molecular dynamics: a method to navigate the
conformational space of complex molecular
systems. J Chem Phys 110(8):3697–3702.
https://doi.org/10.1063/1.478259
25. Bonomi M, Parrinello M (2010) Enhanced
sampling in the well-tempered ensemble. Phys
Rev Lett 104(19):190601. https://doi.org/
10.1103/PhysRevLett.104.190601
26. Palazzesi F, Valsson O, Parrinello M (2017)
Conformational entropy as collective variable
for
proteins.
J
Phys
Chem
Lett
8
(19):4752–4756.
https://doi.org/10.1021/
acs.jpclett.7b01770
27. Tiwary P, Mondal J, Berne BJ (2017) How and
when does an anticancer drug leave its binding
site? Sci Adv 3(5):e1700014. https://doi.org/
10.1126/sciadv.1700014
28. Lovera S, Sutto L, Boubeva R, Scapozza L,
Dolker N, Gervasio FL (2012) The different
ﬂexibility of c-Src and c-Abl kinases regulates
the accessibility of a druggable inactive confor-
mation. J Am Chem Soc 134(5):2496–2499.
https://doi.org/10.1021/ja210751t
29. Provasi D, Bortolato A, Filizola M (2009)
Exploring molecular mechanisms of ligand rec-
ognition by opioid receptors with metady-
namics. Biochemistry 48(42):10020–10029.
https://doi.org/10.1021/bi901494n
30. McCarty J, Parrinello M (2017) A variational
conformational
dynamics
approach
to
the
selection of collective variables in metady-
namics.
J
Chem
Phys
147(20):204109.
https://doi.org/10.1063/1.4998598
31. Tiwary P, Berne BJ (2016) How wet should be
the reaction coordinate for ligand unbinding? J
Chem Phys 145(5):054113. https://doi.org/
10.1063/1.4959969
32. Sarich M, Noe´ F, Schu¨tte C (2010) On the
approximation quality of Markov state models.
Multiscale
Model
Simul
8(4):1154–1177.
https://doi.org/10.1137/090764049
33. Tiwary P, Berne BJ (2016) Spectral gap opti-
mization of order parameters for sampling
complex molecular systems. Proc Natl Acad
Sci U S A 113(11):2839–2844. https://doi.
org/10.1073/pnas.1600917113
34. Sultan MM, Wayment-Steele HK, Pande VS
(2018)
Transferable
neural
networks
for
enhanced sampling of protein dynamics. J
Chem
Theory
Comput
14(4):1887–1894.
https://doi.org/10.1021/acs.jctc.8b00025
35. Tiana G (2008) Estimation of microscopic
averages from metadynamics. Eur Phys J B 63
(2):235–238.
https://doi.org/10.1140/
epjb/e2008-00232-8
36. Bonomi M, Barducci A, Parrinello M (2009)
Reconstructing the equilibrium Boltzmann
distribution
from
well-tempered
250
Davide Provasi

metadynamics.
J
Comput
Chem
30
(11):1615–1621.
https://doi.org/10.1002/
jcc.21305
37. Branduardi D, Bussi G, Parrinello M (2012)
Metadynamics
with
adaptive
Gaussians.
J
Chem
Theory
Comput
8(7):2247–2254.
https://doi.org/10.1021/ct3002464
38. Tiwary
P,
Parrinello
M
(2015)
A
time-
independent free energy estimator for metady-
namics. J Phys Chem B 119(3):736–742.
https://doi.org/10.1021/jp504920s
39. Grubmuller H (1995) Predicting slow struc-
tural transitions in macromolecular systems:
conformational ﬂooding. Phys Rev E Stat
Phys Plasmas Fluids Relat Interdiscip Topics
52(3):2893–2906
40. Voter AF (1997) A method for accelerating the
molecular dynamics simulation of infrequent
events. J Chem Phys 106(11):4665–4677.
https://doi.org/10.1063/1.473503
41. Tiwary P, Parrinello M (2013) From metady-
namics to dynamics. Phys Rev Lett 111
(23):230602.
https://doi.org/10.1103/Phy
sRevLett.111.230602
42. Valsson O, Tiwary P, Parrinello M (2016)
Enhancing important ﬂuctuations: rare events
and metadynamics from a conceptual view-
point. Annu Rev Phys Chem 67:159–184.
https://doi.org/10.1146/annurev-
physchem-040215-112229
43. Casasnovas
R,
Limongelli
V,
Tiwary
P,
Carloni P, Parrinello M (2017) Unbinding
kinetics of a p38 MAP kinase type II inhibitor
from metadynamics simulations. J Am Chem
Soc 139(13):4780–4788. https://doi.org/10.
1021/jacs.6b12950
44. Mondal J, Ahalawat N, Pandit S, Kay LE, Val-
lurupalli P (2018) Atomic resolution mecha-
nism
of
ligand
binding
to
a
solvent
inaccessible cavity in T4 lysozyme. PLoS Com-
put Biol 14(5):e1006180. https://doi.org/10.
1371/journal.pcbi.1006180
45. Salvalaglio M, Tiwary P, Parrinello M (2014)
Assessing the reliability of the dynamics recon-
structed from metadynamics. J Chem Theory
Comput 10(4):1420–1425. https://doi.org/
10.1021/ct500040r
46. Marinelli F, Pietrucci F, Laio A, Piana S (2009)
A kinetic model of trp-cage folding from mul-
tiple biased molecular dynamics simulations.
PLoS Comput Biol 5(8):e1000452. https://
doi.org/10.1371/journal.pcbi.1000452
47. Pietrucci F, Marinelli F, Carloni P, Laio A
(2009)
Substrate
binding
mechanism
of
HIV-1 protease from explicit-solvent atomistic
simulations.
J
Am
Chem
Soc
131
(33):11811–11818.
https://doi.org/10.
1021/ja903045y
48. Hummer G (2005) Position-dependent diffu-
sion coefﬁcients and free energies from Bayes-
ian
analysis
of
equilibrium
and
replica
molecular dynamics simulations. New J Phys
7:34
49. Juraszek J, Saladino G, van Erp TS, Gervasio
FL (2013) Efﬁcient numerical reconstruction
of protein folding kinetics with partial path
sampling and pathlike variables. Phys Rev Lett
110(10):108106.
https://doi.org/10.1103/
PhysRevLett.110.108106
50. Moroni D, Bolhuis PG, van Erp TS (2004)
Rate constants for diffusive processes by partial
path
sampling.
J
Chem
Phys
120
(9):4055–4065. https://doi.org/10.1063/1.
1644537
51. Dixit PD, Dill KA (2018) Caliber corrected
Markov modeling (C2M2): correcting equilib-
rium Markov models. J Chem Theory Comput
14(2):1111–1119. https://doi.org/10.1021/
acs.jctc.7b01126
52. Olsson S, Wu H, Paul F, Clementi C, Noe F
(2017) Combining experimental and simula-
tion data of molecular processes via augmented
Markov models. Proc Natl Acad Sci U S A 114
(31):8265–8270.
https://doi.org/10.1073/
pnas.1704803114
53. Wan
H,
Zhou
G,
Voelz
VA
(2016)
A
maximum-caliber approach to predicting per-
turbed folding kinetics due to mutations. J
Chem Theory Comput 12(12):5768–5776.
https://doi.org/10.1021/acs.jctc.6b00938
54. Donati
L,
Keller
BG
(2018)
Girsanov
reweighting for metadynamics simulations. J
Chem Phys 149(7):072335. https://doi.org/
10.1063/1.5027728
55. Donati L, Hartmann C, Keller BG (2017) Gir-
sanov reweighting for path ensembles and Mar-
kov
state
models.
J
Chem
Phys
146
(24):244112.
https://doi.org/10.1063/1.
4989474
56. Wang L, Wu Y, Deng Y, Kim B, Pierce L,
Krilov G, Lupyan D, Robinson S, Dahlgren
MK, Greenwood J, Romero DL, Masse C,
Knight
JL,
Steinbrecher
T,
Beuming
T,
Damm W, Harder E, Sherman W, Brewer M,
Wester R, Murcko M, Frye L, Farid R, Lin T,
Mobley DL, Jorgensen WL, Berne BJ, Friesner
RA, Abel R (2015) Accurate and reliable pre-
diction of relative ligand binding potency in
prospective drug discovery by way of a modern
free-energy calculation protocol and force ﬁeld.
J Am Chem Soc 137(7):2695–2703. https://
doi.org/10.1021/ja512751q
Ligand Binding with Metadynamics
251

57. Masetti M, Cavalli A, Recanatini M, Gervasio
FL (2009) Exploring complex protein-ligand
recognition mechanisms with coarse metady-
namics. J Phys Chem B 113(14):4807–4816.
https://doi.org/10.1021/jp803936q
58. Clark AJ, Tiwary P, Borrelli K, Feng S, Miller
EB, Abel R, Friesner RA, Berne BJ (2016)
Prediction of protein-ligand binding poses via
a combination of induced ﬁt docking and
metadynamics simulations. J Chem Theory
Comput 12(6):2990–2998. https://doi.org/
10.1021/acs.jctc.6b00201
59. Baumgartner MP, Evans DA (2018) Lessons
learned in induced ﬁt docking and metady-
namics in the drug design data resource grand
challenge 2. J Comput Aided Mol Des 32
(1):45–58.
https://doi.org/10.1007/
s10822-017-0081-y
60. Bortolato A, Deﬂorian F, Weiss DR, Mason JS
(2015) Decoding the role of water dynamics in
ligand-protein unbinding: CRF1R as a test
case. J Chem Inf Model 55(9):1857–1866.
https://doi.org/10.1021/acs.jcim.5b00440
61. Deganutti
G,
Zhukov
A,
Deﬂorian
F,
Federico S, Spalluto G, Cooke RM, Moro S,
Mason JS, Bortolato A (2017) Impact of
protein-ligand solvation and desolvation on
transition state thermodynamic properties of
adenosine A2A ligand binding kinetics. In
Silico Pharmacol 5(1):16. https://doi.org/
10.1007/s40203-017-0037-x
62. Gervasio FL, Laio A, Parrinello M (2005) Flex-
ible docking in solution using metadynamics. J
Am Chem Soc 127(8):2600–2607. https://
doi.org/10.1021/ja0445950
63. Kranjc A, Bongarzone S, Rossetti G, Biarnes X,
Cavalli
A,
Bolognesi
ML,
Roberti
M,
Legname G, Carloni P (2009) Docking ligands
on protein surfaces: the case study of prion
protein.
J
Chem
Theory
Comput
5
(9):2565–2573.
https://doi.org/10.1021/
ct900257t
64. Limongelli V, Bonomi M, Marinelli L, Gerva-
sio FL, Cavalli A, Novellino E, Parrinello M
(2010) Molecular basis
of cyclooxygenase
enzymes (COXs) selective inhibition. Proc
Natl Acad Sci U S A 107(12):5411–5416.
https://doi.org/10.1073/pnas.0913377107
65. Incerti M, Russo S, Callegari D, Pala D,
Giorgio C, Zanotti I, Barocelli E, Vicini P,
Vacondio F, Rivara S, Castelli R, Tognolini M,
Lodola A (2017) Metadynamics for perspective
drug design: computationally driven synthesis
of new protein-protein interaction inhibitors
targeting the EphA2 receptor. J Med Chem
60(2):787–796.
https://doi.org/10.1021/
acs.jmedchem.6b01642
66. Morando MA, Saladino G, D’Amelio N,
Pucheta-Martinez
E,
Lovera
S,
Lelli
M,
Lopez-Mendez B, Marenchino M, Campos-
Olivas R, Gervasio FL (2016) Conformational
selection and induced ﬁt mechanisms in the
binding of an anticancer drug to the c-Src
kinase. Sci Rep 6:24439. https://doi.org/10.
1038/srep24439
67. Saleh N, Saladino G, Gervasio FL, Haensele E,
Banting L, Whitley DC, Sopkova-de Oliveira
Santos J, Bureau R, Clark T (2016) A three-site
mechanism for agonist/antagonist selective
binding
to
vasopressin
receptors.
Angew
Chem
Int
Ed
Engl
55(28):8008–8012.
https://doi.org/10.1002/anie.201602729
68. Yuan X, Raniolo S, Limongelli V, Xu Y (2018)
The molecular mechanism underlying ligand
binding to the membrane-embedded site of a
G-protein-coupled receptor. J Chem Theory
Comput 14(5):2761–2770. https://doi.org/
10.1021/acs.jctc.8b00046
69. Saleh N, Ibrahim P, Saladino G, Gervasio FL,
Clark T (2017) An efﬁcient metadynamics-
based protocol to model the binding afﬁnity
and the transition state ensemble of G-protein-
coupled receptor ligands. J Chem Inf Model 57
(5):1210–1217.
https://doi.org/10.1021/
acs.jcim.6b00772
70. Vargiu AV, Ruggerone P, Magistrato A, Carloni
P (2008) Dissociation of minor groove binders
from DNA: insights from metadynamics simu-
lations. Nucleic Acids Res 36(18):5910–5921.
https://doi.org/10.1093/nar/gkn561
71. Bochicchio
A,
Rossetti
G,
Tabarrini
O,
Kraubeta S, Carloni P (2015) Molecular view
of ligands speciﬁcity for CAG repeats in anti-
Huntington therapy. J Chem Theory Comput
11(10):4911–4922.
https://doi.org/10.
1021/acs.jctc.5b00208
72. Tiwary P, Limongelli V, Salvalaglio M, Parri-
nello M (2015) Kinetics of protein-ligand
unbinding: predicting pathways, rates, and
rate-limiting steps. Proc Natl Acad Sci U S A
112(5):E386–E391.
https://doi.org/10.
1073/pnas.1424461112
73. Wang
Y, Martins
JM,
Lindorff-Larsen
K
(2017) Biomolecular conformational changes
and ligand binding: from kinetics to thermody-
namics. Chem Sci 8(9):6466–6473. https://
doi.org/10.1039/c7sc01627a
74. Bocahut A, Bernad S, Sebban P, Sacquin-Mora
S (2009) Relating the diffusion of small ligands
in human neuroglobin to its structural and
mechanical properties. J Phys Chem B 113
(50):16257–16267.
https://doi.org/10.
1021/jp906854x
75. Russo S, Callegari D, Incerti M, Pala D,
Giorgio C, Brunetti J, Bracci L, Vicini P,
252
Davide Provasi

Barocelli
E,
Capoferri
L,
Rivara
S,
Tognolini M, Mor M, Lodola A (2016)
Exploiting
free-energy
minima
to
design
novel
EphA2
protein-protein
antagonists:
from simulation to experiment and return.
Chemistry
22(24):8048–8052.
https://doi.
org/10.1002/chem.201600993
76. Lovera S, Morando M, Pucheta-Martinez E,
Martinez-Torrecuadrada JL, Saladino G, Ger-
vasio FL (2015) Towards a molecular under-
standing
of
the
link
between
Imatinib
resistance and kinase conformational dynamics.
PLoS
Comput
Biol
11(11):e1004578.
https://doi.org/10.1371/journal.pcbi.
1004578
77. Marino KA, Sutto L, Gervasio FL (2015) The
effect of a widespread cancer-causing mutation
on the inactive to active dynamics of the B-Raf
kinase. J Am Chem Soc 137(16):5280–5283.
https://doi.org/10.1021/jacs.5b01421
78. Fidelak
J,
Juraszek
J,
Branduardi
D,
Bianciotto
M, Gervasio FL (2010) Free-
energy-based
methods
for
binding
proﬁle
determination in a congeneric series of CDK2
inhibitors.
J
Phys
Chem
B
114
(29):9516–9524.
https://doi.org/10.1021/
jp911689r
79. Saladino G, Gauthier L, Bianciotto M, Gerva-
sio FL (2012) Assessing the performance of
metadynamics and path variables in predicting
the binding free energies of p38 inhibitors. J
Chem
Theory
Comput
8(4):1165–1170.
https://doi.org/10.1021/ct3001377
80. Crowley RS, Riley AP, Sherwood AM, Groer
CE, Shivaperumal N, Biscaia M, Paton K,
Schneider S, Provasi D, Kivell BM, Filizola M,
Prisinzano TE (2016) Synthetic studies of neo-
clerodane diterpenes from Salvia divinorum:
identiﬁcation of a potent and centrally acting
mu opioid analgesic with reduced abuse liabil-
ity.
J
Med
Chem
59(24):11027–11038.
https://doi.org/10.1021/acs.jmedchem.
6b01235
81. Shang Y, Yeatman HR, Provasi D, Alt A,
Christopoulos A, Canals M, Filizola M (2016)
Proposed mode of binding and action of posi-
tive allosteric modulators at opioid receptors.
ACS Chem Biol 11(5):1220–1229. https://
doi.org/10.1021/acschembio.5b00712
82. Saleh N, Hucke O, Kramer G, Schmidt E,
Montel F, Lipinski R, Ferger B, Clark T, Hil-
debrand PW, Tautermann CS (2018) Multiple
binding sites contribute to the mechanism of
mixed agonistic and positive allosteric modula-
tors of the cannabinoid CB1 receptor. Angew
Chem
Int
Ed
Engl
57(10):2580–2585.
https://doi.org/10.1002/anie.201708764
83. Yuri S, Atsushi K, Kyosuke N, Takatsugu H
(2018) Analysis by metadynamics simulation
of binding pathway of inﬂuenza virus M2 chan-
nel
blockers.
Microbiol
Immunol
62
(1):34–43.
https://doi.org/10.1111/1348-
0421.12561
84. Comitani F, Limongelli V, Molteni C (2016)
The free energy landscape of GABA binding to
a pentameric ligand-gated ion channel and its
disruption by mutations. J Chem Theory
Comput 12(7):3398–3406. https://doi.org/
10.1021/acs.jctc.6b00303
85. Di Leva FS, Festa C, Renga B, Sepe V,
Novellino E, Fiorucci S, Zampella A, Limon-
gelli V (2015) Structure-based drug design
targeting
the
cell
membrane
receptor
GPBAR1: exploiting the bile acid scaffold
towards selective agonism. Sci Rep 5:16605.
https://doi.org/10.1038/srep16605
86. Zheng W, Vargiu AV, Rohrdanz MA, Carloni P,
Clementi C (2013) Molecular recognition of
DNA by ligands: roughness and complexity of
the free energy proﬁle. J Chem Phys 139
(14):145102.
https://doi.org/10.1063/1.
4824106
87. Mlynsky V, Bussi G (2018) Molecular dynam-
ics simulations reveal an interplay between
SHAPE reagent binding and RNA ﬂexibility. J
Phys Chem Lett 9(2):313–318. https://doi.
org/10.1021/acs.jpclett.7b02921
88. Buch I, Giorgino T, De Fabritiis G (2011)
Complete
reconstruction
of
an
enzyme-
inhibitor binding process by molecular dynam-
ics simulations. Proc Natl Acad Sci U S A 108
(25):10184–10189.
https://doi.org/10.
1073/pnas.1103547108
89. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for beta hairpin
folding from combined parallel tempering and
metadynamics.
J
Am
Chem
Soc
128
(41):13435–13441.
https://doi.org/10.
1021/ja062463w
90. Bonomi M, Branduardi D, Gervasio FL, Parri-
nello M (2008) The unfolded ensemble and
folding mechanism of the C-terminal GB1
beta-hairpin.
J
Am
Chem
Soc
130
(42):13938–13944.
https://doi.org/10.
1021/ja803652f
91. Dixit PD, Dill KA (2014) Inferring micro-
scopic kinetic rates from stationary state distri-
butions.
J
Chem
Theory
Comput
10
(8):3002–3005.
https://doi.org/10.1021/
ct5001389
Ligand Binding with Metadynamics
253

Chapter 11
The Adaptive Path Collective Variable: A Versatile Biasing
Approach to Compute the Average Transition Path
and Free Energy of Molecular Transitions
Alberto Pe´rez de Alba Ortı´z, Jocelyne Vreede, and Bernd Ensing
Abstract
In the past decade, great progress has been made in the development of enhanced sampling methods, aimed
at overcoming the time-scale limitations of molecular dynamics (MD) simulations. Many sampling schemes
rely on adding an external bias to favor the sampling of transitions and to estimate the underlying free
energy landscape. Nevertheless, sampling molecular processes described by many order parameters, or
collective variables (CVs), such as complex biomolecular transitions, remains often very challenging. The
computational cost has a prohibitive scaling with the dimensionality of the CV-space. Inspiration can be
taken from methods that focus on localizing transition pathways: the CV-space can be projected onto a
path-CV that connects two stable states, and a bias can be exerted onto a one-dimensional parameter that
captures the progress of the transition along the path-CV. In principle, such a sampling scheme can handle
an arbitrarily large number of CVs. A standard enhanced sampling technique combined with an adaptive
path-CV can then locate the mean transition pathway and obtain the free energy proﬁle along the path. In
this chapter, we discuss the adaptive path-CV formalism and its numerical implementation. We apply the
path-CV with several enhanced sampling methods—steered MD, metadynamics, and umbrella sampling—
to a biologically relevant process: the Watson–Crick to Hoogsteen base-pairing transition in double-
stranded DNA. A practical guide is provided on how to recognize and circumvent possible pitfalls during
the calculation of a free energy landscape that contains multiple pathways. Examples are presented on how
to perform enhanced sampling simulations using PLUMED, a versatile plugin that can work with many
popular MD engines.
Key words Enhanced sampling, Metadynamics, Path sampling, Path collective variable, Free energy,
Molecular dynamics, PLUMED, DNA, Hoogsteen base-pairing
1
Introduction
Enhanced sampling methods have expanded the accessible time-
scale of molecular dynamics (MD) simulations, and, with that, our
understanding of complex biomolecular phenomena. Molecular
processes that are very slow or infrequent with respect to the
molecular vibrations and thermal motions, such as most chemical
reactions, conformational changes, and nucleation events—all
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_11, © Springer Science+Business Media, LLC, part of Springer Nature 2019
255

characterized by a transition over a free energy barrier—can now, in
principle, be tackled by a wide range of enhanced sampling techni-
ques. Popular approaches include: adding an external bias to the
system, e.g., using metadynamics [1–3], steered MD [4, 5],
umbrella sampling [6], the adaptive biasing force method [7], etc.
[8–14]; increasing the temperature, e.g., by parallel tempering
[15, 16], multi-canonical sampling [17], the temperature acceler-
ated method [18], etc. [19–21]; or ﬁnding transition pathways,
e.g., through transition path sampling (TPS) [22, 23], the string
method [24–27], nudged elastic band (NEB) [28], and so forth
[29–34]; and combinations of these [35, 36]. Many of these tech-
niques, and in particular those applying an external bias, allow for
estimating the Landau free energy of the process, from which
transition rates and equilibrium constants can be computed. The
key challenge in these schemes is choosing an adequate, and prefer-
ably small, set of collective variables (CVs), which are the key order
parameters that describe the transition. For relatively simple transi-
tions, a few well-chosen CVs can be used to steer the process of
interest without problems of hysteresis or degeneracy. However,
many interesting biomolecular transitions involve concerted dis-
placements of many groups of atoms, requiring large sets of CVs for
the description of the process. This gives rise to high-dimensional
free energy landscapes that are very cumbersome to sample and
converge. Sometimes, the problem can still be handled by sheer
computational power, or by combining in a smart manner several
CVs into fewer, more complex, ones. But generally, sampling high-
dimensional free energy landscapes poses a notoriously difﬁcult
problem in computational studies of biomolecular processes.
A promising route to tackle the problem of sampling high-
dimensional CV-spaces is to map the CV-space onto a so-called
path-CV [26, 33, 34, 37–41], a parameterized curve in the
CV-space that describes the transition between the reactant and
the product states. By performing the sampling along this path—
for
example,
with
the
path-metadynamics
(PMD)
method
[37, 41]—the dimensionality problem is circumvented. The chal-
lenge now consists in optimizing the path-CV in the space spanned
by the original set of descriptive CVs, such that it “falls” into the
channel corresponding to the average transition path. Optimizing a
parameterized curve as a string of nodes to locate the minimum free
energy path (MFEP) can be done by computing and following the
gradients of the nodes in the perpendicular direction to the path
[26, 33]. However, a further speedup can be realized by optimizing
via the average sampled density of the CVs, which—under reason-
able assumptions—leads to the average transition ﬂux density
[37, 41]. Irregularities on the free energy landscape, such as
ill-deﬁned or multiple transition channels, can be managed by
restricting the sampling to the neighborhood of the path and by
tuning the path ﬂexibility.
256
Alberto Pe´ rez de Alba Ortı´z et al.

In this chapter, we present a concise introduction to the theory
of the path-CV and its use in PMD. We also include the necessary
scripts to run a case study using the path-CV implementation in the
PLUMED software [42], a plugin that can be linked with several
popular MD engines to perform enhanced sampling simulations.
The chapter is organized as follows: In Subheading 2, we introduce
the basic theory behind the path-CV deﬁnition (Subheading 2.1),
its use in a biasing method (Subheading 2.2), the path optimization
algorithm (Subheading 2.3), and the implementation in PLUMED
(Subheading 2.4). In Subheading 3, we list the computational tools
used to run simulations. Subheading 4 consists of a step-by-step
guide on how to study a complex biomolecular process at the
hand of an illustrative transition in double-stranded DNA: the
Watson–Crick to Hoogsteen base-pairing transition. The set of
CVs for this process is deﬁned in Subheading 4.2; the stable states
in this CV-space are discussed in Subheading 4.3. An initial steered
MD simulation along an evolving path-CV is performed in
Subheading 4.4, followed by an exploratory multiple-walker meta-
dynamics [43] run in Subheading 4.5. The Watson–Crick to
Hoogsteen transition involves multiple mechanisms, and we discuss
which measures are taken to converge on a speciﬁc path, using a
multiple-walker metadynamics simulation (Subheading 4.6). We
also perform umbrella sampling along the optimized path, and
reconstruct a free energy proﬁle using the weighted histogram
analysis method (WHAM) [44] (Subheading 4.7). In Subheading
4.8, we show how to carry out an a posteriori path-CVoptimization
from a pre-existing trajectory along a different pathway, from which
also the free energy proﬁle can be computed. We end this chapter
with a compilation of “notes” (Subheading 5) on how to use the
path-CV to compute the average transition pathway and the free
energy of a molecular transition, including several “rules of thumb”
on how to choose parameters and how to monitor for, and avoid,
possible pitfalls.
2
Theory
2.1
Deﬁning the Path
Collective Variable
Let us consider an L-particle system with positions qðtÞ∈3L and
velocities vðtÞ∈3L. The dynamics of the system is governed by a
potential U(q) and follows a canonical distribution at a temperature
T. Let us also assume that the system has an underlying free energy
surface (FES) with two stable states A and B. The FES can be fully
described by a set of N key descriptive degrees of freedom, the
collective variables (CVs) {zi(q)}, with i ¼ 1,. . .,N. We aim to ﬁnd
the average transition path between A and B in the space of the
CVs, zi, and deﬁne the progress along it as a reaction coordinate.
Provided that the CVs are sufﬁciently good descriptors of
the system, the reaction coordinate is well-deﬁned in terms of
The Adaptive Path Collective Variable
257

transition path theory [45] and the committor distribution
[46, 47]. That is, along the path, we can determine the committor
probability pB(q) that a trajectory starting with random Maxwell–
Boltzmann distributed velocities arrives in state B before going
through state A. As the system moves near the A or B basins in
CV-space, pB(q) approaches, respectively, 0 or 1. In this CV-space it
is possible to deﬁne an isocommittor surface comprising all points
where pB(q) ¼ 0.5. Furthermore, the isocommittor surfaces span-
ning all committor values from 0 to 1 provide a continuous folia-
tion of CV-space from A to B. In these hyperplanes, we can deﬁne
the transition ﬂux density ρ as the number of trajectories going
through the surface per unit area. This ﬂux density peaks at the
transition channel in the FES between A and B, resulting in the
average transition path that we wish to localize.
To locate the average transition path, we make the following
assumptions [37]:
1. The average transition path can be represented in CV-space by
a path-CV: a curve
sðσÞ : ! N , where the parameter
σðzÞjs : N ! ½0,1 yields the progress along the path from
A to B, such that s(0) ∈A and s(1) ∈B. This quantity can
in principle be connected to the committor value.
2. In the vicinity of the path, the isocommitor planes Sσ are
perpendicular to s(σ).
3. In the vicinity of the path, the normalized transition ﬂux den-
sity ρ can be represented by conﬁgurational probability
pðzÞ ¼ expðFðzÞ=kBT Þ, where F is the free energy, and kB is
the Boltzmann constant.
Given the ﬁrst and second assumptions, it is possible to project
any point z in CV-space onto its closest point on the path s(σ), and
derive the path progress parameter σ(z). Moreover, since we wish
the curve s(σ) to follow the transition channel of maximum ﬂux
density, we can take the third assumption and approximate the
average transition path as:
sðσÞ ¼
Z
Sσ
dSσz0pσðz0
1, . . . , z0
NÞ, with
pðz0
1, . . . , z0
N Þ ¼ 1
Z
Z
dqeβU ðqÞδðz1  z0
1Þ . . . δðzN  z0
NÞ,
ð1Þ
where pσðz0
1, . . . , z0
NÞ is the ﬂux probability density at the isocom-
mitor surface perpendicular to s(σ), with the Dirac delta function δ
and the partition function Z.
258
Alberto Pe´ rez de Alba Ortı´z et al.

2.2
Finding
the Average
Transition Path
In principle, Eq. 1 enables the calculation of the average transition
path by sampling and making a histogram of z during an MD run,
or a Monte Carlo simulation. However, the transition is a rare event
on the time-scales accessible to standard simulations. The ﬂux
density away from the neighborhood of the A or the B basins will
be poorly sampled. This problem is typically overcome with
enhanced sampling methods—e.g., metadynamics—by biasing
directly the dynamics of the CVs, z. But in practice, such an
approach is limited to low-dimensional CV-spaces. The path-CV
aims to overcome this limitation.
Let us exert a time-dependent metadynamics bias,
V biasðσg, tÞ ¼
X
t
HðtÞexpð ðσg  σgðtÞÞ2
2W 2
Þ,
ð2Þ
onto the one-dimensional path progress parameter, σ(t), along a
guess transition path σg ¼ σðzÞjsg, with Gaussian height H and
width W. This growing repulsive potential drives the system back
and forth along the path, away from already visited conﬁgurations.
If the path remains ﬁxed, the metadynamics bias potential con-
verges, eventually, to (minus) the free energy along the guess path
Fg ¼ Vbias(σg, t) [1].
To improve our guess path and use it to locate the average
transition path, we replace in Eq. 1 the ensemble average of transi-
tion points through the hyperplanes by a time average:
hziσg ¼ lim
t!1
Z
t
0
Z
Sσg
zðt0ÞdSσgdt0:
ð3Þ
We can now optimize the path toward the average transition path
by iteratively relocating the guess path to the cumulative average
density sgðσgÞ ¼ hziσg (Fig. 1). Simultaneously, the metadynamics
algorithm will adapt the bias potential after each path update as it
keeps adding layers of Gaussian potentials to the total bias, over-
writing the free energy at previous trial paths [48], and continu-
ously converging toward the free energy at the average transition
path F ¼ Vbias(σ, t).
Most of the extensive machinery developed in the last years for
metadynamics can be applied directly with the PMD method. For
example, the well-tempered method [2, 3] can aid in converging a
free energy proﬁle by gradually reducing the height of the Gaus-
sians on the ﬂy. The same effect can be obtained by manually
reducing the Gaussian height at every recrossing from A to
B [37] (see Note 1). Another interesting feature is multiple-walker
metadynamics [43], which can be applied with the path-CV to
speed up the simulation. Here, several replicas of the system are
simulated simultaneously in parallel for the exploration of different
regions of CV-space, while each replica communicates its updates
The Adaptive Path Collective Variable
259

on both the path and on the bias potential to the other replicas. By
initializing walkers both in the A and B basins, the shape of the path
can be rendered signiﬁcantly faster (see Note 2).
The presented recipe to locate the average transition path with
an adaptive path-CV is not exclusively coupled to metadynamics.
Other enhanced sampling methods, such as steered MD, con-
strained MD, umbrella sampling, or even TPS, can be used with
the path-CV, without changes to the path formalism. In this chap-
ter, we will exemplify the use of the path-CV with steered MD,
metadynamics, and with umbrella sampling.
2.3
Path-CV
Optimization
Algorithm
2.3.1
Projection of CV-
space onto a String
of Nodes
In order to implement the method numerically, we must provide a
discrete deﬁnition of the path-CV as a parameterized curve. This is
done by representing the curve as a string of M ordered nodes,
sgðσg, tÞ ! sti
j , with j ¼ 1,. . .,M labeling the nodes on the string
and ti representing the discrete time parameter at path update
step i. Then, the projection of a point in CV-space, z, onto the
path—which yields the value of the path progress parameter σ—is
given by:
σgðzÞ ¼ m
M 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ðv1  v3Þ2  jv3j2ðjv1j2  jv2j2Þ
q
 ðv1  v3Þ þ jv3j2
2Mjv3j2
,
with
v1 ¼ sm  hzi,
v2 ¼ hzi  sm1,
v3 ¼ smþ1  sm,
ð4Þ
Fig. 1 Graphical representation of an initial guess path-CV section (red) converging to the average transition
path (green) between basins A and B. The curve points sg(σg) are relocated to the cumulative average density
hziσg in CV-space, which peaks at the valley in the free energy F (yellow) at each hyperplane Sσg
260
Alberto Pe´ rez de Alba Ortı´z et al.

where sm is the closest path node to z, and sm1 and sm+1 are its
neighboring nodes. This expression implies that points beyond the
ﬁrst or last nodes are mapped to values of σg < 0 and σg > 1,
respectively. To have control over this mapping at and outside the
stable states, extra trailing nodes can be added at both ends of the
original path. If necessary, wall potentials can be added to restrict
the sampling on a particular σg-region. Note also that the projec-
tion in Eq. 4 requires that the nodes are equidistant. This require-
ment is imposed by a reparameterization step [26] after each path
update.
2.3.2
Evolution
of the Path-CV
The path update step, which sets sgðσgÞ ¼ hziσg, uses the time
averaged distance between the sampled z-points and their projected
points on the path, sg(σg(z)). This distance is weighted by a weight,
w, which is only non-zero for the two closest nodes, giving the
following path node propagation equation:
stiþ1
j
¼ sti
j þ
P
k wj,k  ðzk  stiðσðzkÞÞÞ
P
k wj,k
, with
wj,k ¼ max 0,
1 
sti
j  stiðσðzkÞÞ


sti
j  sti
jþ1


0
B
@
1
C
A
2
64
3
75,
ð5Þ
where k is the current MD step and Δt ¼ ti+1  ti is the time
interval between two path updates. See Fig. 2 for an illustration
of the path update calculation. In order to slow down or accelerate
the
convergence
of
the
path,
an
additional
fade
factor,
ξ ¼ expð ln ð2Þ=τÞ, can be introduced, with a half-life parameter,
τ, being the number of MD steps after which a distance measured
from the path contributes only 50% of its original value to the
average. We reformulate:
stiþ1
j
¼ sti
j þ
P
k wj,k  ðzk  stiðσðzkÞÞÞ
P
k ξtikwj,k
:
ð6Þ
2.3.3
Tube Potential,
CV-space Scaling, Multiple
Walkers, and Corner-
Cutting
When facing landscapes with multiple or ill-deﬁned transition
valleys, it can be beneﬁcial to not only bias the sampling along the
path, but also restrain the sampling to the path vicinity. A harmonic
restraint potential set at jjzk  stiðσðzkÞÞjj, either at zero distance or
allowing some freedom, can help in converging a transition path.
We refer to this restraint as a “tube” potential. In the limit of an
inﬁnitesimally narrow tube potential, the path is optimized by
following the local free energy gradient—in a similar fashion to
the string method [26]—and PMD converges to the MFEP closest
to the initial guess path instead of to the average transition path.
Thus, the tube potential allows to control the behavior of PMD by
switching between a path optimization based on CV density, quick
The Adaptive Path Collective Variable
261

for well-deﬁned landscapes with a single channel, and a path opti-
mization based on the free energy gradient, suitable for more
complex scenarios with multiple channels. This versatility is key to
the adaptive path framework presented in this chapter, especially
when considering that the essential distinction between different
path-CV implementations is the optimization rule [26, 33, 34,
37–39, 41]. Of course, when using a tube potential, care has to
be taken regarding its effect on the entropic contribution to the free
energy (see Note 3).
Another
useful
algorithmic
extension
is
the
scaling
of
CV-space. Imagine a set of CVs with numerical ranges differing
several orders of magnitude. In order to keep an equidistant set of
nodes under these conditions, the node distribution across dimen-
sions would need to be severely unbalanced. As a consequence, the
path progress parameter σ would also be deﬁned mostly by the
most widely ranging CV. To avoid this imbalance, one may rescale
the CVs in a manner that the space to be sampled is in all dimen-
sions normalized to one (see Note 4). This is particularly helpful
when dealing with CVs of different units (e.g., rad and deg) or
dimensions (e.g., rad and nm). To rescale the CV-space, it is useful
to have a priori knowledge of the minimum and maximum values
that each CV can have.
A ﬁnal remark on the algorithm concerns a side effect of the
reparameterization step to ensure node equidistance. The imple-
mented reparameterization algorithm [26] turns out to favor
straight paths somewhat and displays a tendency to “cut corners”
while redistributing the nodes. While this tendency is often beneﬁ-
cial, as it maintains a smooth, non-curling, or self-intersecting
curve, there are obvious drawbacks. In particular, when the meta-
dynamics is temporarily sampling one end of the path, the repeating
reparameterization after every path update redistributes also the
Fig. 2 Graphical explanation of a path node update. The sampled average density hziσg is projected onto the
path at sg(σg). The two closest path nodes sm1 and sm are relocated according to weights that depend on
their distances from sg(σg). A subsequent reparameterization step redistributes the nodes along the path to
make them equidistant again
262
Alberto Pe´ rez de Alba Ortı´z et al.

nodes at the other end of the path, moving them gradually back to a
straight path and thus undoing previous path optimization. This
side effect is much reduced in the multiple-walker PMD implemen-
tation, because in that case the sampling is more continuous along
the entire path. Apart from preventing the information loss, of
course the multiple-walker option also results in an almost trivial
parallelization speedup for the sampling of the path and the free
energy, thus providing a powerful extension to the original method
[41] (see Note 5).
In summary, the path-CV consists of a set of ordered nodes
describing the transition from basin A to basin B in the high-
dimensional CV-space. The system can be biased to move along
the path, while the positions of the nodes in CV-space can be
optimized by following the average density of the sampled points,
which peaks at the free energy valley. By means of this sampling
along and around the path, we can converge the average transition
path and the free energy along it. Additional actions can be taken to
control the extent of the sampling and the ﬂexibility of the path
when facing challenging, forking free energy landscapes. Namely,
we can add a tube potential to restrain the sampling in the direction
perpendicular to the path and switch from a density-based optimi-
zation toward the average transition path, to a gradient-based
optimization toward the closest MFEP to the initial guess path.
2.4
Path-CV
Implementation
in PLUMED
The theoretical and numerical framework discussed above has been
implemented into the PLUMED software [42] as a function of
CVs. Invoking the action PATHCV in PLUMED requires that the
following keywords are speciﬁed:
l
LABEL: sets the identiﬁer for this instance.
l
ARG: sets the list of (priorly deﬁned) CVs that span the space in
which the path exists.
l
GENPATH: generates a straight path between two points in
CV-space; the two points typically marking the stable states. It
takes 3 integers as arguments, corresponding to the number of
anterior trailing nodes, actual transition nodes, and posterior
trailing nodes, followed by the CV-space coordinates of the
initial and ﬁnal transition nodes separated by commas.
l
INFILE: points to a ﬁle containing an input path.
l
FIXED: indicates the two ﬁxed nodes corresponding to the
initial and ﬁnal states. The default values are the ﬁrst and last
nodes, thus assuming no trailing nodes.
l
OUTFILE (PATH) : points to a ﬁle where the path updates are
printed, concatenated one after the other.
l
SCALE: lists the scaling factors to normalize the CV-space. The
default value is one for each CV.
The Adaptive Path Collective Variable
263

l
STRIDE (PACE) : indicates the frequency for printing the path
in MD steps.
l
PACE (0) : indicates the frequency for optimizing the path
nodes in MD steps.
l
HALFLIFE (-1) : indicates the number of MD steps after which
a previously measured path distance weighs only 50% in the
average. A negative number sets it to inﬁnity.
The parenthesized arguments indicate the default values for the
keywords when relevant. The format of the INFILE and OUTFILE
comprehends a ﬁrst column with the numbering of the nodes,
followed by N columns with the value of each CV at each node
position, which in turn are followed by N columns showing the
cumulative measured displacement of the system from the given
node along each CV. The ﬁnal column contains the cumulative
weight wj,k for the corresponding node, such that the cumulative
displacement divided by the cumulative weight gives the average
distance between the path and the measured average transition
density. After each path update, the cumulative displacement is
reset to zero for the non-ﬁxed nodes, but the cumulative weights
remain.
To use the multiple-walker implementation, one should also
provide:
l
WALKERS_ID: indicates the ID of the current walker, starting
from zero.
l
WALKERS_N: indicates the total number of walkers.
l
WALKERS_DIR: points to the directory where all walkers write
and read each other’s ﬁles.
l
WALKERS_RSTRIDE: indicates the reading frequency for walkers
in MD steps.
Two quantities can be extracted, and biased, from the path-CV:
the components s and z, corresponding to the progress along
the
path,
σðzkÞjsti ,
and
the
displacement
from
the
path,
jjzk  stiðσðzkÞÞjj. In the PLUMED syntax, the components are
called by LABEL.s and LABEL.z, respectively.
3
Materials
Simulations of the Watson–Crick to Hoogsteen DNA base-pairing
transition are carried out using GROMACS version 5.1.4 [49]
compiled with PLUMED version 2.1.3 [42] with the added
PMD code available on http://www.acmm.nl/ensing/software/
PathCV.cpp. Figures have been rendered with Gnuplot [50]. All
simulations were performed in Carbon, the local computing cluster
of the Van ’t Hoff Institute for Molecular Sciences at the University
of Amsterdam. The reader is referred to the documentation of
264
Alberto Pe´ rez de Alba Ortı´z et al.

GROMACS, PLUMED, and our implemented path-CV for details
about how to install and execute these software codes.
4
Methods
In this section, we present an application of path-CV enhanced
sampling
to
study
the
transition
between
Watson–Crick
(WC) [51] and Hoogsteen (HG) [52] base pairs (bps) in double-
stranded DNA. HG bps form via a 180∘rotation of the purine base
around the glycosidic bond from an anti to sin conformation with
respect to WC [53–56] (Fig. 3). This conformational change has
raised attention after discovering that DNA presents a dynamical
equilibrium between the two base-pairings, and that the alternative
HG conformation can be involved in biological functionalities
related to recognition, replication, damage induction, and repair
[53–56].
Experimental [53, 55] and computational [53, 57, 58] studies
have been carried out to elucidate the mechanistic pathways, the
free energy differences, and the barriers between the WC and HG
bps. Previous simulations have focused, among others, on the
transition of the A16–T9 bp of A6-DNA, which we will also do in
this chapter. In these studies, the transition was described by two
CVs: the glycosidic torsion, χ, and the base opening angle, θ. These
two CVs can in principle distinguish between two suggested transi-
tion mechanisms involving the base rotation (Fig. 3c) and base
ﬂipping outside of the double helix (Fig. 3d). In these previous
investigations, the pathways and free energy proﬁles were deter-
mined by conjugate peak reﬁnement (CPR), connecting the two
stable conformers on the adiabatic free energy surface [53], and by
umbrella sampling simulations, restrained to speciﬁc points on the
(χ, θ)-plane followed by an a posteriori search for possible pathways
on the free energy surface [57]. Six different transition pathways
have been identiﬁed, as one can distinguish two directions for the
rotation around the glycosidic bond (clockwise and counter-
Fig. 3 (a) Double-stranded A6-DNA; (b) WC A16–T9 bp; (c) HG A16–T9 bp after the 180∘rotation of the
adenine; (d) Base ﬂipping of the adenine in the A16–T9 bp
The Adaptive Path Collective Variable
265

clockwise) and three kinds of base ﬂipping (opening to the DNA
major groove, opening to the minor groove, or without base
opening).
In the following sections, we will describe the application of the
adaptive path-CV to study this transition in DNA. The path-CV
allows us to include a larger set of descriptive CVs to enhance the
sampling, giving a more detailed picture of the process, including
conformational changes in the DNA backbones, reorganization of
neighboring bps, and the overall shape of the DNA double helix.
Moreover, previous work on this system in our Computational
Chemistry Group using TPS simulations [59, 60] (manuscript in
preparation) provides us not only with a prepared and tested setup
for the molecular model system, but also a large set of reactive
trajectories between the WC and HG states that serve as compari-
son for the path-CV enhanced sampling results.
This section is organized as follows: Subheading 4.1 deals with
the equilibration of the system in each of the two stable states
(WC and HG). Subheading 4.2 provides a description of the CVs.
Subheading 4.3 describes the localization of the stable states in the
CV-space. In Subheading 4.4 we describe how to use the steered
MD method along the path-CV to test the CV set. In Subheading
4.5, we illustrate an exploratory multiple-walker PMD simulation,
which reveals key properties of the studied transition. Subheading
4.6 shows a more exhaustive multiple-walker PMD run to converge
a transition path without base ﬂipping. In Subheading 4.7,
umbrella sampling is performed along this path to extract a free
energy proﬁle using WHAM [44]. In Subheading 4.8, we perform
an a posteriori path optimization for a TPS trajectory of the base-
ﬂipping transition and compute from this another free energy
proﬁle.
4.1
System
Preparation
The setup of the aqueous double-stranded DNA system for classical
MD simulation with the GROMACS software was done as part of a
previous work [59, 60] and will be described in full detail elsewhere.
In brief, an ideal B-DNA duplex structure is created with
the
make_na
webtool
[61].
The
nucleotide
sequence
50-
CGATTTTTTGGC-30—and its complementary strand—is repro-
duced from ref. 53. The chain is placed in a periodic dodecahedron
box and solvated in 6691 TIP3P water molecules [62] with 28 Na+
and 6 Cl ions (25 mM NaCl), resulting in a charge-neutral system of
20868 atoms. The AMBER03 force ﬁeld [63] is used to describe
atomic interactions. Non-bonded interactions are treated with a
cut-off at 0.8 nm and long-range electrostatics are handled by the
particle mesh Ewald method [64, 65]. Energy minimization is per-
formed by conjugate gradient (with a threshold of 100 N), and
followed by a 1 ns position restrained run (with a force constant of
1000 kJ/(mol nm2) for DNA heavy atoms). Equilibration is per-
formed in nine, 200 ns long, MD runs starting with different random
266
Alberto Pe´ rez de Alba Ortı´z et al.

Maxwell–Boltzmann distributed velocities and using a time step of
2 fs, the v-rescale thermostat [66] at 300 K, and the Parrinello–Rah-
man barostat [67] at 1 bar. These equilibrations are used to obtain an
initial metadynamics-biased transition to initialize the TPS algo-
rithm. For our path-CV simulations, two 100 ns re-equilibrations,
one in WC and one in HG, are performed after changing the force
ﬁeld to parmbsc1 [68], which contains special parameters for DNA.
The same setup is employed for production runs.
4.2
Collective
Variables
Determining a good set of CVs to describe the slow dynamics of a
system is a highly non-trivial problem. For a long time, chemical
intuition was the main way to identify geometric order parameters
to describe a molecular transition. Today, state-of-the-art efforts in
automating the discovery of CVs include: the spectral gap optimi-
zation of order parameters (SGOOP) [69], the time-structure
based independent component analysis (tICA) [70], and the har-
monic linear discriminant analysis (HLDA) [71]. Regardless of the
method for choosing CVs, one big advantage of the path approach
is that it enables to use a large set of CVs (i.e., more than the usual
two or three). We may even have some redundancy or include some
irrelevant CVs, without running immediately into problems. Here,
we constructed the set of CVs after a careful analysis of available
TPS trajectories of the transition and using a trial-and-error
approach at the hand of test runs with steered MD and PMD.
Key aspects aimed for in the test run included: (1) structural con-
sistency of the stable states and (2) of the overall DNA double helix,
(3) consistent capture of the transition mechanism, and (4) mini-
mizing hysteresis effects in the path ﬁnding and free energy estima-
tion. The set contains the following 7 CVs (Fig. 4 for a graphical
illustration):
l
dWC: The distance of the characteristic WC H-bond between
A16 (N1) and T9 (N3).
l
dHG: The distance of the characteristic HG H-bond between
A16 (N7) and T9 (N3).
l
dHB: The distance of the conserved H-bond, present both in
WC and in HG, between A16 (N6) and T9 (O4).
l
dCC: The distance between A16 (C1’) and T9 (C1’).
l
dNB: The distance between the centers of mass P1’ and P2’.
l
tGB: The torsion around the glycosidic bond deﬁned by the
pseudo-dihedral angle formed by the axis A16 (C1’-N9) and
the vectors P2-P1 and P5-P6.
l
tBF: The base-ﬂipping torsion deﬁned by the pseudo-dihedral
angle (P1+P2)-P3-P4-P5.
The ﬁrst two CVs—dWC and dHG—discriminate the H-bond
forming and breaking that distinguishes each of the stable states.
On the other hand, dHB and dCC ensure the alignment and
The Adaptive Path Collective Variable
267

complete forming of both types of bps. By including these CVs in
the path deﬁnition we make sure that the bps are well-formed when
running the biased dynamics, preventing stacking and dislocations.
During the transition without base ﬂipping, dNB represents a slight
displacement of the neighboring bps, which provides the required
space for the rotation of the base. The last two CVs, tGB and tBF,
which have been already introduced in previous work [53, 57],
describe the rotation of the purine base, A16, and its ﬂipping out
the helix, respectively.
Fig. 4 (a) WC bp with graphical representations of the CVs: dWC, dHB, and dCC; (b) HG bp with graphical
representations of the CVs: dHG, dHB, and dCC; (c) A16–T9 bp and its two neighboring bps with graphical
representations of the centers of mass involved in the calculation of CVs: dNB, tGB, and tBF
268
Alberto Pe´ rez de Alba Ortı´z et al.

It should be noted that the deﬁnition of the glycosidic torsion,
tGB, involves the centers of mass of the neighboring bps rather than
just the immediate sugar atoms, as done in refs. 53 and 57. This
alteration was introduced after the observation of sugar and back-
bone perturbations when running biased dynamics. Such deforma-
tions prevent an exact measurement of the base rotation, as the
atoms used as reference also rotate. The extra ﬂexibility that we
observe in DNA can be a consequence of the chosen force ﬁeld, or
of the fact that the sampling is done by evolving dynamics, instead
of minimization steps [53] or restrained windows [57].
Our ﬁnal remark on this CV set concerns the non-periodic
nature of the path-CV. The WC-to-HG transition can occur either
with a clockwise or counter-clockwise rotation around the glyco-
sidic torsion, tGB. However, the current formulation of the path can
only capture one direction, as it does not capture a periodic crossing
from π to  π. This implies that a particular deﬁnition for tGB is also
bound to a speciﬁc kind of rotation. In this chapter, we focus on the
rotation which crosses the zero radian line in our deﬁnition of tGB
(with the A16 six-ring pointing toward A17), as it corresponds to
the MFEP reported in ref. 53, and the second MFEP in ref. 57. We
refer to this rotation as clockwise. In Note 6, further discussion is
provided about possible ways to handle periodic CVs in a path. We
do not contemplate this issue for tBF, which would correspond to
the base opening to the DNA major groove and coming back in the
minor groove. In our deﬁnition, negative values of tBF imply base
ﬂipping to the major groove, while positive values do so to the
minor groove.
4.3
Stable States
Before we can embark on introducing and optimizing a transition
path in CV-space, we need to deﬁne the two stable states. To this
end, we perform two 100 ns equilibration simulations of the WC
and HG states with the parmbsc1 force ﬁeld. The resulting trajec-
tories are stored for analysis using the PLUMED driver (see Note
7). The PLUMED driver is the stand-alone feature of the
PLUMED package, which does not require linking to an MD
code to operate on conﬁgurations generated during a simulation,
but rather operates on conﬁgurations from an input trajectory. This
tool allows us to compute and print CVs from a pre-existent trajec-
tory (.xtc ﬁle). The inclusion of a protein data bank (PDB) ﬁle
[72] is required to provide atomic masses to the PLUMED driver.
We execute:
plumed driver --pdb dna.pdb --mf_xtc traj.xtc --plumed plumed.dat
with the plumed.dat ﬁle, which contains the CV deﬁnitions and
some printing instructions.
# set units
UNITS LENGTH=A TIME=ps ENERGY=kcal/mol
The Adaptive Path Collective Variable
269

# define centers of mass
p1:
CENTER
ATOMS=234,235,237,238,242,243,244,246,247,518,519,521,522,523,524,527,
528,530,531 MASS
p2:
CENTER
ATOMS=456,457,459,461,462,465,466,467,298,299,301,302,303,304,305,307,
308,311,312 MASS
p1p2:
CENTER
ATOMS=234,235,237,238,242,243,244,246,247,518,519,521,522,523,524,527,
528,530,531,456,457,459,461,462,465,466,467,298,299,301,302,303,304,305,307,308,
311,312 MASS
p1_prime: CENTER ATOMS=518,519,521,522,523,524,527,528,530,531 MASS
p2_prime: CENTER ATOMS=456,457,459,461,462,465,466,467 MASS
p3: CENTER ATOMS=505,506,507,508,509 MASS
p4: CENTER ATOMS=473,474,475,476,477 MASS
p5: CENTER ATOMS=486,487,489,490,499 MASS
p6: CENTER ATOMS=490,491,495,499,496,498 MASS
# define CVs
dWC: DISTANCE ATOMS=495,276
dHG: DISTANCE ATOMS=489,276
dHB: DISTANCE ATOMS=275,492
dCC: DISTANCE ATOMS=264,484
dNB: DISTANCE ATOMS=p1_prime,p2_prime
tGB: TORSION VECTOR1=p2,p1 AXIS=484,486 VECTOR2=p5,p6
tBF: TORSION ATOMS=p1p2,p3,p4,p5
# output
PRINT ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF STRIDE=10 FILE=COLVAR
Note that, depending on the MD engine and setup, periodic
boundary conditions (PBC) might need to be treated using the
WHOLEMOLECULES command in PLUMED.
Table 1 shows the average values for the CVs in the stable
states, obtained from this analysis, which will subsequently be
used in the following sections for the location of the two ﬁxed,
initial and ﬁnal, nodes of the path. The path progress parameter, σ,
is equal to 0 in the WC state, and equal to 1 in the HG state.
4.4
Steered MD
We employ steered MD simulations [4, 5] to perform a ﬁrst assess-
ment of the CVs. The goal is to validate whether the CV set
provides an accurate enough descriptor to drive the transition and
Table 1
Average values of the seven CVs in the stable WC and HG states
bp/CV
dWC (A˚ )
dHG (A˚ )
dHB (A˚ )
dCC (A˚ )
dNB (A˚ )
tGB (rad)
tBF (rad)
WC
2.9
6.4
3.0
10.6
7.9
1.5
0.1
HG
5.9
3.0
3.0
9.0
7.8
1.7
0.0
270
Alberto Pe´ rez de Alba Ortı´z et al.

successfully arrive at each of the stable states. From this relatively
fast analysis one can gain already an approximate idea of the shape
of the path curve, the features of the immediate landscape, the
number of required nodes (see Note 8), and the free energy differ-
ence between states.
We start a simulation in the WC state and deﬁne an initial
straight path (that is, a linear interpolation in the CV-space between
the ﬁxed nodes deﬁning the stable states) to the HG state, contain-
ing 50 nodes. No trailing nodes are necessary at this stage, as we do
not pull the system beyond the stable states. We apply a harmonic
restraint on the path, with a force constant of 2000 kcal/mol per
squared normalized path unit. During a simulation of 1 ns, we
gradually, and with a constant velocity, move the center of the
restraint from σ ¼ 0 to σ ¼ 1 . Thus steering the system toward
the ﬁnal HG state. We also include a tube potential with a force
constant of 50 kcal/mol per squared normalized path unit, to keep
the system close to the path. Simultaneously, we update the path
nodes every 0.2 ps, so that the system can ﬁnd its way toward the
transition valley. A short half-life (0.2 ps) increases the path ﬂexibil-
ity; a convenient choice when starting from an uninformed ﬁrst
guess (see Note 9).
We add the following commands to the CV deﬁnitions in the
plumed.dat ﬁle.
# define path-CV
PATHCV LABEL=pcv ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF
GENPATH= 0,50,0,2.9,6.4,3.0,10.6,7.9,1.5,-0.1,5.9,
3.0,3.0,9.0,7.8,-1.7,0.0 HALFLIFE=100 PACE=100
# set tube potential
RESTRAINT LABEL=tube ARG=pcv.z AT=0.0 KAPPA=50.0
# do steered MD
MOVINGRESTRAINT ...
LABEL=steer
ARG=pcv.s
STEP0=50000 AT0=0.00 KAPPA0=2000.0
STEP1=550000 AT1=1.00 KAPPA1=2000.0
... MOVINGRESTRAINT
# output
PRINT ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF,pcv.s,pcv.z,
steer.pcv.s_cntr,steer.bias,steer.work,steer.
force2,tube.bias STRIDE=10 FILE=COLVAR
and start the simulation with the command:
gmx mdrun -plumed plumed
The Adaptive Path Collective Variable
271

Steering along the path successfully achieves the WC-to-HG
transition, as seen in Fig. 5, left. The initial, intermediate, and ﬁnal
structures show a conserved double helix and the bps are properly
H-bonded and aligned. From the two selected projections of the
7-dimensional CV-space (Fig. 5, center and right), characteristic
features of the path can be observed. In particular, we observe the
sampling of the major groove base ﬂipping from the WC state, seen
as a negative value of tBF and an increase of both dWC and dHG. In
the steered MD simulation, the base is driven to ﬂip before com-
pleting a rotation without much base opening. We also note that
the number of nodes (further discussed hereafter) appears adequate
for the transition, as the path can capture the curvature as dictated
by the mechanism, and does not loop or overlap (see Note 8).
The average path obtained after this short steered MD run,
sampling only one crossing between the stable states, is still far from
a converged result. Still, by iteratively repeating this procedure,
feeding the last path optimization of each iteration as the initial
guess of the next, an optimal path can be converged. Furthermore,
by applying the Jarzynski method [5] a free energy difference can
be calculated after collecting enough statistics. However, in this
chapter we will not follow this route and instead continue with the
application of the path-CV with other sampling schemes.
4.5
Metadynamics
After the steered MD simulation, we set out for an exploratory
metadynamics run. We use the multiple-walker PMD approach,
using 16 walkers—8 starting in the WC state and 8 in the HG
state—all probing and updating the same path and biasing poten-
tial. Gaussians with a height of 0.05 kcal/mol and a width of 0.05
normalized path units are deposited every 0.5 ps (see Notes 2 and
10). Since the range of the biased variable is known a priori, it is
easy and computation-efﬁcient to use a grid to store the potential.
−0.4
−0.2
 0
 0.2
 0.4
 0.6
 0.8
 1
 1.2
 1.4
0
200
400
 600
 800  1000  1200
σ
t (ps)
sampled config.
restraint center
−2
−1.5
−1
−0.5
 0
 0.5
 1
 1.5
 2
−2 −1.5 −1 −0.5  0
 0.5
 1
 1.5
 2
tBF (rad)
tGB (rad)
sampled config.
WC
HG
 2
 4
 6
 8
 10
 12
 2
 4
 6
 8
 10
 12
dHG (Å)
dWC (Å)
sampled config.
WC
HG
Fig. 5 Left: time evolution of the path progress parameter, σ (gray) and of the target restraint value (purple)
during the steered MD simulation; Center: sampled conﬁgurations projected onto the torsion angle CVs, tGB
and tBF (gray); Right: sampled conﬁgurations projected onto the distance CVs, dWC and dHG (gray). The stable
states are indicated by crosses
272
Alberto Pe´ rez de Alba Ortı´z et al.

For the initial guess path, we take the same linear interpolation as
used before in the steered MD case, but now add 20 trailing nodes
at the beginning and at the end of the original 50 transition nodes
(see Notes 8 and 11). The path update has a half-life of 1 ps (see
Note 9) and is performed every 0.5 ps (see Note 10). No tube
potential is set, so that the CV-space perpendicular to the path
is sampled freely. Harmonic walls with force constants of 1000
kcal/mol per squared normalized path unit are set on σ to limit
the sampling inside the [0.2,1.2] interval. Similarly, harmonic
walls with a force constant of 1000 kcal/(mol rad2) are set on tGB
to prevent counter-clockwise rotations, which are mapped by the
path as sudden jumps from negative values to values greater than
one. Note that, when putting a wall on a periodic CV, it is necessary
to deﬁne a non-periodic instance of it to avoid force artifacts.
We generate 16 plumed.{ID}.dat ﬁles that include the pre-
vious CV deﬁnitions, followed by:
# define non-periodic tGB
tGB_np: COMBINE ARG=tGB COEFFICIENTS=1. PERIODIC=NO
# define path-CV
P A T H C V
L A B E L = p c v
A R G = d W C , d H G , d H B , d C C , d N B , t G B , t B F
G E N -
PATH=20,50,20,2.9,6.4,3.0,10.6,7.9,1.5,-0.1,5.9,3.0,3.0,9.0,7.8,-1.7,0.0
FIXED=21,70 HALFLIFE=500 PACE=250 WALKERS_RSTRIDE=250 WALKERS_ID={ID} WALK-
ERS_N=16 WALKERS_DIR=.
# do metadynamics
METAD LABEL=metadyn ARG=pcv.s SIGMA=0.05 HEIGHT=0.05 PACE=250 GRID_MIN=-1.0
GRID_MAX=2.0 WALKERS_MPI
# set walls on pcv.s and non-periodic tGB
LOWER_WALLS LABEL=s_lwall ARG=pcv.s AT=-0.2 KAPPA=1000.0
UPPER_WALLS LABEL=s_uwall ARG=pcv.s AT=1.2 KAPPA=1000.0
LOWER_WALLS LABEL=tGB_lwall ARG=tGB_np AT=-2.2 KAPPA=1000.0
UPPER_WALLS LABEL=tGB_uwall ARG=tGB_np AT=2.0 KAPPA=1000.0
#output
PRINT
ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF,pcv.s,pcv.z,metadyn.bias,s_lwall.
bias,s_uwall.bias,tGB_lwall.bias,tGB_uwall.bias STRIDE=10 FILE=COLVAR
and run 16 parallel GROMACS simulations, 8 starting in the WC
state and 8 in the HG state, each with different random Maxwell–-
Boltzmann distributed velocities. The PMD multiple-walker simu-
lation is started with the command:
gmx mdrun -plumed plumed -multi 16
The distribution of the walkers along the path in time (Fig. 6,
left) shows how the deposited Gaussians generate a repulsive effect
The Adaptive Path Collective Variable
273

among the walkers. The walkers quickly de-correlate and sample
different sections of the path. This makes the path updates more
efﬁcient, as most nodes are now sampled and relocated at each path
update. The sampled CV values, illustrated in the middle and right
panels in Fig. 6, show evidence for three competing pathways: one
with a small degree of ﬂipping (tBF  0.5 rad) toward the minor
groove, one with no ﬂipping, and one which opens up to tBF π/
2 rad toward the major groove. Due to the partial overlap of these
three pathways, the PMD simulation does not succeed in converg-
ing to a single average transition path. Instead, the nodes oscillate
between the path of no base ﬂipping and several paths with various
degrees of base opening, which prevents convergence. In the fol-
lowing section, we will show how to converge the path-CV to a
speciﬁc mechanistic pathway.
4.6
Converging
a Path
Starting again from the guess path based on the linear interpolation
between the stable states, we will now aim to converge the path-CV
to a speciﬁc mechanistic transition pathway and its corresponding
free energy proﬁle. To do so, we use a tube potential to control the
sampling in the neighborhood of the path. This restraint prevents
bifurcation, such as that seen in Fig. 6, and maintains all walkers
exploring the same valley. The force constant for the tube, after
several trials, is set to 20 kcal/mol per squared normalized path unit
(see Note 3). The number of walkers is decreased to eight (4 starting
in each stable state), and the Gaussian height to 0.04 kcal/mol, as
smaller and more infrequent increases of the bias potential favor the
ability of metadynamics to overwrite and self-heal a free energy
proﬁle [48]. We also reduce to 500 kcal/mol per squared normal-
ized path unit the force constant of the wall potentials on σ that
restrict the sampling to the [0.2,1.2] range. The rest of the
parameters are the same as in Subheading 4.5. Eight parallel runs
are started with different random Maxwell–Boltzmann distributed
velocities.
−0.4
−0.2
 0
 0.2
 0.4
 0.6
 0.8
 1
 1.2
 1.4
 0
 1000
 2000
 3000
 4000
σ
t (ps)
−2
−1.5
−1
−0.5
 0
 0.5
 1
 1.5
 2
−2 −1.5 −1 −0.5  0
 0.5
 1
 1.5
 2
tBF (rad)
tGB (rad)
WC
HG
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 2
 4
 6
 8  10  12  14  16  18
dHG (Å)
dWC (Å)
WC
HG
−2
−1.5
−1
−0.5
 0
 0.5
 1
tBF (rad)
Fig. 6 Left: time evolution of the path progress parameter, σ, for each of the 16 PMD walkers (green-pink
colormap); Center: sampled conﬁgurations by all walkers projected onto tGB and tBF; Right: sampled
conﬁgurations by all walkers projected onto dWC and dHG. The stable states are indicated by crosses
274
Alberto Pe´ rez de Alba Ortı´z et al.

Similar to before, we observe that the walkers repel each other
and explore different sections of the path (Fig. 7, left). The full
range along the path is sampled, although most walkers do not
actually explore σ over the entire range. The walkers are only able to
diffuse above and below a narrow region close to σ ¼ 0.3 that is not
crossed as much; we will comment on this feature at the end of the
section. The middle and right panels of Fig. 7 show that the
sampling is now mostly focused on a single transition pathway.
The path shows only a very small degree of base ﬂipping toward
the minor groove, and rotates mainly inside of the DNA double
helix, with the bases remaining at a close distance from each other
for the entire transition.
In Fig. 8, we show the sampling along the path projected onto
each of the 7 CVs. Apart from the slight ﬂipping to the minor
groove seen from tBF, we observe an increase in the neighboring bp
distance, dNB, to provide space for the rotation. The H-bond
distances, dWC, dHG, and dHB, as well as the inter-strand C1’–C1’
distance, dCC, show that the bp is well-formed and aligned during
the sampling, and that there is no signiﬁcant dislocation of the pair.
The rotation of the adenine, seen from tGB, occurs early in the
transition, as the mid-rotation—which is expected to coincide
with the peak of the free energy barrier—occurs at σ ¼ 0.3. This
is somewhat contradictory with respect to previous work, which
reported a late transition state, more similar in structure to the HG
state [55, 57]. The discrepancy with our results can be explained
either by the different force ﬁeld, or by our redeﬁnition of the
glycosidic torsion CV, tGB, which is based on centers of mass, rather
than single atomic positions (Subheading 4.2).
The convergence of the path-CV to the found transition path is
rather robust and invariant upon modest variations of the PMD
parameters. Reduction of the height of the Gaussian height from
−0.4
−0.2
 0
 0.2
 0.4
 0.6
 0.8
 1
 1.2
 1.4
 0
 1000
 2000
 3000
 4000
σ
t (ps)
−2
−1.5
−1
−0.5
 0
 0.5
 1
 1.5
 2
−2 −1.5 −1 −0.5  0
 0.5
 1
 1.5
 2
tBF (rad)
tGB (rad)
sampled config.
path at t=3500 ps
WC
HG
 2
 3
 4
 5
 6
 7
 8
 2
 3
 4
 5
 6
 7
 8
dHG (Å)
dWC (Å)
sampled config.
path at t=3500 ps
WC
HG
Fig. 7 Left: time evolution of the path progress parameter, σ, for each of the 8 PMD walkers (in colors);
Center: sampled conﬁgurations by all walkers projected onto tGB and tBF (gray), and the optimized path
(purple) with trailing nodes (black); Right: sampled conﬁgurations by all walkers projected onto dWC and dHG
(gray), and the optimized path (purple) with trailing nodes (black). The stable states are indicated by crosses
The Adaptive Path Collective Variable
275

2.0
4.0
6.0
8.0
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
dWC (Å)
node
2.0
4.0
6.0
8.0
dHG (Å)
2.0
3.0
4.0
5.0
dHB (Å)
8.0
10.0
12.0
dCC (Å)
6.0
8.0
10.0
12.0
dNB (Å)
−2.0
0.0
2.0
tGB (rad)
−0.4
0.0
0.4
−0.4 −0.2
 0
 0.2  0.4  0.6  0.8
 1
 1.2  1.4
tBF (rad)
σ
Fig. 8 Sampled conﬁgurations by the 8 PMD walkers projected onto each of the
7 CVs and σ (gray), and the optimized path nodes for each CV (in colors)
276
Alberto Pe´ rez de Alba Ortı´z et al.

0.04 to 0.02 kcal/mol leads to a slower buildup of the bias poten-
tial and, with that, a slower diffusion over the path, but the same
mechanism is found. Increasing the number of nodes from 50 to
70 makes the path-CV somewhat more ﬂexible, but the ﬁnal result
is not different (interestingly, increasing the number of trailing
nodes from 20 to 30 causes them to capture the pathway with
base ﬂipping toward the major groove, described in Subheading
4.5, while the transition nodes remain in the same path with no bp
opening; a behavior pointed out in Note 11). Finally, increasing
the force constant of the harmonic tube potential from 20 to
30 kcal/mol per squared normalized path unit still leads to the
same results; however, a decrease to 10 kcal/mol per squared
normalized path unit is not restrictive enough to prevent bifurca-
tions to other pathways, which hinders the convergence.
To assess the convergence of the path-CV, we show in Fig. 9
the time evolution of the distance of the system from its projection
onto the path in CV-space, jjzk  stiðσðzkÞÞjj, averaged over the
walkers. At the start of the simulation, we observe peaks at both
stable states, as the walkers attempt to ﬁnd their way out of the
basins. Next, we observe smaller peaks up to around 1200 ps,
corresponding to the ﬁrst crossings of the walkers. Eventually, as
the path adapts to the sampled transition density, the sampled
distance from the path continues to decrease. The convergence of
PMD can also be assessed by the time evolution of the root-mean-
 0
 500  1000 1500 2000 2500 3000 3500 4000 −0.4
−0.2
 0
 0.2
 0.4
 0.6
 0.8
 1
 1.2
 1.4
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
t (ps)
σ
weighted average distance to the path
Fig. 9 Time evolution of the distance from the path, jjzk  st iðσðzkÞÞjj, with
respect to the path progress parameter, σ, averaged over the 8 PMD walkers.
The color map on the z-axis shows the average distance from the path,
jjzk  st iðσðzkÞÞjj, weighted according to the inverse distance to the grid points
The Adaptive Path Collective Variable
277

square deviation (RMSD) of the path, as well as of the free energy
proﬁle, with respect to some references (e.g., the initial linearly
interpolated path and ﬂat proﬁle). Increasingly smaller RMSD
changes reﬂect a convergent simulation, as shown in ref. 41.
Although the path is seen to nicely converge, the estimation of
the free energy proﬁle along the path is not as well-behaved. Gen-
erally, there are several approaches to converge the free energy
estimation of a metadynamics simulation. One can gradually reduce
the height of the Gaussian potentials after each recrossing [37], or
use the well-tempered approach [2, 3] to reduce the Gaussian size
in an automatic manner, or one can compute a running average of
the free energy starting from the moment of the ﬁrst recrossing
back to the initial state [41] (see Note 1). First, however, we check
for hysteresis in the construction of the metadynamics bias poten-
tial, which would be an indication that our set of CVs is incomplete,
or that the path-CV has not properly converged to the average
transition path. Unfortunately, we indeed observe hysteresis in the
time evolution of the bias potential, despite our rather extensive set
of CVs to describe the base-rotation transition. This hysteresis
explains the already observed depletion around σ ¼ 0.3 in Fig. 7
(left), which indicated the difﬁculty of all walkers to cross from WC
to HG, and vice versa, even after the minima had been ﬁlled. The
hysteresis is even more evident in a single walker metadynamics run
along the ﬁxed optimized path: during each crossing, the minima
are over-ﬁlled and the previously constructed proﬁle becomes again
undone. By analyzing the structures before and after crossing, we
hypothesize that our CV set is missing a CV describing a large-scale
conformational change in the DNA strands. This is consistent with
the tilting and rotation of DNA chains around HG bps reported in
ref. 56. To test this possibility, we restrain the position of all DNA
atoms except for those in the rotating bp and its immediate neigh-
boring bps, and run metadynamics along the optimized path. Now,
we observe that the system is unable to cross from one state to the
other, until eventually the simulation crashes due to too high forces
on the atoms. In this manner of (1) monitoring for hysteresis,
(2) comparing conﬁgurations before and after crossing, and
(3) testing candidate “hidden CVs” by constraining them, we can
systematically discover the essential CVs to describe the process.
Further PMD simulations with a more extensive set of CVs are
described in a forthcoming publication, in which we focus on the
mechanistic, thermodynamic, and kinetic details of the WC-to-HG
transition and their DNA sequence-dependence. For this chapter
instead, we proceed with two other illustrations of the path-CV: in
an umbrella sampling simulation and in an a posteriori path
optimization.
In this section, we compute the free energy proﬁle of the WC-to-
HG transition, using the path-CVoptimized in the previous section
278
Alberto Pe´ rez de Alba Ortı´z et al.

4.7
Umbrella
Sampling
in combination with umbrella sampling simulations. By dividing
the sampling into regions along a CV (here, the path progress
parameter, σ) using window potentials, umbrella sampling is less
sensitive to hysteresis due to a “hidden CV” (i.e., an imperfect
reaction coordinate) than metadynamics due to the dynamic nature
of the latter. Of course, the resulting free energy would still suffer
from the incomplete description of the process, giving a too low
barrier, which would become evident in an a posteriori transmission
coefﬁcient calculation or a committor analysis.
We run ten, 20 ns long, umbrella sampling simulations. The
harmonic window potentials are placed at every 0.1 normalized
path units to restrain the sampling to different regions along the
optimized path, from σ ¼ 0 to σ ¼ 1. The initial molecular struc-
tures for each window are obtained via steered MD along the
optimized path. The force constants for the window potentials are
of 2000 kcal/mol per squared normalized path unit. An additional
window at σ ¼ 0.34 was added to ﬁll a gap in the distribution
overlap. We also apply a tube potential with a force constant of
30 kcal/mol per squared normalized path unit.
The PLUMED input ﬁle for the path-CV umbrella sampling
simulations is as follows:
# define path-CV
PATHCV LABEL=pcv ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF
INFILE=PMD_path.input HALFLIFE=-1 PACE=0
# set tube potential
RESTRAINT LABEL=tube ARG=pcv.z AT=0.0 KAPPA=30.0
# set umbrella
RESTRAINT LABEL=umbrella ARG=pcv.s AT={WINDOW} KAPPA=2000.0
# output
PRINT ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF,pcv.s,pcv.z,
umbrella.bias,tube.bias STRIDE=10 FILE=COLVAR
To construct the free energy proﬁle, we apply WHAM [44] to
the last 10 ns of each simulation. The result, shown in Fig. 10,
conﬁrms the early barrier (σ ¼ 0.3) already observed in the PMD
simulation, which coincides with the halfway point of the base
rotation (Fig. 8). An indistinct metastable state can be identiﬁed
at σ ¼ 0.7, which signiﬁes the completion of the base rotation, but
with the HG bp still not fully aligned.
Here we performed the umbrella sampling along a ﬁxed path
that was already optimized with PMD. But of course, the path can
also be evolved with umbrella sampling using multiple walkers; the
The Adaptive Path Collective Variable
279

required PLUMED keywords to do so are found in Subheadings
4.5 and 4.6.
4.8
A Posteriori Path
Optimization
As a ﬁnal illustration of optimizing the adaptive path-CV to ﬁnd a
transition mechanism, we will employ the path-CV as an a poster-
iori analysis tool on a pre-existing trajectory (see Note 12). Of
course, this trajectory should contain conﬁgurations from at least
one transition between two stable states, for example, from a very
long (or very lucky) brute-force MD or Monte Carlo simulation, or
from an enhanced sampling simulation. Here, we will analyze a
reactive trajectory obtained from a TPS simulation [59], and opti-
mize a path for one WC-to-HG transition involving the base open-
ing to the major groove (described in more detail in Subheading
4.5). We start with a straight path and use the PLUMED driver to
optimize it using the trajectory as input. The driver can compute
and print CVs, and, for the current purpose, also compute the
distance to the path-CV in each trajectory frame to optimize the
path. Typically, a single run of the PLUMED driver over the
trajectory is not enough to converge the path-CV. But by running
the driver several times on the trajectory, while every time providing
the previously optimized path as the initial guess for the next run,
the path-CV can be optimized efﬁciently in a few iterations.
The plumed.dat ﬁle contains the CV deﬁnitions and the
following commands:
#INIT
PATHCV
LABEL=pcv
ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF
GEN-
PATH=0,50,0,2.9,6.4,3.0,10.6,7.9,1.5,-0.1,5.9,3.0,3.0,9.0,7.8,-1.7,0.0
SCALE=0.1,0.1,0.1,0.3,0.2,0.6,0.5 HALFLIFE=250 PACE=100 OUTFILE=path.out
#RESTART PATHCV LABEL=pcv ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF INFILE=path.input
SCALE=0.1,0.1,0.1,0.3,0.2,0.6,0.5 HALFLIFE=250 PACE=100 OUTFILE=path.out
PRINT ARG=dWC,dHG,dHB,dCC,dNB,tGB,tBF,pcv.s,pcv.z STRIDE=1 FILE=colvar.out
0
 4
 8
 12
 16
 20
0
0.2
0.4
0.6
0.8
1
FE (kcal/mol)
σ
Fig. 10 WHAM free energy proﬁle obtained from the umbrella sampling simula-
tions along the WC-to-HG path without base ﬂipping optimized by PMD
280
Alberto Pe´ rez de Alba Ortı´z et al.

and we execute a simple bash script to automate the iterative
procedure for optimizing the path-CV with the PLUMED driver:
#!/bin/bash
# run first optimization
sed ’s/#INIT//’ plumed.dat > plumed.input
plumed driver --pdb dna.pdb --mf_xtc traj.xtc --
plumed plumed.input
# do 100 iterations
for (( i=0; i<100; i++ )); do
# set last optimized path as input
tail -56 path.out > path.input
# save input and output files
cp path.input path.input_$i
mv path.out path.out_$i
# run optimization
sed ’s/#RESTART//’ plumed.dat > plumed.input
plumed driver --pdb dna.pdb --mf_xtc traj.xtc --
plumed plumed.input
done
# clean up
mv path.out path.out_$i
rm bck.*
After 100 iterations a good ﬁt is obtained for all CVs. Notice that
this simulation was done without a tube, which explains the ﬂuc-
tuating sampling (Fig. 11).
To obtain the free energy along the optimized path, we use
umbrella sampling, similar as we did before for the mechanism
without base ﬂipping found by PMD. Harmonic window potentials
are placed at every 0.1 normalized path units, from σ ¼ 0 to σ ¼ 1,
with force constants of 2000 kcal/mol per squared normalized path
unit. Additional windows with the same force constant are placed at
σ values of 0.35, 0.65, and 0.95; and with a force constant of 3000
kcal/mol per squared normalized path unit at σ ¼ 0.1.
Figure 12 shows the resulting free energy proﬁle for the base-
ﬂipping transition, which is characterized by additional small bar-
riers close to σ ¼ 0.1 and σ ¼ 0.9. These barriers mark the ﬂipping
of the nucleotide out of, and back into, the conﬁnes of the double
helix. In between these steps, the base rotation takes place. In this
mechanism, the top of the central barrier is not located at the
mid-rotation state, but to a stage in which the base starts to
The Adaptive Path Collective Variable
281

5.0
10.0
15.0
20.0
 0
 10
 20
 30
 40
 50
dWC (Å)
node
5.0
10.0
15.0
20.0
dHG (Å)
5.0
10.0
15.0
20.0
dHB (Å)
8.0
10.0
12.0
14.0
16.0
dCC (Å)
6.0
7.0
8.0
9.0
10.0
dNB (Å)
−2.0
0.0
2.0
tGB (rad)
−1.5
−1.0
−0.5
0.0
 0
 0.2
 0.4
 0.6
 0.8
 1
tBF (rad)
σ
Fig. 11 Sampled conﬁgurations by the TPS trajectory projected onto each of the
7 CVs and σ (gray), and the optimized path nodes for each CV (in colors)
282
Alberto Pe´ rez de Alba Ortı´z et al.

re-enter into the double helix. As expected, the H-bond distances
between bps, dWC, dHG, and dHB, increase more than in the mech-
anism without base opening, and the distance of the neighboring
bps, dNB, does not play a role. The inconsistency in the free energy
difference between the WC and HG states in both proﬁles could be
a consequence of the missing CV related to the DNA large-scale
motion.
The free energy barriers for both mechanisms—with and with-
out base ﬂipping—are similar according to our calculations. This
differs from previous results [53, 57], and is likely rooted in the
chosen force ﬁeld and the different CV deﬁnitions. The similarity of
the barriers, and the greater depth and width of the WC basin,
explains the base opening escapades observed both in steered MD
and metadynamics simulations. For a system starting in the WC
basin, it is indeed more favorable to climb the ﬁrst base-ﬂipping
barrier, rather than the base-rotation one. It is not until later in the
pathway that the barrier of the base-ﬂipped mechanism becomes
higher. On the other side, for a system starting in the HG valley,
base rotation without opening is consistently the most favorable
mechanism.
Naturally, the path-CV can be adapted for the other transition
mechanisms, either on the ﬂy or by a posteriori optimization. In
search for other transition channels, one can fully exploit the versa-
tility of the path-CV, and of the enhanced sampling methods
applied to it. Moreover, the WC-to-HG transition in DNA contains
a complexity due to the involvement of various local and non-local
degrees of freedom that is rather common to conformational
changes in biomolecules and bio-assemblies. In that sense, we
believe that the path-CV framework is a promising tool to unravel
the mechanisms and obtain the free energy proﬁles of all sorts of
biomolecular phenomena (see Note 13).
 0
 4
 8
 12
 16
 20
 0
 0.2
 0.4
 0.6
 0.8
 1
FE (kcal/mol)
σ
no base−flipping path
base−flipping path
Fig. 12 WHAM free energy proﬁles obtained from umbrella sampling simulations along WC-to-HG transition
paths with and without base ﬂipping
The Adaptive Path Collective Variable
283

5
Notes
1. It is a common practice in metadynamics to gradually reduce
the Gaussian height to converge a free energy proﬁle. This can
be done manually after each recrossing on the path, or via the
well-tempered method. When using the latter option, one
should use a somewhat larger bias factor than advertised for
“normal” (non-adaptive) CVs, because path optimization
requires generally the sampling of several barrier crossings,
before which the Gaussian height should not have already
been reduced too much. In our experience, a well-tempered
bias factor of around 10–15 times the height of the barrier is a
working choice. Another very interesting option is to use
transition-tempered metadynamics (TTMetaD), a method
that ﬁrst ﬁlls the valleys in a non-tempered phase, and then
converges
the
free
energy
proﬁle
in
a
well-tempered
fashion [73].
2. When using multiple-walker metadynamics, it is always recom-
mended to keep Gaussians narrow and small. Otherwise, we
risk the walkers not actually exploring the underlying free
energy proﬁle, but only feeling each other’s repulsive poten-
tials. This can be assessed by analyzing the diffusion of σ over
time for all walkers. There should indeed be some repulsion,
but also crossings between walkers.
3. The tube potential is a convenient handle to temper a too
ﬂexible path evolution and to restrict the sampling to a speciﬁc
transition pathway by blocking bifurcations. However, it
should be noted that, as long as the path is not yet optimal,
the tube potential acts as an additional hurdle, forcing the
system to cross outside the intrinsic transition valley. Secondly,
after the path optimization is converged, the tube potential
affects the sampling of the degrees of freedom orthogonal to
the path, thus affecting the entropic contribution to the proﬁle.
This biasing by a tube potential can be relaxed somewhat by
setting
the
harmonic
wall
at
a
non-zero
value
of
jjzk  stiðσðzkÞÞjj. In this spirit, it can be convenient to ﬁrst
measure the widths of the stable state basins, and then use
this to set a tube potential that does not affect the stable state
valleys.
4. Scaling of CV-space can be done once the range of each CV
during the transition is known. We simply calculate each scaling
factor as 1/(zi,max  zi,min) for each CV, zi.
5. One can use multiple walkers to continuously explore all
regions of the path and avoid the reparameterization step
from undoing the node optimization in temporarily unsampled
regions. When doing this, it is recommended to have at least as
284
Alberto Pe´ rez de Alba Ortı´z et al.

many walkers as expected stable and metastable states along the
path. Another very interesting way to use multiple walkers is to
include a dummy walker—which updates the path, but not the
metadynamics
bias—restrained
to
a
particular
point
in
CV-space. Thus, we can ﬁnd the optimal path which crosses
that region.
6. The current numerical implementation of the path-CV does
not support periodic crossings. This implies that periodic CVs
must always be handled in a speciﬁc direction. An alternative
way to circumvent this is to map the periodic CV to its sine and
cosine, and include those two in the path-CV. In this way, the
periodic movement can be represented by a curve in the given
2D space. Nevertheless, one should be cautious when
performing metadynamics on this CV set, as the hard boundary
of the sine and cosine can generate artifacts.
7. It is highly recommended to save the trajectory ﬁles of the
equilibration runs in each stable state. In this way, they can
always be re-analyzed using the PLUMED driver tool. After
adding a new CV, we can quickly determine the location and
width of the stable state basins in the new CV-space.
8. Determining a good number of nodes to capture a transition is
a trial-and-error procedure. As a rule of thumb, one can start
with a small number of transition nodes (20–30). If the result-
ing curve is able to capture all CV ﬂuctuations of the transition,
then one has succeeded. Otherwise, one can gradually add
more nodes until all features of the transition are represented.
In general, the path is resilient to changes in this parameter. We
have increased the number of transition nodes up to 40%
without affecting the ﬁnal result. However, when too many
nodes are added, the path tends to coil or loop around the
stable states, and oscillate excessively around small ﬂuctuations
of the CVs [41].
9. There is no satisfactory default value for the half-life parameter.
The general rule of thumb is to start with a relatively short half-
life if the initial guess path is likely to be outside the intrinsic
transition valley, and then switch to a large value, possibly even
to inﬁnite, once the (neighborhood of the) intrinsic transition
valley is found. However, a too small half-life may yield a very
ﬂexible and dynamical evolution, which leads to curvy paths
that do not guide the biased system over the transition barrier.
With a too large half-life, the path evolves evermore slowly
during the simulation, as each newly sampled transition density
weights less due to the ever-growing history of previous sam-
ples. To check whether the path has stopped evolving because
of the large half-life, or because it has actually found the transi-
tion valley, one should analyze the time evolution of the node
weights from the path output ﬁles. If very large weight values
The Adaptive Path Collective Variable
285

appear early on in the simulation, a shorter half-life is probably
needed.
10. In a PMD simulation, the parameters for the Gaussian deposi-
tion pace and the path update pace should be somewhat bal-
anced for optimal efﬁciency. Setting a high metadynamics
deposit frequency with a low path update frequency leads to
many recrossings before ﬁnding an optimum path, while at the
same time the initial crossings may take place at high-energy
states outside the intrinsic transition valley. On the other hand,
if one sets a slow metadynamics deposit pace and a high path
update frequency, it may take a long time for the barrier
crossing to occur, but it will most likely take place over paths
that are already close to optimal. Note that the effect of increas-
ing the metadynamics deposit frequency is generally the same
as increasing the size of the Gaussian potentials. A sensible
initial setup is to have the same pace for the metadynamics
deposit frequency and for the path updates; the Gaussian
height can be set to around two orders of magnitude less
than the expected barrier (generally smaller than kBT to allow
for self-healing) and the width to around 0.05 normalized path
units. Then, the path ﬂexibility can be controlled using the
half-life parameter.
11. Typically, we set a small number of additional trailing nodes
(10–20), as we require just enough of them to capture the
valleys at both ends of the path. However, sometimes the
trailing nodes can be exploited in other clever ways. For exam-
ple, one can intentionally direct them to steep regions in the
free energy landscape and get a natural wall effect to restrain
the sampling. This works as long as the trailing nodes are not
relocated. Alternatively, one can have the trailing nodes probe a
secondary relevant transition channel. We have performed
simulations on other systems, in which the transition nodes
capture the optimal path, while the trailing nodes fall into the
second optimal path (although both ends do not touch and
therefore that second path is not fully captured). In these cases,
care must be taken that the trailing nodes do not approach the
primary channel of the transition nodes. If this occurs, points in
CV-space lying close to both sets of nodes can be suddenly
mapped from one σ value to the other, leading to ill-deﬁned
sampling. In some calculations where the sampling does not go
beyond the stable basins (as we saw in the application of steered
MD), trailing nodes are not needed.
12. A posteriori path optimization can be a very powerful tool
when a TPS ensemble is already available. We collaborated
with the developers of the OpenPathSampling (OPS) Python
library [74, 75], to include a PLUMED patch that enables the
286
Alberto Pe´ rez de Alba Ortı´z et al.

integrated use of the path-CV, as well as the rest of the
PLUMED CVs [76].
13. In this chapter, we focused our attention on a non-chemical,
conformational transition, modeled by classical MD simula-
tion. However, applications that require quantum mechanical
simulations (e.g., density functional theory (DFT) MD as
implemented in Car–Parrinello MD or Born–Oppenheimer
MD) may also beneﬁt highly from the use of a path-CV. The
computationally costly dynamics can be focused on a speciﬁc
chemical transition of interest. In addition, physical insight can
be extracted from the properties of the system along the opti-
mized path [41].
Acknowledgements
We wish to acknowledge our fellow group members Peter
G. Bolhuis and David W. H. Swenson for their previous TPS
work on the DNA WC-to-HG transition. They provided us with
readied structures and MD protocols, as well as valuable and moti-
vating comparison and discussion points. We also acknowledge
Davide Branduardi for his support in coding the ﬁrst version of
the PMD method in PLUMED. We thank the Mexican National
Council for Science and Technology (CONACYT), which provided
funding for Alberto Pe´rez de Alba Ortı´z during his PhD research at
the University of Amsterdam.
References
1. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci USA 99
(20):12562–12566
2. Barducci A, Bussi G, Parrinello M (2008) Well-
tempered metadynamics: a smoothly converg-
ing and tunable free-energy method. Phys Rev
Lett 100(2):020603
3. Bonomi M, Barducci A, Parrinello M (2009)
Reconstructing the equilibrium Boltzmann
distribution
from
well-tempered
metady-
namics. J Comput Chem 30:1615–1621
4. Grubmu¨ller H, Heymann B, Tavan P (1996)
Ligand binding: molecular mechanics calcula-
tion of the streptavidin-biotin rupture force.
Science 271(5251):997–999
5. Jarzynski C (1997) Nonequilibrium equality
for free energy differences. Phys Rev Lett 78
(14):2690
6. Torrie GM, Valleau JP (1977) Nonphysical
sampling distributions in Monte Carlo free-
energy estimation: umbrella sampling. J Com-
put Phys 23(2):187–199
7. Darve E, Pohorille A (2001) Calculating free
energies using average force. J Chem Phys
115:9169
8. Carter EA, Ciccotti G, Hynes JT, Kapral R
(1989)
Constrained
reaction
coordinate
dynamics for the simulation of rare events.
Chem Phys Lett 156:472
9. den Otter WK, Briels WJ (1998) The calcula-
tion of free-energy differences by constrained
molecular dynamics simulations. J Chem Phys
109:4139
10. Huber T, Torda A, van Gunsteren W (1994)
Local elevation: a method for improving the
searching properties of molecular dynamics sim-
ulation. J Comput Aided Mol Des 8:695–708
11. Grubmu¨ller H (1995) Predicting slow struc-
tural transitions in macromolecular systems:
conformational ﬂooding. Phys Rev E 52:2893
12. Voter A (1997) Hyperdynamics: accelerated
molecular dynamics of infrequent events. Phys
Rev Lett 78:3908
The Adaptive Path Collective Variable
287

13. Babin V, Roland C, Sagui C (2008) Adaptively
biased molecular dynamics for free energy cal-
culations. J Chem Phys 128:134101
14. Wang F, Landau DP (2001) Efﬁcient, multiple-
range random walk algorithm to calculate the
density of states. Phys Rev Lett 86:2050
15. Hansmann UH (1997) Parallel tempering
algorithm
for
conformational
studies
of
biological molecules. Chem Phys Lett 281
(1):140–150
16. Sugita Y, Okamoto Y (1999) Replica-exchange
molecular dynamics method for protein fold-
ing. Chem Phys Lett 314:141–151
17. Berg B, Neuhaus T (1992) Multicanonical
ensemble: a new approach to simulate ﬁrst-
order phase transitions. Phys Rev Lett 68:9–12
18. Maragliano L, Vanden-Eijnden E (2006) A
temperature accelerated method for sampling
free energy and determining reaction pathways
in rare events simulations. Chem Phys Lett
426:168–175
19. Kirkpatrick S, Gelatt C, Vecchi M (1983) Opti-
mization
by
simulated
annealing.
Science
220:671–680
20. Sorensen M, Voter A (2000) Temperature-
accelerated dynamics for simulation of infre-
quent events. J Chem Phys 112:9599–9606
21. Rosso L, Minary P, Zhu Z, Tuckerman M
(2002) On the use of the adiabatic molecular
dynamics technique in the calculation of free
energy proﬁles. J Chem Phys 116:4389–4402
22. Dellago C, Bolhuis PG, Csajka FS, Chandler D
(1998) Transition path sampling and the calcu-
lation of rate constants. J Chem Phys 108
(5):1964–1977
23. Bolhuis PG, Chandler D, Dellago C, Geissler
PL (2002) Transition path sampling: throwing
ropes over rough mountain passes, in the dark.
Annu Rev Phys Chem 53:291
24. Weinan E, Ren W, Vanden-Eijnden E (2002)
String method for the study of rare events.
Phys Rev B 66(5):052301
25. Weinan E, Ren W, Vanden-Eijnden E (2005)
Finite temperature string method for the study
of
rare
events.
J
Phys
Chem
B
109
(14):6688–6693
26. Maragliano L, Fischer A, Vanden-Eijnden E,
Ciccotti G (2006) String method in collective
variables: minimum free energy paths and iso-
committor
surfaces.
J
Chem
Phys
125
(2):024106
27. Vanden-Eijnden E, Venturoli M (2009) Revi-
siting the ﬁnite temperature string method for
the calculation of reaction tubes and free ener-
gies. J Chem Phys 130(19):194103
28. Jo´nsson H, Mills G, Jacobsen KW (1998)
Nudged elastic band method for ﬁnding mini-
mum energy paths of transitions. In: Berne B,
Ciccotti G, Coker DF (eds) Classical and quan-
tum dynamics in condensed phase simulations.
World Scientiﬁc, Singapore, pp 385–404
29. Crooks GE, Chandler D (2001) Efﬁcient tran-
sition path sampling for nonequilibrium sto-
chastic dynamics. Phys Rev E 64:026109
30. Van Erp TS, Moroni D, Bolhuis PG (2003) A
novel path sampling method for the calculation
of rate constants. J Chem Phys 118:7762
31. Faradjian AK, Elber R (2004) Computing time
scales from reaction coordinates by mileston-
ing. J Chem Phys 120:10880
32. Allen RJ, Frenkel D, ten Wolde PR (2006)
Simulating rare events in equilibrium or non-
equilibrium stochastic systems. J Chem Phys
124:94111
33. Branduardi D, Gervasio FL, Parrinello M
(2007) From A to B in free energy space. J
Chem Phys 126:054103
34. Pan AC, Sezer D, Roux B (2008) Finding
transition pathways using the string method
with swarms of trajectories. J Phys Chem B
112(11):3432–3440
35. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for beta hairpin
folding from combined parallel tempering and
metadynamics.
J
Am
Chem
Soc
128:13435–13441
36. Piana S, Laio A (2007) A bias-exchange
approach to protein folding. J Phys Chem B
111:4553–4559
37. Dı´az Leines G, Ensing B (2012) Path ﬁnding
on high-dimensional free energy landscapes.
Phys Rev Lett 109(2):020601
38. Gallet GA, Pietrucci F, Andreoni W (2012)
Bridging static and dynamical descriptions of
chemical reactions: an ab initio study of CO2
interacting with water molecules. J Chem The-
ory Comput 8:4029–4039
39. Pietrucci F, Saitta AM (2015) Formamide reac-
tion network in gas phase and solution via a
uniﬁed theoretical approach: toward a reconcil-
iation of different prebiotic scenarios. Proc
Natl Acad Sci USA 112:15030–15035
40. Chen C (2017) Fast exploration of an optimal
path on the multidimensional free energy sur-
face. PLoS One 12(5):e0177740
41. Pe´rez
de
Alba
Ortı´z
A,
Tiwari
A,
Puthenkalathil R, Ensing B (2018) Advances
in enhanced sampling along adaptive paths of
collective
variables.
J
Chem
Phys
149
(7):072320
42. Tribello
GA,
Bonomi
M,
Branduardi
D,
Camilloni C, Bussi G (2014) PLUMED 2:
288
Alberto Pe´ rez de Alba Ortı´z et al.

new feathers for an old bird. Comput Phys
Commun 185(2):604–613
43. Raiteri P, Laio A, Gervasio FL, Micheletti C,
Parrinello M (2006) Efﬁcient reconstruction of
complex free energy landscapes by multiple
walkers metadynamics. J Phys Chem B 110
(8):3533–3539
44. Grossﬁeld A (2013) WHAM: the weighted his-
togram analysis method, version 2.0.9. http://
membrane.urmc.rochester.edu/content/
wham
45. Ferrario M, Ciccotti G, Binder K (2007) Com-
puter simulations in condensed matter: from
materials to chemical biology, vol 1. Springer,
Berlin
46. Onsager L (1938) Initial recombination of
ions. Phys Rev 54(8):554
47. Bolhuis PG, Dellago C, Chandler D (2000)
Reaction coordinates of biomolecular isomeri-
zation.
Proc
Natl
Acad
Sci
USA
97
(11):5877–5882
48. Ensing B, Laio A, Parrinello M, Klein ML
(2005) A recipe for the computation of the
free energy barrier and the lowest free energy
path of concerted reactions. J Phys Chem B
109(14):6676–6687
49. Berendsen HJC, van der Spoel D, van Drunen
R (1995) GROMACS: a message-passing par-
allel
molecular
dynamics
implementation.
Comput Phys Commun 91(1–3):43–56
50. Williams T, Kelley C et al (2013) Gnuplot 4.6:
an
interactive
plotting
program.
http://
gnuplot.sourceforge.net/
51. Watson JD, Crick FH et al (1953) Molecular
structure
of
nucleic
acids.
Nature
171
(4356):737–738
52. Hoogsteen K (1959) The structure of crystals
containing a hydrogen-bonded complex of
1-methylthymine and 9-methyladenine. Acta
Crystallogr 12(10):822–823
53. Nikolova EN, Kim E, Wise AA, O’Brien PJ,
Andricioaei I, Al-Hashimi HM (2011) Tran-
sient Hoogsteen base pairs in canonical duplex
DNA. Nature 470(7335):498–502
54. Nikolova EN, Zhou H, Gottardo FL, Alvey
HS, Kimsey IJ, Al-Hashimi HM (2013) A his-
torical account of Hoogsteen base-pairs in
duplex DNA. Biopolymers 99(12):955–968
55. Alvey
HS,
Gottardo
FL,
Nikolova
EN,
Al-Hashimi HM (2014) Widespread transient
Hoogsteen
base-pairs
in
canonical
duplex
DNA with variable energetics. Nat Commun
5:4786
56. Zhou
H,
Hintze
BJ,
Kimsey
IJ,
Sathyamoorthy B, Yang S, Richardson JS,
Al-Hashimi HM (2015) New insights into
Hoogsteen base pairs in DNA duplexes from
a structure-based survey. Nucleic Acids Res 43
(7):3420–3433
57. Yang C, Kim E, Pak Y (2015) Free energy
landscape and transition pathways from Wat-
son–Crick to Hoogsteen base pairing in free
duplex
DNA.
Nucleic
Acids
Res
43
(16):7769–7778
58. Chakraborty D, Wales DJ (2017) Energy land-
scape and pathways for transitions between
Watson–Crick and Hoogsteen base pairing in
DNA. J Phys Chem Lett 9(1):229–241
59. Vreede J, Bolhuis PG, Swenson DW (2016)
Predicting the mechanism and kinetics of the
Watson-Crick to Hoogsteen base pairing tran-
sition. Biophys J 110(3):563a–564a
60. Vreede J, Bolhuis PG, Swenson DW (2017)
Path sampling simulations of the mechanisms
and rates of transitions between Watson-Crick
and Hoogsteen base pairing in DNA. Biophys J
112(3):214a
61. Macke TJ, Case DA (1998) Modeling unusual
nucleic acid structures. In: Leontes NB, Santa-
Lucia J Jr (eds) Molecular modeling of nucleic
acids. American Chemical Society, Washington,
DC, pp 379–393
62. Jorgensen WL, Chandrasekhar J, Madura JD,
Impey RW, Klein ML (1983) Comparison of
simple potential functions for simulating liquid
water. J Chem Phys 79:926–935
63. Duan Y, Wu C, Chowdhury S, Lee MC,
Xiong G, Zhang W, Yang R, Cieplak P,
Luo R, Lee T, Caldwell J, Wang J, Kollman P
(2003) A point-charge force ﬁeld for molecular
mechanics simulations of proteins based on
condensed-phase quantum mechanical calcula-
tions. J Comput Chem 24:1999–2012
64. Darden T, York D, Pedersen L (1993) Particle
mesh Ewald: an NLog(N) method for Ewald
sums
in
large
systems.
J
Chem
Phys
98:10089–10092
65. Essmann
U,
Perera
L,
Berkowitz
ML,
Darden T, Lee H, Pedersen LG (1995) A
smooth particle mesh Ewald method. J Chem
Phys 103:8577–8593
66. Bussi G, Donadio D, Parrinello M (2007)
Canonical sampling through velocity rescaling.
J Chem Phys 126:014101
67. Parrinello M, Rahman A (1981) Polymorphic
transitions in single crystals: a new molecular
dynamics method. J Appl Phys 52:7182–7190
68. Ivani I, Dans PD, Noy A, Pe´rez A, Faustino I,
Walther J, Andrio P, Gon˜i R, Balaceanu A, Por-
tella G et al (2016) Parmbsc1: a reﬁned force
ﬁeld for DNA simulations. Nat Methods 13
(1):55–58
69. Tiwary P, Berne B (2016) Spectral gap optimi-
zation
of
order
parameters
for
sampling
The Adaptive Path Collective Variable
289

complex molecular systems. Proc Natl Acad Sci
USA 113:2839–2844
70. Sultan
MM,
Pande
VS
(2017)
tICA-
metadynamics: accelerating metadynamics by
using kinetically selected collective variables. J
Chem Theory Comput 13(6):2440–2447
71. Mendels D, Piccini G, Parrinello M (2018)
Collective variables from local ﬂuctuations. J
Phys Chem Lett 9(11):2776–2781
72. Berman
HM,
Westbrook
J,
Feng
Z,
Gilliland G, Bhat TN, Weissig H, Shindyalov
IN, Bourne PE (2000) The Protein Data Bank.
Nucleic Acids Res 28:235–242
73. Dama JF, Rotskoff G, Parrinello M, Voth GA
(2014)
Transition-tempered
metadynamics:
robust, convergent metadynamics via on-the-
ﬂy transition barrier estimation. J Chem The-
ory Comput 10(9):3626–3633
74. Swenson D, Prinz JH, Noe F, Chodera JD,
Bolhuis PG (2019) OpenPathSampling:
a
Python framework for path sampling simula-
tions. I. Basics. J Chem Theory Comput
15:813–836
75. Swenson D, Prinz JH, Noe F, Chodera JD,
Bolhuis PG (2019) OpenPathSampling:
a
Python framework for path sampling simula-
tions.
II.
Building
and
customizing
path
ensembles and sample schemes. J Chem The-
ory Comput 15:837–856
76. Pe´rez de Alba Ortı´z A (2017) PLUMED
Wrapper for OpenPathSampling. https://e-
cam.readthedocs.io/en/latest/Classical-MD-
Modules/modules/OpenPathSampling/ops_
plumed_wrapper/readme.html
290
Alberto Pe´ rez de Alba Ortı´z et al.

Chapter 12
Google-Accelerated Biomolecular Simulations
Kai J. Kohlhoff
Abstract
Biomolecular simulations rely heavily on the availability of suitable compute infrastructure for data-driven
tasks like modeling, sampling, and analysis. These resources are typically available on a per-lab and
per-facility basis, or through dedicated national supercomputing centers. In recent years, cloud computing
has emerged as an alternative by offering an abundance of on-demand, specialist-maintained resources that
enable efﬁciency and increased turnaround through rapid scaling.
Scientiﬁc computations that take the shape of parallel workloads using large datasets are commonplace,
making them ideal candidates for distributed computing in the cloud. Recent developments have greatly
simpliﬁed the task for the experimenter to conﬁgure the cloud for use and job submission. This chapter will
show how to use Google’s Cloud Platform for biomolecular simulations by example of the molecular
dynamics package GROningen MAchine for Chemical Simulations (GROMACS). The instructions readily
transfer to a large variety of other tasks, allowing the reader to use the cloud for their speciﬁc purposes.
Importantly, by using Docker containers, a popular light-weight virtualization solution, and cloud
storage, key issues in scientiﬁc research are addressed: reproducibility of results, record keeping, and the
possibility for other researchers to obtain copies and directly build upon previous work for further
experimentation and hypothesis testing.
Key words Cloud computing, Large-scale simulation, Distributed computing
1
Introduction
Ever-increasing volumes of data obtained both experimentally and
synthetically contain a wealth of information that is often time
consuming to process. Strategies for addressing this challenge
include the scaling of computations across compute clusters and
supercomputers with fast interconnects, the development of dedi-
cated hardware [1, 2], use of highly distributed volunteer-provided
resources [3], and the move to accelerators like general-purpose
graphics processing units [4].
Recent years have seen the emergence of cloud computing as a
new paradigm, with vast compute capacities made available by
providers such as Amazon Web Services, Microsoft Azure, and
Google Cloud Platform (GCP). These platforms enable high-
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_12, © Springer Science+Business Media, LLC, part of Springer Nature 2019
291

performance computing on-demand: virtual machines with as
many as 96 CPU cores and large memory sizes in the hundreds of
Gigabytes to Terabyte range are available.
Cloud computing is particularly useful for embarrassingly par-
allel workloads with large numbers of jobs submitted in batch. In
certain other cases, it is possible to use approaches like sampling and
statistical treatment to adapt a computation to the cloud. An exam-
ple is the identiﬁcation of rare events, such as state transitions in
biomolecular simulations, where unfeasibly long simulations can be
replaced with large numbers of short simulations run in parallel.
Approaches that enable this kind of treatment include Markov state
models [5] and transition path sampling [6].
Apart from adapting a biomolecular simulation to the cloud,
dividing up computations into many parallel jobs also allows more
efﬁcient use of the available cycles across all employed CPU cores.
To illustrate this, consider the common practice of accelerating an
individual long-running simulation by splitting it over many cores:
even on clusters with fast interconnects between CPU nodes or
CPUs with many cores, doing so is met with the law of diminishing
returns. Figure 1 shows the relative speedup for GROningen
MAchine for Chemical Simulations (GROMACS) [7], a highly
optimized multi-core-capable code, for different numbers of Mes-
sage Passing Interface (MPI) parallel threads. Due to the need for
frequent communication between nodes, GROMACS can only take
advantage of a fraction γ of each core’s performance that decreases
with the number of cores across which the job is split. Performance
depends on conﬁguration parameters, simulated system, and com-
pute infrastructure, but this general behavior is common to modern
molecular dynamics codes [8, 9]. For a large number of jobs, this
strategy to accelerate job completion is suboptimal.
More formally, total runtime T for a set of jobs J can be
described by:
T ¼
X
J
i¼1
xi þ ci
γnini
,
ð1Þ
where xi is the runtime of job i, ci the job’s overhead including
startup and data transfer, and ni the assigned number of cores.
Assuming that the last three quantities are approximately equal
across jobs, as would be the case when simulating an ensemble of
GROMACS trajectories of the same molecular system on the same
CPU type, this equation simpliﬁes to:
T  J ∗xi þ ci
γn
:
ð2Þ
If the goal is to minimize overall compute time, then γ should
be 1, which is achieved by n ¼ 1. With the advent of large-scale
on-demand cloud computing, it is thus more economical and
292
Kai J. Kohlhoff

efﬁcient to run large numbers of jobs of similar length in parallel on
dedicated single cores.
We can now consider the effect of introducing parallelization to
accelerate simulations in terms of wallclock time. When running
P jobs in parallel, wallclock time Twallclock is given by:
T wallclock 
J
P
 
∗x þ c
γn :
ð3Þ
To reduce Twallclock, we can increase P, γ, and n, or reduce c.
The ideal setup to minimize wall-clock time therefore enables a
high level of parallelism, splits each job across many cores while
maintaining high per-core performance, and minimizes overhead.
Conventional shared compute clusters with local storage typi-
cally have an advantage over the cloud in terms of latency when it
comes to ﬁle access, which beneﬁts data transfer and reduces over-
head. However, in practice, signiﬁcant overhead is created by the
fact that a shared cluster’s total CPU and graphics processing unit
(GPU) count is constant. Firstly, jobs are submitted to a queue,
Fig. 1 Example of relative speedup when simulating a molecular dynamics trajectory using Gromacs 2016.4
over the Message Passing Interface (MPI) on the Intel Xeon Skylake architecture at 2.0 GHz. Performance was
measured in ns of simulated chemical time per day. As the computation is split across an increasing number
of MPI threads using one thread per core, the beneﬁt of adding each additional core diminishes as more time is
spent with communication. At 48 MPI threads, a nearly 50% reduction of performance relative to ideal
speedup is observed
Google-Accelerated Biomolecular Simulations
293

where they might take hours or days to schedule, depending on a
user’s priority. Secondly, users often have to limit their compute jobs
to a fraction of these shared resources. As a consequence, large
numbers of compute jobs might end up being executed in sequence.
Taken together, the actual overhead c on compute clusters is large
and jobs that could run in hours might take days to complete.
In contrast, computations on the cloud schedule quickly and
can be done in bursts when they are needed. This allows adjusting
the number of parallel jobs, up to P ¼ J, in which case Twallclock in
Eq. 3 is a constant equaling the longest job duration. Furthermore,
requisitioning 10,000 cores for 1 h is comparable in cost to
100 cores for 100 h. The result of this elastic use of resources is
an acceleration of the computation-analysis cycle, possibly by
orders of magnitude, allowing the computational scientist to obtain
results more quickly and test hypotheses in a timely fashion.
Examples of successful scientiﬁc use of cloud environments
include the improvement of force ﬁelds for molecular structure
modelling [10], the simulation of molecular trajectories [11], and
genome analysis to identify genetic variants [12, 13].
In this chapter, we will show how to conﬁgure a cloud com-
puting project on GCP, set up a Docker container with the Linux
operating system and the required binaries and tools, and efﬁciently
submitting compute jobs to a large number of cloud CPUs
on GCP.
2
Materials
Simulations have been carried out with the GROMACS molecular
dynamics package in version 2016.4 and Docker version 1.12.6
with an Ubuntu 16.04 image. The dsub utility was downloaded for
commit 6894e2d from 10/19/2017. Instructions for Google
Compute Engine and Google Cloud Storage are accurate as of
early 2018.
3
Methods
In this section, we show an application for running a biomolecular
simulation in the cloud. We will use a pre-equilibrated molecular
dynamics system of a protein as an example and will show how to
run copies of it on 100s or 1000s of (optionally preemptible, see
Note 1) CPUs. The focus of this chapter is on the cloud computa-
tions, so we omit a detailed treatment of the simulated system and
its analysis. Instead, we will describe an efﬁcient path to getting
started with a large-scale simulation in the cloud. Various conﬁgu-
ration parameters and features allow optimizing the cloud for a
particular use case. Here, we will take a focused approach to
294
Kai J. Kohlhoff

providing the core knowledge needed to efﬁciently run a wide
variety of computations. For more specialized needs, it is worth
consulting the detailed documentation on the various parts of the
cloud ecosystem that is available online. Figure 2 gives an overview
of the relationships between the different components of the cloud
setup that will be described later.
This section is organized as follows. In Subheading 3.1, we
brieﬂy describe the molecular system. In Subheading 3.2, we show
how to set up a cloud project on Google Cloud Platform, which
includes requesting quotas and setting up billing in the GCP Con-
sole. In Subheading 3.3, we show how to conﬁgure a cloud bucket
for the storage of input and output data. This includes options to
set permissions to make it available to speciﬁc groups of collabora-
tors or sharing it publicly. In Subheading 3.4, we describe how to
use the command line interface to access cloud resources. We will
Fig. 2 Diagram of interactions between GCP and the user. Files are updownloaded and downloaded by the
user directly to and from cloud buckets, where they are stored alongside Docker containers that are handled
through the Google Container Registry. Buckets are accessible from virtual machines (VMs) running in various
regions around the world. Dsub handles the launch of new VMs running pre-built Docker containers with
desired operating systems and tools, the transfer of ﬁles in and out of the container, and the execution of user-
speciﬁed commands. The user can perform all relevant operations through the web browser, using the Google
Cloud Shell running on its own virtual machine instance
Google-Accelerated Biomolecular Simulations
295

explain how to use a preconﬁgured cloud instance with the Google
Cloud Shell to upload Docker containers [14] and transfer ﬁles
between a local machine and Google Cloud Storage. In Subhead-
ing 3.5, we show how to set up a Docker container with an Ubuntu
image and the GROMACS molecular dynamics package. Simula-
tions can be started and tested inside the container using an inter-
active mode. The container is uploaded to the Container Registry
to have the ability to serve it to virtual machines around the world.
While these instructions can take a while to complete, they have to
be completed just once: A conﬁgured GCP Project and an
uploaded Docker container can be reused for all future computa-
tions. Finally, in Subheading 3.6, we demonstrate how to submit a
large number of compute jobs in batch to the Google Compute
Engine.
3.1
System
Preparation
A molecular system of a protein dissolved in water was prepared and
equilibrated using the Protein Data Bank entry 1AKI for hen
lysozyme. The topology was created with GROMACS with the
all-atom variant of the OPLS force ﬁeld [15]. The protein was
placed in a triclinic box, solvated in 9499 water molecules of type
TIP3P [16] and charge equalized with eight Cl ions. The system
was energy minimized with 50,000 steps of steepest descent with a
tolerance of 1000 kJ/mol/nm. Temperature equilibration was
performed for 200 ps in the canonical ensemble (NVT) with a
2 fs time step. Pressure equilibration was performed with the
same step size for another 200 ps in the isothermal-isobaric ensem-
ble (NPT). The equilibrated system was stored in the GROMACS
tpr ﬁle format as md_system.tpr.
3.2
Setting Up
a Google Cloud Project
The following are step-by-step instructions for conﬁguring a cloud
project. New projects are set up from the GCP Console (http://
console.cloud.google.com, see Fig. 3 for an overview of the web
interface). This requires acceptance of the terms of service and a
Google-associated account, such as a Gmail account. Once logged
in, a new project can be created by opening the “Select a project”
menu in the console’s header. If this has been done before, a project
name will be shown here. In the selected menu, click the “+”
symbol to add a new project and type in a project name. Edit the
project ID or accept the auto-generated ID (typically the project
name plus a number). The name of the project will not be used in
the rest of this chapter, as all further steps will rely on the ID only.
We will use four components of the Google Cloud Platform:
Compute Engine, Cloud Storage, Cloud APIs, and Cloud Shell. If
its name is not already shown, the new project needs to be selected to
proceed, which can be done by clicking on “Select a project” again.
To access the relevant sections for the topics that will be dis-
cussed in the next paragraphs, use the main menu that can be
accessed by clicking the menu button (three horizontal parallel
296
Kai J. Kohlhoff

lines, or “hamburger” symbol) that can be found in the upper left
corner, or the console’s search box near the top of the screen.
3.2.1
Enabling
application programming
interfaces (APIs)
A number of Google Cloud APIs are enabled by default. Find
“APIs & Services” in the main menu, or search for “Dashboard”
and select the one for “APIs & Services” from the suggestions. The
enabled APIs are shown as a list, which should include “Google
Cloud Storage.” To run computations in virtual machines (see Note
2), we need to add three more APIs. First, ﬁnd the link “ENABLE
APIS AND SERVICES” and click on it. Search for “Google Com-
pute Engine API” and select it. Click “ENABLE” to allow the
project to run VMs. Second, do the same for the “Genomics
API”. While this particular API is not strictly necessary for running
computations in the cloud, it is being used by the tool dsub [17]
(see Note 3), which we will take advantage of for batch submission.
Finally, search for the “Container Registry API” and add that as
well. It will enable the upload of Docker containers that can then be
used by the virtual machines.
Fig. 3 Overview of the Google Cloud Console with relevant user interface (UI) elements highlighted. Accessible
from the header bar: (1) products and services main menu, (2) menu to select or create a cloud project,
(3) search box, and (4) launcher for the Google Cloud Console. Accessible through the main menu on the left:
(5) billing panel, (6) APIs and services dashboard, (7) IAM & admin settings for permissions and quotas, and
(8) storage browser
Google-Accelerated Biomolecular Simulations
297

3.2.2
Requesting Quota
Google Cloud Engine has default quotas set, which should be
enough for a ﬁrst trial run. To look up the current settings and
request an increase if needed, select “IAM & Admin” ! “Quotas”
from the main menu, or search for “IAM & Admin,” then click on
“Quotas.” This will show a list of services, the region for which
each service is enabled, and ﬁnally, the currently set quota. The
rows that are required for our purposes are:
l
in-use IP addresses;
l
preemptible CPUs;
l
CPUs (all regions); and
l
CPUs.
Take a look at the default and decide if they are sufﬁcient. As a
rule, each virtual machine requires one in-use IP address. The
number of preemptible CPUs must match the total number of
cores across all VMs, and one CPU is needed for every ten VMs
(see Note 4). Lastly, the number of CPUs (all regions) has to match
the total number of cores that will be used. So, to run jobs with
100 cores using 4-core VMs, quotas could be set to 25 IP
addresses, 100 preemptible CPUs, 3 CPUs, and 3 CPUs (all
regions). To use non-preemptible CPUs only, the quotas could
instead be set to 25, 0, 100, and 100, respectively. To add quotas,
choose a region where jobs will be run, such as “us-east1,” select
the services for that region, and click the “EDIT QUOTAS” link
on the quotas page. Change requests to quotas will require a
non-trial account and might take a couple of days to be processed.
3.2.3
Billing
Cloud providers usually offer a free tier or limited trial, which
allows experimenting with their cloud infrastructure without incur-
ring costs. To conﬁgure billing, select “Billing” from the main
menu, or enter “Billing” in the search box. If not used before, the
project will not yet be linked to a billing account. Select the option
to manage a billing account and add a new one on the next page. A
payment method will have to be provided. The GCP Project will
then be automatically linked to the billing account. Charges are
typically incurred for the active use of resources, such as hours of
CPU use, per-months persistent storage use, and the number of
calls to different APIs. The Billing panel allows specifying a
budget along with alerts that are triggered once certain portions
of that budget are reached (suggested are 50%, 90%, 100%).
3.3
Creating a Cloud
Bucket
A cloud bucket will be used for all input and output data for our
computations. In addition, we might use it to temporarily store
source code to generate a Docker image. In the GCP Console
(Fig. 3), ﬁnd and click the “Storage” section on the main menu
panel on the left and select “Browser,” or enter “Browser” in the
search box. Select “Create bucket” and type in a new name. This
298
Kai J. Kohlhoff

name will be required to access ﬁles later on. Choose a storage class
and location or accept the default. Clicking on “Create” sets up the
bucket before returning to the Storage Browser.
The new bucket will be listed. The list also contains a column
for “Requester pays.” If enabled, any requests to download shared
ﬁles from the bucket will be billed to the requester instead of the
bucket’s owner. This removes the need for the owner to provide
funding for serving the data when providing access to their results
to the scientiﬁc community.
A number of options are provided in the Browser to upload ﬁles
and folders from local disk. It provides a convenient way to transfer
data without the need to conﬁgure the Google Cloud SDK
command-line tools. By clicking on the bucket’s name, ﬁles and
folders stored in it can be explored. The ﬁles are listed with a
column that allows sharing them publicly and generating a
direct link.
To give access to the bucket to speciﬁc groups of people, such
as collaborators on the project, locate the three vertical dots on the
list entry for the bucket and select “Edit bucket permissions.” This
opens the permissions tab, on which additional members can be
added by email and given “Storage Object Viewer” and “Storage
Object Creator” permissions for read and write access, respectively.
It is also possible to grant permissions for all buckets in a project at
once (see Note 5).
3.4
Command-Line
Access to Cloud
Resources
The Google Cloud Shell provides a Linux shell environment on a
speciﬁcally provisioned cloud VM that can be accessed in the
browser. It is preconﬁgured for access to a project’s resources and
offers persistent storage space for ﬁles. We will use the shell to set up
the Docker container. The wget tool is an efﬁcient way to download
ﬁles while setting up the container, but it might fail to connect to
the GROMACS server from within the Google Cloud Shell. In that
case, we’ll have to ﬁrst upload a copy of the GROMACS source
code to cloud storage by completing the following steps:
Download the GROMACS source code from gromacs.org to
local disk (see Note 6). For example:
wget ftp://ftp.gromacs.org/pub/gromacs/gromacs-2016.4.tar.gz
In the Storage Browser, use one of the provided options to
upload this source archive to the Bucket. The GCP Shell can be
started from the Google Cloud Console (Fig. 3) by locating and
clicking the shell prompt symbol “>_” in the upper right corner. It
will appear on the bottom edge of the browser window. To down-
load the source archive from the cloud bucket, enter the following
command:
gsutil cp gs://<bucket name>/gromacs-2016.4.tar.gz .
Google-Accelerated Biomolecular Simulations
299

This will create a persistent copy local to the Google Cloud
Console that is accessible by Docker.
In some cases, it is preferable to have a local system conﬁgured
to access a cloud project’s resources, for example, a workstation
that has the tools and data needed to set up a compute and analysis
pipeline and provides a familiar environment. In those cases, it is
possible to install the Google Cloud SDK with the tools gcloud and
gsutil locally (see Note 7) and simplify access to a cloud bucket by
mounting it locally (see Note 8).
3.5
Setting Up
a Docker Container
The use of a Docker container has a number of important beneﬁts,
such as versioning, a hermetic execution environment, reusability,
and reproducibility. Computations done in a container also remove
the need to recompile code for different computer architectures.
This ability to preserve and share a computing environment accel-
erates scientiﬁc progress, as each conﬁguration has to be created
only once and can be used as often and by as many people as
needed.
The remaining part of this section can be easily modiﬁed to suit
other computing jobs. Commands in Subheading 3.5 have to be
run only once. Afterwards, the container is available both locally on
the machine on which it was built and from any virtual machine
running in the cloud environment.
We start by creating a new directory in the Cloud Shell that
contains only a ﬁle called “Dockerﬁle” with the following contents:
# Use an image of Ubuntu 16.04.
FROM ubuntu:16.04
#
Copy
the
contents
of
the
current
directory
into
the
container.
ADD . .
# Install Gromacs and its dependencies.
RUN apt -y update \
&& apt install -y wget cmake g++ libxml2-dev openmpi-bin
openmpi-doc libopenmpi-dev \
&&
wget
ftp://ftp.gromacs.org/pub/gromacs/gromacs-
2016.4.tar.gz \
&& tar xvf gromacs-2016.4.tar.gz \
&& rm gromacs-2016.4.tar.gz \
&& mkdir gromacs-2016.4/build \
&& cd gromacs-2016.4/build \
&& cmake .. -DGMX_BUILD_OWN_FFTW=ON
-DCMAKE_CXX_COMPILER=/usr/bin/g++ -DGMX_THREAD_MPI=on \
&& make -j \
&& make install
300
Kai J. Kohlhoff

The “FROM” line contains the operating system that will form
the basis of the container. The “RUN” line is essentially a line-by-
line recording of the commands required to set up GROMACS on
that operating system (see Note 9). If unsure about which steps to
perform, it is useful to build a container without it ﬁrst, then use
the interactive mode introduced below to experiment. If a local
copy of the GROMACS source archive is available, add it to the
same directory and remove the line with “&& wget” from the
Dockerﬁle. While building the Docker container, the contents of
the Dockerﬁle’s directory will be copied into the container. The
Docker container can be built by issuing the following command:
docker build -t gromacs_2016.4 .
This will use the resources of the computer on which it is run.
The Dockerﬁle contains the line “make –j’ to build GROMACS,
which will use all available cores. Since this can temporarily consid-
erably slow down the system, consider changing that line by
appending the number of allowed cores. The build process will
take several minutes. Once it has completed, the container should
show up as the top entry when running:
docker images
REPOSITORY
TAG
IMAGE ID
CREATED
SIZE
Gromacs_2016.4
latest
34d05c53be2f
10 minutes
ago
772MB
To test the correct functioning of the GROMACS installation
inside the container, it is possible to enter an interactive mode with:
docker run -it gromacs_2016.4 bash
A molecular dynamics job can be run from within the interac-
tive session to test if everything is working as expected (see Note
10). For a quick test that the GROMACS binary is compiled
properly, it is possible to just print versioning and compilation
information with:
gromacs-2016.4/build/bin/gmx --version
Next, tagging the Ubuntu/Gromacs container with a registry
name allows identifying it later when running it on Cloud Engine:
docker tag gromacs_2016.4 us.gcr.io/<project
ID>/gromacs_2016.4:v1
Here, us.gcr.io is the hostname, with preﬁxes us., eu., and asia.
indicating that the images will live in the USA, European Union, or
Asia, respectively. Following it are the ID of the cloud project, the
Google-Accelerated Biomolecular Simulations
301

image name, and an optional tag, which is useful for versioning.
Next, the container can be pushed to the Google Container Regis-
try with gcloud:
gcloud docker -- push us.gcr.io/<project
ID>/gromacs_2016.4:v1
The container is now available for use with Google Compute
Engine’s virtual machines. It is being stored in a bucket with a name
of the form us.artifacts.<project ID>.appspot.com within the
cloud project, which means that the container can be shared with
others in the same way as Storage Buckets, as discussed in Subhead-
ing 3.3.
3.6
Submit Tasks
with Dsub
Dsub is a pipeline manager that handles workloads and job submis-
sion similarly to slurm or qsub. While there are several ways to set
up virtual machines, dsub offers a particularly convenient way. By
default, the maximum number of resources allowed by the quota
will be used as long as there are sufﬁcient compute jobs in the
queue.
The installation instructions for dsub can be found at https://
github.com/DataBiosphere/dsub. Since the instructions might
change over time, we capture two possible ways to install dsub. If
pip is installed on the system (which is the case for the Cloud Shell):
pip install dsub
It might be necessary to prepend sudo for the relevant permis-
sions. Without pip, instead clone the repository with git and install
with Python:
git clone https://github.com/DataBiosphere/dsub
cd dsub
python setup.py install
This last step concludes the conﬁguration and setup phase, and
everything is ready for starting cloud jobs. Files will persist between
successive uses of the Cloud Shell but changes to the system will
not, which means the dsub installation and local copies of container
images will disappear when a new VM for the shell is provisioned.
Docker containers pushed to the registry will remain available and
can be retrieved with “gcloud docker -- pull <tag>.”
The following is a quick “Hello World” example. It starts a VM
and executes the given command, which outputs a string to ﬁle.
This example does not specify our Docker container; instead, dsub
will automatically pull a default container, such as an Ubuntu 14.04
image, and execute the command there.
302
Kai J. Kohlhoff

dsub \
--project <project ID> \
--zones "us-central1-∗" \
--logging gs://<bucket name>/logs \
--command=’echo "Hello World" > "${OUTPUT}"’ \
--output OUTPUT=gs://<bucket name>/hello_world.txt \
--wait
Dsub will submit the job and print instructions for monitoring
and canceling it to stdout. The command line does a number of
things: it gives dsub the ID of the cloud project, speciﬁes that the
VM can be run in any zone in the us-central1 region, determines
where to store any logs and output produced by the job, which
command to execute, and ﬁnally, that dsub is to wait for the job to
complete. This last ﬂag allows dsub to report back any error con-
ditions encountered during job execution. Logs include objects
(i.e., Google Cloud Bucket’s equivalents for ﬁles) that capture
stdout and stderr, as well as status changes and operations per-
formed and logged by dsub.
The output ﬂag has a particular form; it speciﬁes the location
for the output object as well as the name of an environment variable
that is accessible from within the Docker container. This variable
does not actually hold the path to the object in the cloud bucket
but rather a dsub-generated ﬁle path in the container’s ﬁle system.
The variable can be passed to a program running inside the con-
tainer, which can then perform local ﬁle operations without any
knowledge of how to access cloud buckets. The command executed
here, “echo ‘Hello World’ > ’${OUTPUT},’” redirects the printed
“Hello World” string to that ﬁle. On job completion, dsub takes
the output ﬁle and copies it to the bucket. It is possible to specify
multiple input and output ﬁles in this way. The input ﬁles need to
exist as objects in the bucket and are speciﬁed with the “--
input” ﬂag.
Log and output objects can be accessed in two ways: through
the Storage Browser or with the use of gsutil. For example, the
following lists all objects in the log location:
gsutil ls gs://<bucket name>/logs
The objects can be copied to local ﬁles with gsutil cp. To check
that the “Hello World” example ran successfully, open the hello_-
world.txt object in the Storage Browser, retrieve it with the gsutil ls
and cp commands, or print its contents directly:
gsutil cat gs://<bucket name>/hello_world.txt
Google-Accelerated Biomolecular Simulations
303

If the job ﬁnished without error, the object will contain the
expected string “Hello World.” If not, check the logs for any
reported errors.
To start an actual run with GROMACS, we will ﬁrst extend the
command to run a single simulation. Finally, we’ll show how to
submit multiple tasks as batches using the “--task” ﬂag and run
longer scripts or programs with the “--script” ﬂag.
The following command starts a job that will run 50,000 steps
of a molecular dynamics simulation. Since the simulated system was
set up with a 2 fs step size, this amounts to 100 ps of simulated
chemical time.
dsub --project <project ID> \
--zones "us-central1-∗" \
--logging gs://<bucket name>/logs \
--image=us.gcr.io/<project ID>/gromacs_2016.4:v1 \
--command=“cd /; cp $INPUT /md_system.tpr; /gromacs-
2016.4/build/bin/gmx mdrun -nsteps 50000 -deffnm /md_system;
tar cvzf $OUTPUT md_system.∗“ \
--input INPUT=gs://<bucket name>/md_system.tpr \
--output OUTPUT=gs://<bucket name>/md_system.tar.gz \
--preemptible \
--min-cores=8
This command adds two additional ﬂags to those already dis-
cussed: “--preemptible,” which instructs dsub to run on the less
costly preemptible virtual machine type, and “--min-cores,” which
determines how many CPU cores will be available on the VM. For
values larger than 1, dsub will default to n1-highcpu-∗machine
types, which trade a small memory size for lower cost. The ﬂag “--
min-ram” can be used to request a speciﬁc amount of memory.
Newer versions of dsub also offer the “—retries” ﬂag to simplify
restarting failed tasks.
Dsub’s “--command” ﬂag in this example is actually given three
commands that are run inside the container in sequence: ﬁrst, we
copy the input ﬁle to a known location, then use the GROMACS
mdrun command to run the simulation, and ﬁnally, we use the tar
tool to compress all output ﬁles that were generated by GROMACS
into a single archive.
To avoid stringing commands together and complicating the
command line, any shell script ﬁle can be submitted through dsub
for automatic execution in the Docker container using the “--
script” ﬂag. The shell script needs to be local to the machine on
which the dsub command is executed.
To avoid repeated calls to dsub, it is possible to streamline job
submission by creating a tab-separated-values ﬁle that contains one
line per task plus a header. Each line contains tab-separated paths to
input and output ﬁles for a task, while the header line gives the
304
Kai J. Kohlhoff

sequence of ﬂags that those ﬁle names are substituted into. For
example, the ﬁle below speciﬁes that there are four input and four
output ﬁles, each with their individual environment variable name
(see Note 11).
--input IN1 --input IN2 --input IN3 --input IN4 --output OUT1 -
-output OUT2 --output OUT3 --output OUT4
gs://<bucket name>/input1.tpr gs://<bucket name>/input2.tpr
gs://<bucket name>/input3.tpr gs://<bucket name>/input4.tpr
gs://<bucket name>/output1.tar.gz gs://<bucket name>/output2.
tar.gz gs://<bucket name>/output3.tar.gz
gs://<bucket name>/output4.tar.gz
...
The only spaces in this ﬁle are between the “--input” ﬂags and
the respective environment variable names. All other whitespaces
are tab characters. Each subsequent line then has to have exactly
eight tab-separated strings to match the header. As before, the
input ﬁles are in GROMACS’s tpr format, while the output ﬁles
are compressed tar archives. The ﬁle is then submitted to dsub with
the “--script” ﬂag. The result is that the same instructions in
identical environments, that is, the Docker container, are executed
on a large number of different inputs. Large batches of tasks can be
submitted in this way, after which the outputs will start appearing in
the designated cloud bucket (see Note 12). To analyze cloud-
generated trajectories using GROMACS’s tools, the data does not
have to be downloaded, and no new Docker container is needed.
Instead, it is sufﬁcient to provide a new task ﬁle and a new com-
mand string or script to run the analysis.
This chapter has shown how to use the cloud for running
biomolecular simulations, generate data, and store it in the cloud.
The instructions can be modiﬁed for other use cases or expanded to
build an entire pipeline. To learn more about available resources
and related topics, the reader might want to consult the online
tutorials and documentation at https://cloud.google.com/docs/
tutorials#compute_engine.
As cloud technology continues to grow and evolve, it is becom-
ing an ever-more impactful new tool for the computationalist to
simplify and accelerate biomolecular simulations.
4
Notes
1. Preemptible virtual machines run at a low priority and can be
preempted at any time by higher priority jobs. They trade
guaranteed availability for running computations at a fraction
Google-Accelerated Biomolecular Simulations
305

of the cost of non-preemptible VMs. While they are not suit-
able for applications that require constant up-time (such as
running a service that interacts with end-users), preemptible
VMs are useful for scientiﬁc workloads that run in batches. It is
up to the user to implement the required job management
logic to handle job resubmissions as well as the intermittent
storage of checkpoints where job continuation is preferred over
restarts. Preemption rates will ﬂuctuate, as they are subject to a
variety of factors (off-peak vs. peak usage, machine types, job
duration, job count, etc.), and excessive retries might reduce or
revert the cost beneﬁts of preemptible VMs. To limit the possi-
ble impact of preemptions:
(a)
There is a 30-s warning in form of an ACPI G2 Soft Off
signal to the VM that can be used for shutting down a
computation and to upload any important data, such as
checkpoint ﬁles, to persistent storage like a cloud bucket.
Examples for shutdown scripts can be found in the GCP
documentation at https://cloud.google.com/compute/
docs/instances/create-start-preemptible-instance#
handle_preemption.
(b)
There currently is no charge if the preemptible VM is
preempted within 10 min from when it was created, with
the exception of a charge for the use of operating systems
in the premium category, like Red Hat Enterprise Linux
and Windows Server.
2. Virtual machines come in a variety of different conﬁgurations
to match the broad spectrum of possible applications. Among
the options to choose from are machines with high memory
versus high CPU, CPU only versus CPU and GPU, and pre-
emptible versus non-preemptible.
3. An alternative to dsub is the use of “Containers on Compute
Engine,” which allows the deployment of containers on virtual
machines and managed instance groups. This feature is
described in the Google Cloud Platform documentation and
requires additional conﬁguration steps that are beyond the
scope of this chapter.
4. The number of concurrent preemptible virtual machines that
can be run in a project is limited to ten times the available CPU
quota, even if sufﬁcient preemptible CPU quota is available.
With a default for the latter of 24, it is not possible to run more
than 240 VMs in a region, unless a CPU quota increase is
requested.
5. To give access to all buckets in a project at once, use the identity
and access management section of GCP. Search for “IAM &
admin” or select the link with the same name from the main
menu. In the now open permissions page, select the “ADD”
306
Kai J. Kohlhoff

link near the top to add another user or group. See the question
mark after the “Members” label to learn about permissible
values for selection by email or group. Under “Roles,” navigate
to the “Storage” line at the end of the pull-down menu and
select “Storage Object Viewer” to grant read access and “Stor-
age Object Creator” for write access.
6. If the md5 checksum is known, it is possible to include a check
for whether the correct ﬁle is retrieved. For example,
wget \
ftp://ftp.gromacs.org/pub/gromacs/gromacs-2016.4.tar.gz \
| md5sum | awk ’{ print "Checksum",
($1=="d41d8cd98f00b204e9800998ecf8427e") ? "matches" :
"ERROR!" }’
7. A more ﬂexible alternative to the Google Cloud Shell is the
local installation of the Google Cloud SDK along with gcloud
and gsutil. This option is useful when performing signiﬁcant
work with scripts running on a local machine, such as monitor-
ing job progress and restarting preempted VMs. Gcloud allows
to push containers and gsutil allows the uploading and down-
loading of ﬁles to and from Google Cloud Storage. An impor-
tant part of the SDK installation is the setup of proper
authentication, which requires access to a web browser (possi-
bly on another machine). Providing detailed information on
how to accomplish this is outside the scope of this chapter, but
the online documentation for GCP contains detailed instruc-
tions on setting up and authenticating gsutil and installing the
Cloud SDK.
8. It is possible to mount a cloud bucket to a local ﬁle system with
Cloud Storage FUSE (see the GCP online documentation for
installation instructions), which makes it convenient to explore
the ﬁles from the command line and use command line tools
and scripts directly on the stored data. Since this will be slow, if
large amounts of data are to be transferred, it might be better
to create a local copy by issuing the “-m” ﬂag to “gsutil cp,”
which performs a faster parallel copy.
9. It is good practice to delete any temporary ﬁles, such as com-
pressed archives with source code that were used only during
installation during the build process, since these ﬁles will add to
the size of the container. It therefore makes sense to clean up
carefully, as all of these extra bytes will persist in the container
and unnecessarily get copied between the Container Registry
and virtual machines.
10. While Docker containers are hermetically sealed by design and
changes don’t persist between sessions, it is still possible to
copy ﬁles in and out of a running container by using “docker
Google-Accelerated Biomolecular Simulations
307

cp.” This is particularly useful for debugging locally before
running at scale.
A running container has a unique identiﬁer, which can be
looked up with “docker ps” and is printed in the “NAMES”
column, for example, “fervent_yonath.” Files can be copied in
and out of the container by prepending that name and a colon
to the path of the ﬁle inside the container, for example, “docker
cp ﬁle1 fervent_yonath:/app/ﬁle1” or “docker cp fervent_yo-
nath:/app/ﬁle2 ﬁle2.”
11. It is possible to run several tasks in parallel on a multicore
VM. Since each newly started VM has to download a copy of
the Docker container, this has the advantage of reducing the
amount of data that needs to be transferred. A possible down-
side is that as the number of cores per VM increases, the
likelihood of preemption increases as well.
12. Checking for output ﬁles in the cloud bucket can be slow and is
often not optimal when the goal is to identify completed jobs
in a timely fashion. GCP offers a PubSub mechanism to moni-
tor changes to the contents of the cloud bucket.
Acknowledgments
This work was performed on Google infrastructure. The author
thanks Jojo Dijamco for many detailed discussions and careful
review of the manuscript, and members of the Google Accelerated
Science team for helpful feedback.
References
1. Shaw DE, Deneroff MM, Dror RO, Kuskin JS,
Larson RH, Salmon JK, Young C, Batson B,
Bowers
KJ,
Chao
JC,
Eastwood
MP,
Gagliardo J, Grossman JP, Ho CR, Ierardi
DJ, Kolossva´ry I, Klepeis JL, Layman T,
McLeavey C, Moraes MA, Mueller R, Priest
EC,
Shan
Y,
Spengler
J,
Theobald
M,
Towles B, Wang SC (2008) Anton, a special-
purpose machine for molecular dynamics sim-
ulation. Commun ACM 51(7):91–97
2. Shaw DE, Grossman JP, Bank JA, Batson B,
Butts JA, Chao JC, Deneroff MM, Dror RO,
Even A, Fenton CH, Forte A, Gagliardo J,
Gill G, Greskamp B, Ho CR, Ierardi DJ,
Iserovich
L,
Kuskin
JS,
Larson
RH,
Layman
T,
Lee
L,
Lerer
AK,
Li
C,
Killebrew D, Mackenzie KM, Mok SY, Moraes
MA, Mueller R, Nociolo LJ, Peticolas JL,
Quan T, Ramot D, Salmon JK, Scarpazza DP,
Schafer
UB,
Siddique
N,
Snyder
CW,
Spengler J, Tang PTP, Theobald M, Toma H,
Towles B, Vitale B, Wang SC, Young C (2014)
Anton 2: raising the bar for performance and
programmability in a special-purpose molecu-
lar dynamics supercomputer. In: Kellenberger
P (ed) SC’14 proc. int. conf. high performance
computing, networking, storage and analysis,
New Orleans, 2014
3. Shirts M, Pande VS (2000) Screensavers of the
world, unite! Science 290:1903–1904
4. Eastman P, Swails J, Chodera JD, McGibbon
RT, Zhao Y, Beauchamp KA, Wang L-P, Sim-
monett AC, Harrigan MP, Stern CD, Wiewiora
RP, Brooks BR, Pande VS (2017) OpenMM 7:
rapid development of high performance algo-
rithms for molecular dynamics. PLoS Comput
Biol 13(7):e1005659
5. Bowman GR, Pande VS, Noe´ F (eds) (2014)
An introduction to Markov state models and
their application to long timescale molecular
simulation. Springer, Dordrecht
308
Kai J. Kohlhoff

6. Dellago C, Bolhuis PG (2009) Transition path
sampling and other advanced simulation tech-
niques
for
rare
events.
Adv
Polym
Sci
221:167–233
7. Hess B, Kutzner C, van der Spoel D, Lindahl E
(2008) GROMACS 4: Algorithms for highly
efﬁcient, load-balanced, and scalable molecular
simulation.
J
Chem
Theory
Comput
4
(3):435–447
8. Abraham MJ, Murtola T, Schulz R, Pall S,
Smith JC, Hess B, Lindahl E (2015) GRO-
MACS: High performance molecular simula-
tions through multi-level parallelism from
laptops
to
supercomputers.
SoftwareX
1–2:19–25
9. Bowers KJ, Chow E, Xu H, Dror RO, Eastwood
MP, Gregersen BA, Klepeis JL, Kolossva´ry I,
Moraes MA, Sacerdoti FD, Salmon JK, Shan Y,
Shaw DE (2006) Scalable algorithms for molec-
ular dynamics simulations on commodity clus-
ters.
In:
SC’06
proc.
ACM/IEEE
conf.
supercomputing, Tampa, 2006
10. Conway P, Tyka MD, DiMaio F, Konerding
DE, Baker D (2013) Relaxation of backbone
bond geometry improves protein energy land-
scape modeling. Protein Sci 23(1):47–55
11. Kohlhoff KJ, Shukla D, Lawrenz M, Bowman
GR, Konerding DE, Belov D, Altman RB,
Pande SB (2014) Cloud-based simulations on
Google Exacycle reveal ligand modulation of
GPCR
activation
pathways.
Nat
Chem
6:15–21
12. Poplin
R,
Newburger
D,
Dijamco
J,
Nguyen N, Loy D, Gross SS, McLean CY,
DePristo MA (2017) Creating a universal
SNP and small indel variant caller with deep
neural networks, biorxiv. https://doi.org/10.
1101/092890
13. Mak HC (2017) Unhidden ﬁgures. Cell Syst 5
(6):533
14. Hykes S (2013) The future of Linux contain-
ers. In: PyCon’13 lightning talks
15. Jorgensen WL, Maxwell DS, Tirado-Rives J
(1996) Development and testing of the OPLS
all-atom force ﬁeld on conformational energet-
ics and properties of organic liquids. J Am
Chem Soc 118(45):11225–11236
16. Jorgensen WL, Chandrasekhar J, Madura JD,
Impey RW, Klein ML (1983) Comparison of
simple potential functions for simulating liquid
water. J Chem Phys 79:926–935
17. Google Cloud Platform (2018) Running a
dsub
pipeline.
https://cloud.google.com/
genomics/tutorials/dsub. Accessed 26 Aug
2018
Google-Accelerated Biomolecular Simulations
309

Part III
Integrative Approaches for Biomolecular Simulations

Chapter 13
A Practical Guide to the Simultaneous Determination
of Protein Structure and Dynamics Using Metainference
Thomas Lo¨hr, Carlo Camilloni, Massimiliano Bonomi,
and Michele Vendruscolo
Abstract
Accurate protein structural ensembles can be determined with metainference, a Bayesian inference method
that integrates experimental information with prior knowledge of the system and deals with all sources of
uncertainty and errors as well as with system heterogeneity. Furthermore, metainference can be implemen-
ted using the metadynamics approach, which enables the computational study of complex biological
systems requiring extensive conformational sampling. In this chapter, we provide a step-by-step guide to
perform and analyse metadynamic metainference simulations using the ISDB module of the open-source
PLUMED library, as well as a series of practical tips to avoid common mistakes. Speciﬁcally, we will guide
the reader in the process of learning how to model the structural ensemble of a small disordered peptide by
combining state-of-the-art molecular mechanics force ﬁelds with nuclear magnetic resonance data, includ-
ing chemical shifts, scalar couplings and residual dipolar couplings.
Key words Functional dynamics, Ensemble determination, Bayesian data modelling, Integrative
modelling
1
Introduction
The goal of molecular dynamics (MD) simulations is to provide a
characterization of molecular processes in terms of their structures,
thermodynamics and kinetics [1]. This goal is ambitious and pre-
sents a series of major challenges, including the development of
accurate force ﬁelds, of effective sampling methods and of quanti-
tative accounting of the various sources of errors [2–4]. Quite
generally, because of the intrinsic approximations of the force ﬁelds
and the fact that they are optimized to maximize transferability (see
Chapters 1–3), the results of a simulation of a speciﬁc system might
not quantitatively match available experimental measurements,
even when the sampling is exhaustive [5, 6]. In Parts I and II of
this book, the reader is introduced to the strengths and weaknesses
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_13, © Springer Science+Business Media, LLC, part of Springer Nature 2019
313

of current force ﬁelds, as well as to some of the approaches for
achieving exhaustive sampling of the conformational space.
Nonetheless, the advances made over a period of 50 years are
making it possible to provide atomistic interpretations of various
experimental measurements of molecular processes in terms of
structural ensembles. For example, one might want to determine
the distribution of conﬁgurations underlying a small-angle X-ray
scattering (SAXS) proﬁle or a nuclear magnetic resonance (NMR)
chemical shifts spectrum of a protein. In order for this interpreta-
tion to be meaningful, the structural ensemble must be well deﬁned
in terms of statistical mechanics, as well as in quantitative agreement
with the available experimental observations [2, 3, 7, 8].
Alternatively, given a set of equilibrium measurements, one can
ask whether there is a representative structure, or more generally an
ensemble of structures, that recapitulates them. This is a typical
inverse problem that can be solved by using some form of regular-
isation technique [8, 9]. An accurate force ﬁeld combined with
exhaustive sampling will provide an ensemble of structures that
quantitatively match the experimental data, or, if appropriate, a
representative structure that summarises the main structural fea-
tures of the system. However, as mentioned above, such an ideal
force ﬁeld does not yet exist, and therefore, one can ask: given a
state-of-the-art transferable force ﬁeld and a speciﬁc system of
interest, how can we obtain a quantitative agreement with the
available experimental knowledge? In this section and starting
from the present chapter, we will explore different approaches to
address this problem.
2
Theory
In MD force ﬁelds, when one wants to enforce a property f(X) on a
given structural parameter X (e.g. the length of a covalent bond), a
harmonic potential, for example, k ∙( f(X)  d)2, can be used to
restrain the property around the expected value d with strength k.
However, many properties measured using bulk techniques cannot
be expressed in terms of individual conformations, but they can
only be calculated on the ensemble of conformations populated
under certain external conditions. For example, solution measure-
ments, such as SAXS and many NMR observables, depend on the
average of speciﬁc structural properties calculated over the entire
ensemble. In these situations, one can approximate the ensemble
with a certain number of copies of the system (replicas), calculate
the property f(X) for each replica and then apply the restraint to the
average hf(X)i across the replicas as k ∙(hf(X)i  d)2 [10, 11].
To complicate this picture, experimental measurements of any
property of the system are affected by random noise and systematic
errors [7, 12]. Furthermore, also the structural interpretation of an
314
Thomas Lo¨ hr et al.

experimental observable (the function f(X), also known as forward
model or predictor) is hampered by approximations that might
introduce additional errors. Consequently, the agreement between
experimental measurements and the ensemble obtained from the
simulation should be enforced only up to a certain extent [2, 3, 7,
8], which can be quantiﬁed by the overall error. In practical situa-
tions, estimating this error is far from trivial.
Statistical inference offers a rigorous theoretical framework to
combine all the available sources of information about a system in
order to obtain an accurate and precise description of its properties.
The metainference approach [2] described in this chapter, by build-
ing on the inferential structure determination method [13],
enables modelling accurate structural ensembles by optimally com-
bining prior information on a system with noisy, ensemble-
averaged experimental data and by keeping into account all sources
of errors introduced above [8].
2.1
Inferential
Structure
Determination
To construct the best possible structural model of a system, one can
score different possible models according to their consistency with
the overall knowledge available. This includes theoretical knowl-
edge (often called the ‘prior’ information, I), such as physicochem-
ical information about the system (the force ﬁeld), and the
knowledge acquired from experimental measurements (i.e. the
‘data’, D). In this view, the best model is the one that is most likely
to occur given the information available.
Inferential structure determination (ISD) [13] is a Bayesian
inference approach that, by estimating the probability of a model
given the information available, enables one to infer the best possi-
ble model. In this approach, the assessment of the quality of a
model, M, is made with the posterior probability p(M| D, I) of
M given D and I, which is given by
p MjD, I
ð
Þ / p DjM, I
ð
Þ p MjI
ð
Þ
ð1Þ
where the likelihood function p(D| M, I) is the probability of
observing D given M and I, and the prior probability p(M| I) is
the probability of M given I.
To deﬁne the likelihood function, one needs a forward model
fi(X) to predict the data point di that would be observed for a
system in state X, and a noise model that speciﬁes the distribution of
the deviations between observed and predicted data. Both the
forward model and the noise model are deﬁned in terms of
unknown parameters that are part of the model M and inferred
along with the state X by sampling the posterior distribution. The
sampling is usually carried out using Monte Carlo (MC), MD or
combined techniques based on Gibbs sampling [14].
ISD has been used to determine the macromolecular architec-
ture of several protein complexes of outstanding biological
A Practical Guide to Metainference
315

importance [15–23], using a variety of experimental data and soft-
ware such as the Integrative Modelling Platform (IMP) [24] and
the Crystallography & NMR System (CNS) [25].
2.2
Metainference
Metainference [2] extends ISD [13] to deal with experimental data
that are averaged over multiple conformations and thus enables
modelling structural ensembles [8]. In metainference, the modiﬁed
force ﬁeld (or metainference energy function) for a set of N replicas
of the system is deﬁned as EMI ¼  kBT log pMI, where kB is the
Boltzmann constant, T the temperature of the system and pMI the
metainference posterior probability. In general terms, the metain-
ference energy function can be written as
EMI ¼ kBT logpMI

X; ~f ; σSEM; σBjD

¼ kBT log ∏
N
r¼1 p X r
ð
Þ ∏
N d
i¼1 p

dij~f r,i, σ B
r,i

p
~f r,ijX, σ SEM
r,i

p σ SEM
r,i


p σ B
r,i




ð2Þ
where
– D ¼ [di] is a set of Nd independent experimental data points;
– X ¼ [Xr], where Xr represents the state of replica r, deﬁned here
by the coordinates of all the particles of the system;
–
~f ¼
~f r,i
	
, where ~f r,i is the average of the predictor (forward
model) fi of the ith experimental observable, calculated over an
inﬁnite number of replicas;
–
σSEM¼ σ SEM
r,i
h
i
, where σ SEM
r,i
is the standard error of the mean
related to the average of fi being calculated over a ﬁnite number
of replicas;
– σB¼ σ B
r,i
h
i
, where σ B
r,i is an uncertainty parameter that describes
random and systematic errors in the experimental data point di
as well as in the forward model fi;
–
p

dij~f r,i, σ B
r,i

encodes the noise model (data likelihood),
deﬁned as the conditional probability of di given ~fr,i and σ B
r,i;
– p
~f r,ijX, σ SEM
r,i

is the conditional probability of observing ~f r,i
given that the average of fi is calculated on a ﬁnite number of
replicas N, f i X
ð Þ ¼ 1
N
PN
r¼1 f i X r
ð
Þ. According to the central
limit theorem (CLT), this is a Gaussian distribution;
–
p σ SEM
r,i


encodes the CLT scaling of
σ SEM
r,i
with N:
σ SEM
r,i
/ 1=
ﬃﬃﬃﬃﬃ
N
p
.
– p σ B
r,i


and p(Xr) are the priors on σ B
r,i and Xr, respectively.
For simplicity, in the following, we will consider the speciﬁc
case of Gaussian noise. However, all the considerations below
remain valid in the general case of Eq. 2. When the data likelihood
316
Thomas Lo¨ hr et al.

p

dij~f r,i, σ B
r,i

is a Gaussian function, the metainference energy
function EMI can be written as [2]
EMI ¼ EFF þ kBT
2
X
r, i
di  f i X
ð
Þ

	2
σ B
r,i

2
þ
σ SEM
r,i

2 þ Eσ
ð3Þ
where
the
force
ﬁeld
of
standard
MD
simulations
EFF ¼ PN
r¼1 EFF X r
ð
Þ ¼ kBT PN
r¼1 logp X r
ð
Þ
is
modiﬁed
by
(1) a series of (harmonic) data-restraints, which enforce the
agreement of the replicas with the ensemble-averaged data,
and
(2)
an
error
restraint,
Eσ ¼ kBT P
r, i
logp σ B
r,i


þ 0:5log
σ B
r,i

2
þ
σ SEM
r,i

2




, that
accounts for normalization of the data likelihood and error priors.
Metainference has been used to model structural ensembles
using multiple NMR data [26, 27] and, more recently, cryo-
electron microscopy density maps [28, 29]. Furthermore, the
metainference equivalence to ISD has been used to perform an
integrative structure reﬁnement of a protein–RNA complex using
SAXS and NMR data [30].
2.3
Implementation
2.3.1
Gibbs Sampling
In the following, we describe how a metainference simulation is run
in practice. Given the system of interest, multiple MD simulations
(the replicas) are prepared using the same force ﬁeld and simulation
setup (number of atoms, temperature, pressure, etc.). The replicas
are then simulated in parallel using the energy function in Eq. 3. At
each time step, the metainference energy is calculated as the sum of
the force-ﬁeld energy of all the replicas, the data-restraints and the
error-restraints. The intensity of the data-restraint is ultimately
determined by the value of the errors parameters σ B
r,i, which quan-
tify the level of noise: small errors will result in strong structural
restraints; outliers and high-error data points will automatically
decrease the strength of the data-restraint. The conformations
X and the error parameters are then updated using a Gibbs sampler,
as described in Fig. 1.
2.3.2
Parameter
Optimization
In a metainference simulation, the number of replicas employed is
necessarily smaller than the numbers of conformations actually
contributing to an experimental observable. This discrepancy is
accounted for by the variable σ SEM
r,i
in Eq. 3, which quantiﬁes the
error in calculating averaged properties using a small set of replicas.
According to the central limit theorem, σ SEM
r,i
is proportional to
1=
ﬃﬃﬃﬃﬃ
N
p
. This term can be estimated on-the-ﬂy [31] as the standard
error of the mean over the replicas, which can be calculated either
on the entire trajectory or on a window of a ﬁnite size
A Practical Guide to Metainference
317

σ SEM
i
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
X
N
r¼1
f r,i X
ð
Þ < f r,i X
ð
Þ >

2
N
v
u
u
u
t
ð4Þ
2.4
Metadynamic
Metainference
As in standard MD simulations, in metainference simulations, rele-
vant states might be separated by large free energy barriers. To
accelerate sampling, metainference was combined with metady-
namics [32] in its Parallel-Bias (PBMetaD) ﬂavour [33] (see Note
1). In this combined approach (M&M) [34], an additional, time-
dependent bias potential VPB is added to each replica and shared
among all of them, in the spirit of the multiple-walkers approach
[35]. Consequently, one needs to account for the VPB bias potential
when calculating the average forward model fi(X) used in the
metainference data-restraint. A weighted average can be calculated
using the Umbrella Sampling reweighting weights [36], which
instantaneously accounts for the presence of the PBMetaD bias
potential (see Note 2). Furthermore, these weights can be averaged
over a short time window in order to decrease their ﬂuctuations and
prevent numerical instabilities due to too high instantaneous forces.
As a result of using a weighted average to calculate fi(X), the effective
number of replicas might vary during the simulation along with the
associated error σ SEM
r,i . To account for this effect, σ SEM
r,i
can be
estimated as the standard error of the weighted mean [31].
R1
RN
force
data-
restraint
metainference energy
Gibbs sampling
+
+
replicas
metainference simulation
MD
MC
MD
MC
,
,
,
,
N
r=1
EF F (Xr(t))
N
r=1
EF F (Xr(t + Δt))
error-
restraint
Eσ(t)
+
+
Eσ(t + Δt)
{σ1,i(t)}
{σN,i(t)}
{σN,i(t + Δt)}
{σ1,i(t + Δt)}
kBT
2
r,i
[di −fi(X)]2
σ2
r,i(t)
kBT
2
r,i
[di −fi(X)]2
σ2
r,i(t + Δt)
Fig. 1 Illustration of the Gibbs sampling mechanism in the multiple-replica MD simulation scheme used in
metainference. The metainference energy function EMI is composed of the force ﬁeld EFF, the data-restraints,
which enforce the agreement of the forward model averaged across replicas f i X
ð Þ ¼ 1
N
PN
r¼1 f i X r
ð
Þ with the
experimental data, and the error restraint Eσ (Eq. 3). The error parameters {σr, i} determine the intensity of the
data-restraints and are deﬁned as σ2
r,i ¼
σ B
r,i

2
þ
σ SEM
r,i

2
, where σ B
r,i is the Bayesian error sampled by
MC, and σ SEM
r,i
is the standard error of the mean, which is estimated based on a windowed average (Eq. 4)
318
Thomas Lo¨ hr et al.

3
Materials
Simulations of the EGAAWAASS peptide were carried out using
GROMACS 5.1.4 [37] and the ISDB module [38] of the
PLUMED open-source library, version 2.3 [39]. For didactic pur-
poses, the scripts presented here are updated to PLUMED version
2.5. The initial conformation of the peptide was modelled using
VMD [40], and all plots were created with the Matplotlib library
[41]. All simulations should be run in parallel on a cluster machine
using MPI. The reader should refer to the GROMACS and
PLUMED user manuals for detailed instructions about how to
compile and execute the codes. Basic knowledge about the use of
GROMACS is required to set up the MD simulations and manipu-
late the trajectories.
4
Methods
In this section, we will demonstrate the use of M&M [34] on the
EGAAWAASS peptide [31]. This molecule is highly disordered and
has been used as a model system to study the quality of MD force
ﬁelds [42] and the suitability of residual dipolar couplings (RDCs)
to reveal structural information [43]. The quality of modern force
ﬁelds is insufﬁcient to accurately determine the structural ensemble
of this system, making this an excellent candidate for the applica-
tion of M&M. Previous NMR studies [43] provided chemical
shifts, 3J-couplings and RDC data (Tables 1, 2, and 3), which can
be used with M&M to correct the inaccuracies of the underlying
force ﬁeld. By comparing simulations performed with increasing
amounts of experimental data, we can evaluate the impact of spe-
ciﬁc experimental observables on the accuracy of the reconstructed
ensemble.
This section is organized as follows. In Subheading 4.1, we
describe the system preparation and equilibration steps. In Sub-
heading 4.2, we simulate the system using PBMetaD without the
addition of experimental data. In Subheading 4.3, we introduce
chemical shifts and 3J-couplings as experimental restraints in the
M&M framework. We describe the setup of the simulation as well
as the various parameters and observables that need to be moni-
tored during the simulation. In Subheading 4.4, we also add RDCs,
which require some additional considerations. Finally, in Subhead-
ing 4.5, we discuss the protocol used to analyze the simulations,
such as the calculation of root-mean-square deviations (RMSDs)
from experimental data, and the free energy surfaces generated by
all simulations.
A Practical Guide to Metainference
319

4.1
System
Preparation
The EGAAWAASS peptide is initially modelled with VMD and
solvated in a rhombic dodecahedron box with side lengths of 4.5,
4.5 and 3.2 nm and containing 2118 water molecules. The system
is neutralized by three Na+ and two Cl ions. Energy minimization
of the system is performed using the steepest descent algorithm to a
maximum force of less than 100 kJ/(mol/nm). Equilibration is
performed for 500 ps in the NVT ensemble using the Bussi-
Donadio-Parrinello thermostat [44] and for 500 ps in the NPT
ensemble using the Parrinello-Rahman barostat [45], with position
restraints added to all heavy atoms. We use the CHARMM22∗
force ﬁeld [46] in combination with the TIP3P water model. We
Table 1
Experimental chemical shifts for the EGAAWAASS peptide (ppm)
Residue
HN
N
Hα
Cα
C0
Hβ
Cβ
E1
4.103
55.83
173.15
2.152
29.99
G2
8.780
111.42
4.034
45.12
173.46
A3
8.353
124.31
4.285
52.35
177.72
1.277
19.31
A4
8.344
123.67
4.287
52.68
177.58
1.361
19.07
W5
8.008
119.98
4.612
57.37
175.80
3.308
29.50
A6
7.833
126.18
4.224
52.04
176.69
1.247
19.73
A7
8.055
123.48
4.241
52.49
177.78
1.429
19.37
S8
8.283
115.37
4.511
58.27
173.82
3.930
64.13
S9
8.024
122.84
59.91
178.50
Table 2
Experimental RDCs for the EGAAWAASS peptide (Hz)
Residue
NH
Cα-Hα
Cα C0
E1
12.95
0.59
G2
5.4
1.55
A3
1.26
11.5
0.67
A4
5.22
21.42
0.94
W5
0.91
9.37
1.49
A6
2.33
10.01
0.55
A7
2.88
15.01
0.3
S8
8.37
15.73
1.44
S9
3.78
320
Thomas Lo¨ hr et al.

also use the Particle-Mesh-Ewald [47] approach for both van der
Waals and electrostatic interactions with a cut-off of 0.9 nm, as well
as the LINCS algorithm [48] for constraint solving using a matrix
expansion on the order of 6 and 2 iterations per step (see Note 3).
4.2
PBMetaD
Simulation
We begin with simulating the EGAAWAASS peptide without the
addition of experimental data. To ensure an adequate sampling of
the conformational landscape of this system, we use well-tempered
[49] PBMetaD [33] (see Note 1), in combination with the
multiple-walkers approach [35]. We will use all the backbone dihe-
dral angles ϕ and ψ as CVs, as well as the W5 χ1 and χ2 dihedral
angles, the similarities (DIHCOR) of the dihedral angles between
each pair of alanine residues, and the E1-S9 Cα-Cα distance. The
following PLUMED input ﬁle can be used to deﬁne the CVs listed
above:
MOLINFO MOLTYPE=protein STRUCTURE=egaawaass.pdb
WHOLEMOLECULES ENTITY0=1-111
# Dihedral backbone angles: Psi9, Phi1 are not defined
psi1: TORSION ATOMS=@psi-1
psi2: TORSION ATOMS=@psi-2
psi3: TORSION ATOMS=@psi-3
psi4: TORSION ATOMS=@psi-4
psi5: TORSION ATOMS=@psi-5
psi6: TORSION ATOMS=@psi-6
psi7: TORSION ATOMS=@psi-7
psi8: TORSION ATOMS=@psi-8
phi2: TORSION ATOMS=@phi-2
phi3: TORSION ATOMS=@phi-3
Table 3
Experimental 3J-couplings for the EGAAWAASS peptide (Hz)
Residue
Hα-N
Hα-HN
C-Cγ
N-Cγ
E1
G2
0.49
A3
6.05
A4
0.54
5.95
W5
0.53
6.44
1.59
1.21
A6
6.53
A7
0.39
5.93
S8
0.39
6.98
S9
7.16
A Practical Guide to Metainference
321

phi4: TORSION ATOMS=@phi-4
phi5: TORSION ATOMS=@phi-5
phi6: TORSION ATOMS=@phi-6
phi7: TORSION ATOMS=@phi-7
phi8: TORSION ATOMS=@phi-8
phi9: TORSION ATOMS=@phi-9
# Bulky Trp residue dihedral
dihtrp_cacb: TORSION ATOMS=67,47,49,52
dihtrp_cbcg: TORSION ATOMS=47,49,52,53
# Similarity of Ala-Ala dihedrals
aasimpsi: DIHCOR ATOMS1=@psi-3,@psi-6
aasimphi: DIHCOR ATOMS1=@phi-4,@phi-7
# Distance between alpha-carbons of first and last residue
peplen: DISTANCE NOPBC ATOMS=5,102
To use the @ shorthand to deﬁne the four atoms of the TOR-
SION CV, we need to ﬁrst specify a structure ﬁle with the MOLINFO
directive. A convenient way is to generate a PDB ﬁle from the
standard GROMACS TPR ﬁle:
gmx make_ndx –f topol0.tpr
gmx editconf –f topol0.tpr –n index.ndx –o egaawaass.pdb
The ﬁrst command creates an index ﬁle, which will allow us to
select only the protein atoms in the second line. The WHOLEMOLE-
CULES command tells PLUMED to rebuild molecules that have
been broken inside the MD code by periodic boundary conditions
(see Note 4). We can now set up the PBMETAD directive using the
CVs previously deﬁned as arguments (ARG). We will choose a
BIASFACTOR of 8, a Gaussian deposition PACE of 1 ps, an initial
Gaussian HEIGHT of 0.3 kJ/mol, and Gaussian widths SIGMA equal
to 0.6 rad for the dihedrals, 0.3 for the dihedral similarities and
0.3 nm for the end-to-end distance. We use the WALKERS_MPI ﬂag
to instruct PLUMED to activate the multiple-walkers approach and
share the bias across replicas using MPI.
PBMETAD ...
ARG=phi2,phi3,phi4,phi5,phi6,phi7,phi8,phi9,psi1,psi2,psi3,psi4,psi5,psi6,psi7,
psi8,dihtrp_cacb,dihtrp_cbcg,aasimpsi,aasimphi,peplen
SIGMA=0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,
0.6,0.3,0.3,0.3
HEIGHT=0.3
PACE=500
BIASFACTOR=8
LABEL=pb
322
Thomas Lo¨ hr et al.

GRID_MIN=-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,
0,0,0
GRID_MAX=pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,1,1,3.5
WALKERS_MPI
... PBMETAD
The grid options (GRID_MIN and GRID_MAX) allow us to store
the bias on a grid, thus increasing the computational performances.
The value of the PBMetaD bias potential and the associated forces
in a generic point of the CV space are then calculated using a
bicubic spline interpolation of the grid points. The units of mea-
sures are: kJ/mol for energy, nm for distances, K for temperature
and number of MD steps for time (here the time step is set to 2 fs).
Finally, we print out the value of each biased CV as well as the
PBMetaD bias.
PRINT
ARG=phi2,phi3,phi4,phi5,phi6,phi7,phi8,phi9,psi1,psi2,psi3,psi4,psi5,psi6,
psi7,psi8,dihtrp_cacb,dihtrp_cbcg,aasimpsi,aasimphi,peplen,pb.bias
FILE=CVS
STRIDE=500
We are now ready to start the simulation. Starting from 14 dif-
ferent conformations extracted from the equilibration run, we gen-
erate 14 TPR ﬁles and run the following command (see Note 5):
mpirun -n 14 gmx_mpi mdrun –s topol –plumed plumed.dat –multi 14
We let the simulation run until convergence (see Note 6) and
then perform a more thorough analysis (Subheading 4.5).
4.3
M&M
with 3J-Couplings
and Chemical Shifts
We now simulate the EGAAWAASS peptide using 3J-couplings and
chemical shifts. In order to do this, we need to add to the
PLUMED ﬁle described above the forward models of the experi-
mental data that will be incorporated into the M&M simulation.
3J-couplings are related to the backbone dihedral angles through
the Karplus equation [50]
3J θ
ð Þ ¼ A cos 2 θ þ Δθ
ð
Þ þ B cos θ þ Δθ
ð
Þ þ C
ð5Þ
where θ is the dihedral angle in question (either ϕ or ψ), and A, B,
C and Δθ are empirically determined parameters, which depend on
the type of coupling observed. PLUMED allows us to calculate
these experimental observables by using the JCOUPLING directive,
and to specify the reference (experimental) values by adding the
ADDCOUPLINGS ﬂag. We also need to specify the TYPE of coupling
[51, 52] and list the dihedral angles associated with each coupling.
In the following PLUMED input, we deﬁne the Hα-N, Hα-HN,
C-Cγ and N-Cγ 3J-couplings along with their reference values in
Hz.
A Practical Guide to Metainference
323

# _G_AW_AS_
JCOUPLING ...
ADDCOUPLINGS
TYPE=HAN
ATOMS1=@psi-2 COUPLING1=-0.49
ATOMS2=@psi-4 COUPLING2=-0.54
ATOMS3=@psi-5 COUPLING3=-0.53
ATOMS4=@psi-7 COUPLING4=-0.39
ATOMS5=@psi-8 COUPLING5=-0.39
LABEL=jhan
... JCOUPLING
# __AAWAASS
JCOUPLING ...
ADDCOUPLINGS
TYPE=HAHN
ATOMS1=@phi-2 COUPLING1=6.05
ATOMS2=@phi-3 COUPLING2=5.95
ATOMS3=@phi-4 COUPLING3=6.44
ATOMS4=@phi-5 COUPLING4=6.53
ATOMS5=@phi-6 COUPLING5=5.93
ATOMS6=@phi-7 COUPLING6=6.98
ATOMS7=@phi-8 COUPLING7=7.16
LABEL=jhahn
... JCOUPLING
# ____W____
JCOUPLING ...
ADDCOUPLINGS
TYPE=CCG
ATOMS1=@chi1-5 COUPLING1=1.59
LABEL=jccg
... JCOUPLING
# ____W____
JCOUPLING ...
ADDCOUPLINGS
TYPE=NCG
ATOMS1=@chi1-5 COUPLING1=1.21
LABEL=jncg
... JCOUPLING
We now add the chemical shifts, which are implemented in the
PLUMED action activated by the CS2BACKBONE directive. This
action uses the CamShift algorithm [53] to calculate the chemical
shifts from a given structure using the following equation
324
Thomas Lo¨ hr et al.

δpred
a
¼ δrc
a þ
X
b, c
αbcdβbc
bc
ð6Þ
where δpred
a
is the predicted chemical shift of atom a, δrc
a
is the
random coil chemical shift of atom a, dbc is the distance between
atoms b and c and αbc and βbc are atom- and residue-dependent
empirical parameters. Atoms b and c are chosen based on complex
distance and residue criteria [53]. In the line of the CS2BACKBONE
directive, we need to specify the ATOMS involved in the calculation
of the chemical shifts, which are typically all the atoms of the
protein:
cs: CS2BACKBONE ATOMS=1-111 DATADIR=data TEMPLATE=egaawaass.pdb
For computational efﬁciency, PLUMED internally uses a
neighbour list to calculate the pairwise interactions required by
CS2BACKBONE. Furthermore, we need to supply a PDB ﬁle of the
molecule (referred to as TEMPLATE), as well as the name of the data
folder (DATADIR). This folder contains the reference chemical shifts
(#shifts.dat), the reference structure (egaawaass.pdb) and
the CamShift database (camshift.pdb):
data
|––– CAshifts.dat
|
|––– CBshifts.dat
|
|––– Cshifts.dat
|
|––– HAshifts.dat
|
|––– Hshifts.dat
|
|––– Nshifts.dat
|
|––– camshift.db
||––– egaawaass.pdb
We are now ready to set up the metainference calculations using
the following input:
METAINFERENCE ...
ARG=(cs\.nh_.∗),(cs\.hn_.∗),(cs\.ha_.∗),(cs\.ca_.∗),(cs\.
cb_.∗),(cs\.co_.∗),(jhan\.j_.∗),(jhahn\.j_.∗),(jccg\.j.∗),
(jncg\.j.∗),pb.bias
PARARG=(cs\.expnh.∗),(cs\.exphn.∗),(cs\.expha.∗),(cs\.expca.
∗),(cs\.expcb.∗),(cs\.expco.∗),(jhan\.exp_.∗),(jhahn\.exp_.
∗),(jccg\.exp.∗),(jncg\.exp.∗)
NOISETYPE=MGAUSS
REWEIGHT
OPTSIGMAMEAN=SEM AVERAGING=200
SIGMA0=25.0 SIGMA_MIN=0.001 SIGMA_MAX=25.0 DSIGMA=0.1
A Practical Guide to Metainference
325

WRITE_STRIDE=10000
LABEL=bycsj
... METAINFERENCE
We will go through the METAINFERENCE directive line by line.
First, in ARG, we specify the output of our previously deﬁned CVs
representing the experimental observables. CS2BACKBONE sorts the
different types of chemical shifts into different components and
residue numbers, so we can use regular expressions to conveniently
provide a list of these CVs. The same principle applies to the
3J-couplings. A very important part of this line is the addition of
the PBMetaD bias from the PBMetaD directive (pb.bias) at the
end of the list of arguments. This bias is used to calculate a
weighted ensemble average of the experimental observables by
accounting for the PBMetaD bias potential (see Subheading 2.4).
Then, in PARARG, we specify the experimental reference values in
the same order as in the ARG keyword and again using regular
expressions.
We continue by specifying the NOISETYPE. We assume that
data points are independent, and we use a Gaussian model of noise
(NOISETYPE) with one error parameter per data point (MGAUSS).
Other available options are a single error parameter for all data
points (GAUSS) or long-tailed distributions to account for outliers
(OUTLIERS, MOUTLIERS). The latter can be used when large ran-
dom or systematic errors are expected for a few data points. The
REWEIGHT ﬂag indicates that we are passing to the METAINFER-
ENCE directive an additional argument (the last) in ARG, which
contains the value of the PBMetaD bias. Next, we specify the
technique used for calculating the standard error of the mean
σ SEM
r,i
(OPTSIGMAMEAN). In this case, SEM implies the automatic
estimation via a windowed average calculation, in which the size of
the window in steps is given by AVERAGING. This quantity corre-
sponds to the size of the window used to average the weights from
PBMetaD.
We sample the error associated with each data using a MC
algorithm (see Note 7). We specify a starting value SIGMA0, lower
and upper sampling bounds SIGMA_MIN and SIGMA_MAX and a
step size DSIGMA. As the data-restraint force is inversely propor-
tional to both the standard error of the meanσ SEM
r,i
and the Bayesian
error σ B
r,i and the averaging procedure for the estimation of σ SEM
r,i
may start from very low values (if the starting conﬁgurations are
similar), it is thus safer to begin the sampling of σ B
r,i from a fairly
high value. The sampling range of σ B
r,i varies depending on the type
of experimental data used (see Note 8). Finally, we allow METAIN-
FERENCE to create checkpoint ﬁles every 10,000 steps with WRI-
TE_STRIDE. These ﬁles contain information necessary to restart
the simulations, such as the variances of each experimental
326
Thomas Lo¨ hr et al.

observable, as well as the last values of the errors σ B
r,i, so that
PLUMED can restart sampling from where it left off.
Before running the simulation, we can instruct PLUMED to
calculate some relevant information that are useful to monitor the
simulation:
# Calculate weighted ensemble average
ENSEMBLE ...
ARG=(nh\.rdc_.∗),(caha\.rdc_.∗),(jhan\.j_.∗),(jhahn\.j_.∗),
(jccg\.j_.∗),(jncg\.j_.∗),(cs\..._.∗),pb.bias REWEIGHT
LABEL=ens
... ENSEMBLE
# We use the analogous function for all other observables
STATS ...
ARG=(ens\.cs\..._.∗) PARARG=(cs\.exp.∗)
LABEL=csst
... STATS
ENSEMBLE performs the same action as the ﬁrst line in
METAINFERENCE, that is, it calculates a weighted ensemble average
on-the-ﬂy. The STATS directive calculates useful statistical informa-
tion, such as the correlation with the experimental values, thus
allowing us to quickly judge the quality of our ensemble. Finally,
we print out the output of the STATS and ENSEMBLE directives
above and the value of each CV biased by PBMetaD:
PRINT ARG=bycsj.∗STRIDE=100 FILE=BAYES.CSJ
PRINT ARG=csst.∗,(ens\.cs\..._.∗) STRIDE=500 FILE=ST.CS
PRINT
ARG=phi2,phi3,phi4,phi5,phi6,phi7,phi8,phi9,psi1,psi2,
psi3,psi4,psi5,psi6,psi7,psi8,dihtrp_cacb,dihtrp_cbcg,aasimp-
si,aasimphi,peplen,pb.bias FILE=CVS STRIDE=500
The output from metainference contains the values of all the
errors (σ B
r,i and σ SEM
r,i ), information regarding the sampling of these
quantities, the weight of each replica and the metainference energy.
We start the simulation as we previously did (Subheading 4.2).
M&M makes use of multiple replicas of the system and, gener-
ally speaking, a higher number of replicas lead to a higher quality
result (see Note 9). To monitor the simulation on-the-ﬂy and
ensure the effectiveness of the metainference approach, we can
look at the value of the standard error of the mean σ SEM
r,i
(Fig. 2)
and of the error σ B
r,i (Fig. 3) along the simulation. These two
quantities together determine the overall intensity of the data-
restraint. Furthermore, we can monitor the metainference energy,
its derivative with respect to the PBMetaD bias, the MC acceptance
A Practical Guide to Metainference
327

rate of the error parametersσ B
r,i (Fig. 4), and the agreement with the
experimental data during the simulation (Fig. 5, see Note 10). We
will let the simulation run until convergence (see Note 6) and then
perform a more thorough analysis (Subheading 4.4).
Fig. 2 Time series of σ SEM
r,i for all the Cβ chemical shifts during the ﬁrst 1000 ps of simulation. After calculating
σ SEM
r,i at each time step t, the square root of the maximum of this value over the last m steps (200 in our case)
is used
Fig. 3 Time series of σ B
r,i for all the Cβ chemical shifts during the ﬁrst 1000 ps of simulation. Their observed
decrease in value corresponds to the data-restraint becoming stronger for the corresponding data point. The
errors become larger when the structural ensemble is inconsistent with the experimental data
328
Thomas Lo¨ hr et al.

4.4
M&M Simulation
3J-Couplings,
Chemical Shifts
and RDCs
We continue by adding residual dipolar couplings (RDCs) to the
M&M simulation. RDCs can be calculated using the θ-method
[54]:
Di ¼  μ0γ1γ2ℏ
8π3
3 cos 2ϑi  1
r3
i


ð7Þ
where Di is the residual dipolar coupling, ri is the bond length, ϑi is
the angle between the bond in question and the external magnetic
ﬁeld (usually taken to be the z-axis), μ0, γ1and γ2 are atom-
dependent constants and ℏis the Planck constant. RDCs are
measured in alignment media and report on the fraction of aligned
molecules. Thus, directly comparing these experimentally observed
values with those calculated in a simulation makes little sense. The
relationship is governed by a scaling factor λ that can be sampled
during the simulation.
We start by deﬁning our forward models for Cα-Hα and N-H
RDCs by using the RDC PLUMED directive. As in the case of the
3J-couplings, we use the ADDCOUPLINGS ﬂag to enable adding the
Fig. 4 Metainference observables during the ﬁrst 1000 ps of the M&M simulation with 3J-couplings and
chemical shifts. (a) Time series of the metainference energy, quantifying the data-restraint intensity. We
would typically expect to see a relatively constant value after equilibration. (b) The derivative of the
metainference energy EMI with respect to the PBMetaD bias VPB. (c) The average MC step acceptance rate
of σ B
r,i for all data points
Fig. 5 Agreement between calculated and experimental Cβ chemical shifts during the ﬁrst 1000 ps of the
simulation. (a) RMSD and (b) Pearson’s correlation coefﬁcient between the back-calculated chemical shifts
and the experimental observables
A Practical Guide to Metainference
329

reference experimental values. For each measured RDC, we need to
specify a pair of ATOMS and the corresponding experimental value
(COUPLING). We also specify the gyromagnetic ratio γ with the
GYROM keyword, which is dependent on the type of observed
dipolar coupling (see PLUMED manual). Finally, the SCALE key-
word allows us to apply a ﬁxed rescaling factor to the calculated
RDCs.
# _GAAWAASS
RDC ...
ADDCOUPLINGS
GYROM=-72.5388
SCALE=0.0001
ATOMS1=18,19 COUPLING1=-5.4
ATOMS2=25,26 COUPLING2=-1.26
ATOMS3=35,36 COUPLING3=-5.22
ATOMS4=45,46 COUPLING4=-0.91
ATOMS5=69,70 COUPLING5=2.33
ATOMS6=79,80 COUPLING6=-2.88
ATOMS7=89,90 COUPLING7=-8.37
ATOMS8=100,101 COUPLING8=-3.78
LABEL=nh
... RDC
# E_AAWAAS_
RDC ...
ADDCOUPLINGS
GYROM=179.9319
SCALE=0.0001
ATOMS1=5,6 COUPLING1=12.95
ATOMS2=27,28 COUPLING2=11.5
ATOMS3=37,38 COUPLING3=21.42
ATOMS4=47,48 COUPLING4=-9.37
ATOMS5=71,72 COUPLING5=10.01
ATOMS6=81,82 COUPLING6=15.01
ATOMS7=91,92 COUPLING7=15.73
LABEL=caha
... RDC
We are now ready to deﬁne the METAINFERENCE directive. We
will use a similar setup as the one used above for the chemical shifts,
with the addition of the keywords needed to activate the sampling
of the scaling factor. As we are using two different datasets of
RDCs, we need to use two separate METAINFERENCE directives
to allow for two different scaling factors. In each directive, we use
the SCALEDATA ﬂag to indicate the use of a variable scaling factor
and the SCALE_PRIOR ﬂag to deﬁne the type of prior distribution.
As the scaling factor should remain relatively constant over time,
330
Thomas Lo¨ hr et al.

specifying a Gaussian prior (see Note 11) will allow us to sample
points around a typical value SCALE0 without deviating too much
from this estimate. The standard deviation of this Gaussian prior is
speciﬁed with DSCALE.
METAINFERENCE ...
ARG=(nh\.rdc_.∗),pb.bias
PARARG=(nh\.exp_.∗)
NOISETYPE=MGAUSS
SCALEDATA
REWEIGHT
OPTSIGMAMEAN=SEM AVERAGING=200
SCALE_PRIOR=GAUSSIAN SCALE0=8.0 DSCALE=0.5
SIGMA0=25.0 SIGMA_MIN=0.001 SIGMA_MAX=25.0 DSIGMA=0.1
WRITE_STRIDE=10000
LABEL=byrdcnh
... METAINFERENCE
METAINFERENCE ...
ARG=(caha\.rdc_.∗),pb.bias
PARARG=(caha\.exp_.∗)
NOISETYPE=MGAUSS
SCALEDATA
REWEIGHT
OPTSIGMAMEAN=SEM AVERAGING=200
SCALE_PRIOR=GAUSSIAN SCALE0=9.0 DSCALE=0.5
SIGMA0=25.0 SIGMA_MIN=0.001 SIGMA_MAX=25.0 DSIGMA=0.1
WRITE_STRIDE=10000
LABEL=byrdccaha
... METAINFERENCE
Estimating the correct value for the scaling factor can be done
as follows. First, one should set DSCALE to some fairly large number
and set SCALE0 to some arbitrary starting point. By running a short
simulation (in this case, 100 ps) and monitoring the value of the
scaling factor in the output of the METAINFERENCE directive, we
can obtain a measure of a reasonable sampling range. Then, the
static scaling in the RDC CV can be adjusted together with the
starting point SCALE0 and DSCALE. The whole procedure should
be done separately for each individual RDC dataset, and the result-
ing factors should be veriﬁed when both datasets are active, as the
scaling factors can be subtly inﬂuenced by additional restraints.
Once the scaling factor λ has been correctly determined, we should
expect to see values for λ oscillating around our SCALE0 value
(Fig. 6a), along with a fairly high MC acceptance rate (Fig. 6b). If
our initial guess is inaccurate, we will see a low acceptance rate
together with sampled values that tend to be far away from our
A Practical Guide to Metainference
331

initial guess. In this case, we would have to revise our estimate of
the scaling factor (see Note 12).
We run the production simulation in the same way as before.
We will monitor the errors σ B
r,i and σ SEM
r,i
as well as the other
metainference observables and the correlations between the for-
ward models and the reference experimental data. We should also
monitor the value of the scaling factor λ (Fig. 6) and, if necessary,
make any adjustments to the sampling range.
4.5
Analysis
In the analysis of our simulations, we will focus on the experimental
observables and their associated errors and also brieﬂy illustrate
how to calculate probability distributions for any generic CVs.
First, we should concatenate our trajectories:
$ gmx trjcat –f traj_comp∗-o cat_traj.xtc -settime
$ gmx trjconv –f cat_traj.xtc –s topol0.tpr –o traj.xtc –pbc mol
The settime ﬂag allows us to specify the starting and end time
for each replica’s trajectory. It should be used to obtain one contin-
uous trajectory. We also correct discontinuities due to periodic
boundary conditions and remove the water, if present. To analyse
this resulting trajectory, we will make use of the PLUMED driver
utility, which reads in a trajectory and calculates certain observables
based on those frames. To do this, the driver requires a PLUMED
input ﬁle, very similar to the one used in the simulation, with some
important differences. First, we need to pass the RESTART ﬂag to
PLUMED. Second, we need to adjust the PACE parameter in
PBMetaD to stop PLUMED from adding additional Gaussians to
the HILLS ﬁles and pass the simulation temperature to PLUMED
by adding TEMP ¼ 300 (see Note 13). We are especially interested in
the PBMetaD bias per frame, as we need it to calculate the weights
[36]. We will also calculate the radius of gyration Rg of the peptide
for each frame by using the GYRATION directive and specifying all
Cα carbons as arguments. Finally, we calculate the experimental
Fig. 6 (a) The scaling factor λ and (b) its MC acceptance rate for the NH RDCs. The initial value of λ ¼ 8 is
slightly larger than ideal, as indicated by the mean and the acceptance rate dropping quickly
332
Thomas Lo¨ hr et al.

observables for each frame using the same directives deﬁned in our
original input ﬁle. The PLUMED ﬁle for analysis with the driver is
RESTART
MOLINFO MOLTYPE=protein STRUCTURE=egaawaass.pdb
WHOLEMOLECULES ENTITY0=1-111
# CVs go here...
cagyr: GYRATION TYPE=RADIUS ATOMS=5,20,27,37,47,71,81,91,102
PBMETAD ...
ARG=phi2,phi3,phi4,phi5,phi6,phi7,phi8,phi9,psi1,psi2,psi3,
psi4,psi5,psi6,psi7,psi8,dihtrp_cacb,dihtrp_cbcg,aasimpsi,aa-
simphi,peplen
SIGMA=0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,
0.6,0.6,0.6,0.6,0.6,0.3,0.3,0.3
HEIGHT=0.3
PACE=500000000
TEMP=300
BIASFACTOR=8
LABEL=pb
GRID_MIN=-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,-pi,
-pi,-pi,-pi,-pi,-pi,-pi,0,0,0
GRID_MAX=pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,pi,
pi,1,1,3.5
... PBMETAD
# We do not need the Metainference directive for post proces-
sing
PRINT ARG=pb.bias FILE=FULLBIAS
PRINT ARG=cagyr FILE=GYR
# Add PRINT directive for all other experimental observables...
PRINT ARG=(jhahn\.j_.∗) FILE=JHAHN
To perform the analysis, we run the following command:
$ plumed driver –-plumed plumed-analysis.dat –-mf_xtc traj.xtc
which will produce the FULLBIAS and GYR ﬁles. These ﬁles contain
the PBMetaD bias and the radius of gyration for each frame of the
trajectory, respectively. We also obtain ﬁles containing the value of
each experimental observable for every frame of the trajectory.
To calculate ensemble averages and free energies, we need to
calculate the weight of each frame from the bias, which can be done
using the following python code (see Note 2):
A Practical Guide to Metainference
333

import numpy as np
KBT = 2.49
bias = np.loadtxt("FULLBIAS")
weights = np.exp(bias[:,1] / KBT)
weights /= weights.sum()
Using these unbiasing weights, we can now calculate ensemble
averages and probability distributions of any function of the coor-
dinates of the system. We start by calculating ensemble averages for
all back-calculated experimental observables. With those, we can
obtain root-mean-square deviations (RMSDs) between a particular
dataset (such as Hα-HN 3J-couplings) and the experimental refer-
ence values (Fig. 7, see Note 14):
jhahn = np.loadtxt("JHAHN")[:,1:]
jhahn_mean = (jhahn ∗weights.reshape(-1, 1)).sum(axis=0)
jhahn_exp = np.array([6.05, 5.95, 6.44, 6.53, 5.93, 6.98, 7.16])
rmsd = np.sqrt(((jhahn_mean - jhahn_exp) ∗∗2).mean())
We skip loading the ﬁrst column of the ﬁle JHAHN, since it only
contains the simulation time, which is not needed for this particular
analysis. We then compute the ensemble average using the weights
determined above and continue by calculating the RMSD between
our ensemble averages and the reference experimental values for a
particular dataset. We can use the same principle to compute the
RMSDs with respect to the other experimental observables. Look-
ing at the results, we can see a better agreement with the experi-
mental data (Fig. 7).
We will continue by looking at the probability distribution of
the radius of gyration Rg. We make use of the weights previously
calculated to calculate probability distributions:
Fig. 7 RMSD between the calculated experimental observables from unrestrained, partially restrained
(chemical shifts and 3J-couplings) and fully restrained (chemical shifts, 3J-couplings, RDCs) simulations
and the experimental measurements. While the agreement of both chemical shifts and 3J-couplings with the
experimental data is signiﬁcantly improved upon the introduction of these data, the RDCs remain largely
unaffected. Vice versa, the RDCs have little inﬂuence on the quality of the chemical shifts and 3J-couplings
334
Thomas Lo¨ hr et al.

gyr = np.loadtxt("GYR")[:,1]
hist, bins = np.histogram(gyr, bins=50, weights=weights, den-
sity=True)
The probability densities give us crucial information on the
behaviour of the system. In this case, we can see that EGAAWAASS
is primarily found in two states (Fig. 8): a fairly compact
(Rg ~ 0.5 nm) and a more extended form (Rg ~ 0.8 nm). This
feature only emerges when introducing experimental data, as the
prior information encoded in the CHARMM22∗force ﬁeld is
insufﬁcient to accurately determine these states.
Finally, we also look at the distributions of the Bayesian error
σ B
r,i for several data points (Fig. 9). In the case of Cβ chemical shifts,
we see a fairly large spread for the A6 residue, indicating a relatively
weak restraint. This could be due to errors in the parameterization
of the CamShift predictor and/or random or systematic errors in
the experimental data.
5
Notes
1. PBMetaD deposits multiple Gaussians along n one-dimen-
sional CVs as opposed to the one n-dimensional Gaussian
added in standard metadynamics. As CVs are typically corre-
lated, Gaussians are not simultaneously added to all variables,
but only to an “active” CV deﬁned by a discrete switching
variable η. After marginalising η, we obtain a conditionally
weighted Gaussian.
2. The weights needed to unbias a PBMetaD simulation can be
calculated using the Torrie-Valleau approach [36]:
Fig. 8 Probability distribution of the radius of gyration Rg for unrestrained,
partially restrained (3J-couplings and chemical shifts) and fully restrained
(3J-couplings, chemical shifts, and RDCs) simulations. With an increase in
experimental data used in metainference, we see the appearance of two
distinct peaks from the originally ﬂat distribution
A Practical Guide to Metainference
335

w S1; S2
ð
Þ / e
V PB

S1;S2;t

kBT
where V PB

S1; S2; t

is the ﬁnal PBMetaD bias, and S1 and S2
are two CVs.
3. The LINCS constraint parameters used in M&M simulations
are typically more conservative than the default of values of
1 iteration and a matrix expansion of the order of 4 because the
introduction of experimental data can add additional strains on
constrained bonds.
4. The
WHOLEMOLECULES
directive
reconstructs
inside
PLUMED the molecules broken inside the MD code by peri-
odic boundary conditions. The atoms deﬁning the molecules
are speciﬁed by the ENTITY0 keyword. Additional molecules
can be speciﬁed by using multiple ENTITY keywords.
5. To run multi-replica simulations, both PLUMED and GRO-
MACS must be compiled with MPI support. The GROMACS
executable is typically called gmx_mpi, and all simulations
should be started with an appropriate launcher such as
mpiexec or mpirun and specifying the number of MPI pro-
cesses to used. The exact name and syntax of this command
depend on the system used.
6. The convergence of well-tempered PBMetaD simulations as
well as the error in the reconstructed free energies can be
assessed by using the block-analysis procedure illustrated in
the PLUMED tutorials available at www.plumed.org.
7. For systems with many data points and thus many associated
error parameters, one may experience very low MC acceptance
rates and thus encounter sampling issues. This problem can be
Fig. 9 Distribution of σ B
r,i for all the Cβ chemical shifts across the metainference
ensemble. The mean and median are indicated with a line and a dot, while the
box edges and whiskers indicate the mid two quartiles and ﬁfth and 95th
percentile, respectively. With high-quality data and good sampling, we expect
to observe small errors
336
Thomas Lo¨ hr et al.

alleviated by performing sampling of the error parameters in
groups by using the MC_CHUNKSIZE and MC_STEPS keywords.
For example, with 100 data points, one can perform ﬁve MC
steps, with 20 data points moved at each step.
8. When setting DSIGMA, we need to take care that the step sizes
are not too large to cause instabilities and low MC acceptance
rate (Fig. 4c) and not too small to result in slow and insufﬁcient
sampling.
9. In metainference, f i is the (unknown) average of the forward
model fi calculated over an inﬁnite number of replicas, while
p

f e
r,ijX; σ SEM
r,i

quantiﬁes the difference between the unknown
average f i and the estimate fi calculated using a small set of
replicas. Therefore, in order to keep σ SEM
r,i
small, we should use
as many replicas as possible.
10. The best way to determine the agreement with the experimen-
tal data is to calculate the RMSDs of the average of the experi-
mental observables over the entire metainference simulation.
However, during the course of the simulation, quantities such
as the correlation and RMSDs between the forward model and
the experimental value can be used to evaluate the satisfaction
of the data-restraints. It is very important to keep in mind that
typical values for the correlation might vary between systems
and types of data, and therefore, they can only be used to
evaluate the relative as opposed to absolute quality of the ﬁt.
11. In metainference, the sampling of the scaling factor λ makes use
of an Ornstein-Uhlenbeck process [55]. The result is a trajec-
tory of points with limited jumps and sampling a Gaussian
distribution:
dλt ¼ 1
2 μ  λt
ð
Þ þ ΔλdW t
where dλt is the step taken, μ is the speciﬁed mean of the
stationary Gaussian distribution, λt is the scaling value at time
t, Δλ is the standard deviation of the stationary Gaussian distri-
bution and dWt denotes the Wiener process (i.e. Brownian
motion). Using a process of this form ensures that the step
size is not too large and helps to keep the simulation stable.
12. When working with RDCs, one can sometimes observe a neg-
ative correlation. In this case, one should invert the sign of the
scaling factor (in the RDC CV).
13. Specifying the temperature is not required during simulation,
as it is explicitly passed to PLUMED from the MD engine.
A Practical Guide to Metainference
337

14. The root-mean-square deviation (RMSD) is given by
RMSD ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
N d
X
N d
i¼1
f i X
ð Þ  di

2
v
u
u
t
where Nd is the total number of data points, fi(X) is the
ensemble-average of the forward model for the ith data point
and di is the reference experimental value.
References
1. Frenkel D, Smit B (2002) Understanding
molecular
simulation:
from
algorithms
to
applications, 2nd edn. Academic Press, San
Diego, p xxii, 638p
2. Bonomi M, Camilloni C, Cavalli A, Vendrus-
colo M (2016) Metainference: a Bayesian infer-
ence method for heterogeneous systems. Sci
Adv 2:e1501177
3. Bonomi M, Vendruscolo M (2019) Determi-
nation of protein structural ensembles using
cryo-electron microscopy. Curr Opin Struct
Biol 56:37–45
4. Camilloni C, Pietrucci F (2018) Advanced sim-
ulation techniques for the thermodynamic and
kinetic characterization of biological systems.
Adv Phys X 3:1477531
5. Robustelli P, Piana S, Shaw DE (2018) Devel-
oping a molecular dynamics force ﬁeld for both
folded and disordered protein states. Proc Natl
Acad Sci U S A. https://doi.org/10.1073/
pnas.1800690115
6. Nerenberg PS, Head-Gordon T (2018) New
developments in force ﬁelds for biomolecular
simulations.
Curr
Opin
Struct
Biol
49:129–138
7. Bottaro S, Lindorff-Larsen K (2018) Biophysi-
cal experiments and biomolecular simulations:
a perfect match? Science 361:355–360
8. Bonomi M, Heller GT, Camilloni C, Vendrus-
colo M (2017) Principles of protein structural
ensemble determination. Curr Opin Struct
Biol 42:106–116
9. Ravera E, Sgheri L, Parigi G, Luchinat C
(2016) A critical assessment of methods to
recover information from averaged data. Phys
Chem Chem Phys 18:5686–5701
10. Lindorff-Larsen K, Best RB, Depristo MA,
Dobson CM, Vendruscolo M (2005) Simulta-
neous determination of protein structure and
dynamics. Nature 433:128–132
11. Cavalli A, Camilloni C, Vendruscolo M (2013)
Molecular dynamics simulations with replica-
averaged
structural
restraints
generate
structural ensembles according to the maxi-
mum
entropy
principle.
J
Chem
Phys
138:094112
12. Schneidman-Duhovny D, Pellarin R, Sali A
(2014) Uncertainty in integrative structural
modeling. Curr Opin Struct Biol 28:96–104
13. Rieping W, Habeck M, Nilges M (2005) Infer-
ential
structure
determination.
Science
309:303–306
14. Box GEP, Tiao GC (1973) Bayesian inference
in statistical analysis. Addison-Wesley Pub. Co.,
Reading, MA, p xviii, 588p
15. Viswanath S, Bonomi M, Kim SJ et al (2017)
The molecular architecture of the yeast spindle
pole body core determined by Bayesian inte-
grative
modeling.
Mol
Biol
Cell
28:3298–3314
16. Molnar KS, Bonomi M, Pellarin R et al (2014)
Cys-scanning disulﬁde cross linking and Bayes-
ian modeling probe the transmembrane signal-
ing mechanism of the histidine kinase, PhoQ.
Structure 22:1239–1251
17. Street TO, Zeng XH, Pellarin R et al (2014)
Elucidating the mechanism of substrate recog-
nition by the bacterial Hsp90 molecular chap-
erone. J Mol Biol 426:2393–2404
18. Zelter A, Bonomi M, Kim JO et al (2015) The
molecular architecture of the Dam1 kineto-
chore complex is deﬁned by cross-linking
based structural modelling. Nat Commun 6:
E9673
19. Kim SJ, Fernandez-Martinez J, Nudelman I
et al (2018) Integrative structure and func-
tional anatomy of a nuclear pore complex.
Nature 555:475–482
20. Erzberger JP, Stengel F, Pellarin R et al (2014)
Molecular architecture of the 40S center dot
eIF1 center dot eIF3 translation initiation
complex. Cell 158:1123–1135
21. Bonomi M, Hanot S, Greenberg C et al (2019)
Bayesian weighing of electron cryo-microscopy
data for integrative structural modeling. Struc-
ture 27:1–14
338
Thomas Lo¨ hr et al.

22. Robinson PJ, Trnka MJ, Pellarin R et al (2015)
Molecular architecture of the yeast mediator
complex. Elife 4:e08719
23. Ferber M, Kosinski J, Ori A et al (2016) Auto-
mated structure modeling of large protein
assemblies
using
crosslinks
as
distance
restraints. Nat Methods 13:515–520
24. Russel D, Lasker K, Webb B et al (2012) Put-
ting the pieces together: integrative modeling
platform software for structure determination
of macromolecular assemblies. PLoS Biol 10:
e1001244
25. Brunger AT, Adams PD, Clore GM et al
(1998) Crystallography & NMR system: a
new software suite for macromolecular struc-
ture
determination.
Acta
Crystallogr
D
54:905–921
26. Heller GT, Aprile FA, Bonomi M et al (2017)
Sequence
speciﬁcity
in the entropy-driven
binding of a small molecule and a disordered
peptide. J Mol Biol 429:2772–2779
27. Hultqvist G, Aberg E, Camilloni C et al (2017)
Emergence and evolution of an interaction
between intrinsically disordered proteins. Elife
6:e16059
28. Bonomi M, Pellarin R, Vendruscolo M (2018)
Simultaneous determination of protein struc-
ture and dynamics using cryo-electron micros-
copy. Biophys J 114:1604–1613
29. Vahidi S, Ripstein ZA, Bonomi M et al (2018)
Reversible inhibition of the ClpP protease via
an N-terminal conformational switch. Proc
Natl Acad Sci U S A 115:E6447–E6456
30. Kooshapur N, Choudhury NR, Simon B et al
(2018) Structural basis for terminal loop rec-
ognition and stimulation of pri-miRNA-18a
processing by hnRNP A1. Nat Commun 9:
E2479
31. Lohr T, Jussupow A, Camilloni C (2017)
Metadynamic
metainference:
convergence
towards force ﬁeld independent structural
ensembles of a disordered peptide. J Chem
Phys 146:165102
32. Barducci A, Bonomi M, Parrinello M (2011)
Metadynamics.
Wires
Comput
Mol
Sci
1:826–843
33. Pfaendtner J, Bonomi M (2015) Efﬁcient sam-
pling of high-dimensional free-energy land-
scapes
with
parallel
bias metadynamics.
J
Chem Theory Comput 11:5062–5067
34. Bonomi M, Camilloni C, Vendruscolo M
(2016) Metadynamic metainference: enhanced
sampling of the metainference ensemble using
metadynamics. Sci Rep 6:31232
35. Raiteri P, Laio A, Gervasio FL, Micheletti C,
Parrinello M (2006) Efﬁcient reconstruction of
complex free energy landscapes by multiple
walkers
metadynamics.
J
Phys
Chem
B
110:3533–3539
36. Torrie GM, Valleau JP (1977) Non-physical
sampling distributions in Monte-Carlo free-
energy estimation – umbrella sampling. J Com-
put Phys 23:187–199
37. Hess B, Kutzner C, van der Spoel D, Lindahl E
(2008) GROMACS 4: algorithms for highly
efﬁcient, load-balanced, and scalable molecular
simulation.
J
Chem
Theory
Comput
4:435–447
38. Bonomi M, Camilloni C (2017) Integrative
structural
and
dynamical
biology
with
PLUMED-ISDB.
Bioinformatics
33:3999–4000
39. Tribello
GA,
Bonomi
M,
Branduardi
D,
Camilloni C, Bussi G (2014) PLUMED 2:
new feathers for an old bird. Comput Phys
Commun 185:604–613
40. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph Model 14:33–38
41. Barrett P, Hunter J, Miller JT, Hsu JC, Green-
ﬁeld P (2005) Matplotlib – a portable python
plotting package. ASP Conf Ser 347:91–95
42. Palazzesi F, Prakash MK, Bonomi M, Barducci
A (2015) Accuracy of current all-atom force-
ﬁelds in modeling protein disordered states. J
Chem Theory Comput 11:2–7
43. Dames SA, Aregger R, Vajpai N et al (2006)
Residual dipolar couplings in short peptides
reveal systematic conformational preferences
of individual amino acids. J Am Chem Soc
128:13508–13514
44. Bussi G, Donadio D, Parrinello M (2007)
Canonical sampling through velocity rescaling.
J Chem Phys 126:014101
45. Parrinello M, Rahman A (1980) Crystal-
structure and pair potentials – a molecular-
dynamics study. Phys Rev Lett 45:1196–1199
46. Piana S, Lindorff-Larsen K, Shaw DE (2011)
How robust are protein folding simulations
with respect to force ﬁeld parameterization?
Biophys J 100:L47–L49
47. Essmann U, Perera L, Berkowitz ML et al
(1995) A smooth particle mesh Ewald method.
J Chem Phys 103:8577–8593
48. Hess B (2008) P-LINCS: a parallel linear con-
straint solver for molecular simulation. J Chem
Theory Comput 4:116–122
49. Barducci A, Bussi G, Parrinello M (2008) Well-
tempered metadynamics: a smoothly converg-
ing and tunable free-energy method. Phys Rev
Lett 100:020603
A Practical Guide to Metainference
339

50. Karplus M (1959) Contact electron-spin cou-
pling of nuclear magnetic moments. J Chem
Phys 30:11–15
51. Wang AC, Bax A (1995) Reparametrization of
the Karplus relation for (3)J(H-Alpha-N) and
(3)J(H-N-C0)
in
peptides
from
uniformly
C-13/N-15-enriched human ubiquitin. J Am
Chem Soc 117:1810–1813
52. Hu JS, Bax A (1997) Determination of phi and
chi(1) angles in proteins from C-13-C-13
three-bond J couplings measured by three-
dimensional heteronuclear NMR. How planar
is
the
peptide
bond?
J
Am
Chem
Soc
119:6360–6368
53. Kohlhoff
KJ,
Robustelli
P,
Cavalli
A,
Salvatella X, Vendruscolo M (2009) Fast and
accurate predictions of protein NMR chemical
shifts from interatomic distances. J Am Chem
Soc 131:13894–13895
54. Camilloni C, Vendruscolo M (2015) A tensor-
free method for the structural and dynamical
reﬁnement of proteins using residual dipolar
couplings. J Phys Chem B 119:653–661
55. Uhlenbeck GE, Ornstein LS (1930) On the
theory
of
Brownian
motion.
Phys
Rev
36:823–841
340
Thomas Lo¨ hr et al.

Chapter 14
Inferring Structural Ensembles of Flexible and Dynamic
Macromolecules Using Bayesian, Maximum Entropy,
and Minimal-Ensemble Reﬁnement Methods
Ju¨rgen Ko¨ﬁnger, Bartosz Ro´z˙ycki, and Gerhard Hummer
Abstract
The ﬂexible and dynamic nature of biomolecules and biomolecular complexes is essential for many cellular
functions in living organisms but poses a challenge for experimental methods to determine high-resolution
structural models. To meet this challenge, experiments are combined with molecular simulations. The latter
propose models for structural ensembles, and the experimental data can be used to steer these simulations
and to select ensembles that most likely underlie the experimental data. Here, we explain in detail how the
“Bayesian Inference Of ENsembles” (BioEn) method can be used to reﬁne such ensembles using a wide
range of experimental data. The “Ensemble Reﬁnement of SAXS” (EROS) method is a special case of
BioEn, inspired by the Gull-Daniell formulation of maximum entropy image processing and focused
originally on X-ray solution scattering experiments (SAXS) and then extended to integrative structural
modeling. We also brieﬂy sketch the “minimum ensemble method,” a maximum-parsimony reﬁnement
method that seeks to represent an ensemble with a minimal number of representative structures.
Key words Ensemble reﬁnement, Bayes, Maximum entropy, Minimal ensemble
1
Introduction
The inference of structural ensembles for ﬂexible and dynamic
biomolecules and biomolecular complexes is a challenging task for
experiment and simulation [1–4]. The structural information con-
tent of experiments is usually not high enough to infer large
ensembles of high-resolution structures from the data alone.
Molecular simulations, in contrast, can generate ensembles of
structures but suffer to varying degrees from systematic and sam-
pling errors. The integration of experimental data and molecular
simulations can overcome the limitations of the individual
approaches. By reﬁning simulation ensembles with the information
from experiments, we aim to obtain an ensemble of structures
representative of the true ensemble that underlies the data (Fig. 1).
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_14, © Springer Science+Business Media, LLC, part of Springer Nature 2019
341

When integrating experimental data and molecular simula-
tions, we have to balance the information provided by these two
complementary approaches. Speciﬁcally, we have to take into
account all signiﬁcant sources of uncertainties. For many experi-
ments, error models are available and estimates of the errors are
provided with the data. The uncertainties in simulations are gener-
ally more difﬁcult to obtain. Errors due to coarse-graining and due
to approximations in the force ﬁelds have not yet been assessed
systematically. However, our conﬁdence in simulation ensembles
usually reﬂects the level of coarse-graining, the different qualities of
force ﬁelds, and the extent of the sampling. In such a situation, we
can take advantage of the Bayesian approach not only to combine
information from experiment and simulation but also to express
our prior conﬁdence in the uncorrected simulation ensemble. Here
we describe the Bayesian Inference of Ensembles (BioEn) method
[5], which is a generalization of the “Ensemble Reﬁnement of
SAXS” (EROS) method [6], to combine information from experi-
ment and simulation.
The EROS method is based on the maximum entropy
approach [7]. This approach and the Bayesian method are tightly
connected [8]. Unlike the Bayesian approach, which offers a clear
way to take into account experimental and theoretical uncertainties
via the likelihood, accounting for uncertainties is more challenging
in a maximum entropy approach. Various solutions to this problem
have been proposed [1, 9, 10]. Notably, the method of Cesari and
Bussi corresponds to a special case of the EROS method for Gauss-
ian errors [10, 11] and has been recently applied to reﬁne ensem-
bles of RNA oligonucleotides using NMR data [12]. EROS was
originally developed to integrate SAXS data but is not restricted to
this kind of experimental data. It has also been used to integrate
data from spectroscopy methods based on site-directed labeling
[13, 14]. A variant of EROS can be accessed via a webserver to
Fig. 1 Schematic representation of ensemble reﬁnement by combining simulation and experiment using the
BioEn or EROS methods. Areas of the color-ﬁlled circles represent the statistical weights of the enclosed
molecular structures (black) from simulations before reﬁnement (left box) and after reﬁnement (right box),
integrating diverse experimental data (center box)
342
Ju¨ rgen Ko¨ ﬁnger et al.

integrate NOEs, J-couplings, and chemical shifts measured in
NMR experiments, using a coil library as reference that is based
on experimental structures of proteins [15, 16].
To illustrate the general formalism with a concrete source of
experimental data, we focus here on small-angle X-ray scattering
(SAXS) experiments as a prototypical example of an ensemble
method that beneﬁts from ensemble reﬁnement. SAXS experiments
are performed on macromolecules in aqueous solutions. As a result,
the X-rays are scattered by macromolecules that are oriented ran-
domly relative to the incident beam. Because of this orientational
averaging, the resulting scattering image depends on the scattering
angle only. In this way, three-dimensional molecular structures are
reduced to one-dimensional intensity proﬁles. Despite the resulting
loss in information, the scattering intensity proﬁles can be used to
determine the average molecular shapes and dimensions of the
macromolecule or macromolecular complex. Moreover, SAXS
data have a high distinguishing power, which is exploited to reﬁne
ensembles of molecular models for ﬂexible and highly dynamic
protein complexes.
With the help of methods such as BioEn, data from various
experiments can be combined and used together in molecular
modeling. For instance, X-ray crystallography and NMR experi-
ments provide high-resolution structures of individual domains.
NMR experiments can in addition provide a wide range of struc-
tural and dynamic information, also for systems with a high degree
of disorder. Electron microscopy provides information about the
domain organization, in some cases at atomic resolution. SAXS
provides information on the global size and shape of the molecular
assembly. DEER or FRET data impose restraints on distances
between selected sites. By combining such experimental data, it
has been possible to obtain detailed representations of the struc-
tures and motions in systems ranging from the ESCRT membrane-
protein trafﬁcking system [13, 14] to protein kinases in dynamic
complexes with phosphatases [17, 18], and the Atg1-complex
[19]. In Subheading 5, we will give a point-by-point description
of how hybrid structures are obtained using the EROS method.
2
Theory
In the BioEn [5] and EROS methods [6], we determine the statis-
tical weights of the members of the structural ensemble that most
likely underlies the experimental data. To express our conﬁdence in
the simulation ensemble before new data are available, a prior
p({wα}) is acting on the statistical weights wα of individual struc-
tures indexed by α, with
PN
α¼1 wα ¼ 1. The posterior p({wα}|
data) / p({wα}) p(data| {wα}) accounts for the new data by multi-
plying the prior with the likelihood p(data| {wα}), which is
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
343

determined by experimental errors and by errors in the forward
calculation of the experimental observables from the simulation
ensemble. The optimal statistical weights maximize the posterior.
In BioEn, we use an entropic prior on the vector of weights of
the ensemble members,
pðfwαgÞ / exp θSKL
wα
f
g, wð0Þ
α






,
where SKL
wα
f
g, wð0Þ
α




¼ P
αwαlog wα
wð0Þ
α
is the Kullback-Leibler
divergence, with respect to the reference weights
wð0Þ
α


. A large
value of the conﬁdence parameter θ expresses large conﬁdence in
the simulation ensemble. The maximum of the posterior with
respect to the weight vector {wα} determines the optimal weights,
that is, the optimal ensemble. For a large value of θ, the optimal
solution for {wα} will be close to the reference weights
wð0Þ
α


.
For (un)correlated Gaussian experimental errors, the BioEn
maximum posterior solution corresponds to the minimum free
energy solution of the EROS method. Then, the likelihood is
given by the Gaussian distribution
p dataj wα
f
g
ð
Þ / exp χ2
2
h
i
where χ2 ¼ δYTΣ1δY is determined by the difference vector
δY between experimental and predicted data points and by the
covariance matrix Σ representing the errors. Instead of maximizing
the posterior, we can minimize the negative log-posterior given by
χ2
2 þ θSKLðfwαg, fwð0Þ
α g

. This expression corresponds to the EROS
free energy [6], originally written in terms of the relative entropy
S given by the negative Kullback-Leiber divergence, that is,
S ¼ SKL. Note that in the BioEn formulation, χ2 is multiplied by
½, stemming from the likelihood, which trivially redeﬁnes θ com-
pared to the original EROS deﬁnition, which does not include the
factor ½.
3
Methods
To perform ensemble reﬁnement, we have to (a) generate an
ensemble of structures (see Notes 1, 2, and 3), (b) calculate the
experimental observable for each structure in the ensemble (see
Notes 4, 5, 6, and 7), and (c) determine the optimal statistical
weights of these structures describing the true ensemble (see Notes
8 and 9).
For ensemble reﬁnement to be successful, our reference ensem-
ble has to have good coverage of the true ensemble underlying the
data. To generate such an ensemble, we can run any form of biased
and/or unbiased simulation as long as we determine the statistical
weights of all structures with respect to the reference ensemble, for
example, using binless WHAM [20]. Usually, we choose the unbi-
ased ensemble as the reference and express our conﬁdence in the
simulations with respect to this ensemble. To obtain good cover-
age, we ideally use the experimental data itself to directly steer the
344
Ju¨ rgen Ko¨ ﬁnger et al.

simulations [5, 9, 10, 21–24]. This kind of biasing using either
replica simulations or generalized forces is usually more efﬁcient for
smaller ensemble sizes. However, if the ensemble size is too small
then the ensemble will suffer from ﬁnite-size effects. Importantly,
we can effectively remove such ﬁnite size effects by properly com-
bining enriched ensembles from biased simulations and applying
BioEn reweighting [5].
We have to be able to calculate the experimental observables
accurately and efﬁciently for biasing of simulations and for
reweighting of an existing ensemble. For SAXS, we can choose
from a wide range of tools and methods [6, 25–29] including
methods for fully atomistic molecular dynamics simulations using
explicit water [30–32]. The latter methods cover both the small-
angle (SAXS) and the wide-angle (WAXS) regimes, and software is
available via webserver [33] or download ([30], https://github.
com/bio-phys/capriqorn), for example.
Once we have generated a reference ensemble and calculated
the observables, we have to ﬁnd the optimal weights by maximizing
the posterior, that is, minimizing the negative log-posterior, which
corresponds to the EROS free energy for Gaussian errors. We can
perform this minimization using simulated annealing or gradient-
based minimization [51]. Nuisance parameters, like scaling of abso-
lute intensities or hydration shell densities in the case of SAXS, can
be included in such a minimization.
4
Concluding Remarks
An ensemble of structures generated by molecular simulations does
not have to be perfect to be useful. The molecular simulations serve
merely to produce an initial pool of meaningful candidate confor-
mations and initial estimates of their statistical weights in the
ensemble. However, the success of the BioEn and EROS methods
requires that this pool covers at least in part the relevant conforma-
tion space. To ensure extensive sampling, it is important that the
simulation model is computationally efﬁcient. To ensure sufﬁcient
populations of relevant conformations, physics-based simulation
models hold much promise also for multi-domain proteins and
multi-protein complexes. In fact, the transferable energy function
used in the EROS simulations, that is, the KH-model, has been
shown to correctly predict structures and binding afﬁnities of a
number of protein–protein complexes [34]. Also, in a recent
study on cellulosomal proteins [35], the ensemble of simulation
structures ﬁtted SAXS experimental data without any reﬁnement.
In principle, the structural ensemble can be ﬁtted either to raw
experimental data or to commensurate quantities such as SAXS-
derived pair-distance distribution functions or DEER-derived
inter-label distance distribution functions. However, to avoid
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
345

introducing any regularization-dependent artifacts into the ensem-
ble reﬁnement, the simulation structures are ﬁtted directly to exper-
imental data in the framework of the EROS method. Fitting the
weights of a structural ensemble directly to the raw data has also
opened an avenue to model electron microscopy images of systems
exhibiting dynamics or disorder [36, 37].
Open source software to perform BioEn ensemble reﬁnement
is available free of charge at https://github.com/bio-phys/BioEn.
5
Notes
In the following, we detail how ensemble reﬁnement using the
BioEn and EROS methods is implemented in practice. To illustrate
this procedure we focus on SAXS experimental data [38].
1. Construct a structural model of the complete macromolecular
system under study. The resolution required for the input struc-
tures is determined by the coarse-graining used in the simula-
tions. Often, atomistic structures of the constituent proteins
and/or domains are available. If not, homology models of the
protein domains can be used instead. The ﬂexible loops and
inter-domain linkers, which are absent in the atomic structures,
need to be built into the model using tools such as MODEL-
LER [39]. For simulations using the KH-model for protein
complexes [34], one has to decide which parts of the macro-
molecule are ﬂexible and which ones are ordered.
2. Generate an ensemble of structural models using molecular simu-
lations. The simulations typically start from the models devel-
oped in step 1. The simulations can be biased using prior
knowledge or experimental data. For example, in simulations
of the p38α:HePTP complex, NMR chemical shift perturba-
tions were incorporated as weak bias potentials [18, 21]. Binless
WHAM [20] makes it possible to combine different biased and
unbiased simulations and to give the resulting structures prior
weights that properly reﬂect the chosen reference ensemble. To
trade off between the competing demands of force-ﬁeld accu-
racy and sampling a large conformational space, an appropriate
level of coarse-graining should be chosen. To simulate large
conformational ﬂuctuations in ﬂexible protein systems, Kim
and
Hummer
[34]
introduced
a
highly
coarse-grained
approach. This KH-model has been simulated using in-house
software but has also been implemented in software packages
such as CHARMM [40] and other simulation software for
coarse-grained models [41]. Recently, Dignon and coworkers
[42] have used the KH-model in LAMMPS [43] and
HOOMD [44] to study the phase behavior of disordered
proteins. Note that reference ensembles do not have to be
346
Ju¨ rgen Ko¨ ﬁnger et al.

produced by simulations to be amenable to ensemble reﬁne-
ment by reweighting as, for example, is done in spin-label
rotamer reﬁnement [45–47].
3. Reweighting to common reference. A set of (un)biased simula-
tions can be combined to a reference ensemble using binless
WHAM [20]. This procedure returns reference statistical
weights wð0Þ
α
for each structure in the ensemble. If we use the
simulation ensemble generated in an unbiased simulation as the
reference ensemble, then all reference weights are set equal.
4. Experimental observables. For each of the simulation structures
obtained above, one computes the relevant experimental obser-
vables. The original EROS method uses a particularly simple
approach to calculate SAXS intensities, which assumes constant
form-factors of the amino-acid beads [6]. To compute FRET
efﬁciencies or the DEER dipolar evolution function, it is
required to model the ﬂuorescence labels or the spin labels on
the protein surface. One can use rotamer libraries [48] or
molecular dynamics simulations [49, 50] to generate a pool
of possible conformations of the ﬂuorescence or spin labels.
5. (Optional) Clustering. To reduce the size of the ensemble,
simulation structures can be clustered. Instead of reﬁning the
weights of individual structures, one then reﬁnes the weights of
clusters. The latter are given by the sum of the weights of the
cluster members. Standard clustering algorithms such as k-
means [51] or QT-clustering [52] are typically sufﬁcient for
this purpose. However, it is important to choose an appropriate
metric to cluster the simulation structures. In fact, there are
many possible measures for the degree of similarity between
protein structures. The most common one is the root-mean-
square deviation (RMSD) of atomic positions. To compute
RMSD, however, it is necessary to superimpose structures,
which can be problematic in the case of ﬂexible protein systems.
For
this
reason,
EROS
uses
distance
root-mean-square
(DRMS) instead. The DRMS between structures A and B is
deﬁned as DRMS A; B
ð
Þ ¼
1
N 2
P
n,m
d A
ð Þ
n,m  d B
ð Þ
n,m
	
2
 
!1=2
where
d A
ð Þ
n,m is the Cartesian distance between the amino acid beads
n and m in structure A, and N2 is the number of bead pairs over
which the sum is performed. Similarity of the experimental
observables can be used as an additional clustering criterion.
The following steps are the same if clustering has been applied
or not.
6. Assign measurable quantities to the (clusters of) simulation
structures. If clustering has been applied, then the SAXS inten-
sity Ik(q) at momentum transfer q assigned to cluster number
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
347

k is the weighted average of SAXS intensities. In this average,
each intensity of a structure α in the cluster Ck is weighted by
wα/wk, where the cluster weight wk is given by the sum of the
weights of all structures γ in cluster Ck, that is, wk ¼ P
γϵCkwγ.
By analogy, FRET efﬁciencies or DEER dipolar evolution func-
tions assigned to a given cluster are weighted averages of FRET
or DEER signals resulting from all structures in this cluster.
7. Ensemble-averaged observables. The average SAXS intensity pro-
ﬁle resulting from the whole ensemble of simulation structures
is given by a weighted average, that is, I sim q
ð Þ ¼ P
α
wαI α q
ð Þ,
where Iα(q) is the SAXS intensity proﬁles assigned to the indi-
vidual structure, or if clustering has been applied, the proﬁles of
the clusters, that is, I sim q
ð Þ ¼ P
k
wkI k q
ð Þ. Correspondingly, we
have to perform weighted averages for other ensemble-
averaged quantities such as FRET efﬁciencies or DEER dipolar
evolution functions, which should be compared directly to
experimental data. The discrepancy between the computed,
ensemble-averaged intensity proﬁle Isim(q), and the experimen-
tal
SAXS
data
Iexp(q)
can
be
quantiﬁed
by
χ2
SAXS ¼ P
N q
i¼1
cI sim qi
ð ÞþdI exp qi
ð Þ
ð
Þ
2
σ2 qi
ð Þ
where the scale factor c and off-
set d result from the conditions
∂χ2
SAXS=∂c ¼ 0
and
∂χ2
SAXS=∂d ¼ 0. Nq is the number of data points. The offset
parameter d accounts for uncertainties in the buffer subtraction
and/or uncertainties in the electron contrast. The discrepancy
between the computed, ensemble-averaged FRET or DEER
signals and the data from FRET or DEER experiments, respec-
tively, can be quantiﬁed by analogous expressions. The result-
ing model-data discrepancy χ2 ¼ χ2
SAXS þ χ2
FRET þ χ2
DEER is a
function of the statistical weights of the clusters. Note that in
the original EROS method we multipliedχ2
SAXSby a factor 1/Nq
to balance the different contributions to χ2. However, in the
BioEn formulation the likelihood functions of the different
independent experiments enter as products, without scaling
of the χ2 terms. The additional scaling in the EROS method
thus corresponds to a different likelihood function, which is
not solely determined by the error model.
8. Reﬁne the simulation ensemble by optimizing the statistical
weights. The optimal ensemble can be efﬁciently obtained by
gradiant-based minimization of the BioEn posterior (https://
github.com/bio-phys/BioEn) [53]. Before the experimental
data become available, our best guess for the statistical weights
is given by the reference weights. In the course of the ensemble
reﬁnement, the weights are optimized to improve agreement
with experimental data while still staying close to the
348
Ju¨ rgen Ko¨ ﬁnger et al.

simulation ensemble. How close one wants to stay to the
reference simulation ensemble is determined by the conﬁdence
parameter θ. Often, we lack experience to express a priori the
conﬁdence in the simulation ensemble as a particular value of
the conﬁdence parameter θ. In such a situation, we recommend
to perform an L-curve analysis [54]. One plots χ2 as a function
of SKL for the optimal weights at different θ values. For large
values of θ, one usually ﬁnds that χ2 is large while SKL is small.
Decreasing the value of θ, the value of χ2 decreases and
approaches the least-χ2 ﬁt value, under constraints of positive
and normalized weights, while SKL increases. In this L-shaped
curve, one chooses a point in the elbow region, where the
simulation ensemble agrees better with experiment without
undue overﬁtting. Large values of SKL indicate that the refer-
ence ensemble was poorly chosen and that it is possibly incom-
plete. As a result, a few structures then tend to dominate the
reweighted ensemble.
9. (Optional) Minimal ensemble reﬁnement. It is instructive to
reﬁne the structural ensemble using alternative methods and
compare the outcomes [18]. An orthogonal approach of reﬁn-
ing the simulation ensemble is the minimum ensemble
method, which selects the smallest possible set of clusters
accounting for the experimental data [6, 18, 55]. In the
approach of [14, 18], a function G ¼ χ2 + μN is minimized
numerically. Here, N is the number of clusters with non-zero
weights, wα>0, and μ > 0 is a control parameter, which should
be ﬁne-tuned using an elbow-plot, in such a way that minimi-
zation of the function G leads to a good ﬁt with only few
ensemble members, ideally reaching χ2
SAXS/Nq  1. The
parameter μ takes the form of a chemical potential that pena-
lizes against large ensembles. The advantage of this method is
that it usually produces only a small set of representative struc-
tures that can be easily inspected visually. However, by discard-
ing a signiﬁcant portion of the simulation ensemble, the
minimum ensemble method does not fully exploit the predic-
tive power of molecular simulations.
10. Validate the structural ensemble using independent datasets
excluded from reﬁnement [13, 14].
Acknowledgments
J.K. and G.H. acknowledge ﬁnancial support by the Max Plank
Society. B.R. has received support from the National Science Cen-
tre, Poland, grant number 2016/21/B/NZ1/00006.
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
349

References
1. Boomsma W, Ferkinghoff-Borg J, Lindorff-
Larsen K (2014) Combining experiments and
simulations using the maximum entropy prin-
ciple. PLoS Comput Biol 10(2):e1003406
2. Bottaro S, Lindorff-Larsen K (2018) Biophysi-
cal experiments and biomolecular simulations:
A perfect match? Science 361(6400):355
3. Schro¨der GF (2015) Hybrid methods for mac-
romolecular structure determination: experi-
ment with expectations. Curr Opin Struct
Biol 31:20–27
4. Sali A, Berman HM, Schwede T, Trewhella J,
Kleywegt
G,
Burley
SK,
Markley
J,
Nakamura H, Adams P, Bonvin AM, Chiu W,
Peraro
MD,
Di
Maio
F,
Ferrin
TE,
Grunewald K, Gutmanas A, Henderson R,
Hummer G, Iwasaki K, Johnson G, Lawson
CL, Meiler J, Marti-Renom MA, Montelione
GT, Nilges M, Nussinov R, Patwardhan A,
Rappsilber J, Read RJ, Saibil H, Schroder GF,
Schwieters CD, Seidel CA, Svergun D, Topf M,
Ulrich EL, Velankar S, Westbrook JD (2015)
Outcome of the ﬁrst wwPDB hybrid/integra-
tive methods task force workshop. Structure 23
(7):1156–1167.
5. Hummer
G,
Ko¨ﬁnger
J
(2015)
Bayesian
ensemble reﬁnement by replica simulations
and
reweighting.
J
Chem
Phys
143
(24):243150
6. Ro´z˙ycki B, Kim YC, Hummer G (2011) SAXS
ensemble reﬁnement of ESCRT-III CHMP3
conformational
transitions.
Structure
19
(1):109–116
7. Gull
SF,
Daniell
GJ
(1978)
Image-
reconstruction from incomplete and noisy
data. Nature 272(5655):686–690
8. Jaynes ET (1988) The relation of Bayesian and
maximum entropy methods. In: Erickson GJ,
Smith CR (eds) Maximum-entropy and Bayes-
ian methods in science and engineering: Foun-
dations. Springer Netherlands, Dordrecht, pp
25–29.
https://doi.org/10.1007/978-94-
009-3049-0_2
9. Bonomi M, Camilloni C, Cavalli A, Vendrus-
colo M (2016) Metainference: A Bayesian
inference method for heterogeneous systems.
Sci Adv 2(1):e1501177
10. Cesari A, Gil-Ley A, Bussi G (2016) Combin-
ing simulations and solution experiments as a
paradigm for RNA force ﬁeld reﬁnement. J
Chem Theory Comput 12(12):6192–6200
11. Cesari A, Reißer S, Bussi G (2018) Using the
maximum entropy principle to combine simu-
lations and solution experiments. Computation
6(1):15
12. Bottaro S, Bussi G, Kennedy SD, Turner DH,
Lindorff-Larsen
K
(2018)
Conformational
ensembles of RNA oligonucleotides from inte-
grating NMR and molecular simulations. Sci
Adv 4(5):eaar8521
13. Boura E, Ro´z˙ycki B, Chung HS, Herrick DZ,
Canagarajah
B,
Caﬁso
DS,
Eaton
WA,
Hummer G, Hurley JH (2012) Solution struc-
ture of the ESCRT-I and -II supercomplex:
Implications for membrane budding and scis-
sion. Structure 20(5):874–886
14. Boura E, Ro´z˙ycki B, Herrick DZ, Chung HS,
Vecer J, Eaton WA, Caﬁso DS, Hummer G,
Hurley JH (2011) Solution structure of the
ESCRT-I complex by small-angle X-ray scatter-
ing, EPR, and FRET spectroscopy. Proc Natl
Acad Sci U S A 108(23):9437–9442
15. Mantsyzov AB, Maltsev AS, Ying JF, Shen Y,
Hummer G, Bax A (2014) A maximum
entropy approach to the study of residue-
speciﬁc backbone angle distributions in alpha-
synuclein, an intrinsically disordered protein.
Protein Sci 23(9):1275–1290
16. Mantsyzov AB, Shen Y, Lee JH, Hummer G,
Bax A (2015) MERA: A webserver for evaluat-
ing backbone torsion angle distributions in
dynamic and disordered proteins from NMR
data. J Biomol NMR 63(1):85–95
17. Francis
DM,
Ro´z˙ycki
B,
Tortajada
A,
Hummer G, Peti W, Page R (2011) Resting
and active states of the ERK2:HePTP complex.
J Am Chem Soc 133(43):17138–17141
18. Francis DM, Ro´z˙ycki B, Koveal D, Hummer G,
Page R, Peti W (2011) Structural basis of p38
alpha regulation by hematopoietic tyrosine
phosphatase. Nat Chem Biol 7(12):916–924
19. Ko¨ﬁnger J, Ragusa MJ, Hummer G, Hurley JH
(2015) Autophagy: Solution structure of the
Atg17-Atg29-Atg31-Atg1-Atg13
complex.
Biophys J 108(2):343a
20. Rosta E, Nowotny M, Yang W, Hummer G
(2011) Catalytic mechanism of RNA backbone
cleavage by ribonuclease H from quantum
mechanics/molecular mechanics simulations.
J Am Chem Soc 133(23):8934–8941
21. Dannenhoffer-Lafage T, White AD, Voth GA
(2016) A direct method for incorporating
experimental
data
into
multiscale
coarse-
grained models. J Chem Theory Comput 12
(5):2144–2153
22. Pitera JW, Chodera JD (2012) On the use of
experimental observations to bias simulated
ensembles.
J
Chem
Theory
Comput
8
(10):3445–3451
350
Ju¨ rgen Ko¨ ﬁnger et al.

23. White AD, Voth GA (2014) Efﬁcient and min-
imal method to bias molecular simulations with
experimental data. J Chem Theory Comput 10
(8):3023–3030
24. Best RB, Vendruscolo M (2004) Determina-
tion of protein structures consistent with NMR
order
parameters.
J
Am
Chem
Soc
126
(26):8090–8091
25. Grishaev A, Guo LA, Irving T, Bax A (2010)
Improved ﬁtting of solution X-ray scattering
data to macromolecular structures and struc-
tural ensembles by explicit water modeling. J
Am Chem Soc 132(44):15484–15486
26. Schneidman-Duhovny D, Hammel M, Sali A
(2010) FoXS: A web server for rapid computa-
tion and ﬁtting of SAXS proﬁles. Nucleic Acids
Res 38:W540–W544
27. Svergun D, Barberato C, Koch MHJ (1995)
CRYSOL – a program to evaluate X-ray solu-
tion scattering of biological macromolecules
from atomic coordinates. J Appl Crystallogr
28:768–773
28. Virtanen JJ, Makowski L, Sosnick TR, Freed
KF (2010) Modeling the hydration layer
around
proteins:
HyPred.
Biophys
J
99
(5):1611–1619
29. Yang SC, Park S, Makowski L, Roux B (2009)
A rapid coarse residue-based computational
method for X-ray solution scattering character-
ization of protein folds and multiple conforma-
tional
states
of
large
protein
complexes.
Biophys J 96(11):4449–4463
30. Ko¨ﬁnger
J,
Hummer
G
(2013)
Atomic-
resolution structural information from scatter-
ing experiments on macromolecules in solu-
tion. Phys Rev E Stat Nonlin Soft Matter Phys
87(5):052712
31. Oroguchi T, Ikeguchi M (2011) Effects of
ionic strength on SAXS data for proteins
revealed by molecular dynamics simulations. J
Chem Phys 134(2):025102
32. Park S, Bardhan JP, Roux B, Makowski L
(2009) Simulated X-ray scattering of protein
solutions
using
explicit-solvent
models.
J
Chem Phys 130(13):134114
33. Knight CJ, Hub JS (2015) WAXSiS: a web
server for the calculation of SAXS/WAXS
curves based on explicit-solvent molecular
dynamics.
Nucleic
Acids
Res
43(W1):
W225–W230
34. Kim YC, Hummer G (2008) Coarse-grained
models for simulations of multiprotein com-
plexes: application to ubiquitin binding. J Mol
Biol 375(5):1416–1433
35. Ro´z˙ycki B, Cieplak M, Czjzek M (2015) Large
conformational
ﬂuctuations
of
the
multi-
domain xylanase Z of Clostridium thermocel-
lum. J Struct Biol 191(1):68–75
36. Cossio P, Hummer G (2013) Bayesian analysis
of
individual
electron
microscopy
images:
towards structures of dynamic and heteroge-
neous biomolecular assemblies. J Struct Biol
184(3):427–437
37. Cossio P, Hummer G (2018) Likelihood-based
structural
analysis
of
electron
microscopy
images. Curr Opin Struct Biol 49:162–168
38. Svergun DI, Koch MHJ, Timmins PA, May RP
(2013) Small angle X-ray and neutron scatter-
ing from solutions of biological macromole-
cules. Oxford University Press, Oxford, UK
39. Fiser A, Do RKG, Sali A (2000) Modeling of
loops in protein structures. Protein Sci 9
(9):1753–1773
40. Best RB, Hummer G (2010) Coordinate-
dependent diffusion in protein folding. Proc
Natl Acad Sci U S A 107(3):1088–1093
41. Kenzaki H, Koga N, Hori N, Kanada R, Li WF,
Okazaki K, Yao XQ, Takada S (2011) CafeMol:
a coarse-grained biomolecular simulator for
simulating proteins at work. J Chem Theory
Comput 7(6):1979–1989
42. Dignon GL, Zheng WW, Kim YC, Best RB,
Mittal J (2018) Sequence determinants of pro-
tein phase behavior from a coarse-grained
model. PLoS Comput Biol 14(1):e1005941
43. Plimpton S (1995) Fast parallel algorithms for
short-range molecular-dynamics. J Comput
Phys 117(1):1–19
44. Anderson JA, Lorenz CD, Travesset A (2008)
General purpose molecular dynamics simula-
tions fully implemented on graphics processing
units. J Comput Phys 227(10):5342–5359
45. Reichel K, Stelzl LS, Ko¨ﬁnger J, Hummer G
(2018) Precision DEER distances from spin-
label ensemble reﬁnement. J Phys Chem Lett
9(19):5748–5752
46. Chang Y, Jaumann EA, Reichel K, Hartmann J,
Oliver D, Hummer G, Joseph B, Geertsma ER
(2019) Structural basis for functional interac-
tions in dimers of SLC26 transporters. Nature
Commun 10(1):2032
47. Jeschke G (2012) DEER distance measure-
ments on proteins. Ann Rev Phys Chem 63
(1):419–446
48. Polyhach Y, Bordignon E, Jeschke G (2011)
Rotamer libraries of spin labelled cysteines for
protein studies. Phys Chem Chem Phys 13
(6):2356–2366
49. Best RB, Merchant KA, Gopich IV, Schuler B,
Bax A, Eaton WA (2007) Effect of ﬂexibility
and cis residues in single-molecule FRET stud-
ies of polyproline. Proc Natl Acad Sci U S A
104(48):18964–18969
Inferring Structural Ensembles of Flexible and Dynamic Macromolecules
351

50. Merchant KA, Best RB, Louis JM, Gopich IV,
Eaton WA (2007) Characterizing the unfolded
states of proteins using single-molecule FRET
spectroscopy and molecular simulations. Proc
Natl Acad Sci U S A 104(5):1528–1533
51. Hartigan JA, Wong MA (1979) A k-means
clustering algorithm. JSTOR Appl Stat 28
(1):100–108
52. Heyer LJ, Kruglyak S, Yooseph S (1999)
Exploring expression data: Identiﬁcation and
analysis of coexpressed genes. Genome Res 9
(11):1106–1115
53. Ko¨ﬁnger J, Stelzl LS, Reuter K, Allande C,
Reichel
K,
Hummer
G
(2019)
Efﬁcient
ensemble reﬁnement by reweighting. J Chem
Theory Comput 15(5):3390–3401
54. Hansen PC, Oleary DP (1993) The use of the
L-curve in the regularization of discrete ill-
posed problems. SIAM J Sci Comput 14
(6):1487–1503
55. Berlin
K,
Castaneda
CA,
Schneidman-
Duhovny D, Sali A, Nava-Tudela A, Fushman
D (2013) Recovering a representative confor-
mational
ensemble
from
underdetermined
macromolecular structural data. J Am Chem
Soc 135(44):16595–16609
352
Ju¨ rgen Ko¨ ﬁnger et al.

Chapter 15
Modeling Biological Complexes Using Integrative Modeling
Platform
Daniel Saltzberg, Charles H. Greenberg, Shruthi Viswanath,
Ilan Chemmama, Ben Webb, Riccardo Pellarin, Ignacia Echeverria,
and Andrej Sali
Abstract
Integrative structure modeling provides 3D models of macromolecular systems that are based on informa-
tion from multiple types of experiments, physical principles, statistical inferences, and prior structural
models. Here, we provide a hands-on realistic example of integrative structure modeling of the quaternary
structure of the actin, tropomyosin, and gelsolin protein assembly based on electron microscopy, solution
X-ray scattering, and chemical crosslinking data for the complex as well as excluded volume, sequence
connectivity, and rigid atomic X-ray structures of the individual subunits. We follow the general four-stage
process for integrative modeling, including gathering the input information, converting the input informa-
tion into a representation of the system and a scoring function, sampling alternative model conﬁgurations
guided by the scoring function, and analyzing the results. The computational aspects of this approach are
implemented in our open-source Integrative Modeling Platform (IMP), a comprehensive and extensible
software package for integrative modeling (https://integrativemodeling.org). In particular, we rely on the
Python Modeling Interface (PMI) module of IMP that provides facile mixing and matching of macromolec-
ular representations, restraints based on different types of information, sampling algorithms, and analysis
including validations of the input data and output models. Finally, we also outline how to deposit an
integrative structure and corresponding experimental data into PDB-Dev, the nascent worldwide Protein
Data Bank (wwPDB) resource for archiving and disseminating integrative structures (https://pdb-dev.
wwpdb.org). The example application provides a starting point for a user interested in using IMP for
integrative modeling of other biomolecular systems.
Key words Integrative modeling, Biomolecular simulation, Biophysical data, Structural modeling
1
Introduction
To understand the function of a macromolecular assembly, we must
know the structure and dynamics of its components and the inter-
actions between them [1–4]. However, direct experimental deter-
mination of such a structure is generally rather difﬁcult, as no
experimental method is universally applicable. For example, crystals
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_15, © Springer Science+Business Media, LLC, part of Springer Nature 2019
353

suitable for X-ray crystallography cannot always be produced, espe-
cially for large assemblies of multiple components [5]. Cryo-
electron microscopy, on the other hand, can be used to study
large assemblies, but is often limited to worse than atomic resolu-
tion [6–8]. Finally, molecular biology, biochemistry, and proteo-
mics techniques, such as yeast two-hybrid [9], afﬁnity puriﬁcation
[10], and mass spectrometry [11], yield information about the
interactions between proteins but not the positions of these pro-
teins within the assembly or the structures of the proteins
themselves.
One approach to solve this problem is integrative modeling
[12], which is used to characterize the structures of single proteins
or their complexes by relying on multiple types of input informa-
tion, including varied experiments, physical theories, statistical
inferences, and prior structural models. By simultaneously consid-
ering all information, the method maximizes the accuracy, preci-
sion, completeness, and efﬁciency of structure determination.
Numerous structures have already been solved using this approach,
including the 26S ribosome [13], the bacterial type II pilus [14],
the structure of chromatin around the alpha-globin gene [15], the
molecular architecture of the yeast spindle pole body core [16], and
the architecture of the yeast nuclear pore complex [17]. The
method can also compute multistate models of conformationally
heterogeneous systems, as demonstrated by the two-state model of
the PhoQ sensor histidine kinase [18].
The Integrative Modeling Platform (IMP) is a comprehensive
and extensible software package for performing integrative model-
ing. The ﬂexibility of core software allows for constructing custo-
mized representations of structure and data as well as sampling and
analysis protocols. The tools to complete the entire integrative
modeling workﬂow (Fig. 1) are contained within IMP. Herein,
we describe the Python Modeling Interface (PMI) to IMP that
signiﬁcantly simpliﬁes encoding the modeling process [19].
2
Methods
The goal of PMI is to allow structural biologists with limited
programming expertise to determine the structures of large protein
complexes. PMI is a top-down modeling system that relies on a
series of macros and classes to simplify encoding of the modeling
protocol, including designing the system representation, specifying
scoring function, sampling alternative structures, analyzing the
results, facilitating the creation of publication-ready ﬁgures, and
depositing into PDB-Dev (see below). PMI exchanges the high
ﬂexibility of IMP for ease-of-use, all within one short Python script
(<100 lines). Despite its simplicity in creating standard modeling
workﬂows, PMI is powerful and extensible—it is built on IMP and
354
Daniel Saltzberg et al.

creates native IMP objects, which means that the advanced user can
customize many aspects of the modeling protocol. Below, we out-
line each stage of the modeling process as performed in PMI
(Fig. 2).
2.1
Gathering
Information
Information about a system that we wish to model includes every-
thing that we directly observe, can infer through comparison to
other systems, and fundamental physical principles. Experimental
data that are commonly utilized in integrative modeling include
X-ray crystal structures, EM density maps, NMR data, chemical
crosslinks, yeast two-hybrid data, and Fo¨rster resonance energy
Fig. 1 The four stages of integrative modeling. This schematic describes the integrative structure modeling
procedures used in this tutorial. The ﬁrst row details the information to be used in modeling. The background
color of each information source indicates where the information is applied in modeling, as detailed in the key
at the top. The second row describes how each information source is converted into spatial restraints. The
third row details the sampling protocol. The last row details the analysis and validation steps of the modeling.
The modiﬁable Adobe Illustrator ﬁle for this ﬁgure can be found in the tutorial repository: ﬁgures/Figure1/
actin_tutorial_4stage.ai
Modeling Biological Complexes Using IMP
355

transfer (FRET) measurements. Atomic resolution information
may be applied directly as structural restraints from atomic statisti-
cal potentials [20, 21] and molecular mechanics force ﬁelds
[22, 23] or derived from comparative modeling programs such as
MODELLER [24] and PHYRE2 [25].
Each piece of information can be utilized within the modeling
procedure in one or more of ﬁve distinct ways: deﬁning model
representation, deﬁning sampling space/degrees of freedom, scor-
ing models during sampling, ﬁltering models post-sampling, and
validating completed models.
2.2
System and Data
Representation
The representation of the system deﬁnes the structural degrees of
freedom that will be sampled and is designed based on the infor-
mation at hand. We can utilize a multiscale representation, where
model components can be modeled at one or more different reso-
lutions commensurate with the information content at that site
(Fig. 3). For example, a domain described by a crystal structure
can be represented at atomic resolution and a disordered segment
can be represented as a string of spherical beads of ten residues
each. In addition, non-particle-based representations, such as
Gaussian mixture models (GMMs), can also be used, for example,
System
State 0
State 1
State 2
MolA.0
MolA.1
MolA.2
MolB.0
MolC.0
Res1
Res2
Res3
Res4
ResN
Fragment 1-10
Fragment 11-20
Fragment M
N
C
CA
H
Gaussian 1
Gaussian 2
Gaussian K
Resolution 0
Resolution 1
Resolution 10
Densities
Fig. 2 PMI hierarchy. PMI is constructed as a top-down hierarchy beginning with a system. A system can
contain one or more states with each state being a different conformation, composition, or time-ordered step
in the system. Each state comprises one or more molecules that may have one or more copies per molecule.
At the ﬁnal level, each molecule is represented at one or more resolutions
356
Daniel Saltzberg et al.

in EM density ﬁtting [26, 27]. Choosing a representation reﬂects a
compromise between the need for details required by the biological
application of the model and the need for coarseness required by
limited computing power.
Some of the input information is translated into restraints on
the structure of the model. These spatial restraints are combined
into a single scoring function that ranks alternative model conﬁg-
urations (models) based on their agreement with the information.
The scoring function deﬁnes a multi-dimensional landscape
spanned by the model degrees of freedom; the good-scoring mod-
els on this landscape satisfy the input restraints.
2.3
Sampling
In most cases, all possible models cannot be generated. Thus, we
utilize sampling methods to search for models that agree with the
input data according to the scoring function deﬁned above (good-
scoring models). One approach for sampling models in IMP is a
Monte Carlo algorithm [28], guided by our scoring function and
accelerated by replica exchange [29]. Other sampling methods can
be utilized for speciﬁc cases (see Note 1).
2.4
Analysis
The results of stochastic sampling (i.e., an ensemble of output
structures and their respective scores) must be analyzed to estimate
the sampling precision and accuracy, detect inconsistencies with
respect to the input information, and suggest future experiments
(Fig. 4).
We wish to analyze only models that are sufﬁciently consistent
with the input information (good-scoring models). A good-scoring
model must sufﬁciently satisfy every single piece of information
used to compute it; therefore, one needs a threshold for every
data point or set of data. Sampling may produce zero such models,
which can result from inconsistent data or an unconsidered multi-
plicity of conformational states (see Note 2).
Given a set of good-scoring models, we must ﬁrst estimate the
precision at which sampling found these most good-scoring solu-
tions (sampling precision) (Fig. 4, step 1) [16, 17, 30]. This esti-
mate relies on splitting the set of good-scoring models into two
independent samples, followed by comparing them to each other
using four independent tests: (1) convergence of the model score,
(2) whether model scores for the two samples were drawn from the
same parent distribution, (3) whether each structural cluster
includes models from each sample proportionally to its size, and
(4) sufﬁcient similarity between the localization densities (see Note
3) for the entire system, from each sample. After threshold cluster-
ing of models, the sampling precision is deﬁned as the largest
RMSD value between a pair of structures within any cluster, in
the ﬁnest clustering for which the structures from the two indepen-
dent runs contribute proportionally to their size (Fig. 6d). In other
words, the sampling precision is deﬁned as the precision at which
Modeling Biological Complexes Using IMP
357

Fig. 3 Ways of representing a single biomolecule. (a) The complexity of a molecular system can be
represented in four ways. An ensemble of states describes the structural heterogeneity around a single
solution. Multiple states are used to describe systems that exist in multiple thermodynamic wells. The system
can be modeled at a multitude of scales commensurate with the different types of information known about
it. Finally, individual states can be time-ordered, allowing for the modeling of the transition rates between
them. (b) Multiple representations can be simultaneously applied to the same biomolecule so that information
of various types can be applied at the proper scale and form. The molecule is ﬁrst deﬁned by its sequence
connectivity. Flexible beads comprising one or more residues are commonly applied to loops where no high-
resolution structure is available. Areas that have high-resolution structure can be modeled by spherical beads
358
Daniel Saltzberg et al.

the two independent samples are statistically indistinguishable. The
individual clusters for each sample are also compared visually (Sub-
heading 4.5.3) to conﬁrm similarity.
At this step, the model precision (uncertainty), which is repre-
sented by the variability among the good-scoring models, is also
reported. This uncertainty can be quantiﬁed by measures such as
root-mean-square deviation (RMSD) of model components for
models within each cluster or between clusters determined above.
The lower bound on model precision is provided by the sampling
precision; the model precision cannot be higher than the sampling
precision.
An accurate model must satisfy all information about the sys-
tem, and this is evaluated in a number of steps. First, the consis-
tency of the model with input information is assessed by
independently assessing the clusters determined above against the

Fig. 3 (continued) of one residue for the evaluation of residue-speciﬁc information such as chemical cross-
links or NMR distance restraints. Ten-residue beads are generally used to model lower resolution information
such as SAXS data and the excluded volume restraint. The molecule can be represented as a Gaussian mixture
model for comparisons to EM densities. IMP and PMI can utilize all of these representations simultaneously in
a multi-scale model. Panel a adapted from [34]
Low 
variance 
Good scoring 
models from all 
sampling runs
4. Fit to data not 
used in modeling
3. Resampling 
   jackknifing 
   bootstrapping 
   cross-validation 
Split into two 
independent 
samples 
5. Biological sense 
1. Sampling Convergence
Pass
2. Analyze fit to 
input information
Consistent 
Validated  
Model
Consistent 
Yes 
Sample A 
Sample B 
Fig. 4 Analysis pipeline. Analysis of sampling runs begins by ﬁltering models that satisfy all input information.
In step one, this set is split into two independent samples to assess the precision at which sampling is
converged. If sampling has converged at a high enough precision, the resulting models can be assessed
against the input information to identify potential multiple states. Resampling can be performed by either
systematically or randomly excluding data sets and rerunning the simulation and sampling convergence
algorithms. The models can then be assessed against data that were not used in modeling. Finally, the models
are assessed for logical sense in answering the original biological question
Modeling Biological Complexes Using IMP
359

input data (Fig. 4, step 2). In the next step, the models are assessed
by random or systematic cross-validation (Fig. 4, step 3). The next
and most robust validation is the consistency of the model with data
not used to compute it (Fig. 4, step 4), similar to a crystallographic
Rfree.
A ﬁnal validation is the presence of features in the model that
are unlikely to occur by chance and/or are consistent with the
biological context of the system (Fig. 4, step 5). For example, a
16-fold symmetry was found in the model of the Nuclear Pore
Complex, when only eightfold symmetry had been enforced [31]
and the displacement of the aspartate sensor domain in a two state
model of the histidine kinase PhoQ transmembrane signaling
agreed with previous analysis [18].
A key feature of the four-step procedure for integrative model-
ing (Fig. 1) is that it is iterative. Assessment may reveal a need to
collect more input data or suggest future experiments, both by the
researchers who constructed the initial model and by others.
2.5
Deposition
For the models, data, and modeling protocols to be generally
useful, they must be reproducible and available to everyone in a
publicly accessible database. This availability allows any scientist to
use a deposited model to plan experiments by simulating potential
beneﬁts gained from new data. Computational groups can more
easily experiment with new scoring, sampling, and analysis meth-
ods, without having to reimplement the existing methods from
scratch. Finally, the authors themselves will maximize the impact
of their work, increasing the odds that their results are incorporated
into future modeling. Following the recommendations of the
wwPDB Hybrid/Integrative Methods Task Force in 2015 [32], a
prototype archive, PDB-Development (PDB-Dev, https://pdb-
dev.wwpdb.org/) [33, 34] has been recently established to store
integrative models and corresponding data. The mmCIF ﬁle format
used to archive regular atomic PDB structures was extended to
support the description of integrative models, including informa-
tion on the input data used, the modeling protocol, and the ﬁnal
output models. As of July 2018, PDB-Dev contains 14 depositions,
including nine generated by IMP.
3
Materials
3.1
IMP
IMP binaries for most platforms can be downloaded and installed
from:
https://integrativemodeling.org/download.html.
The tutorial has been built to work with the latest stable release
of IMP at the time of writing, 2.9.0.
360
Daniel Saltzberg et al.

3.2
Chimera
Modeling results can be visualized using Chimera version 1.13 or
later, which can be downloaded from https://www.cgl.ucsf.edu/
chimera/download.
3.3
Actin Tutorial
Code and Data
The data and code used in the tutorial below can be downloaded
from https://github.com/salilab/actin_tutorial. The home direc-
tory of the repository, actin_tutorial, will be used to reference
all other paths in the tutorial below.
Analysis scripts are located in ./analysis/scripts. These
are slightly modiﬁed from the stand-alone script library for
performing sampling exhaustiveness found at https://github.
com/salilab/IMP-sampcon. These analyses rely on pyRMSD [35].
3.4
Computer Skills
Requirements
PMI stands for Python Modeling Interface. Interaction with PMI
requires Python scripts. The tutorial scripts for PMI are written to
be interpretable by even those with minimal or no Python experi-
ence. However, performing advanced tasks and/or designing novel
workﬂows beneﬁts from a working knowledge of Python.
3.5
Computational
Resources and Time
The full tutorial simulation can be run in a few hours on a modern
desktop computer or a laptop. A multicore system is preferred to
utilize replica exchange.
4
Integrative Modeling of ADP-Actin, Gelsolin, and C-Terminal Actin-Binding
Domain of Tropomodulin
Herein, we demonstrate integrative modeling using the PMI inter-
face by modeling the complex of actin and tropomodulin–gelsolin
chimera using SAXS, EM, crosslinking, crystal structures of the
individual domains, and physical principles. This complex was
solved by X-ray crystallography at 2.3 A˚ resolution (PDB: 4PKI)
[36]. We use this structure to simulate biophysical data and assess
the accuracy of the modeled complexes. In this simple exercise, we
assume that we have a crystal structure of only the actin–gelsolin
interface and would like to ﬁnd the tropomyosin–actin binding
interface. The entire modeling protocol is summarized in the
four-stage diagram (Fig. 1).
4.1
Gathering and
Preparing Information
All data are contained in subfolders of the ./data directory of the
tutorial.
4.1.1
Structural Data
from the PDB
The crystal structure 4PKI is used to set the atomic coordinates for
each of the domains in the FASTA sequence that determines the
composition of each biomolecule, as well as the coordinates for
tropomyosin and the actin–gelsolin complex (Fig. 5).
Modeling Biological Complexes Using IMP
361

4.1.2
Chemical
Crosslinks
Thirty-three simulated crosslinks were generated from a random
subset of lysine residue pairs whose CA-CA distances are under
25 A˚ .
4.1.3
Electron
Microscopy
A simulated EM density of the entire complex was created at 20 A˚
resolution using IMP (see Note 4). The simulated map is approxi-
mated as a Gaussian Mixture Model (GMM) [27].
4.1.4
SAXS
A simulated SAXS proﬁle of the entire 4pki.pdb complex was
created using FoXS [37].
4.1.5
Other Information
We also deﬁne restraints such as excluded volume and sequence
connectivity to add chemical and physical knowledge to the mod-
eling protocol.
4.2
Deﬁning System
Representation and
Degrees of Freedom
in the Topology File
The model representation (e.g., bead size and rigid bodies) can be
set within the topology ﬁle. The topology ﬁle is a pipe-delimited
format with each line specifying a separate domain and keyword
values determining how the domain is represented. A deﬁnition of
each keyword is given in Table 1.
Fig. 5 Actin–gelsolin–tropomyosin complex. Top: Reference crystal structure
4PKI showing actin in green, gelsolin in red, and tropomyosin in blue. Bottom:
Multiscale representation and position of the system after domain shufﬂing and
bead relaxation. Structured domains are represented by spherical beads of one
and ten residues. Unstructured residues from the linker between the gelsolin and
tropomyosin domains are represented as gray beads
362
Daniel Saltzberg et al.

The topology ﬁle for this tutorial, shown below, is found at
./modeling/topology.txt. Here, the system is subdivided into
four distinct domains: one each for the three structured domains
(actin, gelsolin, and tropomyosin) and one consisting of the
18-residue engineered linker between gelsolin and tropomyosin.
The ﬁrst domain, the entire actin molecule, is colored green and
contains the entirety of chain A from 4pki.pdb. A bead_size of
1 residue per bead is assigned to any unmodeled section (i.e., not
present in the PDB ﬁle) (see Note 5). A GMM is approximated
using ten residues per Gaussian. This domain is assigned to
rigid_body 1. The second domain, the gelsolin portion of the
chimera, is constructed by selecting the residue_range 52–177
of chain G. These residues, however, are numbered 1–126 in the
FASTA ﬁle; therefore, a pdb_offset of 51 must be added. This
domain is also assigned to rigid_body 1 to preserve the actin/
gelsolin interface. The third domain is the linker, whose residues
have no structure associated with them; thus, they are given a
pdb_fn of BEADS with a bead_size of 1 (see Note 6). The
ﬁnal domain, tropomyosin, is built similarly to gelsolin and
Table 1
Topology file keywords and descriptions
molecule_name
Name of the molecule that this domain is a part of
color
The color used in the output RMF ﬁle for this component. Uses Chimera
deﬁned names (see Note 23) or RGB values (e.g., 155,35,0)
fasta_fn
Name of FASTA ﬁle containing this component
fasta_id
String found in FASTA sequence header line
pdb_fn
Name of PDB ﬁle with coordinates (if available). If left empty, will set up as
BEADS. Using IDEAL_HELIX will build a helix (see Note 24)
chain
Chain ID of this domain in the PDB ﬁle
residue_range
Comma delimited pair deﬁning range of residues. Can leave empty or put
all to use entire sequence from FASTA ﬁle
pdb_offset
Offset to sync PDB residue numbering with FASTA numbering
bead_size
The size (in residues) of beads used to model areas not covered by PDB
coordinates
em_residues_
per_gaussian
The number of residues per Gaussian used to model the electron density of
this domain. Set this to zero if no EM ﬁtting will be done
rigid_body
The ID number of the rigid body that contains this component
super_rigid_body The ID number(s) of the super rigid body(ies) containing this component
chain_of_super_
rigid_bodies
Automatically group overlapping segments of beads into super rigid bodies.
The number here, as for rigid_body, speciﬁes the member of the chain
to which this domain belongs
Modeling Biological Complexes Using IMP
363

assigned to rigid_body 2, since we would like to sample its
position separate of the rest of the complex.
|molecule_name
|
color
|
fasta_fn
|
fasta_id
|
pdb_fn
|
chain
|
residue_range
|
pdb_offset | bead_size | em_residues_per_gaussian | rigid_body | super_rigid_body |
chain_of_super_rigid_bodies |
|actin
|green|4pki.fasta.txt|actin
|4pki.pdb|A|1,END |0
|1|10|1|1||
|geltrop|red |4pki.fasta.txt |gelsolin-tropomyosin|4pki.pdb|G |52,177|-51 |1|10|1|1||
|geltrop|gray|4pki.fasta.txt|gelsolin-tropomyosin|BEADS|G|178,195
|-51 |1|10|1|1||
|geltrop|blue|4pki.fasta.txt|gelsolin-tropomyosin|4pki.pdb|G|1170,1349|-1025|1|10|2|
1||
This topology ﬁle also places all domains in a single super_-
rigid_body. This deﬁnition allows the entire complex to move as
a single unit, which is useful for ﬁtting to the EM map.
4.3
Constructing the
Modeling Script
The modeling script contains the entire workﬂow from deﬁning the
system representation through execution of sampling. The system
representation and sampling degrees of freedom can be built man-
ually (see Note 7) or, as here, read from a topology ﬁle. Restraints
are added and the sampling protocol deﬁned and executed.
4.3.1
Importing and
Building System
Representation
First, we create an IMP Model object, which stores all components
of the model. Second, we create a BuildSystem object and deﬁne
the resolutions at which residues in the structured sections will
be modeled. Here, we set resolutions of 1 and 10 residues per bead
so that crosslinking restraints can be evaluated at residue resolution
and the expensive excluded volume restraint (below) can be eval-
uated at the lower resolution. Third, the topology ﬁle is read using
a TopologyReader object, followed by generating a useful list of
component molecules. To this BuildSystem object, we add a
state corresponding to the representation deﬁned in the topology
ﬁle using bs.add_state() (see Note 8).
mdl = IMP.Model()
bs = IMP.pmi.macros.BuildSystem(mdl, resolutions=[1,10])
t = IMP.pmi.topology.TopologyReader(topology.txt)
molecules = t.get_components()
bs.add_state(t)
We then execute the macro, which returns the root_hier root
hierarchy and dof degrees of freedom objects, which will be used
later. Within the macro, we set the movement parameters of indi-
vidual beads and rigid bodies. Translations (trans) are deﬁned in
angstroms and rotations (rot) in radians.
364
Daniel Saltzberg et al.

root_hier, dof = bs.execute_macro(max_rb_trans=1.0,
max_rb_rot=0.5,
max_bead_trans=2.0,
max_srb_trans=1.0,
max_srb_rot=0.5)
4.3.2
Adding Restraints
to the Model
PMI contains simple interfaces for a number of IMP restraints that
model various types of chemical and physical data and knowledge.
All of these restraints produce output, which we will collect in an
output_objects list. Each restraint also needs to be explicitly
added to the scoring function for sampling, using the add_to_-
model() command. We will add the restraints to the scoring
function in a speciﬁc order, discussed below.
First, we deﬁne the restraints that enforce physical and chemical
principles (see Note 9). The ConnectivityRestraint adds a
bond between each pair of consecutive residues in each molecule.
The ExcludedVolumeSphere restraint is applied to the entire
system and enforced at the lowest resolution possible (indicated
by resolution ¼ 1000), because this restraint is costly to evaluate.
output_objects=[]
for m in molecules:
cr
=
IMP.pmi.restraints.stereochemistry.ConnectivityRes-
traint(m)
cr.add_to_model()
output_objects.append(cr)
evr = IMP.pmi.restraints.stereochemistry.ExcludedVolumeSphere(
included_objects=[root_hier],
resolution=1000)
output_objects.append(evr)
Second, we build a SAXSRestraint based on the comparison
of SAXS data to the model. Since our model is calculated at residue
resolution, we calculate the SAXS proﬁle using residue form factors.
For residue-based calculations, we compare curves out to a q of
0.15 (see Note 10).
sr = IMP.pmi.restraints.saxs.SAXSRestraint(input_objects=[root_hier],
saxs_datafile=saxs_data,
weight=0.01,
ff_type=IMP.saxs.RESIDUES,
maxq=0.15)
To set up a crosslinking restraint, we ﬁrst build a PMI Cross-
LinkDataBase that uses a CrossLinkDataBaseKeywordsCon-
verter to interpret a crosslink data ﬁle. At a minimum, the
crosslink data ﬁle needs four columns labeled with a key: one for
Modeling Biological Complexes Using IMP
365

each protein name and one for each residue number of the cross-
link. The standard keys are Protein1, Residue1, Protein2, and
Residue2 (see Note 11).
xl_data = "./derived_data/xl/derived_xls.dat
xldbkc = IMP.pmi.io.crosslink.CrossLinkDataBaseKeywordsConverter()
xldbkc.set_standard_keys()
xldb = IMP.pmi.io.crosslink.CrossLinkDataBase()
xldb.create_set_from_file(file_name=xl_data,
converter=xldbkc)
Using this database, we can construct the crosslinking restraint.
We input the root hierarchy of the system and the database, and
specify the length of the crosslinker. The restraint can be evaluated
at any resolution, though it is generally most informative at resolu-
tion ¼ 1. The length determines the inﬂection point of the scoring
function sigmoid [18] and is generally set to 10 A˚ + the crosslinker
length for Lys-Lys crosslinkers.
xlr = IMP.pmi.restraints.crosslinking.CrossLinkingMassSpectrometryRestraint(
root_hier=root_hier,
# Must pass the system root hierarchy
CrossLinkDataBase=xldb,
# The crosslink database.
length=25,
# The crosslinker plus side chain length
resolution=1,
# The resolution to evaluate the crosslink
slope=0.0001,
# This adds a linear term to the score
#
to bias crosslinks towards each other
weight=10)
# Scaling factor for the restraint score.
output_objects.append(xlr)
The EM restraint is determined by calculating the overlap
(cross-correlation) between the system GMM density particles
and the map GMM particles. First, we must collect the density
particles using an IMP Selection. We then invoke the restraint
using these particles and the gmm ﬁle generated from the EM map.
densities = IMP.atom.Selection(root_hier,
representation_type=IMP.atom.DENSITIES).get_selected_particles()
em_map = "./derived_data/em/4pki_20a_50.gmm"
emr = IMP.pmi.restraints.em.GaussianEMRestraint(
densities,
# Evaluate the restraint using these model densities
target_fn=em_map,
# The EM map approximated as a Gaussian mixture model (GMM)
slope=0.00000001,
# a small force to pull objects towards the EM map
scale_target_to_mass=True, # Normalizes the mass of the model wrs: EM map
weight=100)
# the scaling factor for the EM score
output_objects.append(emr)
366
Daniel Saltzberg et al.

4.3.3
Deﬁning the
Sampling Protocol
Sampling begins by randomizing the coordinates of the starting
particles using shuffle_configuration (see Note 13). Because
this randomization generally places beads of neighboring residues
far apart, we ﬁrst optimize the positions of these ﬂexible beads
using steepest descent minimization for 500 steps based on only
the connectivity restraint. We then add the balance of the scoring
function terms to the model prior to the main sampling step.
IMP.pmi.tools.shuffle_configuration(root_hier,
max_translation=50)
dof.optimize_flexible_beads(500)
evr.add_to_model()
emr.add_to_model()
xlr.add_to_model()
sr.add_to_model()
We implement a Monte Carlo sampling scheme with replica
exchange using the PMI ReplicaExchange0 macro. Within this
macro, we set the directory where all output ﬁles will be placed,
global_output_directory, and the number_of_frames to
generate. The ﬁnal line of the script executes the sampling macro.
rex=IMP.pmi.macros.ReplicaExchange0(mdl,
root_hier=root_hier,
# the system root hierarchy
crosslink_restraints= [xlr],
# This allows viewing of crosslinks in Chimera
monte_carlo_sample_objects=dof.get_movers(), # all objects to be moved
global_output_directory=’run1/’ # Set the output directory for this run.
output_objects=output_objects,
# Write these items to the stat file
monte_carlo_steps=10,
# Number of MC steps between writing frames
number_of_best_scoring_models=0,
# set >0 to store best scoring PDB files
number_of_frames=10000)
# Total number of frames to generate
rex.execute_macro()
4.4
Running the
Modeling Script
Modeling analysis requires at least two independent sampling runs
be performed. For each run, in modeling.py, the global_out-
put_directory keyword can be set to run1, run2, . . ., runX.
The modeling script can be run on a single processor using the
following command:
python ../modeling.py
or in parallel using N processors using the command
mpirun -np N python ../modeling.py
Modeling Biological Complexes Using IMP
367

A parallel invocation of IMP will run replica exchange with N
replicas. A serial run will run a basic Monte Carlo protocol with one
replica.
Raw output will be written to the ./runX/output folder, as
speciﬁed in the replica exchange macro. Within this folder, stat ﬁles
contain tabulated statistics for each frame. In the rmf directory,
model coordinates for the lowest temperature replica are stored.
These can be opened directly in Chimera and the “trajectories”
observed.
4.5
Analysis
Analysis is performed using scripts located in./analysis/
scripts/. The already-generated sampling output will be ana-
lyzed here; it is contained in the folders ./modeling/run1 and
./modeling/run2.
Analysis is performed in a new directory: ./analysis/
tutorial_analysis/.
4.5.1
Filtering Good
Scoring Models
The
select_good_scoring_models.py script ﬁlter models
based on score and parameter thresholds. In this script, required
ﬂags are rd, which speciﬁes the directory containing sampling
output folders; rp, which deﬁnes the preﬁx for the sampling
output folders; sl, which deﬁnes the stat ﬁle keywords (see
Note 13) that we wish to ﬁlter on; pl, which speciﬁes the key-
words that will be written to the output ﬁle; alt and aut, which
specify, respectively, the lower and upper threshold for each key-
word in sl that deﬁne acceptance. The mlt and mut keywords,
which are optional, deﬁne thresholds for restraints made of multiple
components (such as crosslinks).
Here, we ﬁrst use crosslink satisfaction as an initial ﬁltering
criterion because we usually have an a priori estimate of the false
positive rate and/or cutoff distance (see Note 14). For this
simulated system, we only accept models with 100% satisfaction of
crosslinks by setting both alt and aut to 1.0. A crosslink is
satisﬁed if the distance is between 0.0 and 30.0 A˚ , as delineated by
the mlt and mut keywords, respectively. We specify that connec-
tivity, crosslink data score, excluded volume, EM, SAXS, and total
scores be printed as well.
python
../scripts/select_good_scoring_models.py
-rd
../../modeling
-rp
run
-sl
"CrossLinkingMassSpectrometryRestraint_Distance_" -pl
ConnectivityRestraint_None CrossLinkingMassSpectrometryRestraint_Data_Score
ExcludedVolumeSphere_None GaussianEMRestraint_None SAXSRestraint_Score
Total_Score -alt 1.0 -aut 1.0 -mlt 0.0
-mut 30.0
This script creates a directory./filter/ and a ﬁle, ./filter/
models_scores_ids.txt, that contains the model index, its
run, replica ID, frame ID, scores, and sample ID for each model.
We can now use the script plot_score.py to plot the distribution
368
Daniel Saltzberg et al.

of SAXS, EM, connectivity, and excluded volume scores from this
ﬁrst set of ﬁltered models to determine a reasonable threshold for
accepting or rejecting a model.
python ../scripts/plot_score.py ./filter/model_ids_scores.txt
SAXSRestraint_Score
python ../scripts/plot_score.py ./filter/model_ids_scores.txt
GaussianEMRestraint_None
The resulting histograms (SAXSRestraint_score.jpg and
GaussianEMRestraint_None.jpg)
are
roughly
Gaussian.
Based on these distributions, we set our criteria for good scoring
models as those whose EM and SAXS scores are >1 standard
deviation below the mean, except for connectivity, which is well
satisﬁed in almost all models and EM, which has a large tail (see
Note 15). Our high score thresholds are 2.0 for EM, 4.554 for
SAXS, 1.0 for connectivity, and 4.916 for excluded volume.
We rerun select_good_scoring_models.py adding the
extra keywords and score thresholds. We add the extra ﬂag, e, to
extract Rich Molecular Format (RMF) ﬁles of all good scoring
models. These thresholds return 1618 good scoring models (see
Note 16).
python
../scripts/select_good_scoring_models.py
-rd
../../modeling
-rp
run
-sl
"CrossLinkingMassSpectrometryRestraint_Distance_" GaussianEMRestraint_None
SAXSRestraint_Score ConnectivityRestraint_None ExcludedVolumeSphere_None -pl
ConnectivityRestraint_None CrossLinkingMassSpectrometryRestraint_Data_Score
ExcludedVolumeSphere_None Total_Score -alt 1.0 -50 -50.0 0.0 0.0 -aut 1.0 2.0
4.554 1.0 4.916 -mlt 0.0 0.0 0.0 0.0 0.0 -mut 30.0 0.0 0.0 0.0 0.0 -e
The output directory,
good_scoring_models, contains
folders sample_A and sample_B, which hold the RMF ﬁles of
the good scoring models for each independent run (or set of runs).
The ﬁle model_ids_scores.txt contains the model index, its
run, replica ID, frame ID, scores, and sample ID for each model.
4.5.2
Determining
Sampling Precision,
Clustering, and Computing
Localization Densities
The
Master_Sampling_Exhaustiveness_Analysis.py
script is used to calculate the sampling precision of the modeling.
During this step, multiple tests for convergence are performed on
the two samples determined in Subheading 4.5.1, models are clus-
tered, and localization densities are computed.
First, we create a ﬁle, density_ranges.txt, in the tutor-
ial_analysis/ directory with a single line that deﬁnes compo-
nents using PMI selection tuples on which we calculate localization
densities (see Note 17). Here, we create three localization densities,
one for the entire actin molecule and one each for the structured
residues of each of the other two molecules.
Modeling Biological Complexes Using IMP
369

d e n s i t y _ c u s t o m _ r a n g e s = { " A c t i n " : [ ’ A ’ ] , " G e l s o l i n " :
[(1,126,’G’)],"Tropomysin":[(145,324,’G’)]}
We now run the script for testing sampling exhaustiveness.
python
../scripts/Master_Sampling_Exhaustiveness_Analysis.py
-n
actin
–p
good_scoring_models/
-d
density_ranges.txt
-m
cpu_omp -c 8 -a -g 0.1
The system name, actin, deﬁnes the labels for the output ﬁles.
The a ﬂag aligns all models (see Note 18) and g determines the
step size in A˚ for calculating sampling precision (see Note 19). This
routine can be run in parallel using the m cpu_omp ﬂag (see Note
20) and c N, where N is the number of processors. The p ﬂag
deﬁnes the path to the good scoring model directory.
The results of the convergence tests are summarized in the
output ﬁgure (Fig. 6) actin_convergence.png, which identiﬁes
our sampling precision of 3.5 A˚ , with one dominant cluster, one
minor cluster, and one cluster of insigniﬁcant size. Text ﬁles con-
taining this information are also produced (see Note 21). Output
also includes localization densities for each cluster, which are
contained in separate directories (cluster.0, cluster.1, . . .).
Within these directories are a representative RMF ﬁle cluster_-
center_model.rmf3 and localization densities for each subunit
deﬁned in the density_ranges.txt ﬁle (see Note 22).
4.5.3
Visualizing Models
The cluster RMF ﬁles and localization densities can be visualized
using UCSF Chimera version 1.13. Example scripts for visualiz-
ing all localization densities are provided in ./analysis/
scripts/chimera_scripts.
At this point, one must decide if the models are helpful in
answering our biological questions. In the case of this tutorial,
the PPI is localized to within a few A˚ , and we can make predictions
as to what residues may be important for this interaction. If our
models are not resolved well enough, then more information may
have to be added through additional experiments, addition of
constraints to the sampling, change in system representation,
and/or additional sampling. We can iterate this process until we
are satisﬁed with our output models.
4.5.4
Additional Model
Validation
Additional validation of the ﬁnal model ensemble can be performed
by rerunning the above protocol while omitting one or more of the
input data points. Ideally, models generated with only a subset of
the data will not differ signiﬁcantly from the original models.
Further, any information not used in the modeling process can be
used as a validation of the ﬁnal model ensemble (Subheading 2.4).
370
Daniel Saltzberg et al.

4.6
Storing and
Reporting Results
in the wwPDB
For our modeling to be reproducible—a key requirement for the
four-stage modeling procedure (Fig. 1) and for science in general—
the modeling protocol, all of the input data we used, and the ﬁnal
output models, should be deposited in a public location, ideally the
nascent PDB-Dev repository (https://pdb-dev.wwpdb.org/).
4.6.1
Modeling Protocol
The modeling protocol includes the entire procedure of converting
raw input data to output models, and so comprises both the set of
IMP Python scripts described above and any procedures used to
prepare IMP inputs, such as comparative modeling of subunits,
segmentation of an EM density, and processing of XL-MS data to
get a set of proximate residues. An excellent way to store and
disseminate such a protocol is by using a source control system
with a publicly accessible web frontend, such as GitHub (as is used
for this tutorial). Integrative modeling is an inherently collaborative
process. Source control makes it straightforward to track changes
to all of the protocol scripts and data by local and remote colla-
borators. All protocol ﬁles should be deposited in a permanent
location with a ﬁxed Digital Object Identiﬁer (DOI). A number
of free services are available for deposition of such ﬁles, such as
Zenodo (https://zenodo.org) and FigShare (https://ﬁgshare.
com), where a snapshot of a GitHub repository for the published
work can be deposited. For an example, see ref. 38.
4.6.2
Input Data
Each piece of input data used should also be publicly available.
Where possible, these data should be deposited in a repository
speciﬁc to the given experimental technique and referenced from
the model mmCIF ﬁle. For example, all of the crystal structures
used in this example are simply referenced by their PDB IDs. Where
such a repository does not exist, the data ﬁles should be made
available at a DOI. The simplest way to archive these ﬁles is to
store them in the same GitHub repository used for the modeling
protocol. If derived data are used, the modeling protocol should
indicate where the original raw data came from.
4.6.3
Output Models
A decision needs to be made about which models to deposit.
Generally, a representative sample of each cluster should be depos-
ited, together with the localization densities of the entire cluster.
The mmCIF ﬁle format allows for multiple models, potentially
at multiple scales, in multiple states, and/or different time points,
to be stored in a single ﬁle together with pointers to the input data
and modeling protocol. Implementation of this format in IMP is
still under development. The functionality will extract information
from the RMF ﬁles output by the IMP modeling and combine it
with metadata extracted from each experimental input. This ﬁle can
be visualized in UCSF ChimeraX [39], and similar ﬁles from real
modeling runs can be deposited in PDB-Dev and cited in
publications.
Modeling Biological Complexes Using IMP
371

Fig. 6 Results for sampling exhaustiveness protocol for modeling in complex of actin and tropomodulin–gel-
solin chimera. (a) Results of test 1, convergence of the model score, for the 1618 good-scoring models; the
scores do not continue to improve as more models are computed essentially independently. The error bar
represents the standard deviations of the best scores, estimated by repeating sampling of models ten times.
The red dotted line indicates a lower bound reference on the total score. (b) Results of test 2, testing similarity
of model score distributions between samples 1 (red) and 2 (blue); the difference in distribution of scores is
372
Daniel Saltzberg et al.

5
Notes
1. Other sampling methods include Rapidly Exploring Random
Trees (RRT) for searching dihedral space [40], divide-and-
conquer message passing methods [41] for large discrete
spaces, conjugate gradients, and molecular dynamics.
2. In this case, the user may reformulate the representation by
adding a state to the system (see Note 8).
3. In general, an ensemble of models can be visualized as a locali-
zation probability density map (localization density). The map
speciﬁes the probability of any volume element being occupied
by a given bead in superposed good scoring models.
4. Simulated EM maps can be created in IMP using the following
command:
simulate_density_from_pdb
<file.pdb>
<output.mrc> <resolution> <a/pixel>
5. Spherical beads are applied to every ten residues with smaller
beads applied to loops of smaller length.
6. These residues are also assigned to rigid_body 1 to improve
sampling. All beads within rigid bodies are, by default, allowed
to be ﬂexible.
7. The ﬁle ./modeling/modeling_manual.py contains this
exact system built manually using PMI commands instead of
a topology ﬁle. PMI commands allow signiﬁcantly more ﬂexi-
bility in model design.
8. To add a second state with the same topology, this line can be
repeated, or to use a different topology, bs.add_state(t2)
can be invoked with a different topology ﬁle.
9. For coarse-grained models, a molecular mechanics force ﬁeld is
not applicable. However, the CHARMM force ﬁeld can be

Fig. 6 (continued) signiﬁcant (Kolmogorov-Smirnov two-sample test p-value less than 0.05) but the magni-
tude of the difference is small (the Kolmogorov-Smirnov two-sample test statistic D is 0.02); thus, the two
score distributions are effectively equal. (c) Results of test 3, three criteria for determining the sampling
precision (Y-axis), evaluated as a function of the RMSD clustering threshold (X-axis). First, the p-value is
computed using the χ2-test for homogeneity of proportions (red dots). Second, an effect size for the χ2-test is
quantiﬁed by the Cramer’s V value (blue squares). Third, the population of models in sufﬁciently large clusters
(containing at least ten models from each sample) is shown as green triangles. The vertical dotted gray line
indicates the RMSD clustering threshold at which three conditions are satisﬁed ( p-value >0.05 [dotted red
line], Cramer’s V < 0.10 [dotted blue line], and the population of clustered models >0.80 [dotted green line]),
thus deﬁning the sampling precision of 3.5 A˚. (d) Populations of sample 1 and 2 models in the clusters
obtained by threshold-based clustering using the RMSD threshold of 3.5 A˚ . Cluster precision is shown for each
cluster. (e, f) Results of test 4: comparison of localization probability densities of models from sample A and
sample B for the major cluster (84% population). The cross-correlation of the density maps of the two samples
is 0.99 for the gelsolin (red) and tropomysin (blue) maps and 0.97 for the actin map (green)
Modeling Biological Complexes Using IMP
373

applied to enforce stereochemistry on atomic models. See the
examples in the IMP.atom module to learn how to implement
this restraint.
10. Model SAXS proﬁles can be computed using residues, CA
atoms, heavy atoms, or all atoms, depending on the resolution
of the model. The recommended maxq values are dependent
on this choice. At residue resolution, the ﬁt is only valid up
until q ~ 0.15; for heavy atoms q ¼ 0.4; and for all atoms, the ﬁt
is valid out to q ¼ 1.0 (the maximum value).
11. See derived_xls.dat and the modeling.py script for a
more in-depth explanation of crosslink keys.
12. The shufﬂe algorithm fails if it cannot ﬁnd a conﬁguration
without any overlap between components. If this happens,
try increasing the max_translation parameter. Do not set
this too high as you will spend way too much time getting your
system to move back together.
13. A list of acceptable keywords can be determined by running
../scripts/plot_stat.py ./path/to/stat/file pk.
14. For scores whose thresholds are not known a priori, one can
perform a multistage ﬁltering process as outlined in the above
protocol.
15. Currently, the choice of ﬁltering criteria is very subjective.
Ideally, a fully Bayesian framework will allow for objective
weighting of different restraints and allow for ﬁltering at single
likelihood. Until then, the choice of a score or parameter that
represents a “good scoring model” should be carefully thought
out by the modeler and reported in the text.
16. In general, we require at least 1000 or more models for asses-
sing sampling exhaustiveness. Our score thresholds were cho-
sen in order to have a reasonable number (1000–20,000)
models for analysis. If we have too few models, the satisfaction
criteria should be relaxed, or more sampling should be per-
formed to ﬁnd more satisfactory models. Too many models
(>20,000) will make subsequent processing more computa-
tionally intensive; in this case, satisfaction criteria can be made
stricter, or one can pass a random subset of these models to the
sampling convergence protocol.
17. An explanation of the PMI selection format can be found at
https://github.com/salilab/pmi/wiki/PMI-Tuple-Selection-
Format
18. One can choose whether to align models (a option) or not.
Alignment of models is sometimes not necessary, for example,
when one has a medium resolution or better EM map.
19. For calculating sampling precision, the grid size is the step size
at which clustering is performed between the minimum and
374
Daniel Saltzberg et al.

maximum RMSDs in the dataset. This tutorial uses 0.1 A˚ to get
a very precise estimate of the sampling precision; however, this
results in a very long calculation. In practice, especially for
larger systems whose sampling precision will be much lower,
one would choose a larger value to make calculation more
efﬁcient.
20. If alignment is necessary, the GPU mode of pyRMSD generally
increases performance signiﬁcantly. It is invoked by using m
cuda.
21. The output of the protocol can be readily plotted using any
plotting software. Example scripts in ./analysis/scripts/
gnuplot_scripts can be used to obtain the plots in Fig. 6.
22. Sometimes, there are too many clusters to visualize at the
determined sampling precision. In this case, we can rerun
clustering using a threshold worse than the sampling precision
to get fewer clusters to visualize. In that case, the skip option
(s) along with the value of clustering threshold (ct) allows
one to bypass RMSD and sampling precision calculation and
get the clusters and their densities, as follows: python ../
scripts/Master_Sampling_Exhaustiveness_Analy-
sis.py n actin d density_custom.txt ct 4.39 a
s. Note that this clustering threshold should always be
worse than the sampling precision.
23. Built-in Chimera color names can be found at: https://www.
cgl.ucsf.edu/chimera/docs/UsersGuide/colortables.html
24. These keywords are speciﬁcally for completely disordered
domains or short helical components. For IDEAL_HELIX, a
single helix will be created for that component.
References
1. Mitra
K,
Frank
J
(2006)
RIBOSOME
DYNAMICS: insights from atomic structure
modeling
into
cryo-electron
microscopy
maps.
Annu
Rev
Biophys
Biomol
Struct
35:299–317.
https://doi.org/10.1146/
annurev.biophys.35.040405.101950
2. Robinson CV, Sali A, Baumeister W (2007)
The molecular sociology of the cell. Nature
450:973–982
3. Sali A, Glaeser R, Earnest T, Baumeister W
(2003) From words to literature in structural
proteomics. Nature 422:216–225
4. Schmeing TM, Ramakrishnan V (2009) What
recent ribosome structures have revealed about
the
mechanism
of
translation.
Nature
461:1234–1242.
https://doi.org/10.1038/
nature08403
5. Blundell TL, Johnson LN (1976) Protein crys-
tallography. Academic Press, New York
6. Chiu W, Baker ML, Jiang W et al (2005) Elec-
tron cryomicroscopy of biological machines at
subnanometer
resolution.
Structure
13:363–372.
https://doi.org/10.1016/j.str.
2004.12.016
7. Lucˇic´ V, Leis A, Baumeister W (2008) Cryo-
electron tomography of cells: connecting struc-
ture
and
function.
Histochem
Cell
Biol
130:185–196.
https://doi.org/10.1007/
s00418-008-0459-y
8. Stahlberg H, Walz T (2008) Molecular elec-
tron microscopy: state of the art and current
challenges.
ACS
Chem
Biol
3:268–281.
https://doi.org/10.1021/cb800037d
9. Parrish JR, Gulyas KD, Finley RL (2006) Yeast
two-hybrid
contributions
to
interactome
mapping. Curr Opin Biotechnol 17:387–393.
https://doi.org/10.1016/j.copbio.2006.06.
006
Modeling Biological Complexes Using IMP
375

10. Fernandez-Martinez J, Phillips J, Sekedat MD
et al (2012) Structure–function mapping of a
heptameric module in the nuclear pore com-
plex. J Cell Biol 196:419–434. https://doi.
org/10.1083/jcb.201109008
11. Gingras A-C, Gstaiger M, Raught B, Aebersold
R (2007) Analysis of protein complexes using
mass spectrometry. Nat Rev Mol Cell Biol
8:645–654.
https://doi.org/10.1038/
nrm2208
12. Ward AB, Sali A, Wilson IA (2013) Integrative
structural
biology.
Science
339:913–915.
https://doi.org/10.1126/science.1228565
13. Lasker K, Fo¨rster F, Bohn S et al (2012)
Molecular architecture of the 26S proteasome
holocomplex determined by an integrative
approach.
Proc
Natl
Acad
Sci
U
S
A
109:1380–1387
14. Simon B, Madl T, Mackereth CD et al (2010)
An efﬁcient protocol for NMR-spectroscopy-
based structure determination of protein com-
plexes in solution. Angew Chem Int Ed Engl
49:1967–1970.
https://doi.org/10.1002/
anie.200906147
15. Bau` D, Sanyal A, Lajoie BR et al (2011) The
three-dimensional folding of the α-globin gene
domain reveals formation of chromatin glo-
bules.
Nat
Struct
Mol
Biol
18:107–114.
https://doi.org/10.1038/nsmb.1936
16. Viswanath S, Bonomi M, Kim SJ et al (2017)
The molecular architecture of the yeast spindle
pole body core determined by Bayesian inte-
grative
modeling.
Mol
Biol
Cell
28:3298–3314.
https://doi.org/10.1091/
mbc.E17-06-0397
17. Kim SJ, Fernandez-Martinez J, Nudelman I
et al (2018) Integrative structure and func-
tional anatomy of a nuclear pore complex.
Nature
555:475–482.
https://doi.org/10.
1038/nature26003
18. Molnar K, Bonomi M, Pellarin R et al (2014)
Cys-scanning disulﬁde crosslinking and Bayes-
ian modeling probe the transmembrane signal-
ing mechanism of the histidine kinase, PhoQ.
Structure 22:1239–1251
19. Webb B, Viswanath S, Bonomi M et al (2018)
Integrative structure modeling with the inte-
grative modeling platform: integrative struc-
ture
modeling
with
IMP.
Protein
Sci
27:245–258.
https://doi.org/10.1002/pro.
3311
20. Shen M, Sali A (2006) Statistical potential for
assessment and prediction of protein struc-
tures. Protein Sci 15:2507–2524. https://doi.
org/10.1110/ps.062416606
21. Sippl MJ (1990) Calculation of conformational
ensembles from potentials of mena force. J Mol
Biol 213:859–883. https://doi.org/10.1016/
S0022-2836(05)80269-4
22. Brooks BR, Brooks CL, Mackerell AD et al
(2009) CHARMM: the biomolecular simula-
tion
program.
J
Comput
Chem
30:1545–1614.
https://doi.org/10.1002/
jcc.21287
23. Weiner SJ, Kollman PA, Case DA et al (1984) A
new force ﬁeld for molecular mechanical simu-
lation of nucleic acids and proteins. J Am Chem
Soc 106:765–784. https://doi.org/10.1021/
ja00315a051
24. Sˇali A, Blundell TL (1993) Comparative pro-
tein
modelling
by
satisfaction
of
spatial
restraints. J Mol Biol 234:779–815. https://
doi.org/10.1006/jmbi.1993.1626
25. Kelley LA, Mezulis S, Yates CM et al (2015)
The Phyre2 web portal for protein modeling,
prediction
and
analysis.
Nat
Protoc
10:845–858.
https://doi.org/10.1038/
nprot.2015.053
26. Hanot S, Bonomi M, Greenberg CH et al
(2018) Bayesian multi-scale modeling of mac-
romolecular structures based on cryo-electron
microscopy density maps. https://doi.org/10.
1101/113951
27. Kawabata T (2008) Multiple subunit ﬁtting
into a low-resolution density map of a macro-
molecular complex using a Gaussian mixture
model. Biophys J 95:4643–4658. https://doi.
org/10.1529/biophysj.108.137125
28. Metropolis N, Rosenbluth AW, Rosenbluth
MN et al (1953) Equation of state calculations
by fast computing machines. J Chem Phys
21:1087–1092. https://doi.org/10.1063/1.
1699114
29. Swendsen RH, Wang J-S (1986) Replica
Monte Carlo simulation of spin-glasses. Phys
Rev Lett 57:2607–2609. https://doi.org/10.
1103/PhysRevLett.57.2607
30. Viswanath S, Chemmama IE, Cimermancic P,
Sali A (2017) Assessing exhaustiveness of sto-
chastic sampling for integrative modeling of
macromolecular
structures.
Biophys
J
113:2344–2353. https://doi.org/10.1016/j.
bpj.2017.10.005
31. Alber F, Dokudovskaya S, Veenhoff LM et al
(2007) The molecular architecture of the
nuclear pore complex. Nature 450:695–701
32. Sali A, Berman HM, Schwede T et al (2015)
Outcome of the ﬁrst wwPDB hybrid/integra-
tive methods task force workshop. Structure
23:1156–1167.
https://doi.org/10.1016/j.
str.2015.05.013
33. Burley SK, Kurisu G, Markley JL et al (2017)
PDB-Dev: a prototype system for depositing
integrative/hybrid
structural
models.
376
Daniel Saltzberg et al.

Structure 25:1317–1318. https://doi.org/10.
1016/j.str.2017.08.001
34. Vallat B, Webb B, Westbrook JD et al (2018)
Development of a prototype system for archiv-
ing integrative/hybrid structure models of
biological
macromolecules.
Structure.
https://doi.org/10.1016/j.str.2018.03.011
35. Gil VA, Guallar V (2013) pyRMSD: a Python
package for efﬁcient pairwise RMSD matrix
calculation
and
handling.
Bioinformatics
29:2363–2364. https://doi.org/10.1093/bio
informatics/btt402
36. Rao JN, Dominguez R (2014) Complex of
ATP-actin with the C-terminal actin-binding
domain of tropomodulin. https://doi.org/
10.2210/pdb4pki/pdb
37. Schneidman-Duhovny D, Hammel M, Sali A
(2010) FoXS: a web server for rapid computa-
tion and ﬁtting of SAXS proﬁles. Nucleic Acids
Res 38:541–544
38. Robinson P, Trnka M, Pellarin R et al (2015)
Molecular architecture of the yeast mediator
complex.
Elife.
https://doi.org/10.7554/
eLife.08719
39. Goddard TD, Huang CC, Meng EC et al
(2018) UCSF ChimeraX: meeting modern
challenges in visualization and analysis: UCSF
ChimeraX visualization system. Protein Sci
27:14–25.
https://doi.org/10.1002/pro.
3235
40. Carter L, Kim SJ, Schneidman-Duhovny D
et al (2015) Prion protein-antibody complexes
characterized
by
chromatography-coupled
small-angle
X-ray
scattering.
Biophys
J
109:793–805
41. Lasker K, Topf M, Sali A, Wolfson HJ (2009)
Inferential optimization for simultaneous ﬁt-
ting of multiple components into a cryoEM
map of their assembly. J Mol Biol 388:180–194
Modeling Biological Complexes Using IMP
377

Chapter 16
Coevolutionary Analysis of Protein Sequences
for Molecular Modeling
Duccio Malinverni and Alessandro Barducci
Abstract
Thanks to the explosion of genomic sequencing, coevolutionary analysis of protein sequences has gained
great and ever-increasing popularity in the last decade, and it is currently an important and well-established
tool in structural bioinformatics and computational biology. This chapter concisely introduces the theoret-
ical foundation and the practical aspects of coevolutionary analysis, as well as discusses the molecular
modeling strategies to exploit its results in the study of protein structure, dynamics, and interactions. We
present here a complete pipeline from sequence extraction to contact prediction through two examples,
focusing on the predictions of inter-residue contacts in a single protein domain and on the analysis of a
multi-domain protein that undergoes functional, large-scale conformational transitions.
Key words Direct-coupling analysis, Structural bioinformatics, Residue contact prediction, Confor-
mational dynamics, Protein complexes
1
Introduction
Recent advances in genomic sequencing technologies have led to
an astonishing increase in the size of protein sequence databases. In
contrast, the number of deposited protein structures has been
increasing at a signiﬁcantly slower pace. This has led to the renewal
of interest in computational methods aimed at exploiting large
protein sequence datasets to explore structural properties of pro-
teins in the last decade. In particular, the analysis of correlated
mutations to infer structural contacts between residue pairs in
proteins has recently been successfully exploited through the use
of new statistical models [1–5]. These models aim at identifying
pairs of amino acids in spatial proximity, which therefore cannot
mutate independently and thus display patterns of correlated muta-
tions. Such amino acid pairs are called coevolutionary contacts.
Algorithmic improvements in coevolutionary contact predic-
tions combined with improved molecular modeling techniques has
allowed the computational determination of three-dimensional
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_16, © Springer Science+Business Media, LLC, part of Springer Nature 2019
379

protein structures with near-atomistic precision [3, 4, 6]. In partic-
ular, coevolutionary-assisted structure prediction has allowed the
computational modeling of transmembrane proteins, a notoriously
difﬁcult experimental challenge [7, 8]. Furthermore, inter-protein
residue coevolution has allowed the study and reconstruction
of protein complexes which can be experimentally difﬁcult to inves-
tigate
[9–12]
as
well
as
homo-oligomeric
arrangements
[11, 13–15]. Beyond purely structural studies, it has been recog-
nized early on that correlated mutations encode multiple confor-
mations [11, 16–18].
The capabilities of coevolutionary analysis to extract contact
information on multiple scales, ranging from the intra-domain
residue pairs up to protein complexes, called for accompanying
molecular modeling techniques to translate the inferred contacts
to three-dimensional models.
In this chapter, we focus on the use of coevolutionary analysis
to predict inter-residue contacts in protein families and discuss
different strategies to reconstruct molecular models. We present a
complete pipeline from the sequence retrieval to the contact pre-
diction discussing two practical cases, with particular emphasis on
the practical aspects of coevolutionary contact prediction.
2
Theory
2.1
Direct-Coupling
Analysis
The theory behind coevolutionary contact prediction is based on
the concept of proximity-induced mutated correlations between
pairs of interacting residues in proteins. It has long been observed
that pairs of residues located in close proximity in the three-
dimensional structure tend to display highly correlated mutations
[19]. The basic idea behind coevolutionary contact prediction is to
measure these pairwise correlations between pairs of positions in a
multiple-sequence alignment (MSA) of homologous proteins and
thus infer structural proximity between pairs of positions displaying
strong correlations [19–21]. However, methods based on the anal-
ysis of isolated pairs of positions in the MSA suffered from the effect
of mediated chains of correlations, which easily appear in the context
of densely packed protein domains. Such mediated correlations
appear when two amino acids A and B are in structural contact
with a common third residue C, while no direct interaction exists
between A and B. This results in the A–B mutations patterns to be
correlated through a chaining effect mediated by the third amino
acid C. To circumvent these limitations, several classes of global
statistical models were introduced, which modeled the complete
joint distribution of amino acids in a protein family, thus naturally
incorporating the effect of mediated correlations [1, 2, 20,
22]. Although based on different theoretical frameworks and
380
Duccio Malinverni and Alessandro Barducci

parametric forms, these different approaches all share the property
of jointly modeling all sequence positions of a protein family.
One class of such methods, referred to as Direct-Coupling
Analysis (DCA), has recently gained great popularity [1, 14, 23,
24]. The DCA model is based on the principle of maximum
entropy [25], whereby one seeks the least constraint distribution
over sequence space subject to the constraint that it reproduces the
one- and two-site marginal which are measured on the families’
MSA. Explicitly performing the entropy maximization with the
aforementioned imposed restraints leads DCA models to take the
form of generalized q-state Potts models (Eq. 1)
P a
ð Þ ¼ 1
Z e
P
i
hi ai
ð
ÞþP
i,j
J ij ai;a j
ð
Þ
ð1Þ
where a denotes an amino acid sequence (a1, a2,
. . . , aN) of
length N, i and j denote the residue positions along the sequences,
and hi and Jij are the parameters controlling the single-site occupa-
tion and two-site correlations, respectively. After ﬁtting these para-
meters such that the model reproduces the measured one- and
two-site marginals, it has been shown that the direct-couplings Jij
are excellent predictors of structural contacts [1, 14, 23]. The
rationale behind this model is that a reduced set of coupling para-
meters Jij are in principle sufﬁcient to generate a larger number of
correlations, as they effectively couple all positions in the global
model given by Eq. 1. In fact, the coupling parameters Jij between
two positions take the form of local 21  21 matrices (20 amino
acids +1 alignment gap). In order to reduce these couplings to
scalars that can be used to rank predicted coevolving contacts, a
score based on the Frobenius norm of Jij, combined with an
average-product correction, has empirically been shown to give
excellent results for protein contact predictions [23, 26].
The exact inference of the parameters hi and Jij in Eq. 1 is in
principle a computationally intractable task, as it either involves the
computation of the partition function Z or marginalization, which
both involve a number of terms which grow exponentially with the
length N of the protein family. Several approximation schemes have
thus been derived, which allow the approximate inference of the
model parameters in polynomial times (Table 1). These different
DCA ﬂavors can roughly be classiﬁed into different classes: Mean-
Field-like techniques are based on a small coupling expansion of the
Potts model in Eq. 1 and involve the explicit inversion of a correla-
tion matrix measured on the MSA [14, 28]. Pseudo-likelihood
approximations numerically maximize a likelihood function of
Eq. 1, which has been modiﬁed to be tractable [3, 4, 32]. The
adaptive cluster expansion (ACE) approach is based on a cluster
expansion of the Potts model to build an iteratively improving
approximation of the model [30]. Finally, Boltzmann machine
Coevolutionary Analysis for Molecular Modeling
381

learning techniques tackle the direct maximization of the Likeli-
hood function of the Potts model, by iteratively computing the
gradient of the Likelihood through Monte-Carlo simulations of the
model [18, 31].
In general, Mean-Field-like DCAs are the fastest, as they only
involve computing and inverting a covariance matrix. This rapidity
has allowed the use of Mean-Field DCA in iterative paralog match-
ing problems [33, 34], which require the computation of a full
DCA at each iteration. Pseudo-likelihood methods are considered
to be the state of the art DCA methods with highest contact-
prediction precision [9, 23, 27]. This comes at the price of a higher
computational cost, as they involve the numerical resolution of a
large-scale convex optimization problem. Finally, ACE and Boltz-
mann machine learning approaches are known to outperform other
inference schemes with respect to the quality of models when
employed as generative models, that is, resampled to generate
new sequences of the family. In the task of contact-prediction,
however, these methods are generally at par with pseudo-
likelihood-based approaches.
In practice, there are generally O(N2212) parameters to infer
from the data. This illustrates the high requirement in the number
of input samples (i.e., number of sequences) of DCA methods. To
partially counter this over-ﬁtting issue, all DCA methods rely on
regularization techniques, which vary depending on the ﬂavor of
the methods. Different estimates have been performed to give
guidelines on the number of required sequences to efﬁciently
infer the model [3, 4, 35]. It has recently been recognized that
the absolute number of available sequences was less critical for the
Table 1
List of different implementations of DCA
Code
Method
Website
References
DCA
Mean-Field
http://dca.rice.edu/portal/dca/
[14]
FreeContact
Mean-Field
ftp://rostlab.org/free/
[27]
GaussDCA
Gaussian DCA
https://github.com/carlobaldassi/GaussDCA.jl
[28]
Gremlin
Sym. PLM
http://openseq.org/index.php
[4, 9]
EVFold
Sym. PLM
http://evfold.org/evfold-web/evfold.do
[3, 7]
CCMpred
Sym. PLM
https://github.com/soedinglab/CCMpred
[29]
lbsDCA
Asym. PLM
https://gitlab.com/ducciomalinverni/lbsDCA/
[11]
ACE
Cluster Expansion
https://github.com/johnbarton/ACE
[30]
ELSS
Boltzman Learning
https://github.com/simomarsili/elss
[18]
bmDCA
Boltzman Learning
https://github.com/matteoﬁgliuzzi/bmDCA
[31]
382
Duccio Malinverni and Alessandro Barducci

overall prediction quality than the effective number of sequences,
after taking into account the redundancy in the dataset [1, 4, 7,
14]. While the ﬁrst generations of DCA implementations require
thousands of effective sequences to generate reliable predictions,
recent contact prediction software have lowered the sequence
requirement to the order of 100–300 effective sequences (dis-
cussed later in this study) to achieve a high precision on the highest
ranked predictions [36, 37]. Notice that while these methods are
able to predict structural contacts from small sequence datasets, the
absolute number of predictions remains relatively small. In our
experience, as a rule of thumb, families with more than ~1000
effective sequences (discussed later in this study) give reasonably
good results, while, starting from ~2000 effective sequences, the
DCA predictions are very reliable. In general, the fraction of correct
predictions grows with the number of available sequences until
saturation. In a meta-genomic-based study, Ovchinnikov et al. esti-
mate that a reliable prediction of the three-dimensional fold using
the Rosetta package requires at least 32 Nf protein sequences,
where Nf corresponds to the number of effective sequences
(at 80% identity) normalized by the square root of the protein
length [38].
Sequences in deposited databases (Uniprot, Pfam) are generally
not statistically independent. Indeed, unequal experimental interest
in different model organisms leads to an overrepresentation of such
organisms in the databases, thus leading to a dataset not truthfully
representing the natural statistics of the family. To overcome this
bias, an empirical reweighting scheme is used in all DCA proce-
dures. To this aim, one can assign to each sequence a statistical
weight that is inversely proportional to the number of similar
sequences found in the MSA, where the similarity is deﬁned by a
user-set cutoff on the pairwise Hamming distances (typically 80%
or 90% identity). This procedure effectively decreases the weight of
sequences having a large number of very similar sequences in the
database, typically a hallmark of over-sampled organisms. The com-
puted weights (by construction less than or equal to 1) can be used
to compute the effective number of sequences BEff, deﬁned as the
sum of the weights. This is a measure of the number of “statistically
independent” sequences in the dataset, which gives a better esti-
mate of the quality of the dataset than the raw number B of initial
input sequences. Thus, as discussed earlier, a BEff > 1000 can be
used as an empirical rule to assess the reliability of a DCA model.
2.2
DCA-Guided
Molecular Modeling
As in many domains of structural biology, molecular modeling is an
essential ingredient for translating the results of sequence coevolu-
tionary analysis into three-dimensional protein structures. This task
is usually accomplished in de novo protein structural determination
by taking advantage of the structural information embedded in the
top-ranked coevolutionary predictions with robust minimization
Coevolutionary Analysis for Molecular Modeling
383

protocols (see Table 2). Particularly, DCA predictions can be trans-
lated into residue–residue constraints to be used as input for a
distance geometry algorithm that is routinely used for structural
determination by NMR spectroscopy data [3]. Alternatively, the
strongest coevolutionary couplings can be used in CG simulations
based on structure-based models (SBM) to deﬁne energetically
favorable native-like interactions [16]. Both these approaches are
usually complemented with a priori secondary structure prediction
and rely on a posteriori further structural reﬁnement via atomistic
molecular dynamics (MD) simulations. Since these ﬁrst pioneering
studies [3, 16], these computational strategies have been shown to
result into high-quality native structures if sufﬁcient sequence
information is available. Notably, a closely related “hybrid” proto-
col for structural determination, which combines DCA-inspired
restraints and the multi-scale energy functions of the ROSETTA
package, obtained remarkable success in the 11th Critical Assess-
ment of methods for protein Structure Prediction (CASP11) exper-
iment, and it was then applied to provide large-scale structural
information about several protein families of unknown fold
[4, 46]. In the same manner, the introduction of coevolutionary
restraints was shown to signiﬁcantly improve the quality of the
native structures predicted with the AWSEM force ﬁeld [42, 47].
Interestingly, the determination of coevolutionary couplings and
their application as structural restraints are not hindered by the
canonical limitations that affect most experimental structural biology
techniques, such as strict requirements on the target solubility, size,
or structural stability. DCA-assisted structural determination has
thus been successfully extended to challenging molecular systems,
including membrane proteins and intrinsically disordered chains that
fold only upon binding to a cellular partner [7, 48].
Furthermore, coevolutionary analysis can be extended to struc-
tural investigation of protein-protein interaction by evaluating the
statistical couplings in paired MSAs of interacting proteins [9, 10,
49]. This approach can report about residues involved in the
Table 2
List of molecular modeling software used in conjunction with coevolu-
tionary predictions
Code
Website
References
Rosetta
https://www.rosettacommons.org/software
[9, 39]
CNS
http://cns-online.org/v1.3/
[3, 40]
Haddock
https://haddock.science.uu.nl
[10, 41]
AWSEM
http://awsem-md.org
[42, 43]
SMOG
http://smog-server.org
[44, 45]
384
Duccio Malinverni and Alessandro Barducci

intermolecular interface and provide sufﬁcient information for
accurate structural determination of protein complexes. In this
respect, one of the main limitations in inferring protein–protein
interactions is related to the difﬁculties in pairing same-organism
sequences in the presence of multiple paralogs, although methods
have been proposed to address this problem [33, 50]. Additionally,
coevolving inter-protein residues have also been identiﬁed at the
homo-dimeric level, allowing the study of novel functional homo-
dimeric assemblies through coevolutionary analysis [13, 14, 51,
52]. This approach can report about residues involved in the inter-
molecular interface and results in the accurate structural determi-
nation
of
protein
complexes
by
combining
intermolecular
DCA-derived restraints into popular docking tools, such as HAD-
DOCK [41] or ROSETTA [39].
Crucially, the potential of coevolutionary analysis is not
restricted to the determination of the native conformations of
protein and/or protein complexes. Indeed, proteins are ﬂexible
molecules that most often undergo sizable structural transition
and thus transiently populate heterogeneous conformational states
to perform their cellular function. In such a respect, a pair of
residues is expected to coevolve if they are spatially proximal in at
least one of these functionally relevant conformations. Indeed, all
these states leave an evolutionary footprint and thus are naturally
encoded in the protein sequences. This key concept signiﬁcantly
broadens the possible applications of coevolutionary information in
molecular modeling strategy. Indeed, on the one hand, a direct
comparison with DCA results provides a novel and effective way of
assessing the functional relevance of the conformations sampled
with all-atom or coarse-grained molecular simulations based on
physical potential [11, 53, 54]. On the other hand, coevolutionary
information can be directly used to guide the sampling toward
alternative yet evolutionary-conserved conformations with the ulti-
mate aim of elucidating the entire functional ensemble. To this end,
SBM potentials derived from DCA analysis, and thus encoding
multiple conformations, represent a natural and effective strategy,
which has been successfully applied for sampling with coarse-
grained description the structural transitions between apo and
holo
conformational
states
and/or
folding
intermediates
[16, 18]. More recently, this approach was further extended in a
multi-step computational protocol based on discrete MD that
includes a ﬁltering step aimed at removing uninformative DCA
prediction [55]. Thanks to the improvement in computational
resources and the continuous efforts in devising efﬁcient sampling
algorithms, one can reasonably expect that in the coming years,
coevolutionary information will be routinely used to guide all-atom
simulations in the characterization large-scale conformational tran-
sitions and protein assembly as suggested by recent studies
[56, 57].
Coevolutionary Analysis for Molecular Modeling
385

3
Materials
In the following protocol, all simulations and scripts are performed
using a UNIX environment (Linux or Mac OS). We will use the
lbsDCA implementation of DCA in combination with scripts avail-
able in the dcaTools repository to perform a complete coevolution-
ary analysis of a protein family. lbsDCA is available at https://gitlab.
com/ducciomalinverni/lbsDCA/. dcaTools can be downloaded at
https://gitlab.com/ducciomalinverni/dcaTools/. The dcaTools
package requires a working python 2.7 installation, including bio-
python, numpy, scipy, scikit, and pandas. In addition, the hmmer
software suite [58], available at http://hmmer.org, is required. It is
assumed that all codes and scripts are in the users PATH.
The multiple sequence alignments for the Hsp40-CTD and
Hsp70 families can be downloaded from the PFAM database
(http://pfam.xfam.org) [59] with accession numbers PF01556
and PF00012, respectively. The relevant PDB structures can be
obtained from the PDB database (https://www.rcsb.org) with ID
4J80, 4JNE, and 2KHO.
4
Methods
In the following sections, we will present two complete coevolu-
tionary analyses on the Hsp40-CTD and Hsp70 families.
4.1
Single Domain
Analysis
4.1.1
Multiple Sequence
Alignment Preparation
We will take advantage of the availability of large precomputed
protein
family
alignments
available
in
the
PFAM
database
(Note 1). To retrieve the relevant ﬁles needed for DCA analysis,
one can access the Alignments tab in the page of the PF01556
protein family of interest on PFAM (http://pfam.xfam.org/fam
ily/pf01556). In the “Format an alignment” section, select Full
as Alignment, FASTA as Format, and Gaps as “.”or “-“for the Gaps
option. The alignment can then be generated and downloaded
using
Generate.
Furthermore,
the
Hidden
Markov
Model
(HMM) of the family will be needed, which can be downloaded
at the bottom of the Curation & model tab. The downloaded
multiple sequence alignment (MSA) of the Hsp40-CTD family
(PF01556_full.fasta) needs several preprocessing steps before
being used as input to Direct-Coupling Analysis. Indeed, PFAM
MSAs are built using the hmmer utility [58], which by default
outputs information about inserts not relevant to DCA. The MSA
is ﬁltered of these inserts using the following command:
$
filterMSAOfInserts
PF01556_full.fasta
PF01556_noInserts.
fasta
386
Duccio Malinverni and Alessandro Barducci

A further issue with the current MSA is that it contains a sizable
fraction of sequence fragments, which appear as highly gapped
sequences in the alignment. To extract these fragments, we will
set a threshold on the maximally allowed gap content per sequence
and remove all sequences having more gaps than this threshold (see
Note 2). In the following, we will allow a maximum of 25% gaps
per sequence, which is done using the following command:
$
filterMSAByGapContent
PF01556_noInserts.fasta
0.25
PF01556_75cov.fasta
where we see that from the 13,298 original sequences in the MSA,
12,667 have passed the 75% coverage ﬁltering.
We now have a correctly formatted and ﬁltered MSA on which
we can perform DCA.
4.1.2
Inference of the
DCA Model
To perform coevolutionary-based contact prediction using DCA,
we will use the lbsDCA code to perform the inference using the
asymmetric pseudo-likelihood approximation [23] (see Note 3).
The basic use of this code is straightforward. Here, we will perform
DCA on the previously curated MSA (PF01556_75cov.fasta),
reweighting the sequences using a sequence identity reweighting
scheme for 90% maximum identity (wid 0.9) and four threads
(t 4), resulting in the following call to lbsDCA.
$ lbsDCA -f PF01556_75cov.fasta -wid 0.9 -t 4 -o hsp40_dca
The inference typically takes less than 5 minutes on a mid-range
2016 desktop.
We see in the fourth line of the output, a summary of the model
which is being inferred.
Loaded Model: N=148, B=12,667, Beff=7986.53, q = 21, . . .
In particular, we see that the effective number of sequences
after
reweighting
with
a
90%
identity
cutoff
results
in
BEff ¼ 7986.53 sequences, which ensures us that we have sufﬁcient
variability in our dataset to reliably infer a DCA mode.
By default, lbsDCA outputs the Frobenius norm DCA scores
(Subheading
2.1),
both
with
(hsp40_dca.dat)
and
without
(hsp40_dca_raw.dat) APC correction. For the following analysis,
we will only use the full APC-corrected DCA scores, contained
in the hsp40_dca.dat ﬁle. As the DCA scores are symmetric, that
is, Si,j ¼ Sj,i, with zero diagonal, this ﬁle only stores the upper
diagonal part of the scores. This output format is natively compati-
ble with the dcaTools scripts which we will use in the following
section to analyze the DCA predictions.
Coevolutionary Analysis for Molecular Modeling
387

4.1.3
DCA Predictions
Analysis
To assess the quality of the DCA predictions, we can take advantage
of the availability of experimentally determined structures to
benchmark the prediction precision. This requires computing the
inter-residue distance map for a known structure and further align-
ing it to the DCA predictions. Indeed, the coordinates indexing the
predicted DCA contacts pertain to the positions in the family MSA,
whereas the coordinates indexing the structural distance map per-
tain to the positions along the chain in the PDB. In the MSA,
alignment gaps and inserts are such that these two sets of indices
generally do not overlap. The computation of the experimental
distance map and its alignment to the MSA are performed by a
single script in the dcaTools package, which takes as arguments the
PDB ﬁle to be mapped (4J80.pdb), the chain identiﬁer in the PDB
(A), the HMM of the protein family contained in the MSA
(DnaJ_C.hmm), and the output ﬁle name (4J80_A.map).
$ mapPDB -hmm1 DnaJ_C.hmm 4J80.pdb A 4J80_A.map
Note that this script requires the installation of the hmmalign
tool contained in the HMMER software package [58]. The output
distance map will have the same dimensions as the DCA predic-
tions, namely NxN, where N denotes the width (number of col-
umns) of the input MSA.
Having obtained an experimental reference distance map, we
can now quantify the precision of the DCA prediction, that is, the
fraction
of correctly
predicted
contacts
with the
following
command:
$ plotTPrates
4J80_A.map hsp40_dca.dat 500 8.5
where we have chosen to compute the precision up to the
500 top-ranked contacts, using an inter-residue contact deﬁnition
of 8.5 A˚ to deﬁne a structural contact in the experimental structure
(see Note 4). Note that, in general, very short-range contacts (i.e.,
between residues separated by less than ~5 residues along the chain)
display very strong DCA scores. These contacts are generally not
informative about the global tertiary structure of a protein and are
therefore not included in subsequent analyses. Indeed, the plotTP-
rates routine does not account for short-ranged contacts with
sequence separation below four residues.
The precision curve (Fig. 1a) is informative of the range over
which our DCA predictions are reliable. We observe that all the
initial predictions are correct, up to about ten predictions (Npred/
N ¼ 0.067, Precision ¼ 1.0), followed by a sharp drop of the
precision and a stabilization up to around 150 predictions
(Npred/N ¼ ~1, Precision ~84%). Such drops in the initial range
of the precision curves are often observed due to minor discrepan-
cies in the contact map. As the precision is computed over a
388
Duccio Malinverni and Alessandro Barducci

relatively low number of contacts at the left end of the curve, minor
false positives hugely inﬂuence the precision, while the observed
stabilization plateau generally gives a reliable quantitative estima-
tion of the quality of the predictions. From this example, we thus
see that approximately N ¼ 148 ﬁrst contacts seem reliable and can
be considered for further analysis. We can thus visualize them as a
predicted contact map. The plotTopContacts scripts of dcaTools
allows overlaying the DCA predictions over the reference contact
map extracted from a PDB. We here decide to visualize the
148 highest ranked DCA predictions, compared to a reference
contact map deﬁned at 8.5 A˚ .
$ plotTopContacts 4J80_A.map hsp40_dca.dat 148 8.5
The results in Fig. 1b show that the DCA predictions are well
distributed over the entire length of the protein, and that they are
formed by both short- and long-range contacts. Notice that, similar
to plotTPrates, plotTopContact does not account for short-ranged
contacts with sequence-separation below ﬁve residues. We can also
observe that, in this case, all the false-positive predictions lie in close
vicinity of native structural contacts observed in the PDB structure.
Such effects are often seen in DCA predictions and reﬂect the fact
that epistasis-induced correlated mutations span a physical range
which can exceed the typical distances deﬁning crystallographic
contacts (see comment in Subheading 4.2.2).
We can now output the list of predicted DCA contacts using
the listTopContacts routine of dcaTools. For
the structural
A
B
Fig. 1 (a) Precision curve for the DCA predictions computed over the 500 highest ranked contacts. The
horizontal gives the number of predicted contacts Npred, normalized by the length N of the protein family. (b)
Structural contact map overlaid with 148 highest ranked DCA contacts, computed with the PDB 4J80
structure. Gray background: PDB contact. Green: Correct DCA predictions. Red: False DCA predictions. In
both panels, structural contacts are deﬁned by a minimal distance between heavy-atoms of 8.5 A˚
Coevolutionary Analysis for Molecular Modeling
389

reconstruction of a speciﬁc member of the Hsp40 family, it is useful
to have the indices of the DCA contacts relative to a particular
sequence. To perform this mapping, we have to supply the target
sequence in fasta format, as well as the hmm of the family, so that
the index mapping can be performed. We will here focus on DnaJ of
Salmonella typhimurium, the sequence of which is found in the
P0A1G7.fasta ﬁle, and list the 148 highest ranked DCA predictions
using the following command:
$ listTopContacts -hmm DnaJ_C.hmm -seq P0A1G7.fasta hsp40_dca.
dat 148
which results in the output shown in Fig. 2.
We here see the difference in mapping indices between the
MSA numbering of the contacts (ﬁrst two columns i,j) and the
indices mapped onto the target sequence (third and fourth columns
i_map,j_map). In this particular case, the MSA covers only the
C-terminal domain of the Hsp40 cochaperones, which have a
complex and variable multi-domain architecture. We therefore see
that while the MSA numbering starts at 1 in the ﬁrst column, the
corresponding starting index in the PDB structure which contains
the full-length protein starts at 120. These projected contacts can
now be used in a molecular modeling approach to perform
DCA-guided molecular reconstruction, structure prediction, or
analysis as discussed in Subheading 2.2.
4.2
A More Complex
Scenario
In this second example, we will analyze a protein family character-
ized by multiple conformations, namely the Hsp70 chaperone.
4.2.1
Sequence
Preprocessing and DCA
Inference
We follow the same sequence extraction procedure as presented in
Subheading 4.1.1, namely ﬁltering the Pfam MSA of inserts and
keeping only sequences having less than 25% of gaps, using the
Fig. 2 Expected output from the listTopContacts utility
390
Duccio Malinverni and Alessandro Barducci

ﬁlterMSAOfInserts and ﬁlterMSAByGapContent scripts as dis-
cussed
earlier.
After
this
procedure,
the
resulting
MSA
(PF00012_75cov.fasta) contains 12,063 out of the original
23,150 sequences in the Pfam MSA, covering 599 positions. We
here again perform DCA with 90% identity sequence reweighting
running on four threads.
$ lbsDCA -f PF00012_75cov.fasta -wid 0.9 -t 4 -o hsp70_dca
As the Hsp70 MSA is considerably longer compared to the
Hsp40 CTD MSA (599 vs. 148 positions), the DCA inference on
this case takes roughly 1–2 h using four threads.
4.2.2
Contact Analysis in
Presence of Multiple
Conformations
The Hsp70 chaperone is characterized by multiple conformations,
depending on the nature of the bound nucleotide. The two con-
formational states are separated by an allosteric transition which
induces a large-scale rearrangement of the two domains forming
the protein (Fig. 3). These conformational states are characterized
by two diverse sets of inter-residue contacts that are only partially
overlapping. Here we will see how DCA can predict the interactions
present in both conformational states as well as those contacts that
are formed exclusively in each individual structure.
The aligned distance maps of the two conformations are
obtained as for the single case by
$ mapPDB -hmm1 HSP70.hmm 4JNE.pdb A 4JNE_A.map.
$ mapPDB -hmm1 HSP70.hmm 2KHO.pdb A 2KHO_A.map.
The warnings about chain discontinuity can safely be ignored.
In addition to these two maps, we also want to compute the union
Fig. 3 Multiple conformations of the Hsp70 chaperone. (a) ATP-bound state (PDB
ID 4JNE). (b) ADP-bound state (PDB ID 2KHO). The nucleotide-binding-domain
(Blue-Green) is aligned in the two structures
Coevolutionary Analysis for Molecular Modeling
391

of the distance maps of the two conformations, deﬁned as the
minimum of the two individual maps, and obtained by.
$ combineMaps 2kho_A.map 4jne_A.map union.map.
We can now analyze the quality of the DCA predictions com-
paring them to the two reference contact maps and to their union
using the plotTPrates tool described earlier. The precision curves for
the three cases (ATP, ADP, and Union) show that a sizeable fraction
of the predictions pertain exclusively to one conformation (Fig. 4).
Indeed, among the ﬁrst N ¼ 599 predictions, approximately 5% are
present only in one of either conformation. By visualizing the
highest ranked predictions on the contact maps, we can clearly
identify the regions involving the domains undergoing large-scale
rearrangements between the two states (Fig. 5).
We here took advantage of the availability of experimental
structures for the two conformations of Hsp70, but how would
one proceed in a blind scenario? If one structural state is known, the
partial agreement of the coevolutionary predictions can be assessed
to identify predicted contacts pertaining to an alternative confor-
mational state. As seen in Figs. 1 and 5, false-positive predictions
are typically of two types: in the ﬁrst case, false-positive predictions
are found in close proximity to native contacts, which generally
indicates a truly underlying coevolution ranging beyond the spatial
scale used to deﬁne structural contacts. Alternatively, false predic-
tions can be located at isolated spots in the contact maps (Fig. 5, left
Fig. 4 Precision curves for the Hsp70 family, computed with ATP (Red), ADP
(Green), or Union (blue) contact maps at 8.5 A˚
392
Duccio Malinverni and Alessandro Barducci

and right panels), which can be indicative of an alternative struc-
tural state encoded in the sequence covariation. To quantify the
proximity of predicted contacts to the experimental contact maps,
we introduced in Fantini et al. and Malinverni et al. [15, 51]
introduced the use of the shortest-path (SP) measure. In this
context, the SP of a prediction corresponds to the minimal number
of structural contacts that must be taken in account to connect the
coevolving residues. Thus, predictions with high SP measures are
potentially indicative of alternative conformational states as illu-
strated by the Hsp70 analysis, while predictions with low SP usually
correspond to native (SP ¼ 1) or pseudo-native contacts as previ-
ously discussed for the Hsp40 family.
5
Notes
1. Pfam
versus
manually
constructed
MSAs.
The
multiple-
sequence alignments available in the PFAM database are gen-
erally an excellent starting point for performing coevolutionary
analysis. However, it has been shown that manually building
and curating input MSAs can signiﬁcantly improve the predic-
tion quality [35]. Particularly, the manual construction of
MSAs allows the query of the latest releases of protein sequence
databases, as well as a higher control of the taxonomic distribu-
tion of the included sequences. Particularly, when manually
querying a sequence database, the user has the control over
the inclusion thresholds used (typically E-values). These allow
the ﬁne tuning of the balance between the number of
sequences included in the MSA and the remoteness of the
homology of the retrieved sequences.
2. Gapped regions. Highly gapped regions in the MSAs result in
strong local couplings between positions inside such regions.
Fig. 5 Structural contact maps overlaid with 599 highest ranked DCA contacts, computed with the ATP (PDB ID
4JNE) and ADP (PDB ID 2KHO) structures, and their union. Gray background: PDB contact (8.5 A˚ threshold).
Green: Correct DCA predictions. Red: False DCA predictions
Coevolutionary Analysis for Molecular Modeling
393

Such regions are often located at the N- and C-termini of the
alignments, a consequence of the gap-scoring scheme used by
multiple-sequence alignment algorithms. Most DCA packages
include a correction to downweigh the importance of gaps in
the contact predictions [35], which consists in ignoring the
couplings involving the gap symbol when taking the Frobenius
norm DCA score. While this correction partially removes the
gap-induced false-positives predictions, one should always
closely inspect strong predictions located in highly gapped
regions to assess whether these are residual couplings due to
the presence of gaps.
3. Choice of DCA inference method. Different ﬂavors of DCA
methods and software packages are available, which mainly
differ by the inference method used to (approximately) learn
the Potts model parameters. In practice, the choice of an
inference method strongly depends on the objective of the
study. For pure residue contact predictions, pseudo-likelihood-
based methods are recommended, as these have been shown to
have the highest contact prediction quality [4, 23]. If DCA
must be performed on extremely large datasets or on a very
large number of MSAs with slightly less stringent requirement
on the prediction quality, Mean-Field-based methods are sug-
gested, as these have the highest numerical efﬁciency and gen-
erally produce the fastest codes [14]. Finally, if the precise
parameters of the Potts model are required, and particularly
in the case where one is interested in using DCA as a generative
model, inference methods of higher accuracy are required.
Both the Boltzmann machine learning [18, 31] and cluster-
expansion methods [30] are designed to produce high-quality
generative models, at the cost of highly increased computa-
tional burden.
4. Structural contact deﬁnition. The deﬁnition of structural con-
tacts in coevolutionary analysis is generally taken to be rather
generous compared to crystallographic standards. This is
justiﬁed, as it has been shown that coevolving residue pairs
capture
interactions
beyond
purely
structural
contacts
[14, 60]. Particularly a secondary peak in distance distribution
of DCA-predicted contacts at around 7–8 A˚ justiﬁes the use of
a contact threshold deﬁnition of typically 8–8.5 A˚ .
Acknowledgements
The authors thank Paolo De Los Rios, Faruck Morcos, Elijah
Irvine, Re´my Bailly and Camille Elleaume for their critical reading
of this manuscript. Duccio Malinverni acknowledges the support of
394
Duccio Malinverni and Alessandro Barducci

the National Science foundation under grants 2012_149278 and
20020_163042/1. Alessandro Barducci acknowledges the support
of the Agence Nationale de Recherche (ANR) under grant ANR-
14-ACHN-0016.
References
1. Weigt M, White RA, Szurmant H et al (2009)
Identiﬁcation of direct residue contacts in
protein-protein interaction by message passing.
Proc Natl Acad Sci U S A 106:67–72. https://
doi.org/10.1073/pnas.0805923106
2. Jones DT, DW a B, Cozzetto D, Pontil M
(2012) PSICOV: precise structural contact
prediction using sparse inverse covariance esti-
mation on large multiple sequence alignments.
Bioinformatics 28:184–190. https://doi.org/
10.1093/bioinformatics/btr638
3. Marks DS, Colwell LJ, Sheridan R et al (2011)
Protein 3D structure computed from evolu-
tionary
sequence
variation.
PLoS
One
6.
https://doi.org/10.1371/journal.pone.
0028766
4. Balakrishnan S, Kamisetty H, Carbonell JG
et al (2011) Learning generative models for
protein fold families. Proteins 79:1061–1078.
https://doi.org/10.1002/prot.22934
5. Morcos F, Hwa T, Onuchic JN, Weigt M
(2014) Direct coupling analysis for protein
contact prediction. In: Kihara D (ed) Protein
structure prediction. Springer, New York, NY,
pp 55–70
6. Sułkowska JI, Morcos F, Weigt M et al (2012)
Genomics-aided
structure
prediction.
Proc
Natl Acad Sci U S A 109:10340–10345.
https://doi.org/10.1073/pnas.1207864109
7. Hopf TA, Colwell LJ, Sheridan R et al (2012)
Three-dimensional structures of membrane
proteins
from
genomic
sequencing.
Cell
149:1607–1621. https://doi.org/10.1016/j.
cell.2012.04.012
8. T a H, Morinaga S, Ihara S et al (2015) Amino
acid coevolution revealrs three-dimensional
structure and functional domains of insect
odorant
receptors.
Nat
Commun
6:1–7.
https://doi.org/10.1038/ncomms7077
9. Ovchinnikov S, Kamisetty H, Baker D (2014)
Robust and accurate prediction of residue-
residue interactions across protein interfaces
using
evolutionary
information.
elife
3:
e02030.
https://doi.org/10.7554/eLife.
02030
10. Hopf TA, Sch€arfe CPI, Rodrigues JPGLM et al
(2014) Sequence co-evolution gives 3D con-
tacts and structures of protein complexes. elife
3:e03430
11. Malinverni D, Jost Lopez A, De Los Rios P
et al (2017) Modeling Hsp70/Hsp40 interac-
tion by multi-scale molecular simulations and
co-evolutionary
sequence
analysis.
elife
6:
e23471.
https://doi.org/10.7554/eLife.
23471
12. Szurmant H, Weigt M (2017) Inter-residue,
inter-protein
and
inter-family
coevolution:
bridging the scales. Curr Opin Struct Biol
50:26–32.
https://doi.org/10.1016/j.sbi.
2017.10.014
13. Uguzzoni G, John Lovis S, Oteri F et al (2017)
Large-scale identiﬁcation of coevolution sig-
nals across homo-oligomeric protein interfaces
by direct coupling analysis. Proc Natl Acad Sci
114:E2662–E2671.
https://doi.org/10.
1073/pnas.1615068114
14. Morcos F, Pagnani A, Lunt B et al (2011)
Direct-coupling analysis of residue coevolution
captures native contacts across many protein
families. Proc Natl Acad Sci U S A 108:
E1293–E1301.
https://doi.org/10.1073/
pnas.1111471108
15. Fantini M, Malinverni D, De Los Rios P, Pas-
tore A (2017) New techniques for ancient pro-
teins:
direct
coupling
analysis
applied
on
proteins involved in iron sulfur cluster biogen-
esis. Front Mol Biosci 4:1–14. https://doi.
org/10.3389/fmolb.2017.00040
16. Morcos F, Jana B, Hwa T, Onuchic JN (2013)
Coevolutionary signals across protein lineages
help capture multiple protein conformations.
Proc Natl Acad Sci U S A 110:20533–20538.
https://doi.org/10.1073/pnas.1315625110
17. Parisi G, Zea DJ, Monzon AM, Marino-Buslje
C (2015) Conformational diversity and the
emergence of sequence signatures during evo-
lution. Curr Opin Struct Biol 32:58–65.
https://doi.org/10.1016/j.sbi.2015.02.005
18. Sutto L, Marsili S, Valencia A, Gervasio FL
(2015) From residue coevolution to protein
conformational
ensembles
and
functional
dynamics.
Proc
Natl
Acad
Sci
112:13567–13572.
https://doi.org/10.
1073/pnas.1508584112
19. Go¨bel U, Sander C, Schneider R, Valencia A
(1994) Correlated mutations and residue con-
tacts in proteins. Proteins Struct Funct Genet
18:309–317
Coevolutionary Analysis for Molecular Modeling
395

20. Lapedes AS, Giraud BG, Liu L, Stormo GD
(1999) Correlated mutations in models of pro-
tein sequences: phylogenetic and structural
effects. Lect Notes Monogr Ser 33:236–256.
https://doi.org/10.2307/4356049
21. Martin LC, Gloor GB, Dunn SD, Wahl LM
(2005) Using information theory to search
for co-evolving residues in proteins. Bioinfor-
matics
21:4116–4124.
https://doi.org/10.
1093/bioinformatics/bti671
22. Burger L, Van Nimwegen E (2010) Disentan-
gling direct from indirect co-evolution of resi-
dues in protein alignments. PLoS Comput Biol
6.
https://doi.org/10.1371/journal.pcbi.
1000633
23. Ekeberg M, Lo¨vkvist C, Lan Y et al (2013)
Improved
contact
prediction
in
proteins:
using pseudolikelihoods to infer Potts models.
Phys Rev E 87:0127071–0127016. https://
doi.org/10.1103/PhysRevE.87.012707
24. Cocco S, Feinauer C, Figliuzzi M et al (2017)
Inverse statistical physics of protein sequences:
a
key
issues
review.
Rep
Prog
Phys
81
(3):032601
25. Jaynes ET (1957) Information theory and sta-
tistical mechanics. Phys Rev 106:620–630
26. Dunn SD, Wahl LM, Gloor GB (2008) Mutual
information without the inﬂuence of phylog-
eny or entropy dramatically improves residue
contact
prediction.
Bioinformatics
24:333–340. https://doi.org/10.1093/bioin
formatics/btm604
27. Kaja´n L, Hopf TA, Kalasˇ M et al (2014) Free-
Contact: fast and free software for protein con-
tact prediction from residue co-evolution.
BMC
Bioinformatics
15:1–6.
https://doi.
org/10.1186/1471-2105-15-85
28. Baldassi C, Zamparo M, Feinauer C et al
(2014) Fast and accurate multivariate Gaussian
modeling of protein families: predicting resi-
due contacts and protein-interaction partners.
PLoS One 9:1–12. https://doi.org/10.1371/
journal.pone.0092721
29. Seemayer S, Gruber M, So¨ding J (2014)
CCMpred – fast and precise prediction of pro-
tein residue-residue contacts from correlated
mutations. Bioinformatics. https://doi.org/
10.1093/bioinformatics/btu500
30. Barton JP, De Leonardis E, Coucke A, Cocco S
(2016) ACE: adaptive cluster expansion for
maximum entropy graphical model inference.
Bioinformatics
32:3089–3097.
https://doi.
org/10.1093/bioinformatics/btw328
31. Figliuzzi
M,
Barrat-Charlaix
P,
Weigt
M
(2018) How pairwise coevolutionary models
capture the collective residue variability in
proteins. Mol Biol Evol:1–17. https://doi.
org/10.1093/molbev/msy007
32. Ekeberg M, Hartonen T, Aurell E (2014) Fast
pseudolikelihood
maximization
for
direct-
coupling analysis of protein structure from
many homologous amino-acid sequences. J
Comput Phys 276:341–356. https://doi.org/
10.1016/j.jcp.2014.07.024
33. Gueudre´ T, Baldassi C, Zamparo M et al
(2016) Simultaneous identiﬁcation of speciﬁ-
cally interacting paralogs and inter-protein
contacts by direct-coupling analysis. Proc Natl
Acad Sci 113:12186–12191. https://doi.org/
10.1073/pnas.1607570113
34. Bitbol A-F, Dwyer RS, Colwell LJ, Wingreen
NS (2016) Inferring interaction partners from
protein
sequences.
Proc
Natl
Acad
Sci
113:12180–12185.
https://doi.org/10.
1101/050732
35. Feinauer C, Skwark MJ, Pagnani A, Aurell E
(2014) Improving contact prediction along
three dimensions. PLoS Comput Biol 10:
e1003847. https://doi.org/10.1371/journal.
pcbi.1003847
36. Skwark MJ, Raimondi D, Michel M, Elofsson
A (2014) Improved contact predictions using
the recognition of protein like contact patterns.
PLoS Comput Biol 10:e1003889. https://doi.
org/10.1371/journal.pcbi.1003889
37. Michel M, Skwark MJ, Mene´ndez Hurtado D
et al (2017) Predicting accurate contacts in
thousands of Pfam domain families using
PconsC3.
Bioinformatics
33:2859–2866.
https://doi.org/10.1093/bioinformatics/
btx332
38. Ovchinnikov S, Park H, Varghese N et al
(2017) Protein structure determination using
metagenome
sequence
data.
Science
(80)
355:294–298.
https://doi.org/10.
1126/science.aah4043
39. Kim DE, Dimaio F, Yu-Ruei Wang R et al
(2014) One contact for every twelve residues
allows robust and accurate topology-level pro-
tein structure modeling. Proteins 82(Suppl
2):208–218.
https://doi.org/10.1002/prot.
24374
40. Brunger AT (2007) Version 1.2 of the crystal-
lography
and
NMR
system.
Nat
Protoc
2:2728–2733.
https://doi.org/10.1038/
nprot.2007.406
41. Dominguez C, Boelens R, Bonvin AMJJ
(2003) HADDOCK: a proteinprotein dock-
ing approach based on biochemical or biophys-
ical
information.
J
Am
Chem
Soc
125:1731–1737.
https://doi.org/10.1021/
ja026939x
396
Duccio Malinverni and Alessandro Barducci

42. Sirovetz BJ, Schafer NP, Wolynes PG Protein
structure
prediction:
making
AWSEM
AWSEM-ER by adding evolutionary restraints.
Proteins 85:2127–2142. https://doi.org/10.
1002/prot.25367
43. Davtyan A, Schafer NP, Zheng W et al (2012)
AWSEM-MD:
protein structure
prediction
using coarse-grained physical potentials and
bioinformatically based local structure biasing.
J Phys Chem B 116:8494–8503. https://doi.
org/10.1021/jp212541y
44. Noel JK, Whitford PC, Sanbonmatsu KY,
Onuchic JN (2010) SMOG@ctbp: simpliﬁed
deployment
of
structure-based
models
in
GROMACS.
Nucleic
Acids
Res
38:
W657–W661.
https://doi.org/10.1093/
nar/gkq498
45. Noel JK, Levi M, Raghunathan M et al (2016)
SMOG 2: a versatile software package for gen-
erating structure-based models. PLoS Comput
Biol 12:e1004794. https://doi.org/10.1371/
journal.pcbi.1004794
46. Kamisetty H, Ovchinnikow S, Baker D (2013)
Assessing the utility of coevolution-based resi-
due-residue contact predictions in a sequence-
and structure-rich era. Proc Natl Acad Sci
110:15674–15679.
https://doi.org/10.
1073/pnas.1319550110
47. Morcos F, Schafer NP, Cheng RR et al (2014)
Coevolutionary information, protein folding
landscapes, and the thermodynamics of natural
selection.
Proc
Natl
Acad
Sci
111:12408–12413.
https://doi.org/10.
1073/pnas.1413575111
48. Toth-Petroczy A, Palmedo P, Ingraham J et al
(2016) Structured states of disordered proteins
from genomic sequences. Cell 167:158–170.
e12.
https://doi.org/10.1016/j.cell.2016.
09.010
49. Feinauer C, Szurmant H, Weigt M, Pagnani A
(2016) Inter-protein sequence co-evolution
predicts known physical interactions in bacte-
rial ribosomes and the Trp operon. PLoS One
11:e0149166. https://doi.org/10.1371/jour
nal.pone.0149166
50. Bitbol A-F, Dwyer RS, Colwell LJ, Wingreen
NS (2016) Inferring interaction partners from
protein sequences. bioRxiv 2016, 050732.
https://doi.org/10.1101/050732
51. Malinverni D, Marsili S, Barducci A, De Los
Rios P (2015) Large-scale conformational
transitions and dimerization are encoded in
the amino-acid sequences of Hsp70 chaper-
ones.
PLoS
Comput
Biol
11:e1004262.
https://doi.org/10.1371/journal.pcbi.
1004262
52. Schug A, Weigt M, Onuchic JN et al (2009)
High-resolution protein complexes from inte-
grating genomic information with molecular
simulation.
Proc
Natl
Acad
Sci
U
S
A
106:22124–22129.
https://doi.org/10.
1073/pnas.0912100106
53. dos Santos RN, Khan S, Morcos F (2018)
Characterization of C-ring component assem-
bly in ﬂagellar motors from amino acid coevo-
lution. R Soc Open Sci 5. https://doi.org/10.
1098/rsos.171854
54. Pandini A, Morcos F, Khan S (2016) The gear-
box of the bacterial ﬂagellar motor switch.
Structure
24:1209–1220.
https://doi.org/
10.1016/j.str.2016.05.012
55. Sfriso P, Duran-Frigola M, Mosca R et al
(2016) Residues coevolution guides the sys-
tematic identiﬁcation of alternative functional
conformations
in
proteins.
Structure
24:116–126.
https://doi.org/10.1016/j.str.
2015.10.025
56. Shamsi Z, Moffett AS, Shukla D (2017)
Enhanced
unbiased
sampling
of
protein
dynamics using evolutionary coupling informa-
tion. Sci Rep 7:1–13. https://doi.org/10.
1038/s41598-017-12874-7
57. Feng J, Shukla D (2018) Characterizing con-
formational dynamics of proteins using evolu-
tionary
couplings.
J
Phys
Chem
B
122:1017–1025.
https://doi.org/10.1021/
acs.jpcb.7b07529
58. Finn
RD,
Clements
J,
Eddy
SR
(2011)
HMMER web server: interactive sequence sim-
ilarity searching. Nucleic Acids Res 39:29–37.
https://doi.org/10.1093/nar/gkr367
59. Finn RD, Mistry J, Tate J et al (2010) The
Pfam protein families database. Nucleic Acids
Res
38:D211–D222.
https://doi.org/10.
1093/nar/gkp985
60. Anishchenko I, Ovchinnikov S, Kamisetty H,
Baker
D
(2017)
Origins
of
coevolution
between residues distant in protein 3D struc-
tures. Proc Natl Acad Sci 114:9122–9127.
https://doi.org/10.1073/pnas.1702664114
Coevolutionary Analysis for Molecular Modeling
397

Chapter 17
Coarse Graining of a Giant Molecular System: The
Chromatin Fiber
Guido Tiana and Luca Giorgetti
Abstract
The chromatin ﬁber is a complex polymer whose conformational properties are quite important to regulate
gene transcription. One cannot but resort to coarse-grained models to describe the structure and the
dynamics of this system on the length scale of the cellular nucleus. Bulk biological data can be used within
the framework of the principle of maximum entropy to generate a realistic interaction potential that can be
used to sample the equilibrium state of the ﬁber. The analysis of the structure and of the dynamics of the
ﬁber can be correlated with its biological function, thus providing interesting results about transcriptional
regulation.
Key words Chromosome structure, Principle of maximum entropy, Coarse-grained models
1
Introduction
Among the several kinds of biopolymers that occur in living cells,
chromatin has a fundamental place. Besides allowing to efﬁciently
compact meters of linear DNA to ﬁt into the micron-sized cell
nucleus, its spatial arrangement within chromosomes contributes
to the control of gene expression, and aberrant misfolding caused
by genomic mutations are associated with diseases [1].
The chromatin ﬁber is composed by the DNA double helix
wrapped around protein octameric complexes called nucleosome
ﬁber (see Fig. 1a, b). The internal structure of the ﬁber as well as its
degree of variation throughout the genome in time are a matter of
debate. While in vitro data support the existence of a ﬁber with a
diameter of 30 nm [2], recent electron microscopy measurements
in vivo report a diameter varying between 5 and 24 nm [3]. The
persistence length of the chromatin ﬁber is approximately 200 nm
in yeast [4], whereas no consensus exists for higher organisms. In
eukaryotes, the genome is divided into a set of disjoint chromo-
somes; in diploid organisms such as humans, each cell nucleus
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_17, © Springer Science+Business Media, LLC, part of Springer Nature 2019
399

contains a number of chromatin polymers equal to twice the num-
ber of chromosomes, each extending hundreds of billion base pairs.
Fluorescence in situ hybridization (FISH) experiments, in
which the DNA within chromosomes is directly visualized under
the microscope, indicate that the chromatin ﬁber is folded in a
globular state that densely ﬁlls the nucleus (see Fig. 1c). Chromo-
somes are only marginally intertwined with each other, each occu-
pying a rather well-deﬁned region called its chromosomal territory
[5]. Evidence deriving from experiments and theoretical investiga-
tion, discussed later, support the idea that the three-dimensional
folding of the ﬁber is not entirely random within a chromosome,
but rather ﬂuctuates among conformations that display well-
deﬁned properties. Under this light, the behavior of chromosomes
in vivo might be described as lying between that of a structured
protein and that of an unstructured polymer.
The conformational properties of chromosomes are strictly
connected with the control of the transcriptional activity of the
genes they harbor. One mechanism that couples chromosome con-
formation to gene expression involves the interactions of genes
with genomic control regions called transcriptional enhancers.
Fig. 1 The DNA double helix (a), wrapping around histones (b) forms a ﬁber that,
during interphase, is collapsed into a globule that occupies the whole cellular
nucleus (c). Although the exact mechanism is not yet clariﬁed, the interaction
between different chromatin loci is mediated by DNA-bound protein complexes
(d). An effect of the spatial approach of loci which are far along the ﬁber is often
to put genes in contact with enhancers that are genetic elements which
contribute to transcriptional activation
400
Guido Tiana and Luca Giorgetti

Enhancers are DNA sequences located up to hundreds of kilobases
(kb) away from the genes that they control, which are thought to
activate their transcription via three-dimensional interactions with
their promoter regions (see Fig. 1d). Since chromosome structure
modulates the spatial distances between genes and enhancers, it is
thought to contribute to transcriptional control [6].
The conformational properties of chromosomes in the nucleus
have therefore become a matter of intense experimental and theo-
retical investigation. However, chromosomes present several dis-
tinct layers of complication compared to other biopolymers such as
proteins and RNA. From the experimental point of view, a substan-
tial limitation comes from the necessity of studying its conforma-
tional properties in vivo, since many factors that contribute to
determine its structure cannot be reproduced in a test tube, such
as the interactions with the nuclear lamina and the potentially large
number
of
proteins
that
interact
with
DNA
and
mediate
interactions.
On the modeling side, several problems arise with respect to
small biomolecules. The ﬁrst (and the most obvious) is the size of
the system. Mammalian chromosomes are hundreds of billions of
base pairs long, which amounts to ~1012 atoms including nucleo-
somes, and even excluding the surrounding water, ions, and pro-
teins that are present in the dense nuclear environment. Although
atomistic or multi-scale approaches have been attempted to
describe small fragments of chromatin [7, 8], studying it at the
scale of 1 Mb inevitably requires coarse-grained models.
Another problem resides in our limited understanding of the
molecular nature of the interactions along the chromatin ﬁber.
While in the case of proteins and “naked” nucleic acids it is clear
that their equilibrium states are stabilized by hydrogen bonds, van
der Waals forces and so on, and realistic parametrizations of these
interactions are available, nothing similar applies to chromosomes.
Accumulated evidence suggests that site-speciﬁc interactions are
mediated by DNA-bound proteins. For example, reductions in
the levels of the CCCTC-binding factor (CTCF, [9, 10]) or cohe-
sin [11, 12], substantially affect chromosome structure at the Mb
scale. However, their detailed mechanism of action remains poorly
understood. Models that explain site-speciﬁc interaction between
CTCF-bound sites have been developed assuming direct interac-
tions between chromatin-bound proteins [13–17], or hypothesiz-
ing that their interactions are mediated by other proteins diffusing
through the nucleus [18–22], or positing the presence of loop-
extrusion [23] molecules (potentially, cohesin itself) which depends
on adenosine triphosphate (ATP) [24], or moves according to a
ratcheting mechanism [25]. In other approaches, the main effect of
chromatin-bound molecules is regarded as inducing supercoiling of
the ﬁber [26, 27]. All these models can reproduce some of the
Modeling The Chromatin Fiber
401

experimental data available, but no smoking-gun evidence exists to
select any of them.
A further question that is difﬁcult to answer is whether chro-
mosomes can be modeled as systems at thermodynamic equilib-
rium. Cells divide, and the relevant timescale when studying
chromosome folding is the cell-cycle duration, which for mammals
is of the order of tens of hours. Whole chromosomes are so long
that equilibration times could largely exceed the duration of one
cell cycle [28]. However, when considering small portion of chro-
mosome (below the Mb, where enhancer-promoter interactions
occur) relaxation time can be expected to be shorter. Live-cell
tracking of single chromosomal loci using time-lapse ﬂuorescence
microscopy suggests that within single domains, the motion of the
chromatin ﬁber at sub-Mb scale is subdiffusive, and conformational
changes might take place on the timescale of minutes, enough to
guarantee equilibration at these length scales [29].
2
A Maximum-Entropy Approach for Coarse Graining
In the absence of a force ﬁeld similar to that used for smaller
biomolecules and of a clear understanding of the molecular mecha-
nism of intra-chromosome interactions, one cannot but build a
potential function for coarse-grained models of chromatin based
on the available data. The theoretical framework for doing this is
provided by the principle of maximum entropy [30] and has been
recently applied to the correction of available force ﬁelds for several
molecular systems, such as proteins and RNA [31–35].
The basic hypotheses are that the available experimental data
are ensemble averages of some conformational property fk(r), called
“forward model,” and that the conformations of the systems are at
equilibrium, and thus they are distributed according to Boltzmann
statistics. If this is the case, one can look for the conformational
probability distribution p(r), which agrees with the experimental
data and, at the same time, introduces as little further arbitrary
information as possible. This can be done maximizing the Shannon
entropy of the distribution S p½  ¼  P
r
p r
ð Þlogp r
ð Þ with the con-
strains
f k r
ð Þ


¼ f exp
k
, where the angular brackets indicate the
thermal average, and f exp
k
is the set of measured experimental
data. The constrained maximization of the entropy gives
p r
ð Þ ¼ 1
Z exp 
X
k
λkf k r
ð Þ
"
#
,
ð1Þ
where λk represents the Lagrange multipliers deﬁned by
∂logZ
∂λk
¼ f exp
k
:
ð2Þ
402
Guido Tiana and Luca Giorgetti

If the system is in equilibrium, Eq. 1 must be equal to the
Boltzmann distribution p(r) ¼ exp [U(r)/kT]/Z, giving
U r
ð Þ ¼ kT
X
k
λkf k r
ð Þ:
ð3Þ
This means that the principle of maximum entropy suggests
that the fairest choice for the potential based on the data f exp
k
is that
which has the same functional form of the forward model. While, in
principle, Eq. 2 can be used to ﬁnd the numerical parameters that
fully deﬁne potential, this is difﬁcult to use in practice because it
depends on the partition function Z, which is a sum over all the
conformations. Different approaches were developed to solve this
problem [34, 36].
It is worth noticing that in the case of small biomolecules, one
can start from an a priori knowledge of the system, provided by the
conformational distribution p0(r) ¼ exp [U0(r)/kT]/Z obtained
from molecular, portable force ﬁelds U0(r). An approach analogous
to that of maximizing the entropy consists in minimizing the
Kullback-Leibler divergence between p(r) and p0(r), which results
in the correction U r
ð Þ ¼ U 0 r
ð Þ  kT P
k
λkf k r
ð Þ. However, in the
present case of chromatin modeling, we have not this kind of a
priori information.
3
The Available Experimental Data
Large amounts of information on how chromosomes are folded at
the Mb scale in vivo have been obtained using a powerful set of
experimental techniques collectively known as Chromosome Con-
formation Capture (3C), where chromatin is cross-linked using
formaldehyde in a sample of ~106 cells, thus “freezing” the confor-
mation in every cell (see Fig. 2a). DNA is then digested with a
restriction enzyme, high-throughput sequenced, and the sequence
of each pair of fragments compared with the known genomic
sequence [37]. The result of 3C experiments, and in particular of
experimental variants known as 5C [38] and Hi-C [39], is a matrix
(see Fig. 2b) whose elements are proportional to the contact proba-
bility (see Note 1) between pairs of chromosome regions ranging
typically between 3 and 20 kb (corresponding to linear scales of
approximately 50 and 300 nm, respectively). An exact deﬁnition of
“contact” in this context is missing; it is reasonable to assume that
genomic sequences become cross-linked through protein bridges,
extending for hundreds of nanometers [40].
Matrices obtained for mammalian chromosomes [41, 42] in
interphase, display well-deﬁned patterns of high-probability con-
tact regions, that clearly deviate from what is expected in a random
polymer. Hierarchies of nested interaction domains can be clearly
detected (see Fig. 2b), from small contact domains spanning few
Modeling The Chromatin Fiber
403

hundred kilobases to large multi-Mb compartments. A speciﬁc level
within this hierarchy, originally named topologically associating
domains (TADs) [41–43], has been shown to be optimally corre-
lated with functional properties, such as the transcriptional
co-regulation of genes within one domain [44].
Additional experimental information can be obtained with
DNA ﬂuorescence in situ hybridization (DNA FISH), in which
ﬂuorescent DNA probes can be hybridized to selected chromo-
somal locations and observed in high-resolution microscopy
experiments. An advantage of DNA FISH with respect to 3C
techniques is that it can measure distributions of distances between
speciﬁc sites rather than population-averaged contact probabilities.
Its main drawback is that it is not a high-throughput technique, and
the distribution of only few pairwise distances can be measured in
one experiment. Typical results obtained from DNA FISH for
distances between sites belonging to the same TAD display unim-
odal distributions with a large width [45], indicating that confor-
mational ﬂuctuations play a major role in the thermodynamics of
the ﬁber.
4
Building the Coarse-Grained Model
In our coarse-grained description, the ﬁber is represented as an
inextensible chain of beads (see Fig. 3a). As a rule, we model one,
or few TADs at a time, under the assumption that their
Fig. 2 Techniques based on 3C follow a scheme (a) according to which a large number of nuclei are treated
with formaldehyde, which cross-links loci that are in contact at that very moment; the ﬁber is then digested by
enzymes and the two loci are ligated together and sequenced. Comparing their sequence with that (known) of
the whole genome, it is possible to obtain the genomic coordinates of the two loci. Counting the cross-linked
pairs, one obtains a matrix (b) whose elements are proportional to the contact probabilities between the
corresponding loci. Typical matrices display a nested hierarchy of blocks (dashed lines), corresponding to
domains of the ﬁber
404
Guido Tiana and Luca Giorgetti

conformation is only weakly dependent on that of the other, sur-
rounding TADs. Each bead of the model represents a segment of
the ﬁber of size equal to the resolution of the experimental data,
typically from 3 to 20 kb (see Note 2).
Since the normalized data p exp
ij
obtained by 5C/Hi-C experi-
ments reﬂect the contacts between chromosomal regions, follow-
ing the requirements of the principle of maximum entropy, we
deﬁne a potential which is the sum of contact functions between
all the beads of the model (cf. Fig. 3b). The calculation of the
numerical parameters that is the Lagrange multipliers which act as
contact energies Bij by means of Eq. 2 is unfeasible, due to the
difﬁculty to calculate the partition function. Consequently, for this
purpose,
we
shall
resort
to
an
iterative
Monte
Carlo
(MC) algorithm (see Fig. 4).
Starting from a rough approximation of the contact energies
Bij ¼ log
p exp
ij
1  p exp
ij
 3
2 log i  j
j
j,
ð4Þ
corresponding to independent contact formations in a chain whose
looping entropy is approximated as that of an ideal, chain, a
Metropolis Monte Carlo (MC) sampling is carried out. The typical
elementary moves of the MC algorithm are ﬂips and pivot moves.
From the sampling, we collect ~5000 uncorrelated conformations
of the chain (see Note 3).
At the end of the MC simulation, we perform a random mini-
mization of the χ2 between the experimental contact probabilities
p exp
ij
and those back-calculated from the simulation. At each step of
the minimization, we vary an energy Bij at random of a random
quantity, and we change the statistical weight of the conformations
recorded in the MC sampling according to the scheme developed in
ref. 36, that is, the weight of each conformation {ri} after the
change Bij ! B0ij becomes
Fig. 3 The coarse-grained model used to simulate the chromatin ﬁber is a chain
of beads linked by an inextensible chain (a). The inter-bead potential is a
spherical well with hard-core radius RHC, range R, and the bottom of the well
has a pair-dependent energy Bij (b)
Modeling The Chromatin Fiber
405

p0
ri
f g
ð
Þ ¼ Z
Z 0 exp
B0
ij þ Bij


Δ jri  r jj


h
i
p
ri
f g
ð
Þ,
ð5Þ
where Δ(| ri  rj| ) is a contact function which assumes the value
1 if residues i and j are in contact, and zero otherwise, and the new
partition function is
Z 0 ¼
X
ri
f
g
exp
B0
ij þ Bij


Δ jri  r jj


h
i
:
ð6Þ
Since the function to be minimized is convex, the minimization
is rather straightforward. The problems arise because of the ﬁnite
sampling: when Bij has become quite different from that used for
the MC sampling, the recorded conformations can become statisti-
cally irrelevant for the new potential, and a new sampling is neces-
sary.
The
procedure
is
then
repeated
iteratively
until
the
χ2 converges to low values (see Note 4).
initial choice of Bij
Monte Carlo sampling
minimization of x2
by reweighting
analyse chain conformations
is x2 at convergence?
sampled
conformations
no
yes
Fig. 4 The algorithm implemented to obtain the set of interaction energies Bij that
match the principle of maximum entropy and the experimental data
406
Guido Tiana and Luca Giorgetti

A validation of this procedure was carried out by modeling two
TADs, namely the Tsix and the Xist domains of mouse embryonic
stem cells (mESC) [45]. After approximately 100 iterations, the
χ2 between the experimental and the calculated contact map con-
verged to a value of around 10, corresponding to the map displayed
in Fig. 5.
Different types of validations were possible for this system.
First, we compared the distribution of distances between seven
selected pairs of beads obtained from the simulation with the
analogous distribution obtained from FISH experiments, obtain-
ing a remarkable agreement [45]. Moreover, we compared the
effect of mutations on the system, in the case of both a large
deletion of 58 kb, corresponding to 20 beads in the model, and a
small deletion of 3 kb, corresponding to a single bead in the model.
The experimental data were compared to simulations obtained
deleting the corresponding beads of the chain (and the associated
rows and column in the interaction matrix) but leaving unaffected
the other elements of the interaction matrix. Also in this case, the
agreement was good [45].
5
Predictions of the Model
Besides reproducing data that were either present in the input 5C/
Hi-C matrix or that could be obtained with other experimental
techniques,
the
model
described
earlier
allows
to
access
Fig. 5 In the left panel, a comparison is made between the simulated contact map resulting from the
optimization of the interaction potential and the experimental 5C map of the system composed of the two
TADs—Tsix and Xist—of mouse embryonic stem cells. In the right panel is an example of the conformations
of the ﬁber
Modeling The Chromatin Fiber
407

conformational properties that cannot be observed experimentally.
The analysis of the ensembles of simulated conformations for the
TADs harboring the Xist and Tsix genes indicate that the ﬁber
ﬂuctuates
among
very
different
but
not
random
conformations [29].
The coarse-grained model described earlier is computationally
cheap and allowed where one can study all the ~2500 TADs in the
mouse genome [46]. On average, the root mean square gyration
radius s of the different TADs results to follow, as a function of their
genomic size N, the N1/2 law of ideal chains, as expected for
segments embedded in a larger globule by the Flory theorem.
However, there are detectable ﬂuctuations around this mean
behavior. The value of s correlates negatively with the mean expres-
sion level of the genes contained in each TAD, as measured by RNA
sequencing experiments. Vice versa, gene expression within TADs
positively correlates with their degree of spatial anisotropy.
While experimental 5C/Hi-C maps only give access to
two-body contact probabilities, the model can be used to infer
many-body contacts. We found that mouse embryonic stem cells
display a small number of co-localizing triplets [46], deﬁned as
triplets of loci that are mutually in contact with probability larger
than the contact probability of each pair. These triplets are enriched
in CTCF-bound loci, in triplets of promoters, and in triplets of two
promoters and one enhancer, suggesting that genomic locations
that interact functionally occasionally form hubs of interactions
such as in the case of the triplet Tsix/Chic1/Linx, whose
co-localization was experimentally conﬁrmed using DNA FISH
[45], as well as other highly transcribed cell-type speciﬁc genes.
The model can be used also to make predictions on the time
dynamics of the conformation of the ﬁber. Implementing only
small elementary moves, the MC algorithm can also be used to
simulate dynamic trajectories [47], whose timescale can be set
comparing the simulated diffusion coefﬁcient with that obtained
by time-resolved ﬂuorescence microscopy [29]. Simulated trajec-
tories indicate that conformational de-correlation follows a power
law as a function of time, suggesting the absence of large energy
barriers between conformational states. Moreover, the residence
time of conformational states is of the order of minutes, suggesting
that during a cell cycle (that is of ~16 h in mESC) the overall
structure, and its control over gene expression, takes place under
equilibrium conditions.
6
Notes
1. The 5C/Hi-C data must be properly normalized, so that they
can be interpreted as average of a contact function. This can be
done, for example, dividing the experimental counts by the
median of the co-diagonal elements.
408
Guido Tiana and Luca Giorgetti

2. The degree of coarse graining of the model, in terms of number
of DNA base pairs (bp) per polymer bead, should match the
resolution of the 5C/Hi-C map. To translate the number of bp
into a length, one could refer to the case of the Tsix TAD [45]
where the comparison with FISH data gives 3 kb is equal
to 53 nm. Moreover, the optimal values of the interaction
range and of the hard-core radius for that system are 80 and
32 nm, respectively. One can rescale this result obtained at 3 kb
resolution to models with arbitrary resolution n, assuming an
ideal-chain scaling, that is using interaction range
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
n=3 kb
p

80 nm and hard-core radius
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
n=3 kb
p
 32 nm.
3. In the iterative MC algorithm, a tricky choice is the number of
optimization steps of the parameters of the potential. A rule-of-
thumb strategy is to tune it to perform the largest amount of
iterations for which the initial χ2 of the new iteration is compa-
rable with the last value of the previous one. In fact, if too many
updates of the potentials are evaluated just by reweighting, the
sampled conformations are no longer representative of the new
potential, and this becomes apparent when a new sampling
with the new potential is carried out.
4. The whole optimization and sampling algorithms are imple-
mented in the code MonteGrappa that is freely available [48].
References
1. Bonev B, Cavalli G (2016) Organization and
function of the 3D genome. Nat Rev Genet
17:661–678
2. Robinson PJJ, Fairall L, Huynh VAT et al
(2006) EM measurements deﬁne the dimen-
sions of the “30-nm” chromatin ﬁber: evidence
for a compact, interdigitated structure. Proc
Natl Acad Sci U S A 103:6506–6511
3. Ou HD, Phan S, Deerinck TJ et al (2017)
ChromEMT: visualizing 3D chromatin struc-
ture and compaction in interphase and mitotic
cells. Science 357:eaag0025
4. Bystricky K, Heun P, Gehlen L et al (2004)
Long-range compaction and ﬂexibility of inter-
phase chromatin in budding yeast analyzed by
high-resolution imaging techniques. Proc Natl
Acad Sci U S A 101:16495–16500
5. Cremer T, Cremer C (2001) Chromosome
territories, nuclear architecture and gene regu-
lation in mammalian cells. Nat Rev Genet
2:292–301
6. Spitz F (2016) Gene regulation at a distance:
from remote enhancers to 3D regulatory
ensembles. Semin Cell Dev Biol 57:57–67
7. Ozer G, Luque A, Schlick T (2015) The chro-
matin
ﬁber:
multiscale
problems
and
approaches.
Curr
Opin
Struct
Biol
31:124–139
8. Dans PD, Walther J, Go´mez H et al (2016)
Multiscale simulation of DNA. Curr Opin
Struct Biol 37:29–45
9. Nora EP, Goloborodko A, Valton AL et al
(2017) Targeted degradation of CTCF decou-
ples local insulation of chromosome domains
from
genomic
compartmentalization.
Cell
169:930–944
10. Merkenschlager M, Nora EP (2016) CTCF
and cohesin in genome folding and transcrip-
tional gene regulation. Annu Rev Genomics
Hum Genet 17:17–43
11. Schwarzer W, Abdennur N, Goloborodko A
et al (2017) Two independent modes of chro-
matin
organization
revealed
by
cohesin
removal. Nature 152:1270
12. Rao S, Huang S-C, Hilaire BGS et al (2017)
Cohesin loss eliminates all loop domains, lead-
ing to links among superenhancers and down-
regulation of nearby genes. Cell 171:305–320
13. Jost D, Carrivain P, Cavalli G et al (2014)
Modeling epigenome folding: formation and
dynamics of topologically associated chromatin
domains. Nucleic Acids Res 42:9553–9561
Modeling The Chromatin Fiber
409

14. Di Stefano M, Rosa A, Belcastro V et al (2013)
Colocalization of coregulated genes: a steered
molecular dynamics study of human chromo-
some 19. PLoS Comput Biol 9:e1003019
15. Nazarov LI, Tamm MV, Avetisov VA et al
(2015)
A
statistical
model
of
intra-
chromosome
contact
maps.
Soft
Matter
11:1019–1025
16. Shukron O, Holcman D (2017) Transient
chromatin
properties revealed
by polymer
models and stochastic simulations constructed
from chromosomal capture data. PLoS Com-
put Biol 13:e1005469
17. Tark-Dame M, Jerabek H, Manders EMM et al
(2014) Depletion of the chromatin looping
proteins CTCF and cohesin causes chromatin
compaction: insight into chromatin folding by
polymer modelling. PLoS Comput Biol 10:
e1003877
18. Barbieri M, Chotalia M, Fraser J et al (2012)
Complexity of chromatin folding is captured by
the strings and binders switch model. Proc Natl
Acad Sci U S A 109:16173–16178
19. Johnson J, Brackley CA, Cook PR et al (2015)
A simple model for DNA bridging proteins and
bacterial or human genomes: bridging-induced
attraction and genome compaction. J Phys
Condens Matter 27:064119
20. Brackley CA, Johnson J, Kelly S et al (2016)
Simulated binding of transcription factors to
active and inactive regions folds human chro-
mosomes into loops, rosettes and topological
domains. Nucleic Acids Res 44:3503–3512
21. Marenduzzo D (2016) Predicting the three-
dimensional folding of cis-regulatory regions
in mammalian genomes using bioinformatic
data
and
polymer
models.
Genome
Biol
17:1–16
22. Barbieri M, Xie SQ, Torlai Triglia E et al
(2017) Active and poised promoter states
drive folding of the extended HoxB locus in
mouse embryonic stem cells. Nat Struct Mol
Biol 24:515–524
23. Fudenberg G, Imakaev M, Lu C et al (2016)
Formation of chromosomal domains by loop
extrusion. Cell Rep 15:2038–2049
24. Goloborodko A, Marko JF, Mirny LA (2016)
Chromosome compaction by active loop extru-
sion. Biophys J 110:2162–2168
25. Brackley CA, Johnson J, Michieletto D et al
(2017) Nonequilibrium chromosome looping
via
molecular
slip
links.
Phys
Rev
Lett
119:138101
26. Benedetti F, Dorier J, Burnier Y et al (2013)
Models that include supercoiling of topological
domains reproduce several known features of
interphase chromosomes. Nucleic Acids Res
42:2848–2855
27. Benedetti F, Racko D, Dorier J et al (2017)
Transcription-induced
supercoiling
explains
formation
of
self-interacting
chromatin
domains in S. pombe. Nucleic Acids Res
45:9850–9859
28. Rosa A, Everaers R (2008) Structure and
dynamics of interphase chromosomes. PLoS
Comput Biol 4:e1000153
29. Tiana G, Amitai A, Pollex T et al (2016) Struc-
tural ﬂuctuations of the chromatin ﬁber within
topologically associating domains. Biophys J
110:1234–1245
30. Jaynes ET (1957) Information theory and sta-
tistical mechanics. Phys Rev 106:620–630
31. Pitera JW, Chodera JD (2012) On the use of
experimental observations to bias simulated
ensembles.
J
Chem
Theory
Comput
8:3445–3451
32. Roux B, Weare J (2013) On the statistical
equivalence of restrained-ensemble simulations
with the maximum entropy method. J Chem
Phys 138:084107–084109
33. Cavalli A, Camilloni C, Vendruscolo M (2013)
Molecular dynamics simulations with replica-
averaged structural restraints generate struc-
tural ensembles according to the maximum
entropy principle. J Chem Phys 138:094112
34. White AD, Voth GA (2014) Efﬁcient and min-
imal method to bias molecular simulations with
experimental data. J Chem Theory Comput
10:3023–3030
35. Cesari A, Gil-Ley A, Bussi G (2016) Combin-
ing simulations and solution experiments as a
paradigm for RNA force ﬁeld reﬁnement. J
Chem Theory Comput 12:6192–6200
36. Norgaard AB, Ferkinghoff-Borg J, Lindorff-
Larsen K (2008) Experimental parameteriza-
tion of an energy function for the simulation
of unfolded proteins. Biophys J 94:182–192
37. Dekker J, Rippe K, Dekker M et al (2002)
Capturing chromosome conformation. Science
295:1306–1311
38. Dostie J, Richmond TA, Arnaout RA et al
(2006) Chromosome conformation capture
carbon copy (5C): a massively parallel solution
for mapping interactions between genomic ele-
ments. Genome Res 16:1299–1309
39. Lieberman-Aiden E, van Berkum NL, Williams
L et al (2009) Comprehensive mapping of
long-range interactions reveals folding princi-
ples
of
the
human
genome.
Science
326:289–293
40. Giorgetti L, Heard E (2016) Closing the loop:
3C versus DNA FISH. Genome Biol 17:215
410
Guido Tiana and Luca Giorgetti

41. Nora EP, Lajoie BR, Schulz EG et al (2012)
Spatial partitioning of the regulatory landscape
of
the
X-inactivation
centre.
Nature
485:381–385
42. Dixon JR, Selvaraj S, Yue F et al (2012) Topo-
logical domains in mammalian genomes iden-
tiﬁed by analysis of chromatin interactions.
Nature 485:376–380
43. Sexton T, Yaffe E, Kenigsberg E et al (2012)
Three-dimensional
folding
and
functional
organization
principles
of
the
Drosophila
genome. Cell 148:458–472
44. Zhan Y, Mariani L, Barozzi I et al (2017)
Reciprocal insulation analysis of Hi-C data
shows that TADs represent a fu nctionally but
not structurally privileged scale in the hierar-
chical folding of chromosomes. Genome Res
27:479–490
45. Giorgetti L, Galupa R, Nora EP et al (2014)
Predictive polymer modeling reveals coupled
ﬂuctuations
in
chromosome
conformation
and transcription. Cell 157:950–963
46. Zhan Y, Giorgetti L, Tiana G (2017) Model-
ling
genome-wide
topological
associating
domains in mouse embryonic stem cells. Chro-
mosom Res 25:5–14
47. Tiana G, Sutto L, Broglia RA (2007) Use of
the metropolis algorithm to simulate the
dynamics
of
protein
chains.
Physica
A
380:241–249
48. Tiana G, Villa F, Zhan Y et al (2014) Monte-
Grappa: an iterative Monte Carlo program to
optimize biomolecular potentials in simpliﬁed
models. Comput Phys Commun 186:93–104
Modeling The Chromatin Fiber
411

Part IV
Analyzing, Visualizing, and Comparing Biomolecular
Simulations

Chapter 18
Analyzing Biomolecular Ensembles
Matteo Lambrughi, Matteo Tiberti, Maria Francesca Allega,
Valentina Sora, Mads Nygaard, Agota Toth, Juan Salamanca Viloria,
Emmanuelle Bignon, and Elena Papaleo
Abstract
Several techniques are available to generate conformational ensembles of proteins and other biomolecules
either experimentally or computationally. These methods produce a large amount of data that need to be
analyzed to identify structure–dynamics–function relationship. In this chapter, we will cover different tools
to unveil the information hidden in conformational ensemble data and to guide toward the rationalization
of the data. We included routinely used approaches such as dimensionality reduction, as well as new
methods inspired by high-order statistics and graph theory.
Key words Biomolecules, Molecular dynamics, Conformational ensembles, High-order statistics,
Graph theory
1
Introduction
Structure–function relationship has been a central dogma in pro-
tein science over the last century. We witnessed a paradigm shift,
according to which the native state of biomolecules has to be
considered as a conformational ensemble of structures in exchange
over different time-scales [1–11]. We should thus describe a protein
as an ensemble of different conformations and not only the major
dominant conformational state, which is the one captured as “aver-
age” structure from experimental techniques such as X-ray crystal-
lography and NMR.
As biochemists, we used to infer properties related to function
by looking exclusively at the protein structure and a small subset of
relevant residues. We had to learn that proteins undergo changes of
different magnitudes and over a wide range of different time-scales,
contributing to “the protein dance” [12]. Some of these
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_18, © Springer Science+Business Media, LLC, part of Springer Nature 2019
Matteo Lambrughi and Matteo Tiberti contributed equally to this work.
415

conformational changes could be intimately linked to the biological
function of proteins.
Proteins can also be (de)stabilized by post-translational mod-
iﬁcations or disease-related mutations [11, 13, 14]. In this context,
cancer-related missense mutations in the coding region of cancer
genes are especially challenging to unravel at the structural and
dynamic level, due to their interplay with post-translational modiﬁ-
cation sites [15, 16] and the massive accumulation of somatic
mutations. Moreover, an extra layer of complexity comes from the
fact that only a small number of somatic cancer mutations are the
real cancer drivers, whereas a multitude of them are passenger
mutations with just mild or neutral effects [17].
In this context, the information contained in the experiments is
rarely sufﬁcient to deﬁne a unique set of structures. By combining
experimental data with data from the best physical models in simu-
lations, we can model protein states more accurately [3, 18]. Atom-
istic simulations such as molecular dynamics (MD) [1, 8] are
particularly suited to this purpose.
Currently, there are multiple algorithms to sample the confor-
mational space of proteins in the MD framework ranging from
classical approaches to different enhanced sampling algorithms
[19, 20] (see Chapters in Part II and III of this book). The contin-
uous development of new methods for protein conformational
sampling and advances in software and hardware for MD simula-
tions are generating a massive amount of trajectory data. We thus
need the proper tools to decipher the complexity hidden in MD
data and to move from protein ensembles to functional properties.
This protocol will focus on the integration of different methods
for the analysis of conformational ensembles of proteins. We will
cover mainly the analysis of structural ensembles generated by
molecular simulations. Similar approaches can also be applied to
biomolecular ensembles generated by other computational or
experimental methods. The approaches presented here, which are
routinely used in our group, allow to collect data on the quality of
the simulations and the sampling, along with to gain information
on local and more distal effects in the protein structures, for exam-
ple, upon a mutation or modiﬁcation of the protein. In particular,
we will use—as an illustrative example—the SCAN domain of
MZF1 (myeloid zinc ﬁnger 1), a key transcription factor whose
role is emerging in cancer [21–25].
2
MZF1 Protein Architecture and MD Ensembles
2.1
Three-
Dimensional
(3D) Architecture
of MZF1 SCAN Domain
In this paragraph, we will brieﬂy introduce MZF1 to orient the
reader.
A SCAN domain is a small protein domain of up to 80 residues
often found in transcription factors [26] such as MZF1. The MZF1
SCAN domain (PDB entry 2FI2 [27]) is a dimer, where each
416
Matteo Lambrughi et al.

monomer is composed of ﬁve α-helices connected by loops (Fig. 1).
Each domain has a V-shaped structure and can be divided into two
subdomains. The N-terminal subdomain comprises the α1 and
α2 helices, while the C-terminal one includes α3, α4, and α5.
Interactions between α2 and α3 provide the interface between the
two subdomains, whereas α2 of one monomer and α3 and α5 of the
other monomer are the main interfaces for dimerization. In the
dimer of MZF1 SCAN domain, a domain-swapped topology is
observed where the N-terminal subdomain of one monomer
packs with the C-terminal subdomain of the other monomer.
SCAN domains are modules for both homo- and hetero-
dimerization [27–29], contributing to generate functional diversity
in cellular signaling. MZF1, for example, is also known to interact
with many other SCAN-containing proteins such as ZNF24,
ZNF174, ZNF202, and RAZ1 SCAND1/RAZ108 through
SCAN-SCAN interactions [30, 31]. We have also recently pre-
dicted that other heterodimers could be formed with other proteins
harboring the SCAN domain, such as Peg3 and Zfp206, or
deprived of a SCAN domain, such as the Cdk4 kinase, CD14, and
the transcription factor Nfyc [22].
A group of mutations found in cancer patients within The
Cancer Genome Atlas and other similar genomic initiatives has
been identiﬁed in the MZF1 SCAN domain and recently structur-
ally analyzed, also employing MD simulations to discriminate
among predicted passenger and driver mutations in cancer [22].
Fig. 1 Three-dimensional (3D) architecture of MZF1. The different secondary
structural elements are numbered from the N- to the C-terminal extremities. The
ﬁrst conformer of the NMR ensemble is deposited in the PDB entry 2FI2
Analyzing Biomolecular Ensembles
417

2.2
MD Ensembles
of MZF1
To better discriminate between differences related to the usage of
different physical models in MD simulations and genuine struc-
tural/functional features, we suggest scrutinizing different force
ﬁelds for a protein of interest. Moreover, properties calculated
from the MD ensembles can be compared to parameters that can
be quantiﬁed experimentally, such as those measured with NMR or
other biophysical spectroscopies [8, 11, 32–35].
In the case of MZF1, for example, we selected ﬁve different
force ﬁelds, that are, CHARMM22∗[36], CHARMM27 [37, 38],
Amber-ff99SB∗-ILDN
[39,
40],
Amber-ff99SB-NMR-ILDN
[41], and RSFF1 [42], to assess the inﬂuence of the parametriza-
tion from three force ﬁeld families (CHARMM, Amber, and
OPLS). For each force ﬁeld, we collected 1-μs MD simulations
[22], which are here used to illustrate our protocol of analyses of
MD ensembles. Indeed, even small changes, which account for the
torsional potential of backbone and side chains in the force-ﬁeld
parameters, can have a signiﬁcant impact on the conformational
sampling and the dynamics described by MD simulations of the
same target protein [34, 43–46].
In summary, force-ﬁeld performance and accuracy are highly
system dependent. It is, therefore, difﬁcult to identify common
rules for force-ﬁeld selection. Thus, when a new protein is under
study, a suitable strategy is to test more than one physical model
and compare the results.
3
Assessment of the Biomolecular Ensembles
When dealing with structural ensembles from simulations, it is
important to ﬁrst carry out (1) a proper preprocessing of the
trajectory ﬁles, (2) assessment of the sampling exhaustiveness
achieved in the simulations, (3) estimation of the overlap of the
conformational space spanned by different replicates of the same
protein, and (4) evaluation of the quality of the conformational
ensemble collected. In this chapter, we illustrate some examples of
the tools that can be used to achieve these goals applied to the
MZF1 MD simulations recently published by our group [22].
3.1
Preprocessing
of a Single MD
Trajectory
In MD simulations, one of the ﬁrst steps is the selection (in terms
of size and shape) of a box of water molecules, in which the system
to be simulated is placed. This box, containing the atoms of the
systems, is then surrounded by translated copies of itself (images)
using periodic boundary conditions, which are used to minimize
edge effects in a ﬁnite system. In this way, when employing an
inﬁnite-like system, the user has to be careful of possible effects
due to periodicity. Indeed, the molecules are free to move and
diffuse inside the box. Thus, it could occur that one atom leaves
the simulation box and enters an image.
418
Matteo Lambrughi et al.

When protein structures—especially multimeric protein assem-
blies—are simulated using MD, it can be challenging to predict a
suitable box size that minimizes the risk of the protein system to
come in contact with its periodic images, forming erroneous artiﬁ-
cial interactions with itself, that is, so-called periodic boundary
artifacts. A ﬁrst step in the preprocessing of an MD trajectory is
to exploit tools that allow to verify if potential artifacts are in
play (see Note 1). We suggest to employ, for example, the gmx
mindist GROMACS tool to compute the minimum distance
between the atoms of the simulated system and its periodic images.
In this way, the user can check if the protein system has come in
contact with its periodic image during a simulation. While using
this GROMACS tool, we realized that—especially when handling
large systems and multimeric proteins—it is crucial to ﬁnd the
center of mass of the system and then calculate the gmx mindist
on the centered trajectory. Otherwise, the usage of a noncentered
trajectory could bring to incorrect results such as the identiﬁcation
of spurious contacts between the protein and its periodic images.
To this aim, one could use, for instance, CALCOM [47], which
calculates the center of mass of a protein, starting from the PDB ﬁle
of the initial structure. The GROMACS gmx traj tool can also be
used with the ﬂag -com for the same purpose. Once the atom that
better represents the center of mass of the protein has been identi-
ﬁed, the workﬂow to apply is usually the following: (1) to generate
a GROMACS index ﬁle with the gmx make_ndx tool, which
includes the closest Cα atom to the center of mass of the protein
identiﬁed by CALCOM, (2) to generate a centered trajectory, using
the gmx trjconv tool (with the ﬂag -center) and the index ﬁle created
at the previous step. Additionally, the ﬂag -pbc allows to account for
the periodic boundary conditions; (3) to use the gmx mindist tool
on the centered trajectory and plot the resulting output (Fig. 2).
For example, we illustrated the results that we achieved for the
different MZF1 simulations. As a rule of thumb, it is important
to verify that the minimum distance between the system and its
periodic image is higher than the cutoffs used for Coulomb and van
der Waals interactions in the MD simulations, which are 0.9 nm in
our case. Moreover, in those cases in which the minimum distance
is lower than the cutoffs, it is essential to verify that this is related to
transient interactions. Otherwise, we encounter the risk that artiﬁ-
cial intermolecular contacts alter the protein structure and its
dynamics. As it can be appreciated by our examples, we observed
simulation frames in which the minimum distances between the
periodic images were lower than the MD cutoffs for van der Waals
and short-range electrostatic interactions. This result could indicate
that the box is rather small, and its size could have been increased in
the original MD setup. These contacts are transient and occur in a
minor subset of the simulation frames (i.e., in less than 5% of the
Analyzing Biomolecular Ensembles
419

40
35
30
25
20
15
10
5
0
0
200
400
600
800
1000 0
200
400
600
800
1000
Time (ns)
Time (ns)
0
200
400
600
800
1000
0
200
400
600
800
1000
Time (ns)
Time (ns)
0
200
400
600
800
1000
Time (ns)
ff99SB - NMR - ILDN
RSFF1
ff99SB* - ILDN
C22*
C27
Distance (Å)
40
35
30
25
20
15
10
5
0
Distance (Å)
40
35
30
25
20
15
10
5
0
Distance (Å)
Fig. 2 The minimum distance (y axis) of the protein to its periodic images during the simulation time (x axis)
has been plotted for each of the force ﬁelds used to simulate MZF1 dynamics. To calculate this distance, the
GROMACS tool gmx mindist has been used (for the details, refer to the main text)
420
Matteo Lambrughi et al.

structures of the ensemble). Thus, they do not pose signiﬁcant
problems.
We also provide a Python script Mol_Analysis.py, which allows us
to carry out the steps described above, together with other basic
analyses of the trajectory. The script is available at https://github.
com/ELELAB/Mol-Analysis.
3.2
Sampling
Evaluation of a Single
MD Trajectory
Dimensionality reduction techniques such as Principal Component
Analysis (PCA) [48, 49] can be used to assess the sampling exhaus-
tiveness in MD simulations. In brief, PCA allows the extraction
of the motions with largest amplitude from an MD trajectory using
the eigenvectors (i.e., the Principal Components, PCs) of the mass-
weighted covariance matrix of the atomic positional ﬂuctuations.
The simulation can then be analyzed in a reduced “essential sub-
space” that still accounts for the most important dynamical fea-
tures. If the protein includes, for example, relatively unstructured
N- and C-terminal tails, whose motions are not the main focus of
the
MD
investigation,
it
is
recommended
to
discard
the
corresponding atoms/residues from the calculation of the covari-
ance matrix so that structural/dynamical differences in other pro-
tein regions can be identiﬁed.
Different metrics can be used to evaluate the sampling achieved
in the simulations once the PCA data are available. For example, the
“cosine content” of those principal components (PCs) that con-
tribute to most of the variance of atomic ﬂuctuations is a measure of
the quality of the sampling collected with an MD trajectory
[50, 51]. The ﬁrst few PCs of a high-dimensional random diffusion
motion are cosines. The cosine content varies from 0 (no cosine
shape) to 1 (perfect cosine shape, indicating a simulation with a
high probability of random diffusion) [50, 52]. A reasonable cosine
content might reach the value of 0.2 for MD simulations of small
peptides and, up to 0.5 for proteins [52, 53]. A very high cosine
content along the ﬁrst PCs is, thus, an indicator of not sufﬁcient
sampling or sampling that can be improved with regard to the
atomic ﬂuctuations of interest and in the context of the time-scale
and local sampling enabled by a classical MD simulation.
For example—as reported in Fig. 3—for each of the force ﬁelds
used to simulate MZF1 dynamics, we performed the PCA of each
trajectory and then calculated the cosine content of the ﬁrst 20 PCs.
Most of the PCs in all the force ﬁelds sampled had values of cosine
content very close to 0 and always below 0.5, suggesting a reason-
able local conformational sampling.
To perform this analysis, one can take advantage of different
GROMACS tools, following these steps: (1) to use the gmx trjconv
tool and a proper index ﬁle to ﬁlter, for example, retaining the Cα
atoms of interest of the trajectory obtained after postprocessing;
(2) to calculate the covariance matrix with the gmx covar tool;
(3) to analyze the resulting ﬁrst 20 eigenvectors with the gmx
Analyzing Biomolecular Ensembles
421

Fig. 3 The cosine content (on the y axis) of the ﬁrst 20 principal components (x axis) has been calculated to
measure the quality of the sampling collected with the MD simulations. The cosine content ranges from
0 (no cosine shape) to 1 (perfect cosine shape), but, consistently with the reasonable sampling of the
trajectories with several force ﬁelds, the maximum values obtained are around 0.3–0.4

anaeig tool to derive the projections of the trajectory onto the
eigenvectors, thus obtaining the principal components; and
(4) ﬁnally, to estimate the cosine content of the PCs by exploiting
the tool gmx analyze.
Another useful PCA-based metric is the root mean square inner
product (RMSIP) calculated on the ﬁrst 10 or 20 PCs. RMSIP is
often used to quantify the similarity between the regions of the
conformational space sampled by independent trajectories (i.e.,
replicates) of the same protein system, as well as to compare the
sampling achieved in the two parts of the same simulation [46, 51,
54, 55]. RMSIP ranges from 0 (i.e., completely orthogonal spaces
sampled by the essential subspaces of the two trajectories) to 1 (i.e.,
a perfect overlap). For example, in our MZF1 simulations, the
RMSIP values were always higher than 0.85 in pairwise compar-
isons between the two halves of the same MD trajectory [22]. This
result indicates that no major conformational rearrangements of
the protein were occurring during the MD runs since the confor-
mational space covered by the two halves of the same trajectory was
overlapping. Thus, there was no need, in this case, to extend the
simulations further to explore a certain conformational transition
with higher accuracy. Overlap metrics, such as RMSIP, can be also
calculated using the above-mentioned GROMACS gmx anaeig
tool, as well as functions of the Bio3D R package [56, 57].
3.3
Ensemble
Comparisons:
Structure, Dynamics,
and Different Physical
Models
In cases in which the conformational ensemble is generated by MD
simulations or approaches relying on a force ﬁeld, another impor-
tant assessment is the evaluation of the agreement among the
different physical models in describing protein structure and
dynamics.
Indeed, since the ﬁrst applications of molecular mechanics,
several different force ﬁelds have been derived according to differ-
ent parametrization strategies and principles; a number of strategies
exist and have been used in the past years. The same is true when we
consider coarse-grain physical models. As all classical force ﬁelds are
designed to reproduce data as close as possible to experimental or
other theoretical results, they should all give rise to the same or
similar conformational ensembles when used in the context of
stochastic simulations, such as MD. In practice, however, this has
been shown not to be necessarily the case, as different force ﬁelds
favor the sampling of some regions of the conformational space
rather than some other depending on the energies assigned to the
conformations, sometimes showing unsatisfactory agreement with
the experimental data [34]. For this reason, it is essential to quan-
tify the difference in the conformational space explored by replicates
of the same protein using different force ﬁelds, along with to
evaluate the differences in dynamical properties between the
ensembles. This observation is not limited to the force ﬁeld com-
parison, illustrated here, but can conceptually be extended to any
Analyzing Biomolecular Ensembles
423

comparison across ensembles, for example, the one between wild-
type and mutated variants of the same protein.
The comparison between MD ensembles can be carried out
using a collection of methods [58] that we have implemented,
together with other colleagues, in the ENCORE software package
[45]. The main idea behind them is to represent conformations
from natural or synthetic ensembles as samples generated from an
underlying distribution, which is possible to estimate according to
different strategies. The probability distributions are then com-
pared using standard metrics derived from information theory,
such as the Jensen–Shannon divergence. The outcome of the pro-
cess is a number to estimate how much two conformational ensem-
bles differ, that is, an ensemble similarity measure. This can be
useful when comparing ensembles generated using different force
ﬁelds, different replicates of the same system, simulations of differ-
ent variants of the same protein or even different portions of the
same simulation. For instance, ENCORE can be used to under-
stand if satisfactory sampling has been achieved, as we did with
RMSIP in the example in Subheading 3.2, or to check if sampling
has changed after an event has occurred, for instance, a relevant
conformational transition or binding/unbinding of a molecule.
In this protocol, we illustrate in detail two of the three methods
implemented in ENCORE: the Clustering Ensemble Similarity
(CES) and the Dimensionality Reduction Ensemble Similarity
(DRES). The former is based on partitioning the set of conforma-
tions belonging to all the considered trajectories under comparison
into clusters (by default using the Afﬁnity Propagation, AP, cluster-
ing algorithm [59]) and using the relative occupancy of each
ensemble in each cluster as an estimate of the probability density.
The latter relies on the use of kernel density estimation to evaluate
the probability density, performed on a lower dimensionality space,
which is obtained using a dimensionality reduction method
(by default, Stochastic Proximity Embedding, SPE [60], in our
implementation) on the original full conformational space.
The use of both CES and DRES requires the calculation of a
similarity/distance matrix (respectively) for the AP and SPE meth-
ods. We have used, for MZF1, a Cα RMSD matrix as distance
matrix for SPE, and a negative Cα RMSD matrix as similarity matrix
for AP. An RMSD matrix is simply a symmetric square matrix
containing the conformational distance values—calculated with
root mean square deviation after best-ﬁt superimposition consider-
ing Cα atoms only—between each pair of conformations of all the
ensembles to be considered. Additionally, AP requires a parameter
(called Preference) which controls the number of clusters that the
algorithm will produce. SPE requires the number of dimensions of
the target dimensionally reduced space. We have performed the
ENCORE analysis using the implementation in MDAnalysis
0.16.2 [61], which is the most recent version available at the
424
Matteo Lambrughi et al.

moment of writing this protocol. To perform the analysis, we have
carried out the following steps that can be used as a reference
workﬂow:
1. To gather a single preprocessed (see Subheading 3.1) 1-μs MD
trajectory per force ﬁeld. We have ﬁltered each of them keeping
Cα atoms only and one conformation per nanosecond, result-
ing in 1001 frames per simulation.
2. To perform a Cα root mean square ﬂuctuation analysis for each
complete trajectory, allowing us to identify the most ﬂexible
regions of the protein (as chain terminals and extended/disor-
dered loops). These should be kept out of the analysis, as their
dynamics converge much slower than the time-scale analyzed,
and differences in their behavior are not necessarily a ﬁnger-
print of differences among the force ﬁelds. In this case, we have
kept residues 40–122 of each protein chain of MZF1.
3. To calculate a common RMSD matrix for the all the ensembles
to be considered. This has been saved on disk using the facilities
present in ENCORE, so it could be re-used for both CES and
DRES analyses at a later time, allowing us to save computa-
tional time. The user just needs to provide a single simulation
trajectory per ensemble to be compared.
4. To run CES using the matrix obtained in step 3 as a (negative)
similarity matrix. We have performed, in our example, a few
different runs with varying preference values for AP (0.1,
0.5, 1.0, 2.0, 5.0, 10.0, 20.0). The damping factor
was set to 0.7 to ensure convergence.
5. To run DRES using the matrix obtained in step 3 as a distance
matrix, using two, three, or four dimensions for SPE. The
number of cycles was set to 104, and the number of operations
per cycle was set to 106 to ensure convergence.
The outcome of each calculation is a square matrix that con-
tains an estimate of the distance between each pair of ensembles,
ranging from 0 to ln(2), where 0 means identical ensembles and ln
(2) means completely unrelated ensembles (Fig. 4a). It should be
noted that the outcome of each run performed with different
parameters will necessarily have slightly different results; however,
while visualizing the results from different runs, the trend between
different simulations should be maintained, keeping the same gen-
eral meaning. This is especially important for CES, for which, in
those cases where the clustering output consists of just one confor-
mation per cluster, the outcome will be a matrix ﬁlled with ln
(2) values. If this is the case, the user should select higher
(in absolute value) preference values, aiming at generating a lower
number of clusters and having a better mean of comparison.
Analyzing Biomolecular Ensembles
425

For MZF1, we have compared simulations generated with two
force ﬁelds of the AMBER family (Amber-ff99SB-NMR-ILDN,
Amber-ff99SB∗-ILDN),
two
of
the
CHARMM
family
(CHARMM22∗, CHARMM27), and one of the OPLS-AA family
(RSFF1). The results are presented in Fig. 4a. Force ﬁelds of the
Fig. 4 Ensemble comparison measures. (a) Similarity measures between differ-
ent ensembles of MZF1 obtained using the ENCORE methods, CES and DRES. (b)
Normalized ΔF between correlation matrices (DCCM or LMI; see text) of the
MZF1 ensembles
426
Matteo Lambrughi et al.

same family (AMBER or CHARMM) sample similar regions of the
conformational space; nonetheless, Amber-ff99SB-NMR-ILDN is
found to have similar behavior to that of the CHARMM force
ﬁelds, especially in relation with CHARMM27. This trend is less
pronounced for Amber-ff99SB∗-ILDN, whose sampling is only
partially superimposable with that of the CHARMM force ﬁelds
(Figs. 4a and 5). The clear outlier here is the OPLS-derived force
ﬁeld (RSFF1), which samples distinct regions of the conformational
space compared with the other force ﬁelds. This feature is consis-
tent with that previously found for long time-scale ubiquitin simu-
lations using an older version of OPLS [45].
Another method to compare biomolecular ensembles is to
compare more dynamic properties that can be extracted from MD
simulations or other trajectories that are continuous in time; hence,
it is not applicable to biased and replica-exchange simulations,
namely quantitatively comparing differences in the correlation of
motions of pairs of residue/atoms. This is another important
assessment to do when it comes to analyzing protein ensembles,
since often measures of atomic motion correlation are used to infer
biological properties and differences among different protein var-
iants. A clear understanding of the reproducibility of cross-
correlated motions is crucial when different physical models or
different replicates are used to describe the same protein. In fact,
methods such as Dynamical Cross-Correlation Matrices (DCCM)
[62, 63] and Linear Mutual Information (LMI) [64] have been
used to compute correlation indices of protein motions between
Fig. 5 3D representation of the conformational space of the MZF1 MD
trajectories
upon
dimensionality
reduction,
obtained
as
detailed
in
Subheading 3.3 using the stochastic proximity embedding method
Analyzing Biomolecular Ensembles
427

the pair of residues of a protein structure. Brieﬂy, these indices
indicate how much residues move in a correlated fashion during a
MD simulation and are expressed in terms of a square matrix having
the same shape as the number of residues, where each element
represents the entity of correlation between residues of a certain
pair. DCCM is based on the Pearson correlation coefﬁcient and
ranges between 1 (negative correlation) to 1 (positive correla-
tion), passing through 0 (no correlation). LMI comes from the
framework
of
information
theory
and
ranges
from
0 (no correlation) to 1 (full correlation). Both these coefﬁcients
capture only linear correlation, and DCCM can be particularly
tricky, as the distinction between negative and positive correlation
can be problematic (for instance, correlation is 0 if two atoms move
in a perfectly coordinated fashion with perpendicular vectors of
displacement) [64]. Both DCCM and LMI are calculated on the
coordinates of the Cα atoms only. Starting from the correlation
matrices, we have devised a measure between pairs of matrices that
is able to quantify the overall difference between these matrices
[65]. This index (ΔF) is a normalized Frobenius norm of the
difference matrix computed between two matrices. To calculate it,
the following steps need to be applied:
1. To divide the target trajectory in nonoverlapping windows of
the same length. In our MZF1 examples, we divided each
trajectory into 10 ns-long trajectories. Then we ﬁtted each of
them to the average structure to cancel the effects of transla-
tions and rotations.
2. To calculate the LMI or DCCM index for each of them. This
was done using Wordom 0.22 [66]. Each calculation will result
in a single correlation matrix.
3. To average the obtained matrices, separately for LMI and
DCCM (i.e., calculate, for each matrix element the average of
that element in the set of matrices).
4. To calculate ΔF using the deltamat script, available on https://
github.com/ELELAB/xpyder.
It is important to estimate the correlation indices on small time
windows as suggested by previous analyses performed on correla-
tion matrices [65, 67]. In the case of MZF1, ΔF comparison
matrices between simulations performed using different force ﬁelds
are shown in Fig. 4b. While the absolute values of ΔF are overall
small, some differences are still discernible between the different
simulations so that a similar overall pattern seen in the ENCORE
analysis is reproduced for ΔF. This suggests that, while the overall
dynamics of the system are quite similar among the different simu-
lations and robust in the case of CHARMM and AMBER simula-
tions of MZF1, using different force ﬁelds also has subtler effects
on protein dynamics that our sensitive correlation analysis is able to
428
Matteo Lambrughi et al.

pick up. The difference is especially evident when comparing the
OPLS force ﬁeld with all the others, for which it is also a clear
outlier in terms of correlated motions.
Another useful quantitative metric that can be used to compare
the quality of different ensembles is the predicted resolution as
calculated by the ResProx (Resolution-by-proxy) software [68]. It
is based on a machine learning approach to estimate the atomic
resolution of a structure or an ensemble of structures (where both
the average and the individual values can be obtained). It is based
on 25 different measurable features that are derived from the
atomic coordinates. The resolution predicted by ResProx is a very
convenient index, since atomic resolution (such as the one asso-
ciated to crystallographic structures) is a simple universal measure
of structure quality. We applied the Resprox resolution to the differ-
ent MZF1 ensembles collected with different force ﬁelds, using
representations such as boxplots that allow the visualization of
data distribution based on the minimum, maximum, quantiles,
and median of the data [22]. This allowed evaluating how large
was each ensemble of structures in terms of structure quality, along
with the physical models providing the ensembles with higher
structural quality. It is important to use ResProx in combination
with the other methods and metrics described above for a clear
assessment of the ensembles under investigation.
3.4
Agreement with
Experimental Data
An alternative way to evaluate a computationally derived conforma-
tional ensemble is to back-calculate parameters from the ensemble
that can be directly compared to experimental biophysical observa-
bles, such as the ones recorded by NMR spectroscopy.
We thus conceived a protocol to compare NMR spectroscopic
data of either chemical shifts values or NOE-based distances with
the corresponding values calculated from the molecular ensembles.
Chemical shifts predictions are currently implemented, in our
script, with the predictor PPM:One [69]. We wrapped the PPM:
One prediction in a Python script (CSX2.py), enabling prediction
and comparison of chemical shifts on a large number of structures
with a time-resolved value of the differences between experimen-
tally measured and predicted data. For NOEs, the average Carte-
sian distance between NOE pairs is calculated and compared to
experimentally obtained NOEs. CSX2.py is available at https://
github.com/ELELAB/CSX2-cross-validation.
The steps needed to perform the cross-validation can be sum-
marized as follows:
1. To collect the input ﬁles, which are a reference NMR chemical
shift ﬁle and an ensemble ﬁle in a PDB format including multi-
ple conformers. The resonances need to be compatible with the
NMR-STAR formatted ﬁles deposited at the Biological Mag-
netic Resonance Bank (BMRB). To make sure the script reads
Analyzing Biomolecular Ensembles
429

the correct chemical shifts, it is recommended to clean up the
NMR-STAR ﬁle to include information of chemical shifts only.
The input PDB ﬁle can be generated from the MD trajectory,
for example, using gmx trjconv GROMACS tool. In our MZF1
example, 1-μs trajectories have been ﬁltered to store only con-
formations sampled every 2 ns in the input PDB ﬁle for CSX2.
py, thus collecting 500 representative frames for each ensemble.
2. CSX2.py can then be used following the instruction in the help
function. The script carries out the runs using the PPM:One
predictor for each of the 500 structures in the ﬁltered ensem-
ble. Once the PPM:One predictions are completed, a χ2-like
approach is used to calculate a “score” of distance between the
predicted values compared to the experimentally derived
values. The lower the value is to 0, the closer the experimental
and calculated ensembles are.
3. Several output ﬁles are generated using the CSX2.py script,
including per-residue data, along with the averages for the
different resonance types. In our case, the calculated χ2 values
quickly converged to low values for all ﬁve force ﬁelds, indicat-
ing a reasonable agreement with the experimentally derived
chemical shifts.
For comparisons between distances obtained by NOEs and
distances in the ensemble, we developed another script called
g_reff.py (available at https://github.com/ELELAB/G_reff), for
which two input ﬁles are needed. The ﬁltered PDB ﬁle of the
trajectory generated for the chemical shift analysis can be reused.
The second ﬁle contains the experimentally determined NOE dis-
tances as well as the information about the number of protons per
NOE pair. An example of input ﬁle is located together with the
script. When generating the two input ﬁles, special care must be
taken to make sure the nomenclature of the atoms in the PDB and
the input NOE ﬁles matches. We also provided a script (NOEcon-
verter.py) to help with the conversion to the right nomenclature.
Then the script g_reff.py can be used to carry out the calculations on
the theoretical ensemble.
As output, the average distance of the NOE pairs over the
complete simulation, the corresponding experimentally derived
NOE, along with the difference between the two are provided.
To analyze the resulting data, histograms of the distance differences
can be plotted. Furthermore, plotting the distance differences of,
for example, short-range, long-range, intermolecular NOEs, or
NOEs in speciﬁc regions of interest individually can yield additional
information of secondary, tertiary, or quaternary structural stability
of the system.
In the comparison between experimental and predicted NMR
parameters, it is important to consider the error associated with the
430
Matteo Lambrughi et al.

prediction of the properties of interest. Indeed, in the case in which
the differences between the calculated and experimental observable
of interest are lower than the error, the ensembles under compari-
son need to be considered equally good from the point of view of
the selected observables. For example, in the case of prediction of
chemical shifts from PPM:One, we can take advantage of the
reported errors for each class of atoms for which the method allows
us to derive chemical shift and verify if the estimated deviation
between experimentally measured chemical shifts and the calcu-
lated ones is higher than the error itself.
Similar calculations have been used for the MZF1 simulations
in our previous publication [22], which showed a reasonable agree-
ment between the experimental and computationally derived
MZF1 ensembles.
3.5
Convergence
of the Protein
Structure Network
As stated in the introduction, proteins are highly dynamic systems
that undergo changes of different types (e.g., mutations or post-
translational modiﬁcations). These perturbations can be transmit-
ted over long distances to other locations. Methods based on
network theory have been used to study the dynamics and the
properties of the proteins. Networks are well suited to model
complex system in which many elements interact and also to link
local to global perturbations occurring during protein dynamics
[11, 70–72]. These methods are the so-called “Protein Structure
Networks” (PSN), in which protein residues are the nodes of the
network, and they are connected by edges that can depend on
interaction strength or energetic coupling. Alternatively, the
edges can be deﬁned using different strategies, such as distances
between side chains, atomic contacts, van der Waals interactions,
and different classes of intra- and inter-molecular interactions
[8, 73–76].
PSN methods can be integrated with conformational ensem-
bles from MD simulations or other sampling methods [66, 76,
77]. The capability of PSN methods to deﬁne paths of communi-
cation over long distances makes them a suitable technique for
prediction of regions that are likely to be sensitive to allosteric
effects in protein structure ensembles [11]. Despite their broad
applicability, there are no clear rules to determine optimal para-
meters for PSNs. There are different principles for edges and weight
deﬁnition such as energies or correlated motions. PSN methods
applied on MD are often based on a contact-based approach, where
the centers of mass of residue side chains are the nodes, the dis-
tances between the residue centers of mass are the edges, and the
occurrence of the contact (persistence) is the weight [76]. In this
case, it is important to evaluate different aspects, as the impact of
the force ﬁeld and the minimal distance cutoff between the nodes
to add an edge in the PSN, ultimately affecting the network topol-
ogy. For this reason, we carried out a study to identify an optimal
Analyzing Biomolecular Ensembles
431

distance cutoff based on distances between the centers of mass of
protein residues [78]. We identiﬁed an optimal cutoff of 5 A˚ that is
generally robust for proteins of different size, fold, and simulated
with different force ﬁelds. The dataset used was including only a
small group of proteins, so it would be interesting in the future to
evaluate if this cutoff can be maintained for other cases of study or
if a more tolerant threshold need to be applied, which could be in
the range of 5–5.5 A˚ . We recommend for new proteins and simula-
tion to run the entire pipeline PyInKnife pipeline, which is illu-
strated below.
In detail, we evaluated the convergence of the two most impor-
tant properties of a PSN: hubs and connected components. The
hubs are nodes that have a high degree of connectivity in a network,
and the connected components are clusters of nodes with no edges
in common with nodes from other clusters. In order to evaluate the
convergence of the PSN properties from MD simulations, we used
a Jackknife approach (see Note 3) implemented on a pipeline called
PyInKnife to automate the steps (Fig. 6), which is available free of
charge at https://github.com/ELELAB/PyInKnife.
As an example of the PSN analysis, we selected the MZF1
simulation with CHARMM27 force ﬁeld (Fig. 6). To perform the
analysis, we carried out the following steps: (a) to select the trajec-
tory and topology ﬁles from the simulation and run the PyInKnife
pipeline; (b) to calculate and plot the hubs and connected compo-
nents distribution (Fig. 7).
4
Analysis of the Biomolecular Ensembles to Study Molecular and Structural
Mechanisms
Once the ensemble has been properly assessed, the analyses of
structural properties can be carried out with a multitude of different
approaches (see also the other Chapters in Part IV). The selection of
speciﬁc tools for analyses of biomolecular ensembles has to be
driven by the question and the molecular mechanism to address.
For example, we illustrated
below the approaches that, if
integrated, allow to collect information on either local or more
distal effects related to important hotspots of a protein structure.
In particular, we focused in those local and long-range interactions
that involve sites affected by cancer mutations in MZF1. Similar
methods can be transferred to other studies, that is, to assess the
impact of post-translational modiﬁcations to study interfaces for
recruitment of other biomolecules, binding pockets for small
ligands or peptides, etc.
4.1
Evaluation
of Local Changes
Among the several descriptors that can be used to probe local
structural changes, dihedral angles give information about the
conformational ﬂexibility of given residues, as well as their
432
Matteo Lambrughi et al.

conformational sub-states [79]. It is possible to plot histograms of
dihedral angle distribution for selected/all residues from a certain
system using a Python script developed by our group, available free
of charge (https://github.com/ELELAB/Angle_histograms). We
applied
the
following
protocol
to
the
MZF1
simulation
(CHARMM27 force ﬁeld) as an example. Our script does not
automatically support trajectories of multimeric systems (as in our
case, since MZF1 is a homodimer). In such case, the following
preparatory steps should be done and are here illustrated for
GROMACS:
1. To create an index ﬁle containing a group for each chain. This
can be done using gmx make_ndx command.
2. To generate a .gro ﬁle for each chain separately, using gmx
editconf with the -n ﬂag to source the index ﬁle created in
step 1.
Fig. 6 Schematic ﬂowchart of the steps followed in the PSN analyses. White boxes in the upper part are the
main inputs of the pipeline while the white boxes in the bottom are the main outputs. The gray boxes represent
the commands used from PyInteraph. First, PyInteraph identiﬁes all the pairwise interactions for the selected
class, that is, hydrogen bonds, salt bridges, or contacts between residues. In the following step, it is necessary
to ﬁlter the interactions to exclude very transient ones with ﬁlter_graph, a tool of PyInteraph. The last step is
the network analysis carried out with graph_analysis, another tool of PyInteraph. On the right side, there is a
schematic representation of the statistical method implemented in the PyInKnife pipeline, that is, the
Jackknife method
Analyzing Biomolecular Ensembles
433

Fig. 7 Distribution of connected components and hubs at different distance
cutoffs used for the PSN-MD analyses. We evaluated the changes in the
population of the connected components (Cluster ID in the upper panel) and
434
Matteo Lambrughi et al.

3. To create two separated .xtc trajectory ﬁles (one for each chain)
with gmx trjconv specifying the -n ﬂag again.
Once the .gro and .xtc ﬁles have been generated for each chain,
one has to calculate the dihedral angles using the gmx chi com-
mand (see Note 2). Here it is necessary to use the -all ﬂag to obtain
the separated .xvg ﬁles for every residue, which will be used by our
script. The other ﬂags can be used depending on which angles the
user would like to plot, that is, maxchi, omega, psi, and phi. In our
example, we computed all angles with a maxchi value set to 6 for
both chains. Hence, we obtained .xvg ﬁles for the 94 residues of
each chain. Then, one has to specify additional parameters, called
Local_shift, Label and Folder (path of the folder containing the
dihedral angles values) in the conﬁg.cfg ﬁle in the “Folders” sec-
tion—an example can be downloaded from our Github repository.
It is possible to plot the angles for more than one trajectory at the
same time by adding the new lines corresponding to the same
parameters for the second trajectory in this section. The Local_shift
value is used to shift the resids selection independently, which can
be useful to plot angles for two or more systems with different
numbering. Noteworthy, if the systems exhibit different sequences,
the -align ﬂag can be used to align the plots in the output pdf ﬁles,
which requires an alignment ﬁle—more information can be found
at our Github repository. In the example below, we plot the distri-
bution of the dihedral angles for both chains A and B of MZF1,
using one line for each chain in “Folders” in the conﬁguration ﬁle,
and we set Local_shift to 0 for both chains, since they are identical.
The “Settings” section can also be modiﬁed depending on
what the user wants to plot (see Note 2). We selected all the
residues (resids ¼ all) and all residue types (restypes ¼ all) for
which we chose to plot chi1, omega, psi, and phi (angles ¼ chi1,
omega, psi, phi). The gshift value can be modiﬁed to shift the residue
numbers in the plots, since gmx chi numbering starts from 1. Our
MZF1 structure begins by GLY35 for both chains, thus the gshift
was set to 34.
Our script provides a histogram plot of the backbone and side
chain angles for each residue speciﬁed by resids and restypes. The
output is in pdf format, and the number of plots by pdf ﬁle can be

Fig. 7 (continued) the number of hubs and their node degree (lower panel) as a
function of different distance cutoffs in the PSN derived from the MD trajectory
(histogram values) and the associated standard deviations (error bars). The
standard deviations were calculated from the average PSN obtained from the
Jackknife resampled trajectories. We observed that at distance cutoffs higher
than 5 A˚ , most of the nodes of the PSN were located in the same cluster (cluster
ID 1). On the other hand, we noticed that hubs are virtually absent at distance
cutoffs lower than 5 A˚
Analyzing Biomolecular Ensembles
435

set with the n option in the “Settings” section. Here we used the
default value, which is set to 10.
Once the values in the conﬁg.cfg ﬁle are set, the script can be
used with the -f conﬁg.cfg ﬂag. Hence, we obtain in our case pdf
ﬁles corresponding to chi1, omega, psi, and phi angles for all the
residues (10 for each pdf ﬁle for the sake of clarity), and plots for
both chains are on the same pdf ﬁle (Fig. 8). The color scale reﬂects
the changes in dihedral angles along the simulation, which is in our
case 1-μs long. The residue numbering starts from 35, since the
global shift has been set to 34. In this example, we used the version
5.1.0 of GROMACS, but this protocol is applicable to trajectories
obtained with GROMACS 4 as well.
4.2
Long-Range
Effects Unveiled by
Principal Component
Analysis
The PCA approach [48, 49] can also be used to study the short-
and long-range effects on the structure of the MZF1 SCAN dimer
and the differential dynamics behavior of the two monomers. We
conducted a PCA scan and performed analyses, considering subsets
of atoms corresponding to each of the monomeric SCAN domain
in the MZF1 dimer (Fig. 9), to identify effects of the different
regions that are not directly involved in the binding interface. To
perform this analysis, one can take advantage of GROMACS tools
using the following steps:
1. Use the gmx make_ndx tool to create a proper index ﬁle con-
taining a group for each structural element that should be
analyzed (e.g., the residues in each monomer, corresponding
to chains A and B). The gmx trjconv tool can be used to ﬁlter
the trajectory obtained after the post-processing for the atoms
Fig. 8 Distribution plot of χ1 side chain dihedral angles for the ﬁrst ten residues of MZF1
436
Matteo Lambrughi et al.

of interests, for instance, the Cα atoms. Here we performed the
analysis on the CHARMM27 trajectory using all the protein
atoms, and we avoided considering a few highly ﬂexible resi-
dues at the N- and C-terminals of each chain in the same way as
explained above to prevent problems associated with their
intrinsic higher ﬂexibility that could mask other dynamic pat-
terns of interest.
2. Calculate the covariance matrix with the gmx covar tool, which
requires the deﬁnition of two different groups, that is, one
subset of atoms to perform structural alignment of the trajec-
tory frames against a reference structure and another subset to
be used for the covariance calculation. Since PCA is based on
the calculation of the covariance matrix of the atomic positional
ﬂuctuations, the outcome of the analysis is strongly dependent
on a correct structural alignment against the reference struc-
ture. Identifying an optimal subset of atoms to perform the
alignment can be complex, and the use of other methods not
only based on the analysis of the cartesian coordinates, such as
Fig. 9 PCA to identify distant conformational changes in MZF1 dimer. The analysis has been performed on
CHARMM27 trajectory. (a) 2D distribution plot along PC1 and PC2 calculated considering all the protein atoms
excluding the last ﬁve residues at the N- and C-terminal. (b) 2D distribution plot along PC1 and PC2 calculated
considering all the protein atoms of chain A (upper panel) or of chain B (lower panel) excluding the last ﬁve
residues at the N- and C-terminal. (c) Representative structures extracted from the two identiﬁed conforma-
tional states are shown as cartoon and indicated in purple and green, respectively. Chain B in each structure is
shown in gray, while chain A is highlighted in purple and green
Analyzing Biomolecular Ensembles
437

the TimeScapes approach discussed below (Subheading 4.3),
can be helpful to achieve this goal. We here used as a reference
the starting structure of the CHARMM27 MZF1 simulation.
We performed the alignment on the α3 helices of chains A
and B, which are involved in the binding interface and mainte-
nance of a stable orientation during the simulation, allowing us
to capture the motions of the rest of the protein.
3. Analyze the resulting eigenvectors with the gmx anaeig tool to
calculate the projections of the trajectory on them, thus obtain-
ing the principal components (PCs). The tool can also be used
to obtain the two-dimensional (2D) projections along two
PCs, for example, the ﬁrst and the second. We used a MATLAB
script (available on demand) to process the data obtained from
the ﬁrst two PCs and calculate a distribution plot that permits
to evaluate the presence of possible sub-states in the sampled
ensemble.
Looking at the subspace described (Fig. 9a–b), we observe that
the two chains have a similar behavior with minor differences in
their dynamics, and they can both populate at least two possible
subsets of states in the PCA subspace. To understand the localiza-
tion on the protein structure of the principal ﬂuctuations described
by the ﬁrst two PCs, we used the gmx trjconv tool to extract some
representative structures from the ensemble (Fig. 9c). Looking at
the conformations from the two identiﬁed subsets, the major struc-
tural differences are associated with ﬂuctuations in the loops con-
necting α1–α2, α3–α2, α3–α4, and α4–α5, determining changes in
the positioning of the associated helices. This is evident especially
for the α1 and α4 helices of both the monomers, which are distant
from the interaction interface of the domain. These motions and
long-range effects in regions of the protein that are exposed to the
solvent might be important for the recruitment and binding to
other cofactors [22].
4.3
High-Order
Statistics Methods
Using the TimeScapes
Package
The aforementioned methods based on PCA have strong utility in
the investigation of both local and long-range conformational
effects in MD ensembles, but they have also shown limitations to
identify structural populations and important events in simulations
and may not be sufﬁcient to describe complex mechanisms
[64, 80]. To improve our description of the system, we used
methods based on higher order statistics, as the ones implemented
in the TimeScapes package [81], which is speciﬁcally developed to
efﬁciently and accurately analyze complex ensembles composed of
several measured observables, as the ones collected by MD simula-
tions [82–84]. The advantage of higher order statistics methods for
the analysis of dynamics of biomolecular systems is that they permit
to efﬁciently investigate both the global dynamics and transient
conformational populations that are poorly discriminated by other
438
Matteo Lambrughi et al.

approaches. Moreover, these methods allow to structurally capture
the individual components underlying the conformational changes,
such as regions, structural elements, or groups of residues.
Here we used the TimeScapes package version 1.5 [81] to
identify conformational changes in the two SCAN domains of the
MZF1 dimer by MD simulations. The approach implemented in
TimeScapes describes protein dynamics by measuring the formation
and breaking of atomic contacts between residues in the system
under investigation, using a coarse-grained model. The evolution
of molecular contacts is measured as “activity” of the system during
MD simulation time, that is, the total number of changes in contact
per unit time, providing a proﬁle as shown in Fig. 10a that permits
to monitor the global dynamics along MD simulations. Periods of
high activity are associated with conformational transitions (forma-
tion and breaking of contacts) of the protein, while periods of low
activity correspond to local stable states. To perform this analysis,
we carried out the following steps:
1. We collected a 1-μs trajectory of MZF1 SCAN dimer per-
formed using CHARMM27 force ﬁeld and ﬁltered it using
the gmx trjconv GROMACS tool, storing only conformations
sampled every 200 ps, for a total of 5000 for analyses.
2. We used the TimeScapes script terrain.py that performs event
detection and activity analysis. We performed the analysis con-
sidering all the protein atoms of chain A or chain B, and we
avoided considering the highly ﬂexible residues at the N- and
C-terminals of each chain in the same way as that performed for
RMSD and PCA analysis in order to prevent problems with
slower convergence in their dynamics behavior. An indicative
example of command line is.
terrain.py refA.pdb traj.xtc 2 3 250 GMD output_files_prefix
We used the starting structure as reference PDB ﬁle to
deﬁne the coarse grain model and the trajectory ﬁle (.xtc). We
set the smoothing parameter to 250 trajectory timestep units,
corresponding to 50 ns, to have a global view of the dynamics
of the system. This parameter impacts the details of the analysis
and depends on the problems and systems under investigation,
so we have employed the suggested value [81] setting the
median ﬁlter to the 5% of the total time length of the MD
simulation. We employed both types of graph provided by
TimeScapes to monitor time-dependent evolution of contacts
in the ensemble: (a) cutoff activity measures contacts based on
geometric distances; (b) GMD activity measures contacts by
the Generalized Masked Delaunay (GMD) tetrahedralization
of the coarse-grained model. The Cutoff method is reported to
be more sensitive to local changes, while GMD permits a more
Analyzing Biomolecular Ensembles
439

global analysis of structural variability. To separate contacts and
noncontacts between pair of residues and avoid events of
re-crossing, we used a buffer region setting upper and lower
bound values of 6 and 7 A˚ and 2 and 3 edge order for the
Fig. 10 Distal effects on each domain of the MZF1 dimer (chain A and chain B) identiﬁed by the TimeScapes
tools. (a) The cutoff activity plots are reported, showing the contribution of both “forming” (green) and
“breaking” (red) activities. The analysis permits to identify basins of minimal activity of the system, and we
collected the corresponding structures, shown as cartoon. We performed structural alignment of each
structure against the starting crystallographic structure of MZF1 SCAN dimer and calculated the RMSD
between Cα atoms. The RMSD values were stored as B-factor and shown with a color spectrum from 0.0 A
(blue) to 6.5 A˚ (red). (b) The measured MI correlation values of residues and hinges local motions to the total
activity in each chain were projected onto the amino acid sequence, stored as B-factor on the initial structure
of the simulation and shown with color spectrum, white-blue and white-purple, respectively
440
Matteo Lambrughi et al.

Cutoff
and
GMD
methods,
respectively,
as
previously
suggested [81].
3. We analyzed and plotted the results from the ﬁles provided in
output, one containing the calculated total, forming, and
breaking activity during simulation time (output_ﬁles_preﬁx_-
activity.dat, Fig. 10a), a ﬁle containing the list of the individual
events identiﬁed (output_ﬁles_preﬁx_events.log) and one con-
taining total activity and ﬁrst derivative (output_ﬁles_preﬁx_seg-
mentation.dat) used below to perform other analysis. We used
the
ﬁles
containing
the
list
of
the
simulation
frames
corresponding to the transition events and basin minima (out-
put_ﬁles_preﬁx_transitions.log and output_ﬁles_preﬁx_minima.
log respectively) along with the corresponding structures in
DCD trajectory format to identify the regions of the system
involved in the measured motions, as shown in Fig. 10a.
Despite some differences associated with the type of graph
employed, both the Cutoff and GMD methods point out
similar proﬁles about the activity of both chains A and B,
supporting the consistency of the analysis performed. In agree-
ment with the PCA, the analysis indicates similar dynamical
properties of chains A and B. Moreover, the use of TimeScapes
permits to identify sub-states populated by each chain during
the simulation, corresponding to the basin of minimal activity,
separated by periods of high activity corresponding to confor-
mational events. To investigate possible long-range effects in
each MZF1 SCAN domain and the regions involved in the
identiﬁed changes, we collected the structures from each
basin minima and calculated the Cα RMSD relatively to the
starting structure and shown with a color spectrum (Fig. 10a).
We show that the α2 and α3 helices, which provide the inter-
faces both for the two N- and C-terminal subdomains and for
the dimerization, undergo minor changes in their spatial orien-
tations. Looking at the conformations from the basin minima,
the principal changes are localized in the loops connecting
α1–α2, α3–α2, α3–α4, and α4–α5, and rearrangements are
evident especially in the orientation of the helices α4 and α1.
To further detail our analysis and identify possible important
residues associated with the dynamics in each of the domain com-
posing the MZF1 SCAN dimer, we used the newly developed
TimeScapes tools tagging.py and turning.py [85]. To perform this
analysis, we carried out the following steps:
1. We used the results from the previous activity analysis per-
formed with terrain.py, in particular the total activity and ﬁrst
derivative values (output_ﬁles_preﬁx_segmentation.dat), for the
one collected with the GMD-based method.
Analyzing Biomolecular Ensembles
441

2. We employed the TimeScapes tools tagging.py and turning.py.
The approach used in these programs enables identifying
potentially functionally relevant residues by detecting relation-
ships between their fast local motions (tagging.py) or turning
motions (turning.py) to global dynamics measured as activity
[85]. In the ﬁrst case, the analysis is based on identifying
pairwise residue distances, while in the second case, the analysis
is based on dihedral angles deﬁned by four consecutive Cα
atoms, whose absolute time differentials are correlated with the
activity of the system. An indicative example of command is.
turning.py
(tagging.py)
refA.pdb
traj.xtc
output_files_pre-
fix_segmentation.dat -mi output_files_prefix
We set the parameters as previously explained when
performing the calculations using terrain.py. We used the ﬂag
-mi to employ mutual information (MI) to detect possible
nonlinear relationships.
3. From the output results, we collected the measured MI corre-
lation values of residues and hinges with global activity of the
system (output_ﬁles_preﬁx_projected.dat and output_ﬁles_pre-
ﬁx_turning.dat) and projected onto the amino acid sequence.
The projected MI correlation values were inserted in the
B-factor column on the reference pdb ﬁle to structurally local-
ize the identiﬁed elements, and they were represented with
different shades of colors (Fig. 10b). The analysis identiﬁes
similar correlations for the local motions of residues in the
dynamics of both the chains, which are principally evident for
residues in the loop α3–α2, as E76 and E81, in the loop α4–α5,
as R108, and in the helix α1, as R48. We identiﬁed regions with
dihedral angles correlated to the global activity that are com-
mon in the two chains, as in the loop α1, loop α3-α2, and helix
α1. Moreover, we detected evident differences in the identiﬁed
activity-correlated hinges for the two chains: in chain A, dihe-
dral angles localized around P75, E76, loop α4–α5, as G110,
and the C-terminal region of helix α5; in chain B, dihedral
angles localized around E81, loop α1–α2, as F50, and helix α1.
These long-range effects identiﬁed with TimeScapes in regions
of the SCAN domain that are not directly involved in the binding
with the partner monomer could be associated with distal effects
that can have a role also in the context of the full-length protein.
In summary, we showed that methods based on higher-order
statistics can be used to complement methods based only on analy-
sis of Cartesian coordinates, such as PCA, to get structural infor-
mation that are difﬁcult to obtain otherwise. On the other hand,
since the analyses carried out with TimeScapes depend on changes in
the protein contacts, events that do not alter them cannot be
442
Matteo Lambrughi et al.

accurately investigated. Moreover, this method requires simula-
tions in the micro/millisecond time-scale to provide meaningful
results, and it can be limited by sampling issues in MD simulations
or approximations in the force ﬁelds (see Note 4).
4.4
Contact-Based
View on Allostery:
Structural
Communication
Pathways
A short introduction to the concept of PSN is reported in
Subheading 3.5. Some notions are summarized here for the sake
of clarity. Each protein structure can be represented as a network of
noncovalent connections between residues. The network entity is
made of nodes and edges: in our case, the nodes are the side chains
of the protein residues, while the different types of noncovalent
pairwise interactions that may occur between them (i.e., hydrogen
bonds, salt bridges, and electrostatic interactions) are used for
deﬁnition of edges. It has been already established that such net-
works can be extremely useful in identifying clusters of amino acid
residues stabilizing the protein structure and protein–protein inter-
faces [86] through the calculation of some simple network proper-
ties, such as hubs and connected components. In the network
terminology, a hub is a highly connected node, namely, a node
touched by a signiﬁcant number of edges; on the other hand, a
connected component of a network is a sub-network of it, whose
nodes have no edges connecting them with other nodes of the full
network. In other words, each connected component of the net-
work is a cluster of nodes topologically isolated from the others. In
our case, the clustering procedure was performed so that each node
was iteratively assigned to a cluster if the node could establish at
least one link with another node belonging to the same cluster.
PSNs may be also investigated exploiting some prior knowl-
edge on pairs of distal residues known to allosterically inﬂuence
each other at the structural level (i.e., a modiﬁcation at a particular
protein site inducing conformational changes in distant sites).
Indeed, the shortest interaction path between the two residues
considered can be computed, displaying possible long-range struc-
tural communication pathways. We exploited a variant of the
depth-ﬁrst-search algorithm to compute the aforementioned short-
est path, deﬁned as the path in which the two residues were non-
covalently connected by the smallest number of intermediate
nodes.
We exploited the different functionalities of the PyInteraph
suite of tools [76] to create and analyze the PSN corresponding
to our MZF1 trajectory generated with the CHARMM27
force ﬁeld. We used this MD ensemble because it was the one
associated with the highest predicted structural resolution (see
Subheading 3.3).
First, we generated the network with the pyinteraph command,
specifying also the force ﬁeld used in the MD simulation
(CHARMM27) in order to correctly weigh the atomic masses.
Since the network builder only considers the centers of mass of
Analyzing Biomolecular Ensembles
443

the side chains, glycine residues were not included in the network
because of the absence of a side chain. The distance cutoff for the
interactions was set at 5.5 A˚ . All noncovalent interactions between
atom pairs were considered.
Subsequently, we ﬁltered the raw network by applying a “per-
sistence cutoff.” It affects the edges and accounts for the percent-
age of frames of the trajectory in which a particular edge is present
over the total number of frames. Edges with a persistence value
lower than the cutoff are deleted from the network. We applied a
cutoff of 20%, as done in previous cases of study [76, 87, 88].
Hence, we identiﬁed the hubs of our network, labeling as hub
every node touched by four or more edges (nodes with degree of
4 or higher), and the connected components. Both the tasks were
performed by using the graph_analysis command with the -u and -c
options for hubs and connected components, respectively. The
most signiﬁcant hubs found were L96(B) and L96(A), having
degree 7; A116(B), P58(A), A116(A), P112(B), V104(B), P58
(B) were hubs with a degree of 6. Those hubs are displayed in
Fig. 11. Hubs with a degree of 5 or less are not shown for clarity
purposes. Concerning the connected components, no signiﬁcant
cluster was identiﬁed.
Then, we calculated the shortest communication path between
the residues P58 and C69 of chain A of our homodimer. Indeed,
mutations of these two residues have been predicted to produce
detrimental effects in terms of free energy of binding and stability
of the monomer [8, 22]. P58(A) and C69(A) are also among the
hubs of the PSN, having a connectivity degree of 6 and 5, respec-
tively. C69 is central in the MZF1 network and has a key role in
long-distance communication paths, since it allows the SCAN
Fig. 11 Hubs of PSN. Both chain A and chain B are displayed as tubes whose
thickness corresponds to the degree of each node (i.e., residue). The thicker the
tube, the higher the degree. The color coding of both chains is consistent with
their thickness, ranging from light gray for low-degree nodes to black for hubs.
The most relevant hubs (degree equal to 6 or 7) are also labeled
444
Matteo Lambrughi et al.

dimerization region to mediate long-range effects to solvent
exposed sites, which might serve as a recruitment point for other
cofactors [22].
On the other hand, P58 is the residue whose substitution yield
the most deleterious consequences among the residues at the inter-
face between the two monomers.
The two shortest paths found between P58(A) and C69
(A) both have length of 6 and included A116(B), L62(A) and
V88(B) as second, third and ﬁfth node. Nonetheless, they differ
in assigning the fourth node: it is R66(A) in one case and P112
(B) in the other (as displayed in Fig. 12). Both the two terminals
and all intermediate nodes are located at the interface between the
two monomers, thus pointing toward the direction of a cross-chain
long-distance communication involved in the dimerization process.
This is also corroborated by the fact that A116(A) and P112(B) are
also among the most relevant hubs; furthermore, V88(B) is also a
hub of degree 4.
To visualize the hubs and the C69(A)-P58(A) path on the
corresponding protein structure, we used the xPyder [89] plugin
for the PyMOL molecular graphics software. Indeed, it is able to
Fig. 12 P58(A)-C69(A) communication paths. Chains A and B are displayed in
dark and light gray, respectively. The residues composing the paths are
highlighted in black and labeled, and the connections between them are
displayed as black lines. The four dotted lines represent the two alternative
paths passing through either R66(A) or P112(B). Both the chains are represented
as tubes whose thickness corresponds to the degree of each node (i.e., residue).
The thicker the tube, the higher the degree
Analyzing Biomolecular Ensembles
445

recognize and interpret the network ﬁles generated by PyInteraph
and visualize them on the corresponding PDB structure, thus
allowing a quick and informative structural overview.
4.5
Validation
of Long-Range
Communication Using
Enhanced Sampling
Approaches
The data collected using approaches such as TimeScapes (see Sub-
heading 4.3) or the analyses of paths of communication in the PSN
(see Subheading 4.4) can be used to identify potential regions
interested by long-range structural communication or even by
allosteric effects. The structural ensembles collected by unbiased
classical MD or other ensemble generation methods are often
limited by the sampling of conformation and ﬂexibility around
the starting structure or suffer remaining entrapped for a long
time in a local minimum. Enhanced sampling methods (see Part II
of this book) are available to provide a larger coverage of the
conformational space sampled by the protein during the simula-
tion, along with to simulate with high accuracy conformational
changes that are occurring on long time-scales, which are generally
the ones involved in allostery. In particular, methods based on the
metadynamics framework [20, 90–92] are very suitable to this
purpose since they allow to estimate with high accuracy different
conformational states of a biomolecule and the associated free-
energy proﬁles. In metadynamics, sampling is accelerated by a
history-dependent biased potential along a set of reaction coordi-
nates (i.e., collective variables or CVs) that capture the slowest
degree of freedom of the process/conformational change of inter-
est. In our application, we used the data from TimeScapes or Pyin-
teraph analyses as a guess of potential regions that are interested by
long-range communication and use this knowledge to design CVs
that allow to verify our hypotheses, with the advantage of
(a) assessing the existence of long-range coupling among two distal
regions, (b) ruling out issues due to poor sampling or entrapment
in very conﬁned regions of the free energy landscape, (c) ensuring a
proper description of different major and minor populated states of
a protein. An example of the integration of PSN analyses and high-
order statistics methods applied to unbiased MD with metady-
namics simulations is reported in our recent study of p53
[93]. Indeed, we have been able to identify a loop whose dynamics
are distally coupled to the one of the DNA-binding loops, alloste-
rically regulated by DNA-binding and post-translational modiﬁca-
tions and that acts as recruitment point for protein–protein
interactions with key players of p53 transcription-independent
functions, such as ku70 [93]. Moreover, as we recently applied
[35, 93], the integration of metadynamics studies designed after
a thorough study of unbiased MD runs could also be useful for
a better and more quantitative assessment of local changes, as
well as conformational states of residues that through a chain of
atom clashes could trigger the rearrangement from one protein
446
Matteo Lambrughi et al.

conformation to another. For more details, on metadynamics
approaches and a protocol to follow with the PLUMED library
see Part II and IV of this book, respectively.
5
Notes
1. After running a MD simulation, because the so-called “peri-
odic boundary conditions” are normally applied, the trajectory
needs to be processed and analyzed in order to check that these
conditions have not caused any artifact in the simulation. To
this aim, the trajectory is centered and the gmx mindist GRO-
MACS tool allows us to compute the minimum distance
between the atoms of the simulated system and their periodic
images. After making sure of this, it is necessary to assess the
sampling of the MD trajectory and we illustrated two different
parameters to do that. One way employs the “cosine content”
of the principal components derived from the PCA, while the
other one compares the RMSIP values of the two halves of the
trajectory.
2. The script to generate distribution plots of dihedral angles does
not work if the -all ﬂag is not used with the gmx chi command.
This allows us to generate .xvg ﬁles that are needed for the
Python script to run correctly.
3. Two important things should be kept in mind when using the
Jackknife method with PyInKnife. First, it is important to
calculate the RMSD if we want to use the jackknife implemen-
tation, which can be easily calculated with the GROMACS tool
gmx rms. The .xvg generated ﬁle will be used as a reference for
the time steps needed for the jackknife implementation. Sec-
ond, in order to perform the resampling of the trajectories, it is
necessary to have GROMACS installed since the gmx trjcat
tool is used for that purpose.
4. The implementations of TimeScapes can be used to obtain
structural information and description of sub-populations in
the ensemble collected by MD simulations. The limitation of
the method is that, since the analysis is based on changes in the
contacts between residues, biological events that have a small
impact on protein structure cannot be investigated. Moreover,
TimeScapes relies on the reliability of the trajectory under anal-
ysis, and it can be prone to approximations due to the force
ﬁeld used and potential sampling issues.
Analyzing Biomolecular Ensembles
447

Acknowledgments
This work was supported by two ISCRA-CINECA HPC Grants
(NetDyn-HP10C2TOOC
and
ALLO-PCM-HP10CWP9KW)
and two EU-PRACE DECI projects DECI-13th and DECI-14th
and DeiC Pilot Project in 2016–2017 on a Danish Infrastructure
Computerome. EP group is supported by LEO Foundation Grant
2017–2019 (grant number LF17006), Alfred Benzon Investigator
Fellowships 2017–2019, a DFF-FNU grant from the Danish
Council of Independent Research (grant number 7014-00272B),
and Carlsberg Foundation Distinguished Fellowship (grant num-
ber CF18-0314). EP group is also part of the Center of Excellence
for Autophagy, Recycling and Disease funded by Danmarks Grund-
forskningsfond (grant number DNRF125).
References
1. Dror RO, Dirks RM, Grossman JP et al (2012)
Biomolecular
simulation:
a
computational
microscope for molecular biology. Annu Rev
Biophys 41:429–452
2. Orozco M (2014) A theoretical view of protein
dynamics. Chem Soc Rev 43:5051–5066
3. Bonomi M, Heller GT, Camilloni C et al
(2017) Principles of protein structural ensem-
ble determination. Curr Opin Struct Biol
42:106–116
4. Piana S, Klepeis JL, Shaw DE (2014) Assessing
the
accuracy
of
physical
models
used
in
protein-folding simulations: quantitative evi-
dence from long molecular dynamics simula-
tions. Curr Opin Struct Biol 24:98–105
5. Karplus
M,
Kuriyan
J
(2005)
Molecular
dynamics and protein function. Proc Natl
Acad Sci U S A 102:6679–6685
6. Henzler-Wildman K, Kern D (2007) Dynamic
personalities of proteins. Nature 450:964–972
7. Bernado´ P, Blackledge M (2010) Proteins in
dynamic equilibrium. Nature 468:1046–1048
8. Papaleo E (2015) Integrating atomistic molec-
ular dynamics simulations, experiments, and
network analysis to study protein dynamics:
strength in unity. Front Mol Biosci 2:28
9. Grant BJ, Gorfe AA, McCammon JA (2010)
Large conformational changes in proteins: sig-
naling and other functions. Curr Opin Struct
Biol 20:142–147
10. Kay LE (2016) New views of functionally
dynamic proteins by solution NMR spectros-
copy. J Mol Biol 428:323–331
11. Papaleo E, Saladino G, Lambrughi M et al
(2016) The role of protein loops and linkers
in
conformational
dynamics
and
allostery.
Chem Rev 116:6391–6423
12. Villali J, Kern D (2011) Choreographing an
enzyme’s
dance.
Curr
Opin
Chem
Biol
14:636–643
13. Tzeng S-R, Kalodimos CG (2011) Protein
dynamics and allostery: an NMR view. Curr
Opin Struct Biol 21:62–67
14. Fujimoto A, Okada Y, Boroevich KA et al
(2016) Systematic analysis of mutation distri-
bution in three dimensional protein structures
identiﬁes cancer driver genes. Sci Rep 6:26483
15. Reimand J, Wagih O, Bader GD (2015) Evo-
lutionary constraint and disease associations of
post-translational modiﬁcation sites in human
genomes. PLoS Genet 11:e1004919
16. Reimand J, Wagih O, Bader GD (2013) The
mutational landscape of phosphorylation sig-
naling in cancer. Sci Rep 3:2651
17. Pon JR, a Marra M (2015) Driver and passen-
ger mutations in cancer. Annu Rev Pathol
Mech Dis 10:25–50
18. Allison JR (2017) Using simulation to inter-
pret experimental data in terms of protein con-
formational ensembles. Curr Opin Struct Biol
43:79–87
19. Spiwok V, Sucur Z, Hosek P (2015) Enhanced
sampling techniques in biomolecular simula-
tions. Biotechnol Adv 33:1130–1140
20. Abrams C, Bussi G (2013) Enhanced sampling
in molecular dynamics Using metadynamics,
replica-exchange,
and
temperature-
acceleration. Entropy 16:163–199
21. Eguchi T, Prince T, Wegiel B et al (2015) Role
and regulation of myeloid zinc ﬁnger protein
1 in cancer. J Cell Biochem 116:2146–2154
448
Matteo Lambrughi et al.

22. Nygaard M, Terkelsen T, Olsen AVet al (2016)
The mutational landscape of the oncogenic
MZF1 SCAN domain in cancer. Front Mol
Biosci 3:1–18
23. Rafn B, Nielsen CF, Andersen SH et al (2012)
ErbB2-driven
breast
cancer
cell
invasion
depends on a complex signaling network acti-
vating
myeloid
zinc
ﬁnger-1-dependent
cathepsin B expression. Mol Cell 45:764–776
24. Gaboli M, Kotsi PA, Gurrieri C et al (2001)
Mzf1 controls cell proliferation and tumori-
genesis service Mzf1 controls cell proliferation
and tumorigenesis. Genes Dev 15:1625–1630
25. Mudduluru G, Vajkoczy P, Allgayer H (2010)
Myeloid zinc ﬁnger 1 induces migration, inva-
sion, and in vivo metastasis through Axl gene
expression in solid cancer. In: Molecular cancer
research : MCR, vol 8, pp 159–169
26. Sander TL, Stringer KF, Maki JL et al (2003)
The SCAN domain deﬁnes a large family of
zinc
ﬁnger
transcription
factors.
Gene
310:29–38
27. Peterson FC, Hayes PL, Waltner JK et al
(2006) Structure of the SCAN domain from
the tumor suppressor protein MZF1. J Mol
Biol 363:137–147
28. Nam K, Honer C, Schumacher C (2004)
Structural
components
of
SCAN-domain
dimerizations. Proteins 56:685–692
29. Liang Y, Huimei Hong F, Ganesan P et al
(2012) Structural analysis and dimerization
proﬁle of the SCAN domain of the pluripo-
tency
factor
Zfp206.
Nucleic
Acids
Res
40:8721–8732
30. Noll L, Peterson FC, Hayes PL et al (2008)
Heterodimer formation of the myeloid zinc
ﬁnger 1 SCAN domain and association with
promyelocytic leukemia nuclear bodies. Leuk
Res 32:1582–1592
31. Sander TL, Haas AL, Peterson MJ et al (2000)
Identiﬁcation of a novel SCAN box-related
protein that interacts with MZF1B. J Biol
Chem 275:12857–12867
32. Lindorff-Larsen K, Best RB, Depristo MA et al
(2005) Simultaneous determination of protein
structure and dynamics. Nature 433:128–132
33. Shaw DE, Maragakis P, Lindorff-Larsen K et al
(2010) Atomic-level characterization of the
structural
dynamics
of
proteins.
Science
330:341–346
34. Lindorff-Larsen K, Maragakis P, Piana S et al
(2012) Systematic validation of protein force
ﬁelds against experimental data. PLoS One 7:
e32131
35. Papaleo E, Sutto L, Gervasio FL et al (2014)
Conformational changes and free energies in a
proline isomerase. J Chem Theory Comput
10:4169–4174
36. Piana S, Lindorff-Larsen K, Shaw DE (2011)
How robust are protein folding simulations
with respect to force ﬁeld parameterization?
Biophys J 100:L47–L49
37. Mackerell AD, Feig M, Brooks CL (2004)
Extending the treatment of backbone energet-
ics
in
protein
force
ﬁelds:
limitations
of
gas-phase quantum mechanics in reproducing
protein conformational distributions in molec-
ular dynamics simulations. J Comput Chem
25:1400–1415
38. Bjelkmar P, Larsson P, Cuendet MA et al
(2010) Implementation of the CHARMM
force ﬁeld in GROMACS: analysis of protein
stability effects from correction Maps, virtual
interaction sites, and water models. J Chem
Theory Comput 6:459–466
39. Best
RB,
Hummer
G
(2009)
Optimized
molecular dynamics force ﬁelds applied to the
helix-coil transition of polypeptides. J Phys
Chem B 113:9004–9015
40. Lindorff-Larsen K, Piana S, Palmo K et al
(2010) Improved side-chain torsion potentials
for the Amber ff99SB protein force ﬁeld. Pro-
teins 78:1950–1958
41. Li DW, Bru¨schweiler R (2010) NMR-based
protein
potentials.
Angew
Chem
Int
Ed
49:6778–6780
42. Jiang F, Zhou C-Y, Wu Y-D (2014) Residue-
speciﬁc force ﬁeld based on the protein coil
library. RSFF1: modiﬁcation of OPLS-AA/L.
J Phys Chem B 118:6983–6998
43. Lange OF, van der Spoel D, de Groot BL
(2010)
Scrutinizing
molecular
mechanics
force ﬁelds on the submicrosecond timescale
with NMR data. Biophys J 99:647–655
44. Unan H, Yildirim A, Tekpinar M (2015) Open-
ing mechanism of adenylate kinase can vary
according
to
selected
molecular
dynamics
force
ﬁeld.
J
Comput
Aided
Mol
Des
29:655–665
45. Tiberti M, Papaleo E, Bengtsen T et al (2015)
ENCORE: software for quantitative ensemble
comparison. PLoS Comput Biol 11:e1004415
46. Martı´n-Garcı´a F, Papaleo E, Gomez-Puertas P
et al (2015) Comparing molecular dynamics
force ﬁelds in the essential subspace. PLoS
One 10:e0121114
47. Costantini
S,
Paladino
A, Facchiano
AM
(2008) CALCOM: a software for calculating
the center of mass of proteins. Bioinformation
2:271–272
48. Daidone I, Amadei A (2012) Essential dynam-
ics: foundation and applications. Comput Mol
Sci 2:762–770
Analyzing Biomolecular Ensembles
449

49. Amadei A, Linssen AB, Berendsen HJ (1993)
Essential
dynamics
of
proteins.
Proteins
17:412–425
50. Hess B (2000) Similarities between principal
components of protein dynamics and random
diffusion. Phys Rev E 62:8438–8448
51. Papaleo E, Mereghetti P, Fantucci P et al
(2009) Free-energy landscape, principal com-
ponent analysis, and structural clustering to
identify
representative
conformations
from
molecular dynamics simulations: The myoglo-
bin case. J Mol Graph Model 27:889–899
52. Maisuradze G, Liwo A, Scheraga H (2009)
Principal component analysis for protein fold-
ing dynamics. J Mol Biol 385:312–329
53. Maisuradze GG, Leitner DM (2007) Free
energy landscape of a biomolecule in dihedral
principal component space: sampling conver-
gence and correspondence between structures
and minima. Proteins 67:569–578
54. Hess B (2002) Convergence of sampling in
protein simulations. Phys Rev E Stat Nonlin
Soft Matter Phys 65:031910
55. Mereghetti P, Riccardi L, Brandsdal BO et al
(2010) Near native-state conformational land-
scape of psychrophilic and mesophilic enzymes:
probing the folding funnel model. J Phys
Chem B 114:7609–7619
56. Yao X, Scarabelli G, Skjaerven L et al (2015)
Protein structure networks with Bio3D. Gran-
tlab, Manassas, VA, pp 1–22
57. Skjærven L, Yao X-Q, Scarabelli G et al (2014)
Integrating protein structural dynamics and
evolutionary analysis with Bio3D. BMC Bioin-
formatics 15:399
58. Lindorff-Larsen K, Ferkinghoff-Borg J (2009)
Similarity measures for protein ensembles.
PLoS One 4:e4203
59. Frey BJ, Dueck D (2007) Clustering by passing
messages
between
data
points.
Science
315:972–976
60. Agraﬁotis DK, Xu H (2002) A self-organizing
principle for learning nonlinear manifolds.
Proc Natl Acad Sci U S A 99:15869–15872
61. Michaud-Agrawal N, Denning EJ, Woolf TB
et al (2011) MDAnalysis: a toolkit for the anal-
ysis of molecular dynamics simulations. J Com-
put Chem 32:2319–2327
62. Ichiye T, Karplus M (1991) Collective motions
in proteins: a covariance analysis of atomic ﬂuc-
tuations in molecular dynamics and normal
mode simulations. Proteins 11:205–217
63. Hu¨nenberger PH, Mark AE, van Gunsteren
WF (1995) Fluctuation and cross-correlation
analysis of protein motions observed in nano-
second molecular dynamics simulations. J Mol
Biol 252:492–503
64. Lange OF, Grubmu¨ller H (2008) Full correla-
tion analysis of conformational protein dynam-
ics. Proteins 70:1294–1312
65. Tiberti M, Invernizzi G, Papaleo E (2015)
(Dis)similarity index to compare correlated
motions in molecular simulations. J Chem
Theory Comput 11:4404–4414
66. Seeber M, Felline A, Raimondi F et al (2011)
Wordom: a user-friendly program for the anal-
ysis of molecular structures, trajectories, and
free
energy
surfaces.
J
Comput
Chem
32:1183–1194
67. Invernizzi G, Tiberti M, Lambrughi M et al
(2014)
Communication
routes
in
ARID
domains between distal residues in helix 5 and
the DNA-binding loops. PLoS Comput Biol
10:e1003744
68. Berjanskii M, Zhou J, Liang Y et al (2012)
Resolution-by-proxy: a simple measure for
assessing and comparing the overall quality of
NMR protein structures. J Biomol NMR
53:167–180
69. Li D, Bru¨schweiler R (2015) PPM_One: a
static protein structure based chemical shift
predictor. J Biomol NMR 62:403–409
70. Guo J, Zhou HX (2016) Protein Allostery and
Conformational
Dynamics.
Chem
Rev
116:6503–6515
71. Ribeiro AAST, Ortiz V (2016) A Chemical
Perspective
on
Allostery.
Chem
Rev
116:6488–6502
72. Vuillon L, Lesieur C (2015) From local to
global changes in proteins: a network view.
Curr Opin Struct Biol 31:1–8
73. Di Paola L, Giuliani A (2015) Protein contact
network topology: a natural language for allo-
stery. Curr Opin Struct Biol 31:43–48
74. Vishveshwara S, Ghosh A, Hansia P (2009)
Intra
and
inter-molecular
communications
through protein structure network. Curr Pro-
tein Pept Sci 10:146–160
75. Csermely P, Nussinov R, Szila´gyi A (2013)
From allosteric drugs to allo-network drugs:
state of the art and trends of design, synthesis
and computational methods. Curr Top Med
Chem 13:2–4
76. Tiberti M, Invernizzi G, Lambrughi M et al
(2014) PyInteraph : a framework for the analy-
sis of interaction networks in structural ensem-
bles
of
proteins.
J
Chem
Inf
Model
54:1537–1551
77. Brown DK, Penkler DL, Sheik Amamuddy O
et al (2017) MD-TASK: a software suite for
analyzing molecular dynamics trajectories. Bio-
informatics 33:2768–2771
78. Salamanca Viloria J, Allega MF, Lambrughi M
et al (2016) An optimal distance cutoff for
450
Matteo Lambrughi et al.

contact-based protein structure networks using
side chain center of masses. Sci Rep 7:2838
79. Lovell SC, Word JM, Richardson JS et al
(2000) The penultimate rotamer library. Pro-
teins 40:389–408
80. Lange OF, Grubmu¨ller H (2006) Can princi-
pal components yield a dimension reduced
description of protein dynamics on long time
scales? J Phys Chem B 110:22842–22852
81. Wriggers W, Stafford KA, Shan Y et al (2009)
Automated event detection and activity moni-
toring in long molecular dynamics simulations.
J Chem Theory Comput 5:2595–2605
82. Savol AJ, Burger VM, Agarwal PK et al (2011)
QAARM:
quasi-anharmonic
autoregressive
model reveals molecular recognition pathways
in
ubiquitin.
Bioinformatics
(Oxford)
27:
i52–i60
83. Ramanathan A, Savol AJ, Agarwal PK et al
(2012) Event detection and sub-state discovery
from biomolecular simulations using higher-
order statistics: application to enzyme adeny-
late kinase. Proteins 80:2536–2551
84. Fan Z, Dror RO, Mildorf TJ et al (2015) Iden-
tifying localized changes in large systems:
change-point detection for biomolecular simu-
lations.
Proc
Natl
Acad
Sci
U
S
A
112:7454–7459
85. Kovacs JA, Wriggers W (2016) Spatial heat
maps from fast information matching of fast
and slow degrees of freedom: application to
molecular dynamics simulations. J Phys Chem
B 120:8473–8484
86. Brinda KV, Vishveshwara S (2005) A network
representation of protein structures: implica-
tions
for
protein
stability.
Biophys
J
89:4159–4170
87. Papaleo E, Renzetti G, Tiberti M (2012)
Mechanisms of intramolecular communication
in a hyperthermophilic acylaminoacyl pepti-
dase:
a
molecular
dynamics
investigation.
PLoS One 7:e35686
88. Papaleo E, Pasi M, Tiberti M et al (2011)
Molecular dynamics of mesophilic-like mutants
of a cold-adapted enzyme: insights into distal
effects induced by the mutations. PLoS One 6:
e24214
89. Pasi M, Tiberti M, Arrigoni A et al (2012)
xPyder: a PyMOL plugin to analyze coupled
residues and their networks in protein struc-
tures. J Chem Inf Model 279:1–6
90. Laio A, Gervasio FL (2008) Metadynamics: a
method to simulate rare events and reconstruct
the free energy in biophysics, chemistry and
material science. Rep Prog Phys 71:126601
91. Camilloni C, Cavalli A, Vendruscolo M (2013)
Replica-averaged metadynamics. J Chem The-
ory Comput 9:5610–5617
92. Bonomi M, Camilloni C, Vendruscolo M
(2016) Metadynamic metainference: enhanced
sampling of the metainference ensemble using
metadynamics. Sci Rep 6:31232
93. Lambrughi M, De Gioia L, Gervasio FL et al
(2016) DNA-binding protects p53 from inter-
actions
with
cofactors
involved
in
transcription-independent functions. Nucleic
Acids Res 44:9096–9109
Analyzing Biomolecular Ensembles
451

Chapter 19
Using Data-Reduction Techniques to Analyze
Biomolecular Trajectories
Gareth A. Tribello and Piero Gasparotto
Abstract
This chapter discusses the way in which dimensionality reduction algorithms such as diffusion maps and
sketch-map can be used to analyze molecular dynamics trajectories. The ﬁrst part discusses how these
various algorithms function as well as practical issues such as landmark selection and how these algorithms
can be used when the data to be analyzed comes from enhanced sampling trajectories. In the later part a
comparison between the results obtained by applying various algorithms to two sets of sample data is
performed and discussed. This section is then followed by a summary of how one algorithm in particular,
sketch-map, has been applied to a range of problems. The chapter concludes with a discussion on the
directions that we believe this ﬁeld is currently moving.
Key words Data analysis, Dimensionality reduction, Molecular dynamics, Sketch-map
1
Introduction
The ﬁrst molecular dynamics (MD) simulation of a biomolecule
was performed in 1977 [1]. The 9.2 ps trajectory for the bovine
pancreatic trypsin inhibitor that was extracted from this work and
the countless longer simulations that have followed have funda-
mentally changed our view of biomolecules. We now no longer
believe that proteins, DNA, and so on are simply rigid structures
and instead acknowledge that the dynamical motions of these
molecules are often critical to their functions. Dynamical simula-
tions are thus an essential tool when it comes to the study of these
complex structures. The problem, however, is that the trajectories
that emerge from these studies contain almost too much informa-
tion as they describe how the positions and velocities of all the
atoms within the biomolecule change as a function of time. On
top of this biomolecules, unlike simpler systems, have energy land-
scapes that are very complicated. Consequently, unlike crystalline
solids or clusters of indistinguishable atoms, biomolecules do not
normally undergo transitions that involve a change in symmetry. It
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_19, © Springer Science+Business Media, LLC, part of Springer Nature 2019
453

is therefore difﬁcult to ﬁnd the lowest energy conﬁguration for a
biomolecule and to thus develop a rationale for analyzing the
results from a simulation [2].
The lack of a simple theoretical framework based on symmetry
for rationalizing the behavior of all biomolecules together with the
abundance of dynamical information that can be easily extracted by
performing long molecular dynamics simulations has led many
researchers to use machine learning algorithms when analyzing
trajectories of biomolecules. In this chapter we will document
some of this work. Before discussing algorithms, however, we ﬁrst
note that it is important to think carefully about what information
emerges when these machine learning algorithms are used to ana-
lyze molecular dynamics trajectories. In essence all the algorithms
we will discuss in this chapter treat the trajectory as a set of high-
dimensional vectors. They then generate a representation of this
data that deﬁnitely has a lower information content by attempting
to capture the most important features from the input data. In
other words, all the algorithms we will discuss perform a data-
reduction operation on a set of high-dimensional vectors. In prac-
tice, this data-reduction operation is achieved by either:
1. Selecting a small number of representative points in this high-
dimensional space and asserting that the variations between
this small number of points describe all the important varia-
tions between the points in the larger input data set.
2. Generating projections of each of the high-dimensional vectors
in some lower dimensional space and assuming that the varia-
tion between the structures that is observed in the high-
dimensional space can be represented in this lower dimensional
space.
All the algorithms that are described in this chapter adopt one
of the above strategies or both strategies in combination. The
critical thing to remember, however, with both of these approaches
and, by extension about the algorithms that will be discussed in this
chapter, is that a mathematical model is used to reduce the high-
dimensional data. Using this model introduces assumptions about
the structure of the data as models cannot be ﬁtted to data without
making assumptions. Hence, when using method (1), we assume
that most of the trajectory frames will be clustered about one or
more representative structures. This assumption seems reasonable
given that we know from statistical mechanics that the system will,
at low temperature, for the most part remain close to the deepest
basins in the potential energy landscape. We should not forget the
so-called curse of dimensionality, however, and the fact that many
of the very-standard algorithms that we might use to analyze
low-dimensional data cannot necessarily be applied to high-
dimensional data [3].
454
Gareth A. Tribello and Piero Gasparotto

The theoretical case for using method (2) is much less well
established. Studies have shown that the dimension of the space
explored by a protein containing N atoms is considerably lower
than 3N, which is what would be expected based on the number of
degrees of freedom [4–9]. Furthermore, the fact that biomolecules
behave in predictable ways suggests that the potential constrains
these molecules to explore only a small fraction of conﬁguration
space. Importantly, however, the assumption in many data-
reduction algorithms of type (2) is that the biomolecule can only
adopt conﬁgurations that lie on a low-dimensional linear or
non-linear manifold. This assumption is considerably stronger
than the assertion that the system is conﬁned in a small region of
conﬁguration space. The system might, for instance, be conﬁned in
a region with a low fractal dimension, which cannot be represented
in a low-dimensional Euclidean space [10].
This brings us to the most critical piece of advice we would give
to a person just starting out with these algorithms. The techniques
described in this chapter are tools for visualizing the data contained
in a trajectory. It is very important to understand how they function
and what assumptions they make. Most critically, however, these
algorithms are not a replacement for chemical or physical intuition.
When used well though they may enhance our ability to make leaps
in understanding by clearing away distractions.
2
Theory
There are many excellent books, papers, and online resources on
machine learning that cover the wider theory of these dimension-
ality reduction algorithms [11–13]. What we will thus do here is
provide a summary of the important considerations that must be
taken into account when using these algorithms to analyze trajec-
tory data. In particular, we will discuss how the data should be
collected in Subheading 2.1. We will then talk about what is input
into these algorithms in Subheading 2.2 and how a subset of the
so-called landmark points can be selected in Subheading 2.3 before
describing how the algorithms operate in Subheading 2.4. In addi-
tion, to presenting this material we will show a number of case
studies that demonstrate the way these algorithms have been used
to analyze trajectories of biomolecules. We will then ﬁnish by spec-
ulating on the general direction in which we believe the ﬁeld is
moving.
2.1
Step 1: Collecting
Some Data
Obviously, we cannot perform any form of machine learning with-
out ﬁrst collecting some data. The ﬁrst thing we must then consider
is the manner in which the data is collected. For the purposes of this
chapter we will assume that data has been generated by performing
a molecular dynamics simulation [14, 15]. As has been discussed at
Dimensionality Reduction for Molecular Dynamics
455

length in many of the other chapters in this book, however, collect-
ing representative data on the regions of conﬁguration space that a
biomolecule typically samples from in this way is not straightfor-
ward. The problem is that there are often large barriers that prevent
the molecule from diffusing freely around all of conﬁguration
space. These barriers are typically not crossed during short molecu-
lar dynamics simulations and thus conﬁguration space is only par-
tially sampled. The consequence of this when we run our machine
learning algorithm on the generated data is that the simpliﬁed view
that we construct only gives a partial insight into the structure of
conﬁguration space. There is, obviously, no guarantee that any
representation extracted from this data gives a reasonable represen-
tation for the parts of conﬁguration space that were not sampled
during the molecular dynamics trajectory.
Other chapters in this book discuss a range of enhanced sam-
pling algorithms that allow us to resolve this timescale problem.
When these algorithms are used we change the manner in which the
system samples conﬁguration space by either adding a simulation
bias to the potential or by adding new ways for the system to move
around in conﬁguration space. Furthermore, when these techni-
ques are used free energy differences and barrier heights for the
unbiased ensemble can be extracted by exploiting reweighting
techniques. These reweighting methods are important in the con-
text of machine learning as they should be used when data gener-
ated using an enhanced sampling technique is analyzed using a
machine learning algorithm.
Ultimately, we know from elementary statistical mechanics
that, if a protein is at equilibrium, we can think of the conﬁguration,
X, that it adopts at any given instance in time as a random vector
taken from some high-dimensional probability distribution P(X)
that depends on the macroscopic state, which in this case means
that it depends on the number of atoms, N, the volume, V , and the
temperature, T. We can thus think of the conﬁgurations sampled
during an unbiased molecular dynamics simulation as a series of
random vectors, {Xi}, that are generated from P(X). Furthermore,
when we analyze an unbiased molecular dynamics simulation using
a machine learning algorithm we exploit the law of large numbers
and the central limit theorem and assume that the distribution of
sampled vectors provides us information on this probability distri-
bution P(X). When we use an enhanced sampling algorithm, how-
ever, the conﬁgurations sampled can no longer be thought of as
random vectors generated from P(X). The problem with doing so
is that to achieve the greater rates of sampling we changed the
Hamiltonian or the thermodynamic constraints. The conﬁgura-
tions generated from these enhanced sampling trajectories are
thus samples from some other probability distribution, P0(X). All
is not lost, however, because, as discussed in the other chapters of
this book, there are simple recipes from extracting information on
456
Gareth A. Tribello and Piero Gasparotto

P(X) from a set of samples of P0(X). The way these methods work is
illustrated in Fig. 1. To generate the right panel of this ﬁgure we
generated 20 random variables from the probability distribution,
P(x), that is shown using a black line. The values of these random
variables are indicated using blue dots on the x axis of the ﬁgure. A
kernel density estimation was then performed using these points as
input in order to generate the estimate of the probability density
function that is shown inverted and in red in the ﬁgure. To generate
the middle panel we instead generated points using the probability
distribution, P0(x), that is shown in green in the central panel of the
ﬁgure. The 20 random variables generated from this distribution
are once again shown in green and you can see that the estimate of
the probability density that we construct by performing a kernel
density estimation using this data bears no resemblance to the black
0.3
0.2
0.1
0.0
–0.1
P(x)
–0.2
–0.3
–5
0
5
–5
0
5
–5
0
5
5
10
15
20
weight of point
x
x
x
Fig. 1 Figure illustrating how we can use reweighting algorithms to extract
information on the unbiased distribution from a biased trajectory. The black line
in the right panel shows a probability distribution and a set of blue dots that
represent 20 samples that we have generated from this distribution. The red line
then shows the estimate of the probability density that we extract when we
perform a kernel density estimation using this data. The middle panel shows
something similar but this time we have generated our blue samples from the
distribution shown as a dashed green line. Consequently, the estimate of the
probability density that we get by performing a kernel density estimation using
this data (red line) resembles the green line and not the black line. In the third
panel, however, we show that if we ascribe a weight to each of the points
sampled from the green distribution using the formula in the text we can recover
a probability density function from kernel density estimation (red line) that
resembles the black curve. The substantial differences between the underlying
distributions and the estimates we get from kernel density estimation are due to
the limited sampling, which is something that would also need to be considered
when analyzing trajectory data
Dimensionality Reduction for Molecular Dynamics
457

line, P(x), and instead resembles the green dashed line, P0(x). The
third panel of the ﬁgure shows, however, that if we ascribe a weight:
wi ¼ PðxiÞ
P0ðxiÞ
to each of the points generated, xi, we can recover the probability
distribution P(x) even if we sample from P0(x). In this ﬁnal panel the
points sampled from P0(x) are shown on the x-axis once more and
are colored according to the value of wi. The estimate of the
probability density function that is shown in red is then calculated
using:
X
N
i¼1
wiKðxiÞ
where the sum runs over the number of data points generated and
where K is a Gaussian kernel. As you can see the estimated proba-
bility density function in this ﬁnal panel resembles the black line,
P(x). Consequently, if we analyze appropriately weighted conﬁg-
urations using a machine learning algorithm the representation that
is extracted provides information on P(X). In the remainder of this
chapter we will thus assume that the input to our machine learning
algorithm consists of a set of high-dimensional vectors, {Xi}, and a
set of associated weights {wi}. If the data to be analyzed comes from
an unbiased molecular dynamics trajectories these weights are all set
equal to one. We need to have this ﬂexibility to give the vectors
different weights, however, in order to deal effectively with data
from enhanced sampling trajectories.
2.2
Step 2:
Representing the Data
In the previous section we discussed the collection of data from
biased and unbiased molecular dynamics trajectories in abstract
terms. The trajectories output from these methods were thought
of as a set of random high-dimensional vectors with associated
weights. In this section we will discuss more precisely what infor-
mation we might want to collect in these vectors. The key point is
that we want to throw away information that we know is irrelevant
at an early stage as otherwise any interesting signal that we might
detect with a machine learning algorithm will be lost in a sea of
noise. As an example, if we were simulating the dynamics of a
protein in water, we could simply collect the positions of all the
protein and water atoms in the system. This is probably self-
defeating, however, as the number of atoms of water outnumbers
the number of protein atoms by far and our interest is in the
behavior of the protein and not the water. With this in mind we
should thus probably only collect information on the positions of
the protein atoms. Even this might be more than we require,
however. The trajectory for all the protein atoms probably contains
a signiﬁcant amount of noise that describes the small ﬂuctuations of
458
Gareth A. Tribello and Piero Gasparotto

the atomic positions around equilibrium positions, whereas we are
probably more interested in larger-scale, global motions that result
in a signiﬁcant change in the protein’s conformation. We might,
therefore, be tempted to throw away most of this information on
the atomic positions and to instead collect only the values of the
backbone torsional angles.
The point we are trying to make is this: you shouldn’t disregard
your physical or chemical intuition just because you are using a
machine learning algorithm. In other words, these algorithms
should be used to complement your intuition about the system in
question and not to replace it. The plain fact is that you are more
likely to get an informative projection of your trajectories if you use
what you know to ensure that there is not too much noise in the
input data.
Figure 2 illustrates a further consideration that is important
when it comes to the representation of the trajectory. Remember
that when we use a machine learning algorithm to analyze a trajec-
tory, {Xi}, what we are essentially trying to illustrate is how these
random vectors are distributed in relation to each other. There are,
however, three different ways that we can illustrate these relations
in the high-dimensional space. In particular:
1. We can use a vector, Xi, of ﬁngerprints to represent each of the
conﬁgurations. The various components of this vector repre-
sent the projections of the vector connecting the origin and the
point Xi on some arbitrarily chosen axes.
2. We can use a dissimilarity matrix, D, in which element Dij gives
the distance between conﬁguration i and conﬁguration j. This
distance can be calculated using any metric.
Fig. 2 Figure illustrating the three possible representations of the data contained
in a trajectory that can be used as the input in these dimensionality reduction
algorithms. The data can either be represented as in panel (a) by using a set of
ﬁngerprint vectors, X, that describe the positions of the trajectory frames in some
feature space. Alternatively, and as shown in panel (b), the dissimilarity, D,
between each pair of conﬁgurations can be computed and stored in a matrix.
Lastly, as is also shown in panel (b), the inner product, K, between each pair of
ﬁngerprints can be computed and these quantities can be stored in a Gram
matrix
Dimensionality Reduction for Molecular Dynamics
459

3. We can use a Gram matrix, K in which element Kij gives the
inner product between the vectors of ﬁngerprints for conﬁg-
urations i and j.
It is straightforward to convert between these three different
ways of representing the data. For instance, if you are given vectors
of ﬁngerprints you can clearly compute the matrices of inner pro-
ducts, K, or the matrix of distances, D. What is perhaps less obvious
is that you can compute a matrix of inner products, K, from a
matrix of distances, D, and that you can convert any matrix of
inner products into a set of vector ﬁngerprints. To convert the
matrix of distances into a matrix of inner products we exploit the
fact that we can write the (i, j)-element of the matrix of squared
distances as follows:
D2
i j ¼
X
α
ðXðiÞ
α  XðjÞ
α Þ2 ¼
X
α
ðXðiÞ
α Þ2 þ ðXðjÞ
α Þ2  2XðiÞ
α XðiÞ
α
ð1Þ
where the symbolXðiÞ
α is used to represent the αth component of the
vector of ﬁngerprints for conﬁguration i. Notice that the ﬁnal term
in this expression is the (i, j)-element of the Gram matrix of dot
products, K, that we require. Furthermore, the ﬁrst and second
terms are independent of j and i, respectively. We can thus rewrite
the matrix of dissimilarities D as (see Note 1):
D ¼ c1T þ cT 1  2K
ð2Þ
In this expression c and 1 are column vectors containing the same
number of elements as there are rows in D. All the elements of 1 are
equal to 1 and the ith element of c is equal to P
αðX ðiÞ
α Þ2. We now
introduce the centering matrix:
J ¼ I  1
M 11T
ð3Þ
where I is the identity and M is the number of rows in D. This
centering matrix is useful because if D is multiplied from the front
and back by  1
2 J we recover the Gram matrix of kernels modulo an
additive constant (see Note 2).
Extracting vectors of ﬁngerprints from a Gram matrix is simi-
larly straightforward. To do so we begin by considering a rectangu-
lar matrix, X, that contains the ith vector of ﬁngerprints in its ith
column. The Gram matrix can be calculated from X by computing
the following product of matrices:
K ¼ XT X
ð4Þ
The matrix K that we compute in this way is symmetric and has all
real elements so we can thus exploit the spectral decomposition for
symmetric matrices and write:
460
Gareth A. Tribello and Piero Gasparotto

K ¼ VΛVT
ð5Þ
where Λ is a diagonal matrix containing the eigenvalues of K and
where V is a matrix containing the corresponding eigenvectors in
its columns. Comparing Eqs. 4 and 5 we thus ﬁnd that the matrix of
ﬁngerprints is given by:
XT ¼ VΛ
1
2
In other words, the eigenvectors of the Gram matrix can serve as a
basis on which we can project each of our conﬁgurations. Further-
more, this process of collecting ﬁngerprints, calculating a matrix of
dissimilarities between them using Pythagoras’ theorem, centering
this matrix, and then diagonalizing it can be seen as equivalent to
principal component analysis in that it is simply a rotation of the
reference frame on which we are projecting our ﬁngerprint vectors.
The fact that we can prove that these three ways of representing
the high-dimensional data are all equivalent may feel like a pointless
exercise in linear algebra. After all, you may ask, wouldn’t we always
collect a vector of ﬁngerprints from the trajectory? In other words,
are we not always computing D and K from ﬁngerprint vectors?
The answer to this is yes but in an equally real sense no as, although
we do always collect vectors of data, we may choose to not calculate
the matrix of dissimilarities, D, between these vectors by simply
using Pythagoras theorem as we did in Eq. 1. For example, we
might choose to calculate the (i, j) element of Dij by taking the root
mean square deviation between the positions of the atoms in frame
i and frame j in a way that removes the motion of the center of mass
and the rotation of the reference frame [16]. Alternatively, in the
manifold learning method known as ISOMAP, the dissimilarities in
the matrix D are representative of the geodesic distances between
trajectory frames [17, 18]. In both these cases the vectors that
emerge are thus no longer related to the vectors that were collected
from our trajectory by a rotation.
An even more interesting case is presented in the method
known as kernel principal component analysis [19]. This method
was developed based on the observation that, although it may not
be possible to linearly separate N points in d < N dimensions, it
will almost always be possible to do so in d  N dimensions. This
method thus argues that we should thus begin by mapping each of
the points, xi, in our d < N dimensional space into an N-dimen-
sional space using some function Φ such that:
ΦðxiÞ,
where
Φ : d ! N
The problem is that we do not know how this mapping should be
done in practice. This difﬁculty is avoided in kernel-PCA, however,
which exploits the so-called kernel trick. This trick relies on the fact
that certain functions, k, of pairs of vectors, for example,
Dimensionality Reduction for Molecular Dynamics
461

kðx, yÞ ¼ expðjx  yjÞ, can be expressed as inner products in a
high-dimensional space. In other words:
kðx, yÞ ¼ ΦðxÞT ΦðyÞ
In practice what this relation means for kernel PCA is that we do
not need to determine the mapping Φ(xi). Instead we can calculate
the Gram matrix by evaluating k(x, y) for each pair of conﬁgura-
tions from our trajectory. By diagonalizing the Gram matrix we
thus get vector ﬁngerprints, Φ(xi), for each of the conﬁgurations in
our trajectory. Once again, however, the set of operations that we
perform when we use this method is not equivalent to a rotation of
the basis vectors. What we are doing instead, albeit indirectly, is
projecting the data into some higher dimensional space.
In summary two important points have been covered in this
section:
l
The high-dimensional data collected from a trajectory is often
noisy. Much of this noise is due to thermal ﬂuctuations that are
not that interesting, however. Consequently, only data that is
believed to be relevant to the phenomenon should be collected
from the trajectory. Many dimensionality reduction algorithms
can deal with noise but if there is a lot of noise in your trajectory
it becomes increasingly unlikely that you will see anything inter-
esting when it is analyzed.
l
The high-dimensional data collected from a trajectory can be
represented using either vectors of ﬁngerprints, a dissimilarity
matrix, or a Gram matrix. It is possible to convert between these
various representations, which is important because, as we shall
see in Subheading 2.4, many dimensionality reduction algo-
rithms work by simply converting between these various
representations.
2.3
Step 3: Selecting
Landmarks
Many of the algorithms that can be used to analyze trajectory data
scale quadratically or cubically with the number of input vectors.
Consequently, these algorithms cannot be used to analyze all the
structures in a molecular dynamics trajectory as the associated
computational expense would be too large. One must, therefore,
select a small number of representative, landmark structures to
analyze using the expensive algorithm. Furthermore, it is useful to
have an out-of-sample algorithm that allows you to construct a
representation for any conﬁguration that is outside this initial train-
ing set as you can then adopt a work ﬂow like that shown in Fig. 3.
In other words, you can ﬁrst analyze a small fraction of the input
data points using the expensive algorithm and then analyze the
remainder of the points using the cheaper out-of-sample method.
The simplest method for reducing the number of high-
dimensional vectors from {Xi} that have to be analyzed is to ran-
domly select a smaller number of points from the input data set. If
462
Gareth A. Tribello and Piero Gasparotto

one is analyzing a molecular dynamics trajectory that has output
10,000 frames this is very straightforward. A random selection of
1000 vectors can be obtained by simply taking every 10th vector
from the larger data set. Life is made slightly more complex if one is
analyzing data from an enhanced sampling trajectory because, as
discussed in Subheading 2.1, the weights, wi, associated with the
random vectors are no longer all equal to one. These weights
should thus be considered when drawing landmark points as the
distribution of landmarks should be consistent with the probability
distribution of interest P(X). Incorporating these weights is not
difﬁcult, however [20]. The python code below explains how
N points can be drawn from a list of random vectors, R, with
weights in a second list, W, in practice.
Fig. 3 Figure illustrating a workﬂow that is often used when dimensionality reduction algorithms are used to
analyze a trajectory. In panel (a) of this scheme a trajectory is collected that describes how all the atom
positions change as a function of time. As discussed in the early parts of Subheading 2.2 it is often beneﬁcial
to calculate a large number of descriptors that describe the processes that you are interested in instead of
working with the positions of all the atoms in the trajectory directly. This is thus what is illustrated in panel (b)
above. Once we have this high-dimensional representation we then analyze all the input data in order to set
the hyperparameters for the dimensionality reduction algorithm as shown in panel (c). Furthermore, as
indicated by the red arrow connecting panels (b) and (d) we also select a subset of so-called landmarks
points to analyze. The blue arrow connecting panels d and e indicates that only the landmark points are
analyzed using the dimensionality reduction algorithm. As shown in panel (f) Projections for the remainder of
the trajectory are found using an out-of-sample procedure that takes the projections that were found for the
landmarks (green arrow) and the high-dimensional descriptions for all the points in the trajectory as input
Dimensionality Reduction for Molecular Dynamics
463

Listing 1
Selecting landmarks at random:
def select_random (
N,
W ,
R
)
:
# Calculate sum of all weights
totw
=
sum (
W
)
tt ,
landmarks
=
0 ,
[ ]
for i in range (0 ,N) :
# Generate a random number between 0 and the
total
weight
# of the unselected points
tw,
rand
=
0 , (totw- tt) * random . uniform (0, 1)
for
j
in range (0 , len (R) ) :
# Make sure each landmark
is only selected once
if
R[ j ]
in landmarks
:
continue
tw
+=
W [ j ]
if
rand
<
tw
:
landmarks . append (R[ j ] )
tt
+=
W [ j ]
break
return landmarks
Oftentimes selecting landmark conﬁgurations at random is not
optimal. For example, suppose that the trajectory samples from a
deep basin in the energy landscape and the surrounding, higher-
energy regions. If the landmark points are selected at random they
will be distributed in space in a manner that is consistent with the
probability distribution P(X). Consequently, the majority of the
selected landmarks will lie inside the basin and very few landmarks
from the higher-energy regions that surround the basin will be
selected. This selection would not be ideal as any lower dimensional
representation generated by analyzing these landmarks may not
provide a good description outside of the basin as the algorithm
was provided with no data in these regions. For these reasons a
popular alternative to using random sampling of landmarks is to use
a method known as farthest point sampling (FPS) [21]. As the
name suggests this method tries to select the most widely spread
set of landmarks from the input random vectors. In other words,
the ﬁrst landmark, L1, is selected at random and the remaining
landmarks are selected from the set of all random vectors, {Ri},
using the following deterministic criteria:
Ljþ1 ¼
max
R∈fRig
min
kj jLk  Rj
where |Lk  R| is the dissimilarity between the random vectors Lk
and R. A sample python code that performs farthest point sampling
is provided below. In this code it is assumed that the function
distance returns the dissimilarity between two random vectors.
464
Gareth A. Tribello and Piero Gasparotto

Listing 2
Farthest point sampling:
def
farthest_point_sampling (
N,
W ,
R
)
:
#
Select
the
first
landmark at random
ll = select_random (1, W, R)
landmarks
=
[
l l [ 0 ]
]
for
i
in range (1 ,N) :
# The outer loop ensures that the new landmark
is
the
#
vector that is furthest from the
set
of
landmarks that
have
# been selected thus far.
maxd =
0.0
for
rr in R :
# The inner loop here finds the minimum distance
# between data point rr and the set
of landmarks that
# have been selected thus far .
mind =float ( ‘ I n f i n i t y ’ )
for ll in landmarks :
if
distance ( ll , rr ) < mind : mind =
distance
(ll , rr )
if mind > maxd :
maxd = mind
tland =
rr
landmarks . append ( tland )
return landmarks
Selecting landmarks using FPS is an improvement on selecting
landmarks at random because, as shown in the top part of Fig. 4, by
using this algorithm we ensure that all the areas of phase space that
were sampled during the trajectory are represented in the ﬁnal set of
landmark points. One disadvantage, however, is that the distribu-
tion of landmarks that we get from this procedure no longer
provides information on P(X). We can, however, resolve this prob-
lem by giving each of the landmark points, {Lj}, generated using the
FPS algorithm a weight. These weights, {ωj}, can be generated
from the weights, {wi}, of the input data points, {Ri}, using a
Voronoi diagram as follows:
ωj ¼ P
wi for all vectors in Ri that have jRi  Ljj < jRi  Lkj
8
k 6¼ j
A sample python code that calculates the Voronoi weights for the
landmarks in the list L from a list containing the input random
vectors R and a list containing the weights of those vectors W is
provided below. Notice that this code also calculates the set of
random vectors that is in each of the Voronoi polyhedra and that,
as in the previous code, the function distance returns the dissimilar-
ity between two random vectors.
Dimensionality Reduction for Molecular Dynamics
465

Listing 3
Calculating Voronoi weights:
def voronoi_weights ( L, R, W )
:
weights
=
[ 0 ] * len (L)
points
=
[ [ ] ] * len (L)
# Loop over
a l l
random
vectors
in data
set
for i in range (0 , len (R) )
:
nearest ,
mind
=
0 ,
distance ( L[ 0 ] ,
R[ i ]
)
# Find
closest
landmark to
ith
random vector
for
j
in range (1 , len (L) )
:
dist
=
distance ( L[ j ] ,
R[ i ]
)
if ( dist <
mind )
:
mind
=
dist
nearest
=
j
# Add weight of ith random vector
# to weight of closest landmark
Fig. 4 Figure showing how the various landmark selection algorithms perform on model data. Panel (a) shows
a set of data points that were generated by sampling from three 2D normal distributions. The remaining panels
then show the set of landmarks that are selected from this data set with each of the algorithms described in
the text together with a representation of the three normal distributions that the original data was generated
from. As you can see from panel (b) if random sampling is used the selected landmarks are concentrated in
the regions where the density of points is highest. When FPS is used in panel (c), by contrast, the points are
uniformly distributed across the whole space. Panels (d), (e) and (f) show that adjusting the γ parameter in the
well-tempered farthest point sampling algorithm allows you to interpolate between these two behaviors and to
control the degree to which the points are spread out
466
Gareth A. Tribello and Piero Gasparotto

weight [ nearest ]
+=
W [ i ]
# Also add the
ith
random vector to the
list
of
# random vectors that are assigned to this landmark
points [ nearest ] . append (R[ i ] )
return weights, points
A slight concern when using FPS sampling to draw landmarks is
that the algorithm is rather sensitive to outliers. To resolve this
problem we thus developed a procedure that combines the
strengths of FPS and random sampling of landmarks and that
involves a two-stage selection process [22]. When this procedure
is used to select M landmarks from a set of N random vectors the
ﬁrst of these stages involves selecting K ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
NM
p
vectors using
farthest point sampling. The top right panel in Fig. 4 demonstrates
that it is reasonable to assume that these points are distributed
uniformly across the space so we can further assume that all the
Voronoi polyhedra have the same volume and that the quantity:
Pi ¼
ωi
PK
j¼1 ωj
ð6Þ
thus provides a measure of the probability density in the vicinity of
the center of the polyhedron. In this expression ωi is the weight of
the ith landmark, which is calculated from the weights of the data
points that were input {wi} using the Voronoi procedure that was
outlined in the previous paragraph. It is interesting to note that, if
we now select M points by ﬁrst picking a Voronoi polyhedron by
performing a random sampling using the weights of the polyhedra
and if we then select one of the random vectors that is within that
Voronoi polyhedron at random, we recover the random sampling
method albeit via a rather convoluted route. More intriguingly,
however, we can modify the weights calculated using Eq. 6 using
the expression below:
P0
i ¼ Pγ
i
and thus introduce a parameter, γ, that allows us to smoothly
interpolate
between
random
and
farthest
point
sampling
[23, 24]. In particular, and as shown in the bottom part of Fig. 4,
when γ < 1 the procedure is more likely to select landmarks in the
vicinity of the densely sampled regions of the space. By contrast
setting γ > 1 encourages the algorithm to ignore the underlying
probabilities and to pick a set of landmarks that are more uniformly
distributed over the space.
A function that provides an implementation of this so-called
well-tempered farthest point sampling algorithm and that takes as
input the value of the γ parameter, g, the ﬁnal number of landmarks
required, N, a list of random vectors, R, and their associated
weights, W, in python is provided below:
Dimensionality Reduction for Molecular Dynamics
467

Listing 4
Selecting landmarks using the well-tempered farthest point
sampling algorithm:
def wtfps_landmark_selection ( g ,
N,
R,
W
)
:
K = int ( sqrt (len (R)* N) )
#
Select
K landmarks using FPS
fps_l = farthest_point_sampling (
K,
R,
W
)
# Calculate voronoi weights of fps landmarks and assign each of
# the input random vectors to its associated voronoi polyhedron
fps_w ,
fps_p
=
voronoi_weights (
fps_l ,
R,
W
)
# Modify the weights. We assume here that the sum of all
# the weights in W
i s
equal to one
for w in fps_w
:
w
=
w**g
# Create a list containing the indices of the voronoi polyhedra
fps_i
=
[ ]
for
i
in range (0 ,k)
:
fps_i . append ( i )
# Now
actually
select
the
final
landmarks
landmarks
=
[ ]
for i in range (0 ,N) :
# Get the index
of
the Voronoi polyhedron from which the
# landmark will be selected
myv
=
select_random ( 1 , fps_w ,
fps_i
)
# Create a list of weights for all the random
vectors
in
# this polyhedron. All these weights should be set equal
# to one.
poly_weights
= len ( fpos_p [myv [ 0 ] ] ) * [ 1 ]
# Now
select one of the random
vectors in the
# previously-selected Voronoi polyhedron
selection = select_random ( 1 , poly_weights ,
fps_p [myv [ 0 ] ]
)
# Add the
selected
landmark to the final list. Notice that
# code should be added here so that one random
# vector is not added to the list of landmarks multiple
# times.
landmarks . append ( selection [ 0 ] )
return landmarks
To summarize we often have to run these dimensionality reduc-
tion algorithms on a subset of landmark points from the input data
set as these algorithms are expensive. There are three methods we
can use to select landmarks:
1. Random sampling which involves selecting points at random
from the input data set.
2. Farthest point sampling which gives us a set of widely spread
landmarks.
468
Gareth A. Tribello and Piero Gasparotto

3. Well-tempered farthest point sampling which provides a
single parameter γ that allows us to interpolate between ran-
dom and farthest point sampling.
In addition, we can ascribe a weight to each of the landmark
points we select by using a procedure based on Voronoi diagrams.
This procedure allows one to recover the information on the prob-
ability distribution P(X) that is encoded in the distribution of the
input random vectors.
2.4
Step 4:
Dimensionality
Reduction
In the preceding three sections we discussed how we can run
molecular dynamics or enhanced sampling calculations to generate
biomolecular trajectories. We then discussed how this trajectory
data can be represented using either a matrix that measures the
dissimilarities between each pair of input trajectory frames or by
using one high-dimensional vector of structural ﬁngerprints to
represent each frame from our trajectory. Knowing that each tra-
jectory frame can be represented using a high-dimensional vector is
critical when it comes to understanding how these dimensionality
reduction algorithms work. In fact, many of these algorithms work
by orthogonalizing and rotating the basis in which these ﬁngerprint
vectors are represented so that the ﬁrst few vectors in the new basis
set describe the majority of the variability in the input data set. The
fact that this mode of operation is true of algorithms such as
principal component analysis (PCA), which take the ﬁngerprint
vectors as input, is obvious [12]. What is less obvious, however, is
that methods such as metric multidimensional scaling (MDS),
which take a matrix of dissimilarities as input, also work in this
way because, as discussed in Subheading 2.2, we can convert any
matrix of dissimilarities into a set of high-dimensional, ﬁngerprint
vectors [11].
Clearly, given the arguments in the previous paragraph, much
about dimensionality reduction algorithms can be gleaned from an
understanding of the PCA algorithm. To understand how this
algorithm works consider the n centered, ﬁngerprint vectors indi-
cated using the black crosses in Fig. 5. The coordinates of each of
these black crosses can be included in a ﬁngerprint vector that has
m components in total. We can thus put all these vectors into an
n  m matrix, M, that has one ﬁngerprint vector in each of its rows.
We can then calculate the projections of the n ﬁngerprint vectors in
M on any arbitrary m-dimensional, unit vector w using:
t ¼ Mw
ð7Þ
This process of taking projections on an arbitrary vector, w, is
illustrated in Fig. 5 for two of the ﬁngerprints. The projections of
these two ﬁngerprints on the vector, w, which is shown as a red line,
are indicated. When we do the operation above for all of the
ﬁngerprint vectors we obtain an n-dimensional vector, t, that
Dimensionality Reduction for Molecular Dynamics
469

contains the n projections. Furthermore, the squared norm of this
vector |t|2 is only large when the unit vector w encodes a great deal
of the variability for the vectors in M. Performing dimensionality
reduction effectively is thus a matter of ﬁnding the unit vector w for
which the norm of the vector t is maximal. In other words, we
search over all possible unit vectors, w, and solve the following
optimization problem:
arg max
jwj¼1 wT MT Mw


In Fig. 5 the optimal choice for the vector w is shown as a blue line.
As you can see the projections of the two chosen points on this blue
line are both larger than the projections on the red line. This
optimal choice for the vector w can be easily found by remember-
ing that the ﬁngerprint vectors in M are centered and that as such
the matrix MTM is nothing more than the m  m covariance
matrix, C. We can thus reformulate the problem as an optimization
of wTCw subject to the constraint that wTw ¼ 1 and use the
method of Lagrange multipliers. When employing this method
we seek to ﬁnd stationary points for the following function:
LðwÞ ¼ wT Cw  λðwT w  1Þ
Fig. 5 Figure illustrating how the PCA algorithm works. Each of the black crosses
represents one of the n centered ﬁngerprint vectors that are input into the
algorithm. We can calculate the projection of these vectors on any arbitrary
vector, w. In the ﬁgure we show the projection of two of the ﬁngerprint vectors
onto the vector that is indicated using the red line. The blue line indicates the
vector for which the sum of the squares of all these projections is maximized.
The projections of the two ﬁngerprint vectors on this optimal direction are clearly
larger than the projections on the red line. The contour plot in the background of
the ﬁgure gives a set of isocontours for the function r2 ¼ xTΣ1x, where Σ is a
covariance matrix that is calculated from the set of ﬁngerprint vectors. These
isocontours have an elliptical shape and it is clear that the blue line runs parallel
to the principal axes of the ellipse
470
Gareth A. Tribello and Piero Gasparotto

These stationary points are the vectors, w, that satisfy:
dLðwÞ
dw
¼ Cw  λw ¼ 0
!
Cw ¼ λw
What we thus ﬁnd is that the vector, w, with the largest value for |t|2
is the eigenvector corresponding to the principal eigenvalue of the
covariance matrix, C.
This process is even simpler when a method such as MDS is
performed as we have already seen in Subheading 2.2 how we can
generate vectors of ﬁngerprints from an n  n dissimilarity matrix
by centering and then diagonalizing this matrix. We could in theory
take the n ﬁngerprints that we extract by this procedure and con-
struct an n  n matrix of data points in this case too, M. Further-
more, we could then multiply M by its transpose to obtain a
covariance matrix to diagonalize. Performing these additional
steps really is an exercise in futility, however, as the covariance
matrix contains the same information as the projections. The pro-
jections you would get after applying PCA would thus be identical
to the ﬁrst few rows of the ﬁngerprint vector VΛ
1
2 that was discussed
at the end of Subheading 2.2.
These linear dimensionality reduction techniques, PCA and
MDS, have been part of the toolkit data that scientists use to
analyze data for many years. It is thus hardly surprising that
researchers studying the behavior of biomolecules were quick to
apply them to the trajectories that they extracted [4–6]. The results
that were obtained when they performed these analyses, however,
were mixed. One problem was that the ﬁrst few eigenvectors of the
covariance matrix often did not appear to encode the majority of
the information about the distribution of the points in the high-
dimensional space. In other words, when the principal eigenvector
of the covariance matrix was inserted into Eq. 7 the norm of the
vector t that emerged was often found to not be very large. Conse-
quently, much of the information contained in the trajectory was
thrown away when the data was projected on the ﬁrst few eigen-
vectors of covariance matrix.
One theoretical justiﬁcation for using PCA to analyze biomo-
lecular trajectories is a belief that the folded state of a biomolecule is
at the bottom of a quasi-harmonic basin in a potential energy
landscape. If this were the case the points visited during the trajec-
tory would be distributed in accordance with a multivariate Gauss-
ian and the PCA eigenvectors would be very similar to those of the
Hessian matrix at the minimum in the landscape. When compar-
isons were performed between the eigenvectors extracted from a
PCA analysis of a trajectory and the eigenvectors extracted from the
Hessian matrix of the optimal structure of the protein, however,
little similarity between the ﬁrst few eigenvectors of these matrices
was found [25]. It was thus concluded that the biomolecules were
Dimensionality Reduction for Molecular Dynamics
471

doing more than simply ﬂuctuating around a single, quasi-
harmonic basin in a high-dimensional potential energy landscape.
An alternative to these linear dimensionality reduction algo-
rithms emerged in the early 2000s with the development of two
new algorithms for manifold learning—locally linear embedding
[26] and isomap [17]. The difference between what these methods
could do and what can be done with the conventional formulations
of PCA and metric MDS is illustrated in Fig. 6. As you can see from
Fig. 6 Figure illustrating how PCA and isomap perform on model data. The top row of the ﬁgure illustrates the
original data sets. All three data sets are three dimensional. In the ﬁrst data set the model data all lies on a
two-dimensional plane that is embedded in the three-dimensional space. This structure can thus be found
using both PCA and isomap. In the second data set all the points lie on a non-linear manifold. As you can see,
while isomap is able to unroll this curved manifold and display the relationship between the data points in the
plane, PCA is not. The third data set resembles the second but now there are three circular regions in the
curved manifold that are not sampled. Unsurprisingly, PCA is still unable to produce a projection of this data
that recognizes structure of the manifold. In addition, there are some difﬁculties with isomap. In particular, the
un-sampled regions do not appear to be circular in the projection and are instead elliptical because, as
discussed in the text, the presence of the poorly sampled regions ensures that the length of the shortest path
through the graph connecting two points is no longer equal to the geodesic distance between those points. All
three data sets were generated by mapping a set of two-dimensional input data points onto the three-
dimensional manifold of interest. In the ﬁgures above the points are therefore colored according to the values
of one of these input coordinates
472
Gareth A. Tribello and Piero Gasparotto

the ﬁgure the linear methods are able to determine whether the
data points all lie on a hyperplane in the high-dimensional space.
The non-linear methods, however, are able to determine whether
the points lie on a curved manifold—a structure that would not be
detected with the linear methods. In isomap these non-linear struc-
tures are found by using the geodesic distances between conﬁgura-
tions in place of the Euclidean distances that are used in metric
MDS. Consequently, when the resulting matrix of geodesic dis-
tances is then centered and diagonalized using the techniques dis-
cussed in Subheading 2.2, the ﬁngerprints that emerge give the
projections of the structures on the curved space.
Isomap has been used to analyze trajectory data on biomole-
cules [27–29] but some of the earliest advocates of this approach
seem to have now moved on to other algorithms [30, 31]. That
there are problems with isomap is well established [32–34]. Most of
these problems arise because of the way the geodesic distances
between points are actually computed. In essence, to calculate the
geodesic distance a graph is constructed from the data by connect-
ing two data points if they are within a certain cutoff distance of
each other. The geodesic distance between two points A and B is
then found by ﬁnding the shortest path through this graph that
connects A and B using Dijkstra’s algorithm [35] or the Floyd–-
Warshall algorithm [36]. The problem with this approach is that, as
shown in bottom right panel of Fig. 6 it works poorly if there are
regions of the manifold that are not sampled because the shortest
path through the graph, unlike the true geodesic path, has to go
around the poorly sampled region. In addition, and for similar
reasons, isomap is also not always effective if there is noise in the
directions that are locally orthogonal to the low-dimensional
manifold.
Another non-linear dimensionality that has been used to exam-
ine biomolecular trajectories is diffusion maps [37–39]. There have
been some promising results [40, 41] using this method although
some non-trivial modiﬁcations are required in order to get this
method to work effectively for trajectory data. In the limited
space we have in this chapter we cannot really do justice to the
literature on using diffusion maps to analyze trajectory data and
would instead direct the interested reader to the following review
[42]. In the comparisons that follow we have used the related but
simpler technique of Laplacian eigenmaps [43] in place of diffusion
maps. Much like isomap this algorithm starts by constructing a
graph that connects all the data points. In the simplest version of
Laplacian eigenmaps this is done by constructing a matrix P which
has element (i, j) equal to one if point i and point j are within a
certain distance of each other. In what follows, however, we calcu-
lated the k nearest neighbors for each of our data points and set the
matrix elements that corresponded to these neighborhood rela-
tions to one and all other matrix elements to zero. We thus
Dimensionality Reduction for Molecular Dynamics
473

introduced a sort of local scale when constructing the graph. It is
worth noting that it is possible to make further modiﬁcations to
Laplacian eigenmaps, which make the embedding generated by this
algorithm more like that generated by diffusion maps (see Note 3).
To be clear, however, we did not use these particular modiﬁcations
in what follows.
In Laplacian eigenmaps the Laplacian, L, of the weighted
graph, P, that is constructed in the ﬁrst stage is computed using:
L ¼ D  P
where
Di j ¼
X
j6¼iPi j
if
i ¼ j
0
otherwise
(
Once the Laplacian is computed the random-walk-normalized
Laplacian is constructed using:
LðrwÞ ¼ D1L
ð8Þ
A matrix with low-dimensional projections for the M input points
in its rows, X, is obtained from this matrix by diagonalizing L(rw),
discarding the lowest eigenvalue and its corresponding eigenvector
and by then taking the eigenvectors corresponding to the N lowest
eigenvalues that remain, placing them in a M  N matrix V and
computing:
X ¼ DV
The approach used in diffusion maps is similar to that outlined
above for Laplacian eigenmaps (see Notes 4 and 5). Furthermore,
the mathematical theory behind both methods is rooted in the
theory of discrete time Markov chains. In particular, these algo-
rithms both assume that the matrix P can be used to model the rates
of diffusion between the input high-dimensional vectors (see Note
6). They then use a combination of the spectral decomposition and
the Chapman–Kolmogorov relationship to conclude that diffusion
along the eigenvectors whose corresponding eigenvalues are large is
slow and that diffusion along the eigenvalues whose corresponding
eigenvalues are small is fast. For diffusion maps constructing pro-
jections using the eigenvectors whose corresponding eigenvalues
are large therefore ensures that if the modeled rate of diffusion
between two points is slow their projections appear far apart.
Furthermore,
the
same
holds
for
the
eigenvectors
whose
corresponding eigenvalues are small when Laplacian eigenmaps is
used (see Note 7).
The researchers who have used diffusion maps to analyze tra-
jectory data have found that they obtain the best results when they
use a locally scaled variant which assumes that diffusion is more
rapid in regions of the energy landscape that are sampled more
sparsely. In other words, when this locally scaled diffusion maps
technique [30, 31] is employed it is assumed that diffusion is rapid
when the biomolecule is close to a transition states and slow when it
474
Gareth A. Tribello and Piero Gasparotto

is inside a basin. Another algorithm that uses a scale parameter
whose value changes based on the local-density of the data is
t-distributed stochastic neighbor embedding (t-SNE) [44]. In
this method one begins by computing a matrix of conditional
probabilities:
Pjji ¼
exp  jXi  Xjj2
2σ2
i


P
k6¼iexp  jXi  Xkj2
2σ2
i


ð9Þ
The elements of this matrix give a measure of the conditional
probability that a data point Xi would pick a second data point Xj
as its neighbor if neighbors were picked in proportion to their
probability density under a Gaussian centered at Xi. This matrix is
not symmetric but a symmetric matrix can be constructed from it
using:
Pi j ¼ Pjji þ Pijj
2
t-SNE then constructs projections, yi, for each of the input data
points by minimizing the Kullback–Leibler divergence between the
distribution Pij and a second distribution:
Qi j ¼
ð1 þ jyi  yjj2Þ1
P
k6¼jð1 þ jyi  ykj2Þ1
which is computed from the distances between the projections of
the points. The ﬁnal Kullback–Leibler divergence is then computed
using:
KLðPjjQÞ ¼
X
i6¼j
Pi jlog
Pi j
Qi j
 
!
As you can see the local scale parameters for the data enter into
this procedure through Eq. 9. To calculate these local parameters
the user speciﬁes a parameter known as the perplexity, which can be
interpreted as a smooth measure of the effective number of neigh-
bors each of the high-dimensional data points will have. Conse-
quently, and much like the scale parameter in the locally scaled
version of diffusion maps, the σ parameters that appear in Eq. 9
will be small for those points that are in the densely sampled basins
in the energy landscape and large in the transition regions between
basins where the sampling is assumed to be much more sparse.
The ﬁnal dimensionality reduction technique that we will dis-
cuss is our own method sketch-map [22, 45, 46]. Furthermore, this
technique will be the subject of much of the rest of this chapter. We
developed sketch-map while studying the data from a simulation
Dimensionality Reduction for Molecular Dynamics
475

[47] of a twelve-residue sequence of alanines [48] because when we
tried to use the algorithms described in the previous paragraphs to
project these trajectories we got a low-dimensional projection that
was not particularly informative. In particular, we never observed a
wide gap between the norms of the t-vectors that were obtained
when any two neighboring eigenvectors, w, were inserted into
Eq. 7. Instead we observed a steady decline in the values of the
norms of the t-vectors for the various eigenvectors and thus con-
cluded that the information in this data set was spread out over all
over the high-dimensional space and that as such the conventional
techniques would not work. We thus sought to develop a three-
dimensional data set, which we knew we could not project using
any of the algorithms outlined above in the hope that if we were
able to develop an algorithm that could give us a meaningful
projection of this data it would also give us meaningful information
on our ala12 trajectories. The data set we developed for this pur-
pose is shown in the central panel of Fig. 7. This data was generated
by randomly sampling points from the probability distribution:
pðx, y, zÞ ¼ exp 3½3  sin 4ðxÞ  sin 4ðyÞ  sin 4ðzÞ  1


An isosurface in this probability density is shown in the left panel of
Fig. 7. What makes data generated from this distribution so difﬁcult
to project is the topology of this probability distribution. The
energy landscape that underpins this probability distribution has
eight basins and most of the points that are generated are samples
from these basins. Each pair of basins is then connected by two
transition pathways, one which runs through the center of the box
and one which runs through the periodic boundary. An ideal
Fig. 7 Figure illustrating the form of the data set that was used in the development of the sketch-map
algorithm. The left-most panel (a) of the ﬁgure shows the probability distribution from which points were
sampled, while the central panel (b) shows the points that were sampled from the distribution and analyzed
using the various dimensional reduction algorithms. The right-most panel (c) shows an idealized projection of
the data in two dimensions. As you can see from the left panel the distribution has eight modes and the
distribution is periodic in all three directions. Consequently, each pair of modes is connected by two distinct
pathways. It is this structure that we would thus like to see in the low-dimensional projection
476
Gareth A. Tribello and Piero Gasparotto

two-dimensional projection of this data would thus look something
like the cartoon shown in the right-most panel of Fig. 7.
Projections of the data set in Fig. 7 were constructed using the
implementations of the algorithms described in the previous para-
graphs that are in SciKit Learn [49]. For isomap and Laplacian
eigenmaps we constructed a graph connecting all the points using
a k-nearest neighbor approach with k ¼ 20. For t-SNE we used a
perplexity value of 90 and the Barnes–Hut implementation in
SciKit learn with an angular size of 0.5. The ﬁnal results are
shown in Fig. 8. As you can see the performance of all of these
algorithms is far from satisfactory.
Distance matching is arguably the best performing of the algo-
rithms tested in Fig. 8 as in the projection generated using this
method it is clear that at least some of the basins are connected by
two different pathways. When this algorithm is used all the linear
algebra discussed in Subheading 2.2 is discarded and projections, x,
are found by minimizing the stress function:
χ2ðxÞ ¼
X
i6¼j
wiwjðDi j  di jÞ2
ð10Þ
Fig. 8 Figure showing the projections of the data set that was introduced in Fig. 7 using the dimensionality
reduction algorithms that have been discussed in the text. The left panel shows the three-dimensional data set
that was projected once more but the points are now colored in accordance with the value of one of the three
high-dimensional coordinates. The points in each of the projections are colored in the same way. Notice that
none of these projections are similar to the ideal projection shown in the right panel of Fig. 7. In particular,
none of the projections allow one to determine that each basin in the landscape is connected by two transition
pathways. The Hyperparameters that were used with each of the algorithms are given in the ﬁgure
Dimensionality Reduction for Molecular Dynamics
477

using an interactive algorithm such as steepest descent or conjugate
gradients. In Eq. 10 Dij is the dissimilarity between the high-
dimensional vectors of ﬁngerprints for conﬁgurations i and j and
dij represents the distance between the corresponding projections
of these two points. A further advantage of this algorithm over
those discussed thus far is that the weights discussed in Subhead-
ings 2.1 and 2.3 can be included in the stress function. For these
reasons we thus chose this method as our start point when devel-
oping sketch-map.
There is a rich literature on generating low-dimensional projec-
tions of high-dimensional data by optimizing stress functions such
as the one in Eq. 10 [11, 34]. Many of these algorithms work by
giving each distance that appears in the stress function a weight, wij.
By adjusting the weights of these distances one can then force the
algorithm to focus its attention on getting the distances between
particular pairs of projections to match the dissimilarities between a
particularly important pair of high-dimensional ﬁngerprints. Alter-
natively, a second class of algorithm focuses on ensuring that the
distances between the projections give information on the ordering
of the dissimilarities between the high-dimensional vector of ﬁn-
gerprints [11]. We mention these algorithms here not because we
need to focus on their details but rather because of what they tell us
about how this business of dimensionality reduction has been
approached in other ﬁelds. In short, researchers have used their
intuition about the data being studied to adjust the stress function
that is optimized by the algorithm in a way that downplays the
uninteresting information contained in the high-dimensional dis-
tribution. By doing so they have thus developed algorithms that
focus on reproducing, in the low-dimensional projection, the infor-
mation from the high-dimensional data set that they believe is
important based on their intuition about the problem. This realiza-
tion is important in the context of sketch-map as this algorithm
does not produce an isometric mapping of the high-dimensional
space as is done in many other dimensionality reduction algorithms.
Instead, much of the information on the disposition of the points in
the high-dimensional space is discarded so that the algorithm can
focus on producing a low-dimensional projection that contains the
most pertinent information.
In practice a sketch-map projection, x, is generated by optimiz-
ing the following stress function:
χðxÞ ¼
X
i6¼j
wiwj½FðDi jÞ  f ðdi jÞ2
ð11Þ
As in Eq. 10 Dij here is the dissimilarity between the high-
dimensional ﬁngerprints for conﬁgurations i and j, respectively,
and dij is the distance between the projections of these two points.
478
Gareth A. Tribello and Piero Gasparotto

At variance with Eq. 10, however, these two distances are trans-
formed by two sigmoid functions of the form:
FðxÞ ¼ 1  ð1 þ ð2a=b  1Þðr=σÞaÞb=a
ð12Þ
which have the same value for the σ parameter but different values
for the a and b parameters. These two functions have a value that is
close to zero for values of x that are much less that σ and a value that
is close to one for values of x that are much greater than σ.
Incorporating these two function in the stress function in Eq. 11
ensures that the algorithm focuses most of its attention on repro-
ducing the dissimilarities that are close to σ when constructing
projections. Meanwhile, if points are separated by less than σ in
the high-dimensional space their sketch-map projections will
appear very close together. In addition, the projections of points
that are very far apart in the high-dimensional space can be almost
arbitrarily far apart. In other words, sketch-map focuses on repro-
ducing proximity information from the high-dimensional data set.
It ensures that points that are closer than a characteristic distance
are mapped close together, while simultaneously ensuring that the
farther apart points are well separated in the projection.
The reason sketch-map focuses on reproducing the dissimila-
rities that have values that are close to σ when constructing the
projection is that these dissimilarities are considered to be the most
important in terms of understanding the structure of conﬁguration
space. It is assumed that the parts of conﬁguration space that are
sampled in any trajectory are clustered around energetic basins.
These basins are then connected by a spider’s web of transition
pathways. What one would thus like to do with the dimensionality
reduction algorithm is to visualize the connections between the
energetic basins. The internal structure of the basins, which is less
interesting, should be collapsed in the projection and any points
that are in basins that are very far apart should be projected very far
apart so that it is clear to see these basins are not connected by a
transition pathway. The degree to which sketch-map succeeds in
this regard is illustrated in Fig. 9. To generate this ﬁgure we
generated the data shown in the right-most panel by sampling a
series of points from 5 normal distributions. These normal distri-
butions were arranged in the two-dimensional space so that it
would be difﬁcult to produce a one-dimensional projection of the
data using MDS and the points in the left panel of the ﬁgure
were colored in accordance with the Gaussian they were sampled
from. As you can see from the top right panel of the ﬁgure the
projection we get using MDS is not so revealing. To generate this
panel we took the projections of each of the data points in each of
the basins and generated a separate histogram for each of the basins
using kernel density estimation. This procedure gave us a sense of
the shape of each of the projected basins and as you can see there are
Dimensionality Reduction for Molecular Dynamics
479

substantial overlaps between the various basins when projections
are constructed using MDS. These overlaps are not present for the
sketch-map projections that are shown in the lower right panel,
however. The reason sketch-map performs better is illustrated in
the two central panels. The upper ﬁgure here shows the distribution
of the distances between the points that are shown in black in the
left panel of the ﬁgure and each of the other sets of points in the
ﬁgure. There is considerable overlap between the green red and
black distributions, which is why in the MDS projections the black
histogram overlaps with the green and red histograms. The upper
panel in Fig. 9 also shows a dashed line that indicates the sigmoid
function (Eq. 12) that has been used within the sketch-map algo-
rithm. The lower central panel then shows the histograms for the
transformed distances between the points that are shown in black in
the left panel of the ﬁgure and each of the other sets of points in the
ﬁgure. The sigmoid converts the majority of the distances between
pairs of black points to values that are close to one. Similarly the
8
6
4
2
0
–2
–4
–6
–6 –3
3
6
0.0
0
5
10
mds projection
5
–5
–10
sketch-map projection
0
10
0
Dn
0.5
F [Dn]
X1
X2
0
Fig. 9 Figure illustrating the purpose of the sigmoid functions in sketch-map. The right-most panels of this
ﬁgure show the 1D-projections of the model data in the left-most panel of the ﬁgure that are generated by
MDS (upper) and sketch-map (lower). The 2D model data in the left-most panel was generated by sampling
points from ﬁve normal distributions. The points in the left panel are colored according to the distribution they
were sampled from. Furthermore, to illustrate the projections of each of the basins in the 1D space we show
the histograms for the projections of the points in each of the ﬁve basins. The upper central panel shows the
distribution of distances between the points that are shown in black in the left panel and each of the other sets
of points in the panel. In this panel we also show the sigmoid function that was used in sketch-map to
transform these distances using a dashed line. The lower central panel shows the histograms for the
transformed distances. It is clear from these histograms of transformed distances that the sigmoid function
squeezes together points that belong to the same feature while spreading out points that belong to different
features
480
Gareth A. Tribello and Piero Gasparotto

majority of the distances that connect black points to blue or purple
points are converted to one by the sigmoid. As a consequence
during the ﬁtting process sketch-map works hard to ensure that
the distances between the black and red and the black and green
points are reproduced in the projection. The black points, mean-
while, are projected closer together than they are in actuality, while
the distances between the black and blue and black and purple
points are extended in the projection. The fact that these distances
can be distorted in this way is what ensures that each of the basins
appear as separate, non-overlapping features in the projection in the
lower right panel of Fig. 9.
Figure 10 shows a sketch-map projection of the data from
Fig. 7. It is clear that the sigmoid functions once again contract
each of the basins and thus ensure that the algorithm focuses on
reproducing the distances between the various basins. As a conse-
quence it is much easier to see that there are multiple transition
pathways between each pair of basins in the energy landscape.
Admittedly, the projection is still not the ideal conﬁguration
shown in the right-most panel of Fig. 7 but it is certainly more
revealing than the projections of this data that are shown in Fig. 8.
Fig. 10 Figure illustrating the projection that is generated by sketch-map of the
data set that was introduced in Fig. 7. This representation is much closer to the
ideal projection that was shown in the right panel of Fig. 7 than any of the
representations that were shown in Fig. 8. In particular the two pathways
connecting each of the basins are much clearer in the sketch-map representa-
tion that is shown above. The hyperparameters used in constructing this
projection were σ ¼ 2, A ¼ 2, B ¼ 10, a ¼ 2, and b ¼ 3
Dimensionality Reduction for Molecular Dynamics
481

In this section a lot of detail about the various dimensionality
reduction algorithms that have been used to analyze biochemical
trajectories has been provided. It is impossible to summarize all this
information in a single paragraph but it is worth emphasizing that
the differences between algorithms that have been discussed are in
the ways that the dissimilarities between the vectors of ﬁngerprints
for each conﬁguration are calculated and employed. Progress has
been made and better algorithms have been developed by either:
1. Thinking of ways to calculate physically meaningful dissimila-
rities between conﬁgurations. For example, the model of diffu-
sion that is used in diffusion maps notionally ensures that the
projection coordinates are the directions along which diffusion
is slow.
2. Pragmatically discarding dissimilarities that are thought to be
uninteresting when constructing projections as is done in
sketch-map.
In other words, the algorithms that work well are those that
endeavor to use the known physics of the problem when construct-
ing projections.
3
Examples
The previous sections of this chapter have introduced the theory
behind a number of dimensionality reduction algorithms. In the
following three sections we will show how these methods have been
applied in practice. We will begin by projecting some data from a
simulation of the C-terminal fragment of the immunoglobulin
binding domain B1 of protein G of Streptococcus using some of
the algorithms that were discussed in the previous section in order
to compare their performances. We will then give a brief survey of
the ways in which the sketch-map algorithm has been used by the
community. Finally, we will ﬁnish by discussing the challenge of
accurate sampling and how sketch-map has been used to enhance
sampling.
3.1
Performance
In
Subheading
2.4
we
showed
how
the
various
different
dimensionality reduction algorithms that we have discussed fare
when projecting some model data. This was, arguably, not a partic-
ularly fair test as the model data was deliberately designed so that
sketch-map would outperform the others. In preparing this section
we have thus taken some data [50] from a parallel tempering
trajectory of the C-terminal fragment of the immunoglobulin bind-
ing domain B1 of protein G of Streptococcus and projected it using
the various algorithms that were discussed in the previous section.
The ﬁnal results are shown in Figs. 11 and 13.
482
Gareth A. Tribello and Piero Gasparotto

To construct the projections shown in Fig. 11 we took 25311
randomly selected points from the wild-type trajectories that were
presented in the paper by Ardevol et al. [50]. For each of these
conﬁgurations we computed the full set of 16 torsional backbone
dihedral angles. Two-dimensional projections for each of these
32-dimensional vectors were then generated using the implemen-
tations of the various algorithms described in the ﬁgure that are
available in SciKit Learn [49]. The hyperparameters that we used
for each of these algorithms are given in the ﬁgure.
Before projecting the trajectory we used the STRIDE algo-
rithm [51] to determine the secondary structure content in each
of the frames that was analyzed. In particular, we counted the
number of residues that had a structure that was similar to an
alpha helix and the number of residues that had a structure that
was similar to a beta sheet. When constructing the projections in
Fig. 11 we thus colored the projections according to the number of
residues in the corresponding trajectory frames that appeared to be
Fig. 11 Projections of a parallel tempering trajectory of the C-terminal fragment of the immunoglobulin binding
domain B1 of protein G of Streptococcus. Each of the ﬁgures above is a projection of 25311 randomly selected
frames from the trajectory of the wild-type protein that was simulated in the paper by Ardevol et al. [50]. We
used the STRIDE algorithm [51] to determine how many residues had a conﬁguration similar to a beta sheet
and how many residues had a conﬁguration similar to an alpha helix for each of the conﬁgurations in the
trajectory. In the projections above we have thus colored the points in each of the projections in accordance
with the secondary structure that was observed in the corresponding trajectory frame
Dimensionality Reduction for Molecular Dynamics
483

in an alpha helix conﬁguration and the number of residues that
appeared to be in a conﬁguration that resembled a beta hairpin.
Coloring the projections in this way gives us a qualitative way to
compare how well each of the algorithms does when it comes to
projecting the trajectory data. What we see is that all the algorithms
do a reasonable job of separating the conﬁgurations that are pre-
dominantly alpha helix like from those that have a structure that is
predominantly composed of beta sheets. In this sense at least then
the algorithms all give a reasonable projection of the high-
dimensional data.
In Subheading 2.4 we discussed how the classical MDS and
PCA algorithms that were used to construct the top right and top
center panels of Fig. 11 are identical. The fact that these two
projections of the beta hairpin data are very similar is thus perhaps
unsurprising. It is important to note, however, that this similarity
persists here even though slightly different representations of the
input data were used when constructing these two projections. In
particular, when constructing the MDS projection the input, high-
dimensional vectors contained the 32 backbone dihedral angles and
distances between these vectors were computed in a way that took
the periodicity of these quantities into account. To run PCA,
however, we needed to use 64-dimensional input vectors contain-
ing the sines and cosines [52, 53] of the backbone dihedral angles
as this algorithm will not work if any of the high-dimensional input
variables are periodic.
Although the projections that have been generated using PCA
and MDS separate the conﬁgurations that resemble alpha helices
from those that resemble beta sheets it is clear from Fig. 11 that
these projections do not provide an optimal reﬂection of the
distances between the high-dimensional data points. In Subhead-
ing 2.4 we discussed how these two algorithms ﬁnd the
low-dimensional representation by projecting the data on a
two-dimensional plane that is embedded in the high-dimensional
space. It is clear from Fig. 11, however, that many of the high-
dimensional points do not lie within this plane as the projection
shown in the bottom left of the ﬁgure that was generated using the
distance matching algorithm is radically different from the PCA and
MDS projection. In particular, the points in this projection are
spread out more uniformly across the low-dimensional space and
some of the clusters that were apparent in the PCA and MDS
projections have disappeared. It is thus clear from these three
projections that the trajectory data does not simply lie on
two-dimensional linear manifold.
Further
evidence
that
the
points
do
not
lie
on
a
two-dimensional linear manifold is provided by Fig. 12. To con-
struct
the
panels
shown
in
this
ﬁgure
we
generated
two-dimensional histograms and thus estimated the joint probabil-
ity density function for the dissimilarities between the trajectory
484
Gareth A. Tribello and Piero Gasparotto

frames and the distances between the projections of these conﬁg-
urations. Furthermore, we constructed these histograms for all of
the projections that are shown in Fig. 11. The results from PCA and
MDS are shown in the middle top and right top panel of Fig. 12,
respectively. For both of these algorithms the distances between the
projections of the points are systematically shorter than the dissim-
ilarities between the actual trajectory frames. The reason these
distances are shorter is that for both of these algorithms the dis-
tance between any pair of projections is equal to the length of a
projection of the vector connecting the two conﬁgurations in a
two-dimensional space. The lengths of the projections of the vec-
tors connecting the conﬁgurations are shorter than the lengths of
the original, un-projected, and high-dimensional vectors because
during the projection operation some components of these vectors
are discarded. Notice that a different behavior is observed when
distance matching is used in place of these linear techniques. When
the projections are found by minimizing a stress function using an
iterative algorithm the projections the algorithm ﬁnds no longer
have to lie on a low-dimensional linear manifold. Instead the dis-
tance matching algorithm must simply seek to match as many
distances to dissimilarities as possible. In the histogram shown in
the bottom left panel of Fig. 12 we thus see that the number of
distances between pairs of projections that are larger than the
corresponding dissimilarities is roughly equal to the number of
Fig. 12 Histograms illustrating the joint probability density function for the dissimilarities between the
conﬁgurations in the trajectory and the distances between the corresponding projections of these trajectory
frames. The particular projections that have been analyzed here are those that are shown in Fig. 11. The black
line in each of these ﬁgures is the line Rij ¼ rij. For an ideal projection all the density in these histograms
would lie on this line
Dimensionality Reduction for Molecular Dynamics
485

distances between pair of projections that are shorter than the
corresponding dissimilarities. Furthermore, the average value for
the distances between the projections is approximately equal to the
average value for the average dissimilarity.
Figure 11 shows that none of the non-linear dimensionality
reduction algorithms that were described in the previous section do
much better than the linear methods when it comes to projecting
the trajectory data. In fact the ISOMAP projection that is shown in
the top left of the ﬁgure bears some similarity with the projections
that were generated using PCA and MDS. The similarity between
these two projections suggests that the geodesic distances are simi-
lar to the Euclidean distances and that the trajectory does not
uniformly sample a non-linear manifold in the high-dimensional
space. The histogram in the top left hand corner of Fig. 12 suggests
that there are differences between the geodesic and the Euclidean
distances, however. The ﬁgure shows that the distances between the
projections of many of the most dissimilar conﬁgurations are con-
siderably larger than the dissimilarities between the trajectory
frames. It would seem, therefore, that replacing the Euclidean
distances with geodesic distances has made a substantial difference
but that it is difﬁcult to see this difference just by looking at the
projection shown in Fig. 11.
The projection that was generated using Laplacian eigenmaps is
shown in the bottom center of Fig. 11. The Laplacian eigenmaps
projection has the conﬁgurations that resemble alpha helices pro-
jected closer to the projections of conﬁgurations that resemble the
beta sheets than the other projections. The model of diffusion that
underpins this method thus suggests that diffusion between these
conﬁgurations is relatively rapid. This makes physical sense as one
would expect the slowest process in the system to be diffusion
between the folded states and the unfolded states that are projected
in the periphery of the map. If one wishes to examine the relative
free energies of the various different folded states, however, this
representation may not be optimal.
It is perhaps not fair to compare the distances between the
projections of the points with the dissimilarities for this algorithm
as the Laplacian eigenmaps makes no effort to generate a projection
that reproduces these quantities. The joint probability distribution
for the dissimilarities between the trajectory frames and the dis-
tances between the corresponding projections that is obtained
using this algorithm is nevertheless shown in the bottom middle
panel of Fig. 11. It is clear that many conﬁgurations are projected
much closer together than they are in actuality and that the dis-
tances between the projection of any two conﬁgurations are likely
to be close to zero even if the dissimilarity between the two con-
ﬁgurations is substantial. The reason that there are such big mis-
matches between the distances and the dissimilarities is that when
we construct the graph that is used to model the diffusion between
486
Gareth A. Tribello and Piero Gasparotto

the high-dimensional data points each point is connected to its
k nearest neighbors. Two neighboring points can be very far
apart, however, particularly in regions of conﬁguration space that
are sampled sparsely. In other words, when using the Laplacian
maps algorithm in the way we have applied it one assumes that
the non-linear manifold whose structure one is endeavoring dis-
cover using the dimensionality reduction algorithm is sampled
relatively uniformly. This is clearly not true in our case as we
know that an MD simulation will sample extensively from the
basins in the energy landscape and that the transition states will
be weakly sampled. This uneven sampling of phase space is in fact
one reason why the modiﬁcations that introduce local scaling para-
meters into diffusion maps and that were discussed in Subheading
2.4 are required when analyzing trajectory data [42].
Another algorithm that introduces a kind of local scaling is
t-SNE. The t-SNE projection of the trajectory data is shown in
the bottom right of Fig. 11. This representation is composed of a
large number of disjoint clusters and consequently if the free energy
surface were projected as a function of these coordinates it would
appear very rough. If one looks more closely, however, the struc-
tures in many of these clusters are very similar. In the representation
shown in Fig. 11, for example, the conﬁgurations that resemble an
alpha helix appear to have been split between a number of different
basins, which is a very different behavior to that observed for the
other representations of the trajectory. The reason the projection
appears this way is clear from the histogram that is shown in the
bottom right panel of Fig. 12. It would seem that the distances
between the projections that are constructed using the t-SNE
algorithms are much larger than the dissimilarities between the
corresponding trajectory frames.
A projection of the β-hairpin trajectory that was generated
using sketch-map is shown in Fig. 13. This projection resembles
the projection that was generated using t-SNE in that many clusters
in the data have been identiﬁed. At variance with t-SNE, however,
all the conﬁgurations that resemble alpha helices have been pro-
jected in one cluster close to the center of the map, while all the
conﬁgurations that resemble beta sheets have been projected in a
second, different cluster at the center of the map. High-energy
conﬁgurations that resemble neither of these two secondary struc-
ture types have meanwhile been projected in the periphery of the
map. In other words, for this particular data set sketch-map appears
to have generated a projection that has an appearance that is inter-
mediate between that generated by t-SNE and those generated by
the other algorithms. Furthermore, it has done so using a single
scale parameter for all points without the need to resort to any form
of local scaling. The reason the sketch-map projection appears this
way is clear from the histogram that is shown in the inset in Fig. 13.
This histogram, much like those shown in Fig. 12, shows the joint
Dimensionality Reduction for Molecular Dynamics
487

probability density function for the dissimilarities between trajec-
tory frames and the distances between their corresponding projec-
tions. The histogram that is observed for sketch-map is similar to
the histogram that was observed for t-SNE in that the points that
are close together are projected much closer together than they are
in actuality. The distances between the projections of the
Fig. 13 A sketch-map projection for a parallel tempering trajectory of the C-terminal fragment of the
immunoglobulin binding domain B1 of protein G of Streptococcus is shown in panel (a). The data that was
used to construct this projection was taken from the work of Ardevol et al. [50]. In particular, the simulations of
the wild-type protein. The initial sketch-map projection here was constructed from 1000 landmark point which
were selected using the well-tempered farthest point sampling algorithm that was described in Subheading
2.3 and a gamma parameter of 0.1. Weights for each of these landmarks were generated using a Voronoi
procedure and the sketch-map stress function with parameters σ ¼ 6, A ¼ 8, B ¼ 8, a ¼ 2, and b ¼ 8
was then optimized to ﬁnd projections for each of these landmarks. Once projections for these landmarks had
been found the remainder of the trajectory was projected using the out-of-sample procedure. The location at
which a number of representative structures are projected has been indicated in the ﬁgure. In addition, we
used STRIDE [51] to determine the number of residues in each conﬁguration that was visited in the trajectory
that had the atoms arranged similarly to the arrangement of the atoms in a beta sheet or alpha helix. As was
the case in Fig. 11 the points in the above representation are colored according to the secondary structure that
is observed in the corresponding conﬁguration. In addition, a histogram similar to those in Fig. 12 that shows
the joint probability distribution for the dissimilarities between the high-dimensional conﬁgurations and the
distances between the corresponding projections of these points is shown in panel (b)
488
Gareth A. Tribello and Piero Gasparotto

conﬁgurations that are far apart, however, can be much larger than
corresponding dissimilarities. Even so there is a substantial differ-
ence between the histograms that are observed with t-SNE and
sketch-map. For sketch-map there is a region around σ ¼ 6 where
the majority of the dissimilarities and the distances are very similar.
This behavior occurs because, as discussed in Subheading 2.4, the
two sigmoid function in the stress function that is optimized within
sketch-map ensure that the projection will reproduce the distances
in this particular range. This ability to control the shape of this
histogram and by extension the distances that will be reproduced in
the projection is the real strength of the sketch-map algorithm.
Sketch-map unlike the other algorithms that have been discussed
in this section allows you to pragmatically choose the distances that
you would like to accurately reproduce when you construct projec-
tions. Figure 12 and the discussions above show that when the
other algorithms that have been described in this section are used
in place of sketch-map the user has much less control over the
distances that are accurately reproduced.
3.2
Applications
In the previous section we discussed the efﬁcacy of the various
dimensionality reduction algorithms in terms of whether they
could distinguish conﬁgurations containing alpha helices from
those containing beta sheets. Given this it is perhaps not unreason-
able to ask what purpose is served by using these dimensionality
reduction algorithms? The previous section suggests that we would
be better off using CVs that measure the numbers of alpha helices
and beta sheets in the protein when analyzing this trajectory [54].
We would then have a projection of the trajectory that we under-
stand and that therefore is perhaps more physically revealing.
There is certainly some merit to the argument outlined in the
previous paragraph. If you have some clearly deﬁned physical/
chemical question to answer, then you should display the free
energy surface as a function of some CVs that allow you to answer
the question you seek to answer. For example, if you are interested
in the relative free energies of the folded and unfolded states of a
protein and if you know the structure of the folded state, it is
probably best to display the free energy as a function of a CV,
such as RMSD, that is small when the structure is folded and that
is large when it is not. After all, and as we have said many times in
this chapter, these dimensionality reduction algorithms should not
be used to replace your chemical/physical intuitions about the
problem. The problem with chemical intuition, however, is that
there are many physical systems for which our intuition is severely
lacking [55–58]. For example, there are many so-called intrinsically
disordered proteins that do not have a clear folded state [59]. It is
thus when studying these types of problems that the insights that
can be obtained by performing an analysis using a dimensionality
reduction
algorithm
can
prove
invaluable.
Dimensionality
Dimensionality Reduction for Molecular Dynamics
489

reduction allows one to extract a visual representation of the
ensemble of conﬁgurations that have been sampled during the
simulation. The free energy can be projected as a function of
these low-dimensional coordinates and, because there is a one to
one mapping between conﬁgurations in the trajectory and the
projections of the low-dimensional points, you can get some insight
into the structures in the various basins that are found in this energy
landscape. An example, where sketch-map has been used to gener-
ate this sort of representation is shown in Fig. 13 [50]. Notice that
we surround the free energy surface with snapshots from the tra-
jectories in this ﬁgure and indicate where each of these structures
are projected in the low-dimensional representation. This step of
working out what structures are projected in each part of the
landscape is critical for interpreting the free energy surfaces when
they are output in terms of these types of automated coordinates.
These automated approaches for generating collective variables
show real promise when it comes to investigating how a small
perturbation in the conditions can affect the free energy landscape
and hence the properties of the system under investigation. Obvi-
ously, any change in the conditions causes the system’s Hamilto-
nian to change. Even if the change to the Hamiltonian is relatively
small, however, there can be a substantial difference in the free
energy surface and hence the properties of the perturbed system.
Furthermore, the complicated relationship between the Hamilto-
nian and the free energy surface makes predicting what changes
there will be almost impossible. These difﬁculties thus clearly make
determining what collective variable to use when visualizing these
free energy surfaces extremely challenging. By using a dimension-
ality reduction algorithm to extract a representation from the tra-
jectories,
however,
you
essentially
sidestep
these
problems.
Furthermore, because these algorithms give you an unbiased view
of the ensemble of conﬁgurations that were sampled during the
trajectory, the differences between the perturbed and unperturbed
free energy landscapes provide information on changes in the prop-
erties of the system that you might not have predicted otherwise.
Figure 14 gives an example that shows how sketch-map can be
used to understand how changes in the conditions affect the free
energy landscape. This ﬁgure shows the free energy surfaces for a
38-atom cluster of Lennard Jonesium at three different tempera-
tures [22]. This particular cluster is interesting because it has an
energy landscape with a double funnel and because it therefore
undergoes a ﬁnite-size phase transition from an ordered form to a
disordered form [60–63]. The free energy surfaces that are shown
in Fig. 14 are thus for a temperature below the phase boundary, at a
temperature close to the phase boundary, and at temperature that is
above the phase boundary. The same set of sketch-map coordinates
were used to construct each of these three free energy surfaces. It is
therefore possible to perform a direct comparison between them
490
Gareth A. Tribello and Piero Gasparotto

and to consequently work out what parts of conﬁguration space this
particular system explores at each temperature. It is perhaps not
surprising to note that the system is trapped in one of the two small
regions of conﬁguration space at low temperature. Furthermore,
these two regions correspond to the two ordered structures that
this system adopts at low temperatures. As the temperature is raised
the system is progressively allowed to explore more and more of
conﬁguration space. Consequently, when the system is close to the
transition temperature it will sample ordered and disordered con-
ﬁgurations. For temperatures above the transition temperature,
however, entropy plays the principle role in determining the con-
ﬁgurations that the system samples from. The system therefore no
longer samples the ordered conﬁgurations and is instead disordered
at all times.
Fig. 14 Figure showing the free energy surface at three different temperatures for a cluster of 38 Lennard-
Jones atoms. This particular cluster undergoes a ﬁnite-size phase transition at the temperature at which the
central free energy surface in the ﬁgure above was constructed. Furthermore, all three of the free energy
surfaces above are shown as a function of a set of sketch-map coordinates that were constructed using
landmark points that were taken from a trajectory at this particular temperature. It is clear from this ﬁgure that
the conﬁgurations sampled at temperatures below the transition temperature are completely different to those
sampled at temperatures above the transition temperature. At temperatures close to the transition tempera-
ture, however, the system is able to sample from both of these regions of conﬁguration space
Dimensionality Reduction for Molecular Dynamics
491

The results shown in Fig. 14 are perhaps obvious given the
predictions of statistical mechanics. As temperature is increased of
course the system samples from a wider portion of conﬁguration
space. What is pleasing about the representation that is generated
using the sketch-map coordinates, however, is that one really sees
that the system is sampling a larger part of conﬁguration space at
the higher temperature. When one uses coordinates based on phys-
ical or chemical intuition by contrast this broader sampling of phase
space is not always evident in the projection of the higher-
temperature trajectories.
Recent work by Ardevol et al. [50] has shown how the sort of
analysis that was demonstrated in Fig. 14 can be used to understand
the behavior of biomolecules. Ardevol et al. were interested in how
mutations in the amino acid sequence affected the free energy
surface for the C-terminal fragment of the immunoglobulin bind-
ing domain B1 of protein G of Streptococcus (amino acid sequence
Ace-GEWTYDDATKTFTVTE-NMe). To answer this question
they thus constructed a representation of a parallel tempering +
metadynamics trajectory [64] for the wild-type protein using the
sketch-map algorithm. They then projected the wild-type trajectory
using these coordinates as well as similar trajectories that were
generated for each of the mutants under investigation. They were
then able to plot the free energy surfaces for the wild type and for
the mutant proteins side by side and to do a point-by-point com-
parison between them. From this sort of analysis they were thus
able to determine what features were stabilized by the mutation and
what features were destabilized by the mutation. Furthermore, by
looking at the chemical structure of the wild type and mutant they
were then able to determine which chemical features were respon-
sible for the differences in the free energy landscape.
This idea of using the sketch-map representation for one tra-
jectory to analyze a second different trajectory can be taken a step
further once you recognize that the data you analyze using these
machine learning algorithms does not have to come from a molec-
ular dynamics trajectory. You can, for example, use a dimensionality
reduction algorithm to construct a low-dimensional representation
for the structures in databases such as the Protein Data Bank (www.
rcsb.org) [65–67]. An analysis such as this can provide you with a
set of generalized collective variables that can then be used to study
trajectories for a range of biomolecules. An idea similar to this one
was recently used by Ardevol et al. [68]. They took every
16-residue fragment contained in the 7846 NMR-solved structures
deposited in the PDB Data Bank and constructed a sketch-map
representation of these structures. They then used this projection
to analyze a parallel tempering trajectory for the C-terminal frag-
ment of the immunoglobulin binding domain B1 of protein G of
Streptococcus. They showed that the general coordinates that were
constructed using data from the protein data bank were as good at
492
Gareth A. Tribello and Piero Gasparotto

discriminating between the various structures that were adopted
during the trajectory as sketch-map coordinates that were con-
structed using the trajectory data directly. This result suggests
that it might be possible to use generic coordinates using some
particularly representative data set to analyze a range of different
protein systems. These generic coordinates would provide a single
common basis that would be useful when it comes to comparing
the behaviors of these various different proteins.
3.3
Enhanced
Sampling
In the previous section we showed how the sketch-map algorithm
has been used to visualize trajectory data. What was not really
discussed in great detail was the way in which the analyzed trajec-
tories were generated. This question of how you generate trajec-
tories to analyze is critical, however, as any projection that you
generate can only ever be as informative as the data that was used
to generate it. If the trajectory that is input into the dimensionality
reduction did not explore all the energetically accessible parts of
conﬁguration space any projection of this data that is generated will
only provide a partial insight into the behavior of the protein. To
resolve this impasse a number of researchers have suggested using
the projections that are extracted using these algorithms to enhance
the sampling of phase space in one of the two ways:
1. A short MD trajectory is generated and then analyzed using a
dimensionality reduction algorithm [69]. When the projected
data is visualized some regions of the low-dimensional space are
found to be densely sampled, while other parts are found to be
sampled more sparsely. To broaden the sampling the research-
ers thus seed new trajectories using conﬁgurations taken from
these sparsely sampled regions.
2. The low-dimensional projections obtained using a dimension-
ality reduction algorithm are used as a collective variable
(CV) and a simulation bias that is a function of this variable is
constructed using techniques such as metadynamics [70]. This
simulation bias forces the system to more fully explore conﬁg-
uration space.
The ﬁrst of the two methods described above is relatively self-
explanatory and we will thus not dwell on it much further. Similarly,
if a linear dimensionality reduction algorithm such as PCA is used it
is
straightforward
to
use
this
as
a
CV
for
metadynamics
[71, 72]. After all the CV in this case is just a linear combination
of some, usually easy to calculate, set of physical parameters. What is
more challenging in this second case is if the CV is some non-linear
combination of these physical parameters that is generated via a
method such as sketch-map [73]. This business of how to run
enhanced sampling calculations using sketch-map as the CV will
thus be the focus in the remainder of this section.
Dimensionality Reduction for Molecular Dynamics
493

For sketch-map, unlike some of the other algorithms discussed
in the previous sections, it is relatively simple to generate an out-of-
sample projection, s, for an arbitrary high-dimensional conﬁgura-
tion, X, by minimizing the following function:
χ2ðsjXÞ ¼
X
N
i¼1
wi F½DðX,XiÞ  f ½dðs,siÞ
f
g2
ð13Þ
The sum here runs over the set of landmark points that were used to
generate the initial projection. Xi, si, and wi are the high-
dimensional coordinates, the projection, and the weight of land-
mark conﬁguration i, respectively. D(X, Xi) and d(s, si) thus mea-
sure the distance between the high-dimensional coordinates of the
out-of-sample point and the high-dimensional coordinates of the
ith landmark and the distance between the projection of the point
and the projection of the ith landmark. Furthermore, in the expres-
sion above these two distances are transformed by the sigmoid
functions that were discussed in Subheading 2.4. This stress func-
tion is thus large for s values for which the transformed distances to
the projections of the landmarks are very different to the trans-
formed dissimilarities from the high-dimensional coordinates. It is
small when these two sets of transformed distances are similar,
which ensures that the projected landmarks that are close to s are
those of the landmarks that are close to X in the high-dimensional
space. This way of constructing out-of-sample projections has been
shown to be very robust [22] but it is, nevertheless, not possible to
use the projections generated by minimizing Eq. 13 as a CV for
metadynamics [46]. The problem with this approach is illustrated
in Fig. 15. Essentially, the low-dimensional space in which the
trajectory is projected may have a different topology to the energy
landscape on which the protein moves. Consequently, paths that
appear to be discontinuous in the low-dimensional projection may
in actuality be continuous in the high-dimensional space. In other
words, the value of the CV that is calculated by minimizing Eq. 13
can change by a signiﬁcant amount even when the displacement in
the atomic positions is only small.
To resolve this problem with using sketch-map coordinates as a
CV for metadynamics simulations we introduced the notion of a
ﬁeld CV [46]. In this technique the state of the system is repre-
sented by the following function:
ϕ½sjXðtÞ ¼
exp  χ2½sjXðtÞ
2σ2


R
exp  χ2½s0jXðtÞ
2σ2


ds0
Here χ2[s|X(t)] is the stress function that is deﬁned in Eq. 13. The
high-dimensional coordinates, X(t), for the conﬁguration can be
494
Gareth A. Tribello and Piero Gasparotto

thought of as a set of parameters that deﬁne this probability distri-
bution, which is calculated on a grid of points, s, in the
low-dimensional space. The probability distributions that are
deﬁned using this formula are then used in place of the Gaussians
that appear in metadynamics. There is thus a history-dependent
bias of sorts in this ﬁeld CV method that is simply:
vðs, tÞ ¼
X
t
t0¼0
wðt0Þϕ½sjXðt0Þ
where w(t0) is analogous to the heights of the Gaussians in meta-
dynamics. This quantity is time dependent because we use the
standard techniques of well-tempered metadynamics (see chapter
IV) [23] to ensure that the bias converges.
In addition to using ﬁelds in place of the Gaussians when
constructing the bias another major difference between the ﬁeld-
CV technique and metadynamics is the manner in which the
history-dependent
bias
acts
upon
the
system.
Rather
than
Fig. 15 Figure illustrating the problems associated with using sketch-map
coordinates as CVs for enhanced sampling. To illustrate these problems we
have used the energy landscape that was introduced in Fig. 7 once more and two
isosurfaces in this energy landscape are shown in the left panel above. The right
panel shows a representation of the sketch-map projection for this landscape.
The projections of each of the basins are shown using a circle, while the dashed
lines are used to indicate how the transition pathways between the basins are
projected. The value of Eq. 13 has been evaluated on a grid in the
low-dimensional space for the three points on the energy landscape labeled a,
b, and c. Isocontours in these functions are shown in the right panel. As you can
see while there is a single minimum in this function and thus a single location
where it is reasonable to project points a and c, there is a double minimum when
this function is evaluated for point b. It is thus difﬁcult to know where to place the
projection of this coordinate and small changes in the position of the point in the
high-dimensional space can lead to large changes in the position of the
projection
Dimensionality Reduction for Molecular Dynamics
495

calculating the value of the history-dependent bias for the instanta-
neous value of the CV the ﬁeld CV method calculates the instanta-
neous bias by performing the following integral:
V ½XðtÞ ¼ R
ϕ½sjXðtÞvðs, tÞds
As shown in Fig. 15 calculating the instantaneous bias using this
equation resolves the issues associated with continuous paths in the
high dimensional being projected as discontinuous paths in the
low-dimensional space. In essence the system now deposits bias in
all the parts of the low-dimensional space where it would be rea-
sonable to project the conﬁgurations. Furthermore, at any given
time the system feels the bias that has been deposited in all the
points where it would be reasonable to project the conﬁguration.
Simulations that demonstrate that the ﬁeld CV method that has
been outlined in the previous paragraphs can be used to enhance
the sampling in model systems have been performed [46]. The
method shows considerable promise but it is currently computa-
tionally expensive to run and thus has only been rarely used. It is,
however, an interesting approach and one that should be investi-
gated further in the future.
4
Conclusions
The chapter has discussed how machine learning algorithms can be
used to visualize molecular dynamics trajectories and to enhance
sampling. There has been a veritable explosion of interest in using
these techniques to understand simulation data in the past few years
and as such any presentation on this topic will probably barely
scratch the surface of the literature. What we hope that we have
provided in the preceding pages is an easy-to-digest-but-far-from-
exhaustive introduction to some of the ideas that are being used. In
this ﬁnal section we would like to ﬁnish by brieﬂy discussing some
interesting recent directions in which we believe the ﬁeld is moving.
Throughout this chapter we have asserted that these methods
should be used to complement chemical and physical understand-
ing and not to replace it. With this in mind an interesting recent
development is the so-called PAMM methodology [74, 75], which
uses Bayesian statistics to determine whether the arrangement of
the atoms in a particular conﬁguration resembles the canonical
deﬁnition of a molecular motif such as a hydrogen bond or alpha
helix. This method is appealing as physical intuition and machine
learning are used in tandem. Finding appropriate ﬁngerprint vec-
tors to encode our physical understanding remains a challenge,
however, and some have argued that we should instead use more
generic representations to describe the arrangement of the atoms
[76, 77].
496
Gareth A. Tribello and Piero Gasparotto

A second interesting recent direction has involved applying the
deep learning techniques that have proved so successful in a range
of ﬁelds to biophysical problems. In particular, a number of recent
articles have used autoencoder neural networks to construct collec-
tive coordinates that can be used both to analyze molecular dynam-
ics trajectories and as a collective variable for metadynamics
simulations [78, 79].
Finally, most of the algorithms discussed in this chapter do not
consider the order that the frames are visited in within the trajec-
tory. Consequently, any projections that are constructed reproduce
the spatial relationships between the frames in the input trajectories
rather than the temporal relationships. Recent developments in
Markov state modeling [80, 81] and the development of techni-
ques for extracting rate constants from enhanced sampling calcula-
tions [82] perhaps provide ways of generating low-dimensional
projections that incorporate information on the temporal informa-
tion in the trajectory [9, 79, 83, 84]. In other words, these new
techniques generate low-dimensional coordinates that describe the
directions in which the system diffuses slowly by analyzing transi-
tion probability matrices directly. This form of analysis is an exciting
development as the projections that emerge would provide real
insight into the slow-degrees of freedom and hence the reaction
mechanisms.
5
Notes
1. We can write out all the matrix elements for a 3  3 matrix of
distances using Eq. 1 and thus see that Eq. 2 holds:
0
d2
12
d2
13
d2
12
0
d2
23
d2
13
d2
23
0
2
64
3
75 ¼
X
α
ðX ð1Þ
α Þ2
ðX ð1Þ
α Þ2
ðX ð1Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð3Þ
α Þ2
ðX ð3Þ
α Þ2
ðX ð3Þ
α Þ2
2
6664
3
7775
þ
X
α
ðX ð1Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð3Þ
α Þ2
ðX ð1Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð3Þ
α Þ2
ðX ð1Þ
α Þ2
ðX ð2Þ
α Þ2
ðX ð3Þ
α Þ2
2
664
3
775
2
X
α
X ð1Þ
α X ð1Þ
α
X ð1Þ
α X ð2Þ
α
X ð1Þ
α X ð3Þ
α
X ð2Þ
α X ð1Þ
α
X ð2Þ
α X ð2Þ
α
X ð2Þ
α X ð3Þ
α
X ð3Þ
α X ð1Þ
α
X ð3Þ
α X ð2Þ
α
X ð3Þ
α X ð3Þ
α
2
64
3
75
Dimensionality Reduction for Molecular Dynamics
497

2. The centering matrix, J, that was introduced in Eq. 3 has the
useful property that 1TJ ¼ J1 ¼ 0, where 0 is a matrix of
zeros. We thus ﬁnd if we multiply the matrix D that was
introduced in Eq. 2 from the front and the back by  1
2 J that:
 1
2 JDJ ¼  1
2 Jc1T J  1
2 JcT 1J þ JKJ ¼ JKJ
Furthermore, by substituting in our expression for J we ﬁnd:
 1
2 JDJ ¼ K  1
M 2 11T K11T
Every element of 11TK11T is equal to the sum of the
elements of K so the above manipulations demonstrate that
the centered matrix of distances,  1
2 JDJ, is equal to the Gram
matrix of kernels modulo an additive constant.
3. It is possible to introduce further sophistication into Laplacian
eigenmaps by introducing a diffusion kernel. When this modi-
ﬁcation is used the distances between each xi and each of its
k nearest points, yj, are transformed using the following isotro-
pic diffusion kernel:
Pi j ¼ Pðxi, yjÞ ¼ exp  jx  yj2
σ


ð14Þ
where σ is a hyperparameter. This diffusion kernel is at the heart
of diffusion maps, which works by calculating this quantity for
each pair of input data points without ﬁrst computing the
k nearest points or the pairs of data point that are within a
certain cutoff.
4. In diffusion maps a weighted graph P is calculated using
Eq. 14. This graph is then transformed using:
^P i j ¼
Pi j
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
DiiDj j
p
to give a matrix ^P that is equal to the identity minus the
symmetric-normalized Laplacian of the graph P. From this
matrix we then compute ^D using:
^D i j ¼
X
j6¼i
^Pi j
if
i ¼ j
0
otherwise
(
we then obtain an M  N matrix, ^X , with low-dimensional
projections for the M input points in its rows by diagonalizing
^D
1
2^P ^D
1
2,
discarding
the
largest
eigenvalue
and
its
corresponding eigenvector and then by taking the eigenvectors
corresponding to the N largest eigenvalues that remain and
placing them in the rows of ^X .
498
Gareth A. Tribello and Piero Gasparotto

5. The eigenvectors of the matrix that is diagonalized in diffusion
maps, ^D
1
2^P ^D
1
2, are related by a relatively simple transforma-
tion to the eigenvectors of ^D
1^P . This matrix is similar to the
matrix that appeared in Eq. 8 and that is diagonalized in
Laplacian eigenmaps.
6. The Chapman–Kolmogorov relation tells us that if we are given
a one-step transition probability matrix for a Markov chain, P,
we can extract the t-step transition probability matrix by raising
P to the tth power. It is well established, however, that we can
write the tth power of this transition matrix as:
Mt ¼ VΛtV1
ð15Þ
where V is a matrix containing the eigenvectors of M in its
columns and where Λ is a diagonal matrix that contains the
eigenvalues of M. Calculating the tth power of a diagonal
matrix involves simply raising each element to the power t.
Applying this procedure to Eq. 15 will therefore widen the
gap between the largest and smallest eigenvalues. Furthermore,
when Eq. 15 is used to recompose Mt each of the exponen-
tiated eigenvalues is only multiplied by its corresponding eigen-
vector. We thus ﬁnd that, when t is large, the matrix, Mt, that
we would construct by entering only the largest few eigenva-
lues and their corresponding eigenvectors into Eq. 15 is very
similar to the matrix that we would have obtained had we used
all the eigenvalues and eigenvectors when evaluating Eq. 15.
7. The matrix P that is diagonalized in diffusion maps is related to
the symmetric-graph Laplacian, ^L ¼ I  ^P . Graph Laplacians
of this sort appear in Laplacian eigenmaps. Furthermore, the
eigenvectors of ^L are identical to those of ^P . In addition, the
eigenvalues, λ, of ^L
are related to those of ^P
by 1  λ.
Consequently, because ^P is a positive matrix with eigenvalues
that are all positive, the eigenvectors that correspond to the
largest eigenvalues of ^P will be equal to the eigenvectors that
correspond with the smallest eigenvalues of ^L . This is why one
takes the eigenvectors corresponding to the smallest eigenva-
lues when using Laplacian eigenmaps and the eigenvectors
corresponding
to
the
largest
eigenvalues
when
using
diffusion maps.
References
1. McCammon JA, Gelin BR, Karplus M (1977)
Dynamics of folded proteins. Nature 267:585
2. Wales DJ (2003) Energy landscapes. Cam-
bridge University Press, Cambridge
3. Friedman JH (1997) On bias, variance, 0/1—
loss, and the curse-of-dimensionality. Data Min
Knowl Disc 1(1):55–77
4. Amadei A, Linssen ABM, Berendsen HJC
(1993) Essential dynamics of proteins. Proteins
Struct Funct Genet 17:412
5. Garcia AE (1992) Large-amplitude nonlinear
motions
in
proteins.
Phys
Rev
Lett
68:2696–2699
Dimensionality Reduction for Molecular Dynamics
499

6. Zhuravlev PI, Materese CK, Papoian GA
(2009) Deconstructing the native state: energy
landscapes, function and dynamics of globular
proteins. J Phys Chem B 113:8800–8812
7. Hegger R, Altis A, Nguyen PH, Stock G
(2007) How complex is the dynamics of pep-
tide folding? Phys Rev Lett 98(2):028102
8. Facco E, d’Errico M, Rodriguez A, Laio A
(2017) Estimating the intrinsic dimension of
datasets by a minimal neighborhood informa-
tion. Sci Rep 7:12140
9. Noe´ F, Clementi C (2015) Kinetic distance and
kinetic maps from molecular dynamics simula-
tion.
J
Chem
Theory
Comput
11
(10):5002–5011. PMID: 26574285
10. Piana S, Laio A (2008) Advillin folding takes
place on a hypersurface of small dimensionality.
Phys Rev Lett 101(20):208101
11. Borg I, Groenen PJF (2005) Modern multidi-
mensional scaling: theory and applications.
Springer, Berlin
12. Jolliffe IT (2002) Principal component analy-
sis. Springer, Berlin
13. James G, Witten D, Hastie T, Tibshirani R
(2013) An introduction to statistical learning
with applications in R. Springer, Berlin
14. Frenkel D, Smit B (2002) Understanding
molecular
simulation.
Academic
Press,
Orlando
15. Allen MP, Tildesley DJ (1990) Computer sim-
ulation of liquids. Oxford University Press,
Oxford
16. Kabsch W (1976) A solution for the best rota-
tion to relate two sets of vectors. Acta Crystal-
logr Sect A Cryst Phys Diffr Theor Gen
Crystallogr 32(5):922–923
17. Tenenbaum JB, de Silva V, Langford JC (2000)
A global geometric framework for nonlinear
dimensionality
reduction.
Science
290
(5500):2319–2323
18. de Silva V, Tenenbaum J (2004) Sparse multi-
dimensional scaling using landmark points.
Stanford
Univ.,
Stanford,
CA.
http://
graphics.stanford.edu/courses/cs468-05-win
ter/Papers/Landmarks/Silva_landmarks5.pdf
19. Scho¨lkopf B, Smola A, Mu¨ller K-R (1998)
Nonlinear component analysis as a kernel
eigenvalue
problem.
Neural
Comput
10
(5):1299–1319
20. Voter AF (2007) Introduction to the kinetic
Monte Carlo method. In: Sickafus KE, Koto-
min EA, Uberuaga BP (eds) Radiation effects
in solids, volume 235 of NATO science series.
Springer, Dordrecht, pp 1–23
21. Hochbaum DS, Shmoys DB (1985) A best
possible heuristic for the k-center problem.
Math Oper Res 10(2):180–184
22. Ceriotti M, Tribello GA, Parrinello M (2013)
Demonstrating
the
transferability
and
the
descriptive power of sketch-map. J Chem The-
ory
Comput
9(3):1521–1532.
PMID:
26587614
23. Barducci A, Bussi G, Parrinello M (2008) Well
tempered metadynamics: a smoothly converg-
ing and tunable free energy method. Phys Rev
Lett 100:020603
24. Bonomi M, Parrinello M (2010) Enhanced
sampling in the well-tempered ensemble. Phys
Rev Lett 104:190601
25. Balsera MA, Wriggers W, Oono Y, Schulten K
(1996) Principal component analysis and long
time protein dynamics. J Phys Chem 100
(7):2567–2572
26. Roweis
ST,
Saul
LK
(2000)
Nonlinear
dimensionality
reduction
by
locally
linear
embedding. Science 290(5500):2323–2326
27. Das P, Moll M, Stamati H, Kavraki LE, Clem-
enti C (2006) Low-dimensional, free-energy
landscapes of protein-folding reactions by non-
linear dimensionality reduction. Proc Natl
Acad Sci USA 103(26):9885–9890
28. Plaku E, Stamati H, Clementi C, Kavraki LE
(2007) Fast and reliable analysis of molecular
motion
using
proximity
relations
and
dimensionality
reduction.
Proteins
Struct
Funct Bioinf 67(4):897–907
29. Stamati H, Clementi C, Kavraki LE (2010)
Application of nonlinear dimensionality reduc-
tion to characterize the conformational land-
scape of small peptides. Proteins Struct Funct
Bioinf 78(2):223–235
30. Rohrdanz MA, Zheng W, Maggioni M, Clem-
enti C (2011) Determination of reaction coor-
dinates via locally scaled diffusion map. J Chem
Phys 134(12):124116
31. Zheng W, Rohrdanz MA, Maggioni M, Clem-
enti C (2011) Polymer reversal rate calculated
via locally scaled diffusion map. J Chem Phys
134(14):144109
32. Donoho DL, Grimes C (2002) When does
isomap recover the natural parameterization
of families of articulated images? Technical
Report 2002–27, Department of Statistics,
Stanford University
33. Donoho DL, Grimes C (2003) Hessian eigen-
maps: locally linear embedding techniques for
high-dimensional data. Proc Natl Acad Sci
USA 100(10):5591–5596
34. Rosman G, Bronstein MM, Bronstein AM,
Kimmel R (2010) Nonlinear dimensionality
reduction by topologically constrained isomet-
ric embedding. Int J Comput Vis 89:56–58
35. Dijkstra EW (1959) A note on two problems in
connexion
with
graphs.
Numer
Math
1
(1):269–271
500
Gareth A. Tribello and Piero Gasparotto

36. Floyd RW (1962) Algorithm 97: shortest path.
Commun ACM 5(6):345
37. Coifman RR, Lafon S, Lee AB, Maggioni M,
Nadler B, Warner F, Zucker SW (2005) Geo-
metric diffusions as a tool for harmonic analysis
and structure deﬁnition of data: multiscale
methods.
Proc
Natl
Acad
Sci
USA
102
(21):7432–7437
38. Coifman RR, Lafon S (2006) Diffusion maps.
Appl Comput Harmon Anal 21(1):5–30
39. Belkin M, Niyogi P (2003) Laplacian eigen-
maps for dimensionality reduction and data
representation.
Neural
Comput
15
(6):1373–1396
40. Ferguson AL, Panagiotopoulos AZ, Debene-
detti PG, Kevrekidis IG (2010) Systematic
determination of order parameters for chain
dynamics using diffusion maps. Proc Natl
Acad Sci USA 107(31):13597–13602
41. Singer A, Erban R, Kevrekidis IG, Coifman RR
(2009) Detecting intrinsic slow variables in
stochastic dynamical systems by anisotropic dif-
fusion maps. Proc Natl Acad Sci USA 106
(38):16090–16095
42. Rohrdanz MA, Zheng W, Clementi C (2013)
Discovering mountain passes via torchlight:
methods for the deﬁnition of reaction coordi-
nates and pathways in complex macromolecu-
lar
reactions.
Annu
Rev
Phys
Chem
64
(1):295–316. PMID: 23298245
43. Belkin M, Niyogi P (2003) Laplacian eigen-
maps for dimensionality reduction and data
representation.
Neural
Comput
15
(6):1373–1396
44. van der Maaten L, Hinton G (2008) Visualiz-
ing data using t-SNE. J Mach Learn Res
9:2579–2605
45. Ceriotti M, Tribello GA, Parrinello M (2011)
Simplifying the representation of complex free-
energy landscapes using sketch-map. Proc Natl
Acad Sci USA 108:13023–13029
46. Tribello GA, Ceriotti M, Parrinello M (2012)
Using sketch-map coordinates to analyze and
bias molecular dynamics simulations. Proc Natl
Acad Sci USA 109(14):5196–5201
47. Tribello GA, Ceriotti M, Parrinello M (2010)
A self-learning algorithm for biased molecular
dynamics. Proc Natl Acad Sci USA 107
(41):17509–17514
48. Mortenson PN, Evans DA, Wales DJ (2002)
Energy landscapes of model polyalanines. J
Chem Phys 117:1363
49. Pedregosa F,
Varoquaux
G, Gramfort A,
Michel V, Thirion B, Grisel O, Blondel M,
Prettenhofer
P,
Weiss
R,
Dubourg
V,
Vanderplas
J,
Passos
A,
Cournapeau
D,
Brucher M, Perrot M, Duchesnay E (2011)
Scikit-learn: machine learning in Python. J
Mach Learn Res 12:2825–2830
50. Ardevol A, Tribello GA, Ceriotti M, Parrinello
M (2015) Probing the unfolded conﬁgurations
of a β-hairpin using sketch-map. J Chem The-
ory
Comput
11(3):1086–1093.
PMID:
26579758
51. Frishman D, Argos P (1995) Knowledge-based
protein secondary structure assignment. Pro-
teins Struct Funct Bioinf 23(4):566–579
52. Mu Y, Nguyen PH, Stock G (2005) Energy
landscape of a small peptide revealed by dihe-
dral angle principal component analysis. Pro-
teins Struct Funct Bioinf 58(1):45–52
53. Hinsen K (2006) Comment on: “energy land-
scape of a small peptide revealed by dihedral
angle principal component analysis”. Proteins
Struct Funct Bioinf 64(3):795–797
54. Pietrucci F, Laio A (2009) A collective variable
for the efﬁcient exploration of protein beta-
sheet structures: application to SH3 and GB1.
J Chem Theory Comput 5(9):2197–2201
55. Dunker AK, Silman I, Uversky VN, Sussman
JL (2008) Function and structure of inherently
disordered proteins. Curr Opin Struct Biol
18:756–764
56. Constanzi S (2010) Modeling g protein-
coupled
receptors:
a
concrete
possibility.
Chim Oggi 28:26–31
57. Goldfeld DA, Zhu K, Beuming T, Friesner RA
(2011) Successful prediction of the intra- and
extracellular loops of four g-protein-coupled
receptors.
Proc
Natl
Acad
Sci
108
(20):8275–8280
58. Kmiecik S, Jamroz M, Kolinski M (2015)
Structure prediction of the second extracellular
loop in G-protein-coupled receptors. Biophys J
106:2408–2416
59. Dyson HJ, Wright PE (2005) Intrinsically
unstructured proteins and their functions. Nat
Rev Mol Cell Biol 6:197–208
60. Doye JPK, Miller MA, Wales DJ (1999) The
double-funnel
energy
landscape
of
the
38-atom Lennard-Jones cluster. J Chem Phys
110(14):6896–6906
61. Neirotti JP, Calvo F, Freeman DL, Doll JD
(2000) Phase changes in 38-atom Lennard-
Jones clusters. I. A parallel tempering study in
the canonical ensemble. J Chem Phys 112
(23):10340–10349
62. Calvo F, Neirotti JP, Freeman DL, Doll JD
(2000) Phase changes in 38-atom Lennard-
Jones clusters. II. A parallel tempering study
of equilibrium and dynamic properties in the
molecular
dynamics
and
microcanonical
ensembles.
J
Chem
Phys
112
(23):10350–10357
Dimensionality Reduction for Molecular Dynamics
501

63. Wales DJ (2002) Discrete path sampling. Mol
Phys 100:3285–3306
64. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for β hairpin
folding from combined parallel tempering and
metadynamics.
J
Chem
Am
Soc
128
(41):13435–13441. PMID: 17031956
65. Berman
HM,
Westbrook
J,
Feng
Z,
Gilliland G, Bhat TN, Weissig H, Shindyalov
IN, Bourne PE (2000) The protein data bank.
Nucleic Acids Res 28:235–242
66. Berman HM, Henrick K, Nakamura H (2003)
Announcing the worldwide protein data bank.
Nat Struct Biol 10:980
67. Rose PW, Prlic A, Altunkaya A, Bi C, Bradley
AR, Christie CH, Costanzo LD, Duarte JM,
Dutta S, Feng Z, Green RK, Goodsell DS,
Hudson B, Kalro T, Lowe R, Peisach E,
Randle
C,
Rose
AS,
Shao
C,
Tao
Y-P,
Valasatava Y, Voigt M, Westbrook JD, Woo J,
Yang H, Young JY, Zardecki C, Berman HM,
Burley SK (2017) The RCSB protein data
bank: integrative view of protein, gene and 3d
structural information. Nucleic Acids Res 45:
D271–D281
68. Ardevol A, Palazzesi F, Tribello GA, Parrinello
M (2016) General protein data bank-based
collective
variables
for
protein
folding.
J
Chem Theory Comput 12(1):29–35. PMID:
26632859
69. Kukharenko O, Sawade K, Steuer J, Peter C
(2016) Using dimensionality reduction to sys-
tematically expand conformational sampling of
intrinsically disordered peptides. J Chem The-
ory
Comput
12(10):4726–4734.
PMID:
27588692
70. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci USA 99
(20):12562–12566
71. Spiwok V, Lipovova´ P, Kra´lova´ B (2007) Meta-
dynamics in essential coordinates: free energy
simulation of conformational changes. J Phys
Chem
B
111(12):3073–3076.
PMID:
17388445
72. Sutto L, D’Abramo M, Gervasio FL (2010)
Comparing the efﬁciency of biased and unbi-
ased molecular dynamics in reconstructing the
free energy landscape of met-enkephalin. J
Chem Theory Comput 6(12):3640–3646
73. Spiwok V, Kralova B (2011) Metadynamics in
the
conformational
space
nonlinearly
dimensionally reduced by Isomap. J Chem
Phys 135(22):224504
74. Gasparotto P, Ceriotti M (2014) Recognizing
molecular patterns by machine learning: an
agnostic structural deﬁnition of the hydrogen
bond. J Chem Phys 141(17):174110
75. Gasparotto P, Meißner RH, Ceriotti M (2018)
Recognizing local and global structural motifs
at the atomic scale. J Chem Theory Comput 14
(2):486–498. PMID: 29298385
76. De S, Bartok AP, Csanyi G, Ceriotti M (2016)
Comparing molecules and solids across struc-
tural and alchemical space. Phys Chem Chem
Phys 18:13754–13769
77. Musil F, De S, Yang J, Campbell JE, Day GM,
Ceriotti M (2018) Machine learning for the
structure-energy-property
landscapes
of
molecular crystals. Chem Sci 9:1289–1300
78. Chen W, Ferguson AL (2018) Molecular
enhanced sampling with autoencoders: on-
the-ﬂy collective variable discovery and acceler-
ated free energy landscape exploration. arXiv
e-prints, December 2018
79. Sultan MM, Wayment-Steele HK, Pande VS
(2018)
Transferable
neural
networks
for
enhanced sampling of protein dynamics. arXiv
e-prints, January 2018
80. Bowman GR, Pande VS, Noe´ F (2014) An
introduction to Markov state models and their
application to long timescale molecular simula-
tion. In: Bowman GR, Pande VS, Noe´ F (eds)
Advances in experimental medicine and biol-
ogy. Springer, Dordrecht
81. Noe´ F, Clementi C (2017) Collective variables
for the study of long-time kinetics from molec-
ular trajectories: theory and methods. Curr
Opin Struct Biol 43:141–147. Theory and
simulation l Macromolecular assemblies
82. Tiwary P, Parrinello M (2013) From metady-
namics
to
dynamics.
Phys
Rev
Lett
111:230602
83. Tiwary P, Berne BJ (2016) Spectral gap opti-
mization of order parameters for sampling
complex molecular systems. Proc Natl Acad
Sci 113(11):2839–2844
84. Sultan
MM,
Pande
VS
(2017)
tICA-
metadynamics: accelerating metadynamics by
using kinetically selected collective variables. J
Chem
Theory
Comput
13(6):2440–2447.
PMID: 28383914
502
Gareth A. Tribello and Piero Gasparotto

Chapter 20
Analysis Libraries for Molecular Trajectories:
A Cross-Language Synopsis
Toni Giorgino
Abstract
Analyzing the results of molecular dynamics (MD)-based simulations usually entails extensive manipula-
tions of ﬁle formats encoding both the topology (e.g., the chemical connectivity) and conﬁgurations (the
trajectory) of the simulated system. This chapter reviews a number of software libraries developed to
facilitate interactive and batch analysis of MD results with scripts written in high-level, interpreted
languages. It provides a beginners’ introduction to MD analysis presenting a side-by-side comparison of
major scripting languages used in MD and shows how to perform common analysis tasks within the Visual
Molecular Dynamics (VMD), Bio3D, MDTraj, MDAnalysis, and High-Throughput Molecular Dynamics
(HTMD) environments.
Key words Molecular dynamics, Trajectory analysis, Scripting languages, VMD, Bio3D, MDTraj,
MDAnalysis, HTMD
1
Introduction
The backbone of molecular dynamics (MD)-based methods is to
integrate the equations of motion of a system with a given Hamil-
tonian. The integration is performed by an MD engine with a ﬁnite
time-step, sufﬁciently ﬁne to capture the fastest motion of interest
(e.g., bond vibrations). Commonly, one is interested in long-time
behavior, and therefore, simulations are performed for several
orders of magnitudes longer than the integration time-steps,
making integration the most compute-intensive component of
the MD workﬂow; this, in turn, makes it natural to keep a record
(“trajectory”) of the states through which the system goes for later
analysis.
The objective of this chapter is to provide an operative intro-
duction to the libraries most often used in MD analysis in combi-
nation
with the corresponding
programming
languages. In
particular, I strive to provide (a) a side-by-side view of the con-
structs most important for analysis (including ﬁle input and output
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_20, © Springer Science+Business Media, LLC, part of Springer Nature 2019
503

operations) and (b) a side-by-side view of the object models used
with reference to a simple but realistic analysis task.
This review is restricted to a few MD analysis libraries usable in
interpreted (also known as scripting) languages because they are
best suited for interactive and rapid prototyping tasks. The chapter
focuses on ﬁve libraries which are actively developed, open-source,
(Table 1) and whose scope was mainly trajectory analysis rather
than modeling (although the line between the two may be blurred;
Note 1 lists additional libraries).
2
Background
One important output of MD simulations are so-called trajectory
ﬁles, that is, the record of the coordinates of particles composing a
system, taken at regular intervals (in atomistic simulations, particles
model individual atoms, while in coarse-grained models they repre-
sent more generic “beads”). While MD runs occupy computing
resources for days or months, the analysis of trajectories is generally
fast enough to enable an “iterative” hypothesis-calculation-assess-
ment development cycle, for example, in search of collective vari-
ables, collective modes, or any other of the observables which are
most expressive for the system at hand and which can be computed
from the trajectory.
Other chapters of this book present a wealth of tools to per-
form specialized analysis types. Such tools can be distributed as
either command-line utilities (e.g., GROMACS’ utilities [1],
Amber project’s CPPTRAJ [2]), or with graphical user interfaces
(GUI; either stand-alone or embedded in molecular viewers; see
Note 2). Of particular importance is the PLUMED library: origi-
nally developed for biasing MD simulations along selected collec-
tive variables (CV), the array of CVs has become increasingly rich
and expressive [3, 4]. The libraries can therefore be used to perform
analysis on pre-computed trajectories, deﬁning the observables to
Table 1
Libraries presented in this chapter (sorted by first publication date)
Software
Version Language Reference Pub. date URL
VMD
1.9.3
Tcl
[6]
1996
www.ks.uiuc.edu/Research/vmd
Bio3D
2.3
R
[9]
2006
thegrantlab.org/bio3d
MDAnalysis 0.17.0
Python
[16]
2011
www.mdanalysis.org
MDTraj
1.9.1
Python
[18]
2015
www.mdtraj.org
HTMD
1.14
Python
[19]
2016
www.htmd.org
Python-based ones were used with Python version 3.6.5, from the Conda distribution of Anaconda, Inc.
504
Toni Giorgino

be computed and atom sets through PLUMED’s syntax [5] which,
while not as general as a general-purpose programming language, is
still very expressive for structure-oriented computations to be per-
formed on each trajectory frame.
Developing one’s own analysis routine in the form of computer
code is, however, necessary whenever pre-made tools fall short of
the task. This is a frequent occurrence for advanced MD users,
especially when involved in method development. Traditional sci-
entiﬁc computing languages such as Fortran, C, and C++ in their
“bare” form do not suit well the analysis of MD trajectories for two
reasons: ﬁrst, processing trajectories requires parsing a wealth of
molecular formats, which have been developed over time to accom-
modate the needs of ever-increasing scales of simulations; these
formats do not only encode the coordinates of atoms but also a
number of important attributes such as masses, charges, and chem-
ical bonding. Second, and related, the analysis of biological macro-
molecules does in large part make use of chemical (e.g., how does
one tell protein from ligand from water?) or structural (e.g., how
does one distinguish secondary structure elements?) characteristics
of the underlying system. Accessing these atomic attributes
becomes easier in presence of an appropriate object model specifying
(a) which are the entities modeled in software, (b) how are they
related (e.g., by chemical connectivities) and (c) what are their
attributes (e.g., atoms have beta factors, bonds have orders), and
(d) the methods that can be called on each. Developing a suitable
object model is no easy task, greatly simpliﬁed in high-level, object-
oriented languages.
3
Programming Languages
The scripting languages underlying the libraries examined in this
review are Tcl, R, and Python 3. They have in common their being
dynamic (i.e., functions can be deﬁned at run-time) and dynami-
cally typed (i.e., there is no need to predeclare the types of vari-
ables—see Note 3 for remarkable cases when this is useful).
It will be out of the scope of this chapter to discuss the details of
each programming language (easily found outside of the scientiﬁc
literature), nor shall it provide a systematic description of the
feature of each library, for which the corresponding reference man-
uals are the best and most updated resource (see Note 4).
3.1
Tcl
The Tcl language (originally Tool Command Language) was cre-
ated in 1988 as an interpreted language suitable for embedding in
other software. It has an important role in the analysis of MD
simulations mostly because it is the language of choice for the
Visual Molecular Dynamics (VMD) software [6], an open-source
MD Analysis Libraries: A Synopsis
505

package enabling the manipulation of long MD-derived trajectories
(Subheading 5.1).
The structure of the Tcl language is somewhat unusual in the
sense that it is centered around strings (function bodies, lists, and
numbers, all being strings by default) and a Polish notation for
function calls—that is, f(x,y) is written as [f $x $y]. Square brack-
ets execute the function which they contain, replacing the return
value, while curly braces quote strings (including function bodies).
Other features are:
l
Variables are preﬁxed by $ to be replaced by their value. A rule of
thumb is therefore to use $ when reading variables, and not
when modifying them.
l
Variables of outer scopes are not visible by default; they are
exposed by constructs such as global (globals), upvar (access
the upper evaluation frame), and variable (variables bound to
a namespace).
l
Lists are space-separated strings (items can be quoted by curly
braces if necessary). Functions such as llength and lindex
provide array-like access (including nested ones). Indices start
from 0.
l
There are two types of associative hashes, namely arrays, which
use round parentheses and cannot be nested and dictionaries,
which can be nested.
l
Mathematical expressions can be written in the more customary
inﬁx notation if evaluated with expr.
3.2
R
The R programming language derives from the S language, itself
rooted in the 1970s’ efforts at the Bell Labs to provide an interac-
tive environment for statistical calculations. R is also the name of
the interpreter, which is actively developed and distributed as an
open-source project [7].
R is a higher-level language still, and its features enable a
programming style which is not conductive to meaningful parallels
with the other two languages considered. For example, instead of
loops, functional “apply” is encouraged (and sometimes necessary
for efﬁciency reasons); it is therefore excluded from some of the
syntax comparisons. Implicit rules often allow one not to concern
himself with array shapes, which for the most part follow the
“natural behavior,” carrying over annotations such as row and
column names. Also, functions are heavily overloaded by optional
arguments, so that, for example, the seq function will generate all
kinds of numeric sequences (given length vs. given spacing and so
on); likewise, many variations of text parsing are accommodated by
(say) the read.table function, or equivalent ones provided in
external packages.
506
Toni Giorgino

For the reasons above, R is a natural ﬁt for statistics-heavy
computations. Other arguably attractive features of the R language
are: (1) its expressive functional foundation and (2) two extensive,
yet cohesive and well-curated, repositories of add-on packages,
known as CRAN (general purpose) and Bioconductor (focused
on bioinformatics [8]). Of special relevance for MD analysis is the
Bio3D package [9], which will be part of the side-by-side examples
in this chapter.
3.3
Python
Python is a relatively new (ﬁrst released in 1991) interpreted lan-
guage for general purpose programming. Its main features are
arguably a balance of readability, conciseness, and speed; the
object-oriented semantics are especially intuitive; and extension
modules are easy to import (recently made even simpler with the
centralized Conda package manager). The main interest of this
language for the MD community is the number of MD-related
libraries which are being released: beyond those listed in Table 1
and Note 1, it may be worth mentioning PyEMMA (Markov
Model training and testing, [10]), OpenMM (MD engine with
GPU acceleration, [11]), MSMBuilder (statistical models for bio-
molecular dynamics, [12]), and many others. Notable language
features are:
l
White space is signiﬁcant, deﬁning indentation-based control
blocks.
l
Built-in data types include integer, ﬂoating point, and associative
arrays (hashes). Arbitrary classes can be deﬁned with object-
oriented constructs.
l
Many notable libraries, of which NumPy (linear algebra) and
Pandas (record-based data frames) are especially convenient for
trajectory analysis purposes.
l
Add-on packages (modules) become visible in the namespace
when import-ed. The pip and conda package managers pro-
vide automated installations.
l
Packages exist to compile compute-intensive portions into
native code almost transparently (see Note 3).
4
Useful Programming Constructs
This section will brieﬂy review how common structured program-
ming constructs and input-output (IO) operations are expressed in
the language mentioned earlier, by means of side-by-side parallels.
The objective of this comparison is didactic and practical, in order
to enable users to easily switch languages.
MD Analysis Libraries: A Synopsis
507

4.1
Iterations
Figure 1 shows how four common loop idioms can be implemen-
ted, namely (1) the common “indexed for” which increments an
integer index i from 0 (included) to N (excluded); (2) iterating over
the contents of a list, assigning the element to the variable x;
(3) iterating two vectors in parallel, which is useful, for example,
when Cartesian coordinates are stored separately; and (4) not only
iterating at the same time over a list of contents as in (b) but also
keeping an integer index. Of note, R has the for(x in vec)
construct, but it is often replaced by implicit vectorization and
mapping operators such as apply.
4.2
File Input
and Output
Figure 2 shows Tcl and Python idioms for accessing ﬁles in read and
write modes. In the case of read, line-based iterations are shown.
Note that Python modules are an excellent alternative to parse and
create ﬁles in common formats; of particular note are comma-
separated values (via the csv standard module); Excel ﬁles (via
openpyxl, xlrd, and others) and HDF5 (via h5py). Further-
more, the numpy package can parse text ﬁles into numeric matrices
(function genfromtxt()), and pandas reads and writes data
frames (PDB-like data structures representing tables with multiple
attributes of heterogeneous types) in various formats via its read_X
and to_X methods. Explicit ﬁle IO is seldom necessary in R, given
TCL
for {set i 0} {$i<$N} {incr i}
{ ... }
→
foreach x $vec
{ ... }
→
foreach x $xvec y $yvec
{ ... }
→
set i 0
foreach x $vec { ...; incr i }
R
for (i in 1:N) { ... }
for (x in vec) { ... }
mapply(function(x,y) { ... },
xvec, yvec)
# R indexes from 1
for (i in seq_len(vec)) { ... }
Python
for i in range(N):
...
for x in vec:
...
for x,y in zip(xvec, yvec):
...
for i,x in enumerate(vec):
...
Fig. 1 Four iteration styles: integer index, list contents, parallel lists, and list contents plus index
508
Toni Giorgino

the ﬂexibility of its high-level parsing functions (see, e.g., read.
table and write.table, the openxlsx package, and so on).
4.3
Strings
Figure 3 shows a selection of common string manipulation opera-
tors. In addition to the split and join operators (on chosen delimi-
ters), several other operators are provided as subcommands of the
string command (Tcl), in the str module (Python), and the
stringr package (R).
TCL
set f [open $name r]
set data [read $f]
set lines [split $data "\n"]
close $f
set g [open $name w]
puts $g "Hello world"
close $g
Python
with open(name,"r") as f:
# data=f.read()
# Read whole file
lines=f.readlines()
with open(name,"w") as g:
g.write("Hello world")
Fig. 2 File input and output
TCL
set sl [string length $s]
set l [split $s ,]
set s2 [join $l ,]
string range $s 10 20
set v 123
format "%5.2f" $v
R
sl <- nchar(s)
l <- strsplit(s,",")[[1]]
paste(l,collapse=",")
substr(s,11,21)
v <- 123
sprintf("%5.2f",v)
Python
sl = len(s)
l = s.split(",")
s2 = ",".join(l)
s[10:21]
v = 123
f"{v:5.2f}"
"%5.2f" % v
# equivalent
"{:5.2f}".format(v) # equivalent
Fig. 3 Basic string operations
MD Analysis Libraries: A Synopsis
509

4.4
Functions
Figure 4 shows how functions are deﬁned in TCL, Python, and
R. Of note, TCL provides optional arguments with defaults. Both
Python and R provide named arguments with defaults. Python
functions may uncharacteristically return multiple values at once:
x,y ¼ f().
4.5
Arrays
and Hashes
The nomenclature of data structures differs between languages. For
homogeneity I will use the names array (ordered lists of objects
indexed by an integer) and hash (unordered lists indexed by arbi-
trary objects, also known as associative array). Figure 5 shows
typical semantics in the three languages.
Accessing arrays in Python and R occurs with a square bracket
notation, with the caveat that the latter uses 1-based indices. TCL
uses list operators such as lindex (indexing), lset (assignment),
linsert, lsort, and so on, all zero-based.
TCL
proc sum {a b} {
return [expr $a+$b]
}
proc norm {v {n 2}} {
set s 0.0
foreach x $v {
set s [expr $s+$x**$n]
}
return [expr $s**(1.0/$n)]
}
norm {3 4}
;# = 5
norm {3 4} 1
;# = 7
R
sum_n <- function(x,y) x+y
norm_n <- function(v, n=2) {
s <- sum(v**n)
return(s**(1/n))
}
# Avoids built-in sum, norm
norm_n( c(3,4) )
# = 5
norm_n( c(3,4), 1 )
# = 7
norm_n( n=1, v=c(3,4) )
# also 7
Python
def sum(x,y):
return x+y
def norm(v, n=2):
s=0
for x in v:
s+=x**n
return s**(1/n)
norm([3,4])
# = 5
norm([3,4], 1)
# = 7
norm(n=1, v=[3,4]) # also 7
Fig. 4 Deﬁning functions. The norm function takes the Ln norm of the ﬁrst argument (a list of ﬂoating-point
values), with n defaulting to 2
510
Toni Giorgino

All three languages support hashes, with slightly different
semantics. Of note, Tcl provides two hash-like structures, both
shown in Fig. 5, namely arrays, restricted to simple key-value
pairs, and more ﬂexible dictionaries, which can implement arbi-
trarily nested data structures.
4.6
Algebra
Figure 6 shows basic math and linear algebra constructs. Using the
common inﬁx syntax in TCL requires the expr function. Common
linear algebra operators are part of core R functions; of the numpy
module in Python; and (to a limited degree) of the math::
linearalgebra TCL package and VMD’s built-in functions
such as vecscale.
TCL
set v {10 20 30}
set v [list 10 20 30];
# equivalent
lindex $v 1
lset v 1 42;
# no £ prefix
llength $v
set m {{1 2} {3 4}}
lindex $m 0 1;
# = 2
set a_dict [dict create beta 1 occ .7]
dict get $a_dict beta;
# 1
dict keys $a_dict;
# beta, occ
array set a_arr {beta 1 occ .7}
puts $a_arr(beta);
# 1
array names a_arr;
# beta, occ
R
v <- c(10,20,30)
v[2]
v[2] <- 42
length(v)
m <- matrix(c(1,2,3,4),
byrow=T,ncol=2)
m[1,2]
a=list(beta=1, occ=.7)
names(a)
# beta, occ
a[['beta']]
Python
v = [10, 20, 30]
v[1]
v[1] = 42
len(v)
m=[[1,2], [3,4]]
m[0][1]
# = 2
import numpy as np
mn = np.array(m)
# more flexibly
mn[0,1]
a = {'beta': 1 ,
'occ':
.7}
list(a.keys())
# beta, occ
a['beta']
Fig. 5 Array- and hash-wise manipulation
MD Analysis Libraries: A Synopsis
511

TCL
# Floating point math requires "expr"
set d [expr sqrt($x**2+$y**2)]
# Expr is implicit in conditionals
if { $x>0 && $y>0 }
{ puts "First quadrant" }
→
# Part of tcllib
package require math::linearalgebra
set m {{1 2} {2 1}}
math::linearalgebra::matmul $m $m
math::linearalgebra::det $m
math::linearalgebra::eigenvectorsSVD $m
# Eig. for symmetric matrices only
package require math::complexnumbers
namespace import math::complexnumbers::*
sqrt [complex -1 0]
exp [complex 0 3.1416]
R
## Assignment arrow is common
d <- sqrt(x**2+y**2)
if(x>0 && y>0) {
message("First quadrant")
}
m <- matrix(c(1,2,2,1),
byrow=T,ncol=2)
m %*% m
det(m)
eigen(m)$values
## Imaginary is postfix i
sqrt(-1+0i)
exp(pi*1i)
Python
# Import math functions
from math import *
d=sqrt(x**2+y**2)
# Note the non-C-like Boolean operators
if x>0 and y>0:
print("First quadrant")
# Linear algebra by numpy
m=np.array([[1, 2], [2, 1]])
m @ m
# Matrix product; also
m.dot(m)
→
np.linalg.det(m)
np.linalg.eig(m)
# Use numpy or cmath for complex maths.
Imaginary unit is postfix j
→
np.sqrt(-1+0j)
np.exp(pi*1j)
Fig. 6 Arithmetic and linear algebra
512
Toni Giorgino

4.7
Exceptions
Finally, Fig. 7 shows the common idioms for recovering from errors
(catching) or signaling them to the callers (raising).
5
Molecular Dynamics Analysis Libraries
This section will present parallel comparisons for the ﬁve MD
analysis libraries listed in Table 1. Each of the packages contains
extensive reference material and examples (see Note 5 for pointers).
I will not discuss installation procedures, found in the available
documentation, but only remark that the TCL interpreter is
embedded in the VMD software (accessible under “Extensions/
Tk Console”); that Bio3D is available through R’s install.
packages(“bio3d”) call; and that Python-based libraries can be
easily installed via the Conda package manager (see Note 6).
5.1
Visual Molecular
Dynamics
VMD [6] is one of the most widely used software packages for MD
visualization and analysis (it also includes modeling facilities). Its
main strength is that it deals well with large systems (of the order of
millions of atoms) and/or very long trajectories (millions of
frames). Of note, VMD has a plug-in system [13–15], which allows
graphical interfaces to be developed with Tcl/Tk, an unusually
programmer-friendly GUI tool kit.
5.2
Bio3D
Bio3D [9] is an R package for comparative analysis of protein
structures. It is notable for its integration with the R statistical
TCL
# To catch
if [catch {dangerous} e] {
puts "Error caught: $e"
}
# To raise
error "Singularity encountered"
R
## To catch
tryCatch(dangerous(),
error = function(e) {
message("Error caught:",
e)})
→
## To raise
stop("Singularity encountered")
Python
# To catch
try:
dangerous()
except Exception as e:
print(f"Error caught: {e}")
# To raise
raise Exception("Singularity")
Fig. 7 Exception handling
MD Analysis Libraries: A Synopsis
513

environment and object model, which facilitates interoperability
with the large array of statistical methods implemented in CRAN
packages, and the fact that it provides methods for analysis on the
basis of sequence alignments (multiple-PDB objects).
5.3
MDAnalysis
MDAnalysis [16, 17] is an object-oriented Python library for the
processing of MD trajectories. Notable features are its “streaming”
design enabling larger- than-memory processing, methods dedi-
cated to lipid bilayers identiﬁcation, and an object model for
set-oriented manipulation of atom selections.
5.4
MDTraj
MDTraj [18] is a Python library dedicated to the manipulation of
MD trajectories, with an eye to the integration with external
packages. Of note, the library is well integrated with the OpenMM
GPU-accelerated simulation engine [11].
5.5
High-Throughput
Molecular Dynamics
High-throughput molecular dynamics (HTMD) [19] is a Python-
based environment integrating facilities for MD analysis, system
preparation [20], building [21], ligand parameterization, and sim-
ulation (with the included ACEMD engine [22]). Of note, HTMD
suits well the analysis of multiple independent trajectories (“high-
throughput”) via Markov state model analysis.
6
Examples of Trajectory Analysis Constructs
To provide a concrete example, I demonstrate side by side how a
simple but realistic analysis task is implemented in the various
analysis libraries. It is applied to a publicly available trajectory
containing 40 ns of constant-pressure simulation of the acid-
sensing ion channel (ASIC) 1 trimer [23] embedded in a POPC
membrane, retrieved from the PlayMolecule membrane protein
repository [21].
The comparison is restricted to the basic features that could be
reasonably compared side by side. They constitute the “least com-
mon denominator” of MD processing: each of the libraries has far
more advanced capabilities, to whose documentation readers are
referred. Finally, note that there are differences in the physical units
returned.
The code blocks provided in the next subsections build on each
other and are meant to be executed in order. Note 7 provides code
to initialize the pdb and xtc ﬁle name variables and download the
data ﬁles.
6.1
Loading
Trajectories
The ﬁrst step of analysis is to load trajectories into memory (Fig. 8).
This generally requires supplying both a topology ﬁle, containing
atom types and residue information, and a binary trajectory ﬁle,
514
Toni Giorgino

containing the coordinates taken at regular intervals during the
simulation.
Note that usually the number of atoms is assumed constant
throughout the simulation (this also a limitation of common MD
trajectory formats). Note also that MDAnalysis does not hold the
whole trajectory in memory but rather it updates the associated
objects while iterating; see Note 8 for coding implications. Once a
system is loaded, a representation of the topology (or at least the
main ﬁelds) is built in-memory and can be queried. Depending
on the language, a number of attributes provide object-oriented
access to residues’ and atoms’ properties (Table 2). Some libraries
(depending on the simulation software) also provide access to unit-
cell dimensions and physical time between frames.
6.2
Frame Selection
Figure 9 shows the syntax to retrieve the number of atoms (system
size), the length of a trajectory, and the actual values of coordinates.
Coordinates are usually stored as the underlying language’s matrix
objects. Section 6.4 will show how “slice” operators extract of a
subset of atoms or frames.
6.3
Atom Selection
The ability to select atoms on the basis of their characteristics
(identiﬁers, residues numbers, or chemical properties) is central to
analysis. Most libraries implement atom selection languages (ASL),
strings which can be applied to a trajectory frame, and ultimately
evaluate to a Boolean value per each atom, indicating whether the
selection includes the atom or not (Fig. 10). For system-speciﬁc
examples, let us show how to extract the Oη atom of ASIC1’s Y72
residue and the four atoms comprising the χ1 dihedral of W288
(involved in acid-dependent gating [24]).
It is important to note some variations in the ASL syntaxes,
summarized in Table 3. Of note, atom selection objects (returned
VMD
set t [mol new $pdb]
animate delete all
mol addfile $xtc waitfor all
Bio3D
library(bio3d)
tp <- read.pdb(pdb)
tp$xyz <- read.dcd(dcd)
MDAnalysis
import MDAnalysis as mda
t = mda.Universe(pdb, xtc)
MDTraj
import mdtraj as mdt
t = mdt.load(xtc, top=pdb)
HTMD
from htmd.ui import *
t=Molecule(pdb)
t.read(xtc)
[Space for caption]
Fig. 8 Loading topologies and trajectories. R code uses a different variable name not to overwrite the built-in
transpose operator t()
MD Analysis Libraries: A Synopsis
515

by the atomselect command) are central in VMD, as they are
used to read and modify most of a system’s properties; its extensive
ASL has keywords that select on primary sequence, PDB ﬁelds,
steric context, geometry, polarity, and so on.
6.4
Filtering
and Writing
It is often useful to ﬁlter out atoms not of interest (say, water
molecules) either to speed up calculations or to produce input
ﬁles for further programs (e.g., docking software). Figure 11
shows an example of the syntax used for ﬁltering the trimer’s
backbone atoms and writing the ﬁrst frame to a PDB ﬁle.
6.5
Basic Geometry
Once coordinates are extracted from the trajectory object, they can
be manipulated with the language’s native operators. All libraries
Table 2
Approximate correspondence between fields in PDB, VMD atom selection objects, Bio3D’s atom data
frame, properties of MDAnalysis’ AtomGroup objects and MDTraj object model properties (R: an
instance of a Residue object; A: an instance of an Atom object)
PDB ﬁeld
VMD,
HTMD
Bio3D MDAnalysisa MDTraj
Description (PDB 3.3 standard)
ATOM
type
Record name
serial
serial
eleno
A.serial
Atom serial number
name
name
elety
names
A.name
Atom name
altLoc
altloc
alt
altLocs
Alternate location indicator
resName
resname
resid
resnames
R.name
Residue name
chainID
chain
chain
R.chain.index
Chain identiﬁer
resSeq
resid
resno
resids
R.resSeq
Residue sequence number
iCode
insertion
insert
icodes
Code for insertion of residues
x
x
x
Orthogonal coordinates for X in
Angstroms
y
y
y
Orthogonal coordinates for Y in
Angstroms
z
z
z
Orthogonal coordinates for Z in
Angstroms
occupancy
occupancy o
occupancies
Occupancy
tempFactor beta
b
tempfactors
Temperature factor
segIDb
segname
segid
segids
R.segment_id
Segment identiﬁer
element
element
elesy
A.element
Element symbol
charge
charge
charge
Charge on the atom
aEquivalent properties are also present in Residue and Atom instances
bNo longer part of the PDB 3.3 format version but used, for example, for deﬁning molecules in system building
516
Toni Giorgino

provide operators to compute derived quantities such as distances,
angles, torsions, hydrogen bonds, surface-accessible areas, con-
tacts, and so on. As noted earlier, the analysis features of each library
are extensive, and even a partial list would be prohibitively long.
Figure 12 shows the programming style followed in each sys-
tem to compute two representative quantities, that is, (1) the center
of mass and (2) the W288 χ1 dihedral, either for a single frame or
over the whole trajectory. Care must be taken to check whether
operators account for periodic boundary conditions.
6.6
Alignment
and Root-Mean-
Square Deviation
Minimum root-mean-square deviation (RMSD) alignments are a
frequent operation in MD analysis, enabling the geometrical com-
parison between selected portions of two structures. The typical
VMD
# Number of frames
molinfo top get numframes
set t [atomselect top all]
$t num;
# Number of atoms
$t frame 0
$t get {x y z}; # Coordinates
pbc get;
# Unit cell
Bio3D
nrow(tp$xyz)
# 40 frames
nrow(tp$atom)
# 28799 atoms
## Accessing coordinates in frame 0
## reshaped for convenience
xyz <- tp$xyz[1,]
xyz <- matrix(xyz, ncol=3, byrow=T)
## Or: array(xyz,c(40,3,28799))
MDAnalysis
# Self-explanatory
t.atoms.n_atoms
t.trajectory.n_frames
# Atoms by 3
t.atoms.positions
# Unit cell
t.atoms.dimensions
MDTraj
# Number of frames
len(t)
# Frames by Atoms by 3
t.xyz.shape
# Coordinates in frame 0
t.xyz[0]
# Unit cell
t.unitcell_lengths[0,:]
HTMD
t.numFrames
t.numAtoms
# Atoms by 3 by frames
t.coords
# Unit cell
t.box[:,0]
Fig. 9 Accessing system sizes and frame coordinates
MD Analysis Libraries: A Synopsis
517

formulation proceeds in three steps: (1) search the proper rigid
transformation that minimizes the RMSD distance between a set
of alignment atoms of a trajectory and the corresponding set in a
reference conﬁguration (superposition step), (2) apply the transfor-
mation to the trajectory (alignment); and (3) optionally return the
root-mean square of the distances between a set of aligned mea-
surement (or displacement) atoms and the corresponding ones in
the reference (RMSD computation proper; see Note 9). Figure 13
summarizes how the steps can be performed; the alignment and
RMSD computation steps are coded separately to make them
explicit. Once the alignment is performed, the modiﬁed trajectory
can be further processed or saved back as seen in Sect. 6.4
(or with the AlignTraj method in the case of MDAnalysis). Code
for VMD uses the VMD Extensions Functions convenience library
(see Note 10).
VMD
set y72_oeta [atomselect top "resid 72
and name OH and chain 0"]
→
set w288_chi1 [atomselect top "resid 288
and name N CA CB CG and chain 0"]
→
# Access the "occupancy" property
# of a single atom
$y72_oeta get occupancy
Bio3D
pdb <- tp$atom
y72_oeta <- pdb[pdb$resno == 72
&
pdb$elety == "OH" &
pdb$chain == "0" , ]
w288_chi1 <- atom.select(tp,
elety=c("N","CA","CB","CG"),
resno=288, chain="0")
y72_oeta$o
MDAnalysis
y72_oeta = t.select_atoms("resid 72 and
name OH and segid 0")
→
w288_chi1 = t.select_atoms("resid 288
and name N CA CB CG and segid 0")
→
y72_oeta.atoms.occupancies
y72_oeta.atoms[0].occupancy
# also
MDTraj
y72_oeta = t.topology.select("residue 72
and name OH and chainid 0")
→
w288_chi1 = t.topology.select("residue
288 and name N CA CB CG and chainid
0")
→
→
t.atom_slice(y72_oeta).topology.\
atom(0).element
HTMD
y72_oeta = t.atomselect("resid 72 and
name OH and chain 0")
→
w288_chi1 = t.atomselect("resid 288 and
name N CA CB CG and chain 0")
→
t.occupancy[y72_oeta]
[Space for caption]
Fig. 10 Selection of Tyr72’s Oη atom and the four atoms deﬁning the Trp288’s χ1 dihedral in the ﬁrst protein
subunit via atom selection languages
518
Toni Giorgino

Table 3
Correspondences between keywords in the atom selection languages
VMD-like*
MDTraj
Description
name
name
Atom name
index
index
Atom index (0-based)
mass
mass
Element atomic mass (Dalton)
resname
resname
Three-letter residue code
residue
resid
Residue index (0-based)
resid
residue
Residue sequence record
rescode
One-letter residue code
element
type
Chemical symbol
type
Forceﬁeld atom type
chainid
Chain index (0-based)
chain
Chain identiﬁer
segid
segment_ id
Segment identiﬁer
Computed attributes (e.g., “backbone”) are omitted
*VMD, MDAnalysis and HTMD
VMD
set bb [atomselect top backbone]
# Write backbone frame 0
animate write pdb bb_frame0.pdb
beg 0 end 0 sel $bb
→
Bio3D
bb <- atom.select(tp, "backbone")
tp_bb <- trim(tp, bb)
## Select frame 1 (i.e. 0) only
bb_ref <- tp_bb
bb_ref$xyz <- trim(bb_ref$xyz, 1)
write.pdb(bb_ref, "bb_frame0.pdb")
MDAnalysis
bb = t.select_atoms("backbone")
with mda.Writer("bb_frame0.pdb") as w:
t.trajectory[0]
w.write(bb)
# Also bb.write() for single frames
MDTraj
bb = t.topology.select("backbone")
t_bb = t.atom_slice(bb)
# Subset
# Select frame 0 (also [0])
bb_ref = t_bb.slice(0)
# Write to file
bb_ref.save("bb_frame0.pdb")
HTMD
bb = t.copy()
bb.filter("backbone")
bb.dropFrames(keep=0)
bb.write("bb_frame0.pdb")
Fig. 11 Trajectory ﬁltering and writing
MD Analysis Libraries: A Synopsis
519

VMD
# Center of mass
$bb frame 0
measure center $bb weight mass
# W288, chi 1, first frame
measure dihed [$w288_chi1 get index]
# All frames
measure dihed [$w288_chi1 get index]
first 0 last 40
→
Bio3D
# Center of mass
com(tp_bb)
# Torsion, first frame
tmp <- tp$xyz[1, w288_chi1$xyz]
torsion.xyz(c(t(tmp)))
# All frames (reshape as 1D vector)
tmp <- tp$xyz[ , w288_chi1$xyz]
torsion.xyz(c(t(tmp)))
MDAnalysis
# Self-explanatory
bb.center_of_mass()
# Current frame
w288_chi1.dihedral.value()
# All frames (iterator)
[w288_chi1.dihedral.value()
for f in t.trajectory]
MDTraj
# Self-explanatory
mdt.compute_center_of_mass(bb_ref)
# First frame (to degrees)
mdt.compute_dihedrals(t[0],
[w288_chi1])*180.0/np.pi
# All frames
mdt.compute_dihedrals(t,
[w288_chi1])*180.0/np.pi
HTMD
# Center of geometry: add
"weights=bb.masses" if available in
topology
→
→
np.average(bb.coords, axis=0).T
# First frame
htmd.molecule.util.dihedralAngle(
t.coords[w288_chi1,:,0])
# All frames
htmd.molecule.util.dihedralAngle(
t.coords[w288_chi1,:,:])
Fig. 12 Geometry operations
520
Toni Giorgino

VMD
# Convenience functions from
# github.com/tonigi/vmd_extensions
source ˜/VMDextensions.tcl
# t: trajectory; r: reference;
# alg: alignment; meas: measurement
set meas_t [atomselect top protein]
set meas_r [atomselect top protein
frame 0]
set alg_t [atomselect top backbone]
set alg_r [atomselect top backbone
frame 0]
set rmsd_traj [rmsdOf $meas_t $meas_r
$alg_t
$alg_r]
Bio3D
meas.r <- trim(tp$xyz,1)
meas.t <- tp$xyz
alg.set <- bb$xyz
fitted <- fit.xyz(fixed = meas.r,
mobile = meas.t,
fixed.inds = alg.set,
mobile.inds = alg.set)
meas.set <- atom.select(tp,
"protein")$xyz
rmsd.traj <- rmsd(a = meas.r,
b = fitted,
a.inds = meas.set,
b.inds = meas.set)
MDAnalysis
from MDAnalysis.analysis.rms import RMSD
R = RMSD(atomgroup=t,
reference=t,
select="backbone",
# align set
groupselections=["protein"])
R.run()
# Measures found in column 4 and on
rmsd_traj = R.rmsd[:,3]
MDTraj
fitted = t[:]
# Copy
# Align
alg_set = t.topology.select("backbone")
fitted.superpose(reference=t,
frame=0,
atom_indices=alg_set)
meas_set = t.topology.select("protein")
meas_r = t.atom_slice(meas_set)
meas_t = fitted.atom_slice(meas_set)
d = meas_t.xyz-meas_r.xyz[0]
rmsd_traj = 10 * np.sqrt( np.mean(
np.sum(d**2,axis=2),axis=1))
HTMD
meas_r = t.copy()
meas_r.dropFrames(keep=0)
meas_t = t.copy()
meas_t.align("backbone",meas_r)
meas_set = meas_t.atomselect("protein")
rmsd_traj = htmd.molecule.util.molRMSD(
meas_t,meas_r,meas_set,meas_set)
Fig. 13 RMSD-based alignments
MD Analysis Libraries: A Synopsis
521

7
Conclusion
A wealth of libraries has been developed to ease structural biology-
oriented manipulation of MD trajectories with general-purpose
programming languages. This chapter tried to provide MD
users—and beginning students in particular—with a “Rosetta
stone” showing languages and constructs side by side. It is also
hoped that this effort promotes the integration of methods and
data interchange between MD communities.
8
Notes
1. The number of libraries dealing with aspects of MD analysis is
extensive. Table 4 provides a partial list of packages further to
the ones examined in this chapter. The selection made in this
review is therefore to a large degree arbitrary, and the balance
may change as technologies evolve. I apologize for the neces-
sary omissions.
2. Some tension exists between tackling analysis tasks in a fully
general purpose environment, versus using simpliﬁed “shells”
optimized for speciﬁc MD-related analysis operations. The
advantage of the former approach is its generality, as the
Table 4
A selection of MD-oriented analysis libraries and tool kits
Name
Language
Pub. date
Reference
MGLTools/PMV
Python
1999
[29]
PyMOL
Python
ca. 2000
[30]
BALL
C++
2000
[31]
MMTK
Python
2000
[32]
UCSF Chimera
Python
2003
[33]
Biskit
Python
2007
[34]
LOOS
C++
2009
[35]
BioPython
Python
2009
[36]
OpenStructure
C++, Python
2010
[37]
ProDy
Python
2011
[38]
JGromacs
Java
2012
[39]
Victor
C++
2015
[40]
Pteros
C++, Python
2015
[41]
522
Toni Giorgino

algorithm may use the same spectrum of operations allowed to
native code; however, general-purpose compiled languages
(usually Fortran, C and C++) are hard to master, arguably
error-prone, and make for verbose source codes. Structural
and trajectory manipulation libraries make MD-related opera-
tions somewhat simpler and more robust, but programming
challenges remain. Conversely, interactive MD-speciﬁc applica-
tions (either graphical or command-line) restrict the analysis
tasks
to
the
domain-speciﬁc
ones
which
have
been
pre-programmed. The dilemma is to a large extent solved by
high-level interpreted scripting languages such as the ones
examined in this chapter, which provide access to a wide variety
of libraries, terse syntaxes, and fast prototype-execute cycles.
Unsurprisingly, interpreters for scripting languages are now
embedded in most molecular analysis environments.
3. Python variables can indeed be strongly typed when the inter-
preter is used in combination with packages such as Cython
[25] or Numba [26]. Both packages transparently compile
Python code, annotated with static types, into optimized
native code.
4. The detailed understanding of variable visibility and namespace
partitioning rules is of particular relevance for development
projects more complex than one-off scripts. Although outside
of the scope of this chapter, mastering them is highly desirable
because of the increase in productivity and code quality it
affords.
5. Some resources providing realistic worked-out examples:
VMD – VMD’s Tutorials, available at www.ks.uiuc.edu/
Training/Tutorials.
Bio3D – Executable demos (pdb, md and pca) and tutorials
(called vignettes in the context of R), installed with the
package and also available on thegrantlab.org/bio3d.
MDAnalysis – The tutorial section available at mdanalysis.
org.
MDTraj – The examples section available at mdtraj.org in
the form of IPython notebooks.
HTMD – The Introduction to HTMD section of the User
Guide, at htmd.org.
6. Each package’s documentation speciﬁes in which Conda chan-
nel it is found. Many contributed packages, including MDTraj
and MDAnalysis, are found in the conda-forge channel, which
provides an automated building and distribution pipeline. The
typical
command
line
is
“conda
install
-c
<channel>
<packagename>[=version].”
MD Analysis Libraries: A Synopsis
523

7. Figure 14 provides scripts which download the data ﬁles used
in this tutorial and set the corresponding ﬁle name variables.
The ﬁles are simulation trajectories of the acid-sensing ion
channel 1 trimer (PDB: 2QTS [23]), embedded in a POPC
membrane located by the OPS algorithm [27] and simulated
for 40 ns with the CHARMM36 forceﬁeld [28]. They are
available from the PlayMolecule repository of pre-equilibrated
OPM membrane proteins [21].
8. MDAnalysis’ out of core design enables the analysis of trajec-
tories much larger than the memory physically available; how-
ever, care must be taken because iterating over frames in a
Universe changes the objects derived from it. This is evident,
e.g., in Fig. 11 (MDAnalysis panel), where access to trajectory
frame—0 in the example—also updates the bb object about to
be written. (The same occurs in Fig. 12 for the w288 chi1
object.) This is perhaps less surprising recalling that in general
Python objects are references, not values.
VMD/TCL
set code 2qts
set url "http://www.playmolecule.org/static/apps/OPM/data/$code/equil_charmm/"
set pdb structure.filtered.pdb
set xtc traj.filtered.xtc
vmd_mol_urlload $url/$pdb $pdb
vmd_mol_urlload $url/$xtc $xtc
R
code <- "2qts"
url <- sprintf("http://www.playmolecule.org/static/apps/OPM/data/%s/equil_charmm/", code)
pdb <- "structure.filtered.pdb"
xtc <- "traj.filtered.xtc"
dcd <- "traj.filtered.dcd"
download.file(file.path(url, pdb), pdb)
download.file(file.path(url, xtc), xtc)
## Convert to DCD format for Bio3D
system(sprintf("catdcd -o %s -xtc %s", dcd, xtc))
Python
code = "2qts"
url = f"http://www.playmolecule.org/static/apps/OPM/data/{code}/equil_charmm/"
pdb = "structure.filtered.pdb"
xtc = "traj.filtered.xtc"
import numpy as np
from urllib.request import urlretrieve
urlretrieve(url+pdb, pdb)
urlretrieve(url+xtc, xtc)
Fig. 14 Initialization code
524
Toni Giorgino

9. The term “RMSD calculation” may be ambiguous; in particu-
lar, it may indicate the result of the calculation either with or
without applying the optimal rotation operator. This chapter,
for the sake of clarity and generality, presents two-step proce-
dures in which the alignment and (unaligned) RMSD calcula-
tion steps are explicitly separated. In some software packages,
“RMSD” functions perform the alignment implicitly.
10. The rmsdOf function is a shorthand operator part of the VMD
Extensions Functions library, available at tonigi.github.io/
vmd_extensions.
Acknowledgments
I gratefully acknowledge the constructive comments received from
Prof. B. Grant, Prof. O. Beckstein, M. Linke, and J. Barnoud. I also
acknowledge Acellera Ltd. and the Dipartimento di Medicina
e Chirurgia of the Universita` degli Studi dell’Insubria for funding,
as well as CINECA awards MiXT and Insk2 under the ISCRA
initiative for the availability of high performance computing
resources and support.
References
1. Pronk
S,
Pa´ll
S,
Schulz
R,
Larsson
P,
Bjelkmar P, Apostolov R, Shirts MR, Smith
JC, Kasson PM, Spoel Dvd, Hess B, Lindahl
E (2013) GROMACS 4.5: a high-throughput
and highly parallel open source molecular sim-
ulation
toolkit.
Bioinformatics
29
(7):845–854. https://doi.org/10.1093/bioin
formatics/btt055
2. Roe DR, Cheatham TE (2013) PTRAJ and
CPPTRAJ: software for processing and analysis
of molecular dynamics trajectory data. J Chem
Theory Comput 9(7):3084–3095. https://
doi.org/10.1021/ct400341p
3. Tribello
GA,
Bonomi
M,
Branduardi
D,
Camilloni C, Bussi G (2014) Plumed 2: new
feathers for an old bird. Comput Phys Com-
mun
185(2):604–613.
https://doi.org/10.
1016/j.cpc.2013.09.018
4. Giorgino T (2018) How to differentiate col-
lective
variables
in
free
energy
codes:
computer-algebra code generation and auto-
matic differentiation. Comput Phys Commun
228:258–263.
https://doi.org/10.1016/j.
cpc.2018.02.017.2-s2.0-85043302064
5. Giorgino T (2014) PLUMED-GUI: an envi-
ronment for the interactive development of
molecular dynamics analysis and biasing scripts.
Comput Phys Commun 185(3):1109–1114.
https://doi.org/10.1016/j.cpc.2013.11.019
6. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph
14(1):33–38.
https://doi.org/10.
1016/0263-7855(96)00018-5
7. R Development Core Team (2008) R: a lan-
guage and environment for statistical comput-
ing. R Foundation for Statistical Computing,
Vienna. isbn:3-900051-07-0
8. Huber W, Carey VJ, Gentleman R, Anders S,
Carlson M, Carvalho BS, Bravo HC, Davis S,
Gatto L, Girke T, Gottardo R, Hahne F, Han-
sen KD, Irizarry RA, Lawrence M, Love MI,
MacDonald
J,
Obenchain
V,
Oles´
AK,
Page`s H, Reyes A, Shannon P, Smyth GK,
Tenenbaum
D,
Waldron
L,
Morgan
M
(2015) Orchestrating high-throughput geno-
mic analysis with bioconductor. Nat Methods
12(2):115–121.
https://doi.org/10.1038/
nmeth.3252
9. Grant
BJ,
Rodrigues
APC,
ElSawy
KM,
McCammon JA, Caves LSD (2006) Bio3d: an
R package for the comparative analysis of pro-
tein
structures.
Bioinformatics
22
(21):2695–2696.
https://doi.org/10.1093/
bioinformatics/btl461
MD Analysis Libraries: A Synopsis
525

10. Scherer MK, Trendelkamp-Schroer B, Paul F,
Pe´rez-Herna´ndez G, Hoffmann M, Plattner N,
Wehmeyer
C,
Prinz
JH,
Noe´
F
(2015)
PyEMMA 2: a software package for estimation,
validation, and analysis of Markov models. J
Chem Theory Comput 11(11):5525–5542.
https://doi.org/10.1021/acs.jctc.5b00743
11. Eastman P, Swails J, Chodera JD, McGibbon
RT, Zhao Y, Beauchamp KA, Wang LP, Sim-
monett AC, Harrigan MP, Stern CD, Wiewiora
RP, Brooks BR, Pande VS (2017) OpenMM 7:
rapid development of high performance algo-
rithms for molecular dynamics. PLoS Comput
Biol
13(7):e1005,659.
https://doi.org/10.
1371/journal.pcbi.1005659
12. Harrigan MP, Sultan MM, Herna´ndez CX,
Husic BE, Eastman P, Schwantes CR, Beau-
champ KA, McGibbon RT, Pande VS (2017)
MSMBuilder: statistical models for biomolecu-
lar
dynamics.
Biophys
J
112(1):10–15.
https://doi.org/10.1016/j.bpj.2016.10.042
13. Giorgino T (2014) Computing 1-D atomic
densities in macromolecular simulations: the
density proﬁle tool for VMD. Comput Phys
Commun 185(1):317–322. https://doi.org/
10.1016/j.cpc.2013.08.022
14. Giorgino T, Laio A, Rodriguez A (2017)
METAGUI 3: a graphical user interface for
choosing the collective variables in molecular
dynamics simulations. Comput Phys Commun
217:204–209.
https://doi.org/10.1016/j.
cpc.2017.04.009
15. Guixa`-Gonza´lez
R,
Rodriguez-Espigares
I,
Ramı´rez-Anguita
JM,
Carrio´-Gaspar
P,
Martinez-Seara
H,
Giorgino
T,
Selent
J
(2014) MEMBPLUGIN: studying membrane
complexity
in
VMD.
Bioinformatics
30
(10):1478–1480.
https://doi.org/10.1093/
bioinformatics/btu037
16. Gowers RJ, Linke M, Barnoud J, Reddy TJE,
Melo MN, Seyler SL, Doman´ski J, Dotson DL,
Buchoux S, Kenney IM, Beckstein O (2016)
MDAnalysis: a python package for the rapid
analysis of molecular dynamics simulations.
Proceedings of the 15th Python in science con-
ference (SCIPY 2016). pp. 98–105
17. Michaud-Agrawal N, Denning EJ, Woolf TB,
Beckstein O (2011) MDAnalysis: a toolkit for
the analysis of molecular dynamics simulations.
J Comput Chem 32(10):2319–2327. https://
doi.org/10.1002/jcc.21787
18. McGibbon RT, Beauchamp KA, Harrigan MP,
Klein C, Swails JM, Herna´ndez CX, Schwantes
CR, Wang LP, Lane TJ, Pande VS (2015)
MDTraj: a modern open library for the analysis
of molecular dynamics trajectories. Biophys J
109(8):1528–1532.
https://doi.org/10.
1016/j.bpj.2015.08.015
19. Doerr S, Harvey MJ, Noe´ F, De Fabritiis G
(2016) HTMD: high-throughput molecular
dynamics for molecular discovery. J Chem The-
ory Comput 12(4):1845–1852. https://doi.
org/10.1021/acs.jctc.6b00049
20. Martinez-Rosell G, Giorgino T, De Fabritiis G
(2017) PlayMolecule ProteinPrepare: a web
application for protein preparation for molecu-
lar dynamics simulations. J Chem Inf Model.
https://doi.org/10.1021/acs.jcim.7b00190
21. Doerr S, Giorgino T, Martinez-Rosell G,
Damas JM, De Fabritiis G (2017) High-
throughput automated preparation and simu-
lation of membrane proteins with HTMD. J
Chem Theory Comput. https://doi.org/10.
1021/acs.jctc.7b00480
22. Harvey MJ, Giupponi G, De Fabritiis G (2009)
ACEMD: accelerating biomolecular dynamics
in the microsecond time scale. J Chem Theory
Comput 5(6):1632–1639. https://doi.org/
10.1021/ct9000685
23. Jasti J, Furukawa H, Gonzales EB, Gouaux E
(2007) Structure of acid-sensing ion channel
1 at 1.9 A˚ resolution and low pH. Nature 449
(7160):316–323.
https://doi.org/10.1038/
nature06163
24. Sherwood TW, Frey EN, Askwith CC (2012)
Structure and activity of the acid-sensing ion
channels. Am J Physiol Cell Physiol 303(7):
C699–C710.
https://doi.org/10.1152/
ajpcell.00188.2012
25. Behnel S, Bradshaw R, Citro C, Dalcin L,
Seljebotn D, Smith K (2011) Cython: the
best of both worlds. Comput Sci Eng 13
(2):31–39. https://doi.org/10.1109/MCSE.
2010.118
26. Lam SK, Pitrou A, Seibert S (2015) Numba: a
LLVM-based Python JIT compiler. In: Pro-
ceedings of the second workshop on the
LLVM
compiler
infrastructure
in
HPC,
LLVM
‘15.
ACM,
New
York,
NY,
pp
7:1–7:6. https://doi.org/10.1145/2833157.
2833162
27. Lomize MA, Pogozheva ID, Joo H, Mosberg
HI, Lomize AL (2012) OPM database and
PPM web server: resources for positioning of
proteins in membranes. Nucleic Acids Res 40
(Database
issue):D370–D376.
https://doi.
org/10.1093/nar/gkr703
28. Best RB, Zhu X, Shim J, Lopes PEM, Mittal J,
Feig M, MacKerell AD (2012) Optimization of
the additive CHARMM all-atom protein force
ﬁeld targeting improved sampling of the back-
bone ϕ, ψ and side-chain χ1 and χ2 dihedral
angles.
J
Chem
Theory
Comput
8
(9):3257–3273.
https://doi.org/10.1021/
ct300400x
526
Toni Giorgino

29. Sanner MF (1999) Python: a programming
language for software integration and develop-
ment. J Mol Graph Model 17(1):57–61.
WOS:000084162500006
30. Schro¨dinger, LLC (2015) The PyMOL molec-
ular graphics system, version 1.8. Schro¨dinger,
LLC, New York, NY
31. Hildebrandt
A,
Dehof
AK,
Rurainski
A,
Bertsch A, Schumann
M, Toussaint NC,
Moll A, Sto¨ckel D, Nickels S, Mueller SC,
Lenhof HP, Kohlbacher O (2010) BALL –
biochemical algorithms library 1.3. BMC Bio-
informatics
11(531).
https://doi.org/10.
1186/1471-2105-11-531
32. Hinsen K (2000) The molecular modeling
toolkit: a new approach to molecular simula-
tions. J Comput Chem 21(2):79–85
33. Pettersen
EF,
Goddard TD,
Huang
CC,
Couch GS, Greenblatt DM, Meng EC, Ferrin
TE (2004) UCSF Chimera—a visualization
system for exploratory research and analysis. J
Comput Chem 25(13):1605–1612. https://
doi.org/10.1002/jcc.20084
34. Gru¨nberg R, Nilges M, Leckner J (2007) Bis-
kit—a software platform for structural bioin-
formatics.
Bioinformatics
23(6):769–770.
https://doi.org/10.1093/bioinformatics/
btl655
35. Romo TD, Grossﬁeld A (2009) LOOS: an
extensible platform for the structural analysis
of simulations. In: 2009 Annual international
conference of the IEEE Engineering in Medi-
cine and Biology Society, pp 2332–2335.
https://doi.org/10.1109/IEMBS.2009.
5335065
36. Cock PJA, Antao T, Chang JT, Chapman BA,
Cox CJ, Dalke A, Friedberg I, Hamelryck T,
Kauff F, Wilczynski B, Hoon DMJ (2009) Bio-
python:
freely
available
Python
tools
for
computational molecular biology and bioinfor-
matics.
Bioinformatics
25(11):1422–1423.
https://doi.org/10.1093/bioinformatics/
btp163
37. Biasini M, Mariani V, Haas J, Scheuber S,
Schenk AD, Schwede T, Philippsen A (2010)
OpenStructure: a ﬂexible software framework
for computational structural biology. Bioinfor-
matics 26(20):2626–2628. https://doi.org/
10.1093/bioinformatics/btq481
38. Bakan A, Meireles LM, Bahar I (2011) ProDy:
protein dynamics inferred from theory and
experiments.
Bioinformatics
27
(11):1575–1577.
https://doi.org/10.1093/
bioinformatics/btr168
39. Mu¨nz M, Biggin PC (2012) JGromacs: a Java
package for analyzing protein simulations. J
Chem Inf Model 52(1):255–259. https://doi.
org/10.1021/ci200289s
40. Hirsh L, Piovesan D, Giollo M, Ferrari C,
Tosatto SCE (2015) The victor C++ library
for
protein
representation
and
advanced
manipulation.
Bioinformatics
31
(7):1138–1140.
https://doi.org/10.1093/
bioinformatics/btu773
41. Yesylevskyy SO (2015) Pteros 2.0: evolution of
the fast parallel molecular analysis library for C
++
and
Python.
J
Comput
Chem
36
(19):1480–1488.
https://doi.org/10.1002/
jcc.23943
MD Analysis Libraries: A Synopsis
527

Chapter 21
Analyzing and Biasing Simulations with PLUMED
Giovanni Bussi and Gareth A. Tribello
Abstract
This chapter discusses how the PLUMED plugin for molecular dynamics can be used to analyze and bias
molecular dynamics trajectories. The chapter begins by introducing the notion of a collective variable and
by then explaining how the free energy can be computed as a function of one or more collective variables. A
number of practical issues mostly around periodic boundary conditions that arise when these types of
calculations are performed using PLUMED are then discussed. Later parts of the chapter discuss how
PLUMED can be used to perform enhanced sampling simulations that introduce simulation biases or
multiple replicas of the system and Monte Carlo exchanges between these replicas. This section is then
followed by a discussion on how free-energy surfaces and associated error bars can be extracted from such
simulations by using weighted histogram and block averaging techniques.
Key words PLUMED, Enhanced sampling, Collective variables, Free energy, Replica exchange,
WHAM
1
Introduction
The chapters in sections I–IV will have given you some sense of the
broad range of methods and techniques that have been used to
simulate biomolecular processes. The aim of this chapter is not to
introduce more techniques but rather to focus on how these tech-
niques can be employed in practice. We will do so by explaining
how a particular piece of software, PLUMED [1, 2], can be used to
run and analyze many of the types of simulation that are discussed
in Section II. Note 1 discusses the various different versions of
PLUMED. The most important thing to know at the outset,
however, is that PLUMED is not a molecular dynamics (MD) or
Monte Carlo code. It is instead designed to complement MD codes
such as GROMACS [3], LAMMPS [4], DL_POLY [5], CP2K [6],
AMBER [7], and OpenMM [8]. PLUMED does this in two ways:
1. It can be used to post-process the molecular dynamics trajec-
tories that are generated by these codes.
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7_21, © Springer Science+Business Media, LLC, part of Springer Nature 2019
529

2. It can serve as a plugin to these MD codes and thus allow the
user to add the additional biasing forces that are required for
the enhanced sampling methods, such as umbrella sampling or
metadynamics, that are described in Section II.
The manner in which PLUMED is plugged into an MD code is
illustrated in Fig. 1. As you can see PLUMED is called during
initialization and its input ﬁle is read in at that time. It is then called
during each run-through of the main loop of the MD code just
after the forces that describe the interactions between the atoms are
calculated. Calling PLUMED at these points allows the plugin to
do any analysis that is required and also allows any forces due to bias
potentials that are calculated by PLUMED to be returned from
PLUMED to the MD code so that they can be incorporated when
the equations of motion are integrated. PLUMED is not the only
piece of software that interacts with other MD codes in this manner.
Two other notable examples are the COLVARS package [9], which
is also reviewed in this book, and the recently published program
SSAGES [10].
When the PLUMED package is used to post-process trajec-
tories a program that is part of PLUMED and that is called driver
is employed. When PLUMED driver is used the trajectory is not
Fig. 1 Schematic representation of the interface between PLUMED and an MD
engine. The green arrow indicates that the function called should create the
PLUMED object and the red arrow indicates that the function called should delete
the PLUMED object
530
Giovanni Bussi and Gareth A. Tribello

generated by integrating the equations of motion. The trajectory
is
instead
read
from
disk
so
the
forces
calculated
within
PLUMED thus play no role in the systems’ dynamics. PLUMED
driver is, nevertheless, useful as the PLUMED code contains
numerous analysis tools that can also be used to post-process
trajectories.
PLUMED is written using C++ and the object-oriented para-
digm is heavily used in the design of the code. The consequence of
this is that the code contains a set of core modules that look after
the communication with the MD codes and various other mission
critical features. This code is maintained by a small cadre of core
developers. Additional functionalities can be built on this core and
contributed by any user in the community. In fact, developers who
wish to contribute to the project in this way often only need to
contribute one single ﬁle that contains class and method deﬁni-
tions, the code itself and the sections of the manual that describe
the new functionality as well as ﬁles for a regression test that can be
used to ensure that the new functionality continues to work if
changes are made elsewhere. The fact that it is relatively easy to
extend PLUMED ensures that the code, the associated website,
and the various user meetings provide a forum that developers can
use to share new techniques and methods with the scientiﬁc com-
munity. In fact, in PLUMED v2.4, a modular framework was
introduced that allows developers to contribute groups of func-
tionalities that are logically connected. So far Omar Valsson (VES
module, for variational enhanced sampling), Glen Hocky and
Andrew White (EDS module, for experiment-directed simula-
tions), and Haochuan Chen and Haohao Fu (DRR module, for
extended-system adaptive biasing force), who are all non-core
developers, have used this model to contribute modules to the
code base. We expect, however, that the number of contributed
modules will increase in the future.
The size and scope of the PLUMED code ensures that we
cannot describe everything that it can do in this single chapter.
For those who are interested we would recommend reading the
original article [2], the code’s online manual, the many tutorials
included in the manual, and some of the considerable number of
papers that describe simulations done or analyzed with PLUMED.
What we will do in the following is quickly summarize the theory
behind some of the methods that are implemented in PLUMED.
We will also provide relevant examples of PLUMED input ﬁles that
can be used for these types of calculations. Our focus in these
sections is on describing how free energies are estimated from
these types of calculations, how results from multiple replicas can
be combined, and how suitable error bars on these estimates are
determined.
Analyzing and Biasing Simulations with PLUMED
531

2
Collective Variables
Complex biochemical reactions or conformational changes are
often interpreted in terms of free-energy surfaces that are com-
puted as a function of a small number of collective variables
(CVs). These free-energy surfaces, which are often referred to as
potentials of mean force, provide a coarse-grained representation of
the energy landscape for the system, which can in turn provide
useful insights into the behavior of these biochemical systems. To
see why consider the following examples:
l
We know that nucleosides have multiple conformations and that
inter-conversion between these conformers involves rotation
around the glycosidic bond. A free-energy surface for such a
system as a function of the torsional angle χ around this bond is
thus useful as it provides us with information on the relative free
energies of the conformations and an indication of the height of
the barrier for inter-conversion (see, e.g., ref. 11).
l
We know that the secondary and tertiary structures of many
proteins determine their function and that it is important to
understand the mechanism by which proteins fold. If we run
molecular dynamics simulations we can understand something
about this folding process by extracting the free-energy surface
along a coordinate that counts the number of native contacts
that are present (see, e.g., [12, 13]).
l
We know that cells are constantly exchanging water and ions
across their membrane. To extract information on the mechan-
isms for these processes we can run molecular dynamics simula-
tions and extract a free-energy surface that describes how the
free energy of the ion changes as the ion moves through an ion
channel (see, e.g., [14]).
l
We know that the behavior of biomolecules changes when their
protonation state changes. To extract information on the likely
protonation state of a biomolecule we might, therefore, calcu-
late how the free energy of the molecule changes as the distance
between the hydrogen atoms and the various protonation sites
on the molecule changes (see, e.g., [15]).
l
We know that the solute molecules in a solution must all aggre-
gate in one place in order for a crystal to form. To investigate the
ease with which a crystal forms from a particular solution and the
earliest stages of this nucleation process we might, therefore,
calculate the free energy as a function of the number of mole-
cules that are in the solid phase (see, e.g., [16, 17]).
In all these examples the Hamiltonian depends on numerous
degrees of freedom, but we are only interested in the behavior of a
small number of these degrees of freedom (e.g., a torsional angle or
532
Giovanni Bussi and Gareth A. Tribello

a distance between two atoms). A CV, s, is thus simply an arbitrary
function of the atomic coordinates, q. As we will see in what
follows, in many cases the function s is very simple and thus easy
to calculate from q. In other cases, however, the function is consid-
erably more complicated so for these cases the scripting language of
the PLUMED input ﬁle is invaluable.
2.1
Ensemble
Averages
Section IV discussed a variety of different ways in which MD
trajectories can be analyzed. The simplest way to analyze the values
a CV takes during a trajectory is to compute an ensemble average.
We are able to compute such averages from MD simulations
because, if we are running at temperature T on a system containing
N atoms that interact through a Hamiltonian, H(q, p), the proba-
bility, P(q, p), that a microstate in which the atoms have positions
q and momenta p will be sampled at a particular instant in time is
given by:
Pðq, pÞ ¼
exp  Hðq, pÞ
kBT


R
dq0dp0exp  Hðq0, p0Þ
kBT


ð1Þ
where kB is Boltzmann’s constant and where the 6N-dimensional
integral in the denominator runs over all the possible values of
position and momentum that each of the atoms in the system
might have. Consequently, an observable A(q) will have an ensem-
ble average that is equal to:
hAi ¼
Z
dqdpAðqÞPðq, pÞ
ð2Þ
By the ergodic theorem, however, we know that if we add together
the value A(q) took in each of the frames in our molecular dynamics
trajectory and if we divide this sum by the number of frames in our
trajectory we will obtain an estimate for hAi.
2.2
Free-Energy
Landscapes
A slightly more advanced way to analyze CVs is to compute the
probability density along the CV. This function is deﬁned as:
PðsÞ /
Z
dqdpPðq, pÞδðsðq, pÞ  sÞ
ð3Þ
The free-energy surface, F(s), is then nothing more than the nega-
tive logarithm of this probability density function expressed in units
of energy:
FðsÞ ¼ kBT ln
Z
dqdpPðq, pÞδðsðq, pÞ  sÞ
"
#
þ C
ð4Þ
where C is an arbitrary constant.
Analyzing and Biasing Simulations with PLUMED
533

Recognizing this connection between the value of the thermo-
dynamic potential and the probability of having a particular value
for a collective variable is fundamental in terms of understanding
what a free-energy landscape means. As a case in point consider the
free-energy surface shown in Fig. 2. This ﬁgure shows how the free
energy changes as the distance between two particles is increased.
One might be tempted, based on the shape of the curve, to assume
that the two particles repel each other. In actual fact, however, there
is no interaction between the particles. The free energy decreases
because all possible distance vectors are equally likely. In three
dimensions the probability of observing a particular distance, r,
is thus proportional to r2. The free energy for a pair of
non-interacting particles as a function of the distance between
them is thus FðrÞ ¼ 2kBT ln r þ C. Hence, when free-energy
landscapes are used to provide information on the strength of the
interaction between two particles, for example, in a binding afﬁnity
study these two particles would be a small drug molecule and
a protein, the surface obtained is usually corrected by adding
2kBT ln r
so
that
the
free-energy
surface
for
a
pair
of
non-interacting particles appears ﬂat.
Let us now suppose that we have extracted a free-energy surface
that looks something like the one shown in Fig. 3. This free-energy
surface contains two metastable basins, which we will, for the time
being, assume correspond to the reactant and product states for a
chemical reaction that our simulated system can undergo. If we
want to calculate the free-energy change associated with this reac-
tion we would use the expression below:
8
6
4
2
0
0.0
0.2
0.4
0.6
distance / nm
0.8
1.0
free energy / energy units
Fig. 2 Figure showing the free-energy surface as a function of the distance
between two atoms that do not interact. As you can see the free energy
decreases as the two atoms move apart but this is only because the phase
space volume that is accessible to two atoms that are exactly a distance r apart
is proportional to r2
534
Giovanni Bussi and Gareth A. Tribello

F products  F reactants ¼ kBT log
R
productse FðsÞ
kBT ds
R
reactantse FðsÞ
kBT ds
2
64
3
75
ð5Þ
Here the integrals in the numerator and the denominator of the
quotient on the right-hand side run over the regions highlighted
in Fig. 3. Notice, furthermore, that the free-energy difference
between the reactant and product states is calculated in this way
because the value of the CV will ﬂuctuate when it is in either state.
Calculating the reaction free energy using the formula above incor-
porates the effect of these ﬂuctuations whereas simply calculating
the difference between the values of the free energy at the bottom
of two minima does not.
A further interesting thing that is worth noting about free-
energy surfaces is that, if one has the free energy, F(s), as a function
of some CV, s, and if one wishes to determine the free energy as a
function of some second CV, ζ, as long as ζ is a one-to-one function
of s with an inverse function that is differentiable one can write an
analytic expression for F(ζ) in terms of F(s). The reason that this is
possible is that if ζ(s) is one-to-one then we know that:
PðζÞdζ ¼ PðsÞds ¼ PðsÞ ds
dζ

dζ
ð6Þ
6
4
2
0
–2
–2
0
2
4
CV value / arbitrary units
reactants
products
Free energy / energy units
–4
–4
Fig. 3 Figure showing a typical one-dimensional free-energy surface that we
might extract from an MD simulation. It is clear from this diagram that there are
two metastable basins in this landscape and that the system must cross a
substantial barrier in order to get from one to the other. The two shaded regions
in this ﬁgure indicate the two sets of limits that we would integrate over when
evaluating the free-energy difference between these two metastable basins
using Eq. 5. To be clear, however, the precise choice for these limits will not
affect the calculated free energy difference signiﬁcantly as long as the two free-
energy minima are reasonably deep
Analyzing and Biasing Simulations with PLUMED
535

Once we recall the connection between free energy and probability
we thus arrive at:
FðζÞ ¼ FðsÞ  kBT ln ds
dζ


ð7Þ
F(ζ) may look rather different to F(s) but these two free-energy
surfaces will still convey the same information about depths of the
basins and the heights of the barriers. In general, however, one
should be particularly careful when discussing the barriers found in
free-energy landscapes, as the height of the barrier will depend on
the particular combination of CVs that are used to display the free-
energy landscape. As illustrated in Fig. 4, if the critical degree of
freedom that distinguishes between two metastable states is in a
direction that is orthogonal to the CVs, then these two states will
both contribute their probability density to a single basin in the
ﬁnal free-energy landscape that is extracted. If you want to extract
5
0
–5
4
2
0
–2
–4
–3
–2
–1
0
1
2
3
–5
–3
0
0
3
6
9
12
15
18
Free energy / energy units
CV 1 / arbitrary units
CV 2 / arbitrary units
Fig. 4 The central panel of this ﬁgure shows a two-dimensional free-energy surface with two metastable
states that is a function of two CVs called CV1 and CV2. The panels above and to the right of this ﬁgure show
the free-energy surface as a function of CV1 and CV2, respectively. It is clear from these two ﬁgures that while
CV2 is able to distinguish the two metastable basins CV1 is not
536
Giovanni Bussi and Gareth A. Tribello

information on barriers, you should thus probably also extract the
average passage times between states as this better characterizes the
behavior of the chemical system. Strictly speaking, a free-energy
landscape alone can only tell you about the relative stabilities of the
various metastable states that can be distinguished by the CVs that
were used in its construction. Relating the free-energy barriers to
the rates with which the system will pass from state to state is far
from trivial and the result might depend systematically on the
capability of the CVs to correctly describe the transition [18].
2.3
Analyzing
Simulations
with PLUMED
In this section we will discuss how to compute various CVs using
PLUMED. It is important to emphasize at the outset that the
PLUMED input ﬁles we provide can be used when running a
simulation using some other MD code combined with PLUMED
or when analyzing a simulation trajectory using PLUMED
driver. In the ﬁrst case the command line input will depend on
which precise MD code one is using. For instance, simulations done
with GROMACS are typically launched using a command such as:
> gmx mdrun -plumed plumed.dat
where plumed.dat is the name of the PLUMED input ﬁle. In the
second case, however, as only PLUMED is being used, the com-
mand is nearly always the same and will be something akin to:
> plumed driver --plumed plumed.dat --igro traj.gro
where traj.gro is a trajectory ﬁle in GROMACS format and
plumed.dat is once again a PLUMED input ﬁle.
For the ﬁnal end user a PLUMED input ﬁle looks like it is
written in a rudimentary and easy-to-use scripting language. Each
line in the input ﬁle tells the code to do something, which may be as
simple as calculating a position of a center of mass or as complex as
calculating and accumulating a metadynamics bias. As these com-
mands can be used in a wide range of different contexts and orders
the user has the ﬂexibility to do the full range of analyses described
in the previous sections. Furthermore, if they choose to incorporate
some new functionality, they can quickly start to use it in tandem
with all of the other methods developed by members of the
PLUMED community.
2.4
Distances,
Angles, and Torsions
Chemical reactions are one class of phenomena that we can investi-
gate using MD simulations. In many chemical reactions two atoms
or groups of atoms approach each other so that a chemical bond can
form between them. The ideal CV to use to describe this phenom-
enon is thus the distance between the relevant atoms. We can
calculate and print the distance between a pair of atoms using the
PLUMED input ﬁle below:
Analyzing and Biasing Simulations with PLUMED
537

d1: DISTANCE ATOMS=1,2
PRINT ARG=d1 FILE=colvar STRIDE=10
This input instructs PLUMED to calculate the distance
between the positions of the ﬁrst and second atoms in the MD
code’s input ﬁle and to print this quantity to a ﬁle called colvar
every 10 steps. We can take the output from this calculation and
plot a graph showing the value of the distance as a function of time.
The resulting curve would look something like the red curve in
Fig. 5.
We can also use PLUMED to calculate the average value of the
distance between two atoms. The following input calculates the
distance every 10 steps and then calculates a sample mean over the
whole trajectory.
d1: DISTANCE ATOMS=1,2
a1: AVERAGE ARG=d1
PRINT ARG=a1 FILE=colvar STRIDE=100
The output generated by this calculation is plotted in blue in
Fig. 5. There are multiple points in the output ﬁle as the above
input instructs PLUMED to calculate an ensemble average from
the ﬁrst 100 trajectory frames, the ﬁrst 200 trajectory frames, the
ﬁrst 300 trajectory frames, and so on. It is worth noting that one
can also use PLUMED to calculate the running averages from the
ﬁrst 100 frames, the second 100 frames, and so on—points that are
4
2
0
–2
–4
0
20000
40000
60000
80000
100000
Fig. 5 Figure showing some things PLUMED can do with the CVs it calculates. As
discussed in the main text to calculate the curves shown in this ﬁgure we
calculated the distance between atoms 1 and 2 on every 10th MD step. The red
points are thus the values of these distances. The blue points indicate the mean
value of this distance calculated for a range of differently sized samples. Lastly,
the green points are running averages from the ﬁrst 100 frames, the second
100 frames, and so on
538
Giovanni Bussi and Gareth A. Tribello

shown using green dots in Fig. 5—by using an input ﬁle like the one
below:
d1: DISTANCE ATOMS=1,2
a1: AVERAGE ARG=d1 CLEAR=100
PRINT ARG=a1 FILE=colvar STRIDE=100
To calculate and print an angle between two bonds using
PLUMED one might use an input ﬁle like the one below:
ang: ANGLE ATOMS=1,2,3
PRINT ARG=ang FILE=colvar STRIDE=5
As shown in Fig. 6a this input calculates the angle between the
vector connecting atom 2 to atom 1 and the vector connecting
atom 2 to atom 3. The assumption here is that there are chemical
bonds connecting atom 2 to atoms 1 and 3. This input is thus
measuring the angle between these bonds. As illustrated in Fig. 6b
we can, however, also use PLUMED to calculate the angle between
any pair of distance vectors. For example, the input ﬁle below
would calculate the angle between the vector that connects atom
2 to atom 1 and the vector that connects atom 3 to atom 4.
ang2: ANGLE ATOMS=1,2,3,4
PRINT ARG=ang2 FILE=colvar STRIDE=2
PLUMED can also be used to calculate and print the torsional
angles illustrated in Fig. 6c that involve sets of four atoms as shown
below:
tor: TORSION ATOMS=1,2,3,4
PRINT ARG=tor FILE=colvar STRIDE=1
Much like the command to calculate the angle where three
atoms are speciﬁed the assumption made when writing this input
ﬁle is that there are chemical bonds between atoms 1 and 2, atoms
Fig. 6 Schematic representations of the angles and torsions that PLUMED can compute. (a) Angle deﬁned
using three atoms; (b) angle deﬁned using four atoms; (c) torsion deﬁned using four atoms; (d) torsion deﬁned
using six atoms
Analyzing and Biasing Simulations with PLUMED
539

2 and 3, and atoms 3 and 4. In general, however, a torsional angle
measures the angle between two planes, which have at least one
vector in common as illustrated in Fig. 6d. As shown below, there is
thus an alternate, more general, way through which we can deﬁne a
torsional angle:
tor2: TORSION VECTOR1=1,2 AXIS=3,4 VECTOR2=5,6
PRINT ARG=tor2 FILE=colvar STRIDE=20
This input instructs PLUMED to calculate the angle between
the plane containing the vector connecting atoms 1 and 2 and the
vector connecting atoms 3 and 4 and the plane containing this
second vector and the vector connecting atoms 5 and 6. Notice
that there is one additional syntax for selecting the atoms that
should be used to calculate a torsion that is discussed in Note 2.
2.5
Positions
and RMSD
One of the processes that we stated we might want to study was the
diffusion of ions across cell membranes. If the membrane is parallel
to the xy plane, one might be tempted to conclude that that correct
CV to use in this case is the z component of the position of the ion.
Assuming that the ion is atom number 1001, this can be done with
the following input ﬁle:
pos: POSITION ATOM=1001
PRINT ARG=pos.z FILE=colvar STRIDE=10
The variable POSITION that is used here has multiple compo-
nents. As we want the z component speciﬁcally, we thus use pos.z
in the PRINT command. Using this CV is a bad idea as the potential
energy functions that we use within MD simulations are almost
always translationally invariant. As illustrated in Fig. 7 for our
membrane example a particular value for the z component of our
ion’s coordinate might be inside the membrane at one particular
time. During the simulation, however, the membrane can move
and as such this same value for the ion’s z coordinate might be
outside the membrane at some later time. It is thus usually much
better to use the z component of the distance between the coordi-
nates of the ion and the center of the membrane and to thus track
the z position of the ion relative to the z position of the membrane.
An example input that can be used to calculate and print this
quantity is given below:
c1: COM ATOMS=1-1000
dist: DISTANCE ATOMS=c1,1001 COMPONENTS
PRINT ARG=dist.z FILE=colvar STRIDE=10
Here we assumed that the ﬁrst 1000 atoms together form the
membrane.
540
Giovanni Bussi and Gareth A. Tribello

It is worth noting here how the COM command is used to keep
track of the position of the center of mass of the large number of
atoms that make up the membrane and how the position of this
center of mass is referred to in the DISTANCE command using the
label, c1, of the COM command. It is also important to understand
how PLUMED deals with periodic boundary conditions (see Sub-
heading 2.7) and to remember that, for the position of the center
to be computed correctly, the vertical span of the membrane must
be less than half of the box height. Finally, one should be aware that
using a large number of atoms when calculating a CV may well slow
down the calculation. It may thus be worth using only a subset of
the atoms in the membrane when calculating the position of the
center by, for instance, replacing the ﬁrst line of the input ﬁle above
with:
c1: COM ATOMS=1-1000:10
The extra :10 here tells PLUMED to only use every 10th atom in
the range speciﬁed. This is a crude solution, however, and it is
probably always better in practice to select speciﬁc atoms using
your understanding of the chemistry of the system.
It can be useful to consider the atomic positions directly when
considering problems such as protein folding. Let’s suppose that
you know the precise arrangement that the atoms have in the native
structure and that you want to monitor the progression of folding
during a trajectory. An obvious CV to measure would be the degree
of similarity between the instantaneous coordinates of the protein
and this special, folded conﬁguration. A method that is commonly
a)
b)
Fig. 7 Figure illustrating the vertical position of an ion with respect to a
membrane. The ion is shown in green, whereas the atoms of the membrane
are depicted as empty circles. The center of the membrane is represented using
a star. Panels (a) and (b) report two different structures. Notice that the vertical
coordinate of the ion is the same, but that its position relative to the membrane is
different. The correct way to describe the position of the ion with respect to the
membrane is thus to use the vertical component of the distance between the ion
and the center of the membrane
Analyzing and Biasing Simulations with PLUMED
541

used to calculate this degree of similarity involves computing the
root-mean-square deviation (RMSD) between the instantaneous
coordinates and the coordinates in the reference structure using:
s ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
N
X
N
i¼1
qi  qðrefÞ
i

2
v
u
u
t
ð8Þ
In this expression N is the number of atoms, qi is used to denote
the instantaneous coordinates of atom i, and qðrefÞ
i
is used to denote
the coordinates of atom i in the reference structure. It is important
to note that if you were to use the formula above you would have
the same problem as if you used the position of an atom as a
CV. Consequently, the RMSD formula above is usually computed
from a reference frame that is found by performing translation and
rotation operations on the original reference structure that mini-
mize the value of the RMSD [19]. An input ﬁle that can be used to
calculate and print this quantity using PLUMED is shown below:
rmsd: RMSD REFERENCE=ref.pdb TYPE=OPTIMAL
PRINT ARG=rmsd FILE=colvar STRIDE=5
This input computes the root-mean-square deviation between
the instantaneous positions of the atoms that are listed in the input
ref.pdb ﬁle and the positions of those atoms in the pdb ﬁle. In this
case any translation of the center of mass and rotation of the
reference frame is removed before calculating the displacements
that enter Eq. 8. As discussed in Note 3, however, PLUMED
provides a range of options that allow you to perform these
RMSD calculations in various different ways.
As we will see, PLUMED is often used to apply a simulation
bias that is a function of the CVs it computes. The forces due to this
bias are then propagated onto the atoms that were used to calculate
the CV. When these CVs are calculated using the RMSD procedure
outlined above the forces required to restore invariance with
respect to translations and/or rotations must be applied to all the
atoms employed in the alignment procedure, which is computa-
tionally expensive. In fact even if you don’t have any forces to
propagate just performing the alignment operation with a large
number of atoms is expensive. One would, therefore, typically
never use the positions of all the atoms when performing RMSD
calculations.
An alternative to RMSD is the so-called DRMSD:
s ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
M
X
i j
di j  dðrefÞ
i j

2
s
ð9Þ
In this expression the sum runs over M pairs of atoms and dij is used
to denote the instantaneous distance between these pairs while
542
Giovanni Bussi and Gareth A. Tribello

dðrefÞ
i j
is used to denote the distance between the corresponding pair
of atoms in the reference structure. An input ﬁle that calculates and
prints this quantity using PLUMED is given below. Notice how the
two cutoff keywords can be used to specify the range of values the
distances should take in the reference structure in order to be
considered as part of the sum in Eq. 9.
# the dots here indicate that the command
# will be continued on the following line.
drmsd: DRMSD ...
REFERENCE=ref.pdb LOWER_CUTOFF=0.1 UPPER_CUTOFF=0.8
...
PRINT ARG=drmsd FILE=colvar STRIDE=5
2.6
Gyration Radius
and Gyration Tensor
The CVs that have been discussed thus far are all based on a very
detailed view of the positions of particular atoms. CVs that give a
more coarse-grained view of the instantaneous shape of a molecule
can also be used, however. One particularly popular CV of this type
is the so-called radius of gyration, which can be calculated using:
s ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
P
iwi
X
i
wi qðiÞ  qðcÞ

2
s
ð10Þ
where qðcÞ ¼
P
iwiqðiÞ
P
iwi and q(i) is the position of the ith atom. The wi
are a set of weights that are ascribed to each of the atoms in the
system. These weights might be, for instance, the masses of the
atoms. To calculate and print this quantity using PLUMED you
would use an input like the one below:
gyr: GYRATION TYPE=RADIUS ATOMS=10-20
PRINT ARG=gyr STRIDE=1 FILE=colvar
This calculates the radius of gyration using the positions of the
10th to the 20th atom in the MD code’s input ﬁle and sets the
weights of all these atoms equal to 1.
When the gyration radius is calculated using Eq. 10 the quan-
tity output provides a measure of the average radius of the mole-
cule. No information on the shape of the molecule is provided,
however, and so this average radius may be misleading. For exam-
ple, and as shown in Fig. 8, the radius of gyration for an extended
polymer, which has a shape that is very anisotropic, would not be
representative of the extent of the molecule in either its extended or
compact directions. For this reason, some researchers have chosen
to use the eigenvalues of the gyration tensor instead [20]. The
elements of the 3  3 gyration tensor are computed using:
Analyzing and Biasing Simulations with PLUMED
543

sjk ¼
1
P
iwi
X
i
wi qðiÞ
j
 qðcÞ
j


qðiÞ
k  qðcÞ
k


ð11Þ
where qðiÞ
j
is used to denote the jth component of the position of
atom i and qðcÞ
j
is used to denote the jth component of q(c). Figure 8
shows how the square roots of the eigenvalues of this matrix give a
sense of the shape of the molecule. By changing the word after the
TYPE keyword in the PLUMED input above one can access these
eigenvalues directly or various functions of these eigenvalues that
can be used to give one a sense of the sphericity of the molecule or
the cylindricity [20].
2.7
Dealing
with Periodic
Boundary Conditions
Figure 9 illustrates a technical problem that can appear when
PLUMED is used to calculate some CVs. When the underlying
MD code applies the periodic boundary conditions molecules can
end up split across either side of the periodic box. Consequentially,
atoms can appear to be much farther apart than they are in actuality
and, as shown in the ﬁgure, the position of the center of mass of the
molecule can be calculated wrongly. In this case, however, and in
some of the others discussed thus far PLUMED resolves this prob-
lem automatically by adjusting the positions so that the set of
molecules that are used to calculate the position of a center of
mass or a CV form one single unbroken molecule. This is still a
problem that any user must be aware of, however, as there are some
cases that PLUMED cannot ﬁx automatically. For example, sup-
pose that you wanted to calculate the end-to-end distance for the
molecule illustrated in Fig. 9. In order to do this correctly one must
reconstruct the whole molecule before calculating the distance
1
2
3
4
5
6
1
2
3
4
5
6
a)
b)
Fig. 8 Figure illustrating the components of the radius of gyration of a polymer.
The center of the polymer is represented as a star. A circle with a radius
corresponding to the radius of gyration of the polymer and centered on the
center of the polymer is shown using a dashed line. (a) For a globular polymer,
the circle correctly represents the shape of the polymer. (b) For an elongated
polymer, however, the circle does not represent the shape of the polymer
correctly. An ellipsoid with axes that have lengths corresponding to the square
roots of the eigenvalues of the gyration tensor is more representative and is
shown in yellow
544
Giovanni Bussi and Gareth A. Tribello

between the two terminal atoms. To resolve this problem
PLUMED provides a command, WHOLEMOLECULES, that
allows one to adjust the way the positions are stored and to thus
specify the molecules that must be reconstructed. A sample input
that calculates this end-to-end distance and that uses a WHOLE-
MOLECULES command is provided below
WHOLEMOLECULES ENTITY0=1-6
d1: DISTANCE ATOMS=1,6 NOPBC
The WHOLEMOLECULES command here ensures that the bond
between each pair of adjacent atoms speciﬁed to the ENTITY key-
word is not broken by the periodic boundaries. The distance is thus
computed from the positions of the atoms shown in the right panel
of Fig. 9. There is thus no need to apply periodic boundary condi-
tions. In fact if, when the molecule is extended, it has a length that
is longer than half the box length, it is wrong to apply periodic
boundary conditions as the “end-to-end distance” computed this
way would no longer be representative of the distance along the
chain.
A more complicated example which has been taken from ref. 21
and which also requires the WHOLEMOLECULES command to be
used is shown in Fig. 10. In this case the reconstruction has been
done using the following input ﬁle:
MOLINFO STRUCTURE=ref.pdb
rna: GROUP ATOMS=1-258
mg:
GROUP ATOMS=6580
wat: GROUP ATOMS=259-6579
1
2
3
4
5
6
4
5
6
1
2
3
4
5
6
4
5
6
d
d
a)
b)
Fig. 9 An illustration showing how molecules can be split by the periodic boundary conditions and how this can
cause a problem when computing collective variables. Panels (a) and (b) represent the same set of six atoms.
In both of these ﬁgures these atoms sit in the periodic box indicated using the rectangle so periodic images of
atoms 4, 5, and 6 are included. The atoms used to calculate the collective variables are highlighted. In panel
(a), a broken molecule is used so the position of center of mass (indicated using a star) and the end-to-end
distance (indicated using an arrow) are computed incorrectly. In panel (b), however, the molecule has been
correctly reconstructed across the periodic boundaries using WHOLEMOLECULES and the center of mass
has thus been computed correctly. Notice that the correct value for the end-to-end distance is only obtained
from panel (b) if the periodic boundary conditions are ignored when computing the distance (keyword
NOPBC). If the PBC are taken into account, the incorrect image of atom 6 will be used and the incorrect
result illustrated in panel (a) will be obtained once more
Analyzing and Biasing Simulations with PLUMED
545

# Make the RNA duplex whole.
WHOLEMOLECULES ENTITY0=rna
# Align the RNA duplex to a reference structure
FIT_TO_TEMPLATE REFERENCE=ref-rna.pdb TYPE=OPTIMAL
# Notice that before using FIT_TO_TEMPLATE
# we used WHOLEMOLECULES to make the RNA whole
# This is necessary otherwise you would be aligning
# a broken molecule!
# compute the center of the RNA molecule
center: CENTER ATOMS=rna
# Wrap atoms correctly around the center of the RNA
WRAPAROUND ATOMS=mg AROUND=center
WRAPAROUND ATOMS=wat AROUND=center GROUPBY=3
# Dump the resulting trajectory
DUMPATOMS ATOMS=rna,wat,mg FILE=rna-wrap.gro
Notice here how the action FIT_TO_TEMPLATE has been used
to align the RNA molecules to a template structure that is at the
center of the box and how the action WRAPAROUND has been used
to reposition the water molecules around the aligned RNA mole-
cule. In addition, notice that by aligning the molecule to a template
we have made the positions of these atoms roto-translationally
invariant. We can thus use the positions of the aligned atoms as
Fig. 10 Figures showing how PLUMED can be used to reconstruct a solvated RNA molecule that has been split
by the periodic boundary conditions. The RNA duplex is represented using licorice and the water molecules are
represented using lines. In panel (a) the molecules that cross the periodic boundaries are broken. In panel (b),
however, the RNA molecule has been reconstructed and centered, and the periodic images of the water
molecules that are closest to the center of the RNA molecule have been selected. Notice that selecting the
water molecules in this way ensures that the water molecules are made whole
546
Giovanni Bussi and Gareth A. Tribello

CVs using the POSITION command that was introduced earlier.
Furthermore, when we do so the FIT_TO_TEMPLATE command
will ensure that the process of aligning the molecule is considered
correctly when propagating any forces to the underlying positions.
As it is probably clear at this stage, correctly reconstructing the
atoms across the periodic boundary conditions is crucial as when
this is not done some variables will be computed incorrectly. In
order to simplify the preparation of PLUMED input and to
decrease the number of errors, we have tried to automatize the
reconstruction in all the cases where this is easy to do. You should
thus check the manual of the PLUMED version that you are using
to know when the reconstruction of molecules that have been
broken by the periodic boundary conditions is dealt with
automatically.
2.8
Going Further
with Collective
Variables
Hopefully the example input ﬁles in the previous sections have
given you a sense of how PLUMED input ﬁles work. In essence,
all the PLUMED commands for calculating CVs that we have
introduced thus far calculate a scalar valued quantity. Any scalar
valued quantity that we calculate can then be referred to later in the
input ﬁle by using the label of the command that calculates it. So,
for instance, in the following PLUMED input ﬁle:
dist: DISTANCE ATOMS=1,2
PRINT ARG=dist FILE=colvar STRIDE=1
the PRINT command instructs PLUMED to print the quantity
called dist which is calculated by the ﬁrst DISTANCE command to
a ﬁle called colvar during every MD step. The fact that we can pass
scalar valued quantities in this way is enormously useful as it means
we can script new CVs directly from the input ﬁle. For example,
suppose that we want to calculate the number of native contacts in a
protein. This CV is often computed using the continuous switching
function shown below or by using some other function that dis-
plays a similar behavior [12]:
s ¼
X
i j∈N C
1
1 þ ðri j=r0Þ6
ð12Þ
Here the sum runs over the list of pairs of atoms that are in contact
when the protein is folded and r0 is a parameter. If we had a total of
four native contacts in the protein and if r0 were set equal to 6 A˚ we
could compute and print this quantity using the following
PLUMED input ﬁle:
d1: DISTANCE ATOMS=1,2
d2: DISTANCE ATOMS=5,6
d3: DISTANCE ATOMS=9,10
Analyzing and Biasing Simulations with PLUMED
547

d4: DISTANCE ATOMS=15,16
# The braces allow us to use spaces
# within the argument of the FUNC keyword
contacts: CUSTOM ...
ARG=d1,d2,d3,d4 VAR=a,b,c,d
FUNC={
1/(1+(a/0.6))^6
+1/(1+(b/0.6))^6
+1/(1+(c/0.6))^6
+1/(1+(d/0.6))^6
}
PERIODIC=NO
...
PRINT ARG=contacts FILE=colvar STRIDE=10
Notice here how we have used our familiar friend the DIS-
TANCE command to calculate each of the distances required and
have then used the command CUSTOM to calculate the non-linear
combination of quantities that the CV requires. The fact is that
most of the more complicated CVs that have been used to analyze
molecular dynamics trajectories are simply linear or non-linear
combinations of the quantities that have been introduced thus far.
One can thus compute many complicated CVs by just using the
commands that were introduced in the previous sections together
with the CUSTOM command. It is worth understanding how to use
this approach, but we would, in practice, not recommend you write
your PLUMED input ﬁles in this way. Instead, we would recom-
mend that you use the numerous shortcuts PLUMED provides for
accessing these non-linear combinations. For example, a shorter
input that does the same calculation as the input ﬁle above is as
follows:
dists: DISTANCES ...
ATOMS1=1,2 ATOMS2=5,6 ATOMS3=9,10 ATOMS4=15,16
LESS_THAN={RATIONAL R_0=0.6}
...
PRINT ARG=dists.lessthan FILE=colvar STRIDE=10
This input takes advantage of the fact that many of the more
complicated CVs that we wish to compute have a functional form
that can be thought of as follows:
s ¼
X
N
i¼1
f ðfXgiÞ
ð13Þ
In other words, to calculate the CV one computes the same func-
tion, f, for N different sets, {X}i, of atomic positions. Some more
complicated examples of CVs of this form are the so-called
548
Giovanni Bussi and Gareth A. Tribello

secondary structure variables ALPHARMSD, ANTIBETARMSD, and
PARABETARMSD [22]. For
ALPHARMSD one takes each set of
M atoms in the protein that might together be able to form an
alpha helix. For each of these sets of variables one then computes
the DRMSD distance between the instantaneous positions of the
atoms and the positions of the atoms in an ideal alpha helix. Each of
these DRMSD distances is then transformed by a continuous
switching function and these transformed values are then added
together. The ﬁnal value of the CV, that is calculated and printed
using the input below, thus measures how many segments in the
protein resemble an alpha helix.
MOLINFO STRUCTURE=helix.pdb
a: ALPHARMSD ...
RESIDUES=all TYPE=DRMSD
LESS_THAN={RATIONAL R_0=0.08 NN=8 MM=12}
...
PRINT ARG=a.lessthan FILE=colvar STRIDE=10
The ANTIBETARMSD and PARABETARMSD commands do some-
thing very similar but the reference conﬁguration in these cases are
obviously an ideal anti-parallel beta sheet and an ideal parallel beta
sheet, respectively. For these three commands one could, in theory,
calculate this quantity using multiple DRMSD commands and the
CUSTOM command that was introduced earlier. It is obviously much
easier though to use the input above, which determines the sets of
atoms for which you have to determine DRMSD distances from the
template pdb structure directly. Having said that, however, it can be
useful to try to write input ﬁles that use only the simple commands
that were introduced in the previous sections in order to better
understand what precisely is being calculated by these shortcuts.
This chapter would be overly long if we listed all the CVs that
are available in PLUMED. If you are interested we would recom-
mend reading the literature. To get you started we have provided
the following short and far from exhaustive list, of references for a
range of CVs, which can be calculated by PLUMED. This list
includes the total energy of the system [23, 24], some of the
components of the energy [25, 26], the dimer interaction energy
[27], discrepancy measures [28], principal components [29, 30],
path collective variables [31, 32], property maps [33], puckering
variables [34, 35], Steinhardt order parameters [17], and a number
of experimental observables [36]. In addition, PLUMED contains
implementations of the principal component analysis [37], multi-
dimensional scaling [38], and sketch-map [39] algorithms, which
are all tools that can be used to analyze simulation trajectories.
PLUMED input ﬁles can be prepared using a graphical user inter-
face [40] and this graphical user interface also allows you to com-
pute PLUMED CVs from within the VMD program [41].
Analyzing and Biasing Simulations with PLUMED
549

3
Biasing Collective Variables
Subheading 2 has hopefully given you a sense of some of the
quantities we might be interested in monitoring during the course
of a simulation. If this were all that PLUMED could do, however,
there would be no reason for it to be usable on the ﬂy. After all, all
of the quantities we have discussed can be calculated by post-
processing the trajectory ﬁles that are output during the simulation.
The reason that PLUMED runs on the ﬂy is that it can also modify
the Hamiltonian, H(q, p). These modiﬁcations introduce addi-
tional forces that must be incorporated when the underlying MD
code integrates the equation of motion. Calculation of the
PLUMED potential and the associated forces can, however, be
separated from the calculation of the forces due to the underlying
potential as the bias potential, V (q, t), that is calculated by
PLUMED and that is a function of the atomic positions and
possibly also time, t, is simply added to the Hamiltonian, H(q, p),
that is calculated by the MD code. In other words, the modiﬁed
Hamiltonian, H0(q, p) is
H 0ðq, pÞ ¼ Hðq, pÞ þ V ðq, tÞ
ð14Þ
3.1
Reweighting
To understand how free energies can be extracted from biased MD
simulations we must return once again to the probability distribu-
tion that is sampled during a molecular dynamics trajectory. This
distribution was ﬁrst introduced in Subheading 2.1 when we intro-
duced the following equation:
Pðq, pÞ / e Hðq,pÞ
kBT
ð15Þ
and explained how the quantity on the right-hand side of this
equation is proportional to the probability of sampling any given
vector of atomic positions, q, and momenta, p. Now suppose that we
are not integrating the Hamiltonian H(q, p) given above and that we
are instead integrating a modiﬁed Hamiltonian H(q, p) + V (q).
The probability distribution, P 0(q, p), that we will sample from
when we integrate this biased Hamiltonian will be proportional to:
P0ðq, pÞ / e Hðq,pÞ
kBT e V ðqÞ
kBT
ð16Þ
for the same reasons that the probability of sampling a particular
conﬁguration when the system is unbiased is given by Eq. 15.
Notice, furthermore, that the right-hand side of Eq. 15 appears in
the equation above and that we can thus rewrite this expression as:
Pðq, pÞ / P0ðq, pÞeþ V ðqÞ
kBT
ð17Þ
550
Giovanni Bussi and Gareth A. Tribello

This equation relates the probabilities that we extract from biased
simulations to the corresponding unbiased probabilities and, as we
will see in the next section, it is thus the central equation for the
analysis of biased simulations. Strictly speaking, this relationship is
only valid if the bias potential does not change with time. As
discussed below, different formalisms can be used when the bias
potentials are time-dependent.
3.2
Extracting
the Free Energy
We now have all the pieces we require and can thus ﬁnally discuss
the topic that was ﬁrst introduced in Subheading 2, namely how we
analyze biased and unbiased MD simulations so as to extract the
free energy as a function of a small number of collective variables.
The ﬁrst step in this process is to discretize the CV space and to
introduce a set of probabilities, pj, each of which tells us the proba-
bility that the CV value falls in a particular range or bin. These bins
are set up so that all possible CV values fall within exactly one of the
bins. Consequently, if we discretize the CV space, s(qi), into M bins
with centers at sj the probability that t1 of the frames from our MD
trajectory fall within the ﬁrst of these bins, that t2 of the frames fall
within the second bin, and so on is given by the following multino-
mial distribution:
Pðt1, t2, . . . , tM Þ / ∏
M
j¼1p
tj
j
ð18Þ
where pj is the probability that any given trajectory frame will fall
into the jth bin. It is easy to extract the set of tj values that appear in
this expression from our trajectory. All we need to do is construct a
histogram that tells us the number of times the trajectory visited
each bin (see Note 4). Furthermore, once we have this information
on the values of tj we can perform a constrained optimization on
Eq. 18 and thus determine the most likely values for the probabil-
ities, the pjs, given the particular set of tj values that we observed
during our trajectory. It is easier if we start this process of optimiz-
ing Eq. 18 by taking the logarithm of both sides of the equation.
Doing so has no effect on the position of the minimum as the
logarithm is a monotonically increasing function. Having taken
the logarithm we then recall that the set of pj values are probabilities
and that as such they must satisfy PM
j¼1 pj ¼ 1. We must therefore
perform a constrained optimization using the method of Lagrange
multipliers. The ﬁnal function we need to optimize is thus:
L ¼
X
M
j¼1
tj ln pj þ λ
X
M
j¼1
pj  1
0
@
1
A
ð19Þ
where λ is a Lagrange multiplier. When this expression is maximized
we obtain (see Note 5)
Analyzing and Biasing Simulations with PLUMED
551

pk ¼ tk
T
ð20Þ
where T ¼∑jtj is the total number of frames in the trajectory. In
other words, the most likely estimate for the probability that the
CV will take a value within a particular range is just the fraction of
time that the trajectory spent with CV values in that particular
range. By recalling the relationship between probability and free
energy we can thus express the free energy for having the CV value
in the kth range as:
F k ¼ kBT ln tk þ C
ð21Þ
Let us now suppose that we had taken the data from a biased
trajectory rather than an unbiased trajectory and discuss how we
would extract the histogram in this case. In other words, suppose
that instead of integrating the Hamiltonian, H(p, q), directly we
had integrated the biased Hamiltonian, H(p, q) + V (q). As dis-
cussed in the previous section we know that the probability distri-
bution that we sample conﬁgurations from when we do this biased
simulation, P 0(q, p), is related to the probability distribution, P(q,
p), that we would have sampled conﬁgurations from had we run
our simulation without the bias by Eq. 17. We therefore might
expect that we can extract a free-energy landscape for the unbiased
simulation using the data from our biased simulations and a proce-
dure much like that outlined above. The trick for doing this is to
recognize that we can use Eq. 17 to write the multinomial distribu-
tion that we sample from when we run a biased simulations in terms
of the elements of the probability distribution, pj, that would have
been sampled if we had run our simulation without any bias as
shown below:
P0ðt1, t2, . . . , tMÞ / ∏
M
j¼1ðwjpjÞtj,
ð22Þ
where wj ¼ e
V ðqiÞ
kBT and where V (qi) is the bias potential calculated
for the ith frame. If we take the logarithm of this expression and
impose the constraint that PM
j¼1 ðwjpjÞ ¼ 1 we thus ﬁnd that the
function to optimize in this case is
L ¼
X
M
j¼1
tj ln wjpj þ λ
X
N
j¼1
wjpj  1
0
@
1
A
ð23Þ
When this expression is maximized we obtain (see Note 6)
pk / tkeþ V ðqiÞ
kBT
ð24Þ
By taking the logarithm of the above and by multiplying by  kBT
we can thus extract the unbiased free-energy surface from a biased
simulation.
552
Giovanni Bussi and Gareth A. Tribello

3.3
Biasing
Simulations
with PLUMED
The need for numerous methods based on integrating modiﬁed
Hamiltonians has been discussed at length in Section II. We will
thus limit the discussion of these methods here to providing a few
sample PLUMED input ﬁles that instruct PLUMED to calculate
various bias potentials. The ﬁrst of these examples involves the
following input, which instructs PLUMED to use a harmonic
restraint on the distance between atoms 1 and 2 as a bias potential.
The instantaneous values for the distance and the bias potential are
then output to a ﬁle called colvar.
d1: DISTANCE ATOMS=1,2
rr: RESTRAINT ARG=d1 AT=0.2 KAPPA=10
PRINT ARG=d1,rr.bias FILE=colvar
This input encourages the system to sample conﬁgurations
where the distance between atoms 1 and 2 is close to 0.2
nm. Many such inputs are typically used when performing umbrella
sampling calculations with multiple restraints [42, 43].
Bias potentials do not have to be independent of time. There
are, in fact, a whole class of steered MD methods in which a time-
dependent bias potential is used to force the system to change its
conformation over the course of a simulation. A sample PLUMED
input for such a calculation is given below.
MOLINFO STRUCTURE=helix.pdb
phi3: TORSION ATOMS=@phi-3
mr: MOVINGRESTRAINT ...
ARG=phi3 STEP0=0 STEP1=10000 STEP2=20000
KAPPA=100 AT0=-pi/3 AT1=pi/4 AT2=-pi/3
...
PRINT ARG=phi3,mr.∗FILE=colvar
The input above is for a 20,000 step steered MD simulation
[44] in which the ϕ angle in the third residue of protein is forced to
change its value from  π
3 radians to π
4 radians before being forced to
change the value of this torsional angle back to  π
3 radians once
more. This input instructs PLUMED to output the instantaneous
value of the torsional angle, the bias and the work the bias has done
on the system. Obviously, the user can make the path the system is
forced to take through conﬁguration space more complicated by
using linear combinations of CVs and by changing the number of
STEP and AT commands.
The ﬁnal sample input below gives an example of how
PLUMED can be used to perform the metadynamics simulations
[45] that were discussed at length in Chapter 4.
phi: TORSION ATOMS=5,7,9,15
psi: TORSION ATOMS=7,9,15,17
metad: METAD ...
Analyzing and Biasing Simulations with PLUMED
553

ARG=phi,psi PACE=500 HEIGHT=1.2 SIGMA=0.35,0.35
...
PRINT STRIDE=10 ARG=phi,psi,metad.bias FILE=COLVAR
The input here is for a classic test case for these methods:
calculating the free-energy surface for alanine dipeptide as a func-
tion of the ϕ and ψ backbone dihedral angles.
What you have hopefully noticed from the above input ﬁles is
that PLUMED separates the calculation of the CVs from the calcu-
lation of the bias potential. Consequently, when using PLUMED
we would normally express the bias as:
V ðq, tÞ ¼ V ðs1ðqÞ, s2ðqÞ, . . . , snðqÞ, tÞ
ð25Þ
This introduces a set of biased collective variables s(q) ¼ {s1(q),
s2(q), . . ., sn(q)} that allow us to represent the dynamics that all the
atoms undergo in some low-dimensional space. If we can calculate
the partial derivatives of these collective variables with respect to the
atomic positions we can then use the chain rule to calculate the
forces on the atoms that result from the bias potential using:
f m ¼  ∂V
∂qm
¼ 
X
n
i¼1
∂V
∂si
∂si
∂qm
ð26Þ
Here the sum runs over the n collective variables that V (s, t) is a
function of. fm, meanwhile, is the force acting on one of the three
components of the position of a particular atom, and
∂si
∂xm is the
derivative of the ith collective variable with respect to this particular
component of the position of this same atom.
The key point to recognize is that the bias, which is some
complicated function of the atomic positions, is expressed as a
function of some set of simpler functions of the atomic positions.
Consequently, as we saw in the discussion of CVs, we can thus build
very complicated bias potentials by combining simpler pieces
together in the PLUMED input ﬁle. Notice also that, as discussed
in Note 7, we can make this business of computing bias potentials
and CVs compatible with multiple-time-step algorithms for inte-
grating the equations of motion.
As was the case for the CVs PLUMED contains implementa-
tions of other free-energy methods that we do not have the space to
discuss here. We will thus ﬁnish this section once more with a list of
methods that are implemented in PLUMED together with relevant
papers that describe them. This list of methods includes: many
variants of metadynamics [11, 46–55] including techniques that
allow boundary conditions to be treated correctly in metadynamics
simulations [56] and methods for extracting kinetic information
from metadynamics simulations [57]. Then, in addition to meta-
dynamics,
we
also
have
implementations
of
temperature-
accelerated MD [58, 59], adaptive biasing force [60–62], and
variationally enhanced sampling [63, 64]. Lastly, several bias
554
Giovanni Bussi and Gareth A. Tribello

potentials are included that allow one to force the ensemble
averages that are extracted from the simulations to agree with
data extracted from experiments. The techniques for this that
have been implemented include experiment-directed simulations
[65, 66], maximum entropy restraints [67], target metadynamics
[68–70], and metainference [71].
3.4
Free Energies
To calculate the free energy as a function of the distance between
two atoms using PLUMED and the technique described in Sub-
heading 3.2 one would use an input like the one shown below:
d1: DISTANCE ATOMS=1,2
h: HISTOGRAM ...
ARG=d1 GRID_MIN=0 GRID_MAX=1.0
GRID_BIN=200 KERNEL=DISCRETE STRIDE=10
...
f: CONVERT_TO_FES GRID=h TEMP=300
DUMPGRID GRID=f FILE=fes.dat
The input above creates a histogram with 200 bins that cover
the range of distance values between 0 and 1 nm. This histogram is
constructed using the distance calculated for every 10th trajectory
frame. The free energy is then calculated from the accumulated
histogram and output once the calculation has completed.
We can also use PLUMED and the methods described in
Subheading 3.2 to calculate the free-energy landscape from a biased
simulation. Below is a sample input that performs this type of
calculation:
phi: TORSION ATOMS=1,2,3,4
psi: TORSION ATOMS=5,6,7,8
EXTERNAL ARG=phi,psi FILE=bias_potential.dat
as: REWEIGHT_BIAS TEMP=300
hh: HISTOGRAM ...
LOGWEIGHTS=as ARG=d STRIDE=10
GRID_MIN=-pi,pi GRID_MAX=pi GRID_BIN=400
KERNEL=DISCRETE
... HISTOGRAM
ff: CONVERT_TO_FES GRID=hh TEMP=300
DUMPGRID GRID=ff FILE=fes.dat
This is an input ﬁle for an enhanced sampling calculation that
uses a bias that has been read from a ﬁle called bias_potential.
dat. The bias potential that is read from this ﬁle is designed to act
on the two torsional angles and to thus force them to sample
conﬁguration
space
more
exhaustively.
The
histogram
is
Analyzing and Biasing Simulations with PLUMED
555

constructed using data from every 10th trajectory frame. The free
energy is then calculated from the accumulated histogram and
output once the calculation has completed. This is all very similar
to what was done in the unbiased case. The major difference here,
however, is that we have used the REWEIGHT_BIAS command and
the LOGWEIGHTS keyword to ensure that the effect of the bias is
discounted when the histogram is constructed. The free-energy
surface output is thus the free-energy surface for the unbiased
Hamiltonian.
It is important to notice that weighting each of the simulated
snapshots with a factor of eþV ðqÞ
kBT is correct when V only depends on
the coordinates of the systems. If the bias potential, V , is time-
dependent, more advanced procedures, that will not be discussed at
length in this chapter, should be employed. Two particularly
important enhanced sampling techniques that employ time-
dependent bias potential, and for which we provided sample inputs
above, are:
l
Steered MD: To extract free energies from such simulations one
has to run multiple steered MD calculations and then analyze
the ensemble of trajectories obtained using the Jarzynski
equality [72].
l
Metadynamics: Several procedures have been proposed that
allow one to compute appropriate weighting factors for these
types of simulations [51, 73, 74].
4
Calculating Error Bars
The methods that we have introduced thus far for calculating
ensemble averages and for calculating histograms are all based on
the fact that we can calculate an approximate value for the true
ensemble average by taking a large number of samples from the
underlying distribution. In other words, in all these methods we are
calculating a sample mean and assuming that it provides a reason-
able estimate for the true population mean. What has thus far been
missing from this discussion, however, is how we get an estimate for
the error bar on the sample mean. Any sample mean, after all, is
itself a random variable and thus has an underlying distribution,
which we should attempt to characterize. The difﬁculty in doing so
when our data is extracted from an MD trajectory is, however, that
there are strong and measurable (see Note 8) correlations between
the conﬁgurations sampled in the frames of the trajectory that are
adjacent. As we will see in the remainder of this section, however,
we can take these correlations into account when we calculate the
variance and can thus calculate appropriate error bars.
Figure 11 shows why these correlations represent such a prob-
lem. To construct the histogram shown in the panel on the left we
556
Giovanni Bussi and Gareth A. Tribello

generated 50,000 sets of n ¼ 20 normal random variables. We then
calculated a sample average for each of these sets, μi, and a sample
mean, hXi, and sample variance, σ2, for all 1,000,000 points in the
data set. This sample variance was calculated using:
σ2 ¼
1
N  1
X
N
i¼1
ðX i  hXiÞ2
ð27Þ
The reason for doing this is that the central limit theorem tells us
that the distribution of μi values should be a Gaussian centered on
the sample mean with a variance of σ2
n . As you can see from the left
panel this is a good model for the distribution of the sample means
that were obtained by averaging the independent random variables.
The right panel shows, however, that this is not a good model when
the data is taken from an MD or Monte Carlo trajectory. As
discussed in Note 9 to construct this ﬁgure sample means for
50,000 sets of n ¼ 20 correlated random variables were calculated
once more as well as the sample mean and variance for the full set of
1,000,000 variables. The blue histogram shows the distribution of
the sample means. As you can see the correlation between the
1.75
1.50
1.25
1.00
0.75
0.50
0.25
0.00
–1.0
–4
–2
0
2
4
–0.5
0.0
0.5
1.0
0.0
0.1
0.2
0.3
0.4
0.5
Average CV
Average CV
Fraction of counts
Fig. 11 Histograms that are obtained by sampling independent and identically
distributed random variables (left) and by sampling CV values from a trajectory
(right). Each of the quantities that were used to calculate the histograms was
constructed by taking an average of n ¼ 20 random variables. The central limit
theorem would thus predict the distribution of these averages to be a Gaussian
with a variance of σ2
n , where σ2 is the sample variance. The red lines thus show
what this analytical function looks like for the two data sets. For the independent
random variables in the left panel it is clear that this is a good model for the
sampled data. For the correlated data in the right panel, however, this model
substantially underestimates the variance in the true distribution of averages. In
fact, the green line shows a Gaussian that has the sample variance as its
parameter and it is clear that this provides a much better model for the shape
of this distribution
Analyzing and Biasing Simulations with PLUMED
557

values of the CVs ensures that this distribution is substantially wider
than the central limit theorem (red line) would predict it to be. In
other words, for correlated data σ2
n is not a sensible estimate for the
variance of the sample mean.
This problem can be resolved using the so-called block averag-
ing technique [75]. In essence this technique involves splitting the
trajectory into a set of N blocks that are all of equal length.
N separate sample means, μi, are then calculated from each of
these blocks of data. Obviously, the mean for these N quantities
that is calculated using:
μ ¼ 1
N
X
N
i¼1
μi
ð28Þ
is equal to the mean we would have obtained had we averaged every
frame in our trajectory. The advantage of block averaging in this
way is, however, that, if each μi is calculated over a long enough
block of trajectory, the values of the μis are no longer correlated. We
can thus calculate an error bar on the estimate of μ that we would
calculate using the formula above as:
ε ¼ Φ1 pc þ 1
2


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
NðN  1Þ
X
N
i¼1
ðμi  μÞ2
v
u
u
t
ð29Þ
where Φ1 is the inverse of the cumulative probability distribution
function for the standard normal random variable and where pc is
the level of statistical conﬁdence we want our error bar to represent.
Figure 12 shows the outcome of applying this technique on
data obtained by sampling independent and identically distributed
random variables and on data obtained by calculating the value of a
CV over the course of a trajectory. The mean and error bars are
shown as a function of the sizes of the blocks over which the μi
averages were calculated. In both cases you can see that the ﬁnal
value of μ does not depend on the size of the blocks. The small
differences in this value are due to the ﬁnite precision algebra the
computer uses. For the correlated data from the MD trajectory,
however, the size of the error bar does depend on the length of the
blocks. In particular, the error bar is smaller when the block sizes
are small as the μi values are still correlated. As the block sizes get
larger, however, the μi values become decorrelated and the size of
the error bar thus plateaus to a near constant value.
A similar technique can be used to calculate error bars for
histograms and free-energy surfaces. For the weighted histograms
discussed at the end of Subheading 3.2 the probability, gðiÞ
j , for
the jth bin of the histogram is computed using Eq. 24, and the data
from the ith block of trajectory data. The following input shows
how these histograms can be constructed in practice by using
PLUMED.
558
Giovanni Bussi and Gareth A. Tribello

phi: TORSION ATOMS=1,2,3,4
psi: TORSION ATOMS=5,6,7,8
EXTERNAL ARG=phi,psi FILE=bias_potential.dat
as: REWEIGHT_BIAS TEMP=300
hh: HISTOGRAM ...
LOGWEIGHTS=as ARG=d STRIDE=10
GRID_MIN=-pi,pi GRID_MAX=pi GRID_BIN=400
KERNEL=DISCRETE CLEAR=1000000
... HISTOGRAM
DUMPGRID GRID=hh FILE=histo.dat STRIDE=1000000
The simulation that is being analyzed here is the same biased
calculation that was described in Subheading 3. The input above,
however, instructs PLUMED to output independent histograms
from each block of 1,000,000 MD steps in the trajectory to a set of
ﬁles called analysis.0.histo.dat, analysis.1.histo.dat, . . . and histo.
dat. This procedure obviously gives multiple estimates for the
Fig. 12 Figure showing how the error bars calculated using the block averaging
technique depend on the lengths of the blocks used for independent and
identically distributed random variables (left) and for data from a typical
MD/MC trajectory (right). As you can see, the size of the error bar is largely
independent of the block size when the data points being averaged are samples
of a random variable. The correlations between the CV values we obtain in a
trajectory, however, ensure that the error bar is underestimated when the block
size used is small. Consequently, as the length of time over which the block
averages are taken is increased the error bar increases in size until it eventually
reaches a plateau
Analyzing and Biasing Simulations with PLUMED
559

probability of each bin, which can be combined to give a single set
of sample means and conﬁdence limits using the following or other
similar expressions:
hgji ¼
1
PN
i¼1 wi
X
N
i¼1
wigðiÞ
j
ð30Þ
εj ¼ Φ1 pc þ 1
2


ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
N
W  S
W


X
N
i¼1
wi∗ðgðiÞ
j
 hgjiÞ2
v
u
u
u
u
t
ð31Þ
Here wi is used to indicate the sum of the weights of all the
conﬁgurations in each of the blocks of data. W and S are then the
sum of these wi values and the sum of the squares of these values,
respectively.
Example python code for taking the set of histogram ﬁles out-
put by PLUMED and for calculating the means and the error bars
using the formulas above can be found on the PLUMED website.
Figure 13 shows how the average size of the errors on the estimate of
the free energy obtained from a metadynamics simulation changes
as the length of the blocks is increased (see Note 10). Similarly to
Fig. 13 Figure showing how the average error on the estimate of a free energy
obtained for a metadynamics simulation of alanine dipeptide depends on the
sizes of the blocks over which the individual histograms were calculated. As with
the example involving the ensemble average in Fig. 12 the error is under-
estimated when small blocks are used. When larger blocks of data are used,
however, the value of the error plateaus at a constant value
560
Giovanni Bussi and Gareth A. Tribello

what we observed in the right panel of Fig. 12 when small blocks are
used the error bar on the free energy is underestimated and the error
bars are thus too small. When sufﬁciently large blocks are used,
however, the size of the error reaches a plateau value.
5
Multiple-Replica Techniques
Thus far we have considered cases where a single simulation is
performed and then analyzed. There are, however, situations
where one wants to simultaneously run multiple simulation repli-
cas. Sometimes these replicas are run under equivalent conditions
and the only differences between them are the initial conﬁgura-
tions. If this is the case one can simply concatenate all the trajec-
tories and analyze them using the techniques that have been
discussed in the previous sections. Alternatively, if the simulations
are short and are thus not expected to reach equilibrium, more
statistically reliable results may well be obtained if they are analyzed
using the Markov state models that have been discussed in
Chapter 4. Oftentimes, however, the various replicas are run
using different conditions (e.g., the replicas have different tempera-
tures or different biasing potentials). In this case the replicas will
often also communicate with each other using a replica-exchange
procedure. In this section we will thus discuss how such multiple-
replica simulations operate and how they should be analyzed. The
analysis described in what follows can be applied when replicas are
simulated independently of each other or when they are simulated
in a manner that permits exchanges between replicas. For best
results we would always suggest allowing exchanges between repli-
cas as this increases the ergodicity of the simulation.
Replica-exchange molecular dynamics provides a rigorous the-
oretical framework that can be used to swap coordinates between
trajectories that are calculated simultaneously but performed using
different conditions (see Chapter 2). Perhaps the most commonly
used of these techniques is parallel tempering [76], which uses a
different temperature in each of the simulated replicas. The replicas
can also experience different simulation biases, however, so,
because PLUMED is designed to bias MD simulations and because
there are a number of techniques in the literature that are based on
this principle (see, e.g., [11, 49, 77, 78]), this will be the focus in
this section. Within many of these replica-exchange techniques the
metropolis Monte Carlo scheme is employed with proposed moves
that involve swapping the coordinates of replica i (q(i)) with the
coordinates of replica j (q(i)) and an acceptance probability that is
given by:
Analyzing and Biasing Simulations with PLUMED
561

α ¼ min 1, PðiÞðqðjÞÞPðjÞðqðiÞÞ
PðiÞðqðiÞÞPðjÞðqðjÞÞ
 
!
ð32Þ
Here P(i)(q) is the probability that the set of coordinates q will be
observed under the conditions experienced by the ith replica.
Assuming that the only difference between the two replicas is the
bias potential experienced and that the bias potentials for replica i is
V(i)(q) allows us to use Eq. 16 to rewrite this probability using an
expression that only depends on the bias potentials:
α ¼ min 1,exp V ðiÞðqðjÞÞV ðjÞðqðiÞÞþV ðiÞðqðiÞÞþV ðjÞðqðjÞÞ
kBT
 
!
 
!
ð33Þ
When coordinate swaps are accepted or rejected using these criteria
we ensure that the system remains at equilibrium. Consequently,
any averages that we obtain are in principle indistinguishable from
those that would have been obtained if the simulations had been
performed independently. The advantage, however, is that the
coordinate swaps usually systematically increase the number of
slow transitions that are sampled. We can thus use these methods
to obtain more statistically robust averages from shorter (parallel)
simulations.
5.1
The Weighted
Histogram Method
The multiple-replica simulations that were introduced above pro-
vide us with a powerful set of tools that allow us rapidly explore a
wide region of conﬁguration space and to take advantage of parallel
computing facilities. In this ﬁnal section we will discuss how the
trajectories we obtain from these simulations are analyzed. Much
like the analysis that was discussed in Subheading 3.2 the aim here is
to extract the free energy as a function of a CV or set of CVs.
Furthermore, when analyzing these multiple-replica simulations
we are again going to calculate a histogram and then exploit the
maximum likelihood technique to convert this to a free energy. At
odds with Subheading 3.2, however, we now have multiple trajec-
tories, each of which was obtained by integrating a different biased
Hamiltonian. We thus calculate the probability of observing this
particular set of conﬁgurations during the N trajectories that we ran
using the product of multinomial distributions shown below:
PðTÞ / ∏
M
j¼1∏
N
k¼1ðckwk jpjÞtk j
ð34Þ
In this expression the second product runs over the biases that were
used when calculating the N trajectories. The ﬁrst product then
runs over the M bins in our histogram. The pj variable that is inside
this product is the quantity we wish to extract, namely the unbiased
probability of having a set of CV values that lie within the range
562
Giovanni Bussi and Gareth A. Tribello

for the jth bin. The quantity that we can easily extract from our
simulations, tkj, however, measures the number of frames from
trajectory k that are inside the jth bin. To interpret this quantity
we must consider the bias that acts on each of the replicas so the wkj
term is introduced. This quantity is calculated using Eq. 17 and is
essentially the factor that we have to multiply the unbiased proba-
bility of being in the bin by in order to get the probability that we
would be inside this same bin in the kth of our biased simulations.
Obviously, these wkj values depend on the value that the CVs take
and also on the particular trajectory that we are investigating all of
which, remember, have different simulation biases. Finally, ck is a
free parameter that ensures that, for each k, the biased probability is
normalized.
We can use Eq. 34 to ﬁnd a set of values for pj that maximizes
the likelihood of observing the trajectory. This constrained optimi-
zation must be performed using a set of Lagrange multipliers, λk,
that ensure that each of the biased probability distributions are
normalized, that is ∑jckwkjpj ¼ 1. Furthermore, much as in Sub-
heading 3.2, the problem is made easier if Eq. 34 is replaced by its
logarithm.
L ¼
X
M
j¼1
X
N
k¼1
tk j ln ckwk jpj þ
X
k
λk
X
N
j¼1
ckwk jpj  1
0
@
1
A
ð35Þ
After some manipulations (see Note 11 or the derivation reported
in ref. 79), the following equations emerge:
pj /
PN
k¼1 tk j
P
kckwk j
ð36Þ
ck ¼
1
PM
j¼1 wk jpj
ð37Þ
Equations 36 and 37 can be solved by computing the pj values
using Eq. 36 with an initial guess for the ck values and by then
reﬁning these pj values using the ck values that are obtained by
inserting the pj values obtained into Eq. 37. Usually the ck and pj
values become self-consistent after a few rounds of this iterative
algorithm.
When writing scripts to do this form of analysis it is worth
noting that only ∑ktkj, which is the total number of conﬁgurations
from all the replicas that enter the jth bin, enters Eqs. 36 and 37.
There is thus no need to record which replica generated each of the
frames and one can thus simply gather the trajectories from all the
replicas together at the outset.
The fact that we can simply gather the trajectories from all our
replicas before performing the weighted histogram analysis that has
Analyzing and Biasing Simulations with PLUMED
563

been described in the previous paragraph is also evident when we
consider Eq. 36. This expression tells us that we can calculate pj by
constructing a weighted histogram from the concatenated trajec-
tory and that the weight for the nth frame will be
ew n ¼
1
P
kckwkn
ð38Þ
where the sum runs over the replicas and where wkn is the factor the
kth replica has to be reweighted in order to recover the unbiased
probability for conﬁguration n. Notice that we can also use the
concatenated trajectory when extracting values for ck using Eq. 37
as the sum over bins in the denominator can be replaced with a sum
over the concatenated trajectory. These observations are important
as they are the basis of the binless formulation of the weighted
histogram
technique
(WHAM)
that
is
implemented
within
PLUMED and that has been variously proposed by a number of
different authors [80–82] (Fig. 14).
5.2
WHAM Analysis
with PLUMED
Subheading 5 discussed simulations in which multiple replicas are
run in parallel and in which exchanges are attempted between
replicas. To run these types of calculations you need an MD code
that can manage the communication between these replicas. GRO-
MACS is able to run simulations in this way using a command line
V2
V1
V3
V2
V1
V3
B
A
C
B
A
C
B
A
C
B
A
C
a) simulation
b) analysis
B
A
C
c) weights
d) statistics
t
w
s
N
Fig. 14 Schematic representation of a WHAM analysis. (a) Multiple simulations are performed using different
bias potentials. These simulations can be done separately, but we would always recommend using a replica-
exchange procedure. (b) Trajectories are concatenated for subsequent analysis. The ﬁrst step of this analysis
is to compute the value of all the biasing potentials on all the snapshots in the concatenated trajectory. Notice
that in principle it is not necessary to concatenate the trajectory as the order of the accumulated snapshots is
irrelevant. It is critical, however, to compute all the bias potentials for all the frames in all the trajectories as
only then can you solve Eqs. 36 and 37. (c) Once these equations are solved a weight for each snapshot in the
concatenated trajectory is obtained. (d) These weights are then used to, for example, reconstruct the unbiased
probability along some a posteriori chosen CV
564
Giovanni Bussi and Gareth A. Tribello

syntax that is similar to the one shown below, which tells GRO-
MACS to run 3 replicas in parallel and to attempt coordinate
exchanges every 1000 MD steps:
> mpirun -np 3 gmx_mpi mdrun -multi 3 \
-plumed plumed.dat -replex 1000
For MD codes that can handle multiple replicas PLUMED
provides a convenient syntax for having different biases on the
various different replicas. As an example the PLUMED input
below assumes that three replicas are being run in parallel and
that these three replicas differ only in the position of the center of
the harmonic restraint:
d: DISTANCE ATOMS=10,20
RESTRAINT ARG=d AT=@replicas:1.0,1.1,1.2 KAPPA=1.0
Obviously, the centers of the harmonic restraint in the three
simulations are at 1.0, 1.1, and 1.2, respectively. The CV on which
this restraint acts and the strength of the restraint are, however, the
same in all three replicas.
Once the multiple-replica simulation has run, it must be ana-
lyzed. As discussed in Subheading 5.1 the WHAM technique pro-
vides a good method for doing this analysis. To do WHAM using
PLUMED you must ﬁrst concatenate the trajectories from the
various replicas. The exact way this will be done will depend on
the format of the trajectory ﬁle. If the format is a plain text .gro
ﬁle, ﬁle concatenation may be sufﬁcient. For other ﬁle types, how-
ever, it may be necessary to use the speciﬁc tools that are provided
by the MD engine. Regardless of these details, however, once a
single concatenated trajectory is available it can be analyzed using
PLUMED with an input ﬁle like the one shown below:
d: DISTANCE ATOMS=10,20
RESTRAINT ARG=d AT=@replicas:1.0,1.1,1.2 KAPPA=1.0
hh: WHAM_HISTOGRAM ...
ARG=d BIAS=d.bias TEMP=300
GRID_MIN=0 GRID_MAX=10 GRID_BIN=100
KERNEL=DISCRETE
...
ff: CONVERT_TO_FES GRID=hh TEMP=300
DUMPGRID GRID=ff FILE=fes.dat
The ﬁrst part of this input will be basically identical to the input
used for the biased calculations. The rest, meanwhile, uses the
functionality for reweighting that was discussed in Subheading 3.4
through the shortcut command WHAM_HISTOGRAM (see Note 12).
Analyzing and Biasing Simulations with PLUMED
565

It is important to remember that there are multiple replicas when
running the WHAM calculation using the input above as to deal
with the replicas PLUMED driver has to be called using a com-
mand like that shown below:
> mpirun -np 3 plumed driver --multi 3 \
--plumed plumed.dat
We will now see how this syntax can be used to compute the
free-energy landscape for an adenosine in water. The simulation
reported here was done using the setup and parameters described in
ref. 67. Consequently, a simulation with 16 replicas was run using
the command below:
> mpirun -np 16 gmx_mpi mdrun -multi 16 \
-plumed plumed.dat -replex 1000
with the following PLUMED input ﬁle:
MOLINFO STRUCTURE=adenosine.pdb
chi: TORSION ATOMS=@chi-1
#
# Impose an umbrella potential on chi
# with a spring constant of 80 kjoule/mol
# and centered in chi=AT
#
r: RESTRAINT ...
ARG=chi KAPPA=80.0
AT=@replicas:{
0∗pi/8
1∗pi/8
2∗pi/8
3∗pi/8
4∗pi/8
5∗pi/8
6∗pi/8
7∗pi/8
8∗pi/8
9∗pi/8
10∗pi/8 11∗pi/8
12∗pi/8 13∗pi/8
14∗pi/8 15∗pi/8
}
...
The numbers listed after the @replicas instruction are basi-
cally 16 equally spaced values between 0 and 2π. Furthermore, in
setting up this grid of restraints we have exploited the fact that
PLUMED can perform simple algebraic calculations when inter-
preting its input.
The restraints on the 16 replicas that will be simulated by
executing the command above ensure that all the possible values
for the χ glycosidic torsion of this nucleoside, including the unfa-
vorable ones that correspond to free-energy barriers, will be
explored during these simulations. Furthermore, once the simula-
tion has completed we can concatenate all the trajectories produced
by GROMACS (called traj0.xtc, traj1.xtc, . . . traj15.
566
Giovanni Bussi and Gareth A. Tribello

xtc) into a single long trajectory called traj-all.xtc. This
trajectory can then be analyzed using the following command:
> mpirun -np 16 plumed driver --multi 16 \
--plumed plumed.dat --ixtc traj-all.xtc
and a PLUMED input ﬁle that is very similar to the one described
above. Instead of writing a new ﬁle from scratch, however, it is
often more convenient to include the ﬁle that was used when the
simulation was run into the analysis ﬁle by using the command
INCLUDE. Doing so allows us to write an analysis ﬁle, called plu-
med_wham.dat, that reads as follows:
INCLUDE FILE=plumed.dat
# also compute the puckering of the sugar:
puck: PUCKERING ATOMS=@sugar-1
h1: WHAM_HISTOGRAM ...
ARG=chi BIAS=r.bias TEMP=300
GRID_MIN=-pi GRID_MAX=pi GRID_BIN=100
BANDWIDTH=0.1
...
fes1: CONVERT_TO_FES TEMP=300 GRID=h1
DUMPGRID GRID=fes1 FILE=fes1.dat
h2: WHAM_HISTOGRAM ...
ARG=chi,puck.Zx BIAS=r.bias TEMP=300
GRID_MIN=-pi,-pi GRID_MAX=pi,pi GRID_BIN=100,100
BANDWIDTH=0.1,0.1
...
fes2: CONVERT_TO_FES TEMP=300 GRID=h2
DUMPGRID GRID=fes2 FILE=fes2.dat
For RNA, it is common to analyze the conformation of the
sugar using the Zx component that is deﬁned in [35]. To calculate
this CV using PLUMED you use the puck.Zx component of the
PUCKERING command. Notice that this CV is used in the above
input because, in addition to computing the free energy as a func-
tion of the χ torsion, it also computes a second free-energy surface
that depends on both χ and the puckering conformation of the
sugar. This second variable was not biased, but it can also be
analyzed at this latter stage. The two free-energy surfaces that are
extracted when the above analysis is performed on the trajectory are
shown in Fig. 15. In addition, this ﬁgure also shows the result of
using a HISTOGRAM command without taking the weighting factors
into account.
Analyzing and Biasing Simulations with PLUMED
567

Notice that the WHAM procedure discussed here can be used
to remove any arbitrary bias that has been added to a simulation.
For instance, it can be used to analyze bias-exchange metadynamics
simulations [49], which is a method that involves using a replica-
exchange scheme where each replica experiences a metadynamics
bias on a different variable. In these types of calculations different
replicas can use different PLUMED input ﬁles. These replicas can
even use a different number of biasing potentials. For example, in
references [21, 83], a similar procedure was used to reweight bias-
exchange metadynamics simulations where, in addition to the
metadynamics potential, each replica was subject to a different
restraint. In all these cases, however, the replicas always share the
same simulation parameters. In other words, the only differences
are in the bias that is applied by PLUMED.
- /2
+ /2
0
- /2
+ /2
0
Zx
0
1/2
-1/2
F [kBT]
(a)
(b)
Fig. 15 Results from a replica-exchange umbrella sampling simulation per-
formed on adenosine in water. As explained in the text restraints are applied
on the glycosidic torsion χ in these simulations. (a) The free energy as a function
of χ computed using the WHAM equation is shown in black. This proﬁle is in
agreement with that reported in reference [67]. The free energy that one would
have obtained if one had (erroneously) collected the histogram from the replica-
exchange simulation without performing any reweighting is also shown (red
line). This proﬁle is signiﬁcantly ﬂatter because the system is forced by the
restraints to explore the entire CV span. (b) Two-dimensional proﬁle showing the
free energy as a function of the biased χ torsion and the Zx puckering variable
that reports on the sugar conformation. Even though this latter variable was not
biased, the two-dimensional proﬁle can be correctly reconstructed as transitions
between the two typical conformations are accessible on the simulation
timescale
568
Giovanni Bussi and Gareth A. Tribello

6
Perspectives
This chapter has introduced the PLUMED code, explained some of
the theory behind the methods that are implemented in this code
and given some practical examples that show how PLUMED can be
used. Space constraints mean that we cannot describe everything
that PLUMED can do, so we have instead chosen to focus on some
of the issues that come up most frequently on the code’s mailing
list. The discussion in the previous sections has thus included
information on the difﬁculties that can arise when treating periodic
boundary conditions and a discussion on the proper treatment of
statistical errors and the analysis of multiple-replica simulations. In
what follows we will ﬁnish by giving a brief perspective on how we
believe that PLUMED will evolve in the near future.
Our principal reason for developing PLUMED was to provide
functionality for performing enhanced sampling calculations. There
were two interrelated reasons for writing this as a separate piece of
software. The ﬁrst of these was that we wanted an inter-operable
implementation that could work with multiple MD codes. Differ-
ent MD codes contain different functionalities and as such the
particular engine that you will work with on any given project will
depend on the particular system under study. At the same time,
however, the efﬁcacy of any enhanced sampling method depends
strongly on the degree to which the biased CVs separate the meta-
stable basins and transition states in the energy landscape. Conse-
quently, PLUMED needed to be a large, stand-alone code not
simply because some of the biasing methods that are implemented
within it are rather sophisticated but also because it contains imple-
mentations for many of the, in some cases very-complicated, CVs
that have been used in these types of calculations. In fact, to the best
of our knowledge there is no other code that contains implementa-
tions of as many different CVs. Having said that, however, a num-
ber of recently developed CVs are not yet included and will thus be
implemented in the near future. We are particularly interested in
some of the ideas from machine learning [84–88] that are entering
this ﬁeld and are actively investigating how such methods could be
implemented within the PLUMED framework. Furthermore, we
have in the last couple of years been working with the developers of
Open Path Sampling [89] in order to help them interface their
code with PLUMED so that methods such as transition path
sampling and forward ﬂux can be performed on-the-ﬂy using a
broad range of CVs without any need to perform a posteriori
analysis.
Another issue that we need to work on in the future is the
performance of the code. As PLUMED is designed to compute and
Analyzing and Biasing Simulations with PLUMED
569

bias CVs its design is rather different from some of the other pieces
of software that are used to drive MD simulations. One big poten-
tial performance bottleneck comes about because PLUMED needs
access to a subset of the simulated atoms during every time step. This
requirement can slow down the simulations particularly when the
CVs are computed from the positions of a large number of atoms.
In the future we will thus work in order to decrease the computa-
tional cost of the operation that transfers the atomic positions from
the MD code to PLUMED. One easy way to reduce this cost,
which will be available in version 2.5, is to allow expensive CVs
that are computed within the underlying MD code to be trans-
ferred to PLUMED. Computing the CV within the MD code
would allow you take advantage of the data structures in the MD
code. Furthermore, as an added beneﬁt, one could also take advan-
tage of this feature when using CVs that are based on features that
are difﬁcult to transfer to PLUMED such as partial charges or other
functions of the electronic structure. It is still to be seen if any these
features will ﬁnd a practical application, however.
One thing that will not change a great deal in the future is
PLUMED API. The simple and well-documented interface
between PLUMED and the various MD codes that call it is one
of the code’s great strengths so any future change will be made in a
way that ensures backward compatibility. The reason this interface
is so important is that this is what allows such a large number of
MD codes to call PLUMED. In addition, some developers have
incorporated the PLUMED API within their code base so that
users can download their codes and immediately use PLUMED
without performing any sort of patching procedure. This model of
having the calls to PLUMED within the MD codes is something
that we would like to use more widely in future. Furthermore, to
facilitate this, and to keep pace with the growing popularity of
python within the molecular simulation community, we have
recently provided an interface to the PLUMED API that makes
the PLUMED routines callable from python.
The most important changes to PLUMED that we foresee,
however, will be the features contributed to the code by indepen-
dent groups. It is clear from the github pages of PLUMED that a
number of forks of the code are now being actively developed.
Furthermore, some of the features that have been developed in
these forks have been already contributed back into the main ver-
sion of the code. We are convinced that transforming this project
in a community effort will be the best way to keep it lively and
up to date. In fact, inviting contributions from the whole simula-
tion community is the only way to ensure that the code contains
the most exciting recent methodological developments from the
ﬁeld.
570
Giovanni Bussi and Gareth A. Tribello

7
Notes
1. The ﬁrst version of PLUMED was released in 2009 [1]. A
complete rewrite, that made the code easier to maintain and
extend, was published in 2014 [2]. This second version
changed the inner structure of the code and also changed the
syntax for the input ﬁle so it is this second version of the code
that will be the focus of this chapter.
2. When a reference pdb ﬁle is provided using the MOLINFO
command numerous shortcuts can be employed when calcu-
lating backbone torsional angles in proteins and nucleic acids.
For example, the input below instructs PLUMED to calculate
and print the ϕ and ψ angles in the 3rd and 9th residue of a
protein.
MOLINFO STRUCTURE=helix.pdb
phi3: TORSION ATOMS=@phi-3
psi3: TORSION ATOMS=@psi-3
phi9: TORSION ATOMS=@phi-9
psi9: TORSION ATOMS=@psi-9
PRINT ARG=phi3,psi3,phi9,psi9 FILE=colvar STRIDE=10
A number of other convenient shortcuts are explained in
the PLUMED manual.
3. If for some reason one only wishes to only disregard translation
of the center of mass, that is to say if one wishes to include any
displacements that come about because of rotation of the
reference frame, when computing the RMSD one can replace
TYPE¼OPTIMAL with TYPE¼SIMPLE. In addition, one can use
one set of atoms to calculate the roto-translation operation that
minimizes the RMSD and then use a different set of atoms to
compute the ﬁnal RMSD by adjusting the numbers that appear
in the occupancy and beta columns of the input pdb ﬁle. Using
different sets of atoms to align the molecule and compute the
RMSD displacement is commonly used when tracking the
position of a ligand in the reference frame of a protein.
4. The amount of time that the system spent in bin j can be
computed as follows:
tj ¼
X
T
i¼1
H
jsðqiÞ  sjj
w


where
HðxÞ ¼
1
if
x < 1=2
0
otherwise

ð39Þ
where w is the width of each bin.
Analyzing and Biasing Simulations with PLUMED
571

5. When we differentiate L in Eq. 19 with respect to pk we ﬁnd
that at the constrained optimum:
∂L
∂pk
¼ tk
pk
þ λ ¼ 0
!
pk ¼  tk
λ
ð40Þ
We know, however, that:
X
M
j¼1
pj ¼ 1
!
λ ¼ 
X
M
j¼1
tj
ð41Þ
If we add together the number of trajectory frames in each of
bins, however, we get the total number of trajectory frames, T.
λ is thus equal to  T and thus the most likely value of pk is
simply:
pk ¼ tk
T
ð42Þ
6. When we differentiate L in Eq. 23 with respect to pk and set its
derivatives to zero we obtain
∂L
∂pk
¼ tj
pk
þ wkλ ¼ 0
!
pk ¼  ðwkÞ1tk
λ
ð43Þ
We can then recall our constraint, namely
PM
j¼1 wjpj ¼ 1.
Notice that by enforcing this constraint we are not doing
anything to ensure that the unbiased distribution, pj, is normal-
ized. The constraint instead ensures that the biased distribution
wjpj is normalized. This is important as it is this probability
distribution that is used when we compute the total probability
of observing the trajectory. It is, in fact, not at all necessary for
the unbiased probability distribution, pj, to be normalized. In
fact, and to be clear, the unbiased distribution that emerges
when this form of analysis is performed will be unnormalized as
we will obtain λ ¼ T and hence pk ¼ ðwkÞ1tk
T
. The ﬁnal result is
thus:
pk / ðwkÞ1tk
ð44Þ
7. The STRIDE keyword takes a default value of one and tells you
how frequently a PLUMED command is executed. When it is
used in combination with the PRINT command, it thus con-
trols the frequency with which the CVs are printed. In addition,
PLUMED automatically knows that these CVs should only
ever be calculated when they are printed. The STRIDE keyword
can also be used with commands that bias CVs such as
RESTRAINT and METAD, however. In this context the com-
mand tells PLUMED that the bias, and the biased CVs, should
be computed with a frequency as part of a multiple-time step
scheme [90, 91]. By using these schemes you can speed up
572
Giovanni Bussi and Gareth A. Tribello

calculations especially when expensive CVs are used. You
should, however, only ever use moderate values for STRIDE
in this case – typically, something between 1 and 5.
8. We can measure the degree of correlation within a time series,
Xt, of random variables with expectation hXi and variance
h(δX)2i by measuring the autocorrelation function:
RðτÞ ¼ hðX t  hXiÞðX tþτ  hXiÞi
hðδXÞ2i
ð45Þ
The value of this function at τ gives a measure of the average
degree of correlation between each pair of random variables
that were measured τ time units apart. If the random variables
are all independent and identically distributed, this function
will decay to zero for all t > 0. If the autocorrelation function
is calculated for a time series of CV values taken from a trajec-
tory, the function will not decay immediately, however, as the
system will most likely not diffuse from one edge of CV space to
the other during a single time step. The CV value that we
calculate from the (i + 1)th frame of the trajectory will thus
be similar to the value obtained for the ith trajectory frame.
9. The Monte Carlo data that was used to construct the right
panel of Fig. 11 was generated by performing a metropolis
Monte Carlo simulation that sampled points from a standard
normal distribution.
10. The error bars, εj, obtained for the components of the histo-
gram, hgji, that are calculated using Eq. 31 must be propagated
in order to obtain the error on the free energy. As the free
energy is proportional to the logarithm of the probability, the
error on this quantity is kBT
εj
hgji.
11. When we differentiate L in Eq. 35 with respect to pk we ﬁnd
that at the constrained optimum:
∂L
∂pj
¼
X
N
k¼1
tk j
pj
þ
X
N
k¼1
λkckwk j ¼ 0
ð46Þ
which can be rearranged to give:
pj ¼ 
PN
k¼1 tk j
P
kλkckwk j
ð47Þ
Similarly, when we differentiate L in Eq. 35 with respect to ck
we ﬁnd that
∂L
∂ck
¼
X
M
j¼1
tk j
ck
þ
X
M
j¼1
λkwk jpj ¼ 0
ð48Þ
Analyzing and Biasing Simulations with PLUMED
573

which rearranges to give:
λk ¼ 
PM
j¼1 tk j
PM
j¼1 ckwk jpj
ð49Þ
Finally, when we differentiate L in Eq. 35 with respect to λk
we obtain the constraint:
X
M
j¼1
ckwk jpj ¼ 1
ð50Þ
The last two of these equations can be combined to give:
λk ¼ 
X
M
j¼1
tk j
ð51Þ
Notice that PM
j¼1 tk j is simply the length of trajectory k. By
assuming that all the trajectories have the same length we can
thus ensure that λk is independent of k. Inserting this result into
Eq. 47 will thus give
pj /
PN
k¼1 tk j
P
kckwk j
ð52Þ
Furthermore, rearranging Eq. 50 gives
ck ¼
1
PM
j¼1 wk jpj
ð53Þ
12. When PLUMED reads in the command WHAM_HISTOGRAM it
converts it into the input for three actions automatically. The
ﬁrst of these is a REWEIGHT_WHAM command that is similar to
the REWEIGHT_BIAS command. This command calculates a
set of weights for the input conﬁgurations that are used when
constructing weighted histograms using a HISTOGRAM com-
mand. When using WHAM there is an important difference in
computing the histogram, however. When WHAM is used the
weights can only be computed once the whole trajectory has
been processed. A special syntax and a COLLECT_FRAMES
command is thus required between the REWEIGHT_WHAM and
HISTOGRAM commands in this case. This special syntax thus
instructs the action HISTOGRAM to wait until the end of the
trajectory and to only then retrieve the weights and construct
the histogram. Notice also that Eqs. 36 and 37 are solved in the
REWEIGHT_WHAM command and that this command can thus
accept additional arguments in order to ﬁne-tune the tolerance
with which these equations are solved.
574
Giovanni Bussi and Gareth A. Tribello

Acknowledgements
Writing and maintaining PLUMED involves a considerable
amount of effort and we thus would like to ﬁnish by acknowledging
everyone who has contributed to PLUMED in some way over the
years. PLUMED 2 was developed by a team of ﬁve core developers
that include the authors, Massimiliano Bonomi, Davide Bran-
duardi, and Carlo Camilloni. Furthermore, Haochuan Chen, Hao-
hao Fu, Glen Hocky, Omar Valsson, and Andrew White have all
contributed modules to the code, whereas several other users have
contributed other minor functionalities or ﬁxed bugs in the code.
Lastly, we would like to acknowledge the many users and devel-
opers who have emailed our user and developer lists or attended the
various PLUMED tutorials and user meetings. The contributions
of these people have been invaluable in terms of alerting us to bugs
in the code.
References
1. Bonomi
M,
Branduardi
D,
Bussi
G,
Camilloni
C,
Provasi
D,
Raiteri
P,
Donadio D, Marinelli F, Pietrucci F, Broglia
RA et al (2009) PLUMED: a portable plugin
for free-energy calculations with molecular
dynamics.
Comput
Phys
Commun
180
(10):1961
2. Tribello
GA,
Bonomi
M,
Branduardi
D,
Camilloni C, Bussi G (2014) PLUMED 2:
new feathers for an old bird. Comput Phys
Commun 185(2):604
3. Abraham MJ, Murtola T, Schulz R, Pa´ll S,
Smith JC, Hess B, Lindahl E (2015) GRO-
MACS: high performance molecular simula-
tions through multi-level parallelism from
laptops to supercomputers. SoftwareX 1:19
4. Plimpton S (1995) Fast parallel algorithms for
short-range molecular dynamics. J Comput
Phys 117(1):1
5. Todorov IT, Smith W, Trachenko K, Dove MT
(2006)
DL_POLY_3:
new
dimensions
in
molecular dynamics simulations via massive
parallelism. J Mater Chem 16(20):1911
6. Hutter J, Iannuzzi M, Schiffmann F, Vande-
Vondele J (2014) CP2K: atomistic simulations
of condensed matter systems. Wiley Interdiscip
Rev Comput Mol Sci 4(1):15
7. Case D, Betz R, Cerutti D, Cheatham T III,
Darden T, Duke R, Giese T, H. Gohlke AG,
Homeyer N, Izadi S, Janowski P, Kaus J,
Kovalenko A, Lee T, LeGrand S, Li P, Lin C,
Luchko T, Luo R, Madej B, Mermelstein D,
Merz K, Monard G, Nguyen H, Nguyen H,
Omelyan I, Onufriev A, Roe D, Roitberg A,
Sagui C, Simmerling C, Botello-Smith W,
Swails JM, Walker RC, Wang J, Wolf R,
Wu X, Xiao L, Kollman P (2016) AMBER
2016. University of California, San Francisco
8. Eastman P, Swails J, Chodera JD, McGibbon
RT, Zhao Y, Beauchamp KA, Wang LP, Sim-
monett AC, Harrigan MP, Stern CD et al
(2017) OpenMM 7: rapid development of
high performance algorithms for molecular
dynamics.
PLOS
Comput
Biol
13(7):
e1005659
9. Fiorin G, Klein ML, He´nin J (2013) Using
collective variables to drive molecular dynamics
simulations. Mol Phys 111(22–23):3345
10. Sidky H, Colo´n YJ, Helfferich J, Sikora BJ,
Bezik C, Chu W, Giberti F, Guo AZ, Jiang X,
Lequieu J et al (2018) SSAGES: software suite
for advanced general ensemble simulations. J
Chem Phys 148(4):044104
11. Gil-Ley A, Bussi G (2015) Enhanced confor-
mational sampling using replica exchange with
collective-variable tempering. J Chem Theory
Comput 11(3):1077
12. Best RB, Hummer G, Eaton WA (2013) Native
contacts determine protein folding mechan-
isms in atomistic simulations. Proc Natl Acad
Sci U S A 110(44):17874
13. Camilloni C, Vendruscolo M (2014) Statistical
mechanics of the denatured state of a protein
using replica-averaged metadynamics. J Am
Chem Soc 136(25):8982
14. Zhang Y, Voth GA (2011) Combined metady-
namics and umbrella sampling method for the
Analyzing and Biasing Simulations with PLUMED
575

calculation of ion permeation free energy pro-
ﬁles. J Chem Theory Comput 7(7):2277
15. De Meyer T, Ensing B, Rogge SM, De
Clerck
K, Meijer
EJ,
Van
Speybroeck
V
(2016) Acidity constant (pKa) calculation of
large solvated dye molecules: evaluation of
two advanced molecular dynamics methods.
ChemPhysChem 17(21):3447
16. Cheng B, Tribello GA, Ceriotti M (2015)
Solid-liquid interfacial free energy out of equi-
librium. Phys Rev B 92(18):180102
17. Tribello
GA,
Giberti
F,
Sosso
GC,
Salvalaglio M, Parrinello M (2017) Analyzing
and driving cluster formation in atomistic
simulations. J Chem Theory Comput 13
(3):1317
18. Peters B (2016) Reaction coordinates and
mechanistic hypothesis tests. Annu Rev Phys
Chem 67:669
19. Kabsch W (1976) A solution for the best rota-
tion to relate two sets of vectors. Acta Crystal-
logr A 32(5):922
20. Vymetal J, Vondrasek J (2011) Gyration-and
inertia-tensor-based collective coordinates for
metadynamics. application on the conforma-
tional behavior of polyalanine peptides and
trp-cage
folding.
J
Phys
Chem
A
115
(41):11455
21. Cunha RA, Bussi G (2017) Unraveling Mg2
+–RNA
binding
with
atomistic
molecular
dynamics. RNA 23(5):628
22. Pietrucci F, Laio A (2009) A collective variable
for the efﬁcient exploration of protein beta-
sheet structures: application to SH3 and GB1.
J Chem Theory Comput 5(9):2197
23. Bartels C, Karplus M (1998), Probability dis-
tributions
for
complex
systems:
adaptive
umbrella sampling of the potential energy. J
Phys Chem B 102(5):865
24. Bonomi M, Parrinello M (2010) Enhanced
sampling in the well-tempered ensemble. Phys
Rev Lett 104(19):190601
25. Lazaridis T, Karplus M (1999) Effective energy
function for proteins in solution. Proteins 35
(2):133
26. Do TN, Carloni P, Varani G, Bussi G (2013)
RNA/peptide binding driven by electrostatics
– insight from bidirectional pulling simula-
tions. J Chem Theory Comput 9(3):1720
27. Nava M, Palazzesi F, Perego C, Parrinello M
(2017) Dimer metadynamics. J Chem Theory
Comput 13(2):425
28. Bottaro S, Banas P, Sponer J, Bussi G (2016)
Free energy landscape of GAGA and UUCG
RNA tetraloops. J Phys Chem Lett 7(20):4032
29. Spiwok V, Lipovova´ P, Kra´lova´ B (2007) Meta-
dynamics in essential coordinates: free energy
simulation of conformational changes. J Phys
Chem B 111(12):3073
30. Sutto L, D’Abramo M, Gervasio FL (2010)
Comparing the efﬁciency of biased and unbi-
ased molecular dynamics in reconstructing the
free energy landscape of met-enkephalin. J
Chem Theory Comput 6(12):3640
31. Branduardi D, Gervasio FL, Parrinello M
(2007) From A to B in free energy space. J
Chem Phys 126(5):054103
32. Leines GD, Ensing B (2012) Path ﬁnding on
high-dimensional free energy landscapes. Phys
Rev Lett 109(2):020601
33. Spiwok V, Kra´lova´ B (2011) Metadynamics in
the conformational space nonlinearly dimen-
sionally reduced by isomap. J Chem Phys 135
(22):224504
34. Cremer Dt, Pople J (1975), General deﬁnition
of ring puckering coordinates. J Am Chem Soc
97(6):1354
35. Huang M, Giese TJ, Lee TS, York DM (2014)
Improvement of DNA and RNA sugar pucker
proﬁles from semiempirical quantum methods.
J Chem Theory Comput 10(4):1538
36. Bonomi M, Camilloni C (2017) Integrative
structural
and
dynamical
biology
with
PLUMED-ISDB. Bioinformatics 33(24):3999
37. Jolliffe I (2002) Principal component analysis.
Springer, New York
38. Borg I, Groenen PJF (2005) Modern multidi-
mensional scaling: theory and applications.
Springer, New York
39. Ceriotti M, Tribello GA, Parrinello M (2011)
Simplifying the representation of complex free-
energy landscapes using sketch-map. Proc Natl
Acad Sci USA 108(32):13023
40. Giorgino T (2014) PLUMED-GUI: an envi-
ronment for the interactive development of
molecular dynamics analysis and biasing scripts.
Comput Phys Commun 185(3):1109
41. Humphrey W, Dalke A, Schulten K (1996)
VMD:
visual
molecular
dynamics.
J
Mol
Graph 14(1):33
42. Torrie GM, Valleau JP (1977) Nonphysical
sampling distributions in Monte Carlo free-
energy estimation: umbrella sampling. J Com-
put Phys 23(2):187
43. Kumar S, Rosenberg JM, Bouzida D, Swend-
sen RH, Kollman PA (1992) The weighted
histogram analysis method for free-energy cal-
culations on biomolecules. I. The method. J
Comput Chem 13(8):1011
576
Giovanni Bussi and Gareth A. Tribello

44. Isralewitz B, Izrailev S, Schulten K (1997)
Binding pathway of retinal to bacterio-opsin:
a prediction by molecular dynamics simula-
tions. Biophys J 73(6):2972
45. Laio A, Parrinello M (2002) Escaping free-
energy minima. Proc Natl Acad Sci USA 99
(20):12562
46. Iannuzzi M, Laio A, Parrinello M (2003) Efﬁ-
cient exploration of reactive potential energy
surfaces
using
Car-Parrinello
molecular
dynamics. Phys Rev Lett 90(23):238302
47. Raiteri P, Laio A, Gervasio FL, Micheletti C,
Parrinello M (2006). Efﬁcient reconstruction
of complex free energy landscapes by multiple
walkers metadynamics. J Phys Chem B 110
(8):3533
48. Bussi G, Gervasio FL, Laio A, Parrinello M
(2006) Free-energy landscape for β hairpin
folding from combined parallel tempering and
metadynamics.
J
Am
Chem
Soc
128
(41):13435
49. Piana S, Laio A (2007) A bias-exchange
approach to protein folding. J Phys Chem B
111(17):4553
50. Barducci A, Bussi G, Parrinello M (2008) Well-
tempered metadynamics: a smoothly converg-
ing and tunable free-energy method. Phys Rev
Lett 100(2):020603
51. Branduardi D, Bussi G, Parrinello M (2012)
Metadynamics
with
adaptive
Gaussians.
J
Chem Theory Comput 8(7):2247
52. Dama JF, Parrinello M, Voth GA (2014) Well-
tempered metadynamics converges asymptoti-
cally. Phys Rev Lett 112(24):240602
53. Dama JF, Rotskoff G, Parrinello M, Voth GA
(2014)
Transition-tempered
metadynamics:
robust, convergent metadynamics via on-the-
ﬂy transition barrier estimation. J Chem The-
ory Comput 10(9):3626
54. Pfaendtner J, Bonomi M (2015) Efﬁcient sam-
pling of high-dimensional free-energy land-
scapes
with
parallel
bias metadynamics.
J
Chem Theory Comput 11(11):5062
55. Hosek P, Toulcova D, Bortolato A, Spiwok V
(2016) Altruistic metadynamics: multisystem
biased simulation. J Phys Chem B 120(9):2209
56. Baftizadeh F, Cossio P, Pietrucci F, Laio A
(2012) Protein folding and ligand-enzyme
binding
from
bias-exchange
metadynamics
simulations. Curr Phys Chem 2(1):79
57. Tiwary P, Parrinello M (2013) From metady-
namics to dynamics. Phys Rev Lett 111
(23):230602
58. Maragliano L, Vanden-Eijnden E (2006) A
temperature accelerated method for sampling
free energy and determining reaction pathways
in rare events simulations. Chem Phys Lett
426:168
59. Abrams JB, Tuckerman ME (2008) Efﬁcient
and direct generation of multidimensional free
energy surfaces via adiabatic dynamics without
coordinate transformations. J Phys Chem B
112(49):15742
60. Lelie`vre T, Rousset M, Stoltz G (2007) Com-
putation of free energy proﬁles with parallel
adaptive
dynamics.
J
Chem
Phys
126
(13):134111
61. Zheng L, Yang W (2012) Practically efﬁcient
and robust free energy calculations: double-
integration orthogonal space tempering. J
Chem Theory Comput 8(3):810
62. Fu H, Shao X, Chipot C, Cai W (2016)
Extended adaptive biasing force algorithm. An
on-the-ﬂy implementation for accurate free-
energy calculations. J Chem Theory Comput
12(8):3506
63. Valsson O, Parrinello M (2014) Variational
approach
to
enhanced
sampling
and
free
energy
calculations.
Phys
Rev
Lett
113
(9):090601
64. Valsson O, Parrinello M (2015) Well-tempered
variational approach to enhanced sampling. J
Chem Theory Comput 11(5):1996
65. White AD, Voth GA (2014) An efﬁcient and
minimal method to bias molecular simulations
with experimental data. J Chem Theory Com-
put 10:3023
66. Hocky GM, Dannenhoffer-Lafage T, Voth GA
(2017) Coarse-grained directed simulation. J
Chem Theory Comput 13(9):4593
67. Cesari A, Gil-Ley A, Bussi G (2016) Combin-
ing simulations and solution experiments as a
paradigm for RNA force ﬁeld reﬁnement. J
Chem Theory Comput 12(12):6192
68. White AD, Dama JF, Voth GA (2015) Design-
ing free energy surfaces that match experimen-
tal data with metadynamics. J Chem Theory
Comput 11(6):2451
69. Marinelli
F,
Faraldo-Go´mez
JD
(2015)
Ensemble-biased metadynamics: a molecular
simulation method to sample experimental dis-
tributions. Biophys J 108(12):2779
70. Gil-Ley A, Bottaro S, Bussi G (2016) Empirical
corrections to the amber RNA force ﬁeld with
target metadynamics. J Chem Theory Comput
12(6):2790
71. Bonomi M, Camilloni C, Cavalli A, Vendrus-
colo M (2016) Metainference: a Bayesian infer-
ence method for heterogeneous systems. Sci
Adv 2(1):e1501177
Analyzing and Biasing Simulations with PLUMED
577

72. Jarzynski C (1997) Nonequilibrium equality
for free energy differences. Phys Rev Lett 78
(14):2690
73. Bonomi M, Barducci A, Parrinello M (2009)
Reconstructing the equilibrium Boltzmann
distribution
from
well-tempered
metady-
namics. J Comput Chem 30(11):1615
74. Tiwary
P,
Parrinello
M
(2014)
A
time-
independent free energy estimator for metady-
namics. J Phys Chem B 119(3):736
75. Flyvbjerg H, Petersen H (1989) Error esti-
mates on averages of correlated data. J Chem
Phys 91(1):461
76. Sugita Y, Okamoto Y (1999) Replica-exchange
molecular dynamics method for protein fold-
ing. Chem Phys Lett 314(1):141
77. Murata K, Sugita Y, Okamoto Y (2004) Free
energy calculations for DNA base stacking by
replica-exchange umbrella sampling. Chem
Phys Lett 385(1):1
78. Curuksu J, Zacharias M (2009) Enhanced con-
formational sampling of nucleic acids by a new
Hamiltonian
replica
exchange
molecular
dynamics
approach.
J
Chem
Phys
130
(10):03B610
79. Bartels C (2000) Analyzing biased Monte
Carlo and molecular dynamics simulations.
Chem Phys Lett 331(5–6):446
80. Souaille M, Roux B (2001) Extension to the
weighted histogram analysis method: combin-
ing umbrella sampling with free energy calcula-
tions. Comput Phys Commun 135(1):40
81. Shirts MR, Chodera JD (2008) Statistically
optimal analysis of samples from multiple equi-
librium states. J Chem Phys 129(12):124105
82. Tan Z, Gallicchio E, Lapelosa M, Levy RM
(2012) Theory of binless multi-state free
energy
estimation
with
applications
to
protein-ligand binding. J Chem Phys 136
(14):04B608
83. Mly´nsky´ V, Bussi G et al (2018) Molecular
dynamics
simulations
reveal
an
interplay
between SHAPE reagent binding and RNA
ﬂexibility. J Phys Chem Lett 9:313
84. Gasparotto P, Ceriotti M (2014) Recognizing
molecular patterns by machine learning: an
agnostic structural deﬁnition of the hydrogen
bond. J Chem Phys 141(17):174110
85. Tribello GA, Ceriotti M, Parrinello M (2012)
Using sketch-map coordinates to analyze and
bias molecular dynamics simulations. Proc Natl
Acad Sci USA 109(14):5196
86. M.
Sultan
M,
Pande
VS
(2017)
TICA-
metadynamics: accelerating metadynamics by
using kinetically selected collective variables. J
Chem Theory Comput 13(6):2440
87. Chen W, Ferguson AL (2018) Molecular
enhanced sampling with autoencoders: On-
the-ﬂy collective variable discovery and acceler-
ated free energy landscape exploration. J Com-
put Chem 39(25):2079
88. Sultan MM, Wayment-Steele HK, Pande VS
(2018)
Transferable
neural
networks
for
enhanced sampling of protein dynamics. J
Chem Theory Comput 14(4):1887
89. Open
path
sampling.
http://
openpathsampling.org/latest
90. Tuckerman M, Berne BJ, Martyna GJ (1992)
Reversible
multiple
time
scale
molecular
dynamics. J Chem Phys 97(3):1990
91. Ferrarotti MJ, Bottaro S, Pe´rez-Villa A, Bussi G
(2014) Accurate multiple time step in biased
molecular simulations. J Chem Theory Com-
put 11(1):139
578
Giovanni Bussi and Gareth A. Tribello

INDEX
A
AMBER ............................................................... 6–13, 28,
33, 56, 57, 63, 66, 130, 163, 418, 426–428, 504,
529
Amber force ﬁeld ............................................7, 8, 10, 22,
25, 26, 33, 55–71, 189
B
Bayes ..............................................................................327
Bayesian data modeling ................................................315
Binding kinetics.............................................................245
Bio3D ......................................................... 423, 504, 507,
513–516, 523
Biomolecular simulations ................................... 155–174,
179, 180, 184, 189–191, 291–308
Biomolecular systems...........................24, 35, 56, 75, 80,
130, 131, 162, 185, 191, 192, 438
Biomolecules ........................................3, 33, 34, 57, 105,
135, 145, 166, 171, 180, 187, 188, 190, 191,
214, 283, 341, 358, 361, 401–403, 415, 432,
446, 453–456, 471, 474, 492, 532
Biophysical data.............................................................361
C
CADD, see Computer-aided drug design
CHARMM, see Chemistry at Harvard Molecular
Mechanics
Chemistry at Harvard Molecular Mechanics
(CHARMM)................................... 6, 7, 9–13, 22,
25–27, 30, 32, 33, 36, 43, 56, 90, 94, 95, 99, 119,
130, 163, 189, 320, 335, 346, 373, 418,
426–428, 432, 433, 437–439, 443, 524
Chromosome structure.................................................401
Cloud computing................................................. 291, 292
Coarse grained models............................... 3, 4, 107, 346,
373, 401, 402, 404–408, 439, 504
Collective variables..................................... 161, 180–182,
235–239, 242, 243, 245, 247, 248, 255–287,
446, 490, 492, 493, 497, 532–551, 554
Computer-aided drug design (CADD) ...........21, 23, 42,
43, 203, 224
Conformational change .........................10, 92, 134, 138,
156, 192, 221, 225, 226, 238, 255, 265, 266,
278, 416, 437, 439, 443, 446, 532
Conformational dynamics .............................................. 39
Conformational ensembles.......................... 92, 162, 415,
416, 423
D
Data analysis ......................................................... 202, 203
Dimensionality reduction .......................... 421, 424, 427,
459, 462, 463, 469–483, 487, 489, 493
Direct-coupling analysis...............................380–383, 386
Discrete path sampling (DPS)..................................56, 67
DNA ........................................................... 12, 34, 40, 55,
57, 60–64, 70, 76, 109–119, 122, 243, 245, 257,
264–267, 269, 275, 278, 283, 399–401, 403,
404, 408, 409, 446, 453
Drude oscillator model................................27–33, 37, 43
Drug discovery...............................................................22,
202, 203, 206–208, 210–216, 219, 225, 226,
233, 246
E
Enhanced sampling.............................................4, 15, 16,
92, 107, 156, 157, 160, 162, 163, 181, 182, 190,
191, 203, 207, 224, 226, 246, 255–257, 259,
260, 266, 280, 283, 416, 446–447, 456, 458,
463, 469, 493–497, 530, 531, 554–556, 569
Ensemble determination...............................................314
Ensemble reﬁnement ........................................... 341–349
Enzyme catalysis........................................................56, 75
F
FEP+ ..................................................................... 201–228
Free energy ........................................................16, 34, 35,
56, 67–69, 75, 76, 79–81, 92, 93, 96–98, 100,
121, 123, 134, 135, 155, 157, 161, 167–169,
172, 173, 181–185, 187, 193, 202–206, 208,
210, 214–216, 218, 219, 221, 224–226, 236,
240, 241, 243–246, 255–287, 318, 319, 456,
487, 489–492, 532, 534–537, 551–556, 558,
560–562, 566–568, 573
Free energy landscape .....................................68, 69, 155,
156, 167, 172, 194, 256, 263, 286, 446, 490,
492, 533–537, 552, 555, 566
Free energy perturbation (FEP)........................... 92, 156,
201–228
Massimiliano Bonomi and Carlo Camilloni (eds.), Biomolecular Simulations: Methods and Protocols, Methods in Molecular Biology,
vol. 2022, https://doi.org/10.1007/978-1-4939-9608-7, © Springer Science+Business Media, LLC, part of Springer Nature 2019
579

G
Go¯-model ......................................................................130
Graph theory .................................................................433
GROMOS ...........................................6, 8, 9, 22, 56, 107
H
High-order statistics ............................................ 438–443
Hoogsteen base-pairing................................................257
HTMD ..............................504, 514, 516, 519, 521, 523
I
Integrative modeling............................................ 353–375
L
Large-scale simulation ........................................... 13, 294
Ligand binding.......................................33, 34, 138, 161,
187, 203, 207, 218, 219, 221, 226, 233–249
M
Martini force ﬁeld ................................................ 105–124
Maximum entropy .............................341–349, 402–403,
405, 406, 555
MDAnalysis ......................424, 504, 514, 516, 518, 519,
523, 524
MDTraj.......................................504, 514, 516, 519, 523
Membrane proteins................................ 12–13, 121, 122,
244, 380, 384, 514, 524
Metadynamics................................ 56, 92, 156, 179–195,
233–249, 256, 257, 259, 260, 267, 272–274,
278, 279, 283–286, 318, 335, 446, 447,
492–495, 497, 530, 537, 553–556, 560, 568
Metainference......................................188, 313–338, 555
Molecular dynamics (MD) .......................... 85, 107, 233,
234, 246, 292, 293, 296, 301, 373, 416, 454,
456, 458, 462, 469, 496, 497, 503, 513–514,
529, 533, 548, 550, 561
Molecular dynamics (MD) simulations .............4, 11, 21,
22, 43, 56, 59, 65, 66, 79, 80, 90–92, 94, 95, 97,
100, 105, 111, 120, 129, 162, 164, 165, 187,
190–193, 202, 225, 227, 255, 257, 266, 270,
272, 304, 313, 317–319, 345, 347, 384,
416–419, 421, 422, 428, 431, 432, 439, 443,
447, 453–456, 458, 487, 504, 532, 533, 535,
537, 540, 551, 553, 561, 570
O
OPLS3 ......................................................8, 22, 203, 207,
223–226, 228
Optimized potentials for liquid simulations
(OPLS)............................................ 6, 8, 9, 22, 28,
207, 296, 418, 427, 429
Oxidoreductase ............................................................... 77
P
Path collective variable........................................237, 238,
243, 245, 247, 248, 255–287, 549
Path sampling................................. 56, 67, 256, 292, 569
Photobiology................................................................... 76
PLUMED...........................................184, 188–191, 193,
235, 257, 263–265, 269–271, 273, 279–281,
285–287, 319, 321–325, 327, 329, 330, 332,
333, 336, 337, 447, 504, 505, 529–574
Polarized force ﬁeld .....................................24, 27–43, 88
Potential of mean force................................................... 57
Principle of maximum entropy...........................381, 402,
403, 405, 406
Protein(s)
complexes .................... 315, 343, 345, 380, 385, 400
folding..................10–13, 16, 24, 130, 147, 148, 541
Protein-ligand binding ..........24, 88, 120, 187, 201–228
Proton transfer ............................................ 85, 90, 96, 97
Q
QM cluster models ...................... 77–79, 94–96, 99, 100
Quantum biochemistry...........................................75–100
R
Replica exchange........................................ 155–173, 207,
227, 236, 357, 361, 368, 427, 561
Replica-exchange umbrella sampling (REUS) ...........156,
159, 161, 171, 568
Replica-exchange with solute tempering (REST)......156,
158–162, 164–167, 169–173, 202, 203, 207,
225, 228
Residue contact prediction.................................. 380, 394
REST, see Replica-exchange with solute tempering
REST2 ........................................160, 161, 203, 207, 226
Reweighting approaches.................................13, 93, 167,
172, 183, 195, 239–242, 318, 345, 347, 383,
387, 391, 409, 456, 457, 550–551, 565, 568
Ribonucleic acid (RNA)
mononucleoside ........................................................ 70
repeat expansion........................................... 57, 66–69
S
SBM, see Structure-based model
Scripted languages....................................... 504, 505, 523
580 BIOMOLECULAR SIMULATIONS: METHODS AND PROTOCOLS
Index

Single-stranded RNA tetramer................................57–60,
62–66, 70
Sketch-map................................................. 186, 475, 476,
478–482, 487–495, 549
SMOG ..........................................................129–149, 384
Structural bioinformatics............................ 379, 383, 384
Structural modeling .................................... 315, 346, 354
Structure-based model (SBM) ..........129–132, 134, 135,
138–148, 384, 385
T
Trajectory analysis ........................................162, 503–525
Transferable model....................................................3–5, 9
U
Umbrella sampling..................................... 56, 68, 69, 96,
98, 156, 161, 181, 256, 257, 260, 265, 266,
278–281, 283, 318, 530
Unfolding state .............................. 10, 34, 122, 187, 190
V
Visual molecular dynamics (VMD)...................... 94, 110,
114–118, 134, 147, 162, 319, 320, 504, 505,
511, 513, 516, 518, 519, 523, 525, 549
W
Weighted histogram analysis method (WHAM)..........94,
96, 167, 182, 257, 266, 279, 280, 283, 344, 346,
347, 563–568, 574
BIOMOLECULAR SIMULATIONS: METHODS AND PROTOCOLS
Index 581

