Nature  |  Vol 630  |  6 June 2024  |  123
Article
Companies inadvertently fund online 
misinformation despite consumer backlash
Wajeeha Ahmad1 ✉, Ananya Sen2, Charles Eesley1 & Erik Brynjolfsson3
The financial motivation to earn advertising revenue has been widely conjectured to 
be pivotal for the production of online misinformation1–4. Research aimed at 
mitigating misinformation has so far focused on interventions at the user level5–8, with 
little emphasis on how the supply of misinformation can itself be countered. Here we 
show how online misinformation is largely financed by advertising, examine how 
financing misinformation affects the companies involved, and outline interventions 
for reducing the financing of misinformation. First, we find that advertising on 
websites that publish misinformation is pervasive for companies across several 
industries and is amplified by digital advertising platforms that algorithmically 
distribute advertising across the web. Using an information-provision experiment9, 
we find that companies that advertise on websites that publish misinformation can 
face substantial backlash from their consumers. To examine why misinformation 
continues to be monetized despite the potential backlash for the advertisers involved, 
we survey decision-makers at companies. We find that most decision-makers are 
unaware that their companies’ advertising appears on misinformation websites but 
have a strong preference to avoid doing so. Moreover, those who are unaware and 
uncertain about their company’s role in financing misinformation increase their 
demand for a platform-based solution to reduce monetizing misinformation when 
informed about how platforms amplify advertising placement on misinformation 
websites. We identify low-cost, scalable information-based interventions to reduce 
the financial incentive to misinform and counter the supply of misinformation online.
The prevalence of online misinformation can have important social 
consequences, such as contributing to greater fatalities during the 
COVID-19 pandemic10, exacerbating the climate crisis11, and sowing 
political discord12. Yet the supply of misinformation is often finan-
cially motivated. The economic incentive to produce misinforma-
tion has been widely conjectured by academics and practitioners 
to be one of the main reasons websites that publish misinformation 
(hereafter referred to as ‘misinformation websites’ or ‘misinforma-
tion outlets’), masquerading as legitimate news outlets, continue to 
be prevalent online1–4. During the 2016 US Presidential election, one 
operator of a misinformation outlet openly stated “For me, this is all 
about income”13.
Media reports have anecdotally observed that companies and digital 
platforms contribute towards financially sustaining misinformation 
outlets via advertising14,15. Advertising companies can either place their 
advertisements directly on specific websites or use digital advertis-
ing platforms to distribute their advertisements across the internet 
(Methods, ‘Background on digital advertising’). The vast majority of 
online display advertising today is done via digital advertising plat-
forms that automatically distribute advertisements across millions 
of websites16, which may include misinformation outlets. According 
to a recent industry estimate, for every US$2.16 in digital advertising 
revenue sent to legitimate newspapers, US advertisers send US$1 to 
misinformation sites17.
Existing work to counter the proliferation of misinformation online 
has primarily focused on empowering news consumers3,5 in order to 
reduce the demand for misinformation through interventions such 
as fact-checking news articles6, providing crowd-sourced labels8 
and nudging users to share more accurate content7. However, a vital  
question remains regarding how the incentive to produce or supply 
misinformation may be countered. Indeed, recently, academics have 
proposed ‘supply-side’ policies for steering platforms away from the 
revenue models that might contribute towards sustaining harmful 
content18. Digital platforms have also attempted to decrease adver-
tising revenue going to some misinformation websites19. However, 
despite these attempts, advertising from well-known companies and 
organizations continues to appear on misinformation websites, thereby 
financing such outlets20,21. Moreover, the supply of misinformation is 
expected to increase with generative AI technologies making it easier 
to create large volumes of content to earn advertising revenue22,23.
In this Article, we attempt to provide a first step in understanding 
how to limit the financing of online misinformation via advertising 
using descriptive and experimental evidence. To tackle the problem 
of financing online misinformation, it is important to first understand 
https://doi.org/10.1038/s41586-024-07404-1
Received: 7 July 2023
Accepted: 9 April 2024
Published online: 5 June 2024
Open access
 Check for updates
1Department of Management Science and Engineering, Stanford University, Stanford, CA, USA. 2Heinz College of Information Systems and Public Policy, Carnegie Mellon University, Pittsburgh, 
PA, USA. 3Institute for Human-Centered Artificial Intelligence, Stanford University, Stanford, CA, USA. ✉e-mail: wajeehaa@stanford.edu

124  |  Nature  |  Vol 630  |  6 June 2024
Article
the role of different entities within this ecosystem. In particular, we 
need to establish whether companies directly place advertisements on 
misinformation outlets or do so by automating such placement through 
digital advertising platforms. Although several mainstream digital 
platforms generate the vast majority of their revenue via advertising3, 
little is understood about the role of advertising-driven platforms in 
financing misinformation. To evaluate the relative roles of advertising 
companies and digital advertising platforms in monetizing misinfor-
mation, we construct unique large-scale datasets by combining data 
on websites publishing misinformation with advertising activity per 
website over a period of three years.
Next, the extent to which companies can be dissuaded from adver-
tising on misinformation websites depends on how their customers 
respond to information about the prevalence of companies’ advertising 
on such websites. As people find out about companies advertising on 
misinformation websites through news and social media reports20,24, 
they may reduce their demand for such companies or voice concerns 
against such practices online25,26. Therefore, it is important to measure 
the preferences of the people who consume a company’s products or 
services regardless of whether these consumers visit misinformation 
websites themselves. To measure these effects, we conducted a survey 
experiment with a sample of the US population by randomly varying the 
pieces of factual information we provided to participants. By simultane-
ously measuring how people shift their consumption and the types of 
actors (that is, advertisers or digital advertising platforms) that they 
voice concerns about, we capture how peoples’ reactions change as the 
degree to which advertisers and advertising platforms are held respon-
sible varies. We also study how consumer responses may vary depend-
ing on the intensity of a company’s advertising on misinformation  
websites by providing company rankings on this dimension.
Finally, whether decision-makers within companies are aware of 
their company’s advertisements appearing on misinformation out-
lets and prefer to avoid doing so can have an important role in curb-
ing the financing of misinformation. In recent years, advertisers have 
often participated in boycotts of advertising-driven platforms such 
as YouTube, Facebook and Twitter for placing their advertisements 
next to problematic content27,28. However, there is little systematic 
measurement of the knowledge and preferences of key decision-makers 
within companies in this context. To address this gap, we surveyed 
executives and managers by contacting the alumni of executive educa-
tion programmes. Moreover, we conducted an information-provision 
experiment to examine whether decision-makers would increase their 
demand for a platform-based solution to avoid advertising on misin-
formation outlets when informed about the role of digital advertising 
platforms in monetizing misinformation.
We report three sets of findings from our descriptive and experi-
mental analyses. First, our descriptive analysis suggests that misin-
formation websites are primarily monetized via advertising revenue, 
with a substantial proportion of companies across several industries 
appearing on such websites. We further show that the use of digital 
advertising platforms amplifies the financing of misinformation. 
Second, we find that people switch consumption away from compa-
nies whose advertising appears on misinformation outlets, reducing 
the demand for such companies. This switching effect persists even 
when consumers are informed about the role of digital advertising 
platforms in placing companies’ advertisements on misinformation 
websites and the role of other advertising companies in financing mis-
information. Third, our survey of decision-makers suggests that most 
of them are ill-informed about the roles of their own company and the 
digital advertising platforms that they use in financing misinformation 
outlets. However, decision-makers report a high demand for informa-
tion on whether their advertisements appeared on misinformation 
outlets and solutions to avoid doing so. Those who were uncertain 
and unaware about where their advertising appeared also increased 
their demand for a platform-based solution to reduce advertising 
on misinformation websites upon learning how platforms amplify 
advertising on such websites.
In sum, our results indicate that there is room to decrease the financ-
ing of misinformation using two low-cost, scalable interventions. First, 
improving transparency for advertisers about where their advertise-
ments appear could by itself reduce advertising on misinformation 
websites, especially among companies who were previously unaware 
of their advertisements appearing on such outlets and were thus inad-
vertently financing misinformation. Second, although it is currently 
possible for consumers to find out about advertising companies 
financing misinformation through news and social media, platforms 
could make advertising on misinformation outlets more easily and 
continuously traceable to the advertising companies involved for con-
sumers. Our results suggest that both simple information disclosures 
and comparative company rankings can reduce consumer demand 
away from companies advertising on misinformation websites.
We build on prior work analysing the ecosystem supporting misin-
formation websites29–33 and programmatic advertising34 by matching 
millions of instances of advertising companies appearing across thou-
sands of news outlets with data on misinformation websites, thereby 
providing large-scale evidence of the ecosystem that sustains online 
misinformation over a consistent period of three years. Additionally, 
we present descriptive evidence about the relative roles of advertising 
companies and digital advertising platforms in financing misinforma-
tion. Next, our information-provision experiments examine the effects 
of advertising on misinformation websites for companies and plat-
forms. Previous work has examined the conditions under which people 
react against companies for failing to operate up to their expectations— 
for example, due to service quality deterioration26, not fulfilling social 
responsibilities35, advertising next to violent content36, or taking a 
political stance37,38. Our research design contributes to this literature 
in two key ways by: (1) measuring both types of potential consumer 
responses—that is, ‘exit’ and ‘voice’—that are theorized in the lit-
erature25; and (2) doing so using incentive-compatible behavioural 
outcomes at the individual level, which enables us to capture costly 
decisions people make and move beyond stated preferences recorded 
in related experimental research36,39. More broadly, our research sug-
gests an alternative approach to countering misinformation online by 
suggesting how the monetization of misinformation could be curbed 
using information interventions. Our study complements and extends 
prior work on using disclosures40,41 and interventions to counter mis-
information5,7 by showing that disclosures about companies advertis-
ing on misinformation outlets can shift consumption away from such 
companies, ultimately incentivizing companies to reduce the financing 
of misinformation via advertising.
Collection of website and advertising data
To categorize whether a website contains misinformation, we com-
piled a list of misinformation domains using three different sources: 
NewsGuard, the Global Disinformation Index (GDI) and websites used 
in prior work (see Methods, ‘Collecting website data’). NewsGuard and 
the GDI use automated and manual methods to source and evaluate 
websites, but each website is rated manually by expert professionals 
who apply journalistic standards to evaluate online news outlets in a 
non-partisan and transparent manner.
We collected data on advertiser behaviour from 2019 to 2021 via 
Oracle’s Moat Pro platform, which includes data collected by ‘crawl-
ing’ approximately 10,000 websites daily to create a snapshot of the 
advertising landscape. Moat’s web crawlers mirror a normal user expe-
rience and attempt to visit a representative sample of pages for each 
website at least once a day. To the best of our knowledge, these data 
are the gold standard used by many industry stakeholders for com-
petitive analysis. For all the websites in our sample that get non-zero 
traffic throughout this period and have advertising data available on 

Nature  |  Vol 630  |  6 June 2024  |  125
the Moat Pro platform, we collected monthly data on the advertising 
companies appearing on each website and digital advertising platforms 
used by each website.
Our final dataset, which contains data on advertising and misinfor-
mation, consists of 5,485 websites (including 1,276 misinformation 
websites and 4,209 non-misinformation websites) and 42,595 unique 
advertisers with 9,539,847 instances of advertising companies appear-
ing on news websites between 2019 and 2021. Additionally, for the 
most active 100 advertisers each year, as identified by Moat Pro, we 
collected weekly data on the websites that they appeared on and the 
digital advertising platforms that they used.
Descriptive analysis
Of the websites in our sample, 89.3% were supported by advertising 
revenue between 2019 and 2021, and the majority of misinformation 
websites (74.5%) were monetized by advertising during this period. 
Moreover, among websites rated by NewsGuard, a much smaller per-
centage of misinformation websites had a paywall (2.7% in the USA 
and 3.2% globally) relative to non-misinformation websites (25.0% 
in the USA and 24.0% globally), which indicates a greater reliance on 
advertising for financing relative to other subscription-based busi-
ness models among misinformation websites. Although different 
entities may have specific ideological or financial motivations for 
propagating online misinformation, data from NewsGuard-rated 
websites (see Supplementary Table 3) shows that relative to non-mis-
information websites, misinformation websites were also more likely 
to be operated by individuals as opposed to corporate, non-profit or 
government entities. Given that advertising appears to be the domi-
nant business model that sustains misinformation outlets, it merits a 
closer look. We find that companies that advertise on misinformation 
websites span a wide range of industries (Supplementary Table 4) and 
account for 46% to 82% of overall companies in each industry (Fig. 1a). 
These include several well-known brands among commonly used 
household products, technology products and business services, 
as well as finance, health, government and educational institutions 
among other industries. Further, the intensity of advertising on mis-
information sites is similar (mean = 1.01, 95% confidence interval 
[0.945, 1.074], t(22) = 0.311, P = 0.759 from one-sample t-test, n = 23) 
to that on non-misinformation sites for companies across several 
industries (Fig. 1b).
Next, we examined the role of digital advertising platforms in financ-
ing misinformation. For the one hundred most active advertisers in 
each year, we collected weekly data on the websites their advertise-
ments appeared on and their use of digital advertising platforms. 
On average, about 79.8% of advertisers that used digital advertising 
platforms in a given week appeared on misinformation websites that 
week. In contrast, among companies that did not use digital advertis-
ing platforms in a given week, only 7.74% appeared on misinformation 
websites on average in a given week (two-sided t-test t(192.12) = 93.903, 
P < 0.001, n = 144). In other words, companies that used digital adver-
tising platforms were approximately ten times more likely to appear 
on misinformation websites than companies that did not use digital 
advertising platforms. Moreover, we account for industry and time 
trends to find that the use of digital advertising platforms by compa-
nies substantially amplifies the likelihood of a company’s advertising 
appearing on misinformation websites (see Extended Data Table 1).
Effects of advertising on misinformation
Next, our survey experiment aimed to determine potential changes 
in consumer behaviour based on experimentally varied informa-
tion about the roles of companies and platforms in financing mis-
information via advertising. Using the framework of Hirschman25, 
we measured how people (1) exit (that is, decrease their consump-
tion), and (2) voice concerns about company or platform practices 
via online petitions in response to the information provided in an  
incentive-compatible manner.
Average treatment effects
As detailed in Methods, ‘Consumer experiment design’, participants 
in our experiment were offered a gift card from a company of their 
choice. Our primary pre-registered outcome is whether respondents 
exit by switching their top gift card choice after receiving an infor-
mation treatment, which takes the value one for people who switch 
and the value zero for all other participants (n = 4,039). To observe 
exit outcomes, we focus on company-related information treatments  
0
10
20
30
40
50
60
70
80
90
Digital publishing
Print publishing
Media and entertainment 
Industrial
Babies and kids
Government, politics and religion
Automotive
Finance
Health
Dining
Retail
Household
Online services
Apparel and accessories
Food and beverages
Education
Natural gas and electric 
Insurance
Telecommunications 
Technology
Holding companies
82
79
77
76
75
73
71
70
70
69
68
68
66
65
65
64 
64
63
62
60
56
50
46
a
0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
0.78
1.10
0.90
0.99
0.94
1.02
1.10
1.06
0.82
1.25
1.16
1.02
0.98
0.82
0.85
0.95
0.76
1.13
1.10
1.38
1.01
1.05
1.05
b
Business solutions 
Travel 
Proportion of companies appearing on misinformation sites (%)
Advertising intensity on misinformation relative to non-misinformation sites
Fig. 1 | Advertising companies appearing on misinformation websites by 
industry. From 2019 to 2021, we recorded the number of times companies in a 
given industry appeared on the 5,485 websites in our sample per month. Our 
final sample of advertisers consists of 42,595 companies and 9,539,847 instances 
of companies advertising on the websites in our sample. We removed industries 
where the number of advertising appearances by all companies combined was 
below the 5th percentile of the total number of advertising appearances, resulting 
in a total of 23 industries. a, The proportion of companies in each industry that 
appear on misinformation websites at least once in our sample. b, The advertising 
intensity on misinformation sites relative to non-misinformation websites for 
each industry. This is calculated by dividing the proportion of advertisements 
from companies of that industry appearing on misinformation websites among 
all advertising appearances on misinformation websites with the same proportion 
for non-misinformation websites per industry. Therefore, values lower than 1 
indicate less, values close to 1 represent similar and values higher than 1 represent 
greater advertising intensity on misinformation sites relative to non-misinformation 
websites.

126  |  Nature  |  Vol 630  |  6 June 2024
Article
(T1, T3 and T4), where respondents are informed that advertisements 
from their top choice of gift card company recently appeared on misin-
formation websites. Table 1, column 1 shows that respondents increas-
ingly exit (that is, increase switching away or decrease demand from) 
their first choice company relative to control (b = 0.13, 95% confidence 
interval [0.10, 0.16], P < 0.001) in response to learning about their top 
choice gift card company’s advertisements appearing on misinforma-
tion websites (T1). This effect persists (b = 0.13, 95% confidence interval 
[0.10, 0.16], P < 0.001; Table 1, column 2) when we control for partici-
pants’ demographic and behavioural characteristics in our preferred 
specification, which enables more precise estimates (see Supplemen-
tary Information, ‘Analysis: consumer study outcomes’). We also use 
text analysis of the responses to a free-form question, which helps 
to identify the effect of the information intervention more directly. 
Respondents’ text responses explaining their choice of the gift card 
reveal that misinformation concerns drive this switching behaviour 
(Extended Data Fig. 1a).
Switching behaviour also increases relative to the control group 
(b = 0.10, 95% confidence interval [0.07, 0.13], P < 0.001) when respond-
ents are told about the substantial role of digital advertising platforms 
in placing companies’ advertisements on misinformation websites 
(T3). This switching behaviour persists even though respondents are 
more likely to state that digital advertising platforms are responsible 
for placing companies’ advertisements on misinformation websites 
by four percentage points relative to the control group (b = 0.04, 95% 
confidence interval [0.02, 0.06], P < 0.001, Extended Data Fig. 1b). 
This suggests that advertising companies can continue to experience 
a decline in demand for their products or services despite consumers 
knowing that digital advertising platforms have a substantial role in 
placing companies’ advertisements on misinformation websites.
When provided with a ranking of companies in order of their intensity 
of appearance on misinformation websites (T4), respondents switch 
away from opting for their top choice gift card company (b = 0.08, 95% 
confidence interval [0.05, 0.11], P < 0.001). This result shows that the 
advertising companies can expect to face a decrease in consumption 
for financing misinformation despite other companies also advertis-
ing on misinformation outlets. Respondents are less likely to mention 
product features that are relevant to the companies they are interested 
in—for example, healthy food, good prices and availability in the local 
area, among others (b = −0.07, 95% confidence interval [−0.09, −0.05], 
P < 0.001, Extended Data Fig. 1a). Examining the direction of consumer 
switching shows that among those who switch their gift card prefer-
ence (n = 430), those provided with company-ranking information in 
T4 made the most switches towards companies that less frequently 
advertised on misinformation websites (b = 0.95, 95% confidence inter-
val [0.19, 1.71], P = 0.015). This result suggests that providing a ranking 
of advertising companies transparently could steer consumer demand 
towards companies that advertise less frequently on misinformation 
websites.
Our results are robust to alternative exit outcomes that include 
whether participants switch to a product they prefer less than their first 
choice (Table 1, columns 3 and 4) and whether they switch their choice 
across product categories (Table 1, columns 5 and 6), further indicat-
ing that participants incur a real cost of switching to a company that is 
not equivalent to their top-ranked one. Although our platform-related 
information treatment (T2) does not explicitly mention the respond-
ents’ first choice gift company (as in T1, T3 and T4) or its specific use of 
digital advertising platforms (as in T3), we observe a small amount of 
switching in T2 relative to the control group (b = 0.03, 95% confidence 
interval [0.01, 0.05], P = 0.012). This could be because respondents 
might partially blame their first choice gift card company as it could 
be top of mind for them42 or assume that the information provided in 
T2 alluded to the company they had just chosen43. It is important to 
note that the other outcomes reported in Table 1 in the paper—that is, 
switching to lower preference gift cards and switching across categories 
are not statistically significant for T2, which suggests that T2 does not 
Table 1 | Average treatment effects on exit
Switch in preference
Switch to lower preference
Switch in category
Switch to lower misinformation
1
2
3
4
5
6
7
8
Company (T1)
0.13***
0.13***
0.08***
0.08***
0.05***
0.05***
1.03**
0.69∗
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.48)
(0.38)
<0.001
<0.001
<0.001
<0.001
<0.001
<0.001
0.031
0.075
Platform (T2)
0.03***
0.03**
0.01
0.01
0.02*
0.01
0.52
0.23
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.54)
(0.48)
0.010
0.012
0.114
0.118
0.076
0.130
0.335
0.629
Company and platform (T3)
0.10***
0.10***
0.06***
0.06***
0.04***
0.04***
0.69
0.28
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.49)
(0.38)
<0.001
<0.001
<0.001
<0.001
<0.001
<0.001
0.157
0.452
Company ranking (T4)
0.08***
0.08***
0.06***
0.06***
0.03***
0.02**
1.57***
0.95**
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.50)
(0.39)
<0.001
<0.001
<0.001
<0.001
0.006
0.015
0.002
0.015
Controls
No
Yes
No
Yes
No
Yes
No
Yes
Control group mean
0.04
0.04
0.02
0.02
0.03
0.03
0.65
0.65
Observations
4039
4039
4039
4039
4039
4039
430
430
Ordinary least squares (OLS) regression results for each of the four treatment groups (T1, T2, T3 and T4) in our sample. Columns are numbered along the top. In columns 1 and 2, the dependent  
variable is a binary variable that takes the value 1 when a participant switches their gift card choice from their top choice company after receiving the information treatment and is zero 
otherwise (n = 4,039). In columns 3 and 4, the dependent variable is a binary variable that takes the value 1 when a participant switches their gift card choice from their top choice company to 
a company they prefer less (as measured by how participants assign weights to each of the 6 gift card choices that must all sum up to 100) and is zero otherwise (n = 4,039). In columns 5 and 6, 
the dependent variable is a binary variable that takes the value 1 when a participant switches their gift card choice across product categories (for example, from ride-sharing gift cards to a fast 
food gift card) and is zero otherwise (n = 4,039). Columns 7 and 8 show regressions for the sub-sample of participants who switch their gift card choice; the dependent variable is the difference 
in the intensity of advertising misinformation between the participant’s top choice gift card company and the company they finally choose after receiving the information treatment (n = 430). 
We report summary statistics and demonstrate that our treatment groups are balanced across observable characteristics in Supplementary Table 5. Results for the sample including inattentive 
respondents are shown in Supplementary Table 9. No adjustments were made for multiple comparisons. Robust standard errors are shown in parentheses. P values derived from two-sided 
t-tests are reported below the standard errors. The remaining pairwise P values are reported in Supplementary Table 6. *P < 0.1, **P < 0.05, ***P < 0.01.

Nature  |  Vol 630  |  6 June 2024  |  127
result in treatment effects similar to our other treatments. Overall, we 
find that companies whose advertisements appear on misinformation 
websites can face substantial consumer backlash in terms of both exit 
and voice. Consumers who switched their gift card choice as a result 
of our information treatments lost about 39.4% of the mean value and 
42.9% of the median value of their gift card value on average. Given that 
the value of the gift card is US$25, a 39.4% decline in the mean value 
translates to treated consumers losing an equivalent of US$9.85. The 
distribution of weights assigned to the initial top gift card choice and 
the final selection is shown in Extended Data Fig. 2, which illustrates a 
substantial leftward shift in the weight distribution when individuals 
switch away from their top choice. We also find suggestive evidence 
for vast differences between consumers’ stated and revealed prefer-
ences, as shown in Supplementary Fig. 3. When compared to prior 
research, our 13 percentage point decline in demand is similar in mag-
nitude to the demand reduction observed from receiving negative 
product feedback44 and exceeds the magnitude of previously meas-
ured changes in demand associated with companies taking a social or 
political stance37,38.
Next, we examine the effects of the information interventions on 
our pre-registered voice outcomes captured by individuals signing 
an online petition to voice concerns about advertising on misinforma-
tion websites. Participants were given the option to sign one of four 
different petitions on Change.org (https://www.change.org/): two 
company-level petitions advocating that companies in general should 
block or allow their advertisements from appearing on misinforma-
tion outlets, and two similar platform-level petitions. Although we 
observe petition signatures at the group level, we use clicks on petition 
links as our primary voice outcome since this information is available 
at the individual level and most closely matches the proportions of 
actual signatures (Extended Data Fig. 3). Our results are robust to using 
alternative petition outcomes, such as intention to sign a petition, 
self-reported petition signatures and actual signatures (Extended 
Data Table 2). Of note, we do not analyse actual signatures for the T4 
group since Change.org accidentally deleted these petitions after 
they were recorded.
Relative to the control group, participants were 5 percentage points 
(36%) significantly more likely to click on the platform petition link 
when given information about the role of digital advertising platforms 
in automatically placing advertisements on misinformation websites 
in the platform (T2) treatment group (Table 2, columns 3 and 4). Text 
analysis from respondents’ explanation of their petition choice con-
firms that respondents hold digital advertising platforms more respon-
sible for financing misinformation in T2 relative to the control group 
(b = 0.02, 95% confidence interval [0.01, 0.04], P = 0.012, Extended 
Data Fig. 1b). For example, one respondent stated who opted for the 
platform blocking petition explained their choice by stating that the 
platform option “involves more than one company.” Another stated 
that their chosen gift card company is “not the only ad being put on 
misinformation sites. It is a larger issue that has to do with the plat-
forms used to place ads.” Indeed, signing these petitions is the only 
way that participants can take any action to hold advertising platforms  
responsible in response to T2, which explicitly highlights the role of 
platforms.
Upon receiving information about all six gift card companies’ adver-
tisements appearing on misinformation websites (T4), participants 
were significantly more likely to click on petition links suggesting that 
advertising companies need to block their advertisements from appear-
ing on misinformation websites (Table 2, columns 3 and 4). Based on 
their open-ended text responses (Extended Data Fig. 1a), respondents 
increasingly highlighted misinformation-related concerns (b = 0.09, 
95% confidence interval [0.07, 0.11], P < 0.001) and placed less emphasis 
on product usage (b = −0.05, 95% confidence interval [−0.07, − 0.03], 
P < 0.001) and product features (b = −0.07, 95% confidence interval 
[−0.09, − 0.05], P < 0.001). In T4, the treatment intensity for companies, 
in general, is significantly stronger relative to T1 and T3 since we high-
lighted that all six gift card companies advertise on misinformation 
websites (at varying levels). This increase in treatment intensity could 
explain a higher treatment effect for T4 relative to the null effects for 
company petitions in the other treatment arms, which only specifically 
mentioned the respondents’ top choice gift card company.
Heterogeneous treatment effects
Next, we explore heterogeneity in treatment effects along four 
pre-registered dimensions (gender, political orientation, frequency 
of use of the company’s products or services, and consumption of mis-
information) based on our hypotheses (see Methods, ‘Consumer experi-
ment design’). Focusing on exit (Extended Data Table 3, columns 1–4), 
we observe positive treatment effects for all groups—that is, male and 
female, Biden voters and Trump voters, frequent and infrequent users 
of a company’s products or services, and those who report consuming 
news from misinformation outlets in our survey and those who do 
not. As reported in Extended Data Table 3, in line with our predictions, 
we find stronger treatment effects for exit among women (b = 0.05, 
P = 0.011) and Biden voters (b = 0.03, P = 0.058) and less strong treat-
ment effects for frequent users (b = −0.05, P = 0.007) and those who 
consume news from select popular misinformation outlets (b = −0.04, 
P = 0.097). Respondents who voted for President Biden in the 2020 
US Presidential election were also 5 percentage points more likely to 
voice concerns against company practices (P = 0.04; Extended Data 
Table 3, column 6). Overall, we believe these heterogeneity results 
bolster the external validity of our experimental estimates. In particular, 
we highlight that product-specific factors such as frequency of use can 
have an important role in the decision to switch or not separately from 
ideological reasons such as political leaning.
Table 2 | Average treatment effects on voice
Company
Platform
1
2
3
4
Company (T1)
0.02
0.02
−0.02
−0.02
(0.02)
(0.02)
(0.02)
(0.02)
0.180
0.257
0.286
0.349
Platform (T2)
−0.01
−0.01
0.05∗∗∗
0.05∗∗∗
(0.02)
(0.02)
(0.02)
(0.02)
0.546
0.007
0.436
0.006
Company and 
platform (T3)
−0.00
−0.00
−0.01
−0.01
(0.02)
(0.02)
(0.02)
(0.02)
0.863
0.940
0.638
0.708
Company ranking (T4)
0.04∗∗
0.04∗∗
−0.03∗
−0.03
(0.02)
(0.02)
(0.02)
(0.02)
0.047
0.049
0.080
0.115
Controls
No
Yes
No
Yes
Control group mean
0.15
0.15
0.14
0.14
Observations
4039
4039
4039
4039
OLS regression results for each of the four treatment groups (T1, T2, T3 and T4) in our sample 
(n = 4,039). Columns are numbered along the top. In columns 1 and 2, the dependent variable 
is clicking on a link to sign a petition that suggests that companies like the respondent’s top 
choice gift card company need to block their advertisements from appearing on misinformation 
websites. In columns 3 and 4, the dependent variable is clicking on a link to sign a petition that  
suggests that digital advertising platforms used by companies need to block advertisements 
from appearing on misinformation websites. Alternative petition outcomes are shown in 
Extended Data Table 2. Alternative petition outcomes are shown in Extended Data Table 2. 
Results for the sample including inattentive respondents are shown in Supplementary Table 10.  
No adjustments were made for multiple comparisons. Robust standard errors are shown in 
parentheses. P values derived from two-sided t-tests are reported below the standard errors. 
The remaining pairwise P values are reported in Supplementary Table 7.

128  |  Nature  |  Vol 630  |  6 June 2024
Article
Measuring decision-maker preferences
Given that advertising on misinformation websites is pervasive and 
could provoke consumer backlash, we next examine what explains 
the prevalence of this phenomenon among companies. To shed light 
on this question, we surveyed key strategic decision-makers such as 
executives and managers at companies by partnering with the execu-
tive education programmes at two universities to survey their alumni.  
In collaboration with our partner organizations, we also verified the job 
titles of the majority (71%) of our respondents using external sources, 
which are shown in Extended Data Fig. 4. About 94% of the participants 
whose job titles we were able to verify served in a top executive role or 
managerial role at the time of our survey (for example, chief executive, 
general or operations manager of multiple departments or locations, 
advertising or sales manager or operations manager) and the remainder 
were individuals who could influence decision-making within their 
companies, especially given their interest in learning leadership and 
managerial skills via executive education programmes.
Baseline beliefs and preferences
We found a wide dispersion in decision-makers’ pre-registered beliefs 
about the role of companies and platforms in financing misinforma-
tion as shown in Supplementary Fig. 6 and 7, which complements 
prior work showing wide dispersion in decision-makers’ beliefs in 
other settings45,46. Decision-makers largely overestimate the overall 
proportion of companies that advertise on misinformation websites 
and underestimate the role of digital advertising platforms in placing 
companies’ advertisements on misinformation websites. In particular, 
respondents estimated that about 64% of companies’ advertisements 
appeared on misinformation websites on average (Supplementary 
Table 12). However, our data show that 55% of the 100 most active 
advertisers appeared on misinformation websites. Regarding the role 
of digital advertising platforms, respondents estimated that around 
44.5% of companies using digital advertising platforms appear on 
misinformation websites (Supplementary Table 12), whereas 79.8% 
of companies among the 100 most active advertisers in fact do so. 
Moreover, only 41% of decision-makers believed that consumers react 
against companies whose advertisements appear on misinformation 
websites. These results suggest that decision-makers believe that 
advertising on misinformation websites is probably commonplace 
but has little to do with using digital advertising platforms and has 
limited consequences for the companies involved.
However, in contrast to the average belief that most companies 
advertised on misinformation websites, respondents substantially 
underestimated their own company’s likelihood of appearing on mis-
information websites. Only 20% of respondents believing that their 
own company’s advertisements recently appeared on misinformation 
websites, which indicates the presence of a false uniqueness effect 
among decision-makers47. We further segmented our results by type 
of role within the company (Extended Data Table 4). Although our 
sub-samples were small, these baseline beliefs and characteristics were 
largely similar across various roles. Among participants who expressed 
an interest in learning about whether their company’s advertisements 
appeared on misinformation websites (that is, requested an advertise-
ment check by providing their company name and contact details) and 
whose companies appeared in our advertising data, approximately 
81% of companies appeared on misinformation websites. Moreover, 
most respondents who were given follow-up information that their 
companies’ advertisements appeared on misinformation websites 
reported being surprised by this information (62%), whereas none of 
those who learned their companies advertisements did not appear on 
misinformation websites reported being surprised. These figures illus-
trate that decision-makers are largely uninformed about the high likeli-
hood of their company’s advertisements appearing on misinformation 
websites. Given these findings about the beliefs of decision-makers, 
our results suggest that companies may be financing misinformation 
inadvertently.
Most participants requested an advertisement check by provid-
ing their company name and email address (74%). The demand 
for an advertisement check was high regardless of respondents’ 
initial beliefs, suggesting a substantial interest in learning about 
whether their company’s advertisements appeared on misinfor-
mation websites. Despite only 41% of respondents agreeing that  
consumers react against companies whose advertisements appear on 
misinformation websites, most participants (73%) opted to receive 
information on how consumers respond to companies whose adver-
tisements appear on misinformation websites with 58% inquiring 
about exit and 15% enquiring about voice. This suggests that although 
decision-makers may be unaware of how advertising on misinfor-
mation websites can provoke consumer backlash, most of them are 
interested in learning about the degree of potential backlash. Finally, 
for our most costly revealed-preference measure—that is, signing 
up to attend a 15-minute expert-led information session on how  
companies can avoid advertising on misinformation websites—18% 
of decision-makers opted to sign up, an arguably high rate given the 
value of decision-makers’ time and the opportunity cost of attending  
the session.
Information intervention results
We report the results of our information treatment on our pre-registered 
outcomes. For the full sample of participants, we estimate positive and 
statistically significant effects on participants’ posterior beliefs about 
the role of advertising platforms in placing advertisements on misin-
formation websites (Table 3, column 1), driven mainly by respondents 
who believe that their company’s advertisements had not appeared on 
misinformation websites in the recent past (Table 3, column 3).
We find an overall null effect of our information treatment on parti­
cipants’ demand for a platform-based solution, as measured by 
their demand for information on which platforms least frequently 
place companies’ advertisements on misinformation websites  
Table 3 | Average treatment effects of information 
intervention
Posterior platform belief
Platform solution demand
All
Yes
No
All
Yes
No
1
2
3
4
5
6
Treatment
48.99∗∗∗
6.11
54.15∗∗∗
−0.03
−0.10
−0.03
(15.79)
(43.43)
(17.77)
(0.05)
(0.13)
(0.05)
0.002
0.883
0.002
0.559
0.436
0.567
Controls
Yes
Yes
Yes
Yes
Yes
Yes
Control group 
mean
96.10
124.47
88.65
0.37
0.34
0.38
Observations
442
88
354
442
88
354
OLS regression results where the dependent variables are posterior beliefs (columns 1–3) 
and demand for platform solution (columns 4–6). Columns are numbered along the top. We 
winsorize the posterior beliefs to remove outliers. Our platform solution demand outcome 
variable is a binary variable that takes a value of one when participants choose to receive 
information on which platforms least frequently place companies’ advertisments on  
misinformation websites and zero otherwise. Columns 1 and 4 show results for the full sample 
of participants (n = 442). Columns 2 and 5 show results for the sub-sample of participants 
who reported ‘yes’ to the question “Do you think your company or organization had its 
ads appear on misinformation websites during the past three years (2019–2021)?” (n = 88). 
Columns 3 and 6 show results for the sub-sample who reported ‘No’ in response to the same 
question (n = 354). We control for decision-makers’ characteristics and prior beliefs. Results 
for the sample including inattentive respondents are shown in Supplementary Table 14. 
No adjustments were made for multiple comparisons. Robust standard errors are shown in 
parentheses. P values derived from two-sided t-tests are reported below the standard errors.

Nature  |  Vol 630  |  6 June 2024  |  129
(Table 3, columns 4–6). However, this result masks substantial het-
erogeneity based on participants’ prior beliefs. Since our information 
treatment changes beliefs for the subset of participants who believe 
that their company’s advertisements had not recently appeared on mis-
information websites (Table 3, column 3), we further investigated and 
reported results based on participant’s prior beliefs for this sub-sample 
in Table 4. Only participants who were uncertain and unaware about 
their own company’s advertisements appearing on misinformation 
websites responded positively and significantly to our information 
treatment by increasing their demand for a platform-based solution 
by 36 percentage points (b = 0.36, 95% confidence interval [0.11, 0.61], 
P = 0.008, n = 68), as shown in Table 4, column 4. Our results imply that 
the way in which participants respond to information about the role 
of digital advertising platforms in financing misinformation is highly 
dependent on their prior beliefs about their own company. Such infor-
mation could make companies switch advertising platforms or pressure 
the platforms they currently use to enable them to easily steer their 
advertising away from misinformation outlets. This finding is in line 
with a lack of attention describing decision-makers’ behaviours across 
various settings48–50. However, these results should be viewed as sug-
gestive and exploratory since the subsample sizes in these regressions 
are small and these sample splits were not pre-registered.
We did not find meaningful treatment effects for our donation pref-
erence outcome, which measures the proportion of respondents who 
prefer that we donate to the GDI instead of DataKind (Supplementary 
Table 13). Since both GDI and DataKind have similar goals of advanc-
ing technology’s ethical and responsible use, respondents may have 
considered their missions interchangeable. Moreover, unlike our first 
behavioural outcome, respondents could have considered donating 
to the GDI less relevant to their own organizations’ needs and more a 
matter of personal preference.
Discussion
Together, our descriptive and experimental findings offer clear, practi-
cal implications. Given the potential for a substantial decline in demand, 
as demonstrated by our consumer study, advertising companies may 
wish to account for consumer preferences in placing their advertising 
across various online outlets and exercise caution while incorporating 
automation in their business processes via digital advertising plat-
forms. For instance, given that consumers switched to other products 
upon learning about a company’s advertisements appearing on mis-
information websites, companies could use lists of misinformation 
outlets provided by independent third-party organizations such as 
NewsGuard and the GDI to limit advertising budgets being spent on 
misinformation outlets through digital platforms. Moreover, since 
consumer backlash was particularly strong for women and politically 
left-leaning consumers, companies targeting such audiences may need 
to exercise greater caution.
On the basis of our results, we identify two interventions that could 
reduce the financing of online misinformation. First, digital advertis-
ing platforms that run automated auctions could enable advertisers 
to more easily access data on whether their advertisements appear 
on misinformation outlets. This would enable advertisers to make 
advertising placement decisions consistent with their preferences 
rather than inadvertently financing misinformation51. Second, while 
it is currently possible for consumers to find out about companies 
financing misinformation through media reports, digital platforms 
could improve transparency for consumers about which companies 
advertise on misinformation outlets. Platforms could provide such 
information to consumers when they are viewing an advertisment 
using simple information labels (as in our ‘company only’ information 
treatment) similar to the ‘sponsored by’ and ‘paid for by’ labels that 
are presently common on various digital media platforms. Similarly, 
rank-based information provided in our company-ranking information 
treatment (T4) could be provided as a ranking of companies in order of 
intensity of appearing on misinformation websites where customers are 
selecting products from a menu of choices while shopping. Platforms 
have provided similar contextual information about companies in other 
settings—for example, Google Flights displays carbon emissions data 
alongside flight prices when people select a flight to purchase among 
several options52. Enabling consumers to view such information at the 
point of purchase could provide a stronger incentive for companies to 
steer their advertisements away from such outlets, especially since the 
effect of negative information can persist for several months53. Overall, 
these interventions could decrease the inadvertent advertising revenue 
going towards misinformation outlets, which could eventually lead to 
such sites ceasing to operate, as observed anecdotally in prior work29.
These interventions could ensure that both consumers and adver-
tisers are provided with information about the consequences of their 
respective purchasing and advertising placement decisions so that they 
can account for their preferences. Having access to such information is 
necessary for an efficiently functioning economic system in accordance 
with the first fundamental theorem of welfare economics. However, 
whereas digital platforms are uniquely well-positioned in the ecosystem 
of consumers, advertisers and publishers to implement information 
interventions in the form of disclosures and rankings54,55, they may not 
have incentives to implement such interventions. With the backdrop 
of mounting pressure from advertisers27,28 and calls for transparency 
in the programmatic advertising business56, information-based inter-
ventions could be incorporated into existing legislation to improve 
transparency. These include efforts such as the EU Digital Services Act, 
which includes a Code of Practice on Disinformation with enforceable 
provisions for different stakeholders in the advertising ecosystem 
to collectively fight misinformation, and US bills such as the Honest 
Ads Act and the Competition and Transparency in Digital Advertis-
ing (CTDA) Act, which include provisions to improve transparency 
in political advertising and the digital advertising ecosystem in gen-
eral. Notably, in recent years, policy proposals that aim to reduce the 
prevalence of misinformation such as the Combating Misinformation 
and Disinformation bill in Australia and the bill against fake news in 
Germany have faced backlashes over posing risks to free speech57,58. 
Although such proposals face the challenge of striking the right bal-
ance between combating misinformation and protecting freedom of 
Table 4 | Treatment effects based on prior beliefs
Posterior platform belief
Platform solution demand
Certain
Uncertain
Certain
Uncertain
1
2
3
4
Treatment
39.98**
144.25**
−0.07
0.36***
(20.23)
(60.23)
(0.06)
(0.13)
0.049
0.022
0.213
0.008
Controls
Yes
Yes
Yes
Yes
Control group 
mean
90.23
80.80
0.37
0.43
Observations
286
68
286
68
OLS regression results for the sub-sample of participants who reported ‘No’ to the question 
“Do you think your company or organization had its advertisements appear on misinformation 
websites during the past three years (2019–2021)?” (n = 354). Columns are numbered along the 
top. The dependent variables are posterior beliefs (columns 1 and 2) and demand for platform 
solution (columns 3 and 4) from Table 3. Columns 1 and 3 show results for participants who 
report being certain about their response to the question—that is, choosing ‘Somewhat 
sure’, ‘Sure’ or ‘Very sure’ (n = 286). Column 4 shows results for participants who report being 
uncertain about their response to the question—that is, choosing ‘Unsure’ or ‘Very unsure’ 
(n = 68). Results for the sample including inattentive respondents are shown in Supplementary 
Table 15. No adjustments were made for multiple comparisons. Robust standard errors  
are shown in parentheses. P values derived from two-sided t-tests are reported below the 
standard errors.

130  |  Nature  |  Vol 630  |  6 June 2024
Article
expression, the information interventions that we identify could help 
counter the financial incentive to produce misinformation in the first 
place by reducing the unintended advertising revenue going towards 
misinformation outlets. There are many parallels for regulation by 
information provision to address externalities in other industries, 
including chemicals (toxic release inventory reporting requirements), 
automobiles (fuel consumption information), food (nutrition and con-
tent labels) and airlines (greenhouse gas emissions), of which several 
have been demonstrated to be effective in prior work41,59,60.
Previously studies have shown that ‘demand-side’ interventions to 
counter online misinformation have focused on reducing the consump-
tion and spread of misinformation among news consumers on online 
platforms. Although interventions such as accuracy prompts and digital 
literacy tips can increase the quality of news that people share5, this 
line of work has found limited support for news credibility signals in 
increasing the demand for credible news61 or in reducing mispercep-
tions among users6. Such constraints in changing user behaviour may 
also apply to credibility signals like watermarks for detecting AI misin-
formation. Moreover, whereas such interventions are only effective for 
the small subset of users who are exposed to misinformation62, our com-
plementary ‘supply-side’ approach targets entities and individuals who 
might not necessarily consume or spread misinformation themselves.
Relative to existing proposals of supply-side interventions to 
curb the production of misinformation, which involve social media 
platforms banning the advertising of false news63 or changing their 
advertising-driven business model altogether18, we outline a middle 
path to suggest that accounting for the preferences of advertisers and 
consumers could help counter the financing of online misinforma-
tion. Although platforms could coordinate to identify and deplatform 
misinformation websites64, prior work suggests that misinformation 
websites nearly always resurface through alternative providers unless 
the incentive to produce misinformation is addressed29. Moreover, the 
information interventions that we identify are also an improvement on 
the status quo, whereby advertisers and consumers can only implement 
their preferences by participating in boycotts of digital platforms over 
their inability to contain misinformation. Allowing advertisers to more 
easily observe and control whether their advertisements appear on 
misinformation websites could also limit backlash by enabling advertis-
ers to better implement their preferences rather than participating in 
one-off short-term advertising boycotts27,28. Additionally, since consist-
ently providing negative information can create lasting associations 
for consumers65, providing information disclosures on every adver-
tisement for whether the advertising company involved appears on 
misinformation websites could have a substantial effect on consumer 
demand over time, providing incentives for advertising companies to 
reduce advertising on misinformation websites.
Given our findings, we suggest three promising avenues for future 
research. First, future work could evaluate the effectiveness of our 
information interventions in the field over a longer time period to 
quantify the decline in revenue generated by misinformation outlets 
resulting from increasing transparency for consumers or advertisers. 
Related to this, future work could also target a wider set of advertisers 
to validate the robustness of our interventions which would allow for 
broader generalizability. Second, our results on whether companies 
are willing to adopt solutions to avoid monetizing misinformation are 
based on their existing (often incorrect) beliefs about the prevalence 
of advertising on misinformation websites in general and for their own 
company. More research is needed to understand how advertising com-
panies would respond in the context of correct beliefs. Third, although 
our research identifies potential interventions that digital platforms 
can adopt to curb the monetization of online misinformation, it is 
unclear whether it is in the interest of digital advertising platforms to 
do so. Moreover, whether the potential monetary and societal benefits 
of the information interventions we identify outweigh the revenue plat-
forms generate by serving advertisements on misinformation websites 
remains to be studied. Overall, the effectiveness of platforms in mitigat-
ing misinformation will depend on a multi-pronged approach. Given 
that misinformation is largely financially motivated and that financially 
sustaining online misinformation can be substantially harmful for the 
advertising companies involved, simple low-cost informational inter-
ventions such as the ones we identify could go a long way in curbing 
the supply of online misinformation.
Online content
Any methods, additional references, Nature Portfolio reporting summa-
ries, source data, extended data, supplementary information, acknowl-
edgements, peer review information; details of author contributions 
and competing interests; and statements of data and code availability 
are available at https://doi.org/10.1038/s41586-024-07404-1.
1.	
Blumberg, D. L. 3 ways the ‘splinternet’ is damaging society. MIT Management Sloan 
School https://mitsloan.mit.edu/ideas-made-to-matter/3-ways-splinternet-damaging- 
society (2023).
2.	
Guess, A., Nagler, J. & Tucker, J. Less than you think: prevalence and predictors of fake 
news dissemination on Facebook. Sci. Adv. 5, 1494–1504 (2019).
3.	
Lazer, D. M. et al. The science of fake news: addressing fake news requires a multidisciplinary 
effort. Science 359, 1094–1096 (2018).
4.	
Mosseri, A. Working to Stop Misinformation and False News. Meta Newsroom https://
about.fb.com/news/2017/04/working-to-stop-misinformation-and-false-news/ (2017).
5.	
Arechar, A. A. et al. Understanding and combatting misinformation across 16 countries on 
six continents. Nat. Hum. Behav. 7, 1502–1513 (2023).
6.	
Aslett, K., Guess, A. M., Bonneau, R., Nagler, J. & Tucker, J. A. News credibility labels have 
limited average effects on news diet quality and fail to reduce misperceptions. Sci. Adv. 
8, 3844 (2022).
7.	
Pennycook, G. et al. Shifting attention to accuracy can reduce misinformation online. 
Nature 592, 590–595 (2021).
8.	
Pennycook, G. & Rand, D. G. Fighting misinformation on social media using crowdsourced 
judgments of news source quality. Proc. Natl Acad. Sci. USA 116, 2521–2526 (2019).
9.	
Haaland, I., Roth, C. & Wohlfart, J. Designing information provision experiments. J. Econ. Lit. 
61, 3–40 (2023).
10.	
Bursztyn, L., Rao, A., Roth, C. P. & Yanagizawa Drott, D. H. Misinformation during a pandemic. 
Working paper 27417 (National Bureau of Economic Research, 2020); https://www.nber.org/
papers/w27417.
11.	
Van der Linden, S., Leiserowitz, A., Rosenthal, S. & Maibach, E. Inoculating the public 
against misinformation about climate change. Global Challenges 1, 756–784 (2017).
12.	
McCarthy, B. Misinformation and the Jan 6 insurrection: when ‘patriot warriors’ were fed 
lies. Politifact https://www.politifact.com/article/2021/jun/30/misinformation-and-jan-6- 
insurrection-when-patriot/ (2021).
13.	
Higgins, A., McIntire, M. & Dance, J. G. Inside a fake news sausage factory: ‘This Is All 
About Income’. The New York Times (25 November 2016); https://www.nytimes.
com/2016/11/25/world/europe/fake-news-donald-trump-hillary-clinton-georgia.html
14.	
Hao, K. How Facebook and Google fund global misinformation. MIT Technology Review 
https://www.technologyreview.com/2021/11/20/1039076/facebook-google-disinformation- 
clickbait/ (2021).
15.	
Giansiracusa, N. Google needs to defund misinformation. Slate https://slate.com/
technology/2021/11/google-ads-misinformation-defunding-artificial-intelligence.html. 
(2021).
16.	
Austin, A., Barnard, J. & Hutcheon, N. Programmatic Marketing Forecasts (Zenith,  
2019); https://s3.amazonaws.com/media.mediapost.com/uploads/
ProgrammaticMarketingForecasts2019.pdf
17.	
Special Report: Top Brands are Sending $2.6 Billion to Misinformation Websites Each Year 
(NewsGuard, 2021); https://www.newsguardtech.com/special-reports/brands-send- 
billions-to-misinformation-websites-newsguard-comscore-report/.
18.	
Romer, P. A tax that could fix big tech. The New York Times (6 May 2019); https://www.
nytimes.com/2019/05/06/opinion/tax-facebook-google.html.
19.	
Love, J. & Cooke, K. Google, Facebook move to restrict ads on fake news sites. Reuters 
https://www.reuters.com/article/us-alphabet-advertising/
google-facebook-move-to-restrict-ads-on-fake-news-sites-idUSKBN1392MM (2016).
20.	 Hsu, T. & Tracy, M. Investors push Home Depot and Omnicom to steer ads from 
misinformation. The New York Times (18 January 2021); https://www.nytimes.
com/2021/01/18/business/media/investors-push-home-depot-and-omnicom-to-steer- 
ads-from-misinformation.html.
21.	
Grant, N. & Myers, S. L. Google promised to defund climate lies, but the ads keep coming. 
The New York Times (2 May 2023); https://www.nytimes.com/2023/05/02/technology/
google-youtube-disinformation-climate-change.html.
22.	 Ryan-Mosley, T. Junk websites filled with AI-generated text are pulling in money from 
programmatic ads. MIT Technology Review https://www.technologyreview.
com/2023/06/26/1075504/junk-websites-filled-with-ai-generated-text-are-pulling-in- 
money-from-programmatic-ads/ (2023).
23.	 Milmo, D. & Hern, A. Elections in UK and US at risk from AI-driven disinformation, say 
experts. The Guardian (20 May 2023); https://www.theguardian.com/technology/2023/
may/20/elections-in-uk-and-us-at-risk-from-ai-driven-disinformation-say-experts.
24.	 Gomes Ribeiro, B., Horta Ribeiro, M., Almeida, V. & Meira, W. Analyzing the “sleeping 
giants” activism model in Brazil. In Proc. 14th ACM Web Science Conference https://doi.
org/10.1145/3501247.3531563 (ACM, 2022).

Nature  |  Vol 630  |  6 June 2024  |  131
25.	 Hirschman, A. O. Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, 
and States (Harvard Univ. Press, 1970).
26.	 Gans, J. S., Goldfarb, A. & Lederman, M. Exit, tweets, and loyalty. Am. Econ. J. 
Microeconomics 13, 68–112 (2021).
27.	
Hsu, T. Twitter’s advertisers pull back as layoffs sweep through company. The New York 
Times (4 November 2022); https://www.nytimes.com/2022/11/04/technology/twitter- 
advertisers.html.
28.	 Hsu, T. & Lutz, E. More than 1,000 companies boycotted Facebook. Did it work? The New 
York Times (1 August 2020); https://www.nytimes.com/2020/08/01/business/media/
facebook-boycott.html.
29.	 Han, C., Kumar, D. & Durumeric, Z. On the infrastructure providers that support 
misinformation websites. In Proc. 16th International AAAI Conference on Web and Social 
Media https://ojs.aaai.org/index.php/ICWSM/article/view/19292/19064 (Association for 
the Advancement of Artificial Intelligence, 2022).
30.	 Papadogiannakis, E., Papadopoulos, P., Markatos, E. P. & Kourtellis, N. Who funds 
misinformation? A systematic analysis of the ad-related profit routines of fake news sites. 
Preprint at https://doi.org/10.48550/arXiv.2202.05079 (2023).
31.	
Bozarth, L. & Budak, C. An analysis of the partnership between retailers and low-credibility 
news publishers. J. Quant. Descr. Digit. Media https://doi.org/10.51685/jqd.2021.010 
(2021).
32.	 Bozarth, L. & Budak, C. Market forces: quantifying the role of top credible ad servers in the 
fake news ecosystem. In Proc. 15th International AAAI Conference on Web and Social 
Media https://ojs.aaai.org/index.php/ICWSM/article/view/18043/17846 (Association for 
the Advancement of Artificial Intelligence, 2021).
33.	 Kohno, T., Zeng, E. & Roesner, F. Bad news, cickbait and deceptive ads on news and 
misinformation websites. In Workshop on Technology and Consumer Protection https://
badads.cs.washington.edu/files/Zeng-ConPro2020-BadNews.pdf (2020).
34.	 Braun, J. A. & Eklund, J. L. Fake news, real money: ad tech platforms, profit-driven hoaxes, 
and the business of journalism. Digit. Journal. https://doi.org/10.1080/21670811.2018.1556
314 (2019).
35.	 Du, S., Bhattacharya, C. B. & Sen, S. Corporate social responsibility and competitive 
advantage: overcoming the trust barrier. Manage. Sci. 57, 1528–1545 (2011).
36.	 Bellman, S., Abdelmoety, Z. H., Murphy, J., Arismendez, S. & Varan, D. Brand safety:  
the effects of controversial video content on pre-roll advertising. Heliyon 4, e01041  
(2018).
37.	
Liaukonyte, J., Tuchman, A. & Zhu, X. Frontiers: spilling the beans on political consumerism: 
do social media boycotts and buycotts translate to real sales impact? Market. Sci. https://
doi.org/10.1287/mksc.2022.1386 (2022).
38.	 Chatterji, A. K. & Toffel, M. W. Assessing the impact of CEO activism. Organ. Environ. 32, 
159–185 (2019).
39.	 Lull, R. B. & Bushman, B. J. Do sex and violence sell? A meta-analytic review of the effects 
of sexual and violent media and ad content on memory, attitudes, and buying intentions. 
Psychol. Bull. 141, 1022–1048 (2015).
40.	 Gaskell, G., Veltri, G. A., Lupianez-Villanueva, F., Folkvord, F. & Theben, A. The impact of 
online platform transparency of information on consumers’ choices. Behav. Public Policy 
7, 55–82 (2020).
41.	
Doshi, A. R., Dowell, G. W. & Toffel, M. W. How firms respond to mandatory information 
disclosure. Strat. Manage. J. 34, 1209–1231 (2013).
42.	 Bettinger, E., Cunha, N., Lichand, G. & Madeira, R. Are the Effects of Informational 
Interventions Driven by Salience? Working paper (Univ. of Zurich, Department of 
Economics, 2021); https://www.econ.uzh.ch/apps/workingpapers/wp/econwp350.pdf.
43.	 Hauser, D. J. & Schwarz, N. It’s a trap! Instructional manipulation checks prompt 
systematic thinking on “tricky” tasks. SAGE Open https://doi.org/10.1177/2158244015584617 
(2015).
44.	 Cabral, L. & Hortaçsu, A. The dynamics of seller reputation: evidence from Ebay. J. Ind. 
Econ. 58, 54–78 (2010).
45.	 Link, S., Peichl, A., Roth, C. & Wohlfart, J. Information frictions among firms and households. 
J. Monet. Econ. 135, 99–115 (2023).
46.	 Coibion, O., Gorodnichenko, Y. & Kumar, S. How do firms form their expectations? New 
survey evidence. Am. Econ. Rev. 108, 2671–2713 (2018).
47.	
Perloff, L. S. & Brickman, P. False consensus and false uniqueness: biases in perceptions 
of similarity. Acad. Psychol. Bull. 4, 475–494 (1982).
48.	 Kim, H. The value of competitor information: evidence from a field experiment. Acad. 
Manage. Proc. https://doi.org/10.5465/AMBPP.2021.12714abstract (2021).
49.	 Hanna, R., Mullainathan, S. & Schwartzstein, J. Learning through noticing: theory and 
evidence from a field experiment. Q. J. Econ. 129, 1311–1353 (2014).
50.	 Ocasio, W. Towards an attention-based view of the firm. Strat. Manage. J. 18, 187–206 (1997).
51.	
Ada, S., Nabout, N. A. & Feit, E. M. Context information can increase revenue in online 
display advertising auctions: evidence from a policy change. J. Market. Res. 59, 1040–1058 
(2021).
52.	 Holden, R. Google Travel: Find flights with lower carbon emissions. Google Blog https://
blog.google/products/travel/find-flights-with-lower-carbon-emissions/ (2021).
53.	 Spampatti, T., Hahnel, U. J., Trutnevyte, E. & Brosch, T. Short and long-term dominance of 
negativeinformation in shaping public energy perceptions: the case of shallow geothermal 
systems. Energy Pol. 167, 113070 (2022).
54.	 Boudreau, K. & Hagiu, A. Platforms, Markets, and Innovation (Edward Elgar, 2009).
55.	 Rietveld, J., Seamans, R. & Meggiorin, K. Market orchestrators: The effects of certification 
on platforms and their complementors. Strat. Sci. 6, 244–264 (2021).
56.	 Horwitz, J. & Hagey, K. Google’s secret ‘Project Bernanke’ revealed in Texas antitrust case. 
Wall Street Journal (11 April 2021); https://www.wsj.com/articles/googles-secret-project- 
bernanke-revealed-in-texas-antitrust-case-11618097760.
57.	
Remeikis, A. Why is Labor’s bill on combatting disinformation so controversial? The 
Guardian (1 October 2023); https://www.theguardian.com/australia-news/2023/oct/01/
why-is-labors-bill-on-combatting-disinformation-so-controversial
58.	 Faiola, A. & Kirchner, S. How do you stop fake news? In Germany, with a law. The 
Washington Post (5 April 2017) https://www.washingtonpost.com/world/europe/how-do-
you-stop-fake-news-in-germany-with-a-law/2017/04/05/e6834ad6-1a08-11e7-bcc2-
7d1a0973e7b2_story.html.
59.	 Johnson, M. Regulation by shaming: deterrence effects of publicizing violations of 
workplace safety and health laws. Am. Econ. Rev. 110, 1866–1904 (2020).
60.	 Jin, G. Z. & Leslie, P. Reputational Incentives for restaurant hygiene. Am. Econ. J. 
Microeconomics 1, 237–267 (2009).
61.	
Chopra, F., Haaland, I. & Roth, C. Do people demand fact-checked news? Evidence from 
U.S. Democrats. J. Public Econ. 205, 104549 (2022).
62.	 Allen, J., Howland, B., Mobius, M., Rothschild, D. & Watts, D. J. Evaluating the fake news 
problem at the scale of the information ecosystem. Sci. Adv. https://doi.org/10.1126/
sciadv.aay3539 (2020).
63.	 Chiou, L. & Tucker, C. Fake News and Advertising on Social Media: A Study of the 
Anti-Vaccination Movement Working Paper 25223 (National Bureau of Economic 
Research, 2018); http://www.nber.org/papers/w25223.pdf.
64.	 Doshi, A. R. & Schmidt, W. Soft governance across digital platforms using transparency. 
Strat. Sci. https://doi.org/10.1287/stsc.2023.0006 (2024).
65.	 Lougee, B. & Wallace, J. The corporate social responsibility (CSR) trend. J. Appl. Corp. 
Finance 20, 96–108 (2008).
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in 
published maps and institutional affiliations.
Open Access This article is licensed under a Creative Commons Attribution 
4.0 International License, which permits use, sharing, adaptation, distribution 
and reproduction in any medium or format, as long as you give appropriate 
credit to the original author(s) and the source, provide a link to the Creative Commons licence, 
and indicate if changes were made. The images or other third party material in this article are 
included in the article’s Creative Commons licence, unless indicated otherwise in a credit line 
to the material. If material is not included in the article’s Creative Commons licence and your 
intended use is not permitted by statutory regulation or exceeds the permitted use, you will 
need to obtain permission directly from the copyright holder. To view a copy of this licence, 
visit http://creativecommons.org/licenses/by/4.0/.
© The Author(s) 2024

Article
Methods
Background on digital advertising
The predominant business model of several mainstream digital media 
platforms relies on monetizing attention via advertising3. While these 
platforms typically offer free content and services to individual con-
sumers, they generate revenue by serving as an intermediary or adver-
tising exchange connecting advertisers with independent websites that 
want to host advertisements. To do so, platforms run online auctions 
to algorithmically distribute advertising across websites, known as 
‘programmatic advertising’. For example, Google distributes advertis-
ing in this manner to more than two million non-Google sites that are 
part of the Google Display Network. This allows websites to generate 
revenue for hosting advertising, and they share a percentage of this 
payment with the platform. In the USA, more than 80% of digital dis-
play advertisements are placed programmatically16. We refer to these 
advertising exchanges as digital advertising platforms and use the 
term digital platforms to collectively refer to all the services offered 
by such media platforms.
We examine the role of advertising companies and digital advertis-
ing platforms in monetizing online misinformation. While in other 
forms of (offline) media, advertisers typically have substantial con-
trol over where their advertisements appear, advertising placement 
through digital advertising platforms is mainly automated. Since most 
companies do not have the capacity to participate in high-frequency 
advertising auctions that require them to place individual bids for 
each advertising slot they are interested in, they typically outsource 
the bidding process to an advertising platform. Such programmatic 
advertising gives companies relatively less control over where their 
advertisements end up online. However, companies can take steps to 
reduce advertising on misinformation websites, such as by only being 
part of advertising auctions for a select list of credible websites or block-
ing advertisements from appearing on specific misinformation outlets.
Collecting website data
We collect data on misinformation websites in three steps. First, we use 
a dataset maintained by NewsGuard. This company rates all the news 
and information websites that account for 95% of online engagement 
in each of the five countries where it operates. Journalists and experi-
enced editors manually generate these ratings by reviewing news and 
information websites according to nine apolitical journalistic crite-
ria. Recent research has used this dataset to identify misinformation 
websites6,66,67. In this paper, we consider each website that NewsGuard 
rates as repeatedly publishing false content between 2019 and 2021 to 
be a misinformation website and all others to be non-misinformation 
websites, leading to a set of 1,546 misinformation websites and 6,499 
non-misinformation websites. To get coverage throughout our study 
period, we sample websites provided by NewsGuard from the start, 
middle and end of each year from 2019 to 2021. Additionally, we also 
sample websites from January 2022 and June 2022 to account for web-
sites that may have existed during our study period and discovered 
later. Supplementary Table 3 summarizes the characteristics of this 
dataset. Our NewsGuard dataset contains websites across the political 
spectrum, including left-leaning websites (for example, https://www.
palmerreport.com/ and https://occupydemocrats.com/), politically 
neutral websites (for example, https://rt.com/ and https://www.nation-
alenquirer.com), and right-leaning websites (for example, https://www.
thegatewaypundit.com/ and http://theconservativetreehouse.com/).
Note that prior research that has used the NewsGuard dataset has 
often used the term ‘untrustworthy’ to describe websites6,67. Such 
research has used NewsGuard’s aggregate classification whereby a 
site that scores below a certain threshold (60 points) on NewsGuard’s 
weighted score system is labelled as untrustworthy. Instead of using 
NewsGuard’s overall score for a website, we use the first criterion 
classified by NewsGuard for each website—that is, whether a website 
repeatedly publishes false news to identify a set of 1,546 misinformation 
websites. While 94% of the NewsGuard misinformation websites we 
identify in this manner are also untrustworthy based on NewsGuard’s 
classification, only about 52% of the untrustworthy websites are mis-
information websites or websites that repeatedly publish false news. 
Our measure of misinformation is, therefore, more conservative than 
prior work using NewsGuard’s ‘untrustworthy’ label.
In addition to the NewsGuard dataset, we use a list of websites pro-
vided by the GDI. This non-profit organization identifies disinformation 
by analysing both the content and context of a message, and how they 
are spread through networks and across platforms68. In this way, GDI 
maintains a list of monthly-updated websites, which it also shares with 
interested advertising tech platforms to help reduce advertising on mis-
information websites. The GDI list allows us to identify 1,869 additional 
misinformation websites. Finally, we augment our list of misinforma-
tion websites with 396 additional ones used in prior work69,70. Among 
the websites that NewsGuard rated as non-misinformation (at any point 
in our sample), 310 websites were considered to be misinformation 
websites by our other sources or by NewsGuard itself (during a different 
period in our sample). We categorize these websites as misinformation 
websites given their risk of producing misinformation.
Altogether, our website dataset consists of 10,310 websites, including 
3,811 misinformation and 6,499 non-misinformation websites. Similar 
to prior work6,67, our final measure of misinformation is at the level of 
the website or online news outlet. Aggregating article-level informa-
tion and using website-level metadata is meaningful since it reduces 
noise when arriving at a website-level measure. Finally, we use data 
from SEMRush, a leading online analytics platform, to determine the 
level of monthly traffic received by each website from 2019 to 2021.
Consumer experiment design
This study was reviewed by the Stanford University Institutional Review 
Board (Protocol No. IRB-63897) and the Carnegie Mellon University 
Institutional Review Board (protocol no. IRB00000603). Our study 
was pre-registered at the American Economic Association’s Registry 
under AEARCTR-0009973. Informed consent was obtained from all 
participants at the beginning of the survey.
Setting and sample recruitment. We recruited a sample of US internet 
users via CloudResearch. CloudResearch screened respondents for our 
study so that they are representative of the US population in terms of 
age, gender and race based on the US Census (2020). It is important to 
note that while we recruited our sample to be representative on these 
dimensions to improve the generalizability and external validity of our 
results, our sample is a diverse sample of US internet users, which is not 
necessarily representative of the US population on other dimensions71. 
To ensure data quality, we include a screener in our survey to check 
whether participants pay attention to the information provided. Only 
participants who pass this screener can proceed with the survey. Our 
total sample includes 4,039 participants, who are randomized into five 
groups approximately evenly.
The flow of the survey study is shown in Supplementary Fig. 1. We 
begin by asking participants to report demographics such as age, 
gender and residence. From a list of trustworthy and misinformation 
outlets, we then ask participants questions about their behaviours in 
terms of the news outlets they have used in the past 12 months, their 
trust in the media (on a 5-point scale), the online services or platforms 
they have used and the number of petitions they have signed in the 
past 12 months.
Initial gift card preferences. We then inform participants that one 
in five (that is, 20% of all respondents) who complete the survey will 
be offered a US$25 gift card from a company of their choice out of 
six company options. Respondents are asked to rank the six gift card 
companies on a scale from their first choice (most preferred) to their 

sixth choice (least preferred). These six companies belong to one of 
three categories: fast food, food delivery and ride-sharing. All six 
companies appeared on the misinformation websites in our sample 
during the past three years (2019–2021), offer items below US$25, and 
are commonly used throughout the USA. The order in which the six 
companies are presented is randomized at the respondent level. As a 
robustness check, we also ask respondents to assign weights to each 
of the six gift card options. This question gives respondents greater 
flexibility by allowing them to indicate the possibility of indifference 
(that is, equal weights) between any set of options. We then ask partici-
pants to confirm which gift card they would like to receive if they are 
selected to ensure they have consistent preferences regardless of how 
the question is asked. At this initial elicitation stage, the respondents 
did not know that they will get another chance to revise their choice. 
Hence, these choices can be thought of as capturing their revealed 
preference.
Information treatments. All participants in the experiment are given 
baseline information on misinformation and advertising. This is meant 
to ensure that all participants in our experiment are made aware of how 
we define misinformation along with examples of a few misinformation 
websites (including right-wing, neutral and left-wing misinformation 
websites), how misinformation websites are identified, and how compa-
nies advertise on misinformation websites (via an illustrative example) 
and use digital platforms to automate placing advertisements.
Participants are then randomized into one control and four treatment 
groups, in which the information treatments are all based on factual 
information from our data and prior research. We use an active control 
design to isolate the effect of providing information relevant to the 
practice of specific companies on people’s behaviour9. Participants in 
the control group are given generic information based on prior research 
that is unrelated to advertising companies or platforms but relevant 
to topic of news and misinformation.
In our first ‘company only’ treatment group (T1), participants are given 
factual information stating that advertisements from their top choice 
gift card company appeared on misinformation websites in the recent 
past. Based on their preferences, people may change their final gift card 
preference away from their initial top-ranked company after receiving 
this information. It is unclear, however, whether advertising on misin-
formation websites would cause a sufficient change in consumption 
patterns and which sets of participants may be more affected.
Our second ‘platform only’ treatment group (T2) informs partici-
pants that companies using digital advertising platforms were about 
10 times more likely to appear on misinformation websites than com-
panies that did not use such platforms in the recent past. This informa-
tion treatment measures the effects of digital advertising platforms 
in financing misinformation news outlets. Since it does not contain 
information about advertising companies, it practically serves as a 
second control group for our company-level outcome and aims to 
measure how people may respond to our platform-related outcome.
Because our descriptive data suggest that the use of digital advertis-
ing platforms amplifies advertising revenue for misinformation outlets, 
we are interested in measuring how consumers respond to a specific 
advertising company appearing on misinformation websites when 
also informed of the potential role of digital advertising platforms 
in placing companies’ advertising on misinformation websites. It is 
unclear whether consumers will attribute more blame to companies 
or advertising platforms for financing misinformation websites when 
informed about the role of the different stakeholders in this ecosystem. 
For this reason, our third ‘company and platform’ treatment (T3) com-
bines information from our first two treatments (T1 and T2). Similar 
to T1, participants are given factual information that advertisements 
from their top choice gift card company appeared on misinformation 
websites in the recent past. Additionally, we informed participants 
that their top choice company used digital advertising platforms and 
companies that used such platforms were about ten times more likely 
to appear on misinformation websites than companies that did not use 
digital advertising platforms, as mentioned in T2.
Finally, since several advertising companies appear on misinforma-
tion websites, we would like to determine whether informing consumers 
about other advertising companies also appearing on misinformation 
websites changes their response towards their top choice company. In 
our fourth company-ranking treatment (T4), participants are given 
factual information, which states that “In the recent past, ads from all six 
companies below repeatedly appeared on misinformation websites in 
the following order of intensity”, and provided with a ranking from one 
of three years in our study period—that is, 2019, 2020 or 2021. We per-
sonalize these rankings by providing truthful information based on data 
from different years in the recent past such that the respondents’ top 
gift card choice company does not appear last in the ranking (that is, is 
not the company that advertises least on misinformation websites) and 
in most cases, advertises more intensely on misinformation websites 
than its potential substitute in the same company category (for exam-
ple, fast food, food delivery or ride-sharing). Such a treatment allows us 
to measure potential differences in the direction of consumers switch-
ing their gift card choices, such as switching towards companies that 
advertise more or less intensely on misinformation websites. It could 
also give consumers reasonable deniability such as “everyone adver-
tises on misinformation websites” leading to ambiguous predictions  
about the exact impact of the treatment effect.
Outcomes. We measure two pre-registered behavioural outcomes that 
collectively allow us to measure how people respond to our informa-
tion treatments in terms of both voice and exit25. After the informa-
tion treatment, all participants are asked to make their final gift card 
choice from the same six options they were shown earlier. Our main 
outcome of interest is whether participants ‘exit’ or switch their gift 
card preference—that is, whether they select a different gift card after 
the information treatment than their top choice indicated before the 
information treatment. To ensure incentive compatibility, participants 
are (truthfully) told that those randomly selected to receive a gift card 
will be offered the gift card of their choice at the end of our study. As 
mentioned above, the probability of being randomly chosen to receive 
a gift card is 20%. We choose a high probability of receiving a gift card 
relative to other online experiments since prior work has shown that 
consumers process choice-relevant information more carefully as 
realization probability increases72. To make the gift card outcome as 
realistic as possible, we also had a large value gift card (US$25). The 
focus of our experiments is on single-shot outcomes. While it would 
have been interesting to capture longer-term effects, the cost of imple-
menting our gift card outcome for a large sample and expenditure on 
the other studies made a follow-up study cost-prohibitive.
Secondly, participants are given the option to sign one of several real 
online petitions that we made and hosted on Change.org. Participants 
can opt to sign a petition that advocates for either blocking or allow-
ing advertising on misinformation or choose not to sign any petition. 
Further, participants could choose between two petitions for blocking 
advertisements on misinformation websites, suggesting that either: 
(1) advertising companies, or (2) digital advertising platforms, need 
to block advertisements from appearing on misinformation websites. 
Overall, participants selected among the following five choices: (1) 
“Companies like X need to block their ads from appearing on misinfor-
mation websites.”, where X is their top choice gift card company; (2) 
“Companies like X need to allow their ads to appear on misinformation 
websites.”, where X is their top choice gift card company; (3) “Digital 
ad platforms used by companies need to block ads from appearing on 
misinformation websites.”; (4) “Digital ad platforms used by companies 
need to allow ads to appear on misinformation websites.”; and (5) I do 
not want to sign any petition. To track the number of petition signatures 
for each of these four petition options across our randomized groups, 

Article
we provide separate petition links to participants in each randomized 
group. We record several petition-related outcomes. First, we measure 
participants’ intention to sign a petition based on the option they select 
in this question. Participants who pass our attention check and opt to 
sign a petition are later provided with a link to their petition of choice. 
This allows tracking whether participants click on the petition link 
provided. Participants can also self-report whether they signed the 
petition. Finally, for each randomized group, we can track the total 
number of actual petition signatures.
Our petition outcomes serves two purposes. While our gift card 
outcome measures how people change their consumption behaviour in 
response to the information provided, people may also respond to our 
information treat ments in alternative ways—for example, by voicing 
their concerns or supplying information to the parties involved25,26. 
Given that the process of signing a petition is costly, participants’ 
responses to this outcome would constitute a meaningful measure 
similar to petition measures used in prior experimental work73,74. Sec-
ond, since participants must choose between signing either company 
or platform petitions, this outcome allows us to measure whether or 
not, across our treatments, people hold advertising companies more 
responsible for financing misinformation than the digital advertising 
platforms that automatically place advertisements for companies.
In addition to our behavioural outcomes, we also record partici-
pants’ stated preferences. To do so, we ask participants about their 
degree of agreement with several statements about misinformation on 
a seven-point scale ranging from ‘strongly agree’ to ‘strongly disagree’. 
These include whether they think: (1) companies have an important role 
in reducing the spread of misinformation through their advertising 
practices; and whether (2) digital platforms should give companies 
the option to avoid advertising on misinformation websites.
Heterogeneous treatment effects. We explore heterogeneity in con-
sumer responses along four pre-registered dimensions. First, prior 
research recognizes differences in the salience of prosocial motivations 
across gender75, with women being more affected by social-impact mes-
sages than men76 and more critical consumers of new media content77. 
Given these findings, we could expect female participants to be more 
strongly affected by our information treatments.
Responses to our information treatments may also differ by respond-
ents’ political orientation. According to prior research, conservatives 
are especially likely to associate the mainstream media with the term 
‘fake news’. These perceptions are generally linked to lower trust in 
media, voting for Trump, and higher belief in conspiracy theories78. 
Moreover, conservatives are more likely to consume misinformation2 
and the supply of misinformation has been found to be higher on the 
ideological right than on the left79. Consequently, we might expect 
stronger treatment effects for left-wing respondents.
Consumers who more frequently use a company’s products or ser-
vices could be presumed to be more loyal towards the company or 
derive greater utility from its use, which could limit changes in their 
behaviour37. Alternatively, more frequent consumers may be more 
strongly affected by our information treatments as they may perceive 
their usage as supporting such company practices to a greater extent 
than less frequent consumers.
Finally, we measure whether people’s responses differ by whether 
they consume misinformation themselves based on whether they 
reported using misinformation outlets in the initial question asking 
them to select which news outlets they used in the past 12 months.
Tackling experimental validity concerns. In our incentivized, online 
setting where we measure behavioural outcomes, we expect experi-
menter demand effects to be minimal as has been evidenced in the 
experimental literature80,81. We take several steps to mitigate potential 
experimenter demand effects, including implementing best prac-
tices recommended in prior work9. First, our experiment has a neutral 
framing throughout the survey since the recruitment of participants. 
While recruiting participants, we invite them to “take a survey about the 
news, technology and businesses” without making any specific refer-
ences to misinformation or its effects. While introducing misinforma-
tion websites and how they are identified by independent non-partisan 
organizations, we include examples of misinformation websites across 
the political spectrum (including both right-wing and left-wing sites) 
and provide an illustrative example of misinformation by foreign ac-
tors. In drafting the survey instruments, the phrasing of the questions 
and choices available were as neutral as possible. For example, while 
introducing our online petitions, we presented participants with the 
option to sign real petitions that suggest both blocking and allow-
ing advertising on misinformation sites. Indeed, we find that the vast 
majority of participants believe that the information provided in the 
survey was unbiased as shown in Supplementary Fig. 4. Only about 
10% of participants chose one of the ‘biased’ or ‘very biased’ options 
when asked to rate the political bias of the survey information provided 
from a seven-point scale ranging from ‘very right-wing biased’ to ‘very 
left-wing biased’.
In our active control design, participants in all randomized groups are 
presented with the same baseline information about misinformation, 
given misinformation-related information in the information interven-
tion and asked the same questions after the information intervention 
to emphasize the same topics and minimize potential differences in 
the understanding of the study across treatment groups. Moreover, 
to maximize privacy and increase truthful reporting82, respondents 
complete the surveys on their own devices without the physical pres-
ence of a researcher. We also do not collect respondents’ names or 
contact details (with the exception of eliciting emails to provide gift 
cards to participants at the end of the study).
In presenting our information interventions and measuring our 
behavioural outcomes, we take special care to not highlight the names 
of the specific entities being randomized across groups to avoid 
emphasizing what is being measured. We do, however, highlight our 
gift card incentives by putting the gift card information in bold text to 
ensure incentive compatibility since prior work has found that failing 
to make incentives conspicuous can vastly undermine their ability to 
shift behaviour83.
Apart from making the above design choices to minimize experi-
menter demand effects, we measure their relevance using a survey ques-
tion. Since demand effects are less likely a concern if participants cannot 
identify the intent of the study9, we ask participants an open-ended 
question—that is, “What do you think is the purpose of our study?”. 
Following prior work84,85, we then analyse the responses to this question 
to examine whether they differ across treatment groups. To measure 
potential differences in the respondents’ perceptions of the study, we 
examine their open-ended text responses about the purpose of the 
study using a Support Vector Machine classifier, which incorporates 
several features in text analysis, including word, character, and sentence 
counts, sentiments, topics (using Gensim) and word embeddings. 
We predict treatment status using the classifier, keeping 75% of the 
sample for the training set and the remaining 25% as the test set. The 
classifier predicts treatment status similar to chance for our main treat-
ment groups relative to the control group, as shown in Supplementary 
Table 11. These results, which are similar in magnitude to those found 
in previous research84,85, suggest that our treatments do not substan-
tially affect participants’ perceptions about the purpose of the study. 
Overall, this analysis gives us confidence that our main experimental 
findings are unlikely to be driven by experimenter demand effects.
To address external validity concerns, we incorporate additional 
exit outcomes in the paper, showing that treated individuals switched 
to lower preference products (Table 1, columns 3 and 4) and prod-
ucts across categories (Table 1, columns 5 and 6) after our informa-
tion interventions by 8 and 5 percentage points, respectively. We 
also show in Supplementary Table 8 that as the difference between 

participants’ highest weighted and second highest weighted gift card 
choice increases, their switching behaviour decreases. This shows 
that the weights assigned by participants to their gift card options are 
capturing meaningful and costly differences in value, highlighting the 
external validity of our findings. More generally, our pre-registered 
heterogeneity analysis lends credence to the study’s external validity. 
In line with expectations, we find that less frequent users and more 
politically liberal individuals are likelier to switch (see Extended Data 
Table 3 for the full set of pre-registered heterogeneity results). Moreo-
ver, we find that the cost of switching gift cards varies based on partici-
pants’ observable characteristics. For example, treated participants 
who reported not using any of the misinformation news outlets in 
our survey lost 50% of the median value (US$12.50) of their initial top 
choice gift card whereas treated participants who reported reading 
such outlets lost 33.3% of the median value (US$8.33) of their initial 
top choice gift card. Participants’ text responses also indicate that 
they believed their choices to be consequential (see Supplementary 
Tables 1 and 2). As an example, while explaining their choice of gift card, 
one participant stated, “Because I would most likely use this gift card 
on my next visit to… and it is less likely that i would use the others.” 
Regarding the petition outcome, one participant stated “The source 
of this problem seems to be from the digital advertising platforms, 
so I’d rather sign the petition that stops them from putting ads on 
misinformation websites.”
Decision-maker experiment design
We followed the same IRB review, pre-registration and consent pro-
cedures as those used for our consumer study. This study addresses 
two research questions. First, we aim to measure the existing beliefs 
and preferences decision-makers have about advertising on misin-
formation websites. This will help inform whether companies may be 
inadvertently or willingly sustaining online misinformation. Secondly, 
we ask: how do decision-makers update their beliefs and demand for 
a platform-based solution to avoid advertising on misinformation 
websites in response to information about the role of platforms in 
amplifying the financing of misinformation? This will suggest whether 
companies may be more interested in adopting advertising platforms 
that reduce the financing of misinformation. To this end, we conduct 
an information-provision experiment9. While past work has examined 
how firm behaviour regarding market decisions changes in response to 
new information48,49, it is unclear how information on the role of digital 
advertising platforms in amplifying advertising on misinformation 
would affect decision-makers’ non-market strategies.
Setting and sample recruitment. To recruit participants, we partnered 
with the executive education programmes at the Stanford Graduate 
School of Business and Heinz College at Carnegie Mellon University. We 
did so in order to survey senior managers and leaders who could influ-
ence strategic decision-making within their firms, in contrast to studies 
relying heavily on MBA students for understanding decision-making 
in various contexts such as competition, pricing, strategic alliances 
and marketing86–89. Additionally, partnering with two university pro-
grammes instead of a specific firm allowed us to access a more diverse 
sample of companies than prior work that sampled specific types of 
firms—for example, innovative firms, startups or small businesses90–92. 
Throughout this study, we use the preferences of decision-makers (for 
example, chief executive officers) as a proxy for company-level prefer-
ences since people in such roles shape the outcomes of their companies 
through their strategic decisions93,94.
Our partner organizations sent emails to their alumni on our behalf. 
We used neutral language in our study recruitment emails to attract a 
broad audience of participants to our survey regardless of their initial 
beliefs and concerns about misinformation, stating our goal as “con-
ducting vital research on the role of digital technologies in impacting 
your organization” without mentioning misinformation. We received 
567 complete responses, of which 90% are kept since they are from 
currently employed respondents. To ensure data quality, we dropped 
an additional 13% of responses where participants were inattentive in 
answering the survey, resulting in a final sample of 442 responses. These 
participants were determined to be inattentive since they provided an 
answer greater than 100 when asked to estimate a number out of 100 
in the two questions eliciting their prior beliefs about companies and 
platforms before the information treatment was provided. Our final 
sample of 442 respondents is from companies that span all the 23 indus-
tries in our descriptive analysis. Moreover, as shown in Supplementary 
Fig. 5, our sample of participants represents a broad array of company 
sizes and experience levels at their current roles. Additionally, about 
22% of the executives in our sample (and 25% of all our participants) 
are women, which is aligned with the 21% to 26% industry estimates of 
women in senior roles globally95,96.
Supplementary Fig. 2 shows the design of the survey study. We first 
elicit participants’ current employment status. All those working in 
some capacity are allowed to continue the survey, whereas the rest 
of the participants are screened out. After asking for their main occu-
pation, all participants in the experiment are provided with baseline 
information on misinformation and advertising similar to that provided 
in the consumer experiment.
Baseline beliefs and preferences.  In our pre-registration, we high-
lighted that we would measure the baseline beliefs and preferences 
of decision-makers. We measure participants’ baseline beliefs about 
the roles of companies in general, their own company and platforms 
in general in financing misinformation. Specifically, participants are 
asked to estimate the number of companies among the most active 
100 advertisers whose advertisements appeared on misinformation 
websites during the past three years (2019–2021). Additionally, we ask 
participants to report whether they think their company or organiza-
tion had its advertisements appear on misinformation websites in 
the past three years. Finally, we measure participants’ beliefs about 
the role of digital advertising platforms in placing advertisements on 
misinformation websites. To do so, we first inform participants that dur-
ing the past three years (2019–2021), out of every 100 companies that 
did not use digital advertising platforms, eight companies appeared 
on misinformation websites on average. We then asked participants 
to provide their best estimate for the number of companies whose 
advertisements appeared on misinformation websites out of every 
100 companies that did use digital advertising platforms.
In addition to recording participants’ stated preferences using 
self-reported survey measures, we measure participants’ revealed 
preferences. To ensure incentive compatibility, participants are asked 
three questions in a randomized order: (1) information demand about 
consumer responses—that is, whether they would like to learn how 
consumers respond to companies whose advertisements appear on 
misinformation websites (based on our consumer survey experiment); 
(2) advertisement check—that is, whether they would like to know about 
their own company’s advertisements appearing on misinformation 
websites in the recent past; and (3) demand for a solution—that is, 
whether they would like to sign up for a 15-minute information session 
on how companies can manage where their advertisements appear 
online. Participants are told they can receive information about con-
sumer responses at the end of the study if they opt to receive it whereas 
the advertisement check and solution information are provided as a 
follow-up after the survey. Participants are required to provide their 
emails and company name for the advertisement check. To sign up 
for an information session from our industry partner on a potential 
solution to avoid advertising on misinformation websites, participants 
sign up on a separate form by providing their emails. Since all three 
types of information offered are novel and otherwise costly to obtain, 
we expect respondents’ demand for such information to capture their 
revealed preferences.

Article
Information intervention. Participants are then randomized into a 
treatment group, which receives information about the role of digital 
advertising platforms in placing advertising on misinformation web-
sites, and a control group, which does not receive this information. 
Based on the dataset we assembled, participants are given factual 
information that companies that used digital advertising platforms 
were about ten times more likely to appear on misinformation web-
sites than companies that did not use such platforms in the recent 
past. This information is identical to the information provided to 
participants in the T2 (that is, platform only) group in the consumer 
experiment.
Outcomes. After the information intervention, we first measure partici-
pants’ posterior beliefs about the role of digital advertising platforms 
in placing advertisements on misinformation websites following our 
pre-registration. Participants are told about the average number of 
companies whose advertisements appear per month on misinforma-
tion websites that are not monetized by digital advertising platforms. 
They are then asked to estimate the average number of companies 
whose advertisements appear monthly on misinformation websites 
that use digital advertising platforms. This question measures whether 
participants believe that the use of digital advertising platforms ampli-
fies advertising on misinformation websites.
We record two behavioural outcomes, which were pre-registered 
as our primary outcomes of interest after the information interven-
tion. Our main outcome of interest is the respondents’ demand for 
a platform-based solution to avoid advertising on misinformation 
websites. Participants can opt to learn more about two different types 
of information—that is: (1) which platforms least frequently place 
companies’ advertising on misinformation websites; and (2) which 
types of analytics technologies are used to improve advertising perfor-
mance—or opt not to receive any information. Since participants can 
only opt to receive one of the two types of information, this question 
is meant to capture the trade-off between respondents’ concern for 
avoiding misinformation outlets and their desire to improve advertis-
ing performance, respectively. Participants are told that they will be 
provided with the information they choose at the end of this study. 
Following the literature in measuring information acquisition97, we 
measure respondents’ demand for solution information, which serves 
as a revealed-preference proxy for their interest in implementing a 
solution for their organization.
Additionally, to measure whether the information treatment 
increases concern for financing misinformation in general, we record 
a second behavioural measure. Participants are told that the research 
team will donate US$100 to one of two organizations after randomly 
selecting one of the first hundred responses: (1) the GDI; and (2) Data-
Kind, which helps mission-driven organizations increase their impact 
by unlocking their data science potential ethically and responsibly.
Tackling experimental validity concerns. Similarly to our consumer 
experiment, this survey was carried out in an online setting, where ex-
perimenter demand effects are limited80,81. We followed best practices9 
by keeping the treatment language neutral and ensuring the anonymity 
of the participants wherever possible. We find that most participants 
believe that the information provided in the survey was unbiased. Only 
about 7% of participants chose one of the ‘biased’ or ‘very biased’ op-
tions when asked to rate the political bias of the survey information 
provided from a seven-point scale ranging from ‘very right-wing biased’ 
to ‘very left-wing biased’.
Importantly, to ensure truthful reporting, our main experimental 
outcomes were incentive-compatible. In particular, respondents 
who chose our platform solution demand outcome to learn about 
which platforms least contribute to placing companies’ advertise-
ments on misinformation websites had to face a trade-off between 
receiving this information and receiving information on improving 
advertising performance. Additionally, our baseline information 
demand outcomes elicited before the information intervention were 
also incentive-compatible in that participants would be asked to follow 
up on their decisions whether they opted for additional information 
via email or via an online information session.
These design choices are made to minimize demand effects on our 
main outcomes of interest. However, it is possible that these effects 
are still relevant, partially because participants may have an interest 
in ‘doing the right thing’ on a survey administered by an institution 
they have a connection with. We measure the relevance of potential 
demand effects using a survey question mirroring the approach used 
for our consumer experiment. To measure potential differences in 
the respondents’ perceptions of the study across our treatment and 
control groups, we predict treatment status based on respondents’ 
open-ended text responses about the purpose of the study via a support 
vector machine classifier, keeping 75% of the sample for the training 
set and the remaining 25% as the test set. We find that the classifier 
is only slightly worse than random chance in predicting treatment 
status (Supplementary Table 16) but similar in magnitude to those in 
the consumer experiment. Therefore, although experimenter demand 
effects may still be present, these results suggest that these effects do 
not drive our findings.
We address the external validity of our findings by verifying the 
decision-making capacity of our respondents within their organizations 
and by examining the generalizability of our sample. We find that the 
vast majority of those whose job titles we verify (94%) serve in executive 
or managerial roles within their organizations. The regression estimates 
in Supplementary Tables 18 and 19 show that our results remain qualita-
tively and quantitatively similar after the exclusion of the small sample 
of individuals in non-executive and non-managerial roles. Moreover, the 
verified and self-reported decision-makers are similar across observ-
able characteristics as reported in Supplementary Table 17, suggesting 
limited selection in our verification process. To examine the generaliz-
ability of our sample, we investigate their observable characteristics. As 
shown in Supplementary Fig. 5, our sample of participants represents 
a broad array of company sizes and experience levels at their current 
roles. Additionally, about 22% of the executives in our sample (and 25% 
of all our participants) are women, which is aligned with the 21% to 26% 
industry estimates of women in senior roles globally95,96.
Reporting summary
Further information on research design is available in the Nature Portfolio 
Reporting Summary linked to this article.
Data availability
Our study was pre-registered at the American Economic Associa-
tion’s Registry under AEARCTR-0009973. The data that we collected 
for our experimental studies are available in anonymized form 
and can be accessed from https://github.com/wajeeha-ahmad/
misinformation-advertising. Data on job titles for the second survey 
experiment are not available, to protect participant confidentiality. 
Data analysing the descriptive analysis of advertising on misinforma-
tion websites can be made available after obtaining permission from 
the proprietary sources on misinformation domains (NewsGuard 
and the GDI) and advertising (Oracle). Source data are provided with 
this paper.
Code availability
Code supporting the findings of the paper is available at https://github.
com/wajeeha-ahmad/misinformation-advertising. Code analysing the 
descriptive analysis of advertising on misinformation websites can 
be made available after obtaining permission from the proprietary 
sources.
 

66.	 Bhadani, S. et al. Political audience diversity and news reliability in algorithmic ranking. 
Nat. Hum. Behav. 6, 495–505, (2022).
67.	
Moore, R. C., Dahlke, R. & Hancock, J. T. Exposure to untrustworthy websites in the 2020 
US election. Nat. Hum. Behav. 7, 1096–1105 (2023).
68.	 Decker, B. Adversarial narratives: a new model for disinformation. Global Disinformation 
Index https://www.disinformationindex.org/research/2019-4-1-adversarial-narratives-a-ne
w-model-for-disinformation/ (2019).
69.	 Grinberg, N., Friedland, L., Swire-Thompson, B. & Lazer, D. Fake news on Twitter during 
the 2016 U.S. presidential election. Science 363, 374–378 (2019).
70.	 Allcott, H., Gentzkow, M. & Yu, C. Trends in the diffusion of misinformation on social 
media. Res. Politics https://doi.org/10.1177/2053168019848554 (2019).
71.	
Coppock, A. & McClellan, O. A. Validating the demographic, political, psychological, and 
experimental results obtained from a new source of online survey respondents. Res. Politics 
https://doi.org/10.1177/2053168018822174 (2019).
72.	
Cao, X. & Zhang, J. Preference learning and demand forecast. Market. Sci, 40, 62–79 (2021).
73.	 Grigorieff, A., Roth, C. & Ubfal, D. Does information change attitudes toward immigrants? 
Demography 57, 1117–1143 (2020).
74.	 Haaland, I. & Roth, C. Labor market concerns and support for immigration. J. Public Econ. 
191, 104256 (2020).
75.	
Falk, A. et al. Global evidence on economic preferences. Q. J. Econ. 133, 1645–1692 (2018).
76.	 Guzman, J., Oh, J. J. & Sen, A. What motivates innovative entrepreneurs? Evidence from a 
global field experiment. Manage. Sci. 66, 4808–4819 (2020).
77.	
Xiao, X., Su, Y. & Lee, D. K. L. Who consumes new media content more wisely? Examining 
personality factors, SNS use, and new media literacy in the era of misinformation. Soc. 
Media Soc. https://doi.org/10.1177/2056305121990635 (2021).
78.	 Van der Linden, S., Panagopoulos, C. & Roozenbeek, J. You are fake news: political bias in 
perceptions of fake news. Media Cult. Soc. 42, 460–470 (2020).
79.	 Garrett, R. K. & Bond, R. M. Conservatives’ susceptibility to political misperceptions. Sci. 
Adv. https://doi.org/10.1126/sciadv.abf1234 (2021).
80.	 Mummolo, J. & Peterson, E. Demand effects in survey experiments: an empirical assessment. 
Am. Polit. Sci. Rev. 113, 517–529 (2019).
81.	
De Quidt, J., Haushofer, J. & Roth, C. Measuring and bounding experimenter demand. Am. 
Econ. Rev. 108, 3266–3302 (2018).
82.	 Ong, A. D. & Weiss, D. J. The impact of anonymity on responses to sensitive questions.  
J. Appl. Soc. Psychol. 30, 1691–1708 (2000).
83.	 John, L. K., Blunden, H., Milkman, K. L., Foschini, L. & Tuckfield, B. The limits of 
inconspicuous incentives. Organ. Behav. Hum. Decis. Process. 172, 104180 (2022).
84.	 Bursztyn, L., Haaland, I. K., Rao, A. & Roth, C. P. Disguising Prejudice: Popular Rationales as 
Excuses for Intolerant Expression (Univ. of Warwick, Department of Economics, 2021); 
https://ideas.repec.org/p/wrk/warwec/1340.html
85.	 Song, L. The heterogeneous effects of social media content on racial attitudes. Working 
paper (2022); https://www.dropbox.com/s/f48vgfadd23226r/TwitterDiversity.pdf?dl=0.
86.	 Mintz, O. & Currim, I. S. What drives managerial use of marketing and financial metrics and 
does metric use affect performance of marketing-mix activities? J. Market. 77, 17–40 (2013).
87.	
Shah, R. H. & Swaminathan, V. Factors influencing partner selection in strategic alliances: 
the moderating role of alliance context. Strat. Manage. J. 29, 471–494 (2008).
88.	 Dyer, J. H., Gregersen, H. B. & Christensen, C. Entrepreneur behaviors, opportunity 
recognition, and the origins of innovative ventures. Strat. Entrep. J. 2, 317–338 (2008).
89.	 Montgomery, D. B., Moore, M. C. & Urbany, J. E. Reasoning about competitive reactions: 
evidence from executives. Market. Sci. 24, 138–149 (2005).
90.	 Alekseev, G. et al. The effects of COVID-19 on U.S. small businesses: evidence from owners, 
managers, and employees. Manage. Sci. 69, 7–24 (2022).
91.	
Bessen, J., Impink, S. M., Reichensperger, L. & Seamans, R. The role of data for AI startup 
growth. Res. Policy 51, 104513 (2022).
92.	 Kerr, S. P., Kerr, W. R. & Dalton, M. Risk attitudes and personality traits of entrepreneurs 
and venture team members. Proc. Natl Acad. Sci. USA 116, 17712–17716 (2019).
93.	 Bertrand, M. & Schoar, A. Managing with style: the effect of managers on firm policies.  
Q. J. Econ. 118, 1169–1208 (2003).
94.	 Porter, M. E. Competitive Strategy Techniques for Analyzing Industries and Competitors 
(Free Press, 1980).
95.	 Women in the Workplace 2022 (LeanIn.org and McKinsey, 2022); https://
womenintheworkplace.com/2022.
96.	 Women in Business 2021: A Window of Opportunity (Grant Thornton, 2021); https://www.
grantthornton.global/globalassets/1.-member-firms/global/insights/
women-in-business/2021/grant-thornton-women-in-business-report-2021.pdf.
97.	
Capozza, F., Haaland, I., Roth, C. & Wohlfart, J. Studying information acquisition in the field: 
a practical guide and review. Working paper (Department of Economics, University of 
Copenhagen, 2021); https://www.econstor.eu/bitstream/10419/258958/1/cebi-wp2115.pdf.
Acknowledgements The authors thank their data partners (NewsGuard, the GDI and Oracle) 
for sharing data; the executive education programmes at the Stanford Graduate School of 
Business and Heinz College at Carnegie Mellon University for partnership; T. Le for providing 
research assistance on part of this work; G. Jin, J. Wu, M. Liu, M. Collis, M. Gentzkow, P. 
Schwardmann, R. J. Duran, R. Moore, R. Appel, S. Agarwal, S. Borwankar and W. Lee for 
feedback and comments on earlier versions of this work; and participants at the Queen’s 
Workshop on the Economics of Media 2022, 2022 MIT Conference on Digital Experimentation, 
Workshop on Information Systems Economics 2022, Rotman School of Management PhD 
Strategy Seminar 2023, ISMS Marketing Science Conference 2023, The Sumantra Ghoshal 
Conference at London Business School 2023, Platform Strategy Research Symposium at 
Boston University 2023, NBER SI 2023 Digital Economics and Artificial Intelligence, Social 
Science Research Council Workshop on the Economics of Social Media 2023, West Coast 
Research Symposium 2023, Stanford University Trust and Safety Research Conference 2023, 
Conference on Information Systems and Technology 2023, HKU Business School Management 
and Strategy Seminar 2023, and Boston University Online Research Seminar on Digital 
Businesses 2024. This research was supported in part by the Stanford Digital Economy Lab, 
Stanford McCoy Family Center for Ethics in Society, Stanford Impact Labs, Stanford 
Technology Ventures Program, Project Liberty Institute and the Economics of Digital Services 
initiative at the University of Pennsylvania.
Author contributions W.A. conceived the research and collected the descriptive data. W.A. 
and A.S. designed the survey experiments. W.A. conducted the consumer and decision-maker 
experiments. W.A. analysed the descriptive and experimental data for all three studies, with 
A.S. aiding in research conceptualization and data analysis. W.A. wrote the paper with input 
from A.S. W.A., A.S. and C.E. edited the paper. A.S., E.B. and C.E. supervised the work. All 
authors secured grant financing and partnerships, made revisions and approved the final 
manuscript.
Competing interests W.A. was a research intern at Microsoft during summer 2023. The other 
authors declare no competing interests.
Additional information
Supplementary information The online version contains supplementary material available at 
https://doi.org/10.1038/s41586-024-07404-1.
Correspondence and requests for materials should be addressed to Wajeeha Ahmad.
Peer review information Nature thanks the anonymous reviewer(s) for their contribution to the 
peer review of this work. Peer review reports are available.
Reprints and permissions information is available at http://www.nature.com/reprints.

Article
Extended Data Fig. 1 | Text Explanation Clustering by Randomized 
Treatment Group. Notes: This figure plots regression coefficients from OLS 
regressions of an indicator for cluster membership on each randomized group. 
Results are shown for our primary model specification, which controls for 
participants’ demographic and behavioral characteristics (see Supplementary 
Information, “Analysis: Consumer study outcomes”). Data are presented as 
coefficients with the horizontal bars representing 95% confidence intervals 
derived from robust standard errors. The topics along the y-axes are binary 
variables that take value 1 if a participant’s response is classified into the given 
topic and zero otherwise. Details about the text analyses are mentioned 
in Supplementary Information and sample text responses are shown in Tables 
A1 and A2. Figure (a) shows OLS regression results for text analysis on the 
open-ended reasons participants mentioned while explaining their choice of 
gift card (n = 4039). Figure (b) shows OLS regression results for text analysis on 
the open-ended reasons participants mentioned while explaining their choice 
of online petition to sign (n = 4039).

Extended Data Fig. 2 | Weights Assigned by Treated Participants to their 
Initial and Final Gift Card Choices. Notes: This figure shows the distribution 
of weights assigned by treated participants (i.e. those in randomized treatments 
T1, T3 or T4) to their top choice gift card before and after receiving the information 
treatment. The mean weight drops from 39.11 to 23.71 after receiving the 
information treatment, representing a 39.4% decline in the mean gift card value. 
The median weight drops from 35.0 to 20.0 after receiving the information 
treatment, representing a 42.9% decline in the median gift card value.

Article
Extended Data Fig. 3 | Delta Values by Treatment Group and Type of Voice Outcome. Notes: The delta value reported here represents the difference between 
the proportion of a particular outcome variable and the proportion of actual recorded signatures for each treatment group.

Extended Data Fig. 4 | Verified job titles of participants in our second 
survey experiment by category. Notes: This figure shows the job titles of the 
sub-sample of participants (N = 316) whose job titles we were able to verify from 
external sources, e.g., LinkedIn, Crunchbase, etc. The size of each word 
corresponds to its frequency of appearance in our sample.

Article
Extended Data Table 1 | Top 100 advertisers’ activity on misinformation websites
This table shows regression results for the top 100 most active advertisers in a given year based on weekly data collected for the years 2019 to 2021 (n = 11, 969). In Columns (1)-(3), we show 
results from logit regressions where the dependent variable is appears on misinformation websites, a binary variable that takes value 1 when an advertiser appears on a misinformation website 
in a given week and zero otherwise. In Columns (4)-(6), we show results from poisson regressions where the dependent variable is number of misinformation websites, a continuous variable 
for the number of misinformation websites an advertiser appears on in a given week. Digital platform usage is a binary variable that takes value 1 when a company is using digital advertising 
platforms in a given week and zero otherwise. No adjustments were made for multiple comparisons. Robust standard errors in parentheses. P-values derived from two-sided t-tests reported 
below standard errors.

Extended Data Table 2 | Comparison of responses across all petition outcomes
Notes: This table shows OLS regression results for each of the four treatment groups (T1, T2, T3 and T4) across all of our petition outcomes. Columns (1) to (4) refer to company-specific petitions 
suggesting that companies like the respondent’s top choice gift card company need to block their advertisements from appearing on misinformation websites. Columns (5) to (8) refer to 
platform-specific petitions suggesting that digital advertising platforms used by companies need to block advertisements from appearing on misinformation websites. In columns (1) and (5), 
the dependent variable is the intention to sign a petition, a binary variable that takes the value 1 when a participant indicates wanting to sign a given petition and zero otherwise (n = 4039). In col-
umns (2) and (6), the dependent variable is a click on the petition link that takes the user to the Change.org platform to sign a petition, a binary variable that takes the value 1 when a participant 
clicks on the link and zero otherwise (n = 4039). In columns (3) and (7), the dependent variable is the self-reported petition signature, a binary variable that takes the value 1 when a participant 
reports having signed a given petition and zero otherwise (n = 4039). We record actual petition signatures in columns (4) and (8); we omit signatures for the T4 group since these petitions were 
accidentally deleted by Change.org (n = 3225). Since we only observe actual signatures on the treatment group level, we cannot include controls and run regressions for these outcomes. To do 
testing, we calculate standard errors using the standard formula for (two-sided) proportion tests. For the remaining columns, we apply robust standard errors in parentheses. No adjustments 
were made for multiple comparisons. P-values derived from two-sided t-tests reported below standard errors.

Article
Extended Data Table 3 | Heterogeneous Treatment Effects for Exit and Voice
Notes: This table shows OLS regression results for our full sample (n = 4039) where Treatment is a binary variable that takes a value of 1 if a respondent is randomized into any of the 
company-specific treatment groups (T1, T3 or T4) and zero otherwise. In columns 1 to 4, the dependent variable is switch in gift card choice from the respondent’s top choice company (i.e. 
“exit”). In columns 5 to 8, the dependent variable is clicking on a link to sign a petition that suggests that companies like the respondent’s top choice gift card company need to block their 
advertisements from appearing on misinformation websites. Female is a binary variable that takes a value of 1 if a respondent reports being female and zero otherwise. Biden voter is a binary 
variable that takes a value of 1 if a respondent reported voting for President Biden in the 2020 US Presidential election and zero otherwise. Frequent user is a binary variable that takes a value of 
1 if a respondent reported using their top choice gift card at least once a month. Consumes misinformation is a binary variable that takes a value of 1 if a respondent reported using one or more 
misinformation news outlets (out of a list of 26 popular news outlets) in the past 12 months and zero otherwise. No adjustments were made for multiple comparisons. Robust standard errors in 
parentheses. P-values derived from two-sided t-tests reported below standard errors.

Extended Data Table 4 | Decision-makers’ Beliefs and Characteristics about Advertising on Misinformation Websites
Notes: This table shows respondents’ beliefs and characteristics about their own company advertising on misinformation outlets. Column (1) shows results for the full sample (n = 442), Column 
(2) for the sub-sample of executives (n = 248), Column 3 for the sub-sample of managers (n = 147), and Column 4 for the remaining individuals (n = 47). The proportions in rows marked with an 
asterisk (*) are calculated based on the subsample of participants who requested an ad check and whose companies appeared in our advertising data (n = 106) in Column (1).





