Arenberg Doctoraatsschool Wetenschap & Technologie 
Faculteit Ingenieurswetenschappen 
Departement Werktuigkunde
Rigorously Bayesian Multitarget Tracking
and Localization
Proefschrift voorgedragen 
tot het behalen van de 
graad van Doctor in de 
Ingenieurswetenschappen
Mei 2010
2010D10
Jury
Prof. dr. ir. Hugo Hens (voorzitter)
Prof. dr. ir. Herman Bruyninckx (promotor)
Prof. dr. ir. Joris De Schutter (promotor)
Prof. dr. ir. Tinne Tuytelaars
Prof. dr. Désiré Bollé
Prof. dr. Luc De Raedt
Prof. dr. Justus Piater
         (Université de Liège)
Tinne DE LAET
 
 

© Katholieke Universiteit Leuven – Faculty of Engineering
Kasteelpark Arenberg 1, B-3001 Leuven (Belgium)
Alle rechten voorbehouden. Niets uit deze uitgave mag worden vermenigvuldigd
en/of openbaar gemaakt worden door middel van druk, fotokopie, microﬁlm,
elektronisch of op welke andere wĳze ook zonder voorafgaande schriftelĳke
toestemming van de uitgever.
All rights reserved. No part of the publication may be reproduced in any form
by print, photoprint, microﬁlm or any other means without written permission
from the publisher.
D/2010/7515/48
ISBN 978-94-6018-209-9

Dank u wel!
Toen ik aan mĳn ingenieursstudies begon, heb ik nooit durven denken dat
mĳn verblĳf in Leuven zoveel langer zou duren dan vĳf jaar. Na de eerste
maanden van ontzag en knikkende knieën heeft de schoonheid van de toegepaste
wetenschappen mĳ aangezet om met volle moed en steeds grotere honger naar
kennis de kandidaturen te voltooien. Mechanica, de mooiste aller disciplines,
is vervolgens de richting van mĳn ingenieursjaren geworden. Studeren is echter
zoveel meer dan ‘blokken’: de vrienden die zelfs de minst leuke aspecten aan
het studeren altĳd snel deden vergeten (bedankt Bart, Bert, Katrien, Lien,
Friedl, Liesbeth, . . . ), de stimulerende samenwerking met Friedl met wie ik een
onafscheidelĳk duo heb gevormd voor alle werkjes (en thesis) vanaf de tweede
kandidatuur, . . .
Dan was er nog de plotse afstand van Hans die de overgang
van de middelbaar school naar Leuven had gecreëerd: van naast elkaar in de
klas in het middelbaar naar plots een andere groep en aula op de universiteit.
Het is deze afstand, Hans, die mĳ bewust gemaakt heeft van mĳn liefde voor
jou, die nog steeds onverminderd voortduurt.
Na het beëindigen van de ingenieursstudies was de honger naar kennis niet
verminderd en bovendien had mĳn thesis de onderzoekster in mĳ wakker
gemaakt. Ik was vereerd dat professor De Schutter en Bruyninckx, ondertussen
Joris en Herman, mĳ aanboden om onder hun vleugels een doctoraat te maken.
Dankzĳ de begeleiding die Friedl en ik van Joris hebben mogen genieten tĳdens
de werkjes en het vakantiewerk en het onaﬂatende enthousiasme van Herman,
heb ik niet lang moeten twĳfelen over mĳn antwoord.
Zo geschiedde mĳn
aantreden in augustus 2005 op PMA. Tĳdens de ganse duur van mĳn doctoraat
was ik aspirant van het Fonds voor Wetenschappelĳk Onderzoek - Vlaanderen.
Bedankt FWO voor de ﬁnanciële middelen die mĳn onderzoek mogelĳk hebben
gemaakt.
Ik wil Herman en Joris bedanken voor de begeleiding gedurende de vier en een
half jaar van mĳn doctoraat. Joris, bedankt voor de vliegende start die ik heb
kunnen nemen dankzĳ de kans om mee te werken aan iTaSC, bedankt voor alle
constructieve feedback op mĳn werk, en bedankt om mĳ te helpen in mĳn strĳd
i

ii
Dankwoord
met het schrĳven van Engelse teksten. Herman, bedankt voor alle ideeën en om
mĳ te betrekken bĳ interessante onderzoeksprojecten. Daarenboven wil ik mĳn
jury bedanken voor het nalezen van mĳn doctoraatstekst en voor de uitdagende
discussie tĳdens de preliminaire verdediging. Thanks, professor Piater for your
thorough analysis of my PhD text and for all the good suggestions concerning
the text and my research.
Dankzĳ de collega’s in de robot onderzoeksgroep is mĳn doctoraat nooit
geworden tot de eenzame bezigheid waar het soms voor versleten wordt. Eerst
en vooral was er, en is er nog steeds, Ruben, die de personiﬁcatie is van het
spreekwoord ‘van aanpakken weten’. Ruben, het bloed, zweet en tranen die we
gelaten hebben tĳdens het realiseren van de ‘open house demo’ werden draaglĳk
door het samen vloeken, klagen, en toch . . . lachen. Dan is er natuurlĳk ‘ome’
Wilm, die ondanks zĳn inertie, meer is dan de jongen die tegenover mĳ zit
en daarom zelfs tot het onderwerp is geëvolueerd van het lievelingsliedje van
mĳn zoontje (Op ome Wilms boerderĳ, . . . ). Stille, bescheiden Diederik, die
meerdere ‘onderzoeksdoorbraken kon forceren’ en toch met beide voetjes op
de (bĳ voorkeur West-Vlaamse) grond bleef staan. Optimist en globetrotter
Kasper, die altĳd openstond voor een goed gesprek of gewoon een gezellige
babbel. Het olĳke trio Wim, Johan en Peter Sl., die een tripje naar de overkant
van de gang, zelfs al zouden ze mĳn programmeerproblemen niet opgelost
hebben, toch steevast de moeite waard maakten.
Peter So., de ontwerper
van Orocos, op wie je nooit lang kan boos blĳven, zelfs nadat een nieuwe
release al je applicaties onbruikbaar maakte. Peter, sorry voor de ‘angry user
feedback’, ik zal het bĳ deze proberen goed te maken: LEVE OROCOS! Klaas,
die niet alleen BFL aan mĳ heeft nagelaten, maar ook steeds beschikbaar was
voor een goede discussie bĳ een alma-etentje. ‘The new guys’, Nick, Steven,
Koen en Hans, die me ondanks het feit dat ze me toch wat oud doen voelen,
ervoor zorgen dat opvolging (en goede sfeer in ons bureau) verzekerd is. Our
international oﬃce mates who provided me with a touch of internationalism
while just sitting in front of my computer: thanks Markus, for your German
‘grundlichkeit’, your advice and helping hand; thanks Enrico, for your Italian
spaghetti sauce and good discussion on estimation problems; thanks Hugo,
for your American burgers and enthousiasm; and thanks Lin, for you Asian
kindness and eagerness to learn. Bedankt René voor de interessante discussies
tĳdens je verblĳf van drie maanden in onze groep.
Niet alleen de mensen van de robotgroep hebben de Celestĳnenlaan 300B
tot meer dan een werkplek gemaakt.
Tĳdens de lunchpauzes, koﬃepauzes,
PMA-weekends, happy hours, . . . waren er altĳd collega’s om mee te babbelen:
bedankt Alex, Anke, Bert St., Bert VG., Bram, Clara, Dirk B., Dries, Duc, Eric,
Goele, Jan P., Jan Sw., Karin, Kris D., Lieve, Maarten W., Manu, Marnix
V., Michael (Shu), Myriam, Paul V., Tobias, Ton, en alle andere collega’s
die ik heb nagelaten te bedanken. Alex, thanks for all the fun moments and

Dankwoord
iii
especially those of joint study and relaxing during the summer school. Ook
een welgemeende dankuwel aan alle mensen van het secretariaat, de dienst
informatica en de werkplaats. Verder wil ik expliciet Karin en Lieve bedanken
voor de steun bĳ alle praktische dingen die bĳ een doctoraat komen kĳken en
om PMA een beetje als ‘thuis’ te doen voelen.
Bedankt Friedl, om steeds mĳn koppigheid te trotseren tĳdens onze veelvuldige
samenwerkingen en omdat ik je steeds mag lastigvallen om mĳn hart te luchten
of gewoon voor een gezellige babbel.
Monique en Eric, bedankt om alle mythes over schoonouders te ontkrachten
en oprecht geïnteresseerd te zĳn in mĳn werk. Bedankt schoonzusjes Leen en
Greet, om mĳ welkom te doen voelen in de familie Van Dommelen.
Bedankt Lieze, die is geëvolueerd van het 9 jarige meisje dat mĳ een ‘een goed
leven’ wenste op kot in Leuven, tot de studente die nu bĳ ons op kot zit, om
mĳ een grote wĳze zus te doen voelen. Bedankt broers Hannes en Jeroen, en
schoonzus Stefanie om ons gezin compleet te maken. Mama en papa, bedankt
voor de warme thuis, alle kansen die jullie mĳ hebben gegeven en voor alle hulp
en opvang van Siemen op momenten dat het allemaal wat moeilĳk was (in het
bĳzonder tĳdens mĳn longonsteking in de eindfase van mĳn doctoraat)!
Hans, bedankt voor alle steun en liefde, zelfs tĳdens de moeilĳke momenten.
Siemen, mĳn zonnetje, bedankt om mĳ te tonen wat echt belangrĳk is.
Tinne De Laet,
Heverlee, mei 2010.

Abstract
Robots are moving towards uncertain, cluttered and human-populated en-
vironments, both in industrial and domestic settings.
Therefore, robots
have to be intelligent: they have to be able to handle the uncertainty and
the dynamics of this uncertainty associated with real-world environments.
This thesis focuses on one aspect of cognitive robot systems: the tracking
and localization of targets.
In future cognitive robot systems, multitarget
tracking and localization (MTTL) algorithms will be a basic tool since the
robot’s awareness of targets, and especially persons, in its environment is
essential for safety and a prerequisite for intelligent human-robot interaction
and cooperation. This thesis aims at developing MTTL algorithms that are
suited for online estimation of both the number of targets and the states of
these targets.
To this end this thesis uses Bayesian probability theory to
estimate the unknown variables underlying the MTTL problem.
The term
‘rigorously Bayesian’ in the title of this thesis refers to the fact that all unknown
variables are estimated using fully Bayesian methods, and that all trade-oﬀs
and assumptions are made explicit, for instance in the form of a Bayesian prior.
This thesis contains four contributions to the MTTL research domain:
• Probabilistic measurement models are an important building block of
Bayesian methods. It is of vital importance that all types of uncertainty
aﬀecting the measurements are accounted for in the probabilistic
measurement model. Especially the dynamic nature of the environment,
stemming from unmodeled and moving objects and people, is an
important source of inaccuracies.
Therefore, this thesis proposes a
Bayesian network model for range ﬁnders suited for dynamic
environments, together with learning algorithms to learn the
measurement model parameters from experimental data.
• A large number of MTTL algorithms are available in literature. This
thesis reviews the important state-of-the-art MTTL algorithms
and classiﬁes them. By formulating the algorithms in a uniﬁed
framework using the same terminology and symbols and by
iv

Abstract
v
analyzing their Bayesian network representation, this thesis
compares the diﬀerent algorithms and reveals the underlying
assumptions.
• Existing state-of-the-art MTTL algorithms are often limited to cases
where a target generates at most one measurement at a given time
instant.
To circumvent this limitation, these algorithms are preceded
by a measurement preprocessing step that groups measurements into
features.
Summarizing individual measurements into features results
in information loss. This thesis presents an online two-level MTTL
algorithm that avoids this information loss, while being able
to
track
and
localize
a
variable
number
of
targets,
and
while maintaining correct target identiﬁcation throughout the
tracking. The proposed MTTL algorithm shows how the target shape
information can be used during MTTL.
• The mixture particle ﬁlter is a state-of-the-art algorithm suited for
multitarget tracking and localization.
This thesis shows that the
nearest-neighbor data association of the mixture particle ﬁlter
prevents fully Bayesian tracking, and presents three extensions
to transform the mixture particle ﬁlter into a fully Bayesian
algorithm.

Beknopte Samenvatting
Het werkgebied van robots evolueert meer en meer in de richting van onzekere,
ongestructureerde en door personen bevolkte omgevingen, zowel in industriële
als huishoudelĳke context. Deze evolutie vereist steeds meer intelligentie van
robots: ze moeten kunnen omgaan met de onzekerheid en de dynamica van de
onzekerheden in deze omgevingen. Dit proefschrift richt zich op één aspect van
cognitieve robots: het volgen en detecteren van objecten. In de toekomstige
cognitieve robot systemen zullen algoritmen voor multiobject volgen en detectie
een basisinstrument zĳn voor robots.
Robots moeten zich immers bewust
zĳn van objecten, en vooral personen, in hun omgeving om de veiligheid te
garanderen en om intelligente mens-robot interactie en samenwerking mogelĳk
te maken.
Dit proefschrift is gericht op het ontwikkelen van algoritmen voor multiobject
volgen en detecteren, die geschikt zĳn voor online schatting van zowel het
aantal objecten als de toestanden van deze objecten.
Hiertoe gebruikt dit
proefschrift Bayesiaanse kansrekening om de onbekende variabelen binnen het
probleem vam multiobject volgen en detecteren te schatten. De term ‘rigoureus
Bayesiaans’ in de titel van dit proefschrift heeft betrekking op het feit dat
alle onbekende variabelen worden geschat met behulp van volledig Bayesiaanse
methoden, en dat alle compromissen en aannames expliciet zĳn gemaakt,
bĳvoorbeeld in de vorm van een Bayesiaanse prior. Dit proefschrift bevat vier
bĳdragen aan het onderzoeksdomein van multiobject volgen en detecteren:
• Probabilistische meetmodellen zĳn een belangrĳke bouwsteen van Bay-
esiaanse methoden.
Het is van vitaal belang dat alle bronnen van
onzekerheid die een invloed hebben op de metingen worden verwerkt
in het probabilistische meetmodel. Vooral de dynamische aard van de
omgeving, als gevolg van ongemodeleerde en bewegende objecten, is een
belangrĳke bron van onnauwkeurigheden.
Dit proefschrift ontwikkelt
daarom een Bayesiaans netwerk model voor range ﬁnders dat
geschikt is voor dynamische omgevingen, samen met algoritmen
voor het leren van de modelparameters uit experimentele
vi

Beknopte Samenvatting
vii
gegevens.
• Een groot aantal algoritmen voor multiobject volgen en detectie zĳn
beschikbaar in de literatuur. Dit proefschrift geeft een overzicht van
de belangrĳkste algoritmen en classiﬁceert hen.
Door het
formuleren van de algoritmen in een uniform raamwerk met
behulp van dezelfde terminologie en symbolen en door het
analyseren van hun Bayesiaanse netwerk voorstelling, vergelĳkt
dit proefschrift de verschillende algoritmen en onthult de
veronderstellingen gemaakt binnen deze algoritmen.
• Bestaande algoritmen voor multiobject volgen en detectie zĳn vaak
beperkt tot gevallen waarin een object hooguit één meting genereert
per tĳdstip.
Om deze beperking te omzeilen, worden deze algoritmen
voorafgegaan door een voorverwerkingsstap die metingen groepeert in
kenmerken.
Het samenvatten van individuele metingen in kenmerken
leidt tot informatieverlies. Dit proefschrift presenteert een online twee-
niveau algoritme voor multiobject volgen en detecteren dat dit
informatieverlies vermĳdt en toch in staat is om een variabel
aantal object te volgen en detecteren met behoud van een
unieke object identiﬁcatie gedurende het volgen. Het voorgestelde
algoritme is bovendien in staat om de informatie over de objectvorm te
gebruiken tĳdens het multiobject volgen en detecteren.
• De mixture particle ﬁlter is een state-of-the-art algoritme geschikt voor
multiobject volgen en detectie.
Dit proefschrift toont aan dat de
nearest-neighbor data associatie van de mixture particle ﬁlter
in strĳd is met een volledig Bayesiaanse aanpak en presenteert
drie uitbreidingen die de mixture particle ﬁlter transformeren
tot een volledig Bayesiaans algoritme.

Symbols, Deﬁnitions and
Abbreviations
General Abbreviations
1D, 2D, 3D
: 1-, 2-, or 3-dimensional
ARD
: Automatic relevance detection
BFL
: Bayesian ﬁltering library
BWSR
: Bayesian weighted spatial reclustering
BN
: Bayesian network
DAG
: Directed acyclic graph
DBN
: Dynamic Bayesian network
EKF
: Extended Kalman ﬁlter
EM
: Expectation-maximization
FSM
: Finite state machine
GM-PHD
: Gaussian mixture probability hypothesis density
HMPF
: Hybrid marginalized particle ﬁlter
HPF
: Hybrid particle ﬁlter
IMM
: Interacting multiple models
IPPF
: Independent partition particle ﬁlter
JPDA
: Joint probabilistic data association
JPDAF
: Joint probabilistic data association ﬁlter
KF
: Kalman ﬁlter
KL
: Kullback-Leibler
KLD
: Kullback-Leibler divergence
MAP
: Maximum a posteriori
MC
: Monte Carlo
MC-JPDAF
: Monte Carlo JPDAF
MCMC
: Markov chain Monte Carlo
MCMC-PF
: Markov chain Monte Carlo particle ﬁlter
MCPdf
: Monte Carlo probability density function
MHT
: Multihypothesis tracking
ML
: Maximum likelihood
viii

Symbols, Definitions and Abbreviations
ix
MPF
: Mixture particle ﬁlter
MRF
: Markov random ﬁeld
MTPF
: Multitarget particle ﬁlter
MTT
: Multitarget tracking
MTTL
: Multitarget tracking and localization
NN
: Nearest-neighbor
PDA
: Probabilistic data association
pdf
: Probability density function
PF
: Particle ﬁlter
PHD
: Probability hypothesis density
pmf
: Probability mass function
PMHT
: Probabilistic multihypothesis tracking
ROI
: Region of interest
SJPDAF
: Sample-based JPDAF
SLAM
: Simultaneous localization and mapping
SMC
: Sequential Monte Carlo
SMC-PHD
: Sequential Monte Carlo probability hypothesis density
SN
: Strongest-neighbor
SSPF
: Sequential sampling particle ﬁlter
RBBM
: Rigorously Bayesian beam model
RFS
: Random ﬁnite set(s)
RJMCMC
: Recursive jump Markov chain Monte Carlo
RJMCMC-PF : Recursive jump Markov chain Monte Carlo particle ﬁlter
UKF
: Unscented Kalman ﬁlter
VB
: Variational Bayesian
General Symbols and Deﬁnitions
Cov[x, y]
: Covariance of two random variables x and y
∆t
: Length of a time step
Ψ
: Digamma function
δa (.)
: Dirac delta measure with mass at a
Dir(µ|α)
: Dirichlet
distribution
over
random
variable
µ
with
parameters α
DH (P||Q)
: Discrete Hellinger distance between P and Q
EP(x)[f(x)]
: Expected value of the function f(x) given the distribution
P(x)
i
: The index over the particles
KL (P||Q)
: Kullback-Leibler divergence between P and Q
P(x)
: Probability density function of random variable x
P(x | y)
: Probability density function of random variable x given
random variable y

x
Symbols, Definitions and Abbreviations
N(x|µ, Σ)
: Normal distribution over random variable x with mean µ
and covariance Σ
Np
: The number of particles
Q(x)
: Proposal distribution for x
Q(x | y)
: Conditional proposal distribution for x given y
t
: Index over the time steps
T
: The total time or total number of time steps
VarP(x)[f(x)]
: Variance of the function f(x) given the distribution P(x)
W(Λ|W, ν)
: Wishart distribution over random variable Λ, with W the
scale matrix and ν the number of degrees of freedom
w(i)
: Weight of the ith particle
x
: The state vector
x(i)
: State of the ith particle
y
: The measurement vector
Rigorously Bayesian Beam Model
b
: Index of a beam of the range ﬁnder
B
: Total number of beams of the range ﬁnder
z
: Measurement along a beam of the range ﬁnder
zb
: Measurement along beam b of the range ﬁnder
zmax
: Maximum range of the range ﬁnder
z
: Vector containing all measured distances, i.e.
along all
beams of range ﬁnder
z⋆
: Ideal measurement along a beam of the range ﬁnder
z⋆
occl
: Ideal measurement of occluding objects along a beam of the
range ﬁnder
θ
: Angle of a beam of the range ﬁnder
θb
: Angle of beam b of the range ﬁnder
θ
: Vector of angles of beams of the range ﬁnder
x
: State representing the position of mobile robot and sensor
mounted on it
m
: Map of the environment
a
: Extra state variables for positions of unmodeled objects
n
: Unkown number of unmodeled objects
j
: Index over the unmodeled objects
xN j
: Position of the jth unmodeled object along the beam
xN
: Vector of positions of all unmodeled objects along the beam
k
: Number of unmodeled occluding objects
i
: Index over the occluding objects
xKi
: Position of the ith occluding object along the beam
xKc
: Position of the closest occluding object along the beam

Symbols, Definitions and Abbreviations
xi
xK
: Vector of positions of all occluding objects along the beam
p
: Probability that at least one unmodeled object is present
u
: Probability that an unmodeled object is occluding the map
σm
: Standard deviation of zero mean measurement noise on
ideal range ﬁnder measurement
p′
: Probability that the map is occluded along the beam
Phit (z | x, m)
: Probability distribution of the distance measurement z
along the beam if the beam is not occluded
Poccl (z | x, m)
: Probability distribution of the distance measurement z
along the beam if the beam is occluded
Prand (z | x, m)
: Probability distribution of the distance measurement z
along the beam for unexplainable measurements
Pmax (z | x, m)
: Probability distribution of the distance measurement z
along the beam for max-range measurements
π1
: Probability that the measurement is caused by the map,
i.e.
the measurement is not due to an occlusion, an
unexplainable measurement nor a max-range measurement
π2
: Probability that the measurement is due to an occlusion
π3
: Probability that the measurement is an unexplainable
measurement
π4
: Probability that the measurement is a max-range measure-
ment
π
: [π1, π2, π3, π4]
Θ
: [σm, p′, π3, π4], the vector of four independent RBBM model
parameters
Θ′
: [σm, π], non-minimal set of RBBM model parameters
Θ′′
: [µ, σm, π], non-minimal set of RBBM model parameters for
variational Bayesian learning
ι
: Index over measurements available for learning
J
: Total number of measurements available for learning
Z
: {zι}ι=1:J, vector containing all measurements available for
learning
X
: {xι}ι=1:J, vector containing all states available for learning
d
: Latent correspondence variable representing the unknown
cause of a measurement using a 1-of-S representation: d =
[d1, d2, d3, d4]
D
: {dι}ι=1:J, latent correspondences of the measurements
available for learning
s
: Variable indicating the cause of a measurement
S
: Total number of available causes of a measurement
πs
: Probability that a measurement has cause s

xii
Symbols, Definitions and Abbreviations
Q(Θ′, Θ′old)
: Expectation of the complete-data log likelihood with
respect to the posterior distribution of the latent variables
γ (dιs)
: E[dιs], responsibility of cause s for data point ι obtained
during maximum likelihood learning
Js
: Eﬀective number of data points associated with cause s
¯zs
: Mean of the eﬀective data points associated with cause s
Cs
: Covariance of the eﬀective data points associated with
cause s
QD(D)
: Distribution (factor) over latent variables D
QΘ(Θ)
: Distribution (factor) over parameters Θ
Q⋆
D(D)
: Optimal factor over latent variables D obtained through
variational Bayesian learning
Q⋆
Θ(Θ)
: Optimal factor
over parameters Θ
obtained through
variational Bayesian learning
α0
: Eﬀective number of (prior) observations associated with
each component of the mixture
µ
: Expected value of Phit (z | x, m) for variational Bayesian
learning
λm
: σ−1
m , precision of zero mean measurement noise on ideal
range ﬁnder measurement
¯µ0
: Mean of the Gaussian prior on the expected value of
Phit (z | x, m)
β0
: Parameter governing the covariance of the Gaussian prior
on the expected value of Phit (z | x, m)
W0
: Scale matrix of the Wishart prior on the precision λm
ν0
: Degrees of freedom of the Wishart prior on the precision
λm
¯µ
: Mean of the Gaussian distribution on the expected value of
Phit (z | x, m)
β
: Parameter governing the
covariance of the
Gaussian
distribution over the expected value of Phit (z | x, m)
W
: Scale matrix of the Wishart distribution over the precision
λm
ν
: Degrees of freedom of the Wishart distribution over the
precision λm
rιs
: Responsibility of cause s for data point ι obtained after
variational Bayesian learning
H (z)
: Histogram over the experimental data
U(x)
: Local environment of state x
˜x
: Element in the environment of state x
dU(x)
: Diameter of a circular region representing the environment
of state x

Symbols, Definitions and Abbreviations
xiii
l
: Index over simulated complete range scans
L
: Total number of simulated complete range scans
Overview and Classiﬁcation of MTTL Algorithms
n
: Index over the targets
N t
: Total number of targets at time step t
xt
n
: State of the nth target at time step t
xt
: {xt
n}n=1:N t, all target states at time step t
X T
n
: {xt
n}t=1:T , track of the nth target containing all target
states of the nth target up to time step T
X T
:

X T
n
	
n=1:N T , track of all targets up to time step T
k
: Index over the measurements
KT
: Total number of measurements at time step t
yt
k
: kth measurement at time step t
yt
: {yt
k}k=1:Kt, all measurements at time step t
y1:t
: All measurements up to time step t
rt
k
: Measurement-to-target association vector of kth measure-
ment at time step t
rt
: {rt
k}k=1:Kt, measurement-to-target association vector at
time step t
ert
n
: Target-to-measurement association vector of nth target at
time step t
ert
:
n
ert
n
o
n=1:N t, target-to-measurement association vector at
time step t
PC(y)
: Pdf over clutter measurements
V
: Observation volume
PN(y)
: Pdf over measurements of new targets
dm
: Mahalanobis distance
h
: The index over the hypotheses
H
: The total number of hypotheses
θt
h
: {rt
k}k=1:Kt, association event of the hth hypothesis at time
step t
Θt
h
:

θti
h
	ti=1:t, vector containing all association events θt
h up
to time step t
¯xt
h
: Target state according to hth hypothesis after prediction
p (h)
: Parent hypothesis of hypothesis h
M t
f
: Number of false alarms at time step t
M t
n
: Number of measurements from new targets at time step t
P t
det,n
: The probability of detection of the track of target n at time
step t

xiv
Symbols, Definitions and Abbreviations
P t
del,n
: The probability of deletion of the track of target n at time
step t
λn
: Density of Poisson distribution over M t
n
λf
: Density of Poisson distribution over M t
f
µt
n
: The expected value of the Gaussian distribution over the
nth target state at time step t
Σt
n
: The covariance of the Gaussian distribution over the nth
target state at time step t
¯µt
n
: The expected value of the predicted Gaussian distribution
over the nth target state at time step t
¯Σt
n
: The covariance of the predicted Gaussian distribution over
the nth target state at time step t
fn(.)
: Function describing the dynamics of the nth target
Qn
: Process model covariance for the nth target
g(.)
: Measurement function
Rt
: Measurement model covariance at time step t
Gt
: Measurement model matrix at time step t
ρt
n
: P(rt
k = n),
data
association probability denoting
the
probability that a measurement yt
k is assigned to the nth
target
ρt
: {ρt
n}n=1:N, data association probability vector
wt
kn
: Responsability,
i.e.
the conditional probability that
measurement yt
k is assigned to target n given x1:T and y1:T
eyt
n
: Synthetic measurement to apply to target n at time step t
eR
t
: Covariance of Gaussian measurement noise associated with
synthetic measurement eyt
n at time step t
ct
kn
: P
 rt
k = n | y1:t
,
probability that
measurement yt
k
is
assigned to the nth target given all measurements up to
time step t
θt
: {rt
k}k=1:Kt, association event at time step t
Θt
kn
: {θt : rt
k = n ∈θt}, all association events at time step t
assigning measurement yt
k to target n
¯yt
n
: g
 ¯µt
n

, the predicted measurement for the nth target at
time step t
νt
n
: Innovation (Kalman Filter) to apply to the tracker of target
n at time step t
i
: The index over the particles
xt,(i)
n
: The state of the ith particle of the marginal distribution of
the nth target at time step t
wt,(i)
n
: The weight of the ith particle of the marginal distribution
of the nth target at time step t

Symbols, Definitions and Abbreviations
xv
¯xt,(i)
n
: The state of the ith particle of the predicted marginal
distribution of the nth target at time step t
¯wt,(i)
n
: The weight of the ith particle of the predicted marginal
distribution of the nth target at time step t
Qn(. | .)
: Proposal for the nth target
Kn
: The set of measurement indexes that are expected to have
an impact on the nth target (for instance the measurements
in the gate of that target)
tw
: The width of a time slice
j
: Index over regions of interest
Jt
: Total number of regions of interest at time step t
St
j
: jth region of interest at time step t
St
:

St
j
	
j=1:Jt, vector gathering all regions of interest at time
step t
Ψ (xt
n, xt
m)
: Interaction potential describing the interaction between two
targets
E
: the set of edges indicating interactions between targets
g
: {a, b, E}, bipartite graph where a set of nodes a are
connected with a set of nodes b through a set of edges E
s
: Index over the auxiliary variables
Ns
: Total number of auxiliary variables
µt,(s)
: Mean association with auxiliary variable s at time step t
Σt,(s)
: Covariance association with auxiliary variable s at time step
t
N t
p
: The total number of particles at time step t
N t
p,n
: The number of particles for the marginal distribution of
target n at time step t
xt,(i)
: The state of the ith particle at time step t
wt,(i)
: The weight of the ith particle at time step t
¯xt,(i)
: The state of the predicted ith particle of at time step t
¯wt,(i)
: The weight of the predicted ith particle at time step t
l
: The index over the components of a mixture
Lt
: The total number of components of a mixture at time step
t
πt
l
: Weight of component l at time step t
Pl(. | .)
: The pdf of the lth component
ct,(i)
: Component indicator indicating to which component the
ith particle belongs
Ql(.|.)
: Proposal for the lth component
Xt
: {xt
1, . . . , xt
N t}, the set of target states at time step t
Y t
: {yt
1, . . . , yt
Kt}, the set of measurements at time step t

xvi
Symbols, Definitions and Abbreviations
F (.)
: Finite subset
St|t−1
 xt−1
: RFS model for existing targets
Bt|t−1
 xt−1
: RFS model for new targets spawned from existing ones
Γt
: RFS model for spontaneous birth of targets
Θt (xt)
: RFS model for measurements originating from the targets
at time step t
Kt
: RFS model for false alarms at time step t
vt (.)
: PHD at time step t
βt|t−1 (.)
: Intensity of the RFS Bt|t−1
γt(.)
: Intensity of the RFS Γt
κt(.)
: Intensity of the RFS Kt
µt
l
: Mean of the lth component of the mixture of Gaussians
Σt
l
: Covariance of the lth component of the mixture of
Gaussians
Shape-based Online MTTL for Targets Causing Multiple Measurements
n
: Index over targets
N t
: Total number of targets at time step t
xt
n
: Partial nth target state containing information on the
position, velocity, acceleration, etc.
of the nth target at
time step t
St
n
: nth target shape at time step t
Xt
n
: Full nth target state at time step t
k
: Index over the measurements
Kt
: The total number of measurements at time step t
yt
k
: kth measurement at time step t
wt
k
: The weight of measurement yt
k indicating the probability
that
the
measurement
does
not
originate
from
the
environment
m
: Index over clusters
M
: Total number of clusters
µm
: Mean of the mth cluster
µ
: {µm}m=1:M, vector gathering all cluster means
Σm
: Covariance of the mth cluster
Σ
: {Σm}m=1:M, vector gathering all cluster covariances
at
k
: [a1k, a2k, . . . , aMk]t, correspondence variable using a 1-of-
M representation to indicate to which cluster measurement
yt
k is assigned
D
: Dimension of the state space of clustering
Am
: Mixing coeﬃcient of mth component of a Gaussian mixture
A
: {Am}m=1:M, vector grouping all mixing coeﬃcients Am
Θ
: [A, µ, Σ], the set of parameters of the clustering

Symbols, Definitions and Abbreviations
xvii
α0
: {α0m}m=1:M, parameters of the Dirichlet prior on the
mixing coeﬃcients A
α0m
: Measure for the conﬁdence in the prior on the cluster
parameters of the mth cluster
m0
: {m0m}m=1:M
m0m
: Mean of the Gaussian prior on the mth cluster mean
β0
: {β0m}m=1:M
β0m
: Parameters governing the covariance of the Gaussian prior
on the mth cluster mean
W0
: {W0m}m=1:M
W0m
: The scale matrix of the Wishart prior on the precision of
the mth cluster
ν0
: {ν0m}m=1:M
ν0m
: The degrees of freedom of the Wishart prior on the precision
of the mth cluster
α
: {αm}m=1:M, parameters of the Dirichlet distribution over
the mixing coeﬃcients A
αm
: Measure for the conﬁdence in the cluster parameters of the
mth cluster
m
: {mm}m=1:M
mm
: Mean of the Gaussian distribution over the mth cluster
mean
β
: {βm}m=1:M
βm
: Parameters governing the covariance of the Gaussian
distribution over the mth cluster mean
W
: {W0m}m=1:M
Wm
: The scale matrix of the Wishart distribution over the
precision of the mth cluster
ν
: {νm}m=1:M
νm
: The degrees of freedom of the Wishart distribution over the
precision of the mth cluster
rkm
: Responsability that cluster m takes for explaining measure-
ment k
fm0(Xn)
: Function determining how to obtain a prior estimate for
the cluster position m0m from the nth target state
fW0(Xn)
: Function determining how to obtain a prior estimate for
the scale matrix W0m from the nth target state
g
: Measurement function
θ
: Joint association event containing the pairs of measurement
and target indexes uniquely determining which measure-
ment is assigned to which target
ct
kn
: Probability that measurement yt
k is caused by target n

xviii
Symbols, Definitions and Abbreviations
Θkn
: The set of all θ assigning measurement yt
k to target n
ct
mn
: Probability that the measurements in the mth cluster are
caused by target n
ct
m
: {ct
m1, ct
m2, . . . , ct
mN}
γ
: The probability of a false alarm
Mf
: The number of false alarms in θ
b
: Index of the beam of the range ﬁnder
bk
: Beam along which measurement k is made
B
: Total number of beams of the range ﬁnder
θ(bk)
: The angle of the beam bk with the x-axis of the world
dk
: Distance measurement along beam bk
σenv
: Measure for the uncertainty on the prerecorded environ-
ment
fmotion (xt
n)
: Function describing nth target motion
Σmotion
: Covariance of Gaussian noise on target motion model
(xlaser, ylaser)
: The position of the laser scanner in the world
Σmeas
: Covariance of Gaussian noise on measurement model
Fully Bayesian Mixture Particle Filter for MTTL
xt
: The target state at time step t
yt
: The measurements at time step t
y1:t
: All measurements up to time step t
k
: Index over the measurements
Kt
: The number of measurements at time step t
yt
k
: The kth measurement at time step t
Pt
: Mixture of Monte-Carlo pdfs
i
: Index over the particles
N t
p
: Number of particles at time step t
m
: Index over the mixture components
M t
: Number of mixture components in the MCPdf mixture at
time step t
Πt
: The vector of mixture component weights at time step t
X t
: The vector of all particle states at time step t
Wt
: The vector of all particle weights at time step t
Ct
: The vector of all component indicators at time step t
πt
m
: The mixture component weight of the mth mixture
component at time step t
xt,(i)
: The state of the ith particle at time step t
wt,(i)
: The weight of the ith particle at time step t
ct,(i)
: The component indicator of the ith particle at time step t

Symbols, Definitions and Abbreviations
xix
Il
: The set of all particle indexes belonging to the lth mixture
component
D
 xt | xt−1
: The dynamic model describing the target state evolution
L(yt | xt)
: The measurement model
Pt′
: Mixture of Monte-Carlo pdfs after reclustering procedure
F
: Spatial reclustering function
Fw
: Bayesian weighted spatial reclustering function
A
: Vector of mixing coeﬃcients of Gaussian mixture
Am
: Mixing coeﬃcients of mth Gaussian mixture component
µ
: The vector of component locations of the Gaussian mixture
µm
: The location of the mth component of the Gaussian mixture
S
: The vector of component sizes of the Gaussian mixture
Sm
: The size of the mth component of the Gaussian mixture
a(i)
: Correspondence variable representing the unknown compo-
nent of the ith particle using a 1-of-M representation
Θ
: {A, µ, S}, parameters of the variational Bayesian cluster
ﬁnding
α0
: Parameters of the Dirichlet prior on the mixing coeﬃcients
A
m0
: Mean of the Gaussian prior on the cluster means µ
β0
: Parameter governing the covariance of the Gaussian prior
on the cluster means µ
W0
: Scale matrix of the Wishart prior on the cluster precision
S−1
ν0
: Degrees of freedom of the Wishart prior on the cluster
precision S−1
α
: Parameters of the Dirichlet distribution over the mixing
coeﬃcients A
m
: Mean of the Gaussian distribution over the cluster means
µ
β
: Parameter governing the
covariance of the
Gaussian
distribution over the cluster means µ
W
: Scale matrix of the Wishart distribution over the cluster
precision S−1
ν
: Degrees of freedom of the Wishart distribution over the
cluster precision S−1
pnew
: The probability of detecting a new target


Contents
Dankwoord
i
Abstract
iv
Beknopte Samenvatting
vi
Symbols, Deﬁnitions and Abbreviations
viii
Contents
xxi
List of Figures
xxv
List of Tables
xxxv
1
Introduction
1
1.1
Methodology
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Contributions and Outline . . . . . . . . . . . . . . . . . . . . .
4
2
Probabilistic Background
7
2.1
Probability Theory . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.2
Bayesian Networks . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.3
Inference and Learning in Bayesian Networks . . . . . . . . . .
20
2.4
Marginalization . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
xxi

xxii
Contents
2.5
Modeling
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.6
Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
3
Range Finder Model for Dynamic Environments
37
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
3.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3.3
Beam Model
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
3.4
Variational Bayesian Learning of the Model Parameters . . . .
60
3.5
Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
3.6
Adaptive Full Scan Model . . . . . . . . . . . . . . . . . . . . .
75
3.7
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
3.8
Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
4
Overview and Classiﬁcation of MTTL Algorithms
89
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
4.2
Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
4.3
Classiﬁers for MTTL algorithms
. . . . . . . . . . . . . . . . .
100
4.4
Algorithms for MTTL . . . . . . . . . . . . . . . . . . . . . . . . 101
4.5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
170
5
Shape-based Online MTTL
173
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
174
5.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
5.3
Two-level Tracking and Localization Algorithm . . . . . . . . .
178
5.4
Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
5.5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
206
5.6
Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
209
6
Fully Bayesian Mixture Particle Filter for MTTL
221

Contents
xxiii
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
6.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . .
223
6.3
Mixture Particle Filter for Multitarget Tracking . . . . . . . . .
226
6.4
Adapted Measurement Model . . . . . . . . . . . . . . . . . . .
230
6.5
MTT with MPF, Adapted Measurement Model and BWSR . .
237
6.6
Extension to Localization . . . . . . . . . . . . . . . . . . . . .
243
6.7
Simulations and Experiments . . . . . . . . . . . . . . . . . . .
245
6.8
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
248
7
General Conclusions
249
7.1
Situation of the Work
. . . . . . . . . . . . . . . . . . . . . . .
249
7.2
Main Contributions . . . . . . . . . . . . . . . . . . . . . . . . .
250
7.3
Suggestions for Future Work . . . . . . . . . . . . . . . . . . . .
259
8
Other Contributions
265
8.1
Kalman Smoothing for the Estimation of Joint Kinematics and
Kinetics in Marker-based Human Gait Analysis . . . . . . . . .
265
8.2
Constraint-based Task Speciﬁcation and Estimation for Sensor-
based Robot Systems in the Presence of Geometric Uncertainty
266
8.3
Bayesian Filtering Library (BFL) . . . . . . . . . . . . . . . . .
267
References
269
Index
283
Curriculum Vitae
289
List of Publications
291


List of Figures
2.1
Bayesian network example with nodes and directed connections
(edges) forming a directed acyclic graph (DAG) and an explicit
parameter p. The box (plate) denotes a set of M similar nodes.
The shaded node is observed. . . . . . . . . . . . . . . . . . . .
19
2.2
Bayesian network model for the EM-algorithm. With Θ the set
of parameters, x the latent variables and y the observations or
data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.3
Bayesian network model for the Bayes ﬁlter. The shaded nodes
are observed.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.4
Bayesian network model for clustering of measurements through
EM-clustering with a mixture of Gaussians.
The box (plate)
denotes a set of K measurements. The shaded nodes are observed. 32
2.5
Bayesian network model for clustering of measurements through
variational Bayesian clustering for a mixture of Gaussians. The
boxes (plates) denote a set of K weighted measurements and a
set of M clusters. The shaded nodes are observed.
. . . . . . .
34
3.1
The Bayesian network for the probabilistic measurement model
supplemented with the deterministic parameters represented by
the solid dot nodes. A compact representation with plates (the
rounded rectangular boxes) is used. A plate represents a number,
indicated in the lower right corner, of independent nodes of which
only a single example is shown explicitly. . . . . . . . . . . . . .
45
3.2
P(n) (Eq. (3.2)) for p = 0.65. . . . . . . . . . . . . . . . . . . .
46
3.3
P(xNj | n) (Eq. (3.3)). . . . . . . . . . . . . . . . . . . . . . . .
46
3.4
P(k | n, x, m) (Eq. (3.5)) for n = 10 and u = 0.25. . . . . . . . .
47
xxv

xxvi
List of Figures
3.5
The selection scheme, where each cross eliminates an unmodeled
object that is not occluding the map. . . . . . . . . . . . . . . .
48
3.6
P(xKi | n, k, x, m) (Eq. (3.15)). . . . . . . . . . . . . . . . . . . .
51
3.7
Comparison of the approximation (Eq.(3.36)) of the integral in
Eq. (3.34) with a ﬁnite sum approximation with small step size
for p = 0.8, zmax = 10, z⋆= 5 and σm = 0.15. . . . . . . . . . .
55
3.8
Comparison of the obtained RBBM P(z | x, m) (Eq. (3.37)) with
a ﬁnite sum approximation of Eq. (3.34) with small step size for
p = 0.8, zmax = 10, z⋆= 5 and σm = 0.15. . . . . . . . . . . . .
55
3.9
Comparison of the obtained RBBM P(z | x, m) (3.45), a ﬁnite
sum approximation of Eq. (3.34) with small stepsize and the
normalized histogram of 500 samples obtained by a Monte Carlo
Simulation of the proposed Bayesian network (Fig. 3.1) for p =
0.8, zmax = 10, z⋆= 5, σ = 0.15, π3 = 0.2 and π4 = 0.02. . . . .
59
3.10 Graphical representation of the mixture measurement model
(Eq. (3.45)) with latent correspondence variable Dι = {Dι1, Dι2, Dι3, Dι4}
and model parameters Θ′ = [σm, π1, π2, π3, π4].
. . . . . . . . .
60
3.11 Data for second learning experiment reported by Thrun et al.
2005.
These data consist of two series of measurements
obtained with a mobile robot traveling through a typical
oﬃce environment.
From the set of measurements 10000
measurements that are centered around two diﬀerent expected
ranges are selected. . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.12 Comparison of the results of the ML-EM and VB-EM estimators
for the RBBM and the results of a maximum likelihood estimator
for Thrun’s model (Thrun et al. 2005) for the data of Figure 3.11. 73
3.13 Setup for the second learning experiment with a Sick LMS 200
laser scanner mounted on the ﬁrst axis of an industrial Kuka 361
robot. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
3.14 Map build of the robot’s static environment, i.e. without any
unexpected objects or people moving around, by rotating the
ﬁrst axis of the industrial robot. For safety reasons, people were
not allowed to move inside the safety region (circle with radius
1m). Therefore, measurements smaller than 1m are discarded.
The studied expected ranges in the second learning experiment
range from 3.0m to 4.5m in steps of 0.1m and are indicated in
the ﬁgure by the selected ranges region.
. . . . . . . . . . . . .
76

List of Figures
xxvii
3.15 Comparison of the results of the ML-EM and VB-EM estimators
for the RBBM and the results of a maximum likelihood estimator
for two diﬀerent expected ranges and two diﬀerent number of
people populating the robot environment. . . . . . . . . . . . .
78
3.16 Panorama taken from the Sick LMS 200 range ﬁnder mounted
on a Kuka 361 industrial robot. The environment consists of a
rectangular ‘room’ with an object (a Kuka KR 15/2 robot) in the
middle. We show that even for this simple static environment,
the presented sample-based full scan model outperforms the
Gaussian-based state-of-the-art models.
. . . . . . . . . . . . . .
81
3.17 Experimental results for sample-based adaptive full scan model
for static environments.
(a) models the simple environment
of Fig. 3.16.
The range ﬁnder is located at (0.15m, 0.75m).
Samples from U(x) (resulting from a local uncertainty on the
x- and y−position of 0.01m and a rotational uncertainty of 5◦)
are shown with black dots, and some simulated measurements
are shown in grey.
(b) and (c) show the marginal likelihood
P(zb | x, m) for the two selected beams together with the
histogram of the experimentally recorded range ﬁnder data, the
Gaussian-based approximation (L = 150) of Pfaﬀet al. 2007,
and the sample-based approximation (L = 150) of this paper.
(d) shows the diﬀerence for all beams between the experimentally
obtained cumulative marginal (L = 1500) and the Gaussian-
based and sample-based approximation. . . . . . . . . . . . . .
82
3.18 Results for sample-based adaptive full scan model for dynamic
environments.
(a) and (b) show the marginal likelihood
P(zb | x, m) for the two selected beams of Fig. 3.17(a) together
with the Gaussian-based approximation (L = 150) of (Pfaﬀ
et al.
2007) and the sample-based approximation (L = 150)
extended for the use in dynamic environments. (c) shows the
probability map resulting from the sample-based approximation.
The probability map shows P(z | x, m) as a function of the x-
and y−position in the map. . . . . . . . . . . . . . . . . . . . .
84
4.1
Bayesian network model for multihypothesis tracker (MHT).
The boxes (plates) denote a set of Kt−1,
Kt and Kt+1
measurements, a set of Nh targets (the number of targets in
hypothesis h) and a set of H hypotheses. The shaded nodes are
observed or known.
. . . . . . . . . . . . . . . . . . . . . . . .
107

xxviii
List of Figures
4.2
Bayesian network model for the probabilistic multihyptothesis
tracker (PMHT). The boxes (plates) denote a set of Kt−1, Kt
and Kt+1 measurements and a set of N targets. The shaded
nodes are observed.
. . . . . . . . . . . . . . . . . . . . . . . .
113
4.3
Simpliﬁed Bayesian network model for the probabilistic multihy-
pothesis tracker (PMHT). The PMHT is equivalent to a bank of
Kalman smoothers with synthetic measurements eyt
n. The box
(plate) denotes a set of N targets. The shaded nodes are observed.117
4.4
Underlying Bayesian network model for joint probabilistic data
association ﬁlter (JPDAF). The boxes (plates) denote a set of
Kt−1, Kt and Kt+1 measurements and a set of N targets. The
shaded nodes are observed.
. . . . . . . . . . . . . . . . . . . .
126
4.5
Simpliﬁed Bayesian network model for the joint probabilistic
data association ﬁlter (JPDAF). The JPDAF is equivalent to
a bank of Kalman ﬁlters with synthetic measurements. The box
(plate) denote a set of N targets. The shaded nodes are observed.132
4.6
Bayesian network model for the estimator of the number of
targets in the sample-based JPDAF (SJPDAF) proposed by
Schulz et al. 2003. The shaded nodes are observed. . . . . . . .
136
4.7
Bayesian network model for the sequential sampling particle
ﬁlter (SSPF). The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements and a set of N targets. The shaded nodes
are observed.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
4.8
Bayesian network model for the independent partition particle
ﬁlter (IPPF). The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements and a set of N targets. The shaded nodes
are observed.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
4.9
Bayesian network model for the hybrid particle ﬁlter (HPF)
proposed by Ng et al. 2005a. The boxes (plates) denote a set of
Kt−1, Kt and Kt+1 measurements and a set of N targets. The
shaded nodes are observed.
. . . . . . . . . . . . . . . . . . . .
148
4.10 Bayesian network model for recursive jump Markov chain Monte
Carlo particle ﬁlter (RJMCMC-PF). The boxes (plates) denote a
set of Kt−1, Kt and Kt+1 measurements. The shaded nodes are
observed. Each node containing the target states is represented
by a pairwise Markov Random Field. The above ﬁgure shows
an example with ﬁve targets.
. . . . . . . . . . . . . . . . . . .
150

List of Figures
xxix
4.11 Bayesian network model for the Markov chain Monte Carlo
particle ﬁlter and data association algorithm of Khan et al. 2006
(MCMC-PF). The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements and a set of N targets. The shaded nodes
are observed.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
4.12 Bayesian network model for mixture particle ﬁlter (MPF). The
boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements.
The shaded nodes are observed. . . . . . . . . . . . . . . . . . . . 161
4.13 Bayesian network model for the probability hypothesis density
(PHD) ﬁlter. Xt represents the random ﬁnite set of target states
at time step t, i.e.: Xt = {xt
1, . . . , xt
N t}. The shaded, observed
nodes are the random ﬁnite sets of the measurements deﬁned as:
Y t = {yt
1, . . . , yt
Kt} . . . . . . . . . . . . . . . . . . . . . . . . .
167
4.14 Decision graph to help researchers in choosing an algorithm
suited for their particular MTTL problem. . . . . . . . . . . . . . 171
5.1
Information ﬂow for the proposed two-level multitarget tracking
and localization (MTTL) algorithm. The measurement prepro-
cessing step is not within the scope of the paper. Section 5.3.1
explains the data ﬂow in more detail and introduces all symbols. 179
5.2
Bayesian network model for clustering of measurements through
variational mixture of Gaussians. The boxes (plates) denote a
set of K weighted measurements and a set of M clusters. The
shaded nodes are observed.
. . . . . . . . . . . . . . . . . . . .
183
5.3
Underlying Bayesian network model for the target tracker at
the high level. The boxes (plates) denote a set of M t−1, M t and
M t+1 clusters and a set of N targets. The shaded nodes are
observed.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
5.4
Bayesian network model for the estimator of the number of
targets. The shaded nodes are observed. . . . . . . . . . . . . .
192
5.5
Estimation results for the experiment with laser scanner in
natural environment populated by three persons. Figure 5.5(a)
shows the high-level estimate of the trajectories of the three
targets, Figure 5.5(b) shows the low-level estimate of the cluster
positions.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195

xxx
List of Figures
5.6
Estimation results for the experiment with laser scanner in
natural environment populated by three persons:
this ﬁgure
shows the low-level estimate of the number of clusters and the
high-level estimate of the number of targets as a function of time. 196
5.7
Estimation results for tracking of ﬁve people: the ﬁgure shows
the low-level estimate of the number of clusters and the high-
level estimate of the number of targets as a function of the scan
number.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
199
5.8
Estimation results of laser scan 3820. The left plot shows the
high-level estimate of the targets trajectories from laser scan
3620 up to 3820 together with the measurements, while the right
plot shows the low-level clusters together with the measurements.
Due to persistent incomplete background subtraction,
the
algorithm adds a target at position (23,9.2) to explain the
measurements.
This extra tracker is however automatically
deleted when the measurements due to incomplete background
subtraction disappear. . . . . . . . . . . . . . . . . . . . . . . .
200
5.9
Estimation results of laser scan 968. The left plot shows the high-
level estimate of the targets trajectories from laser scan 768 up to
laser scan 968 together with the measurements, while the right
plot shows the low-level clusters together with the measurements.
The algorithm is able to distinguish and track the targets even
during close interactions. . . . . . . . . . . . . . . . . . . . . . . . 201
5.10 Estimation results of laser scan 891.
The left plot shows
the estimated targets together with the measurements, while
the right plot shows the low level clusters together with the
measurements. The algorithm is able to track all targets even
though two targets are occluded. . . . . . . . . . . . . . . . . .
202
5.11 Estimation results for tracking of ants: Figure (a) shows the
estimated trajectories of the ants, and Figure (b) shows the
low-level estimate of the number of clusters and the high-level
estimate of the number of targets as a function of the frame
number. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
204
5.12 Occlusion event during ants tracking. Two ants pass over one
other creating an occlusion. The algorithm succesfully tracks the
ants through the occlusion. During the occlusion, the covariance
of the occluded target increases as can be seen in the top middle
ﬁgure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
205

List of Figures
xxxi
5.13 Example of prior for the variational Bayesian clustering in case
of a target with circular cross-section observed by a laser scanner.215
5.14 Examples of prior for the variational Bayesian clustering for the
case of a target with shape deﬁned by a set of points.
. . . . .
216
5.15 Overview of software components developed for the two-level
Bayesian multitarget tracking and localization algorithm. The
blue blocks are Orocos components, with their properties
(P), methods (M), events (E) and read (R) and write (W)
dataports represented by purple, green, red and blue circles
respectively.
The grey rectangles indicate which software
components are belonging together conceptually.
Component
schemes for diﬀerent conﬁgurations, the software itself and API
documentation is available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.
217
6.1
Illustration of the MPF and its maintaining mixture step. In
the ideal case, each mode of the target distribution represents
one target and each particle ﬁlter of the MPF tracks one target.
To maintain the ideal situation where each component of the
mixture represents one target a mixture computation is needed
from time to time (Vermaak and Doucet 2003). This mixture
step is called ‘maintain mixture step’ in the MPF (Vermaak
and Doucet 2003).
The maintain mixture step in the MPF
will revise the mixture representation: the number of mixture
components, i.e. the number of targets, and the division of the
particles over the diﬀerent components of the mixture.
The
ellipses in the ﬁgure indicate how the particles are devided
over the diﬀerent components of the mixture.
During the
maintain mixture step the mixture representation is recomputed:
(i) the number of components, i.e. the number of targets, is
estimated, (ii) components with signiﬁcant degree of overlap
are merged, and (iii) components that are too diﬀuse are split
or deleted.
The mixture recomputation calculates from the
current mixture representation Pt =

N t
p, M t, Πt, X t, Wt, Ct	
a
new mixture representation Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
without changing the ﬁltering distribution. . . . . . . . . . . . .
224

xxxii
List of Figures
6.2
Bayesian network model for mixture particle ﬁlter (MPF) with
x the state variable, y the measurement variable, and t the
time step.
The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements.
The shaded nodes are observed.
The
diﬀerent modes of posterior over the state variable represent
diﬀerent targets. Therefore, the state space size is equal to the
size of a single target state. The measurement model L(yt | xt)
corresponds to the arrow from xt to the set of measurements
yt and therefore has to capture the probabilistic relationship
between all measurements and all targets. . . . . . . . . . . . .
227
6.3
Bayesian network model for measurement model where measure-
ment can come from multiple targets, but where the diﬀerent
targets are not occluding eachother.
The shaded nodes are
observed. The boxes (plates) denote a set of Kt measurements
and the set all target states {xt
m}m̸=n except the state of the
nth target.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
6.4
Figure (a) shows the Bayesian network for the probabilistic
measurement model supplemented with the deterministic pa-
rameters represented by the smaller solid nodes (for detailed
explanation on all variables and conditional probabilities see
De Laet et al. 2008). A compact representation with plates (the
rounded rectangular boxes) is used. A plate represents a number,
indicated in the lower right corner, of independent nodes of which
only a single example is shown explicitly.
The states crossed
out represent the states modeling the unknown environment
dynamics, which are marginalized out in the RBBM. The
shaded nodes are observed.
Figure (b) shows the RBBM for
P(yt
k | xt
n, m) for p = 0.8, ymax = 10, y⋆t
k
= 5, σm = 0.15,
π3 = 0.2 and π4 = 0.02.
. . . . . . . . . . . . . . . . . . . . . .
235
6.5
Bayesian network model for variational mixture of Gaussians.
The boxes (plates) denote a set of Np weighted particles and a
set of M clusters. The shaded nodes are observed.
. . . . . . .
240

List of Figures
xxxiii
6.6
Simulation of the MPF with RBBM and BWSR for tracking
and localization of four targets with a laser scanner. The left
ﬁgure shows the tracking and localization results over the entire
time sequence. Numbers 1-4 indicate the starting position of the
targets, while the boxed numbers indicate the end position of the
targets. Target 1 and 2 start outside the sensor range. Target 3
and 4 have the same initial position. The initial estimate of the
MPF only captures 3. After a few time steps the MPF recognizes
that component 3 has split in two, thanks to the ARD of the
BWSR. Once target 1 and 2 enter the sensor range the MPF add
components for this new targets thanks to the proposal presented
in Section 6.6 to extend the MPF for target localization. The
MPF is able to track all targets, even though target 1 and 2
temporarily occlude target 3 and target 4 respectively.
The
maintain mixture step does not maintain target numbers. This
is illustrated in this simulation:
component 1 and 2 of the
mixture represent target 1 and 2 before the crossing, while
after the crossing, component 1 and 2 of the mixture represent
target 2 and 1. The right ﬁgure shows the ﬁltering distribution
during the occlusion.
The particle clouds of target 3 and 4
are growing since these targets are occluded by target 1 and
2 respectively. Animations of the simulations are available at
http://people.mech.kuleuven.be/~tdelaet/peopleTracking/.246
6.7
Experiment of the MPF with RBBM and BWSR for people
tracking and localization with a laser scanner.
The left
ﬁgure shows the tracking and localization results over a 60
seconds time sequence.
The ﬁrst person is standing still
around location [−0.1m, 2m].
The second and third person
enter the scene later and walk around.
Both persons are
detected by the MPF the time step they enter the scene.
The MPF is able to localize and track all targets, even
though the targets occasionaly occlude each other. The right
ﬁgure shows the ﬁltering distribution during an occlusion
the occlusion.
The particle cloud of the person standing
still is growing since it is occluded by a person walking in
front of it.
Animations of the experiments are available at
http://people.mech.kuleuven.be/~tdelaet/peopleTracking/.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
247

xxxiv
List of Figures
7.1
Situation of the two MTTL algorithms developed in this thesis
(Shape-based online MTTL (Chapter 5) and Fully Bayesian
MPF (Chapter 6)) in a part of the decision graph proposed in
Chapter 4 to help researchers in choosing an algorithm suited
for their particular MTTL problem (Figure 4.14). . . . . . . . .
257

List of Tables
3.1
EM-parameters for ﬁrst and second learning experiment (all in
SI-units). In the ML approaches, the mean of Phit (z | x, m) is
set to xmp, i.e. the most probable bin of the histogram of the
training set H (z).
. . . . . . . . . . . . . . . . . . . . . . . . .
73
3.2
Discrete KL-divergence (d1) and square root Hellinger distance
(d2) for the ﬁrst learning experiment between the training set
and the results of the ML-EM and VB-EM estimators for the
RBBM and the ML-EM estimator for Thrun’s model (Thrun
et al. 2005). . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
3.3
Discrete KL-divergence (d1) and square root Hellinger distance
(d2) averaged for the studied expected range for the diﬀerent set
of measurements of the second learning experiment. Distances
are between the training set and the results of the ML-EM and
VB-EM estimators for the RBBM and the ML-EM estimator for
Thrun’s model (Thrun et al. 2005). The ﬁrst column indicates
the number of people walking around in the environment in that
particular set of measurements. . . . . . . . . . . . . . . . . . .
77
7.1
Properties of the shape-based online MTTL algorithm (Chap-
ter 5) and the fully Bayesian MPF (Chapter 6) according to the
classiﬁers proposed in Chapter 4. . . . . . . . . . . . . . . . . .
258
xxxv


Chapter 1
Introduction
Robots have been widely used in factories for executing repetitive, dangerous
or laborious tasks such as material handling and spot welding. Since industrial
robots outperform humans in speed and accuracy, they have shown to increase
the productivity, raise quality, or save costs in industrial settings. Traditional
industrial robots are however no match for the intelligence and ﬂexibility
of humans: they mainly execute simple tasks requiring little intelligence in
structured environments, where all the positions, orientations and shapes of
all objects in the robot’s environment are exactly known.
The territory of
industrial robots is limited to these structured environments since these robots
are not equipped with sensors, making them unaware of their environment and
especially to any change of their environment. This makes traditional industrial
robots unsuited for small batches in ﬂexible production environments and for
tasks in non-industrial, e.g. household and service, environments.
Recently, robots have been equipped with various sensors such as cameras,
force/torque sensors, laser distance sensors, sonars, etc.
Through this
sensors, robot can observe their environment and as such robots can evolve
towards uncertain, cluttered and even human-populated environments and
new applications arise where robots assist humans in domestic settings during
everyday tasks, where robots and humans are coworkers in an intelligent
factory, etc.
The evolution to real-world environments requires intelligent
robots since they have to be able to handle the uncertainty associated with
these real-world environments. Real-world environments not only contain an
unknown number of objects, with unknown positions, orientations and shapes
but these positions, orientations and shapes also change over time, i.e. real-
world environments are intrinsically dynamic.
Intelligent robots have to be
aware of targets, and especially persons, in their environments to operate safely
1

2
Chapter 1
Introduction
and to allow for safe human-robot interaction and cooperation. This thesis
focuses on one aspect of cognitive robots: multitarget tracking and localization.
Multitarget tracking (MTT) consists of estimating the state of diﬀerent
targets recursively. Multitarget tracking and localization (MTTL) furthermore
includes detection of appearing and disappearing targets. Multitarget tracking
is not only important for future robot systems but arises in a wide variety of
contexts: vision or laser-based people tracking for both mobile robotics and
surveillance systems, sonar-based submarine tracking, multitarget tracking for
manipulation, tracking of animals to study their behavior, etc.
Multitarget tracking (MTT) has the following challenges:
(i) the data
association of raw data to each target, (ii) the curse of dimensionality as
the size of the state space increases exponentially with the number of targets,
(iii) the non-linearity of target dynamics and measurement models, and (iv)
the handling of occlusions. Sensors provide unlabelled measurements of the
targets, leading to challenging combinatorial data association: (i) the spatial
separation between targets can be small compared to the measurement errors
and (ii) clutter measurements, i.e. measurements not corresponding to any of
the targets, can occur. Moreover multitarget localization (MTTL) introduces
extra diﬃculties: the number of targets to track is unknown and possibly
varying. In the absence of prior information on the environment, targets can
appear and disappear at any time and in any place. A multitarget tracker and
localizer has to automatically detect appearing and disappearing targets and
estimate the number of targets.
Since the focus of the thesis is on multitarget tracking and localization for
robotics, the online nature of the algorithms is important. Therefore, this thesis
aims at developing methods that are suited for online estimation of both the
number of targets and the state of these targets. Furthermore, since Bayesian
theory oﬀers a unifying and consistent framework to reason about uncertainty,
and forces the researcher to make all implicit assumptions explicit (Gadeyne
2005), this thesis uses Bayesian probability theory to estimate unknown, also
called hidden or latent, variables underlying the MTTL problem. The term
‘rigorously Bayesian’ in the title of the thesis, refers to the fact that all unknown
variables are estimated using fully Bayesian methods, and that all trade-oﬀs
and assumptions are made explicit, for instance in the form of a Bayesian prior.
First, this thesis proposes and experimentally validates a Bayesian network
model for a range ﬁnder adapted to dynamic environments and applicable as a
measurement model in MTTL. Second, this thesis reviews, classiﬁes, compares
and reveals underlying assumptions of the important state-of-the-art MTTL
algorithms. Third, this thesis proposes and experimentally validates a novel
online two-level MTTL algorithm that is able to handle targets producing
multiple measurements and a variable and unknown number of targets. Finally,
this thesis extends and adapts an existing algorithm for MTT, the Mixture

1.1 Methodology
3
Particle Filter (Vermaak and Doucet 2003), to make it suited for fully Bayesian
MTTL.
Section 1.1 describes the general methodology of this thesis, while Section 1.2
details the four contributions mentioned above and gives an outline of the thesis
text.
1.1
Methodology
The four contributions to the area of multitarget tracking and localization
made in this thesis are all founded on the common methodology of rigorously
Bayesian modeling. The goal of the rigorously Bayesian modeling is to obtain a
fully Bayesian model of the estimation problem in which any unknown variables
and parameters underlying the MTTL problem are given prior distributions
and are incorporated into the set of states.
This thesis shows how the
underlying variables and parameters can be made explicit for the MTTL
estimation problem and shows how this helps to discover implicit assumptions
and to encode domain, expert, and context-speciﬁc knowledge as a prior in the
Bayesian framework. Since the choice of how to represent a random variable as
a state and the probability distribution associated with this state can contain
implicit assumptions and approximations, this thesis uncovers these implicit
assumptions and approximations and explicitly states them. This thesis uses
Bayesian networks (Section 2.2) to graphically represent all estimation variables
and parameters and the conditional dependencies between them.
This way
the Bayesian networks help to design and motivate the estimation models.
Furthermore this thesis gives a physical interpretation of all the states and
parameters included in the Bayesian MTTL model since this helps researchers
with interpreting the estimation results and allows researchers to choose the
parameters based on their physical intuition.
The rigorously Bayesian approach however comes at a cost: the increased
complexity requires more computational power.
Due to the inclusion of
all unknown variables and parameters together with their priors into the
estimation problem, the dimensionality of the estimation space grows and
the posterior distribution can have a highly complex form for which the
expectations are not analytically tractable.
In the case of continuous
variables, the integrations required in the estimation problem may not result
in closed form analytical solutions, while the dimensionality of the space and
the complexity of the integrand may prohibit numerical integration.
For
discrete variables, the estimation problem can require to sum over all possible
conﬁgurations of the discrete variables, while the number of conﬁgurations
can increase exponentially with the number of discrete variables, making the
enumeration of this conﬁgurations computationally infeasible.

4
Chapter 1
Introduction
This thesis proposes two approaches to handle the increased computational
cost associated with the rigorously Bayesian approach: marginalization and
approximation schemes.
Marginalization (Section 2.4) can be used to tackle the growing dimensionality
of the state space. During marginalization some of the states introduced to
model all unknown variables can be marginalized before the estimation. This
marginalization will prevent the need to estimate a particular outcome for
the variables being marginalized, while keeping the information on how these
variables are distributed (a priori).
Approximation schemes can be used if the equations underlying the estimation
problem are not analytically tractable or are too computationally demanding
to represent analytically.
This thesis uses two approximation schemes for
the MTTL problem: stochastic and deterministic approximation techniques.
Monte Carlo methods, such as the particle ﬁlter (Section 2.3.3.2), use stochastic
approximations of the distributions in the estimation problem to approximate
the analytically intractable or computationally demanding calculations. Vari-
ational Bayes (Section 2.3.2) uses deterministic approximation schemes based
on the analytical approximation of the posterior distributions. Although the
approximate nature of variational Bayesian techniques does not guarantee
the solutions to be optimal, they are widely used when the exact solution is
intractable. Variational inference tries to make the optimizations or probability
calculations tractable by restricting them to a limited range of probability
distributions.
This thesis uses both parametric and factorized distributions
in the variational Bayes approximations. When using parametric distributions,
the optimization over all possible probability distributions boils down to the
optimization of a ﬁnite set of parameters underlying the parametric distribution.
In contrast, when using factorized distributions the probability distribution is
assumed to be a product of a set of factors, each depending on a subgroup of the
variables and parameters to estimate. The optimization is done by optimizing
with respect to each of the factors in turn. Remark that there is no restriction
on the function form of the individual factors.
The next section explains in more detail how this thesis applied the above
methodology in the diﬀerent contributions in the domain of MTTL.
1.2
Contributions and Outline
This thesis presents four contributions to the multitarget tracking and localiza-
tion research domain, each founded on the rigorously Bayesian methodology.
Each contribution is described in a paper, which constitute Chapters 3-6.
The ﬁrst contribution, presented in Chapter 3, consists of a Bayesian
network model for range ﬁnders adapted to dynamic environments.

1.2 Contributions and Outline
5
The presented measurement model is useful in the multitarget tracking and
localization problem but it is not limited to this application. While deriving
the range ﬁnder model, all modeling assumptions are rigorously explained, and
all model parameters have a physical interpretation. This approach results in
a transparent and intuitive model. With respect to the state-of-the-art beam
model this chapter: (i) proposes a diﬀerent functional form for the probability
of range measurements caused by unmodeled objects, (ii) intuitively explains
the discontinuity encountered in the state-of-the-art model, and (iii) reduces
the number of model parameters, while maintaining the same representational
power for experimental data.
The proposed beam model is called RBBM,
short for Rigorously Bayesian beam model. A maximum likelihood and
a variational Bayesian estimator are proposed to learn the model parameters.
Furthermore, the RBBM is extended to a full scan model in two steps: ﬁrst,
to a full scan model for static environments and next, to a full scan model
for general, dynamic environments.
The full scan model accounts for the
dependency between beams, and it adapts to the local sample density when
using a particle ﬁlter. In contrast to Gaussian-based state-of-the-art models,
the proposed full scan model uses a sample-based approximation. This sample-
based approximation enables handling dynamic environments and capturing
multimodality, which occurs even in simple static environments.
The second contribution, presented in Chapter 4, is to review the important
state-of-the-art multitarget tracking and localization algorithms, and
to classify them.
To this end this chapter (i) formulates state-of-the-
art MTTL algorithms in a uniﬁed framework using the same terminology
and symbols, (ii) lists the assumptions of the MTTL algorithms, (iii) gives
advantages and disadvantages of the algorithms, and (iv) discusses advances of
these algorithms.
By (i) formulating the state-of-the-art MTTL algorithms
in a uniﬁed framework using the same terminology and symbols and (ii)
by analyzing the Bayesian network representation for probabilistic MTTL
algorithms, the diﬀerent algorithms are compared and underlying assumptions
are revealed. Bayesian networks are used to provide a graphical representation
of the conditional independence assumptions of the algorithms.
These
independence assumptions are fundamental for understanding most MTTL
algorithms.
The third contribution, presented in Chapter 5, is a novel online two-level
multitarget tracking and localization algorithm. The algorithm focuses
on MTTL for the case where a target can produce multiple measurements
and where the number of targets being tracked is unknown and possibly time-
varying.
Information is continuously exchanged in both directions between
the two levels. By using the high-level target position and shape information,
the low level clusters the measurements. Furthermore, the low level features
automatic relevance detection (ARD) as it automatically determines the

6
Chapter 1
Introduction
optimal number of clusters from the measurements, taking into account the
expected target shapes. The high level’s data association allows for a varying
number of targets. A joint probabilistic data association algorithm looks for
associations between clusters of measurements and targets. These associations
are used to update the target trackers (based on an underlying motion model),
and the target shapes, with the individual measurements.
No information
is lost in the two-level approach, since the measurement information is not
summarized into features.
The high level is supplemented with a ﬁlter
estimating the number of targets.
The algorithm is veriﬁed using both
simulations and experiments using two sensor modalities, video and laser
scanner, for people and ants tracking and localization.
The fourth contribution, presented in Chapter 6, extends and adapts the
mixture particle ﬁlter (MPF) (Vermaak and Doucet 2003) in three
ways to make it suited for fully Bayesian MTTL. First, this chapter
analyses the MPF using its Bayesian network representation and shows that
the state-of-the-art nearest-neighbor data association of the MPF prevents
fully Bayesian tracking. This chapter therefore proposes a Bayesian soft-data
association using an adapted measurement model. Second, this chapter replaces
the state-of-the-art heuristic mixture computation step of the MPF with a
heuristic-free mixture computation:
Bayesian weighted spatial reclustering
(BWSR). BWSR is based on variational Bayesian cluster ﬁnding and uses prior
shape information of the particle cloud. Third, this chapter extends the MPF to
handle not only tracking but also target localization and detection. Simulations
and experiments of people tracking and detection using a laser scanner validate
the three extensions of the MPF.
Finally, Chapter 7 states the general conclusions of this thesis and outlines
future work. Chapter 2 provides the reader with the necessary probabilistic
background, while Chapter 8 brieﬂy discusses three other contributions made
during this research work that, although being outside the main scope of
this thesis text, are all concerned with the application and implementation
of Bayesian estimation techniques.

Chapter 2
Probabilistic Background
To provide the reader with the necessary probabilistic background, this chapter
elaborates on probability theory (Section 2.1), Bayesian networks (Section 2.2),
inference and learning in Bayesian networks (Section 2.3), marginalization (Sec-
tion 2.4), modeling (Section 2.5), and clustering (Section 2.6).
2.1
Probability Theory
Intelligent systems such as robots have to be able to perceive and manipulate
the world in which they are working. The world however is inherently uncertain:
• First of all, there are some uncertainties in the world, for instance the
number of persons and the positions of the persons in the room, that
the intelligent system wants to estimate explicitly by observing the world.
The variables to be estimated are typically grouped together and are
called the state.
• While intelligent systems are usually provided with models predicting
how the state evolves over time, the motion model, this evolution itself is
subject to uncertainty.
• To estimate the state, intelligent systems observe the world through
sensors. The measurements provided by these sensors and the process
underlying the measurement formation are however subject to uncertainty
themselves.
7

8
Chapter 2
Probabilistic Background
• Furthermore, the world can contain, on top of the estimated state,
uncertainties that the intelligent system does not want, or is not able
to estimate, for instance due to limited memory or computational power.
Probability theory provides a consistent framework for reasoning under uncer-
tainty.
2.1.1
The Probabilistic Approach
Random variables are the basic building blocks in probability theory. A random
variable models the uncertain outcome of a statistical experiment. There exist
three types of random variables, distinguished by the type of values they can
take according to speciﬁc probabilistic laws:
• continuous random variables map the events of a random process to an
inﬁnite number of possible values (uncountable set),
• discrete random variables map the events of a random process to a ﬁnite
number of distinct values (countable set), and
• mixed random variables map the events of a random process to a vector
that contains both continuous and discrete random variables.
Probabilistic inference is the process of calculating the probabilistic laws
underlying the random variable by observing some related random variables.
The probability mass function (pmf), P(X = x), is a function that gives the
probability that a discrete random variable X takes a value x:
P(X = x) .
(2.1)
Discrete probabilities are non-negative, i.e. P(X = x) ≥0, and sum to one:
X
x
P(X = x) = 1.
(2.2)
The shorter notation P(x) for P(X = x) is used throughout this thesis. The
probability density function (pdf), P(x), is a function that describes the
probability that a continuous random variable occurs at a certain place in the
uncountable output set of the continuous random variable. The probability of
the continuous variable random variable falling within a given region is given
by the integral of its pdf over this region:
P(x ∈[a, b]) =
Z
a,b
P(x) dx.
(2.3)

2.1 Probability Theory
9
Continuous probabilities are non-negative, i.e. P(x) ≥0, and the integral of
the pdf over the output set of the continuous random variables is unity:
Z
P(x) dx = 1.
(2.4)
Probability density function, probability, and probability density are used
interchangeably in literature and in this thesis.
The joint probability of two random variables X and Y describes the probability
that the random variable X takes a certain value x and the random variable
Y takes a certain value y:
P(x, y) = P(X = x and Y = y) .
(2.5)
The conditional probability of a random variable X given Y describes the
probability of X given that the random variable Y takes a certain value y:
P(x | y) = P(X = x | Y = y) .
(2.6)
The two basic rules of probability are the sum rule and the product rule. The
sum rule describes how the marginal probabilities can be determined from a
joint probability distribution:
P(x) =
X
y
P(x, y) and P(y) =
X
x
P(x, y)
(discrete), and
(2.7)
P(x) =
Z
y
P(x, y) dy and P(y) =
Z
x
P(x, y) dx
(continuous).
(2.8)
The product rule describes how a joint probability distribution can be
decomposed in a conditional and a marginal probability distribution:
P(x, y) = P(y | x) P(x) and P(x, y) = P(x | y) P(y) .
(2.9)
The theorem of total probability combines the sum and the product rule:
for discrete variables
(
P(x) = P
y P(x | y) P(y)
P(y) = P
x P(y | x) P(x)
, and
(2.10)
for continuous variables
(
P(x) =
R
y P(x | y) P(y) dy
P(y) =
R
x P(y | x) P(x) dx
.
(2.11)

10
Chapter 2
Probabilistic Background
A third rule of probability is Bayes’ theorem, describing how a conditional
probability distribution P(x | y) can be determined from P(y | x):
P(x | y) = P(y | x) P(x)
P(y)
.
(2.12)
An important concept in probability is independence. If two random variables
X and Y are (absolutely) independent their joint probability distribution
factorizes as:
P(x, y) = P(x) P(y) .
(2.13)
If two random variables X and Y are conditionally independent given the
random variable Z their joint probability distribution factorizes as:
P(x, y | z) = P(x | z) P(y | z) .
(2.14)
Conditional independence does not imply absolute independence.
The expected value and variance are two widespread statistics to summarize the
information in a probability distribution function or a probability mass function.
The expected value, also called expectation value, mathematical expectation,
expectation, mean, or ﬁrst moment, of a random variable is the integral/sum
of the random variable with respect to its probability measure:
E[X]
=
X
x
xP(x)
(discrete), and
(2.15)
E[X]
=
Z
x
xP(x)
(continuous).
(2.16)
The variance, also called second moment, is a measure for the squared expected
deviation from the expected value:
Var[X]
=
E[X −E[X]]2 = E

X2
−E[X]2 .
(2.17)
The covariance is more general than the variance and is a measure for the
extent to which two random variables X and Y vary together:
Cov[X, Y ]
=
Ex,y
h
(x −E[x])(yT −E[y]T )
i
.
(2.18)
Variance is a special case of the covariance when the two variables X and Y
are identical.

2.1 Probability Theory
11
Frequentist versus Bayesian
There are two diﬀerent ways in which probabilities can be interpreted. The ﬁrst
one is the frequentist, classical or objective interpretation of probability. In the
frequentist approach probabilities are interpreted as repeatable, random events.
A widely used frequentist estimator typically wants to estimate a state x by
optimizing the data likelihood function P(y | x) of the observed data (also called
measurements) y. Such estimator is called a maximum likelihood estimator.
The second interpretation is the Bayesian or subjective interpretation in which
probabilities provide a quantiﬁcation of uncertainty. This interpretation is also
referred to as subjective as it sees the probability as a personal belief of the
state. Central in the Bayesian interpretation is the use of Bayes theorem (2.12)
in the following interpretation:
P(x | y)
| {z }
posterior
∝P(y | x)
| {z }
likelihood
P(x)
| {z }
prior
,
(2.19)
where P(x) represents the subjective, a priori probability of the state under
estimation.
A Bayesian estimator estimates the state x by optimizing the
posterior P(x | y). Such estimator is called a maximum a posteriori estimator.
An important advantage of the Bayesian interpretation is the explicit inclusion
of prior knowledge, also referred to as expert knowledge: (i) it forces the user to
make prior assumptions explicit and (ii) it allows him to use prior knowledge
on the estimation problem.
This thesis uses the Bayesian interpretation of
probability.
2.1.2
Probability Distributions
This section lists some important probability mass functions and probability
distribution functions that are used throughout this thesis. For a more complete
and detailed overview we direct the reader to Bishop 2006.
Besides their discrete or continuous nature, another way to distinguish between
probability functions is whether they are based on a small set of parameters
or not.
A parametric distribution is a probability function with a speciﬁc
functional form governed by a small number of parameters. The advantage of
the limited number of parameters needed to represent the distribution, comes
at the cost of limited representational power: the speciﬁc functional form of
the parametric distribution can fail to capture the observed data.
A non-
parametric distribution however, makes few assumptions about the form of its
distribution. The increased representational power comes at the cost of a less
compact representation.

12
Chapter 2
Probabilistic Background
To understand the importance of some of the probability mass/density
functions listed below, it is important to understand the concept of conjugate
priors. Conjugate priors are an important tool to obtain practical Bayesian
estimation algorithms.
Conjugate priors are priors that lead to a posterior
distribution of the same functional form as the prior, thereby simplifying the
Bayesian analysis (see Equation (2.19)).
Parametric Distributions
A uniform distribution can be both continuous and discrete. The discrete
uniform distribution is a probability mass function that models the equal
probability with which the random variable takes a ﬁnite set of values, i.e.
there is no information on which of the possible values the random variable
will take:
P(X = x) =
(
1
N
if x ∈support X
0
otherwise,
(2.20)
where N is the number of diﬀerent values the random variable can take. The
continuous uniform distribution is a probability density function that models
the equal probability with which the random variable takes a value at any place
within a region, deﬁned by [a, b] below:
P(X = x) =
(
1
(b−a)
if x ∈[a, b]
0
otherwise.
(2.21)
The expected value and the covariance of the continuous uniform distribution
are given by:
E[x]
=
a + b
2
, and
(2.22)
Var[x]
=
(b −a)2
12
,
(2.23)
respectively.
The binomial distribution is a probability mass function describing the number
of successes k in a set of N Bernouilli trials. A Bernouilli trial is an experiment
with a probabilistic outcome that can either be success or failure.
If the

2.1 Probability Theory
13
probability of success is µ, the binomial distribution becomes:
P(k | N, µ)
=
(
N!
(N−k)!k!µk (1 −µ)N−k
if k ∈{0, 1, . . . N}
0
otherwise.
(2.24)
The expected value and covariance of the distribution are given by:
E[k|N, µ]
=
Nµ, and
(2.25)
Var[k|N, µ]
=
Nµ (1 −µ) ,
(2.26)
respectively.
The multinomial distribution is a probability mass function for discrete
variables that can take one of K possible values. A 1-of-K scheme is often used
to represent these discrete variables: this scheme describes the discrete random
variable by a vector with dimension K, in which the element corresponding to
the value the discrete variable takes is one, and all remaining elements are zero:
e.g.:
x = (0, 0, 1, 0)T ,
(2.27)
where xk = 1 if the discrete variable takes value k. If the probability that the
discrete variable takes value k is indicated with µk, the distribution of x is a
multinomial distribution given by:
P(x | µ)
=
K
Y
k=1
µxk
k ,
(2.28)
where µ = (µ1, . . . , µK)T . The expected value and variance of the multinomial
distribution are given by:
E[xk|µ]
=
µk, and
(2.29)
Var[xk]
=
µk (1 −µk) ,
(2.30)
respectively.
The Dirichlet distribution is the conjugate prior for the parameters µ of the
multinomial distribution and is given by:
P(µ | α) = Dir(µ|α) =
Γ
PK
k=1 αk

QK
k=1 Γ (αk)
K
Y
k=1
µαk−1
k
,
(2.31)

14
Chapter 2
Probabilistic Background
where Γ (.) is the gamma function. Remark that the Dirichlet distribution is
conﬁned to a simplex of dimensionality K−1 since 0 ≤µk ≤1 and PK
k=1 µk = 1.
The expected value and variance of the Dirichlet distribution are given by:
E[µk|α]
=
αk
PK
k=1 αk
, and
(2.32)
Var[µk]
=
αk
PK
k=1 αk −αk

PK
k=1 αk
2 PK
k=1 αk + 1
,
(2.33)
respectively. When using the Dirichlet as a conjugate prior for the multinomial
distribution, the parameters αk have a useful interpretation as the prior number
of observations of xk = 1, i.e. the prior belief that the discrete variable will
take value k.
The geometric distribution is a probability mass function that models the
number of trials in a Bernouilli process needed before getting one success (i.e.
the number of failures). The geometric distribution is a parametric distribution
determined by the single parameter p, which represents the probability of
success of a single trial:
P(k | p)
=
(1 −p)kp
with k ∈{0, 1, 2, . . .} .
(2.34)
The expected value and variance of the exponential distribution are given by:
E[k|p]
=
1 −p
p
, and
(2.35)
Var[k]
=
1 −p
p2
,
(2.36)
respectively.
The Poisson distribution is a probability mass function that models the
probability of a number of events, k, occuring in a ﬁxed period of time, where
the events are subject to a Poisson process. A Poisson process is a probabilistic
process in which events occur continuously and independently of one another. It
is the continuous counterpart of the Bernouilli process underlying the geometric
distribution. The Poisson process is a parametric distribution determined by a
single parameter, i.e.:
P(k | λ)
=
λk
k! exp (−λ) .
(2.37)

2.1 Probability Theory
15
The expected value and variance of the Poisson distribution are given by:
E[k|λ]
=
λ, and
(2.38)
Var[k]
=
λ,
(2.39)
respectively.
The exponential distribution is a probability density function that models
the time between events in a Poisson process. The exponential distribution is
a parametric distribution determined by a single parameter λ:
P(x | λ)
=
λ exp (−λx) .
(2.40)
The expected value and variance of the exponential distribution are given by:
E[x|λ]
=
1
λ, and
(2.41)
Var[x]
=
1
λ2 ,
(2.42)
respectively.
The Gaussian distribution, also called normal distribution, is the most widely
used probability density function. For a continuous random variable x with
dimension D the Gaussian distribution is given by:
N (x|µ, Σ) =
1
(2π)
D
2 |Σ|
1
2
exp

−1
2 (x −µ) Σ−1 (x −µ)T

,
(2.43)
with µ the mean vector, Σ the covariance matrix and |Σ| the determinant of
Σ. The expected value of a Gaussian distribution is its mean, and the variance
is equal to the covariance matrix, i.e. :
E[x]
=
µ, and
(2.44)
Var[x]
=
Σ.
(2.45)
The precision Λ is the inverse of the covariance matrix, i.e. Λ = Σ−1. The
widespread use of the Gaussian can be explained by a number of reasons:
• The Gaussian is the probability density function that maximizes the
entropy (Bishop 2006).

16
Chapter 2
Probabilistic Background
• The central limit theorem states that, under some mild conditions, the
sum of a set of random variables is a random variable of which the
distribution becomes more Gaussian as the number of terms in the sum
increases.
• The Gaussian has many interesting analytical properties (Bishop 2006),
e.g.:
– If two sets of variables are jointly Gaussian, the conditional
distribution on one set conditioned on the other is again Gaussian.
– The marginal distribution resulting from marginalizing a jointly
Gaussian distribution is also Gaussian.
The Gaussian-Wishart distribution is the conjugate prior for a Gaussian with
unknown mean and unknown precision, and is given by:
P(µ, Λ | µ0, β, W, ν)
=
N

µ|µ0, (βΛ)−1
W(Λ|W, ν) ,
(2.46)
with W(Λ|W, ν) the D-dimensional Wishart distribution deﬁned as:
W(Λ|W, ν)
∝
|Λ|
ν−D−1
2
exp
−1
2 trace
 W−1Λ

,
(2.47)
where trace (·) and | · | denote the trace and the determinant of a matrix,
respectively. The Wishart distribution has two parameters: ν is the number of
degrees of freedom and W is the scale matrix.
The Student’s t-distribution, also simply called the t-distribution, is a
parametric pdf that arises in the problem of estimating the mean of a normally
distributed variable in the case of small sample size, and is given by:
P(x | ν)
=
Γ
  ν+1
2

√νπΓ
  ν
2


1 + x2
ν
−ν+1
2
,
(2.48)
with Γ (.) the gamma function, and ν the degrees of freedom of the Student’s
t-distribution. The expected value of a Student’s t-distribution is 0, and the
variance is given by:
Var[x]
=
ν
ν −2.
(2.49)

2.1 Probability Theory
17
Non-parametric Distributions
A histogram is a non-parametric approximation of a continuous density
function. It decomposes the state space of the continuous random variable into
ﬁnitely many regions and represents the probability that the continuous random
variable falls withing a region as a single probability. The histogram is not
bound to any underlying functional description and can therefore approximate
probability density functions of any shape.
The histogram has two main
limitations however: (i) the discontinuities at the borders of the regions and
(ii) the exponential scaling of the histogram with the dimension of the state
space.
Just like the histogram, the Monte Carlo (MC) probability distribution
(MCPdf) or particle distribution is a non-parametric approximation of
continuous density functions. The MCPdf consists of a ﬁnite set of samples,
also called particles, drawn from the pdf it approximates:

x(i)	
i=1:Np, with
i the sample index, and Np the total number of samples. This sample-based
approximation can be formalized as:
P(x)
≈
Np
X
i=1
δx(i) (x) ,
(2.50)
with δa (.) the Dirac delta measure with mass at a.
A MCPdf can also
consist of a set of weighted samples

x(i), w(i)	
i=1:Np resulting in the following
approximation:
P(x)
≈
Np
X
i=1
w(i)δx(i) (x) .
(2.51)
Just like the histogram, the MCPdf is not bound to any underlying functional
description, and can therefore approximate probability density functions of any
shape. The MCPdf also has two main limitations however: (i) the discontinuous
description of the pdf as a sum of Dirac functions, and (ii) the exponential
growth of the number of samples needed to represent the pdf with the dimension
of the state space.

18
Chapter 2
Probabilistic Background
Mixtures
A mixture is a probability mass/density function that is a weighted sum of
other probability mass/density functions:
P(x) =
N
X
n=1
πnPn (x) ,
(2.52)
where N is the number of components in the mixture and πn are the component
weights.
The component weights indicate the relative importance of the
diﬀerent components in the mixture and have to obey the following rules:
(
0 ≤πn ≤1
∀n ∈1 . . . N, and
PN
n=1 πn = 1.
(2.53)
The expected value of a mixture is the weighted sum of the expected values of
its components, weighted according to component weights:
E[x] =
N
X
n=1
πnEx[n] .
(2.54)
2.2
Bayesian Networks
Bayesian networks graphically represent probabilistic relationships between
variables in a mathematical model, to structure and facilitate probabilistic infer-
ence computations with those variables (Jensen and Nielsen 2007; Neapolitan
2004). A Bayesian network is deﬁned as follows:
• A Bayesian network is represented by a set of nodes, also called vertices,
each with an associated random variable, connected by directed edges,
also called links or arcs, forming a directed acyclic graph (DAG);
• Associated with each node of the Bayesian network is a discrete/contin-
uous random variable having a ﬁnite/inﬁnite set of mutually exclusive
states;
• Each random variable A with parents B1, . . . , BN has a conditional prob-
ability distribution P(A | B1, . . . , BN) (known as conditional probability
table in the case of discrete variables).

2.2 Bayesian Networks
19
A
B
C
D
Em
F
G
M
p
Figure 2.1: Bayesian network example with nodes and directed connections
(edges) forming a directed acyclic graph (DAG) and an explicit parameter p.
The box (plate) denotes a set of M similar nodes. The shaded node is observed.
In this thesis observed random variables, also called evidence, are indicated
in the Bayesian network by shading the corresponding node of the network.
Unobserved random variables are also known as hidden or latent random
variables.
Plates are another graphical notation allowing for a compact
graphical representation. A plate represents a set of M similar nodes: a plate is
graphically represented by a single representative of the M nodes, surrounded
with a rounded box containing the number of similar nodes in its lower right
corner. In this thesis explicit parameters in the Bayesian network are indicated
with a letter, not encircled by a node. Figure 2.1 shows a simple example of a
Bayesian network and clariﬁes the representation of Bayesian networks used in
this thesis.
The graph associated with the Bayesian network represents a decomposition
of the joint probability distribution over all variables x in the graph in terms
of the product of a set of conditional distributions, one for each node in the
graph. More speciﬁcally, the joint distribution deﬁned by the graph is given by
the product, over all nodes of the graph, of a conditional distribution for each
node, conditional on the variables corresponding to the parents of that node in
the graph, i.e.:
P(x) =
N
Y
n=1
P(xn | p (n)) ,
(2.55)
where N is the total number of nodes in the graph, p (n) denotes the set of
parent nodes of node n, and xn the random variable associated with node
n (Bishop 2006).

20
Chapter 2
Probabilistic Background
Although the deﬁnition of Bayesian networks does not refer to causality, and
there is no requirement that the directed edges represent causal impact, a
well-known way of structuring variables for reasoning under uncertainty is to
construct a graph representing causal relations (Jensen and Nielsen 2007). In
this case the graphical models are also known as generative models (Bishop
2006), since they capture the causal process generating the random variables.
This thesis uses causality to construct Bayesian networks, since this causality
best reﬂects physical intuition.
Bayesian networks oﬀer several useful properties (Bishop 2006):
• They provide a simple way to visualize the structure of a probabilistic
model, and they can be used to design and motivate new models.
• Insights into the properties of the model, including conditional indepen-
dence properties, can be obtained by inspection of the Bayesian network
graph.
• Complex computations, required to perform inference and learning sophis-
ticated models, can be expressed in terms of graphical manipulations, in
which underlying mathematical expressions are carried along implicitly.
Bayesian networks can be used for inference, learning and decision making.
Inference is the process of estimating some latent variables given some observed
variables. The main interest of this thesis is to perform this inference online,
as new data is received. Learning is the process of estimating the conditional
probabilities, the parameters, or even the structure of the Bayesian network
from data. Due to its diﬃculty and need for large amount of informative data,
learning is usually performed oﬄine, during a training phase. Decision making
is usually the last step after inference and learning and involves, based on the
outcome of inference and learning, making a (discrete) decision. To this end
the Bayesian network can be extended to a decision graph consisting of utility
and decision nodes (Jensen and Nielsen 2007). Decision making is not handled
in this thesis.
2.3
Inference and Learning in Bayesian Networks
Inference and learning in a general Bayesian network are hard tasks, especially
when the Bayesian network contains continuous random variables and (condi-
tional) probabilities that are not a member of the exponential family.
This section does not aim at discussing the learning and inference algorithms
available in literature, but discusses the most important algorithms that are
used throughout this thesis.

2.3 Inference and Learning in Bayesian Networks
21
y
x
Θ
Figure 2.2: Bayesian network model for the EM-algorithm. With Θ the set of
parameters, x the latent variables and y the observations or data.
2.3.1
Expectation-Maximization
The expectation-maximization (EM) algorithm (Dempster et al. 1977; Shumway
and Stoﬀer 1982) is an iterative inference method for the learning of parameters
Θ in presence of latent variables x.
In general, it is an oﬄine, iterative,
maximum likelihood method that is guaranteed to converge to a local maximum
of the observed data likelihood function, P(y | Θ), where y is the set of
observations (data).
Figure 2.2 shows the Bayesian network representation
of the general EM algorithm with the observations, the parameters and latent
variables.
The EM algorithm is based on the observation that the maximization of
the complete data likelihood P(x, y | Θ), i.e. the likelihood of the data and
the latent variables, is usually easier than the maximization of the observed
data likelihood function.
The latent variables are unknown however.
The
most recent information about the latent variables is given by the posterior
distribution P(x | Θ, y). Since the posterior over the latent variables x requires
the knowledge of the parameters Θ and the maximization of the complete
data likelihood requires the latent variables x, this results in a chicken-and-egg
problem. The EM algorithm uses an iterative procedure to circumvent this
chicken-and-egg problem: after making an initial estimate of the parameters Θ
two steps are iterated (τ indicates the iteration step):
1. The E-step estimates the posterior distribution over the latent variables
P(x | Θτ, y), using the most recent estimate of the parameters (Θτ). This
posterior is then used to construct the expectation of the complete data

22
Chapter 2
Probabilistic Background
log likelihood:
Q(Θ | Θτ)
=
EP(x | Θτ,y)[ln (P(x, y | Θ))]
(2.56)
=
Z
P(x | Θτ, y) ln P(x, y | Θ) dx.
(2.57)
2. The M-step maximizes Q(Θ | Θτ) to obtain a new estimate of the
parameters:
Θτ+1
=
argmax
Θ
Q(Θ | Θτ) .
(2.58)
Since the E- and M-step can be shown to increase the observed data log
likelihood, the EM-algorithm is guaranteed to converge to an at least local
optimum. Nevertheless, both the E- and M-step can still remain intractable,
since the dimensionality of the space of latent variables can be too high, and
the expectation in Equation (2.56) can be analytically intractable.
Section 2.6.2 applies the EM algorithm to the clustering of data points.
2.3.2
Variational Bayes
Variational Bayes (VB), also called variational inference, techniques (Jordan
1999; Jaakkola and Jordan 2000) use deterministic approximation schemes
based on the analytical approximation of the posterior distributions. Although
the approximate nature of variational Bayesian techniques does not guarantee
the solutions to be optimal, they are widely used when the exact solution is
intractable. Variational inference tries to make the optimizations or probability
calculations tractable by restricting them to a limited range of probability
distributions. Two popular ways to restrict the distributions are (Bishop 2006):
• to use parametric distributions.
In this case the optimization over all
possible probability distributions boils down to the optimization of a
ﬁnite set of parameters underlying the parametric distribution;
• to use factorized distributions. In this case the probability distribution
is assumed to be a product of a set of factors, each depending on a sub-
group of the variables and parameters to estimate. The optimization is
done by optimizing with respect to each of the factors in turn. Remark
that there is no restriction on the function form of the individual factors.
Section 2.6.3 applies VB inference with factorized distributions to the clustering
of data points.

2.3 Inference and Learning in Bayesian Networks
23
2.3.3
Bayes Filters
The most basic algorithm for sequentially calculating/estimating a target state
xt at time step t given some observations y1:t is the Bayes ﬁlter. The probability
distribution of interest in the sequential setting is the posterior P
 xt | y1:t
.
The Bayes ﬁlter starts with an initial belief over the target state P
 x0
. After
this initialization, P
 xt | y1:t
is sequentially updated. A single iteration of a
Bayes ﬁlter at a time step t consists of two essential steps: the prediction step
and the correction step. In the prediction step the new target state is predicted
using the information from the previous time step and the target process model
P
 xt | xt−1
modeling the state transition over time:
P
 xt | y1:t−1
=
Z
P
 xt | xt−1
P
 xt−1 | y1:t−1
dxt−1.
(2.59)
In the correction step, also called measurement update, the measurement
information of time step t is applied to update the target state estimate by
using the measurement model P(yt | xt):
P
 xt | y1:t
∝
P
 yt | xt
P
 xt | y1:t−1
.
(2.60)
An essential assumption underlying the Bayes ﬁlter is the Markov assumption,
also referred to as the complete state assumption.
The Markov assumption
states that the past and the future are independent given the current state xt,
i.e.:
P
 xt−1, xt+1 | xt
=
P
 xt−1 | xt
P
 xt+1 | xt
.
(2.61)
Thrun et al.
2005 list some factors resulting in a violation of the Markov
assumption, of which the following are relevant for this thesis:
• unmodeled dynamics, i.e. dynamics not included in the target state,
• inaccuracies in the probabilistic process and measurement model, and
• approximation errors when using approximate representations of proba-
bilities.
While, in theory, the above factors can be included in the state space,
incomplete state representations are often preferable to limit the computational
complexity of the algorithms. In practice, Bayes ﬁlters have been found to be
suprisingly robust to Markov assumption violations (Thrun et al. 2005).

24
Chapter 2
Probabilistic Background
...
...
yt−1
yt−1
yt+1
xt−1
xt
xt+1
Figure 2.3: Bayesian network model for the Bayes ﬁlter. The shaded nodes are
observed.
Figure 2.3 shows the Bayesian network representation of the Bayes ﬁlter.
Bayes ﬁlters can be implemented in diﬀerent ways, depending on the
assumptions made regarding to the representation of the process model, the
measurement model, and the prior.
2.3.3.1
Kalman Filter
The Kalman ﬁlter (KF), also called Gaussian ﬁlter, was the earliest tractable
implementation of the Bayes ﬁlter for continuous state spaces, and it is still
one of the most popular estimation algorithms.
The Kalman ﬁlter is a parametric ﬁlter that is founded on the following
assumptions:
• The process model is assumed to be a linear function with additive
Gaussian noise:
P
 xt | xt−1
= N
 xt|F txt−1, Qt
,
(2.62)
where F t is the process model matrix and Qt the process model
covariance.
• The measurement model is assumed to be a linear function with additive
Gaussian noise:
P
 yt | xt
= N
 yt|Gtxt, Rt
,
(2.63)
where Gt is the measurement model matrix and Rt the measurement
model covariance.

2.3 Inference and Learning in Bayesian Networks
25
• The prior is assumed to be Gaussian:
P
 x0
= N
 x0|µ0, Σ0
.
(2.64)
Under these assumptions the Bayes ﬁlter equations can be calculated in closed
form and the posterior is the Gaussian N
 xt|µt, Σt
. The prediction step of
Equation (2.59) gives rise to a Gaussian prediction probability:
P
 xt | y1:t−1
=
N

xt|¯µt, ¯Σ
t
,
(2.65)
with
¯µt
=
F tµt−1,
(2.66)
¯Σ
t
=
F tΣt−1F tT + Qt.
(2.67)
Similarly, the correction step of Equation (2.60) gives rise to a Gaussian
posterior probability:
P
 xt | y1:t
= N
 xt|µt, Σt
,
(2.68)
with
µt
=
¯µt + Kt  yt −Gt ¯µt
,
(2.69)
Σt
=
 I −KtGt ¯Σ
t,
(2.70)
where
 yt −Gt ¯µt
is also referred to as the innovation, νt, and Kt is the
Kalman gain, calculated as:
Kt
=
¯Σ
tGtT 
Gt ¯Σ
tGt + Rt−1
.
(2.71)
The extended Kalman ﬁlter (EKF) relaxes the assumption on the linear
process and measurement model.
By linearizing the non-linear process and
measurement model around the current estimate, the same machinery as the
Kalman ﬁlter can be used, however due to the linearization, leading to an
approximate Bayes estimator.
The unscented Kalman ﬁlter (UKF) is similar to the extended Kalman ﬁlter, but
instead of linearizing the process and measurement model around the current

26
Chapter 2
Probabilistic Background
estimate, it performs a stochastic linearization through the use of a weighted
statistical regression using so-called sigma-points.
Due to the parametric representation of the posterior as a Gaussian the
Kalman ﬁlter and its variants are only suited for estimation problems where
the posterior can be approximated by a Gaussian. Kalman ﬁlters are therefore
not suited for handling for instance multimodal posterior distributions.
2.3.3.2
Particle Filter
The particle ﬁlter (PF), also called sequential Monte Carlo (SMC) ﬁlter, is a
non-parametric ﬁlter representing the posterior by a Monte Carlo distribution
(see Section 2.1.2). While the particle representation is only approximate, it
can represent a much broader space of distributions than for example Gaussians,
and it can handle non-linear process and measurement models.
In the particle ﬁlter the posterior is approximated by a ﬁnite set of weighted
samples

wt,(i), xt,(i)	
i=1:Np as in Equation (2.51).
In the proposal step of the particle ﬁlter the particles are sampled from a
proposal distribution:
xt,(i)
∼
Q

¯x | xt−1,(i), yt
.
(2.72)
In the weight update step of the particle ﬁlter, the weights of the particles
sampled in the proposal step are updated as:
wt,(i) = wt−1,(i) P
 yt | xt,(i)
P
 xt,(i) | xt−1,(i)
Q
 xt,(i) | xt−1,(i), yt
.
(2.73)
Due to the ﬁnite set of samples used to approximate the posterior, the particle
ﬁlter suﬀers from impoverishment, also called degeneracy or depletion, where
after some iterations one particle, the most probable one, will carry all the
weight (all other particles will have weight zero). To ﬁght the impoverishment
a resampling step is added to the particle ﬁlter. This resampling step relocates
the particles over the state space, focusing the computational resources, i.e. the
particles, to regions in the state space with higher probabilities.
For more details on the particle ﬁlter, including a discussion on how to choose
the proposal, other methods to ﬁght impoverishment, and the convergence of
particle ﬁlters, this thesis refers to Gadeyne 2005.

2.5 Marginalization
27
2.4
Marginalization
Marginalization is the process of obtaining marginal probabilities from joint
probability distributions as in Equations (2.7) and (2.8).
Marginalization
is a known method to treat so called nuisance variables in statistical
methods (Streit and Luginbuhl 1995). Marginalization removes the dependency
on the particular outcome of the variables marginalized, while maintaining
the dependency on the distributional parameters of these variables.
The
technique of marginalization is therefore useful in situations where the state
is high-dimensional, making the state estimation problem computationally
complex, while some state variables are not of primary interest. Marginalization
of these state variables avoids the increase in complexity to infer the
probability distributions of the remaining state variables, while maintaining
the dependency on the distributional parameters of the variables marginalized.
Chapter 3 applies the idea of marginalization to obtain a tractable measurement
model for range ﬁnders suited for dynamic environments.
2.5
Modeling
This section explains how probabilistic motion models and measurement
models, especially useful in sequential ﬁlters, can be constructed.
2.5.1
Motion Models
Motion models P
 xt | xt−1
, also called process or state space models, model
the state transition over time.
If the target state describes the state of a
controllable device, e.g. a robot, the motion model can also take into account
the control signals u: P
 xt | xt−1, u

. In the probabilistic modeling used in this
thesis, the motion model is a probabilistic rather than deterministic function
accounting for the uncertainty in the state transition. A very common model
is the constant Nth-order-derivative model: 0th-order is constant position, 1st-
order is constant velocity, etc. For the constant Nth-order derivative model the
state is constructed using all derivatives from the state vector x from the 0th
to the Nth order:

x
x(1)
. . .
x(N)T , resulting in the following expression
for the constant Nth-order-derivative model:


x
x(1)
. . .
x(N)


t
=


1
∆t
∆t2
2
. . .
∆tN
N!
0
1
∆t
. . .
∆tN−1
(N−1)!
. . .
. . .
. . .
. . .
. . .
0
0
0
. . .
1




x
x(1)
. . .
x(N)


t−1
+ νt,
(2.74)

28
Chapter 2
Probabilistic Background
with ∆t the time step, and νt the process noise distributed according to
N (0, Q) with:
Q
=
σ2
N+1GT G, and
(2.75)
G
=
h
∆tN+1
(N+1)!
∆tN
N!
. . .
∆t
i
,
(2.76)
where σ2
N+1 is a measure for the uncertainty on the unmodeled (N + 1)th
derivative.
The popularity of the constant Nth-order-derivative model is
mainly due its linearity and simplicity (it belongs the class of linear models with
additive Gaussian noise), making it suitable for even the most basic Kalman
ﬁlters.
Another motion model, which has been proved to be very useful in the
application of multitarget tracking, is the switching state space model, also
referred to as jump Markov systems or Markovian switching systems. Switching
state space models describe system dynamics that can switch in a discrete
manner from one operating regime to another.
The state in these models
is hybrid and consists of a continuous and discrete part. The discrete state
indicates in which of the operating regimes the system is.
For reasons of
tractability and simplicity, the switching state space models are often limited
to switch between a set of linear dynamic systems:
xt
=
F (dt)xt−1 + H(dt)νt,
(2.77)
with dt the discrete part of the state having M possible values indicating one
of the M operating regimes, and F (dt) and H(dt) the system model matrices
of the corresponding operating regime. Each of the linear dynamic systems
can for instance correspond to a constant Nth-order-derivative model as in
Equation (2.74), where each one can have a diﬀerent level of continuity. Even
in this linear case the application of analytic representations to switching state
space models is not straightforward (Gadeyne 2005). Consider for instance
the case where the state is initially represented by a single Gaussian.
In
the next time step, the state will be represented by a mixture of Gaussians,
where each component is due to a feasible switch of the switching state
space model.
In the next time step, each component in turn will give
rise to multiple new components, etc, resulting in an exponential growth
of the number of components in the mixture.
Several methods have been
proposed for approximately solving the estimation problem with switching state
space models, such as generalized pseudo Bayes (GPB) algorithms (Ackerson
and Fu 1970), interacting multiple model (IMM) ﬁlters (Blom 1984; Blom
and Bar-Shalom 1988; Bar-Shalom and Li 1993), Rao-Blackwellized particle
ﬁlters (Montemerlo et al. 2002), particle ﬁlters (Gadeyne 2005), etc. In the

2.6 Clustering
29
application of multitarget tracking, the IMM ﬁlter has been very popular. The
IMM ﬁlter reduces the multimodal posterior at each time step to a single
Gaussian and only requires M Kalman ﬁlter updates (with M the number
of possible switches).
2.5.2
Measurement Models
Measurement models P(yt | xt), also known as sensor, observation or perception
models, model the formation process by which sensor measurements are
generated in the physical world (Thrun et al. 2005). In many applications,
especially in robotics, the dependency of the measurements on the environment
is explicitly written in the measurement model as:
P(yt | xt, m), where
m represents a map of the environment.
Similar to the motion model,
the measurement model is a probabilistic rather than deterministic function
accounting for the uncertainty in the measurement formation process.
The
uncertainty is embedded in the stochastic nature of the model, particularly
in the conditional probability density representing the measurement process.
When using the measurement model during inference or learning, it is of
vital importance that all types of inaccuracies aﬀecting the measurements are
incorporated in the probabilistic measurement model. Inaccuracies arise from
sensor limitations, noise, and the fact that most complex environments can
only be represented and perceived in a limited way. The dynamic nature of the
environment in particular is an important source of inaccuracies. This dynamic
nature results from the presence of unmodeled and possibly moving objects and
people.
The speciﬁc expression of the measurement model primarily depends on the
type of sensor used (laser distance sensors, cameras, range ﬁnders, force sensors,
etc.) and the physics underlying the sensor. Chapter 3 shows how Bayesian
networks can help to develop a transparent and intuitive measurement model
for a range ﬁnder that is adapted to dynamic environments.
2.6
Clustering
The clustering of data points is a problem that is mentioned several times
throughout this thesis.
To help the reader, this section explains diﬀerent
approaches, both probabilistic and non-probabilistic, Bayesian and non-
Bayesian, to cluster data that are appearing as blobs in the space of clustering.
The data is given by a set of (possibly multidimensional) data points {yk}k=1:K.
The problem of clustering is the problem of ﬁnding groups, or clusters, of data
points. Therefore the goal is to ﬁnd:

30
Chapter 2
Probabilistic Background
• the number of clusters M,
• the positions of the clusters {µm}m=1:M, and
• an assignment of data points to clusters.
2.6.1
K-means Clustering
K-means clustering assumes that the number of clusters, M, is known.
K-
means clustering can be formulated using a hidden correspondence variable
ak = {akm}m=1:M, where only the one element akm assigning data point k to
cluster m is one, and all remaining elements are zero. K-means clustering uses
an iterative scheme to minimize the following objective function:
J =
K
X
k=1
M
X
m=1
akm||yk −µm||2.
(2.78)
After deﬁning initial guesses for the cluster means µm, k-means clustering
iterates two steps until convergence:
1. minimize J with respect to akm keeping µm ﬁxed by assigning the kth
data point to the closest cluster center:
akm =



1
if m = argmin
j
||yk −µj||2
0
otherwise,
(2.79)
2. minimize J with respect to µm keeping akm ﬁxed:
µm
=
P
k akmyk
P
k akm
.
(2.80)
Since each step in the iteration reduces the objective function J, convergence
to an at least local optimum is guaranteed.
2.6.2
EM Clustering
Expectation-maximization clustering (EM clustering) formulates the clustering
problem as the problem of ﬁtting a Gaussian mixture with M components:
P(y) =
M
X
m=1
AmN (y|µm, Σm) ,
(2.81)

2.6 Clustering
31
to the data points.
In contrast to k-means clustering, EM clustering is
a probabilistic clustering approach.
Just like the k-means clustering, EM
clustering assumes that the number of clusters is known, and it makes use
of hidden correspondence variables ak = {akm}m=1:M. Due to its probabilistic
nature, the EM-clustering attaches a multinomial probability distribution to
the correspondence variables:
P(ak | A)
=
M
Y
m=1
Aakm
m
,
(2.82)
with A = {Am}m=1:M. The conditional likelihood of a data point given the
data association variables is:
P(yk | ak, µ, Σ)
=
M
Y
m=1
N (yk|µm, Σm)akm ,
(2.83)
where µ = {µm}m=1:M and Σ = {Σm}m=1:M. The data point likelihood is
determined by integrating out the correspondence variables:
P(yk | µ, Σ, A)
=
X
ak
P(ak | A) P(yk | ak, µ, Σ)
(2.84)
=
X
ak
M
Y
m=1
(AmN (yk|µm, Σm))akm
(2.85)
=
M
X
m=1
AmN (yk|µm, Σm) .
(2.86)
By assuming that all data points are independent given the cluster data, the
entire data likelihood function is:
P(y | µ, Σ, A)
=
K
Y
k=1
M
X
m=1
AmN (yk|µm, Σm) .
(2.87)
Figure 2.4 shows the Bayesian network representation of the model underlying
the EM clustering algorithm.
EM clustering uses an iterative EM-procedure (Section 2.3.1) to ﬁnd a
maximum likelihood solution for the cluster parameters by maximizing the

32
Chapter 2
Probabilistic Background
yk
ak
A
K
Σ
µ
Figure 2.4: Bayesian network model for clustering of measurements through
EM-clustering with a mixture of Gaussians. The box (plate) denotes a set of
K measurements. The shaded nodes are observed.
observed data log likelihood:
log P(y | µ, Σ, A)
=
K
X
k=1
log
M
X
m=1
AmN (yk|µm, Σm) .
(2.88)
In EM terms, ak are the latent or hidden variables, and µ, Σ and A are the
parameters.
In the E-step the responsabilities wkm (Bishop 2006) are calculated.
The
responsability wkm is the posterior probability that akm = 1.
It can be
interpreted as the responsability of cluster m for explaining data point yk,
and it is given by:
wkm
≜
P(akm = 1 | y, µ, Σ, A)
(2.89)
=
AmN (yk|µm, Σm)
PM
j=1 AjN
 yk|µj, Σj
.
(2.90)
In the M-step the parameters are re-estimated using the responsabilities
calculated in the E-step:
µm
=
PK
k=1 wkmyk
PK
k=1 wkm
,
(2.91)
Σm
=
PK
k=1 wkm (yk −µm) (yk −µm)T
PK
k=1 wkm
, and
(2.92)
Am
=
PK
k=1 wkm
K
.
(2.93)

2.6 Clustering
33
The E- and M-step are iterated until convergence.
The EM-algorithm is
guaranteed to converge to an at least local optimum, since each iteration
increases the data log likelihood log P(y | µ, Σ, A).
In contrast to the hard assignment in k-means clustering where each data point
is assigned to one cluster, the EM-clustering performs a soft assignment of data
points to clusters where each data point yk is assigned to cluster m with a
certain probability wkm.
2.6.3
VB Clustering
Variational Bayesian clustering (VB clustering) results from applying varia-
tional Bayesian estimation techniques (Section 2.3.2) to the clustering problem
formulated as ﬁtting a Gaussian mixture, as in Equation (2.81), to the data
points.
While VB clustering is similar to EM clustering, there exists an essential
diﬀerence: µ, Σ and A are considered to be variables rather than parameters
as in the EM clustering. As such, (conjugate) prior probabilities are attached
to these variables:
• a Dirichlet prior for the mixing coeﬃcients/component weights:
P(A | α0)
=
C (α0)
M
Y
m=1
Aα0m−1
m
,
(2.94)
where the constant C (α0) is deﬁned according to Equation (2.31), and
• an independent Gaussian-Wishart prior for the mean and precision of
each Gaussian component of the mixture:
P(µ, Λ | m0, β0, W0, ν0) =
M
Y
m=1
N

µm|m0, (β0Λm)−1
W(Λm|W0m, ν0m) .
(2.95)
VB clustering optimizes the data log likelihood by using approximate varia-
tional inference techniques. Variational inference approximates the optimiza-
tion of the data log likelihood by only optimizing over a restricted range of
functions. In VB clustering the solution is assumed to factorize between the
correspondence variables a and the cluster parameters A, µ and Σ, i.e.:
Q(a, A, µ, Σ)
=
Q(a) Q(A, µ, Σ) .
(2.96)

34
Chapter 2
Probabilistic Background
yk
ak
A
K
M
Λm
µm
α0
β0m
m0m
W0m
ν0m
Figure 2.5: Bayesian network model for clustering of measurements through
variational Bayesian clustering for a mixture of Gaussians. The boxes (plates)
denote a set of K weighted measurements and a set of M clusters. The shaded
nodes are observed.
Under this assumption the variational Bayesian approach leads to an iterative
solution with two steps equivalent to the E- and M-step in the EM algorithm.
Figure 2.5 shows the Bayesian network representation of the VB clustering
algorithm.
In the variational ‘E-step’ the responsabilities wkm (Bishop 2006) are
calculated. The responsability wkm is the posterior probability that akm = 1.
It can be interpreted as the responsability of cluster m for explaining data point
yk, and it is given by:
wkm ∝eAm eΛm exp
 D
2βm
−νm
2 (yk −mm)T Wm (yk −mm)

,
(2.97)
with
ln eAm
=
ψ(αm) −ψ(
M
X
j=1
αj),
(2.98)
ln eΛm
=
D
X
d=1
ψ
νm + 1 −d
2

+ D ln 2 + ln |Wm|, and
(2.99)
with D the dimension of the state space, and ψ (·) the digamma func-
tion (Abramowitz and Stegun 1965).

2.6 Clustering
35
In the variational
M-step the parameters are re-estimated using the
responsabilities calculated in the E-step:
αm
=
α0m + Km,
(2.100)
βm
=
β0m + Km,
(2.101)
mm
=
1
βm
(β0mm0m + Km ¯µm) ,
(2.102)
W−1
m
=
W0
−1
m + KmSm + β0mKm
β0 + Km
(¯µm−m0m) (¯µm−m0m)T,(2.103)
νm
=
ν0m + Km,
(2.104)
with
Km
=
K
X
k=1
wkm,
(2.105)
¯µm
=
1
Km
K
X
k=1
wkmyk, and
(2.106)
Sm
=
1
Km
K
X
k=1
wkm (yk −¯µm) (yk −¯µm)T .
(2.107)
VB clustering iterates the E- and M-step until convergence. The algorithm
is guaranteed to converge to an at least local optimum, since each iteration
increases the data log likelihood log P(y | µ, Σ, A).
While VB clustering has only little computational overhead with respect to the
EM-clustering, it has some substantial advantages over it (Bishop 2006):
• The maximization of the log-likelihood in the EM-clustering is an ill-
posed problem, since there are always singularities that occur when a
Gaussian component collapses onto a single data point. VB clustering
does not suﬀer from singularities, since a prior is included on the Gaussian
component shape, i.e. its covariance prevents it from collapsing onto a
single data point.
• In contrast to EM clustering, VB clustering does not suﬀer from over-
ﬁtting if the number of mixture components M is larger than the actual
number of data point clusters.

36
Chapter 2
Probabilistic Background
• Finally, VB clustering can automatically determine the optimal number of
components in the mixture, without resorting to techniques such as cross
validation.
This property is known as Automatic Relevance Detection
(ARD). ARD is achieved by using the prior over the mixing coeﬃcient
such that solutions are favored in which some of the mixing coeﬃcients
are zero, i.e. by choosing α0m ≤1.

Chapter 3
A Rigorously Bayesian Beam
Model and an Adaptive Full
Scan Model for Range
Finders in Dynamic
Environments1
This paper proposes and experimentally validates a Bayesian network model of
a range ﬁnder adapted to dynamic environments. All modeling assumptions are
rigorously explained, and all model parameters have a physical interpretation.
This approach results in a transparent and intuitive model. With respect to
the state-of-the-art beam model this paper: (i) proposes a diﬀerent functional
form for the probability of range measurements caused by unmodeled objects,
(ii) intuitively explains the discontinuity encountered in the cited paper, and
(iii) reduces the number of model parameters, while maintaining the same
representational power for experimental data.
The proposed beam model
is called RBBM, short for rigorously Bayesian beam model.
A maximum
likelihood and a variational Bayesian estimator (both based on expectation-
maximization) are proposed to learn the model parameters.
1This chapter has been published as a full article in the Journal of Artiﬁcial Intelligence
Research:
Tinne De Laet, Joris De Schutter, and Herman Bruyninckx;
A rigorously
Bayesian beam model and an adaptive full scan model for range ﬁnders in dynamic
environments; Journal of Artiﬁcial Intelligence Research, volume 33, pp.
179–222, 2008;
Available online: http://jair.org/papers/paper2540.html. Only minor changes concerning
notational consistency and lay-out have been performed.
37

38
Chapter 3
Range Finder Model for Dynamic Environments
Furthermore, the RBBM is extended to a full scan model in two steps: ﬁrst,
to a full scan model for static environments and next, to a full scan model
for general, dynamic environments.
The full scan model accounts for the
dependency between beams and adapts to the local sample density when using
a particle ﬁlter.
In contrast to Gaussian-based state-of-the-art models, the
proposed full scan model uses a sample-based approximation. This sample-
based approximation enables handling dynamic environments and capturing
multimodality, which occurs even in simple static environments.
3.1
Introduction
In a probabilistic approach, inaccuracies are embedded in the stochastic nature
of the model, particularly in the conditional probability density representing
the measurement process. It is of vital importance that all types of inaccuracies
aﬀecting the measurements are incorporated in the probabilistic sensor model.
Inaccuracies arise from sensor limitations, noise, and the fact that most complex
environments can only be represented and perceived in a limited way. The
dynamic nature of the environment in particular is an important source of
inaccuracies. This dynamic nature results from the presence of unmodeled and
possibly moving objects and people.
This paper proposes a probabilistic range ﬁnder sensor model for dynamic
environments. Range ﬁnders, which are widely used in mobile robotics, measure
the distances z to objects in the environment along certain directions θ relative
to the sensor. We derive the sensor model in a form suitable for mobile robot
localization, i.e.: P(Z = z | X = x, M = m)2, where Z indicates the measured
range, X the position of the mobile robot (and of the sensor mounted on it),
and M the environment map. The presented model is however useful in other
applications of range sensors as well.
First, this paper derives a probabilistic sensor model for one beam of a range
ﬁnder, i.e. the beam model. In particular, this paper gives a rigorously Bayesian
derivation using a Bayesian network model while stating all model assumptions
and giving a physical interpretation for all model parameters. The obtained
model is named RBBM, short for rigorously Bayesian beam model.
The
innovations of the presented approach are (i) to introduce extra state variables
A = a for the positions of unmodeled objects in the probabilistic sensor
model P(z | x, m, a), and (ii) to marginalize out these extra state variables
from the total probability before estimation. The latter is required because
extra variables (exponentially!) increase the computational complexity of state
2To simplify notation, the explicit mention of the random variable in the probabilities is
omitted whenever possible, and replaced by the common abbreviation P (x) instead of writing
P (X = x).

3.2 Related Work
39
estimation while in a lot of applications estimating the position of unmodeled
objects is not of primary interest. In summary, the marginalization avoids the
increase in complexity to infer the probability distributions P(x) and P(m),
while maintaining the modeling of the dynamic nature of the environment.
This paper furthermore presents a maximum-likelihood and a variational
Bayesian estimator (both based on expectation-maximization) to learn the
model parameters of the RBBM.
Next, the paper presents an extension of the RBBM to a full scan model i.e.:
P(z | θ, x, m) where z and θ contain all the measured distances and beam
angles, respectively. This full scan model accounts for the dependency between
beams and adapts to the local sample density when using a particle ﬁlter.
In contrast to Gaussian-based state-of-the-art models, the proposed full scan
model uses a sample-based approximation. The sample-based approximation
allows us to capture the multimodality of the full scan model, which is shown
to occur even in simple static environments.
3.1.1
Paper Overview
This paper is organized as follows.
Section 3.2 gives an overview of the
related work. Section 3.3 (i) presents a Bayesian beam model for range ﬁnders
founded on Bayesian networks, the RBBM, (ii) mathematically derives an
analytical formula for the probabilistic sensor model while clearly stating all
assumptions, (iii) provides useful insights in the obtained beam model, and
(iv) shows that the obtained analytical sensor model agrees with the proposed
Bayesian network. Section 3.4 presents a maximum likelihood and a variational
Bayesian estimator (both based on expectation-maximization) to learn the
model parameters.
In Section 3.5 the model parameters of the RBBM are
learned from experimental data and the resulting model is compared with the
state-of-the-art beam model proposed by Thrun et al. 2005, further on called
Thrun’s model. Section 3.6 extends the RBBM to an adaptive full scan model
for dynamic environments. the multimodality of the full scan model, which,
as shown in this section, occurs even in simple non-dynamic environments.
Section 3.7 discusses the obtained RBBM and adaptive full scan model and
compares them with previously proposed range ﬁnder sensor models.
3.2
Related Work
Three basic approaches to deal with dynamic environments exist in the
literature (Fox et al. 1999; Thrun et al. 2005): state augmentation, adapting
the sensor model and outlier detection. In state augmentation the latent states,

40
Chapter 3
Range Finder Model for Dynamic Environments
e.g. the position of moving objects and people in the environment, are included
in the estimated states.
Wang et al.
2003 developed an algorithm ‘SLAM
with DATMO’, short for SLAM with the detection and tracking of moving
objects. State augmentation however is often infeasible since the computational
complexity of state estimation increases exponentially with the number of
independent state variables to estimate.
A closely related solution consists
of adapting the map according to the changes in the environment. Since such
approaches assume that the environment is almost static, they are unable to
cope with real dynamics as in populated environments (Fox et al. 1999). A
more recent, related approach proposed by Wolf and Sukhatme 2004 maintains
two coupled occupancy grids of the environment, one for the static map and
one for the moving objects, to account for environment dynamics.
Probabilistic approaches are to some extent robust to unmodeled dynamics,
since they are able to deal with sensor noise. In such approaches however, the
sensor noise should reﬂect the real uncertainty due to the unmodeled dynamics
of the environment. Therefore, a second approach for dealing with dynamic
environments is to adapt the sensor model to correctly reﬂect situations in
which measurements are aﬀected by the unmodeled environment dynamics. Fox
et al. 1999 show that such approaches are only capable to model such noise
on average, and, while these approaches work reliably with occasional sensor
blockage, they are inadequate in situations where more than ﬁfty percent of
the measurements are corrupted.
To handle measurement corruption more eﬀectively, an approach based on
outlier detection can be used. This approach uses an adapted sensor model,
as explained in the previous paragraph. The idea is to investigate the cause of
a sensor measurement and to reject measurements that are likely to be aﬀected
by unmodeled environment dynamics. Hähnel, Schulz, and Burgard 2003 and
Hähnel, Triebel, Burgard, and Thrun 2003 studied the problem of performing
SLAM in environments with many moving objects using the EM algorithm for
ﬁltering out aﬀected measurements. By doing so, they were able to acquire
maps in the environment where conventional SLAM techniques failed.
Fox
et al. 1999 propose two diﬀerent kinds of ﬁlters: an entropy ﬁlter, suited for an
arbitrary sensor, and a distance ﬁlter, designed for proximity sensors. These
ﬁlters detect whether a measurement is corrupted or not, and discard sensor
readings resulting from objects that are not contained in the map.
This paper focuses on (sonar and laser) range ﬁnders, whose physical principle
is the emission of a sound or light wave, followed by the recording of its
echo. Highly accurate sensor models would include physical parameters such
as surface curvature and material absorption coeﬃcient. These parameters are
however diﬃcult to estimate robustly in unstructured environments. Hence,
the literature typically relies on purely basic geometric models.

3.2 Related Work
41
The range ﬁnder sensor models available from the literature are traditionally
divided in three main groups: feature-based approaches, beam-based models
and correlation-based methods.
Feature-based approaches extract a set of
features from the range scan and match them to features contained in an
environmental model.
Beam-based models, also known as ray cast models,
consider each distance measurement along a beam as a separate range
measurement. These models represent the one-dimensional distribution of the
distance measurement by a parametric function, which depends on the expected
range measurement in the respective beam directions. In addition, these models
are closely linked to the geometry and the physics involved in the measurement
process. They often result in overly peaked likelihood functions due to the
underlying assumption of independent beams. The last group of range ﬁnder
sensor models, correlation-based methods, builds local maps from consecutive
scans and correlate them with a global map. The simple and eﬃcient likelihood
ﬁeld models or end point models (Thrun 2001) are related to these correlation-
based methods. Plagemann et al. 2007 nicely summarize the advantages and
drawbacks of the diﬀerent range ﬁnder sensor models.
Range ﬁnder sensor models can also be classiﬁed according to whether they use
discrete geometric grids (Hähnel, Schulz, and Burgard 2003; Hähnel, Triebel,
Burgard, and Thrun 2003; Fox et al. 1999; Burgard et al. 1996; Moravec 1988)
or continuous geometric models (Thrun et al. 2005; Choset et al. 2005; Pfaﬀ
et al.
2006).
Moravec 1988 proposed non-Gaussian measurement densities
over a discrete grid of possible distances measured by sonar; the likelihood of
the measurements has to be computed for all possible positions of the mobile
robot at a given time.
Even simpliﬁed models (Burgard et al.
1996) in
this approach turned out to be computationally too expensive for real-time
application. Therefore, Fox et al. 1999 proposed a beam model consisting of a
mixture of two physical causes for a measurement: a hit with an object in the
map, or with an object not yet modeled in the map. The last cause accounts
for the dynamic nature of the environment.
An analogous mixture (Thrun
et al. 2005; Choset et al. 2005) adds two more physical causes: a sensor failure
and an unknown cause resulting in a ‘max-range’ measurement and a ‘random’
measurement, respectively. While Thrun et al. 2005 and Pfaﬀet al. 2006
use a continuous model, Choset et al. 2005 present the discrete analog of the
mixture, taking into account the limited resolution of the range sensor. Pfaﬀ
et al. 2006 extend the basic mixture model for use in Monte Carlo localization.
To overcome problems due to the combination of the limited representational
power and the peaked likelihood of the accurate range ﬁnder, they propose
an adaptive likelihood model. The likelihood model is smooth during global
localization and more peaked during tracking.
Recently, diﬀerent researchers tried to tackle the problems associated with
beam-based models, caused by the independence assumptions between beams.

42
Chapter 3
Range Finder Model for Dynamic Environments
Plagemann et al.
2007 propose a sensor model for the full scan.
The
model treats the sensor modeling task as a non-parametric Bayesian regression
problem, and solves it using Gaussian processes. It is claimed that the Gaussian
beam processes combine the advantages of the beam-based and the correlation-
based models. Due to the underlying assumption that the measurements are
jointly Gaussian distributed, the Gaussian beam processes are not suited to
take into account the non-Gaussian uncertainty due to the dynamic nature
of the environment.
An alternative approach to handle the overly-peaked
likelihood functions resulting from the traditional beam models is proposed by
Pfaﬀet al. 2007. A location-dependent full scan model takes into account the
approximation error of the sample-based representation, and explicitly models
the correlations between individual beams introduced by the pose uncertainty.
The measurements are assumed to be jointly Gaussian distributed just as
Plagemann et al.
2007 proposed.
While Plagemann et al.
2007 represent
the covariance matrix as a parametrized covariance function using Gaussian
processes whose parameters are learned from data, Pfaﬀet al.
2007 learn
the full covariance matrix being less restrictive in this manner. Despite the
modeled correlation between beams, the measurements are still assumed to be
jointly Gaussian distributed, which again limits the applicability in dynamic
environments.
This paper proposes a rigorously Bayesian modeling of the probabilistic range
sensor beam model for dynamic environments, referred to as RBBM. Similar to
the work of Thrun et al. 2005 and Pfaﬀet al. 2006, the sensor model is derived
for a continuous geometry. Unlike previous models of Thrun et al. 2005; Pfaﬀ
et al. 2006; Fox et al. 1999 and Choset et al. 2005, the mixture components
are founded on a Bayesian modeling. This modeling makes use of probabilistic
graphical models, in this case Bayesian networks.
Such graphical models
provide a simple way to visualize the structure of a probabilistic model, and can
be used to design and motivate new models (Bishop 2006). By inspection of
the graph, insights of the model, including conditional independence properties
are obtained. Next, inspired by the adaptive full scan models in the literature
(Pfaﬀet al.
2006; Pfaﬀet al.
2007; Plagemann et al.
2007), the RBBM
is extended to an adaptive full scan model.
The underlying sample-based
approximation of the full scan model, in contrast to the Gaussian-based
approximation proposed by Pfaﬀet al.
2007 and Plagemann et al.
2007,
enables handling dynamic environments and capturing multimodality, which
occurs even in simple static environments.

3.3 Beam Model
43
3.3
Beam Model
We model the probabilistic beam model P(Z = z | X = x, M = m) for dynamic
environments as a Bayesian network.
We introduce extra state variables
A = a for the positions of unmodeled objects in the probabilistic sensor
model P(z | x, m, a). To prevent an exponential increase of the computational
complexity of the state estimation due to the extra variables, these variables
are marginalized out from the total probability before estimation.
The
marginalization:
P(z | x, m) =
Z
a
P(z | x, m, a) P(a) da,
(3.1)
avoids increasing the complexity to infer the conditional probability dis-
tributions of interest, P(x) and P(m), while it maintains the modeling
of the dynamic nature of the environment.
Section 3.3.1 explains which
extra state variables are physically relevant, while Section 3.3.3 explains the
marginalization of these extra state variables.
Section 3.3.5 summarizes all
assumptions and approximations. Finally, Section 3.3.6 provides useful insights
in the obtained beam model, called RBBM, and in its derivation. Section 3.3.7
shows that the obtained analytical expression for the RBBM agrees with the
proposed Bayesian network by means of a Monte Carlo simulation.
3.3.1
Bayesian Model
Bayesian networks graphically represent probabilistic relationships between
variables in a mathematical model, to structure and facilitate probabilistic infer-
ence computations with those variables (Jensen and Nielsen 2007; Neapolitan
2004). A Bayesian network is deﬁned as follows: (i) a set of nodes, each with
an associated random variable, connected by directed edges forming a directed
acyclic graph (DAG); (ii) each discrete (continuous) random variable has a ﬁnite
(inﬁnite) set of mutually exclusive states; (iii) each random variable A with
parents B1, . . . , BN has a conditional probability distribution P(A | B1, . . . , Bn)
(known as conditional probability table in the case of discrete variables).
Although the deﬁnition of Bayesian networks does not refer to causality, and
there is no requirement that the directed edges represent causal impact, a
well-known way of structuring variables for reasoning under uncertainty is to
construct a graph representing causal relations (Jensen and Nielsen 2007). In
this case the graphical models are also known as generative models (Bishop
2006), since they capture the causal process generating the random variables.
In this application, the range sensor ideally measures z⋆, the distance to the
closest object in the map.
An unknown number n of unmodeled objects,

44
Chapter 3
Range Finder Model for Dynamic Environments
possibly preventing the measurement of the closest object in the map, are
however present in the environment. Depending on the position of the jth
unmodeled object along the measurement beam, xNj, the unmodeled object
occludes the map or not. The unmodeled object only occludes the map if it
is located in front of the closest object contained in the map. k is the total
number of occluding objects out of the n unmodeled objects. The positions of
these occluding objects on the measurement beam are denoted by {xKi}i=1:k.
If the map is occluded by an unmodeled object, the range sensor will ideally
measure z⋆
occl = xKc, with xKc the position of the closest occluding object.
The following extra state variables, a in Eq. (3.1), are included in the Bayesian
model: N is the discrete random variable indicating the unknown number of
unmodeled objects in the environment; XNj is the continuous random variable
for the position of the jth unmodeled object on the measurement beam; K
is the discrete random variable indicating the number of objects occluding
the measurement of the map; XKi is the continuous random variable for the
position of the ith occluding object on the measurement beam; and Z⋆
occl is
the continuous random variable indicating the ideal range measurement of
the closest occluding object. Figure 3.1 shows the Bayesian network for the
probabilistic range ﬁnder sensor model with the variables Z, X and M that
occur in the probabilistic sensor model (deﬁned in Section 3.1), all the extra
variables N, XN = {XNj}j=1:n , K, XK = {XKi}i=1:k, Z⋆
occl and the model
parameters p and σm (deﬁned in Section 3.3.2).
The directed edges in the graphical model represent causal relationships
between the variables. For example, X and M unambiguously determine the
measured range Z for a perfect sensor in the absence of unmodeled occluding
objects. The number of occluding objects K depends on the total number N
of unmodeled objects and their positions XN with respect to the measurement
beam. X and M also have a causal impact on K: the larger the expected
measurement z⋆, the higher the possibility that one or more unmodeled objects
are occluding the modeled object corresponding to the expected measurement.
The positions along the measurement beam XK of the occluding objects are
equal to the positions of the K of N unmodeled objects occluding the map.
Therefore, random variables XK are not only inﬂuenced by K but also by
XN. Since the K objects are occluding the map, their positions along the
measurement beam are limited to the interval [0, z⋆], so XK has a causal
dependency on X and M. The ideal measurement z⋆
occl of an occluding object
is the position of the occluding object closest to the sensor, so Z⋆
occl depends
on the positions XK of the occluding objects. Finally, measurement Z also
depends on the ideal measurement of the occluding object Z⋆
occl and the number
of occluding objects K. In case of occlusion (k ≥1), z⋆
occl is ideally measured,
else (no occlusion, k = 0) z⋆is ideally measured.

3.3 Beam Model
45
N
K
XKi
XNj
X
Z⋆
occl
Z
M
n
k
p
σm
Figure 3.1: The Bayesian network for the probabilistic measurement model
supplemented with the deterministic parameters represented by the solid dot
nodes. A compact representation with plates (the rounded rectangular boxes)
is used. A plate represents a number, indicated in the lower right corner, of
independent nodes of which only a single example is shown explicitly.
3.3.2
Conditional Probability Distributions
Inferring the probability distribution of the extra state variables such as P(n)
is often infeasible.
Marginalization of the extra state variables Z, X, M,
N, XN, K, XK, Z⋆
occl avoids the increase in complexity of the estimation
problem, but still takes into account the dynamic nature of the environment.
Marginalization requires the modeling of all conditional probability tables and
conditional probability distributions (pdf) of each random variable conditionally
on its parents.
First of all, some assumptions have to be made for P(n). Assume that the
probability of the number of unmodeled objects decreases exponentially, i.e. P(n)

46
Chapter 3
Range Finder Model for Dynamic Environments
0.1
0.2
0.3
10
9
8
7
6
5
4
3
2
1
0
P(n)
n
Figure 3.2: P(n) (Eq. (3.2)) for p = 0.65.
1
zmax
z
zmax
z⋆
u
P(xNj | n)
0
Figure 3.3: P(xNj | n) (Eq. (3.3)).
is given by:
P(n) = (1 −p) pn,
(3.2)
with p a measure for the degree of appearance of unmodeled objects. More
precisely, p is the probability that at least one unmodeled object is present.
While p is indicated in Figure 3.1, Figure 3.2 shows the resulting distribution
P(n).
Secondly, assume that nothing is known a priori about the position of the
unmodeled objects along the measurement beam.
Hence each unmodeled
object’s position is assumed to be uniformly distributed over the measurement
beam (Figure 3.3):
P(xNj) =
(
1
zmax
if xNj ≤zmax
0
otherwise,
(3.3)

3.3 Beam Model
47
0.1
0.2
0.3
10
9
8
7
6
5
4
3
2
1
0
P(k | n, x, m)
k
Figure 3.4: P(k | n, x, m) (Eq. (3.5)) for n = 10 and u = 0.25.
with zmax the maximum range of the range sensor.
Thirdly, assume the positions of the unmodeled objects are independent:
P(xN | n) =
n
Y
j=1
P(xNj) .
(3.4)
Next, an expression is needed for the conditional probability: P(k | n, xN, x, m),
i.e.
the probability that k of the n unmodeled objects are occluding the
map m. An unmodeled object is occluding the map m if it is located along
the measurement beam and in front of the closest object in the map. It is
straightforward to show that P(k | n, xN, x, m) is a binomial distribution:
P(k | n, xN, x, m) =





 
n
k
!
uk (1 −u)n−k
if k ≤n
0
otherwise,
(3.5)
where u is the probability that an unmodeled object is occluding the map and
n
k

=
n!
(n−k)!k! is the number of ways of selecting k objects out of a total of
n objects. Figure 3.4 shows this binomial distribution. Since it was assumed
that the positions of the unmodeled objects were uniformly distributed, u, the
probability that an unmodeled object is occluding the map is:
u = P(xNj < z⋆) =
z⋆
zmax
,
(3.6)

48
Chapter 3
Range Finder Model for Dynamic Environments
XK1
XK2
XKk
XKi
. . .
. . .
. . .
. . .
XN1
XN2
XN3
XNn−2
XNn−1
XNn
XNj
Figure 3.5: The selection scheme, where each cross eliminates an unmodeled
object that is not occluding the map.
as depicted in Figure 3.3.
Furthermore, an analytical expression for P(xK | xN, k) is necessary.
The
positions of the occluding objects xK are equal to the positions of the
unmodeled objects xN that are occluding the map, as shown in Figure 3.5. In
other words, xKi equals xNj if and only if the unmodeled object is occluding
the map, i.e. if xNj ≤z⋆:
P(xKi | xNj, k, x, m) =
(
1
P(xNj≤z⋆)δ (xKi −xNj) = zmax
z⋆δ (xKi −xNj)
if xNj ≤z⋆
0
otherwise,
(3.7)
with δ the Dirac function and xKi the occluding object corresponding to xNj.
In case of occlusion, the range sensor ideally measures the distance to the closest
occluding object xKc:
P(z⋆
occl | xK) = δ (z⋆
occl −xKc) .
(3.8)
While range ﬁnders are truly quite deterministic since the measurements
are to a great extent explainable by underlying physical phenomena such as
specular reﬂections, inference, ...
these underlying phenomena are complex
and therefore costly to model.
On top of these underlying phenomena
additional uncertainty on the measurement is due to (i) uncertainty in the
sensor position, (ii) inaccuracies of the world model, and (iii) inaccuracies
of the sensor itself.
So far only disturbances on the measurements due to
unmodeled objects in the environment are included. To capture the additional
uncertainty, additional measurement noise is added. After taking into account
the disturbances by unmodeled objects, unexplainable measurements and
sensor failures (Section 3.4), there is no physical reason to expect that the

3.3 Beam Model
49
mean value of the true measurements deviates from the expected measurement
and that the true measurements are distributed asymmetrically around the
mean. Therefore symmetrical noise with mean value zero is added. Two facts
justify the modeling of the measurement noise as a normal distribution: (i) the
normal distribution maximizes the information entropy among all distributions
with known mean and variance, making it the natural choice of underlying
distribution for data summarized in terms of sample mean and variance; and (ii)
if the underlying phenomena are assumed to have a small, independent eﬀect on
the measurement, the central limit theorem states that under certain conditions
(such as being independent and identically distributed with ﬁnite variance),
the sum of a large number of random variables is approximately normally
distributed.
If the measurement noise is modeled by a zero mean Gaussian
with standard deviation σm, the conditional probability P(z | x, m, z⋆
occl, k) is:
P(z | x, m, z⋆
occl, k) =
(
N (z; z⋆, σm)
if k = 0
N (z; z⋆
occl, σm)
if k ≥1,
(3.9)
where the conditional probability P(z | x, m, z⋆
occl, k) has two main cases, the
ﬁrst for k = 0 where no occlusion is present and the sensor is observing the
map m, and the second case for k ≥1 where the sensor observes an occluding
object. σm is included in the Bayesian network of Figure 3.1.
3.3.3
Marginalization
This section shows the diﬀerent steps needed to marginalize out the extra
state variables in Eq. (3.1), and motivates the approximation that leads to
an analytical sensor model.
The product rule rewrites the sensor model P(z | x, m) as:
P(z | x, m) = P(z, x, m)
P(x, m)
= P(z, x, m)
P(x) P(m),
(3.10)
since X and M are independent. The numerator is obtained by marginalizing
the joint probability pjoint
=
P(z, x, m, xN, n, xK, k, z⋆
occl) of the whole
Bayesian network over xN, n, xK, k and z⋆
occl:
P(z, x, m) =
Z
z⋆
occl
X
k
Z
xK
X
n
Z
xN
pjoint dxN dxK dz⋆
occl.
(3.11)

50
Chapter 3
Range Finder Model for Dynamic Environments
Using the chain rule to factorize the joint distribution while making use of the
conditional dependencies in the Bayesian network (Figure 3.1) yields:
pjoint
=
P(z | x, m, z⋆
occl, k) P(z⋆
occl | xK) P(k | n, xN, x, m)
P(xK | xN, k, x, m) P(xN | n) P(n) P(x) P(m) .
(3.12)
Substituting (3.12) and then (3.11) into (3.10) gives:
P(z | x, m) =
Z
z⋆
occl
X
k
P(z | x, m, z⋆
occl, k)
Z
xK
P(z⋆
occl | xK)
X
n
P(k | n, x, m) P(n) P(xK | n, k, x, m) dxK dz⋆
occl,
(3.13)
where
P(xK | n, k, x, m) =
Z
xN
P(xK | xN, k, x, m) P(xN | n) dxN.
(3.14)
Since the binomial distribution P(k | n, xN, x, m) of Eq. (3.5) is independent of
xN, it is moved out of the integral over xN in (3.14), and is further on denoted
by P(k | n, x, m).
Marginalizing xN
Now study the integral over xN in Eq. (3.14) and focus on
xNj, the position of one unmodeled object. Substituting (3.3) and (3.7) results
in:
P(xKi | n, k, x, m)
=
Z z⋆
xNj=0
zmax
z⋆δ (xKi −xNj)
1
zmax
dxNj
=
(
1
z⋆
if xKi ≤z⋆
0
otherwise.
(3.15)
This equation expresses that xKi is uniformly distributed when conditioned on
n, k, x and m as shown in Figure 3.6. Since all occluding objects are considered
independent:
P(xK | n, k, x, m) =
(  1
z⋆
k
if ∀0 ≤i ≤k : xKi ≤z⋆
0
otherwise.
(3.16)

3.3 Beam Model
51
1
z⋆
xKi
z⋆
zmax
xKi
P(xKi | x, m)
0
Figure 3.6: P(xKi | n, k, x, m) (Eq. (3.15)).
This equation shows that P(xK | n, k, x, m) is independent of n and thus can
be moved out of the summation over n in Eq. (3.13):
P(z | x, m) =
Z
z⋆
occl
X
k
P(z | x, m, z⋆
occl, k) P(z⋆
occl | k, x, m) P(k | x, m) dz⋆
occl,
(3.17)
with
P(k | x, m)
=
X
n
P(k | n, x, m) P(n) ,
(3.18)
and
P(z⋆
occl | n, k, x, m)
=
Z
xK
P(z⋆
occl | xK) P(xK | k, x, m) dxK.
(3.19)
Marginalizing n
First focus on the summation over n in Eq. (3.18) and
substitute (3.2) and (3.5):
P(k | x, m) =
∞
X
n=k

n
k

uk (1 −u)n−k (1 −p) pn

.
(3.20)
Appendix 3.8.1 proves that this inﬁnite sum simpliﬁes to:
P(k | x, m) = (1 −p′) p′k,
(3.21)
with
p′ =
up
1 −(1 −u) p.
(3.22)

52
Chapter 3
Range Finder Model for Dynamic Environments
Marginalizing xK
Now focus on the integral over xK
in Eq. (3.19).
Substituting (3.8) into this equation results in:
P(z⋆
occl | k, x, m)
=
Z
xKc
δ (z⋆
occl −xKc) P(xKc | k) dxKc
=
P(xKc = z⋆
occl | k, x, m) .
(3.23)
This equation shows that the conditional probability P(z⋆
occl | k, x, m) repre-
sents the probability that the perfect measurement of the nearest occluding
object is z⋆
occl, i.e. the probability that the nearest occluding object is located
at z⋆
occl. This is only the case when one of the k objects along the measurement
beam is located such that z⋆
occl is measured, while all other objects along the
measurement beam are located behind the occluding object, or expressed in
probabilities:
P(z⋆
occl | k, x, m) =
k
X
i=1
P(xK̸=i ≥z⋆
occl | k, x, m) P(xKi = z⋆
occl | k, x, m) .
(3.24)
Since xK is uniformly distributed over [0, z⋆] as shown by Eq. (3.15), it follows
that:
P(xKi = z⋆
occl | k, x, m)
=
1
z⋆,
(3.25)
P(xKi ≥z⋆
occl | k, x, m)
=
z⋆−z⋆
occl
z⋆
,
(3.26)
and (3.24) can be written as:
P(z⋆
occl | k, x, m)
=
k 1
z⋆
z⋆−z⋆
occl
z⋆
k−1
.
(3.27)
Marginalizing k
After obtaining expressions for P(k | x, m) (Eq. (3.21)) and
P(z⋆
occl | k, x, m) (Eq. (3.27)) we turn the attention to the summation over k in
Eq. (3.17):
P(z, z⋆
occl | x, m) =
X
k
P(z | x, m, z⋆
occl, k) P(z⋆
occl | k, x, m) P(k | x, m) .
(3.28)

3.3 Beam Model
53
Split this summation in two parts: one for k = 0, when there is no occlusion,
and one for k
≥1, and substitute the expressions for P(k | x, m) and
P(z | x, m, z⋆
occl, k) given by Eq. (3.21) and Eq. (3.9), respectively:
P(z, z⋆
occl | x, m)
=
N (z; z⋆, σm) P(z⋆
occl | k = 0, x, m) P(k = 0 | x, m) +
N (z; z⋆
occl, σm) P(z⋆
occl | k ≥1, x, m) P(k ≥1 | x, m)
=
N (z; z⋆, σm) P(z⋆
occl | k = 0, x, m) (1 −p′) +
N (z; z⋆
occl, σm) α (z⋆
occl | x, m) ,
(3.29)
where α (z⋆
occl | x, m)
=
P(z⋆
occl | k ≥1, x, m) P(k ≥1 | x, m)
=
∞
X
k=1
P(z⋆
occl | k, x, m) (1 −p′) p′k.
(3.30)
Substituting (3.27) into (3.30) results in:
α (z⋆
occl | x, m) =
∞
X
k=1
k 1
z⋆
z⋆−z⋆
occl
z⋆
k−1
(1 −p′) p′k,
(3.31)
which is simpliﬁed using Eq. (3.114) in Appendix 3.8.1:
α (z⋆
occl | x, m)
=
1
z⋆(1 −p′) p′
∞
X
k=1
k
z⋆−z⋆
occl
z⋆
p′
k−1
=
p′ (1 −p′)
z⋆
h
1 −
 z⋆−z⋆
occl
z⋆
p′
i2 .
(3.32)
Substituting (3.32) into (3.29) gives:
P(z, z⋆
occl | x, m) = N (z; z⋆, σm) P(z⋆
occl | k = 0, x, m) (1 −p′) +
N (z; z⋆
occl, σm)
(1 −p′) p′
z⋆
h
1 −
 z⋆−z⋆
occl
z⋆
p′
i2 .
(3.33)

54
Chapter 3
Range Finder Model for Dynamic Environments
Marginalizing z⋆
occl
Substituting (3.33) into (3.17) shows that only the
integration over z⋆
occl still has to be carried out:
P(z | x, m) = (1 −p′)N (z; z⋆, σm) +
p′
Z z⋆
z⋆
occl=0
N (z; z⋆
occl, σm)
1 −p′
z⋆
h
1 −
 z⋆−z⋆
occl
z⋆
p′
i2 dz⋆
occl . (3.34)
The ﬁrst term of the right hand side is a Gaussian distribution around the
ideal measurement, multiplied with the probability of no occlusion (k = 0).
The second term is an integration over all possible positions of the occluding
object of a scaled Gaussian distribution centered at the ideal measurement of
the occluding object (z⋆
occl). The scaling factor represents the probability that
the occluding objects are located such that z⋆
occl is measured. From Eq. (3.20)
and Eq. (3.32) it follows that the scaling factor can be written as:
α (z⋆
occl | x, m)
=
p (1 −p)
zmax
h
1 −

1 −
z⋆
occl
zmax

p
i2 ,
(3.35)
which is independent of z⋆.
Until now, no approximations where made to obtain Eq. (3.34) for the beam
model P(z | x, m). The integral over the scaled Gaussian distributions however,
cannot be obtained analytically.
Therefore, a ﬁrst approximation in the
marginalization is made by neglecting the noise on the range measurement in
case of occlusion, i.e.: N (z; z⋆
occl, σm) ≈δ (z −z⋆
occl). Using this approximation
the second term in the right hand side of Eq. (3.34) becomes:
p′ (1 −p′)
z⋆
1 −z⋆−z
z⋆p′2 =
p (1 −p)
zmax
h
1 −

1 −
z
zmax

p
i2 .
(3.36)
Figure 3.7 shows the quality of the approximation of the integral in Eq. (3.34)
compared to a ﬁnite sum approximation with small step size.
The approx-
imation introduces a discontinuity around z = z⋆.
Using the proposed
approximation for the integral the resulting beam model is:
P(z | x, m) =



(1 −p′) N (z; z⋆, σm) + p′
(1−p′)
z⋆[1−( z⋆−z
z⋆
p′)]
2
if z ≤z⋆
(1 −p′) N (z; z⋆, σm)
otherwise,
(3.37)
as shown in Figure 3.8.

3.3 Beam Model
55
0.05
0.15
0.25
0.35
0.45
0.1
0.2
0.3
0.5
7
6
5
4
3
2
1
0
z
Finite sum
Approximation
Figure 3.7: Comparison of the approximation (Eq.(3.36)) of the integral in
Eq. (3.34) with a ﬁnite sum approximation with small step size for p = 0.8,
zmax = 10, z⋆= 5 and σm = 0.15.
0.90
0.86
0.82
0.78
5.10
5.05
5.00
4.95
4.90
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
10
9
8
7
6
5
4
3
2
1
0
P(z | x, m)
z
Finite sum
Approximation
Figure 3.8: Comparison of the obtained RBBM P(z | x, m) (Eq. (3.37)) with
a ﬁnite sum approximation of Eq. (3.34) with small step size for p = 0.8,
zmax = 10, z⋆= 5 and σm = 0.15.

56
Chapter 3
Range Finder Model for Dynamic Environments
The RBBM can be written as a mixture of two components:
P(z | x, m) = π1Phit (z | x, m) + π2Poccl (z | x, m) ,
(3.38)
with π1 = (1 −p′)
(3.39)
π2 = p′
(3.40)
Phit (z | x, m) = N (z; z⋆, σm)
(3.41)
Poccl (z | x, m) =



1
z⋆
1−p′
[1−( z⋆−z
z⋆
p′)]
2
if 0 ≤z ≤z⋆
0
otherwise.
(3.42)
3.3.4
Extra Components
Occasionally, range ﬁnders produce unexplainable measurements, caused by
phantom readings when sonars bounce oﬀwalls, or suﬀer from cross-talk
(Thrun et al. 2005). Furthermore additional uncertainty on the measurements
is caused by (i) uncertainty in the sensor position, (ii) inaccuracies of the
world model, and (iii) inaccuracies of the sensor itself. These unexplainable
measurements are modeled using a uniform distribution spread over the entire
measurement range [0, zmax]:
Prand (z | x, m) =
(
1
zmax
if 0 ≤z ≤zmax,
0
otherwise.
(3.43)
Furthermore,
sensor failures typically produce max-range measurements,
modeled as a point-mass distribution centered around zmax:
Pmax (z | x, m) = I (zmax) =
(
1
if z = zmax,
0
otherwise.
(3.44)
These two extra components can be added to Eq. (3.38), resulting in the ﬁnal
RBBM:
P(z | x, m) = π1 Phit (z | x, m) + π2 Poccl (z | x, m) +
π3 Prand (z | x, m) + π4 Pmax (z | x, m) ,
(3.45)
where π3 and π4 are the probabilities that the range ﬁnder returns an unex-
plainable measurement and a maximum reading, respectively. Furthermore,
π1 = (1 −p′) (1 −π3 −π4) and
(3.46)
π2 = p′(1 −π3 −π4),
(3.47)

3.3 Beam Model
57
while Phit (z | x, m), Poccl (z | x, m), Prand (z | x, m) and Pmax (z | x, m) are given
by (3.41), (3.42), (3.43) and (3.44) respectively.
3.3.5
Assumptions and Approximations
This section summarizes the assumptions and approximations made to arrive
at the RBBM of Eq. (3.45).
Section 3.3.2 makes four assumptions:
(i) the probability of the number of unmodeled objects decreases exponentially,
Eq. (3.2);
(ii) the unmodeled object’s position is uniformly distributed over the measure-
ment beam (Figure 3.3, Eq. (3.3));
(iii) the positions of the unmodeled objects are independent, Eq. (3.4); and
(iv) the measurement noise is zero mean normally distributed with standard
deviation σm (Eq. 3.9).
Furthermore, Section 3.3.3 makes one approximation to obtain an analytical
expression by neglecting the noise on the range measurement in case of
occlusion (Eq. (3.34)).
3.3.6
Interpretation
The following paragraphs give some insights in the RBBM and its derivation.
The mixture representation (3.45) shows the four possible causes of a range
measurement: a hit with the map, a hit with an unmodeled object, an unknown
cause resulting in a random measurement, and a sensor failure resulting in a
maximum reading measurement.
The derivation of Section 3.3.3 shows that the position of each of the occluding
objects is uniformly distributed between the sensor and the ideally measured
object in the environment (Eq. (3.15), Figure 3.6). This is perfectly reasonable
considering the assumption of uniformly distributed unmodeled objects.
Furthermore, some insights are provided concerning α (z⋆
occl | x, m) (Eq. (3.35),
Figure 3.7), the probability that the occluding objects are located such that
z⋆
occl is measured. First of all, this probability is independent of the location
of the ideally measured object in the environment (z⋆) (except that this
probability is zero for z > z⋆). This agrees with intuition, since one expects
the measurements caused by the occluding objects to be independent of z⋆,

58
Chapter 3
Range Finder Model for Dynamic Environments
the measurement in the case of no occlusion.
Second, the probability of
sensing unmodeled objects decreases with the range, as expected.
This is
easily explained with the following thought experiment: if two objects are
present with the same likelihood in the perception ﬁeld of the range ﬁnder, and
the ﬁrst object is closest to the range sensor, then the sensor is more likely
to measure the ﬁrst object. To measure the second object, the second object
should be present and the ﬁrst object should be absent (Thrun et al. 2005).
Moreover, the rate of decrease of the likelihood of sensing unmodeled objects
is only dependent on p, the degree of appearance of unmodeled objects.
The probability of measuring a feature of the map, and therefore the integral
under the scaled Gaussian (1 −p′)Phit (z | x, m) (3.45), decreases with the
expected range. This is easily explained since the probability that the map
is not occluded decreases when the feature is located further away.
Finally, the discontinuity of the RBBM (Figure 3.8) was shown to be caused
by the only approximation made (Section 3.3.5).
Since the state-of-the-art
range sensors are very accurate, neglecting the measurement noise on the
measurement of an occluding object is an acceptable approximation.
This
is also shown by the experiments presented in Section 3.5.
With respect to the state-of-the-art beam model of Thrun et al.
2005, the
model proposed here, Eq. (3.45), has:
(i) a diﬀerent functional form for
the probability of range measurements caused by unmodeled objects, (ii) an
intuitive explanation for the discontinuity encountered in the cited paper, and
(iii) a reduction in the number of model parameters. Thrun et al. 2005 ﬁnd that
Poccl (z | x, m) has an exponential distribution. This exponential distribution
results from the following underlying assumptions (although not revealed by the
authors): (i) the unmodeled objects are equally distributed in the environment
and (ii) a beam is reﬂected with a constant probability at any range. The last
assumption equals assuming that the probability that an unmodeled object
is located at a certain distance is constant. This assumption fails to capture
that the number of unmodeled object is ﬁnite and that it is more probable
to have a limited number of unmodeled objects than a huge number of them.
While we also assume that unmodeled objects are equally distributed in the
environment (Eq. (3.3)), we assume that the number of unmodeled objects is
geometrically distributed (Eq. (3.2)) capturing the ﬁniteness of the number of
unmodeled objects and the higher probability of a smaller number of unmodeled
objects. The modeling of the ﬁniteness of the number of unmodeled objects
and the higher probability of a smaller number of unmodeled objects results
in a quadratic decay of Poccl (z | x, m), instead of the exponential decay of
Poccl (z | x, m) found by Thrun et al. 2005.
As stated in the previous paragraph, the discontinuity of the RBBM (Figure 3.8)
is caused by an approximation. While Thrun’s model considers the rate of decay

3.4 Beam Model
59
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
10
9
8
7
6
5
4
3
2
1
0
P(z | x, m)
z
Finite sum
Approximation
Monte Carlo Simulation
Figure 3.9: Comparison of the obtained RBBM P(z | x, m) (3.45), a ﬁnite sum
approximation of Eq. (3.34) with small stepsize and the normalized histogram
of 500 samples obtained by a Monte Carlo Simulation of the proposed Bayesian
network (Fig. 3.1) for p = 0.8, zmax = 10, z⋆= 5, σ = 0.15, π3 = 0.2 and
π4 = 0.02.
of Poccl (z | x, m) to be independent of π2, the probability of an occlusion, it
is shown here that they both depend on the same parameter p′ (Eq. (3.42),
Eq. (3.47)). Therefore the RBBM has fewer parameters than Thrun’s model.
3.3.7
Validation
The goal of this section is to show by means of a Monte Carlo simulation3
that the RBBM, Eq. (3.45), agrees with the Bayesian network in Figure 3.1.
A Monte Carlo simulation is an approximate inference method for Bayesian
networks. The idea behind the Monte Carlo simulation is to draw random
conﬁgurations of the network variables Z, X, M, N, XN = {XNj}j=1:n,
K, XK = {XKi}i=1:k and Z⋆
occl and to do this a suﬃcient number of times.
Random conﬁgurations are selected by ancestral sampling (Bishop 2006), i.e.
by successively sampling the states of the variables following the causal model
deﬁned by the directed acyclic graph of the Bayesian network.
Figure 3.9 shows that the RBBM agrees with a Monte Carlo simulation with
500 samples of the proposed Bayesian network.
3A Monte Carlo simulation is also known as stochastic simulation in the Bayesian network
literature (Jensen and Nielsen 2007).

60
Chapter 3
Range Finder Model for Dynamic Environments
Dι
Zι
J
π1, π2, π3, π4
σm
Figure 3.10:
Graphical representation of the mixture measurement model
(Eq. (3.45)) with latent correspondence variable Dι = {Dι1, Dι2, Dι3, Dι4} and
model parameters Θ′ = [σm, π1, π2, π3, π4].
3.4
Variational Bayesian Learning of the Model
Parameters
The RBBM, Eq. (3.45), depends on four independent model parameters:
Θ = [σm, p′, π3, π4] ,
(3.48)
while zmax is a known sensor characteristic. This set of parameters has a clear
physical interpretation; σm is the standard deviation of the zero mean Gaussian
measurement noise in Eq. (3.9) governing Phit (z | x, m) (Eq. (3.41)); p′, deﬁned
in Eq. (3.21), is the probability that the map is occluded (P(k ≥1 | x, m)); π3
and π4 are the probabilities that the range ﬁnder returns an unexplainable
measurement (unknown cause) and a maximum reading (sensor failure),
respectively.
An alternative non-minimal set of parameters containing all the mixing
coeﬃcients π = [π1, π2, π3, π4] could be used: Θ′ = [σm, π], provided that
the constraint:
S=4
X
s=1
πs
=
1,
(3.49)

3.4 Variational Bayesian Learning of the Model Parameters
61
is taken into account.
The set of minimal parameters Θ straightforwardly
follows from the non-minimal set Θ′ since:
p′
=
π2
1 −π3 −π4
,
(3.50)
as can be seen from Eq. (3.47).
The physical interpretation of the parameters Θ allows us to initialize them by
hand with plausible values. However, another, more ﬂexible way is to learn the
model parameters from actual data containing J measurements Z = {zι}ι=1:J
with corresponding states X = {xι}ι=1:J and map m. Furthermore, learning
the model parameters is also a validation for the proposed analytical model:
if the learning algorithm succeeds in ﬁnding model parameters such that the
resulting distribution gives a good explanation of the data, the analytical model
is likely to agree well with reality.
In this paper two diﬀerent estimators4, a maximum likelihood (ML) (Dempster
et al. 1977; McLachlan and Krishnan 1997; Bishop 2006) and a variational
Bayesian (VB) (Beal and Ghahramani 2003; Bishop 2006) estimator, are
presented to learn the model parameters from data. Section 3.4.1 derives a
maximum likelihood estimator, which is a known approach for this problem, but
reformulated for the RBBM. This ML estimator only provides point estimates
of the parameters and leads to overﬁtting since the likelihood function is
generally higher for more complex model structures. Therefore, we propose a
variational Bayesian (VB) estimator in Section 3.4.2, which is a new approach
for learning the parameters for beam models.
The VB estimator is a fully
Bayesian learning approach; priors over the unknown parameters are included,
complex (overﬁtting) models are punished, and a full probability distribution
over the parameters is obtained.
3.4.1
Maximum Likelihood Learning
A maximum likelihood estimator is proposed to identify the model parameters
Θ that maximize the likelihood of the data Z with corresponding X and map
m:
Θ = argmax
Θ
log P(Z | X, m, Θ) .
(3.51)
When using the mixture representation of the RBBM (Eq. (3.45)), the
estimation problem can be formulated as ﬁnding the ML estimates for the
4This paper approximately follows the notation by Bishop 2006.

62
Chapter 3
Range Finder Model for Dynamic Environments
parameters Θ′ = [σm, π] provided that the constraint in Eq. (3.49) is included.
In general it is not known which of the four possible causes actually caused
each of the measurements. In that case the ML estimation problem is diﬃcult
and lacks a closed-form solution.
If however, the corresponding causes of
each of the measurements are known, the solution is easily obtained in closed
form. Therefore, introduce a latent correspondence variable d = [d1, d2, d3, d4],
representing the unknown cause, using a 1-of-S representation. The elements
ds of d give the probability that the measurement is a result of the s’th cause.
The graphical representation of the mixture formulation including the latent
correspondence d variable is shown in Figure 3.10. Although the ML estimation
problem lacks a closed-form solution due to the unknown correspondences, an
expectation-maximization approach (EM) can solve the problem by iterating
an expectation and a maximization step. The expectation step calculates an
expectation for the correspondence variables ds while the maximization step
computes the other model parameters under these expectations.
Algorithm 3.1: ML estimator for model parameters
while convergence criterion not satisﬁed do
for all zι in Z, with ι = 1 : J, where J = |Z|−1 do
calculate z⋆
m
η = [ π1 Phit (zι | xι, m) + π2 Poccl (zι | xι, m) +
π3 Prand (zι | xι, m) + π4 Pmax (zι | xι, m)]−1
γ (dι1) = η π1 Phit (zι | xι, m)
γ (dι2) = η π2 Poccl (zι | xι, m)
γ (dι3) = η π3 Prand (zι | xι, m)
γ (dι4) = η π4 Pmax (zι | xι, m)
end for
π1 = J−1 P
ι γ (dι1)
π2 = J−1 P
ι γ (dι2)
π3 = J−1 P
ι γ (dι3)
π4 = J−1 P
ι γ (dι4)
p′ =
π2
1−π3−π4
σm =
rP
ι γ(dι1)(zι−z⋆ι )2
P
ι γ(dι1)
end while
return Θ = [σm, p′, π3, π4]
The marginal distribution over the correspondence variable d is speciﬁed in
terms of the mixing coeﬃcients πs such that:
P(ds = 1) = πs,
(3.52)

3.4 Variational Bayesian Learning of the Model Parameters
63
where the parameters π must satisfy the following two conditions:
 0 ≤πs ≤1,
PS
s=1 πs = 1.
(3.53)
Since d uses a 1-of-S representation, the marginal distribution can be written
as:
P(d) =
S
Y
s=1
πds
s .
(3.54)
The EM-algorithm expresses the complete-data log likelihood, i.e.
the log
likelihood of the observed and the latent variables:
log P(Z, D | X, Θ′, m) =
J
X
ι=1
(dι1 (log π1 + log Phit (zι | xι, m)) +
dι2 (log π2 + log Poccl (zι | xι, m)) +
dι3 (log π3 + log Prand (zι | xι, m)) +
dι4 (log π4 + log Pmax (zι | xι, m))) ,
(3.55)
where Z = {zι}ι=1:J is the vector containing the observed data and D = {dι}
is the vector containing the matching correspondences.
Expectation step:
Taking the expectation of the complete-data log likelihood
in Eq. (3.55) with respect to the posterior distribution of the latent variables
gives:
Q(Θ′, Θ′old) = ED[log P(Z, D | X, Θ′, m)]
=
J
X
ι=1
(γ (dι1) (log π1 + log Phit (zι | xι, m)) +
γ (dι2) (log π2 + log Poccl (zι | xι, m)) +
γ (dι3) (log π3 + log Prand (zι | xι, m)) +
γ (dι4) (log π4 + log Pmax (zι | xι, m))) ,
(3.56)

64
Chapter 3
Range Finder Model for Dynamic Environments
where γ (dιs) = E[dιs] is the discrete posterior probability, or responsibility
(Bishop 2006), of cause s for data point zι. In the E-step, these responsibilities
are evaluated using Bayes’ theorem, which takes the form:
γ (dι1)
=
E[dι1] = π1Phit (zι | xι, m)
Norm
,
(3.57)
γ (dι2)
=
E[dι2] = π2Poccl (zι | xι, m)
Norm
,
(3.58)
γ (dι3)
=
E[dι3] = π3Prand (zι | xι, m)
Norm
, and
(3.59)
γ (dι4)
=
E[dι4] = π4Pmax (zι | xι, m)
Norm
,
(3.60)
where Norm is the normalization constant:
Norm = π1 Phit (zι | xι, m) + π2 Poccl (zι | xι, m) +
π3 Prand (zι | xι, m) + π4 Pmax (zι | xι, m) .
(3.61)
Two measures are derived from the responsibilities:
Js
=
J
X
ι=1
γ (dιs) , and
(3.62)
¯zs
=
1
Js
J
X
ι=1
γ (dιs) zι,
(3.63)
where Js is the eﬀective number of data points associated with cause s, and ¯zs
is the mean of the eﬀective data points associated with cause s.
Maximization step:
In the M-step the expected complete-data log likelihood
in Eq. (3.56) is maximized with respect to the parameters Θ′ = [σm, π]:
Θ′new = argmax
Θ′
Q(Θ′, Θ′old).
(3.64)
Maximization with respect to πs using a Lagrange multiplier to enforce the
constraint P
s πs = 1 results in:
πs = Js
J ,
(3.65)

3.4 Variational Bayesian Learning of the Model Parameters
65
which is the eﬀective fraction of points in the data set explained by cause s.
Maximization with respect to σm results in:
σm =
v
u
u
t 1
J1
J
X
ι=1
γdι1 (zι −z⋆ι )2.
(3.66)
Algorithm 3.1 summarizes the equations for the ML estimator, further on called
ML-EM algorithm.
3.4.2
Variational Bayesian Learning
The ML estimator only provides point estimates of the parameters and is
sensitive to overﬁtting (Bishop 2006).
Therefore, we propose a variational
Bayesian (VB) estimator, which is a new approach for learning the parameters
for beam models.
The VB estimator is a fully Bayesian learning approach;
priors over the unknown parameters are included, complex (overﬁtting) models
are punished, and a full probability distribution over the parameters is obtained.
The VB estimator has only a little computational overhead as compared to the
ML estimator (Bishop 2006).
The Bayesian approach attempts to integrate over the possible values of all
uncertain quantities rather than optimize them as in the ML approach (Beal
2003; Beal and Ghahramani 2003). The quantity that results from integrating
out both the latent variables and the parameters is known as the marginal
likelihood5: P(Z) = R P(Z | D, Θ) P(D, Θ) d(D, Θ), where P(D, Θ) is a prior
over the latent variables and the parameters of the model. Integrating out the
parameters penalizes models with more degrees of freedom, since these models
can a priori model a larger range of data sets.
This property of Bayesian
integrations is known as Occam’s razor, since it favors simpler explanations
for the data over complex ones (Jeﬀreys and Berger 1992; Rasmussen and
Ghahramani 2000).
Unfortunately, computing the marginal likelihood, P(Z), is intractable for
almost all models of interest.
The variational Bayesian method constructs
a lower bound on the marginal likelihood, and attempts to optimize this bound
using an iterative scheme that has intriguing similarities to the standard EM
algorithm. To emphasize the similarity with ML-EM, the algorithm based on
variational Bayesian inference is further on called VB-EM.
5To avoid overloading the notation the conditioning on the map m and the positions
X = {xι} associated with the data Z = {zι} is not explicitly written.

66
Chapter 3
Range Finder Model for Dynamic Environments
By introducing the distribution Q over the latent variables the complete log
marginal likelihood can be decomposed as (Bishop 2006):
log P(Z) = L(Q) + KL (Q||P) ,
(3.67)
where
L(Q) =
Z
Q(D, Θ) log
P(Z, D, Θ)
Q(D, Θ)

d (D, Θ) ,
(3.68)
and KL (Q||P) is the KL-divergence between Q and P.
Since this KL-
divergence is always greater or equal than zero, L(Q) is a lower bound on
the log marginal likelihood.
Maximizing this lower bound with respect to
the distribution Q(D, Θ) is equivalent to minimizing the KL-divergence. If
any possible choice for Q(D, Θ) is allowed, the maximum of the lower bound
would occur when the KL-divergence vanishes, i.e.
when Q(D, Θ) is equal
to the posterior distribution P(D, Θ | Z).
Working with the true posterior
distribution is however often intractable in practice. One possible approximate
treatment considers only a restricted family of distributions Q(D, Θ) and seeks
the member of this family minimizing the KL-divergence.
The variational
Bayesian treatment uses a factorized approximation, in this case between the
latent variables D and the parameters Θ.
Q(D, Θ) = QD (D) QΘ(Θ) .
(3.69)
The variational approach makes a free form (variational) optimization of L(Q)
with respect to the distributions QD(D) and QΘ(Θ), by optimizing with
respect to each of the factors in turn. The general expressions for the optimal
factors are (Bishop 2006):
log Q⋆
D(D)
=
EΘ[log P(Z, D, Θ)] + Cte,
and
(3.70)
log Q⋆
Θ(Θ)
=
ED[log P(Z, D, Θ)] + Cte,
(3.71)
where ⋆indicates the optimality. These expressions give no explicit solution
for the factors, because the optimal distribution for one of the factors depends
on the expectation computed with respect to the other factor. Therefore an
iterative procedure, similar to EM, that cycles through the factors and replaces
each in turn with a revised optimal estimate is used.
Introducing priors
Since the variational Bayesian approach is a fully Bayesian
approach, priors have to be introduced over the parameters Θ′′ = [µ, σm, π].

3.4 Variational Bayesian Learning of the Model Parameters
67
Remark that in the variational Bayesian estimator not only the standard
deviation σm governing Phit (z | x, m) (Eq. (3.41)) is estimated but also the
mean, referred to as µ further on. Since the analysis is considerably simpliﬁed
if conjugate prior distributions are used, a Dirichlet prior is chosen for the
mixing coeﬃcients π:
P(π) = Dir (π|α0) ,
(3.72)
as well as an independent Gaussian-Wishart prior6 for the mean µ and the
precision λm = σ−1
m of the Gaussian distribution Phit (z | x, m) (Eq. (3.41)):
P(µ, λm) = N

µ|¯µ0, (βλm)−1
W(λm|W0, ν0) .
(3.73)
α0 gives the eﬀective prior number of observations associated with each
component of the mixture.
Therefore, if the value of α0 is set small, the
posterior distribution will be mainly inﬂuenced by the data rather than by
the prior.
Expectation step
Using these conjugate priors, it can be shown that the
factor Q⋆
D(D) can be written as:
Q⋆
D(D) =
J
Y
ι=1
rdι1
ι1 rdι2
ι2 rdι3
ι3 rdι4
ι4 ,
(3.74)
where the quantities rιs are responsibilities analogous to the γιs of Eq. (3.57)
and are given by:
rιs =
ριs
ρι1 + ρι2 + ρι3 + ρι4
,
(3.75)
where
log ρι1
=
E[log π1] + E[log Phit (zι | xι, m)] ,
(3.76)
log ρι2
=
E[log π2] + E[log Poccl (zι | xι, m)] ,
(3.77)
log ρι3
=
E[log π3] + E[log Prand (zι | xι, m)] , and
(3.78)
log ρι4
=
E[log π4] + E[log Pmax (zι | xι, m)] .
(3.79)
6The parameters are as deﬁned by Bishop 2006.

68
Chapter 3
Range Finder Model for Dynamic Environments
The above equations can be rewritten as:
log ρι1
=
E[log π1] + 1
2E[log |λm|] −1
2 log (2π)
−1
2Eµ,λm
h
(zι −µ)T λ (zι −µ)
i
,
(3.80)
log ρι2
=
E[log π2] + log Poccl (zι | xι, m) ,
(3.81)
log ρι3
=
E[log π3] + log Prand (zι | xι, m) , and
(3.82)
log ρι4
=
E[log π4] + log Pmax (zι | xι, m) ,
(3.83)
in which the expectations can be calculated as follows:
E[log πs]
=
Ψ (αs) −Ψ (α1 + α2 + α3 + α4) , (3.84)
E[log |λm|]
=
Ψ
ν
2

+ log 2 + log |W|, and
(3.85)
Eµ,λm
h
(zι −µ)T λ (zι −µ)
i
=
β−1 + ν (zι −¯µ)T W (zι −¯µ) ,
(3.86)
where Ψ is the digamma function.
Three measures are derived from the responsibilities:
Js
=
J
X
ι=1
rιs,
(3.87)
¯zs
=
1
Js
J
X
ι=1
rιszι, and
(3.88)
Cs
=
1
Js
J
X
ι=1
rιs (zι −¯zs) (zι −¯zs)T ,
(3.89)
where Js is the eﬀective number of data points associated with cause s, ¯zs is the
mean of the eﬀective data points associated with cause s, and Cs the covariance
of the eﬀective data points associated with cause s. Due to the similarity with
the E-step of the EM-algorithm, the step of calculating the responsibilities in
the variational Bayesian inference is known as the variational E-step.
Maximization step
In accordance with the graphical representation in
Figure 3.10, it can be shown that the variational posterior QΘ(Θ) factorizes

3.4 Variational Bayesian Learning of the Model Parameters
69
as Q(π) Q(µ, σm) and that the ﬁrst optimal factor is given by a Dirichlet
distribution:
Q⋆(π) = Dir (π|α) ,
(3.90)
with
αs = α0 + Js.
(3.91)
The second optimal factor is given by a Gaussian-Wishart distribution:
Q⋆(µ, λm) = N

µ|¯µ, (βλm)−1
W(λm|W, ν) ,
(3.92)
with
β
=
β0 + J1,
(3.93)
¯µ
=
1
β (β0¯µ0 + J1¯z1) ,
(3.94)
W −1
=
W −1
0
+ J1C1 +
β0J1
β0 + J1
(¯z1 −¯µ0) (¯z1 −¯µ0)T , and
(3.95)
ν
=
ν0 + J1.
(3.96)
These update equations are analogous to the M-step of the EM-algorithm for
the maximum likelihood solution and are therefore known as the variational
M-step. The variational M-step computes a distribution over the parameters
(in the conjugate family) rather than a point estimate as in the case of the
maximum likelihood estimator. This distribution over the parameters allows
us to calculate a predictive density P(z | Z).
Due to the use of conjugate priors, the integrals in the predictive density can
be calculated analytically:
P(z | Z) =
1
α1 + α2 + α3 + α4

α1St

z|¯µ,
νβ
1 + β W, ν

+
α2Poccl (z | x, m) + α3Prand (z | x, m) + α4Pmax (z | x, m)

,
(3.97)
where St (.) is a Student’s t-distribution.
When the size J of the data is
large, the Student’s t-distribution approximates a Gaussian and the predictive

70
Chapter 3
Range Finder Model for Dynamic Environments
distribution can be rewritten as:
P(z | Z) =
1
α1 + α2 + α3 + α4
(α1N (z|µ, λm) +
α2Poccl (z | x, m) + α3Prand (z | x, m) + α4Pmax (z | x, m)) .
(3.98)
If point estimates are desired for the parameters, maximum a posteriori
estimates can be obtained as follows:
ˆπs
=
E[πs] =
αs
α1 + α2 + α3 + α4
,
(3.99)
σm
=
 νβ
1 + β W
−1
2
, and
(3.100)
p′
=
ˆπ2
1 −ˆπ3 −ˆπ4
.
(3.101)
Algorithm 3.2 summarizes the equations for the VB-EM estimator.
3.5
Experiments
The goal of this section is threefold:
(i) to learn the model parameters
(Eq. (3.48)) of the RBBM (Eq. (3.45)) from experimental data, (ii) to compare
the results of the proposed ML-EM and VB-EM estimator (Section 3.4), and
(iii) to compare the results of the proposed estimators with the learning
approach of Thrun’s model proposed by Thrun et al.
2005.
To this end
two experimental setups from diﬀerent application areas in robotics are used.
The data for the ﬁrst learning experiment is gathered during a typical mobile
robot application in which the robot is equipped with a laser scanner and is
travelling in an oﬃce environment. The data for the second learning experiment
is gathered during a typical industrial pick-and-place operation in a human
populated environment. A laser scanner is mounted on the industrial robot to
make it aware of people and other unexpected objects in the robot’s workspace.
To see how well the learned model explains the experiment, the learned
continuous pdf P(z | x, m, Θ) of Eq. (3.45) has to be compared with the discrete
pdf of the experimental data (histogram) H (z).
To this end, the learned
pdf is ﬁrst discretized using the same bins {zf}f=1:F as the experimental pdf.
To quantize the diﬀerence between the learned and the experimental pdf two

3.5 Experiments
71
Algorithm 3.2: Variational Bayesian estimator for model parameters
while convergence criterion not satisﬁed
for all zι in Z, with ι = 1 : J, where J = |Z|−1
calculate z⋆
m
ρι1 = exp [Ψ (α1) −Ψ (α1 + α2 + α3 + α4) +
1
2
 Ψ
  ν
2

+ log 2 + log |W|

−1
2 log (2π) −
1
2

β−1 + ν (zι −¯µ)T W (zι −¯µ)
i
ρι2 = exp [Ψ (α2) −Ψ (α1 + α2 + α3 + α4) + log Poccl (zι | x, m)]
ρι3 = exp [Ψ (α3) −Ψ (α1 + α2 + α3 + α4) + log Prand (zι | x, m)]
ρι4 = exp [Ψ (α4) −Ψ (α1 + α2 + α3 + α4) + log Pmax (zι | x, m)]
η = ρι1 + ρι2 + ρι3 + ρι4
rι1 = η−1ρι1
rι2 = η−1ρι2
rι3 = η−1ρι3
rι4 = η−1ρι4
end for
J1 = PJ
ι=1 rι1
J2 = PJ
ι=1 rι2
J3 = PJ
ι=1 rι3
J4 = PJ
ι=1 rι4
¯z1 =
1
J1
PJ
j=1 rι1zι
C1 =
1
J1
PJ
ι=1 rι1 (zι −¯z1) (zι −¯z1)T ,
α1 = α0 + J1.
α2 = α0 + J2.
α3 = α0 + J3.
α4 = α0 + J4.
β = β0 + J1
¯µ = 1
β (β0¯µ0 + J1¯z1)
W −1 = W −1
0
+ J1C1 +
β0J1
β0+J1 (¯z1 −¯µ0) (¯z1 −¯µ0)T
ν = ν0 + J1
π1 =
α1
α1+α2+α3+α4
π2 =
α2
α1+α2+α3+α4
π3 =
α3
α1+α2+α3+α4
π4 =
α4
α1+α2+α3+α4
p′ =
π2
1−π3−π4
σm =

νβ
1+β W
−1
2
end while
return {α1, α2, α3, α4, β, ¯µ, W, ν, Θ′′ = [µ, σm, p′, π3, π4]}

72
Chapter 3
Range Finder Model for Dynamic Environments
100
200
300
400
500
600
700
800
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
0
N
z[m]
(a) Short range
100
200
300
400
500
600
700
800
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
0
N
z[m]
(b) Long range
Figure 3.11: Data for second learning experiment reported by Thrun et al. 2005.
These data consist of two series of measurements obtained with a mobile robot
traveling through a typical oﬃce environment. From the set of measurements
10000 measurements that are centered around two diﬀerent expected ranges
are selected.
‘distance’ measures are used: the discrete KL-divergence:
d1 = KL (H||P) ≈
F
X
f=1
H (zf) log
H (zf)
P(zf | x, m, Θ),
(3.102)
and the square root of the discrete Hellinger distance:
d2 = DH (H||P) ≈
v
u
u
t
F
X
f=1

H (zf)
1
2 −P(zf | x, m, Θ)
1
2
2
.
(3.103)
The latter is known to be a valid symmetric distance metric (Bishop 2006).
3.5.1
First Learning Experiment
In a ﬁrst learning experiment, the experimental data reported by Thrun et al.
2005 is used. The data consists of two series of measurements obtained with
a mobile robot traveling through a typical oﬃce environment. From the set
of measurements, 10000 measurements that are centered around two diﬀerent
expected ranges, are selected. The two obtained sets with diﬀerent expected
ranges are shown in Figure 3.11. The parameters of the learning algorithms
are listed in Table 3.1. Figure 3.12 and Table 3.2 show the results of the ML-
EM and VB-EM estimators for the RBBM compared to the results of the ML

3.5 Experiments
73
ML-EM
VB-EM
ML-EM
RBBM
RBBM
Thrun’s model
σm,init = 0.5
p′
init = 1
3
α3,init = 1
8
σm,init = 0.5
p′
init = 0.4
βinit = 5000
α4,init = 1
8
zhit,init = 0.4
π3,init = 0.2
Winit = 12
β0 = 5
zshort,init = 0.3
π4,init = 0.1
¯µinit = xmp
W0 = 50
zmax,init = 0.1
νinit = 100
¯µ0 = xmp
zrand,init = 0.2
α1,init = 5
8
ν0 = 100
λshort,init = 0.1
α2,init = 1
8
α0 = 1
Table 3.1: EM-parameters for ﬁrst and second learning experiment (all in SI-
units). In the ML approaches, the mean of Phit (z | x, m) is set to xmp, i.e. the
most probable bin of the histogram of the training set H (z).
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.2
0.4
0.6
0.8
1.0
1.2
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
(a) Short range
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.1
0.2
0.3
0.4
0.6
0.7
0.8
0.0
0.5
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
(b) Long range
Figure 3.12: Comparison of the results of the ML-EM and VB-EM estimators
for the RBBM and the results of a maximum likelihood estimator for Thrun’s
model (Thrun et al. 2005) for the data of Figure 3.11.
estimator for Thrun’s model (Thrun et al. 2005) for these two sets. The results
are obtained by running the learning algorithms for 30 iteration steps.
The proposed ML-EM and VB-EM estimator outperform the ML-EM estimator
for Thrun’s model for the studied data sets.
Despite the reduced number
of parameters of the RBBM compared to Thrun’s model (Section 3.3.6), the
RBBM has at least the same representational power.

74
Chapter 3
Range Finder Model for Dynamic Environments
Experiment
d1 (Eq. (3.102))
ML-EM
VB-EM
ML-EM
RBBM
RBBM
Thrun’s model
short range
0.5295
0.5127
0.7079
long range
0.4366
0.4368
0.5852
average
0.4830
0.4747
0.6465
Experiment
d2 (Eq. (3.103))
ML-EM
VB-EM
ML-EM
RBBM
RBBM
Thrun’s model
short range
0.3166
0.2971
0.5629
long range
0.1683
0.2100
0.3481
average
0.2425
0.2535
0.4555
Table 3.2: Discrete KL-divergence (d1) and square root Hellinger distance (d2)
for the ﬁrst learning experiment between the training set and the results of the
ML-EM and VB-EM estimators for the RBBM and the ML-EM estimator for
Thrun’s model (Thrun et al. 2005).
3.5.2
Second Learning Experiment
The data for the second learning experiment is gathered during the execution
of a typical industrial pick-and-place operation in a human-populated environ-
ment. A Sick LMS 200 laser scanner is mounted on the ﬁrst axis of an industrial
Kuka 361 robot (Figure 3.13). The laser scanner provides measurements of the
robot environment and therefore of people and other unexpected objects in
the robot’s workspace. Processing these measurements is a ﬁrst step towards
making industrial robots aware of their possibly changing environment and as
such of moving these robots out of their cages.
In a ﬁrst step, a map (Figure 3.14) is build of the robot’s static environment,
i.e. without any unexpected objects or people moving around, by rotating the
ﬁrst axis of the industrial robot. Next, the robot performs a pick-and-place
operation while a number of people are walking around at random in the robot
environment. Diﬀerent sets of measurements are acquired each with a diﬀerent
number of people. Similar to the ﬁrst learning experiment, measurements are
selected centered around diﬀerent expected ranges from the acquired data. The
studied expected ranges in the second learning experiment range from 3.0m
to 4.5m in steps of 0.1m (Figure 3.14). For safety reasons, people were not
allowed to move closer than 1m to the robot, i.e. the safety region. Therefore,
measurements smaller than 1m are discarded.

3.6 Adaptive Full Scan Model
75
(a) Front view
(b) Side view
(c) Zoomed front view
Figure 3.13: Setup for the second learning experiment with a Sick LMS 200
laser scanner mounted on the ﬁrst axis of an industrial Kuka 361 robot.
From the data, the model parameters are learned using the same learning
parameters as in the ﬁrst learning experiment (Table 3.1).
Table 3.3 shows the Kullback-Leibler divergence (Eq. (3.102)) and the Hellinger
distance (Eq. (3.103)) averaged for the studied expected range for the diﬀerent
sets of measurements after running the ML-EM and VB-EM estimators for
the RBBM and the ML estimator for Thrun’s model (Thrun et al.
2005).
The results were obtained after running each of the learning algorithms for 30
iteration steps.
Figure 3.15 compares the results of the ML-EM and VB-EM estimators by
showing the results of the learning for two diﬀerent expected ranges and two
diﬀerent number of people populating the robot environment.
The proposed ML-EM and VB-EM estimator outperform the ML-EM estimator
for Thrun’s model for the studied data sets.
Despite the reduced number
of parameters of the RBBM compared to Thrun’s model (Section 3.3.6), the
RBBM has at least the same representational power7.
3.6
Adaptive Full Scan Model
This section extends the RBBM to an adaptive full scan model for dynamic
environments; adaptive, since it automatically adapts to the local density of
7To avoid confusion we want to stress that we use ‘representational power’ to indicate the
expressivity of the RBBM for experimental data.

76
Chapter 3
Range Finder Model for Dynamic Environments
 
 
selected ranges
cut out region
environment
x[m]
y[m]
Robot
-6
-6
-4
-4
-2
-2
0
0
2
2
4
4
6
Figure 3.14: Map build of the robot’s static environment, i.e. without any
unexpected objects or people moving around, by rotating the ﬁrst axis of the
industrial robot. For safety reasons, people were not allowed to move inside
the safety region (circle with radius 1m).
Therefore, measurements smaller
than 1m are discarded. The studied expected ranges in the second learning
experiment range from 3.0m to 4.5m in steps of 0.1m and are indicated in the
ﬁgure by the selected ranges region.
samples when using sample-based representations; full scan, since the model
takes into account the dependencies between individual beams.
In many applications using a range ﬁnder, the posterior is approximated by a
ﬁnite set of samples (histogram ﬁlters, particle ﬁlters). The peaked likelihood
function associated with a range ﬁnder (small σm due to its accuracy) is
problematic when using such ﬁnite set of samples. The likelihood P(z | x, m)
is evaluated at all samples, which are approximately distributed according to
the posterior estimate. Basic sensor models typically assume that the estimate
x and the map m are known exactly, that is, they assume that one of the
samples corresponds to the true value. This assumption, however, is only valid
in the limit of inﬁnitely many samples. Otherwise, the probability that a value
exactly corresponds to the true location is virtually zero. As a consequence,
these peaked likelihood functions do not adequately model the uncertainty due
to the ﬁnite, sample-based representation of the posterior (Pfaﬀet al. 2007).

3.6 Adaptive Full Scan Model
77
Experiment
d1 (Eq. (3.102))
number of
ML-EM
VB-EM
ML-EM
people
RBBM
RBBM
Thrun’s model
1
1.7911
1.5271
1.9697
2
1.8002
1.5172
1.9735
3
1.7789
1.5199
1.9606
4
1.8277
1.5140
1.9853
6
1.8007
1.5168
1.9655
8
1.7676
1.5157
1.9498
average
1.7944
1.5185
1.9674
Experiment
d2 (Eq. (3.103))
number of
ML-EM
VB-EM
ML-EM
people
RBBM
RBBM
Thrun’s model
1
5.6141
4.3449
6.5582
2
5.7038
4.3334
6.6119
3
5.6033
4.3468
6.5365
4
5.7563
4.2972
6.6744
6
5.6483
4.3126
6.5596
8
5.4989
4.2843
6.4257
average
5.6375
4.3199
6.5611
Table 3.3: Discrete KL-divergence (d1) and square root Hellinger distance (d2)
averaged for the studied expected range for the diﬀerent set of measurements of
the second learning experiment. Distances are between the training set and the
results of the ML-EM and VB-EM estimators for the RBBM and the ML-EM
estimator for Thrun’s model (Thrun et al. 2005). The ﬁrst column indicates
the number of people walking around in the environment in that particular set
of measurements.
Plagemann et al. 2007 and Pfaﬀet al. 2007 showed that by considering a
region around samples, the individual beams become statistically dependent.
The degree of dependency depends on the geometry of the environment and
on the size and location of the considered region. Beam models, such as the
RBBM, implicitly assume however that the beams are independent, that is:
P(z | θ, x, m)
=
B
Y
b=1
P(zb | θb, x, m) ,
(3.104)
where z = {zb}b=1:B and θ = {θb}b=1:B are the vectors containing the measured
ranges and the angles of the diﬀerent beams respectively; zb is the range

78
Chapter 3
Range Finder Model for Dynamic Environments
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.0
0.5
1.0
2.0
1.5
2.5
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
(a) Short range, 3 people
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.0
0.5
1.0
2.0
1.5
2.5
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
(b) Short range, 8 people
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.0
0.5
1.0
2.0
1.5
2.5
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
(c) Long range, 3 people
P(z | x, m)
z[m]
Histogram Training set
ML-EM RBBM
ML-EM Thrun’s model
VB-EM RBBM
0.0
0.5
1.0
2.0
1.5
2.5
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
(d) Long range, 8 people
Figure 3.15: Comparison of the results of the ML-EM and VB-EM estimators
for the RBBM and the results of a maximum likelihood estimator for two
diﬀerent expected ranges and two diﬀerent number of people populating the
robot environment.
measured at the beam with angle θb; B is the total number of beams and
P(zb | θb, x, m) is for instance the RBBM (Eq. (3.45)).
By neglecting the
dependency between beams, the resulting likelihoods P(z | θ, x, m) are overly
peaked. Models taking into account the dependencies between beams consider
the full range scan and are therefore called full scan models further on. The
full scan models proposed by Plagemann et al. 2007 and Pfaﬀet al. 2007 both
assume that the beams of a range scan are jointly Gaussian distributed. The
oﬀ-diagonal elements of the covariance matrix associated with the Gaussian
distribution represent the dependency. To learn the model parameters, both
methods draw samples from the region around a sample and perform ray-
casting using these samples. Plagemann et al. 2007 train a Gaussian process

3.6 Adaptive Full Scan Model
79
which models the full scan, while Pfaﬀet al. 2007 directly provide a maximum
likelihood estimate for the mean and covariance of the Gaussian.
Section 3.6.1 shows that the dependency between beams may introduce
multimodality, even for simple static environments.
Multivariate Gaussian
models as proposed by Plagemann et al.
2007 and Pfaﬀet al.
2007
cannot handle this multimodality. Therefore, a new sample-based method for
obtaining an adaptive full scan model from a beam model, able to handle
multimodality, is proposed.
Section 3.6.2 extends the adaptive full scan
model for dynamic environments by taking into account non-Gaussian model
uncertainty.
3.6.1
Sample-based Adaptive Full Scan Model for Static
Environments
Plagemann et al.
2007 and Pfaﬀet al.
2007 estimate the full scan model,
P(z | x, m)8, based on a local environment U(x) of the exact estimate x:
P(z | x, m) ≈
Z
P(˜x | x) Phit (z | ˜x, m) d˜x,
(3.105)
with P(˜x | x) the distribution representing the probability that ˜x is an element
of the environment U(x), i.e: ˜x ∈U(x). The environment U(x) is modeled as
a circular region around x. Since this section does not consider the dynamics
of the environment, only one component of the RBBM in Eq. (3.37) is used:
Phit (z | x, m). The marginalization over the environment U(x) in Eq.(3.105)
introduces dependencies between the measurements zb of the measurement
vector z.
The environment U(x), as explained above, depends on the sample density
around the sample x under consideration. Pfaﬀet al. 2006 proposed to use a
circular region with diameter dU(x), which is a weighted sum of the Euclidean
distance and the angular diﬀerence. Like Plagemann et al. 2007 and Pfaﬀet al.
2007, an approximation of the above likelihood can be estimated online for
each sample x by simulating L complete range scans at locations drawn from
U(x) using the given map m of the environment. Contrary to the multivariate
Gaussian approximation proposed by Plagemann et al. 2007 and Pfaﬀet al.
2007, we propose a sample-based approximation, able to handle multimodality.
Sampling from the environment U(x) immediately results in a sample-based
8To simplify the notation θ and θ are omitted from P (z | θ, x, m) and P (zb | θb, x, m),
respectively.

80
Chapter 3
Range Finder Model for Dynamic Environments
approximation of P(˜x | x):
P(˜x | x)
≈
1
L
L
X
l=1
δ˜x(l),
(3.106)
where δ˜x(l) denotes the delta-Dirac mass located in ˜x(l), and the samples are
distributed according to P(˜x | x):
˜x(l) ∼P(˜x | x) .
(3.107)
Using this sample-based approximation of P(˜x | x) the likelihood of Eq. (3.105)
can be approximated as:
P(z | x, m) ≈1
L
L
X
l=1
Phit

z | ˜x(l), m

.
(3.108)
Since this sample-based approximation has to be calculated online, the number
of samples has to be limited.
If the used environment U(x) is large, the
resulting approximation will be bad. To smooth the undesired bumpy behavior
due to the limited number of samples, the measurement noise σm governing
Phit (z | x, m) in Eq. (3.45), is artiﬁcially increased depending on the size of
U(x) by multiplying it with a factor:
1 + C
q
dU(x).
(3.109)
In further experiments, C was set to 20.
Experiment
A simple environment consisting of a rectangular ‘room’ with an object (a
Kuka KR 15/2 robot) in the middle (Figure 3.16) is used to show that the
marginalization over (even small) U(x) to obtain the true likelihood not only
introduces dependencies between the beams but also multimodality. The U(x)
results from a local uncertainty on the x- and y−position of 0.01m and a
rotational uncertainty of 5◦.
To obtain a reference, a Sick LMS 200 range
ﬁnder is used to take a large number of measurements (L = 1500) at random
locations sampled in U(x).
To allow for exact positioning, the Sick LMS
200 is placed on a Kuka 361 industrial robot.
The Sick LMS 200 range
ﬁnder is connected to a laptop that controls the motion of the Kuka 361

3.6 Adaptive Full Scan Model
81
Figure 3.16: Panorama taken from the Sick LMS 200 range ﬁnder mounted on
a Kuka 361 industrial robot. The environment consists of a rectangular ‘room’
with an object (a Kuka KR 15/2 robot) in the middle. We show that even
for this simple static environment, the presented sample-based full scan model
outperforms the Gaussian-based state-of-the-art models.
industrial robot over the network using Corba-facilities in the Open Robot
Control Software, Orocos (Bruyninckx 2001; Soetens 2006). A simpliﬁed map
of the environment (Figure 3.17(a)) is built to simulate the 150 complete range
scans needed to construct a full scan model. The marginal P(zb | x, m) of two
selected beams are studied in more detail. The marginal likelihoods for the
selected beam using the proposed sample-based approximation of Eq. (3.108)
and the Gaussian approximation proposed by Pfaﬀet al. 2007, are compared
in Figure 3.17(b)-3.17(c). The histogram of the measurements of the selected
beam in this ﬁgure clearly shows the multimodality of the likelihood caused
by the dependency between beams. In contrast to the Gaussian-based state-
of-the-art full scan model, the proposed sample-based approximation is able
to handle the multimodality of the range ﬁnder data. Figure 3.17(d) shows
the diﬀerence for all beams between the experimentally obtained cumulative
marginal (L = 1500) and the Gaussian-based and sample-based approximation
for all beams. The mean diﬀerence with the experimental data for the sample-
based approximation is 2.8 times smaller than the diﬀerence for the Gaussian-
based approximation, even for the simple static environment of Figure 3.16 and
the small U(x).
3.6.2
Sample-based Adaptive Full Scan Model for Dynamic
Environments
The adaptive beam model proposed by Pfaﬀet al. 2006 is suited for use in
dynamic environments since it uses the four component mixture beam model
(Thrun et al. 2005; Choset et al. 2005). To date however, the adaptive full scan
likelihood models of Pfaﬀet al. 2007 and Plagemann et al. 2007 have not been
adapted for dynamic environments. The assumption that the beams are jointly

82
Chapter 3
Range Finder Model for Dynamic Environments
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
 
 
x[m]
y[m]
Environment
Some measurements
Samples of U(x)
Example beams
(a) Environment model
0
1
2
3
4
5
6
0
0.5
1
1.5
2
2.5
3
3.5
4
 
 
P(zb | x, m)
z[m]
Experimental data (1500 samples)
Gaussian approximation (Pfaﬀet al. 2007)
Sample-based approximation
(b) Marginal likelihood for left beam
0
1
2
3
4
5
6
0
0.5
1
1.5
2
2.5
 
 
P(zb | x, m)
z[m]
Experimental data (1500 samples)
Gaussian approximation (Pfaﬀet al. 2007)
Sample-based approximation
(c) Marginal likelihood for right beam
0
50
100
150
200
250
300
350
400
0
1
2
3
4
5
6
7
x 10
−3
beam
 
 
∆Pc (z | x, m)
Gaussian-based approximation (Pfaﬀet al. 2007)
Sample-based approximation
(d) Diﬀerence between experimental cumula-
tive marginal and Gaussian and sample-based
approximations
Figure 3.17: Experimental results for sample-based adaptive full scan model for
static environments. (a) models the simple environment of Fig. 3.16. The range
ﬁnder is located at (0.15m, 0.75m). Samples from U(x) (resulting from a local
uncertainty on the x- and y−position of 0.01m and a rotational uncertainty of
5◦) are shown with black dots, and some simulated measurements are shown
in grey.
(b) and (c) show the marginal likelihood P(zb | x, m) for the two
selected beams together with the histogram of the experimentally recorded
range ﬁnder data, the Gaussian-based approximation (L = 150) of Pfaﬀet al.
2007, and the sample-based approximation (L = 150) of this paper. (d) shows
the diﬀerence for all beams between the experimentally obtained cumulative
marginal (L = 1500) and the Gaussian-based and sample-based approximation.

3.7 Discussion
83
Gaussian distributed, unable to capture the non-Gaussian uncertainty due to
environment dynamics, prevents the straightforward extension for dynamic
environments. In contrast, the sample-based approximation of the full scan
likelihood, as proposed in Section 3.6.1, can be extended to include environment
dynamics. To this end, replace Phit (z | x, m) in Eq. (3.105) and Eq. (3.108) by
the full mixture of Eq. (3.38).
Experiment
Figure 3.18(a) and Figure 3.18(b) compare the marginals for the selected
beams (Figure 3.17(a)) obtained from the adaptive full scan model for
dynamic environments using the proposed sample-based approximation and
the Gaussian approximation proposed by Pfaﬀet al.
2007.
In contrast
to the Gaussian-based state-of-the-art full scan model, the proposed sample-
based approximation is able to handle the multimodality of the range ﬁnder
data. Figure 3.18(c) shows a probability map of the adaptive full scan model
(sample-based approximation) suited for dynamic environments for the example
environment of Figure 3.16. The probability map plots P(z | x, m) as a function
of the position in the map and shows that the marginalization over the
environment U(x) of a sample in Eq. (3.105) not only introduces dependency
between beams but also introduces multimodality.
3.7
Discussion
This paper proposed and experimentally validated the RBBM, a rigorously
Bayesian network model of a range ﬁnder adapted to dynamic environments.
All modeling assumptions are rigorously explained, and all model parameters
have a physical interpretation. This approach resulted in a transparent and
intuitive model. The rigorous modeling revealed all underlying assumptions
and parameters. This way a clear physical interpretation of all parameters is
obtained providing intuition for the parameter choices.
In contrast to the
model of Thrun et al.
2005, the assumption underlying the non-physical
discontinuity in the RBBM is uncovered.
Furthermore, the paper proposes
a diﬀerent functional form for the probability of range measurements caused
by unmodeled objects Poccl (z | x, m) (Eq. (3.45)), i.e. quadratic rather than
exponential as proposed by Thrun et al. 2005. Furthermore, compared to the
work of Thrun et al. 2005; Choset et al. 2005; Pfaﬀet al. 2006 the RBBM
depends on fewer parameters, while maintaining the same representational
power for experimental data. Bayesian modeling revealed that both the rate
of decay of Poccl (z | x, m) and the probability of an occluded measurement π2
depend on one parameter p′. State of the art sensor models however, assume

84
Chapter 3
Range Finder Model for Dynamic Environments
0
1
2
3
4
5
6
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
 
 
P(z | x, m)
z[m]
Large sample approximation
Gaussian appr. (Pfaﬀ, 2007)
Sample-based approximation
(a) Marginal likelihood for left beam
0
1
2
3
4
5
6
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
 
 
P(z | x, m)
z[m]
Large sample approximation
Gaussian appr. (Pfaﬀ, 2007)
Sample-based approximation
(b) Marginal likelihood for right beam
−5
−4
−3
−2
−1
0
1
2
3
4
5
0
1
2
3
4
5
6
7
8
9
 
 
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
x[m]
y[m]
(c) Probability map P (z | x, m) from sample-
based approximation
Figure 3.18: Results for sample-based adaptive full scan model for dynamic
environments. (a) and (b) show the marginal likelihood P(zb | x, m) for the two
selected beams of Fig. 3.17(a) together with the Gaussian-based approximation
(L = 150) of (Pfaﬀet al. 2007) and the sample-based approximation (L = 150)
extended for the use in dynamic environments. (c) shows the probability map
resulting from the sample-based approximation. The probability map shows
P(z | x, m) as a function of the x- and y−position in the map.

3.7 Discussion
85
independency of these two parameters. Finally, a maximum-likelihood and a
variational Bayesian estimator (both based on expectation-maximization) were
proposed to learn the model parameters of the RBBM. Learning the model
parameters from experimental data beneﬁts from the RBBM’s reduced number
of parameters. Using two sets of learning experiments from diﬀerent application
areas in robotics (one reported by Thrun et al. 2005) the RBBM was shown
to explain the obtained measurements at least as well as the state-of-the-art
model of Thrun et al. 2005.
Furthermore, the paper extended the RBBM to an adaptive full scan model
in two steps: ﬁrst, to a full scan model for static environments and next, to a
full scan model for general, dynamic environments. The full scan model adapts
to the local sample density when using a particle ﬁlter, and accounts for the
dependency between beams. In contrast to the Gaussian-based state-of-the-
art models of Plagemann et al. 2007 and Pfaﬀet al. 2007, the proposed full
scan model uses a sample-based approximation, which can cope with dynamic
environments and with multimodality (which was shown to occur even in simple
static environments).

86
Chapter 3
Range Finder Model for Dynamic Environments
3.8
Appendices
3.8.1
Simpliﬁcation of Inﬁnite Sum
To goal of this appendix is to prove that
X
n
P(k | n, x, m) P(n) =
∞
X
n=k
 n
k

uk (1 −u)n−k (1 −p) pn

, (3.110)
can be simpliﬁed to:
X
n
P(k | n, x, m) P(n) = (1 −p′) p′k,
(3.111)
with p′ =
up
1−(1−u)p.
Expand Eq. (3.110) and move terms out of the summation so that:
X
n
P(k | n, x, m) P(n) =
(1 −p) ukpk
∞
X
n=k

n!
(n −k)!k! [(1 −u) p]n−k

.
(3.112)
Next introduce variables t = n −k and e = (1 −u) p:
X
n
P(k | n, x, m) P(n) = (1 −p) ukpk
∞
X
t=0
(t + k)!
t!k!
et

.
(3.113)
The next step is to prove by induction that:
∞
X
t=0
(t + k)!
t!k!
et

=
1
(1 −e)k+1 .
(3.114)
First, show that the above equality holds for k = 0:
∞
X
t=0
t!
t!et =
∞
X
t=0
et,
(3.115)

3.8 Appendices
87
which is the well-known geometric series, so:
∞
X
t=0
et =
1
1 −e,
(3.116)
showing that equality (3.114) indeed holds for k = 0. Next it is proved that, if
the expression holds for k −1, it also holds for k. Introduce variable V for the
solution of the inﬁnity sum for k and split up (3.114) in two parts:
V =
∞
X
t=0
(t + k)!
t!k!
et

=
∞
X
t=0
(t + k)!
t!k!
−(t + k −1)!
t! (k −1)!

et +
∞
X
t=0
(t + k −1)!
t! (k −1)! et

|
{z
}
1
(1−e)k
,
(3.117)
where the fact is used that the equality (3.114) holds for k −1. Simplify the
ﬁrst term of the summation to:
∞
X
t=0
(t + k)!
t!k!
−(t + k −1)!
t! (k −1)!

et =
∞
X
t=0
(t + k −1)!
t!k!
tet

.
(3.118)
The term in the summation for t = 0 is equal to zero. Hence, introduce the
variable t′ = t −1 and simplify:
∞
X
t=0
(t + k)!
t!k!
−(t + k −1)!
t! (k −1)!

et =
∞
X
t′=0
 (t′ + k)!
(t′ + 1)!k! (t′ + 1) et′+1

(3.119)
= e
∞
X
t′=0
(t′ + k)!
t′!k!
et′
|
{z
}
V
,
(3.120)
from which the series V we were looking for is recognized. Substitute the above
result in Eq. (3.117) so that:
V = eV +
1
(1 −e)k .
(3.121)
Solving this equation for V gives:
V =
1
(1 −e)k+1 ,
(3.122)

88
Chapter 3
Range Finder Model for Dynamic Environments
proving that equality (3.114) holds for k if it assumed to hold for k −1, and
closing the proof by induction.
Now substitute Eq. (3.114) in Eq. (3.113):
X
n
P(k | n, x, m) P(n) =
(1 −p) ukpk
[1 −(1 −u) p]k+1 ,
(3.123)
or rewrite as:
X
n
P(k | n, x, m) P(n) = (1 −p′) p′k,
(3.124)
where p′ =
up
1−(1−u)p, what is exactly what had to be proved.

Chapter 4
Overview and Classiﬁcation of
Multitarget Tracking and
Localization Algorithms using
their Bayesian Network
Representation
The goal of this chapter is to review the important state-of-the-art multitarget
tracking and localization (MTTL) algorithms, and classify them.
To this
end this chapter (i) formulates state-of-the-art MTTL algorithms in a uniﬁed
framework using the same terminology and symbols, (ii) lists the assumptions
of the MTTL algorithms, (iii) gives advantages and disadvantages of the
algorithms, and (iv) discusses advances in these algorithms. By (i) formulating
the state-of-the-art MTTL algorithms in a uniﬁed framework using the same
terminology and symbols and (ii) by analyzing the Bayesian network represen-
tation for probabilistic MTTL algorithms the diﬀerent algorithms are compared
and underlying assumptions are revealed.
Bayesian networks are used to
provide a graphical representation of the conditional independence assumptions
of the algorithms.
These independence assumptions are fundamental for
understanding and comparing most MTTL algorithms.
89

90
Chapter 4
Overview and Classification of MTTL Algorithms
4.1
Introduction
Multitarget tracking (MTT) consists of estimating the state of diﬀerent
targets recursively. Multitarget tracking and localization (MTTL) furthermore
includes detection of appearing and disappearing targets. Multitarget tracking
arises in a wide variety of contexts:
vision or laser-based people tracking
for mobile robotics and surveillance systems, sonar-based submarine tracking,
multitarget tracking for manipulation, tracking of animals to study their
behavior, etc.
Multitarget tracking has the following challenges: (i) the data association of raw
data to each target, (ii) the curse of dimensionality as the size of the state space
increases exponentially with the number of targets, (iii) the nonlinearity of
target dynamics and measurement models, and (iv) the handling of occlusions.
Sensors provide unlabelled measurements of the targets, leading to challenging
combinatorial data association: (i) the spatial separation between targets can
be small compared to the measurement errors and (ii) clutter measurements,
i.e. measurements not corresponding to any of the targets, can occur.
Moreover multitarget localization introduces extra diﬃculties: the number of
targets to track is unknown and possibly varying.
In the absence of prior
information on the environment, targets can appear and disappear at any time
and in any place.
A multitarget tracker and localizer has to automatically
detect appearing and disappearing targets and estimate the number of targets.
In a lot of MTTL applications it is important to obtain a unique identiﬁcation of
each target and to maintain a correct identiﬁcation for each target throughout
the entire sequence studied. Maintaining a correct identiﬁcation can be diﬃcult
when (i) targets are temporarily occluded, (ii) targets are interacting closely,
and (iii) targets appear and disappear.
Most MTTL algorithms rely on the following data ﬂow:
1. Raw sensor data is received from the sensors.
2. During a background subtraction process, measurements possibly origi-
nating from targets are separated from the raw sensor data.
3. The selected measurements are fed to a MTTL algorithm.
As will become clear later in this chapter, a lot of MTTL algorithms can only
handle at most one measurement per target. Therefore, step 3 in the above
data ﬂow is often preceded with a clustering step, where measurements possibly
originating from the same target are grouped together in one cluster. Instead of
feeding the individual measurements to the MTTL algorithm, the summarizing
cluster information is fed to the MTTL algorithm.

4.2 Basics
91
The family of track-before-detect algorithms tries to circumvent the explicit
background subtraction process, since in case of high clutter, i.e. low signal-to-
noise ratio, the background subtraction process may result in information loss.
The track-before-detect problem has been solved using dynamic programming,
maximum likelihood techniques, and particle ﬁlters. These algorithms are not
handled in this overview.
The goal of this chapter is to review the important state-of-the-art multitarget
tracking and localization (MTTL) algorithms, and classify them. Section 4.2
ﬁrst introduces the important concepts and nomenclature of the MTTL
problem together with the basic concepts of the data association problem
underlying MTTL. Section 4.3 lists the properties of the MTTL that are
used to classify MTTL algorithms. Section 4.4 discusses the most important
MTTL algorithms and (i) formulates state-of-the-art MTTL algorithms in
a uniﬁed framework using the same terminology and symbols, (ii) lists the
assumptions of the MTTL algorithm, (iii) gives advantages and disadvantages
of the algorithm, (iv) discusses advances of the algorithm, and (v) presents the
Bayesian network representation of the algorithm to graphically represent the
conditional independence assumptions of the algorithm. Finally, Section 4.5
presents a classiﬁcation table for the most important MTTL algorithms and
discusses this classiﬁcation.
4.2
Basics
Section 4.2.1 ﬁrst introduces the important nomenclature and notation of the
MTTL problem. Section 4.2.2 discusses the data association problem, which is
a fundamental problem in MTTL.
4.2.1
Nomenclature and Notation
The ﬁnal goal of MTTL is to obtain an estimate of the track of the targets
during the observation period.
• A target, also referred to as object, is the goal of the tracking. The state of
a target at a particular time step t is indicated with xt
n, where n indicates
one of the N t targets at time step t. xt = {xt
n}n=1:N t represents all of
the target states at time step t.
• A track refers to the entire trajectory of a target up to a time step T ,
i.e. the collection of target states up to time step T : X T
n = {xt
n}t=1:T .

92
Chapter 4
Overview and Classification of MTTL Algorithms
Again, X T = {xt}t=1:T = {xt
n}t=1:T
n=1:N T represents all of the target tracks
at time step T 1.
• Track detection, creation or initiation refers to the process of detecting
(also called localizing) new targets as they appear in the scene or
observation volume.
Likewise, track termination or deletion refers to
the process of removing target tracks, as targets leave the scene. Track
management encapsulates both track detection and termination.
• The process model P
 xt | xt−1
, also referred to as target dynamics,
motion model, state space model, dynamic model or system model,
models the probabilistic change of the target states over time. A common
assumption states that the individual targets evolve independently over
time:
P
 xt | xt−1
=
n=1:N t
Y
n
P
 xt
n | xt−1
n

.
(4.1)
This assumption is obviously violated during target interaction.
• At a particular time step t the available sensors produce a set of Kt
measurements: yt = {yt
k}k=1:Kt of the targets under study. y1:t groups
all measurement information up to time step t.
• The measurement model P(yt | xt), also referred to as the observation
model or likelihood model, models the probabilistic measurement process
given the target states.
The measurements can be divided in mea-
surements originating from the targets under study and the ones not
originating from any of the targets. The latter are referred to as clutter,
false alarms, false measurements, spurious measurements or noise. The
area covered by the sensors is referred to as the observation volume,
surveillance volume, or ﬁeld of view and denoted by V .
• The data association or correspondence describes which measurement
originates from which target or which target causes which measure-
ment. Measurement-to-target (M→T), also called measurement-to-track,
data association tries to assign measurements to target tracks, while
target-to-measurement (T→M), also called track-to-measurement data
association assigns target tracks to measurements.
Measurement-to-
target associations are most popular. While measurement-to-track and
track-to-measurement association are completely exchangeable from a
theoretical point of view, they are useful in diﬀerent contexts.
Here,
1In literature (Gauvrit et al. 1997; Cox 1993) another deﬁnition of track is also available:
A track is the set of measurements assigned to the same target n up to the considered time
T: X T
n = 
yt
k|rt
k = n	t=1:T , where yt
k and rt
k are deﬁned further on in this section.

4.2 Basics
93
the measurement-to-target association vector at time step t is denoted by
rt. The elements of the association vector rt = {rt
k}k=1:Kt are deﬁned
as:
rt
k =
(
0
if yt
k is clutter,
n ∈{1 · · · N t}
if yt
k is caused by target n.
(4.2)
So rt
k is a discrete variable taking a value between 0 and N t thereby
indicating if measurement yt
k is a false measurement or by which target
it is caused. The above deﬁnition reveals an implicit assumption made
when using M→T associations: a measurement can originate from at
most one target or from clutter. This assumption will be referred to as
DA1a.
Similar, the target-to-measurement association vector at time step t is
denoted by ert. The elements of the association vector ert =
n
ert
n
o
n=1:N t
are deﬁned as:
ert
n =
(
0
if target n is not detected,
k ∈{1 · · · Kt}
if target n generates measurement yt
k.(4.3)
So ert
n is a discrete variable taking a value between 0 and Kt thereby
indicating if a target with state xt
n is undetected or which measurement
it generates. The above deﬁnition reveals an implicit assumption made
when using T→M associations:
a target can generate at most one
measurement at every time step.
This assumption will be referred to
as DA2a.
It is straightforward to convert the M→T associations to T→M associa-
tions and vice versa provided that both the data associations assumption
DA1a and DA2a hold (Vermaak et al. 2005):
T →M to M →T :
rt
er
t
n = n
if ert
n ̸= 0, n = 1 · · · N t, and (4.4)
M →T to T →M :
ert
rt
k = k
if rt
k ̸= 0, k = 1 · · · Kt.
(4.5)
• In some cases it can be convenient to explicitly model the distinction
between the false measurements and measurements originating from
targets in the measurement model (conditional on the target states and
data association variables P(yt | xt, rt). The measurement model for the
false measurements PC(yt | xt) is generally assumed to be independent
of the target states xt, resulting in: PC(yt). If the measurements yt, i.e.
both false measurements and measurements originating from the targets,

94
Chapter 4
Overview and Classification of MTTL Algorithms
are assumed to be conditionally independent given the target states xt
and data association variables, the measurement model factorizes as:
P
 yt | xt, rt
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
k:rt
k∈{1:N t}
P

yt
k | xt
rt
k

|
{z
}
target measurements
,
(4.6)
or when using the M→T associations and,
P

yt | xt, ert
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
n∈{1:N t}:er
t
n̸=0
P

yt
er
t
n | xt
n

|
{z
}
target measurements
, (4.7)
when using the T→M associations. It is commonly assumed that the false
measurements are uniformly distributed over the observation volume V :
PC
 yt
k

=
V −1.
(4.8)
• Another useful probability distribution is P
 yt | xt−1, rt
. This proba-
bility distribution expresses the probability of the measurements given
only the target states at the previous time step t −1 and the data
association variables rt.
Again, it can be useful to explicitly model
the distinction between diﬀerent kind of measurements.
On top of
the false measurements, a distinction is made between measurements
originating from the targets already being tracked at time step t −1
and measurements originating from new targets (since no information
on the target states at time step t is available).
Assuming that all
measurements are conditionally independent given the target states xt−1
and data association variables, rt, P
 yt | xt−1, rt
factorizes as:
P
 yt | xt−1, rt
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
k:rt
k>N t−1
PN
 yt
k | xt−1
|
{z
}
new target measurements
Y
k:rt
k∈{1:N t−1}
P

yt
k | xt−1
rt
k

|
{z
}
existing target measurements
,
(4.9)

4.2 Basics
95
or when using the M→T associations and,
P

yt | xt−1, ert
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
n>N t−1
PN

yt
er
t
n | xt−1
|
{z
}
new target measurement
Y
n∈{1:N t−1}:er
t
n̸=0
P

yt
er
t
n | xt−1
n

|
{z
}
existing target measurements
,
(4.10)
when using the T→M associations, where PN
 yt
k | xt−1
is the probability
distribution of the measurements originating from new targets given the
target states at the previous time step t−1. As for the false measurements
it is commonly assumed that measurements originating from new targets
are uniformly distributed over the observation volume V given only the
target states up to time step t −1:
PN
 yt
k | xt−1
=
V −1.
(4.11)
4.2.2
Data Association
Data association is a fundamental problem in MTTL. Since sensors provide
unlabelled measurements of targets, the measurements have to be assigned to
targets. These assignments are unknown, as are the true targets. Therefore, the
data association and the tracking of the targets must be solved jointly. The data
association problem is beside combinatorial (causing an exponential increase of
the number of associations with the number of targets and measurements),
challenging since:
(i) the spatial separation between targets can be small
compared to the measurement errors, (ii) measurements not corresponding
to any of the current targets can occur, both clutter measurements (i.e.
measurements not corresponding to any of the targets) and measurements from
a new target not yet being tracked, (iii) targets can be temporarily occluded
or leave the scene, not producing any measurements.
The data association
problem has also been referred to as the motion correspondence problem or
perceptual grouping (Cox 1993).
This section ﬁrst lists the assumptions most commonly made in data association
and next, gives an overview of the most important data association approaches
for MTTL: neareast-neighbor and strongest-neighbor, multihypothesis tracking,
joint probabilistic data association and joint ﬁlters.

96
Chapter 4
Overview and Classification of MTTL Algorithms
4.2.2.1
Assumptions
Measurement Gating
Measurement gating is a way to reduce the number
of legal data associations by only taking into account ‘reasonable’ data
associations.
To this end, a validation volume, also called gate, is created
around each target estimate. The size of the validation volume depends on
both the uncertainty of the target estimate and the measurement uncertainty.
Measurements outside the validation volume of a target are not taking into
account during the data association hereby reducing the combinatorics of the
data association problem. The validation volume is usually deﬁned using the
Mahalanobis distance. The Mahalanobis distance dm between a measurement
y and a target estimate, is a dissimilarity measure between the measurement
y and the probability distribution of the expected measurement with mean µ
and covariance Σ given the current target estimate:
d2
m = (y −µ)T Σ (y −µ) .
(4.12)
A thorough discussion on gating including references to eﬃcient implementa-
tions of the measurement gating procedure and eﬃcient approximations of the
Mahalanobis distance can be found in (Cox 1993). Also worth mentioning is
the eﬃcient gating proposed by Collins and Uhlmann 1992.
Multiple and merged measurements
Most probabilistic algorithms for data
association assume that a measurement can originate from at most one
target or from clutter (DA1a) and that a target can generate at most one
measurement at every time step (DA2a).
The above two assumptions are
reasonable in for instance radar tracking and reduce the combinatorics of
the data association problem. In laser-based and vision tracking, the above
assumptions are violated (Khan et al. 2006). A laser range scanner typically
returns several range measurements for each target.
Likewise in vision
based tracking, measurements of the targets are provided by background
subtraction algorithms or interest point detectors. The former return multiple
blob centroids per target, or during close interactions return a merged blob
centroid for two or more targets.
The latter return a cloud of multiple
measurements for each target. Therefore, in laser-based and vision tracking
the assumption DA1a should be replaced by: a measurement can originate
from one target, multiple targets or from clutter (DA1b); and DA2a should
be replaced by:
a target can generate zero or multiple measurements at
every time step (DA2b).
Measurements originating from multiple targets
are referred to as merged measurements or unresolved measurements, while
multiple measurements originating from a single target are referred to as
multiple measurements or split measurements. In the literature (MacCormick
and Blake 2000; Schulz et al. 2001b), mutual exclusion is also used to refer to
the fact that a measurement can only originate from a single target (DA1a).

4.2 Basics
97
Since most MTTL algorithms rely on assumptions DA1a and DA2a, researchers
(i) tend to assign merged measurements to a single target , and (ii) have applied
measurement preprocessing techniques where multiple ‘close’ measurements are
clustered and summarized into a single summarizing measurements in order to
obtain a single measurement for each target.
4.2.2.2
Nearest-neighbor and strongest-neighbor
The nearest-neighbor (NN) or strongest-neighbor (SN) approach is relatively
simple and has relatively low computational cost. In the simplest and most
common setting, the assumptions DA1a and DA2a are made: a measurement
can originate from one target or from clutter and a target can produce zero or
one measurements at a time. In this case, the NN approach only has to assign
one (or no) measurement to each existing target track, and conceptually, it
selects the measurement that is ‘nearest’ to the expected measurement for that
track. In most cases ‘nearest’ is used in the context of a statistical distance by
using the Mahalanobis distance as deﬁned in Equation (4.12). After calculating
the statistical distances, the measurement to target assignments can be done
in a ‘local’ or ‘global’ way. The global NN assigns measurements to tracks
using an optimal assignment algorithm that maximizes the likelihood of the
measurements, given the current target tracks. The term global is used to refer
to the fact that the assignment is made considering all possible (within gates)
associations under the constraint that an observation can be associated with at
most one track. The local NN however reduces the computational cost by using
a greedy algorithm to assign measurements to tracks, coming at the cost of lack
of optimality guarantees. It updates a track with the closest measurement, even
if it is already used by another track and as such drops assumption DA1a.
In the NN setting, track initiation and deletion is determined by heuristics.
Nearest-neighbor algorithms usually perform badly since (i) there is always a
chance that the ‘nearest’ measurement is not belonging to the target, especially
during close target interactions or high clutter, and (ii) the association is only
made by examining the current frame (Cox 1993). Therefore, NN algorithms
only work well in the case of widely spaced targets, accurate measurements and
limited amount of clutter (Blackman 2004).
4.2.2.3
Multihypothesis Tracking (MHT)
The multihypothesis approach permits the delay of ambiguous association
decisions until future measurements that relief the ambiguity are incorporated
into the target estimates.
It defers decisions by forming alternative data
association hypotheses whenever the data association is ambiguous. Rather

98
Chapter 4
Overview and Classification of MTTL Algorithms
than choosing the best hypothesis, or combining diﬀerent hypotheses, the
hypotheses are propagated into the future until measurements resolve the
ambiguities.
The MHT algorithm maintains several association hypotheses for each target at
each time frame (Reid 1979). To this end the MHT exhaustively enumerates all
possible associations over time. The ﬁnal tracks correspond to the most likely
set of associations over the time period of the observation. The algorithm has
the ability to create new tracks for targets entering the scene and to terminate
tracks for targets leaving the scene.
The MHT algorithm makes the associations in a deterministic sense and
exhaustively enumerates all possible associations.
This makes the MHT
algorithm computationally exponential in both memory and time. To overcome
this limitation, a number of techniques have been developed:
clustering,
hypothesis and track pruning (N-scan pruning), and track merging (Blackman
2004).
Blackman 2004 distinguishes four diﬀerent approaches to the MHT implemen-
tation: hypothesis-oriented MHT, track-oriented MHT, the multidimensional
(or multiple frame) assignment method, and the Bayesian MHT. For brevity,
we only discuss the ﬁrst, hypothesis-oriented MHT, following the original work
of Reid 1979, which deﬁnes a systematic way to generate and evaluate multiple
data association, in this case M→T hypotheses.
The hypothesis-oriented MHT forms a large number of hypotheses, where each
hypothesis provides an interpretation of all past measurements consisting of a
collection of disjoint tracks (i.e. tracks NOT sharing a measurement (DA1a)).
These hypotheses are constructed in an iterative way as new measurements are
received. The hypotheses can be visualized in a hypothesis tree, where each
node represents a hypothesis. An iteration begins with a set of current track
hypotheses (the leaf nodes). For each hypothesis (leaf node), a prediction of
each target state is made. These predictions are then compared probabilistically
with the actual measurements by evaluating a distance measure (for instance
the Mahalanobis distance (Equation (4.12)). A set of new associations (child
nodes) are established for each hypothesis (leaf node) based on the distance
measure. Diﬀerent possibilities are taken into account: a measurement can (i)
belong to a target already being tracked, (ii) originate from a new target, or
(iii) be clutter. As such, each iteration extends the depth of the hypothesis
tree with one level. Each hypothesis has to be evaluated, i.e. a probability has
to be assigned to each hypothesis. The probability has to take into account
all aspects of the data association problem: the prior probability of the target
presence, the clutter density, the history of the hypothesis, and the consistency
of the observations in the tracks.
The techniques of clustering, hypothesis and track pruning (N-scan pruning),

4.2 Basics
99
and track merging can be regarded as techniques for pruning the hypothesis
tree.
Another strategy to reduce the computational time and storage, the track
tree (Kurien 1990), is based on the observation that the same track (and
the attached ﬁlter) may appear in more than one hypothesis.
Rather than
replicating common tracks over diﬀerent hypotheses, the hypotheses tree
contains pointers to nodes in the track tree.
Practical implementation of Reid’s algorithm have to prevent the indiscriminate
generation of hypothesis in each step of the iteration. Murty’s algorithm (Murty
1968) can be used to only generate hypotheses with considerable probabilities,
by determining the k-best hypotheses in polynomial time (Cox and Miller 1995;
Cox and Hingorani 1996; Cox et al. 1997; Miller et al. 1997; Danchick and
Newnam 2006).
4.2.2.4
Joint Probabilistic Data Association (JPDA)
The probabilistic data association (PDA) approach avoids ambiguous deci-
sions by ‘averaging’ over the diﬀerent data association hypotheses.
The
PDA approach was originally developed for tracking a single target under
clutter (Bar-Shalom and Jaﬀer 1972; Kirubarajan and Bar-Shalom 2004) but
was modiﬁed for application in multitarget environments, referred to as the
joint probabilistic data association (JPDA) (Fortmann et al. 1983).
The JPDA algorithm is the best known example of the Bayesian data
association paradigm. From this point of view, JPDA is considered to have
a fundamental advantage over classical data association techniques including
the NN and MHT algorithms (Blom and Bloem 2000).
The JPDA tackles uncertain data association conditions by allowing a target
to be updated by a weighted sum of all measurements (in its gate).
The
weights represent the probability that the measurement originates from that
target. As such, a measurement can contribute to more than one track, and it
contributes to this target with a certain weight. Such associations are referred
to as ‘soft’ assignments as compared to the ‘hard’ assignments of the NN and
MHT algorithms. In order to determine these weights, the probability that
each measurement originates for each target has to be calculated. To this end,
in the most basic setting, all possible hypotheses have to be enumerated at
every time step. To construct these hypotheses the assumptions DA1a and
DA2a are made: a measurement can only originate from a single target and a
target cannot generate more than one measurement. To limit the number of
hypotheses, Murty’s algorithm (Murty 1968) can be used, as in the MHT, to

100
Chapter 4
Overview and Classification of MTTL Algorithms
only generate hypotheses with considerable probabilities, by determining the
k-best hypotheses in polynomial time.
In contrast to the MHT algorithm, the JPDA algorithm in its basic setting is
not adapted for track initiation and deletion as it is formulated for a ﬁxed and
known number of targets.
4.2.2.5
Joint ﬁlters
Joint ﬁlter approaches formulate the MTT problem in the joint state space of
the target states and the unknown data association hypotheses. Since (i) the
state space dimension of this joint ﬁlters is high (exponential in the number of
targets) and possibly changing (in the case of unknown and varying number
of targets), and (ii) the posterior on the target states and the unknown data
association hypothesis is multimodal, special estimation techniques have to
be used. Section 4.4.4 discusses some joint particle ﬁlter approaches and the
techniques used herein to handle the diﬃculties arising due to the joint state
space formulation.
4.3
Classiﬁers for MTTL algorithms
This section lists properties that are used in this chapter to classify/distinguish
MTTL algorithms.
• The online versus batch nature of the algorithm.
• The tracker can rely on parametric versus non-parametric distributions.
• The ability or inability to maintain unique track identities.
• The ability to handle an unknown and varying number of targets. The
three possibilities are:
– a ﬁxed and known number of targets,
– a ﬁxed and unknown number of targets, or
– a varying and unknown number of targets.
• The ability of the tracker to handle linear versus nonlinear process and
measurement models.
• The ability of the tracker to handle multiple measurements (DA2b).
• The ability of the tracker to handle merged measurements (DA1b).

4.4 Algorithms for MTTL
101
• The fact that the tracker relies on explicit gating or not.
• The state space of the estimation:
– has the dimension of a single target,
– groups all individual target states together,
– groups all individual target states and data association variables, or
– is the set of random ﬁnite sets of the target states (see PHD ﬁlter
in Section 4.4.6).
• The multitarget tracker can consist of single versus multiple trackers:
– single multimodal tracker, where the tracker tries to track multiple
targets by ﬁtting a multimodal distribution to the posterior, where
each mode represents a single target.
– single joint tracker, where the tracker works in the joint state space
of all targets (and data association variables).
– multiple trackers, where each tracker is an instantiation of a single
target tracker.
• The data association problem is:
– circumvented,
– based on hard assignments, or
– based on soft assignments.
• The data association variables are:
– estimated, or
– marginalized.
The classiﬁcation of the algorithms discussed in the next section (Section 4.4)
according to the classiﬁers listed above, is presented in tabular format in
Section 4.5.
4.4
Algorithms for MTTL
This section discusses the most important MTTL algorithms and (i) formulates
state-of-the-art MTTL algorithms in a uniﬁed framework using the same
terminology and symbols, (ii) lists the assumptions of the MTTL algorithm, (iii)
gives advantages and disadvantages of the algorithm, (iv) discusses advances

102
Chapter 4
Overview and Classification of MTTL Algorithms
in the algorithm, and (v) presents the Bayesian network representation of the
algorithm to graphically represent the conditional independence assumptions.
Below, diﬀerent closely related algorithms are grouped in a single section: ﬁrst
the general algorithm together with assumptions, advantages and disadvantages
is discussed, followed by the diﬀerent variants together with their speciﬁc
assumptions and disadvantages.
4.4.1
Multihypothesis Tracking (MHT)
The multihypothesis tracking (MHT) (Reid 1979; Blackman 2004) algorithm
for multitarget tracking and localization is founded on the multihypothesis
tracking strategy for data association (Section 4.2.2.3). The MHT maintains
multiple hypotheses, whenever the data association is ambiguous. Along with
each hypothesis the MHT maintains a tracker for the targets. By using the
MHT strategy for data association the algorithm is able to defer diﬃcult
data association hypotheses to later time steps, this way avoiding premature
decisions.
The MHT algorithm is a recursive ﬁlter maintaining a hypothesis tree
(Section 4.2.2.3) where in each time step the hypothesis tree is expanded with
a new set of leafs (hypotheses):
1. the target states for all target tracks within the leaf hypotheses are
predicted according to their process model (target prediction),
2. new hypotheses (i.e. new leafs) are generated from the leaf hypotheses of
the hypothesis tree (hypothesis generation),
3. the probability of the new hypotheses are calculated (hypothesis evalua-
tion),
4. the hypotheses tree is pruned (pruning), and
5. the target states of all target tracks within the hypotheses left after
pruning, are updated according to the data association of the new
hypothesis (target correction).
More formally, a hypothesis h at time step t, indicated with Θt
h, consists of a
set of association events θti
h up to time step t:
Θt
h
=

θti
h
	ti=1:t .
(4.13)

4.4 Algorithms for MTTL
103
An association event θt
h in turn, represents a set of M→T associations indicating
which measurement yt
k originates from which target xt
n at time step t, i.e.:
θt
h
=

rt
k
	
k=1:Kt .
(4.14)
Along with each hypothesis Θt
h the MHT maintains a set of target trackers
estimating the states xt
n,h of the N t
h targets in the hypothesis. Up to time step
t −1, the target states xt−1
n,h have been updated using all the association events

θti
h
	ti=1:t−1 contained in the association vectors in Θt−1
h
of hypothesis h.
In the target prediction step, the states of the N t
h targets in a hypothesis are
predicted, given all measurement information up to time step t −1, i.e:
¯xt
h ∼P
 xt
h | y1:t−1
.
(4.15)
By assuming independent target dynamics, the target states in a hypothesis h
(with p (h) representing the parent hypothesis) the prediction step factorizes
as:
P

xt
h | xt−1
p(h)

=
N t
h
Y
n=1
P

xt
n,h | xt−1
n,p(h)

, and
(4.16)
the prediction step can proceed independently for each target:
¯xt
n,h
∼
P
 xt
n,h | y1:t−1
(4.17)
=
Z
P

xt
n,h | xt−1
n,p(h)

P

xt−1
n,p(h) | y1:t−1
dxt−1
n,p(h),
(4.18)
with P

xt−1
n,p(h) | y1:t−1
the distribution of the target state of the nth target
in the parent hypothesis p (h) at the previous time step t −1.
During the hypothesis generation a new set of hypotheses {Θt
h}h=1:Ht is created
from the hypotheses at the previous time step

Θt−1
h
	
h=1:Ht−1 by combining
one of the hypothesis at time step t −1 with an association event θt
h i.e.:
Θt
h
=
n
Θt−1
p(h), θt
h
o
.
(4.19)
Generating the association events θt = {rt
k}k=1:Kt consists of determining
which measurements originate from which targets, from clutter or from

104
Chapter 4
Overview and Classification of MTTL Algorithms
previously unobserved targets (new targets). This requires the enumeration
of all legal associations events. To limit the number of legal associations the
data association assumptions DA1a and DA2a are commonly made (Cox 1993).
During the hypothesis evaluation the probability P
 Θt
h | y1:t
of all new
hypotheses is calculated.
Using Bayes’ rule this probability can be written
as:
P
 Θt
h | y1:t
∝
P
 yt | Θt
h, y1:t−1
P
 Θt
h | y1:t−1
(4.20)
∝
P
 yt | Θt
h, y1:t−1
P

θt
h, Θt−1
p(h) | y1:t−1
(4.21)
∝
P
 yt | Θt
h, y1:t−1
P

θt
h | Θt−1
p(h), y1:t−1
P

Θt−1
p(h) | y1:t−1
. (4.22)
Each factor in Equation (4.22) denotes a probability distribution with a
physical interpretation:
• The factor P
 yt | Θt
h, y1:t−1
denotes the probability of obtaining the
measurements yt given all associations up to time step t and the mea-
surement information up to time step t −1. To obtain P
 yt | Θt
h, y1:t−1
a distinction is made between measurements originating from targets
already being tracked, from clutter and from new targets. The association
event θt
h contains a set of M t
f false alarms and a set of M t
n measurements
from a new target, while the other Kt −M t
f −M t
n measurements are
assumed to originate from a single target (DA1a). Assuming that the
measurements are detected independently of each other results in (see
also Equation (4.9)):
P
 yt | Θt
h, y1:t−1
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
k:rt
k>N t−1
p(h)
PN
 yt
k | y1:t−1
|
{z
}
new target measurements
Y
k:rt
k∈
1:N t−1
p(h)
	 P
 yt
k | Θt
h, y1:t−1
|
{z
}
existing target measurements
.
(4.23)
In the above equation, an expression for P
 yt
k | Θt
h, y1:t−1
, the prob-
ability of measurement yt
k given that it is target originated and given

4.4 Algorithms for MTTL
105
all measurements up to time step t −1, is still required. Using some
probability calculus this probability can be rewritten as:
P
 yt
k | Θt
h, y1:t−1
=
Z
xt P
 yt
k, xt | Θt
h, y1:t−1
dxt
(4.24)
=
Z
xt P
 yt
k | xt, Θt
h, y1:t−1
P
 xt | Θt
h, y1:t−1
dxt, (4.25)
=
Z
xt
rt
k
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k,(4.26)
where P

yt
k | xt
rt
k

is the measurement model and P

xt
rt
k | y1:t−1
is the
prediction of the target state as obtained in the target prediction step of
Equation (4.17). Substituting Equation (4.26) in Equation (4.23) gives:
P
 yt | Θt
h, y1:t−1
=
Y
k:rt
k=0
PC
 yt
k

|
{z
}
false alarms
Y
k:rt
k>N t−1
p(h)
PN
 yt
k | y1:t−1
|
{z
}
new target measurements
Y
k:rt
k∈
1:N t−1
p(h)
	
Z
xt
rt
k
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k
|
{z
}
existing target measurements
.
(4.27)
Assuming that the false measurements and the measurements originating
from a new target are uniformly distributed over the observation volume
V (Equation (4.8) and Equation (4.11)) simpliﬁes Equation (4.27) to:
P
 yt | Θt
h, y1:t−1
= V −(Mt
f +Mt
n)
Y
k:rt
k∈
1:N t−1
p(h)
	
Z
xt
rt
k
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k
|
{z
}
existing target measurements
.
(4.28)
The integral in this equation can only be determined analytically for
a restricted set of distributions.
In the basic MHT, discussed further
on, distributions are assumed to be Gaussian resulting in a closed form
expression for P
 yt | Θt
h, y1:t−1
.

106
Chapter 4
Overview and Classification of MTTL Algorithms
• The factor P

θt
h | Θt−1
p(h), y1:t−1
represents the probability of the asso-
ciation θt
h given all measurement information and data associations up
to time step t −1. This probability takes into account the probability
distributions of false alarms, new measurements, track detection and
termination (Cox and Hingorani 1996):
P

θt
h | Θt−1
p(h), y1:t−1
=
M t
n!M t
f!
Kt!
P(Mn) P(Mf)
N t
Y
n=1
 P t
det,n
1t
det,n  1 −P t
det,n
1−1t
det,n
 P t
del,n
1t
del,n  1 −P t
del,n
1−1t
del,n ,
(4.29)
with M t
n and M t
f the number of measurements from new targets and false
alarms in the association event θt
h respectively, P(Mn) and P(Mf) the
prior probability mass functions of the number of measurements from
new targets and the number of false measurements respectively, P t
det,n
and P t
del,n the probabilities of detection and termination of the track of
target n at time step t respectively, and 1t
det,n and 1t
del,n the indicator
variables deﬁned by:
1t
det,n ≜
(
1
if target n (in Θt−1
p(h)) is detected at time step t
0
otherwise, and
(4.30)
1t
del,n ≜
(
1
if target n (in Θt−1
p(h)) is deleted at time step t
0
otherwise.
(4.31)
Two common assumptions are to assume that P(M t
n) and P

M t
f

are
either (i) Poisson distributed with densities λn and λf respectively, i.e.
P(M t
n) =
λn
Mt
n! and P

M t
f

=
λf
Mt
f ! or (ii) uniformly distributed, i.e.
P(M t
n) = Cte and P

M t
f

= Cte.
• The factor P

Θt−1
p(h) | y1:t−1
represents the probability of the parent
hypothesis Θt−1
p(h) given all measurement information up to time step t−1
and is available from the previous time step t −1.
During the pruning the probability of each hypothesis calculated during the
hypothesis generation step is used to limit the number of hypotheses (by only
maintaining the most probable hypotheses).

4.4 Algorithms for MTTL
107
...
...
yt−1
k
yt
k
yt+1
k
rt−1
k
rt
k
rt+1
k
Kt−1
Kt
Kt+1
Nh
xt−1
n,h
xt
n,h
xt+1
n,h
H
Figure 4.1: Bayesian network model for multihypothesis tracker (MHT). The
boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements, a set of Nh
targets (the number of targets in hypothesis h) and a set of H hypotheses. The
shaded nodes are observed or known.
Finally, during the target correction the target states xt
n,h of all target
tracks within the hypotheses left after pruning, are updated according to the
association vectors θt
h:
P
 xt
n,h | y1:t
∝P
 yt
k | xt
n,h

P
 xt
n,h | y1:t−1
with k : rt
k ∈θt
h = n,(4.32)
with P

yt
k | xt
n,h

the measurement model and P

xt
n,h | y1:t−1
according to
the target prediction in Equation (4.17).
Figure 4.1 shows the Bayesian network of the MHT representing all conditional
independence assumptions graphically.
Although the discrete association
variables rt were not used in the original MHT formulation, they are included
here in the Bayesian network representation to stress some implicit assumptions
and to compare the MHT with other MTTL algorithms. For each diﬀerent
hypothesis h the MHT maintains a bank of ﬁlters, one for each of the N t
h
targets in that hypothesis. Within each hypothesis h, the M→T associations
rt
k are ﬁxed and known, they are the associations listed in the association event
θt
h = {rt
k}k=1:Kt.

108
Chapter 4
Overview and Classification of MTTL Algorithms
Assumptions
• Since the MHT uses M→T associations for modeling the data association,
the data association assumption DA1a is implicitly made:
i.e one
measurement can only originate from one target or from clutter.
• To limit the number of legal associations that have to be enumerated
during the hypothesis generation most MHT algorithms use data
association assumptions DA1a and DA2a.
• The M→T associations and the target states are assumed to evolve
independently over time.
• The MHT assumes that target states xt
n evolve independently over time,
i.e. the targets have independent dynamics.
• The M→T associations rt are assumed independent over time and
independent for diﬀerent measurements.
• Measurements are assumed conditionally independent when conditioned
on the collection of target states and data association variables.
• Measurements in the diﬀerent time steps are assumed independent.
Advantages
• The MHT is accepted as one of the preferred methods for solving the
data association problem in MTT systems (Blackman 2004).
• By maintaining diﬀerent hypotheses the MHT is able to discard
ambiguous data association decisions until ambiguity is resolved by more
measurement information.
• Even the basic MHT is able to handle an unknown and varying number
of targets.
• The MHT has been shown to be easy extensible (see Advances in MHT).
Disadvantages
• The MHT requires the enumeration of all legal association events. The
number of legal associations however grows exponentially with the
number of targets and measurements.
Additional assumptions (e.g.
DA1a and DA2a) or special techniques such as Murty’s algorithm are
needed to reduce the number of hypotheses. DA1a and DA2a make the
MHT unsuited for merged and multiple measurements respectively.

4.4 Algorithms for MTTL
109
• Since the MHT maintains multiple hypotheses and trackers along with
these hypotheses, special care has to be taken to limit the number of
associations being tracked. Therefore to limit computational time and
storage, the MHT must rely on a number of techniques such as gating,
clustering, hypothesis and track pruning, and track merging, to keep the
potential growth in check (Blackman 2004). Pruning and gating however
hold the risk of eliminating some correct hypotheses.
• The MHT requires more computational resources and storage than for
instance the JPDAF (Section 4.4.3) and the PMHT (Section 4.4.2) since
it maintains diﬀerent hypotheses, together with the trackers associated
with the targets in these hypotheses.
• A particular diﬃculty of the MHT is how to display the estimation results
online (Moore and Blair 2000). Displaying the most likely hypothesis
over time can be confusing, since the maximum likelihood hypothesis
can change considerably over one time step, both in the number of
targets and the state of these targets.
Therefore, it is preferable to
present a composite track picture containing combined data for the most
likely hypotheses.
Such compositions is however not straightforward
since the diﬀerent hypotheses can diﬀer a lot.
For instance, a simple
weighted average using the hypothesis probabilities determined during
the hypothesis evaluation step, only produces an acceptable result when
the most likely hypotheses are quite similar.
Basic MHT
The basic MHT uses a factorial representation of the ﬁltering distribution of
the joint target state P
 xt | y1:t
, where each factor is the marginal ﬁltering
distribution P
 xt
n | y1:t
corresponding to a single target and where each of the
marginals is approximated by a Gaussian:
P
 xt | y1:t
=
N t
Y
n=1
P
 xt
n | y1:t
≈
N t
Y
n=1
N
 xt
n|µt
n, Σt
n

,
(4.33)
with µt
n and Σt
n the expected value and the covariance of the nth target state,
respectively. Furthermore, the basic MHT assumes that (i) the process model
of each target is Gaussian, i.e.:
P
 xt
n | xt−1
n

=
N
 xt
n|¯µt
n, Qt
n

,
(4.34)
with ¯µt
n = fn
 µt−1
n

and fn the function describing the dynamics of the nth
target, and Qt
n the process model covariance, and that (ii) the measurement

110
Chapter 4
Overview and Classification of MTTL Algorithms
model is also Gaussian:
P
 yt
k | xt
n, rt
k = n

=
N
 yt
k|g(xt
n), Rt
,
(4.35)
with g the measurement function and Rt the measurement model covariance.
The Gaussian assumptions on the target states and the process model reduce
the target prediction to a simple Kalman ﬁlter prediction step, acting for each
target separately.
The Gaussian assumptions of the basic MHT furthermore simplify the hypoth-
esis evaluation by obtaining the following expression for P
 yt | Θt
h, y1:t−1
in
Equation (4.28):
P
 yt | Θt
h, y1:t−1
= V −(Mt
f+Mt
n)
Y
k:rt
k∈
1:N t−1
p(h)
	 N

yt
k|¯yt
rt
k, ¯St
rt
k

|
{z
}
existing target measurements
,
(4.36)
where ¯yt
rt
k = g

¯µt
rt
k

is the predicted measurement for the rt
kth target with
whom measurement yt
k is associated according to the current hypothesis and
¯Srt
k the associated covariance given by:
¯St
rt
k
=
G ¯Σ
t
rt
kGT + Rt,
(4.37)
with G the measurement model matrix, Rt the measurement noise covariance
matrix, and ¯Σ
t
rt
k the covariance of the predicted rt
kth target state.
Similar to the target prediction step, the Gaussian assumptions on the marginal
target state distributions and the measurement model, reduce the target
correction step of Equation (4.32) to a simple Kalman ﬁlter correction step,
acting for each target separately.
Assumptions, advantages and disadvantages basic MHT
On top of the
assumptions of the general MHT, the basic MHT:
• approximates the marginal ﬁltering distributions of each target by a
Gaussian (normal) distribution, by using an approximate and suﬃcient
statistic of the mean and covariance of each target estimate, and
• assumes linear Gaussian process and measurement models.

4.4 Algorithms for MTTL
111
By using a Gaussian approximation of the marginal ﬁltering distributions the
basic MHT is reduced to a bank of Kalman ﬁlters, one for each target in each
hypothesis, making it attractive from a computational point of view.
On top of the disadvantages of the general MHT, the basic MHT is limited to
linear Gaussian process and measurement models, due to the approximation of
the marginal ﬁltering distributions by Gaussians. While, extending the basic
MHT with extended Kalman ﬁlter-like equations enables it to handle nonlinear
models, its performance for strongly nonlinear systems is limited, especially
when these nonlinear models cause multimodal distributions.
Advances in MHT
This section lists some interesting extensions and applications of the MHT.
A lot of researchers have developed extensions for the MHT in order to relax
its assumptions. Koch and Van Keuk 1997 formulate the MHT for merged
measurements. The IMM-MHT combines the MHT with interacting multiple
models (IMM) in an eﬀort to relax the assumption of linear Gaussian dynamics
and instead using switching state space models.
The MHT has been applied to a variety of problems: the tracking of legs of a
walking person (Arras et al. 2008; Taylor and Kleeman 2004), the tracking of
targets with multiple features using geometric constraints (Arras et al. 2003),
the tracking of groups of targets (Lau et al. 2009), etc.
For further reading we advice the tutorial on MHT for multitarget tracking by
Blackman 2004.
4.4.2
Probabilistic Multihypothesis Tracker (PMHT)
As it name suggests the probabilistic multihypothesis tracker (PMHT) is a
probabilistic version of the MHT, which handles the data association in a
deterministic fashion.
The PMHT was originally proposed to reduce the
computational load with respect to the MHT (Streit and Luginbuhl 1995). To
this end the PMHT considers the associations to be statistically independent
random variables, this way circumventing an exhaustive enumeration of these
associations.
The original PMHT was the ﬁrst one to explicitly incorporate discrete data
association variables in the joint state. To this end the state to be estimated
contains besides the target states xt
n, the M→T association variables rt. Let
the data association probability ρt
n denote the probability that a measurement

112
Chapter 4
Overview and Classification of MTTL Algorithms
yt
k is assigned to target n at time step t, i.e.:
ρt
n
=
P
 rt
k = n

.
(4.38)
These probabilities are grouped into the data association probability vector as:
ρt
=

ρt
n
	
n=1:N .
(4.39)
As the above notation already suggested the distribution underlying the data
association probability vector ρt is assumed to be the same for all measurements
made at a certain time t.
The data association probabilities ρt
n take into
account the fact that individual targets can produce a diﬀerent number of
measurements at a certain time step (DA2b).
In the process model, the target states and data association variables are
assumed to evolve independently, and the data association variables are
furthermore assumed independent over time:
P
 xt, rt | xt−1, rt−1
=
P
 xt | xt−1
P
 rt
.
(4.40)
Additionally, individual targets and M→T associations are assumed to be
independent resulting in:
P
 xt, rt | xt−1, rt−1
=
N
Y
n=1
P
 xt
n | xt−1
n
 Kt
Y
k=1
ρt
n|n=rt
k.
(4.41)
In the measurement model, the measurements yt are assumed to be condition-
ally independent given the target states and data association variables:
P
 yt | xt, rt
=
Kt
Y
k=1
P
 yt
k | xt
n

|n=rt
k =
Kt
Y
k=1
P

yt
k | xt
rt
k

.
(4.42)
Figure 4.2 presents the Bayesian network of the PMHT representing all
above conditional independence assumptions in a graphical manner.
These
independence assumptions are also represented by the following factorization
of the joint pdf over the target states, measurements, and M→T associations
at a time step t:
P
 yt, xt, rt | xt−1, rt−1
=
N
Y
n=1
P
 xt
n | xt−1
n
 Kt
Y
k=1
ρt
nP
 yt
k | xt
n

|n=rt
k.
(4.43)

4.4 Algorithms for MTTL
113
...
...
yt−1
k
yt
k
yt+1
k
rt−1
k
rt
k
rt+1
k
Kt−1
Kt
Kt+1
N
xt−1
n
xt
n
xt+1
n
ρt−1
ρt
ρt+1
Figure 4.2:
Bayesian network model for the probabilistic multihyptothesis
tracker (PMHT). The boxes (plates) denote a set of Kt−1, Kt and Kt+1
measurements and a set of N targets. The shaded nodes are observed.
The PMHT is a batch algorithm in which the batch joint pdf, grouping all target
states, measurements and M→T associations over all time steps, is essential:
P
 y1:T , x1:T , r1:T 
=
( N
Y
n=1
P
 x0
n

) T
Y
t=1
( N
Y
n=1

P
 xt
n | xt−1
n

Kt
Y
k=1
h
ρt
nP
 yt
k | xt
n

|n=rt
k
i


,
(4.44)
with P
 x0
n

the a priori pdf of the target states. Another important algebraic
entity is the marginal distribution of the batch joint pdf over the discrete

114
Chapter 4
Overview and Classification of MTTL Algorithms
component M→T associations r:
P
 y1:T , x1:T 
=
X
r1:T
P
 y1:T , x1:T , r1:T 
=
( N
Y
n=1
P
 x0
n

) T
Y
t=1
( N
Y
n=1

P
 xt
n | xt−1
n

Kt
Y
k=1
" N
X
n=1
ρt
nP
 yt
k | xt
n

#

.
(4.45)
This equation provides the useful insight that the components of the data
association vector ρt
n can be interpreted as the mixing proportions of a
measurement pdf mixture, where each component corresponds to a single
target, from which the measurements y are drawn:
yt
k
∼
N
X
n=1
ρt
nP
 yt
k | xt
n

.
(4.46)
The PMHT tries to optimize the posterior probability of the target states x1:T
given the measurements y1:T :
 x1:T ∗
=
argmax
x1:T
log P
 x1:T | y1:T 
(4.47)
=
argmax
x1:T
log
X
r1:T
P
 x1:T , r1:T , y1:T 
.
(4.48)
As can be seen in the above equation optimizing the posterior probability of the
target states is equivalent to optimizing the batch joint pdf of Equation (4.44)
marginalized over the data association variables r1:T . For this optimization the
PMHT uses an EM-approach where the M→T association variables r1:T are the
‘missing data’ in the EM nomenclature, while the ‘complete data’ consists of
y1:T , x1:T and r1:T . Here, the most important equations of the EM algorithm
are summarized. A detailed derivation of the PMHT algorithm is available
in (Streit and Luginbuhl 1995). The E-step evaluates the expectation of the
logarithm of the batch joint pdf of Equation (4.44) where the expectation is

4.4 Algorithms for MTTL
115
with respect to the conditional pdf P
 r1:T | y1:T , x1:T
old , ρ1:T
old

:
Q
≜
Q
 x1:T , ρ1:T | x1:T
old , ρ1:T
old

(4.49)
=
Er1:T

log P
 y1:T , x1:T , r1:T | ρ1:T 
(4.50)
=
X
r1:T
log P
 y1:T , x1:T , r1:T 
P
 r1:T | y1:T , x1:T
old , ρ1:T
old

.
(4.51)
The conditional pdf of the data association variables given the measurements,
target states and the data association probabilities is given by:
P
 r1:T | y1:T , x1:T
old , ρ1:T
old

=
T
Y
t=1
Kt
Y
k=1
wt
kn|n=rt
k,
(4.52)
where wt
kn, also called responsabilities, are interpreted as the conditional
probability that measurement yt
k is assigned to target n given the target states
x1:T and the measurements y1:T :
wt
kn
=
P
 rt
k = n | x1:T , y1:T 
(4.53)
=
ρt
nP(yt
k | xt
n)
PN
nc=1 ρtncP(yt
k | xtnc)
.
(4.54)
When substituting Equations (4.52)-(4.53), the expectation of Equation (4.51)
can be rewritten as:
Q
 x1:T , ρ1:T | x1:T
old , ρ1:T
old

=
T
X
t=1
Qt,ρ +
N
X
n=1
Qn,x,
(4.55)

116
Chapter 4
Overview and Classification of MTTL Algorithms
with
Qt,ρ
=
Qt,ρ
 ρt | y1:T , xt
old, ρt
old

(4.56)
=
Kt
X
k=1
N
X
n=1
wt
kn,old log ρt
n, and
(4.57)
Qn,x
=
Qn,x
 x1:T
n
| y1:T , x1:T
n,old, ρ1:T
n,old

(4.58)
=
log P
 x0
n

+
T
X
t=1


log P
 xt
n | xt−1
n

+
Kt
X
k=1
wt
kn,old log P
 yt
k | xt
n



.
(4.59)
In the M-step the expectation of Equation (4.55) is maximized to obtain new
values for the target states x1:T and data association probabilities ρ1:T :
Q
 x1:T , ρ1:T ∗| x1:T
old , ρ1:T
old

≜
max
x1:T ,ρ1:T Q
 x1:T , ρ1:T | x1:T
old , ρ1:T
old

.(4.60)
From Equation (4.55) it can be seen that this maximization decouples into a
maximization problem for each of the T data association probability vectors
ρt and a maximization problem for each of the N target state sequences x1:T
n .
The optimal data association probability vectors are given by:
 ρt
n
∗
=
1
Kt
Kt
X
k=1
wt
kn,old,
(4.61)
while the optimal target states
 x1:T
n
∗are conceptually equivalent to the
outcome of a single-target maximum a posteriori (MAP) tracker. The optimal
target state sequences are therefore the outcome of a bank of MAP trackers,
one for each target. These trackers are not independent since they are linked
via the data association probability vectors ρt
n (or the responsabilities wt
kn).
Gaussian case
In general, the computation of
 x1:T
n
∗requires an iterative numerical
procedure. In the special case of Gaussian process and measurement models

4.4 Algorithms for MTTL
117
...
...
eyt−1
n
eyt−1
n
eyt+1
n
N
xt−1
n
xt
n
xt+1
n
Figure
4.3:
Simpliﬁed
Bayesian
network
model
for
the
probabilistic
multihypothesis tracker (PMHT). The PMHT is equivalent to a bank of
Kalman smoothers with synthetic measurements eyt
n. The box (plate) denotes
a set of N targets. The shaded nodes are observed.
however, the optimal target state sequences are proved to be the outcome
of a bank of (extended) Kalman smoothers (Streit and Luginbuhl 1995), one
for each target.
The process model of each Kalman smoother is equal to
the process model of the corresponding target, while the measurement step
processes synthetic measurements eyt
n. The synthetic measurement eyt
n applied
to the smoother of target n, is a weighted average of the measurements yt:
eyt
n
=
PKt
k=1 wt
kn,oldyt
k
PKt
k=1 wt
kn,old
.
(4.62)
As such, the smoother attached to each target n associates all measurements
yt with the target n (soft assignment) according to the probability that the
measurement is caused by target n: wt
kn,old. The measurement noise associated
with this synthetic measurement is:
eRt
=
Rt
PKt
k=1 wt
kn,old
,
(4.63)
with Rt the covariance of the Gaussian measurement model. Figure 4.3 shows
the Bayesian network representation of the PMHT interpretation as a bank
of MAP target state estimators.
This simpliﬁed graphical representation is
possible since the complexity of the data association is in the construction of
synthetic measurements eyt
n.

118
Chapter 4
Overview and Classification of MTTL Algorithms
Assumptions
• The PMHT assumes that the number of targets N is ﬁxed and known.
• Since the PMHT uses M→T associations for modeling the data associa-
tion, the data association assumption DA1a is implicitly made: i.e one
measurement can only originate from one target. In the original PMHT
no false measurements, i.e. measurements due to clutter, are taken into
account.
• The PMHT can handle targets producing zero or several measurements
at time (DA2b). The fact that a target can produce more measurements
is modeled with the data association probability vector ρt = {ρt
n}n=1:N,
which is also estimated by the PMHT.
• The M→T associations and the target states are assumed to evolve
independently over time.
• The PMHT assumes that the target states xt
n evolve independently over
time, i.e. that the targets have independent dynamics.
• M→T associations rt are assumed independent over time and indepen-
dent for diﬀerent measurements.
• Measurements are assumed conditionally independent when conditioned
on the collection of target states and data association variables.
• Measurements in the diﬀerent time steps are assumed independent.
Advantages
The PMHT is a fully Bayesian and theoretical elegant multitarget tracking
algorithm.
The PMHT is ﬂexible and extensible.
The PMHT algorithm
requires neither enumeration of M→T assignments nor pruning because all
measurements are assigned to all tracks. A measurement is weighted with the
estimated M→T probability before it is assigned to a target (soft assignment).
Because pruning is not required, the PMHT algorithm is an optimal empirical
Bayesian multitarget tracking algorithm under idealized assumptions.
The
computational cost of the PMHT is linear in all parameters: the number of
time steps T , the number of measurements Kt and the number of targets N.
Disadvantages
Despite its theoretical attractiveness, the performance of the PMHT is often
disappointing (Willett et al.
2002).
Below, the main disadvantages and

4.4 Algorithms for MTTL
119
problems of the PMHT are listed.
Willett et al.
2002 provide a detailed
overview of some problems. The terminology used below is mainly based on
this overview.
• The main limitation of the PMHT is the assumption that the number of
targets is constant and known in advance.
• The PMHT is a batch algorithm. The PMHT can however be formulated
as a sliding-window algorithm.
• The PMHT is an iterative algorithm (EM) and provides no guarantees for
convergence to the global optimum. Care has to be taken when to stop
the iterations: (i) after a ﬁxed number of times, or (ii) after reaching
a convergence measure (examination of the current likelihood function
or monitoring diﬀerence between iterated track estimates (Willett et al.
2002)).
• The basic PMHT requires linear models to be eﬃcient, therefore
the linearization of nonlinear models is required for its practical
implementation (Efe and Willet 2004). Gauvrit et al. 1997 propose to
combine the PMHT with a Gauss-Newton algorithm to handle nonlinear
measurement equations.
Despite the ability to extend te PMHT for
nonlinear process and measurement models its performance for strongly
nonlinear systems is limited, especially when these nonlinear models cause
multimodal distributions.
• The basic PMHT does not handle false measurements (clutter).
The
PMHT can however be extended to handle clutter (Hutchins and Dunham
1998; Davey 2003), e.g. by adding a false alarm target, which role is to
absorb measurements that are with a high probability clutter-generated
(Willett et al. 2002).
• The PMHT does not have a quality measure for the tracking performance
of diﬀerent tracks.
• The problem of non-adaptivity (Willett et al. 2002) refers to the fact
the probability of a measurement to be generated by a target wt
kn is
independent of the uncertainty on the target estimate. This is most clear
when a single target is occluded and does not produce any measurements
for some time.
In this case the uncertainty on the target estimate
increases but in the PMHT the probability of measurements to be
incorporated by that target does not increase.
Therefore, the PMHT
is to a large extent incapable of rescuing itself from a currently poor
target estimate.

120
Chapter 4
Overview and Classification of MTTL Algorithms
• The problem of narcissism (Willett et al. 2002) refers to the willingness
of the PMHT to believe the track is progressing normally, even if there
is a lot of evidence to the contrary. Even a single false alarm near an
incorrect track estimate is satisfactory for the PMHT, and the lack of
satisfactory validated measurements does not faze it.
• The problem of hospitality (Willett et al. 2002) refers to the fact that
the PMHT accepts multiple measurements for a single target (see DA2b),
even if the measurement information is not consistent. The PMHT fails
to recognize the fact if there are many measurements associated with
a target that possibly some of these measurements are false alarms or
originate from other targets.
Advances in PMHT
The theoretical attractiveness of the PMHT has motivated a lot of researchers
to extend or adapt the PMHT to relieve its well-known problems.
This
paper does not aim at giving a detailed list but rather refers to the paper of
Willett et al. 2002 where the homothetic PMHT, the spirograph PMHT, the
adaptive homethetic PMHT, the PMHT with PDAF measurement model, the
detection-oriented PMHT, the maneuvering PMHT, the maneuvering/home-
thetic PMHT, the joint manoeuver/homethetic PMHT, the deﬂationary PMHT
and the homoscedastic PMHT are evaluated and compared by the way they
handle the non-adaptivity, narcissism and hospitality problems of the PMHT.
Eﬀorts towards combining the interacting multiple model (IMM) algorithm for
switching state space models with the PMHT are described by Zaveri et al.
2007.
Another, even more important research topic is the extension of the PMHT
towards localization: i.e. track initiation and termination and the track quality
measure needed in this process; (i) Luginbuhl et al.
2001 propose a track
management system based on a test function for track candidates; (ii) Davey
2003 develops and compares automatic track initiation schemes, which are also
used to reject superﬂuous targets; (iii) Musicki and Wang 2007 accommodate
the PMHT for a variable number of tracks by adding the probability of track
existence to the PMHT, and modeling the target existence as a Markov Chain;
(iv) Davey and Gray 2007 propose a PMHT with a hysteresis model for track
maintenance, which incorporates a hyperparameter in the data association
process quantifying the signiﬁcance of the mixture component associated with
the track; and (v) Wieneke and Koch 2008 integrate a sequential likelihood-
ratio test into the PMHT to allow for track management.

4.4 Algorithms for MTTL
121
Another work worth mentioning is the use of the PMHT for feature-based
simultaneous localization and map building (SLAM) by Davey 2007.
4.4.3
Joint Probabilistic Data Association Filter (JPDAF)
To circumvent the exponential growth of the state space with the number of
targets, the joint probabilistic data association ﬁlter (JPDAF) uses a factorial
representation of the ﬁltering distribution of the joint state P
 xt | y1:t
in which
an individual tracker is assigned to each target. As such, the JPDAF combats
the curse of dimensionality by recursively updating the marginal ﬁltering
distributions, P
 xt
n | y1:t
, of each of the targets.
These marginal ﬁltering
distributions are updated using Bayesian sequential estimation recursions
consisting of a prediction and correction step. By assuming independent target
dynamics:
P
 xt | xt−1
=
Y
n=1:N
P
 xt
n | xt−1
n

,
(4.64)
the prediction step can proceed independently for each target:
P
 xt
n | y1:t−1
=
Z
P
 xt
n | xt−1
n

P
 xt−1
n
| y1:t−1
dxt−1
n
.
(4.65)
In the correction or ﬁltering step, the measurement information of time step t
in incorporated into the target estimate:
P
 xt | y1:t
∝
P
 yt | xt
P
 xt | y1:t−1
.
(4.66)
Due to the data association uncertainty however, this correction step cannot
be executed independently for each target.
The JPDAF circumvents this
problem by using a JPDA strategy (Section 4.2.2.4), which tackles uncertain
data association conditions by updating the marginal ﬁltering distributions of
each target with a weighted set of the measurements. The weights represent the
posterior probability that the measurement originates from that target. Such
a soft assignment strategy can be seen as a marginalization over the uncertain
data association variables and results in the deﬁnition of the likelihood of each
target as a mixture:
P
 yt | xt
n

=
K
X
k=1
ct
knP
 yt
k | xt
n

,
(4.67)

122
Chapter 4
Overview and Classification of MTTL Algorithms
with ct
kn = P
 rt
k = n | y1:t
. In this mixture, there is one mixture component
for each possible M→T association, and the mixture weights are equal to the
posterior probabilities of the corresponding association:
i.e.
the posterior
probability that measurement yt
k is caused by target n. More formally, the
correction step for target n is rewritten as:
P
 xt
n | y1:t
∝
K
X
k=1
ct
knP
 yt
k | xt
n

P
 xt
n | y1:t−1
.
(4.68)
To complete the correction step, the JPDAF has to compute at each time
step t, the probabilities ct
kn.
To this end the JPDAF treats the data
associations as events: a joint association event θt contains M→T associations
uniquely determining which measurement is assigned to which target:
i.e.
θt = {rt
k}k=1:Kt. The probabilities ct
kn can be expressed using these events
as:
ct
kn
≜
X
θt∈Θt
kn
P
 θt | y1:t
,
(4.69)
with Θt
kn denoting the set of all joint association events θt that assign
measurement yt
k to target n: i.e. Θt
kn = {θt : rt
k = n ∈θt}. Under the Markov
assumption, the probability of a single joint association event can be written
as:
P
 θt | y1:t
=
Z
P
 θt, xt | yt, y1:t−1
dxt
(4.70)
=
Z
P
 θt | xt, yt, y1:t−1
P
 xt | yt, y1:t−1
dxt
(4.71)
=
Z
P
 θt | xt, yt
P
 xt | yt, y1:t−1
dxt.
(4.72)
The above equation reveals a ‘chicken and egg’ problem. To determine the
joint association events θt, the target states xt have to be known, while the
data associations θt have to be known to estimate the target states xt with
the correction step in Equation (4.68). Instead of estimating joint association
events θt and the target states xt jointly, the JPDAF uses an approximation to
circumvent the ‘chicken and egg’ problem. To this end the P
 xt | yt, y1:t−1
is
approximated by P
 xt | y1:t−1
. As a consequence, the state of the targets used
for estimating the joint association event θt is approximated by the prediction
of the target state given all measurement information up to time step t −1.

4.4 Algorithms for MTTL
123
This approximation and Bayes’ rule reduce Equation (4.72) to:
P
 θt | y1:t
≈
Z
P
 θt | xt, yt
P
 xt | y1:t−1
dxt
(4.73)
∝
Z
P
 θt | xt
P
 yt | θt, xt
P
 xt | y1:t−1
dxt.
(4.74)
The normalizer of the last equation can be determined by ensuring that
P
 θt | y1:t
is normalized. Each of the factors in Equation (4.74) denotes a
probability distribution with a physical interpretation:
• The factor P(θt | xt) represents the probability of the association θt
given the current state of the targets. In a lot of situations a valuable
assumption is to assume that all assignments have the same likelihood
given the target states, i.e. P(θt | xt) = Cte (Schulz et al. 2003). Another
possibility is to take into account the probability distributions of clutter
measurements (Cox 1993):
P
 θt | xt
=
M t
f!
Kt! P
 M t
f
 N t
Y
n=1
 P t
det,n
1t
n  1 −P t
det,n
1−1t
n ,
(4.75)
with M t
f the number of false alarms in the association event θt, and
P

M t
f

the prior probability mass function of the number of false
measurements, P t
det,n the probability of observing target n at time step
t, and 1t
n the indicator variable deﬁned by:
1t
n
≜
(
1
if target n is observed at time step t
0
otherwise.
(4.76)
There are two main versions of the JPDA depending on the assumed
model for the false alarms P

M t
f

(Cox 1993). The parametric JPDA
assumes a Poisson distribution with parameter value λ, P

M t
f

=
λ
Mt
f
Mt
f ! while the nonparametric JPDA assumes a uniform distribution,
P

M t
f

= Cte.
• The factor P(yt | θt, xt) denotes the probability of obtaining the mea-
surements yt given the target states xt and the associations θt between
the measurements and targets. To obtain P(yt | θt, xt) a distinction is
made between measurements originating from targets and clutter. The

124
Chapter 4
Overview and Classification of MTTL Algorithms
joint association event contains a set of Mf false alarms, while the other
Kt −Mf measurements are assumed to originate from a single target.
Assuming that the measurements are detected independently of each
other the factor is rewritten as (see also Equation (4.6)):
P
 yt | θt, xt
=
Y
k:rt
k=0∈θt
PC
 yt
k

Y
k:rt
k∈{1:N t}
P

yt
k | xt
rt
k

.(4.77)
By assuming that the false measurements are uniformly distributed over
the observation volume V t as in Equation (4.8), the above equation
reduces to:
P
 yt | θt, xt
=
V −Mf
Y
k:rt
k∈{1:N t}
P

yt
k | xt
rt
k

.
(4.78)
• The factor P
 xt | y1:t−1
denotes the probability of the target states at
time step t given all measurement information up to time step t −1 and
can be obtained from the prediction step in Equation (4.65).
Substitution of all factors in Equation (4.74) and inserting the result in
Equation (4.69) gives:
ct
kn ∝
X
θt∈Θt
kn

V −Mt
f
Y
k:rt
k∈{1:N t}
Z
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k

, (4.79)
when assuming that P(θ | xt) = Cte, and:
ct
kn ∝
X
θt∈Θt
kn

V −Mt
f M t
f!
K! P(Mf)
N t
Y
n=1
 P t
det,n
1t
n  1 −P t
det,n
1−1t
n
Y
k:rt
k∈{1:N t}
Z
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k

,
(4.80)
when using the approximation of Equation (4.75) for P(θ | xt) with Poisson
distributed M t
n and M t
f.
Evaluating the probability of Equation (4.79) or
Equation (4.80) requires enumerating all Θt
kn, i.e.
all possible associations
events θt assigning measurement yt
k to target n. This becomes intractable for
a large number of targets and measurements as explained in Section 4.2.2.4. To
limit the number of possible associations, gating and Murty’s algorithm can be

4.4 Algorithms for MTTL
125
applied (Section 4.2.2.1). Equation (4.79) and Equation (4.80) can be written
more compactly by recognizing that the integral in these equations represents
the predictive likelihood for measurement yt
k using the predicted information
of target n:
P
 yt
k | y1:t−1, rt
k = n

=
Z
P

yt
k | xt
rt
k

P

xt
rt
k | y1:t−1
dxt
rt
k. (4.81)
Using the above expression, Equation (4.79) and Equation (4.80) reduce to:
ct
kn
∝
X
θt∈Θkn

V −Mt
f
Y
k:rt
k∈{1:N t}
P
 yt
k | y1:t−1, rt
k = n


,
(4.82)
and
ct
kn ∝
X
θt∈Θkn

V −Mt
f M t
f!
K! P(Mf)
N t
Y
n=1
 P t
det,n
1t
n  1 −P t
det,n
1−1t
n
Y
k:rt
k∈{1:N t}
P
 yt
k | y1:t−1, rt
k = n


,
(4.83)
respectively.
Figure 4.4 shows the Bayesian network representing all conditional indepen-
dence assumptions graphically. Although the discrete association variables rt
were not used in the original JPDAF formulation, they are included here in
the Bayesian network representation to stress some implicit assumptions and
to compare the JPDAF with other MTTL algorithms. In the JPDAF it is
implicitly assumed that the joint association events θt containing all M→T
associations (θt = {rt
k}k=1:Kt) are independent over time, implying that the
M→T associations rt themselves are independent over time. Furthermore it is
implicitly assumed that each measurement yt
k has the same a priori probability
to be caused by any of the targets, i.e.:
ρt
n = P
 rt
k

= 1
N .
(4.84)
Since the number of targets N is assumed to be known and ﬁxed the data
association probability vector ρt is also assumed to be known and as such
indicated as a parameter rather than a variable in the Bayesian network.

126
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
yt−1
k
yt
k
yt+1
k
rt−1
k
rt
k
rt+1
k
Kt−1
Kt
Kt+1
N
xt−1
n
xt
n
xt+1
n
ρt−1
ρt
ρt+1
Figure 4.4: Underlying Bayesian network model for joint probabilistic data
association ﬁlter (JPDAF). The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements and a set of N targets. The shaded nodes are observed.
Assumptions
• The JPDAF assumes that the number of targets N is ﬁxed and known and
that all target tracks are initialized (i.e. only tracking, no localization).
• The JPDAF assumes that the joint probability of the target states
P
 xt | y1:t
factorizes, where the factors, P
 xt
n | y1:t
, are the marginal
distributions of the target states.
• Since the JPDAF uses M→T associations for modeling the data
association, the data association assumption DA1a is implicitly made:
i.e one measurement can only originate from one target.
• To limit the number of legal associations that have to be enumerated to
calculate the probabilities ct
kn in Equations (4.79) and (4.80), the JPDAF
uses data association assumptions DA1a and DA2a.
• The M→T associations and the target states are assumed to evolve
independently over time.
• The JPDAF assumes that the target states xt
n evolve independently over
time, i.e. that the targets have independent dynamics.

4.4 Algorithms for MTTL
127
• M→T associations, rt, are assumed independent over time and indepen-
dent for diﬀerent measurements.
• Measurements are assumed conditionally independent when conditioned
on the collection of target states and data association variables.
Advantages
• The JPDAF is a simple and recursive algorithm.
• The JPDAF is based on a Bayesian data association paradigm.
• In contrast to the MHT and similar to the PMHT, the JPDAF
does not need to maintain diﬀerent hypotheses, reducing the need for
computational power and storage.
Disadvantages
• The principal limitation of the JPDA is its inability to perform track
initiation and deletion since it assumes that the number of targets to be
tracked is ﬁxed and known (Cox 1993).
• The JPDAF is only an approximate solution to the MTTL problem as
a number of independence assumptions and an approximation (chicken
and egg problem) are made to perform both the ﬁltering operations and
the calculation of the data association probabilities (Equation 4.73).
• The JPDAF requires the enumeration of all joint association hypotheses
(Equation 4.69). This number of joint association hypotheses however
grows exponentially with the number of targets and measurements.
Additional assumptions (e.g. DA1a and DA2a) or special techniques such
as Murty’s algorithm are needed to reduce the number of hypotheses.
DA1a and DA2a make the JPDAF unsuited for merged and multiple
measurements respectively.
• An important problem of the JPDAF is known as track coalesence (Blom
and Bloem 2000). If two target are close together, their measurement
associations probabilities will be similar and they will pick up the same
measurement information during the data association.
Updating the
targets with the same measurement information makes them even more
similar, etc. resulting in a coalescence of the two diﬀerent target tracks
into a single track.

128
Chapter 4
Overview and Classification of MTTL Algorithms
Comparison between JPDAF and PMHT
When looking at the Bayesian network representations of the JPDAF in
Figure 4.4 and the PMHT in Figure 4.2, the similarity is striking.
There
exists however, a fundamental diﬀerence between the JPDAF and the PMHT
not shown in the Bayesian network: the JPDAF is a sequential algorithm,
while the PMHT is a batch algorithm. Therefore, the resemblance between the
algorithms is closest for a unit batch of size T = 1 (Streit and Luginbuhl 1995).
The similarity between the JPDAF and PMHT comes from the common
assumption that the measurements yt originate from a mixture, where each
mixture component corresponds to one target2, and where the mixture weights
represent the a priori probability that a measurement originates from that
target:
N
X
n=1
ρt
nP
 yt | xt
n

.
(4.85)
There are however two important diﬀerences between the JPDAF and PMHT in
the way they construct this mixture. The ﬁrst diﬀerence is due to the mixture
weights ρt. The PMHT explicitly models the fact that measurements do not
have the same a priori probability to originate from each of the targets. This
non-uniform assumption for ρt models the fact that each target can produce
multiple, and a diﬀerent number of, measurements at each time step (DA2b).
The recursive EM procedure in the PMHT provides ML estimates of the data
association probability vector, ρt, and hence ρt are indicated as variables in
the Bayesian network in Figure 4.2. The JPDAF however, assumes that each
measurement has the same a priori probability to be caused by any of the
targets, resulting in a uniform distribution of the data association probabilities,
see Equation (4.84).
This uniform distribution originally comes from the
assumption that each target can only generate at most one measurement at
a certain time (DA2a). The uniformity assumption would also hold if, at every
time step, it is assumed that the number of measurements each target produces
is unknown. The data association probability vector ρt is therefore a parameter
in the JPDAF and hence indicated as such in the JPDAF Bayesian network in
Figure 4.4. The second diﬀerence is due to the mixture components. Besides
the ML estimates of the mixture weights, the recursive EM procedure of the
PMHT also provides ML estimates of the target states xt.
Therefore, the
conditional probability P(yt | xt
n) in Equation (4.85) is conditioned on the ML
estimates of the target states. Due to its sequential nature however, the JPDAF
cannot use the ML estimates of the target states. Therefore, the predictions
for the target positions at time step t given all measurements up to timestep
2Clutter measurements are not considered in this discussion.

4.4 Algorithms for MTTL
129
t −1, i.e. the target states according to P
 xt
n | y1:t−1
are used in P(yt | xt
n)
of Equation (4.85). (For this approximation also check the derivation around
Equation (4.72) and the explanation of the ‘chicken and egg’ problem).
The above similarity between the JPDAF and the PMHT can also be discovered
by studying the likelihood P(yt | xt
n) for the nth target. The fact that both
the JPDAF and the PMHT handle the uncertain data association by a soft
assignment strategy, i.e. by updating the marginal ﬁltering distribution of each
target by a weighted set of measurements, is reﬂected by the interpretation of
the likelihood P(yt | xt
n) as a mixture.
The JPDAF explicitly models this
likelihood as a mixture as can seen in Equation (4.67). The mixture weights
ct
kn represent the posterior probability that the measurement yt
k originates
from target n.
Due to the ‘chicken and egg problem’ (estimating the data
association variables ck,n requires the target states xt
n, while estimating the
target states xt
n requires the data association variables ct
kn) the mixture weights
are approximated by using the predictions for the target states at time step t
given all measurements up to time step t −1, i.e. the target states according
to P
 xt
n | y1:t−1
, instead of the target states incorporating all measurement
information up to time t. For the PMHT however, the interpretation of the
likelihood P(yt | xt
n) as a mixture arises during the EM procedure as can be
seen in Equation (4.59).
The mixture weights wt
kn represent the posterior
probability that the measurement yt
k originates from target n (4.53) and are
therefore similar to the ct
kn in the JPDAF. In contrast to ct
kn in the JPDAF
however, wt
kn are ML estimates obtained after convergence of the EM procedure
and are therefore based on the ML estimates of the target states rather than
on predictions.
Basic JPDAF
The original formulation of the JPDAF (Fortmann et al. 1983), here referred to
as the basic JPDAF, uses a factorial representation of the ﬁltering distribution
of the joint target states P
 xt | y1:t
where each of the factors is the marginal
ﬁltering distribution, P
 xt
n | y1:t
, corresponding to a single target.
The
marginal ﬁltering distribution of a target P
 xt
n | y1:t
is approximated by a
Gaussian using the suﬃcient statistic of the mean and covariance, i.e.:
P
 xt
n | y1:t
≈
N
 xn|µt
n, Σt
n

,
(4.86)
with µt
n the expected value of target state n and Σt
n the target state covariance.
The basic JPDAF furthermore approximates the association probabilities in
Equation (4.70) with Gaussians.

130
Chapter 4
Overview and Classification of MTTL Algorithms
By using a Gaussian approximation for the underlying distributions in the
MTT, the basic JPDAF obtains recursive update equations similar to the basic
Kalman ﬁlter algorithm. The prediction step of Equation (4.65), proceeding
independently for each target, reduces to a simple Kalman ﬁlter prediction step
if the target process model is also assumed to be Gaussian:
P
 xt
n | xt−1
n

= N
 xt
n|¯µt
n, Qt
n

,
(4.87)
with ¯µt
n = fn
 µt−1
n

and fn the function describing the dynamics of the nth
target, and Qt
n the process model covariance. Using the predicted target states
distributed according to N
 xt
n|¯µt
n, ¯Σt
n

and assuming that the measurement
model P

yt
k | ¯xt,(i)
n

is Gaussian:
P
 yt
k | xt
n, rt
k = n

= N
 yt
k|g
 xt
n

, Rt
,
(4.88)
with g the measurement function and Rt the measurement model covariance,
the predictive likelihood of Equation (4.81) can be approximated as:
P
 yt
k | y1:t−1, rt
k = n

≈
Z
N

yt
k | g

xt
rt
k

, Rt
N

xrt
k|¯µt
rt
k, ¯Σt
rt
k

dxt
rt
k,
(4.89)
=
N

yt
k|¯yt
rt
k, ¯St
rt
k

,
(4.90)
where ¯yt
rt
k = g

¯µt
rt
k

is the predicted measurement for the rt
kth target with
whom measurement yt
k is associated according to the current hypothesis, and
¯St
rt
k is the associated covariance given by:
¯St
rt
k
=
G ¯Σ
t
rt
kGT + Rt,
(4.91)
with G the measurement model matrix, and ¯Σ
t
rt
k the covariance of the predicted
rt
kth target state. (Remark the resemblance with the hypothesis evaluation in
the basic MHT of Equation (4.36)).
The above approximation of the predictive likelihood can be directly sub-
stituted in Equation (4.82) or Equation (4.83) to obtain a Gaussian-based
approximation of the data association probabilities ct
kn.
After calculating the data association probabilities ct
kn, the correction step
of Equation (4.68) for the individual target trackers can be rewritten as a

4.4 Algorithms for MTTL
131
simple Kalman Filter correction with an adapted innovation. This adapted
innovation, νt
n, applied to the tracker of target n, reﬂects that JPDA associates
all measurements with the nth target according to the probability that the
measurement is caused by that target:
νt
n
=
Kt
X
k=1
ct
kn
 yt
k −¯yt
n

,
(4.92)
with ¯yt
n = g
 ¯µt
n

. The interpretation of the basic JPDAF as a bank of Kalman
ﬁlters is illustrated by the Bayesian network representation in Figure 4.5. In
this ﬁgure the synthetic measurements eyt
n are deﬁned as:
eyt
n
=
Kt
X
k=1
ct
knyt
k,
(4.93)
obeying the following implicit measurement model:
0
=
eyt
n −g
 xt
n
 Kt
X
k=1
ct
kn.
(4.94)
Assumptions, advantages and disadvantages basic JPDAF
On top of the
assumptions of the general JPDAF, the basic JPDAF:
• approximates the marginal ﬁltering distributions of each target by a
Gaussian (normal) distribution, by using an approximate and suﬃcient
statistic of the mean and covariance of each target estimate, and
• assumes linear Gaussian process and measurement models.
The Gaussian approximations of the marginal ﬁltering distributions, the
process and measurement model, reduce the basic JPDAF to a bank of Kalman
ﬁlters, making it attractive from a computational point of view.
On top of the disadvantages of the general JDPAF, the basic JPDAF is limited
to linear Gaussian process and measurement models, due to the approximation
of the marginal ﬁltering distributions by Gaussians.
While, extending the
basic JPDAF with extended Kalman ﬁlter-like equations enables it to handle
nonlinear models, its performance for strongly nonlinear systems is limited,
especially when these nonlinear models cause multimodal distributions.

132
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
eyt−1
n
eyt−1
n
eyt+1
n
N
xt−1
n
xt
n
xt+1
n
Figure 4.5: Simpliﬁed Bayesian network model for the joint probabilistic data
association ﬁlter (JPDAF). The JPDAF is equivalent to a bank of Kalman
ﬁlters with synthetic measurements. The box (plate) denote a set of N targets.
The shaded nodes are observed.
Comparision between basic JPDAF and PMHT for the Gaussian case
The
resemblance between the JPDAF and the PMHT as discussed in Section 4.4.3
is even more remarkable when studying the Gaussian case. In the Gaussian
case both the process and measurement model are assumed to be Gaussian.
Remember that for the Gaussian case the PMHT reduces to a bank of Kalman
smoothers (Figure 4.3), while the basic JPDAF reduces to a bank of Kalman
ﬁlters (Figure 4.5). The reduction of the PMHT to a bank of smoothers versus
the reduction of the basic JPDAF to a bank of ﬁlters is due the batch and
sequential nature of the PMHT and the JPDAF respectively. The PMHT uses
a convex combination eyt
n of the measurements yt to update target n (4.62).
The JPDAF however uses a convex combination of innovations νt
n to update
target n (4.92). The convex combination of the PMHT, a weighted average
of measurements yt
k, occurs in the measurement space; while the convex
combination of the JPDAF, a weighted average of the innovations νt
n, occurs
in the state space.
This diﬀerence is due the diﬀerence in the handling of
the M→T assignments (Streit and Luginbuhl 1995): the PMHT incorporates
assignments in the observer while the JPDAF treats assignments as events.
JPDAF variants avoiding track coalescence
A lot of researchers have developed methods to improve the important
shortcoming of the JPDAF concerning track coalescence.
One of the
ﬁrst, and most known algorithms is the Exact Nearest Neighbor JPDAF
(ENNJPDAF) (Fitzgerald 1990). The ENNPDA uses the weight evaluation
and subsequently prunes all Gaussians from the conditional density, except
the joint association hypothesis that has the heighest weight. The ENNPDA

4.4 Algorithms for MTTL
133
approach is remarkably insensitive to track coalescence in case of low clutter
and few missed detections. The dramatic pruning used for ENNPDA, however,
leads to an higher sensitivity to clutter and missed detections (Blom and Bloem
2000). Other extensions of the JPDAF to handle track coalescence include the
cheap JPDAF (CJPDAF) (Hoﬀmann and Dang 2006), the IMMJPDAF* (Blom
and Bloem 2002), and the JPDA coupled (JPDACF) ﬁlter (Shertukde and
Bar-Shalom 1991). Blom and Bloem 2000 propose the Coupled probabilistic
data association* (CPDA*) and the JPDA* (the * is short for track-coalescence-
avoiding), and compare and evaluate the performance of the JPDA, Coupled
probabilistic data association (CPDA), CPDA*, JPDA*, and JPDAC with
respect to their ability to avoid track coalescence in the case of a simple two-
target tracking under clutter problem where the targets cross.
Advances in JPDAF
A lot of researcher have developed extensions to the JPDAF in order to relax
the assumptions and limitations of the JPDAF. Chang and Bar-Shalom 1995;
Shertukde and Bar-Shalom 1991 and Luginbuhl et al. 2006 adapt the JPDA
underlying the JPDAF such that it can handle merged measurements. Diﬀerent
approximations to the JPDA have been proposed to prevent the exponential
growth of the number of associations to be enumerated (Fitzgerald 1990;
Roecker and Phillips 1993; Roecker 1994; Roecker 1995; Popp et al. 2001). To
relax the assumption that the individual targets are independent, the JPDA
coupled ﬁlter (JPDACF) (Shertukde and Bar-Shalom 1991) performs coupled
estimation for the targets under consideration. The coupling between target
states can for instance be caused due to the data association uncertainty when a
single measurement can possibly originate from multiple targets. The JPDACF
executes the data association and the target estimation in a coupled manner for
the targets with shared measurements, yielding a covariance matrix with oﬀ-
diagonal blocks, called cross covariances, which reﬂect the correlation between
the state estimation errors of the targets (Bar-Shalom et al. 2009).
Diﬀerent researchers have developed algorithms combining interacting multiple
models (IMM) for switching state models with the JPDAF (Bar-Shalom et al.
1992b; de Feo et al. 1997; Chen and Tugnait 2001; Blom and Bloem 2002;
Hoﬀmann and Dang 2006; Puranik and J.K. 2007; Hoﬀmann and Dang 2009)
in an eﬀort to relax the assumption of linear Gaussian dynamics in order to
better handle highly maneuvering targets.
Below, the sample-based JPDAF (Schulz et al.
2001a; Schulz et al.
2003)
and Monte Carlo JPDAF (Vermaak et al. 2005) are discussed. These ﬁlters
use particle-based approximations for the marginal ﬁltering distributions of the
target rather than normal distributions, hereby allowing for nonlinear process

134
Chapter 4
Overview and Classification of MTTL Algorithms
and measurement models.
The sample-based JPDAF (Schulz et al.
2001a;
Schulz et al.
2003) furthermore extends the JPDAF with a separate ﬁlter
estimating the number of targets, this way enabling it to handle a varying and
unknown number of targets.
Sample-based JPDAF (SJPDAF) and Monte Carlo JPDAF (MC-JPDAF)
The sample-based JPDAF (SJPDAF) (Schulz et al. 2001a; Schulz et al. 2003)
and Monte Carlo JPDAF (MC-JPDAF) (Vermaak et al. 2005) use a factorial
representation of the ﬁltering distribution of the joint state P
 xt | y1:t
, and the
distributions of interest are the marginal ﬁltering distributions, P
 xt
n | y1:t
,
one for each of the targets.
In contrast to the basic JPDAF, the marginal
ﬁltering distributions P
 xt
n | y1:t
are not assumed to be Gaussian, but are
rather approximated with Monte Carlo pdfs (MCPdfs):
P
 xt
n | y1:t
≈
N t
p,n
X
i=1
wt,(i)
n
δxt,(i)
n
 xt
n

,
(4.95)
with i an index indicating an individual particle, N t
p,n the number of particles
for the marginal distribution of target n, wt,(i)
n
the weight of the ith particle,
xt,(i)
n
the state of the ith particle, and δa (.) the Dirac delta measure with mass
at a. The SJPDAF and MC-JPDAF furthermore approximate the association
probabilities in Equation (4.70) using particles.
By using a particle approximation for the underlying distributions in the MTT
problem, the SJPDAF and MC-JPDAF obtain recursive update equations
similar to the particle ﬁlter algorithm.
The prediction step of Equation (4.65), proceeding independently for each
target, reduces to a particle ﬁlter prediction step in which the individual
particles are propagated using a proposal Qn

xt
n | xt−1,(i)
n
, yt
resulting in the
‘predicted particle set’
n
¯xt,(i)
n
, ¯wt,(i)
n
oi=1:N t
p,n with:
¯xt,(i)
n
∼
Qn

xt
n | xt−1,(i)
n
, yt
, and
(4.96)
¯wt,(i)
n
∝
wt−1,(i)
n
P

xt,(i)
n
| xt−1,(i)
n

Qn

xt,(i)
n
| xt−1,(i)
n
, yt
,
(4.97)

4.4 Algorithms for MTTL
135
where the normalization constant for the particle weights ¯wt,(i)
n
is determined
by the fact that they have to sum to one:
PN t
p,n
i=1
¯wt,(i)
n
=
1.
The
SJPDAF (Schulz, Burgard, Fox, and Cremers 2003) uses the target process
model P

xt
n | xt−1,(i)
n

as a proposal, just like in the basic bootstrap ﬁlter,
resulting in an easy prediction step:
¯xt,(i)
n
∼
P

xt
n | xt−1,(i)
n

, and
(4.98)
¯wt,(i)
n
∝
wt−1,(i)
n
.
(4.99)
Using the predicted particle sets of Equations (4.96)-(4.97), the predictive
likelihood of Equation (4.81) can be approximated as:
P
 yt
k | y1:t−1, rt
k = n

≈
N t
p,n
X
i=1
¯wt,(i)
n
P

yt
k | ¯xt,(i)
n

.
(4.100)
The above approximation of the predictive likelihood can be directly sub-
stituted in Equation (4.82) or Equation (4.83) to obtain a particle-based
approximation of the data association probabilities ct
kn.
After calculating
the data association probabilities ct
kn, the correction step of Equation (4.68)
for the individual target trackers can be rewritten as a simple particle
ﬁlter correction where the ‘corrected sample sets’
n
xt,(i)
n
, wt,(i)
n
,
oi=1:N t
p,n are
calculated according to:
xt,(i)
n
=
¯xt,(i)
n
, and
(4.101)
wt,(i)
n
∝
¯wt,(i)
n
Kt
X
k=1
ct
knP

yt
k | xt,(i)
n

,
(4.102)
in which the normalization constant for the particle weights ¯wt,(i)
n
is determined
by the fact that they have to sum to one: PN t
p,n
i=1 wt,(i)
n
= 1. As in the traditional
particle ﬁlter the recursion ends with a resample step. This resampling can be
done for each target individually.
The interpretation of the SJPDAF and MC-JPDAF as a bank of particle ﬁlters
can also illustrated by the Bayesian network representation in Figure 4.5,
provided that the synthetic measurements eyt indicate that the adapted
formulae of Equation (4.102) taking into account the diﬀerent data associations
should be used in the correction step.

136
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
Kt−1
Kt
Kt+1
N t−1
N t
N t+1
Figure 4.6: Bayesian network model for the estimator of the number of targets
in the sample-based JPDAF (SJPDAF) proposed by Schulz et al. 2003. The
shaded nodes are observed.
Schulz et al. 2003 furthermore extend the SJPDAF for tracking an unknown
and varying number of targets. To this end, they add a separate ﬁlter to the
SJPDAF estimating the number of targets N t from the number of ‘features’, i.e.
groups of measurements belonging to the same target. They assume that the
grouping of measurements in features is performed before starting the JPDAF,
and use these summarizing features as basic measurements.
Therefore, the
number of features is equal to the number of measurements Kt. By assuming
that the number of features is independent over time, given the target states,
Schulz et al. 2003 obtain the following recursive update equation for the number
of targets:
P
 N t | Kt
∝P
 Kt | N t
Nmax
X
N t−1=1
P
 N t | N t−1
P
 N t−1 | Kt−1
, (4.103)
with Nmax the maximum number of targets, P(Kt | N t) the measurement
model giving the probability of observing Kt features when there are N t targets
in the scene, P
 N t | N t−1
the process model describing how the number of
targets changes over time, and P
 N t−1 | Kt−1
the probability of the number
of targets at the previous time step. Figure 4.6 shows the Bayesian network
for the separate ﬁlter estimating the number of targets. Schulz et al. 2003 use
the maximum likelihood estimate of P(N t | Kt) to adapt the number of targets
in the SJPDAF. See
Schulz et al. 2003 for an example on how to initialize
new targets and how to decide which target to remove, when the maximum a
posteriori estimate predicts and increase or decrease of the number of targets
respectively.

4.4 Algorithms for MTTL
137
Assumptions, advantages and disadvantages of SJPDAF and MC-JPDAF
On top of the assumptions of the general JPDAF the SJPDAF and MC-JPDAF
approximate the marginal ﬁltering distributions of each target by a Monte Carlo
distribution.
The Monte Carlo approximation of the marginal ﬁltering distributions (i)
reduces the SJPDAF and MC-JPDAF to a bank of particle ﬁlters, making them
attractive from a computational point of view, and (ii) provides the SJPDAF
and MC-JPDAF with some advantages as compared to the basic JPDAF:
• The SJPDAF and MC-JPDAF give more accurate state estimates due to
their ability to represent arbitrary densities over the state spaces of the
individual targets.
• The SJPDAF and MC-JPDAF are able to handle nonlinear process and
measurement models leading to more robust target tracking and fewer
data association errors.
• The SJPDAF and MC-JPDAF are more robust to situations with large
amount of clutter (Schulz et al. 2003).
Compared to the basic JPDAF, the Monte Carlo approximation of the SJPDAF
and MC-JPDAF comes at the cost of higher computational load due to the
particle ﬁlter computations. In contrast, the extension of the JPDAF with a
separate ﬁlter for the number of targets as proposed by Schulz et al. 2003,
relaxes one of the most important disadvantages of the JPDAF (and basic
JPDAF): its inability to handle an unknown and varying number of targets.
4.4.4
Joint Particle Filters
Joint particle ﬁlter approaches formulate the multitarget tracking problem in
the joint state space of the target states and the unknown data association
hypotheses (see Section 4.2.2.5) and subsequently use a particle ﬁlter strategy
to estimate the joint ﬁltering distribution P
 xt, rt | y1:t
in terms of M→T
associations or P

xt, ert | y1:t
in terms of T→M associations. The explanation
below will be formulated in terms of M→T associations, r, but can be
straightforwardly rewritten to T→M associations, er. The joint particle ﬁlter
approximates the joint ﬁltering distribution by a Monte Carlo pdf , i.e. by
a set of N t
p particles

wt,(i), xt,(i), rt,(i)	i=1:N t
p, with i the index describing a
particular particle and wt,(i) the particle weight. In the joint particle ﬁlter
each particle holds a value for all the target states xt = {xt
n}n=1:N and the
association variables rt.

138
Chapter 4
Overview and Classification of MTTL Algorithms
Using Bayes’ rule (step 1), the Markov assumption (step 2, step 3), and
assuming that the data association hypotheses are independent over time (step
2), the following recursive update equations can be obtained for the joint
ﬁltering distribution:
P
 xt, rt | y1:t
∝
P
 yt | xt, rt, y1:t−1
P
 xt | y1:t−1
P
 rt | xt, y1:t−1
(4.104)
=
P
 rt
P
 yt | xt, rt
Z
P
 xt | xt−1
P
 xt−1 | y1:t−1
dxt−1. (4.105)
The factors in the above equation have the following physical meaning:
• P(rt) is the prior probability for the M→T associations at time step t.
Remember that these associations are assumed to be independent over
time.
• P(yt | xt, rt) represents the measurement likelihood of the measurements
given the target states and data association hypotheses.
• P
 xt | xt−1
is the conditional probability distribution describing the
joint state dynamics.
• P
 xt−1 | y1:t−1
is the joint probability of the target states at the previous
time step t −1 given all measurement information up to time step t −1.
The joint particle ﬁlter approaches use a particle ﬁlter to implement the above
sequential update equations. In the proposal step, new particles are sampled
from a proposal:

xt,(i), rt,(i)
∼
Q

¯xt, ¯rt | xt−1,(i), yt
.
(4.106)
The proposal can be rewritten using the following factorization:
Q

¯xt, ¯rt | xt−1,(i), yt
=
Q
 ¯rt | ¯xt, yt
Q

¯xt | xt−1,(i), yt
.
(4.107)
In the weight update step, the weights of the particles sampled from the proposal
in Equation (4.106) are calculated as:
wt,(i)
∝wt−1,(i) P
 rt,(i)
P
 yt | xt,(i), rt,(i)
P
 xt,(i) | xt−1,(i)
Q
 xt,(i), rt,(i) | xt−1,(i), yt
. (4.108)

4.4 Algorithms for MTTL
139
It has been proved that the straightforward application of the particle ﬁlter to
the MTT problem suﬀers from the curse of dimensionality: to have the same
estimation accuracy, the number of particles has to be increased exponentially
with the number of targets (Vermaak et al.
2005). A practical problem is
that during the correction step, a particle gets punished (i.e. a low weight) as
soon as one of the target estimations is not good, even though the other target
states might be reasonable. This results in a rapid depletion of the particle
set, making the straightforward application of particle ﬁlters unsuited for the
MTT problem. Two main strategies can be used to adapt the particle ﬁlter for
MTT:
• The incorporation of an adapted proposal. The use of a well-chosen and
data-driven proposal aims at sampling targets during the proposal step
such that they will receive high weights during the correction step.
• The use of MCMC-based sampling strategies instead of the traditional
importance sampling in the particle ﬁlter, since the MCMC-based
sampling strategy has been shown to eﬀectively handle high-dimensional
state spaces.
Another important problem of the joint particle ﬁlter is the need to dynamically
grow and shrink the joint state space as targets appear and disappear.
Therefore, most joint particle ﬁlters are limited to a ﬁxed and known number
of targets.
Sequential Sampling Particle Filter
The sequential sampling particle ﬁlter (SSPF) proposed by Vermaak et al. 2005
constructs an adapted proposal Q
 ¯xt, ¯rt | xt−1,(i), yt
in order to combat the
curse of dimensionality. The proposal is founded on the observations that (i)
if the joint ﬁltering distribution would factorize over the individual targets,
the curse of dimensionality would be defeated, and that (ii) this factorization
is achieved if the data association problem is solved, and under the following
(implicit) assumptions:
• the targets evolve independently over time:
P
 xt | xt−1
=
N
Y
n=1
P
 xt
n | xt−1
n

, and
(4.109)
• a measurement is only inﬂuenced by the target from which it originates:
P
 yt
k | xt, rt
=
P

yt
k | xt
rt
k

.
(4.110)

140
Chapter 4
Overview and Classification of MTTL Algorithms
The SSPF uses data associations in terms of T→M associations ert, hereby
implicitly assuming that a target only generates a single (or no) measurement
(DA2a).
The SSPF constructs a proposal for the T→M associations that
factorizes sequentially over the individual target associations, this way enabling
a sampling strategy where the target states and the data associations are
sampled sequentially, conditionally on each other. To this end, the proposal for
the target states in Equation (4.106) is assumed to factorize over the individual
target states, i.e.:
Q
 xt | xt−1, yt
=
N
Y
n=1
Qn
 xt
n | xt−1
n
, yt
, and
(4.111)
the proposal for the data association variables ert in Equation (4.106) is assumed
to factorize sequentially over the individual target associations, i.e.:
Q

ert | xt, yt
=
N
Y
n=1
Q

ert
n | ert
1:n−1, xt
n, yt
.
(4.112)
Vermaak et al. 2005 use the sequential factorization of the data association
variables ert in Equation (4.112) to obtain only legal association hypotheses by
making sure that measurements already associated with targets earlier in the
sequence, i.e. measurements associated to the 1st to (n −1)th target, are no
longer considered as candidates to be associated with the current nth target,
hereby implying DA1a.
Substituting the above proposal in the correction step of Equation (4.108)
and assuming that the false measurements are uniformly distributed over the
observation volume as in Equation (4.8), the particle weights can be updated
as:
wt,(i)
∝
wt−1,(i)V −Mt
f P
 M t
f

N
Y
n=1
wt,(i)
n
,
(4.113)
with M t
f the number of false alarms in the data association hypothesis ert,(i)
and wt,(i)
n
the weight of the nth target calculated as:
wt,(i)
n
∝
P

xt,(i)
n
| xt−1,(i)
n

P

yt
rt,(i)
n
| xt,(i)
n

P

ert,(i)
n
| ert,(i)
1:n−1, xt,(i)
n

Q

xt,(i)
n
| xt−1,(i)
n

Q

ert,(i)
n
| ert,(i)
1:n−1, xt,(i)
n
, yt

.
(4.114)

4.4 Algorithms for MTTL
141
From Equations (4.113) and (4.114) it can be seen that the total particle weight
wt,(i) can be calculated as the product of the weights wt,(i)
n
, each associated
with a single target. The weight wt,(i)
n
of the nth target only depends on the
associations for the targets earlier in the sequence, i.e. the 1st to (n −1)th
target. Inspired by this observation, Vermaak et al. 2005 propose a sampling
procedure where the joint target state and association vector are constructed
in a sequential fashion.
For the target state proposal of Equation (4.111) Vermaak et al. 2005 develop
a proposal distribution that is a compromise between the simple target state
dynamics proposal of the bootstrap ﬁlter and the optimal proposal distribution:
Qn
 xt
n | xt−1
n
, yt
=
γP
 xt
n | xt−1
n

+
(1 −γ)
X
k∈Kn
Qn
 xt
n | xt−1
n
, yt
k

,
(4.115)
with Kn the set of measurement indices that are expected to have an impact
on the nth target (for instance the measurements in the gate of that target),
and Qn
 xt
n | xt−1
n
, yt
k

the optimal proposal for a particular measurement, i.e.
for the assignment ert
n = k. If no closed form expression is available for this
optimal proposal, Vermaak et al. 2005 propose to approximate this proposal by
the best approximation within a parametric class of distribution, for instance
Gaussian distributions.
For the data association proposal of Equation (4.112) Vermaak et al. 2005
develop a proposal distribution with the following properties:
• the probability of a T→M association is high for measurements well-
explained by the target,
• the probability of a T→M association diminishes as the measurements
are less well-explained by the target,
• targets explaining no measurements have a high probability of being
undetected.
The functional form of the proposal obeying the above properties can be found
in Vermaak et al. 2005.
Figure 4.7 shows the Bayesian network representing all conditional indepen-
dence assumptions of the SSPF graphically. The sequential decomposition of
the T→M associations of Equation (4.112) is explicitly depicted in this Bayesian
network.

142
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
...
...
...
...
...
...
yt−1
k
yt
k
yt+1
k
Kt−1
Kt
Kt+1
N
xt−1
n
xt
n
xt+1
n
ert−1
n−1
ert
n−1
ert+1
n−1
ert−1
n+1
ert
n+1
ert+1
n+1
ert−1
n
ert
n
ert+1
n
Figure 4.7: Bayesian network model for the sequential sampling particle ﬁlter
(SSPF). The boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements
and a set of N targets. The shaded nodes are observed.
Assumptions
• The SSPF assumes that the number of targets N is ﬁxed and known.
• Since the SSPF uses T→M associations for modeling the data association,
the data association assumption DA2a is implicitly made: i.e. one target
can cause at most one measurement.
• In the sequential construction of individual target associations the SSPF
assumes that a measurement can only originate from a single target or
from clutter (DA1a).
• The T→M associations and the target states are assumed to evolve
independently over time.
• The SSPF assumes that target states xt
n evolve independently over time,
i.e. the targets have independent dynamics.
• The T→M associations, ert, are assumed independent over time.
Advantages
• The SSPF is a particle ﬁlter strategy successfully defeating the curse of
dimensionality by developing an adapted proposal distribution for both
the target states and the data associations.
• Due to its particle-based nature the SSPF can naturally handle both
nonlinear target dynamics and measurement models.

4.4 Algorithms for MTTL
143
• The SSPF does not require any explicit pruning.
The design of the
proposal for the data associations results in a soft assignment strategy,
where all measurements are associated to all targets using the probability
that the measurement originates from that target.
Disadvantages
• The main limitation of the SSPF is the assumption that the number of
targets is ﬁxed and known.
• The SSPF can not handle multiple and merged measurements (DA1a and
DA2a).
• Due to its particle-based nature the SSPF is more computationally
expensive than Kalman-based strategies. The SSPF is furthermore more
computationally expensive than the MC-JPDAF (Section 4.4.3) and the
IPPF (Section 4.4.4).
• Vermaak et al. 2005 have shown that the SSPF is outperformed by the
MC-JPDAF (Section 4.4.3).
Advances in SSPF
Vermaak, Ikoma, and Godsill 2005 use the same ideas as
the SSPF to track a single extended object. They deﬁne an extended object as
an object with a known set of point features, where the exact location of the
point features on the extended object is unknown.
Independent Partition Particle Filter
Just as the SSPF, the independent partition particle ﬁlter (IPPF) proposed
by Vermaak et al. 2005 tries to tackle the curse of dimensionality by using an
adapted proposal. Just like the SSPF, the IPPF uses data associations in terms
of T→M associations, ert, hereby implicitly assuming that a target can cause
at most one measurement (DA2a). But on top of the adapted proposal, the
IPPF assumes that the T→M associations are independent over the individual
targets, i.e.:
P

ert
n = k | ert
j̸=n

=
P

ert
n = k

(4.116)
=





1 −P t
det,n
if k=0, i.e. if target n
is not detected
P t
det,n
N
otherwise,
(4.117)

144
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
...
...
yt−1
k
yt
k
yt+1
k
ert−1
n
ert
n
ert+1
n
Kt−1
Kt
Kt+1
N
N
N
N
xt−1
n
xt−1
n
xt
n
xt
n
xt+1
n
xt+1
n
Figure 4.8: Bayesian network model for the independent partition particle ﬁlter
(IPPF). The boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements
and a set of N targets. The shaded nodes are observed.
where P t
det,n the probability that target n is detected at time step t.
This
assumption implies that a single measurement can be caused by multiple
targets, i.e. merged measurements are allowed (DA1b).
Just as the SSPF (Equation (4.111)), the IPPF assumes that the proposal
for the target states in Equation (4.106) factorizes over the individual target
states. In the IPPF however, the proposal for the data association variables er
in Equation (4.106) simpliﬁes due to the additional assumption that the T→M
associations are independent over the individual targets:
Q

ert | xt, yt
=
N
Y
n=1
Q

ert
n | xt
n, yt
.
(4.118)
Due to the factorization of both the target proposal and the data association
proposal over the individual targets, the product over the individual target
weights in Equation (4.114) also factorizes over the individual targets and
associations. This factorization allows for an eﬃcient component-wise sampling
strategy to construct new particles (Vermaak et al.
2005):
a new joint
particle is constructed by sampling the individual target components according
to the individual target component weights, this way avoiding the curse of
dimensionality.

4.4 Algorithms for MTTL
145
Figure 4.8 shows the Bayesian network representing all conditional indepen-
dence assumptions of the IPPF graphically. The independence assumption of
the T→M associations over the individual targets is explicitly depicted in this
Bayesian network.
Assumptions
• The IPPF assumes that the number of targets N is ﬁxed and known.
• Since the PMHT uses T→M associations for modeling the data associ-
ation, the data association assumption DA2a is implicitly made: i.e. a
target can cause at most one measurement.
• The IPPF assumes that the T→M associations are independent for
the diﬀerent targets,
hereby assuming that a single measurement
can be caused by multiple targets (DA1b) and allowing for merged
measurements.
• The T→M associations and the target states are assumed to evolve
independently over time.
• The IPPF assumes that target states xt evolve independently over time,
i.e. the targets have independent dynamics.
• The T→M associations, ert, are assumed independent over time.
Advantages
• The IPPF is a particle ﬁlter strategy successfully defeating the curse of
dimensionality by developing an adapted proposal distribution for both
the target states and the data associations.
• Due to its particle-based nature the IPPF can naturally handle both
nonlinear target dynamics and measurement models.
• The IPPF does not require any explicit pruning.
The design of the
proposal for the data associations results in a soft assignment strategy,
where all measurements are associated to all targets using the probability
that the measurement originates from that target.
• The IPPF can handle merged measurements (DA1b).

146
Chapter 4
Overview and Classification of MTTL Algorithms
Disadvantages
• The main limitation of the IPPF is the assumption that the number of
targets is constant and known in advance.
• The IPPF can not handle multiple measurements originating from a single
target (DA2a).
• Due to its particle-based nature the IPPF is more computationally
expensive than Kalman-based strategies.
• Vermaak et al.
2005 have shown that the IPPF is outperformed by
the MC-JPDAF (Section 4.4.3).
and that its performance degrades
signiﬁcantly with an increase in the diﬃculty of the association problem
or the number of targets.
Hybrid particle ﬁlter for MTTL
Just as the SSPF and IPPF, the hybrid particle ﬁlter (HPF) proposed by Ng
et al.
2005a constructs an adapted proposal Q
 ¯xt, ¯rt | xt−1,(i), yt
in order
to combat the curse of dimensionality.
In contrast to the SSPF and the
IPPF, the HPF uses M→T associations, rt, hereby implicitly assuming that a
measurement can only originate from a single target or from clutter (DA1a).
On top of this assumption, the HPF assumes that a target can at most generate
a single measurement (DA2a). Also, in contrast to the SSPF and IPPF, the
HPF is able to handle a varying and unknown number of targets.
At each time step, before applying the particle ﬁlter to the joint state of the
target states xt and data association variables rt, a clustering is performed.
The clustering procedure deterministically clusters measurements of successive
scans, i.e.
yt−tw:t, where tw is the width of the time slice.
At time step
t the output of the clustering is a set of Jt clusters, also called regions of
interest (ROIs):
St =

St
j
	
j=1:Jt.
By studying the history of the ROIs
(consistency) and the relation to the existing targets,

xt−1
n
	
n=1:N t−1, the
HPF deterministically estimates the number of targets N t, and classiﬁes the
tracks as: active tracks, new tracks, and deleted tracks (for details see Ng et al.
2005a). Before processing to the proposal and weight update step, the HPF
ﬁrst adapts the state space of the particle ﬁlter if new tracks are found or tracks
are deleted during the clustering step. If a track is deleted, all corresponding
particles are deleted from the tracker (hereby reducing the state space of the
joint particle ﬁlter with the dimension of the state of a single target). If the
clustering ﬁnds a new target, a new target track and corresponding particles
are generated by sampling from a data-driven proposal (if the measurement

4.4 Algorithms for MTTL
147
function is invertible), i.e. by sampling from the measurements that are found
to be caused by a new target during the clustering step.
After adapting the joint particle ﬁlter for new targets and targets that have
disappeared, the HPF’s proposal and weight update step are given by the
general expressions in Equations (4.106) and (4.108) respectively. To construct
an adapted proposal the HPF assumes, just as the SSPF, that the targets
evolve independently over time (Equation (4.109)) and that the measurements
are only inﬂuenced by targets from which they originate (Equation (4.110)).
The proposal for the target states in the HRF is very similar to the SSPF
since (i) it is also assumed to factorize over the individual target states as in
Equation (4.111) and (ii) the individual target state proposals are a compromise
between the simple target state dynamics proposal of the bootstrap ﬁlter and
the optimal proposal distribution:
Qn
 xt
n | xt−1
n
, yt
=





P
 xt
n | xt−1
n

if target n is not detected,
γP
 xt
n | xt−1
n

+ (1 −γ) Qn
 xt
n | xt−1
n
, St
j

if target n is detected,
(4.119)
where the nth target proposal uses the information from the jth ROI, St
j, that
is found to correspond to the nth target during the clustering step.
The HPF constructs a proposal for the M→T associations by randomly
sampling from the L most probable data associations determined by applying a
deterministic 2-D assignment procedure (e.g. Murty’s algorithm) to the target
samples

xt,(i)	
i=1:Np, i.e.:
Q

rt | xt,(i), yt
=
Lt,(i)
X
l=1
P
 rt
l

δ
 rt −rt
l

,
(4.120)
where P(rt
l) is the probability of the lth assignment.
Figure 4.9 shows the Bayesian network representing all conditional indepen-
dence assumptions of the HPF graphically.
Assumptions
• Since the HPF uses M→T associations for modeling the data association,
the data association assumption DA1a is implicitly made: a measurement
can only originate from a single target or from clutter.
• The HPF additionally assumes that a target can at most generate one
measurement (DA2a).

148
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
yt−1
k
yt
k
yt+1
k
rt−1
rt
rt+1
Kt−1
Kt
Kt+1
N
xt−1
n
xt
n
xt+1
n
Figure 4.9:
Bayesian network model for the hybrid particle ﬁlter (HPF)
proposed by Ng et al. 2005a. The boxes (plates) denote a set of Kt−1, Kt and
Kt+1 measurements and a set of N targets. The shaded nodes are observed.
• The M→T asociations and the target states are assumed to evolve
independently over time.
• The HPF assumes that target states xt evolve independently over time,
i.e. the targets have independent dynamics.
• M→T associations, rt, are assumed independent over time.
Advantages
• The HPF allows an unknown and varying number of targets N.
• The HPF is a particle ﬁlter strategy defeating the curse of dimensionality
by developing an adapted proposal distribution for both the target states
and the data associations.
• Due to its particle-based nature, the HPF can naturally handle both
nonlinear target dynamics and measurement models.
• The HPF does not require any explicit pruning or gating.
• The HPF is shown to outperform the PHD-ﬁlter (Section 4.4.6) (Ng et al.
2005a).

4.4 Algorithms for MTTL
149
Disadvantages
• The HPF deterministically determines the number of targets from a
clustering procedure and a large number of rules (heuristics) checking
track persistency, etc.
• The HPF can not handle multiple and merged measurements (DA1a and
DA2a).
• Due to its particle-based nature the HPF is more computationally
expensive than Kalman-based strategies.
Hybrid marginalized particle ﬁlter for MTTL
Ng et al.
2005b propose a particle ﬁlter that is very similar to the HPF
discussed above. In contrast to the HPF however, this ﬁlter does not include
the data association variables in the joint state but marginalizes them before
estimation. Therefore, we will refer to this ﬁlter as the hybrid marginalized
particle ﬁlter (HMPF). Since enumerating all possible data associations is too
computationally expensive, Ng et al. 2005b only marginalize over the k-best
hypotheses. This marginalization results in a soft assignment strategy.
The HMPF has the same assumptions, advantages and disadvantages as the
HPF.
Recursive Jump Markov Chain Monte Carlo Particle Filter
Khan et al.
2005 apply an MCMC-based particle ﬁlter to handle the
exponential complexity of the joint state of the targets. This MCMC-based
particle ﬁlter does not explicitly include data association variables: the joint
state exists of the concatenation of the single target states. The authors show
that (i) the tracking in the joint state space of the targets allows the inclusion of
a Markov random ﬁeld (MRF) motion model modeling the interactions between
targets, and (ii) modeling the target interactions using this MRF improves the
tracking performance.
To model the target interactions, Khan et al.
2005 extend the joint target
process model with a pairwise MRF:
P
 xt | xt−1
=
N
Y
n=1
P
 xt
n | xt−1
n

Y
(n,m)∈E
Ψ
 xt
n, xt
m

,
(4.121)

150
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
yt−1
k
yt
k
yt+1
k
Kt−1
Kt
Kt+1
xt−1
xt
xt+1
xt
1
xt
2
xt
3
xt
4
xt
5
Figure 4.10: Bayesian network model for recursive jump Markov chain Monte
Carlo particle ﬁlter (RJMCMC-PF). The boxes (plates) denote a set of Kt−1,
Kt and Kt+1 measurements.
The shaded nodes are observed.
Each node
containing the target states is represented by a pairwise Markov Random Field.
The above ﬁgure shows an example with ﬁve targets.
where Ψ (xt
n, xt
m) is the interaction potential describing the interaction between
two targets and E is the set of all edges indicating the interactions between
individual targets. The explicit modeling of the target interactions results in
dependencies between diﬀerent target states and makes a factorization of the
joint state space over the individual targets impossible as shown in the Bayesian
network representation in Figure 4.10. To sample from the joint target state,
Khan et al. 2005 apply an MCMC-based particle ﬁlter with an eﬃcient proposal
density that selects one target at a time and only updates this target according
to a single target proposal:
Q

xt′ | xt
≜
(
1
N Q

xt
n
′ | xt
n

if xt′ \ xt
n
′ = xt \ xt
n,
0
otherwise,
(4.122)
where xt \ xt
n denotes the set of all target states except the mth target state.
This proposal density gives the MCMC-based particle ﬁlter the appealing
property that the ﬁlter behaves as a set of individual particle ﬁlters when the

4.4 Algorithms for MTTL
151
targets are not interacting, but eﬃciently deals with complicated interactions
when targets approach eachother (Khan et al. 2005).
Furthermore, Khan et al. 2005 extend the MCMC-based particle ﬁlter to a
reversible-jump MCMC-based particle ﬁlter (RJMCMC-PF), able to handle a
varying number of targets. To this end the joint state is extended with a set of
identiﬁers kt, containing the set of all target identities being tracked. To this
end the proposal of Equation (4.122) is extended with proposals that vary the
dimensionality of the state space by adding and removing targets. See Khan
et al. 2005 for details.
To summarize:
the RJMCMC-PF has the advantage of incorporating the
interactions between targets in the joint process model, coming at the cost of
and iterative MCMC-sampling strategy, which requires an unknown number of
iterations to converge. Therefore, the RJMCMC ﬁlters is not entirely suitable
for online applications.
MCMC particle ﬁlter and data association
Khan et al. 2006 also propose an MCMC strategy for eﬃciently sampling the
joint state space.
As in the SSPF and IPPF they include data association
variables into the joint state space.
Rather than using the classical M→T
associations or T→M associations they model the data association as a bipartite
graph:
gt =
n
xt
n
	N
n=1 ,

yt
k
	Kt
k=1 , Eto
,
(4.123)
where the set of target nodes {xt
n}N
n=1 are connected with the set of
measurement nodes {yt
k}Kt
k=1 through a set of edges Et, where an edge
represents the fact that the measurements is caused by a particular target.
This graph representation allows for both multiple and merged measurements
(DA1b and DA2b).
The MCMC-based ﬁlter proposed by Khan et al.
2006, and referred to as
MCMC-PF in this paper, estimates the target states by marginalizing over the

152
Chapter 4
Overview and Classification of MTTL Algorithms
uncertain data association variables gt from Equation (4.104):
P
 xt | y1:t
=
X
gt
P
 xt, gt | y1:t
(4.124)
∝
X
gt
P
 gt
P
 yt | xt, gt
Z
P
 xt | xt−1
P
 xt−1 | y1:t−1
dxt−1.
(4.125)
Since the straightforward application of the particle ﬁlter to the above equations
has proved to be intractable Khan et al. 2006 propose:
• an auxiliary variable sampler where it is assumed that the posterior can
be represented by a mixture of Gaussians:
P
 xt | y1:t
≈
1
Ns
Ns
X
s=1
N

xt|µt,(s), Σt,(s)
,
(4.126)
with s the index for the auxiliary variables, Ns the number of auxiliary
variables, and µt,(s) and Σt,(s) the mean and covariances associated with
the auxiliary variable s, respectively,
• a Rao-Blackwellized target density to avoid sampling over the continuous
target space, and
• an eﬃcient MCMC sampler to sample from the Rao-Blackwellized target
density.
Using the assumption of Equation (4.126) and assuming independent linear
Gaussian dynamics, the posterior of Equation (4.124) is approximated as:
P
 xt | y1:t
∼
X
gt
P
 gt
P
 yt | xt, gt 1
Ns
Ns
X
s=1
N

xt|¯µt,(s), ¯Σ
t,(s)
,
(4.127)
with ¯µt,(s) and ¯Σ
t,(s) the predicted mean and covariance according to the linear
Gaussian process model, respectively. The above equation is still intractable

4.4 Algorithms for MTTL
153
due to the summations over the data association and auxiliary variables.
Therefore, Khan et al. 2006 propose a second Monte Carlo approximation:
P
 xt | y1:t
∼
Np
X
i=1
P

gt,(i)
P

yt | xt,(i), gt,(i)
N

xt,(i)|¯µt,(s(i)), ¯Σ
t,(s(i))
,
(4.128)
where i is the index over the set of particles

xt,(i), gt,(i), s(i)	
i=1:Np sampled
from:
P
 gt
P
 yt | xt, gt
N

xt|¯µt,(s), ¯Σ
t,(s)
.
(4.129)
Rather than sampling from the above distribution, Khan et al.
2006 draw
samples from a Rao-Blackwellized target density, avoiding the sampling over
the continuous space of target states, under the assumption of linear Gaussian
measurement model P(yt | xt, gt):
n
gt,(i), s(i)o
i=1:Np
∼P
 gt
Z
P
 yt | xt, gt
N

xt|¯µt,(s), ¯Σ
t,(s)
dxt.
(4.130)
To obtain the samples

gt,(i), s(i)	
i=1:Np, Khan et al. 2006 construct a MCMC
sampler with two simple proposals, avoiding the computational cost of data-
driven proposals:
• a proposal that updates the auxiliary variable s,
• a proposal that adds or removes an edge from the data association gt.
Details can be found in Khan et al. 2006.
The algorithm proposed by Khan et al. 2006 succeeds in online tracking of a
large number of targets with multiple and merged measurements in the joint
state space of targets and data association variables. To achieve this a number
of assumptions have to be made:
• The number of targets is known and ﬁxed.
• The targets evolve independently over time.

154
Chapter 4
Overview and Classification of MTTL Algorithms
...
...
yt−1
k
yt
k
yt+1
k
gt−1
gt
gt+1
Kt−1
Kt
Kt+1
N
xt−1
n
xt
n
xt+1
n
Figure 4.11: Bayesian network model for the Markov chain Monte Carlo particle
ﬁlter and data association algorithm of Khan et al. 2006 (MCMC-PF). The
boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements and a set of
N targets. The shaded nodes are observed.
• The targets have linear Gaussian dynamics.
• The measurement model is linear Gaussian.
• Each measurement is generated independently.
• The data association variables, given by a bipartite graph, are indepen-
dent over time.
• Gating is applied to limit the computational time.
Figure 4.11 shows the above independence assumptions using a Bayesian
network. The disadvantage of the algorithm is due to its inability to track a
varying number of targets and due to the assumptions of linear and independent
target dynamics and linear Gaussian measurement models. The MCMC-PF has
however the ability to handle multiple and merged measurements.
Multitarget tracker particle ﬁlter with Gibbs sampler
The multitarget particle ﬁlter (MTPF) proposed by Hue et al. 2002a and Hue
et al. 2002b uses a Gibbs sampler to compute the distribution of the association
hypotheses at each time step. Similar to the spirit of the PMHT presented in
Section 4.4.2 the MTPF includes the data association probabilities ρt
n in the

4.4 Algorithms for MTTL
155
estimation, hereby enabling multiple measurements per target (DA2b).
In
contrast to the PMHT however the MTPF uses a particle ﬁlter strategy to
solve the multitarget tracking problem.
The MTPF approximates the joint target state including all individual target
states (but no data association variables!) by a set of samples

xt,(i)	
i=1:Np,
where each sample contains an estimate for the individual target states denoted
as xt,(i)
n
. In the proposal step samples are generated from the proposals:
xt,(i) ∼Q

¯xt | xt−1,(i), yt
.
(4.131)
Hue et al. 2002a and Hue et al. 2002b propose to use the target dynamics,
which are assumed to be independent for the diﬀerent targets. In the correction
step the weights of the above samples are calculated according to:
wt,(i) ∝wt−1,(i) P
 xt,(i) | xt−1,(i)
P
 yt | xt,(i)
Q
 xt,(i) | xt−1,(i), yt
,
(4.132)
where the measurement likelihood P
 yt | xt,(i)
, as in the spirit of the PMHT,
is written as a mixture:
P

yt | xt,(i)
=
K
Y
K=1
 
ρt
0
V +
N
X
n=1
P

yt | xt,(i)
ρt
n
!
,
(4.133)
assuming independent measurements given the target states, and assuming
the clutter is uniformly distributed over the observation volume as in
Equation (4.8).
In order to evaluate the particle weights, an estimate for
the data association probabilities ρt = {ρt
n}N
n=1 is needed.
The MTPF
computes these association probabilities using a data augmentation method
where a Markov chain is created that converges to the stationary distribution:
P
 xt, rt, ρt | y1:t
.
The MTPF uses a Gibbs sampler where the joint state
is partitioned as θt = {xt, rt, ρt}.
The Gibbs sampler iteratively samples
over the conditional posterior distribution of each component in the partition
and therefore iterates the following steps (τ indicates the step in the iteration
process):

156
Chapter 4
Overview and Classification of MTTL Algorithms
1. Draw rt
k,τ+1 as:
rt
k,τ+1 ∼
P
 rt
k,τ = n

∝



ρt
n,τP

yt
k,τ | xt
n,τ

if n ∈{1 . . . N}
ρt
0,τ
V
if n = 0.
(4.134)
2. Draw ρt
τ+1 as:
ρt
τ+1 ∼Dir
 ρt
τ+1|αt
τ

,
(4.135)
with Dir the Dirichlet distribution with parameters α =

αt
n,τ
	
n=1:N
where αt
n,τ
= 1 + ♯
n
k : rt
k,τ+1 = n
o
, i.e.
αt
n,τ is the number of
measurements assigned to target n increased with one.
3. Approximately draw xt
τ+1 from Q
n=1:N P

xt
n | y1:t, rt
k,τ+1, ρt
τ+1

as:
xt
n,τ+1 ∼













PNp
i=1
P

{yk}k:rt
k,τ+1=n | xt,(i)
n

wt−1,(i)
PNp
j=1 P

{yk}k:rt
k,τ+1=n | xt,(j)
n

wt−1,(j) δ

xt−1,(i)
n

if ∃k : rt
k,τ+1 = n
PNp
i=1 wt−1,(i)δ

xt−1,(i)
n

otherwise.
(4.136)
After a ﬁnite number of iterations of the Gibbs sampler, the data association
probabilities ρt = {ρt
n}N
n=1 are estimated by averaging over the last iterations
of the Gibbs sampler:
ρt
n =
1
τend −τbegin
τend
X
τ=τbegin
ρt
n,τ.
(4.137)
Since the estimated data association probabilities take into account the current
measurement information yt
k, they provide the a posteriori probability that a
target is detected.
The MTPF proposed by Hue et al. 2002a succeeds in online tracking of multiple
targets causing multiple measurements in the joint state space of targets and
data association variables. To achieve this a number of assumptions have to
be made:

4.4 Algorithms for MTTL
157
• The MTPF assumes that the number of targets N is known and ﬁxed.
• Since the MTPF uses M→T associations for modeling the data associa-
tion, the data association assumption DA1a is implicitly made: i.e. one
measurement can only originate from one target.
• The M→T associations, rt, and the target states are assumed to evolve
independently over time.
• Measurements are assumed conditionally independent when conditioned
on the collection of target states and data association variables.
• Measurements in the diﬀerent time steps are assumed independent.
From the above independence assumptions it can be seen that the MTPF is
represented by the same Bayesian network as the PMHT (Figure 4.2). The
MTPF has the advantage that it (i) does not require gating, (ii) can handle
nonlinear process models and measurements equations, and (iii) allows for
multiple measurements for a single target (DA2b). The disadvantage of the
algorithm is due to (i) its inability to track a varying number of targets, (ii)
the iterative procedure of the Gibbs sampler which has only proved to be fast
enough for a limited number of targets, and (iii) its inability to handle merged
measurements.
Hue et al. 2002a extend the MTPF for tracking a variable number of targets
by introducing some probabilistic rules:
• A consistent decrease of ρt
n marks the disappearance of target;
• Unexplained measurements, i.e.
measurements with low likelihood
P(yk | xt
n) for all targets n, mark the arrival of a new target.
Details can be found in Hue et al. 2002a.
4.4.5
Mixture Particle Filter (MPF)
The mixture particle ﬁlter (MPF) (Vermaak and Doucet 2003) was originally
developed to improve the poor performance of Monte Carlo methods (particle
ﬁlters) when dealing with consistently multimodal distributions. Multimodal
distributions arise if there is ambiguity about the estimated state, or if
measurements come from diﬀerent targets that are all tracked in the same state
space. In the ﬁrst case all the modes have to be tracked until the ambiguity
is resolved, and in the second case, it is desired to track all the modes and
therefore all the targets.

158
Chapter 4
Overview and Classification of MTTL Algorithms
By representing the target distribution by a non-parametric mixture of ﬁltering
distributions, the MPF has been shown to better maintain multimodality of
the distributions (Vermaak and Doucet 2003). This section explains the use of
MPF for online multitarget tracking.
The MPF formulates the MTT problem in the state space with the size of a
single target state thereby circumventing the problem of exponential growth of
the state space with the number of targets. To this end the MPF models the
distribution of interest at time step t, i.e. the ﬁltering posterior P
 xt | y1:t
,
as a non-parametric mixture with Lt components:
P
 xt | y1:t
=
PLt
l=1 πt
lPl
 xt | y1:t
,
(4.138)
where each mixture component Pl
 xt | y1:t
is a Monte Carlo probability
distribution (MCPdf). In the ideal case, each mode of the ﬁltering posterior
corresponds to a component Pl
 xt | y1:t
of the mixture and each mixture
component in turn, represents one target. The mixture of MCPdfs representing
the ﬁltering distribution is denoted by: Pt =

N t
p, Lt, Πt, X t, Wt, Ct	
, with
N t
p the number of particles, Lt the number of mixture components, Πt =
{πt
l}Lt
l=1 the mixture component weights, X t =

xt,(i)	N t
p
i=1 the particles with i
indicating an individual particle, Wt =

wt,(i)	N t
p
i=1 the particle weights, and
Ct =

ct,(i)	N t
p
i=1 the component indicators, with ct,(i) ∈{1 . . . Lt}, and ct,(i) = l
if particle i belongs to mixture component l. This particle representation results
in a Monte Carlo approximation of the mixture ﬁltering distribution of the form:
P
 xt | y1:t
≈
Mt
X
m=1
πt
l
X
i∈Il
wt,(i)δxt,(i)(xt),
(4.139)
where δa(.) is the Dirac delta measure with mass at a, and
Il =

i ∈

1 . . . N t
p
	
: ct,(i) = l
	
is the set of indexes of the particles belonging
to the lth mixture component. The mixture component weights and the particle
weights for each mixture component sum to one, i.e.
Lt
X
l=1
πt
l = 1,
and
X
i∈Il
wt,(i) = 1
for l = 1 . . . Lt.
(4.140)
The MPF is a recursive ﬁlter, calculating at each time step t the new mixture
representation of the ﬁltering distribution Pt from the one at the previous time
step Pt−1:

4.4 Algorithms for MTTL
159
1. In the proposal the target states are predicted by performing the proposal
step for each component of the mixture individually (target prediction).
2. In the weight update step the target states are updated with the
measurement information of the current time step (target correction).
This weight update step involves:
(a) performing the weight update step for each component of the
mixture individually, and
(b) updating the mixture weights of all mixture components (in this
step, the diﬀerent components interact).
3. In the last step the MPF attempts to maintain the ideal case where
one mode of the mixture represents one mode in the target ﬁltering
distribution or, in the MTT case, one mode represents a single target
(maintain mixture).
To underline the assumptions that are implicitly made by the formulation
of the MTT problem in the state space with the size of a single target, the
recursive update equations for the mixture distribution of Equation (4.138) are
derived below. The recursive update is done in two steps (under the Markov
assumption), the prediction step:
P
 xt | y1:t−1
=
Z
P
 xt | xt−1
P
 xt−1 | y1:t−1
dxt−1, and
(4.141)
the correction step:
P
 xt | y1:t
=
P(yt | xt) P
 xt | y1:t−1
R
P(yt | xt) P(xt | y1:t−1) dxt .
(4.142)
When using the mixture representation of Equation (4.138) the prediction step
is rewritten as:
P
 xt | y1:t−1
=
Lt−1
X
l=1
πt−1
l
Z
P
 xt | xt−1
Pl
 xt−1 | y1:t
dxt−1,
(4.143)
=
Lt−1
X
l=1
πt−1
l
Pl
 xt | y1:t−1
.
(4.144)
The above equation shows that the prediction step can be executed for each
target individually and that the mixture weights remain unchanged.
The

160
Chapter 4
Overview and Classification of MTTL Algorithms
individual targets are predicted with the same process model P
 xt | xt−1
since
each target is represented by a component of a mixture residing in the same
state space. Likewise, the correction step can be rewritten using the mixture
representation of Equation (4.138) into:
P
 xt | y1:t
=
Lt−1
X
l=1
πt−1
l
P(yt | xt) Pl
 xt | y1:t−1
PLt−1
m=1 πt−1
m
R
P(yt | xt) Pm(xt | y1:t−1) dxt(4.145)
=
Lt−1
X
l=1
πt−1
l
R
P(yt | xt) Pl
 xt | y1:t−1
dxt
PLt−1
m=1 πt−1
m
R
P(yt | xt) Pm(xt | y1:t−1) dxt
|
{z
}
πt
l
P(yt | xt) Pl
 xt | y1:t−1
R
P(yt | xt) Pl(xt | y1:t−1) dxt
|
{z
}
Pl(xt | y1:t)
(4.146)
=
Lt−1
X
l=1
πt
lPl
 xt | y1:t
.
(4.147)
The above derivation shows that the correction step is completed by ﬁrst
performing the correction for each target individually and subsequently
updating the mixture weights. A mixture weight πt
l is the normalized weighted
likelihood of the component. Remark that the mixture weight of a component
depends on all other components. The individual targets are corrected using
the same likelihood P(yt | xt) since each target is represented by a component
of a mixture residing in the same state space.
Vermaak and Doucet 2003 provide recursions to propagate the ﬁltering
distribution represented by a mixture of MCPdfs.
They (i) show that the
well-known particle ﬁlter prediction and correction can be performed for each
component individually, (ii) present a particle approximation of the component
weights (see Equation 4.148), (iii) show that the mixture modeling allows
independent resampling of each of the mixture components according to the
component particle weights, and (iv) show the need for a maintain mixture
step. The approximation of the components weights proposed by Vermaak and
Doucet 2003 is as follows:
πt
l
≈
P
i∈Il ewt,(i)
PLt−1
m=1

πt−1
l
P
i∈Il ewt,(i),
(4.148)

4.4 Algorithms for MTTL
161
...
...
yt−1
k
yt
k
yt+1
k
Kt−1
Kt
Kt+
xt−1
xt
xt+1
Figure 4.12: Bayesian network model for mixture particle ﬁlter (MPF). The
boxes (plates) denote a set of Kt−1, Kt and Kt+1 measurements. The shaded
nodes are observed.
with ewt,(i) the unnormalized particle weights given by:
ewt,(i)
=
wt−1,(i)P
 yt | xt,(i)
P
 xt,(i) | xt−1,(i)
Ql(xt,(i)|xt−1,(i), yt)
,
(4.149)
where Ql(xt|xt−1,(i), yt) is the proposal distribution for the lth component.
As mentioned above Vermaak and Doucet 2003 show that since the prediction
and correction step of the mixture just propagate the individual mixture
components and recompute the weights, an extra step is needed to maintain
the ideal situation where each component of the mixture represents one target
(targets and hence components can appear, disappear, merge split, etc.).
Vermaak and Doucet 2003 propose a maintain mixture step in which particles
are redistributed over a number, possibly diﬀerent from the number at the
previous time step, of components. Their maintain mixture step consists of a
spatial reclustering procedure step using heuristics to merge, split and delete
components, followed by a particle and mixture weight recomputation. Remark
that the maintain mixture step does not change the underlying probability
distribution, it only changes the way the probability distribution is described
by a mixture of MCPdfs.
Figure 4.12 shows the Bayesian network representation of the MPF.
Data association problem
In the previous paragraph it was shown that the MPF solves the problem of
exponential growth of the state space with the number of targets by formulating

162
Chapter 4
Overview and Classification of MTTL Algorithms
the estimation problem in the state space of a single target and interpreting
the diﬀerent modes of the ﬁltering distribution as diﬀerent targets.
The
MPF however does not solve the data association problem.
How then to
decide which measurements originate from which targets or in this case, which
measurements originate from which modes in the distribution? In the state
of the art MPF (Vermaak and Doucet 2003; Du and Piater 2005b; Okuma
et al.
2004; Madapura and Li 2008) a data association algorithm assigns
measurements to diﬀerent modes of the ﬁltering distribution, i.e. to diﬀerent
targets, using a nearest-neighbor approach. This nearest-neighbor approach
has some problems: (i) it is not clear which distance metrics are appropriate
or allowed, (i) it has been shown that a nearest neighbor approach is not
robust against target occlusions (Cox 1993), and (iii) it assigns measurements
to diﬀerent parts of the same state space by means of an implicit, arbitrary
choice made in each particular conﬁguration (Cox 1993).
Such assignment
cannot be represented in the Bayesian network, hence the nearest neighbor
approach cannot be considered to be a fully Bayesian method.
Assigning diﬀerent measurements to diﬀerent parts of the state space is not
theoretically sound, it can not be modeled in a Bayesian framework and thus it
can not be represented by a Bayesian network. A diﬀerent degree of evidence is
assigned to diﬀerent parts in the state space by assigning the measurements to
the closest mode of the ﬁltering posterior, therefore the resulting posterior can
no longer be interpreted as a probability density function. All measurements,
possibly originating from diﬀerent targets, have to be applied to the entire
state space, i.e. to all modes of the ﬁltering distribution. This approach requires
a measurement model P(yt | xt) that can take into account measurements
originating from other targets than the one under study. This way the data
association problem is circumvented, since as stated above, all measurements
are applied to all modes of the ﬁltering distribution, i.e. to all targets.
The rigorously Bayesian beam model (RBBM) (De Laet et al. 2008) presented
in Chapter 3, is a measurement model that does follow a Bayesian approach,
since it allows any measurement to be associated to other targets than just
the one under consideration. Chapter 6 shows how the RBBM can be used
as in measurement model in the MPF, this way making it suited for Bayesian
multitarget tracking. Chapter 6 furthermore presents a novel fully Bayesian
method for maintaining the mixture representation, this way avoiding any
heuristics.
Assumptions
• The MPF assumes that the target states can be represented in a single
state space by a mixture of MCPdfs, where in the ideal case each mixture

4.4 Algorithms for MTTL
163
component represents a single target.
• The MPF is based on the Bayes ﬁlter recursions thereby assuming that
the Markov assumption holds.
• Measurements in the diﬀerent time steps are assumed independent.
• The MPF implicitly assumes that individual target states xt (components
of the mixture) evolve independently over time, i.e.
the targets have
independent dynamics.
• Since the target states are represented by diﬀerent modes in the same
state space, the targets are also assumed to have identical dynamics.
Advantages
• The MPF circumvents the exponential growth of the state space with the
number of targets by formulating the MTT problem in the state space
with the size of a single target state.
• By modeling the target distribution as a mixture of MCPdfs, where each
component represents one target, the prediction and correction step can
be executed for each target individually.
• The MPF can handle a varying and unknown number of targets.
• The MPF has no problem with handling multiple and merged mea-
surements (DA1b, DA2b) since all measurements are applied to all
components of the mixture, i.e. to all targets.
• Thanks to the particle representation of the target states, the MPF can
handle nonlinear process and measurement models.
• The MPF avoids explicit associations between measurements and targets.
Disadvantages
• Due to the formulation of the MTT problem in the state space with the
size of a single target state, the MPF requires an adapted measurement
model allowing to apply all measurements to all component to be a fully
Bayesian method.
• To maintain the ideal situation where each component of the mixture
represents one target, a maintain mixture step is needed in the MPF. In
the maintain mixture step, a new mixture representation is calculated.
During this step an extra procedure should take care of managing the
unique target identities.

164
Chapter 4
Overview and Classification of MTTL Algorithms
• The MPF performs poor when the diﬀerent targets are close in the state
space: if diﬀerent components of the mixture are close in the state space
the mixture computation step will tend to merge them.
• The maintain mixture step decides on the number of components in the
mixture and their locations based on the target distribution at that time
step.
• The state-of-the-art MPF algorithms rely on heuristics in the mixture
computation step. (Chapter 6 tries to relief the MPF from this advantage
by presenting a fully Bayesian method for maintaining the mixture
representation, this way avoiding any heuristics.)
Advances in MPF
Diﬀerent applications and improvements have been suggested for the MPF in
multitarget tracking problems. Vermaak and Doucet 2003 validated the MPF
using the tracking of football players in a video sequence using nearest neighbor
assignments. Du and Piater 2005b studied the MPF to track multiple targets
based on camera images and apply an EM-based cluster analysis of the features
extracted from the camera preceding the particle ﬁltering to initialize particle
ﬁlters for new targets. The features from the camera images are assigned to one
target, using a nearest-neighbor data association. The authors propose to use
a voting technique to determine the number of clusters in the data and provide
heuristics to decide when to start and stop a ﬁlter and to merge overlapping
and split spatially disjoint clusters. Okuma et al. 2004 successfully combine the
MPF with the Adaboost algorithm to track hockey players during a game. The
proposal is a mixture of both the target dynamics and the detection hypothesis
generated by Adaboost. Adaboost also provides a mechanism for obtaining
and maintaining the mixture representation: it allows to quickly detect targets
entering and leaving the scene. Madapura and Li 2008 combine the MPF with a
KLD sampling stage (Fox 2001; Fox 2003) to minimize the number of particles
and thus to improve the tracking speed, while the accuracy is improved by
using radial basis functions to interpolate the sparse particle set. The MPF
was validated on vision based tracking of hockey players.
4.4.6
Probability Hypothesis Density (PHD) Filter
The Probability Hypothesis Density (PHD) ﬁlter is a formulation of the MTTL
problem that avoids explicit associations between measurements and targets.
The PHD ﬁlter is based on a formulation of the MTTL problem in the random
ﬁnite set (RFS), also called point process, framework.

4.4 Algorithms for MTTL
165
The set of target states {xt
n}n=1:N t and measurements {yt
k}k=1:Kt can be
naturally represented as ﬁnite sets if there is no ordering in the collections
of target states and measurements:
Xt
=

xt
1, . . . , xt
N t
	
∈F (X) , and
(4.150)
Y t
=

yt
1, . . . , yt
Kt
	
∈F (Y) ,
(4.151)
where F (X) and F (Y) are the collections of all ﬁnite subsets of X and Y,
respectively. The key in the random ﬁnite set formulation is to treat the target
set Xt and the measurement set Y t as the multitarget state and multitarget
measurement, respectively (Vo and Ma 2006). In this case, the MTTL problem
becomes a ﬁltering problem in the state space F (X) and observation space
F (Y). The uncertainty in the MTTL problem is characterized by modeling
the multitarget state Xt and the mulitarget measurement set Y t as random
ﬁnite sets (RFS) (Mahler 2003). The assumption on the lack of ordering will
make the ﬁlters founded on random ﬁnite sets, including the PHD ﬁlter, unable
to maintain a record of target identities.
The formulation of the MTTL problem in terms of random ﬁnite sets naturally
allows to incorporate target detection, target disappearance and clutter. To
this end a RFS model for the time evolution of the multitarget state and for
the measurement model are needed. The RFS model for the time evolution of
the multitarget state can be deﬁned as (Vo and Ma 2006):
Xt =


[
xt−1∈Xt−1
St|t−1
 xt−1


|
{z
}
existing targets
[


[
xt−1
n
∈Xt
Bt|t−1
 xt−1


|
{z
}
new targets spawned from targets at t−1
[
Γt
|{z}
spontaneous birth targets
,
(4.152)
where St|t−1
 xt−1
models the fact that a target state xt−1 continuous to exist
with probability P t
cont and in this case evolves according to the process model
P
 xt | xt−1
. Likewise, the RFS measurement model can be deﬁned as (Vo
and Ma 2006):
Y t =
" [
xt∈Xt
Θt
 xt
#
|
{z
}
target measurements
[
Kt
|{z}
false alarms
,
(4.153)

166
Chapter 4
Overview and Classification of MTTL Algorithms
where Θt (xt) models that fact that a target with state xt−1 is detected with
probability Pdet,n and in this case causes a measurement according to the
measurement model P(yt | xt). In the RFS process and measurement model
the RFS constituting the union are assumed independent of each other, hereby
assuming independent target states and independent measurements given the
target states.
The recursions in the Bayes ﬁlter needed to obtain an estimate for the
multitarget posterior in term of RFS P
 Xt | Y 1:t
, involve multiple integrals
on the space F (X), which are computationally intractable. The PHD ﬁlter
is an approximation developed to alleviate the computational intractability
in the multitarget Bayes ﬁlter (Vo and Ma 2006).
Instead of propagating
the multitarget posterior density P
 Xt | Y 1:t
, the PHD ﬁlter propagates the
probability hypothesis density (PHD), also called the posterior intensity, a ﬁrst-
order moment statistic of the posterior state estimate (Mahler 2003). The PHD
can be deﬁned as the density vt (xt) whose integral
R
S vt (xt) dxt on any region
S of the state space is N t(S), the expected number of targets contained in S.
Therefore, the expected number of targets is given by N t =
R
vt (xt) dxt. The
PHD ﬁlter provides recursions to propagate the PHD over time (Mahler 2003):
vt|t−1
 xt
=
Z
P t
cont(xt−1)P
 xt | xt−1
vt−1
 xt−1
dxt−1 +
Z
βt|t−1(xt|xt−1)P
 xt | xt−1
vt−1
 xt−1
dxt−1 + γt(xt), (4.154)
vt
 xt
=

1 −P t
det,n(xt−1)

vt|t−1
 xt
+
X
yt∈Y t
P t
det,n(xt−1)P(yt | xt) vt|t−1 (xt)
κt(yt) +
R
P t
det,n(ǫ)P(yt | ǫ) vt|t−1 (ǫ) dǫ,
(4.155)
where γt(·), βt|t−1(·) and κt(·) are the intensities of the RFS Γt, Bt|t−1 and Kt,
respectively.
Figure 4.13 shows the Bayesian network representation of a Bayes ﬁlter based
on RFS, and thus the PHD ﬁlter.
Assumptions
• The PHD ﬁlter models the set of target states and measurements as a
RFS, hereby assuming that;
– all targets are independent,

4.4 Algorithms for MTTL
167
...
...
Y t−1
Y t−1
Y t+1
Xt−1
Xt
Xt+1
Figure 4.13: Bayesian network model for the probability hypothesis density
(PHD) ﬁlter. Xt represents the random ﬁnite set of target states at time step
t, i.e.: Xt = {xt
1, . . . , xt
N t}. The shaded, observed nodes are the random ﬁnite
sets of the measurements deﬁned as: Y t = {yt
1, . . . , yt
Kt}
– all measurements are independent given the target states,
– individual targets evolves independently over time according to the
same process model, i.e. the targets have independent and identical
dynamics, and
– all target generate measurements independently according the same
measurement model.
• The PHD ﬁlter is based on Bayes ﬁlter recursions thereby assuming that
the Markov assumption holds.
• Measurements in the diﬀerent time steps are assumed independent.
• The false alarms are Poisson distributed and are independent of the target-
originated measurements.
• The predicted multitarget RFS given by P
 Xt | Y 1:t−1
is Poisson
distributed.
Advantages
From this recursions it is clear that the PHD ﬁlter completely avoids the
combinatorial computations due to the data association problem and that the
PHD recursions require less computational power than the general multitarget
recursions for RFS processes (Vo and Ma 2006).
• As can be seen from the PHD recursions in Equations (4.154)-(4.155),
the PHD circumvents the combinatorial computations due to the data

168
Chapter 4
Overview and Classification of MTTL Algorithms
association problem by modeling the target states and measurements as
RFS.
• The modeling of the target states and measurements as RFS naturally
allows to handle a varying number of targets, i.e. both appearance and
disappearance of targets, and false alarms.
• The general PHD has no problem with handling multiple and merged
measurements (DA1b, DA2b).
Disadvantages
• In general, the PHD ﬁlter recursion don’t have a closed form solution
and the numerical integrations in the PHD ﬁlter still suﬀer from the
curse of dimensionality (Vo and Ma 2006). Additional assumptions or
approximations are needed to obtain a closed form solution such as the
Gaussian mixture PHD ﬁlter and the sequential Monte Carlo PHD ﬁlter
discussed below.
• The approximation that the predicted multitarget RFS, P
 Xt | Y 1:t−1
,
is Poisson distributed, is only valid if the interactions between diﬀerent
targets is negligible.
• The PHD ﬁlter gives as the output the PHD and no point estimates of
the individual targets and the number of targets. Therefore, the PHD
ﬁlter has to be supplemented with reliable algorithms for computing point
estimates from intensity function estimates (Vo et al. 2005).
• All ﬁlters based on RFS, including the PHD ﬁlter, are unable to maintain
a record of target identities.
• The performance of the PHD ﬁlter in terms of target detection and
estimation is signiﬁcantly degraded when the environment is hostile, i.e.
under high clutter density and low target detection probability (Ng et al.
2005a).
Gaussian Mixture Probability Hypothesis Density (GM-PHD) Filter
The Gaussian mixture PHD (GM-PHD) ﬁlter, proposed by Vo and Ma 2006,
models the PHD as a mixture of Gaussians, i.e.:
vt
 xt
=
Lt
X
l=1
πt
lN
 xt|µt
l, Σt
l

,
(4.156)

4.4 Algorithms for MTTL
169
and presents closed-form recursions to propagate the means {µl}l=1:Lt,
covariances {Σl}l=1:Lt, and weights {πl}l=1:Lt of the PHD over time, under
the following assumptions:
• The process and measurement model are linear Gaussian, i.e:
P
 xt | xt−1
=
N
 xt|F txt−1, Qt
,
(4.157)
P
 yt | xt
=
N
 yt|Gtxt−1, Rt
.
(4.158)
• The probabilities of track continuation and target detection are state
independent, i.e.:
P t
cont(xt)
=
P t
cont,
(4.159)
P t
det,n(xt)
=
P t
det,n.
(4.160)
• The intensities γt(·) and βt(·) are also Gaussian mixtures.
In the GM-PHD ﬁlter, the number of components required to represent
the PHD increases without bound.
Therefore, the GM-PHD has to be
supplemented with a pruning procedure to reduce the number of components in
the Gaussian mixture (Vo and Ma 2006). Vo and Ma 2006 furthermore propose
an extended Kalman PHD (EK-PHD) ﬁlter and and unscented Kalman PHD
(UK-PHD) ﬁlter relaxing the assumption on the linear Gaussian process and
measurement model, by using linearizations of the process and measurement
model in the iterations in the spirit of the extended Kalman ﬁlter and unscented
Kalman ﬁlter, respectively.
Sequential Monte Carlo Probability Hypothesis Density (SMC-PHD) Filter
The Sequential Monte Carlo PHD (SMC-PHD) ﬁlter, proposed by Vo et al.
2005, approximates the PHD using a Monte Carlo approximation, i.e.
the
PHD is represented by a large set of weighted particles:
vt
 xt
=
N t
p
X
i=1
wt,(i)δxt,(i)
 xt
,
(4.161)
and presents recursions to propagate the particle weights

wt,(i)	
i=1:N tp, and
the particle states

xt,(i)	
i=1:N tp of the PHD over time. Comparable to the

170
Chapter 4
Overview and Classification of MTTL Algorithms
unbounded increase of number of components in the GM-PHD, the number of
particles needed to represent the PHD in the SMC-PHD ﬁlter also increases.
During a resampling step, the number of particles to represent the posterior
PHD is again set to the original number of particles.
Ng et al. 2005a show that while the SMC-PHD ﬁlter approach is theoretically
sound, it demands intense computation, with a huge number of particles
required to explore diﬀerent dimensional state spaces in the case of target
detection/localization.
4.5
Discussion
This section presents the classiﬁcation of the algorithms discussed in the
previous section according to the classiﬁers listed in Section 4.3, (i) in tabular
format and (ii) using the decision graph of Figure 4.14. The table and decision
graph helps researchers in (i) choosing an algorithm suited for their particular
MTTL problem and (ii) comparing newly developed algorithms with existing
ones.
The above classiﬁcation, together with the assumptions, advantages
and disadvantages of the studied algorithms (Section 4.4) shows that despite
the large number of algorithms available in literature there is still a need for
online MTTL algorithms that can (i) handle a large number of targets (and
measurements), (ii) maintain unique target identities, (iii) estimate a varying
and unknown number of targets, (iv) handle nonlinear process and models, (v)
process multiple and merged measurements, and (vi) take interaction dynamics
existing during close target interactions into account.
This chapter formulated a set of important state-of-the-art MTTL algorithms
in a uniﬁed framework using the same terminology and symbols and analyzed
the conditional independence assumptions made in these algorithms using their
Bayesian network.
This uniﬁed framework and Bayesian networks help to
analyze the diﬀerences and similarities between the diﬀerent algorithms. We
hope that this thorough analysis will (i) help researchers in choosing the most
suited algorithm to solve their MTTL problem and (ii) create a framework
in which new MTTL algorithms can be presented and compared to existing
MTTL algorithms.

4.5 Discussion
171
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
yes
no
no
no
no
no
no
no
no
no
no
no
no
no
no
no
no
no
Modeled Target
Interactions
Fixed Number of Targets
Linear Models
Linear Models
Online
Multiple and Merged
Measurements
Merged Measurements
Merged Measurements
Merged Measurements
Multiple Measurements
Multiple Measurements
Maintains Target
Maintains Target
Maintains Target
Identities
Identities
Identities
Multiple Hypotheses
Multiple Trackers
Explicit Gating
?
?
?
RJMCMC-PF
PMHT
MCMC-PF
basic JPDAF
MPF
IPPF
SSPF
MC-JPDAF
basic MHT
MG-PHD
MTPF
MHT
SJPDAF
HPF
HMPF
SMC-PHD
Figure 4.14: Decision graph to help researchers in choosing an algorithm suited for their particular MTTL problem.

172
Chapter 4
Overview and Classification of MTTL Algorithms
hhhhhhhhhhhhhhh
Property
Algorithm
MHT
PMHT
basic JPDAF
SJPDAF
MC-JPDAF
SSPF
IPPF
HPF
HMPF
RJMCMC-PF
MCMC-PF
MTPF
MPF
MG-PHD
SMC-PHD
(O)nline vs. (B)atch
O
B
O
O
O
O
O
O
O
O
O
O
O
O
O
(P)arametric/(N)onparametric
P
P
P
N
N
N
N
N
N
N
P
N
N
P
N
(A)ble/(U)nable to maintain track
identities
A
A
A
A
A
A
A
A
A
A
A
A
U
U
U
Number of targets: (FN) ﬁxed
and known, (VU) varying and
unknown
VU
FN
FN
VU
FN
FN
FN
VU
VU
VU
FN
VU
VU
VU
VU
(L)inear/(N)onlinear models
L
L
L
N
N
N
N
N
N
N
L
N
N
L
N
(A)ble/(U)nable to handle
multiple measurements
U
A
U
U
U
U
U
U
U
U
A
A
A
A
A
(A)ble/(U)nable to handle merged
measurements
U
U
U
U
U
U
A
U
U
U
A
U
A
A
A
(E)xplicit gating or (N)ot
E
N
E
E
E
N
N
N
N
N
E
N
N
N
N
State space: (ST) dim. single
target, (AT) groups all target
states (ATD) AT + data ass. var.,
(RFS) space of RFS
ST
ST
ST
ST
ST
ATD ATD ATD AT
AT
ATD ATD ST
RFS RFS
(SM) single multimodal, (SJ)
single joint, or (MT) multiple
trackers
MT MT MT MT MT
SJ
SJ
SJ
SJ
SJ
SJ
SJ
SM
SM
SM
Data ass. problem: (C)
circumvented, (H) hard or, (S)
soft ass.
H
S
S
S
S
S
S
S
S
C
S
S
C
C
C
Data ass. variables: (E)
estimated, (M) marginalized
-
M
M
M
M
E
E
E
M
-
M
E
-
-
-

Chapter 5
Shape-based Online
Multitarget Tracking and
Localization for Targets
causing Multiple
Measurements: Variational
Bayesian Clustering and
Lossless Data Association1
This paper proposes a novel online two-level multitarget tracking and localiza-
tion (MTTL) algorithm. The algorithm focuses on multitarget localization and
tracking for the case where a target can produce multiple measurements and
where the number of targets being tracked is unknown and possibly changing.
Information is continuously exchanged in both directions between the two
levels.
Using the high-level target position and shape information, the low level clusters
the measurements. Furthermore, the low level features automatic relevance
1This chapter has been submitted as a full article for publication in IEEE Transactions
Pattern Analysis and Machine Intelligence: Tinne De Laet, Herman Bruyninckx, and Joris
De Schutter; Shape-based online multitarget tracking and localization for targets causing
multiple measurements: variational Bayesian clustering and lossless data association.
173

174
Chapter 5
Shape-based Online MTTL
detection (ARD) as it automatically determines the optimal number of clusters
from the measurements, taking into account the expected target shapes.
The high level’s data association allows for a varying number of targets. A joint
probabilistic data association algorithm looks for associations between clusters
of measurements and targets. These associations are used to update the target
trackers (based on an underlying motion model), and the target shapes, with
the individual measurements. No information is lost in the two-level approach,
since the measurement information is not summarized into features. The high
level is supplemented with a ﬁlter estimating the number of targets.
The algorithm is veriﬁed using both simulations and experiments using two
sensor modalities, video and laser scanner, for localization and tracking of
people and ants.
5.1
Introduction
Multitarget tracking (MTT) consists of estimating the state of diﬀerent
targets recursively. Multitarget tracking and localization (MTTL) furthermore
includes detection of appearing and disappearing targets. Multitarget tracking
arises in a wide variety of contexts:
vision or laser-based people tracking
for mobile robotics and surveillance systems, sonar-based submarine tracking,
multitarget tracking for manipulation, tracking of animals to study their
behavior, etc.
Multitarget tracking has the following challenges : (i) the data association
of raw data to each target, (ii) the curse of dimensionality as the size of the
state space increases exponentially with the number of targets, (iii) the non-
linearity of target dynamics and measurement models, and (iv) the handling of
occlusions. Sensors provide unlabelled measurements of the targets, leading to
challenging combinatorial data association: (i) the spatial separation between
targets can be small compared to the measurement errors and (ii) clutter
measurements, i.e. measurements not corresponding to any of the targets, can
occur.
Moreover multitarget localization introduces extra diﬃculties: the number of
targets to track is unknown and possibly varying.
In the absence of prior
information on the environment, targets can appear and disappear at any time
and in any place.
A multitarget tracker and localizer has to automatically
detect appearing and disappearing targets and estimate the number of targets.
Existing algorithms are often limited to cases where targets generate at most
one measurement at a given time instant. This assumption is reasonable for
radar tracking, but is not valid for camera and laser-based multitarget tracking.

5.2 Related Work
175
Computer vision algorithms typically return multiple blob centroids per target
or a cloud of multiple measurements (e.g. pixels of interest) around a target.
Likewise, a laser scanner also results in multiple measurements for a single
target, since one target returns several range measurements. To circumvent the
limitation of one measurement per target existing algorithms are often preceded
by a measurement preprocessing step that tries to group the measurements
in features.
Subsequently, the summarized feature information is fed to
the tracking algorithm.
Obviously, summarizing individual measurements
into features may result in information loss.
Instead of combining the
target measurements into a single feature, such as an average or a centroid
measurement, a richer and lossless representation may be achieved by passing
all the available measurements to the tracking algorithm (Vermaak et al. 2005).
The algorithm proposed in this paper is concerned with online tracking and
localization of a variable number of targets for the case where a single target
can produce multiple measurements. The goal is to correctly detect entering
and leaving targets and to obtain a record of the trajectories of targets over time,
maintaining a correct identiﬁcation for each target throughout. To this end this
paper proposes a novel online two-level multitarget localization and tracking
algorithm. The low level clusters the measurements by using the high-level
target position and shape information. The high data association and tracking
level performs the data association, tracks the targets based on an underlying
motion model, and updates the target shapes. To construct the set of possible
joint association events during the data association it is generally assumed that
a measurement originates from a single target and that the target generates
only a single measurement. The algorithm proposed in this paper drops the
second assumption as the two-level approach allows us to take into account
multiple measurements per target. To this end all measurements in a cluster
are jointly assigned to a target. After this association the measurements are
individually processed by the algorithm avoiding the information loss caused
by summarizing the measurement information.
Section 5.2 gives an overview of related work. Section 5.3 describes the novel
online two-level multitarget tracking and localization algorithm. Section 5.4
contains the experimental validation of the new algorithm. Finally, Section 5.5
discusses the new algorithm as well as future work. The paper includes an
appendix (Section 5.6.3) describing the developed software.
5.2
Related Work
A vast literature exists on multitarget tracking and localization (Cox 1993;
Vermaak et al.
2005; Bar-Shalom et al.
2009).
This paper does not aim
at giving an exhaustive summary but situates the proposed algorithm within

176
Chapter 5
Shape-based Online MTTL
the group of multitarget tracking algorithms by showing how the proposed
algorithm tackles the diﬀerent challenges in MTTL.
A ﬁrst way to distinguish between MTTL algorithms is how they handle the
curse of dimensionality that arises as the size of the state space exponentially
increases with the number of targets. A ﬁrst category of multitarget trackers
explicitly extends the state space to include all targets of interest (and even
data association variables) (Hue et al. 2002a; Vermaak et al. 2005; Vermaak
et al.
2005; Ng et al.
2005a; MacCormick and Blake 2000; Khan et al.
2005; Khan et al.
2006).
To allow for a variable number of targets, the
state space dimension for this ﬁrst category of algorithms has to be changed
dynamically (Ng et al. 2005a) or an indicator state has to be included showing
which targets are active (MacCormick and Blake 2000).
Speciﬁc measures
are made to handle the curse of dimensionality: pruning, good proposals for
the Monte Carlo ﬁlters (Vermaak et al.
2005; Ng et al.
2005a), eﬃcient
sampling (Hue et al.
2002a; MacCormick and Blake 2000; Vermaak et al.
2005), Markov Chain Monte Carlo sampling (Khan et al. 2005; Khan et al.
2006), adaptive resampling for particle ﬁlters (Hue et al.
2002a), etc.
A
second category builds a multitarget tracker by multiple instantiations of single
target tracking algorithms (JPDAF, SJPDAF, PMHT, etc.) (Bar-Shalom and
Fortmann 1988; Bar-Shalom et al. 2009; Cox 1993; Schulz et al. 2003; Kotecha
and Djuric 2003; Streit and Luginbuhl 1995; Vermaak and Doucet 2003; Du and
Piater 2005a). Diﬀerent mechanisms have been proposed to handle a variable
number of targets (Blom et al. 1992; Bar-Shalom et al. 1992a; Schulz et al.
2003; Bar-Shalom et al. 1992b). The algorithm proposed in this paper builds
multiple instantiations of a single target tracker and keeps a separate ﬁlter for
estimating the number of targets (Schulz et al. 2003).
A second way to distinguish between MTTL algorithms is how they handle
the data association problem. A ﬁrst category uses hard assignments, each
measurement is assigned to one target:
for instance nearest-neighbor or
strongest-neighbor assignments (Montemerlo et al.
2002; Lindström and
Eklundh 2001; Fod et al.
2002; Song et al.
2005).
A second category
uses soft assignments, each measurement is assigned to multiple, or all,
targets (Cox 1993; Bar-Shalom and Fortmann 1988; Schulz et al. 2003; Streit
and Luginbuhl 1995). The data association weight in this kind of methods is
usually determined by the probability that a measurement originates from a
given target. The proposed algorithm uses joint probabilistic data association
(JPDA) (Cox 1993) to associate clusters of measurements with targets.
A third way to distinguish between MTTL algorithms is whether parametric
or non-parametric ﬁlters underlie the algorithm. Parametric ﬁlters use a ﬁxed
functional form, often Gaussian to represent the posterior (Bar-Shalom and
Fortmann 1988; Streit and Luginbuhl 1995; Kotecha and Djuric 2003; Khan
et al. 2006). This property makes the parametric ﬁlters eﬃcient, but limits
their representational power.
Non-parametric ﬁlters, such as Monte Carlo

5.2 Related Work
177
ﬁlters, do not rely on a ﬁxed functional form, and hence make no strong
assumptions about the posterior density, which however results in a high
computational complexity (MacCormick and Blake 2000; Schulz et al. 2003;
Vermaak et al. 2005; Vermaak et al.
2005; Hue et al.
2002a; Khan et al.
2005; Vermaak and Doucet 2003; Du and Piater 2005a). The high level of
the proposed algorithm still allows us to freely choose between parametric and
non-parametric ﬁlters for the target trackers.
A fourth way to distinguish between MTTL algorithms is whether they can
handle targets generating multiple measurements, i.e. whether they allow
lossless tracking. Most state of the art algorithms are limited to cases where
targets generate at most one measurement at a given time instant (MacCormick
and Blake 2000; Cox 1993; Bar-Shalom and Fortmann 1988; Schulz et al. 2003;
Streit and Luginbuhl 1995; Vermaak et al.
2005; Khan et al.
2005).
To
circumvent the limitation of one measurement per target existing algorithms
are often preceded by a measurement preprocessing step that tries to group
the measurements in features, such as an average or centroid measurement.
Subsequently, the summarized feature information is fed to the tracking
algorithm. Although only suited for one target, the extended object tracker
proposed by Vermaak et al.
2005 can handle multiple measurements per
target. The target, however, is assumed to produce a ﬁxed and known number
of features, resulting in at most one measurement each at a particular time
step. The particle ﬁlter proposed by Hue et al. 2002a, which works in the
joint state space, is capable of handling multiple measurements per target
but simulation nor experimental results for this case are shown. The mixture
particle ﬁlter (Vermaak and Doucet 2003; Du and Piater 2005a) represents the
posterior in the state space of a single target. This posterior is multimodal if
measurements are caused by multiple targets. The algorithm tracks multiple
targets by ﬁtting a mixture of Monte Carlo probability distributions to the
posterior. This method allows to handle multiple measurements per target,
but is not suited to maintain correct identiﬁcation for each target throughout
close interactions. The MCMC-based ﬁlter developed by Khan et al. 2006 can
also handle multiple measurements per target and has capabilities most similar
to the algorithm proposed in this paper.
The MCMC-based ﬁlter (Khan et al.
2006) works in the joint state space
of target states and data association variables. It overcomes the exponential
complexity typical of ﬁlters working in the joint space by (i) using a MCMC
sampling strategy and (ii) Rao-Blackwellizing the Markov chain to eliminate
sampling over the continuous state space of targets. Their approximate MCMC-
based ﬁlter assumes linear-Gaussian motion and measurement models. The
posterior over the joint state space is approximated by a mixture of Gaussians.
In contrast to our algorithm however, the MCMC-based ﬁlter is not extended
to handle a varying number of targets.

178
Chapter 5
Shape-based Online MTTL
Another MCMC-based ﬁlter from the same research group (Khan et al. 2005)
focusing on interacting targets is able to handle a varying number of targets,
but only deals with targets producing at most one measurement. In contrast
to our algorithm, the estimation of the number of targets requires a target
detector that, at each time step, returns a set of detected targets along with
their estimated state.
The algorithm proposed in this paper integrates the
tracking and detection of targets within a single algorithm.
5.3
Two-level Tracking and Localization Algorithm
5.3.1
General
The proposed algorithm is a two-level tracking and localization algorithm.
Figure 5.1 depicts the information ﬂow for the algorithm.
The ﬁnal goal of the multitarget tracking and localization algorithm is to obtain,
at any time step t, estimates of the states of the unknown number N of targets,
Xt = {X}t
n=1:N = {(xn, Sn)}t
n=1:N, where xn contains information on the
position, velocity, acceleration, etc. of target n, and Sn contains the information
on the target shape.
The K sensor measurements (cameras, laser range scanners, etc.) {yk}t
k=1:K
are preprocessed so that measurements originating from the environment are
removed or that all measurements yt
k are attributed a weight wt
k indicating
the probability that they do not originate from the environment:
wt
k ∼
P(yt
k /∈environment). In the vision community such operation is often referred
to as background subtraction, but it generalizes to all kind of sensors. The
measurement preprocessing step is not within the scope of this paper.
The low measurement clustering level groups the preprocessed measurement
weight pairs {(yk, wk)}t
k=1:K into M clusters, {(µm, Σm)}t
m=1:M. A cluster m
is deﬁned as a Gaussian with mean µm and covariance Σm.
The number
of clusters M is not known beforehand, but is automatically determined
from the data.
In the ideal case each cluster groups the measurements
originating from a single underlying target.
The correspondence variable
at
k = [ak1, ak2, . . . , akM]t uses a 1-of-M representation to indicate to which
cluster measurement yt
k is assigned. All but one of the elements of at
k are 0.
The non-zero element at
km indicates that measurement yt
k is assigned to cluster
m. The clustering uses information from the high data association and tracking
level, i.e. target positions and shapes of the current estimate, {(xn, Sn)}t
n=1:N,
as prior knowledge (see Section 5.3.2). Since the target positions and shapes at
the current time step t are still unknown, the prediction uses the target states

5.3 Two-level Tracking and Localization Algorithm
179
Sensors
Sensors
Measurement preprocessing
Measurement preprocessing
Measurement clustering
Measurement clustering
Data association and tracking
Data association and tracking
{yk}t
k=1:K
{yk}t+1
k=1:K
{(yk, wk)}t
k=1:K
{(yk, wk)}t+1
k=1:K
{(µm, Σm)}t
m=1:M
{(yk, ak)}t
k=1:K
{(µm, Σm)}t+1
m=1:M
{(yk, ak)}t+1
k=1:K
{(xn, Sn)}t
n=1:N
{(xn, Sn)}t+1
n=1:N
{(xn, Sn)}t
n=1:N
{(xn, Sn)}t
n=1:N
{(xn, Sn)}t+1
n=1:N
{(xn, Sn)}t+1
n=1:N
{(xn, Sn)}t−1
n=1:N
MTTL
time step t + 1
time step t
Figure 5.1: Information ﬂow for the proposed two-level multitarget tracking and localization (MTTL) algorithm. The
measurement preprocessing step is not within the scope of the paper. Section 5.3.1 explains the data ﬂow in more detail
and introduces all symbols.

180
Chapter 5
Shape-based Online MTTL
at the previous time step t −1 and a motion model to predict {(xn, Sn)}t
n=1:N
(see Section 5.3.3).
The clustering level realizes a signiﬁcant data reduction before proceeding to the
high level. The high-level data association step beneﬁts from the data reduction
by associating clusters of measurements {(µm, Σm)}t
m=1:M with the target
trackers instead of individual measurements.
The individual measurement
information is however not lost, each target tracker is updated with each
individual measurement yt
k and not with a processed ‘feature’ from the low
level.
The next sections detail the clustering level and the tracking level of the
proposed multitarget tracking and localization algorithm.
5.3.2
Measurement Clustering
Requirements
The clustering level groups the preprocessed measurement/weight pairs y =
{(yk, wk)}k=1:K in M clusters with positions µ = {µm}m=1:M and sizes Σ =
{Σm}m=1:M so that each cluster contains the measurements originating from
one underlying target2.
The clustering level should:
1. use information of previous target states and shapes (high-level informa-
tion),
2. delete clusters not needed to explain the measurements and detect
clusters not corresponding to any previous targets (a property referred to
as ﬂexibility further on),
3. scale well with the number of measurements, and
4. allow realtime execution,
while it need not handle the data association between measurements and targets
nor occlusions.
2Remark that in this section, for reasons of compactness of presentation, the superscript
with the time step t is omitted.

5.3 Two-level Tracking and Localization Algorithm
181
Algorithm
The goal of the clustering is to group the measurements into clusters and to
estimate the number of clusters M, the cluster locations µ, and the cluster
sizes Σ, given the measurements y. D is the dimension of the state space of
clustering, i.e. D = dim (y). The clustering problem is formulated as ﬁtting a
Gaussian mixture distribution to the measurements (Bishop 2006):
P(y | A, µ, Σ)
≈
M
X
m=1
AmN (y|µm, Σm) ,
(5.1)
with A = {Am}m=1:M the mixing coeﬃcients. In general it is not known to
which cluster m each of the measurements yk belongs. In that case estimating
the cluster locations µ and sizes Σ corresponds to maximizing the data log
likelihood (assuming independent measurements):
log P(y | A, µ, Σ)
=
K
X
k=1
wk log P(yk | A, µ, Σ) ,
(5.2)
=
K
X
k=1
wk log
M
X
m=1
AmN (yk|µm, Σm) .
(5.3)
Due to the presence of the sum after the logarithm, this maximization is
diﬃcult and it lacks a closed-form solution.
If however, the corresponding
clusters of each of the measurements were known, the solution would easily
be obtained in closed form. This suggests an expectation-maximization (EM)
approach (Bishop 2006) for estimating the cluster parameters. To this end, the
correspondence variables ak introduced before are used as latent (also known
as hidden) variables (see Figure 5.2). The probability that measurement yk
belongs to the mth cluster is represented by the elements Am of A, i.e.:
P(akm = 1) = Am,
(5.4)
where akm represents the mth element of the correspondence variable. The
conditional distribution of the latent correspondence variable giving the mixing
coeﬃcients is a multinomial distribution, and therefore the likelihood of the of
these correspondence variables can be written as:
P({ak}k=1:K | A)
=
K
Y
k=1
 M
Y
m=1
Aakm
m
!wk
.
(5.5)

182
Chapter 5
Shape-based Online MTTL
The conditional distribution of the measurements giving the latent correspon-
dence variable can be written as:
P(y | {ak}k=1:K , µ, Σ)
=
K
Y
k=1
 M
Y
m=1
N (yk|µm, Σm)akm
!wk
.
(5.6)
From Equations (5.5)-(5.6) the complete data log likelihood, i.e. the data log
likelihood over both data and the latent variables, optimized during the EM-
approach is:
log P(y, {ak}k=1:K | A, µ, Σ) ≈
K
X
k=1
wk log
 M
Y
m=1
(AmN (yk|µm, Σm))akm
!
.
(5.7)
Although the estimation problem still lacks a closed-form solution due to
the unknown correspondences ak, an EM approach can solve the problem
by iterating an expectation and a maximization step.
The expectation
step calculates an expectation for the correspondence variables ak, while
the maximization step computes the other model parameters Θ = (A, µ, Σ)
under these expectations by maximizing the complete-data log likelihood of
Equation (5.7).
This paper applies a variational Bayesian (VB) method instead of an EM
approach to solve the clustering. The VB method is a fully Bayesian approach
that allows us to integrate priors over the unknown parameters, making
automatic relevance detection possible as discussed further on. This Bayesian
approach integrates over the possible values of all uncertain quantities rather
than optimizing them as in the maximum likelihood (ML) approach of the EM
method (Beal 2003; Beal and Ghahramani 2003). The quantity that results
from integrating out or marginalizing both the latent variables {ak}k=1:K and
the parameters Θ is known as the marginal likelihood:
P(y) =
Z
P(y | {ak}k=1:K , Θ) P({ak}k=1:K , Θ) d({ak}k=1:K , Θ), (5.8)
where P({ak}k=1:K , Θ) is a prior over the latent variables and the model
parameters.
Unfortunately, computing the marginal likelihood, P(y), is
intractable.
The variational Bayesian method constructs a lower bound on
the marginal likelihood and optimizes this bound using an iterative scheme
that has similarities to the EM algorithm.
To make the optimization
tractable, the variational Bayesian method looks for the best distribution

5.3 Two-level Tracking and Localization Algorithm
183
yk
wk
ak
A
K
M
Σm
µm
α0
β0m
m0m
W0m
ν0m
Figure 5.2: Bayesian network model for clustering of measurements through
variational mixture of Gaussians. The boxes (plates) denote a set of K weighted
measurements and a set of M clusters. The shaded nodes are observed.
Q(a, Θ) within a restricted family of distributions. In this case it is assumed
that Q({ak}k=1:K , Θ) factorizes as Q({ak}k=1:K) Q(Θ).
Remark that no
approximation on the functional form of Q({ak}k=1:K) nor Q(Θ) is made.
We are still left with deﬁning the prior P({ak}k=1:K , Θ). The prior over the
latent variable a is conditionally dependent on the mixing coeﬃcients A and
is already deﬁned in Equation (5.5), while the prior over the model parameters
is factorized as:
P(Θ)
=
P(A, µ, Σ) = P(A) P(µ | Σ) P(Σ) .
(5.9)
Conjugate priors are deﬁned for the parameters, i.e. (i) a Dirichlet distribution
over the mixing coeﬃcients A:
P(A)
=
Dir(A|α0) ,
(5.10)
with α0 = {α0m}m=1:M, where α0m is a measure for the conﬁdence in the
prior on the cluster parameters of cluster m (i.e. the corresponding number of
‘prior’ observations associated with each component of the mixture), and (ii)
an independent Gaussian-Wishart prior over the mean and the precision, i.e.
the inverse of the covariance, of the Gaussian mixture components:
P(µ|Σ)P(Σ)=
M
Y
m=1
N
 µm|m0m, β0
−1
m Σm

W
 Σ−1
m |W0m, ν0m

.
(5.11)
Figure 5.2 shows the resulting Bayesian network representation for the
variational Bayesian cluster ﬁnder, including the prior parameters α0, β0 =
{β0m}m=1:M, m0
=
{m0m}m=1:M, W0
=
{W0m}m=1:M, and ν0
=
{ν0m}m=1:M using a Bayesian network representation with plates.

184
Chapter 5
Shape-based Online MTTL
Bishop 2006 gives a complete derivation of variational Bayesian cluster ﬁnding
for unweighted data points. This paper extends the algorithm so that it can
handle weighted data points (the preprocessed measurements {(yk, wk)}k=1:K).
The optimal factors Q⋆() resulting from maximizing the lower bound are:
Q⋆({ak}k=1:K)
=
QK
k=1
QM
m=1 rakm
km ,
Q⋆(A)
=
Dir(A|α) , and
Q⋆(µm, Σm)
=
N
 µm|mm, β−1
m Σm

W
 Σ−1
m |Wm, νm

,
(5.12)
with {rkm}m=1:M,k=1:K, α = [α1, . . . , αM]T , and {(Wm, mm, νm)}m=1:M as
calculated in Algorithm 5.1. rkm can be interpreted as the responsability that
cluster m takes for explaining measurement k (Bishop 2006). Remark that,
as a consequence of the choice of conjugate priors in Equations (5.5), (5.10),
and (5.11), the optimal factors have the same functional form as the priors
without making any additional assumptions. While Appendix 5.6.1 shows the
derivation of the variational Bayesian clustering of weighted measurements,
Algorithm 5.1 summarizes the resulting algorithm.
The VB cluster ﬁnder is a fully Bayesian approach; priors over the unknown
parameters are included, complex (overﬁtting) models are punished, and
a full probability distribution over the latent variables and parameters is
obtained. The VB estimator proposed here has only a small computational
overhead compared with a maximum likelihood estimator (Bishop 2006), while
it circumvents many problems associated with maximum likelihood (ML)
estimators (K-means, EM cluster ﬁnding, etc.)
such as overﬁtting (Bishop
2006). From the full probability distributions maximum a posteriori (MAP)
estimates can be obtained for the latent variables and parameters:
E[akm]
=
rkm,
(5.13)
E[µm]
=
mm,
(5.14)
E

Σ−1
m

=
νmWm, and
(5.15)
E[Akm]
=
αm
Mα0 + K .
(5.16)
Clustering Prior
This section explains how a prior enables the clustering to (i) automatically
determine the number of clusters, (ii) incorporate information from the tracking
level about target positions and shapes, and (iii) detect new targets.

5.3 Two-level Tracking and Localization Algorithm
185
Algorithm 5.1: Clustering level: variational Bayesian clustering of weighted
measurements
Data: {(yk, wk)}k=1:K,α0,β0,m0,W0,ν0
for m = 1 : M do // Initialize cluster parameters to prior values
1
αm = α0;
βm = β0m;
mm = m0m;
Wm = W0m;
νm = ν0m;
2
end
3
while convergence criterion not satisﬁed or maximum number of iterations
4
not exceeded do
forall {(yk, wk)}k=1:K do // E-step
5
for m = 1 : M do // loop over clusters
6
// calculate unnormalized responsability of cluster m
for measurement k (Ψ is the digamma
function (Abramowitz and Stegun 1965))
ρkm = exp
h
Ψ (αm) −Ψ
PM
s=1 αs

+ 1
2
PD
d=1

Ψ
  νm+1−d
2

7
+D log 2 + log |Wm| −1
2

D
βm + νm (yk −mm)T Wm (yk −mm)
i
;
end
8
η = PM
m=1 ρkm;
9
for m = 1 : M do // loop over clusters
10
// calculate normalized responsabilities
rkm = η−1wkρkm;
11
end
12
end
13
for m = 1 : M do // M-step
14
Km = PK
k=1 rkm;
15
¯ym =
1
Km
PK
k=1 rkmyk;
16
Sm =
1
Km
PK
k=1 rkm (yk −¯ym) (yk −¯ym)T ,;
17
αm = α0 + Km;
18
βm = β0m + Km;
19
mm =
1
βm (β0mm0m + Km¯ym);
20
νm = ν0m + Km;
21
W−1
m = W0
−1
m + KmSm + β0mKm
βm
(¯ym −m0m) (¯ym −m0m)T ;
22
end
23
end
24
return {αm, βm, mm, Wm, νm}m=1:M
25

186
Chapter 5
Shape-based Online MTTL
By including prior information, the variational Bayesian clustering enables
automatic relevance detection (ARD): the number of relevant clusters is
automatically determined from the data without resorting to ad-hoc or cross-
validation techniques. This means that the number of clusters M needs not be
known a priori.
To automatically determine the number of clusters M from the measurements,
the parameters α0m of the prior over the mixing coeﬃcients A in Equa-
tion (5.10) are chosen smaller than 1.
In this case the Dirichlet prior has
high probability for the boundaries of the simplex it is deﬁned on, i.e. in this
case high probabilities when a lot of mixing coeﬃcients are zero (Bishop 2006).
Thanks to this property, the clustering favours solutions in which some of
the mixing coeﬃcients are zero: i.e. favoring solutions with as few clusters
as possible to explain the data.
ARD makes the clustering level ﬂexible: the prior for the cluster parameters in
Equation (5.11) can contain a large number of clusters, since the VB clustering
determines the optimal number of clusters automatically.
In each step the
following clusters are hypothesized: (i) a cluster for each target detected at
the tracking level, (ii) a new cluster in the neighborhood of each target, and
(iii) a new cluster for each measurement unexplained by the clusters of (i) and
(ii). The ﬁrst set (i) of hypothesized clusters {m0m, W0m}m=1:N handles the
targets already being tracked: the positions and shapes of the targets at the
tracking level are used as prior for the cluster position and sizes:
m0m
=
fm0 (Xn)
W0m
=
fW0 (Xn)

for m = n = 1 : N,
(5.17)
where m0m and W0m are the positions and shapes of clusters approximating
the targets with states and shapes Xn = {(xn, Sn)}n=1:N. Examples of how
to get fm0 and fW0 for some target shapes are given in Section 5.6.2.
The second set (ii) {m0m, W0m}m=N+1:2N handles ‘splitting targets’:
two
targets previously perceived as a single target.
To this end clusters are
hypothesized at positions slightly perturbed from the positions of the targets
at the tracking level:
m0(N+m)
=
fm0 (Xn) + N (0, σr)
W0(N+m)
=
fW0 (Xn)

for m = n = 1 : N,
(5.18)
with N (0, σr) normally distributed noise to slightly perturb the cluster mean.
The third set (iii) {m0m, W0m}m=2N+1:M allows for detection of new targets.
To this end it is ﬁrst checked which measurements are not explained by
the clusters hypothesized so far ({m0m, W0m}m=1:2N).
The unnormalized
responsabilities ρkm calculated on line 7 of Algorithm 5.1 indicate how well

5.3 Two-level Tracking and Localization Algorithm
187
cluster m explains measurement yk. Therefore, η, the summed responsabilities
over the clusters (line 9, Algorithm 5.1) indicate how well the clusters explain
measurement yk. If η is lower than a given threshold ηthreshold, a new cluster
m with parameters:
m0m
=
g−1(yk),
W0m
=
Σ−1
0 ,
(5.19)
is hypothesized, with g the measurement function and Σ0 an initial cluster size.
Finally, the prior parameters β0 and ν0 are left to deﬁne. β0m is a measure for
the conﬁdence on the prior mean m0m, since the covariance of the Gaussian
distribution on the prior mean in Equation (5.11) is proportional to the inverse
of β0m. Therefore β0m can be chosen proportional to the uncertainty on the
high-level estimate of the position targets. ν0m is the degree of freedom of
the Wishart distribution on the precision Σ−1
m . Since the uncertainty on the
prior covariance will decrease when increasing ν0m, ν0m can be interpreted as
a measure for the conﬁdence on the cluster size.
Section 5.6.2 gives some examples of how to use the tracking level target info
to produce the prior for the cluster positions and sizes in Equation (5.17), i.e.
examples of fm0 and fW0.
Summary
The clustering level uses the target positions and shapes from the tracking
level to produce a prior for the variational Bayesian clustering, Equation
(5.17) (requirement 1, Section 5.3.2). By including new clusters hypothesizing
splitting targets, Equation (5.18) and new clusters based on unexplained
measurements, Equation (5.19), the clustering level is able to detect clusters
not corresponding to any previous target (requirement 2, Section 5.3.2)).
The proposed algorithm scales linearly with the number of measurements
(requirement 3, Section 5.3.2)). By limiting the number of iterations (line 4,
Algorithm 5.1), and the maximum number of clusters, the execution time
remains limited allowing realtime execution of the algorithm (requirement 4,
Section 5.3.2)).
5.3.3
Data Association and Tracking
Requirements
The high level of the multitarget tracking and localization algorithm, the
‘tracking level’, is responsible for tracking and detecting of new targets. To

188
Chapter 5
Shape-based Online MTTL
this end the tracking level should:
1. comprise data association to associate the measurements with the targets,
2. estimate the number of targets (detection),
3. estimate the target states and shapes (tracking),
4. be robust to occlusions, etc. and maintain correct identiﬁcation of targets,
5. beneﬁt from the preprocessing by the clustering level,
6. be realtime executable.
In general, tracking multiple targets requires estimating the joint probability
distribution of the states of all targets.
In this case the state space grows
exponentially with the number of targets, making the approach already
intractable for a limited number of targets.
One solution is factorizing the
joint distribution for the individual target states (Cox 1993; Schulz et al.
2003), resulting in independent trackers for the diﬀerent targets once the data
association problem is solved. This section (i) explains how the data association
problem is solved in this paper, (ii) shows how the individual target trackers
can be set up and maintained after solving the data association problem, and
(iii) explains how the algorithm tackles the varying number of targets.
Data Association for Multiple Measurements per Target
The data association introduced in this paper uses the principles of the joint
probabilistic data association ﬁlter (JPDAF) (Cox 1993).
At each time step t the JPDAF3 computes the probability that a measurement
yt
k is caused by target n:
ct
kn
=
X
θt∈Θt
kn
P
 θt | y1:t
,
(5.20)
with y1:t grouping all measurements up to time step t and θt a joint association
event.
A joint association event θt contains M→T associations uniquely
determining which measurement is assigned to which target:
i.e.
θt =
{rt
k}k=1:Kt. Θt
kn denotes the set of all joint association events θt that assign
measurement yt
k to target n: i.e. Θt
kn = {θt : rt
k = n ∈θt}.
3This paper uses the notation of Schulz et al. 2003, who derive the complete JPDAF.

5.3 Two-level Tracking and Localization Algorithm
189
To construct the set of possible joint association events it is generally assumed
that a measurement originates from a single target and that the target generates
only a single measurement. The algorithm proposed in this paper drops the
second assumption as the two-level approach allows us to take into account
multiple measurements per target. To this end all measurements in a cluster
are jointly assigned to a target. After this association the measurements are
individually processed by the algorithm avoiding the information loss caused
by summarizing the measurement information in ‘features’.
The posterior probability that the measurements in cluster m, i.e. yt
k for which
at
km = 1, are caused by target n is computed as:
ct
mn
=
X
θt∈Θtmn
P
 θt | y1:t
.
(5.21)
Variables θt and Θt
mn have a similar meaning as the corresponding variables in
Equation (5.20), but they assign clusters m=1:M to targets n=1:N instead
of measurements k=1:Kt to targets. The probabilities ct
mn are grouped per
cluster as:
ct
m
=

ct
m1, ct
m2, . . . , ct
mN
	
.
(5.22)
Under the Markov assumption, i.e. assuming that Xt−1 contains all mea-
surement information y1:t−1 up to time t −1, the probability P
 θt | y1:t
is
calculated incrementally as (Schulz et al. 2003):
P
 θt | y1:t
≈α
Z
P
 yt | θt, Xt
P
 θt | Xt
P
 Xt | y1:t−1
dXt,
(5.23)
with α a normalizer, and P
 θt | Xt
assumed to be uniformly distributed (Schulz
et al. 2003). P
 yt | θt, Xt
is the probability of the measurements yt given the
state of the targets Xt and the speciﬁc data associations deﬁned by θt. This
probability has to take into account the case that a cluster of measurements is
not caused by any of the targets. Such cluster of measurements is called a false
alarm. The probability of a false alarm is assumed to be ﬁxed and indicated
with γ; the number of false alarms in an association event θt is M t
f. Assuming
that all measurements are independent (given the target states) P
 yt | θt, Xt
becomes:
P
 yt | θt, Xt
=
γMt
f
Y
(m,n)∈θt
Y
k:at
km=1
Z
P
 yt
k | Xt
n

P
 Xt
n | y1:t−1
dXt
n.
(5.24)

190
Chapter 5
Shape-based Online MTTL
Inserting Equations (5.23)-(5.24) into Equation (5.21) gives:
ct
mn ∝
X
θt∈Θt
mn

γMt
f Y
(m,n)∈θt
Y
k:at
km=1
Z
P
 yt
k | Xt
n

P
 Xt
n | y1:t−1
dXt
n

,
(5.25)
where P
 yt
k | Xt
n

is the measurement model and P
 Xt
n | y1:t−1
is obtained
during the prediction step of the target tracker as explained in Equation (5.26).
If the underlying densities are assumed Gaussian the above equation leads to a
data association algorithm very similar to the JPDAF (Cox 1993; Bar-Shalom
et al. 2009), while if the underlying distributions are modeled as Monte Carlo
distributions equations similar to the sample-based joint probabilistic data
association (SJPDAF) are obtained (Schulz et al. 2003). In Equation (5.25),
the number of associations grows exponentially with the number of clusters
(typically much smaller than the number of measurements) and the number
of targets. Gating is applied to limit the computation time (Bar-Shalom and
Fortmann 1988). Furthermore, Murty’s algorithm (Murty 1968) allows us to
determine the k-best hypothesis in a time linear with k.
Target Tracking
After solving the data association the individual targets have to be updated
to obtain P
 Xt
n | y1:t
. Figure 5.3 shows the Bayesian network representation
of the target tracker. In the Bayesian ﬁltering framework the update of the
targets is separated in a prediction step, using the process model of the target,
and a correction step, using the measurement model. The prediction equation
is:
P
 Xt
n | y1:t−1
=
Z
P
 Xt
n | Xt−1
n

P
 Xt−1
n
| y1:t−1
dXt−1
n
,
(5.26)
with P
 Xt−1
n
| y1:t−1
the target belief of the previous time step and
P
 Xt
n | Xt−1
n

the target process model. If xn and Sn are assumed to evolve
independently, the process model becomes:
P
 Xt
n | Xt−1
n

= P
 xt
n | xt−1
n

P
 St
n | St−1
n

,
(5.27)
with P
 xt
n | xt−1
n

the target motion model, and P
 St
n | St−1
n

the target shape
update model.
Using appropriate motion models for the individual targets
helps to track targets, even during occlusions.

5.3 Two-level Tracking and Localization Algorithm
191
...
...
...
...
yt−1
k
yt
k
yt+1
k
rt−1
rt
rt+1
M t−1
M t
M t+1
N
xt−1
n
xt
n
xt+1
n
St−1
n
St
n
St+1
n
Figure 5.3: Underlying Bayesian network model for the target tracker at the
high level. The boxes (plates) denote a set of M t−1, M t and M t+1 clusters
and a set of N targets. The shaded nodes are observed.
In the correction step the predicted target belief P
 Xt
n | y1:t−1
is updated
with the current measurement information yt:
P
 Xt
n | y1:t
∝P
 yt | Xt
n

P
 Xt
n | y1:t−1
.
(5.28)
Since the data association is uncertain, the data association variables are
integrated out by assigning the individual measurements yt
k to target n with
probability ct
(m:at
km=1)n as deﬁned in Equation (5.21):
P
 yt | Xt
n

=
X
k=1:K
ct
(m:at
km=1)nP
 yt
k | Xt
n

,
(5.29)
with P
 yt
k | Xt
n

the measurement model. The standard JPDAF (Cox 1993)
models the underlying densities as Gaussians, in which case the ﬁltering
equations of Equations (5.26)-(5.29) give rise to an extended Kalman ﬁlter
attached to each of the targets. The sample-based Joint Probabilistic Data
Association Filter (SJPDAF) (Schulz et al.
2003) models the underlying

192
Chapter 5
Shape-based Online MTTL
...
...
M t−1
M t
M t+1
N t−1
N t
N t+1
Figure 5.4: Bayesian network model for the estimator of the number of targets.
The shaded nodes are observed.
densities as Monte Carlo distributions, in which case the ﬁltering equations
of Equations (5.26)-(5.29) give rise to a particle ﬁlter attached to each of the
targets.
Varying Number of Targets
The JPDAF assumes that the number of targets N to be tracked is ﬁxed and
known. Schulz et al. 2003 extend the JPDAF to allow for a varying number of
targets over time. They additionally maintain a distribution for the number of
targets. This paper adopts the same approach, but the input for the algorithm
is the number of clusters M, rather than the number of features. Figure 5.4
shows the Bayesian network of the estimator for the number of targets. The
recursive update procedure for the number of targets is:
P
 N t | M 1:t
∝
P
 M t | N t X
n

P
 N t | N t−1= n

P
 N t−1= n | M 1:t−1
,
(5.30)
where N t indicates the number of targets at time t and M 1:t groups all numbers
of clusters up to time t. P
 N t | N t−1= n

is the process model describing how
the number of targets is expected to change over time. The appearance of a new
target and the disappearance of a tracked target is often modeled as a Poisson
process. P(M t | N t) is the measurement model representing the probability of
observing M t clusters, if there are actually N t targets in the perceptual ﬁeld
of the sensor. This probability distribution can be learned from observed or
simulated data (Schulz et al. 2003). To adapt the number of trackers, the
maximum a posteriori estimate of P
 N t | M 1:t
is used (Schulz et al. 2003).
If the algorithm decides that the number of targets increases, a new target

5.4 Experiments
193
tracker is started. To initialize the target, the position and size of the most
unexplained cluster of measurements, (µm, Σm) is used. A measure for how
well the targets explain cluster m is:
ct
m =
X
n=1:N t
ct
mn,
(5.31)
therefore argmin
m
ct
m is the most unexplained cluster.
On the other hand, if the algorithm estimates a decrease in the number of
targets, the target tracker with the largest covariance is deleted. An alternative
approach is to estimate the tracking performance and to delete the tracker with
the lowest tracking performance (Schulz et al. 2003).
Summary
The tracking level factorizes the joint distribution for the individual target
states.
After solving the data association problem, a separate ﬁlter is
maintained for every target (requirement 3, Section 5.3.3).
The number
of targets is estimated online from the number of clusters as explained in
Section 5.3.3 (requirement 2, Section 5.3.3).
The data association between
cluster of measurements and targets is handled through joint probabilistic
data association (requirement 1, Section 5.3.3). The tracking level can handle
occlusions by adopting appropriate motion models for the individual trackers
of the JPDAF and the SJPDAF (requirement 4, Section 5.3.3). Schulz et al.
2003 showed that a sample-based variant of the JPDAF is more robust for
tracking multiple persons thanks to the underlying particle ﬁlter approach.
The tracking level beneﬁts from the clustering level since (i) it allows us
to handle multiple measurement per target and (ii) reduces the number of
associations to be calculated (Equation (5.25)) (requirement 5, Section 5.3.3).
To make the algorithm realtime executable (requirement 6, Section 5.3.3)
gating (Bar-Shalom and Fortmann 1988) and Murty’s algorithm (Murty 1968)
should be applied for the data association problem.
5.4
Experiments
This section presents experiments for two sensors (video and laser scanner), for
diﬀerent types of targets, and for both localization and tracking. As mentioned
in Appendix 5.6.3, the experimental data, the software, and the property ﬁles
for the experiments are available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.

194
Chapter 5
Shape-based Online MTTL
5.4.1
Localization and Tracking of People using Laser Scanner
The goal of this experiment is to show the tracking and localization capabilities
of the algorithm.
The experimental setup consists of a natural oﬃce
environment populated by people. The sensor is a Sick laser scanner (range 8m),
ﬁxed with respect to the environment. During the experiment, one person is
standing still somewhere in the middle of the oﬃce (this is no restriction, just
a means of validation). During the experiment two other persons enter the
room and walk around at random (no instructions were given), resulting in a
maximum of three targets.
Measurement Preprocessing
The measurement preprocessing (see Figure 5.1)
consists of a simple continuous Bayes ﬁlter, estimating the probability that the
measurements from the Sick laser scanner do not originate from the (in this
case prerecorded) environment: wk ∼P(yk /∈environment). The prerecorded
environment consists of a set of distance measurements denv(b) along the
diﬀerent beams b = 1 : B of the laser scanner. The probability that a laser
measurement yk consisting of a distance dk measurement along beam bk does
not originate from the environment is then calculated as:
P(yk /∈environment)
=
1 −P(yk ∈environment)
(5.32)
=
1 −P(dk, bk | denv(1 : B)) ,
(5.33)
=
1 −N(denv(bk), σenv),
(5.34)
where σenv is a measure for the uncertainty on the prerecorded environment.
The preprocessed measurements are fed to the two-level multitarget tracking
and localization algorithm.
Modeling
A person is modeled as a cylindrically shaped object, resulting
in a circular cross-section with the laser’s scanning plane.
A person’s
motion is modeled using a constant velocity model.
Hence xn contains
the person’s position and velocity in the laser’s scanning plane:
xn
=
 xn
vxn
yn
vyn
T . The motion model is:
P
 xt
n | xt−1
n

=
N
 fmotion
 xt
n

, Σmotion

,
(5.35)

5.4 Experiments
195
 5
0
5
0
2
4
6
8
environment
sensor range
laser scanner
target 1
target 2
target 3
x[m]
y[m]
(a) Estimated target positions
5
0
5
0
2
4
6
8
environment
sensor range
laser scanner
cluster positions
x[m]
y[m]
(b) Estimated cluster positions
Figure 5.5: Estimation results for the experiment with laser scanner in natural
environment populated by three persons. Figure 5.5(a) shows the high-level
estimate of the trajectories of the three targets, Figure 5.5(b) shows the low-
level estimate of the cluster positions.

196
Chapter 5
Shape-based Online MTTL
10
20
30
40
50
60
70
0.0
0.5
1.0
1.5
2.0
2.5
3.0
# of clusters M
# of targets N
number of . . .
time[s]
Figure 5.6: Estimation results for the experiment with laser scanner in natural
environment populated by three persons:
this ﬁgure shows the low-level
estimate of the number of clusters and the high-level estimate of the number
of targets as a function of time.
with:
fmotion
 xt
n

=


1
∆t
0
0
0
1
0
0
0
0
1
∆t
0
0
0
1




xt−1
n
vt−1
xn
yt−1
n
vt−1
yn

, and
(5.36)
Σmotion
=
σ2
motion
 GT G
02×2
02×2
GT G

,
(5.37)
where G
=
h
∆t2
2!
∆t
i
and σmotion is a measure for the unmodeled
acceleration. Hence the shape Sn corresponds to a circle with radius R. The

5.4 Experiments
197
shape is assumed to be static and known:
P
 St
n | St−1
n

=
δ
 St−1
n

,
(5.38)
with δ the Dirac function. Finally, a simple Gaussian measurement model is
used that represents the measurements as a noisy cloud around the target’s
position:
P(yk | Xn)
=
P
 xlaser + dk cos(θ(bk))
ylaser + dk sin(θ(bk))

| Xn

(5.39)
=
N (Xn, Σmeas) ,
(5.40)
with (xlaser, ylaser) the position of the laser scanner in the world, θ(bk) the
angle of the beam bk with the x-axis and Σmeas the Gaussian measurement
noise. More advanced measurement models making explicit use of the target
shape Sn can be easily used.
In this experiment the prior for the variational Bayesian clustering does not
make explicit use of the target shapes. Simple circular clusters are hypothesized
with ﬁxed radius as explained in Appendix 5.6.2.
Results
Figures 5.5(a) to 5.6 show the experimental results. Figure 5.5(a)
shows the estimated trajectories of the three targets, Figure 5.5(b) shows the
estimated cluster positions, and Figure 5.6 shows the number of clusters and
the estimated number of targets as a function of time.
The number of clusters is automatically determined from the data.
The
measurements from targets entering the sensor range are immediately grouped
in a new cluster. This results for instance in the immediate detection at the
ﬁrst time step of the target standing still (see Figure 5.6), although the prior
of the proposed algorithm does not contain any targets: i.e. the prior estimate
is N = 0.
As a target is occluded it does not produce any measurements
resulting in an occasional decrease in the number of clusters in Figure 5.6.
Since the estimated number of targets (tracking level) does not decrease during
the occlusions, as shown in Figure 5.6, the tracking level is still capable of
tracking the targets during occlusions. If a new target enters the scene (around
8s and 17s), the number of clusters increases. If this increase turns out to
be persistent the number of estimated target increases a few time steps later
and a new target tracker is automatically started at the location of the most
unexplained cluster (Equation (5.31)).
If a target leaves the scene (around
65s and 67s), the number of clusters decreases, the estimated number of
targets decreases and the tracker with the largest covariance is deleted. Color

198
Chapter 5
Shape-based Online MTTL
ﬁgures and videos, including a 3D Blender visualization are available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.
5.4.2
Missed Detections and Close Interactions
To investigate the algorithm’s robustness to missed detections and close target
interactions the algorithm was applied to a Sick laser range data set recorded
by Khan et al. 2006, available at http://www.kinetrack.org/. To show the
robustness to missed detections only the data from a single laser scanner was
used, which is reported as the toughest situation for a tracking system (Khan
et al. 2006). Five people were asked to occasionally bump into each other to
introduce close interactions. For the data set consisting of 4752 scans, a human
observer counted 164 missed interactions. A missed detection is deﬁned as an
event where all of the measurements accounting for a single target disappeared
for several scans. This paper compares the results of the proposed algorithm
with the tracking algorithm of Khan et al.
2006, referred to as the GIT
algorithm further on.
Measurement Preprocessing
From the available Sick laser range data the
background had already been subtracted to remove stationary objects from
the environment (Khan et al. 2006).
Modeling
The modeling is the same as in Section 5.4.1.
To make a fair
comparison with the GIT algorithm, the target motion was also modeled using
a constant velocity model.
Results
The proposed algorithm looses track of a target once throughout
the entire sequence, resulting in a success rate of 99.39%.
The algorithm
automatically recovers from the missed detection. Our algorithm outperforms
the GIT algorithm, which failed 15 times, resulting in a success rate of 90.85%.
Figure 5.7 shows the number of clusters detected at the low level and the
number of estimated targets as a function of the scan number.
The ﬁgure
shows that people are often occluded, resulting in a decrease of the number of
clusters found by the low level. Incomplete background subtraction resulting in
a group of laser measurements not being removed or a single target perceived as
two targets, results in a higher than expected number of clusters. The number
of people estimated by the high level is however not aﬀected by occasional
ﬂuctuations in the number of clusters.
Only after a persistent change, the
number of estimated people changes. Figure 5.10 shows the targets and clusters
for scan number 891, where two targets are occluded.

5.4 Experiments
199
0
1000
2000
3000
4000
5000
0
1
2
3
4
5
6
7
8
number of ... 
# of clusters M
# of targets N
scan number
Figure 5.7: Estimation results for tracking of ﬁve people: the ﬁgure shows the
low-level estimate of the number of clusters and the high-level estimate of the
number of targets as a function of the scan number.
During four time slots, our algorithm detected more than the ﬁve people
who where actually present in the environment.
This is due to incomplete
background subtraction resulting in a group of laser measurements not being
removed as shown in Figure 5.8. If this behavior is persistent during multiple
laser scans, the algorithm adds a target to explain the measurements. This
extra tracker is however automatically deleted when the measurements due to
incomplete background subtraction disappear.
Figure 5.9 shows that the proposed algorithm is able to track the targets during
close interactions.
Once during the entire sequence a target is not correctly tracked. While the
target is occluded another target in its neighborhood is perceived as a double
target since this target produces two clusters of laser scan measurements.
Therefore, the tracker believes the target has changed location and switches
to one of the clusters of the double target. After the double target is again

200
Chapter 5
Shape-based Online MTTL
22
24
26
28
30
32
34
36
x[m]
0
2
4
6
8
10
12
14
y[m]
targets
measurements
target 1 covariance
target 1
target 2 covariance
target 2
target 3 covariance
target 3
target 4 covariance
target 4
target 5 covariance
target 5
target 10 covariance
target 10
22
24
26
28
30
32
34
36
x[m]
0
2
4
6
8
10
12
14
y[m]
clusters
measurements
cluster 1
cluster 2
cluster 3
cluster 4
Figure 5.8: Estimation results of laser scan 3820. The left plot shows the high-level estimate of the targets trajectories
from laser scan 3620 up to 3820 together with the measurements, while the right plot shows the low-level clusters together
with the measurements. Due to persistent incomplete background subtraction, the algorithm adds a target at position
(23,9.2) to explain the measurements. This extra tracker is however automatically deleted when the measurements due
to incomplete background subtraction disappear.

5.4 Experiments
201
27
28
29
30
31
32
33
34
35
x[m]
2
3
4
5
6
7
8
9
10
y[m]
targets
measurements
target 1 covariance
target 1
target 2 covariance
target 2
target 3 covariance
target 3
target 4 covariance
target 4
target 5 covariance
target 5
27
28
29
30
31
32
33
34
35
x[m]
2
3
4
5
6
7
8
9
10
y[m]
clusters
measurements
cluster 1
cluster 2
cluster 3
cluster 4
cluster 5
Figure 5.9: Estimation results of laser scan 968. The left plot shows the high-level estimate of the targets trajectories
from laser scan 768 up to laser scan 968 together with the measurements, while the right plot shows the low-level clusters
together with the measurements. The algorithm is able to distinguish and track the targets even during close interactions.

202
Chapter 5
Shape-based Online MTTL
27
28
29
30
31
32
33
34
35
x[m]
2
3
4
5
6
7
8
9
10
y[m]
targets
measurements
target 1 covariance
target 1
target 2 covariance
target 2
target 3 covariance
target 3
target 4 covariance
target 4
target 5 covariance
target 5
27
28
29
30
31
32
33
34
35
x[m]
2
3
4
5
6
7
8
9
10
y[m]
clusters
measurements
cluster 1
cluster 2
cluster 3
Figure 5.10: Estimation results of laser scan 891. The left plot shows the estimated targets together with the measurements,
while the right plot shows the low level clusters together with the measurements. The algorithm is able to track all targets
even though two targets are occluded.

5.4 Experiments
203
correctly perceived as a single target, the tracker automatically recovers and
starts tracking the correct target again.
Color ﬁgures and video, including a 3D Blender visualization, are available
online at http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.
5.4.3
Occlusions
To investigate the algorithm’s robustness to partial and full occlusions a video
of ants recorded by the Georgia Institute of Technology College of Computing
(Khan et al.
2006) is used, available at http://www.kinetrack.org/.
In
the video a colony of Leptothorax curvinoposis ants is in the process of nest
emigration. The artiﬁcial nest located in the ﬁeld of view consists of a cavity
constructed out of balsa wood and top covered by a pane of glass. Ants may
enter the nest at the entrance at the top of the image, but they may also walk
on the glass cover. As a result, there are two planes in which ants may move:
the top glass and the ﬂoor of the nest cavity. The algorithm should be robust to
occlusions, partial and full, caused by the ants moving over one another. This
section compares the results for the video sequence of the proposed algorithm
with the GIT algorithm (Khan et al. 2006).
Measurement Preprocessing
A simple procedure as proposed by Khan
et al.
2006 was used where image pixel thresholds are applied to obtain
ant measurements.
The original images were blurred and down sampled.
Next pixels within the following YUV ranges were considered as detections:
39 < Y < 101, 116 < U < 125 and 128 < V < 136.
Modeling
The ant’s motion is modeled as a constant velocity model:
therefore xn contains the ant’s position and velocity in the image: xn =
 xn
vxn
yn
vyn
T . To make a fair comparison with the GIT algorithm,
the target motion was also modeled using a constant velocity model (Equa-
tion (5.35)).
The ant’s shape Sn is modeled as an ellipse with equatorial radii l1 and l2.
The ant’s shape is assumed to be static and known as in Equation (5.38). A
simple Gaussian measurement model is used that represents the measurements
consisting of the pixel coordinates (uk, vk) as a noisy cloud around the target’s
position:
P(yk | Xn)
=
P

uk
vk

| Xn

= N (Xn, Σmeas) ,
(5.41)

204
Chapter 5
Shape-based Online MTTL
2
3
4
5
6
0
1
2
3
4
Tracks of ants
100 pixels
100 pixels
target 1
target 2
target 3
target 4
target 5
target 6
target 7
target 8
(a) Estimated trajectories of the ants.
0
20
40
60
80
100
120
140
0
2
4
6
8
10
number of ... 
number of objects N 
number of clusters M 
frame number
(b) Low-level estimate of number of clusters and high-level estimate of
number of targets.
Figure 5.11: Estimation results for tracking of ants: Figure (a) shows the
estimated trajectories of the ants, and Figure (b) shows the low-level estimate
of the number of clusters and the high-level estimate of the number of targets
as a function of the frame number.

5.4 Experiments
205
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
targets before crossing
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
clusters before crossing
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
targets during crossing
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
clusters during crossing
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
targets after crossing
1.5
2.0
2.5
3.0
3.5
2.0
2.5
3.0
3.5
4.0
clusters after crossing
target 1
target 1
target 1
target 2
target 2
target 2
target 3
target 3
target 3
target 4
target 4
target 4
target 5
target 5
target 5
target 6
target 6
target 6
target 7
target 7
target 7
target 8
target 8
target 8
cluster 1
cluster 1
cluster 1
cluster 2
cluster 2
cluster 2
cluster 3
cluster 3
cluster 3
cluster 4
cluster 4
cluster 4
cluster 5
cluster 5
cluster 5
cluster 6
cluster 6
cluster 6
cluster 7
cluster 7
cluster 8
measurements
measurements
measurements
measurements
measurements
measurements
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
100 pixels
Figure 5.12: Occlusion event during ants tracking. Two ants pass over one other creating an occlusion. The algorithm
succesfully tracks the ants through the occlusion. During the occlusion, the covariance of the occluded target increases
as can be seen in the top middle ﬁgure.

206
Chapter 5
Shape-based Online MTTL
with Σmeas the Gaussian measurement noise. Again, more advanced measure-
ment models making explicit use of the target shape Sn can be easily used.
In this experiment the prior for the variational Bayesian clustering makes use
of the ant’s shape. If the ant’s orientation is also included in the state (not
included here to compare with GIT) the procedure explained in Section 5.6.2
and more speciﬁcally in Equation (5.67) can be used.
Since the target’s
orientation is unknown however, the circumscribed circle is used as a prior
for the clusters, i.e. a circle with radius R = max (l1, l2).
Results
The algorithm is not provided with the knowledge of the initial ants
positions and the number of ants. The number of ants in the environment is
estimated online.
Figure 5.11(a) shows the estimated tracks of the eight ants. The algorithm is
able to track all ants, even during occlusions.
Figure 5.11(b) shows the number of clusters and the number of estimated ants
as a function of the frame number. The ﬁgure shows that the ants are often
occluded, resulting in a decrease of the number of clusters detected at the low
level. The number of ants estimated by the high level is however not aﬀected
by occasional ﬂuctuations in the number of clusters. Only after a persistent
change, the number of estimated ants changes. At the beginning of the video
sequence the algorithm detects only six of the eight ants present in the scene
since two ants initially do not produce enough measurements (only three pixels)
to create a cluster. At frame 18 however, these ants produce more pixels and
two ﬁlters are automatically started to track them.
Figure 5.12 shows the occlusion event in the video sequence.
Two targets
pass over another creating an occlusion. The algorithm successfully tracks the
targets through this occlusion, as did the GIT algorithm. In contrast to the
GIT algorithm, the number of ants was automatically determined from the
data and not assumed known.
Color ﬁgures and video, including one with estimation results overlaid on the
original video, are available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.
5.5
Discussion
This paper proposed a novel online two-level multitarget tracking and
localization (MTTL) algorithm.
The clustering level consists of a fast and
ﬂexible estimator for clusters of measurements, while the tracking level is

5.5 Discussion
207
a powerful data association level allowing for a varying number of targets.
Information is exchanged in both directions between the two levels.
In
contrast to many MTTL algorithms, the proposed algorithm does not require to
preprocess the measurements so that summarizing features (one per target) are
fed to the MTTL algorithm. The algorithm proposed in this paper allows us to
use multiple measurements for a single target preventing information loss. The
proposed algorithm furthermore uses the target shape to cluster measurements
and to update the individual target trackers. Using the target shape info helps
to distinguish between interacting targets. The distinguishing characteristics
can even be improved by individualizing the target shapes.
The proposed
algorithm correctly detects entering and leaving targets and obtains a record
of the trajectories of targets over time, maintaining a correct identiﬁcation for
each target throughout.
The algorithm was veriﬁed using two sensor modalities, video and laser scanner,
for people and ants tracking and localization.
The proposed algorithm has similar capabilities as the MCMC-based ﬁlter
developed by Khan et al.
2006, since this algorithm is also capable of
handling multiple measurements per target.
There are however a number
of diﬀerences in the underlying approach: (i) the proposed algorithm builds
multiple instantiations of a single target tracker, while the MCMC-based
ﬁlter (Khan et al. 2006) works in the joint state space of target states and
data association variables; (ii) to overcome the exponential complexity typical
of ﬁlters operating in the joint space, the Markov chain is Rao-Blackwellized
to eliminate sampling over the continuous space of targets. To this end the
MCMC-ﬁlter assumes linear Gaussian motion and measurement models. In
contrast, the proposed algorithm is not limited to linear Gaussian motion and
measurement models. The high level allows us to attach either a Kalman or
a Monte Carlo ﬁlter to the individual targets; (iii) the MCMC-ﬁlter is not
extended to handle a varying number of targets, while the proposed algorithm
keeps a separate ﬁlter to estimate the number of targets online. This paper
compared the performance of the proposed two-level MTTL algorithm with
the MCMC-based ﬁlter by applying the former to data sets, which are freely
available and used to validate the latter. The proposed algorithm outperformed
the MCMC-based ﬁlter on the laser scanner data of people, while it has similar
performance for the video data of ants during nest emigration.
The proposed algorithm could still be improved in some aspects. First, the
low-level clustering ﬁts a Gaussian mixture distribution to the measurements.
Therefore, it is implicitly assumed that the measurements form ‘blobs’. Second,
the high-level data association only associates a single cluster of measurements
with a target. Therefore, the high level is limited to targets causing a single
‘blob’ of measurements. Reasoning about compound objects, such as the two
legs of a single persons, remains to be done.

208
Chapter 5
Shape-based Online MTTL
Future work consists of (i) exploring the capabilities of the proposed algorithm
for using target shape info, i.e. updating the shape model for individual
targets, using Gaussian processes to describe the probabilistic target shape,
etc.; (ii) using a more advanced measurement model for laser scanning to
include information about occlusions (De Laet et al.
2008); (iii) extending
the high level such that compound targets, i.e. targets causing multiple blobs
of measurements, can be handled; and (iv) adding a level to reason about
group behavior.
Reasoning about group behavior has multiple advantages:
(i) tracking groups can help the multitarget tracking when targets cannot be
separated as individuals (Gennari and Hager 2004), (ii) tracking groups is more
eﬃcient than tracking people separately (Lau et al. 2009) and (iii) a suitable
motion model for the high level can be deducted from the group behavior (e.g.
people queueing, talking, walking together, etc.).

5.6 Appendices
209
5.6
Appendices
5.6.1
Measurement Clustering through Weighted Variational
Bayesian Clustering
The variational Bayesian method constructs a lower bound on the marginal
likelihood of Equation (5.8) and optimizes this bound using an iterative
scheme that has similarities to the EM algorithm. To make the optimization
tractable, the variational Bayesian method looks for the best distribution
Q(a, Θ) within a restricted family of distributions. In this case it is assumed
that Q({ak}k=1:K , Θ) factorizes as Q({ak}k=1:K) Q(Θ).
Remark that no
approximation on the functional form of Q({ak}k=1:K) nor Q(Θ) is made.
Using the theory of variational calculation with factorized distributions, the
optimal factors are given by:
log Q⋆({ak}k=1:K) = EA,µ,Σ[log (P(y, {ak}k=1:K , A, µ, Σ))] + Cte, (5.42)
log Q⋆(A, µ, Σ) = E{ak}k=1:K[log (P(y, {ak}k=1:K , A, µ, Σ))] + Cte. (5.43)
During the variational optimization, the caculation of the optimal factor
over the hidden variables of Equation (5.42) and over the parameters of
Equation (5.43) are iterated until convergence.
The optimal factor over the hidden variables of Equation (5.42) is calculated
during the variational E-step :
log Q⋆({ak}k=1:K)
=
EA[log P({ak}k=1:K | A)] +
Eµ,Σ[log P(y | {ak}k=1:K , µ, Σ)] + Cte,
(5.44)
=
K
X
k=1
wk [akm log ρkm] ,
(5.45)
with
ρkm = E[Am] + 1
2E

log |Σ−1
m |

−1
2 log (2π)
−1
2Eµm,Σ−1
m
h
(yk −µm)T Σ−1
m (yk −µm)
i
,
(5.46)

210
Chapter 5
Shape-based Online MTTL
and
E[Am]
=
ψ (αm) −ψ
 M
X
s
αs
!
,
(5.47)
E

log |Σ−1
m |

=
D
X
d=1
σ
νm + 1 −d
2

+ D log 2 + log |Wm|, and (5.48)
Eµm,Σ−1
m
h
(yk −µm)T Σ−1
m (yk −µm)
i
=
Dβ−1
m + νm (yk −µm)T Wm (yk −µm) ,
(5.49)
with ψ the digamma function (Abramowitz and Stegun 1965) and D the
dimension of the state space of clustering, i.e. D = dim (y).
Therefore
Q⋆({ak}k=1:K) is a multinomial distribution:
Q⋆({ak}k=1:K)
=
K
Y
k=1
 M
Y
m=1
rakm
km
!wk
,
(5.50)
where rkm =
ρkm
PM
s=1 ρkm can be interpreted as the responsability that cluster
m takes for explaining measurement k, i.e. E[akm] = rkm.
From the
responsabilities three statistics are deﬁned that are useful to calculate the
optimal factors over the parameters:
Km
=
K
X
k=1
wkrkm,
(5.51)
¯ym
=
1
Km
K
X
k=1
wkrkmyk, and
(5.52)
Sm
=
1
Km
K
X
k=1
wkrkm (yk −¯ym) (yk −¯ym)T ,
(5.53)
with Km the eﬀective number of measurements associated with cluster m, and
¯ym and Sm the mean and covariance of the measurements associated with
cluster m, respectively.
The optimal factor over the parameters of Equation (5.43) is calculated during
the variational M-step using the conjugate priors as deﬁned in Equations (5.10)

5.6 Appendices
211
and (5.11):
log Q⋆(A, µ, Σ) = log P(A) +
M
X
m=1
log E[log P({ak}k=1:K | A)]
|
{z
}
log Q⋆(A)
+
P
 µm, Σ−1
m

+
K
X
k=1
wk
M
X
m=1
E[akm] log N (yk|µm, Σm)
|
{z
}
log Q⋆(µ,Σ)
+Cte,
(5.54)
which, as already indicated above, induces a factorization of Q⋆(A, µ, Σ) as
Q⋆(A) Q⋆(µ, Σ). The optimal factor over the mixture weights can be written
as:
log Q⋆(A) = (α0 −1)
M
X
m=1
log Am +
K
X
k=1
wk
M
X
m=1
rkm log Am + Cte, (5.55)
whereby Q⋆(A) is shown to be Dirichlet distributed:
Q⋆(A)
=
M
Y
m=1
Aαm−1
m
,
(5.56)
with
αm = α0 +
K
X
k=1
rkmwk = α0 + Km.
(5.57)
The optimal factor over the cluster means and covariances can be written as:
log Q⋆(µ, Σ) =
M
X
m=1

log P
 µm | Σ−1
m

P
 Σ−1
m

+
K
X
k=1
wk
M
X
m=1
rkm log N (yk|µ, Σ) + Cte,
(5.58)

212
Chapter 5
Shape-based Online MTTL
hereby showing that Q⋆(µ, Σ) factorizes over the diﬀerent clusters, i.e.:
Q⋆(µ, Σ) = QM
m=1 Q⋆(µm, Σm), with
log Q⋆(µm, Σm) = log

N
 µm|m0m, β0
−1
m Σm

W
 Σ−1
m |W0m, ν0m

+
K
X
k=1
wkrkm log N (yk|µm, Σm) + Cte.
(5.59)
By inspecting the above equation and reading oﬀthe terms that involve µm
and Σm, Q⋆(µm, Σm) can be written as a Gaussian-Wishart distribuation:
Q⋆(µm, Σm)
=
N
 µm|mm, β−1
m Σm

W
 Σ−1
m |Wm, νm

,
(5.60)
where
βm
=
β0m + Km,
(5.61)
mm
=
1
βm
(β0mm0 + Km¯ym) ,
(5.62)
νm
=
ν0m + Km, and
(5.63)
W−1
m
=
W0
−1
m + KmSm + β0mKm
βm
(¯ym −m0m) (¯ym −m0m)T. (5.64)
Algorithm 5.1 summarizes all equations needed for weighted variational
Bayesian clustering.
5.6.2
Examples of Using Target Shape Info in Prior
This appendix gives some examples of how to use the tracking level target info
to produce the prior for the cluster positions and sizes in Equation (5.17), i.e.
examples of fm0 and fW0.
The prior for the clusters hypothesized to handle splitting targets are
straightforwardly determined from Equation (5.18) once fm0 and fW0 are
known.
No shape info
In case no shape info on the high-level targets is available or if
using this shape info is considered too computationally expensive or unneeded,

5.6 Appendices
213
the prior for the cluster positions and sizes (Equation (5.17)) is determined as
follows:
m0m
=
[xn(1), xn(2)]
W0m
=
Σ−1
0

for m = n = 1 : N,
(5.65)
where xn(1) and xn(2) are the target’s estimated x and y position respectively,
and Σ0 is an estimate for the size of the cluster grouping the measurements
produced by a single target. For instance, to hypothesize a circular cluster with
radius R,
Σ−1
0
=
 R2
0
0
R2

.
(5.66)
Elliptical targets
An elliptical shape occurs for instance when tracking blobs
in an image.
For elliptically shaped targets the target state is deﬁned by
x = [x, y, θ], where x and y represent the target position and θ is the target
orientation (the angle of its main axis with the x-axis). The target’s elliptical
shape is deﬁned by S = [l1, l2], where l1 and l2 are the equatorial radii.
In this case the positions and elliptical shapes for the targets at the tracking
level can be used as a prior for the cluster positions and sizes (Equation (5.17))
as follows:
m0m
=
[xn(1), xn(2)]
W0m
=
U T
"
1
l2
1
0
0
1
l2
2
#
U,





for m = n = 1 : N,
(5.67)
with
U
=
 cos xn(3)
−sin xn(3)
sin xn(3)
cos xn(3)

.
(5.68)
Circular targets and laser scanner
A partially observed circular shape occurs
for instance when observing people with a laser scanner at waist height. The
intersection of a person at waist height can be approximated as a circle. When
observing a person at waist height with a laser scanner the circular cross-section
is only partially visible as shown in Figure 5.13.
In this case the target state is deﬁned by x = [x, y], where x and y represent
the target position. The target shape is deﬁned by S = [R], where R is the
radius of the circular cross-section of the target.

214
Chapter 5
Shape-based Online MTTL
The parameters of an ellipse circumscribing the predicted laser scanner
measurements are found by deﬁning the points (xt1, yt1) and (xt2, yt2) where a
beam touches the circular cross-section:
xt1 = x + mt1y
m2
t1 + 1
,
yt1 = mt1xt1 and
(5.69)
xt2 = x + mt2y
m2
t2 + 1
,
yt1 = mt2xt2,
(5.70)
with mt1 and mt2 the slopes of the beams touching the target’s circular cross-
section:
mt1
=
−xy + R
p
x2 + y2 −R2
R2 −x2
,
(5.71)
mt2
=
−xy −R
p
x2 + y2 −R2
R2 −x2
.
(5.72)
The point (xf, yf) is the closest intersection point:
xf =
x + mfy −
r
m2
f + 1

R2 −(y −mfx)2
m2
f + 1
,
yf = mfxf,
(5.73)
with mf =
y
x the slope of the beam pointing to the center of the circular
cross-section.
Now the cluster position and size for the prior resulting from target n
(Equation (5.17)) can be chosen as follows (the physical meaning of the
parameters are shown in Figure 5.13):
m0m
=
 xt1+xt2
2
, yt1+yt2
2

,
W0m
=
U T
"
1
l2
1
0
0
1
l2
2
#
U
,
(5.74)

5.6 Appendices
215
0.0
0.5
1.0
1.5
2.0
2.5
3.0
0.0
0.5
1.0
1.5
2.0
2.5
laser scanner
target position
target shape
measurements
front intersection point
touching beams
middle touching points
touching points
ﬁtted ellipse
x[m]
y[m]
(xf, yf)
(xt1, yt1)
(xt2, yt2)
l2
l1
From shape to prior
Figure 5.13: Example of prior for the variational Bayesian clustering in case of
a target with circular cross-section observed by a laser scanner.
with:
U
=

y
x2+y2
−x
x2+y2
x
x2+y2
y
x2+y2

,
(5.75)
l2
1
=
1
4

(xt1 −xt2)2 + (yt1 −yt2)2
, and
(5.76)
l2
2
=
1.2
"xt1 + xt2
2
−xf
2
+
yt1 + yt2
2
−yf
2#
.
(5.77)
Shape deﬁned by a set of points
A set of points Sn = {snp}p=1:Pn, where Pn
is the number of points deﬁning the shape of target n may be used for tracking
groups (Lau et al. 2009). Furthermore, a set of points allows us to construct
a general method which applies to any kind of shape. To this end, points snp
are sampled from the measurement model, Equation (5.29), given the current
high-level estimate of the target state Xn = (xn, Sn):
snp ∼P(y | xn, Sn) .
(5.78)
The position of the cluster for target n can be chosen as the mean of the
points deﬁning the target shape, while the elliptical shape is deﬁned as

216
Chapter 5
Shape-based Online MTTL
1
0
1
2
3
4
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
target shape
shape center
ﬁtted ellipse
x[m]
y[m]
From shape to prior
(a) Shape deﬁned by set of points.
1
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
target shape
target shape
target position
shape center
ﬁtted ellipse
x[m]
y[m]
From shape to prior
laser scanner
(b)
Points
obtained
by
sampling
from
P (y | xn, Sn) for the case of a target shape
deﬁned by two circles and a laser scanner.
Figure 5.14: Examples of prior for the variational Bayesian clustering for the
case of a target with shape deﬁned by a set of points.
being proportional to the covariance of these points (e.g. the 2σ boundary)
(Equation (5.17)):
m0m
=
1
Pn
P
p=1:Pn snp,
W0m
=
4
Pn
P
p=1:Pn (snp −m0m)T (snp −m0m) .
(5.79)
Figure 5.14 shows two examples: in the ﬁrst example (Figure 5.14(a)) the target
shape is deﬁned by a set of points, while in the second example (Figure 5.14(b))
points are sampled using the measurement model and the target state Xn.
5.6.3
Software
This section describes the software implementing the proposed two-level
Bayesian multitarget tracking and localization algorithm.
All the software
(LGPL-licensed), API documentation and speciﬁc property ﬁles for the
experiments are available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL. The developed
software uses the Open Robot Control Software (Orocos) (Bruyninckx 2001;
Soetens 2006) and the Bayesian Filtering Library (Gadeyne and De Laet 2001).
Figure 5.15 shows some of the Orocos components, i.e. the ones used in the ﬁrst
experiment (Section 5.4.1), developed to implement the proposed algorithm.
Thanks to the modularity of the design, the components can be reused for
diﬀerent software conﬁgurations such as other sensors (e.g.
camera instead

5.6 Appendices
217
Sensor
Measurement Preprocessor
Visualization
Two level MTTL
LaserScanner
Blender
SeparateObjects
measurementsObjectsSeparated
W
LaserDistance
R
separateObjects
M
getEnvironment
M
numMeasurementsObjectsSeparated
W
probMeasurementsEnv
W
distancesSeparatedObjectsSeparated
W
LaserAngle
R
environment_file
P
sigma_environment
P
zmax
P
treshold
P
pC1
P
nbeams
P
LaserDistance
W
LaserAngle
W
priority
P
port
P
range_mode
P
res_mode
P
unit_mode
P
distanceOutOfRange
E
NumObjectsEstimator
numObjectsEstimated
W
numClusters
R
estimateNumObjects
M
maxNumberClusters
P
maxNumberObjects
P
probObjects
W
VBClusters
measurementsObjects
R
estimateClusters
W
findClusters
M
dimension
P
treshold_new_cluster
P
treshold_effective_cluster
P
max_iter
P
maxNumberClusters
P
maxNumberComponents
P
maxNumberMeasurements
P
betaPrior
P
setPrior
M
setInitial
M
numMeasurementsObjects
R
stateClusters
W
covarianceClusters
W
numClusters
W
nuPrior
P
alphaPrior
P
WPrior
P
SigmaPrior
P
betaNewCluster
P
nuNewCluster
P
alphaNewCluster
P
WNewCluster
P
SigmaNewCluster
P
probSysOneObjectLess
P
probSysOneObjectMore
P
probSysTwoObjectsLess
P
probSysTwoObjectsMore
P
twoLevelMTTL
stateClusters
R
findClusters
M
updateFilters
M
covarianceClusters
R
numClusters
R
numObjectsEstimated
R
measDimension
P
treshold
P
gamma
P
tresholdAddFilter
P
tresholdDeleteFilter
P
maxNumberFilters
P
maxNumberClusters
P
maxNumberAssociations
P
priorCovariance
P
level
P
sysNoiseMeanValue
P
sysNoiseCovarianceValue
P
measNoiseMean
measNoiseCovariance
measModelMatrix
P
P
P
estimateStateFilters
W
numFilters
W
estimateCovarianceFilters
W
filterID
W
closestTargetState
W
distanceClosestTarget
W
estimateMxFilters
W
estimateMyFilters
W
estimateNumObjects
M
prepareMeasurement
M
anglesSeparatedObjectsSeparated
W
snapshotReporting
M
Reporting
Reporter
snapshotReporting
M
PrepareSeparatedMeasurementsSeparated
measurementsObjects
W
measurementsObjectsSeparated
R
separateObjects
M
prepareMeasurement
M
numMeasurementsObjects
W
distancesSeparatedObjects
W
numMeasurementsObjectsSeparated
R
anglesSeparatedObjects
W
distancesSeparatedObjectsSeparated
R
anglesSeparatedObjectsSeparated
R
maxNumberAssociationCalls
P
priorMean
P
robotState
P
Figure 5.15: Overview of software components developed for the two-level Bayesian multitarget tracking and localization
algorithm. The blue blocks are Orocos components, with their properties (P), methods (M), events (E) and read (R) and
write (W) dataports represented by purple, green, red and blue circles respectively. The grey rectangles indicate which
software components are belonging together conceptually. Component schemes for diﬀerent conﬁgurations, the software
itself and API documentation is available online at
http://people.mech.kuleuven.be/~tdelaet/twoLevelMTTL.

218
Chapter 5
Shape-based Online MTTL
of laser scanner), data available from a ﬁle instead of online, etc. The most
important components and their functionality are brieﬂy described below.
twoLevelMTTL
The twoLevelMTTL is the main component: it (i) ﬁres the
methods of its peers:
VBClusters, NumObjectsEstimator, PrepareSeparat-
edMeasurement, . . . , when required and (ii) maintains the individual target
trackers.
PrepareSeparatedMeasurement
The PrepareSeparatedMeasurementSeparated
component is an interface component. It helps to connect the twoLevelMTTL
with components like the SeparateObjects components responsible for the
measurement preprocessing.
This component inherits from an abstract
PrepareSeparatedMeasurement component, providing the generic interface for
a PrepareSeparateMeasurement component.
SeparateObjects
The SeparateObjects component is an example of a mea-
surement preprocessing component.
This component is used in the ﬁrst
experiment and its functionality is described in Section 5.4.1. When the method
separateObjects is called, the component calculates the probabilities that the
laser measurements produced by the laser scanner belong to the prerecorded
environment.
VBClusters
The VBClusters component implements the low-level clustering
step described in Section 5.3.2. When the method ﬁndClusters is called, the
component looks for the cluster positions and sizes clustering the measurements
given by the SeparateObjects component.
NumObjectsEstimator
The NumObjectsEstimator component implements
the number of target estimator of the high level described in Section 5.3.3.
When the method estimateNumObjects is called, the component estimates
the number of targets from the number of clusters found by the VBClusters
component.
Other components
Figure 5.15 still mentions three other Orocos components:
LaserScanner, Reporter and Visualization.
The LaserScanner component
communicates with the laser scanner hardware and puts the laser scanner
measurements on its ports.
The Reporter is a component used to write
the results of the components to a ﬁle for validation purposes.
For online

5.6 Appendices
219
3D visualization of the estimation results the twoLevelMTTL component is
connected to Blender (Roosendaal 2002).


Chapter 6
Fully Bayesian Mixture
Particle Filter for Multitarget
Tracking and Localization: by
Measurement Model Induced
Data Association and
Heuristic-free Mixture
Computation1
This paper makes three contributions to make the mixture particle ﬁlter (MPF)
suited for fully Bayesian target tracking and detection.
First, this paper
analyses the MPF using its Bayesian network representation and shows that
the state-of-the-art nearest-neighbor data association of the MPF prevents
fully Bayesian tracking. This paper therefore proposes a Bayesian soft-data
association using an adapted measurement model. Second, this paper replaces
the state-of-the-art heuristic mixture computation step of the MPF with a
heuristic-free mixture computation:
Bayesian weighted spatial reclustering
1This chapter has been submitted as a full article for publication in International Journal
of Social Robotics:
Tinne De Laet, Herman Bruyninckx, and Joris De Schutter; Fully
Bayesian Mixture Particle Filter for Multitarget Tracking and Localization: by Measurement
Model Induced Data Association and Heuristic-Free Mixture Computation.
221

222
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
(BWSR). BWSR is based on variational Bayesian cluster ﬁnding and uses prior
shape information of the particle cloud. Third, this paper extends the MPF to
handle not only tracking but also target localization and detection.
Simulations and experiments of people tracking and detection using a laser
scanner validate the three contributions.
6.1
Introduction
Multitarget tracking (MTT) consists of recursively estimating the state of
diﬀerent targets. Multitarget tracking and localization (MTTL) furthermore
includes detection of appearing and disappearing targets. Multitarget tracking
arises in a wide variety of contexts:
vision or laser-based people tracking
for mobile robotics and surveillance systems, sonar-based submarine tracking,
multitarget tracking for manipulation, etc.
Multitarget tracking suﬀers from diﬀerent important problems: (i) the data
association problem, (ii) the curse of dimensionality that arises due to the
increased size of the state space associated with multiple targets, (iii) the
non-linearity of target dynamics and measurement processes, and (iv) the
handling of occlusions. In multitarget tracking the sensors provide unlabelled
measurements of the targets. This leads to a challenging combinatorial data
association problem since (i) the targets can have a small separation compared
to the measurement errors and (ii) clutter measurements, i.e. measurements
not corresponding to any of the targets, can occur. Multiple target tracking
suﬀers from the curse of dimensionality, since the size of the joint state space
increases exponentially with the number of targets.
Multitarget tracking and localization introduces some more diﬃculties. In the
localization case the number of targets to track is unknown and possibly varying.
At any time and in any place, targets can appear and disappear. A multitarget
tracker and localizer has to automatically detect appearing and disappearing
targets and estimate the number of targets.
Vermaak and Doucet 2003 proposed an algorithm for MTT, to which we refer
as the mixture particle ﬁlter (MPF). By formulating the MTT problem in the
state space with the size of a single target the MPF circumvents the problem of
exponential growth of the state space with the number of targets. This MTT
formulation results in a multimodal posterior distribution, where in the ideal
case each mode represents a target. In the MPF Vermaak and Doucet 2003
model the target distribution as a non-parametric mixture model, and they
present the general tracking recursion in this case. They show how a Monte
Carlo implementation of the general recursion leads to a mixture of particle

6.2 Related Work
223
ﬁlters, each ﬁlter tracking one mode of the target distribution. The particle
ﬁlters only interact in the computation of the mixture weights, thus leading
to an eﬃcient numerical algorithm. When applying the MPF for multitarget
tracking, in the ideal case, each mode of the target distribution represents one
target and each particle ﬁlter of the MPF tracks one target. To maintain the
ideal situation where each component of the mixture represents one target a
mixture computation is needed from time to time (Vermaak and Doucet 2003).
This mixture step is called ‘maintain mixture step’ in the MPF (Vermaak and
Doucet 2003). The maintain mixture step in the MPF will revise the mixture
representation consisting of the number of mixture components, i.e. the number
of targets, and the division of the particles over the diﬀerent components of the
mixture as illustrated in Figure 6.1.
This paper shows how the mixture particle ﬁlter can be applied in a real
Bayesian context to multitarget tracking.
First, an in-depth analysis and
theoretical validation of the MPF using Bayesian networks is performed. To
obtain a fully Bayesian interpretation of the MPF an adapted measurement
model (for instance the rigorously Bayesian beam model (RBBM) (De Laet
et al.
2008)) is proposed as a measurement model for the MPF in range
ﬁnder applications. To avoid any heuristics in the mixture computation and to
realize a fully Bayesian MPF, Bayesian weighted spatial reclustering (BWSR)
is proposed, replacing the spatial reclustering procedure of the original MPF.
Using BWSR for maintaining the mixture allows for non-ad hoc Bayesian
estimation of the optimal number of modes and automatic mode merging
and splitting. This paper also shows how the MPF can be extended to allow
multitarget tracking and localization. The MPF with adapted measurement
model and BWSR is evaluated both in simulation and in experiments, showing
the limitations and possible improvements of the MPF.
6.2
Related Work
A vast literature exists on strategies to address the diﬃculties associated with
multitarget tracking and localization.
This paper does not aim at giving
an exhaustive summery but (i) ﬁrst situates the MPF within the group of
multitarget tracking algorithms by showing how the MPF tackles the diﬀerent
important problems in MTT, and (ii) next gives an overview of extensions
and applications of the MPF to multitarget tracking and localization. For a
nice overview of multitarget tracking we refer to the overview papers (Cox and
Miller 1995; Vermaak et al. 2005).
A ﬁrst way to distinguish algorithms is by the way they handle the curse of
dimensionality that arises due to the increased size of the state space associated
with multiple targets. A ﬁrst category of multitarget trackers explicitly extends

224
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
maintain
mixture
step
Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
Pt =

N t
p, M t, Πt, X t, Wt, Ct	
Figure 6.1: Illustration of the MPF and its maintaining mixture step.
In
the ideal case, each mode of the target distribution represents one target
and each particle ﬁlter of the MPF tracks one target.
To maintain the
ideal situation where each component of the mixture represents one target a
mixture computation is needed from time to time (Vermaak and Doucet 2003).
This mixture step is called ‘maintain mixture step’ in the MPF (Vermaak
and Doucet 2003).
The maintain mixture step in the MPF will revise the
mixture representation: the number of mixture components, i.e. the number of
targets, and the division of the particles over the diﬀerent components of the
mixture. The ellipses in the ﬁgure indicate how the particles are devided over
the diﬀerent components of the mixture. During the maintain mixture step
the mixture representation is recomputed: (i) the number of components, i.e.
the number of targets, is estimated, (ii) components with signiﬁcant degree
of overlap are merged, and (iii) components that are too diﬀuse are split
or deleted. The mixture recomputation calculates from the current mixture
representation Pt =

N t
p, M t, Πt, X t, Wt, Ct	
a new mixture representation
Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
without changing the ﬁltering distribution.

6.2 Related Work
225
the state space to include all targets of interest (and even data association
variables, etc.) (Hue et al. 2002a; Vermaak et al. 2005; Vermaak et al. 2005;
Ng et al. 2005a; MacCormick and Blake 2000). To allow for a variable number
of targets, the state space dimension has to be changed dynamically (Ng et al.
2005a) or an indicator state has to be included showing which targets are
active (MacCormick and Blake 2000). Speciﬁc measures should be made to
handle the curse of dimensionality: pruning, eﬃcient proposals (Vermaak et al.
2005; Ng et al. 2005a), eﬃcient sampling (Hue et al. 2002a; MacCormick and
Blake 2000; Vermaak et al. 2005), adaptive resampling (Hue et al. 2002a),
MCMC techniques (Khan et al. 2005; Khan et al. 2006; Oh et al. 2004), etc.
A second category, including the MPF algorithm, builds a multitarget tracker
by multiple instantiations of single target tracking algorithms (Bar-Shalom and
Fortmann 1988; Reid 1979; Blackman 2004; Cox and Miller 1995; Schulz et al.
2003; Kotecha and Djuric 2003; Streit and Luginbuhl 1995).
A second way to distinguish algorithms is by the way they handle the
data association problem.
A ﬁrst category uses hard assignments, each
measurement is assigned to one target:
for instance nearest-neighbor or
strongest neighbor assignments (Montemerlo, Whittaker, and Thrun 2002;
Lindström and Eklundh 2001; Fod, Howard, and Matarić 2002; Song, Lee,
and Ryu 2005) or the multihypothesis tracker (Reid 1979; Blackman 2004).
A second category uses soft assignments, each measurement is assigned to
multiple, or all, targets (Bar-Shalom and Fortmann 1988; Schulz, Burgard,
Fox, and Cremers 2003; Streit and Luginbuhl 1995).
The data association
weight in this kind of methods is usually determined by the probability that
the measurement originates from the target under study. The MPF as used
so far uses an implicit nearest-neighbor data association strategy. This paper
shows how the inclusion of an adapted measurement model makes the MPF a
fully Bayesian multitarget tracker using soft assignment data association.
A third way to distinguish MTTL algorithms is based on the choice between
parametric or non-parametric ﬁlters underlying the multitarget tracking
algorithm. Parametric ﬁlters use a ﬁxed functional form, often Gaussian to
represent the posterior (Bar-Shalom and Fortmann 1988; Reid 1979; Streit and
Luginbuhl 1995; Kotecha and Djuric 2003). This makes them eﬃcient, but
comes at the cost of limited representational power. Non-parametric ﬁlters,
such as Monte Carlo ﬁlters, do not rely on a ﬁxed functional form.
While
they make no strong assumptions on the posterior density, they have a higher
computational complexity (Schulz et al. 2003; Vermaak et al. 2005; Vermaak
et al. 2005; Hue et al. 2002a). The MPF is a non-parametric ﬁlter where
the posterior is modeled as a mixture of Monte Carlo probability distribution
functions (MCPdfs).
Summarizing, to circumvent the ﬁrst problem of MTT, the curse of dimension-
ality, the MPF builds a multitarget tracker by multiple instantiations of single
target tracking algorithms. The MPF furthermore resides in the family of non-

226
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
parametric ﬁlters where each posterior is modeled as a mixture of Monte Carlo
probability distributions, this way being able to handle non-linearities in the
target dynamics and measurement processes. To tackle the data association
problem, the MPF as used so far for MTT is supplemented with a nearest or
strongest-neighbor data association strategy.
Diﬀerent applications and improvements have been suggested for the MPF in
multitarget tracking problems. Vermaak and Doucet 2003 validated the MPF
using the tracking of football players in a video sequence using nearest-neighbor
assignments. Du et al. studied both independent particle ﬁlters (Du and Piater
2005a) and the MPF (Du and Piater 2005b) to track multiple targets based
on camera images. In both cases an EM-based cluster analysis of the features
extracted from the camera precedes the particle ﬁltering: given the cluster
parameters obtained from the cluster analysis, the particle ﬁlters are initialized.
The features from the camera images are assigned to one target, using a nearest-
neighbor data association. The authors propose to use a voting technique to
determine the number of clusters in the data and provide heuristics to decide
when to start and stop a ﬁlter and when to merge overlapping and split spatially
disjoint clusters. Okuma et al. 2004 successfully combine the MPF with the
Adaboost algorithm to track hockey players during a game. The proposal is a
mixture of both the target dynamics and the detection hypotheses generated by
Adaboost. Adaboost also provides a mechanism for obtaining and maintaining
the mixture representation: it allows to quickly detect targets entering and
leaving the scene.
Madapura and Li 2008 combine the MPF with a KLD
sampling stage to minimize the number of particles and thus to improve the
tracking speed, while the accuracy is improved by using radial basis functions
to interpolate the sparse particle set. The MPF was validated on vision based
tracking of hockey players.
6.3
Mixture Particle Filter for Multitarget Tracking
In the mixture particle ﬁlter (MPF) for multitarget tracking the distribution
of interest at time t is the ﬁltering posterior P
 xt | y1:t
, with xt the state
at time t, and y1:t = {yti}ti=1:t grouping the measurements up to time
t.
The state typically comprises the position, velocity, acceleration, etc.
of the targets.
In MPF multitarget tracking, each mode of the ﬁltering
posterior corresponds to a component of the mixture representing one target.
Figure 6.2 shows the Bayesian network representation of the MPF. The MPF
represents the ﬁltering distribution at time t with a mixture of MCPdfs:
Pt =

N t
p, M t, Πt, X t, Wt, Ct	
, with N t
p the number of particles, M t the
number of mixture components, Πt = {πt
m}Mt
m=1 the mixture component

6.3 Mixture Particle Filter for Multitarget Tracking
227
...
...
yt−1
k
yt
k
yt+1
k
Kt−1
Kt
Kt+1
xt−1
xt
xt+1
Figure 6.2: Bayesian network model for mixture particle ﬁlter (MPF) with x
the state variable, y the measurement variable, and t the time step. The boxes
(plates) denote a set of Kt−1, Kt and Kt+1 measurements. The shaded nodes
are observed. The diﬀerent modes of posterior over the state variable represent
diﬀerent targets. Therefore, the state space size is equal to the size of a single
target state. The measurement model L(yt | xt) corresponds to the arrow from
xt to the set of measurements yt and therefore has to capture the probabilistic
relationship between all measurements and all targets.
weights, X t =

xt,(i)	N t
p
i=1 the particles with i indicating an individual particle,
and Wt =

wt,(i)	N t
p
i=1 the particle weights, and Ct =

ct,(i)	N t
p
i=1 the component
indicators, with ct,(i) ∈{1 . . . M}, and ct,(i) = m if particle i belongs to mixture
component m. This particle representation is a Monte Carlo approximation of
the mixture ﬁltering distribution of the form:
P
 xt | y1:t
≈
Mt
X
m=1
πt
m
X
i∈Im
wt,(i)δxt,(i)(xt),
(6.1)
where δa(.) is the Dirac delta measure with mass at a, and
Im
=

i ∈

1 . . . N t
p
	
: ct,(i) = m
	
is the set of indexes of the particles
belonging to the mth mixture component. The mixture component weights and
the particle weights for each mixture component sum to one, i.e. PMt
i=1 πt
m = 1,
and P
i∈Im wt,(i) = 1 for m = 1 . . . M t.
Vermaak and Doucet 2003 provide recursions to propagate the ﬁltering
distribution represented by a mixture of MCPdfs.
They show that (i) the
ﬁltering recursion can be performed for each component individually, (ii) the
components only interact through the calculation of the component weights
Πt, and (iii) the mixture modeling allows independent resampling of each of
the mixture components according to the component particle weights. When

228
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
applying the MPF for multitarget tracking, each component of the mixture
represents one target in the ideal case. A ‘maintain mixture step’ is needed
from time to time to maintain the mixture representation, i.e. to realize the
ideal situation where each component of the mixture represents one target as
illustrated in Figure 6.1. The maintain mixture step is necessary, since the
number of targets can vary: components can merge, split, etc. Vermaak and
Doucet 2003 propose a maintain mixture step consisting of a spatial reclustering
procedure step using heuristics to merge, split and delete components, followed
by a particle and mixture weight recomputation.
Algorithm 6.1 gives an overview of the mixture particle ﬁlter as proposed by Ver-
maak and Doucet 2003. D
 xt | xt−1
represents the dynamic model describing
the target state evolution, while L(yt | xt) represents the measurement model.
The MPF recursions are initialized with an initial probability distribution
P(x0), represented by a mixture of Monte Carlo Pdfs: P0. Q
 xt | xt−1,(i), yt
represents the proposal distribution.
The general MPF does not provide a
speciﬁc choice for the proposal distribution, the resampling algorithm, nor the
maintain mixture step.
6.3.1
Data Association Problem
In the previous paragraph it was shown that the MPF solves the problem of
exponential growth of the state space with the number of targets by formulating
the estimation problem in the state space of a single target and interpreting
the diﬀerent modes of the ﬁltering distribution as diﬀerent targets.
The
MPF however does not solve the data association problem.
How then to
decide which measurements originate from which targets or in this case, which
measurements originate from which modes in the distribution? In the state-
of-the-art MPF (Vermaak and Doucet 2003; Du and Piater 2005b; Okuma
et al.
2004; Madapura and Li 2008) a data association algorithm assigns
measurements to diﬀerent modes of the ﬁltering distribution, i.e. to diﬀerent
targets, using a nearest-neighbor approach. This nearest-neighbor approach
has some problems: (i) it is not clear which distance metrics are appropriate
or allowed, (i) it has been shown that a nearest-neighbor approach is not
robust against target occlusions (Cox 1993), and (iii) it assigns measurements
to diﬀerent parts of the same state space by means of an implicit, arbitrary
choice made in each particular conﬁguration (Cox 1993).
Such assignment
cannot be represented in the Bayesian network, hence the nearest-neighbor
approach cannot be considered to be a fully Bayesian method.
Assigning diﬀerent measurements to diﬀerent parts of the state space is not
theoretically sound, it cannot be modeled in a Bayesian framework and thus it
cannot be represented by a Bayesian network. A diﬀerent degree of evidence is

6.4 Mixture Particle Filter for Multitarget Tracking
229
Algorithm 6.1: Mixture particle ﬁlter (MPF) algorithm
Data: Pt−1 =

N t−1
p
, M t−1, Πt−1, X t−1, Wt−1, Ct−1	
for m = 1 : M t−1 do // loop over components
for i ∈Im do // loop over particles of mth component
xt,(i) ∼Q
 xt | xt−1,(i), yt
// sample from proposal
ewt,(i) =
wt−1,(i)L(yt | xt,(i))D(xt,(i) | xt−1,(i))
Q(xt | xt−1,(i),yt)
// calculate
unnormalized particle weight
end
for i ∈Im do // loop over particles of mth component
wt,(i) =
e
wt,(i)
P
j∈Im e
wt,(j) // normalize particle weight
end
ewt
m = P
i∈Im ewt,(i) // calculate sum unnormalized particle
weights
eπt
m = πt−1
m
ewt
m // calculate unnormalized component weight
end
for m = 1 : M t−1 do // loop over components
πt
m =
eπt
m
PMt−1
m=1 eπtm
// normalize component weight

xt,(i), wt,(i)	
i∈Im →

xt,(i), wt,(i)	
i∈Im // resample component
end
Pt =

N t
p, M t = M t−1, Πt, X t, Wt, Ct = Ct−1	
→
Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
// maintain mixture step
return Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
assigned to diﬀerent parts in the state space by assigning the measurements to
the closest mode of the ﬁltering posterior, therefore the resulting posterior
can not be interpreted as a probability density function any more.
All
measurements, possibly originating from diﬀerent targets, have to be applied
to the entire state space, i.e. to all modes of the ﬁltering distribution. This
approach requires a measurement model L(yt | xt) that can take into account
measurements originating from other targets than the one under study.
Section 6.4 explains how adapted measurement models can be developed, while
Section 6.5 explains why using such an adapted measurement model in the MPF
makes it suited for Bayesian MTT. Section 6.5 furthermore presents a novel
fully Bayesian method for maintaining the mixture representation, this way
avoiding any heuristics.

230
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
6.4
Adapted Measurement Model
This section proposes measurement models L(yt | xt) that can take into account
measurements originating from other targets than the one under study.
To derive such a probablistic measurement model, (i) extra state variables
A = a are introduced for the states of the targets that are not under study, and
(ii) these extra state variables are marginalized to remove the dependency on
the particular outcome of these target states while maintaining the dependency
on the distributional parameters of these variables.
In the sections below two cases are studied: Section 6.4.1 derives a measurement
model suited for the case where the other targets do not occlude the target
under study, while Section 6.4.2 proposes a measurement model for the case
where the other targets can possibly occlude the target under study.
6.4.1
Measurement Model without Occlusions
This section proposes a measurement model that takes into account the
measurements originating from other targets than the one under study, for
the case where the other targets do not occlude the target under study. An
example of such a situation is a camera with top view over the observation
volume, such that all individual targets are observable.
To derive the measurement model for this case two sets of extra state variables
A are introduced:
• the target states of the other targets than the one under study: {xt
m}m̸=n,
and
• the data association variables rt
k indicating which target is causing the
measurement yt
k, i.e.:
rt
k =
(
0
if yt
k is clutter,
n ∈{1 : N t}
if yt
k is caused by target n.
(6.2)
Concerning the extra variables three assumptions are made:
• the targets are independent:
P
 
xt
n
	
n=1:N t

=
N t
Y
n=1
P
 xt
n

;
(6.3)

6.4 Adapted Measurement Model
231
yt
k
rt
k
Kt
xt
n
xt
m
m̸=n
N t
Figure
6.3:
Bayesian
network
model
for
measurement
model
where
measurement can come from multiple targets, but where the diﬀerent targets
are not occluding eachother.
The shaded nodes are observed.
The boxes
(plates) denote a set of Kt measurements and the set all target states {xt
m}m̸=n
except the state of the nth target.
• the measurements can be due to clutter or can be target-originated, in
which case they have the same a priori probability to be caused by any
of the targets:
(
P(rt
k = 0) = γ
P(rt
k = n) = (1 −γ) 1
N
∀n = 1 : N t, and
(6.4)
with γ the a priori probability that a measurement is due to clutter;
• a clutter-originated measurement is distributed according to PC(yt
k):
P

yt
k | xt
n,

xt
m
	
m̸=n , rt
k = 0

=
PC
 yt
k

; and
(6.5)
• a target-originated measurement only depends on the target causing the
measurement:
P

yt
k | xt
n,

xt
m
	
m̸=n , rt
k ∈

1 : N t	
=
P

yt
k | xt
rt
k

.
(6.6)
Figure 6.3 presents the Bayesian network visualizing the conditional dependen-
cies between the variables yt
k, {xt
n}n=1:N t, and rt
k.

232
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
To obtain the adapted measurement model L(yt
k | xt
n), the extra state variables
{xt
m}m=n, and rt
k are marginalized from P

yt
k, {xt
m}m̸=n , rt
k | xt
n

:
L
 yt
k | xt
n

=
N t
X
rt
k=0
Z
{xt
m}m̸=n
P

yt
k,

xt
m
	
m̸=n , rt
k | xt
n

d

xt
m
	
m̸=n ,
(6.7)
=
N t
X
rt
k=0
Z
{xtm}m̸=n
P

yt
k | xt
n,

xt
m
	
m̸=n , rt
k

P

xt
m
	
m̸=n

P
 rt
k

d

xt
m
	
m̸=n .
(6.8)
Now, split the summation over rt
k in three parts: one for rt
k = 0, when the
measurement is due to clutter, one for rt
k = n, when the measurement is due
to the target under study, and one for rt
k = m with m ∈{1 : N t} \ {n}, when
the measurement is due to the other targets:
L
 yt
k | xt
n

=
γPC
 yt
k

+
(6.9)
(1 −γ) 1
N


Z
{xt
m}m̸=n
P
 yt
k | xt
n
 Y
m̸=n
P
 xt
m

d

xt
m
	
m̸=n
|
{z
}
T1
+
X
rt
k̸=n̸=0
Z
{xtm}m̸=n
P

yt
k | xt
rt
k
 Y
m̸=n
P
 xt
m

d

xt
m
	
m̸=n
|
{z
}
T2


. (6.10)
The second term on the right hand side (T1) is simpliﬁed to:
T1
=
P
 yt
k | xt
n

,
(6.11)

6.4 Adapted Measurement Model
233
while the third term on the right hand side (T2) is simpliﬁed to:
T2
=
X
rt
k̸=n̸=0


Z
{xt
m}m̸=n
Y
m̸=n̸=rt
k
P
 xt
m

d

xt
m
	
m̸=n̸=rt
k


|
{z
}
=1
(6.12)


Z
xt
rt
k
P

yt
k | xt
rt
k

P

xt
rt
k

d
n
xt
rt
k
o

,
=
X
rt
k̸=n̸=0
Z
xt
rt
k
P

yt
k | xt
rt
k

P

xt
rt
k

d
n
xt
rt
k
o
.
(6.13)
In general the integral in the above equation is intractable.
Therefore the
following approximation is made: P

yt
k | xt
rt
k

≈δ

yt
k −g

xt
rt
k

, with g the
measurement function. This can be interpreted as neglegting the measurement
noise on the measurement formation process, resulting in a deterministic
measurement function. Using this approximation Equation (6.13) results in:
T2
≈
(N t −1)
X
i
P(xi)
| ∂g(xi)
∂x |
,
(6.14)
where the sum extends over all roots xi of g(x) −yt
k.
Substituting
Equation (6.11) and Equation (6.14) into Equation (6.16) results in:
L
 yt
k | xt
n

≈(1 −γ)
N t
P
 yt
k | xt
n

+
(1 −γ) N t −1
N t
X
i
P(xi)
| ∂g(xi)
∂x |
+ γPC
 yt
k

,
(6.15)
which can be interpreted as a mixture, where the ﬁrst component is due to the
targets under study, the second component is due to the other targets, and the
last component is due to clutter. In case the measurement function is invertible,
the measurement model reduces to:
L
 yt
k | xt
n

≈(1 −γ)
N t
P
 yt
k | xt
n

+
(1 −γ) N t −1
N t
P
 g−1 (yt
k)


∂g(g−1(yt
k))
∂x

+ γPC
 yt
k

.
(6.16)

234
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
Consider the example where no information is used for the other target
positions, P

xt
m̸=n

=
1
V , with V the observation volume, and where the
measurement function is g (xt
n) = xt
n. In this case the measurement model
simpliﬁes to:
L
 yt
k | xt
n

≈(1 −γ)
N t
P
 yt
k | xt
n

+ (1 −γ) N t −1
N t
V −1 + γPC
 yt
k

.(6.17)
6.4.2
Measurement Model with Occlusions
This section presents a measurement model that takes into account the
measurements originating from other targets than the one under study, for the
case where the other targets can occlude the target under study. An example
of such a situation occurs when a 2D laser scanner is observing the targets. In
this case each beam will measure the distance to the closest target, which can
be diﬀerent from the target under study.
The rigorously Bayesian beam model (RBBM) (De Laet et al.
2008) is a
measurement model for range ﬁnders and was ﬁrst used in the context of mobile
robot localization and single target tracking in dynamic environments. The
dynamic nature of the environment refers to the presence of unmodeled and
possibly moving objects and people or other targets, causing measurements that
do not originate from the targets under study. The RBBM is a measurement
model that does follow a Bayesian approach, since it allows any measurement
to be associated to other targets than just the one under consideration. This
section explains the applicability of the RBBM as a measurement model in the
MPF for multitarget tracking. In this case the RBBM following introduces
extra state variables for:
• the total number of targets N t,
• the target states of the other targets than the one under study: {xt
m}m̸=n,
and
• the number of targets occluding the target under study: N t
occl
• the target states of the targets occluding the one under study:
n
xt
occl,n
o
n=1:N t
occl
, and
• the measurement that would ideally result from the occluding targets:
y⋆t
occl.
Figure 6.4(a) shows the Bayesian network of the RBBM including all extra
variables.

6.4 Adapted Measurement Model
235
N t
N t
occl
xt
occl,n
xt
m
xt
n
y⋆t
occl
yt
k
M
m ̸= n
N t
N t
occl
p
σm
(a) The Bayesian network for the RBBM
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
10
9
8
7
6
5
4
3
2
1
0
y[m]
P(yt
k | xt
n, m)
(b) P yt
k | xt
n, m
Figure 6.4: Figure (a) shows the Bayesian network for the probabilistic measure-
ment model supplemented with the deterministic parameters represented by the
smaller solid nodes (for detailed explanation on all variables and conditional
probabilities see De Laet et al. 2008). A compact representation with plates
(the rounded rectangular boxes) is used. A plate represents a number, indicated
in the lower right corner, of independent nodes of which only a single example
is shown explicitly. The states crossed out represent the states modeling the
unknown environment dynamics, which are marginalized out in the RBBM.
The shaded nodes are observed. Figure (b) shows the RBBM for P(yt
k | xt
n, m)
for p = 0.8, ymax = 10, y⋆t
k = 5, σm = 0.15, π3 = 0.2 and π4 = 0.02.

236
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
Since inferring the probability distribution of the extra state variables is
infeasible, these variables are marginalized in the RBBM. A detailed derivation
of the marginalization is given by De Laet et al.
2008.
The result of
the marginalization is the RBBM, which can be represented as mixture
that models four possible causes of a range measurement:
a hit with the
map or target under study (Phit (y | x, m)), a hit with an unmodeled object
or other targets (Poccl (y | x, m)), an unknown cause resulting in a random
measurement (Prand (y | x, m)) and a sensor failure resulting in a maximum
reading measurement (Pmax (y | x, m)):
P(y | x, m) = π1Phit (y | x, m) + π2Poccl (y | x, m) +
π3Prand (y | x, m) + π4Pmax (y | x, m) ,
(6.18)
where
π1
=
(1 −p′) (1 −π3 −π4),
(6.19)
π2
=
p′(1 −π3 −π4),
(6.20)
Phit (y | x, m)
=
N (y; z⋆, σm) ,
(6.21)
Poccl (y | x, m)
=



1
z⋆
1−p′
[1−( z⋆−y
z⋆
p′)]
2
if 0 ≤y ≤z⋆
0
otherwise.
,
(6.22)
Prand (y | x, m)
=
(
1
zmax
if 0 ≤y ≤zmax,
0
otherwise.
, and
(6.23)
Pmax (y | x, m)
=
I (zmax) =
(
1
if y = zmax,
0
otherwise,
(6.24)
with z⋆= g (x, m) the distance the range sensor would ideally measure, i.e.
the distance to the closest object in the map, σm the standard deviation of
the zero mean Gaussian measurement noise governing Phit (y | x, m); p′ the
probability that the target under study is occluded, π3 and π4 the probabilities
that the range ﬁnder returns an unexplainable measurement (unknown cause)
and a maximum reading (sensor failure) respectively and zmax a known
sensor characteristic representing the measurement range.
So, the RBBM,
given by Equations (6.18)-(6.24), depends on four independent parameters
Θ = [σm, p′, π3, π4] with a clear physical interpretation. Details on the RBBM
including algorithms to learn the model parameters Θ from data are found in
De Laet et al. 2008.

6.5 MTT with MPF, Adapted Measurement Model and BWSR
237
Figure 6.4(b) shows an example of the RBBM. The shape of the RBBM is
in accordance with intuition: (i) measurements around the distance of the
expected target increase the target’s probability, (ii) measurements ‘behind’
an expected target have a low probability since it is physically impossible to
measure something behind your target, and (iii) measurements ‘in front’ of
the target have a non-zero probability since these measurements can be caused
by other targets, modeled by the environment dynamics. This shows why the
RBBM can be used as the measurement model in the MPF for multitarget
tracking: it allows any measurement to be associated to other targets than just
the one under consideration.
To tackle the problems associated with beam-based models, caused by the
independence assumption between beams, De Laet et al.
2008 extend the
RBBM to a full scan model adapted to dynamic environments. This full scan
model accounts for the dependency between beams and adapts to the local
sample density when using a particle ﬁlter.
Therefore, the RBBM can be
replaced by this full scan model in applications where the dependency between
beams is important, for instance in the case of localization of a mobile robot
equipped with a laser scanner (Thrun et al. 2001).
6.5
MTT with MPF, Adapted Measurement Model
and BWSR
This section explains how MPF can be used in a fully Bayesian way for
multitarget tracking. To this end MPF uses an adapted measurement model
L(yt | xt) as derived in Section 6.4 and uses a new procedure for maintaining
the clusters, Bayesian weighted spatial reclustering (BWSR), proposed in this
paper.
6.5.1
Mixture Particle Filter and adapted measurement model
Combining the MPF with an adapted measurement has multiple advantages.
First, the combination of MPF with the adapted measurement models proposed
in Section 6.4 allows a fully Bayesian approach for MPF multitarget tracking,
since it allows to apply all measurements to the entire state space. Second,
the adapted measurement model allow to apply all measurements to the entire
state space of the targets, i.e. to al modes in the ﬁltering distribution. This
is advantageous since measurements are not only informative for their nearest-
neighbor targets but for all targets.
For instance, in case of the RBBM, a
measurement ‘behind’ an expected target decreases the belief of the target,
since the target is not observed when expected, while a measurement ‘in

238
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
front’ of a target does not decrease the probability of the target since this
measurement can be caused by another target, even if this measurement does
not originate from that target.
6.5.2
Maintaining Mixture
The MPF provides recursions to propagate a ﬁltering distribution represented
by a mixture of MCPdfs. It however does not show how to initially obtain and
subsequently maintain the mixture of MCPdfs. By maintaining the mixture
the MPF attempts to realize the ideal case where one mode of the mixture
represents one mode in the target ﬁltering distribution or, in the MTT case,
one mode for each target. This is far from trivial, since (i) the number of modes,
i.e. the number of targets, is rarely known beforehand and, (ii) the number of
modes is unlikely to remain ﬁxed, since targets can appear and disappear again.
Therefore, the general MPF applies from time to time a recomputation of the
mixture representation (Vermaak and Doucet 2003). The maintain mixture
step is illustrated in Figure 6.1. Recomputing the mixture representation has
to (i) determine the number of modes, i.e. targets, (ii) merge modes with
signiﬁcant degree of overlap, and (iii) split or delete components that are
too diﬀuse. The mixture recomputation calculates from the current mixture
representation Pt =

N t
p, M t, Πt, X t, Wt, Ct	
a new mixture representation
Pt′ =
n
N t
p
′, M t′, Πt′, X t′, Wt′, Ct′o
without changing the ﬁltering distribution
i.e. Pt′ ∼Pt.
Vermaak and Doucet 2003 propose to use a spatial reclustering procedure
denoted by

Ct′, M t′
= F (X t, Ct, M t) taking as inputs the particles and
the current mixture representation (component indicators and number of
components).
Such a spatial reclustering procedure has to encapsulate
any mixture computation operation of interest, including merging, splitting,
reclustering, etc. The spatial reclustering procedure does not change particle
locations X t, it just updates the way particles are assigned to clusters (Ct′ and
M t′).
In this paper we propose to use a Bayesian weighted spatial reclustering
procedure, denoted by

Ct′, M t′
= Fw (X t, Wt, Ct, M t), taking as inputs
the particles, the particle weights and the current mixture representation
(component indicators and number of components).
In contrast to the
state-of-the-art spatial reclustering procedures, the Bayesian weighted spatial
reclustering procedure (i) takes into account the particle weights, (ii) does
not rely on any heuristics for determining the number of clusters, merging,
splitting, etc. and (iii) relies on Bayesian probability theory. By taking into
account particle weights, high-weight particles will aﬀect the new mixture

6.5 MTT with MPF, Adapted Measurement Model and BWSR
239
representation more than low-weight particles. A diﬀuse cloud of low-weight
particles will not trigger a new mixture component while a few high-weight
particles will.
After the (Bayesian weighted) spatial reclustering the new mixture and particle
weights Πt′ and Wt′ still have to be updated such that Pt′ ∼Pt (Vermaak and
Doucet 2003):
πt
m
′ =
X
i∈I′m
πt
ct,(i)wt,(i) and wt,(i)′ = πt
ct,(i)wt,(i)
πt
ct,(i)
′
.
(6.25)
The mixture recomputation does not inﬂuence the convergence properties of
the particle ﬁlter, since Pt′ and Pt represent the same ﬁltering distribution.
Bayesian Weighted Spatial Reclustering (BWSR)
The goal of the Bayesian weighted spatial reclustering (BWSR) procedure is
to recognize clusters in the ﬁltering distribution P
 xt | y1:t
represented by
the particle cloud {X t, Wt}. This is equivalent to ﬁtting a Gaussian mixture
distribution to the particle cloud {X t, Wt}:
P
 xt | y1:t
≈
M
X
m=1
AmN
 xt|µm, Sm

,
(6.26)
with A = {Am}m=1:M the mixing coeﬃcients. The goal of BWSR is therefore
to estimate the number of clusters M, the cluster locations µ = {µm}m=1:M,
and the cluster sizes S = {Sm}m=1:M, given the particle cloud {X t, Wt}. In
general it is not known to which cluster m each of the particles xt,(i) belongs.
In that case estimating the cluster locations µ and sizes S is diﬃcult and lacks
a closed-form solution. If however, the corresponding cluster of each of the
particles is known, the solution is easily obtained in closed form. This suggests
an EM-approach to estimate the cluster parameters. To this end, introduce
a latent correspondence variable a(i) =
h
a(i)
1 , a(i)
2 , . . . , a(i)
M
i
, representing the
unknown cluster, using a 1-of-M representation in which the element a(i)
m of
the corresponding cluster is equal to 1 and all the other elements are equal to 0.
The elements Am of A represent the probability that the particle x(i) belongs
to the mth cluster, i.e.:
P

a(i)
m = 1

= Am.
(6.27)

240
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
xt,(i)
wt,(i)
a(i)
A
Np
M
Sm
µm
α0
β0
m0
W0
ν0
Figure 6.5: Bayesian network model for variational mixture of Gaussians. The
boxes (plates) denote a set of Np weighted particles and a set of M clusters.
The shaded nodes are observed.
The Gaussian mixture distribution in Equation (6.26) rewritten with the latent
correspondence variables a =

a(i)	
i=1:Np becomes:
P
 xt | y1:t
≈
M
X
m=1
M
Y
m=1
 AmN
 xt|µm, Sm
am .
(6.28)
The graphical representation of the mixture formulation including the latent
correspondence variable a is shown in Figure 6.5. Although the estimation
problem lacks a closed-form solution due to the unknown correspondences, an
expectation-maximization approach (EM) can solve the problem by iterating
an expectation and a maximization step. The expectation step calculates an
expectation for the correspondence variables a, while the maximization step
computes the other model parameters under these expectations.
In this paper we suggest a variational Bayesian method cluster ﬁnder. This
Bayesian approach integrates over the possible values of all uncertain quantities
rather than optimizing them as in the ML approach (Beal 2003; Beal and
Ghahramani 2003). The quantity that results from integrating out both the
latent variables a and the parameters Θ = {A, µ, S} is known as the marginal
likelihood:
P
 xt | y1:t
=
Z
P
 xt | y1:t, a, Θ

P(a, Θ) d(a, Θ),
(6.29)
where P(a, Θ) is a prior over the latent variables and the parameters of the
model.
Unfortunately, computing the marginal likelihood, P
 xt | y1:t
, is
intractable for almost all models of interest. The variational Bayesian method
constructs a lower bound on the marginal likelihood, and optimizes this bound
using an iterative scheme that has intriguing similarities to the standard EM
algorithm.

6.5 MTT with MPF, Adapted Measurement Model and BWSR
241
We are still left with deﬁning the prior P(a, Θ) over the latent variables a and
parameters of the model Θ = {A, µ, S}. The prior over the latent variable is
conditionally dependent on the mixing coeﬃcients a:
P(a | A)
=
Np
Y
i=1
M
Y
m=1
Aa(i)
m ,
(6.30)
while the prior over the parameters can be factorized as:
P(A, µ, S)
=
P(A) P(µ | S) P(S) .
(6.31)
Conjugate priors are deﬁned for the parameters i.e. a Dirichlet distribution over
the mixing coeﬃcients A:
P(A)
=
Dir(A|α0) ,
(6.32)
with α0 = [α0, . . . , α0]T for symmetry reasons, and an independent Gaussian-
Wishart prior (Bishop 2006) over the mean and the precision of the Gaussian
mixture components:
P(µ|S)P(S) =
M
Y
m=1
N
 µm|m0, β0
−1S

W
 S−1|W0, ν0

.
(6.33)
Figure 6.5 shows the resulting model, including the prior parameters α0, W0,
ν0, m0 and β0 using a Bayesian network representation with plates.
Bishop 2006 gives a complete derivation of variational Bayesian cluster ﬁnding
for unweighted data points. This paper extends the algorithm such that it can
handle weighted data points (the weighted particles). The derivation is omitted
but Algorithm 6.2 summarizes the equations for the Bayesian weighted spatial
reclustering, using weighted variational Bayesian cluster ﬁnding.
The Advantages of BWSR
We proposed a variational Bayesian (VB) estimator to ﬁnd clusters of
particles, avoiding the use of any heuristics. The VB cluster ﬁnder is a fully
Bayesian approach; priors over the unknown parameters are included, complex
(overﬁtting) models are punished, and a full probability distribution over the
parameters is obtained.
The VB estimator has only a little computational

242
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
Algorithm 6.2: Bayesian weighted spatial reclustering
Data: {X, W},α0,β0,m0,W0,ν0
for m = 1 : M do // Initialize cluster parameters to prior values
1
αm = α0;
βm = β0m;
mm = m0m;
Wm = W0m;
νm = ν0m;
2
end
3
while convergence criterion not satisﬁed or maximum number of iterations
4
not exceeded do
forall x(i) in X and w(i) in W, with i = 1 : Np do // E-step
5
for m = 1 : M do // loop over clusters
6
ρim = exp
h
Ψ (αm) −Ψ
PM
s=1 αs

+ 1
2
PD
d=1

Ψ
  νm+1−d
2

7
+ D log 2 + log |Wm|
8
−1
2

D
βm + νm
 x(i) −¯µm
T Wm
 x(i) −¯µm
i
;
// unnormalized responsability of mth cluster for ith
particle
end
9
η = PM
m=1 ρim ;
// calculate normalization constant
10
for m = 1 : M do // loop over clusters
11
rim = η−1w(i)ρim ;
// normalized weighted responsability
12
of mth cluster for ith particle
end
13
end
14
for m = 1 : M do // M-step
15
Npm = PNp
i=1 rim
16
¯xm =
1
Npm
PNp
i=1 rimx(i)
17
Sm =
1
Npm
PNp
i=1 rim
 x(i) −¯xm
  x(i) −¯xm
T
18
αm = α0 + Npm
19
βm = β0 + Npm
20
mm =
1
βm
 β0m0 + Npm¯xm

21
W−1
m =W0
−1+ β0Npm
βm
(¯xm −m0) (¯xm −m0)T + NpmSm
22
νm = ν0 + Npm
23
Am =
αm
Mα0+Np
24
end
25
end
26
return {¯xm, Sm, αm, βm, mm, Wm, νm, Am}m=1:M
27

6.6 Extension to Localization
243
overhead as compared to a ML estimator (Bishop 2006), while it circumvents a
lot of problems associated with maximum likelihood (ML) estimators (K-means,
EM cluster ﬁnding, etc.) such as overﬁtting (Bishop 2006).
ML solutions such as the EM cluster ﬁnding, require the knowledge the number
of clusters M, since singularities will arise when a component collapses onto
a speciﬁc data point. Such singularities are absent in a variational Bayesian
treatment due to the inclusion of a prior over all model parameters and by
getting a maximum a posteriori (MAP) estimate of the model parameters
instead of maximum likelihood.
Furthermore, there is no overﬁtting in the
variational treatment if the initial number of clusters is larger than needed to
explain the data. The variational treatment allows to determine the optimal
number of components in the mixture without resorting to ad hoc or cross
validation techniques.
Using the BWSR for maintaining the mixture allows for non-ad hoc Bayesian
estimation of the optimal number of modes and automatic mode merging and
splitting. To automatically determine the number of clusters M from the data,
the parameter α0 of the prior over the mixing coeﬃcients A is chosen smaller
than 1, favoring solutions in which some of the mixing coeﬃcients are zero.
Next, point estimates of the mixing coeﬃcients A are made from the probability
distribution in the fully Bayesian approach: Am = rim
Np .
Components that provide insuﬃcient contribution to explaining the data have
their mixing coeﬃcients driven to zero during the optimization, and are thus
removed from the model.
This property is called automatic relevance
detection (ARD) (Bishop 2006). This allows us to start the cluster ﬁnding
with a large number of clusters since clusters unnecessary to explain the data
are pruned out from the model.
Introducing a prior over the model parameters µ and S, the location and size
of the clusters respectively, allows to automatically split and merge modes in
a non-ad hoc Bayesian way. A component whose particle cloud splits in two
parts will give rise to two clusters, since two clusters explain the particle cloud
in better accordance with the prior than a single large cluster.
6.6
Extension to Localization
This section shows how the MPF can be extended to cover not only the target
tracking but also localization of targets. First this section proposes a procedure
to detect targets leaving the scene or lost targets. Next, this section presents
a proposal for the MPF that allows to detect targets entering the scene.

244
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
When targets get lost or leave the scene, the divergence of the tracker will
increase steadily.
Therefore, to detect lost targets and targets leaving the
scene, the divergence of each of the trackers is studied. If the covariance of
a component of the mixture, which is a measure for divergence, exceeds a
certain threshold, the target is assumed to be lost or to have left the scene. Du
and Piater 2005b propose to monitor the component weight of each mixture
component and to terminate the tracker when this weight drops below a certain
threshold.
From simulations and experiments we conclude that using such
method suﬀers from a problem: the component weight of the target receiving
the most evidence quickly goes to 1, while the component weights of the other
targets go to zero. The component weight is a measure for the relative evidence
received for a target, but it is not a good measure for the tracker divergence.
To detect targets entering the scene, a new target is hypothesised at every time
step by adding a mixture component to the MCPdf mixture P(xt | yt) with a
probability pnew based on a Poisson process:
eP
 xt | y1:t
= (1 −pnew) P
 xt | y1:t
+ pnewP0
 xt
,
(6.34)
with P0 (xt) the a priori distribution of the new target state. Since no a priori
information is available on the position of the target when entering the scene,
a uniform a priori distribution over the sensor range is assumed:
P0
 xt
=



1
R
xt∈dom(g) dxt
if xt ∈dom (g) , and
0
otherwise,
(6.35)
with dom (g) the domain of the measurement function, i.e. the sensor range.
Simply using the a priori distribution as the proposal is very ineﬃcient, since
in most applications the sensor range is large compared to the measurement
noise: the importance weights for many particles sampled from the proposal
will be zero. The optimal proposal distribution, i.e. the one minimizing the
variance of the importance weights, is of the form:
Q
 xt | xt−1, yt
=
L
 yt | xt
P0
 xt
.
(6.36)
Since the RBBM, and many other practical measurement models, contains
non-linearities and non-Gaussian noise, it is not possible to obtain a closed-
form expression for the optimal proposal distribution. Therefore we suggest in
this paper a proposal, inspired by the optimal proposal of Thrun et al. 2000
and Vermaak et al.
2005, using the measurement information to generate
samples. Assuming measurement independence and approximating the RBBM

6.7 Simulations and Experiments
245
by eL(yt
k | xt), a simple Gaussian around the expected value the proposal can be
written as a mixture of Gaussians, where each mixture component corresponds
to one measurement:
Q
 xt | xt−1, yt
=
Kt
X
k=1
1
Kt
eL(yt
k | xt)
R eL(yt
k | xt) dxt ,
=
K
X
k=1
1
K N
 xt | g−1(yt
k), σm

,
(6.37)
with g−1 the inverse measurement function, mapping a measurement to a
position.
For range ﬁnders it is possible to map a measurement, existing
of an angle and a distance, to a position in the state space using the
inverse measurement function. Sampling from the proposal in Equation (6.37)
corresponds to sampling from a mixture of Gaussians. Taking into account
the uniform prior distribution of the new target state, the corresponding
importance weights for the samples are:
w(i)
∝
(
L(yt | xt,(i))
Q(xt | xt−1,yt)
if xt ∈dom (g) , and
0
otherwise.
(6.38)
Summarizing, the diﬀerent steps are: ﬁrst, add a component to the predicted
mixture distribution (Equation (6.34)); then, generate samples for the new
component by sampling from the proposal (Equation (6.37)) and calculating
the importance weights (Equation (6.38)) for the samples.
6.7
Simulations and Experiments
This section presents simulation results evaluating the performance of the MPF
with the RBBM and BWSR.
Figure 6.6 shows the simulation results of the MPF tracking four targets using
a laser scanner. The MPF with RBBM and BWSR is able to automatically
detect the splitting targets 3 and 4, and is able to handle the occlusion of target
3 and 4 by target 1 and 2 respectively.
Figure 6.7 shows the experimental results of the MPF tracking three persons
using a Sick laser scanner.
The MPF with RBBM and BWSR is able to
automatically detect all the persons the moment they enter the scene, and
to track them, even during occlusions.

246
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
 
 
 
 
−8
−8
−6
−6
−4
−4
−2
−2
9
9
8
8
8
8
7
7
6
6
6
6
5
5
4
4
4
4
3
3
2
2
2
2
1
1
0
0
0
0
4
4
4
3
3
3
2
2
2
1
1
1
x [m]
x [m]
y [m]
y [m]
real positions
real positions
target 1
target 2
target 3
target 4
part. comp. 1
part. comp. 2
part. comp. 3
part. comp. 4
sensor range
sensor range
sensor
sensor
environment
environment
measurements
Figure 6.6: Simulation of the MPF with RBBM and BWSR for tracking and localization of four targets with a laser scanner.
The left ﬁgure shows the tracking and localization results over the entire time sequence. Numbers 1-4 indicate the starting
position of the targets, while the boxed numbers indicate the end position of the targets. Target 1 and 2 start outside the
sensor range. Target 3 and 4 have the same initial position. The initial estimate of the MPF only captures 3. After a few
time steps the MPF recognizes that component 3 has split in two, thanks to the ARD of the BWSR. Once target 1 and
2 enter the sensor range the MPF add components for this new targets thanks to the proposal presented in Section 6.6
to extend the MPF for target localization. The MPF is able to track all targets, even though target 1 and 2 temporarily
occlude target 3 and target 4 respectively. The maintain mixture step does not maintain target numbers. This is illustrated
in this simulation: component 1 and 2 of the mixture represent target 1 and 2 before the crossing, while after the crossing,
component 1 and 2 of the mixture represent target 2 and 1. The right ﬁgure shows the ﬁltering distribution during the
occlusion. The particle clouds of target 3 and 4 are growing since these targets are occluded by target 1 and 2 respectively.
Animations of the simulations are available at http://people.mech.kuleuven.be/~tdelaet/peopleTracking/.

6.7 Simulations and Experiments
247
 
 
 
 
−5
−5
9
9
8
8
7
7
6
6
5
5
5
5
4
4
3
3
2
2
1
1
0
0
0
0
3
2
1
x [m]
x [m]
y [m]
y [m]
part. comp. 1
part. comp. 2
part. comp. 3
sensor range
sensor range
sensor position
sensor position
environment
environment
measurements
estimated person positions
Figure 6.7: Experiment of the MPF with RBBM and BWSR for people tracking and localization with a laser scanner.
The left ﬁgure shows the tracking and localization results over a 60 seconds time sequence. The ﬁrst person is standing
still around location [−0.1m, 2m]. The second and third person enter the scene later and walk around. Both persons
are detected by the MPF the time step they enter the scene. The MPF is able to localize and track all targets, even
though the targets occasionaly occlude each other. The right ﬁgure shows the ﬁltering distribution during an occlusion
the occlusion. The particle cloud of the person standing still is growing since it is occluded by a person walking in front
of it. Animations of the experiments are available at http://people.mech.kuleuven.be/~tdelaet/peopleTracking/.

248
Chapter 6
Fully Bayesian Mixture Particle Filter for MTTL
A movie of the experimental results is available at
http://people.mech.kuleuven.be/~tdelaet/peopleTracking/.
6.8
Conclusion
This paper made three contributions to make the mixture particle ﬁlter (MPF)
suited for fully Bayesian target tracking and detection.
First, this paper
analyzed the MPF using its Bayesian network representation and showed that
the state-of-the-art nearest-neighbor data association of the MPF prevents
fully Bayesian tracking. This paper therefore proposed a Bayesian soft-data
association using an adapted measurement model. Second, this paper replaced
the state-of-the-art heuristic mixture computation step of the MPF with a
heuristic-free mixture computation:
Bayesian weighted spatial reclustering
(BWSR). BWSR is based on variational Bayesian cluster ﬁnding and uses prior
shape information of the particle cloud. Third, this paper extended the MPF
to handle not only tracking but also target localization and detection.
Simulations and experiments of target tracking and detection using a laser
scanner validated the three contributions.
The fully Bayesian MPF could still be improved in some aspects.
The
performance of the MPF should be compared with state-of-the-art MTTL
algorithms. Furthermore, in the current setting, the MPF does not maintain
target numbers, since no distinction is made between diﬀerent modes of the
posterior. Future work will add an identiﬁer to each mode of the posterior
distribution to maintain the target numbers.

Chapter 7
General Conclusions
This chapter situates this thesis within the world of robotics (Section 7.1),
summarizes the main contributions of Chapters 3-6 (Section 7.2), and gives
suggestions for future work (Section 7.3).
7.1
Situation of the Work
Recently, robots are moving towards uncertain, cluttered and human-populated
environments, in both industrial and domestic settings.
Therefore, robots
have to be intelligent since they have to be able to handle the uncertainty
associated with these real-world environments.
This thesis focused on one
aspect of cognitive robot systems: the tracking and localization of targets. In
future cognitive robot systems, MTTL algorithms will be a basic tool since
the robot’s awareness of targets, and especially persons, in its environment is
essential for safety and a prerequisite for intelligent human-robot interaction
and cooperation.
The tracking and localization of targets is related to a wide range of
applications.
In motion analysis, the motion of a target, especially human,
is estimated (De Groote 2009). In particular, the goal is to estimate the state
of a kinematic model underlying the motion. Motion analysis has applications
in gait analysis for biomedical purposes, revalidation, the study of human and
animal motion, movie industry, etc.
Motion intention recognition (Aarno and Kragic 2006; Aarno and Kragic 2008;
Rusu et al. 2009) is concerned with estimating the intention of a target by
studying its motion. Motion intention recognition is of particular interest if
it has to be performed online and in realtime.
In this case the recognized
249

250
Chapter 7
General Conclusions
intention can for instance be used by a robot to provide support to a human
operator in order to assist the operator during the execution of a task.
A related research domain is that of activity recognition (Oliver et al. 2004;
Liao et al.
2005), where the aim is to understand the activity of a target.
While being very similar to motion intention recognition, activity recognition
focuses on estimating the activity of a target by not only focusing to its motion,
but especially to its interactions with the environment.
While motion intention and activity recognition are mainly studying the global
motion (or end-eﬀector) motion of a target, gesture recognition (Park et al.
2005; Kulić et al.
2008; Kulić et al.
2009) is observing the full motion of
the kinematic model underlying the motion. Gesture recognition goes beyond
motion analysis, since it not only tries to estimate the motion but also tries to
recognize which of a known set of gestures is underlying the observed motion.
The state-of-the-art methods for the above areas of motion analysis, motion
intention estimation, activity and gesture recognition, assume that there is
only a single target in the environment, i.e. the target of which the motion
has to be analyzed. Therefore, these methods should be preceded by a MTTL
algorithm when there are multiple targets in the environment. This way, the
MTTL can localize and track the target of interest even though other targets
are present in the environment or are (temporarily) occluding the target of
interest.
7.2
Main Contributions
This thesis makes contributions to the area of multitarget tracking and
localization for robotics where the online nature of the algorithms is important.
This thesis developed methods that are suited for online estimation of both
the number of targets and the state of these targets. To this end, this thesis
used Bayesian theory as a unifying and consistent framework to estimate the
unknown variables underlying the MTTL problem. Since all unknown variables
are estimated using fully Bayesian methods and all trade-oﬀs and assumptions
are made explicit, for instance in the form of a Bayesian prior, the approach
underlying this thesis is rigorously Bayesian.
Below, Sections 7.2.1-7.2.4 individually discuss the contributions of Chapters 3-
6 in more detail, while Section 7.2.5 compares the two algorithms for MTTL
proposed in this thesis, the shape-based online MTTL algorithm (Chapter 5)
and the fully Bayesian MPF (Chapter 6), and situates them within the state-
of-the-art MTTL algorithms discussed in Chapter 4.

7.2 Main Contributions
251
7.2.1
Range Finder Measurement Model for Dynamic Envi-
ronments
The objective of Chapter 3 was to develop a range ﬁnder measurement model
that is suited for the use in dynamic environments.
This measurement
model models the formation process by which range ﬁnder measurements are
generated in the physical world. Probabilistic measurement models account for
the uncertainty in the measurement formation process, and therefore it is of
vital importance that all types of inaccuracies aﬀecting the measurements are
incorporated in the probabilistic measurement model. Inaccuracies arise from
sensor limitations, noise, and the fact that most complex environments can
only be represented and perceived in a limited way. The dynamic nature of the
environment in particular is an important source of inaccuracies. This dynamic
nature results from the presence of unmodeled and possibly moving objects
and people. The possibly moving objects and people are ‘unmodeled’, since
introducing state variables to model these objects and people and estimating
these states is computationally too hard: these extra variables (exponentially!)
increase the computational complexity of state estimation while in many
applications estimating the position of the unmodeled objects is not of primary
interest.
In order to obtain a range ﬁnder measurement model suited for dynamic
environments, this thesis proposed a Bayesian network model for the mea-
surement model while stating all model assumptions and giving a physical
interpretation for all model parameters.
The obtained model is named
RBBM, short for rigorously Bayesian beam model.
The innovations of the
presented approach are (i) to introduce extra state variables for the positions
of unmodeled objects in the probabilistic sensor model, and (ii) to marginalize
out these extra state variables from the total probability before estimation.
The marginalization avoids the increase in complexity to infer the probability
distributions of interest, while maintaining the modeling of the dynamic nature
of the environment.
The rigorously Bayesian approach resulted in a transparent and intuitive
mixture model.
In contrast to the state-of-the-art model of Thrun et al.
2005, the assumption underlying the non-physical discontinuity in the RBBM
is uncovered.
Furthermore, this thesis proposed a diﬀerent functional form
for the probability of range measurements caused by unmodeled objects as
compared to Thrun et al. 2005. Furthermore, compared to the work of Thrun
et al. 2005; Choset et al. 2005, and Pfaﬀet al. 2006, the RBBM depends
on fewer parameters, while maintaining the same representational power for
experimental data.
Finally, a maximum-likelihood and a variational Bayesian estimator (both

252
Chapter 7
General Conclusions
based on expectation-maximization) were proposed to learn the model
parameters of the RBBM. Learning the model parameters from experimental
data beneﬁts from the RBBM’s reduced number of parameters.
Using two
sets of learning experiments from diﬀerent application areas in robotics, the
RBBM was shown to explain the obtained measurements at least as well as the
state-of-the-art model of Thrun et al. 2005.
To tackle the problems associated with beam-based models, caused by the
independence assumption between beams, this thesis extended the RBBM to
a full scan model adapted to dynamic environments.
This full scan model
accounts for the dependency between beams and adapts to the local sample
density when using a particle ﬁlter. Therefore, the RBBM can be replaced by
this full scan model in applications where the dependency between beams is
important, for instance in the case of localization of a mobile robot equipped
with a laser scanner (Thrun et al. 2001). The extension of the RBBM to an
adaptive full scan model was performed in two steps: ﬁrst, to a full scan model
for static environments and next, to a full scan model for general, dynamic
environments.
In contrast to the Gaussian-based state-of-the-art models of
Plagemann et al. 2007 and Pfaﬀet al. 2007, the proposed full scan model uses
a sample-based approximation, which can cope with dynamic environments
and with multimodality (which was shown to occur even in simple static
environments).
7.2.2
Overview and Classiﬁcation of MTTL Algorithms
The objective of Chapter 4 was to review the important state-of-the-art
multitarget tracking and localization (MTTL) algorithms, and classify them.
To this end this thesis (i) formulated state-of-the-art multitarget tracking and
localization algorithms in a uniﬁed framework using the same terminology
and symbols, (ii) listed the assumptions of the MTTL algorithms, (iii) gave
advantages and disadvantages of the algorithms, and (iv) discussed advances
in these algorithms. By (i) using the uniﬁed formulation and (ii) by analyzing
the Bayesian network representation for probabilistic MTTL algorithms, this
thesis compared the diﬀerent algorithms and revealed underlying assumptions.
Bayesian networks were used to provide a graphical representation of the
conditional independence assumptions of the algorithms. These independence
assumptions are fundamental for understanding and comparing most MTTL
algorithms.
To classify the state-of-the-art algorithms this thesis proposed a set of classiﬁers.
The classiﬁcation of the state-of-the-art algorithms was presented in tabular
format and using a decision graph.
The table and decision graph help
researchers in (i) choosing an algorithm suited for their particular MTTL

7.2 Main Contributions
253
problem, and (ii) comparing newly developed algorithms with existing ones.
The presented classiﬁcation, together with the assumptions, advantages and
disadvantages of the studied algorithms, showed that despite the large number
of algorithms available in literature there is still a need for online MTTL
algorithms that can (i) handle a large number of targets (and measurements),
(ii) maintain unique target identities, (iii) estimate a varying and unknown
number of targets, (iv) handle nonlinear process and measurement models,
(v) process multiple and merged measurements, and (vi) take into account
interaction dynamics existing during close target interactions.
7.2.3
Shape-based Online MTTL
The objective of Chapter 5 was to develop an online MTTL algorithm for
a variable number of targets for the case where a single target can produce
multiple measurements and which is furthermore able to correctly detect
entering and leaving targets and to obtain a record of the trajectories of targets
over time, maintaining a correct identiﬁcation for each target throughout the
tracking.
To this end, this thesis proposed a novel online two-level MTTL algorithm.
By using the high-level target position and shape information, the low level
clusters the measurements. Next, the high level performs the data association,
tracks the targets based on an underlying motion model, and updates the
target shapes. To construct the set of possible joint association events during
the data association, it is generally assumed that a measurement originates
from a single target and that the target generates only a single measurement.
The algorithm proposed in this thesis drops the second assumption as the
two-level approach allows us to take into account multiple measurements per
target. To this end all measurements in a cluster are jointly assigned to a
target. After this association the measurements are individually processed
by the algorithm avoiding the information loss caused by summarizing the
measurement information.
In contrast to many MTTL algorithms, the proposed algorithm does not require
to preprocess the measurements so that summarizing features (one per target)
are fed to the MTTL algorithm. The algorithm proposed in this thesis allows
us to use multiple measurements for a single target, preventing information
loss.
The proposed algorithm furthermore uses the target shape to cluster
measurements and to update the individual target trackers. Using the target
shape info helps to distinguish between interacting targets. The distinguishing
characteristics can even be improved by individualizing the target shapes.
The proposed algorithm correctly detects entering and leaving targets and

254
Chapter 7
General Conclusions
obtains a record of the trajectories of targets over time, maintaining a correct
identiﬁcation for each target throughout the tracking.
The algorithm was veriﬁed using two sensor modalities, video and laser scanner,
for people and ants tracking and localization.
The proposed algorithm has similar capabilities as the MCMC-based ﬁlter
developed by Khan et al.
2006, since this algorithm is also capable of
handling multiple measurements per target.
There are however a number
of diﬀerences in the underlying approach: (i) the proposed algorithm builds
multiple instantiations of a single target tracker, while the MCMC-based
ﬁlter (Khan et al. 2006) works in the joint state space of target states and
data association variables; (ii) to overcome the exponential complexity typical
of ﬁlters operating in the joint space the Markov chain is Rao-Blackwellized
to eliminate sampling over the continuous space of targets. To this end the
MCMC-ﬁlter assumes linear Gaussian motion and measurement models. In
contrast, the proposed algorithm is not limited to linear Gaussian motion and
measurement models. The high level allows us to attach either a Kalman or
a Monte Carlo ﬁlter to the individual targets; (iii) the MCMC-ﬁlter is not
extended to handle a varying number of targets, while the proposed algorithm
keeps a separate ﬁlter to estimate the number of targets online. This thesis
compared the performance of the proposed two-level MTTL algorithm with
the MCMC-based ﬁlter by applying the former to data sets, which are freely
available and used to validate the latter. The proposed algorithm outperformed
the MCMC-based ﬁlter on the laser scanner data of people, while it has similar
performance for the video data of ants during nest emigration.
The proposed algorithm could still be improved in some aspects. First, the
low-level clustering ﬁts a Gaussian mixture distribution to the measurements.
Therefore, it is implicitly assumed that the measurements form ‘blobs’. Second,
the high-level data association only associates a single cluster of measurements
with a target. Therefore, the high level is limited to targets causing a single
‘blob’ of measurements. Reasoning about compound objects, such as the two
legs of a single person, remains to be done.
Future work consists of (i) exploring the capabilities of the proposed algorithm
for using target shape info, i.e. updating the shape model for individual
targets, using Gaussian processes to describe the probabilistic target shape,
etc.; (ii) using a more advanced measurement model for laser scanning to
include information about occlusions (De Laet et al.
2008); (iii) extending
the high level such that compound targets, i.e. targets causing multiple blobs
of measurements, can be handled; and (iv) adding a level to reason about
group behavior.
Reasoning about group behavior has multiple advantages:
(i) tracking groups can help the multitarget tracking when targets cannot be
separated as individuals (Gennari and Hager 2004), (ii) tracking groups is more

7.2 Main Contributions
255
eﬃcient than tracking people separately (Lau et al. 2009) and (iii) a suitable
motion model for the high level can be deducted from the group behavior (e.g.
people queueing, talking, walking together, etc.).
7.2.4
Fully Bayesian Mixture Particle Filter
The objective of Chapter 6 was to make the mixture particle ﬁlter (MPF) (Ver-
maak and Doucet 2003) suited for fully Bayesian MTTL. The MPF was
originally developed by Vermaak and Doucet 2003 to improve the poor
performance of Monte Carlo methods (particle ﬁlters) when dealing with
consistently multimodal distributions. Multimodal distributions arise if there
is ambiguity about the estimated state, or if measurements come from diﬀerent
targets that are all tracked in the same state space. By representing the target
distribution by a non-parametric mixture of ﬁltering distributions, the MPF
has been shown to better maintain multimodality of distributions (Vermaak
and Doucet 2003).
This thesis studied the use of the MPF for MTTL and adapts the MPF to
make it suited for fully Bayesian MTTL. This thesis ﬁrst analyzed the MPF
using its Bayesian network representation and showed that the state-of-the-art
nearest-neighbor data association of the MPF prevents fully Bayesian tracking.
In this approach diﬀerent measurements are assigned to diﬀerent parts of
the state space which cannot be modeled in a Bayesian framework and thus
cannot be represented by a Bayesian network.
To obtain a fully Bayesian
MPF all measurements, possibly originating from diﬀerent targets, have to be
applied to the entire state space, i.e. to all modes of the ﬁltering distribution.
This requires a measurement model that can take into account measurements
originating from other targets than the one under study. This thesis therefore
proposed a Bayesian soft-data association using adapted measurement models
that allow any measurement to be associated to other targets than just the one
under consideration.
This thesis furthermore replaced the state-of-the-art heuristic mixture compu-
tation step of the MPF with a heuristic-free mixture computation: Bayesian
weighted spatial reclustering (BWSR). BWSR is based on variational Bayesian
cluster ﬁnding and uses prior shape information of the particle cloud.
In
contrast to the state-of-the-art spatial reclustering procedures, the Bayesian
weighted spatial reclustering procedure (i) takes into account the particle
weights, (ii) does not rely on any heuristics for determining the number of
clusters, merging, splitting, etc., and (iii) relies on Bayesian probability theory.
Finally this thesis extended the MPF to handle not only tracking but also target
localization and detection. To this end, this thesis presented (i) a procedure

256
Chapter 7
General Conclusions
to detect targets leaving the scene or lost targets, and (ii) a proposal for the
MPF that allows to detect targets entering the scene.
Simulations and experiments of target tracking and detection using a laser
scanner validate the three contributions made in this thesis to transform the
MPF to a fully Bayesian MTTL algorithm.
The fully Bayesian MPF could still be improved in some aspects.
The
performance of the MPF should be compared with state-of-the-art MTTL
algorithms. Furthermore, in the current setting, the MPF does not maintain
target numbers, since no distinction is made between diﬀerent modes of the
posterior. Future work will add an identiﬁer to each mode of the posterior
distribution to maintain the target numbers.
7.2.5
Situation and Comparison of the Shape-based Online
MTTL Algorithm and the Fully Bayesian MPF
This section ﬁrst situates the two algorithms for MTTL proposed in this thesis,
the shape-based online MTTL algorithm (Chapter 5) and the fully Bayesian
MPF (Chapter 6) within the state-of-the-art MTTL algorithms discussed in
Chapter 4, and subsequently gives some guidelines on when to use each
algorithm.
The shape-based online MTTL algorithm and the fully Bayesian MPF can be
compared with the state-of-the art MTTL algorithms by using the classiﬁers
proposed in Chapter 4.
To this end, Table 7.1 shows the properties of the
two proposed algorithms according to the classiﬁers proposed in Chapter 4.
Additionally, Figure 7.1 extends the decision graph of Figure 4.14, which
helps researchers in choosing an algorithm from the state-of-the-art MTTL
algorithms that is suited for their particular MTTL problem, with the shape-
based online MTTL algorithm and the fully Bayesian MPF.
As can be seen from Table 7.1 and Figure 7.1, both the shape-based online
MTTL algorithm and the fully Bayesian MPF are able to handle a varying
number of targets, nonlinear process and measurement models and multiple
measurements originating from a single target. In contrast to the shape-based
online MTTL algorithm, the fully Bayesian MPF can also handle merged
measurements. The shape-based MTTL algorithm is however, unlike the fully
Bayesian MPF, capable of maintaining unique track identities throughout the
tracking. The shape-based online MTTL algorithm and the fully Bayesian MPF
both operate in a state space with the dimension of a single target state, hereby
avoiding the exponential growth of the state space with the number of targets.
The shape-based online MTTL algorithm maintains a bank of separate ﬁlters,
one for each target, each operating in its own state space. The fully Bayesian

7.2 Main Contributions
257
No Modeled Target Interactions
No Fixed Number of Targets
yes
yes
yes
yes
yes
yes
yes
yes
yes
no
no
no
no
no
no
no
no
no
Linear Models
Merged Measurements
Multiple Measurements
Maintains Target
Maintains Target
Identities
Identities
Multiple Hypotheses
Multiple Trackers
State Space with Dimension
State Space with Dimension
Single Target State
Single Target State
?
MPF
basic MHT
MG-PHD
MTPF
MHT
SJPDAF
HPF
HMPF
SMC-PHD
Shape-based
online MTTL
Fully Bayesian
Figure 7.1: Situation of the two MTTL algorithms developed in this thesis (Shape-based online MTTL (Chapter 5) and
Fully Bayesian MPF (Chapter 6)) in a part of the decision graph proposed in Chapter 4 to help researchers in choosing
an algorithm suited for their particular MTTL problem (Figure 4.14).

258
Chapter 7
General Conclusions
hhhhhhhhhhhhhhh
Property
Algorithm
Shape-based
online MTTL
Fully Bayesian
MTTL
(O)nline vs. (B)atch
O
O
(P)arametric/(N)onparametric
P/N
N
(A)ble/(U)nable to maintain track
identities
A
U
Number of targets: (FN) ﬁxed
and known, (VU) varying and
unknown
VU
VU
(L)inear/(N)onlinear models
L/N
N
(A)ble/(U)nable to handle
multiple measurements
A
A
(A)ble/(U)nable to handle merged
measurements
U
A
(E)xplicit gating or (N)ot
E
N
State space: (ST) dim. single
target, (AT) groups all target
states (ATD) AT + data ass. var.,
(RFS) space of RFS
ST
ST
(SM) single multimodal, (SJ)
single joint, or (MT) multiple
trackers
MT
SM
Data ass. problem: (C)
circumvented, (H) hard or, (S)
soft ass.
S
C
Data ass. variables: (E)
estimated, (M) marginalized
M
-
Table 7.1: Properties of the shape-based online MTTL algorithm (Chapter 5)
and the fully Bayesian MPF (Chapter 6) according to the classiﬁers proposed
in Chapter 4.
MPF however, formulates the estimation problem in the state space of a single
target by ﬁtting a mixture to the multimodal posterior and maintains a ﬁlter
for each component of the mixture. All ﬁlters, each tracking a component, are
therefore operating in the same state space.
With respect to performance, the shape-based online MTTL has been shown
to better handle MTTL problems with targets that are closely interacting for
longer periods of time than the fully Bayesian MPF. The shape-based online

7.3 Suggestions for Future Work
259
MTTL maintains a separate estimator for the number of targets while the
fully Bayesian MPF will determine the number of targets from the number of
blobs in the particle cloud at that particular time step. The separate estimator
for the number of targets of the shape-based online MTTL has been shown
to be a good estimator, even during occlusions and close target interactions.
The estimated number of targets will only change if suﬃcient evidence has
arrived to motivate the appearance or disappearance of a target. For the fully
Bayesian MPF however, if targets are closely interacting, the two particle clouds
representing the two targets will become more similar and the BWSR step will
tend to merge the two particle clouds into a single component of the mixture.
Therefore, the MPF thinks that one target has disappeared and will remove
the estimator of the target that has ‘disappeared’.
7.3
Suggestions for Future Work
This thesis presented four contributions in the area of multitarget tracking
and localization. The ability to keep track of targets, e.g. people or other
robots, in real time is fundamental in a wide range of robotic applications
including personal and service robots, intelligent factories with human-robot
cooperation, robot football, intelligent cars, crowd control, surveillance, robot-
animal interactions, etc. Both people and animals are however not independent
targets but social beings that interact with each other, cooperate, form groups,
merge to larger groups, or separate from groups. Likewise, robot teams and
swarms are programmed to interact as a team and hence they exhibit social-like
behavior. Therefore, MTTL algorithms should be extended with the ability
to track targets that are closely interacting, and to track groups of targets.
Despite the fact that the tracking of closely interacting targets will proﬁt from
the use of target shape and advanced motion models taking into account target
interactions, most state-of-the-art MTTL algorithms are limited to targets
with simple Gaussian or elliptical target shapes and simple motion models.
Therefore, future research can focus on extended MTTL algorithms with more
advanced models for the target shapes and more advanced motion models.
Furthermore, keeping track of targets is not suﬃcient in robotics. To allow for
intelligent and safe robotic behavior the robot has to be aware, on top of the
positions, of the intention of the targets. For instance in intelligent factories,
the robot should estimate or recognize what the human coworker’s intention is:
if the coworker is heading for a work cell, robots can prepare the work cell; if a
coworker is reaching for an object, a robot can hand it over. Therefore, future
research can focus on using the output of the MTTL algorithm to estimate the
intention of the targets.

260
Chapter 7
General Conclusions
While this thesis mainly focused on algorithms for MTTL, these algorithms
should be supplemented with ‘estimation skills’ that are able to coordinate and
monitor the MTTL algorithms in order to obtain robust estimation during long-
term robotic tasks. Therefore, future research can focus on the development of
these estimation skills.
While the contributions of this thesis are situated at the subsymbolical level,
recent and future research aims at using symbolical and high-level knowledge
representations in estimation.
The symbolical and high-level knowledge
representations are an answer to the need for generality required by autonomous
robot systems having to act in a real-world environment. To accommodate
for both the need for knowledge representation and the ability to reason
under uncertainty, probabilistic algorithms have to be combined with high-level
knowledge representations such as ﬁrst-order logic. Knowledge representation
and reasoning is an area in artiﬁcial intelligence that is concerned with how
to formally ‘think’, that is, how to use a symbol system to represent an
entire domain, along with rules that generalize over the domain of relevant
objects. First-order languages allow to abstract away from concrete objects,
allowing models to be as general as possible, while not being speciﬁc to
a particular instance of for instance the robot environment.
Logical and
relational learning is the study of machine learning and data mining within
expressive knowledge representation formalisms encompassing relational or
ﬁrst-order logic (De Raedt 2008).
It speciﬁcally targets learning problems
involving multiple entities and the relationships amongst them. In order to
combine probabilistic algorithms with high-level knowledge representations,
probabilistic models for relational data can be applied. These models can be
expressed in representation languages like Markov logic networks (Richardson
and Domingos 2006), relational Bayesian networks (Jaeger 2001), probabilistic
relational models (Friedman et al. 1999), or Bayesian logic programs (Kersting
and De Raedt 2001). Probabilistic models for relational data allow to extend
probabilistic graphical networks with the concept of logical representations of
objects, their properties and relations and specify a template for a probability
distribution over a domain. The template includes a relational component that
describes the relational scheme for the domain and a probabilistic component
that describes the probabilistic dependencies in the domain.
Relational
robotics, i.e. the application of statistical relational learning within robotics
is an emerging ﬁeld and a promising line of research (Cocora et al.
2006;
Liao et al. 2005; Meyer-Delius et al. 2007; Jain et al. 2009). Therefore, future
research can aim at combining the MTTL algorithms with high-level knowledge
representations and relational learning.
Below, some possible future research tracks are discussed in more detail: (1) the
extension of MTTL algorithms towards more general target shapes and more
advanced motion models, (2) the use of high-level knowledge representations

7.3 Suggestions for Future Work
261
and relational learning to track groups of targets, (3) the estimation of the
target intentions based on the output of a MTTL algorithm, and (4) the
development of estimation skills for coordinating estimation.
7.3.1
MTTL Algorithms with more General Target Shapes
and more Advanced Motion Models
Despite the fact that the potential of using more advanced target shapes and
more advanced motion models has already been shown in for instance the
tracking of closely interacting targets (Chapter 5), most state-of-the-art MTTL
algorithms are limited to simple target shapes and motion models.
Although targets can have complex and even multipart shapes, many state-of-
the-art MTTL algorithms (Koch and Feldmann 2009) are limited to simple
Gaussian or elliptical target shapes.
Consider for instance the application
of range-based people tracking where placing the range ﬁnder at leg height
results in two independent groups of measurements: one for each leg. For this
setup, a tracker for a single target corresponding to two legs was developed
using a switching dynamic model (Taylor and Kleeman 2004). Likewise, in the
computer vision community methods for tracking a single target with a complex
shape in the presence of clutter (Nascimento and Marques 2004) and methods
for detection of targets using a probabilistic object representation framework
based on Markov networks (Detry et al. 2009) have been developed, but again,
these methods have not been applied to MTTL. Future research can explore
diﬀerent methods for describing target shapes and apply them to MTTL in
order to track targets with complex shapes and in order to improve tracking
performance during for instance close target interactions.
While motion models are very important during MTTL, especially during target
occlusions, the motion models of state-of-the-art MTTL algorithms do not
adequately capture the dynamics of complex moving targets (Arras et al. 2008).
Switching Linear Dynamic System (SLDS) models, a special case of dynamic
Bayesian networks, are a powerful and popular tool for modeling complex linear
dynamic systems (Oh et al. 2008). In an SLDS model there are multiple linear
dynamic models that underlie the motion, one for each behavioral mode. While
inference methods have been presented for modeling and interpreting complex
target motions for oﬄine application and learning complex temporal patterns
for single targets (Oh et al. 2008; Pavlovic et al. 1999), there is still a challenge
in applying these methods for online MTT with complex and possibly multipart
shapes in order to track motions and to improve the tracking performance
during for instance occlusions and close interactions of targets.

262
Chapter 7
General Conclusions
7.3.2
Tracking Groups of Targets
Another topic of future research is to reveal semantic information about the
group formation processes of targets and to track the targets during these group
formation processes. This study is useful, since (i) it is a ﬁrst step towards
understanding target activities, (social) relations and intentions, and (ii) it
helps to reduce the computational cost by enabling tracking groups of targets
rather than individual targets. To achieve group tracking the following two
subgoals can be deﬁned: (1) learning and online estimation of group formation
processes while maintaining individual target tracks, and (2) online estimation
of group formation processes without maintaining individual target tracks. The
ﬁrst step can directly build on the tracks of individual targets obtained from a
MTTL algorithm. These tracks can be used (i) to learn the relations involved
in group formation processes, and (ii) to estimate the group formations and
tracks of the groups online using the learned group formation processes. To
this end probabilistic models for relational data can be applied. Probabilistic
models for relational data extend probabilistic networks with the concept of
logical representations of objects, their properties and relations and specify a
template for a probability distribution over a domain.
Future research can
consist of building a framework for tracking of groups by building on relational
models. This application is, beside new, challenging since the tracking problem
does not only involve discrete but also continuous and time-dependent variables.
Since learning general probabilistic relational models is hard, future research
should aim at developing application-speciﬁc optimizations and approximations.
This research should also beneﬁt from links with social and biological sciences
where social interactions are studied (Hall 1974).
Despite the increasing resolution of modern sensors, individual targets are
often unresolvable during close interactions and group formation. Furthermore,
during close interactions and group formation, individual targets are typically
occluding each other. Trying to maintain individual target estimates in these
cases is challenging due to (i) the data association ambiguity, i.e. the space of
feasible measurements to target associations quickly becomes intractable, and
(ii) the individual targets can be occluded for prolonged periods of time (Lau
et al. 2009; Lau et al. 2010). Furthermore, for many applications, knowledge
about groups can be suﬃcient if the task does not require to know the state
of every individual target: e.g.
a mobile service robot traveling in densely
populated environments. Therefore, future research can aim at tracking groups
consisting of multiple targets. The high-level abstraction on group formation
processes provided by the group tracker will be used to manage the individual
trackers, which can then both correspond to individual targets and groups of
targets (Lau et al. 2009; Lau et al. 2010). Since groups of people can form
complex and even multipart shapes, the group tracker will beneﬁt from research
on integrating more complex shapes in MTTL algorithms.

7.3 Suggestions for Future Work
263
7.3.3
Beyond Tracking: Target Intention Estimation
As explained before, intelligent and safe robotic behavior during for instance
human-robot interaction, requires that the robot is aware on top of the target
(i.e.
humans and robots) tracks, of the intention of the targets.
While a
lot of valuable research already has been done on target intention estimation,
there is still a challenge in estimating or recognizing the target intention by
studying its motion trajectory. Since mid and long-term target behaviors and
activities can be well described by an underlying motion trajectory, studying
motion trajectories for eﬀective motion description and intention estimation
and recognition is of practical importance. While valuable methods have been
developed for learning collections of typical trajectories that characterize the
motion patterns of targets in a ﬁxed environment (Bennewitz et al. 2005), there
is still a challenge in developing methods which (i) can learn models for motion
primitives from multiple demonstrations in diﬀerent contexts and environments,
and (ii) can use these models in still diﬀerent contexts and environments.
Future work can build on recent work of Joris De Schutter (De Schutter 2010)
where a minimal, invariant, coordinate-free description of rigid body motion
trajectories is proposed.
This work provides a theoretically sound basis for
representing human or robot motion facilitating recognition, classiﬁcation, and
characterization of an executed motion, as well as model-based generation of a
motion that is adapted to a speciﬁc task and task environment. The invariants
can be used (i) to develop a probabilistic ﬁlter to allow for online estimation
of the invariants, (ii) to learn collections of invariant descriptions of typical
motion trajectories for core tasks from human demonstration or recorded
motions (Pastor et al.
2009), and (iii) to develop an online probabilistic
recognition based on the obtained invariants (Park et al. 2005). While the
intention estimation algorithms can be used for learning and recognizing typical
motion patterns for humans and robots, their full power will only be shown
when applied to general six degree-of-freedom motions. Therefore, the methods
for intention estimation should be applicable to for instance human intention,
where motion trajectories can be learned and recognized by studying the motion
of the tool held by the human.
7.3.4
Estimation Skills for Coordinating Estimation
Robots are evolving from industrial work cells to domestic, cluttered and
populated real-world environments, where they have to execute tasks over
prolonged periods of time. The execution of these tasks requires more than
just algorithms for task speciﬁcation and estimation. Since these tasks consist
of a sequence of subtasks, each with its own motion speciﬁcation, controller
and estimator, they have to be coordinated and conﬁgured. The coordination

264
Chapter 7
General Conclusions
and conﬁguration level is called a skill (Smits 2010) in the robotic domain. A
skill is more formally deﬁned as the component of a robot control system that
is responsible for the coordinated execution and parameter conﬁguration of the
set of available instantaneous robot motion controllers, such that, together,
multiple motion controllers let the robot system realize a given task in a
given environment (Smits 2010).
Since future robots will operate during
prolonged periods in uncertain environments there is also a need for estimation
skills that are responsible for the coordinated execution and conﬁguration
of the available estimators.
These skills are responsible for monitoring the
estimation algorithms (for instance the MTTL algorithms), the decision of
when to apply which estimation algorithms, and the reconﬁguration of the
estimation parameters and models underlying the estimator when necessary.
Since ﬁnite state machines (FSM) (Gill 1962; Ginsburg 1962) have proved to
be suited to implement coordination of robot tasks (Finkemeyer et al. 2005;
Dillmann et al. 1995; Smits 2010), future work consists of the development of
estimation skills and the implementation of these skills using FSMs. To this
end the four primitives (states, actions executed during the state, transitions
between states, and events triggering the transitions) have to be deﬁned for
the estimation skills. This requires the deﬁnition of features and properties of
the estimation algorithms that are suited to trigger events in the FSM, and
mechanisms allowing for a smooth transition between diﬀerent states of the
estimation skill (for instance between diﬀerent estimation algorithms).

Chapter 8
Other Contributions
This chapter brieﬂy discusses three other contributions made during the thesis,
of which two resulted in a journal publication and one is related to software.
Although these three contributions are outside the main scope of this thesis text,
they are all concerned with the application and implementation of Bayesian
estimation techniques.
8.1
Kalman Smoothing for the Estimation of Joint
Kinematics and Kinetics in Marker-based Hu-
man Gait Analysis
In this contribution a Kalman smoothing algorithm was developed to improve
estimates of joint kinematics from measured trajectories during human motion
analysis.
Kalman smoothing estimates are based on complete marker
trajectories.
This algorithm is an improvement over other techniques, such
as the Global Optimization Method (GOM), Kalman ﬁltering, and Local
Marker Estimation (LME), where the estimate at each time instant is only
based on part of the marker trajectories. GOM, Kalman ﬁltering, LME and
Kalman smoothing were applied to marker trajectories from both simulated
and experimental gait motion, to estimate the joint kinematics of a ten
segment biomechanical model, with 21 degrees of freedom. Three simulated
marker trajectories were studied: without errors, with instrumental errors, and
with soft tissue artifacts (STA). Two modeling errors were studied: increased
thigh length and hip center dislocation.
The estimation errors from the
known joint kinematics in the simulation study were calculated. Compared
265

266
Chapter 8
Other Contributions
with other techniques, Kalman smoothing reduced the estimation errors for
the joint positions, by more than 50% for the simulated marker trajectories
without errors and with instrumental errors. Compared with GOM, Kalman
smoothing reduced the estimation errors for the joint moments by more than
35%. Compared with Kalman ﬁltering and LME, Kalman smoothing reduced
the estimation errors for the joint accelerations by at least 50%. The simulation
results show that the use of Kalman smoothing substantially improves the
estimates of joint kinematics and kinetics compared with previously proposed
techniques (GOM, Kalman ﬁltering, and LME) for both simulated, with and
without modeling errors, and experimentally measured gait motion.
The above contribution was published as a full article in the Journal of
Biomechanics (De Groote et al.
2008).
My contribution is mainly in
the appliation of Bayesian estimation techniques and especially the Kalman
smoother to the high-dimensional estimation problems where the individual
degrees of freedom are related through an underlying musculoskeletal model,
while the thorough simulations and experiments, the comparison to other
methods, and the biomechanical interpretation is the work of Friedl De
Groote (De Groote 2009).
8.2
Constraint-based Task Speciﬁcation and Esti-
mation for Sensor-based Robot Systems in the
Presence of Geometric Uncertainty
The work on constraint-based task speciﬁcation and estimation consists of
a systematic constraint-based approach to specify complex tasks of general
sensor-based robot systems consisting of rigid links and joints. The approach,
called iTaSC (short for instanteneous task speciﬁcation based on constraints),
integrates both instantaneous task speciﬁcation and estimation of geometric
uncertainty in a uniﬁed framework. Major components are the use of feature
coordinates, deﬁned with respect to object and feature frames, which facilitate
the task speciﬁcation, and the introduction of uncertainty coordinates to model
geometric uncertainty. While the focus of this work is on task speciﬁcation, an
existing velocity-based control scheme is reformulated in terms of these feature
and uncertainty coordinates. This control scheme compensates for the eﬀect
of time varying uncertainty coordinates. Constraint weighting results in an
invariant robot behavior in case of conﬂicting constraints with heterogeneous
units. The approach applies to a large variety of robot systems (mobile robots,
multiple robot systems, dynamic human-robot interaction, etc.), various sensor
systems, and diﬀerent robot tasks. Ample simulation and experimental results
are presented.

8.3 Bayesian Filtering Library (BFL)
267
The constraint-based task speciﬁcation approach was published as a full article
in the International Journal of Robotics Research (De Schutter et al. 2007).
My contribution to iTaSC is mainly in the application of the constraint-based
task speciﬁcation approach to a number of involved robotic examples (De Laet
et al. 2007a; De Laet et al. 2007b; Decré et al. 2007; De Schutter et al. 2007),
the development of control schemes for iTaSC (De Laet and De Schutter 2007),
and in the development of a Bayesian estimation procedure for the geometric
uncertainties in the robot system (De Laet et al. 2007a; De Laet et al. 2007b;
Decré et al. 2007; De Schutter et al. 2007).
8.3
Bayesian Filtering Library (BFL)
The Bayesian ﬁltering library (BFL) (Gadeyne and De Laet 2001) is the
estimation component of Orocos (Open Robot Control Software) (Bruyninckx
2001). BFL was founded by Klaas Gadeyne (Gadeyne 2005) and provides an
application independent framework for inference in dynamic Bayesian networks,
i.e., recursive information processing and estimation algorithms based on Bayes’
rule, such as (extended) Kalman Filters, particle ﬁlters (sequential Monte Carlo
methods), etc. These algorithms can, for example, be run on top of the realtime
services, or be used for estimation in kinematics and dynamics applications.
During my thesis I was the maintainer of BFL, wrote a tutorial for
BFL (De Laet et al.
2005), and extended BFL with more types of prob-
ability distributions, smoothing algorithms (Rauch-Tung-Striebel smoother
(Bar-Shalom and Li 1993; Rauch et al. 1965) and particle smoother (Isard
and MacCormick 1998)), clustering algorithms, data association algorithms,
and a toolkit for use with the real time services of Orocos.


References
Aarno, D. and D. Kragic (2006). Layered HMM for motion intention
recognition.
In
Proceedings
of
the
2006
IEEE/RSJ
International
Conference on Intelligent Robots and Systems, Beĳing, China, pp. 5130–
5135. IROS2006.
Aarno, D. and D. Kragic (2008). Motion intention recognition in robot
assisted applications. Robotics and Autonomous Systems 56, 692–705.
Abramowitz, M. and I. A. Stegun (1965). Handbook of Mathematical
functions. Dover.
Ackerson, G. and K. Fu (1970, february). On state estimation in switching
environments. IEEE Transactions on Automatic Control 15(1), 10–17.
Arras,
K.
O.,
J.
Castellanos,
M.
Schilt,
and
R.
Siegwart
(2003).
Feature-based multi-hypothesis localization and tracking using geometric
constraints. Robotics and Autonomous Systems 44, 41–53.
Arras, K. O., S. Grzonka, M. Luber, and W. Burgard (2008). Eﬃcient
people tracking in laser range data using a multi-hypothesis leg-
tracker with adaptive occlusion probabilities. In Proceedings of the 2008
IEEE International Conference on Robotics and Automation, Pasadena,
California, U.S.A., pp. 1710–1715.
Bar-Shalom, Y., K. Chang, and H. Blom (1992a). Automatic track formation
in clutter with a recursive algorithm. In Multitarget-Multisensor tracking:
Advanced Applications, pp. 25–42. Norwood, MA: Artech House.
Bar-Shalom, Y., K. Chang, and H. Blom (1992b). Tracking splitting targets
in clutter by using an interacting multiple model joint probabilistic
data association ﬁlter. In Multitarget-Multisensor tracking:
Advanced
Applications, Volume 2, pp. 93–110. Norwood, MA: Artech House.
Bar-Shalom, Y., F. Daum, and J. Huang (2009). The probabilistic data
association ﬁlter:
estimation in the presence of measurement origin
uncertainty. ICSM 29(6), 82–100.
Bar-Shalom, Y. and T. Fortmann (1988). Tracking and Data Association.
Mathematics in Science and Engineering. Academic Press.
269

270
References
Bar-Shalom, Y. and A. Jaﬀer (1972). Adaptive nonlinear ﬁltering for tracking
with measurements of uncertain origin. In Proceedings of the 11th IEEE
International Conference on Decision and Control, New Orleans, LA, pp.
243–247.
Bar-Shalom, Y. and X. Li (1993). Estimation and Tracking, Principles,
Techniques, and Software. Norwood, MA: Artech House.
Beal,
M. J. (2003). Variational algorithms for approximate Bayesian
inference. Ph. D. thesis, University College London.
Beal, M. J. and Z. Ghahramani (2003). The variational Bayesian EM
algorithm for incomplete data: with application for scoring graphical
model structures. In Valencia International Meeting on Bayesian
Statistics, Tenerife, Canary Islands, Spain.
Bennewitz, M., W. Burgard, G. Cielniak, and S. Thrun (2005). Learning
motion patterns of people for compliant robot motion. The International
Journal of Robotics Research 24(1), 31–48.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
Blackman, S. S. (2004). Multiple hypothesis tracking for multiple target
tracking. IEEE Aerospace and Electronic Systems Magazine 19(1), 5–18.
Blom, A. and E. Bloem (2000). Probabilistic data association avoiding track
coalescence. IEEE Transactions on Automatic Control 45(2), 247–259.
Blom, A. and E. Bloem (2002, December). Interacting multiple model joint
probabilistic data association avoiding track coalescence. In Proc. of the
41th IEEE Conference on Decision and Control, Volume 3, Las Vegas,
pp. 3408–3415.
Blom, H. (1984). An eﬃcient ﬁlter for abruptly changing systems. In Proc. of
the 23rd IEEE Conf. on Decision and Control, Las Vegas, pp. 656–658.
Blom, H. and Y. Bar-Shalom (1988, August). The interacting Multiple
Model algorithm for systems with Markovian switching coeﬃcients. IEEE
Transactions on Automatic Control 33(8), 780–783.
Blom, H., R. Hogendoorn, and B. van Doorn (1992). Design of a multisensor
tracking
system
for
advanced
air
traﬃc
control.
In
Multitarget-
Multisensor tracking:
Advanced Applications, Volume 2, pp. 31–63.
Norwood, MA: Artech House.
Bruyninckx,
H.
(2001).
Open
Robot
COntrol
Software.
http://www.orocos.org/. Last visited 2010.
Burgard, W., D. Fox, D. Hennig, and T. Schmidt (1996). Estimating the
absolute position of a mobile robot using position probability grids. In
Proc. of the National Conference on Artiﬁcial Intelligence.

References
271
Chang, C. and Y. Bar-Shalom (1995). Joint probabilistic data association
for multitarget tracking with possibly unresolved measurements and
maneuvers. IEEE Transactions on Automatic Control 29(7), 585–594.
Chen, B. and J. K. Tugnait (2001). Tracking of multiple maneuvering
targets in clutter using IMM/JPDA ﬁltering and ﬁxed-lag smoothing.
Automatica 37(2), 239–249.
Choset, H., K. M. Lynch, S. Hutchinson, G. A. Kantor, W. Burgard, L. E.
Kavraki, and S. Thrun (2005, June). Principles of Robot Motion: Theory,
Algorithms, and Implementations. MIT Press.
Cocora, A., K. Kersting, C. Plagemann, W. Burgard, and L. De Raedt
(2006). Learning relational navigation policies. In Proceedings of the 2006
IEEE/RSJ International Conference on Intelligent Robots and Systems,
Beĳing, China, pp. 2792–2797. IROS2006.
Collins, J. and J. Uhlmann (1992). Eﬃcient gating in data association
with multivariate Gaussian distributed states. IEEE Transactions on
Aerospace and Electronic Systems 28(3), 909–916.
Cox, I. J. (1993). A review of statistical data association techniques for
motion correspondence. International Journal of Computer Vision 10(1),
53–667.
Cox, I. J. and S. L. Hingorani (1996). An eﬃcient implementation of Reid’s
multiple hypothesis tracking algorithm and its evaluation for the purpse
of visual tracking. IEEE Transactions on Pattern Analysis and Machine
Intelligence 18(2), 138–150.
Cox, I. J. and M. L. Miller (1995). On ﬁnding ranked assignments with
application to multi-target tracking and motion correspondance. IEEE
Transactions on Aerospace and Electronic Systems 32, 486–489.
Cox, I. J., M. L. Miller, R. Danchick, and G. Newnam (1997). A comparison
of two algorithms for determining ranked assignments with application
to multi-target tracking and motion correspondence. IEEE Transactions
on Aerospace and Electronic Systems 33(1), 295–301.
Danchick, R. and G. Newnam (2006, February). Reformulating Reid’s MHT
method with generalised Murty k-best ranked linear assignment method.
IEE Proceedings of Radar, Sonar and Navigation 153(1), 13–22.
Davey, S. J. (2003). Extensions to the Probabilistic Multi-Hypothesis Tracker
for Improved Data Association. Ph. D. thesis, School of Electrical
and Electronic Engineering, Faculty of Engineering, The University of
Adelaide, South Australia.
Davey, S. J. (2007, April). Simultaneous localization and map building
using the probabilistic multi-hypothesis tracker. IEEE Transactions on
Robotics 23(2), 271–280.

272
References
Davey, S. J. and D. A. Gray (2007, January). Integrated track maintenance
for the pmht via the hysteresis model. IEEE Transactions on Aerospace
and Electronic Systems 43(1), 93–111.
de Feo, M., A. Graziano, R. Migliolo, and A. Farina (1997). IMMJPDA
versus MHT and Kalman ﬁlter with NN correlation:
performance
comparison. In IEE Proceedings Radar, Sonar and Navigation, Volume
144, pp. 49–56.
De Groote, F. (2009, November). Enhancing human motion analysis through
Kalman smoothing, convex optimization, and sensitivity analysis. Ph. D.
thesis, Department of Mechanical Engineering, Katholieke Universiteit
Leuven, Belgium.
De Groote, F., T. De Laet, I. Jonkers, and J. De Schutter (2008). Kalman
smoothing improves the estimation of joint kinematics and kinetics in
marker-based human gait analysis in marker-based human gait analysis.
Journal of Biomechanics 41(16), 3390–3398.
De Laet, T. and J. De Schutter (2007). Control schemes for constraint-
based task speciﬁcation in the presence of geometric uncertainty
using auxiliary coordinates. Internal report 07RP001, Department of
Mechanical Engineering, Katholieke Universiteit Leuven, Belgium.
De Laet, T., J. De Schutter, and H. Bruyninckx (2008). A rigorously Bayesian
beam model and an adaptive full scan model for range ﬁnders in dynamic
environments. Journal of Artiﬁcial Intelligence Research 33, 179–222.
Available online: http://jair.org/papers/paper2540.html.
De Laet, T., W. Decré, J. Rutgeerts, H. Bruyninckx, and J. De Schutter
(2007a). An application of constraint-based task speciﬁcation and
estimation for sensor-based robot systems. In Proceedings of the 2007
IEEE/RSJ International Conference on Intelligent Robots and Systems,
San Diego, California, pp. 1658–1664. IROS2007.
De Laet, T., W. Decré, J. Rutgeerts, H. Bruyninckx, and J. De Schutter
(2007b). Application of constraint-based task speciﬁcation and estimation
for sensor-based robot systems to a laser tracing task. In Book of abstracts
of the 2007 Benelux Meeting on Systems and Control, Lommel, Belgium.
De
Laet,
T.,
W.
Meeussen,
and
K.
Gadeyne
(2005).
Getting
started
guide
Bayesian
Filtering
Library.
http://people.mech.kuleuven.be/~tdelaet/tutorialBFL.html.
Last visited 2010.
De Raedt, L. (2008). Logical and Relational Learning. Springer.
De Schutter, J. (2010). Invariant description of rigid body motion trajectories.
Transactions of the ASME, Journal of Mechanisms and Robotics 2(1),
011004/1–9.

References
273
De
Schutter,
J.,
T.
De
Laet,
J. Rutgeerts,
W.
Decré,
R.
Smits,
E. Aertbeliën, K. Claes, and H. Bruyninckx (2007). Constraint-based
task speciﬁcation and estimation for sensor-based robot systems in the
presence of geometric uncertainty. The International Journal of Robotics
Research 26(5), 433–455.
Decré, W., T. De Laet, J. Rutgeerts, H. Bruyninckx, and J. De Schutter
(2007, September). Application of a generic constraint-based program-
ming approach to an industrial relevant robot task with uncertain
geometry. In IEEE International Conference on Computer as a Tool,
Warsaw, Poland, pp. 2620–2626.
Dempster, A. P., N. M. Laird, and D. B. Rubin (1977). Maximum likelihood
from incomplete data via the EM algorithm (with discussion). Journal of
the Royal Statistical Society (Series B) 39, 1–38.
Detry, R., N. Pugeault, and J. H. Piater (2009). A probabilistic framework for
3D visual object representation. IEEE Transactions on Pattern Analysis
and Machine Intelligence 31(10), 1790–1803.
Dillmann, R., M. Kaiser, and A. Ude (1995). Acquisition of elementary robot
skills from human demonstration. In Proceedings of the International
Symposium on Intelligent Robotic Systems, Pisa, Italia, pp. 185 – 192.
Du, W. and J. Piater (2005a). Tracking by cluster analysis of feature points
and multiple particle ﬁlters. In Proceedings of the 3th International
Conference on Advances in Pattern Recognition, pp. 701–710.
Du, W. and J. Piater (2005b). Tracking by cluster analysis of feature points
using a mixture particle ﬁlter. In Proceedings of the 9th International
Conference on Advanced Video and Signal based Suveillance, pp. 165–
170.
Efe,
M. and P. Willet (2004). Probabilistic multi-hypothesis tracker:
Addressing some basic issues. IEE Proceedings of Radar, Sonar and
Navigation 151(4).
Finkemeyer, B., T. Kröger, and F. M. Wahl (2005). Executing assembly
tasks speciﬁed by manipulation primitive nets. Advanced Robotics 19(5),
591–611.
Fitzgerald, R. (1990). Multitarget-Multisensor tracking:
Advanced Appli-
cations, Chapter Development of practical PDA logic for multi target
tracking by microprocessors, pp. 1–23.
Fod, A., A. Howard, and M. J. Matarić (2002). Laser-based people tracker.
In Proceedings of the 2002 IEEE International Conference on Robotics
and Automation, Washington DC, U.S.A., pp. 3024–3029. ICRA2002.
Fortmann, T. E., Y. Bar-Shalom, and M. Scheﬀe (1983). Sonar tracking of
multiple targets using joint probabilistic data association. IEEE Journal
of Oceanic Engineering 8, 173–184.

274
References
Fox, D. (2001). KLD-Sampling: Adaptive particle ﬁlters. In Advances in
Neural Information Processing Systems. MIT Press.
Fox, D. (2003, December). Adapting the sample size in particle ﬁlters through
KLD-sampling. The International Journal of Robotics Research 22(12),
985–1003.
Fox, D., W. Burgard, and S. Thrun (1999). Markov localization for
mobile robots in dynamic environments. Journal of Artiﬁcial Intelligence
Research 11, 391–427.
Friedman, N., L. Getaoor, D. Koller, and A. Pfeﬀer (1999). Learning
probabilistic relational models. In Proceedings of the 16th International
Joint Conference on Artiﬁcial Intelligence, Stockholm, Sweden, pp. 1300–
1309.
Gadeyne, K. (2005, September). Sequential Monte Carlo methods for
rigorous Bayesian modeling of Autonomous Compliant Motion. Ph. D.
thesis, Department of Mechanical Engineering, Katholieke Universiteit
Leuven, Belgium.
Gadeyne, K. and T. De Laet (2001). BFL: Bayesian Filtering Library.
http://www.orocos.org/bfl. Last visited 2010.
Gauvrit, H., J. Le Cadre, and C. Jauﬀret (1997). A formulation of multitarget
tracking as an incomplete data problem. IEEE Transactions on Aerospace
and Electronic Systems 33(4), 1242–1255.
Gennari, G. and G. Hager (2004, July). Probabilistic data association
methods in visual tracking of groups. In Proc. of the IEEE Computer
Society
Conference
on
Computer
Vision
and
Pattern
Recognition
(CVPR), Volume 2, Los Alamitos, CA, USA, pp. 876–881. CVPR: IEEE
Computer Society.
Gill, A. (1962). Introduction to the theory of ﬁnite-state machines. New York:
McGraw-Hill.
Ginsburg, S. (1962). Introduction to Mathematical Machine Theory. Addison-
Wesley series in computer science and information processing. Addison-
Wesley.
Hähnel, D., D. Schulz, and W. Burgard (2003). Mobile robot mapping in
populated environments and sensor planning. Journal of the Advanced
Robotics 17(7), 579–597.
Hähnel, D., R. Triebel, W. Burgard, and S. Thrun (2003). Map building with
mobile robots in dynamic environments. In Proceedings of the 2003 IEEE
International Conference on Robotics and Automation, Taipeh, Taiwan,
pp. 1557–1569. ICRA2003.
Hall,
E. T. (1974). Handbook of proxemics research (Society for the
Anthropology of Visual Communication). Amer Anthropological Assn.

References
275
Hoﬀmann, C. and T. Dang (2006, July). Cheap joint probabilistic data
association ﬁlters in an interacting multiple model design. In Proceedings
of the Ninth International Conference on Information Fusion, Florence,
Italy, pp. 197–202.
Hoﬀmann, C. and T. Dang (2009). Cheap joint probabilistic data association
ﬁlters in an interacting multiple model design. Robotics and Autonomous
Systems 57(3), 268–278.
Hue, C., J. P. Le Cadre, and P. Pérez (2002a). Sequential Monte Carlo
methods for multiple target tracking and data fusion. IEEE Transactions
on Signal Processing 50(2), 309–325.
Hue, C., J. P. Le Cadre, and P. Pérez (2002b). Tracking multiple objects
with particle ﬁltering. IEEE Transactions on Aerospace and Electronic
Systems 38, 791–812.
Hutchins, R. G. and D. T. Dunham (1998). Evaluation of a probabilistic
multihypothesis tracking algorithm in cluttered envrionments. Technical
report, Naval Postgraduate school monterey ca department of electrical
and computer engineering.
Isard, M. and J. MacCormick (1998). A smoothing ﬁlter for condensation. In
Proceedings of the European Conference on Computer Vision, Freiburg,
Germany. Springer-Verlag.
Jaakkola, T. S. and M. I. Jordan (2000, January). Bayesian parameter
estimation via variational methods. Statistics and Computing 10(1), 25–
37.
Jaeger, M. (2001). Complex probabilistic modeling with recursive relational
Bayesian networks. Annals of Mathematics and Artiﬁcial Intelligence 32,
179–220.
Jain,
D.,
L. Mösenlechner,
and M. Beetz (2009). Equipping robot
control programs with ﬁrst-order probabilistic reasoning capabilities. In
Proceedings of the 2009 IEEE International Conference on Robotics and
Automation, Kobe, Japan, pp. 3626–3631.
Jeﬀreys, W. and J. O. Berger (1992). Ockham’s razor and Bayesian analysis.
American Scientist 80, 64–72.
Jensen, F. V. and T. D. Nielsen (2007). Bayesian Networks and Decision
Graphs. Springer.
Jordan, M. I. (Ed.) (1999). Learning in Graphical Models. Adaptive
Computation and Machine Learning. London, England: MIT Press.
Kersting, K. and L. De Raedt (2001). Towards combining inductive
logic programming with Bayesian networks. In Proceedings of the 11th
International Conference on Inductive Logic Programming, Strasbourg,
France, pp. 118–131.

276
References
Khan, Z., T. Balch, and F. Dellaert (2005). MCMC-based particle ﬁltering
for tracking a variable number of interacting targets. IEEE Transactions
on Pattern Analysis and Machine Intelligence 27(11), 1805–1818.
Khan, Z., T. Balch, and F. Dellaert (2006). MCMC-based data association
and sparse factorization updating for real time multitarget tracking
with merged and multiple measurements. IEEE Transactions on Pattern
Analysis and Machine Intelligence 28(12), 1960–1972.
Kirubarajan, T. and Y. Bar-Shalom (2004). Probabilistic data association
techniques for target tracking in clutter. Proceedings of the IEEE 92(3),
536–557.
Koch, W. and M. Feldmann (2009). Cluster tracking under kinematical
constraints using random matrices. Robotics and Autonomous Systems 57,
296–309.
Koch, W. and G. Van Keuk (1997, July). Multiple hypothesis track
maintenance with possibly unresolved measurements.
Kotecha, H. and P. M. Djuric (2003, October). Gaussian sum particle
ﬁltering. IEEE Transactions on Signal Processing 51(10), 2602–2612.
Kulić, D., D. Lee, and Y. Nakamura (2009). Whole body motion primitive
segmentation from monocular video. In Proceedings of the 2009 IEEE
International Conference on Robotics and Automation, Kobe, Japan, pp.
3166–3172.
Kulić, D., W. Takano, and Y. Nakamura (2008). Incremental learning,
clustering and hierarchy formation of whole body motion patterns using
adaptive Hidden Markov Chains. 27(7), 761–784.
Kurien, T. (1990). Multitarget-multisensor tracking: Advanced applications,
Chapter Issues in the design of practical multitarget tracking algorithms,
pp. 43–48. Multitarget-multisensor tracking. Norwood, MA: Artech
House.
Lau, B., K. O. Arras, and W. Burgard (2009). Tracking groups of people
with a multi-model hypothesis tracker. In Proceedings of the 2009 IEEE
International Conference on Robotics and Automation, Kobe, Japan, pp.
3180–3185.
Lau, B., K. O. Arras, and W. Burgard (2010, March). Multi-model
hypothesis group tracking and group size estimation. International
Journal of Social Robotics 2(1).
Liao, L., D. Fox, and H. Kautz (2005). Location-based activity recognition
using relational Markov networks. In Proceedings of the 19th International
Joint Conference on Artiﬁcial Intelligence, Edinburgh, Scotland, pp. 773–
78.

References
277
Lindström, M. and J.-O. Eklundh (2001). Detecting and tracking moving
objects from a mobile platform using a laser range scanner. In Proceedings
of the 2001 IEEE/RSJ International Conference on Intelligent Robots
and Systems, Wailea, Hawaii, pp. 1364–1369. IROS2001.
Luginbuhl,
T.,
E. Giannopoulos,
and P. Ainsleigh (2006,
July). A
modiﬁed JPDA. In Proceedings of the Ninth International Conference
on Information Fusion, Florence, Italy, pp. 1–8.
Luginbuhl, T., Y. Sun, and P. Willett (2001, August). A track management
system for the PMHT. In Proceedings of the Fourth International
Conference on Information Fusion, Montreal, Canada.
MacCormick, J. and A. Blake (2000). A probabilistic exclusion principle
for
tracking
multiple
objects.
International
Journal
of
Computer
Vision 39(1), 57–71.
Madapura, J. and B. Li (2008). Multi-target tracking based on KLD mixture
particle ﬁlter with radial basis function support. In Proceedings of IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 725–728.
Mahler, R. P. (2003). Multitarget Bayes ﬁltering via ﬁrst-order multitarget
moments. IEEE Transactions on Aerospace and Electronic Systems 39(4),
1152–1178.
McLachlan, G. J. and T. Krishnan (1997). The EM algorithm and extensions.
New York, NY: John Wiley & Sons.
Meyer-Delius, D., C. Plagemann, G. von Wichert, W. Feiten, G. Lawitzky,
and B. Wolfram (2007). A probabilistic relational model for character-
izing situations in dynamic multi-agent systems. In Conference of the
German Classiﬁcation Society.
Miller, M. L., H. S. Stone, and I. J. Cox (1997). Optimizing Murty’s ranked
assignment method. IEEE Transactions on Aerospace and Electronic
Systems 33, 851–862.
Montemerlo, M., S. Thrun, D. Koller, and B. Wegbreit (2002). FastSLAM:
A Factored Solution to the Simultaneous Localization and Mapping
Problem. In Nat. Conf. on Artiﬁcial Intelligence, pp. 593–598.
Montemerlo, M., W. Whittaker, and S. Thrun (2002). Conditional particle
ﬁlters for simultaneous mobile robot localization and people-tracking. In
Proceedings of the 2002 IEEE International Conference on Robotics and
Automation, Washington DC, U.S.A., pp. 695–701. ICRA2002.
Moore, R. and W. Blair (2000). Multitarget-multisensor tracking: Applica-
tions and advances, Chapter Practicual aspects of multisensor tracking,
pp. 1–76. Multitarget-multisensor tracking. Norwood, MA: Artech House.

278
References
Moravec, H. P. (1988). Sensor fusion in certainty grids for mobile robots. AI
Magazine 9, 61–74.
Murty, K. (1968). An algorithm of ranking all the assignments in order of
increasing cost. Operations Research 16, 682–687.
Musicki, D. and X. Wang (2007, July). A track management system for
the pmht. In Proceedings of the Tenth International Conference on
Information Fusion, Quebec, Canada.
Nascimento, J. and J. Marques (2004). Robust shape tracking in the presence
of cluttered background. IEEE Transactions on Multimedia 6(6).
Neapolitan, R. E. (2004). Learning Bayesian Networks. New York, NY:
Pearson Prentice Hall.
Ng, W., J. Li, S. Godsill, and J. Vermaak (2005a). A hybrid approach for
online joint detection and tracking for multiple targets. In Proceedings of
the 2005 IEEE Aerospace Conference, Big Sky, Montana, pp. 2126–2141.
Ng, W., J. Li, S. Godsill, and J. Vermaak (2005b). A review of recent
results in multiple target tracking. In Proceedings of the 4th International
Symposium on Image and Signal Processing and Analysis, pp. 40–45.
Oh, S., J. Rehg, and T. Balch (2008). Learning and inferring motion
patterns using parametric segmental switching linear dynamic systems.
International Journal of Computer Vision 77(1-3), 103–124.
Oh, S., S. Russell, and S. Sastry (2004, December). Markov Chain Monte
Carlo data association for general multiple-target tracking problems. In
Proc. of the 41th IEEE Conference on Decision and Control, Paradise
Island, Bahamas.
Okuma, K., A. Taleghani, N. De Freitas, J. J. Little, and D. G. Lowe (2004,
May). A boosted particle ﬁlter: Multitarget detection and tracking. In
Proceedings of the European Conference on Computer Vision, Volume
3022 of Lecture Notes in Computer Science, Prague, Czech Republic, pp.
28–39. Springer.
Oliver, N., A. Garg, and E. Horvitz (2004). Layered representations for
learning and inferring oﬃce activity from multiple sensory channels.
Computer Vision and Image Understanding 96, 163–180.
Park, H. S., E. Y. Kim, S. S. Jang, S. H. Park, M. H. Park, and H. J.
Kim (2005). HMM-based gesture recognition for robot control. Pattern
Recognition and Image Analysis 3522, 607–614.
Pastor, P., H. Hoﬀmann, T. Asfour, and S. Schaal (2009). Learning
and generalization of motor skills by learning from demonstration. In
Proceedings of the 2009 IEEE International Conference on Robotics and
Automation, Kobe, Japan, pp. 1293–1298.

References
279
Pavlovic, V., J. Rehg, T.-J. Cham, and K. Murphy (1999, September).
A dynamic bayesian network approach to ﬁgure tracking using learned
dynamic models. In Proceedings of the 7th International Conference on
Computer Vision, Kerkyra, Corfu, Greece, pp. 94–101.
Pfaﬀ, P., W. Burgard, and D. Fox (2006, March). Robust Monte-Carlo
localization using adaptive likelihood models. In H. I. Christensen (Ed.),
European Robotics Symposium, Volume 22, Palermo, Italy, pp. 181–194.
Springer-Verlag Berlin Heidelberg, Germany.
Pfaﬀ, P., C. Plagemann, and W. Burgard (2007). Improved likelihood models
for probabilistic localization based on range scans. In Proceedings of
the 2007 IEEE/RSJ International Conference on Intelligent Robots and
Systems, San Diego, California. IROS2007.
Plagemann, C., K. Kersting, P. Pfaﬀ, and W. Burgard (2007, June).
Gaussian beam processes:
A nonparametric Bayesian measurement
model for range ﬁnders. In Robotics: Science and Systems (RSS), Atlanta,
Georgia, USA.
Popp, R., K. Pattipati, and Y. Bar-Shalom (2001). m-best s-d assignment
algorithm with application to multitarget tracking. IEEE Transactions
on Aerospace and Electronic Systems 37(1), 22–39.
Puranik, S. and T. J.K. (2007). Tracking of multiple maneuvering targets
using multiscan JPDA and IMM ﬁltering. IEEE Transactions on
Aerospace and Electronic Systems 43, 23–25.
Rasmussen, C. and Z. Ghahramani (2000, December). Occam’s razor. In
Advances in Neural Information Processing 13, Denver, Colorado. MIT
Press.
Rauch, H., F. Tung, and C. Striebel (1965). Maximum likelihood estimates
of linear dynamic systems. AIAA Journal 3(8), 1445–1450.
Reid, D. (1979, December). An algorithm for tracking multiple targets. IEEE
Transactions on Automatic Control AC-24(6), 843–854.
Richardson, M. and P. Domingos (2006). Markov logic networks. Machine
Learning 62(1–2), 107–136.
Roecker,
J. (1994). A class of near optimal jpda algorithms. IEEE
Transactions on Aerospace and Electronic Systems 30(2), 504–510.
Roecker, J. (1995). Multiple scan joint data association. IEEE Transactions
on Aerospace and Electronic Systems 31(3), 1204–1210.
Roecker,
J.
and
G.
Phillips
(1993).
Suboptimal
joint
probabilistic
data association. IEEE Transactions on Aerospace and Electronic
Systems 29(3), 510–517.
Roosendaal, T. (2002). Blender. http://www.blender.org. Last visited
March 2010.

280
References
Rusu, R. B., J. Bandouch, F. Meier, I. Essa, and M. Beetz (2009).
Human action recognition using global point feature histograms and
action shapes. Advanced Robotics journal, Robotics Society of Japan
(RSJ) 23(14), 1873–1908.
Schulz, D., W. Burgard, D. Fox, and A. B. Cremers (2001a). Tracking
multiple
moving
targets
with
a
mobile
robot.
In
Proc.
of
the
IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR), Hawaii, USA, pp. 371–377. CVPR: IEEE Computer
Society.
Schulz, D., W. Burgard, D. Fox, and A. B. Cremers (2001b). Tracking
multiple moving targets with a mobile robot using particle ﬁlters and
statistical data assocation. In Proceedings of the 2001 IEEE International
Conference on Robotics and Automation, Seoul, Korea, pp. 1665–1670.
ICRA2001.
Schulz, D., W. Burgard, D. Fox, and A. B. Cremers (2003). People tracking
with mobile robots using sample-based joint probabilistic data association
ﬁlters. The International Journal of Robotics Research 22(2), 99–116.
Shertukde, H. and Y. Bar-Shalom (1991, July). Tracking of crossing targets
with imaging sensors. IEEE Transactions on Aerospace and Electronic
Systems 27(4), 582–592.
Shumway, R. H. and D. S. Stoﬀer (1982). An approach to time series
smoothing and forecasting using the EM algorithm. J. Time Series
Analysis 3(4), 253–264.
Smits, R. (2010, May). Robot skills: design of a constraint-based methodology
and
software
support.
Ph.
D.
thesis,
Department
of
Mechanical
Engineering, Katholieke Universiteit Leuven, Belgium.
Soetens,
P. (2006,
May). A Software Framework for Real-Time and
Distributed Robot and Machine Control. Ph. D. thesis, Department
of Mechanical Engineering, Katholieke Universiteit Leuven, Belgium.
http://www.mech.kuleuven.be/dept/resources/docs/soetens.pdf.
Song, T. L., D. G. Lee, and J. Ryu (2005). A probabilistic nearest
neighbor ﬁlter algorithm for tracking in a clutter environment. Signal
Processing 85(10), 2044 – 2053.
Streit, R. L. and T. E. Luginbuhl (1995). Probabilistic multi-hypothesis
tracking. Technical Report NUWC-NPT TR 10,428, Naval Undersea
Warfare Center Division Newport, Rhode Island.
Taylor, G. and L. Kleeman (2004). A multiple hypothesis walking person
tracker with switched dynamic model. In Proceedings of the Australasian
Conference on Robotics and Automation, Canberra, Australia.

References
281
Thrun, S. (2001). A probabilistic online mapping algorithm for teams of
mobile robots. The International Journal of Robotics Research 20(5),
335–363.
Thrun, S., W. Burgard, and D. Fox (2005). Probabilistic Robotics. MIT Press.
Thrun, S., D. Fox, and W. Burgard (2000). Monte carlo localization with
mixture proposal distribution. In Proceedings of the AAAI National
Conference on Artiﬁcial Intelligence, Austin, Texas. AAAI.
Thrun, S., D. Fox, W. Burgard, and F. Dellaert (2001). Robust Monte Carlo
localization for mobile robots. Artiﬁcial Intelligence 128, 99–141.
Vermaak, J. and A. Doucet (2003). Maintaining multi-modality through
mixture tracking. In Proceedings of the 9th International Conference on
Computer Vision, Nice, France, pp. 1110–1116.
Vermaak, J., S. J. Godsill, and P. Pérez (2005). Monte Carlo Filtering
for Multi-Target Tracking and Data Association. IEEE Transactions on
Aerospace and Electronic Systems 41, 309–332.
Vermaak, J., N. Ikoma, and S. J. Godsill (2005). A sequential Monte Carlo
framework for extended object tracking. IEE Proceedings of Radar, Sonar
and Navigation 152, 353–363.
Vo,
B.-N. and W.-K. Ma (2006). The Gaussian mixture probability
hypothesis density ﬁlter. IEEE Transactions on Signal Processing 54(11),
4091–4101.
Vo, B.-N., S. Singh, and A. Doucet (2005). Sequential monte carlo methods
for multitarget ﬁltering with random ﬁnite sets. IEEE Transactions on
Aerospace and Electronic Systems 41(4), 1224–1245.
Wang, C.-C., C. Thorpe, and S. Thrun (2003). Online simultaneous
localization and mapping with detection and tracking of moving objects:
Theory and results from a ground vehicle in crowded urban areas. In
Proceedings of the 2003 IEEE International Conference on Robotics and
Automation, Taipeh, Taiwan. ICRA2003.
Wieneke, M. and W. Koch (2008). On sequential track extraction within
the PMHT framework. EURASIP Journal on Advances in Signal
Processing 2008(Article ID 276914), 13 pages.
Willett, P., Y. Ruan, and R. Streit (2002). PMHT: Problems and some
solutions. IEEE Transactions on Aerospace and Electronic Systems 38(3),
738–754.
Wolf, D. F. and G. S. Sukhatme (2004). Mobile robot simultaneous
localization and mapping in dynamic environments. In Proceedings of
the 2004 IEEE International Conference on Robotics and Automation,
New Orleans, U.S.A., pp. 1301–1307. ICRA2004.

282
References
Zaveri, M. A., S. N. Merchant, and U. B. Desai (2007). A combined PMHT
and IMM approach to multiple-point target tracking in infrared image
sequence. EURASIP Journal on Image and Video Processing 2007(2).

Index
activity recognition, 250
adapted proposal, 139, 142, 143,
145, 146, 150, 243, 244
arc, 18
ARD, see automatic relevance de-
tection
association event, 103, 122, 188
automatic relevance detection, 5,
36, 174, 186, 243
background subtraction, 90, 178
basic
JPDAF, 129–132
MHT, 109–111
PMHT, 116–117
Bayes ﬁlter, 23, 163, 166, 167, 194
Bayes’ rule, 104, 123, 138
Bayes’ theorem, see Bayes’ rule
Bayesian
interpretation, 11
logic programs, 260
network, 18, 43, 89, 91, 170,
190, 192
Bayesian weighted spatial recluster-
ing, 6, 223, 237–243
beam model, 38, 54
binomial distribution, 12, 47
BN, see Bayesian network
BWSR, see Bayesian weighted spa-
tial reclustering
causality, 20, 44
central limit theorem, 16
clustering, 29–36, 180
clutter, see false alarms
complete data assumption, 23
conditional independence, 10
conditional probability, 9
conjugate priors, 12, 33, 67, 69, 183
constant Nth-order-derivative model,
27
continuous random variable, 8
correction, 23, 110, 121, 130, 135,
140, 155, 191
correspondence, see data associa-
tion
covariance, 10
DAG, see directed acyclic graph
data association, 92, 95–100
data likelihood function, 11
decision graph, 20
decision making, 20
directed acyclic graph, 18
Dirichlet distribution, 13, 33, 67,
69, 156, 183, 186, 241
discrete random variable, 8
dynamic environment, 37, 39
dynamic model, see process model
edge, 18
EKF, see extended Kalman ﬁlter
EM, see expectation-maximization
evidence, 19
expectation-maximization, 21, 37,
63, 114, 181, 240
clustering, 30–33
expected value, 10
283

284
Index
expert knowledge, 11
exponential distribution, 15
extended Kalman ﬁlter, 25, 111,
131, 169, 191
false alarms, 92, 94, 104, 106, 118,
119, 123, 124, 140, 165,
168, 189
false measurements, see false alarms
ﬁeld of view, see observation vol-
ume
ﬁltering step, see correction
ﬁnite state machines, 264
frequentist, 11
FSM, see ﬁnite state machine
full scan model, 38, 39, 75, 237
gate, 96, 141
gating, 96, 101, 109, 124, 148, 154,
157, 190, 193
Gaussian distribution, 15, 49, 105,
109, 110, 116, 129, 152,
168, 176, 177, 181, 191,
245
Gaussian ﬁlter, see Kalman ﬁlter
Gaussian mixture PHD ﬁlter, 168–
169
Gaussian-Wishart distribution, 16,
33, 67, 69, 183, 241
generative model, 43
geometric distribution, 14, 46
gesture recognition, 250
global nearest-neighbor, 97
GM-PHD ﬁlter, see Gaussian mix-
ture PHD ﬁlter
hard assignment, 33, 99, 101, 176,
225
Hellinger distance, 72
hidden random variable, 19
histogram, 17
HMPF, see hybrid marginalized par-
ticle ﬁlter
hospitality, 120
HPF, see hybrid particle ﬁlter
hybrid marginalized particle ﬁlter,
149
hybrid particle ﬁlter, 146–149
hypothesis, 97, 102
evaluation, 102, 104, 110
generation, 102, 103
IMM, see interacting multiple model
impoverishment, 26
independence, 10
independent partition particle ﬁlter,
143–146
inference, 20
innovation, 25, 131, 132
interacting multiple model, 28, 111,
120, 133
IPPF, see independent partition
particle ﬁlter
joint ﬁlters, 100
joint particle ﬁlter, 137–157
joint probabilistic data association,
99–100, 176
ﬁlter, 121–137, 188
joint probability, 9
JPDA, see joint probabilistic data
association
JPDAF, see joint probabilistic data
association ﬁlter
Monte Carlo, 134–137
sample-based, 134–137
k-means clustering, 30
Kalman ﬁlter, 24, 110, 111, 130–132
Kalman gain, 25
Kalman smoother, 117, 132
KF, see Kalman ﬁlter
KL, see Kullback-Leibler
knowledge representation, 260
Kullback-Leibler, 66, 72
latent random variable, 19
learning, 20

Index
285
likelihood model, see measurement
model
Mahalanobis distance, 96
maintain mixture step, 159, 161,
164, 223, 228, 238–243
MAP, see maximum a posteriori
marginal probabilities, 9
marginalization, 27, 38, 43, 49, 149,
151, 182, 236
Markov assumption, 23, 122, 138,
159, 163, 167, 189
Markov chain Monte Carlo particle
ﬁlter, 151
Markov logic networks, 260
max-range measurements, 56
maximum a posteriori, 11, 116, 136,
184, 192, 243
maximum likelihood, 11, 31, 37, 61,
91, 109, 184, 243
MC-JPDAF, see Monte Carlo JPDAF
MCMC particle ﬁlter, 151–154
MCMC-PF, see MCMC particle
ﬁlter
MCMC-sampling, 139, 176
MCPdf, see Monte Carlo pdf
measurement model, 29, 92, 190,
191, 221, 223, 225, 228–
230, 237, 244, 248
measurement-to-target, 92
measurement-to-track, see measurement-
to-target
merged measurements, 96, 100, 108,
111, 127, 133, 143–145,
149, 151, 154, 157, 163,
168
MHT, see multihypothesis tracking
mixed random variables, 8
mixture, 18, 114, 121, 129, 152, 158,
168, 177, 181, 222, 225,
226, 245
mixture particle ﬁlter, 6, 157–164,
177, 221–248
ML, see maximum likelihood
Monte Carlo
ﬁlter, see particle ﬁlter
pdf, 17, 134, 137, 158, 177, 192,
225, 226
simulation, 59
motion analysis, 249
motion correspondence, see data
association
motion intention recognition, 249
motion model, see process model
MPF, see mixture particle ﬁlter
MTPF, see multitarget particle ﬁl-
ter
MTT, see multitarget tracking
MTTL, see multitarget tracking and
localization
multihypothesis tracking, 97–99, 102–
111, 225
multinomial distribution, 13, 31
multiple measurements,
96,
100,
108, 112, 118, 127, 128,
143, 146, 149, 151, 154–
157, 163, 168, 173, 177
multitarget particle ﬁlter, 154–157
multitarget tracking, 2, 90, 174, 222
and localization, 2, 89, 90, 173,
174, 222
Murty’s algorithm, 99, 108, 124,
127, 147, 190, 193
mutual exclusion, 96
narcissism, 120
nearest-neighbor, 97, 176, 221, 225,
226, 228, 237, 248
NN, see nearest-neighbor
node, 18
non-adaptivity, 119
non-parametric distribution, 11
normal distribution, see Gaussian
distribution
observation model, see measurement
model

286
Index
observation volume, 92, 94, 95, 124,
140, 155
parametric distribution, 11
particle distribution, see Monte Carlo
pdf
particle ﬁlter, 26, 91, 135, 138, 142,
145, 150, 155, 192, 223,
226
particles, 17
PDA, see probabilistic data associ-
ation
pdf, see probability density func-
tion
perceptual grouping, see data asso-
ciation
PF, see particle ﬁlter
PHD, see probability hypothesis
density ﬁlter
plate, 19
pmf, see probability mass function
PMHT, see probabilistic multihy-
pothesis tracking
point process, see random ﬁnite
sets
Poisson distribution, 14, 106, 123,
167
Poisson process, 14, 192, 244
prediction, 23, 110, 121, 130, 134,
178, 190
prior knowledge, 11
probabilistic data association, 99
probabilistic inference, 8
probabilistic multihypothesis track-
ing, 111–121
probabilistic relational models, 260
probability density function, 8
probability hypothesis density, 166
probability hypothesis density ﬁl-
ter, 164–170
probability mass function, 8
process model, 27–29, 92
product rule, 9, 49
proposal step, 26, 138, 155, 159
pruning, 102, 106, 109, 118, 133,
143, 145, 148, 225
random ﬁnite sets, 164, 165
random variables, 8
RBBM, see rigorously Bayesian beam
model
recursive jump Markov chain Monte
Carlo particle ﬁlter, 149–
151
region of interest, 146
relational
Bayesian networks, 260
learning, 260
probabilistic models, 260
robotics, 260
resampling, 26, 135, 160, 170
responsability, 32, 34, 115, 116, 184,
186
RFS, see random ﬁnite sets
rigorously Bayesian, 2
rigorously Bayesian beam model, 5,
37, 42–59, 223, 234–237
RJMCMCPF, see recursive jump
Markov chain Monte Carlo
particle ﬁlter
ROI, see region of interest
sample-based JPDAF, 190, 191
samples, see particles
sequential Monte Carlo ﬁlter, see
particle ﬁlter
sequential Monte Carlo PHD ﬁlter,
169–170
sequential sampling particle ﬁlter,
139–143
SJPDAF, see sample-based JPDAF
skill, 264
estimation, 264
SMC, see sequential Monte Carlo
SMC-PHD ﬁlter, see sequential Monte
Carlo PHD ﬁlter
SN, see strongest-neighbor

Index
287
soft assignment, 33, 99, 101, 117,
118, 121, 129, 143, 145,
149, 176, 221, 225, 248
spatial reclustering, 238
split measurements, see multiple
measurements
spurious measurements, see false
alarms
SSPF, see sequential sampling par-
ticle ﬁlter
state space model, see process model
strongest-neighbor, 97, 176, 225,
226
Student’s t-distribution, 16, 69
sum rule, 9
surveillance volume, see observa-
tion volume
switching state space model, 28,
111, 120, 133
system model, see process model
target, 91
correction, 102, 107, 110, 159
detection, 165
prediction, 102, 103, 110, 159
termination, 165
target-to-measurement, 92
theorem of total probability, 9
track, 91
coalescence, 127, 132–133
creation, see track detection
deletion, see track termination
detection, 92, 98, 106, 120, 127
initiation, see track detection
management, 92, 120
termination, 92, 98, 106, 120,
127
track-before-detect, 91
track-to-measurement, see target-
to-measurement
UKF, see unscented Kalman ﬁlter
unexplainable measurements, 56
uniform distribution, 12, 46, 56, 94,
95, 105, 106, 123, 124, 128,
140, 155, 245
unresolved measurements, see merged
measurements
unscented Kalman ﬁlter, 25, 169
validation volume, see gate
variance, 10
variational Bayes, 22, 37, 61, 65,
182, 209, 240, 241
variational Bayesian clustering, 33–
36, 182–184, 186, 187, 197,
206, 241
variational inference, 22
VB, see variational Bayesian
vertix, 18
weight update step, 26, 138, 159
Wishart distribution, 16, 187


Curriculum Vitae
Personal data
Tinne De Laet
August 6, 1982 in Lier (Belgium)
tinne.delaet@mech.kuleuven.be or tinne.delaet@gmail.com
http://people.mech.kuleuven.be/∼tdelaet/ or
http://sites.google.com/site/tinnedelaet/
Education
• 2005 - 2010: PhD in mechanical engineering at the Department
of Mechanical Engineering, Katholieke Universiteit Leuven, (Belgium).
Personal fund by the Research Foundation-Flanders (aspirant FWO-
Vlaanderen). Supervised by prof. Herman Bruyninckx and prof. Joris
De Schutter.
• 2003 - 2005:
Master of science in mechanical engineering
(maximo cum laude, grootste onderscheiding met felicitaties van de exam-
encommissie) specialization biomechanical engineering at the Katholieke
Universiteit Leuven, Belgium.
• 2000 - 2003: Bachelor in engineering (maximo cum laude, groot-
ste onderscheiding met felicitaties van de examencommissie) at the
Katholieke Universiteit Leuven, Belgium.
• 1994-2000: Secondary school (ASO) at Sint-Gabriëlcollege, Boechout,
Belgium.


List of Publications
Articles in Internationally Reviewed Journals
1. Tinne De Laet, Joris De Schutter, and Herman Bruyninckx.
A rigorously Bayesian beam model and an adaptive full scan model for
range ﬁnders in dynamic environments.
Journal of Artiﬁcial Intelligence Research 33, pp. 179–222, 2008.
Available online: http://jair.org/papers/paper2540.html.
2. Friedl De Groote, Tinne De Laet, Ilse Jonkers, and Joris De Schutter.
Kalman smoothing improves the estimation of joint kinematics and
kinetics in marker-based human gait analysis.
Journal of Biomechanics 41(16), pp. 3390–3398, 2008.
3. Joris De Schutter, Tinne De Laet, Johan Rutgeerts, Wilm Décre, Ruben
Smits, Erwin Aertbeliën, and Herman Bruyninckx.
Constraint-based task speciﬁcation and estimation for sensor-based robot
systems in the presence of geometric uncertainty.
International Journal of Robotics Research 26(5), pp. 433–455, 2007.
4. Tinne De Laet, Herman Bruyninckx, and Joris De Schutter.
Shape-based online multitarget tracking and localization for targets
causing multiple measurements:
variational Bayesian clustering and
lossless data association.
Submitted to the IEEE Transactions on Pattern Analysis and Machine
Intelligence, 2010.
5. Tinne De Laet, Herman Bruyninckx, and Joris De Schutter.
Fully Bayesian mixture particle ﬁlter for people tracking and localization:
by measurement model induced data-association and heuristic-free mix-
ture computation.
Submitted to the International Journal on Social Robotics, 2010.
291

292
List of Publications
6. Koen Poppe, Ronald Cools, Tinne De Laet, Herman Bruyninckx.
Quasi-Monte Carlo techniques for particle ﬁlters, an inquiry using the
Kullback-Leibler divergence.
Submitted to the IEEE Transactions on Robotics, 2010.
Book Chapters, Internationally Recognized Scientiﬁc
Publisher
1. Tinne De Laet, Ruben Smits, Joris De Schutter, and Herman Bruyninckx.
Adaptive full scan model for range ﬁnders in dynamic environments.
In: Experimental Robotics, Springer tracts in Advanced Robotics, 54, pp.
441–450, 2009. Springer Berlin / Heidelberg.
2. Ruben Smits, De Laet Tinne, Kasper Claes, Herman Bruyninckx, Joris
De Schutter.
iTaSC: a tool for multi-sensor integration in robot manipulation.
In: Lee S., Ko H., Hahn H. (Eds.) Multisensor Fusion and Integration
for Intelligent Systems, pp. 235–254, 2009. United Kingdom: Springer
London Ltd.
3. Ruben Smits, Ducio Fioravanti, Tinne De Laet, Benedetto Allotta,
Herman Bruyninckx, and Joris De Schutter.
Image-based visual servoing with extra task related constraints in a
general framework for sensor-based robot systems.
In: Unifying perspectives in computational and robot vision, pp. 187–204,
United Kingdom: Springer London Ltd., 2008.
International Journal Abstract
1. Friedl De Groote, Tinne De Laet, Ilse Jonkers, and Joris De Schutter.
Bayesian ﬁltering and smoothing techniques in human motion analysis.
Journal of Biomechanics 40(S2), S407, 2007 (XXI Congress of Interna-
tional Society of Biomechanics, Taipei, Taiwan).
Papers at International Conferences and Symposia,
Published in Full in Proceedings
1. Ruben Smits, Tinne De Laet, Kasper Claes, Herman Bruyninckx, and
Joris De Schutter.

List of Publications
293
iTASC: a tool for multi-sensor integration in robot manipulation.
In:
Proceedings 2008 IEEE International Conference on Multisensor
Fusion and Integration for Intelligent Systems, pp. 445–452, Seoul, Korea,
2008.
2. Tinne De Laet, Joris De Schutter, and Herman Bruyninckx.
Adaptive full scan model for range ﬁnders in dynamic environments.
In: Proceedings of the 2008 International Symposium on Experimental
Robotics, Athens, Greece, 2008.
3. Tinne De Laet, Joris De Schutter, and Herman Bruyninckx.
Rigorously Bayesian range ﬁnder sensor model for dynamic environments.
In: Proceedings of 2008 IEEE International Conference on Robotics and
Automation, pp. 1658–1664, Pasadena, California, 2008.
4. Tinne De Laet, Wilm Decré, Johan Rutgeerts, Herman Bruyninckx, and
Joris De Schutter.
An application of constraint-based task speciﬁcation and estimation for
sensor-based robot systems.
In: Proceedings of 2007 International Conference on Intelligent Robots
and Systems, pp. 1658–1664, San Diego, California, 2007.
5. Wilm Decré, Tinne De Laet, Johan Rutgeerts, Herman Bruyninckx, and
Joris De Schutter.
Application of a generic constraint-based programming approach to an
industrially relevant robot task with geometric uncertainties.
In: Proceedings of 2007 IEEE The International Conference on Computer
as a Tool, pp. 2620–2626, Warsaw, Poland, 2007.
6. Joris De Schutter,
Johan Rutgeerts,
Erwin Aertbeliën,
Friedl De
Groote, Tinne De Laet, Tine Lefebvre, Walter Verdonck, and Herman
Bruyninckx.
Uniﬁed constraint-based task speciﬁcation for complex sensor-based robot
systems;
In: Proceedings of the 2005 IEEE International Conference on Robotics
and Automation, pp. 3618–3623, Barcelona, Spain, 2005.
Meeting Abstracts, Presented at International Con-
ferences and Symposia, Published or not Published
in Proceedings or Journals
1. Tinne De Laet, Wilm Decré, Johan Rutgeerts, Herman Bruyninckx, and
Joris De Schutter.

294
List of Publications
Application of constraint-based task speciﬁcation and estimation for
sensor-based robot systems to a laser tracing task.
In: Proceedings of the 26th Benelux Meeting on Systems and Control,
Lommel, Belgium, 13–15 maart 2007;
2. Friedl De Groote, Tinne De Laet, Ilse Jonkers, and Joris De Schutter.
Bayesian ﬁltering and smoothing techniques in gait analysis.
In: Proceedings of the 26th Benelux Meeting on systems and Control,
Lommel, Belgium, 13–15 maart 2007.
3. Friedl De Groote, Tinne De Laet, Ilse Jonkers, and Joris De Schutter.
Bayesian techniques improve human motion estimation.
American Society of Biomechanics 2007 annual conference, Stanford,
USA, 2007.
National Conference: Published in Proceedings
1. Friedl De Groote, Tinne De Laet, Tom De Wilde, Bart Haex, and Jos
Vander Sloten.
Kinematic reconstruction of the lower limb based on measurements of the
body surface.
7th National Congress of the Theoretical and Applied Mechanics, Mons,
Belgium, May 29–30, 2006.
Internal Reports
1. Tinne De Laet and Joris De Schutter.
Constraint-based control of sensor-based robot systems with uncertain
geometry.
Internal report 07RP001, 2007.

