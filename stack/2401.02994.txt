Blending Is All You Need: Cheaper, Better Alternative to
Trillion-Parameters LLM
Xiaoding Lu§ Adian Liusie§
Vyas Raina§
Yuwen Zhang¶
William Beauchamp§
§University of Cambridge
¶University College London
Chai Research
Abstract
In conversational AI research, there’s a notice-
able trend towards developing models with a
larger number of parameters, exemplified by
models like ChatGPT. While these expansive
models tend to generate increasingly better chat
responses, they demand significant computa-
tional resources and memory. This study ex-
plores a pertinent question: Can a combina-
tion of smaller models collaboratively achieve
comparable or enhanced performance relative
to a singular large model? We introduce an
approach termed Blending, a straightforward
yet effective method of integrating multiple
chat AIs. Our empirical evidence suggests that
when specific smaller models are synergisti-
cally blended, they can potentially outperform
or match the capabilities of much larger coun-
terparts. For instance, integrating just three
models of moderate size (6B/13B paramaeters)
can rival or even surpass the performance met-
rics of a substantially larger model like Chat-
GPT (175B+ paramaters). This hypothesis is
rigorously tested using A/B testing methodolo-
gies with a large user base on the Chai research
platform over a span of thirty days. The find-
ings underscore the potential of the Blended
strategy as a viable approach for enhancing
chat AI efficacy without a corresponding surge
in computational demands. 1
1
Introduction
Due to the remarkable capabilities of current gen-
erative AI technology, pre-trained large language
models (LLMs) have found extensive utilization
across a diverse array of applications. One such
application is in chat AI, where automatic systems
are deployed as conversational assistants that keep
users engaged in entertaining conversations. A
common finding is that as one scales up the num-
ber of model parameters and the training data size,
the quality and ability of the LLMs dramatically
1All
trained
models
are
provided
at
https://
huggingface.co/ChaiML.
increases. This has led to the current trend of
scaling up models to tremendous sizes, with cur-
rent state-of-the-art systems having hundreds of
billions of parameters. Although this has enabled
highly capable chat AI with extraordinary emer-
gent abilities, this comes at a practical cost of large
inference overheads, with specialized infrastruc-
ture required, and access to these systems restricted
through public APIs. It is therefore highly desirable
to overcome these dramatic practical limitations,
and have smaller and efficient chat AIs, while keep-
ing users engaged and maintaining the conversa-
tional quality that current 100B+ parameters LLMs
have achieved.
Although a single small model is unlikely to
compete against the current behemoth state-of-the-
art LLMs, one may question whether a group of
moderately-sized LLMs can together form a chat
AI of equivalent or perhaps better ability. In this
work, we introduce Blended, an innovative and
simple approach where we demonstrate that, sur-
prisingly, if responses are selected randomly from a
group of base chat AIs, the resulting combined chat
AI is highly capable and engaging, and can outper-
form systems with orders of magnitude more pa-
rameters. We interestingly observe that the blended
model appears to take characteristics that are the
“best of all", and that by conditioning a response
on the conversational history, a single model with
particular properties learns abilities from other sys-
tems. This leads to more captivating and diverse
responses, and a more engaging user experience.
We demonstrate the effectiveness of Blended over
large-scale A/B tests on real users on the CHAI
platform, where our results show that a Blended
ensemble with three 6-13B parameter LLMs, out-
competes OpenAI’s 175B+ parameter ChatGPT.
We observe significantly higher user retention for
blended ensembles than for ChatGPT-based chat
AIs, illustrating that users find Blended chat AIs to
be more engaging, entertaining and useful, despite
arXiv:2401.02994v2  [cs.CL]  9 Jan 2024

Blended only requiring a fraction of the inference
cost and memory overhead.
2
Related Work
2.1
Chat AI approaches
Chat AIs have been developed for a variety of appli-
cations, from user assistance to casual interactions
(for chitchat) (Chen et al., 2017). Early designs
were based on rule-based algorithms (Weizenbaum,
1966) which later progressed to generative retrieval-
based models (Papangelis et al., 2021). The emer-
gence of pre-trained transformer language models
marked a significant change in chat AI develop-
ment (Zhu, 2022; Vaswani et al., 2017; Zaib et al.,
2020), where scaling-up trends led to increasingly
larger Transformer-based models finetuned to con-
versational datasets for the development of chat
AIs (Adiwardana et al., 2020; Roller et al., 2021;
Bao et al., 2020; Choudhary and Kawahara, 2022;
Yan et al., 2022).
Traditionally, chat AIs have been trained with
self-supervised methods on conversational datasets.
However, more recent approaches highlight the im-
portance of human feedback in training to align
better with human expectations of an engaging con-
versation (Leike et al., 2018; Askell et al., 2021;
Gabriel, 2020). This is typically achieved through
either reinforcement learning from human feedback
(RLHF; Christiano et al., 2017; Stiennon et al.,
2020) or by using the reward model on its own to
select or filter out responses (Dathathri et al., 2019;
Irvine et al., 2023)
In our work, our Blended approach does not con-
sider how one can train better conversational LLMs,
and instead demonstrates that one can leverage a
group of existing small conversational LLMs and
encourage them to collaborate over a conversation
to form a single chat AI that generates more engag-
ing and diverse responses.
2.2
Generative system combination
Systems combination has been well-explored for
deep-learning systems, with approaches such as
stacking (Wolpert, 1992), negative correlation
learning (Liu and Yao, 1999), max-voter schemes
(Ju et al., 2018; Simonyan and Zisserman, 2014) or
probability averaging (He et al., 2016; Raina et al.,
2020; Szegedy et al., 2015) employed for a range
of regression and classification tasks. With these
ensembling methods, it has further been shown that
increasing the diversity of the individual members
can lead to better-performing combined systems
(Kilimci et al., 2018; Seijo-Pardo et al., 2017).
However, for generative language tasks where
the outputs are a sequence of tokens, most ensem-
bling approaches become inapplicable and inef-
fective. Sequence-level ensembling approaches,
though, get around this by often averaging condi-
tional token level probabilities of multiple systems
(Sennrich et al., 2015; Freitag et al., 2017; Ma-
linin and Gales, 2021; Fathullah et al., 2021). This
approach, however, often requires identical mem-
ber architectures and access to the output proba-
bilities of the tokens. With an increasing trend
of limited black box access to LLMs (e.g. Chat-
GPT (Liu et al., 2023) and BARD (Nyberg et al.,
2021)), ensembling methods that only use output
sequences may have practical benefit. Minimum
Bayes’ Risk (MBR) decoding (Kumar and Byrne,
2004) enables this by using system outputs to se-
lect the predicted ‘best’ system output. Though
this approach has traditionally been used for Auto-
matic Speech Recognition (ASR), it has also been
successfully applied to NLP tasks (Rosti et al.,
2007; Freitag et al., 2022; Manakul et al., 2023;
Raina and Gales, 2023). With a growing number
of (API-access only) deployed large language mod-
els, performing well at different tasks, (Jiang et al.,
2023) also observed the need for a method to com-
bine outputs in a blackbox setting. They propose
LLM-Blender to blend the outputs from different
language models by first ranking the outputs as per
a PairRanker and then fuse the top-K outputs us-
ing a separate deep sequence-to-sequence system
(termed GenFuser).
As with MBR and LLM-Blender, in this work
we also propose an ensembling approach that is
able to combine outputs from blackbox language
models. However, by designing our method for
the specific nature of a multi-turn task (such as
dialogue agents) our Blended approach does not
require all component systems to generate outputs
but instead stochastically selects the system that
generates the next response, allowing for model
blending at the level of a multi-turn conversation.
3
Blended
3.1
Chat AI
The objective of a chat AI is to design an automatic
system that can produce engaging and entertaining
conversations that human users can interact with.
Let uk denote the user’s kth turn, where each user

turn is a sequence of words, uk =(w(k)
1
. . . , w(k)
|uk|).
Similarly, let rk denote the system’s kth generated
response, which is also a sequence of words rk =
(w(k)
1 , . . . , w(k)
|rk|). As an implicit language model, a
particular chat AI, parameterised by θ, models the
probability of the next response given the previous
conversational history,
P(rk|u1:k, r1:k−1; θ)
(1)
During training, the system implicitly learns to as-
sign higher probability to responses that are fluent,
engaging and high quality. Therefore an output
can simply be sampled from its distribution, either
stochastically, or through an approximate search
process such as beam search.
rk ∼P(r|u1:k, r1:k−1; θ)
(2)
Inspired by InstructGPT (Ouyang et al., 2022) and
outlined in (Irvine et al., 2023), state-of-the-art chat
AIs tends to follow a three-stage-pipeline. First, a
pre-trained language model (PrLM) is fine-tuned
on a relevant textual domain, e.g. entertaining lit-
erature for the design of an engaging chatbot. Sec-
ond, a reward model is trained using explicit human
feedback, for example, by using user engagement
as a proxy for response quality (Irvine et al., 2023).
Then finally, the reward model is used to improve
the original PrLM, either by Proximal Policy Op-
timisation (Ouyang et al., 2022) or by following a
simple rejection sampling strategy.
In developing a particular chat AI, there are
many design choices such as the base PrLM, the
conversational data used in fine-tuning, and the na-
ture of human feedback used to update the system.
One may expect that different recipes and train-
ing seeds may lead to highly diverse systems that
each demonstrate unique strengths and characteris-
tics. One can then consider how a set of chat AIs
can be combined for a system with overall better
characteristics.
3.2
Ensembling
In accordance with Bayesian statistical principles,
the probability assigned to a particular response
can be conceptualized as the marginal expectation
taken over all plausible chat AI parameters,
P(rk|u1:k, r1:k−1)
(3)
=Eθ∼PΘ [P(rk|u1:k, r1:k−1; θ)]
(4)
=
Z
PΘ(θ)P(rk|u1:k, r1:k−1; θ)dθ
(5)
In practice, where we only have access to a finite set
of chat AI systems {θ1, θ2...θN}, one can approx-
imate the continuous integral as a discrete sum-
mation. Further, one can assume that PΘ(θ) is
distributed uniformly over the systems such that
PΘ(θn) =
1
N , which may be a valid assumption
if the set consists of similarly performing models.
This yields the approximation,
P(rk|u1:k, r1:k−1)
(6)
≈
X
θ
PΘ(θ)P(rk|u1:k, r1:k−1; θ)
(7)
= 1
N
N
X
n=1
P(rk|u1:k, r1:k−1; θn)
(8)
3.3
Blended
The objective of our approach is to approximately
draw samples from the true ensemble distribution
(equation 8). To achieve this approximation, each
turn Blended randomly (and uniformly) selects the
chat AI θ that generates the current response. This
process is illustrated in Algorithm 1. It can be noted
that during a conversation, the response generated
by a specific chat AI is conditional on all previ-
ous responses generated by the previously selected
chat AIs. This means that the different chat AIs
are able to implicitly influence the output of the
current response. As a result, the current response
is a blending of individual chat AI strengths, as
they collaborate to create an overall more engag-
ing conversation.
Algorithm 1 Blended Algorithm
1: k ←1
2: while true do
3:
uk ←user’s current input turn
4:
Sample model parameter θn ∼PΘ
5:
Generate response rk according to:
rk ∼P(r|u1:k, r1:k−1; θn)
6:
k = k + 1
7: end while
4
Evaluating Chat AIs
Evaluating the quality of NLG outputs is a notori-
ously challenging task (Fabbri et al., 2021; Liusie
et al., 2023), where traditional gold-standard ap-
proaches use human evaluators that score the qual-
ity of generated responses, which can be costly.

However, since chat AIs are by definition deployed
in social environments with humans, one can lever-
age statistics of users interaction as a meaningful
and aligned measure of chat AI engagingness and
quality. To assess the ’quality’ of a chat AI, we
consider two main proxy functions: the industry
standard user retention and the main objective func-
tion, user engagement.
4.1
User Retention
User retention is a standard industrial measure of
a platform’s success by measuring the fraction of
users that return to the platform k days after joining.
Let the control group Gn be a randomly selected
group of new users, where each user in this group
will only be served chat AI θn. Let Sn(k) be the
number of users from Gn that use the platform and
interact with the chat AI on day k. Therefore, the
k-day user retention rate, R(k), is simply given by
the fraction,
R(k) = Sn(k)
|Gn| .
(9)
Retention rates from different models can be com-
pared throughout the A/B testing period, where one
can compare the immediate and long-term engage-
ment of different chat AIs. Hence, for a considered
group Gn and control group Gc, one can define the
test to control retention ratio, qn(k) as
qn(k) = Rn(k)
Rc(k) .
(10)
Beyond comparing models, it is useful to extract
retention curve statistics that can summarize a chat
AI’s performance with interpretable metrics. Em-
pirical evidence suggests that the retention rate can
be modelled well as,
R∗(k) = R(1)
k−β ,
(11)
where the parameter β indicates the rate of user
retention decay days, k. Taking the log of both
sides yields;
log(q∗(k)) = ∆ζ + ∆β log k,
(12)
where ∆ζ = (log(Rw(1))−log(Rc(1)) and ∆β =
(βw −βc). One can therefore use the gradient and
intercept of the log-log linear best-fit line to esti-
mate the parameters ∆β and ∆ζ, which gives a
useful comparison of the initial retention ratio and
retention ratio decay rate relative to the control chat
AI.
4.2
User Engagement
User retention is a useful industry metric, however,
it may not perfectly align with the metrics that
are of true interest. High-quality, engaging con-
versations are likely to keep users captivated for
longer; therefore we directly define a proxy user
engagement metric as the average time spent per
visiting user. Let E(u)(t) represent whether a user
is engaged at a time t,
E(u)(t) =
(
1, user interacts in t −∆to t + ∆,
0, otherwise,
(13)
Then we can define En(t), the engagement at time
t for all users in cohort Gn, as
En(t) =
1
|Gn|
X
u∈Gn
E(u)(t).
(14)
As with user retention, the A/B setting allows for
direct comparison of the engagement between dif-
ferent chat AIs. Hence we define the test to control
engagement ratio, rn(t) as
rn(t) = En(t)
Ec(t) .
(15)
It is also useful to have an overall single metric
for the engagement score of a chat AI over time
t. Hence, to obtain this, it is empirically observed
that a sensible approximation for a chat AI engage-
ment’s decay is 2,
E∗(t) = αtγ,
(16)
This then gives a model for the test to control en-
gagement ratio as
log(r∗(t)) = ∆α + ∆γ log t,
(17)
where ∆α = (log(α(w)) −log(α(c))) and ∆γ =
(γ(w) −γ(c))). By plotting r(t) against t, a linear
line of best fit can be found, with the parameters
∆α and ∆γ being the intercept and gradient respec-
tively. This gives the summarising metrics ∆α and
∆γ to compare the engagement quality of different
test chat AIs.
5
Experiments
5.1
Experimental Set Up
Base chat AI systems: In our experiments we
consider four different base chat AI systems. We
2Periodic oscillations are not modeled here.

Blend (13,6,6B)
GPT3.5 (175B)
Vicuna+ (13B)
ChaiLLM (6B)
0
20
40
60
80
100
120
Improvement Over Control %
Engagement
Retention
Figure 1: Model performance comparisons, setting the
baseline as Pygmalion 6B. Each model is assigned to
5,000 unique new users, graphs report the day 30 reten-
tion and engagement improvement with respect to the
baseline.
first have 3 moderately sized open-sourced LLMs:
Pygmillion 6B3, Chai Model 6B4 and Vicuna 13B5.
Each base LLM has been further finetuned on
conversational data, and uses rejection sampling
from a trained reward model (detailed in (Irvine
et al., 2023)). We finally also consider the state of
art chat AI, OpenAI’s Davinci (GPT3.5), which
has 175B parameters and is only available through
a closed API call.
Methodology: Each of the base chat AI systems
are deployed with A/B tests on independent user
groups, as discussed in Section 3.3, where the
groups are of real users engaging with the Chai Re-
search Platform. We conduct a large-scale evalua-
tion with at least 10000 users in each group, and we
monitor the user engagement on the platform over
a 30-day period. Further, we deploy our blended
system (Blended), encompassing Pygmillion, Chai
Model and Vicuna. Since there can be external
factors that may influence users’ retention and en-
gagement (e.g. platform popularity, holidays etc.),
3https://huggingface.co/PygmalionAI/
pygmalion-6b
4https://huggingface.co/ChaiML/edit_
sft_pyg_v2e_cp_17515
5https://huggingface.co/lmsys/
vicuna-13b-v1.3
systems are only compared using relative engage-
ment and relative retention, which are the metrics
normalised to the selected baseline group.
5.2
Experimental Results
For each chat AI deployed on the Chai Research
platform, we compute the user engagement for each
day k, as per Equation 15 in an A/B test setting.
By considering the 20th day (k = 20), Figure 1a
shows the engagement ratio of Blended, its con-
stituent chat AIs and Open AI’s GPT-3.5. We ob-
serve that the moderate-sized chat AIs (Pygmillion,
Vicuna and ChaiLLM) have significantly lower en-
gagement than that of GPT3.5, which is expected
as GPT3.5 has over an order of magnitude more pa-
rameters. However, by blending the three base chat
AIs, not only does Blended have higher engage-
ment than each of the constituent systems, but the
performance gains are so significant that Blended
can outperform OpenAI’s GPT3.5. The success of
Blended over other chat AIs can also be observed
when comparing the k = 20 user retention ratio
(Equation 10), as seen in Figure 1.
We highlight that Blended has a total of 25B
parameters compared to OpenAIs 175B parame-
ters, and further, since responses for Blended are
each sampled from a single component chat AI,
the inference cost is equivalent to that of a single
6B/13B system. The significant difference in infer-
ence speed (measured as the inverse of total Float-
ing Point Operations at test time) is highlighted in
Figures 2 and 2 respectively, where it can be ob-
served that Blended offers significant performance
gains with respect to engagement and user reten-
tion, with speeds similar to that of small chat AIs.
Implications of this are strong: instead of scal-
ing up systems to improve quality, one can simply
blend multiple smaller open-source systems, and
without increasing any inference costs can drasti-
cally improve a user’s conversational experience.
This demonstrates the importance of model collab-
oration over simple model parameter scaling when
designing engaging and successful chat AIs.
As an objective comparison, Table 1 reports the
single metric summaries (proposed in Section 3.3).
With Pygmillion as the control, we report the test-
to-control engagement ratio metrics ∆α and ∆γ,
as well as the test-to-control retention ratio metrics
∆ζ and ∆β. Blended has the highest relative ini-
tial engagement, ∆α and the best engagement ratio
decay rate, ∆γ. Although the retention ratio decay

0
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
1.2
1.4
GPT3.5 (175B)
Blend (13,6,6B)
Vicuna+ (13B)
ChaiLLM (6B)
Relative Inference Speed (1/FLOPs)
Improvement Over Baseline
Engagement vs Inference Speed
Figure 2: User Engagement
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
GPT3.5 (175B)
Blend (13,6,6B)
Vicuna+ (13B)
ChaiLLM (6B)
Relative Inference Speed (1/FLOPs)
Improvement Over Baseline
Retention vs Inference Speed
Figure 3: User Retention
rate, ∆β is better for Vicuna than Blended, Vicuna
has a significantly lower initial retention ratio, ∆ζ,
demonstrating that Vicuna would require an ex-
tended period of time to reach Blended’s retention
score 6, as can be seen from figures 3. Overall
it is clear that Blended, using a collaboration of
smaller chat AIs, is effective in offering higher
quality conversations than a single, much larger
chat AI (OpenAI’s GPT3.5).
chat AI
∆ζ
∆β
∆γ
∆α
FLOP
Chai
0.1
0.0
0.3
0.2
1.0
Vicuna
-0.4
0.9
0.0
0.1
2.2
Pygmillion (ctrl)
0.0
0.0
0.0
0.0
1.0
Blended
0.2
0.5
2.1
1.7
1.4
GPT3.5
0.0
0.3
1.4
0.5
29.2
Table 1: Test to Control Retention and Engagement
summary statistics and inference time (total Floating
Point Operations / control) for component chat AIs
(ChaiModel, Vicuna, Pygmillion (control); Blended
and OpenAI’s Davinci GPT3.5.
6
Future Work
The work demonstrated that Blended, a collab-
oration of multiple small chat AIs, performs
better than a single large-scale chat AI, such as
OpenAI’s Davinci (ChatGPT). In this section we
offer methods by which the Blended model can be
further improved to create even more engaging
user conversations.
6This period of time is estimated to be around one year.
Selection set scaling: Experiments in this work
have demonstrated that with even a selection set
of three component chat AIs (Chai model, Vicuna
and Pygmillion), Blended is able to perform better
than the much larger Davinci GPT3.5 model. This
performance gain is attributed to the individual
expertise of each individual component model
that creates a conversation with a diverse set of
qualities as the component systems collaborate.
Hence, one simple approach to further increase the
diversity and thus richness in the conversation is
to scale to more than three component systems.
Increasing the number of component systems has
no computational cost, as inference is always only
run through a single system for each response in
Blended’s methodology. Therefore, future work
will explore the impact of increasing the selection
set of component chat AIs on the overall quality of
conversations.
Optimal Selection Distribution: As demonstrated
in Equation 6, Blended in this work adopts a simple
approximation for model selection, PΘ(θn) = 1
N .
However, although each component chat AI, θn,
may have some value to add to an overall conver-
sation, an equal contribution from each chat AI
may not be the optimal setup. Hence, to combat
this, a better approximation for the model selection
distribution can be made with,
PΘ(θn) = F(u1:k, r1:k−1)n,
(18)
where F is a deep-learning classifier trained to
predict the probability distribution over the chat
AI selection set for identifying the θn to give the

next most engaging response rk. This classifier
can be trained using standard signals from Human-
Feedback to identify effective and ineffective re-
sponses generated in conversations, e.g. if the user
regenerated the response it is indicative of being
an undesirable response. Future work will explore
methodologies to design and train such a classifier,
F to allow for a more optimal (aligned with user
engagement) distribution, PΘ to select the com-
ponent chat AI for each response, rk. A further
advantage of this approach is that we can now add
new chat AIs to the selection set, without the risk
of damaging the performance of Blended, as the
classifier learns to de-weigh the contribution from
bad quality chat AIs.
7
Conclusions
This paper introduced Blended, a simple approach
of combining multiple chat AIs by stochastically
selecting responses from the different systems.
Though simple, the approach is surprisingly power-
ful and enables a group of three 6-13B parameter
models to achieve retention and engagement that is
superior to that of the 175B ChatGPT. We demon-
strate findings over large scale user A/B tests,
which highlights that blending might be a promis-
ing solution to improve the quality of chat AIs, all
while maintaining inference costs of smaller sys-
tems.
References
Daniel Adiwardana, Minh-Thang Luong, David R. So,
Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,
Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,
and Quoc V. Le. 2020. Towards a human-like open-
domain chatbot. CoRR, abs/2001.09977.
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain,
Deep Ganguli, Tom Henighan, Andy Jones, Nicholas
Joseph, Benjamin Mann, Nova DasSarma, Nelson
Elhage, Zac Hatfield-Dodds, Danny Hernandez, Jack-
son Kernion, Kamal Ndousse, Catherine Olsson,
Dario Amodei, Tom B. Brown, Jack Clark, Sam Mc-
Candlish, Chris Olah, and Jared Kaplan. 2021. A
general language assistant as a laboratory for align-
ment. CoRR, abs/2112.00861.
Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng
Wang, Wenquan Wu, Zhen Guo, Zhibin Liu, and
Xinchao Xu. 2020. PLATO-2: towards building an
open-domain chatbot via curriculum learning. CoRR,
abs/2006.16779.
Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang
Tang. 2017. A survey on dialogue systems: Recent
advances and new frontiers. SIGKDD Explor. Newsl.,
19(2):25–35.
Ritvik Choudhary and Daisuke Kawahara. 2022.
Grounding in social media: An approach to build-
ing a chit-chat dialogue model. In Proceedings of
the 2022 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies: Student Research
Workshop, pages 9–15, Hybrid: Seattle, Washington
+ Online. Association for Computational Linguistics.
Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar-
tic, Shane Legg, and Dario Amodei. 2017. Deep
reinforcement learning from human preferences. Ad-
vances in neural information processing systems, 30.
Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane
Hung, Eric Frank, Piero Molino, Jason Yosinski, and
Rosanne Liu. 2019. Plug and play language mod-
els: A simple approach to controlled text generation.
CoRR, abs/1912.02164.
Alexander R. Fabbri, Wojciech Kry´sci´nski, Bryan Mc-
Cann, Caiming Xiong, Richard Socher, and Dragomir
Radev. 2021. Summeval: Re-evaluating summariza-
tion evaluation.
Yassir Fathullah, Mark J.F. Gales, and Andrey Malinin.
2021. Ensemble distillation approaches for grammat-
ical error correction. In ICASSP 2021 - 2021 IEEE
International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pages 2745–2749.
Markus Freitag, Yaser Al-Onaizan, and Baskaran
Sankaran. 2017. Ensemble distillation for neural ma-
chine translation. arXiv preprint arXiv:1702.01802.
Markus Freitag, David Grangier, Qijun Tan, and Bowen
Liang. 2022. High quality rather than high model
probability: Minimum Bayes risk decoding with neu-
ral metrics. Transactions of the Association for Com-
putational Linguistics, 10:811–825.
Iason Gabriel. 2020. Artificial intelligence, values and
alignment. CoRR, abs/2001.09768.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 770–
778.
Robert Irvine, Douglas Boubert, Vyas Raina, Adian
Liusie, Ziyi Zhu, Vineet Mudupalli, Aliaksei Kor-
shuk, Zongyi Liu, Fritz Cremer, Valentin Assassi,
Christie-Carol Beauchamp, Xiaoding Lu, Thomas
Rialan, and William Beauchamp. 2023. Rewarding
chatbots for real-world engagement with millions of
users.
Dongfu Jiang, Xiang Ren, and Bill Yuchen Lin. 2023.
Llm-blender: Ensembling large language models
with pairwise ranking and generative fusion.

Cheng Ju, Aurélien Bibaut, and Mark van der Laan.
2018. The relative performance of ensemble meth-
ods with deep convolutional neural networks for
image classification. Journal of Applied Statistics,
45(15):2800–2818.
Zeynep H Kilimci, Selim Akyokus, et al. 2018. Deep
learning-and word embedding-based heterogeneous
classifier ensembles for text classification. Complex-
ity, 2018.
Shankar Kumar and William Byrne. 2004. Minimum
Bayes-risk decoding for statistical machine transla-
tion. In Proceedings of the Human Language Tech-
nology Conference of the North American Chapter
of the Association for Computational Linguistics:
HLT-NAACL 2004, pages 169–176, Boston, Mas-
sachusetts, USA. Association for Computational Lin-
guistics.
Jan Leike, David Krueger, Tom Everitt, Miljan Martic,
Vishal Maini, and Shane Legg. 2018. Scalable agent
alignment via reward modeling: a research direction.
CoRR, abs/1811.07871.
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang,
Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li,
Mengshen He, Zhengliang Liu, Zihao Wu, Dajiang
Zhu, Xiang Li, Ning Qiang, Dingang Shen, Tianming
Liu, and Bao Ge. 2023. Summary of chatgpt/gpt-4
research and perspective towards the future of large
language models.
Yong Liu and Xin Yao. 1999. Ensemble learning via
negative correlation. Neural networks, 12(10):1399–
1404.
Adian Liusie, Potsawee Manakul, and Mark J. F. Gales.
2023. Llm comparative assessment: Zero-shot nlg
evaluation through pairwise comparisons using large
language models.
Andrey Malinin and Mark Gales. 2021. Uncertainty
estimation in autoregressive structured prediction. In
International Conference on Learning Representa-
tions.
Potsawee Manakul, Yassir Fathullah, Adian Liusie,
Vyas Raina, Vatsal Raina, and Mark Gales. 2023.
Cued at probsum 2023: Hierarchical ensemble of
summarization models.
Erik P. Nyberg, Ann E. Nicholson, Kevin B. Korb,
Michael Wybrow, Ingrid Zukerman, Steven Mas-
caro, Shreshth Thakur, Abraham Oshni Alvandi,
Jeff Riley, Ross Pearson, Shane Morris, Matthieu
Herrmann, A.K.M. Azad, Fergus Bolger, Ulrike
Hahn, and David Lagnado. 2021. BARD: A struc-
tured technique for group elicitation of bayesian net-
works to support analytic reasoning. Risk Analysis,
42(6):1155–1178.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
2022.
Training language models to follow in-
structions with human feedback.
arXiv preprint
arXiv:2203.02155.
Alexandros Papangelis, Paweł Budzianowski, Bing Liu,
Elnaz Nouri, Abhinav Rastogi, and Yun-Nung Chen,
editors. 2021. Proceedings of the 3rd Workshop on
Natural Language Processing for Conversational AI.
Association for Computational Linguistics, Online.
Vyas Raina and Mark Gales. 2023. Minimum bayes’
risk decoding for system combination of grammatical
error correction systems.
Vyas Raina, Mark J.F. Gales, and Kate M. Knill. 2020.
Universal adversarial attacks on spoken language as-
sessment systems. In Interspeech 2020. ISCA.
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju,
Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott,
Eric Michael Smith, Y-Lan Boureau, and Jason We-
ston. 2021. Recipes for building an open-domain
chatbot. In Proceedings of the 16th Conference of
the European Chapter of the Association for Compu-
tational Linguistics: Main Volume, pages 300–325,
Online. Association for Computational Linguistics.
Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spy-
ros Matsoukas, Richard Schwartz, and Bonnie Dorr.
2007. Combining outputs from multiple machine
translation systems. In Human Language Technolo-
gies 2007: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics; Proceedings of the Main Conference, pages
228–235, Rochester, New York. Association for Com-
putational Linguistics.
Borja Seijo-Pardo, Iago Porto-Díaz, Verónica Bolón-
Canedo, and Amparo Alonso-Betanzos. 2017. En-
semble feature selection: homogeneous and hetero-
geneous approaches.
Knowledge-Based Systems,
118:124–139.
Rico Sennrich, Barry Haddow, and Alexandra Birch.
2015.
Improving neural machine translation
models with monolingual data.
arXiv preprint
arXiv:1511.06709.
Karen Simonyan and Andrew Zisserman. 2014. Very
deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556.
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul F Christiano. 2020. Learn-
ing to summarize with human feedback. Advances
in Neural Information Processing Systems, 33:3008–
3021.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Ser-
manet, Scott Reed, Dragomir Anguelov, Dumitru
Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
2015. Going deeper with convolutions. In Proceed-
ings of the IEEE conference on computer vision and
pattern recognition, pages 1–9.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, volume 30. Curran Associates, Inc.
Joseph Weizenbaum. 1966. Eliza—a computer pro-
gram for the study of natural language communi-
cation between man and machine. Commun. ACM,
9(1):36–45.
David H Wolpert. 1992. Stacked generalization. Neural
networks, 5(2):241–259.
Rui Yan, Juntao Li, Zhou Yu, et al. 2022. Deep learn-
ing for dialogue systems: Chit-chat and beyond.
Foundations and Trends® in Information Retrieval,
15(5):417–589.
Munazza Zaib, Quan Z. Sheng, and Wei Emma Zhang.
2020. A short survey of pre-trained language mod-
els for conversational ai-a new age in nlp. In Pro-
ceedings of the Australasian Computer Science Week
Multiconference, ACSW ’20, New York, NY, USA.
Association for Computing Machinery.
Zhenyi Zhu. 2022. A simple survey of pre-trained lan-
guage models. Preprints.org 202208.0238.

