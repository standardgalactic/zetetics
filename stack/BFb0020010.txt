I. HISTORICAL DEVELOPMENT 
AND SCOPE 
I.A Newton's Mechanics 
Sir Isaac Newton (1642-1727) developed mechanics in order to understand the motion of the 
planets and their moons. He recognized that the same mechanical laws and the same "universal" 
gravitational attraction apply to all bodies, large and small. This correlation, spanning length 
and time scales from astronomical to atomic, set the stage for the study of smaller-scale terrestrial 
problems in fluid and solid mechanics, ranging down to those of special interest to Boltzmann and 
to us, the "molecular dynamics" of atomistic particles. That these problems are many, important, 
and varied can be verified by skimming any of the dozens of research journals devoted to their 
solutions. 
There are still interesting conceptual problems associated with applying Newton's mechan- 
ics in practice: how can the many degrees of freedom in a macroscopic system be described most 
simply? That is, how does the few-parameter description of thermodynamics and hydrodynamics 
come from the many-parameter microscopic description? How does the irreversible character of 
the macroscopic linear diffusion equation arise? How can we understand nonlinear phenomena 
which lie far from equilibrium without unnecessary complexity? Atomistic molecular dynamics is 
an extremely useful tool in addressing all of these questions. It can reveal the hidden mechanisms 
and correlations which underly macroscopic behavior and it can contribute to the testing and 
improvement of theoretical descriptions. 
All of the problems mechanics treats are idealized. They are not exact copies of nature, but 
are rather intended to illustrate the interesting features of nature in a relatively clear and simple 
way. Unimportant features are consciously omitted. Consider gravity. In a mole of material the 
gravitational accelerations affect the trajectories only beyond the tenth decimal place. Likewise, 
faraway stars and minor mountain ranges have a negligible influence on the evolution of the solar 
system. In atomistic mechanics our model of the atoms themselves is imperfect, not so much 
because quantum mechanics is ignored, but because our knowledge of constitutive behavior is still 
inadequate for the reliable construction of interatomic forces that can reproduce the experimental 
data. 
Because the best available trajectory data were those establishing Kepler's laws of planetary 
motion, the proving ground for Newton's ideas was astronomical. Kepler found that [1] the planets 
travel in elliptical orbits with the sun at foci of these ellipses, that [2] the vector joining the moving 
planet to the sun sweeps out area at a constant rate, and that [3] the period during which each 
ellipse is traced out varies as the three-halves power of the orbit's size. In Figure 1 we include 
finite-difference solutions of Newton's equations of motion for two different orbits. The orbits were 
generated using the ~Verlet algorithm" described in more detail below. The orbits are shown as 
series of dots to emphasize their finite-difference source. 

1.0 
0.5- 
y 
0- 
-0.5 - 
-1.0 -0.5 
Figure 1.1 
i " =-1" E = 1~2 _1 
r 2' 
2 
r 
• 
• 
I 
I 
[ 
I 
0 
0.5 
1.0 
1.5 
2.0 
X 
The orbits serve to illustrate all three of Kepler's laws. Both orbits are ellipses, composed 
of pie-slice pieces of equal areas. The relative size of the orbits has been chosen so that the period 
of the larger one is exactly eight times that of the smaller one. In accordance with Kepler's third 
law the ratio of the larger orbit's major axis size 2R to that of the smaller orbit 2r is 8 2/s = 4. 
The last two of Kepler's three laws are easily seen as consequences of the conservation 
of angular momentum and the virial theorem, respectively. As an introduction to mechanics, 
helping to establish the notation we use for more complicated many-body systems, let's consider 
these laws in more detail. For convenience, we choose a plane polar-coordinate system with an 
infinitely-massive point, the sun, at the origin. 
The angular momentum of a particle, or planet, of mass m travelling around the sun, is 
given by the cross-product of the vectors mr and v, where the velocity v is not necessarily normal 
to the direction of r. The magnitude of the cross-product mr × v is also 2 m times the rate at 
which the radius vector sweeps out area in the plane of the orbit. This equivalence of angular 
momentum with the rate of area generation establishes Kepler's second law. 
Kepler's third law is simply related to the =virial theorem", a theorem to which we will 
return in Section C of Chapter II, in greater generality. To derive the simplest, scalar, version of 
this theorem we can take the dot product of the radius vector r and Newton's equation of motion 
for the particle of mass m located at r: 

m~ = F. 
The righthand side of the dot product, r.F, is equal to the gravitational potential. A substitution, 
(,~r~) = md (r÷)Idt - m÷ ~, 
followed by a time-average over one full orbit, shows that the gravitational potential energy is also 
equal to minus twice the kinetic energy. This equivalence, between the potential, which depends 
on the orbital radius as [1/r], and minus twice the kinetic energy, which depends on the radius r 
and the period r as [r2/~2], establishes Kepler's third law. Alternatively, this law can be used to 
infer the inverse-square form of the acceleration due to gravity. 
In astronomical problems the accelerations are gravitational. In the atomistic problems of 
molecular dynamics the accelerations are much shorter ranged, acting over distances of the order 
of nanometers. In truth, atomistic systems are governed by quantum mechanics, but in these 
notes we mainly ignore quantum effects, concentrating almost completely on classical mechanics 
and its recent modifications. The rationale for this choice lies in the fact that the qualitative fea- 
tures of thermodynamic and hydrodynamic behavior are scarcely affected by quantum mechanics, 
while the difficulties involved in implementing quantum simulations, especially away from equi- 
librium, are formidable. Thus we will generate atomistic trajectories using techniques borrowed 
from macroscopic Newtonian mechanics. Newtonian mechanics is concerned with using the "ac- 
celerations" which result when "forces" act on "masses". The goal of Newtonian mechanics is the 
calculation of the velocities and trajectories of these masses. 
In the absence of "accelerations" inertial-frame particles move along straight-line trajec- 
tories. Changes in this straight-line behavior are due to "forces'. Particles respond to the forces 
imposed upon them by undergoing accelerations inversely proportional to their "masses". If 
these accelerations are given functions of the coordinates, such as the gravitational accelerations 
acting among the planets and the stars or the idealized hard-sphere repulsions acting between 
billiard-ball caricatures of atoms, the corresponding velocity changes can be calculated. Newton's 
second-order equations of motion cannot be solved without first specifying appropriate boundary 
conditions. In the usual case these would be the initial values of the coordinates and veloci- 
ties. Once these initial values are given the system of equations rnF = F(r) can be solved by 
straightforward numerical methods. 
In his CalTech lectures, Feynman provides two nice illustrations to introduce numerical 
simulation techniques. He works out two elliptical trajectories of the type shown in Figure 1 
illustrating Kepler's laws, the phase-space trajectory of a harmonic oscillator and the coordinate- 
space trajectory of a planet about the sun. In both calculations he uses a centered second- 
difference StSrmer algorithm which has come to be known as the "Verlet algorithm": 
m[rCt + dr) -- 2rCt) + rCt - dr)] = FCt) dt 

In order to start the algorithm it is necessary to approximate the initial velocity by either [r(0) - 
r(-dt)]/dt or [r(dt) - r(-dt)]/(2dt). Given the coordinates at times 0 and -dt the StSrmer- 
Verlet finite-difference equation can be solved for new values at times +dt, +2dt, .... It is easy to 
see (by expanding the left hand side in powers of~t) that the difference equation becomes exact 
through terms of order dt a for small dt. Because the "local" single-step error in r(t + dt) is of 
order dt 4 it might appear that the "global" long-time error at time r, after [r/dt] steps, would 
vanish as dt 3. But the error is actually larger, of order dt 2, because the equation of motion is 
second order. 
The reversibility of Newtonian mechanics is retained by Verlet's approximate "finite- 
difference" representation. "Reversibility" means that a movie of the motion, run backward, 
would satisfy exactly the same equations of motion. There is nothing in the mathematically sym- 
metric structure of the equations to suggest that they really do produce physically irreversible 
behavior. 
On the other hand, thermodynamics is certainly an accurate description of material be- 
havior. And thermodynamics is not reversible. In isolated systems the energy is fixed (first law 
of thermodynamics) but the entropy behaves irreversibly (second law of thermodynamics), al- 
ways increasing with time in isolated systems not in complete thermal, mechanical, and chemical 
equilibrium. For more than 100 years there has been a continuous discussion of how reversible 
equations can produce, or be used to explain, irreversible behavior. 
The apparent contradiction between the microscopic and macroscopic viewpoints can be 
concisely expressed in terms of the Zermelo-Poincarfi and Loschmidt objections to the explanation 
of irreversibility using reversible mechanics: 
(ZP) for an isoenergetic Hamiltonian system with a bounded "phase space" the long-time so- 
lution of Newton's equations must eventually approach the initial conditions arbitrarily 
closely (Zermelo-Poincar~ recurrence). [Phase space is the 2f-dimensional space whose 
orthogonal axes correspond to the f coordinates and f momenta required to describe the 
state of a system with f degrees of freedom.] 
(L) the reversibility of Newton's equations means that any entropy-producing trajectory could 
be reversed in time to make an equally valid trajectory along which the entropy would 
decrease (Loschmidt objection). 
Both objections can be illustrated by the harmonic oscillator trajectories shown in Figure 
2. Choosing an oscillator with unit mass and force constant gives an oscillator period of 27r. The 
recurrence time, for any initial state, is 2r. Figure 2 shows also the reversibility of oscillator 
trajectories. The q and ~ histories shown cover 7/12 of an oscillator period in the forward 
direction, according to the equations q = sin(t) and ~ = cos(t). In the reversed direction ~ changes 
sign, and, after 7/12 of an oscillator period, the oscillator returns to its initial state. Thus an 

q 
-1 
I 
~/2 
It 
I 
I 
I 
• Figure 
1.2 
X'X- Time reversal 
I 
I 
I 
ml 
~ 
r/2 
1 
• 
0 
I 
n 
• 
9 
• 
I 
• 
• 
E 
-1 
I 
• 
& • 
__l 
__1 
0 
~/2 
~ 
~ 
~/2 
oscillator illustrates both the Zermelo-Poincarg recurrence and the Loschmidt reversibility alleged 
to contradict the second law of thermodynamics. But the two objections to the use of reversible 
mechanics as the basis for understanding irreversible phenomena can be countered in several ways: 
(i) the time required for Poincar~ recurrence is outrageously large, reaching the age of the 
universe for systems with only a few dozen degrees of freedom. 
(ii) the information required to produce a reversed set of trajectories is not available experi- 
mentally. 
(iii) 
(iv) 
(v) 
the macroscopic equations refer only to "average" behavior. [Averages are constructed 
by including many similar systems which begin with different initial conditions.] The 
fluctuations seen in small systems can violate the second law of thermodynamics. 
the influence of boundaries, faraway stars, Coriolis accelerations, in fact, any time-varying 
influence from outside t-he system, effectively destroys reversibility. 
the Lyapunov instability of the equations (discussed below) makes it impossible in principle 
to solve them for long times. 

(vi) only very simple systems such as the harmonic oscillator whose coordinate and velocity 
trajectories are shown in Figure 2 are reversible. Systems only a little more complicated 
than the oscillator typically exhibit the chaotic irreversible behavior characteristic of real 
materials. 
The discussion of reversibility may well continue for another 100 years, but it appears 
likely that it is primarily a mathematical, as opposed to physical, problem. The intuitive ideas 
of Boltzmann, which link reversible motion equations to irreversibility, have been buttressed by 
the computer calculations carried out since the second World War. There is now no reasonable 
doubt that the solutions of the reversible equations exhibit the same irreversible behavior that 
thermodynamics and fluid dynamics describe for macroscopic systems. Furthermore, the study of 
the solutions of Newton's reversible equations, using molecular dynamics, reveals the mechanism 
for that irreversible behavior, the Lyapunov instability of the underlying equations. 
Molecular Dynamics calculations are not unduly difficult. Feynman obtains three-digit 
accuracy in both of his elliptic-orbit back-of-the-envelope calculations. If such a calculation 
involves more than a few time steps or more than a few degrees of freedom it is worthwhile to use 
a fast computer to do the work. Typical molecular dynamics simulations involve 32, 108, 256, ... 
particles (numbers chosen to be consistent with periodic face-centered cubic packing) and would 
be far from fast if pursued with pencil and paper. ~Fast" is just fast relative to human speed, 
and includes the local departmental VAX computer as well as the dozen or so ~multimegaflop" 
(~flops" is an acronym for floating-point operations per second) computers a hundred times faster 
that are used at the Lawrence Livermore Laboratory. 
There is no reasonable doubt that very high accuracy is unnecessary in solving Newton's 
equations of motion unless one is specially interested in rigor morris properties related to mathe- 
matical reversibility. High accuracy might prove necessary in classical periodic orbit calculations 
to be used as bases for estimating semi-classical quantum properties. But in a typical study 
intended to measure the pressure of a many-body system within one percent, one would expect 
to need on the order of only six-digit accuracy in the fundamental description of the dynamics. 
The dynamics must be known with a slightly greater accuracy than the desired thermodynamic 
and hydrodynamic properties because the contributing variables are generated by a differential 
equation. Thus the velocities and the accelerations (first and second time derivatives of the par- 
ticle trajectories) contribute to the energy, pressure, and other macroscopic properties of interest. 
Not just the trajectory, but also its first and second time derivatives need to be given with an 
accuracy comparable to that of the desired macroscopic averages. 
The trajectory equations for most nonlinear problems exhibit what is called ~Lyapunov 
instability". This means that the separation in the phase space between two neighboring phase- 
space trajectories increases, exponentially fast, on the average, with time. The separation con- 
tinues to increase until it approaches a value imposed by the geometric and energetic constraints 
on the system. 

Y 
1- 
0 
I 
' 
I 
' 
I 
; 
I 
' 
I 
' 
I 
x 
= t 
y 
= 
2t 
- t 2 
~-X 
= 5/4 t 
// 
Figure 1.3 
oOo 
0o0 
gO 
• 
0 
• 
gO 
O 
gO 
• 
0 
• 
OO 
O 
oO 
• 
0 
• 
0 
• 
0 
go 
• 
0 
• 
0 
• 
O 
gO 
• 
~ 
0 
• 
0 
ql) 
• 
• 
0 
O 
• 
@ 
• 
• 
@ 
• 
@ 
- 
I 
, 
I 
, 
L 
, 
I 
, 
I 
I 
0 
1 
2 
3 
4 
5 
X 
We illustrate the non-Lyapunov stable case in Figure 3 by showing the motion of a particle 
of unit mass in a gravitational field. The filled circles correspond to the trajectory of such a 
particle moving to the right, at unit x velocity, while bouncing vertically on the y = 0 plane in 
a gravitational field with g = 2. A similar particle, with x velocity component 1.25 rather than 
1.00, traces out the trajectory indicated by open circles. The two trajectories depart from each 
other linearly, not exponentially, with time. The motion is therefore =stable". 
We illustrate the Lyapunov unstable case by showing two representations (linear in Figure 
4 and semilogarithmic in Figure 5) of a ball bouncing on a unit sphere, this time with a grav- 
itational field of unity. The motion of this system is identical to that in which a ball with unit 
diameter bounces on a fixed sphere of the same size. Initially the bouncing mass point is offset by 
0.00001 diameters relative to the fixed lower ball. After nine bounces this offset has increased to 
exceed the radius of the lower ball. The exponential growth of the offset is emphasized in Figure 
5 by plotting the logarithm of the offset, which grows very nearly linearly with the number of 
bounces. Each bounce increases the offset by about a factor of 3.7. 
Boltzmann understood this dynamical instability, but widespread recognition that it is 
inherent in most systems of nonlinear differential equations was long in coming. The instability is 
easily illustrated by calculating the maximum number of bounces made by an idealized, perfectly 
elastic and perfectly round, billiard ball, dropped from above on to a similar ball. 

1.5 
i 
I 
~ 
I 
' 
I 
' 
I 
~ 
I 
i 
I 
Figure 1.4 
Ball bouncing on a unit sphere 
, 
^ 
x o=0.00001;yo =1.25;m=1;g=1 
1.0 
Y 
0.5 
0~ 
I 
I 
I 
I 
I 
I 
I 
I 
I 
a 
ii 
i 
i 
0.2 
0.4 
0.6 
0.8 
1.0 
1.2 
1.4 
X 
It is 9 in the case shown in Figure 4 above and in Figure 5 with an offset of 0.00001. 
In principle, if the dropping ball were exactly centered over the lower ball (and perfectly elastic) 
the motion would continue, periodically, forever. On the other hand, a computer simulation of 
the experiment would be likely to predict different results. The finite precision of the computer 
calculation (typically between 8 and 14 decimal digits) would result in the upper ball's landing 
some distance away from the top of the lower ball, inducing a horizontal acceleration and velocity. 
Both the acceleration and the velocity would then act to increase the offset on the second bounce, 
roughly by a factor of ten, and then the offset would continue to increase exponentially until the 
upper ball had missed the lower one completely. There is no doubt that a careful attempt to 
carry out such an experiment in the laboratory would lead to the same kind of unstable behavior 

Y 
I 
I 
t 
I 
0.5 
1.0 
Ball bouncing on a unit sphere 
L 
x o = 0.00001; Yo = 1.25; rn = 1; g = 1 
1 
Figure 1.5 
1.5 
01 
I 
L 
I 
1 
-5 
-4 
-3 
-2 
-1 
0 / 
Log (x) 
seen in the computer experiment, but probably with many fewer bounces due to the relatively 
larger experimental asymmetries from nonuniformity and nonelasticity in real balls. 
If we were to use quantum mechanics in setting up the initial conditions for the experiment 
much the same result would be obtained, even for idealized perfect spherical elastic balls. Con- 
sider Heisenberg's uncertainty principle. This principle places theoretical limits on the accuracy 
with which coordinates and momenta can simultaneously be known. The product of the two 
"uncertainties" is at least of order Planck's constant h. Thus the limited accuracy with which 
one ball can be centered over another (with the product dp × dq of order h) allows only (about} 17 
bounces. Either real irregularities or the real space-momentum correlations described by quantum 
mechanics would lead to the unstable behavior seen in the idealized dropping-ball experiment. 

10 
Solutions of differential equations for dynamical systems require appropriate initial and 
boundary conditions. The problems with which Newton began had the simplest possible bound- 
ary, a perfect vacuum. In the strongly nonequilibrium problems to which molecular dynamics 
is now being applied such a simple vacuum boundary is not usually appropriate. Instead, the 
container must be taken into account, or explicitly avoided through the use of periodic boundary 
conditions. Periodic boundaries are illustrated in Figure 6 for a three-dimensional two-body 
system by showing 125 -- 5 a separate images of both particles. Periodic boundaries have the 
unusual property that they are inconsistent with the conservation of angular momentum. For 
example, Figure 7 shows a particle passing out of the "top" of a periodic two-dimensional L × L 
system, with y -- +L/2. 
The sign of y, and hence of my& changes discontinuously when the 
particle reenters at the bottom of the system, with y = -L/2. 
Thus one of the two contributions 
to the angular momentum, Po = m(x~ - ySc) changes sign. The lack of conservation of angular 
momentum is not usually a problem, but this example points out the need for considering the 
effect of boundary conditions on observed properties. 

11 
/ ~" 
Figure 1.7 
PO <0 
Origin 
L 
+ 
L 
L 
PO >0 
To illustrate simultaneously the ideas of Lyapunov instability and periodic boundaries, 
we show in the Figure 8 three views of 125 superposed periodic 2-body systems undergoing 
shear deformation. The larger of the two particles forms a lattice undergoing steady shear. 125 
independent images of the smaller particle are shown in each of the three snapshots. Initially the 
space coordinates of the small particles differed in the fourth digit only. These small differences 
led, after just a few collisions of the small particle with the large (but periodic) scatterer particle, 
to the nearly random small-particle distribution seen at the lower left of Figure 8. 
Periodic boundaries have confused many students. Newton's small-particle acceleration 
equations, rnF = F, can contain either an explicit vector sum of forces from all periodic images of 
the large particle or, if the coordinates of the smaller particle are replaced within the central box 
whenever a periodic boundary is crossed, and if the forces are short-ranged, only a few terms. 
The simplest procedure, exact for forces which vanish beyond half the periodic box width, is to 
select only the nearest particle for calculating the force. This is the "nearest-image" convention. 
For the short-ranged forces characteristic of neutral matter it is usual to include all particles lying 
within about three particle diameters in the force sum. 
If gravitational forces were to be included, an attempt to work out the energy of an infinite 
array of identical unit cells would yield not only a divergent sum, but also a divergent sum for 
the interaction of each cell with the rest. So we have another good reason for ignoring gravity. 

]2 
Figure 1.8 
Gravity is inconsistent with the so-called "thermodynamic limit", in which the intensive proper- 
ties converge to values given by the thermodynamic ~infinite-system" equation of state. 
To summarize, Newtonian mechanics consists of three elements: 
(i) a recipe (forces F and masses rn) giving the accelerations in terms of the coordinates r: 
~(r) -- F(r)/m. Newton's recipe is a set of second-order ordinary differential equations. 
(ii) boundary conditions for the differential equations, including both initial conditions and 
time-dependent boundary accelerations exerted on the system by the outside world. 
(iii) an algorithm for solving the differential equations. Adams-Moulton, Runge-Kutta, or Gear 
methods can solve first-order equations such as Hamilton's, or the nonequilibrium equations 
of motion described in Chapter IV. Runge-Kutta algorithms are easily programmed and 
suitable for use on small personal computers. 

13 
I.B Lagrange~s Mechanics and Hamilton's Least Action Principle 
Joseph Louis Lagrange(1736-1813) studied in his native Italy and spent his research career 
in Berlin and Paris. He contributed to the description of physical systems by developing the 
theory of differential equations. 
For conservative (constant-energy) systems, Lagrange's formulation of mechanics is spe- 
cially useful in dealing with systems incorporating "holonomic" constraints. Taken literally~ halo- 
nomic means "whole laws". In mechanics holonomic constraints involve geometric, as opposed to 
kinetic, constraints. Lagrange's equations of motion differ from Newton's in making the motion 
of constrained systems easier to treat. This is done by formulating equations of motion in terms 
of "generalized ~ coordinates q(r, ~), which can be complicated functions of the space coordinates 
r. In either the Newtonian case or the Lagrangian case, the coordinates and their time derivatives 
appear in equations for the accelerations. 
How does Lagrangian mechanics work? The fundamental equation, the equation of motion, 
can be obtained from Hamilton's Principle, often, but not always, also called the Principle of 
Least Action. To start out, first write down the "Lagrangian', L(m, q, ~). The Lagrangian is the 
difference between the Kinetic Energy of the system, K(rn, q, ~), written in terms of the masses 
m, generalized coordinates q, and velocities ~, and the Potential Energy, ~ : L -- K - ~. The 
kinetic energy is my2/2 summed over all mass elements. Hamilton's Least Action Principle then 
states that the motion q(t) between any two fixed space-time points qo(to) and ql(Q) is that 
which minimizes the integral of L relative to slightly different, varied motions: 
/ Ldt minimum, or / ~Ldt=O. 
Figure 9 illustrates this principle for a unit mass travelling from x -- 0 to x -- 2 in a gravitational 
field, with field energy ¢ -- 2y. We work out the action integral for three different parabolic 
trajectories, with the parameter a equal to 1,2, and 3, as shown in Figure 9: 
x=t; 
y=at(1-0.bt). 
For this set of trajectories the kinetic energy integrated over time is 1 T (1/3)a 2 and the potential 
energy integrated over time is (4/3)a. The difference between these integrals is the action integral, 
1 - (4/3)a÷ (1/3) a 2, which has a minimum value, -1/3, for a = 2. This path , which corresponds 
to the parabola satisfying the classical equations of motion, has a smaller action integral than 
do any neighboring paths. For instance, a -- 1 and a = 3 correspond to greater, and therefore 
unacceptable, action integrals of 0. But there is a fly in the ointment. A path which passes 
through the barrier shown in Figure 9 can have an arbitrarily large negative action (by making 
the potential barrier, shown as a rectangular box, arbitrarily large and positive). This example 
emphasizes the local nature of the variation in Hamilton's principle. The principle must be applied 
locally to avoid drawing qualitatively incorrect conclusions. 

14 
Y 
2 
0 
---T 
T 
y= [t- ½t 2] 
Figure 1.9 
(0, 1, 2, 3) 
~Ldt = 0 
x=t 
m=l 
g=2 
• 
SLdt = -1/3 
• 
• 
fLdt = 0 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
" 
• 
• 
• 
I 
fLdt 
__l 
1 
0 
1 
2 
Because, in the general case, L depends explicitly upon both q and its time derivative ~, 
the variation has the form 
f 6Ldt = 0 = f [ (OL/Oa) Zq + (OL/O(t) (dgq/dt) ] dr. 
The derivative (d~q/dt) can be integrated (with respect to time) by parts, because the integral, 
~q, is known to vanish at the two endpoints. Then, because the form of the variation that results, 
f [(OL/Oq) - (d/dt)(OL/O(t)] 6q dt contains the arbitrary variation 6q, the coefficient of 5q must 
vanish at all times in the interval. This requirement establishes Lagrange's equations of motion, 
(d/dt) (OL/O(t) = OL/Oq. 
Because the Lagrangian equations of motion still don't convey much information, and are 
identical to Newton's equation mF = F provided that OL/O~ corresponds to m~ and OL/Oq 
corresponds to F, we consider an example with constraints. Shown in Figure 10 is a two- 
dimensional system involving two holonomic constraints, a triatomic molecule with Particles 
labelled 0, 1, and 2, with the two distances rl0 and r20 fixed at 1. We choose masses for the 
particles which make the problem as simple as possible: the central particle, Particle 0, has no 
mass; Particles 1 and 2 have equal masses, rn. Because the center-of-mass motion of (rl + r2)/2 
has no bearing on the motion relative to the center of mass, we consider the case in which the 
center of mass is fixed at the origin. 

\ 
15 
Figure 
1.10 
/ 
In the Newtonian mechanics of Section A of Chapter I or the Gaussian mechanics to be 
described in Section D of Chapter I we would need to introduce "constraint" forces to keep 
these two distances fixed. In Lagrangian mechanics we can avoid defining the constraint forces by 
incorporating the constraints in our description of the problem, using as "generalized coordinates" 
a, half the angle between the 01 and 02 directions~ and the angle fl between r12 and some fixed 
axis in space, chosen horizontal in Figure 10. The variable r is equal to sins. 
Because there is no potential energy, the Lagrangian and the kinetic energy K are identical 
for this problem: 
L = K- a = K = m[(~sin.) 2 + (acos.y]. 
From this Lagrangian, to which we return in the following section on Hamiltonian mechanics, a(t) 
and j3(t) can be calculated from Lagrange's equations of motion without any special difficulty. 

16 
I.C Hamilton's Mechanics - Introduction to Nos6's Mechanics 
William Rowan Hamilton (1805-1865) was educated in his native Ireland and joined the 
faculty at Dublin in 1827. His analyses of optical phenomena led to mathematical tools funda- 
mental to the treatment of both classical and quantum mechanical systems. 
In Hamilton's mechanics, just as in Lagrange's, (generalized) coordinates q can be used 
to simplify the treatment of (holonomically) constrained systems. In Hamilton's mechanics the 
conjugate momenta p (not velocities) and coordinates q appear in the Hamiltonian H(q, p) on 
an equal and symmetric footing. Hamilton's equations of motion also differ from Newton's and 
Lagrange's in another way. They are first-order in time rather than second, giving ~ and ~ in 
terms of the coordinates and momenta: 
= + on/Op; 
~ = - OH/Oq. 
Hamilton's mechanics is basic to treating quantum systems. The SchrSdinger equation of 
quantum mechanics, which describes not only stationary states but also the time-development 
of a quantum system's behavior, is based upon the existence of a Hamiltonian description of 
that system. Like Newton's and Lagrange's equations, Hamilton's equations of motion are time- 
reversible. But the coordinates and momenta behave differently when time is reversed. In the 
reversed motion each coordinate q is unchanged in value and with successive values traced out 
in reversed order along the reversed trajectory. On the other hand each momentum p has to be 
replaced by -p. 
In any of the three kinds of mechanics we have mentioned so far the underlying potential 
function, ¢, L, or H, does not depend upon the direction of time. The Hamiltonian H is usually 
the total energy, K + ~, expressed as a function of the q and p. Generally, it can be constructed 
from the Lagrangian L(q, q) through the equations 
p = aL(q, ~)/oq~,; 
H(q, p) = (dl" p) - L. 
Thus, in the case of the two-dimensional triatomic molecule considered above, the Hamil- 
tonian has the form 
H(,~, ~,p~,, p~) = [(p~,/cos~) ~ + (p~/sin~)~]/4m. 

17 
Gibbs' statistical mechanics gives the probability of finding a classical tiamiltonian sys- 
tem at temperature T in the phase-space region q,p within dq and dp in terms of the system's 
Hamiltonian function, H(q,p). The corresponding "canonical-ensemble" probability density is 
proportional to the "Boltzmann factor" e -H(q'p)/(kT). 
This result allows us to calculate the 
probability distribution for the angle a defined above in the triatomic molecule problem. If we 
perform a canonical-ensemble average, integrating first over ;3 (which provides only a factor of 
2~r), and then over the momenta, pa and p~, we find that the probability density P(a) is propor- 
tional to sin(a) cos(a) = (1/2) sin(2a). This probability density has its maximum value for the 
right-angled configuration. On the other hand, if we avoided Lagrangian mechanics and instead 
forced the two distances rot and r02 to lie close to 1 by linking the pairs of particles 01 and 02 
with very stiff Hooke's-Law springs, there would be no coupling between the coordinates and 
momenta. The Hooke's-Law Hamiltonian in this case, for springs of unit rest length, would be 
H = [(p2 +p2)/(2m) ] + (~/2) [(to1 - 1) 2 + (r02 - 1)2], 
and a canonical average would give a constant probability density for the angle a. In Figure 11 
the rigid-constraint and the Hooke's-Law probability densities P(2a) are compared. 
A 
O4 
v 
o.. 
0.5 
1 
I 
I 
1 
I 
I 
I 
I 
I 
I 
I 
/ 
/ 
/ 
/ 
00/ 
l 
/ 
, 
/ 
-... 
/--Rigid 
(~..~ 
_ 
_ 
.~.'~'" 
" ~ p ~  
• f 
"~..\ 
_ 
/ 
Hooke.-~ 
\ 
\. 
~. 
\ 
Figure 1.11 \. - 
\ 
I 
I 
I 
I 
I 
I 
I 
I 
I 
"~ 
7[ 
2~ 
This example, which is relatively "well-known" (to the experts), illustrates that classical 
mechanics contains many surprises. Simply stating that we would like to consider the dynamics 
of a molecule with "fixed" bondlengths or fixed angles does not constitute a well-posed problem. 
We must specify the details of how such constraints are to be imposed. 

18 
Hamilton's equations of motion differ from Newton's in that the coordinates and momenta 
are independent variables. No longer is p necessarily equal to rn~. A very recent modification and 
extension of Hamiltonian mechanics, due to Shfiichi Nos~, can be thought of as scaling either time 
or mass, in order to satisfy desirable constraints. In Nose's mechanics, to be discussed in Section 
E of Chapter I, the time derivative of q is generally quite different from Hamilton's p/rn. Let 
us briefly illustrate that difference by considering a harmonic oscillator with mass m and force 
constant J¢. We first consider a Hamiltonian oscillator, for which p is identical to toO, and next a 
Nos~ one-dimensional oscillator, for which it is not. 
In the Hamilton case the Hamiltonian is 
H = [(p2/m) +/¢q2]/2, 
from which the familiar equations of motion follow: 
cl= p/m; 
~= -icq; 
or, to emphasize the symmetry between the coordinates and momenta~ 
~l = -w2 q; 
P --- -uJ2 P. 
These Hamilton's equations, like Newton's, are "reversible". Figures 12 and 13 illustrate 
a typical oscillator trajectory (with the force constant ~ and mass m set equal to unity) q = 
sin(t); p = 4 = cos(t), as well as the reversed trajectories. In the q,p, t representation of Figure 
12 reversal would correspond to an inversion through the q axis, from the point (q,p,t) to the 
corresponding point (q,-p,-t). In the q,p representation of Figure 13 the reversed motion 
shown at the bottom of the Figure corresponds to a jump, at fixed q, from p to -p. 
P 
/ ~ 
q=p;Io=-q;¼ =1 
q 
Figure 1.12 

19 
~=p 
~=-q 
qo = 0 
Po=l 
1 
Figure 1.13 
I 
-1 
0 
q 
-1 
An oscillator can also be described by a more complicated constant-temperature version 
of Hamiltonian mechanics which was recently invented, or discovered, by ShQichi Nos4. This 
important development merits its own section, Section E of Chapter I, but here we consider 
briefly the harmonic-oscillator example to indicate the relation between Hamilton's and Nose's 
mechanics. Very little work has so far been carried out with Nose's mechanics, either in the 
classical or the quantum case. But this is so only because it is new. For a classical one-dimensional 
oscillator Nose's temperature-dependent Hamiltonian is 
HNosd = [pUlC2ms2)] + (~q2/2) + kTlns + [p2/C2Q)]. 
There is a new variable s, which is dimensionless, with a new "conjugate momentum" pa, which 
has units of action, in addition to the usual oscillator coordinate q and momentum p. T is the 
temperature and k is Boltzmann's constant. 
Q is a parameter with units of mass × area. A 
polar-coordinate form of the Hamiltonian is more useful in the quantum-mechanical case: 

20 
HNos~ ----- [(P~ + P2)/(2m)] + [aQ82/(2m)] + (kT/2)ln(mr2/Q). 
The dimensionless variable 8, which becomes r in the polar representation, can be thought 
of as scaling the mass or scaling the time. Nosd prefers the latter interpretation. If we interpret 
the variable r in the polar-coordinate Hamiltonian as a length, and 0 as an angle, the conjugate 
momenta become the conventional radial and angular momenta. Q, the parameter determining 
the time-dependence of the temperature (kinetic energy) fluctuations, still has units of mass times 
area in this form. 
It is straightforward to differentiate Nose's oscillator Hamiltonian in order to write down 
the equations of motion. There are four of these, one each for q,p, s, and Ps: 
= p/(ms2); 
~=-~q; 
~ = p~/Q; 
~ = [p2/Cms3)] - (kT/~). 
There is no convenient way to rewrite these first-order equations as second-order equations, so the 
Verlet algorithm cannot be used to solve them. Two typical (Runge-Kutta) solutions, projected 
onto qp space and followed for many oscillator vibration periods, are shown as the two upper 
trajectories in Figure 14. These projected q,p trajectories are not affected by time scaling. 
Figure 1.14 

21 
But the q, ~ trajectories are changed, qualitatively, by scaling. Suppose that we pursue 
Nos6's time scaling idea, introducing a new time t,~w related to the old time by the equation 
dt,~ew = dtotd/S. 
The effect of this time scaling on the four equations of motion just given is to multiply each time 
derivative by s. Thus, with the dots now indicating derivatives with respect to the new time, 
t,~w, we have, 
(t = p/(ms); 
~= -aqs; 
~ = sps/Q; 
~8 = [p~/(ms2)] - kT. 
In Figure 14 the q, ~j trajectories from these equations are shown just below the corre- 
sponding q, p trajectories after time scaling has been introduced. In Figure 14 the initial values 
of q, p, s, and Ps are respectively 1, 1, 1, and 0. The lefthand trajectory corresponds to Q = 1 while 
the righthand trajectory corresponds to Q = 0.1. Nos6's generalization of Hamiltonian mechanics 
changes the connection between the momentum p and the time derivative of the coordinate q. 
Because the time scale variable 8 is relatively small near the turning points the magnitudes of 
the scaled velocities ~ are much greater than those of the p/m. Because the trajectories are not 
periodic a two-dimensional region in the space is gradually filled in. 
~l=p 
I$ = -q - ~'p 
~'= 10 (02- 
1) 
Po = Pmax = 2.25 
-q 
Figure 1.15 

22 
Figure 15 illustrates a periodic solution of the scaled Nos4 oscillator equations. Any of 
the three combinations of p, m, and s -- [p/(ms2)], [p/(ms)], or [p/m] -- can correspond to 
"momentum". (Remember that s is dimensionless.) The consequences of the three choices are 
quite different because s varies over such a wide range of values. (The microcanonical-ensemble 
fluctuations of 1/s diverge!) The variables q,p,s, and Ps are interrelated in the same way by 
either set of equations. But the trajectories are traced out at different rates in the two cases. The 
equations shown in the Figure are written in terms of the new variables, corresponding to the 
choice q,~w = pot~/(ms) = p,~ew/m, with m, t¢, and kT all set equal to unity, and with Q set 
equal to 0.10. The variable f in the Figure corresponds to the momentum pe/Q. 
Despite the close connection between Hamilton's and Nose's mechanics, as illustrated here 
for the oscillator, it is possible to develop another even more useful version of Nos6's mechanics 
which is entirely distinct from Hamilton's. We will return to that subject in Section E of this 
Chapter. The present version of Hamilton-Nos4 mechanics, like the usual Hamilton's, Lagrange's, 
or Newton's mechanics, uses a potential function (here H, rather than L, or q~) to generate future 
behavior. The main difference between the various approaches is computational. The numerical 
techniques appropriate for second-order differential equations cannot always be applied to first- 
order equations. 
I.D Gauss' Mechanics and the Principle of Least Constraint 
There is a mechanics, founded on Gauss' Principle of Least Constraint, which is still 
more general than Newton's or Lagrange's or Hamilton's mechanics. These other three forms 
of mechanics can all be derived from Gauss' Principle. This Principle is particularly useful 
in describing the motion of constrained systems. A "rigid" diatomic molecule is probably the 
simplest example. In such a molecule the two atoms are constrained to remain a fixed distance 
apart. 
Gauss' Principle can readily be applied to the triatomic molecule just treated with La- 
grange's mechanics in Section B. This typical holonomic application presents no difficulties. 
Gauss' mechanics can just as easily be applied to nonholonomic constraints, with the veloci- 
ties entering in an essential way. If the constraints are either (i) holonomic or (ii) nonholonomic, 
but only linear in the velocities, then Gaussian mechanics predicts nothing new. That is, the mo- 
tion predicted by Gauss would be the same as that predicted by Newton or Lagrange or Hamilton. 
On the other hand, for general nonlinear nonholonomic constraints, Gauss makes new predictions 
while Newton, Lagrange, and Hamilton are silent. 

23 
There are very few solved problems in the mechanics literature involving nonlinear non- 
holonomic constraints. We illustrate one of these museum pieces here, probably the best known, 
with a quadratic nonholonomic constraint: 
~2 : ~ + ~2. 
This textbook example arises in the approximate treatment of the motion of "Appell's cart". The 
cart is shown in Figure 16. The knife-edged front wheel can rotate only in the plane parallel to 
the cart body. The motion is driven by a weight mounted on a pulley at the rear of the cart. 
Figure 1.16 

F c 
The twin skids at the rear of the cart can slide, without friction, both back and forth 
and from side to side. The trajectories of Appell's cart are interesting. In addition to the 
oscillatory back-and-forth motion, the cart can spin about the bottom of the knife-edged wheel. 
This combination of back-and-forth with spinning motions can trace out patterns resembling the 
arrangements of petals in flowers. 
Once we consider thermodynamic and hydrodynamic many-body systems, many nonlinear 
nonholonomic constraints become possible. For example, energy, stress, and heat flux are all 
nonlinear functions of the particle velocities. In constraining such variables Gauss' principle is 
useful in a unique way, inaccessible to Newton's, Lagrange's, and Hamilton's mechanics. 
Figure 1.17 
/ 
( 
24 
= -mr" ~2 
What is Gauss' Principle? Gauss stated that the constraint forces Fc required to impose 
any constraint should be as small as possible in a least-squares sense: 
m~ = F + Fc; 
[F~/(2m)] 
minimized. 
This is Gauss' Principle of Least Constraint. Let us illustrate the Principle by applying it to the 
simple two-dimensional rigid diatomic molecule shown in Figure 17". In this case Gauss' Prin- 
ciple produces a radial acceleration counteracting the centrifugal forces, without any tangential 

25 
component. We can find the acceleration by considering two restrictions on the variation of the 
constraint force -Pc. First, we formulate the constraint: 
r2/2 ---- constant 
in terms of the acceleration ~. To do this we calculate the second time derivative of the constraint. 
The result is 
~ + i? + ~ + u~ = ~ + i? + • (F: /m) + u (F~ /m) = o. 
If we then consider a small variation of the constraint force, the variation must obey the 
restriction: 
x~(F:/m) + u~CF]/m) = O. 
On the other hand, Gauss' Principle also restricts variations in the constraint force. The vari- 
ational condition, [(F¢)2/(2rn)] minimum, implies that the dot product of the constraint force 
and its variation must vanish: 
(F: ~F: + f~ ~F~)/m = 0. 
Combining the two restrictions on 6Fc, using a Lagrange multiplier A chosen such that 
F: + ~x -- 0 implies that F~ + ),y -- 0 as well, so that the second time derivative of the original 
constraint equation becomes 
~ + #~ + ~(F: l~) + yCF~/~) = ~ + #~ - (~/~)(.~ ~ + u ~) = o. 
Thus we find the value of the Lagrange multiplier, ~ = m/2/r2, and the corresponding constraint 
force, directly from the constraint equation. 
This illustration of Gauss' Principle is a typical textbook one in which the energy 2re(r0)2/2 
is conserved because the forces of constraint do no work. But Gauss' Principle can also be ap- 
plied to more-complicated work-performing constraints involving collective thermodyn~nic and 
hydrodynamic variables. No fundamental rules or variational principles independent of Gauss' 
are available for such constraints. For instance it is not true that the work performed by the con- 
straints should be a minimum. Constraint forces leading toward the ultimate potential minimum, 
the formation of a perfect crystal, would perform less work against the potential energy • than 
would any others. 

26 
Gauss' Principle is particularly useful in simulating steady nonequilibrium flows. Such 
flows require special methods to compensate for the natural dissipation of work into heat. The heat 
should be extracted to avoid the complicated description and analysis of a continually changing 
thermodynamic state. 
For simplicity it is convenient to use Gauss' Principle to remove the heat in such a way 
that the nonequilibrium state is a "steady" one. By steady we mean that the driving force or the 
resulting flux, as well as two thermodynamic state variables (energy and density, or temperature 
and stress, for instance) are held constant. 
To illustrate the application of Gauss' Principle to the problem of maintaining temperature 
constant, consider a D-dimensional N-body system. In such systems the kinetic energy typically 
fluctuates on the same time scale as do the particle velocities. These fluctuations correspond to 
fluctuations in temperature. The temperature of a many-body system can be most simply defined 
in terms of the kinetic energy: 
DNkT/2 = ~(m÷2/2). 
Thus, fixing the kinetic energy corresponds to fixing a dynamical estimate of the thermodynamic 
temperature. The derivative of the isothermal constraint just given can be written 
~. 
~ = ~. 
[(F+ Fo + ~Fo)/m] = ~[m÷. 
(~Fo/~)] = 0. 
Combining this with the variational form of Gauss' Principle, ~:~(Fc. $Fe)lrn = O, using a 
Lagrange multiplier ~" gives 
Fc = - #m~; 
with 
,a = F(r) + FoCr,~) = F- ~m÷, 
= ~(F. 
÷)/ZCm÷2). 
These second-order differential equations are the ~Gaussian isothermal" equations of mo- 
tion. Like Newton's, these equations are time reversible with the friction coefficient ~ changing 
sign in the reversed trajectory. The friction coefficient enforces the constraint of constant tem- 
perature. Like the temperature-dependent HamUtonian of Nos~, this is an example of something 
new in mechanics. Many more examples are given in Chapter IV, Nonequillbrium Equations 
of Motion. In the next section we join Nos~ in straying even farther from Newton. 

27 
I.E Nose's Mechanics - Temperature and Pressure Constraints 
The classical approaches of Newton, Lagrange, and Hamilton all generate trajectories r(t), 
q(t), or q(t), p(t) along which energy is conserved. With periodic boundaries, linear momentum 
is also conserved. The ensemble approach of Gibbs' equilibrium statistical mechanics is more 
flexible. Energy and volume can be fixed, as in the microcanonieal ensemble. Alternatively, 
temperature and pressure can be used as independent variables, allowing the energy and volume 
to fluctuate. But in these cases temperature and pressure characterize an ensemble of systems and 
not the individual members. It may be necessary to average over many states in an equilibrium 
statistical ensemble in order to estimate the corresponding temperature or pressure. 
On the other hand, any treatment of nonequUibrium problems would be useless if it lacked 
a method for following stress, heat flux, and temperature as instantaneous functions of time in 
individual systems. In real laboratory experiments such variables are monitored by measurement, 
or inference, even under nonequilibrium conditions. In computer experiments one would also ex- 
pect to measure time-dependent currents and to find that these currents vary in a reproducible 
way. This expectation has been abundantly justified in a variety of simulations. Thus, molecular 
dynamics simulations have instilled confidence that pressure and temperature can be usefully de- 
fined as instantaneous mechanical phase functions in individual systems, rather than as nebulous 
ensemble properties which can only be determined by exhaustive sampling. 
Here we hold to the usual, and useful, viewpoint that the instantaneous temperature is 
defined by the mean-squared velocity, relative to the local stream velocity 
(DNkT/2) -- E(m/2)(v - Vo) 2. 
With this point of view Gauss' dynamics generates a canonical ensemble of configurations, 
in which the probability of any configuration with potential energy ~ is proportional to e-c/(k~'), 
where T is the temperature just defined. 
This canonical-ensemble form for the phase-space distribution can be derived from the 
extension of Liouville's Theorem appropriate to non-Newtonian systems described by dynamical 
equations such as Gauss'. In the system's phase space q,p the product of the probability density 
f(q, p) and the differential hyp~rvolume dq dp is conserved by any set of equations of motion which 
neither creates nor destroys systems. The probability density itself flows through the phase space 
as a compressible fluid because Gaussian mechanics allows the phase-space dilatational strain-rate, 
[(O~/Oq) + (Of~/Op)], to be nonzero. Thus the probability density f(q, p) obeys a generalized 
"continuity" ("mass" conservation) equation, 
÷ 
+ 
[aC.r 
)/ap] -- o. 

28 
For clarity, it is worthwhile to illustrate this conservation relation with a specific example, 
the damped one-dimensional harmonic oscillator. For convenience we choose the mass and the 
force constant both equal to unity. The equation of motion is 
~+e~+x=O, 
where E = 2 corresponds to the critically-damped case. For the critically-damped oscillator 
X .= XO e-l: 
is a solution of the equation of motion. This critically-damped case is compared with undamped, 
underdamped, and overdamped trajectories in Figure 18 with initial condition x : ~ = 1. In 
the critically-damped case the phase space density follows the differential equation 
] = -f (O#/Op) = 2f. 
1.5r 
I 
I 
I 
i 
[ 
1 
1.0 
0.5 
Damped 
oscillators 
+ e~ +x 
= 0; 
x o = 1;~ o = 1 
0 
-0.5 
-1.0 
-1.5 
m 
i 
i 
.5 
-1.0 
-0.5 
e=4 
e=( 
Y 
I 
[ 
0 
0.5 
X 
J 
1 
i 
1.0 
1.5 

29 
Thus the critically-damped probability density increases exponentially in time, as the phase 
points near the origin become increasingly likely. The volume element dxdp likewise decreases 
exponentially with time, because the product, f x dxdp, is constant. Such a phase-space vol- 
ume corresponds to an ensemble of critically-damped oscillators, originally distributed uniformly 
throughout the volume dxdp. As time goes on, the ensemble will occupy a phase-space volume 
which decreases exponentially in time. Because probability is conserved, the product, f(x, p)dxdp, 
is a constant of the equations of motion, namely the number of systems in the ensemble. 
The compressible flow of phase-space probability leads to interesting consequences for 
many-body systems. Consider again our many-body Gaussian isothermal example, in which the 
temperature is kept fixed by a friction coefficient ~ which varies with time. The probability density 
f(q,p) in the many-body phase space varies with time because the ~ are explicit functions of the 
p. The derivative of the probability density function, following the motion, is 
/ = (Of~cOt) + ~ [q (Of/Oq) T ~ (Of/Op)] = 
-f ~ [(O~/Oq) Jr (O~/Op)] = +3Nff : -[~/(kT)] f. 
Thus the logarithm of the probability density rises and falls, as a function of time, in phase with 
the fluctuations in the potential energy. It is evident that a steady solution of this differential 
equation is the "isokinetic" canonical distribution 
f o: 6(K - Ko) e -¢/(kT), 
where kT is 2Ko/DN for an N-body D-dimensional system and where the delta function guar- 
antees that K is equal to Ko. It makes no sense to apply Gauss' constant-temperature dynamics 
to a single one-dimensional harmonic oscillator. Such an oscillator would have no turning point 
and the coordinate would diverge linearly with time. The simplest oscillator problem which can 
be treated with Gaussian constant-temperature dynamics is a two-dimensional harmonic oscilla- 
tor. That case leads to coordinate-space trajectories resembling the floral patterns generated by 
Appel's cart. 
Shfiichi Nos~ discovered a different dynamics which generates the complete canonical dis- 
tribution, not just the configurational part. In Nos~ dynamics fluctuations in the kinetic energy 
K are included. His equation of motion is exactly the same as the isothermal example just given 
using Gauss' mechanics: 
m~= F-~m~, 

30 
but the friction coefficient f is not solely a function of the current phase variables. Instead it 
depends on the time integral of the difference, K - Ko, between the kinetic energy K and its 
desired value Ko: 
The lower limit of the integral must be a fixed, but arbitrary, time--here chosen equal to 0. 
Other versions of Nose's equations can be based on higher velocity moments. For instance 
the equations of motion for N one-dimensional particles 
¢ =(kr/e) [(p2/mkr)2-3(p2/mkr)]. 
have also the same canonical-ensemble steady distribution in the phase space. 
Nose's mechanics is reversible in time, as are also the isoenergetic mechanics of Newton, 
Lagrange, and Hamilton, and the isokinetic mechanics of Gauss. Just as in the Ganssian case, in 
the reversed Nos$ motion not only is the momentum p replaced by -p; but also Nose's friction 
coefficient f is replaced by -~. See Figure 19 for a periodic solution of Nose's oscillator equations 
of motion. Reversing the time would correspond, in Figure 19, to inverting the trajectory through 
the q axis so that the point (q,p, z) becomes (q,-p,-z) in the reversed trajectory. 
~l=p 
I~ = -q - ~'P 
~" = 100 (p2 _ 1) 
Po -- 1.0085 
P 
q 
Figure 1.19 

31 
Pedagogical derivations for Nose's dynamics can be developed in two different ways, (i) by 
starting with a temperature-dependent Hamiltonian in which the variable 8 scales the time or the 
mass, or (ii) by requiring that the equation of motion generate the canonical distribution including 
a Gaussian distribution in the friction coefficient ~. Nose's papers follow the former approach. 
Because the latter approactr is not only constructive and simple, but also can be generalized 
to other forms of the equations of motion, we illustrate it here. We begin by considering the 
probability density f(q,p, ~) in an extended phase space which includes ~ as well as all pairs of 
phase variables q and p. This density f satisfies the conservation of probability 
(ol/0t) + 
[o(oi)/Oq] + 
+ 
= 0. 
This general continuity equation is called the "Liouville equation" in the special case that 
it can be simplified, using the Hamiltonian equations of motion, to the form dr~dr -- O. 
If the distribution has the form 
Q~2/(2kT) ~t 
..... 
f 0( e- 
Jequ~zorzurn~ 
and the equations of motion have a friction-coefficient form: 
=p/m; 
~=F-fp; 
¢=~(q,p,Q), 
we can calculate each of the four contributions to the phase-space flow equations. These contri- 
butions are: 
(Of~Or) = 0; 
O(~f)/Oq = Z 
F (p/m)(f/kT); 
O(f~)/Op = ~ 
[-pF + ~ (p2 _ (p2))] [f/(mkT)]; 
O( f ¢) / O~ : ~ ( O f / O~) = -Q~ (f / kT)¢, 
where we have assumed that ~ depends only on the phase variables, and not on ~'. The conservation 
of probability requires that the four contributions listed above sum to zero. This requirement in 
turn implies that ¢ must satisfy the equation 
= ~[p2 _ (p2)]/(mQ) .= 2(K - Ko)/Q. 
If we were to use a cubic frictional force, -q'pS/(rnkT) rather than -~p, we could alter- 
natively fix the value of the fourth moment of the velocity distribution relative to the second 
moment, and again recover the canonical distribution. These same ideas can be generalized to 

32 
include "constant-pressure" or "constant-stress-tensor" ensembles. The result is a strain rate (di- 
latational for constant-pressure, and including shear for constant-stress) which obeys a first-order 
relaxation equation similar to that just written for the kinetic energy. 
Before leaving Nose's mechanics, a technical point should be made. It has only been 
shown that the equations are consistent with the canonical distribution. That is, a canonical 
distribution in the phase space is preserved by Nose's equations of motion. Whether or not the 
equations will generate such a distribution from almost all initial conditions is a subtle question. 
For a collisionless gas, they will not. Consider for instance a Nos~ ideal gas with kinetic energy 
g = ~ p2/(2m). Nose's equation of motion gives 
k = ~(~p/m) = ~(-~p2/m) = -2~K; 
¢ = - [(d/dt) 2 ln(K/Ko)]/2 = 2(K - Ko)/Q, 
where Ko is the specified time-averaged value of K. 
If we introduce a new variable X, the logarithm of the kinetic energy ratio, K/Ko, then 
X oscillates in a nonlinear Toda potential: 
-- -( 4Ko/ Q) [ e x - e x°] = -d( ¢ /m)~/ /~¢~i,¢l dX. 
8 
6 
!4 
2 
Figure 
1.20 
I 
I 
I 
I 
I 
I 
°° 
z 
t 
I 
I 
I 
I 
-8 
-6 
-4 
-2 
0 
2 
4 
X =In(K/K o) 

33 
This Toda potential is sketched in Figure 20. Both the friction coeffÉcient and the kinetic 
energy itself oscillate (with harmonic oscillations if K is close to Ko). These periodic oscillations 
show that a collisionless gas will never actually reach a canonical distribution under the influence 
of Nose's mechanics. On the other hand, numerical work indicates that the Lyapunov instabilities 
associated with collisions are ordinarily sufficient to induce canonical behavior. 
In general, if the parameter Q, which is proportional to the square of the heat-bath response 
time, is made small enough, Nos~ dynamics becomes indistinguishable from Gaussian isokinetic 
dynamics and never reaches a true canonical distribution in momentum space. If Q is large the 
dynamics approaches Newtonian dynamics with (p2/m) = DkT. The approach to the Gaussian 
and Newtonian limits for the one-dimensional oscillator is indicated in Figure 21. The truly 
Gaussian case is singular, with turning points at =kc~. In Figure 21, with Q -- 0.01, there are 
turning points just beyond q -- ±4, but the limiting behavior for Q N 0 is easy to visualize. The 
inner Nos~ trajectory shows the same solution in Nosg's original variables, without time scaling. 
The one-dimensional Newtonian ellipse with (p2/m) = kT is also shown. 
From Figure 21, it can be seen that a single harmonic Nos~ oscillator doesn't achieve the 
canonical distribution, for any value of the parameter Q. And the situation is no better if cubic 
frictional forces, enforcing the fourth moment, are added. Thus the indications are that systems 
cannot be too simple if they are to show the phase-space mixing properties necessary to establish 
the canonical distribution. 
P 
3 
_ 
1- 
0- 
-1 - 
-3 
-5 
I 
I 
I 
I 
I 
I 
I 
I 
1 
~1 = P; I~ = -q - ~'p; ~" = 100 (p2 _ 1), Po = 1.0085 
I 
-4 
L 
I 
I 
I 
L 
I 
-3 
-2 
-1 
0 
1 
2 
q 
I 
I 
I 
3 
4 
5 
Figure 1.21 

34 
At present it isn't possible to prove that a particular system has the necessary mixing 
property. Computation can provide clues, but ultimately the problem of proof is a theoretical 
one. The finite precision of any computer simulation guarantees that the long-time solution of 
any interesting trajectory will be dominated by numerical errors. On the other hand, it appears, 
from numerical work, that a two-dimensional two-body problem can already exhibit canonical 
behavior. The precise degree of complexity required for Nos6 dynamics to produce canonical 
behavior is not yet firmly established, even numerically. Evidently the value of Q is important 
to the convergence properties. If Q is very small, then the frictional reaction to disparities in the 
kinetic energy is rapid, and Ganssian isothermal dynamics results. In the opposite limit, when 
Q is very large, so that the response of the frictional forces is sluggish, the dynamics reduces to 
Newton's original form. All that can be said at present is this: "For some sufficiently chaotic 
problems, in two or more space dimensions, it seems that Nos6 mechanics does generate the 
canonical distribution. 

35 
The Nosg oscillator is an extremely interesting problem in its own right. 
For some, 
relatively-high-energy and small-Q initial conditions, the distribution function in the (q,p,~) 
phase space has a sponge-like structure, with many holes of various shapes and sizes. Figure 22 
shows a q = 0 cross section (sometimes called a "Poincar~ surface of section" or a "puncture plot") 
through a long trajectory. The occupied part of the phase space resembles a three-dimensional 
sponge. The holes in the sponge correspond to structures known as Kolmogorov-Arnold-Moser 
tori, stable regions surrounding reentrant periodic orbits. Resonances describing the coupling 
of pairs of these tori axe responsible for the irregular sponge-like structure seen here. Such a 
structure is characteristic of chaotic dynamical systems. 
I.F Numerical Mechanics - Fermi, Alder, Vineyard, and Rahman 
With the invention of fast computers the scope of numerical integration expanded by orders 
of magnitude. By now, with the CRAY-2 and CRAY-XMP computers, computer capabilities have 
reached more than ten orders of magnitude beyond pencil-and-paper capabilities. Fast computers 
proliferated in the National Laboratories in the United States, first at Los Alamos, for the second 
World War bomb calculations, and later at Livermore, Brookhaven, and Argonne. For the first 
time, it became possible to solve Newton's equations for relatively complicated systems, with 
many degrees of freedom and for long periods of time. This capability made it possible to study 
numerically the irreversibility paradox that fascinated Boltzmann. This paradox can appear even 
in small systems such as the one-dimensional Nos6 oscillator. In outline form, the reversibility 
paradox is as follows: 
(i) From a macroscopic standpoint many-body systems exhibit irreversible behavior, as de- 
scribed by the second law of thermodynamics. 
(ii) From a microscopic standpoint many-body systems are described by reversible equations 
of motion. 
At Los Alamos Enrico Fermi wanted to resolve the paradox by applying the new compu- 
tational tool, the computer "MANIAC", to the many-body problem. He wanted to study the 
approach to equilibrium of an anharmonic chain, in which the linear-force modes were coupled 
together by quadratic or cubic force functions of the interparticle separations. 
Fermi expected to find that the entropy increase for isolated systems, predicted by the 
second law of thermodynamics, would follow as a consequence of Newtonian mechanics. The 
resulting Fermi-Pasta-Ulam calculations, mostly carried out with 16 and 32-particle anharmonic 
chains, showed what first appeared to be a slow approach to equilibrium, with the energy in the 
initially excited mode returning to its initial value less closely with each near repetition. These 
near repetitions occurred after dozens of vibrations of the chain, so that only a few repetitions 
could be accurately calculated. The early Los Alamos work did show that the number of particles 

36 
I 
l 
I 
Figure 1.23 
| 
I 
! 
| 
1 
1 
i 
J 
i 
,\ 
% 
\ 
J 
N 
Z 
/ 
" 
,d 
,¢ 
/" 
¢= 
,,P 
............ 
~=,A 
+ 
2000 
4000 
6000 
8000 
10,000 
12,000~ 14,000 
f 
Time steps × 6T 
I 
t 
! 
l 
, 
, 
60,000 
120',000 
1801000' 
"2401000 " 
o, 
I! 
i i 
! i'f 
i~!, ,i fl 
was not important--17 behaved in essentially the same way as did 16 and 32--and also that the 
motion could be accurately reversed after several hundred time steps so as to retrace the reversed 
history back to the original configuration. 

37 
It is interesting that in these pioneering molecular dynamics simulations Fermi, Pasta, 
and Ulam did not even describe the algorithm used to integrate the equations of motion. It was 
assumed that the reader could work out such a scheme. The centered-difference "Verlet" scheme 
used by Feynman or the even better fourth-order Runge-Kutta method would be good choices. 
Later calculations, carried out by Tuck and Menzel at Los Alamos, showed that the Fermi- 
Pasta-Ulam chains do not, in general, equilibrate and that statistical mechanics is therefore not 
generally valid for these oversimplified systems. See Figure 23. It shows a typical variation of 
mode energies with time. The curve labelled "1" is the amplitude of the energy of the initially- 
excited lowest-frequency "mode". The initial condition nearly recurs after about 13,000 time 
steps, as shown in the top of the Figure. The recurrence is even closer after the 200,000 timestep 
superperiod discovered by Tuck and Menzel. The somewhat pathological character of these sys- 
tems which don't equilibrate continues to stimulate the interest of mathematicians even today. 
The Nos~ oscillator is probably the simplest such system. 
There is a reference to some unpublished two-dimensional many-body calculations by Fermi 
at Los Alamos, but the first (and very extensive) published simulations in two and three dimen- 
sions were carried out by Berni Alder and Tom Wainwright at the Lawrence Livermore "National" 
Laboratory (then the "Radiation" Laboratory). Alder and Wainwright wanted to see whether 
or not the reversible equations of motion of Newton could account for the irreversible behavior 
described by the Boltzmann Equation and the second law of thermodynamics. 
¢.D 
-500 
-550 
-600 
-650 
-7 O0 - 
-750 - 
_800 ~ _ 
0 
] 
I 
I 
I 
I 
I 
I 
] 
0 0 
• 
oo 
oo 
• 
• 
o- 
O0 
0 
• 
Figure 
1.24 _ 
I 
I 
I 
I 
I 
I 
I 
I 
l 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
Time 

38 
Figure 1.25 
G 
.__,yE 
__~,~. 
~
-
-
-
-
#
 
• 
A 
B 
~ 
_o. 
_
_
.
o
.
_
_
 
_
_
o
_
_
 
J 
,. 
40 eV in (100) plane 
15 ° off [100] direction 
Pot. #2 
Atoms in plane 
o Time 0 
• Time 99 
Atoms in planes 
above and below 
• Time 0 
Alder and Wainwright studied the motion of 100 hard spheres, all with the same initial 
speed, but with different velocities. Their calculation of the low-density approximation to the 
entropy S -w- -Nk ~ lnf(p, t) ), where f is the one-particle probability density in momentum space, 
is shown in Figure 24. They found that the spheres established an equilibrium momentum 
distribution relatively rapidly, in about three collisions per particle. The resulting equilibrium 
thermodynamic properties also agreed with the Monte-Carlo statistical predictions generated by 
Alder and Wainwright's collaborators, Wood and Parker, at Los Alamos. 
Alder and Wainwright also predicted the rate at which Boltzmann's low-density form 
for the entropy -Nk Ilnf(p,t)~ = S(t), would rise to the equilibrium value according to the 

39 
Boltzmann equation. Their prediction was fully consistent with the results of the molecular 
dynamics simulation. At that time it was not generally recognized that the hard-sphere behavior 
incorporated the typical Lyapunov instability, while Fermi's anharmonic chain did not. So the 
early computer results were a little puzzling, with statistical mechanics and the second law of 
thermodynamics working at Livermore, but failing at Los Alamos. 
At the Brookhaven Laboratory George Vineyard and his coworkers were interested in an 
application of molecular dynamics to metals damaged by radiation. This class of problems has 
remained important in the design of reactors. The Brookhaven calculations were fully three- 
dimensional, used continuous forces, and incorporated viscoelastic boundary particles. The earli- 
est literature reference to this work seems to be the cover of the August 1959 issue of the Journal 
of Applied Physics. The cover, reproduced as Figure 25, shows the trajectories of several metal 
atoms in a crystal. Inside the issue there is no accompanying article, only a caption identifying 
the workers and a very brief description of the problems being studied. 
At the Argonne Laboratory, Anees Rahman was carrying out an ambitious simulation of 
liquid argon, using periodic boundary conditions and 864 particles, for a long time the world's 
record. Rahman's calculation was the first attempt to study liquid physics with continuous 
potentials, focusing on structural information that could be directly compared with experiment. 
This emphasis followed Vineyard's in seeking to simulate particular materials. Fermi's and Alder's 
calculations, on the other hand, sought to elucidate mechanisms underlying general properties of 
simple materials. 
Rahman's innowtive work was honored at an Argonne Laboratory Festschrift in 1984. 
Alder celebrated his 60th birthday in 1985. So molecular dynamics is well on its way to becoming 
a "mature" field. The fact that Rahman used 864 particles, rather than a smaller number, 
is to some extent responsible for the relatively large number of particles that many subsequent 
investigators used. As we will soon point out, with several examples, both the equilibrium and the 
transport properties of simple systems depend only weakly on the number of particles. Because 
the equilibration time increases roughly as N 2/3, the diffusion time across an N-particle system, 
it is often more efficient to carry out a longer calculation on a smaller system than a shorter large- 
size calculation. A considerable amount of work has been carried out on the number-dependence 
of computer-experiment results. We discuss number-dependence in Section E of Chapter IL 
These four sets of workers, at Argonne, Brookhaven, Livermore, and Los Alamos, set the 
stage for what is now called "molecular dynamics" (despite the fact that until recently most of 
the calculations involved monatomic interactions), an enterprise now carried on in a hundred 
institutions in a dozen countries, and having tremendous impact on the development of the 
theoretical description of classical many-body systems. 

40 
By 1985 Farid Abraham and his coworkers at IBM San Jose had carried out long simula- 
tions using 161,604 particles. Figure 26 shows the cell structure formed by a monatomic layer 
of rare-gas atoms adsorbed on graphite. This was done by plotting the positions of those atoms 
which were out of register with the underlying graphite lattice. The calculations are unusual in 
that the number of atoms treated in the computer experiment is approximately the same as that 
observed in corresponding laboratory experiments. 

Bibliography for Chapter I. 
41 
The Lyapunov instability present in the equations of motion of most interesting systems 
is discussed in two recent books on nonlinear dynamics, Hao Bai-Lin's Chaos (World Scientific, 
Singapore, 1984) and Heinz G. Schuster's Deterministic Chaos (Physik-Verlag, Weinheim, 1984). 
Current papers in molecular dynamics can be found by scanning the Journal of Chemical 
Physics, the Journal of Statistical Physics, Physica, the Physical Review, and Physical Review 
Letters. The early molecular dynamics calculations are summarized in a popular article, "Molec- 
ular Motions", by B. J. Alder and T. E. Wainwright, in the Scientific American for October, 1959. 
This article attracted me to Livermore in 1962. 
Equilibrium applications of the "Nos~ thermostat" are described in two clear papers by 
Shfiichi Nosg: "A Unified Formulation of the Constant-Temperature Molecular Dynamics Meth- 
ods", Journal of Chemical Physics 81, 511 (1984) and "A Molecular Dynamics Method for Sim- 
ulations in the Canonical Ensemble", Molecular Physics 52,255 (1984). See also W. G. Hoover, 
"Canonical Dynamics: Equilibrium Phase-Space Distributions", Physical Review A 81, 1695 
(1985) and H. A. Posch, W. G. Hoover, and F. J. Vesely, "Dynamics of the Nos~-Hoover Oscilla- 
tor: Chaos, Order, and Stability", Physical Review A 38, 4253 (1986). 
A comprehensive and pedagogical treatment of holonomic constraints can be found in a 
paper "Constraints", by N. G. van Kampen and J. J. Lodder, American Journal of Physics 52, 
419 (1984). Nine different forms for nonholonomic constraint forces are compared in treating a 
heat-flow simulation in the review by D. J. Evans and W. G. Hoover, "Flows Far From Equilibrium 
via Molecular Dynamics", Annual Review of Fluid Mechanics 18,243 (1986). See also Section D 
of Chapter IV of these notes. 
The "Feynman Lectures", R. P. Feynman, R. B. Leighton, and M. Sands, Feynmaa LecJures 
on Physics (Addison-Wesley, Reading, Massachusetts, 1964) contain not only the finite-difference 
calculations mentioned in the chapter, but also an interesting chapter on Hamilton's Principle of 
Least Action. 
For applications of Gauss' Principle see "Nonequilibrium Molecular Dynamics via Gauss' 
Principle of Least Constraint", by D. J. Evans, W. G. Hoover, B. H. Failor, B. Moran, and A. J. 
C. Ladd, Physical Review A 28, 1016 (1983). See also Section G of Chapter IV of these notes. 
The Fermi-Pasta-Ulam calculation is extensively reviewed and extended in an article by 
J. L. Tuck and M. T. Menzel, "The Superperiod of the Nonlinear Weighted String (Fermi-Pasta- 
Ulam) Problem", Advances in Mathematics 9, 399 (1972). 
The 161,604-particle simulation is described in F. F. Abraham, W. E. Rudge, D. J. Auer- 
bach, and S. W. Koch, "Molecular-Dynamics Simulations of the Incommensurate Phase of Kryp- 
ton on Graphite Using More Than 100,000 Atoms", Physical Review Letters 52,445 (1984). 

