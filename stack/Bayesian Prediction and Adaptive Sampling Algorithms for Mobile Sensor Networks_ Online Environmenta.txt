123
SPRINGER BRIEFS IN ELECTRICAL AND COMPUTER
ENGINEERING ïš½ CONTROL, AUTOMATION AND ROBOTICS
YunfeiÂ Xu
JongeunÂ Choi
SaratÂ Dass
TapabrataÂ Maiti
Bayesian Prediction 
and Adaptive Sampling 
Algorithms for Mobile 
Sensor Networks
Online Environmental 
Field Reconstruction in 
Space and Time

SpringerBriefs in Electrical and Computer
Engineering
Control, Automation and Robotics
Series editors
Tamer BaÅŸar
Antonio Bicchi
Miroslav Krstic

More information about this series at http://www.springer.com/series/10198

Yunfei Xu
â€¢ Jongeun Choi
â€¢ Sarat Dass
Tapabrata Maiti
Bayesian Prediction
and Adaptive Sampling
Algorithms for Mobile
Sensor Networks
Online Environmental Field Reconstruction
in Space and Time
123

Yunfei Xu
Michigan State University
East Lansing, MI
USA
Jongeun Choi
Michigan State University
East Lansing, MI
USA
Sarat Dass
Department of Statistics
Michigan State University
East Lansing, MI
USA
Tapabrata Maiti
Department of Statistics
Michigan State University
East Lansing, MI
USA
ISSN 2191-8112
ISSN 2191-8120
(electronic)
SpringerBriefs in Electrical and Computer Engineering
ISSN 2192-6786
ISSN 2192-6794
(electronic)
SpringerBriefs in Control, Automation and Robotics
ISBN 978-3-319-21920-2
ISBN 978-3-319-21921-9
(eBook)
DOI 10.1007/978-3-319-21921-9
Library of Congress Control Number: 2015950872
Springer Cham Heidelberg New York Dordrecht London
Â© The Author(s) 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciï¬cally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microï¬lms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciï¬c statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media
(www.springer.com)

To our loving parents and beautiful families

Preface
We have witnessed a surge of applications using static or mobile sensor networks
interacting with uncertain environments. To treat a variety of useful tasks such as
environmental monitoring, adaptive sampling, surveillance, and exploration, this
book introduces a class of problems and efï¬cient spatio-temporal models when
scalar ï¬elds need to be predicted from noisy observations collected by mobile
sensor networks. The book discusses how to make inference from the observations
based on the proposed models and also explores adaptive sampling algorithms for
robotic sensors to maximize the prediction quality subject to constraints on mem-
ory, communication, and mobility.
The objective of the book is to provide step-by-step progress in chapters for
readers to gain better understanding of the interplay between all the essential
constituents such as resource-limited mobile sensor networks, spatio-temporal
models, data-driven prediction, prediction uncertainty, and adaptive sampling for
making better predictions. The book builds on previous collective works by the
authors and is not meant to provide a comprehensive review of the topics of
interest. Speciï¬cally, materials from the previous publications by the authors [1â€“5]
make up a large portion of the book.
In this book, a spatio-temporal scalar ï¬eld is used to represent the collection of
scalar quantities of interest, such as chemical concentration or biomass of algal
blooms (e.g., see Fig. 1.3), transported via physical processes. To deal with com-
plexity and practicality, phenomenological and statistical modeling techniques are
used to make inference from noisy observations collected, taking into account a
large scope of uncertainties. To this end, nonparametric models such as Gaussian
processes and Gaussian Markov random ï¬elds (GMRFs), along with their predic-
tion and adaptive sampling algorithms, will be explored and tailored to our needs.
The importance of selecting a Gaussian process prior via hyperparameters for given
experimental observations is illustrated (Chap. 3). Adaptive sampling to improve
the quality of hyperparameters is proposed (Chap. 3). Memory efï¬cient prediction
based on truncated observations in space and time as well as the collective mobility
based on distributed navigation are discussed (Chap. 4). While the book starts with
vii

a rather simple empirical Bayes approach (Chap. 3), as we move through further
chapters, we discuss recent efforts with a fully Bayesian perspective to maximize
the ï¬‚exibility of the models under various uncertainties while minimizing the
computational complexity (Chaps. 5 and 7). A fully Bayesian framework is adopted
here as it offers several advantages when inferring parameters and processes from
highly complex models (Chaps. 5 and 7). The Bayesian approach requires prior
distributions to be elicited for model parameters that are of interest. Once the priors
are elicited, the Bayesian framework is ï¬‚exible and effective in incorporating all
uncertainties as well as information (limited or otherwise from data) into a single
entity, namely, the posterior. The fully Bayesian approach thus allows additional
sources and extent of uncertainties to be integrated into the inferential framework,
with the posterior distribution effectively capturing all aspects of uncertainties
involved. Subsequently, the practitioner needs only to focus on different compo-
nents of the posterior to obtain inference separately for the parameters of interest,
nuisance parameters, and hyperparameters. The fully Bayesian approach also
allows data to select the most appropriate values for nuisance parameters and
hyperparameters automatically and achieve optimal inference and prediction for the
scalar ï¬eld. In this book, a fully Bayesian approach for spatio-temporal Gaussian
process regression will be formulated for resource-constrained robotic sensors to
fuse multifactorial effects of observations, measurement noise, and prior distribu-
tions for obtaining the predictive distribution of a scalar environmental ï¬eld of
interest. Traditional Markov Chain Monte Carlo (MCMC) methods cannot be
implemented on resource-constrained mobile sensor networks due to high com-
putational complexity. To deal with complexity, the Bayesian spatio-temporal
models will be carefully tailored (Chap. 5). For example, we will approximate a
Gaussian process with a GMRF for computational efï¬ciency (Chaps. 6 and 7).
A new spatial model is proposed via a GMRF (Chap. 6). In addition, ways to
improve computational efï¬ciency will be proposed in form of empirical Bayes and
approximate Bayes instead of MCMC-based computation. For some special cases,
the developed centralized algorithms will be further reï¬ned in a distributed manner
such that mobile robots can implement distributed algorithms only using local
information available from neighboring robots over a proximity communication
graph (Chaps. 4â€“6).
We note that although regression problems for sensor networks under location
uncertainty have practical importance, they are not considered in this book. The
interested reader is referred to [6, 7] (centralized scheme) and [8] (distributed
scheme) for further information on this topic.
Organization
This book is organized as follows: Chapter 1 gives some background information
and a summary for each chapter. In Chap. 2, we introduce the basic mathematical
notation that will be used throughout the book. We then describe the general
viii
Preface

Gaussian process and its usage in nonparametric regression problems. The notations
for mobile sensor networks are also introduced in Chap. 2. In Chap. 3, we deal with
the case where hyperparameters in the covariance function is deterministic but
unknown. We design an optimal sampling strategy to improve the maximum
likelihood estimation of these hyperparameters. In Chap. 4, we assume the
hyperparameters in the covariance function are given; they can be obtained using
the approach proposed in Chap. 3. We then analyze the error bounds of prediction
error using Gaussian process regression with truncated observations. Inspired by the
error analysis, we propose both centralized and distributed navigation strategies for
mobile sensor networks to move in order to reduce prediction error variances at
points of interest. In Chap. 5, we consider a fully Bayesian approach for Gaussian
process regression in which the hyperparameters are treated as random variables.
Using discrete prior probabilities and compactly supported kernels, we provide a
way to design sequential Bayesian prediction algorithms that can be computed in
constant time as the number of observations increases. To cope with the compu-
tational complexity brought by using standard Gaussian processes with covariance
functions, in Chap. 6, we exploit the sparsity of the precision matrix by using
Gaussian Markov random ï¬elds (GMRFs). We ï¬rst introduce a new class of
Gaussian processes with built-in GMRF and show its capability of representing a
wide range of nonstationary physical processes. We then derive the formulas for
Chapter 2: Preliminaries: Gaussian process (GP)
and Gaussian Markov random ï¬eld (GMRF)
Chapter 1: Background: Mobile sen-
sor network (MSN) and robotic sensors
Chapter 3: GP, prediction, adaptive
sampling, & empirical Bayes appr.
Chapter 5: GP, prediction, adaptive sam-
pling, MCMC appr., & fully Bayesian appr.
Chapter 6: new spatial model, GMRF, predic-
tion, distributed strategy, & empirical Bayes appr.
Chapter 7: approximated GP, GMRF, predic-
tion, adaptive sampling, & fully Bayesian appr.
Chapter 4: GP, prediction, & distributed strategy
Fig. 1 Organization of chapters along with keywords
Preface
ix

predictive statistics and design sequential prediction algorithms with ï¬xed com-
plexity. In Chap. 7, we consider a discretized spatial ï¬eld that is modeled by a
GMRF with unknown hyperparameters. From a Bayesian perspective, we design a
sequential prediction algorithm to exactly compute the predictive inference of the
random ï¬eld. An adaptive sampling strategy is also designed for mobile sensing
agents to ï¬nd the most informative locations in taking future measurements in order
to minimize the prediction error and the uncertainty in the estimated hyperpara-
meters simultaneously.
Keywords for chapters are summarized in Fig. 1. While each chapter is
self-contained and so can be read independently, arrows in Fig. 1 recommend
possible reading sequences for readers.
Acknowledgments
We would like to thank Songhwai Oh at Seoul National University for his
suggestions and contribution to Chap. 4. We also thank the National Science
Foundation RET teacher, Alexander Robinson, undergraduate student David York,
and Ph.D. student Huan N. Do at Michigan State University for collecting the
experimental data using a robotic boat in Chap. 3. We thank Jeffrey W. Laut,
Maurizio Porï¬ri (NYU Polytechnic School of Engineering), Xiaobo Tan (Michigan
State University), and Derek A. Paley (University of Maryland) for providing
pictures of their robots used in the introduction of Chap. 1.
The authors Yunfei Xu and Jongeun Choi have been supported in part by the
National Science Foundation through CAREER Award CMMI-0846547. This
support is gratefully acknowledged. Any opinions, ï¬ndings, and conclusions, or
recommendations expressed in this book are those of the authors and do not
necessarily reï¬‚ect the views of the National Science Foundation.
Santa Clara, California
Yunfei Xu
East Lansing, Michigan
Jongeun Choi
Seri Iskandar, Malaysia
Sarat Dass
East Lansing, Michigan
Tapabrata Maiti
May 2015
x
Preface

Contents
1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Background. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Contents in Chapters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1
Mathematical Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Physical Process Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.1
Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.2
Spatiotemporal Gaussian Process . . . . . . . . . . . . . . . . . .
13
2.2.3
Gaussian Markov Random Field . . . . . . . . . . . . . . . . . .
14
2.3
Mobile Sensor Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.4
Gaussian Processes for Regression . . . . . . . . . . . . . . . . . . . . . .
17
3
Learning Covariance Functions . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3.1
Selection of Gaussian Process Prior . . . . . . . . . . . . . . . . . . . . .
19
3.2
Learning the Hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.3
Optimal Sampling Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
3.4
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4
Memory Efficient Prediction With Truncated Observations . . . . . .
27
4.1
GPR with Truncated Observations . . . . . . . . . . . . . . . . . . . . . .
28
4.1.1
Error Bounds Using Truncated Observations . . . . . . . . . .
28
4.1.2
Selecting Temporal Truncation Size . . . . . . . . . . . . . . . .
34
4.2
Optimal Sampling Strategies . . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.2.1
Centralized Navigation Strategy. . . . . . . . . . . . . . . . . . .
37
4.2.2
Distributed Navigation Strategy . . . . . . . . . . . . . . . . . . .
39
4.3
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4.3.1
Centralized Sampling Scheme . . . . . . . . . . . . . . . . . . . .
46
4.3.2
Distributed Sampling Scheme . . . . . . . . . . . . . . . . . . . .
48
xi

5
Fully Bayesian Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
5.1
Fully Bayesian Prediction Approach . . . . . . . . . . . . . . . . . . . . .
54
5.1.1
Prior Selection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
5.1.2
MCMC-Based Approach. . . . . . . . . . . . . . . . . . . . . . . .
56
5.1.3
Importance Sampling Approach . . . . . . . . . . . . . . . . . . .
61
5.1.4
Discrete Prior Distribution. . . . . . . . . . . . . . . . . . . . . . .
64
5.2
Sequential Bayesian Prediction . . . . . . . . . . . . . . . . . . . . . . . .
64
5.2.1
Scalable Bayesian Prediction Algorithm . . . . . . . . . . . . .
65
5.2.2
Distributed Implementation for a Special Case. . . . . . . . .
66
5.2.3
Adaptive Sampling. . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
5.3
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
5.3.1
MCMC-Based Approach on a 1-D Scenario . . . . . . . . . .
70
5.3.2
Centralized Scheme on 1-D Scenario . . . . . . . . . . . . . . .
71
5.3.3
Distributed Scheme on 2-D Scenario . . . . . . . . . . . . . . .
74
6
New Efficient Spatial Model with Built-In Gaussian Markov
Random Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
6.1
Spatial Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
6.1.1
Spatial Model Based on GMRF. . . . . . . . . . . . . . . . . . .
78
6.1.2
Gaussian Process Regression . . . . . . . . . . . . . . . . . . . . .
79
6.1.3
Sequential Prediction Algorithm. . . . . . . . . . . . . . . . . . .
82
6.2
Distributed Spatial Prediction. . . . . . . . . . . . . . . . . . . . . . . . . .
83
6.2.1
Distributed Computation . . . . . . . . . . . . . . . . . . . . . . . .
84
6.2.2
Distributed Prediction Algorithm . . . . . . . . . . . . . . . . . .
84
6.3
Simulation and Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.1
Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.2
Centralized Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.3
Distributed Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
6.3.4
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7
Fully Bayesian Spatial Prediction Using Gaussian Markov
Random Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
7.1
Spatial Field Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
7.2
Bayesian Predictive Inference . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.3
Sequential Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . .
96
7.3.1
Update Full Conditional Distribution . . . . . . . . . . . . . . .
97
7.3.2
Update Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
7.3.3
Update Predictive Distribution . . . . . . . . . . . . . . . . . . . .
99
7.4
Adaptive Sampling. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
7.5
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
Appendix A: Mathematical Background. . . . . . . . . . . . . . . . . . . . . . .
107
References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
111
xii
Contents

Chapter 1
Introduction
1.1 Background
Sensor networks are ubiquitous due to the recent technological breakthroughs in
micro-electro-mechanical systems (MEMS), wireless communications, and embed-
ded systems [9, 10]. A sensor network consists of a collection of low-cost, low-power,
and multifunctional sensing devices that communicate over ï¬nite distances. A ï¬‚exi-
ble and application-speciï¬c operating system, TinyOS, was developed at UC Berke-
ley for sensor networks with severe memory and power constraints [11]. TinyOS
runs on small and cheap wireless sensor nodes (e.g., MICA2DOT from Crossbow
Technology, Inc., CA, USA) as shown in Fig.1.1a. Such sensor nodes have been
equipped with various environmental and ambient sensors such as temperature sen-
sors, lighting sensors, chemical sensors, accelerometers, and RFID readers along
with the communication capability with neighbors via low-power wireless commu-
nication to form a wireless ad hoc sensor network with up to 100,000 nodes [10].
Endowing the nodes in a sensor network with mobility signiï¬cantly increases the
sensor networkâ€™s sampling capabilities [12, 13]. The sensor networks which consist
of mobile sensing agents are more ï¬‚exible than the ones with only static nodes. A
conceptual picture of a distributed mobile sensor network with a (R-disk) proximity
communication graph model is shown in Fig.1.1b, which assumes that a robotic
sensor can communicate with its neighboring robots within distance R. Devised in
the Laboratory of Intelligent Systems at the Swiss Federal Institute of Technology,
the Swarming Micro Air Vehicle Network (SmavNet) depicted in Fig.1.1c allows
a single operator to control an entire swarm of cheap unmanned aerial vehicles
(UAVs) for search and rescue operation [14]. 3D Robotics, Inc., Berkeley, USA
produces â€œpersonal dronesâ€ such as DIY drone kits as well as ready-to-ï¬‚y quadrotors,
multirotors, and ï¬xed wing UAVs based on open source UAV autopilot platforms. A
quadrotor with a camera from 3D Robotics is shown in Fig.1.2.
Biologists and other scientists are interested in leveraging recent technological
advances [10, 15, 16] by deploying mobile sensor networks for environmental and
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_1
1

2
1
Introduction
(a)
(b)
(c)
Fig. 1.1 a Wireless microsensor mote (MICA2DOT) from Crossbow Technology, Inc., CA, USA,
(www.xbow.com). b Distributed mobile sensor network with a (R-disk) proximity communication
graph for environmental monitoring (credit: Justin Mrkva). c Swarming Micro Air Vehicle Network
(SmavNet) developed in the Laboratory of Intelligent Systems at the Swiss Federal Institute of
Technology for search and rescue operation (Photo courtesy of Laboratory of Intelligent Systems
at EPFL, http://lis.epï¬‚.ch)
wildlife monitoring. For example, one of the pressing societal concerns about water
quality is the proliferation of harmful algal blooms in ponds, lakes, rivers, and coastal
ocean worldwide. A satellite image of a 2011 signiï¬cant harmful algal bloom in
western Lake Erie is shown in Fig.1.3. The excessive growth of cyanobacteria leads
to a decaying biomass and oxygen depletion, which are detrimental to ï¬sh and other
aquatic life as well as to land animals and humans consequently (due to the produced

1.1 Background
3
Fig. 1.2 Personal drone (IRIS+) manufactured by 3D Robotics Inc., Berkeley, USA (credit: 3D
Robotics, http://3drobotics.com)
Fig. 1.3 Satellite image of 2011 signiï¬cant harmful algal bloom in western Lake Erie in
Michigan, which impacted over half of the lake shore (credit: MERIS/ESA, processed by
NOAA/NOS/NCCOS, http://www.noaanews.noaa.gov)
toxins that deteriorate water quality) [17â€“19]. Deploying mobile sensor networks
can be a viable way to reconstruct and monitor such harmful algal blooms [20, 21].
Indeed, we have seen the increasing exploration of robotic technologies in aquatic
sensing [20, 22â€“25]. A robotic boat was used in concert with stationary buoys to form
an aquatic microbial system [20]; spatiotemporal aquatic ï¬eld reconstruction was
implemented using inexpensive, low-power, robotic ï¬sh in [21] (see also Fig.1.5a
for gliding robotic ï¬sh [26]); and low-cost, self-sustained mobile surface vehicles
have been designed for environmental monitoring as part of the citizen science project
Brooklyn Atlantis [23] (see Fig.1.4). A robotic boat equipped with a depth sensor, as

4
1
Introduction
(a)
(b)
Fig. 1.4 Robots developed by NYU Polytechnic School of Engineering for image and water quality
data collection as part of the citizen science project Brooklyn Atlantis (http://www.brooklynatlantis.
poly.edu) [23] (credit: Jeffrey W Laut)
shown in Fig.1.5b, can sample the depth of a lake for its estimation [27]. Autonomous
underwater vehicles (AUVs) are being developed as an important tool in oceanog-
raphy, marine biology, and other maritime applications [28â€“30]. Autonomous sea
gliders are another noteworthy example. These battery-powered, buoyancy-driven
vehicles can travel thousands of miles horizontally, for many months, without chang-
ing or recharging batteries [31â€“34]. With the networks of gliders as shown in Fig.1.6,
adaptive sampling has been demonstrated in Monterey Bay, California [35â€“37].

1.1 Background
5
(a)
(b)
Fig. 1.5 a Gliding robotic ï¬sh â€œGraceâ€ sampling harmful algae in the Wintergreen Lake, Michigan
[26] (credit: Xiaobo Tan). b Robotic boat sampling depth near Hawk Island, Lansing, Michigan
(credit: Jongeun Choi)
The robotic sensor technologies have then brought an increasing exploitation of
navigation of mobile sensor networks and robotic sensors interacting with uncertain
environments [2, 35â€“42]. A necessity in such scenarios is to design algorithms to
process collected observations from environments (e.g., distributed estimators) for
robots such that either the local information about the environment can be used for
local control actions or the global information can be estimated asymptotically.
The approach of designing such algorithms takes two different paths depend-
ing on whether it uses an environmental model in space and time or not. Without

6
1
Introduction
Fig. 1.6 Gliders used for adaptive sampling [35â€“37] (credit: Derek A. Paley)
environmentalmodels,extremumseekingcontrolhasbeenproventobeveryeffective
for ï¬nding a source of a signal (chemical, electromagnetic, etc.) [38, 39]. Distributed
algorithms for stochastic source seeking with mobile robot networks have been devel-
oped for both cases with and without the mutual information model between their
expected measurements and the expected source location [43]. A unifying frame-
work of distributed stochastic gradient algorithms that can deal with coverage control,
spatial partitioning, and dynamic vehicle routing problems in the absence of a priori
knowledge of the event location distribution has been presented in [40].
A drawback of the spatial model free approach is that it limits its task to ï¬nding
the maximum (or minimum) point of the environmental ï¬eld. To tackle a variety
of useful tasks such as the exploration, estimation, prediction, and maximum seek-
ing of a scalar ï¬eld, it is essential for robots to have a spatial (and temporal) ï¬eld
model [2â€“4, 36, 41, 42, 44â€“50]. Although control algorithms for mobile robots have
been developed based on computationally demanding, physics-based ï¬eld models
[51], for resource-constrained mobile robots, recently, phenomenological and statis-
tical modeling techniques such as kriging, Gaussian process regression, and kernel
regression have gained much attention. Among phenomenological spatial models,
adaptive control of multiple robotic sensors based on a parametric approach needs
a persistent excitation (PE) condition for convergence of parameters [42, 50], while
control strategies based on Bayesian spatial models do not require such conditions
(e.g., by utilizing priori distributions as in Kalman ï¬ltering [41] or Gaussian process
regression [2]). Hence, control engineers have become more aware of the useful-
ness of nonparametric Bayesian approaches such as Gaussian processes (deï¬ned by

1.1 Background
7
mean and covariance functions) [52, 53] to statistically model physical phenomena
for the navigation of mobile sensor networks, e.g., [2â€“4, 36, 44â€“47]. Other more
data-driven approaches have also developed (without statistical structure used in
Gaussian processes) such as using kernel regression [48] and in reproducing kernel
Hilbert spaces [49]. However, without a statistical structure in a random ï¬eld, such
an approach (as in [48, 49]) usually requires a great number of observations than the
one with a statistical structure for a decent prediction quality.
In a mobile sensor network, the resource-limited sensing agents are required to
collaborate in order to achieve a speciï¬c objective. The cooperative control becomes
essential. The most popular applications are in networks of autonomous ground
vehicles [54, 55], underwater and surface vehicles [23, 36, 56â€“58], or aerial vehicles
[59â€“61]. Emerging technologies have been reported on the coordination of mobile
sensing agents [41, 62â€“70].
The mobility of mobile agents can be designed in order to perform the optimal
sampling of the ï¬eld of interest. Optimal sampling design is the process of choosing
where to take samples in order to maximize the information gained. Recently, in
[36], Leonard et al. developed mobile sensor networks that optimize ocean sampling
performance deï¬ned in terms of uncertainty in a model estimate of a sampled ï¬eld.
A typical sensor placement technique [71] that puts sensors at the locations where
the entropy is high tends to place sensors along the borders of the area of interest
[44]. In [44], Krause et al. showed that seeking sensor placements that are most
informative about unsensed locations is NP-hard, and they presented a polynomial
time approximation algorithm by exploiting the submodularity of mutual information
[72]. In a similar approach, in [73], Singh et al. presented an efï¬cient planning of
informative paths for multiple robots that maximize the mutual information.
To ï¬nd these locations that predict the phenomenon best, one needs a model
of the spatiotemporal phenomenon. To this end, we use Gaussian processes (and
Gaussian random ï¬elds) to model ï¬elds undergoing transport phenomena. Nonpara-
metric Gaussian process regression (or Kriging in geostatistics) has been widely used
as a nonlinear regression technique to estimate and predict geostatistical data [52, 53,
74, 75]. A Gaussian process is a natural generalization of the Gaussian probability
distribution. It generalizes a Gaussian distribution with a ï¬nite number of random
variables to a Gaussian process with an inï¬nite number of random variables in the
surveillance region [53]. Gaussian process modeling enables us to efï¬ciently pre-
dict physical values, such as temperature, salinity, pH, or biomass of harmful algal
blooms, at any point with a predicted uncertainty level. For instance, near-optimal
static sensor placements with a mutual information criterion in Gaussian processes
were proposed in [44, 76]. A distributed Kriged Kalman ï¬lter for spatial estimation
based on mobile sensor networks was developed in [45]. Multiagent systems that are
versatile for various tasks by exploiting predictive posterior statistics of Gaussian
processes were developed in [77, 78].
Gaussian process regression, based on the standard mean and covariance func-
tions, requires an inversion of a covariance matrix whose size grows as the number
of observations increases. The signiï¬cant computational complexity in Gaussian

8
1
Introduction
process regression due to the growing number of observations (and hence the size of
covariance matrix) has been tackled in different ways [2, 79â€“83].
Unknown hyperparameters in the covariance function can be estimated by a max-
imum likelihood (ML) estimator or a maximum a posteriori (MAP) estimator and
then be used in the prediction as the true hyperparameters [1]. However, the point
estimate (ML or MAP estimate) itself needs to be identiï¬ed using a sufï¬cient amount
of measurements and it fails to incorporate the uncertainty in the estimated hyper-
parameters into the prediction in a Bayesian perspective. The advantage of a fully
Bayesian approach is that the uncertainty in the model parameters is incorporated in
the prediction [84]. In [85], Gaudard et al. presented a Bayesian method that uses
importance sampling for analyzing spatial data sampled from a Gaussian random
ï¬eld whose covariance function was unknown. However, the solution often requires
Markov Chain Monte Carlo (MCMC) methods, which greatly increases the com-
putational complexity. In [46], an iterative prediction algorithm without resorting
to MCMC methods has been developed based on analytical closed-form solutions
from results in [85], by assuming that the covariance function of the spatiotemporal
Gaussian random ï¬eld is known up to a constant.
There have been growing efforts to ï¬t a computationally efï¬cient Gaussian
Markov random ï¬eld (GMRF) on a discrete lattice to a Gaussian random ï¬eld on a
continuum space [4, 86â€“88]. It has been demonstrated that GMRFs with small neigh-
borhoods can approximate Gaussian ï¬elds surprisingly well [86]. This approximated
GMRF and its regression are very attractive for the resource-constrained mobile sen-
sor networks due to its computational efï¬ciency and scalability [89] as compared to
the standard Gaussian process and its regression. Fast kriging of large datasets using
a GMRF as an approximation of a Gaussian ï¬eld has been proposed in [88].
1.2 Contents in Chapters
A brief summary for each subsequent chapter is as follows. Chapter2 gives an
introduction to Gaussian processes and Gaussian Markov random ï¬elds for general
domains as well as the space-time domain.
In Chap.3, we develop covariance function learning algorithms for the sensing
agents to perform nonparametric prediction based on a properly adapted Gaussian
process for a given spatiotemporal phenomenon. By introducing a generalized covari-
ance function, we expand the class of Gaussian processes to include the anisotropic
spatiotemporal phenomena. Maximum likelihood (ML) optimization is used to esti-
mate hyperparameters for the associated covariance function as an empirical Bayes
method.Theproposedoptimalnavigationstrategyforautonomousvehicleswillmax-
imize the Fisher information [90], improving the quality of the estimated covariance
function.
In Chap.4, we ï¬rst present a theoretical foundation of Gaussian process regres-
sion with truncated observations. In particular, we show that the quality of prediction
based on truncated observations does not deteriorate much as compared to that of

1.2 Contents in Chapters
9
prediction based on all cumulative data under certain conditions. The error bounds to
use truncated observations are analyzed for prediction at a single point of interest. A
way to select the temporal truncation size for spatiotemporal Gaussian processes is
also introduced. Inspired by the analysis, we then propose both centralized and dis-
tributed navigation strategies for mobile sensor networks to move in order to reduce
prediction error variances at points of interest. In particular, we demonstrate that
the distributed navigation strategy produces an emergent, swarming-like, collective
behavior to maintain communication connectivity among mobile sensing agents.
In Chap.5, we formulate a fully Bayesian approach for spatiotemporal Gaussian
process regression under practical conditions such as measurement noise and
unknown hyperparameters (particularly, the bandwidths). Thus, multifactorial effects
of observations, measurement noise, and prior distributions of hyperparameters are
all correctly incorporated in the computed posterior predictive distribution. Using
discrete prior probabilities and compactly supported kernels, we provide a way to
design sequential Bayesian prediction algorithms that can be computed (without
using the Gibbs sampler) in constant time (i.e., O(1)) as the number of observations
increases. An adaptive sampling strategy for mobile sensors, using the maximum
a posteriori (MAP) estimation, has been proposed to minimize the prediction error
variances.
In Chap.6, we propose a new class of Gaussian processes for resource-constrained
mobile sensor networks that build on a Gaussian Markov random ï¬eld (GMRF) with
respect to a proximity graph over the surveillance region. The main advantages of
using this class of Gaussian processes over standard Gaussian processes deï¬ned by
mean and covariance functions are its numerical efï¬ciency and scalability due to
its built-in GMRF and its capability of representing a wide range of nonstationary
physical processes. The formulas for predictive statistics are derived and a sequential
ï¬eld prediction algorithm is provided for sequentially sampled observations. For a
special case using compactly supported weighting functions, we propose a distributed
algorithm to implement ï¬eld prediction by correctly fusing all observations.
In Chap.7, we consider a discretized spatial ï¬eld that is modeled by a GMRF with
unknown hyperparameters. From a Bayesian perspective, we design a sequential pre-
diction algorithm to exactly compute the predictive inference of the random ï¬eld.
The main advantages of the proposed algorithm are (1) the computational efï¬ciency
due to the sparse structure of the precision matrix, and (2) the scalability as the num-
ber of measurements increases. Thus, the prediction algorithm correctly takes into
account the uncertainty in hyperparameters in a Bayesian way and also is scalable to
be usable for the mobile sensor networks with limited resources. An adaptive sam-
pling strategy is also designed for mobile sensing agents to ï¬nd the most informative
locations in taking future measurements in order to minimize the prediction error
and the uncertainty in the estimated hyperparameters simultaneously.

Chapter 2
Preliminaries
2.1 Mathematical Notation
Standard notation is used throughout this book. Let R, Râ‰¥0, R>0, Z, Zâ‰¥0, Z>0 denote
the sets of real numbers, nonnegative real numbers, positive real numbers, integers,
nonnegative integers, and positive integers, respectively.
Let E, Var, Corr, Cov denote the expectation, variance, correlation, and the covari-
ance operators, respectively.
Let AT âˆˆRMÃ—N be the transpose of a matrix A âˆˆRNÃ—M. Let tr(A) and det(A)
denote the trace and the determinant of a matrix A âˆˆRNÃ—N, respectively. Let
rowi(A) âˆˆRM and col j(A) âˆˆRN denote the ith row and the jth column of a matrix
A âˆˆRNÃ—M, respectively.
The positive deï¬niteness and the positive semi-deï¬niteness of a square matrix A
are denoted by A â‰»0 and A âª°0, respectively.
Let |x| denote the absolute value of a scalar x. Let âˆ¥xâˆ¥denote the standard
Euclidean norm (2-norm) of a vector x. The induced 2-norm of a matrix A is denoted
by âˆ¥Aâˆ¥. Let âˆ¥xâˆ¥âˆdenote the inï¬nity norm of a vector x.
Let 1 denote the vector with all elements equal to one and I denote the identity
matrix with an appropriate size. Let ei be the standard basis vector of appropriate
size with 1 as its ith element and 0 on all other elements.
The symbol âŠ—denotes the Kronecker product. The symbol â—¦denotes the
Hadamard product (also known as the entry-wise product and the Schur product).
A random vector x, which is distributed by a normal distribution of mean Î¼ and
covariance matrix C, is denoted by x âˆ¼N(Î¼, C). The corresponding probability
density function is denoted by N(x; Î¼, C).
The relative complement of a set A in a set B is denoted by B \ A := B âˆ©Ac,
where Ac is the complement of A. For a set A âˆˆI, we deï¬ne zA = {zi | i âˆˆA}.
Let âˆ’A denote the set I \ A.
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_2
11

12
2
Preliminaries
An undirected graph G = (V, E) is a tuple consisting of a set of vertices V :=
{1, Â· Â· Â· , n} and a set of edges E âŠ‚V Ã— V. The neighbors of i âˆˆV in G are denoted
by Ni := { j âˆˆV | {i, j} âˆˆE}.
Other notations will be explained in due course.
2.2 Physical Process Model
In this section, we review important notions for the Gaussian process which will be
used to model the physical phenomenon. In particular, we introduce a class of spa-
tiotemporalGaussianprocessmodelwithanisotropiccovariancefunctions.Theprop-
erties of Gaussian Markov random ï¬elds (GMRF) are also brieï¬‚y reviewed.
2.2.1 Gaussian Process
A Gaussian process can be thought of a generalization of a Gaussian distribution over
a ï¬nite vector space to function space of inï¬nite dimension. It is formally deï¬ned as
follows [53, 91]:
Deï¬nition 2.1 A Gaussian process (GP) is a collection of random variables, any
ï¬nite number of which have a consistent1 joint Gaussian distribution.
A Gaussian process, denoted by
z(x) âˆ¼GP

Î¼(x), C(x, xâ€²; Î¸)

(2.1)
is completelyspeciï¬edbyits meanfunction Î¼(x) andcovariancefunctionC(x, xâ€²; Î¸)
which are deï¬ned as
Î¼(x) = E [z(x)] ,
C(x, xâ€²; Î¸) = E

(z(x) âˆ’Î¼(x)) (z(xâ€²) âˆ’Î¼(xâ€²))|Î¸

.
Although not needed to be done, we take the mean function to be zero for notational
simplicity,2 i.e., Î¼(x) = 0. If the covariance function C(x, xâ€²; Î¸) is invariant with
respect to translations in the input space, i.e., C(x, xâ€²; Î¸) = C(x âˆ’xâ€²; Î¸), we call it
stationary. Furthermore, if the covariance function is a function of only the distance
between the inputs, i.e., C(x, xâ€²; Î¸) = C(
x âˆ’xâ€² ; Î¸), then it is called isotropic.
1It is also known as the marginalization property. It means simply that the random variables obey
the usual rules of marginalization, etc.
2This is not a drastic limitation since the mean of the posterior process is not conï¬ned to zero [53].

2.2 Physical Process Model
13
Fig. 2.1 Realization of a
two-dimensional (D = 2)
Gaussian process with
Ïƒ 2
f = 5, Ïƒ1 = 2.5, and
Ïƒ2 = 1.5.
Inpractice, aparametricfamilyof functions is usedinsteadof ï¬xingthecovariance
function [84]. One common choice of a stationary covariance function is
C(x, xâ€²; Î¸) = Ïƒ 2
f exp

âˆ’
D

â„“=1

xâ„“âˆ’xâ€²
â„“
2
2Ïƒ 2
â„“
	
,
(2.2)
where xâ„“is the â„“th element of x âˆˆRD. From (2.2), it can be easily seen that the
correlation between two inputs decreases as the distance between them increases.
This decreasing rate depends on the choice of the length scales {Ïƒâ„“}. A very large
length scale means that the predictions would have little bearing on the correspond-
ing input which is then said to be insigniï¬cant. Ïƒ 2
f gives the overall vertical scale
relative to the mean of the Gaussian process in the output space. These parame-
ters play the role of hyperparameters since they correspond to the hyperparame-
ters in neural networks and in the standard parametric model. Therefore, we deï¬ne
Î¸ = (Ïƒ 2
f , Ïƒ1, Â· Â· Â· , ÏƒD)T âˆˆRD+1 as the hyperparameter vector. A realization of a
Gaussian process that is numerically generated is shown in Fig.2.1.
2.2.2 Spatiotemporal Gaussian Process
In this section, spatiotemporal Gaussian processes are of particular interest. Spa-
tiotemporal Gaussian processes are obtained as a special case of (2.1) by setting
x âŠ‚RD Ã— Râ‰¥0, where RD is for spatial locations and Râ‰¥0 is the temporal domain.
A spatiotemporal Gaussian process can be written as
z(s, t) âˆ¼GP(Î¼(s, t), C(s, t, sâ€², tâ€²; Î¸)),

14
2
Preliminaries
(a)
(b)
(c)
Fig. 2.2 Realization of a spatiotemporal (D = 2) Gaussian process with Ïƒ 2
f = 5, Ïƒ1 = 2.5,
Ïƒ2 = 1.5, and Ïƒt = 8 at a t = 1, b t = 5, and c t = 10.
where x = (sT , t)T
âˆˆRD Ã— Râ‰¥0. We consider the following generalized
anisotropic covariance function C(x, xâ€²; Î¸) with a hyperparameter vector Î¸ :=
(Ïƒ 2
f , Ïƒ1, Â· Â· Â· , ÏƒD, Ïƒt)T âˆˆRD+2:
C(x, xâ€²; Î¸) = Ïƒ 2
f exp

âˆ’
D

â„“=1
(sâ„“âˆ’sâ€²
â„“)2
2Ïƒ 2
â„“

exp

âˆ’(t âˆ’tâ€²)2
2Ïƒ 2t

,
(2.3)
where s, sâ€² âˆˆQ âŠ‚RD, t, tâ€² âˆˆRâ‰¥0. {Ïƒ1, Â· Â· Â· , ÏƒD} and Ïƒt are kernel bandwidths
for space and time, respectively. (2.3) shows that points close in the measurement
space and time indices are strongly correlated and produce similar values. In reality,
the larger temporal distance two measurements are taken with, the less correlated
they become, which strongly supports our generalized covariance function in (2.3).
This may also justify the truncation (or windowing) of the observed time series data
to limit the size of the covariance matrix for reducing the computational cost. A
spatially isotropic version of the covariance function in (2.3) has been used in [36].
A realization of a spatiotemporal Gaussian process that is numerically generated is
shown in Fig.2.2.
2.2.3 Gaussian Markov Random Field
The Gaussian Markov random ï¬eld is formally deï¬ned as follows [92]:
Deï¬nition 2.2 (GMRF, [92, Deï¬nition 2.1]) A random vector z = (z1, Â· Â· Â· , zN)T âˆˆ
RN is called a GMRF with respect to a graph G = (V, E) with mean Î¼ and precision
matrix Q â‰»0, if and only if its density has the form
Ï€(z) =
|Q|1/2
(2Ï€)N/2 exp

âˆ’1
2(z âˆ’Î¼)T Q(z âˆ’Î¼)

,

2.2 Physical Process Model
15
and(Q)i j Ì¸= 0 â‡”{i, j} âˆˆE foralli Ì¸= j,wheretheprecisionmatrix(orinformation
matrix) Q = Câˆ’1 is the inverse of the covariance matrix C, and |Q| denotes the
determinant of Q.
The Markov property of a GMRF can be shown by the following theorem.
Theorem 2.1 ([92, Theorem 2.4]) Let z be a GMRF with respect to G = (V, E).
Then the followings are equivalent.
1. The pairwise Markov property:
ziâŠ¥z j | zâˆ’i j
if {i, j} /âˆˆE and i Ì¸= j,
where âŠ¥denotes conditional independence and zâˆ’i j := zâˆ’{i, j} = zI\{i, j}. This
implies that zi and z j are conditionally independent given observations at all
other vertices except {i, j} if i and j are not neighbors.
2. The local Markov property:
ziâŠ¥zâˆ’{i,Ni} | zNi
for every i âˆˆI.
3. The global Markov property:
zAâŠ¥zB | zC
for disjoint sets A, B, and C where C separates A and B, and A and B are
nonempty.
If a graph G has small cardinalities of the neighbor sets, its precision matrix Q
becomes sparse with many zeros in its entries. This plays a key role in computation
efï¬ciency of a GMRF which can be greatly exploited by the resource-constrained
mobile sensor network. For instance, some of the statistical inference can be obtained
directly from the precision matrix Q with conditional interpretations.
Theorem 2.2 ([92, Theorem 2.3]) Let z be a GMRF with respect to G = (V, E)
with mean Î¼ and precision matrix Q â‰»0, then we have
E(zi | zâˆ’i) = Î¼i âˆ’
1
(Q)ii

jâˆˆNi
(Q)i j(z j âˆ’Î¼ j),
Var(zi | zâˆ’i) =
1
(Q)ii
,
Corr(zi, z j | zâˆ’i j) = âˆ’
(Q)i j

(Q)ii(Q) j j
,
âˆ€i Ì¸= j.

16
2
Preliminaries
2.3 Mobile Sensor Network
In this section, we explain the sensor network formed by multiple mobile sensing
agents and present the measurement model used throughout the thesis.
Let N be the number of sensing agents distributed over the surveillance region
Q âˆˆRD. The identity of each agent is indexed by I := {1, 2, Â· Â· Â· , N}. Assume that
all agents are equipped with identical sensors and take noisy observations at time
t âˆˆZ>0. At time t, the sensing agent i takes a noise-corrupted measurement yi(t)
at its current location qi(t) âˆˆQ, i.e.,
yi(t) = z(qi(t), t) + Ïµi,
Ïµi
i.i.d.
âˆ¼N(0, Ïƒ 2
w),
where the sensor noise Ïµi is considered to be an independent and identically dis-
tributed Gaussian random variable. Ïƒ 2
w > 0 is the noise level and we deï¬ne the
signal-to-noise ratio as
Î³ =
Ïƒ 2
f
Ïƒ 2w
.
Notice that when a static ï¬eld is considered, we have z(s, t) = z(s).
For notational simplicity, we denote the collection of positions of all N agents at
time t as q(t), i.e.,
q(t) :=

q1(t)T , Â· Â· Â· , qN(t)T T
âˆˆQN.
The collective measurements from all N mobile sensors at time t are denoted by
yt := (y1(t), Â· Â· Â· , yN(t))T âˆˆRN.
The cumulative measurements from time t âˆˆZ>0 to time tâ€² âˆˆZ>0 are denoted by
yt:tâ€² :=

yT
t , Â· Â· Â· , yT
tâ€²
T
âˆˆRN(tâ€²âˆ’t+1).
The communication network of mobile agents can be represented by an undirected
graph. Let G(t) := (I, E(t)) be an undirected communication graph such that an edge
(i, j) âˆˆE(t) if and only if agent i can communicate with agent j Ì¸= i at time t. We
deï¬ne the neighborhood of agent i at time t by Ni(t) := { j âˆˆI | (i, j) âˆˆE(t)}.
Similarly, let q[i](t) denote the vector form of the collection of positions in

q j(t) | j âˆˆ{i} âˆªNi(t)

. Let y[i]
t
denote vector form of the collection of obser-
vations in

y(q j(t), t) | j âˆˆ{i} âˆªNi(t)

. The cumulative measurements of agent i
from time t to time tâ€² are denoted as y[i]
t:tâ€².

2.4 Gaussian Processes for Regression
17
2.4 Gaussian Processes for Regression
Suppose we have a dataset D =

(x(i), y(i)) | i = 1, Â· Â· Â· , n

collected by mobile
sensing agents where x(i) denotes an input vector of dimension D and y(i) denotes a
scalar value of the noise-corrupted output. The objective of probabilistic regression
is to compute the predictive distribution of the function values zâˆ—:= z(xâˆ—) at some
test input xâˆ—.
For notational simplicity, we deï¬ne the design matrix X of dimension n Ã— D as
the aggregation of n input vectors (i.e., rowi(X) := (x(i))T ), and the outputs are
collected in a vector y := (y(1), Â· Â· Â· , y(n))T . The corresponding vector of noise-free
outputs is deï¬ned as z := (z(x(1)), Â· Â· Â· , z(x(n)))T .
The advantage of the Gaussian process formulation is that the combination of the
prior and noise models can be carried out exactly via matrix operations [93]. The
idea of Gaussian process regression is to place a GP prior directly on the space of
functions without parameterizing the function z(Â·), i.e.,
Ï€(z|Î¸) = N(z; Î¼, K),
where Î¼ âˆˆRn is the mean vector obtained by (Î¼)i
= Î¼(x(i)), and K :=
Cov(z, z|Î¸) âˆˆRnÃ—n is the covariance matrix obtained by (K)i j = C(x(i), x( j); Î¸).
Notice that the GP model and all expressions are always conditional on the corre-
sponding inputs. In the following, we will always neglect the explicit conditioning
on the input matrix X.
The inference in the Gaussian process model is as follows. First, we assume a
joint GP prior Ï€(z, zâˆ—|Î¸) over functions, i.e.,
Ï€(z, zâˆ—|Î¸) = N

Î¼
Î¼(xâˆ—)

,
 K
k
kT C(xâˆ—, xâˆ—; Î¸)

,
(2.4)
where k := Cov(z, zâˆ—|Î¸) âˆˆRn is the covariance between z and zâˆ—obtained by
(k)i = C(x(i), xâˆ—; Î¸). Then, the joint posterior is obtained using Bayes rule, i.e.,
Ï€(z, zâˆ—|Î¸, y) = Ï€(y|z)Ï€(z, zâˆ—|Î¸)
Ï€(y|Î¸)
,
where we have used Ï€(y|z, zâˆ—) = Ï€(y|z). Finally, the desired predictive distribution
Ï€(zâˆ—|Î¸, y) is obtained by marginalizing out the latent variables in z, i.e.,
Ï€(zâˆ—|Î¸, y) =

Ï€(z, zâˆ—|Î¸, y)dz
=
1
Ï€(y|Î¸)

Ï€(y|z)Ï€(z, zâˆ—|Î¸, y)dz.
(2.5)

18
2
Preliminaries
Since we have the joint Gaussian prior given in (2.4) and
y|z âˆ¼N

z, Ïƒ 2
wI

,
the integral in (2.5) can be evaluated in closed-form and the predictive distribution
turns out to be Gaussian, i.e.,
zâˆ—|Î¸, y âˆ¼N

Î¼zâˆ—|Î¸,y, Ïƒ 2
zâˆ—|Î¸,y

,
(2.6)
where
Î¼zâˆ—|Î¸,y = Î¼(xâˆ—) + kT (K + Ïƒ 2
wI)âˆ’1(y âˆ’Î¼),
(2.7)
and
Ïƒ 2
zâˆ—|Î¸,y = C(xâˆ—, xâˆ—; Î¸) âˆ’kT (K + Ïƒ 2
wI)âˆ’1k.
(2.8)
For notational simplicity, we deï¬ne the covariance matrix of the noisy observations
as C := Cov(y, y|Î¸) = K + Ïƒ 2
wI.

Chapter 3
Learning Covariance Functions
We often assume that Gaussian processes are isotropic implying that the covariance
function only depends on the distance between locations. Many studies also assume
that the corresponding covariance functions are known a priori for simplicity. How-
ever, this is not the case in general as pointed out in the literature [44, 76, 94], in
which they treat the nonstationary process by fusing a collection of isotropic spatial
Gaussian processes associated with a set of local regions. Our objective in this chapter
is to develop theoretically sound algorithms for mobile sensor networks to learn the
anisotropic covariance function of a spatiotemporal Gaussian process. Mobile sens-
ing agents can then predict the Gaussian process based on the estimated covariance
function in a nonparametric manner.
First, in Sect.3.1, we illustrate the importance of the choice of the covariance
function. In Sect.3.2, we introduce a covariance function learning algorithm for an
anisotropic, spatiotemporal Gaussian process. The covariance function is assumed to
be deterministic but unknown a priori and it is estimated by the maximum likelihood
(ML) estimator. In Sect.3.3, an optimal sampling strategy is proposed to minimize
the CramÃ©râ€“Rao lower bound (CRLB) of the estimation error covariance matrix. In
Sect.3.4, simulation results illustrate the usefulness of our proposed approach.
3.1 Selection of Gaussian Process Prior
In this subsection, we illustrate the importance of selecting a Gaussian process prior
via hyperparameters when we make inferences from the experimental data. To have
illustrative cases, we consider the experimental data collected by the robotic boat
(see Fig.3.1a) that was deployed in a pond in Central Park, Okemos, Michigan. A set
of water depth values and sampling locations was collected from onboard sensors in
the robotic boat. Figure3.1b shows the location site with boat trajectories in red lines.
Without loss of generality, the GPS data, in particular the longitude and latitude, are
normalized to [0, 1]. Let us assume that the process has a known constant mean so
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_3
19

20
3
Learning Covariance Functions
(a)
(b)
Fig. 3.1 a Remotely controlled boat equipped with depth sensor and GPS (credit: Jongeun Choi),
b experiment site with robotic boatâ€™s trajectories (shown as red lines)
that we only care to select the covariance function. With the squared exponential
covariance function in (2.2), i.e.,
C(x, xâ€²; Î¸) = Ïƒ2
f exp

âˆ’
2

â„“=1
(xâ„“âˆ’xâ€²
â„“)2
2Ïƒ2
â„“

,
the estimated depth ï¬eld and the prediction error variance using the estimated hyper-
parameters by maximizing the likelihood function are shown in Fig.3.2. Another set
of corresponding ï¬gures are provided with the scaled Ïƒ1 and Ïƒ2 values by 0.2 from
the estimates as shown in Fig.3.3. With different bandwidths (or length scales) Ïƒ1
and Ïƒ2 while keeping other parameters ï¬xed on the same values, the prediction and
its prediction error variance on the same experimental data are signiï¬cantly different.
(a)
(b)
Fig. 3.2 Prediction with estimated hyperparameters Ïƒ f = 2.19, Ïƒ1 = 0.40, Ïƒ2 = 0.29, Ïƒw = 0.24.
a Estimated depth, and b prediction error variance, with sampling positions shown as white crosses

3.1 Selection of Gaussian Process Prior
21
(a)
(b)
Fig. 3.3 Prediction with scaled Ïƒ1 and Ïƒ2 by 0.2, i.e., Ïƒ f = 2.19, Ïƒ1 = 0.08, Ïƒ2 = 0.058,
Ïƒw = 0.24. a Estimated depth, and b prediction error variance, with sampling positions shown as
white crosses
With smaller bandwidths, the predicted depth ï¬eld is much more wiggly and wavy
than its counterpart (Figs.3.2a and 3.3a), which is an artifact due to the wrong choice
of bandwidths in this case.
For the sake of illustration, let us assume that hyperparmeters are known to be
different as reported in Figs.3.2 and 3.3. As shown in Figs.3.2 and 3.3, in general,
the Gaussian process with larger bandwidths (and stronger spatial correlations) tends
to be smooth and does not need dense sampling for a decent level of prediction error
variance quality (Fig.3.2b). On the other hand, the Gaussian process with smaller
bandwidths (and weaker spatial correlations) allows much more complicated spatial
details and needs to be densely sampled. From these ï¬ndings, we recognize the
importance of the choice of the covariance function to make precise prediction as
well as schedule the sampling in an optimal way. More discussions on the selection
of covariance functions from a Bayesian perspective can be found in [95].
3.2 Learning the Hyperparameters
Without loss of generality, we consider a zero-mean spatiotemporal Gaussian process
z(s, t) âˆ¼GP

0, C(s, t, sâ€², tâ€²; Î¸)

,
with the covariance function
C(s, t, sâ€², tâ€²; Î¸) = Ïƒ2
f exp
â›
ââˆ’

â„“=1,2
(sâ„“âˆ’sâ€²
â„“)2
2Ïƒ2
â„“
â
â exp

âˆ’(t âˆ’tâ€²)2
2Ïƒ2t

,

22
3
Learning Covariance Functions
where s, sâ€² âˆˆQ âŠ‚R2, t, tâ€² âˆˆRâ‰¥0, for modeling the ï¬eld undergoing a physical
transport phenomenon. Î¸ = (Ïƒ2
f , Ïƒ1, Ïƒ2, Ïƒt)T âˆˆRM is the hyperparameter vector,
where M = 4. The assumption of zero-mean is not a strong limitation since the mean
of the posterior process is not conï¬ned to zero [53].
If the covariance function C(s, t, sâ€², tâ€²; Î¸) of a Gaussian process is not known a
priori, mobile agents need to estimate parameters of the covariance function (i.e.,
the hyperparameter vector Î¸ âˆˆRM) based on the observed samples. In the case
where measurement noise level Ïƒw is also unknown, it can be incorporated in the
hyperparameter vector and be estimated. Thus, we have Î¸ = (Ïƒ2
f , Ïƒ1, Ïƒ2, Ïƒt, Ïƒw)T âˆˆ
RM where M = 5.
Existing techniques for learning the hyperparameters are based on the likelihood
function. Given the observations y = (y(1), . . . , y(n))T âˆˆRn collected by mobile
sensing agents over time, the likelihood function is deï¬ned as
L(Î¸|y) = Ï€(y|Î¸).
(3.1)
Notice that in this chapter, the hyperparameter vector Î¸ is considered to be deter-
ministic, and hence Ï€(y|Î¸) should not be considered as conditional distribution.
A point estimate of the hyperparameter vector Î¸ can be made by maximizing the
log likelihood function. The maximum likelihood (ML) estimate Ë†Î¸ âˆˆRM of the
hyperparameter vector is obtained by
Ë†Î¸ = arg max
Î¸âˆˆ log L(Î¸|y),
(3.2)
where  is the set of all possible choices of Î¸. The log likelihood function is given
by
log L(Î¸|y) = âˆ’1
2yT Câˆ’1y âˆ’1
2 log det(C) âˆ’n
2 log 2Ï€,
where C := Cov(y, y|Î¸) âˆˆRnÃ—n is the covariance matrix, and n is the total number
of observations. Maximization of the log likelihood function can be done efï¬ciently
using gradient-based optimization techniques such as the conjugate gradient method
[96, 97]. The partial derivative of the log likelihood function with respect to a hyper-
parameter Î¸i âˆˆR, i.e., the ith entry of the hyperparameter vector Î¸, is given by
âˆ‚log L(Î¸|y)
âˆ‚Î¸i
= 1
2yT Câˆ’1 âˆ‚C
âˆ‚Î¸i
Câˆ’1y âˆ’1
2 tr

Câˆ’1 âˆ‚C
âˆ‚Î¸i

= 1
2 tr

(Î±Î±T âˆ’Câˆ’1) âˆ‚C
âˆ‚Î¸i

,
where Î± = Câˆ’1y âˆˆRn. In general, the log likelihood function is a nonconvex
function and hence it can have multiple maxima.
As an alternative, when certain prior knowledge is available on the hyperparame-
ters, a prior distribution Ï€(Î¸) can be imposed on the hyperparameter vector. Using

3.2 Learning the Hyperparameters
23
Bayesâ€™ rule, the posterior distribution Ï€(Î¸|y) is proportional to the likelihood L(Î¸|y)
times the prior distribution Ï€(Î¸), i.e.,
Ï€(Î¸|y) âˆL(Î¸|y)Ï€(Î¸)
= Ï€(y|Î¸)Ï€(Î¸),
in light of (3.1) deï¬ned earlier. Then the maximum a posteriori (MAP) estimate
Ë†Î¸ âˆˆRM of the hyperparameter vector can be obtained similarly by
Ë†Î¸ = arg max
Î¸âˆˆ (log L(Î¸|y) + log Ï€(Î¸)) .
(3.3)
Notice that when no prior information is available, the MAP estimate is equivalent
to the ML estimate.
Once the estimate of the hyperparameter vector Î¸ is obtained with conï¬dence, it
can be used as the true value for the mobile sensor network to predict the ï¬eld of
interest using Gaussian process regression in (2.6).
3.3 Optimal Sampling Strategy
We assume now that the estimate of hyperparameters has been obtained using the
procedure outlined in Sect.3.2 based on all observations collected up to and including
time t. At time t + 1, agents should ï¬nd new sampling positions to improve the
quality of the estimated covariance function. For instance, to precisely estimate the
anisotropic phenomenon, i.e., processes with different covariances along x and y
directions, sensing agents need to explore and sample measurements along different
directions.
To this end, we consider a centralized scheme. Suppose that a central station (or a
leader agent) has access to all measurements collected by agents. Assume that at time
t + 1, agent i moves to a new sampling position Ëœqi âˆˆQ and makes an observation
yi(t + 1) âˆˆR. The collection of the new sampling positions and new observations
from all agents are denoted by Ëœq âˆˆQN and Ëœy âˆˆRN, respectively. The objective of
the optimal sampling strategy is to ï¬nd the best sampling positions Ëœq such that the
maximum likelihood (ML) estimate Ë†Î¸t+1 âˆˆRM at time t + 1 is as close to the true
hyperparameter vector Î¸âˆ—âˆˆRM as possible. Notice that Î¸âˆ—is unknown in practice,
but this issue will be addressed slightly later.
Consider the Fisher information matrix (FIM) that measures the information pro-
duced by y1:t âˆˆRNt and Ëœy âˆˆRN for estimating the true hyperparameter vector
Î¸âˆ—âˆˆRM at time t + 1. The CramÃ©râ€“Rao lower bound (CRLB) theorem states that
the inverse of the FIM (denoted by M âˆˆRMÃ—M) is a lower bound of the estimation
error covariance matrix [90, 98]:
E

(Ë†Î¸t+1 âˆ’Î¸âˆ—)(Ë†Î¸t+1 âˆ’Î¸âˆ—)T 
âª°Mâˆ’1,

24
3
Learning Covariance Functions
where Ë†Î¸t+1 âˆˆRm represents the ML estimate of Î¸âˆ—at time t + 1. The FIM [90] is
given by
(M)i j = âˆ’E
âˆ‚2 ln L(Î¸|Ëœy, y1:t)
âˆ‚Î¸iâˆ‚Î¸ j

,
where L(Î¸|Ëœy, y1:t) is the likelihood function at time t + 1, and the expectation is
taken with respect to Ï€(y1:t, Ëœy|Î¸). Notice that the likelihood is now a function of Î¸
and Ëœy. The analytical form of the FIM is given by
(M)i j = 1
2 tr

ËœC
âˆ’1 âˆ‚ËœC
âˆ‚Î¸i
ËœC
âˆ’1 âˆ‚ËœC
âˆ‚Î¸ j

,
where ËœC âˆˆRN(t+1)Ã—N(t+1) is deï¬ned as
ËœC := Cov
y1:t
Ëœy

,
y1:t
Ëœy
 Î¸âˆ—

.
Since the true value Î¸âˆ—is not available, we will evaluate the FIM at the currently
best estimate Ë†Î¸t.
We can expect that minimizing the CramÃ©râ€“Rao lower bound results in a decrease
of uncertainty in estimating Î¸ [99]. The most common optimality criterion is
D-optimality [100, 101]. It corresponds to minimizing the volume of the ellipsoid
which represents the maximum conï¬dence region for the maximum likelihood esti-
mate of the unknown hyperparameters [101]. Using the D-optimality criterion [100,
101], the objective function J(Â·) is given by
J(Ëœq) := det(Mâˆ’1).
However, if one hyperparameter has a very large variance compared to the others, the
ellipsoid will be skinny and thus minimizing the volume may be misleading [101].
As an alternative, A-optimality which minimizes the sum of the variances is often
used. The objective function J(Â·) based on A-optimality criterion is
J(Ëœq) := tr(Mâˆ’1).
Hence, a control law for the mobile sensor network can be formulated as follows:
q(t + 1) = arg min
ËœqâˆˆQN J(Ëœq).
(3.4)
In (3.4), we only consider the constraint that robots should move within the region
Q. However, the mobility constraints, such as the maximum distance that a robot

3.3 Optimal Sampling Strategy
25
Table 3.1 Centralized optimal sampling strategy at time t
For i âˆˆI, agent i performs:
1: make an observation at current position qi(t), i.e., yi(t)
2: transmit the observation yi(t) to the central station
The central station performs:
1: collect the observations from all N agents, i.e., yt
2: obtain the cumulative measurements, i.e., y1:t
3: compute the maximum likelihood estimate Ë†Î¸t based on
Ë†Î¸t = arg maxÎ¸âˆˆÎ˜ ln L(Î¸|y1:t),
starting with the initial point Ë†Î¸tâˆ’1
4: compute the control in order to minimize the cost function J(Ëœq)
via
q(t + 1) = arg minËœqâˆˆQN J(Ëœq)
5: send the next sampling positions {qi(t + 1) | i âˆˆI} to all N
agents
For i âˆˆI, agent i performs:
1: receive the next sampling position qi(t + 1) from the central
station
2: move to qi(t + 1) before time t + 1
can move between two time indices, or the maximum speed with which a robot can
travel, can be incorporated as additional constraints in the optimization problem [45].
The overall protocol for the sensor network is summarized as in Table3.1.
3.4 Simulation
We apply our approach to a spatial Gaussian process. The Gaussian process was
numerically generated for the simulation [53]. The hyperparameters used in the sim-
ulation were chosen such that Î¸ = (Ïƒ2
f , Ïƒ1, Ïƒ2, Ïƒw)T = (5, 4, 2, 0.5)T . In this case,
N = 9 mobile sensing agents were initialized at random positions in a surveillance
region Q = [0, 10] Ã— [0, 10]. The initial values for the algorithm were given to be
Î¸0 = (1, 1, 1, 0.1)T . The gradient method was used to ï¬nd the MAP estimate of the
hyperparameter vector.
For simplicity, we assumed that the global basis is the same as the model basis. We
considered a situation where at each time, measurements of agents are transmitted
to a leader (or a central station) that uses our Gaussian learning algorithm and sends
optimal control back to individual agents for next iteration to improve the quality of
the estimated covariance function. The maximum distance for agents to move in one
time step was chosen to be 1 for both x and y directions. The A-optimality criterion
was used for optimal sampling.

26
3
Learning Covariance Functions
0
2
4
6
8
10
0
2
4
6
8
Ïƒ
Ïƒ
Ïƒ
Ïƒ
Ïƒ
Ïƒ
Ïƒ
Ïƒ
f
0
2
4
6
8
10
0
5
10
1
0
2
4
6
8
10
0
2
4
6
2
0
2
4
6
8
10
âˆ’0.5
0
0.5
1
w
t
(a)
0
2
4
6
8
10
0
2
4
6
8
f
0
2
4
6
8
10
0
5
10
1
0
2
4
6
8
10
0
2
4
6
2
0
2
4
6
8
10
âˆ’0.5
0
0.5
1
w
t
(b)
Fig. 3.4 Monte Carlo simulation results (100 runs) for a spatiotemporal Gaussian process using a
the random sampling strategy, and b the adaptive sampling strategy. The estimated hyperparameters
are shown in blue circles with error bars. The true hyperparameters that used for generating the
process are shown in red dashed lines
For both proposed and random strategies, Monte Carlo simulations were run
for 100 times and the statistical results are shown in Fig.3.4. The estimates of the
hyperparameters (shown in circles and error bars) tend to converge to the true values
(shown in dotted lines) for both strategies. As can be seen, the proposed scheme
(Fig.3.4a) outperforms the random strategy (Fig.3.4b) in terms of the A-optimality
criterion.
After converging to a good estimate of Î¸, agents can switch to a decentralized
conï¬guration and collect samples for other goals such as peak tracking and prediction
of the process [42, 77, 78].

Chapter 4
Memory Efï¬cient Prediction
With Truncated Observations
The main reason why the nonparametric prediction using Gaussian processes has not
been popular for resource-constrained multi-agent systems is the fact that the optimal
prediction must use all cumulatively measured values in a non-trivial way [74, 75].
In this case, a robot needs to compute the inverse of the covariance matrix whose
size grows as it collects more measurements. With this operation, the robot will run
out of memory quickly. Therefore, it is necessary to develop a class of prediction
algorithms using spatio-temporal Gaussian processes under a ï¬xed memory size.
A simple way to cope with this dilemma is to design a robot so that it predicts a
spatio-temporal Gaussian process at the current (or future) time based on truncated
observations, e.g., the last m observations from a total of n of observations as shown
in Fig.4.1. This seems intuitive in the sense that the last m observations are more
correlated with the point of interest than the other r = n âˆ’m observations (Fig.4.1)
in order to predict values at current or future time. Therefore, it is very important
to analyze the performance degradation and trade-off effects of prediction based on
truncated observations compared to the one based on all cumulative observations.
The second motivation is to design and analyze distributed sampling strategies
for resource-constrained mobile sensor networks. Developing distributed estimation
and coordination algorithms for multi-agent systems using only local information
from local neighboring agents has been one of the most fundamental problems in
mobile sensor networks [42, 45, 62â€“66]. Emphasizing practicality and usefulness, it
is critical to synthesize and analyze distributed sampling strategies under practical
constraints such as measurement noise and a limited communication range.
In Sect.4.1, we propose to use only truncated observations to bound the computa-
tional complexity. The error bounds in using truncated observations are analyzed for
prediction at a single point in Sect.4.1.1. A way of selecting a temporal truncation
size is also discussed in Sect.4.1.2. To improve the prediction quality, centralized and
distributed navigation strategies for mobile sensor networks are proposed in Sect.4.2.
In Sect.4.3, simulation results illustrate the usefulness of our schemes under different
conditions and parameters.
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_4
27

28
4
Memory Efï¬cient Prediction With Truncated Observations
sy
sx
1
2
3
t
t âˆ’Î·
time
r = n âˆ’m observations
m observations
xâˆ—
. . .
. . .
Fig. 4.1 Robot predicts a scalar value at xâˆ—(denoted by a red star) based on cumulative n spatio-
temporal observations (denoted by blue crosses). Near-optimal prediction can be obtained using
truncated observations, e.g., the last m observations. In this case, x = (sx, sy, t)T
4.1 GPR with Truncated Observations
As mentioned in above, one drawback of Gaussian process regression is that its
computational complexity and memory space increase as more measurements are
collected, making the method prohibitive for robots with limited memory and com-
puting power. To overcome this increase in complexity, a number of approximation
methods for Gaussian process regression have been proposed. In particular, the sparse
greedy approximation method [79], the Nystrom method [80], the informative vec-
tor machine [81], the likelihood approximation [82], and the Bayesian committee
machine [83] have been shown to be effective for many problems. However, these
approximation methods have been proposed without theoretical justiï¬cations.
In general, if measurements are taken from nearby locations (or space-time loca-
tions), correlation between measurements is strong and correlation exponentially
decays as the distance between locations increases. If the correlation function of a
Gaussian process has this property, intuitively, we can make a good prediction at a
point of interest using only measurements nearby. In the next subsection, we for-
malize this idea and provide a theoretical foundation for justifying Gaussian process
regression with truncated observations proposed in this chapter.
4.1.1 Error Bounds Using Truncated Observations
Consider a zero-mean Gaussian process
z(x) âˆ¼GP(0, Ïƒ2
f C(x, xâ€²)).
(4.1)

4.1 GPR with Truncated Observations
29
Notice that we denote the covariance function as Ïƒ2
f C(x, xâ€²) in which C(x, xâ€²) :=
Corr(z(x), z(xâ€²)) is the correlation function. Recall that the predictive distribution
of zâˆ—:= z(xâˆ—) at a point of interest xâˆ—given observations y = (y(1), . . . , y(n))T is
Gaussian, i.e.,
zâˆ—|y âˆ¼N

Î¼zâˆ—|y, Ïƒ2
zâˆ—|y

,
(4.2)
where
Î¼zâˆ—|y = kT Câˆ’1k,
(4.3a)
and
Ïƒ2
zâˆ—|y = Ïƒ2
f (1 âˆ’kT Câˆ’1k).
(4.3b)
In (4.3a) and (4.3b), we have deï¬ned C := Corr(y, y) âˆˆRnÃ—n, and k :=
Corr(y, zâˆ—) âˆˆRn. Notice that in this chapter, we assume the hyperparameter vector
Î¸ âˆˆRM is given, and hence we neglect the explicit conditioning on Î¸.
Without loss of generality, we assume that the ï¬rst m out of n observations are used
to predict zâˆ—. Let r = n âˆ’m, ym = (y(1), . . . , y(m))T , yr = (y(m+1), . . . , y(n))T .
Then the covariance matrix K âˆˆRnÃ—n and k âˆˆRn can be represented as
K =
 Km Kmr
KT
mr Kr

,
k =
km
kr

.
Using truncated observations, we can predict the value zâˆ—as
Î¼zâˆ—|ym = kT
mCâˆ’1
m km,
(4.4)
with a prediction error variance given by
Ïƒ2
zâˆ—|ym = Ïƒ2
f (1 âˆ’kT
mCâˆ’1
m km),
(4.5)
where Cm = Km + Ïƒ2
wI âˆˆRmÃ—m.
The following result shows the gap between predicted values using truncated
measurements and all measurements.
Theorem 4.1 Consider a Gaussian process z(x) âˆ¼GP(0, Ïƒ2
f C(x, xâ€²)), we have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym = (kr âˆ’KT
mrCâˆ’1
m km)T (Cr âˆ’KT
mrCâˆ’1
m Kmr)âˆ’1(yr âˆ’KT
mrCâˆ’1
m ym),
(4.6a)
and
Ïƒ2
zâˆ—|yy âˆ’Ïƒ2
zâˆ—|ym = âˆ’Ïƒ2
f (kr âˆ’KT
mrCâˆ’1
m km)T (Cr âˆ’KT
mrCâˆ’1
m Kmr)âˆ’1(kr âˆ’KT
mrCâˆ’1
m km) < 0.
(4.6b)

30
4
Memory Efï¬cient Prediction With Truncated Observations
Proof We can rewrite (4.3a) as
Î¼zâˆ—|y =
km
kr
T  Cm Kmr
KT
mr Cr
âˆ’1 ym
yr

,
(4.7a)
and (4.3b) as
Ïƒ2
zâˆ—|y = Ïƒ2
f

1 âˆ’
km
kr
T  Cm Kmr
KT
mr Cr
âˆ’1 km
kr

.
(4.7b)
Using the identity based on matrix inversion lemma (see AppendixA.2), (4.7a) and
(4.7b) become
Î¼zâˆ—|y = kT
mCâˆ’1
m ym
+ (kr âˆ’KT
mrCâˆ’1
m km)T (Cr âˆ’KT
mrCâˆ’1
m Kmr)âˆ’1(yr âˆ’KT
mrCâˆ’1
m ym),
and
Ïƒ2
zâˆ—|y = Ïƒ2
f

1 âˆ’kT
mCâˆ’1
m km

âˆ’Ïƒ2
f (kr âˆ’KT
mrCâˆ’1
m km)T (Cr âˆ’KT
mrCâˆ’1
m Kmr)âˆ’1(kr âˆ’KT
mrCâˆ’1
m km).
Hence, by the use of (4.4) and (4.5), we obtain (4.6a) and 4.6b.
â–¡
Corollary 4.1 The prediction error variance Ïƒ2
zâˆ—|ym is a non-increasing function
of m.
Proof The proof is straightforward from Theorem4.1 by letting n = m + 1.
â–¡
Considering an ideal case in which the measurements ym are not correlated with
the remaining measurements yr, we have the following result.
Proposition 4.1 Under the assumptions used in Theorem4.1 and for given yr âˆ¼
N(0, Cr), if Kmr = 0, then Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym = kT
r Câˆ’1
r yr and Ïƒ2
zâˆ—|y âˆ’Ïƒ2
zâˆ—|ym =
âˆ’Ïƒ2
f kT
r Câˆ’1
r kr. In addition, we also have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 â‰¤
			kT
r Câˆ’1
r
			
âˆšr Â¯y(p1)
with a non-zero probability p1. For a desired p1, we can ï¬nd Â¯y(p1) by solving
p1 =

1â‰¤iâ‰¤r

1 âˆ’2Î¦

âˆ’Â¯y(p1)
Î»1/2
i

,
(4.8)

4.1 GPR with Truncated Observations
31
where Î¦ is the cumulative normal distribution and {Î»i | i = 1, . . . ,r} are the eigen-
values of Cr = UUT with a unitary matrix U, and  = diag(Î»1, . . . , Î»r).
Proof The ï¬rst statement is straightforward from Theorem4.1.
For the second statement, we can represent yr as yr = C1/2
r
u = U1/2u = UËœy,
where u is a vector of independent standard normals and Cr = UUT and C1/2
r
=
U1/2. By using the Cauchy-Schwarz inequality and norm inequalities, we have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 =
kT
r Câˆ’1
r yr
 =
kT
r Câˆ’1
r UËœy

â‰¤
			kT
r Câˆ’1
r
			
		UËœy
		 =
			kT
r Câˆ’1
r
			
		Ëœy
		
â‰¤
			kT
r Câˆ’1
r
			
âˆšr
		Ëœy
		
âˆâ‰¤
			kT
r Câˆ’1
r
			
âˆšr Â¯y.
Recall that we have u âˆ¼N(0, I) and Ëœy âˆ¼N(0, ), where  = diag(Î»1, . . . , Î»r).
Then we can compute the probability p1 = Pr(
		Ëœy
		
âˆâ‰¤Â¯y) as follows.
p1 = Pr

max
1â‰¤iâ‰¤r
 Ëœy(i) â‰¤Â¯y

= Pr

max
1â‰¤iâ‰¤r
Î»1/2
i
ui
 â‰¤Â¯y

=

1â‰¤iâ‰¤r
Pr

Î»1/2
i
|ui| â‰¤Â¯y

=

1â‰¤iâ‰¤r
Pr

|ui| â‰¤
Â¯y
Î»1/2
i

=

1â‰¤iâ‰¤r

1 âˆ’2Î¦

âˆ’
Â¯y
Î»1/2
i

,
where Î¦(Â·) is the cumulative standard normal distribution.
â–¡
Hence, if the magnitude of Kmr is small, then the truncation error from using trun-
cated measurements will be close to kT
r Câˆ’1
r kr. Furthermore, if we want to reduce this
error, we want kr to be small, i.e., when the covariance between zâˆ—and the remaining
measurements yr is small. In summary, if the following two conditions are satisï¬ed:
(1) the correlation between measurements ym and the remaining measurements yr
is small and (2) the correlation between zâˆ—and the remaining measurements yr is
small, then the truncation error is small and Î¼zâˆ—|ym can be a good approximation to
Î¼zâˆ—|y. This idea is formalized in a more general setting in the following theorem.
Theorem 4.2 Consider a zero-mean Gaussian process z(x) âˆ¼N(0, Ïƒ2
f C(x, xâ€²))
with the correlation function
C(x, xâ€²) = exp

âˆ’
		x âˆ’xâ€²		2
2Ïƒ2
â„“

,
(4.9)

32
4
Memory Efï¬cient Prediction With Truncated Observations
andassumethatwehavecollectedn observations, y(1), . . . , y(n).SupposethatKmr is
smallenoughsuchthat
			KT
mrCâˆ’1
m km
			 â‰¤âˆ¥krâˆ¥,and
			KT
mrCâˆ’1
m ym
			 â‰¤Î´2
		yr
		andfor
some Î´2 > 0. Given 0 < p2 < 1, choose Â¯y(p2) such that maxn
i=m+1
y(i) < Â¯y(p2)
with probability p2 and Ïµ > 0 such that Ïµ < 2Î³r(1 + Î´2) Â¯y(p2) where Î³ is the
signal-to-noise ratio. For xâˆ—, if the last r = n âˆ’m data points satisfy
			x(i) âˆ’xâˆ—
			
2
> 2Ïƒ2
â„“log

2Î³ 1
Ïµr(1 + Î´2) Â¯y(p2)

,
then, with probability p2, we have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 < Ïµ.
Proof Let A = Câˆ’1
m Kmr and B = KT
mrCâˆ’1
m Kmr for notational convenience. Then
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 =
			(kT
r âˆ’kT
mA)(Cr âˆ’B)âˆ’1(kr âˆ’AT ym)
			
â‰¤
			kT
r âˆ’kT
mA
			
			(Cr âˆ’B)âˆ’1(yr âˆ’AT ym)
			
â‰¤
			kT
r âˆ’kT
mA
			 Ã— (
			(Cr âˆ’B)âˆ’1yr
			 +
			(Cr âˆ’B)âˆ’1AT ym
			)
â‰¤2 âˆ¥krâˆ¥
			(Cr âˆ’B)âˆ’1yr
			 +
			(Cr âˆ’B)âˆ’1AT ym
			

Since Kr is positive semi-deï¬nite, and Cm is positive deï¬nite, we have Kr âˆ’B is
positive semi-deï¬nite. Then we have
(Cr âˆ’B)âˆ’1 = (Kr + 1/Î³I âˆ’B)âˆ’1 âª¯Î³I.
Combining this result, we get
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 â‰¤2Î³ âˆ¥krâˆ¥(
		yr
		 +
			AT ym
			)
â‰¤2Î³(1 + Î´2) âˆ¥krâˆ¥
		yr
		
â‰¤2Î³(1 + Î´2)âˆšrCmax
		yr
		 ,
where C(x(i), xâˆ—) â‰¤Cmax for i
âˆˆ{m + 1, . . . , n}. Deï¬ne Â¯y(p2) such that
maxn
i=m+1
y(i) â‰¤Â¯y(p2) with probability p2. Then, with probability p2, we have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 â‰¤2Î³r(1 + Î´2)Cmax Â¯y(p2).
Hence, for Ïµ > 0, if
Cmax <
Ïµ
2Î³r(1 + Î´2) Â¯y(p2)
(4.10)

4.1 GPR with Truncated Observations
33
with probability p2, we have
Î¼zâˆ—|y âˆ’Î¼zâˆ—|ym
 < Ïµ.
Let l2 = min
		x(i) âˆ’xâˆ—
		2 for any i âˆˆ{m + 1, . . . , n}. Then (4.10) becomes, with
probability p2,
exp

âˆ’l2
2Ïƒ2
â„“

â‰¤Cmax <
Ïµ
2Î³r(1 + Î´2) Â¯y(p2)
l2 > âˆ’2Ïƒ2
â„“log

Ïµ
2Î³r(1 + Î´2) Â¯y(p2)

For Ïµ < 2Î³r(1 + Î´2) Â¯y(p2), we have
l2 > 2Ïƒ2
â„“log

2Î³ 1
Ïµr(1 + Î´2) Â¯y(p2)

,
and this completes the proof.
â–¡
Remark 4.1 The last part of Proposition4.1 and Theorem4.2 seek a bound for the
difference between predicted values using all and truncated observations with a given
probability since the difference is a random variable.
Example 4.1 We provide an illustrative example to show how to use the result of
Theorem4.2 as follows. Consider a Gaussian process deï¬ned in (4.1) and (4.9) with
Ïƒ2
f = 1, Ïƒâ„“= 0.2, and Î³ = 100. If we have any randomly chosen 10 samples
(m = 10) within (0, 1)2 and we want to make prediction at xâˆ—= (1, 1)T . We choose
Â¯y(p2) = 2Ïƒ f = 2 such that maxn
i=m+1
y(i) < Â¯y(p2) with probability p2 = 0.95.
According to Theorem4.2, if we have an extra sample x(11) (r = 1) at (2.5, 2.5)T ,
which satisï¬es the condition
		x(11) âˆ’xâˆ—
		 > 0.92, then the difference in prediction
using with and without the extra sample is less than Ïµ = 0.01 with probability
p2 = 0.95.
Example 4.2 Motivated by the results presented, we take a closer look at the use-
fulness of using a subset of observations from a sensor network for a particular
realization of the Gaussian process. We consider a particular realization shown in
Fig.4.2, where crosses represent the sampling points of a Gaussian process deï¬ned
in (4.1) and (4.9) with Ïƒ2
f = 1, Ïƒâ„“= 0.2, and Î³ = 100 over (0, 1)2. We have selected
ym as the collection of observations (blue crosses) within the red circle of a radius
R = 2Ïƒâ„“= 0.4 centered at a point (a red star) located at xâˆ—= (0.6, 0.4)T . If a mea-
surement is taken outside the red circle, the correlation between this measurement
and the value at xâˆ—decreases to 0.135. The rest of observations (blue crosses outside

34
4
Memory Efï¬cient Prediction With Truncated Observations
Fig. 4.2 Example of the
selection of truncated
observations. The parameters
used in the example are:
Ïƒ2
f = 1, Ïƒâ„“= 0.2, Ïƒw = 0.1
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
of the red circle) are selected as yr. The prediction results are shown in Table4.1. In
this particular realization, we have zâˆ—= 1.0298. It can be seen that the prediction
means and variances using only ym are close to the one using all observations. We
also compute the prediction at xâˆ—with yr which is far from the true value with a
large variance.
The result of Theorem4.2 and Examples4.1 and 4.2 all suggest the usage of
observations that are highly correlated with the point of interest.
4.1.2 Selecting Temporal Truncation Size
Inprevioussubsection,wehaveobtainedtheerrorboundsforthepredictionatasingle
point. In general, the observations made close to that point are more informative than
the others.
Table 4.1 Prediction means and variances using y, ym, and yr
n = 20
m = 12
r = 8
Î¼zâˆ—|y
1.0515
1.0633
0.3491
Ïƒ2
zâˆ—|y
0.0079
0.0080
0.9364

4.1 GPR with Truncated Observations
35
Consider a zero-mean spatio-temporal Gaussian process
z(s, t) âˆ¼GP(0, Ïƒ2
f C(s, t, sâ€², tâ€²)),
(4.11)
with covariance function
C(x, xâ€²) = Cs(s, sâ€²)Ct(t, tâ€²)
= exp
â›
ââˆ’

â„“=1,2
(sâ„“âˆ’sâ€²
â„“)2
2Ïƒ2
â„“
â
â exp

âˆ’(t âˆ’tâ€²)2
2Ïƒ2t

.
(4.12)
We deï¬ne Î· as the truncation size, and our objective is to use only the observations
made during the last Î· time steps, i.e., from time t âˆ’Î·+1 to time t, to make prediction
at time t. In general, a small Î· yields faster computation but lower accuracy and a large
Î· yields slower computation but higher accuracy. Thus, the truncation size Î· should
be selected according to a trade-off relationship between accuracy and efï¬ciency.
Next, we show an approach to select the truncation size Î· in an averaged perfor-
mance sense. Given the observations and associated sampling locations and times
(denoted by D which depends on Î·), the generalization error Ïµxâˆ—,D at a point
xâˆ—= (sT
âˆ—, tâˆ—)T is deï¬ned as the prediction error variance Ïƒ2
zâˆ—|D [102, 103]. For
a given tâˆ—not knowing user speciï¬c sâˆ—a priori, we seek to ï¬nd Î· that guarantees
a low prediction error variance uniformly over the entire space Q, i.e., we want
ÏµD = Esâˆ—[Ïƒ2
zâˆ—|D] to be small [102, 103]. Here Esâˆ—denotes the expectation with
respect to the uniform distribution of sâˆ—.
According to Mercerâ€™s Theorem, we know that the kernel function Cs can be
decomposed into
Cs(s, sâ€²) =
âˆ

i=1
Î»iÏ†i(s)Ï†i(sâ€²),
where {Î»i} and {Ï†i(Â·)} are the eigenvalues and corresponding eigenfunctions, respec-
tively [103]. In a similar way shown in [103], the input dependent generalization error
ÏµD for our spatio-temporal Gaussian process can be obtained as
ÏµD = Esâˆ—

Ïƒ2
f

1 âˆ’tr

kkT (K + 1/Î³I)âˆ’1
(4.13)
= Ïƒ2
f

1 âˆ’tr

Esâˆ—[kkT ](K + 1/Î³I)âˆ’1
.
We have
Esâˆ—[kkT ] = 2T â—¦ktkT
t ,
(4.14)
and
K = T â—¦KtKT
t ,
(4.15)

36
4
Memory Efï¬cient Prediction With Truncated Observations
where ()i j = Ï† j(si), (kt) j = Ct(t( j), tâˆ—), (Kt)i j = Ct(t(i), t( j)), and ()i j =
Î»iÎ´i j. Î´i j denotes the Dirac delta function. â—¦denotes the Hadamard (element-wise)
product [103]. Hence, the input-dependent generalization error ÏµD can be computed
analytically by plugging (4.14) and (4.15) into (4.13). Notice that ÏµD is a function of
inputs (i.e., the sampling locations and times). To obtain an averaged performance
level without the knowledge of the algorithmic sampling strategy a priori, we use
an appropriate sampling distribution which models the stochastic behavior of the
sampling strategy. Thus, further averaging over the observation set D with the samp-
ing distribution yields Ïµ(Î·) = ED[ÏµD] which is a function of the truncation size
Î· only. This averaging process can be done using Monte Carlo methods. Then Î·
can be chosen based on the averaged performance measure Ïµ(Î·) under the sampling
distribution.
An alternative way, without using the eigenvalues and eigenfunctions, is to directly
and numerically compute ÏµD = Esâˆ—[Ïƒ2
zâˆ—|D] uniformly over the entire space Q with
random sampling positions at each time step. An averaged generalization error with
respect to the temporal truncation size can be plotted by using such Monte Carlo
methods. Then the temporal truncation size Î· can be chosen such that a given level
of the averaged generalization error is achieved.
Example 4.3 Consider a problem of selecting a temporal truncation size Î· for
spatio- temporal Gaussian process regression using observations from 9 agents.
The spatio-temporal Gaussian process is deï¬ned in (4.1) and (4.9) with Ïƒ2
f = 1,
Ïƒ1 = Ïƒ2 = 0.2, Ïƒt = 5, and Î³ = 100 over (0, 1)2. The Monte Carlo simulation
result is shown in Fig.4.3. The achieved generalization error ÏµD are plotted in blue
circles with error-bars with respect to the temporal truncation size Î·. As can be seen,
an averaged generalization error (in blue circles) under 0.1 can be achieved by using
observations taken from last 10 time steps.
Fig. 4.3 Example of
selecting a temporal
truncation size Î·. The
parameters used in the
example are: Ïƒ2
f = 1,
Ïƒ1 = Ïƒ2 = 0.2, Ïƒt = 5,
Î³ = 100
0
5
10
15
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
Î·
ÏµD

4.1 GPR with Truncated Observations
37
Notice that the prediction error variances can be signiï¬cantly minimized by opti-
mally selecting the sampling positions. Hence, the selected Î· guarantees at least
the averaged performance level of the sensor network when the optimal sampling
strategy is used.
By using a ï¬xed truncation size Î·, the computational complexity and memory
space required for making prediction (i.e., evaluating (4.3a) and (4.3b)) do not
increase as more measurements are collected. Our next objective is to improve the
quality of the prediction by carefully selecting the future sampling positions for the
mobile sensor network.
4.2 Optimal Sampling Strategies
At time t, the goal of the mobile sensor network is to make prediction at pre-speciï¬ed
points of interest

p j = (v j, Ï„ j) | j âˆˆJ

indexed by J := {1, . . . , M}. From here
on, points of interest will be referred to as target points. The introduction of target
points is motivated by the fact that the potential environmental concerns should be
frequently monitored. For instance, the target points can be assigned at the interface
of a factory and a lake, sewage systems, or polluted beaches. Thus, the introduction
of target points, which can be arbitrarily speciï¬ed by a user, provides a ï¬‚exible way
to deï¬ne a geometrical shape of a subregion of interest in a surveillance region.
Notice that the target points can be changed by a user at any time. In particular, we
allow that the number of target points M can be larger than that of agents N, which
is often the case in practice. The prediction of z j := z(p j) of the Gaussian process
at a target point p j can be obtained as in (4.3a) and (4.3b).
4.2.1 Centralized Navigation Strategy
Consider the case in which a central station receives collective measurements from
all N mobile sensors and performs the prediction. Let the central station discard the
oldest set of measurements ytâˆ’Î·+1 after making the prediction at time t. At the next
time index t + 1, using the remained observations ytâˆ’Î·+2:t in the memory along
with new measurements yt+1 from all N agents at time t + 1, the central station will
predict z(sâˆ—, tâˆ—) evaluated at target points

p j | j âˆˆJ

. Hence, agents should move
to the most informative locations for taking measurements at time t + 1 [44].
For notational simplicity, let Â¯y âˆˆRN(Î·âˆ’1) be the remaining observations, i.e.,
Â¯y := ytâˆ’Î·+2:t, and Ëœy âˆˆRN be the measurements that will be taken at positions
Ëœq = (ËœqT
1 , . . . , ËœqT
N)T âˆˆQN and time t + 1. In contrast to the information-theoretic
control strategies using the conditional entropy or the mutual information criterion
[44, 72], in this chapter, the mobility of the robotic sensors will be designed such

38
4
Memory Efï¬cient Prediction With Truncated Observations
that they directly minimize the average of the prediction error variances over target
points, i.e.,
Jc(Ëœq) =
1
|J |

jâˆˆJ
Ïƒ2
z j|Â¯y,Ëœy(Ëœq),
(4.16)
where |J | = M is the cardinality of J . The prediction error variance at each of M
target points is given by
Ïƒ2
z j|Â¯y,Ëœy(Ëœq) = Ïƒ2
f

1 âˆ’k j(Ëœq)T C(Ëœq)âˆ’1k j(Ëœq)

,
âˆ€j âˆˆJ ,
where k j(Ëœq) and C(Ëœq) are deï¬ned as
k j(Ëœq) =
Corr(Â¯y, z j)
Corr(Ëœy, z j)

,
C(Ëœq) =
Corr(Â¯y, Â¯y) Corr(Â¯y, Ëœy)
Corr(Ëœy, Â¯y) Corr(Ëœy, Ëœy)

.
In order to reduce the average of prediction error variances over target points

p j | j âˆˆJ

, the central station solves the following optimization problem
q(t + 1) = arg min
ËœqâˆˆQN Jc(Ëœq).
(4.17)
Notice that in this problem set-up, we only consider the constraint that robots should
move within the region Q. However, the mobility constraints such as the maximum
distance a robot can move between two time indices or the maximum speed a robot
can travel, can be incorporated as additional constraints in the optimization problem
[45].
The sensor network conï¬guration q(t) can be controlled by a gradient descent
algorithm such that q(t) can move to a local minimum of Jc for the prediction at
time t + 1. The gradient descent control algorithm is given by
dq(Ï„)
dÏ„
= âˆ’âˆ‡qJc(q(Ï„)),
(4.18)
where âˆ‡x Jc(x) denotes the gradient of Jc(x) at x. A critical point of Jc(q) obtained
in (4.18) will be q(t +1). The analytical form of âˆ‚Ïƒ2
z j|Â¯y,Ëœy(Ëœq)/âˆ‚Ëœqi,â„“, where Ëœqi,â„“is the
â„“th element in Ëœqi âˆˆQ, can be obtained by
âˆ‚Ïƒ2
z j|Â¯y,Ëœy(Ëœq)
âˆ‚Ëœqi,â„“
= kT
j Câˆ’1
 âˆ‚C
âˆ‚Ëœqi,â„“
Câˆ’1k j âˆ’2 âˆ‚k j
âˆ‚Ëœqi,â„“

,
âˆ€i âˆˆI, â„“âˆˆ{1, 2} .
Other more advanced non-linear optimization techniques may be applied to solve
the optimization problem in (4.17) [104].

4.2 Optimal Sampling Strategies
39
The centralized sampling strategy for the mobile sensor network with the cost
function Jc in (4.16) is summarized in Table4.2. Notice that the prediction in the
centralized sampling strategy uses temporally truncated observations. A decentral-
ized version of the centralized sampling strategy in Table4.2 may be developed using
the approach proposed in [105] in which each robot incrementally reï¬nes its decision
while intermittently communicating with the rest of the robots.
4.2.2 Distributed Navigation Strategy
Now, we consider a case in which each agent in the sensor network can only com-
municate with other agents within a limited communication range R. In addition,
no central station exists. In this section, we present a distributed navigation strategy
for mobile agents that uses only local information in order to minimize a collective
network performance cost function.
The communication network of mobile agents can be represented by an undirected
graph. Let G(t) := (I, E(t)) be an undirected communication graph such that an
edge (i, j) âˆˆE(t) if and only if agent i can communicate with agent j at time t. We
deï¬ne the neighborhood of agent i at time t by Ni(t) := { j âˆˆI | (i, j) âˆˆE(t)}. In
particular, we have
Ni(t) =

j âˆˆI |
		qi(t) âˆ’q j(t)
		 < R, j Ì¸= i

.
Note that in our deï¬nition above, â€œ<â€ is used instead of â€œâ‰¤â€ in deciding the com-
munication range.
At time t âˆˆZ>0, agent i collects measurements

y j(t) | j âˆˆ{i} âˆªNi(t)

sampled
at

q j(t) | j âˆˆ{i} âˆªNi(t)

from its neighbors and itself. The collection of these
observations and the associated sampling positions in vector forms are denoted by
y[i]
t
and q[i]
t , respectively. Similarly, for notational simplicity, we also deï¬ne the
cumulative measurements that have been collected by agent i from time t âˆ’Î· + 1
to t as
y[i]
tâˆ’Î·+1:t =

(y[i]
tâˆ’Î·+1)T , . . . , (y[i]
t )T T
.
In contrast to the centralized scheme, in the distributed scheme, each agent deter-
mines the sampling points based on the local information from neighbors. After
making the prediction at time t, agent i discards the oldest set of measurements
y[i]
tâˆ’Î·+1. At time t + 1, using the remained observations y[i]
tâˆ’Î·+2:t in the memory
along with new measurements y[i]
t+1 from its neighbors in Ni(t + 1), agent i will
predict z(sâˆ—, tâˆ—) evaluated at target points

p j | j âˆˆJ

.

40
4
Memory Efï¬cient Prediction With Truncated Observations
Table 4.2 Centralized sampling strategy at time t
Input:
(1) Number of agents N
(2) Positions of agents {qi(t) | i âˆˆI}
(3) Hyperparameters of the Gaussian process Î¸ = (Ïƒ2
f, Ïƒ1, Ïƒ2, Ïƒt)T
(4) Target points

pj | j âˆˆJ

(5) Truncation size Î·
Output:
(1) Prediction at target points

Î¼zj|ytâˆ’Î·+1:t | j âˆˆJ

(2) Prediction error variance at target points

Ïƒ2
zj|ytâˆ’Î·+1:t | j âˆˆJ

For i âˆˆI, agent i performs:
1: make an observation at current position qi(t), i.e., yi(t)
2: transmit the observation yi(t) to the central station
The central station performs:
1: collect the observations from all N agents, i.e., yt = (y1(t), Â· Â· Â· , yN(t))T
2: obtain
the
cumulative
measurements,
i.e.,
ytâˆ’Î·+1:t
=
(yT
tâˆ’Î·+1, Â· Â· Â· , yT
t )T
3: for j âˆˆJ do
4:
make prediction at a target point pj
Î¼zj|ytâˆ’Î·+1:t = kT Câˆ’1y,
with a prediction error variance given by
Ïƒ2
zj|ytâˆ’Î·+1:t = Ïƒ2
f(1 âˆ’kT Câˆ’1k),
where y = ytâˆ’Î·+1:t, k = Corr(y, zj), and C = Corr(y, y)
5: end for
6: if t â‰¥Î· then
7:
discard the oldest set of measurements taken at time t âˆ’Î· + 1, i.e.,
ytâˆ’Î·+1
8: end if
9: compute the control with the remained data ytâˆ’Î·+2:t
q(t + 1) = arg minËœqâˆˆQN Jc(Ëœq),
via
dq(Ï„)
dÏ„
= âˆ’âˆ‡qJc(q(Ï„))
10: send the next sampling positions {qi(t + 1)}N
i=1 (a critical point of Jc(Ëœq))
to all N agents
For i âˆˆI, agent i performs:
1: receive the next sampling position qi(t + 1) from the central station
2: move to qi(t + 1) before time t + 1

4.2 Optimal Sampling Strategies
41
For notational simplicity, let Â¯y[i] be the remaining observations of agent i, i.e.,
Â¯y[i] := y[i]
tâˆ’Î·+2:t. Let Ëœy[i] be the new measurements that will be taken at positions of
agent i and its neighbors Ëœq[i] âˆˆQ|Ni(t+1)|+1, and at time t + 1, where |Ni(t + 1)|
is the number of neighbors of agent i at time t + 1. The prediction error variance
obtained by agent i at each of M target points (indexed by J ) is given by
Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]) = Ïƒ2
f

1 âˆ’k[i]
j (Ëœq[i])T C[i](Ëœq[i])âˆ’1k[i]
j (Ëœq[i])

,
âˆ€j âˆˆJ ,
where k[i]
j (Ëœq[i]) and C[i](Ëœq[i]) are deï¬ned as
k[i]
j (Ëœq[i]) =

Corr(Â¯y[i], z j)
Corr(Ëœy[i], z j)

,
C[i](Ëœq[i]) =

Corr(Â¯y[i], Â¯y[i]) Corr(Â¯y[i], Ëœy[i])
Corr(Ëœy[i], Â¯y[i]) Corr(Ëœy[i], Ëœy[i])

.
(4.19)
The performance of agent i can be evaluated by the average of the prediction error
variances over target points, i.e.,
J [i](Ëœq[i]) =
1
|J |

jâˆˆJ
Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]),
âˆ€i âˆˆI.
One criterion to evaluate the network performance is the average of individual per-
formance, i.e.,
J(Ëœq) = 1
|I|

iâˆˆI
J [i](Ëœq[i]).
(4.20)
However, the discontinuity of the function J occurs at the moment of gaining or
losing neighbors, e.g., at the set
Ëœq |
		Ëœqi âˆ’Ëœq j
		 = R

.
A gradient decent algorithm for mobile robots that minimizes such J may produce
hybrid system dynamics and/or chattering behaviors when robots lose or gain neigh-
bors.
Therefore, we seek to minimize an upper-bound of J that is continuously differ-
entiable. Consider the following function
Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]) = Ïƒ2
f

1 âˆ’k[i]
j (Ëœq[i])T Â¯C
[i](Ëœq[i])âˆ’1k[i]
j (Ëœq[i])

,
âˆ€j âˆˆJ ,
(4.21)

42
4
Memory Efï¬cient Prediction With Truncated Observations
Fig. 4.4 Function Î¦(d) in
(4.22) with Î³ = 100,
R = 0.4, and d0 = 0.1 is
shown in a red dotted line.
The function Î¦(d) = Î³ is
shown in a blue solid line
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
d
Î¦(d)
where Â¯C
[i](Ëœq[i]) is deï¬ned as
Â¯C
[i](Ëœq[i]) =

Corr(Â¯y[i], Â¯y[i])
Corr(Â¯y[i], Ëœy[i])
Corr(Ëœy[i], Â¯y[i]) Corr(Ëœy[i], Ëœy[i]) + ËœC
[i](Ëœq[i])

.
Notice that Â¯C
[i](Ëœq[i]) is obtained by adding a positive semi-deï¬nite matrix ËœC
[i](Ëœq[i])
to the lower right block of C[i](Ëœq[i]) in (4.19), where
ËœC
[i](Ëœq[i]) = diag

Î¦(di1)âˆ’1, . . . , Î¦(di(|Ni(t+1)|+1))âˆ’1
âˆ’1
Î³ I,
where di j :=
		Ëœqi âˆ’Ëœq j
		 is the distance between agent i and agent j, âˆ€j âˆˆ{i} âˆª
Ni(t + 1). Î¦ : [0, R) â†’(0, Î³] is a continuously differentiable function deï¬ned as
Î¦(d) = Î³Ï†
d + d0 âˆ’R
d0

,
(4.22)
where
Ï†(h) =
 1,
h â‰¤0,
exp

âˆ’h2
1âˆ’h2

, 0 < h < 1.
An example of Î¦(d) where Î³ = 100, R = 0.4, and d0 = 0.1 is shown in the red
dotted line in Fig.4.4. Notice that if Î¦(d) = Î³ is used (the blue solid line in Fig.4.4),
we have Â¯C
[i](Ëœq[i]) = C[i](Ëœq[i]). We then have the following result.
Proposition 4.2 Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]) is an upper-bound of Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]), âˆ€i âˆˆI.

4.2 Optimal Sampling Strategies
43
Proof Let A := C[i](Ëœq[i]) and B := diag(0, ËœC
[i](Ëœq[i])). The result follows immedi-
ately from the fact that (A + B)âˆ’1 âª¯Aâˆ’1 for any A â‰»0 and B âª°0.
â–¡
Hence, we construct a new cost function as
Jd(Ëœq) = 1
|I|

iâˆˆI
1
|J |

jâˆˆJ
Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]).
(4.23)
By Proposition4.2, Jd in (4.23) is an upper-bound of J in (4.20).
Next, we show that Jd is continuously differentiable when agents gain or lose
neighbors. In doing so, we compute the partial derivative of Jd with respect to Ëœqi,â„“,
where Ëœqi,â„“is the â„“th element in Ëœqi âˆˆQ, as follows.
âˆ‚Jd(Ëœq)
âˆ‚Ëœqi,â„“
= 1
|I|

kâˆˆI
1
|J |

jâˆˆJ
âˆ‚Â¯Ïƒ2
z j|Â¯y[k],Ëœy[k](Ëœq[k])
âˆ‚Ëœqi,â„“
= 1
|I|

kâˆˆ{i}âˆªNi
1
|J |

jâˆˆJ
âˆ‚Â¯Ïƒ2
z j|Â¯y[k],Ëœy[k](Ëœq[k])
âˆ‚Ëœqi,â„“
,
âˆ€i âˆˆI, â„“âˆˆ{1, 2} .
(4.24)
We then have the following.
Proposition 4.3 The cost function Jd in (4.23) is of class C1, i.e., it is continuously
differentiable.
Proof We need to show that the partial derivatives of Jd with respect to Ëœqi,â„“, âˆ€i âˆˆ
I, â„“âˆˆ{1, 2} exist and are continuous. Without loss of generality, we show that
âˆ‚Jd/âˆ‚Ëœqi,â„“, âˆ€â„“âˆˆ{1, 2} is continuous at any point Ëœqâˆ—in the following boundary set
deï¬ned by
Sik :=
Ëœq | dik =
		Ëœqi âˆ’Ëœqk
		 = R

.
First, we consider a case in which Ëœq /âˆˆSik and dik < R, i.e., k âˆˆNi and i âˆˆNk. By
the construction of Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i] in (4.21) using (4.22), when we take the limit of the
partial derivative, as dik approaches R from below (as Ëœq approaches Ëœqâˆ—), we have
that
lim
dikâ†’Râˆ’
âˆ‚Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i])
âˆ‚Ëœqi,â„“
=
âˆ‚Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i]\Ëœqk)
âˆ‚Ëœqi,â„“
,
lim
dikâ†’Râˆ’
âˆ‚Â¯Ïƒ2
z j|Â¯y[k],Ëœy[k](Ëœq[k])
âˆ‚Ëœqi,â„“
=
âˆ‚Â¯Ïƒ2
z j|Â¯y[k],Ëœy[k](Ëœq[k]\Ëœqi)
âˆ‚Ëœqi,â„“
= 0,

44
4
Memory Efï¬cient Prediction With Truncated Observations
Table 4.3 Distributed sampling strategy at time t
Input:
(1) Number of agents N
(2) Positions of agents {qi(t) | i âˆˆI}
(3) Hyperparameters of the Gaussian process Î¸ = (Ïƒ2
f, Ïƒ1, Ïƒ2, Ïƒt)T
(4) Target points

pj | j âˆˆJ

(5) Truncation size Î·
Output:
(1) Prediction at target points

Î¼zj|y[i]
tâˆ’Î·+1:t | i âˆˆI, j âˆˆJ

(2) Prediction error variances at target points

Ïƒ2
zj|y[i]
tâˆ’Î·+1:t | i âˆˆI, j âˆˆJ

For i âˆˆI, agent i performs:
1: make an observation at qi(t), i.e., yi(t)
2: transmit the observation to the neighbors in Ni(t)
3: collect the observations from neighbors in Ni(t), i.e., y[i](t)
4: obtain
the
cumulative
measurements,
i.e.,
y[i]
tâˆ’Î·+1:t
=

(y[i]
tâˆ’Î·+1)T , Â· Â· Â· , (y[i]
t )T 	T
5: for j âˆˆJ do
6:
make prediction at a target point pj
Î¼zj|y[i]
tâˆ’Î·+1:t = kT Câˆ’1y,
with a prediction error variance given by
Ïƒ2
zj|y[i]
tâˆ’Î·+1:t = Ïƒ2
f(1 âˆ’kT Câˆ’1k),
where y = y[i]
tâˆ’Î·+1:t, k = Corr(y, zj), and C = Corr(y, y)
7: end for
8: if t â‰¥Î· then
9:
discard the oldest set of measurements taken at time t âˆ’Î· + 1, i.e.,
y[i]
tâˆ’Î·+1
10: end if
11: while t â‰¤Ï„ â‰¤t + 1 do
12:
compute âˆ‡qâ„“J[i] with the remained data y[i]
tâˆ’Î·+2
13:
send âˆ‡qâ„“J[i] to agent â„“in Ni(Ï„)
14:
receive âˆ‡qiJ[â„“] from all neighbors in Ni(Ï„)
15:
compute the gradient âˆ‡qiJd = 
â„“âˆˆNi(Ï„) âˆ‡qiJ[â„“]/|I|
16:
update position according to qi(Ï„ + Î´t) = qi(Ï„) âˆ’Î±âˆ‡qiJd for a small
step size Î±
17: end while

4.2 Optimal Sampling Strategies
45
where Ëœq[a]\Ëœqb denotes the collection of locations of agent a and its neighbors exclud-
ing Ëœqb. Hence we have
lim
dikâ†’Râˆ’
âˆ‚Jd(Ëœq)
âˆ‚Ëœqi,â„“
= âˆ‚Jd(Ëœqâˆ—)
âˆ‚Ëœqi,â„“
.
(4.25)
Consider the other case in which Ëœq /âˆˆSik and dik > R, i.e., k /âˆˆNi and i /âˆˆNk.
When dik approaches R from above (as Ëœq approaches Ëœqâˆ—), we have
lim
dikâ†’R+
âˆ‚Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i])
âˆ‚Ëœqi,â„“
=
âˆ‚Â¯Ïƒ2
z j|Â¯y[i],Ëœy[i](Ëœq[i])
âˆ‚Ëœqi,â„“
,
and hence
lim
dikâ†’R+
âˆ‚Jd(Ëœq)
âˆ‚Ëœqi,â„“
= âˆ‚Jd(Ëœqâˆ—)
âˆ‚Ëœqi,â„“
.
(4.26)
Therefore, from (4.25) and (4.26), we have
lim
dikâ†’Râˆ’
âˆ‚Jd(Ëœq)
âˆ‚Ëœqi,â„“
=
lim
dikâ†’R+
âˆ‚Jd(Ëœq)
âˆ‚Ëœqi,â„“
= âˆ‚Jd(Ëœqâˆ—)
âˆ‚Ëœqi,â„“
.
This completes the proof due to Theorem4.6 in [106].
â–¡
By using Jd in (4.23), a gradient descent algorithm can be used to minimize the
network performance cost function Jd in (4.23) for the prediction at t + 1.
dq(Ï„)
dÏ„
= âˆ’âˆ‡qJd(q(Ï„)).
(4.27)
Note that the partial derivative in (4.24), which builds the gradient ï¬‚ow in (4.27), is a
function of positions in âˆªjâˆˆNi(t)N j(t) only. This makes the algorithm distributed. A
distributed sampling strategy for agent i with the network cost function Jd in (4.23)
is summarized in Table4.3. In this way, each agent with the distributed sampling
strategy uses spatially and temporally truncated observations.
4.3 Simulation
In this section, we apply our approach to a spatio-temporal Gaussian process with
a covariance function in (4.12). The Gaussian process was numerically generated
through circulant embedding of the covariance matrix for the simulation [107]. The
hyperparameters used in the simulation were chosen to be Î¸ = (Ïƒ2
f , Ïƒ1, Ïƒ2, Ïƒt)T =
(1, 0.2, 0.2, 5)T . The surveillance region Q is given by Q
=
(0, 1)2. The

46
4
Memory Efï¬cient Prediction With Truncated Observations
signal-to-noise ratio Î³ = 100 is used throughout the simulation which is equiva-
lent to a noise level of Ïƒw = 0.1. In our simulation, N = 9 agents sample at time
t âˆˆZ>0. The initial positions of the agents are randomly selected. The truncation
size Î· = 10 is chosen using the approach introduced in Sect.4.1.2 that guarantees the
averaged performance level Ïµ(Î· = 10) < 0.1 under a uniform sampling distribution
(see Example4.3).
In the ï¬gures of simulation results, the target positions, the initial positions of
agents, the past sampling positions of agents, and the current positions of agents are
represented by white stars, yellow crosses, pink dots, and white circles with agent
indices, respectively.
4.3.1 Centralized Sampling Scheme
Consider a situation where a central station has access to all measurements collected
by agents. At each time, measurements sampled by agents are transmitted to the cen-
tral station that uses the centralized navigation strategy and sends control commands
back to individual agents.
Case 1: First, we consider a set of ï¬xed target points, e.g., 6 Ã— 6 grid points on
Q at a ï¬xed time t = 10. At each time step, the cost function Jc in (4.16), which
is the average of prediction error variances at target points, is minimized due to the
proposed centralized navigation strategy in Sect.4.2.1. As a benchmark strategy, we
consider a random sampling scheme in which a group of 9 agents takes observations
at randomly selected positions within the surveillance region Q.
In Fig.4.5a, the blue circles represent the average of prediction error variances
over target points achieved by the centralized scheme, and the red squares indicate the
2
4
6
8
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
t
Prediction error variance
2
4
6
8 10 12 14 16 18 20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
t
Prediction error variance
2
4
6
8 10 12 14 16 18 20
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
t
Prediction error variance
(a)
(b)
(c)
Fig. 4.5 Average of prediction error variances over target points (in blue circles) achieved by the
centralized sampling scheme using all collective observations for a Case 1, b Case 2, and c Case
3. In (a), the target points are ï¬xed at time t = 10, and the counterpart achieved by the benchmark
random sampling strategy is shown in red squares with error-bars. In (b) and (c), the target points
are at t + 1 and change over time. The counterpart achieved by using truncated observations are
shown in red squares

4.3 Simulation
47
(a)
(b)
(c)
(d)
(d)
(f)
Fig. 4.6 Simulation results at t = 1 and t = 5 obtained by the centralized sampling scheme for
Case 2. a True ï¬eld at t = 1. b True ï¬eld at t = 5. c Predicted ï¬eld at t = 1. d Predicted ï¬eld at
t = 5. e Prediction error variance at t = 1. f Prediction error variance at t = 5.

48
4
Memory Efï¬cient Prediction With Truncated Observations
average of prediction error variances over target points achieved by the benchmark
strategy. Clearly, the proposed scheme produces lower averaged prediction error
variances at target points as time increases, which demonstrates the usefulness of
our scheme.
Case 2: Next, we consider the same 6Ã—6 grid points on Q as in Case 1. However,
at time t, we are now interested in the prediction at the next sampling time t + 1. At
each time step, the cost function Jc is minimized. Figure4.5b shows the average of
prediction error variances over target points achieved by the centralized scheme with
truncation (in red squares) and without truncation (in blue circles). With truncated
observations, i.e., with only observations obtained from latest Î· = 10 time steps, we
are able to maintain the same level of the averaged prediction error variances (around
0.05 in Fig.4.5b).
Figure4.6a, c and e show the true ï¬eld, the predicted ï¬eld, and the prediction error
variance at time t = 1, respectively. To see the improvement, the counterpart of the
simulation results at time t = 5 are shown in Fig.4.6b, d and f. At time t = 1, agents
have little information about the ï¬eld and hence the prediction is far away from
the true ï¬eld, which produces a large prediction error variance. As time increases,
the prediction becomes close to the true ï¬eld and the prediction error variances are
reduced due to the proposed navigation strategy.
Case 3: Now, we consider another case in which 36 target points (plotted in
Fig.4.7 as white stars) are evenly distributed on three concentric circles to form a
ring shaped subregion of interest. As in Case 2, we are interested in the prediction
at the next time iteration t + 1. The average of prediction error variances over these
target points at each time step achieved by the centralized scheme with truncation
(in red squares) and without truncation (in blue circles) are shown in Fig.4.5c. The
prediction error variances at time t = 1 and t = 5 are shown in Fig.4.7a and b,
respectively. It is shown that agents are dynamically covering the ring shaped region
to minimize the average of prediction error variances over the target points.
4.3.2 Distributed Sampling Scheme
Consider a situation in which the sensor network has a limited communication range
R, i.e., Ni(t) :=

j âˆˆI |
		qi(t) âˆ’q j(t)
		 < R, j Ì¸= i

. At each time t âˆˆZ>0,
agent i collects measurements from itself and its neighbors Ni(t) and makes pre-
diction in a distributed fashion. The distributed strategy is used to navigate itself to
move to the next sampling position. To be comparable with the centralized scheme,
the same target points as in Case 2 of Sect.4.3.1 are considered.

4.3 Simulation
49
(a)
(b)
Fig. 4.7 Simulation results obtained by the centralized sampling scheme for Case 3. The trajectories
of agents are shown in solid lines a Prediction error variance at t = 1. b Prediction error variance
at t = 5
Figure4.8 shows that the cost function, which is an upper-bound of the averaged
prediction error variance over target points and agents, deceases smoothly from time
t = 1 to t = 2 by the gradient descent algorithm with a communication range
R = 0.4. Signiï¬cant decreases occur whenever one of the agent gains a neighbor.
Notice that the discontinuity of minimizing J in (4.20) caused by gaining or losing
neighbors is eliminated due to the construction of Jd in (4.23). Hence, the proposed
distributed algorithm is robust to gaining or losing neighbors.
200
400
600
800
1000
1200
0.65
0.7
0.75
0.8
0.85
Number of iterations
Cost function
Fig. 4.8 Cost function Jd(Ëœq) from t = 1 to t = 2 with a communication range R = 0.4

50
4
Memory Efï¬cient Prediction With Truncated Observations
2
4
6
8 10 12 14 16 18 20
0
0.2
0.4
0.6
0.8
1
t
Prediction error variance
(a)
2
4
6
8 10 12 14 16 18 20
0
0.2
0.4
0.6
0.8
1
t
Prediction error variance
(b)
Fig. 4.9 Average of prediction error variances over all target points and agents achieved by
the distributed sampling scheme with a communication range a R = 0.3, and b R = 0.4. The
average of prediction error variances over all target points and agents are shown in blue circles.
The average of prediction error variance over local target points and agents are shown in red squares.
The error-bars indicate the standard deviation among agents
The following study shows the effect of different communication range. Intu-
itively, the larger the communication range is, the more information can be obtained
by the agent and hence the better prediction can be made. Figures4.9a and b show
the average of prediction error variances over all target points and agents in blue
circles with error-bars indicating the standard deviation among agents for the case
R = 0.3 and R = 0.4, respectively. In both cases, d0 = 0.1 in (4.22) was used. The
average of prediction error variances is minimized quickly to a certain level. It can
be seen that the level of achieved averaged prediction error variance with R = 0.4
is lower than the counterpart with R = 0.3.
Now, assume that each agent only predict the ï¬eld at target points within radius
R (local target points). The average of prediction error variances, over only local
target points and agents, are also plotted in Fig.4.9 in red squares with the standard
deviation among agents. As can be seen, the prediction error variances at local target
points (the red squares) are signiï¬cantly lower than those for all target points (the
blue circles).
Figure4.10 shows the prediction error variances obtained by agent 1 along with
the edges of the communication network for different communication range R and
different time step t. In Fig.4.10, the target positions, the initial positions, and the
current positions are represented by white stars, yellow crosses, and white circles,
respectively. Surprisingly, the agents under the distributed navigation algorithm pro-
duce an emergent, swarm-like behavior to maintain communication connectivity

4.3 Simulation
51
(a)
(b)
(c)
(d)
Fig. 4.10 Simulation results obtained by the distributed sampling scheme with different commu-
nication ranges. The edges of the graph are shown in solid lines. a R = 0 : 3, t = 1. b R = 0 : 3,
t = 2. c R = 0 : 3, t = 5. d R = 0 : 3, t = 20. e R = 0 : 4, t = 1. f R = 0 : 4, t = 2. g R = 0 : 4,
t = 5. h R = 0 : 4, t = 20
among local neighbors. Notice that this collective behavior emerged naturally and
was not generated by the ï¬‚ocking or swarming algorithm as in [42].
This interesting simulation study (Fig.4.10) shows that agents wonâ€™t get too close
each other since the average of prediction error variances at target points can be
reduced by spreading over and covering the target points that need to be sampled.
However, agents wonâ€™t move too far away each other since the average of prediction
error variances can be reduced by collecting measurements from a larger population
of neighbors. This trade-off is controlled by the communication range. With the

52
4
Memory Efï¬cient Prediction With Truncated Observations
(e)
(f)
(g)
(h)
Fig. 4.10 (continued)
intertwined dynamics of agents over the proximity graph, as shown in Fig.4.10,
mobile sensing agents are coordinated in each time iteration in order to dynamically
cover the target positions for better collective prediction capability.

Chapter 5
Fully Bayesian Approach
In Chap.4, we analyzed the conditions under which near-optimal prediction can
be achieved using only truncated observations. This motivates the usage of sparse
Gaussian process proposed in [108]. However, they both assumed the covariance
function is known a priori. In this chapter, we relax this stringent assumption.
Unknown parameters in the covariance function can be estimated by a point esti-
mator based on maximum likelihood (ML) or maximum a posterior (MAP). Such
ML or MAP estimates may be regarded as the true parameters and then used in the
prediction as in Chap.3. However, the point estimate itself needs to be identiï¬ed
using sufï¬cient amount of measurements and most importantly, the whole procedure
fails to incorporate the uncertainty in the point estimate into the prediction.
Motivated by the aforementioned issues, a fully Bayesian framework is adopted in
this chapter as it offers several advantages when inferring parameters and processes
from highly complex models. The Bayesian approach requires prior distributions to
be elicited for model parameters that are of interest. Although difï¬cult initially, this
forces the practitioner to reï¬‚ect on all sources and extent of uncertainties from sci-
entiï¬c knowledge and past experience. In highly complex models, this pre-analysis
of uncertainties eventually yields better inference for the parameters of interest, and
even more so when data contains limited information. Once the priors are elicited,
the Bayesian framework is ï¬‚exible and effective in incorporating all uncertainties
as well as information (limited or otherwise from data) into a single entity, namely,
the posterior. There is, thus, no need to pre-process or account for each source of
uncertainty separately. The Bayesian framework seamlessly describes their joint
inï¬‚uence and contributions through the posterior distributionâ€”which is also, con-
veniently, the only entity to focus on for inference. The fully Bayesian approach
further advocates priors for all unknown entities in the model; these entities can
either be nuisance parameters (such as the scale of measurement error from each
mobile sensor) or (hyper) parameters that govern the prior distributions (such as the
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_5
53

54
5
Fully Bayesian Approach
extent of spatial variability of the scalar ï¬eld). The fully Bayesian approach thus
allows additional sources and extent of uncertainties to be integrated into the infer-
ential framework, with the posterior distribution effectively capturing all aspects of
uncertainties involved. Subsequently, the practitioner needs only to focus on differ-
ent components of the posterior to obtain inference separately for the parameters
of interest, nuisance parameters and hyperparameters. The fully Bayesian approach
also allows data to select the most appropriate values for nuisance parameters and
hyperparameters automatically, and achieve optimal inference and prediction for the
scalar ï¬eld.
The advantage of a fully Bayesian approach, which will be adopted in this chapter,
is that the uncertainty in the model parameters are incorporated in the prediction [84].
In [85], Gaudard et al. presented a Bayesian method that uses importance sampling
for analyzing spatial data sampled from a Gaussian random ï¬eld whose covariance
function was unknown. However, the assumptions made in [85], such as noiseless
observations and time-invariance of the ï¬eld, limit the applicability of the approach
on mobile sensors in practice. The computational complexity of a fully Bayesian pre-
diction algorithm has been the main hurdle for applications in resource-constrained
robots. In [46], an iterative prediction algorithm without resorting to Markov Chain
Monte Carlo (MCMC) methods has been developed based on analytical closed form
solutions from results in [85], by assuming that the covariance function of the spa-
tiotemporal Gaussian random ï¬eld is known up to a constant. Our work builds on
such Bayesian approaches used in [46, 85] and explores new ways to synthesize
practical algorithms for mobile sensor networks under more relaxed conditions.
In Sect.5.1, we provide fully Bayesian approaches for spatiotemporal Gaussian
process regression under more practical conditions such as measurement noise and
the unknown covariance function. In Sect.5.2, using discrete prior probabilities and
compactly supported kernels, we provide a way to design sequential Bayesian pre-
diction algorithms in which the exact predictive distributions can be computed in
constant time (i.e., O(1)) as the number of observations increases. In particular, a
centralized sequential Bayesian prediction algorithm is developed in Sect.5.2.1, and
its distributed implementation among sensor groups is provided for a special case in
Sect.5.2.2. An adaptive sampling strategy for mobile sensors, utilizing the maximum
a posteriori (MAP) estimation of the parameters, is proposed to minimize the pre-
diction error variances in Sect.5.2.3. In Sect.5.3, the proposed sequential Bayesian
prediction algorithms and the adaptive sampling strategy are tested under practical
conditions for spatiotemporal Gaussian processes.
5.1 Fully Bayesian Prediction Approach
In this chapter, we consider a spatiotemporal Gaussian process denoted by
z(x) âˆ¼GP

Î¼(x), Ïƒ2
f C(x, xâ€²; Î¸)

,

5.1 Fully Bayesian Prediction Approach
55
where z(x) âˆˆR and x := (sT , t)T âˆˆQ Ã— Z>0 contains the sampling location
s âˆˆQ âŠ‚R2 and the sampling time t âˆˆZ>0. The mean function is assumed to be
Î¼(x) = f (x)T Î²,
where f (x) := ( f1(x), . . . , f p(x))T âˆˆRp is a known regression function, and
Î² âˆˆRp is an unknown vector of regression coefï¬cients. The correlation between
z(x) and z(xâ€²) is taken as
C(x, xâ€²; Î¸) = Cs
s âˆ’sâ€²
Ïƒs

Ct
t âˆ’tâ€²
Ïƒt

,
(5.1)
which is governed by spatial and temporal distance functions Cs(Â·) and Ct(Â·). We
assume that Cs(Â·) and Ct(Â·) are decreasing kernel functions over space and time,
respectively, so that the correlation between two inputs decreases as the distance
between spatial locations (respectively, time indices) increases. The decreasing rate
depends on the spatial bandwidth Ïƒs (respectively, the time bandwidth Ïƒt) for given
ï¬xed time indices (respectively, spatial locations). The signal variance Ïƒ2
f gives the
overall vertical scale relative to the mean of the Gaussian process in the output space.
We deï¬ne Î¸ := (Ïƒs, Ïƒt)T âˆˆR2 for notational simplicity.
Given the collection of noise-corrupted observations from mobile sensing agents
up to time t, we want to predict z(sâˆ—, tâˆ—) at a prespeciï¬ed location sâˆ—âˆˆS âŠ‚Q and
current (or future) time tâˆ—. To do this, suppose we have a collection of n observations
D =

(x(i), y(i)) | i = 1, . . . , n
	
from N mobile sensing agents up to time t. Here
x(i) denotes the ith input vector of dimension 3 (i.e., the sampling position and time
of the ith observation) and y(i) denotes the ith noise-corrupted measurement. If all
observations are considered, we have n = Nt. Notice that the number of observations
n grows with the time t. For notational simplicity, let y := (y(1), . . . , y(n))T âˆˆRn
denote the collection of noise-corrupted observations. Based on the spatiotemporal
Gaussian process, the distribution of the observations given the parameters Î², Ïƒ2
f ,
and Î¸ is Gaussian, i.e.,
y|Î², Ïƒ2
f , Î¸ âˆ¼N(FÎ², Ïƒ2
f C)
with F and C deï¬ned as
F :=

f (x(1)), . . . , f (x(n))
T
âˆˆRnÃ—p,
C := Corr(y, y|Î¸) =

C(x(i), x( j); Î¸) + 1
Î³ Î´i j

âˆˆRnÃ—n,
(5.2)
where Î´i j is the Kronecker delta which equals to one when i = j, and zero otherwise.

56
5
Fully Bayesian Approach
5.1.1 Prior Selection
ToinfertheunknownparametersÎ²,Ïƒ2
f ,andÎ¸ inaBayesianframework,thecollection
of them is considered to be a random vector with a prior distribution reï¬‚ecting the
a priori belief of uncertainty for them. In this chapter, we use the prior distribution
given by
Ï€(Î², Ïƒ2
f , Î¸) = Ï€(Î²|Ïƒ2
f )Ï€(Ïƒ2
f )Ï€(Î¸),
(5.3)
where
Î²|Ïƒ2
f âˆ¼N(Î²0, Ïƒ2
f T).
The prior for Ï€(Ïƒ2
f ) is taken to be the inverse gamma distribution, chosen to guarantee
positiveness of Ïƒ2
f and a closed-form expression for the posterior distribution of Ïƒ2
f
for computational ease of the proposed algorithms. To cope with the case where no
prior knowledge on Î² is available, which is often the case in practice, we propose to
use a noninformative prior. In particular, we take Î²0 = 0, T = Î±I, and subsequently,
let Î± â†’âˆ. Any proper prior Ï€(Î¸) that correctly reï¬‚ects the priori knowledge of Î¸
can be used.
5.1.2 MCMC-Based Approach
According to the Bayes rule, the posterior distribution of Î², Ïƒ2
f , and Î¸ is given by
Ï€(Î², Ïƒ2
f , Î¸|y) =
Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f , Î¸)

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f , Î¸)dÎ²dÏƒ2
f dÎ¸ .
(5.4)
When a proper prior is used, the posterior distribution can be written as
Ï€(Î², Ïƒ2
f , Î¸|y) âˆÏ€(y|Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f , Î¸).
The inference on Î², Ïƒ2
f , and Î¸ can be carried out by sampling from the posterior
distribution in (5.4) via the Gibbs sampler. Table5.1 gives the steps based on the
following proposition.
Proposition 5.1 For a prior distribution given in (5.3) with the noninformative prior
on Î², the conditional posteriors are given by
1. Î²|Ïƒ2
f , Î¸, y âˆ¼N

Ë†Î², Ïƒ2
f  Ë†Î²

, where
 Ë†Î² = (FT Câˆ’1F)âˆ’1,
Ë†Î² =  Ë†Î²(FT Câˆ’1y).

5.1 Fully Bayesian Prediction Approach
57
Table 5.1 Gibbs sampler
Input: initial samples Î²(1), Ïƒ2
f
(1), and Î¸(1)
Output: samples

Î²(i), Ïƒ2
f
(i), Î¸(i)m
i=1 from joint distribution Ï€(Î², Ïƒ2
f, Î¸|y)
1: initialize Î²(1), Ïƒ2
f
(1), Î¸(1)
2: for i = 1 to m do
3:
sample Î²(i+1) from Ï€(Î²|Ïƒ2
f
(i), Î¸(i), y)
4:
sample Ïƒ2
f
(i+1) from Ï€(Ïƒ2
f|Î²(i+1), Î¸(i), y)
5:
sample Î¸(i+1) from Ï€(Î¸|Î²(i+1), Ïƒ2
f
(i+1), y)
6: end for
2. Ïƒ2
f |Î², Î¸, y âˆ¼IG

Â¯a, Â¯b

, where
Â¯a = a + n + p
2
,
Â¯b = b + 1
2(y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²).
3.
Ï€(Î¸|Î², Ïƒ2
f , y) âˆdet(C)âˆ’1/2 exp

âˆ’(y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²)
2Ïƒ2
f

Ï€(Î¸).
Proof Since the noninformative prior is chosen, the posterior distribution shall be
computed with T = Î±I and then let Î± â†’âˆ.
(i) For given Ïƒ2
f , Î¸, and y, we have
Ï€(Î²|Ïƒ2
f , Î¸, y) = lim
Î±â†’âˆ
Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )dÎ² .
Let
num1 = Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )
=
exp

âˆ’1
2Ïƒ2
f (y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²)

(2Ï€Ïƒ2
f )n/2 det(C)1/2
exp

âˆ’1
2Ïƒ2
f Î²T Tâˆ’1Î²

(2Ï€Ïƒ2
f )p/2 det(T)1/2
=
exp

âˆ’1
2Ïƒ2
f RSS

(2Ï€Ïƒ2
f )(n+p)/2 det(C)1/2 det(T)1/2
Ã— exp

âˆ’1
2Ïƒ2
f
(Î² âˆ’Ë†Î²)T (FT Câˆ’1F + Tâˆ’1)(Î² âˆ’Ë†Î²)

,

58
5
Fully Bayesian Approach
and
den1 =
exp

âˆ’1
2Ïƒ2
f RSS

(2Ï€Ïƒ2
f )(n+p)/2 det(C)1/2 det(T)1/2
Ã—

exp

âˆ’1
2Ïƒ2
f
(Î² âˆ’Ë†Î²)T (FT Câˆ’1F + Tâˆ’1)(Î² âˆ’Ë†Î²)

dÎ²
=
exp

âˆ’1
2Ïƒ2
f RSS

(2Ï€Ïƒ2
f )(n+p)/2 det(C)1/2 det(T)1/2 (2Ï€Ïƒ2
f )p/2 det(FT Câˆ’1F + Tâˆ’1)âˆ’1/2
where
RSS = yT 
Câˆ’1 âˆ’Câˆ’1F(FT Câˆ’1F + Tâˆ’1)âˆ’1FT Câˆ’1
y
= yT (C + FTFT )âˆ’1y.
Then we have
Ï€(Î²|Ïƒ2
f , Î¸, y) = lim
Î±â†’âˆ
num1
den1
= lim
Î±â†’âˆ
exp

âˆ’1
2Ïƒ2
f (Î² âˆ’Ë†Î²)T (FT Câˆ’1F + Tâˆ’1)(Î² âˆ’Ë†Î²)

(2Ï€Ïƒ2
f )p/2 det(FT Câˆ’1F + Tâˆ’1)âˆ’1/2
=
exp

âˆ’1
2Ïƒ2
f (Î² âˆ’Ë†Î²)T âˆ’1
Ë†Î² (Î² âˆ’Ë†Î²)

(2Ï€Ïƒ2
f )p/2 det( Ë†Î²)1/2
.
Therefore, we have Î²|Ïƒ2
f , Î¸, y âˆ¼N( Ë†Î², Ïƒ2
f  Ë†Î²).
(ii) For given Î², Î¸, and y, we have
Ï€(Ïƒ2
f |Î², Î¸, y) = lim
Î±â†’âˆ
Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Ïƒ2
f |Î²)

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Ïƒ2
f |Î²)dÏƒ2
f
= lim
Î±â†’âˆ
Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )Ï€(Ïƒ2
f )

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )Ï€(Ïƒ2
f )dÏƒ2
f
.

5.1 Fully Bayesian Prediction Approach
59
Let
num2 = Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )Ï€(Ïƒ2
f )
=
exp

âˆ’1
2Ïƒ2
f (y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²)

(2Ï€Ïƒ2
f )n/2 det(C)1/2
Ã—
exp

âˆ’1
2Ïƒ2
f Î²T Tâˆ’1Î²

(2Ï€Ïƒ2
f )p/2 det(T)1/2
ba exp

âˆ’b
Ïƒ2
f

Î“ (a)(Ïƒ2
f )a+1
=
ba
Î“ (a)(2Ï€)Â¯a+1 det(C)1/2 det(T)1/2
1
(Ïƒ2
f )Â¯a+1 exp

âˆ’
Â¯b + 1
2Î²T Tâˆ’1Î²
Ïƒ2
f

,
and
den2 =
ba
Î“ (a)(2Ï€)Â¯a+1 det(C)1/2 det(T)1/2
Ã—

1
(Ïƒ2
f )Â¯a+1 exp

âˆ’
Â¯b + 1
2Î²T Tâˆ’1Î²
Ïƒ2
f

dÏƒ2
f
=
ba
Î“ (a)(2Ï€)Â¯a+1 det(C)1/2 det(T)1/2 Î“ (Â¯a)Â¯bâˆ’Â¯a.
Then we have
Ï€(Ïƒ2
f |Î², Î¸, y) = lim
Î±â†’âˆ
num2
den2
= lim
Î±â†’âˆ
Â¯bÂ¯a
Î“ (Â¯a)(Ïƒ2
f )Â¯a+1 exp

âˆ’
Â¯b + 1
2Î²T Tâˆ’1Î²
2Ïƒ2
f

=
Â¯bÂ¯a
Î“ (Â¯a)(Ïƒ2
f )Â¯a+1 exp

âˆ’
Â¯b
2Ïƒ2
f

.
Therefore, we have Ïƒ2
f |Î², Î¸, y âˆ¼IG

Â¯a, Â¯b

.
(iii) For given Î², Ïƒ2
f , and y, we have
Ï€(Î¸|Î², Ïƒ2
f , y) = lim
Î±â†’âˆ
Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î¸)

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î¸)dÎ¸
âˆdet(C)âˆ’1/2 exp

âˆ’(y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²)
2Ïƒ2
f

Ï€(Î¸).

60
5
Fully Bayesian Approach
The posterior predictive distribution of zâˆ—:= z(sâˆ—, tâˆ—) at location sâˆ—and time tâˆ—
can be obtained by
Ï€(zâˆ—|y) =

Ï€(zâˆ—|y, Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f , Î¸|y)dÎ²dÏƒ2
f dÎ¸,
(5.5)
where in (5.5), the conditional distribution Ï€(zâˆ—|Î², Ïƒ2
f , Î¸, y), is integrated with
respect to the posterior of Î², Ïƒ2
f , and Î¸ given observations y. The conditional distri-
bution of zâˆ—is Gaussian, i.e.,
zâˆ—|Î², Ïƒ2
f , Î¸, y âˆ¼N(Î¼zâˆ—|Î²,Ïƒ2
f ,Î¸,y, Ïƒ2
zâˆ—|Î²,Ïƒ2
f ,Î¸,y),
with
Î¼zâˆ—|Î²,Ïƒ2
f ,Î¸,y = E(zâˆ—|Î², Ïƒ2
f , Î¸, y) = f (xâˆ—)T Î² + kT Câˆ’1(y âˆ’FÎ²),
Ïƒ2
zâˆ—|Î²,Ïƒ2
f ,Î¸,y = Var(zâˆ—|Î², Ïƒ2
f , Î¸, y) = Ïƒ2
f (1 âˆ’kT Câˆ’1k),
where k := Corr(y, zâˆ—|Î¸) = [C(x(i), xâˆ—; Î¸)] âˆˆRn. To obtain numerical values of
Ï€(zâˆ—|y), we draw m samples

Î²(i), Ïƒ2
f
(i), Î¸(i)m
i=1 from the posterior distribution
Ï€(Î², Ïƒ2
f , Î¸|y) using the Gibbs sampler presented in Table5.1, and then obtain the
predictive distribution in (5.5) by
Ï€(zâˆ—|y) â‰ˆ1
m
m

i=1
Ï€(zâˆ—|y, Î²(i), Ïƒ2
f
(i), Î¸(i)).
It follows that the predictive mean and variance can be obtained numerically by
Î¼zâˆ—|y = E(zâˆ—|y) â‰ˆ1
m
m

i=1
Î¼zâˆ—|Î²(i),Ïƒ2
f
(i),Î¸(i),y,
Ïƒ2
zâˆ—|y = Var(zâˆ—|y) â‰ˆ1
m
m

i=1
Ïƒ2
zâˆ—|Î²(i),Ïƒ2
f
(i),Î¸(i),y
+ 1
m
m

i=1

Î¼zâˆ—|Î²(i),Ïƒ2
f
(i),Î¸(i),y âˆ’Î¼zâˆ—|y
2
.
Remark 5.1 The Gibbs sampler presented in Table5.1 may take long time to con-
verge,whichimpliesthatthenumberofsamplesrequiredcouldbequitelargedepend-
ing on the initial values. This convergence rate can be monitored from a trace plot
(a plot of sampled values versus iterations for each variable in the chain). More-
over, since C is a complicated function of Ïƒs and Ïƒt, sampling from Ï€(Î¸|Î², Ïƒ2
f , y) in
Proposition5.1isdifï¬cult.Aninversecumulativedistributionfunction(CDF)method

5.1 Fully Bayesian Prediction Approach
61
[109] needs to be used to generate samples, which requires griding on a continuous
parameter space. Therefore, high computational power is needed to implement the
MCMC-based approach.
In the next subsection, we present an alternative Bayesian approach which only
requires drawing samples from the prior distribution Ï€(Î¸) using a similar approach
to one used in [85].
5.1.3 Importance Sampling Approach
The posterior predictive distribution of zâˆ—:= z(sâˆ—, tâˆ—) can be written as
Ï€(zâˆ—|y) =

Ï€(zâˆ—|Î¸, y)Ï€(Î¸|y)dÎ¸,
(5.6)
where
Ï€(Î¸|y) =
Ï€(y|Î¸)Ï€(Î¸)

Ï€(y|Î¸)Ï€(Î¸)dÎ¸ ,
is the posterior distribution of Î¸, by integrating out analytically the parameters Î² and
Ïƒ2
f . We have the following proposition.
Proposition 5.2 For a prior distribution given in (5.3) with the noninformative prior
on Î², we have
1. Ï€(Î¸|y) âˆw(Î¸|y)Ï€(Î¸) with
log w(Î¸|y) = âˆ’1
2 log det(C) âˆ’1
2 log det(FT Câˆ’1F) âˆ’Ëœa log Ëœb,
(5.7)
where
Ëœa = a + n
2,
Ëœb = b + 1
2yT Câˆ’1y âˆ’1
2(FT Câˆ’1y)T (FT Câˆ’1F)âˆ’1(FT Câˆ’1y).
2. Ï€(zâˆ—|Î¸, y) is a shifted studentâ€™s t-distribution with location parameter Î¼, scale
parameter Î», and Î½ degrees of freedom, i.e.,
Ï€(zâˆ—|Î¸, y) = Î“
 Î½+1
2

Î“
 Î½
2

 Î»
Ï€Î½
 1
2 
1 + Î»(zâˆ—âˆ’Î¼)2
Î½
âˆ’Î½+1
2
,
(5.8)
where Î½ = 2Ëœa, and

62
5
Fully Bayesian Approach
Î¼ = kT Câˆ’1y + ( f (xâˆ—) âˆ’FT Câˆ’1k)T (FT Câˆ’1F)âˆ’1(FT Câˆ’1y),
Î» =
Ëœb
Ëœa

(1 âˆ’kT Câˆ’1k) + ( f (xâˆ—) âˆ’FT Câˆ’1k)T (FT Câˆ’1F)âˆ’1( f (xâˆ—)
âˆ’FT Câˆ’1k)

.
Proof (i) For given Î¸, we have
Ï€(y|Î¸) =

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f )dÎ²dÏƒ2
f
=

Ï€(y|Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f )Ï€(Ïƒ2
f )dÎ²dÏƒ2
f
=
ba
Î“ (a)(2Ï€)n/2 det(C)1/2 det(T)1/2 det(FT Câˆ’1F + Tâˆ’1)1/2
Ã—
 exp

âˆ’b+ RSS
2
Ïƒ2
f

(Ïƒ2
f )n/2+a+1 dÏƒ2
f
=
Î“ ( n+2a
2
)ba
Î“ (a)(2Ï€)n/2 det(C)1/2 det(T)1/2 det(FT Câˆ’1F + Tâˆ’1)1/2
Ã—

b + RSS
2
âˆ’n+2a
2
where
RSS = yT 
Câˆ’1 âˆ’Câˆ’1F(FT Câˆ’1F + Tâˆ’1)âˆ’1FT Câˆ’1
y.
As Î± â†’âˆ, we have
Ï€(Î¸|y) = lim
Î±â†’âˆ
Ï€(y|Î¸)Ï€(Î¸)

Ï€(y|Î¸)Ï€(Î¸)dÎ¸
âˆdet(C)âˆ’1/2 det(FT Câˆ’1F)âˆ’1/2

b + 1
2yT y
âˆ’n+2a
2
,
where  = Câˆ’1 âˆ’Câˆ’1F(FT Câˆ’1F)âˆ’1FT Câˆ’1.
(ii) For given Î¸ and y, we have
Ï€(zâˆ—|Î¸, y) =

Ï€(zâˆ—|y, Î², Ïƒ2
f , Î¸)Ï€(Î², Ïƒ2
f |Î¸, y)dÎ²dÏƒ2
f
=

Ï€(zâˆ—|y, Î², Ïƒ2
f , Î¸)Ï€(Î²|Ïƒ2
f , Î¸, y)Ï€(Ïƒ2
f |Î¸, y)dÎ²dÏƒ2
f ,

5.1 Fully Bayesian Prediction Approach
63
where
zâˆ—|y, Î², Ïƒ2
f , Î¸ âˆ¼N

f (xâˆ—)T Î² + kT Câˆ’1(y âˆ’FÎ²), Ïƒ2
f (1 âˆ’kT Câˆ’1k)

,
Î²|Ïƒ2
f , Î¸, y âˆ¼N( Ë†Î², Ïƒ2
f  Ë†Î²),
Ïƒ2
f |Î¸, y âˆ¼IG

a + n
2, b + RSS
2

.
Then, it can be shown that
Ï€(zâˆ—|Î¸, y) = Î“
 Î½+1
2

Î“
 Î½
2

 Î»
Ï€Î½
 1
2 
1 + Î»(zâˆ—âˆ’Î¼)2
Î½
âˆ’Î½+1
2
,
when Î± â†’âˆ.
The results in Proposition5.2 are different from those obtained in [85] by using
a noninformative prior on Î². For a special case where Î² and Ïƒ2
f are known a pri-
ori, we have the following corollary which will be exploited to derive a distributed
implementation among sensor groups in Sect.5.2.2.
Corollary 5.1 In the case where Î² and Ïƒ2
f are known a priori, (5.7) and (5.8) can
be simpliï¬ed as
log w(Î¸|y) = âˆ’1
2 log det(C) âˆ’1
2(y âˆ’FÎ²)T Câˆ’1(y âˆ’FÎ²),
zâˆ—|Î¸, y âˆ¼N

f (xâˆ—)T Î² + kT Câˆ’1(y âˆ’FÎ²), Ïƒ2
f (1 âˆ’kT Câˆ’1k)

.
If we draw m samples

Î¸(i)m
i=1 from the prior distribution Ï€(Î¸), the posterior
predictive distribution in (5.6) can then be approximated by
Ï€(zâˆ—|y) â‰ˆ
 w(Î¸(i)|y)Ï€(zâˆ—|Î¸(i), y)
 w(Î¸(i)|y)
.
It follows that the predictive mean and variance can be obtained by
Î¼zâˆ—|y = E(zâˆ—|y) â‰ˆ
 w(Î¸(i)|y)Î¼zâˆ—|Î¸(i),y
 w(Î¸(i)|y)
,
Ïƒ2
zâˆ—|y = Var(zâˆ—|y) â‰ˆ
 w(Î¸(i)|y)Ïƒ2
zâˆ—|Î¸(i),y
 w(Î¸(i)|y)
+
 w(Î¸(i)|y)

Î¼zâˆ—|Î¸(i),y âˆ’Î¼zâˆ—|y
2
 w(Î¸(i)|y)
,

64
5
Fully Bayesian Approach
where the mean and variance of the studentâ€™s t-distribution Ï€(zâˆ—|Î¸, y) are given by
Î¼zâˆ—|Î¸,y = E(zâˆ—|Î¸, y) = Î¼,
Ïƒ2
zâˆ—|Î¸,y = Var(zâˆ—|Î¸, y) =
Ëœa
Ëœa âˆ’1Î».
5.1.4 Discrete Prior Distribution
To further reduce the computational demands from the Monte Carlo approach, we
assign discrete uniform probability distributions to Ïƒs and Ïƒt as priors instead of
continuous probability distributions. Assume that we know the range of parameters
in Î¸, i.e.,
Ïƒs âˆˆ

Ïƒs, Ïƒs

and Ïƒt âˆˆ

Ïƒt, Ïƒt

,
where Ïƒ and Ïƒ denote the known lower-bound and upper-bound of the random
variable Ïƒ, respectively. We constrain the possible choices of Î¸ on a ï¬nite set of grid
points denoted by . (Note here  is deï¬ned as a ï¬nite set of discrete points, not to
be confused with the continuous space deï¬nition used in previous chapters.) Hence,
Ï€(Î¸) is now a probability mass function (i.e., 
Î¸âˆˆ Ï€(Î¸) = 1) as opposed to a
probability density. The integration in (5.6) is reduced to the following summation
Ï€(zâˆ—|y) =

Î¸âˆˆ
Ï€(zâˆ—|Î¸, y)Ï€(Î¸|y),
(5.9)
where the posterior distribution of Î¸ is evaluated on the grid points in Î¸ by
Ï€(Î¸|y) =
w(Î¸|y)Ï€(Î¸)

Î¸âˆˆÎ¸ w(Î¸|y)Ï€(Î¸).
(5.10)
In order to obtain the posterior predictive distribution in (5.9), the computation of
Ï€(zâˆ—|Î¸, y) and w(Î¸|y) for all Î¸ âˆˆ using the results from Proposition5.2 (or
Corollary5.1 for a special case) are necessary. Note that these quantities are available
in closed-form which reduces the computational burden signiï¬cantly.
5.2 Sequential Bayesian Prediction
Although the aforementioned efforts in Sects.5.1.3 and 5.1.4 reduce the compu-
tational cost signiï¬cantly, the number of observations (that mobile sensing agents
collect) n increases with the time t. For each Î¸ âˆˆ, an n Ã— n positive deï¬nite
matrix C needs to be inverted which requires time O(n3) using standard methods.

5.2 Sequential Bayesian Prediction
65
This motivates us to design scalable sequential Bayesian prediction algorithms by
using subsets of observations.
5.2.1 Scalable Bayesian Prediction Algorithm
The computation of Ï€(zâˆ—|y1:t) soon becomes infeasible as t increases. To overcome
this drawback while maintaining the Bayesian framework, we propose to use subsets
of all observations y1:t âˆˆRn. However, instead of using truncated local observations
only as in [2], Bayesian inference will be drawn based on two sets of observations:
â€¢ First, a set of local observations near target points Ëœy which will improve the quality
of the prediction, and
â€¢ second, a cumulative set of observations Â¯y which will minimize the uncertainty in
the estimated parameters.
Taken together, they improve the quality of prediction as the number of observations
increases. We formulate this idea in detail in the following paragraph. For notational
simplicity, we deï¬ne y âˆˆRn as a subset of all observations y1:t which will be used for
Bayesian prediction. We partition y into two subsets, namely Â¯y and Ëœy. Let Â¯F and ËœF be
the counterparts of F deï¬ned in (5.2) for Â¯y and Ëœy, respectively. The following lemma
provides the conditions under which any required function of y in Proposition5.2
can be decoupled.
Lemma 5.1 For a given Î¸ âˆˆÎ¸, let C = Corr(y, y|Î¸), Â¯C = Corr(Â¯y, Â¯y|Î¸), ËœC =
Corr(Ëœy, Ëœy|Î¸), k = Corr(y, zâˆ—|Î¸), Â¯k = Corr(Â¯y, zâˆ—|Î¸), and Ëœk = Corr(Ëœy, zâˆ—|Î¸). If the
following conditions are satisï¬ed
C1: Corr(Ëœy, Â¯y|Î¸) = 0, i.e., Ëœy and Â¯y are uncorrelated, and
C2: Corr(Â¯y, zâˆ—|Î¸) = 0, i.e., Â¯y and zâˆ—are uncorrelated,
then we have the following results:
FT Câˆ’1F = Â¯F
T Â¯C
âˆ’1 Â¯F + ËœF
T ËœC
âˆ’1 ËœF âˆˆRpÃ—p,
FT Câˆ’1y = Â¯F
T Â¯C
âˆ’1 Â¯y + ËœF
T ËœC
âˆ’1 Ëœy âˆˆRp,
yT Câˆ’1y = Â¯yT Â¯C
âˆ’1 Â¯y + ËœyT ËœC
âˆ’1 Ëœy âˆˆR,
log det C = log det Â¯C + log det ËœC âˆˆR,
FT Câˆ’1k = ËœF
T ËœC
âˆ’1 Ëœk âˆˆRp,
kT Câˆ’1k = Ëœk
T ËœC
âˆ’1 Ëœk âˆˆR.
Proof The results follow by noting the correlation matrix C can be decoupled such
that C = diag( Â¯C, ËœC) and Â¯k = 0.

66
5
Fully Bayesian Approach
Remark 5.2 In order to compute the posterior predictive distribution Ï€(zâˆ—|y) (or the
predictive mean and variance) in (5.9), Ï€(zâˆ—|Î¸, y) and Ï€(Î¸|y) for all Î¸ âˆˆ need to be
calculated. Notice that the posterior distribution of Î¸ can be obtained by computing
w(Î¸|y) in (5.7). Suppose Â¯F
T Â¯C
âˆ’1 Â¯F âˆˆRpÃ—p, Â¯F
T Â¯C
âˆ’1 Â¯y âˆˆRp, Â¯yT Â¯C
âˆ’1 Â¯y âˆˆR, and
log det Â¯C âˆˆR are known for all Î¸ âˆˆ. If ËœF
T ËœC
âˆ’1 ËœF âˆˆRpÃ—p, ËœF
T ËœC
âˆ’1 Ëœy âˆˆRp,
ËœyT ËœC
âˆ’1 Ëœy âˆˆR, and log det ËœC âˆˆR for all Î¸ âˆˆ have ï¬xed computation times,
then (5.7) and (5.8) can be computed in constant time due to decoupling results of
Lemma5.1.
The following theorem provides a way to design scalable sequential Bayesian
prediction algorithms.
Theorem 5.1 Consider the discrete prior probability Ï€(Î¸) and the compactly sup-
ported kernel function Ï†t(Â·). If we select Î· â‰¥âŒŠÏƒtâŒ‹âˆˆZ>0, Î” âˆˆZ>0 and deï¬ne
ct := max
 t âˆ’Î”
Î” + Î·

, 0

âˆˆR,
Î¾ j := y( jâˆ’1)(Î”+Î·)+1:( jâˆ’1)(Î”+Î·)+Î” âˆˆRÎ”N,
Â¯y := (Î¾T
1 , . . . , Î¾T
ct )T âˆˆRÎ”Nct ,
Ëœy := ytâˆ’Î”+1:t âˆˆRÎ”N,
(5.11)
where âŒŠÂ·âŒ‹is the ï¬‚oor function deï¬ned by âŒŠxâŒ‹:= max {m âˆˆZ | m â‰¤x}, then the
posterior predictive distribution in (5.9) can be computed in constant time (i.e., does
not grow with the time t).
Proof Byconstruction,conditionsC1â€“2 inLemma5.1aresatisï¬ed.Hence,itfollows
fromRemark5.2thattheposteriorpredictivedistributioncanbecomputedinconstant
time.
Remark 5.3 In Theorem5.1, Î· â‰¥âŒŠÏƒtâŒ‹guarantees the time distance between Î¾ j and
Î¾ j+1 is large enough such that the conditions in Lemma5.1 are satisï¬ed. Notice that
Î” is a tuning parameter for users to control the trade-off between the prediction
quality and the computation efï¬ciency. A large value for Î” yields a small predictive
variance but long computation time, and vice versa. An illustrative example with
three agents sampling the spatiotemporal Gaussian process in 1-D space is shown in
Fig.5.1.
Based on Theorem5.1, we provide the centralized sequential Bayesian prediction
algorithm as shown in Table5.2.
5.2.2 Distributed Implementation for a Special Case
In this subsection, we will show a distributed way (among agent groups) to implement
the proposed algorithm for a special case in which Î² and Ïƒ2
f are assumed to be known

5.2 Sequential Bayesian Prediction
67
10
(sâˆ—, tâˆ—)
t = 15
Ïƒt
1
2
Â· Â· Â·
Â· Â· Â·
time
space
13
Fig. 5.1 Example with three agents sampling the spatiotemporal Gaussian process in 1-D space
and performing Bayesian inference. In this example, Ïƒt = 2.5, Î· = 2, Î” = 3, t = 15, ct = 2,
Â¯y = (yT
1:3, yT
6:8)T and Ëœy = y13:15
a priori. The assumption for this special case is the exact opposite of the one made
in [46] where Î² and Ïƒ2
f are unknown and Î¸ is known a priori.
To develop a distributed scheme among agent groups for data fusion in Bayesian
statistics, we exploit the compactly supported kernel for space. Let Cs(h) in (5.1) also
be a compactly supported kernel function as Ct(h) so that the correlation vanishes
whenthespatialdistancebetweentwoinputsislargerthanÏƒs,i.e.,Cs(h) = 0, âˆ€h >1.
Consider a case in which M groups of spatially distributed agents sample a spa-
tiotemporal Gaussian process over a large region Q. Each group is in charge of its
sub-region of Q. The identity of each group is indexed by V := {1, . . . , M}. Each
agent in group i is indexed by I[i] := {1, . . . , N}. The leader of group i is referred
to as leader i, which implements the centralized scheme to make prediction on its
sub-region using local observations and the globally updated posterior distribution
of Î¸. Therefore, the posterior distribution of Î¸ shall be updated correctly using all
observations from all groups (or agents) in a distributed fashion.
Let G(t) := (V, E(t)) be an undirected communication graph such that an edge
(i, j) âˆˆE(t) if and only if leader i can communicate with leader j at time t. We deï¬ne
the neighborhood of leader i at time t by Ni(t) := { j âˆˆV | (i, j) âˆˆE(t), j Ì¸= i}. Let
a[i] denote the quantity as a in the centralized scheme for group i. We then have the
following theorem.
Theorem 5.2 Assume that Â¯y[i] and Ëœy[i] for leader i are selected accordingly to
Theorem5.1 in time-wise. Let Ëœy deï¬ned by Ëœy := ((Ëœy[1])T , . . . , (Ëœy[M])T )T . If the
following condition is satisï¬ed
C3: âˆ¥q[i]
â„“(t) âˆ’q[ j]
Î½ (tâ€²)âˆ¥â‰¥Ïƒs, âˆ€i Ì¸= j, âˆ€â„“âˆˆI[i], âˆ€Î½ âˆˆI[ j],
in the spatial domain, then the weights w(Î¸|y), based on all observations from all
agents, can be obtained from
log w(Î¸|y) = log w(Î¸|Â¯y) +
M

i=1
log w(Î¸|Ëœy[i]).
(5.12)

68
5
Fully Bayesian Approach
Table 5.2 Centralized Bayesian prediction algorithm
Input:
(1) prior distribution on Ïƒ2
f, i.e., Ï€(Ïƒ2
f) = IG(a, b)
(2) prior distribution on Î¸ âˆˆÎ˜, i.e., Ï€(Î¸)
(3) tuning variables Î” and Î·
(4) number of agents N
(5) M(Î¸).A = 0 âˆˆRpÃ—p, M(Î¸).B = 0 âˆˆR, M(Î¸).c = 0 âˆˆRp, M(Î¸).D = 0 âˆˆR,
M0(Î¸) = M(Î¸), âˆ€Î¸ âˆˆÎ˜
Output:
(1) The predictive mean at location sâˆ—âˆˆS and time tâˆ—= t, i.e., Î¼zâˆ—|y
(2) The predictive variance at location sâˆ—âˆˆS and time tâˆ—= t, i.e., Ïƒ2
zâˆ—|y
At time t, the central station does:
1: receive observations yt from agents, set Ëœy = ytâˆ’Î”+1:t and n = NÎ”
2: compute ËœF = (f(Ëœx(1)), Â· Â· Â· , f(Ëœx(n)))T where Ëœx(i) is the input of the i-th element
in Ëœy
3: for each Î¸ âˆˆÎ¸ do
4:
compute ËœC = Cor(Ëœy, Ëœy) âˆˆRnÃ—n
5:
compute the key values
FT Câˆ’1F = M(Î¸).A + ËœF
T ËœC
âˆ’1ËœF âˆˆRpÃ—p, yT Câˆ’1y = M(Î¸).B + ËœyT ËœC
âˆ’1Ëœy âˆˆR,
FT Câˆ’1y = M(Î¸).c + ËœF
T ËœC
âˆ’1Ëœy âˆˆRp, log det C = M(Î¸).D + log det ËœC âˆˆR
6:
compute Ëœa = a + n
2 and
Ëœb = b + 1
2yT Câˆ’1y âˆ’1
2(FT Câˆ’1y)T (FT Câˆ’1F)âˆ’1(FT Câˆ’1y)
7:
update weights via
log w(Î¸|y) = âˆ’1
2 log det C âˆ’1
2 log det(FT Câˆ’1F) âˆ’Ëœa log Ëœb
8:
for each sâˆ—âˆˆS do
9:
compute f(xâˆ—) âˆˆRp, Ëœk = Corr(Ëœy, zâˆ—) âˆˆRn
10:
compute predictive mean and variance for given Î¸
Î¼zâˆ—|Î¸,y = ËœkËœC
âˆ’1Ëœy + (f(xâˆ—) âˆ’ËœF
T ËœC
âˆ’1Ëœk)T (FT Câˆ’1F)âˆ’1(FT Câˆ’1y),
Ïƒ2
zâˆ—|Î¸,y =
Ëœb
Ëœaâˆ’1

(1 âˆ’Ëœk
T ËœC
âˆ’1Ëœk) + (f(xâˆ—) âˆ’ËœF
T ËœC
âˆ’1Ëœk)T (FT Câˆ’1F)âˆ’1(f(xâˆ—) âˆ’ËœF
T ËœC
âˆ’1Ëœk)

11:
end for
12:
if mod(t, Î” + Î·) = Î” then
13:
set M(Î¸) = M0(Î¸), then M0(Î¸).A = FT Câˆ’1F, M0(Î¸).B = yT Câˆ’1y,
M0(Î¸).c = FT Câˆ’1y, and M0(Î¸).D = log det C
14:
end if
15: end for
16: compute the posterior distribution
Ï€(Î¸|y) =
w(Î¸|y)Ï€(Î¸)

Î¸ w(Î¸|y)Ï€(Î¸)
17: compute the predictive mean and variance
Î¼zâˆ—|y = 
Î¸ Î¼zâˆ—|Î¸,yÏ€(Î¸|y),
Ïƒ2
zâˆ—|y = 
Î¸ Ïƒ2
zâˆ—|Î¸,yÏ€(Î¸|y) + 
Î¸ Î¼zâˆ—|Î¸,y âˆ’Î¼zâˆ—|y
2 Ï€(Î¸|y).

5.2 Sequential Bayesian Prediction
69
Ïƒs
Ïƒs
Ïƒs
Fig. 5.2 Example with three group of agents sampling the spatiotemporal Gaussian process in 2-D
space and performing Bayesian prediction. The symbol â€˜oâ€™ denotes the position of a leader for a
group and the symbol â€˜xâ€™ denotes the position of an agent. Distance between any two sub-regions
is enforced to be greater than Ïƒs which enables the distributed Bayesian prediction
Proof The result follows by noting Corr(Ëœy[i], Ëœy[ j]|Î¸) = 0, âˆ€i Ì¸= j, when the condi-
tion C3 is satisï¬ed.
An exemplary conï¬guration of agents which satisï¬es C3 is shown in Fig.5.2.
Suppose that the communication graph G(t) is connected for all time t. Then
the average 1
M
M
i=1 log w(Î¸|Ëœy[i]) can be achieved asymptotically via discrete-time
average-consensus algorithm [110]:
log w(Î¸|Ëœy[i]) â†log w(Î¸|Ëœy[i]) + Ïµ

jâˆˆNi

log w(Î¸|Ëœy[ j]) âˆ’log w(Î¸|Ëœy[i])

,
with 0 < Ïµ < 1/Î”(G) that depends on the maximum node degree of the network
Î”(G) = maxi |Ni|.
5.2.3 Adaptive Sampling
At time t, the goal of the navigation of agents is to improve the quality of prediction of
the ï¬eld Q at the next sampling time t + 1. Therefore, mobile agents should move to
the most informative sampling locations q(t +1) = (q1(t +1)T , . . . , qN(t +1)T )T
at time t + 1 in order to reduce the prediction error [44].
Suppose at time t +1, agents move to a new set of positions Ëœq = (ËœqT
1 , . . . , ËœqT
N)T .
The mean squared prediction error is deï¬ned as
J(Ëœq) =

sâˆˆS
E

(z(s, t + 1) âˆ’Ë†z(s, t + 1))2
ds,
(5.13)

70
5
Fully Bayesian Approach
where Ë†z(s, t + 1) is obtained as in (5.9). Due to the fact that Î¸ has a distribution, the
evaluation of (5.13) becomes computationally prohibitive. To simplify the optimiza-
tion, we propose to utilize a maximum a posteriori (MAP) estimate of Î¸ at time t,
denoted by Ë†Î¸t, i.e.,
Ë†Î¸t = arg max
Î¸âˆˆÎ¸ Ï€(Î¸|y),
where y is the subset of all observations used up to time t. The next sampling positions
can be obtained by solving the following optimization problem
q(t + 1) = arg min
ËœqiâŠ‚Q

sâˆˆS
Var(z(s, t + 1)|y, Ë†Î¸t)ds.
(5.14)
This problem can be solved using standard constrained nonlinear optimization tech-
niques (e.g., the conjugate gradient algorithm), possibly taking into account mobility
constraints of mobile sensors.
Remark 5.4 The proposed control algorithm in (5.14) is truly adaptive in the sense
that the new sampling positions are functions of all collected observations. On the
other hand, if all parameters are known, the optimization in (5.14) can be performed
ofï¬‚ine without taking any measurements.
5.3 Simulation
In this section, we apply the proposed sequential Bayesian prediction algorithms
to spatiotemporal Gaussian processes with a correlation function in Sect.5.1. The
Gaussian process was numerically generated through circulant embedding of the
covariance matrix for the simulation study [107]. This technique allows us to numer-
ically generate a large number of realizations of the Gaussian process.
5.3.1 MCMC-Based Approach on a 1-D Scenario
We consider a scenario in which N = 5 agents sample the spatiotemporal Gaussian
process in 1-D space and the central station performs Bayesian prediction. The sur-
veillance region Q is given by Q = [0, 10]. We consider the squared exponential
function
Cs(h) = exp

âˆ’1
2h2

,
for space correlation and a compactly supported correlation function [111] for time
as

5.3 Simulation
71
5
0
5
0
200
400
0
2
4
6
0
200
400
600
1.6 1.8
2
2.2
0
50
100
150
4
6
8
10
12
0
50
100
150
Î²
Ïƒ2
f
Ïƒs
Ïƒt
2
0
2
0
200
400
0
1
2
3
0
100
200
300
1.6 1.8
2
2.2
0
100
200
300
4
6
8
10
12
0
200
400
Î²
Ïƒ2
f
Ïƒs
Ïƒt
(a)
(b)
Fig. 5.3 Posterior distribution of Î², Ïƒ2
f , Ïƒs, and Ïƒt at a t = 1, and b t = 20
Ct(h) =
 (1âˆ’h) sin(2Ï€h)
2Ï€h
+ 1âˆ’cos(2Ï€h)
Ï€Ã—2Ï€h
, 0 â‰¤h â‰¤1,
0,
otherwise,
(5.15)
The signal-to-noise ratio Î³ is set to be 26dB which corresponds to Ïƒw = 0.158.
The true values for the parameters used in simulating the Gaussian process are given
by (Î², Ïƒ2
f , Ïƒs, Ïƒt) = (0, 1, 2, 8). Notice that the mean function is assumed to be an
unknown random variable, i.e., the dimension of the regression coefï¬cient Î² is 1.
We assume that Î²|Ïƒ2
f has the noninformative prior and Ïƒ2
f âˆ¼IG(3, 20). The Gibbs
sampler in Table5.1 was used to generate samples from the posterior distribution
of the parameters. A random sampling strategy was used in which agents make
observations at random locations at each time t âˆˆZ>0. The prediction was evaluated
at each time step for 51 uniform grid points within Q.
The histograms of the samples at time t = 1 and t = 10 are shown in Fig.5.3a and
Fig.5.3b, respectively. It is clear that the distributions of the parameters are centered
around the true values with 100 observations at time t = 20. The prediction results
at time t = 1 and t = 20 are shown in Fig.5.4a and Fig.5.4b, respectively. However,
with only 100 observations, the running time using the full Bayesian approach is
about several minutes which will soon become intractable.
5.3.2 Centralized Scheme on 1-D Scenario
We consider the same scenario in which N = 5 agents sample the spatiotemporal
Gaussian process in 1-D space and the central station performs Bayesian prediction.
The true values for the parameters used in simulating the Gaussian process are given
by (Î², Ïƒ2
f , Ïƒs, Ïƒt) = (20, 10, 2, 8). Notice that the mean function is assumed to
be an unknown random variable, i.e., the dimension of the regression coefï¬cient
Î² is 1. We assume that Î²|Ïƒ2
f has the noninformative prior and Ïƒ2
f âˆ¼IG(3, 20).

72
5
Fully Bayesian Approach
0
2
4
6
8
10
-2
-1
0
1
2
s
0
2
4
6
8
10
s
-1
0
1
2
(a)
(b)
Fig. 5.4 Prediction at a t = 1, and b t = 20 using the MCMC-based approach. The true ï¬elds
are plotted in blue solid lines. The predicted ï¬elds are plotted in red dash-dotted lines. The area
between red dotted lines indicates the 95 % conï¬dence interval
We also assume the bounds of Î¸, viz. Ïƒs âˆˆ[1.6, 2.4] and Ïƒt âˆˆ[4, 12] are known.
Î” = 12 is used and Î· = 11 is selected satisfying the condition in Theorem5.1. We
use a discrete uniform probability distribution for Ï€(Î¸) as shown in Fig.5.6a. The
adaptive sampling strategy was used in which agents make observations at each time
t âˆˆZ>0. The prediction was evaluated at each time step for 51 uniform grid points
within Q.
Figure5.5 shows the comparison between predictions at time t = 1 using
(a) the maximum likelihood (ML) based approach, and (b) the proposed fully
Bayesian approach. The ML based approach ï¬rst generates a point estimate of the
hyperparameters and then uses them as true ones for computing the prediction and
the prediction error variance. In this simulation, a poor point estimate on Î¸ was
achieved by maximizing the likelihood function. As a result, the prediction and the
associated prediction error variance are incorrect and are far from being accurate
for a small number of observations. On the other hand, the fully Bayesian approach
which incorporates the prior knowledge of Î¸ and uncertainties in Î¸ provides a more
accurate prediction and an exact conï¬dence interval.
Using the proposed sequential Bayesian prediction algorithm along with the adap-
tive sampling strategy, the prior distribution was updated in a sequential manner. At
time t = 100, the posterior distribution of Î¸ is shown in Fig.5.6b. With a larger num-
ber of observations, the support for the posterior distribution of Î¸ becomes smaller
and the peak gets closer to the true value. As shown in Fig.5.7a, the quality of the
prediction at time t = 100 is signiï¬cantly improved. At time t = 300, the prior dis-
tribution was further updated which is shown in Fig.5.6c. At this time, Î¸ = (2, 8)T ,
which is the true value, has the highest probability. The prediction is also shown in
Fig.5.7b. This demonstrates the usefulness and correctness of our algorithm. The
running time at each time step is ï¬xed, which is around 12s using Matlab, R2008a
(MathWorks) in a PC (2.4GHz Dual-Core Processor).

5.3 Simulation
73
0
2
4
6
8
10
14
16
18
20
22
24
26
28
s
0
2
4
6
8
10
14
16
18
20
22
24
26
28
s
(a)
(b)
Fig. 5.5 Prediction at t = 1 using (a) the maximum likelihood based approach, and (b) the
proposed fully Bayesian approach. The true ï¬elds are plotted in blue solid lines. The predicted
ï¬elds are plotted in red dash-dotted lines. The area between red dotted lines indicates the 95 %
conï¬dence interval
1.6 1.8 2 2.2 2.4
4
6
8
10
12
0
0.005
0.01
0.015
Ïƒs
Ïƒt
1.6 1.8 2 2.2 2.4
4
6
8
10
12
0
0.05
0.1
0.15
0.2
Ïƒs
Ïƒt
1.6 1.8 2 2.22.4
4
6
8
10
12
0
0.2
0.4
0.6
0.8
Ïƒs
Ïƒt
(a)
(b)
(c)
Fig. 5.6 a Prior distribution Î¸, b posterior distribution of Î¸ at time t = 100, c posterior distribution
of Î¸ at time t = 300
0
2
4
6
8
10
16
17
18
19
20
21
22
23
24
s
0
2
4
6
8
10
16
17
18
19
20
21
22
23
24
s
(a)
(b)
Fig. 5.7 Prediction at a t = 100, and b t = 300 using the centralized sequential Bayesian approach.
The true ï¬elds are plotted in blue solid lines. The predicted ï¬elds are plotted in red dash-dotted
lines. The area between red dotted lines indicates the 95 % conï¬dence interval

74
5
Fully Bayesian Approach
1.6
1.8
2
2.2
2.4
4
6
8
10
12
0
0.1
0.2
0.3
0.4
Ïƒs
Ïƒt
Fig. 5.8 Posterior distribution of Î¸ at time t = 100 using the distributed algorithm
(a)
(b)
Fig. 5.9 Comparison of (a) the true ï¬eld at t = 100 and (b) the predicted ï¬eld at t = 100 using
the distributed algorithm
5.3.3 Distributed Scheme on 2-D Scenario
Finally, we consider a scenario in which there are 4 groups, each of which contain 10
agents sampling the spatiotemporal Gaussian process in 2-D space. The surveillance
region Q is given by Q = [0, 10]Ã—[0, 10]. The parameter values used in simulating
the Gaussian process are given by Î¸ = (Ïƒs, Ïƒt)T = (2, 8)T , Î² = 0, and Ïƒ2
f = 1,
last two values of which are assumed to be known a priori. To use the distributed
scheme, we only consider compactly supported kernel functions for both space and
time. In particular, we consider Cs(h) = Ct(h) as in (5.15). We also assume the fact
that Ïƒs âˆˆ[1.6, 2.4] and Ïƒt âˆˆ[4, 12] are known a priori. Î” = 12 is used and Î· = 11
is selected satisfying the condition in Theorem5.1. The region Q is divided into 4
square sub-regions with equal size areas as shown in Fig.5.9a. Distance between any
two sub-regions is enforced to be greater than Â¯Ïƒs = 2.4, satisfying the condition in

5.3 Simulation
75
Theorem5.2, which enables the distributed Bayesian prediction. The same uniform
prior distribution for Î¸ as in the centralized version (see Fig.5.6a) is used.
The globally updated posterior distribution of Î¸ at time t100 is shown in Fig.5.8. It
has a peak near the true Î¸, which shows the correctness of the distributed algorithm.
The predicted ï¬eld compared with the true ï¬eld at time t100 is shown in Fig.5.9. Due
to the construction of sub-regions, the interface areas between any of two sub-regions
are not predicted. Notice that the prediction is not as good as in the 1-D scenario due
to the effect of curse of dimensionality when we move from 1-D to 2-D spaces. The
prediction quality can be improved by using more number of sensors at the cost of
computational time. The running time of the distributed algorithm in this scenario
is about several minutes due to the complexity of the 2-D problem under the same
computational environment as the one used for the 1-D scenario. However, thanks
to our proposed sequential sampling schemes, the running time does not grow with
the number of measurements.

Chapter 6
New Efï¬cient Spatial Model with Built-In
Gaussian Markov Random Fields
Recently, there have been efforts to ï¬nd a way to ï¬t a computationally efï¬cient
Gaussian Markov Random Field (GMRF) on a discrete lattice to a Gaussian random
ï¬eldonacontinuumspace[86â€“88]. Suchmethods havebeendevelopedusingaï¬tting
with a weighted L2-type distance [86], using a conditional-mean least-squares ï¬tting
[87], and for dealing with large data by fast Kriging [88]. It has been demonstrated
that GMRFs with small neighborhoods can approximate Gaussian ï¬elds surprisingly
well [86]. This approximated GMRF and its regression are very attractive for the
resource-constrained mobile sensor networks due to its computational efï¬ciency
and scalability [89] as compared to the standard Gaussian process and its regression,
which is not scalable as the number of observations increases.
Mobile sensing agents form an ad hoc wireless communication network in which
each agent usually operates under a short communication range, with limited mem-
ory and computational power. For resource-constrained mobile sensor networks,
developing distributed prediction algorithms for robotic sensors using only local
information from local neighboring agents has been one of the most fundamental
problems [42, 45, 46, 68, 112, 113].
In Sect.6.1.1, a new class of Gaussian processes is proposed for resource-
constrained mobile sensor networks. Such a Gaussian process builds on a GMRF [92]
with respect to a proximity graph, e.g., the Delaunay graph of a set of vertices over a
surveillance region. The formulas for predictive statistics are derived in Sect.6.1.2.
We propose a sequential prediction algorithm which is scalable to deal with sequen-
tially sampled observations in Sect.6.1.3. In Sect.6.2, we develop a distributed and
scalable statistical inference algorithm for a simple sampling scheme by applying
the Jacobi over-relaxation and discrete-time average consensus algorithms. Simula-
tion and experimental study demonstrate the usefulness of the proposed model and
algorithms in Sect.6.3.
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_6
77

78
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
6.1 Spatial Prediction
In this section, we ï¬rst propose a new class of Gaussian random ï¬elds with built-in
Gaussian Markov Random Fields (GMRF) [92]. Then we show how to compute the
prediction at any point of interest based on Gaussian process regression, and provide
a sequential ï¬eld prediction algorithm for mobile sensor networks.
6.1.1 Spatial Model Based on GMRF
Let Î³ := (Î³(p1), Â· Â· Â· , Î³(pm))T âˆ¼N(0, Qâˆ’1) be a zero-mean GMRF [92] with
respect to an undirected graph G = (V, E), where the location of vertex i is denoted
by pi in the surveillance region Q. Such locations of vertices will be referred to
as generating points. The inverse covariance matrix (precision matrix) Q â‰»0 has
the property (Q)i j Ì¸= 0 â‡”{i, j} âˆˆE. If the graph G has small cardinalities of the
neighbor sets, its precision matrix Q becomes sparse with many zeros in its entries.
This plays a key role in computation efï¬ciency of a GMRF which can be greatly
exploited by the resource-constrained mobile sensor network.
The spatial ï¬eld is modeled by a Gaussian process with a built-in GMRF
deï¬ned as
z(s) = Î¼(s) +
m

j=1
Î»(s, p j)Î³(p j),
(6.1)
where Î»(Â·, Â·) is a weighting function. The new class of Gaussian processes is capable
of representing a wide range of nonstationary Gaussian ï¬elds, by selecting
1. different number of generating points m,
2. different locations of generating points

p j | j = 1, Â· Â· Â· , m

over Q,
3. a different structure of the precision matrix Q, and
4. different weighting functions

Î»(Â·, p j) | j = 1, Â· Â· Â· , m

.
Remark 6.1 The number of generating points could be determined by a model selec-
tion criterion such as the Akaike information criterion [114]. Similar to hyperpara-
meter estimation in the standard Gaussian process regression, one can estimate all
other parameters using maximum likelihood (ML) optimization [1, 53]. This is non-
convex optimization and so the initial conditions need to be chosen carefully to avoid
local minima. In our approach, we use basic structures for weighting functions and
the precision matrix; however, we make them as functions of the locations of gen-
erating points. Different spatial resolutions can be obtained by a suitable choice of
locations of generating points. As an example shown in Fig.6.1, higher resolution
can be obtained by higher density of generating points (see lower left corner). In this
way, we only need to determine the locations of generating points. This approach
will be demonstrated with real-world data in Sect.6.3.4.

6.1 Spatial Prediction
79
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
(a)
(b)
Fig. 6.1 a Generating points in blue dots and the associated Delaunay graph with edges in red
dotted lines. The Voronoi partition is also shown in blue solid lines. b Gaussian random ï¬eld with
a built-in GMRF with respect to the Delaunay graph in (a)
6.1.2 Gaussian Process Regression
Suppose we have a collection of observations y := (y1, Â· Â· Â· , yn)T whose entries are
sampled at the corresponding points s1, Â· Â· Â· , sn. The noise corrupted measurement
yi âˆˆR is given by
yi = z(si) + Ïµi,
where Ïµi
i.i.d.
âˆ¼N(0, Ïƒ2
w) is an independent and identically distributed (i.i.d.) Gaussian
white noise. We then have the following results.
Proposition 6.1 Let  âˆˆRnÃ—m be a matrix obtained by ()i j = Î»(si, p j) and
let Î» âˆˆRm be a vector obtained by (Î»)i = Î»(s0, pi), where s0 is a point of
interest. Then the covariance matrix of y and the covariance between y and z(s0) are
given by
C := E[(y âˆ’Ey)(y âˆ’Ey)T ] = Qâˆ’1T + Ïƒ2
wI,
k := E[(y âˆ’Ey)z(s0)] = Qâˆ’1Î»,
where Q âˆˆRmÃ—m is the precision matrix of the GMRF Î³ âˆˆRm.
Proof The (i, j)th element of the covariance matrix C, i.e., the covariance between
yi and y j, can be obtained by

80
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
(C)i j = Cov(z(si), z(s j)) + Ïƒ2
wÎ´i j
= E(z(si) âˆ’Î¼(si))(z(s j) âˆ’Î¼(s j)) + Ïƒ2
wÎ´i j
= E

k
Î»(si, pk)Î³(pk)
 
l
Î»(s j, pl)Î³(pl)

+ Ïƒ2
wÎ´i j
= E
â›
â
k,l
Î»(si, pk)Î³(pk)Î³(pl)Î»(s j, pl)
â
â + Ïƒ2
wÎ´i j
=

k,l
Î»(si, pk)E(Î³(pk)Î³(pl))Î»(s j, pl) + Ïƒ2
wÎ´i j
=

k,l
Î»(si, pk)(Qâˆ’1)klÎ»(s j, pl) + Ïƒ2
wÎ´i j.
The ith element of the covariance vector k, i.e., the covariance between yi and
z(s0), can be obtained by
(k)i = Cov(z(si), z(s0))
= E(z(si) âˆ’Î¼(si))(z(s0) âˆ’Î¼(s0))
= E

k
Î»(si, pk)Î³(pk)
 
l
Î»(s0, pl)Î³(p j)

= E
â›
â
k,l
Î»(si, pk)Î³(pk)Î³(pl)Î»(s0, pl)
â
â 
=

k,l
Î»(si, pk)E(Î³(pk)Î³(pl))Î»(s0, pl)
=

k,l
Î»(si, pk)(Qâˆ’1)klÎ»(s0, pl),
whose matrix form completes the proof.
â–¡
By Proposition 6.1, we can make prediction at the point of interest s0 using
Gaussian process regression [53]. This is summarized by the following theorem.
Theorem 6.1 For given y, the prediction of z0 := z(s0) at any location s0 âˆˆQ is
given by the conditional distribution
z0|y âˆ¼N

Î¼z0|y, Ïƒ2
z0|y

,

6.1 Spatial Prediction
81
where the predictive mean and variance are obtained by
Î¼z0|y = Î¼(s0) + Î»T Ë†Q
âˆ’1 Ë†y,
(6.2)
Ïƒ2
z0|y = Î»T Ë†Q
âˆ’1Î»,
with
Ë†Q = Q + Ïƒâˆ’2
w T  âˆˆRmÃ—m,
Ë†y = Ïƒâˆ’2
w T (y âˆ’Î¼) âˆˆRm.
Proof By using the Woodbury matrix identity (see Appendix A.2.1), the prediction
mean can be obtained by
Î¼z0|y = Î¼(s0) + kT Câˆ’1(y âˆ’Î¼)
= Î¼(s0) + (Qâˆ’1Î»)T (Qâˆ’1T + Ïƒ2
wI)âˆ’1(y âˆ’Î¼)
= Î¼(s0) + Î»T Qâˆ’1T (Qâˆ’1T + Ïƒ2
wI)âˆ’1(y âˆ’Î¼)
= Î¼(s0) + Î»T Qâˆ’1T (Ïƒâˆ’2
w Iâˆ’
Ïƒâˆ’2
w (Q + Ïƒâˆ’2
w T )âˆ’1T Ïƒâˆ’2
w )(y âˆ’Î¼)
= Î¼(s0) + Î»T (Ïƒâˆ’2
w Qâˆ’1âˆ’
Ïƒâˆ’4
w Qâˆ’1T (Q + Ïƒâˆ’2
w T )âˆ’1)T (y âˆ’Î¼)
= Î¼(s0) + Î»T T (y âˆ’Î¼),
where
 = Ïƒâˆ’2
w Qâˆ’1 âˆ’Ïƒâˆ’4
w Qâˆ’1T (Q + Ïƒâˆ’2
w T )âˆ’1
= Ïƒâˆ’2
w Qâˆ’1(Q + Ïƒâˆ’2
w T )(Q + Ïƒâˆ’2
w T )âˆ’1
âˆ’Ïƒâˆ’4
w Qâˆ’1T (Q + Ïƒâˆ’2
w T )âˆ’1
= (Ïƒâˆ’2
w I + Ïƒâˆ’4
w Qâˆ’1T )(Q + Ïƒâˆ’2
w T )âˆ’1
âˆ’Ïƒâˆ’4
w Qâˆ’1T (Q + Ïƒâˆ’2
w T )âˆ’1
= Ïƒâˆ’2
w (Q + Ïƒâˆ’2
w T )âˆ’1.
Similarly, the prediction error variance can be obtained by
Ïƒ2
z0|y = Î»T Qâˆ’1Î» âˆ’kT Câˆ’1k
= Î»T Qâˆ’1Î» âˆ’(Qâˆ’1Î»)T (Qâˆ’1T + Ïƒ2
wI)âˆ’1(Qâˆ’1Î»)
= Î»T 
Qâˆ’1 âˆ’Qâˆ’1T (Qâˆ’1T + Ïƒ2
wI)âˆ’1Qâˆ’1
Î»
= Î»T (Q + Ïƒâˆ’2
w T )âˆ’1Î»,

82
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
where Cov(z(s0), z(s0)) = Î»T Qâˆ’1Î» is obtained similarly as in Proposition 6.1. â–¡
Remark 6.2 When the generating points

p1, p2, Â· Â· Â· , pm

are not known a priori,
they can be estimated by maximizing the likelihood function. Given n observations
y = (y1, y2, Â· Â· Â· , yn)T sampled at {s1, s2, Â· Â· Â· , sn}, the log likelihood of y is given
by
log Ï€(y) = âˆ’1
2(y âˆ’Î¼)T Câˆ’1(y âˆ’Î¼) âˆ’1
2 log det C âˆ’n
2 log 2Ï€,
where C = Qâˆ’1T + Ïƒ2
wI is the covariance matrix of y. the maximum likeli-
hood estimate of the generating points can be obtained via solving the following
optimization problem.
Ë†pML = arg max
p log Ï€(y).
(6.3)
Remark 6.3 Note that the number of generating points m is ï¬xed and the num-
ber of observations n may grow in time, and so in general we consider m â‰ªn.
Theorem 6.1 shows that only the inversion of an m Ã— m matrix Ë†Q = Q + Ïƒâˆ’2
w T 
is required in order to compute the predictive distribution of the ï¬eld at any point.
The computational complexity grows linearly with the number of observations, i.e.,
O(nm2), compare to the standard Gaussian process regression which requires O(n3).
Moreover, it enables a scalable prediction algorithm for sequential measurements.
In what follows, we present a sequential ï¬eld prediction algorithm for sequential
observations by exploiting the results of Theorem 6.1.
6.1.3 Sequential Prediction Algorithm
Consider a sensor network consisting of N mobile sensing agents distributed in
the surveillance region Q. The index of the robotic sensors is denoted by I :=
{1, Â· Â· Â· , N}. The sensing agents sample the environmental ï¬eld at time t âˆˆZ>0 and
send the observations to a central station which is in charge of the data fusion.
At time t, agent i makes an observation yi(t) at location si(t). Denote the collec-
tion of observations at time t by yt := (y1(t), Â· Â· Â· , yN(t))T . We have the following
proposition.
Proposition 6.2 At time t âˆˆZ>0, the predictive mean and variance at any point of
interest can be obtained via (6.2) with
Ë†Qt = Ë†Qtâˆ’1 + Ïƒâˆ’2
w T
t t,
Ë†Q0 = Q
Ë†yt = Ë†ytâˆ’1 + Ïƒâˆ’2
w T
t (yt âˆ’Î¼t),
Ë†y0 = 0,
where (t)i j = Î»(si(t), s j(t)), and (Î¼t)i = Î¼(si(t)).

6.1 Spatial Prediction
83
Table 6.1 Sequential algorithm for ï¬eld prediction
Input:
a set of target points S
Output:
(1) prediction mean {Ë†z(s0) | s0 âˆˆS}
(2) prediction error variance {Ïƒ2(s0) | s0 âˆˆS}
Assumption:
(1) the central station knows p, Q, and Î»(Â·, Â·)
(2) the central station initially has Ë†Q â†Q, Ë†y â†0
At time t, agent i âˆˆI in the network does:
1: take measurement yi from its current location si
2: send the measurement (si, yi) to the central station
At time t, the central station does:
1: obtain measurements {(sâ„“, yâ„“) | âˆ€â„“âˆˆI} from mobile sensors
2: compute Î› via (Î›)ij = Î»(si, pj)
3: update Ë†Q â†Ë†Q + Ïƒâˆ’2
w Î›T Î›
4: update Ë†y â†Ë†y + Ïƒâˆ’2
w Î›T (y âˆ’Î¼), where (Î¼)i = Î¼(si)
5: for s0 âˆˆS do
6:
compute (Î»)i via Î»(s0, pi)
7:
compute Ë†z(s0) = Î¼(s0) + Î»T Ë†Q
âˆ’1Ë†y
8:
compute Ïƒ2(s0) = Î»T Ë†Q
âˆ’1Î»
9: end for
Proof The result can be obtained easily by noting that AT A = AT
1 A1 + AT
2 A2,
where A = (AT
1 , AT
2 )T .
â–¡
Based on Proposition 6.2, we present a sequential ï¬eld prediction algorithm using
mobile sensor networks in Table6.1.
6.2 Distributed Spatial Prediction
In this section, we propose a distributed approach, in which robotic sensors exchange
only local information between neighbors, to implement the ï¬eld prediction effec-
tively fusing all observations collected by all sensors correctly. This distributed
approach can be implemented for a class of weighting functions Î»(Â·, Â·) in (6.1) that
have compact supports. In particular, we consider the weighting function deï¬ned by
Î»(s, p j) = Î»(
s âˆ’p j
 /r),
(6.4)
where
Î»(h) :=

(1 âˆ’h) cos(Ï€h) + 1
Ï€ sin(Ï€h), h â‰¤1,
0,
otherwise.

84
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
Notice that the weighting function Î»(Â·, Â·) in (6.4) has a compact support, i.e., Î»(s, p j)
is nonzero if and only if the distance
s âˆ’p j
 is less than the support r âˆˆR>0.
6.2.1 Distributed Computation
We ï¬rst brieï¬‚y introduce distributed algorithms for solving linear systems and com-
puting the averages. They will be used as major tools for distributed implementation
of ï¬eld prediction.
â€¢ Jacobi over-relaxation method: The Jacobi over-relaxation (JOR) [112] method
provides an iterative solution of a linear system Ax = b, where A âˆˆRnÃ—n is a
nonsingular matrix and x, b âˆˆRn. If agent i knows the rowi(A) âˆˆRn and bi, and
ai j = (A)i j = 0 if agent i and agent j are not neighbors, then the recursion is
given by
x(k+1)
i
= (1 âˆ’h)x(k)
i
+ h
aii
â›
âbi âˆ’

jâˆˆNi
ai j x(k)
j
â
â .
(6.5)
This JOR algorithm converges to the solution of Ax = b from any initial condition
if h < 2/n [45]. At the end of the algorithm, agent i knows the ith element of
x = Aâˆ’1b.
â€¢ Discrete-time average consensus: The Discrete-time average consensus (DAC)
provides a way to compute the arithmetic mean of elements in the a vector c âˆˆRn.
Assume the graph is connected. If agent i knows the ith element of c, the network
can compute the arithmetic mean via the following recursion [113]
x(k+1)
i
= x(k)
i
+ Ïµ

jâˆˆNi
ai j(x(k)
j
âˆ’x(k)
i
),
(6.6)
with initial condition x(0) = c, where ai j = 1 if j âˆˆNi and 0 otherwise,
0 < Ïµ < 1/Î”, and Î” = maxi(
jÌ¸=i ai j) is the maximum degree of the network.
After the algorithm converges, all node in the network know the average of c, i.e.,
n
i=1 ci/n.
6.2.2 Distributed Prediction Algorithm
Consider a GMRF with respect to a proximity graph G = (V, E) that generates a
Gaussian random ï¬eld in (6.1). The index of the generating points is denoted by
V := {1, Â· Â· Â· , n}. The location of the ith generating point is pi. The edges of the
graph are considered to be E :=
{i, j} |
pi âˆ’p j
 â‰¤R

, where R is a constant
that ensures the graph is connected.

6.2 Distributed Spatial Prediction
85
Consider a mobile sensor network consisting of N mobile sensing agents dis-
tributed in the surveillance region Q. For simplicity, we assume that the number of
agents is equal to the number of generating points, i.e., N = m. The index of the
robotic sensors is denoted by I := {1, Â· Â· Â· , m}. The location of agent i is denoted
by si.
The assumptions made for the resource-constrained mobile sensor networks are
listed as follows.
A.1 Agent i is in charge of sampling at point si within a r-disk centered at pi, i.e.,
âˆ¥si âˆ’piâˆ¥< r.
A.2 r is the radius of the support of the weighting function in (6.4) and also satisï¬es
that 0 < r < R
2 .
A.3 Agenti canonlylocallycommunicatewithneighborsin Ni := { j âˆˆI | {i, j} âˆˆE}
deï¬ned by the connected proximity graph G = (V, E).
A.4 Agent i knows rowi(Q), i.e., the ith row of Q, where (Q)i j Ì¸= 0 if and only if
j âˆˆ{i} âˆªNi.
Remark 6.4 As in A.1, it is reasonable to have at least one agent collect measure-
ments that are correlated with a random variable from a single generating point. This
sampling rule may be modiï¬ed such that a single agent dynamically samples for
multiple generating points or more number of agents samples for a generating point
depending on available resources. Since there is at least one agent in charge of a
generating point by A.1, it is natural to have A.3 and A.4 taking advantage of the
proximity graph for the GMRF. Notice that each agent only knows local information
of Q as described in A.4.
An illustration of agent â„“sampling a measurement at point sâ„“in the intersection
of the supports of the weighting functions of pi and p j is shown in Fig.6.2.
From A.1 and A.2, since R > 2r, we have Î»(sâ„“, pi) = 0 if â„“/âˆˆNi. Thus the
matrix Ë†Q = Q + Ïƒâˆ’2
w T  âˆˆRmÃ—m and the vector Ë†y = Ïƒâˆ’2
w T (y âˆ’Î¼) âˆˆRm can
be obtained in the following form.
Fig. 6.2 Example of
computing (T )i j =
Î»(sâ„“, pi)Î»(sâ„“, p j)
pi
pj
pk
r
sâ„“

86
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
( Ë†Q)i j = (Q)i j + Ïƒâˆ’2
w

â„“âˆˆ{{i}âˆªNi}âˆ©{{ j}âˆªN j}
Î»(sâ„“, pi)Î»(sâ„“, p j),
(Ë†y)i
= Ïƒâˆ’2
w

â„“âˆˆ{i}âˆªNi
Î»(sâ„“, pi)(yâ„“âˆ’Î¼â„“).
(6.7)
Noticethat Ë†QhasthesamesparsityasQ.From (6.7),A.3andA.4,agenti cancompute
rowi( Ë†Q) and (Ë†y)i by using only local information from neighbors. Using rowi( Ë†Q) and
(Î»)i, agent i can obtain the ith element in the vector Ë†Q
âˆ’1Î» = (Q + Ïƒâˆ’2
w T )âˆ’1Î»
via JOR by using only local information. Finally, using (Ë†y)i and (Î»)i the prediction
meanandvariancecanbeobtainedviathediscrete-timeaverageconsensusalgorithm.
Notice that the sequential update of Ë†Q and Ë†y for sequential observations proposed in
Sect.6.1.3 can be also applied to the distributed algorithm. The distributed algorithm
for sequential ï¬eld prediction under assumptions A.1â€“4 is summarized in Table6.2.
Table 6.2 Distributed algorithm for sequential ï¬eld prediction
Input:
(1) a set of target points S
(2) the topology of sensor network G = (I, E) in which E :=

{i, j} |
pi âˆ’pj
 â‰¤R

Output:
(1) prediction mean

Î¼z0|y | s0 âˆˆS

(2) prediction error variance

Ïƒ2
z0|y | s0 âˆˆS

Assumption:
(A1) agent i âˆˆI is in charge of sampling at point si within a r-disk centered at pi,
i.e., âˆ¥si âˆ’piâˆ¥< r
(A2) the radius of the support of the weighting function satisï¬es 0 < r < R
2
(A3)
agent
i
âˆˆ
I
can
only
locally
communicate
with
neighbors
Ni
:=
{j âˆˆI | {i, j} âˆˆE} deï¬ned by the connected graph G = (V, E)
(A4) agent i âˆˆI initially has rowi(Ë†Q) â†rowi(Q), (Ë†y)i â†0
At
time
t,
agent
i
âˆˆ
I
in
the
network
does
the
following
concur-
rently:
1: take measurement yi from its current location si
2: update rowi(Ë†Q) â†rowi(Ë†Q) + rowi(Ïƒâˆ’2
w Î›T Î›) by exchanging information from
neighbors Ni
3: update (Ë†y)i â†(Ë†y)i +(Ïƒâˆ’2
w Î›T (yâˆ’Î¼))i by exchanging information from neighbors
Ni
4: for s0 âˆˆS do
5:
compute (Î»)i = Î»(s0, pi)
6:
compute (Ë†Q
âˆ’1Î»)i via JOR
7:
compute Î¼z0|y = Î¼(s0) + Î»T Ë†Q
âˆ’1Ë†y via DAC
8:
compute Ïƒ2
z0|y = Î»T Ë†Q
âˆ’1Î» via DAC
9: end for

6.2 Distributed Spatial Prediction
87
The number of robotic sensors and the sampling rule can be modiï¬ed or optimized
to maintain a better quality of the prediction and the corresponding distributed algo-
rithm may be derived in a same way accordingly.
6.3 Simulation and Experiment
In this section, we apply the proposed schemes to both simulation and experimental
study.
6.3.1 Simulation
We ï¬rst apply our proposed prediction algorithms to a numerically generated
Gaussian random ï¬eld z(Â·) based on a GMRF with respect to a graph G = (V, E)
deï¬ned in (6.1). The mean function Î¼(Â·) is assumed to be constant and Î¼ = 5 is
used in the simulation. We assume the generating points of the GMRF, indexed by
V = {1, Â· Â· Â· , n} where n = 30, are located at

p1, Â· Â· Â· , pn

in a 2-D unit area Q.
The edges of the graph are assumed to be E :=
{i, j} |
pi âˆ’p j
 â‰¤R

, where
R = 0.4.
The GMRF Î³ = (Î³(p1), Â· Â· Â· , Î³(pn))T has a zero-mean and the precision matrix
Q is given by
(Q)i j =
â§
â¨
â©
|N(i)| + c0, if j = i,
âˆ’1,
if j âˆˆN(i),
0,
otherwise,
where |N(i)| denotes the degree of node i, i.e., the number of connections it has
to other nodes, c0 = 0.1 is used to ensure Q is positive deï¬nite since a Hermitian
diagonally dominant matrix with real non-negative diagonal entries is positive semi-
deï¬nite [92]. We use compactly supported weighting functions deï¬ned in (6.4) for
both centralized and distributed schemes with different support r. The sensor noise
level is given by Ïƒw = 0.5. Since the optimal sampling is beyond the scope of
this chapter, in the simulation, we use a random sampling strategy in which robotic
sensors sample at random locations at each time instance.
6.3.2 Centralized Scheme
We ï¬rst consider a scenario in which N = 5 agents take samples in the surveillance
region D at certain time instance t âˆˆZ>0 and send the observations to a central
station in which the prediction of the ï¬eld is made.

88
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
(a)
(b)
(c)
(d)
Fig. 6.3
Simulation results for the centralized scheme. a The true ï¬eld, b the predicted ï¬eld at
time t = 1, c the predicted ï¬eld at time t = 5, d the predicted ï¬eld at time t = 20. The generating
points are shown in black circles, and the sampling locations are shown in black crosses
The Gaussian random ï¬eld z(Â·) is shown in Fig.6.3a with the n = 30 generating
points of the built-in GMRF shown in black circles. The predicted ï¬eld at times
t = 1, t = 5, and t = 20 are shown in Figs.6.3b, c and d, respectively. The sampling
locations are shown in black crosses. Clearly, the predicted ï¬eld gets closer to the
true ï¬eld as the number of observations increases. The computational time for ï¬eld
prediction at each time instance remains ï¬xed due to the nice structure of the proposed
Gaussian ï¬eld in (6.1) and its consequent results from Theorem 6.1.
6.3.3 Distributed Scheme
Next, we consider a scenario in which prediction is implemented in a distributed
fashion (Table6.2) under assumptions A.1â€“4 for the resource-constrained mobile
sensor network in Sect.6.2.2. In particular, N = 30 robotic sensors are distributed

6.3 Simulation and Experiment
89
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
25
30
0
5
10
15
20
25
30
(a)
(b)
Fig. 6.4
a Graph G = (V, E). b Sparsity structure of the precision matrix Q
according to the graph G = (V, E), which is connected. Agent i is in charge of the
sampling with in a r-disk centered at pi, where the support r = 0.2 is used. Agent i
has a ï¬xed neighborhood, i.e., N(i) = { j | {i, j} âˆˆE}. In the simulation, h = 0.02
in (6.5) and Ïµ = 0.02 in (6.6) are chosen to ensure the convergence of the JOR
algorithm and the DAC algorithm.
Figure6.4a shows the underlying graph G = (V, E) for the GMRF with the
generating points denoted by black circles and the edges in red lines. The sparsity
of the precision matrix Q is shown in Fig.6.4b. Notice that only 316 out of 900
elements in Q are nonzero which enables the efï¬cient distributed computation. The
true and the predicted ï¬elds at time t = 5 are shown in Figs.6.5a, b, respectively. The
normalized RMS error computed over about 10000 grid points at time t = 5 is 7.8 %.
The computational time at each time instance remains ï¬xed due to the nice structure
of the proposed Gaussian ï¬eld in (6.1) and its consequent results from Theorem 6.1.
6.3.4 Experiment
In order to show the practical usefulness of the proposed approach, we apply the
centralized scheme in Theorem 6.1 on an experimentally obtained observations.
We ï¬rst measured depth values of a terrain on grid points by using a Microsoft
Kinect sensor [115] as shown in Fig.6.6a. As pointed out in Remark 6.1, we make
the structures of weighting functions and the precision matrix as functions of the
locations of generating points. In particular, two generating points are neighbors if
and only if their corresponding Voronoi cells intersect. The individual weighting
function takes the same form as in (6.4) and its support size ri is selected to be the
largest distance between the generating point i and itâ€™s neighbors. We then predict the

90
6
New Efï¬cient Spatial Model with Built-In Gaussian Markov Random Fields
0
0.5
1
0
0.5
1
5.8
6
4.8
5
5.2
5.4
5.6
0
0.5
1
0
0.5
1
5.8
6
4.8
5
5.2
5.4
5.6
(a)
(b)
Fig. 6.5
Simulation results for the distributed scheme. a The true ï¬eld, b the predicted ï¬eld at
time t = 5. The generating points are shown in circles, and the sampling locations are shown in
crosses
10
20
30
40
50
60
5
10
15
20
25
30
35
40
45
780
790
800
810
820
830
840
10
20
30
40
50
60
5
10
15
20
25
30
35
40
45
780
790
800
810
820
830
840
(a)
(b)
Fig. 6.6
a True ï¬eld on grid positions obtained by the Kinect sensor and randomly sampled
positions indicated in black crosses. b The ï¬tted Gaussian random ï¬eld with a build-in GMRF with
respect to the Delaunay graph
ï¬eld by our model with 20 estimated generating points given by the ML estimator
in (6.3) using a subset of experimental observations, i.e., 200 randomly sampled
observations denoted by crosses in Fig.6.6a. The estimated positions of generating
points along with the predicted ï¬eld are shown in Fig.6.6b. In this experiment, it is
clear to see that our approach effectively produces the predicted ï¬eld, which is very
close to the true ï¬eld for the case of unknown generating points.

Chapter 7
Fully Bayesian Spatial Prediction
Using Gaussian Markov Random Fields
In this chapter, we consider the problem of predicting a large scale spatial ï¬eld using
successive noisy measurements obtained by mobile sensing agents. The physical
spatial ï¬eld of interest is discretized and modeled by a Gaussian Markov random
ï¬eld (GMRF) with unknown hyperparameters. From a Bayesian perspective, we
design a sequential prediction algorithm to exactly compute the predictive inference
of the random ï¬eld. The main advantages of the proposed algorithm are: (1) the
computational efï¬ciency due to the sparse structure of the precision matrix, and
(2) the scalability as the number of measurements increases. Thus, the predic-
tion algorithm correctly takes into account the uncertainty in hyperparameters in
a Bayesian way and also is scalable to be usable for the mobile sensor networks
with limited resources. An adaptive sampling strategy is also designed for mobile
sensing agents to ï¬nd the most informative locations in taking future measurements
in order to minimize the prediction error and the uncertainty in hyperparameters. The
effectiveness of the proposed algorithms is illustrated by a numerical experiment.
In Chap.5, we designed a sequential Bayesian prediction algorithm to deal with
unknown bandwidths by using a compactly supported kernel and selecting a subset
of collected measurements. In this chapter, we instead seek a fully Bayesian approach
overadiscretizedsurveillanceregionsuchthattheBayesianspatialpredictionutilizes
all collected measurements in a scalable fashion. In contrast to this chapter, Chap.6
focuses on efï¬cient spatial modeling using a GMRF with known hyperparameters.
A distributed version of the prediction algorithm in this chapter for a special case
can be found in [5].
In Sect.7.1, we model the physical spatial ï¬eld as a GMRF with unknown hyper-
parameters and formulate the estimation problem from a Bayesian point of view. In
Sect.7.2, we design a sequential Bayesian estimation algorithm to effectively and
efï¬ciently compute the exact predictive inference of the spatial ï¬eld. The proposed
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_7
91

92
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
algorithm often takes only seconds to run even for a very large spatial ï¬eld, as will be
demonstrated in this chapter. Moreover, the algorithm is scalable in the sense that the
running time does not grow as the number of observations increases. In particular,
the scalable prediction algorithm does not rely on the subset of samples to obtain
scalability (as was done in Chap.5), correctly fusing all collected measurements. In
Sect.7.4, an adaptive sampling strategy for mobile sensor networks is designed to
largely improve the quality of prediction and to reduce the uncertainty in the hyper-
parameter estimation simultaneously. We demonstrate the effectiveness through a
simulation study in Sect.7.5.
7.1 Spatial Field Model
In what follows, we specify the models for the spatial ï¬eld and the mobile sen-
sor network. Notice that in this chapter, we slightly change notation for notational
simplicity.
Let Qâˆ—âŠ‚RD denote the spatial ï¬eld of interest. We discretize the ï¬eld into nâˆ—
spatial sites Sâˆ—:=

s1, . . . , snâˆ—

and let zâˆ—= (z1, . . . , znâˆ—)T âˆˆRnâˆ—be the value of
the ï¬eld (e.g., the temperature). Due to the irregular shape a spatial ï¬eld may have,
we extend the ï¬eld such that n â‰¥nâˆ—sites denoted by S := {s1, . . . , sn} are on a
regular grid. The latent variable zi := z(si) âˆˆR is modeled by
zi = Î¼(si) + Î·i,
âˆ€1 â‰¤i â‰¤n,
(7.1)
where si âˆˆS âŠ‚RD is the ith site location. The mean function Î¼ : RD â†’R is
deï¬ned as
Î¼(si) = f (si)T Î²,
where f (si) = ( f1(si), . . . , f p(si))T âˆˆRp is a known regression function, and
Î² = (Î²1, . . . , Î²p)T âˆˆRp is an unknown vector of regression coefï¬cients. We deï¬ne
Î· = (Î·1, . . . , Î·n)T âˆˆRn as a zero-mean Gaussian Markov random ï¬eld (GMRF)
[92] denoted by
Î· âˆ¼N

0, Qâˆ’1
Î·|Î¸

,
where the inverse covariance matrix (or precision matrix) QÎ·|Î¸ âˆˆRnÃ—n is a function
of a hyperparameter vector Î¸ âˆˆRM.
There exists many different choices of the GMRF (i.e., the precision matrix QÎ·|Î¸)
[92]. For instance, we can choose one with the full conditionals in (7.2) (with obvious
notation as shown in [92]).

7.1 Spatial Field Model
93
E(Î·i|Î·âˆ’i, Î¸) =
1
4 + a2
â›
âœâœâœâœâ
2a
â—¦â—¦â—¦â—¦â—¦
â—¦â—¦â€¢ â—¦â—¦
â—¦â€¢ â—¦â€¢ â—¦
â—¦â—¦â€¢ â—¦â—¦
â—¦â—¦â—¦â—¦â—¦
âˆ’2
â—¦â—¦â—¦â—¦â—¦
â—¦â€¢ â—¦â€¢ â—¦
â—¦â—¦â—¦â—¦â—¦
â—¦â€¢ â—¦â€¢ â—¦
â—¦â—¦â—¦â—¦â—¦
âˆ’1
â—¦â—¦â€¢ â—¦â—¦
â—¦â—¦â—¦â—¦â—¦
â€¢ â—¦â—¦â—¦â€¢
â—¦â—¦â—¦â—¦â—¦
â—¦â—¦â€¢ â—¦â—¦
â
âŸâŸâŸâŸâ 
,
Var(Î·i|Î·âˆ’i, Î¸) = (4 + a2)Îº.
(7.2)
Figure7.1 displays the elements of the precision matrix related to a single location
that explains (7.2). The hyperparameter vector is deï¬ned as Î¸ = (Îº, Î±)T âˆˆR2
>0,
where Î± = a âˆ’4. The resulting GMRF accurately represents a Gaussian random
ï¬eld with the MatÃ©rn covariance function [116]
C(r) = Ïƒ2
f
21âˆ’Î½
Î“ (Î½)
âˆš
2Î½r
â„“
Î½
KÎ½
âˆš
2Î½r
â„“

,
where KÎ½(Â·) is a modiï¬ed Bessel function [53], with order Î½ = 1, a bandwidth
â„“= 1/âˆšÎ±, and vertical scale Ïƒ2
f = 1/4Ï€Î±Îº. The hyperparameter Î± > 0 guarantees
the positive deï¬niteness of the precision matrix QÎ·|Î¸. In the case where Î± = 0, the
resulting GMRF is a second-order polynomial intrinsic GMRF [92, 117]. Notice that
the precision matrix is sparse which contains only small number of non-zero ele-
ments. This property will be exploited for fast computation in the following sections.
Example 7.1 Consider a spatial ï¬eld of interest Qâˆ—âˆˆ[0, 100] Ã— [0, 50]. We ï¬rst
divide the spatial ï¬eld into a 100 Ã— 50 regular grid with equal areas 1, which makes
nâˆ—= 5000. We then extend the the ï¬eld such that 120 Ã— 70 grids (i.e., n = 8400)
are constructed on the extended ï¬eld Q = [âˆ’10, 110] Ã— [âˆ’10, 60]. The precision
matrix QÎ·|Î¸ introduced above is chosen with the regular lattices wrapped on a torus
[92]. In this case, only 0.15 % elements in the sparse matrix QÎ·|Î¸ are non-zero.
The numerically generated ï¬elds with the mean function Î¼(si) = Î² = 20, and the
hyperparameter vector Î¸ = (Îº, Î±)T being different values are shown in Fig.7.2.
Fig. 7.1 Elements of the
precision matrix Q related to
a single location

94
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
0
20
40
60
80
100
0
10
20
30
40
50
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
15
20
25
30
(a)
(b)
(c)
Fig. 7.2 Numerically generated spatial ï¬elds deï¬ned in (7.1) with Î¼(si) = Î² = 20, and QÎ·|Î¸
constructed using (7.2) with hyperparameters being a Î¸ = (4, 0.0025)T , b Î¸ = (1, 0.01)T , and
c Î¸ = (0.25, 0.04)T
7.2 Bayesian Predictive Inference
In this section, we propose a Bayesian inference approach to make predictive infer-
ences of a spatial ï¬eld zâˆ—âˆˆRnâˆ—.
First, we assign the vector of regression coefï¬cients Î² âˆˆRp with a Gaussian prior,
namely Î² âˆ¼N

0, Tâˆ’1
, where the precision matrix T âˆˆRpÃ—p is often chosen as a
diagonal matrix with small diagonal elements when no prior information is available.
Hence, the distribution of latent variables z given Î² and the hyperparameter vector
Î¸ is Gaussian, i.e.,

7.2 Bayesian Predictive Inference
95
z|Î², Î¸ âˆ¼N

FÎ², Qâˆ’1
Î·|Î¸

,
where F = ( f (s1), . . . , f (sn))T âˆˆRnÃ—p. For notational simplicity, we denote the
full latent ï¬eld of dimension n + p by x = (zT , Î²T )T . Then, for a given hyperpa-
rameter vector Î¸, the distribution Ï€(x|Î¸) is Gaussian obtained by
Ï€(x|Î¸) = Ï€(z|Î², Î¸)Ï€(Î²)
âˆexp

âˆ’1
2(z âˆ’FÎ²)T QÎ·|Î¸(z âˆ’FÎ²) âˆ’1
2Î²T TÎ²

= exp

âˆ’1
2xT Qx|Î¸x

,
where the precision matrix Qx|Î¸ âˆˆR(n+p)Ã—(n+p) is deï¬ned by
Qx|Î¸ =

QÎ·|Î¸
âˆ’QÎ·|Î¸F
âˆ’FT QÎ·|Î¸ FT QÎ·|Î¸F + T

.
By the matrix inversion lemma, the covariance matrix x|Î¸ âˆˆR(n+p)Ã—(n+p) can be
obtained by
x|Î¸ = Qâˆ’1
x|Î¸ =

Qâˆ’1
Î·|Î¸ + FTâˆ’1FT FTâˆ’1
(FTâˆ’1)T
Tâˆ’1

.
At time t âˆˆZ>0, we have a collection of observational data y1:t âˆˆRNt obtained
by the mobile sensing agents over time. Let A1:t = (A1, . . . , At) âˆˆR(n+p)Ã—Nt,
where AÏ„ âˆˆR(n+p)Ã—N is deï¬ned by
(AÏ„)i j =
1, if si = qÏ„, j,
0, otherwise.
Then the covariance matrix of y1:t can be obtained by
R1:t = AT
1:tx|Î¸A1:t + P1:t,
where P1:t = Ïƒ2
wI âˆˆRNtÃ—Nt. By Gaussian process regression [53], the full condi-
tional distribution of x is also Gaussian, i.e.,
x|Î¸, y1:t âˆ¼N(Î¼x|Î¸,y1:t , x|Î¸,y1:t ),
where
x|Î¸,y1:t = x|Î¸ âˆ’x|Î¸A1:tRâˆ’1
1:t AT
1:tx|Î¸,
Î¼x|Î¸,y1:t = x|Î¸A1:tRâˆ’1
1:t y1:t.
(7.3)

96
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
The posterior distribution of the hyperparameter vector Î¸ can be obtained via
Ï€(Î¸|y1:t) âˆÏ€(y1:t|Î¸)Ï€(Î¸),
where the log likelihood function is deï¬ned by
log Ï€(y1:t|Î¸) = âˆ’1
2yT
1:tRâˆ’1
1:t y1:t âˆ’1
2 log det R1:t âˆ’Nt
2 log 2Ï€.
(7.4)
If a discrete prior on the hyperparameter vector Î¸ is chosen with a support  =
{Î¸1, . . . , Î¸L}, the posterior predictive distribution Ï€(x|y1:t) can be obtained by
Ï€(x|y1:t) =

â„“
Ï€(x|Î¸â„“, y1:t)Ï€(Î¸â„“|y1:t).
(7.5)
The predictive mean and variance then follow as
Î¼xi|y1:t =

â„“
Î¼xi|Î¸â„“,y1:t Ï€(Î¸â„“|y1:t),
Ïƒ2
xi|y1:t =

â„“
Ïƒ2
xi|Î¸â„“,y1:t Ï€(Î¸â„“|y1:t) +

â„“
(Î¼xi|Î¸â„“,y1:t âˆ’Î¼xi|y1:t )2Ï€(Î¸â„“|y1:t),
(7.6)
where Î¼xi|Î¸â„“,y1:t is the ith element in Î¼x|Î¸â„“,y1:t , and Ïƒ2
xi|Î¸â„“,y1:t is the ith diagonal
element in x|Î¸â„“,y1:t .
Remark 7.1 The discrete prior Ï€(Î¸) greatly reduced the computational complexity
in that it enables summation in (7.5) instead of numerical integration which has to be
performed with a choice of continuous prior distribution. However, the computation
of the full conditional distribution Ï€(x|Î¸, y1:t) in (7.3) and the likelihood Ï€(y1:t|Î¸)
(7.4) requires the inversion of the covariance matrix R1:t, whose size grows as the
time t increases. Thus, the running time grows fast as new observations are collected
and it will soon become intractable.
7.3 Sequential Bayesian Inference
Inthissection,weexploitthesparsityoftheprecisionmatrix,andproposeasequential
Bayesian prediction algorithm which can be performed in constant time and fast
enough even for a very large spatial ï¬eld.

7.3 Sequential Bayesian Inference
97
7.3.1 Update Full Conditional Distribution
First, we rewrite the full conditional distribution Ï€(x|Î¸, y1:t) in terms of the sparse
precision matrix Qx|Î¸ as follows
x|Î¸, y1:t âˆ¼N(Î¼x|Î¸,y1:t , Qâˆ’1
x|Î¸,y1:t ),
where
Qx|Î¸,y1:t = Qx|Î¸ + A1:tPâˆ’1
1:t AT
1:t
Î¼x|Î¸,y1:t = Qâˆ’1
x|Î¸,y1:t A1:tPâˆ’1
1:t y1:t.
(7.7)
From here on, we will use Qt|Î¸ = Qx|Î¸,y1:t and Î¼t|Î¸ = Î¼x|Î¸,y1:t , for notational
simplicity. Notice that (7.7) can be represented by the following recursion
Qt|Î¸ = Qtâˆ’1|Î¸ + 1
Ïƒ2w
N

i=1
ut,iuT
t,i,
bt = btâˆ’1 + 1
Ïƒ2w
N

i=1
ut,i yt,i,
(7.8)
where bt = Qt|Î¸Î¼t|Î¸ with initial conditions
Q0|Î¸ = Qx|Î¸,y1:0 = Qx|Î¸, and b0 = 0.
In (7.8), we have deï¬ned ut,i âˆˆRn+p as
(ut,i) j =
1, if s j = qt,i,
0, otherwise.
Lemma 7.1 For a given Î¸ âˆˆÎ¸, the full conditional mean and variance, i.e., Î¼t|Î¸
and Qt|Î¸, can be updated in short constant time given Qtâˆ’1|Î¸ and btâˆ’1.
Proof The update of Qt|Î¸ and bt can be obviously computed in constant time. Hence
Î¼t|Î¸ can be obtained by solving a linear equation Qt|Î¸Î¼t|Î¸ = bt. Due to the sparse
structure of Qt|Î¸, this operation can be done in a very short time. Moreover, notice
that Qt|Î¸ and Qtâˆ’1|Î¸ have the same sparsity structure and hence the computational
complexity remains ï¬xed.
â–¡
From Lemma7.1, we can compute Î¼xi|Î¸,y1:t in (7.6) in constant time. In order to
ï¬nd Ïƒ2
xi|Î¸,y1:t in (7.6), we need to compute x|Î¸,y1:t which requires the inversion of
Qt|Î¸. The inversion of a big matrix (even a sparse matrix) is undesirable. However,
notice that only the diagonal elements in Qâˆ’1
t|Î¸ are needed. Following the Sherman-
Morrison formula (see AppendixA.2.2) and using (7.8), Ïƒ2
xi|Î¸,y1:t can be obtained

98
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
exactly via
diag(Qâˆ’1
t|Î¸) = diag
â›
â

Qtâˆ’1|Î¸ +
N

i=1
ut,iuT
t,i
âˆ’1â
â 
= diag(Qâˆ’1
tâˆ’1|Î¸) âˆ’
N

i=1
ht,i|Î¸ â—¦ht,i|Î¸
Ïƒ2w + uT
t,iht,i|Î¸
,
ht,i|Î¸ = Bâˆ’1
t,i|Î¸ut,i,
Bt,i|Î¸ = Qtâˆ’1|Î¸ + 1
Ïƒ2w
i
j=1
ut, juT
t, j,
(7.9)
where â—¦denotes the element-wise produce. By this way, the computation can be done
efï¬ciently in constant time.
7.3.2 Update Likelihood
Next, we derive the update rule for the log likelihood function. We have the following
proposition.
Proposition 7.1 The log likelihood function log Ï€(y1:t|Î¸) in (7.4) can be obtained by
log Ï€(y1:t|Î¸) = ct + gt,Î¸ + 1
2bT
t Î¼t|Î¸ âˆ’Nt
2 log(2Ï€Ïƒ2
w)
(7.10)
where
ct = ctâˆ’1 âˆ’
1
2Ïƒ2w
N

i=1
y2
t,i,
c0 = 0,
gt|Î¸ = gtâˆ’1|Î¸ âˆ’1
2
N

i=1
log

1 + 1
Ïƒ2w
uT
t,iht,i|Î¸

,
g0|Î¸ = 0,
with ht,i|Î¸ deï¬ned in (7.9).
Proof The inverse of the covariance matrix R1:t can be obtained by
Râˆ’1
1:t = (AT
1:tQâˆ’1
0|Î¸A1:t + P1:t)âˆ’1
= Pâˆ’1
1:t âˆ’Pâˆ’1
1:t AT
1:t(Q0|Î¸ + A1:tPâˆ’1
1:t AT
1:t)âˆ’1A1:tPâˆ’1
1:t
= Pâˆ’1
1:t âˆ’Pâˆ’1
1:t AT
1:tQâˆ’1
t|Î¸A1:tPâˆ’1
1:t .

7.3 Sequential Bayesian Inference
99
Similarly, the log determinant of the covariance matrix 1:t can be obtained by
log det R1:t = log det(AT
1:tQâˆ’1
0|Î¸A1:t + P1:t)
= log det(I + 1
Ïƒ2w
AT
1:tQâˆ’1
0|Î¸A1:t) + Nt log Ïƒ2
w
= log det(Q0|Î¸ + 1
Ïƒ2w
t
Ï„=1
N

i=1
uÏ„,iuT
Ï„,i) âˆ’log det(Q0|Î¸) + Nt log Ïƒ2
w
=
t
Ï„=1
log(1 + uT
Ï„ Qâˆ’1
Ï„âˆ’1|Î¸uÏ„) + Nt log Ïƒ2
w.
Hence, we have
log Ï€(y1:t|Î¸)
= âˆ’1
2yT
1:tRâˆ’1
1:t y1:t âˆ’1
2 log det R1:t âˆ’Nt
2 log 2Ï€
= âˆ’1
2yT
1:tPâˆ’1
1:t y1:t + 1
2bT
t Î¼t|Î¸ âˆ’1
2
t
Ï„=1
N
i=1
log(1 + uT
Ï„,iBâˆ’1
Ï„,i|Î¸uÏ„,i) âˆ’Nt
2 log(2Ï€Ïƒ2
w).
â–¡
Lemma 7.2 For a given Î¸ âˆˆÎ¸, the log likelihood function, i.e., log Ï€(y1:t|Î¸) can
be computed in short constant time.
Proof The result follows directly from Proposition7.1.
â–¡
7.3.3 Update Predictive Distribution
Combining the results in Lemmas7.1, 7.2, and (7.5), (7.6), we summarize our results
in the following theorem.
Theorem 7.1 The predictive distribution in (7.5) (or the predictive mean and vari-
ance in (7.6)) can be obtained in constant time as time t increases.
WesummarizetheproposedsequentialBayesianpredictionalgorithminTable7.1.

100
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
Table 7.1 Sequential Bayesian predictive inference
Input:
(1) prior distribution of Î¸ âˆˆÎ˜, i.e., Ï€(Î¸)
Output:
(1) predictive mean

Î¼xi|y1:t
nâˆ—
i=1
(2) predictive variance

Ïƒ2
xi|y1:t
nâˆ—
i=1
Initialization:
1: initialize b = 0, c = 0
2: for Î¸ âˆˆÎ˜ do
3:
initialize QÎ¸, gÎ¸ = 0
4:
compute diag(Qâˆ’1
Î¸ )
5: end for
At time t âˆˆZ>0, do:
1: for 1 â‰¤i â‰¤N do
2:
obtain new observations yt,i collected at current locations qt,i
3:
ï¬nd the index k corresponding to qt,i, and set u = ek
4:
update b = b + yt,i
Ïƒ2
w u
5:
update c = c âˆ’
1
2Ïƒ2
w y2
t,i
6:
for Î¸ âˆˆÎ˜ do
7:
compute hÎ¸ = Qâˆ’1
Î¸ u
8:
update diag(Qâˆ’1
Î¸ ) = diag(Qâˆ’1
Î¸ ) âˆ’
hÎ¸â—¦hÎ¸
Ïƒ2
w+uT hÎ¸
9:
update QÎ¸ via QÎ¸ = QÎ¸ +
1
Ïƒ2
w uuT
10:
update gÎ¸ = gÎ¸ âˆ’1
2 log(1 +
1
Ïƒ2
w uT h)
11:
end for
12: end for
13: for Î¸ âˆˆÎ˜ do
14:
compute Î¼Î¸ = Qâˆ’1
Î¸ b
15:
compute the likelihood via
log Ï€(Î¸|y1:t) = c + gÎ¸ + 1
2bT Î¼Î¸
16: end for
17: compute the posterior distribution via
Ï€(Î¸|y1:t) âˆÏ€(y1:t|Î¸)Ï€(Î¸)
18: compute the predictive mean via
Î¼xi|y1:t = 
â„“(Î¼Î¸â„“)iÏ€(Î¸â„“|y1:t)
19: compute the predictive variance via
Ïƒ2
xi|y1:t = 
â„“(diag(QÎ¸â„“))i + ((Î¼Î¸â„“)i âˆ’Î¼xi|y1:t)2
Ï€(Î¸â„“|y1:t)

7.4 Adaptive Sampling
101
7.4 Adaptive Sampling
In the previous section, we have designed a sequential Bayesian prediction algorithm
for estimating the scalar ï¬eld at time t. In this section, we propose an adaptive
sampling strategy for ï¬nding most informative sampling locations at time t + 1 for
mobile sensing agents in order to improve the quality of prediction and reduce the
uncertainty in hyper parameters simultaneously.
In our previous work [118], we have proposed to use the conditional entropy
H(zâˆ—|Î¸ = Ë†Î¸t, y1:t+1) as an optimality criterion, where
Ë†Î¸t = arg max
Î¸
Ï€(Î¸|y1:t),
is the maximum a posterior (MAP) estimate based on the cumulative observations
up to current time t. Although this approach greatly simpliï¬es the computation, it
does not count for the uncertainty in estimating the hyperparameter vector Î¸.
In this chapter, we propose to use the conditional entropy H(zâˆ—, Î¸|yt+1, y1:t)
which represents the uncertainty remained in both random vectors zâˆ—and Î¸ by know-
ing future measurements in the random vector yt+1. Notice that the measurements
y1:t have been observed and treated as constants. It can be obtained by
H(zâˆ—, Î¸|yt+1, y1:t) = H(zâˆ—|Î¸, yt+1, y1:t) + H(Î¸|yt+1, y1:t)
= H(zâˆ—|Î¸, yt+1, y1:t) + H(yt+1|Î¸, y1:t)
+ H(Î¸|y1:t) âˆ’H(yt+1|y1:t).
Notice that we have the following Gaussian distributions (the means will not be
exploited and hence not shown here):
zâˆ—|Î¸, yt+1, y1:t âˆ¼N(Â·, xâˆ—|Î¸,y1:t+1),
yt+1|Î¸, y1:t âˆ¼N(Â·, yt+1|Î¸,y1:t + Ïƒ2
wI),
yt+1|y1:t
approx
âˆ¼
N(Â·, yt+1|y1:t + Ïƒ2
wI),
in which the last one is approximated using (7.6). Notice that the approximation is
used here to avoid numerical integration over the random vector yt+1 which needs to
be done using Monte Carlo methods. Moreover, the entropy H(Î¸|y1:t) = c is a con-
stant since y1:t is known. Since the entropy for a multivariate Gaussian distribution
has a closed-from expression [72], we have

102
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
H(zâˆ—, Î¸|yt+1, y1:t) =

â„“
1
2 log

(2Ï€e)nâˆ—det(xâˆ—|Î¸â„“,y1:t+1)

Ï€(Î¸â„“|y1:t)
+

â„“
1
2 log

(2Ï€e)N det(qt+1|Î¸â„“,y1:t )

Ï€(Î¸â„“|y1:t)
âˆ’1
2 log

(2Ï€e)N det(qt+1|y1:t )

+ c.
It can also be shown that
log det(xâˆ—|Î¸â„“,y1:t+1) = log det(Qâˆ’1
t+1|Î¸â„“)(Sâˆ—)
= log det(Qt+1|Î¸â„“)(âˆ’Sâˆ—) âˆ’log det(Qt+1|Î¸â„“),
where A(Sâˆ—) denotes the submatrix of A formed by the ï¬rst 1 to nâˆ—rows and columns
(recall that Sâˆ—=

s1, . . . , snâˆ—

). Notice that the term log det(Qt+1|Î¸â„“)(âˆ’Sâˆ—) is a
constant since agents only sample at Sâˆ—. Hence, the optimal sampling locations at
time t + 1 can be determined by solving the following optimization problem
qâˆ—
t+1 = arg
min
{qt+1,iâˆˆRt,i}
H(zâˆ—, Î¸|yt+1, y1:t)
= arg
min
{qt+1,iâˆˆRt,i}

â„“
âˆ’log det(Qt+1|Î¸â„“)Ï€(Î¸â„“|y1:t)
+

â„“
log det(yt+1|Î¸â„“,y1:t )Ï€(Î¸â„“|y1:t) âˆ’log det(yt+1|y1:t ),
where Rt,i =

s |
s âˆ’qt,i
 â‰¤r, s âˆˆSâˆ—

(in which r âˆˆR>0 is the maximum
distance an agent can move between time instances) is the reachable set at time t.
This combinatorial optimization problem can be solved using a greedy algorithm,
i.e., ï¬nding the sub-optimal sampling locations for agents in sequence.
7.5 Simulation
In this section, we demonstrate the effectiveness of the proposed sequential Bayesian
inference algorithm and the adaptive sampling strategy through a numerical experi-
ment.
Consider a spatial ï¬eld introduced in Example7.1. The mean function is a constant
Î² = 20. We choose the precision matrix Qx|Î¸ with hyperparameters Î± = 0.01
equivalent to a bandwidth â„“= 1/âˆšÎ± = 10, and Îº = 1 equivalent to a vertical
scale Ïƒ2
f = 1/4Ï€Î±Îº â‰ˆ8. The numerically generated ï¬eld is shown in Fig.7.2b. The
precision matrix T âˆˆR of Î² is chosen to be 10âˆ’4. The measurement noise level
Ïƒw = 0.2 is assumed to be known. A discrete uniform distribution is selected with a
support shown in Fig.7.3. N = 5 mobile sensing agents take measurements at time

7.5 Simulation
103
0.25
1
4
0.0025
0.01
0.04
0
0.1
0.2
0.3
0.4
Îº
Î±
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
Îº
Î±
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
Îº
Î±
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
Îº
Î±
(a)
(b)
(c)
(d)
Fig. 7.3 Posterior distributions of Î¸, i.e., Ï€(Î¸|y1:t), at a t = 1, b t = 5, c t = 10, and d t = 20
t âˆˆZ>0, starting from locations shown in Fig.7.4b (in white dots). The maximum
distance each agent can travel between time instances is chosen to be r = 5.
Figure7.4 shows the predicted ï¬elds and the prediction error variances at times
t = 1, 5, 10, 20. The trajectories of agents are shown in white circles with the cur-
rent locations shown in white dots. It can be seen that agents try to cover the ï¬eld
of interest as time evolves. The predicted ï¬eld (the predictive mean) gets closer to
the true ï¬eld (see Fig.7.2b) and the prediction error variances become smaller as
more observations are collected. Figure7.3 shows the posterior distribution of the
hyperparameters in Î¸. Clearly, as more measurements are obtained, this posterior
distribution becomes peaked at the true value (1,0.01). Figure7.5a shows the pre-
dicted distribution of the estimated mean Î² as time evolves. In Fig.7.5b, we can see
that the RMS error computed via
rms(t) =



 1
nâˆ—
nâˆ—

i=1
(Î¼zi|y1:t âˆ’zi)2,

104
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
7
8
(a)
(b)
(c)
(d)
Fig. 7.4 Predicted ï¬elds at a t = 1, c t = 5, e t = 10, and g t = 20. Prediction error variances at
b t = 1, d t = 5, f t = 10, and h t = 20

7.5 Simulation
105
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
(e)
(f)
(g)
(h)
Fig. 7.4 (continued)

106
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
Fig. 7.5 a Estimated Î², and
b root mean square error
10
15
20
25
30
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
Î²
t=1
t=5
t=10
t=20
0
5
10
15
20
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
2.6
2.8
t
(a)
(b)
decreases as time increases, which shows the effectiveness of the proposed scheme.
The most important contribution is that the computation time at each time step
does not grow as the number of measurements increases.

Appendix A
Mathematical Background
A.1 Gaussian Identities
ThemultivariateGaussiandistributionofarandomvectorx âˆˆRn (i.e.,x âˆ¼N(Î¼, ))
has a joint probability density function (pdf) given by
p(x; Î¼, ) =
1
(2Ï€)âˆ’n/2||âˆ’1/2 exp

âˆ’1
2(x âˆ’Î¼)T âˆ’1(x âˆ’Î¼)

,
where Î¼ âˆˆRn is the mean vector, and  âˆˆRnÃ—n is the covariance matrix.
Now, suppose x consists of two disjoint subsets xa and xb, i.e.,
x =
xa
xb

.
The corresponding mean vector Î¼ and covariance matrix Î£ can be written as
Î¼ =
Î¼a
Î¼b

,
Î£ =
aa ab
ba bb

,
where ab = T
ba due to the symmetry of . Then, the marginal distribution of xa
is given by
xa âˆ¼N(Î¼a, aa),
and the conditional distribution of xa given xb is given by
xa|xb âˆ¼N(Î¼a|b, a|b),
where
Î¼a|b = Î¼a + abâˆ’1
bb (xb âˆ’Î¼b)
a|b = aa âˆ’abâˆ’1
bb ba.
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9
107

108
Appendix A: mathematical background
A.2 Matrix Inversion Lemma
Matrices canbeinvertedblockwisebyusingthefollowinganalyticinversionformula:
 A B
BT C
âˆ’1
=
Aâˆ’1 + Aâˆ’1B(C âˆ’BT Aâˆ’1B)âˆ’1BT Aâˆ’1 âˆ’Aâˆ’1B(C âˆ’BT Aâˆ’1B)âˆ’1
âˆ’(C âˆ’BT Aâˆ’1B)âˆ’1BT Aâˆ’1
(C âˆ’BT Aâˆ’1B)âˆ’1

,
where A, B, and C are matrix subblocks of arbitrary size. Matrices A and C âˆ’
BT Aâˆ’1B must be nonsingular.
A.2.1 Woodbury Identity
The Woodbury matrix identity is
(A + UCV)âˆ’1 = Aâˆ’1 âˆ’Aâˆ’1U

Câˆ’1 + VAâˆ’1U
âˆ’1
VAâˆ’1,
where A, U, C, and V denote matrices with appropriate size.
A.2.2 Shermanâ€“Morrison Formula
Suppose A âˆˆRnÃ—n is invertible and u âˆˆRn and v âˆˆRn are vectors. Assume that
1 + vT Aâˆ’1u Ì¸= 0, the Shermanâ€“Morrison formula states that
(A + uvT )âˆ’1 = Aâˆ’1 âˆ’Aâˆ’1uvT Aâˆ’1
1 + vT Aâˆ’1u
.
A.3 Generating Gaussian Processes
In order to implement algorithms in simulation studies, we need to generate multi-
variate Gaussian samples from N(Î¼, ) with arbitrary mean Î¼ and covariance matrix
. In what follows, we introduce two approaches.

Appendix A: mathematical background
109
A.3.1 Cholesky Decomposition
Given an arbitrary mean Î¼ and a positive deï¬nite covariance matrix , the algorithm
generates multivariate Gaussian samples is shown in TableA.1.
A.3.2 Circulant Embedding
Consider a 1D zero-mean stationary Gaussian process z(x) with a covariance func-
tion C(x, xâ€²). The covariance matrix  of z(x) sampled on the equispaced grids
Î© =

x(1), . . . , x(n)	
has entries ()pq = C(|x(p) âˆ’x(q)|). Notice that the covari-
ance matrix  is a positive semi-deï¬nite symmetric Toeplitz matrix which can be
characterized by its ï¬rst row r = row1().
The key idea behind circulant embedding method is to construct a circulant matrix
S that contains  as its upper-left submatrix. The reason for seeking a circulant
embedding is the fact that, being a m Ã— m circulant matrix, S has an eigendecompo-
sition S = (1/m)FFH, where F is the standard FFT matrix of size m with entries
(F)pq = exp(2Ï€ipq/m), FH is the conjugate transpose of F, and  is a diagonal
matrix whose diagonal entries form the vector Ëœs = Fs (s is the ï¬rst row of S).
Given a positive semi-deï¬nite circulant extension S of , the algorithm generates
the realization of z(x) sampled on Î© is shown in TableA.2. Extension to multidi-
mensional cases can be found in [107].
Table A.1 Generating multivariate Gaussian samples by Cholesky decomposition
1: compute the Cholesky decomposition of the positive deï¬nite symmetric covariance
matrix Î£ = LLT , where L is a lower triangular matrix
2: generate u âˆ¼N(0, I) by multiple separate calls to the scalar Gaussian generator
3: compute x = Î¼ + Lu which has desired normal distributed with mean Î¼ and
covariance matrix LE[uuT ]LT = LLT = Î£
Table A.2 Generating multivariate Gaussian samples by circulant embedding
1: compute via the FFT the discrete Fourier transform of Ëœs = Fs and form the vector
(Ëœs/m)1/2
2: generate a vector Ïµ = Ïµ1 + iÏµ2 of dimension m with Ïµ1 âˆ¼N(0, I) and Ïµ2 âˆ¼N(0, I)
being independent and real random variables
3: compute a vector Ëœe = Ïµ â—¦(Ëœs/m)1/2
4: compute via FFT the discrete Fourier transform e = FËœe. The real and imaginary
parts of the ï¬rst n entries in e yield two independent realizations of z(x) on Î©

References
1. Y. Xu, J. Choi, Adaptive sampling for learning Gaussian processes using mobile sensor net-
works. Sensors 11(3), 3051â€“3066 (2011)
2. Y. Xu, J. Choi, S. Oh, Mobile sensor network navigation using Gaussian processes with
truncated observations. IEEE Transactions on Robotics 27(6), 1118â€“1131 (2011)
3. Y. Xu, J. Choi, S. Dass, T. Maiti, Sequential Bayesian prediction and adaptive sampling
algorithms for mobile sensor networks. IEEE Trans. Autom. Control 57(8), 2078â€“2084 (2012)
4. Y. Xu, J. Choi, Spatial prediction with mobile sensor networks using Gaussian processes with
built-in Gaussian markov random ï¬elds. Automatica 48(8), 1735â€“1740 (2012)
5. Y. Xu, J. Choi, S. Dass, T. Maiti, Efï¬cient Bayesian spatial prediction with mobile sensor
networks using Gaussian Markov random ï¬elds. Automatica 49(12), 3520â€“3530 (2013)
6. M. Jadaliha, Y. Xu, J. Choi, N.S. Johnson, W. Li, Gaussian process regression for sensor
networks under localization uncertainty. IEEE Trans. Signal Process. 61(2), 223â€“237 (2013)
7. L.S. Muppirisetty, T. Svensson, H. Wymeersch, Spatial wireless channel prediction under
location uncertainty, 4 (2015). arXiv:1501.0365
8. S.Choi,M.Jadaliha,J.Choi,S.Oh,DistributedGaussianprocessregressionunderlocalization
uncertainty. J. Dyn. Syst., Meas. Control 137(3) (2015)
9. I.F. Akyildiz, W. Su, Y. Sankarasubramaniam, E. Cayirci, Wireless sensor networks: a survey.
Comput. Netw. 38(4), 393â€“422 (2002)
10. D. Culler, D. Estrin, M. Srivastava, Guest editorsâ€™ introduction: overview of sensor networks.
Computer 37(8), 41â€“49 (2004)
11. P. Levis, S. Madden, J. Polastre, R. Szewczyk, K. Whitehouse, A. Woo, D. Gay, J. Hill,
M. Welsh, E. Brewer et al., TinyOS: an operating system for sensor networks, in Ambient
Intelligence (Springer, Berlin, 2005), pp. 115â€“148
12. C.G. Cassandras, W. Li, Sensor networks and cooperative control. Eur. J. Control 11(4â€“5),
436â€“463 (2005)
13. S. Oh, L. Schenato, P. Chen, S. Sastry, Tracking and coordination of multiple agents using
sensor networks: system design, algorithms and experiments. Proc.-IEEE 95(1), 234â€“254
(2007)
14. S. Hauert, S. Leven, J. Zufferey, D. Floreano, The swarming micro air vehicle network
(smavnet) project (2012)
15. P. Juang, H. Oki, Y. Wang, M. Martonosi, L.S. Peh, D. Rubenstein, Energy-efï¬cient computing
for wildlife tracking: design tradeoffs and early experiences with zebranet, in ACM Sigplan
Notices, vol. 37, no. 10 (ACM, 2002), pp. 96â€“107
Â© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9
111

112
References
16. V. Dyo, S. A. Ellwood, D. W. Macdonald, A. Markham, C. Mascolo, B. PÃ¡sztor, S. Scellato,
N. Trigoni, R. Wohlers, K. Yousef, Evolution and sustainability of a wildlife monitoring
sensor network, in Proceedings of the 8th ACM Conference on Embedded Networked Sensor
Systems (ACM, 2010), pp. 127â€“140
17. J. Huisman, H.C.P. Matthijs, P.M. Visser, Harmful Cyanobacteria (Springer, New York, 2005)
18. K. Johnk, J. Huisman, J. Sharples, B. Sommeijer, P. Visser, J. Stroom, Summer heatwaves
promote blooms of harmful cyanobacteria. Glob. Change Biol. 14(3), 495â€“512 (2008)
19. I. Chorus, J. Bartram, Toxic Cyanobacteria in Water: A Guide to Their Public Health Conse-
quences, Monitoring, and Management (Sponpress, London, 1999)
20. G.S. Sukhatme, A. Dhariwal, B. Zhang, C. Oberg, B. Stauffer, D.A. Caron, Design and
development of a wireless robotic networked aquatic microbial observing system. Environ.
Eng. Sci. 24(2), 205â€“215 (2007)
21. Y. Wang, R. Tan, G. Xing, X. Tan, J. Wang, R. Zhou, Spatiotemporal aquatic ï¬eld reconstruc-
tion using cyber-physical robotic sensor systems. ACM Trans. Sensor Netw. (TOSN) 10(4),
57 (2014)
22. J. Lee, M. Roh, K. Kim, D. Lee, Design of autonomous.underwater vehicles for cage aqua-
farms, in Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, Istanbul, Turkey,
2007, pp. 938â€“943
23. J. Laut, E. Henry, O. Nov, M. Porï¬ri, Development of a mechatronics-based citizen science
platform for aquatic environmental monitoring. IEEE Trans. mechatron. 19(5), 1541â€“1551
(2014)
24. I. Vasilescu, K. Kotay, D. Rus, M. Dunbabin, P. Corke, Data collection, storage, and retrieval
with an underwater sensor network, in Proceedings of the 3rd International Conference on
Embedded Networked Sensor Systems (ACM, 2005), pp. 154â€“165
25. A. Marino, G. Antonelli, A.P. Aguiar, A. Pascoal, S. Chiaverini, A decentralized strategy
for multirobot sampling/patrolling: theory and experiments. IEEE Transactions on Control
Systems Technology (2014)
26. F. Zhang, O. En-Nasr, E. Litchman, X. Tan, Autonomous sampling of water columns using
gliding robotic ï¬sh: control algorithms and ï¬eld experiments, in Proceedings of 2015 IEEE
Conference on Robotics and Automation (ICRA), Seattle. IEE, May (2015)
27. J. Choi, D. MilutinoviÂ´c, Tips on stochastic optimal feedback control and Bayesian spatiotem-
poral models: applications to robotics, J. Dyn. Syst., Meas. Control 137(3) (2015)
28. S.S. Mupparapu, S.G. Chappell, R.J. Komerska, D.R. Blidberg, R. Nitzel, C. Benton, D.O.
Popa, A.C. Sanderson, Autonomous systems monitoring and control (ASMAC)â€”an AUV
ï¬‚eet controller, in IEEE/OES Autonomous Underwater Vehicles, 2004, pp. 119â€“126 (2004)
29. C.L. Nickell, C.A. Woolsey, D.J. Stilwell, A low-speed control module for a streamlined AUV,
in Proceedings of MTS/IEEE OCEANS, Boston, 2005, pp. 1680â€“1685
30. P.R. Bandyopadhyay, Trends in biorobotic autonomous undersea vehicles. IEEE J. Ocean.
Eng. 30, 109â€“139 (2005)
31. C.C. Ericksen, T.J. Osse, R.D. Light, T. Wen, T.W. Lehman, P.L. Sabin, J.W. Ballard, A.M.
Chiodi, Seaglider: a long-range autonomous underwater vehicle for oceanographic research.
IEEE J. Ocean. Eng. 26, 424â€“436 (2001)
32. J. Sherman, R.E. Davis, W.B. Owens, J. Valdes, The autonomous underwater glider â€œsprayâ€.
IEEE J. Ocean. Eng. 26, 437â€“446 (2001)
33. D.C. Webb, P.J. Simonetti, C.P. Jones, â€œSLOCUMâ€: an underwater glider propelled by envi-
ronmental energy. IEEE J. Ocean. Eng. 26, 447â€“452 (2001)
34. D.L. Rudnick, C.C. Eriksen, D.M. Fratantoni, M.J. Perry, Underwater gliders for ocean
research. Mar. Technol. Soc. J. 38, 48â€“59 (2004)
35. E. Fiorelli, N.E. Leonard, P. Bhatta, D.A. Paley, R. Bachmayer, D.M. Fratantoni, Multi-AUV
control and adaptive sampling in Monterey Bay. IEEE J. Ocean. Eng. 31(4), 935â€“948 (2006)
36. N.E. Leonard, D.A. Paley, F. Lekien, R. Sepulchre, D.M. Fratantoni, R. Davis, Collective
motion, sensor networks, and ocean sampling. Proc. IEEE 95(1), 48â€“74 (2007)
37. N.E. Leonard, D.A. Paley, R.E. Davis, D.M. Fratantoni, F. Lekien, F. Zhang, Coordinated con-
trol of an underwater glider ï¬‚eet in an adaptive ocean sampling ï¬eld experiment in Monterey
Bay. J. Field Robot. 27(6), 718â€“740 (2010)

References
113
38. C. Zhang, A. Siranosian, M. Krstic, Extremum seeking for moderately unstable systems and
for autonomous vehicle target tracking witwith position measurements. Automatica 43(10),
1832â€“1839 (2007)
39. M.S. Stankovic, D.M. Stipanovic, Extremum seeking under stochastic noise and applications
to mobile sensors. Automatica 46(8), 1243â€“1251 (2010)
40. J. Le Ny, G.J. Pappas, Adaptive deployment of mobile robotic networks. IEEE Trans. Autom.
Control 58(3), 654â€“666 (2013)
41. K.M. Lynch, I.B. Schwartz, P. Yang, R.A. Freeman, Decentralized environmental modeling
by mobile sensor networks. IEEE Trans. Robot. 24(3), 710â€“724 (2008)
42. J. Choi, S. Oh, R. Horowitz, Distributed learning and cooperative control for multi-agent
systems. Automatica 45, 2802â€“2814 (2009)
43. N.A. Atanasov, J. Le Ny, G.J. Pappas, Distributed algorithms for stochastic source seeking
with mobile robot networks, J. Dyn. Syst. Meas. Control 137(3) (2015)
44. A. Krause, A. Singh, C. Guestrin, Near-optimal sensor placements in Gaussian processes:
theory, efï¬cient algorithms and empirical studies. J. Mach. Learn. Res. 9, 235â€“284 (2008)
45. J. CortÃ©s, Distributed kriged Kalman ï¬lter for spatial estimation. IEEE Trans. Autom. Control
54(12), 2816â€“2827 (2009)
46. R. Graham, J. CortÃ©s, Cooperative adaptive sampling of random ï¬elds with partially known
covariance. Int. J. Robust Nonlinear Control 1, 1â€“2 (2009)
47. R. Graham, J. CortÃ©s, Adaptive information collection by robotic sensor networks for spatial
estimation. IEEE Trans. Autom. Control 57(6), 1404â€“1419 (2012)
48. Y. Xu, J. Choi, Stochastic adaptive sampling for mobile sensor networks using kernel regres-
sion. Int. J. Control, Autom. Syst. 10(4), 778â€“786 (2012)
49. D. Varagnolo, G. Pillonetto, L. Schenato, Distributed parametric and nonparametric regression
with on-line performance bounds computation. Automatica 48(10), 2468â€“2481 (2012)
50. M. Jadaliha, J. Lee, J. Choi, Adaptive control of multiagent systems for ï¬nding peaks of
uncertain static ï¬elds. J. Dyn. Syst. Meas. Control 134(5) (2012)
51. C.-H. Moeng, A large-eddy-simulation model for the study of planetary boundary-layer tur-
bulence. J. Atmos. Sci. 41(13), 2052â€“2062 (1984)
52. N. Cressie, Kriging nonstationary data. J. Am. Stat. Assoc. 81(395), 625â€“634 (1986)
53. C.E. Rasmussen, C.K.I. Williams, Gaussian Processes for Machine Learning (The MIT Press,
Cambridge, 2006)
54. California partners for advanced transit and highways. http://www.path.berkeley.edu. (2015)
55. P. Seiler, A. Pant, K. Hedrick, Disturbance propagation in vehicle strings. IEEE Trans. Autom.
Control 49(10), 1835â€“1842 (2004)
56. B. Zhang, G. Sukhatme, Adaptive sampling for estimating a scalar ï¬eld using a robotic boat
and a sensor network, in 2007 IEEE International Conference on Robotics and Automation
(IEEE, 2007), pp. 3673â€“3680
57. M. Jadaliha, J. Choi, Environmental monitoring using autonomous aquatic robots: sampling
algorithms and experiments. IEEE Trans. Control Syst. Technol. 21(3), 899â€“905 (2013)
58. Y. Wang, R. Tan, G. Xing, X. Tan, J. Wang, R. Zhou, Spatiotemporal aquatic ï¬eld reconstruc-
tion using robotic sensor swarm, in 2012 IEEE 33rd Real-Time Systems Symposium (2012)
59. B. Grocholsky, J. Keller, V. Kumar, G. Pappas, Cooperative air and ground surveillance. IEEE
Robot. Autom. Mag. 13(3), 16â€“25 (2006)
60. C. Tomlin, G.J. Pappas, S. Sastry, Conï¬‚ict resolution for air trafï¬c management: a study in
multiagent hybrid systems. Autom. Control, IEEE Trans. 43(4), 509â€“521 (1998)
61. R.P. Anderson, E. Bakolas, D. MilutinoviÂ´c, P. Tsiotras, Optimal feedback guidance of a small
aerial vehicle in a stochastic wind. J. Guid. Control Dyn. 36(4), 975â€“985 (2013)
62. M.M. Zavlanos, G.J. Pappas, Dynamic assignment in distributed motion planning with local
coordination. IEEE Trans. Robot. 24(1), 232â€“242 (2008)
63. M.M. Zavlanos, G.J. Pappas, Distributed connectivity control of mobile networks. IEEE
Trans. Rob. 24(6), 1416â€“1428 (2008)
64. A. Jadbabaie, J. Lin, A.S. Morse, Coordination of groups of mobile autonomous agents using
nearest neighbor rules. IEEE Trans. Autom. Control 48(6), 988â€“1001 (2003)

114
References
65. R. Olfati-Saber, Flocking for multi-agent dynamic systems: algorithms and theory. IEEE
Trans. Autom. Control 51(3), 401â€“420 (2006)
66. W. Ren, R.W. Beard, Consensus seeking in multiagent systems under dynamically changing
interaction topologies. IEEE Trans. Autom. Control 50(5), 655â€“661 (2005)
67. M. Mesbahi, M. Egerstedt, Graph theoretic methods in multiagent networks (Princeton Uni-
versity Press, Princeton, 2010)
68. F. Bullo, J. CortÃ©s, S. MartÃ­nez, Distributed Control of Robotic Networks, Applied Mathe-
matics Series (Princeton University Press, Princeton, 2009)
69. R.M. Murray, Recent research in cooperative control of multivehicle systems. J. Dyn. Syst.
Meas. Control 129(5), 571â€“583 (2007)
70. Y. Cao, W. Yu, W. Ren, G. Chen, An overview of recent progress in the study of distributed
multi-agent coordination. IEEE Trans. Ind. Inf. 9(1), 427â€“438 (2013)
71. N. Cressie, Statistics for Spatial Data (A Wiley-Interscience Publication, John Wiley and
Sons Inc, New York, 1991)
72. T.M. Cover, J.A. Thomas, Elements of Information Theory, 2nd edn. (Wiley, Hoboken, 2006)
73. A. Singh, A. Krause, C. Guestrin, W. Kaiser, Efï¬cient informative sensing using multiple
robots. J. Artif. Intell. Res. 34(1), 707â€“755 (2009)
74. M. Gibbs, D.J.C. MacKay, Efï¬cient implementation of Gaussian processes (1997) http://
www.cs.toronto.edu/mackay/gpros.ps.gz
75. D.J.C. MacKay, Introduction to Gaussian processes. NATO ASI Ser. F Comput. Syst. Sci.
168, 133â€“165 (1998)
76. A. Krause, C. Guestrin, A. Gupta, J. Kleinberg, Near-optimal sensor placements: maximizing
information while minimizing communication cost, in Proceedings of the 5th International
Conference on Information Processing in Sensor Networks (2006), pp. 2â€“10
77. J. Choi, J. Lee, S. Oh, Biologically-inspired navigation strategies for swarm intelligence using
spatial Gaussian processes, in Proceedings of the 17th International Federation of Automatic
Control (IFAC) World Congress (2008)
78. J. Choi, J. Lee, S. Oh, Swarm intelligence for achieving the global maximum using spatio-
temporal Gaussian processes, in Proceedings of the 27th American Control Conference (ACC)
(2008)
79. A.J. Smola, P. Bartlett, Sparse greedy Gaussian process regression, in Advances in Neural
Information Processing Systems, 13 (2001)
80. C.K.I. Williams, M. Seeger, Using the NystrÃ¶m method to speed up kernel machines, in
Advances in Neural Information Processing Systems, 13 (2001)
81. N. Lawrence, M. Seeger, R. Herbrich, Fast sparse Gaussian process methods: the informative
vector machine, in Advances in Neural Information (2003)
82. M. Seeger, Bayesian Gaussian process models: PAC-Bayesian generalisation error bounds
and sparse approximations. Ph.D. dissertation, School of Informatics, University of Edinburgh
(2003)
83. V. Tresp, A Bayesian committee machine. Neural Comput. 12(11), 2719â€“2741 (2000)
84. C.M. Bishop, Pattern Recognition and Machine Learning (Springer, New York, 2006)
85. M. Gaudard, M. Karson, E. Linder, D. Sinha, Bayesian spatial prediction. Environmental and
Ecological Statistics 6(2), 147â€“171 (1999)
86. H. Rue, H. Tjelmeland, Fitting Gaussian Markov random ï¬elds to Gaussian ï¬elds. Scand. J.
Stat. 29(1), 31â€“49 (2002)
87. N. Cressie, N. Verzelen, Conditional-mean least-squares ï¬tting of Gaussian Markov random
ï¬elds to Gaussian ï¬elds. Comput. Stat. Data Anal. 52(5), 2794â€“2807 (2008)
88. L. Hartman, O. HÃ¶ssjer, Fast kriging of large data sets with Gaussian Markov random ï¬elds.
Comput. Stat. Data Anal. 52(5), 2331â€“2349 (2008)
89. J. Le Ny, G. Pappas, On trajectory optimization for active sensing in Gaussian process models,
in Decision and Control, 2009 Held Jointly with the 2009 28th Chinese Control Conference.
CDC/CCC 2009. Proceedings of the 48th IEEE Conference on, 2010, pp. 6286â€“6292
90. S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory. (Prentice Hall,
Inc., Upper Saddle River, 1993)

References
115
91. J. QuiÃ±onero-Candela, C.E. Rasmussen, A unifying view of sparse approximate Gaussian
process regression. J. Mach. Learn. Res. 6, 1939â€“1959 (2005)
92. H. Rue, L. Held, Gaussian Markov Random Fields: Theory and Applications. (Chapman &
Hall, Upper Saddle River, 2005)
93. C.K.I.Williams,C.E.Rasmussen,Gaussianprocessesforregression.Adv.NeuralInf.Process.
Syst. 8, 514â€“520 (1996)
94. D.J. Nott, W.T.M. Dunsmuir, Estimation of nonstationary spatial covariance structure. Bio-
metrika 89(4), 819â€“829 (2002)
95. J.Q. Shi, T. Choi, Gaussian Process Regression Analysis for Functional Data (CRC Press,
New York, 2011)
96. J. Nocedal, S.J. Wright, Numerical Optimization (Springer, Berlin, 1999)
97. W.W. Hager, H. Zhang, A survey of nonlinear conjugate gradient methods. Pac. J. Optim.
2(1), 35â€“58 (2006)
98. M. Mandic, E. Franzzoli, Efï¬cient sensor coverage for acoustic localization, in Proceedings
of the 46th IEEE Conference on Decision and Control (2007), pp. 3597â€“3602
99. S. MartÃ­nez, F. Bullo, Optimal sensor placement and motion coordination for target tracking.
Automatica 42(4), 661â€“668 (2006)
100. F. Pukelsheimi, Optimal Design of Experiments (Wiley, New York, 1993)
101. A.F. Emery, A.V. Nenarokomov, Optimal experiment design. Meas. Sci. Technol. 9(6), 864â€“
876 (1998)
102. C.K.I. Williams, F. Vivarelli, Upper and lower bounds on the learning curve for Gaussian
processes. Mach. Learn. 40(1), 77â€“102 (2000)
103. P. Sollich, A. Halees, Learning curves for Gaussian process regression: approximations and
bounds. Neural Comput. 14(6), 1393â€“1428 (2002)
104. D.P. Bertsekas, W.W. Hager, O.L. Mangasarian, Nonlinear Programming (Athena Scientiï¬c,
Belmont, 1999)
105. G.M. Mathews, H. Durrant-Whyte, M. Prokopenko, Decentralised decision making in het-
erogeneous teams using anonymous optimisation. Robot. Auton. Syst. 57(3), 310â€“320 (2009)
106. W. Rudin, Principles of Mathematical Analysis (McGraw-Hill, New York, 1976)
107. C.R. Dietrich, G.N. Newsam, Fast and exact simulation of stationary Gaussian processes
through circulant embedding of the covariance matrix. SIAM J. Sci. Comput. 18(4), 1088â€“
1107 (1997)
108. S. Oh, Y. Xu, J. Choi, Explorative navigation of mobile sensor networks using sparse Gaussian
processes, in Proceedings of the 49th IEEE Conference on Decision and Control (CDC) (2010)
109. L. Devroye, Non-uniform Random Variate Generation (Springer, New York, 1986)
110. R. Olfati-Saber, R. Franco, E. Frazzoli, J.S. Shamma, Belief consensus and distributed hypoth-
esis testing in sensor networks, Networked Embedded Sensing and Control, pp. 169â€“182
(2006)
111. T. Gneiting, Compactly supported correlation functions. J. Multivar. Anal. 83(2), 493â€“508
(2002)
112. D.P. Bertsekas, J.N. Tsitsiklis, Parallel and Distributed Computation: Numerical Methods
(Prentice Hall, Englewood Cliffs, 1999)
113. R. Olfati-Saber, J.A. Fax, R.M. Murray, Consensus and cooperation in networked multi-agent
systems. Proceedings of the IEEE 95(1), 215â€“233 (2007)
114. H. Akaike, A new look at the statistical model identiï¬cation. IEEE Trans. Autom. Control
19(6), 716â€“723 (1974)
115. M. Corporation, Ofï¬cial website of Kinect for Xbox 360. http://www.xbox.com/en-US/kinect
116. F. Lindgren, H. Rue, J. LindstrÃ¶m, An explicit link between Gaussian ï¬elds and Gaussian
Markov random ï¬elds: the stochastic partial differential equation approach. J. R. Stat. Soc.:
Ser. B 73(4), 423â€“498 (2011)
117. H. Rue, S. Martino, N. Chopin, Approximate Bayesian inference for latent Gaussian models
by using integrated nested Laplace approximations. J. R. Stat. Soc.: Ser. B (Stat. Methodol.)
71(2), 319â€“392 (2009)
118. Y. Xu, J. Choi, S. Dass, T. Maiti, Bayesian prediction and adaptive sampling algorithms for
mobile sensor networks, in Proceedings of the 2011 American Control Conference (ACC)
(2011), pp. 4095â€“4200

