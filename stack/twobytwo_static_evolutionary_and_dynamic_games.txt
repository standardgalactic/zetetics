20
Two-by-two static, evolutionary, and
dynamic games
Pierre Bernhard and Fr´ed´eric Hamelin
I3S, University of Nice-Sophia Antipolis and CNRS, France
Foreword
Gilles Kahn and I were classmates at ´Ecole Polytechnique where, in
the academic year 1965–1966, he taught me programming (this was in
MAGE 2, a translation in French of Fortran 2 I believe, on a punched
tape computer SETI PALAS 250), then we met again and became good
friends at Stanford University, where he was a computer science student
while I was in aeronautics and astronautics. Our paths were to get closer
starting in the spring of 1980 when we started planning and, from 1983
on, heading INRIA Sophia-Antipolis together.
Gilles has always believed that game theory was worth pursuing. He
was adament that our laboratory should take advantage of my being
conversant with that topic. He was instrumental in maintaining it alive
in the lab.
He was to be later the president of INRIA who presided over the
introduction of “biological systems” as a full-ﬂedged scientiﬁc theme of
INRIA. Although this was after I had left INRIA, this again met with
my personal scientiﬁc taste. I had by then embraced behavioural ecology
as my main domain of interest and of application of dynamic games,
much thanks to Eric Wajnberg, from INRA, but also out of an old desire
of looking into the ecological applications of these techniques.
It is why I think ﬁt to write here a few words about games and
behavioural ecology, and also population dynamics and evolution, which
are closely related topics.
From Semantics to Computer Science Essays in Honour of Gilles Kahn,
eds Yves
Bertot, G´erard Huet, Jean-Jacques L´evy and Gordon Plotkin. Published by Cambridge
University Press.
c
⃝Cambridge University Press 2009.
465
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

466
P. Bernhard and F. Hamelin
Abstract
We discuss related aspects of the simplest possible games, i.e. games
where two players have two pure strategies each, and consider static
games, population games – a generalization of evolutionary games – and
dynamic games.
20.1 Introduction
What follows begins as a form of entertainment with two by two
(2 × 2) games, the very simple structure of such static games shaping
the dynamic aspects of evolutionary games, – a topic invented by
the biologists – population games and bilinear diﬀerential games, of
which we show here an example in behavioural ecology where it arises
naturally.
We begin with a short taxonomy of 2 × 2 static games, which
will be useful in the sequel. Then we investigate how concepts of
evolutionary game theory translate in that simple case. The material
up to Section 20.3.3, is reminiscent of [13], may be with more emphasis
on the role of our parameter σ. A natural generalization of classical
evolutionary games are population games.1 We develop some very
simple, yet probably original, results for such games still in the 2 × 2
case, and look at their relationship to evolutionary games.
Then we venture into diﬀerential games. The literature on diﬀerential
games bears a striking diﬀerence with that on classical game theory in
that, while the latter is mainly concerned with mixed strategies – up
to the point that ordinary decisions have to be called pure strategies to
recall that they are not mixed – mixed strategies have had little impact
on diﬀerential games research. On the one hand, diﬀerential games
have been mainly concerned with state feedback or non-anticipative
strategies, and the concept of mixed state feedback, or, for that matter
mixed nonanticipative strategy, is surely not simple. On the other
hand, most of that literature has considered continous decision sets,
as opposed to ﬁnite, thus allowing for enough convexity or concavity
without relying on mixed strategies.
However, we recently showed [7] that in the case of a two-player (non-
zero-sum) game where each player has only two possible controls – the
framework of this article – not only do mixed strategies come up as
a natural concept, but moreover they lead to a concept of bi-singular
1 As far as we know, this phrase has been introduced by W. Sandholm [14]
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
467
trajectory ﬁelds which seems to have no counterpart in control theory.
Looking into older literature, this concept should have been uncovered
in the late 1960s or early 1970s. We are surprised – and a bit suspicious
– that we did not ﬁnd any mention of it.
We use this theory to investigate a problem of conﬂict over parental
care which has been investigated in the literature on behavioural ecology
([8, 11, 9, 4]) in various forms (static, discrete dynamic, symmetric. . . ).
Here we adopt a continuous time model, asymmetric, that ﬁts with
the current paper, and is solved in part via our theory of bi-singular
trajectory ﬁelds. We ﬁnd that the solution of the more realistic ﬁnite
horizon version investigated here, shares, to our surprise, some features
of the inﬁnite horizon version investigated in [7], but also displays new
features.
20.2 Static games
There is a wealth of classical 2×2 static games, starting with the famous
Prisoner’s Dilemma – a story due to Tucker – including Stag and Hare,
Hawk and Doves, Sex War, – four related games that attempt to capture
the beneﬁt of cooperation over agression (See [3]). We propose here a
taxonomy of all 2 × 2 games adapted to our use in the sequel.
20.2.1 Notations
Let a two-person game be described by the following 2 × 2 bi-matrix:
u1\u2
1
2
a2
c2
1
a1
b1
b2
d2
2
c1
d1
Player 1 chooses the row through his control u1, his payments – or
rewards – are indexed by the subscript 1, while player 2 chooses the
column through her control u2, her payments being indexed by the
subscript 2.
We shall all along adopt the convention that when a property holds
for indices i = 1 and i = 2, we shall simply write it with the index i
without every time writing i ∈{1, 2}, which shall be implicit. Also, the
index j in an expression involving i will mean j = 3 −i.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

468
P. Bernhard and F. Hamelin
We let
Ai =
 ai
bi
ci
di

Because of the way we have arranged the bi-matrix of payments, each
player chooses the row of his or her own matrix, the opponent chooses
the column. Let
δi = aidi −bici ,
σi = ai −bi −ci + di ,
and when σi ̸= 0,
p⋆
j = di −bi
σi
,
1 −p⋆
j = ai −ci
σi
.
(20.1)
20.2.2 Interpretation
We notice that if σi = 0, player i has a dominating pure strategy since
ai −ci = bi −di, so that the ﬁrst strategy dominates the second one if
both are positive, and the second dominates if both are negative. (And
his choice is void if both are zero.)
Moreover, we also stress that σi is the second derivative of the
restriction of the quadratic form of R2
x &→⟨x, 1
2(Ai + At
i)x⟩
to the subspace orthogonal to the vector (1 1). This will have an impact
in view of classical theorems on evolutionary stable strategies (ESS).
If we let pi and 1 −pi be the probabilities that player i chooses his or
her ﬁrst and second pure strategy respectively, p⋆
i is a candidate strategy
of player i equalizing for player j, i.e. such that both decisions of j
provide the same payment:
( p⋆
i
1 −p⋆
i )Aj = δj
σj
( 1
1 ) .
However, p⋆
i can be a mixed strategy only if it belongs to [0, 1]. If so,
any mixed strategy of player j is a best response to that strategy.
The property that p⋆
i ∈(0, 1) means that player j has a dilemma: the
best decision for that player depends on the decision of the other one.
Conversely, if either p⋆
i ≤0 or p⋆
i ≥1, one line of Aj dominates the other
one (weakly if p⋆
i is at one of the bounds), so that player j can play that
decision regardless of the opponent’s choice. The dominating line is the
ﬁrst one if σjp⋆
i < 0, and the second one if σjp⋆
i > 0.
Invariance We stress the following invariances and symetries.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
469
• Under addition of the same constant to all four entries of Ai, σi and
pj are invariant.
• Interchanging the order of the pure strategies of player i, but not j,
changes both σi and σj to their opposite, leaves p⋆
j invariant, and,
obviously, changes p⋆
i to 1 −p⋆
i .
• In evolutionary games, the sign of σi will have a strong meaning.
But this is a symmetric game with A1 = A2, so that one can only
interchange the order of the pure strategies of both players simulta-
neously, thus preserving this sign.
20.2.3 Taxonomy
To avoid unnecessary particular cases, we make the following hypothesis.
Hypothesis 20.1
ai ̸= ci
and
bi ̸= di .
As a consequence both p⋆
i are diﬀerent from 0 and 1.
Let us list the possibilities that arise.
Theorem 20.2 Under hypothesis 20.1, occurences of Nash equilibria in
2 × 2 games are as follows:
(i) Either of the σi = 0. Then, Player i has a dominating pure
strategy, the game has a single Nash equilibrium, which is pure.
(ii) Both σi ̸= 0, but one at least of the p⋆
i /∈(0, 1). The corresponding
player(s) j has a dominating pure strategy. There is a unique
Nash equilibrium, which is in pure strategies.
(iii) Both σi ̸= 0, and both p⋆
i ∈(0, 1). Then (p⋆
1, p⋆
2) is a mixed Nash
equilibrium. Two subcases arise.
(a) σ1σ2 < 0. There is no Nash equilibrium in pure strategies.
The mixed Nash equilibrium is the only one.
(b) σ1σ2 > 0. There are two pure Nash equilibria in addition to
the mixed one. They are,
1. if σi < 0, (0, 1) and (1, 0) (in terms of p1 and p2).
2. if σi > 0, (1, 1) and (0, 0). (A coordination game, e.g. Sex
War.)
Proof
(i) The case where one σi = 0 has been covered in the Section 20.2.2.,
entitled “Interpretation” above.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

470
P. Bernhard and F. Hamelin
(ii) Assume that both σi ̸= 0, but that p⋆
i /∈(0, 1). (Remember that
our Hypothesis 20.1 rules out the case p⋆
i ∈{0, 1}.) Then p⋆
i and
1 −p⋆
i have opposite signs. Therefore, according to (20.1) bj −dj
and aj −cj have the same sign. Thus the ﬁrst line of Aj dominates
the second if that common sign is positive, and conversely if it is
negative. The domination is strict because of our Hypothesis 20.1.
Therefore, a Nash equilibrium has to be pure for player j. But
then player i must play his or her best response against that pure
strategy, which is pure and unique again due to Hypothesis 20.1.
(If both p⋆
i are outside (0, 1), both players have a dominating
strategy. A typical example is Prisoner’s Dilemma.)
(iii) If both p⋆
i belong to (0, 1), they constitute a pair of mutually
equalizing strategies, hence a mixed Nash equilibrium.
(a) The only two possibilities for there being no pure Nash
equilibrium, is that, for a choice of i and j, ai > ci and di > bi
while aj < cj and dj < bj. Then, trivially σi > 0 and σj < 0.
(b) Otherwise, one of the two pairs of diagonally opposite payments
are Nash. The cases i. or ii. of the theorem can be checked by
inspection.
Remark If the context allows one to number the pure strategies of
both players independently, then cases (i) and (ii) of (iii)(b) in Theorem
20.2 above are not diﬀerent, since, according to the facts pointed out
in the paragraph “Invariance”, one is converted into the other one by
interchanging the numbering of the pure strategies of any one (but one
only) of the players.
20.3 Evolutionary and population games
20.3.1 Mixed strategies and dynamics
In this section, we investigate in the particular case of our simple 2 × 2
games the implications of a simple idea: replace players by populations,
and probabilities in mixed strategies by proportions of the population
that use a given (pure) strategy. One can still recover a probabilistic
interpretation, in that, if an individual is chosen “at random” (with a
uniform law among the population), the probabilities that it plays one
or the other strategy (that it be of one or the other phenotype) agree
with population proportions. Yet, each individual uses a unique strategy
(is of a given phenotype).
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
471
On the one hand, this gives a much more concrete and convincing
interpretation of mixed strategies. On the other hand, this allows
naturally for an evolution of the mixed strategies as individuals in the
population switch from one pure strategy to another one.
In that respect, Sandholm [14] shows that at least two very natural
strategy revision schemes lead to the same strategy dynamics, which are
those considered in behavioural ecology if the ﬁtness of a phenotype (the
payment associated to a pure strategy) is taken to be the growth rate
of the sub-population using it.
We use this last explanation to justify the so-called “replicator
equation”. We imply that a Nash equilibrium is the credible outcome of
a game if it is stable under that dynamics. For the sake of completeness,
we shall compare it with the Cournot – or pseudo-gradient – dynamics.
20.3.2 Evolutionary games
20.3.2.1 Taxonomy
Evolutionary games consider a competition between several (here, two)
behaviours within a single population. In our wording, this means that,
on the one hand A1 = A2 = :A, and on the other hand, p1 = p2 = :p.
In that context, two remarks are in order concerning the application of
Theorem 20.2. On the one hand, the case (iii)(a) cannot appear. On the
other hand, interchanging the numbering of the pure strategies of one
player alone is not possible, hence the two sub-cases of case (iii)(b) of
Theorem 20.2 are indeed diﬀerent. And the two pure Nash equilibrium
of the sub-case (i) being non-symmetric, they are not Nash equilibria in
this context.
The basic concept is that of an evolutionarily stable strategy (ESS).
This is deﬁned by two conditions: on the one hand it is a Nash
equilibrium in this symmetric context. On the other hand, in the case
of a mixed Nash point, strategies as good as p against p must be less
eﬃcient than p against themselves. We state both conditons in the
simple form it takes for a 2 × 2 game.
Deﬁnition 20.3 A symmetric strategy (p, p) of a symmetric game is
called an ESS if
(i) It is a Nash equilibrium,
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

472
P. Bernhard and F. Hamelin
(ii) If p /∈{0, 1} (then it has to be p⋆of the previous section), for
any q ∈[0, 1] diﬀerent from p, the strategy (p, 1 −p) is a better
response to (q, 1 −q) than (q, 1 −q) itself, i.e.
( p −q
q −p )A

q
1 −q

> 0 .
The ESS that may arise are now described by this corollary.
Corollary 20.4 Occurrences of ESS in 2 × 2 symmetric games are as
follows:
(i) σ
= 0. There is a unique ESS, which is pure. (Typically,
Prisoner’s Dilemma according to [3].)
(ii) σ ̸= 0 but p⋆/∈(0, 1). There is a unique ESS, which is pure.
(Typically, Prisoner’s Dilemma, with c < a < d < b.)
(iii) σ ̸= 0, p⋆∈(0, 1).
i If σ < 0, the only ESS is p⋆, (typically, Hawk and Dove),
ii if σ > 0, there are two pure ESS : (0, 0) and (1, 1), and no
mixed ESS. (Typically, Stag and Hare.)
Proof
This is just applying Theorem 20.2 to Deﬁnition 20.3, except
for the case p⋆∈(0, 1) which requires distinguishing ESS among Nash
points. But only symmetric Nash points may be ESS, and a simple
calculation shows that
( p⋆−p
p −p⋆)A

p
1 −p

= −σ(p −p⋆)2 .
This is positive if and only if σ < 0.
Several remarks are in order. The only mixed ESS is therefore
obtained when σ < 0, p⋆∈(0, 1). Embedded into a population with
that particular mix, individuals using strategy 1 and 2 fare as well. This
characterization of an equilibrium population was ﬁrst discovered by
Wardrop in the context of road traﬃc [15].
20.3.2.2 Dynamics
Assume payments to pure strategies are to be understood as sub-
population growth rates. Let therefore ni be the number of individuals
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
473
of type i in the population, and p = n1/(n1 + n2). Assume furthermore
that the growth rate of each sub-population is
˙n1
n1
=
ap + b(1 −p) ,
˙n2
n2
=
cp + d(1 −p) .
(20.2)
A straightforward calculation yields the replicator dynamics:
˙p
=
σp(1 −p)(p −p⋆)
if σ ̸= 0 ,
(20.3)
˙p
=
(b −d)p(1 −p)
if σ = 0 .
(20.4)
It is straightforward to check, concerning (20.3), that if σ < 0, its only
stable equilibrium is p⋆, while both 0 and 1 are stable, and not p⋆, if
σ > 0. This is an instance of the general theorem that states that ESS
are (at least locally) stable points of the replicator dynamics. The same
holds for (20.4) which converges to 0 or 1 according to whether b −d is
negative or positive.
Stag and Hare’s paradox Stag and Hare (after J-J. Rousseau [12]) is
a symmetric game with
A =
 S
0
1
1

with S > 1. This an instance of the case σ = S > 0, p⋆= 1/S ∈(0, 1),
the last case (3.b, ii) of Theorem 20.2, where there are three symmetric
Nash equilibria, but only two pure ESS. Indeed, if the mixed strategy p⋆
is considered as a possible outcome of the game, we run into a paradox:
the probability of choosing strategy 1 would decrease with the payment
S of coordinated choices in favor of 1. The solution is in the replicator
dynamics : the interval (p⋆, 1) is the attraction basin of the ESS (1, 1).
And it is increasing with S.
20.3.3 Population games
20.3.3.1 Equilibria and stability
We turn now to games between two diﬀerent populations, each composed
of individuals of two diﬀerent types. This is exactly the framework of
(non-symmetric) games, but with players interpreted as populations.
The status of Nash equilibria are therefore described by Theorem 20.2.
We do not attempt to deﬁne the equivalent of an ESS, but rely on the
stability of the replicator dynamics to select realistic outcomes of a game.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

474
P. Bernhard and F. Hamelin
As mentioned earlier, several natural considerations lead to this same
dynamics, either in a learning paradigm (see [14]) or, as we assume here,
in an evolutionary context.
We now have two sets (ni1, ni2) of subpopulation numbers, and we
extend equations (20.2) to both populations, as well as the deﬁnition
pi = ni1/(ni1 + ni2). Diﬀerentiating that last expression, we get, in case
both σi ̸= 0,
˙pi = σipi(1 −pi)(pj −p⋆
j) .
(20.5)
These equations have (1, 1), (1, 0), (0, 1), and (0, 0) as equilibria, and
(p⋆
1, p⋆
2) if both p⋆
i ∈(0, 1). The stability of these equilibria are readily
seen from the Jacobian
J(p1, p2) =
 −σ1(1 −2p1)
σ1p1(1 −p1)
σ2p2(1 −p2)
−σ2(1 −2p2)

.
We skip the discussion of the four “pure” cases. The conclusion is that
the pure Nash equilibria are stable. Let us concentrate on the phase
portrait in case 3 of the theorem. The Jacobian at (p⋆
1, p⋆
2) is
J(p⋆
1, p⋆
2) =

0
σ1p⋆
1(1 −p⋆
1)
σ2p⋆
2(1 −p⋆
2)
0

.
Therefore two cases arise
a σ1σ2 < 0. The equilibrium (p⋆
1, p⋆
2) is a center,
b σ1σ2 > 0. The equilibrium (p⋆
1, p⋆
2) is a saddle.
Let us furthermore emphasize the following fact. Consider the
functions
Ui(pi) = p⋆
i ln p⋆
i
pi
+ (1 −p⋆
i ) ln 1 −p⋆
i
1 −pi
and
V (p1, p2) = σ2U1(p1) −σ1U2(p2) .
Lemma 20.5 The function V (p1, p2) is a ﬁrst integral of the replicator
dynamics (20.5).
Proof The lemma is proved by direct diﬀerentiation, checking that the
lagrangian derivatives of the Ui’s are ˙Ui(pi) = σi(p1 −p⋆
1)(p2 −p⋆
2).
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
475
20.3.3.2 Phase portraits
We can now give a fairly complete description of case 3.
Theorem 20.6 In case both σi ̸= 0 and both p⋆
i ∈(0, 1),
(a) If σ1σ2 < 0, the trajectories of the replicator dynamics are all
periodic, the center being (p⋆
1, p⋆
2),
(b) If σ1σ2 > 0, (p⋆
1, p⋆
2) is a saddle. The two pure Nash equilibria
are the stable points of the dynamics. Their attraction basins are
separated by the curve V (p1, p2) = 0.
Proof
It is a classical fact that, as long as the p⋆
i ∈(0, 1), the Ui are
positive, null in p⋆
i and strictly convex. Hence, if σ1 and σ2 are of opposite
signs, V is strictly convex or concave, with its extremum 0 in (p⋆
1, p⋆
2),
and the trajectories, lying on level curves of V , are periodic. Otherwise,
the curve V (p1, p2) = 0 has to be a trajectory, and as it passes through
(p⋆
1, p⋆
2), the result follows.
Take A1 = A2 = A, with σ < 0. Remark that the stable mixed ESS
of the previous section has now turned into a saddle. The ESS dynamics
was the diagonal dynamics of the current two-dimensional (2D) game,
and indeed, in the saddle, the diagonal is the trajectory heading towards
the saddle point. But in this 2D game, it is highly unstable. Whether the
stable case can be taken as such depends on the context. Two identical
populations are not the same as a single population.
20.3.3.3 Wolves and lynxes
We give here an example of population dynamics taken from a model of
intraguild predation. (This is a somewhat formal model.2 See [1] for a
recent review.) In the classical Hawk and Doves game, one investigates
the equilibrium between two behaviors in a population of predators
competing for prey. Here, we have two diﬀerent species of predators,
say wolves and lynxes hunting deer. “Dog does not eat dog”. In our
model, the competition is extra-speciﬁc, but we still have two possible
behaviours, agressive or paciﬁc, in each population.
In that model, Lynxes are at a trophic level above that of wolves. In
particular, if two aggressive individuals meet, the lynx is hurt, but the
wolf is killed. We also assume that against a paciﬁc (coward) wolf, an
2 The authors thank Fr´ed´eric Grognard, of INRIA, and Ludovic Mailleret, of INRA,
for a discussion that helped improve this model.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

476
P. Bernhard and F. Hamelin
agressive lynx gets less than 1 (the full beneﬁt of the prey), because it
has spent unnecessary time and eﬀort chasing a competitor who would
have left anyhow.
The result is the following bi-matrix of rewards:
L\W
p
a
1 −λ
1
p
λ
0
0
−θ
a
1 −µ
1 −ν
with λ+µ > 1 > ν. In that game, we have σ1 = λ+µ−ν and σ2 = −λ−θ,
p⋆
1 = θ/(λ + θ), p⋆
2 = (1 −ν)/(λ + µ −ν).
A typical example of the resulting phase portrait is depicted in Figure
20.1, where we have taken λ = ν = 1/2, θ = 2µ = 1.5, initial state
at (0.2, 0.2). We have integrated with an order 4 Runge Kutta scheme,
with a step of 2.5 × 10−2 from t = 0 up to t = 40.
Fig. 20.1. Population dynamics for wolves and lynxes, λ = ν = 1/2, θ = 2µ =
1.5, time span : 40 units.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
477
20.3.3.4 Cournot dynamics
It may be worthwhile to compare the replicator dynamics to the
“natural” dynamics whereby the pi’s would evolve according to the
gradient of the rewards. (This could be considered the natural extension
of Cournot iterations, and is Rosen’s pseudo-gradient algorithm.) This
leads to
˙pi = σi(pj −p⋆
j) .
This is either an harmonic oscillator or a diverging exponential according
to the sign of σ1σ2. It does not take into consideration the restriction
p ∈[0, 1] and does not seem to be a good basis for Nash selection.
20.4 Conﬂict over parental care, a diﬀerential game
We turn now to an application of the theory described in [6, 7] where
we show how a mixed Nash equilibrium of a two-player non-zero-sum
game where each player has, as here, two pure strategies (two possible
phenotypes), can be found via the solution of a pair of uncoupled partial
diﬀerent equations (PDEs), derived from Isaacs’ PDE.
20.4.1 The parental care game
Rather than an exhaustive taxonomy, which does not seem feasible, we
investigate here a variation of a famous problem in behavioural ecology,
the conﬂict over parental care. [2, 9]. We signiﬁcanty improve, we believe,
our own treatment of that question in [6, 7] by allowing for a ﬁxed
duration breeding season.
Two animals, 1 and 2, have jointly given birth to an oﬀspring. Each
of the two parents may take care of the young, but this time is taken
from the time it could spend caring for itself and thus increasing the
likelihood of disseminating its genes by other means. Or it may defect,
but then the eﬀort put into nesting and giving birth to the young is
wasted. We allow each parent a mixed strategy, in the form of a partial
rather than full eﬀort.
Let therefore x ∈R be the weight increase of the young. At initial
time, x = 0. The oﬀspring is adult and viable when x = 1. But this must
happen during the year it was born, say at or before time T. Let ui = 1
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

478
P. Bernhard and F. Hamelin
if parent i takes care full time of the young, ui = 0 if it defects. In the
“pure” dynamics ˙x is given as follows:
u1\u2
0
1
0
−δ
α2
1
α1
γ
The coeﬃcients αi, γ and δ are all assumed positive, with γ > α1 > α2.
We let β = γ −α1 −α2 be the synergy coeﬃcient.
Allowing for “mixed strategies” or partial eﬀorts ui ∈[0, 1] leads to
˙x = a1u1 + a2u2 + cu1u2 −δ
(20.6)
ai = αi + δ ,
c = γ −α1 −α2 −δ.
We allow both parents to behave in closed loop, i.e. use controls of the
form ui = φi(t, x). We shall encounter only constant controls, so that
the existence of solutions to our dynamic equations is not an issue.
The game ends at τ = min{t | x(t) = 1 , T}. The reward of the parents
are M(x(τ)) = 1 or 0 according to whether the young has achieved
viability or not, —i.e. M(1) = 1, M(x) = 0 ∀x < 1—, decreased by the
cost of caring, say
Ji(u1(·), u2(·)) = M(x(τ)) −εi
 τ
0
ui(t) dt .
20.4.2 Pure equilibria
20.4.2.1 Constant controls
We notice the following simple facts.
Lemma 20.7
(1) Any eﬀort that does not lead to x(τ) = 1 is dominated by 0.
(2) A parent who cares alone should use the pure strategy ui = 1.
(3) The best response to ui = 1 is never uj = 1 unless γT = 1.
Proof
(1) If M(x(τ)) = 0, the payoﬀto each parent is negative, or 0 for
whichever has used ui = 0.
(2) If a parent cares alone, to reach x(τ) = 1, it needs to achieve
 τ
0
(aiu(t) −δ) dt = 1 ,
=⇒
ai
 τ
0
ui(t) dt = 1 + δτ .
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
479
Hence its reward is Ji = 1 −(εi/ai)(1 + δτ) which is decreasing
with τ. Hence it should strive to minimize τ.
(3) Against uj = 1, a constant response ui yields τ = 1/[(γ −αj)ui +
αj] which is decreasing with ui, as is Ji = 1 −εiτui. Hence if
τ < T, a ui < 1 still leads to termination before T and a higher
reward.
This simple fact suﬃces to allow us to investigate pure Nash equilibria.
Consider the game space in the (t, x) plane. Draw the lines x = 1 −
αi(T −t), called Li, and x = 1−γ(T −t) called Lγ, as in Figure 20.1. (We
carry the discussion below for x(0) = 0, and with respect to the position
of 0 on the time axis. This could easily be extended to an arbitary initial
pair (t0, x0).)
We claim the following (Fig. 20.2)
Theorem
20.8
The following discussion provides all pure Nash
equilibria with constant controls
Discussion To the right of line Lγ, the child cannot be brought
to adulthood within the remaining time. Therefore, the only Nash
equilibrium is (0, 0).
Assume α1 > α2. To the right of line L1, no parent can bring the
child to adulthood alone. Therefore, if the other parent plays uj = 0,
the optimum is ui = 0, and (0, 0) is Nash. A joint eﬀort may drive x
to 1 before time T, but, according to the lemma, except on the line Lγ,
-
t
6
x
1
T








Lγ
(0, 0)
#
#
#
#
#
#
#
#
#
#
L1
(0, 0)
















L2
(1, 0)
(1, 0)
(0, 1)
Fig. 20.2. The pure Nash equilibria if the εi are small.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

480
P. Bernhard and F. Hamelin
(1, 1) cannot be a Nash equilibrium. We shall see mixed equilibria in
that region.
Between lines L1 and L2, the parent 1 can succeed alone. If its reward
in so doing is positive, it is its best response against u2 = 0. And of
course u2 = 0 is the best response to u1 = 1 since it yields a reward of
1 to parent 2. Therefore, (1, 0) is the only Nash equilibrium if ε1 < α1.
Otherwise, the same situation as to the right of L1 prevails.
To the left of line L2, both parents are able to succeed alone. Therefore,
if both εi < αi, there are two asymmetric Nash equilibria, (1, 0) and
(0, 1). If any of the εi > αi, that parent has no incentive to breed the
child alone. Therefore, its best response to 0 is 0. Therefore if one only,
say 1, is in that situation, the only Nash equilibrium is (0, 1). If both are,
again (0, 0) is a Nash equilibrium, and also (1, 1) provided that εi < γ.
20.4.2.2 Synchronous on-oﬀequilibria
If c > 0, Nash equilibria appear, where both parents care or rest
simultanesouly. The following suﬃcient condition has no claim of
optimality. Note that we have used α1 ≥α2 to keep the most stringent
of symmetric conditions.
Theorem 20.9 Assume c > 0. Let T0 be a subset of [0, T] with measure
τ0 ≤1/εi, i = 1, 2. Assume that the controls ¯u1(t) = ¯u2(t) = 1lT0(t)
generate a trajectory ¯x(t) ending at ¯x(τ) = 1 before time T, and that
(1, ¯u2) generate a trajectory ending at τ1. Assume further that over
[τ1, τ], the trajectory ¯x(t) lies below the line of slope γ −α2 passing
through its end-point. Then the pair (¯u1, ¯u2) is a Nash equilibrum.
Proof
Fix u2 = ¯u2, and pick an arbitrary u1(·). If the pair (u1(·), ¯u2)
does not lead to termination before time T, parent 1 incurs a negative
reward, while the condition τ0 ≤1/ε1 ensures a positive reward for
the pair (¯u1, ¯u2). Let therefore τ ′ be the termination time on this new
trajectory. Note that, necessarily, τ ′ ≥τ1. Two cases arise depending on
whether τ ′ is less or more than τ.
If τ ′ < τ, the support of ¯u2 may have been curtailed by the early
termination. Let T2 be that curtailed support, and τ2 its measure. Let
T1 = [0, τ ′] −T2, and let v1 and w1 be the integrals of u1(·), respectively
over T1 and T2. We have
x(τ ′) = 1 = a1(v1 +w1)+a2τ2 +cw1 −δτ ′ = ¯x(τ) = (a1 +a2 +c)τ0 −δτ .
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
481
This can be rearranged in
(a1 + c)(v1 + w1 −τ0) = cv1 + a2(τ0 −τ2) −δ(τ −τ ′) .
(20.7)
The hypothesis in the theorem can be written, using γ −α2 = a1 + c,
¯x(τ ′) = (a1 + a2 + c)τ2 −δτ ′ ≤(a1 + a2 + c)τ0 −δτ −(a1 + c)(τ −τ ′) ,
which can be rearranged into
a2(τ0 −τ2) −δ(τ −τ ′) ≥(a1 + c)[τ −τ ′ −(τ0 −τ2)] .
Combining this with (20.7), and noting that necessarily, τ0 −τ2 ≤τ −τ ′,
we get
(a1 + c)(v1 + w1 −τ0) ≥cv1 ≥0 .
Since J1(u1(·), ¯u2) −J1(¯u1, ¯u2) = −ε1(v1 + w1 −τ0), we conclude that
J1 has creased in the change.
Otherwise, if τ ′ ≥τ, then τ2 = τ0, and (20.7) directly yields the
desired result.
20.4.3 Time-sharing equilibria
If β < 0, that is γ < α1+α2, i.e. if no synergy exists between the parents,
but to the contrary a law of diminishing return prevails, another family
of Nash equilibria shows up, in which the parents agree to take their
turn in caring for the child. Assume that α1T > 1. Pick a time τ < T
such that α2τ < 1 < α1τ. Let
τ1 = 1 −α2τ
α1 −α2
and
τ2 = α1τ −1
α1 −α2
.
This way, τ1 + τ2 = τ < T and α1τ1 + α2τ2 = 1. Choose a partition
of [0, τ] into two (measurable) sets T1 and T2 of respective Lebesgue
measures τ1 and τ2. Choose ¯ui(t) = 1lTi(t), i.e. 1 if t ∈Ti, 0 elsewhere.
We claim the following theorem.
Theorem 20.10 If β < 0, and if both εiτi < 1, the pair (¯u1, ¯u2) is a
Nash equilibrium.
Proof Fix ¯u2, and choose an arbitrary u1(·). Let τ ′ be the time when
the game ends, T ′
2 of measure τ ′
2 ≤τ2 the support of ¯u2 in [0, τ ′] – it
might be less than τ2 if the game ends earlier – and T ′
1 of measure τ ′
1 its
complement. Let also v1 and w1 be the integrals of u1(·) over cT ′
1 and
T ′
2, respectively. Notice that v1 ≤τ ′
1.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

482
P. Bernhard and F. Hamelin
If (u1(·), ¯u2) do not bring the state to 1 before time T, J1 is negative.
Otherwise, using v1 + w1 =

u1dt,
J1(u1(·), ¯u2) −J1(¯u1, ¯u2) = −ε1(v1 + w1 −τ1) .
Also, writing the dynamics in terms of the Greek parameters, we have
that
x(τ ′) = (α1 + δ)v1 + α2τ ′
2 + (γ −α2)w1 −δτ ′
1 = 1 = α1τ1 + α2τ2 .
Using the second and the fourth terms of this equality, we easily get that
α1(v1 + w1 −τ1) = δ(τ ′
1 −v1) −βw1 + α2(τ2 −τ ′
2) .
If β < 0, the right-hand side is positive, hence the variation in J1 is
negative.
Notice that, contrary to the mixed equilibrium of the next paragraph,
this is a strict Nash equilibrium, as the right hand side above can be
zero only if u1 = ¯u1.
20.4.4 Mixed equilibria
20.4.4.1 Time-unconstrained trajectories
We now turn to mixed equilibria, using the theory of [7], whereby each
player renders the opponent’s Hamiltonian singular. This is therefore an
pair of “dynamically equalizing strategies”. The Isaacs equation is as
follows. We let Vi(t, x) be the two Value functions of the players. We
write λi(t, x) for their derivative in x. If they are of class C1, they satisfy
∂Vi(t, x)
∂t
+ Hi(λi, φ⋆
1, φ⋆
2) = 0 ,
Vi(τ, x) = M(x) ,
(20.8)
with
Hi(λi, u1, u2) = λi(a1u1 + a2u2 + cu1u2 −δ) −εiui .
In these equations, (φ⋆
1, φ⋆
2) stands for a Nash equilibrium of the 2 × 2
game whose payoﬀs are the Hi.
It is useful to rewrite this as
Hi(λi, u1, u2)
=
( ui
1 −ui )λiA

uj
1 −uj

−εiui
=
( ui
1 −ui )Hi

uj
1 −uj

https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
483
with
A =
 γ
α1
α2
−δ

,
Hi = λiA −εi
 1
1
0
0

.
As a result, the Nash point sought is that of the bi-matrix game
u1\u2
1
0
λ2γ −ε2
λ2α1
1
λ1γ −ε1
λ1α1 −ε1
λ2α2 −ε2
−λ2δ
0
λ1α2
−λ1δ
Notice that in this game, with reference to the notations of the previous
sections,
σi = λic ,
∆i: = det Hi = −λ2
i (a1a2 + cδ) + λiajεi .
(20.9)
The Nash equilibria of the above bi-matrix game are singular controls
in the sense of control theory. They are
φ⋆
i = εj −λjaj
λjc
(20.10)
We investigate a ﬁeld of trajectories reaching the boundary x = 1. On
such trajectories, locally, the ﬁnal time is unconstrained. As the rest of
the formulation is time invariant, the associated Value is stationary, and
∂Vi/∂t = 0. Placing this and (20.10) in (20.8) yields
φ⋆
i = δ
ai
,
(20.11)
and therefore
˙x = δ a1a2 + cδ
a1a2
= δ
α1α2 + γδ
(α1 + δ)(α2 + δ) .
(20.12)
This slope is necessarily positive and less than γ. However, depending
on c, it may be more or less than αi.
Theorem 20.11 If
T >
a1a2
δ(a1a2 + cδ) ,
and
εi < a1a2 + cδ
aj
,
the mixed strategies (20.11) are a Nash equilibrium over feedback
strategies.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

484
P. Bernhard and F. Hamelin
Proof
Using (20.12), the ﬁrst condition in the theorem insures that
τ < T, hence M(x(τ)) = 1, and using this, the second one insures that
both parents get a positive reward. (Otherwise, ui = 0 is better.) If so,
the functions
Vi(x) = 1 −
εiaj
a1a2 + cδ (1 −x)
satisfy equations (20.8) in the region of the game space covered by the
trajectories (20.12), which includes the initial sate of interest, x(0) = 0.
20.4.4.2 Time-constrained trajectories
We investigate now trajectories that end up exactly at time T with
x(T) = 1, such that both parents get a positive reward. Let ui ∈[0, 1]
be such that
T[a1u1 + a2u2 + cu1u2 −δ] = 1 ,
Tεiui < 1 .
(20.13)
Theorem 20.12 Under conditions (20.13) the pair of constant controls
(u1, u2) is a Nash equilibrium over feedback strategies if and only if for
i = 1, 2, either ui = 1 and 1−Tαi ∈[0, (γ −αi)/εj], or uj ≥φ⋆
j as given
by (20.11).
Proof We compare the constant control ui to any ui + vi(t), assuming
that the other parent keeps its control uj constant. Let τ be the ﬁnal
time on the trajectory generated by these new controls. If τ = T and
x(T) < 1, both parents have a negative payoﬀ. Parent i loses in so
doing. Therefore, the new control can be better only if τ ≤T, which is
impossible to achieve by player i alone if ui = 1.
Assume thus that ui = 1. Since we also assume x(T) = 1, this implies
uj = ( 1
T −αi)/(γ−αi). This must be non-negative, and yield 1−εjTuj >
0, which is what our condition ensures.
Assume now that ui < 1, and let wi =
 τ
0 vi(t) dt. We have
τ[a1u1 + a2u2 + cu1u2 −δ] + (ai + cuj)wi = 1 ,
(20.14)
We assume that indeed τ ≤T, thus that wi > 0. (Recall that ai +cuj ≥
0, even though c may be negative.) We have also Ji(ui + vi, uj) = 1 −
εiτui −εiwi , Using (20.13) and (20.14) we ﬁnd that
Ji(ui + vi, uj) −Ji(ui, uj) = −εiwiT(ajuj −δ) .
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
485
Therefore, if ajuj −δ < 0, the open loop control ui + vi(·) improves the
reward of player i, and (u1, u2) was not Nash. Conversely, if ajuj −δ ≥0,
no open loop control can improve Ji, and then no feedback strategy
can either. (Just apply the above calculation with ui + vi(t) equal to
the control of player i generated by a test closed loop strategy and uj.)
Notice also that if uj = φ⋆
j, the variation in Ji is identically 0. This is
the classical equalization property of mixed Nash equilibria.
The trajectories generated by these new Nash strategies are straight
lines through the point t = T, x = 1. They ﬁll the void between the last
bi-singular trajectory and the curve Lγ of Figure 20.2, and cut into the
bi-singular ﬁeld if a ui = 1 is Nash.
20.4.5 Biological implications
Let us mention a few biological considerations drawn from this analysis.
First, let us comment on the parameters of the game. As opposed to
previous literature, we have both a ﬁxed level of welfare to reach and a
maximum end time. Moreover, we let welfare go down if the child is left
without care. Also, we allow male and female to be asymmetric in terms
of “cost” of breeding their oﬀspring. One of the two, for instance, might
be more prone to predation, either because it is more visible, or less apt
to defend its life. Also, we let them diﬀer in their eﬃciency at gathering
food or otherwise breeding the child.
In that respect, intuitively, if γ > α1 + α2, we may consider this as
a synergetic eﬀect, since both parents acting together do better than
the sum of their lone eﬀorts. But if we consider that the eﬃciency of
a parent is in replacing a decrease rate of δ by an increase of αi, i.e.
ai = αi+δ, and similarily for the pair γ +δ, then the measure of synergy
is rather c. Both play a role in the above results.
We do not claim to have described all Nash equilibria. But they are
clearly highly non-unique. More analysis in terms of biological interpre-
tations is needed to sort them out. We give here a few hints.
We notice that some regions of the game space have the mixed stratey
as their natural outcome. It is particularily so if T is large and the εi
small enough, so that the pure Nash equilibria are (1, 0) and (0, 1). Then,
the mixed equilibrium appears as the “fair” outcome. The link with an
ESS in a population comprising both males and females remains to be
investigated further.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

486
P. Bernhard and F. Hamelin
The peculiarity of the mixed Nash is that each parent does exactly the
eﬀort which, if made alone, keeps ˙x = 0. The interpretation is that this
is true on locally time-unconstrained trajectories. Therefore the same
reasoning as in [7] holds. The fact that the available time be, globally,
constrained by T is reﬂected, on the one hand, through the possible
overlap of the bi-singular ﬁeld of trajectories with the ﬁeld (0, 0), and
on the other hand, by the existence of a new ﬁeld of mixed equilibria
trajectories, ﬁlling the gap between the bi-singular ﬁeld and the fastest
trajectory to just-in-time completion of the breeding process.
A last point we want to raise is that of the incentive to defect. It
follows from the threshold εi < ai + cδ/aj that, if c > 0, increasing the
eﬃciency of the partner j will eventually lead to a choice for i to desert.
An apparent paradox. The explanation we propose is that c > 0 means a
large synergetic eﬀect. In that case, a less eﬃcient mate, having a lower
aj, has a larger φ⋆
j = δ/aj. (The threshold is precisely ai + cφ⋆
j.) Thus,
under the mixed strategy, it will be more often present in the nest, and
through the synergetic eﬀect, this will compensate and over for its lower
eﬃciency.
Is this a plausible explanation for the paradox of the handicap [5, 17,
16, 10] in sexual selection whereby a morphological trait which is a clear
handicap to the individual enhances its sex-appeal ? We doubt, since it
has been noticed that, as a rule, accross species, the male takes the less
care of the young that the morphological diﬀerence is larger.
Bibliography
[1]
C. J. Bampfylde and M. A. Lewis. Biological control through intraguild
predation: case studies in pest control, invasive species and range expansion.
Bulletin of Mathematical Biology 69:1031–1066, 2007.
[2]
T. H. Clutton-Brock. The Evolution of Parental Care, University Press,
Oxford, 1991.
[3]
M. Doebeli and C. Hauert. Models of cooperation based on Prisoner’s
dilemma and Snowdrift games. In Ecology Letters, 8:748–756, 2005.
[4]
C.-O. Ewald, J. M. McNamara and A. Houston. Parental care as a diﬀer-
ential game: a dynamic extension of the Houston–Davis game. Applied
Mathematics and Computations, 190:1450–1465, 2007.
[5]
R. A. Fisher. The Genetical Theory of Natural Selection, University Press,
Oxford, 1930.
[6]
F. Hamelin. Jeux dynamiques en ´ecologie du comportement. th`ese de
doctorat, Universit´e de Nice, soutenue le 4 juillet 2007.
[7]
F. Hamelin and P. Bernhard. Uncoupling Isaacs’equations in two-player
nonzero-sum diﬀerential games. Parental conﬂict over care as an example.
Automatica, 44:882–885, 2008.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

Two-by-two static, evolutionary, and dynamic games
487
[8]
A. I. Houston and N. B. Davies. The evolution of cooperation and life
history in the dunnock Prunella modularis. In Behavioural Ecology, R. M.
Silby and R. H. Smith (eds) pp. 471–487. Blackwell Scientiﬁc Publications,
1985.
[9]
A. I. Houston, T. Szekely and J. M. McNamara. Conﬂict between parents
over care. Trends in Ecology and Evolution, 20:33–38, 2005.
[10]
H. Kokko, M. D. Jennions and R. Brooks. Unifying and testing models
of sexual selection. Annual Reviews of Ecology, Evolution and Systematics,
37:43–66, 2006.
[11]
J. M. McNamara, et al. A dynamic game-theoretic model of parental
care. Journal of Theoretical Biology 205:605–623, 2000.
[12]
J.-J. Rousseau. Discours sur l’origine et les fondemens de l’in´egalit´e
parmi les hommes (Deuxi`eme partie), Dijon, 1755.
(See http://hypo.ge.ch/athena/rousseau/jjr ineg.html)
[13]
L. Samuelson. Evolutionary Games and Equilibrium Selection. MIT
Press, 1998.
[14]
W. H. Sandholm. Population Games and Evolutionary Dynamics.
Preprint, http://www.ssc.edu/∼whs/book/index.html, 2007.
[15]
J. G. Wardrop. Some theoretical aspects of road traﬁc. Proceedings of
the Institution of Civil Engineers, Part II, 1:325–378, 1952.
[16]
T. Winquist and R. E. Lemon. Sexual selection and exaggerated male
tail length in birds. The American Naturalist, 143:95–116, 1994.
[17]
A. Zahavi. Mate selection – a selection for the handicap. Journal of
Theoretical Biology, 53:205–214, 1975.
https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

https://doi.org/10.1017/CBO9780511770524.021 Published online by Cambridge University Press

