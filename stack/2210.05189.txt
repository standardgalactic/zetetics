Neural Networks are Decision Trees
Caglar Aytekin
AI Lead
AAC Technologies
caglaraytekin@aactechnologies.com, cagosmail@gmail.com
Abstract
In this manuscript, we show that any neural network
with any activation function can be represented as a de-
cision tree. The representation is equivalence and not an
approximation, thus keeping the accuracy of the neural net-
work exactly as is. We believe that this work provides bet-
ter understanding of neural networks and paves the way to
tackle their black-box nature. We share equivalent trees
of some neural networks and show that besides providing
interpretability, tree representation can also achieve some
computational advantages for small networks. The analysis
holds both for fully connected and convolutional networks,
which may or may not also include skip connections and/or
normalizations.
1. Introduction
Despite the immense success of neural networks over the
past decade, the black-box nature of their predictions pre-
vent their wider and more reliable adoption in many indus-
tries, such as health and security. This fact led researchers to
investigate ways to explain neural network decisions. The
efforts in explaining neural network decisions can be cate-
gorized into several approaches: saliency maps, approxima-
tion by interpretable methods and joint models.
Saliency maps are ways of highlighting areas on the in-
put, of which a neural network make use of the most while
prediction. An earlier work [20] takes the gradient of the
neural network output with respect to the input in order to
visualize an input-speciﬁc linearization of the entire net-
work. Another work [26] uses a deconvnet to go back to
features from decisions. The saliency maps obtained via
these methods are often noisy and prevent a clear under-
standing of the decisions made. Another track of meth-
ods [29], [18], [4], [6] make use of the derivative of a neural
network output with respect to an activation, usually the one
right before fully connected layers. This saliency maps ob-
tained by this track, and some other works [27], [11], [5] are
clearer in the sense of highlighting areas related to the pre-
dicted class. Although useful for purposes such as check-
ing whether the support area for decisions are sound, these
methods still lack a detailed logical reasoning of why such
decision is made.
Conversion between neural networks and interpretable
by-design models -such as decision trees- has been a topic
of interest. In [8], a method was devised to initialize neural
networks with decision trees. [9, 19, 25] also provides neu-
ral network equivalents of decision trees. The neural net-
works in these works have speciﬁc architectures, thus the
conversion lacks generalization to any model. In [24], neu-
ral networks were trained in such a way that their decision
boundaries can be approximated by trees. This work does
not provide a correspondence between neural networks and
decision trees, and merely uses the latter as a regulariza-
tion. In [7], a neural network was used to train a decision
tree. Such tree distillation is an approximation of a neural
network and not a direct conversion, thus performs poorly
on the tasks that the neural network was trained on.
Joint neural network and decision tree models [12], [16],
[13], [14], [17], [2], [10], [22] genarally use deep learning to
assists some trees, or come up with a neural network struc-
ture so it resembles a tree. A recent work [23] replaces the
ﬁnal fully connected layer of a neural network with a deci-
sion tree. Since the backbone features are still that of neural
networks, the explanation is sought to be achieved via pro-
viding a means to humans to validate the decision as a good
or bad one, rather than a complete logical reasoning of the
decision.
In this paper, we show that any neural network having
any activations has a directly equivalent decision tree rep-
resentation. Thus, the induced tree output is exactly the
same with that of the neural network and tree representation
doesn’t limit or require altering of the neural architecture
in any way. We believe that the decision tree equivalence
provides better understanding of neural networks and paves
the way to tackle the black-box nature of neural networks,
e.g. via analyzing the category that a test sample belongs
to, which can be extracted by the node rules that a sample
is categorized. We show that the decision tree equivalent of
arXiv:2210.05189v3  [cs.LG]  25 Oct 2022

a neural network can be found for either fully connected or
convolutional neural networks which may include skip lay-
ers and normalizations as well. Besides the interpretability
aspect, we show that the induced tree is also advantageous
to the corresponding neural network in terms of computa-
tional complexity, at the expense of increased storage mem-
ory.
Upon writing this paper, we have noticed the following
works having overlaps with ours [28], [3], [15], [21], es-
pecially for feedforward ReLU networks. We extend the
ﬁndings in these works to any activation function and also
recurrent neural networks.
2. Decision Tree Analysis of Neural Networks
The derivations in this section will be ﬁrst made for feed-
forward neural networks with piece-wise linear activation
functions such as ReLU, Leaky ReLU, etc. Next, the analy-
sis will be extended to any neural network with any activa-
tion function.
2.1. Fully Connected Networks
Let Wi be the weight matrix of a network’s ith layer.
Let σ be any piece-wise linear activation function, and x0
be the input to the neural network. Then, the output and an
intermediate feature of a feed-forward neural network can
be represented as in Eq. 1.
NN(x0) = WT
n−1σ(WT
n−2σ(...WT
1 σ(WT
0 x0)))
xi = σ(WT
i−1σ(...WT
1 σ(WT
0 x0)))
(1)
Note that in Eq. 1, we omit any ﬁnal activation (e.g.
softmax) and we ignore the bias term as it can be simply
included by concatenating a 1 value to each xi. The acti-
vation function σ acts as an element-wise scalar multiplica-
tion, hence the following can be written.
WT
i σ(WT
i−1xi−1) = WT
i (ai−1 ⊙(WT
i−1xi−1))
(2)
In Eq. 2, ai−1 is a vector indicating the slopes of activa-
tions in the corresponding linear regions where WT
i−1xi−1
fall into, ⊙denotes element-wise multiplication. Note that,
ai−1 can directly be interpreted as a categorization result
since it includes indicators (slopes) of linear regions in ac-
tivation function. The Eq. 2 can be re-organized as follows.
WT
i σ(WT
i−1xi−1) = (Wi ⊙ai−1)T WT
i−1xi−1
(3)
In Eq.
3, we use ⊙as a column-wise element-wise
multiplication on Wi. This corresponds to element-wise
multiplication by a matrix obtained via by repeating ai−1
column-vector to match the size of Wi. Using Eq. 3, Eq. 1
can be rewritten as follows.
NN(x0) = (Wn−1 ⊙an−2)T (Wn−2 ⊙an−3)T
...(W1 ⊙a0)T WT
0 x0
(4)
From Eq. 4, one can deﬁne an effective weight matrix
ˆW
T
i of a layer i to be applied directly on input x0 as follows:
Ci−1 ˆW
T
i = (Wi ⊙ai−1)T ...(W1 ⊙a0)T WT
0
Ci−1 ˆW
T
i x0 = WT
i xi
(5)
In Eq. 5, the categorization vector until layer i is de-
ﬁned as follows: ci−1 = a0 ∥a1 ∥...ai−1, where ∥is the
concatenation operator.
One can directly observe from Eq.
5 that, the effec-
tive matrix of layer i is only dependent on the categoriza-
tion vectors from previous layers. This indicates that in
each layer, a new efﬁcient ﬁlter is selected -to be applied
on the network input- based on the previous categoriza-
tions/decisions. This directly shows that a fully connected
neural network can be represented as a single decision tree,
where effective matrices acts as categorization rules.
In
each layer i, response of effective matrix Ci−1 ˆW
T
i is catego-
rized into ai vector, and based on this categorization result,
next layer’s effective matrix Ci ˆW
T
i+1 is determined. A layer
i is thus represented as kmi-way categorization, where mi is
the number ﬁlters in each layer i and k is the total number
of linear regions in an activation. This categorization in a
layer i can thus be represented by a tree of depth mi, where
a node in any depth is branched into k categorizations.
In order to better illustrate the equivalent decision tree of
a neural network, in Algorithm 1, we rewrite Eq. 5 for the
entire network, as an algorithm. For the sake of simplic-
ity and without loss of generality, we provide the algorithm
with the ReLU activation function, where a ∈{0, 1}. It
can be clearly observed that, the lines 5 −9 in Algorithm 1
corresponds to a node in the decision tree, where a simple
yes/no decision is made.
The decision tree equivalent of a neural network can thus
be constructed as in Algorithm 2. Using this algorithm,
we share a a tree representation obtained for a neural net-
work with three layers, having 2,1 and 1 ﬁlter for layer 1,
2 and 3 respectively. The network has ReLU activation in
between layers, and no activation after last layer. It can be
observed from Algorithm 2 and Fig. 1 that the depth of a
NN-equivalent tree is d = Pn−2
i=0 mi, and total number of
categories in last branch is 2d. At ﬁrst glance, the number
of categories seem huge. For example, if ﬁrst layer of a neu-
ral network contains 64 ﬁlters, there would exist at least 264
branches in a tree, which is already intractable. But, there

WT
00x0 > 0
WT
01x0 > 0
00 ˆ
W10
T x0 > 0
000 ˆ
W20
T x0
001 ˆ
W20
T x0
01 ˆ
W10
T x0 > 0
010 ˆ
W20
T x0
011 ˆ
W20
T x0
WT
01x0 > 0
10 ˆ
W10
T x0 > 0
100 ˆ
W20
T x0
101 ˆ
W20
T x0
11 ˆ
W10
T x0 > 0
110 ˆ
W20
T x0
111 ˆ
W20
T x0
Figure 1. Decision Tree for a 2-layer ReLU Neural Network
may occur violating and redundant rules that would pro-
vide lossless pruning of the NN-equivalent tree. Another
observation is that, it is highly likely that not all categories
will be realized during training due to the possibly much
larger number of categories (tree leaves) than training data.
These categories can be pruned as well based on the ap-
plication, and the data falling into these categories can be
considered invalid, if the application permits. In the next
section, we show that such redundant, violating and unre-
alized categories indeed exist, by analysing decision trees
of some neural networks. But before that, we show that the
tree equivalent of a neural network exists for skip connec-
tions, normalizations, convolutions, other activation func-
tions and recurrence.
2.1.1
Skip Connections
We analyse a residual neural network of the following type:
rx0 = WT
0 x0
rxi = rxi−1 + WT
i σ(rxi−1)
(6)
Using Eq. 6, via a similar analysis in Sec. 2.1, one can
rewrite rxi as follows.
rxi = ai−1 ˆW
T
i rxi−1
ai−1 ˆW
T
i = I + (Wi ⊙ai−1)T
(7)
Finally, using ai−1 ˆW
T
i in Eq. 7, one can deﬁne effective
matrices for residual neural networks as follows.
rxi = r ˆW
T
i x0
r ˆW
T
i = ai−1 ˆW
T
i ai−2 ˆW
T
i−1...a0 ˆW
T
1 WT
0
(8)
One can observe from Eq. 8 that, for layer i, the residual
effective matrix r ˆW
T
i is deﬁned solely based on categoriza-
tions from the previous activations. Similar to the analysis
Algorithm 1: Algorithm of Eq. 5 for ReLU net-
works
1 ˆW = W0
2 for i = 0 to n −2 do
3
a = []
4
for j = 0 to mi −1 do
5
if ˆW
T
ijx0 > 0 then
6
a.append(1)
7
else
8
a.append(0)
9
end
10
end
11
ˆW = ˆW(Wi+1 ⊙a)
12 end
13 return ˆW
T x0
Algorithm 2: Algorithm of converting neural net-
works to decision trees
1 Initialize Tree: Set root.
2 Branch all leafs to k nodes, decision rule is ﬁrst
effective ﬁlter.
3 Branch all nodes to k more nodes, and repeat until
all effective ﬁlters in a layer is covered.
4 Calculate effective matrix for each leaf via Eq. 5.
Repeat 2,3.
5 Repeat 4 until all layers are covered.
6 return Tree
in Sec. 2.1, this enables a tree equivalent of residual neural
networks.

2.1.2
Normalization Layers
A separate analysis is not needed for any normalization
layer, as popular normalization layers are linear, and after
training, they can be embedded into the linear layer that it
comes after or before, in pre-activation or post-activation
normalizations respectively.
2.2. Convolutional Neural Networks
Let Ki : Ci+1 ×Ci ×Mi ×Ni be the convolution kernel
for layer i, applying on an input Fi : Ci × Hi × Wi. Note
that Mi and Ni denote the spatial size of the convolutional
kernel, and Hi and Wi denote the spatial size of the input.
One can write the output of a convolutional neural net-
work CNN(F0), and an intermediate feature Fi as follows.
CNN(F0) = Kn−1 ∗σ(Kn−2 ∗σ(...σ(K0 ∗F0))
Fi = σ(Ki−1 ∗σ(...σ(K0 ∗F0))
(9)
Similar to the fully connected network analysis, one can
write the following, due to element-wise scalar multiplica-
tion nature of the activation function.
Ki ∗σ(Ki−1 ∗Fi−1) = (Ki ⊙ai−1) ∗(Ki−1 ∗Fi−1) (10)
In Eq. 10, ai−1 is of same spatial size as Ki and consists
of the slopes of activation function in corresponding regions
in the previous feature Fi−1. Note that the above only holds
for a speciﬁc spatial region, and there exists a separate ai−1
for each spatial region that the convolution Ki−1 is applied
to. For example, if Ki−1 is a 3 × 3 kernel, there exists a
separate ai−1 for all 3 × 3 regions that the convolution is
applied to. An effective convolution Ci−1 ˆKi can be written
as follows.
ci−1 ˆKi = (Ki ⊙ai−1) ∗... ∗(K1 ⊙a0) ∗K0
ci−1 ˆKi ∗x0 = Ki ∗xi
(11)
Note that in Eq. 11, Ci−1 ˆKi contains speciﬁc effective
convolutions per region, where a region is deﬁned accord-
ing to the receptive ﬁeld of layer i. c is deﬁned as the con-
catenated categorization results of all relevant regions from
previous layers.
One can observe from Eq.
11 that effecive convolu-
tions are only dependent on categorizations coming from
activations, which enables the tree equivalence -similar to
the analysis for fully connected network. A difference from
fully connected layer case is that many decisions are made
on partial input regions rather than entire x0.
2.3. Continuous Activation Functions
In Eq. 2, for piece-wise linear activations, elements of a
can have a number of values limited by the piece-wise lin-
ear regions in the activation function. This number deﬁnes
the number of child nodes per effective ﬁlter. The exten-
sion to continuous activation functions is trivial as they can
be considered as piece-wise linear functions with inﬁnite
regions. Therefore, for continuous activations, the neural
network equivalent tree immediately becomes inﬁnite width
even for a single ﬁlter. This might not be a useful result, but
we provide this discussion here for completeness. In order
to guarantee ﬁnite trees, one may consider using quantized
versions of continuous activations which may result in a few
piece-wise linear regions, hence few child nodes per activa-
tion.
2.4. Recurrent Networks
As recurrent neural networks (RNNs) can be unrolled to
feed-forward representation, RNNs can also be equivalently
represented as decision trees. We study following recurrent
neural network. Note that we simply omit the bias terms as
they can be represented by concatenating a 1 value to input
vectors.
h(t) = σ(WT h(t−1) + UT x(t))
o(t) = VT h(t)
(12)
Similar to previous analysis, one can rewrite h(t) as fol-
lows.
h(t) = a(t) ⊙(WT h(t−1) + UT x(t))
(13)
Eq. 13 can be rewritten follows.
h(t) = a(t) ⊙(
1
Y
j=(t−1)
(WT ⊙a(j)))WT h(0)
+a(t) ⊙
t
X
i=1
(
iY
j=(t−1)
(WT ⊙a(j)))UT x(i)
(14)
Note that in Eq. 14, the product operator stands for ma-
trix multiplication, its steps are −1 and we consider the out-
put of product operator to be 1 when i = t. One can rewrite
Eq. 14 by introducing cj ˆWj as follows.
h(t) = a(t) ⊙c1 ˆW1WT h(0) + a(t) ⊙
t
X
i=1
ci ˆWiUT x(i)
ci ˆW
T
i =
iY
j=(t−1)
(WT ⊙a(j))
(15)

x < −1.16
x < 0.32
x > 1
x < −0.1
0 ˆW
T x0
1 ˆW
T x0
x0 < −0.1
2 ˆW
T x
3 ˆW
T x
x > 0.54
x < 0.11
4 ˆW
T x
5 ˆW
T x
x < 0.11
6 ˆW
T x
7 ˆW
T x
x < 0.32
x > 0.52
x < −0.7
8 ˆW
T x
9 ˆW
T x
x < −0.7
10 ˆW
T x
11 ˆW
T x
x > 0.39
x < −0.38
12 ˆW
T x
13 ˆW
T x
x < −0.38
14 ˆW
T x
15 ˆW
T x
Figure 2. Decision Tree for a y = x2 Regression Neural Network
x < −1.16
x < 0.32
x > 1
0.55x + 0.09
3.47x −2.83
x < 0.11.
2.37x −0.50
−1.00x −0.12
−3.67x −3.22
(a) Cleaned Tree
(b) Neural Network Approximation of y = x2
Figure 3. Cleaned Decision Tree for a y = x2 Regression Neural Network
Combining Eq. 15 and Eq. 12, one can write o(t) as
follows.
o(t) = a(t) ˆV
T
c1 ˆW1WT h(0)+a(t) ˆV
T
t
X
i=1
ci ˆWiUT x(i) (16)
Eq. 16 can be further simpliﬁed to the following.
o(t) = c1 ˆZ
T
1 WT h(0) +
t
X
i=1
ci ˆZiUT x(i)
(17)
In Eq. 17, ci ˆZ
T
i = a(t) ˆV
T
ci ˆWi .As one can observe from
Eq. 17, the RNN output only depends on the categoriza-
tion vector ci, which enables the tree equivalence -similar
to previous analysis.
Note that for RNNs, a popular choice for σ in Eq. 12
is tanh. As mentioned in Section 2.3, in order to provide
ﬁnite trees, one might consider using a piece-wise linear
approximation of tanh.
3. Experimental Results
First, we make a toy experiment where we ﬁt a neural
network to: y = x2 equation. The neural network has 3
dense layers with 2 ﬁlters each, except for last layer which
has 1 ﬁlter. The network uses leaky-ReLU activations after
fully connected layers, except for the last layer which has
no post-activation. We have used negative slope of 0.3 for
leaky-ReLU which is the default value in Tensorﬂow [1].
The network was trained with 5000 (x, y) pairs where x was
regularly sampled from [−2.5, 2.5] interval. Fig. 2 shows
the decision tree corresponding to the neural network. In the
tree, every black rectangle box indicates a rule, left child
from the box means the rule does not hold, and the right
child means the rule holds. For better visualization, the
rules are obtained via converting wT x + β > 0 to direct
inequalities acting on x. This can be done for the partic-
ular regression y = x2, since x is a scalar. In every leaf,
the network applies a linear function -indicated by a red
rectangle- based on the decisions so far. We have avoided
writing these functions explicitly due to limited space. At
ﬁrst glance, the tree representation of a neural network in
this example seems large due to the 2
Pn−2
i
mi = 24 = 16
categorizations. However, we notice that a lot of the rules
in the decision tree is redundant, and hence some paths in
the decision tree becomes invalid. An example to redundant
rule is checking x < 0.32 after x < −1.16 rule holds. This

−0.98x −0.49y + 0.95
−1.6x + 0.2y −0.07
−0.15x + 0.19y + 0.41
1
0.45x −0.3y + 0.05
0
1.6x −1.35y −1.44
0
1
0
−1.6x + 0.2y −0.07
0.5x + 0.52y −0.22
1
−0.46x −0.76y + 0.94
0
−2.72x −3.53y + 2.77
0
1
−0.5x + 0.64y −0.27
1.51x −1y + 1.03
1.59x −1.35y + 0.78
0
1
4.18x −3.17y + 2.54
0
1
1.51x −1y + 1.03
0
5.31x −4.51y + 3.14
0
1
Figure 4. Classiﬁcation Tree for a Half-Moon Classiﬁcation Neural Network
Figure 5. Categorizations made by the decision tree for half-moon
dataset
directly creates the invalid left child for this node. Hence,
the tree can be cleaned via removing the left child in this
case, and merging the categorization rule to the stricter one :
x < −1.16 in the particular case. Via cleaning the decision
tree in Fig. 2, we obtain the simpler tree in Fig. 3a, which
only consists of 5 categories instead of 16. The 5 categories
are directly visible also from the model response in Fig. 3b.
The interpretation of the neural network is thus straightfor-
ward: for each region whose boundaries are determined via
the decision tree representation, the network approximates
the non-linear y = x2 equation by a linear equation. One
can clearly interpret and moreover make deduction from the
decision tree, some of which are as follows. The neural
network is unable to grasp the symmetrical nature of the
regression problem which is evident from the fact that the
decision boundaries are asymmetrical. The region in below
−1.16 and above 1 is unbounded and thus neural decisions
lose accuracy as x goes beyond these boundaries.
Next, we investigate another toy problem of classifying
half-moons and analyse the decision tree produced by a neu-
ral network. We train a fully connected neural network with
y = x2
Half-Moon
Param.
Comp.
Mult./Add.
Param.
Comp.
Mult./Add.
Tree
14
2.6
2
39
4.1
8.2
NN
13
4
16
15
5
25
Table 1. Computation and memory analysis of toy problems.
3 layers with leaky-ReLU activations, except for last layer
which has sigmoid activation. Each layer has 2 ﬁlters ex-
cept for the last layer which has 1. The cleaned decision
tree induced by the trained network is shown in Fig. 4. The
decision tree ﬁnds many categories whose boundaries are
determined by the rules in the tree, where each category
is assigned a single class. In order to better visualize the
categories, we illustrate them with different colors in Fig.
5. One can make several deductions from the decision tree
such as some regions are very well-deﬁned, bounded and
the classiﬁcations they make are perfectly in line with the
training data, thus these regions are very reliable. There are
unbounded categories which help obtaining accurate classi-
ﬁcation boundaries, yet fail to provide a compact represen-
tation of the training data, these may correspond to inaccu-
rate extrapolations made by neural decisions. There are also
some categories that emerged although none of the training
data falls to them.
Besides the interpretability aspect, the decision tree rep-
resentation also provides some computational advantages.
In Table 1, we compare the number of parameters, ﬂoat-
point comparisons and multiplication or addition operations
of the neural network and the tree induced by it. Note that
the comparisons, multiplications and additions in the tree
representation are given as expected values, since per each
category depth of the tree is different. As the induced tree
is an unfolding of the neural network, it covers all possi-
ble routes and keeps all possible effective ﬁlters in mem-
ory. Thus, as expected, the number of parameters in the tree
representation of a neural network is larger than that of the
network. In the induced tree, in every layer i, a maximum

of mi ﬁlters are applied directly on the input, whereas in the
neural network always mi ﬁlters are applied on the previous
feature, which is usually much larger than the input in the
feature dimension. Thus, computation-wise, the tree repre-
sentation is advantageous compared to the neural network
one.
4. Conclusion
In this manuscript, we have shown that neural networks
can be equivalently represented as decision trees. The tree
equivalence holds for fully connected layers, convolutional
layers, residual connections, normalizations, recurrent lay-
ers and any activation. We believe that this tree equivalence
provides directions to tackle the black-box nature of neural
networks.
References
[1] Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene
Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy
Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian
Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath
Kudlur, Josh Levenberg, Dandelion Man´e, Rajat Monga,
Sherry Moore, Derek Murray, Chris Olah, Mike Schuster,
Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Tal-
war, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fer-
nanda Vi´egas, Oriol Vinyals, Pete Warden, Martin Watten-
berg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensor-
Flow: Large-scale machine learning on heterogeneous sys-
tems, 2015. Software available from tensorﬂow.org. 5
[2] Karim Ahmed, Mohammad Haris Baig, and Lorenzo Torre-
sani. Network of experts for large-scale image categoriza-
tion. In European Conference on Computer Vision, pages
516–532. Springer, 2016. 1
[3] Randall Balestriero and Richard Baraniuk.
Mad max:
Afﬁne spline insights into deep learning.
arXiv preprint
arXiv:1805.06576, 2018. 2
[4] Aditya Chattopadhay, Anirban Sarkar, Prantik Howlader,
and Vineeth N Balasubramanian.
Grad-cam++: General-
ized gradient-based visual explanations for deep convolu-
tional networks. In 2018 IEEE winter conference on appli-
cations of computer vision (WACV), pages 839–847. IEEE,
2018. 1
[5] Edo Collins, Radhakrishna Achanta, and Sabine Susstrunk.
Deep feature factorization for concept discovery.
In Pro-
ceedings of the European Conference on Computer Vision
(ECCV), pages 336–352, 2018. 1
[6] Rachel Lea Draelos and Lawrence Carin. Use hirescam in-
stead of grad-cam for faithful explanations of convolutional
neural networks. arXiv e-prints, pages arXiv–2011, 2020. 1
[7] Nicholas Frosst and Geoffrey Hinton.
Distilling a neu-
ral network into a soft decision tree.
arXiv preprint
arXiv:1711.09784, 2017. 1
[8] Kelli D Humbird, J Luc Peterson, and Ryan G McClar-
ren. Deep neural network initialization with decision trees.
IEEE transactions on neural networks and learning systems,
30(5):1286–1295, 2018. 1
[9] Peter Kontschieder, Madalina Fiterau, Antonio Criminisi,
and Samuel Rota Bulo. Deep neural decision forests. In Pro-
ceedings of the IEEE international conference on computer
vision, pages 1467–1475, 2015. 1
[10] Mason McGill and Pietro Perona. Deciding how to decide:
Dynamic routing in artiﬁcial neural networks. In Interna-
tional Conference on Machine Learning, pages 2363–2372.
PMLR, 2017. 1
[11] Mohammed Bany Muhammad and Mohammed Yeasin.
Eigen-cam: Class activation map using principal compo-
nents.
In 2020 International Joint Conference on Neural
Networks (IJCNN), pages 1–7. IEEE, 2020. 1
[12] Ravi Teja Mullapudi, William R Mark, Noam Shazeer, and
Kayvon Fatahalian. Hydranets: Specialized dynamic archi-
tectures for efﬁcient inference. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 8080–8089, 2018. 1
[13] Calvin Murdock, Zhen Li, Howard Zhou, and Tom Duerig.
Blockout: Dynamic model selection for hierarchical deep
networks. In Proceedings of the IEEE conference on com-
puter vision and pattern recognition, pages 2583–2591,
2016. 1
[14] Venkatesh N Murthy, Vivek Singh, Terrence Chen, R Man-
matha, and Dorin Comaniciu. Deep decision network for
multi-class image classiﬁcation.
In Proceedings of the
IEEE conference on computer vision and pattern recogni-
tion, pages 2240–2248, 2016. 1
[15] Duy T Nguyen, Kathryn E Kasmarik, and Hussein A Ab-
bass. Towards interpretable anns: An exact transformation
to multi-class multivariate decision trees.
arXiv preprint
arXiv:2003.04675, 2020. 2
[16] Joseph Redmon and Ali Farhadi. Yolo9000: better, faster,
stronger. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 7263–7271, 2017. 1
[17] Anirban Roy and Sinisa Todorovic. Monocular depth esti-
mation using neural regression forest. In Proceedings of the
IEEE conference on computer vision and pattern recogni-
tion, pages 5506–5514, 2016. 1
[18] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das,
Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
Grad-cam:
Visual explanations from deep networks via
gradient-based localization. In Proceedings of the IEEE in-
ternational conference on computer vision, pages 618–626,
2017. 1
[19] Ishwar Krishnan Sethi. Entropy nets: from decision trees
to neural networks. Proceedings of the IEEE, 78(10):1605–
1613, 1990. 1
[20] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
Deep inside convolutional networks:
Visualising image
classiﬁcation models and saliency maps.
arXiv preprint
arXiv:1312.6034, 2013. 1
[21] Agus Sudjianto, William Knauth, Rahul Singh, Zebin Yang,
and Aijun Zhang. Unwrapping the black box of deep relu
networks: interpretability, diagnostics, and simpliﬁcation.
arXiv preprint arXiv:2011.04041, 2020. 2

[22] Andreas Veit and Serge Belongie. Convolutional networks
with adaptive inference graphs. In Proceedings of the Euro-
pean Conference on Computer Vision (ECCV), pages 3–18,
2018. 1
[23] Alvin Wan, Lisa Dunlap, Daniel Ho, Jihan Yin, Scott Lee,
Henry Jin, Suzanne Petryk, Sarah Adel Bargal, and Joseph E
Gonzalez.
Nbdt:
neural-backed decision trees.
arXiv
preprint arXiv:2004.00221, 2020. 1
[24] Mike Wu, Michael Hughes, Sonali Parbhoo, Maurizio Zazzi,
Volker Roth, and Finale Doshi-Velez. Beyond sparsity: Tree
regularization of deep models for interpretability. In Pro-
ceedings of the AAAI conference on artiﬁcial intelligence,
volume 32, 2018. 1
[25] Yongxin Yang, Irene Garcia Morillo, and Timothy M
Hospedales.
Deep neural decision trees.
arXiv preprint
arXiv:1806.06988, 2018. 1
[26] Matthew D Zeiler and Rob Fergus. Visualizing and under-
standing convolutional networks. In European conference on
computer vision, pages 818–833. Springer, 2014. 1
[27] Jianming Zhang, Sarah Adel Bargal, Zhe Lin, Jonathan
Brandt, Xiaohui Shen, and Stan Sclaroff. Top-down neu-
ral attention by excitation backprop. International Journal
of Computer Vision, 126(10):1084–1102, 2018. 1
[28] Liwen Zhang, Gregory Naitzat, and Lek-Heng Lim. Tropical
geometry of deep neural networks. In International Confer-
ence on Machine Learning, pages 5824–5832. PMLR, 2018.
2
[29] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva,
and Antonio Torralba. Learning deep features for discrimina-
tive localization. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pages 2921–2929,
2016. 1

