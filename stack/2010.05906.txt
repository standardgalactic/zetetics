Back to the Future: Unsupervised Backprop-based Decoding for
Counterfactual and Abductive Commonsense Reasoning
Lianhui Qin†‡
Vered Shwartz †‡
Peter West †‡
Chandra Bhagavatula‡
Jena D. Hwang ‡
Ronan Le Bras ‡
Antoine Bosselut ^‡
Yejin Choi†‡
†Paul G. Allen School of Computer Science & Engineering, University of Washington
‡Allen Institute for Artiﬁcial Intelligence
^Stanford University
{lianhuiq, pawest, yejin}@cs.washington.edu
{vered, chandrab, jenah, ronanlb}@allenai.org
Abstract
Abductive and counterfactual reasoning, core
abilities of everyday human cognition, require
reasoning about what might have happened at
time t, while conditioning on multiple contexts
from the relative past and future.
However,
simultaneous incorporation of past and future
contexts using generative language models
(LMs) can be challenging, as they are trained
either to condition only on the past context or
to perform narrowly scoped text-inﬁlling.
In this paper, we propose DELOREAN, a new
unsupervised decoding algorithm that can ﬂex-
ibly incorporate both the past and future con-
texts using only off-the-shelf, left-to-right lan-
guage models and no supervision. The key in-
tuition of our algorithm is incorporating the fu-
ture through back-propagation, during which,
we only update the internal representation of
the output while ﬁxing the model parameters.
By alternating between forward and backward
propagation, DELOREAN can decode the out-
put representation that reﬂects both the left
and right contexts. We demonstrate that our
approach is general and applicable to two
nonmonotonic reasoning tasks: abductive text
generation and counterfactual story revision,
where DELOREAN outperforms a range of
unsupervised and some supervised methods,
based on automatic and human evaluation.1
1
Introduction
Everyday causal reasoning requires reasoning
about the likely explanations to partially observ-
able past and future (abductive reasoning (Peirce,
1960)) and reasoning about the alternative future
based on counterfactual past (counterfactual rea-
soning). Such nonmonotonic reasoning requires
1Code
is
available
at
https://github.com/
qkaren/unsup_gen_for_cms_reasoning
She hit the rope 
and the tire fell 
on top of her.
Abductive Reasoning 
Ray hung a tire on 
a rope to make his 
daughter a swing.
Past Observation 
Ray ran to his 
daughter to make 
sure she was okay.
Future Observation 
Original Ending 
Zeke thought about 
being a vampire or 
a wizard.  
Then he decided on 
a scarier costume.  
Zeke dressed up 
like a skeleton. 
Zeke thought about 
Lannister, but he 
didn’t want to look 
like a Lannister. 
He wanted to look 
like a Stark. 
Zeke dressed up like 
a Stark.
Story Context 
Zeke was throwing 
a party. 
All his friends were 
dressing up for this 
Halloween party.  
All his friends were 
dressing up for this 
Game of Thrones 
themed party. 
[Counterfactual]
DELOREAN
Rewritten Ending
Hypothesis
Counterfactual Reasoning
Figure 1: DELOREAN, our proposed method, with gen-
erated reasoning results. Top: the goal in abductive
reasoning is to generate a hypothesis (Y ) of what hap-
pened between the observed past (X) and future (Z)
contexts. Bottom: In counterfactual reasoning, given
a story context altered by a counterfactual condition,
X, and the original ending Z, the goal is to generate a
new ending Y which is coherent with X while remain-
ing similar to Z. The story from TIMETRAVEL (Qin
et al., 2019a) consists of ﬁve sentences. Our approach
alternates forward (left-to-right) and backward (right-
to-left) passes that iteratively reﬁne the generated texts
w.r.t context from each side.
inferring plausible but potentially defeasible con-
clusions from incomplete or hypothetical observa-
tions (Reiter, 1988). While humans are remarkably
good at this type of causal reasoning, developing
AI systems capable of nonmonotonic reasoning for
arXiv:2010.05906v4  [cs.CL]  2 Aug 2021

a wide range of situations describable in natural
language has been a major open research question.
More concretely, with abductive reasoning, the
goal is to ﬁnd the most plausible explanation for
incomplete observations (Peirce, 1960). In the top
part of Figure 1, given the ﬁrst observation that
Ray is “making his daughter a swing” and the later
observation that he “ran to [her] to make sure she
was okay,” we can hypothesize that she somehow
got hurt by the swing.
In contrast, counterfactual reasoning concerns
the causal changes to future events given a change
in the past condition (i.e., “counterfactual condi-
tion”; Goodman, 1947). For example, the bottom
part of Figure 1 shows the original ﬁve sentence
story (S1, ..., S5) and an alternative counterfac-
tual condition given in S′
2—that instead of being
a generic “Halloween party”, the new counterfac-
tual condition is that it is going to be a “Game
of Thrones themed party”! Given these, the prob-
lem we want to solve is to update the future events
(S′
3, ..., S′
5), so that instead of “Zeke dressed up as
skeleton”, we have “Zeke dressed up like a Stark”.2
Recently, two tasks and corresponding bench-
marks have been introduced to tackle language-
based nonmonotonic reasoning: the ART dataset
for abductive NLG (Bhagavatula et al., 2019), and
the TIMETRAVEL dataset for counterfactual story
rewriting (Qin et al., 2019a). Both tasks are framed
as conditional generation, with multiple contexts
to condition on. The currently dominant paradigm
for conditional text generation tasks is ﬁne-tuning
pre-trained language models (LMs), such as GPT2
(Radford et al., 2019a), on large-scale training data
for supervision. However, despite the large num-
ber of training examples, supervised approaches
still perform considerably worse than humans and
are subject to developing superﬁcial strategies such
as repeating the observations as is or memorizing
prevalent surface patters speciﬁc in the dataset (Qin
et al., 2019a). Furthermore, having to require large-
scale training data for each domain and task would
be utterly inefﬁcient for broad-coverage nonmono-
tonic reasoning in language.
In this paper, we investigate an alternative path
toward language-based nonmonotonic reasoning
using pre-trained language models as is. Intuitively,
both the abductive and counterfactual reasoning
2“Lannister” in S′
3 and “Stark” in S′
4 and S′
5 refer to char-
acter names in the TV show, “Game of the Thrones.” All the
output text shown in Figure 1 is the actual system output from
DELOREAN.
requires learning coherent patterns in narrative,
which should be already available in large-scale
pretrained language models. However, the key chal-
lenge is that most generative language models are
trained to condition only on the left context, or to
perform narrowly scoped text-inﬁlling.
This paper presents DELOREAN: DEcoding for
nonmonotonic LOgical REAsoNing, an unsuper-
vised decoding algorithm that only assumes off-the-
shelf left-to-right language models with no supervi-
sion. The key intuition of our algorithm is incorpo-
rating the future through back-propagation, during
which, we only update the internal representation
of the output while ﬁxing the model parameters.
More speciﬁcally, DELOREAN alternates between
the forward and backward passes, where the for-
ward pass performs left-to-right inference given
the left context (roughly maximizing P(Y |X) in
Figure 1), while the backward pass instills the
right constraint through right-to-left backpropaga-
tion with a task-speciﬁc loss (roughly maximizing
P(Z|XY )). The forward and backward outputs
are mixed into a single vector, from which tokens
are sampled to generate the desired output. To
choose the best output across iterations, we employ
an unsupervised ranking step based on BERT’s
next sentence prediction task to measure coherence
(Devlin et al., 2018).
On both tasks, DELOREAN outperforms all other
unsupervised methods in terms of both automatic
metrics and human evaluation, demonstrating that
nonmonotonic reasoning through conditional de-
coding is a promising research direction. Moreover,
outputs produced by our model are judged as more
coherent than those from the supervised models. In
sum, our study shows that backpropagation-based
decoding may enable additional future applications
of unsupervised generation and reasoning.
2
Background
Most NLP benchmarks have focused on reason-
ing about information that is entailed from the
premise.
For instance, natural language infer-
ence (NLI; Bowman et al., 2015) focuses primarily
on whether a hypothesis is entailed from a given
premise, which means the information stated in the
hypothesis is a subset of the information provided
in the premise. However, it has been noted that
human reasoning is often the other way, where hy-
potheses often contain new information that was
not available in the premise, but plausibly true (but

…
˜yf
1
˜yf
2
˜yf
N
˜yb
1
˜yb
2
˜yb
N
˜y2
˜yN
…
…
…
Ray
ran
[S]
…
Computing Loss
Backpropagation
Past context X
Input:  
Ray hung a tire on a rope to 
make his daughter a swing.
x1 x2
xNX
…
Future constraint Z
Input:  
Ray ran to his daughter to 
make sure she was okay.
z1 z2
zNZ
…
to
LM
Repeat  
T times
Generation Y
˜y1
Output:  She hit the rope and the tire fell on top of her.
LM Forward Pass
LM Backward Pass
Forward Backward Mix
Forward Logits
Backward Logits
LM
x1
xNX
…
…
˜y1 ˜y2
˜yN
x2
Initialization
Figure 2: Illustration of the DELOREAN decoding procedure, using abductive reasoning as an example. At ini-
tialization (upper-left box), the language model (LM) initializes the logits
˜Y = {˜y1, . . . , ˜yN} of the hypothesis
by reading the past context X and generating a continuation with regular decoding. At each forward-backward
iteration, we compute the task-speciﬁc loss L ˜Y of the logits
based on the future constraint Z (red box). The
backward pass then performs back-propagation and produces the backward logits
˜Y b = {˜yb
1, . . . , ˜yb
N}. In the
subsequent forward pass, for each step n, we compute the forward logits
˜yf
n conditioning on the preceding logits
˜yn−1, and then mix it with the respective backward logits
to produce the new logits
˜yn at step n.
possibly defeasible with new additional context)
(Johnson-Laird, 2006; Mercier and Sperber, 2017).
This type of reasoning corresponds to nonmono-
tonic reasoning (Kraus et al., 1990), as it contra-
dicts the monotonicity property according to which
valid arguments cannot be made invalid by adding
premises. We study two tasks of that nature: abduc-
tive reasoning (§2.1) and counterfactual reasoning
(§2.2).
2.1
Abductive Reasoning
Abductive reasoning aims at ﬁnding the most likely
explanation to partial observations (Peirce, 1960).
It has a central role in the human ability to “read be-
tween the lines,” and is crucial for language acqui-
sition (Andersen, 1973), understanding sentences
in discourse (Hobbs et al., 1993), and many more.
Despite the importance, however, relatively little
focus has been given to it in NLP research.
Recently, Bhagavatula et al. (2019) propose the
abductive reasoning task. Given two observations,
the goal is to determine the most likely explana-
tion of what happened in-between. The dataset
introduced for the task, ART, consists of 20k obser-
vations derived from the ﬁrst and last sentence of
stories in the ROCStories dataset (Mostafazadeh
et al., 2016a). We focus on the abductive NLG
setup introduced in the paper, which is framed as a
conditional generation task where a plausible expla-
nation to the observations must be generated using
language. The authors reported the performance of
several pre-trained LM-based baselines and showed
promises and limitations of such approaches.
2.2
Counterfactual Reasoning
Counterfactual reasoning aims at inferring alterna-
tive past events that could have happened given
a certain change in conditions (Goodman, 1947;
Starr, 2019). While counterfactual reasoning plays
an important role in AI systems (Isard, 1974; Gins-

berg, 1986), it requires causal reasoning abilities,
which are arguably absent from current association-
based AI (Pearl and Mackenzie, 2018). While
there has been work on counterfactual reasoning
in NLP, including recognizing counterfactuals in
text (Son et al., 2017), and improving the perfor-
mance of NLP tasks using counterfactual learn-
ing (Lawrence et al., 2017; Lawrence and Riezler,
2018), it remains a major research challenge.
Recently, Qin et al. (2019a) introduce the task of
counterfactual story generation. Given a 5-sentence
original story, and an alternative context in which
the second sentence of the story was altered by
a counterfactual, the task is to generate a new 3-
sentence story ending that addresses the alternative
beginning while minimally editing the original end-
ing. The associated TIMETRAVEL dataset is based
on ﬁctional narratives from ROCStories, for which
counterfactual contexts and alternative endings are
crowdsourced, yielding 29,849 problem instances.
Qin et al. (2019a) report several baseline perfor-
mances, and ﬁnd that models based on pre-trained
LMs produce output that recognize the counterfac-
tual, but generated endings which deviated consid-
erably from the original storyline. In contrast, in
the supervised setup, models optimize the easier of
the two goals and generate endings that are overly
similar to the original endings.
3
The DELOREAN Approach
Humans make inferences based on available in-
formation and reﬁne them when new information
arrives. Since currently available pre-trained LMs
generate text by sequentially predicting the next
token from left to right, they are incapable of con-
ditioning on future constraints. Therefore, we pro-
pose DELOREAN: an unsupervised backprop-based
decoding algorithm, which is summarized in Algo-
rithm 1, illustrated in Figure 2, and detailed below.
DELOREAN intermittently reﬁnes the predictions
to cohere with either the context or the constraints
(Section 3.1). The candidate generations are then
ranked by coherence (Section 3.2).
3.1
Decoding Strategy
Given context text X, the goal is to generate contin-
uation text Y = (y1, . . . , yN), such that Y satisﬁes
certain constraints according to the reasoning tasks,
usually deﬁned based on another context Z (see
Figure 1; we discuss the task-speciﬁc constraints
in the respective task sections).
Algorithm 1: DELOREAN Decoding
Input: Pre-trained language model (LM)
Context X
Future constraint Z
1: Initialize logits ˜Y (0)
2: Initialize Ys, list of candidate generations
3: for t ←1 to T do
4:
// Backward pass
5:
for n ←N to 1 do
6:
Compute backward logits ˜yb
n, Eq.(1)
7:
end for
8:
// Forward pass
9:
for n ←1 to N do
10:
Compute forward logits ˜yf
n, Eq.(2)
11:
Mix forward and backward logits, Eq.(3)
12:
end for
13:
Sample candidate Y from logits ˜Y and add to Ys
14: end for
15: Rank Ys by coherence
Output: The most coherent generated text Y from Ys
The proposed approach interleaves two proce-
dures, namely, forward and backward, that produce
and iteratively reﬁne the generation, for a prede-
ﬁned number of iterations T. In particular, the
forward pass ensures the generated text is a ﬂuent
continuation of the context X, while the backward
pass informs the model about the constraint and
steers the generation to satisfy it.
As detailed below, the backward pass uses gradi-
ent descent to update the generation Y . However,
Y is a discrete text that is not differentiable. In-
stead, throughout the algorithm, we maintain a soft
representation of the sequence ˜Y = (˜y1, . . . , ˜yN),
where ˜yn ∈RV represents the logits of the n-th
token and V is the vocabulary size. After the logits
are reﬁned over multiple iterations of the forward
and backward passes, we generate discrete text at
each step by sampling from yn ∼softmax(˜yn/τ),
where τ > 0 is the temperature.
We start by initializing the logits before the ﬁrst
iteration, ˜Y (0) = (˜y(0)
1
. . . ˜y(0)
N ), by feeding the
context X into the LM and greedily decoding N
continuation tokens.
Backward
The backward pass uses gradient
backpropagation to update the generation with
respect to the constraint.
Speciﬁcally, we ex-
press the task-speciﬁc constraint as a loss function
L(X, ˜Y (t−1), Z) that evaluates how well the gener-
ation Y (approximated with the soft representation
˜Y ) obeys the constraint (see the subsequent sec-
tions for concrete instantiations of the loss). The
goal of this pass is thus to minimize the loss w.r.t
the generation. Speciﬁcally, at iteration t, for each

step n in the generation, we update its logits with:
˜y(t),b
n
= ˜y(t−1)
n
−λ · ∇˜ynL(X, ˜Y (t−1), Z), (1)
where ∇˜ynL(X, ˜Y (t−1), Z) is the gradient of the
constraint-informed loss L w.r.t the n-th logits, and
λ ∈R is the step size. In practice, we may repeat
the gradient updates multiple times in a single pass.
Forward
The forward pass ensures that Y is ﬂu-
ent and coherent with the preceding context X. At
iteration t, for a particular step n, we compute the
forward logits with the LM:
˜y(t),f
n
= LM(X, ˜Y (t)
1:n−1).
(2)
We then mix the nth-step forward and backward
logits to get the ﬁnal logits of iteration t:
˜y(t)
n = γ · ˜y(t),f
n
+ (1 −γ) · ˜y(t),b
n
,
(3)
where 0 < γ < 1 is the mixing weight. The result-
ing logits ˜y(t)
n are then fed to the LM to compute
the forward logits at the (n+1)th step (Eq.2). This
way, information from the backward pass is inte-
grated into the left-to-right generation process to
produce text that is informed by the constraint.
We pre-deﬁne the number of tokens N required
by the backward pass, but we allow the forward
pass to generate more than N tokens if those are
needed to obtain complete sentences. In that case,
we set the logits of the extra tokens to the forward
logits, without mixing: ˜y(t)
n
= ˜y(t),f
n
for n > N.
We then prune any trailing tokens in the sampled
text to get complete sentences.
3.2
Ranking
The output of the decoding step is a list of candi-
date generations for each iteration: Ys = {Y (t)|t =
1, ..., T}. We further use an unsupervised approach
to rank and pick the best sample as the ﬁnal out-
put. Speciﬁcally, we take advantage of the BERT
model, which was pre-trained with a next-sentence
prediction (NSP) objective. Given two sentences
A and B, we use NSP to compute the likelihood of
B following A as a proxy for coherence:
c(A, B) = BERT NSP(A, B),
(4)
where c(·, ·) denotes the coherence score. This
score is used to evaluate the quality of a given
candidate continuation Y by measuring (1) its com-
patibility with the subsequent text of the context
X, (2) the internal consistency of Y if it consists
of multiple sentences, and (3) the compatibility of
Y with its right-side text when it is applicable.
Model
BLEU-4
ROUGE-L
BERT
Supervised
Sup
3.46
25.60
49.38
+COMET-Emb
4.06
26.06
49.71
Unsupervised
Zero-ShotX
0.65
14.99
39.36
Zero-ShotZX
0.53
14.23
40.03
Zero-ShotX-Ranked
0.87
16.76
41.58
Zero-ShotZX-Ranked
0.98
17.25
41.93
DELOREAN
1.38
18.94
42.86
Human
8.25
30.40
53.30
Table 1: Automatic evaluation results on the abductive
task, using the test set of ART.
4
Task 1: Abductive Reasoning
Each instance in the ART dataset consists of two
observations O1, O2 and a hypothesis H that ex-
plains the two observations. These inputs naturally
map to X, Z and Y in our framework. Formally,
the abductive generation task aims to maximize
P(Y |X, Z) – i.e. models must consider both left
and right contexts (X and Z) jointly.
4.1
Task Setup
Constraints
We maximize Z given X ˜Y by deﬁn-
ing the loss function as the cross-entropy loss of
generating Z given X ˜Y with the LM:3
L(X, ˜Y , Z) := −PNZ
n=1 log PLM(zn|X, ˜Y , Z1:n−1), (5)
where PLM(aj|a1:j−1) is the likelihood of generat-
ing token aj given the preceding text a1:j−1.
Following the earlier study of the task (Bhagavat-
ula et al., 2019), we also prepend Z to X to “leak”
the future information to the LM. That is, we re-
place X with Z⟨e⟩X in the above equation, where
⟨e⟩denotes a special end-of-text token. However,
the comparisons with respective baselines below
show the prepended Z is minor to the performance.
Ranking
We rank candidates by the overall co-
herence after inserting Y in between X and Z:
ranking score(Y ) = c(XY, Z) + c(X, Y Z). (6)
Hyperparameters
We use GPT2-345M (Rad-
ford et al., 2019b) as the pre-trained LM for all
models. We use the ART development set to se-
lect hyperparameters. We use greedy decoding for
our method and top k decoding (Fan et al., 2018)
(k = 40, τ = 0.7) for our baselines. Other hyper-
parameters are outlined in Appendix A.1.
3Note that this is applied to each preﬁx of ˜Y , although
some of them are not complete sentences.

Ray drive his car on a steep mountain road.
Ray was fine but his car was totaled.
As he drives the car to the top of the mountain his car is hit by a car.
Peter was excited to go to the Sanders rally in New Hampshire.
He couldn't wait to vote for him.
?
?
He has a long history of supporting Bernie Sanders and was excited to see him in person.
Figure 3: Examples of generated hypotheses on three abductive reasoning cases. Given observations O1 and O2,
DELOREAN generates a hypothesis explaining the observations.
4.2
Experimental Setup
Baselines
We compare our method against base-
lines from Bhagavatula et al. (2019). The unsu-
pervised baselines use a pre-trained GPT-2 model
to generate Y given a prompt text—either the ob-
servation X alone (Zero-ShotX) or Z⟨e⟩X (Zero-
ShotZX). The supervised method (Sup) follows
the same input format as Zero-ShotZX, but ﬁne-
tunes GPT-2 on the ART training set.
Finally,
our knowledge-informed baseline (+COMET-Emb)
further augments the representation of Sup with
knowledge from COMET (Bosselut et al., 2019).
To separately study the contribution of our de-
coding strategy and ranking component, we also
report the performance of ranking the baseline out-
puts. Speciﬁcally, we let each baseline generate 20
candidates and rank them by coherence (Eq. 6).4
4.3
Results
Automatic Evaluation
We report the same met-
rics as Bhagavatula et al. (2019): BLEU-4 (Pa-
pineni et al., 2002), ROUGE-L (Lin, 2004) and
BERTSCORE (Zhang et al., 2019) (with the bert-
base-uncased model). The results in Table 1 show
that DELOREAN performs best among the unsuper-
vised systems across all metrics. We also note that
our ranking step improves both the performance of
our model and that of the zero-shot baselines.
Human Evaluation
We conduct two sets of hu-
man evaluations on 100 test examples using crowd-
workers from Amazon Mechanical Turk. In the
scoring setting, presented in Table 2, workers were
presented a pair of observations (X and Z) and
a generated hypothesis Y , and asked to rate the
4We tried ablating the ranking component from our method
in preliminary experiments, and found that ranking is essential
to obtaining good performance. By adding ranking to our
baselines, we assess the contribution of our decoding strategy.
Model
X-Y
Y -Z
X-Y -Z
Supervised
Sup
0.510
0.375
0.314
+COMET-Emb
0.466
0.342
0.286
Unsupervised
Zero-ShotZX
0.233
0.103
0.108
Zero-ShotX-Ranked
0.478
0.208
0.195
Zero-ShotZX-Ranked
0.474
0.238
0.236
DELOREAN
0.522
0.325
0.297
Human
0.879
0.823
0.783
Table 2: Human calibration results on test set of ART .
All scores are normalized to [0, 1].
Overall - Human Judges Preferred
Our model
Neutral
Comparator
DELOREAN
21%
43%
36%
Sup
DELOREAN
25%
44%
31%
+COMET-Emb
DELOREAN
23%
62%
15%
Zero-ShotX-Ranked
DELOREAN
27%
50%
23%
Zero-ShotXZ-Ranked
DELOREAN
3%
11%
86%
Human
Table 3: Human pairwise comparison results on the test
set of ART, between DELOREAN and each of the base-
lines, by jointly considering all 3 criteria from Table 2.
“Neutral” means “equally good/bad”.
coherence of the hypothesis with respect to the ob-
servation X (X-Y ), the observation Z (Y -Z), and
both (X-Y -Z), on a 4-point Likert scale. In the
pairwise comparison setting, presented in Table 3,
workers were presented the outputs from a pair of
systems (DELOREAN and baseline) and asked to
choose the better output in terms of the same co-
herence criteria. Each example was labeled by 3
workers.5
In both evaluation setups, our method sub-
stantially outperform the unsupervised baselines,
achieving a relative improvement of 36% −215%
with respect to Y -Z coherence. Our method also
5The average inter-rater agreement measured by Fleiss’
κ = 0.44 (“moderate agreement”) (Fleiss, 1971).

BLEU 4
ROUGE L
BERT
Supervised + Discriminative
Sup+Disc
75.71
72.72
62.39
Unsupervised+ Discriminative
Recon+CF
75.92
70.93
62.49
Unsupervised
FT
4.06
24.09
62.55
FT+CF
4.02
24.35
62.63
Pretrained-only
Zero-Shots1s′
2
1.74
21.41
59.31
Zero-Shots1s′
2-Ranked
2.26
25.81
60.07
DELOREAN
21.35
40.73
63.36
Human
64.93
67.64
61.87
Table 4: Automatic evaluation results of counterfactual
story rewriting, on the test set of TIMETRAVEL.
outperform the supervised methods with respect to
X-Y coherence (Table 2), and achieve competitive
performance in the pairwise comparison (Table 3).
Again, the ranking component contributes to in-
creasing performance for the zero-shot baselines.
Finally, the large performance gap between the
methods and human-written explanations stresses
the difﬁculty of this reasoning task and warrants
future research.
Qualitative Analysis
Figure 3 presents two ex-
ample outputs produced by DELOREAN. We can
see our approach generates reasonable hypotheses
by taking into account both the past and future con-
texts. For instance, in the ﬁrst example, the future
observation (O2) “car was totaled” indicates that
Ray had a car accident, which is correctly captured
in the generated hypothesis “car is hit by a car”.
5
Task 2: Counterfactual Reasoning
Given an original story ending Z of story con-
text Xori, and a counterfactual condition X that
changes Xori to invalidate Z (see Fig. 1), the task
is to generate a new story ending Y that minimally
edits the original ending Z to regain coherence with
the counterfactual condition X (Qin et al., 2019a).
5.1
Task Setup
Constraints
The constraint we enforce is that Y
is close to Z (i.e., minimal edits). We impose this
constraint by minimizing their KL divergence:
L(X, ˜Y , Z) :=KL

Z∥softmax( ˜Y /τ)

,
(7)
where, with a slight abuse of notation, Z is the
one-hot distribution of the tokens in the original
ending. That is, we encourage the generated logits
to recover the original ending.
1.2
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
HARMONIC MEAN
HARMONIC MEAN OF COHERENCE 
AND MIN_EDIT SCORES
Delorean
RECON
ZS_ranked
ZS
FT
FT+CF
β
COHERENCE
MIN_EDIT
Figure 4: Human calibration results for counterfactual
generation in terms of weighted harmonic mean of co-
herence and min-edit, Hβ = (1+β2)·coherence·min edit
β2·coherence+min edit , as
a function of the scaling factor β. Low β values assign
more weight to coherence, and high β values empha-
size more on min-edit.
Ranking
We rank the candidates based on both
their coherence with the context, as well as the
internal coherence between the multiple sentences
of each candidate (rewritten ending, consists of 3
sentences). More concretely, given a candidate Y ,
we compute the aggregated coherence score:
ranking score(Y ) = c(X, Y ) + PS−1
s=1 c(Y [s], Y [s + 1]), (8)
where each candidate has S sentences (here, S = 3)
and Y [s] denotes the sth sentence.
Hyperparameters
We largely follow the same
setting as in the abductive reasoning task, but tune
hyperparameters on the TIMETRAVEL develop-
ment set. Deviations from these settings are out-
lined in Appendix A.2.
5.2
Experimental Setup
Baselines
We compare our method with base-
lines from Qin et al. (2019a). The zero-shot base-
line uses the pre-trained GPT-2 model to generate
Y as a continuation to the counterfactual condition
X. It is the most apt comparison to our method
which also doesn’t require additional supervision.
We also experiment with two baselines that ﬁne-
tune GPT-2 on the original story XoriZ to ﬁt the
model to the story domain, either with an LM ob-
jective (FT) or a tailored conditional objective that
encourages minimal edits of Z (Recon+CF).6 Fi-
nally, we report the performance of a supervised
6See Qin et al. (2019a) for more details.

She knew of a cool place online that did custom fits really cheaply, and ordered  from there.
They browsed shirts from a variety of stores. Tara picked out a floral 
patterned shirt that she liked best. Tara looked forward to wearing it.
They sent her a shirt that fit her perfectly. Tara was so 
excited to wear it. She looked forward to wearing it.
Tara wanted to buy a new shirt for her upcoming school formal. She went to the mall with her mom.
Story Context
Counterfactual Condition
Original Ending
Rewritten Ending
Shane enjoyed volunteering his time helping others.
John was not allowed to be friends with Shane anymore. this bothered John greatly but 
his mom explained the reasons. She explained that Shane was a bad influence on John.
John was a good student and was always looking for ways to help others. They were 
both very kind and caring people. Shane was a member of the Boy Scouts of America.
Shane and John were best friends at school. Shane was caught stealing and got suspended from school.
Story Context
Counterfactual Condition
Original Ending
Rewritten Ending
Figure 5: Examples of generated story endings on three counterfactual reasoning cases. Given a story context, a
counterfactual condition, and a original ending, DELOREAN generates a rewritten ending which is coherent with
the counterfactual condition and is similar to the original ending.
Coherence - Human Judges Preferred
Our model
Neutral
Comparator
DELOREAN
25%
58%
17%
Sup+Disc
DELOREAN
23%
70%
7%
Recon+CF
DELOREAN
22%
48%
30%
FT
DELOREAN
18%
60%
22%
Zero-Shots1s′
2
DELOREAN
27%
42%
31%
Zero-Shots1s′
2-Ranked
DELOREAN
10%
29%
61%
Human
Min-Edits - Human Judges Preferred
Our model
Neutral
Comparator
DELOREAN
4%
17%
79%
Sup+Disc
DELOREAN
1%
14%
85%
Recon+CF
DELOREAN
21%
76%
3%
FT
DELOREAN
28%
71%
1%
Zero-Shots1s′
2
DELOREAN
37%
56%
7%
Zero-Shots1s′
2-Ranked
M+Sup
8%
22%
70%
Human
Table 5: Human pairwise comparison results on the
counterfactual task, between our best model and each
baseline with respect to coherence and min-edits.
baseline (Sup), in which GPT-2 is ﬁne-tuned to
produce the gold Y from XoriZ and X.
5.3
Results
Automatic Evaluation
Following Qin et al.
(2019a), we report BERTSCORE (Zhang et al.,
2019), which was shown to best correlate with hu-
man judges’ notion of counterfactual coherence,
and BLEU-4 and ROUGE-L, which better mea-
sure minimum-edits. We ﬁnd that the discrimina-
tive baselines achieve the highest degree of plot
ﬁdelity. Meanwhile, DELOREAN achieves the high-
est BERTSCORE for counterfactual coherence.
Human Evaluation
We repeat the human eval-
uation setup from Section 4.3. Presented with the
original story, the counterfactual condition X, and
the generated ending Y , workers were asked to
judge (1) the coherence of Y with respect to the
X; and (2) to what extent the generated ending
minimally-edits the original ending.7 In order to
judge both criteria, we report the weighted har-
monic mean Hβ of these scores across a range of
weights β (Figure 4).
Our results show that DELOREAN is the only
model that maintains a consistent balance between
coherence (1.66) and minimal edits (1.54). While
the ranking-augmented zero-shot model produces
the most coherent endings (coherence = 1.8), it de-
viates from the original ending. As β is increased
(i.e., increasing importance of minimal edits), its
weighted performance drops considerably, indicat-
ing it cannot generate new endings that follow the
original plot of the story (min-edit = 1.25). Con-
versely, Recon+CF generates stories that are faith-
ful to the original endings, but are far less coher-
ent with the counterfactual condition (coherence =
1.23). Through human annotation, we found that
Recon+CF copies the original ending word-for-
word in a 84% of cases.
The pairwise comparison results in Table 5
7Fair inter-rater agreement with Fleiss’ κ = 0.34

parallel these observations. DELOREAN signiﬁ-
cantly outperforms the discriminative approaches
(Recon+CF and Sup+Disc) in coherence, while
falling short of the Zero-shot re-ranked baselines.
In minimal edits, this pattern is ﬂipped with our
approach outperforming Zero-shot baselines con-
siderably and losing to the discriminative baselines.
Qualitative Analysis
Figure 5 provides two ex-
ample results for counterfactual story rewriting by
DELOREAN. The approach successfully captures
the causal relations between events and properly
rewrites the endings with minimal edits. For in-
stance, in the ﬁrst example, given the counterfac-
tual condition that “Tara ordered a shirt online” (as
opposed to the original “went to mall”), the rewrit-
ten ending is about “sent shirt” to Tara (as opposed
to the original “browsed from stores”). The last
sentence of the original ending “She looked for-
ward to wearing it” is correctly preserved as it is
coherent with the counterfactual condition.
6
Related Work
Unsupervised text generation.
Unsupervised
approaches are often applied to problems that copy
information from a source text into decoded text.
Unsupervised paraphrasing requires repeating this
information (Miao et al., 2019; Bao et al., 2019),
as does translation, but with a bilingual transfor-
mation (Artetxe et al., 2017; Lample et al., 2018).
In summarization there is an additional task to se-
lect a subset of the original text (Baziotis et al.,
2019; Schumann et al., 2020; West et al., 2019). In
cases where information is mostly copied from the
original, auto-encoding objectives can ensure the
correct information is captured (Bao et al., 2019;
Baziotis et al., 2019; Artetxe et al., 2017). This
work tackles problems where generation is more
open-ended. Rather than reproducing information
from the prompt, generations should agree with and
expand on it, making autoencoding less applicable.
Controllable language generation.
Earlier ap-
proaches for controllable generation involved pre-
serving the content of text while changing it along
discrete dimensions, such as theme, sentiment, or
style (Koncel-Kedziorski et al., 2016; Hu et al.,
2017; Ficler and Goldberg, 2017; Shen et al., 2017;
Lample et al., 2019). Recent works such as Grover
(Zellers et al., 2019) and CTRL model (Keskar
et al., 2019) used these ideas to augment trans-
former language models that can condition on struc-
tured metadata such as source, domain, etc. The
Plug & Play model (PPLM; Dathathri et al., 2019)
controls topic and sentiment in an approach similar
to ours that involves forward and backward passes
to update token distributions. However, PPLM
relies on trained attribute discriminators for super-
vision, while our method is unsupervised. While
these models are restricted to speciﬁc dimensions,
often with pre-deﬁned values, our model can adjust
to any open-ended textual constraint. Perhaps the
most similar work in that aspect is the “text inﬁll-
ing” models, which, however, are in a more narrow
setting by ﬁlling only a relatively short text span
(Devlin et al., 2018; Zhu et al., 2019; Donahue
et al., 2020), and more restrictive due to the reliance
on an extra right-to-left language model (Sun et al.,
2017) or a pre-speciﬁed generation length (Zeldes
et al., 2020, which is not publicly available).
Reasoning about narratives.
A prominent re-
source from recent years is the RocStories corpus
(Mostafazadeh et al., 2016b), consisting of 98K
crowdsourced 5-sentence everyday life stories. It
was used for the story cloze task whose goal was to
predict the story ending from its ﬁrst 4 sentences,
but gained popularity and became the base of ad-
ditional benchmarks (Rashkin et al., 2018). Addi-
tional related work includes “script knowledge”, i.e.
learning about prototypical series of events (Schank
and Abelson, 1977; Chambers and Jurafsky, 2008;
Pichotta and Mooney, 2014), temporal common-
sense (Granroth-Wilding and Clark, 2016; Li et al.,
2018), and modeling pre- and post- conditions of
events (Roemmele et al., 2011; Sap et al., 2019;
Bosselut et al., 2019). Qin et al. (2019b) studied
conversation modeling that reads and connects the
dots of events in related documents. Finally, a re-
cent line of work explores counterfactual questions
in reading comprehension (Huang et al., 2019; Tan-
don et al., 2019), but instantiates the problem of
counterfactual reasoning as a multiple choice task.
7
Conclusion
We presented DELOREAN, an unsupervised LM-
based approach to generate text conditioned on
past context as well as future constraints, through
forward and backward passes considering each con-
dition. We demonstrated its effectiveness for ab-
ductive and counterfactual reasoning, on which it
performed substantially better than unsupervised
baselines. Our method is general and can be easily
adapted for other generative reasoning tasks.

Acknowledgements
We thanks the anonymous reviewers and colleages
at UW NLP and AI2 for many helpful comments.
This research was supported in part by DARPA
CwC through ARO (W911NF15-1-0543), DARPA
MCS program through NIWC Paciﬁc (N66001-19-
2-4031), and Allen Institute for AI.
References
Henning Andersen. 1973.
Abductive and deductive
change. Language, pages 765–793.
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and
Kyunghyun Cho. 2017.
Unsupervised neural ma-
chine translation. arXiv preprint arXiv:1710.11041.
Yu Bao, Hao Zhou, Shujian Huang, Lei Li, Lili
Mou, Olga Vechtomova, Xinyu Dai, and Jiajun
Chen. 2019.
Generating sentences from disentan-
gled syntactic and semantic spaces. arXiv preprint
arXiv:1907.05789.
Christos Baziotis, Ion Androutsopoulos, Ioannis Kon-
stas, and Alexandros Potamianos. 2019. Seq3: Dif-
ferentiable sequence-to-sequence-to-sequence au-
toencoder for unsupervised abstractive sentence
compression. In NAACL-HLT.
Chandra Bhagavatula, Ronan Le Bras, Chaitanya
Malaviya, Keisuke Sakaguchi, Ari Holtzman, Han-
nah Rashkin, Doug Downey, Wen-tau Yih, and Yejin
Choi. 2019. Abductive commonsense reasoning. In
International Conference on Learning Representa-
tions.
Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-
tanya Malaviya, Asli Celikyilmaz, and Yejin Choi.
2019. COMET: Commonsense transformers for au-
tomatic knowledge graph construction. In Proceed-
ings of the 57th Annual Meeting of the Association
for Computational Linguistics, pages 4762–4779,
Florence, Italy. Association for Computational Lin-
guistics.
Samuel R Bowman, Gabor Angeli, Christopher Potts,
and Christopher D Manning. 2015. A large anno-
tated corpus for learning natural language inference.
arXiv preprint arXiv:1508.05326.
Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT, pages 789–797.
Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane
Hung, Eric Frank, Piero Molino, Jason Yosinski, and
Rosanne Liu. 2019. Plug and play language mod-
els: a simple approach to controlled text generation.
arXiv preprint arXiv:1912.02164.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.
C. Donahue, M. Lee, and P. Liang. 2020.
Enabling
language models to ﬁll in the blanks. In ACL.
Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-
erarchical neural story generation. In ACL.
Jessica Ficler and Yoav Goldberg. 2017. Controlling
linguistic style aspects in neural language genera-
tion. In Proceedings of the Workshop on Stylistic
Variation, pages 94–104.
Joseph L Fleiss. 1971. Measuring nominal scale agree-
ment among many raters.
Psychological bulletin,
76(5):378.
Matthew L Ginsberg. 1986. Counterfactuals. Artiﬁcial
intelligence, 30(1):35–79.
Nelson Goodman. 1947.
The problem of counter-
factual conditionals.
The Journal of Philosophy,
44(5):113–128.
Mark Granroth-Wilding and Stephen Clark. 2016.
What happens next? event prediction using a com-
positional neural network model. In Thirtieth AAAI
Conference on Artiﬁcial Intelligence.
Jerry R Hobbs, Mark E Stickel, Douglas E Appelt, and
Paul Martin. 1993. Interpretation as abduction. Ar-
tiﬁcial intelligence, 63(1-2):69–142.
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward con-
trolled generation of text. In ICML.
Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and
Yejin Choi. 2019.
Cosmos qa: Machine reading
comprehension with contextual commonsense rea-
soning. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natu-
ral Language Processing (EMNLP-IJCNLP), pages
2391–2401.
Steve D Isard. 1974. What would you have done if...?
Theoretical Linguistics, 1(1-3):233–256.
Philip Nicholas Johnson-Laird. 2006. How we reason.
Oxford University Press, USA.
Nitish Shirish Keskar, Bryan McCann, Lav R Varshney,
Caiming Xiong, and Richard Socher. 2019. Ctrl: A
conditional transformer language model for control-
lable generation. arXiv preprint arXiv:1909.05858.
Rik Koncel-Kedziorski, Ioannis Konstas, Luke Zettle-
moyer, and Hannaneh Hajishirzi. 2016.
A theme-
rewriting approach for generating algebra word
problems. In Proceedings of the 2016 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1617–1628.

Sarit Kraus, Daniel Lehmann, and Menachem Magidor.
1990. Nonmonotonic reasoning, preferential models
and cumulative logics. Artiﬁcial intelligence, 44(1-
2):167–207.
Guillaume Lample, Myle Ott, Alexis Conneau, Lu-
dovic Denoyer, and Marc’Aurelio Ranzato. 2018.
Phrase-based & neural unsupervised machine trans-
lation. arXiv preprint arXiv:1804.07755.
Guillaume Lample, Sandeep Subramanian, Eric Smith,
Ludovic Denoyer, Marc’Aurelio Ranzato, and Y-
Lan Boureau. 2019. Multiple-attribute text rewrit-
ing. In ICLR.
Carolin Lawrence and Stefan Riezler. 2018. Improving
a neural semantic parser by counterfactual learning
from human bandit feedback. In Proceedings of the
56th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1820–1830.
Carolin Lawrence, Artem Sokolov, and Stefan Riezler.
2017. Counterfactual learning from bandit feedback
under deterministic logging: A case study in statisti-
cal machine translation. In Proceedings of the 2017
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 2566–2576.
Zhongyang Li, Xiao Ding, and Ting Liu. 2018. Con-
structing narrative event evolutionary graph for
script event prediction. In IJCAI.
Chin-Yew Lin. 2004.
Rouge: A package for auto-
matic evaluation of summaries. Text Summarization
Branches Out.
Hugo Mercier and Dan Sperber. 2017. The enigma of
reason. Harvard University Press.
Ning Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei
Li. 2019. Cgmh: Constrained sentence generation
by metropolis-hastings sampling. In Proceedings of
the AAAI Conference on Artiﬁcial Intelligence, vol-
ume 33, pages 6834–6842.
Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Pushmeet Kohli, and James Allen. 2016a.
A cor-
pus and evaluation framework for deeper under-
standing of commonsense stories.
arXiv preprint
arXiv:1604.01696.
Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Pushmeet Kohli, and James F. Allen. 2016b. A cor-
pus and cloze evaluation for deeper understanding of
commonsense stories. In HLT-NAACL.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In ACL, pages 311–
318.
Judea Pearl and Dana Mackenzie. 2018. The book of
why: the new science of cause and effect.
Basic
Books.
Charles Sanders Peirce. 1960.
Collected papers of
charles sanders peirce, volume 2. Harvard Univer-
sity Press.
Karl Pichotta and Raymond Mooney. 2014.
Statisti-
cal script learning with multi-argument events. In
EACL, pages 220–229.
Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chan-
dra Bhagavatula, Elizabeth Clark, and Yejin Choi.
2019a.
Counterfactual story reasoning and gener-
ation.
In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natu-
ral Language Processing (EMNLP-IJCNLP), pages
5046–5056.
Lianhui Qin, Michel Galley, Chris Brockett, Xiaodong
Liu, Xiang Gao, Bill Dolan, Yejin Choi, and Jian-
feng Gao. 2019b.
Conversing by reading: Con-
tentful neural conversation with on-demand machine
reading. In ACL, pages 5427–5436.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019a. Language
models are unsupervised multitask learners. -.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019b.
Lan-
guage models are unsupervised multitask learners.
OpenAI Blog, 1:8.
Hannah Rashkin, Antoine Bosselut, Maarten Sap,
Kevin Knight, and Yejin Choi. 2018.
Modeling
naive psychology of characters in simple common-
sense stories. arXiv preprint arXiv:1805.06533.
Raymond Reiter. 1988. Nonmonotonic reasoning. In
Exploring artiﬁcial intelligence, pages 439–481. El-
sevier.
Melissa Roemmele, Cosmin Adrian Bejan, and An-
drew S Gordon. 2011. Choice of plausible alterna-
tives: An evaluation of commonsense causal reason-
ing. In 2011 AAAI Spring Symposium Series.
Maarten Sap, Ronan LeBras, Emily Allaway, Chan-
dra Bhagavatula, Nicholas Lourie, Hannah Rashkin,
Brendan Roof, Noah A Smith, and Yejin Choi. 2019.
ATOMIC: An atlas of machine commonsense for if-
then reasoning. In AAAI.
Roger C Schank and Robert P Abelson. 1977. Scripts,
plans, goals and understanding: An inquiry into hu-
man knowledge structures.
Raphael Schumann, Lili Mou, Yao Lu, Olga Vech-
tomova, and Katja Markert. 2020.
Discrete op-
timization for unsupervised sentence summariza-
tion with word-level extraction.
arXiv preprint
arXiv:2005.01791.
Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Advances in neural informa-
tion processing systems, pages 6830–6841.

Youngseo Son, Anneke Buffone, Joe Raso, Allegra
Larche, Anthony Janocko, Kevin Zembroski, H An-
drew Schwartz, and Lyle Ungar. 2017. Recognizing
counterfactual thinking in social media texts. In Pro-
ceedings of the 55th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 654–658.
William Starr. 2019. Counterfactuals. In Edward N.
Zalta, editor, The Stanford Encyclopedia of Philos-
ophy, fall 2019 edition. Metaphysics Research Lab,
Stanford University.
Qing Sun, Stefan Lee, and Dhruv Batra. 2017. Bidirec-
tional beam search: Forward-backward inference in
neural sequence models for ﬁll-in-the-blank image
captioning. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages
6961–6969.
Niket Tandon, Bhavana Dalvi Mishra, Keisuke Sak-
aguchi, Antoine Bosselut, and Peter Clark. 2019.
Wiqa: A dataset for” what if...” reasoning over pro-
cedural text. In EMNLP.
Peter West, Ari Holtzman, Jan Buys, and Yejin Choi.
2019. Bottlesum: Unsupervised and self-supervised
sentence summarization using the information bot-
tleneck principle. In Proceedings of the 2019 Con-
ference on Empirical Methods in Natural Language
Processing and the 9th International Joint Confer-
ence on Natural Language Processing (EMNLP-
IJCNLP), pages 3743–3752.
Yoel Zeldes, Dan Padnos, and Barak Peleg. 2020.
Haim-1.5 - the next generation.
Rowan Zellers,
Ari Holtzman,
Hannah Rashkin,
Yonatan Bisk, Ali Farhadi, Franziska Roesner, and
Yejin Choi. 2019.
Defending against neural fake
news. In Advances in Neural Information Process-
ing Systems, pages 9051–9062.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
Weinberger, and Yoav Artzi. 2019.
BERTScore:
Evaluating text generation with BERT.
CoRR,
abs/1904.09675.
Wanrong Zhu, Zhiting Hu, and Eric Xing. 2019. Text
inﬁlling. arXiv preprint arXiv:1901.00158.

A
Additional Experiment Conditions
A.1
Abductive Reasoning
We set the hypothesis length N = 15 in the back-
ward pass and allow the forward pass to gener-
ate N*2 tokens for complete sentences. We run
T = 20 forward-backward iterations, with each
backward pass performing 20 gradient updates us-
ing a small step size λ = 0.0003. The mixing
weight of forward/backward logits is γ = 0.88.
We use greedy decoding to produce a single candi-
date at each iteration T.
A.2
Counterfactual Reasoning
We use a step size λ = 0.0004 in backward
pass and a mixing weight γ = 0.92. One differ-
ence from the abductive task is that, here we vary
the number of forward-backward iterations within
{5, 10} and the number of backward gradient up-
dates within {5, 8, 10, 15}. Each conﬁguration pro-
duces one candidate at the end of the algorithm.
So for each example, we produce 8 candidates for
ranking. We found such a generation-ranking proto-
col gives better performance on the counterfactual
task.
Since we need to generate 3 sentences, the num-
ber of tokens N is relatively large. For the effective-
ness of backpropagation and forward computation,
we split the generation into 3 segments, one for
each sentence, and perform the forward-backward
passes for each segment separately. A sentence that
was generated for the ith segment, is then appended
to the context when generating the i+1 segment.

