
Differential Geometry
of Manifolds


Differential Geometry
of Manifolds
Stephen Lovett
A K Peters, Ltd.
Natick, Massachusetts

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
Â© 2010 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20110714
International Standard Book Number-13: 978-1-4398-6546-0 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made 
to publish reliable data and information, but the author and publisher cannot assume responsibility for the validity of all 
materials or the consequences of their use. The authors and publishers have attempted to trace the copyright holders of 
all material reproduced in this publication and apologize to copyright holders if permission to publish in this form has not 
been obtained. If any copyright material has not been acknowledged please write and let us know so we may rectify in any 
future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://www.
copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-
750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For organiza-
tions that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for identi-
fication and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

Contents
Preface
vii
Acknowledgments
xiii
1
Analysis of Multivariable Functions
1
1.1
Functions from Rn to Rm
. . . . . . . . . . . . . . . . . .
1
1.2
Continuity, Limits, and Diï¬€erentiability
. . . . . . . . . .
9
1.3
Diï¬€erentiation Rules: Functions of Class C r . . . . . . . .
20
1.4
Inverse and Implicit Function Theorems . . . . . . . . . .
27
2
Coordinates, Frames, and Tensor Notation
37
2.1
Curvilinear Coordinates . . . . . . . . . . . . . . . . . . .
37
2.2
Moving Frames in Physics . . . . . . . . . . . . . . . . . .
44
2.3
Moving Frames and Matrix Functions
. . . . . . . . . . .
53
2.4
Tensor Notation
. . . . . . . . . . . . . . . . . . . . . . .
56
3
Differentiable Manifolds
79
3.1
Deï¬nitions and Examples . . . . . . . . . . . . . . . . . .
80
3.2
Diï¬€erentiable Maps between Manifolds . . . . . . . . . . .
94
3.3
Tangent Spaces and Diï¬€erentials . . . . . . . . . . . . . .
99
3.4
Immersions, Submersions, and Submanifolds . . . . . . . .
113
3.5
Chapter Summary . . . . . . . . . . . . . . . . . . . . . .
122
4
Analysis on Manifolds
125
4.1
Vector Bundles on Manifolds
. . . . . . . . . . . . . . . .
126
4.2
Vector Fields on Manifolds
. . . . . . . . . . . . . . . . .
135
4.3
Diï¬€erential Forms
. . . . . . . . . . . . . . . . . . . . . .
145
4.4
Integration on Manifolds . . . . . . . . . . . . . . . . . . .
158
4.5
Stokesâ€™ Theorem
. . . . . . . . . . . . . . . . . . . . . . .
177
v

vi
Contents
5
Introduction to Riemannian Geometry
185
5.1
Riemannian Metrics
. . . . . . . . . . . . . . . . . . . . .
186
5.2
Connections and Covariant Diï¬€erentiation . . . . . . . . .
204
5.3
Vector Fields Along Curves: Geodesics . . . . . . . . . . .
219
5.4
The Curvature Tensor . . . . . . . . . . . . . . . . . . . .
234
6
Applications of Manifolds to Physics
249
6.1
Hamiltonian Mechanics
. . . . . . . . . . . . . . . . . . .
250
6.2
Electromagnetism . . . . . . . . . . . . . . . . . . . . . . .
262
6.3
Geometric Concepts in String Theory
. . . . . . . . . . .
269
6.4
A Brief Introduction to General Relativity . . . . . . . . .
278
A
Point Set Topology
295
A.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . .
295
A.2 Metric Spaces . . . . . . . . . . . . . . . . . . . . . . . . .
296
A.3 Topological Spaces . . . . . . . . . . . . . . . . . . . . . .
313
A.4 Proof of the Regular Jordan Curve Theorem . . . . . . . .
335
A.5 Simplicial Complexes and Triangulations . . . . . . . . . .
339
A.6 Euler Characteristic
. . . . . . . . . . . . . . . . . . . . .
343
B
Calculus of Variations
347
B.1
Formulation of Several Problems . . . . . . . . . . . . . .
347
B.2
The Euler-Lagrange Equation . . . . . . . . . . . . . . . .
348
B.3
Several Dependent Variables . . . . . . . . . . . . . . . . .
353
B.4
Isoperimetric Problems and Lagrange Multipliers . . . . .
359
C
Multilinear Algebra
365
C.1
Direct Sums . . . . . . . . . . . . . . . . . . . . . . . . . .
366
C.2
Bilinear and Quadratic Forms . . . . . . . . . . . . . . . .
368
C.3
The Hom Space and the Dual Space . . . . . . . . . . . .
376
C.4
The Tensor Product
. . . . . . . . . . . . . . . . . . . . .
381
C.5
Symmetric Product and Alternating Product . . . . . . .
390
C.6
The Wedge Product and Analytic Geometry . . . . . . . .
401
Bibliography
411
Index
415

Preface
Purpose of This Book
This book is the second in a pair of books that together are intended to
bring the reader through classical diï¬€erential geometry into the modern
formulation of the diï¬€erential geometry of manifolds, assuming only prior
experience in multivariable calculus and linear algebra. The ï¬rst book in
the pair, Diï¬€erential Geometry of Curves and Surfaces by Banchoï¬€and
Lovett [5], introduces the classical theory of curves and surfaces. This book
continues the development of diï¬€erential geometry by studying manifoldsâ€”
the natural generalization of regular curves and surfaces to higher dimen-
sions. Though [5] provides many examples of one- and two-dimensional
manifolds that lend themselves well to visualization, this book does not
rely on [5] and can be read independently.
Taken on its own, this book attempts to provide an introduction to dif-
ferentiable manifolds, geared toward advanced undergraduate or beginning
graduate readers and retaining a view toward applications in physics. For
readers primarily interested in physics, this book may ï¬ll a gap between
the geometry typically oï¬€ered in undergraduate programs and the geom-
etry expected in physics graduate programs. For example, some graduate
programs in physics ï¬rst introduce electromagnetism in the context of a
manifold.
The student who is unaccustomed to the formalism of man-
ifolds may be lost in the notation at worst or, at best, be unaware of
how to parametrize coordinate patches or how to do explicit calculations
of diï¬€erentials of maps between manifolds. For readers with primarily a
mathematics leaning, this book gives a concrete introduction to the theory
of manifolds at an advanced undergraduate or beginning graduate level.
What is Differential Geometry?
Diï¬€erential geometry studies properties of and analysis on curves, surfaces,
and higher-dimensional spaces using tools from calculus and linear algebra.
vii

viii
Preface
Just as the introduction of calculus expands the descriptive and predictive
abilities of nearly every ï¬eld of scientiï¬c study, the use of calculus in ge-
ometry brings about avenues of inquiry that extend far beyond classical
geometry.
Though diï¬€erential geometry does not possess the same restrictions as
Euclidean geometry on what types of objects it studies, not every conceiv-
able set of points falls within the purview of diï¬€erential geometry. One of
the underlying themes of this book is the development and description of
the types of geometric sets on which it is possible to â€œdo calculus.â€ This
leads to the deï¬nition of diï¬€erentiable manifolds. A second, and some-
what obvious, theme is how to actually do calculus (e.g., measure rates
of change of functions or interdependent variables) on manifolds. A third
general theme is how to â€œdo geometryâ€ (e.g., measure distances, areas, and
angles) on such geometric objects. This theme leads us to the notion of a
Riemannian manifold.
Applications of diï¬€erential geometry outside of mathematics ï¬rst arise
in mechanics in the study of the dynamics of a moving particle or system
of particles. The study of inertial frames is common to both physics and
diï¬€erential geometry. Most importantly, however, diï¬€erential geometry is
necessary to study physical systems that involve functions on curved spaces.
For example, just to make sense of directional derivatives of the surface tem-
perature at a point on the earth (a sphere) requires analysis on manifolds.
The study of mechanics and electromagnetism on a curved surface also
requires analysis on a manifold. Finally, arguably the most revolutionary
application of diï¬€erential geometry to physics came from Einsteinâ€™s theory
of general relativity. In this theory, Einstein proposed that space and time
were joined together as a spacetime unit, and he described this spacetime
as a 4-manifold that curved more tightly in the presence of mass.
Organization of Topics
A typical calculus sequence analyzes single-variable real functions (R â†’R),
parametric curves (R â†’Rn), multivariable functions (Rn â†’R), and vector
ï¬elds (R2 â†’R2 or R3 â†’R3). This does not quite reach the full generality
that one needs for the deï¬nition of manifolds.
Chapter 1 presents the
analysis of functions f : Rn â†’Rm for any positive integers n and m.
Chapter 2 discusses the calculus of moving frames.
The concept of
moving frames arises as a summary to some results found in Chapters 1, 3
and 9 of [5] but also in the context of inertial frames, an important topic in

Preface
ix
dynamics. Implicit in the treatment is a view toward Lie algebra. However,
to retain the chosen level of this book, we do not develop this theory here.
Chapter 3 deï¬nes the category of diï¬€erentiable manifolds. Manifolds
serve as the appropriate and most complete generalization to higher dimen-
sions of regular curves and regular surfaces. The chapter also introduces
the deï¬nition for the tangent space on a manifold and attempts to provide
the underlying intuition behind the abstract deï¬nitions.
Having deï¬ned the concept of a manifold manifolds, Chapter 4 develops
the analysis on diï¬€erentiable manifolds, including the diï¬€erentials of func-
tions between manifolds, vector ï¬elds, diï¬€erential forms, and integration.
Chapter 5 introduces Riemannian geometry without any pretention of
being comprehensive. One can easily take an entire course on Riemannian
geometry, the proper context in which one can do both calculus and ge-
ometry on a curved space. The chapter introduces the notions of metrics,
connections, geodesics, parallel transport, and the curvature tensor.
Having developed the technical machinery of manifolds, in Chapter 6
we apply the theory to a few areas in physics. We consider the Hamiltonian
formulation of dynamics, with a view toward symplectic manifolds; the ten-
sorial formulation of electromagnetism; a few geometric concepts involved
in string theory, namely the properties of the world sheet that describes
a string moving in a Minkowski space; and some fundamental concepts in
general relativity.
In order to be comprehensive and rigorous and still only require the
standard core of most undergraduate math programs, three appendices
provide any necessary background from topology, calculus of variations,
and multilinear algebra.
Using This Book
Because of the intended purpose of the book, it can serve well either as a
textbook or for self study. The conversational style attempts to introduce
new concepts in an intuitive way, explaining why one formulates certain
deï¬nitions as one does.
As a mathematics text, proofs or references to
proofs are provided for all claims. On the other hand, this book does not
supply all the physical theory and discussion behind the topics we broach.
Each section concludes with an ample collection of exercises. The au-
thor has marked exercises that require some speciï¬c physics background
by (Phys) and exercises that require ordinary diï¬€erential equations with
(ODE). Problems marked with (*) indicate diï¬ƒculty that may be related
to technical ability, insight, or length.

x
Preface
As mentioned above, this book only assumes prior knowledge of mul-
tivariable calculus and linear algebra. A few key results presented in this
textbook rely on theorems from the theory of diï¬€erential equations but
either the calculations are all spelled out or a reference to the appropriate
theorem has been provided. Therefore, experience with diï¬€erential equa-
tions is helpful though not necessary.
A proper introduction to the theory of diï¬€erentiable manifolds does re-
quire some topology and some linear algebra beyond what is normally cov-
ered by the stated prerequisites. The appendices provide this background.
Appendix A on topology primarily supports Chapter 3 and to some degree
Chapter 1. Appendix B on calculus of variations supports Chapter 5 in
the context of geodesics and Section 6.1 on Hamiltonian mechanics. Ap-
pendix C on advanced linear algebra primarily supports Chapter 4 and
gives a complete explanation for the dichotomy between contravariant and
covariant indices for tensors. The reader should feel free to consult these
appendices as indicated above or simply when referred to them in the main
text.
Notation
It has been said jokingly that â€œdiï¬€erential geometry is the study of things
that are invariant under a change of notation.â€ A quick perusal of the
literature on diï¬€erential geometry shows that mathematicians and physi-
cists present topics in this ï¬eld in a variety of diï¬€erent ways. One could
argue that notational diï¬€erences have contributed to a communication
gap between mathematicians and physicists.
In addition, the classical
and modern formulations of many diï¬€erential geometric concepts vary
signiï¬cantly. Whenever diï¬€erent notations or modes of presentation ex-
ist for a topic (e.g., diï¬€erentials, metric tensor, and tensor ï¬elds), this
book attempts to provide an explicit coordination between the notation
variances.
As a comment on vector and tensor notation, this book consistently uses
the follows conventions. A vector or vector function in a Euclidean vector
space is denoted by âƒ—v, âƒ—X(t), or âƒ—X(u, v).
Curves on manifolds, tangent
vectors, vector ï¬elds, or tensor ï¬elds have no superscript vector designation
and are written, for example, as Î³, X, or T . A fair number of physics texts
use a bolded font like
  or
 to indicate tensors or tensor ï¬elds. Therefore,
when discussing tensors taken from a physics problem, we sometimes also
use that notation.

Preface
xi
The authors of [5] chose the following notations for certain speciï¬c ob-
jects of interest in diï¬€erential geometry. Often Î³ indicates a curve para-
metrized by âƒ—X(t), while writing âƒ—X(t) = âƒ—X(u(t), v(t)) indicates a curve on
a surface. The unit tangent and the binormal vectors of a curve in space
are written in the standard notation âƒ—T(t) and âƒ—B(t), respectively, but the
principal normal is written âƒ—P(t), reserving âƒ—N(t) to refer to the unit normal
vector to a curve on a surface. For a plane curve, âƒ—U(t) is the vector obtained
by rotating âƒ—T(t) by a positive quarter turn. Furthermore, we consistently
denote by Îºg(t) the curvature of a plane curve because one identiï¬es this
curvature as the geodesic curvature in the theory of curves on surfaces.
When these concepts occur in this text, we use the same conventions.
Occasionally, there arise irreconcilable discrepancies in deï¬nitions or
notations, e.g., the deï¬nition of a critical point for a function f : Rn â†’Rm,
how to place the signs on a Minkowski metric, how one deï¬nes Î¸ and Ï†
in spherical coordinates, what units to use in electromagnetism, etc. In
these instances, we made a choice that best suits our purposes and indicate
commonly used alternatives.


Acknowledgments
I would ï¬rst like to thank Thomas Banchoï¬€, my teacher, mentor, and
friend. After one class, he invited me to join his team of students on devel-
oping electronic books for diï¬€erential geometry and multivariable calculus.
Despite ultimately specializing in algebra, the exciting projects he lead
and his inspiring course in diï¬€erential geometry instilled in me a passion
for diï¬€erential geometry. His ability to introduce diï¬€erential geometry as
a visually stimulating and mathematically interesting topic served as one
of my personal motivations for writing this book.
I am grateful to the students and former colleagues at Eastern Nazarene
College.
In particular, I would like to acknowledge the undergraduate
students who served as a sounding board for the ï¬rst few drafts of this
manuscript: Luke Cochran, David Constantine, Joseph Cox, Stephen Mapes,
and Christopher Young.
Special thanks are due to my colleagues Karl
Giberson, Lee Hammerstrom, and John Free. In addition, I am indebted
to Ellie Waal who helped with editing and index creation.
The continued support from my colleagues at Wheaton College made
writing this book a gratifying project. In particular, I must thank Terry
Perciante, Chair of the Department of Mathematics and Computer Science,
for his enthusiasm and his interest. I am indebted to Dorothy Chapell, Dean
of the Natural and Social Sciences, and to Stanton Jones, Provost of the
College, for their encouragement and for a grant that freed up my time to
ï¬nish writing. I am also grateful to Thomas VanDrunen and Darren Craig.
Finally, I cannot adequately express in just a few words how much I am
grateful to my wife, Carla Favreau Lovett, and my daughter, Anne. While
I was absorbed in this project, they provided a loving home, they braved
the signiï¬cant time commitment, and encouraged me at every step. They
also kindly put up with my occasional geometry comments such as how to
see the Gaussian curvature in the reï¬‚ection of â€œthe Beanâ€ in Chicago.
xiii


CHAPTER
1
Analysis of Multivariable Functions
Parametrized curves into Rn are continuous functions from an interval of R
to Rn. Therefore, the study of local and global properties of curves requires
single-variable calculus. As one might expect, the study of surfaces in Eu-
clidean three-space involves continuous functions from R2 to R3. Therefore,
in order to properly phrase the theory of surfaces and, more generally, the
theory of manifolds, one needs to understand the analysis of multivariable
functions f : Rn â†’Rm.
1.1
Functions from Rn to Rm
Let U be a subset of Rn, and let f : U â†’Rm be a function from U to Rm.
Let {âƒ—u1, . . . , âƒ—un} be a basis of Rn, and let {âƒ—v1, . . . ,âƒ—vm} be a basis of Rm.
Writing the input variable as
âƒ—x = (x1, x2, . . . , xn)
= x1âƒ—u1 + x2âƒ—u2 + Â· Â· Â· + xnâƒ—un,
we denote the output assigned to âƒ—x by f(âƒ—x) or f(x1, . . . , xn). Since the
codomain of f is Rm, the images of f are vectors and one writes
f(âƒ—x) = (f1(âƒ—x), . . . , fm(âƒ—x))
= f1(x1, . . . , xn)âƒ—v1 + Â· Â· Â· + fm(x1, . . . , xn)âƒ—vm.
The functions f1(x1, . . . , xn), . . . , fm(x1, . . . , xn) are called the component
functions of f with respect to the basis {âƒ—v1, . . . ,âƒ—vm}.
One sometimes uses the notation âƒ—f(âƒ—x) to emphasize the fact that the
codomain Rm is a vector space and that any operation on m-dimensional
vectors is permitted on functions âƒ—f : Rn â†’Rm. Therefore, some authors
call such functions vector functions of a vector variable.
1

2
1. Analysis of Multivariable Functions
In any Euclidean space Rn, the standard basis is the set of vectors
written as {âƒ—e1,âƒ—e2, . . . ,âƒ—en}, where
âƒ—ei =
â›
âœ
âœ
âœ
âœ
âœ
âœ
â
0
...
1
...
0
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
â 
with the only nonzero entry 1 occurring in the ith coordinate. If no basis
is explicitly speciï¬ed for Rn, then it is assumed that one uses the standard
basis.
At this point, a remark is in order concerning the diï¬€erences in nota-
tions between calculus and linear algebra. In calculus, one usually denotes
an element of Rn as an n-tuple and writes this element on one line as
(x1, . . . , xn). On the other hand, in order to reconcile vector notation with
the rules for multiplying a matrix by a vector, in linear algebra one denotes
an element of Rn as a column vector
â›
âœ
â
x1
...
xn
â
âŸ
â .
This unfortunate diï¬€erence in notation is a result of history and impossible
to change now. Nor is the diï¬€erence a trivial one since, in linear algebra,
a column vector is an n Ã— 1 matrix, which is distinct from a 1 Ã— n matrix.
This variance in notation is also related to the diï¬€erence between a vector
space and its dual, a concept which we develop later. In the rest of this
book, we will write the components of a vector function on one line as per
the n-tuple notation, but whenever a vector or vector function appears in
a linear algebraic equation, it must be understood as a column vector.
Example 1.1.1 (Curves in Rn). A parametrized curve into n-dimensional space
is a continuous function âƒ—x : I â†’Rn.
Parametrized curves are vector
functions of a vector variable, but the variable is taken from a subset of a
one-dimensional vector space.
Example 1.1.2 (Nonlinear Coordinate Changes).
A general change of coordi-
nates in R2 is a function F : U â†’R2, where U is the subset of R2 in
which the coordinates are deï¬ned. For example, the change from polar

1.1. Functions from Rn to Rm
3
coordinates to Cartesian coordinates is given by the function F : R2 â†’R2
deï¬ned by
F(r, Î¸) = (r cos Î¸, r sin Î¸).
Example 1.1.3. In a usual multivariable calculus course, one studies func-
tions F : Rn â†’R, written as F(x1, x2, . . . , xn). All such functions are just
examples of vector functions of a vector variable with codomain R.
Example 1.1.4. As an example of a function from R2 to R3, consider the
function
F(x1, x2) =

2x2(1 âˆ’x2
1)
(1 + x2
1)(1 + x2
2),
4x1x2
(1 + x2
1)(1 + x2
2), 1 âˆ’x2
2
1 + x2
2
	
.
Notice that the component functions satisfy
F 2
1 + F 2
2 + F 2
3 = 4x2
2(1 âˆ’x2
1)2 + 16x2
1x2
2 + (1 + x2
1)2(1 âˆ’x2
2)2
(1 + x2
1)2(1 + x2
2)2
= 4x2
2(1 + x2
1)2 + (1 + x2
1)2(1 âˆ’x2
2)2
(1 + x2
1)2(1 + x2
2)2
= (1 + x2
1)2(1 + x2
2)2
(1 + x2
1)2(1 + x2
2)2
= 1.
Thus, the image of F lies on the unit sphere S2 = {(x, y, z) âˆˆR3 | x2 +y2 +
z2 = 1}.
It is interesting to note that F is not surjective onto S2. Assuming
x2 + y2 + z2 = 1, if F(u, v) = (x, y, z), then in particular
z = 1 âˆ’v2
1 + v2 â‡â‡’v =

1 âˆ’z
1 + z ,
which implies that âˆ’1 < z â‰¤1, and hence, the point (0, 0, âˆ’1) is not an
image of F. Furthermore, since
z2 +

2v
1 + v2
	2
= 1
and thus
2v
1 + v2 =

1 âˆ’z2,
for any ï¬xed z, we have
x = 1 âˆ’u2
1 + u2

1 âˆ’z2
and
y =
2u
1 + u2

1 âˆ’z2.

4
1. Analysis of Multivariable Functions
Figure 1.1. Portion of the image for Example 1.1.4.
But then, if y = 0, it is impossible to obtain x = âˆ’
âˆš
1 âˆ’z2. Consequently,
the image of F is all points on S2 except points in the set
{(x, y, z) âˆˆS2 | x = âˆ’

1 âˆ’z2 with z < 1}.
Figure 1.1 shows the image of F over the rectangle (x1, x2) âˆˆ[âˆ’2, 5] Ã—
[0.5, 5].
Whether one has at oneâ€™s disposal a computer algebra system with
graphing capabilities or whether one attempts to picture a function with
paper and pencil, there are a few diï¬€erent ways to visualize functions.
Of course, as n and m get beyond 2 or 3, visualization becomes more
diï¬ƒcult. Recall that the graph of a function f : Rn â†’Rm is the subset of
Rn Ã— Rm = Rn+m deï¬ned by
{(x1, . . . , xn, y1, . . . , ym) âˆˆRn+m | (y1, . . . , ym) = f(x1, . . . , xn)}.
The usual method to depict functions f : R â†’R (respectively f : R2 â†’R)
is to depict the graph as a subset of R2 (respectively R3).
This is the
standard practice in every calculus course.
For functions F : R2 â†’R (respectively F : R3 â†’R), another way
to attempt to visualize F is by plotting together (or in succession if one
has dynamical graphing capabilities) a collection of level curves (respec-
tively surfaces) deï¬ned by F(x, y) = ci (respectively F(x, y, z) = ci) for
a discrete set of values ci.
This is typically called a contour diagram
of F. Figure 1.2(a) depicts a contour diagram of 2y/(x2 + y2 + 1) with
c = 0, Â±0.2, Â±0.4, Â±0.6, Â±0.8.

1.1. Functions from Rn to Rm
5
x
y
(a) A contour diagram.
x
y
z
(b) A space curve.
Figure 1.2. Methods of visualizing functions.
In a multivariable calculus course or in a basic diï¬€erential geometry
course [5], one typically uses yet another technique to visualize functions
of the form âƒ—f : R â†’Rn, for n = 2 or 3. One usually depicts a function
âƒ—f : R â†’R2 as a plane curve and a function âƒ—f : R â†’R3 as a space curve,
but one only plots the image of âƒ—f in R2 or R3. In doing so, we lose visual
information about the magnitude âˆ¥âƒ—f â€²(t)âˆ¥, intuitively speaking, how fast
one travels along the curve. Figure 1.2(b) shows the image of the so-called
space cardioid, given by the function
âƒ—f(t) = ((1 âˆ’cos t) cos t, (1 âˆ’cos t) sin t, sin t) .
Similarly, when one studies the geometry of surfaces, one again depicts a
function âƒ—F : R2 â†’R3 by plotting its image in R3. (The graph of a function
of the form R2 â†’R3 is a subset of R5, which is quite diï¬ƒcult to visualize
no matter what computer tools one has at oneâ€™s disposal!)
One can deï¬ne the usual operations on functions as one would expect.
Deï¬nition 1.1.5. Let âƒ—f and âƒ—g be two functions deï¬ned over a subset U of
Rn with codomain Rm. Then we deï¬ne the following functions:
1. (âƒ—f + âƒ—g) : U â†’Rm, where (âƒ—f + âƒ—g)(âƒ—x) = âƒ—f(âƒ—x) + âƒ—g(âƒ—x).
2. (âƒ—f Â· âƒ—g) : U â†’R, where (âƒ—f Â· âƒ—g)(âƒ—x) = âƒ—f(âƒ—x) Â· âƒ—g(âƒ—x).
3. If m = 3, (âƒ—f Ã— âƒ—g) : U â†’R3, where (âƒ—f Ã— âƒ—g)(âƒ—x) = âƒ—f(âƒ—x) Ã— âƒ—g(âƒ—x).

6
1. Analysis of Multivariable Functions
Deï¬nition 1.1.6. Let âƒ—f be a function from a subset U âŠ‚Rn to Rm, and let
âƒ—g be a function from V âŠ‚Rm to Rs. If the image of âƒ—f is a subset of V ,
then the composition function âƒ—g â—¦âƒ—f is the function U â†’Rs deï¬ned by
(âƒ—g â—¦âƒ—f)(âƒ—x) = âƒ—g

âƒ—f(âƒ—x)

.
Out of the vast variety of possible functions one could study, the class
of linear functions serves a fundamental role in the analysis of multivariable
functions. (This book assumes the reader is familiar with linear algebra,
but we present a reminder of a few fundamental facts at this point.)
Deï¬nition 1.1.7. A function F : Rn â†’Rm is called a linear function if
F(âƒ—x + âƒ—y) = F(âƒ—x) + F(âƒ—y)
for all âƒ—x, âƒ—y âˆˆRn,
F(kâƒ—x) = kF(âƒ—x)
for all k âˆˆR and all âƒ—x âˆˆRn.
If a function F : Rn â†’Rm is linear, then
F(âƒ—0) = F(âƒ—0 âˆ’âƒ—0) = F(âƒ—0) âˆ’F(âƒ—0) = âƒ—0,
and hence F maps the origin of Rn to the origin of Rm.
If B = {âƒ—u1, . . . , âƒ—un} is a basis of Rn, then any vector âƒ—u âˆˆRn can be
written uniquely as a linear combination of vectors in B as
âƒ—u = c1âƒ—u1 + Â· Â· Â· + cnâƒ—un.
One often writes the coeï¬ƒcients in linear algebra as the column vector
[âƒ—u]B =
â›
âœ
â
c1
...
cn
â
âŸ
â .
If the basis B is not speciï¬ed, one assumes that the coeï¬ƒcients are given
in terms of the standard basis. If F is a linear function, then
F(âƒ—u) = c1F(âƒ—u1) + Â· Â· Â· + cnF(âƒ—un),
hence, to know all outputs of F one needs to know the coeï¬ƒcients of
[âƒ—u]B and the output of the basis vectors of B. Suppose also that Bâ€² =
{âƒ—v1, . . . ,âƒ—vm} is a basis of Rm. If the Bâ€²-coordinates of the outputs of the
vectors in B are
[F(âƒ—u1)]Bâ€² =
â›
âœ
âœ
âœ
â
a11
a21
...
am1
â
âŸ
âŸ
âŸ
â ,
[F(âƒ—u2)]Bâ€² =
â›
âœ
âœ
âœ
â
a12
a22
...
am2
â
âŸ
âŸ
âŸ
â ,
Â· Â· Â· ,
[F(âƒ—un)]Bâ€² =
â›
âœ
âœ
âœ
â
a1n
a2n
...
amn
â
âŸ
âŸ
âŸ
â ,

1.1. Functions from Rn to Rm
7
then the image of the vector âƒ—u âˆˆRn is given by
[F(âƒ—u)]Bâ€² = c1
â›
âœ
âœ
âœ
â
a11
a21
...
am1
â
âŸ
âŸ
âŸ
â + c2
â›
âœ
âœ
âœ
â
a12
a22
...
am2
â
âŸ
âŸ
âŸ
â + Â· Â· Â· + cn
â›
âœ
âœ
âœ
â
a1n
a2n
...
amn
â
âŸ
âŸ
âŸ
â 
=
â›
âœ
âœ
âœ
â
a11
a12
Â· Â· Â·
a1n
a21
a22
Â· Â· Â·
a2n
...
...
...
...
am1
am2
Â· Â· Â·
amn
â
âŸ
âŸ
âŸ
â 
â›
âœ
âœ
âœ
â
c1
c2
...
cn
â
âŸ
âŸ
âŸ
â .
The matrix
A =
â›
âœ
âœ
âœ
â
a11
a12
Â· Â· Â·
a1n
a21
a22
Â· Â· Â·
a2n
...
...
...
...
am1
am2
Â· Â· Â·
amn
â
âŸ
âŸ
âŸ
â 
is called the B, Bâ€²-matrix of the linear function F. Therefore, one of the
fundamental results of linear algebra is that, with respect to the bases B
of Rn and Bâ€² of Rm, any linear function F : Rn â†’Rm can be written
uniquely as
[F(âƒ—u)]Bâ€² = A [âƒ—u]B
for some m Ã— n matrix A.
Given a linear function F : Rn â†’Rn, one calls the image of F the set
Im(F) = F(Rn), and the kernel of F is the zero set
ker F = {âƒ—u âˆˆRn | F(âƒ—u) = âƒ—0}.
The image Im F is a vector subspace of Rm, and the kernel is a subspace
of Rn. The rank of F is the dimension dim(Im F) and can be shown to
be equal to the size of the largest nonvanishing minor in the matrix of F,
which is independent of the bases. The image of F cannot have a greater
dimension than either the domain or the codomain can, so
rank F â‰¤min{m, n},
and one says that F has maximal rank if F = min{m, n}. It is not hard
to show that a linear function F : Rn â†’Rm is surjective if and only if
rank F = m and F is injective if and only if rank F = n.
The rank is also useful in determining the linear dependence between a
set of vectors. If {âƒ—u1, âƒ—u2, . . . , âƒ—un} is a set of vectors in Rm, then the matrix
A =
âƒ—u1
âƒ—u2
Â· Â· Â·
âƒ—un

,

8
1. Analysis of Multivariable Functions
where the âƒ—ui are viewed as column vectors, represents a linear function
F : Rn â†’Rm, with
Im F = Span{âƒ—u1, âƒ—u2, . . . , âƒ—un}.
Thus, the set of vectors {âƒ—u1, âƒ—u2, . . . , âƒ—un} is linearly independent if and only
if rank F = n.
In the case of n = m, the determinant provides an alternative charac-
terization to linear independence. If F is a linear function from Rn to itself
with associated matrix A, then | det A| is the n-volume of the image under
F of the unit n-cube. Consequently, if the columns of A are not linearly
independent, the n-volume of this parallelepiped will be 0. This leads one
to a fundamental summary theorem in linear algebra.
Theorem 1.1.8. For a linear function F : Rn â†’Rn with associated square
matrix A, the following statements are equivalent:
1. rankF = n.
2. det A Ì¸= 0.
3. Im F = Rn.
4. ker F = {âƒ—0}.
5. The column vectors of A are linearly independent.
6. The column vectors of A form a basis of Rn.
7. The column vectors of A span Rn.
8. F has an inverse function.
We remind the reader that matrix multiplication is deï¬ned in such a
way so that if A is the matrix for a linear function F : Rn â†’Rm and B is
the matrix for a linear function matrix G : Rp â†’Rn, then the product AB
is the matrix representing the composition F â—¦G : Rp â†’Rm. Furthermore,
if m = n and rank F = n, then the matrix Aâˆ’1 is the matrix that represents
the inverse function of F.
Problems
1.1.1. Consider the function F in Example 1.1.4. Prove algebraically that if the
domain is restricted to R Ã— (0, +âˆ), it is injective. What is the image of
F in this case?

1.2. Continuity, Limits, and Differentiability
9
1.1.2. Let F : R2 â†’R2 be the function deï¬ned by F(s, t) = (s2 âˆ’t2, 2st), and
let G : R2 â†’R2 be the function deï¬ned by G(u, v) = (2u2 âˆ’3v, uv + v3).
Calculate the component functions of F â—¦G and of G â—¦F.
1.1.3. Show that the function âƒ—X : [0, 2Ï€] Ã— [0, Ï€] â†’R3, with
âƒ—X(x1, x2) = (cos x1 sin x2, sin x1 sin x2, cos x2),
deï¬nes a mapping onto the unit sphere in R3. Which points on the unit
sphere have more than one preimage?
1.1.4. Consider the function F from R3 to itself deï¬ned by
F(x1, x2, x3) = (x1 + 2x2 + 3x3, 4x1 + 5x2 + 6x3, 7x1 + 8x2 + 9x3).
Prove that this is a linear function. Find the matrix associated to F (with
respect to the standard basis). Find the rank of F, and if the rank is less
than 3, ï¬nd equations for the image of F.
1.1.5. Consider a line L in Rn traced out by the parametric equation âƒ—x(t) = tâƒ—a+âƒ—b.
Prove that for any linear function F : Rn â†’Rm, the image F(L) is either
a line or a point.
1.1.6. Let F : Rn â†’Rm be a linear function, and let L1 and L2 be parallel lines
in Rn. Prove that F(L1) and F(L2) are either both points or both lines
in Rm. If F(L1) and F(L2) are both lines, prove that they are parallel.
1.1.7. Let F : Rn â†’Rm be a linear function with associated matrix A. Prove
that F(L1) âŠ¥F(L2) for any pair of perpendicular lines L1 and L2 in Rn
if and only if AT A = Im.
1.1.8. Let âƒ—Ï‰ be a nonzero vector in Rn. Deï¬ne the function F : Rn â†’R as
F(âƒ—x) = âƒ—Ï‰ Â· âƒ—x.
Prove that F is a linear function. Find the matrix associated to F (with
respect to the standard basis).
1.1.9. Let âƒ—Ï‰ be a nonzero vector in R3. Deï¬ne the function F : R3 â†’R3 as
F(âƒ—x) = âƒ—Ï‰ Ã— âƒ—x.
Prove that F is a linear function. Find the matrix associated to F (with
respect to the standard basis). Prove that rank F = 2.
1.2
Continuity, Limits, and Differentiability
Intuitively, a function is called continuous if it preserves â€œnearness.â€ A
rigorous mathematical deï¬nition for continuity for functions from Rn to
Rm is hardly any diï¬€erent for functions from R â†’R.

10
1. Analysis of Multivariable Functions
In calculus of a real variable, one does not study functions deï¬ned over
a discrete set of real values because the notions behind continuity and dif-
ferentiability do not make sense over such sets. Instead, one often assumes
the function is deï¬ned over some interval. Similarly, for the analysis of
functions Rn to Rm, one does not study functions deï¬ned from any sub-
set of Rn into Rm. One typically considers functions deï¬ned over what is
called an open set in Rn, a notion we deï¬ne now.
Deï¬nition 1.2.1. The open ball around âƒ—x0 of radius r is the set
Br(âƒ—x0) = {âƒ—x âˆˆRn : âˆ¥âƒ—x âˆ’âƒ—x0âˆ¥< r} .
A subset U âŠ‚Rn is called open if for all âƒ—x âˆˆU there exists an r > 0 such
that Br(âƒ—x) âŠ‚U.
The reader is encouraged to consult Section A.2.2 for more background
on open and closed sets. The situation in which we need to consider an
open set U and a point âƒ—x0 in U is so common that another terminology
exists for U in this case.
Deï¬nition 1.2.2. Let âƒ—x0 âˆˆRn. Any open set U in Rn such that âƒ—x0 âˆˆU is
called an open neighborhood, or more simply, a neighborhood, of âƒ—x0.
We are now in a position to formally deï¬ne continuity for functions.
Deï¬nition 1.2.3. Let U be an open subset of Rn, and let âƒ—F be a function
from U into Rm. The function âƒ—F is called continuous at the point âƒ—x0 âˆˆU
if F(âƒ—x0) exists and if, for all Îµ > 0, there exists a Î´ > 0 such that for all
âƒ—x âˆˆR,
âˆ¥âƒ—x âˆ’âƒ—x0âˆ¥< Î´
=â‡’
âˆ¥âƒ—F(âƒ—x) âˆ’âƒ—F(âƒ—x0)âˆ¥< Ïµ.
The function âƒ—F is called continuous on U if it is continuous at every point
of U.
With the language of open balls, one can rephrase the deï¬nition of
continuity as follows. Let U be an open subset of Rn. A function âƒ—F : U â†’
Rm is continuous at a point âƒ—x0 if for all Îµ > 0 there exists a Î´ > 0 such
that
F(BÎ´(âƒ—x0)) âŠ‚BÎµ(F(âƒ—x0)).
(Sections A.2.2 and A.2.4 provide a comprehensive discussion about open
sets in a metric space, a generalization of Rn, and continuity of functions
between metric spaces.)

1.2. Continuity, Limits, and Differentiability
11
Example 1.2.4. Consider the function F : Rn â†’Rn deï¬ned by
F(âƒ—x) =

âƒ—x/âˆ¥âƒ—xâˆ¥,
if âƒ—x Ì¸= âƒ—0,
âƒ—0,
if âƒ—x = âƒ—0.
This function leavesâƒ—0 ï¬xed and projects the rest of Rn onto the unit sphere.
If âƒ—x Ì¸= âƒ—0, then
âˆ¥F(âƒ—x) âˆ’F(âƒ—x0)âˆ¥=

âƒ—x
âˆ¥âƒ—xâˆ¥âˆ’
âƒ—x0
âˆ¥âƒ—x0âˆ¥
 â‰¤

âƒ—x
âˆ¥âƒ—xâˆ¥âˆ’
âƒ—x
âˆ¥âƒ—x0âˆ¥
 +

âƒ—x
âˆ¥âƒ—x0âˆ¥âˆ’
âƒ—x0
âˆ¥âƒ—x0âˆ¥
 .
However,

âƒ—x
âˆ¥âƒ—xâˆ¥âˆ’
âƒ—x
âˆ¥âƒ—x0âˆ¥
 =

1
âˆ¥âƒ—xâˆ¥âˆ’
1
âˆ¥âƒ—x0âˆ¥
 âˆ¥âƒ—xâˆ¥= âˆ¥âƒ—xâˆ¥| âˆ¥âƒ—x0âˆ¥âˆ’âˆ¥âƒ—xâˆ¥|
âˆ¥âƒ—xâˆ¥âˆ¥âƒ—x0âˆ¥
â‰¤
1
âˆ¥âƒ—x0âˆ¥âˆ¥âƒ—x âˆ’âƒ—x0âˆ¥,
and thus,
âˆ¥F(âƒ—x) âˆ’F(âƒ—x0)âˆ¥â‰¤
2
âˆ¥âƒ—x0âˆ¥âˆ¥âƒ—x âˆ’âƒ—x0âˆ¥.
Consequently, given any Îµ > 0 and setting
Î´ = min

âˆ¥âƒ—x0âˆ¥, 1
2Îµâˆ¥âƒ—x0âˆ¥
	
,
we know that âƒ—x Ì¸= âƒ—0 and also that âˆ¥F(âƒ—x) âˆ’F(âƒ—x0)âˆ¥< Îµ.
Hence, F is
continuous at all âƒ—x0 Ì¸= âƒ—0.
On the other hand, if âƒ—x0 = âƒ—0, for all âƒ—x Ì¸= âƒ—x0,
âˆ¥F(âƒ—x) âˆ’F(âƒ—0)âˆ¥= âˆ¥F(âƒ—x) âˆ’âƒ—0âˆ¥= âˆ¥F(âƒ—x)âˆ¥= 1,
which can never be less than Îµ if Îµ â‰¤1.
Example 1.2.5. As a contrast to Example 1.2.4, consider the function
âƒ—F(âƒ—x) =

âƒ—x,
if all components of âƒ—x are rational,
âƒ—0,
otherwise.
The function F is obviously continuous at âƒ—0, with Î´ = Îµ satisfying the
requirements of Deï¬nition 1.2.3. On the other hand, if âƒ—x0 Ì¸= âƒ—0, then in
BÎ´(âƒ—x0), for any Î´ > 0, one can always ï¬nd an âƒ—x that has either all rational
components or has at least one irrational component. Thus, if Îµ < âˆ¥âƒ—x0âˆ¥,
for all Î´ > 0, we have
F(BÎ´(âƒ—x0)) âŠˆBÎµ(F(âƒ—x0)).
Thus, F is not continuous at any point diï¬€erent from âƒ—0.

12
1. Analysis of Multivariable Functions
The following theorem implies many other corollaries concerning conti-
nuity of multivariable functions.
Theorem 1.2.6. Let U be an open subset of Rn, let âƒ—F : U â†’Rm be a function,
and let Fi, with i = 1, . . . , m, be the component functions. The function âƒ—F
is continuous at the point âƒ—a âˆˆU if and only if, for all i = 1, . . . , m, the
component function Fi : U â†’R is continuous at âƒ—a.
Proof: Without loss of generality, assume that the component functions of
âƒ—F are given in terms of an orthonormal basis of Rm.
Suppose that âƒ—F is continuous at âƒ—a. Thus, for all Îµ > 0, there exists a
Î´ > 0 such that âˆ¥âƒ—x âˆ’âƒ—aâˆ¥< Î´ implies âˆ¥âƒ—F(âƒ—x) âˆ’âƒ—F(âƒ—a)âˆ¥< Îµ. Since
âˆ¥âƒ—F(âƒ—x) âˆ’âƒ—F(âƒ—a)âˆ¥=

(âƒ—F (âƒ—x)1 âˆ’âƒ—F(âƒ—a)1)2 + Â· Â· Â· + (âƒ—F (âƒ—x)m âˆ’âƒ—F(âƒ—a)m)2
â‰¥|âƒ—F(âƒ—x)i âˆ’âƒ—F(âƒ—a)i|,
given any Îµ, the above Î´ suï¬ƒces since âˆ¥âƒ—x âˆ’âƒ—aâˆ¥< Î´ implies that
|Fi(âƒ—x) âˆ’Fi(âƒ—a)| â‰¤âˆ¥âƒ—F(âƒ—x) âˆ’âƒ—F(âƒ—a)âˆ¥< Îµ.
Conversely, suppose that all the functions Fi are continuous at âƒ—a. Thus,
for any Îµ and for all i, there exist Î´i > 0 such that âˆ¥âƒ—x âˆ’âƒ—aâˆ¥< Î´i implies
|Fi(âƒ—x) âˆ’Fi(âƒ—a)| < Îµ/âˆšm. Then taking Î´ = min(Î´1, . . . , Î´m), if âˆ¥âƒ—x âˆ’âƒ—aâˆ¥< Î´,
then
âˆ¥âƒ—F(âƒ—x) âˆ’âƒ—F(âƒ—a)âˆ¥=

|F1(âƒ—x) âˆ’F1(âƒ—a)|2 + Â· Â· Â· + |Fm(âƒ—x) âˆ’Fm(âƒ—a)|2
â‰¤

Îµ2
m + Â· Â· Â· + Îµ2
m = Îµ.
Thus, âƒ—F is continuous.
â–¡
Theorem 1.2.7. Let U be an open set in Rn, let âƒ—F and âƒ—G be functions from
U to Rm, let h : U â†’R, and suppose that âƒ—F, âƒ—G, and h are all continuous
at âƒ—a âˆˆU. Then the following functions are also continuous at âƒ—a:
âˆ¥âƒ—Fâˆ¥, âƒ—F + âƒ—G, hâƒ—F, âƒ—F Â· âƒ—G.
If m = 3, then the vector function âƒ—F Ã— âƒ—G is also continuous at âƒ—a.
Proof: (Left as an exercise for the reader.)
â–¡

1.2. Continuity, Limits, and Differentiability
13
If U is an open set containing a point âƒ—a, then the set U âˆ’{âƒ—a} is called a
deleted neighborhood of âƒ—a. If a function âƒ—F is a function into Rm deï¬ned on
a deleted neighborhood of a point âƒ—a âˆˆRn, it is possible to deï¬ne the limit
of âƒ—F at âƒ—a. The limit of âƒ—F at âƒ—a is the value âƒ—p such that if âƒ—F(âƒ—a) were âƒ—p, then
âƒ—F(âƒ—a) would be continuous at âƒ—a. We make this more precise as follows.
Deï¬nition 1.2.8. Let âƒ—a âˆˆRn.
Let âƒ—F be a function from an open subset
U âˆ’{âƒ—a} âŠ‚Rn into Rm. The limit of âƒ—F at âƒ—a is deï¬ned as the point âƒ—L if, for
all Îµ, there exists a Î´ such that
âƒ—F(BÎ´(âƒ—a) âˆ’{âƒ—a}) âŠ‚BÎµ(âƒ—L).
In most multivariable calculus courses, before meeting the partial deriva-
tives, one encounters the directional derivative, which measures the rate of
change of a function in a given direction. Therefore, before introducing the
diï¬€erential of a vector function of a vector variable, we introduce directional
derivatives.
Deï¬nition 1.2.9. Let âƒ—F be a function from an open subset U âŠ‚Rn into Rm,
let âƒ—x0 âˆˆU be a point, and let âƒ—u be a unit vector. The directional derivative
of âƒ—F in the direction âƒ—u at the point âƒ—x0 is
Dâƒ—u âƒ—F(âƒ—x0) = lim
hâ†’0
âƒ—F(âƒ—x0 + hâƒ—u) âˆ’âƒ—F(âƒ—x0)
h
whenever the limit exists.
An alternate deï¬nition of the directional derivative is to deï¬ne the curve
into Rm by âƒ—F(t) = âƒ—F(âƒ—x0 + tâƒ—u). Then Dâƒ—u âƒ—F(âƒ—x0) is equal to the derivative of
âƒ—F at t = 0, namely,
d
dt âƒ—F(âƒ—x0 + tâƒ—u)|t=0.
Like the directional derivative introduction in multivariable calculus
for functions from Rn into R, the deï¬nition of Dâƒ—u âƒ—F(âƒ—x0) reduces to a single
variable before taking a derivative. However, unlike multivariable calculus,
the resulting quantity is a vector, not a real number.
Example 1.2.10. Consider the function âƒ—F(s, t) = (s2 âˆ’t2, 2st) from R2 to
itself. We will calculate the directional derivative of âƒ—F at âƒ—x0 = (1, 2) in the
direction of âƒ—u = (1/2, âˆ’
âˆš
3/2).
One can picture this kind of function by plotting a discrete set of coor-
dinate lines mapped under âƒ—F (see Figure 1.3). However, for functions like
âƒ—F that are not injective, even this method of picturing âƒ—F can be misleading
since every point in the codomain can have multiple preimages.

14
1. Analysis of Multivariable Functions
s
t
(1, 2)
âƒ—u
t = Â±1
t = Â±2
s = Â±1
s = Â±2
Dâƒ—u âƒ—F(âƒ—x0)
âƒ—F
Figure 1.3. Example 1.2.10.
Now,
âƒ—F(âƒ—x0 + tâƒ—u) =
â›
â

1 + 1
2t
	2
âˆ’

2 âˆ’
âˆš
3
2 t
2
, 2

1 + 1
2t
	 
2 âˆ’
âˆš
3
2 t
â
â 
=

âˆ’3 + (2 + 4
âˆš
3)t âˆ’2t2, 4 + (4 âˆ’2
âˆš
3)t âˆ’2
âˆš
3t2
,
so
Dâƒ—u âƒ—F(âƒ—x0) =

(2 + 4
âˆš
3) âˆ’4t, (4 âˆ’2
âˆš
3) âˆ’4
âˆš
3t
 
t=0 = (2+4
âˆš
3, 4âˆ’2
âˆš
3).
Figure 1.3 shows the curve âƒ—F(âƒ—x0 + tâƒ—u) and illustrates the directional
derivative as being the derivative of âƒ—F(âƒ—x0 + tâƒ—u) at t = 0. The ï¬gure shows
that though âƒ—u must be a unit vector, the directional derivative is usually
not.
Now suppose that an orthonormal basis {âƒ—u1, . . . , âƒ—un} in Rn is ï¬xed. Let
âƒ—F be a function from an open set U âŠ‚Rn to Rm. For any point âƒ—x0 âˆˆU,
the directional derivative of âƒ—F in the direction âƒ—uk at âƒ—x0 is called the kth
partial derivative of âƒ—F at âƒ—x0. The kth partial derivative of âƒ—F is itself a
vector function possibly deï¬ned on a smaller set than U. Writing
âƒ—F(âƒ—x) = (F1(x1, . . . , xn), . . . , Fm(x1, . . . , xn)) ,
some common notations for the kth partial derivative Dâƒ—uk âƒ—F are
âƒ—Fxk,
âˆ‚âƒ—F
âˆ‚xk
,
Dk âƒ—F,
âƒ—F,k.

1.2. Continuity, Limits, and Differentiability
15
Figure 1.4. Graph of the function in Example 1.2.11.
(The notation âƒ—F,k for the kth partial derivative is not standard but is
typically understood as the derivative with respect to the kth variable. One
uses the comma to distinguish the derivative operation from an index.) It
is not hard to show that
âˆ‚âƒ—F
âˆ‚xk
(âƒ—x) =
âˆ‚F1
âˆ‚xk
(x1, . . . , xn), . . . , âˆ‚Fm
âˆ‚xk
(x1, . . . , xn)
	
.
Example 1.2.11. Consider the real-valued function f(x1, x2) deï¬ned by
f(x1, x2) =
â§
â¨
â©
x1x2
2
x2
1 + x4
2
,
if (x1, x2) Ì¸= (0, 0),
0,
otherwise.
See Figure 1.4. We study the behavior of f near âƒ—x = âƒ—0.
Let âƒ—u = (u1, u2) be a unit vector, with u1 Ì¸= 0. Then
Dâƒ—uf(âƒ—0) = lim
hâ†’0
f(âƒ—0 + hâƒ—u) âˆ’f(âƒ—0)
h
= lim
hâ†’0
h3u1u2
2
h(h2u2
1 + h4u4
2)
= lim
hâ†’0
u1u2
2
(u2
1 + h2u4
2) = u2
2
u1
.
If u1 = 0, then f(âƒ—0+hâƒ—u) = 0 for all h, so Dâƒ—uf(âƒ—0) = 0. Thus, the directional
derivative Dâƒ—uf(âƒ—0) is deï¬ned for all unit vectors âƒ—u.
On the other hand, consider the curve âƒ—x(t) = (t2, t). Along this curve,
if t Ì¸= 0,
f(âƒ—x(t)) =
t4
t4 + t4 = 1
2.

16
1. Analysis of Multivariable Functions
Thus,
f(âƒ—x(t)) =

1
2,
if t Ì¸= 0,
0,
if t = 0,
which is not continuous. Notice that this implies that f as a function from
R2 to R is not continuous at âƒ—0 since making Îµ = 1
4, for all Î´ > 0, there exist
points âƒ—x (in this case, points of the form âƒ—x = (t2, t)) such that âˆ¥âƒ—xâˆ¥< Î´
have |f(âƒ—x)| > Îµ.
Therefore, the function f is deï¬ned at âƒ—0, has directional derivatives in
every direction at âƒ—0, but is not continuous at âƒ—0.
Example 1.2.11 shows that it is possible for a vector function to have
directional derivatives in every direction at some point âƒ—a but, at the same
time, fail to be continuous at âƒ—a. The reason for this is that the directional
derivative depends only upon the behavior of a function along a line through
âƒ—a, while approaching âƒ—a along other families of curves may exhibit a diï¬€erent
behavior of the function.
The behavior of the function in Example 1.2.11 makes it clear that even
if all the partial derivatives of a function âƒ—F exist at a point, one should
not call it diï¬€erentiable there. A better approach is to call a function dif-
ferentiable at some point if it can be approximated by a linear function. A
more precise deï¬nition follows.
Deï¬nition 1.2.12. Let âƒ—F be a function from an open set U âŠ‚Rn to Rm and
let âƒ—a âˆˆU. We call âƒ—F diï¬€erentiable at âƒ—a if there exist a linear transformation
L : Rn â†’Rm and a function âƒ—R deï¬ned in a neighborhood of âƒ—a such that
âƒ—F(âƒ—a + âƒ—v) = âƒ—F(âƒ—a) + L(âƒ—v) + âƒ—R(âƒ—v),
with
lim
âƒ—vâ†’âƒ—0
âƒ—R(âƒ—v)
âˆ¥âƒ—vâˆ¥= âƒ—0.
If âƒ—F is diï¬€erentiable at âƒ—a, the linear transformation L is denoted by dâƒ—Fâƒ—a
and is called the diï¬€erential of âƒ—F at âƒ—a.
Notations for the diï¬€erential vary widely. Though we will consistently
use dâƒ—Fâƒ—a for the diï¬€erential of âƒ—F at âƒ—a, some authors write dâƒ—F(âƒ—a) instead.
The notation in this text attempts to use the most common notation in dif-
ferential geometry texts and to incorporate some notation that is standard
among modern linear algebra texts.
If âƒ—F is diï¬€erentiable over an open set U âŠ‚Rn, the diï¬€erential dâƒ—F is a
function from U to Hom(Rn, Rm), the set of linear transformations from

1.2. Continuity, Limits, and Differentiability
17
Rn to Rm. If bases B and Bâ€² are given for Rn and Rm, then we denote the
matrix for dâƒ—Fâƒ—a by

dâƒ—Fâƒ—a
Bâ€²
B .
Assuming we use the standard bases for Rn and Rm, we write the matrix
for dâƒ—Fâƒ—a as [dâƒ—Fâƒ—a]. The matrix [dâƒ—F ], which is a matrix of functions deï¬ned
over U, is called the Jacobian matrix of âƒ—F. If m = n, the determinant
of the Jacobian matrix is simply called the Jacobian and is written J(âƒ—F ).
Note that J(âƒ—F) is a function from U to R.
Theorem 1.2.13. Let âƒ—F be a function from an open set U âŠ‚Rn to Rm, and
let âƒ—a âˆˆU. If âƒ—F is diï¬€erentiable at âƒ—a, then it has a directional derivative in
every direction at âƒ—a. Furthermore, Dâƒ—u âƒ—F(âƒ—a) = dâƒ—Fâƒ—a(âƒ—u).
Proof: (Left as an exercise for the reader.)
â–¡
Since the diï¬€erential dâƒ—Fâƒ—a is a linear function from Rn to Rm, for a
vector âƒ—v = (v1, v2, . . . , vn) with coordinates given with respect to some
ï¬xed orthonormal basis {âƒ—u1, . . . , âƒ—un}, we have at any point âƒ—a
dâƒ—Fâƒ—a(v1âƒ—u1 + Â· Â· Â· + vnâƒ—un) = v1dâƒ—Fâƒ—a(âƒ—u1) + Â· Â· Â· + vndâƒ—Fâƒ—a(âƒ—un)
= v1
âˆ‚âƒ—F
âˆ‚x1

âƒ—a + Â· Â· Â· + vn
âˆ‚âƒ—F
âˆ‚xn

âƒ—a,
where the second line follows from the last part of Theorem 1.2.13. Finally,
viewing each partial derivative âˆ‚âƒ—F
âˆ‚xi (âƒ—a) as a column vector, we have
dâƒ—Fâƒ—a(âƒ—v) =

âˆ‚âƒ—F
âˆ‚x1
(âƒ—a)
âˆ‚âƒ—F
âˆ‚x2
(âƒ—a)
Â· Â· Â·
âˆ‚âƒ—F
âˆ‚xn
(âƒ—a)
	
âƒ—v.
This proves the following proposition.
Proposition 1.2.14. Let âƒ—F be a function from an open set U âŠ‚Rn to Rm. At
every point âƒ—a âˆˆU where âƒ—F is diï¬€erentiable, if we write âƒ—F = (F1, F2, . . . , Fm)
with respect to some orthonormal basis, then the Jacobian matrix of âƒ—F is

dâƒ—F

=

âˆ‚âƒ—F
âˆ‚x1
âˆ‚âƒ—F
âˆ‚x2
Â· Â· Â·
âˆ‚âƒ—F
âˆ‚xn
	
=
â›
âœ
âœ
âœ
âœ
âœ
â
âˆ‚F1
âˆ‚x1
âˆ‚F1
âˆ‚x2
Â· Â· Â·
âˆ‚F1
âˆ‚xn
âˆ‚F2
âˆ‚x1
âˆ‚F2
âˆ‚x2
Â· Â· Â·
âˆ‚F2
âˆ‚xn
...
...
...
...
âˆ‚Fm
âˆ‚x1
âˆ‚Fm
âˆ‚x2
Â· Â· Â·
âˆ‚Fm
âˆ‚xn
â
âŸ
âŸ
âŸ
âŸ
âŸ
â 
.
(1.1)

18
1. Analysis of Multivariable Functions
If m = n, because of Equation (1.1), the Jacobian is commonly denoted
by any one of the following notations:
J(âƒ—F ),
âˆ‚(F1, . . . , Fn)
âˆ‚(x1, . . . , xn) ,
det
âˆ‚Fi
âˆ‚xj
	
,
det(dâƒ—F).
Example 1.2.11 shows that the implication statement in Theorem 1.2.13
cannot be replaced with an equivalence statement. Therefore, one should
remember the caveat that the Jacobian matrix may exist at a point âƒ—a
without âƒ—F being diï¬€erentiable at âƒ—a, but in that case, dâƒ—Fâƒ—a does not even
exist.
Example 1.2.15. Consider a function h from an open set U âŠ‚Rn to R. The
diï¬€erential dh has the matrix
[dh] =
 âˆ‚h
âˆ‚x1
âˆ‚h
âˆ‚x2
Â· Â· Â·
âˆ‚h
âˆ‚xn
	
,
which is in fact the gradient of h, though viewed as a row vector.
Example 1.2.16. As a simple example of calculating the Jacobian matrix,
consider the function
F(x1, x2) =

3x1 + x2
2, x1 cos x2, ex1âˆ’2x2 + 2x2

.
It is deï¬ned over all R2. The Jacobian matrix is
â›
âœ
âœ
â
âˆ‚F1
âˆ‚x1
âˆ‚F1
âˆ‚x2
âˆ‚F2
âˆ‚x1
âˆ‚F2
âˆ‚x2
âˆ‚F3
âˆ‚x1
âˆ‚F3
âˆ‚x2
â
âŸ
âŸ
â =
â›
â
3
2x2
cos x2
âˆ’x1 sin x2
ex1âˆ’2x2
âˆ’2ex1âˆ’2x2 + 2
â
â .
If, for example, âƒ—a = (2, Ï€/2), then the matrix for dâƒ—Fâƒ—a is
[dâƒ—Fâƒ—a] =
â›
â
3
Ï€
0
âˆ’2
e2âˆ’Ï€
âˆ’2e2âˆ’Ï€ + 2
â
â .
If, in addition, âƒ—v = (3, âˆ’4) with coordinates given in the standard basis,
then
dâƒ—Fâƒ—a(âƒ—v) =
â›
â
3
Ï€
0
âˆ’2
e2âˆ’Ï€
âˆ’2e2âˆ’Ï€ + 2
â
â 
 3
âˆ’4
	
=
â›
â
9 âˆ’4Ï€
8
11e2âˆ’Ï€ âˆ’8
â
â .
To calculate the directional derivative in the direction of âƒ—v, we must use
the unit vector âƒ—u = âƒ—v/âˆ¥âƒ—vâˆ¥= (0.6, âˆ’0.8) and
Dâƒ—u âƒ—F(âƒ—a) = dâƒ—Fâƒ—a(âƒ—u) =
â›
â
1.8 âˆ’0.8Ï€
1.6
2.2e2âˆ’Ï€ âˆ’1.6
â
â .

1.2. Continuity, Limits, and Differentiability
19
Problems
1.2.1. Let âƒ—F(x, y) = (3xâˆ’2y +4xy, x4 âˆ’3x3y2 +3xy+1). Determine the domain
of the function, explain why or why not the function is continuous over its
domain, and ï¬nd all its (ï¬rst) partial derivatives.
1.2.2. Repeat Problem 1.2.1 with âƒ—F(x, y) = ((x âˆ’y)/(x + y), y ln x).
1.2.3. Repeat Problem 1.2.1 with
âƒ—F(x, y, z) =

tan
 x
y
	
, x3ey+3z,

x2 + y2 + z2
	
.
1.2.4. Let âƒ—F(x, y, z) = (cos(4x+3yz), xz/(1+x2 +y2)). Calculate âƒ—Fxx, âƒ—Fyz, and
âƒ—Fxyz.
1.2.5. Let F : Rn â†’R be a function deï¬ned by F(âƒ—x) = eâƒ—uÂ·âƒ—x, where âƒ—u is a unit
vector in Rn. Prove that
âˆ‚2F
âˆ‚2x1 + âˆ‚2F
âˆ‚2x2 + Â· Â· Â· + âˆ‚2F
âˆ‚2xn = F.
1.2.6. If âƒ—F is a linear function, show that âƒ—F is continuous.
1.2.7. Show that the following function is continuous everywhere:
âƒ—F(u, v) =

x1 sin

1
x2

+ x2 sin

1
x1

,
if x1x2 Ì¸= 0,
0,
if x1x2 = 0.
1.2.8. Find the directional derivative of âƒ—F(s, t) = (s3 âˆ’3st2, 3s2t âˆ’t3) at (2, 3)
in the direction âƒ—u = (1/
âˆš
2, 1/
âˆš
2).
1.2.9. Find the directional derivative of âƒ—F(x1, x2, x3) = (x1 + x2 + x3, x1x2 +
x2x3+x1x3, x1x2x3) at (1, 2, 3) in the direction of âƒ—u = (1/
âˆš
2, 1/
âˆš
3, 1/
âˆš
6).
1.2.10. Let âƒ—F : R2 â†’R2 be deï¬ned by F(u, v) = (u2 âˆ’v2, 2uv). Calculate the
Jacobian matrix of âƒ—F. Find all points in R2 where J(âƒ—F) = 0.
1.2.11. Deï¬ne âƒ—F over R2 by âƒ—F(x, y) = (ex cos y, ex sin y). Calculate the partial
derivatives âƒ—Fx and âƒ—Fy. Show that the Jacobian J(âƒ—F) is never 0. Conclude
that âƒ—Fx and âƒ—Fy are never collinear.
1.2.12. Let âƒ—F(u, v) = (cos u sin v, sin u sin v, cos v) be a function deï¬ned over [0, 2Ï€]
Ã—[0, Ï€]. Show that the image of âƒ—F lies on the unit sphere in R3. Calculate
d âƒ—F(u,v) for all (u, v) in the domain.
1.2.13. Deï¬ne âƒ—F : R3 â†’R3 by
âƒ—F(u, v, w) =

(u3 + uv) cos w, (u3 + uv) sin w, u2
.
Calculate the partial derivatives âƒ—Fx, âƒ—Fy, and âƒ—Fz. Calculate the Jacobian
J(âƒ—F). Determine where âƒ—F does not have maximal rank.

20
1. Analysis of Multivariable Functions
1.2.14. Deï¬ne âƒ—F over the open set {(x, y, z) âˆˆR3 | x > 0, y > 0, z > 0} by
âƒ—F(x, y, z) = (x Â· yz, y Â· zx, z Â· xy). Calculate the partial derivatives âƒ—Fx, âƒ—Fy,
and âƒ—Fz. Calculate the Jacobian J(âƒ—F).
1.2.15. Let F : Rn â†’Rm be a linear function, with F(âƒ—v) = Aâƒ—v for some m Ã— n
matrix A. Prove that the Jacobian matrix is the constant matrix A and
that for all âƒ—a, dFâƒ—a = F.
1.2.16. Let âƒ—F(u, v) = (u cos v, u sin v, u) deï¬ned over R2. Show that the image of
âƒ—F is a cone z =

x2 + y2. Calculate the diï¬€erential, and determine where
the diï¬€erential does not have maximal rank.
1.2.17. Prove Theorem 1.2.7.
1.2.18. Prove Theorem 1.2.13. [Hint: Using Deï¬nition 1.2.12, set âƒ—v = hâƒ—u, where
âƒ—u is a unit vector.]
1.2.19. Prove that if a function âƒ—F is diï¬€erentiable at âƒ—a, then âƒ—F is continuous at âƒ—a.
1.2.20. Mean Value Theorem.
Let F be a real-valued function deï¬ned over an
open set U âˆˆRn and diï¬€erentiable at every point of U. If the segment
[âƒ—a,âƒ—b] âŠ‚U, then there exists a point âƒ—c in the segment [âƒ—a,âƒ—b] such that
F(âƒ—b) âˆ’F(âƒ—a) = dFâƒ—c(âƒ—b âˆ’âƒ—a).
1.2.21. (*) Let n â‰¤m, and consider a function F : U â†’Rm of class C1, where U
is an open set in Rn. Let p âˆˆU, and suppose that dFp is injective.
(a) Prove that there exists a positive real number Ap such that âˆ¥dFp(âƒ—v)âˆ¥
â‰¥Apâˆ¥âƒ—vâˆ¥for âƒ—v âˆˆRn.
(b) Use part (a) and the Mean Value Theorem to show that F is locally
injective near p, i.e., there exists an open neighborhood U â€² of p such
that F : U â€² â†’F(U â€²) is injective.
1.3
Differentiation Rules: Functions of Class Cr
In a single-variable calculus course, one learns a number of diï¬€erentiation
rules. With functions âƒ—F from Rn to Rm, one must use some caution since
the matrix [dâƒ—F] of the diï¬€erential dâƒ—F is not a vector function but a matrix
of functions. (Again, we remind the reader that our notation for evaluating
the matrix of functions [dâƒ—F] at a point âƒ—a is [dâƒ—Fâƒ—a].)
Theorem 1.3.1. Let U be an open set in Rn. Let âƒ—f and âƒ—g be functions from
U to Rm, and let h : U â†’R be a scalar function. If âƒ—f, âƒ—g, and h are
diï¬€erentiable at âƒ—x, then âƒ—f + âƒ—g and hâƒ—f are diï¬€erentiable at âƒ—x and
1. d(âƒ—f + âƒ—g) = dâƒ—f + dâƒ—g;
2. the diï¬€erential d(hâƒ—f) has the matrix [d(hâƒ—f)] = h[dâƒ—f] + [âƒ—f] [dh].

1.3. Differentiation Rules: Functions of Class Cr
21
Note that in Theorem 1.3.1, [âƒ—f] is a column vector of dimension m
while [dh] is a row vector of dimension m, so [âƒ—f] [dh] is an m Ã— n matrix,
as expected.
Example 1.3.2. Let âƒ—f(u, v) = (u2 âˆ’v, v3, u + 2v + 1), and let h(u, v) =
u3 + uv âˆ’2. The diï¬€erentials of âƒ—f and h are

dâƒ—f

=
â›
â
2u
âˆ’1
0
3v2
1
2
â
â 
and
[dh] =
3u2 + v
u
.
According to Theorem 1.3.1, the Jacobian matrix of hâƒ—f is
[d(hâƒ—f)] = h

dâƒ—f

+

âƒ—f

[dh]
= (u3 + uv âˆ’2)
â›
â
2u
âˆ’1
0
3v2
1
2
â
â +
â›
â
u2 âˆ’v
v3
u + 2v + 1
â
â 3u2 + v
u
=
â›
â
2u(u3 + uv âˆ’2)
âˆ’(u3 + uv âˆ’2)
0
3v2(u3 + uv âˆ’2)
(u3 + uv âˆ’2)
2(u3 + uv âˆ’2)
â
â +
â›
â
(u2 âˆ’v)(3u2 + v)
u(u2 âˆ’v)
v3(3u2 + v)
uv3
(u + 2v + 1)(3u2 + v)
u(u + 2v + 1)
â
â 
=
â›
â
5u4 âˆ’v2 âˆ’4u
âˆ’2uv + 2
3u2v4 + v4
3u3v2 + 4uv3 âˆ’6v2
4u3 + 6u2v + 3u2 + 2uv + 2v2 + v âˆ’2
2u3 + u2 + 4uv + u âˆ’4
â
â .
If we had to ï¬nd [d(hâƒ—f)(1,2)], one could simplify the work and do
[d(hâƒ—f)(1,2)] = h(1, 2)

dâƒ—f(1,2)

+

âƒ—f(1, 2)
 
dh(1,2)

= 1
â›
â
2
âˆ’1
0
12
1
2
â
â +
â›
â
âˆ’1
8
6
â
â 5
1
=
â›
â
2
âˆ’1
0
12
1
2
â
â +
â›
â
âˆ’5
âˆ’1
40
8
30
6
â
â =
â›
â
âˆ’3
âˆ’2
40
20
31
8
â
â .
We now consider the composition of two multivariable functions. Let âƒ—f
be a function from a set U âŠ‚Rn to Rm, and let âƒ—g be a function from a set
V âŠ‚Rp to Rn such that âƒ—g(V ) âŠ‚U. The composite function âƒ—fâ—¦âƒ—g : V â†’Rm,
depicted by the diagram
V (âŠ‚Rp)
âƒ—g
 U(âŠ‚Rn)
âƒ—f
 Rm,

22
1. Analysis of Multivariable Functions
is the function such that, for each âƒ—a âˆˆV ,
(âƒ—f â—¦âƒ—g)(âƒ—a) = âƒ—f (âƒ—g(âƒ—a)) .
As a consequence of a general theorem in topology (see Proposition
A.2.30), we know that the composition of two continuous functions is con-
tinuous. The same is true for diï¬€erentiable functions, and the chain rule
tells us how to compute the diï¬€erential of the composition of two functions.
Theorem 1.3.3 (The Chain Rule). Let âƒ—f be a function from an open set U âŠ‚Rn
to Rm, and let âƒ—g be a function from an open set V âŠ‚Rp to Rn such that
âƒ—g(V ) âŠ‚U. Let âƒ—a âˆˆV . If âƒ—g is diï¬€erentiable at âƒ—a and âƒ—f is diï¬€erentiable at
âƒ—g(âƒ—a), then âƒ—f â—¦âƒ—g is diï¬€erentiable at âƒ—a and
d(âƒ—f â—¦âƒ—g)âƒ—a = dâƒ—fâƒ—g(âƒ—a) â—¦dâƒ—gâƒ—a.
(1.2)
The Jacobian matrices satisfy the matrix product

d(âƒ—f â—¦âƒ—g)âƒ—a

=

dâƒ—fâƒ—g(âƒ—a)

[dâƒ—gâƒ—a] .
Before proving this theorem, we establish a lemma.
Lemma 1.3.4. Let A be an m Ã— n matrix. For all âƒ—v âˆˆRn, with âˆ¥âƒ—vâˆ¥= 1, the
length âˆ¥Aâƒ—vâˆ¥is less than or equal to the square root of the largest eigenvalue
Î»1 of AT A. Furthermore, if âƒ—u1 is a unit eigenvector of AT A corresponding
to Î»1, then âˆ¥Aâƒ—u1âˆ¥= âˆšÎ»1.
Proof: Assuming that we use standard bases in Rn and Rm, then
âˆ¥Aâƒ—vâˆ¥2 = (Aâƒ—v) Â· (Aâƒ—v) = (Aâƒ—v)T (Aâƒ—v) = âƒ—vT AT Aâƒ—v.
By the Spectral Theorem from linear algebra, since AT A is a symmetric
matrix, it is diagonalizable, has an orthonormal eigenbasis {âƒ—u1, . . . , âƒ—un},
and all the eigenvalues are real. Assume âƒ—ui has eigenvalue Î»i, and, without
loss of generality, assume that Î»1 â‰¥Î»2 â‰¥Â· Â· Â· â‰¥Î»n. It is also not hard to
conï¬rm that the eigenvalues of AT A are in fact nonnegative. Then if âƒ—v has
unit length, we can write âƒ—v = x1âƒ—u1 + Â· Â· Â· + xnâƒ—un, with x2
1 + Â· Â· Â· + x2
n = 1.
Then
âˆ¥Aâƒ—vâˆ¥2 = âƒ—vT AT Aâƒ—v = Î»1x2
1 + Â· Â· Â· + Î»nx2
n.
A simple calculation using Lagrange multipliers shows that âˆ¥Aâƒ—vâˆ¥2, subject
to the constraint âˆ¥âƒ—vâˆ¥= 1, is maximized when Î» = Î»1 and (x1, . . . , xn) =
(1, 0, . . . , 0). The lemma follows.
â–¡

1.3. Differentiation Rules: Functions of Class Cr
23
We will call âˆšÎ»1 in the above theorem the matrix norm of A and denote
it by |A|. One notices that for all âƒ—v âˆˆRn, âˆ¥Aâƒ—vâˆ¥â‰¤|A| âˆ¥âƒ—vâˆ¥.
Proof (of Theorem 1.3.3): Let âƒ—f and âƒ—g be functions as deï¬ned in the hy-
potheses of the theorem. Then there exist an mÃ—n matrix A and an nÃ—p
matrix B such that
âƒ—g(âƒ—a + âƒ—h) = âƒ—g(âƒ—a) + Bâƒ—h + R1(âƒ—h),
âƒ—f(âƒ—g(âƒ—a) + âƒ—k) = âƒ—f(âƒ—g(âƒ—a)) + Aâƒ—k + R2(âƒ—k),
with
lim
âƒ—hâ†’âƒ—0
R1(âƒ—h)
âˆ¥âƒ—hâˆ¥
= âƒ—0
and
lim
âƒ—kâ†’âƒ—0
R2(âƒ—k)
âˆ¥âƒ—kâˆ¥
= âƒ—0.
(1.3)
Then for the quantity (âƒ—f â—¦âƒ—g)(âƒ—a + âƒ—h), one has
(âƒ—f â—¦âƒ—g)(âƒ—a + âƒ—h) = âƒ—f(âƒ—g(âƒ—a)) + ABâƒ—h + AR1(âƒ—h) + R2(Bâƒ—h + R1(âƒ—h)).
(1.4)
Note that âˆ¥AR1(âƒ—h)âˆ¥â‰¤|A| âˆ¥R1(âƒ—h)âˆ¥, so
lim
âƒ—hâ†’âƒ—0
âˆ¥AR1(âƒ—h)âˆ¥
âˆ¥âƒ—hâˆ¥
â‰¤lim
âƒ—hâ†’âƒ—0
|A| âˆ¥R1(âƒ—h)âˆ¥
âˆ¥âƒ—hâˆ¥
= 0.
Thus,
lim
âƒ—hâ†’âƒ—0
AR1(âƒ—h)
âˆ¥âƒ—hâˆ¥
= âƒ—0.
Now since limâƒ—hâ†’âƒ—0 âˆ¥R1(âƒ—h)âˆ¥/âˆ¥âƒ—hâˆ¥= 0, then for any Îµ > 0, there exists
a Î´ > 0 such that if âƒ—h âˆˆRn, with âˆ¥âƒ—hâˆ¥< Î´, then âˆ¥R1(âƒ—h)âˆ¥< Îµâˆ¥âƒ—hâˆ¥. In
particular, pick Îµ = 1 and let Î´0 be the corresponding value of Î´. Then if
âˆ¥âƒ—hâˆ¥< Î´0, we have
âˆ¥Bâƒ—h + R1(âƒ—h)âˆ¥â‰¤âˆ¥Bâƒ—hâˆ¥+ âˆ¥R1(âƒ—h)âˆ¥â‰¤(|B| + 1)âˆ¥âƒ—hâˆ¥.
This leads to
0 â‰¤âˆ¥R2(Bâƒ—h + R1(âƒ—h))âˆ¥
âˆ¥âƒ—hâˆ¥
â‰¤(|B| + 1)âˆ¥R2(Bâƒ—h + R1(âƒ—h))âˆ¥
âˆ¥Bâƒ—h + R1(âƒ—h)âˆ¥
.
(1.5)
However, by Equation (1.3), one concludes that
lim
âƒ—hâ†’âƒ—0
âˆ¥R2(Bâƒ—h + R1(âƒ—h))âˆ¥
âˆ¥Bâƒ—h + R1(âƒ—h)âˆ¥
= 0

24
1. Analysis of Multivariable Functions
and consequently, by Equation (1.5),
lim
âƒ—hâ†’âƒ—0
âˆ¥R2(Bâƒ—h + R1(âƒ—h))âˆ¥
âˆ¥âƒ—hâˆ¥
= 0.
We have shown that setting R3(âƒ—h) = AR1(âƒ—h) + R2(Bâƒ—h + R1(âƒ—h)), we have
limâƒ—hâ†’âƒ—0 R3(âƒ—h)/âˆ¥âƒ—hâˆ¥= âƒ—0. All parts of the theorem now follow from Equa-
tion (1.4).
â–¡
Example 1.3.5. Consider the following functions: âƒ—f(r, Î¸) = (r cos Î¸, r sin Î¸)
and âƒ—g(s, t) = (s2 âˆ’t2, 2st). Calculating the composition function directly,
we have
(âƒ—g â—¦âƒ—f)(r, Î¸) = (r2 cos2 Î¸ âˆ’r2 sin2 Î¸, 2r2 cos Î¸ sin Î¸) = (r2 cos 2Î¸, r2 sin 2Î¸).
Thus,
[d(âƒ—g â—¦âƒ—f)(r,Î¸)] =
2r cos 2Î¸
âˆ’2r2 sin 2Î¸
2r sin 2Î¸
2r2 cos 2Î¸
	
.
On the other hand, we have
[dâƒ—g(s,t)] =

2s
âˆ’2t
2t
2s
	
and
[dâƒ—f(r,Î¸)] =

cos Î¸
âˆ’r sin Î¸
sin Î¸
r cos Î¸
	
.
Using the right-hand side of the chain rule, we calculate
[dâƒ—g âƒ—f(r,Î¸)] [dâƒ—f(r,Î¸)] = [dâƒ—g(r cos Î¸,r sin Î¸)] [dâƒ—f(r,Î¸)]
=
2r cos Î¸
âˆ’2r sin Î¸
2r sin Î¸
2r cos Î¸
	 cos Î¸
âˆ’r sin Î¸
sin Î¸
r cos Î¸
	
=

2r cos 2Î¸
âˆ’2r2 sin 2Î¸
2r sin 2Î¸
2r2 cos2Î¸
	
= [d(âƒ—g â—¦âƒ—f)(r,Î¸)],
as expected.
The style of presentation of the chain rule in Theorem 1.3.3 is often
attributed to Newtonâ€™s notation.
Possible historical inaccuracies aside,
Equation (1.2) is commonly used by mathematicians. In contrast, physi-
cists tend to use Leibnizâ€™s notation, which we present now.
Suppose that the vector variable âƒ—y = (y1, . . . , yn) is given as a function
of a variable âƒ—x = (x1, . . . , xp) (this function corresponds to âƒ—g in Equa-
tion (1.2)), and suppose that the vector variable âƒ—z = (z1, . . . , zm) is given

1.3. Differentiation Rules: Functions of Class Cr
25
as a function of the variable âƒ—y (this function corresponds to âƒ—f ).
With
Leibnizâ€™s notation, one writes the chain rule as
âˆ‚zi
âˆ‚xj
=
n

k=1
âˆ‚zi
âˆ‚yk
âˆ‚yk
âˆ‚xi
for all i = 1, . . . , m and j = 1, . . . , p.
Implicit in this notation is that when evaluating âˆ‚zi/âˆ‚xj at a point âƒ—a âˆˆRp,
one must calculate
âˆ‚zi
âˆ‚xj

âƒ—a =
n

k=1
âˆ‚zi
âˆ‚yk

âƒ—y(âƒ—a)
âˆ‚yk
âˆ‚xi

âƒ—a.
Suppose a function âƒ—f is diï¬€erentiable over an open set U âŠ‚Rn to
Rm. Then for any unit vector âƒ—u âŠ‚Rn, the directional derivative Dâƒ—u âƒ—f is
itself a vector function from U to Rm, and we can consider the directional
derivative Dâƒ—v(Dâƒ—u âƒ—f) along some unit vector âƒ—v. This second-order directional
derivative is denoted by D2
âƒ—vâƒ—u âƒ—f.
Higher-order directional derivatives are
deï¬ned in the same way.
If Rn is given a basis, then one can take higher-order partial derivatives
with respect to this basis. Some common notations for the second partial
derivative
âˆ‚
âˆ‚xj ( âˆ‚âƒ—f
âˆ‚xi ) are
âˆ‚2 âƒ—f
âˆ‚xjâˆ‚xi
,
âˆ‚jâˆ‚i âƒ—f ,
DjDi âƒ—f ,
âƒ—fxixj ,
âƒ—f,ij
and notations for third partial derivatives are
âˆ‚3 âƒ—f
âˆ‚xkâˆ‚xjâˆ‚xi
,
âˆ‚kâˆ‚jâˆ‚i âƒ—f ,
DkDjDi âƒ—f ,
âƒ—fxixjxk ,
âƒ—f,ijk .
Most advanced physics texts use the notation âˆ‚i âƒ—f for the partial derivative
âˆ‚âƒ—f
âˆ‚xi . In that case, the second and third partial derivatives are âˆ‚jâˆ‚i âƒ—f and
âˆ‚kâˆ‚jâˆ‚i âƒ—f, as indicated above. Of course, if one uses the notation f instead
of âƒ—f to refer to a function from U âŠ‚Rn to Rn, all the above notations
change correspondingly.
Note that the order of the indices or subscripts is important since it is
possible that
âˆ‚2 âƒ—f
âˆ‚x1âˆ‚x2
Ì¸=
âˆ‚2 âƒ—f
âˆ‚x2âˆ‚x1
.
However, this inequality does not happen if both of the second partials are
continuous. (See [14, Theorem 8.24] for a proof of this fact from multivari-
able calculus.)

26
1. Analysis of Multivariable Functions
In general, we say that a function âƒ—f is of class Cr in U if all of its rth
partial derivatives exist and are continuous. More precisely, if we wish to
specify the domain U âŠ‚Rn and the codomain Rm in the notation, we write
âƒ—f âˆˆCr(U, Rm). Finally, we say that âƒ—f is of class Câˆif all of its higher
partial derivatives exist and are continuous.
Problems
1.3.1. Prove Theorem 1.3.1.
1.3.2. Suppose that âƒ—f and âƒ—g are diï¬€erentiable at âƒ—a âˆˆRn. Prove that the function
âƒ—f Â· âƒ—g is diï¬€erentiable at âƒ—a and that
d(âƒ—f Â· âƒ—g)âƒ—a = âƒ—f(âƒ—a) Â· dâƒ—gâƒ—a + âƒ—g(âƒ—a) Â· dâƒ—fâƒ—a
are linear functions.
1.3.3. Let âƒ—f(r, Î¸, Ï†) = (r cos Î¸ sin Ï†, r sin Î¸ sin Ï†, r cos Ï†). Calculate the Jacobian
matrix. Prove that the Jacobian is the function r2 sin Ï†.
1.3.4. Let

z1
= 2y1 + 3y2,
z2
= y1y2
2,
and

y1
= ex1 + x2 + x3,
y2
= ex2âˆ’x3 + x1.
Use the chain rule to calculate the partial derivatives
âˆ‚zi
âˆ‚xj for i = 1, 2 and
j = 1, 2, 3.
1.3.5. Let âƒ—f be a diï¬€erentiable function from an open set U âŠ‚Rn to Rn, and let
âƒ—g be a diï¬€erentiable function from an open set V âŠ‚Rn to U. Prove that
J(âƒ—f â—¦âƒ—g) = J(âƒ—f)J(âƒ—g).
1.3.6. Suppose that U and V are open sets in Rn and that âƒ—F is bijective from
U to V . Suppose in addition that âƒ—F is diï¬€erentiable on U and âƒ—F âˆ’1 is
diï¬€erentiable on V .
Prove that for all âƒ—a âˆˆU, the linear function d âƒ—Fâƒ—a
is invertible and that
(d âƒ—Fâƒ—a)âˆ’1 = dâƒ—F âˆ’1
âƒ—F(âƒ—a).
Conclude that J(âƒ—F âˆ’1) = 1/J(âƒ—F ).
1.3.7. Let âƒ—f be a function from U âŠ‚R2 to R3 such that dâƒ—fâƒ—x has rank 2 for all
âƒ—x âˆˆU. Let âƒ—Î± be a regular curve from an interval I to U. Show that
(a) the function âƒ—Î²(t) = âƒ—f(âƒ—Î±(t)) is a regular curve in R3;
(b) the speed of âƒ—Î² satisï¬es

dâƒ—Î²
dt

2
=

âˆ‚âƒ—f
âˆ‚x1

2  dÎ±1
dt
	2
+2

âˆ‚âƒ—f
âˆ‚x1 Â· âˆ‚âƒ—f
âˆ‚x2

dÎ±1
dt
dÎ±2
dt +

âˆ‚âƒ—f
âˆ‚x2

2 dÎ±2
dt
	2
.

1.4. Inverse and Implicit Function Theorems
27
1.3.8. Repeat part (b) of Problem 1.3.7, but prove that
âˆ¥âƒ—Î²â€²(t)âˆ¥2 = (âƒ—Î±â€²(t))T 
dâƒ—f
T 
dâƒ—f

âƒ—Î±â€²(t).
[Hint: Recall that we view the vectors âƒ—a,âƒ—b âˆˆRn as column vectors and
âƒ—a Â·âƒ—b = âƒ—aTâƒ—b as a matrix product.]
1.3.9. Let âƒ—f(s, t) = (s2t + t3, tes + set), and let âƒ—u be the unit vector in the
direction (1, 1) and âƒ—v be the unit vector in the direction (2, 3). Calculate
the second directional derivative function D2
âƒ—vâƒ—u âƒ—f. [Hint: This is a function
of (s, t).]
1.3.10. Let âƒ—f be a function from an open set U âŠ‚Rn to Rm. Let âƒ—v and âƒ—u be two
unit vectors in Rn. Prove that
D2
âƒ—vâƒ—u âƒ—f =
n

i,j=1
âˆ‚âƒ—f
âˆ‚xiâˆ‚xj viuj.
1.3.11. Let âƒ—f(r, Î¸) = (r cos Î¸, r sin Î¸). Calculate all the second partial derivatives
of âƒ—f. Prove that âƒ—f is of class Câˆover all of R2.
1.3.12. Let âƒ—f(u, v) = (u2 + ve2u, v + tanâˆ’1(u + 3), sin v). Find the domain of âƒ—f.
Calculate all of its second partial derivatives. Calculate the following third
partial derivatives: âƒ—fvvu, âƒ—fvuv, and âƒ—fuuv.
1.3.13. If (w1, w2) = (eâˆ’x1+x2
2, cos(x2 + x3)), calculate
âˆ‚2w1
âˆ‚x1âˆ‚x3 ,
âˆ‚2w1
âˆ‚x3âˆ‚x2 ,
âˆ‚3w2
âˆ‚x1âˆ‚x2âˆ‚x3 .
1.3.14. Let the function f : R2 â†’R be deï¬ned by
f(s, t) =
â§
â¨
â©
2st(s2 âˆ’t2)
s2 + t2
,
if (s, t) Ì¸= (0, 0),
0,
if (s, t) = (0, 0).
Show that f is of class C1. Show that the mixed second partial derivatives
fst and fts exist at every point of R2. Show that fst(0, 0) Ì¸= fts(0, 0).
1.4
Inverse and Implicit Function Theorems
In single-variable and multivariable calculus of a function F : Rn â†’R, one
deï¬nes a critical point as a point âƒ—a = (a1, . . . , an) such that the gradient
of F at âƒ—a is âƒ—0, i.e.,
âˆ‡F(âƒ—a) =
 âˆ‚F
âˆ‚x1
(âƒ—a), . . . , âˆ‚F
âˆ‚x1
(âƒ—a)
	
= âƒ—0.

28
1. Analysis of Multivariable Functions
At such a point, F is said to have a ï¬‚at tangent line or tangent plane, and,
according to standard theorems in calculus, F(âƒ—a) is either a local minimum,
local maximum, or a â€œsaddle point.â€ This notion is a special case of the
following general deï¬nition.
Deï¬nition 1.4.1. Let U be an open subset of Rn, F : U â†’Rm a diï¬€erentiable
function, and q a point in U. We call q a critical point of F if F is not
diï¬€erentiable at q or if dFq : Rn â†’Rm is not of maximum rank, i.e., if
rank dFq < min(m, n). If q is a critical point of F, we call F(q) a critical
value. If p âˆˆRm is not a critical value of F (even if p is not in the image
of F), then we call p a regular value of F.
We point out that this deï¬nition simultaneously generalizes the notion
of a critical point for functions F : U â†’R, with U an open subset of
Rn, and the deï¬nition for a critical point of a parametric curve in Rn [5,
Deï¬nition 3.2.1]. If m = n, the notion of a critical point has a few alternate
equivalent criteria.
Proposition 1.4.2. Let U be an open subset of Rn, F : U â†’Rn a diï¬€eren-
tiable function, and q a point in U such that F is diï¬€erentiable at q. The
following are equivalent:
1. q is a critical point of U.
2. J(F)(q) = 0.
3. The set of partial derivatives { âˆ‚F
âˆ‚x1 (q), . . . , âˆ‚F
âˆ‚xn (q)} is a linearly de-
pendent set of vectors.
4. The diï¬€erential dFq is not invertible.
Proof: These all follow from Theorem 1.1.8.
â–¡
Finally, if n Ì¸= m and both are greater than 1, determining for what
values of q in the domain U the diï¬€erential dFq does not have maximal
rank is not easy if done simply by looking at the matrix of functions [dFq].
The following proposition provides a concise criterion.
Proposition 1.4.3. Let F : U â†’Rm be a function where U is an open subset
of Rn, with n Ì¸= m. Let q âˆˆU such that F is diï¬€erentiable at q, and call
A the Jacobian matrix [dFq] at q. Then the following are equivalent:

1.4. Inverse and Implicit Function Theorems
29
1. q is a critical point of U.
2. The determinants of all the maximal square submatrices of A are 0.
3. The sum of the squares of the determinants of all the maximal square
submatrices of A is 0.
Furthermore, if n > m, then q is a critical point of U if and only if
det(AAT ) Ì¸= 0.
Proof: To prove 1 â†”2, note that by deï¬nition, q is a critical point if dFq
does not have maximal rank, which means that the set of column vectors
or the set of row vectors of [dFq] is linearly dependent. This is equivalent
to the determinants of all maximal submatrices of A (sometimes referred
to as the maximal minors of A) being 0 since, if one such determinant
were not 0, then no nontrivial linear combination of the columns of [dFq]
or of the rows of [dFq] would be 0, and hence, this set would be linearly
independent.
The equivalence 2 â†”3 is trivial.
To prove the last part of the proposition, assuming that n > m, recall
that if {âƒ—v1, . . . ,âƒ—vm} are vectors in Rn, the m-volume of the parallelepiped
formed by {âƒ—v1, . . . ,âƒ—vm} is

det(BT B),
where B is the n Ã— m matrix, with the âƒ—vi as columns (see [13, Fact 6.3.7]).
Now the m-volume of this parallelepiped is 0 if and only if {âƒ—v1, . . . ,âƒ—vm} are
linearly dependent. Thus, taking B = AT and taking the âƒ—vi as the columns
of AT establishes the result.
â–¡
By referring to some advanced linear algebra, it is possible to prove
directly that, if n > m, Condition 3 in the above proposition implies that
det(AAT ) Ì¸= 0. In fact, even more can be said. If A is an mÃ—n matrix with
n > m, then det(AAT ) is equal to the sum of the squares of the maximal
minors of A. (See Proposition C.6.2 in Appendix C for a proof of this fact.)
Example 1.4.4. For example, consider the function F : R3 â†’R2 deï¬ned
by F(x, y, z) = (x2 + 3y + z3, xy + z2 + 1). The Jacobian matrix for this
function is
[dF] =
2x
3
3z2
y
x
2z
	
.
In this case, the easiest way to ï¬nd the critical points of this function is to
use the second equivalence statement in Proposition 1.4.3. The maximal

30
1. Analysis of Multivariable Functions
2 Ã— 2 submatrices are
2x
3
y
x
	
,
2x
3z2
y
2z
	
,
3
3z2
x
2z
	
,
so since critical points occur where all of these have determinant 0, the
critical points satisfy the system of equations
â§
âª
â¨
âª
â©
2x2 âˆ’3y = 0,
4xz âˆ’3yz2 = 0,
6z âˆ’3xz2 = 0.
This is equivalent to
â§
âª
â¨
âª
â©
y = 2
3x2,
4xz âˆ’2x2z2 = 0,
z(2 âˆ’xz) = 0,
â‡â‡’
â§
âª
â¨
âª
â©
y = 2
3x2,
xz(2 âˆ’xz) = 0,
z(2 âˆ’xz) = 0.
Thus, the set of critical points of F is

x, 2
3x2, 2
x
	
âˆˆR3  x âˆˆR âˆ’{0}
 
âˆª

x, 2
3x2, 0
	
âˆˆR3  x âˆˆR
 
.
The set of critical values is then

3x2 + 8
x3 , 2
3x3 + 4
x2 + 1
	
âˆˆR2  x âˆˆR âˆ’{0}
 
âˆª

3x2, 2
3x3 + 1
	
âˆˆR2  x âˆˆR
 
.
One important aspect of critical points already arises with real func-
tions. With a real diï¬€erentiable function f : [a, b] â†’R, if f â€²(x0) = 0, one
can show that f does not have an inverse function that is diï¬€erentiable
over a neighborhood of x0. Conversely, if f â€²(x0) Ì¸= 0, the function f has a
diï¬€erentiable inverse in a neighborhood of x0, with
(f âˆ’1)â€²(y0) =
1
f â€²(f âˆ’1(y0)).
A similar fact holds for multivariable functions and is called the Inverse
Function Theorem.
The proof of the Inverse Function Theorem and the following Implicit
Function Theorem are quite long and not necessary for the purposes of
this book, so we refer the reader to a book on analysis for a proof (see,
for example, [14, Section 8.5]). Instead, we simply state the theorems and
present a few examples.

1.4. Inverse and Implicit Function Theorems
31
Theorem 1.4.5 (Inverse Function Theorem). Let F be a function from an open
set U âŠ‚Rn to Rn, and suppose that F is of class Cr, with r â‰¥1. If
q âˆˆU is not a critical point of F, then dFq is invertible and there exists
a neighborhood V of q such that F is one-to-one on V , F(V ) is open, and
the inverse function F âˆ’1 : F(V ) â†’V is of class Cr. Furthermore, for all
p âˆˆF(V ), with p = F(q),
d(F âˆ’1)p = (dFq)âˆ’1.
Example 1.4.6. Consider the function F(s, t) = (s2 âˆ’t2, 2st) and q = (2, 3).
Note that F is deï¬ned on all U = R2. The Jacobian matrix is
2s
âˆ’2t
2t
2s
	
,
and thus, the Jacobian is the function J(F)(s, t) = 4(s2 + t2). By Propo-
sition 1.4.2, the only critical point of F is (0, 0), so F satisï¬es the condi-
tions of the Inverse Function Theorem at q. For simplicity, letâ€™s assume
V = {(s, t) âˆˆR2 | s > 0, t > 0}. We set (x, y) = F(s, t), solve for (s, t), and
ï¬nd that F(V ) = {(x, y) âˆˆR2 | y > 0} and the inverse of F is given by
s =
!
x2 + y2 + x
2
and
t =
!
x2 + y2 âˆ’x
2
.
Calculating the partial derivative âˆ‚s/âˆ‚x, we have
âˆ‚s
âˆ‚x =
1
2
âˆš
2

x2 + y2 + x

x

x2 + y2 + 1

=
1
2

x2 + y2
!
x2 + y2 + x
2
,
and similarly, the Jacobian matrix of F âˆ’1 is

dF âˆ’1
=
â›
âœ
âœ
â
1
2âˆš
x2+y2
âˆš
x2+y2+x
2
1
2âˆš
x2+y2
âˆš
x2+y2âˆ’x
2
âˆ’
1
2âˆš
x2+y2
âˆš
x2+y2âˆ’x
2
1
2âˆš
x2+y2
âˆš
x2+y2+x
2
â
âŸ
âŸ
â .
(1.6)
Now with q = (2, 3), we have F(q) = (âˆ’5, 12) and
[dFq] =
4
âˆ’6
6
4
	
and
[dFq]âˆ’1 = 1
26
 2
3
âˆ’3
2
	
.

32
1. Analysis of Multivariable Functions
Furthermore, using Equation (1.6), we calculate directly that

dF âˆ’1
F (q)

=
1
2

(âˆ’5)2 + 122
â›
â
âˆš
(âˆ’5)2+122âˆ’5
2
âˆš
(âˆ’5)2+122+5
2
âˆ’
âˆš
(âˆ’5)2+122+5
2
âˆš
(âˆ’5)2+122âˆ’5
2
â
â 
= 1
26
 2
3
âˆ’3
2
	
.
Hence, [dFq]âˆ’1 =[dF âˆ’1
F (q)], thus illustrating the Inverse Function Theorem.
Another important theorem about functions in the neighborhood of a
point p that is not critical, is the fact that the level set through p can
be parametrized by (is the image of) an appropriate function. This is the
Implicit Function Theorem.
Theorem 1.4.7 (Implicit Function Theorem). Let F be a function from an open
set U âŠ‚Rn to Rm, with n > m, and suppose that F is of class Cr, with
r â‰¥1. Let q âˆˆU, and let Î£ be the level surface of F through q, deï¬ned as
Î£ = {âƒ—x âˆˆRn | F(âƒ—x) = F(p)}.
If q âˆˆU is not a critical point, then the coordinates of Rn can be relabeled
so that
nâˆ’m
m
dFq =

S

T

m,
with T an m Ã— m invertible matrix. Then there exist an open neighborhood
V of q in Rn, an open neighborhood W of a = (q1, . . . , qnâˆ’m) in Rnâˆ’m,
and a function g : W â†’Rm that is of class Cr such that Î£âˆ©V is the graph
of g, i.e.,
Î£ âˆ©V = {(âƒ—s, g(âƒ—s)) |âƒ—s âˆˆW}.
Furthermore, the Jacobian matrix of g at a is
[dga] = âˆ’T âˆ’1S.
Example 1.4.8. We use the Implicit Function Theorem to tell us something
about the set
Î£ = {(x, y, z) âˆˆR3 | x2 + y2 + z2 = 1 and x + y + z = 1}.
This is the intersection between a sphere and a plane, which is a circle
lying in R3. (In Figure 1.5, Î£ is the circle shown as the intersection of

1.4. Inverse and Implicit Function Theorems
33
Figure 1.5. Example 1.4.8.
the sphere and the plane.) Consider the point q = ( 4
13, âˆ’3
13, 12
13) âˆˆÎ£. To
study Î£ near q, consider the function F : R3 â†’R2 deï¬ned by F(x, y, z) =
(x2 + y2 + z2, x + y + z). The Jacobian matrix of F is
[dF] =

2x
2y
2z
1
1
1
	
,
and so the critical points of F are points (x, y, z) âˆˆR3 such that x = y = z.
Thus, q is not a critical point and
[dFq] =
 8
13
âˆ’6
13
24
13
1
1
1
	
.
Writing
S =
 8
13
1
	
and
T =
âˆ’6
13
24
13
1
1
	
,
since T is invertible, F and q satisfy the criteria of the Implicit Function
Theorem. Thus, there exist an open neighborhood V of q in R3, an open
interval W around a =
4
13 in R, and a function g : W â†’R2 such that the
portion of the circle Î£ âˆ©V is the graph of g. Also, the Jacobian matrix of
g at a (the gradient of g at a) is
dga = âƒ—âˆ‡g
 4
13
	
= âˆ’T âˆ’1S = âˆ’

âˆ’13
30
24
30
13
30
6
30
  8
13
1
	
=

âˆ’8
15
âˆ’7
15

.
(1.7)

34
1. Analysis of Multivariable Functions
One can ï¬nd Î£ by ï¬rst noting that the subspace x + y + z = 0 has
{(0, âˆ’1, 1), (âˆ’2, 1, 1)} as an orthogonal basis. Thus, the plane x+y+z = 1
can be parametrized by
âƒ—X(u, v) =
1
3, 1
3, 1
3
	
+ u(0, âˆ’1, 1) + v(âˆ’2, 1, 1),
and all vectors in this expression are orthogonal to each other. The addi-
tional condition that x2 + y2 + z2 = 1 be equivalent to âƒ—X Â· âƒ—X = 1 leads to
2u2 + 6v2 = 2
3. This shows that the set Î£ can be parametrized by
â§
âª
âª
â¨
âª
âª
â©
x
= 1
3 âˆ’2
3 sin t,
y
= 1
3 âˆ’
1
âˆš
3 cos t + 1
3 sin t,
z
= 1
3 +
1
âˆš
3 cos t + 1
3 sin t.
However, this parametrization is not the one described by the Implicit
Function Theorem. But by using it, one can ï¬nd that in a neighborhood
of q = ( 4
13, âˆ’3
13, 12
13), Î£ is parametrized by

x, 1 âˆ’x
2
âˆ’1
2

1 + 2x âˆ’3x2, 1 âˆ’x
2
+ 1
2

1 + 2x âˆ’3x2
	
,
and thus the implicit function g in Theorem 1.4.7 is
g(x) =
1 âˆ’x
2
âˆ’1
2

1 + 2x âˆ’3x2, 1 âˆ’x
2
+ 1
2

1 + 2x âˆ’3x2
	
.
From here it is not diï¬ƒcult to verify Equation (1.7) directly.
Example 1.4.8 illustrates the use of the Implicit Function Theorem.
However, though the theorem establishes the existence of the implicit func-
tion g and provides a method to calculate [dga], the theorem provides no
method to calculate the function g. In fact, unlike in Example 1.4.8, in
most cases, one cannot calculate g with elementary functions.
Problems
1.4.1. Find the critical points of the following R â†’R functions: (a) f(x) = x3,
(b) g(x) = sin x, and (c) h(x) = x3 âˆ’3x2 + x + 1.
1.4.2. Find all the critical points of the function F(x, y) = (x3 âˆ’xy + y2, x2 âˆ’y)
deï¬ned over all R2.
1.4.3. Let F : R3 â†’R3 be deï¬ned by F(x, y, z) = (z2âˆ’xy, x3âˆ’3xyz, x2+y2+z2).

1.4. Inverse and Implicit Function Theorems
35
(a) Find an equation describing the critical points of this function. (If
you have access to a computer algebra system, plot it.)
(b) Prove that if (x0, y0, z0) is a critical point of F, then any point
(Î»x0, Î»y0, Î»z0), with Î» âˆˆR, is also a critical point.
(That is, if
(x0, y0, z0) is a critical point, then any point on the line through
(0, 0, 0) and (x0, y0, z0) is also critical. We say that the equation for
the critical points is a homogeneous equation.)
1.4.4. Let F : R3 â†’R2 be deï¬ned by F(x, y, z) = (exy, z cos x). Find all the
critical points of F.
1.4.5. Consider the function f : R3 â†’R3 deï¬ned by
f(x1, x2, x3) = (x1 cos x2 sin x3, x1 sin x2 sin x3, x1 cos x3).
Find the critical points and the critical values of f.
1.4.6. Let F : R2 â†’R2 be the function deï¬ned by F(s, t) = (s3 âˆ’3st2, 3s2tâˆ’t3),
and let q = (2, 3). Find the critical points of F. Prove that there exists a
neighborhood V of q such that F is one-to-one on V so that F âˆ’1 : F(V ) â†’
V exists. Let p = F(q) = (âˆ’46, 9). Find d(F âˆ’1)(âˆ’46,9).
1.4.7. Let âƒ—F : R2 â†’R2 be deï¬ned by âƒ—F(x, y) = (y2 sin x+1, (x+2y)cos y). Show
that (0, Ï€/2) is not a critical point of âƒ—F. Show that âƒ—F is a bijection from
a neighborhood U of (0, Ï€/2) to a neighborhood V of (1, 0). If âƒ—G : V â†’U
is the inverse function âƒ—G = âƒ—F âˆ’1, then ï¬nd the matrix of d âƒ—G(1,0).
1.4.8. Consider the function
âƒ—f(x1, x2, x3) =

x2 + x3
1 + x1 + x2 + x3 ,
x1 + x3
1 + x1 + x2 + x3 ,
x1 + x2
1 + x1 + x2 + x3
	
deï¬ned over the domain U = R3 âˆ’{(x1, x2, x3) | 1 + x1 + x2 + x3 = 0}.
(a) Show that no point in the domain of âƒ—f is a critical point. [Hint:
Prove that J(âƒ—f) = 2/(1 + x1 + x2 + x3)4.]
(b) Prove that âƒ—f is injective.
(c) Find [dâƒ—f âˆ’1] in terms of (x1, x2, x3) at every point using the Implicit
Function Theorem.
(d) Show that the inverse function is
âƒ—f âˆ’1(y1, y2, y3) =
 âˆ’y1 + y2 + y3
2 âˆ’y1 âˆ’y2 âˆ’y3 ,
y1 âˆ’y2 + y3
2 âˆ’y1 âˆ’y2 âˆ’y3 ,
y1 + y2 âˆ’y3
2 âˆ’y1 âˆ’y2 âˆ’y3
	
.
(e) Prove that âƒ—f is a bijection between
U = R3 âˆ’{(x1, x2, x3) | 1 + x1 + x2 + x3 = 0}
and
V = R3 âˆ’{(x1, x2, x3) | 2 âˆ’x1 âˆ’x2 âˆ’x3 = 0}.
1.4.9. Verify all the calculations of Example 1.4.8.


CHAPTER
2
Coordinates, Frames,
and Tensor Notation
The strategy of choosing a particular coordinate system or frame to perform
a calculation or to present a concept is ubiquitous in both mathematics and
physics. For example, Newtonâ€™s equations of planetary motion are much
easier to solve in polar coordinates than in Cartesian coordinates. In the
diï¬€erential geometry of curves, calculations of local properties are often
simpler when carried out in the Frenet frame associated to the curve at a
point. This chapter introduces general coordinate systems on Rn and the
concept of variable frames in a consistent and general manner. With a solid
foundation of coordinate systems, we conclude the chapter by introducing
tensor notation in what one might call the physics style or the classical
style.
2.1
Curvilinear Coordinates
Many problems in introductory mechanics involve ï¬nding the trajectory of
a particle under the inï¬‚uence of various forces and/or subject to certain
constraints. The ï¬rst approach uses the coordinate functions and describes
the trajectory as
âƒ—r(t) = (x(t), y(t), z(t)) = x(t)âƒ—i + y(t)âƒ—j + z(t)âƒ—k.
Newtonâ€™s equations of motion then lead to diï¬€erential equations in the
three coordinate functions x(t), y(t), and z(t).
We point out that
d
dtâƒ—i = 0,
d
dtâƒ—j = 0, and
d
dtâƒ—k = 0. Following the presen-
tation we used to describe how the Frenet frame behaves under derivatives,
we write
d
dt

âƒ—i
âƒ—j
âƒ—k

=

âƒ—i
âƒ—j
âƒ—k

â›
â
0
0
0
0
0
0
0
0
0
â
â ,
37

38
2. Coordinates, Frames, and Tensor Notation
where, as in linear algebra, we view the vectors as columns. This remark
appears trivial but it will become important as we study the behavior of
frames associated to other natural coordinate systems. Alternate coordi-
nate frames are important because when a particle is under the inï¬‚uence
of a force (radial, for example) or is bound by certain constraints, cylindri-
cal or spherical coordinates oï¬€er a simpler description for the equations of
motion.
With cylindrical coordinates (Figure 2.1(a)), one locates a point in R3
using the distance r between the origin and the projection of the point
onto the xy-plane, the angle Î¸ from the positive x-axis, and the height z
above the xy-plane. We have the following relationship between Cartesian
coordinates and cylindrical coordinates:
â§
âª
â¨
âª
â©
x = r cos Î¸,
y = r sin Î¸,
z = z,
â†â†’
â§
âª
â¨
âª
â©
r =

x2 + y2,
Î¸ = tanâˆ’1  y
x

,
z = z.
Of course, by the expression tanâˆ’1(y/x), one must understand that we
assume that x > 0. For x â‰¤0, one must adjust the formula to obtain the
appropriate corresponding angle. Using cylindrical coordinates, one would
locate a point in space by
âƒ—r = (r cos Î¸, r sin Î¸, z).
We deï¬ne the natural frame with respect to this coordinate system
as follows. To each independent variable in the coordinate system, one
associates the unit vector that corresponds to the directions of change with
respect to that variable. For example, with cylindrical coordinates, we have
the following three unit vectors:
âƒ—er =
âˆ‚âƒ—r
âˆ‚r

âˆ‚âƒ—r
âˆ‚r

,
âƒ—eÎ¸ =
âˆ‚âƒ—r
âˆ‚Î¸

âˆ‚âƒ—r
âˆ‚Î¸

,
âƒ—ez =
âˆ‚âƒ—r
âˆ‚z

âˆ‚âƒ—r
âˆ‚z

.
(2.1)
To get explicit descriptions of these unit vectors, we merely compute the
above formulas to get
âƒ—er = (cos Î¸, sin Î¸, 0) = cos Î¸âƒ—i + sin Î¸âƒ—j,
âƒ—eÎ¸ = (âˆ’sin Î¸, cos Î¸, 0) = âˆ’sin Î¸âƒ—i + cos Î¸âƒ—j,
(2.2)
âƒ—ez = (0, 0, 1) = âƒ—k.

2.1. Curvilinear Coordinates
39
Of course, we are using the Cartesian frame (âƒ—i,âƒ—j,âƒ—k) to describe this new
basis that corresponds to cylindrical coordinates. As opposed to the ï¬xed
frame (âƒ—i,âƒ—j,âƒ—k), the frames associated to non-Cartesian coordinates depend
on the coordinates of the base point p of the frame.
Thus, the frame
(âƒ—er,âƒ—eÎ¸,âƒ—ez) associated to cylindrical coordinates depends explicitly on the
coordinates (r, Î¸, z) (in this case, only on Î¸) of the frameâ€™s origin point.
We apply this treatment of frames associated to non-Cartesian coor-
dinate systems to space curves. Consider a space curve parametrized by
âƒ—r : I â†’R3, where I is an interval of R. We can attach the frame (âƒ—er,âƒ—eÎ¸,âƒ—ez)
to each point âƒ—r(t) of the curve, but, unlike with the ï¬xed Cartesian frame,
the frame (âƒ—er,âƒ—eÎ¸,âƒ—ez) is not constant. As one rephrases equations of mo-
tion in the new coordinate system, one is led to take higher derivatives
of âƒ—r(t) and express them with components in the frame associated to the
particular coordinate system.
Using cylindrical coordinates, a point is located by
âƒ—r = râƒ—er + zâƒ—ez,
and if one considers a curve in cylindrical coordinates, r, Î¸, and z are
functions of time t. Therefore, taking the derivative with respect to time
t, we get
âƒ—r â€² = râ€²âƒ—er + r d
dtâƒ—er + zâ€²âƒ—ez + z d
dtâƒ—ez.
Thus, in order to write equations of motion in cylindrical coordinates, one
must determine
d
dtâƒ—er,
d
dtâƒ—eÎ¸, and
d
dtâƒ—ez. One obtains
âƒ—e â€²
r = d
dt(cos Î¸, sin Î¸, 0) = (âˆ’Î¸â€² sin Î¸, Î¸â€² cos Î¸, 0) = Î¸â€²âƒ—eÎ¸,
âƒ—e â€²
Î¸ = d
dt(âˆ’sin Î¸, cos Î¸, 0) = (âˆ’Î¸â€² cos Î¸, âˆ’Î¸â€² sin Î¸, 0) = âˆ’Î¸â€²âƒ—er,
âƒ—e â€²
z = d
dt(0, 0, 1) = âƒ—0.
Following the same method of presenting the change in the Frenet frame,
we can write
d
dt
âƒ—er
âƒ—eÎ¸
âƒ—ez

=
âƒ—er
âƒ—eÎ¸
âƒ—ez

â›
â
0
âˆ’Î¸â€²
0
Î¸â€²
0
0
0
0
0
â
â .

40
2. Coordinates, Frames, and Tensor Notation
x
y
z
Î¸
r
z
(a) Cylindrical coordinates
x
y
z
Î¸
Ï• Ï
(b) Spherical coordinates
Figure 2.1. Cylindrical and spherical coordinates.
One can now write, for the velocity vector and acceleration vector,
âƒ—r â€² = râ€²âƒ—er + rÎ¸â€²âƒ—eÎ¸ + zâ€²âƒ—ez,
âƒ—r â€²â€² = râ€²â€²âƒ—er + râ€²Î¸â€²âƒ—eÎ¸ + râ€²Î¸â€²âƒ—eÎ¸ + rÎ¸â€²â€²âƒ—eÎ¸ + r(Î¸â€²)2(âˆ’âƒ—er) + zâ€²â€²âƒ—ez
=

râ€²â€² âˆ’r(Î¸â€²)2
âƒ—er + (2râ€²Î¸â€² + rÎ¸â€²â€²)âƒ—eÎ¸ + zâ€²â€²âƒ—ez.
If we restrict ourselves to polar coordinates, the above formula would still
hold but with no z-component. In the study of trajectories in the plane,
the ï¬rst four terms in the last expression have particular names (see [21,
Section 5.2]). One calls
râ€²â€²âƒ—er the radial acceleration,
âˆ’r(Î¸â€²)2âƒ—er the centripetal acceleration,
2râ€²Î¸â€²âƒ—eÎ¸ the Coriolis acceleration, and
rÎ¸â€²â€²âƒ—eÎ¸ the component due to angular acceleration.
For spherical coordinates (Figure 2.1(b)), we merely need to repeat the
constructions for cylindrical coordinates, only beginning with the appro-
priate relationship between Cartesian and spherical coordinate systems.
Using spherical coordinates, one locates a point P in R3 as follows. Let
P â€² be the projection of P onto the xy-plane. Use the distance from the
origin Ï = OP, longitude Î¸ (i.e., the angle from the positive x-axis to the

2.1. Curvilinear Coordinates
41
ray [OP â€²)), and the angle Ï•, which is the angle between the positive z-axis
and the ray [OP). We have the following relationship between Cartesian
coordinates and cylindrical coordinates:
â§
âª
â¨
âª
â©
x = Ï cosÎ¸ sin Ï•,
y = Ï sin Î¸ sin Ï•,
z = Ï cos Ï•,
â†â†’
â§
âª
âª
âª
â¨
âª
âª
âª
â©
Ï =

x2 + y2 + z2,
Î¸ = tanâˆ’1  y
x

,
Ï• = cosâˆ’1

z
âˆš
x2+y2+z2
	
,
(2.3)
with the same caveat for Î¸ as discussed with cylindrical coordinates.
It becomes a simple exercise to determine the natural frame for the
spherical coordinate system as
âƒ—eÏ = (cos Î¸ sin Ï•, sin Î¸ sin Ï•, cos Ï•),
âƒ—eÎ¸ = (âˆ’sin Î¸, cos Î¸, 0),
âƒ—eÏ• = (cos Î¸ cos Ï•, sin Î¸ cos Ï•, âˆ’sin Ï•).
Furthermore, if âƒ—r : I â†’R3 is a parametric curve in R3, we can determine
the rate of change of the spherical frame along that curve as
d
dt

âƒ—eÏ
âƒ—eÎ¸
âƒ—eÏ•

=

âƒ—eÏ
âƒ—eÎ¸
âƒ—eÏ•

â›
â
0
âˆ’Î¸â€² sin Ï•
âˆ’Ï•â€²
Î¸â€² sin Ï•
0
Î¸â€² cos Ï•
Ï•â€²
âˆ’Î¸â€² cos Ï•
0
â
â .
(2.4)
All the coordinate systems we have considered thus far, though curvi-
linear, are examples of orthogonal coordinate systems, that is to say, the
basis vectors we associate to the coordinate system are mutually perpen-
dicular. In general, this is not the case. We point out that, as shown in
Equation (2.2), both mathematicians and physicists make the traditional
choice when they impose that the frames associated to the cylindrical and
spherical coordinate systems be composed of unit vectors. As useful as this
is for calculations involving distances or angles, this choice has considerable
drawbacks in general. Consequently, in what follows, we do not make this
imposition but show how we must change the formula for distances.
We now consider general coordinate systems in Rn.
Let S be an open set in Rn. A continuous surjective function f : U â†’S,
where U is an open set in Rn, deï¬nes a coordinate system on S by associ-
ating to every point P âˆˆS an n-tuple x(P) = (x1(P), x2(P), Â· Â· Â· , xn(P))
such that f(x(P)) = P. In this notation, the superscripts do not indicate
powers of a variable x but the ith coordinate for that point in the given
coordinate system. Though a possible source of confusion at ï¬rst, diï¬€er-
ential geometry literature uses superscripts instead of the usual subscripts

42
2. Coordinates, Frames, and Tensor Notation
in order to mesh properly with subsequent tensor notation. One should be
aware that, as with polar coordinates where (r0, Î¸0) and (r0, Î¸0 + 2Ï€) cor-
respond to the same point in the plane, the n-tuple need not be uniquely
associated to the point P.
Let (x1, x2, . . . , xn) be a coordinate system in Rn. Now Rn is a vector
space, and we can talk about position vectors of points in Rn. To say that
the n-tuple (x1, x2, . . . , xn) gives coordinates of a point p means that p
has a position vector âƒ—r that is a function of (x1, x2, . . . , xn). For a general
system of coordinates, the associated basis of Rn at p is the set of vectors
 âˆ‚âƒ—r
âˆ‚x1

p, âˆ‚âƒ—r
âˆ‚x2

p, . . . , âˆ‚âƒ—r
âˆ‚xn

p
 
.
(2.5)
If there is no cause for confusion, one often drops the |p but understands
from context that the derivatives are evaluated at a given point p. We say
that the components of a vector âƒ—A at p in this system of coordinates are
âƒ—A = (A1, A2, . . . , An) if we can write
âƒ—A =
n

i=1
Ai
âˆ‚âƒ—r
âˆ‚xi
.
In this general setup, one must note that, in general,
âˆ¥âƒ—Aâˆ¥2 Ì¸= A2
1 + A2
2 + Â· Â· Â· + A2
n.
The usual length formula no longer holds precisely because the basis vectors
âˆ‚âƒ—r
âˆ‚xi are no longer orthonormal. However, if âƒ—B = (B1, . . . , Bn) is another
vector given in the basis associated to the coordinate system at p, then
âƒ—A Â· âƒ—B =
n

i=1
n

j=1
AiBj
âˆ‚âƒ—r
âˆ‚xi
Â· âˆ‚âƒ—r
âˆ‚xj
.
(2.6)
The coeï¬ƒcients
âˆ‚âƒ—r
âˆ‚xi Â·
âˆ‚âƒ—r
âˆ‚xj depend only on p and not on the vectors âƒ—A and
âƒ—B, and since
âˆ‚âƒ—r
âˆ‚xi
Â· âˆ‚âƒ—r
âˆ‚xj
= âˆ‚âƒ—r
âˆ‚xj
Â· âˆ‚âƒ—r
âˆ‚xi
,
Equation (2.6) is a symmetric bilinear form. We can now use this to calcu-
late lengths of vectors and angles between vectors using their components
in the basis associated to the coordinate system. Though Equation (2.6)
may seem unpleasant, we point out that this formula for calculating dis-
tances meshes perfectly with the formalism of the so-called metric tensor,
which we introduced in Section 6.1 in [5].

2.1. Curvilinear Coordinates
43
x
y
z
P
Figure 2.2. Coordinate planes for parabolic coordinates.
To try to tie together this correct presentation of bases associated to
a general coordinate system with the tradition shown for cylindrical and
spherical coordinates, some authors (e.g., [35, p. 9]) say, for example, that
spherical coordinates (r, Î¸, Ï•) have scale factors of (1, r sin Ï•, r). By this,
such authors mean that a vector âƒ—A based at a point p has components
âƒ—A = (A1, A2, A3) if
âƒ—A = A1 âƒ—er + A2r sin Ï•âƒ—eÎ¸ + A3r âƒ—eÏ•.
Problems
2.1.1. Prove Equation (2.4) for the rate of change of the spherical coordinates
frame.
2.1.2. Calculate âƒ—r â€² and âƒ—r â€²â€² in terms of functions of spherical coordinates.
2.1.3. The parabolic coordinates system of R3 consists of the triple (u, v, Î¸), with
u âˆˆ[0, +âˆ), v âˆˆ[0, +âˆ), and Î¸ âˆˆ[0, 2Ï€) with equations
â§
âª
â¨
âª
â©
x = uv cos Î¸,
y = uv sin Î¸,
z = 1
2(u2 âˆ’v2).
Figure 2.2 shows the three coordinate â€œplanesâ€ for parabolic coordinates
in R3 passing through the point P âˆˆR3 with coordinates (u, v, Î¸) =
(1, 1/2, Ï€/4).

44
2. Coordinates, Frames, and Tensor Notation
(a) Find the rate of change of coordinate functions that go from Carte-
sian coordinates to parabolic coordinates.
(b) Find the basis vectors for the associated frame according to Equa-
tion (2.5).
(c) Consider also the basis {âƒ—eu,âƒ—ev,âƒ—eÎ¸} that involves unit vectors using
Equation (2.1). Calculate the rate of change matrix for this frame.
2.1.4. Consider the coordinate system on R2 that employs the pair (r, Î±) âˆˆ
[0, +âˆ) Ã— [0, 2Ï€) to represent the point on the ellipse
x2
4 + y2 = r2
that lies on the ray that comes out of the origin and goes through (cos Î±,
sin Î±).
(a) Determine change of coordinate system equations from and to Carte-
sian coordinates.
(b) Find the set B of basis vectors for the associated frame according to
Equation (2.5).
(c) Calculate the rate of change matrix associated to this frame B.
2.2
Moving Frames in Physics
In many instances in physics, it is convenient to use a frame that is diï¬€erent
from the Cartesian frame.
Changing types of frames sometimes makes
diï¬ƒcult integrals tractable or makes certain diï¬ƒcult diï¬€erential equations
manageable.
In Chapter 1 in [5], we used the {âƒ—T, âƒ—U} frame to study the local prop-
erties of a plane curve âƒ—x(t). The vector âƒ—T (t) is the unit tangent vector
âƒ—T(t) = âƒ—xâ€²(t)/âˆ¥âƒ—xâ€²(t)âˆ¥, and the unit normal vector âƒ—U(t), is the result of
rotating âƒ—T(t) by Ï€/2 in a counterclockwise direction.
This is a moving
frame that is deï¬ned in terms of a given regular curve âƒ—x(t) and, at t = t0,
is viewed as based at the point âƒ—x(t0). To compare with applications in
physics, it is important to note that the {âƒ—T, âƒ—U} frame is not the same as
the polar coordinate frame {âƒ—er,âƒ—eÎ¸}. From Equation (2.2) (and ignoring the
z-component), we know that
âƒ—er = (cos Î¸, sin Î¸)
and
âƒ—eÎ¸ = (âˆ’sin Î¸, cos Î¸).
Assuming that x, y, r, and Î¸ are functions of t and since x = r cos Î¸ and
y = r sin Î¸, we have
âƒ—x â€²(t) = (xâ€²(t), yâ€²(t)) = (râ€² cos Î¸ âˆ’rÎ¸â€² sin Î¸, râ€² sin Î¸ + rÎ¸â€² cos Î¸) = râ€²âƒ—er + rÎ¸â€²âƒ—eÎ¸.

2.2. Moving Frames in Physics
45
We then calculate the speed function to be
sâ€²(t) = âˆ¥âƒ—xâ€²(t)âˆ¥=

(râ€²)2 + r2(Î¸â€²)2
and ï¬nd the unit tangent and unit normal vectors to be
âƒ—T =
1

(râ€²)2 + r2(Î¸â€²)2 (râ€²âƒ—er + rÎ¸â€²âƒ—eÎ¸) ,
âƒ—U =
1

(râ€²)2 + r2(Î¸â€²)2 (âˆ’rÎ¸â€²âƒ—er + râ€²âƒ—eÎ¸) .
Therefore, the orthogonal matrix
1

(râ€²)2 + r2(Î¸â€²)2
 râ€²
âˆ’rÎ¸â€²
rÎ¸â€²
râ€²
	
is the transition matrix between the {âƒ—T, âƒ—U} basis and the {âƒ—er,âƒ—eÎ¸} basis.
Parenthetically, it is now not diï¬ƒcult to obtain a formula for the plane
curvature of âƒ—x(t) in terms of the functions r(t) and Î¸(t). We use either of
the formulations
Îºg(t) =
1
sâ€²(t)
âƒ—T â€² Â· âƒ—U =
1
(sâ€²(t))3 (âƒ—xâ€² Ã— âƒ—xâ€²â€²) Â· âƒ—k,
and we ï¬nd that
Îºg(t) = âˆ’rrâ€²â€²Î¸â€² + r2(Î¸â€²)3 + 2(râ€²)2Î¸â€² + rrâ€²Î¸â€²â€²
((râ€²)2 + r2(Î¸â€²)2)3/2
.
(2.7)
In general, to understand dynamics with respect to a moving frame, one
considers the trajectory âƒ—x : I â†’R3 of a particle in reference to a moving
frame F. Suppose that the base of the frame moves along the trajectory
Î±(t) and that the basis vectors {âƒ—e1,âƒ—e2,âƒ—e3} of the frame F vary with time
but always form an orthonormal set. In addition, we will always suppose
that this basis is labeled so that it is a positively oriented basis, that is, it
satisï¬es âƒ—e1 Ã— âƒ—e2 = âƒ—e3. Now. for all t,
âƒ—ei Â· âƒ—ej =

1,
if i = j,
0,
if i Ì¸= j,
so
âƒ—e â€²
i Â· âƒ—ej =

0,
if i = j,
âˆ’âƒ—ei Â· âƒ—e â€²
j,
if i Ì¸= j.

46
2. Coordinates, Frames, and Tensor Notation
Thus, there exists a vector âƒ—Ï‰, namely,
âƒ—Ï‰ = (âƒ—e â€²
2 Â· âƒ—e3)âƒ—e1 + (âƒ—e â€²
3 Â· âƒ—e1)âƒ—e2 + (âƒ—e â€²
1 Â· âƒ—e2)âƒ—e3
(2.8)
such that
âƒ—e â€²
i = âƒ—Ï‰ Ã— âƒ—ei
for all i. This vector is the angular velocity vector of the moving frame F.
We now want to determine the perceived position, velocity, and ac-
celeration vectors in the frame F in terms of the true position, velocity,
and acceleration. Label (âƒ—x)F, (âƒ—xâ€²)F, and (âƒ—xâ€²â€²)F as the perceived position,
velocity, and acceleration vectors. Firstly,
(âƒ—x)F = âƒ—x âˆ’âƒ—Î±,
(2.9)
but the perceived velocity and acceleration of âƒ—x are obtained by taking the
derivatives of the components of (âƒ—x)F in {âƒ—e1,âƒ—e2,âƒ—e3}. More explicitly, we
have
(âƒ—x)F = ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e1)âƒ—e1 + ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e2)âƒ—e2 + ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e3)âƒ—e3,
(âƒ—x â€²)F = d
dt ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e1)âƒ—e1 + d
dt ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e2)âƒ—e2 + d
dt ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e3)âƒ—e3,
(âƒ—x â€²)F = d2
dt2 ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e1)âƒ—e1 + d2
dt2 ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e2)âƒ—e2 + d2
dt2 ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—e3)âƒ—e3.
To understand dynamics in the moving frame F, one must relate the
perceived position, velocity, and acceleration to the position, velocity, and
acceleration with respect to the ï¬xed frame {âƒ—i,âƒ—j,âƒ—k}. By Equation (2.9),
we have
âƒ—x = (âƒ—x)F + âƒ—Î±.
Then for the velocity,
âƒ—xâ€² = d
dt(âƒ—x)F + âƒ—Î±â€²
=
 3

i=1
d
dt((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—ei

+
 3

i=1
((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—eâ€²
i

+ âƒ—Î±â€²
(2.10)
= (âƒ—xâ€²)F +
 3

i=1
((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—Ï‰ Ã— âƒ—e

+ âƒ—Î±â€²
= (âƒ—xâ€²)F + âƒ—Ï‰ Ã— (âƒ—x)F + âƒ—Î±â€².

2.2. Moving Frames in Physics
47
For the acceleration,
âƒ—xâ€²â€² = d
dt(âƒ—xâ€²)F + d
dt (âƒ—Ï‰ Ã— (âƒ—x)F) + âƒ—Î±â€²â€²
= d
dt
 3

i=1
((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—ei

+ dâƒ—Ï‰
dt Ã— (âƒ—x)F + âƒ—Ï‰ Ã— d
dt(âƒ—x)F + âƒ—Î±â€²â€²
=
 3

i=1
d2
dt2 ((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—ei

+
 3

i=1
d
dt((âƒ—x âˆ’âƒ—Î±) Â· âƒ—ei)âƒ—eâ€²
i

+ âƒ—Ï‰â€² Ã— (âƒ—x)F + âƒ—Ï‰ Ã— d
dt(âƒ—x)F + âƒ—Î±â€²â€²
= (âƒ—xâ€²â€²)F + âƒ—Ï‰ Ã— (âƒ—xâ€²)F + âƒ—Ï‰â€² Ã— (âƒ—x)F + âƒ—Ï‰ Ã— ((âƒ—xâ€²)F + âƒ—Ï‰ Ã— (âƒ—x)F) + âƒ—Î±â€²â€²,
where the second-to-last term follows from Equation (2.10). Thus,
âƒ—xâ€²â€² = (âƒ—xâ€²â€²)F + 2âƒ—Ï‰ Ã— (âƒ—xâ€²)F + âƒ—Ï‰â€² Ã— (âƒ—x)F + âƒ—Ï‰ Ã— (âƒ—Ï‰ Ã— (âƒ—x)F) + âƒ—Î±â€²â€².
(2.11)
All of the above terms have names in physics (see [21, p. 118]). The term
(âƒ—xâ€²â€²)F is called the perceived acceleration or acceleration with respect to F.
The component 2âƒ—Ï‰Ã—(âƒ—xâ€²)F is the Coriolis acceleration, while âƒ—Ï‰Ã—(âƒ—Ï‰Ã—(âƒ—x)F)
is the centripetal acceleration. The term âƒ—Ï‰â€² Ã— (âƒ—x)F is sometimes called the
transverse acceleration because it is perpendicular to the perceived position
vector (âƒ—x)F. Finally, the vector âƒ—Î±â€²â€² is the translational acceleration of the
frame.
As an example of the application of diï¬€erential geometry of curves to
physics, we consider the notion of centripetal acceleration of a curve and
its relation to the Frenet frame.
Example 2.2.1 (Centripetal Acceleration of Curves).
One ï¬rst encounters cen-
tripetal acceleration in the context of a particle moving around on a circle
with constant speed v, and one deï¬nes it as the acceleration due to the
change in the velocity vector. Phrasing the scenario mathematically, con-
sider a particle moving along the trajectory with equations of motion
âƒ—x(t) = (R cos(Ï‰t), R sin(Ï‰t)),
where R is the radius of the circle and Ï‰ is the (constant) angular speed.
The velocity, speed and acceleration are, respectively,
âƒ—xâ€²(t) = (âˆ’RÏ‰ sin(Ï‰t), RÏ‰ cos(Ï‰t)),
sâ€²(t) = v = RÏ‰,
âƒ—xâ€²â€²(t) = (âˆ’RÏ‰2 cos(Ï‰t), âˆ’RÏ‰2 sin(Ï‰t)).

48
2. Coordinates, Frames, and Tensor Notation
Hence, the acceleration is
âƒ—xâ€²â€²(t) = âˆ’Ï‰2âƒ—x(t) = âˆ’Ï‰2Râƒ—er = âˆ’v2
R âƒ—er,
(2.12)
where âƒ—er is the unit vector in the radial direction (see Equation (2.2)). This
is the centripetal acceleration for circular motion, often written âƒ—ac.
The angular velocity vector âƒ—Ï‰ is the vector of magnitude Ï‰ that is
perpendicular to the plane of rotation and with direction given by the right-
hand rule. Thus, taking âƒ—k as the direction perpendicular to the plane, we
have in this simple setup âƒ—Ï‰ = Ï‰âƒ—k. Setting the radial vector âƒ—R = râƒ—er, it is
not hard to show that for this circular motion,
âƒ—ac = âƒ—Ï‰ Ã— (âƒ—Ï‰ Ã— âƒ—R),
as expected from Equation (2.11).
Now consider a general curve in space âƒ—x : I â†’R3, where I is an interval
of R. We recall a few diï¬€erential geometric properties of space curves. The
derivative âƒ—x â€²(t) is called the velocity, and sâ€²(t) = âˆ¥âƒ—x â€²(t)âˆ¥is called the speed.
The curve âƒ—x(t) is called regular at t if âƒ—xâ€²(t) Ì¸= âƒ—0. At all regular points of a
curve, we deï¬ne the unit tangent as âƒ—T(t) = âƒ—x â€²(t)/âˆ¥âƒ—x â€²(t)âˆ¥. Because âƒ—T(t) is
a unit vector for all t, âƒ—T â€²(t) is perpendicular to âƒ—T(t).
The curvature of the curve is the unique nonnegative function Îº(t) such
that
âƒ—T â€²(t) = sâ€²(t)Îº(t)âƒ—P (t)
(2.13)
for some unit vector âƒ—P(t). The vector function âƒ—P(t) is called the principal
normal vector. Finally, we deï¬ne the binormal vector function âƒ—B(t) by
âƒ—B = âƒ—T Ã— âƒ—P. In so doing, we have deï¬ned an orthonormal set {âƒ—T, âƒ—P, âƒ—B}
associated to each point of the curve âƒ—x(t). This set {âƒ—T, âƒ—P, âƒ—B} is called the
Frenet frame.
It is not hard to show that, by construction, the derivative âƒ—B â€²(t) is
perpendicular to âƒ—B and to âƒ—T.
We deï¬ne the torsion function Ï„(t) of a
space curve as the unique function such that
âƒ—B â€²(t) = âˆ’sâ€²(t)Ï„(t)âƒ—P (t).
(2.14)
Finally, from Equations (2.13) and (2.14), we get that
âƒ—P â€²(t) = âˆ’sâ€²(t)Îº(t)âƒ—T (t) + sâ€²(t)Ï„(t) âƒ—B(t).
(The above paragraphs only give the deï¬nitions of the concepts we will
use here. A full treatment of these topics can be found in Chapter 3 of [5].)

2.2. Moving Frames in Physics
49
x
y
z
 âƒ—Î±(t)
âƒ—T(t)
âƒ—P(t)
âƒ—B(t)
  âƒ—x(t)
Figure 2.3. Center of curvature and osculating circle.
Since a space curve is not necessarily circular, one cannot use Equa-
tion (2.12) to determine the centripetal acceleration of âƒ—x. Instead, we view
âƒ—x in relation to an appropriate moving frame in which centripetal acceler-
ation makes sense. The osculating circle is the unique circle of maximum
contact with the curve âƒ—x(t) at any point t, and hence, the appropriate frame
F is based at the center of curvature
âƒ—Î±(t) = âƒ—x(t) +
1
Îº(t)
âƒ—P(t)
and has the vectors of the Frenet frame {âƒ—T, âƒ—P, âƒ—B} as its basis. Figure 2.3
depicts a space curve along with the center of curvature âƒ—Î±(t) and the os-
culating circle associated to a point âƒ—x(t) on the curve.
By Equation (2.8), the angular velocity vector of F is
âƒ—Ï‰ = (âƒ—P â€² Â· âƒ—B)âƒ—T + ( âƒ—Bâ€² Â· âƒ—T)âƒ—P + (âƒ—T â€² Â· âƒ—P) âƒ—B
= âˆ’sâ€²Ï„ âƒ—T + sâ€²Îº âƒ—B.
The relative position vector for the curve âƒ—x with reference to its center of
curvature is âƒ—R = (âƒ—x)F = âˆ’1
Îº âƒ—P. Therefore, the centripetal acceleration is

50
2. Coordinates, Frames, and Tensor Notation
âƒ—ac = âƒ—Ï‰ Ã— (âƒ—Ï‰ Ã— âƒ—R)
= âƒ—Ï‰ Ã—

(âˆ’sâ€²Ï„ âƒ—T + sâ€²Îº âƒ—B) Ã— (âˆ’1
Îº
âƒ—P)
	
= (âˆ’sâ€²Ï„ âƒ—T + sâ€²Îº âƒ—B) Ã— (sâ€² âƒ—T + sâ€² Ï„
Îº
âƒ—B)
= (sâ€²)2Îºâƒ—P + (sâ€²)2 Ï„ 2
Îº
âƒ—P
= (sâ€²)2 Îº2 + Ï„2
Îº
âƒ—P.
(2.15)
It is interesting to note that if a curve happens to be planar, then Ï„ = 0,
and the centripetal acceleration becomes âƒ—ac = (sâ€²)2Îºâƒ—P, which matches
Equation (2.12) exactly since sâ€² = v and Îº is the reciprocal of the radius of
curvature,
1
R. However, Equation (2.15) shows that, for a curve in space,
the â€œcorkscrewingâ€ eï¬€ect, measured by Ï„, produces a greater centripetal
acceleration than does simply rotating about the same axis. (Hence, on a
roller coaster, a rider will experience more centrifugal forceâ€”the force that
balances out centripetal accelerationâ€”if the roller coaster corkscrews than
when it simply rotates around with the same radius of curvature.)
Example 2.2.2 (Radial Forces). As an application of cylindrical coordinate sys-
tems, we can study Newtonâ€™s equation of motion applied to a particle un-
der the inï¬‚uence of a radial force. By deï¬nition, a force is called radial if
âƒ—F(âƒ—r) = f(r)âƒ—er, that is, if the force only depends on the distance from an
origin and is parallel to the position vector âƒ—r. (The force of gravity be-
tween two point objects and the electric force between two charged point
objects are radial forces, while the magnetic force on a charged particle
is not.)
Newtonâ€™s law of motion produces the following vector diï¬€erential equa-
tion:
mâƒ—r â€²â€² = f(r)âƒ—er.
In order to solve this diï¬€erential equation explicitly, one needs the initial
position âƒ—r0 and the initial velocity âƒ—v0.
For convenience, choose a plane P that goes through the origin and
is parallel to both âƒ—r0 and âƒ—v0.
(If âƒ—r0 and âƒ—v0 are not parallel, then this
information deï¬nes a unique plane in R3. If âƒ—r0 and âƒ—v0 are parallel, then
any plane parallel to these vectors suï¬ƒces.) Consider P to be the xy-plane,
choose any direction for the ray [Ox), and now use cylindrical coordinates
in R3.

2.2. Moving Frames in Physics
51
For radial forces, Newtonâ€™s law of motion written in the cylindrical
frame as three diï¬€erential equations is
â§
âª
â¨
âª
â©
âƒ—er :
m(râ€²â€² âˆ’r(Î¸â€²)2) = f(r),
âƒ—eÎ¸ :
m(2râ€²Î¸â€² + rÎ¸â€²â€²) = 0,
âƒ—ez :
0 = 0.
(2.16)
Obviously, since âƒ—r0 and âƒ—v0 lie in the plane through the origin and parallel
to âƒ—er and âƒ—eÎ¸, the equations show that âƒ—r(t) never leaves the xy-plane. Thus,
z(t) = 0.
One can now solve the second diï¬€erential equation in the above system
in such a way as to obtain a relationship between the functions r and Î¸.
First write
2râ€²
r
= âˆ’Î¸â€²â€²
Î¸â€² .
Integrating both sides with respect to t, we then obtain 2 ln |r| = âˆ’ln |Î¸â€²|+
C, where C is some constant of integration. Taking the exponential of both
sides, one obtains the relationship r2Î¸â€² = h where h is a constant. In terms
of the initial conditions, one has
âƒ—r Ã— âƒ—r â€² = r2Î¸â€²âƒ—ez
and therefore, for all time t, we have
h = (âƒ—r0 Ã— âƒ—v0) Â· âƒ—ez.
Thus, one concludes that the quantity âƒ—L = âƒ—r Ã— (mâƒ—v) = m(âƒ—r Ã— âƒ—v), which is
called the angular momentum and in general depends on t, is a constant
vector function for radial forces.
Finally, to solve the system in Equation (2.16) completely, it is conve-
nient to substitute variables and write the ï¬rst equation in terms of u = 1
r
and Î¸. Since r = 1
u, we have
dr
dt = âˆ’1
u2
du
dt = âˆ’1
u2
dÎ¸
dt
du
dÎ¸ = âˆ’hdu
dÎ¸ .
The second derivative of r gives
d2r
dt2 = âˆ’h d
dt
du
dÎ¸
	
= âˆ’hdÎ¸
dt
d2u
dÎ¸2 = âˆ’h2u2 d2u
dÎ¸2 .
The ï¬rst part of Equation (2.16) becomes
d2u
dÎ¸2 + u = âˆ’
1
mh2u2 f(uâˆ’1).
(2.17)

52
2. Coordinates, Frames, and Tensor Notation
If the radial force in question is an inverse-square law (such as the force
of gravity and the electrostatic force caused by a point charge), then the
radial force is of the form
f(r) = âˆ’k
r2 .
In this case, Equation (2.17) becomes
d2u
dÎ¸2 + u = âˆ’
k
mh2 .
Techniques from diï¬€erential equations show that the general solution to
this equation is
u(Î¸) = âˆ’k
mh2 + C cos(Î¸ âˆ’Î¸0),
where C and Î¸0 are constants of integration that depend on the original
position and velocity of the point particle under the inï¬‚uence of this radial
force. In polar coordinates, this gives the equation
r(Î¸) =
1
âˆ’
k
mh2 + C cos(Î¸ âˆ’Î¸0).
(2.18)
Problems
2.2.1. Provide the details for the proof of Equation (2.7).
2.2.2. Prove that Equation (2.8) is the correct vector to satisfy âƒ—eâ€²
i = âƒ—Ï‰ Ã— âƒ—ei for
all i.
2.2.3. Determine the transition matrix between the cylindrical coordinate frame
and the Frenet frame.
2.2.4. Calculate the curvature and torsion of a space curve deï¬ned by the func-
tions, in cylindrical coordinates, (r, Î¸, z) = (r(t), Î¸(t), z(t)).
2.2.5. Determine the transition matrix between the spherical coordinate frame
and the Frenet frame.
2.2.6. Calculate the curvature and torsion of a space curve deï¬ned by the func-
tions, in spherical coordinates, (r, Î¸, Ï†) = (r(t), Î¸(t), Ï†(t)).
2.2.7. Determine the transition matrix between the parabolic coordinate frame
and the Frenet frame (see Problem 2.1.3).
2.2.8. Consider the solution r(Î¸) in Equation (2.18). Determine h, C, and Î¸0 in
terms of some initial conditions for position and velocity âƒ—r(0) and âƒ—v(0).
Prove that for diï¬€erent initial conditions and diï¬€erent values of the con-
stants, the locus of Equation (2.18) is a conic. State under what conditions
one obtains a circle, ellipse, parabola, and hyperbola.
2.2.9. (ODE) Find the locus of the trajectory of a particle moving under the
eï¬€ect of a radial force that is an inverse cube, i.e., f(r) = âˆ’k/r3.

2.3. Moving Frames and Matrix Functions
53
2.3
Moving Frames and Matrix Functions
In the preceding sections, we encountered many examples of moving frames.
In the local theory of plane curves [5, Chapter 1], one uses the {âƒ—T, âƒ—U} frame
and, in this section, we reviewed the polar frame {âƒ—er,âƒ—eÎ¸}, both of which are
considered to be attached at a point of a regular plane curve âƒ—x : I â†’R2.
Similarly, in the local theory of space curves (see [5, Section 3.2]), one
studies the Frenet frame while, in this section, we reviewed the frames
associated to cylindrical and spherical coordinates, all three of which are
considered to be based at a point.
All of these scenarios are examples of moving frames and, more precisely,
orthonormal moving frames (though Problem 2.1.4 presented an example
where the coordinate frame is not orthonormal). In all ï¬ve of these exam-
ples of orthonormal moving frames attached to a curve, the rate of change
of the frame was related to the frame by multiplication of an antisymmetric
matrix, i.e., a matrix A such that AT = âˆ’A, where AT is the transpose
of A. This is no coincidence but depends only on the fact that the moving
frame is orthonormal, as we shall see shortly.
An orthonormal basis in Rn is any n-tuple of vectors (âƒ—u1, âƒ—u2, . . . , âƒ—un)
such that
âƒ—ui Â· âƒ—uj =

1,
if i = j,
0,
if i Ì¸= j.
(2.19)
One easily conï¬rms that if one considers the âƒ—ui as column vectors, then
the matrix
M =
â›
â
|
|
|
âƒ—u1
âƒ—u2
Â· Â· Â·
âƒ—un
|
|
|
â
â 
is an orthogonal n Ã— n matrix, that is, it satisï¬es
M T M = In
where In is the n Ã— n identity matrix. Since M T M = In, an orthogonal
matrix M satisï¬es det(M) = Â±1. An orthonormal basis (âƒ—u1, âƒ—u2, . . . , âƒ—un) is
called positively oriented if det(M) = 1 and negatively oriented otherwise.
The set of orthogonal n Ã— n matrices is denoted by O(n), and the set of
positive orthogonal matrices is denoted by
SO(n) = {M âˆˆO(n) | det(M) = 1 }.
(Note that the order of the basis vectors in the n-tuple (âƒ—u1, âƒ—u2, . . . , âƒ—un)
matters because a permutation of these vectors may change the sign of the

54
2. Coordinates, Frames, and Tensor Notation
determinant of the corresponding matrix M. Consequently, we must talk
about an n-tuple of vectors as opposed to just a set of vectors. One should
also be aware that a permutation of vectors in the basis B = (âƒ—u1, âƒ—u2, . . . , âƒ—un)
would lead to another basis Bâ€² that consists of the same set of vectors but
has a coordinate transition matrix that is a permutation matrix.)
One can therefore deï¬ne a moving orthonormal frame in Rn in two
equivalent ways:
as an n-tuple of continuous vector functions (âƒ—u1(t),
âƒ—u2(t), . . . , âƒ—un(t)) that satisfy the condition in Equation (2.19) or as a contin-
uous function M : I â†’O(n). In the latter way of viewing an orthonormal
frame, the notion of continuity for a function F : R â†’O(n) makes sense
when one views O(n) as a subset of the vector space of n Ã— n matrices,
which is isomorphic as a vector space to Rn2. (The set O(n) has the sub-
set topology induced from the Euclidean topology on Rn2.) Furthermore,
we call the moving frame diï¬€erentiable if all of the coordinate functions
involved are diï¬€erentiable.
Proposition 2.3.1. Let I âŠ‚R be an interval, and let M : I â†’O(n) be a
diï¬€erentiable function. Viewing M(t) as an orthogonal matrix for all t,
then for all t âˆˆI, we have
M â€²(t) = M(t)A(t)
where A(t) is an antisymmetric matrix.
Proof: Since for all t âˆˆI, the frame (âƒ—u1(t), âƒ—u2(t), . . . , âƒ—un(t)) is a basis of
Rn, one can write âƒ—uâ€²
i(t) as a linear combination of these basis vectors (with
coeï¬ƒcients that depend on t).
Thus, we can write M â€²(t) = M(t)A(t),
where the ith column of A(t) are the coordinates of âƒ—u â€²
i in the moving basis.
Furthermore, taking the derivative of the condition in Equation (2.19), we
obtain

2âƒ—u â€²
i(t) Â· âƒ—ui(t) = 0,
âƒ—u â€²
i(t) Â· âƒ—uj(t) + âƒ—ui(t) Â· âƒ—u â€²
j(t) = 0,
â‡â‡’

âƒ—ui(t) Â· âƒ—u â€²
i(t) = 0,
âƒ—ui(t) Â· âƒ—u â€²
j(t) = âˆ’âƒ—uj(t) Â· âƒ—u â€²
i(t).
(2.20)
Since M(t) is an orthogonal matrix, then
A(t) = M(t)âˆ’1M â€²(t) = M(t)T M â€²(t),
and the conditions in Equation (2.20) imply that
A(t)T = M â€²(t)T M(t) = âˆ’M(t)T M â€²(t) = âˆ’A(t).
Hence, A(t) is an antisymmetric matrix for all t âˆˆI.
â–¡

2.3. Moving Frames and Matrix Functions
55
Proposition 2.3.1 is only a particular case of a broader fact. Identifying
the set of m Ã— n matrices with Rmn, one can consider continuous functions
of matrices as curves Î³ : I â†’Rmn, where I is an interval of R. As with any
parametrized curve, the derivative Î³â€²(t) is taken component-wise, which as
matrices means entry-wise.
Proposition 2.3.2. Let Î³1(t) and Î³2(t) be matrix functions deï¬ned over an
interval I, and let A be any constant matrix. Assuming the operations are
deï¬ned, the following identities hold:
1.
d
dt(A) is the 0-matrix of the same dimensions of A.
2.
d
dt(AÎ³1(t)) = AÎ³â€²
1(t) and
d
dt(Î³1(t)A) = Î³â€²
1(t)A.
3.
d
dt(Î³1(t) + Î³2(t)) = Î³â€²
1(t) + Î³â€²
2(t).
4.
d
dt

Î³1(t)T 
= (Î³â€²
1(t))T .
5.
d
dt(Î³1(t)Î³2(t)) = Î³â€²
1(t)Î³2(t) + Î³1(t)Î³â€²
2(t).
6. If Î³1(t) is invertible for all t, then d
dt

Î³1(t)âˆ’1
=âˆ’Î³1(t)âˆ’1Î³â€²
1(t)Î³1(t)âˆ’1.
Proof: (Left as exercises for the reader.)
â–¡
Since the derivative of a constant matrix is the zero matrix, it is obvious
that the rank of a matrix function and the invertibility of a square matrix
function do not â€œcommuteâ€ with diï¬€erentiation (see Problem 2.3.2).
Problems
2.3.1. Let A be a constant invertible n Ã— n matrix, and let Î³ : I â†’Rn2 be a
matrix function. Suppose that Î³(t0) = In (the nÃ— n identity matrix), and
suppose that for all t, the identity Î³(t)T AÎ³(t) = I holds. Find an equation
that Î³â€²(t0) satisï¬es.
2.3.2. Find an example of an nÃ—n-matrix function Î³(t) such that f â€²(t) is never 0,
where f(t) = det(Î³(t)), but such that det(Î³â€²(t)) = 0 for all t.
2.3.3. Let Î³ : I â†’RmÃ—n be a diï¬€erentiable matrix function, and let f : J â†’I
be a diï¬€erentiable function.
Prove the chain rule for matrix functions,
namely,
d
dt (Î³(f(t))) = Î³â€²(f(t)) f â€²(t).
2.3.4. Let A(t) and B(t) be two n Ã— n matrix functions deï¬ned over an interval
I âŠ‚R.
(a) Suppose that A(t) and B(t) are similar for all t âˆˆI. Prove that Aâ€²(t)
and Bâ€²(t) are not necessarily similar.

56
2. Coordinates, Frames, and Tensor Notation
(b) Suppose that A(t) and B(t) are similar in that B(t) = SA(t)Sâˆ’1
for some ï¬xed invertible matrix S. Prove that Aâ€²(t) and Bâ€²(t) are
similar.
(c) Suppose that A(t0) = 0. Prove that Aâ€²(t0) and Bâ€²(t0) are similar.
2.3.5. Prove Proposition 2.3.2.
2.3.6. Let A(t) be an n Ã— n matrix function that is antisymmetric (i.e., A =
âˆ’AT ) for all t. Suppose that M(t) is an n Ã— n matrix function such that
M â€²(t) = M(t)A(t). Prove that M T (t)M(t) is constant.
2.3.7. Recall that given a square matrix A, the exponential eA is deï¬ned by
eA =
âˆ

i=0
1
i!Ai
and that this inï¬nite series converges for all matrices A.
(a) Prove that
d
dt(eAt) = AeAt.
(b) If A(t) is a matrix function, is it always true that
d
dt(eA(t)) = Aâ€²(t)eA(t)?
2.4
Tensor Notation
In the local theory of surfaces, one encounters the ï¬rst fundamental form,
which is also called the metric tensor of the regular surface. In an intro-
ductory physics course, one may encounter the moment of inertia tensor.
At the time one ï¬rst encounters these objects, one usually does not have
the time to discuss what a tensor is in general.
Mathematicians and physicists often present tensors and the tensor
product in very diï¬€erent ways, sometimes making it diï¬ƒcult for a reader to
see that authors in diï¬€erent ï¬elds are talking about the same thing. In this
section, we introduce classical tensor notation by emphasizing how com-
ponents of objects change under a coordinate transformation. Readers of
mathematics who are well acquainted with tensor algebras on vector spaces
might ï¬nd this approach unsatisfactory, but physicists should recognize it.
In later chapters, as we study analysis on manifolds, we will mesh this
current approach to tensors with the modern mathematical presentation of
tensors. Appendix C on multilinear algebra provides the algebraic back-
ground behind the tensor product and tensor algebra. In particular, Sec-
tion C.3 explains the duality between covariance and contravariance while,
Section C.4 explains the linear algebra of tensor products of vector spaces.
(For readers who have also read [5], this section is essentially the same as
Section 7.1 of that text.)

2.4. Tensor Notation
57
2.4.1
Transformations of Coordinate Systems
Let S be an open set in Rn, and consider two coordinate systems on S, rel-
ative to which the coordinates of a point P are denoted by (x1, x2, . . . , xn)
and (Â¯x1, Â¯x2, . . . , Â¯xn). Suppose that the open set U âŠ‚Rn parametrizes S
in the (x1, x2, . . . , xn) system and that the open set V âŠ‚Rn parametrizes
S in the (Â¯x1, Â¯x2, . . . , Â¯xn) system. We assume that there exists a bijective
change of coordinates function F : U â†’V so that we can write
(Â¯x1, Â¯x2, . . . , Â¯xn) = F(x1, x2, . . . , xn).
Again using the superscript notation, we might write explicitly
â§
âª
âª
â¨
âª
âª
â©
Â¯x1
= F 1(x1, x2, . . . , xn),
...
Â¯xn
= F n(x1, x2, . . . , xn),
where F i are functions from U to R. We will assume from now on that
the change-of-variables function F is always of class C2, i.e., that all the
second partial derivatives are continuous. Unless it becomes necessary for
clarity, one often abbreviates the notation and writes
Â¯xi = Â¯xi(xj),
by which one understands that the coordinates (Â¯x1, Â¯x2, . . . , Â¯xn) functionally
depend on the coordinates (x1, x2, . . . , xn). Therefore, one writes âˆ‚Â¯xi/âˆ‚xj
for âˆ‚F i/âˆ‚xj, and the matrix of the diï¬€erential dFP (see Proposition 1.2.14)
is given by
(dFP )ij =
 âˆ‚Â¯xi
âˆ‚xj
	
.
Just as the functions Â¯xi = Â¯xi(xj) represent the change of variables F,
we write xj = xj(Â¯xk) to indicate the component functions of the inverse
F âˆ’1 : V â†’U. In this notation, the Inverse Function Theorem (Theorem
1.4.5) states that, as matrices,
âˆ‚xj
âˆ‚Â¯xi
	
=
 âˆ‚Â¯xi
âˆ‚xj
	âˆ’1
,
(2.21)
where we assume that the functions in the ï¬rst matrix are evaluated at p in
the (Â¯x1, . . . , Â¯xn)-coordinate system while the functions in the second matrix
are evaluated at p in the (x1, . . . , xn)-coordinate system. One can express

58
2. Coordinates, Frames, and Tensor Notation
the same relationship in an alternate way by writing xi = xi(Â¯xj(xk)) and
applying the chain rule when diï¬€erentiating with respect to xk as follows:
âˆ‚xi
âˆ‚xk = âˆ‚xi
âˆ‚Â¯x1
âˆ‚Â¯x1
âˆ‚xk + âˆ‚xi
âˆ‚Â¯x2
âˆ‚Â¯x2
âˆ‚xk + Â· Â· Â· + âˆ‚xi
âˆ‚Â¯xn
âˆ‚Â¯xn
âˆ‚xk =
n

j=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚Â¯xj
âˆ‚xk .
However, by deï¬nition of a coordinate system in Rn, there must be no
functional dependance of one variable on another so
âˆ‚xi
âˆ‚xk = Î´i
k,
where Î´i
k is the Kronecker delta symbol deï¬ned by
Î´i
j =

1,
if i = j,
0,
if i Ì¸= j.
Therefore, since Î´i
j are essentially the entries of the identity matrix, we
conclude that
n

j=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚Â¯xj
âˆ‚xk = Î´i
k
(2.22)
and hence recover Equation (2.21).
Though we have presented the notion of curvilinear coordinates in gen-
eral, one should keep in mind linear coordinate changes, namely, where
â›
âœ
âœ
âœ
â
Â¯x1
Â¯x2
...
Â¯xn
â
âŸ
âŸ
âŸ
â = M
â›
âœ
âœ
âœ
â
x1
x2
...
xn
â
âŸ
âŸ
âŸ
â ,
where M is an n Ã— n matrix. If either of these coordinate systems is given
as coordinates in a basis of Rn, then the other system simply corresponds
to a change of basis in Rn. It is easy to conï¬rm that the transition matrix
is then
 âˆ‚Â¯xi
âˆ‚xj
	
= M,
the usual basis transition matrix. Furthermore, (âˆ‚Â¯xi/âˆ‚xj) is constant over
all Rn.
Example 2.4.1 (Spherical Coordinates). Let us call (x1, x2, x3) = (x, y, z) the
Cartesian system of coordinates and (Â¯x1, Â¯x2, Â¯x3) = (Ï, Î¸, Ï•) the spherical

2.4. Tensor Notation
59
coordinate system (recall Figure 2.1(b)). Then from the coordinate-change
function given by Equation (2.3), one shows that the diï¬€erential of the
transformation is
âˆ‚xj
âˆ‚Â¯xi
	
=
â›
â
cos Î¸ sin Ï•
âˆ’Ï sin Î¸ sin Ï•
Ï cos Î¸ cos Ï•
sin Î¸ sin Ï•
âˆ’Ï cosÎ¸ sin Ï•
Ï sin Î¸ cos Ï•
cos Ï•
0
âˆ’Ï sin Ï•
â
â .
(2.23)
2.4.2
Tensors: Deï¬nition and Notation
We are now in a position to discuss how components of various quantities
deï¬ned locally, namely, in a neighborhood U of a point p âˆˆR3, change un-
der a coordinate transformation on U. As mentioned before, our deï¬nitions
do not possess the usual mathematical ï¬‚avor and the supporting discussion
might feel like a game of symbols, but it is important to understand the
transformational properties of tensor components even before becoming fa-
miliar with the machinery of linear algebra of tensors. We begin with the
simplest situation.
Deï¬nition 2.4.2. Let p âˆˆRn, and let U be a neighborhood of p. Suppose
that (x1, x2, . . . , xn) and (Â¯x1, Â¯x2, . . . , Â¯xn) are two systems of coordinates
on U. A function f(x1, . . . , xn) given in the (x1, x2, . . . , xn)-coordinates is
said to be a scalar if its transformation Â¯f(Â¯x1, . . . , Â¯xn) in the (Â¯x1, . . . , Â¯xn)-
coordinates has the same numerical value. In other words,
Â¯f(Â¯x1, . . . , Â¯xn) = f(x1, . . . , xn).
In Deï¬nition 2.4.2, it is understood that the coordinates (x1, x2, . . . , xn)
and (Â¯x1, Â¯x2, . . . , Â¯xn) refer to the same point p in Rn.
This deï¬nition might appear at ï¬rst glance not to hold much content in
that every function deï¬ned in reference to some coordinate system should
possess this property, but that is not true. Suppose that f is a scalar. The
quantity that gives the derivative of f in the ï¬rst coordinate is not a scalar,
for though Â¯f(Â¯x1, . . . , Â¯xn) = f(x1, . . . , xn), we have
âˆ‚Â¯f
âˆ‚Â¯x1 = âˆ‚f
âˆ‚x1
âˆ‚x1
âˆ‚Â¯x1 + âˆ‚f
âˆ‚x2
âˆ‚x2
âˆ‚Â¯x1 + Â· Â· Â· + âˆ‚f
âˆ‚xn
âˆ‚xn
âˆ‚Â¯x1 ,
which in general is not âˆ‚f/âˆ‚x1.
As a second example of how quantities change under coordinate trans-
formations, we consider the gradient âƒ—âˆ‡f of a diï¬€erentiable scalar function f.

60
2. Coordinates, Frames, and Tensor Notation
Recall that
âƒ—âˆ‡f =
 âˆ‚f
âˆ‚x1 , âˆ‚f
âˆ‚x2 , . . . , âˆ‚f
âˆ‚xn
	
in usual Cartesian coordinates. The gradient is a vector ï¬eld, or we may
simply consider the gradient of f at P, namely, âƒ—âˆ‡fP , which is a vector. We
highlight the transformational properties of the gradient. The chain rule
gives
âˆ‚Â¯f
âˆ‚Â¯xj =
n

i=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚f
âˆ‚xi .
(2.24)
However, it turns out that this is not the only way components of what
we usually call a â€œvectorâ€ can change under a coordinate transformation.
Again, consider two coordinate systems (x1, x2, . . . , xn) and (Â¯x1,
Â¯x2, . . . , Â¯xn) on an open set of Rn.
Let âƒ—A be a vector in Rn, which we
consider based at P. The components of the vector âƒ—A in the respective
coordinate systems is (A1, . . . , An) and ( Â¯A1, . . . , Â¯An), where
âƒ—A =
n

i=1
Ai âˆ‚âƒ—r
âˆ‚xi =
n

j=1
Â¯Aj âˆ‚âƒ—r
âˆ‚Â¯xj .
Since âˆ‚âƒ—r/âˆ‚xi = "
j(âˆ‚âƒ—r/âˆ‚Â¯xj)(âˆ‚Â¯xj/âˆ‚xi), we ï¬nd that the components of âƒ—A
in the two systems of coordinates are related by
Â¯Aj =
n

i=1
âˆ‚Â¯xj
âˆ‚xi Ai.
(2.25)
Example 2.4.3 (Velocity in Spherical Coordinates). Consider a space curve that
is parametrized by âƒ—r(t) for t âˆˆI. The chain rule allows us to write the
velocity vector in spherical or Cartesian coordinates as
âƒ—r â€²(t) = Ïâ€²(t)âˆ‚âƒ—r
âˆ‚Ï + Î¸â€²(t)âˆ‚âƒ—r
âˆ‚Î¸ + Ï•â€²(t) âˆ‚âƒ—r
âˆ‚Ï•
= xâ€²(t)âƒ—i + yâ€²(t)âƒ—j + zâ€²(t)âƒ—k.
However, diï¬€erentiating Equation (2.3), assuming Ï, Î¸, and Ï• are functions
of t, allows us to identify the Cartesian coordinates of the velocity vector as
â›
â
xâ€²
yâ€²
zâ€²
â
â =
â›
â
cos Î¸ sin Ï•
âˆ’Ï sin Î¸ sin Ï•
Ï cos Î¸ cos Ï•
sin Î¸ sin Ï•
âˆ’Ï cosÎ¸ sin Ï•
Ï sin Î¸ cos Ï•
cos Ï•
0
âˆ’Ï sin Ï•
â
â 
â›
â
Ïâ€²
Î¸â€²
Ï•â€²
â
â .
If we label the spherical coordinates as (Â¯x1, Â¯x2, Â¯x3) and the Cartesian co-
ordinates as (x1, x2, x3), the transition matrix between components of the

2.4. Tensor Notation
61
velocity vector from spherical coordinates to Cartesian coordinates is pre-
cisely (âˆ‚xi/âˆ‚Â¯xj), as calculated in Equation (2.23). Thus, the velocity vector
of any curve âƒ—Î³(t) through a point P = âƒ—Î³(t0) does not change according to
Equation (2.24) but according to Equation (2.25).
The relations established in Equations (2.24) and (2.25) show that there
are two diï¬€erent kinds of vectors, each following diï¬€erent transformational
properties under a coordinate change. This distinction is not emphasized
in most linear algebra courses but essentially corresponds to the diï¬€erence
between a column vector and a row vector, which in turn corresponds to
vectors in Rn and its dual (Rn)âˆ—.
(The âˆ—notation denotes the dual of
a vector space. See Appendix C.3 for background.) We summarize this
dichotomy in the following two deï¬nitions.
Deï¬nition 2.4.4. Let (x1, . . . , xn) and (Â¯x1, . . . , Â¯xn) be two coordinate sys-
tems in a neighborhood of a point p âˆˆRn. An n-tuple (A1, A2, . . . , An) is
said to constitute the components of a contravariant vector at a point p if
these components transform according to the relation
Â¯Aj =
n

i=1
âˆ‚Â¯xj
âˆ‚xi Ai,
where we assume the partial derivatives are evaluated at p.
Deï¬nition 2.4.5.
Under the same conditions as above, an n-tuple (B1,
B2, . . . , Bn) is said to constitute the components of a covariant vector at a
point p if these components transform according to the relation
Â¯Bj =
n

i=1
âˆ‚xi
âˆ‚Â¯xj Bi,
where we assume the partial derivatives are evaluated at p.
A few comments are in order at this point.
Though the above two
deï¬nitions are unsatisfactory from the modern perspective in that they
do not clearly deï¬ne some set of vectors, these are precisely what one is
likely to ï¬nd in a classical mathematics text or a physics text presenting
diï¬€erential geometry. Nonetheless, we will content ourselves with these def-
initions and with the more general Deï¬nition 2.4.6. We defer until Chap-
ter 4 what is considered the proper modern deï¬nition of a tensor on a
manifold.

62
2. Coordinates, Frames, and Tensor Notation
Next, we point out that the quantities (A1, A2,. . . ,An) in Deï¬nition 2.4.4
or (B1, B2, . . . , Bn) in Deï¬nition 2.4.5 can either be constant or can be
functions of the coordinates in a neighborhood of p. If the quantities are
constant, one says they form the components of an aï¬ƒne vector. If the
quantities are functions in the coordinates, then the components deï¬ne a
diï¬€erent vector for every point in an open set, and thus, one views these
quantities as the components of a vector ï¬eld over a neighborhood of p.
Finally, in terms of notation, we distinguish between the two types
of vectors by using subscripts for covariant vectors and superscripts for
contravariant vectors. This convention of notation is consistent throughout
the literature and forms a central part of tensor calculus. This convention
also explains the use of superscripts for the coordinates since (xi) represents
the components of a contravariant vector, namely, the position vector of a
point.
As a further example to motivate the deï¬nition of a tensor, recall the
metric tensor of a regular surface S. If a coordinate patch of a regular
surface is parametrized by âƒ—X(x1, x2) (so that (x1, x2) forms a coordinate
system on that patch), then one deï¬nes the components of the metric
tensor as
gij = âˆ‚âƒ—X
âˆ‚xi Â· âˆ‚âƒ—X
âˆ‚xj .
(2.26)
Suppose that some open set U of S can be parametrized by âƒ—X(x1, x2)
and by some other parametrization âƒ—Y (Â¯x1, Â¯x2). (The pair (Â¯x1, Â¯x2) deï¬nes
another coordinate system on U.) Deï¬ne Â¯gkl similarly to Equation (2.26)
but with respect to the parametrization âƒ—Y . It is not hard to show that
Â¯gkl =
2

i=1
2

j=1
âˆ‚xi
âˆ‚Â¯xk
âˆ‚xj
âˆ‚Â¯xl gij.
This formula mimics but generalizes the transformational properties in Def-
inition 2.4.4 and Deï¬nition 2.4.5.
As we will see, many objects of interest that arise in diï¬€erential geom-
etry and in physics possess similar transformational properties. This leads
to the following deï¬nition of a tensor.
Deï¬nition 2.4.6. Let (x1, . . . , xn) and (Â¯x1, . . . , Â¯xn) be two coordinate sys-
tems in a neighborhood of a point p âˆˆRn. A set of nr+s quantities T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js
is said to constitute the components of a tensor of type (r, s) if under a
coordinate transformation, these quantities transform according to

2.4. Tensor Notation
63
Â¯T k1Â·Â·Â·kr
l1Â·Â·Â·ls
=
n

i1=1
Â· Â· Â·
n

ir=1
n

j1=1
Â· Â· Â·
n

js=1
âˆ‚Â¯xk1
âˆ‚xi1 Â· Â· Â· âˆ‚Â¯xkr
âˆ‚xir
âˆ‚xj1
âˆ‚Â¯xl1 Â· Â· Â· âˆ‚xjs
âˆ‚Â¯xls T i1Â·Â·Â·ir
j1Â·Â·Â·js ,
(2.27)
where we assume that the partial derivatives are evaluated at p. We deï¬ne
the rank of the tensor as the integer r + s.
From the above deï¬nition, one could rightly surmise that basic cal-
culations with tensors involve numerous repeated summations. In order
to alleviate this notational burden, mathematicians and physicists who use
the tensor notation as presented above utilize the Einstein summation con-
vention. In this convention of notation, one assumes that one takes a sum
from 1 to n (the dimension of Rn or the number of coordinates) over any
index that appears both in a superscript and a subscript of a product. Fur-
thermore, for this convention, in a partial derivative âˆ‚Â¯xi/âˆ‚xj, the index i
is considered a superscript and the index j is considered a subscript.
For example, if the quantities Aij form the components of a (0, 2)-tensor
and the quantities Bk constitute the components of a contravariant vector,
with the Einstein summation convention, the expression AijBj means
n

j=1
AijBj.
As another example, with the Einstein summation convention, the trans-
formational property of a tensor as given in Equation (2.27) is written as
Â¯T k1k2Â·Â·Â·kr
l1l2Â·Â·Â·ls
= âˆ‚Â¯xk1
âˆ‚xi1
âˆ‚Â¯xk2
âˆ‚xi2 Â· Â· Â· âˆ‚Â¯xkr
âˆ‚xir
âˆ‚xj1
âˆ‚Â¯xl1
âˆ‚xj2
âˆ‚Â¯xl2 Â· Â· Â· âˆ‚xjs
âˆ‚Â¯xls T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js,
where the summations from 1 to n over the indices i1, i2 Â· Â· Â· ir, j1, j2 Â· Â· Â· js
are understood.
As a third example, if the quantities Cij
kl constitute a
tensor of type (2, 2), then the expression Cij
kj means
n

j=1
Cij
kj.
On the other hand, with this convention, we do not sum over the index i
in the expression Ai+Bi or even in Ai+Bi. In fact, as we shall see, though
the former expression has a linear algebraic interpretation, the latter does
not.
In the rest of this book, we will use the Einstein summation convention
when working with components of tensors.

64
2. Coordinates, Frames, and Tensor Notation
2.4.3
Operations on Tensors
It is possible to construct new tensors from old ones. (Again, the reader
is encouraged to consult Appendix C.4 to see the underlying algebraic
meaning of the following operations.)
First of all, if Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·js and T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js are both components of tensors of
type (r, s), then the quantities
W i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js = Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·js + T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js
form the components of another (r, s)-tensor. In other words, tensors of
the same type can be added to obtain another tensor of the same type.
The proof is very easy and follows immediately from the transformational
properties and distributivity.
Secondly, if Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·js and T k1k2Â·Â·Â·kt
l1l2Â·Â·Â·lu
are components of tensors of type
(r, s) and (t, u), respectively, then the quantities obtained by multiplying
these components
W i1i2Â·Â·Â·irk1k2Â·Â·Â·kt
j1j2Â·Â·Â·jsl1l2Â·Â·Â·lu = Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·jsT k1k2Â·Â·Â·kt
l1l2Â·Â·Â·lu
form the components of another tensor but of type (r+t, s+u). Again, the
proof is very easy, but one must be careful with the plethora of indices. One
should note that this operation of tensor product works also for multiplying
a tensor by a scalar since a scalar is a tensor of rank 0.
Finally, another common operation on tensors is the contraction be-
tween two indices. We illustrate the contraction with an example. Let
Aijk
rs be the components of a (3, 2)-tensor and deï¬ne the quantities as
Bij
r = Aijk
rk
def
=
n

k=1
Aijk
rk
(by Einstein summation convention).
It is not hard to show (left as an exercise for the reader) that Bij
r constitute
the components of a tensor of type (2, 1). More generally, starting with a
tensor of type (r, s), if one sums over an index that appears both in the
superscript and in the subscript, one obtains the components of a (r âˆ’1,
s âˆ’1)-tensor. This is the contraction of a tensor over the stated indices.
2.4.4
Examples
Example 2.4.7. Following the terminology of Deï¬nition 2.4.6, a covariant
vector is often called a (0, 1)-tensor and similarly a contravariant vector is
called a (1, 0)-tensor.

2.4. Tensor Notation
65
Example 2.4.8 (Inverse of a (0, 2)-Tensor). As a more involved example, con-
sider the components Aij of a (0, 2)-tensor in Rn. Denote by Aij the quan-
tities given as the coeï¬ƒcients of the inverse matrix of (Aij). (Parentheses
around the components of a tensor of rank 2 indicate that we consider the
associated matrix and not just the collection of components.) We prove
that Aij form the components of a (2, 0)-tensor.
Suppose that the coeï¬ƒcients Aij are given in a coordinate system with
variables (x1, . . . , xn), and Â¯Ars are given in the (Â¯x1, . . . , Â¯xn) coordinate
system. That they are the inverse to the matrices (Aij) and ( Â¯Ars) means
that Aij and Â¯Ars are the unique quantities such that
AijAjk = Î´i
k,
and
Â¯Ars Â¯Ast = Î´r
t ,
(2.28)
where the reader must remember that we are using the Einstein summation
convention. Combining Equation (2.28) and the transformational proper-
ties of Ajk, we get
Â¯Ars âˆ‚xi
âˆ‚Â¯xs
âˆ‚xj
âˆ‚Â¯xt Aij = Î´r
t .
Multiplying both sides by âˆ‚Â¯xt/âˆ‚xÎ± and summing over t, we obtain
Â¯Ars âˆ‚xi
âˆ‚Â¯xs
âˆ‚xj
âˆ‚Â¯xt Aij
âˆ‚Â¯xt
âˆ‚xÎ± = Î´r
t
âˆ‚Â¯xt
âˆ‚xÎ±
â‡â‡’
Â¯Ars âˆ‚xi
âˆ‚Â¯xs Î´j
Î±Aij = âˆ‚Â¯xr
âˆ‚xÎ±
â‡â‡’
Â¯Ars âˆ‚xi
âˆ‚Â¯xs AiÎ± = âˆ‚Â¯xr
âˆ‚xÎ± .
Multiplying both sides by AÎ±Î² and then summing over Î±, we get
Â¯Ars âˆ‚xi
âˆ‚Â¯xs Î´Î²
i = Â¯Ars âˆ‚xÎ²
âˆ‚Â¯xs = âˆ‚Â¯xr
âˆ‚xÎ± AÎ±Î².
Finally, multiplying the rightmost equality by âˆ‚Â¯xs/âˆ‚xÎ² and summing over
Î², one concludes that
Â¯Ars = âˆ‚Â¯xr
âˆ‚xÎ±
âˆ‚Â¯xs
âˆ‚xÎ² AÎ±Î².
This shows that the quantities Aij satisfy Deï¬nition 2.4.6 and form the
components of a (2, 0)-tensor.
By a similar manipulation, one can show that if Bij are the components
of a (2, 0)-tensor, then the quantities Bij corresponding to the inverse of
the matrix (Bij) form the components of a (0, 2)-tensor.

66
2. Coordinates, Frames, and Tensor Notation
Example 2.4.9 (Gauss Map Coefï¬cients). In diï¬€erential geometry, one denotes
by gij the coeï¬ƒcients of the inverse of the matrix associated to the ï¬rst
fundamental form. Example 2.4.8 showed that gij is a (2, 0)-tensor. The
coeï¬ƒcients gij occur frequently in the geometry of surfaces and in Rie-
mannian geometry (Chapter 5). For example, the Weingarten equations,
which we will see in Example 3.3.9 (also presented in [5, Chapter 6]), can
be written concisely as
ai
j = âˆ’Ljkgki.
By tensor product and contraction, we see that the functions ai
j must form
the components of a (1, 1)-tensor. (These are called the coeï¬ƒcients of the
Gauss map.)
Example 2.4.10 (Metric Tensors). It is important to understand some standard
operations on vectors in the context of tensor notation. Consider two vec-
tors in a vector space V of dimension n. Using tensor notation, one refers
to these vectors as aï¬ƒne contravariant vectors with components Ai and
Bj, with i, j = 1, 2, . . ., n. We have seen that addition of the vectors or
scalar multiplication are the usual operations from linear algebra. Another
operation between vectors in V is the dot product, which was originally
deï¬ned as
n

i=1
AiBi,
but this is not the correct way to understand the dot product in the context
of tensor algebra. The very fact that one cannot use Einstein summation
convention is a hint that we must analyze this operation in more detail. The
use of the usual dot product for its intended geometric purpose makes an
assumption of the given basis of V , namely, that the basis is orthonormal.
When using tensor algebra, one makes no such assumption. Instead, one
associates to the basis of V with respect to which coordinates are deï¬ned
as a (0, 2)-tensor gij, called the metric tensor. Then the ï¬rst fundamental
form (or scalar product) between Ai and Bj is
gijAiBj
(by Einstein summation).
One immediately notices that because of tensor multiplication and contrac-
tion, the result is a scalar quantity and hence will remain unchanged under
a coordinate transformation. In this formulation, the assumption that a
basis is orthonormal is equivalent to having
gij =

1,
if i = j,
0,
if i Ì¸= j.

2.4. Tensor Notation
67
2.4.5
Symmetries
The usual operations of tensor addition and scalar multiplication were ex-
plained above. We should point out that using distributivity and associa-
tivity, one notices that the set of aï¬ƒne tensors of type (r, s) in Rn form a
vector space. The (r + s)-tuple of all the indices can take on nr+s values,
so this vector space has dimension nr+s.
However, it is not uncommon that there exist symmetries within the
components of a tensor. For example, as we saw for the metric tensor,
we always have gij = gji. In the context of matrices, we said that the
matrix (gij) is a symmetric matrix but in the context of tensor notation,
we say that the components gij are symmetric in the indices i and j. More
generally, if T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js are the components of a tensor of type (r, s), we say
that the components are symmetric in a set S of indices if the components
remain equal when we interchange any two indices from among the indices
in S.
For example, let Aijk
rs be the components of a (3, 2)-tensor. To say that
the components are symmetric in {i, j, k} aï¬ƒrms the equalities
Aijk
rs = Aikj
rs = Ajik
rs = Ajki
rs = Akij
rs = Akji
rs
for all i, j, k âˆˆ{1, 2, . . ., n}. Note that, because of the additional conditions,
the dimension of the vector space of all (3, 2)-tensors that are symmetric
in their contravariant indices is smaller than n5 but is not simply n5/6
either. We can ï¬nd the dimension of this vector space by determining the
cardinality of
I =
#
(i, j, k) âˆˆ{1, 2, . . ., n}3 | 1 â‰¤i â‰¤j â‰¤k â‰¤n
$
.
We will see shortly that |I| =
n+2
3

, and therefore, the dimension of the
vector space of (3, 2)-tensors that are symmetric in their contravariant in-
dices is
n+2
3

n2. We provide the following proposition for completeness.
Proposition 2.4.11. Let Aj1Â·Â·Â·jr
k1Â·Â·Â·ks be the components of a tensor over Rn that
is symmetric in a set S of its indices. Assuming that all the indices are
ï¬xed except for the indices of S, the number of independent components of
the tensor is equal to the cardinality of
I = {(i1, . . . , im) âˆˆ{1, 2, . . . , n}m | 1 â‰¤i1 â‰¤i2 â‰¤Â· Â· Â· â‰¤im â‰¤n} .
This cardinality is
n âˆ’1 + m
m
	
= (n âˆ’1 + m)!
(n âˆ’1)!m! .

68
2. Coordinates, Frames, and Tensor Notation
Proof: Since the components are symmetric in the set S of indices, one
gets a unique representative of equivalent components by imposing that the
indices in question be listed in nondecreasing order. This remark proves
the ï¬rst part of the proposition. To prove the second part, consider the
set of integers {1, 2, . . ., n + m}, and pick m distinct integers {l1, . . . , lm}
that are greater than 1 from among this set. We know from the deï¬nition
of combinations that there are
nâˆ’1+m
m

ways to do this. Assuming that
l1 < l2 < Â· Â· Â· < lm, deï¬ne it = lt âˆ’t. It is easy to see that the resulting
m-tuple (i1, . . . , im) is in the set I. Furthermore, since one can reverse the
process by lt = it + t for 1 â‰¤t â‰¤m, there exists a bijection between I and
the m-tuples (l1, . . . , lm) described above. This establishes that
|I| =
n âˆ’1 + m
m
	
.
â–¡
Another common situation with relationships between the components
of a tensor occurs when components are antisymmetric in a set of indices.
We say that the components are antisymmetric in a set S of indices if
the components are negated when we interchange any two indices from
among the indices in S. This condition imposes a number of immediate
consequences.
Consider, for example, the components of a (0, 3)-tensor
Aijk that are antisymmetric in all their indices.
If k is any value, but
i = j, then
Aijk = Aiik = Ajik = âˆ’Aijk,
and so Aiik = 0. Hence, any triple (i, j, k) in which at least two of the
indices are equal, the corresponding component is equal to 0. As another
consequence of the antisymmetric condition, consider the component A231.
One obtains the triple (2, 3, 1) from (1, 2, 3) by ï¬rst interchanging 1 and 2 to
get (2, 1, 3) and then interchanging the last two to get (2, 3, 1). Therefore,
we see that
A123 = âˆ’A213 = A231.
In modern algebra, a permutation (a bijection on a ï¬nite set) that inter-
changes two inputs and leaves the rest ï¬xed is called a transposition. We
say that we used two transpositions to go from (1, 2, 3) to (2, 3, 1).
The above example illustrates that the value of the component involving
a particular m-tuple (i1, . . . , im) of distinct indices determines the value of
any component involving a permutation (j1, . . . , jm) of (i1, . . . , im) accord-
ing to
Aj1...jm = Â±Ai1...im,

2.4. Tensor Notation
69
where the sign Â± is + (respectively âˆ’) if it takes an even (respectively
odd) number of interchanges to get from (i1, . . . , im) to (j1, . . . , jm). A
priori, if one could get from (i1, . . . , im) to (j1, . . . , jm) with both an odd
and an even number of transpositions, then the value of Ai1...im and all
components indexed by a permutation of (i1, . . . , im) would be 0. However,
a fundamental fact in modern algebra (see [24, Theorem 5.5]) states that
given a permutation Ïƒ on {1, 2, . . ., m}, if we have two ways to write Ïƒ as
a composition of transpositions, e.g.,
Ïƒ = Ï„1 â—¦Ï„2 â—¦Â· Â· Â· â—¦Ï„a = Ï„â€²
1 â—¦Ï„â€²
2 â—¦Â· Â· Â· â—¦Ï„â€²
b ,
then a and b have the same parity.
Deï¬nition 2.4.12. We call a permutation even (respectively odd) if this com-
mon parity is even (respectively odd) and the sign of Ïƒ is
sign(Ïƒ) =

1,
if Ïƒ is even,
âˆ’1,
if Ïƒ is odd.
The above discussion leads to the following proposition about the com-
ponents of an antisymmetric tensor.
Proposition 2.4.13. Let Aj1Â·Â·Â·jr
k1Â·Â·Â·ks be the components of a tensor over Rn that
is antisymmetric in a set S of its indices. If any of the indices in S are
equal, then
Aj1Â·Â·Â·jr
k1Â·Â·Â·ks = 0.
If |S| = m, then ï¬xing all but the indices in S, the number of independent
components of the tensor is equal to
nr+sâˆ’m
n
m
	
=
n!
m!(n âˆ’m)!nr+sâˆ’m.
Finally, if the indices of Ai1Â·Â·Â·ir
j1Â·Â·Â·js diï¬€er from Ak1Â·Â·Â·kr
l1Â·Â·Â·ls
only by a permutation
Ïƒ on the indices in S, then
Ak1Â·Â·Â·kr
l1Â·Â·Â·ls = sign(Ïƒ) Ai1Â·Â·Â·ir
j1Â·Â·Â·js.
Proof: We already saw the ï¬rst part of the proposition.
If we ï¬x values for all the indices not in S, the remaining number of
independent components of the tensor Aj1Â·Â·Â·jr
k1Â·Â·Â·ks corresponds to a collection
of distinct indices in S. There are precisely
 n
m

ways to choose the indices
in S to be distinct. Given any choice of values for the indices in S, there

70
2. Coordinates, Frames, and Tensor Notation
are n choices for all the remaining indices. Since there are r +sâˆ’m indices
not in S, the number of independent components of the tensor is equal to
nr+sâˆ’m
n
m

=
n!
m!(n âˆ’m)!nr+sâˆ’m.
For the last part of the proposition, if we can go from Ai1Â·Â·Â·ir
j1Â·Â·Â·js to Ak1Â·Â·Â·kr
l1Â·Â·Â·ls
with h transpositions, then by the previous discussion, the quantities diï¬€er
by (âˆ’1)h.
The proposition follows from the deï¬nition of the sign of a
permutation.
â–¡
2.4.6
Numerical Tensors
As a motivating example of what are called numerical tensors, note that the
quantities Î´i
j form the components of a (1, 1)-tensor. To see this, suppose
that Î´i
j is given in a system of coordinates (x1, . . . , xn) and Â¯Î´k
l is its trans-
formed value in another system of coordinates (Â¯x1, . . . , Â¯xn). Obviously, for
all ï¬xed i and j, the value of Î´i
j is constant, and therefore,
Â¯Î´k
l =

1,
if k = l,
0,
if k Ì¸= l.
But using the properties of Î´i
j and the chain rule,
âˆ‚Â¯xk
âˆ‚xi
âˆ‚xj
âˆ‚Â¯xl Î´i
j = âˆ‚Â¯xk
âˆ‚xi
âˆ‚xi
âˆ‚Â¯xl = âˆ‚Â¯xk
âˆ‚Â¯xl = Â¯Î´k
l .
Therefore, Î´i
j is a (1, 1)-tensor in a tautological way.
A numerical tensor is a tensor of rank greater than 0 whose components
are constant in the variables (x1, . . . , xn) and hence also (Â¯x1, . . . , Â¯xn). The
Kronecker delta is just one example of a numerical tensor, and we have
already seen that it plays an important role in many complicated calcu-
lations. The Kronecker delta is the simplest case of the most important
numerical tensor, the generalized Kronecker delta. The generalized Kro-
necker delta of order r is a tensor of type (r, r), with components denoted
by Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr deï¬ned as the following determinant:
Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr =

Î´i1
j1
Î´i1
j2
Â· Â· Â·
Î´i1
jr
Î´i2
j1
Î´i2
j2
Â· Â· Â·
Î´i2
jr
...
...
...
...
Î´ir
j1
Î´ir
j2
Â· Â· Â·
Î´ir
jr

.
(2.29)

2.4. Tensor Notation
71
It is not obvious from Equation (2.29) that the quantities Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr form
the components of a tensor. However, one can write the components of the
generalized Kronecker delta of order 2 as
Î´ij
kl = Î´i
kÎ´j
l âˆ’Î´i
lÎ´j
k,
which presents Î´ij
kl as the diï¬€erence between two (2, 2)-tensors, which shows
that Î´ij
kl is indeed a tensor. More generally, expanding out Equation (2.29)
by the Laplace expansion of a determinant gives the generalized Kronecker
delta of order r as a sum of r! components of tensors of type (r, r), proving
that Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr are the components of an (r, r)-tensor.
Properties of the determinant imply that Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr is antisymmetric in
the superscript indices and antisymmetric in the subscript indices. That
is to say that Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr = 0 if any of the superscript indices are equal or if
any of the subscript indices are equal, and the value of a component is
negated if any two superscript indices are interchanged and similarly for
subscript indices. We also note that if r > n, where we assume Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr are
the components of a tensor in Rn, then Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr = 0 for all choices of indices
since at least two superscript (and at least two subscript) indices would be
equal.
We introduce one more symbol related to the generalized Kronecker
delta, namely, the permutation symbol. Deï¬ne
Îµi1Â·Â·Â·in = Î´i1Â·Â·Â·in
1Â·Â·Â·n ,
Îµj1Â·Â·Â·jn = Î´1Â·Â·Â·n
j1Â·Â·Â·jn.
(2.30)
Note that the maximal index n in Equation (2.30) as opposed to r is in-
tentional. Because of the properties of the determinant, it is not hard to
see that one has the values
Îµi1Â·Â·Â·in = Îµi1Â·Â·Â·in
=
â§
âª
âª
â¨
âª
âª
â©
1,
if (i1, . . . , in) is an even permutation of (1, 2, . . . , n),
âˆ’1,
if (i1, . . . , in) is an odd permutation of (1, 2, . . . , n),
0,
if (i1, . . . , in) is not a permutation of (1, 2, . . . , n).
We are careful, despite the notation, not to call the permutation sym-
bols the components of a tensor for they are not. Instead, we have the
following proposition.

72
2. Coordinates, Frames, and Tensor Notation
Proposition 2.4.14. Let (x1, . . . , xn) and (Â¯x1, . . . , Â¯xn) be two coordinate sys-
tems. The permutation symbols transform according to
Â¯Îµj1Â·Â·Â·jn = J âˆ‚Â¯xj1
âˆ‚xi1 Â· Â· Â· âˆ‚Â¯xjn
âˆ‚xin Îµi1Â·Â·Â·in,
Â¯Îµk1Â·Â·Â·kn = Jâˆ’1 âˆ‚xh1
âˆ‚Â¯xk1 Â· Â· Â· âˆ‚xhn
âˆ‚Â¯xkn Îµh1Â·Â·Â·hn,
where J = det( âˆ‚Â¯xi
âˆ‚xj ) is the Jacobian of the transformation of coordinates
function.
Proof: (Left as an exercise for the reader.)
â–¡
Example 2.4.15 (Cross Product). As an example of the permutation symbol,
consider two contravariant vectors Ai and Bj in R3. If we deï¬ne Ck =
ÎµijkAiBj, we easily ï¬nd that
C1 = A2B3 âˆ’A3B2,
C2 = A3B1 âˆ’A1B3,
C3 = A1B2 âˆ’A2B1.
The values Ck are precisely the terms of the cross product of the vectors
Ai and Bj. However, a quick check shows that the quantities Ck do not
form the components of a covariant tensor.
One explanation in relation to standard linear algebra for the fact that
Ck does not give a contravariant vector is that if âƒ—a and âƒ—b are vectors in R3
given with coordinates in a certain basis and if M is a coordinate-change
matrix, then
(Mâƒ—a) Ã— (Mâƒ—b) Ì¸= M(âƒ—a Ã—âƒ—b).
In many physics textbooks, when one assumes that we use the usual
metric, (gij) being the identity matrix, one is not always careful with the su-
perscript and subscript indices. This is because one can obtain a contravari-
ant vector Bj from a covariant vector Ai simply by deï¬ning Bj = gijAi,
and the components (B1, B2, B3) are numerically equal to (A1, A2, A3).
Therefore, in this context, one can deï¬ne the cross product as the vector
with components
Cl = gklÎµijkAiBj,
(2.31)
However, one must remember that this is not a contravariant vector since it
does not satisfy the transformational properties of a tensor. From Propo-
sition 2.4.14, it is not hard to show that the quantity Cl will transform
according to
Â¯Ch = Jâˆ’1 âˆ‚Â¯xh
âˆ‚xl Cl,
where J is the Jacobian of the transformation from (xi)- to (Â¯xj)-coordinates.

2.4. Tensor Notation
73
The generalized Kronecker delta has a close connection to determinants
which, we will elucidate here.
Note that if the superscript indices are
exactly equal to the subscript indices, then Î´i1Â·Â·Â·ir
j1Â·Â·Â·jr is the determinant of the
identity matrix. Thus, the contraction over all indices, Î´j1Â·Â·Â·jr
j1Â·Â·Â·jr counts the
number of permutations of r indices taken from the set {1, 2, . . ., n}. Thus,
Î´j1Â·Â·Â·jr
j1Â·Â·Â·jr =
n!
(n âˆ’r)!.
Another property of the generalized Kronecker delta is that Îµj1Â·Â·Â·jnÎµi1Â·Â·Â·in
= Î´j1Â·Â·Â·jn
i1Â·Â·Â·in , the proof of which is left as an exercise for the reader (Prob-
lem 2.4.11). Now let ai
j be the components of a (1, 1)-tensor, which we can
view as the matrix of a linear transformation from Rn to Rn. By deï¬nition
of the determinant,
det(ai
j) = Îµj1Â·Â·Â·jna1
j1 Â· Â· Â· an
jn.
Then, by properties of the determinant related to rearranging rows or
columns, we have
Îµi1Â·Â·Â·in det(ai
j) = Îµj1Â·Â·Â·jnai1
j1 Â· Â· Â· ain
jn.
Multiplying by Îµi1Â·Â·Â·in and summing over all the indices i1, . . . , in, we have
Îµi1Â·Â·Â·inÎµi1Â·Â·Â·in det(ai
j) = Î´j1Â·Â·Â·jn
i1Â·Â·Â·in ai1
j1 Â· Â· Â· ain
jn,
and since Îµi1Â·Â·Â·inÎµi1Â·Â·Â·in counts the number of permutations of {1, . . . , n},
we have
n! det(ai
j) = Î´j1Â·Â·Â·jn
i1Â·Â·Â·in ai1
j1 Â· Â· Â· ain
jn.
Problems
2.4.1. Consider the rectangular and spherical coordinate systems as described in
Example 2.4.1. Calculate (âˆ‚Â¯xi/âˆ‚xj) directly from formulas for Ï, Î¸, Ï• in
terms of x, y, z. Conï¬rm that, as matrices,
âˆ‚xk
âˆ‚Â¯xl
	
=
 âˆ‚Â¯xi
âˆ‚xj
	âˆ’1
.
2.4.2. Prove that (a) Î´i
jÎ´j
kÎ´k
l = Î´i
l and (b) Î´i
jÎ´j
kÎ´k
i = n.
2.4.3. Let Bi be the components of a covariant vector. Prove that
âˆ‚Bj
âˆ‚xk âˆ’âˆ‚Bk
âˆ‚xj
form the components of a (0, 2)-tensor.

74
2. Coordinates, Frames, and Tensor Notation
2.4.4. Let T i1i2Â·Â·Â·ir
j1j2Â·Â·Â·js be a tensor of type (r, s). Prove that the quantities T ii2Â·Â·Â·ir
ij2Â·Â·Â·js ,
obtained by contracting over the ï¬rst two indices, form the components
of a tensor of type (r âˆ’1, s âˆ’1). Explain why one still obtains a tensor
when one contracts over any superscript and subscript index.
2.4.5. Let Sijk be the components of a tensor, and suppose they are antisymmet-
ric in {i, j}. Find a tensor with components Tijk that is antisymmetric in
j, k satisfying
âˆ’Tijk + Tjik = Sijk.
2.4.6. If Ajk is antisymmetric in its indices and Bjk is symmetric in its indices,
show that the scalar AjkBjk is 0.
2.4.7. Consider Ai, Bj, and Ck to be the components of three contravariant
vectors. Prove that ÎµijkAiBjCk is the value of the triple product ( âƒ—A âƒ—B âƒ—C) =
âƒ—A Â· ( âƒ—B Ã— âƒ—C), which is the volume of the parallelepiped spanned by these
three vectors.
2.4.8. Prove that ÎµijkÎµrsk = Î´rs
ij . Assume that we use a metric gij as the identity
matrix, and deï¬ne the cross product âƒ—C of two contravariant vectors âƒ—A =
(Ai) and âƒ—B = (Bj) as Ck = gklÎµijlAiBj. Use what you just proved to
show that
âƒ—A Ã— ( âƒ—B Ã— âƒ—C) = ( âƒ—A Â· âƒ—C) âƒ—B âˆ’( âƒ—A Â· âƒ—B) âƒ—C.
2.4.9. Let âƒ—A, âƒ—B, âƒ—C, and âƒ—D be vectors in R3. Use the Îµijk symbols to prove that
( âƒ—A Ã— âƒ—B) Ã— ( âƒ—C Ã— âƒ—D) = ( âƒ—A âƒ—B âƒ—D) âƒ—C âˆ’( âƒ—A âƒ—B âƒ—C) âƒ—D.
2.4.10. Prove Proposition 2.4.14.
2.4.11. Prove that Îµi1Â·Â·Â·inÎµj1Â·Â·Â·jn = Î´i1Â·Â·Â·in
j1Â·Â·Â·jn.
2.4.12. Let Aij be the components of an antisymmetric tensor of type (0, 2), and
deï¬ne the quantities
Brst = âˆ‚Ast
âˆ‚xr + âˆ‚Atr
âˆ‚xs + âˆ‚Ars
âˆ‚xt .
(a) Prove that Brst are the components of a tensor of type (0, 3).
(b) Prove that the components Brst are antisymmetric in all their in-
dices.
(c) Determine the number of independent components of antisymmetric
tensors of type (0, 3) over Rn.
(d) Would the quantities Brst still be the components of a tensor if Aij
were symmetric?
2.4.13. Let A be an n Ã— n matrix with coeï¬ƒcients A = (Aj
i), and consider the
coordinate transformation
Â¯xj =
n

i=1
Aj
ixi.

2.4. Tensor Notation
75
Recall that this transformation is called orthogonal if AAT = I where
AT is the transpose of A and I is the identity matrix. The orthogonality
condition implies that det(A) = Â±1.
An orthogonal transformation is
called special or proper if, in addition, det(A) = 1. A set of quantities
T i1Â·Â·Â·ir
j1Â·Â·Â·js is called a proper tensor of type (r, s) if it satisï¬es the tensor
transformation property from Equation (2.27) for all proper orthogonal
transformations.
(a) Prove that the orthogonality condition is equivalent to requiring that
Î·ij = Î·hkAh
i Ak
j ,
where
Î·ij =

1,
if i = j,
0,
if i Ì¸= j.
(b) Prove that the orthogonality condition is also equivalent to saying
that orthogonal transformations are the invertible linear transforma-
tions that preserve the quantity
(x1)2 + (x2)2 + Â· Â· Â· + (xn)2.
(c) Prove that (i) the space of proper tensors of type (r, s) form a vector
space over R, (ii) the product of a proper tensor of type (r1, s1) and a
proper tensor of type (r2, s2) is a proper tensor of type (r1 + r2, s1 +
s2), and (iii) contraction over two indices of a proper tensor of type
(r, s) produces a proper tensor of type (r âˆ’1, s âˆ’1).
(d) Prove that the permutation symbols are proper tensors of type (n, 0)
or (0, n), as appropriate.
(e) Use this to prove that the cross product of two contravariant vec-
tors in R3, as deï¬ned by Equation (2.31) is a proper tensor of type
(1, 0). [Remark: This explains that the cross product of two vectors
transforms correctly only if we restrict ourselves to proper orthogonal
transformations on R3.]
(f) Suppose that we are in R3. Prove that the rotation with matrix
A =
â›
â
cos Î±
âˆ’sin Î±
0
sin Î±
cos Î±
0
0
0
1
â
â 
is a proper orthogonal transformation.
(g) Again, suppose that we are in R3. Prove that the linear transforma-
tion with matrix given with respect to the standard basis
B =
â›
â
cos Î²
sin Î²
0
sin Î²
âˆ’cos Î²
0
0
0
1
â
â 
is an orthogonal transformation that is not proper.

76
2. Coordinates, Frames, and Tensor Notation
2.4.14. Consider the vector space Rn+1 with coordinates (x0, x1, . . . , xn) where
(x1, . . . , xn) are called the space coordinates and x0 is the time coordinate.
The usual connection between x0 and time t is x0 = ct, where c is the
speed of light. We equip this space with the metric deï¬ned by Î·Î¼Î½, where
Î·00 = âˆ’1, Î·ii = 1 for 1 â‰¤i â‰¤n, and Î·ij = 0 if i Ì¸= j. (The quantities
Î·Î¼Î½ do not give a metric in the sense we have presented in this text so
far because it is not positive deï¬nite. For this reason, the quantities Î·Î¼Î½
are often said to constitute a pseudometric. Though we do not provide
the details here, this unusual metric gives a mathematical justiï¬cation for
why it is impossible to travel faster than the speed of light c.) This vector
space equipped with the metric Î·Î¼Î½ is called the n-dimensional Minkowski
spacetime, and Î·Î¼Î½ is called the Minkowski metric.
Let L be an n Ã— n matrix with coeï¬ƒcients LÎ±
Î², and consider the linear
transformation
Â¯xj =
n

i=0
Lj
ixi.
A Lorentz transformation is an invertible linear transformation on Minkowski
spacetime, with matrix L such that
Î·Î±Î² = Î·Î¼Î½LÎ¼
Î±LÎ½
Î².
Finally, a collection of quantities T i1Â·Â·Â·ir
j1Â·Â·Â·js , with indices ranging in {0, 1, . . . , n},
is called a Lorentz tensor of type (r, s) if it satisï¬es the tensor transfor-
mation property Equation (2.27) for all Lorentz transformations.
(a) Prove that a transformation of Minkowski spacetime is a Lorentz
transformation if and only if it preserves the quantity
âˆ’(x0)2 + (x1)2 + (x2)2 + Â· Â· Â· + (xn)2.
(b) Suppose we are working in three-dimensional Minkowski spacetime.
Prove that the rotation matrix
A =
â›
âœ
âœ
â
1
0
0
0
0
cos Î±
âˆ’sin Î±
0
0
sin Î±
cos Î±
0
0
0
0
1
â
âŸ
âŸ
â 
represents a Lorentz transformation.
(c) Again, suppose we are working in three-dimensional Minkowski space-
time. Consider the matrix
L =
â›
âœ
âœ
â
Î³
âˆ’Î²Î³
0
0
âˆ’Î²Î³
Î³
0
0
0
0
1
0
0
0
0
1
â
âŸ
âŸ
â ,
where Î² is a positive real number satisfying âˆ’1 < Î² < 1 and Î³ =
1/

1 âˆ’Î²2. Prove that L represents a Lorentz transformation.

2.4. Tensor Notation
77
(d) Prove that (i) the space of Lorentz tensors of type (r, s) form a vector
space over R, (ii) the product of a Lorentz tensor of type (r1, s1)
and a Lorentz tensor of type (r2, s2) is a Lorentz tensor of type
(r1 + r2, s1 + s2), and (iii) contraction over two indices of a Lorentz
tensor of type (r, s) produces a Lorentz tensor of type (r âˆ’1, s âˆ’1).
2.4.15. Let ai
j be the components of a (1, 1)-tensor, or in other words the matrix
of a linear transformation from Rn to Rn given with respect to some basis.
Recall that the characteristic equation for the matrix is
det(ai
j âˆ’Î»Î´i
j) = 0.
(2.32)
Prove that Equation (2.32) is equivalent to
Î»n +
n

r=1
(âˆ’1)ra(r)Î»nâˆ’r = 0,
where
a(r) = 1
r!Î´i1Â·Â·Â·ir
j1Â·Â·Â·jrai1
j1 Â· Â· Â· air
jr.
[Hint: The solutions to Equation (2.32) are the eigenvalues of the matrix
(ai
j).]
2.4.16. Moment of Inertia Tensor. Suppose that R3 is given a basis that is not
necessarily orthonormal. Let gij be the metric tensor corresponding to this
basis, which means that the scalar product between two (contravariant)
vectors Ai and Bj is given by
âŸ¨âƒ—A, âƒ—BâŸ©= gijAiBj.
In the rest of the problem, call (x1, x2, x3) the coordinates of the position
vector âƒ—r.
Let S be a solid in space with a density function Ï(âƒ—r), and suppose that
it rotates about an axis â„“through the origin. The angular velocity vector
âƒ—Ï‰ is deï¬ned as the vector along the axis â„“, pointing in the direction that
makes the rotation a right-hand corkscrew motion with magnitude Ï‰ that
is equal to the radians per second swept out by the motion of rotation.
Let (Ï‰1, Ï‰2, Ï‰3) be the components of âƒ—Ï‰ in the given basis. The moment
of inertia of the solid S about the direction âƒ—Ï‰ is deï¬ned as the quantity
Iâ„“=
%%%
S
Ï(âƒ—r)r2
âŠ¥dV,
where râŠ¥is the distance from a point âƒ—r with coordinates (x1, x2, x3) to
the axis â„“.
The moment of inertia tensor of a solid is often presented using cross
products, but we deï¬ne it here using a characterization that is equivalent

78
2. Coordinates, Frames, and Tensor Notation
to the usual deï¬nition but avoids cross products. We deï¬ne the moment
of inertia tensor as the unique (0, 2)-tensor Iij such that
(IijÏ‰i)Ï‰j
Ï‰ = Iâ„“Ï‰,
(2.33)
where Ï‰ = âˆ¥âƒ—Ï‰âˆ¥=

âŸ¨âƒ—Ï‰, âƒ—Ï‰âŸ©.
(a) Prove that
r2
âŠ¥= gijxixj âˆ’(gklÏ‰kxl)2
grsÏ‰rÏ‰s .
(b) Prove that, using the metric gij, the moment of inertia tensor is given
by
Iij =
%%%
S
Ï(x1, x2, x3)(gijgkl âˆ’gikgjl)xkxl dV.
(c) Show that
(gijgkl âˆ’gikgjl)xkxl = gipgqlÎ´pq
jkxkxl,
where Î´pq
jk is the generalized Kronecker delta of order 2.
(d) Prove that Iij is symmetric in its indices.
(e) Prove that if the basis of R3 is orthonormal (which means that (gij)
is the identity matrix), one recovers the following usual formulas one
ï¬nds in physics texts:
I11 =
%%%
S
Ï((x2)2 + (x3)2) dV,
I12 = âˆ’
%%%
S
Ïx1x2 dV,
I22 =
%%%
S
Ï((x1)2 + (x3)2) dV,
I13 = âˆ’
%%%
S
Ïx1x3 dV,
I33 =
%%%
S
Ï((x1)2 + (x2)2) dV,
I23 = âˆ’
%%%
S
Ïx2x3 dV.
(We took the relation in Equation (2.33) as the deï¬ning property of the
moment of inertia tensor because of the theorem that Iâ„“Ï‰ is the component
of the angular moment vector along the axis of rotation that is given by
(IijÏ‰i) Ï‰j
Ï‰ . See [21, pp. 221â€“222] and, in particular, Equation (9.7) for an
explanation. The interesting point about this approach is that it avoids
the use of an orthonormal basis and provides a formula for the moment of
inertia tensor when one has an aï¬ƒne metric tensor that is not the identity.
Furthermore, since it avoids the cross product, the above deï¬nitions for
the moment of inertia tensor of a solid about an axis are generalizable to
solids in Rn.)

CHAPTER
3
Differentiable Manifolds
Until now, our study of curves and surfaces has always described them as
subsets of some ambient Euclidean space Rn. We deï¬ned parametrizations
as vector functions of one (for a curve) or two (for a surface) variables into
R2 or R3, without pointing out that many of our constructions relied on
the fact that R2 and R3 are topological vector spaces. That we have only
studied geometric objects that are subsets of R3 does not bely our intuition
since the daily reality of human experience evolves (or at least appears to
evolve) completely in three dimensions that we feel are ï¬‚at. However, both
in mathematics and in physics, one does not need to take such a large step
in abstraction to realize the insuï¬ƒciency of this intuition.
In geometry, one can easily deï¬ne natural point sets that cannot be
properly represented in only three dimensions. For example, the real pro-
jective plane RP2 can be deï¬ned as the set of equivalence classes of lines
through the origin in R3 or also as the set of equivalence classes of points
in R3 âˆ’{(0, 0, 0)} under the equivalence relation
(x0, x1, x2) âˆ¼(y0, y1, y2)
if and only if
(y0, y1, y2) = (Î»x0, Î»x1, Î»x2) for some Î» âˆˆR âˆ’{0}.
This object plays a role of fundamental importance in both topology and
algebraic geometry. In some sense, it appears that the projective plane
should be a two-dimensional object since, from a topological viewpoint, it is
the identiï¬cation space (see Deï¬nition A.3.38) of a three-dimensional object
by a one-dimensional object. Both in classical geometry and in algebraic
geometry, there exist natural methods to study curves on the projective
plane, thereby providing a language to â€œdo analysisâ€ on it. Nonetheless, it
is not hard to show that no subset of R3 is homeomorphic to RP2. There
does exist a subset of R4 that is homeomorphic to RP2 but this fact is
not obvious from the deï¬nition of the projective plane. Consequently, to
provide deï¬nitions that include projective spaces and other more abstract
geometric objects, one must avoid referring to some ambient Euclidean
space.
79

80
3. Differentiable Manifolds
In physics, the need for eliminating a Euclidean ambient space boasts
a more colorful history. Inspired by evidence provided by scientists like
Toricelli, explorers of the ï¬fteenth and sixteenth centuries debunked the
ï¬‚at-earth theory by circumnavigating the globe. Though the normal Eu-
clidean geometry remained valid on the small scale, namely, doing geometry
on a ï¬‚at surface (sheet of paper or plot of land), such methods no longer
suï¬ƒced when considering the geometry of the earth as a whole. In particu-
lar, the science of cartography suddenly became far more mathematical in
nature as navigators attempted to represent, with some degree of accuracy,
coastlines of continents on a ï¬‚at sheet of paper.
No less revolutionary was Einsteinâ€™s theory of general relativity in which
both space and time are connected as a single, four-dimensional space-time
entity that could itself be curved. In fact, following from the postulate that
nothing with mass travels faster than the speed of light, Einsteinâ€™s theory
purports that mass must distort space-time.
The practical need to do geometry or do physics in continuous point-set
spaces that are not Euclidean leads us to generalize our concepts of curves
and surfaces to higher-dimensional objects. We will call these objects of
study diï¬€erentiable manifolds. We will then deï¬ne maps between manifolds
and establish an analysis of maps between diï¬€erentiable manifolds. Our
deï¬nitions, which may seem a little weighty, attempt to retain suï¬ƒcient
restrictions to ensure that doing calculus on the sets is possible, while
preserving enough freedom to incorporate the rich variety of geometric
objects to which we wish to apply our techniques.
3.1
Deï¬nitions and Examples
As a motivating example for diï¬€erentiable manifolds, we recall the deï¬ni-
tion of a regular surface in R3 (see [5, Chapter 5] for more background).
Deï¬nition 3.1.1. A subset S âŠ†R3 is a regular surface if for each p âˆˆS,
there exists an open set U âˆˆR2, an open neighborhood V of p in R3, and
a surjective continuous function âƒ—X : U â†’V âˆ©S such that
1. âƒ—X is diï¬€erentiable: if we write âƒ—X(u, v) = (x(u, v), y(u, v), z(u, v)),
then the functions x(u, v), y(u, v), and z(u, v) have continuous partial
derivatives of all orders;
2. âƒ—X is a homeomorphism: âƒ—X is continuous and has an inverse âƒ—Xâˆ’1 :
V âˆ©S â†’U such that âƒ—Xâˆ’1 is continuous;

3.1. Deï¬nitions and Examples
81
3. âƒ—X satisï¬es the regularity condition: for each (u, v) âˆˆU, the diï¬€eren-
tial d âƒ—X(u,v) : R2 â†’R3 is a one-to-one linear transformation.
This deï¬nition already introduces many of the subtleties that are in-
herent in the concept of a manifold. In the above deï¬nition, each function
âƒ—X : U â†’V âˆ©S is called a parametrization of a coordinate neighborhood.
Now, as we set out to deï¬ne diï¬€erentiable manifolds and remove any
reference to an ambient Euclidean space, we begin from the context of
topological spaces. (Appendix A gives a brief introduction to topological
spaces.) Not every topological space can ï¬t the bill of usefulness for dif-
ferential geometry, so we require some additional properties of what types
of topological spaces we will consider. We ï¬rst impose the requirement of
having a cover of open sets, each of which is homeomorphic to an open set
in a Euclidean space.
Deï¬nition 3.1.2. A topological manifold of dimension k is a Hausdorï¬€topo-
logical space M with a countable base such that for all x âˆˆM, there exists
an open neighborhood of x that is homeomorphic to an open set of Rk.
The reader is encouraged to refer to Section A.3 for deï¬nitions and dis-
cussions about the base of a topology and the property of being Hausdorï¬€.
The technical aspect of this deï¬nition attempts to make the category of
objects of study as general as possible, while still remaining relevant for
geometry.
In the deï¬nition of a topological manifold, a given homeomorphism
of a neighborhood of M with a subset of Rk provides a local coordinate
system or coordinate patch. As one moves around on the manifold, one
passes from one coordinate patch to another. In the overlap of coordinate
patches, there exist change-of-coordinate functions that, by deï¬nition, are
homeomorphisms between open sets in Rn (see Figure 3.1). However, in
order to deï¬ne a theory of calculus on the manifold, these functions must
be diï¬€erentiable. We make this clear in the following deï¬nition.
Deï¬nition 3.1.3. A diï¬€erentiable manifold M of dimension n is a topological
manifold along with a collection of maps Ï†Î± : UÎ± â†’Rn, called charts, with
UÎ± open subsets in M, satisfying the following three conditions:
1. The collection of sets UÎ±, called coordinate patches, cover M.
2. Each chart is a homeomorphism Ï†Î± : UÎ± â†’VÎ±, where VÎ± is an open
subset of Rn.

82
3. Differentiable Manifolds
Ï†1
Ï†2
Ï†2 â—¦Ï†âˆ’1
1
V1
V2
M
U1
U2
Figure 3.1. Change-of-coordinate maps.
3. For any pair of charts Ï†Î± and Ï†Î², the change-of-coordinates function
Ï†Î±Î²
def
= Ï†Î± â—¦Ï†âˆ’1
Î² |Ï†Î²(UÎ±âˆ©UÎ²) : Ï†Î²(UÎ± âˆ©UÎ²) âˆ’â†’Ï†Î±(UÎ± âˆ©UÎ²),
called the transition function, is a function of class C1 between open
subsets of Rn.
The set of pairs {(UÎ±, Ï†Î±)}Î±âˆˆI, where I is some indexing set, is called an
atlas.
A diï¬€erentiable manifold is called a Ck manifold, a smooth manifold, or
an analytic manifold if the transition functions in the atlas are respectively
Ck, Câˆ, or analytic.
Two comments about notation are in order here. Mimicking the no-
tation habits for common sets (the n sphere as Sn or the real projective
space RPn), if M is an n-dimensional manifold, we sometimes shorten the
language by referring to the diï¬€erentiable manifold M n.
Also, though
technically a chart is a function Ï† : U â†’Rn, where U is an open subset of
the manifold M, one sometimes refers to the chart (U, Ï†) to emphasize the
letter to be used for the domain of Ï†.
One might wonder why it is necessary to remove any reference to an
ambient space. Indeed, at ï¬rst glance, the above deï¬nition of a diï¬€eren-
tiable manifold may seem unnecessarily complicated. A ï¬rst response to
such a criticism is to say that this is the safe thing to do: that a priori

3.1. Deï¬nitions and Examples
83
we do not know whether a given manifold can be described as a subset of
an ambient Euclidean space. A second response comes from physics. Gen-
eral relativity establishes that spacetime is not a Euclidean space. Popular
literature sometimes calls spacetime a â€œcurvedâ€ space. However, it would
be misleading to think of this curved spacetime as a subset of a larger
Euclidean space since the coordinates of the ambient space would have
no physical meaning. Removing any reference to an ambient space is the
proper approach to presenting a mathematical structure that appropriately
models a non-Euclidean space in which we wish to do calculus. The above
deï¬nition and subsequent constructions have proven to be general enough
and structured enough to be useful in geometry and in physics.
Many properties of manifolds that arise in analysis are local properties,
in that we only need to know information about the manifold in some neigh-
borhood of a point p âˆˆM. When this is the case, we can restrict our atten-
tion to a single coordinate chart Ï†Î± : UÎ± â†’Rn, where p âˆˆUÎ±. Saying that
the coordinates of a point p (with respect to this chart) are (x1, x2, . . . , xn)
means that Ï†Î±(p) = (x1, x2, . . . , xn). For reasons that will only become
clear later, it is convenient to follow the tensor notation convention of us-
ing superscripts for coordinates. This makes writing polynomial functions
in the coordinates more tedious but this notation will provide a convenient
way to distinguish between covariant and contravariant properties.
Example 3.1.4 (Sphere). Consider the unit sphere S2 = {(x, y, z) âˆˆR3 | x2 +
y2 + z2 = 1}, which we cover with an atlas of two coordinate patches: the
stereographic projection from the north pole and from the south pole (see
Figure 3.2). It is not hard to verify the following formulas for stereographic
projection:
1. The north pole is Ï€N : S2 âˆ’{(0, 0, 1)} â†’R2, with
Ï€N(x, y, z) =

x
1 âˆ’z ,
y
1 âˆ’z
	
.
2. the south pole is Ï€S : S2 âˆ’{(0, 0, âˆ’1)} â†’R2, with
Ï€S(x, y, z) =

x
1 + z ,
y
1 + z
	
.
It is not hard to conï¬rm that Ï€N and Ï€S are homeomorphisms and that
every point p âˆˆS2 is in the domain of one of these charts. Furthermore,
the overlap of these two coordinate patches is the entire sphere except the
north and south poles. We now check the second condition in the deï¬nition

84
3. Differentiable Manifolds
x
y
z
N
   p
 Ï€(p)
Figure 3.2. Stereographic projection.
of a manifold, namely, that the change of coordinates in this overlap is
diï¬€erentiable.
In Problem 3.1.1, one will show that
Ï€âˆ’1
N (u, v) =

2u
u2 + v2 + 1,
2v
u2 + v2 + 1, u2 + v2 âˆ’1
u2 + v2 + 1
	
.
Then the change-of-coordinate function Ï€S â—¦Ï€âˆ’1
N
: R2 âˆ’{(0, 0)} â†’
R2 âˆ’{(0, 0)} is explicitly given by
Ï€S â—¦Ï€âˆ’1
N (u, v) =

u
u2 + v2 ,
v
u2 + v2
	
.
By standard methods of multivariable calculus on R2, one can show that
Ï€S â—¦Ï€âˆ’1
N
is Câˆon R2 âˆ’{(0, 0)}. Similarly, one can show that Ï€N â—¦Ï€âˆ’1
S
is
Câˆ. Since the set {Ï€N, Ï€S} provides an atlas on S2 and since the associated
transition functions are Câˆ, we conclude that S2 equipped with this atlas
is in fact a smooth manifold.
Example 3.1.5 (Sphere with Another Atlas). We can prove that the unit sphere
S2 is a smooth two-dimensional manifold using another atlas, this time
using rectangular coordinates for the parametrizations.
Consider a point p = (x, y, z) âˆˆS2, and let V = {(u, v) | u2 + v2 < 1}.
If z > 0, then the mapping âƒ—X(1) : V â†’R3 deï¬ned by (u, v,
âˆš
1 âˆ’u2 âˆ’v2)
is clearly a bijection between V and S2 âˆ©{(x, y, z)|z > 0}. âƒ—X(1) is also a
homeomorphism because it is continuous and its inverse âƒ—Xâˆ’1
(1) is simply the
vertical projection of the upper unit sphere onto R2, and since projection
is a linear transformation, it is continuous.

3.1. Deï¬nitions and Examples
85
âƒ—X(1)
âƒ—X(2)
âƒ—X(3)
âƒ—X(4)
âƒ—X(5)
âƒ—X(6)
Figure 3.3. Six coordinate patches on the sphere.
We cover S2 with the following parametrizations âƒ—X(i) : V â†’R3:
if z > 0, âƒ—X(1)(u, v) = (u, v,

1 âˆ’u2 âˆ’v2),
if z < 0, âƒ—X(2)(u, v) = (u, v, âˆ’

1 âˆ’u2 âˆ’v2),
if y > 0, âƒ—X(3)(u, v) = (u,

1 âˆ’u2 âˆ’v2, v),
if y < 0, âƒ—X(4)(u, v) = (u, âˆ’

1 âˆ’u2 âˆ’v2, v),
if x > 0, âƒ—X(5)(u, v) = (

1 âˆ’u2 âˆ’v2, u, v),
if x < 0, âƒ—X(6)(u, v) = (âˆ’

1 âˆ’u2 âˆ’v2, u, v).
The inverses for each of these parametrizations give coordinate charts Ï†i =
âƒ—Xâˆ’1
(i) : Ui â†’Vi, which together form an atlas on the sphere (see Figure 3.3).
One notices in this case that all Vi = {(u, v) | u2 + v2 < 1}. Also, not
all Ui overlap. For example, U1 âˆ©U2 = âˆ…(i.e., the empty set) and similarly
for U3 âˆ©U4 and U5 âˆ©U6. To show that the sphere equipped with this atlas
is a diï¬€erentiable manifold, one must show that all transition functions are
C1. We illustrate this with Ï†31 = Ï†3 â—¦Ï†âˆ’1
1 .
The identiï¬cation (Â¯u, Â¯v) = Ï†3 â—¦Ï†âˆ’1
1 (u, v) is equivalent to
(Â¯u,

1 âˆ’Â¯u2 âˆ’Â¯v2, Â¯v) = (u, v,

1 âˆ’u2 âˆ’v2).
This leads to
Ï†1(U1 âˆ©U3) = {(u, v) | u2 + v2 < 1 and v > 0},
Ï†3(U1 âˆ©U3) = {(Â¯u, Â¯v) | Â¯u2 + Â¯v2 < 1 and Â¯v > 0},

86
3. Differentiable Manifolds
and
Ï†31(u, v) = (u,

1 âˆ’u2 âˆ’v2).
It is now easy to verify that Ï†31 is of class C1 over Ï†1(U1 âˆ©U3). In fact,
higher derivatives of Ï†31 involve polynomials in u and v possibly divided
by powers of
âˆš
1 âˆ’u2 âˆ’v2. Hence, over Ï†1(U1 âˆ©U3), the function Ï†31 is
of class Câˆ. It is not hard to see that all other transition functions are
similar. Thus, this atlas A = {(Ui, Ï†i)}6
i=1 equips S2 with the structure of
a smooth manifold.
Example 3.1.6 (Projective Space). The n-dimensional real projective space RPn
is deï¬ned as the set of lines in Rn+1 through the origin.
No two lines
through the origin intersect any place else and, for each point p in Rn,
there exists a unique line through the origin and p. Therefore, one can de-
scribe RPn as the set of equivalence classes of points in Rn+1âˆ’{(0, 0, . . ., 0)}
under the equivalence relation
(x0, x1, . . . , xn) âˆ¼(y0, y1, . . . , yn)
if and only if
(y0, y1, . . . , yn) = (Î»x0, Î»x1, . . . , Î»xn) for some Î» âˆˆR âˆ’{0}.
One often designates the equivalence class of a point (x0, x1, . . . , xn) by the
notation (x0 : x1 : . . . : xn). The set RPn is a topological space with the
identiï¬cation topology coming from Rn+1 âˆ’{0}.
One can deï¬ne an atlas on RPn as follows. Note that if (x0, x1, . . . , xn) âˆ¼
(y0, y1, . . . , yn), then for any i, we have xi = 0 if and only if yi = 0. For
i âˆˆ{0, 1, . . ., n}, deï¬ne Ui = {(x0 : x1 : . . . : xn) âˆˆRPn | xi Ì¸= 0} and deï¬ne
Ï†i : Ui â†’Rn by
Ï†i(x0 : x1 : . . . : xn) =
x0
xi
, x1
xi
, . . . , &
xi
xi
, . . . , xn
xi
	
,
where the 'a indicates ignoring that entry. It is easy to see that each Ï†i is a
homeomorphism between Ui and Rn. Furthermore, U0 âˆªÂ· Â· Â· âˆªUn includes
all ratios (x0 : . . . : xn) for which not all xi = 0. Thus, U0 âˆªÂ· Â· Â·âˆªUn = RPn.
Now assume, without loss of generality, that i < j and analyze the
change of coordinates in any Uiâˆ©Uj. We have Ï†i(Uiâˆ©Uj) = {(a1, . . . , an) âˆˆ
Rn | aj Ì¸= 0} and Ï†j(Ui âˆ©Uj) = {(a1, . . . , an) âˆˆRn | ai+1 Ì¸= 0}.
(The
diï¬€erence comes from i < j.)
Then the change-of-coordinate function
Ï†j â—¦Ï†âˆ’1
i
is

3.1. Deï¬nitions and Examples
87
Ï†j â—¦Ï†âˆ’1
i (a1, a2, . . . , an) = Ï†j(a1 : a2 : . . . :
1
()*+
ith
: . . . : an)
=
â›
âœ
âœ
âœ
â
a1
aj
, a2
aj
, . . . ,
1
aj
()*+
ith
, . . . , &
aj
aj
()*+
jth
, . . . , an
aj
â
âŸ
âŸ
âŸ
â .
It is easy to see that this is indeed a bijection between Ï†i(Ui âˆ©Uj) and
Ï†j(Ui âˆ©Uj). Furthermore, all higher partial derivatives of Ï†j â—¦Ï†âˆ’1
i
exist
over Ï†i(Ui âˆ©Uj).
The same reasoning works if i > j. Therefore, this atlas satisï¬es the
condition required to equip RPn with the structure of a smooth manifold.
Before providing more examples, we must emphasize a technical aspect
to the deï¬nition of a diï¬€erentiable manifold. If M is a topological manifold
not inherently deï¬ned as the subset of a Euclidean space, one does not show
whether M is or is not a diï¬€erentiable manifold, but rather, one discusses
whether one can equip M with a diï¬€erentiable atlas.
This amounts to
providing a set M with an atlas A = {Ï†Î±}Î±âˆˆI that satisï¬es Deï¬nition 3.1.3.
Two diï¬€erentiable (respectively, Ck, smooth, analytic) atlases {Ï†Î±} and
{Ïˆi} on a topological manifold M are said to be compatible if the union
of the two atlases is again an atlas on M in which all the transition func-
tions are diï¬€erentiable (respectively, Ck, smooth, analytic). Interestingly
enough, not all atlases are compatible in a given category. It is also possible
for the union of two atlases of class Ck to form an atlas of class Cl, with
l < k. The notion of compatibility between atlases is an equivalence rela-
tion, and an equivalence class of diï¬€erentiable (respectively, Ck, smooth,
analytic) atlases is called a diï¬€erentiable (respectively, Ck, smooth, ana-
lytic) structure. Proving that a given topological manifold has a unique
diï¬€erentiable structure or enumerating the diï¬€erentiable structures on a
given topological manifold involves techniques that are beyond the scope
of this book. For example, in 1963, Kervaire and Milnor proved that S7
has exactly 28 nondiï¬€eomorphic smooth structures [28].
Example 3.1.7. We point out that for any integer n â‰¥1, the Euclidean space
Rn is an n-dimensional manifold. (The standard atlas consists of only one
function, the identity function on Rn.)
Example 3.1.8. A manifold M of dimension 0 is a set of points with the
discrete topology, i.e., every subset of M is open. If M is a subset of Rn,

88
3. Differentiable Manifolds
then the points of M are isolated. The notion of diï¬€erentiability is vacuous
over a 0-dimensional manifold.
Note that this example indicates that a manifold is not necessarily con-
nected but may be a union of connected components, each of which is a
manifold in its own right.
When working with examples of manifolds in Rk, it is often easier to
specify coordinate charts x : U âŠ‚M n â†’Rn by providing a parametrization
xâˆ’1 : x(U) â†’M n that is homeomorphic with its image. Since the chart is
a homeomorphism, this habit does not lead to any diï¬ƒculties.
Example 3.1.9. Consider a trefoil knot K in R3. One can realize K as the
image of the parametric curve
Î³(t) = ((2 + cos(3t)) cos(2t), (2 + cos(3t)) sin(2t), sin(3t))
for t âˆˆR. We can choose an atlas of K as follows. Set one coordinate
patch on K to be U1 = Î³((0, 2Ï€)) and another coordinate patch to be
U2 = Î³((Ï€, 3Ï€)). Use as charts the functions Ï†1 and Ï†2, which are the
inverse functions of Î³ : (0, 2Ï€) â†’K and Î³ : (Ï€, 3Ï€) â†’K, respectively.
Now
Ï†2(U1 âˆ©U2) = (Ï€, 2Ï€) âˆª(2Ï€, 3Ï€)
and
Ï†1(U1 âˆ©U2) = (0, Ï€) âˆª(Ï€, 2Ï€),
and the coordinate transition functions are
Ï†1 â—¦Ï†âˆ’1
2 (t) =

t,
if t âˆˆ(Ï€, 2Ï€),
t âˆ’2Ï€,
if t âˆˆ(2Ï€, 3Ï€);
Ï†2 â—¦Ï†âˆ’1
1 (t) =

t + 2Ï€,
if t âˆˆ(0, Ï€),
t,
if t âˆˆ(Ï€, 2Ï€).
Both of these transition functions are diï¬€erentiable on their domains. This
shows that K, equipped with the given atlas, is a 1-manifold.
From the previous example, it is easy to see that any regular, simple,
closed curve in Rk can be given an atlas that gives it the structure of a
diï¬€erentiable 1-manifold. Our intuition might tell us that, say, a square in
the plane should not be a diï¬€erentiable 1-manifold because of its corners.
This idea, however, is erroneous, as we shall now explain.
Example 3.1.10. Consider the square with unit length side, and deï¬ne two
chart functions as follows. The function Ï†1 measures the distance traveled

3.1. Deï¬nitions and Examples
89
0
1
2
3
4
1
2
3
4
5
Figure 3.4. A square as a diï¬€erentiable manifold.
as one travels around the square in a counterclockwise direction, starting
with a value of 0 at (0, 0). The function Ï†2 measures the distance traveled
as one travels around the square in the same direction, starting with a value
of 1 at (1, 0) (see Figure 3.4).
The functions Ï†1 and Ï†2 are homeomorphisms, and the coordinate tran-
sition function is
Ï†1 â—¦Ï†âˆ’1
2
: (1, 4) âˆª(4, 5) â†’(0, 1) âˆª(1, 4),
with
Ï†1 â—¦Ï†âˆ’1
2 (x) =

x,
if x âˆˆ(1, 4),
x âˆ’4,
if x âˆˆ(4, 5).
This transition function (and its inverse, the other transition function) is
diï¬€erentiable over its domain.
Therefore, the atlas {Ï†1, Ï†2} equips the
square with the structure of a diï¬€erentiable manifold.
This example shows that, in and of itself, the square can be given the
structure of a diï¬€erentiable 1-manifold. However, this does not violate our
intuition about diï¬€erentiability and smoothness because one only perceives
the â€œsharpâ€ corners of the square in reference to the diï¬€erential structure
of R2.
Once we have the appropriate deï¬nitions, we will say that the
square is not a submanifold of R2 with the usual diï¬€erential structure (see
Deï¬nition 3.4.1). In fact, the atlases in Examples 3.1.9 and 3.1.10 bear
considerable similarity, and, ignoring the structure of the ambient space,
both the square and the knot resemble a circle. We develop these notions
further when we consider functions between manifolds.
It is not hard to verify that a regular surface S in R3 (see Deï¬ni-
tion 3.1.1) is a diï¬€erentiable 2-manifold.
The only nonobvious part is
showing that the properties of coordinate patches of a regular surface imply

90
3. Differentiable Manifolds
Figure 3.5. Not a bijection.
p
p
q
q
Figure 3.6. The Klein bottle.
that the coordinate transition functions are diï¬€erentiable. We leave this as
an exercise for the reader (see Problem 3.1.6).
Parametrized surfaces that are not regular surfaces provide examples
of geometric sets in R3 that are not diï¬€erentiable manifolds. For exam-
ple, with the surface in Figure 3.5, for any point along the line of self-
intersection, there cannot exist an open set of R2 that is in bijective cor-
respondence with any given neighborhood of p. However, the notion of a
regular surface in R3 has more restrictions than that of a 2-manifold for
two reasons. Applying the ideas behind Example 3.1.10, a circular (single)
cone can be given the structure of a diï¬€erentiable manifold even though it
is not a regular surface. Furthermore, not every diï¬€erentiable 2-manifold
can be realized as a regular surface or even as a union of such surfaces in
R3. A simple example is the Klein bottle, deï¬ned topologically as follows.
Consider a rectangle, and identify opposite edges according to Figure 3.6.
One pair of sides is identiï¬ed directly opposite each other (the horizontal
edges in Figure 3.6), and the other pair of sides is identiï¬ed in the reverse
direction.
It is not hard to see that the Klein bottle can be given an atlas that
makes it a diï¬€erentiable 2-manifold. However, it turns out that the Klein
bottle cannot be realized as a regular surface in R3.
Despite the ï¬‚exibility of the deï¬nition of a manifold with a given dif-
ferential structure, it does not allow for a boundary. In many interesting
applications, it is useful to have the notion of a manifold with a boundary.
A separate deï¬nition is needed.
Deï¬nition 3.1.11. A diï¬€erentiable n-manifold M with boundary has the same
deï¬nition as in Deï¬nition 3.1.3 except that the codomains for the charts

3.1. Deï¬nitions and Examples
91
can be open subsets of the half-space
{(x1, x2, . . . , xn) âˆˆRn | xn â‰¥0}.
The boundary of the manifold, written âˆ‚M, is the set consisting of all points
mapped to {(x1, x2, . . . , xn) | xn = 0} by a chart.
For simplicity of notation, we will write Rn
+ for {(x1, x2, . . . , xn) âˆˆ
Rn | xn â‰¥0} and will refer to it as the upper half-space in Rn.
Proposition 3.1.12. Let M be a diï¬€erentiable (respectively, Ck, smooth, an-
alytic) n-manifold with boundary. Its boundary âˆ‚M is a diï¬€erentiable (re-
spectively, Ck, smooth, analytic) (n âˆ’1)-manifold without boundary.
Proof: Let A = {Ï†Î±}Î±âˆˆI be an atlas for M, where the codomain for all
charts is Rn
+. Consider the projection Ï€ : Rn
+ â†’Rnâˆ’1 deï¬ned by ignoring
the last coordinate xn. Let Iâ€² be the subset of the indexing set I such that
the domain of Ï†Î± contains points of âˆ‚M. For Î± âˆˆIâ€², since Ï€|xn=0 is a
homeomorphism with Rnâˆ’1, then the restricted function ÏˆÎ± = (Ï€ â—¦Ï†Î±)|âˆ‚M
is a homeomorphism onto its image.
Furthermore, the domains of ÏˆÎ±
for Î± âˆˆIâ€² cover âˆ‚M.
Since the transition functions for the collection
Aâ€² = {ÏˆÎ±}Î±âˆˆIâ€² are restrictions of the transition functions of M, then âˆ‚M
has the same diï¬€erential (respectively, Ck, smooth, or analytic) structure
as M.
â–¡
Example 3.1.13. As an example of a manifold with boundary, consider the
half-torus in R3 given as the image of âƒ—X : [0, Ï€] Ã— [0, 2Ï€] â†’R3, with
âƒ—X(u, v) = ((2 + cos v) cos u, (2 + cos v) sin u, sin v) .
The image of âƒ—X is a half-torus M with y â‰¥0, which, to conform to Deï¬ni-
tion 3.1.11, is easily covered by four coordinate patches. The boundary âˆ‚M
is the disconnected manifold with the following two connected components:
R+ = {(x, y, z) | (x + 2)2 + z2 = 1, y = 0},
Râˆ’= {(x, y, z) | (x âˆ’2)2 + z2 = 1, y = 0}.
Deï¬nition 3.1.14 (Orientability).
Let M n be a diï¬€erentiable n-manifold
equipped with an atlas {Ï†Î±}Î±âˆˆI. Suppose that for any two charts Ï†Î± and
Ï†Î² of the atlas, the Jacobian of the transition function Ï†Î²Î± = Ï†Î² â—¦Ï†âˆ’1
Î±
is
positive at all points in the domain. Then M is called an oriented manifold
or is referred to as an orientable manifold.

92
3. Differentiable Manifolds
Deï¬nition 3.1.15. Let M n be a diï¬€erentiable n-manifold equipped with two
separate atlases A = {Ï†Î±}Î±âˆˆI and B = {ÏˆÎ²}Î²âˆˆJ. Suppose that both atlases
equip M with the structure of an oriented manifold. The atlases A and B
are said to have equivalent orientations if the atlas A âˆªB also makes M
an oriented manifold. An equivalence class of oriented atlases is called an
orientation.
Example 3.1.16. Returning to Example 3.1.4 of the sphere, it turns out that
the atlas {Ï€N, Ï€S} does not show that the sphere is orientable. However, the
atlas {Ï€N, Â¯Ï€S} does give the sphere an oriented structure, where Â¯Ï€S is the
composition of Ï€S with the reï¬‚ection (u, v) â†’(u, âˆ’v) so that Â¯Ï€S(x, y, z) =
(x/(1 + z), âˆ’y/(1 + z)). Writing (Â¯u, Â¯v) = Â¯Ï€S â—¦Ï€âˆ’1
N (u, v), we get
Â¯u =
u
u2 + v2
and
Â¯v = âˆ’
v
u2 + v2 .
We easily ï¬nd that the Jacobian is
âˆ‚(Â¯u, Â¯v)
âˆ‚(u, v) =

âˆ‚Â¯u
âˆ‚u
âˆ‚Â¯u
âˆ‚v
âˆ‚Â¯v
âˆ‚u
âˆ‚Â¯v
âˆ‚v
 =

u2âˆ’v2
(u2+v2)2
âˆ’
2uv
(u2+v2)2
2uv
(u2+v2)2
u2âˆ’v2
(u2+v2)2

=
1
(u2 + v2)2 .
(3.1)
This shows that the atlas {Ï€N, Â¯Ï€S} gives the sphere the structure of an
oriented smooth manifold. From now on, we will typically use this atlas as
the standard atlas on S2.
We end the section by deï¬ning the product structure of two manifolds.
Deï¬nition 3.1.17. Let M m and N n be two diï¬€erential (respectively, Ck,
smooth, analytic) manifolds.
Call their respective atlases {Ï†Î±}Î±âˆˆI and
{Ïˆi}iâˆˆJ. Consider the set M Ã— N that is equipped with the product topol-
ogy. If Ï† : U â†’Rm is a chart for M and Ïˆ : V â†’Rn is a chart for
N, then deï¬ne the function Ï† Ã— Ïˆ : U Ã— V â†’Rm+n.
The collection
{Ï†Î± Ã— Ïˆi}(Î±,i)âˆˆIÃ—J deï¬nes a diï¬€erential (respectively, Ck, smooth, ana-
lytic) structure on M Ã— N, called the product structure.
Consider, for example, the circle S1 with a smooth structure.
The
product S1Ã—S1 is topologically equal to a (two-dimensional) torus, and the
product structure deï¬nes a smooth structure on the torus. By extending
this construction, one can deï¬ne the 3-torus as the manifold T 3 = S1 Ã—
S1 Ã— S1 and inductively the n-torus as T n = T nâˆ’1 Ã— S1.

3.1. Deï¬nitions and Examples
93
Problems
3.1.1. Stereographic Projection.
One way to deï¬ne coordinates on the surface
of the sphere S2 given by x2 + y2 + z2 = 1 is to use the stereographic
projection of Ï€ : S2 âˆ’{N} â†’R2, where N = (0, 0, 1), deï¬ned as follows.
Given any point p âˆˆS2, the line (pN) intersects the xy-plane at exactly
one point, which is the image of the function Ï€(p). If (x, y, z) are the
coordinates for p in S2, let us write Ï€(x, y, z) = (u, v) (see Figure 3.2).
(a) Prove that Ï€(x, y, z) = (x/(1 âˆ’z), y/(1 âˆ’z)).
(b) Prove that
Ï€âˆ’1(u, v) =

2u
u2 + v2 + 1,
2v
u2 + v2 + 1, u2 + v2 âˆ’1
u2 + v2 + 1
	
.
(c) Prove that, using stereographic projections, it is possible to cover
the sphere with two coordinate neighborhoods.
3.1.2. Consider the n-dimensional sphere Sn = {(x1, . . . , xn+1) âˆˆRn+1 | x2
1+Â· Â· Â·+
x2
n+1 = 1}. Exhibit an atlas that gives Sn the structure of a diï¬€erentiable
n-manifold. Explicitly show that the atlas you give satisï¬es the axioms of
a manifold.
3.1.3. Explicitly show that solid ball Bn = {(x1, . . . , xn) âˆˆRn | x2
1+Â· Â· Â·+x2
n â‰¤1}
is a smooth n-manifold with boundary and show that its boundary is the
sphere Snâˆ’1.
3.1.4. Let V be an open set in Rk, and let f : V â†’Rm be a diï¬€erentiable
function. Prove that the graph of f,
f(x) = {(x, f(x)) âˆˆRk+m | x âˆˆV },
is a diï¬€erentiable k-manifold.
3.1.5. Describe an atlas for the 3-torus T 3 = S1 Ã— S1 Ã— S1. Find a parametric
function X : U â†’R4, where U is a subset of R3, such that the image of
X is a 3-torus.
3.1.6. Prove that a regular surface in R3 (see Deï¬nition 3.1.1) is a diï¬€erentiable
2-manifold.
3.1.7. Show that if M is a compact manifold, then so is âˆ‚M. [Hint: See Deï¬ni-
tion A.3.45.]
3.1.8. Prove that if M is an orientable manifold with boundary, then âˆ‚M is also
orientable.
3.1.9. Consider X the subset of R2 given as the graph of the function f(x) = |x|.
Deï¬ne a set of charts on X in which the charts are deï¬ned as restrictions
to X of functions R2 â†’R that are smooth on R2 in the usual sense. Show
that this set of charts does not equip X with a diï¬€erentiable structure.

94
3. Differentiable Manifolds
3.1.10. Consider the following two parametrizations of the circle S1 as a sub-
set of R2:
X1(t) = (cos t, sin t)
for t âˆˆ(0, 2Ï€),
Y1(t) =
1 âˆ’t2
1 + t2 ,
2t
1 + t2
	
.
Find functions X2 and Y2 â€œsimilarâ€ to X1 and Y1 respectively, to make
{X1, X2} and {Y1, Y2} atlases that give S1 diï¬€erentiable structures. Show
that these two diï¬€erentiable structures are compatible.
3.1.11. Consider the real projective plane RP2. The atlas described for RP2 has
three coordinate charts.
(a) Calculate explicitly all six of the coordinate transition functions, and
verify directly that Ï†ij = Ï†âˆ’1
ji .
(b) Show that RP2 is not orientable.
3.1.12. Show that RPn is orientable if and only if n is odd.
3.1.13. Consider S2 to be the unit sphere in R3. Consider the parametrizations
f : (0, 2Ï€) Ã— (0, Ï€) â†’S2,
with
f(u, v) = (cos u sin v, sin u sin v, cos v),
g : (0, 2Ï€) Ã— (0, Ï€) â†’S2,
with
g(Â¯u, Â¯v) = (âˆ’cos Â¯u sin Â¯v, cos Â¯v, sin Â¯u sin Â¯v).
We have seen that f is injective and so is a bijection onto its range.
(a) Find the range U of f and the range V of g.
(b) Determine f âˆ’1(x, y, z) and gâˆ’1(x, y, z), where (x, y, z) âˆˆS2.
(c) Show that the set of functions {(U, f âˆ’1), (V, gâˆ’1)} forms an atlas for
S2 and equips S2 with a diï¬€erentiable structure.
3.2
Differentiable Maps between Manifolds
From a purely set-theoretic perspective, it is easy to deï¬ne functions be-
tween manifolds. Since diï¬€erentiable manifolds are topological manifolds
to begin with, one can easily discuss continuous functions between mani-
folds just as one does in the context of topology. However, a diï¬€erential
structure on a manifold expressed by a speciï¬c atlas allows one to make
sense of the notion of diï¬€erentiable maps between manifolds.
Deï¬nition 3.2.1. Let M m and N n be diï¬€erentiable (respectively, Ck, smooth,
analytic) manifolds. A continuous function f : M m â†’N n is said to be dif-
ferentiable (respectively, Ck, smooth, analytic) if for any chart y : V â†’Rn

3.2. Differentiable Maps between Manifolds
95
R2
R2
x
U
x(U)
M
f
y
V
y(V )
N
y â—¦f â—¦xâˆ’1
Figure 3.7. Diï¬€erentiable map between manifolds.
on N and for any chart x : U â†’Rm on M, the map
y â—¦f â—¦xâˆ’1 : x(U âˆ©f âˆ’1(V )) âŠ‚Rm âˆ’â†’y(V ) âŠ‚Rn
is a diï¬€erentiable (respectively, Ck, smooth, analytic) function (see Fig-
ure 3.7).
In the above deï¬nition, the domain and codomain of yâ—¦fâ—¦xâˆ’1 may seem
complicated, but the domain is simply the natural one for this composition
of functions.
Note that from the deï¬nition it follows that a function between two
manifolds cannot have a stronger diï¬€erentiability property than do the
manifolds themselves.
In linear algebra, where one studies the category of vector spaces, one
does not study properties of any kind of function between two vector spaces.
Instead, we restrict the attention to linear transformations. In an intuitive
sense, one does this because linear transformations â€œpreserve the structureâ€
of vector spaces. Furthermore, from the perspective of linear algebra, two
vector spaces V and W are considered the same (isomorphic) if there ex-
ists a bijective linear transformation between the two. In the same way,
in the category of diï¬€erentiable manifolds, one is primarily interested in
diï¬€erentiable (or perhaps Ck or smooth) maps between these manifolds.

96
3. Differentiable Manifolds
The following deï¬nition is the equivalent notion of an isomorphism but for
manifolds.
Deï¬nition 3.2.2. Let M and N be two diï¬€erentiable manifolds. A diï¬€eomor-
phism (respectively, Ck diï¬€eomorphism) between M and N is a bijective
function F : M â†’N such that F is diï¬€erentiable (respectively, Ck) and
F âˆ’1 is diï¬€erentiable (respectively, Ck). If a diï¬€eomorphism exists between
M and N, we say that M and N are diï¬€eomorphic.
Example 3.2.3. Consider the map f : S2 â†’RP2 that identiï¬es antipodal
points on the unit sphere
f(x, y, z) = (x : y : z)
for any (x, y, z) âˆˆS2. For S2, we use the atlas {Ï€N, Â¯Ï€S} as presented in
Example 3.1.16, and for RP2, we use the atlas in Example 3.1.6, namely,
Ï†i : Ui â†’R2 for 0 â‰¤i â‰¤2, with Ï†i(x0 : x1 : x2) = (. . . , Ë†xi, . . .).
For each pairing of coordinate charts we have
Ï†i â—¦f â—¦Ï€âˆ’1
N (u, v) = Ï†i

2u
u2 + v2 + 1 :
2v
u2 + v2 + 1 : u2 + v2 âˆ’1
u2 + v2 + 1
	
and
Ï†i â—¦f â—¦Â¯Ï€âˆ’1
S (u, v) = Ï†i

âˆ’
2u
u2 + v2 + 1 :
2v
u2 + v2 + 1 : u2 + v2 âˆ’1
u2 + v2 + 1
	
.
In all six cases, the resulting functions are diï¬€erentiable functions R2 â†’
R2. This shows that the antipodal identiï¬cation map f : S2 â†’RP2 is
diï¬€erentiable.
Example 3.2.4. Similar to the real projective space RPn, we can also deï¬ne
the complex projective space CPn as follows.
Deï¬ne the relation âˆ¼on
nonzero (n + 1)-tuples in Cn+1 by (z0, z1, . . . , zn) âˆ¼(w0, w1, . . . , wn) if and
only if there exists Î» âˆˆC such that wi = Î»zi for 0 â‰¤i â‰¤n. This relation
is an equivalence relation, and the complex projective space CPn is the set
of equivalence classes. In fewer words, one typically writes
CPn =

Cn+1 âˆ’{(0, . . . , 0)}

/ {(z0, z1, . . . , zn) âˆ¼(Î»z0, Î»z1, . . . , Î»zn), for Î» âˆˆC} .
One writes (z0 : z1 : Â· Â· Â· : zn) for the equivalence class of (z0, z1, . . . , zn).
The stereographic projection Ï€N of the sphere onto the plane sets up a
homeomorphism h between CP1 and the unit 2-sphere S2 such that
h(z0 : z1) =

Ï€âˆ’1
N (z1/z0),
if z0 Ì¸= 0,
(0, 0, 1),
if z0 = 0.

3.2. Differentiable Maps between Manifolds
97
Note that if z0 Ì¸= 0, then there is a unique zâ€² such that (z0 : z1) = (1, zâ€²),
namely, zâ€² = z1/z0, and that if z0 = 0, then (z0 : z1) = (0, z1) for all
z1 Ì¸= C âˆ’{0}. Therefore, one sometimes says that CP1 is the complex
plane C with a â€œpoint at inï¬nity,â€ where this point at inï¬nity corresponds
to the class of (0 : z1). The function h is a bijection that maps the point
at inï¬nity to the north pole of the sphere, but we leave it as an exercise
for the reader to verify that this function is indeed a homeomorphism.
In complex analysis, one studies holomorphic (i.e., analytic) functions.
This notion is tantamount to diï¬€erentiable in the complex variable. Any
holomorphic function f : C â†’C deï¬nes a map pf : S2 â†’S2 by identifying
R2 with C and
pf(q) =

Ï€âˆ’1
N â—¦f â—¦Ï€N(q),
if q Ì¸= (0, 0, 1),
(0, 0, 1),
if q = (0, 0, 1).
(That pf must send (0, 0, 1) to (0, 0, 1) follows from Liouvilleâ€™s Theorem in
complex analysis.)
Consider S2 as a diï¬€erentiable manifold with atlas {Ï€N, Â¯Ï€S}, as de-
scribed in Example 3.1.16. It is interesting to notice that, according to
Example 3.1.16, the change-of-coordinates map Â¯Ï€S â—¦Ï€N corresponds to
z â†’1/z over C âˆ’{0}.
Take for example f(z) = z2. The associated function pf leaves (0, 0, âˆ’1)
and (0, 0, 1) ï¬xed and acts in a nonobvious manner on S2. According to
Deï¬nition 3.2.1, in order to verify the diï¬€erentiability of pf as a function
S2 â†’S2, we need to determine explicitly the four combinations
(Ï€N or Â¯Ï€s) â—¦pf â—¦(Ï€N or Â¯Ï€s)âˆ’1
and show that they are diï¬€erentiable on their appropriate domains.
Setting z = u + iv, we have z2 = (u2 âˆ’v2) + (2uv)i. Since we are using
the stereographic projection from the north pole to deï¬ne pf in the ï¬rst
place, we have Ï€N â—¦pf â—¦Ï€âˆ’1
N (u, v) = (u2 âˆ’v2, 2uv). Determining the other
three combinations, we ï¬nd that
Ï€N â—¦pf â—¦Ï€âˆ’1
N (u, v) = (u2 âˆ’v2, 2uv),
Â¯Ï€S â—¦pf â—¦Ï€âˆ’1
N (u, v) =
 u2 âˆ’v2
(u2 + v2)2 , âˆ’
2uv
(u2 + v2)2
	
,
Ï€N â—¦pf â—¦Â¯Ï€âˆ’1
S (u, v) =
 u2 âˆ’v2
(u2 + v2)2 , âˆ’
2uv
(u2 + v2)2
	
,
Â¯Ï€S â—¦pf â—¦Â¯Ï€âˆ’1
S (u, v) = (u2 âˆ’v2, 2uv).

98
3. Differentiable Manifolds
It is not hard to show that, with f(z) = z2, the corresponding natural
domains of these four functions are R2, R2 âˆ’{(0, 0)}, R2 âˆ’{(0, 0)}, and
R2. Then it is an easy check that all these functions are diï¬€erentiable on
their domain and, hence, that pf is a diï¬€erentiable function from S2 to S2.
Since R is a one-dimensional manifold, if M is a diï¬€erentiable manifold,
then one can discuss whether a real-valued function f : M â†’R is diï¬€eren-
tiable by testing it against Deï¬nition 3.2.1. Suppose also that p is a point
of M and that x : U â†’Rm is a coordinate chart of a neighborhood of p.
We can write x as an m-tuple of functions x = (x1, x2, . . . , xm). Then we
deï¬ne the partial derivative of f at p in the xi coordinate as
âˆ‚f
âˆ‚xi

p
def
= âˆ‚(f â—¦xâˆ’1)
âˆ‚xi

x(p)
.
(3.2)
The notation on the left-hand side is deï¬ned as the partial derivative of the
right-hand side, which is taken in the usual multivariable calculus sense.
The notion of a diï¬€erentiable map between diï¬€erentiable manifolds also
allows us to easily deï¬ne what we mean by a curve on a manifold.
Deï¬nition 3.2.5. Let M be a diï¬€erentiable manifold. A diï¬€erentiable curve
on M is a diï¬€erentiable function f : (a, b) â†’M, where the interval (a, b)
is understood as a one-dimensional manifold with the diï¬€erential structure
inherited from R. A diï¬€erentiable curve with endpoints on M is a diï¬€eren-
tiable function f : [a, b] â†’M, where the interval [a, b] is understood as a
one-dimensional manifold with boundary. A closed diï¬€erentiable curve on
M is a diï¬€erentiable function f : S1 â†’M, where S1 is the circle manifold.
Problems
3.2.1. Consider the antipodal identiï¬cation map described in Example 3.2.3. Ex-
plicitly write out all six functions Ï†i â—¦f â—¦Ï€N and Ï†i â—¦f â—¦Â¯Ï€S. Prove that
each one is diï¬€erentiable on its natural domain.
3.2.2. In Example 3.2.4, with f(z) = z2, consider points on the unit sphere S2
with coordinates (x, y, z) âˆˆR3. Express pf on S2 âˆ’{(0, 0, 1)} in terms of
(x, y, z)-coordinates by calculating Ï€âˆ’1
N â—¦f â—¦Ï€N(x, y, z).
3.2.3. Consider the torus T 2 in R3 parametrized by
X(u, v) = ((2 + cos v) cos u, (2 + cos v) sin u, sin v)
for (u, v) âˆˆ[0, 2Ï€]2. Consider the Gauss map of the torus n : T 2 â†’S2
that sends each point of the torus to its outward unit normal vector as an
element of S2. Using the stereographic projection of the sphere, explicitly
show that this Gauss map is diï¬€erentiable.

3.3. Tangent Spaces and Differentials
99
3.2.4. Consider the (unit) sphere given with the atlas deï¬ned by stereographic
projection A = {(S2 âˆ’{(0, 0, 1)}, Ï€N), (S2 âˆ’{(0, 0, âˆ’1)}, Â¯Ï€S)}, where
(u, v) = Ï€N(x, y, z) =

x
1 âˆ’z ,
y
1 âˆ’z
	
and
(Â¯u, Â¯v) = Â¯Ï€S(x, y, z) =

x
1 + z , âˆ’
y
1 + z
	
.
Consider the function f : S2 â†’R given by f(x, y, z) = z in terms of
Cartesian coordinates.
(a) Show that for points in the sphere in the coordinate chart of Ï€N, a
formula for the partial derivatives of f is
âˆ‚f
âˆ‚u =
4u
(u2 + v2 + 1)2
and
âˆ‚f
âˆ‚v =
4u
(u2 + v2 + 1)2 .
(b) Find a formula for the partial derivatives âˆ‚f
âˆ‚Â¯u and âˆ‚f
âˆ‚Â¯v over the coor-
dinate chart Â¯Ï€S.
(c) Explain in what sense these partial derivatives are equal over S2 âˆ’
{(0, 0, 1), (0, 0, âˆ’1)}.
[Hint: Use the chain rule and the Jacobian
matrix from Equation (3.1).]
3.2.5. Consider the 3-sphere described by S3 = {(z1, z2) âˆˆC2 | |z1|2 + |z2|2 = 1}.
Consider the function f : S3 â†’S2 deï¬ned by f(z1, z2) = (z1 : z2) where
we identify S2 with CP1. Prove that this function is diï¬€erentiable. (This
function is called the Hopf map.)
3.2.6. Let f : Rn+1 âˆ’{0} â†’Rm+1 âˆ’{0} be a diï¬€erentiable map. Let d âˆˆZ, and
suppose that f is such that f(Î»x) = Î»df(x) for all Î» âˆˆR âˆ’{0} and all
x âˆˆRn+1 âˆ’{0}. Such a map is said to be homogeneous of degree d. For
any x âˆˆRk+1 âˆ’{0}, denote by Â¯x the corresponding equivalence class in
RPk. Show that the map F : RPn â†’RPm deï¬ned by F(Â¯x) = f(x) is well
deï¬ned and diï¬€erentiable.
3.3
Tangent Spaces and Differentials
3.3.1
Tangent Vectors
In the local theory of regular surfaces S âŠ‚R3, the tangent plane plays a
particularly important role. One also deï¬nes the ï¬rst fundamental form on
the tangent plane as the restriction of the dot product in R3 to the tangent.
From the coeï¬ƒcients of the ï¬rst fundamental form, one obtains all the con-
cepts of intrinsic geometry, which include angles between curves, areas of

100
3. Differentiable Manifolds
regions, Gaussian curvature, geodesics, and even the Euler characteristic
(see references to intrinsic geometry in [5]). The deï¬nition of a real diï¬€er-
entiable manifold, however, makes no reference to an ambient Euclidean
space, so one cannot imitate the theory of surfaces in R3 to deï¬ne a tangent
space to a manifold as a vector subspace of some Rn.
The reader can anticipate that to circumvent this diï¬ƒculty, we must
take a step in the direction of abstraction.
The strategy is to deï¬ne a
tangent vector as a directional derivative at a point p of a real-valued
function on a manifold M. Furthermore, since we cannot use vectors in
an ambient Euclidean space to provide the notion of direction, we simply
talk about curves on M through p as providing a notion of direction. The
following construction makes this precise.
Deï¬nition 3.3.1. Let M m be a diï¬€erentiable manifold, p be a point on M,
and let U be an open neighborhood of M. Let Îµ > 0, and let Î³ : (âˆ’Îµ, Îµ) â†’U
be a diï¬€erentiable curve on M such that Î³(0) = p. For any diï¬€erentiable
function f : U âŠ‚M â†’R, we deï¬ne the directional derivative of f along Î³
to be the number
DÎ³(f) = d
dt(f(Î³(t)))

t=0.
(3.3)
The operator DÎ³ is called the tangent vector to Î³ at p. If Î³1 and Î³2 are
two curves, then we set DÎ³1 = DÎ³2 if these operators have the same value
at p for all diï¬€erentiable functions f : U â†’R.
Note that f â—¦Î³ is a function (âˆ’Îµ, Îµ) â†’R, so the derivative in Equa-
tion (3.3) is taken as a usual real function. It is also interesting to observe
that the above deï¬nition does not explicitly refer to any particular chart
on U.
The above deï¬nition of a tangent vector may initially come as a source
of mental discomfort since it presents tangent vectors as operators instead
of as the geometric objects with which one is used to working. However, any
tangent vector (deï¬ned in the classical sense) to a regular surface S in R3
naturally deï¬nes a directional derivative of a function S â†’R so Deï¬nition
3.3.1 generalizes the usual notion of a tangent vector (see [5, Section 5.2]).
Furthermore, as the name â€œtangent vectorâ€ suggests, the set of all tangent
vectors forms a vector space, a fact that we show now.
Call C1(U, R) the set of all diï¬€erentiable functions from U to R. A
priori, the set of tangent vectors DÎ³ at p on M is a subset of all operators
W = {C1(U, R) â†’R}. As a set of functions with domains in R, one can
naturally deï¬ne addition and scalar multiplication on W. We need to show

3.3. Tangent Spaces and Differentials
101
that the set of tangent vectors is closed under scalar multiplication and
addition.
Let Î³ : (âˆ’Îµ, Îµ) â†’M be a diï¬€erentiable curve with Î³(0) = p. If we
deï¬ne Î³1(t) = Î³(at), where a is some real number, then using the usual
chain rule for any diï¬€erentiable function f âˆˆC1(U, R), we have
DÎ³1(f) = d
dt(f(Î³(at)))

t=0 = a d
dt(f(Î³(t)))

t=0 = aDÎ³(f).
This shows that the set of tangent vectors is closed under scalar multipli-
cation.
In order to prove that the set of tangent vectors is closed under addition,
we make reference to the coordinate chart x : U â†’Rm. We rewrite the
composition f â—¦Î³ = f â—¦xâˆ’1 â—¦x â—¦Î³ where x â—¦Î³ : (âˆ’Îµ, Îµ) â†’Rm and
f â—¦xâˆ’1 : x(U) âŠ‚Rm â†’R. By the chain rule in multivariable analysis,
Theorem (1.3.3), we have
DÎ³(f) = d
dt(f(Î³(t)))

t=0
= d
dt(f â—¦xâˆ’1(x â—¦Î³(t)))

t=0
= d(f â—¦xâˆ’1)pd(x â—¦Î³)

t=0.
Now let x : U â†’Rm be a coordinate chart of a neighborhood of p on
M such that x(p) = (0, Â· Â· Â· , 0). Let Î± and Î² be two diï¬€erentiable curves
on M such that Î±(0) = Î²(0) = p. Over the intersection of the domains of
Î± and Î², deï¬ne the curve Î³ by
Î³(t) = xâˆ’1 (x â—¦Î±(t) + x â—¦Î²(t)) .
Then for any function f : U â†’R, we have
DÎ±(f) + DÎ²(f) = d(f â—¦xâˆ’1)pd(x â—¦Î±)|t=0 + d(f â—¦xâˆ’1)pd(x â—¦Î²)|t=0
= d(f â—¦xâˆ’1)p (d(x â—¦Î±)|t=0 + d(x â—¦Î²)|t=0)
= d(f â—¦xâˆ’1)pd(x â—¦Î± + x â—¦Î²)|t=0
= DÎ³(f).
Thus, the set of tangent vectors is closed under addition. This brings
us in a position to prove the following foundational fact.
Proposition 3.3.2. Let M be a diï¬€erentiable manifold of dimension m, and
let p be a point of M. The set of all tangent vectors to M at p is a vector
space of dimension m with basis {âˆ‚/âˆ‚xi | i = 1, . . . , m}.

102
3. Differentiable Manifolds
Deï¬nition 3.3.3. The vector space of tangent vectors is called the tangent
space of M at p and is denoted by TpM.
Proof (of Proposition 3.3.2): The prior discussion has shown that the set
TpM is a vector space. It remains to be shown that it has dimension m.
Let x : U â†’Rm be a system of local coordinates at p. Write x(q) =
(x1(q), . . . , xm(q)), and deï¬ne the coordinate line curve vi : (âˆ’Îµ, Îµ) â†’M by
vi(t) = xâˆ’1(0, . . . , 0, t, 0, . . ., 0) where the t occurs in the ith place. Then
Dvi(f) = d
dt

f â—¦xâˆ’1(0, . . . , 0, t, 0, . . ., 0)
 
t=0 = âˆ‚f
âˆ‚xi

p
according to the notation given in Equation (3.2). We can therefore write,
as operators, Dvi =
âˆ‚
âˆ‚xi |p.
For any diï¬€erentiable curve Î³ on M with Î³(0) = p, we can then write
in coordinates x â—¦Î³(t) = (Î³1(t), . . . , Î³m(t)), where Î³i = xi(Î³(t)). Then
DÎ³(f) = d
dtf â—¦xâˆ’1(Î³1(t), . . . , Î³m(t))

t=0
=
m

i=1
âˆ‚f
âˆ‚xi

p
dÎ³i
dt

t=0.
This presents the operator DÎ³ as a linear combination of the operators
âˆ‚
âˆ‚xi |p.
It is also a trivial matter to show that for 1 â‰¤i â‰¤m, the operators
âˆ‚
âˆ‚xi |p are linearly independent. Consequently, they form a basis of TpM,
which proves that dim TpM = m.
â–¡
Because the operators
âˆ‚
âˆ‚xi occur so often in the theory of manifolds,
one often uses an abbreviated notation. Whenever the coordinate system
is understood by context, where one uses x = (x1, . . . , xn) or another letter,
we write
âˆ‚i
def
=
âˆ‚
âˆ‚xi ,
(3.4)
whose explicit meaning is given by Equation (3.2). This notation shortens
the standard partial derivative notation and makes it easier to write it in
inline formulas.
The tangent space TpM to M at p carries additional structure than
just a vector subspace of W. Any tangent vector X âˆˆTpM is an operator
on C1(U, R). More precisely, X is a derivation on the algebra C1(U, R) of
functions because it satisï¬es

3.3. Tangent Spaces and Differentials
103
1. linearity: X(af + bg) = aX(f) + bX(g) for all f, g âˆˆC1(U, R) and
a, b âˆˆR;
2. Leibnizâ€™s rule: X(fg) = X(f)g(p) + f(p)X(g) for all f, g âˆˆC1(U, R).
(An algebra is a vector space V with the additional structure of a multi-
plication between elements of V that only has to satisfy distributivity over
the addition of the vector space.)
Example 3.3.4 (Tangent Space of Rn). We consider the tangent space for the
manifold Rn itself.
We assume that the diï¬€erential structure on Rn is
given by the atlas consisting simply of the identity map.
Let p be a point in Rn, and let v = (v1, . . . , vn) be a vector. Consider the
line traced out by the curve Î³(t) = p+tv. We wish to ï¬nd the coordinates of
the tangent vector DÎ³ with respect to the standard basis of TpM, namely,
{ âˆ‚
âˆ‚xi } or, according to the notation of Equation (3.4), {âˆ‚i}. For any real
function f deï¬ned over a neighborhood of p, we have
DÎ³(f) = d
dtf(p1 + tv1, . . . , pn + tvn)

t=0 =
n

i=1
âˆ‚f
âˆ‚xi

pvi
Therefore, with respect to the basis {âˆ‚/âˆ‚xi}, the coordinates of DÎ³ are
(v1, . . . , vn). Thus, at each p âˆˆRn, the map v â†’DÎ³ sets up an isomor-
phism between the vector spaces Rn and Tp(Rn) by identifying âˆ‚i with the
ith standard basis vector. It is common to abuse the notation and view
these spaces as equal.
Example 3.3.5 (Regular Surfaces). Let S be a regular surface in R3. In Chap-
ter 5 of [5], the authors deï¬ne the tangent plane to S at p as the subspace of
R3 consisting of all vectors Î³â€²(0), where Î³(t) is a curve on S with Î³(0) = p.
The correspondence Î³â€²(0) â†”DÎ³ identiï¬es the tangent space for regular
surfaces with the tangent space of manifolds as deï¬ned above. This shows
that the present deï¬nition directly generalizes the previous deï¬nition as a
subspace of the ambient space Rn.
In multivariable calculus, one shows that given a parametrization âƒ—X :
V âŠ‚R2 â†’R3 of a coordinate patch of a regular surface, if p = âƒ—X(u0, v0),
then a basis for TpS is
,
âƒ—Xu(u0, v0), âƒ—Xv(u0, v0)
-
.
The deï¬nition of the tangent plane given in calculus meshes with Deï¬ni-
tion 3.3.1 and Proposition 3.3.2 in the following way. A tangent vector in

104
3. Differentiable Manifolds
the classical sense, âƒ—w âˆˆTpM, is a vector such that âƒ—w = âƒ—Î³â€²(t0), where âƒ—Î³(t) is
a curve on S with âƒ—Î³(t0) = p. Write âƒ—Î³(t) = âƒ—X(Î±(t)), with Î±(t0) = (u0, v0).
Writing Î±(t) = (u(t), v(t)), we have
âƒ—w = uâ€²(t0) âƒ—Xu(u0, v0) + vâ€²(t0) âƒ—Xv(u0, v0).
Now the corresponding coordinate chart x on S in the language of
manifolds is the inverse of the parametrization x = âƒ—Xâˆ’1 deï¬ned over
U = âƒ—X(V ) âŠ‚S. The tangent vector (in the phrasing of Deï¬nition 3.3.1)
associated to Î³ at p is
DÎ³(f) = d
dt (f(âƒ—Î³(t)))

t0 = d
dt

f

âƒ—X(Î±(t))
 
t0 = d
dt

f â—¦xâˆ’1(Î±(t))
 
t0
= uâ€²(t0)âˆ‚f
âˆ‚u

p + vâ€²(t0)âˆ‚f
âˆ‚v

p.
where the partial derivatives
âˆ‚f
âˆ‚u|p and
âˆ‚f
âˆ‚v |p are in the sense of Equa-
tion (3.2). We can write as operators
DÎ³ = uâ€²(t0) âˆ‚
âˆ‚u

p + vâ€²(t0) âˆ‚
âˆ‚v

p.
Therefore, we see that the correspondence between the deï¬nition of the
tangent space for manifolds and the deï¬nition for tangent spaces to reg-
ular surfaces in R3 identiï¬es âƒ—Xu(u0, v0) with
âˆ‚f
âˆ‚u|p and similarly for the
v-coordinate.
3.3.2
The Differential of a Map
Having established the notion of a tangent space to a diï¬€erentiable manifold
at a point, we are in a position to deï¬ne the diï¬€erential of a diï¬€erentiable
map f : M â†’N. In some sense, this is where analysis on manifolds begins.
Recall that in multivariable real analysis, we call a function F : Rm â†’Rn
diï¬€erentiable at a point âƒ—p âˆˆRm if there exists an nÃ—m matrix A such that
F(âƒ—p + âƒ—h) = F(âƒ—p) + Aâƒ—h + R(âƒ—h)âƒ—h,
where R(âƒ—h) is a matrix function such that âˆ¥R(âƒ—h)âˆ¥â†’0 as âˆ¥âƒ—hâˆ¥â†’0. We refer
to the matrix A as the diï¬€erential dFp. Surprisingly, given our deï¬nition
of the tangent space to a manifold, there exists a more natural way to
generalize the diï¬€erential.

3.3. Tangent Spaces and Differentials
105
p
Î³
TpM
Ï†(p)
Ï† â—¦Î³
TÏ†(p)N
Ï†
DÎ³
DÏ†â—¦Î³
dÏ†p
Figure 3.8. The diï¬€erential of a map between manifolds.
Deï¬nition 3.3.6. Let Ï† : M m â†’N n be a diï¬€erentiable map between diï¬€er-
entiable manifolds. We deï¬ne the diï¬€erential of Ï† at p âˆˆM as the linear
transformation between vector spaces
dÏ†p : TpM âˆ’â†’TÏ†(p)N,
DÎ³ âˆ’â†’DÏ†â—¦Î³.
The diï¬€erential dÏ†p is also denoted by Ï†âˆ—when the point p is understood
by context. If X âˆˆTpM, then Ï†âˆ—(X) is also called the push-forward of X
by Ï†. (See Figure 3.8.)
From this deï¬nition, it is not immediately obvious that dÏ†p is linear,
but, as the following proposition shows, we can give an equivalent deï¬nition
of the diï¬€erential that makes it easy to show that the diï¬€erential is linear.
Proposition 3.3.7. Let Ï† : M â†’N be a diï¬€erentiable map between diï¬€eren-
tiable manifolds. Then at each p âˆˆM, the function Ï†âˆ—= dÏ†p satisï¬es
Ï†âˆ—(X)(g) = X(g â—¦Ï†)

106
3. Differentiable Manifolds
for every vector X âˆˆTpM and every function g from N into R deï¬ned in
a neighborhood of Ï†(p). Furthermore, Ï†âˆ—is linear.
Proof: Let X âˆˆTpM, with X = DÎ³, for some curve Î³ on M with Î³(0) = p.
For every real-valued function g deï¬ned in a neighborhood of Ï†(p) on N,
we have
Ï†âˆ—(X)(g) = dÏ†p(DÎ³)(g) = DÏ†â—¦Î³(g)
= d
dt(g â—¦Ï† â—¦Î³)(t)

p = DÎ³(g â—¦Ï†) = X(g â—¦Ï†).
Now, let X, Y âˆˆTpM and a, b âˆˆR. Then
Ï†âˆ—(aX + bY )(g) = aX(g â—¦Ï†) + bY (g â—¦Ï†) = aÏ†âˆ—(X)(g) + bÏ†âˆ—(Y )(g),
which shows that Ï†âˆ—is linear.
â–¡
Note that this deï¬nition is independent of any coordinate system near
p or Ï†(p).
However, given speciï¬c coordinate charts x : U â†’Rm and
y : V â†’Rn whose domains are, respectively, neighborhoods of p in M and
Ï†(p) in N, with f(U) âŠ‚V , we can deï¬ne a matrix that represents dÏ†p. Set
vi as the coordinate line for the variable xi in the chart x. In the usual
basis of TpM, we have
Ï†âˆ—(Dvi) = Ï†âˆ—
 âˆ‚
âˆ‚xi
	
= DÏ†â—¦vi.
However, for any smooth function g : N â†’R,
DÏ†â—¦Î³(g) =
n

j=1
âˆ‚g
âˆ‚yj
d(yj â—¦Ï† â—¦Î³)
dt

t=0
=
n

j=1
âˆ‚g
âˆ‚yj
 m

i=1
âˆ‚(yj â—¦Ï†)
âˆ‚xi
dÎ³i
dt

t=0

,
where Î³i = xi â—¦Î³. Therefore, in terms of these coordinate patches, the
matrix for Ï†âˆ—with respect to the standard bases {âˆ‚/âˆ‚xi} on TpM and
{âˆ‚/âˆ‚yj} on TÏ†(p)N is
[dÏ†p] =
âˆ‚Ï†j
âˆ‚xi
	
p
,
with
1 â‰¤i â‰¤m and 1 â‰¤j â‰¤n,
(3.5)
by which we explicitly mean
âˆ‚Ï†j
âˆ‚xi

p
def
= âˆ‚(yj â—¦Ï† â—¦xâˆ’1)
âˆ‚xi

x(p)
.
(3.6)

3.3. Tangent Spaces and Differentials
107
Example 3.3.8 (Curves on a Manifold). We used the notion of a curve on a
manifold to deï¬ne tangent vectors in the ï¬rst place.
However, we can
now restate the notion of a curve on a manifold as a diï¬€erentiable map
Î³ : I â†’M, where I is an open interval of R and M is a diï¬€erentiable
manifold. The tangent vector DÎ³ âˆˆTÎ³(t0)M to the curve Î³ can also be
understood as
DÎ³ = Î³âˆ—
 d
dt

t0
	
.
Matching with notation from calculus courses, this tangent vector is some-
times denoted as Î³â€²(t0). Then this tangent vector acts on diï¬€erentiable
functions f : M â†’R by
Î³â€²(t0)(f) = Î³âˆ—
 d
dt

t0
	
(f) = d(f â—¦Î³)
dt

t0.
Example 3.3.9 (Gauss Map). Consider a regular oriented surface S in R3 with
orientation n : S â†’S2. (Recall that the orientation is a choice of a unit
normal vector to S at each point such that n : S â†’S2 is a continuous
function.) In the local theory of surfaces, the function n is often called the
Gauss map. The diï¬€erential of the Gauss map plays a central role in this
theory. In that context, one deï¬nes the diï¬€erential of the Gauss map dnp
at a point p âˆˆS in the following way.
A parametrization âƒ—X of a coordinate patch U around p amounts to the
inverse âƒ—X = xâˆ’1 of a chart x : U â†’R2. Similarly, on S2, the parame-
trization âƒ—N = n â—¦âƒ—X is the inverse of a chart y on S2 of a neighborhood
of n(p).
Since âƒ—N : U â†’R3 is a unit vector, by the comments in Sec-
tion 2.2, we know that âƒ—Nu and âƒ—Nv are perpendicular to âƒ—N and hence are
in the tangent space TpS. Hence, one often identiï¬es TpS = Tn(p)(S2). Let
âƒ—X(t) = âƒ—X(âƒ—Î±(t)) be any curve on the surface such that âƒ—X(0) = p. Then dnp
is the transformation on TpS that sends a tangent vector âƒ—Xâ€²(0) âˆˆTp(S) to
d
dt( âƒ—N(âƒ—Î±(t)))|t=0.
Via the association of Î³â€²(0) â†’DÎ³ between the classical and the modern
deï¬nition of the tangent space, we see that the classical deï¬nition of the
Gauss map is precisely Deï¬nition 3.3.6. (Note that Figure 3.8 speciï¬cally
illustrates the diï¬€erential of the Gauss map.)
Over some neighborhood of n(p), âƒ—N : xâˆ’1(U) â†’S2 gives a parametr-
ization of a coordinate neighborhood of n(p) on S2. Write the coordinate
functions as x(q) = (x1(q), x2(q)) and similarly for y. Then the associated

108
3. Differentiable Manifolds
bases on TpS and Tn(p)(S2) are
 âˆ‚
âˆ‚x1 , âˆ‚
âˆ‚x2
 
= { âƒ—Xu, âƒ—Xv}
and
 âˆ‚
âˆ‚y1 , âˆ‚
âˆ‚y2
 
= { âƒ—Nu, âƒ—Nv}.
Thus, with respect to the coordinate charts x and y as described here, the
matrix for dnp is
[dnp] =

ai
j

,
where
âƒ—Nj = a1
j âƒ—X1 + a2
j âƒ—X2,
where by âƒ—Xi, we mean âˆ‚âƒ—X/âˆ‚xi. It is not hard to show that
a1
1
a1
2
a2
1
a2
2
	
= âˆ’
g11
g12
g21
g22
	âˆ’1 L11
L12
L21
L22
	
,
(3.7)
where gij = âƒ—XiÂ· âƒ—Xj and Lij = âƒ—XijÂ· âƒ—N. In classical diï¬€erential geometry, this
matrix equation for the coeï¬ƒcients ai
j is called the Weingarten equations.
As noted in Example 2.4.9, using tensor notation, Equation (3.7) is written
simply as
ai
j = âˆ’gikLkj.
Corollary 3.3.10 (The Chain Rule). Let M, N, and S be diï¬€erentiable mani-
folds, and consider Ï† : M â†’N and Ïˆ : N â†’S to be diï¬€erentiable maps
between them. Then
(Ïˆ â—¦Ï†)âˆ—= Ïˆâˆ—â—¦Ï†âˆ—.
More speciï¬cally, at every point p âˆˆM,
d(Ïˆ â—¦Ï†)p = dÏˆÏ†(p) â—¦dÏ†p .
Proof: By Proposition 3.3.7, for all functions f from a neighborhood of
Ïˆ(Ï†(p)) on S to R and for all X âˆˆTpM, we have
(Ïˆ â—¦Ï†)âˆ—(X)(g) = X(g â—¦Ïˆ â—¦Ï†) = (Ï†âˆ—(X))(g â—¦Ïˆ)
= (Ïˆ(Ï†âˆ—(X)))(g) = Ïˆâˆ—â—¦Ï†âˆ—(X)(g).
â–¡
Deï¬nition 3.3.6 for the diï¬€erential avoids referring to any coordinate
neighborhood of points on M. In contrast to the matrix for the diï¬€erential
introduced in Chapter 1, the matrix for the diï¬€erential dfp of maps be-
tween manifolds depends on the coordinate charts used around p and f(p),
according to Equations (3.5) and (3.6). We can, however, say the following
about how the matrix of the diï¬€erential changes under coordinate changes.

3.3. Tangent Spaces and Differentials
109
Proposition 3.3.11. Let f : M â†’N be a diï¬€erentiable map between diï¬€er-
entiable manifolds.
Let x = (x1, . . . , xm) and Â¯x = (Â¯x1, . . . , Â¯xm) be two
coordinate systems in a neighborhood of p, and let y = (y1, . . . , yn) and
Â¯y = (Â¯y1, . . . , Â¯yn) be two coordinate systems in a neighborhood of f(p). Let
[dfp](x,y) be the matrix for dfp associated to the x- and y- coordinate sys-
tems and similarly for [dfp](Â¯x,Â¯y). Then [dfp](x,y) and [dfp](Â¯x,Â¯y) are similar
matrices. Furthermore,
[dfp](Â¯x,Â¯y) =
 âˆ‚Â¯yi
âˆ‚yj

f(p)
	
[dfp](x,y)
âˆ‚xk
âˆ‚Â¯xl

p
	
.
Proof: (The proof is left as an exercise for the reader.)
â–¡
3.3.3
Orientability and Tangent Spaces
We end this section with a brief comment on the connection between the
orientation of a manifold and the standard bases in coordinate systems.
Let M n be an oriented manifold, and let (U, x) and ( Â¯U, Â¯x) be two over-
lapping coordinate systems on M. Let p âˆˆU âˆ©Â¯U. The ordered bases of
TpM with respect to (U, x) and ( Â¯U, Â¯x), respectively, are
 âˆ‚
âˆ‚x1 , . . . ,
âˆ‚
âˆ‚xn
	
and
 âˆ‚
âˆ‚Â¯x1 , . . . ,
âˆ‚
âˆ‚Â¯xn
	
.
(As a comment on notation, we use usual parentheses ( ) to describe the
basis as an n-tuple of vectors, as opposed to a set notation { }, because the
order of how we list the basis vectors is crucial for the notion of orientabil-
ity.) The transition matrix between these two bases (from the former to the
latter) is given by the matrix (âˆ‚xi/âˆ‚Â¯xj). According to Deï¬nition 3.1.14,
since M is oriented, then
det
 âˆ‚xi
âˆ‚Â¯xj
	
> 0
at p. Hence, given a coordinate patch (U, x) on a connected component
of an orientable manifold, calling the basis ( âˆ‚
âˆ‚x1 , . . . ,
âˆ‚
âˆ‚xn ) as positively
oriented for all p âˆˆU naturally deï¬nes an orientation on that connected
component. Any other basis of TpM given as the standard tangent vectors
of another coordinate patch would also need to be positively oriented in
reference to ( âˆ‚
âˆ‚x1 , . . . ,
âˆ‚
âˆ‚xn ).
Note that if M is a manifold with c connected components, there are
2c possible orientations on M.
This includes the degenerate case of 0-
manifolds that correspond to a set of points equipped with the discrete
topology. In this case, each point can have an orientation of +1 or âˆ’1.

110
3. Differentiable Manifolds
âˆ‚
âˆ‚x1
âˆ‚
âˆ‚x2
âˆ‚
âˆ‚x1
âˆ’
âˆ‚
âˆ‚x2
p
q
M
âˆ‚M
Figure 3.9. Half-torus with boundary.
These comments allow us to induce a natural orientation onto âˆ‚M from
an orientation on M. The following construction is essential for Stokesâ€™
Theorem in Section 4.5.
Let M n be an oriented diï¬€erential manifold with boundary. Let p âˆˆ
âˆ‚M, and let (U, x) be a coordinate neighborhood of p. Recall that since
p âˆˆâˆ‚M, the coordinate function x is a homeomorphism onto an open
subset of Rn
+ = {(x1, . . . , xn) | xn â‰¥0}. The tangent vector âˆ’âˆ‚/âˆ‚xn is in
TpM but not in Tp(âˆ‚M). We say that âˆ’âˆ‚n = âˆ’âˆ‚/âˆ‚xn is a tangent vector
that points outward from âˆ‚M. (The vector âˆ‚n = âˆ‚/âˆ‚xn points inward.)
Deï¬nition 3.3.12. Let M n be an oriented manifold with boundary âˆ‚M. Over
a given coordinate chart U, we say that the basis (âˆ‚1, . . . , âˆ‚nâˆ’1) is the
induced orientation on âˆ‚M if (âˆ’âˆ‚n, âˆ‚1, . . . , âˆ‚nâˆ’1) is positively oriented
and that the induced orientation is the opposite from (âˆ‚1, . . . , âˆ‚nâˆ’1) if
(âˆ’âˆ‚n, âˆ‚1, . . . , âˆ‚nâˆ’1) is negatively oriented on M.
One should note from this deï¬nition that if M is an n-dimensional
manifold with boundary, then (âˆ‚1, . . . , âˆ‚nâˆ’1) is positively oriented on âˆ‚M
if n is even and is negatively oriented if n is odd.
Example 3.3.13. Consider the half-torus M shown in Figure 3.9. The bound-
ary âˆ‚M has two components. The point q is a generic point in a neigh-
borhood that contains the boundary component where p is. If (x1, x2) is a
coordinate system in a neighborhood of p, the boundary component that
contains p is given by x2 = 0. The ï¬gure depicts the basis (âˆ‚1, âˆ‚2) at the
generic point q and also the basis (âˆ’âˆ‚2, âˆ‚1) at p. Since these two bases have
the same orientation (imagine moving the standard basis at q over to p),
then âˆ‚1 determines the induced orientation on âˆ‚M (as opposed to âˆ’âˆ‚1).

3.3. Tangent Spaces and Differentials
111
For the other boundary component, the reasoning is the same except
that one must use at least one other coordinate chart (Â¯x1, Â¯x2) where the
boundary is given by Â¯x2 = 0 and the portion of M that is not on âˆ‚M has
Â¯x2 > 0. Intuitively speaking, in order for (Â¯x1, Â¯x2) to have an orientation
compatible with (x1, x2), one must switch the direction of the basis vector
âˆ‚/âˆ‚Â¯x2 (from what one would obtain from moving âˆ‚/âˆ‚x2 over along a line
of x1 =const.). One must then also switch the sign of âˆ‚/âˆ‚x1 to get the
equivalent âˆ‚/âˆ‚Â¯x1 in order to keep a positively oriented atlas. The induced
orientation on the second boundary component is shown with an arrow.
We set a convention for use later concerning 1-manifolds. Let Î³ : [a, b] â†’
M be a 1-manifold with two boundary points p1 = Î³(a) and p2 = Î³(b).
Then we equip p2 with a positive orientation +1 and p1 with a negative
orientation âˆ’1.
p1
p2
âˆ’1
+1
This association of endpoints to âˆ’1 and +1 as shown above is, by conven-
tion, the induced orientation of Î³ onto âˆ‚Î³.
Problems
3.3.1. Let Ï† : Rm â†’Rn be a linear transformation. Show that under the identiï¬-
cation of Tp(Rk) with Rk as described in Example 3.3.4, Ï†âˆ—gets identiï¬ed
with Ï†.
3.3.2. Consider a diï¬€erentiable manifold M m and a real-valued, diï¬€erentiable
function h : M m â†’R.
Apply Proposition 3.3.7 to show that hâˆ—(X)
corresponds to the diï¬€erential operator
hâˆ—(X) = X(h) d
dt
on functions g : R â†’R, where we assume we use the variable t on R.
3.3.3. Let T 2 be the torus given as a subset of R3 with a parametrization
âƒ—X(u, v) = ((2 + cos v) cos u, (2 + cos v) sin u, sin v) .
Consider the sphere S2 given as a subset of R3, and use the stereographic
atlas {Ï€N, Â¯Ï€s} as the coordinate patches of S2. Consider the map f : T 2 â†’
S2 deï¬ned by
x â†’
x
âˆ¥xâˆ¥.
Explicitly calculate the matrix of the diï¬€erential dfp, with p given in terms
of (u, v)-coordinates for (u, v) âˆˆ(0, 2Ï€)2 and using the stereographic atlas
on the sphere.

112
3. Differentiable Manifolds
3.3.4. Let S3 be the 3-sphere given in R4 by S3 = {u âˆˆR4 : âˆ¥uâˆ¥= 1}, and let S2
be the unit sphere in R3, where we use coordinates (x1, x2, x3). Consider
the Hopf map h : S3 â†’S2 given by
h(u1, u2, u3, u4)=

2(u1u2 + u3u4), 2(u1u4 âˆ’u2u3), (u2
1 + u2
3) âˆ’(u2
2 + u2
4)

.
(a) Show that this map indeed surjects S3 onto S2.
(b) Show that the preimage hâˆ’1(q) of any point q âˆˆS2 is a circle on S3.
(c) For a coordinate patch of your choice on S3 and also on S2, calculate
the diï¬€erential dhp for points p on S3.
(Note that the description of h is equivalent to the one given in Prob-
lem 3.2.5.)
3.3.5. Consider the map F : RP3 â†’RP2 deï¬ned by
f(x : y : z : w) = (x3 âˆ’y3 : xyz âˆ’2xw2 + z3 : z3 + 2yz2 âˆ’6y2z âˆ’w3).
This function is homogeneous, and the result of Problem 3.2.6 ensures that
this map is diï¬€erentiable. Let p = (1 : 2 : âˆ’1 : 3) âˆˆRP3.
(a) After choosing standard coordinate neighborhoods of RP3 and RP2
that contain, respectively, p and f(p), calculate the matrix of dfp
with respect to these coordinate neighborhoods.
(b) Choose a diï¬€erent pair of coordinate neighborhoods for p and f(p)
and repeat the above calculation.
(c) Explain how these two matrices are related.
3.3.6. Consider the spheres S2 and S3, viewed as subsets of R3 and R4, respec-
tively. Assume that we use the atlas {Ï€N, Ï€S} on S2 given by stereographic
projection, as described in Example 3.1.4, and assume that we also use
the atlas {Î N, Î S} on S3 that corresponds to the stereographic projection
(into R3).
(a) Write out Î N and Î s and their inverses as done for S2 in Example
3.1.4.
(b) Suppose that Ï€N deï¬nes the coordinate system (u1, u2) on the open
set U = S2 âˆ’{(0, 0, 1)} on S2, that Î N deï¬nes the coordinate system
(v1, v2, v3) on an open set V of S3, and that we use (x1, x2, x3) as
the coordinates of R3 and (y1, y2, y3, y4) as the coordinates in R4.
Let F : R3 â†’S3 be the function deï¬ned by
f(x1, x2, x3) =

sin(x1) sin(x2) sin(x3), sin(x1) sin(x2) cos(x3), sin(x1) cos(x2), cos(x1)

,
and deï¬ne f : S2 â†’S3 by restricting F to S2 (as a subset of R3).
Calculate the matrix of the diï¬€erential [dfp] for any p âˆˆU given with
respect to (u1, u2)- and (v1, v2, v3)-coordinates.

3.4. Immersions, Submersions, and Submanifolds
113
3.3.7. Example 3.1.6 shows that if we give R3 the coordinates (x0, x1, x2), there
is a natural surjection f : R3 âˆ’{(0, 0, 0)} â†’RP2 via Ï€(x0, x1, x2) = (x0 :
x1, x2). Consider the unit sphere S2 (centered at the origin), and consider
the map g : S2 â†’RP2 given as the restriction of f to S2.
Using the
oriented atlas on the sphere given in Example 3.1.16 and the coordinate
patches for RP2 as described in Example 3.1.6, give the matrix for dgp
between the north pole patch Ï€N and U0. Do the same between the north
pole patch and U1 and explicitly verify Proposition 3.3.11.
3.3.8. Prove Proposition 3.3.11.
3.3.9. Let M1 and M2 be two diï¬€erentiable manifolds, and consider their product
manifold M1 Ã— M2. Call Ï€i : M1 Ã— M2 â†’Mi for i = 1, 2 the projection
maps. Show that for all points p1 âˆˆM1 and p2 âˆˆM2, the linear transfor-
mation
S : T(p1,p2)(M1 Ã— M2) âˆ’â†’Tp1M1 âŠ•Tp2M2,
X âˆ’â†’(Ï€1âˆ—(X), Ï€2âˆ—(X))
is an isomorphism.
3.4
Immersions, Submersions, and Submanifolds
The linear transformation Ï†âˆ—(which is implicitly local to p) and the associ-
ated matrix [dÏ†p] allow us to discuss the relation of one manifold to another.
A number of diï¬€erent situations occur frequently enough to warrant their
own terminologies.
Deï¬nition 3.4.1. Let Ï† : M â†’N be a diï¬€erentiable map between diï¬€eren-
tiable manifolds.
1. If Ï†âˆ—is an injective at all points p âˆˆM, then Ï† is called an immersion.
2. If Ï†âˆ—is a surjective at all points p âˆˆM, then Ï† is called a submersion.
3. If Ï† is an immersion and one-to-one, then the pair (M, Ï†) is called a
submanifold of N.
4. If (M, Ï†) is a submanifold and Ï† : M â†’Ï†(M) is a homeomorphism for
the topology on Ï†(M) induced from N, then Ï† is called an embedding
and Ï†(M) is called an embedded submanifold.
It is important to pause and give examples of the above four situations.
In fact, in the theory of diï¬€erentiable manifolds, it is only in the context of
Deï¬nition 3.4.1 that one can discuss how a manifold â€œsitsâ€ in an ambient

114
3. Differentiable Manifolds
âƒ—Î³(t)
âƒ—Î³â€²(0)
Figure 3.10. Double cone.
Figure 3.11. Enneperâ€™s surface.
Euclidean space by considering a diï¬€erentiable function f : M â†’Rn, where
Rn is viewed as a manifold with its usual diï¬€erential structure.
Clearly, every embedded submanifold is a submanifold and every sub-
manifold is an immersion. These three categories represent diï¬€erent situa-
tions that we addressed when studying regular surfaces in R3. The cylinder
S1 Ã—R is a diï¬€erentiable manifold. We can consider the double cone in Fig-
ure 3.10 as the image of a map f : S1 Ã— R â†’R3 given by
f(u, v) = (v cos u, v sin u, v).
It is not hard to check that at all points p = (u, 0) âˆˆS1 Ã—R, the diï¬€erential
dÏ†p is not injective. Thus, the cone is not an immersion in R3.
Enneperâ€™s surface (see Figure 3.11) is deï¬ned as the locus of the para-
metrization
âƒ—X(u, v) =

u âˆ’u3
3 + uv2, v âˆ’v3
3 + vu2, u2, v2
	
for (u, v) âˆˆR2.
Enneperâ€™s surface can be considered a diï¬€erentiable map of âƒ—X : R2 â†’
R3. It is not hard to check that according to Deï¬nition 3.4.1, Enneperâ€™s
surface is an immersion, but because âƒ—X is not one-to-one, the surface is
not a submanifold. (In Figure 3.11, the locus of self-intersection of the
parametrized surface is indicated in thick black.)
To illustrate the idea of a submanifold that is not an embedded sub-
manifold, consider the ribbon surface in Figure 3.12. One can consider this
surface to be a function between manifolds in the following sense. Consider

3.4. Immersions, Submersions, and Submanifolds
115
âƒ—X
Figure 3.12. Not a homeomorphism.
the two-dimensional manifold without boundary M = (0, 5) Ã— (0, 1) with
the natural product topology and diï¬€erential product structure. Then the
ribbon surface can be viewed as a diï¬€erentiable map f : (0, 5)Ã—(0, 1) â†’R3
between manifolds. The map f is a submanifold but not an embedded sub-
manifold because, as Figure 3.12 shows, open sets on M might not be open
sets on f(M) with the topology induced from R3.
Some authors (usually out of sympathy for their readers) introduce
the theory of â€œmanifolds in Rn.â€ By this one means manifolds that are
embedded submanifolds of Rn. Though not as general as Deï¬nition 3.4.1,
that approach has some merit as it more closely mirrors Deï¬nition 3.1.1
for regular surfaces in R3. However, our current approach to discussing
relations of one manifold to another is more general. Admittedly, it might
seem strange to call a diï¬€erentiable map a submanifold, but, as the above
examples show, this tactic generalizes the various situations of interest for
subsets of R3. Furthermore, this approach again removes the dependence
on an ambient Euclidean space. Consequently, it is not at all strange to
discuss submanifolds of RPn or any other space of interest.
We now wish to spend a few paragraphs discussing embedded subman-
ifolds of a diï¬€erentiable manifold since they occupy an important role in
subsequent sections and allow us to quickly determine certain classes of
manifolds.
Proposition 3.4.2. Let M m be a diï¬€erentiable manifold. An open subset S of
M is an embedded submanifold of dimension m.

116
3. Differentiable Manifolds
y2 âˆ’x3 = 0
Figure 3.13. Not an embedded submanifold.
Proof: Let {Ï†i : Ui â†’Rm}iâˆˆI be the atlas of M. Equip S with the atlas
{Ï†i|S}iâˆˆI. The inclusion map Î¹ : S â†’M is a one-to-one immersion. The
topology of S is induced from M, so S, with the given atlas, is an embedded
submanifold of M.
â–¡
Example 3.4.3. Consider the set MnÃ—n of n Ã— n matrices with real coeï¬ƒ-
cients. We can equip MnÃ—n with a Euclidean topology by identifying MnÃ—n
with Rn2. In particular, MnÃ—n is a diï¬€erentiable manifold. Consider the
subset GLn(R) of invertible matrices in MnÃ—n. We claim that, with the
topology induced from MnÃ—n, GLn(R) is an embedded submanifold. We
can see this by the fact that an n Ã— n matrix A is invertible if and only
if det A Ì¸= 0. However, the function det : MnÃ—n â†’R is continuous, and
therefore,
GLn(R) = det âˆ’1(R âˆ’{0})
is an open subset of Mn. Proposition 3.4.2 proves the claim.
The proof of Proposition 3.4.2 is deceptively simple. If S âŠ‚M, though
the inclusion map Î¹ : S â†’M is obviously one-to-one, one cannot use it to
show that any subset is an embedded submanifold. Consider the subset S
of R2 deï¬ned by the equation y2 âˆ’x3 = 0 (see Figure 3.13). The issue is
that in order to view S as a manifold, we must equip it with an atlas. In
this case, the atlas of R2 consists of one coordinate chart, the identity map.
The restriction of the identity map id|S is not a homeomorphism into an
open subset of R or R2 so cannot serve as a chart. In fact, if we put any
atlas {Ï†i} of coordinate charts on S, the inclusion Î¹ : S â†’R2 is such that
Î¹ â—¦Ï†i will be some regular reparametrization of t â†’(t2, t3), i.e.,
Î¹ â—¦Ï†i(t) = (g(t)2, g(t)3),

3.4. Immersions, Submersions, and Submanifolds
117
where gâ€²(t) Ì¸= 0. Hence,
[dÎ¹t] =

2g(t)gâ€²(t)
3g(t)2gâ€²(t)
	
,
and thus dÎ¹t fails to be an immersion at the point where g(t) = 0, which
corresponds to (0, 0) âˆˆS, the cusp of the curve.
Having a clear deï¬nition of the diï¬€erential of a function between mani-
folds, we can now imitate Deï¬nition 1.4.1 and given a deï¬nition for regular
points and for critical points of functions between manifolds.
Deï¬nition 3.4.4. Let Ï† : M m â†’N n be a diï¬€erentiable map between dif-
ferentiable manifolds. Then any point p âˆˆM is called a critical point if
rank(Ï†âˆ—) < min(m, n), i.e., dÏ†p is not of maximal rank. If p is a critical
point, then the image Ï†(p) is called a critical value. Furthermore, any el-
ement q âˆˆN that is not a critical value is called a regular value (even if
q /âˆˆÏ†(M)).
We remind the reader that this deï¬nition for critical point directly
generalizes all the previous deï¬nitions for critical points of functions (see
the discussion following Deï¬nition 1.4.1). The only novelty here from the
discussion in Chapter 1 was to adapt the deï¬nition for functions from Rm
to Rn to functions between manifolds.
Our main point in introducing the above deï¬nition is to introduce the
Regular Value Theorem. A direct generalization to a similar theorem for
regular surfaces (see [5, Proposition 5.2.13]), the Regular Value Theorem
provides a class of examples of manifolds for which it would otherwise take a
considerable amount of work to verify that these sets are indeed manifolds.
However, we need a few supporting theorems ï¬rst.
Theorem 3.4.5. Let f : M m â†’N n be a diï¬€erentiable function between dif-
ferentiable manifolds, and assume that dfp is injective. Then there exist
charts Ï† at p and Ïˆ at f(p) that are compatible with the respective diï¬€er-
ential structures on M and N and such that Â¯f = Ïˆ â—¦f â—¦Ï†âˆ’1 corresponds
to the standard inclusion
(x1, . . . , xm) âˆ’â†’(x1, . . . , xm, 0, . . . , 0)
of Rm into Rn.
Proof: Let Ï† and Ïˆ be charts on M and N, respectively, for neighborhoods
of p and f(p). If necessary, translate Ï† and Ïˆ so that Ï†(p) and Ïˆ(f(p))

118
3. Differentiable Manifolds
correspond to the origin. Then, with respect to these charts, dfp has the
same matrix as d Â¯f0, so d Â¯f0 is injective by assumption. By a rotation in Rn,
we can assume that the image of d Â¯f0 is {(x1, . . . , xm, 0, . . . , 0) âˆˆRn}.
We wish to change coordinates on Rn via some diï¬€eomorphism h : Rn â†’
Rn that would make Â¯f the standard inclusion. We view Rn as Rm Ã— Rnâˆ’m
and deï¬ne the function h : Rn â†’Rn by
h(x, y) = ( Â¯f(x), y).
(3.8)
Note that the diï¬€erential of h at 0 is dh0 = d Â¯f0 âŠ•id or, as matrices,
[dh0] =

[d Â¯f0]
0
0
Inâˆ’m
	
.
Since d Â¯f0 is injective, we see that dh0 is invertible.
Now, by the Inverse Function Theorem (Theorem 1.4.5), we know that
hâˆ’1 exists and is diï¬€erentiable. Thus, h is a diï¬€eomorphism between open
neighborhoods of the origin in Rn. We reparametrize the neighborhood of
f(p) with the chart hâˆ’1 â—¦Ïˆ. By Equation (3.8), replacing Ïˆ with Ïˆâ€² =
hâˆ’1 â—¦Ïˆ leads to an atlas that is compatible with the given atlas on N.
Furthermore, by construction, the new Â¯f satisï¬es
Â¯f â€²(x) = Ïˆâ€² â—¦f â—¦Ï†âˆ’1(x) = hâˆ’1 â—¦Â¯f(x) = (x, 0)
as desired.
â–¡
The functional relationship discussed in the above proof is often de-
picted using the following diagram:
M m
f

Ï†

N n
Ïˆ

Rn
Â¯
f
 Rn
We say that the diagram is commutative if, when one takes diï¬€erent di-
rected paths from one node to another, the diï¬€erent compositions of the
corresponding functions are equal.
In this simple case, to say that the
above diagram is commutative means that
Ïˆ â—¦f = Â¯f â—¦Ï† .
These kinds of diagrams are often used in algebra and in geometry as a
schematic to represent the kind of relationship illustrated by Figure 3.7.

3.4. Immersions, Submersions, and Submanifolds
119
Corollary 3.4.6. Let M be a diï¬€erentiable manifold of dimension m, and let
S âŠ‚M. The subset S is an embedded submanifold of M of dimension k
if and only if, for all p âˆˆS, there is a coordinate neighborhood (U, Ï†) of p
compatible with the atlas on M such that
U âˆ©S = {(x1, . . . , xk, xk+1, . . . , xm) | xk+1 = Â· Â· Â· = xm = 0}.
Proof: The implication (â†’) follows immediately from Theorem 3.4.5.
For the converse (â†), assume that for all p âˆˆS, there is a coordinate
neighborhood (U, Ï†) in M compatible with the atlas of M satisfying the
condition for S âˆ©U. We cover S with a collection of such open sets {UÎ± âˆ©
S}Î±âˆˆI. Let Ï€ : Rn â†’Rk be the projection that ignores the last n âˆ’k
variables. Then on each coordinate neighborhood, Ï€ â—¦Ï†Î± : UÎ± âˆ©S â†’Rk is
a coordinate chart for S. It is easy to see that
{(UÎ± âˆ©S, Ï€ â—¦Ï†Î±)}Î±âˆˆI
forms an atlas on S that gives S the structure of a diï¬€erentiable manifold.
Furthermore, the inclusion map satisï¬es all the axioms of an embedded
submanifold.
â–¡
The following theorem is similar to Theorem 3.4.5 but applies to local
submersions.
Theorem 3.4.7. Let f : M m â†’N n be a diï¬€erentiable map such that fâˆ—:
TpM â†’Tf(p)N is onto.
Then there are charts Ï† at p and Ïˆ at f(p)
compatible with the diï¬€erentiable structures on M and N, respectively, such
that
Ïˆ â—¦f = Ï€ â—¦Ï†,
where Ï€ is the standard projection of Rm onto Rn by ignoring the last mâˆ’n
variables.
Proof: (The proof mimics the proof of Theorem 3.4.5 and is left to the
reader.)
â–¡
Theorem 3.4.8 (Regular Value Theorem). Suppose that m â‰¥n, let f : M m â†’
N n be a diï¬€erentiable map, and let q be a regular value of f. Then f âˆ’1(q)
is an embedded submanifold of M of dimension m âˆ’n.
Proof: Since m â‰¥n and q is a regular value, then for all p âˆˆf âˆ’1(q), dfp
has rank n.

120
3. Differentiable Manifolds
We ï¬rst prove that the set of points p âˆˆM, where rank dfp = n is an
open subset of M. Let {(UÎ±, Ï†Î±)} be an atlas for M. For all Î±, deï¬ne
gÎ± : UÎ± â†’R, with gÎ±(p) as the product of determinants of all minors
of dfp. Note that there are
m
n

minors in dfp and that, for all Î±, each
function gÎ± is well deï¬ned on the coordinate patch UÎ±. The functions gÎ±
need not induce a well-deï¬ned function g : M â†’R. (One would need
gÎ±|UÎ±âˆ©UÎ² = gÎ²|UÎ±âˆ©UÎ² for all pairs (Î±, Î²).) However, gÎ±(p) = 0 if and only
if rank dfp < n and the rank is independent of any coordinate system, so
gâˆ’1
Î± (0) âˆ©UÎ² = gâˆ’1
Î² (0) âˆ©UÎ±. Deï¬ne VÎ± = gâˆ’1(R âˆ’{0}). Since each gÎ± is
continuous, VÎ± is open and the set
V =
.
Î±âˆˆI
VÎ±
is an open subset of M. By construction, V is precisely the set of points
in which rank dfp = n. Since V is open in M, by Proposition 3.4.2, V is an
embedded submanifold of dimension m.
We consider now the diï¬€erentiable map f|V
: V
â†’N.
Let p âˆˆ
f âˆ’1(q), and let U be a coordinate neighborhood of p in V with coordinates
(x1, . . . , xm). By Theorem 3.4.7, we can assume that U and a coordinate
neighborhood of q in N are such that
f âˆ’1(q) âˆ©U = {(x1, . . . , xn, xn+1, . . . , xm) | xn+1 = Â· Â· Â· = xm = 0}.
By Corollary 3.4.6, f âˆ’1(q) is therefore an embedded submanifold of M. â–¡
The Regular Value Theorem is also called the Regular Level Set Theo-
rem because any subset of the form f âˆ’1(q), where q âˆˆN, is called a level
set of f.
Example 3.4.9 (Spheres). With the Regular Value Theorem at our disposal,
it is now easy to show that certain objects are diï¬€erentiable manifolds. We
consider the sphere Sn as the subset of Rn+1, with
(x1)2 + (x2)2 + Â· Â· Â· + (xn+1)2 = 1.
The Euclidean spaces Rn+1 and R are diï¬€erentiable manifolds with trivial
coordinate charts.
Consider the diï¬€erentiable map f : Rn+1 â†’R de-
ï¬ned by
f(x) = âˆ¥xâˆ¥2.

3.4. Immersions, Submersions, and Submanifolds
121
In the standard coordinates, the diï¬€erential of f is
[dfx] =
â›
âœ
âœ
âœ
â
2x1
2x2
...
2xn+1
â
âŸ
âŸ
âŸ
â .
We note that the only critical point of f is (0, . . . , 0) and that the only
critical value is 0.
Thus, Sn = f âˆ’1(1) is an embedded submanifold of
Rn+1, and hence, Sn is a diï¬€erentiable manifold in its own right when
equipped with the subspace topology of Rn+1.
Problems
3.4.1. Let M be a diï¬€erentiable manifold, and suppose that f : M â†’R is a
diï¬€erentiable map.
Prove that if fâˆ—= 0 at all points of M, then f is
constant on each connected component of M.
3.4.2. Let N be an embedded submanifold of a diï¬€erentiable manifold M. Prove
that at all points p âˆˆN, TpN is a subspace of TpM.
3.4.3. Let M m be a diï¬€erentiable manifold that is embedded in Rn. (By Ex-
ercise 3.4.2, TpM is a subspace of Tp(Rn) âˆ¼= Rn.) Let f : Rn â†’R be a
diï¬€erentiable function deï¬ned in a neighborhood of p âˆˆM. Show that if f
is constant on M, then fâˆ—(v) = 0 for all v âˆˆTpM. Conclude that, viewed
as a vector in Tp(Rn), the diï¬€erential dfp is perpendicular to TpM.
3.4.4. Let M be a diï¬€erentiable manifold, and let U be an open set in M. Deï¬ne
Î¹ : U â†’M as the inclusion map. Prove that for any p âˆˆU, the diï¬€erential
Î¹âˆ—: TpU â†’TpM is an isomorphism.
3.4.5. Let M and N be k-manifolds in Rn, in the sense that they are both
embedded submanifolds. Show that the set M âˆªN is not necessarily an
embedded submanifold of Rn. Give suï¬ƒcient conditions for M âˆªN to be
a manifold.
3.4.6. Suppose that the deï¬ning rectangle of the Klein bottle, as illustrated in
Figure 3.6, is [0, 2Ï€] Ã— [0, 2Ï€]. It is a well-known fact that it is impossible
to embed the Klein bottle in R3. Show that the parametrization
X(u, v) = ((2 + cos v) cos u, (2 + cos v) sin u, sin v cos(u/2), sin v sin(v/2))
gives an embedding of the Klein bottle in R4. (Remark: This parame-
trization is similar to the standard parametrization of the torus in R3 as
the union of circles traced in the normal planes of a planar circle of larger
radius. A planar circle in R4 admits a normal three-space. The parame-
trization X is the locus of a circle in the normal three-space that rotates
in the fourth coordinate dimension by half a twist as one travels around
the circle of larger radius.)

122
3. Differentiable Manifolds
3.4.7. Deï¬ne O(n) as the set of all orthogonal n Ã— n matrices.
(a) Prove that O(n) is a smooth manifold of dimension 1
2n(n âˆ’1).
(b) Consider the tangent space to O(n) at the identity matrix, TI(O(n)),
as a subspace of the tangent space to MnÃ—n (which is MnÃ—n itself).
Prove that A âˆˆMnÃ—n is a tangent vector in TI(O(n)) if and only if
A is skew-symmetric, i.e., AT = âˆ’A.
3.4.8. Prove Theorem 3.4.7.
3.4.9. Let M m and N n be embedded submanifolds of a diï¬€erentiable manifold
Ss, and suppose that m + n > s. Let p âˆˆM âˆ©N. We say that M and N
intersect transversally at p in S if
dim(TpM âˆ©TpN) = m + n âˆ’s,
where the tangent spaces are understood as subspaces of TpS by virtue
of Problem 3.4.2. Show that if M and N intersect transversally at each
point of M âˆ©N, then M âˆ©N is a diï¬€erentiable manifold.
3.5
Chapter Summary
This section introduces nothing new but summarizes the essential points
underlying the concepts of a diï¬€erentiable manifold.
Intuitively speaking, a diï¬€erentiable manifold M of dimension n is a
topological space that locally resembles Rn. This means that around point
p âˆˆM, there is an open set U in which we can talk about coordinates
(x1, . . . , xn) for points in U. A manifold M must be covered by such coor-
dinate patches, and it is possible a given point p âˆˆM lies in more than one
coordinate patch. Whether a manifold is considered topological, diï¬€eren-
tiable, Ck, smooth, or analytic depends on whether the coordinate transi-
tion functions are, respectively, continuous, diï¬€erentiable, Ck, smooth, or
analytic.
In order to do calculus on functions f : M â†’N between two dif-
ferentiable manifolds, one always refers to local coordinate charts, say
x : M â†’Rm on M and y : N â†’Rn on N, so that one may apply
the usual calculus of functions from Rm â†’Rn to y â—¦f â—¦xâˆ’1. A function
f : M â†’N is called diï¬€erentiable if it is â€œlocallyâ€ diï¬€erentiable in the
sense that y â—¦f â—¦xâˆ’1 is diï¬€erentiable for all choices of coordinate charts x
and y.
Since a manifold is deï¬ned without reference to any ambient space,
one must take some care to even deï¬ne the diï¬€erential of a diï¬€erentiable
function f : M â†’N. The diï¬€erential is an operation on â€œdirectionsâ€ near

3.5. Chapter Summary
123
a given point, but without reference to an ambient space, the notion of a
direction of travel is diï¬ƒcult as well. For analysis of functions from Rm to
R, a vector and a directional derivative have well-deï¬ned meanings. For
functions from a manifold M to R, only the notion of a directional derivative
at a point makes sense, and that only in reference to curves passing through
that point. The solution to the problem of deï¬ning a direction vector was
to equate it with a corresponding directional derivative. Though seemingly
abstract compared to usual analysis, this deï¬nition of a tangent vector
works in that it generalizes the idea of a tangent space to a regular surface
in R3 and has the linear algebraic properties one expects for direction
vectors.
With the notion of a tangent vector established and with the tangent
space of a manifold M at a point p, the diï¬€erential at p of a diï¬€erentiable
function f : M â†’N is a linear transformation dfp : TpM â†’Tf(p)N that
describes how the function f aï¬€ects directional derivatives. Deï¬nition 3.3.6
presents the diï¬€erential independently from any reference to coordinate
systems. However, if systems of coordinates x = (x1, . . . , xm) and y =
(y1, . . . , yn) are given for neighborhoods of p and f(p), respectively, then
in the standard coordinates for TpM and Tf(p)N, the matrix of dfp is the
n Ã— m matrix whose (i, j)th entry is the partial derivative
âˆ‚f i
âˆ‚xj ,
where this notation is explicitly given by Equation (3.6).
This matrix
depends on local coordinates of p and f(p), but it changes according to
Proposition 3.3.11 when one changes coordinate systems near p and f(p).
In subsequent chapters, we will further develop the analysis on mani-
folds and discuss applications to physics.


CHAPTER
4
Analysis on Manifolds
In Chapter 3, we introduced the concept of a diï¬€erentiable manifold as
motivated by a search for topological spaces over which it is possible to
do calculus or do physics. The idea of having a topological space locally
homeomorphic to Rn drove the deï¬nition of a diï¬€erentiable manifold. Sub-
sequent sections in that chapter discussed diï¬€erentiable maps between man-
ifolds and the corresponding diï¬€erential. We used these to introduce the
important notions of immersions, submersions, and submanifolds as quali-
ï¬ers of one way manifolds can relate to one another.
The astute reader would point out that we have not so far made good
on our promise to do physics on a manifold, no matter how amorphous that
expression may be. As an illustrative example, consider Newtonâ€™s second
law of motion applied to, say, simple gravity, as follows:
mâƒ—xâ€²â€²(t) = mâƒ—g,
(4.1)
where m is constant and âƒ—g is a constant vector. In introductory physics,
âƒ—x(t) is a curve in R3 and âƒ—xâ€²â€²(t) is its acceleration vector, also in R3. In order
for Equation (4.1) to have meaning, it is essential that the quantities on
both sides of the equation exist in the same Euclidean space. Applying this
type of equation to the context of manifolds poses a variety of diï¬ƒculties.
Firstly, note that a curve in a manifold M is a submanifold Î³ : I â†’M,
where I is an open interval of R, whereas the velocity vector of a curve
at a point p is an element of the tangent plane to M at p. Secondly, the
discussion of diï¬€erentials in Chapter 3 does not readily extend to a concept
of second derivatives for a curve in a manifold. It is not even obvious in
what space a second derivative would exist. Consequently, it is not at all
obvious how to transcribe equations of curves in R3 that involve âƒ—x, âƒ—xâ€², and
âƒ—xâ€²â€² to the context of manifolds.
As a second point of concern, one also encounters numerous diï¬ƒculties
when one tries to express in the context of diï¬€erentiable manifolds the
classical local theory of surfaces in R3 (as presented in [5, Chapter 5]). It
is not diï¬ƒcult to deï¬ne the ï¬rst fundamental form as a bilinear form on
125

126
4. Analysis on Manifolds
TpM. However, since we do not view a given manifold M as a subset of
any Euclidean (vector) space, the concept of normal vectors does not exist.
Therefore, there is no equivalent of the second fundamental form, and all
concepts of curvature become problematic to deï¬ne (see [5, Chapter 6]).
This chapter does not yet discuss how to do physics on a manifold,
but it does begin to show how to do calculus. We study in greater detail
the relationship between the tangent space to a manifold M at p. Also,
in order to overcome the conceptual hurdles mentioned in the previous
paragraphs, we introduce the formalism of vector bundles on a manifold,
discuss vector (and tensor) ï¬elds on the manifold, develop the calculus of
diï¬€erential forms, and end by considering integration on manifolds.
Geometers and physicists both use tensors but usually with very diï¬€er-
ent formalism. The ways of describing tensors are so diï¬€erent that many
mathematicians and physicists do not immediately recognize them as rep-
resenting the same kind of object. As an important aside in this chapter,
we explain in Section 4.2 how the tangent bundle formalism used by math-
ematicians is the same as the component description of tensors usually
preferred by physicists. However, we must begin by introducing the vector
bundle formalism.
4.1
Vector Bundles on Manifolds
A vector bundle over a manifold is a particular case of what is called a
ï¬ber bundle over a topological space. However, as we do not need the full
generality of ï¬ber bundles in this book, we do not develop the notion of
ï¬ber bundles. Instead, we refer the interested reader to [50] or [11].
In Chapter 3, we discussed tangent spaces to manifolds. In particular,
to each point p âˆˆM, we associated a tangent space. The elements of the
tangent space are diï¬€erential operators of diï¬€erentiable functions f : M â†’
R, but despite their abstraction, the diï¬€erential operators properly model
the function of tangent vectors. Since M is not a subset of some Euclidean
space, the tangent spaces TpM are not subspaces of any ambient space
either. A manifold equipped with tangent spaces at each point motivates
the idea of â€œattachingâ€ a vector space to each point p of a manifold M.
Furthermore, from an intuitive perspective, we would like to attach these
vector spaces, in some sense, continuously. We make this formal in the
following deï¬nition.
Deï¬nition 4.1.1.
Let M n be a diï¬€erentiable manifold with atlas A =
{(UÎ±, Ï†Î±)}Î±âˆˆI, and let V be a ï¬nite-dimensional, real, vector space. A

4.1. Vector Bundles on Manifolds
127
vector bundle over M of ï¬ber V is a Hausdorï¬€topological space E with a
continuous surjection Ï€ : E â†’M (called a bundle projection) and a collec-
tion Î¨ of homeomorphisms (called trivializations) ÏˆÎ± : UÎ± Ã—V â†’Ï€âˆ’1(UÎ±)
such that if UÎ± âˆ©UÎ² Ì¸= âˆ…, then
Ïˆâˆ’1
Î²
â—¦ÏˆÎ± : (UÎ± âˆ©UÎ²) Ã— V â†’(UÎ± âˆ©UÎ²) Ã— V
is of the form
Ïˆâˆ’1
Î²
â—¦ÏˆÎ±(p, v) = (p, Î¸Î²Î±(p)v),
where Î¸Î²Î±(p) : UÎ± âˆ©UÎ² â†’GL(V ) is a continuous map into the general
linear group (i.e., the set of invertible transformations from V to V ). The
vector bundle is called diï¬€erentiable (respectively, Ck or smooth) if M
is diï¬€erentiable (respectively, Ck or smooth) and if all the maps involved
are diï¬€erentiable (respectively, Ck or smooth) as maps between manifolds.
A vector bundle is often denoted by a single Greek letter Î¾ or Î·. The
topological space E is called the total space and denoted E(Î¾) while the
manifold M is called the base space and denoted B(Î¾). All of the relevant
data for a vector bundle is implied.
A few examples are in order.
Example 4.1.2 (The Trivial Bundle). Let M n be a manifold with atlas A =
{Ï†Î±}, and let V be a real vector space.
The topological space M Ã— V
is a vector bundle over M. The trivialization maps ÏˆÎ± are all the identity
maps on UÎ± Ã— V and the maps Î¸Î²Î± are the identity linear transformation.
Example 4.1.3. Consider the circle S1 to be a manifold with the following
atlas:
Ï†1 : S1 âˆ’{(1, 0)} â†’(0, 2Ï€),
with Ï†1(cos Î¸, sin Î¸) = Î¸,
Ï†2 : S1 âˆ’{(âˆ’1, 0)} â†’(0, 2Ï€),
with Ï†2(cos(Î¸ + Ï€), sin(Î¸ + Ï€)) = Î¸.
Note that the transition map between these two charts is
Ï†2 â—¦Ï†âˆ’1
1
: (0, Ï€) âˆª(Ï€, 2Ï€) â†’(0, Ï€) âˆª(Ï€, 2Ï€)
Î¸
â†’(Î¸ + Ï€)
mod 2Ï€,
where a mod 2Ï€ is the unique real number r âˆˆ[0, 2Ï€) such that a = 2Ï€k+r
for some k âˆˆZ. Now consider the vector bundle Î¾ of ï¬ber R over S1 deï¬ned
by the map Î¸21 : (0, Ï€) âˆª(Ï€, 2Ï€) â†’GL(R) = R, where
Î¸21(x) =

1,
if 0 â‰¤x â‰¤Ï€,
âˆ’1,
if Ï€ â‰¤x â‰¤2Ï€.

128
4. Analysis on Manifolds
This vector bundle can be realized as a parametrized surface in R4 via
âƒ—X(u, t) =

cos u, sin u, t cos
u
2

, t sin
u
2

, with (u, t) âˆˆ[0, 2Ï€] Ã— R.
This is evidently not the cylinder S1 Ã— R. Furthermore, one can get an
intuition for this set as a MÂ¨obius band of inï¬nite width.
The intuitive stance behind this deï¬nition is that a vector bundle is not
just a manifold with a vector space V associated to each point but that
the vector spaces â€œvary continuouslyâ€ or that the vector bundle is locally
homeomorphic to M Ã— V .
Consider now a diï¬€erentiable manifold, and consider also the disjoint
union of all the tangent planes to M at points p âˆˆM, i.e.,
/
pâˆˆM
TpM = {(p, X) | p âˆˆM and X âˆˆTpM}.
The identity map i : M â†’M is certainly diï¬€erentiable, and we calculate
its diï¬€erential at a point p âˆˆUÎ± âˆ©UÎ² in overlapping charts. Label the
coordinate charts x = Ï†Î± and Â¯x = Ï†Î². According to Equation (3.5), the
matrix of the diï¬€erential of the identity map is
[dip] =

âˆ‚Â¯xj
âˆ‚xi

p

,
and the reader should recall that the explicit meaning of this partial deriva-
tive is given in Equation (3.6). Given any pair of overlapping coordinate
charts, this diï¬€erential is invertible so it is an element in GLn(R) and cor-
responds to the maps Î¸Î²Î±.
One can arrive at this same result in another way. Consider the coor-
dinate systems deï¬ned by Â¯x and x over UÎ± âˆ©UÎ². The chain rule gives, as
operators,
âˆ‚
âˆ‚Â¯xj

p
=
n

i=1
âˆ‚xi
âˆ‚Â¯xj

p
âˆ‚
âˆ‚xi

p
.
(4.2)
(The subscript |p becomes tedious and so in the remaining paragraphs,
we understand the diï¬€erential operators and the matrices as depending on
p âˆˆM.) Recall that (âˆ‚xi/âˆ‚Â¯xj) and (âˆ‚Â¯xj/âˆ‚xi) are invertible matrices to
each other, so, in particular,
n

i=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚Â¯xk
âˆ‚xi = Î´k
j ,
(4.3)

4.1. Vector Bundles on Manifolds
129
where Î´k
j is the Kronecker delta. Note that Equation (4.3) follows from
Equation (4.2) by applying
âˆ‚
âˆ‚Â¯xj to Â¯xk.
Let X âˆˆTpM be a vector in the tangent space.
Suppose that the
vector X has coordinates aj in the basis ( âˆ‚
âˆ‚xj ) and coordinates Â¯aj in the
basis ( âˆ‚
âˆ‚Â¯xj ). Then
X =
n

j=1
Â¯aj âˆ‚
âˆ‚Â¯xj .
Then we have
X =
n

j=1
Â¯aj
n

i=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚
âˆ‚xi =
n

i=1
â›
â
n

j=1
Â¯aj âˆ‚xi
âˆ‚Â¯xj
â
â âˆ‚
âˆ‚xi ,
and so
ai =
n

j=1
Â¯aj âˆ‚xi
âˆ‚Â¯xj .
Multiplying by âˆ‚Â¯xk/âˆ‚xi and summing over i, we obtain
n

i=1
âˆ‚Â¯xk
âˆ‚xi ai =
n

i=1
n

j=1
Â¯aj âˆ‚xi
âˆ‚Â¯xj
âˆ‚Â¯xk
âˆ‚xi
=
n

j=1
Â¯aj
 n

i=1
âˆ‚xi
âˆ‚Â¯xj
âˆ‚Â¯xk
âˆ‚xi

=
n

i=1
âˆ‚Â¯xk
âˆ‚xi ai =
n

j=1
Â¯ajÎ´k
j = Â¯ak.
So this leads to the change-of-coordinates formula
Â¯ak =
n

i=1
âˆ‚Â¯xk
âˆ‚xi ai.
(4.4)
The above calculations are important in their own right, but in terms
of vector bundles, they allow one to conclude the following proposition.
Proposition 4.1.4. Let M n be a diï¬€erentiable manifold. The disjoint union
of all the tangent planes to M
/
pâˆˆM
TpM,
is a vector bundle with ï¬ber Rn over M. It is called the tangent bundle to
M and is denoted by T M.

130
4. Analysis on Manifolds
Figure 4.1. Intuitive picture for a tangent bundle.
Proof: An element of T M is of the form (p, Xp), where p âˆˆM and Xp âˆˆ
TpM. We point out ï¬rst that the bundle projection Ï€ : T M â†’M is simply
the function Ï€(p, Xp) = p.
We have already seen that for each p âˆˆM, the matrix âˆ‚Â¯xk/âˆ‚xi|p is
invertible. It remains to be veriï¬ed that this matrix varies continuously in
p âˆˆM over UÎ± âˆ©UÎ², where x is the coordinate system over UÎ± and Â¯x is
the coordinate system over UÎ². However, âˆ‚Â¯xk/âˆ‚xi|p is the matrix of the
diï¬€erential of Â¯x â—¦xâˆ’1 and the fact that this is continuous is part of the
deï¬nition of a diï¬€erentiable manifold (see Deï¬nition 3.1.3).
â–¡
There is an inherent diï¬ƒculty in visualizing the tangent bundle, and
more generally any vector bundle, to a manifold. Consider the tangent
bundle to a circle. The circle S1 is a one-dimensional manifold that one
typically visualizes as the unit circle as a subset of R2. If one views the
tangent spaces to the circle as subspaces of R2 or even as the geometric
tangent lines to S1 at p, then one would view the union 0
p TpM as a subset
of R2. This is not what is meant by the deï¬nition of T M. The spaces
TpM and TqM do not intersect if p Ì¸= q. At best, if M is an embedded
submanifold of Rn, then TpM may be viewed as a subspace of a diï¬€erent
Rn. Thus, for example, for the circle S1, the tangent bundle T (S1) can be
realized as an embedded submanifold of R4. In fact, one can parametrize
T (S1) by
Y (u, t) = (cos u, sin u, âˆ’t sinu, t cos u)
for
(u, t) âˆˆ[0, 2Ï€] Ã— R.
Thus, even in this simple example, visualizing the tangent bundle requires
more than three dimensions. Nonetheless, it is not uncommon to illustrate
the tangent bundle over a manifold by a picture akin to Figure 4.1.

4.1. Vector Bundles on Manifolds
131
Proposition 4.1.5. If M m is a diï¬€erentiable manifold of dimension m, and
V is a real vector space of dimension n, then a diï¬€erentiable vector bundle
of ï¬ber V over M is a diï¬€erentiable manifold of dimension m + n.
Proof: Let E be a vector bundle of a ï¬ber V over a diï¬€erentiable manifold
M with the data described in Deï¬nition 4.1.1. Since V is isomorphic to Rn,
without loss of generality, letâ€™s take V = Rn. On each open set Ï€âˆ’1(UÎ±) in
the ï¬ber bundle E, consider the function Ï„Î± deï¬ned by the composition
Ï„Î± : Ï€âˆ’1(UÎ±)
Ïˆâˆ’1
Î±
âˆ’âˆ’âˆ’âˆ’â†’UÎ± Ã— Rn
Ï†Î±Ã—id
âˆ’âˆ’âˆ’âˆ’â†’Rm Ã— Rn = Rm+n,
where by Ï†Î± Ã— id we mean the function (Ï†Î± Ã— id)(p, v) = (Ï†Î±(p), v). We
prove that the collection of functions {(Ï€âˆ’1(UÎ±), Ï„Î±)} is an atlas that equips
E with the structure of a diï¬€erentiable manifold.
Since Ï€ is continuous, Ï€âˆ’1(UÎ±) is open and, by construction, the col-
lection of open sets Ï€âˆ’1(UÎ±) cover E. The function Ï†Î± : UÎ± â†’VÎ± is a
homeomorphism, where VÎ± is an open subset of Rm. Therefore, it is easy
to check that for each Î± âˆˆI,
Ï†Î± Ã— id : UÎ± Ã— Rn â†’VÎ± Ã— Rn
is a homeomorphism. Thus, since ÏˆÎ± is a homeomorphism by deï¬nition,
the composition Ï„Î± is also a homeomorphism.
Let (y, v) âˆˆÏ†Î²(UÎ± âˆ©UÎ²)Ã—Rn, and let (p, v) = (Ï†Î² Ã—id)âˆ’1(y, v) so that
(p, v) is in the domain of the trivialization for ÏˆÎ². Then we calculate that
(Ï„Î± â—¦Ï„âˆ’1
Î² )(y, v) =

(Ï†Î± Ã— id) â—¦Ïˆâˆ’1
Î±
â—¦ÏˆÎ² â—¦(Ï†âˆ’1
Î²
Ã— id)

(y, v)
=

Ï†Î± â—¦Ï†âˆ’1
Î² (y), Î¸Î±Î²(p)v

because Ïˆâˆ’1
Î±
â—¦ÏˆÎ²(p, v) = (p, Î¸Î±Î²(p)v) by deï¬nition of a vector bundle.
At this stage, we must use the fact that Î¸Î±Î² is a diï¬€erentiable map be-
tween the diï¬€erentiable manifolds M and GL(Rn). Since GL(Rn) inherits
its manifold structure as an embedded submanifold of Rn2, the following
quantities exist as n Ã— n matrices:
âˆ‚(Î¸Î±Î² â—¦Ï†âˆ’1
Î² )
âˆ‚yi
for 1 â‰¤i â‰¤m.
To simplify notations, we set F = Î¸Î±Î² â—¦Ï†âˆ’1
Î² . Then a simple calculation for
the function Ï„Î± â—¦Ï„ âˆ’1
Î²
as a function from Rm+n into itself gives the following

132
4. Analysis on Manifolds
diï¬€erential as a block matrix:
[d(Ï„Î± â—¦Ï„âˆ’1
Î² )(y,v)] =
â›
âœ
âœ
â
[d(Ï†Î± â—¦Ï†âˆ’1
Î² )y]
0
âˆ‚F
âˆ‚y1 v Â· Â· Â·
âˆ‚F
âˆ‚ym v
F(y)
â
âŸ
âŸ
â .
Furthermore, each of the entries in the above matrix is continuous. This
shows that all the transition functions Ï„Î± â—¦Ï„ âˆ’1
Î²
are of class C1, establishing
that the diï¬€erentiable vector bundle is indeed a diï¬€erentiable manifold. â–¡
It is not hard to see that by adapting the above proof, one can also
show that a Ck (respectively, smooth) vector bundle is a Ck (respectively,
smooth) manifold. However, we point out the following consequence for
tangent bundles to a manifold.
Corollary 4.1.6. If M is a manifold of class Ck and dimension m, then T M
is a manifold of class Ckâˆ’1 and dimension 2m.
Furthermore, if M is
a smooth manifold of dimension m, then T M is a smooth manifold of
dimension 2m.
Proof: This follows from the proof of the above proposition and the fact
that the linear transformation Î¸Î±Î² is (âˆ‚Â¯xj/âˆ‚xi), where (Â¯xj) are the coordi-
nates with respect to Ï†Î² and (xi) are the coordinates with respect to Ï†Î±.
Therefore, in order for the functions Î¸Î±Î² to be of class Cl, the transition
functions Ï†Î² â—¦Ï†âˆ’1
Î±
must be of class Cl+1.
The second claim of the corollary follows immediately.
â–¡
Example 4.1.7 (Tangent Bundle of Rn.). As we saw in Example 3.3.4, the tan-
gent plane to any point p in Rn is again Rn. However, we can now make
the stronger claim that the tangent bundle of Rn is T (Rn) = Rn Ã— Rn. We
can see this from the fact that Rn is a manifold that can be equipped with
an atlas of just one coordinate chart. Then, from Deï¬nition 4.1.1, there is
only one trivialization map. Thus, the tangent bundle is a trivial bundle.
We remind the reader of a few operations on vector spaces and en-
courage the reader who is unfamiliar with multilinear algebra to consult
Appendix C. Given a vector space V of dimension m, the dual V âˆ—, the
symmetric product Symk V , and the alternating product 1k V (see Sec-
tion C.5) are all other vector spaces associated to V . Also, if we are given
a vector space W of dimension n, the direct product V âŠ•W and the ten-
sor product V âŠ—W are new vector spaces. In each case, if V and W are
equipped with bases, there exist natural bases on the new vector spaces.

4.1. Vector Bundles on Manifolds
133
These constructions on vector spaces carry over to vector bundles over
a diï¬€erentiable manifold M in the following way. Let Î¾ be a vector bundle
over M with ï¬ber V , and let Î· be a vector bundle over M with ï¬ber W. It
is possible to construct the following vector bundles over M in such a way
that their bundle data are compatible with the data for Î¾ and Î· and the
properties of the associated ï¬ber:
â€¢ The dual bundle Î¾âˆ—. The ï¬ber is the vector space V âˆ—.
â€¢ The direct sum Î¾ âŠ•Î·. The ï¬ber is the vector space V âŠ•W. The
direct sum is also called the Whitney sum of two vector bundles.
â€¢ The tensor product Î¾ âŠ—Î·. The ï¬ber is the vector space V âŠ—W.
â€¢ The symmetric product Symk Î¾ for some positive integer k. The ï¬ber
is the vector space Symk V .
â€¢ The alternating product 1k Î¾ for some positive integer k. The ï¬ber
is the vector space 1k V .
Each of the above situations requires careful construction and proof
that they are in fact vector bundles over M. We omit the details here but
refer the reader to Chapter 3 in [38] for a careful discussion of how to get
new vector bundles from old ones.
One of the ï¬rst useful bundles constructed from the tangent bundle is
the cotangent bundle, T M âˆ—, the dual to the tangent bundle. We describe
a natural basis on the ï¬bers of T M âˆ—. Recall that if p âˆˆM m, U is an
open neighborhood of p in M, and x : U â†’Rm is a chart for U, then the
operators
âˆ‚1, . . . , âˆ‚m
def
=
âˆ‚
âˆ‚x1

p
, . . . ,
âˆ‚
âˆ‚xm

p
form a basis of TpM. We call this the basis associated to the chart x. The
basis of the dual bundle TpM âˆ—associated to x consists of the covectors of
these basis vectors for TpM, written
dx1, dx2, . . . , dxm,
(4.5)
deï¬ned as the linear function on TpM â†’R such that
dxi(âˆ‚j) = dxi

âˆ‚
âˆ‚xj

p

= Î´i
j =

1
if i = j,
0
if i Ì¸= j.
(4.6)
The dependence on the point p âˆˆM is understood by context.

134
4. Analysis on Manifolds
Example 4.1.8. Consider a regular surface M in R3. M is a two-dimensional
diï¬€erentiable manifold given as an embedded submanifold of R3. Consider
the bundle T M âˆ—âŠ—T M âˆ—over M. Via a comment after Proposition C.4.8,
we identify T M âˆ—âŠ—T M âˆ—as the vector bundle over M such that each ï¬ber at
a point p âˆˆM corresponds to the vector space of all bilinear forms on TpM.
The formalism of vector bundles over manifolds may initially appear
unnecessarily pedantic. However, since in general a manifold need not be
given as a subset of an ambient Euclidean space, it is only in the context
of the tangent bundle on a manifold that one can make sense of tangent
vectors to M at various points p âˆˆM. We discussed how to obtain new
bundles from old ones so that it would be possible to discuss other linear
algebraic objects associated to the tangent bundle, such as bilinear forms
on T M, as in Example 4.1.8.
The value for physics is that if one must study the motion of a particle
or a system of particles that is not in Rn, then the ambient space for this
system would be a manifold.
Without the structure of a diï¬€erentiable
manifold, one cannot talk about diï¬€erentiability at all.
However, on a
diï¬€erentiable manifold, any kind of diï¬€erentiation will be given in reference
to the tangent bundle. It is not hard to imagine the need to do physics on a
sphere, say if one were studying global earth phenomenon but only looking
at the surface of the earth. In some natural problems, the variable space
(the space in which the variables of interest exist) is not a Euclidean space,
and in this context, the equations of dynamics must take into account
the fact that the ambient space is a manifold. Perhaps the most blatant
examples of the need for manifolds come from cosmology, in which it is now
well understood that our universe is not ï¬‚at. Therefore, doing cosmological
calculations (calculations on large portions of the universe) requires the
manifold formalism.
In popular literature, one reads phrases like â€œthe laws of physics break
down at a black hole.â€ The geometric meaning of such a phrase is that
a black hole is a point where the manifold that is the universe is not dif-
ferentiable. The manifold is singular or has a singularity at that point.
In particular, the tangent bundle does not exist at a black hole, and any
equation that involves diï¬€erentials has no meaning.
Problems
4.1.1. Recall the inï¬nite MÂ¨obius strip introduced in Example 4.1.3. Explicitly
describe the bundle projection p and the trivializations Ïˆ1 and Ïˆ2 for the
image of the parametrization âƒ—X(u, t).

4.2. Vector Fields on Manifolds
135
4.1.2. Consider the unit sphere S2 equipped with the oriented stereographic atlas
{Ï€N, Â¯Ï€S} described in Examples 3.1.16 and 3.1.4. Explicitly describe an
atlas for the tangent bundle T (S2) as a manifold and write down the
transition functions for this atlas.
4.1.3. Normal Bundle. Consider a regular surface S in R3. At each point p âˆˆS,
let N(p) be the set of all normal vectors. Explicitly show that the points
in S, along with its normal vectors at corresponding points, form a vector
bundle. Determine the functions Î¸Î²Î± between diï¬€erent trivialization maps.
(This vector bundle is called the normal bundle.)
4.1.4. Normal Bundle.
Let M m be a diï¬€erentiable manifold embedded in Rn
where m < n. Repeat the previous exercise given this situation. Prove
that the dimension of each ï¬ber is n âˆ’m.
4.1.5. In the study of dynamics of a particle, one locates the position of a point
in R3 using its three coordinates.
Therefore, the variable space is R3.
Explain why the variable space for a general solid object (or system of
particles rigidly attached to each other) is R3 Ã—S2 Ã—S1. In particular, why
one requires six variables to completely describe the position of a solid
object in R3.
4.1.6. Provide appropriate details behind the construction of the Whitney sum
of two vector bundles.
4.1.7. Consider the real projective space M = RPn. We view RPn as the set
of one-dimensional subspaces of Rn+1. Consider the set {(V, âƒ—u) âˆˆRPn Ã—
Rn+1 | âƒ—u âˆˆV }.
(a) Show that this is a vector bundle where each ï¬ber has dimension of
one.
(b) Show that this vector bundle is not the trivial bundle.
(This bundle is called the canonical line bundle on RPn.)
4.1.8. Consider the following parametrization for a torus S1Ã—S1 as a subset of R3
âƒ—X(u, v) = ((2 + cos u) cos v, (2 + cos u) sin v, sin u) ,
for (u, v) âˆˆ[0, 2Ï€]Ã—[0, 2Ï€]. Using âƒ—X, given the associated parametrization
of the manifold T(S1 Ã— S1) as a subset of R6.
4.2
Vector Fields on Manifolds
Deï¬nition 4.2.1. Let Î¾ be a vector bundle over a manifold M with ï¬ber V ,
with projection Ï€ : E(Î¾) â†’M. A global section of Î¾ is a continuous map
s : M â†’E(Î¾) such that Ï€ â—¦s is the identity function on M. The set of all
global sections is denoted by Î“(Î¾). Given an open set U âŠ†M, we call a
local section over U a continuous map s : U â†’E(Î¾) such that Ï€ â—¦s is the
identity on U. The set of all local sections on U is denoted by Î“(U; Î¾).

136
4. Analysis on Manifolds
Note that sections of a vector bundle (whether local or global) can
be added or multiplied by a scalar.
If s1, s2 âˆˆÎ“(U; Î¾), then for each
p âˆˆU âŠ†M, s1(p) and s2(p) are vectors in the same ï¬ber Ï€âˆ’1(p), so
as1(p) + bs2(p) is well deï¬ned as an element in Ï€âˆ’1(p), where a and b are
scalars.
Deï¬nition 4.2.2. Let M be a diï¬€erentiable manifold. A global section of
T M is called a vector ï¬eld on M. In other words, a vector ï¬eld associates
to each p âˆˆM a vector X(p) (also denoted by Xp) in TpM. The set of all
vector ï¬elds on M is denoted by X(M). A vector ï¬eld X is said to be of
class Ck if X : M â†’T M is a map of class Ck between manifolds.
Example 4.2.3. Let M be a regular surface in R3. In the local theory of
regular surfaces in R3, the ï¬rst fundamental form (alternatively called the
metric tensor) is the bilinear product Ip(Â·, Â·) on TpM obtained as the re-
striction of the dot product in R3. Therefore, with the formalism of vector
bundles and using Example 4.1.8, the ï¬rst fundamental form is a section
of T M âˆ—âŠ—T M âˆ—. In fact, since Ip(Â·, Â·) is symmetric and deï¬ned for all p,
independent of any particular basis on T M âˆ—âŠ—T M âˆ—, then the metric tensor
is in fact a global section of Sym2 T M âˆ—.
Let p be a point of M, and let U be a coordinate neighborhood of p
with coordinates (x1, x2). This coordinate system deï¬nes the basis
dx1 âŠ—dx1, dx1 âŠ—dx2, dx2 âŠ—dx1, dx2 âŠ—dx2
on TpM âˆ—âŠ—TpM âˆ—.
Furthermore, each basis vector is a local section in
Î“(U, T M âˆ—âŠ—T M âˆ—). The coeï¬ƒcient functions gij of the metric tensor are
functions so that, as an element of Î“(U, T M âˆ—âŠ—T M âˆ—), the metric tensor
can be written as
g11dx1 âŠ—dx1 + g12dx1 âŠ—dx2 + g21dx2 âŠ—dx1 + g22dx2 âŠ—dx2.
Deï¬nition 4.2.4. A tensor ï¬eld of type (r, s) is a global section of the vector
bundle T M âŠ—r âŠ—T M âˆ—âŠ—s.
We are now in a position to connect the usual physics formalism for
tensors (introduced in Section 2.4) over Rn with the modern mathematical
formalism.
Let A be a tensor ï¬eld of type (r, s) on a manifold M n. Over a coordi-
nate patch U of a diï¬€erentiable manifold M with coordinates (x1, x2, . . . , xn),
we write the components of A as Ai1i2Â·Â·Â·ir
j1j2Â·Â·Â·js.
This means that Ai1i2Â·Â·Â·ir
j1j2Â·Â·Â·js

4.2. Vector Fields on Manifolds
137
are nr+s functions U â†’R.
Furthermore, with respect to the basis on
T M âŠ—r
p
âŠ—T M âˆ—âŠ—s
p
associated to the coordinates,
A = Ai1i2Â·Â·Â·ir
j1j2Â·Â·Â·js
âˆ‚
âˆ‚xi1 âŠ—
âˆ‚
âˆ‚xi2 âŠ—Â· Â· Â· âŠ—
âˆ‚
âˆ‚xir âŠ—dxj1 âŠ—dxj2 âŠ—Â· Â· Â· âŠ—dxjs,
where we have used the Einstein summation convention.
If U â€² is another coordinate patch on M with coordinates (Â¯x1, Â¯x2, . . . , Â¯xn),
we label the components of A in reference to this system as Â¯Ak1k2Â·Â·Â·kr
l1l2Â·Â·Â·ls .
Again, these components are a collection of nr+s functions U â€² â†’R. On
the intersection U âˆ©U â€², both sets of components describe the same ten-
sor but in reference to diï¬€erent bases. Following the same reasoning that
proves Equation (4.4), one shows that the components are related to each
other by
Â¯Ak1k2Â·Â·Â·kr
l1l2Â·Â·Â·ls
= âˆ‚Â¯xk1
âˆ‚xi1
âˆ‚Â¯xk2
âˆ‚xi2 Â· Â· Â· âˆ‚Â¯xkr
âˆ‚xir
âˆ‚xj1
âˆ‚Â¯xl1
âˆ‚xj2
âˆ‚Â¯xl2 Â· Â· Â· âˆ‚xjs
âˆ‚Â¯xls Ai1i2Â·Â·Â·ir
j1j2Â·Â·Â·js.
(4.7)
In Deï¬nition 2.4.6, we called the collection of nr+s functions that trans-
form according to Equation (4.7) the components of a tensor of type (r, s).
We have now shown precisely what is meant by a tensor and why their
components transform according to Deï¬nition 2.4.6. Furthermore, in the
process, we have generalized the notion of tensors in Rn to tensor ï¬elds
over a manifold M.
As we promised in the introduction to this chapter, vector bundles on a
manifold allow for the possibility of doing physics on a manifold. We begin
to see this in the following way.
Let Î´ > 0, and let Î³ : (âˆ’Î´, Î´) â†’M be a diï¬€erentiable curve on M.
Recall that we must understand Î³ as a diï¬€erentiable function between
manifolds. Let X be a vector ï¬eld on M so that for each p âˆˆM, Xp is a
tangent vector in TpM. Referring to Example 3.3.8 for notation, the curve
Î³ is called a trajectory of X through p if
Î³â€²(t) = XÎ³(t)
for all t âˆˆ(âˆ’Î´, Î´) and Î±(0) = p. A trajectory is also called an integral curve
of the vector ï¬eld X.
Since a diï¬€erentiable manifold is locally diï¬€eomorphic to Rn, the stan-
dard theorems of existence, uniqueness, and continuous dependence on ini-
tial conditions for ordinary diï¬€erential equations carry over to the context
of diï¬€erentiable manifolds (see [3, Sections 2.7 and 2.8]). These theorems
imply the local existence and uniqueness of trajectories of a vector ï¬eld

138
4. Analysis on Manifolds
Figure 4.2. A vector ï¬eld on a manifold.
through any points on a diï¬€erentiable manifold. We restate these funda-
mental results from the theory of diï¬€erential equations for the context of
manifolds.
Theorem 4.2.5. Let M be a diï¬€erentiable manifold, and let X be a vector
ï¬eld on M. Let p âˆˆM. There exists an open neighborhood U of p in M,
a positive real Î´ > 0, and a diï¬€erentiable map Ï• : (âˆ’Î´, Î´) Ã— U â†’M such
that t â†’Ï•(t, q) for t âˆˆ(âˆ’Î´, Î´) is the unique curve that satisï¬es
âˆ‚Ï•
âˆ‚t = XÏ•(t,q),
and Ï•(0, q) = q.
Note in the above theorem that âˆ‚Ï•
âˆ‚t means the tangent vector Ï•âˆ—( âˆ‚
âˆ‚t|(t,q)).
It is common to write Ï•t(q) for Ï•(t, q). Then one calls the function Ï•t :
U â†’M the local ï¬‚ow of X on M.
Figure 4.2 depicts a vector ï¬eld X on two-dimensional manifold M
(embedded in R3). The black curve is a particular trajectory since every
tangent vector to the curve at p (a point on the curve) is parallel to Xp.
Furthermore, the shown curve is only the locus of the trajectory since the
trajectory itself is a curve parametrized in such a way that the velocity
vector at each point p is exactly Xp.
4.2.1
Push-Forwards of Vector Fields
If F : M â†’N is a diï¬€erentiable map and X is a vector ï¬eld on M, then for
each point p âˆˆM we deï¬ne the vector Fâˆ—Xp âˆˆTF (p)N as the push-forward

4.2. Vector Fields on Manifolds
139
of X by F. This does not in general deï¬ne a vector ï¬eld on N. If F is not
surjective, there is no natural way to deï¬ne a vector ï¬eld associated to X
on N âˆ’F(M). (Even setting the putative push-forward vector ï¬eld to 0 on
N âˆ’F(M) would not ensure a continuous vector ï¬eld on N.) Furthermore,
if F is not injective and if p1 and p2 are preimages of a point q âˆˆF(M), then
nothing guarantees that Fâˆ—(Xp1) = Fâˆ—(Xp2). Thus, the push-forward is not
well deï¬ned in this case. However, we can make the following deï¬nition.
Deï¬nition 4.2.6. Let M and N be diï¬€erentiable manifolds, let F : M â†’N
be a diï¬€erentiable map, let X be a vector ï¬eld on M, and let Y be a vector
ï¬eld on N. We say that X and Y are F-related if Fâˆ—(Xp) = YF (p) for all
p âˆˆM.
With this terminology, the above comment can be rephrased to say that
if X is a vector ï¬eld on M and F : M â†’N is a diï¬€erentiable map, then
there does not necessarily exist a vector ï¬eld on N that is F-related to X.
Proposition 4.2.7. Let F : M â†’N be a diï¬€erentiable map between diï¬€er-
entiable manifolds. Let X âˆˆX(M) and Y âˆˆX(N). The vector ï¬elds X
and Y are F-related if and only if for every open subset U of N and every
function f âˆˆC1(U, R) we have
X(f â—¦F) = (Y f) â—¦F.
Proof: For any p âˆˆM and any f âˆˆC1(U, R), where U is a neighborhood
of F(p), we have
X(f â—¦F)(p) = Xp(f â—¦F) = dFp(Xp)(f) = Fâˆ—(Xp)(f).
On the other hand,
(Y f) â—¦F(p) = (Y f)(F(p)) = YF (p)f.
Thus, X(f â—¦F) = (Y f) â—¦F is true for all f if and only if Fâˆ—(Xp) = YF (p)
for all p âˆˆM. The proposition follows.
â–¡
Though in general vector ï¬elds cannot be pushed forward via a diï¬€eren-
tiable map, we show one particular case in which push-forwards for vector
ï¬elds exist.
Proposition 4.2.8. Let X âˆˆX(M) be a vector ï¬eld, and let F : M â†’N be
a diï¬€eomorphism. There exists a unique vector ï¬eld Y âˆˆX(N) that is F-
related to X. Furthermore, if X is of class Ck and F is a diï¬€eomorphism
of class Ck, then so is Y .

140
4. Analysis on Manifolds
Proof: In order for X and Y to be F-related, we must have Fâˆ—Xp = YF (p).
Therefore, we deï¬ne Yq = Fâˆ—(XF âˆ’1(q)). Since F is a diï¬€eomorphism, the
association q â†’Yq is well deï¬ned. However, we must check this association
is continuous before we can call it a vector ï¬eld.
If (xi) is a coordinate system on a neighborhood of p = F âˆ’1(q) and if
(yj) is a coordinate system on a neighborhood of q, then the coordinates
of Yq are
Yq = âˆ‚F j
âˆ‚xi

F âˆ’1(q)
Xi
F âˆ’1(q)
âˆ‚
âˆ‚yj

q
.
Finally, if F âˆ’1 and X are of class Ck, then by composition and product
rule, the map N â†’T N deï¬ned by q â†’(q, Yq) is of class Ck.
â–¡
4.2.2
The Lie Bracket
We remind the reader that a vector ï¬eld X on a manifold M is such that, at
each point p âˆˆM, we have a diï¬€erential operator on real-valued functions
Xp : C1(M, R) â†’R. It is convenient to think of a vector ï¬eld as a mapping
X : C1(M, R) â†’C0(M, R) via the identiï¬cation
Xf = (p â†’Xp(f)).
Over a coordinate chart U of M with coordinate system (x1, x2, . . . , xn),
we write
Xp =
n

i=1
ai(p)âˆ‚i,
so the real-valued function Xf on M is deï¬ned by
(Xf)(p) =
n

i=1
ai(p) âˆ‚f
âˆ‚xi

p
.
Assume now that M is a C2-manifold and that X is a diï¬€erentiable
vector ï¬eld, i.e., that over any coordinate chart, the corresponding compo-
nents ai are diï¬€erentiable functions M â†’R. With the above interpretation
of a vector ï¬eld on M, we can talk about the functions Y (Xf) or X(Y f),
where X and Y are two diï¬€erentiable vector ï¬elds on M. However, neither
of the operations XY or Y X leads to another vector ï¬eld. Set
X = aiâˆ‚i
and
Y = bjâˆ‚j,

4.2. Vector Fields on Manifolds
141
where we use Einstein summation convention. Then for any function f âˆˆ
C2(M, R), we have
X(Y f) = X(bjâˆ‚jf) =
n

i=1
aiâˆ‚i(bjâˆ‚jf) = ai(âˆ‚ibj)(âˆ‚jf) + aibj(âˆ‚i(âˆ‚jf)).
(4.8)
Thus, we see that f â†’X(Y f)(p) is obviously not a tangent vector to M
at p since it involves a repeated diï¬€erentiation of f. Nonetheless, we do
have the following proposition.
Proposition 4.2.9. Let M be a diï¬€erentiable manifold, and let X and Y be
two vector ï¬elds of class C1. Then the operation f â†’(XY âˆ’Y X)f is
another vector ï¬eld.
Proof: Since the second derivatives of f are continuous, then the mixed
partials with respect to the same variables, though ordered diï¬€erently, are
equal. By using Equation (4.8) twice, we ï¬nd that
(XY âˆ’Y X)f =

aiâˆ‚ibjâˆ‚jf

âˆ’

bjâˆ‚jaiâˆ‚if

=

aiâˆ‚ibj âˆ’biâˆ‚iaj âˆ‚f
âˆ‚xj .
Since for all j = 1, . . . , n the expressions in the above parentheses are
continuous real-valued functions on M, then (XY âˆ’Y X) has the structure
of a vector ï¬eld.
â–¡
Deï¬nition 4.2.10. The vector ï¬eld deï¬ned in Proposition 4.2.9 is called the
Lie bracket of X and Y and is denoted by [X, Y ] = XY âˆ’Y X. If X and Y
are of class Cn, then [X, Y ] is of class Cnâˆ’1. Also, if X and Y are smooth
vector ï¬elds, then so is [X, Y ].
The proof of Proposition 4.2.9 shows that, in a coordinate neighbor-
hood, if X = aiâˆ‚i and Y = bjâˆ‚j, the Lie bracket is
[X, Y ] =

aiâˆ‚ibj âˆ’biâˆ‚iaj
âˆ‚j.
Example 4.2.11. Consider the manifold R3 âˆ’{(x, y, z)|z = 0}, and consider
the two vector ï¬elds
X = xy âˆ‚
âˆ‚x + 1
z
âˆ‚
âˆ‚y âˆ’3yz3 âˆ‚
âˆ‚z ,
Y = âˆ‚
âˆ‚x + (x + y) âˆ‚
âˆ‚z .

142
4. Analysis on Manifolds
The one iterated derivation is
XY f =

xy âˆ‚
âˆ‚x + 1
z
âˆ‚
âˆ‚y âˆ’3yz3 âˆ‚
âˆ‚z
	 âˆ‚f
âˆ‚x + (x + y)âˆ‚f
âˆ‚z
	
= xy âˆ‚2f
âˆ‚x2 + xy âˆ‚f
âˆ‚z + xy(x + y) âˆ‚2f
âˆ‚xâˆ‚z + 1
z
âˆ‚2f
âˆ‚yâˆ‚x + 1
z
âˆ‚f
âˆ‚z
+ 1
z (x + y) âˆ‚2f
âˆ‚yâˆ‚z âˆ’3yz3 âˆ‚2f
âˆ‚zâˆ‚x âˆ’3yz3(x + y)âˆ‚2f
âˆ‚z2 .
The expression Y Xf has exactly the same second derivative expressions
for f, and upon subtracting, we ï¬nd that
[X, Y ] = (XY âˆ’Y X) = âˆ’y âˆ‚
âˆ‚x+ 1
z2 (x+y) âˆ‚
âˆ‚y +

xy + 1
z + 9yz2(x + y)
	 âˆ‚
âˆ‚z .
For speciï¬c calculations, suppose that M is an m-dimensional manifold
and that x : U â†’Rm is a coordinate patch on M. Then xâˆ’1 : x(U) â†’U
is a parametrization of U. Suppose that X âˆˆX(M) and that over U the
components of X are functions ai : M â†’R so that X = aiâˆ‚i. Then the
partial derivative âˆ‚jai is explicitly
âˆ‚(ai â—¦xâˆ’1)
âˆ‚xj
.
In local coordinates, the functions ai are explicitly ai(p) = (aiâ—¦xâˆ’1)(x1, . . . ,
xm). Thus, one calculates these partials if the ai are given in local coordi-
nates or if ai are given as functions M â†’R and we have a parametrization
xâˆ’1 of the coordinate neighborhood U.
The Lie bracket has the following algebraic properties.
Proposition 4.2.12. Let X, Y , and Z be diï¬€erentiable vector ï¬elds on a dif-
ferentiable manifold M. Let a, b âˆˆR, and let f and g be diï¬€erentiable
functions M â†’R. Then the following hold:
1. Anticommutativity: [Y, X] = âˆ’[X, Y ].
2. Bilinearity: [aX + bY, Z] = a[X, Z] + b[Y, Z] and similarly for the
second input to the bracket.
3. Jacobi identity: [[X, Y ], Z] + [[Y, Z], X] + [[Z, X], Y ] = 0.
4. [fX, gY ] = fg[X, Y ] + fX(g)Y âˆ’gY (f)X.
Proof: (The proofs of these facts are straightforward and are left as exer-
cises for the reader.)
â–¡

4.2. Vector Fields on Manifolds
143
p
t
t
âˆ’t
âˆ’t
X
Y
X
Y
p
c(t)
Figure 4.3. The curve paths deï¬ning c(t).
Besides the algebraic properties, the Lie bracket also carries a more
geometric interpretation. The bracket [X, Y ] measures an instantaneous
path dependence between the integral curves of X and Y . To be more
precise, for suï¬ƒciently small t âˆˆ(âˆ’Îµ, Îµ), consider the curve c(t) that
â€¢ starts at a point c(0) = p;
â€¢ follows the integral curve of X starting at p for time t;
â€¢ starting from there, follows the integral curve of Y for time t;
â€¢ then follows the integral curve of X backwards by time âˆ’t;
â€¢ then follows the integral curve of Y backwards by time âˆ’t.
(See Figure 4.3.) If Ï•t is the ï¬‚ow for X and Ïˆt is the ï¬‚ow for Y , then this
curve c : (âˆ’Îµ, Îµ) â†’M is
c(t) = Ïˆâˆ’t(Ï†âˆ’t(Ïˆt(Ï†t(0)))).
Two properties are obvious. If t approaches 0, then c(t) approaches p.
Also, if x is a system of coordinates on a patch U of M and if X =
âˆ‚1 and Y = âˆ‚2, then the above steps for the description of c(t) travel
around a â€œsquareâ€ with side t based at p, and thus c(t) is constant. Other
properties are not so obvious, and we refer the reader to [49, Proposition
5.15, Theorem 5.16] for proofs.
Proposition 4.2.13. Deï¬ning the curve c(t) as above,
1. câ€²(0) = 0;
2. câ€²â€²(0) is a derivation and hence an element of TpM;
3. câ€²â€²(0) = 2[X, Y ]p.

144
4. Analysis on Manifolds
Consequently, from an intuitive perspective, the Lie bracket [X, Y ] is
a vector ï¬eld that at p measures the second-order derivation of c(t) at p.
Since the ï¬rst derivative câ€²(0) is 0, then câ€²â€²(0) = 2[X, Y ]p gives the direction
of motion of c(t) out of p as a second-order approximation.
Problems
4.2.1. Let M = R2. Calculate the Lie bracket [X, Y ] for each of the following
pairs of vector ï¬elds:
(a) X = x âˆ‚
âˆ‚x + y âˆ‚
âˆ‚y and Y = âˆ’y âˆ‚
âˆ‚x + x âˆ‚
âˆ‚y .
(b) X = sin(x + y) âˆ‚
âˆ‚x + cos x âˆ‚
âˆ‚y and Y = cos x âˆ‚
âˆ‚x + sin y âˆ‚
âˆ‚y .
4.2.2. Let M = R3. Calculate the Lie bracket [X, Y ] for each of the following
pairs of vector ï¬elds:
(a) X = z2 âˆ‚
âˆ‚x + xy âˆ‚
âˆ‚z and Y = (x + y3) âˆ‚
âˆ‚y + yz âˆ‚
âˆ‚z .
(b) X = yz âˆ‚
âˆ‚x + xz âˆ‚
âˆ‚y + xy âˆ‚
âˆ‚z and Y = x âˆ‚
âˆ‚x + y âˆ‚
âˆ‚y + z âˆ‚
âˆ‚z .
(c) X = ln(x2 + 1) âˆ‚
âˆ‚y + tanâˆ’1(xy) âˆ‚
âˆ‚z and Y = âˆ‚
âˆ‚x.
4.2.3. Let M = S2 be the unit sphere and let U be the coordinate patch para-
metrized by
xâˆ’1(u1, u2) = (cos u1 sin u2, sin u1 sin u2, cos u2),
with (u1, u2) âˆˆ(0, 2Ï€) Ã— (0, Ï€). Let X = cos u1 sin u2âˆ‚1 + sin u1 sin u2âˆ‚2,
Y = âˆ‚1, and Z = sin u2âˆ‚1 be vector ï¬elds over U.
(a) Show that X and Z can be extended continuously to vector ï¬elds
over all of M.
(b) Show that Y cannot be extended continuously to a vector ï¬eld in
X(M).
(c) Calculate the components of [X, Z] over U.
4.2.4. Let S be a regular surface in R3, and let X be a vector ï¬eld on R3. For
every p âˆˆS, deï¬ne Yp as the orthogonal projection of Xp onto TpS. Show
that Y is a vector ï¬eld on S.
4.2.5. Suppose that M is the torus that has a dense coordinate patch parame-
trized by
xâˆ’1(u, v) = ((3 + cos v) cos u, (3 + cos v) sin u, sin v) .
Consider the vector ï¬eld X = âˆ’z âˆ‚
âˆ‚x + x âˆ‚
âˆ‚z âˆˆR3. In terms of the coordi-
nates (u, v), calculate the vector ï¬eld on M induced from X by orthogonal
projection, as described in the previous exercise.

4.3. Differential Forms
145
4.2.6. Let M = S1 Ã— S1 Ã— S1 be the 3-torus given as an embedded submanifold
of R4 by the parametrization
(u, v, w) â†’( (4 + (2 + cos u) cos v) cos w,
(4 + (2 + cos u) cos v) sin w, (2 + cos u) sin v, sin u).
Consider the radial vector ï¬eld in R4 given by Z = x1âˆ‚1 + x2âˆ‚2 + x3âˆ‚3 +
x4âˆ‚4. In terms of the coordinates (u, v, w), calculate the vector ï¬eld on M
induced from X by orthogonal projection of Xp onto TpM for all p âˆˆM.
4.2.7. Find a vector ï¬eld on S2 that vanishes at one point. Write down a formula
expression for this vector ï¬eld in some coordinate patch of S2.
4.2.8. Prove that TS1 is diï¬€eomorphic to S1 Ã— R.
4.2.9. Prove Proposition 4.2.12.
4.2.10. Let F : M â†’N be a diï¬€erentiable map. Let X1, X2 âˆˆX(M), and let
Y1, Y2 âˆˆX(N). Suppose that Xi is F-related to Yi. Prove that [X1, X2] is
F-related to [Y1, Y2].
4.2.11. Let M be any diï¬€erentiable manifold.
Show that X(M) is an inï¬nite-
dimensional vector space.
4.3
Differential Forms
We now consider a particular class of tensor ï¬elds, which are called dif-
ferential forms. As we will see, they have many uses in geometry and in
physics, in particular for integration on manifolds. We refer the reader to
Section C.5 for the linear algebra behind the wedge operation deï¬ned in this
section. We also encourage the reader to see Section C.6, which provides
some background on the usefulness of diï¬€erential forms on manifolds.
For simplicity, from now on we will restrict our attention to smooth
manifolds. One should understand that in what follows, one could discuss
manifolds, vector ï¬elds, etc., that are merely diï¬€erentiable or of class Ck
without changing much of the presentation.
4.3.1
Deï¬nitions
Deï¬nition 4.3.1. Let M n be a smooth manifold. A diï¬€erential form Ï‰ of
rank r on M (or more succinctly, r-form) is a smooth global section (tensor
ï¬eld) of 1r(T M âˆ—).
In other words, for each p âˆˆM, one associates Ï‰p âˆˆ1r(TpM âˆ—) in such
a way that Ï‰p varies smoothly with p. The tensor Ï‰p is an alternating
r-multilinear function TpM âŠ—r â†’R. We point out that diï¬€erential forms of

146
4. Analysis on Manifolds
rank 0 are simply smooth real-valued functions on M and that a diï¬€erential
form of rank 1 is a covector ï¬eld, i.e., a smooth vector ï¬eld in T M âˆ—.
Let U be a coordinate neighborhood of M with coordinates x = (x1,
x2, . . . , xn). Deï¬ne I(r, n) as the set of all increasing sequences of length r
with values in {1, 2, . . ., n}. For example, (2, 3, 7) âˆˆI(3, 7) because there
are three elements in the sequence, they are listed in increasing order, and
their values are in {1, 2, . . ., 7}. Over the coordinate patch U, an r-form Ï‰
can be written in a unique way as
Ï‰ =

IâˆˆI(r,n)
aI dxI,
where each aI is a smooth function, and where we denote dxI = dxi1 âˆ§
Â· Â· Â· âˆ§dxir when I is the r-tuple I = (i1, . . . , ir). Recall that the symbol dxi
is deï¬ned in Equations (4.5) and (4.6).
Deï¬nition 4.3.2. If U is an open subset of M, we denote by Î©r(U) the set
of all diï¬€erential forms of rank r on U.
We remark that, similar to Problem 4.2.11, for each r, the set Î©r(U) is
in fact an inï¬nite-dimensional vector space. In particular, if Ï‰, Î· âˆˆÎ©r(U)
and Î» âˆˆR, then Ï‰ + Î· âˆˆÎ©r(U) and Î»Ï‰ âˆˆÎ©r(U), where by deï¬nition
(Ï‰ + Î·)p = Ï‰p + Î·p
and
(Î»Ï‰)p = Î» Ï‰p
in
r2
T M âˆ—.
Stronger yet, not only is each Î©r(U) closed under scalar multiplication,
but it is closed under multiplication by a smooth function. More precisely,
for all smooth functions f : U â†’R, we have fÏ‰ âˆˆÎ©r(U), where (fÏ‰)p =
f(p)Ï‰p for all p âˆˆU.
Finally, similar to the alternating products of a ï¬xed vector space, for
Ï‰ âˆˆÎ©r(U) and Î· âˆˆÎ©s(U), we deï¬ne the exterior product Ï‰ âˆ§Î· âˆˆÎ©r+s(U)
as the diï¬€erential form deï¬ned by (Ï‰ âˆ§Î·)p = Ï‰p âˆ§Î·p for all p âˆˆM.
Example 4.3.3. Consider the sphere S2, and let U be the coordinate neigh-
borhood with a system of coordinates x deï¬ned by the parametrization
xâˆ’1(u, v) = (cos u sin v, sin u sin v, cos v) deï¬ned on (0, 2Ï€) Ã— (0, Ï€). Let
Ï‰ = (sin2 v) du + (sin v cos v) dv,
Î· = cos u sin v du + (sin u cos v âˆ’sin v) dv
be two 1-forms on S2. Remarking that duâˆ§du = dvâˆ§dv = 0, one calculates
Ï‰ âˆ§Î· = sin2 v(sin u cosv âˆ’cos u cosv âˆ’sin v)du âˆ§dv.

4.3. Differential Forms
147
4.3.2
The Exterior Differential
Let f be a smooth real-valued function on a smooth manifold M, and
let X âˆˆX(M). Viewing f as a diï¬€erential map between manifolds, the
diï¬€erential df is such that, at each point p âˆˆM, it evaluates dfp(Xp) to a
tangent vector in Tf(p)(R). However, the tangent space Tf(p)(R) is equal
to R, so dfp(Xp) is just a real number. Hence, dfp âˆˆTpM âˆ—, and since all of
the operations vary smoothly with p, then df âˆˆÎ©1(M). If x = (x1, . . . , xn)
is a coordinate system on an open set U âŠ‚M, then in coordinates we have
df =
n

i=1
âˆ‚f
âˆ‚xi dxi.
Since Câˆ(U) = Î©0(M), the diï¬€erential d deï¬nes a linear transformation
d : Î©0(U) â†’Î©1(U).
We now generalize this remark by the following
deï¬nition.
Deï¬nition 4.3.4. Let Ï‰ = "
I aI dxI be a smooth diï¬€erential r-form over U.
The exterior diï¬€erential of Ï‰ is the (r + 1)-form written as dÏ‰ and deï¬ned
by
dÏ‰ =

IâˆˆI(r,n)
(daI) âˆ§dxI.
(4.9)
Example 4.3.5. Revisiting Example 4.3.3, we calculate dÏ‰ and dÎ·. First, for
dÏ‰ we have
dÏ‰ = (d(sin2 v)) âˆ§du + (d(sin v cos v)) âˆ§dv
= (2 sin v cos v dv) âˆ§du +

(cos2 v âˆ’sin2 v) dv

âˆ§dv
= (âˆ’2 sin v cos v) du âˆ§dv.
For dÎ·, we calculate
dÎ· = (d(cos u sin v)) âˆ§du + (d(sin u cosv âˆ’sin v)) âˆ§dv
= ((âˆ’sin u sin v) du + (cos u cosv) dv) âˆ§du
+ ((cos u cosv) du + (âˆ’sin u sin v âˆ’cos v) dv) âˆ§dv
= (cos u cosv) dv âˆ§du + (cos u cosv) du âˆ§dv = 0.
The diï¬€erential form Î· has the perhaps unexpected property that dÎ· = 0.
We will say that Î· is a closed 1-form (see Deï¬nition 4.3.10).
Proposition 4.3.6. Let M be a smooth manifold, and let U be an open subset
of M. The exterior diï¬€erential satisï¬es the following:

148
4. Analysis on Manifolds
1. For each 0 â‰¤r â‰¤nâˆ’1, the operator d : Î©r(U) â†’Î©r+1(U) is a linear
map.
2. If Ï‰ âˆˆÎ©r(U) and Î· âˆˆÎ©s(U), then
d(Ï‰ âˆ§Î·) = dÏ‰ âˆ§Î· + (âˆ’1)rÏ‰ âˆ§dÎ·.
3. For all Ï‰ âˆˆÎ©r(U), we have d(dÏ‰).
Proof: For part 1, set Ï‰ = "
I aI dxI, where the summation is over all
I âˆˆI(r, n) and aI are smooth real-valued functions on M. Then from
Equation (4.9), each daI is a 1-form, so obviously the summation is over
(r + 1)-forms.
Now let Î· = "
I bI dxI be another r-form, and let Î», Î¼ âˆˆR. Then
d(Î»Ï‰ + Î¼Î·) =

I
d(Î»aI + Î¼bI) âˆ§dxI
=

I
â›
â
n

j=1
âˆ‚
âˆ‚xj (Î»aI + Î¼bI) dxj
â
â âˆ§dxI
=

I
â›
â
n

j=1

Î»âˆ‚aI
âˆ‚xj + Î¼ âˆ‚bI
âˆ‚xj
	
dxj
â
â âˆ§dxI
= Î»

I
â›
â
n

j=1
âˆ‚aI
âˆ‚xj dxj
â
â âˆ§dxI + Î¼

I
â›
â
n

j=1
âˆ‚bI
âˆ‚xj dxj
â
â âˆ§dxI
= Î»dÏ‰ + Î¼dÎ·.
This proves linearity of d.
For part 2, again let Ï‰ be as above, and let Î· âˆˆÎ©s(U) be given by
Î· = "
J bJ dxJ, where the summation in J runs over I(s, n).
By the
linearity of the wedge product, we can write
Ï‰ âˆ§Î· =

I

J
aIbJ dxI âˆ§dxJ.
Note that for various combinations of I and J, the wedge products dxIâˆ§dxJ
will cancel if I and J share any common indices. Then

4.3. Differential Forms
149
d(Ï‰ âˆ§Î·) =

I

J
 n

k=1
âˆ‚aIbJ
âˆ‚xk
dxk

âˆ§dxI âˆ§dxJ
=

I

J
 n

k=1
 âˆ‚aI
âˆ‚xk bJ + aI
âˆ‚bJ
âˆ‚xk
	
dxk

âˆ§dxI âˆ§dxJ
=

I

J
 n

k=1
âˆ‚aI
âˆ‚xk bJ dxk

âˆ§dxI âˆ§dxJ
+

I

J
 n

k=1
aI
âˆ‚bJ
âˆ‚xk dxk

âˆ§dxI âˆ§dxJ.
But by the properties of wedge products, dxk âˆ§dxI âˆ§dxJ = (âˆ’1)rdxI âˆ§
dxk âˆ§dxJ (see Proposition C.5.20). Thus,
d(Ï‰ âˆ§Î·) =

I
n

k=1

J
âˆ‚aI
âˆ‚xk bJ dxk âˆ§dxI âˆ§dxJ
+ (âˆ’1)r 
I

J
n

k=1
aI
âˆ‚bJ
âˆ‚xk dxI âˆ§dxk âˆ§dxJ
=

I
n

k=1
âˆ‚aI
âˆ‚xk dxk âˆ§dxI

âˆ§Î·
+ (âˆ’1)rÏ‰ âˆ§

J
n

k=1
âˆ‚bJ
âˆ‚xk dxk âˆ§dxJ

= dÏ‰ âˆ§Î· + (âˆ’1)rÏ‰ âˆ§dÎ·.
To prove part 3, we ï¬rst show that d(df) = 0 for a smooth function f
on M. We have
d(df) = d
 n

i=1
âˆ‚f
âˆ‚xi dxi

=
n

i=1
n

j=1
âˆ‚2f
âˆ‚xjâˆ‚xi dxj âˆ§dxi
=

IâˆˆI(2,n)

âˆ‚2f
âˆ‚xi1âˆ‚xi2 âˆ’
âˆ‚2f
âˆ‚xi2âˆ‚xi1
	
dxI,
where we assume I = (i1, i2). However, since the function f is smooth, by
Clairautâ€™s Theorem on mixed partials each component function is 0. Thus
d(df) = 0.

150
4. Analysis on Manifolds
Now for any r-form Ï‰ = "
I aI dxI we have
d(dÏ‰) = d

I
d(aI) âˆ§dxI

=

I
d(d(aI) âˆ§dxI)
(by linearity)
=

I

d(daI) âˆ§dxI âˆ’daI âˆ§d(dxI)

(by part 2)
= 0,
where the last line follows because d(daI) = 0 and d(dxI) = 0 for all I. â–¡
It is illuminating to see what the exterior diï¬€erential represents when
the manifold in question is Rn. We ï¬rst emphasize two particular cases.
First, let f be a smooth real-valued function on Rn. Then
df =
n

i=1
âˆ‚f
âˆ‚xi dxi.
Thus, df has exactly the same components as the gradient, deï¬ned in
multivariable calculus as
grad f = âƒ—âˆ‡f = (âˆ‚1f, âˆ‚2f, . . . , âˆ‚nf) .
Therefore, in our presentation, the gradient of a function f is in fact a
covector ï¬eld, i.e., a vector ï¬eld in T M âˆ—= (Rn)âˆ—.
In calculus courses, one does not distinguish between vectors and cov-
ectors, i.e., vectors in Rn or in (Rn)âˆ—, since these are isomorphic as vector
spaces. However, as we saw in Deï¬nitions 2.4.4 and 2.4.5, vector ï¬elds and
covector ï¬elds have diï¬€erent transformational properties under change-of-
coordinate.
One can easily verify that the gradient of a function transforms co-
variantly, but it is also instructive to see how this plays out in common
formulas in calculus. For example, the chain rule for paths states that if
âƒ—c(t) is a diï¬€erentiable curve in Rn and f : Rn â†’R is diï¬€erentiable, then
d
dtf(âƒ—c(t)) = âƒ—âˆ‡fâƒ—c(t) Â· âƒ—c â€²(t).
However, from the perspective of multilinear algebra, one should under-
stand the dot product as the contraction map V âˆ—âŠ—V â†’R deï¬ned by

4.3. Differential Forms
151
Î» âŠ—âƒ—v â†’Î»(âƒ—v). Since by deï¬nition âƒ—c â€²(t) is a tangent vector to Rn at âƒ—c(t),
then we should view the gradient âƒ—âˆ‡f as a covector in (Rn)âˆ—.
As a second illustration, consider (n âˆ’1)-forms over Rn.
For each
1 â‰¤j â‰¤n, deï¬ne the (n âˆ’1)-forms Î·j as
Î·j = (âˆ’1)jâˆ’1dx1 âˆ§Â· Â· Â· âˆ§dxjâˆ’1 âˆ§dxj+1 âˆ§Â· Â· Â· âˆ§dxn.
(4.10)
For each p âˆˆM, the set {Î·j
p} is a basis for 1nâˆ’1 TpM âˆ—, so any (nâˆ’1)-form
Ï‰ can be written as Ï‰ = "n
i=1 aiÎ·i. Thus, ignoring contravariance and
covariance, we can view Ï‰ as a vector ï¬eld over Rn. Note that having the
(âˆ’1)jâˆ’1 factor in the deï¬nition of Î·j leads to the identity
dxj âˆ§Î·i =

0,
if i Ì¸= j,
dx1 âˆ§dx2 âˆ§Â· Â· Â· âˆ§dxn,
if i = j.
(4.11)
Thus, for the diï¬€erential of Ï‰, we have
dÏ‰ =
n

i=1
n

j=1
âˆ‚ai
âˆ‚xj dxj âˆ§Î·j =
 n

i=1
âˆ‚ai
âˆ‚xi

dx1 âˆ§dx2 âˆ§Â· Â· Â· âˆ§dxn.
Hence, for the case of (nâˆ’1)-forms, the exterior diï¬€erential d operates like
the divergence operator div = âƒ—âˆ‡Â· on a vector ï¬eld (a1, . . . , an) in Rn.
In the particular case of R3, the exterior diï¬€erential carries another
point of signiï¬cance. Let Ï‰ âˆˆÎ©1(R3), and write Ï‰ = "n
i=1 ai dxi. Then
dÏ‰ =
n

i=1
n

j=1
âˆ‚ai
âˆ‚xj dxj âˆ§dxi
=
âˆ‚a2
âˆ‚x1 âˆ’âˆ‚a1
âˆ‚x2
	
dx1 âˆ§dx2 +
âˆ‚a3
âˆ‚x1 âˆ’âˆ‚a1
âˆ‚x3
	
dx1 âˆ§dx3
+
âˆ‚a3
âˆ‚x2 âˆ’âˆ‚a2
âˆ‚x3
	
dx2 âˆ§dx3
=
âˆ‚a3
âˆ‚x2 âˆ’âˆ‚a2
âˆ‚x3
	
Î·1 +
âˆ‚a1
âˆ‚x3 âˆ’âˆ‚a3
âˆ‚x1
	
Î·2 +
âˆ‚a2
âˆ‚x1 âˆ’âˆ‚a1
âˆ‚x2
	
Î·3,
which is precisely the curl of the vector ï¬eld (a1, a2, a3).
It is particularly interesting to note that the property d(dÏ‰) = 0 in
Proposition 4.3.6 summarizes simultaneously the following two standard
theorems in multivariable calculus:
curl grad f = âƒ—0
[52, Theorem 17.3],
div curl âƒ—F = 0
[52, Theorem 17.11],

152
4. Analysis on Manifolds
where f : R3 â†’R is a function of class C2 and âƒ—F : R3 â†’R3 is a vector
ï¬eld of class C2.
We point out that the forms Î·j deï¬ned in Equation (4.10) are particular
instances of the Hodge star operator â‹†that will be introduced in Section
C.6.3. One constructs the Hodge star operator in the general context of
a vector space equipped with an inner product (a bilinear form that is
symmetric and nondegenerate). In the above situation, we have V = Rn
and the inner product âŸ¨, âŸ©is the standard Euclidean dot product. Then
according to Proposition C.6.10, we have
Î·j = â‹†dxj.
4.3.3
Pull-Backs
We now deï¬ne the notion of a pull-back of a diï¬€erential form of rank r by a
smooth function between manifolds. Though the construction of pull-backs
is interesting in its own right, the pull-back is essential for deï¬ning how to
integrate on a manifold.
Deï¬nition 4.3.7. Let f : M m â†’N n be a smooth map between two smooth
manifolds, and let Ï‰ âˆˆÎ©r(N). Deï¬ne the pull-back of Ï‰ by f, written f âˆ—Ï‰,
by the alternating multilinear function on TpM that is deï¬ned by
(f âˆ—Ï‰)p(v1, v2, . . . , vr) = Ï‰p(dfp(v1), dfp(v2), . . . , dfp(vr)),
(4.12)
where vi are tangent vectors in TpM.
If x is a local coordinate system on M and y is a coordinate system on N,
then locally, for every v âˆˆTpM, the coordinates of dfp(v) are "m
i=1 âˆ‚if jvi
for j = 1, . . . , n.
Recall that f j = yj â—¦f : M â†’R.
Then for every
I = (i1, . . . , ir) âˆˆI(r, m), we have
(f âˆ—dxI)p(v1, . . . , vr) = dxI(dfp(v1), . . . , dfp(vr))
= (df i1)p(v1, . . . , vr) âˆ§Â· Â· Â· âˆ§(df ir)p(v1, . . . , vr)
= (df i1 âˆ§Â· Â· Â· âˆ§df ir)p(v1, . . . , vr).
We conclude that in coordinates, as a vector ï¬eld over M,
f âˆ—
â›
â

iâˆˆI(r,m)
aI dxI
â
â =

iâˆˆI(r,m)
(aI â—¦f) df i1 âˆ§Â· Â· Â· âˆ§df ir.
(4.13)

4.3. Differential Forms
153
As a corollary to this, which we leave as an exercise (Problem 4.3.13),
we deduce the following fundamental formula. If M and N are smooth
manifolds of the same dimension n, is f a smooth map between them, and
Ï‰ is an n-form, then
f âˆ—(Ï‰)p = (det dfp)Ï‰f(p).
(4.14)
The pull-back of r-forms satisï¬es a few more properties, listed in these
propositions.
Proposition 4.3.8. Let f : M m â†’N n be a smooth map between smooth
manifolds. The following hold for all r â‰¤min(m, n):
1. The pull-back f âˆ—: Î©r(N) â†’Î©r(M) is a linear function.
2. For all Ï‰, Î· âˆˆÎ©r(N), f âˆ—(Ï‰ âˆ§Î·) = (f âˆ—Ï‰) âˆ§(f âˆ—Î·).
3. For all Ï‰ âˆˆÎ©r(N) with r < min(m, n), f âˆ—(dÏ‰) = d(f âˆ—Ï‰).
Proof: Part 1 follows immediately from the functional deï¬nition in Equa-
tion (4.12). Part 2 is an easy application of Equation (4.13). Finally, for
part 3, note that d(df i1 âˆ§Â· Â· Â· âˆ§df ir) = 0 by a repeated use of Proposition
4.3.6(2) and the fact that d(df i) = 0.
Then, if Ï‰ = "
I aIdxI, Equa-
tion (4.13) gives
d(f âˆ—Ï‰) =

IâˆˆI(r,m)
d

(aI â—¦f) df i1 âˆ§Â· Â· Â· âˆ§df ir
=

IâˆˆI(r,m)
d(aI â—¦f) âˆ§df i1 âˆ§Â· Â· Â· âˆ§df ir + (aI â—¦f)d(df i1 âˆ§Â· Â· Â· âˆ§df ir)
=

IâˆˆI(r,m)
d(aI â—¦f) âˆ§df i1 âˆ§Â· Â· Â· âˆ§df ir
=

IâˆˆI(r,m)
d(aI â—¦f) âˆ§f âˆ—(dxI)
= f âˆ—(dÏ‰).
â–¡
Proposition 4.3.9. Let f : M â†’N and g : U â†’M be smooth functions
between smooth manifolds. Then (f â—¦g)âˆ—= gâˆ—â—¦f âˆ—.
Proof: (Left as an exercise for the reader.)
â–¡

154
4. Analysis on Manifolds
4.3.4
Closed and Exact Forms
As a ï¬nal paragraph in this section, we brieï¬‚y mention how the apparently
simple fact that d(dÏ‰) = 0 serves as the basis for profound mathematics
related to the global geometry of a manifold.
Deï¬nition 4.3.10. Let M be a smooth manifold. A diï¬€erential form Ï‰ âˆˆ
Î©r(M) is called closed if dÏ‰ = 0 and is called exact if there exist Î· âˆˆ
Î©râˆ’1(M) such that Ï‰ = dÎ·.
With this terminology, one can say that the identity d(dÏ‰) = 0 means
that every exact form is closed. The converse is not true in general, and
it is precisely this fact that leads to profound results in topology. In the
language of homology, the sequence of vector spaces and linear maps
Î©0(M)
d
âˆ’âˆ’âˆ’âˆ’â†’Î©1(M)
d
âˆ’âˆ’âˆ’âˆ’â†’Î©2(M)
d
âˆ’âˆ’âˆ’âˆ’â†’Â· Â· Â·
d
âˆ’âˆ’âˆ’âˆ’â†’Î©n(M)
satisfying the identity dâ—¦d = 0 is called a complex. To distinguish between
ranks, one writes dr for the diï¬€erential d : Î©r(M) â†’Î©r+1(M). The fact
that every exact form is closed can be restated once more by saying that
Im drâˆ’1 is a vector subspace of ker dr. The quotient vector space
ker dr/ Im drâˆ’1 = ker(d : Î©r(M) â†’Î©r+1(M))/ Im(d : Î©râˆ’1(M) â†’Î©r(M))
is called the rth de Rham cohomology group of M, denoted Hr
dR(M). The
de Rham cohomology groups are in fact global properties of the manifold
M and are related to profound topological invariants of M. This topic
exceeds the scope of this book, but we wish to point out two ways in which
one can glimpse why the groups Hr
dR(M) are global properties of M.
As a ï¬rst example, consider the explicit covector ï¬elds Ï‰ and Î· on S2
described in Example 4.3.3. These vector ï¬elds were deï¬ned in terms of
a coordinate patch U, which turned out to be dense on S2 (covers all but
a subset that is not two-dimensional). Furthermore, they were deï¬ned on
U in such a way that they can be extended continuously over all of S2,
thereby deï¬ning continuous (and here smooth) vector ï¬elds. The key is to
note that in terms of the local coordinates (u, v), one cannot use any pair
of smooth functions a1(u, v) and a2(u, v) to deï¬ne a 1-form
Ï‰ = a1(u, v) du + a2(u, v) dv
that can be extended to create a smooth 1-form on S2. This restriction
shows that Î©1(S2) is aï¬€ected by the global geometry of S2. The principle
behind this example is true in general: the vector spaces Î©r(M), though

4.3. Differential Forms
155
inï¬nite-dimensional and usually impossible to describe explicitly, depend
on the global structure of M.
As a second example, we determine H0
dR(M) for any manifold.
Of
course, dâˆ’1 does not exist explicitly so we set, by convention, Î©âˆ’1(M) = 0,
i.e., the zero-dimensional vector space. Then Im dâˆ’1 = {0} is the trivial
subspace in Î©0(M). Furthermore, since Î©0(M) is the space of all smooth
real-valued functions on M, the 0th cohomology group is
H0
dR(M) = ker(d : Câˆ(M) â†’Î©1(M))/{0} = ker(d : Câˆ(M) â†’Î©1(M)),
namely, the subspace of all smooth functions on M whose diï¬€erentials are
0. In other words, H0
dR(M) is the space of all functions that are constant
on each connected component of M. Thus, H0
dR(M) = Râ„“, where â„“is the
number of connected components of M, a global property.
Problems
4.3.1. Let M be a smooth manifold. Let Ï‰ âˆˆÎ©r(U) be a nonzero r-form. Char-
acterize the forms Î· âˆˆÎ©s(M) such that Ï‰ âˆ§Î·.
4.3.2. Let M = R3. Find the exterior diï¬€erential of the following:
(a) x dy âˆ§dz + y dz âˆ§dx + z dx âˆ§dy.
(b) xy2z3 dx + y sin(xz) dz.
(c) dx âˆ§dy + x dy âˆ§dz
x2 + y2 + z2 + 1 .
4.3.3. Let M = Rn.
Let Ï‰ = x1 dx1 + Â· Â· Â· + xn dxn and Î· = x2 dx1 + Â· Â· Â· +
xn dxnâˆ’1 + x1 dxn.
(a) Calculate dÏ‰ and dÎ·.
(b) Calculate Ï‰ âˆ§Î· and d(Ï‰ âˆ§Î·).
(c) Calculate the exterior diï¬€erential of x1Î·1 + x2Î·2 + Â· Â· Â· + xnÎ·n, where
the forms Î·i are deï¬ned as in Equation (4.10).
4.3.4. Let M = S1 Ã— S1 be the torus in R3 that has a coordinate neighborhood
(U, x) that can be parametrized by
xâˆ’1(u, v) â†’( (3 + cos u) cos v, (3 + cos u) sin v, sin u)
for (u, v) âˆˆ(0, 2Ï€)2.
Consider the two diï¬€erential forms Ï‰ and Î·, given over U by Ï‰ = cos(u +
v) du + 2 sin2 u dv and Î· = 3 sin2 v du âˆ’4 dv.
(a) Show why Ï‰ and Î· extend to diï¬€erential forms over the whole torus.
(b) Calculate Ï‰ âˆ§Ï‰ and Ï‰ âˆ§Î·.
(c) Calculate dÏ‰ and dÎ·.

156
4. Analysis on Manifolds
4.3.5. Consider the manifold RP3 with the standard atlas described in Example
3.1.6. Consider also the 1-form that is described in coordinates over U0 as
Ï‰ = x1 dx1 + x2(x3)3 dx2 + x1x2 dx3.
(a) Write down a coordinate expression for Ï‰ in U1, U2, and U3.
(b) Calculate dÏ‰ and Ï‰ âˆ§Ï‰ in coordinates over U0.
(c) Calculate dÏ‰ in coordinates over U1 and show explicitly that the
coordinates change as expected over U0 âˆ©U1.
4.3.6. Set Ï‰ = x1x2 dx2 + (x2 + 3x4x5) dx3 + ((x2)2 + (x3)2) dx5 as a 1-form over
R5. Calculate dÏ‰, Ï‰ âˆ§dÏ‰, Ï‰ âˆ§Ï‰, and dÏ‰ âˆ§dÏ‰ âˆ§Ï‰.
4.3.7. Consider the spacetime variables x, y, z, and t in R3, and label new
variables by x0 = ct, x1 = x, x2 = y, and x3 = z. Consider the two
2-forms Î± and Î² deï¬ned by
Î± = âˆ’
3

i=1
Ei dx0 âˆ§dxi +
3

j=1
BjÎ·j
and
Î² =
3

i=1
Bi dx0 âˆ§dxi âˆ’
3

j=1
EjÎ·j,
where the forms Î·j are the 2-forms deï¬ned in Equation (4.10) over the
space variables, i.e., Î·1 = dx2 âˆ§dx3, Î·2 = âˆ’dx1 âˆ§dx3, and Î·3 = dx1 âˆ§dx2.
(a) Writing âƒ—E = (E1, E2, E3) and âƒ—B = (B1, B2, B3) as time-dependent
vector ï¬elds in R3, show that the source-free Maxwellâ€™s equations
âˆ‡Ã— âƒ—E = âˆ’1
c
âˆ‚âƒ—B
âˆ‚t ,
âˆ‡Â· âƒ—E = 0,
âˆ‡Ã— âƒ—B = 1
c
âˆ‚âƒ—E
âˆ‚t ,
âˆ‡Â· âƒ—B = 0,
can be expressed in the form
dÎ± = 0
and
dÎ² = 0.
(b) If we write the 1-form Î» = âˆ’Ï† dx0 + A1 dx1 + A2 dx2 + A3 dx3, show
that dÎ» = Î± if and only if
âƒ—E = âˆ’âˆ‡Ï† âˆ’1
c
âˆ‚âƒ—A
âˆ‚t
and
âƒ—B = âˆ‡Ã— âƒ—A.
4.3.8. In the theory of diï¬€erential equations, if M and N are functions of x and y,
an integrating factor for an expression of the form M dy
dx + N is a function
I(x,y) such that
I(x, y)

M(x, y)dy
dx + N(x, y)
	
= d
dxF(x, y)
for some function F(x, y). If M is a smooth manifold and Ï‰ âˆˆÎ©1(M), we
call an integrating factor of Ï‰ a smooth function f that is nowhere 0 on
M and such that fÏ‰ is exact. Prove that if such a function f exists, then
Ï‰ âˆ§dÏ‰ = 0.

4.3. Differential Forms
157
4.3.9. Let Ï‰ = (1 + xy2)exy2 dx + 2x2yexy2 dy be a 1-form on R2. Show that
dÏ‰ = 0. Then ï¬nd a function f : R2 â†’R such that Ï‰ = df.
4.3.10. Let Ï‰ = yz dx âˆ§dz + (âˆ’y + xz) du âˆ§dz be a 2-form on R3. Show that
dÏ‰ = 0. Then ï¬nd a 1-form Î» such that Ï‰ = dÎ».
4.3.11. Suppose that Ï‰ âˆˆÎ©1(M) for some smooth manifold M. Suppose that over
each coordinate chart one writes Ï‰ = Ï‰i dxi. Prove that if âˆ‚jÏ‰i = âˆ‚iÏ‰j
holds in every coordinate neighborhood around every point p âˆˆM, then
Ï‰ is a closed form.
4.3.12. Prove Proposition 4.3.9.
4.3.13. Let f : M â†’N be a smooth map between smooth manifolds, both of
dimension n. Let Ï‰ be a diï¬€erential form of rank n. Prove that
f âˆ—(Ï‰) = (det df) Ï‰ â—¦f.
4.3.14. Let Ï‰ and Î· be forms on a smooth manifold M.
(a) Show that if Ï‰ and Î· are closed, then so is Ï‰ âˆ§Î·.
(b) Show that if Ï‰ and Î· are exact, then so is Ï‰ âˆ§Î·.
4.3.15. Let M be a manifold of dimension m â‰¥4. Let Ï‰ be a 2-form on M, and
let Î± and Î² be 1-forms. Show that
Ï‰ âˆ§Î± âˆ§Î² = 0
if and only if there exist 1-forms Î» and Î· such that
Ï‰ = Î» âˆ§Î± + Î· âˆ§Î².
4.3.16. Consider the manifold GLn(R) of invertible matrices, and consider the
function det : GLn(R) â†’R as a function between manifolds.
(a) Prove that for all X âˆˆGLn(R), the tangent space is TXGLn(R) âˆ¼=
RnÃ—n, the space of n Ã— n matrices.
(b) Writing the entries of a matrix X âˆˆGLn(R) as X = (xi
j), prove that
âˆ‚det
âˆ‚xi
j
(X) = (det X)(Xâˆ’1)i
j.
(c) Prove that the diï¬€erential of the determinant map can be written as
d(det)X(A) = (det X) Tr(Xâˆ’1A),
where Tr M = "
i mi
i is the trace of the matrix.

158
4. Analysis on Manifolds
4.4
Integration on Manifolds
The last topic in this chapter on analysis on a manifold covers the theory of
integration on manifolds. Two comments motivate the following approach.
First, the theory of integration on manifolds that we propose to develop
must generalize all types of integration introduced in the usual calculus
sequence. This includes
â€¢ integration of a one-variable, real-valued function over an interval;
â€¢ integration of a multivariable, real-valued function over a domain
in Rn;
â€¢ line integrals of functions in Rn;
â€¢ line integrals of vector ï¬elds in Rn;
â€¢ surface integrals of a real-valued function deï¬ned over a closed and
bounded region of a regular surface;
â€¢ surface integrals of vector ï¬elds in R3.
It may seem hopeless to consolidate all of these operations into a single,
concise description, but diï¬€erential forms allow us to do precisely that.
Second, readers who have pursued a course in analysis may be aware
of the diï¬€erence between Riemannian integration, the theory introduced
in the usual calculus sequence, and Lebesgue integration, which relies on
the more diï¬ƒcult techniques of measure theory. The theory developed here
below does not depend on either of these theories of integration but could
use either. The deï¬nitions for integration on a manifold use the fact that
a manifold is locally diï¬€eomorphic to an open subset in Rn and deï¬ne an
integral on a manifold in reference to integration on Rn. Therefore, one
can presuppose the use of either Riemannian integration or integration with
respect to the Lebesgue measure.
4.4.1
Partitions of Unity
The basis for deï¬ning integration on a smooth manifold M n relies on re-
lating the integral on M to integration in Rn. However, since a manifold
is only locally homeomorphic to an open set in Rn, one can only deï¬ne
directly integration on a manifold over a coordinate patch.

4.4. Integration on Manifolds
159
We begin this section by introducing a technical construction that
makes it possible, even from just a theoretical perspective, to piece to-
gether the integrals of a function over the diï¬€erent coordinate patches of
the manifoldâ€™s atlas.
Deï¬nition 4.4.1. Let M be a manifold, and let V = {VÎ±}Î±âˆˆI be a collection
of open sets that covers M. A partition of unity subordinate to V is a col-
lection of continuous functions {ÏˆÎ± : M â†’R}Î±âˆˆI that satisfy the following
properties:
1. 0 â‰¤ÏˆÎ±(x) â‰¤1 for all Î± âˆˆI and all x âˆˆM.
2. ÏˆÎ±(x) vanishes outside a compact subset of VÎ±.
3. For all x âˆˆM, there exists only a ï¬nite number of Î± âˆˆI such that
ÏˆÎ±(x) Ì¸= 0.
4. "
Î±âˆˆI ÏˆÎ±(x) = 1 for all x âˆˆM.
Note that the summation in the fourth condition always exists since,
by the third criterion, for all x âˆˆM, it is only a ï¬nite sum. Therefore,
one does not worry about issues of convergence in this deï¬nition.
The
terminology â€œpartition of unityâ€ comes from the fact that the collection of
functions {ÏˆÎ±} add up to the constant function 1 on M.
Theorem 4.4.2 (Existence of Partitions of Unity). Let M be a smooth manifold
with atlas A = {(UÎ±, Ï†Î±)}Î±âˆˆI. There exists a smooth partition of unity of
M subordinate to A.
For the sake of space, we forego a complete proof of this theorem and
refer the reader to [32, pp. 54â€“55], [47, Theorem 10.8], or [14, Section 14.1].
The proof relies on the existence of smooth real-valued functions that are
nonzero in an open set U âŠ‚Rn but identically 0 outside of U. Many of the
common examples of partitions of unity depend on the following lemma.
Lemma 4.4.3. The function f : R â†’R deï¬ned by
f(x) =

0,
if x â‰¤0,
eâˆ’1/x,
if x > 0,
is a smooth function. (See Figure 4.4.)
The proof for this lemma is an exercise in calculating higher derivatives
and evaluating limits. (Interestingly enough, this function at x = 0 is an

160
4. Analysis on Manifolds
x
Figure 4.4. f(x) = eâˆ’1/x.
example of a function that is smooth, i.e., has all its higher derivatives,
but is not analytic, i.e., equal to its Taylor series over a neighborhood of
x = 0.)
The function f(x) in Lemma 4.4.3 is useful because it passes smoothly
from constant behavior to nonconstant behavior. This function f(x) also
leads immediately to functions with other desirable properties. For exam-
ple, f(x âˆ’a) + b is a smooth function that is constant and equal to b for
x â‰¤a and then nonconstant for x > a. In contrast, f(a âˆ’x) + b is a
smooth function that is constant and equal to b for x â‰¥a and then non-
constant for x < a. More useful still for our purposes, if a < b, the function
g(x) = f(x âˆ’a)f(b âˆ’x) is smooth, identically equal to 0 for x /âˆˆ(a, b), and
is nonzero for x âˆˆ(a, b). We can call this a bump function over (a, b) (see
Figure 4.5(a)). Also, the function
h(x) =
f(b âˆ’x)
f(x âˆ’a) + f(b âˆ’x)
is smooth, is identically equal to 1 for x â‰¤a, identically equal to 0 for
x â‰¥b, and strictly decreasing over (a, b). The function h(x) is sometimes
called a cut-oï¬€function (see Figure 4.5(b)).
We will illustrate how to construct partitions of unity over a manifold
with the following two simple examples.
x
1
3
(a) Bump function
x
1
3
(b) Cut-oï¬€function
Figure 4.5. Useful smooth functions.

4.4. Integration on Manifolds
161
Example 4.4.4. Consider the real line R as a 1-manifold, and consider the
open cover U = {Ui}, where Ui = (i âˆ’1, i + 1). In this open cover, we note
that if n is an integer, then n is only contained in one set, Un, and if t is
not an integer, then t is contained in both UâŒŠtâŒ‹and UâŒŠtâŒ‹+1. Consider ï¬rst
the bump functions gi(x) deï¬ned by
gi(x) = f(x âˆ’(i âˆ’0.9))f((i + 0.9) âˆ’x)
=
â§
âª
â¨
âª
â©
0,
if x â‰¤i âˆ’0.9,
e 1.8/(xâˆ’i+0.9)(xâˆ’iâˆ’0.9),
if i âˆ’0.9 < x < i + 0.9,
0,
if x â‰¥i + 0.9,
where we use the function f as deï¬ned in Lemma 4.4.3. It is not hard to
show that these functions are smooth. Furthermore, by deï¬nition, gi(x) =
0 for x /âˆˆ[i âˆ’0.9, i + 0.9] = Ki, which is a compact subset of Ui. For any
i âˆˆZ, the only functions that are not identically 0 on Ui are giâˆ’1, gi, and
gi+1. Now deï¬ne
Ïˆi(x) =
gi(x)
giâˆ’1(x) + gi(x) + gi+1(x).
We claim that the collection {Ïˆi}iâˆˆZ forms a partition of unity subordinate
to U. Again, Ïˆi(x) Ì¸= 0 for x âˆˆKi and Ïˆi(x) = 0 for x /âˆˆKi. Furthermore,
the only functions Ïˆk that are not identically 0 on Ui are Ïˆiâˆ’1, Ïˆi, and
Ïˆi+1. If x = n is an integer, then

iâˆˆZ
Ïˆi(x) = Ïˆn(n) =
gn(n)
gnâˆ’1(n) + gn(n) + gn+1(n) = gn(n)
gn(n) = 1.
If instead x is not an integer, then when we set n = âŒŠxâŒ‹, we have

iâˆˆZ
Ïˆi(x) = Ïˆn(x) + Ïˆn+1(x)
=
gn(x)
gnâˆ’1(x) + gn(x) + gn+1(x) +
gn+1(x)
gn(x) + gn+1(x) + gn+2(x)
=
gn(x)
gn(x) + gn+1(x) +
gn+1(x)
gn(x) + gn+1(x) = 1
since gnâˆ’1(x) = gn+2(x) = 0 for x âˆˆUn âˆ©Un+1.
Example 4.4.5. Consider the unit sphere S2 given as a subset of R3. Cover
S2 with two coordinate patches (U1, x) and (U2, Â¯x), where the coordinate

162
4. Analysis on Manifolds
Figure 4.6. Example 4.4.5.
functions have the following inverses:
xâˆ’1(u, v) = (cos u sin v, sin u sin v, cos v)
for (u, v) âˆˆ(0, 2Ï€) Ã— (0, Ï€),
Â¯xâˆ’1(Â¯u, Â¯v) = (âˆ’cos Â¯u sin Â¯v, âˆ’cos Â¯v, âˆ’sin Â¯u sin Â¯v)
for (Â¯u, Â¯v) âˆˆ(0, 2Ï€) Ã— (0, Ï€).
Deï¬ne now the bump functions
g1(u, v) = f(u âˆ’0.1)f(6 âˆ’u)f(v âˆ’0.1)f(3 âˆ’v),
g2(Â¯u, Â¯v) = f(Â¯u âˆ’0.1)f(6 âˆ’Â¯u)f(Â¯v âˆ’0.1)f(3 âˆ’Â¯v),
where f is the function in Lemma 4.4.3. These functions are smooth and
vanish outside [0.1, 6] Ã— [0.1, 3] = K, which is a compact subset of (0, 2Ï€) Ã—
(0, Ï€). Deï¬ne also the bump functions hi : S2 â†’R by
h1(p) =

g1 â—¦x(p),
if p âˆˆU1,
0,
if p /âˆˆU1,
and
h2(p) =

g2 â—¦Â¯x(p),
if p âˆˆU2,
0,
if p /âˆˆU2.
By construction, these functions are smooth on S2 and vanish outside a
compact subset of U1 and U2, namely, xâˆ’1(K) and Â¯xâˆ’1(K) respectively.
In Figure 4.6, the half-circles depict the complements of U1 and U2 on S2,
and the piecewise-smooth curves that surround the semicircles show the
boundary of xâˆ’1(K) and Â¯xâˆ’1(K).
Finally, deï¬ne the functions Ïˆi : S2 â†’R by
Ïˆi(p) =
hi(p)
h1(p) + h2(p).
These functions are well deï¬ned since h1 and h2 are nonzero on the interior
of xâˆ’1(K) and Â¯xâˆ’1(K), respectively, and these interiors cover S2. The pair
of functions {Ïˆ1, Ïˆ2} is a smooth partition of unity that is subordinate to
the atlas that we deï¬ned on S2.

4.4. Integration on Manifolds
163
An object that recurs when dealing with partitions of unity is the set
over which the function is nonzero. We make the following deï¬nition.
Deï¬nition 4.4.6. Let f : M â†’R be a real-valued function from a mani-
fold M. The support of f, written supp f is deï¬ned as the closure of the
nonzero set, i.e.,
supp f = {p âˆˆM | f(p) Ì¸= 0}.
A function is said to have compact support if supp f is a compact set.
4.4.2
Integrating Differential Forms
We are now in a position to deï¬ne integration of n-forms on a smooth n-
dimensional manifold. We must begin by connecting integration of forms
in Rn to usual integration.
Deï¬nition 4.4.7. Let Ï‰ be a diï¬€erential form of rank n over Rn. Let K be a
compact subset of Rn. If we write
Ï‰ = f(x1, . . . , xn) dx1 âˆ§Â· Â· Â· âˆ§dxn,
then we deï¬ne the integral as

K
Ï‰ =

K
f(x1, . . . , xn) dx1 dx2 Â· Â· Â· dxn,
where the right-hand side represents the usual Riemann integral.
(As pointed out at the beginning of this section, one can also use the
Lebesgue integral instead of the Riemann integral.) Also, if Ï‰ is a form
that vanishes outside a compact set K, which is a subset of an open set U,
then we deï¬ne

U Ï‰ =

K Ï‰.
In order to connect the integration on a manifold M n to integration in
Rn, we must ï¬rst show that this can be done independent of the coordinate
system used.
Lemma 4.4.8.
Let M n be a smooth, oriented manifold with atlas A =
{(Ui, Ï†i)}iâˆˆI. Let K be a compact set with K âˆˆU1 âˆ©U2, and let Ï‰ be an
n-form that vanishes outside of K. If we set Vi = Ï†i(Ui) for i = 1, 2, then
the following integrals are equal:

V1
(Ï†âˆ’1
1 )âˆ—(Ï‰) =

V2
(Ï†âˆ’1
2 )âˆ—(Ï‰).

164
4. Analysis on Manifolds
Proof: Using the standard notation for transition functions, write VÎ±Î² =
Ï†Î±(UÎ± âˆ©UÎ²) and Ï†12 = Ï†2 â—¦Ï†âˆ’1
1 , a homeomorphism from V12 to V21.
Suppose that in coordinates (x1, . . . , xn) of the (U1, Ï†1) patch, we write
(Ï†âˆ’1
1 )âˆ—(Ï‰) = f(x1, . . . , xn) dx1 âˆ§Â· Â· Â· âˆ§dxn as a form in Rn. Then according
to the usual substitution-of-variables formula for integration, one has
%
V12
f dx1 Â· Â· Â· dxn =
%
V21
f â—¦Ï†21 | det dÏ†21| dÂ¯x1 Â· Â· Â· dÂ¯xn,
where (Â¯x1, . . . , dÂ¯xn) are the coordinates over U2. Note that | det dÏ†21| is the
absolute value of the Jacobian of the change-of-coordinate function Ï†21.
The integration of forms on a manifold gives
%
V2
(Ï†âˆ’1
2 )âˆ—(Ï‰) =
%
V21
(Ï†âˆ’1
2 )âˆ—(Ï‰) =
%
V21
(Ï†âˆ’1
1 â—¦Ï†21)âˆ—(Ï‰) =
%
V21
Ï†âˆ—
12((Ï†âˆ’1
1 )âˆ—(Ï‰)).
However, by Equation (4.14), Ï†âˆ—
21(Î·) = (det dÏ†21)Î· â—¦Ï†21. Furthermore,
by virtue of the manifold being oriented, we know that det(dÏ†21) > 0, so
det dÏ†21 = | det dÏ†21|. Thus,
%
V2
(Ï†âˆ’1
2 )âˆ—(Ï‰) =
%
V21
f â—¦Ï†21| det dÏ†21| dÂ¯x1 Â· Â· Â· dÂ¯xn =
%
V12
f dx1 Â· Â· Â· dxn
=
%
V12
(Ï†âˆ’1
1 )âˆ—(Ï‰) =
%
V1
(Ï†âˆ’1
1 )âˆ—(Ï‰).
â–¡
This lemma justiï¬es the following deï¬nition in that it is independent of
the choice of coordinate system.
Deï¬nition 4.4.9. Let M be an oriented, smooth n-dimensional manifold. Let
Ï‰ be an n-form that vanishes outside of a compact subset K of M, and
suppose that K is also a subset of a coordinate neighborhood (U, Ï†). Then
we deï¬ne the integral as
%
M
Ï‰ =
%
Ï†(U)
(Ï†âˆ’1)âˆ—(Ï‰),
where the right-hand side is an integral of a form over Rn, whose meaning
is given by Deï¬nition 4.4.7.
This deï¬nition explains how to integrate an n-form when it vanishes
outside a compact subset of a coordinate patch. If this latter criterion does
not hold, we use partitions of unity to piece together calculations that fall
under Deï¬nition 4.4.9.

4.4. Integration on Manifolds
165
Deï¬nition 4.4.10. Let M n be an oriented, smooth manifold, and let Ï‰ be an
n-form that vanishes outside a compact set. Let {Ïˆi}iâˆˆI be a partition of
unity subordinate to the atlas on M. Deï¬ne
%
M
Ï‰ =

iâˆˆI
%
M
ÏˆiÏ‰
where we calculate each summand on the left using Deï¬nition 4.4.9.
One should notice that the summation only involves a ï¬nite number
of nonzero terms since Ï‰ vanishes outside a compact set. The reader may
wonder why we only consider forms that vanish outside of a compact sub-
set of the manifold. This is similar to restricting oneâ€™s attention to deï¬nite
integrals in standard calculus courses. Otherwise, one faces improper in-
tegrals and must discuss limits. As it is, many manifolds we consider are
themselves compact; in the context of compact manifolds, the requirement
that Ï‰ vanish outside a compact subset is superï¬‚uous.
As it is, one should now understand the diï¬ƒculty of integrating n-forms
on an n-dimensional manifold. By virtue of the structure of a manifold,
simply to provide a consistent deï¬nition, one is compelled to use a formula
similar to that presented in Deï¬nition 4.4.10. On the other hand, integrals
involving terms such as eâˆ’1/x or bump functions as described in Example
4.4.5 are near impossible to compute by hand.
The next proposition outlines some properties of integration of n-forms
on n-dimensional manifolds that easily follow from properties of integration
of functions in Rn as seen in ordinary calculus. However, we ï¬rst give a
lemma that restates the change-of-variables rule in integration over Rn.
Lemma 4.4.11. Let A and B be compact subsets of Rn. Let f : A â†’B
be a smooth map whose restriction to the interior Aâ—¦is a diï¬€eomorphism
with the interior Bâ—¦. Then on Aâ—¦, f is either orientation-preserving or
orientation-reversing on each connected component. Furthermore,
%
B
Ï‰ = Â±1
%
A
f âˆ—Ï‰,
where the sign is +1 (respectively, âˆ’1) if f is orientation-preserving (re-
spectively, orientation-reversing) over A.
Proof: By the Inverse Function Theorem, f âˆ’1 is diï¬€erentiable at a point
f(p) if and only if dfp is invertible and if and only if det dfp Ì¸= 0. Since
each component function in the matrix of dfp is continuous, then det dfp is

166
4. Analysis on Manifolds
a continuous function from A to R. By the Intermediate Value Theorem,
det dfp does not change signs over any connected component of Aâ—¦. Thus,
f is orientation-preserving or orientation-reversing on each connected com-
ponent of Aâ—¦.
Let (x1, x2, Â· Â· Â· , xn) be a system of coordinates on A âŠ‚Rn and (y1,
y2, Â· Â· Â· , yn) a system of coordinates on B âŠ‚Rn. Then we can write Ï‰ =
Î± dy1 âˆ§Â· Â· Â· âˆ§dyn for a smooth function Î± : Rn â†’R. By Problem 4.3.13,
f âˆ—Ï‰ = Î± â—¦f(det df) dx1 âˆ§Â· Â· Â· âˆ§dxn.
Furthermore, according to the change-of-variables formula for integration
in Rn (see [52, Section 16.9, Equations (9) and (13)]) in the usual calculus
notation, we have
%
B
Î± dy1 dy2 Â· Â· Â· dyn =
%
A
Î± â—¦f | det df| dx1 dx2 Â· Â· Â· dxn.
Therefore, if f is orientation-preserving on A,
%
B
Ï‰ =
%
B
Î± dy1 dy2 Â· Â· Â· dyn =
%
A
Î± â—¦f | det df| dx1 dx2 Â· Â· Â· dxn
=
%
A
Î± â—¦f(det df) dx1 dx2 Â· Â· Â· dxn =
%
A
f âˆ—Ï‰.
If f is orientation-reversing, the above reasoning simply changes by
| det df| = âˆ’det df and a âˆ’1 factors out of the integral.
â–¡
Proposition 4.4.12 (Properties of Integration). Let M and N be oriented, smooth
manifolds with or without boundaries. Let Ï‰ and Î· be smooth forms that
vanish outside of a compact set on M.
1. Linearity: For all a, b âˆˆR,
3
M(aÏ‰ + bÎ·) = a
3
M Ï‰ + b
3
M Î·.
2. Orientation change: If we denote by (âˆ’M) the manifold M but with
the opposite orientation, then
%
(âˆ’M)
Ï‰ = âˆ’
%
M
Ï‰.
3. Substitution rule: If g : N â†’M is an orientation-preserving diï¬€eo-
morphism, then
%
M
Ï‰ =
%
N
gâˆ—Ï‰.

4.4. Integration on Manifolds
167
Proof: Part 1 is left as an exercise for the reader.
If M is an oriented manifold with atlas {(UÎ±, Ï†Î±)}Î±âˆˆI, then equipping
M with an opposite orientation means giving a diï¬€erent atlas {(VÎ², ËœÏ†Î²)}Î²âˆˆJ
such that det d(ËœÏ†Î² â—¦Ï†Î±) < 0 whenever ËœÏ†Î² â—¦Ï†Î± is deï¬ned. Following the
proof of Lemma 4.4.8, one can show from the reversal in orientation that
%
(âˆ’K)
Ï‰ = âˆ’
%
K
Ï‰
for any compact set K in any intersection UÎ± âˆ©VÎ². Hence, by using ap-
propriate partitions of unity and piecing together the integral according to
Deï¬nition 4.4.10, we deduce part 2 of the proposition.
To prove part 3, assume again that Ï‰ is compactly supported in just
one coordinate chart (U, Ï†) of M. Otherwise, using a partition of unity, we
can write Ï‰ as a ï¬nite sum of n-forms, each compactly supported in just
one coordinate neighborhood.
Without loss of generality, suppose that
gâˆ’1(U) is a subset of a coordinate chart (V, Ïˆ) on N. Saying that g is
orientation-preserving means that det(Ï† â—¦g â—¦Ïˆâˆ’1) > 0. Since gâˆ’1(U) âŠ‚V ,
then V contains the support of gâˆ—Ï‰. Now, by applying Lemma 4.4.11 to
the diï¬€eomorphism Ï† â—¦g â—¦Ïˆâˆ’1, we have
%
M
Ï‰ =
%
Ï†(U)
(Ï†âˆ’1)âˆ—Ï‰ =
%
Ïˆ(V )
(Ï† â—¦g â—¦Ïˆâˆ’1)âˆ—(Ï†âˆ’1)âˆ—Ï‰
=
%
Ïˆ(V )
(Ï†âˆ’1 â—¦Ï† â—¦g â—¦Ïˆâˆ’1)âˆ—Ï‰ =
%
Ïˆ(V )
(g â—¦Ïˆâˆ’1)âˆ—Ï‰
=
%
Ïˆ(V )
(Ïˆâˆ’1)âˆ—(gâˆ—Ï‰) =
%
N
gâˆ—Ï‰.
â–¡
The following useful proposition combines some of the above properties
and gives a method to calculate integrals of forms on a manifold using
parametrizations while avoiding the use of an explicit partition of unity.
The proposition breaks the calculation into integrals over compact subsets
of Rn, but we need to ï¬rst comment on what types of compact sets we
can allow. We will consider compact sets C âŠ‚Rn whose boundary âˆ‚C has
â€œmeasure 0.â€ By â€œmeasure 0,â€ we mean
3
âˆ‚C 1 dV . More intuitively, we do
not want C to be strange enough that its boundary âˆ‚C has any n-volume.
Proposition 4.4.13. Let M m be a smooth, oriented manifold with or without
boundary. Suppose that there exists a ï¬nite collection {Ci}k
i=1 of compact
subsets of Rm, each with boundary âˆ‚Ci of measure 0, along with a collection
of smooth functions Fi : Ci â†’M such that: (1) each Fi is a diï¬€eomorphism

168
4. Analysis on Manifolds
from the interior Câ—¦
i onto the interior Fi(Ci)o and (2) any pair Fi(Ci) and
Fj(Cj) intersect only along their boundary. Then for any n-form Ï‰ on M,
which has a compact support that is contained in F1(C1) âˆªÂ· Â· Â· âˆªFk(Ck),
%
M
Ï‰ =
k

i=1
%
Ci
F âˆ—
i Ï‰.
Proof: We need the following remarks from set theory and topology. Recall
that for any function f : X â†’Y and any subsets A, B of Y , we have
f âˆ’1(A âˆªB) = f âˆ’1(A) âˆªf âˆ’1(B) and f âˆ’1(A âˆ©B) = f âˆ’1(A) âˆ©f âˆ’1(B). For
general functions, the same equalities do not hold when one replaces f with
f âˆ’1. However, if f is bijective, the equality does hold in both directions.
Let A = {(UÎ±, Ï†Î±)}Î±âˆˆI be the atlas given on M. Let K be the support
of Ï‰. Note that since each Fi is continuous, then Fi(Ci) is compact.
Suppose ï¬rst that K is a subset of a single coordinate chart (U0, Ï†).
Since K âŠ‚F1(C1) âˆªÂ· Â· Â· âˆªFk(Ck),
K = K âˆ©(F1(C1) âˆªÂ· Â· Â· âˆªFk(Ck)) = (F1(C1) âˆ©K) âˆªÂ· Â· Â· âˆª(Fk(Ck) âˆ©K),
and, again, because Ï† is a bijection,
Ï†(K) = (Ï† â—¦F1(C1) âˆ©Ï†(K)) âˆªÂ· Â· Â· âˆª(Ï† â—¦Fk(Ck) âˆ©K) .
(4.15)
Since Ï† is a homeomorphism and since any pair Fi(Ci) and Fj(Cj) intersect
only along their boundaries, then the same holds for any pair Kâˆ©Fi(Ci) and
K âˆ©Fj(Cj) and also for any pair Ï†(K)âˆ©(Ï†â—¦Fi)(Ci) and Ï†(K)âˆ©(Ï†â—¦Fj)(Cj).
By deï¬nition of integration of n-forms over a coordinate chart, i.e.,
Deï¬nition 4.4.9,
%
M
Ï‰ =
%
Ï†(U)
(Ï†âˆ’1)âˆ—Ï‰ =
%
Ï†(K)
(Ï†âˆ’1)âˆ—Ï‰.
By Equation (4.15) and the theorem on subdividing an integral by nonover-
lapping regions in Rn (see [52, Section 16.3, Equation (9)] for the statement
for integrals over R2),
%
M
Ï‰ =
k

i=1
%
Ï†(K)âˆ©(Ï†â—¦Fi)(Ci)
(Ï†âˆ’1)âˆ—Ï‰.
Note that this is precisely where we need to require that the Ci have bound-
aries of measure 0.

4.4. Integration on Manifolds
169
The setup for the proposition was speciï¬cally designed to apply Lemma
4.4.11 to the function Ï† â—¦Fi : Ci â†’(Ï† â—¦Fi)(Ci) for each i âˆˆ{1, . . ., k}. We
have
%
Ï†(K)âˆ©Ï†â—¦Fi(Ci)
(Ï†âˆ’1)âˆ—Ï‰ =
%
F âˆ’1
i
(K)âˆ©Ci
(Ï† â—¦Fi)âˆ—(Ï†âˆ’1)âˆ—Ï‰
=
%
F âˆ’1
i
(K)âˆ©Ci
F âˆ—
i Ï‰ =
%
Ci
F âˆ—
i Ï‰,
and the proposition follows for when K is a subset of a single coordinate
chart.
If K is not a subset of a single coordinate chart, we use a partition of
unity subordinate to the atlas of M. In this case, the proposition again fol-
lows, using Proposition 4.3.8(2), so that for each partition-of-unity function
Ïˆj, we have
F âˆ—
i (ÏˆjÏ‰) = (Ïˆj â—¦Fi)F âˆ—
i Ï‰.
â–¡
We are ï¬nally in a position to present an example of integration of
n-forms on a smooth n-manifold.
Example 4.4.14. Consider the 2-torus T = T2 = S1 Ã— S1 embedded in R3 as
the locus of the parametrization
F(u, v) = ((3 + cos v) cos u, (3 + cos v) sin u, sin v)
for (u, v) âˆˆ[0, 2Ï€]2.
We choose an atlas on T so that the function F : (0, 2Ï€)2 â†’T gives
a parametrization of one coordinate system. Since T = F([0, 2Ï€]2) and
[0, 2Ï€]2 is compact, then we can apply Proposition 4.4.13 to this situation,
with k = 1. Thus, for any 2-form on T ,
%
T
Ï‰ =
%
[0,2Ï€]2 F âˆ—Ï‰.
For example, consider Ï‰ = âˆ’y dx âˆ§dz + x dy âˆ§dz and calculate
3
T Ï‰.
First, we calculate
F âˆ—(dx âˆ§dz) = d((3 + cos v) cos u) âˆ§d(sin v)
= âˆ’sin u cosv(3 + cos v) du âˆ§dv,
F âˆ—(dy âˆ§dz) = d((3 + cos v) sin u) âˆ§d(sin v)
= cos u cos v(3 + cos v) du âˆ§dv.

170
4. Analysis on Manifolds
Thus,
F âˆ—Ï‰ = âˆ’(3 + cos v) sin u F âˆ—(dx âˆ§dz) + (3 + cos v) cos u F âˆ—(dy âˆ§dz)
= (3 + cos v)2 cos v du âˆ§dv.
Therefore, we calculate that
%
T
Ï‰ =
%
[0,2Ï€]2(3 + cos v)2 cos v du âˆ§dv
=
% 2Ï€
0
% 2Ï€
0
(3 + cos v)2 cos v du dv
= 2Ï€
% 2Ï€
0
3 cosv + 6 cos2 v + 9 cos3 v dv = 12Ï€2.
Example 4.4.15. Consider the unit sphere S2 in R3 covered by the six coordi-
nate patches described in Example 3.1.5. Adjusting notation to F1 = âƒ—X(1)
and F2 = âƒ—X(2), one observes that if we use the compact set C1 = C2 as the
closed unit disk {(u, v) | u2 + v2 â‰¤1}, then the sphere can be covered by
F1(C1) and F2(C2). Thus, we have k = 2 in the setup of Proposition 4.4.13.
Consider the 2-form Ï‰ = xz3 dy âˆ§dz on S2, with the x, y, z representing
the coordinates in R3. We have
F1(u, v) = (u, v,

1 âˆ’u2 âˆ’v2)
and
F2(u, v) = (u, v, âˆ’

1 âˆ’u2 âˆ’v2),
so we calculate that
F âˆ—
1 Ï‰ = u(1 âˆ’u2 âˆ’v2)3/2 dv âˆ§

âˆ’
u
âˆš
1 âˆ’u2 âˆ’v2 du âˆ’
v
âˆš
1 âˆ’u2 âˆ’v2 dv
	
= u2(1 âˆ’u2 âˆ’v2) du âˆ§dv,
and similarly, F âˆ—
2 Ï‰ = u2(1 âˆ’u2 âˆ’v2) du âˆ§dv. Then by Proposition 4.4.13,
%
S2 Ï‰ =
%
C1
F âˆ—
1 Ï‰ +
%
C2
F âˆ—
2 Ï‰ = 2
%
C1
u2(1 âˆ’u2 âˆ’v2) du dv.
Putting this in polar coordinates, we get
%
S2 Ï‰ = 2
% 2Ï€
0
% 1
0
r2 cos2 Î¸(1 âˆ’r2)r dr dÎ¸ = 2Ï€
% 1
0
r3 âˆ’r5 dr = Ï€
6 .
The above two examples actually illustrate a special case of a particular
situation. Both the sphere S2 and the torus T2 are (embedded) submani-
folds of R3. The examples motivate the following deï¬nition.

4.4. Integration on Manifolds
171
Deï¬nition 4.4.16 (Integration on Submanifolds). If M is an immersed subman-
ifold of dimension m with the immersion f : M m â†’N n and if Ï‰ âˆˆÎ©m(N),
then we deï¬ne
%
f(M)
Ï‰ =
%
M
f âˆ—Ï‰.
A particular case of this deï¬nition is a line integral.
Deï¬nition 4.4.17. Let Î³ : [a, b] â†’M be a smooth curve, and let Ï‰ be a
1-form on M. We deï¬ne the line integral of Ï‰ over Î³ as
%
Î³
Ï‰ =
%
[a,b]
Î³âˆ—Ï‰.
In addition, if Î³ is a piecewise-smooth curve, we deï¬ne
%
Î³
Ï‰ =
k

i=1
%
[ciâˆ’1,ci]
Î³âˆ—Ï‰,
where [ciâˆ’1, ci], with i = 1, . . . , k, are the smooth arcs of Î³.
At the beginning of this section, we proposed to ï¬nd a deï¬nition of
integration that generalizes many common notions from standard calculus.
We explain now how the above two deï¬nitions generalize the concepts of
line integrals in Rn and integrals of vector ï¬elds over surfaces.
Consider ï¬rst the situation of line integrals in R3. (The case for Rn
is identical in form.) In vector calculus (see [52, Deï¬nition 17.2.13]), one
considers a continuous vector ï¬eld âƒ—F : R3 â†’R3 deï¬ned over a smooth
curve âƒ—Î³ : [a, b] â†’R3. Then one deï¬nes the line integral as
%
âƒ—Î³
âƒ—F Â· dâƒ—r =
% b
a
âƒ—F(âƒ—Î³(t)) Â· âƒ—Î³â€²(t) dt.
To connect the classic line integral to the line integral in our present for-
mulation, set Ï‰ = F1 dx + F2 dy + F3 dz, where âƒ—F = (F1, F2, F3). If we
write Î³(t) = âƒ—Î³(t) = (Î³1(t), Î³2(t), Î³3(t)), then
Î³âˆ—Ï‰ = F1(Î³(t))d(Î³1) + F2(Î³(t))d(Î³2) + F3(Î³(t))d(Î³3)
=

F1(Î³(t))(Î³1)â€²(t) + F2(Î³(t))(Î³2)â€²(t) + F3(Î³(t))(Î³3)â€²(t)

dt
= âƒ—F(âƒ—Î³(t)) Â· âƒ—Î³â€²(t) dt.
Thus, we have shown that the classic and modern line integrals are equal via
%
Î³
Ï‰ =
% b
a
Î³âˆ—Ï‰ =
%
âƒ—Î³
âƒ—F Â· dâƒ—r.

172
4. Analysis on Manifolds
Second, consider the situation for surface integrals. In vector calculus
(see [52, Deï¬nitions 17.7.8 and 17.7.9]), one considers a continuous vector
ï¬eld âƒ—F : R3 â†’R3 deï¬ned over an oriented surface S parametrized by
âƒ—r : D â†’R3, where D is a compact region in R2. If (u, v) are the variables
used in D, then
%%
S
âƒ—F Â· dâƒ—S =
%%
D
âƒ—F(âƒ—r(u, v)) Â· (âƒ—ru Ã— âƒ—rv) dA.
To demonstrate the connection with the modern formulation, if we write
âƒ—F = (F1, F2, F3), then set
Ï‰ = F1Î·1 + F2Î·2 + F3Î·3,
where Î·j are the 2-forms described in Equation (4.10). Set also f(u, v) =
âƒ—r(u, v), and write f = (f 1, f 2, f 3) as component functions in R3. Then
f âˆ—Ï‰ = F1(f(u, v))f âˆ—Î·1 + F2(f(u, v))f âˆ—Î·2 + F3(f(u, v))f âˆ—Î·3.
(4.16)
But we calculate that
f âˆ—Î·1 = f âˆ—(dx2 âˆ§dx3) = df 2 âˆ§df 3
=
âˆ‚f 2
âˆ‚u du + âˆ‚f 22
âˆ‚v
dv
	
âˆ§
âˆ‚f 3
âˆ‚u du + âˆ‚f 3
âˆ‚v dv
	
=
âˆ‚f 2
âˆ‚u
âˆ‚f 3
âˆ‚v âˆ’âˆ‚f 2
âˆ‚v
âˆ‚f 3
âˆ‚u
	
du âˆ§dv.
Repeating similar calculations for f âˆ—Î·2 and f âˆ—Î·3 and putting the results
in Equation (4.16), we arrive at
f âˆ—Ï‰ = âƒ—F(âƒ—r(u, v)) Â· (âƒ—ru Ã— âƒ—rv) du âˆ§dv.
Using Deï¬nition 4.4.16 for the integration on a submanifold, we conclude
that
%
S
Ï‰ =
%
D
f âˆ—Ï‰ =
%%
S
âƒ—F Â· dâƒ—S,
thereby showing how integration of 2-forms on a submanifold gives the
classical surface integral.
It is interesting to observe how the integration of forms on manifolds
and on submanifolds of a manifold generalizes simultaneously many of the
integrals that are studied in classic calculus, which are in turn studied for
their applicability to science. However, the reader who has been check-
ing oï¬€the list at the beginning of this section of types of integration we

4.4. Integration on Manifolds
173
proposed to generalize might notice that until now we have not provided
generalizations for path integrals
3
C f ds or integrals of scalar functions
over a surface
3
S f dA. The reason for this is that these integrals involve
an arclength element ds or a surface area element dA.
However, given
a smooth manifold M without any additional structure, there is no way
to discuss distances, areas, or n-volumes on M. Riemannian manifolds,
which we introduce in the next chapter, provide a structure that allows us
to make geometric calculations of length and volume. In that context, one
can easily deï¬ne generalizations of path integrals and integrals of scalar
functions over a surface.
Before moving on to applications to physics, we mention a special case
where the line integral is easy to compute.
Theorem 4.4.18 (Fundamental Theorem for Line Integrals). Let M be a smooth
manifold, let f : M â†’R be a smooth function, and let Î³ : [a, b] â†’M be a
piecewise-smooth curve on M. Then
%
Î³
df = f(Î³(a)) âˆ’f(Î³(b)).
Proof: By Proposition 4.3.8(3), Î³âˆ—(df) = d(Î³âˆ—f), so we have
Î³âˆ—(df) = d(Î³âˆ—f) = d(f â—¦Î³) = (f â—¦Î³)â€²(t) dt,
where t is the variable on the manifold [a, b]. Thus,
%
Î³
df =
%
[a,b]
Î³âˆ—(df) =
% b
a
(f â—¦Î³)â€²(t) dt = f(Î³(a)) âˆ’f(Î³(b)).
â–¡
4.4.3
Conservative Vector Fields
We now wish to look at a central topic from elementary physics through
the lens of our theory of integration on a manifold.
In elementary physics, one of the ï¬rst areas one studies is the dynamics
of a particle under the action of a force or force ï¬eld. We remind the reader
of some basic facts from physics. Suppose a particle of constant mass m
is acted upon by a force âƒ—F (which may depend on time and space) and
follows a trajectory parametrized by âƒ—r(t). Writing âƒ—v = âƒ—r â€² for the velocity
and v = âˆ¥âƒ—vâˆ¥for the speed of the particle, one deï¬nes the kinetic energy by
T = 1
2mv2. Furthermore, since m is constant, according to Newtonâ€™s law

174
4. Analysis on Manifolds
of motion, âƒ—F = mâƒ—v â€². Finally, as the particle travels for t1 â‰¤t â‰¤t2, one
deï¬nes the work done by âƒ—F as the line integral
W =
% t2
t1
âƒ—F Â· dâƒ—r.
The kinetic energy T depends on time, so we have
dT
dt = d
dt
1
2mâƒ—v Â· âƒ—v
	
= mdâƒ—v
dt Â· âƒ—v.
Thus, as a particle moves along âƒ—r(t) for t1 â‰¤t â‰¤t2, the change in kinetic
energy is
T2 âˆ’T1 = T (t2) âˆ’T (t1) =
% t2
t1
âƒ—F Â· âƒ—v dt =
% t2
t1
âƒ—F Â· dâƒ—r = W.
(4.17)
Thus, the change in kinetic energy is equal to the work done by the external
forces. This result is often called the Energy Theorem. A force is called
conservative if it does not depend on time and, if, as a particle travels over
any closed, piecewise, smooth curve the kinetic energy does not change.
Though in physics one simply speaks of vector ï¬elds, because of the
transformational properties under a coordinate change, one should in fact
usually understand them as covector ï¬elds, i.e., as either 1-forms or 2-forms.
The possible confusion between whether a given â€œvector ï¬eldâ€ should be
understood as a 1-form or a 2-form stems from the fact that over a smooth
manifold of dimension 3, for each p âˆˆM, 11 TpM âˆ—, 12 TpM âˆ—, and TpM
are all isomorphic as vector spaces.
Deï¬nition 4.4.19. A 1-form (covector ï¬eld) on a smooth manifold M is called
conservative if
%
Î³
Ï‰ = 0
for all closed, piecewise-smooth curves Î³ on M.
This deï¬nition has a diï¬€erent and perhaps more useful characterization.
If Î³1 and Î³2 are two piecewise-smooth paths from points p1 to p2, then the
path Î³1 â€¢ (âˆ’Î³2) deï¬ned by ï¬rst traveling from p1 to p2 along Î³1 and then
traveling backwards from p2 to p1 along Î³2 is a closed, piecewise-smooth
curve (see Figure 4.7). It is not hard to show that for any 1-form Ï‰,
%
Î³1â€¢(âˆ’Î³2)
Ï‰ =
%
Î³1
Ï‰ +
%
(âˆ’Î³2)
Ï‰ =
%
Î³1
Ï‰ âˆ’
%
Î³2
Ï‰.

4.4. Integration on Manifolds
175
p1
p2
Î³1
Î³2
Figure 4.7. Two paths between p1 and p2.
Hence, a covector ï¬eld Ï‰ is conservative if and only if the integral of Ï‰
between any two points p1 and p2 is independent of the path between
them.
A smooth 1-form has another alternative characterization, whose proof
we leave as an exercise for the reader.
Theorem 4.4.20. Let M be any smooth manifold. A 1-form Ï‰ âˆˆÎ©1(M) is
conservative if and only if Ï‰ is exact.
Returning to physics in Euclidean R3, according to the Energy Theo-
rem from Equation (4.17), a force is conservative if and only if the work
done over a piecewise-smooth path between any two points p1 and p2 is
independent of the path chosen. Thus, if âƒ—F is conservative, one deï¬nes the
potential energy by
V (x, y, z) = âˆ’
% (x,y,z)
(x0,y0,z0)
âƒ—F Â· dâƒ—r.
where (x0, y0, z0) is any ï¬xed point. Obviously, the potential energy of âƒ—F
is a function that is well deï¬ned only up to a constant that corresponds to
the selected origin point (x0, y0, z0). It is easy to check that
âƒ—F = âˆ’âˆ‡V.
For a conservative force âƒ—F with potential energy V , the work of âƒ—F as
the particle travels along âƒ—r(t) for t âˆˆ[t1, t2] is
W =
% t2
t1
âƒ—F Â· dâƒ—r = âˆ’
% t2
t1
âˆ‡V Â· dâƒ—r = âˆ’(V (âƒ—r(t2)) âˆ’V (âƒ—r(t1))) = âˆ’(V2 âˆ’V1).
Hence, the Energy Theorem can be rewritten as
T1 + V1 = T2 + V2.

176
4. Analysis on Manifolds
The sum T + V of kinetic and potential energy is often referred to simply
as the energy or total energy of a particle. This justiï¬es the terminology
â€œconservativeâ€: the total energy of a particle moving under the action of a
conservative force is conserved along any path.
Problems
4.4.1. Let Î³ be the curve in R4 parametrized by Î³(t) = (1 + t2, 2t âˆ’1, t3 âˆ’4t, 1
t )
for t âˆˆ[1, 3]. Let Ï‰ = x dy+(y2+z) dz+xw dw. Calculate the line integral
3
Î³ Ï‰.
4.4.2. Calculate the line integral
3
Î³ Ï‰, where Î³ is the triangle in R3 with vertices
(0, 1, 2), (1, 2, 4), and (âˆ’3, 4, âˆ’2) and where Ï‰ is the 1-form given in R3 by
Ï‰ = (2xy + 1) dx + 3x dy + yz dz.
4.4.3. Evaluate
3
M Ï‰, where M is the portion of paraboloid in R3 given by z =
9âˆ’x2 âˆ’y2 above the xy-plane and where Ï‰ is the 2-form Ï‰ = y2 dx âˆ§dy +
z2 dx âˆ§dz + 2 dy âˆ§dz.
4.4.4. Let T2 be the torus embedded in R4 that is given by the equations x2+y2 =
z2 + w2 = 1. Note that the ï¬‚at torus can be parametrized by
âƒ—X(u, v) = (cos u, sin u, cos v, sin v)
for appropriate u and v. Compute the integral
3
T2 Ï‰, where Ï‰ is the 2-form
in R2 given by
(a) Ï‰ = x3 dy âˆ§dw;
(b) Ï‰ = x3z dy âˆ§dw;
(c) Ï‰ = (xyz + 1) dx âˆ§dy + exyz dx âˆ§dw.
4.4.5. Consider the unit sphere M = S2 embedded in R3. Let
Ï‰ = z2 dx âˆ§dy + x dx âˆ§dz + xy dy âˆ§dz
x2 + y2 + z2
be a 2-form pulled back to S2. Calculate directly the integral
3
M Ï‰ using
(a) the latitude-longitude parametrization âƒ—r(u, v)=(cos u sin v, sin u sin v,
cos v);
(b) the stereographic parametrizations {Ï€n, Â¯Ï€S} deï¬ned in Problem 3.2.4
and Example 3.1.16. [Hint: Use two coordinate patches.]
4.4.6. Consider the 3-torus described in Problem 4.2.6. Calculate
3
M Ï‰, where
(a) Ï‰ = (cos2 v + (1 + sin w)/(2 + cos u)) du âˆ§dv âˆ§dw given in local
coordinates;
(b) Ï‰ = x1 dx1 âˆ§dx2 âˆ§dx3 + x2 dx2 âˆ§dx3 âˆ§dx4 in coordinates in R4.

4.5. Stokesâ€™ Theorem
177
4.4.7. Prove part 1 of Proposition 4.4.12.
4.4.8. The force exerted by an electric charge placed at the origin on a charged
particle is given by the force ï¬eld âƒ—F(âƒ—r) = Kâƒ—r/âˆ¥âƒ—râˆ¥3, where K is a constant
and âƒ—r = (x, y, z) is the position vector of the charged particle.
(a) Calculate the work exerted by the force on a charged particle that
travels along the straight line from (3, âˆ’1, 2) to (4, 5, âˆ’1).
(b) Prove that âƒ—F is a conservative force.
(c) If we write âƒ—F = (F1, F2, F3) in component functions, then set Ï‰ =
F1Î·1 +F2Î·2 +F3Î·3. Calculate
3
M Ï‰, where M is the sphere of radius
R in R3.
4.4.9. Let T2 be the 2-torus embedded in R3, using the parametrization given in
Example 4.4.14. Show by direct calculation that
%
T2 Ï‰ = 0
where Ï‰ is the 2-form described in Problem 4.4.8.
4.4.10. Let M be a smooth, oriented manifold. Referring to Example 4.4.20, prove
that a smooth (co)vector ï¬eld Ï‰ on M is conservative if and only if Ï‰ is
exact.
4.5
Stokesâ€™ Theorem
In the last section of this chapter, we present Stokesâ€™ Theorem, a central
result in the theory of integration on manifolds.
In multivariable calculus, one encounters a theorem by the same name.
What is called Stokesâ€™ Theorem for vector ï¬elds in R3 states that if S is
an oriented, piecewise-smooth surface that is bounded by a simple closed,
piecewise-smooth curve C, then for any C1 vector ï¬eld âƒ—F deï¬ned over an
open region that contains S,
%
C
âƒ—F Â· dâƒ—r =
%
S
(âˆ‡Ã— âƒ—F) Â· dâƒ—S.
(See [52, Section 17.8].)
It is a striking result that the generalization of this theorem to the
context of manifolds simultaneously subsumes the Fundamental Theorem
of Integral Calculus, Greenâ€™s Theorem, the classic Stokesâ€™ Theorem, and
the Divergence Theorem.
Before giving the theorem, we state a convention for what it means
to integrate a 0-form on an oriented, zero-dimensional manifold.
If N

178
4. Analysis on Manifolds
is an oriented zero-dimensional manifold, then N = {p1, p2, . . . , pc} is a
discrete set of points equipped with an association of signs si = Â±1 for
each i = 1, . . . , c. Then by convention for any 0-form f (i.e., a function
on N),
%
N
f =
c

i=1
sif(pi).
(4.18)
Theorem 4.5.1 (Stokesâ€™ Theorem). Let M n be a smooth, oriented manifold with
or without boundary, and let Ï‰ be an (n âˆ’1)-form that is compactly sup-
ported on M.
If one equips âˆ‚M with the induced orientation, then the
following integrals are equal
%
M
dÏ‰ =
%
âˆ‚M
Ï‰,
(4.19)
where on the right side we take Ï‰ to mean the restriction of Ï‰ to âˆ‚M. If
âˆ‚M = âˆ…, we understand the right side as 0.
Proof: We ï¬rst treat the case where n > 1.
Suppose ï¬rst that Ï‰ is compactly supported in a single coordinate chart
(U, Ï†). Then by the deï¬nition of integration and by Proposition 4.3.8,
%
M
dÏ‰ =
%
Rn
+
(Ï†âˆ’1)âˆ—dÏ‰ =
%
Rn
+
d

(Ï†âˆ’1)âˆ—Ï‰

.
Using the (nâˆ’1)-forms Î·j deï¬ned in Equation (4.10) as a basis for Î©n(Rn
+),
write (Ï†âˆ’1)âˆ—Ï‰ = "n
j=1 Ï‰jÎ·j. Then, for the exterior diï¬€erential, we have
d

(Ï†âˆ’1)âˆ—Ï‰

=
n

j=1
 n

i=1
âˆ‚Ï‰j
âˆ‚xi dxi

âˆ§Î·j
=
 n

i=1
âˆ‚Ï‰i
âˆ‚xi

dx1 âˆ§Â· Â· Â· âˆ§dxn,
where the second equality follows from Equation (4.11).
Since Ï‰ is compactly supported in U, then for large enough R, the
component functions Ï‰i(x1, . . . , xn) vanish identically outside the paral-
lelepiped
DR = [âˆ’R, R] Ã— Â· Â· Â· Ã— [âˆ’R, R]
(
)*
+
nâˆ’1
Ã— [0, R].

4.5. Stokesâ€™ Theorem
179
Therefore, we remark that for all i = 1, . . . , n âˆ’1, we have
% R
âˆ’R
âˆ‚Ï‰i
âˆ‚xi dxi = [Ï‰i(x)]xi=R
xi=âˆ’R = 0.
(4.20)
Consequently, we deduce that
%
M
dÏ‰ =
% R
0
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
 n

i=1
âˆ‚Ï‰i
âˆ‚xi

dx1 Â· Â· Â· dxnâˆ’1 dxn
=
n

i=1
% R
0
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
âˆ‚Ï‰i
âˆ‚xi dx1 Â· Â· Â· dxn
=
nâˆ’1

i=1
% R
0
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
% R
âˆ’R
âˆ‚Ï‰i
âˆ‚xi dxi

dx1 Â· Â· Â· &
dxi Â· Â· Â· dxn
+
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
% R
0
âˆ‚Ï‰n
âˆ‚xn dxn

dx1 Â· Â· Â· dxnâˆ’1
=
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
[Ï‰n(x)]xn=R
xn=0 dx1 Â· Â· Â· dxnâˆ’1
by Equation (4.20)
= âˆ’
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
Ï‰n(x1, . . . , xnâˆ’1, 0) dx1 Â· Â· Â· dxnâˆ’1,
(4.21)
where the last equality holds because Ï‰n(x1, . . . , xnâˆ’1, R) = 0. Note that if
the support of Ï‰ does not meet the boundary âˆ‚M, then Ï‰n(x1, . . . , xnâˆ’1, 0)
is also identically 0 and 3
M Ï‰ = 0.
To understand the right-hand side of Equation (4.19), let i : âˆ‚M â†’M
be the embedding of the boundary into M. The restriction of Ï‰ to âˆ‚M
is iâˆ—(Ï‰).
Furthermore, in coordinates in (U, Ï†), iâˆ—(dxk) = dxk if k =
1, . . . , n âˆ’1 and iâˆ—(dxn) = 0. Hence, iâˆ—(Î·j) = 0 for all j Ì¸= n. Thus, in
coordinates,
iâˆ—(Ï‰) = Ï‰n(x1, Â· Â· Â· , xnâˆ’1, 0)Î·n
= (âˆ’1)nâˆ’1Ï‰n(x1, Â· Â· Â· , xnâˆ’1, 0) dx1 âˆ§Â· Â· Â· âˆ§dxnâˆ’1.
However, by Deï¬nition 3.3.12 for the orientation induced on the boundary
of a manifold, we have
%
âˆ‚M
a(x) dx1 âˆ§Â· Â· Â· âˆ§dxnâˆ’1 = (âˆ’1)n
%
Rnâˆ’1 a(x) dx1 Â· Â· Â· dxnâˆ’1

180
4. Analysis on Manifolds
for the (n âˆ’1)-form a dx1 âˆ§Â· Â· Â· âˆ§dxnâˆ’1. Thus,
%
âˆ‚M
Ï‰ =
%
âˆ‚M
iâˆ—(Ï‰)
=
%
DRâˆ©{xn=0}
(âˆ’1)nâˆ’1Ï‰n(x1, Â· Â· Â· , xnâˆ’1, 0) dx1 âˆ§Â· Â· Â· âˆ§dxnâˆ’1
= âˆ’
% R
âˆ’R
Â· Â· Â·
% R
âˆ’R
Ï‰n(x1, . . . , xnâˆ’1, 0) dx1 Â· Â· Â· dxnâˆ’1,
which by Equation (4.21) is equal to
3
M dÏ‰. This proves Equation (4.19)
for the case when Ï‰ is supported in a compact subset of a single coordinate
patch.
Suppose now that Ï‰ is supported over a compact subset K of M that is
not necessarily a subset of any particular coordinate patch in the atlas A =
{(UÎ±, Ï†Î±)} for M. Then we use a partition of unity {ÏˆÎ±} that is subordinate
to A.
Since K is compact, we can cover it with a ï¬nite collection of
coordinate patches {(Ui, Ï†i)}k
i=1. Then
%
âˆ‚M
Ï‰ =
k

i=1
%
âˆ‚M
ÏˆiÏ‰ =
k

i=1
%
M
d(ÏˆiÏ‰)
by application of Stokesâ€™ Theorem for each form ÏˆiÏ‰ that is supported over
a compact set in the coordinate patch Ui. But d(ÏˆiÏ‰) = dÏˆi âˆ§Ï‰ +ÏˆidÏ‰, so
%
âˆ‚M
Ï‰ =
k

i=1
%
M
(dÏˆi âˆ§Ï‰ + ÏˆidÏ‰)
=
k

i=1
%
M
dÏˆi âˆ§Ï‰ +
k

i=1
%
M
ÏˆidÏ‰
=
%
M
d
 k

i=1
Ïˆi

âˆ§Ï‰ +
k

i=1
%
M
ÏˆidÏ‰
=
%
M
d(1) âˆ§Ï‰ +
k

i=1
%
M
ÏˆidÏ‰
= 0 +
k

i=1
%
M
ÏˆidÏ‰
=
%
M
dÏ‰.
This establishes Stokesâ€™ Theorem for n > 1.

4.5. Stokesâ€™ Theorem
181
Now consider the case of a 1-manifold M; then âˆ‚M is a zero-dimensional
manifold. The 0-form Ï‰ is simply a real-valued function on M. Now for a
compact set K contained in a coordinate system Ï† : U â†’R+ on M, the
intersection Kâˆ©âˆ‚M is either empty or consists of a single point {pi}. Thus,
with the assumption that Ï‰ is supported over a compact set contained in
a coordinate patch of M, we conclude that

M
df = f(pi)si
simply by the usual Fundamental Theorem of Integral Calculus. By the
convention in Equation (4.18) for integration on a zero-dimensional man-
ifold, we also have

âˆ‚M f = f(pi)si. Utilizing a partition of unity when
Ï‰ is not assumed to be supported in a single coordinate patch, one also
immediately recovers Stokesâ€™ Theorem.
â–¡
Two cases of Stokesâ€™ Theorem occur frequently enough to warrant spe-
cial emphasis. The proofs are implicit in the above proof of Stokesâ€™ Theo-
rem.
Corollary 4.5.2. If M is a smooth manifold without boundary and Ï‰ is a
smooth (n âˆ’1)-form, then

M
dÏ‰ = 0.
Corollary 4.5.3. If M is a smooth manifold with or without boundary and Ï‰
is a smooth (n âˆ’1)-form that is closed (i.e., dÏ‰ = 0), then

âˆ‚M
Ï‰ = 0.
The convention for integrating 0-forms on a zero-dimensional manifold
allows Stokesâ€™ Theorem to directly generalize the Fundamental Theorem
of Calculus in the following way.
Consider the interval [a, b] as a one-
dimensional manifold M with boundary with orientation of displacement
from a to b. Then âˆ‚M = {a, b} with an orientation of âˆ’1 for a and +1 for b.
A 0-form on M is a smooth function f : [a, b] â†’R. Then Theorem 4.5.1
simply states that

[a,b]
df =
 b
a
f â€²(x) dx = f(b) âˆ’f(a),
which is precisely the Fundamental Theorem of Calculus.

182
4. Analysis on Manifolds
(The careful reader might remark that, as stated, Stokesâ€™ Theorem on
manifolds only generalizes the Fundamental Theorem of Calculus (FTC)
when f is a smooth function, whereas most calculus texts only presup-
pose that f is C1 over [a, b]. The history behind the FTC and the search
for exactly which functions satisfy the FTC formula is long. In fact, the
work in analysis related to the FTC in part motivated the deï¬nition of
the Lebesgue integral and also loosened the conditions on what properties
f had to satisfy.
See [12] for an excellent historical account.
Since we
restricted our attention to smooth manifolds and smooth functions, these
technical details are moot.)
It is possible to generalize Stokesâ€™ Theorem even further by includ-
ing manifolds that are piecewise-smooth or manifolds with corners. (One
should be familiar with these situations from the classic Stokesâ€™ Theorem
and the Divergence Theorem.) However, to present these generalizations
properly one must deï¬ne smoothness in these contexts and discuss orien-
tations on such objects. For the sake of space, we refrain from developing
that topic.
Problems
4.5.1. Explicitly show how Stokesâ€™ Theorem on manifolds directly generalizes
Stokesâ€™ Theorem from standard multivariable calculus.
4.5.2. Use Stokesâ€™ Theorem to evaluate
3
S dÏ‰, where S is the image in R4 of the
parametrization
r(u, v) = (1 âˆ’v)(cos u, sin u, sin 2u, 0) + v(2, cos u, sin u, sin 2u)
and where Ï‰ = x2 dx1 + x3 dx2 + x4 dx3 âˆ’x1 dx4.
4.5.3. Let B4 = {x âˆˆR4 | âˆ¥xâˆ¥â‰¤1} be the unit ball in R4, and note that âˆ‚B4 = S3.
We use the coordinates (x, y, z, w) in R4 and hence in B4. Use Stokesâ€™
Theorem to evaluate
%
S3(exy cos w dx âˆ§dy âˆ§dz + x2z dx âˆ§dy âˆ§dw).
4.5.4. Let M be a compact, oriented, n-manifold, and let Ï‰ âˆˆÎ©j(M) and Î· âˆˆ
Î©k(M), where j + k = n âˆ’1. Suppose that Î· vanishes on the boundary
âˆ‚M or that âˆ‚M = âˆ…. Show that
%
M
Ï‰ âˆ§dÎ· = (âˆ’1)jâˆ’1
%
M
dÏ‰ âˆ§Î·.
4.5.5. Let M be a compact, oriented n-manifold. Let Ï‰ and Î· be forms of rank
j and k respectively, such that j + k = n âˆ’2. Show that
%
M
dÏ‰ âˆ§dÎ· =
%
âˆ‚M
Ï‰ âˆ§dÎ·.

4.5. Stokesâ€™ Theorem
183
Explain how this generalizes the well-known result in multivariable calcu-
lus that
%
C
(fâˆ‡g) Â· dâƒ—r =
%%
S
(âˆ‡f Ã— âˆ‡g) Â· dâƒ—S,
where S is a regular surface in R3 with boundary C and where f and
g are real-valued functions that are deï¬ned and have continuous second
derivatives over an open set containing S.
4.5.6. Integration by Parts on a Curve. Let M be a compact and connected one-
dimensional smooth manifold. Let f, g : M â†’R be two smooth functions
on the curve M.
Show that âˆ‚M consists of two discrete points {p, q}.
Suppose that M is oriented so that the orientation induced on âˆ‚M is âˆ’1
for p and +1 for q. Show that
%
M
f dg = f(q)g(q) âˆ’f(p)g(p) âˆ’
%
M
g df.
4.5.7. Let M be an embedded submanifold of Rn of dimension n âˆ’1. Suppose
that M encloses a compact region R. Setting Ï‰ =
1
n("n
i=1 xiÎ·i), where
the Î·j are deï¬ned by Equation (4.10), show that the n-volume of R is
3
M Ï‰.
4.5.8. Consider M = Rn âˆ’{(0, . . . , 0)} as a submanifold of Rn, and let Snâˆ’1 be
the unit sphere in Rn centered at the origin.
(a) Show that if Ï‰ âˆˆÎ©nâˆ’1(M) is exact, then
3
Snâˆ’1 Ï‰ = 0.
(b) Find an example of a closed form Ï‰
âˆˆ
Î©nâˆ’1(M) such that
3
Snâˆ’1 Ï‰ Ì¸= 0.


CHAPTER
5
Introduction to
Riemannian Geometry
To recapitulate what we have done in the past two chapters, manifolds
are topological spaces that are locally homeomorphic to a Euclidean space
Rn in which one could do calculus.
Chapter 4 introduced the analysis
on manifolds by connecting it to analysis on Rn via coordinate charts.
However, the astute reader might have noticed that our presentation of
analysis on manifolds so far has not recovered one of the foundational
aspects of Euclidean calculus: the concept of distance. And related to the
concept of distance are angles, areas, volumes, curvature, etc.
In the local theory of regular surfaces S in R3, the ï¬rst fundamental
form (see Example 4.2.3) allows one to calculate the length of curves on
a surface, the angle between two intersecting curves, and the area of a
compact set on S (see [5, Section 6.1] for details).
This should not be
surprising: we deï¬ned the ï¬rst fundamental form on S as the restriction
of the usual Euclidean dot product in R3 to the tangent space Tp(S) for
any given point p âˆˆS, and the dot product is the basis for measures of
distances and angles in R3.
In general, manifolds are not given as topological subspaces of Rn so
one does not immediately have a ï¬rst fundamental form as we deï¬ned in
Example 4.2.3. Furthermore, from the deï¬nition of a diï¬€erential manifold,
it is not at all obvious that it has a metric (though we will see in Propo-
sition 5.1.8 that every smooth manifold has a metric structure). Conse-
quently, one must equip a manifold with a metric structure, which we will
call a â€œRiemannian structure.â€ Applications of manifolds to geometry and
curved space in physics will require this additional metric structure.
As in many mathematics text, our treatment of manifolds and Rieman-
nian metrics does not emphasize how long it took these ideas to develop
nor have the previous two chapters followed the historical trajectory of the
subject. After the discovery of non-Euclidean geometries (see [10] for a
good historical discussion), by using only an intuitive notion of a manifold,
185

186
5. Introduction to Riemannian Geometry
it was Riemann [45, Section II] in 1854 who ï¬rst proposed the idea of a
metric that varied at each point of a manifold. During the following 50
or more years, many mathematicians (Codazzi, Beltrami, Ricci-Curbastro,
Levi-Civita, and Klein, to name a few) developed the theories of curvature
and of geodesy for Riemann spaces. However, the concept of a diï¬€erential
manifold as presented in Chapter 3 did not appear until 1913 in the work of
H. Weyl [56, I.Â§4]. According to Steenrod [50, p. v], general deï¬nitions for
ï¬ber bundles and vector bundles, which we introduced in part in Chapter 4,
did not appear until the work of Whitney in 1935â€“1940.
Turning to physics, general relativity, one of the landmark achieve-
ments in science of the early twentieth century, stands as the most visible
application of Riemann manifolds to science.
Starting from the princi-
ple that the speed of light in a vacuum is constant regardless of reference
frame [20, p. 42], Einstein developed the theory of special relativity, de-
ï¬ned in the absence of gravity. The â€œinterpretationâ€ of the law that â€œthe
gravitational mass of a body is equal to its inertial massâ€ [20, p. 65] and
the intention to preserve the principle of the constancy of the speed of
light led Einstein to understand spacetime as a curved space where â€œthe
geometrical properties of space are not independent, but . . . determined by
matterâ€ [20, p. 113]. Riemannian metrics, curvature, and the associated
theorems for geodesics gave Einstein precisely the mathematical tools he
needed to express his conception of a curvilinear spacetime.
The reader should be aware that other applications of manifolds to
science do not (and should not) always require a metric structure. Appli-
cations of manifolds to either geometry or physics may require a diï¬€erent
structure from or additional structure to a Riemann metric. For exam-
ple, in its properly generalized context, Hamiltonian mechanics require the
structure of what is called a symplectic manifold.
5.1
Riemannian Metrics
5.1.1
Deï¬nitions and Examples
Deï¬nition 5.1.1. Let M be a smooth manifold. A Riemannian metric on M
is a tensor ï¬eld g in Sym2 T M âˆ—that is positive deï¬nite. In more detail, at
each point p âˆˆM, a Riemannian metric determines a symmetric bilinear
inner product on TpM that is positive deï¬nite (i.e., g(X, X) > 0 if X Ì¸= 0).
A smooth manifold M together with a Riemannian metric g is called a
Riemannian manifold and is denoted by the pair (M, g).

5.1. Riemannian Metrics
187
Over a coordinate patch of M with coordinate system (x1, . . . , xn), as
a section of T M âˆ—âŠ—2, one writes the metric g as
gij dxi âŠ—dxj,
where gij are smooth functions on M. (In this chapter, we regularly use
Einsteinâ€™s summation convention.) Since at each point, g is a symmetric
tensor, gij = gji identically. Furthermore, using the notation from Ap-
pendix Section C.5, since g is a section of Sym2 TpM âˆ—, we write
gij dxi dxj.
(5.1)
The square root of the expression in Equation (5.1) is called the line element
ds associated to this metric. Many texts, in particular, physics texts, give
the metric in reference to the line element by writing ds2 = gij dxi dxj.
For vectors X, Y âˆˆTpM, we sometimes use the same notation as the
ï¬rst fundamental form and write âŸ¨X, Y âŸ©p for gp(X, Y ), and it is also com-
mon to drop the subscript p whenever the point p is implied by context. By
analogy with the dot product, the Riemannian metric allows one to deï¬ne
many common notions in geometry.
Deï¬nition 5.1.2. Let (M, g) be a Riemannian manifold.
Suppose that X
and Y are vectors in TpM.
1. The length of X, denoted âˆ¥Xâˆ¥, is deï¬ned by âˆ¥Xâˆ¥=

g(X, X).
2. The angle Î¸ between X and Y is deï¬ned by cos Î¸ = g(X, Y )
âˆ¥Xâˆ¥âˆ¥Y âˆ¥.
3. X and Y are called orthogonal if g(X, Y ) = 0.
Whenever one introduces a new mathematical structure, one must dis-
cuss functions between them and when two structures are considered equiv-
alent. In the context of Riemannian manifolds, one still studies any smooth
functions between two manifolds. However, two Riemannian manifolds are
considered the same if they have the same metric. The following deï¬nition
makes this precise.
Deï¬nition 5.1.3. Let M and N be two Riemannian manifolds. A diffeomor-
phism f : M â†’N is called an isometry if for all p âˆˆM,
âŸ¨X, Y âŸ©p = âŸ¨dfp(X), dfp(Y )âŸ©f(p)
for all X, Y âˆˆTpM.
Two Riemannian manifolds are called isometric if there exists an isometry
between them.

188
5. Introduction to Riemannian Geometry
Figure 5.1. Bending the catenoid into the helicoid.
From an intuitive perspective, an isometry is a transformation that
bends (which also includes rigid motions) one manifold into another with-
out stretching or cutting. Problem 5.1.5 asks the reader to show that the
catenoid and the helicoid are isometric.
Figure 5.1 shows intermediate
stages of bending the catenoid into the helicoid. Though one might think
this transformation incorporates some stretching because the longitudinal
lines straighten out, the twist created in the helicoid strip â€œbalances outâ€
the ï¬‚attening of the lines in just the right way so that one only needs to
bend the surface.
Many examples of Riemannian metrics arise naturally as submanifolds
of Riemannian manifolds.
Deï¬nition 5.1.4. Let (N, Ëœg) be a Riemannian manifold and M any smooth
manifold. Let f : M â†’N be an immersion of M into N, i.e., f is diï¬€er-
entiable and dfp is injective for all p. The metric g on M induced by f (or
â€œfrom Nâ€) is deï¬ned as the pull-back g = f âˆ—Ëœg. In other words,
âŸ¨X, Y âŸ©p = âŸ¨dfp(X), dfp(Y )âŸ©f(p)
for all p âˆˆM and X, Y âˆˆTpM.
Note that the property that dfp is injective ensures that âŸ¨, âŸ©p is positive
deï¬nite.
Example 5.1.5 (Euclidean Spaces).
Consider the manifold M = Rn, where
Tp(Rn) = Rn is naturally equipped with a Riemannian metric: the usual
dot product. In particular,
g (âˆ‚i, âˆ‚j) = Î´ij =

1,
if i = j,
0,
if i Ì¸= j.
This metric is called the Euclidean metric.

5.1. Riemannian Metrics
189
Example 5.1.6 (First Fundamental Form). A regular surface S is a manifold em-
bedded in R3, where the embedding map is simply the injection i : S â†’R3.
The ï¬rst fundamental form (see Example 4.2.3) is precisely the metric on
S induced by i from the Euclidean metric on R3. This connection gives us
immediately a whole host of examples of Riemannian 2-manifolds that we
take from the local theory of regular surfaces.
Proposition 5.1.7. Let M be an m-dimensional manifold embedded in Rn. If
âƒ—F(u1, . . . , um) is a parametrization of a coordinate patch of M, then over
this coordinate patch, the coeï¬ƒcients of the metric g on M induced from
Rn are
gij = âˆ‚âƒ—F
âˆ‚ui Â· âˆ‚âƒ—F
âˆ‚uj .
Proof: Let (x1, . . . , xn) be the coordinates on Rn. Suppose that a coordi-
nate patch (U, Ï†) of M has coordinates (u1, . . . , um) and that âƒ—F(u1, . . . , um)
= Ï†âˆ’1(u1, . . . , um) is a parametrization of this coordinate patch. By Equa-
tion (3.6) the matrix of dâƒ—F in the given coordinate systems is
âˆ‚F i
âˆ‚uj
	
,
where âƒ—F = (F 1, . . . , F n).
Set âŸ¨, âŸ©as the usual dot product in Rn. Then at each point in U, the
coeï¬ƒcients gkl of the metric g satisfy
gkl = g
 âˆ‚
âˆ‚uk , âˆ‚
âˆ‚ul
	
=
4
dâƒ—F
 âˆ‚
âˆ‚uk
	
, dâƒ—F
 âˆ‚
âˆ‚uk
	5
= âˆ‚F i
âˆ‚uk
âˆ‚F j
âˆ‚ul
4 âˆ‚
âˆ‚xi , âˆ‚
âˆ‚xj
5
= âˆ‚F i
âˆ‚uk
âˆ‚F j
âˆ‚ul Î´ij = âˆ‚âƒ—F
âˆ‚uk Â· âˆ‚âƒ—F
âˆ‚ul .
â–¡
We should emphasize at this point that a given manifold can be equipped
with nonisometric Riemannian metrics. Problem 5.1.1 presents two diï¬€er-
ent metrics on the 3-torus, each depending on a diï¬€erent embedding into
some Euclidean space. In both cases, the 3-torus can be equipped with the
same atlas, and so in both situations, the 3-torus is the same as a smooth
manifold.
As another example, already in his seminal dissertation [45], Riemann
introduced the following metric on the open unit ball in Rn:
gii =
1
1 âˆ’âˆ¥xâˆ¥2
and
gij = 0 if i Ì¸= j.

190
5. Introduction to Riemannian Geometry
As we will see, this is not isometric with the open unit ball equipped with
the Euclidean metric.
Example 5.1.5 could be misleading in its simplicity. The reader might
consider the possibility of deï¬ning a metric on any smooth manifold M by
taking âŸ¨, âŸ©p as the usual dot product in each TpM with respect to the co-
ordinate basis associated to a particular coordinate system. The problem
with this idea is that it does not deï¬ne a smooth section in Sym2 T M âˆ—
over the whole manifold. Nonetheless, as the proof of the following propo-
sition shows, we can use a partition of unity and stitch these bilinear forms
together.
Proposition 5.1.8. Every smooth manifold M has a Riemannian metric.
Proof: Let M be a smooth manifold with atlas A = {(UÎ±, Ï†Î±)}Î±âˆˆI. For
each Î± âˆˆI, label âŸ¨, âŸ©Î± as the usual dot product with respect to the coor-
dinate basis over UÎ±. Let {ÏˆÎ±} be a partition of unity that is subordinate
to A. For each p âˆˆM, deï¬ne the bilinear form âŸ¨, âŸ©p on TpM by
âŸ¨X, Y âŸ©p
def
=

Î±âˆˆI
ÏˆÎ±(p)âŸ¨X, Y âŸ©Î±
p
(5.2)
for any X, Y âˆˆTpM.
Since for each p âˆˆM, only a ï¬nite number of Î± âˆˆI have ÏˆÎ±(p) Ì¸= 0,
then the sum in Equation (5.2) is ï¬nite. It is obvious by construction that
âŸ¨X, Y âŸ©p is symmetric. To prove that âŸ¨, âŸ©p is positive deï¬nite, note that
each âŸ¨X, Y âŸ©Î±
p is. Let Iâ€² be the set of all indices Î±I such that ÏˆÎ±(p) Ì¸= 0.
By deï¬nition of a partition of unity, 0 < ÏˆÎ±(p) â‰¤1. Thus, for all X âˆˆ
TpM, clearly âŸ¨X, XâŸ©p â‰¥0. Furthermore, if âŸ¨X, XâŸ©p = 0, then at least one
summand in

Î±âˆˆIâ€²
ÏˆÎ±(p)âŸ¨X, XâŸ©Î±
p
is 0.
(In fact, all summands are 0.) Thus, there exists an Î± âˆˆI with
âŸ¨X, XâŸ©Î±
p = 0. Since âŸ¨, âŸ©Î±
p is positive deï¬nite, then X = 0. Hence, âŸ¨X, XâŸ©p
itself is positive deï¬nite.
â–¡
One should note that though Equation (5.2) presents a Riemannian
metric on any smooth manifold M, this is not in general easy to work with
for speciï¬c calculations since it uses a partition of unity, which involves
functions that are usually complicated. Furthermore, at any given point
p âˆˆM, Equation (5.2) does not involve one coordinate system around p
but all of the atlasâ€™s coordinate neighborhoods of p.

5.1. Riemannian Metrics
191
5.1.2
Lengths and Volume
Using integration, the Riemannian metric allows for formulas that measure
nonlocal properties, such as length of a curve and volume of a region on a
manifold.
For example, consider a C1 curve Î³ : [a, b] â†’M on a Riemannian
manifold (M, g).
At each point Î³(t) in M, the vector Î³â€²(t) =
dÎ³
dt is a
tangent vector, called the velocity vector. The Riemannian metric g = âŸ¨, âŸ©
allows one to calculate the length âˆ¥Î³â€²(t)âˆ¥, which we call the speed. This
motivates the following deï¬nition.
Deï¬nition 5.1.9. Let Î³ : [a, b] â†’M be a curve on a Riemannian manifold
M of class C1. The arclength of the curve Î³ is
â„“(Î³) =
% b
a
!4dÎ³
dt , dÎ³
dt
5
Î³(t)
dt.
Proposition 5.1.10. Let (M, g) be an oriented Riemannian manifold of di-
mension n. There exists a unique n-form, denoted dV , such that dVp(e1, . . . ,
en) = 1 for all orthonormal bases (e1, . . . , en) in TpM. Furthermore, over
any coordinate patch U with coordinates x = (x1, . . . , xn),
dV =

det(gij) dx1 âˆ§Â· Â· Â· âˆ§dxn,
(5.3)
where gij = g(âˆ‚i, âˆ‚j) = âŸ¨âˆ‚/âˆ‚xi, âˆ‚/âˆ‚xjâŸ©.
Proof: The content of this proposition is primarily linear algebraic. By
Proposition C.6.6, on each coordinate patch UÎ±, the form dV |UÎ± = Ï‰Î±
exists on each TpM and is given by Equation (5.3). In order to deï¬ne the
form dV on the whole manifold, one refers to a partition of unity {ÏˆÎ±}
subordinate to the atlas on M and deï¬nes
dV =

Î±
ÏˆÎ±Ï‰Î±.
â–¡
Deï¬nition 5.1.11. The form dV described in Proposition 5.1.10 is called the
volume form of (M, g) and is sometimes denoted dVM if there is a chance
of confusion about the manifold.
If M m is a compact manifold, then we can integrate dV over M. In
that case, we deï¬ne the m-volume of M as the integral
Vol(M) =
%
M
dV.

192
5. Introduction to Riemannian Geometry
If i : M m â†’N n is an embedded submanifold of a Riemannian manifold
(N, Ëœg) then one can also calculate the m-volume of the submanifold M by
equipping M with the metric g = iâˆ—Ëœg, i.e., the metric induced from N.
One should note, however, that the volume form on M is not necessarily
iâˆ—(dVN). In particular, if m < n, then iâˆ—(dVN) would be an n-form on M,
but there are no n-forms on M.
Example 5.1.12 (Volume Form on Sn). We consider the unit n-sphere Sn as a
Riemannian manifold when equipped with the metric induced from Rn+1.
Consider the usual latitude and longitude parametrization of sphere S2:
âƒ—X(u, v) = (cos u sin v sin u sin v, cos v)
for
(u, v) âˆˆ[0, 2Ï€] Ã— [0, Ï€].
Note that if we restrict the domain to (0, 2Ï€) Ã— (0, Ï€), one obtains a dense
open subset of S2.
By Proposition 5.1.7, with respect to this associate
coordinate system, the coeï¬ƒcients of the metric tensor are
gij =

sin2 v
0
0
1
	
.
Since sin v â‰¥0 for v âˆˆ[0, Ï€], the volume form on S2 with respect to this
coordinate system is dV = sin v duâˆ§dv. By Proposition 4.4.13, the volume
of the sphere is easily calculated by
V =
%
S2 dV =
% 2Ï€
0
% Ï€
0
sin v du dv = 2Ï€ [âˆ’cosv]Ï€
0 = 4Ï€.
We now calculate the volume form on Sn using an alternate approach.
By Example C.5.23, we see that the volume form on Rn+1 is
eâˆ—
1 âˆ§Â· Â· Â· âˆ§eâˆ—
n+1,
where {e1, . . . , en+1} is the standard basis on Rn+1.
Furthermore, one
should recall that as an alternating function,
eâˆ—
1 âˆ§Â· Â· Â· âˆ§eâˆ—
n+1(v1, . . . , vn+1) = det(v1, Â· Â· Â· , vn+1)
for any (n + 1)-tuple of vectors (v1, . . . , vn+1).
Deï¬ne a form Ï‰ âˆˆÎ©n(Rn+1), where for each x âˆˆRn+1 and for any
vectors vi
Ï‰x = det(x, v1 , Â· Â· Â· , vn).
By the properties of the determinant, for each x, Ï‰x is an alternating n-
multilinear function on Rn+1, so Ï‰ is indeed an n-form. Using the Laplace

5.1. Riemannian Metrics
193
 x
x
w1
w2
Figure 5.2. Volume form on the sphere.
expansion of the determinant, it is easy to show that
Ï‰ =
n+1

i=1
(âˆ’1)iâˆ’1xi dx1 âˆ§Â· Â· Â· âˆ§&
dxi âˆ§Â· Â· Â· âˆ§dxn+1,
where the ' notation means to exclude the bracketed term. Using the forms
Î·j introduced in Equation (4.10), we can write Ï‰ = "
j xjÎ·j.
Now if x âˆˆSn, then from the geometry of the sphere, x is perpendicular
to TxSn as a subspace of Rn+1 (equipped with the Euclidean metric). Thus,
if {v1, . . . , vn} forms a basis of TxSn, then {x, v1, . . . , vn} forms a basis of
Rn+1. Furthermore, if the n-tuple (v1, . . . , vn) is an orthonormal, positively
oriented basis of TxSn, then the n+1-tuple (x, v1, . . . , vn) is an orthonormal,
positively oriented basis of Rn+1. But then the restriction of Ï‰ to Sn has
the properties described in Proposition 5.1.10. Hence, if i is the inclusion
map for the sphere into Rn+1, we obtain the volume form of Sn as
dVSn = Ï‰|Sn = iâˆ—(Ï‰).
(See Figure 5.2.)
In Section 4.4, we attempted to generalize with the single technique
of integration on manifolds all the types of integration introduced in a
standard calculus sequence. However, as we mentioned at the end of the
section, there were two types of integrals in the list at the beginning of
the section that did not ï¬t in the formalism we had developed for the
integration of n-forms on n-dimensional smooth manifolds, namely

194
5. Introduction to Riemannian Geometry
â€¢ line integrals of functions in Rn,
â€¢ surface integrals of a real-valued function deï¬ned over a closed and
bounded region of a regular surface in R3.
Both of these types of integrals ï¬t into the theory of integration on mani-
folds in the following ways.
For the line integral of functions in Rn over a piecewise-smooth curve
C, let Î³ : [a, b] â†’Rn be a parametrization of C. Let âŸ¨, âŸ©be the Euclidean
form on Rn (i.e., the dot product). Then each smooth piece of Î³ is a one-
dimensional submanifold of Rn, equipped with the metric induced from Rn.
The volume form on Î³ is dVÎ³ so that for any smooth function f deï¬ned on
a neighborhood of C,
%
Î³
f dVÎ³ =
% b
a
f(t)
!4dÎ³
dt , dÎ³
dt
5
Î³(t)
dt =
%
C
f ds.
For surface integrals of a function f on a compact regular surface
S âŠ‚R3, it is not hard to show that dS = dVS, where dVS is the volume
form on S equipped with the metric induced from the Euclidean metric.
Thus, connecting the classical notation with the notation introduced in this
section,
%
S
f dS =
%
S
f dVS.
5.1.3
Raising and Lowering Indices: Trace
Recall that for any vector space V over the reals R, the dual vector space
V âˆ—is the vector space of linear transformations V â†’R (see Section C.3).
An element of V âˆ—is sometimes called a functional on V .
If V is a vector space equipped with any bilinear form âŸ¨, âŸ©, then this
form deï¬nes a linear transformation into the dual V âˆ—by
V âˆ’â†’V âˆ—,
v âˆ’â†’Î»v
= (w â†’âŸ¨v, wâŸ©).
(See Section C.3 for background.) It is not hard to check that if V is ï¬nite-
dimensional and âŸ¨, âŸ©is positive deï¬nite, then the mapping (v â†’Î»v) is an
isomorphism.
We will assume from now on that âŸ¨, âŸ©is symmetric and positive deï¬nite.

5.1. Riemannian Metrics
195
In coordinates, let B = {u1, . . . , un} be a basis of V and let Bâˆ—=
{uâˆ—
1, . . . , uâˆ—
n} be the associated basis (or dual cobasis) for V âˆ—. The coordi-
nates of a vector v âˆˆV are written (vi) to mean that v = viui (Einstein
summation convention). Let A = (aij) be the matrix of âŸ¨, âŸ©with respect
to B, so that
âŸ¨v, wâŸ©= [v]T
BA[w]B = aijviwj.
(5.4)
Note that aij = âŸ¨ui, ujâŸ©. Since âŸ¨, âŸ©is positive deï¬nite, then det A Ì¸= 0 and
A is invertible. It is customary to denote the indices of Aâˆ’1 as
(Aâˆ’1)ij = aij.
The right-most expression in Equation (5.4) gives the coordinates of Î»v
with respect to Bâˆ—as aijvi. Note that the indices for the components of
Î»v arise naturally as subscripts, consistent with our notation. Similarly, if
Î» âˆˆV âˆ—is a functional on V , then Î» = Î»iuâˆ—
i . If Î» = Î»v for some v âˆˆV ,
then
ajkÎ»j = ajkaijvi = aijajkvi = Î´k
i vi = vk.
(5.5)
One often says that the process of mapping v to Î»v â€œlowers the indices,â€
while mapping Î»v to v â€œraises the indices.â€
Now consider a Riemannian manifold (M, g). If X âˆˆX(M) is a vector
ï¬eld on M, then on a given coordinate patch, X has coordinates Xi. By
the process described in the previous paragraphs, one naturally deï¬nes a
covector ï¬eld on M (or 1-form) with component functions as
gijXi.
Mimicking musical notation, one often denotes this covector ï¬eld as Xâ™­
since the result is to lower the indices. Similarly, if Ï‰ âˆˆÎ©1(M) is a 1-form
on M, then on a given coordinate patch, Ï‰ has coordinates Ï‰i. Then one
naturally deï¬nes a vector ï¬eld on M with component functions
gijÏ‰i.
Keeping the musical analogy, one denotes this vector ï¬eld by Ï‰â™¯since the
process raises the indices.
More generally, if T is any tensor ï¬eld of type (p, q) on M, then
giÎ±kT i1Â·Â·Â·ip
j1Â·Â·Â·jq
and
gjÎ²lT i1Â·Â·Â·ip
j1Â·Â·Â·jq
deï¬ne tensors ï¬elds of type (pâˆ’1, q+1) and type (p+1, qâˆ’1), respectively.
It is common to still use the â™­and â™¯notation, but one must indicate in
words upon which index one performs the lowering or raising operations.

196
5. Introduction to Riemannian Geometry
Recall that in linear algebra, the trace of a matrix A is deï¬ned as the
sum of the eigenvalues (counted with multiplicity) or equivalently as the sum
of the diagonal elements. If A has components Ai
j, then the trace is just
Ai
i, using the Einstein summation convention. Now A corresponds to a
linear transformation T (âƒ—v) = Aâƒ—v on a vector space V . Since the trace Tr A
is the sum of the eigenvalues, the trace remains unchanged under a change
in basis in V .
Now, if A is a symmetric (0, 2)-tensor, then Aâ™¯is a (1, 1)-tensor, and
the trace Tr A is deï¬ned in its usual linear algebraic sense. This process is
common enough that we deï¬ne the trace with respect to g of A to be
Trg A
def
= Tr Aâ™¯.
In coordinates, Trg A = gijAij.
5.1.4
Pseudo-Riemannian Metrics
We end this section with a brief comment on another useful metric that
relaxes the requirements of Riemannian metrics.
Deï¬nition 5.1.13. A pseudo-Riemannian metric on a smooth manifold M
is a symmetric tensor ï¬eld g of type (0, 2) that is nondegenerate at every
point. In more detail, at each point p âˆˆM, gp(X, Y ) = 0 for all Y âˆˆTpM
if and only if X = 0 in TpM.
Consider a vector space V equipped with a symmetric bilinear form
âŸ¨, âŸ©. If âŸ¨, âŸ©is positive deï¬nite, then it is nondegenerate. However, the
converse is not true in general. In this sense, pseudo-Riemannian metrics
are a direct generalization of Riemannian metrics. With a nondegenerate
bilinear form, it is not necessarily true that âŸ¨v, vâŸ©> 0 for all nonzero vectors
nor is it true that âŸ¨v, vâŸ©= 0 if and only if v = 0.
The Gram-Schmidt orthonormalization on V , with âŸ¨, âŸ©positive deï¬nite,
allows us to construct a basis {u1, . . . , un} of V in which
âŸ¨, âŸ©= (uâˆ—
1)2 + (uâˆ—
2)2 + Â· Â· Â· + (uâˆ—
n)2
as an element of Sym2 V âˆ—. In contrast, if âŸ¨, âŸ©is only nondegenerate, one
can adapt the Gram-Schmidt process to show that there exists a basis
{u1, . . . , un} of V such that
âŸ¨, âŸ©= âˆ’(uâˆ—
1)2 âˆ’Â· Â· Â· âˆ’(uâˆ—
r)2 + (uâˆ—
r+1)2 + Â· Â· Â· + (uâˆ—
n)2
(5.6)

5.1. Riemannian Metrics
197
for some integer 0 â‰¤r â‰¤n. Furthermore, n âˆ’r is the maximum dimension
of any subspace on which âŸ¨, âŸ©is positive deï¬nite. Hence, by this charac-
terization, r is independent of any choice of basis.
Deï¬nition 5.1.14. Let âŸ¨, âŸ©be a symmetric nondegenerate bilinear form on V .
The integer r in Equation (5.6) is called the index of âŸ¨, âŸ©. One also says
that the space (V, âŸ¨, âŸ©) has signature (n âˆ’r, r).
The most important applications of pseudo-Riemannian metrics occur
in relativity where one uses Lorentz metrics, pseudo-Riemannian metrics
of index 1 (or nâˆ’1). Special relativity is based on the principle (and exper-
imental observation) that the speed of light is the same for all observers,
regardless of their frame of reference. Applying this rule to frames that
move with constant velocity with respect to each other forces a complete
reworking of Newtonian mechanics and leads to many counterintuitive re-
sults. These include relinquishing the absolute nature of time, lengths, and
mass or the idea that the composition of two velocities is their sum (see [40]
for a comprehensive treatment of special relativity).
Now in order to construct laws of physics, one should have at the foun-
dation a notion of distance that is the same for all observers in any inertial
frame. One should recall that the frames of reference for the two observers
can be moving and rotating with respect to each other. In classical me-
chanics, given two points P1 and P2, a distance quantity that does not
change for any two observers is

(Î”x)2 + (Î”y)2 + (Î”x)2.
(5.7)
Problem 2.4.13 shows the invariance of this quantity under the possible
transformations of coordinates between reference frames.
Taking into account the fundamental principle of relativity that the
speed of light is the same for every observer, this quantity is no longer
the same for diï¬€erent observers. In fact, Einstein showed that the speed
diï¬€erence between inertial frames aï¬€ects Equation (5.7). In order to ï¬nd a
distance-like quantity that is preserved between diï¬€erent reference frames,
then one must incorporate time as a dependent variable on par with the
space variables.
To contrast with the mentality of classical mechanics,
in the classical formulation of dynamics, one typically views time t as an
independent parameter and the space variables x, y, and z as functions
of t. In special relativity, one uses four coordinates, i.e.,
(x0, x1, x2, x3) = (ct, x, y, z),
(5.8)

198
5. Introduction to Riemannian Geometry
where c is the speed of light. One calls this mental perspective spacetime.
A point in this spacetime is called an event. The trajectory of a particle in
spacetime is viewed as a one-dimensional submanifold of spacetime, called
the world line of the particle.
Using work by Minkowski, Einstein showed that if one observerâ€™s ref-
erence frame is moving with a constant velocity with respect to the other,
then a distance-like quantity would need to preserve, in addition to, or-
thogonal transformations of the space variables, a Lorentz transformation.
For example, if one frame moves at a constant speed along the x-axis with
reference to another frame, then the Lorentz transformation between coor-
dinates in these diï¬€erent frames is
L =
â›
âœ
âœ
â
Î³
âˆ’Î²Î³
0
0
âˆ’Î²Î³
Î³
0
0
0
0
1
0
0
0
0
1
â
âŸ
âŸ
â ,
where Î³ =
1

1 âˆ’Î²2 and Î² = v
c .
The quantity preserved by Lorentz transformations and orthogonal trans-
formations of the space variables is
âˆ’(Î”s)2 def
= âˆ’(Î”x0)2 + (Î”x1)2 + (Î”x2)2 + (Î”x3)2.
(5.9)
(See Problem 2.4.14 for more on Lorentz transformations.)
Deï¬nition 5.1.15. We deï¬ne (n + 1)-Minkowski spacetime as a real vector
space with coordinates (x0, x1, . . . , xn) that is equipped with the pseudo-
Riemannian metric
g = âˆ’(dx0)2 + (dx1)2 + Â· Â· Â· + (dxn)2.
(5.10)
In other words,
g00 = âˆ’1,
gii = 1 if i > 0,
gij = 0 if i Ì¸= j.
When there is no confusion, Minkowski spacetime is often denoted by R1,n.
The particular metric in Equation (5.10) is often denoted by the letter Î·.
There is some inconsistency in the literature for notation of Minkowski
space. Some authors (typically physicists) prefer our notation, while others
(primarily mathematicians) deï¬ne Î”s2 as the negative of what we chose in
Equation (5.9). We have chosen to use the form Î· as described in Equa-
tion (5.10), but we use the variable s to satisfy âˆ’ds2 = Î·. The beneï¬t of
this choice of s comes from relativity, as shown in the next paragraph.

5.1. Riemannian Metrics
199
The locus of a particle moving in a Minkowski space is described by
a function X(Î») = (x0(Î»), x1(Î»), x2(Î»), x3(Î»)), where Î» is any parameter,
not necessarily time t. The one thing we can say about the function t(Î») is
that if the particle travels slower than c, then t(Î») is a strictly increasing
function. The image of X in R1,3 is the world line of the particle. Then
the speed (with respect to Î», using the Minkowski metric) is
âˆ’
 ds
dÎ»
	2
= âˆ’c2
 dt
dÎ»
	2
+
dx
dÎ»
	2
+
 dy
dÎ»
	2
+
 dz
dÎ»
	2
.
Since dt/dÎ» > 0, we can rewrite this in terms of t.
We ï¬nd that if a
particle has a vector function âƒ—v(t) in the Euclidean part, then ds and dt
are related by
ds = c

1 âˆ’v2
c2 dt.
(5.11)
The quantity ds/c is called the proper time interval and the function
Ï„ = 1
c
% Î»
0
ds
(5.12)
is called the proper time of the particle traveling on its world line. Proper
time plays a central role in the theory of relativity since it is a timelike
quantity that is the same for all inertial observers, i.e., unchanged by any
Lorentz transformation.
In the observed Minkowski space of R1,3, two events for which Î”s2 > 0
are called timelike separated. Clearly, for two timelike separated events,
time must have elapsed. Also, since a particle cannot travel faster than
the speed of light, any two events on the world line of a particle must
be timelike separated.
From another perspective, two events are called
timelike separated if a particle can travel between them (without moving
faster than the speed of light). Two events for which Î”s2 = 0 are called
lightlike separated if only a particle traveling in a straight line at the speed
of light can connect the two events. Finally, two events for which Î”s2 < 0
are called spacelike separated because no particle can have a world line that
connects the two events. [57, Section 2.2] The light cone based at an event
P is the set of all events that are lightlike separated from P. Figure 5.3
shows the light cone for the origin, though we can only display the variables
(x0, x1, x2).
As we will see in Section 6.4, in the general theory of relativity, gravity
aï¬€ects the metric and leads to a metric that varies from point to point but
is still Lorentz.

200
5. Introduction to Riemannian Geometry
lightlike
timelike
spacelike
Figure 5.3. Light cone.
Problems
5.1.1. Consider the 3-torus T3 = S1 Ã— S1 Ã— S1. Calculate the induced metrics for
the following two embeddings:
(a) Into R6 as the image of the parametrization
âƒ—F(u1, u2, u3) =

cos u1, sin u1, cos u2, sin u2, cos u3, sin u3
.
(b) Into R4 as the image of the parametrization âƒ—F(u1, u2, u3) given by
((c + (b + a cos u1) cos u2) cos u3, (c + (b + a cos u1) cos u2) sin u3,
(b + a cos u1) sin u2, a sin u1), where b > a > 0 and c > a + b.
(c) Prove that these two Riemannian manifolds are not isometric.
[Hint: This gives two diï¬€erent metrics on the 3-torus that can be equipped
with the same atlas in each case.]
5.1.2. We consider an embedding of S1Ã—S2 in R4 by analogy with the embedding
of the torus S1 Ã— S1 in R3. Place the sphere S2 with radius a at (0, 0, b, 0)
(where b > a) as a subset of the x1x2x3-subspace, and rotate this sphere
about the origin with a motion parallel to the x3x4-axis.
Call this submanifold M and equip it with the metric induced from R4.
(a) Show that the described manifold M is an embedding as claimed.
(b) Find a parametrization F : D â†’R4 where D âŠ‚R3 such that, as
sets of points F(D) = M, and F(Dâ—¦) is an open subset of M that is
homeomorphic to Dâ—¦. (Dâ—¦is the interior of the set D.)
(c) Calculate the coeï¬ƒcients gij of the metric on M in the coordinate
patch deï¬ned by the above parametrization.

5.1. Riemannian Metrics
201
5.1.3. Let (M1, g1) and (M2, g2) be two Riemannian manifolds, and consider the
product manifold M1 Ã— M2 with a (0, 2)-tensor ï¬eld deï¬ned by
g(X1 + X2, Y1 + Y2) = g1(X1, Y1) + g2(X2, Y2).
(a) Show that g deï¬nes a metric on M1 Ã— M2.
(b) Let (x1, . . . , xn) be local coordinates on M1 and (xn+1, . . . , xn+m) be
local coordinates on M2 so that (x1, . . . , xm+n) are local coordinates
on M1 Ã—M2. Determine the components of the metric g on M1 Ã—M2
in terms of g1 and g2.
5.1.4. Repeat Problem 5.1.2 with S1 Ã— S, where S is a regular surface in R3 that
does not intersect the plane z = x3 = 0.
5.1.5. Consider the following two regular surfaces in R3 parametrized by
â€¢ catenoid: F(Â¯u1, Â¯u2) = (Â¯u2 cos Â¯u1, Â¯u2 sin Â¯u1, coshâˆ’1 Â¯u2) for (u1, u2) âˆˆ
[0, 2Ï€) Ã— R,
â€¢ helicoid: F(u1, u2)=(u2 cos u1, u2 sin u1, u1) for (u1, u2)âˆˆ[0, 2Ï€)Ã—R.
Prove that the helicoid and catenoid are isometric, and ï¬nd an isometry
between them.
5.1.6. Let M be a hypersurface of Rn (submanifold of dimension nâˆ’1), and equip
M with Riemannian structure with the metric induced from Rn. Suppose
that an open set U of M is a graph of an (n âˆ’1)-variable function f, i.e.,
the parametrization of U is
x1 = u1, . . . , xnâˆ’1 = unâˆ’1, xn = f(u1, . . . , unâˆ’1),
(u1, . . . , unâˆ’1) âˆˆD.
(a) Find the coeï¬ƒcients of the metric tensor g on M, and conclude that
a formula for the (n âˆ’1)-volume of U is
%
D

1 + âˆ¥grad fâˆ¥2 dV.
(b) Use this result to calculate the 3-volume of the surface in R4 given
by w = x2 + y2 + z2 for x2 + y2 + z2 â‰¤4.
5.1.7. Let M, N, and S be Riemannian manifolds, and let f : M â†’N and
h : N â†’S be isometries.
(a) Show that f âˆ’1 is an isometry.
(b) Show that h â—¦f is an isometry.
(c) If you have seen some group theory, show that the set of isometries
on a Riemannian manifold M forms a group.
5.1.8. Let Î³ be a curve on a Riemannian manifold (M, g). Show precisely how
the induced metric on Î³ generalizes Deï¬nition 5.1.9.

202
5. Introduction to Riemannian Geometry
5.1.9. PoincarÂ´e ball. The PoincarÂ´e ball is the open ball Bn
R in n dimensions of
radius R equipped with the metric
4R4
(R2 âˆ’âˆ¥xâˆ¥2)2

(dx1)2 + Â· Â· Â· + (dxn)2
.
(a) Set n = 2 and R = 1.
(This choice of parameters is called the
unit PoincarÂ´e disk.) Calculate the area of the region R deï¬ned by
âˆ¥xâˆ¥< 1
2 and 0 â‰¤Î¸ â‰¤Ï€/2.
(b) Set n = 3 and R = 2.
Calculate the length of the curve Î³(t) =
(cos t, sin t, t) in the PoincarÂ´e ball.
5.1.10. Divergence Theorem.
Let (M, g) be an oriented, compact, Riemannian
manifold with boundary.
Given any vector ï¬eld X âˆˆX(M) and any
tensor ï¬eld T of type (p, q), with q â‰¥1, we deï¬ne the contraction of X
with T, denoted iXT, as the tensor ï¬eld of type (p, q âˆ’1) that over any
coordinate chart has components
XlT
i1Â·Â·Â·ip
lj2Â·Â·Â·jq.
We deï¬ne the divergence operator div : X(M) â†’Câˆ(M) implicitly by
d(iX dV ) = (div X) dV.
(a) Show that for a k-form Ï‰, the contraction iXÏ‰ is the (k âˆ’1)-form
such that, for any vectors v1, . . . , vkâˆ’1 âˆˆTpM,
iXÏ‰(v1, . . . , vkâˆ’1) = Ï‰(X, v1, . . . , vkâˆ’1).
(b) Prove the Divergence Theorem, which states that for any X âˆˆX(M)
%
M
div X dV =
%
âˆ‚M
g(X, N) d ËœV ,
where N is the outward unit normal to âˆ‚M and d ËœV is the volume
form associated to the metric on âˆ‚M induced from M.
5.1.11. We consider the sphere S3 of radius R as a submanifold in R4 with the
induced Euclidean metric.
(a) Show that
F(u1, u2, u3) =
(R cos u1 sin u2 sin u3, R sin u1 sin u2 sin u3, R cos u2 sin u3, R cos u3),
where (u1, u2, u3) âˆˆ[0, 2Ï€] Ã— [0, Ï€]2 gives a parametrization for S3
that is homeomorphic to its image when restricted to the open set
V = (0, 2Ï€) Ã— (0, Ï€)2.
(b) Calculate the components of the metric tensor on the coordinate
patch F(V ) = U.

5.1. Riemannian Metrics
203
(c) Use part (b) to calculate the volume of a 3-sphere of radius R.
(d) Leaving R unspeciï¬ed, consider the function f(x1, x2, x3, x4) =
(x1)2 + (x2)2 + (x3)2 and calculate the volume integral
3
S3 f dV .
(Note that this integral would give the radius of gyration of the
spherical shell of radius R about a principal axisâ€”if such a thing
existed in R4!)
5.1.12. Calculate the 5-volume of the 5-sphere S5 of radius R as a submanifold
of R6.
5.1.13. (ODE) A loxodrome on the unit sphere S2 is a curve that makes a con-
stant angle with all meridian lines.
We propose to study analogues of
loxodromes on S3. Consider the unit 3-sphere S3 with the parametriza-
tion from Problem 5.1.11. Set R = 1. We will call a loxodrome on S3 any
curve Î³ such that Î³â€² makes a constant angle of Î±2 with
âˆ‚
âˆ‚u2 and a constant
angle of Î±3 with
âˆ‚
âˆ‚u3 .
(a) Find equations that the components of Î³ must satisfy.
(b) Solve the diï¬€erential equations we get in part (a). [Hint: Obtain u1
and u2 as functions of u3. You might only be able to obtain one of
these functions implicitly.]
5.1.14. Consider the function r : Rn+1 âˆ’{0} â†’Sn given by r(x) = x/âˆ¥xâˆ¥.
(a) Using Example 5.1.12, prove that
ËœÏ‰ = râˆ—(dVSn) =
1
âˆ¥xâˆ¥n+1
n+1

j=1
xjÎ·j.
(b) Show that ËœÏ‰ is closed but not exact in Rn+1 âˆ’{0}.
(c) Use dVSn to show that
Vol(Sn) = (n + 1)Vol(Bn+1),
where Bn+1 is the unit ball in Rn+1.
5.1.15. Let M be a Riemannian manifold, and let f : M â†’M be an isometry on
M. Prove that f âˆ—(dVM) = Â±dVM. (The isometry f is called orientation-
preserving if f âˆ—(dVM) = dVM and orientation-reversing if f âˆ—(dVM) =
âˆ’dVM.)
5.1.16. Suppose that J and K are disjoint, compact, oriented, connected, smooth
submanifolds of Rn+1 whose dimensions are greater than 0 and such that
dim J + dim K = n. Deï¬ne the function Î¨ by
Î¨ : J Ã— K âˆ’â†’Sn
(x, y) âˆ’â†’
y âˆ’x
âˆ¥y âˆ’xâˆ¥.

204
5. Introduction to Riemannian Geometry
The linking number between J and K is deï¬ned as
link(J, K) =
1
Vol(Sn)
%
JÃ—K
Î¨âˆ—(dVSn).
Prove Gaussâ€™s Linking Formula for the linking number of two space curves:
link(C1, C2) = 1
4Ï€
%
I
%
J
det(âƒ—Î±(u) âˆ’âƒ—Î²(v), âƒ—Î±â€²(u), âƒ—Î²â€²(v))
âˆ¥âƒ—Î±(u) âˆ’âƒ—Î²(v)âˆ¥3
du dv.
5.1.17. Let g be a pseudo-Riemannian metric on a smooth manifold M. Prove
that the index of g is constant on each connected component of M.
5.1.18. Hodge Star Operator.
Let (M, g) be an oriented Riemannian manifold.
Section C.6.3 deï¬nes the Hodge star operator on inner product spaces.
Given a form Î· âˆˆÎ©k(M), at each p âˆˆM, the Hodge star operator deï¬nes
an isomorphism â‹†: 1k TpM âˆ—â†’1nâˆ’k TpM âˆ—.
(a) Show that the Hodge star operator â‹†is a map between vector bundles
Î©k(M) â†’Î©nâˆ’k(M) that leaves every base point ï¬xed and that varies
smoothly on M.
(b) Show that for all functions f : Câˆ(M), the Hodge star operator is
given by â‹†f = fdVg.
5.1.19. Consider Rn as a manifold with the standard Euclidean metric.
(a) Calculate â‹†dxi for any i = 1, . . . , n.
(b) Set n = 4, and calculate â‹†(dxi âˆ§dxj).
(c) Set n = 4, and now assume that the metric is the Minkowski metric.
In other words, consider R1,3, with g deï¬ned by Equation (5.10).
Repeat part (b) in this situation.
5.1.20. Let (M, g) be an oriented Riemannian manifold. Prove the following iden-
tities for any vector ï¬eld X âˆˆX(M).
(a) div X = â‹†d â‹†Xâ™­, where div is the divergence operator deï¬ned in
Problem 5.1.10.
(b) iXdVg = â‹†Xâ™­.
5.2
Connections and Covariant Differentiation
Despite all the â€œheavy machineryâ€ we have developed in order to create
a theory of analysis on manifolds, we are still unable to calculate or even
deï¬ne certain things that are simple in Rn.
For example, if Î³ : [a, b] â†’M is a smooth curve on a smooth manifold,
we have no way at present to talk about the acceleration of Î³. Let p âˆˆM,

5.2. Connections and Covariant Differentiation
205
with Î³(t0) = p. In Deï¬nition 3.3.1, we presented the tangent vector Î³â€²(t0)
at p as the operator DÎ³ : C1(M) â†’R that evaluates
DÎ³(f) = d
dtf(Î³(t))

0.
In Section 3.3, we developed the linear algebra of expressions DÎ³ for curves
Î³ through p. The vector space of such operators is what we called the
tangent space TpM.
Mimicking what one does in standard calculus, one could try to deï¬ne
the acceleration vector Î³â€²â€²(t0) at p as a limiting ratio as t â†’t0 of Î³â€²(t) âˆ’
Î³â€²(t0) with t âˆ’t0. However, what we just wrote does not make sense in
the context of manifolds because Î³â€²(t) and Î³â€²(t0) are not even in the same
vector spaces and so their diï¬€erence is not deï¬ned.
A â€œsmarterâ€ attempt to deï¬ne the acceleration might follow Deï¬nition
3.3.1 and try to deï¬ne Î³â€²â€²(t0) at p as the operator D(2)
Î³
: C2(M) â†’R,
where
D(2)
Î³ (f) = d2
dt2 f(Î³(t))

t0.
This operator is well deï¬ned and linear. However, D(2)
Î³
does not satisfy
Leibnizâ€™s rule, and therefore, there does not exist another curve ËœÎ³, with
ËœÎ³(t0) = p such that D(2)
Î³
= DËœÎ³. Hence, D(2)
Î³
/âˆˆTpM. One could develop
properties for the operators of the form D(2)
Î³
but, since the operators do
not exist in any T M âŠ—p âŠ—T M âˆ—âŠ—q, this is not the direction the theory of
manifolds has developed.
Another lack in our current theory is the ability to take partial deriva-
tives or, more generally, directional derivatives of a vector ï¬eld. Over Rn,
it is easy to deï¬ne âˆ‚âƒ—F/âˆ‚xj, where âƒ—F is a vector ï¬eld, and, under suitable
diï¬€erentiability conditions, âˆ‚âƒ—F/âˆ‚xj is again another vector ï¬eld. In con-
trast, if X is a vector ï¬eld over a smooth manifold M and U is a coordinate
neighborhood of p âˆˆM, one encounters the same problem with deï¬ning a
vector âˆ‚iXp as one does in deï¬ning the acceleration of a curve.
A more subtle attempt to deï¬ne partial derivatives of a vector ï¬eld X
on M in a coordinate chart would be to imitate the exterior diï¬€erential of
forms (see Deï¬nition 4.3.4) and set as a diï¬€erential for X the quantity
âˆ‚Xi
âˆ‚xj dxj
	
âŠ—âˆ‚i = âˆ‚Xi
âˆ‚xj âˆ‚i âŠ—dxj.
However, this does not deï¬ne a tensor ï¬eld of type (1, 1) on M. In other
words, the quantities âˆ‚Xi
âˆ‚xj do not form the components of a (1, 1)-tensor

206
5. Introduction to Riemannian Geometry
on M. It is easiest to see this by showing how the components violate
the transformational properties of a tensor ï¬eld. Let Â¯x = (Â¯x1, . . . , Â¯xn) be
another system of coordinates that overlaps with the coordinate patch for
x = (x1, . . . , xn). Call Â¯X the components of the vector ï¬eld X in the Â¯x
system. We know that
Â¯Xj(Â¯x) = âˆ‚Â¯xj
âˆ‚xi Xi(x).
Taking a derivative with respect to Â¯xk and inserting appropriate chain rules,
we have
âˆ‚Â¯Xj
âˆ‚Â¯xk =
âˆ‚
âˆ‚Â¯xk
âˆ‚Â¯xj
âˆ‚xi
	
Xi + âˆ‚Â¯xj
âˆ‚xi
âˆ‚Xi
âˆ‚Â¯xk
=
âˆ‚2Â¯xj
âˆ‚xlâˆ‚xi
âˆ‚xl
âˆ‚Â¯xk Xi + âˆ‚Â¯xj
âˆ‚xi
âˆ‚xl
âˆ‚Â¯xk
âˆ‚Xi
âˆ‚xl .
(5.13)
The presence of the ï¬rst term on the right-hand side shows that the col-
lection of functions âˆ‚jXi do not satisfy Equation (4.7).
To solve the above conceptual problems, we need some coordinate-
invariant way to compare vectors in tangent spaces at nearby points. This
is the role of a connection. A connection on a smooth manifold is an addi-
tional structure that, though we introduced it in the context of Riemannian
manifolds, is entirely independent of any Riemannian structure. We can in
fact deï¬ne a connection on any vector bundle over M. Since we require this
generality for our applications, we introduce connections in this manner.
Deï¬nition 5.2.1. Let M be a smooth manifold, and let Î¾ be a vector bundle
over M. Let E(Î¾) denote the subspace of Î“(Î¾) of smooth global sections
of Î¾. A connection on Î¾ is a map
âˆ‡: X(M) Ã— E(Î¾) â†’E(Î¾),
written âˆ‡XY instead of âˆ‡(X, Y ), that satisï¬es the following:
1. For all vector ï¬elds Y âˆˆE(Î¾), âˆ‡( , Y ) is linear over Câˆ(M), i.e., for
all f, g âˆˆCâˆ(M),
âˆ‡fX1+g Ëœ
XY = fâˆ‡XY + gâˆ‡Ëœ
XY.
2. For all vector ï¬elds X âˆˆX(M), âˆ‡(X, ) is linear over R, i.e., for all
a, b âˆˆR,
âˆ‡X(aY + b ËœY ) = aâˆ‡XY + bâˆ‡X ËœY .

5.2. Connections and Covariant Differentiation
207
3. For all vector ï¬elds X âˆˆX(M), âˆ‡(X, ) satisï¬es the product rule
âˆ‡X(fY ) = (Xf)Y + fâˆ‡XY
for all f âˆˆCâˆ(M).
The vector ï¬eld âˆ‡XY in E(Î¾) is called the covariant derivative of Y in the
direction of X.
The symbol âˆ‡is pronounced â€œdel.â€
The deï¬ning properties of the
covariant derivative are modeled after the properties of directional deriva-
tives of vector ï¬elds on Rn (see Problem 5.2.1). Intuitively, the connection
explicitly deï¬nes how to take a partial derivative in E(Î¾) with respect to
vector ï¬elds in T M. In fact, Problems 5.2.3 and 5.2.4 show that âˆ‡XY
depends only on the values of Xp in TpM and the values of Y in a neigh-
borhood of p on M. Therefore âˆ‡XY |p is truly a directional derivative of Y
at p in the direction Xp. Hence, we often write âˆ‡XpY instead of âˆ‡XY |p.
For the applications of interest in diï¬€erential geometry, we will usu-
ally be interested in using connections on vector bundles of the form Î¾ =
T M âŠ—r âŠ—T M âˆ—âŠ—s. As it will turn out, connections on these vector bundles
are closely related to possible connections on T M. Therefore, we temporar-
ily restrict our attention to connections
âˆ‡: X(M) Ã— X(M) â†’X(M).
Over a coordinate patch U of M, the deï¬ning properties are such that âˆ‡is
completely determined once one knows its values for X = âˆ‚i and Y = âˆ‚j.
Since âˆ‡âˆ‚iâˆ‚j is another vector ï¬eld in M, we write
âˆ‡âˆ‚iâˆ‚j = Î“k
ijâˆ‚k.
(5.14)
The components Î“k
ij are smooth functions M â†’R.
Deï¬nition 5.2.2. The functions Î“k
ij in Equation (5.14) are called the Christof-
fel symbols of the connection âˆ‡.
As it turns out, there are no restrictions besides smoothness on the
functions Î“k
ij.
Proposition 5.2.3. Let M n be a smooth manifold, and let U be a coordinate
patch on M. There is a bijective correspondence between connections on
X(U) and collections of n3 smooth functions Î“i
jk deï¬ned on U. The bijec-
tion is given by the formula
âˆ‡XY = (Xjâˆ‚jY i + Î“i
jkXjY k)âˆ‚i.
(5.15)

208
5. Introduction to Riemannian Geometry
Proof: First, suppose that âˆ‡is a connection on X(U) and let X, Y âˆˆX(U).
Then by the relations in Deï¬nition 5.2.1,
âˆ‡XY = âˆ‡(Xjâˆ‚j)(Y kâˆ‚k) = Xjâˆ‡âˆ‚j(Y kâˆ‚k)
= Xj(âˆ‚jY k)âˆ‚k + XjY kâˆ‡âˆ‚jâˆ‚k = Xj(âˆ‚jY k)âˆ‚k + XjY kÎ“i
jkâˆ‚i.
and Equation (5.15) holds by changing the variable of summation from k
to i in the ï¬rst term of the last expression. Conversely, if Î“i
jk are any
smooth functions on U and if we deï¬ne an operator X(U) Ã— X(U) â†’X(U)
by Equation (5.15), it is quick to check that the three criteria of Deï¬nition
5.2.1 hold. Thus, Equation (5.15) deï¬nes a connection on X(U).
â–¡
Consequently, over any coordinate patch U âŠ‚M, there are many pos-
sible connections on T U. In addition to Proposition 5.2.3, one can use a
partition of unity subordinate to a cover of M by coordinate patches to
deï¬ne a connection on all of M. In this case, one cannot deï¬ne a cor-
respondence between connections and collections of functions in the same
vein as in Proposition 5.2.3.
Example 5.2.4 (The Flat Connection on Rn). In Rn, the vector ï¬elds âˆ‚i are con-
stant, and we identify them with the standard basis vector âƒ—ei. According
to Proposition 5.2.3, a connection exists for any collection of n3 functions.
However, if Y = Y jâˆ‚j is a vector ï¬eld in Rn, our usual way of taking partial
derivatives of vector ï¬elds is
âˆ‡âˆ‚iY = âˆ‚Y j
âˆ‚xi âˆ‚j,
which takes partial derivatives componentwise on Y . By Proposition 5.15,
we see that Î“i
jk = 0 for all choices of the indices. A connection with this
property is called a ï¬‚at connection over the coordinate patch.
Even though the symbols Î“i
jk resemble our notation for the components
of a (1, 2)-tensor, a connection is not a tensor ï¬eld. The reason derives
from the fact that âˆ‚jXi is not a (1, 1)-tensor ï¬eld. In fact, from (5.13)
and the transformational properties of a vector ï¬eld between overlapping
coordinate systems on M, we can deduce the transformational properties
of the component functions of a connection.
Proposition 5.2.5. Let âˆ‡be a connection on X(M). Suppose that U and Â¯U
are overlapping coordinate patches, and denote by Î“i
jk and Â¯Î“l
mn the com-
ponent functions of âˆ‡over these patches, respectively. Then over U âˆ©Â¯U,
the component functions are related to each other by
Â¯Î“l
mn = âˆ‚xj
âˆ‚Â¯xm
âˆ‚xk
âˆ‚Â¯xn
âˆ‚Â¯xl
âˆ‚xi Î“i
jk âˆ’âˆ‚xj
âˆ‚Â¯xm
âˆ‚xk
âˆ‚Â¯xn
âˆ‚2Â¯xl
âˆ‚xjâˆ‚xk .

5.2. Connections and Covariant Differentiation
209
Proof: (Left as an exercise for the reader.)
â–¡
The astute reader might have noticed already from Deï¬nition 5.2.1 that
a connection is not a tensor ï¬eld of type (1, 2). If an operator F : X(M) Ã—
X(M) â†’X(M) were a tensor ï¬eld in T M âŠ—T M âˆ—âŠ—2, then F(X, ) would
be linear in Câˆ(M) and would not satisfy the third property in Deï¬nition
5.2.1.
Example 5.2.6 (Polar Coordinates). We consider the connection âˆ‡on R2 that
is ï¬‚at over the Cartesian coordinate system. We calculate the components
of âˆ‡with respect to polar coordinates. We could calculate the Christoï¬€el
symbols from Proposition 5.2.3, but instead, we use Proposition 5.2.5. Set
x1 = x, x2 = y, Â¯x1 = r, and Â¯x2 = Î¸, and denote by Î“i
jk = 0 and by Â¯Î“l
mn
the Christoï¬€el symbols for âˆ‡in polar coordinates.
By direct calculation,
Â¯Î“2
12 = âˆ’
2

j,k=1
âˆ‚xj
âˆ‚Â¯x1
âˆ‚xk
âˆ‚Â¯x2
âˆ‚2Â¯x2
âˆ‚xjâˆ‚xk
= âˆ’

âˆ’r cos Î¸ sin Î¸ âˆ‚2Î¸
âˆ‚x2 + r2 cos2 Î¸ âˆ‚2Î¸
âˆ‚xâˆ‚y âˆ’r sin2 Î¸ âˆ‚2Î¸
âˆ‚yâˆ‚x
+ r sin Î¸ cos Î¸ âˆ‚2Î¸
âˆ‚y2
	
= âˆ’

âˆ’r sin Î¸ cos Î¸
2xy
(x2 + y2)2 + r(cos2 Î¸ âˆ’sin2 Î¸) y2 âˆ’x2
(x2 + y2)2
âˆ’r sin Î¸ cos Î¸
2xy
(x2 + y2)2
	
= 1
r

2 sin2 Î¸ cos2 Î¸ + (cos2 Î¸ âˆ’sin2 Î¸)2 + 2 sin2 Î¸ cos2 Î¸

= 1
r .
It is not hard (though perhaps a little tedious) to show that
Â¯Î“1
11 = 0,
Â¯Î“1
12 = Â¯Î“1
21 = 0,
Â¯Î“1
22 = âˆ’r,
Â¯Î“2
11 = 0,
Â¯Î“2
12 = Â¯Î“2
21 = 1
r ,
Â¯Î“2
22 = 0.
We now wish to extend our discussion of connections on T M to con-
nections on any tensor bundle T M âŠ—r âŠ—T M âˆ—âŠ—s in a natural manner for
any pair (r, s). Two situations are settled: (1) if f âˆˆT M 0 = Câˆ(M),
then we want âˆ‡Xf = X(f), the expected directional derivative; and (2)
if X âˆˆT M, then the connection should follow the properties described in
Deï¬nition 5.2.1 and Proposition 5.2.3.

210
5. Introduction to Riemannian Geometry
Lemma 5.2.7. Let M be a smooth manifold, and let âˆ‡be a connection on T M.
For each pair (r, s) âˆˆN2, there exists a unique connection on the tensor
bundle T M âŠ—r âŠ—T M âˆ—âŠ—s, also denoted âˆ‡, given by the following condi-
tions:
1. Consistency: âˆ‡is equal to the connection given on T M.
2. Directional derivative: âˆ‡Xf = X(f) for all f âˆˆCâˆ(M) = T M 0.
3. Contraction product rule: if we deï¬ne the pairing âŸ¨Ï‰, Y âŸ©= Ï‰(Y ) for
all covector ï¬elds Ï‰ and vector ï¬elds X, then
âˆ‡X (âŸ¨Ï‰, Y âŸ©) = âŸ¨âˆ‡XÏ‰, Y âŸ©+ âŸ¨Ï‰, âˆ‡XY âŸ©.
4. Tensor product rule: for all tensor ï¬elds A and B of any type,
âˆ‡X(A âŠ—B) = (âˆ‡XA) âŠ—B + A âŠ—(âˆ‡XB).
We omit the proof of this lemma since it is merely constructive. Prop-
erty 3 determines uniquely how to deï¬ne âˆ‡XÏ‰ for any covector ï¬eld and
then Property 4 extends the connection to all other types of tensors.
Deï¬nition 5.2.8. Let M be a smooth manifold. We call âˆ‡an aï¬ƒne connec-
tion on T M âŠ—r âŠ—T M âˆ—âŠ—s if it satisï¬es the conditions of Lemma 5.2.7.
Let âˆ‡be an aï¬ƒne connection on a smooth manifold M. Let F be a
tensor ï¬eld of type (r, s). Then the mapping âˆ‡F that maps a vector ï¬eld
X to âˆ‡XF is a Câˆ(M)-linear transformation from X(M) to the space
of tensor ï¬elds of type (r, s).
Thus, for each p âˆˆM, âˆ‡F|p is a linear
transformation TpM â†’TpM âŠ—r âŠ—TpM âˆ—âŠ—s, so by Proposition C.4.7,
âˆ‡F|p âˆˆHom(TpM, TpM âŠ—r âŠ—TpM âˆ—âŠ—s) = TpM âŠ—r âŠ—TpM âˆ—âŠ—(s+1).
Furthermore, since âˆ‡F|p varies smoothly with p, then âˆ‡F is a smooth
section of the tensor bundle TpM âŠ—r âŠ—TpM âˆ—âŠ—s+1, and hence, it is a tensor
ï¬eld of type (r, s + 1).
Deï¬nition 5.2.9. Let M be a smooth manifold equipped with an aï¬ƒne con-
nection âˆ‡. If F is a tensor ï¬eld of type (r, s), then the tensor ï¬eld âˆ‡F of
type (r, s + 1) is called the covariant derivative of F.

5.2. Connections and Covariant Differentiation
211
Proposition 5.2.10. Let F be a tensor ï¬eld of type (r, s) over a manifold M.
Suppose that F has components F i1Â·Â·Â·ir
j1Â·Â·Â·js over a coordinate chart U. Then
the components of the covariant derivative âˆ‡F are
F i1Â·Â·Â·ir
j1Â·Â·Â·js;k
def
=
âˆ‚F i1Â·Â·Â·ir
j1Â·Â·Â·js
âˆ‚xk
+
r

Î±=1
Î“iÎ±
kpF i1Â·Â·Â·iÎ±âˆ’1piÎ±+1Â·Â·Â·ir
j1Â·Â·Â·js
âˆ’
s

Î²=1
Î“p
kjÎ²F i1Â·Â·Â·ir
j1Â·Â·Â·jÎ²âˆ’1pjÎ²+1Â·Â·Â·js.
(5.16)
(Some authors use the notation F i1Â·Â·Â·ir
j1Â·Â·Â·js|k for the components of the
covariant derivative.) The notation in Equation (5.16) is a little heavy, but
it should become clear with a few examples. If Ï‰ is a 1-form, then âˆ‡Ï‰ is a
2-form with local components given by
âˆ‡Ï‰ = Ï‰j;kdxj âŠ—dxk,
where
Ï‰j;k = âˆ‚kÏ‰j âˆ’Î“p
kjÏ‰p.
Similarly, if Aij
k are the components of a (2, 1)-tensor ï¬eld A, then âˆ‡A is
a (2, 2)-tensor ï¬eld with local components given by
âˆ‡A = Aij
k;lâˆ‚iâŠ—âˆ‚jâŠ—dxkâŠ—dxl, where Aij
k;l = âˆ‚Aij
k
âˆ‚xl +Î“i
lpApj
k +Î“j
lpAip
k âˆ’Î“p
lkAij
p .
Proposition 5.2.3 gives one considerable freedom in choosing the compo-
nents of a connection. Returning to the context of Riemannian geometry,
one may wish to use a connection that is in some sense â€œniceâ€ with re-
spect to the metric on the manifold. The following theorem is motivated
by results in classical diï¬€erential geometry of surfaces discussed in [5, Sec-
tion 7.2] but is so central to Riemannian geometry that it is sometimes
called the â€œmiracleâ€ of Riemannian geometry [43].
Theorem 5.2.11 (Levi-Civita Theorem). Let (M, g) be a Riemannian manifold.
There exists a unique aï¬ƒne connection âˆ‡that satisï¬es the following two
conditions:
1. Compatibility: âˆ‡g is identically 0.
2. Symmetry: for all X, Y âˆˆX(M), [X, Y ] = âˆ‡XY âˆ’âˆ‡Y X.
A few comments are in order before we prove this theorem. The condi-
tion that âˆ‡g = 0 intuitively says that âˆ‡is ï¬‚at with respect to the metric.
We say that âˆ‡is compatible with the metric. We leave it as an exercise

212
5. Introduction to Riemannian Geometry
for the reader (Problem 5.2.12) to show that if we write g = âŸ¨, âŸ©, then âˆ‡g
is identically 0 (i.e., gij;k = 0 in local coordinates) if and only if
âˆ‡X(âŸ¨Y, ZâŸ©) = âŸ¨âˆ‡XY, ZâŸ©+ âŸ¨Y, âˆ‡XZâŸ©.
(5.17)
Hence, if âˆ‡is compatible with the metric g, then it satisï¬es a product rule
with respect to the metric.
By Problem 5.2.14, condition 2 implies that over any coordinate patch
of the manifold, the Christoï¬€el symbols Î“i
jk of the connection âˆ‡satisfy
Î“i
jk = Î“i
kj, which justiï¬es the terminology of a symmetric connection.
Deï¬nition 5.2.12. The connection âˆ‡described in Theorem 5.2.11 is called
the Levi-Civita connection or the Riemannian connection with respect to
the metric g on M.
Proof (of Theorem 5.2.11): Let X, Y, Z âˆˆX(M), and denote g = âŸ¨, âŸ©.
Since âŸ¨X, Y âŸ©is a smooth function on M, then we write âˆ‡Z(âŸ¨X, Y âŸ©) =
ZâŸ¨X, Y âŸ©.
Now suppose that such a connection âˆ‡exists. Then
XâŸ¨Y, ZâŸ©= âŸ¨âˆ‡XY, ZâŸ©+ âŸ¨Y, âˆ‡XZâŸ©,
(5.18)
Y âŸ¨Z, XâŸ©= âŸ¨âˆ‡Y Z, XâŸ©+ âŸ¨Z, âˆ‡Y XâŸ©,
(5.19)
ZâŸ¨X, Y âŸ©= âŸ¨âˆ‡ZX, Y âŸ©+ âŸ¨X, âˆ‡ZY âŸ©.
(5.20)
Adding Equations (5.18) and (5.19) and subtracting Equation (5.20), using
the symmetry of the metric, we get
XâŸ¨Y, ZâŸ©+ Y âŸ¨Z, XâŸ©âˆ’ZâŸ¨X, Y âŸ©= âŸ¨âˆ‡XY âˆ’âˆ‡Y X, ZâŸ©+ âŸ¨âˆ‡XZ âˆ’âˆ‡ZX, Y âŸ©
+ âŸ¨âˆ‡Y Z âˆ’âˆ‡ZY, XâŸ©+ 2âŸ¨Z, âˆ‡Y XâŸ©.
Using the fact that âˆ‡is symmetric, we have
XâŸ¨Y, ZâŸ©+ Y âŸ¨Z, XâŸ©âˆ’ZâŸ¨X, Y âŸ©= âŸ¨[X, Y ], ZâŸ©+ âŸ¨[X, Z], Y âŸ©
+ âŸ¨[Y, Z], XâŸ©+ 2âŸ¨Z, âˆ‡XY âŸ©,
and thus
âŸ¨Z, âˆ‡XY âŸ©= 1
2 (XâŸ¨Y, ZâŸ©+ Y âŸ¨Z, XâŸ©âˆ’ZâŸ¨X, Y âŸ©
âˆ’âŸ¨[X, Y ], ZâŸ©âˆ’âŸ¨[X, Z], Y âŸ©âˆ’âŸ¨[Y, Z], XâŸ©) .
(5.21)
Now a connection on any coordinate patch is uniquely determined by its
Christoï¬€el symbols. However, setting X = âˆ‚i, Y = âˆ‚j and Z = âˆ‚k, Equa-
tion (5.21) gives a method to obtain the Christoï¬€el symbols of âˆ‡strictly

5.2. Connections and Covariant Differentiation
213
in terms of the metric. Hence, if a connection as described in the theorem
exists, then it is unique.
To show that such a connection exists, simply start by deï¬ning âˆ‡using
the identity in Equation (5.21).
Then it is not hard to show that the
connection is both symmetric and compatible with g.
â–¡
Proposition 5.2.13. Let (M n, g) be a smooth Riemannian manifold.
Then
over a coordinate patch of M with coordinates (x1, . . . , xn), the Christoï¬€el
symbols of the Levi-Civita connection are given by
Î“i
jk =
n

l=1
1
2gil
âˆ‚gkl
âˆ‚xj + âˆ‚glj
âˆ‚xk âˆ’âˆ‚gjk
âˆ‚xl
	
,
(5.22)
where gij are the entries to the inverse matrix of (gkl).
Proof: Set g = âŸ¨, âŸ©, and let X = âˆ‚i, Y = âˆ‚j, and Z = âˆ‚k. By the Levi-
Civita connection deï¬ned in Equation (5.21), we have
6
âˆ‚k,
n

l=1
Î“l
ijâˆ‚l
7
= 1
2 (âˆ‚iâŸ¨âˆ‚j, âˆ‚kâŸ©+ âˆ‚jâŸ¨âˆ‚k, âˆ‚iâŸ©âˆ’âˆ‚kâŸ¨âˆ‚i, âˆ‚jâŸ©
âˆ’âŸ¨[âˆ‚i, âˆ‚j], âˆ‚kâŸ©âˆ’âŸ¨[âˆ‚i, âˆ‚k], âˆ‚jâŸ©âˆ’âŸ¨[âˆ‚j, âˆ‚k], âˆ‚iâŸ©) .
However, the smoothness condition implies that [âˆ‚i, âˆ‚j] = 0 for any indices
i, j. Furthermore, by deï¬nition, gij = âŸ¨âˆ‚i, âˆ‚jâŸ©, so by the linearity of the
metric on the left-hand side,
n

l=1
gklÎ“l
ij = 1
2 (âˆ‚igjk + âˆ‚jgki âˆ’âˆ‚kgij) .
The proposition follows by multiplying (and contracting) by gkl, the com-
ponents of the inverse of (gkl).
â–¡
For the reader who is familiar with the diï¬€erential geometry of sur-
faces (especially one who has read [5]), he or she has already seen Propo-
sition 5.2.13 but in a more limited context. In [5, Section 7.2], the authors
talk about Gaussâ€™s equations for a regular surface over a parametrization
âƒ—X. In that section, one sees that even though the normal vector to a sur-
face is not an intrinsic property, âƒ—Xij Â· âƒ—Xk is intrinsic and in fact is given by
the Christoï¬€el symbols of the ï¬rst kind, which are precisely those in Equa-
tion (5.22), though with n = 2. This is not a mere coincidence. In deï¬ning
the Levi-Civita connection, that we might want âˆ‡to be compatible with

214
5. Introduction to Riemannian Geometry
g made intuitive sense. However, the stipulation that we would want âˆ‡to
be symmetric may have seemed somewhat artiï¬cial at the time. It is very
interesting that the two conditions in Theorem 5.2.11 lead to Christoï¬€el
symbols that match those deï¬ned for surfaces in classical diï¬€erential ge-
ometry.
It is possible to develop a theory of embedded submanifolds M m of Rn
following the theory of regular surfaces in R3. Mimicking the presentation
in [5, Section 7.2], if âƒ—X is a parametrization of a coordinate patch of M,
then, by setting
âˆ‚2 âƒ—X
âˆ‚xiâˆ‚xj =
m

k=1
Î“k
ij
âˆ‚âƒ—X
âˆ‚xk + (Normal component),
the components Î“k
ij are again the Christoï¬€el symbols of the second kind,
given by the same formula in Equation (5.22). This shows that for subman-
ifolds of a Euclidean space, the Levi-Civita connection on a Riemannian
manifold is essentially the ï¬‚at connection on Rn restricted to the manifold.
We ï¬nish this section with a comment on the divergence operator on
tensors introduced in Problem 5.1.10. We will show in Problem 5.2.16 that,
using the Levi-Civita connection, the divergence operator on a vector ï¬eld
X âˆˆX(M) can be written as
div X = Xi
;i.
This motivates, ï¬rst, the deï¬nition of the divergence of any tensor T of
type (r, s), with r â‰¥1, on a Riemannian manifold. If T has components
T i1Â·Â·Â·ir
j1Â·Â·Â·js in a coordinate system, then the divergence of T , written div T or
âˆ‡Â· T , is the tensor ï¬eld of type (r âˆ’1, s) with component functions
T Î±i2Â·Â·Â·ir
j1j2Â·Â·Â·js ;Î± = âˆ‡âˆ‚Î±T Î±i2Â·Â·Â·ir
j1Â·Â·Â·js .
Of course, one can just as easily take the divergence with respect to any
contravariant index but one must specify which index. If the index is not
speciï¬ed, we assume the divergence is taken with respect to the ï¬rst index.
One can also deï¬ne the divergence of a covariant index by raising that
index ï¬rst. Thus, for example, if Ï‰ is a 1-form, then
div Ï‰ = (gijÏ‰j);i.
(5.23)
Problem 5.2.16 shows that whether one raises the index before or after the
covariant derivative is irrelevant.

5.2. Connections and Covariant Differentiation
215
Problems
5.2.1. Consider the special case of the manifold M = R3. Let X be the constant
vector ï¬eld âƒ—v, and let X(R3) be the space of vector ï¬elds R3 â†’R3. Show
that the usual partial derivative Dâƒ—v applied to X(R3) satisï¬es conditions
2 and 3 of Deï¬nition 5.2.1.
5.2.2. Recall the permutation symbol deï¬ned in Equation (2.30). Let M be a
three-dimensional manifold equipped with a symmetric aï¬ƒne connection.
Let A and B be vector ï¬elds on M. Show that
ÎµijkAj;i = Îµijk âˆ‚Aj
âˆ‚xi
and that
(ÎµijkAjBk);i = ÎµijkAj;iBk âˆ’ÎµijkAkBj;i.
If M = R3, explain how the latter formula is equivalent to âƒ—âˆ‡Â· ( âƒ—A Ã— âƒ—B) =
(âƒ—âˆ‡Ã— A) Â· âƒ—B âˆ’âƒ—A Â· (âƒ—âˆ‡Ã— âƒ—B).
5.2.3. Let âˆ‡be a connection on a vector bundle Î¾ over a smooth manifold M.
Prove that if X = ËœX and Y = ËœY over a neighborhood of p, then
âˆ‡XY

p = âˆ‡Ëœ
X ËœY

p.
5.2.4. Let âˆ‡be a connection on a vector bundle Î¾ over a smooth manifold M.
Use the result of Problem 5.2.3 to show that âˆ‡XY |p depends only on Xp
and the values of Y in a neighborhood of p.
5.2.5. Prove Proposition 5.2.5.
5.2.6. Prove that the Levi-Civita connection for the Euclidean space Rn is such
that âˆ‡XY = X(Y k)âˆ‚k.
5.2.7. Consider the open ï¬rst quadrant U = {(u, v) âˆˆR2 | u > 0, v > 0}, and
equip U with the metric
(gij) =
â›
â
1
1
âˆš
u2+v2
1
âˆš
u2+v2
1
u2
â
â .
Calculate the Christoï¬€el symbols for the associate Levi-Civita connection.
5.2.8. Consider the cylinder in S2 Ã— R in R4 given by the parametrization
F(u1, u2, u3) = (cos u1 sin u2, sin u1 sin u2, cos u2, u3)
and equip it with the metric induced from R4. Over the open coordinate
patch U = (0, 2Ï€) Ã— (0, Ï€) Ã— R, calculate the metric coeï¬ƒcients and the
Christoï¬€el symbols for the Levi-Civita connection.
5.2.9. Consider the unit sphere S3 as a submanifold of R4 with the induced
metric. Consider the coordinate patch on S3 given by the parametrization
in 5.1.11(a). Calculate one nonzero Christoï¬€el symbol Î“i
jk. (It would be
quite tedious to ask one to calculate all of the symbols since there could
be as many as 27 of them.) [Hint: Show that the conditions of Problem
5.2.13 apply to this coordinate patch and use the result.]

216
5. Introduction to Riemannian Geometry
5.2.10. Let M be a smooth manifold equipped with an aï¬ƒne connection âˆ‡. Let
Ï‰ âˆˆÎ©k(M) be a k-form. Show that âˆ‡Ï‰ is a (k+1)-form and that âˆ‡Ï‰ = dÏ‰
regardless of the choice of connection.
5.2.11. Finish calculating directly the Christoï¬€el symbols in Example 5.2.6.
5.2.12. Let (M, g) be a Riemannian manifold. Prove that a connection âˆ‡satisï¬es
âˆ‡g = 0 identically if and only if Equation (5.17) holds where g = âŸ¨, âŸ©.
5.2.13. Let (M, g) be a Riemannian manifold and let U be an orthogonal coor-
dinate patch, i.e., gij = 0 if i Ì¸= j over U.
Let âˆ‡be the Levi-Civita
connection on M.
(a) Prove that on U the Christoï¬€el symbols Î“i
jk = 0 unless i = j, j = k,
or i = k.
(b) Show that âˆ‡can be speciï¬ed on U by 2n2 âˆ’n smooth functions, i.e.,
there are at most that many distinct nonzero Christoï¬€el symbols.
(c) Show that
Î“i
jj = Â±1
2gii âˆ‚gjj
âˆ‚xi ,
and
Î“i
ij = 1
2gii âˆ‚gii
âˆ‚xj
where there is no summation in either of these formulas and where
the sign of Â± is +1 if i = j and âˆ’1 if i Ì¸= j.
5.2.14. Let M be a smooth manifold, and let âˆ‡be a connection on TM. Deï¬ne
a map Ï„ : X(M) Ã— X(M) â†’X(M) by
Ï„(X, Y ) = âˆ‡XY âˆ’âˆ‡Y X âˆ’[X, Y ].
(a) Show that Ï„ is a tensor ï¬eld of type (1, 2).
(b) The connection âˆ‡is called symmetric if its torsion vanishes identi-
cally. Prove that âˆ‡is symmetric if and only if over every coordinate
patch U, the component functions satisfy Î“i
jk = Î“i
kj.
5.2.15. Let âˆ‡be an aï¬ƒne connection on M.
Prove that âˆ‡+ A is an aï¬ƒne
connection, where A is a (1, 2)-tensor ï¬eld. Conversely, prove that every
aï¬ƒne connection is of the form âˆ‡+ A for some (1, 2)-tensor ï¬eld A.
5.2.16. Consider the divergence operator introduced in Problem 5.1.10 and dis-
cussed at the end of this section.
(a) Show from the deï¬nition in Problem 5.1.10 that
div X = Xi
;i,
where weâ€™ve used the Levi-Civita connection to take the covariant
derivative.
(b) Consider the deï¬nition in Equation (5.23) for the divergence on a
1-form. Show that
div Ï‰ = (gijÏ‰j);i = gijÏ‰j;i.

5.2. Connections and Covariant Differentiation
217
5.2.17. Let f âˆˆCâˆ(M) be a smooth function on a manifold M equipped with
any aï¬ƒne connection âˆ‡. Show that
f;i;j âˆ’f;j;i = âˆ’Ï„ m
ij f;m,
where Ï„ is the torsion tensor from Exercise 5.2.14. Conclude that if âˆ‡is
symmetric, then so is f;i;j.
5.2.18. Let M be a smooth manifold, let Î· âˆˆÎ©2(M) be a 2-form, and let âˆ‡be
any symmetric connection on M. Show that in any coordinate system,
cÎ±Î²Î³ = Î·Î±Î²;Î³ + Î·Î²Î³;Î± + Î·Î³Î±;Î² = âˆ‚Î³Î·Î±Î² + âˆ‚Î±Î·Î²Î³ + âˆ‚Î²Î·Î³Î±.
(5.24)
Show that if we write Î· =
1
2Î·Î±Î²dxÎ± âˆ§dxÎ², then the left-hand side of
Equation (5.24) is the component of dÎ· in the basis dxÎ± âˆ§dxÎ² âˆ§dxÎ³ in
the sense that
dÏ‰ = cÎ±Î²Î³dxÎ± âˆ§dxÎ² âˆ§dxÎ³,
where we sum over all Î±, Î²Î³ = 1, . . . , n.
5.2.19. Let (M, g) be a Riemannian metric with Levi-Civita connection âˆ‡. Show
that over every coordinate patch,
âˆ‚(ln âˆšdet g)
âˆ‚xk
= Î“j
jk,
where one sums over j on the right-hand side.
[Hint: Use a result in
Problem C.6.5.]
5.2.20. Let âˆ‡be an aï¬ƒne connection on M, and let U be a coordinate patch
on M.
(a) Show that there exists a unique matrix of 1-forms Ï‰j
i deï¬ned on U
such that
âˆ‡Xâˆ‚i = Ï‰j
i (X)âˆ‚j
for all X âˆˆX(M). (The matrix Ï‰j
i is called the connection 1-forms
for this coordinate system.)
(b) Suppose that (M, g) is a Riemannian manifold.
Show that âˆ‡is
compatible with the metric g if, over any coordinate system U,
gjkÏ‰k
i + gikÏ‰k
j = dgij.
5.2.21. The Lie Derivative. There exists an alternative way of deï¬ning a deriva-
tive on tensor ï¬elds on a manifold M. This exercise introduces the Lie
derivative in terms of coordinates and then establishes a coordinate-free
interpretation.
Let M be a smooth manifold, and let T i1Â·Â·Â·ir
j1Â·Â·Â·js be the components of a tensor
ï¬eld T deï¬ned over a coordinate system (U, x) of M. Let X âˆˆX(M) be
a vector ï¬eld on M. For a ï¬xed (small) t, the ï¬‚ow Ft of X on M can be
expressed in coordinates by the transformation
xi âˆ’â†’Â¯xi = xi + tXi(x1, . . . , xn).
(5.25)

218
5. Introduction to Riemannian Geometry
Let T i1Â·Â·Â·ir
j1Â·Â·Â·js be the components of a tensor T in the coordinates (xi), and
for a ï¬xed t, denote by T
k1Â·Â·Â·kr
l1Â·Â·Â·ls the components of T under the coordinate
transformation in Equation (5.25). We deï¬ne the Lie derivative LXT as
the tensor of type (r, s) with the components
(LXT )i1Â·Â·Â·ir
j1Â·Â·Â·js = lim
tâ†’0
1
t

T i1Â·Â·Â·ir
j1Â·Â·Â·js (xk) âˆ’T
i1Â·Â·Â·ir
j1Â·Â·Â·js(xk)

.
Prove the following results about the Lie derivative:
(a) The components of the Lie derivative satisfy
(LXT)i1Â·Â·Â·ir
j1Â·Â·Â·js = âˆ‚T i1Â·Â·Â·ir
j1Â·Â·Â·js
âˆ‚xh
Xh âˆ’
r

Î±=1
T
i1Â·Â·Â·iÎ±âˆ’1miÎ±+1Â·Â·Â·ir
j1Â·Â·Â·js
âˆ‚XiÎ±
âˆ‚xm
+
s

Î²=1
T i1Â·Â·Â·ir
j1Â·Â·Â·jÎ²âˆ’1mjÎ²+1Â·Â·Â·js
âˆ‚Xm
âˆ‚xjÎ² .
(b) If f âˆˆCâˆ(M) is a smooth function, then LXf is the function such
that
(LXf)(p) = dfp(Xp).
(c) If Y âˆˆX(M) is a vector ï¬eld on M, then
LXY = d
dt(dF(âˆ’t)(Y ))

t=0 = [X, Y ].
(d) If Î· âˆˆÎ©1(M) is a 1-form on M, then
LXÎ· = d
dt(F âˆ—
t Î·)

t=0.
(e) If A and B are any tensor ï¬elds on M, then
LX(A âŠ—B) = (LXA) âŠ—B + A âŠ—(LXB).
(The properties from (b)â€“(e) recursively show how to deï¬ne the Lie deriva-
tive of any tensor ï¬eld on M in a coordinate-free way.)
5.2.22. Properties of the Lie Derivative. Let Î± âˆˆÎ©k(M) be a k-form on M. Prove
the following properties of the Lie derivative.
(a) LXÎ± = d(iXÎ±) + iX(dÎ±), where iX is the contraction operation de-
ï¬ned in Problem 5.1.10.
(b) LX(Î± âˆ§Î²) = (LXÎ±) âˆ§Î² + Î± âˆ§(LXÎ²) for all Î² âˆˆÎ©l(M).
(c) (LXÎ±)(X1, . . . , Xk) = LX(Î±(X1, . . . , Xk)) âˆ’"k
i=1 Î±(X1, . . . ,
[X, Xi], . . . , Xk).
(d) LX(dÎ±) = d(LXÎ±).
(e) LX(iXÎ±) = iX(LXÎ±).
(f) L[X,Y ]Î± = LXLY Î± âˆ’LY LXÎ±
[Hint: Recall the description of 1k V as a subspace of V âŠ—k, as described
in Section C.5.2.]

5.3. Vector Fields Along Curves: Geodesics
219
Î³
Figure 5.4. A nonextendable vector ï¬eld on a curve.
5.3
Vector Fields Along Curves: Geodesics
Suppose we think of the trajectory of a particle on a manifold M. One
would describe it as curve Î³(t) on M. Furthermore, in order to develop a
theory of dynamics on manifolds, one would need to be able to make sense
of the acceleration of the curve or of higher derivatives of the curve. In
this section, we deï¬ne vector ï¬elds on curves on manifolds. Once we deï¬ne
a covariant derivative of a vector ï¬eld on a curve, we can then discuss
parallel vector ï¬elds on the curve and the acceleration ï¬eld along the curve.
We then show that deï¬ning a geodesic as a curve whose acceleration is
identically 0 leads to the classical understanding of a geodesic as a path of
minimum length in some sense.
5.3.1
Vector Fields Along Curves
Deï¬nition 5.3.1. Let M be a smooth manifold, and let Î³ : I â†’M be a
smooth curve in M, where I is an interval in R. We call V a vector ï¬eld
along Î³ if for each t âˆˆI, V (t) is a tangent vector in TÎ³(t)M and if V deï¬nes
a smooth map I â†’T M. We denote by XÎ³(M) the set of all smooth vector
ï¬elds on M along Î³.
A vector ï¬eld along a curve is not necessarily the restriction of a vector
ï¬eld on M to Î³(I). For example, whenever a curve self-intersects, Î³(t0) =
Î³(t1), with t0 Ì¸= t1, but since V (t0) Ì¸= V (t1) there exists no vector ï¬eld
Y on M such that V (t) = YÎ³(t) for all t âˆˆI (see Figure 5.4). If V is the
restriction of a vector ï¬eld Y , then we say that V is induced from Y or
that V extends to Y .

220
5. Introduction to Riemannian Geometry
Proposition 5.3.2. Let M be a smooth manifold with an aï¬ƒne connection âˆ‡,
and let Î³ : I â†’M be a smooth curve on M. There exists a unique operator
Dt : XÎ³(M) â†’XÎ³(M) (also denoted by D
dt) such that
1. Dt(V + W) = DtV + DtW for all V, W âˆˆXÎ³(M);
2. Dt(fV ) = df
dtV + fDtV for all V âˆˆXÎ³(M) and all f âˆˆCâˆ(M);
3. if V extends to a vector ï¬eld Y âˆˆX(M), then DtV = âˆ‡Î³â€²(t)Y .
Note that the last condition makes sense by the fact that âˆ‡XY |p only
depends on the values of Y in a neighborhood of p and on the value of Xp
(see Exercise 5.2.4).
Before proving Proposition 5.3.2, we introduce the dot notation for
derivatives. The only purpose is to slightly simplify our equationsâ€™ notation.
If x(t) is a real-valued function of a real variable, we write
Ë™x(t)
def
= xâ€²(t) = dx
dt
and
Â¨x(t)
def
= xâ€²â€²(t) = d2x
dt2 .
The dot notation is common in physics in the context of taking derivatives
with respect to time. Therefore, Ë™x is usually used when one uses the letter
t as the only independent variable for the function x.
Proof (of Proposition 5.3.2): Let us ï¬rst suppose that an operator Dt with
Properties 1â€“3 exists. Let U be a coordinate patch of M with coordinates
x = (x1, . . . , xn). For any V âˆˆXÎ³(M), write V = viâˆ‚i where vi âˆˆCâˆ(I)
are smooth functions over I. By Conditions 1 and 2, we have
DtV = Ë™vjâˆ‚j + vjDt(âˆ‚j).
Now if we write Î³(t) = (Î³1(t), . . . , Î³n(t)) for the coordinate functions of Î³
over U, then Î³â€²(t) = "n
i=1 Ë™Î³iâˆ‚i. Thus, by Condition 3,
Dt(âˆ‚j) = âˆ‡Î³â€²(t)âˆ‚j =
n

i=1
Ë™Î³iâˆ‡âˆ‚iâˆ‚j = Ë™Î³iÎ“k
ijâˆ‚k.
Hence, we deduce the following formula for DtV in coordinates over U:
DtV =
dvj
dt âˆ‚j
	
+

Î“k
ij
dÎ³i
dt vjâˆ‚k
	
=

Ë™vk + Î“k
ij Ë™Î³ivj
âˆ‚k.
(5.26)
Equation (5.26) shows that if there does exist an operator satisfying
properties Conditions 1â€“3, then the operator is unique. To prove existence

5.3. Vector Fields Along Curves: Geodesics
221
over all of M, we deï¬ne DÎ±
t by Equation (5.26) on each coordinate chart
UÎ±. However, since DÎ±
t is unique on each coordinate chart, then DÎ±
t = DÎ²
t
over UÎ± âˆ©UÎ² if UÎ± and UÎ² are overlapping coordinate charts. Hence, as
Î± ranges over all coordinate charts in the atlas, the collection of operators
DÎ±
t extends to a single operator Dt over all of M.
â–¡
Note that Equation (5.26) in the above proof gives the formula for
Dt over a coordinate patch of M.
In particular, the expression in the
parentheses on the right gives the component functions (in the index k) for
DtV .
Deï¬nition 5.3.3. The operator Dt : XÎ³(M) â†’XÎ³(M) deï¬ned in Proposition
5.3.2 is called the covariant derivative along Î³.
In the context of Riemannian manifolds, the covariant derivative along
a curve has the following interesting property.
Proposition 5.3.4. Let Î³ be a smooth curve on a Riemannian manifold (M, g)
equipped with the Levi-Civita connection. Write g = âŸ¨, âŸ©. Let V and W be
vector ï¬elds along Î³. Then
d
dtâŸ¨V, WâŸ©= âŸ¨DtV, WâŸ©+ âŸ¨V, DtWâŸ©.
Proof: (Left as an exercise for the reader. See Problem 5.3.10.)
â–¡
The notion of a vector ï¬eld along a curve (in a manifold M) leads us
immediately to two useful notions: parallel transport and acceleration.
Deï¬nition 5.3.5. Let M be a smooth manifold with an aï¬ƒne connection âˆ‡,
and let Î³ : I â†’M be a smooth curve on M. A vector ï¬eld V along Î³ is
called parallel if DtV = 0 identically.
The existence of parallel vector ï¬elds on a curve amounts to the solv-
ability of a system of diï¬€erential equations.
Proposition 5.3.6 (Parallel Transport). Let M be a smooth manifold with an
aï¬ƒne connection âˆ‡, and let Î³ : I â†’M be a smooth curve on M, where
I is a compact interval of R. Let t0 âˆˆI, set p = Î³(t0), and let V0 be any
vector in TpM. There exists a unique vector ï¬eld of M along Î³ that is
parallel and has V (t0) = V0.

222
5. Introduction to Riemannian Geometry
Proof: Suppose ï¬rst that M is a manifold that is covered with a single
coordinate system x = (x1, . . . , xn).
By Equation (5.26), the condition
DtV = 0 means that
Ë™vk + Î“k
ij Ë™Î³ivj = 0
for all k = 1, . . . , n.
(5.27)
The values Î“k
ij depend on the position of Î³(t) as do the derivatives Ë™Î³i(t),
but neither of these depend on the functions vi(t). Hence, Equation (5.27)
is a system of linear, homogeneous, ordinary, diï¬€erential equations in the
n functions vi(t). By a standard result of ordinary diï¬€erential equations
(see [18, Appendix A] or [3, Section 8]), given an initial value t = t0 and
initial conditions vi(t0) = vi
0, there exists a unique solution to the system
of equations satisfying these initial conditions. (The particular form of the
nonautonomous system from Equation (5.27) and the hypothesis that I
is compact imply that the system satisï¬es the Lipschitz condition, which
establishes the uniqueness of the solutions.) Hence V exists and is unique.
Now suppose that M cannot be covered by a single coordinate chart.
We only need to consider coordinate charts that cover Î³(I).
But since
Î³(I) is compact, we can cover it with only a ï¬nite number of coordinate
charts.
However, on each of these charts, we have seen that there is a
unique parallel vector ï¬eld, as described. By identifying the vector ï¬elds
over each coordinate chart, we obtain a single vector ï¬eld over all of Î³ that
is parallel to V0.
â–¡
Deï¬nition 5.3.7. The vector ï¬eld V in Proposition 5.3.6 is called the parallel
transport of V0 along Î³.
It is important to note that the parallel transport of V0 from a point p
to a point q along two diï¬€erent paths generally results in diï¬€erent vectors in
TqM. In Figure 5.5, the tangent vector V0 at p produces diï¬€erent tangent
vectors at q when transported along the black curve versus along the gray
curve. One says that parallel transport is nonintegrable. However, it is
not hard to see, either geometrically or by solving Equation (5.27), that
in Rn parallel transport does not depend on the path.
Therefore, this
nonintegrability of parallel transport characterizes the notion of curvature,
as we will see in the following section.
As a second application of the covariant derivative along a curve, we
ï¬nally introduce the notion of acceleration of a curve on a manifold.
Deï¬nition 5.3.8. Let M be a smooth manifold with an aï¬ƒne connection
and let Î³ : I â†’M be a smooth curve on M. For all t âˆˆI, we deï¬ne the
acceleration of Î³ on M as the covariant derivative DtÎ³â€²(t) of Î³â€²(t) along Î³.

5.3. Vector Fields Along Curves: Geodesics
223
  p
q
V0
Figure 5.5. Path dependence of parallel transport.
Example 5.3.9. With the deï¬nition of the acceleration, we are in a position
to be able to phrase Newtonâ€™s second law of motion on a manifold. In
R3, Newtonâ€™s law states that if a particle has constant mass m and is
inï¬‚uenced by the exterior forces âƒ—Fi, then the particle follows a path âƒ—x(t)
that satisï¬es "
i âƒ—Fi = mâƒ—xâ€²â€². Translated into the theory of manifolds, if a
force (or collection of forces) makes a particle move along some curve Î³,
then writing F as the vector ï¬eld along Î³ that describes the force, Î³ must
satisfy
mDtÎ³â€²(t) = F(t).
The acceleration is itself a vector ï¬eld along the curve Î³ so the notions
of all the higher derivatives are deï¬ned as well.
5.3.2
Geodesics
Intuitively speaking, a geodesic on a manifold is a curve that generalizes
the notion of a straight line in Rn. The seemingly simple task of deï¬ning
a geodesic is surprisingly diï¬ƒcult.
Only now, do we possess the neces-
sary background to do so. Even in Euclidean geometry, though everyone
â€œknowsâ€ what a straight line is, even Euclidâ€™s original deï¬nitions for a
straight line do not satisfy todayâ€™s standards of precision. We introduce
geodesics using two diï¬€erent approaches, each taking a property of straight
lines in Rn and translating it into the context of manifolds.
Deï¬nition 5.3.10. Let M be a smooth manifold with an aï¬ƒne connection âˆ‡.
A curve Î³ : I â†’M is called a geodesic if its acceleration is identically 0,
i.e., DtÎ³â€²(t) = 0.

224
5. Introduction to Riemannian Geometry
Note that this deï¬nition does not require a metric structure on M,
simply an aï¬ƒne connection. One should also observe that this deï¬nition
relies on a speciï¬c parametrization of Î³. The deï¬nition is modeled after
the fact that one can parametrize a straight line in Rn by âƒ—Î³(t) = âƒ—p + tâƒ—v
for constant vectors âƒ—p and âƒ—v and that with this parametrization âƒ—Î³ â€²â€²(t) =
âƒ—0. However, the curve âƒ—x(t) = âƒ—p + t3âƒ—v traces out the same set of points
but âƒ—x â€²â€²(t) = 3t2âƒ—v, which is not identically 0. Despite this, one can leave
Deï¬nition 5.3.10 as it is and keep in mind the role of the parametrization.
Proposition 5.3.11 (Geodesic Equations). Let M be a smooth manifold equipped
with an aï¬ƒne connection, and let x = (x1, . . . , xn) be a system of coordi-
nates on a chart U.
A curve Î³ is a geodesic on U if and only if the
coordinate functions Î³(t) = (Î³1(t), . . . , Î³n(t)) satisfy
d2Î³i
dt2 + Î“i
jk(Î³(t))dÎ³j
dt
dÎ³k
dt = 0
for all i.
(5.28)
Proof: This follows immediately from Equation (5.26).
â–¡
Equation (5.28) for a geodesic is a second-order system of ordinary
diï¬€erential equations in the functions Î³i(t). Setting vi(t) = Ë™Î³i, one can
write Equation (5.28) as a ï¬rst-order system in the 2n functions Î³i and
vi by

Ë™Î³i = vi,
Ë™vi = âˆ’Î“i
jk(Î³(t))vjvk.
This system is now ï¬rst-order and non-linear but autonomous (does not
depend explicitly on t). By standard theorems in diï¬€erential equations [3,
Theorems 7.3, 7.4], we immediately conclude the following theorem.
Theorem 5.3.12. Let M be a manifold with an aï¬ƒne connection. For any
p âˆˆM, for any V âˆˆTpM, and for any t0 âˆˆR, there exists an open interval
I containing t0 and a unique geodesic Î³ : I â†’M satisfying Î³(t0) = p and
Î³â€²(t0) = V .
This theorem shows the existence of the curve Î³ by solving Equa-
tion (5.28) over a coordinate neighborhood. In this case, the interval I
may be limited by virtue of the fact that Î³(I) âŠ‚U. It may be possible
to extend Î³ over other coordinate patches.
If Î³(t1) for some t1 âˆˆI is
in another coordinate patch Â¯U, then we can uniquely extend the geodesic
over Â¯U as going through the point Î³(t1) with velocity Î³â€²(t1). We deï¬ne a
maximal geodesic as a geodesic Î³ : I â†’M whose domain interval cannot

5.3. Vector Fields Along Curves: Geodesics
225
p
q
Figure 5.6. Two geodesics on a cylinder.
be extended. If Î³ is a maximal geodesic with Î³(t0) = p and Î³â€²(t0) = V for
some t0 âˆˆI, we call Î³ the geodesic with initial point p and initial velocity
V âˆˆTpM, and we denote it by Î³V .
Another deï¬ning property of a straight line in Rn is that the shortest
path between two points is a straight line segment.
If we use the con-
cept of distance, we need a metric. Let (M, g) be a Riemannian metric
equipped with the Levi-Civita connection, and let Î³ be a geodesic on M.
By Proposition 5.3.4,
d
dtâŸ¨Î³â€²(t), Î³â€²(t)âŸ©= 2âŸ¨DtÎ³â€²(t), Î³â€²(t)âŸ©= 0,
so we can conclude the following initial result.
Proposition 5.3.13. A geodesic on a Riemannian manifold has constant speed.
Now on a Riemannian manifold, an alternate approach to deï¬ning geo-
desics on a manifold is to call a geodesic a path of shortest length between
two points. However, this deï¬nition is not quite good enough, as Figure 5.6
indicates. Both curves connecting p and q are geodesics, but one is shorter
than the other. To be more precise, we call Î³ a geodesic connecting p1 and
p2 if there is an interval [t1, t2] such that Î³(t1) = p1, Î³(t2) = p2, and Î³
minimizes the arclength integral
L =
% t2
t1

gij(Î³(t))Ë™Î³i(t)Ë™Î³j(t) dt.
(5.29)

226
5. Introduction to Riemannian Geometry
Techniques of calculus of variations discussed in Appendix B produce
the diï¬€erential equations for the curve Î³ that minimizes the arclength.
However, similar to optimization methods in regular calculus, the solutions
we obtain are local minima, which means in our case that there are no
small deviations of Î³ that produce a shorter path between p and q. It is
tedious to show, but Theorem B.3.1 implies that a curve Î³ that minimizes
the integral in Equation (5.29) must satisfy
d2Î³i
ds2 + Î“i
jk
dÎ³j
ds
dÎ³k
ds = 0,
for i = 1, . . . , n,
(5.30)
where s is the arclength of Î³. Proposition 5.3.11 along with Proposition
5.3.13 show that deï¬ning a geodesic as having no acceleration is equivalent
to deï¬ning it as minimizing length in the above sense.
Example 5.3.14 (Sphere). Consider the parametrization of the sphere given by
âƒ—X(x1, x2) = (R cos x1 sin x2, R sin x1 sin x2, R cos x2),
where x1 is the longitude Î¸ in spherical coordinates and x2 is the angle
Ï• down from the positive z-axis. In Example 5.1.12, we determined the
coeï¬ƒcients of the metric tensor. Then it is easy to calculate the Christoï¬€el
symbols Î“i
jk for the sphere. Equations (5.30) for geodesics on the sphere
become
d2x1
ds2 + 2 cot(x2)dx1
ds
dx2
ds = 0,
d2x2
ds2 âˆ’sin(x2) cos(x2)
dx1
ds
	2
= 0.
(5.31)
A geodesic on the sphere is now just a curve of the form âƒ—Î³(s) =
âƒ—X(x1(s), x2(s)) where x1(s) and x2(s) satisfy the system of diï¬€erential
equations in Equation (5.31). Taking a ï¬rst derivative of âƒ—Î³(s) gives
âƒ—Î³â€²(s) = R

âˆ’sin x1 sin x2 dx1
ds + cos x1 cos x2 dx2
ds ,
cos x1 sin x2 dx1
ds + sin x1 cos x2 dx2
ds , âˆ’sin x2 dx2
ds
	
,
and the second derivative, after simpliï¬cation using Equation (5.31), is
d2âƒ—Î³
ds2 = âˆ’
8
sin2(x2)
dx1
ds
	2
+
dx2
ds
	29
âƒ—Î³(s).

5.3. Vector Fields Along Curves: Geodesics
227
However, the term R2[sin2(x2)( dx1
ds )2 + ( dx2
ds )2] is the ï¬rst fundamental
form on
((x1)â€²(s), (x2)â€²(s)),
which is precisely the square of the speed of âƒ—Î³(s).
However, since the
geodesic is parametrized by arclength its speed is identically 1.
Thus,
Equation (5.31) leads to the diï¬€erential equation
âƒ—Î³â€²â€²(s) + 1
R2âƒ—Î³(s) = 0.
Standard techniques with diï¬€erential equations allow one to show that all
solutions to this diï¬€erential equation are of the form
âƒ—Î³(s) = âƒ—a cos
 s
R

+âƒ—b sin
 s
R

,
where âƒ—a and âƒ—b are constant vectors. Note that âƒ—Î³(0) = âƒ—a and that âƒ—Î³â€²(0) =
1
Râƒ—b. Furthermore, to satisfy the conditions that âƒ—Î³(s) lie on the sphere of
radius R and be parametrized by arclength, we deduce that âƒ—a and âƒ—b satisfy
âˆ¥âƒ—aâˆ¥= R,
âˆ¥âƒ—bâˆ¥= R, and
âƒ—a Â·âƒ—b = 0.
Therefore, we ï¬nd that âƒ—Î³(s) traces out a great arc on the sphere that is the
intersection of the sphere and the plane through the center of the sphere
spanned by âƒ—Î³(0) and âƒ—Î³â€²(0).
There are many properties of lines that no longer hold for geodesics on
manifolds. For example, lines in Rn are (â€œobviouslyâ€) simple curves, i.e.,
they do not intersect themselves. In Example 5.3.14, we showed that the
geodesics on a sphere are arcs of great circles (equators). In this case, a
maximal geodesic is a whole circle that, as a closed curve, is still simple.
In contrast, Figure 5.7 of a distorted sphere shows only a portion of a
geodesic that is not closed and intersects itself many times. The problem
of ï¬nding closed geodesics on surfaces illustrates how central the study of
geodesics is in current research: in 1917, Birkhoï¬€used techniques from
dynamical systems to show that every deformed sphere has at least one
closed geodesic [9]; in 1929, Lusternik and Schnirelmann improved upon
this and proved that there always exist three closed geodesics on a deformed
sphere [36]; and in 1992 and 1993, Franks and Bangert [6,22] proved that
there exist an inï¬nite number of closed geodesics on a deformed sphere.
However, a proof of the existence of a closed geodesic would not necessarily
help us construct one for any given surface.

228
5. Introduction to Riemannian Geometry
Figure 5.7. A nonclosed geodesic on a manifold.
We end this section by presenting the so-called exponential map. The-
orem 5.3.12 allows us to deï¬ne a map, for each p âˆˆM, from the tangent
plane TpM to M by mapping V to a ï¬xed distance along the unique geo-
desic Î³V .
Deï¬nition 5.3.15. Let p be a point on a Riemannian manifold (M, g). Let
Dp be the set of tangent vectors V âˆˆTpM such that the geodesic Î³V , with
Î³V (0) = p, is deï¬ned over the interval [0, 1]. The exponential map, written
expp, is the function
expp : Dp âˆ’â†’M,
V âˆ’â†’Î³V (1).
Lemma 5.3.16 (Scaling Lemma). Let V âˆˆTpM, and let c âˆˆR>0. Suppose that
Î³V (t) is deï¬ned over (âˆ’Î´, Î´), with Î³V (0) = p. Then Î³cV (t) is deï¬ned over
the interval (âˆ’Î´/c, Î´/c), and
Î³cV (t) = Î³V (ct).
Proof: (Left as an exercise for the reader. See Problem 5.3.11.)
â–¡
By virtue of the scaling lemma, we can write for the geodesic through
p along V ,
Î³V (t) = expp(tV ).
Proposition 5.3.17. For all p âˆˆM, there exists a neighborhood U of p on M
and a neighborhood D of the origin in TpM such that expp : D â†’U is a
diï¬€eomorphism.
Proof: The diï¬€erential of expp at 0 is a linear transformation d(expp)0 :
T0(TpM) â†’TpM. However, since TpM is a vector space, then the tangent

5.3. Vector Fields Along Curves: Geodesics
229
space T0(TpM) is naturally identiï¬ed with TpM. Thus, d(expp)0 is a linear
transformation on the vector space TpM. The proposition follows from the
Inverse Function Theorem (Theorem 1.4.5) once we show that d(expp)0 =
(expp)âˆ—is invertible.
We show this indirectly using the chain rule. Let V be a tangent vector
in V âˆˆTpM, and let f : (âˆ’Î´, Î´) â†’TpM be the curve f(t) = tV . The
function expp â—¦f is a curve on M. Then
d(expp â—¦f)0 = d expp(tV )
dt

t=0
= dÎ³V (t)
dt

t=0
= V.
However, by the chain rule, we also have
d(expp â—¦f)0 = d(expp)0df0 = (expp)âˆ—V.
Hence, for all V âˆˆTpM, we have (expp)âˆ—V = V . Hence, (expp)âˆ—is in fact
the identity transformation so it is invertible, and the proposition follows.â–¡
Now if {eÎ¼} is any basis of TpM, the exponential map sets up a coor-
dinate system on a neighborhood of p on M deï¬ned by
expp(XÎ¼eÎ¼).
We call this the normal coordinate system at p with respect to {eÎ¼}. If q is
a point in the neighborhood U, as in Proposition 5.3.17, then q is the image
of a unique tangent vector Xq under expp. The coordinates of q are XÎ¼
q .
Interestingly enough, the coeï¬ƒcients of the Levi-Civita connection van-
ish at p in the normal coordinate system XÎ¼ at p. Consider a geodesic on
M from p to q given by c(t) = expp(tXÎ¼
q eÎ¼), which in coordinates is just
XÎ¼(t) = tXÎ¼
q . From the geodesic equation,
d2XÎ¼
dt2
+ Î“Î¼
Î»Î½
dXÎ»
dt
dXÎ½
dt
= Î“Î¼
Î»Î½(tXi
q)XÎ»
q XÎ½
q .
Setting t = 0, we ï¬nd that Î“Î¼
Î»Î½(0)XÎ»
q XÎ½
q = 0 for any q. Thus, by appropri-
ate choices of q, we determine that Î“Î¼
Î»Î½(0) = 0, which are the components
of the Levi-Civita connection at p in the normal coordinate system.
The exponential map allows us to redeï¬ne some common geometric
objects in Rn in the context of Riemannian manifolds. Notice ï¬rst that by
Proposition 5.3.13, the arclength from p to expp(V ) along Î³V (t) is âˆ¥V âˆ¥p.
Now, let r > 0 be a positive real number and Br(0) be the open ball of
radius r centered at the origin in TpM. If r is small enough that Br(0)

230
5. Introduction to Riemannian Geometry
is contained in the neighborhood U from Proposition 5.3.17, then we call
expp(Br(0)) the geodesic ball of radius r centered at p. If the sphere Sr(0)
of radius r centered at 0 in TpM is contained in U, then we call expp(Sr(0))
the geodesic sphere of radius r centered at p.
5.3.3
Geodesics on Pseudo-Riemannian Manifolds
We point out that all of our discussion about geodesics carries through
without considerable change for pseudo-Riemannian manifolds. None of
the formulas for the Christoï¬€el symbols or for the equations of geodesics
rely on the positive-deï¬nite nature of a metric. A few relevant changes
arise in the following contexts:
â€¢ One can no longer deï¬ne the length of a tangent vector if gp(V, V )<0.
â€¢ One cannot deï¬ne the arclength of a curve Î³ if gÎ³(t)(Î³â€²(t), Î³â€²(t)) < 0
for some t âˆˆI.
â€¢ One might not be able to deï¬ne the volume of a region R of M.
Despite these possible obstructions, the equations for geodesics still satisfy
the existence and uniqueness properties of Theorem 5.3.12. Furthermore,
like Proposition 5.3.13, geodesics on pseudo-Riemannian manifolds have a
constant âŸ¨Î³â€²(t), Î³â€²(t)âŸ©. Thus, geodesics come in three categories depending
on the sign of âŸ¨Î³â€²(t), Î³â€²(t)âŸ©= gij Ë™Î³i(t)Ë™Î³j(t).
In the context of a Lorentz spacetime R1,3, where the metric has index 1,
we say that a geodesic is
â€¢ a timelike geodesic if âŸ¨Î³â€²(t), Î³â€²(t)âŸ©< 0;
â€¢ a null geodesic if âŸ¨Î³â€²(t), Î³â€²(t)âŸ©= 0;
â€¢ a spacelike geodesic if âŸ¨Î³â€²(t), Î³â€²(t)âŸ©> 0.
Problems
5.3.1. Let S be a regular surface in R3, and let âƒ—X be a parametrization of a
coordinate chart U of S. Let âˆ‡be the Levi-Civita connection on S with
respect to the ï¬rst fundamental form metric. Let âƒ—Î³(t) = Î³(t) be a curve
on S. Prove that the acceleration DtÎ³â€²(t) is the orthogonal projection of
âƒ—Î³â€²â€²(t) onto the tangent plane to S at Î³(t).
5.3.2. Consider the torus parametrized by
âƒ—X(u, v) = ((a + b cos v) cos u, (a + b cos v) sin u, b sin v),

5.3. Vector Fields Along Curves: Geodesics
231
where a > b. Show that the geodesics on a torus satisfy the diï¬€erential
equation
dr
du = 1
Cbr

r2 âˆ’C2
b2 âˆ’(r âˆ’a)2,
where C is a constant and r = a + b cos v.
5.3.3. Find the diï¬€erential equations that determine geodesics on a function
graph z = f(x, y).
5.3.4. If âƒ—X : U â†’R3 is a parametrization of a coordinate patch on a regular
surface S such that g11 = E(u), g12 = 0, and g22 = G(u), show that
(a) the u-parameter curves (i.e., over which v is a constant) are geodesics;
(b) the v-parameter curve u = u0 is a geodesic if and only if Gu(u0) = 0;
(c) the curve âƒ—x(u, v(u)) is a geodesic if and only if
v = Â±
%
C

E(u)

G(u)

G(u) âˆ’C2 du,
where C is a constant.
5.3.5. Pseudosphere. Consider a surface with a set of coordinates (u, v) deï¬ned
over the upper half of the uv-plane, i.e., on H = {(u, v) âˆˆR2 | v > 0},
such that the metric tensor is
(gij) =
1
0
0
e2v
	
.
Prove in this coordinate system that all the geodesics appear in the H as
vertical lines or semicircles with center on the u-axis.
5.3.6. Let (M, g) be a two-dimensional Riemannian manifold. Suppose that on
a coordinate patch U with coordinates x = (x1, x2), the metric is given by
g11 = 1, g22 = (x2)2, and g12 = g21 = 0. Show that the geodesics of M on
U satisfy the existence and uniqueness of
x1 = a sec(x2 + b).
5.3.7. Let (M, g) be a four-dimensional manifold with a Lorentzian metric that
over a particular coordinate system has the matrix
gij =
â›
âœ
âœ
â
1
0
0
0
0
1
0
0
0
0
1
gt
0
0
gt
k2 âˆ’g2t2
â
âŸ
âŸ
â .
Show that the geodesics that have the initial condition (x, y, z, t) = (0, 0, 0, 0)
when s = 0 satisfy
x = at,
y = bt,
and
z = âˆ’1
2gt2 + ct.
Use this to give a physical interpretation of this metric.

232
5. Introduction to Riemannian Geometry
  Figure 5.8. Mercator projection.
5.3.8. The Mercator projection used in cartography maps the globe (except the
north and south poles, S2 âˆ’{(0, 0, 1), (0, 0, âˆ’1)}) onto a cylinder, which
is then unrolled into a ï¬‚at map of the earth.
However, one does not
necessarily use the radial projection as shown in Figure 5.8. Consider a
map f from (x, y) âˆˆ(0, 2Ï€) Ã— R to the spherical coordinates (Î¸, Ï†) âˆˆS2 of
the form (Î¸, Ï†) = f(x, y) = (x, h(y)).
(a) Recall that the usual Euclidean metric on S2 is
g =
sin2 Ï†
0
0
1
	
.
The Mercator projection involves the above function f(x, y), such
that h(y) gives a pull-back f âˆ—(g) that is a metric with a line element
of the form ds2 = G(y)dx2 +G(y)dy2. Prove that h(y) = 2 cotâˆ’1(ey)
works, and determine the corresponding function G(y).
(b) Show that the geodesics on R2 equipped with the metric obtained
from this h(y) are of the form
sinh y = Î± sin(x + Î²)
for some constants Î± and Î².
5.3.9. Consider the PoincarÂ´e ball Bn
R from Problem 5.1.9. Prove that the geodes-
ics in the PoincarÂ´e ball are either straight lines through the origin or circles
that intersect the boundary âˆ‚Bn
R perpendicularly. (The PoincarÂ´e ball is an
example of a hyperbolic geometry. In this geometry, given a â€œstraight lineâ€

5.3. Vector Fields Along Curves: Geodesics
233
Bn
R
Figure 5.9. A few geodesics in the PoincarÂ´e disk.
(geodesic) L and a point p not on L, there exists a nonempty continuous
set of lines (geodesics) through p that do not intersect L. See Figure 5.9)
5.3.10. Prove Proposition 5.3.4.
[Hint: Use Equation (5.26) and the fact that
since the Levi-Civita connection is compatible with g, then gij;k = 0.]
5.3.11. Prove Lemma 5.3.16.
5.3.12. (ODE) Consider the usual sphere S2 of radius R in R3. In the coordinate
patch where (Î¸, Ï†) âˆˆ(0, 2Ï€) Ã— (0, Ï€), the Christoï¬€el symbols are given in
Equation (5.31) of Example 5.3.14, where we use the coordinates (Î¸, Ï†) =
(x1, x2). Consider a point p on the sphere given by P = (Î¸0, Ï†0). Let V0
be a vector in TpS2 with coordinates (V 1
0 , V 2
0 ).
(a) Show that the stated Christoï¬€el symbols used in Equation (5.31) are
correct.
(b) Calculate the coordinates of the parallel transport V (t) of V0 along
the curve Î³(t) = (Î¸0, t), using the initial condition t0 = Ï†0. Show
that the length of the tangent vectors V (t) does not change.
(c) Calculate the coordinates of the parallel transport V (t) of V0 along
the curve Î³(t) = (t, Ï†0), using the initial condition t0 = Î¸0. Show
that âˆ¥V (t)âˆ¥2 is constant.
5.3.13. Determine the geodesics in a coordinate patch on a pseudo-Riemannian
manifold with metric with the line element
ds2 = x3 (dx0)2 âˆ’(dx1)2 âˆ’(dx2)2 âˆ’1
x3 (dx3)2.
5.3.14. Show that the locus of a geodesic on the n-sphere Sn (as a submanifold of
Rn+1) is the intersection of Sn with 2-planes that pass through the origin.

234
5. Introduction to Riemannian Geometry
5.3.15. Let M be a two-dimensional manifold, and suppose that on a coordinate
patch (x1, x2), the metric is of the form
g =
f(r)
0
0
f(r)
	
,
where r2 = (x1)2 + (x2)2.
Find the function f(r) that gives a ï¬‚at connection.
5.3.16. Let M be a pseudo-Riemannian manifold of dimension 3 with the line
element
ds2 = âˆ’dt2 +
1
1 âˆ’Î»r2 dr2 + r2dÎ¸2,
where we assume r2 < 1/Î».
Show that the null geodesics satisfy the
relationship
 dr
dÎ¸
	2
= r2(1 âˆ’Î»r2)(Cr2 âˆ’1),
where C is a constant. Use the substitution u = 1/r2 to solve this diï¬€er-
ential equation, and show that the solutions are ellipses if we interpret r
and Î¸ as the usual polar coordinates.
5.3.17. Let M be a pseudo-Riemannian manifold of dimension 4 that has a line
element of
ds2 = (1 âˆ’2gx)dt2 âˆ’
1
1 âˆ’2gxdx2 âˆ’dy2 âˆ’dz2,
where g >0 is a constant. Show that the curve deï¬ned by (1âˆ’2gx) cosh2(gt)
= 1, y = z = 0 is a geodesic passing through the origin.
5.3.18. Determine the geodesics corresponding to the line element metric
ds2 = âˆ’xdt2 + 1
xdx2 + dy2 + dz2.
5.4
The Curvature Tensor
In the study of curves and surfaces in classical diï¬€erential geometry, cur-
vature plays a central role. We approach the notion of curvature on Rie-
mannian manifolds in two diï¬€erent but equivalent ways.
5.4.1
Coordinate-Dependent
The ï¬rst approach to curvature involves investigating mixed, partial, co-
variant derivatives. For smooth functions in Rn, mixed, second-order par-
tial derivatives are independent of the order of diï¬€erentiation. Problem
5.2.17 showed that if a connection âˆ‡on M is not symmetric, the same re-
sult is no longer true for the mixed, covariant, partial derivatives of smooth

5.4. The Curvature Tensor
235
functions on a manifold. We found that if f : M â†’R, then over a given
coordinate patch U, one has
f;j;i âˆ’f;i;j = Ï„k
ijf;k,
where Ï„ is the torsion tensor associated to âˆ‡(see Problem 5.2.14), and the
coordinate components are
Ï„k
ij = Î“k
ij âˆ’Î“k
ji.
(5.32)
If we repeat the exercise with a vector ï¬eld instead of a smooth function,
a new phenomenon appears.
Proposition 5.4.1. Let M be a smooth manifold equipped with an aï¬ƒne con-
nection âˆ‡. Let U be a coordinate patch on M, and let X be a vector ï¬eld
deï¬ned over U.
Then, in components, the mixed, covariant derivatives
satisfy
Xi
;k;j âˆ’Xi
;j;k = Ki
jklXl + Ï„m
jkXi
;m
where
Ki
jkl = âˆ‚Î“i
lk
âˆ‚xj âˆ’
âˆ‚Î“i
lj
âˆ‚xk + Î“i
hjÎ“h
lk âˆ’Î“i
hkÎ“h
lj.
(5.33)
Proof: This is a simple matter of calculation. Starting from Xi
;j = âˆ‚Xi/âˆ‚xj+
Î“i
ljXl, we obtain
Xi
;j;k =
âˆ‚
âˆ‚xk
âˆ‚Xi
âˆ‚xj + Î“i
ljXl
	
+ Î“i
mkXm
;j âˆ’Î“h
jkXi
;h
=
âˆ‚2Xi
âˆ‚xkâˆ‚xj +
âˆ‚Î“i
lj
âˆ‚xk Xl + Î“i
lj
âˆ‚Xl
âˆ‚xk
+ Î“i
mk
âˆ‚Xm
âˆ‚xj + Î“m
lj Xl
	
âˆ’Î“h
jk
âˆ‚Xi
âˆ‚xh + Î“i
lhXl
	
.
The result of the proposition follows after collecting and canceling like
terms in the resulting expression for Xi
;k;j âˆ’Xi
;j;k.
â–¡
We point out that some authors deï¬ne Ki
jkl as the negative of the
expression on the right-hand side of Equation (5.33) and some use the
indices of Ki
jkl in diï¬€erent orders (e.g., write K i
l jk for our Ki
jkl). In this
text, we have chosen, with other authors, to use this presentation in order
to be able to mesh this approach with the coordinate-free approach of the
curvature tensor.
We can check the following crucial result.

236
5. Introduction to Riemannian Geometry
Proposition 5.4.2. The collection of functions Ki
jkl deï¬ned in Equation (5.33)
form the components of a tensor of type (1, 3).
Proof: (This proposition relies on the coordinate-transformation properties
of the component functions Î“i
jk given in Proposition 5.2.5. The proof is
left as an exercise for the reader.)
â–¡
The functions Ki
jkl are the components of the so-called curvature tensor
associated to the connection âˆ‡.
The components of the curvature tensor came into play when we con-
sidered the mixed, covariant, partial derivatives of a vector ï¬eld instead of
just a smooth function. One could then ask whether some new quantity
appears when one considers the mixed covariant partials of other tensors.
Surprisingly, the answer is no.
Theorem 5.4.3 (Ricciâ€™s Identities). Let T i1Â·Â·Â·ir
j1Â·Â·Â·js be the components of a tensor
ï¬eld of type (r, s) over a coordinate patch of a manifold equipped with a
connection âˆ‡. Then the mixed, covariant, partial derivatives diï¬€er by
T i1Â·Â·Â·ir
j1Â·Â·Â·js;k;h âˆ’T i1Â·Â·Â·ir
j1Â·Â·Â·js;h;k =
r

Î±=1
KiÎ±
hkmT i1Â·Â·Â·iÎ±âˆ’1miÎ±+1Â·Â·Â·ir
j1Â·Â·Â·js
âˆ’
s

Î²=1
Km
hkjÎ²T i1Â·Â·Â·ir
j1Â·Â·Â·jÎ²âˆ’1mjÎ²+1Â·Â·Â·js + Ï„m
hk T i1Â·Â·Â·ir
j1Â·Â·Â·js;m.
Over the coordinate patch U, the components of the curvature tensor
satisfy the Bianchi identities.
Proposition 5.4.4 (Bianchi Identities). With Ki
jkl deï¬ned as in (5.33) and Ï„ i
jk
deï¬ned as in Equation (5.32), then
Ki
jkl + Ki
klj + Ki
ljk = âˆ’Ï„i
jk;l âˆ’Ï„i
kl;j âˆ’Ï„i
lj;k âˆ’Ï„i
jm Ï„ m
kl âˆ’Ï„i
km Ï„ m
lj âˆ’Ï„i
lm Ï„ m
jk
and
Ki
jkl;h + Ki
jlh;k + Ki
jhk;l = âˆ’Ï„m
kl Ki
jmh âˆ’Ï„m
lh Ki
jmk âˆ’Ï„m
hk Ki
jml.
The second Bianchi identity is also called the diï¬€erential Bianchi identity.
Proof: (Left as an exercise for the reader.)
â–¡
In particular, if âˆ‡is a symmetric connection, the Bianchi identities
reduce to
ï¬rst identity:
Ki
jkl + Ki
klj + Ki
ljk = 0,
second identity:
Ki
jkl;h + Ki
jlh;k + Ki
jhk;l = 0.

5.4. The Curvature Tensor
237
Now if (M, g) is a Riemannian manifold and âˆ‡is the Levi-Civita con-
nection associated to g, then since âˆ‡is symmetric, the torsion tensor Ï„ is
identically 0 and the components of the curvature tensor are denoted by
Ri
jkl. This notation emphasizes the context of Riemannian manifold and
the use of the Levi-Civita connection.
By contracting with the metric tensor g, one obtains the components
of a tensor of type (0, 4) by writing
Rjklm = gimRi
jkl,
(5.34)
which one refers to as the Riemann (or covariant) curvature tensor. Not
all the components of Ri
jkl or of Rjklm are independent. We wish to de-
termine the number of independent component functions in Rjklm, which
by Equation (5.34) is also the number of independent component functions
of Ri
jkl.
By the deï¬nition from Equation (5.33), we see that Ri
jkl = âˆ’Ri
kjl and,
therefore, that
Rjklm = âˆ’Rkjlm.
(5.35)
Furthermore, the ï¬rst Bianchi identity gives
Rjklm + Rkljm + Rljkm = 0.
(5.36)
The compatibility condition of the Levi-Civita connection glm;k = 0 leads
to another relation. The fact that gij;k = 0 and Theorem 5.4.3 imply that
0 = âˆ’Rh
jklghm âˆ’Rh
jkmglh,
which is tantamount to
Rjklm = âˆ’Rjkml.
(5.37)
Equations (5.35) and (5.37) show that the covariant curvature tensor is
skew-symmetric in the ï¬rst two indices and also in the last two indices.
Furthermore, this skew-symmetry relation combined with the identity in
Equation (5.36) leads to
Rjklm = Rlmjk.
(5.38)
One can see this from
0 = Rjklm + Rkljm + Rljkm = âˆ’Rjkml âˆ’Rklmj + Rljkm
= Rkmjl + Rmjkl + Rlmkj + Rmklj + Rljkm
= 2Rkmjl âˆ’Rmjlk âˆ’Rlmjk + Rljkm
= 2Rkmjl + Rjlmk + Rljkm = 2Rkmjl âˆ’2Rjlkm.
Hence, Rkmjl = Rjlkm and relabeling the indices gives Equation (5.38).

238
5. Introduction to Riemannian Geometry
We now count the number of independent functions given the relations
in Equations (5.35), (5.36), and (5.37). There are ï¬ve separate cases de-
pending on how many indices are distinct. By virtue of Equation (5.35),
the cases when all indices are equal or when three of the indices are equal
lead to identically 0 functions for the components of the covariant tensor. If
there are two pairs of equal indices, then we must have Riijj = 0 while the
quantities Rijij could be nonzero. In this case, the identities in Equations
(5.35), (5.36), and (5.38) explicitly determine all other possibilities with
two pairs of equation indices from Rijij. There are
n
2

ways to select the
pair {i, j} to deï¬ne Rijij. If the indices have one pair of equal indices and
the other two indices are diï¬€erent, then by Equations (5.35) and (5.37), the
only nonzero possibilities can be determined by Rijik (where i, j, and k
are all distinct). Hence, there are n
nâˆ’1
2

choices of independent functions
here. Lastly, suppose that all four indices are distinct. All the functions
for combinations of indices can be obtained from the relations, given the
functions for Rijkl and Riljk. Thus, there are 2
n
4

independent functions
in this case. In total, the covariant curvature tensor is determined by
n
2
	
+ n
n âˆ’1
2
	
+ 2
n
4
	
= 1
12n2(n2 âˆ’1)
independent functions.
It is interesting to note that for manifolds of dimension n = 2, there
is only one independent function in the curvature tensor, namely, R1212.
Equation (7.47) in [5] shows that the Gaussian curvature of the surface at
any point is equal to K = R1212/ det(gij). From this, we also ï¬nd that

R1
121
R1
122
R2
121
R2
122

= R1212
g21
âˆ’g11
g22
âˆ’g12
	
,
which gives the formula K = det(Ri
12j) for the Gaussian curvature of a
surface.
5.4.2
Coordinate-Free
A second and more modern approach to curvature on a Riemannian man-
ifold (M, g) deï¬nes the curvature tensor in a coordinate-free way, though
still from a perspective of analyzing repeated covariant diï¬€erentiation. If
X, Y , and Z are vector ï¬elds on M, the diï¬€erence in repeated covariant
derivatives is
âˆ‡Xâˆ‡Y Z âˆ’âˆ‡Y âˆ‡XZ.
(5.39)

5.4. The Curvature Tensor
239
Even with general vector ï¬elds in Rn, Equation (5.39) does not necessarily
cancel out. However, by Problem 5.2.6, for vector ï¬elds in Rn, âˆ‡Xâˆ‡Y Z =
X(Y (Zk))âˆ‚k, so
âˆ‡Xâˆ‡Y Z âˆ’âˆ‡Y âˆ‡XZ = âˆ‡[X,Y ]Z.
(5.40)
Since the Levi-Civita connection is uniquely determined by the Riemannian
metric, Equation (5.40) holds for any manifold that is locally isometric to
Rn. Therefore, the condition in Equation (5.40) holds for ï¬‚at manifolds
and, since âˆ‡XZ is not necessarily as simple for other manifolds, it might
not hold for manifolds not locally isometric to Rn. This motivates deï¬ning
the quantity
R(X, Y )Z
def
= âˆ‡Xâˆ‡Y Z âˆ’âˆ‡Y âˆ‡XZ âˆ’âˆ‡[X,Y ]Z.
(5.41)
The notation R(X, Y )Z emphasizes the understanding that for each vec-
tor ï¬eld X and Y , R(X, Y ) is an operator acting on Z. At ï¬rst glance,
R(X, Y )Z is just a smooth mapping X(M) Ã— X(M) Ã— X(M) â†’X(M),
smooth because the resulting vector ï¬eld is smooth.
However, more is
true.
Proposition 5.4.5. The function R(X, Y )Z deï¬ned in Equation (5.41) is a
tensor ï¬eld of type (1, 3), which is antisymmetric in X and Y .
Proof: The antisymmetry property follows immediately from [Y, X] =
âˆ’[X, Y ] and Deï¬nition 5.2.1.
To prove the tensorial property, we need
only to show that R(X, Y )Z is multilinear over Câˆ(M) in each of the
three vector ï¬elds. We show linearity for the X variable, from which lin-
earity immediately follows for the Y variable. We leave it as an exercise
for the reader to prove linearity in Z.
Let f1, f2 âˆˆCâˆ(M). Then
R(f1X1 + f2X2, Y )Z = (f1âˆ‡X1 + f2âˆ‡X2)âˆ‡Y Z
âˆ’âˆ‡Y (f1âˆ‡X1 + f2âˆ‡X2)Z âˆ’âˆ‡[f1X1,Y ]+[f2X2,Y ]Z.
By Proposition 4.2.12(4), [fiXi, Y ] = fi[Xi, Y ] âˆ’Y (fi)Xi. Thus,
R(f1X1 + f2X2, Y )Z
= f1âˆ‡X1âˆ‡Y Z + f2âˆ‡X2âˆ‡Y Z âˆ’f1âˆ‡Y âˆ‡X1Z âˆ’Y (f1)âˆ‡X1Z âˆ’f2âˆ‡Y âˆ‡X2Z
âˆ’Y (f2)âˆ‡X2Z âˆ’âˆ‡f1[X1,Y ]âˆ’Y (f1)X1Z âˆ’âˆ‡f2[X2,Y ]âˆ’Y (f2)X2Z
= f1âˆ‡X1âˆ‡Y Z âˆ’f1âˆ‡Y âˆ‡X1Z âˆ’f1âˆ‡[X1,Y ] + f2âˆ‡X2âˆ‡Y Z âˆ’f2âˆ‡Y âˆ‡X2Z
âˆ’f2âˆ‡[X2,Y ] âˆ’Y (f1)âˆ‡X1Z âˆ’Y (f2)âˆ‡X2Z + Y (f1)âˆ‡X1Z + Y (f2)âˆ‡X2Z
= f1R(X1, Y )Z + f2R(X2, Y )Z.
â–¡

240
5. Introduction to Riemannian Geometry
Deï¬nition 5.4.6. The tensor ï¬eld R is called the curvature tensor.
We connect this approach to the coordinate-dependent Deï¬nition 5.33
as follows. Let x be a coordinate system on a coordinate patch of M. By
the Câˆ(M)-linearity,
R(X, Y )Z = XiY jZk R(âˆ‚i, âˆ‚j)âˆ‚k,
where X = Xiâˆ‚i and similarly for Y and Z. The components of R in local
coordinates are Rl
ijk, where
R
 âˆ‚
âˆ‚xi , âˆ‚
âˆ‚xj
	
âˆ‚
âˆ‚xk = Rl
ijk
âˆ‚
âˆ‚xl .
Now since [âˆ‚i, âˆ‚j] = 0,
R(âˆ‚i, âˆ‚j)âˆ‚k = âˆ‡âˆ‚iâˆ‡âˆ‚jâˆ‚k âˆ’âˆ‡âˆ‚jâˆ‡âˆ‚iâˆ‚k
= âˆ‡âˆ‚i

Î“h
jkâˆ‚h

âˆ’âˆ‡âˆ‚j

Î“h
ikâˆ‚h

= Î“h
jkâˆ‡âˆ‚iâˆ‚h +
âˆ‚Î“h
jk
âˆ‚xi âˆ‚h âˆ’Î“h
ikâˆ‡âˆ‚jâˆ‚h âˆ’âˆ‚Î“h
ik
âˆ‚xj âˆ‚h
=

Î“h
jkÎ“l
ih âˆ’Î“h
ikÎ“l
jh +
âˆ‚Î“l
jk
âˆ‚xi âˆ’âˆ‚Î“l
ik
âˆ‚xj

âˆ‚l,
from which we obtain
Rl
ijk =
âˆ‚Î“l
jk
âˆ‚xi âˆ’âˆ‚Î“l
ik
âˆ‚xj + Î“h
jkÎ“l
ih âˆ’Î“h
ikÎ“l
jh,
which recovers exactly the coordinate-dependent Deï¬nition 5.33.
We deï¬ne also the Riemann (or covariant) curvature tensor Rm = Râ™­
in a coordinate-free way by
Rm(X, Y, Z, W) = âŸ¨R(X, Y )Z, WâŸ©
where âŸ¨, âŸ©is the Riemannian metric on M. One can easily check that in
a coordinate system, the components of the tensor Rm are precisely the
collection of functions Rjklm deï¬ned in Equation (5.34).
The properties of the Riemann curvature tensor presented earlier in a
coordinate-dependent manner have equivalent expressions in a coordinate-
free formulation.
Proposition 5.4.7. The covariant curvature tensor Rm satisï¬es the following
symmetry properties for vector ï¬elds X, Y , Z, W, and T :

5.4. The Curvature Tensor
241
1. Rm(X, Y, Z, W) = âˆ’R(Y, X, Z, W).
2. Rm(X, Y, Z, W) = âˆ’R(X, Y, W, Z).
3. Rm(X, Y, Z, W) = R(Z, W, X, Y ).
4. Bianchiâ€™s ï¬rst identity:
Rm(X, Y, Z, W) + Rm(Y, Z, X, W) + Rm(Z, X, Y, W) = 0.
5. Bianchiâ€™s diï¬€erential identity:
âˆ‡Rm(X, Y, Z, W, T )+âˆ‡Rm(X, Y, W, T, Z)+âˆ‡Rm(X, Y, T, Z, W)=0.
5.4.3
Geometric Interpretation
Until now, we have not given an interpretation for the geometric meaning
of the curvature or torsion tensors.
Consider ï¬rst the torsion tensor. (Of course, by deï¬nition, the Levi-
Civita connection is symmetric and so the torsion is 0, but we give an
interpretation for any aï¬ƒne connection.) We will use a ï¬rst-order approx-
imation discussion, following the presentation in [42, Section 7.3.2]. This
reasoning diï¬€ers slightly from a rigorous mathematical explanation, but we
include it for the sake of familiarity with physics-style reasoning.
Let p âˆˆM, with coordinates xÎ¼ in a coordinate system on M. Let
X = Î´Î¼âˆ‚Î¼ and Y = ÎµÎ¼âˆ‚Î¼ be two vectors in TpM. Let Î³X(t) be the curve
with coordinate functions Î´Î¼t and let Î³Y (t) be the curve with coordinate
functions ÎµÎ¼t. Consider the parallel transport of the vector X along Î³Y (t).
The coordinates of the resulting vector are Î´Î¼ + Î“Î¼
Î»Î½Î´Î»ÎµÎ½. The coordinates
of pâ€², the tip of the parallel transport of X, are
pâ€² :
Î´Î¼ + ÎµÎ¼ + Î“Î¼
Î»Î½Î´Î»ÎµÎ½
If we take the parallel transport of Y along Î³X(t), the coordinates of the
resulting vector are ÎµÎ¼ + Î“Î¼
Î»Î½ÎµÎ»Î´Î½. The coordinates of pâ€²â€², the tip of the
parallel transport of Y , are
pâ€²â€² :
Î´Î¼ + ÎµÎ¼ + Î“Î¼
Î»Î½ÎµÎ»Î´Î½.
The diï¬€erence between these two parallel transports is
(Î“Î¼
Î»Î½ âˆ’Î“Î¼
Î½Î»)Î´Î»ÎµÎ½,

242
5. Introduction to Riemannian Geometry
p
Î³X
Î³Y
(xÎ¼)
(xÎ¼ + Î´Î¼)
(xÎ¼ + ÎµÎ¼)
X
Y
pâ€²â€²
pâ€²
Figure 5.10. Geometric interpretation of the tor-
sion tensor.
p
q (xÎ¼ + Î´Î¼)
r (xÎ¼ + ÎµÎ¼)
s (xÎ¼ + Î´Î¼ + ÎµÎ¼)
Z
Aâ€²â€²Z
Aâ€²Z
Figure 5.11. Geometric interpretation of the cur-
vature tensor.
which is Ï„ Î¼
Î»Î½Î´Î»ÎµÎ½. Therefore, intuitively speaking, the torsion tensor gives a
local measure of how much parallel transport of two noncollinear directions
with respect to each other fails to close a parallelogram (see Figure 5.10).
The curvature tensor, on the other hand, measures the path dependence
of parallel transport.
In the coordinate-free deï¬nition of the curvature
tensor from Equation (5.41), the expression âˆ‡Xâˆ‡Y Z is a vector ï¬eld that
measures the rate of change of parallel transport of the vector ï¬eld Z along
an integral curve of Y and then a rate of change of parallel transport of
this âˆ‡Y Z along an integral curve of X. The expression âˆ‡Y âˆ‡XZ reverses
the process.
Now, as discussed in Section 4.2 in the subsection on Lie
brackets (see also Figure 4.3), the successive ï¬‚ows of a distance h along
the integral curves of Y and then along the integral curves of X do not in
general lead one to the same point if one follows the integral curves of X
and then of Y . Proposition 4.2.13 shows that [X, Y ] is a sort of measure
for this nonclosure of integral paths in vector ï¬elds. Subtracting âˆ‡[X,Y ]Z
from âˆ‡Xâˆ‡Y Z âˆ’âˆ‡Y âˆ‡XZ eliminates the quantity of path dependence of
parallel transport on a manifold that is naturally caused by the nonclosure
of â€œsquareâ€ paths of integral curves in vector ï¬elds.
Another perspective is to consider a vector Z based at p with coordi-
nates xÎ¼ and look at the path dependence of the parallel transport along
two sides of a â€œparallelogramâ€ based at p and spanned by directions Î´Î¼ and
ÎµÎ¼. Locally, i.e., when Î´Î¼ and ÎµÎ¼ are small, the parallel transport of Z from
p to q = (xÎ¼ + Î´Î¼) to s = (xÎ¼ + Î´Î¼ + ÎµÎ¼) produces a vector Aâ€²Z. Similarly,
the parallel transport of Z from p to r = (xÎ¼ + ÎµÎ¼) to s = (xÎ¼ + Î´Î¼ + ÎµÎ¼)
produces a vector Aâ€²â€²Z (see Figure 5.11). The diï¬€erence Z â†’Aâ€²â€²Z âˆ’Aâ€²Z is

5.4. The Curvature Tensor
243
a linear transformation deï¬ned locally at p that depends on the directions
Î´Î¼ and ÎµÎ¼. In fact, it is not hard to show that, in coordinates,
(Aâ€²â€²Z âˆ’Aâ€²Z)i = Ri
jklÎ´jÎµkZl.
5.4.4
The Ricci Curvature Tensor and the Einstein Tensor
Since tensors of order 4 are so unwieldy, there are a few common ways to
summarize some of the information contained in the curvature tensor.
One of the most common constructions is the Ricci curvature tensor,
denoted by Ric or Rc. Since it is so common in the literature, one writes
Rij instead of Ricij for the components of this tensor with respect to a
coordinate system. In coordinates, the components are deï¬ned by
Rij = Rk
kij = gkmRkijm.
By the symmetries of the curvature tensor, Rij can be expressed equiva-
lently as
Rij = Rk
kij = âˆ’Rk
ikj = âˆ’gkmRikjm = âˆ’gkmRjmki.
Proposition 5.4.8. The Ricci tensor Ric is symmetric.
Proof: We prove this still within the context of a coordinate system.
Since Rij = Rk
kij, we can write
Rij = âˆ‚Î“k
ij
âˆ‚xk âˆ’
âˆ‚Î“k
kj
âˆ‚xi + Î“h
ijÎ“k
kh âˆ’Î“h
kjÎ“k
ih.
(5.42)
In this expression, since the connection is symmetric, the ï¬rst and third
terms of the right-hand side are obviously symmetric in i and j. The fourth
term Î“h
kjÎ“k
ih is also symmetric in i and j by a relabeling of the summation
variables h and k. Surprisingly, the second term in Equation (5.42) is also
symmetric.
By Problem 5.2.19,
âˆ‚(ln âˆšdet g)
âˆ‚xj
= Î“k
jk.
Thus,
âˆ‚Î“k
jk
âˆ‚xi =
âˆ‚2
âˆ‚xiâˆ‚xj (ln

det g) =
âˆ‚2
âˆ‚xjâˆ‚xi (ln

det g) = âˆ‚Î“k
ik
âˆ‚xj .
Hence, all the terms in Equation (5.42) are symmetric in i and j, so Rij =
Rji and the result follows.
â–¡

244
5. Introduction to Riemannian Geometry
The scalar curvature function R is deï¬ned as the trace of the Ricci
tensor with respect to g, i.e.,
S = Trg Ric = gijRij.
(5.43)
(Sometimes, texts use the letter R to denote the scalar curvature, but we
have opted for the other common notation of S so as not to be confused
with the curvature tensor symbol.)
The scalar curvature allows one to
deï¬ne the Einstein tensor, which is of fundamental importance.
Deï¬nition 5.4.9. On any Riemannian manifold (M, g) the Einstein tensor
G is the tensor of type (0, 2) described in coordinates by
GÎ»Î¼ = RÎ»Î¼ âˆ’1
2gÎ»Î¼S,
where S is the scalar curvature.
As we will see in Section 6.4, the Einstein tensor is of central importance
in general relativity. For the moment, we prove the important result about
its divergence (see Problems 5.1.10 and 5.2.16).
Proposition 5.4.10. Let G be the Einstein tensor on a Riemannian manifold.
Then, using the deï¬nition of divergence in Equation (5.23),
div G = 0.
In coordinates, this reads GÎ½
Î»;Î½ = (gÎ½Î¼GÎ»Î¼);Î½ = gÎ¼Î½GÎ¼Î»;Î½ = 0.
Proof: The proof of this proposition follows from the diï¬€erential Bianchi
identity. For the Riemann curvature tensor, by Proposition 5.4.7(5), we
have
Rjklm;h + Rjkmh;l + Rjkhl;m = 0.
Taking the trace with respect to g over the variable pair (j, m),
Rkl;h âˆ’Rkh;l + gjmRjkhl;m = 0,
where the trace operator commutes with the covariant derivative because
of the compatibility condition of the Levi-Civita connection. Multiplying
by gkl and contracting gives
S;h âˆ’gklRhk;l âˆ’gjmRjh;m = 0.

5.4. The Curvature Tensor
245
Relabeling summation indices and using the symmetry of g (or Ric), we
deduce that
S;h âˆ’2gklRhk;l = 0.
(5.44)
But GÎ½
Î» = gÎ½Î¼RÎ»Î¼ âˆ’1
2Î´Î½
Î»R, so
GÎ½
Î»;Î½ = gÎ½Î¼RÎ»Î¼;Î½ âˆ’1
2Î´Î½
Î»S;Î½ = gÎ½Î¼RÎ»Î¼;Î½ âˆ’1
2S;Î»,
and the vanishing divergence follows from Equation (5.44). The last claim
in the proposition follows from Problem 5.2.16.
â–¡
Of particular interest in Riemannian geometry and in general relativ-
ity are manifolds in which the Ricci curvature is proportional to the metric
tensor. The corresponding metric is called an Einstein metric and the man-
ifold is called an Einstein space. More precisely, a Riemannian manifold
(M, g) has an Einstein metric if
Ric = Î»g
(5.45)
for some smooth function Î» : M â†’R. Taking the trace with respect to
g of Equation (5.45) and noting that Trg g = dim M, we ï¬nd that Î» must
satisfy
Î» =
R
dim M .
Proposition 5.4.11. If (M, g) is an Einstein space of dimension dim M â‰¥3,
then the scalar curvature is constant on each connected component of M.
Proof: (Left as an exercise for the reader.)
â–¡
In part because of Proposition 5.4.11, Einstein metrics continue to re-
main an active area of research not only because of their applications to
physics but more so because of their application to possible classiï¬cation
theorems for diï¬€eomorphic manifolds. The Uniformization Theorem, a fun-
damental result in the theory of surfaces, establishes that every connected
2-manifold admits a Riemannian metric with constant Gaussian curvature.
This in turn leads to a classiï¬cation of diï¬€eomorphism classes for surfaces.
One could hope that, in parallel with surfaces, all connected higher-
dimensional manifolds (dim M > 2) would possess an Einstein metric that
would in turn lead to a classiï¬cation theorem of diï¬€eomorphism classes
of manifolds. This turns out not to be the case. There do exist higher-
dimensional compact manifolds that admit no Einstein metric [8]. Never-
theless, in attempts to reach a generalization to the Uniformization Theo-
rem for higher-dimensional manifolds, Einstein metrics play a vital role.

246
5. Introduction to Riemannian Geometry
Problems
5.4.1. Calculate the 16 component functions of the curvature tensor for the
sphere S2 in the standard (Î¸, Ï†) coordinate system.
5.4.2. Prove Proposition 5.4.2.
5.4.3.
(a) Prove the ï¬rst Bianchi identity in Proposition 5.4.4 using a coordinate-
dependent approach.
(b) Prove the ï¬rst Bianchi identity in Proposition 5.4.7 using a coordinate-
free approach.
5.4.4.
(a) Prove the second (diï¬€erential) Bianchi identity in Proposition 5.4.4
using a coordinate-dependent approach.
(b) Prove the second (diï¬€erential) Bianchi identity in Proposition 5.4.7
using a coordinate-free approach. [Hint: This can be long and tedious
if done directly. Instead, since âˆ‡Rm is Câˆ(M)-multilinear, choose
X, Y, Z, W, T to be coordinate basis vector ï¬elds. Also, to make the
computations even easier, use the normal coordinate system.]
5.4.5. Prove that the quantity R(X, Y )Z deï¬ned in Equation (5.41) is Câˆ(M)-
linear in the Z variable.
5.4.6. A smooth family of smooth curves is a function c : (âˆ’Îµ, Îµ) Ã— [a, b] â†’M
such that cs(t) = c(s, t) is a smooth curve in M for each s âˆˆ(âˆ’Îµ, Îµ).
Note that by symmetry, ct(s) is also a smooth curve for each t âˆˆ[a, b]. A
vector ï¬eld along c is a smooth map V : (âˆ’Îµ, Îµ) Ã— [a, b] â†’TM such that
V (s, t) âˆˆTc(s,t)M for each (s, t). Deï¬ne the vector ï¬elds S and T on c by
S = âˆ‚sc and âˆ‚tc, i.e., the tangent vectors to c in the indicated direction.
Show that for any vector ï¬eld V on c,
DsDtV âˆ’DtDs = R(S, T)V.
(This gives another geometric interpretation of the curvature tensor.)
5.4.7. The Jacobi Equation. This exercise considers variations along a geodesic Î³.
A variation through geodesics along Î³ is a smooth family of smooth curves
c (deï¬ned in Problem 5.4.6) such that for each s, the curve cs(t) = c(s, t) is
a geodesic and c(0, t) = Î³(t). The variation ï¬eld V of a variation through
geodesics along Î³ is the vector ï¬eld along Î³ deï¬ned by V (t) = (âˆ‚sc)(0, t).
Show that V satisï¬es the Jacobi equation
D2
t V + R(V, Ë™Î³)Ë™Î³ = 0.
5.4.8. Consider the 3-sphere S3, and consider the coordinate patch given by
the parametrization described in Problem 5.1.11. Calculate the curvature
tensor, the Ricci curvature tensor, and the scalar curvature.
5.4.9. Calculate the curvature tensor, the Ricci curvature tensor, and the scalar
curvature for the PoincarÂ´e ball. (See Problem 5.1.9.)
5.4.10. Consider the 3-torus described in Problem 5.1.1(b) with the metric induced
from R4. Calculate all the components of the curvature tensor, the Ricci
tensor, and the scalar curvature, given in the coordinates deï¬ned by the
parametrization given in Problem 5.1.1(b).

5.4. The Curvature Tensor
247
5.4.11. Consider the metric associated to spherical coordinates in R3, given by
g = dr2 + r2 sin2 Ï†dÎ¸2 + r2dÏ†2.
(Note, we have used the mathematics labeling of the longitude and latitude
angles. Physics texts usually have the Î¸ and Ï† reversed.) Prove that all
the components of the curvature tensor are identically 0.
5.4.12. The Schwarzschild metric has the tensor
g = âˆ’

1 âˆ’2M
r
	
dt2 +
1
1 âˆ’2M
r
dr2 + r2 sin2 Ï†dÎ¸2 + r2dÏ†2.
where 0 < 2M < r. Calculate the curvature tensor, the Ricci tensor and
the scalar curvature. (According to general relativity, the Schwarzschild
metric describes how spacetime curves in the presence of a sphere of mass
M.)
5.4.13. Consider the Riemannian manifold of dimension 2 equipped with the met-
ric g = f(u + v)(du2 + dv2) for some function f. Solve for which f lead to
Rjklm = 0.
5.4.14. Let R be the Riemann curvature tensor (deï¬ned with respect to the Levi-
Civita connection). Prove that
Rijkl =1
2
 âˆ‚2gik
âˆ‚xjâˆ‚xl âˆ’âˆ‚2gjk
âˆ‚xiâˆ‚xl âˆ’
âˆ‚2gil
âˆ‚xjâˆ‚xk +
âˆ‚2gjl
âˆ‚xiâˆ‚xk
	
+ gÎ»Î¼

Î“Î»
ikÎ“Î¼
jl âˆ’Î“Î»
ilÎ“Î¼
jk

.
Conclude that in normal coordinates centered at p, the following holds
at p:
Rijkl = 1
2(âˆ‚jâˆ‚lgik âˆ’âˆ‚iâˆ‚lgjk âˆ’âˆ‚jâˆ‚kgil + âˆ‚iâˆ‚kgjl).
5.4.15. The Killing Equation. Let (M, g) be a Riemannian manifold and let X âˆˆ
X(M). Consider the function fÎµ : M â†’M deï¬ned by
fÎµ(p) = Î³(Îµ)
where Î³ is the integral curve of X through p. Thus, the linear approx-
imation of fÎµ for small Îµ maps p = (xi) to the point with coordinates
xi + ÎµXi(p). Suppose that fÎµ is an isometry for inï¬nitesimal Îµ.
(a) Use a linear approximation in Îµ on the change-of-coordinates formula
for the metric g to show that g and X satisfy the Killing equation:
âˆ‚gij
âˆ‚xk Xk + âˆ‚Xl
âˆ‚xi glj + âˆ‚Xl
âˆ‚xj gil = 0.
(b) Let âˆ‡be the Levi-Civita connection. Show that the Killing equa-
tion is equivalent to the condition that (âˆ‡X)â™­is antisymmetric. In
components related to a coordinate system, this means that
Xi;j + Xj;i = 0,
(5.46)
where Xi = gikXk.

248
5. Introduction to Riemannian Geometry
5.4.16. Consider a covector ï¬eld Ï‰ on a Riemannian manifold (M, g). Suppose
that Ï‰ satisï¬es the covariant Killing equation (see Equation (5.46)), i.e.,
Ï‰i;j +Ï‰j;i = 0. Show that along any geodesic Î³(s) of M, Ï‰(Ë™Î³) is a nonzero
constant.
5.4.17. Suppose that on a Riemannian manifold (M, g), the curvature tensor sat-
isï¬es div R = 0, or in coordinates Ri
jkl;i = 0 for all j, k, l. Show that the
following also hold:
(a) Rij;h = Rih;j;
(b) S;j = 0;
(c) gmlRi
jklRmh + gmlRi
khlRmj + gmlRi
hjlRmk = 0.
5.4.18. Show that if Rijkl + Rljki = 0, then the covariant curvature tensor is
identically 0.
5.4.19. Prove Proposition 5.45. More precisely, show that R;h =0 when dim M â‰¥3.
5.4.20. Let Gi
j = gikGjk, where Gjk are the components of the Einstein tensor,
and deï¬ne Ril
jk = glmRi
jkm. Prove that
Gi
j = âˆ’1
4Î´iÎ½Îº
jÎ»Î¼RÎ»Î¼Î½Îº,
where we have used the generalized Kronecker symbol deï¬ned in Equa-
tion (2.29).
5.4.21. Consider a Lorentzian metric given by ds2 = âˆ’dt2 + f(t)2dx2, where f(t)
is any smooth function of t. Show that the Einstein tensor is identically 0.

CHAPTER
6
Applications of Manifolds
to Physics
In the previous chapters, we set forth the intuitive goal of doing calculus
on curved spaces as the motivating force behind the development of the
theory of manifolds. Having developed a theory of manifolds that satisï¬es
this goal, we now present four applications to physics that utilize this theory
to varying degrees. Each section shows just the tip of the iceberg on very
broad areas of active research.
Hamiltonian mechanics motivate the notion of symplectic manifolds,
which in turn lead to complex structures and KÂ¨ahler manifolds. Because of
their speciï¬c properties, symplectic geometry and KÂ¨ahler manifolds have
become quite signiï¬cant. Furthermore, it was the Hamiltonian formulation
of dynamics that lent itself best to quantization and hence to SchrÂ¨odingerâ€™s
equation in quantum mechanics.
A few exercises in this text have dealt with the theory of electromag-
netism. In Section 6.2, we gather together some of the results we have seen
in the theory of electromagnetism and rephrase them into the formalism of
a Lorentzian spacetime.
We also discuss a few geometric concepts underlying string theory. Be-
tween 1900 and 1940, physics took two large steps in opposite directions
of the size scale, with quantum mechanics describing the dynamics of the
very small scale and general relativity describing the very large scale. These
theories involve very diï¬€erent types of mathematics, which led physicists
to look for reformulations or generalizations that could subsume both theo-
ries. However, despite extensive work to ï¬nd a unifying theory, the task has
proven exceedingly diï¬ƒcult, even on mathematical grounds. String theory
is a model for the structure of elementary particles that currently holds
promise to provide such a uniï¬cation. We wish to mention string theory in
this book because, at its core, the relativistic dynamics of a string involve
a two-dimensional submanifold of a Minkowski space, an object that arises
nicely as an application of pseudo-Riemannian metrics.
249

250
6. Applications of Manifolds to Physics
Finally, Einsteinâ€™s theory of general relativity stands as a direct appli-
cation of Riemannian manifolds. In fact, general relativity motivated some
of the development and helped proliferate the notions of Riemannian (and
pseudo-Riemannian) geometry beyond the conï¬nes of pure mathematics.
Many of the â€œstrangeâ€ phenomena which ï¬ll the pages of popular books on
cosmology occur as consequences of the mathematics of this geometry.
This chapter assumes that the reader has some experience in physics
but no more than a ï¬rst college course (calculus-based) in mechanics. All
the other material will be introduced as needed. Furthermore, we do not
discuss issues of quantization as those exceed the scope of this book.
6.1
Hamiltonian Mechanics
6.1.1
Equations of Motion
The study of dynamics relies almost exclusively on Newtonâ€™s laws of motion,
in particular, his second law. This law states that the sum of exterior forces
on a particle or object is equal to the rate of change of momentum, i.e.,
 âƒ—Fext = dâƒ—p
dt ,
(6.1)
where âƒ—p = m dâƒ—x/dt and âƒ—x(t) is the position of the particle at time t. If m
is constant, Equation (6.1) reduces to
 âƒ—Fext = md2âƒ—x
dt2 .
(6.2)
Furthermore, by a simple calculation, Equation (6.1) directly implies the
following law of motion for angular momentum about an origin O:
dâƒ—L
dt =

âƒ—Ï„ext,
(6.3)
where âƒ—L = âƒ—r Ã— âƒ—p is the angular momentum of a particle or solid, where âƒ—r is
the position vector of the particle or center of mass of the solid, and where
"âƒ—Ï„ext is the sum of the torques about O. (Recall that the torque about
the origin of a force âƒ—F is Ï„ = âƒ—r Ã— âƒ—F.)
Though Equation (6.1) undergirds all of classical dynamics, the value
of ancillary equations, such as Equation (6.3), arises from the fact that
these other equations may elucidate conserved quantities or produce more
tractable equations when using diï¬€erent variables besides the Cartesian

6.1. Hamiltonian Mechanics
251
coordinates. For example, when describing the orbits of planets around
the sun, polar (cylindrical) coordinates are far better suited than Carte-
sian coordinates. In particular, as shown in Example 2.2.2, one ï¬nds that
the angular momentum is a conserved quantity for a particle under the
inï¬‚uence of forces that are radial about some origin.
It turns out that in many cases (in particular when the forces are con-
servative), either Equation (6.2) or Equation (6.3) follows from a speciï¬c
variational principle that has extensive consequences. Suppose that the
state of a physical system is described by a system of coordinates qk, with
k = 1, 2, . . ., n. Hamiltonâ€™s principle states that the motion of a system
evolves according to a path P parametrized by (q1(t), . . . , qn(t)) between
times t1 and t2 so as to minimize the integral
S =
%
P
L dt =
% t2
t1
L dt
where L is the Lagrangian function. The integral S is called the action of
the system. When the system is under the inï¬‚uence of only conservative
forces, the Lagrangian is L = T âˆ’V , where T is the kinetic energy and V
is the potential energy. Recall that for a conservative force âƒ—F, its potential
energy V , which is a function of the position variables alone, satisï¬es
âƒ—F = âˆ’âƒ—âˆ‡V = âˆ’gradV.
Intuitively speaking, in the case of conservative forces, Hamiltonâ€™s princi-
ple states that a system evolves in such a way as to minimize the total
variation between kinetic and potential energy. However, even if a force is
not conservative, it may still possess an associated Lagrangian that pro-
duces the appropriate equation of motion. (See Problem 6.1.8 for such an
example.)
We consider the Lagrangian L as an explicit function of t, the coordi-
nates qk, and their time derivatives Ë™qk = dqk/dt. According to Theorem
B.3.1, the Lagrangian must satisfy the Euler-Lagrange equation in each
coordinate qk, namely,
âˆ‚L
âˆ‚qk
âˆ’d
dt
 âˆ‚L
âˆ‚Ë™qk
	
= 0.
(6.4)
This is called Lagrangeâ€™s equations of motion. Though this system of equa-
tions moves away from the nice vector expression of Equation (6.2), it has
the distinct advantage of expressing equations of motion in a consistent
way for any choice of coordinates.

252
6. Applications of Manifolds to Physics
Î±
h
x
Figure 6.1. An round object rolling downhill.
Example 6.1.1. Consider a ball (or cylinder) of radius R rolling down a plane
inclined with angle Î±, as depicted in Figure 6.1. Because the object rolls
instead of sliding, the rotation about its center leads to an additional kinetic
energy amount of 1
2I Ë™Î¸2, where Ë™Î¸ is the rate of rotation about its center.
However, because there is no slipping, we deduce that Ë™x = R Ë™Î¸, where x is
the coordinate of the distance of the center of mass of the object up the
incline. Thus, the Lagrangian of this system is
L = 1
2I Ë™Î¸2 + 1
2mv2 âˆ’mgh,
L(x, Ë™x) =
I
2R2 I Ë™x2 + 1
2m Ë™x2 âˆ’mgx sin Î±.
The Euler-Lagrange Equation (6.4) gives
âˆ‚L
âˆ‚x âˆ’d
dt
âˆ‚L
âˆ‚Ë™x
	
= âˆ’mg sin Î± âˆ’(I/R2 + m)Â¨x = 0,
which leads to the equation of motion
d2x
dt2 = âˆ’g sin Î±
I
mR2 + 1,
a well-known result from classical mechanics.
Though Example 6.1.1 involves a variable x that is essentially taken
from R, physical systems in general may typically be described by other
types of variables. When studying the motion of a simple pendulum (see
Figure 6.2(a)), one uses as a variable the angle Î¸ of deviation of the pen-
dulum from the vertical. A system that is a double pendulum (see Fig-
ure 6.2(b)) involves two angles.
If a physical system can be described by using n locally independent
variables, then we say the system has n degrees of freedom. The set of

6.1. Hamiltonian Mechanics
253
Î¸
(a) Simple pendulum
Î¸1
Î¸2
(b) Double pendulum
Figure 6.2. Simple and compound pendulum.
all possible states of a physical system is a real manifold Q of dimension
n, called the conï¬guration space of the system. The variables (qk) that
locate a point on (a coordinate chart of) the manifold Q are called the
position variables. (Note, we will use the subscript indices for the position
variables to conform with physics texts and literature on symplectic mani-
folds, though one should remember at this stage that they are contravariant
quantities.) For example, the conï¬guration space of the system in Exam-
ple 6.1.1 is simply Q = R, while the conï¬guration space for the simple
pendulum is Q = S1 and the conï¬guration space of the double pendulum
is the torus Q = S1 Ã— S1.
The time development of a system corresponds to a curve Î³ : t â†’
(qk(t)) on the manifold, and the functions Ë™q1, . . . , Ë™qn are the coordinates of
a tangent vector along Î³ in the tangent space T Q.
Now the Euler-Lagrange Equation (6.4) is a system of second-order,
ordinary, diï¬€erential equations. We would like to change this into a system
of ï¬rst-order diï¬€erential equations for two reasons: (1) many theorems on
diï¬€erential equations are stated for systems of ï¬rst-order equations and
(2) it is easier to discuss ï¬rst-order equations in the context of manifolds.
We do this in the following way.
Deï¬ne the generalized momenta functionally by
pk = âˆ‚L
âˆ‚Ë™qk
.
(6.5)
The quantities pk are the components of the momentum vector, which is
in fact an element of TÎ³(t)Qâˆ—. We can see this as follows. Let W be an
n-dimensional vector space, and let f : W â†’R be any diï¬€erentiable func-
tion. Then the diï¬€erential dfâƒ—v at a point âƒ—v âˆˆW is a linear transformation

254
6. Applications of Manifolds to Physics
dfâƒ—v : W â†’R. Thus, by deï¬nition of the dual space, dfâƒ—v âˆˆW âˆ—. Conse-
quently, the diï¬€erential df gives a correspondence df : W â†’W âˆ—via
âƒ—v âˆ’â†’dfâƒ—v =
n

i=1
âˆ‚f
âˆ‚xi

âƒ—v
dxi.
Taking W as the vector space TÎ³(t)Q, the momentum at the point Î³(t) is
the vector dL( Ë™qk) âˆˆTÎ³(t)Qâˆ—. Hence, we can think of the momentum vector
p as a covector ï¬eld along the curve Î³ given at each point by dL( Ë™qk).
Consider now the Hamiltonian function H deï¬ned by
H =
n

k=1
pk Ë™qk âˆ’L(q1, . . . , qn, Ë™q1, . . . , Ë™qn, t).
Since we can write the quantity Ë™qk in terms of the components pk, we can
view the Hamiltonian as a time-dependent function on T Qâˆ—. Given any
conï¬guration space Q, we deï¬ne the cotangent bundle T Qâˆ—as the phase
space of the system. If Q is an n-dimensional manifold, then T Qâˆ—is a
manifold of dimension 2n.
The variables Ë™qi are now functions of the independent variables (t, q1, . . . ,
qn, p1, . . . , pn). Taking derivatives of H, we ï¬nd that
âˆ‚H
âˆ‚pi
= Ë™qi +
n

k=1
pk
âˆ‚Ë™qk
âˆ‚pi
âˆ’
n

k=1
âˆ‚L
âˆ‚Ë™qk
âˆ‚Ë™qk
âˆ‚pi
= Ë™qi +
n

k=1

pk âˆ’âˆ‚L
âˆ‚Ë™qk
	 âˆ‚Ë™qk
âˆ‚pi
= Ë™qi,
where each term of the summation is 0 by deï¬nition of pk. Furthermore,
note that Lagrangeâ€™s equation reduces to âˆ‚L/âˆ‚qi = Ë™pi. Thus, taking deriva-
tives with respect to qi, we get
âˆ‚H
âˆ‚qi
=
n

k=1
pk
âˆ‚Ë™qk
âˆ‚qi
âˆ’

âˆ‚L
âˆ‚qi
+
n

k=1
âˆ‚L
âˆ‚Ë™qk
âˆ‚Ë™qk
âˆ‚qi

= âˆ’âˆ‚L
âˆ‚qi
+
n

k=1

pk âˆ’âˆ‚L
âˆ‚Ë™qk
	 âˆ‚Ë™qk
âˆ‚qi
= âˆ’âˆ‚L
âˆ‚qi
= âˆ’Ë™pi.

6.1. Hamiltonian Mechanics
255
Therefore, given the deï¬nition in Equation (6.5), the Euler-Lagrange Equa-
tion (6.4) is equivalent to
Ë™qk = âˆ‚H
âˆ‚pk
,
Ë™pk = âˆ’âˆ‚H
âˆ‚qk
.
(6.6)
This system of equations is called Hamiltonâ€™s equations of motion. They
consist of 2n ï¬rst-order, ordinary, diï¬€erential equations in n unknown 2n
functions, whereas Lagrangeâ€™s equations of motion consisted of n second-
order, ordinary, diï¬€erential equations in n unknown functions.
For simple dynamic systems, the kinetic energy T is a homogeneous
quadratic function in the variables Ë™qk. If this is the case, then it is not
hard to show that
n

k=1
Ë™qkpk = 2T,
where T is the kinetic energy. If in addition, the forces acting on the system
are conservative, then
H = 2T âˆ’(T âˆ’V ) = T + V,
which is the total energy of the system.
6.1.2
Symplectic Manifolds
We now introduce the notion of a symplectic manifold and show how Hamil-
tonâ€™s equations of motion arise naturally in this context. The theory of
symplectic geometry is a branch of geometry in and of itself so we do not
pretend to cover it extensively here. Instead, we refer the reader to [7]
or [1] for a more thorough introduction.
Deï¬nition 6.1.2. Let W be a vector space over a ï¬eld K. A symplectic form
is a bilinear form
Ï‰ : V Ã— V â†’K;
that is,
1. antisymmetric: Ï‰(v, v) = 0 for all v âˆˆW;
2. nondegenerate: if Ï‰(v, w) = 0 for all w âˆˆW, then v = 0.
The pair (V, Ï‰) is called a symplectic vector space.

256
6. Applications of Manifolds to Physics
Proposition 6.1.3. Let (V, Ï‰) be a ï¬nite-dimensional, symplectic vector space.
There exists a basis B of V relative to which the matrix of Ï‰ is
[Ï‰]B =
 0
In
âˆ’In
0
	
.
where In is the n Ã— n identity matrix. In addition, V has even dimension.
Proof: (Left as an exercise for the reader. See Problem 6.1.3.)
â–¡
Since the form Ï‰ is antisymmetric and bilinear, then Ï‰ âˆˆ12 V . Suppose
that V has a basis B = {e1, . . . , e2n}, and let Bâˆ—= {eâˆ—
1, . . . , eâˆ—
2n} be the
associated dual basis (see Section C.3). Then in coordinates, we can write
Ï‰ as
Ï‰ =

1â‰¤i<jâ‰¤2n
Ï‰ijeâˆ—
i âˆ§eâˆ—
j.
However, from Proposition 6.1.3 follows immediately a nice corollary.
Corollary 6.1.4. Let (V, Ï‰) be a symplectic vector space of dimension 2n.
Then there exists a basis B = {e1, . . . , e2n} such that Ï‰ can be written as
Ï‰ =
n

i=1
eâˆ—
i âˆ§eâˆ—
n+i.
The expression in Corollary 6.1.4 is called the canonical form of the
symplectic form Ï‰.
Deï¬nition 6.1.5. A symplectic manifold (M, Ï‰) is a smooth manifold M
equipped with a 2-form Ï‰ that is closed (dÏ‰ = 0) and nondegenerate. In
other words, M is a smooth manifold such that for each P âˆˆM, TP M is a
symplectic vector space with symplectic form Ï‰P and Ï‰P varies smoothly
with P.
By Proposition 6.1.3, one sees that a symplectic manifold has even
dimension.
Deï¬nition 6.1.6. If (M, Ï‰) and ( Ëœ
M, ËœÏ‰) are two symplectic manifolds, then a
smooth map F : M â†’Ëœ
M is called symplectic if
F âˆ—ËœÏ‰ = Ï‰.
We say that F preserves the symplectic structure. If in addition, F âˆ’1 is
also a smooth symplectic map, then F is called a symplectomorphism.

6.1. Hamiltonian Mechanics
257
Darbouxâ€™s Theorem, a fundamental result in the theory of symplectic
manifolds, establishes that given any two symplectic forms Ï‰ and ËœÏ‰ such
that Ï‰P = ËœÏ‰P at some point P âˆˆM, there exists a neighborhood U of
P and a diï¬€eomorphism F : U â†’F(U) âŠ‚M such that F(P) = P and
F âˆ—ËœÏ‰ = Ï‰. (We refer the reader to [7, Section 2.2] for a proof.) Darbouxâ€™s
Theorem is equivalent to the following formulation.
Theorem 6.1.7. Let (M, Ï‰) be a symplectic manifold. For each point P âˆˆM,
there exists an open neighborhood U of P and a symplectomorphism F of
U onto F(U) âŠ‚R2n such that (F âˆ’1)âˆ—Ï‰ takes the canonical form in R2n.
As a consequence of this theorem, at every point P âˆˆM, there exists a
coordinate neighborhood U of P with coordinates x in which
Ï‰ =
n

i=1
dxi âˆ§dxn+i.
The formalism of symplectic manifolds applies to Hamiltonian mechan-
ics in the following way. Consider the conï¬guration space Q for a physical
system.
Suppose that Q is a manifold of dimension n.
The cotangent
space M = T Qâˆ—is a manifold in itself of dimension 2n. If U is a coordi-
nate neighborhood of Q with coordinates (q1, . . . , qn), then ËœU = Ï€âˆ’1(U) is
a coordinate neighborhood for the manifold T Qâˆ—, where Ï€ : T Qâˆ—â†’Q is
the bundle projection map. The quantities (q1, . . . , qn, p1, . . . , pn) of posi-
tion coordinates and corresponding generalized momenta form a coordinate
system on ËœU. By the identiï¬cation of TpRn âˆ¼= Rn, it is not hard to show
that T M = T (T Qâˆ—) âˆ¼= T Q âŠ•T Qâˆ—.
Proposition 6.1.8.
The 2-form deï¬ned over a particular coordinate patch
Ï€âˆ’1(U) by
Ï‰ =
n

i=1
dqi âˆ§dpi
(6.7)
extends to a 2-form Ï‰ âˆˆÎ©2(T Qâˆ—) over the whole phase space T Qâˆ—. Fur-
thermore, it is deï¬ned in exactly the same way as in Equation (6.7) over
every coordinate patch on T Qâˆ—obtained as Ï€âˆ’1( Â¯U), where Â¯U is any other
coordinate patch of Q.
Consequently, the form Ï‰ endows T Qâˆ—with the
structure of a symplectic manifold.
Proof: Let F : U âˆ©Â¯U â†’U âˆ©Â¯U be a coordinate transformation from (qi) to
(Â¯qi) coordinates, and let G : Ï€âˆ’1(Uâˆ©Â¯U) â†’Ï€âˆ’1(Uâˆ©Â¯U) be the corresponding
coordinate transformation from (qi, pi) to (Â¯qi, Â¯pi) on T Qâˆ—.
Since pi are

258
6. Applications of Manifolds to Physics
coordinates in the cotangent space, the diï¬€erential of G has coordinate
functions
[dG] =
â›
âœ
â
âˆ‚Â¯qi
âˆ‚qj
0
0
âˆ‚qk
âˆ‚Â¯ql
â
âŸ
â =

[dF]
0
0
[dF]âˆ’1
	
.
In particular, we deduce that
dÂ¯qi = âˆ‚Â¯qi
âˆ‚qj
dqj
and
dÂ¯pi = âˆ‚qk
âˆ‚Â¯qi
dpk.
Thus,
n

i=1
dÂ¯qi âˆ§dÂ¯pi =
n

i=1
 âˆ‚Â¯qi
âˆ‚qj
dqj
	
âˆ§
âˆ‚qk
âˆ‚Â¯qi
dpk
	
=
n

j=1
n

k=1
 n

i=1
âˆ‚Â¯qi
âˆ‚qj
âˆ‚qk
âˆ‚Â¯qi

dqj âˆ§dpk
=
n

j=1
n

k=1
Î´jkdqj âˆ§dpk =
n

j=1
dqj âˆ§dpj.
The result follows.
â–¡
The Hamiltonian function H is a smooth function T Qâˆ—â†’R. We deï¬ne
the Hamiltonian vector ï¬eld XH as the unique vector ï¬eld that satisï¬es
iXHÏ‰ = dH,
(6.8)
where iX is the contraction operator iX deï¬ned in Problem 5.1.10. Accord-
ing to Problem 5.1.10, iXHÏ‰ is the 1-form deï¬ned by iXHÏ‰(Y ) = Ï‰(XH, Y )
at all P âˆˆM and for all Y âˆˆX(M). It is not too hard to show that in
coordinates of T (T Qâˆ—), the vector ï¬eld XH is
XH =
n

i=1
âˆ‚H
âˆ‚pi
âˆ‚
âˆ‚qi
âˆ’
n

i=1
âˆ‚H
âˆ‚qi
âˆ‚
âˆ‚pi
.
(6.9)
Proposition 6.1.9. A curve Î³ on the phase space T Qâˆ—is an integral curve
of the vector ï¬eld XH if and only if in each coordinate system the com-
ponents Î³(t) = (qk(t), pk(t)) satisfy Hamiltonâ€™s equations of motion from
Equation (6.6).

6.1. Hamiltonian Mechanics
259
Proof: As a vector ï¬eld on the curve Î³, the derivative Ë™Î³(t) is written in
coordinates as
Ë™Î³(t) =
n

i=1
Ë™qi
âˆ‚
âˆ‚qi
+
n

i=1
Ë™pi
âˆ‚
âˆ‚pi
.
(6.10)
By Equation (6.9), the Hamiltonian vector ï¬eld XH at points along the
curve is expressed in coordinates as
(XH)Î³(t) =
n

i=1
âˆ‚H
âˆ‚pi
(Î³(t)) âˆ‚
âˆ‚qi
âˆ’
n

i=1
âˆ‚H
âˆ‚qi
(Î³(t)) âˆ‚
âˆ‚pi
.
(6.11)
The proposition follows by identiï¬cation of Equations (6.10) and (6.11).â–¡
In other words, Proposition 6.1.9 states that a solution to Hamiltonâ€™s
equations of motion corresponds to a curve Î³(t) in the phase space T Qâˆ—
such that
Ë™Î³(t) = (XH)Î³(t).
Because of the importance of this formulation, it has its own terminology.
If (M, Ï‰) is a symplectic manifold and H âˆˆCâˆ(M), then with XH deï¬ned
by Equation (6.8), the triple (M, Ï‰, XH) is called a Hamiltonian system.
Problems
6.1.1. Explain why the conï¬guration space of a general solid in Euclidean three-
space is Q = R3 Ã— S2 Ã— S1.
6.1.2. (Phys) Write down the Lagrangian equations of motion and the Hamil-
tonian equations of motion for an elastic pendulum: a particle of mass
m attached to a (massless) elastic string of elasticity constant k and un-
stretched length L0.
6.1.3. (Phys) Consider the motion of the earth around the sun. Placing the sun
at the origin, use polar coordinates (r, Î¸) to locate the center of the earth
with respect to the sun. The force of gravity of the sun acting on the
earth has a potential energy function of V (r) = âˆ’GMSME/r, where G is
Newtonâ€™s universal constant of gravity, MS is the mass of the sun and ME
is the mass of the earth. Take into account the fact that the earth rotates
on its own axis. Use the additional angle Ïˆ to orient the earth around its
axis. Write down the Hamiltonian function for this system, taking into
account earthâ€™s rotation. Show that, despite the fact that the rotation of
the earth aï¬€ects the Hamiltonian, the rotation does not aï¬€ect the motion
of the earth around the sun.
6.1.4. Suppose that Q is the conï¬guration space for a physical system involving
a particle of mass m, and suppose that Q is a Riemannian manifold with

260
6. Applications of Manifolds to Physics
metric g = âŸ¨, âŸ©. Then the kinetic energy of a particle traveling along a
curve Î³(t) is
T = 1
2mâŸ¨Ë™Î³(t), Ë™Î³(t)âŸ©.
(a) Consider the sphere S2 of radius R, and use the coordinates (Î¸, Ï†).
Write down the Lagrangian, the Hamiltonian, and Hamiltonâ€™s equa-
tions of motion of a particle of mass m aï¬€ected by a potential
V = f(Î¸, Ï†).
(b) Let Q be any Riemannian manifold with metric g and with the as-
sociated Levi-Civita connection.
Show that if the potential V is
constant, then a solution to Hamiltonâ€™s equations of motion deï¬nes
a geodesic on Q.
6.1.5. Prove Proposition 6.1.3.
6.1.6. Let V be a vector space of dimension 2n, and let Ï‰ be any bilinear form
on V . Show that Ï‰ is nondegenerate if and only if Ï‰n = Ï‰ âˆ§Â· Â· Â· âˆ§Ï‰ is
nonzero.
6.1.7. Let (V, Ï‰) be a real symplectic vector space. Let B = {e1, Â· Â· Â· , e2n} be a
basis of V that gives Ï‰ a canonical form.
(a) Show that if a linear transformation T : V â†’V leaves the form
invariant, i.e.,
Ï‰(T(âƒ—v), T(âƒ—w)) = Ï‰(âƒ—v, âƒ—w)
for all âƒ—v, âƒ—w âˆˆV,
then the matrix A of T with respect to the basis B satisï¬es
AT JA = J,
where
J =
 0
In
âˆ’In
0
	
.
(b) Suppose that T leaves Ï‰ invariant. Show that if Î» is an eigenvalue
of T with multiplicity k, then 1Î», Â¯Î», and 1/Â¯Î» are also eigenvalues of
T with multiplicity k.
6.1.8. (Phys) Classical electromagnetism. Consider a charged particle of mass m
and charge e under the inï¬‚uence of a static electric ï¬eld âƒ—E and magnetic
ï¬eld âƒ—B. The non-relativistic theory of electromagnetism [44] states that
the force applied to the particle is
âƒ—F = e( âƒ—E + 1
câƒ—v Ã— âƒ—B),
where âƒ—v = dâƒ—x/dt is the velocity vector of the particle and c is the speed
of light. (The presence of c is a mere scaling factor due to the choice of
units.) The electric ï¬eld is induced from an electric potential Ï† so that
âƒ—E = âˆ’âƒ—âˆ‡Ï†. The magnetic force, however, is not a conservative force. Show
that the Lagrangian
L = 1
2mv2 + eÏ† + e
câƒ—v Â· âƒ—A

6.1. Hamiltonian Mechanics
261
yields Newtonâ€™s equation of motion from Equation (6.2), where âƒ—A is the
vector potential satisfying âƒ—B = âƒ—âˆ‡Ã— âƒ—A. Show that the Hamiltonian of this
system given in coordinates (xi, pi) is
H(âƒ—x, âƒ—p) =
1
2m(p2
1 + p2
2 + p2
3) âˆ’eÏ†(âƒ—x) âˆ’e
mc(p1A1 + p2A2 + p3A3).
6.1.9. (Phys) Action for a Relativistic Point Particle. The action of a free (no exter-
nal forces) non-relativistic particle traveling between t = t1 and t = t2 is
simply
S =
% t2
t1
1
2mv2 dt =
% t2
t1
1
2m

dâƒ—x
dt

2
dt,
and thus the Lagrangian is L = T = 1
2mv2. To give a relativistic formu-
lation for the action of a free particle, let us ï¬rst assume we are in the
context of a Minkowski space with coordinates described in Equation (5.8).
One must describe the action in a way that is invariant under a Lorentz
transformation.
Therefore, we cannot directly use the particle velocity
since the velocity is not a Lorentz invariant. This exercise seeks to justify
the deï¬nition of the action of a relativistic point particle as
S = âˆ’mc
%
P
ds,
(6.12)
where we integrate over a world line P of the particle. According to Equa-
tion (5.11), the action in Equation (6.12) has an associated Lagrangian of
L = âˆ’mc2

1 âˆ’v2
c2 .
(6.13)
(a) Calculate the 6th-order Taylor expansion of
âˆš
1 âˆ’x2, and show that
the quadratic approximation to L is
L âˆ¼= âˆ’mc2 + 1
2mv2.
(6.14)
(b) Using Equation (6.13), show that the generalized momentum vector
âƒ—p and the Hamiltonian H satisfy
âƒ—p =
mâƒ—v

1 âˆ’v2
c2
and
H =
mc2

1 âˆ’v2
c2
.
(This formula for H conforms with the formula [23, (1-16)] for the
total energy of a free relativistic particle.)
(c) Let g be any Lorentz metric on a pseudo-Riemannian manifold of
index 1.
Repeat Problem 6.1.4(b) using âˆ’ds2 = gij dxi dxj, and
show that a free relativistic particle travels along a geodesic.
6.1.10. An alternative way to deï¬ne the Hamiltonian vector ï¬eld XH involves us-
ing the process of raising indices as deï¬ned in Equation (5.5) in Section 5.1.
Show that XH = dHâ™¯, relative to the canonical form Ï‰ on TQâˆ—.

262
6. Applications of Manifolds to Physics
6.1.11. Prove Equation (6.9). [Hint: Use the embedding of 12 TQâˆ—in TQâˆ—âŠ—TQâˆ—
given by dqi âˆ§dpi = dqi âŠ—dpi âˆ’dpi âŠ—dqi.]
6.1.12. Let Q be a conï¬guration space and let M be the associated phase space
M = TQâˆ—. Let Ï€ : TQâˆ—â†’Q be the canonical projection. Deï¬ne the
Liouville form Ï‘ âˆˆÎ©1(M) by
Ï‘m(X)
def
= Î»q (dÏ€m(X))
for any point m = (q, Î»q) of the phase space M and for any vector X âˆˆ
TmM.
(a) Using the standard coordinates on Ï€âˆ’1(U) in TQâˆ—, where U is a co-
ordinate patch of Q, show that the Liouville form has the expression
Ï‘ =
n

i=1
pi dqi.
(b) Conclude that the canonical symplectic form on TQâˆ—satisï¬es Ï‰ =
âˆ’dÏ‘.
6.1.13. Poisson Bracket.
Consider the phase space M = TQâˆ—for a conï¬gura-
tion space Q.
Deï¬ne the Poisson bracket { , } on the function space
Câˆ(TQâˆ—) by
{f, g} =
n

i=1
 âˆ‚f
âˆ‚qi
âˆ‚g
âˆ‚pi âˆ’âˆ‚f
âˆ‚pi
âˆ‚g
âˆ‚qi
	
.
(a) Show that { , } is a diï¬€erential in each entry, i.e.,
{f1f2, g} = {f1, g}f2 + f1{f2, g}
and similarly for the second entry.
(b) Prove that { , } gives Câˆ(TQâˆ—) the structure of a Lie algebra, i.e.,
{ , } satisï¬es the ï¬rst three items of Proposition 4.2.12.
(c) Show that Hamiltonâ€™s equations of motion from Equation (6.6) are
equivalent to
Ë™qk = {qk, H}
and
Ë™pk = {pk, H}
for k = 1, . . . , n.
6.2
Electromagnetism
The goal of this section is to summarize the dynamics of a charged particle
moving under the inï¬‚uence of an electric ï¬eld âƒ—E and a magnetic ï¬eld âƒ—B,
both of which are time and space dependent. In no way does this brief sec-
tion attempt to encapsulate all of the theory of electromagnetism. Rather
we show how to pass from a classical formulation of a few of the basic laws
of electromagnetism to a modern formulation that uses Minkowski metrics
and the language of forms. (Note: all formulas in this section use CGS

6.2. Electromagnetism
263
units, i.e., centimeters-grams-seconds units. In this system, force is mea-
sured in dyne, energy in erg, electric charge in esu, electric potential in
statvolt, and the magnetic ï¬eld strength in gauss.)
The mathematical theory relies on the model (based on experiment)
that point charges exist, i.e., particles of negligible size with charge. For
example, the electron and the proton ï¬t this bill. In contrast, magnetic
monopolesâ€”point-like particles with a magnetic chargeâ€”do not (appear
to) exist. The observation of a single magnetic monopole would change
the rest of the theory (by adding an extra magnetic charge density and
magnetic current) but even this â€œwould not alter the fact that in matter as
we know it, the only sources of the magnetic ï¬eld are electric currentsâ€ [44,
p. 405].
Coulombâ€™s law of electrostatic force states that the force acting on point
charge 2 induced by point charge 1 is inversely proportional to the square
of the distance between the charges. More precisely,
âƒ—F = q1q2
r2 Ë†r,
where q1 and q2 are the respective charges of the particles, r is the distance
between them, and Ë†r is the unit vector pointing from 1 to 2. One then
considers systems of charges, modeled by a charge density Ï(x, y, z), acting
on a point particle with charge q. We call the electric ï¬eld of a charged
system the vector ï¬eld
âƒ—E = 1
q
âƒ—F
(6.15)
=

R3 Ï(xâ€², yâ€², zâ€²)
(x âˆ’xâ€², y âˆ’yâ€², z âˆ’zâ€²)
((x âˆ’xâ€²)2 + (y âˆ’yâ€²)2 + (z âˆ’zâ€²)2)3/2 dxâ€² dyâ€² dzâ€²,
where âƒ—F is the force the system would exert on a particle of charge q at
position (x, y, z). An application of Gaussâ€™s Theorem from vector calculus
gives Gaussâ€™s Law for electrostatics, i.e.,
div âƒ—E = 4Ï€Ï,
where, if there is time dependence, then the divergence is only taken in the
space variables.
One can show that an inverse square force is conservative, which means
that there exists a function Ï•(x, y, z) such that
âƒ—E = âˆ’âƒ—âˆ‡Ï•.
(6.16)

264
6. Applications of Manifolds to Physics
The function Ï• is called the electric potential. The potential of a distribu-
tion of charge can be written as the integral
Ï•(x, y, z, t) =
%%%
R3
Ï(xâ€², yâ€², zâ€², t)

(x âˆ’xâ€²)2 + (y âˆ’yâ€²)2 + (z âˆ’zâ€²)2 dxâ€² dyâ€² dzâ€².
(6.17)
The potential energy of the electric force ï¬eld acting on a particle with
charge q is V = qÏ•. If the system of electrical charges is moving, then âƒ—E,
Ï•, and Ï are also functions of time, but Equations (6.15) and (6.16) still
hold with the caveat that the integration and the gradient only involve the
space variables. A system of time-dependent current density also induces
what are called electrical currents. One calls current density the vector ï¬eld
âƒ—J that at each point (x, y, z), intuitively speaking, measures the direction
of the current and how much current is passing per area and per time. A
direct application of Gaussâ€™s Theorem from vector calculus gives
div âƒ—J = âˆ’âˆ‚Ï
âˆ‚t .
(6.18)
At the heart of electromagnetism lies an interdependence between mag-
netic ï¬elds and electric ï¬elds. A charged particle that is moving in the pres-
ence of a current experiences a force perpendicular to its velocity. That
force acting on the particle is called the magnetic force. The magnetic ï¬eld
of a system of charges is the ï¬eld âƒ—B deï¬ned implicitly by
âƒ—F = q( âƒ—E + 1
câƒ—v Ã— âƒ—B).
This overall eï¬€ect on a particle with charge q is called the electromagnetic
force. It is no longer conservative due to the presence of âƒ—v. One can deï¬ne
the magnetic vector potential âƒ—A by
âƒ—A(x, y, z) = 1
c
%%%
R3
âƒ—J(xâ€², yâ€², zâ€², t)

(x âˆ’xâ€²)2 + (y âˆ’yâ€²)2 + (z âˆ’zâ€²)2 dxâ€² dyâ€² dzâ€².
(6.19)
Furthermore, Faraday discovered that not only does a time-dependent dis-
tribution of charge induce a magnetic ï¬eld but so does a variable magnetic
ï¬eld similarly aï¬€ect the electric ï¬eld. The inter-relationship between the
electric and magnetic ï¬elds can be summarized by two separate sets of
equations: Faradayâ€™s law for potential, i.e.,
âƒ—E = âˆ’âƒ—âˆ‡Ï• âˆ’1
c
âˆ‚âƒ—A
âˆ‚t
âƒ—B = âƒ—âˆ‡Ã— âƒ—A,
(6.20)

6.2. Electromagnetism
265
and the celebrated Maxwellâ€™s equations (in a vacuum), i.e.,
âƒ—âˆ‡Â· âƒ—E = 4Ï€Ï,
âƒ—âˆ‡Ã— âƒ—E = âˆ’1
c
âˆ‚âƒ—B
âˆ‚t ,
âƒ—âˆ‡Â· âƒ—B = 0,
âƒ—âˆ‡Ã— âƒ—B = 1
c
âˆ‚âƒ—E
âˆ‚t + 4Ï€
c
âƒ—J.
Maxwellâ€™s equations stand as a crowning achievement in electromagnetism.
It encapsulates the interdependent phenomena of induction and the static
source of the various ï¬elds. Furthermore, solving the equations for empty
space (i.e., Ï = 0 and âƒ—J = âƒ—0) leads to an interpretation of light as an
electromagnetic wave.
Hidden in Maxwellâ€™s equations lie relativistic eï¬€ects. If a charged par-
ticle travels fast (a non-trivial fraction of the speed of light), then due
to relativistic eï¬€ects, its electric ï¬eld appears distorted to a stationary ob-
server. Lorentz transformations, presented in Problem 2.4.14, describe how
the electric and magnetic ï¬elds look diï¬€erent in diï¬€erent moving frames of
reference.
Having developed considerable analytical machinery in the previous
chapters, we are in a position to reformulate the theory of electromag-
netism in a more concise way. We work in a four-dimensional Lorentzian
spacetime, which means the pseudometric
  = âŸ¨, âŸ©has index 1. We label
the coordinates as x0 = ct, x1 = x, x2 = y, and x3 = z. If we use the
speciï¬c pseudometric Î· deï¬ned by
Î·00 = âˆ’1,
Î·ii = 1 for i = 1, 2, 3,
and
Î·ij = 0 otherwise,
then we call our conï¬guration space the Minkowski spacetime. However,
as we wish to leave open the possibility of considering electromagnetism in
a curved spacetime, we assume
  can be non-Minkowski.
Deï¬ne the 4-vector potential
 as the 1-form with components
Ai = (âˆ’Ï†, A1, A2, A3).
(6.21)
We call the electromagnetic tensor
 as the 2-form
F = âˆ’
3

i=1
Eidx0 âˆ§dxi +
3

i=1
Bi(Ëœâ‹†dxi)
= âˆ’E1 dx0 âˆ§dx1 âˆ’E2 dx0 âˆ§dx2 âˆ’E3 dx0 âˆ§dx3
+ B1 dx2 âˆ§dx3 âˆ’B2 dx1 âˆ§dx3 + B3 dx1 âˆ§dx2,

266
6. Applications of Manifolds to Physics
where by Ëœâ‹†we mean the Hodge star operator acting only on the space
variables. If we exhibit the components of
 in an antisymmetric matrix,
we write
FÎ¼Î½ =
â›
âœ
âœ
â
0
âˆ’E1
âˆ’E2
âˆ’E3
E1
0
B3
âˆ’B2
E2
âˆ’B3
0
B1
E3
B2
âˆ’B1
0
â
âŸ
âŸ
â .
(6.22)
In Problem 4.3.7, one showed that Faradayâ€™s law for potential from Equa-
tion (6.20) can be expressed simply as
d =
.
Interestingly enough, this formula does not refer to any metric but rather
to the simple fact that the electromagnetic tensor
 is an exact form.
We also deï¬ne the 4-current vector by
 = (cÏ, J1, J2, J3), where Ï
is the charge density and (J1, J2, J3) = âƒ—J is the classic current-density
vector. Using the Minkowski metric Î·, recall that by F Î±Î² we mean the
raising-indices operation F Î±Î² = Î·Î±Î¼Î·Î²Î½FÎ¼Î½ and similarly for the lowering
operation JÎ± = Î·Î±Î²JÎ². Since there is no possibility of confusion for
, we
write
â™­for the covector associated to
. Note that
F Î±Î² =
â›
âœ
âœ
â
0
E1
E2
E3
âˆ’E1
0
B3
âˆ’B2
âˆ’E2
âˆ’B3
0
B1
âˆ’E3
B2
âˆ’B1
0
â
âŸ
âŸ
â 
and
JÎ± = (âˆ’cÏ, J1, J2, J3).
With this setup, it is not hard to show that Maxwellâ€™s equations can be
written in tensor form as
F Î²Î±
;Î± = 4Ï€
c JÎ²,
ÎµÎ±Î²Î³Î´FÎ±Î²;Î³ = 0.
(6.23)
Note that since we are using a ï¬‚at pseudometric, the second equation in
Equation (6.23) can be written equivalently as
ÎµÎ±Î²Î³Î´FÎ±Î²;Î³ = FÎ±Î²;Î³ + FÎ²Î³;Î± + FÎ³Î±;Î² = âˆ‚Î³FÎ±Î² + âˆ‚Î±FÎ²Î³ + âˆ‚Î²FÎ³Î± = 0.
Using 4-vectors, one can easily describe the potential between the cur-
rent 4-vector and the potential 4-vector. First, we deï¬ne the Dâ€™Alembertian
operator as
â–¡= âˆ‚2
âˆ‚x2 + âˆ‚2
âˆ‚y2 + âˆ‚2
âˆ‚z2 âˆ’1
c2
âˆ‚2
âˆ‚t2 .

6.2. Electromagnetism
267
Note that applying Equation (6.18) to Equations (6.19) and (6.17), one can
show that âƒ—âˆ‡Â· âƒ—A = âˆ’1
câˆ‚Ï•/âˆ‚t. Thus, taking the divergence of âƒ—E expressed
in Equation (6.20), we obtain
â–¡Ï† = âˆ’4Ï€Ï.
(6.24)
Using similar calculations, we can also show that
â–¡Ai = âˆ’4Ï€
c Ji
(6.25)
for i = 1, 2, 3.
Using the language of forms, Maxwellâ€™s equations become even simpler.
Let us suppose we are in the context of a ï¬‚at Minkowski space with the
pseudometric Î·. Using the result of Problem 5.2.18, the second equation in
Equation (6.23) simply states that d = 0. Therefore, Maxwellâ€™s equations
can be restated as
â‹†d(â‹†) = 4Ï€
c
â™­,
d = 0,
(6.26)
where â‹†is the Hodge star operator on the Minkowski space. Though we
presented Equation (6.26) as a reformulation of Maxwellâ€™s equations in
Minkowski space, it turns out this formulation works in any curved space-
time, regardless of the metric. The composition of operations â‹†dâ‹†has ap-
peared in this text before as the divergence operator on a vector ï¬eld. The
result from Problem 5.1.20 shows that the ï¬rst equation of Equation (6.26)
can be rephrased as div
 = 4Ï€/c
â™­. Furthermore, the formula for the
divergence operator on tensors introduced in Problem 5.2.16 immediately
recovers Equation (6.23).
(One must take a little care with the reformulation given in Equa-
tion (6.26).
Some authors deï¬ne the current-density vector as our â‹†â™­.
However, because of Proposition C.6.11 and Proposition 2.4.14, the com-
ponents of â‹†â™­do not transform as the components of a tensor, but as
the components of a tensor density or weight -1, a concept that we do not
deï¬ne here.)
Problem 2.4.14 described the Lorentz transformations, which are trans-
formations that preserve the Minkowski metric.
According to the laws
of special relativity, the type of Lorentz transformation described in Prob-
lem 2.4.14(c), with Î² = v
c where c the speed of light, is precisely the change
of coordinates that corresponds to a second frame traveling at velocity v
along the x-axis with respect to a reference frame.

268
6. Applications of Manifolds to Physics
Problems
6.2.1. Suppose we are in R1,3, and let F be the standard reference frame. Sup-
pose that another frame Fâ€² keeps the x-, y-, and z-axes in the same orien-
tation but has an origin Oâ€² that travels at velocity v along the x-axis of F.
Let âƒ—E and âƒ—B be joint electric and magnetic force ï¬elds with coordinates
(E1, E2, E3) and (B1, B2, B3) as observed in F. Use the electromagnetic
tensor from Equation (6.22) and the coordinate transformation described
in Problem 2.4.14 to show that in Fâ€² the components of the same vector
ï¬elds are observed as having the components
Eâ€²
1 = E1,
Eâ€²
2 = Î³(E2 âˆ’Î²B3),
Eâ€²
3 = Î³(E3 + Î²B2),
Bâ€²
1 = B1,
Bâ€²
2 = Î³(B2 + Î²E3),
Bâ€²
3 = Î³(B3 âˆ’Î²E2).
(This result conforms to standard results of special relativistic eï¬€ects in
electromagnetism. [44, Equation (58), Chapter 6].)
6.2.2. Let f be a smooth function deï¬ned over the Minkowski space R1,3. As
always, set x0 = ct, x1 = x, x2 = y, and x3 = z. Prove that
d(â‹†(df)) = câ–¡fdt âˆ§dx âˆ§dy âˆ§dz.
6.2.3. Suppose we are in Minkowski spacetime.
(a) Prove that 1
2F Î±Î²FÎ±Î² = âˆ¥âƒ—Eâˆ¥2 âˆ’âˆ¥âƒ—Bâˆ¥2. Conclude that âˆ¥âƒ—Eâˆ¥2 âˆ’âˆ¥âƒ—Bâˆ¥2
is preserved under any Lorentz transformation.
(b) Prove that âˆ’1
4Î·ij(â‹†F)jkÎ·ilFlk = âƒ—E Â· âƒ—B.
Conclude that âƒ—E Â· âƒ—B is
preserved under any Lorentz transformation.
6.2.4. Let M be any pseudo-Riemannian manifold. Consider the operation that
consists of the compositions â‹†d â‹†d.
(a) Show that â‹†d â‹†d is an R-linear operator Î©k(M) â†’Î©k(M) for k <
dim M.
(b) Let M = Rn be a standard Euclidean space. Recalling that Î©0(M) =
Câˆ(M), show that for any smooth function f,
â‹†d â‹†df = âˆ‡2f,
where âˆ‡2 is the usual Laplacian âˆ‡2 =
âˆ‚2
âˆ‚(x1)2 + Â· Â· Â· +
âˆ‚2
âˆ‚(xn)2 .
(c) Suppose we are in Minkowski space.
Show that â–¡= â‹†d â‹†d, and
conclude that Equations (6.24) and (6.25) can be summarized by
â‹†d â‹†d   = 4Ï€
c
â™­.
6.2.5. In [57, Equation (5.38)], the author states that â€œthe full action for the
electrically charged point particle isâ€
S = âˆ’mc
%
P
ds + q
c
%
P
AÎ¼ dxÎ¼,
(6.27)

6.3. Geometric Concepts in String Theory
269
where ds is given by Equation (5.11) and AÎ¼ are the components of the
potential covector given in Equation (6.21). Suppose a charged particle
travels along a path (x1(t), x2(t), x3(t)).
(a) Write the action in Equation (6.27) as an integral of time t alone.
(b) Determine the Lagrangian for this system, and write down Lagrangeâ€™s
equations of motion.
(c) Write down Hamiltonâ€™s equations of motion.
6.3
Geometric Concepts in String Theory
What is generically understood in physics as string theory is a collection of
theories called superstring theories. The name of these models derives from
the fact that in many of the ï¬rst proposed theories, elementary particles
were viewed as a string. Since then, theories have been formulated in terms
of points or surfaces. The string can be either open on the ends or be a
closed loop. For theoretical reasons, the length of the strings should be
on the order of the Planck length, â„“P = 1.6162 Ã— 10âˆ’35 m. This size is
so small as to render it impossible to directly observe the string structure
with present technology or, so it would seem, with technology that will be
available in the near future.
In this model, observed properties of the
particle, such as mass or electric charge, arise as speciï¬c properties of
the vibration of the string.
A string in common day occurrence is made of some material like thread
or wire. One could ask what these strings are made of, i.e., what is the
nature of the â€œthread.â€ This type of question is, however, vacuous because
the string is not made up of any constituent parts. One should rather think
of the particle-wave duality that drew considerable debate during the incep-
tion of quantum mechanics. In this duality, under diï¬€erent circumstances,
a particle would exhibit billiard-ballâ€“like behavior while in other circum-
stances it would display a wave-like behavior. While some physicists dis-
cussed the fundamental nature of particles, many simply emphasized the
fact that growing experimental evidence supported the probability wave
function model, without worrying about the ontology.
As a reï¬nement to the standard model of quantum mechanics, string
theory bears a similar duality in that one thinks of the particle as having
a string nature as well as a probability wave nature.
The space of the
â€œstateâ€ functions (i.e., functions that describe the state of the particle) is
the same, but there are more operators than in the point-particle theory.
In practice, instead of debating the nature of the string, the theories work

270
6. Applications of Manifolds to Physics
x
y
z
S
Figure 6.3. The world sheet of a (nonrelativistic) closed string.
out mathematical consequences of this formulation in the hope that the
resulting theory agrees with experimental observations and uniï¬es without
irreparable inconsistencies previously established theories.
Our goal in this section is to introduce a few of the geometric notions
that underlie the relativistic dynamics of a string. Issues of quantization
of these dynamics exceed the scope of this book.
We ï¬rst consider the nonrelativistic dynamics of a string of length L in
Euclidean Rn. If the string is open, we can pick an end of the string and
use the arclength parameter to locate a point on the string. If it is closed,
we pick a speciï¬c point on the string and locate other points on the string
using the same arclength parameter. The position of the string in space at
time t is described by a smooth function X : [0, L]Ã—R â†’Rn, where X(s, t)
is the location of the point of position s on the string at time t. Therefore,
while the trajectory of a classic particle is described by a curve in Rn, the
â€œtrajectoryâ€ of a string is a surface (see Figure 6.3). In keeping with the
terminology of â€œworld lineâ€ for a relativistic point particle, the surface S
is called the world sheet of the string.
To study the dynamics of a relativistic string, we must work in the
context of a Lorentzian spacetime. (This can be curved or ï¬‚at and can have
any number of space dimensions but can have only one time dimension. In
other words, the pseudometric on the space has index 1.) As always, the
coordinates in the spacetime are xÎ¼ = (x0, x1, Â· Â· Â· , xd), with d being the
number of space dimensions and x0 = ct.

6.3. Geometric Concepts in String Theory
271
One can no longer parametrize the world sheet S with the time parame-
ter t since x0 = ct is one of the coordinates in the target space. Nonetheless,
the world sheet requires two parameters, say Î¾1 and Î¾2. Furthermore, we
can no longer give the same deï¬nition of the domain of X as in the nonrel-
ativistic description of moving strings. One refers to the domain of X as
the parameter space for the world sheet.
Now we encounter something new in Lorentzian spacetime that we never
encountered in the study of Riemannian manifolds.
The world sheet S
must be such that at each point there exists at least one spacelike tangent
vector and at least one timelike tangent vector (recall Section 5.1.4 for the
deï¬nitions). It is not hard to see the need for a spacelike tangent vector.
Any point in time corresponds to a slice of x0. Intersecting such a slice with
S gives the locus of the string at a given time. Any point on the string in
this slice will have a tangent vector that is a spacelike vector. On the other
hand, if there did not exist a timelike tangent vector at some point on S,
one would interpret that as that point not having any evolution through
time. This is not a physical situation. Hence, at each point P of S, the
tangent space has both a timelike direction and a spacelike direction. This
is the criterion for motion of the string.
If g is the pseudo-Riemannian metric of the spacetime target space,
then the induced metric Ëœg on the tangent bundle T S is deï¬ned by
Ëœgij = g
âˆ‚X
âˆ‚Î¾i , âˆ‚X
âˆ‚Î¾j
	
.
The criterion of motion for the string is equivalent to Ëœg having index 1 at
all points of S.
Proposition 6.3.1. Let X(Î¾1, Î¾2) be a parametrization for a surface S in Lo-
rentzian space with metric g such that at each point of S, X has at least
one nontrivial spacelike tangent vector and at least one nontrivial timelike
vector. Then
det(Ëœgij) = det

g
âˆ‚X
âˆ‚Î¾i , âˆ‚X
âˆ‚Î¾j
		
< 0
at all points of S.
Proof: Let P be a point on S, and let V (Î±) be the vector in TP S deï¬ned by
V (Î±) = cos Î±âˆ‚X
âˆ‚Î¾1 + sin Î±âˆ‚X
âˆ‚Î¾2

272
6. Applications of Manifolds to Physics
for Î± âˆˆ[0, 2Ï€]. Then
âˆ¥V (Î±)âˆ¥2 = cos2 Î± g
âˆ‚X
âˆ‚Î¾1 , âˆ‚X
âˆ‚Î¾1
	
+ 2 sin Î± cosÎ± g
âˆ‚X
âˆ‚Î¾1 , âˆ‚X
âˆ‚Î¾2
	
+ sin2 Î± g
âˆ‚X
âˆ‚Î¾2 , âˆ‚X
âˆ‚Î¾2
	
(6.28)
= cos2 Î± Ëœg11 + 2 sin Î± cos Î± Ëœg12 + sin2 Î± Ëœg22.
The property of tangent vectors of being timelike or spacelike is indepen-
dent of the length or sign of the vector. Thus, for some Î±1, there exists a
vector V (Î±1) such that âˆ¥V (Î±1)âˆ¥2 < 0, and for some Î±2 there exists a V (Î±2)
such that âˆ¥V (Î±2)âˆ¥2 > 0. Furthermore, âˆ¥V (Î±i + Ï€)âˆ¥2 = âˆ¥V (Î±i)âˆ¥2. Hence,
since âˆ¥V (Î±)âˆ¥2 changes sign twice over Î± âˆˆ[0, Ï€], it must have at least two
distinct roots. Therefore, Equation (6.28) leads to quadratic equations in
tan Î± or cot Î±. Either way, according to the quadratic formula, the equation
for tan Î± or for cot Î± has two distinct roots if and only if
Ëœg2
12 âˆ’Ëœg11Ëœg22 > 0.
The proposition follows immediately.
â–¡
It is customary to parametrize S with two variables labeled Ïƒ and Ï„
deï¬ned in such a way that for all points in the parameter space, âˆ‚X/âˆ‚Ïƒ
is a spacelike tangent vector and âˆ‚X/âˆ‚Ï„ is a timelike tangent vector. The
parameters Ïƒ and Ï„ no longer directly represent position along the string
or time, respectively. One could say that Ïƒ and Ï„ approximately represent
position and time along the world sheet. In fact, with the sole exception
of the endpoints, when considering the motion of open strings, one cannot
know the movement of individual points on the string. In general, Ïƒ ranges
over a ï¬nite interval [0, Ïƒ1], while Ï„ ranges over all of R.
The derivatives âˆ‚X/âˆ‚Ïƒ and âˆ‚X/âˆ‚Ï„ occur often enough that it is com-
mon to use the symbols Xâ€² and Ë™X for them, respectively. In components,
we write
Xâ€²Î¼ = âˆ‚XÎ¼
âˆ‚Ïƒ
and
Ë™XÎ¼ = âˆ‚XÎ¼
âˆ‚Ï„ .
The area element of the world sheet in this Lorentzian space is deï¬ned as
dA =

âˆ’det Ëœg =

g( Ë™X, Xâ€²)2 âˆ’g( Ë™X, Ë™X)g(Xâ€², Xâ€²).
We ï¬nish this section by brieï¬‚y discussing the Nambu-Goto action for a
free relativistic string and the resulting equations of motion for the string.

6.3. Geometric Concepts in String Theory
273
Figure 6.4. A vibrating string.
Deï¬nition 6.3.2. Let g = âŸ¨, âŸ©be a pseudometric of index 1. The Nambu-
Goto action of the string is deï¬ned as
S
def
= âˆ’T0
c
%%
S
dA = âˆ’T0
c
% Ï„2
Ï„1
% Ïƒ1
0

âˆ’det ËœgÎ±Î² dÏƒ dÏ„
(6.29)
= âˆ’T0
c
% Ï„2
Ï„1
% Ïƒ1
0

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2 dÏƒ dÏ„,
where T0 is called the string tension and c is the speed of light.
Before proceeding, we must give some justiï¬cation for this deï¬nition.
First of all, it mimics the action for a free relativistic particle given in
Equation (6.12). The diï¬€erence is that instead of deï¬ning the action as
a multiple of the length of the path in the ambient Lorentzian space, we
deï¬ne it as a multiple of the area of the world-sheet. Furthermore, this
action is obviously invariant under reparametrization since the area is a
geometrical quantity.
As a more convincing argument, we consider a classical vibrating string
of length â„“. Using Figure 6.4 as a guide, we model the motion of the string
by a function y(x, t) that measures the deviation of the string from rest at
horizontal position x and at time t. If the string has constant density Î¼0
and tension T0, then the diï¬€erential equation of motion for a string with
small deviations is
Î¼0
âˆ‚2y
âˆ‚t2 = T0
âˆ‚2y
âˆ‚x2 .
The fraction Î¼0/T0 has the units of time2/length2 and is in fact equal to
1/c2, where c is the speed of propagation of the wave. It is not hard to
reason that at any point in time t, the total kinetic energy of the string is
T =
% â„“
0
1
2Î¼0
âˆ‚y
âˆ‚t
	2
dx,

274
6. Applications of Manifolds to Physics
and that the total potential energy is
V =
% â„“
0
1
2T0
âˆ‚y
âˆ‚x
	2
dx.
Thus the Lagrangian of the system is
L =
% â„“
0
1
2Î¼0
âˆ‚y
âˆ‚t
	2
âˆ’1
2T0
âˆ‚y
âˆ‚x
	2
dx.
(6.30)
The integrand of Equation (6.30) is called the Lagrangian density and is
denoted by L. It is explicitly a function of âˆ‚y/âˆ‚t and âˆ‚y/âˆ‚x. The action
of the system for t âˆˆ[t1, t2] is
S =
% t2
t1
% â„“
0
1
2Î¼0
âˆ‚y
âˆ‚t
	2
âˆ’1
2T0
âˆ‚y
âˆ‚x
	2
dx dt.
Now assume that we are in a Minkowski space R1,2 with the ï¬‚at pseu-
dometric âˆ’ds2 = âˆ’(dx0)2 + (dx1)2 + (dx2)2, where x0 = ct, x1 = x, and
x2 = y. After some manipulation, we can rewrite that string action as
S = âˆ’T0
c
% ct2
ct1
% â„“
0
1
2

âˆ’
 âˆ‚y
âˆ‚x0
	2
+
 âˆ‚y
âˆ‚x1
	2
dx1 dx0.
(6.31)
The motion of the string can be parametrized in R1,2 by âƒ—f(x0, x1) =
(x0, x1, y(x0, x1)).
With the inner product induced by this metric, the
area element becomes
:
;
;
;
<âˆ’
â›
â
6
âˆ‚âƒ—f
âˆ‚x0 , âˆ‚âƒ—f
âˆ‚x0
7 6
âˆ‚âƒ—f
âˆ‚x1 , âˆ‚âƒ—f
âˆ‚x1
7
âˆ’
6
âˆ‚âƒ—f
âˆ‚x0 , âˆ‚âƒ—f
âˆ‚x1
72â
â 
=
!
1 âˆ’
 âˆ‚y
âˆ‚x0
	2
+
 âˆ‚y
âˆ‚x1
	2
âˆ¼= 1 + 1
2

âˆ’
 âˆ‚y
âˆ‚x0
	2
+
 âˆ‚y
âˆ‚x1
	2
.
Adjusting for x0 = ct, the Lagrangian associated to Equation (6.31) diï¬€ers
from the linear approximation to the Nambu-Goto action
âˆ’T0
% â„“
0
1 + 1
2

âˆ’
 âˆ‚y
âˆ‚x0
	2
+
 âˆ‚y
âˆ‚x1
	2
dx1

6.3. Geometric Concepts in String Theory
275
by
âˆ’T0
% â„“
0
1 dx1 = âˆ’T0â„“= âˆ’Î¼0â„“c2 = âˆ’mc2.
Similar to the linear approximation to the Lagrangian for the free rela-
tivistic particle in Equation (6.14), this diï¬€erence is precisely the negative
of the rest energy mc2 of the string.
Since this is a constant, it leaves
the Euler-Lagrange equations unchanged. This shows how the classic La-
grangian of a wave is a linear approximation for the Lagrangian associated
to the Nambu-Goto action.
We now wish to obtain the equations of motion associated to the Nambu-
Goto action. The Lagrangian density in Equation (6.29) is
L( Ë™XÎ¼, Xâ€²Î¼) = âˆ’T0
c

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2.
(6.32)
This is an explicit function of the eight variables Xâ€²Î¼ and
Ë™XÎ¼ for Î¼ =
0, 1, 2, 3. Hamiltonâ€™s principle states that the system will evolve in such a
way as to minimize the action. According to a generalization of the Euler-
Lagrange Theorem in the calculus of variations (see Problem 6.3.2), the
Nambu-Goto action is minimized if and only if the XÎ¼(s, t) satisfy
d
dÏƒ
 âˆ‚L
âˆ‚Xâ€²Î¼
	
+ d
dÏ„
 âˆ‚L
âˆ‚Ë™XÎ¼
	
= 0
for all Î¼. These are the equations of motion for a relativistic string, whether
open or closed. More explicitly, the equations of motion read
âˆ‚
âˆ‚Ïƒ
â›
ââŸ¨Ë™X, Xâ€²âŸ©gÎ¼Î½ Ë™XÎ½ âˆ’âˆ¥Ë™Xâˆ¥2gÎ¼Î½Xâ€²Î½

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2
â
â 
+ âˆ‚
âˆ‚Ï„
â›
ââŸ¨Ë™X, Xâ€²âŸ©gÎ¼Î½Xâ€²Î½ âˆ’âˆ¥Xâ€²âˆ¥2gÎ¼Î½ Ë™XÎ½

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2
â
â = 0
(6.33)
for Î¼ = 0, 1, 2, 3. At ï¬rst glance, these equations are incredibly complicated.
They involve a system of four second-order partial diï¬€erential equations of
four functions each in two variables. A remarkable fact among the basic
results of string theory is that it is possible to solve Equation (6.33) once
one makes a suitable choice of Ïƒ and Ï„.
Using the notion of generalized momenta deï¬ned in Equation (6.5), we
deï¬ne two momenta densities PÏƒ and PÏ„ that are cotangent vectors on the

276
6. Applications of Manifolds to Physics
world sheet with components
PÏƒ
Î¼
def
= âˆ’T0
c
âŸ¨Ë™X, Xâ€²âŸ©gÎ¼Î½ Ë™XÎ½ âˆ’âˆ¥Ë™Xâˆ¥2gÎ¼Î½Xâ€²Î½

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2
,
PÏ„
Î¼
def
= âˆ’T0
c
âŸ¨Ë™X, Xâ€²âŸ©gÎ¼Î½Xâ€²Î½ âˆ’âˆ¥Xâ€²âˆ¥2gÎ¼Î½ Ë™XÎ½

âŸ¨Ë™X, Xâ€²âŸ©2 âˆ’âˆ¥Ë™Xâˆ¥2 âˆ¥Xâ€²âˆ¥2
.
(One should note that in this case the superscript Ïƒ and Ï„ in PÏƒ
Î¼ and PÏ„
Î¼ are
not indices but are parameter indicators.) Then the equations of motion
read
âˆ‚PÏƒ
Î¼
âˆ‚Ïƒ + âˆ‚PÏ„
Î¼
âˆ‚Ï„
= 0.
(6.34)
This is all we will say about the underlying geometry in string theory.
String theory extends well beyond the scope of this book, and we encourage
the reader to consult [57] for an artful and accessible introduction to the
subject.
Problems
6.3.1. Show that at some point on the world-sheet of a string, if the point moves
at the speed of light, there is no timelike direction.
6.3.2. Use the methods of calculus of variations provided for the proof of The-
orem B.3.1 to prove the following result.
Let x1(s, t), . . . , xn(s, t) be
n twice-diï¬€erentiable functions in two variables.
Denote derivatives by
xâ€²i = dxi/ds and Ë™xi = dxi/dt. Suppose that a function f is given explic-
itly in terms of xi, xâ€²i, Ë™xi, s, and t. Show that the integral
% t2
t1
% s2
s1
f(x1, . . . , xn, xâ€²1, . . . , xâ€²1, Ë™x1, . . . , Ë™xn, s, t) ds dt
is optimized when
âˆ‚f
âˆ‚xi âˆ’d
ds
 âˆ‚f
âˆ‚xâ€²i
	
âˆ’d
dt
 âˆ‚f
âˆ‚Ë™xi
	
= 0
for all i = 1, . . . , n.
6.3.3. Consider a free relativistic string with Ïƒ-length Ïƒ1. The Hamiltonian for
the system is
H =
% Ïƒ1
0
PÏ„
Î¼ Ë™XÎ¼ âˆ’L dÏƒ.
(a) Recover the equations of motion as in Equation (6.34) from Hamil-
tonâ€™s equations of motion.
(b) Show that H vanishes identically for all Ï„.

6.3. Geometric Concepts in String Theory
277
(c) Let L be as in Equation (6.32). Consider the matrix with entries
âˆ‚2L/(âˆ‚Ë™XÎ¼âˆ‚Ë™XÎ½). Show that this matrix has two 0 eigenvalues, with
eigenvectors Ë™X and Xâ€². Deduce the following conditions on the mo-
mentum PÏ„:
iXâ€²(PÏ„) = PÏ„
Î¼Xâ€²Î¼ = 0,
âˆ¥PÏ„âˆ¥2 + T 2
0
c2 âˆ¥Xâ€²âˆ¥2 = gÎ¼Î½PÏ„
Î¼PÏ„
Î½ + T 2
0
c2 gÎ¼Î½Xâ€²Î¼Xâ€²Î½ = 0.
6.3.4. Show that according to the relativistic string equations of motion, the
endpoints of an open string move with the speed of light.
6.3.5. Consider a relativistic string in Minkowski space R1,d but only consider
the history of the string in the real space. We parametrize this history
as âƒ—X(Ïƒ, Ï„). (We use the vector superscript to indicate vectors in the Eu-
clidean R part of the spacetime.) Deï¬ne s(Ïƒ) to be the length of the string
along [0, Ïƒ], so that s(0) = 0 and s(Ïƒ1) is the length of the string. Also
set t = Ï„.
(a) Prove that âˆ‚âƒ—X/âˆ‚s is a unit vector.
(b) Deï¬ne the vector âƒ—vâŠ¥as the component of the velocity vector âˆ‚âƒ—X/âˆ‚t
that is perpendicular to the string. Thus,
âƒ—vâŠ¥= âˆ‚âƒ—X
âˆ‚t âˆ’

âˆ‚âƒ—X
âˆ‚t Â· âˆ‚âƒ—X
âˆ‚s

âˆ‚âƒ—X
âˆ‚s ,
where we use the usual dot product. Prove that one can write the
Nambu-Goto string action as
S = âˆ’T0
% t2
t1
% Ïƒ1
0
ds
dÏƒ

1 âˆ’v2
âŠ¥
c2 dÏƒ dt
6.3.6. (Phys,*) The Nambu-Goto Bubble Action. Suppose that instead of consid-
ering particles as strings, we model them as bubbles. Then a world sheet
S is given by a function X(Ïƒ, Â¯Ïƒ, Ï„) into a pseudo-Riemannian manifold M
with index 1.
(a) Explain why it still makes sense to deï¬ne the action of the free motion
of the relativistic bubble for Ï„1 â‰¤Ï„ â‰¤Ï„2 by
S = âˆ’T0
c
%%%
S

âˆ’det ËœgÎ±Î² dÏƒ dÂ¯Ïƒ dÏ„,
where T0 is now a surface tension and Ëœg is the metric induced from
M on S.
(b) Write down the equations of motion associated to this action.

278
6. Applications of Manifolds to Physics
6.4
A Brief Introduction to General Relativity
As with the previous sections, one might consider it outlandish (to say
the least!)
that we only allow one section to discuss general relativity.
General relativity is a vast subject with contributions from an uncountable
(well, mathematically countable, but very large) number of scientists, and
it stands alongside quantum mechanics as one of the most revolutionary
ideas in physics of the twentieth century.
On the other hand, most textbooks on general relativity take a consid-
erable amount of time to develop the techniques of analysis on manifolds,
in particular, pseudo-Riemannian manifolds. However, these are precisely
the mathematical methods we have developed in the previous few chapters,
so we are in a position to introduce some diï¬€erential geometric concepts in
general relativity as applications.
In the rest of this section, when we refer to special relativity, we mean
that we are in the context of a Minkowski space R1,3 with metric Î·, de-
scribed in Deï¬nition 5.1.15. When we refer to general relativity, we mean
that we work in a pseudo-Riemannian manifold M with index 1 and with
non-Minkowski metric tensor
 . Since each tangent space to M has the
structure of a ï¬‚at Lorentzian space R1,3, such manifolds are also called
locally Minkowski.
6.4.1
The Stress-Energy Tensor
In the mechanics of elastic media, one encounters the concept of a stress
tensor, which is a tensor-valued function deï¬ned at each point within the
body or medium. Suppose the body is in equilibrium but subject to exter-
nal forces and/or body forces (i.e., forces that act through the whole body).
Then there must exist internal forces. Let Q be a point, âƒ—n a vector based
at Q, and consider the area element Î”A that is in the plane perpendicular
to âƒ—n and has area equal to âˆ¥âƒ—nâˆ¥(see Figure 6.5). Let Î”âƒ—F be the overall
internal forces distributed over the area element Î”A. The stress vector
through the area element Î”A is the vector
âƒ—T(âƒ—n) =
lim
Î”Aâ†’0
Î”âƒ—F
Î”A.
(6.35)
It is not hard to show that the function âƒ—T(âƒ—n) is a linear function [53,
Section 10.6]. Thus the stress tensor with respect to an orthogonal basis B
based at the point Q is the matrix Ïƒ such that
âƒ—T(âƒ—n) = Ïƒ [âƒ—n]B .

6.4. A Brief Introduction to General Relativity
279
Q
âƒ—n
T(âƒ—n)
dA
Figure 6.5. Stress tensor: an area element in a continuous medium.
Consider now a small rectangular parallelepiped with sides parallel to the
coordinate planes. The stress acts on each face as depicted in Figure 6.6.
Then the columns of Ïƒ are given by
Ïƒâƒ—ei = T (âƒ—ei) =
â›
â
Ïƒi1
Ïƒi2
Ïƒi3
â
â .
Under minimal assumptions, one can reason that the stress tensor Ïƒ is
symmetric.
As a simple example, in an ideal ï¬‚uid, the stress on any small area
element is composed only of pressure, and there is no shearing force. Con-
sequently, the stress tensor is Ïƒ = P
, where P is the pressure and
 is the
3 Ã— 3 identity matrix. (This restates the claim given in calculus texts on
the applications of integration to hydrostatics when one says that â€œat any
point in a liquid the pressure is the same in all directionsâ€ [52, p. 576].)
The stress tensor arises also in the dynamics of viscous ï¬‚uids where it is
no longer necessarily diagonal. The stress tensor at a point â€œmay be a
function of the density and temperature, of the relative positions and ve-
locities of elements near [the point], and perhaps also the previous history
of the medium.â€ [53, p. 434] This characterization describes the stress ten-
sor as a function of many ambient quantities, but the reference to â€œrelative
positionsâ€ indicates that the stress tensor need not be diagonal.
Einsteinâ€™s equation in general relativity involves the so-called stress-
energy tensor. This tensor is diï¬€erent from the stress tensor but is based
on exactly the same concept.
In general relativity, the velocity 4-vector of a particle on a world line
P parametrized by X is the tangent vector along P given by
 = dX
dÏ„ ,

280
6. Applications of Manifolds to Physics
x
y
z
âƒ—e1
T(âƒ—e1)
âƒ—e2
T(âƒ—e2)
âƒ—e3
T(âƒ—e3)
Figure 6.6. Action of stress on an inï¬nitesimal coordinate cube.
where, just as in Equation (5.12), we deï¬ne the proper time of a particle on
P as Ï„ = 1
c
3
P ds. In special relativity, using Equations (5.11) and (5.12),
it is not hard to show that
 = (u0, u1, u2, u3) = (Î³c, Î³vx, Î³vy, Î³vz),
(6.36)
where Î³ = (1 âˆ’v2/c2)âˆ’1/2 and âƒ—v = (dx/dt, dy/dt, dz).
The momentum 4-vector of a particle of rest mass m0 is the tangent
covector deï¬ned by
 = m0
â™­
or in coordinates as
pÎ¼ = m0gÎ¼Î½uÎ½.
This vector is often called the energy-momentum 4-vector because in special
relativity, where we use the metric Î·, we have
(p0, p1, p2, p3) =

âˆ’E
c , px, py, pz
	
,
(6.37)
where (px, py, pz) = m0Î³(vx, vy, vz) is the relativistic 3-vector momentum.
To fully understand Equation (6.37), it is essential to be aware of the
fundamental result in special relativity of the correspondence between mass
and energy via E = mc2 = m0Î³c2. Therefore, we talk about mass and
energy of particles interchangeably. One should also note that even if a
particle of rest mass m0 is not moving, it still has a nontrivial momentum
4-vector of
 = (âˆ’m0c, 0, 0, 0).

6.4. A Brief Introduction to General Relativity
281
Underlying the assumptions that deï¬ne the stress-energy tensor, we as-
sume that â€œspacetime contains a ï¬‚owing river of 4-momentumâ€ [39, p.130].
Any mass that is moving or anything with energy contributes to the 4-
momentum. We could think of an individual particle, in which case the
4-momentum would only be deï¬ned on the particleâ€™s world line, or we could
consider a system of many particles carrying this 4-momentum. In the lat-
ter case, we should think of the 4-momentum as a covector ï¬eld on the
spacetime manifold M, that is, as a 1-form.
Let
 be any 1-form on M. Then at each point Q âˆˆM,
Q is per-
pendicular (using
  = âŸ¨, âŸ©at Q) to a three-dimensional subspace of TQM.
This subspace can be spanned by vectors AQ, BQ, and CQ such that
Q(u) = âˆ’Vol
 (u, AQ, BQ, CQ),
(6.38)
where on the right-hand side we mean the 4-volume (with respect to
 ) of
the 4-parallelepiped spanned by u, AQ, BQ, and CQ. Then the 3-volume of
the 3-parallelepiped AQ, BQ, CQ is the length âˆ¥âˆ¥. We call this 3-volume
Î”V . Then we deï¬ne the (mixed) stress-energy tensor at P in the direction
of
 by
	 â™­() =
lim
Î”V â†’0
Î”
Î”V .
In other words, at a point Q,
	 â™­() gives the rate of change of 4-momentum
through the plane perpendicular to
. As deï¬ned,
	 â™­is a tensor of type
(1, 1). For the contravariant stress-energy tensor, denoted by
	, we simply
raise the covariant index by T Î±Î² = gÎ±Î½T Î²
Î½ . We can also deï¬ne the stress-
energy tensor
	 by saying that for all 1-forms Î± on M,
	(Î±,
) = âŸ¨Î±,
âŸ©
 .
The tensor
	 is a tensor ï¬eld of type (2, 0) on M.
The stress-energy
	 is also called the energy-momentum tensor because
it contains information pertaining to the momentum ï¬‚owing through space
and the presence of static or moving energy in space. The name â€œstress-
energy tensorâ€ is commonly used since it is modeled oï¬€the stress tensor
in mechanics of elastic media.
The following gives a summary of the information included in the stress-
energy tensor. Assuming j, k > 0,
T 00 = density of energy (including mass),
(6.39)
T j0 = jth component of the momentum density,
(6.40)

282
6. Applications of Manifolds to Physics
T 0k = kth component of the energy ï¬‚ux,
(6.41)
T jk = (j, k)th component of the momentum stress
(6.42)
= kâ€™th component of the ï¬‚ux of the j-component of momentum.
The notion of ï¬‚ux in this context refers to a similar limit as in Equa-
tion (6.35) but in the situation where one is concerned with the movement
of something (energy, ï¬‚uid momentum, heat, etc.) through the inï¬nites-
imal area element d âƒ—A. In fact, with this particular concept of ï¬‚ux, one
can deï¬ne the stress-energy tensor in short by saying that T kj is the kth
component of the ï¬‚ux of the jth component of the 4-momentum.
We now state two facts about the stress-energy tensor that we do not
fully justify here.
Proposition 6.4.1. The (contravariant) stress-energy tensor
	 is symmetric.
Proposition 6.4.2 (Einsteinâ€™s Conservation Law). The conservation of energy is
equivalent to the identity
div
	 = T Î±Î²
;Î² = 0.
Proof (Sketch): Suppose that energy is conserved in a certain region of M.
In other words, though energy and mass may move around, no energy or
mass is created or annihilated in M.
Then given any four-dimensional
submanifold V with boundary âˆ‚V, the total ï¬‚ux of 4-momentum passing
through âˆ‚V must be 0. We can restate this as
%%%
âˆ‚V
	 Â· d
 (3) = 0,
where d
 (3) is the 3-volume element with direction along the outward-
pointing normal vector to âˆ‚V. (We can view this as a volume 1-form.) By
the product Â· we mean the contraction of
	 with the volume 1-form element
d
 (3). By Stokesâ€™ Theorem applied to pseudo-Riemannian manifolds, one
can show that
%%%%
V
div
	dV (4) =
%%%
âˆ‚V
	 Â· d
 (3) = 0.
Since this is true for all V as described above, one can show with a limiting
argument that div
	 = 0 everywhere.
â–¡
Example 6.4.3 (Perfect Fluid Stress-Energy Tensor). A perfect ï¬‚uid is a ï¬‚uid in
which the pressure p is the same in any direction. The ï¬‚uid must be free

6.4. A Brief Introduction to General Relativity
283
of heat conduction and viscosity and any process that can cause internal
sheers. Using the interpretation of
	 from Equations (6.39)â€“(6.42), we
immediately see that T jk = 0 if j Ì¸= k and 0 < j, k. Furthermore, since
the pressure is the same in all directions, T jj = p for j = 1, 2, 3.
For
components involving j = 0 or k = 0, we ï¬rst have T 00 = Ï, the energy
density. This quantity includes rest mass m = Î³m0 density but also other
types of energy such as compression energy. For the remaining oï¬€diagonal
terms T 0j = T j0, these are 0 because of the assumption that there is no
heat conduction in the perfect ï¬‚uid. Thus, the stress-energy tensor has
components
T Î±Î² =
â›
âœ
âœ
â
Ï
0
0
0
0
p
0
0
0
0
p
0
0
0
0
p
â
âŸ
âŸ
â .
(6.43)
If we suppose that an observer is in the Lorentz frame that is at rest
with respect to the movement of the ï¬‚uid, then the velocity has components
uÎ± = (1, 0, 0, 0). With respect to the Minkowski metric Î·, we can write
Equation (6.43) as
T Î±Î² = (Ï + p)uÎ±uÎ² + pÎ·Î±Î².
We can rewrite this in a coordinate-free way in any metric as
	 = p  âˆ’1 + (p + Ï) âŠ—
,
where we have written
  âˆ’1 for the contravariant tensor of type (2, 0) asso-
ciated to the metric tensor
 .
Example 6.4.4 (Electromagnetic Stress-Energy Tensor). Directly using the inter-
pretation of
	 given in Equations (6.39)â€“(6.42) and results from electro-
magnetism, which we do not recreate here, one can determine the compo-
nents of the stress-energy tensor for the electromagnetic ï¬eld in free space.
If F Î¼Î½ are the components of the electromagnetic ï¬eld tensor, then
T Î±Î² = 1
Î¼0

F Î±Î¼gÎ¼Î½F Î²Î½ âˆ’1
4gÎ±Î²F Î¼Î½FÎ¼Î½
	
in SI units
= 1
4Ï€

F Î±Î¼gÎ¼Î½F Î²Î½ âˆ’1
4gÎ±Î²F Î¼Î½FÎ¼Î½
	
in CGS units,
where Î¼0 = 4Ï€ Ã— 10âˆ’7 N/Aâˆ’2 is a constant sometimes called the vacuum
permeability.

284
6. Applications of Manifolds to Physics
6.4.2
Einstein Field Equations
The Einstein ï¬eld equations (EFE) are the heart of general relativity. They
stem from the juxtaposition of the two following principles:
1. Every aspect of gravity is merely a description of the spacetime ge-
ometry.
2. Mass (energy) is the source of gravity.
The metric tensor
  encapsulates all the information about the geom-
etry of the spacetime. From
  one constructs the Levi-Civita connection
âˆ‡, the (1, 3)-Riemann curvature tensor
, the Ricci curvature tensor
,
and the scalar curvature function R, deï¬ned in Chapter 5. (Note: In math
texts on Riemannian geometry, one often denotes by S the scalar curvature
while texts on general relativity invariably denote it by R. Using the bold
font
 to indicate the curvature tensor alleviates any confusion between
the scalar and tensor curvature.)
On the other hand, the stress-energy tensor describes the spacetime
content of mass-energy. In fact, any observer with 4-velocity
 measures
the density of mass-energy as
Ï =
 Â·
	 Â·
 = TÎ±Î²uÎ±uÎ².
In order to put together the two above principles, we should be able to
write the tensor
	 exclusively in terms of the components of the metric
tensor
 . The conservation of energy states that div
	 = 0. Also, if
	 is to
serve as a measure of the curvature of spacetime, it should explicitly involve
only components of
 and of
  (no derivatives of any of these terms) and
it should be linear in the components of
. It turns out that under these
restrictions, there are only a few options for a geometric description of
	.
In Problem 6.4.2, one shows that for purely mathematical reasons, these
constraints impose that
TÎ±Î² = C

RÎ±Î² âˆ’1
2RgÎ±Î² + Î›gÎ±Î²
	
,
where RÎ±Î² are the components of the Ricci curvature tensor, R is the scalar
curvature, and Î› and C are real constants. This leads to Einsteinâ€™s ï¬eld
equations.
Let
 be the Einstein curvature tensor deï¬ned in Deï¬nition 5.4.9. Gen-
eral relativity is summarized in this following equation. The presence of

6.4. A Brief Introduction to General Relativity
285
mass-energy deforms spacetime according to
 + Î›   = 8Ï€G
c4
	
in SI units,
(6.44)
where G = 6.67 Ã— 10âˆ’11 m3sâˆ’2kgâˆ’1 is the gravity constant and Î› is the
cosmological constant. If in addition, one assumes that empty (devoid of
energy) spacetime is ï¬‚at, then
 = 8Ï€G
c4
	.
(6.45)
Equation (6.45) is called collectively the Einstein ï¬eld equations (EFE),
and the formulas in Equation (6.44) are the Einstein ï¬eld equations with
cosmological constant. These equations are as important in astrophysics
as Newtonâ€™s second law of motion is in classic mechanics.
In Equation (2) of Einsteinâ€™s original paper on general relativity [19],
Einstein made the assumption that
 vanishes when spacetime is empty
of mass-energy. This corresponds to the assumption that Î› = 0. However,
Equation (6.45) predicts a dynamic universe. This result did not appeal
to Einstein and, at the time, there existed no astronomical evidence to
support this. In 1917, he introduced the constant Î› because it allows for a
static universe. Physically, Î› Ì¸= 0 would imply the presence of an otherwise
unexplained force that counteracts gravity or a sort of negative pressure.
When Hubble discovered that the universe is expanding, the cosmolog-
ical constant no longer appeared to be necessary and many physicists did
away with it. In fact, in his autobiography, George Gamow relays that
Einstein told Gamow that he considered the introduction of the cosmolog-
ical constant as â€œthe biggest blunder of my lifeâ€ [25]. However, as of the
writing of this book, the possibility of a small nonzero Î› has resurfaced and
regularly enters into the debates around the current most vexing problems
in physics, namely, the nature of dark energy and the eï¬€ort to unify gravity
and quantum mechanics.
One should note the Einstein ï¬eld equations (EFE) are very compli-
cated. Finding a solution to the EFE means ï¬nding the metric tensor
 that satisï¬es Equation (6.45). Thus, in their most general form, the EFE
consist of 10 second-order, nonlinear, partial diï¬€erential equations of 10
functions gij(x0, x1, x2, x3), with 0 â‰¤i â‰¤j â‰¤3. Determining the trajec-
tory of a particle or of radiation amounts to determining the geodesics in
this metric. Surprisingly, under some circumstances, especially scenarios
that involve a high level of symmetry, it is possible to provide an exact
solution.

286
6. Applications of Manifolds to Physics
One cannot describe in only a few words the full consequences of the
Einstein ï¬eld equations in Equations (6.45) or (6.44). Whole books have
been written about consequences of solutions to this equation that deviate
from Newtonian mechanics: space and time form a single spacetime unit
that is in general curved; light is bent by the presence of massive objects;
stars may collapse and become black holes, which is the name given for
singularities on the spacetime manifold; the universe as a whole expands;
gravity aï¬€ects the frequency of light . . . .
Physicists have been able to
experimentally verify many of the predictions in favor of general relativ-
ity over Newtonian mechanics. Though any theory that can unify gravity
and quantum mechanics must be able to derive Equation (6.44) and hence
generalize relativity, the Einstein ï¬eld equations have been repeatedly sup-
ported by observation, and they are still held to accurately model nature
at our current possible levels of observation.
6.4.3
The Schwarzschild Metric
We ï¬nish this section with one of the earliest proven and most important
consequences of general relativity, i.e., the Schwarzschild metric, which is
an exact solution to Einsteinâ€™s ï¬eld equations.
One of the main contexts in which one can expect to see the eï¬€ects of
general relativity against Newtonian mechanics is in the context of astron-
omy. The simplest dynamical problem in astronomy involves calculating
the orbit of a single planet around the sun. One can hope that the EFE
for the eï¬€ect of the sun on the space around it will become simple under
the following two assumptions (approximations):
1. The sun is a spherically symmetric distribution of mass-energy den-
sity.
2. Outside of the sun, the stress-energy tensor should vanish.
The spherical symmetry implies that the components of the metric tensor
should be given as functions of x0 and r alone, where r2 = (x1)2 + (x2)2 +
(x3)2.
Since we are looking only for solutions outside the sun, we are
looking for solutions in a vacuum. Thus
	 = 0, from which we deduce that
 = 0. Thus, Tr
  = 0. However,
Tr
  = Tr
 
 âˆ’1
2R
 	
= R âˆ’1
2R Â· 4 = âˆ’R,
where this follows from Equation (5.43) and the fact thatTr
   =dim M=4.
Thus, R = 0 and the fact that
 = 0 implies that we are looking for

6.4. A Brief Introduction to General Relativity
287
spherically symmetric solutions to the equation
RÎ±Î² = 0.
Since we are looking for solutions in a vacuum, it seems as though we have
lost information, but, as we shall see, that is not the case.
The following derivation follows the treatment in [51]. We leave some
of the detailed work as exercises for the reader.
A judicious choice of coordinates and a few coordinate transformations
will simplify the problem. We ï¬rst start with the coordinates
(Â¯x0, x1, x2, x3) = (Â¯x0, Â¯r, Î¸, Ï•),
where Â¯x0 = cT for some timelike variable T , Â¯r2 = (x1)2 + (x2)2 + (x3)2
and where Î¸ and Ï• are given in the physics style of deï¬ning spherical
coordinates, i.e., so that Ï• is the longitudinal angle and Î¸ is the latitude
angle measured down from a â€œpositiveâ€ vertical direction. We know that
the standard line element in spherical coordinates is
ds2 = dÂ¯r2 + Â¯r2dÎ¸2 + Â¯r2 sin2 Î¸dÏ•2.
Though we are not working with the Euclidean metric, spherical symmetry
does imply that the metric tensor in the space coordinates is orthogonal
and that no perpendicular direction to the radial direction is singled out.
Thus, the metric tensor has the form
gÎ±Î² =
â›
âœ
âœ
â
g00(Â¯x0, Â¯r)
g01(Â¯x0, Â¯r)
g02(Â¯x0, Â¯r)
g03(Â¯x0, Â¯r)
g10(Â¯x0, Â¯r)
g11(Â¯x0, Â¯r)
0
0
g20(Â¯x0, Â¯r)
0
f(Â¯x0, Â¯r)2
0
g30(Â¯x0, Â¯r)
0
0
f(Â¯x0, Â¯r)2 sin2 Î¸
â
âŸ
âŸ
â ,
where f is any smooth function. We actually have some choice on Î¸ and
Ï• because they are usually given in reference to some preferred x-axis and
z-axis. We choose Î¸ and Ï• (which may change over time with respect to
some ï¬xed Cartesian frame) so that g20 = g30 = 0, and then the metric
looks like
gÎ±Î² =
â›
âœ
âœ
â
g00(Â¯x0, Â¯r)
g01(Â¯x0, Â¯r)
0
0
g10(Â¯x0, Â¯r)
g11(Â¯x0, Â¯r)
0
0
0
0
f(Â¯x0, Â¯r)2
0
0
0
0
f(Â¯x0, Â¯r)2 sin2 Î¸
â
âŸ
âŸ
â .
We make the coordinate transformation r = f(Â¯x0, Â¯r) and all the other co-
ordinates remain the same. In this coordinate system, the metric looks like

288
6. Applications of Manifolds to Physics
gÎ±Î² =
â›
âœ
âœ
â
g00(Â¯x0, r)
g01(Â¯x0, r)
0
0
g10(Â¯x0, r)
g11(Â¯x0, r)
0
0
0
0
r2
0
0
0
0
r2 sin2 Î¸
â
âŸ
âŸ
â .
(6.46)
Finally, we can orthogonalize the metric tensor by a suitable coordinate
transformation of x0 = ct = h(Â¯x0, r), with r staying ï¬xed (see Prob-
lem 6.4.3). Since we know that the metric has index 1, we can write the
metric in the coordinate system (x0, r, Î¸, Ï•) as
gÎ±Î² =
â›
âœ
âœ
â
âˆ’eÎ½(x0,r)
0
0
0
0
eÎ»(x0,r)
0
0
0
0
r2
0
0
0
0
r2 sin2 Î¸
â
âŸ
âŸ
â ,
(6.47)
where Î» and Î½ are smooth functions. The metric in Equation (6.47) is an
orthogonal metric that is spherically symmetric in the space variables.
Using the notation Ë™u = âˆ‚u/âˆ‚x0 and uâ€² = âˆ‚u/âˆ‚r, one can show (see
Problem 6.4.4) that the independent nonzero Christoï¬€el symbols for the
Levi-Civita connection are
Î“0
00 = 1
2 Ë™Î½, Î“0
01 = 1
2Î½â€²,
Î“0
11 = 1
2
Ë™Î»eÎ»âˆ’Î½, Î“1
00 = 1
2Î½â€²eÎ½âˆ’Î»,
Î“1
01 = 1
2
Ë™Î», Î“1
11 = 1
2Î»â€²,
Î“1
22 = âˆ’reâˆ’Î»,
Î“1
33 = âˆ’r sin2 Î¸eâˆ’Î», (6.48)
Î“2
12 = 1
r ,
Î“2
33 = âˆ’sin Î¸ cos Î¸,
Î“3
13 = 1
r ,
Î“3
23 = cot Î¸.
Though it is a little long to calculate (see Problem 6.4.5), one can then
determine that the only nonzero components of the Ricci tensor are
R00 = eÎ½âˆ’Î»
Î½â€²â€²
2 + (Î½â€²)2
4
âˆ’Î½â€²Î»â€²
4
+ Î½â€²
r
	
âˆ’
Â¨Î»
2 âˆ’
Ë™Î»2
4 +
Ë™Î» Ë™Î½
4 ,
R01 =
Ë™Î»
r ,
R11 = âˆ’Î½â€²â€²
2 âˆ’(Î½â€²)2
4
+ Î½â€²Î»â€²
4
+ Î»â€²
r + eÎ»âˆ’Î½
 Â¨Î»
2 +
Ë™Î»2
4 âˆ’
Ë™Î» Ë™Î½
4

,
R22 = âˆ’eâˆ’Î» 
1 + r
2(Î½â€² âˆ’Î»â€²)

+ 1,
R33 = sin2 Î¸ R22.
(6.49)
Since we are trying to solve RÎ±Î² = 0, we obtain conditions on the
functions Î» and Î½. Since R01 = 0, we deduce immediately that Ë™Î» = 0,

6.4. A Brief Introduction to General Relativity
289
which means that Î» is a function of r alone. Also, since âˆ‚R22/âˆ‚t = 0, we
ï¬nd that âˆ‚Î½â€²/âˆ‚t = 0. Therefore, we can write the function Î½ as
Î½ = Î½(r) + f(t)
for some function f(t).
We now make one ï¬nal coordinate change. In the metric line element, t
appears only in the summand eÎ½d(x0)2 = eÎ½(r)ef(t)d(ct)2. So by choosing
the variable Â¯t in such a way that
dÂ¯t
dt = ef(t)/2
and then renaming Â¯t to just t, we obtain a metric which is independent
of any timelike variable. (The variable Â¯t, relabeled as t, is not necessarily
time anymore so one cannot necessarily call the solution static.)
We can now assume there is no t dependence. Simplifying the expression
R00 + eÎ½âˆ’Î»R11 leads to
1
r (Î»â€² + Î½â€²) = 0.
This implies that Î»(r) = âˆ’Î½(r) + C for some constant C. Without loss of
generality, we can assume that C = 0 since we have not speciï¬ed Î» or Î½.
Thus, we set Î»(r) = âˆ’Î½(r). Then R22 = 0 in Equation (6.49) implies that
eâˆ’Î»(1 âˆ’rÎ»â€²) = 1.
Now setting h(r) = eâˆ’Î»(r), this last equation becomes
hâ€² + h
r = 1
r .
This is a linear, ï¬rst-order, ordinary, diï¬€erential equation whose general
solution is
h(r) = eâˆ’Î»(r) = 1 âˆ’2M
r ,
where M is a constant of integration. One can verify directly that R11 =
R00 = 0 in Equation (6.49) are satisï¬ed by this solution and therefore give
no additional conditions.
Therefore, the spherically symmetric vacuum
solution to the EFE gives a metric with line element
âˆ’ds2 = âˆ’

1 âˆ’2M
r
	
c2dt2 +

1 âˆ’2M
r
	âˆ’1
dr2 + r2dÎ¸2 + r2 sin2 Î¸dÏ•2.
(6.50)

290
6. Applications of Manifolds to Physics
This is called the Schwarzschild metric. This metric provided the ï¬rst exact
solution to the Einstein ï¬eld equations.
Though it is still complicated,
this metric can be compared in fundamental importance to the solution
in mechanics to the diï¬€erential equations d2âƒ—x/dt2 = âˆ’mâƒ—g. Many of the
veriï¬able predictions of general relativity arise from this metric.
In order to understand Equation (6.50), one needs to have some sense of
the meaning of the constant M. Obviously, if M = 0, then the Schwarzschild
metric is simply the ï¬‚at Minkowski metric for spacetime.
To derive an interpretation for M Ì¸= 0, we study some consequences
of Equation (6.50) for small velocities. If the velocity v is much smaller
than the speed of light, i.e., v â‰ªc, then special relativity tells us that
proper time is approximately coordinate time Ï„ âˆ¼= t = x0/c. Furthermore,
from Equation (6.36) we can approximate the velocity of any particle as
 = (c, 0, 0, 0). Plugging these into the geodesic equation
d2xi
dÏ„ 2 = âˆ’Î“i
jk
dxj
dÏ„
dxk
dÏ„ ,
we obtain the approximate relationship
d2xi
dt2 = âˆ’Î“i
00c2 = c2
2 gil âˆ‚g00
âˆ‚xl ,
where the second equality follows from the formula for Christoï¬€el symbols
and the fact that the functions gij are not x0 dependent. However, since
  is diagonal and g00 depends only on r, we ï¬nd that the only nonzero
derivative is
d2r
dt2 = âˆ’c2
2

1 âˆ’2M
r
	 âˆ‚
âˆ‚r

1 âˆ’2M
r
	
= âˆ’Mc2
r2

1 âˆ’2M
r
	
.
We must compare this to the formula for gravitational attraction in New-
tonian mechanics, namely,
d2r
dt2 = âˆ’GMS
r2
where MS is the mass of the attracting body (and G is the gravitational
constant).
Thus, we ï¬nd as a ï¬rst approximation that the constant of
integration M is
M âˆ¼= GMS
c2
.

6.4. A Brief Introduction to General Relativity
291
Hence, M is a constant multiple of the mass of the attracting body. The
constant 2M has the dimensions of length, and one calls rG = 2M the
Schwarzschild radius. The formula for it is
rG = 2G
c2 Â· MS = (1.48 Ã— 10âˆ’27 m/kg)MS.
The Schwarzschild radius is 2.95 km for the sun and 8.8 mm for the
Earth. Evidently, for spherically symmetric objects that one encounters
in common experience, the Schwarzschild radius is much smaller than the
objectâ€™s actual radius. In fact, if a spherically symmetric object has radius
RS and mass MS, then
rG < RS â‡â‡’2G
c2 MS < RS.
A sphere with rG > RS would need to have an enormous density. Fur-
thermore, this situation would seem to be physically impossible for the
following reason. It is understood that the Schwarzschild metric holds only
in the vacuum outside of the body (planet or star). However, if rG > RS,
then the Schwarzschild radius would correspond to a sphere outside of the
spherical body where the Schwarzschild metric has a singularity g11 = 1/0.
For this reason, some physicists initially claimed this to be a result of the
successive approximations or simply a physically impossible situation.
The history of science has occasionally shown that singularities in the
equations do not immediately imply that the scenario is impossible. The
possibility of traveling at the speed of sound was thought to be impos-
sible because of the consequences for the Doppler eï¬€ect equation. Now,
military jets regularly ï¬‚y faster than the speed of sound. Similarly, in re-
cent decades, physicists regularly study objects considered to be so dense
that 2GMS/c2 > RS. Such objects are called black holes. For a time,
the existence of black holes remained in the realm of hypothesis, but now
astronomers are convinced they have observed many such objects, and as-
trophysicists have worked out many of their dynamic properties.
For many, the concept of more than three dimensions, let alone a curved
spacetime, is literally unimaginable. One might argue that this is a con-
sequence of Euclidâ€™s legacy and the Euclidean inï¬‚uence on mathematical
education. However, like quantum mechanics which has proven revolution-
ary and incredibly fruitful despite the advanced level of the mathematics
that govern it, so general relativity and the diï¬€erential geometry that un-
derlies it hold a central place in modern physics.

292
6. Applications of Manifolds to Physics
Problems
6.4.1. Show that we can rephrase the explanation for Equation (6.38) by saying
that for any three vectors A, B, and C in TP M,
(â‹†P )(A, B, C) = Vol
 (â™¯
P , A, B, C),
where Vol
  is the volume form with respect to the metric
.
6.4.2. Let
 be a symmetric tensor of type (0, 2), constructible from the full
curvature tensor
 and the metric tensor
 and linear in
.
(a) Show that
 can only have the form
LÎ±Î² = aRÎ±Î² + bRgÎ±Î² + Î»gÎ±Î²,
where RÎ±Î² are the components of the Ricci curvature tensor, R is
the scalar curvature, and a, b, and Î» are real constants.
(b) Show that div
 = 0 if and only if b = âˆ’1
2a.
(c) If gÎ±Î² = Î·Î±Î², i.e., one is in ï¬‚at spacetime, show that
 = 0 if and
only if Î» = 0.
6.4.3. Find the â€œsuitableâ€ coordinate transformation h that allows one to pass
from Equation (6.46) to Equation (6.47).
6.4.4. Prove that Equation (6.48) is correct.
6.4.5. Prove Equation (6.49).
6.4.6. Light Propagation in the Schwarzschild Metric. In the Schwarzschild metric,
light travels along the null-geodesics, i.e., where ds2 = 0.
(a) Explain why setting Î¸ = 0 does not lose any generality to ï¬nding the
null-geodesics.
(b) Prove that if one sets u = 1/r, then ds2 = 0 implies that
d2u
dÏ•2 + u = 3Mu2.
(6.51)
(c) Deduce that in the vicinity of a black hole, light travels in a circle
precisely at the radius r = 3
2rG.
(d) Solve Equation (6.51) for M = 0. This corresponds to empty space
(no mass present). Call this solution u0(Ï•).
(e) (ODE) Now look for general solutions u to Equation (6.51) by setting
u = u1 + u0. Then u1(Ï•) must satisfy
d2u1
dÏ•2 + u1 = 3M
R0 sin2(Ï• âˆ’Ï•0).
Solve this diï¬€erential equation explicitly, and ï¬nd the complete so-
lution to Equation (6.51).

6.4. A Brief Introduction to General Relativity
293
R0
Ï•âˆ
r = RS/ sin Ï•
Figure 6.7. Deviation of light near a massive body.
(f) In the complete solution, show that M = 0 (empty space) corre-
sponds to traveling along a straight line u =
1
R0 sin(Ï• âˆ’Ï•0), where
R0 is the distance from the line to the origin.
(g) Show that the general solution to Equation (6.51) is asymptotically
a line.
(h) We now consider Eddingtonâ€™s famous experiment to measure the de-
viation of light by the sun. Consider a geodesic G in the Schwarzschild
metric that passes right alongside the sun, i.e., passes through the
point r = RS and Ï• = 0. Deï¬ne Ï•âˆas the limiting angle of deviation
between the line r = RS/ sin Ï• and the geodesic G (see Figure 6.7).
The sun bends the light away from the straight line by a total of
2Ï•âˆ. Using (at a judicious point) the approximation that sin Ï• âˆ¼= Ï•,
prove that the total deviation of light is
2Ï•âˆ= 4GMS
RSc2 ,
where MS is the mass of the sun and RS is the sunâ€™s radius.


APPENDIX
A
Point Set Topology
A.1
Introduction
Though mathematicians, when developing a new area of mathematics, may
deï¬ne and study any object as they choose, the â€œnaturalâ€ notion of a sur-
face requires a far more intricate deï¬nition than does a curve in the theory
of diï¬€erential geometry. The deï¬nition for a regular curve in R2, which im-
mediately generalizes to parametrized curves in Rn, reï¬‚ects the fact that
the most general curve in the plane or in space can be given entirely by a
single n-tuple of continuous coordinate functions âƒ—x(t) = (x1(t), . . . , xn(t))
that satisfy the regularity condition. On the other hand, even for simple
surfaces the situation becomes more complicated. Example 3.1.4 showed
that one needs at least two parametrizations âƒ—X : U âŠ‚R2 â†’R3 to cover
the sphere according to the requirements of a manifold (or regular surface).
Though at ï¬rst somewhat unwieldy, the deï¬nitions for regular surfaces and
for a diï¬€erential manifold are necessary for the concepts in diï¬€erential ge-
ometry to appropriately generalize both the theory of calculus of functions
and the local theory of curves.
On the other hand, numerous concepts introduced in basic calculus
courses can be generalized not by formulating more constrained deï¬nitions
but by expanding the context in which one deï¬nes these concepts. As an
example of this contrast, consider a connected parametrized surface S in
R3. The formula for the distance between two points P and Q on S may
be very complicated, and yet this distance is well deï¬ned as
D(P, Q) = glb{length of C | C is a curve on S connecting P and Q},
where glb stands for the greatest lower bound. That a greatest lower bound
exists for all subsets of Râ‰¥0 is a property of the real numbers. Furthermore,
one can make sense of many common notions of geometry in Euclidean
space Rn in a wider context simply if one possesses the notion of distance
at oneâ€™s disposal.
295

296
A. Point Set Topology
The ï¬rst wider context presented in this appendix is the category of
metric spaces. After introducing the axioms, some basic theorems, and a
few examples of metric spaces, we move on to consider the most general
context for geometry: topological spaces. Though topology is a very wide
ï¬eld of mathematics in its own right, this appendix presents just the basic
notions that support this bookâ€™s presentation of diï¬€erential geometry. We
refer the reader to [26] for a readable and thorough introduction to point set
topology and to [41] and [2] for an introduction to topology that includes
homology, the fundamental group, algebraic topology, and the classiï¬cation
of surfaces.
A.2
Metric Spaces
A.2.1
Metric Spaces: Deï¬nition
A metric space is a set that comes with the notion of â€œclosenessâ€ between
two points. Since one cannot deï¬ne geometric closeness arbitrarily, we im-
pose a few numerical conditions that mimic geometry in Euclidean spaces.
Deï¬nition A.2.1. Let X be any set. A metric on X is a function D : XÃ—X â†’
Râ‰¥0 such that
1. equality: D(x, y) = 0 if and only if x = y;
2. symmetry: D(x, y) = D(y, x) for all x, y âˆˆX;
3. triangle inequality: D(x, y) + D(y, z) â‰¥D(x, z) for all x, y, z âˆˆX.
A pair (X, D) where X is a set with a metric D is called a metric space.
Example A.2.2 (Euclidean Spaces).
Euclidean spaces Rn are metric spaces
where the metric D is the usual Euclidean distance formula between two
points, namely, if P = (p1, p2, . . . , pn) and Q = (q1, q2, . . . , qn), then
D(P, Q) =
:
;
;
<
n

i=1
(qi âˆ’pi)2.
Note that many notions in usual geometry (circles, parallelism, midpoint,
etc.)
depend vitally on this particular distance formula.
Furthermore,
notice that if n = 1, this formula simpliï¬es to the usual distance formula
on the real line R, namely,
d(x, y) = |y âˆ’x|.

A.2. Metric Spaces
297
To prove that (Rn, D) is indeed a metric space, one must verify the
three axioms in Deï¬nition A.2.1. The ï¬rst holds because
D(P, Q) = 0 â‡â‡’
n

i=1
(qi âˆ’pi)2 = 0,
which is equivalent to (qi âˆ’pi)2 = 0 for all 1 â‰¤i â‰¤n, and hence qi = pi for
all 1 â‰¤i â‰¤n. The second obviously holds, and we prove the third axiom
as follows. Since D(P, Q), D(Q, R), and D(P, R) are positive we have
D(P, Q) + D(Q, R) â‰¥D(P, R)
â‡â‡’
:
;
;
<
n

i=1
(qi âˆ’pi)2 +
:
;
;
<
n

i=1
(ri âˆ’qi)2 â‰¥
:
;
;
<
n

i=1
(ri âˆ’pi)2
â‡â‡’
n

i=1
(qi âˆ’pi)2 +
n

i=1
(ri âˆ’qi)2
+ 2
:
;
;
<
n

i=1
(qi âˆ’pi)2
:
;
;
<
n

i=1
(ri âˆ’qi)2 â‰¥
n

i=1
(ri âˆ’pi)2
â‡â‡’
2
:
;
;
<
n

i=1
(qi âˆ’pi)2
:
;
;
<
n

i=1
(ri âˆ’qi)2 â‰¥2
n

i=1
(ri âˆ’qi)(qi âˆ’pi).
Regardless of the sign on the right-hand side, one can show that this last
line is equivalent to
 n

i=1
(qi âˆ’pi)2
  n

i=1
(ri âˆ’qi)2

âˆ’
 n

i=1
(ri âˆ’qi)(qi âˆ’pi)
2
â‰¥0
â‡â‡’

1â‰¤i<jâ‰¤n
((qi âˆ’pi)(rj âˆ’qj) âˆ’(qj âˆ’pj)(ri âˆ’qi))2 â‰¥0.
Since the conclusion is true and since all statements are equivalences, the
third axiom of a metric holds. Of course, the triangle inequality is used in
Deï¬nition A.2.1 precisely because it is one of the fundamental properties of
the Euclidean distance function. However, we needed to verify the triangle
inequality based on the formula given for the Euclidean metric, and the
example illustrates what is required in order to establish the three axioms.
Example A.2.3. There exists, in fact, a variety of other metrics on Euclidean
space, and we illustrate a few of these alternate metrics for R2. Let P =

298
A. Point Set Topology
(x1, y1) and Q = (x2, y2).
We leave to the reader the proofs that the
following functions are metrics on R2:
D1(P, Q) = |x2 âˆ’x1| + |y2 âˆ’y1|,
D3(P, Q) =
3
|x2 âˆ’x1|3 + |y2 âˆ’y1|3 ,
Dâˆ(P, Q) = max {|x2 âˆ’x1|, |y2 âˆ’y1|} .
Example A.2.4 (Six Degrees of Kevin Bacon). A humorous example of a metric
space is the set of syndicated actors A equipped with the function D deï¬ned
as follows. Create a simple graph using A as the set of vertices and place
an edge between two actors a1 and a2 if they acted in a movie together.
D(a1, a2) is deï¬ned as the minimum number of edges it takes to create a
path connecting a1 and a2. With the additional assumption that D(a, a)=0
for all a âˆˆA, shows that the pair (A, D) is a metric space.
The party game called â€œSix Degrees of Kevin Baconâ€ asks players to
ï¬nd the shortest path (and hence the distance D) between any actor and
the actor Kevin Bacon.
Having a notion of distance in a set, we may want to consider the subset
of all points that are within a certain range of a ï¬xed point.
Deï¬nition A.2.5. Let (X, D) be a metric space, and let p âˆˆX be a point.
We deï¬ne the open ball of radius r around p as the set
Br(p) = {y âˆˆX | D(p, y) < r}.
The reader who is new to topology should note that the terminology
â€œopen ballâ€ might be initially misleading since the set Br(p) only takes the
shape of an actual ball (disk, sphere, etc.) in the case of the Euclidean
metric on Rn.
Example A.2.6. Consider the metric D1 from Example A.2.3 above, and let
O = (0, 0). The ball of radius 1 around the origin O using the metric D1
is the set
B1(O) = {(x, y) âˆˆR2 | |x| + |y| < 1}.
Notice that the equation |x| + |y| = 1 has a locus that is symmetric about
the x-axis and about the y-axis so to determine its locus we only need to
see what happens in the ï¬rst quadrant. In the ï¬rst quadrant, the equation
|x| + |y| = 1 becomes x + y = 1, which is a line segment from (1, 0)
to (0, 1).
Thus, the open ball B1(O) is the open square with vertices
{(1, 0), (0, 1), (âˆ’1, 0), (0, âˆ’1)}.

A.2. Metric Spaces
299
a
b
f(x)
Figure A.1. Example A.2.7: a collar around f(x).
Example A.2.7. Metric spaces can encompass a much wider range than the
above examples have illustrated so far.
Let X = C0([a, b]) be the set
of continuous real functions deï¬ned on the closed interval [a, b], or let
X = Fbounded([a, b]) be the set of all bounded functions on interval [a, b].
(A theorem of calculus tells us that any function f continuous over [a, b] is
bounded so C0([a, b]) âŠ‚Fbounded([a, b]).) Deï¬ne the function D : X Ã—X â†’
Râ‰¥0 as
D(f, g) = lub{|g(x) âˆ’f(x)| : x âˆˆ[a, b]},
where lub refers to the least upper bound of a subset of reals.
The open ball of radius r around a function f is the set of all the
functions g âˆˆX such that |f(x) âˆ’g(x)| < r for all x âˆˆ[a, b], or in other
words,
f(x) âˆ’r < g(x) < f(x) + r
for all x âˆˆ[a, b].
In this context, we call the region f(x) âˆ’r < y < f(x) + r with a â‰¤x â‰¤b
the r-collar of f(x). (See Figure A.1.)
In a metric space (X, D), having the notion of distance between two
points allows one to also deï¬ne the notion of distance between two subsets
of X.
Deï¬nition A.2.8. Let (X, D) be a metric space, and let A and B be two
subsets of X. The distance between A and B is
D(A, B) = glb{D(a, b) | a âˆˆA, b âˆˆB},
where glb stands for the greatest lower bound. The distance between a
point x âˆˆX and a subset A âŠ‚X is D({x}, A).

300
A. Point Set Topology
This deï¬nition of distance between subsets does not establish a metric
on P(X), the set of subsets of X. Indeed, for any two subsets A and B in X
such that A Ì¸= B and A âˆ©B Ì¸= 0, the distance between them is D(A, B) =
0, and hence, even the ï¬rst axiom for metric spaces fails.
However, in
geometry, the notion of distance between sets, especially disjoint sets, is
quite useful.
Deï¬nition A.2.9. Let (X, D) be a metric space, and let A be any set. We
deï¬ne the diameter of A to be
diam A = lub {D(x, y) | x, y âˆˆA}.
A subset A of X is called bounded if diam A < âˆ.
A.2.2
Open and Closed Sets
In the study of real functions, one often must refer to subsets of R, and one
also uses the notions of open intervals and closed intervals. In this context,
one simply says that a bounded interval is open if it does not include its
endpoints and closed if it includes both of them, and a similar deï¬nition
is given for an unbounded interval. Then a subset of R is called open if
it is a disjoint union of open intervals. In contrast, in Rn or in a metric
space, given the wide range of possibilities for the shape of sets, one cannot
legitimately talk about endpoints, though one could attempt to make sense
of the concept of â€œincluding its boundary points.â€ Regardless, a diï¬€erent
deï¬nition for openness and closedness is required. Here is what works.
Deï¬nition A.2.10. Let (X, D) be a metric space. A subset U âŠ†X is called
open if for all p âˆˆS there exists r > 0 such that the open ball Br(p) âŠ‚U.
A subset F âŠ†X is called closed if the complement F = X âˆ’F is open.
Intuitively, this deï¬nition states that a subset U of a metric space is
called open if around every point there is an open ball, perhaps with a
small radius, that is completely contained in U. Note that one may wish
to consider more than one metric at the same time on the same set X. In
this case, we will refer to a D-open set.
Proposition A.2.11. Let (X, D) be a metric space. Then
1. X and âˆ…are both open;
2. the intersection of any two open sets is open;
3. the union of any collection of open sets is open.

A.2. Metric Spaces
301
Proof: For part 1, if p âˆˆX, then any open ball satisï¬es Br(p) âŠ‚X. Also,
since âˆ…is empty, the criteria for openness holds trivially for âˆ….
To prove part 2, let U1 and U2 be two open sets and let p âˆˆU1 âˆ©U2.
Since U1 and U2 are open, there exist r1 and r2 such that Br1(p) âŠ‚U1
and Br2(p) âŠ‚U2. Take r = min(r1, r2). Then Br(p) âŠ†Br1(p) âŠ‚U1 and
Br(p) âŠ†Br2(p) âŠ‚U2 so Br(p) âŠ‚U1 âˆ©U2. Thus, U1 âˆ©U2 is open.
Finally, consider a collection of open sets UÎ± where Î± is an index taken
from some indexing set I, which is not necessarily ï¬nite. Deï¬ne
U =
.
Î±âˆˆI
UÎ± .
For any p âˆˆU, there exists some Î±0 âˆˆI such that p âˆˆUÎ±0. Since UÎ±0
is open, there exists r such that Br(p) âŠ‚UÎ±0, and thus, Br(p) âŠ‚U.
Consequently, U is open.
â–¡
Using Proposition A.2.11(2), it is easy to show that any intersection of
a ï¬nite number of open sets is again open. In contrast, part 3 states that
the union of any collection of open subsets of X is again open, regardless
of whether this collection is ï¬nite or not. This diï¬€erence between unions
and intersections of open sets is not an insuï¬ƒciency of this proposition but
rather a fundamental aspect of open sets in a metric space. In fact, as the
following simple example shows, the inï¬nite intersection of open sets need
not be open.
Example A.2.12. For each integer n â‰¥1, consider the open intervals In =
(0, 1 + 1
n), and deï¬ne
S =
âˆ
=
n=1
In .
Obviously, In+1 âŠŠIn, and so the intervals form a decreasing, nested chain.
Since limnâ†’âˆ1
n = 0, we expect S to contain (0, 1), but we must determine
whether it contains anything more. If r > 1, then if n is large enough so
that 1
n < r âˆ’1, we have r /âˆˆIn. On the other hand, for all n âˆˆZâ‰¥1, 1
n > 0,
so 1 < 1 + 1
n. Hence, 1 âˆˆIn for all n âˆˆZâ‰¥1, and thus, 1 âˆˆS. Thus, we
conclude that S = (0, 1]. This shows that the inï¬nite intersection of open
sets need not be open.
Example A.2.13. As a more down-to-earth example, we wish to show that ac-
cording to this deï¬nition, the set S =
#
(x, y) âˆˆR2 | 0<x<1 and 0<y<1}
is open in R2 equipped with the Euclidean metric. Let p = (x0, y0) be a
point in S. Since p âˆˆS, we see that x0 > 0, 1 âˆ’x0 > 0, y0 > 0, and

302
A. Point Set Topology
p
(a) Example A.2.13
p
(b) Example A.2.14
Figure A.2. Open and not open squares.
1âˆ’y0 > 0. Since the closed distance from a point p to any line L is along a
perpendicular to L, then the closest distance between p and any of the lines
x = 0, x = 1, y = 0, and y = 1 is min{x0, 1 âˆ’x0, y0, 1 âˆ’y0}. Consequently,
if r is any positive real number such that
r â‰¤min{x0, 1 âˆ’x0, y0, 1 âˆ’y0},
then Br(p) âŠ‚S. (See Figure A.2(a).)
Example A.2.14. In contrast to the previous example, consider the set
T = {(x, y) âˆˆR2 | 0 â‰¤x < 1 and 0 < y < 1},
where again we assume R2 is equipped with the Euclidean metric. The work
in Example A.2.13 shows that for any point p = (x0, y0), with 0 < x0 < 1
and 0 < y0 < 1, there exists a positive radius r such that Br(p) âŠ‚S âŠ‚T .
Thus, consider now points p âˆˆT with coordinates (0, y0). For all positive r,
the open ball Br(p) contains the point (âˆ’r/2, y0), which is not in T . Hence,
no open ball centered around points (0, y0) is contained in T , and hence T ,
is not open. (See Figure A.2(b).)
It is very common in proofs and deï¬nitions that rely on topology to
refer to an open set that contains a particular point. Here is the common
terminology.
Deï¬nition A.2.15. Let p be a point in a metric space (X, D). An open neigh-
borhood (or simply neighborhood) of p is any open set of X that contains p.

A.2. Metric Spaces
303
Closed sets satisfy properties quite similar to those described in Propo-
sition A.2.11, with a slight but crucial diï¬€erence.
Proposition A.2.16. Let (X, D) be a metric space. Then
1. X and âˆ…are both closed;
2. the union of any two closed sets is closed;
3. the intersection of any collection of closed sets is closed.
Because a set is deï¬ned as closed if its complement is open and because
of DeMorgan laws for sets, this proposition is actually a simple corollary of
Proposition A.2.11.
Therefore, we leave the details of the proof to the
reader.
Note that in any metric space, the whole set X and the empty set âˆ…are
both open and closed. Depending on the particular metric space, these
are not necessarily the only subsets of X that are both open and closed.
Proposition A.2.17. Let (X, D) be a metric space, and let x âˆˆX. The sin-
gleton set {x} is a closed subset of X.
Proof: To prove that {x} is closed, we must prove that X âˆ’{x} is open.
Let y be a point in X âˆ’{x}. Since x Ì¸= y, by the axioms of a metric space,
D(x, y) > 0. Let r =
1
2D(x, y). The real number r is positive, and we
consider the open ball Br(y).
Since D(x, y) > r, then x /âˆˆBr(y), and
hence, Br(y) âŠ‚X âˆ’{x}. Hence, we have shown that X âˆ’{x} is open
and thus that {x} is closed.
â–¡
The notion of distance between sets provides an alternate characteri-
zation of closed sets in metric spaces. Recall that for any subset A âŠ‚X,
x âˆˆA implies that D(x, A) = 0. The following proposition shows that the
converse holds precisely for closed sets.
Proposition A.2.18. Let (X, D) be a metric space. A subset F is closed if and
only if D(x, F) = 0 implies x âˆˆF.
Proof: Suppose ï¬rst that F is closed. If x /âˆˆF, then x âˆˆX âˆ’F, which
is open, so there exists an open ball Br(x) around x contained entirely in
X âˆ’F. Hence, the distance between any point a âˆˆF and x is greater than
the radius r > 0, thus, D(x, F) > 0, and in particular, D(x, F) Ì¸= 0. Thus,
D(x, F) = 0 implies that x âˆˆF.
We now prove the converse.
Suppose that F is a subset of X such
that D(x, F) = 0 implies that x âˆˆF. Then for all x âˆˆX âˆ’F, we have

304
A. Point Set Topology
D(x, F) > 0. Take the positive number r = 1
2D(x, F), and consider the
open ball Br(x). Let p be any point in F and a any point in Br(x). Form
the triangle inequality
D(p, x) â‰¤D(p, a) + D(a, x) â‡â‡’D(p, a) â‰¥D(p, x) âˆ’D(a, x).
The least possible value for D(p, a) occurs when D(p, x) is the least possible
and when D(a, x) is the greatest possible, that is when D(p, x) = D(x, F)
and D(a, x) = r.
Thus, we ï¬nd that D(p, a) â‰¥r > 0.
Hence, for all
a âˆˆBr(x), we have D(F, a) > 0 and thus Br(x) âˆ©F = âˆ….
Therefore,
Br(x) âŠ‚X âˆ’F so X âˆ’F is open and F is closed.
â–¡
Proposition A.2.18 indicates that given any subset A of a metric space
X, one can obtain a closed subset of X by adjoining all the points with 0
distance from A. This motivates the following deï¬nition.
Deï¬nition A.2.19. Let (X, D) be a metric space, and let A âŠ‚X be any
subset. Deï¬ne the closure of A as
Cl A = {x âˆˆX | D(x, A) = 0}.
Proposition A.2.20. Let (X, D) be a metric space and A any subset of X.
Cl A is the smallest closed set containing A. In other words,
Cl A =
=
AâŠ‚F, F closed
F .
Proof: (Left as an exercise for the reader. See Problem A.2.19.)
â–¡
A.2.3
Sequences
In standard calculus courses, one is introduced to the notion of a sequence
of real numbers along with issues of convergence and limits. The deï¬nition
given in such courses for when we say a sequence converges to a certain
limit formalizes the idea of all terms in the sequence ultimately coming
arbitrarily close to the limit point. Consequently, since limits formalize a
concept about closeness and distance, the natural and most general context
for convergence and limits is in a metric space.
Deï¬nition A.2.21. Let (X, D) be a metric spaces and let {xn}nâˆˆN be a se-
quence in X. The sequence {xn} is said to converge to the limit â„“âˆˆX if
for all Îµ âˆˆR>0 there exists N âˆˆN such that if n > N, then D(xn, â„“) < Îµ
(i.e., xn âˆˆBÎµ(â„“)). If {xn} converges to â„“, then we write
lim
nâ†’âˆxn = â„“.

A.2. Metric Spaces
305
Note that we can restate Deï¬nition A.2.21 to say that {xn} converges
to â„“if for all positive Îµ âˆˆR>0, only ï¬nitely many elements of the sequence
{xn} are not in the open ball BÎµ(â„“).
Example A.2.22. Consider the sequence {xn}nâ‰¥1 in R3 given by xn = (3,
1/(n + 2), 2n/(n + 1)). We prove that {xn} converges to (3, 0, 2). We know
that as sequences of real numbers,
lim
nâ†’âˆ
1
n + 2 = 0
and
lim
nâ†’âˆ
2n
n + 1 = 2.
Pick any positive Îµ. Choose N1 such that n > N1 implies that 1/(n + 2) <
Îµ/
âˆš
2; choose N2 such that n > N2 implies that |2n/(n + 1) âˆ’2| < Îµ/
âˆš
2.
Using the Euclidean distance
D(xn, (3, 0, 2)) =
!
(3 âˆ’3)2 +

1
n + 2 âˆ’0
	2
+
 2n
n + 1 âˆ’2
	2
,
one sees that if n > N = max(N1, N2), then
D(xn, (3, 0, 2)) <

Îµ
2 + Îµ
2 = Îµ.
This proves that lim xn = (3, 0, 2).
Note that we could have proved directly that lim xn = (3, 0, 2) by con-
sidering the limit of D(xn, (3, 0, 2)) as a sequence of real numbers and
proving that this converges to 0.
Example A.2.23. Consider the set X of bounded, real-valued functions de-
ï¬ned over the interval [0, 1] equipped with the metric deï¬ned in Exam-
ple A.2.7. For n â‰¥1, consider the sequence of functions given by
fn(x) =

1 âˆ’nx,
for 0 â‰¤x â‰¤1
n,
0,
for 1
n â‰¤x â‰¤1.
One might suspect that the limit of this sequence fn(x) would be the
function
f(x) =

1,
if x = 0,
0,
for x > 0,
but this is not the case. Let r = 1
4, and consider the r-collar around f(x).
There is no n such that fn(x) lies within the 1
4-collar around f(x). Conse-
quently, fn(x) does not converge to f(x) in the metric space (X, D). Note,
however, that for all x âˆˆ[0, 1], as sequences of real numbers limnâ†’âˆfn(x) =
f(x). We say that fn(x) converges pointwise.

306
A. Point Set Topology
1
1
fn(x)
n = 1
n = 2
n = 3
. . .
(a) Sequence of functions
1
1
fn(x)
(b) 1
4-collar around f(x)
Figure A.3. Example A.2.23.
Proposition A.2.24. Let (X, D) be a metric space. Any sequence {xn} can
converge to at most one limit point.
Proof: Suppose that
lim
nâ†’âˆxn = â„“
and
lim
nâ†’âˆxn = â„“â€².
Let Îµ be any positive real number. There exists N1 such that n > N1
implies that D(xn, â„“) < Îµ
2, and there exists N2 such that n > Ns implies
that D(xn, â„“â€²) < Îµ
2. Thus, taking some n > max(N1, N2), we deduce from
the triangle inequality that
D(â„“, â„“â€²) â‰¤D(xn, â„“) + D(xn, â„“â€²) â‰¤Îµ
2 + Îµ
2 = Îµ.
Thus, since D(â„“, â„“â€²) is less than any positive real number, we deduce that
D(â„“, â„“â€²) = 0 and hence that â„“= â„“â€².
â–¡
In any metric space, there are plenty of sequences that do not converge
to any limit. For example, the sequence {an}nâ‰¥1 of real numbers given by
an = (âˆ’1)n + 1
n does not converge toward anything but, in the long term,
alternates between being very close to 1 and very close to âˆ’1. Referring to
the restatement of Deï¬nition A.2.21, one can loosen the deï¬nition of limit
to incorporate the behavior of such sequences as the one just mentioned.
Deï¬nition A.2.25. Let (X, D) be a metric space, and let {xn} be a sequence
in X. A point p âˆˆX is called an accumulation point of {xn} if for all real

A.2. Metric Spaces
307
Îµ > 0, an inï¬nite number of elements xn are in BÎµ(p). The accumulation
set of {xn} is the set of all accumulation points.
Example A.2.26. Consider again the real sequence an = (âˆ’1)n + 1
n. Let Îµ
be any positive real number. If n > 1
Îµ and n is even, then an âˆˆBÎµ(1). If
n > 1
Îµ and n is odd, then an âˆˆBÎµ(âˆ’1). Hence, 1 and âˆ’1 are accumulation
points. However, for any r diï¬€erent than 1 or âˆ’1, suppose we choose a Îµ
such that Îµ < min(|r âˆ’1|, |r + 1|). If n is large enough, then
1
n < |min(|r âˆ’1|, |r + 1|) âˆ’Îµ| ,
and for such n, we have an /âˆˆBÎµ(r). Thus, 1 and âˆ’1 are the only ac-
cumulation points of {an}. In the terminology of Deï¬nition, A.2.25, the
accumulation set is {âˆ’1, 1}.
A.2.4
Continuity
For the same reason as for the convergence of sequences, the notion of
continuity, ï¬rst introduced in the context of real functions over an interval,
generalizes naturally to the category of metric spaces. Here is the deï¬nition.
Deï¬nition A.2.27. Let (X, D) and (Y, Dâ€²) be two metric spaces. A function
f : X â†’Y is called continuous at a âˆˆX if for all Îµ âˆˆR>0, there exists
Î´ âˆˆR>0 such that D(x, a) < Î´ implies that D(f(x), f(a)) < Îµ.
The
function f is called continuous if it is continuous at all points a âˆˆX.
Example A.2.28. As a ï¬rst example of Deï¬nition A.2.27, consider the func-
tion f : R2 â†’R given by f(x, y) = x + y, where we assume R2 and
R are equipped with the usual Euclidean metrics. Consider some point
(a1, a2) âˆˆR2. Let Îµ > 0 be any positive real number. Choosing Î´ = Îµ
2 will
suï¬ƒce, as we now show. First note that
D((x, y), (a1, a2)) =

(x âˆ’a1)2 + (y âˆ’a2)2 < Îµ
2
implies that
|x âˆ’a1| < Îµ
2
and
|y âˆ’a2| < Îµ
2.
But if this is so, then
|f(x, y) âˆ’f(a1, a2)| = |x + y âˆ’(a1 + a2)| < |x âˆ’a1| + |y âˆ’a2| < Îµ
2 + Îµ
2 = Îµ.
Thus, f is continuous.

308
A. Point Set Topology
Example A.2.29. Deï¬nition A.2.27 allows one to study the continuity of func-
tions in much more general contexts, as we show with this example. Let X
be a proper subset of Rn, and let âƒ—p be a point in Rn âˆ’X. We view X as
a metric space by restricting the Euclidean metric to it. Let Snâˆ’1 be the
unit sphere in Rn also with its metric coming from the Euclidean one in
Rn. Deï¬ne a function f : X â†’Snâˆ’1 by
f(âƒ—x) =
âƒ—x âˆ’âƒ—p
âˆ¥âƒ—x âˆ’âƒ—p âˆ¥.
We will show that f is continuous.
Let âƒ—a âˆˆX. (We use vector notation in this example and note that with
vectors, the Euclidean metric can be expressed as D(âƒ—x,âƒ—a) = âˆ¥âƒ—xâˆ’âƒ—aâˆ¥.) Then
D(f(âƒ—a), f(âƒ—x)) =

âƒ—a âˆ’âƒ—p
âˆ¥âƒ—a âˆ’âƒ—p âˆ¥âˆ’
âƒ—x âˆ’âƒ—p
âˆ¥âƒ—x âˆ’âƒ—p âˆ¥

=
! âƒ—a âˆ’âƒ—p
âˆ¥âƒ—a âˆ’âƒ—p âˆ¥âˆ’
âƒ—x âˆ’âƒ—p
âˆ¥âƒ—x âˆ’âƒ—p âˆ¥
	
Â·
 âƒ—a âˆ’âƒ—p
âˆ¥âƒ—a âˆ’âƒ—p âˆ¥âˆ’
âƒ—x âˆ’âƒ—p
âˆ¥âƒ—x âˆ’âƒ—p âˆ¥
	
=
!
2 âˆ’2(âƒ—a âˆ’âƒ—p ) Â· (âƒ—x âˆ’âƒ—p )
âˆ¥âƒ—a âˆ’âƒ—p âˆ¥âˆ¥âƒ—x âˆ’âƒ—p âˆ¥
=
âˆš
2 âˆ’2 cosÎ±,
where Î± is the angle between the vectors (âƒ—a âˆ’âƒ—p ) and (âƒ—x âˆ’âƒ—p ). However,
from the trigonometry identity sin2 Î¸ = (1 âˆ’cos 2Î¸)/2, we deduce that
D(f(âƒ—a), f(âƒ—x)) = 2 sin
Î±
2

.
However, if âƒ—x and âƒ—a are close enough, then (âƒ—a âˆ’âƒ—p ) and (âƒ—x âˆ’âƒ—p ) form an
acute angle, and hence, if d is the height from âƒ—a to the segment between âƒ—p
and âƒ—x, we have
D(f(âƒ—x), f(âƒ—a)) = 2 sin
Î±
2

â‰¤2 sin Î± = 2
d
âˆ¥âƒ—p âˆ’âƒ—aâˆ¥â‰¤2âˆ¥âƒ—x âˆ’âƒ—aâˆ¥
âˆ¥âƒ—p âˆ’âƒ—aâˆ¥.
Therefore, choosing Î´ small enough so that the angle between (âƒ—a âˆ’âƒ—p ) and
(âƒ—x âˆ’âƒ—p ) is acute and Î´ < 1
2âˆ¥âƒ—p âˆ’âƒ—aâˆ¥Îµ, we conclude that
âˆ¥âƒ—x âˆ’âƒ—aâˆ¥< Î´ =â‡’D(f(âƒ—x), f(âƒ—a)) < Îµ
proving that f is continuous at all points âƒ—a âˆˆX.

A.2. Metric Spaces
309
Proposition A.2.30. Let (X, D), (Y, Dâ€²), and (Z, Dâ€²â€²) be metric spaces. Let
f : X â†’Y and g : Y â†’Z be functions such that f is continuous at a
point a âˆˆX and g is continuous at f(a) âˆˆY . Then the composite function
g â—¦f : X â†’Z is continuous at a.
Proof: We know that for all Îµ1 âˆˆR>0, there exists Î´1 âˆˆR>0 such that
D(x, a) < Î´1 implies that D(f(x), f(a)) < Îµ1. At the same time, we know
that for all Îµ2 âˆˆR>0, there exists Î´2 âˆˆR>0 such that D(y, f(a)) < Î´2
implies that D(g(y), g(f(a))) < Îµ2. Therefore, given any Îµ > 0, set Îµ2 = Îµ
and choose Îµ1 so that Îµ1 < Î´2. Then
D(x, a) < Î´1 â†’D(f(x), f(a)) < Îµ1 < Î´2 â†’D (g(f(x)), g(f(a))) < Îµ,
showing that g â—¦f is continuous at a.
â–¡
As Example A.2.29 indicates, proofs with continuity can be unwieldy,
but there exists an alternate formulation for when a function between met-
ric spaces is continuous.
Proposition A.2.31. Let (X, D) and (Y, Dâ€²) be two metric spaces, and let f :
X â†’Y be a function. The function f is continuous if and only if for all
open subsets U âŠ‚Y , the set
f âˆ’1(U) = {x âˆˆX | f(x) âˆˆU}
is an open subset of X.
Proof: First suppose that f is continuous. Let U be an open subset of Y ,
and let x be some point in f âˆ’1(U). Of course f(x) âˆˆU. Since U is open,
there exists a real Îµ > 0 such that BÎµ(f(x)) âŠ‚U. Since f is continuous,
there exists a Î´ > 0 such that y âˆˆBÎ´(x) implies that f(y) âˆˆBÎµ(f(x)).
Hence,
f(BÎ´(x)) âŠ‚BÎµ(f(x)) âŠ‚U,
and thus, BÎ´(x) âŠ‚f âˆ’1(U).
Conversely, suppose that f âˆ’1(U) is an open set in X for every open set
U in Y . Let f(x) be a point in U, and let Îµ be a positive real number.
Then
f âˆ’1 (BÎµ(f(x)))
is an open set in X. Thus, since x âˆˆf âˆ’1(BÎµ(f(x))) is open, we know that
there exists some Î´ such that BÎ´(x) âŠ‚f âˆ’1(BÎµ(f(x))). Thus, f(BÎ´(x)) âŠ‚
BÎµ(f(x)), and therefore, f is continuous.
â–¡

310
A. Point Set Topology
The following proposition is an equivalent formulation to Proposition
A.2.31 but often more convenient for proofs.
Proposition A.2.32. Let (X, D) and (Y, Dâ€²) be two metric spaces and let f :
X â†’Y be a function. The function f is continuous if and only if for all
open balls Br(p) in Y , the set f âˆ’1(Br(p)) is an open subset of X.
Proof: (Left as an exercise for the reader. See Problem A.2.26.)
â–¡
Much more could be included in an introduction to metric spaces. How-
ever, many properties of metric spaces and functions between them hold
simply because of the properties of open sets (Proposition A.2.11) and the
characterization of continuous functions in terms of open sets (Proposi-
tion A.2.31). This fact motivates the deï¬nition of topological spaces.
Problems
A.2.1. Prove that D1, D3, and Dâˆfrom Example A.2.3 are in fact metrics on R2.
A.2.2. In the following functions on R2 Ã— R2, which axioms fail to make the
function into a metric?
(a) D1((x1, y1), (x2, y2)) = |x1| + |x2| + |y1| + |y2|.
(b) D2((x1, y1), (x2, y2)) = âˆ’

(x2 âˆ’x1)2 + (y2 âˆ’y1)2
.
(c) D3((x1, y1), (x2, y2)) = |x2 âˆ’x1| Â· |y2 âˆ’y1|.
(d) D4((x1, y1), (x2, y2)) = |x2
2 âˆ’x2
1| + |y2 âˆ’y1|.
A.2.3. Let (X1, D1) and (X2, D2) be metric spaces. Consider the Cartesian prod-
uct X = X1 Ã— X2 made up of pairs (p1, p2)b with p1 âˆˆX1 and p2 âˆˆX2.
Prove that the following function is a metric on X:
D((p1, p2), (q1, q2)) = D(p1, q1) + D(p2, q2).
A.2.4. Let X = Pï¬n(Z) be the set of all ï¬nite subsets of the integers. Recall that
the symmetric diï¬€erence between two sets A and B is Aâ–³B = (A âˆ’B) âˆª
(B âˆ’A). Deï¬ne the function D : X Ã— X â†’Râ‰¥0 by
D(A, B) = n(Aâ–³B),
where n means the cardinality of, or number of elements in, a set. Prove
that D is a metric on X.
A.2.5. In Euclidean geometry, the median line between two points p1 and p2 in
R2 is deï¬ned as the set of points that are of equal distance from p1 and
p2, i.e.,
M = {q âˆˆR2 | D(q, p1) = D(q, p2)}.
What is the shape of the median lines in R2 for D1, D2, and Dâˆfrom
Example A.2.3?

A.2. Metric Spaces
311
A.2.6. Prove that if (X, D) is any metric space, then D(x, y)n where n is any
positive integer, is also metric on X.
A.2.7. Let (X, D) be a metric space, and let S be any subset of X. Prove that
(S, D) is also a metric space. (The metric space (S, D) is referred to as
the restriction of D to S.)
A.2.8. Let S2 be the unit sphere in R3, i.e.,
S2 = {(x, y, z) âˆˆR3 | x2 + y2 + z2 = 1}.
Sketch the open balls on S2 obtained by the restriction of the Euclidean
metric to S2 (see Problem A.2.7). Setting the radius r < 2, for some point
p âˆˆS2, describe Br(p) algebraically by the equation x2 + y2 + z2 = 1 and
some linear inequality in x, y, and z.
A.2.9. Prove that Example A.2.7 is in fact a metric space.
A.2.10. Find the distance between the following pairs of sets in R2:
(a) A = {(x, y) | x2 + y2 < 1} and B = {(x, y) | (x âˆ’1)2 + y2 < 1}.
(b) A = {(x, y) | xy = 1} and B = {(x, y) | xy = 0}.
(c) A = {(x, y) | xy = 2} and B = {(x, y) | x2 + y2 < 1}.
A.2.11. Prove that a subset A of a metric space (X, D) is bounded if and only if
A âŠ‚Br(p) for some r âˆˆRâ‰¥0 and p âˆˆX.
A.2.12. Inï¬nite Intersections and Unions. Let An = [n, +âˆ) and let Bn = [ 1
n, sin n].
Find
(a)
âˆ
.
n=0
An,
(b)
âˆ
=
n=0
An,
(c)
âˆ
.
n=2
Bn.
A.2.13. Deï¬ne the metric D on R2 as follows.
For any p = (px, py) and q =
(qx, qy), let D(p, q) =

4(px âˆ’qx)2 + (py âˆ’qy)2. Prove that this is in
fact a metric. What is the shape of a unit ball Br((x, y))? What is the
shape of the â€œmedianâ€ between two points? [Hint: See Problem A.2.5.]
A.2.14. Are the following subsets of the plane (using the usual Euclidean metric)
open, closed, or neither:
(a) {(x, y) âˆˆR2 : x2 + y2 < 1}.
(b) {(x, y) âˆˆR2 : x2 + y2 â‰¥1}.
(c) {(x, y) âˆˆR2 : x + y = 0}.
(d) {(x, y) âˆˆR2 : x + y Ì¸= 0}.
(e) {(x, y) âˆˆR2 : x2 + y2 â‰¤1 or x = 0}.
(f) {(x, y) âˆˆR2 : x2 + y2 < 1 or x = 0}.
(g) the set A where A = {(x, y) âˆˆR2 : x = 0 and âˆ’1 â‰¤y â‰¤1}.
A.2.15. Let L be a line in the plane R2. Prove that R2âˆ’L is open in the Euclidean
metric and in the three metrics presented in Example A.2.3.

312
A. Point Set Topology
A.2.16. Let X = R2, and deï¬ne D2 as the Euclidean metric and D1 as
D1((x1, y1), (x2, y2)) = |x2 âˆ’x1| + |y2 âˆ’y1|.
Prove that any D2-open ball contains a D1-open ball and is also contained
in a D1-open ball. Conclude that a subset of R2 is D2-open if and only if
it is D1-open.
A.2.17. Prove that the set { 1
n | n âˆˆZ>0} is not closed in R whereas the set { 1
n | n âˆˆ
Z>0} âˆª{0} is.
A.2.18. Consider a metric space (X, D), and let x and y be two distinct points of
X. Prove that there exists a neighborhood U of x and a neighborhood
V of y such that U âˆ©V = âˆ…. (In general topology, this property is called
the Hausdorï¬€property, and this exercise shows that all metric spaces are
Hausdorï¬€.)
A.2.19. Prove Proposition A.2.20.
A.2.20. Let A be a subset of a metric space (X, D). Suppose that every sequence
{xn} in A that converges in X converges to an element of A. Prove that
A is closed.
A.2.21. Let {xn}nâˆˆN be a sequence in a metric space (X, D). Prove that the closure
of the set of elements {xn} is {xn | n âˆˆN} together with the accumulation
set of the sequence {xn}.
A.2.22. Using Deï¬nition A.2.27, prove that the real function f(x) = 2x âˆ’5 is
continuous over R.
A.2.23. Using Deï¬nition A.2.27, prove that
(a) the real function f(x) = x2 is continuous over R;
(b) the real function of two variables f(x, y) = 1/(x2 + y2 + 1) is con-
tinuous over all R2 (using the usual Euclidean metric).
A.2.24. Let (X, D) and (Y, Dâ€²) be metric spaces, and let f : X â†’Y be a contin-
uous function. Prove that if a sequence {xn} in X converges to a limit
point â„“, then the sequence {f(xn)} in Y converges to f(â„“).
A.2.25. Let f : X â†’Y be a function from the metric space (X, D) to the metric
space (Y, Dâ€²).
Suppose that f is such that there exists a positive real
number Î», with
Dâ€²(f(x1), f(x2))
D(x1, x2)
â‰¤Î»
for all x1 Ì¸= x2,
i.e., that the stretching ratio for f is bounded. Show that f is continuous.
A.2.26. Prove Proposition A.2.32.
A.2.27. Let X = Rm and Y = Rn equipped with the usual Euclidean metric.
Prove that any linear transformation from X to Y is continuous.

A.3. Topological Spaces
313
A.3
Topological Spaces
A.3.1
Deï¬nitions and Examples
Deï¬nition A.3.1. A topological space is a set X along with a set Ï„ of subsets
of X satisfying the following:
1. X and âˆ…are in Ï„.
2. For all U and V in Ï„, U âˆ©V âˆˆÏ„.
3. For any collection {UÎ±}Î± âˆˆI of sets in Ï„, the union 0
Î±âˆˆI UÎ± is in Ï„.
We refer to the pair (X, Ï„) as a topological space and call Ï„ a topology on
X. The elements on Ï„ are called open subsets of X and a subset F âŠ‚X
is called closed if X âˆ’F is open, i.e., if X âˆ’F âˆˆÏ„. Finally, any open set
U âˆˆÏ„ that contains a point x âˆˆX is called a neighborhood of x.
If one works with more than one topology on the same underlying set
X, one often refers to Ï„-open and Ï„-closed subsets to avoid ambiguity.
It is important to note that, as with the properties of open sets in metric
spaces, in criterion 3 of Deï¬nition A.3.1, the indexing set I need not be
countable, and hence, one should not assume that the collection {UÎ±}Î± âˆˆI
can be presented as a sequence of subsets.
Example A.3.2. According to Proposition A.2.11, if (X, D) is a metric space,
it is also a topological space, where we use the topology Ï„ to be the open
sets as deï¬ned by Deï¬nition A.2.10. (Of course, it was precisely Propo-
sition A.2.11 along with the discovery by mathematicians that collections
of sets with the properties described in this proposition arise naturally in
numerous other contexts that led to the given deï¬nition of a topological
space.)
Example A.3.3. Let X be any set. Setting Ï„ = P(X) to be the set of all
subsets of X is a topology on X called the discrete topology on X.
In
the discrete topology, all subsets of X are both closed and open. On the
opposite end of the spectrum, setting Ï„ = {X, âˆ…} also satisï¬es the axioms of
a topology, and this is called the trivial topology on X. These two examples
represent the largest and the smallest possible examples of topologies on a
set X.
Example A.3.4. Let X = {a, b, c} be a set with three elements. Let Ï„ =
{âˆ…, {a}, {a, b}, X}. A simple check shows that Ï„ is a topology on X, namely

314
A. Point Set Topology
that Ï„ satisï¬es all the axioms for a topology. Notice that {a} is open, {c}
is closed (since {a, b} is open) and that {b} is neither open nor closed. By
Proposition A.2.17, there is no metric D on X such that the D-open sets
of X are the open sets in the topology of Ï„.
Deï¬nition A.3.5. Let (X, Ï„) be a topological space.
A collection of open
sets B âŠ‚Ï„ is called a base of the topology if every open set is a union of
elements in B âŠ‚Ï„.
The following proposition provides a characterization of a base for a
topology.
Proposition A.3.6. Let (X, Ï„) be a topological space, and suppose that B is a
base. Then
1. the elements of B cover X;
2. if B1, B2 âˆˆB, then for all x âˆˆB1 âˆ©B2 there exists B3 âˆˆB such that
x âˆˆB3 âŠ‚B1 âˆ©B2.
Conversely, if any collection B of open sets satisï¬es the above two proper-
ties, then there exists a unique topology on X for which B is a base. (This
topology is said to be generated by B.)
Proof: (Left as an exercise for the reader.)
â–¡
This characterization allows one to easily describe topologies by pre-
senting a base of open sets.
Example A.3.7. By Deï¬nition A.2.10, in a metric space, the topology asso-
ciated to a metric has the set of open balls as a base.
Example A.3.8. Let X = R2, and consider the collection B of sets of the
form
U = {(x, y) âˆˆR2 | x > x0 and y > y0},
where x0 and y0 are constants.
This collection B satisï¬es both of the
criteria in Proposition A.3.6, hence there exists a unique topology Ï„ on
R2 with B as a base. It is easy to see that Ï„ is diï¬€erent from the usual
Euclidean topology. Note that for any open set U âˆˆÏ„, if (a, b) âˆˆU, then
the half-inï¬nite ray
{(a + t, b + t) | t â‰¥0}
is a subset of U. This is not a property of the Euclidean metric topology
on R2.

A.3. Topological Spaces
315
Proposition A.3.9. Let (X, Ï„) be a topological space. Then the following are
true about the Ï„-closed sets of X:
1. X and âˆ…are closed.
2. The union of any two closed sets is closed.
3. The intersection of any collection of closed sets is closed.
Proof: Part 1 is obviously true since both X and âˆ…are open.
For part 2, let F1 and F2 be any two closed subsets of X. Then F1 and
F2 are open sets. Thus F1 âˆ©F2 is open. However, by the DeMorgan laws,
F1 âˆ©F2 = F1 âˆªF2.
Thus, since F1 âˆªF2 is open, F1 âˆªF2 is closed.
For part 3, let {FÎ±}, where Î± is in some indexing set I, be a collection of
closed subsets. The collection {FÎ±} is a collection of open sets. Therefore,
0
Î± FÎ± is open. Thus,
=
Î±âˆˆI
FÎ± =
.
Î±âˆˆI
FÎ±
is closed.
â–¡
A converse to this proposition turns out to be useful for deï¬ning certain
classes of topologies on sets.
Proposition A.3.10. Let X be a set. Suppose that a collection C of subsets of
X satisï¬es the following properties:
1. X and âˆ…are in C.
2. The union of any two sets in C is again in C.
3. The intersection of any collection of sets in C is again in C.
Then the set of all complements of sets in C form a topology on X.
Proof: (Left as an exercise for the reader.)
â–¡
Example A.3.11. Let X be any set. Consider the collection C of subsets of
X that include X, âˆ…, and all ï¬nite subsets of X. The collection C satisï¬es
all three criteria in Proposition A.3.10, so X, âˆ…, and the complements of
ï¬nite subsets of X form a topology on X. This is often called the ï¬nite
complement topology.

316
A. Point Set Topology
We now present a topology on Rn that has more open sets than the
ï¬nite complement topology but fewer than the usual Euclidean topology
(induced from the Euclidean metric).
Example A.3.12. Let X = Rn. Let C be the collection of all ï¬nite unions of
aï¬ƒne subspaces of Rn, where by aï¬ƒne subspace we mean any set of points
that is the solution set to a set of linear equations in x1, x2, . . . , xn (i.e.,
points, lines, planes, etc.). Taking the empty set of linear equations or an
inconsistent set of linear equations, one obtains X and âˆ…as elements of
C. Since the union operation of sets is associative, a ï¬nite union of ï¬nite
unions of aï¬ƒne spaces is again just a union of aï¬ƒne spaces.
To establish that the third criterion in Proposition A.3.10 holds for C,
we must prove that the intersection of any collection of ï¬nite unions of aï¬ƒne
spaces is a ï¬nite union of aï¬ƒne spaces. Note ï¬rst that if the intersection
of two aï¬ƒne subspaces A1 and A2 is a strict subspace of both A1 and A2,
then dim A1 âˆ©A2 is strictly less than dim A1 and dim A2. Let {FÎ±}Î±âˆˆI be
a collection of sets in C, and let {Î±i}iâˆˆN be a sequence of indices. Given
the sequence {Î±i}, create a sequence of â€œintersectionâ€ trees according to
the following recursive deï¬nition. The tree T0 is the tree with a base node,
and an edge for each AÎ±0,j in
FÎ±0 =
.
j
AÎ±0,j ,
with a corresponding leaf for each AÎ±0,j. For each tree Ti, construct Ti+1
from Ti as follows. Writing
FÎ±i =
.
j
AÎ±i,j ,
for each leaf F of Ti and for each j such that F âˆ©AÎ±i,j Ì¸= F, adjoin an
edge labeled by AÎ±i,j to F and label the resulting new leaf by F âˆ©AÎ±i,j.
As constructed, for each k, the leaves of the tree Tk are labeled by
intersections of aï¬ƒne spaces so that
k=
i=0
FÎ±i
is the union of the leaves of Tk. Since only a ï¬nite number of edges gets
added to every leaf, for all i â‰¥0, there can be only a ï¬nite number of
vertices at a ï¬xed distance from the base node. Furthermore, since any
nontrivial intersection A âˆ©B of aï¬ƒne spaces has dimension
dim(A âˆ©B) â‰¤min(dim A, dim B) âˆ’1

A.3. Topological Spaces
317
and since the ambient space is Rn, each branch (descending path) in any
tree Ti can have at most n + 1 edges. In conclusion, for all Ti, there can
only be a ï¬nite number of leaves. Thus,
âˆ
=
i=0
FÎ±i
is a ï¬nite union of intersections of aï¬ƒne spaces. Since this holds for all
sequences {Î±i} in I, this then proves that
=
Î±âˆˆI
FÎ±
is a ï¬nite union of intersections of aï¬ƒne spaces.
This rather lengthy proof shows that the collection C of ï¬nite unions
of aï¬ƒne spaces in Rn satisï¬es the criteria of Proposition A.3.10. Conse-
quently, the set Ï„ of subsets of Rn that are complements of a ï¬nite union
of aï¬ƒne spaces forms a topology on Rn.
Example A.3.12, along with the result of Problem A.3.3, show that
given a set X, it is possible to have two topologies Ï„ and Ï„ â€² on X such
that Ï„ âŠŠÏ„ â€², or in other words, that every Ï„-open set in X is Ï„â€²-open but
not vice versa. This leads to a useful notion, which we do not develop any
further than to give its deï¬nition
Deï¬nition A.3.13. Let X be a set and let Ï„ and Ï„ â€² be two topologies on X.
If Ï„ âŠ†Ï„ â€², then we say that Ï„â€² is ï¬ner than Ï„ and that Ï„ is coarser than Ï„â€².
If in addition Ï„ Ì¸= Ï„ â€², we say that Ï„â€² is strictly ï¬ner than Ï„ and that Ï„ is
strictly coarser than Ï„ â€².
In Section A.2.2, Proposition A.2.20 proved that the closure of a subset
A (as deï¬ned by Deï¬nition A.2.19) of a metric space (X, D) is the inter-
section of all closed subsets of X containing A. This formulation of the
closure of a set does not rely explicitly on the metric D and carries over
without changes to topological spaces. The closure of a subset A âŠ‚X is an
example of a topological operator. Other topological operators, which one
could encounter in the context of metric spaces, exist in any topological
space.
Deï¬nition A.3.14. Let (X, Ï„) be a topological space and A a subset of X.
We deï¬ne
1. the closure of A, written Cl A, as the intersection of all closed sets in
X containing A;

318
A. Point Set Topology
2. the interior of A, written Aâ—¦, as the union of all open sets of X
contained in A;
3. the frontier of A, written Fr A, as the set
{x âˆˆX | every neighborhood U of x satisï¬es
U âˆ©A Ì¸= âˆ…and U âˆ©(X âˆ’A) Ì¸= âˆ…} .
We leave some of the basic properties of the above topological operators
to the exercises but present one common characterization of closed sets.
Proposition A.3.15. Let (X, Ï„) be a topological space, and let A be any subset
of X. The set A is closed if and only if
A = Cl A .
Proof: If A is closed, then A is among the closed sets F âŠ‚X that contain
A, and there is no smaller closed subset containing A. Hence A = Cl A.
Conversely, if A = Cl A, then since the intersection of any collection of
closed sets is closed, Cl A is closed, so A is closed.
â–¡
Another useful characterization of closed sets relies not on a topological
operator but on properties of its limit points.
Deï¬nition A.3.16. Let A be any subset of the topological space X. A limit
point of A is any point p âˆˆX such that every open neighborhood of p
contains at least one point of A âˆ’{p}.
(In the vocabulary of sequences in a metric space, if the subset A is a
sequence {xn}, then in Deï¬nition A.2.25, we would call the limit points
of A the accumulation points of A. For this reason, some authors use the
alternate terminology of accumulation point for limit points of a subset A in
a topological space. The discrepancy in terminology is unfortunate, but in
topology, the majority of authors use the vocabulary of Deï¬nition A.3.16.)
Proposition A.3.17. Let A be a subset of a topological space X. The set A is
closed if and only if it contains all of its limit points.
Proof: Assume ï¬rst that A is closed. The complement X âˆ’A is open and
hence is a neighborhood of each of its points. Therefore, there is no point
in X âˆ’A that is a limit point of A. Hence, A contains all its limit points.
Assume now that A contains all of its limit points. Let p âˆˆX âˆ’A.
Since p is not a limit point of A, there exists an open neighborhood U of p
such that U âˆ©A = âˆ…. Thus, X âˆ’A is a neighborhood of each of its points,
and hence, it is open. Thus, A is closed.
â–¡

A.3. Topological Spaces
319
Finally, we mention one last term related to closures.
Deï¬nition A.3.18. Let (X, Ï„) be a topological space. A subset A of X is
called dense in X if Cl A = X.
In other words, by Proposition A.3.17 a set A is dense in X if every
point of X is a limit point of A. We give a few common examples of dense
subsets.
Example A.3.19. Let I = [a, b] be a closed interval in R, and equip I with
the topology induced from the Euclidean metric on R. The open subsets
in this topology on I are of the form U âˆ©I, where U is an open subset of
R. Furthermore, the open interval (a, b) is dense in I.
Proposition A.3.20. The set Q of rational numbers is dense in R.
Proof: A precise proof of this statement must rely on a deï¬nition of real
numbers, as constructed from the rationals. One may ï¬nd this deï¬nition in
any introductory analysis book but is just beyond the scope of this book.
However, using a high school understanding of real numbers as numbers
with an inï¬nite decimal expansion that is not periodic, we can supply a
simple proof of this fact.
Let x0 âˆˆR be any real number, and let U be an open neighborhood
of x0. By deï¬nition, there exists a positive real Îµ > 0 such that (x0 âˆ’Îµ,
x0 + Îµ) âˆˆU. Let N = 1 âˆ’log10 Îµ. Consider q the fraction that represents
the decimal approximation of x0 that stops at N digits after the decimal
period. Then, q âˆˆQ and q âˆˆU. Hence, x0 is a limit point of Q.
â–¡
A.3.2
Continuity
When working with topological spaces (X, Ï„) and (Y, Ï„â€²), one is not always
interested in studying the properties of just any function between f : X â†’Y
because a function without any special properties will not necessarily relate
the topology on X to that on Y or vice versa. In other words, with respect
to the function f, discussion about topologies on X and Y is irrelevant. In
Section A.2.4, Proposition A.2.31 provided a characterization of continuous
functions between metric spaces only in terms of the open sets in the metric
space topology. This motivates the deï¬nition of continuity for functions
between topological spaces.
Deï¬nition A.3.21. Let (X, Ï„) and (Y, Ï„â€²) be two topological spaces, and let
f : X â†’Y be a function. We call f continuous (with respect to Ï„ and Ï„ â€²)
if for every open set U âŠ‚Y , the set f âˆ’1(U) is open in X.

320
A. Point Set Topology
Example A.3.22. Proposition A.2.31 shows that any function called contin-
uous between two metric spaces (X, D) and (Y, Dâ€²) is continuous with
respect to the topologies induced by the metrics on X and Y , respectively.
Proposition A.3.23. Let (X, Ï„) and (Y, Ï„â€²) be topological spaces, and let f :
X â†’Y be a function. Then f is continuous if and only if for all f(x) âˆˆY
and any neighborhood V of f(x), there exists a neighborhood U of x such
that f(U) âŠ‚V .
Proof: First, suppose that f is continuous. Then for all f(x) âˆˆY and for
all open neighborhoods V of f(x), f âˆ’1(V ) is open in X. Furthermore, x âˆˆ
f âˆ’1(V ) so f âˆ’1(V ) is an open neighborhood of x. Also, since f(f âˆ’1(V )) =
V for any set, we see that setting U = f âˆ’1(V ) proves one direction.
Second, assume the conclusion of the proposition. Let V be any open
set in Y . If V contains no image f(x), then f âˆ’1(V ) = âˆ…, which is open in
X. Therefore, assume that V contains some image f(x). Let W = f âˆ’1(V ).
According to the assumption, for all x âˆˆW there exists open neighborhoods
Ux of x such that f(Ux) âŠ‚V . Since f(Ux) âŠ‚V , then Ux âŠ‚f âˆ’1(V ) = W.
But then
W âŠ‚
.
xâˆˆW
Ux âŠ‚W â—¦,
and since W â—¦âŠ‚W always, we conclude that W = W â—¦, which implies (see
Problem A.3.7) that W is open. This shows that f is continuous.
â–¡
Proposition A.3.24. Let (X, Ï„), (Y, Ï„ â€²), and (Z, Ï„ â€²â€²) be three topological spaces.
If f : X â†’Y and g : Y â†’Z are continuous functions, then g â—¦f : X â†’Z
is also a continuous function.
Proof: (Left as an exercise for the reader.)
â–¡
For metric spaces, a continuous function is one that preserves â€œnear-
nessâ€ of points.
Though topological spaces are not necessarily metric
spaces, a continuous function f : X â†’Y between topological spaces pre-
serves nearness in the sense that if two images f(x1) and f(x2) are in the
same open set V , then there is an open set U that contains both x1 and
x2, with f(U) âŠ‚V .
In set theory, one views two sets as â€œultimately the sameâ€ if there exists
a bijection between them: they are identical except for how one labels the
speciï¬c elements. For topological spaces to be considered â€œthe same,â€ not
only do the underlying sets need to be in bijection, but this bijection must
preserve the topology. This is the concept of a homeomorphism.

A.3. Topological Spaces
321
Deï¬nition A.3.25. Let (X, Ï„) and (Y, Ï„â€²) be two topological spaces, and let
f : X â†’Y be a function. The function f is called a homeomorphism if
1. f is a bijection;
2. f : X â†’Y is continuous;
3. f âˆ’1 : Y â†’X is continuous.
If there exists a homeomorphism between two topological spaces, we call
them homeomorphic.
Example A.3.26. Any two squares S1 and S2, as subsets of R2 with the Eu-
clidean metric, are homeomorphic. For i = 1, 2, let ti be the translation
that brings the center of Si to the origin, Ri a rotation that makes the edges
of ti(Si) parallel to the x- and y-axes, and let hi be a scaling (homothetie)
that changes Ri â—¦ti(Si) into the square {(âˆ’1, âˆ’1), (âˆ’1, 1), (1, 1), (1, âˆ’1)}.
It is easy to see that translations are homeomorphisms of R2 to itself. Fur-
thermore, by Problem A.2.27, we see that Ri and hi are continuous, and
since they are invertible linear transformations, their inverses are continu-
ous as well. Thus, Ri and hi are homeomorphisms. Thus, the function
f = tâˆ’1
2
â—¦Râˆ’1
2
â—¦hâˆ’1
2
â—¦h1 â—¦R1 â—¦t1
is a homeomorphism of R2 into itself that sends S1 to S2. Thus, S1 and S2
are homeomorphic.
Example A.3.27. Any circle and any square, as subsets of R2, are homeomor-
phic. To see this, one must present a homeomorphism between a circle and
a square. By Problem A.3.26 with modiï¬cations as needed, one can see
that any two squares are homeomorphic and any two circles are homeomor-
phic. So consider a circle S and a square T that we can assume, without
loss of generality, have the same center O.
Let f : T â†’S be the function that associates to a point P on the
square T the only other intersection Q of the ray [O, P) with the circle S.
An open ball Br(Q) in S corresponds to the intersection of S with Br(Q)
as an open ball in R2 and, in this case, is also the intersection of S with
an appropriate open sector U centered at O (see Figure A.4).
The set
f âˆ’1(Br(Q)) is the open set U âˆ©T , showing that f is continuous. Since
the construction is perfectly reversible, f âˆ’1 is also continuous. Thus weâ€™ve
proven that any circle is homeomorphic to any square.

322
A. Point Set Topology
P
Q
Figure A.4. A homeomorphism between a circle and a square (Example A.3.27).
Example A.3.28. The above two examples only begin to illustrate how dif-
ferent homeomorphic spaces may look. In this example, we prove that any
closed, simple parametrized curve Î³ in Rn is homeomorphic to the unit
circle S1 (in R2). Let âƒ—x : [0, l] â†’Rn be a parametrization by arclength
for the curve Î³ such that âƒ—x(t1) = âƒ—x(t2) implies that t1 = 0 and t2 = l,
assuming t1 < t2. The function f : Î³ â†’S1 deï¬ned by
f(P) =

cos
2Ï€
l âƒ—xâˆ’1(P)
	
, sin
2Ï€
l âƒ—xâˆ’1(P)
		
(A.1)
produces the appropriate homeomorphism. Note that âƒ—xâˆ’1 is not well de-
ï¬ned only at the point âƒ—x(0) because âƒ—xâˆ’1(âƒ—x(0)) = {0, l}. However, using
either 0 or l in Equation (A.1) is irrelevant.
Example A.3.29. In contrast to the previous example, consider the closed,
regular curve Î³2 parametrized by âƒ—x : [0, 2Ï€] â†’R2 with
âƒ—x(t) = (cos t, sin 2t).
The curve Î³2 traces out a ï¬gure eight of sorts and is not simple because
âƒ—x(Ï€/2) = (0, 0) = âƒ—x(3Ï€/2) (and âƒ—xâ€²(Ï€/2) Ì¸= âƒ—xâ€²(3Ï€/2)). We show that it is
not homeomorphic to a circle S1 (see Figure A.5). Call P = (0, 0).
There does exist a surjective continuous map f of Î³2 onto the circle S1,
namely, using the parametrization âƒ—x(t),
f(âƒ—x(t)) = (cos 2t, sin 2t)
which amounts to folding the ï¬gure eight back onto itself so that the circle
is covered twice. However, there exists no continuous bijection g : Î³2 â†’S1.

A.3. Topological Spaces
323
P
g
Q
Figure A.5. Figure eight not homeomorphic to a circle.
To see this, call Q = g(P), and let U be a small open neighborhood of Q. If
g is a bijection, it has exactly one preimage for every element x âˆˆU. Thus,
gâˆ’1(U) is the image of a nonintersecting parametrized curve. However,
every open neighborhood of P includes two segments of curves. Thus, the
circle and Î³2 are not homeomorphic.
Example A.3.30. Consider the same regular, closed parametrized curve as
in the previous example. The function f : (0, 1) â†’Î³2 deï¬ned by f(t) =
âƒ—x(2Ï€t âˆ’Ï€
2 ) is a bijection. Furthermore, f is continuous since it is contin-
uous as a function (0, 1) â†’R2. However, the inverse function f âˆ’1 is not
continuous and in fact no continuous bijection g : (0, 1) â†’Î³2 can have
a continuous inverse.
Let a âˆˆ(0, 1) be the real number such that f(a) = P, the point of self-
intersection on Î³2. Take an open segment U around a. The image f(U) is
a portion of Î³2 through P (see the heavy lines in Figure A.6). However, this
portion f(U) is not an open subset of Î³2 since every open neighborhood of
P includes f((0, Îµ1)) and f((1 âˆ’Îµ2, 1)).
We conclude this section on continuity between topological spaces by
mentioning one particular result, the details of which exceed the scope of
this appendix and for which we therefore do not supply a proof.
Theorem A.3.31. The Euclidean spaces Rn and Rm are homeomorphic if and
only if m = n.
P
f
0
1
a
Figure A.6. Figure eight not homeomorphic to a segment.

324
A. Point Set Topology
This theorem states that Euclidean spaces can only be homeomorphic
if they are of the same dimension. This might seem obvious to the casual
reader but this fact hides a number of subtleties. First of all, the notion
of dimension of a set in topology is not at all a simple one. Secondly, one
must be careful to consider space-ï¬lling curves, such as the Peano curve,
which is a continuous surjection of the closed interval [0, 1] onto the closed
unit square [0, 1] Ã— [0, 1]. (See [27], Section 3-3, for a construction.) The
construction for space-ï¬lling curves can be generalized to ï¬nd continuous
surjections of Rn onto Rm even if n < m. However, Theorem A.3.31 implies
that no space-ï¬lling curve is bijective and has a continuous inverse. That
Euclidean spaces of diï¬€erent dimensions are not homeomorphic means that
they are distinct from the perspective of topology.
A.3.3
Derived Topological Spaces
Given any topological space (X, Ï„), there are a number of ways to create
a new topological space. We present two common waysâ€”subset topology
and identiï¬cation spacesâ€”which are used throughout this book.
Deï¬nition A.3.32. Let (X, Ï„) be a topological space, and let S be any subset
of X. We deï¬ne a topology Ï„â€² on S by calling a subset A âŠ‚S open if and
only if there exists an open subset U of X such that A = S âˆ©U.
The subset topology is sometimes called the topology induced on S from
X. There is an alternate way to characterize it.
Proposition A.3.33. Let (X, Ï„) be a topological space, and let S âŠ‚X. Let
i : S â†’X be the inclusion function. The induced topology on S is the
coarsest topology such that i is a continuous function.
Proof: Given any subset A of X, we have iâˆ’1(A) = Aâˆ©S. If i is continuous,
then for all open subsets U âŠ‚X, the set iâˆ’1(U) = U âˆ©S is open. However,
according to Deï¬nition A.3.32, the subset topology on S has no other open
subsets and therefore is coarser than any other topology on S, making i
continuous.
â–¡
Example A.3.34. Consider R equipped with the usual topology. Let S = [a, b]
be a closed interval. If a < c < b, in the subset topology on S, the interval
[a, c) is open. To see this, take any real d < a. Then
[a, c) = (d, c) âˆ©[a, b],
and (d, c) is open in R.

A.3. Topological Spaces
325
A second and often rather useful way to create new topological spaces
is to induce a topology on a quotient set.
Deï¬nition A.3.35. Let X be a set, and let R be an equivalence relation on
X. The set of equivalence classes of R is denoted by X/R and is called the
quotient set of X with respect to R.
The concept of a quotient set arises in many areas of mathematics
(congruence classes in number theory, quotient groups in group theory,
quotient rings in ring theory, etc.) but also serves as a convenient way to
deï¬ne interesting objects in topology and geometry. We provide a few such
examples before discussing topologies on quotient sets.
Example A.3.36 (Real Projective Space). Let X be the set of all lines in Rn+1,
and let R be the equivalence relation of parallelism on X. We can therefore
discuss the set of equivalence classes X/R.
Each line in X is uniquely
parallel to a line that passes through the origin, and hence, X/R may be
equated with the set of lines passing through the origin. This set is called
the real projective space of dimension n and is usually denoted by RPn.
As an alternate characterization for RPn, consider the unit n-sphere Sn
in Rn+1 and centered at the origin. Each line through the origin intersects
Sn at two antipodal points. Therefore, RPn is the quotient set of Sn with
respect to the equivalence relation, in which two points are called equivalent
if they are antipodal (form the ends of a diameter through Sn).
Example A.3.37 (Grassmannian). Let Xr be the set of all r-dimensional aï¬ƒne
subspaces (planes) in Rn, and let R be the equivalence relation of paral-
lelism between r-planes. The set of equivalence classes is called a Grass-
mannian and is denoted G(r, n). Again, since each r-dimensional plane
is uniquely parallel to one plane through the origin, which is then an r-
dimensional vector subspace, G(r, n) is the set of all r-dimensional vectors
subspaces of Rn.
Of particular interest to geometry is the question of how to give a
topology to X/R if X is equipped with a topology. Proposition A.3.33
illustrates how to make a reasonable deï¬nition.
Deï¬nition A.3.38. Let (X, Ï„) be a topological space and let R be an equiv-
alence relation on X. Deï¬ne f : X â†’X/R as the function that sends an
element in X to its equivalence class; f is called the identiï¬cation map.
We call identiï¬cation topology on X/R the ï¬nest topology that makes f
continuous, and X/R equipped with this topology is called an identiï¬cation
space.

326
A. Point Set Topology
The above deï¬nition for the identiï¬cation topology does not make it
too clear what the open sets of X/R should be. The following proposition
provides a diï¬€erent characterization.
Proposition A.3.39. Let (X, Ï„) be a topological space, and let R be an equiv-
alence relation on X. Let f be the identiï¬cation map. A set U is open in
the identiï¬cation topology on X/R if and only if f âˆ’1(U) is open in X.
Proof: Let Ï„ â€² be a topology on X/R such that f : X â†’X/R is continuous.
Then for all open sets U âˆˆÏ„ â€², we must have f âˆ’1(U) be open in X. Note
ï¬rst that f âˆ’1(âˆ…) = âˆ…and f âˆ’1(X/R) = X, which are both open in X.
Now, it is not hard to show, using basic set theory, that for any function
F : A â†’B and any collection C of subsets of B that
F âˆ’1
 .
SâˆˆC
S

=
.
SâˆˆC
F âˆ’1(S)
and
F âˆ’1
 =
SâˆˆC
S

=
=
SâˆˆC
F âˆ’1(S).
(See Section 1.3 in [46].) Therefore, if U1 and U2 are such that f âˆ’1(U1) âˆ©
f âˆ’1(U2) is open, then f âˆ’1(U1 âˆ©U2) is open. Also, for any collection of sets
{UÎ±}Î±âˆˆI in X/R,
f âˆ’1
 .
Î±âˆˆI
UÎ±

=
.
Î±âˆˆI
f âˆ’1(UÎ±)
so if the right-hand side is open, then so is the left-hand side. Consequently,
the collection of subsets B of X/R such that U âˆˆB if and only if f âˆ’1(U) âˆˆÏ„
is a topology on X/R. However, any ï¬ner topology on X/R would include
some subset S âŠ‚X/R such that f âˆ’1(S) would not be open in X and,
hence, would make f not continuous.
â–¡
Example A.3.40 (Circles). Let I be the interval [0, 1] equipped with the topol-
ogy induced from R. Consider the equivalence relation that identiï¬es 0 with
1 and sets everything else inequivalent. (See Figure A.7.) The identiï¬ca-
tion space I/R is homeomorphic to a circle.
We may use the function
f : I/R â†’S1 deï¬ned by
f(t) = (cos 2Ï€t, sin 2Ï€t),
which is well deï¬ned since f(0) = f(1), so whether one takes 0 or 1 for the
equivalence class {0, 1}, one obtains the same output. This function f is
clearly bijective.

A.3. Topological Spaces
327
0
1
{0, 1}
0.4
0.4
Figure A.7. Open set around {0, 1}.
To prove that f is continuous, let P âˆˆS1, and let x âˆˆI/R. If P Ì¸= (1, 0),
then any open neighborhood U of P contains an open interval of angles
Î¸1 < Î¸ < Î¸2, where 0 < Î¸1 < Î¸2 < 2Ï€ and the angle Î¸0 corresponding to P
satisï¬es Î¸1 < Î¸0 < Î¸2. Then
f
 Î¸1
2Ï€ , Î¸2
2Ï€
	
contains P and is a subset of U. On the other hand, if P = (1, 0), any open
neighborhood U â€² of P in S1 contains an open arc of angles Î¸1 < Î¸ < Î¸2,
with Î¸1 < 0 < Î¸2. Then if g : I â†’I/R is the identiï¬cation map,
f â—¦g
>
0, Î¸2
2Ï€
	
âˆª

1 âˆ’Î¸1
2Ï€ , 1
?	
contains P and is contained in U â€². Furthermore, by deï¬nition, g([0, Î¸2
2Ï€) âˆª
(1 âˆ’Î¸1
2Ï€, 1]) is open in I/R since [0, Î¸2
2Ï€) âˆª(1 âˆ’Î¸1
2Ï€, 1] is open in the subset
topology of [0, 1]. By Proposition A.3.23, f is continuous.
Using a similar argument, it is not hard to show that f âˆ’1 is continuous,
concluding that I/R is homeomorphic to S1.
Example A.3.41. Consider the real projective space RPn given as the quo-
tient space Sn/ âˆ¼, where âˆ¼is the equivalence relation on Sn and where
p1 âˆ¼p2 if and only if they are antipodal to each other, i.e., form a diameter
of the sphere. The unit sphere Sn naturally inherits the subspace topology
from Rn+1. Using Deï¬nition A.3.38 provides the induced topology for RPn.
Example A.3.42 (MÂ¨obius Strip). Let I = [0, 1] Ã— [0, 1] be the unit square with
the topology induced from Rn. Deï¬ne the identiï¬cation (equivalence rela-
tion) between points by

(0, y) âˆ¼(1, 1 âˆ’y), for all y âˆˆ[0, 1],
no other points are equivalent to any others.

328
A. Point Set Topology
p
p
Figure A.8. MÂ¨obius strip.
The topological space obtained is called the MÂ¨obius strip.
In R3, the
MÂ¨obius strip can be viewed as a strip of paper twisted once and with ends
glued together. Figure A.8 shows an embedding of the MÂ¨obius strip in
R3, as well as a diagrammatic representation of the MÂ¨obius strip. In the
diagrammatic representation, the arrows indicate that the opposite edges
are identiï¬ed but in inverse direction. The shaded area shows a disk around
a point p on the identiï¬ed edge.
A.3.4
Compactness
In any calculus course, one encounters the following theorem used in the
proofs of many theorems, such as Rolleâ€™s Theorem and the Mean Value
Theorem.
Theorem A.3.43. Let I âŠ†R be a closed interval, and let f : I â†’R be a
continuous real-valued function. Then f attains a maximum and minimum
over I.
As topology developed, a variety of attempts were made to generalize
the idea contained in this fact.
The essential properties of the interval
[a, b] are that it is closed and bounded, two properties that make sense in
any metric space. It turns out that in topological spaces, the notion of
compactness provides a generalization for the combined property of being
closed and bounded.
Deï¬nition A.3.44. Let (X, Ï„) be a topological space. Let I be any set, and
let U = {Ui}iâˆˆI be a collection of open sets in X. We call U an open cover
of X if
X =
.
iâˆˆI
Ui.

A.3. Topological Spaces
329
If J âŠ‚I, the collection V = {Vj}jâˆˆJ is called an open subcover of U if V is
itself an open cover of X.
Deï¬nition A.3.45. A topological space (X, Ï„) is called compact if every open
cover of X has a ï¬nite subcover. If A is a subset of X, we call A compact
if it is compact when equipped with the subspace topology induced from
(X, Ï„).
Some examples of compact spaces are obvious: for example, any ï¬nite
subset of a topological space is compact. However, the following theorem
justiï¬es, at least in part, the given deï¬nition of compactness.
Theorem A.3.46 (Heine-Borel). A closed and bounded interval [a, b] of R is
compact.
(A variety of proofs exist for the Heine-Borel Theorem. The following
proof is called the â€œcreeping alongâ€ proof.)
Proof: Let U = {UÎ±}Î±âˆˆI be an open cover of [a, b]. Deï¬ne the subset of
[a, b] by
E = {x âˆˆ[a, b] | [a, x] is contained in a ï¬nite subfamily of U}.
Obviously, E is an interval, but a priori we do not know whether it is open
or closed or even nonempty. We will show that b âˆˆE to establish the
theorem.
Now a âˆˆE because there exists some UÎ±0 such that a âˆˆUÎ±0.
Let
c = lub E. Clearly a â‰¤c â‰¤b. Suppose that c < b. Since U covers [a, b],
there exists some index Î² such that c âˆˆUÎ², and therefore there exists Îµ
such that (c âˆ’Îµ, c + Îµ) âŠ‚UÎ². Since c is the least upper bound of E, any
x âˆˆ(c âˆ’Îµ, c) is in E. Therefore, there exists a ï¬nite set {Î±1, Î±2, . . . , Î±n}
such that
[a, x] âŠ‚
n.
i=1
UÎ±i.
But then the ï¬nite union of open sets
(c âˆ’Îµ, c + Îµ) âˆª
n.
i=1
UÎ±i
contains the point c + Îµ/2, contradicting the assumption that c < b and
c = lub E. Thus, c = b and b âˆˆE.
â–¡

330
A. Point Set Topology
Compactness is an important property of topological spaces, and we
refer the reader to [2, Chapter 3], [14, Section 6.6], or [26, Chapter 7] for
complete treatments of the topic. For the purposes of this book however,
we are primarily interested in two results, namely Theorem A.3.50 and
Theorem A.3.51, and a few necessary propositions to establish them. We
will not prove Theorem A.3.50 completely but again refer the reader to the
above sources for proofs.
Proposition A.3.47. Let (X, Ï„) be a topological space, and let K be a compact
subset of X. Every closed subset of K is compact.
Proof: Let F âŠ‚K be a closed set. Then X âˆ’F is open. If U is an open
cover of F, then U âˆªX âˆ’F is an open cover of K. Since K is compact,
U âˆªX âˆ’F must admit a ï¬nite subcover of K. This ï¬nite subcover of K is
of the form Uâ€² âˆªX âˆ’F, where Uâ€² is a ï¬nite subcover of U of F. Thus, F
is compact.
â–¡
Problem A.2.18 established the fact that two distinct points p1 and p2
in a metric space possess, respectively, open neighborhoods U1 and U2 such
that U1 âˆ©U2 = âˆ…. This type of property is called a separation property of a
topological space because it gives some qualiï¬cation for how much one can
distinguish points in the topological space. There exists a variety of sepa-
ration axioms, but we only present the one that is relevant for diï¬€erential
geometry.
Deï¬nition A.3.48. Let (X, Ï„) be a topological space. X is called Hausdorï¬€
if given any two points p1 and p2 in X, there exist in Ï„ open neighborhoods
U1 of p1 and U2 of p2 such that U1 âˆ©U2 = âˆ….
Proposition A.3.49. If (X, Ï„) is a Hausdorï¬€topological space, then every
compact subset K of X is closed.
Proof: Let K be compact. Since X is Hausdorï¬€, for every x âˆˆX âˆ’K and
y âˆˆK, there exist open sets Uxy and Vxy, with x âˆˆUxy and y âˆˆVxy, such
that Uxy âˆ©Vxy = âˆ…. For each x âˆˆX âˆ’K,
{Vxy | y âˆˆK}
is an open cover of K, so it must possess a ï¬nite subcover that we index
with a ï¬nite number of points y1, y2, . . . , yn. But then for each x,
Ux =
n
=
i=1
Uxyi

A.3. Topological Spaces
331
is open since it is a ï¬nite intersection of open sets. Since K âŠ‚0n
i=1 Vxyi,
we conclude that K âˆ©Ux = âˆ…for all x âˆˆX âˆ’K.
Thus, X âˆ’K is a
neighborhood of all of its points and hence it is open. Thus, K is closed.â–¡
Theorem A.3.50. Let A be any subset of Rn (equipped with the Euclidean
topology). The set A is compact if and only if it is closed and bounded.
Proof: (We only prove (â†’).) Suppose that A is compact. Since by Prob-
lem A.2.18 any metric space is Hausdorï¬€, Proposition A.3.49 allows us to
conclude that A is closed. Since every open set in a metric space is the union
of open balls, any open cover of A can be viewed as an open cover of open
balls. If A is compact, it is contained in only a ï¬nite number of such open
balls {Bri(pi)}m
i=1. There exists an open ball Br(p) that contains all the
Bri(pi). The radius r will be less than (m âˆ’1) max{d(pi, pj)} + 2 max{ri}.
Then K âŠ‚Br(P), and hence, K is bounded.
(The proof of the converse is more diï¬ƒcult and uses other techniques
that we do not have the time to develop here.)
â–¡
Theorem A.3.50 establishes that we might view closed and bounded
subsets of Rn as the topological analog to [a, b] âŠ‚R in Theorem A.3.43.
We now complete the generalization to topological spaces.
Theorem A.3.51. Let f : X â†’Y be a continuous function between topological
spaces X and Y . If X is a compact space, then f(X) is compact in Y .
Proof: Let U be an open cover of f(X). Since f is continuous, each f âˆ’1(U)
is open and the collection {f âˆ’1(U) | U âˆˆU} is an open cover of X. Since
X is compact, there exists a ï¬nite set {U1, U2, . . . , Un} âŠ‚U such that
X =
n.
i=1
f âˆ’1(Ui).
Since for any functions f(f âˆ’1(A)) âŠ‚A always and f(0
Î» AÎ») = 0
Î» f(AÎ»),
then
f(X) = f
 n
.
i=1
f âˆ’1(Ui)

=
n.
i=1
f(f âˆ’1(Ui)) âŠ‚
n.
i=1
Ui.
Thus, f(X) is compact.
â–¡
Corollary A.3.52. Let X be a compact topological space, and let f : X â†’R
be a real-valued function from X. Then f attains both a maximum and a
minimum.

332
A. Point Set Topology
Proof: By Theorem A.3.51, the image f(X) is compact. By Theorem A.3.50,
f(X) is a closed and bounded subset of R. Hence, lub {f(x) | x âˆˆX} and
glb {f(x) | x âˆˆX} are both elements of f(X) and hence are the maximum
and minimum of f over X.
â–¡
Corollary A.3.53. Let (X, Ï„) and (Y, Ï„ â€²) be topological spaces, and let f :
X â†’Y be a continuous function onto Y . If X is compact, then so is Y .
Corollary A.3.54. Let X be a compact topological space.
If a space Y is
homeomorphic to X, then Y is compact.
One does not always restrict oneself to compact topological spaces,
though they do possess many nice properties. However, we mention two
ï¬nal deï¬nitions that concern open covers or local compactness of sets and
that appear as essential components of deï¬nitions in other parts of this
book.
Deï¬nition A.3.55. A topological space (X, Ï„) is called second countable if
there exists a countable subset of Ï„ (i.e., a countable collection of open
sets) that covers X.
Deï¬nition A.3.56. A topological space (X, Ï„) is called locally compact if
given any x âˆˆX and any neighborhood U of x, there is a compact set
K such that
x âˆˆKâ—¦âŠ‚K âŠ‚U.
As an example, note that Rn is not compact, but it is locally compact.
Problems
A.3.1. Prove Proposition A.3.10.
A.3.2. Find all the topologies on the set {a, b, c}. How many diï¬€erent topologies
exist on a set of four elements?
A.3.3. Consider the topology Ï„ constructed in Example A.3.12. Prove that every
open set in Ï„ is also open in the topology Ï„ â€² induced from the Euclidean
metric. Give an example of an open set in Ï„ â€² that is not Ï„-open. (When
these two facts hold, one says that Ï„ â€² is a strictly ï¬ner topology than Ï„.)
A.3.4. Let Ï„ be the set of all subsets of R that are unions of intervals of the form
[a, b). Prove that Ï„ is a topology on R. Is Ï„ the same topology as that
induced by the absolute value (Euclidean) metric?
A.3.5. Prove that in a topological space (X, Ï„), a set A is open if and only if it
is equal to its interior.

A.3. Topological Spaces
333
A.3.6. Prove Proposition A.3.6.
A.3.7. Let (X, Ï„) be a topological space, and let A and B be any subsets of X.
Prove the following:
(a) (Aâ—¦)â—¦= Aâ—¦.
(b) Aâ—¦âŠ‚A.
(c) (A âˆ©B)â—¦= Aâ—¦âˆ©Bâ—¦.
(d) A subset U âŠ‚X is open if and only U = U â—¦.
A.3.8. Find an example that shows that (A âˆªB)â—¦is not necessarily equal to
Aâ—¦âˆªBâ—¦.
A.3.9. Let (X, Ï„) be a topological space, and let A and B be any subsets of X.
Prove the following:
(a) Cl(Cl A) = Cl A.
(b) A âŠ‚Cl A.
(c) Cl(A âˆªB) = Cl A âˆªCl B.
(d) A subset F âŠ‚X is closed if and only Cl F = F.
A.3.10. Find an example that shows that Cl(A âˆ©B) is not necessarily equal to
Cl A âˆ©Cl B.
A.3.11. Let (X, Ï„) be a topological space, and let A be any subset of X. Prove
the following:
(a) Cl A = Aâ—¦âˆªFr A.
(b) Cl A âˆ’Fr A = Aâ—¦.
(c) Fr A = Fr(X âˆ’A).
A.3.12. Show that every open subset of R is the union of disjoint open intervals.
A.3.13. Let (X, D) be any metric space, and let A be any subset of X. Consider
the function f : X â†’Râ‰¥0 deï¬ned by D(x, A), where Râ‰¥0 is equipped
with the usual topology.
(Note that [0, a) is open in this topology on
Râ‰¥0.) Prove that f is continuous. (The set f âˆ’1([0, r)) is sometimes called
the open r-envelope of A.)
A.3.14. Let (X, D) be any metric space, and let A and B be closed subsets of X.
Use the previous exercise to construct a continuous function g : X â†’R
such that g(a) = 1 for all a âˆˆA and g(b) = âˆ’1 for all b âˆˆB.
A.3.15. Let X = Rn âˆ’{âƒ—0} be equipped with the induced Euclidean topology.
Let f : Rn â†’Snâˆ’1 be the radial projection onto the unit (n âˆ’1)-sphere
deï¬ned by
f(âƒ—x) =
âƒ—x
âˆ¥âƒ—xâˆ¥.
Prove that f is continuous.

334
A. Point Set Topology
A.3.16. Let S2 be the two-dimensional unit sphere in R3. Give S2 the topology of
a metric induced on S2 as a subset of R3. Suppose we locate points on
S2 using (Î¸, Ï†) in spherical coordinates. Let fÎ± : S2 â†’S2 be the rotation
function such that
f(Î¸, Ï†) = (Î¸ + Î±, Ï†).
Prove that f is continuous.
A.3.17. Let X be a topological space, and let f : X â†’R be a continuous function.
Prove that the set of zeroes of f, namely {x âˆˆX | f(x) = 0}, is closed.
A.3.18. Prove Proposition A.3.24.
A.3.19. Let (X, Ï„) and (Y, Ï„ â€²) be topological spaces, and let f : X â†’Y be a
function.
Prove that F is continuous if and only if for all closed sets
F âŠ‚Y , the set f âˆ’1(F) is closed in X.
A.3.20. Let R be the set of real numbers equipped with the absolute value topology.
Prove the following:
(a) Any open interval (a, b) is homeomorphic to the open interval (0, 1).
(b) Any inï¬nite open interval (a, +âˆ) is homeomorphic to (1, âˆ).
(c) Any inï¬nite open interval (a, +âˆ) is homeomorphic to (âˆ’âˆ, a).
(d) The open interval is homeomorphic to the set of reals R. [Hint: Use
f(x) = tan x.]
(e) The interval (1, âˆ) is homeomorphic to (0, 1).
Conclude that all open intervals of R are homeomorphic.
A.3.21. Prove that a circle and a line segment are not homeomorphic.
A.3.22. Finish proving that the function f in Example A.3.28 is a homeomorphism.
A.3.23. Consider Z and Q as subsets of R equipped with the absolute value metric.
Decide whether Z and Q are homeomorphic.
A.3.24. Let (X, Ï„) and (Y, Ï„ â€²) be topological spaces, and suppose that there exists a
continuous surjective function f : X â†’Y . Deï¬ne the equivalence relation
on X by
x âˆ¼y â‡â‡’f(x) = f(y).
Prove that X/ âˆ¼is homeomorphic to (Y, Ï„ â€²).
A.3.25. What space do we obtain if we take a MÂ¨obius strip and identify all the
points on its boundary to a point?
A.3.26. Find a quotient space of R2 homeomorphic to each of the following:
(a) A straight line.
(b) A sphere.
(c) A (ï¬lled) rectangle.
(d) A torus.

A.4. Proof of the Regular Jordan Curve Theorem
335
A.3.27. Describe each of the following spaces:
(a) A ï¬nite cylinder with each of its boundary circles identiï¬ed to a
point.
(b) The sphere S2 with an equator identiï¬ed to a point.
(c) R2 with points identiï¬ed according to (x, y) âˆ¼(âˆ’x, âˆ’y).
A.3.28. Find an open cover of the following sets that does not contain a ï¬nite
subcover:
(a) R;
(b) [0, 1);
(c) (0, 1).
A.3.29. Let K be a subset of a metric space (X, D). Prove that K is compact if
and only if every sequence in K has an accumulation point in K.
A.3.30. Let K be a compact subset of a metric space (X, D).
Show that the
diameter of K is equal to D(x, y) for some pair x, y âˆˆK. Prove that
given any x âˆˆX, D(x, A) is equal to D(x, y) for some y âˆˆK.
A.3.31. Let X be a compact topological space, and let {Kn}âˆ
n=1 be a sequence
of nonempty closed subsets of X, with Kn+1 âŠ‚Kn for all n. Prove that
@âˆ
n=1 Kn is nonempty.
A.3.32. Prove that the union of ï¬nitely many compact spaces is compact. Is the
intersection between two compact sets necessarily compact?
A.3.33. Prove that the set R equipped with the ï¬nite complement topology (see
Example A.3.11) is not Hausdorï¬€.
A.3.34. Prove that the topological space described in Example A.3.12 is not Haus-
dorï¬€.
A.3.35. Prove Corollary A.3.53.
A.4
Proof of the Regular Jordan Curve Theorem
As mentioned in Section 2.2 of [5], we refrained from providing the proof
of the Jordan Curve Theorem for regular curves. We provide a proof here
since it ï¬ts naturally in the context of topology.
Recall that a parametrized plane curve âƒ—x : I â†’R2 is called regular if
âƒ—xâ€²(t) Ì¸= âƒ—0 for all t in the interval I.
Theorem A.4.1 (Regular Jordan Curve Theorem). Let C be a simple, closed, reg-
ular plane curve parametrized by âƒ—x : [a, b] â†’R2.
Then the open set
R2 âˆ’âƒ—x([a, b]) has exactly two connected components with common boundary
âƒ—x([a, b]). Only one of the connected components is bounded, and we call this
component of R2 âˆ’âƒ—x([a, b]) the interior.

336
A. Point Set Topology
Proof: The proof involves three steps: (1) show that the winding numbers
of two points near but on either side of the curve diï¬€er by 1, (2) establish
the existence of the outside of the curve, and (3) show that the interior of
the complement of the outside of the curve (which by step 1 is not âˆ…) is
connected.
Step 1. Let âƒ—p be a point on the curve, and suppose that we reparametrize
C by arclength so that âƒ—p = âƒ—x(0). We use the domain [âˆ’l/2, l/2] for âƒ—x(s),
where l is the arclength of the curve. Call âƒ—U(s) the unit normal vector (i.e.,
is a counterclockwise rotation of the unit tangent vector âƒ—T(s) by Ï€/2). Let
Î´ âˆˆR, and consider the parallel curve âƒ—Î³Î´(s) = âƒ—x(s) + Î´âƒ—U(s).
Using basic results from the local theory of plane curves, the velocity
of âƒ—Î³Î´(s) is
âƒ—Î³â€²
Î´(s) = âƒ—xâ€²(s) + Î´âƒ—U â€²(s) = âƒ—T(s) + Î´Îºg(s)âƒ—T (s) = (1 + Î´Îºg(s))âƒ—T(s),
where Îºg(s) is the plane curvature of âƒ—x(s). Since [âˆ’l/2, l/2] is a compact
interval and since Îºg(s) is continuous, |Îºg(s)| attains a maximum over
[âˆ’l/2, l/2], say Îºmax. Thus, for |Î´| < 1/Îºmax, the parallel curve âƒ—Î³Î´(s) is
regular. Call Î´1 one such Î´, and deï¬ne
âƒ—p1 = âƒ—p + Î´1âƒ—U(0)
and
âƒ—p2 = âƒ—p âˆ’Î´1 âƒ—U(0).
Let d(s) be the distance between âƒ—x(s) and the tangent line to âƒ—x at âƒ—p.
Since âƒ—x is diï¬€erentiable at s = 0, the Taylor Series Remainder Theorem
for vector functions says that there exists a constant A such that âˆ¥âƒ—x(s) âˆ’
âƒ—x(0)âˆ¥< As for all s âˆˆ[âˆ’l/2, l/2]. Since âƒ—x(0) = âƒ—p is on the tangent line to
âƒ—x at âƒ—p, we have
d(s) â‰¤âˆ¥âƒ—x(s) âˆ’âƒ—x(0)âˆ¥< As.
Consider now the following diagram.
L
r p2
r p1
Î´
Î´








qâ€²
qq
t
d
........Î¸
The law of cosines gives, after some computation,
cos Î¸ =
t2 + Î´2
1 âˆ’Î´1d

t2 + (Î´1 âˆ’d)2 
t2 + Î´2
1
.

A.4. Proof of the Regular Jordan Curve Theorem
337
Now assume that d = d(t) is a continuous function of t satisfying d(t) < At
(for t in some neighborhood of 0). Using the double inequality 0 â‰¤d(t) â‰¤
At, one can easily show that
t2 + Î´2
1 âˆ’AÎ´1t
t2 + Î´2
1
â‰¤
t2 + Î´2
1 âˆ’Î´1d(t)

t2 + (Î´1 âˆ’d(t))2 
t2 + Î´2
1
â‰¤

t2 + Î´2
1

t2 + (Î´1 âˆ’At)2 .
Consequently, by the Sandwich Theorem,
lim
tâ†’0 cos(Î¸(t)) = 1,
and hence, limtâ†’0 Î¸(t) = 0. Furthermore, if Î¸2(t) is the angle âˆ qâ€²pq, then
Î¸2(t) â‰¤Î¸(t).
We apply this construction to the curve âƒ—x near p by using âƒ—x(s) for the
point q, the tangent line for L, t = f(s) for the distance between âƒ—p and
the projection of âƒ—x(s) onto the tangent line and d(s) as above. Let âƒ—Î¾(s)
be the projection of âƒ—x(s) onto the tangent line to âƒ—x at âƒ—p, and, for i = 1, 2,
let Î¸i(s) be the angle between âƒ—x(s) âˆ’âƒ—pi and âƒ—Î¾(s) âˆ’âƒ—pi. We have shown that
the Î¸i(s) are continuous functions, with
lim
sâ†’0 Î¸i(s) = 0,
Since the limit of Î¸1 and Î¸2 is 0 as s â†’0, we can choose s1 small enough
so that the angles Î¸1(s) and Î¸2(s) are all less than or equal to Îµ/10 for all
s âˆˆ[âˆ’s1, s1]. Deï¬ne the position maps Ï•1, Ï•2 : [âˆ’l/2, l/2] â†’S1 by
Ï•i(s) =
âƒ—x(s) âˆ’âƒ—pi
âˆ¥âƒ—x(s) âˆ’âƒ—piâˆ¥,
and let ËœÏ•i : [âˆ’l/2, l/2] â†’R be their liftings relative to 0.
We assume
without loss of generality that the curve is oriented as shown in Fig-
ure A.9.
We note that by construction, for all s âˆˆ[âˆ’l/2, âˆ’s1] âˆª[s1, l/2], the
distances âˆ¥âƒ—x(s)âˆ’âƒ—p1âˆ¥and âˆ¥âƒ—x(s)âˆ’âƒ—p2âˆ¥remain bounded below by Î´, regardless
of the parameter s. Consequently, for all s âˆˆ[âˆ’l/2, âˆ’s1]âˆª[s1, l/2], the angle
between âƒ—x(s) âˆ’âƒ—p1 and âƒ—x(s) âˆ’âƒ—p2 tends uniformly to 0 as Î´1 approaches 0,
i.e., as âƒ—p1 approaches âƒ—p2. We choose Î´1 small enough so that the angle
between âƒ—x(s) âˆ’âƒ—p1 and âƒ—x(s) âˆ’âƒ—p2 is less than Îµ/10.
We also notice that since âƒ—p1 and âƒ—p2 are on the normal line to C at p,
we can choose Î´1 smaller still (if necessary) so that
Ï€ âˆ’âˆ qâˆ’p1q+ < Îµ
10
and
Ï€ âˆ’âˆ qâˆ’p2q+ < Îµ
10.

338
A. Point Set Topology
qâˆ’
q+
Î¸1(s1)
âƒ—x(s1)
p1
p2
âƒ—x(s)
Figure A.9. Setup for the Jordan Curve Theorem.
Furthermore, by construction and keeping track of orientation,
|( ËœÏ•1(âˆ’s1) âˆ’ËœÏ•1(s1)) âˆ’âˆ qâˆ’p1q+| < Îµ
10 + Îµ
10 = Îµ
5,
and
|( ËœÏ•2(âˆ’s1) âˆ’ËœÏ•2(s1)) + âˆ qâˆ’p2q+| < Îµ
10 + Îµ
10 = Îµ
5.
Thus,
|( ËœÏ•1(âˆ’s1) âˆ’ËœÏ•1(s1)) âˆ’Ï€| < 3Îµ
10
and
|( ËœÏ•2(âˆ’s1) âˆ’ËœÏ•2(s1)) + Ï€| < 3Îµ
10.
Let w(p1) and w(p2) be the winding numbers of C around p1 and p2
(see Deï¬nition 2.2.5 in [5]). From the deï¬nition of the winding numbers
and Equation (2.3) in [5], we see that
2Ï€(w(p1) âˆ’w(p2)) = ( ËœÏ•1(l/2) âˆ’ËœÏ•1(âˆ’l/2)) âˆ’( ËœÏ•2(l/2) âˆ’ËœÏ•2(âˆ’l/2))
= ( ËœÏ•1(l/2) âˆ’ËœÏ•1(s1)) + ( ËœÏ•1(s1) âˆ’ËœÏ•1(âˆ’s1))
+ ( ËœÏ•1(âˆ’s1) âˆ’ËœÏ•1(âˆ’l/2)) + ( ËœÏ•2(l/2) âˆ’ËœÏ•2(s1))
+ ( ËœÏ•2(s1) âˆ’ËœÏ•2(âˆ’s1)) + ( ËœÏ•2(âˆ’s1) âˆ’ËœÏ•2(âˆ’l/2))
= [( ËœÏ•1(l/2) âˆ’ËœÏ•2(l/2)) âˆ’( ËœÏ•1(s1) âˆ’ËœÏ•2(s1))]
+ [( ËœÏ•1(s1) âˆ’ËœÏ•1(âˆ’s1)) âˆ’( ËœÏ•2(s1) âˆ’ËœÏ•2(âˆ’s1))]
+ [( ËœÏ•1(âˆ’s1) âˆ’ËœÏ•2(âˆ’s1)) âˆ’( ËœÏ•1(âˆ’l/2) âˆ’ËœÏ•2(âˆ’l/2))].
By our constructions, the middle term diï¬€ers from 2Ï€ by at most 6Îµ/10,
and also, by our choice of Î´1, for all s âˆˆ[âˆ’l/2, âˆ’s1] âˆª[s1, l/2], we have

A.5. Simplicial Complexes and Triangulations
339
| ËœÏ•1(s) âˆ’ËœÏ•2(s)| < Îµ/10. Putting all the inequalities together, we deduce
that our choice of Î´1 implies that
|2Ï€(w(p1) âˆ’w(p2)) âˆ’2Ï€| < Îµ.
Consequently, since we know that w(p1) âˆ’w(p2) is an integer, choosing Î´1
small enough so that Îµ = Ï€, we can conclude that w(p1) âˆ’w(p2) = 1.
We remark here that a diï¬€erent choice of orientation for C would lead
to w(p1)âˆ’w(p2) = âˆ’1, so we conclude that in general w(p1)âˆ’w(p2) = Â±1.
This ï¬nishes step 1.
Step 2. It is easy to see that since C is a regular closed curve, it is bounded
and therefore contained in some open disk DR centered at the origin and
of radius R. Let âƒ—p be a ï¬xed point in R2 âˆ’DR. Let U1 be the connected
component of R2 âˆ’C containing âƒ—p. Let âƒ—q be the closest point on DR to âƒ—p.
Then
(âƒ—x(t) âˆ’âƒ—p ) Â· (âƒ—q âˆ’âƒ—p ) > 0,
and hence, the angle of âƒ—x(t) âˆ’âƒ—p with respect to the ï¬xed vector âƒ—q âˆ’âƒ—p is
strictly between (âˆ’Ï€
2 , Ï€
2 ).
Consequently, the winding number of âƒ—x with
respect to âƒ—p is 0. We call the open set U1 the outside of C.
Step 3. To conclude the proof, we need to show that the complement of
U1 âˆªC is connected.
Let âƒ—p1 and âƒ—p2 be two points in U1 âˆªC, and let âƒ—x(s1) and âƒ—x(s2) be
points on the curve that minimize âˆ¥âƒ—x(s) âˆ’âƒ—piâˆ¥for i = 1, 2. Without loss of
generality, we can assume that s1 < s2. Let Î´ be small enough that âƒ—Î³Î´(s)
is a parallel curve to âƒ—x(s) that is simple and does not intersect âƒ—x(s), with
the sign of delta chosen so that âƒ—x(0) âˆˆU1 âˆªC. Consider the path that
consists of (1) a line segment from âƒ—p1 to âƒ—Î³Î´(s1), (2) adjoined by âƒ—Î³Î´(s) for
s1 â‰¤s â‰¤s2, and (3) adjoined by a line segment from âƒ—Î³Î´(s2) to âƒ—p2. This
path connects âƒ—p1 and âƒ—p2, and all its points are in U1 âˆªC. Thus, U1 âˆªC is
connected.
â–¡
A.5
Simplicial Complexes and Triangulations
In Section A.3, we introduced basic notions concerning topological spaces
and continuous functions between them. When one applies the theory of
point set topology to speciï¬c applications, one quickly encounters a few
diï¬ƒculties.
For example, when proving a geometric result, such as the
Jordan Curve Theorem, one needs to work in a narrower context than the

340
A. Point Set Topology
full generality of a topological space. On the other hand, when one deï¬nes
invariants of topological spaces, it is important to be able to calculate
these invariants for a large enough class of spaces for such invariants to be
of interest. Triangulating a space is a technique that can both be helpful
for proving certain geometric theorems and also for calculating invariants
of topological spaces.
In this section, we discuss triangulations of topological spaces and ex-
pand on some of the results used in Section 8.4 of [5] to prove the global
Gauss-Bonnet Theorem. There is not enough space in this book for a com-
prehensive treatment of triangulations so the propositions here are pre-
sented without proofs. We encourage the reader to consult [2], [41], or [27]
for a more complete introduction to these topics.
Deï¬nition A.5.1. The points p0, p1, . . . , pk in Rn are said to be in general
position if any strict subset of {p0, p1, . . . , pk} determines a smaller hyper-
plane. Vectors âƒ—v0,âƒ—v1, . . . ,âƒ—vk in Rn are in general position if {âƒ—v1 âˆ’âƒ—v0, . . . ,
âƒ—vk âˆ’âƒ—v0} is a linearly independent set.
One can see that the notions of general position for vectors and for
points are equivalent by viewing vectors in Rn as position vectors of points.
Deï¬nition A.5.2. Given k + 1 vectors (or points) âƒ—v0,âƒ—v1, . . . ,âƒ—vk in general
position in Rn, we call the set
{âƒ—x âˆˆRn | âƒ—x=c0âƒ—v0+c1âƒ—v1+Â· Â· Â·+ckâƒ—vk such that c0+c1+Â· Â· Â·+ck =1 and ci â‰¤0}
a simplex of dimension k or k-simplex. We denote this set by [âƒ—v0,âƒ—v1, . . . ,âƒ—vk].
The points âƒ—v0,âƒ—v1, . . . ,âƒ—vk are called the vertices of the simplex.
In more geometric terms, the k-simplex of a set of points in general
position is the convex hull of (i.e., the smallest convex set containing) its
vertices. From an intuitive perspective, a k-simplex is the k-dimensional
generalization of a triangle, as the following list shows. For 0 â‰¤k â‰¤3, the
k-simplexes are
k
shape
0
point
1
closed line segment
2
triangle
3
tetrahedron
By analogy with the language of polyhedra, simplexes have faces. If
A is any nonempty subset of {âƒ—v0,âƒ—v1, . . . ,âƒ—vk}, then [A] is called a face of
[âƒ—v0,âƒ—v1, . . . ,âƒ—vk].

A.5. Simplicial Complexes and Triangulations
341
(a) A simplicial complex.
(b) Not a simplicial complex.
Figure A.10. Simplexes in R3.
Deï¬nition A.5.3. A simplicial complex is a ï¬nite collection K of simplexes
in Rn such that
1. if a simplex is in the collection K, then so are all of its faces;
2. the intersection of any pair of simplexes in K is a face.
Figure A.10(a) provides an example of a simplicial complex. Note that
if a simplicial complex K includes the triangle simplex [p1, p2, p3], then the
simplicial complex must also include all the faces, namely the simplexes
[p1, p2], [p2, p3], [p1, p3], [p1], [p2], and [p3]. In contrast, Figure A.10(b)
shows two simplexes in R3 whose intersection is not a face, and therefore,
this collection of simplexes is not a simplicial complex nor can they be a
part of a simplicial complex.
It is important to make a distinction between the simplicial complex
K, which consists of combinatorial data, and what is called its geometric
realization, denoted |K|.
The realization of a simplicial complex is the
topological space associated to K whose points consist of the union of all
the simplexes of K and whose topology is the subset topology induced
from Rn.
Deï¬nition A.5.4. Let X be a topological space. A triangulation of X consists
of a simplicial complex and a homeomorphism h : |K| â†’X. If for a space
X there exists a triangulation, then X is called triangulable.
Example A.5.5 (MÂ¨obius Strip). Figure A.11 shows that the MÂ¨obius strip is tri-
angulable. Figure A.11(a) shows the realization of a simplicial complex in
R3, while Figure A.11(b) shows the MÂ¨obius strip along with the images of
all the faces of the complex in (a) via the triangulation homeomorphism.

342
A. Point Set Topology
(a) Simplicial complex
(b) Image of the triangulation
Figure A.11. Triangulation of a MÂ¨obius strip.
It is important to note that triangulations of topological spaces are in
no way unique. Not every topological space admits a triangulation, but
most classes of spaces of interest in diï¬€erential geometry do.
We now present a few propositions relating triangulations to the theory
of surfaces. The following ï¬rst result, originally due to Rado (1925), is
what makes the techniques of triangulations useful.
Theorem A.5.6. Every compact regular surface admits a triangulation.
The proof of this useful theorem is not particularly diï¬ƒcult but is te-
dious, so we refer the reader to [17]. The next theorem discusses compati-
bility of triangulations of compact regular surfaces with coordinate neigh-
borhoods.
Proposition A.5.7. Let S be a compact regular surface, and let {Ui}, with
1 â‰¤i â‰¤n, be a ï¬nite collection of open sets in S that covers S. Then there
exists a simplicial complex K and a triangulation h : |K| â†’S such that
every 2-simplex (triangle) T of K satisï¬es h(T ) âŠ‚Ui for some i.
Since one lists the vertices of a simplex [âƒ—v0,âƒ—v1, . . . ,âƒ—vk] in a particular
order, one can associate an orientation to a simplex as a permutation of the
vertices considered equivalent up to the sign of the permutation. Hence,
there are only two possible orientations to any given simplex, depending on
the sign of the associated permutation. When sketching oriented triangles,
one typically draws an oriented arc of a circle in the interior of the triangle
to show the orientation (see Figure A.12).
Suppose two oriented k-simplexes meet along a (k âˆ’1)-dimensional
face F. Call Ïƒ and Ï„ the permutations of the two simplexes that deï¬ne
their respective orientations, and deï¬ne ÏƒF and Ï„F as the permutations
induced from Ïƒ and Ï„, respectively, by ignoring the vertex not in F. We

A.6. Euler Characteristic
343
v0
v1
v2
Figure A.12. Oriented triangle.
(a) Compatible orientation
(b) Incompatible orientation
Figure A.13. Adjacent oriented triangles.
say that these adjacent triangles have compatible orientation if ÏƒF and Ï„F
have opposite signs as permutations.
When considering adjacent triangles, we can think of the orientation of
a triangle as a direction of travel around the edges. Two adjacent triangles
have a compatible orientation if the orientation of the ï¬rst leads one to
travel along the common edge in the opposite direction as the orientation
of the second triangle (see Figure A.13).
Proposition A.5.8. If S is a compact, orientable, regular surface that admits
a triangulation h : |K| â†’S, then all the triangles of K can be given an
orientation so that the orientations are compatible.
A.6
Euler Characteristic
Consider a simplicial complex K.
We denote by Î±i the number of i-
simplexes in K and let n be the maximum dimension of simplexes in K.
We deï¬ne the Euler characteristic Ï‡(K) of the simplicial complex by the
integer
Ï‡(K) =
n

i=0
(âˆ’1)iÎ±i.
The Euler characteristic has numerous nice properties that we attempt to
illustrate with a few simple examples.
If k > 0, call the interior of the k-simplex [âƒ—v0,âƒ—v1, . . . ,âƒ—vk] the set
{âƒ—x âˆˆRn | âƒ—x=c0âƒ—v0+c1âƒ—v1+Â· Â· Â·+ckâƒ—vk such that c0+c1+Â· Â· Â·+ck =1 and ci >0}.
In other words, the interior of a k-simplex is the geometric realization of
the simplex minus the geometric realization of all its faces.
Let K be a simplicial complex, and suppose that Kâ€² is obtained from K
by adding a point q in the interior of a k-simplex A of K and then adding

344
A. Point Set Topology
all appropriate simplexes to complete K âˆª{q} to a simplicial complex.
It is not hard to see that, in this case, one must add
k+1
i

simplexes of
dimension i for 0 < i < k and that the k-face A must be replaced with k
faces of dimension k. Then the calculation of Ï‡(Kâ€²) gives
Ï‡(Kâ€²) =
kâˆ’1

i=0
(âˆ’1)i

Î±i +
k + 1
i
		
+ (âˆ’1)k(Î±k + k) +
n

i=k+1
(âˆ’1)iÎ±i
=
n

i=0
(âˆ’1)iÎ±i +
kâˆ’1

i=0
(âˆ’1)i
k + 1
i
	
+ (âˆ’1)k(k + 1) + (âˆ’1)k+1
=
n

i=0
(âˆ’1)iÎ±i +
k+1

i=0
(âˆ’1)i
k + 1
i
	
=
n

i=0
(âˆ’1)iÎ±i = Ï‡(K).
Without much more work, one arrives at the following proposition.
Proposition A.6.1. Let K and Kâ€² be two simplicial complexes such that
|K| = |Kâ€²|.
Then K and Kâ€² have the same Euler characteristic, i.e.,
Ï‡(K) = Ï‡(Kâ€²).
The following theorem provides a deep generalization of this proposi-
tion.
Theorem A.6.2. Let X be a triangulable topological space, and let K and Kâ€²
be simplicial complexes such that h : |K| â†’X and hâ€² : |Kâ€²| â†’X are
triangulations of X. Then Ï‡(K) = Ï‡(Kâ€²).
Proof: Follows from Theorem 8-11 in [27].
â–¡
The value of this theorem is that one can now deï¬ne the Euler charac-
teristic for any triangulable space.
Deï¬nition A.6.3. Let X be a triangulable space. The Euler characteristic of
X, denoted Ï‡(X), is deï¬ned as Ï‡(K), where h : |K| â†’X is a triangulation
of X.
The deï¬nition of a triangulation leads immediately to the following
proposition.
Proposition A.6.4. Let X and Y be two homeomorphic topological spaces. If
one is triangulable, then so is the other, and Ï‡(X) = Ï‡(Y ).

A.6. Euler Characteristic
345
Figure A.14. Torus triangulation.
One can rephrase Proposition A.6.4 by saying that the Euler charac-
teristic is a topological invariant. A topological invariant is any object or
number associated to a topological space that remains unchanged under a
homeomorphism.
It is not hard to see that a two-dimensional sphere S2 is homeomorphic
to the surface of a tetrahedron K, by which we mean the tetrahedron with
its interior removed.
This polyhedron is the geometric realization of a
simplicial complex that has Î±0 = 4, Î±1 = 6, and Î±2 = 4. Consequently, the
Euler characteristic of a sphere is Ï‡(S2) = 2. Figure A.14 shows a simplicial
complex that gives a triangulation of a torus. This simplicial complex has
Î±0 = 16, Î±1 = 48, and Î±2 = 32. Therefore, the Euler characteristic of a
torus Figure A.15(a) is Ï‡ = 0. Similarly, it is not hard to calculate that a
two-holed torus (Figure A.15(c)) has an Euler characteristic of Ï‡ = âˆ’2.
In topology, a torus is often called a sphere with one handle (see Fig-
ure A.15(b)), and by extension, one discusses spheres with n-handles. It
is easy to determine that any surface homeomorphic to a sphere with n
handles has an Euler characteristic of Ï‡ = âˆ’2(n âˆ’1). The following clas-
siï¬cation theorem is of profound importance in the study of surfaces.
(a) Torus
(b) Sphere with one handle
(c) Two-holed torus
Figure A.15. Tori.

346
A. Point Set Topology
Theorem A.6.5 (Classiï¬cation of Orientable Surfaces). Any compact orientable
surface is homeomorphic to a sphere with a ï¬nite number of handles added.
If S is homeomorphic to a sphere with n handles added, then it has an Euler
characteristic of Ï‡(S) = âˆ’2(n âˆ’1).
Proof: (See [2, Chapter 7].)
â–¡
The number g of handles on a closed orientable surface is called the
genus. The relation to the Euler characteristic is
g = 2 âˆ’Ï‡(S)
2
.
We conclude with an example that is useful in the topological or the
diï¬€erential geometric theory of surfaces. The proofs are simple and left to
the reader.
Lemma A.6.6. Let S be a subset of Rn that is homeomorphic to a closed disk
(in R2). Then Ï‡(S) = 1.
Corollary A.6.7. Let S be a compact orientable surface that is homeomorphic
to a sphere with n handles. Suppose that Sâ€² is obtained from S by removing
a region that is homeomorphic to an open disk (in R2).
Then Ï‡(Sâ€²) =
âˆ’2(n âˆ’1) âˆ’1.

APPENDIX
B
Calculus of Variations
B.1
Formulation of Several Problems
One of the greatest uses of calculus is the principle that extrema of a con-
tinuous function occur at critical points, i.e., at real values of the function,
where the ï¬rst derivative (partial derivatives if one is dealing with a mul-
tivariable function) is (are all) 0 or not deï¬ned. In practical applications,
when one wishes to optimize a certain quantity, one writes down a func-
tion describing said quantity in terms of relevant independent variables,
calculates the ï¬rst partials, and solves the equations obtained by setting
the derivatives equal to 0 or undeï¬ned.
Many other problems in math and physics, however, involve quantities
that do not just depend on independent variables but on an independent
function.
Some classic examples are problems that ask one to ï¬nd the
shortest distance between two points, the shape with ï¬xed perimeter en-
closing the most area, and the curve of quickest descent between two points.
Calculus of variations refers to a general method to deal with such prob-
lems.
Let [x1, x2] be a ï¬xed interval of real numbers. For any diï¬€erentiable
function y : [x1, x2] â†’R, the deï¬nite integral
I(y) =
% x2
x1
f(x, y, yâ€²) dx
(B.1)
is a well-deï¬ned quantity that depends only on y(x) when the integrand
f is a function of the arguments x, y, and yâ€².
We can view the above
integral I as a function from C1([x1, x2], R), the set of all continuously
diï¬€erentiable functions from [x1, x2], to R.
The problem is to ï¬nd all
functions y(x) for which I(y) attains a minimum or maximum value for all
y âˆˆC1([x1, x2], R). Unlike optimization problems in usual multivariable
calculus that involve solving algebraic equations, this initial problem in
the calculus of variations involves a second-order diï¬€erential equation for
347

348
B. Calculus of Variations
which the constants of integration are ï¬xed once one sets y(x1) = y1 and
y(x2) = y2.
Many generalizations to this ï¬rst problem exist. For example, similar to
optimization problems in multiple variables, one may impose certain con-
ditions so that one considers only a subset of functions in C1([x1, x2], R)
among those to optimize I(y). In another direction, one may seek to opti-
mize the double integral
I(w) =
%%
D
f

x, y, w, âˆ‚w
âˆ‚x , âˆ‚w
âˆ‚y
	
dA
where D is a region of R2 and w is a two-variable function. The solution
would be a function w âˆˆC1(D, R) that produces the maximum or minimum
value for the integral. Of course, one can consider situations where the
unknown function w is a function of any number of variables. As a third
type of generalization, one may consider the integral
I(x, y) =
% t2
t1
f

t, x, dx
dt , y, dy
dt
	
dt,
where I(x, y) involves two unknown functions of one independent variable t.
Finally, one may then consider any number of combinations to the above
generalizations. For example, the isoperimetric problemâ€”the problem of
ï¬nding the shape with a ï¬xed perimeter and maximum areaâ€”involves ï¬nd-
ing parametric equations x(t) and y(t) that produce a simple closed curve
that maximizes area (a one-variable integration by Greenâ€™s Theorem), sub-
ject to the condition that the perimeter is some ï¬xed constant.
The following sections follow the excellent presentation given in [55].
B.2
The Euler-Lagrange Equation
B.2.1
The Main Theorem
Many problems in calculus of variations amount to solving a particular dif-
ferential equation called the Euler-Lagrange equation and variants thereof.
However, all the theorems that justify the use of the Euler-Lagrange equa-
tion hinge on one lemma and its subsequent generalizations.
Lemma B.2.1. Let G be a continuous real-valued function on an interval
[x1, x2]. If
% x2
x1
Î·(x)G(x) dx = 0
(B.2)

B.2. The Euler-Lagrange Equation
349
for all continuously diï¬€erentiable functions Î·(x) that satisfy Î·(x1) = Î·(x2)
= 0, then G(x) = 0 for all x âˆˆ[x1, x2].
Proof: We prove the contrapositive, namely, if G is not identically 0 then
there exists some function Î·(x) on [x1, x2] that does not satisfy Equa-
tion (B.2).
If we assume that G is not identically 0, then there exists
c âˆˆ[x1, x2] such that G(c) Ì¸= 0. By continuity, there exist a, b such that
xa â‰¤a < c < b â‰¤x2 and G(x) Ì¸= 0 for all x âˆˆ[a, b]. Now consider the
function
Î·(x) =
â§
âª
â¨
âª
â©
0,
for x1 â‰¤x â‰¤a,
G(c)(x âˆ’a)2(x âˆ’b)2,
for a â‰¤x â‰¤b,
0,
for b â‰¤x â‰¤x2.
The function Î·(x) is continuously diï¬€erentiable, and we have
% x2
x1
Î·(x)G(x) dx =
% b
a
G(c)G(x)(x âˆ’a)2(x âˆ’b)2 dx.
The integrand on the right is nonnegative since G(x) has the same sign as
G(c) and, by construction, equal to 0 only at x = a and x = b. Conse-
quently, the integral on the right is positive. This proves the lemma.
â–¡
Let us consider the ï¬rst problem in the calculus of variations, in which
we wish to optimize the integral in Equation (B.1), with the only condition
that y(x1) = y1 and y(x2) = y2. The general tactic proceeds as follows.
Assume y(x) is a function that optimizes I(y). Let Î·(x) be an arbitrary
continuously diï¬€erentiable function on [x1, x2], with Î·(x1) = Î·(x2) = 0.
Deï¬ne the one-parameter family of functions YÎµ by
YÎµ(x) = y(x) + ÎµÎ·(x).
Obviously, for all Îµ, we have YÎµ(x1) = y(x1) = y1 and YÎµ(x2) = y(x2) = y2.
For shorthand, we deï¬ne
I(Îµ) = I(YÎµ) =
% x2
x1
f(x, YÎµ, Y â€²
Îµ) dx.
With this notation, we see that I(0) = I(y), and since y(x) is an optimizing
function, then
Iâ€²(0) = 0
(B.3)
no matter the choice of arbitrary function Î·(x).

350
B. Calculus of Variations
To calculate the derivative in Equation (B.3), we obtain
Iâ€²(Îµ) =
% x2
x1
 âˆ‚f
âˆ‚Y
âˆ‚Y
âˆ‚Îµ + âˆ‚f
âˆ‚Y â€²
âˆ‚Y â€²
âˆ‚Îµ
	
dx =
% x2
x1
 âˆ‚f
âˆ‚Y Î· + âˆ‚f
âˆ‚Y â€² Î·â€²
	
dx,
where âˆ‚f
âˆ‚Y means explicitly âˆ‚f
âˆ‚y (x, YÎµ(x), Y â€²
Îµ(x)) and similarly for
âˆ‚f
âˆ‚Y â€² . Set-
ting Equation (B.3) then becomes
Iâ€²(0) =
% x2
x1
âˆ‚f
âˆ‚y Î· + âˆ‚f
âˆ‚yâ€² Î·â€²
	
dx = 0.
Integrating the second term in this integral by parts, we obtain
Iâ€²(0) =
> âˆ‚f
âˆ‚yâ€² Î·(x)
?x2
x1
+
% x2
x1
âˆ‚f
âˆ‚y Î· âˆ’d
dx
 âˆ‚f
âˆ‚yâ€²
	
Î· dx
=
% x2
x1
âˆ‚f
âˆ‚y âˆ’d
dx
 âˆ‚f
âˆ‚yâ€²
		
Î· dx = 0.
Applying Lemma B.2.1 to the above equation proves the following theorem.
Theorem B.2.2. Let y : [x1, x2] â†’R be a function that optimizes
I(y) =
% x2
x1
f(x, y, yâ€²) dx.
Then y satisï¬es the diï¬€erential equation
âˆ‚f
âˆ‚y âˆ’d
dx
 âˆ‚f
âˆ‚yâ€²
	
= 0,
(B.4)
which is called the Euler-Lagrange equation.
Just as a solution x0 to f â€²(x) = 0 is not necessarily a maximum or
minimum, a function that does satisfy this equation is not necessarily an
optimizing function. Consequently, we call a solution to Equation (B.4)
an extremizing function. Understanding that âˆ‚f
âˆ‚yâ€² means fyâ€²(x, y(x), yâ€²(x)),
one notices that the Euler-Lagrange equation is a second-order diï¬€erential
equation of y in terms of x.
Since Equation (B.4), and in particular the left-hand side of this equa-
tion, occurs frequently, we deï¬ne it as the Lagrangian operator L on a
function f(x, y, yâ€²), where y is a function of x, by
L(f) = âˆ‚f
âˆ‚y âˆ’d
dx
 âˆ‚f
âˆ‚yâ€²
	
.
Note that L is a linear operator in f. On the other hand, whether the
diï¬€erential equation L(f) = 0 is a linear operator in y(x) depends on f.

B.2. The Euler-Lagrange Equation
351
B.2.2
The Brachistochrone Problem
At the turn of the eighteenth century, Johann Bernoulli posed the problem
of ï¬nding the path in space that a particle will take when traveling un-
der the action of gravity between two ï¬xed points but taking the shortest
amount of time. To be precise, the problem assumes no friction, a simple
constant force of gravity mg (where m is the mass of the particle and g
the gravity constant), and an initial velocity v1 that is not necessarily 0.
This problem became known as the â€œbrachistochroneâ€ problem, the roots
of which come from the Greek words brachistos (shortest) and chronos
(time).
We suppose the two ï¬xed points A and B lie in a vertical plane that we
can label as the xy-plane, with the y-axis directed vertically upward and
the x-axis oriented so that passing from A to B means an increase in x.
Let A = (x1, y1) and B = (x2, y2) so that any curve y(x) connecting A and
B satisï¬es y(x1) = y1 and y(x2) = y2. Note that though the shape of a
curve from A to B is a function y(x), a particle moving along this curve
under the action of gravity travels with nonconstant speed.
The speed along the curve is given by v =
ds
dt , where the arclength
function s(x) satisï¬es
ds
dx =

1 + (yâ€²(x))2.
The total time T of descent along the path y(x) is given by the integral
T =
% x=x2
x=x1
1dt =
% x2
x1
ds
v =
% x2
x1

1 + (yâ€²)2
v
dx.
Since there is no friction and since gravity is a conservative force, the sum
of the kinetic energy and potential energy remains constant, namely,
1
2mv2
1 + mgy1 = 1
2mv + mgy.
Solving for v we obtain
v =

v2
1 + 2gy1 âˆ’2gy =

2gâˆšy0 âˆ’y,
where y0 = y1 + (v2
1/2g) is the height from which the particle descended
from rest to reach v1 at height y1. The time of travel is
T =
1
âˆš2g
% x2
x1

1 + (yâ€²)2
âˆšy0 âˆ’y
dx,
(B.5)

352
B. Calculus of Variations
and ï¬nding the path with the shortest time of travel amounts to ï¬nding a
function y(x) that minimizes this integral.
Applying the Euler-Lagrange equation, we label the integrand in Equa-
tion (B.5) as
f(x, y, yâ€²) =

1 + (yâ€²)2
âˆšy0 âˆ’y .
(B.6)
One notices that this problem has one simpliï¬cation from the general Euler-
Lagrange equation: f does not depend explicitly on x. This fact allows one
to make a useful simpliï¬cation. The chain rule gives
df
dx = âˆ‚f
âˆ‚x + yâ€² âˆ‚f
âˆ‚y + yâ€²â€² âˆ‚f
âˆ‚yâ€² = yâ€² âˆ‚f
âˆ‚y + yâ€²â€² âˆ‚f
âˆ‚yâ€²
since f does not depend directly on x. However,
d
dx

yâ€² âˆ‚f
âˆ‚yâ€²
	
= yâ€²â€² âˆ‚f
âˆ‚yâ€² + yâ€² d
dx
 âˆ‚f
âˆ‚yâ€²
	
,
so
df
dx = d
dx

yâ€² âˆ‚f
âˆ‚yâ€²
	
+ yâ€²
âˆ‚f
âˆ‚y âˆ’d
dx
 âˆ‚f
âˆ‚yâ€²
		
= d
dx

yâ€² âˆ‚f
âˆ‚yâ€²
	
,
where the second term in the middle expression is identically 0 due to
the Euler-Lagrange equation. Integrating both sides with respect to x we
obtain
yâ€² âˆ‚f
âˆ‚yâ€² âˆ’f = C
for some constant C. Using the speciï¬c function in Equation (B.6), we
obtain
(yâ€²)2

(y0 âˆ’y)(1 + (yâ€²)2)
âˆ’

1 + (yâ€²)2
âˆšy0 âˆ’y
= C.
Solving for yâ€² = dy
dx, we obtain
dy
dx =

Câˆ’2 âˆ’(y0 âˆ’y)
âˆšy0 âˆ’y
,
which, upon taking the inverse and integrating with respect to y, becomes
x =
%
âˆšy0 âˆ’y

Câˆ’2 âˆ’(y0 âˆ’y)
dy.
(B.7)
Using the substitution
y0 âˆ’y = 1
C2 sin2 Î¸
2,
(B.8)

B.3. Several Dependent Variables
353
the integral in Equation (B.7) becomes
x = âˆ’1
C2
%
sin2 Î¸
2 dÎ¸ = âˆ’1
2C2
%
1 âˆ’cos Î¸ dÎ¸
=
1
2C2 (sin Î¸ âˆ’Î¸) + x0,
where x0 is some constant of integration. Rewriting Equation (B.8), setting
a = 1/(2C2), and substituting t = âˆ’Î¸, we obtain the equations

x = x0 + a(t âˆ’sin t),
y = y0 âˆ’a(1 âˆ’cos t).
Obviously, these equations do not give y as an explicit function of x but do
show that the path with most rapid descent is in the shape of an upside-
down cycloid.
B.3
Several Dependent Variables
B.3.1
The Main Theorem
A ï¬rst generalization to the basic problem in the calculus of variations
is to ï¬nd n twice-diï¬€erentiable functions x1(t), . . . , xn(t) deï¬ned over the
interval [t1, t2] that optimize the integral
I =
% t2
t1
f(x1, . . . , xn, xâ€²
1, . . . , xâ€²
n, t) dt.
We follow the same technique as in Section B.2. Label x1(t), . . . , xn(t) as
the actual optimizing functions and deï¬ne corresponding one-parameter
families of functions by
Xi(t) = xi(t) + ÎµÎ¾i(t),
where Î¾i(t) are any diï¬€erentiable functions with
Î¾i(t1) = Î¾i(t2) = 0
for 1 â‰¤i â‰¤n.
With the one-parameter families Xi, we form the integral
I(Îµ) =
% t2
t1
f(X1, . . . , Xn, Xâ€²
1, . . . , Xâ€²
n, t) dt.
Then I(0) = I, and since by assumption the functions x1, . . . , xn are the
optimizing functions, we must also have Iâ€²(0) = 0.

354
B. Calculus of Variations
Taking the derivative of I(Îµ) and using the chain rule, we have
Iâ€²(Îµ) =
% t2
t1
âˆ‚f
âˆ‚X1
Î¾1 + Â· Â· Â· + âˆ‚f
âˆ‚Xn
Î¾n + âˆ‚f
âˆ‚Xâ€²
1
Î¾â€²
1 + Â· Â· Â· + âˆ‚f
âˆ‚Xâ€²n
Î¾â€²
n dt,
where by âˆ‚f/âˆ‚Xi we mean the partial derivative to f with respect to
the variable that one evaluates to be the one parameter of functions Xi.
Regardless of the arbitrary functions Î¾i, setting Îµ = 0 replaces the family
of functions Xi with the function xi. Using the same abuse of notation for
âˆ‚f/âˆ‚xi, we have
Iâ€²(0) =
% t2
t1
âˆ‚f
âˆ‚x1
Î¾1 + Â· Â· Â· + âˆ‚f
âˆ‚xn
Î¾n + âˆ‚f
âˆ‚xâ€²
1
Î¾â€²
1 + Â· Â· Â· + âˆ‚f
âˆ‚xâ€²n
Î¾â€²
n dt = 0.
Since this equation must hold for all choices of the functions xi, we can in
particular set Î¾j = 0 for all indices j Ì¸= i. The we deduce that
% t2
t1
âˆ‚f
âˆ‚xi
Î¾i + âˆ‚f
âˆ‚xâ€²
i
Î¾â€²
i dt = 0
for all i.
Integrating the second term in the above integral by parts and using the
fact that Î¾i(t1) = Î¾i(t2) = 0, we obtain
% t2
t1
 âˆ‚f
âˆ‚xi
âˆ’d
dt
 âˆ‚f
âˆ‚xâ€²
i
		
Î¾i dt = 0.
Then using Lemma B.2.1, we deduce the following theorem.
Theorem B.3.1. Consider the integral
I =
% t2
t1
f(x1, . . . , xn, xâ€²
1, . . . , xâ€²
n, t) dt,
where f is a continuous function and where each function xi(t) is twice-
diï¬€erentiable and deï¬ned over [t1, t2]. Then the functions x1, x2, . . . , xn
optimize the integral I if and only if
âˆ‚f
âˆ‚xi
âˆ’d
dt
 âˆ‚f
âˆ‚xâ€²
i
	
= 0
for all 1 â‰¤i â‰¤n.
Here again, if f is a function as deï¬ned in the above theorem, we deï¬ne
the Lagrangian operator Li or Lxi as
Li(f) = âˆ‚f
âˆ‚xi
âˆ’d
dt
 âˆ‚f
âˆ‚xâ€²
i
	
.

B.3. Several Dependent Variables
355
B.3.2
Lagrange Equations of Motion
As a ï¬rst application of Theorem B.3.1, we present the Lagrange equa-
tions of motion, which do not replace but rather rephrase Newtonâ€™s laws
of motion. In fact, this reformulation is particularly well suited for solving
equations of motion of a particle when the particle is naturally conï¬ned to
a predeï¬ned subset of R3 or when considering the motion of a solid.
As simple examples, consider the motion of a bead on a ring or a particle
on the surface of a sphere acted on by external forces. These examples
indicate that for many situations the usual Cartesian coordinates in R2 or
R3 are not ideal since they are not independent. If a particle is constrained
to a circle, one would tend to use the angle Î¸ as a coordinate, and if a
particle is constrained to a sphere, one would tend to use the longitude
and latitude (Î¸, Ï•).
Therefore, we assume that the positional state of a particular physical
system can be described using coordinates q1, q2, . . . , qn that depend on
the independent time variable t. One calls the derivatives (with respect
to time) qâ€²
1, qâ€²
2, . . . , qâ€²
n the generalized velocities. Both the kinetic energy T
and potential energy V can be expressed as functions of q1, q2, . . . , qn and
qâ€²
1, qâ€²
2, . . . , qâ€²
n. If forces involved in the system are time dependent, then T
and V may also depend explicitly on the time variable t.
Hamiltonâ€™s principle states that the motion of a system evolves so as to
minimize the integral
S =
%
P
L dt =
% t2
t1
L dt
(B.9)
for arbitrary moments in time t1 and t2, where L is the Lagrangian function.
The integral S is called the action of the system.
When the system is
under the inï¬‚uence of only conservative forces, it is possible to show that
the Lagrangian is L = T âˆ’V , where T is the kinetic energy and V is the
potential energy. Problem 6.1.8 presented the action for a nonconservative
force.
Theorem B.3.1 allows us to deduce the Lagrange equations from this
principle, namely, Li(L) = 0 for all variables qi or, in other words,
âˆ‚L
âˆ‚qi
âˆ’d
dt
 âˆ‚L
âˆ‚qâ€²
i
	
= 0
for all 1 â‰¤i â‰¤n.
Example B.3.2 (The Spherical Pendulum). As an example, consider the spheri-
cal pendulum (see Figure B.1). This classical problem consists of a point

356
B. Calculus of Variations
x
y
z
 Ï•
Î¸
Figure B.1. Spherical pendulum.
mass that is hanging from a string and is free to move not just in a vertical
plane but in both its natural degrees of freedom. We label the mass of
the object at the end of the string as m and the length of the string as l.
For simplicity, we assume that the string is massless and that there is no
friction where the string attaches at a ï¬xed point. This scenario is called
the spherical pendulum problem because the same equations govern the
motion of an object moving in a spherical bowl under the action of gravity
and with no (negligible) friction.
We use a Cartesian frame of reference, in which the origin is the ï¬xed
point to which the string is attached and the z-axis lines up with the
vertical axis that the string makes when at rest and hanging straight down.
Furthermore, we orient the z-axis downward. With this setup, the degrees
of freedom are the usual angles Î¸ and Ï• from spherical coordinates. To
obtain the Lagrange equations of motion, we need to ï¬rst identify the
kinetic energy T and potential energy V .
The velocity vector for the particle moving at the end of the string is
âƒ—v = l(Ï•â€² cos Ï• cos Î¸ âˆ’Î¸â€² sin Ï• sin Î¸, Ï•â€² cos Ï• sin Î¸ + Î¸â€² sin Ï• cos Î¸, âˆ’Ï•â€² sin Ï•),
so after simpliï¬cations, the kinetic energy is
T = 1
2mgl2 
(Ï•â€²)2 + (Î¸â€²)2 sin2 Ï•

.
The potential energy is V = mgl(1 âˆ’cos Ï•), so the Lagrangian is
L = 1
2mgl2 
(Ï•â€²)2 + (Î¸â€²)2 sin2 Ï•

âˆ’mgl(1 âˆ’cos Ï•).

B.3. Several Dependent Variables
357
The Lagrange equations of motion are
d
dt
 âˆ‚L
âˆ‚Î¸â€²
	
= âˆ‚L
âˆ‚Î¸
and
d
dt
 âˆ‚L
âˆ‚Ï•â€²
	
= âˆ‚L
âˆ‚Ï•,
which lead to
d
dt

ml2Î¸â€² sin2 Ï•

= 0
and
d
dt

ml2Ï•â€²
= ml2(Î¸â€²)2 sin Ï• cos Ï• âˆ’mgl sin Ï•.
After simpliï¬cations, this leads to the two equations
pÎ¸
def
= ml2Î¸â€² sin2 Ï• = const.,
(B.10)
Ï•â€²â€² = sin Ï•

(Î¸â€²)2 cos Ï• âˆ’g
l

.
Since the expression we labeled as pÎ¸ is a constant, we can solve for Î¸â€² out
of the ï¬rst equation and write the second equation only in terms of Ï• to
get the following system:
â§
âª
â¨
âª
â©
pÎ¸ = ml2Î¸â€² sin2 Ï•,
Ï•â€²â€² =
p2
Î¸
m2l4
cos Ï•
sin3 Ï• âˆ’g
l sin Ï•.
(B.11)
It might appear that the sin3 Ï• in the denominator in the second equa-
tion in Equation (B.11) could be a cause for concern at Ï• = 0 but it is not,
as we now explain. If pÎ¸ = 0, then the second equation in Equation (B.11)
does not possess a singularity at Ï• = 0. On the other hand, if pÎ¸ Ì¸= 0, then
by Equation (B.10), Ï• is never 0.
We have isolated the variable Ï•.
Thus, one solves the equations of
motion for a spherical pendulum by ï¬rst solving the second equation in
Equation (B.11) for Ï•(t). By integrating the ï¬rst equation, one then ob-
tains
Î¸â€² =
pÎ¸
ml2 sin2(Ï•(t)),
and Î¸(t) follows by integration once more.
B.3.3
Hamilton Equations of Motion
We now present the Hamilton equations of motion, which arise as a natu-
ral progression from Lagrange equations and also have important theoret-
ical consequences. The presentation we give here is the classical format,
where one does not worry about what the coordinates (q1, . . . , qn) actually
parametrize. The reader should compare this to the modern formulation
of Hamiltonian mechanics, which is presented in Section 6.1.

358
B. Calculus of Variations
As with the Lagrange equations above, we use a set of coordinates
(q1, q2, . . . , qn) to describe the position of the particle or system of particles
whose motion we wish to describe. We associate to each coordinate qi the
generalized momenta pi deï¬ned by
pi = âˆ‚L
âˆ‚qâ€²
i
,
where L is the Lagrangian.
Deï¬ne now the Hamiltonian of the physical system as the function in
terms of the 2n variables q1, . . . , qn, p1, . . . , pn deï¬ned by
H =
n

i=1
piqâ€²
i âˆ’L .
Writing L = " piqâ€²
iâˆ’H, we view the Lagrangian as a function that depends
explicitly on the variables q1, . . . , qn, p1, . . . , pn, their derivatives with re-
spect to time, and the variable time t. We obtain the Hamilton equations
of motion by applying Hamiltonâ€™s principle to the Lagrangian phrased in
this manner. Consequently, we require that the integral in Equation (B.9)
be minimized for all pairs (t1, t2), and we deduce, by the Euler-Lagrange
equations, that
d
dt
âˆ‚
âˆ‚qâ€²
i
 n

i=1
piqâ€²
i âˆ’H

= âˆ‚
âˆ‚qi
 n

i=1
piqâ€²
i âˆ’H

,
and
d
dt
âˆ‚
âˆ‚pâ€²
i
 n

i=1
piqâ€²
i âˆ’H

=
âˆ‚
âˆ‚pi
 n

i=1
piqâ€²
i âˆ’H

.
Since by deï¬nition of the generalized momenta, âˆ‚L/âˆ‚qâ€²
i = pi, the previ-
ous system of 2n equations leads immediately to the following Hamilton
equations of motion:
â§
âª
âª
â¨
âª
âª
â©
pâ€²
i
= âˆ’âˆ‚H
âˆ‚qi
,
qâ€²
i
= âˆ‚H
âˆ‚pi
.
This formulation of the equations of motion for a physical system may,
at ï¬rst glance, seem a little obtuse, but a careful reader should note that
they apply to nonconservative systems, systems in which the potential en-
ergy may depend on some qâ€²
i, and systems in which L depends explicitly
on time. In practice, when solving simple problems in dynamics, Newtonâ€™s
laws of motion or perhaps the Lagrange equation suï¬ƒce. On the other

B.4. Isoperimetric Problems and Lagrange Multipliers
359
hand, the Hamiltonian formulation is central to quantum mechanics and
useful for theoretical mechanics.
If the system is conservative and the potential energy V does not depend
explicitly on qâ€²
i, then the Hamiltonian H is equal to the total energy of the
system, as we shall see.
First note that since âˆ‚V/âˆ‚qâ€²
i = 0, then pi =
âˆ‚T/âˆ‚qâ€²
i.
Suppose that we label a particle in the system as j, and call
its coordinates in a Cartesian system (xj, yj, zj). Since the whole system
can be described by the generalized coordinates q1, q2, . . . , qn, then the
coordinates (xj, yj, zj) are functions of the qis. Then we can write
xâ€²
j =
n

i=1
âˆ‚xj
âˆ‚qi
qâ€²
i,
yâ€²
j =
n

i=1
âˆ‚yj
âˆ‚qi
qâ€²
i,
zâ€²
j =
n

i=1
âˆ‚zj
âˆ‚qi
qâ€²
i,
where all derivatives are taken with respect to time t. Then, the kinetic
energy of the physical system (whether one must integrate or merely take
a summation), one has
T = 1
2

j
mj((xâ€²
j)2 + (yâ€²
j)2 + (zâ€²
j)2),
and so T is homogeneous of degree 2 in the variables qâ€²
i. Thus, we have in
particular
2T =
n

i=1
qâ€²
i
âˆ‚T
âˆ‚qâ€²
i
=
n

i=1
qâ€²
ipi.
(B.12)
Because of Equation (B.12), we can also write
H = 2T âˆ’(T âˆ’V ) = T + V,
which shows that H is the total energy of the system, a fact that does not
hold if V is a function of the generalized velocities qâ€²
i.
B.4
Isoperimetric Problems and Lagrange Multipliers
B.4.1
The Main Theorem
In this section, we approach a new class of problems in which one desires
not only to optimize a certain integral but to do so considering only func-
tions that satisfy an additional criterion besides the usual restriction of
continuity. In all the problems we consider, the criteria consist of imposing
a prescribed value on a certain integral related to our variable function.

360
B. Calculus of Variations
More precisely, we will wish to construct a function x(t) deï¬ned over an
interval [t1, t2] that optimizes the integral
I =
% t2
t1
f(x, xâ€², t) dt,
(B.13)
subject to the condition that
% t2
t1
g(x, xâ€², t) dt = J
(B.14)
for some ï¬xed value of J. It is assumed that f and g are twice-diï¬€erentiable
functions in their variables.
Such a problem is called an isoperimetric
problem.
Following the same approach as in Section B.2, we label x(t) as the
actual optimizing function to the integral in Equation (B.13), which we
assume also satisï¬es Equation (B.14), and we introduce a two-parameter
family of functions
X(t) = x(t) + Îµ1Î¾1(t) + Îµ2Î¾2(t),
where Î¾1(t) and Î¾2(t) are any diï¬€erentiable functions that satisfy
Î¾1(t1) = Î¾2(t1) = Î¾1(t2) = Î¾2(t2) = 0.
(B.15)
The condition in Equation (B.15) guarantees that X(t1) = x(t1) = x1 and
X(t2) = x(t2) = x2 for all choices of the parameters Îµ1 and Îµ2. We use the
family of functions X(t) as a comparison to the optimizing function x(t),
but in contrast to Section B.2, we need a two-parameter family, as we shall
see shortly.
We replace the function x(t) with the family X(t) in Equations (B.13)
and (B.14) to obtain
I(Îµ1, Îµ2) =
% t2
t1
f(X, Xâ€², t) dt
and
J(Îµ1, Îµ2) =
% t2
t1
g(X, Xâ€², t) dt.
The parameters Îµ1 and Îµ2 cannot be independent if the family X(t) is to
always satisfy Equation (B.14).
Indeed, since J is constant, Îµ1 and Îµ2
satisfy the equation
J(Îµ1, Îµ2) = J
(a constant).
(B.16)

B.4. Isoperimetric Problems and Lagrange Multipliers
361
Since x(t) is assumed to be the optimizing function, then I(Îµ1, Îµ2) is op-
timized with respect to Îµ1 and Îµ2, subject to Equation (B.16) when Îµ1 =
Îµ2 = 0, no matter the particular choice of Î¾1(t) and Î¾2(t).
Consequently, one can apply the method of Lagrange multipliers, usu-
ally presented in a multivariable calculus course. Following that method,
I(Îµ1, Îµ2) is optimized, subject to Equation (B.16), when
â§
â¨
â©
âˆ‚I
âˆ‚Îµi
= Î» âˆ‚J
âˆ‚Îµi
,
for i = 1, 2, and
J(Îµ1, Îµ2) = J,
(B.17)
where Î» is a free parameter called the Lagrange multiplier. In order to
apply this to Euler-Lagrange methods of optimizing integrals, deï¬ne the
function
f âˆ—(x, xâ€², t) = f(x, xâ€², t) âˆ’Î»g(x, xâ€², t).
Then the ï¬rst two equations in Equation (B.17) are tantamount to solving
âˆ‚f âˆ—
âˆ‚Îµi
= 0.
Following a nearly identical approach as in Section B.2, the details of which
we leave to the interested reader, one can prove the following theorem.
Theorem B.4.1. Assume that f and g are twice-diï¬€erentiable functions
R3 â†’R. Let x : [t1, t2] â†’R be a function that optimizes
I =
% t2
t1
f(x, xâ€², t) dt,
subject to the condition that
J =
% t2
t1
g(x, xâ€², t) dt
remains constant. Then x satisï¬es the diï¬€erential equation
âˆ‚f âˆ—
âˆ‚x âˆ’d
dt
âˆ‚f âˆ—
âˆ‚xâ€²
	
= 0,
(B.18)
where f âˆ—= f âˆ’Î»g. Furthermore, the solution to Equation (B.18) produces
an expression for x(t) that depends on two constants of integration and the
parameter Î» and, if a solution to this isoperimetric problem exists, then
these quantities are ï¬xed by requiring that x(t1) = x1, x(t2) = x2, and J
be a constant.

362
B. Calculus of Variations
Many generalizations extend this theorem, but rather than presenting
in great detail the variants thereof, we present an example that shows why
one refers to the class of problems presented in this section as isoperimetric
problems.
B.4.2
Problem of Maximum Enclosed Area
Though simple to phrase and yet surprisingly diï¬ƒcult to solve is the clas-
sic question, â€œWhat closed simple curve of ï¬xed length encloses the most
area?â€
Even Greek geometers â€œknewâ€ that if one ï¬xes the length of a
closed curve, the circle has the largest area, but no rigorous proof is possi-
ble without the techniques of calculus of variations.
To solve this problem, consider parametric curves âƒ—x = (x(t), y(t)) with
t âˆˆ[t1, t2].
We assume the curve is closed so that âƒ—x(t1) = âƒ—x(t2) and
similarly for all derivatives of âƒ—x. The arclength formula for this curve is
S =
% t2
t1

(xâ€²)2 + (yâ€²)2 dt,
and by a corollary to Greenâ€™s Theorem, the area of the enclosed region is
A =
% t2
t1
xyâ€² dt.
Therefore, we wish to optimize the integral A, subject to the constraint
that the integral S is ï¬xed, say S = p.
Following Theorem B.4.1 but adapting it to the situation of more than
one dependent variable, we deï¬ne the function
f âˆ—(x, xâ€², y, yâ€², t) = xyâ€² âˆ’Î»

xâ€²2 + yâ€²2,
and conclude that the curve with the greatest area satisï¬es

Lx(f âˆ—) = 0,
Ly(f âˆ—) = 0.
(B.19)
Taking appropriate derivatives, Equation (B.19) becomes
â§
âª
âª
âª
âª
âª
â¨
âª
âª
âª
âª
âª
â©
yâ€² + Î» d
dt

xâ€²

xâ€²2 + yâ€²2

= 0,
d
dt

x âˆ’Î»
yâ€²

xâ€²2 + yâ€²2

= 0,

B.4. Isoperimetric Problems and Lagrange Multipliers
363
and integrating with respect to t, we obtain
â§
âª
âª
âª
â¨
âª
âª
âª
â©
y + Î»
xâ€²

xâ€²2 + yâ€²2 = C1,
x âˆ’Î»
yâ€²

xâ€²2 + yâ€²2 = C2.
From this, we deduce the relation
(x âˆ’C2)2 + (y âˆ’C1)2 = Î»2,
(B.20)
which means that the curve with a given perimeter and with maximum area
lies on a circle. Since the curve is closed and simple, the parametric curve
âƒ—x(t) is an injective function (except for âƒ—x(t1) = âƒ—x(t2)), and the image is in
fact a circle, though there is no assumption that âƒ—x travels around the circle
at a uniform rate. That the Lagrange multiplier appears in Equation (B.20)
is not an issue because, since we know that the perimeter is ï¬xed at p, we
know that Î» = p/2Ï€.


APPENDIX
C
Multilinear Algebra
Manifolds can be thought of locally as vector spaces in the sense that at
any point of the manifold, the tangent space is a vector space. Therefore,
in order to properly understand the objects of interest in the study of
manifolds, it is necessary to deï¬ne and study multilinear functions and
related vector spaces.
This appendix introduces multilinear algebraic objects arising in this
book that are not commonly included in a ï¬rst linear algebra course. The
underlying ï¬eld for all the objects in this book is the ï¬eld of real numbers
R, but this appendix introduces the concepts for an arbitrary ï¬eld K of
characteristic 0.
The reader may wish to think of R or C since these
are the most commonly used base ï¬elds in geometry. (In fact, many of
the deï¬nitions and propositions in this appendix can be generalized to
modules over commutative rings. See [30] for a comprehensive introduction
to module theory.)
Before discussing multilinear algebra, we wish to stress the sometimes
overlooked fact that coordinates depend on a particular basis. Let V be
a vector space over K. If V is ï¬nite-dimensional, with dim V = n, and if
B = {âƒ—u1, . . . , âƒ—un} is a basis of V , the coordinates of âƒ—v with respect to B are
[âƒ—v]B =
â›
âœ
âœ
âœ
â
v1
v2
...
vn
â
âŸ
âŸ
âŸ
â ,
where
âƒ—v = v1âƒ—u1 + Â· Â· Â· vnâƒ—un.
If the basis of V is understood from the problem or if one uses a standard
basis of V , one writes [âƒ—v] for the coordinates or just âƒ—v, though this latter
designation is an abuse of notation since it confuses the vector with its
coordinates in a particular coordinate system.
365

366
C. Multilinear Algebra
C.1
Direct Sums
If V1 and V2 are subspaces of a vector space V , one deï¬nes the vector
subspace sum as the set
V1 + V2 = {âƒ—v âˆˆV |âƒ—v = âƒ—v1 + âƒ—v2, where âƒ—v1 âˆˆV1 and âƒ—v1 âˆˆV1}.
It is an easy exercise to see that this is closed under addition and scalar
multiplication, making this subset a new subspace of V . In general, V1 and
V2 share a subspace V1 âˆ©V2 that need not be the null space, and when this
occurs, the expression âƒ—v1 + âƒ—v2 for a vector in V1 + V2 need not be unique.
Two subspaces V1 and V2 of a vector space V are called complements if
V = V1 + V2 and V1 âˆ©V2 = {âƒ—0}. (See Figure C.1.) It is also an exercise in
linear algebra to prove that V1 and V2 are complements in V if and only if
every âƒ—v âˆˆV can be written uniquely as âƒ—v = âƒ—v1 +âƒ—v2 for âƒ—v1 âˆˆV1 and âƒ—v2 âˆˆV2.
We leave it as an exercise (Problem C.1.1) to show that if V1 and V2 are
complements in V , then
dim V1 + dim V2 = dim V.
Deï¬nition C.1.1. Let V and W be two vector spaces over a ï¬eld K. The
direct sum V âŠ•W is the vector space with underlying set V Ã— W and
operations deï¬ned as follows:
1. (âƒ—v1, âƒ—w1) + (âƒ—v2, âƒ—w2) = (âƒ—v1 + âƒ—v2, âƒ—w1 + âƒ—w2).
2. c Â· (âƒ—v, âƒ—w) = (câƒ—v, câƒ—w) for all c âˆˆK.
As phrased, this deï¬nition makes the implicit assumption that the de-
scribed set equipped with the given operations satisï¬es the deï¬nition of a
vector space, but this is an easy exercise that we omit here.
In the direct sum V âŠ•W, the subspace of vectors (âƒ—v,âƒ—0) is isomorphic
to V and the subspace of vectors (âƒ—0, âƒ—w) is isomorphic to W and so, by
an abuse of notation, we will often say that V and W are subspaces of
V âŠ•W, with V and W identiï¬ed according to these natural isomorphisms.
As subspaces of V âŠ•W, we have V âˆ©W = {âƒ—0} and V âŠ•W = V + W,
so V and W are complements in V âŠ•W. Therefore, we conclude that if
{âƒ—v1, . . . ,âƒ—vm} is a basis of V and {âƒ—w1, . . . , âƒ—wn} is a basis of W, then the set
{(âƒ—v1,âƒ—0), . . . , (âƒ—vm,âƒ—0), (âƒ—0, âƒ—w1), . . . , (âƒ—0, âƒ—wn)}
is a basis of V âŠ•W. Consequently, one also has the following equality for
dimensions:
dim(V âŠ•W) = dim V + dim W.

C.1. Direct Sums
367
V1
 V2
Figure C.1. Complementary subspaces of R3.
As a point of notation, if V is any vector space over a ï¬eld K, we use
the notation V n to denote the repeated direct sum
V n = V âŠ•V âŠ•Â· Â· Â· âŠ•V,
where there are n copies of V in the direct sum.
Problems
C.1.1. Prove that if V1 and V2 are complementary subspaces of V , then dim V1 +
dim V2 = dim V .
C.1.2. Let V1, V2, W1, and W2 be vector spaces over a ï¬eld K. Suppose that
L : V1 â†’V2 and T : W1 â†’W2 are linear transformations with respect to
given bases. Deï¬ne the function
f : V1 âŠ•W1 â†’V2 âŠ•W2
(âƒ—v, âƒ—w) âˆ’â†’(L(âƒ—v), T(âƒ—w)).
Prove that f is a linear transformation and that the matrix of f with
respect to natural bases on V1 âŠ•W1 and V2 âŠ•W2 is block diagonal.
C.1.3. Let V and W be ï¬nite-dimensional vector spaces over a ï¬eld K with
dimensions m and n, respectively, and let f : V â†’W be a linear trans-
formation. Deï¬ne the linear transformation
T : V âŠ•W â†’V âŠ•W
(âƒ—v, âƒ—w) âˆ’â†’(âƒ—v,âƒ—v + f(âƒ—w)).
(a) Prove that the only eigenvalue of T is 1 (with multiplicity m + n).
(b) Prove that the eigenspace of 1 is
E1 = ker f âŠ•W,
and conclude that the geometric multiplicity of 1 is m + n âˆ’rank f.

368
C. Multilinear Algebra
C.1.4. Let V be a vector space, and let W be a subspace. Deï¬ne the relation âˆ¼
on vectors of V by
âƒ—v1 âˆ¼âƒ—v2 â‡â‡’âƒ—v1 âˆ’âƒ—v2 âˆˆW.
(a) Prove that âˆ¼is an equivalence relation.
(b) Denote by V/W the set of equivalence classes. Prove that V/W has
the structure of a vector space under the operations: [âƒ—v1] + [âƒ—v2] =
[âƒ—v1 + âƒ—v2] and c Â· [âƒ—v] = [câƒ—v].
(c) Suppose that V is ï¬nite-dimensional. Prove that dim V/W = dim V âˆ’
dim W .
(The vector space V/W is called the quotient vector space of V with
respect to W .)
C.2
Bilinear and Quadratic Forms
Deï¬nition C.2.1. Let V and W be vector spaces over the ï¬eld K. A bilinear
form âŸ¨Â·, Â·âŸ©on V Ã— W is a function V Ã— W â†’K such that for all âƒ—v âˆˆV ,
âƒ—w âˆˆW, and all Î» âˆˆK,
âŸ¨Î»âƒ—v, âƒ—wâŸ©= Î»âŸ¨âƒ—v, âƒ—wâŸ©,
and
âŸ¨âƒ—v, Î»âƒ—wâŸ©= Î»âŸ¨âƒ—v, âƒ—wâŸ©.
Equivalently, given any ï¬xed âƒ—v0 âˆˆV ,
âƒ—x â†’âŸ¨âƒ—v0, âƒ—xâŸ©
is a linear transformation W â†’K, and for any ï¬xed âƒ—w0 âˆˆW,
âƒ—x â†’âŸ¨âƒ—x, âƒ—w0âŸ©
is linear from V to K. Consequently, a bilinear form is also called a bilinear
transformation.
The notation used for a bilinear form varies widely in the literature
because of the many areas in which it is used. In terms of function notation,
one might encounter the functional notation f : V Ã— W â†’K or perhaps
Ï‰ : V Ã— W â†’K for a bilinear form and âŸ¨Â·, Â·âŸ©or (Â·, Â·) for the â€œproductâ€
notation. If V = W, one sometimes writes the pair (V, f) to denote the
vector space V equipped with the bilinear form f.
In basic linear algebra, the most commonly known example of a bilinear
form on Rn is the dot product between two vectors deï¬ned in terms of
standard coordinates by
âƒ—v Â· âƒ—w = v1w1 + v2w2 + Â· Â· Â· + vnwn.

C.2. Bilinear and Quadratic Forms
369
However, one should realize that the following functions Rn Ã— Rn â†’R are
also bilinear forms:
âŸ¨âƒ—v, âƒ—wâŸ©1 = v1w2 + v2w1 + v3w3 Â· Â· Â· + vnwn,
âŸ¨âƒ—v, âƒ—wâŸ©2 = 2v1w1 + v2w2 + Â· Â· Â· + vnwn,
(C.1)
âŸ¨âƒ—v, âƒ—wâŸ©3 = v1w2.
Despite this variety, bilinear forms can be completely characterized by a
single matrix.
Proposition C.2.2. Let V and W be ï¬nite-dimensional vector spaces, with
dim V = m and dim W = n. Let âŸ¨Â·, Â·âŸ©be a bilinear form on V Ã— W. Given
a basis B of V and Bâ€² of W, if we write [âƒ—v]B as the coordinates of âƒ—v in the
basis B and similarly for coordinates of vectors in W, then there exists a
unique m Ã— n matrix M such that
âŸ¨âƒ—v, âƒ—wâŸ©= [âƒ—v]T
B M [âƒ—w]B.
Furthermore, if B = {âƒ—ei, . . . ,âƒ—em} and Bâ€² = {âƒ—ui, . . . , âƒ—un}, then the entries
of M are mij = âŸ¨âƒ—ei, âƒ—ujâŸ©for 1 â‰¤i â‰¤m and 1 â‰¤j â‰¤n.
Proof: Let âƒ—v âˆˆV and âƒ—w âˆˆW be vectors with coordinates
[âƒ—v] =
â›
âœ
â
v1
...
vm
â
âŸ
â 
and
[âƒ—w] =
â›
âœ
â
w1
...
wn
â
âŸ
â .
Then since âŸ¨Â·, Â·âŸ©is bilinear,
âŸ¨âƒ—v, âƒ—wâŸ©=
m

i=1
n

j=1
viwjâŸ¨âƒ—ei, âƒ—ujâŸ©.
(C.2)
Setting mij = âŸ¨âƒ—ei, âƒ—ujâŸ©and the matrix M = (mij), for 1 â‰¤i â‰¤m,
n

j=1
âŸ¨âƒ—ei, âƒ—ujâŸ©wj
are the coordinates of M âƒ—w and then Equation (C.2) shows that âŸ¨âƒ—v, âƒ—wâŸ©=
[âƒ—v]T M[âƒ—w], where [âƒ—v]T means the coordinates of âƒ—v are written in a row vector
as opposed to a column vector.
â–¡
Deï¬nition C.2.3. Let V and W be vector spaces over K, and let âŸ¨Â·, Â·âŸ©be a
bilinear form on V Ã— W. Then âŸ¨Â·, Â·âŸ©is called

370
C. Multilinear Algebra
1. nondegenerate on the left if for all âƒ—v âˆˆV , there exists âƒ—w âˆˆW such
that âŸ¨âƒ—v, âƒ—wâŸ©Ì¸= 0;
2. nondegenerate on the right if for all âƒ—w âˆˆW, there exists âƒ—v âˆˆV such
that âŸ¨âƒ—v, âƒ—wâŸ©Ì¸= 0;
3. nondegenerate if it is non-degenerate on the right and on the left.
Furthermore, the rank of âŸ¨Â·, Â·âŸ©is the rank of its associated matrix with
respect to any basis on V and W.
Basic facts about the rank of a matrix imply that if a form is nonde-
generate on the left, then the number of rows of its associated matrix M
is equal to the rank of the form. If a form is nondegenerate on the right,
then the number of columns of M is equal to the rank of the form. Hence,
a form can only be nondegenerate if dim V = dim W.
Many applications for bilinear forms arise in geometry or analysis, and
in many situations, one has V = W or at least V isomorphic to W. In
this case, one simply says âŸ¨Â·, Â·âŸ©is a bilinear form on V . Suppose that B is
a basis on V and that M is the matrix associated to âŸ¨Â·, Â·âŸ©. If L : V â†’V
is a linear transformation with matrix A associated to the basis B, then
âŸ¨L(âƒ—v), âƒ—wâŸ©= (Aâƒ—v)T M âƒ—w = âƒ—vT AT M âƒ—w.
There exists a unique linear transformation Lâ€  : V â†’V such that âŸ¨L(âƒ—v), âƒ—wâŸ©
= âŸ¨âƒ—v, Lâ€ (âƒ—w)âŸ©for all âƒ—v, âƒ—w âˆˆV . We ï¬nd the associated matrix Aâ€  of Lâ€  by
remarking that if
âƒ—vT AT M âƒ—w = âƒ—vT M(Aâ€  âƒ—w)
for all âƒ—v, âƒ—w âˆˆV , then AT M = MAâ€  as matrices. Hence,
Aâ€  = M âˆ’1AT M.
(C.3)
Deï¬nition C.2.4. Let âŸ¨Â·, Â·âŸ©be a nondegenerate form on V , and let L : V â†’V
be a linear transformation. The linear transformation Lâ€  such that
âŸ¨L(âƒ—v), âƒ—wâŸ©= âŸ¨âƒ—v, Lâ€ (âƒ—w)âŸ©
for all âƒ—v, âƒ—w âˆˆV is called the adjoint operator to L with respect to âŸ¨Â·, Â·âŸ©.
More generally, let V and W be vector spaces equipped with nonde-
generate bilinear forms âŸ¨Â·, Â·âŸ©V and âŸ¨Â·, Â·âŸ©W . Let L : V â†’W be a linear
transformation. Then there exists a unique linear map Lâ€  : W â†’V such
that
âŸ¨L(âƒ—v), âƒ—wâŸ©W = âŸ¨âƒ—v, Lâ€ (âƒ—w)âŸ©V .

C.2. Bilinear and Quadratic Forms
371
We also call Lâ€  the adjoint of L with respect to these forms. In this more
general setting, if M1 is the matrix corresponding to âŸ¨Â·, Â·âŸ©V and M2 is the
matrix corresponding to âŸ¨Â·, Â·âŸ©W , and if A is the matrix of L, then the adjoint
matrix Aâ€  of Lâ€  is
Aâ€  = M âˆ’1
1 AT M2.
A note on terminology is necessary at this point. Some authors refer to
Lâ€  as deï¬ned above as the transpose of L with respect to a form (or forms)
and use the word adjoint of a linear transformation only in the cases when
V and W are vector spaces over C and when the form âŸ¨Â·, Â·âŸ©is sesquilinear.
(A bilinear form on a vector space over C is a form that is linear in the
ï¬rst and conjugate-linear in the second variable. See [30] for a discussion
on sesquilinear forms.) In this book, we use the terminology of adjoint
for any linear transformation Lâ€  satisfying Deï¬nition C.2.4 for any type of
nondegenerate formâ€”bilinear or sesquilinearâ€”and we use the terminology
of transpose only to refer to the usual operation on matrices as presented
in a basic linear algebra course. In doing so, we hope to dispel confusion
regarding the word â€œtranspose.â€
Example C.2.5. Let L : Rn â†’Rm be a linear transformation between Eu-
clidean spaces, with a matrix A with respect to the standard bases. For all
âƒ—v, âƒ—w âˆˆRn,
L(âƒ—v) Â· âƒ—w = (Aâƒ—v) Â· âƒ—w = (Aâƒ—v)T âƒ—w = âƒ—vT AT âƒ—w = âƒ—v Â· (AT âƒ—w).
Therefore, the transpose AT is the matrix corresponding to the adjoint of
L when we assume Rn and Rm are equipped with the usual dot product.
Proposition C.2.6. Let V , W, and U be vector spaces equipped with nonde-
generate bilinear forms. Then the following formulas hold for the adjoint:
1. (L1 + L2)â€  = Lâ€ 
1 + Lâ€ 
2 for all linear maps L1, L2 : V â†’W.
2. (cL)â€  = cLâ€  for all linear L : V â†’W and c âˆˆK.
3. (L2L1)â€  = Lâ€ 
1Lâ€ 
2 for all linear L1 : V â†’W and L2 : W â†’U.
Proof: (Left as an exercise for the reader.)
â–¡
In many areas of algebra and geometry, one is often lead to consider two
particular types of linear transformations associated to the adjoint operator
of a given nondegenerate bilinear form: automorphisms with respect to the
form and self-adjoint transformations. We describe these in the following
paragraphs.

372
C. Multilinear Algebra
Let V be a vector space, and let f : V Ã— V â†’K be a nondegenerate
bilinear form, which we write as f(âƒ—v1,âƒ—v2) = âŸ¨âƒ—v1,âƒ—v2âŸ©. By an automorphism
of (V, f), one means a linear transformation L : V â†’V such that
âŸ¨L(âƒ—v1), L(âƒ—v2)âŸ©= âŸ¨âƒ—v1,âƒ—v2âŸ©
for all âƒ—v1,âƒ—v2 âˆˆV .
(C.4)
The set of automorphisms is in general not closed under addition, but one
can easily see that it is closed under composition. Furthermore, since the
form is nondegenerate, the adjoint of L with respect to f exists, and since
Equation (C.4) holds for all pairs of vectors âƒ—v and âƒ—w, then we deduce the
following proposition.
Proposition C.2.7. A linear transformation L : V â†’V is an automorphism
of (V, f) if and only if
Lâ€ L = Id,
(C.5)
where by Id we mean the identity transformation on V .
Proposition C.2.8. Let (V, f) be a vector space equipped with a nondegenerate
bilinear form.
Then the set S of automorphisms of (V, f) satisï¬es the
following:
1. S is closed under composition: for all L1, L2 âˆˆS, we have L1â—¦L2 âˆˆS.
2. The identity Id is in S.
3. If L âˆˆS, then L is invertible and Lâˆ’1 âˆˆS.
Proof: We have already discussed the ï¬rst property, and the second is ob-
vious. For the third property, note that for all L âˆˆS, we have Lâ€ L = Id
and hence L is invertible with Lâˆ’1 = Lâ€ . Furthermore, for all âƒ—v, âƒ—w âˆˆV ,
âŸ¨Lâ€ (âƒ—v), Lâ€ (âƒ—w)âŸ©= âŸ¨L â—¦Lâ€ (âƒ—v), L â—¦Lâ€ (âƒ—w)âŸ©= âŸ¨âƒ—v, âƒ—wâŸ©.
Thus, Lâ€  is an automorphism.
â–¡
(Using the language of modern algebra, Proposition C.2.8 shows that
the set of automorphisms of (V, f) is a group. This group is denoted by
Aut(V, f).)
If for a vector space V equipped with a nondegenerate bilinear form f
one also has a basis B = {âƒ—e1, . . . ,âƒ—en}, then Equation (C.3) gives a charac-
terization of matrices of automorphisms. Let M be the matrix associated

C.2. Bilinear and Quadratic Forms
373
to the bilinear form f, and let A be the matrix of a linear transforma-
tion L : V â†’V , all in reference to B. Then by Equation (C.5), L is an
automorphism if and only if
Aâˆ’1 = M âˆ’1AT M.
Before introducing the concept of self-adjoint, we discuss the symmetry
aspects of bilinear forms.
Deï¬nition C.2.9. Let V be a vector space over a ï¬eld K, and let âŸ¨Â·, Â·âŸ©be a
bilinear form on V . Then âŸ¨Â·, Â·âŸ©is called
1. symmetric if âŸ¨âƒ—v, âƒ—wâŸ©= âŸ¨âƒ—w,âƒ—vâŸ©for all âƒ—v, âƒ—w âˆˆV ;
2. antisymmetric if âŸ¨âƒ—v,âƒ—vâŸ©= 0 for all âƒ—v âˆˆV .
If âŸ¨Â·, Â·âŸ©is antisymmetric, then for any two vectors âƒ—v, âƒ—w âˆˆV , since âŸ¨âƒ—v +
âƒ—w,âƒ—v + âƒ—wâŸ©= 0, we also have
0 = âŸ¨âƒ—v,âƒ—vâŸ©+ âŸ¨âƒ—v, âƒ—wâŸ©+ âŸ¨âƒ—w,âƒ—vâŸ©+ âŸ¨âƒ—w, âƒ—wâŸ©= âŸ¨âƒ—v, âƒ—wâŸ©+ âŸ¨âƒ—w,âƒ—vâŸ©.
Thus
âŸ¨âƒ—v, âƒ—wâŸ©= âˆ’âŸ¨âƒ—w,âƒ—vâŸ©.
Example C.2.10. Let V = Rn, use the standard basis, and consider the ex-
amples in Equation (C.1). First, note that the matrix for the dot product
is just the identity matrix
âƒ—v Â· âƒ—w = âƒ—vT âƒ—w = âƒ—vT In âƒ—w.
For the other examples in Equation (C.1), it is easy to ï¬nd that
âŸ¨âƒ—v, âƒ—wâŸ©1 = âƒ—vT
â›
âœ
âœ
âœ
âœ
âœ
â
0
1
0
Â· Â· Â·
0
1
0
0
Â· Â· Â·
0
0
0
1
Â· Â· Â·
0
...
...
...
...
...
0
0
0
Â· Â· Â·
1
â
âŸ
âŸ
âŸ
âŸ
âŸ
â 
âƒ—w,
âŸ¨âƒ—v, âƒ—wâŸ©2 = âƒ—vT
â›
âœ
âœ
âœ
â
2
0
Â· Â· Â·
0
0
1
Â· Â· Â·
0
...
...
...
...
0
0
Â· Â· Â·
1
â
âŸ
âŸ
âŸ
â âƒ—w,
âŸ¨âƒ—v, âƒ—wâŸ©3 = âƒ—vT
â›
âœ
âœ
âœ
â
0
0
Â· Â· Â·
0
1
0
Â· Â· Â·
0
...
...
...
...
0
0
Â· Â· Â·
0
â
âŸ
âŸ
âŸ
â âƒ—w.

374
C. Multilinear Algebra
The dot product, âŸ¨âƒ—v, âƒ—wâŸ©1, and âŸ¨âƒ—v, âƒ—wâŸ©2 are nondegenerate and symmetric.
The form âŸ¨âƒ—v, âƒ—wâŸ©3 is degenerate with rank 1 and is neither symmetric nor
antisymmetric.
An example of an antisymmetric form on R3 is given by
âŸ¨âƒ—v, âƒ—wâŸ©= âƒ—vT
â›
â
0
1
0
âˆ’1
0
0
0
0
0
â
â âƒ—w.
Example C.2.11. Example C.2.10 indicates that the dot product is a sym-
metric, nondegenerate bilinear transformation with associated matrix In,
and Example C.2.5 shows that the transpose of a matrix is the adjoint of a
matrix with respect to the dot product. However, consider the symmetric
bilinear forms f1 and f2 on R4 given by the matrices
M1 =
â›
âœ
âœ
â
0
1
0
0
1
0
0
0
0
0
1
0
0
0
0
1
â
âŸ
âŸ
â 
and
M2 =
â›
âœ
âœ
â
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
â
âŸ
âŸ
â .
Then a simple calculation using Equation (C.3) shows that the adjoint of
A = (aij) with respect to f1 is
â›
âœ
âœ
â
a22
a12
a32
a42
a21
a11
a31
a41
a23
a13
a33
a43
a24
a14
a34
a44
â
âŸ
âŸ
â ,
and the adjoint of A with respect to f2 is
â›
âœ
âœ
â
a44
a34
a24
a14
a43
a33
a23
a13
a42
a32
a22
a12
a41
a31
a21
a11
â
âŸ
âŸ
â .
Remark C.2.12. If (V, f) is a vector space with a symmetric form, then for
all linear transformations L : V â†’V , we show that Lâ€ â€  = L. By deï¬nition
of the adjoint operator, f(L(âƒ—v), âƒ—w) = f(âƒ—v, Lâ€ (âƒ—w)) for all âƒ—v, âƒ—w âˆˆV . Since f
is symmetric, f(L(âƒ—v), âƒ—w) = f(âƒ—w, L(âƒ—v)). Thus,
f(âƒ—w, L(âƒ—v)) = f(L(âƒ—v), âƒ—w) = f(âƒ—v, Lâ€ (âƒ—w)) = f(Lâ€ (âƒ—w),âƒ—v) = f(âƒ—w, Lâ€ â€ (âƒ—v)).
Since these equalities hold for all âƒ—v, âƒ—w âˆˆV and since f is nondegenerate,
we conclude that L = Lâ€ â€ . In general, this equality does not hold if f is
not symmetric.

C.2. Bilinear and Quadratic Forms
375
We now deï¬ne self-adjoint operators.
Deï¬nition C.2.13. Let V be a real vector space with a bilinear form f = âŸ¨Â·, Â·âŸ©.
A linear transformation L : V â†’V is called self-adjoint with respect to
this form if
âŸ¨L(âƒ—v), âƒ—wâŸ©= âŸ¨âƒ—v, L(âƒ—w)âŸ©
for all âƒ—v and âƒ—w in V .
If dim V = n, an n Ã— n matrix A is also called
self-adjoint with respect to âŸ¨Â·, Â·âŸ©if âƒ—v â†’Aâƒ—v is a self-adjoint operator.
It is easy to see that this deï¬nition leads to the criterion that L is
self-adjoint if and only if Lâ€  = L.
We ï¬nally brieï¬‚y introduce quadratic forms on a vector space. Let V
be a vector space over a ï¬eld K of characteristic 0. We shall call a function
f : V â†’K a quadratic form if there exists a symmetric bilinear map
g : V Ã— V â†’K such that
f(âƒ—x) = g(âƒ—x, âƒ—x).
Interestingly enough, given a quadratic form, it is possible to recover the
corresponding symmetric bilinear form as
g(âƒ—x, âƒ—y) = 1
2 (f(âƒ—x + âƒ—y) âˆ’f(âƒ—x) âˆ’f(âƒ—y)) .
(C.6)
Problems
C.2.1. Prove Proposition C.2.6.
C.2.2. Prove Equation (C.6).
C.2.3. Let V and W be ï¬nite vector spaces over a ï¬eld K. Suppose that V and
W are equipped with nondegenerate bilinear forms denoted by âŸ¨, âŸ©V and
âŸ¨, âŸ©W , respectively. Let L : V â†’W be a surjective linear transformation,
and let Lâ€  be its adjoint, namely, Lâ€  : W â†’V satisï¬es
âŸ¨L(v), wâŸ©W = âŸ¨v, Lâ€ (w)âŸ©V
for all v âˆˆV and w âˆˆW .
(a) Show that Lâ€  is injective.
(b) Assume in addition that for all v âˆˆV with v Ì¸= âƒ—0, âŸ¨v, vâŸ©V Ì¸= 0. Then
show that ker L and Im Lâ€  are orthogonal complements in V , that is:
(1) all v âˆˆV can be written as v = v1 + v2, where v1 âˆˆker L and
v2 âˆˆIm Lâ€ ;
(2) ker L âˆ©Im Lâ€  = {âƒ—0}; and
(3) for all v1 âˆˆker L and v2 âˆˆIm Lâ€ , we have âŸ¨v1, v2âŸ©V = 0.

376
C. Multilinear Algebra
C.3
The Hom Space and the Dual Space
In this section, let K be a ï¬eld of characteristic 0 (e.g., R or C).
Deï¬nition C.3.1. Let V and W be two real vector spaces over K. Denote the
set of all linear transformations from V to W by HomK(V, W), or simply
Hom(V, W) if the ï¬eld K is understood in the given context.
Deï¬ne addition and multiplication by a K-scalar on Hom(V, W) in the
following way. If T1 and T2 are two linear transformations in Hom(V, W),
then T1 + T2 is the linear transformation given by
(T1 + T2)(âƒ—v) = T1(âƒ—v) + T1(âƒ—v)
for all âƒ—v âˆˆV.
Also, if Î» âˆˆK and T âˆˆHom(V, W), deï¬ne the linear transformation Î»T by
(Î»T )(âƒ—v) = Î»(T (âƒ—v))
for all âƒ—v âˆˆV.
These deï¬nitions lead us to the following foundational proposition.
Proposition C.3.2. Let V and W be vector spaces over K of dimension m
and n, respectively.
Then Hom(V, W) is a vector space over K, with
dim Hom(V, W) = mn.
Proof: We leave it to the reader to check that Hom(V, W) satisï¬es all the
axioms of a vector space over K.
To prove that dim Hom(V, W) = mn, ï¬rst choose a basis {âƒ—v1, . . . ,âƒ—vm}
of V and a basis {âƒ—w1, . . . , âƒ—wn} of W. Deï¬ne Tij âˆˆHom(V, W) as the linear
transformations deï¬ned by
Tij(âƒ—vk) =

âƒ—wi,
if j = k,
âƒ—0,
if j Ì¸= k,
and extended by linearity over all V . We show that {Tij} for 1 â‰¤i â‰¤m
and 1 â‰¤j â‰¤n form a basis of Hom(V, W).
Because of linearity, any linear transformation L âˆˆHom(V, W) is com-
pletely deï¬ned given the knowledge of L(âƒ—vj) for all 1 â‰¤j â‰¤m. Suppose
that for each j,
L(âƒ—vj) =
n

i=1
aij âƒ—wi.
Then
L =
n

i=1
m

j=1
aijTij,

C.3. The Hom Space and the Dual Space
377
and hence, the Tij span Hom(V, W). Furthermore, suppose that
n

i=1
m

j=1
cijTij
is the 0-linear transformation for some constants cij. Then for all 1â‰¤kâ‰¤m,
n

i=1
m

j=1
cijTij(âƒ—vk) = âƒ—0 â‡â‡’
n

i=1
cik âƒ—wi = âƒ—0.
However, since {âƒ—w1, . . . , âƒ—wn} is a linearly independent set, given any k,
cik = 0. Hence, for all i and j, the constants cij = 0, which shows that the
linear transformations Tij are linearly independent.
Therefore, we conclude that the linear transformations Tij, for 1 â‰¤i â‰¤n
and 1 â‰¤j â‰¤m, form a basis of Hom(V, W).
â–¡
The proof of Proposition C.3.2 provides as a standard basis of
Hom(V, W) the set of linear transformation {Tij} that, with respect to
given bases in V and W, have corresponding n Ã— m matrices Eij with
1 â‰¤i â‰¤n and 1 â‰¤j â‰¤m, where the entries of Eij are all 0 except for a 1
in the (i, j)th entry.
For a vector space V over a ï¬eld K, if we set W = K, then the space
Hom(V, K) is given a special name, the dual space to V , and is denoted
by V âˆ—. In other words, the dual V âˆ—is the vector space of all linear func-
tions f : V â†’K. By Proposition C.3.2, if V is ï¬nite-dimensional, then
dim V âˆ—= dim V and, by well-known facts from linear algebra, V and V âˆ—
are isomorphic. If B = {âƒ—v1,âƒ—v2, . . . ,âƒ—vn} is a basis for V , then the linear
functions fi : V â†’K, with 1 â‰¤i â‰¤n such that
fi(âƒ—v) = ci,
where
[âƒ—v]B =
â›
âœ
â
c1
...
cn
â
âŸ
â ,
(C.7)
form a basis of V âˆ—. Note that one can give the alternate characterization
that the functions fi are linear and satisfy the property that fi(âƒ—vi) = 1
if i = j and 0 otherwise. Therefore, the map Ï• : V â†’V âˆ—that sends âƒ—vi
to fi for all 1 â‰¤i â‰¤n (and that is completed by linearity) provides an
isomorphism between V and V âˆ—.
We sometimes denote the functions fi by âƒ—vâˆ—
i , though one must remember
that the entire basis {âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n} is deï¬ned in reference to B: there is no
canonical way to deï¬ne a function âƒ—vâˆ—âˆˆHom(V, K) in reference to a single

378
C. Multilinear Algebra
vector âƒ—v without reference to a basis of V . The basis {âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n} is called
the dual cobasis or dual coframe to {âƒ—v1, . . . ,âƒ—vn}.
Given any bilinear form Ï‰ : V Ã— V â†’K and a ï¬xed vector âƒ—v âˆˆV ,
the linear function f : V â†’K deï¬ned by f(âƒ—w) = Ï‰(âƒ—v, âƒ—w) is an element
on the dual space V âˆ—. We often write f deï¬ned in this way as Ï‰(âƒ—v, ).
Problem C.3.4 asks the reader to ï¬nd the coordinates of f with respect to
{âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n} in terms of the coordinates of âƒ—v in the basis {âƒ—v1, . . . ,âƒ—vn}.
In the context of a dual space, we are in a position to explain the mean-
ing of the transpose of a matrix. Suppose that V and W are two vector
spaces over K and that L : V â†’W is a linear transformation between
them. There is a natural way to deï¬ne an associated linear transforma-
tion W âˆ—â†’V âˆ—as follows. Given a linear function g âˆˆW âˆ—, the function
âƒ—v â†’g(L(âƒ—v)) is an element of V âˆ—. Therefore, we call Lâˆ—: W âˆ—â†’V âˆ—the
transformation such that Lâˆ—(g) is the unique element of V âˆ—that satisï¬es
Lâˆ—(g)(âƒ—v) = g(L(âƒ—v)).
(C.8)
It is easy to see that Lâˆ—is again linear, and hence, Lâˆ—âˆˆHom(W âˆ—, V âˆ—).
This transformation Lâˆ—is called the dual of L.
Suppose now that V and W are both ï¬nite-dimensional and have bases
B = {âƒ—v1 . . . ,âƒ—vm} and Bâ€² = {âƒ—w1 . . . , âƒ—wn}, respectively, and let A = (aij) be
the matrix of the linear transformation L with respect to these bases so
that
L(âƒ—vi) =
n

j=1
aij âƒ—wj.
Let {âƒ—vâˆ—
1 . . . ,âƒ—vâˆ—
m} and {âƒ—wâˆ—
1 . . . , âƒ—wâˆ—
n} be the dual cobases for V âˆ—and W âˆ—. Let
âƒ—u âˆˆV be written as âƒ—u = c1âƒ—v1 + . . . + cmâƒ—vm. Then
Lâˆ—(âƒ—wâˆ—
j )(âƒ—u) = âƒ—wâˆ—
j (L(âƒ—u)) = âƒ—wâˆ—
j

L
 m

i=1
ciâƒ—vi

= âƒ—wâˆ—
j
 m

i=1
ciL(âƒ—vi)

= âƒ—wâˆ—
j
 m

i=1
ci
n

k=1
aik âƒ—wk

=
m

i=1
ci
n

k=1
aik âƒ—wâˆ—
j (âƒ—wk) =
m

i=1
ciaij
=
m

i=1
aijâƒ—vâˆ—
i (âƒ—u).
Therefore, the matrix for Lâˆ—is in fact (aji).
We summarize the above
discussion in the following proposition.

C.3. The Hom Space and the Dual Space
379
Proposition C.3.3. Let V and W be ï¬nite-dimensional K-vector spaces with
bases B and Bâ€², respectively. Let L : V â†’W be a linear transformation
with matrix A with respect to these bases. Then let Lâˆ—: W âˆ—â†’V âˆ—be
the linear transformation deï¬ned by Lâˆ—(g) = g(L( )). Then Lâˆ—is a linear
transformation with matrix AT , the transpose of A, with respect to the bases
on V âˆ—and W âˆ—associated to B and Bâ€².
Corollary C.3.4. Let V be a vector space with two bases B and Bâ€², and let M
be the transition matrix from coordinates in Bâ€² to coordinates in B. Then
in the dual V âˆ—, the transition matrix from coordinates in Bâˆ—to coordinates
in B
â€²âˆ—is the transpose M T .
It is a common theme in a ï¬rst course in linear algebra to clearly distin-
guish between a particular element of a vector space and the coordinates
of the vector with respect to a basis. A vector in a vector space (respec-
tively, a linear transformation between vector spaces) exists independently
of its coordinates (respectively, matrix) in any particular basis of the vector
space. Linear transformations that arise naturally in geometry (e.g., pro-
jection on a line or plane, reï¬‚ection through a line or plane, rotation, etc.)
are usually deï¬ned without reference to a basis and then ï¬nding a matrix
with respect to some basis is often a simple exercise. On the other hand, a
linear transformation T : V â†’W can be given by its corresponding matrix
with respect to bases on V and W, but the function T is independent of
any basis.
Deï¬nitions or properties of a vector that can be given without reference
to any particular basis are called canonical. For example, the deï¬nition of
the dual of a vector space or the deï¬nition of a dual of a linear transforma-
tion in Equation (C.8) are canonical deï¬nitions. On the other hand, when
a vector space V has a basis B, there exists an isomorphism Ï• as deï¬ned by
Equation (C.7), but this isomorphism is not canonical. In fact, there does
not exist a canonical isomorphism between a vector space and its dual.
However, if we consider the double-dual of V , namely the dual of V âˆ—,
given any vector âƒ—v âˆˆV , one can deï¬ne a linear transformation Tâƒ—v âˆˆV âˆ—âˆ—=
Hom(V âˆ—, K) by
Tâƒ—v(f) = f(âƒ—v).
(C.9)
This deï¬nes a function Ïˆ : V â†’V âˆ—âˆ—by Ïˆ(âƒ—v) = Tâƒ—v.
Proposition C.3.5. The function Ïˆ deï¬ned by Equation (C.9) is an injective
linear transformation. Furthermore, if V is ï¬nite-dimensional, then Ïˆ is a
canonical isomorphism between a vector space V and its double dual V âˆ—âˆ—.

380
C. Multilinear Algebra
Proof: The function Ïˆ was deï¬ned without reference to any basis so is
canonical.
We ï¬rst prove that Ïˆ is a linear transformation. Let âƒ—v, âƒ—w âˆˆV , and let
c âˆˆK. For all f âˆˆV âˆ—,
Ïˆ(âƒ—v + âƒ—w)(f) = Tâƒ—v+ âƒ—w(f) = f(âƒ—v + âƒ—w) = f(âƒ—v) + f(âƒ—w) = Tâƒ—v(f) + T âƒ—w(f),
Ïˆ(âƒ—v + âƒ—w)(f) = Ïˆ(âƒ—v)(f) + Ïˆ(âƒ—w)(f),
so as functions, Ïˆ(âƒ—v + âƒ—w) = Ïˆ(âƒ—v) + Ïˆ(âƒ—w). Similarly,
Ïˆ(câƒ—v)(f) = Tcâƒ—v(f) = f(câƒ—v) = cf(âƒ—v) = cTâƒ—v(f) = cÏˆ(âƒ—v)(f),
so again Ïˆ(câƒ—v) = cÏˆ(âƒ—v).
Next we show that Ïˆ is injective.
Let âƒ—u1, âƒ—u2 âˆˆV be vectors, and
suppose that Ïˆ(âƒ—u1) = Ïˆ(âƒ—u2). Thus, f(âƒ—u1) = f(âƒ—u2) for all f âˆˆHom(V, K).
Therefore, f(âƒ—u1 âˆ’âƒ—u2) = 0 for all f âˆˆV âˆ—, hence âƒ—u1 âˆ’âƒ—u2 = âƒ—0, and thus,
âƒ—u1 = âƒ—u2, proving that Ïˆ is injective.
Finally, we prove that if V is ï¬nite-dimensional, then Ïˆ is an isomor-
phism. If V is ï¬nite-dimensional, then it possesses a basis B = {âƒ—v1, . . . ,âƒ—vn}.
Call {âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n}.
Then any element f âˆˆV âˆ—can be written as f =
a1âƒ—vâˆ—
1 + . . . + anâƒ—vâˆ—
n. Therefore, if âƒ—vj is any basis vector of V , we have
Tâƒ—vj(f) = Tâƒ—vj
 n

i=1
aiâƒ—vâˆ—
i

=
n

i=1
aiâƒ—vâˆ—
i (âƒ—vj) =
n

i=1
aiÎ´i
j = aj,
and we conclude that Ïˆ(âƒ—vj) = âƒ—vâˆ—âˆ—
j . This proves that Ïˆ establishes a bi-
jection between B and the associated basis on V âˆ—âˆ—, and hence gives an
isomorphism between V and V âˆ—âˆ—.
â–¡
Though a more complete discussion lies beyond what we wish to cover
here, we point out that requiring V to be ï¬nite-dimensional for V and V âˆ—âˆ—
to be canonically isomorphic is not a limitation of the above proof. If V
is inï¬nite-dimensional with a basis B, it is possible to show that a basis of
V âˆ—has a strictly greater cardinality than |B|. This suï¬ƒces to show that V
and V âˆ—and by extension V âˆ—âˆ—cannot be isomorphic.
However, the beneï¬t of Proposition C.3.5 is that there is no distinction
between V and V âˆ—âˆ—. This might seem like an innocuous result at ï¬rst,
but it implies that for all functional and linear algebraic reasons one may
always identify V âˆ—âˆ—with V . As we shall see more clearly here below, for
diï¬€erential geometry, this is the ultimate reason why we only have two
types of indicesâ€”covariant and contravariantâ€”in tensors (see Section 2.4)
as opposed to an unlimited number of types of indices.

C.4. The Tensor Product
381
Problems
C.3.1. Prove that Hom(V, W ), with the scalar multiplication and addition as
deï¬ned in this section satisï¬es all the axioms of a vector space over a ï¬eld
K.
C.3.2. Let V be a vector space with basis {âƒ—v1, . . . ,âƒ—vn}. Clearly prove that the
set of functions {fi} deï¬ned in Equation (C.7) form a basis of V âˆ—.
C.3.3. Let U, V , and W be vector spaces over a ï¬eld K. Prove that there exist
canonical isomorphisms
Hom(U âŠ•V, W ) â‰ˆHom(U, W ) âŠ•Hom(V, W ),
Hom(U, V âŠ•W ) â‰ˆHom(U, V ) âŠ•Hom(U, W ).
C.3.4. Let V be a vector space equipped with a bilinear form Ï‰. Set f âˆˆV âˆ—as
the element such that f(âƒ—w) = Ï‰(âƒ—v, âƒ—w). Let B = {âƒ—v1, . . . ,âƒ—vn} be a basis of
V , and let Bâˆ—= {âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n} be the associated cobasis of V âˆ—. Prove that
in coordinates
[f]Bâˆ—= AT [âƒ—v]B ,
where A is the n Ã— n matrix with entries Aij = Ï‰(âƒ—vi,âƒ—vj).
C.4
The Tensor Product
Let V and W be vector spaces over a ï¬eld K. The set V Ã—W is not a vector
space, but it is possible to deï¬ne a vector space associated to V Ã— W.
(The following construction is a little abstract. The casual reader should
feel free to focus his or her attention on the explanations and propositions
following Deï¬nition C.4.2.)
Let U be another vector space over a ï¬eld K. Recall that s function
f : V Ã— W â†’U is called a bilinear transformation if f is linear in both of
its input variables. More precisely, f satisï¬es
f(âƒ—v1 + âƒ—v2, âƒ—w) = f(âƒ—v1) + f(âƒ—v2, âƒ—w),
f(Î»âƒ—v, âƒ—w) = Î»f(âƒ—v, âƒ—w),
f(âƒ—v, âƒ—w1 + âƒ—w2) = f(âƒ—v, âƒ—w1) + f(âƒ—v, âƒ—w2),
f(âƒ—v, Î»âƒ—w) = Î»f(âƒ—v, âƒ—w),
for all âƒ—v1,âƒ—v2,âƒ—v âˆˆV , for all âƒ—w1, âƒ—w2, âƒ—w âˆˆW, and all Î» âˆˆK. The deï¬nition
of what we will call the tensor product of two vector spaces relies on the
following proposition.
Proposition C.4.1. Let U, V , and W be vector spaces over a ï¬eld K. There
exists a unique vector space Z over K and a bilinear transformation V Ã—
W â†’Z such that for any bilinear transformation f : V Ã— W â†’U, there
exists a unique linear transformation Â¯f : Z â†’U such that f = Â¯f â—¦Ïˆ.

382
C. Multilinear Algebra
Proof: We ï¬rst prove the existence of the vector space Z. Consider the set
Â¯Z of formal ï¬nite linear combinations
c1(âƒ—v1, âƒ—w1) + c2(âƒ—v2, âƒ—w2) + Â· Â· Â· + cl(âƒ—vl, âƒ—wl),
where âƒ—vi âˆˆV , âƒ—wi âˆˆW, and ci âˆˆK for 1 â‰¤i â‰¤l. It is not hard to see that
Â¯Z is a vector space over K. Consider now the subspace Â¯Zlin spanned by
vectors of the form
(âƒ—v1 + âƒ—v2, âƒ—w) âˆ’(âƒ—v1, âƒ—w) âˆ’(âƒ—v2, âƒ—w),
(Î»âƒ—v, âƒ—w) âˆ’Î»(âƒ—v, âƒ—w),
(âƒ—v, âƒ—w1 + âƒ—w2) âˆ’(âƒ—v, âƒ—w1) âˆ’(âƒ—v, âƒ—w2),
(âƒ—v, Î»âƒ—w) âˆ’Î»(âƒ—v, âƒ—w).
(C.10)
Deï¬ne Z as the quotient vector space Z = Â¯Z/ Â¯Zlin. The elements of Z are
equivalence classes of elements of Â¯Z under the equivalence relation âƒ—u âˆ¼âƒ—v
if and only if âƒ—v âˆ’âƒ—u âˆˆÂ¯Zlin.
Deï¬ne Ïˆ : U Ã— V â†’Z as the composition Ïˆ = Ï€ â—¦i, where Ï€ : Â¯Z â†’Z
is the canonical projection and i : V Ã— W â†’Â¯Z is the inclusion. The space
Â¯Zlin is deï¬ned in such a way that the canonical projection Ï€ turns Ïˆ into
a bilinear transformation.
Now given any bilinear transformation f : V Ã—W â†’U, we can complete
f by linearity to deï¬ne a linear transformation Ëœf from Â¯Z to U via
Ëœf (c1(âƒ—v1, âƒ—w1) + Â· Â· Â· + cl(âƒ—vl, âƒ—wl)) = c1f(âƒ—v1, âƒ—w1) + Â· Â· Â· + clf(vl, âƒ—wl).
If z0 âˆˆÂ¯Zlin, then z0 is a linear combination of elements of the form in Equa-
tion (C.10). However, every element of the form given in Equation (C.10)
maps to âƒ—0 under Ëœf, so Ëœf(z0). Therefore, if z1, z2 âˆˆÂ¯Z are such that z1 âˆ¼z2,
then z1 âˆ’z2 = z0 âˆˆÂ¯Zlin, so Ëœf(z1 âˆ’z2) = âƒ—0 and Ëœf(z1) = Ëœf(z2). Hence, Ëœf
induces a function Â¯f : Â¯Z/ Â¯Zlin â†’U. It is easy to check that Â¯f is a linear
transformation and that f = Â¯f â—¦Ïˆ. Since the image of Ïˆ spans Â¯Z/ Â¯Zlin, it
follows that the induced map Â¯f is uniquely determined. This proves the
existence of Z.
To prove uniqueness of Z, suppose there is another vector space Zâ€² and
a bilinear transformation Ïˆâ€² : V Ã—W â†’Zâ€² with the desired property. Then
there exist Â¯Ïˆ and Â¯Ïˆâ€² such that Ïˆâ€² = Â¯Ïˆâ€² â—¦Ïˆ and Ïˆ = Â¯Ïˆ â—¦Ïˆâ€². Then we have
Ïˆ = Â¯Ïˆ â—¦Â¯Ïˆâ€² â—¦Ïˆ. However, Ïˆ = idZ â—¦Ïˆ, and since we know that Ïˆ factors
through Z with a unique map, then Â¯Ïˆ â—¦Â¯Ïˆâ€² = idZ. Similarly, one can show
that Â¯Ïˆâ€² â—¦Â¯Ïˆ = idZâ€². Thus, Z âˆ¼= Zâ€², and so Z is unique up to a natural
isomorphism.
â–¡
Deï¬nition C.4.2. The vector space Z in the above proposition is called the
tensor product of V and W and is denoted by V âŠ—W. The element Ïˆ(âƒ—v, âƒ—w)
in V âŠ—W is denoted by âƒ—v âŠ—âƒ—w.

C.4. The Tensor Product
383
Elements of V âŠ—W are linear combinations of vectors of the form âƒ—v âŠ—âƒ—w,
with âƒ—v âˆˆV and âƒ—w âˆˆW. With this notation, it is understood that
(âƒ—v1 + âƒ—v2) âŠ—âƒ—w = âƒ—v1 âŠ—âƒ—w + âƒ—v2 âŠ—âƒ—w,
(Î»âƒ—v) âŠ—âƒ—w = Î»(âƒ—v âŠ—âƒ—w),
âƒ—v âŠ—(âƒ—w1 + âƒ—w2) = âƒ—v âŠ—âƒ—w1 + âƒ—v âŠ—âƒ—w2,
âƒ—v âŠ—(Î»âƒ—w) = Î»(âƒ—v âŠ—âƒ—w).
Deï¬nition C.4.3. Any element of a tensor product of two vector spaces is
often simply called a tensor. A tensor in V âŠ—W that can be written as
âƒ—v âŠ—âƒ—w for âƒ—v âˆˆV and âƒ—w âˆˆW is called a pure tensor.
Deï¬nition C.4.2 introduces the concept of a tensor product between
two vector spaces as a vector space with a certain universal property, i.e.,
a property that relates it to all other possible vector spaces. The following
propositions state some of the basic properties of tensor products of vector
spaces. When used in the context of diï¬€erential geometry, it is convenient
to understand the tensor product using Proposition C.4.6 with the relations
presented in Equation (C.10). For the sake of brevity, we omit the proofs
of the following propositions and refer the reader to [30, Chapter XVI].
Proposition C.4.4. Let V1, V2, and V3 be three vector spaces over a ï¬eld K.
There exists a unique isomorphism
(V1 âŠ—V2) âŠ—V3 âˆ¼= V1 âŠ—(V2 âŠ—V3)
such that
(âƒ—u âŠ—âƒ—v) âŠ—âƒ—w â†’âƒ—u âŠ—(âƒ—v âŠ—âƒ—w)
for all âƒ—u âˆˆV1, âƒ—v âˆˆV2, and âƒ—w âˆˆV3.
In light of Proposition C.4.4, the notation V1 âŠ—V2 âŠ—V3 is well deï¬ned.
Furthermore, one can take the tensor product of any number of vector
spaces. The tensor product of k copies of V is denoted by
V âŠ—V âŠ—Â· Â· Â· âŠ—V = V âŠ—k.
We simply state the following two propositions and leave the proofs of
these as simple exercises for the reader.
Proposition C.4.5. Let V and W be two vector spaces over a ï¬eld K. There
exists a unique isomorphism
V âŠ—W âˆ¼= W âŠ—V
such that âƒ—v âŠ—âƒ—w â†’âƒ—w âŠ—âƒ—v for all âƒ—v âˆˆV and âƒ—w âˆˆW.

384
C. Multilinear Algebra
Proposition C.4.6. If V and W are ï¬nite-dimensional vector spaces over
a ï¬eld K with dimension m and n, respectively, then V âŠ—W is ï¬nite-
dimensional with dimension mn. Furthermore, if {âƒ—e1, . . . ,âƒ—em} is a basis of
V and {âƒ—f1, . . . , âƒ—fn} is a basis of W, then
{âƒ—ei âŠ—âƒ—fj | 1 â‰¤i â‰¤m and 1 â‰¤j â‰¤n}
is a basis of V âŠ—W.
Because of Proposition C.4.6, if âƒ—a âˆˆV âŠ—W, it is common to use two
indices to index the coordinates of âƒ—a with respect to the basis B = {âƒ—eiâŠ—âƒ—fj}.
Saying that the vector âƒ—a has components (aij) with respect to B means that
âƒ—a =
m

i=1
n

j=1
aijâƒ—ei âŠ—âƒ—fj.
We have used the superscript notation for the coordinates of âƒ—a to be con-
sistent with the Einstein summation convention. Note that if âƒ—v âˆˆV and
âƒ—w âˆˆW are vectors with coordinates
âƒ—v = v1âƒ—e1 + Â· Â· Â· + vnâƒ—en
and
âƒ—w = w1 âƒ—f1 + Â· Â· Â· + wm âƒ—fm,
then using the linearity properties of the âŠ—symbol, the coordinates for
âƒ—v âŠ—âƒ—w are
âƒ—v âŠ—âƒ—w =
m

i=1
n

j=1
viwjâƒ—ei âŠ—âƒ—fj.
The next proposition provides a profound connection between the dual
space of a vector space and linear transformations from this space.
Proposition C.4.7. Let V and W be ï¬nite-dimensional vector spaces over a
ï¬eld K. The space V âˆ—âŠ—W is canonically isomorphic to Hom(V, W).
Proof: Consider the function Ï• : V âˆ—âŠ—W âˆ’â†’Hom(V, W) deï¬ned on each
pure tensor Î» âŠ—âƒ—w âˆˆV âˆ—âŠ—W by
Î» âŠ—âƒ—w âˆ’â†’(âƒ—v â†’Î»(âƒ—v)âƒ—w)
and extended by linearity. This function Ï• is well deï¬ned as a function and
is a linear transformation. This claim follows from the properties of the
tensor product of two vector spaces. (The details are left as an exercise for
the reader.)

C.4. The Tensor Product
385
The kernel of Ï• consists of all linear combinations c1Î»1 âŠ—âƒ—w1 + Â· Â· Â· +
cmÎ»m âŠ—âƒ—wm such that the function in Hom(V, W) deï¬ned by
c1Î»1(Â·)âƒ—w1 + Â· Â· Â· + cmÎ»m(Â·)âƒ—wm
is identically 0. Because of the properties of the tensor product, without
loss of generality, we can assume that {âƒ—w1, . . . , âƒ—wm} is a linear independent
set of vectors in W. Thus for each âƒ—v âˆˆV , we conclude that for 1 â‰¤i â‰¤m,
each ciÎ»i is such that ciÎ»i(âƒ—v) = 0. Therefore, either ci = 0 in K or Î»i = 0
in V âˆ—. From this we conclude that ker Ï• = {0}.
Conversely, let T âˆˆHom(V, W) be any linear transformation.
Let
{âƒ—v1, . . . ,âƒ—vn} be a basis of V , and consider the linear functions {âƒ—vâˆ—
1, . . . ,âƒ—vâˆ—
n}
(see Equation (C.7) and the subsequent explanation). Then the element
n

i=1
âƒ—vâˆ—
i âŠ—T (âƒ—vi)
maps to T under Ï•. Therefore, Ï• is also surjective.
â–¡
We now come to a point of notation where mathematicians and physi-
cists have often used diï¬€erent notations to discuss the same object, a dif-
ference that can lead to some confusion for readers consulting both math-
ematics texts and physics texts. In numerous applications of multilinear
algebra, in particular in diï¬€erential geometry, one often has a ï¬nite dimen-
sional vector space V and considers associated vector spaces V âŠ—p âŠ—V âˆ—âŠ—q.
If B = {âƒ—e1, . . . ,âƒ—en} is a basis of V , then the basis of V âŠ—p âŠ—V âˆ—âŠ—q associated
to B consists of all vectors of the form
âƒ—ei1 âŠ—Â· Â· Â· âŠ—âƒ—eip âŠ—âƒ—eâˆ—
j1 âŠ—Â· Â· Â· âŠ—âƒ—eâˆ—
jq
for ik = 1, 2, . . . n and jl = 1, 2, . . .n. Note that this basis conï¬rms the fact
that dim V âŠ—p âŠ—V âˆ—âŠ—q = np+q. It is common practice in advanced linear
algebra to express the coordinates of a tensor A âˆˆV âŠ—p âŠ—V âˆ—âŠ—q as
Ai1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq
(C.11)
so that
A =
n

i1=1
n

i2=1
Â· Â· Â·
n

ip=1
n

j1=1
n

j2=1
Â· Â· Â·
n

jq=1
Ai1i2Â·Â·Â·ip
j1j2Â·Â·Â·jqâƒ—ei1âŠ—âƒ—ei2âŠ—Â· Â· Â·âŠ—âƒ—eipâŠ—âƒ—eâˆ—
j1âŠ—âƒ—eâˆ—
j2âŠ—Â· Â· Â·âŠ—âƒ—eâˆ—
jq.
(C.12)
Using superscript and subscript indices allows one to easily distinguish
between the constituent indices from V and from V âˆ—.
The superscript

386
C. Multilinear Algebra
indices are often called contravariant indices, while the subscript indices
are called covariant indices. Elements of V âŠ—p âŠ—V âˆ—âŠ—q are called tensors of
type (p, q) over V .
The following proposition gives the coordinate-transformation proper-
ties of tensors in V âŠ—p âŠ—V âˆ—âŠ—q under a change of basis in V .
Proposition C.4.8. Let B and Bâ€² be two bases on a ï¬nite dimensional vec-
tor space V . Let (as
r) be the coordinate-change matrix from B to Bâ€². Let
T i1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq be the components of a tensor T âˆˆV âŠ—p âŠ—V âˆ—âŠ—q with respect to B,
and let Â¯T i1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq be the components of the same tensor T with respect to Bâ€².
Then these two diï¬€erent components are related by
Â¯T k1k2Â·Â·Â·kp
l1l2Â·Â·Â·lq
=
n

i1=1
n

i2=1
Â· Â· Â·
n

ip=1
n

j1=1
n

j2=1
Â· Â· Â·
n

jq=1
ak1
i1 ak2
i2 Â· Â· Â· akp
ip aj1
l1 aj2
l2 Â· Â· Â· ajq
lq T i1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq.
(C.13)
Proof: This result follows easily from the linearity properties of tensors and
Proposition C.3.3. (We leave the details to the reader.)
â–¡
Because of the cumbersome nature of Equation (C.12), mathematicians
introduce the tensor product of vector spaces as we have done here and then
simply use the symbol A (or
 ) to express the above tensor. In contrast,
physicists often introduce tensors using the coordinate symbol in Equa-
tion (C.11) and then say that these coordinate symbols must satisfy the
transformational properties described in Proposition C.4.8. The transfor-
mational property in Equation (C.13) is also quite laborious to write down.
Because of this, one usually uses the Einstein summation convention, as
introduced in Section 2.4. In this convention, one assumes that one takes
a summation over any indices that are repeated in an expression involving
the components of a tensor. Furthermore, due to the linear algebraic inter-
pretation of tensor components, repeated indices most often occur between
a contravariant and a covariant index.
In Section 2.4 and, in particular, Deï¬nition 2.4.6, we introduce tensors
on a surface in the manner that physicists typically do. (We discuss tensors
in Chapter 4 but there we work in the context of vector bundles over
a manifold and not just vector spaces.)
The transformational property
speciï¬ed in Equation (2.27) corresponds precisely to Proposition C.4.8,
where the change-of-basis matrix in V = Rn is the Jacobian matrix
âˆ‚Â¯x
âˆ‚x

.

C.4. The Tensor Product
387
One should also note that in light of the chain rule and Equation (2.22),
the Jacobian matrix satisï¬es the additional property of being an orthogonal
matrix, i.e., that its inverse is equal to its transpose.
In light of Proposition C.4.7, we can give a linear algebraic interpreta-
tion to tensors of type (p, q) over V . If V is ï¬nite-dimensional, an element
of V âˆ—âŠ—p âŠ—V âŠ—q corresponds to a linear transformation in Hom(V âŠ—p, V âŠ—q).
For example, a tensor of type (1, 1) over V corresponds to a linear trans-
formation V â†’V . The components of the tensor given in terms of a basis
on V correspond to the matrix of the linear transformation with respect
to the given basis. As another example, a tensor of type (0, 2) is a linear
transformation from V âŠ—V to the base ï¬eld K, or in other words, it is a
bilinear form on V .
We comment now on the linear algebraic meaning of a few common
operations on tensors, in particular, addition, scalar multiplication, multi-
plication, and contraction, which were introduced in Section 2.4.
If Ai1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq form the components of a (p, q)-tensor A and Bi1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq form
the components of a (p, q)-tensor B, then we can deï¬ne the term-by-term
addition
Ci1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq = Ai1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq + Bi1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq.
This operation on components simply corresponds to the addition of A
and B as elements in the vector space V âŠ—p âŠ—V âˆ—âŠ—q. Similarly, given the
components Ai1i2Â·Â·Â·ip
j1j2Â·Â·Â·jq of a tensor of type (p, q), the operation of multiplying
all the components by a given scalar c in the base ï¬eld K corresponds to
multiplying the tensor A by the scalar c again as an operation in the vector
space V âŠ—p âŠ—V âˆ—âŠ—q.
It is not hard to check that if Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·js and T k1k2Â·Â·Â·kt
l1l2Â·Â·Â·lu
are components of
tensors of type (r, s) and (t, u), respectively, then the quantities obtained
by multiplying these components
W i1i2Â·Â·Â·irk1k2Â·Â·Â·kt
j1j2Â·Â·Â·jsl1l2Â·Â·Â·lu = Si1i2Â·Â·Â·ir
j1j2Â·Â·Â·jsT k1k2Â·Â·Â·kt
l1l2Â·Â·Â·lu
form the components of another tensor but of type (r + t, s + u) (see Sec-
tion 2.4). This operation of tensor multiplication corresponds to the natural
bilinear transformation
V âŠ—r âŠ—V âˆ—âŠ—s Ã— V âŠ—t âŠ—V âˆ—âŠ—u âˆ’â†’V âŠ—(r+t) âŠ—V âˆ—âŠ—(s+u).
Therefore, the tensor multiplication utilizes the isomorphism
(V âŠ—r âŠ—V âˆ—âŠ—s) âŠ—(V âŠ—t âŠ—V âˆ—âŠ—u) âˆ¼= V âŠ—r+t âŠ—V âˆ—âŠ—s+u.

388
C. Multilinear Algebra
Consequently, one typically writes S âŠ—T for the multiplication (product)
of two tensors.
(One can describe the operation of tensor multiplication in terms of
an operation in a so-called tensor algebra, but the theory behind tensor
algebras takes us a little too far aï¬eld for this text.)
Finally, the contraction operation on the components of a tensor cor-
responds to setting one contravariant and one covariant index to be the
same and then summing over that index. On the indices involved, this
corresponds to the following linear transformation:
V âŠ—V âˆ—âˆ’â†’K
âƒ—v âŠ—Î» âˆ’â†’Î»(âƒ—v).
The contraction operation is similar to the operation of taking the trace of
a matrix along certain speciï¬ed indices.
Problems
C.4.1. Let V and W be ï¬nite dimensional vector spaces over a ï¬eld K with
respective bases B = {âƒ—e,1 , . . . ,âƒ—en} and Bâ€² = {âƒ—f1, . . . , âƒ—fm}. Let T : V â†’W
be a linear transformation with matrix A with respect to the bases B and
Bâ€². T determines a linear transformation T âŠ—2 : V âŠ—V â†’W âŠ—W via
T âŠ—2(âƒ—v1 âŠ—âƒ—v2) = T(âƒ—v1) âŠ—T(âƒ—v2)
and completed for other elements of V âŠ—V by linearity.
(a) If V = W = R2 and the matrix of a linear transformation T with
respect to the standard basis is
A =
2
3
5
7
	
,
ï¬nd the matrix of T âŠ—2.
(b) In general, for any ï¬nite dimensional vector spaces V and W and
linear transformation T, if the coeï¬ƒcients of A are (aij), ï¬nd the
coeï¬ƒcients of the matrix for T âŠ—2.
C.4.2. Let V be a vector space over C, and let T : V â†’V be a linear transfor-
mation.
(a) Suppose that the Jordan canonical form of T is J = Î»I. Find the
Jordan canonical form of T âŠ—2.

C.4. The Tensor Product
389
(b) Suppose that the Jordan canonical form of T is
J =
â›
âœ
âœ
âœ
âœ
âœ
âœ
âœ
â
Î»
1
0
Â· Â· Â·
0
0
0
Î»
1
Â· Â· Â·
0
0
0
0
Î»
Â· Â· Â·
0
0
...
...
...
...
...
...
0
0
0
Â· Â· Â·
Î»
1
0
0
0
Â· Â· Â·
0
Î»
â
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
âŸ
â 
Find the Jordan canonical form of T âŠ—2.
C.4.3. Let V be a vector space over a ï¬eld K. Let âƒ—v1,âƒ—v2 âˆˆV . Show that in
V âŠ—V , âƒ—v1 âŠ—âƒ—v2 = âƒ—v2 âŠ—âƒ—v1 if and only if âƒ—v1 and âƒ—v2 are collinear.
C.4.4. Let V and W be vector spaces over C, and let S : V â†’V and T : W â†’
W be linear transformations. Consider the linear transformation S âŠ—T
deï¬ned by
S âŠ—T : V âŠ—W âˆ’â†’V âŠ—W
âƒ—v âŠ—âƒ—w âˆ’â†’S(âƒ—v) âŠ—T(âƒ—w).
(a) Suppose that dim V = 2 and that dim W = 3, with bases {âƒ—e1,âƒ—e2}
and {âƒ—f1, âƒ—f2, âƒ—f3}, respectively. Suppose also that with respect to these
bases, the matrices for S and T are
1
3
5
2
	
and
â›
â
âˆ’1
0
2
1
3
âˆ’2
0
1
4
â
â .
Find the matrix for S âŠ—T with respect to the standard basis for
V âŠ—W .
(b) Suppose that S and T are diagonalizable with eigenvalues Î»1, . . . , Î»m
and Î¼1, . . . , Î¼n, respectively. Prove that S âŠ—T is diagonalizable and
that the eigenvalues of S âŠ—T are Î»iÎ¼j for 1 â‰¤i â‰¤m and 1 â‰¤j â‰¤n.
C.4.5. Let V , W1, and W2 be ï¬nite dimensional vector spaces over a ï¬eld K.
Show that there exists a canonical (independent of a given basis) isomor-
phism
V âŠ—(W1 âŠ•W2) âˆ¼= (V âŠ—W1) âŠ•(V âŠ—W2).
C.4.6. Prove Theorem C.4.8.
C.4.7. Let V and W be vector spaces over R with, respectively, bases {âƒ—e1, . . . ,âƒ—em}
and {âƒ—f1, . . . , âƒ—fn}. Call {âƒ—eâˆ—
1, . . . ,âƒ—eâˆ—
m} the standard associated cobasis for
V âˆ—. Proposition C.4.7 describes a canonical isomorphism Ï• : V âˆ—âŠ—W âˆ¼=
Hom(V, W ).
(a) Show that for all pure tensors Ï‰ âŠ—âƒ—w âˆˆV âˆ—âŠ—W , the corresponding
linear transformation T = Ï•(Ï‰ âŠ—âƒ—w) is of rank 1.

390
C. Multilinear Algebra
(b) Conversely show that if T âˆˆHom(V, W ) has rank 1, then T =
Ï•(Ï‰ âŠ—âƒ—w) for some pure tensor Ï‰ âŠ—âƒ—w.
(c) Let Î± âˆˆV âˆ—âŠ—W be a tensor. Prove that if T(Î±) is a linear trans-
formation of rank k, then in any expression of Î± as a sum of pure
tensors, one must use at least k terms.
C.5
Symmetric Product and Alternating Product
We now deï¬ne two more useful constructions on a ï¬nite dimensional vector
space V over R or C. We will occasionally omit the proofs of the proposi-
tions and leave them as exercises for the reader.
C.5.1
The Symmetric Product
In the tensor product V âŠ—V , in general âƒ—v1 âŠ—âƒ—v2 Ì¸= âƒ—v2 âŠ—âƒ—v2. It is some-
times useful to have a tensor-like product that is either commutative or
anticommutative.
For example, in the previous section, we pointed out that every bilinear
form on V is an element of V âˆ—âŠ—V âˆ—. However, in geometry and other
areas, one encounters symmetric bilinear forms. If Aij are the components
of an element in A âˆˆV âˆ—âŠ—V âˆ—with respect to a given basis on V , then the
condition that A be a symmetric bilinear form means that Aij = Aji for all
1 â‰¤i, j â‰¤dim V . The set of symmetric bilinear forms is a linear subspace
of V âˆ—âŠ—2. The kth symmetric product of a vector space V generalizes this
idea.
Let V be a vector space of dimension n. Let Sk be the set of permuta-
tions on k elements (i.e., bijections on {1, 2, . . ., k}). This set acts on
k times
*
+(
)
V âŠ—V âŠ—Â· Â· Â· âŠ—V
by doing the following on pure tensors:
Ïƒ Â· (âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk) = âƒ—vÏƒâˆ’1(1) âŠ—âƒ—vÏƒâˆ’1(2) âŠ—Â· Â· Â· âŠ—âƒ—vÏƒâˆ’1(k)
(C.14)
and extending by linearity on nonpure tensors. (Taking Ïƒâˆ’1 on the indices
means that Ïƒ sends the vector in the ith position in the tensor product
âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk to the Ïƒ(i)th position.)

C.5. Symmetric Product and Alternating Product
391
Deï¬nition C.5.1. Let Î± âˆˆV âŠ—k be a tensor of rank k over V . We deï¬ne the
symmetrization of Î± to be
SÎ± =

ÏƒâˆˆSk
Ïƒ Â· Î±.
Example C.5.2. Let V be a vector space. We consider tensors in V âŠ—V âŠ—V .
We will consider permutations in S3, which has 3! = 6 elements.
S(âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e3) = âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e3 + âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e3 + âƒ—e3 âŠ—âƒ—e2 âŠ—âƒ—e1
+ âƒ—e1 âŠ—âƒ—e3 âŠ—âƒ—e2 + âƒ—e2 âŠ—âƒ—e3 âŠ—âƒ—e1 + âƒ—e3 âŠ—âƒ—e1 âŠ—âƒ—e2.
In contrast,
S(âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2) = âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2 + âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2 + âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e1
+ âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e1 + âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e1 + âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e1
= 2 (âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2 + âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e1 + âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e1) .
By construction, the symmetrization S deï¬nes a linear transformation
S : V âŠ—k â†’V âŠ—k.
Deï¬nition C.5.3. The subspace of V âŠ—k given as the image of S : V âŠ—k â†’V âŠ—k
is called the kth symmetric product of V and is denoted by Symk V .
Proposition C.5.4. Let {âƒ—e1,âƒ—e2, . . . ,âƒ—en} be a basis of V . Then in Symk V , the
elements of S(âƒ—ei1 âŠ—âƒ—ei2 âŠ—Â· Â· Â· âŠ—âƒ—eik) are all distinct for 1 â‰¤i1 â‰¤i2 â‰¤Â· Â· Â· â‰¤
ik â‰¤n. Furthermore, the corresponding vectors S(âƒ—ei1 âŠ—âƒ—ei2 âŠ—Â· Â· Â·âŠ—âƒ—eik) form
a basis of Symk V .
Corollary C.5.5. Let V be a vector space of dimension n. Then
dim Symk V =
n + k âˆ’1
n
	
.
Proposition C.5.6. The subspace Symk V is invariant under the action of Sk
on V âŠ—k.
Proof: Let Ï„ âˆˆSk be a permutation. Then on any pure tensor âƒ—vi1 âŠ—âƒ—vi2 âŠ—
Â· Â· Â· âŠ—âƒ—vik, the action of Ï„ on S(âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik) gives
Ï„ Â· S(âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik) = Ï„ Â·
 
ÏƒâˆˆSk
Ïƒ Â· âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik

=

ÏƒâˆˆSk
Ï„ Â· (Ïƒ Â· âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik)

392
C. Multilinear Algebra
=

ÏƒâˆˆSk
(Ï„Ïƒ) Â· âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik
=

ÏƒâˆˆSk
Ïƒ Â· âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik
= S(âƒ—vi1 âŠ—âƒ—vi2 âŠ—Â· Â· Â· âŠ—âƒ—vik),
where we obtain the second-to-last line because as Ïƒ runs through all the
permutations in Sk, for any ï¬xed Ï„ âˆˆSk, the compositions Ï„Ïƒ also run
through all the permutations of Sk.
â–¡
Corollary C.5.7. For all symmetric tensors Î±âˆˆSymk V , we have S(Î±)=k! Î±.
Proof: The corollary follows immediately from Proposition C.5.6 and Def-
inition C.5.1.
â–¡
Given Î± âˆˆSymk V and Î² âˆˆSyml V , the tensor product Î±âŠ—Î² is of course
an element of V âŠ—(k+l) but is not necessarily an element of Symk+l V . How-
ever, it is possible to construct a new product that satisï¬es this deï¬ciency.
Deï¬nition C.5.8. Let Î± âˆˆSymk V and Î² âˆˆSyml V . Deï¬ne the symmetric
product between Î± and Î² as
Î±Î² =
1
k! l!S(Î± âŠ—Î²).
Note that if Î± and Î² are tensors of rank 1, then the product Î±Î² is
precisely the symmetrization of Î± âŠ—Î². However, a few other properties,
which we summarize in Proposition C.5.10, of this symmetric product also
hold. We need a lemma ï¬rst.
Lemma C.5.9. Let Î± be a tensor of rank k. If S(Î±) = 0, then S(Î± âŠ—Î²) =
S(Î² âŠ—Î±) = 0 for all tensors Î².
Furthermore, if S(Î±) = S(Î±â€²), then
S(Î± âŠ—Î²) = S(Î±â€² âŠ—Î²) for all tensors Î².
Proof: We ï¬rst prove that if S(Î±) = 0, then S(Î± âŠ—Î²) = 0 for all tensors Î²
of rank l, and the result for S(Î² âŠ—Î±) follows similarly.
Let Sk be the subset of permutations in Sk+l that only permute the ï¬rst
k elements of {1, 2, . . ., k+l} and leave the remaining l elements unchanged.
Deï¬ne the relation âˆ¼on Sk+l as Ï„1 âˆ¼Ï„2 if and only if Ï„âˆ’1
2 Ï„1 âˆˆSk. Since
Sk is closed under taking inverse functions and composition of functions,
it is easy to see that âˆ¼is an equivalence relation on Sk+l.

C.5. Symmetric Product and Alternating Product
393
Let C be a set of representatives of distinct equivalence classes of âˆ¼.
Then we have
S(Î± âŠ—Î²) =

ÏƒâˆˆSk+l
Ïƒ Â· (Î± âŠ—Î²) =

Ï„âˆˆC

Ïƒâ€²âˆˆSk
Ï„Ïƒâ€² Â· (Î± âŠ—Î²)
=

Ï„âˆˆC
Ï„ Â·
 
Ïƒâ€²âˆˆSk
Ïƒâ€² Â· Î±

âŠ—Î²

=

Ï„âˆˆC
Ï„ Â· ((SÎ±) âŠ—Î²)
= 0.
For the second part of the lemma, suppose that S(Î±) = S(Î±â€²). Then
S(Î± âˆ’Î±â€²) = 0. Thus, for all tensors Î² we have S((Î± âˆ’Î±â€²) âŠ—Î²) = 0. Hence,
S(Î± âŠ—Î²) âˆ’S(Î±â€² âŠ—Î²) = 0 and the result follows.
â–¡
Proposition C.5.10. Let V be a vector space of dimension n. The following
hold:
1. The symmetric product is bilinear: for all Î±, Î±1, Î±2 âˆˆSymk V , Î², Î²1,
Î²2 âˆˆSyml V , and Î» in the base ï¬eld,
(Î±1 + Î±2)Î² = Î±1Î² + Î±2Î²,
(Î»Î±)Î² = Î»(Î±Î²),
Î±(Î²1 + Î²2) = Î±Î²1 + Î±Î²2,
Î±(Î»Î²) = Î»(Î±Î²).
2. The symmetric product is commutative: for all Î± âˆˆSymk V and
Î² âˆˆSyml V ,
Î±Î² = Î²Î±.
3. The symmetric product is associative:
for all Î± âˆˆSymr V , Î² âˆˆ
Syms V , and Î³ âˆˆSymt V , as an element of Symr+s+t V , we have
(Î±Î²)Î³ = Î±(Î²Î³) =
1
r! s! t!S(Î± âŠ—Î² âŠ—Î³).
Proof: We leave part 1 of the proposition as an exercise for the reader.
For part 2, by Proposition C.5.6, S(Î± âŠ—Î²) is invariant under the ac-
tion of Sk+l. Consider the permutation Ïƒ0 âˆˆSk+l that maps the n-tuple
(1, 2, . . . , k + l) to (k + 1, . . . , k + l, 1, . . ., k). In each pure tensor in an
expression of Î± âŠ—Î², the action Ïƒ0(Î± âŠ—Î²) moves (and keeps in the proper
order) the vector terms coming from Î² in front of the terms coming from
Î±. Hence, we see that Ïƒ0(Î± âŠ—Î²) = Î² âŠ—Î±. Thus, we conclude that
Î²Î± = Ïƒ0(Î±Î²) = Ïƒ0
 1
k! l!S(Î± âŠ—Î²)
	
=
1
k! l!S(Î± âŠ—Î²) = Î±Î².
Thus, the symmetric product is commutative.

394
C. Multilinear Algebra
For part 3, by Corollary C.5.7, since Î±Î² is symmetric,
S(Î±Î²) = (r + s)! Î±Î² = (r + s)!
r! s!
S(Î± âŠ—Î²).
Therefore, by Lemma C.5.9, for all tensors Î³ of rank t,
S(Î±Î² âŠ—Î³) = S
(r + s)!
r! s!
(Î± âŠ—Î²) âŠ—Î³
	
.
Consequently,
(Î±Î²)Î³ =
1
(r + s)! t!S(Î±Î² âŠ—Î³)
=
1
(r + s)! t!
(r + s)!
r! s!
S ((Î± âŠ—Î²) âŠ—Î³)
=
1
r! s! t!S(Î± âŠ—Î² âŠ—Î³).
It is easy to follow the same calculation and ï¬nd that
Î±(Î²Î³) =
1
r! s! t!S(Î± âŠ—Î² âŠ—Î³),
which shows that (Î±Î²)Î³ = Î±(Î²Î³) for all tensors Î±, Î², and Î³.
â–¡
By virtue of associativity, the symmetrization of a pure tensor S(âƒ—v1 âŠ—
âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk) is in fact
âƒ—v1âƒ—v2 Â· Â· Â·âƒ—vk.
We think of this element as a commutative â€œproductâ€ between vectors,
which is linear in each term.
With this notation in mind, one usually
thinks of Symk V as a vector space in its own right, independent of V âŠ—k,
with basis
{âƒ—ei1âƒ—ei2 Â· Â· Â·âƒ—eik | 1 â‰¤i1 â‰¤i2 â‰¤Â· Â· Â· â‰¤ik â‰¤n}.
Furthermore, analogous to polynomials in multiple variables where the
monomial xyx2z3y = x3y2z3, any symmetric product vector âƒ—ei1âƒ—ei2 Â· Â· Â·âƒ—eik is
equal to another expression on which the particular vectors in the product
are permuted.
C.5.2
The Alternating Product
We turn now to the alternating product, also called the wedge product.
Many of the results for the alternating product parallel the symmetric
product.

C.5. Symmetric Product and Alternating Product
395
Let V be a vector space of dimension n and let us continue to consider
the action of Sk on V âŠ—k as described in Equation (C.14). Recall the sign
of a permutation described in Deï¬nition 2.4.12.
Deï¬nition C.5.11. Let Î± âˆˆV âŠ—k be a tensor. We deï¬ne the alternation of Î±
to be
AÎ± =

ÏƒâˆˆSk
sign(Ïƒ)(Ïƒ Â· Î±).
Example C.5.12. Let V be a vector space. We consider tensors in V âŠ—V âŠ—V .
We will consider permutations in S3, which has 3! = 6 elements.
The
identity permutation has a sign of 1, permutations that interchange only
two elements have a sign of âˆ’1, and the permutations that cycle through
the three indices have a sign of 1.
A(âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e3) = âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e3 âˆ’âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e3 âˆ’âƒ—e3 âŠ—âƒ—e2 âŠ—âƒ—e1
âˆ’âƒ—e1 âŠ—âƒ—e3 âŠ—âƒ—e2 + âƒ—e2 âŠ—âƒ—e3 âŠ—âƒ—e1 + âƒ—e3 âŠ—âƒ—e1 âŠ—âƒ—e2
In contrast,
A(âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2) = âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2 âˆ’âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e2 âˆ’âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e1
âˆ’âƒ—e1 âŠ—âƒ—e2 âŠ—âƒ—e1 + âƒ—e1 âŠ—âƒ—e1 âŠ—âƒ—e1 + âƒ—e2 âŠ—âƒ—e1 âŠ—âƒ—e1
= 0
Proposition C.5.13. Let âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â·âŠ—âƒ—vk be a pure tensor in V âŠ—k. If âƒ—vi = âƒ—vj
for some pair (i, j), where i Ì¸= j, then
A(âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk) = 0.
Proof: Suppose that in the pure tensor âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk, we have âƒ—vi = âƒ—vj
for some pair i Ì¸= j. Let f âˆˆSk be the permutation that interchanges the
ith and jth entry and leaves all others ï¬xed. Deï¬ne the relation âˆ¼on Sk
by Ïƒ âˆ¼Ï„ if and only if Ï„âˆ’1Ïƒ âˆˆ{1, f}. Note that f 2 = f â—¦f = 1 is the
identity permutation, and hence, f = f âˆ’1. Because of these properties of
f, one easily checks that the relation âˆ¼is an equivalence relation on Sk.
Let C be a set of representatives for all of the equivalence classes of âˆ¼.
Then if we set Î± = âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk, we have
A(âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk) =

ÏƒâˆˆC
(sign(Ïƒ)(Ïƒ Â· Î±) + sign(Ïƒf)((Ïƒf) Â· Î±))
=

ÏƒâˆˆC
(sign(Ïƒ)(Ïƒ Â· Î±) âˆ’sign(Ïƒ)(Ïƒ Â· (f Â· Î±)))

396
C. Multilinear Algebra
=

ÏƒâˆˆC
(sign(Ïƒ)(Ïƒ Â· Î±) âˆ’sign(Ïƒ)(Ïƒ Â· Î±))
= 0
because âƒ—vi = âƒ—vj, so f Â· Î± = Î±.
â–¡
By construction, the alternation A deï¬nes a linear transformation A :
V âŠ—k â†’V âŠ—k.
Deï¬nition C.5.14. The subspace of V âŠ—k given as the image of A : V âŠ—k â†’
V âŠ—k is called the kth alternating product or the kth wedge product of V
and is denoted by k V .
Proposition C.5.15. Let {âƒ—e1,âƒ—e2, . . . ,âƒ—en} be a basis of V . Then in k V , the
elements A(âƒ—ei1âŠ—âƒ—ei2âŠ—Â· Â· Â·âŠ—âƒ—eik) are all distinct and nonzero for 1 â‰¤i1 < i2 <
Â· Â· Â· < ik â‰¤n. Furthermore, the corresponding vectors A(âƒ—ei1 âŠ—âƒ—ei2 âŠ—Â· Â· Â·âŠ—âƒ—eik)
form a basis of k V .
Corollary C.5.16. Let V be a vector space of dimension n. Then
dim
k
V =
n
k

.
Proposition C.5.17. The subspace k V is skew-invariant under the action
of Sk on V âŠ—k, i.e., for all Ïƒ âˆˆSk and for all tensors Î± âˆˆk V , we have
Ïƒ Â· Î± = sign(Ïƒ)Î±.
Proof: (Left as an exercise for the reader.)
â–¡
Corollary C.5.18. For all alternating tensors Î± âˆˆk V , we have A(Î±) = k! Î±.
Proof: By Proposition C.5.17,
A(Î±) =

ÏƒâˆˆSk
sign(Ïƒ)Ïƒ Â· Î± =

ÏƒâˆˆSk
sign(Ïƒ)2Î± = k! Î±.
â–¡
As in the case of the symmetric product, it is not hard to see that
the tensor product of alternating tensors is, in general, not another al-
ternating tensor.
However, it is possible to deï¬ne a product between
alternating tensors that produces another alternating tensor.
Deï¬nition C.5.19. Let V be a vector space, and let Î± âˆˆk V and Î² âˆˆl V .
We deï¬ne
Î± âˆ§Î² =
1
k! l!A(Î± âŠ—Î²)
so that Î± âˆ§Î² âˆˆk+l V . We call this operation Î± âˆ§Î² the exterior product
or the wedge product of Î± and Î².

C.5. Symmetric Product and Alternating Product
397
Similar properties hold for the exterior product as for the symmetric
product.
Proposition C.5.20. Let V be a vector space of dimension n. The following
hold:
1. The exterior product is bilinear: for all Î±, Î±1, Î±2 âˆˆ1k V , Î², Î²1, Î²2 âˆˆ
1l V , and Î» in the base ï¬eld,
(Î±1 + Î±2) âˆ§Î² = Î±1 âˆ§Î² + Î±2 âˆ§Î²,
(Î»Î±) âˆ§Î² = Î»(Î± âˆ§Î²),
Î± âˆ§(Î²1 + Î²2) = Î± âˆ§Î²1 + Î± âˆ§Î²2,
Î± âˆ§(Î»Î²) = Î»(Î± âˆ§Î²).
2. The exterior product is anticommutative in the sense that for all Î± âˆˆ
1k V and Î² âˆˆ1l V ,
Î² âˆ§Î± = (âˆ’1)klÎ± âˆ§Î².
3. The exterior product is associative: for all Î± âˆˆ1r V , Î² âˆˆ1s V , and
Î³ âˆˆ1t V , as an element of 1r+s+t V , we have
(Î± âˆ§Î²) âˆ§Î³ = Î± âˆ§(Î² âˆ§Î³) =
1
r! s! t!A(Î± âŠ—Î² âŠ—Î³).
Proof: Again we leave part 1 as an exercise for the reader.
For part 2, by Proposition C.5.17, A(Î± âŠ—Î²) is skew-invariant under
the action of Sk+l. As in the proof of Proposition C.5.10, consider the
permutation Ïƒ0 âˆˆSk+l that maps the n-tuple (1, 2, . . . , k + l) to (k +
1, . . . , k + l, 1, . . . , k). In each pure tensor in an expression of Î± âŠ—Î², the
action Ïƒ0 Â· (Î± âŠ—Î²) moves (and keeps in the proper order) the vector terms
coming from Î² in front of the terms coming from Î±. Hence we see that
Ïƒ0 Â· (Î± âŠ—Î²) = Î² âŠ—Î±. Also, it is not diï¬ƒcult to see how Ïƒ0 can be expressed
using kl transpositions (permutations that interchange only two elements),
and therefore, sign(Ïƒ0) = (âˆ’1)kl. Thus, we conclude that
Î² âˆ§Î± =
1
k! l!A(Î² âŠ—Î±)
=
1
k! l!A(Ïƒ0 Â· (Î± âŠ—Î²))
= sign(Ïƒ0) 1
k! l!A(Î± âŠ—Î²)
= (âˆ’1)klÎ± âˆ§Î².
Part 3, follows in a similar manner to the proof of Proposition C.5.10
with appropriate modiï¬cations, including an adaptation of Lemma C.5.9
and using Corollary C.5.18.
â–¡

398
C. Multilinear Algebra
By virtue of the associativity of the exterior product, the alternation of
a pure tensor A(âƒ—v1 âŠ—âƒ—v2 âŠ—Â· Â· Â· âŠ—âƒ—vk) is denoted by
âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vk,
where we often think of this element as an anticommutative â€œproductâ€
between vectors. This means that
âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vk
interchange i,j
= âˆ’âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vk
and also that for all Ïƒ âˆˆSk,
Ïƒ Â· (âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vk) = sign(Ïƒ)âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vk.
(C.15)
With this notation in mind, one often thinks of 1k V as a vector space in
its own right, independent of V âŠ—k, with basis
{âƒ—ei1 âˆ§âƒ—ei2 âˆ§Â· Â· Â· âˆ§âƒ—eik | 1 â‰¤i1 < i2 < Â· Â· Â· < ik â‰¤n}.
Example C.5.21. Let V = R3, and let
âƒ—v =
â›
â
1
âˆ’1
2
â
â 
and
âƒ—w =
â›
â
3
0
2
â
â 
be vectors in V . Recall that dim 12 V = 3. With respect to the standard
basis in 12 V , we have
âƒ—v âˆ§âƒ—w = (âƒ—e1 âˆ’âƒ—e2 + 2âƒ—e3) âˆ§(3âƒ—e1 + 2âƒ—e3)
= 3âƒ—e1 âˆ§âƒ—e1 + 2âƒ—e1 âˆ§âƒ—e3 âˆ’3âƒ—e2 âˆ§âƒ—e1 âˆ’2âƒ—e2 âˆ§âƒ—e3 + 6âƒ—e3 âˆ§âƒ—e1 + 4âƒ—e3 âˆ§âƒ—e3
= 2âƒ—e1 âˆ§âƒ—e3 + 3âƒ—e1 âˆ§âƒ—e2 âˆ’2âƒ—e2 âˆ§âƒ—e3 âˆ’6âƒ—e1 âˆ§âƒ—e3
= âˆ’4âƒ—e1 âˆ§âƒ—e3 + 3âƒ—e1 âˆ§âƒ—e2 âˆ’2âƒ—e2 âˆ§âƒ—e3.
For the symmetric product, recall that dim Sym2 V = 6. With respect to
the standard basis in Sym2 V , we have
âƒ—v âƒ—w = (âƒ—e1 âˆ’âƒ—e2 + 2âƒ—e3)(3âƒ—e1 + 2âƒ—e3)
= 3âƒ—e1âƒ—e1 + 2âƒ—e1âƒ—e3 âˆ’3âƒ—e2âƒ—e1 âˆ’2âƒ—e2âƒ—e3 + 6âƒ—e3âƒ—e1 + 4âƒ—e3âƒ—e3
= 3âƒ—e2
1 + 4âƒ—e2
3 âˆ’3âƒ—e1âƒ—e2 + 8âƒ—e1âƒ—e3 âˆ’2âƒ—e2âƒ—e3.
Proposition C.5.22. Let V be an n-dimensional vector space over a ï¬eld. Let
âƒ—vi for i = 1, . . . , m be m vectors in V where m < n. Let âƒ—wj for j = 1, . . . , m
be another set of vectors, with âƒ—wj âˆˆSpan(âƒ—vi) given by âƒ—wj = "
i cjiâƒ—vi. Then
âƒ—w1 âˆ§âƒ—w2 âˆ§Â· Â· Â· âˆ§âƒ—wn = (det cji)âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vn.

C.5. Symmetric Product and Alternating Product
399
Proof: This is a simple matter of calculation, as follows:
âƒ—w1âˆ§âƒ—w2âˆ§Â· Â· Â·âˆ§âƒ—wm =
 m

i1=1
c1i1âƒ—vi1

âˆ§
 m

i2=1
c2i2âƒ—vi2

âˆ§Â· Â· Â·âˆ§

m

im=1
cmimâƒ—vim

.
(C.16)
In any wedge product, if there is a repeated vector, the wedge product
is 0. Therefore, when distributing out the m summations, the only nonzero
terms are those in which all the i1, i2, . . . , im are distinct. Furthermore, by
Equation (C.15), any nonzero term can be rewritten as
âƒ—vi1 âˆ§âƒ—vi2 âˆ§Â· Â· Â· âˆ§âƒ—vim = sign(Ïƒ)âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vm,
where Ïƒ is the permutation given as a table by
Ïƒ =
 1
2
Â· Â· Â·
m
i1
i2
Â· Â· Â·
im
	
.
Furthermore, by selecting which integer is chosen for each ik in each term
on the right side of Equation (C.16), we see that every possible permutation
is used exactly once. Thus, we have
âƒ—w1âˆ§âƒ—w2âˆ§Â· Â· Â·âˆ§âƒ—wm =
â›
â
ÏƒâˆˆSm
sign(Ïƒ)c1Ïƒâˆ’1(1)c2Ïƒâˆ’1(2) Â· Â· Â· cmÏƒâˆ’1(m)
â
â âƒ—v1âˆ§âƒ—v2âˆ§Â· Â· Â·âˆ§âƒ—vm.
The content of the parentheses in the above equation is precisely the de-
terminant of the matrix (cij) and the proposition follows.
â–¡
Example C.5.23. Let V = Rn with standard basis âƒ—ei, where i = 1, 2, . . ., n.
By Proposition C.5.22, we have
âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vn = det
â›
â
|
|
|
âƒ—v1
âƒ—v2
Â· Â· Â·
âƒ—vn
|
|
|
â
â âƒ—e1 âˆ§âƒ—e2 âˆ§Â· Â· Â· âˆ§âƒ—en.
By a standard result of linear algebra, the determinant det
âƒ—v1
âƒ—v2
Â· Â· Â·
âƒ—vn

is the volume of the parallelepiped spanned by {âƒ—v1,âƒ—v2, Â· Â· Â· ,âƒ—vn}.
Furthermore, if we consider the element âƒ—eâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—eâˆ—
n âˆˆ1n V âˆ—as an
alternating multilinear function on V , we have
âƒ—eâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—eâˆ—
n(âƒ—v1, . . . ,âƒ—vn) =
 
ÏƒâˆˆSk
sign(Ïƒ)Ïƒ Â· (âƒ—eâˆ—
1 âŠ—Â· Â· Â· âŠ—âƒ—eâˆ—
n)

(âƒ—v1, . . . ,âƒ—vn)
= det
â›
â
|
|
|
âƒ—v1
âƒ—v2
Â· Â· Â·
âƒ—vn
|
|
|
â
â .
Therefore, the element âƒ—eâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—eâˆ—
n is often called the volume form on V .

400
C. Multilinear Algebra
Problems
C.5.1. Let V = R3, and consider the linear transformation T : V â†’V given by
T(âƒ—v) =
â›
â
1
2
3
4
5
6
7
8
9
â
â âƒ—v
with respect to the standard basis of R3.
(a) Prove that the function S : 12 V â†’12 V that satisï¬es
S(âƒ—v1 âˆ§âƒ—v2) = T(âƒ—v1) âˆ§T (âƒ—v2)
extends to a linear transformation.
(b) Determine the matrix of S with respect to the associated basis {âƒ—e1 âˆ§
âƒ—e2, âƒ—e2 âˆ§âƒ—e3,âƒ—e1 âˆ§âƒ—e3}.
C.5.2. Repeat the above exercise but with Sym2 V and changing the question
accordingly.
C.5.3. Prove Proposition C.5.17.
C.5.4. Prove part 1 of Proposition C.5.10.
C.5.5. Let V be a vector space over C of dimension n, and let T be a linear
transformation T : V â†’V with eigenvalues Î»i, where 1 â‰¤i â‰¤n. Let
S : 12 V â†’12 V be deï¬ned by S(âƒ—v1 âˆ§âƒ—v2) = T(âƒ—v1) âˆ§T(âƒ—v2).
(a) Prove that the eigenvalues of S are Î»iÎ»j for 1 â‰¤i < j â‰¤n.
(b) Prove that det S = (det T)nâˆ’1.
(c) Prove that the trace of S is
1
2
 n

i=1
Î»i
2
âˆ’
n

i=1
Î»2
i

.
C.5.6. Let V be a vector space over C of dimension n, and let T be a linear
transformation T : V â†’V with eigenvalues Î»i, where 1 â‰¤i â‰¤n. Let
S : Sym2 V â†’Sym2 V be deï¬ned by S(âƒ—v1âƒ—v2) = T (âƒ—v1)T(âƒ—v2).
(a) Prove that the eigenvalues of S are Î»iÎ»j for 1 â‰¤i â‰¤j â‰¤n.
(b) Prove that det S = (det T)n.
(c) Prove that the trace of S is
1
2
 n

i=1
Î»i
2
+
n

i=1
Î»2
i

.

C.6. The Wedge Product and Analytic Geometry
401
C.6
The Wedge Product and Analytic Geometry
C.6.1
Binet-Cauchy and k-Volume of Parallelepipeds
The article [29] develops the connection between the wedge product of
vectors in Rn and analytic geometry.
Most important for applications
to diï¬€erential geometry is a formula for the volume of a k-dimensional
parallelepiped in Rn. The authors of [29] give the following deï¬nition.
Deï¬nition C.6.1.
The dot product of two pure antisymmetric tensors in
1k Rn is
(âƒ—a1 âˆ§âƒ—a2 âˆ§Â· Â· Â· âˆ§âƒ—ak) Â· (âƒ—b1 âˆ§âƒ—b2 âˆ§Â· Â· Â· âˆ§âƒ—bk) =

âƒ—a1 Â·âƒ—b1
âƒ—a1 Â·âƒ—b2
Â· Â· Â·
âƒ—a1 Â·âƒ—bk
âƒ—a2 Â·âƒ—b1
âƒ—a2 Â·âƒ—b2
Â· Â· Â·
âƒ—a2 Â·âƒ—bk
...
...
...
...
âƒ—ak Â·âƒ—b1
âƒ—ak Â·âƒ—b2
Â· Â· Â·
âƒ—ak Â·âƒ—bk

.
It turns out that this deï¬nition is equivalent to the usual dot product
on 1k Rn with respect to its standard basis, namely,
{âƒ—ei1 âˆ§âƒ—ei2 âˆ§Â· Â· Â· âˆ§âƒ—eik},
with 1 â‰¤i1 < i2 < Â· Â· Â· < ik â‰¤n.
The equivalence of these two deï¬nitions is a result of the following combi-
natorial proposition.
Proposition C.6.2 (Binet-Cauchy). Let A and B be two n Ã— m matrices, with
m â‰¤n. Call I(m, n) the set of subsets of {1, 2, . . ., n} of size m and for
any S âˆˆI(m, n) ,denote AS as the mÃ—m submatrix consisting of the rows
of A indexed by S (and similarly for B). Then
det(BT A) =

SâˆˆI(m,n)
(det(BS)) (det(AS)) .
Proof: Let A = (aij) and B = (bij), with 1 â‰¤i â‰¤n and 1 â‰¤j â‰¤m. The
matrix BT A is an m Ã— m-matrix with entries
n

j=1
bjiajk,
indexed by 1 â‰¤i, k â‰¤m. Therefore, the determinant of BT A is
det(BT A) =

ÏƒâˆˆSm
sign(Ïƒ)
â›
â
n

j1=1
bj11aj1Ïƒ(1)
â
â 
â›
â
n

j2=1
bj22aj2Ïƒ(2)
â
â Â· Â· Â·
â›
â
n

jm=1
bjmmajmÏƒ(m)
â
â ,

402
C. Multilinear Algebra
where Sm is the set of permutations on the set {1, 2, . . ., m}. Then, after
rearranging the order of summation, we have
det(BT A)
=

ÏƒâˆˆSm
n

j1=1
n

j2=1
Â· Â· Â·
n

jm=1
sign(Ïƒ)bj11bj22 Â· Â· Â· bjmmaj1Ïƒ(1)aj2Ïƒ(2) Â· Â· Â· ajmÏƒ(m)
=
n

j1=1
n

j2=1
Â· Â· Â·
n

jm=1
bj11bj22 Â· Â· Â· bjmm
 
ÏƒâˆˆSm
sign(Ïƒ)aj1Ïƒ(1)aj2Ïƒ(2) Â· Â· Â· ajmÏƒ(m)

.
Because of the sign of the permutation, any term in the summation where
not all the jl are distinct is equal to 0. Therefore, we only need to consider
the summation over sets of indices j = (j1, j2, . . . , jm) âˆˆ{1, . . . , m}n, where
all of the indices are distinct. We can parametrize this set in an alternative
manner as follows. Let I(m, n) be the set of indices in increasing order,
i.e.,
I(m, n) = {(j1, j2, . . . , jm) âˆˆ{1, . . . , n}m | 1 â‰¤j1 < j2 < Â· Â· Â· < jm â‰¤n} .
(C.17)
The set I(m, n) Ã— Sm is in bijection with the set of all m-tuples of indices
that are distinct via
(j, Ïƒ) â†’(jÏƒ(1), . . . , jÏƒ(m)).
We can now write
det(BT A) =

jâˆˆI(m,n)

Ï„âˆˆSm
bjÏ„(1)1bjÏ„(2)2 Â· Â· Â· bjÏ„(m)m
 
ÏƒâˆˆSm
sign(Ïƒ)ajÏ„(1)Ïƒ(1)ajÏ„(2)Ïƒ(2) Â· Â· Â· ajÏ„(m)Ïƒ(m)

=

jâˆˆI(m,n)

Ï„âˆˆSm
bjÏ„(1)1bjÏ„(2)2 Â· Â· Â· bjÏ„(m)m sign(Ï„)
 
Ïƒâ€²âˆˆSm
sign(Ïƒâ€²)aj1Ïƒâ€²(1)aj2Ïƒâ€²(2) Â· Â· Â· ajmÏƒâ€²(m)

=

jâˆˆI(m,n)

Ï„âˆˆSm
sign(Ï„)bjÏ„(1)1bjÏ„(2)2 Â· Â· Â· bjÏ„(m)m det Aj.
where Aj is the m Ã— m submatrix obtained from A by using only the rows
given in the m-tuple index j. Then we conclude that
det(BT A) =

jâˆˆI(m,n)

Ï„âˆˆSm
sign(Ï„)bj1Ï„ âˆ’1(1)bj2Ï„ âˆ’1(2) Â· Â· Â· bjmÏ„ âˆ’1(m) det Aj
=

jâˆˆI(m,n)

det BT
j

(det Aj) ,

C.6. The Wedge Product and Analytic Geometry
403
and the proposition follows since det(CT ) = det(C) for any square ma-
trix C.
â–¡
Corollary C.6.3. Deï¬nition C.6.1 is equivalent to the dot product on 1k Rn
with respect to the standard basis.
Proof: If âƒ—a1,âƒ—a2, . . . ,âƒ—ak is a k-tuple of vectors in Rn, call A the nÃ—k-matrix
that has the vector âƒ—ai as the ith column. Deï¬ne P(n, k) as in Proposition
C.6.2. For any subset S of {1, 2, . . ., n} of cardinality k, deï¬ne
âƒ—eS = âƒ—es1 âˆ§âƒ—es2 âˆ§Â· Â· Â· âˆ§âƒ—esk,
where S = {s1, s2, . . . , sk}, with the elements listed in increasing order. It
is not hard to check that
a1 âˆ§âƒ—a2 âˆ§Â· Â· Â· âˆ§âƒ—ak =

SâˆˆP (n,k)
(det(AS))âƒ—eS.
(C.18)
The corollary follows immediately from Proposition C.6.2.
â–¡
As with a usual Euclidean vector space Rn, we deï¬ne the Euclidean
norm in the following way.
Deï¬nition C.6.4. Let a = âƒ—a1 âˆ§âƒ—a2 âˆ§Â· Â· Â· âˆ§âƒ—ak âˆˆ1k Rn. The (Euclidean) norm
of this vector is
âˆ¥âƒ—a1 âˆ§âƒ—a2 âˆ§Â· Â· Â· âˆ§âƒ—akâˆ¥= âˆša Â· a.
Corollary C.6.5. The k-dimensional volume of a parallelepiped in Rn spanned
by k vectors âƒ—v1,âƒ—v2, . . . ,âƒ—vk is given by
âˆ¥âƒ—v1 âˆ§âƒ—v2 âˆ§Â· Â· Â· âˆ§âƒ—vkâˆ¥.
Proof: It is a standard fact in linear algebra (see [13, Fact 6.3.7]) that the
k-volume of the described parallelepiped is

det(AT A), where A is the
matrix that has the vector âƒ—vi as the ith column. The corollary follows from
Deï¬nitions C.6.1 and C.6.4.
â–¡
C.6.2
The Volume Form Revisited
In Example C.5.23, we introduced the volume form on Rn in reference to the
standard basis. This is not quite satisfactory for our applications because
the standard basis has internal properties, namely that it is orthonormal
with respect to the dot product. The following proposition presents the
volume form on a vector space in its most general context. (Note that,
since the order in which we list basis vectors matters in what follows, we
think of a basis as an n-tuple of vectors as opposed to a set of vectors.)

404
C. Multilinear Algebra
Proposition C.6.6. Let V be an n-dimensional vector space with a symmetric,
positive-deï¬nite, bilinear form âŸ¨, âŸ©. Then there exists a unique form Ï‰ âˆˆ
1n V âˆ—such that Ï‰(âƒ—e1, . . . ,âƒ—en) = 1 for all oriented bases (âƒ—e1, . . . ,âƒ—en) of V
that are orthonormal with respect to âŸ¨, âŸ©. Furthermore, if (âƒ—u1, . . . , âƒ—un) is
any oriented basis of V , then
Ï‰ =
âˆš
det A âƒ—uâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—uâˆ—
n,
where A is the matrix with entries Aij = (âŸ¨âƒ—ui, âƒ—ujâŸ©).
Proof: (In this proof, we use superscripts for the coordinates of vectors in
order to mesh with the notation in Section 5.1, where this proposition is
explicitly used.)
Let (âƒ—u1, . . . , âƒ—un) be any basis of V and let âƒ—v = "
i aiâƒ—ui and âƒ—w =
"
i biâƒ—ui be two vectors in V along with their coordinates with respect to
(âƒ—u1, . . . , âƒ—un). Then by the linearity of the form,
âŸ¨âƒ—v, âƒ—wâŸ©=
n

i,j=1
aibjâŸ¨âƒ—ui, âƒ—ujâŸ©= âƒ—vT Aâƒ—w.
We remark that det A Ì¸= 0 because otherwise there would exist some
nonzero vector âƒ—v such that Aâƒ—v = 0 and then âŸ¨âƒ—v,âƒ—vâŸ©= 0, which would
contradict the positive-deï¬nite property of the form.
The existence of an orthonormal basis with respect to âŸ¨, âŸ©follows from
the Gram-Schmidt orthonormalization process.
If (âƒ—e1, . . . ,âƒ—en) is an or-
thonormal basis with respect to âŸ¨, âŸ©, then the associated matrix (âŸ¨âƒ—ei,âƒ—ejâŸ©)
is the identity matrix.
Given an orthonormal basis {âƒ—e1, . . . ,âƒ—en}, let {âƒ—eâˆ—
1, . . . ,âƒ—eâˆ—
n} by the dual
cobasis of V âˆ—. Set Ï‰ = âƒ—eâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—eâˆ—
n. Obviously, Ï‰(âƒ—e1, . . . ,âƒ—en) = 1. Now, if
(âƒ—u1, . . . , âƒ—un) is any other orthonormal basis of V with the same orientation
of (âƒ—e1, . . . ,âƒ—en), then det(M T M) = 1, where M is the transition matrix
from coordinates in (âƒ—u1, . . . , âƒ—un) and coordinates in (âƒ—e1, . . . ,âƒ—en). Hence,
det(M)2 = 1, and the assumption that (âƒ—u1, . . . , âƒ—un) has the same orienta-
tion as (âƒ—e1, . . . ,âƒ—en) means that det(M) is positive. Thus, det M = 1.
By Corollary C.3.4, the transition matrix from coordinates in (âƒ—eâˆ—
1, . . . ,âƒ—eâˆ—
n)
to coordinates in (âƒ—uâˆ—
1, . . . , âƒ—uâˆ—
n) is M T . However, by Proposition C.5.22, we
then conclude that
Ï‰ = âƒ—eâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—eâˆ—
n = det(M) âƒ—uâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—uâˆ—
n = âƒ—uâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—uâˆ—
n.
Since eâˆ—
1 âˆ§Â· Â· Â· âˆ§eâˆ—
n(e1, . . . , en) = 1, then Ï‰ evaluates to 1 on all bases of V
that are orthonormal and have the same orientation as {âƒ—e1, . . . ,âƒ—en}.

C.6. The Wedge Product and Analytic Geometry
405
Suppose now that {âƒ—u1, . . . , âƒ—un} is a basis of V but not necessarily or-
thonormal. If we write M = (mij), then by deï¬nition of the transition
matrix,
âƒ—ui =
n

j=1
mjiâƒ—ej.
(Note that it is no longer necessarily true that det M = 1.) Then we can
calculate the coeï¬ƒcients of A as
âŸ¨âƒ—ui, âƒ—ujâŸ©=
6 n

k=1
mkiâƒ—ek,
n

l=1
mljâƒ—el
7
=
n

k=1
n

l=1
mkimljâŸ¨âƒ—ei,âƒ—ejâŸ©
=
n

k=1
n

l=1
mkimljÎ´ij
=
n

k=1
n

l=1
mkimkj.
Hence, we have shown that A = M T M. We conclude that
Ï‰ = det(M) âƒ—uâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—uâˆ—
n =
âˆš
det A âƒ—uâˆ—
1 âˆ§Â· Â· Â· âˆ§âƒ—uâˆ—
n.
â–¡
Deï¬nition C.6.7. Let V be equipped with a symmetric, positive-deï¬nite, bi-
linear form. Then the element Ï‰ âˆˆ1n V âˆ—deï¬ned in Proposition C.6.6 is
called the volume form of V .
C.6.3
The Hodge Star Operator
We conclude this section by introducing an operator on wedge product
spaces 1k V . In this subsection, we assume throughout that V is a ï¬nite
dimensional inner product space, i.e., that V is a vector space equipped
with a symmetric, positive-deï¬nite, bilinear form âŸ¨, âŸ©.
The inner product âŸ¨, âŸ©deï¬nes a natural linear transformation i : V â†’
V âˆ—via
i(âƒ—v)(âƒ—w) = iâƒ—v(âƒ—w) = âŸ¨âƒ—v, âƒ—wâŸ©.
That âŸ¨, âŸ©is positive deï¬nite implies that i is in fact an isomorphism. This
isomorphism i allows us to extend âŸ¨, âŸ©in a natural way to V âˆ—by setting
âŸ¨Î·, Ï„âŸ©= âŸ¨iâˆ’1(Î·), iâˆ’1(Ï„)âŸ©
(C.19)
for all Î·, Ï„ âˆˆV âˆ—. It is easy to see that this gives an inner product on V âˆ—.
Proposition C.6.8. Let Î·1, . . . , Î·k, Ï„1, . . . , Ï„k âˆˆV âˆ—. Setting
âŸ¨Î·1 âˆ§. . . âˆ§Î·k, Ï„1 âˆ§. . . âˆ§Ï„kâŸ©= det(âŸ¨Î·i, Ï„jâŸ©)
deï¬nes a bilinear form on 1k V âˆ—that is symmetric and positive deï¬nite.

406
C. Multilinear Algebra
Proof: (Left as an exercise for the reader. See Problem C.6.7.)
â–¡
Deï¬nition C.6.9. Let (V, âŸ¨, âŸ©) be an inner product space of dimension n, and
let Ï‰ âˆˆ1n V âˆ—be the volume form. The Hodge star operator is the operator
â‹†: 1k V âˆ—â†’1nâˆ’k V âˆ—that is uniquely determined by
âŸ¨â‹†Î·, Ï„âŸ©Ï‰ = Î· âˆ§Ï„
for all Ï„ âˆˆ1nâˆ’k V âˆ—.
The Hodge star operator has the following nice properties, which we
leave as exercises.
Proposition C.6.10. Let (V, âŸ¨, âŸ©) be an inner product space. Let B = {e1, . . . ,
en} be a basis that is orthonormal with respect to âŸ¨, âŸ©, and let Bâˆ—=
{eâˆ—
1, . . . , eâˆ—
n} be the dual cobasis of V âˆ—.
Set Ï‰ as the volume form with
respect to âŸ¨, âŸ©.
1. The Hodge star operator â‹†is well deï¬ned and linear.
2. Viewing 1 as an element of R = 10 V , we have â‹†1 = Ï‰.
3. For any k < n, we have â‹†(eâˆ—
1 âˆ§Â· Â· Â· âˆ§eâˆ—
k) = eâˆ—
k+1 âˆ§Â· Â· Â· âˆ§eâˆ—
n.
4. For any k-tuple (i1, . . . , ik) of increasing indices,
â‹†(eâˆ—
i1 âˆ§Â· Â· Â· âˆ§eâˆ—
ik) = (sign Ïƒ) eâˆ—
j1 âˆ§Â· Â· Â· âˆ§eâˆ—
jnâˆ’k,
where the jl indices are such that {i1, . . . , ik, j1, . . . , jnâˆ’k} = {1, . . ., n}
and Ïƒ is the permutation that maps the ordered n-tuple (i1, . . . , ik,
j1, . . . , jnâˆ’k) to (1, 2, . . . , n).
The following proposition gives a formula for the coordinates of the â‹†Î·
in terms of the coordinates of Î·.
Proposition C.6.11. Let V be a vector space equipped with an inner product
âŸ¨, âŸ©. Let B = {âƒ—u1, . . . , âƒ—un} be any basis of V , and denote by {uâˆ—
1, . . . , uâˆ—
n} its
cobasis in V âˆ—. Let A be the matrix with entries aij = (âŸ¨ui, ujâŸ©), and label
aij the (i, j)th entry of the inverse Aâˆ’1. If Î· âˆˆ1k V âˆ—, with coordinates
Î·i1Â·Â·Â·ik, so that
Î· =

1â‰¤i1<Â·Â·Â·<ikâ‰¤n
Î·i1Â·Â·Â·ik uâˆ—
i1 âˆ§Â· Â· Â· âˆ§uâˆ—
ik,

C.6. The Wedge Product and Analytic Geometry
407
then the components of â‹†Î· with respect to Bâˆ—are
(â‹†Î·)j1Â·Â·Â·jnâˆ’k =
âˆš
det A
k!
Îµi1Â·Â·Â·ikj1Â·Â·Â·jnâˆ’kai1h1 Â· Â· Â· aikhkÎ·h1Â·Â·Â·hk,
where Îµh1Â·Â·Â·hn is the permutation symbol deï¬ned in Equation (2.30) and
where on the right-hand side one sums from 1 to n over all indices that are
repeated, namely i1, . . . , ik and h1, . . . , hk.
Proof: By a calculation similar to the one in the proof of Proposition C.6.6
and using the deï¬nition of the inner product on 1-forms given in Equa-
tion (C.19), we determine that
âŸ¨uâˆ—
i , uâˆ—
jâŸ©= aij,
i.e., the (i, j)th entry of the inverse Aâˆ’1.
As above, denote by Ï‰ the volume form on V associated to âŸ¨, âŸ©.
A few preliminary notations will render the rest of the proof shorter.
Recall the set I(m, n) deï¬ned in Equation (C.17). For any sequence i =
(i1, . . . , ik) âˆˆI(k, n), we denote by uâˆ—
i the wedge product
uâˆ—
i = uâˆ—
i1 âˆ§Â· Â· Â· âˆ§uâˆ—
ik.
Denote also by iâ€² the increasing sequence of length nâˆ’k such that {i, iâ€²} =
{1, 2, . . ., n}. We call iâ€² the complement of i. We deï¬ne the permutation
Ïƒi âˆˆSn by the permutation that maps the sequence (1, 2, . . . , n) to the
sequence (i, iâ€²). Note that the sign of the permutation satisï¬es
sign Ïƒi = Îµi1Â·Â·Â·ikiâ€²
1Â·Â·Â·iâ€²
nâˆ’k.
Consider the kth wedge product uâˆ—
i . According to Deï¬nition C.6.9,
âŸ¨â‹†uâˆ—
i , Ï„âŸ©Ï‰ = uâˆ—
i âˆ§Ï„.
(C.20)
We know that {uâˆ—
j } for j âˆˆI(n âˆ’k, n) forms a basis of 1nâˆ’k V âˆ—. Thus, we
can write
â‹†uâˆ—
i =

jâˆˆI(nâˆ’k,n)
cjuâˆ—
j
for some constants cj. However, Equation (C.20) imposes that âŸ¨â‹†uâˆ—
i , uâˆ—
j âŸ©= 0
unless j = iâ€². We denote K = âŸ¨â‹†uâˆ—
i , uâˆ—
iâ€²âŸ©.
By Deï¬nition C.6.9, âŸ¨â‹†uâˆ—
i , uâˆ—
iâ€²âŸ©Ï‰ = uâˆ—
i âˆ§uâˆ—
iâ€² so by Proposition C.6.6,
âŸ¨â‹†uâˆ—
i , uâˆ—
iâ€²âŸ©
âˆš
det A uâˆ—
1 âˆ§Â· Â· Â· âˆ§uâˆ—
n = (sign Ïƒi) uâˆ—
1 âˆ§Â· Â· Â· âˆ§uâˆ—
n,

408
C. Multilinear Algebra
which implies that
âŸ¨â‹†uâˆ—
i , uâˆ—
j âŸ©= (sign Ïƒi)/
âˆš
det A Î´j,iâ€²,
where Î´j,iâ€² = 1 if j = iâ€² and equals 0 otherwise. On the other hand,
âŸ¨â‹†uâˆ—
i , uâˆ—
j âŸ©=

lâˆˆI(nâˆ’k,n)
clâŸ¨uâˆ—
l , uâˆ—
j âŸ©=

lâˆˆI(nâˆ’k,n)
cl det((Aâˆ’1)lj),
where by Alj we mean the minor of A consisting of the rows l = (l1, . . . , lnâˆ’k)
and columns j = (j1, . . . , jnâˆ’k). So, we conclude that

lâˆˆI(nâˆ’k,n)
cl det((Aâˆ’1)lj) = sign Ïƒi
âˆš
det A
Î´j,iâ€².
(C.21)
To ï¬nd the values of cj for a given i, we need to invert the matrix product
in Equation (C.21), or more precisely, ï¬nd the inverse of the
n
k

Ã—
n
k

matrix det((Aâˆ’1)lj). Though a little tedious to show, the following formula
generalizes the Laplace expansion formula for determinants. For any n Ã— n
matrix B, with notations as above,
det B =

jâˆˆI(k,n)
(sign Ïƒi)(sign Ïƒj) det Bij det Biâ€²jâ€².
A slightly stronger result gives

jâˆˆI(k,n)
det Bij(sign Ïƒh)(sign Ïƒj) det Bhâ€²jâ€² =

det B
if h = i,
0
otherwise,
for all h âˆˆI(k, n). Now multiplying Equation (C.21) by (sign Ïƒh)(sign Ïƒj)âˆ—
det(Aâˆ’1)hâ€²jâ€², summing the result over j âˆˆI(n âˆ’k, n), and taking into
account Î´j,iâ€², we obtain
det(Aâˆ’1)ch = sign Ïƒi
âˆš
det A
(sign Ïƒh)(sign Ïƒjâ€²) det(Aâˆ’1)hâ€²i,
which implies that
ch = (sign Ïƒh)
âˆš
det A det(Aâˆ’1)hâ€²i.
From this we deduce that
â‹†(uâˆ—
i1âˆ§Â· Â· Â·âˆ§uâˆ—
ik) =
n

j1=1
Â· Â· Â·
n

jn=1
âˆš
det A
(n âˆ’k)!Îµj1Â·Â·Â·jnaj1i1 Â· Â· Â· ajkik(uâˆ—
jk+1âˆ§Â· Â· Â·âˆ§uâˆ—
jn),
(C.22)
and the proposition follows by linearity of the Hodge star operator.
â–¡

C.6. The Wedge Product and Analytic Geometry
409
We point out that one can loosen the conditions on the bilinear form
âŸ¨, âŸ©and still deï¬ne the Hodge star operator and obtain many of the same
results. If we only assume that âŸ¨, âŸ©is symmetric and nondegenerate, then
all the above propositions hold except that one must replace det A with
| det A| in Proposition C.6.11.
Problems
C.6.1. Use the results of this section to calculate the surface of the parallelogram
in R3 spanned by
âƒ—v =
â›
â
1
âˆ’3
7
â
â 
and
âƒ—v =
â›
â
4
5
âˆ’2
â
â .
C.6.2. Calculate the 3-volume of the parallelepiped in R4 spanned by
âƒ—a =
â›
âœ
âœ
â
0,
âˆ’2
2
1
â
âŸ
âŸ
â ,
âƒ—b =
â›
âœ
âœ
â
3
1
âˆ’1
0
â
âŸ
âŸ
â ,
and
âƒ—c =
â›
âœ
âœ
â
5
1
âˆ’2
âˆ’3
â
âŸ
âŸ
â .
C.6.3. Using the same vectors âƒ—a, âƒ—b, and âƒ—c in the previous exercise, determine all
vectors âƒ—x such that the four-dimensional parallelepiped spanned by âƒ—a, âƒ—b,
âƒ—c, and âƒ—x has dimension 0.
C.6.4. Verify the claim in Equation (C.18).
C.6.5. This exercise gives an interesting property about the derivative of deter-
minants of square matrices of functions. Let A = (aij(t)) be an n Ã— n
matrix of functions.
(a) Use the standard formula
det A =

ÏƒâˆˆSn
(sign Ïƒ)a1Ïƒ(1)a2Ïƒ(2) Â· Â· Â· anÏƒ(n).
to show that
d
dt(det A) =
n

i=1
n

j=1
(âˆ’1)i+j det(Aij)daij
dt ,
where Aij is the ijth minor of A.
(b) Conclude that if A is a symmetric matrix, then
d
dt(det A) = (det A)
n

i,j=1
aij daij
dt ,
where the aij are the entries of the inverse matrix Aâˆ’1.

410
C. Multilinear Algebra
C.6.6. A Higher Pythagorean Theorem. Let âƒ—a, âƒ—b, and âƒ—c be three vectors in Rn that
are mutually perpendicular.
(a) Prove that
âˆ¥âƒ—a âˆ§âƒ—b + âƒ—a âˆ§âƒ—c +âƒ—b âˆ§âƒ—câˆ¥2 = âˆ¥âƒ—a âˆ§âƒ—bâˆ¥2 + âˆ¥âƒ—a âˆ§âƒ—câˆ¥2 + âˆ¥âƒ—b âˆ§âƒ—câˆ¥2.
(b) Consider the tetrahedron spanned by âƒ—a, âƒ—b, and âƒ—c. Let SC be the
face spanned by âƒ—a and âƒ—b, SB be the face spanned by âƒ—a and âƒ—c, SA be
the face spanned by âƒ—b and âƒ—c, and let SD be the fourth face of the
tetrahedron. Deduce that
S2
A + S2
B + S2
C = S2
D.
C.6.7. Prove Proposition C.6.8.
C.6.8. Prove Proposition C.6.10.
C.6.9. Let (V, âŸ¨, âŸ©) be an inner product space. Prove that the composition â‹†â—¦â‹†:
1k V âˆ—â†’1k V âˆ—is tantamount to multiplication on V âˆ—by (âˆ’1)k(nâˆ’k).
Suppose that âŸ¨, âŸ©is a symmetric and nondegenerate bilinear form. Prove
that in this case â‹†â—¦â‹†: 1k V âˆ—â†’1k V âˆ—is tantamount to multiplication
on V âˆ—by (âˆ’1)k(nâˆ’k)s, where s is the sign of the determinant of the form
matrix for the form.

Bibliography
[1] Ralph Abraham and Jerrold E. Marsden. Foundations of Mechanics. Read-
ing, MA: Benjamin-Gummings, 1978.
[2] M. A. Armstrong. Basic Topology, Undergraduate Texts in Mathematics.
New York: Springer-Verlag, 1983.
[3] Vladimir I. Arnold. Ordinary Diï¬€erential Equations. Cambridge, MA: MIT
Press, 1973.
[4] Andreas Arvanitoyeorgos. An Introduction to Lie Groups and the Geometry
of Homogeneous Spaces, Student Mathematical Library 22. Providence, RI:
American Mathematical Society, 1999.
[5] Thomas F. Banchoï¬€and Stephen T. Lovett. Diï¬€erential Geometry of Curves
and Surfaces. Natick, MA: A K Peters, Ltd., 2010.
[6] Victor Bangert. â€œOn the Existence of Closed Geodesics on Two-Spheres.â€
International J. of Math. 4:1 (1993), 1â€“10.
[7] Rolf Berndt. An Introduction to Symplectic Geometry, Graduate Studies in
Mathematics 26. Providence, RI: American Mathematical Society, 2001.
[8] Arthur L. Besse. Einstein Manifolds. New York: Springer-Verlag, 2007.
[9] George David Birkhoï¬€. â€œDynamical Systems with Two Degrees of Freedom.â€
Trans. Am. Math. Soc. 18:2 (1917), 199â€“300.
[10] Roberto Bonola. Non-Euclidean Geometry: A Critical and Historical Study
of its Developments. New York: Dover Publications, 1955.
[11] Glen E. Bredon. Topology and Geometry, Graduate Texts in Mathematics
139. New York: Springer-Verlag, 1993.
[12] David M. Bressoud. A Radical Approach to Lebesgueâ€™s Theory of Integration.
Cambridge, UK: Cambridge University Press, 2008.
[13] Otto Bretscher.
Linear Algebra with Applications, Third edition.
Upper
Saddle River, NJ: Pearson Prentice Hall, 2005.
[14] Andrew Browder. Mathematical Analysis: An Introduction, Undergraduate
Texts in Mathematics. New York: Springer-Verlag, 1996.
[15] Shiing-Shen Chern. Global Diï¬€erential Geometry, MAA Studies 27. Wash-
ington, DC: Mathematical Association of America, 1989.
[16] Manfredo do Carmo. Riemannian Geometry. Boston, MA: BirkhÂ¨auser, 1992.
411

412
Bibliography
[17] P. H. Doyle and D. A. Moran. â€œA Short Proof That Compact 2-manifolds
Can Be Triangulated.â€ Invent. Math. 5:2 (1968), 160â€“162.
[18] C. Henry Edwards and David E. Penny. Diï¬€erential Equations: Computing
and Modeling, Third edition.
Upper Saddle River, NJ: Pearson Prentice
Hall, 2004.
[19] Albert Einstein. â€œDie Feldgleichungen der Gravitation.â€ Sitzungsberichte der
Preussischen Akademie der Wissenschaften zu Berlin 25 (1915), 844â€“847.
[20] Albert Einstein. Relativity: The Special and the General Theory. New York:
Crown Publishers, Inc., 1961.
[21] Grant R. Fowles. Analytical Mechanics, Fourth edition. Philadelphia: Saun-
ders College Publishing, 1986.
[22] John Franks. â€œGeodesics on S2 and Periodic Points of Annulus Diï¬€eomor-
phisms.â€ Invent. Math. 108:2 (1992), 403â€“418.
[23] Anthony P. French.
Special Relativity.
The M.I.T. Introductory Physics
Series. New York: W. W. Norton & Company, 1968.
[24] Joseph A. Gallian.
Contemporary Abstract Algebra, Sixth. edition.
New
York: Houghton Miï¬„in Company, 2006.
[25] George Gamow. My World Line: An Informal Autobiography. New York:
Viking Press, 1970.
[26] Michael C. Gemignani. Elementary Topology, Second edition. New York:
Dover Publications, 1972.
[27] John G. Hocking and Gail S. Young. Topology. New York: Dover Publica-
tions, 1961.
[28] Michel A. Kervaire and John W. Milnor. â€œGroups of Homotopy Spheres: I.â€
Annals of Math. 77:3 (1963), 504â€“537.
[29] Mehrdad Khosravi and Michael D. Taylor. â€œThe Wedge Product and Ana-
lytic Geometry.â€ American Mathematical Monthly 115:7 (2008), 623â€“644.
[30] Serge Lang. Algebra, Third edition. Reading, MA: Addison-Wesley, 1993.
[31] John M. Lee. Riemannian Manifolds: An Introduction to Curvature, Grad-
uate Texts in Mathematics 176. New York: Springer-Verlag, 1997.
[32] John M. Lee. Introduction to Smooth Manifolds, Graduate Texts in Mathe-
matics 218. New York: Springer-Verlag, 2003.
[33] Martin M. Lipshutz. Diï¬€erential Geometry, Schaumâ€™s Outline Series. New
York: McGraw-Hill, 1969.
[34] Malcolm Longair. Theoretical Concepts in Physics, Second edition. Cam-
bridge, UK: Cambridge University Press, 2003.
[35] David Lovelock and Hanno Rund. Tensors, Diï¬€erential Forms and Varia-
tional Principles. New York: Dover Publications, 1989.
[36] L. Lusternik and L. Schnirelmann. â€œSur le probl`eme de trois gÂ´eodÂ´esiques
fermÂ´ees sur les surfaces de Genre 0.â€
C. R. Acad. Sci. SÂ´er. I Math 189
(1929), 269â€“271.

Bibliography
413
[37] John McCleary. Geometry from a Diï¬€erentiable Viewpoint. Cambridge, UK:
Cambridge University Press, 1994.
[38] John W. Milnor and James D. Stasheï¬€. Characteristic Classes, Annals of
Mathematics Studies 76. Princeton, NJ: Princeton University Press, 1994.
[39] Charles W. Misner, Kip S. Thorne, and John Archibald Wheeler. Gravita-
tion. San Francisco: W. H. Freeman and Company, 1973.
[40] Thomas Moore. Six Ideas that Shaped Physics: Unit R, Second edition. New
York: McGraw-Hill, 2002.
[41] James Munkres. Topology. Englewood Cliï¬€s, NJ: Prentice Hall, 1975.
[42] Mikio Nakahara. Geometry, Topology and Physics, Second edition. Boca
Raton, FL: Taylor & Francis, 2003.
[43] Barrett Oâ€™Neill. Semi-Riemannian Geometry with Applications to Relativity,
Pure and Applied Mathematics 103. New York: Academic Press, 1983.
[44] Edward M. Purcell. Electricity and Magnetism, Berkeley Physics Course 2.
New York: McGraw-Hill, 1985.
[45] G. F. Bernhard Riemann. â€œOn the Hypotheses Which Lie at the Foundation
of Geometry.â€ In From Kant to Hilbert: A Source Book in the Foundations
of Mathematics, Vol. 2, edited by William Bragg Ewald, pp. 651â€“652. New
York: Oxford University Press, 1996.
[46] Halsey L. Royden. Real Analysis. Englewood Cliï¬€s, NJ: Prentice Hall, 1988.
[47] Walter Rudin. Principles of Mathematical Analysis. New York: McGraw-
Hill, 1976.
[48] Melvin Schwartz. Principles of Electromagnetism. New York: Dover Publi-
cations, 1987.
[49] Michael Spivak. A Comprehensive Guide to Diï¬€erential Geometry, Volume
One. Berkeley, CA: Publish or Perish Inc., 1979.
[50] Norman Steenrod. The Topology of Fibre Bundles. Princeton, NJ: Princeton
University Press, 1951.
[51] Hans Stephani. General Relativity. Cambridge, UK: Cambridge University
Press, 1982.
[52] James Stewart. Calculus, Sixth edition. Belmont, CA: Thomson Brooks/
Cole, 2003.
[53] Keith R. Symon. Mechanics. Reading, MA: Addison-Wesley, 1971.
[54] E. R. van Kampen. â€œOn the Argument Functions of Simple Closed Curves
and Simple Arcs.â€ Compositio Mathematica 4 (1937), 271â€“275.
[55] Robert Weinstock. Calculus of Variations. New York: McGraw-Hill, 1952.
[56] Hermann Weyl. The Concept of a Riemannian Surface, Third edition. Read-
ing, MA: Addison-Wesley, 1955. Translated from the German by Gerald R.
Maclane.
[57] Barton Zwiebach. A First Course in String Theory. Cambridge, UK: Cam-
bridge University Press, 2005.



